{
  "courses": [
    {
      "title": "Visualização de dados para Data Science com R: Criando Mapas",
      "url": "https://www.udemy.com/course/mapasnor/",
      "bio": "Aprenda a analisar dados georreferenciados. Vendo os dados de uma outra perspectiva",
      "objectives": [
        "Construir Shapes de Países",
        "Mostrar regiões específicas no Mapa",
        "Mostrar a malha de estados por municípios ou outras subdivisões",
        "Aplicar o Merge a diferentes bancos de dados (combinar bancos)",
        "Construir Visualizações de Pontos específicos no Mapa",
        "Mostrar vários pontos simultaneamente no Mapa",
        "Criar textos explicativos para cada ponto no Mapa",
        "Criar retângulos em regiões de interesse no Mapa",
        "E muito mais utilidades usando mapas no R"
      ],
      "course_content": {},
      "requirements": [
        "Aconselho fazer meu curso de Linguagem R do Zero."
      ],
      "description": "Olá!!! Tudo joia?!!\nMeu nome é Isaías Lira, sou Bacharel em Estatística, Especialista em Docência Superior e Consultor em Análise de Dados e quero muito que a Estatística deixe de ser um problema para você e passe a ser uma nova HABILIDADE para sua carreira profissional ... Vamos lá?!!\n*Por que criei este curso?\nData Scientist (Cientista de Dados, profissional em Análise de Dados) foi classificado como o primeiro emprego no Glassdoor e com salário de mais de mais de $ 120,000 nos Estados Unidos e é sem dúvida a função com vagas sobrando e sem gente capacitada para preenchê-la. É a carreira mais valiosa no momento, pois permite resolver alguns dos problemas mais interessantes do mundo.\nCom o avanço dos aplicativos que usam dados geográficos, as empresas tem tido uma grande necessidade de profissionais para analisar estes tipos de dados como localizações de clientes, fornecedores, operações, ocorrências, etc. Grandes avanços acontecem a cada dia nesta área de geolocalização, e por isso que criei este curso, para tornar você apto(a) a trabalhar com dados georeferenciados no R.\nE se você já programa em outra linguagem, saiba que a principal linguagem para Data Scientist é o R por ser gratuito, completo, suportar grandes massas de dados e ter integrações com quase tudo (SQL, Power BI, Java, etc). Por que não dar este grande salto para Data Science?\n\nEste curso é avaliado em milhares de dólares, mas agora você pode aprender toda essa informação por um preço simbólico!\nCom muito conteúdo em vídeo, vários exercícios, didática simplificada e abordagem inovadora, fizeram deste curso um dos cursos mais abrangentes e mais procurados para ciência de dados e aprendizagem de máquinas na Udemy com língua Portuguesa!\n*O que você vai aprender?\nVamos ensinar-lhe como visualizar uma variável de interesse (vendas, clientes, etc.) por geolocalização (países, municípios, estados, condados, etc.) usando o R!\n\n\nEste curso é diferente por que é o mais simples neste tema! É verdadeiramente um passo a passo para quem quer começar a plotar no mapa usando o próprio R, informações úteis para a tomada de decisão na empresa ou instituição.\nÉ um curso 100% prático, onde você vai:\nDesta forma, mesmo que você tem pavor de números, terá sucesso neste curso!\n\nNão posso esperar para vê-lo na aula...\nInscreva-se no curso e torne-se cientista de dados mais completo ainda hoje! O que você tem a perder?\nObs: Uma grande dificuldade das pessoas é juntar tudo numa ordem lógica (saber o que aprender primeiro, segundo, etc.), então pensando nisto queria te situar na ORDEM DOS CURSOS:\n#1: Curso sobre o R\n#2: Visualização de Dados no R\n#3: Mapas no R\n#4: Correlação no R\n#5: Curso de SPSS\n#6: Regressão Linear no SPSS-R-Excel\n#7: Comparação de Dois Grupos no SPSS\nDevido às atualizações de aperfeiçoamento, estes nomes podem ser alterados o que pode dificultar sua procura aqui no Udemy, então logado no Udemy faça:  \"Meus Cursos\" > Clique no curso MEU em que vc está matriculado > Nas aulas clique em \"Ir ao Painel\" > \"Visão geral\" > No fim tem Instrutor e clique em meu nome > Ok. veja a relação completa de meus cursos.\nForte abraço e estou ansioso para conhecer você!",
      "target_audience": [
        "Leigos interessados em aprender como mostrar dados em Mapas usando o R",
        "Profissionais de TI, estudantes, pesquisadores e qualquer pessoa que deseja analisar dados em mapas no R"
      ]
    },
    {
      "title": "Machine Learning, Text Mining, Explainable AI. Crash-Course.",
      "url": "https://www.udemy.com/course/text-mining-max/",
      "bio": "Курс про text mining та класифікацію текстів, розглядаються різні підходи та варіації методів для роботи з даними.",
      "objectives": [
        "Підготовку датасету",
        "Кросс-валідація",
        "Задачі класифікації текстів",
        "Методи векторизації та обробки тексту",
        "SVM та MLP для text mining",
        "Візуалізація результатів",
        "Шляхи до покращення"
      ],
      "course_content": {
        "Вступ": [
          "Вступ"
        ],
        "Підготовка датасету": [
          "1.1. Критерії датасету",
          "1.2. Збір датасету",
          "1.3. Розмітка датасету",
          "Модуль 1. Завдання для самостійної роботи"
        ],
        "Кросс-валідація": [
          "2.1. Розподіл між тестувальним та тренувальним даними",
          "2.2. K-fold cross-validation",
          "2.3. Знаходження accuracy",
          "2.4. Знаходження f1, precision, recall",
          "Модуль 2. Завдання для самостійної роботи"
        ],
        "Задачі класифікації текстів": [
          "3.1. Рекрутинг",
          "3.2. Стилізація",
          "3.3. Авторство",
          "3.4. Fake news",
          "3.5. Рекомендаційні механізми",
          "3.6. Інтелектуальний аналіз",
          "Модуль 3. Завдання для самостійної роботи"
        ],
        "Методи векторизації та обробки тексту": [
          "4.1. Hashing vectorizer",
          "4.2. Tfidfvectorizer",
          "4.3. Count vectorizer",
          "4.4. Стемінг",
          "Модуль 4. Завдання для самостійної роботи"
        ],
        "SVM та MLP для text mining": [
          "5.1. MLP (Multilayer Perseptron)",
          "5.2. SVM (Support Vector Machines)",
          "5.3. SVR (Support Vector Regression)",
          "5.4. SVC (C-Support Vector Classification)",
          "Модуль 5. Завдання для самостійної роботи"
        ],
        "Візуалізація результатів": [
          "6.2. Візуальна валідація",
          "6.3. Аналіз результатів",
          "Модуль 6. Завдання для самостійної роботи"
        ],
        "Шляхи до покращення": [
          "7.1. Додаткова обробка",
          "7.2. Робота із фічами",
          "Модуль 7. Завдання для самостійної роботи"
        ],
        "Бонус. Технологія роботи з текстовими даними": [
          "8.1. Вступ",
          "8.3. Розбір реального проекту",
          "8.4. Налаштування робочого середовища",
          "8.5. Розмітка датасету та класифікація тексту",
          "8.6. Векторизація",
          "8.7. Архітектура нейронної мережі",
          "8.2. Сфера застосування Text Mining",
          "8.8. Візуалізація результату",
          "8.9. Напрямки розвитку технології",
          "8.10. Препроцесінг тексту",
          "8.11. Основні тези",
          "8.12. Automated Machine Learning",
          "8.13. Софт для локальної роботи (рекомендації)",
          "8.14. Робота з Іменами в тексті"
        ]
      },
      "requirements": [
        "Необхідні навички програмування на Python"
      ],
      "description": "Величезна кількість інформації представлена в неструктурованому вигляді, і навчитися її використовувати, отже, підвищити ефективність роботи з клієнтами, збільшити продажі, швидко реагувати на скарги, вміти оцінювати результати маркетингових кампаній.\n\n\nУСІМ СТУДЕНТАМ БЕЗКОШТОВНІ КОНСУЛЬТАЦІЇ\n\n\nНаукові статті пов'язані з цим курсом Ви можете знайти в Google Scholar за пошуком Maksym Lupei.\n\n\nGithub: TMining repository.\n\n\nКрім того, грамотний аналіз інформації, представленої в текстовому вигляді (в мережі інтернет та ін.), відкриває додаткові можливості для зростання та розширення бізнесу. Для досягнення цих цілей служать технології Data Mining і Text Mining.\n\n\nКлючовими групами завдань Text Mining є: категоризація текстів, вилучення інформації та інформаційний пошук, обробка змін у колекціях текстів, а також розробка засобів подання інформації для користувача.\n\n\nОстаннім часом аналіз тексту привертає дедалі більше уваги різних галузях, таких як безпека, комерція, наука.\n\n\nЦей курс охоплюватиме основні методи вилучення та аналізу текстових даних для виявлення цікавих закономірностей, отримання корисних знань та підтримки прийняття рішень, з акцентом на статистичні підходи, які в цілому можуть застосовуватися до довільних текстових даних будь-якою звичайною мовою з нульовою або мінімальною участю людини.\n\n\nДетальний аналіз текстових даних вимагає розуміння тексту звичайною мовою, що, як відомо, є складним завданням для комп'ютерів. Однак було показано, що ряд статистичних підходів добре працюють для «поверхневого», але надійного аналізу текстових даних для пошуку закономірностей та виявлення інформації. Ви вивчите основні поняття, принципи та основні алгоритми інтелектуального аналізу тексту та їх можливе застосування.",
      "target_audience": [
        "Підходить для тих, хто розв’язує прикладні задачі по text mining та хоче отримати практичні навички а також для тих, хто цікавиться ML та його прикладними задачами"
      ]
    },
    {
      "title": "商业人工智能 (Artificial Intelligence for Business)",
      "url": "https://www.udemy.com/course/artificial-intelligence-for-business-chinese/",
      "bio": "人工智能解决方案解决现实世界中的业务问题 (英文原音)",
      "objectives": [
        "优化业务流程",
        "掌握通用人工智能框架",
        "实施Q-Learning",
        "保存并加载模型",
        "建立优化模型",
        "实施\"早停\"",
        "最大化效率",
        "最大化收入",
        "最小化成本",
        "实施汤普森采样",
        "实施深度Q学习",
        "利用人工智能做出最佳决策",
        "从头构建人工智能环境",
        "实施在线学习",
        "建立一个人工大脑",
        "实施遗憾分析"
      ],
      "course_content": {
        "第一章. 介绍": [
          "介绍"
        ],
        "-------------------- 第一部分 - 优化商业流程 --------------------": [
          "欢迎来到第一部分 - 优化商业流程"
        ],
        "案例研究": [
          "优化商业流程 - 步骤 1",
          "优化商业流程 - 步骤 2",
          "优化商业流程 - 步骤 3",
          "优化商业流程 - 步骤 4"
        ],
        "AI 解决方案": [
          "欢迎使用直觉部分",
          "进攻计划",
          "深度Q学习直觉-步骤1",
          "深度Q学习直觉-步骤2",
          "经验重播",
          "行动选择策略"
        ],
        "实施": [
          "最小化成本 - 步骤 4",
          "最小化成本 - 步骤 5",
          "最小化成本 - 步骤 6",
          "最小化成本 - 步骤 7",
          "最小化成本 - 步骤 8",
          "最小化成本 - 步骤 9",
          "最小化成本 - 步骤 10",
          "最小化成本 - 步骤 11",
          "最小化成本 - 步骤 12",
          "最小化成本 - 步骤 13",
          "最小化成本 - 步骤 14",
          "最小化成本 - 步骤 15",
          "最小化成本 - 步骤 16",
          "最小化成本 - 步骤 17",
          "最小化成本 - 步骤 18",
          "最小化成本 - 步骤 19",
          "最小化成本 - 步骤 20",
          "最小化成本 - 步骤 21",
          "最小化成本 - 步骤 22",
          "最小化成本 - 步骤 23",
          "最小化成本 - 步骤 24",
          "最小化成本 - 步骤 25",
          "最小化成本 - 步骤 26",
          "最小化成本 - 步骤 27",
          "最小化成本 - 步骤 28",
          "最小化成本 - 步骤 29",
          "最小化成本 - 步骤 30",
          "最小化成本 - 步骤 31",
          "最小化成本 - 步骤 32",
          "安装 Keras",
          "最小化成本 - 步骤 33",
          "最小化成本 - 步骤 34",
          "最小化成本 - 步骤 35",
          "最小化成本 - 步骤 36"
        ],
        "家庭作业": [
          "家庭作业指南",
          "家庭作业解决方案"
        ],
        "-------------------- 第二部分 - 最小化成本 --------------------": [
          "欢迎来到第二部分 - 最小化成本"
        ],
        "案例分析": [
          "最小化成本 - 步骤 1",
          "最小化成本 - 步骤 2",
          "最小化成本 - 步骤 3"
        ]
      },
      "requirements": [
        "高中数学",
        "基本的python知识"
      ],
      "description": "课程结构：\n\n\n第1部分-优化业务流程\n案例研究：优化电子商务仓库的流程\n人工智能解决方案：Q学习\n\n\n第2部分-最小化成本\n案例研究：最小化数据中心的能耗成本\n人工智能解决方案：深度Q学习\n\n\n第3部分-最大化收入\n案例研究：最大化在线零售业务的收入\n人工智能解决方案：汤普森抽样\n\n\n真实业务应用程序：\n使用人工智能，您可以为任何业务做三件主要事情：\n\n\n1.优化业务流程\n2.降低成本\n3.实现收入最大化\n\n\n我们将通过真实的商业案例研究，向您展示如何成功完成这些应用。对于这些应用中的每一个，我们都将构建一个独立的人工智能来解决这个挑战。\n\n在第1部分-优化流程中，我们将构建一个将优化电子商务仓库流的人工智能。\n\n\n在第2部分-最小化成本中，我们将构建一个更高级的人工智能，将数据中心的能耗成本降低50%以上！就像谷歌去年由于DeepMind所做的那样。\n\n在第3部分-最大化收入，我们将建立一个不同的人工智能，将最大化在线零售业务的收入，使其收入超过10亿美元！\n\n\n但这并不是全部，这次，也是第一次，我们为您准备了一项巨大的创新。通过本课程，您将获得一个令人难以置信的额外产品，对您的职业生涯非常有价值：\n“一本100页的书，涵盖了商业人工智能的所有内容！”.\n\n\n\n这本书：\n\n\n这本书包括：\n•100页清晰明了的解释，用漂亮干净的格式书写\n•所有人工智能直觉和理论，包括详细的数学解释\n•课程的三个案例研究及其解决方案\n•三种不同的人工智能模型，包括Q学习、深度Q学习和汤普森抽样\n•代码模板\n•家庭作业及其解决方案供您练习\n•此外，还有许多额外的技术和技巧，如保存和加载模型、“早停”等等。\n\n\n结论：\n\n如果你想找到一份高薪的工作或在人工智能领域创建自己的成功企业，那么这就是你需要的课程。\n今天，借助商业人工智能，将你的人工智能事业推向新的高度，这是推动你事业进一步发展的终极人工智能课程。",
      "target_audience": [
        "业务驱动型人员，他们渴望学习如何利用人工智能优化业务、最大化盈利能力和效率。",
        "人工智能从业者，他们想知道他们可以为员工提供什么项目",
        "有抱负的数据科学家，寻找商业案例加入到在他们的知识组合中",
        "有兴趣利用机器学习和人工智能解决业务问题的技术爱好者",
        "希望将公司转变为人工智能驱动企业的顾问"
      ]
    },
    {
      "title": "Python ile Veri Bilimi & Makine Öğrenmesi Projeleri A-Z™",
      "url": "https://www.udemy.com/course/python-ile-veri-bilimi-makine-ogrenmesi-projeleri-a-ztm/",
      "bio": "Kaggle'da Gerçek Dünya Projelerini Çözüp, Tüm Dünya ile Paylaşarak Veri Bilimi Kariyerinizi Bir Sonraki Seviyeye Taşıyın",
      "objectives": [
        "Kaggle platformunda CV'niz için çok faydalı bir sayfa inşa edeceksiniz",
        "Ders sonunda yapacağımız proje ile tüm dünyaya yayın yapacaksınız",
        "Farklı görselleştirme teknikleri ile hem veriyi anlamanız kolaylaşacak hem de data science alanında vizyonunuz genişleyecek",
        "Veri görselleştirme temel kütüphanelerinden olan matplotlib, seaborn ve plotly konusunda uzmanlaşacaksınız",
        "Makine öğrenmesi ile sınıflandırma ve tahmin algoritmaları geliştirebileceksiniz",
        "Makine öğrenmesi projelerinizi tüm dünya ile buluşturacaksınız"
      ],
      "course_content": {
        "Veri Bilimi ve Makine Öğrenmesi Projeleri Giriş": [
          "Giriş",
          "Datai Team: Github ve Kaynaklar"
        ],
        "Kaggle": [
          "Kaggle Nedir?",
          "Kayıt ve Üye Girişi",
          "Ana Sayfa",
          "Yarışmalar",
          "Veri Setleri",
          "Kodlama ve Not Defteri",
          "Tartışma",
          "Courses",
          "Kullanıcı Sıralaması ve İlerleme",
          "Etiketler ve Blog",
          "Kullanıcı Sayfası",
          "Baştan Sona Not Defteri Oluşturma ve Yayınlama",
          "Kaggle Veri Seti İnceleme",
          "Kaggle'da Başarılı Olmak İçin Neler Yapmalı?"
        ],
        "Dünya Mutluluğu Veri Seti Keşifsel Veri Analizi": [
          "Giriş",
          "Python Kütüphaneleri",
          "Veri İçeriği",
          "Veri Seti Yükleme ve Hızlı Analiz",
          "2021 Yılı Özellik Dağılımları",
          "2021'de En Mutlu ve En Mutsuz Ülkeler",
          "Bölgesel Göstergeye Göre Mutluluk Puanı Dağılımı",
          "Harita Görünümünde Ülkelere Göre Mutluluk Puanı Dağılımı",
          "2021'de En Cömert ve Cömert Olmayan Ülkeler",
          "Harita Görünümünde Ülkelere Göre Cömertlik Dağılımı",
          "2021'de Bölgesel Göstergeye Göre Cömertlik Dağılımı",
          "Mutluluk ve Gelir Arasındaki İlişki",
          "Mutluluk ve Özgürlük Arasındaki İlişki",
          "Mutluluk ve Yolsuzluk Arasındaki İlişki",
          "Özellikler Arasındaki İlişki",
          "Sonuç"
        ],
        "Kalp Krizi Analizi Ve Tahmini": [
          "Giriş",
          "Python Kütüphaneleri",
          "Veri İçeriği",
          "Veri Seti Yükleme ve Hızlı Analiz",
          "Kayıp Veri Analizi",
          "Eşsiz Değer Analizi",
          "Kategorik Özellik Analizi",
          "Sayısal Özellik Analizi",
          "Standardizasyon",
          "Kutu Plot Analizi",
          "Swarm Plot Analizi",
          "Cat Plot Analizi",
          "Korelasyon analizi",
          "Aykırı Değer Algılama (Outlier Detection)",
          "Kategorik Sütunları Kodlama (Encoding)",
          "Ölçekleme (Scaling)",
          "Eğitim Test Veri Seti Ayrımı",
          "Lojistik Regresyon ile Sınıflandırma",
          "Lojistik Regresyon Hiperparametre Optimizasyonu",
          "Sonuç"
        ],
        "1957 Yılından Günümüze Uzay Görevleri": [
          "Giriş",
          "Python Kütüphaneleri",
          "Veri İçeriği",
          "Veri Seti Yükleme ve Hızlı Analiz",
          "Şirketlere Göre Roket Fırlatma Sayısı",
          "Roket Durumu",
          "Görev Durumu",
          "Roket Durumuyla Roket Maliyet Dağılımı",
          "Görev Başarımı ile Roket Maliyet Dağılımı",
          "Şirketlerin Toplam Maliyeti",
          "Yıllara Göre Görev Sayıları",
          "Ülkeler ve Görev Durumu",
          "Güneş ışığı Haritası Analizi (Sunburst Chart)",
          "Dünya Haritasında Ülkelere Göre Durum Misyonu",
          "Sonuç"
        ],
        "Su Kalitesi Keşifsel Veri Analizi": [
          "Giriş",
          "Python Kütüphaneleri",
          "Veri İçeriği",
          "Veri Seti Yükleme ve Hızlı Analiz",
          "Bağımlı Değişken Analizi",
          "Özellikler Arasındaki İlişki",
          "Özelliklerin Dağılımı",
          "Önişleme: Eksik Veri Sorunu",
          "Ön İşleme: Eğitim-Test Veri Seti Bölmesi ve Normalleştirme",
          "Modelleme: Karar Ağacı ve Rastgele Orman Sınıflandırıcıları",
          "Karar Ağacını Görselleştirme",
          "Rastgele Ormanlar Hiperparametre Optimizasyonu",
          "Sonuç"
        ],
        "Veri Bilimi ve Makine Öğrenmesi Projeleri Sonuç": [
          "Sonuç",
          "BONUS"
        ]
      },
      "requirements": [
        "İnternet bağlantılı bir bilgisayara sahip olmak yeterlidir",
        "Machine Learning ve Python: A'dan Z'ye Makine Öğrenmesi (4) yada veri bilimi, veri görselleştirme ve makine öğrenmesi temellerinin bilinmesi gerekli"
      ],
      "description": "Python ile Veri Bilimi & Makine Öğrenmesi Projeleri A-Z™\nKaggle'da Gerçek Dünya Projelerini Çözüp, Tüm Dünya ile Paylaşarak Veri Bilimi Kariyerinizi Bir Sonraki Seviyeye Taşıyın\nPython ile Veri Bilimi & Makine Öğrenmesi Projeleri Kursu İçeriği\nKeşifsel-Açıklayı Veri Analizi (Exploratory Data Science)\nİki Değişkenli ve Çok Değişkenli Veri Analizi\nSeaborn ve Plotly Kütüphaneleri ile İleri Seviye Görselleştirme\nÇoklu Veri Seti ile Çalışma\nKümeleme (Clutering)\nAykırı Değer Tespiti (Outlier Detection)\nStandardizasyon ve Normalizasyon\nKayıp Veri Sorunu (Missing Value )\nÖz Nitelik Mühendisliği (Feature Engineering ): One Hot Encoding\nRastgele Ormanlar, Lojistik Regresyon, Karar Ağaçları Sınıflandırıcıları\nKarar Ağaçları Görselleştirme\nHiperparametre Optimizasyonu\nPython ile Veri Bilimi & Makine Öğrenmesi Projeleri Kursu Projeleri\nDünya Mutluluğu Veri Seti Keşifsel Veri Analizi\nKalp Krizi Analizi Ve Tahmini\n1957 Yılından Günümüze Uzay Görevleri\nSu Kalitesi Keşifsel Veri Analizi\nNeden Python?\nPython 2020 IEEE araştırmasına göre dünya çapında en çok kullanılan ve tercih edilen programlama dillerinden\nPython kolay öğrenilebilirliği sayesinde kodlamaya yeni başlayanların ilk tercihi oluyor.\nPython open source (açık kaynak) olması nedeni ile Facebook yada Google gibi dünyanın en büyük şirketleri tarafından destekleniyor.\nGörüntü işleme, veri bilimi, makine öğrenmesi yada yapay zeka denince akla ilk olarak Python dili geliyor. Bu durumda Python'ın dünya çapında büyük bir kitlesinin olmasına neden oluyor.\nPython öğrenmesi en kolay olan dillerin başında geliyor.\nKariyer açısından Python en çok fırsata sahip dillerinden biri.\nNeden Data Science?\nİnsanların daha hızlı ve etkili kararlar vermesine yardımcı,\nVerinin artması ile veri bilimcilere olan talep ve iş fırsatları,\nStart-up fırsatları,\nKarar verme yetisi.\nNeden Data Visualization?\nİnsan beyni çok karmaşık bir yapıyı görselleştirerek kolay bir şekilde anlamlandırabilir,\nData içerisinde bilgiye ulaşmayı kolaylaştırır,\nVeri biliminin temellerindendir,\nAnlaması ve uygulaması kolaydır.\nNeden Makine Öğrenmesi?\nİş sahası çok geniş,\nDünya yapay zeka yani makine öğrenmesine doğru inanılmaz hızlı sürükleniyor,\nMakine öğrenmesi geleceği parlak meslek dallarının olmazsa olmazı,\nBir veriden derinlemesine bilgi çıkarmaya olanak sağlıyor.\nBu Kurs ile Alacaklarınız\nSıfırdan Kodlama Becerisi: Sizinle birlikte kod yazıyoruz. Her ders boş bir sayfa ile başlar ve kodu sıfırdan yazarız. Bu şekilde ilerleyebilir ve kodun nasıl bir araya geldiğini ve her satırın ne anlama geldiğini tam olarak anlayabilirsiniz.\nKodlar ve Şablonları: Kursta oluşturduğumuz her Python şablonlarını ve kodunu indirebilirsiniz. Bu, sizlere hem daha sonra kod üzerinde pratik yapma hem de kendi projelerinizi şablon sayesinde daha kolay bir şekilde yaratma imkanı sağlayacaktır\nTeori ve Mantık: Size yalnızca kod yazmayı değil, hem yazdığımız kodun arkasında yatan mantığı ve teoriyi hem de neden böyle bir kod yazdığımızı anlatıyoruz.\nKurs içi destek: Size sadece video ile ders anlatımı yapmıyoruz. Size destek olmak için profesyonel Veri Bilimcilerinden oluşan bir ekip oluşturduk. Bu da ders ve ya ders dışı sorularınıza en fazla 72 saat içinde yanıt alacağınız anlamına geliyor.\nHemen kaydolun ve bir an önce başlayalım.",
      "target_audience": [
        "Veri bilimi ve veri görselleştirme alanlarında uzmanlaşmak isteyen",
        "Python dilinde uzmanlaşmak isteyenler",
        "Eğitim yada kariyerini veri bilimi(data science), makine öğrenmesi(machine learning) yada yapay zeka(artificial intelligence) alanlarında başlamak yada sürdürmek isteyenler",
        "Makine öğrenmesi konusunda uzmanlaşmak isteyenler",
        "Yapay zeka temellerini oluşturmak isteyenler",
        "Makine öğrenmesini iş hayatında uygulamak isteyenler"
      ]
    },
    {
      "title": "【AIアプリ開発コース・パート3】【TensorFlow 2 + OpenCV】マスク着用判定AIアプリ開発入門",
      "url": "https://www.udemy.com/course/opencv_maskdetect/",
      "bio": "TensorFlow 2とOpenCVを用いて、静止画・動画ファイル・ライブ映像のマスク着用状態の判定を行うプログラムを作成してみよう！",
      "objectives": [
        "マスク着用判定AIアプリの開発手法を学べる",
        "畳み込みニューラルネットワークによる画像分類アプリケーション開発手法を学べる",
        "OpenCV（HAARカスケード判定器）による顔画像の検出手法を学べる",
        "Google ColaboratoryによるAIアプリケーション開発手法を学べる",
        "静止画像をアップロードして、マスク有無を判定するアプリをGoogle Colaboraory上で作れる",
        "MP4動画ファイルやWebカメラのライブストリームを与えて、マスク着用有無を判定するPythonアプリを作れる",
        "TensorFlow GPU環境でWebカメラ映像の判定アプリを動作させる手順を理解できる",
        "M1チップ(Apple Silicon) を搭載したMacにTensorFlow-metalをインストールし、Webカメラ映像の判定アプリを動作させる手順を理解できる"
      ],
      "course_content": {
        "イントロ": [
          "このコースの概要"
        ],
        "Google Colabノートブックの追加とライブラリのインポート": [
          "Colabノートブックの追加とライブラリのインポート",
          "開発のステップ"
        ],
        "データセットのダウンロード（Kaggle）": [
          "データのダウンロードと展開",
          "データを確認してみよう",
          "データを可視化してみよう",
          "データの増量"
        ],
        "AIモデルの定義とトレーニング": [
          "CNNモデルの定義",
          "コンパイルと学習",
          "評価とテスト"
        ],
        "学習したモデルを用いた推定": [
          "静止画像の判定",
          "トレーニングと静止画判定に使用したノートブック",
          "課題１：静止画像の判定"
        ],
        "動画像の判定にチャレンジしよう": [
          "ローカル環境構築",
          "ビデオファイルの判定（モデルのロード）",
          "HAARカスケード判定器のインポート",
          "HAAR判定器についての参考資料",
          "動画（MP4ファイル）を判定してみよう",
          "課題２：動画ファイルから判定",
          "ライブ映像を判定してみよう",
          "課題３：ライブ映像の解析",
          "セクションで作成したプログラムのソースコード"
        ],
        "（オプション）GPU環境で実行してみよう": [
          "このセクションに取り組む上での注意",
          "動画解析をTensorFlow GPU環境で実行してみよう"
        ],
        "（オプション）M1 Macで動画判定プログラムを実行してみよう": [
          "M1 MacにTensorFlowとOpenCVをインストールしてアプリを動かしてみよう"
        ],
        "ボーナスセクション": [
          "最後に"
        ]
      },
      "requirements": [
        "Webブラウザが使えるデバイス",
        "インターネット接続",
        "Google Chromeブラウザ",
        "Google Colaboratory（Googleアカウントを作成すれば無料で使用可能、時間制限あり）",
        "ローカル環境で動くアプリを作るにはWindows 10, またはmacOS最新版",
        "Webカメラ（ライブ映像を解析したい場合）内蔵カメラでもOK",
        "M1 Mac (tensorflow-metalを試したい場合、必須ではありません。）",
        "NVIDIA社製GeForceグラフィックボード（TensorFlow GPUを試したい場合。必須ではありません。）"
      ],
      "description": "【更新情報】\n2021/10/19\nM1 MacにMiniforgeをインストールし、Tensorflow + OpenCV + Pillowをインストールして、判定アプリを動作させる手順を紹介するレクチャーを追加しました。\n2021/10/15\nTensorFlow GPU環境で判定アプリを動作させる手順を解説するレクチャーを追加しました。\n\n\n【コース概要】\nこのコースでは、TensorFlowとOpenCV（HAARカスケード判定器）を用いて、静止画・動画・ウェブカメラからの動画ストリームを分析し、人間の顔を検出し、マスクの着用の有無を判定・表示するアプリケーションを開発します。\nようやくコロナも収束し、仕事や学校生活などの日常が戻ってきた方も多いと思います。\nしかし、これから冬を迎えるにあたり、マスク着用や手指消毒などの感染対策が引き続き欠かせません。\nそこで、今回は\nライブカメラ映像を入力として与え\nリアルタイムに動画像を解析し\n人間の顔が写っている領域を検出し\nマスク着用の有無を判定・ラベルを表示する\nアプリを開発するコースを制作しました。\n\n\n【コースの構成】\n今回は、まずは手軽なGoogle Colabを用いて、\nマスク着用・非着用データのダウンロード\nモデルの定義とトレーニング\n静止画をアップロードして判定するプログラム\nHAARカスケード判定器で顔領域を検出\n検出した領域をファイルに保存\nファイルをTensorFlowのモデルに投入してマスク着用有無を判定\nを作成します。\nそして次に\nローカル環境にTensorFlow, OpenCVをインストール\n動画ファイルを指定して、マスク着用有無を判定\nWebカメラを入力として与えて、マスク着用有無を判定\nTensorFlow GPU版 (Windows 10)で高速実行にチャレンジ\nM1 Macでカメラ映像の判定にチャレンジ\nと進めていきます。",
      "target_audience": [
        "実用的AIアプリ開発手法を学びたい方",
        "Google ColaboratoryをAIアプリ開発に用いる手法を学びたい方",
        "Webカメラ映像からマスク着用有無を判定するアプリを開発して、職場などで活用したい方",
        "M1 MacでTensorFlowが動作する環境を作る手順を知りたい方"
      ]
    },
    {
      "title": "Excel: Tablas Dinámicas para el Manejo de Datos.",
      "url": "https://www.udemy.com/course/tablas-dinamicas-analisis-de-datos-en-excel/",
      "bio": "Aprende diferentes herramientas para trabajar con Tablas Dinámicas y realizar diversos Reportes.",
      "objectives": [
        "Utilizar Tablas Dinámicas para el análisis de datos.",
        "Crear Gráficos Dinámicos con los que mostrar los resultados de las Tablas Dinámicas.",
        "Crear, modificar, actualizar, configurar y eliminar Tablas Dinámicas.",
        "Aprenderás a crear reportes con tablas dinámicas."
      ],
      "course_content": {
        "Tabla Dinámica": [
          "Qué es una Tabla Dinámica",
          "Diferencia entre Tabla y Tabla Dinámica",
          "Como estructurar, organizar una Tabla Dinámica (filtros)",
          "Configuración de Campos",
          "Gráficos dinámicos y segmentación",
          "Tabla dinámica con macros",
          "Cálculos con tablas dinámicas",
          "Múltiples reportes con tablas dinámicas",
          "Ejercicios práctico de tablas dinámicas"
        ]
      },
      "requirements": [
        "Conocimiento básico de Excel."
      ],
      "description": "Las tablas dinámicas en Excel nos ayudan a trabajar con grandes volúmenes de información, nos permite filtrar de manera adecuada los datos que necesitamos, visualizar los campos de la base de datos que estamos utilizando y cambiar fácilmente las columnas y filas con las que queremos trabajar en la hoja de cálculo.\nLa principal finalidad de las tablas dinámicas es resumir y analizar los datos de toda la tabla o base de datos que estamos trabajando, de modo que nos permita trabajar casi que de manera automática en cualquier ámbito (laboral o personal).\nCuando tenemos tablas dinámicas en Excel de una o varias hojas podemos realizar análisis más profundos mediante la agrupación o filtrado de cada valor numérico. Así mismo, apoyados con los gráficos en Excel podemos comparar grandes cantidades de datos, o mediante las tablas, realizar cruces de datos para describir data relevante que nos permita ser más eficiente en el trabajo, los negocios o en los asuntos personales.\nAl finalizar el curso, podrás:\nCrear, modificar, actualizar, configurar y eliminar Tablas Dinámicas en las que mostrar diferentes tipos de resultados y visualizaciones.\nOrdenar y filtrar la información que se muestra en las Tablas Dinámicas.\nConfigurar las diferentes opciones y diseños para cambiar la estructura y aspecto de las Tablas Dinámicas.\nCrear Gráficos Dinámicos con los que mostrar los resultados de las Tablas Dinámicas de una manera más visual, pero sin perder la funcionalidad de las Tablas.",
      "target_audience": [
        "Usuarios que desean aprender a trabajar con Tablas Dinámicas para el manejo de datos."
      ]
    },
    {
      "title": "Python Para Finanzas",
      "url": "https://www.udemy.com/course/python-para-finanzas/",
      "bio": "Optimización de un Portafolio de Inversiones. Métricas de Inversión y Estadística Aplicada a los Mercados Financieros.",
      "objectives": [
        "Optimizar un Portafolio de Inversiones",
        "Python",
        "Extracción y Tratamiento de datos Fianancieros",
        "Metricas de Inversión",
        "Estadística Aplicada en las Finanzas.",
        "Como usar y Obtener Indicadores Técnicos.",
        "Detección de Patrones Técnicos de manera automatica",
        "Pandas",
        "Numpy"
      ],
      "course_content": {},
      "requirements": [
        "Ser una persona proactiva en el aprendizaje"
      ],
      "description": "¿Estás invirtiendo, pero no sabes si tu portafolio está realmente bien optimizado?\n¿Quieres tomar decisiones basadas en datos, no en intuiciones?\n\n\nCon este curso práctico de Python para Finanzas, aprenderás a analizar, medir y optimizar tus inversiones como lo hacen los profesionales.\n\n\n¿Qué aprenderás?\nNo es un curso teórico. Es un entrenamiento práctico para que puedas aplicar lo aprendido en tus propias inversiones:\n\n\nPython básico: domina los fundamentos para trabajar con datos financieros.\nTransformación de datos con Pandas y Numpy: aprende a limpiar, organizar y analizar grandes volúmenes de información.\nExtracción de datos financieros: conecta con APIs y accede a información clave de acciones, ETFs y otros activos.\nEstadística aplicada a las finanzas: comprende métricas esenciales para evaluar tus inversiones.\nOptimización de portafolios: aplica la Teoría de Markowitz en Python para encontrar la mejor combinación de activos.\n¿Por qué este curso?\nPorque no te quedas en la teoría: te llevas el código completo para reutilizarlo en tus inversiones.\nAl finalizar, tendrás las herramientas para medir el rendimiento real de tu portafolio y optimizarlo de forma profesional.\n“Lo que no se mide, no se puede mejorar.” – Peter Drucker\n¿Qué vas a lograr?\nComprender qué métricas realmente importan a la hora de invertir.\nAprender a construir portafolios más eficientes, maximizando el rendimiento ajustado al riesgo.\nIncorporar Python como tu herramienta de análisis financiero.\nEmpieza hoy mismo\nCada día que inviertes sin medir ni optimizar tu portafolio, corres el riesgo de perder oportunidades.\nInscríbete ahora y aprende a invertir con datos, no con corazonadas.",
      "target_audience": [
        "Personas interesadas en el Mundo de la finanzas",
        "Desarrolladores que quieran aprender como aplicar la programación en el mundo financiero.",
        "Estudiantes de Informatica",
        "Estudiantes de Economía",
        "Inversores que quieran Optimizar su portafolio de Inversión"
      ]
    },
    {
      "title": "Rastreamento de Objetos com Python e OpenCV",
      "url": "https://www.udemy.com/course/rastreamento-objetos-python-opencv/",
      "bio": "Utilize 12 algoritmos diferentes para rastreamento de objetos em vídeos e pela webcam",
      "objectives": [
        "Rastreie objetos de vídeos e pela webcam utilizando o Python e o OpenCV",
        "Entenda a teoria básica dos principais algoritmos de rastreamento de objetos",
        "Implemente 12 algoritmos de rastreamento de objetos",
        "Entenda as diferenças entre detecção de objetos e rastreamento de objetos"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Recursos para download - ATUALIZAÇÃO NOS FONTES"
        ],
        "Rastreamento de objetos": [
          "Rastreamento de objetos x Detecção de objetos",
          "Algoritmos de rastreamento de objetos - complementar",
          "Algoritmos BOOSTING e MIL",
          "Algoritmos KCF e CSRT",
          "Algoritmos MedianFlow, TLD, MOSSE e Goturn",
          "Instalação das ferramentas",
          "Rastreamento de um objeto 1",
          "Rastreamento de um objeto 2",
          "Rastreamento de um objeto 3",
          "Rastreamento de um objeto 4",
          "Rastreamento de mais objetos 1",
          "Rastreamento de mais objetos 2",
          "Rastreamento de mais objetos 3",
          "Rastreamento com Goturn",
          "Detecção de objetos",
          "Detecção de objetos + rastreamento 1",
          "Detecção de objetos + rastreamento 2",
          "Algoritmo Meanshift - teoria",
          "Algoritmo Meanshift - implementação 1",
          "Algoritmo Meanshift - implementação 2",
          "Algoritmo CAMShift - teoria",
          "Algoritmo CAMShift - implementação",
          "Algoritmo Optical Flow Sparse – teoria",
          "Algoritmo Optical Flow Sparse – implementação 1",
          "Algoritmo Optical Flow Sparse – implementação 2",
          "Algoritmo Optical Flow Sparse – implementação 3",
          "Algoritmo Optical Flow Dense – teoria",
          "Algoritmo Optical Flow Dense – implementação",
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição (if e for)",
        "Conhecimentos básicos sobre Python são desejáveis",
        "Conhecimentos básicos sobre o OpenCV são desejáveis (não obrigatório)"
      ],
      "description": "Dentro da área da Visão Computacional existe a sub-área de rastreamento de objetos, que visa localizar um objeto em quadros sucessivos de um vídeo. Um exemplo de aplicação é um sistema de vigilância e segurança por vídeos, no qual ações suspeitas podem ser detectadas. Outros exemplos é o monitoramento de tráfego em rodovias e também a análise do movimento de jogadores em uma partida de futebol! Neste último exemplo, é possível traçar a rota completa que o jogador seguiu durante a partida\nE para levar você até essa área, neste curso você aprenderá os principais algoritmos de rastreamento de objetos utilizando a linguagem Python e a biblioteca OpenCV! Você aprenderá o básico da teoria de 12 (doze) dos principais algoritmos e fará as implementações passo a passo! Ao final do curso você saberá como aplicar rastreamento em vídeos e pela webcam e poderá desenvolver os seus próprios projetos.\nOs seguintes algoritmos serão abordados: Boosting, MIL (Multiple Instance Learning), KCF (Kernel Correlation Filters), CSRT (Discriminative Correlation Filter with Channel and Spatial Reliability), MedianFlow, TLD (Tracking Learning Detection), MOSSE (Minimum Output Sum of Squared Error), Goturn (Generic Object Tracking Using Regression Networks), Meanshift, CAMShift (Continuously Adaptive Meanshift), Optical Flow Sparse e Optical Flow Dense.\nO objetivo principal deste curso é que você tenha uma visão prática de como utilizar o OpenCV nesses projetos, portanto, nós mostraremos somente uma intuição básica sobre o funcionamento dos algoritmos. Este curso é para todos os níveis, ou seja, se este for o seu primeiro contato com a área de Visão Computacional você conseguirá acompanhar o curso. Da mesma forma, se você já tem experiência na área também aproveitará o conhecimento adquirido com o desenvolvimento dos projetos práticos.",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial",
        "Pessoas interessadas na área de visão computacional utilizando o Python e o OpenCV",
        "Pessoas interessadas em rastreamento de objetos",
        "Alunos de graduação que cursam disciplinas de Computação Gráfica, Processamento Digital de Imagens ou Inteligência Artificial"
      ]
    },
    {
      "title": "Máster en Procesamiento de Lenguaje Natural (NLP) con Python",
      "url": "https://www.udemy.com/course/master-procesamiento-lenguaje-natural-nlp-python/",
      "bio": "Máster en Redes neuronales profundas para Procesamiento del Lenguaje Natural con Python y Keras. De 0 a experto.",
      "objectives": [
        "Conocer el procesamiento del lenguaje natural y por qué es un desafío.",
        "Aprender a trabajar con las librerías principales de Deep Learning para NLP en Python.",
        "Preparar datos de texto para el modelado en PLN utilizando librerías de Python para ello.",
        "Desarrollar representaciones distribuidas de texto utilizando modelos de Word Embeddings.",
        "Desarrollar modelos de sentiment analysis neuronal para predecir la clase para un documento de texto.",
        "Diseñar y desarrollar modelos de lenguaje neuronal, requerido para cualquier red neuronal generadora de texto.",
        "Diseñar y desarrollar proyectos de NLP con los novedosos Transformers.",
        "Diseñar y desarrollar proyectos de NLP aplicados al mundo profesional y científico.",
        "Desarrollar e implementar muchos más conceptos, técnicas y proyectos dentro del NLP con Python"
      ],
      "course_content": {
        "Introducción al curso Deep Learning con Python y Keras": [
          "Consejos y recomendaciones para usuarios de Udemy",
          "Requisitos previos: Deep Learning con Python y Keras",
          "Máster de especialista en procesamiento del lenguaje natural con Python",
          "Descripción de contenidos",
          "Contenidos a desarrollar en el curso",
          "Qué es el Procesamiento del Lenguaje Natural",
          "Estructura del Curso que vas a Comenzar.",
          "Cómo trabajar el curso",
          "¡Preséntate!",
          "Para saber más..."
        ],
        "Lenguaje de Programación en Python y librerías": [
          "Introducción a Python y sus librerías",
          "Herramientas de trabajo",
          "Tutorial Jupyter",
          "Python para Modelado Predictivo",
          "Python - Asignaciones",
          "Python - Control de Flujo",
          "Python - Estructuras de datos",
          "Python - Curso de NumPy",
          "Python - Curso de MatPlotlib",
          "Python - Curso de Pandas",
          "Curso rápido TensorFlow",
          "Curso rápido Keras",
          "Curso rápido Google Colab",
          "Para saber mas..."
        ],
        "Diseño de Redes Neuronales Avanzdas - Teoría": [
          "Background sobre Redes Neuronales",
          "Parámetros en redes neuronales",
          "Algoritmo de Gradiente Descendiente",
          "Multilayer Perceptron",
          "Coste, sesgo y activacion",
          "Backpropagation",
          "Para saber mas..."
        ],
        "Proyectos de Deep Learning en Tidy Data - Práctica": [
          "Clasicifcación Multiclase - Procesamiento de datos",
          "Clasificación Multiclase - Diseño de Red Neuronal",
          "Clasificación Binaria - Procesamiento de datos",
          "Clasificación Binaria - Diseño de Red Neuronal",
          "Clasificación Binaria - Optimización de la Red Neuronal",
          "Proyecto de Regresión - Procesamiento de datos",
          "Proyecto de Regresión - Diseño de Red Neuronal",
          "Proyecto de Regresión - Optimización de la Red Neuronal",
          "Evaluación de la unidad temática"
        ],
        "Codificación de palabras - Teoría": [
          "Codificación de palabras",
          "Word Embedding",
          "Una breve historia sobre NLP",
          "Procesamiento y limpieza de texto",
          "Bolsa de palabras",
          "Para saber más..."
        ],
        "Procesamiento y limpieza de texto - Práctica": [
          "Limpiar Texto manualmente",
          "Limpiar Texto con la librería NLTK",
          "Procesamiento de texto con sklearn - CountVectorizer()",
          "Procesamiento de texto con sklearn - TfidfVectorizer() & HashingVectorizer()",
          "Preparar datos con Keras - text_to_word_sequence() & one_hot()",
          "Preparar datos con Keras - Tokenizer",
          "Procesamiento de datos para análisis de opinión - Cargar datos",
          "Procesamiento de datos para análisis de opinión - Vocabulario",
          "Procesamiento de datos para análisis de opinión - Guardar datos",
          "Modelo BoW para sentiment analysis - Procesamiento",
          "Modelo BoW para sentiment analysis - Representación",
          "Modelo BoW para sentiment analysis - Modelado",
          "Modelo BoW para sentiment analysis - Predicción en datos no etiquetados",
          "Clasificación de documentos con Regresión Logística - Preprocesamiento",
          "Clasificación de documentos con Regresión Logística - Construcción del modelo",
          "Clasificación de documentos con Regresión Logística - Optimización del modelo",
          "Para saber más...",
          "Examen de la unidad"
        ],
        "Semántica Distribuida y Word Embeddings - Teoría": [
          "Codificación de palabras",
          "Word Embedding",
          "Semántica distribuida y word embeddings",
          "CBoW & Skip-Gram",
          "Generación de Vectores & LDA"
        ],
        "Word Embedding - Práctica": [
          "Procesamiento del Lenguaje Natural - Dataset",
          "Procesamiento del Lenguaje Natural - MLP",
          "Procesamiento del Lenguaje Natural - CNN Unidimensional",
          "Desarrollar word embeddings con Gensim - Word2Vec",
          "Desarrollar word embeddings con Gensim - GloVe",
          "Word embedding en Keras",
          "Word embedding en Keras con GloVe",
          "Clasificación de documentos con Embedding + CNN - Procesamiento",
          "Clasificación de documentos con Embedding + CNN - Implementación CNN",
          "Clasificación de documentos con CNN n-grams - Procesamiento",
          "Clasificación de documentos con CNN n-grams - Impelemtnación CNN",
          "Para saber más...",
          "Cuestionario de la unidad"
        ],
        "Redes Neuronales Recurrentes - Teoría": [
          "Background",
          "Introducción",
          "Redes Feed Forward Vs Redes neuronales recurrentes",
          "Redes Neuronales Recurrentes",
          "Redes LSTM",
          "Modelado del lenguaje",
          "Aplicaciones NLP con RNN",
          "Para saber más..."
        ],
        "Modelado del lenguaje - Práctica": [
          "Desarrollar MLP, CNN y RNN con Keras - Parte 1",
          "Desarrollar MLP, CNN y RNN con Keras - Parte 2",
          "Desarrollar MLP, CNN y RNN con Keras - Parte 3",
          "Modelado del lenguaje basado en caracteres - Procesamiento de datos",
          "Modelado del lenguaje basado en caracteres - Red Neuronal",
          "Modelado del lenguaje basado en en palabras - Modelo 1",
          "Modelado del lenguaje basado en en palabras - Modelo 2 y 3",
          "Evaluar el texto generado con BLEU",
          "Topic modeling con Latent Dirichlet Allocation (LDA) - Entrenamiento",
          "Topic modeling con Latent Dirichlet Allocation (LDA) - Evaluación"
        ]
      },
      "requirements": [
        "Conocimientos intermedios en Machine Learning / Deep Learning.",
        "Conocimientos intermedios en programación (deseable Python)",
        "Aprenderemos desde cero con NLP, por lo que no se necesitan conocimientos previos en NLP",
        "Durante el curso trabajaremos con la última versión del programa, pero no te preocupes si tienes una versión anterior, ya que las distintas versiones difieren muy poco entre sí. Si existe algún cambio importante entre las distintas versiones hablaremos de ello durante la formación.",
        "Para la realización de este curso no vas a necesitar el equipo informático más potente del mercado, ya que el software empleado en la formación se encuentra perfectamente optimizado y en caso contrario utilizaremos recursos de internet.",
        "Cuando compres el curso vas a poder acceder a las clases cuando y donde quieras. El curso se queda en tu cuenta de Udemy para siempre. :)",
        "El más importante requisito para realizar este curso es el entusiasmo y la motivación por aprender nuevas habilidades que aumenten tus competencias profesionales."
      ],
      "description": "Máster de Especialista en Procesamiento del Lenguaje Natural (NLP) con Python.\nMáster en Redes neuronales profundas para Procesamiento del Lenguaje Natural con Python y Keras. De 0 a experto.\nInstructor: PhD. Manuel Castillo.\nRequisitos previos: Antes de realizar el curso se recomienda encarecidamente tener conocimientos sobre Deep Learning. Se recomienda haber desarrallado previamente uno de estos dos cursos, también de Udemy:\nDeep Learning con Python y Keras. Redes Neuronales avanzado. Aprendizaje profundo con la librería Keras-Python. Aprende a diseñar y desarrollar redes neuronales de básico a experto; o también\nMáster de especialista en Ciencia de Datos con Python. Aprenda a desarrollar proyectos de Machine Learning y Deep Learning con Python. Data Science de básico a Experto\n\n\nDescripción del Curso:\nBienvenido al curso de Máster de Especialista en Procesamiento del Lenguaje Natural (NLP) con Python y Keras. En este curso trataremos la librería Keras de Python para Deep Learning y cómo usarla para desarrollar y evaluar modelos de Deep Learning para Procesamiento del Lenguaje Natural. En este curso, descubriremos las técnicas, código y habilidades de Deep Learning que luego puede llevar a sus propios proyectos de Aprendizaje profundo para Procesamiento del Lenguaje Natural con Python y Keras.\nSi está interesado en Deep Learning, tenemos que comenzar por desarrollar y evaluar modelos de Deep Learning. Luego, si descubres que realmente le gusta o tienes una habilidad especial para ello, más adelante podrás profundizar más en los antecedentes y la teoría, según lo necesites para ayudarte a desarrollar mejores y más valiosos resultados.\nEn este contexto, para este curso se ha escogido la mejor plataforma para comenzar y desarrollar muy rápidamente modelos de Deep Learning potentes a través de la librería Keras de Python.\nLa librería Keras envuelve la complejidad de la computación numérica de Theano y TensorFlow proporcionando una API concisa que usaremos para desarrollar nuestra propia red neuronal y modelos Deep Learning. Además, trataremos las habilidades de Deep Learning para llevar esta nueva tecnología asombrosa a nuestros propios proyectos.\nEl curso  está dirigido a personas que tengan conocimientos de Deep Learning, conocimientos intermedios del lenguaje de programación y que quieran adentrarse a este apasionante mundo de dentro del campo de Deep Learning y redes neuronales.\n\n\nContenidos del Curso:\nMÓDULO I. Introducción.\nAnaconda como nuestro gestor de trabajo.\nJupyter Notebook o Google Colab como nuestro entorno de Deep Learning.\nCurso rápido de Python.\nIntroducción a la librería Keras.\nMÓDULO II. Fundamentos de Deep Learning.\nNeurona como unidad fundamental.\nComo trabaja una neuronal.\nPerceptrón multicapa.\nCómo opera el perceptrón multicapa.\nCurso intensivo en perceptrones multicapa.\nNuestra primera red neuronal con Keras.\nModelos de Keras  para Machine Learning general (Clasificación/Regresión).\nMÓDULO III. Redes Neuronales Recurrentes.\nRedes Neuronales Recurrentes.\nRedes LSTM.\nDesarrollar un proyecto con RNN.\nDesarrollar un proyecto con LSTM.\nProyecto de Generación de texto.\nMÓDULO IV. Procesamiento de texto.\nLimpiar, preparar y codificar (encoded) el texto.\nProcesamiento de datos en scikit-learn y Keras.\nRepresentación del vocabulario en Bolsa de palabras (BoW).\nProyecto: Sentiment analysis en un modelo de BoW.\nMÓDULO V. Word embeddings.\nWord Embeddings con Gensim.\nWord Embeddings con Keras.\nProyecto: Word embeddings con un modelo CNN.\nProyecto: Word embeddings con un modelo CNN n-gramas.\nMÓDULO VI. Modelado del lenguaje.\nModelo del lenguaje neuronal basado en caracteres.\nModelo del lenguaje neuronal basado en palabras.\nModelo del lenguaje neuronal para generación de texto.\nProyecto con modelado del lenguaje.\nMÓDULO VII. Modelos de PLN avanzados.\nLatent Dirilecht Allocation\nTransformers.\nHuggingFace para modelos preentrandos.\nExtracción de keywords.\nReconocimiento de entidades.\nMÓDULO VIII. Proyectos avanzados.\nModelo para la traducción automática.\nAnálisis de programas electorales con NLP con modelos clásicos.\nAnálisis de programas electorales con NLP con modelos basados en transformers.\nProyectos avanzados con Transformers.\n\n\nActividad virtual\nSesiones de videoconferencias\nAnálisis de casos\nForos de discusión\nTrabajos parciales de los módulos\nExamen tipo test\nLecturas comentadas y\nBúsquedas de información científica.\n\n\nProcedimiento de la formación:\nLa formación te permitirá convertirte en un experto en la materia, y todo ello desde una formación principalmente práctica. A través de variadas actividades y proyectos completos podrás adquirir los conocimientos suficientes para ejercer profesionalmente de forma solvente. Además conocerás en detalle mi flujo de trabajo a la hora de afrontar un proyecto profesional. Para la realización de este curso no vas a necesitar el equipo informático más potente del mercado, ya que el software empleado durante formación online se encuentra perfectamente optimizado y su uso es muy fluido en todo tipo de equipos, tanto en PC como en Mac.\nEl aprendizaje será un proceso continuo donde los estudiantes tienen la oportunidad de ir trabajando con el editor de texto practicando lo expuesto en la parte de teoría.\nPuedes elegir ver todas las lecciones de forma secuencial (lineal) y aprovecharlas al máximo la formación. Pero también puedes decidir ver este curso como una guía de referencia. Las clases están claramente organizadas en secciones lógicas y puedes decidir visualizar solo las clases que te resulten más importantes según tus necesidades formativas. A excepción de las lecciones PRO, la mayoría de las lecciones son independientes para que puedas comprender los conceptos de cada lección sin tener que ver las lecciones anteriores del curso.\nEs excepcional el aumento en la demanda de profesionales en este ámbito por parte de las empresas de todo el mundo actualmente. Para desarrollar el programa formativo propuesto no ser requieren grandes conocimientos previos, ya que la formación se acomete desde un nivel de usuario 0. El curso está orientado a aquellos creativos que quieran ampliar sus skills (habilidades) y conocer múltiples trucos, consejos, recursos y recomendaciones, de la mano del instructor Dr. Manuel Castillo-Cara. Además todas las formaciones de Udemy disponen acceso automático al curso, sin limitación de tiempo, disponibilidad 24/7 (24 horas al día los 7 días de la semana), sin caducidad y con garantía de devolución.\n\n\nCaracterísticas del Curso:\nRecuerda que esta formación incluye lecciones en vídeo fullHD con audio de estudio (compatible con TV, PC, Mac, tablet y smartphone), artículos didácticos, actividades, proyectos paso a paso, recursos descargables, links de interés, acceso de por vida, certificado de finalización, tutorización online, y una exclusiva comunidad de aprendizaje privada que nos ayudamos aportando nuestras experiencias en el foro de comunicación del curso.\n¿A qué esperas?, este curso es ideal para ti, atrévete a convertirte en un experto. Adelante, nos vemos dentro de la formación.",
      "target_audience": [
        "Entusiastas de la Inteligencia Artificial y, sobre todo, de Ciencia de Datos",
        "Desarrollares de modelos de Machine learning y Deep learning",
        "Aquellos usuarios del programa que quieran ampliar el dominio de mismo y conocer múltiples trucos, consejos y recursos para esta herramienta.",
        "Principalmente aquellos que quieran aumentar sus posibilidades de empleabilidad, contratación y/o promocionar dentro de su sector."
      ]
    },
    {
      "title": "現役CTOが教える！【実践】AWSを使ったデータ分析基盤構築ハンズオン",
      "url": "https://www.udemy.com/course/ctoaws-data-analytics-platform/",
      "bio": "データサイエンティストやデータエンジニアとしてAWSなどのクラウド環境で実践を積んでいきたい方、DXを進めていく方必見！ AWS上でDataLakeやDWH、ETL処理などデータ分析基盤の構築から可視化まで一気通貫で学ぶことができます！",
      "objectives": [
        "クラウドでデータを扱えるようにデータ分析基盤の基本概念を理解できるようになります。",
        "データ基盤のハンズオンを通して分析基盤を構築できるようになります。",
        "jupyter notebookをクラウドで用いることができるようになります。",
        "データベースやログデータを可視化する技術を習得することができます。",
        "目的に応じてデータ分析基盤のアーキテクチャの応用を習得することができます。",
        "DXの際に必要なデジタライゼーション後のデータ収集や可視化の技術を習得することができます。"
      ],
      "course_content": {
        "イントロダクション": [
          "コースの概要"
        ],
        "学習の準備をしよう": [
          "このセクションで学ぶこと",
          "AWSアカウントの作成",
          "ローカル環境でのPythonの設定",
          "ローカル環境でのAWSの設定"
        ],
        "データ分析基盤基礎を学習しよう": [
          "このセクションで学ぶこと",
          "DataLake概論",
          "DataWareHouse概論",
          "ETL処理概論",
          "データ分析環境概論"
        ],
        "DataLakeやDataWareHouseを作成しよう": [
          "このセクションで学ぶこと",
          "DataLake設計",
          "S3の作成",
          "データ格納のノウハウ"
        ],
        "ETL処理を作成しよう": [
          "このセクションで学ぶこと",
          "AWS GlueでのETL構築",
          "ETL自動化",
          "ETLの注意点"
        ],
        "データを可視化しよう": [
          "このセクションで学ぶこと",
          "S3データの可視化",
          "QuickSightでできること"
        ],
        "AWS環境でjupyter notebook環境を構築しよう": [
          "このセクションで学ぶこと",
          "jupyter notebookでのクラウド環境構築",
          "ソース管理ツールとの接続",
          "クラウド開発環境での注意点"
        ],
        "さらに学びたい方のために実用例の紹介": [
          "このセクションで学ぶこと",
          "データベース可視化の実用例",
          "ログデータ可視化の実用例",
          "外部データ可視化の実用例",
          "データを統合し可視化する実用例"
        ]
      },
      "requirements": [
        "pythonプログラミングやCLIを使った操作についての基礎的な知識やスキル",
        "AWSの基礎的な知識 (IAM/S3/EC2などの知識を有している、利用することができる)"
      ],
      "description": "■ こんな課題ありませんか？\n・データ分析基盤を構築するためのAWSの機能やサービスについて、どうやって学べばよいかわからない\n・AWSを使ったデータ分析基盤構築に関するノウハウが不足していて、構築に失敗する可能性がある\n・実践的な手順やハンズオンを通して学ぶことで理解が深まると考えているが、実際に手を動かせる機会がない\n・データ分析基盤構築にあたって、経験の豊富な現役CTOのアドバイスやヒントを得たいと思っている\n・データ分析基盤の構築には時間やコストがかかるため、効率的な構築方法を知りたいと思っている\n\n\nデータ分析基盤の構築から可視化まで一気通貫でハンズオンを実施します！\n実践編として、フェーズややりたいことに応じたアーキテクチャやデータパイプラインの紹介も実施します！\n\n\n■ 昨今のデータに関するトレンド\n昨今ではChatGPTやDXによりデータの重要性が叫ばれるようになってきてから、データエンジニアやAIとデータを使いこなせる人材の需要が上がってきています。\n2030年までにIT人材が79万人不足すると言われている中、一歩先にIT人材に必要なデータ利活用の基礎を身につけられることを目的として、教材を作成しました！\n\n\n■ 講座内容の概要\n・データの扱いに関する基礎知識 (抽出/変換/格納/可視化)\n・データ関連のAWSサービスに関する概要\n・データ分析基盤で利用する各AWSのサービスごとに簡単なハンズオン\n・実践編としてのアーキテクチャの説明\n※ レクチャーの中でページの紹介などを行なっている部分がございますが、その場合は資料をダウンロードすることが可能です。\n\n\n■ 学習後のゴール\n・データレイクやデータウェアハウス、ETLの概念を理解し、データパイプラインを作成できるようになります。\n・データを可視化する、利用するまでのプロセスが明確になります。\n・データを集め、統合することによって様々な用途を提案/企画することができるようになれば嬉しいです。",
      "target_audience": [
        "AWSを使ってデータ分析基盤を構築する方法を学びたいと考えているデータエンジニアやデータサイエンティスト",
        "AWSを使ったデータ分析基盤の構築に関心がある経営者や管理者、DX担当者",
        "AWSを使ったデータ分析基盤構築について学び、スキルアップを目指しているエンジニアや学生"
      ]
    },
    {
      "title": "Analítica Prescriptiva: de datos a decisiones",
      "url": "https://www.udemy.com/course/introduccion-analitica-prescriptiva/",
      "bio": "Basados en datos podemos describir nuestro entorno y predecir lo que vendrá, ahora es hora de convertirlo en acciones",
      "objectives": [
        "Identificar las situaciones en las que la analítica prescriptiva puede apoyar a tomar mejores decisiones",
        "Modelar y formular problemas de decisión en analítica prescriptiva",
        "Implementar modelos de optimización y apoyo a la decisión en python",
        "Generar información para la toma de decisiones a través de herramientas de optimización en analítica prescriptiva"
      ],
      "course_content": {
        "Introducción a la analítica prescriptiva": [
          "Bienvenida",
          "Material del curso",
          "De la analítica descriptiva a la analítica prescriptiva",
          "Ejemplo del ciclo de vida de la analítica de negocios",
          "Roles en la analítica de negocios",
          "Métodos y herramientas de la analítica descriptiva",
          "Nuestro primer problema de decisión",
          "El proceso de apoyo a la decisión",
          "Ejemplo: Optimización, métodos aproximados",
          "Notebook métodos aproximados",
          "Ejemplo: Optimización matemática",
          "Notebook optimización matemática",
          "Explorando los métodos de optimización",
          "Cierre de la sección 1",
          "Evaluación de la sección 1"
        ],
        "El modelo y su formulación": [
          "Bienvenida",
          "El modelo en el flujo de la toma de decisiones",
          "Elementos del modelo y su notación",
          "Verbalización del modelo",
          "¿Qué tan importante es una buena verbalización?",
          "Formulación matemática: El modelo desagregado",
          "Formulación matemática: el modelo generalizado",
          "Extendamos nuestro modelo de ejemplo",
          "Implementación de nuestro modelo extendido",
          "Recomendaciones para crear buenos modelos",
          "Separación Instancia - Modelo",
          "Evaluación de la sección 2",
          "Cierre de la sección 2"
        ],
        "Arquetipos para la formulación matemática": [
          "Introducción",
          "Tipos de arquetipos y problema de referencia",
          "Descripción del problema de referencia",
          "*Bonus*: Implementación del problema de referencia (OPCIONAL)",
          "Arquetipos sobre los elementos del modelo: Conjuntos de conjuntos",
          "Arquetipos sobre los elementos del modelo: Tipos de variables",
          "Arquetipos sobre los elementos del modelo: Cotas de las variables",
          "Práctica sobre arquetipos de los elementos del modelo",
          "Arquetipos sobre la función objetivo: Múltiples sumatorias",
          "Arquetipos sobre la función objetivo: MinMax - MaxMin",
          "Práctica sobre arquetipos de la función objetivo",
          "Arquetipos sobre las restricciones: Restricción de demanda",
          "Arquetipos sobre las restricciones: Disponibilidad de recursos",
          "Arquetipos sobre las restricciones: Asignación",
          "Práctica sobre arquetipos de las restricciones",
          "Arquetipos sobre las restricciones: Mezclas",
          "Arquetipos sobre las restricciones: Conservación del flujo",
          "Arquetipos sobre las restricciones: Estructuras multiperiodo",
          "Arquetipos sobre las restricciones: Restricciones suaves",
          "Práctica sobre arquetipos para la modelación",
          "Evaluación de la sección 3",
          "Cierre de la sección 3"
        ],
        "Inteligencia artificial para la formulación avanzada en optimización": [
          "Bienvenida",
          "¿Qué es la inteligencia artificial generativa?",
          "Inteligencia artificial para la modelación y formulación matemática",
          "Práctica sobre inteligencia artificial para la modelación",
          "Arquetipos sobre relaciones lógicas entre variables",
          "Arquetipos sobre variables con estructuras especiales",
          "Ejemplo de aplicación de las variable con estructura especial",
          "La linealidad en los modelos de decisión",
          "Ejemplo de linealización de la función mínimo",
          "Práctica sobre arquetipos avanzados usando inteligencia artificial",
          "Recomendaciones generales para la formulación de modelos matemáticos",
          "Evaluación de la sección 4",
          "Cierre de la sección 4"
        ],
        "Implementación de modelos para la toma de decisiones": [
          "Bienvenida",
          "Ecosistema tecnológico: Lenguajes y optimizadores",
          "Implementación: Creación del modelo y sus elementos",
          "Implementación: Creación de las variables de decisión",
          "Implementación: Creación de la función objetivo",
          "Implementación: Creación de las restricciones",
          "Práctica sobre implementación de componentes del modelo",
          "Pasar el modelo al optimizador y resolverlo",
          "Automatización de la creación del modelo",
          "Extraer la información de la solución",
          "Practica sobre resolver una nueva instancia y obtener la solución",
          "Implementación en GUROBIPY",
          "El asistente de inteligencia artificial de gurobipy",
          "Práctica de implementación de un modelo",
          "Cierre de la sección 5"
        ],
        "RETO de aplicación": [
          "Presentación del reto de aplicación",
          "Reto de aplicación",
          "Despedida"
        ]
      },
      "requirements": [
        "Conocimiento básico de programación en python"
      ],
      "description": "Convierte datos en decisiones inteligentes: Curso de Analítica Prescriptiva\n¿Te imaginas poder tomar decisiones con total confianza, basadas en datos y respaldadas por modelos de optimización? Eso es exactamente lo que aprenderás en este curso.\nVivimos en un mundo impulsado por la información. Sabemos qué ha pasado (analítica descriptiva) y podemos anticipar qué sucederá (analítica predictiva), pero, ¿cómo tomamos la mejor decisión posible? Aquí entra en juego la analítica prescriptiva, una poderosa disciplina que no solo analiza el pasado y predice el futuro, sino que también propone las mejores acciones a tomar para obtener resultados óptimos.\nEn este curso, te sumergirás en el fascinante mundo de la optimización de decisiones, donde los datos dejan de ser simples números y se convierten en el motor de estrategias inteligentes.\n¿Qué aprenderás?\nCómo transformar problemas de decisión en modelos accionables, estructurándolos de manera lógica y efectiva para resolver desafíos reales.\nCómo formular e implementar estos modelos en código, trabajando con herramientas que te permitirán aplicarlos a situaciones del mundo real.\nQué herramientas tecnológicas y de inteligencia artificial pueden facilitar el proceso de modelación e implementación, optimizando tiempo y recursos en la toma de decisiones.\nCómo conectar la analítica prescriptiva con la estrategia empresarial, garantizando que las decisiones tomadas tengan un impacto positivo en los resultados organizacionales.\n¿Para quién es este curso?\nSi eres nuevo en analítica, este curso será tu puerta de entrada a un mundo más allá de los datos básicos, ayudándote a comprender cómo transformar la información en decisiones.\nSi eres científico de datos o analista, aquí pondrás manos a la obra con modelos avanzados, desarrollando y aplicando soluciones prácticas con código.\nSi ocupas un rol estratégico en una organización, te daremos una visión clara y estructurada de cómo estas herramientas pueden potenciar la toma de decisiones y mejorar los resultados empresariales.\nDa el primer paso hacia decisiones más inteligentes\nEste curso es solo el comienzo de una serie de aprendizajes diseñados para que transformes datos en decisiones poderosas. No se trata solo de aprender teoría, sino de aplicar conocimientos en escenarios reales que marcan la diferencia.",
      "target_audience": [
        "Principiantes en la analítica de datos que están interesados en comprender su alcance en la toma de decisiones",
        "Personas curiosas en torno a los temas de analítica de datos",
        "Tomadores de decisiones interesados en ampliar su abanico de opciones para apoyar decisiones con datos",
        "Expertos en analítica que quieren extender su caja de herramientas con métodos de la analítica prescriptiva"
      ]
    },
    {
      "title": "(Ken Cen出品)從零開始學Machine Learning第二部 -深度學習DL篇",
      "url": "https://www.udemy.com/course/machine-learning-classification-f/",
      "bio": "使用Pytorch製作深度學習模型",
      "objectives": [
        "了解機器學習ML與深度學習DL的區別與關係",
        "知道如何搭配DL的線上/線下運行環境",
        "了解Pytorch框架的使用方法",
        "了解如何製作深度學習模型"
      ],
      "course_content": {
        "如何開始學習 AI": [
          "如何開始學習 AI"
        ],
        "機器學習ML & 深度學習DL": [
          "ML與DL",
          "學習DL需要什麼條件",
          "如何使用Pytorch-線上版",
          "如何安裝Pytorch到本地電腦上",
          "Windows安裝補充",
          "JupyterLab的優點及使用"
        ],
        "Pytorch": [
          "什麼是Tensor & 它有什麼用處",
          "隨機Tensor",
          "Zeros_like & Arange",
          "數據類型- Float浮點數類型",
          "Int & Bool & Complex數據類型",
          "小練習1",
          "View & Reshape & Flatten的區別",
          "運算符號",
          "mul&mm&matmul",
          "矩陣相乘約束",
          "Broadcasting廣播",
          "Min()&max()&mean()&sum()",
          "Argmin&Argmax&where",
          "Stack&vstack&hstack",
          "Squeeze&unsqueeze",
          "Permute",
          "Tensor索引",
          "Numpy & Tensor轉換",
          "隨機數種子",
          "Class類",
          "Class初始化&繼承&多態"
        ],
        "人工神經網絡": [
          "為什麼需要CUDA",
          "CPU To GPU",
          "如何寫一段對比CPU和GPU速度的代碼",
          "對比CPU與GPU的運行速度（Mac）",
          "什麼是Perception感知器",
          "用Python製作感知器",
          "Error Function誤差函數",
          "用Python製作損失函數",
          "Gradient Descent剃度下降"
        ]
      },
      "requirements": [
        "一台Mac或者Windows電腦",
        "有一定Python語言基礎",
        "購買我們機器學習第一部講座"
      ],
      "description": "大家好，我是Ken Cen，鑑於上一部機械學習課程大受歡迎，我們再推出Machine Learning的第二部分內容。在這一部中，我們將講述Pytorch如何實現深度學習的各種演算法，以及如何具體實踐於Python當中。\n演算法作為學習Machine Learning的重點和難點，一直以來，讓很多學生望而卻步。我們的Machine Learning課程正正為此而生。相對於輕輕帶過，我們課程會將重點放在演算法的理解上，為大家打開ML學習的大門。期待在課程中，與大家一起從零到專業學習人工智能！\nHello everyone, I'm Ken Cen. Following the great success of our previous machine learning course, we are launching the second part of our Machine Learning content. In this course, we will be covering various deep learning algorithms and how to implement them in Python.\nAlgorithms are a key and difficult aspect of learning Machine Learning, which has made many students shy away from it. Our Machine Learning course was created specifically for this reason. Instead of brushing over the topic, our course will focus on understanding the algorithms and open the door to learning ML for everyone. We look forward to learning artificial intelligence together with you from beginner to professional in this course!",
      "target_audience": [
        "想學習機械學習的學員",
        "想學習Logistic Regression算法的學員",
        "想學習Decistion Tree決策樹算法的學員",
        "想學習Random Forest算法的學員",
        "想學習KNN（K-nearest neighbors）算法的學員",
        "想學習SVM（Support Vector Machines）算法的學員",
        "想學習Naive Bayes算法的學員"
      ]
    },
    {
      "title": "【한글자막】 AI 만들기 2025: 강화학습과 인공신경망 완전정복, Agentic AI, Gen AI, RL",
      "url": "https://www.udemy.com/course/best-ai-17-hours/",
      "bio": "에이전트 AI, 생성 AI, 강화 학습의 힘을 결합한 강력한 AI 개발! Q-Learning, Deep Q-Learning, Deep Convolutional Q-Learning, A3C, 인공신경망과 CNN 모델",
      "objectives": [
        "7가지 애플리케이션을 위한 7가지 AI 구축",
        "인공 지능의 이론 이해",
        "최첨단 AI 모델 마스터하기",
        "AI로 실제 세계 문제 해결",
        "Q-Learning",
        "딥 Q-러닝",
        "딥 컨볼루션 Q-러닝",
        "A3C(Asynchronous Advantage Actor-Critic)",
        "PPO(Proximal Policy Optimization)",
        "SAC(Soft Actor-Critic)",
        "LLM",
        "트랜스포머",
        "로우랭크 적응(LoRA) 및 정량화(QLoRA)",
        "챗봇을 위한 NLP 기술 토큰화 및 패딩",
        "지식 증강으로 LLM 미세 조정하기",
        "기타: DDPG, Full World Model, Evolution Strategies & Genetic Algorithms"
      ],
      "course_content": {
        "이 강의에 오신 것을 환영합니다!": [
          "강의 자료를 받으세요!",
          "AWS PartyRock을 사용하여 AI 챗봇 구축해보기 | 코딩 필요 없음",
          "Prizes $$ for Learning"
        ],
        "Agentic AI": [
          "비즈니스 지원을 위한 클라우드 기반 AI 에이전트를 처음부터 완전히 새로 구축하세요!"
        ],
        "Part 0: 강화 학습의 기초": [
          "0부: 강화 학습의 기초에 오신것을 환영합니다"
        ],
        "큐러닝 (Q-Learning) 직관": [
          "딥러닝 기초: 신경망 및 활성화 함수 설명",
          "강화 학습이란 무엇인가? AI 훈련 방식에 대한 초보자를 위한 가이드",
          "강화 학습의 벨만 방정식: 단계별 소개",
          "상태 값에서 최적의 계획까지: AI 의사 결정의 벨만 방정식",
          "강화 학습의 마르코프 의사결정 과정: 전체 가이드",
          "강화학습 튜토리얼: AI 의사 결정에서 최적의 정책 대 고정 계획",
          "강화 학습에서의 \"리빙 페널티\": AI 에이전트의 의사결정 최적화",
          "강화 학습의 Q-러닝: V-값에서 Q-값으로",
          "Q-러닝의 시간적 차이: 강화 학습을 위한 완벽한 가이드",
          "퀴즈 1"
        ],
        "큐러닝 (Q-Learning) 구현": [
          "프로세스 최적화를 위한 Q-Learning 구현"
        ],
        "---------- 1부: 딥 큐러닝 (Deep Q-Learning) ----------": [
          "1부: 딥 큐러닝에 오신 것을 환영합니다"
        ],
        "딥 큐러닝 직관": [
          "딥러닝 기초: 신경망 및 활성화 함수 설명",
          "딥러닝과 기존 Q러닝: 주요 차이점 설명",
          "딥 Q러닝의 작동 원리: 신경망 및 강화 학습에 대한 설명",
          "딥 Q-러닝에서 리플레이를 경험하세요: 작동 방식 및 중요한 이유",
          "Q-러닝: 엡실론-그리디 및 소프트맥스 액션 선택 알고리즘 가이드"
        ],
        "딥 큐러닝 구현": [
          "딥 큐 러닝과 Python을 사용하여 AI 달 착륙선을 훈련하는 방법",
          "강의 코드 다운로드",
          "1단계 - 딥 Q-러닝 환경 설정: Gmail에서 달 착륙선 교육까지",
          "2단계 - 구글 Colab 설정: 달 착륙선 튜토리얼을 위한 딥러닝 튜토리얼",
          "3단계 - PyTorch DQN 아키텍처: OpenAI 달 착륙선을 위한 AI 두뇌 구축하기",
          "4단계 - PyTorch 딥 Q-러닝: 신경망의 순방향 방법 구현하기",
          "5단계 - DQN 트레이닝을 위한 LunarLander-v2 환경 파라미터 구성",
          "6단계 - DQN 하이퍼파라미터: 학습 속도 및 리플레이 버퍼 설정 가이드",
          "7단계: Python을 사용하여 DQN에서 경험 재생 메모리 구현하기",
          "8단계: DQN 푸시 방법 - 리플레이 메모리 버퍼에 경험 추가하기",
          "9단계: DQN 메모리 샘플링 코딩 - PyTorch 경험 재생 튜토리얼",
          "10단계 - DQN 튜토리얼: Q-Networks, 옵티마이저 초기화 및 메모리 버퍼 재생하기",
          "11단계: DQN 단계 방법 - 파이썬에서 경험 저장 및 학습하기",
          "12단계: DQN 작업 선택 - 상태 처리에서 정책 구현까지",
          "13단계: 딥 Q-네트워크 학습 - 강화 학습을 위한 학습 방법 구현하기",
          "14단계 - 심층 Q-네트워크 구현: 안정적인 학습을 위한 소프트 업데이트 방법",
          "15단계: 첫 번째 AI 에이전트 만들기 - 딥 큐 네트워크(DQN) 튜토리얼",
          "16단계 - 엡실론-그리디 전략: AI 학습 하이퍼파라미터 초기화",
          "17단계: 딥러닝 학습 루프 - 달 착륙선 가이드 완성하기",
          "18단계: DQN 트레이닝 시각화 - 동적 점수 추적 구현",
          "19단계: 딥러닝 시각화 - 달 착륙선 착륙을 완성한 AI",
          "20단계 - ChatGPT와 사용자 지정 DQN: 심층 강화 학습 구현 비교하기"
        ],
        "---------- 2부: 딥컨볼루셔널 큐러닝 (Deep Convolutional Q-Learning) ----------": [
          "2부: 딥컨볼루셔널 큐러닝(Deep Convolutional Q-Learning)에 오신 것을 환영합니다"
        ],
        "딥컨볼루셔널 큐러닝(Deep Convolutional Q-Learning) 직관": [
          "딥러닝 기초: 신경망 및 활성화 함수 설명",
          "딥 컨볼루션 Q-러닝: 게임 환경을 위한 AI 에이전트 구축",
          "딥 Q-러닝과 적격성 추적 비교: AI 알고리즘 비교 및 가이드"
        ]
      },
      "requirements": [
        "선형대수, 미분, 기초통계 등 고등학교 수준의 수학 지식이 있으면 좋습니다",
        "Python 기초 문법은 숙지하신 후 수강하시길 권장 드립니다"
      ],
      "description": "강화학습, 딥러닝을 통해 인공지능을 구현하기 위한 핵심 기술 트렌드 완벽 반영\n자율주행, 게임 필승 모델 등 실제 사례 기반으로 AI를 직접 구현해보는 프로젝트형 학습\n나만의 AI 모델을 쉽게 만들어갈 수 있도록 최신 AI 모델 관련 템플릿 코드 전부 제공\n\n\n—\n\n[15시간만에 최신 AI 기술 트렌드를 완전 정복하는 방법]\n이 강의는 AI 입문자도 단 15시간으로 최신 AI 모델의 핵심 트렌드를 학습하고 자신만의 AI 모델을 구현할 수 있도록 구성되었습니다.\n\n\n직관적인 강의를 통해 핵심 AI 개념을 학습하여 AI에 대한 모든 것을 빠르게 익히고, 8가지 AI를 구축하여 실습해 보세요:\n\n\n비즈니스 지원을 위한 Foundation Model (LLM)로 AI 에이전트 구축하기: 모두 클라우드 기반입니다.\n프로세스 최적화 사례 연구를 통해 Q-Learning 모델로 AI를 구축하여 창고 흐름을 최적화하도록 훈련하세요.\nDeep Q-Learning 모델로 AI를 구축하여 달 착륙을 위한 훈련을 시키세요.\nDeep Convolutional Q-Learning 모델로 AI를 구축하고, 팩맨 게임을 플레이하도록 훈련하세요.\nA3C(Asynchronous Advantage Actor-Critic) 모델로 AI를 구축하고 쿵푸를 하도록 훈련합니다.\nPPO (Proximal Policy Optimization) 모델로 AI를 구축하고 자율 주행 자동차를 훈련시킵니다.\nSAC (Soft Actor-Critic) 모델로 AI를 구축하고 자율 주행 자동차를 훈련시킵니다.\nHugging Face로 사전 학습된 강력한 LLM(Llama 2 by Meta)을 미세 조정하여 AI를 구축하고 의학 용어에 대해 사용자와 대화하도록 다시 학습시킵니다. 즉, AI 의사 챗봇을 구축합니다.\n\n\n하지만 그게 다가 아닙니다... 강의를 완료하면 3개의 AI가 추가로 제공됩니다: DDPG, Full World Model, 진화 전략 및 유전 알고리즘입니다. 이 AI는 자율 주행 차량과 휴머노이드 애플리케이션을 위한 ChatGPT로 빌드됩니다. 이러한 추가 AI 각각에 대해 구현을 설명하는 긴 분량의 영상 강의, 미니 PDF 및 Python 코드가 제공됩니다.\n\n\n또한 이 강의를 완료하면 클라우드 컴퓨팅을 사용한 생성형 AI 및 LLM에 대한 3시간 무료 추가 강의가 보너스로 제공됩니다.\n\n\n마지막으로, 이 강의를 통해 얻을 수 있는 혜택은 다음과 같습니다:\n\n\n1. 초보자부터 전문가까지 완벽한 AI 기술 - 다양한 목적에 맞게 스스로 개선하는 AI 코딩 방법을 배웁니다. 실제로 여러분과 함께 코딩합니다. 모든 튜토리얼은 빈 페이지로 시작하며 처음부터 코드를 작성합니다. 이렇게 하면 코드가 어떻게 구성되고 각 줄이 무엇을 의미하는지 정확히 이해하고 따라할 수 있습니다.\n\n\n2. 번거로움 없는 코딩 및 코드 템플릿 - 모든 AI를 Google Colab에서 빌드하기 때문에 라이브러리나 패키지를 설치하는 번거로움이 전혀 없으며, 모든 것이 Google Colab 노트북에 이미 사전 설치되어 있습니다. 또한 강의에서 빌드하는 모든 AI에 대해 다운로드 가능한 Python 코드 템플릿(.py 및 .ipynb)이 제공됩니다. 따라서 코드 몇 줄만 변경하면 정말 독특한 AI를 간단하게 만들 수 있습니다. 상상력을 마음껏 발휘하면 잠재력은 무한합니다.\n\n\n3. 직관 튜토리얼 - 대부분의 강의가 단순히 이론을 주입하고 길을 안내하는 데 그치는 반면, 저희는 여러분이 하는 일뿐만 아니라 왜 하는지에 대한 깊은 이해가 필요하다고 믿습니다. 그렇기 때문에 복잡한 수학을 가르치지 않고 AI에 대한 직관력을 키우는 데 집중하여 훨씬 더 나은 결과를 얻을 수 있도록 합니다.\n\n\n4. 실제 세계에서 사용가능한 솔루션 - 하나의 AI 모델뿐만 아니라 5개의 모델에 대해 배웁니다. 각 모듈은 다양한 구조와 난이도로 구성되어 있어 다른 강의처럼 단순 암기식 '테스트 후 잊어버리기'가 아니라 실제 환경에 적응할 수 있는 AI를 구축할 수 있을 만큼 숙련된 실력을 갖추게 됩니다. 연습이 완벽을 만듭니다.\n\n\n5. 강의에 대한 지원 - 전 세계에서 가장 접근성이 높고 결과 중심의 AI 강의로 만들기 위해 최선을 다하고 있습니다. 그러기 위해서는 수강생이 도움이 필요할 때 저희의 도움을 받을 수 있어야 합니다. 그렇기 때문에 전문 데이터 과학자들로 구성된 팀이 여러분의 여정을 지원하기 위해 최대 48시간 이내에 답변을 드릴 수 있도록 준비했습니다.\n\n\n\n\n그렇다면 매혹적인 AI의 세계를 받아들일 준비가 되셨나요?\n저희와 함께 학습을 멈추지 않고 AI를 즐겨보세요!\n\n\n실제 데이터를 통해 모델을 학습시켜가는 과정을 빈 코드 에디터 화면에서 부터 직접 따라하며 구현해봅니다. 단순히 화면에 나오는 코드를 따라 치는것이 아니라, 코드 한 줄 한 줄의 의미를 정확하게 이해시켜 드립니다.\n\n\n[문제 상황에 실제로 적용 가능한 실용적 AI 모델 강의]\n강화학습과 딥러닝의 핵심 모델에 대해 학습한 내용을 토대로 자율주행, 게임 실행 AI를 직접 개발해봅니다. 실습 과정을 통해 AI 핵심 이론부터 코드 레벨의 고민을 함께 해보고, 실제 문제 상황에서도 이를 적용해갈 수 있도록 합니다.\n\n\n또한, 본 강의에서 실습해본 모든 내용과 함께 상황에 따라 일부 코드만 변경하여 바로 사용할 수 있는 코드 템플릿을 강의 수강생 모두에게 제공합니다.\n\n\n이론만 지루하게 학습하는 AI 강의가 아니라, 실제로 나만의 AI를 구현해볼 수 있도록 도와드리는 실전형 강의입니다.\n\n\n[300만 수강생을 AI 학습에 입문시킨 Ligency Team의 한 마디]\n한국 수강생 여러분 안녕하세요! 저희 베스트 셀러 강의 중 하나인 <AI 만들기 : 강화학습과 인공신경망 완전 정복> 강의에 오신 것을 환영합니다!\n\n\n우리는 현실에서 여러분의 잠재력을 발휘해 줄 AI 최적화 방법, 상상을 현실로 만드는 AI 구축방법을 지구상에서 가장 접근하기 쉽게 프로젝트 중심으로 구성하였습니다. 단언컨대, 여러분은 이 강의를 통해 가장 쉽고 직관적으로 AI의 세계에 입문하게 될 것입니다.\n\n\n또한, 저희에게 \"영어로\" 질문을 주시면, 그 어떠한 질문이라도 최대 48시간 이내에 답변을 해드리겠습니다. 여러분의 도움이 필요할 때 언제든 지원해드리기 위해 준비된 전문 데이터 사이언티스트 팀이 여러분의 학습 과정에 함께합니다.\n\n\n함께 이 여정을 떠나봅시다! 기대되는군요.\n강의에서 만나요,\n\n\n- Ligency Team",
      "target_audience": [
        "인공지능 최신 기술 트렌드와 모델에 대한 학습이 필요한 사람 누구나"
      ]
    },
    {
      "title": "Menguasai Data Scraping dengan Python untuk Pekerja Remote!",
      "url": "https://www.udemy.com/course/menguasai-data-scraping-dengan-python-untuk-pekerja-remote/",
      "bio": "Data scraping adalah jalur tercepat bagimu untuk menembus job remote dengan Python. Tuntaskan course ini dan tembus job!",
      "objectives": [
        "Menguasai package beautifulsoup dan scrapy untuk web scraping",
        "Menguasai xpath, css selector dan regex untuk menentukan elemen yang akan di-scrape",
        "Melakukan export data yang sesuai dengan request client",
        "Mempersiapkan personal branding scraping untuk menembus job Upwork dan Fiverr"
      ],
      "course_content": {
        "Dasar Web Scraping yang Wajib Diketahui": [
          "Pengenalan Data Scraping",
          "Apa dan Kenapa Web Scraping",
          "Alur Singkat Web Scraping",
          "Persiapan Tools dan Requirements",
          "Trik Analisa suatu website"
        ],
        "Studi Kasus: Parsing Website Indeed.com": [
          "Scraping Total Pages",
          "Scraping Job Item",
          "Sorting Data Hasil Scraping",
          "Mengolah Hasil Scraping menjadi JSON file",
          "Mengolah Hasil Scraping Menjadi CSV atau Excel File",
          "Finishing Indeed Scraping Project"
        ],
        "Studi Kasus: Parsing Website Detik.com": [
          "Scraping Detik menggunakan BeautifulSoup4 dan Flask"
        ],
        "Studi Kasus: Scraping JSON API Result website Floatrates": [
          "Curency Menggunakan JSON"
        ],
        "Studi Kasus: Parsing Website Jadwal Sholat PKPU": [
          "Scraping Jadwal Sholat PKPU menggunakan BeautifulSoup4"
        ],
        "Studi Kasus: Parsing Website Carousel": [
          "Parsing Website Carousel menggunakan Requests dan BeautifulSoup Part 1",
          "Parsing Website Carousel menggunakan Requests dan BeautifulSoup Part 2",
          "Membuat Carousel Scraping Template menggunakan Flask part 1",
          "Membuat Carousel Scraping Template Menggunakan Flask part 2",
          "Extract Data Hasil Scraping ke Format CSV",
          "Menyimpan Hasil Scraping Deskripsi Produk ke Format CSV",
          "Menyimpan Data Review ke Format CSV",
          "Download Media Postingan Website Carousel"
        ],
        "Tips Dan Trik Menjalankan Repository Contoh Kode": [
          "Menjalankan Repository Contoh Kode di Windows 10 Part 1",
          "Menjalankan Repository Contoh Kode di Windows 10 Part 2",
          "Menjalankan Repository Contoh Kode di Linux"
        ],
        "Advanced Data Scraping menggunakan Flask dan BeautifulSoup": [
          "Advanced Data Scraping Menggunakan BeautifulSoup dan Flask"
        ],
        "Studi Kasus: parsing Website Instagram": [
          "Parsing Like Instagram: JSON API",
          "Parsing Like Instagram: Pagination",
          "Parsing Like Instagram: Extraction",
          "Parsing Like Instagram: Comment Extract",
          "Parsing Like Instagram: Download Media Hashtag"
        ],
        "EXTRA: Scraping dengan Selenium dan Scrapy": [
          "Competitive Learning: Kuliah Umum tentang Remote Worker dan Personal Branding",
          "Otomasi Browser Menggunakan Selenium",
          "Introduction to Scrapy"
        ]
      },
      "requirements": [
        "Menguasai Fundamental Python"
      ],
      "description": "Mengapa harus Web Scraping?\nSebenarnya, jelas bukan harus. Maksudnya, kamu tentunya bebas memilih jalur karir remote work-mu yang manapun. Namun, pengamatan kami di Remote Worker Indonesia menunjukkan suatu trend, bahwa pemula sekalipun, jika sudah menguasai tiga hal ini:\nPython Fundamental\nMastering Git\nData Scraping\nAkan cepat sekali bisa menembus remote work via Upwork.\n\"Wah semudah itu???\"\nMaaf-maaf, ga semudah itu juga.\nKamu tetap harus berproses menuntaskan banyak studi kasus web scraping. Nah, di course ini kamu akan menemukan banyak sekali studi kasus data scraping berikut ini:\nScraping situs indeed\nScraping situs Steam\nScraping situs carousel\nScraping detik\nApa itu Web Scraping?\nWeb Scraping adalah kegiatan untuk mengambil data dari suatu website dengan memanfaatkan tag-tag, class dan id atribut HTML.\nApa yang diperlukan untuk Web Scraping Pemula?\nUntuk melakukan web scraping hal minimal yang harus dipahami adalah\nKomponen Halaman Web\nMengetahui HTML Dasar\nPython Dasar\nMengetahui Jaringan Dasar (misalnya HTTP Request)\nKomponen Halaman Web\nKomponen Halaman Web secara dasar terdiri atas 3 komponen utama seperti\nHTML\nCSS\nJavaScript\nHTML adalah komponen paling dasar yang berfungsi sebagai kerangka utama dalam pembuatan Web CSS digunakan agar web terlihat lebih indah seperti komposisi warna ukuran serta posisi, semua diatur menggunakan CSS ini JavaScript bisa digunakan sebagai backend ataupun frontend sebuah website supaya lebih interaktif dan mudah digunakan pengguna\nWeb Scraping StarterPack\nApa yang dibutuhkan untuk melakukan web scraping?, ada beberapa modul yang biasa digunakan untuk melakukan web scraping seperti\nModul Request\nmodul BeautifulSoup atau Scrapy (kita akan menggunakan BeautifulSoup)\nVirtualEnv atau virtual environtment",
      "target_audience": [
        "Pemula Python yang Sudah Menguasai Fundamental Python"
      ]
    },
    {
      "title": "130+ Ćwiczeń w języku Python - Data Science - Pandas",
      "url": "https://www.udemy.com/course/cwiczenia-jezyk-python-data-science-pandas/",
      "bio": "Pandas w praktyce: Nauka analizy danych i manipulacji - idealny dla każdego poziomu zaawansowania!",
      "objectives": [
        "rozwiąż ponad 130 ćwiczeń w Pandas",
        "zajmij się rzeczywistymi problemami występującymi w data science",
        "pracuj z dokumentacją i Stack Overflow",
        "gwarantowane wsparcie instruktora"
      ],
      "course_content": {
        "Konfiguracja (opcjonalnie)": [
          "Info",
          "Wprowadzenie do Google Colab",
          "Instalacja Anacondy - Windows 10",
          "Wprowadzenie do programu Spyder",
          "Instalacja Anacondy - Linux (Ubuntu)"
        ],
        "Wskazówki": [
          "Kilka słów od autora"
        ],
        "Starter": [
          "Ćwiczenie 0",
          "Rozwiązanie 0",
          "Pandas - Intro"
        ],
        "Ćwiczenia 1-10": [
          "Ćwiczenie 1",
          "Rozwiązanie 1",
          "Ćwiczenie 2",
          "Rozwiązanie 2",
          "Ćwiczenie 3",
          "Rozwiązanie 3",
          "Ćwiczenie 4",
          "Rozwiązanie 4",
          "Ćwiczenie 5",
          "Rozwiązanie 5",
          "Ćwiczenie 6",
          "Rozwiązanie 6",
          "Ćwiczenie 7",
          "Rozwiązanie 7",
          "Ćwiczenie 8",
          "Rozwiązanie 8",
          "Ćwiczenie 9",
          "Rozwiązanie 9",
          "Ćwiczenie 10",
          "Rozwiązanie 10"
        ],
        "Ćwiczenia 11-20": [
          "Ćwiczenie 11",
          "Rozwiązanie 11",
          "Ćwiczenie 12",
          "Rozwiązanie 12",
          "Ćwiczenie 13",
          "Rozwiązanie 13",
          "Ćwiczenie 14",
          "Rozwiązanie 14",
          "Ćwiczenie 15",
          "Rozwiązanie 15",
          "Ćwiczenie 16",
          "Rozwiązanie 16",
          "Ćwiczenie 17",
          "Rozwiązanie 17",
          "Ćwiczenie 18",
          "Rozwiązanie 18",
          "Ćwiczenie 19",
          "Rozwiązanie 19",
          "Ćwiczenie 20",
          "Rozwiązanie 20"
        ],
        "Ćwiczenia 21-30": [
          "Ćwiczenie 21",
          "Rozwiązanie 21",
          "Ćwiczenie 22",
          "Rozwiązanie 22",
          "Ćwiczenie 23",
          "Rozwiązanie 23",
          "Ćwiczenie 24",
          "Rozwiązanie 24",
          "Ćwiczenie 25",
          "Rozwiązanie 25",
          "Ćwiczenie 26",
          "Rozwiązanie 26",
          "Ćwiczenie 27",
          "Rozwiązanie 27",
          "Ćwiczenie 28",
          "Rozwiązanie 28",
          "Ćwiczenie 29",
          "Rozwiązanie 29",
          "Ćwiczenie 30",
          "Rozwiązanie 30"
        ],
        "Ćwiczenia 31-40": [
          "Ćwiczenie 31",
          "Rozwiązanie 31",
          "Ćwiczenie 32",
          "Rozwiązanie 32",
          "Ćwiczenie 33",
          "Rozwiązanie 33",
          "Ćwiczenie 34",
          "Rozwiązanie 34",
          "Ćwiczenie 35",
          "Rozwiązanie 35",
          "Ćwiczenie 36",
          "Rozwiązanie 36",
          "Ćwiczenie 37",
          "Rozwiązanie 37",
          "Ćwiczenie 38",
          "Rozwiązanie 38",
          "Ćwiczenie 39",
          "Rozwiązanie 39",
          "Ćwiczenie 40",
          "Rozwiązanie 40"
        ],
        "Ćwiczenia 41-50": [
          "Ćwiczenie 41",
          "Rozwiązanie 41",
          "Ćwiczenie 42",
          "Rozwiązanie 42",
          "Ćwiczenie 43",
          "Rozwiązanie 43",
          "Ćwiczenie 44",
          "Rozwiązanie 44",
          "Ćwiczenie 45",
          "Rozwiązanie 45",
          "Ćwiczenie 46",
          "Rozwiązanie 46",
          "Ćwiczenie 47",
          "Rozwiązanie 47",
          "Ćwiczenie 48",
          "Rozwiązanie 48",
          "Ćwiczenie 49",
          "Rozwiązanie 49",
          "Ćwiczenie 50",
          "Rozwiązanie 50"
        ],
        "Ćwiczenia 51-60": [
          "Ćwiczenie 51",
          "Rozwiązanie 51",
          "Ćwiczenie 52",
          "Rozwiązanie 52",
          "Ćwiczenie 53",
          "Rozwiązanie 53",
          "Ćwiczenie 54",
          "Rozwiązanie 54",
          "Ćwiczenie 55",
          "Rozwiązanie 55",
          "Ćwiczenie 56",
          "Rozwiązanie 56",
          "Ćwiczenie 57",
          "Rozwiązanie 57",
          "Ćwiczenie 58",
          "Rozwiązanie 58",
          "Ćwiczenie 59",
          "Rozwiązanie 59",
          "Ćwiczenie 60",
          "Rozwiązanie 60"
        ],
        "Ćwiczenia 61-70": [
          "Ćwiczenie 61",
          "Rozwiązanie 61",
          "Ćwiczenie 62",
          "Rozwiązanie 62",
          "Ćwiczenie 63",
          "Rozwiązanie 63",
          "Ćwiczenie 64",
          "Rozwiązanie 64",
          "Ćwiczenie 65",
          "Rozwiązanie 65",
          "Ćwiczenie 66",
          "Rozwiązanie 66",
          "Ćwiczenie 67",
          "Rozwiązanie 67",
          "Ćwiczenie 68",
          "Rozwiązanie 68",
          "Ćwiczenie 69",
          "Rozwiązanie 69",
          "Ćwiczenie 70",
          "Rozwiązanie 70"
        ]
      },
      "requirements": [
        "ukończone kursy ze ścieżki Python Developer na tym koncie instruktorskim",
        "ukończone kursy ze ścieżki Data Scientist na tym koncie instruktorskim",
        "podstawowa wiedza na temat Pandas"
      ],
      "description": "To praktyczny kurs, który ma na celu utrwalenie wiedzy na temat biblioteki Pandas, podstawowego narzędzia dla każdego specjalisty od data science pracującego z językiem Python.\nKurs ten składa się z ponad 130 ćwiczeń, które pokrywają szeroki zakres funkcji Pandas, od tworzenia, indeksowania, sortowania i selekcji DataFrame, do łączenia danych, obsługi brakujących danych, grupowania i zastosowania operacji statystycznych. Wszystkie ćwiczenia są zaprojektowane tak, aby pokazać praktyczne zastosowania Pandas w typowych scenariuszach analizy danych.\nDla każdego ćwiczenia dostępne są szczegółowe rozwiązania, które pomagają uczestnikom porównać ich podejście z optymalnym rozwiązaniem, zrozumieć potencjalne błędy i nauczyć się lepszego podejścia do problemu.\nTen kurs to doskonały wybór dla tych, którzy chcą opanować Pandas i stać się bardziej efektywnymi w data science z użyciem Pythona. Bez względu na to, czy jesteś początkującym w data science, czy doświadczonym analitykiem, ten kurs pomoże Ci udoskonalić swoje umiejętności i zrozumieć, jak efektywnie wykorzystać Pandas w analizie danych.\n\n\nPandas – Twoje dane w porządku\nPandas to potężna biblioteka Pythona przeznaczona do analizy i manipulacji danymi. Umożliwia łatwe przetwarzanie danych tabelarycznych dzięki strukturom takim jak Series i DataFrame. Pandas oferuje intuicyjne narzędzia do filtrowania, grupowania, agregacji, czyszczenia i łączenia danych, co czyni ją niezbędnym narzędziem w pracy każdego analityka danych, naukowca czy inżyniera uczenia maszynowego.",
      "target_audience": [
        "analitycy danych i naukowcy, którzy chcą rozwijać swoje umiejętności w zakresie manipulacji i analizy danych przy użyciu biblioteki Pandas w języku Python",
        "programiści Pythona, którzy chcą poznać zaawansowane techniki przetwarzania danych, filtrowania, grupowania i wizualizacji danych za pomocą biblioteki Pandas",
        "studenci lub absolwenci kierunków związanych z informatyką, statystyką, analizą danych lub pokrewnymi dziedzinami, którzy chcą zdobyć praktyczne umiejętności związane z analizą danych przy użyciu biblioteki Pandas",
        "specjaliści ds. danych i analitycy biznesowi, którzy chcą pogłębić swoje umiejętności w zakresie przetwarzania i analizy danych przy użyciu Pythona i biblioteki Pandas",
        "osoby zainteresowane eksploracją danych, czyszczeniem danych, agregacją danych i przygotowaniem danych do analizy, które preferują język Python i chcą poznać zaawansowane funkcje i techniki dostępne w bibliotece Pandas",
        "osoby pragnące rozpocząć karierę w dziedzinie data science, które chcą zdobyć praktyczne umiejętności w przetwarzaniu i analizie danych przy użyciu biblioteki Pandas w języku Python"
      ]
    },
    {
      "title": "Veri Bilimi, Makine Öğrenimi, Kaggle için Python Programlama",
      "url": "https://www.udemy.com/course/veri-bilimi-makine-ogrenimi-kaggle-icin-python-programlama/",
      "bio": "Makine Öğrenimi (Machine Learning) ve Veri Bilimi(Data Science) için Python, İstatistik, Numpy, Pandas ve Kaggle'ı öğren",
      "objectives": [
        "İster makine öğrenimi, ister finans alanında çalışıyor olun, ister web geliştirme veya veri bilimi alanında kariyer yapıyor olun.",
        "Python öğrenebileceğiniz en önemli becerilerden biridir. Python'un basit sözdizimi özellikle masaüstü, web ve iş uygulamaları için uygundur.",
        "Udemy'deki OAK Academy Python eğitmenleri, yazılım geliştirmeden veri analizine kadar uzmandırlar ve öğrencilere yönelik etkili eğitimleriyle bilinirler.",
        "Veri Bilimi Nedir?",
        "Veri Biliminin Bileşenleri Nelerdir?",
        "Veri Bilimi İle Ne Yapmayı Amaçlıyoruz?",
        "Veriden Anlamlı Bilgiyi Nasıl Çıkarırız?",
        "Veri Biliminde Proje Süreci Nasıl İşliyor?",
        "Gerçek Hayattan Projeler İle Kavramların Pekiştirilmesi",
        "Gerçek Hayattan Örneklere Devam",
        "Kurstan En İyi Şekilde Nasıl Verim Alabilirim?",
        "Meraklılarına Doküman Tavsiyeleri",
        "Veriyi Görmek Ve Okumak Nasıl Olur?",
        "Popülasyon Ve Örneklem",
        "Gözlem Birimi",
        "Değişken Ve Türleri",
        "Ölçek Türleri",
        "Aritmetik Ortalama",
        "Medyan",
        "Mod",
        "Çeyrekler",
        "Merkezi Eğilim Neden Önemlidir?",
        "İstatistikte Veri Desenleri",
        "Değişim Aralığı",
        "Standart Sapma",
        "Varyans",
        "Standart Hata",
        "Çarpıklık",
        "Basıklık",
        "İstatistiksel Düşünce Modelleri Ve Bileşenlerinin İncelenmesi",
        "Verinin Belirlenmesi Ve Tanımlanması",
        "Verinin Düzenlenmesi Ve Planlanması",
        "Verinin Gösterimi",
        "Verinin Gösterimi – Frekans Tablosu",
        "Verinin Gösterimi – Histogram",
        "Verinin Gösterimi – Pasta Grafik",
        "Verinin Gösterimi – Çubuk Grafik",
        "Verinin Gösterimi – Çizgi Grafik",
        "Verinin Çözümlenmesi Ve Yorumlanması",
        "Python",
        "Deep Learning ( Derinlemesine Öğrenme )",
        "Machine Learning ( Makine Öğrenmesi )",
        "Yapay Zeka",
        "İstatistik",
        "Yeni Başlayanlar için Python Tanıtım",
        "Meraklılarına Python Bootcamp Doküman Tavsiyeleri",
        "Anaconda Windows İşletim Sistemi Kurulum",
        "Anaconda Linux İşletim Sistemi Kurulum",
        "Jupyter Notebook’u İnceleme",
        "Jupyter Lab’ı İnceleme",
        "Python Kodlamaya İlk Adımlar",
        "Tırnak Meselesi",
        "Python Kodlama Biçimi Ve Stili(PEP8) Nasıl Olmalı?",
        "Python’da Temel Veri Yapıları İle Tanışma",
        "Atama İşlemi Ve Değişkenler(Variables)",
        "Python Komplex Atama İşlemi",
        "Machine Learning Python Tip Dönüşümleri",
        "Ptyhon’da Aritmetik İşlemler",
        "Print Fonksiyonunu Derinlemesine İnceleme",
        "Escape Sequence İşlemleri",
        "Pyhton Programming ile Boolean Mantık İfadeleri",
        "Boolean Mantıksal İfadelerde İşlem Önceliği",
        "Boolean İşlemlerini Python Üzerinde Uygulama",
        "Karakter Dizilerini(String) Spesifik Olarak İnceleme",
        "Uzunluk Bilgisine Erişme: len() Metodu",
        "Stringlerde Arama Metodları: startswith(), endswith()",
        "Stringlerde Karakter Değiştirme Metodları: replace()",
        "Stringlerde İmla’sal Değiştirme Metodları: swapcase(), capitalize(), upper(), lower(), title()",
        "Stringlerde Kırpma Metodları: strip(), lstrip(), rstrip()",
        "Karakter Dizilerini İndexleme Ve Dilimleme",
        "Komplex İndexleme Ve Dilimleme İşlemleri",
        "Aritmetik İşlemler İle Karakter Dizisi Biçimleme",
        "% Operatörü İle String Formatting",
        "string. format İle String Formatting, f-string Metodu İle String Formatting",
        "Python’da Liste Oluşturma",
        "Liste Elemanlarına Ulaşma – İndexleme Ve Dilimleme, Listelere Eleman Ekleme & Değiştirme & Silme, Listelere Metodlar İle Eleman Ekleme Ve silme",
        "Listelere İndexe Göre Eleman Ekleme Ve silme, Diğer Liste Metodları",
        "Python’da Tuple(Demet) Oluşturma, Tuple(Demet) Elemanlarına Ulaşma – İndexleme Ve Dilimleme",
        "Python’da Sözlük(Dictionary) Oluşturma, Sözlük(Dictionary) Elemanlarına Ulaşma",
        "Sözlük(Dictionary)’lere Eleman Ekleme & Değiştirme & Silme, Sözlük(Dictionary) Metodları",
        "Python’da Set(Küme) Oluşturma",
        "Set(Küme)’lere Eleman Ekleme Ve Çıkarma Metodları, Set(Küme)’lerde Fark İşlem Metodları",
        "Set(Küme)’lerde Kesişim Ve Birşelim İşlemi, Metodları Set(Küme)’lere Soru Soran Metodlar",
        "Karşılaştırma Operatörleri",
        "‘if’ İfadelerinin Yapısı, ‘if – else’ İfadelerinin Yapısı, ‘if – elif - else’ İfadelerinin Yapısı",
        "İç İçe Geçmiş(Nested) ‘if – elif - else’ İfadeleri İf Ve İnput İle Koordineli Programlama",
        "Ternary Condition",
        "Python’da For Dögüsü",
        "For Döngüsü Pekiştirme",
        "Koşullu İfadeler Ve For Döngüsünün Birlikte Kullanımı",
        "Continue Komutu, Break Komutu, List Comprehension",
        "Python’da While Dögüsü, While Döngüsü Pekiştirme",
        "Fonksiyonlar İle Tanışma Fonksiyon Nasıl Yazılır? Fonksiyon’da Return İfadesi, Birden Fazla Argümanlı Fonksiyon Yazma",
        "Fonskiyonlarda Docstring Yazma, Fonksiyonlar Ve Koşullu İfadelerin Birlikte Kullanımı",
        "Argümanlar Ve Parametreler, Argümanlar İle Yüksek Seviye İşlemler",
        "Built-in Fonksiyon – all(), any() Built-in Fonksiyon – map() Built-in Fonksiyon – filter() Built-in Fonksiyon – zip()",
        "Built-in Fonksiyon – enumerate() Built-in Fonksiyon – max(), min() Built-in Fonksiyon – sum() Built-in Fonksiyon – round()",
        "Lambda Fonksiyonu, Local Ve Global Değişkenler",
        "Sınıfların(Class) Özellikleri, Sınıfların Örneklemesi(Attributes)",
        "Örneklemlerin Özellikleri, Sınıf İçinde Fonksiyon Yazma, Miras(Inheritance) Yapıları",
        "Pandas Kütüphanesi Tanıtım",
        "Kaggle Nedir?",
        "Kaggle’a Kaydolma ve Üye Giriş Prosedürleri",
        "Kaggle Ana sayfasını Tanıma",
        "Kaggle da Yarışmalar",
        "Kaggle’da Veri Setleri",
        "Kaggle’da Tartışma Nedir?",
        "Kaggle'da Başarıya Ulaşmak İçin Neler Yapılmalıdır?"
      ],
      "course_content": {
        "Veri Bilimini(Data Science) Tanıma ve Motivasyon": [
          "Veri Bilimi Nedir?",
          "Kurs Proje Dosya Linkleri",
          "Veri Biliminin Bileşenleri Nelerdir?",
          "Veri Bilimi İle Ne Yapmayı Amaçlıyoruz?",
          "Python Veri Bilimi Hakkında Sık Sorulan Sorular",
          "Veriden Anlamlı Bilgiyi Nasıl Çıkarırız?",
          "Veri Biliminde Proje Süreci Nasıl İşliyor?",
          "Gerçek Hayattan Projeler İle Kavramların Pekiştirilmesi",
          "Gerçek Hayattan Örneklere Devam",
          "Kurstan En İyi Şekilde Nasıl Verim Alabilirim?",
          "Meraklılarına Doküman Tavsiyeleri",
          "Quiz-1"
        ],
        "Veri Analizi İle Birlikte Veriyi Tanıma": [
          "Veriyi Görmek Ve Okumak Nasıl Olur?",
          "Popülasyon Ve Örneklem",
          "Gözlem Birimi",
          "Değişken Ve Türleri",
          "Ölçek Türleri",
          "Veri Bilimi Quiz"
        ],
        "Veri Analizinde Merkezi Eğilim Ölçüleri": [
          "Aritmetik Ortalama",
          "Medyan",
          "Mod",
          "Çeyrekler",
          "Merkezi Eğilim Neden Önemlidir?",
          "İstatistikte Veri Desenleri",
          "Veri Bilimi Quiz"
        ],
        "Veri Analizinde Merkezi Dağılım Ölçüleri": [
          "Değişim Aralığı(Range)",
          "Standart Sapma",
          "Varyans",
          "Standart Hata",
          "Çarpıklık(Skewness)",
          "Basıklık(Kurtosis)",
          "Veri Bilimi Quiz"
        ],
        "İstatistiksel Düşünce Modelleri Ve Bileşenleri": [
          "İstatistiksel Düşünce Modelleri Ve Bileşenlerinin İncelenmesi",
          "Veri Bilimi Quiz"
        ],
        "Veri Biliminde(Data Science) Mooney Modeli Basamaklarını Uygulama": [
          "Verinin Belirlenmesi Ve Tanımlanması",
          "Verinin Düzenlenmesi Ve Planlanması",
          "Verinin Gösterimi",
          "Verinin Gösterimi – Frekans Tablosu",
          "Verinin Gösterimi – Histogram",
          "Verinin Gösterimi – Pasta Grafik",
          "Verinin Gösterimi – Çubuk Grafik",
          "Verinin Gösterimi – Çizgi Grafik",
          "Verinin Çözümlenmesi Ve Yorumlanması",
          "Veri Bilimi Quiz"
        ],
        "Kurulumlar(Anaconda Navigator, Jupyter Notebook, Jupyter Lab)": [
          "Python Tanıtım",
          "Meraklılarına Python İle Alakalı Doküman Tavsiyeleri",
          "Python Bootcamp Dokümanları",
          "Python ile Veri Bilimi hakkında Sık Sorulan Sorular",
          "Python Hakkında Alıntılar",
          "Anaconda Windows İşletim Sistemi Kurulum",
          "Anaconda Linux İşletim Sistemi Kurulum",
          "Jupyter Notebook’u İnceleme",
          "Jupyter Lab’ı İnceleme"
        ],
        "Python Kodlamaya İlk Adımlar": [
          "Python Kodlamaya İlk Adımlar",
          "Tırnak Meselesi",
          "Python Kodlama Biçimi Ve Stili(PEP8) Nasıl Olmalı?",
          "Quiz"
        ],
        "Python İle Temel İşlemler(Python For Beginners)": [
          "Python’da Temel Veri Yapıları İle Tanışma",
          "Atama İşlemi Ve Değişkenler(Variables)",
          "Komplex Atama İşlemi",
          "Python'da Tip Dönüşümleri",
          "Python’da Aritmetik İşlemler",
          "Print Fonksiyonunu Derinlemesine İnceleme",
          "Escape Sequence İşlemleri",
          "Quiz"
        ],
        "Boolean Veri Türü İle Python Programlama": [
          "Boolean Mantık İfadeleri",
          "Boolean Mantıksal İfadelerde İşlem Önceliği",
          "Boolean İşlemlerini Python 3 Üzerinde Uygulama",
          "Quiz"
        ]
      },
      "requirements": [
        "Kurs videolarını eksiksiz, sonuna kadar ve sırayla izlemek.",
        "İnternet Bağlantısı",
        "Cep telefonu, bilgisayar veya tablet gibi dersi izleyebileceğiniz herhangi bir cihaz.",
        "Veri Bilimi, İstatistik, Python, Deep Learning, Machine Learning Öğrenme kararlılığı ve sabır.",
        "Machine learning (makine öğrenmesi), deep learning ve big data öğrenme isteği",
        "Numpy kütüphanesi ile ver analizi (data analysis) nasıl yapılır öğrenme isteği",
        "Python ile data science (veri bilimi) öğrenme arzusu",
        "Kaggle ile Veri Bilimi, Makine Öğrenimi, Python Portföyünü geliştirme arzusu"
      ],
      "description": "Veri bilimi, Data Science, makine öğrenimi, Machine Learning, Python, İstatistik, R, Makine Öğrenmesi, Derin Öğrenme, Django, Numpy, Pandas, Kaggle\n\nMerhaba,\n“Veri Bilimi, Makine Öğrenimi, Kaggle için Python Programlama” kursumuza hoş geldiniz.\nMakine Öğrenimi (Machine Learning) ve Veri Bilimi(Data Science) için Python, İstatistik, Numpy, Pandas ve Kaggle'ı öğren\n\n\nVeri bilimi ve Makine öğrenimi (data science and machine learning) olmadan yaşamımızın hayalini kurmak zordur. Kelime tahmin sistemi, e-posta filtreleme ve Amazon'un Alexa'sı ve iPhone'nun Siri'si gibi sanal kişisel yardımcılar, makine öğrenimi algoritmalarına ve matematiksel modellere dayalı olarak çalışan teknolojilerdir.\nVeri bilimi ve Makine öğrenimi yalnızca kelime tahmin sistemi veya akıllı telefon ses tanıma özelliği için fayda sağlamaz. Makine öğrenimi ve veri bilimi, yeni sektörlere ve yeni sorunlara sürekli olarak uygulanır.\nVeri bilimi uygulaması, finans, ulaşım, eğitim, üretim, insan kaynakları ve bankacılık dahil olmak üzere dünya çapında birçok sektörde talep gören bir beceridir. Bilginizi artırmak için Python, istatistik, makine öğrenimi ve daha fazlasını içeren veri bilimi kurslarını keşfedin. Araştırma, istatistik ve analitik ile ilgileniyorsanız veri bilimi eğitimi almalısınız.\nMakine öğrenimi, yalnızca tahmine dayalı mesajlaşma veya akıllı telefon ses tanıma için kullanışlı değildir. Makine öğrenimi sürekli olarak yeni endüstrilere ve yeni sorunlara uygulanmaktadır. İster pazarlamacı ister video oyunu tasarımcısı veya programcı olun, Oak Academy'de makine öğreniminde işinize ve uygulamanıza yardımcı olacak kurslar mevcuttur. Makine öğrenimi olmadan hayatımızı hayal etmek zordur. Tahmini mesajlaşma, e-posta filtreleme ve Amazon'un Alexa'sı ve iPhone'un Siri'si gibi sanal kişisel asistanların tümü, makine öğrenimi algoritmalarına ve matematiksel modellere dayalı olarak çalışan teknolojilerdir.\nGoogle’ın bir yan kuruluşu olan Kaggle, çevrimiçi veri bilimciler ve makine öğrenimi uygulayıcıları topluluğudur.\nKaggle, kullanıcıların veri kümelerini bulmasına ve yayınlamasına, web tabanlı bir veri bilimi ortamında modelleri keşfetmesine ve oluşturmasına, diğer veri bilimciler ve makine öğrenimi mühendisleriyle çalışmasına ve veri bilimi zorluklarını çözmek için yarışmalara katılmasına olanak tanır.\nİster makine öğrenimi, ister finans alanında çalışıyor olun, ister web geliştirme veya veri bilimi alanında kariyer yapıyor olun, Python öğrenebileceğiniz en önemli becerilerden biridir. Python'un basit sözdizimi özellikle masaüstü, web ve iş uygulamaları için uygundur.\nPython'un basit sözdizimi ve okunabilirliği Python'u Flask, Django, veri bilimi ve makine öğrenimi için mükemmel kılar.\nPython, genel amaçlı, nesne yönelimli, üst düzey bir programlama dilidir. İster yapay zeka veya finans alanında çalışıyor olun, ister web geliştirme veya veri bilimi alanında kariyer yapıyor olun, Python öğrenebileceğiniz en önemli becerilerden biridir. Python'un basit sözdizimi özellikle masaüstü, web ve iş uygulamaları için uygundur. Python'un tasarım felsefesi okunabilirliği ve kullanılabilirliği vurgular. Python, işleri yapmanın yalnızca bir yolu (ve tercihen tek bir açık yolu) olması gerektiği fikri üzerine geliştirildi; bu, katı bir kod standardizasyonu düzeyiyle sonuçlanan bir felsefe. Çekirdek programlama dili oldukça küçüktür ve standart kitaplık da büyüktür. Aslında, Python'un en büyük faydalarından biri, programcılar için çeşitli görevlere uygun farklı araçlar sağlayan geniş kütüphanesidir.\nKaggle, kurulum gerektirmeyen, özelleştirilebilir bir Jupyter Notebooks ortamı sunar.\nKaggle ile ücretsiz GPU' lara ve topluluk tarafından yayınlanan büyük bir veri ve kod deposuna erişebilirsiniz.\nKaggle, veri bilimcilerinin makine öğrenimi zorluklarında rekabet edebilecekleri bir platformdur. Bu zorluklar, konut fiyatlarını tahmin etmekten kanser hücrelerini tespit etmeye kadar her şey olabilir.\nKaggle, veri bilimi sorunları konusunda başkalarına her zaman yardım etmeye istekli olan büyük bir veri bilimcisi topluluğuna sahiptir.\nKaggle, yarışmalara ek olarak, makine öğrenimine başlamanıza yardımcı olabilecek birçok öğreticiye ve kaynağa da sahiptir.\nKendini geliştirmeye çalışan bir veri bilimcisi iseniz, Kaggle başlamak için en iyi yoldur. Birçok şirket, yarışmalarında yüksek derecelere sahip olanlara teklifler vermektedir. Aslında, yüksek sıralamalarından birine ulaşabilirseniz, Kaggle tam zamanlı işiniz olabilir.\nKaggle'ın içinde, veri bilimi çalışmanızı yapmak için ihtiyacınız olan tüm kod ve verileri bulacaksınız. Herhangi bir analizi anında kullanmak için 50.000'den fazla genel veri kümesi ve 400.000 genel not defterini bu platformda bulabilirsiniz.\nNumpy Veri bilimi alanında en çok kullanılan kütüphanelerden bir tanesidir.\nPANDAS Veri bilimi alanında en çok kullanılan kütüphanelerden bir tanesidir.\nEvet şimdi gelelim kursumuza..\n21. Yüzyılın en popüler mesleklerinden birisi olarak görülen veri biliminin temeline inip mantığını kavramaya çalışacağımız bu eğitim ile bir çok gerçek hayat uygulaması üzerinden çalışma yapacağız\nGerçek hayattan örnekler ile konuları kavramış olacaksınız. Bu kurs ile adım adım veri analizinin nasıl yapılacağını ve Pyhon Programlama Dilini öğreneceksiniz.\nVeri Bilimi dünyasının kapısını aralayacak ve bundan sonrası için daha derine inme kabiliyetine sahip olacaksınız. Temel istatistik kavramları ile keşifsel veri analizi yapmayı öğreneceksiniz.\nVeri bilimi alanında en çok kullanılan kütüphanelerden Pandas ve Numpy kütüphanelerini öğreneceksiniz.\n\n\nHiçbir platformda Kaggle ile ilgili bu kadar detaylı bir kurs olmadığını biliyor muydunuz?\nVe veri bilimi ihtiyaçlarının 2026 yılına kadar 11,5 milyon iş fırsatı yaratacağını biliyor musunuz?\nVeri bilimi kariyerleri için ortalama maaşın 100.000 dolar olduğunu biliyor musunuz?\n\n\nVERİ BİLİMİ KARİYERLERİ GELECEĞİ ŞEKİLLENDİRİYOR\nBU KARİYER KAGGLE PLATFORMU İLE CANLANDIRIN\n\n\nPeki, Veri Bilimi neden bu kadar önemli bir alan? Gelin birlikte inceleyelim.\nDevlet güvenliğinden flört uygulamalarına kadar hemen hemen her alanda veri bilimi uzmanlarına ihtiyaç vardır. Milyonlarca işletme ve devlet dairesi, başarılı olmak ve müşterilerine daha iyi hizmet vermek için büyük verilere güveniyor. Bu nedenle, veri bilimi kariyerleri yüksek talep görmektedir.\nİşverenin en çok talep ettiği becerilerden birini öğrenmek istiyorsanız?\nVeri Bilimini merak ediyor ve Python ile veri dünyasına kendi kendine öğrenme yolculuğunuza başlamak istiyorsanız?\nDeneyimli bir geliştiriciyseniz ve Veri Biliminde bir iş arıyorsanız!\nHer durumda, doğru yerdesiniz!\n\n\nVeri biliminde CV'nizi geliştirmek için süper bir kurs olan “Kaggle - Veri Bilimi Alanında Daha İyi Bir Profil Oluşturun” kursumuzu sizin için tasarladık.\nKursta, her bölümü ayrıntılı olarak inceleyeceksiniz. Bu kurs ile Kaggle platformunu adım adım tanıyacaksınız.\n\n\nKaggle hakkında Sık Sorulan Sorular:\n\n\nKaggle nedir?\nGoogle LLC'nin bir yan kuruluşu olan Kaggle, çevrimiçi bir veri bilimcileri ve makine öğrenimi uygulayıcıları topluluğudur.\nKaggle, kurulum gerektirmeyen, özelleştirilebilir bir Jupyter Notebooks ortamı sunar. Ücretsiz GPU'lara ve topluluk tarafından yayınlanan büyük bir veri ve kod deposuna erişin.\nKaggle, veri bilimcilerinin makine öğrenimi zorluklarında rekabet edebilecekleri bir platformdur. Bu zorluklar, konut fiyatlarını tahmin etmekten kanser hücrelerini tespit etmeye kadar her şey olabilir. Kaggle, veri bilimi sorunları konusunda başkalarına her zaman yardım etmeye istekli olan büyük bir veri bilimcisi topluluğuna sahiptir. Kaggle, yarışmalara ek olarak, makine öğrenimine başlamanıza yardımcı olabilecek birçok öğretici ve kaynağa da sahiptir.\nKalkınan bir veri bilimcisi iseniz, Kaggle başlamak için en iyi yoldur. Birçok şirket, yarışmalarında yüksek derecelere sahip olanlara teklifler verecektir. Aslında, yüksek sıralamalarından birine ulaşabilirseniz, Kaggle tam zamanlı işiniz olabilir.\nMakine Öğrenmesi nedir?\nMakine öğrenmesi, gerçek dünya verileri üzerinde eğitilmiş bir model kullanarak tahminlerde bulunan sistemleri tanımlar. Örneğin, bir kedinin resimde olup olmadığını tespit edebilen bir sistem kurmak istediğimizi varsayalım. Makine öğrenimi modelimizi eğitmek için önce birçok resmi bir araya getiriyoruz. Bu eğitim aşamasında, bir kedi içerip içermediğine dair bilgilerle birlikte resimleri modele besliyoruz.\nBöylece Eğitim sırasında model, kedilerle en yakından ilişkili olan görüntülerdeki kalıpları öğrenir. Bu model daha sonra, beslediği yeni görüntülerin bir kedi içerip içermediğini tahmin etmek için eğitim sırasında öğrenilen kalıpları kullanabilir.\nBu özel örnekte, bu kalıpları öğrenmek için bir sinir ağı kullanabiliriz, ancak makine öğrenimi bundan çok daha basit olabilir. Bir dizi gözlemlenen veri noktasına bir çizgi uydurmak ve bu çizgiyi yeni tahminler yapmak için kullanmak bile bir makine öğrenimi modeli olarak sayılır.\nVeri bilimi nedir?\nHer zamankinden daha fazla veriye sahibiz. Ancak veriler tek başına çevremizdeki dünya hakkında bize pek bir şey söyleyemez. Bilgileri yorumlamamız ve gizli kalıpları keşfetmemiz gerekiyor.\nİşte burada veri bilimi devreye girer. Veri bilimi, ham verileri anlamak için algoritmalar kullanır. Veri bilimi ile geleneksel veri analizi arasındaki temel fark, tahmine odaklanmasıdır. Veri bilimi, verilerdeki kalıpları bulmaya ve bu kalıpları gelecekteki verileri tahmin etmek için kullanmaya çalışır. Büyük miktarda veriyi işlemek, kalıpları keşfetmek ve eğilimleri tahmin etmek için makine öğreniminden yararlanır.\nVeri bilimi, verilerin hazırlanmasını, analiz edilmesini ve işlenmesini içerir. Birçok bilimsel alandan yararlanır ve bir bilim olarak verileri analiz etmek ve mevcut yöntemleri doğrulamak için yeni algoritmalar oluşturarak ilerler.\nVeri bilimcisi ne iş yapar?\nVeri Bilimcileri, gerçek sorunlara ışık tutmak için büyük miktarda ham verideki gizli kalıpları keşfetmek için makine öğrenimini kullanır. Bu birkaç adım gerektirir. İlk olarak, uygun bir sorunu tanımlamaları gerekir. Daha sonra, böyle bir durumu çözmek için hangi verilere ihtiyaç duyulduğunu belirler ve verilerin nasıl elde edileceğini anlarlar. Verileri elde ettikten sonra, verileri temizlemeleri gerekir. Veriler doğru biçimlendirilmemiş olabilir, gereksiz ek veriler içerebilir, eksik girişler olabilir veya bazı veriler yanlış olabilir. Bu nedenle Veri Bilimcileri, verileri analiz etmeden önce verilerin temiz olduğundan emin olmalıdır. Verileri analiz etmek için, modeller oluşturmak için makine öğrenimi tekniklerini kullanırlar. Bir model oluşturduktan sonra test eder, iyileştirir ve sonunda üretime geçirirler.\nVeri bilimi için en popüler kodlama dilleri nelerdir?\nPython, veri bilimi için en popüler programlama dilidir. Çok sayıda kütüphaneye sahip evrensel bir dildir. Aynı zamanda iyi bir başlangıç dilidir. R ayrıca popülerdir; ancak, daha karmaşıktır ve istatistiksel analiz için tasarlanmıştır. İstatistiksel analizde uzmanlaşmak istiyorsanız iyi bir seçim olabilir. Python veya R ve SQL'i bilmek isteyeceksiniz. SQL, ilişkisel veritabanları için tasarlanmış bir sorgulama dilidir. Veri bilimciler büyük miktarda veriyle uğraşırlar ve bu verilerin çoğunu ilişkisel veritabanlarında depolarlar. Bunlar en çok kullanılan üç programlama dilidir. Java, C++, JavaScript ve Scala gibi diğer diller de az da olsa kullanılmaktadır. Bu dillerde zaten bir geçmişiniz varsa, bu dillerde bulunan araçları keşfedebilirsiniz. Ancak, zaten başka bir programlama dili biliyorsanız, Python'u çok hızlı bir şekilde öğrenebileceksiniz.\nVeri bilimcisi olmak ne kadar sürer?\nBu cevap elbette değişir. Yeni beceriler öğrenmeye ne kadar çok zaman ayırırsanız, o kadar hızlı öğrenirsiniz. Ayrıca başlangıç yerinize de bağlı olacaktır. Zaten matematikte ve istatistikte güçlü bir temeliniz varsa, öğrenecek daha az şeyiniz olacaktır. İstatistik veya ileri matematik geçmişiniz yoksa, yine de bir veri bilimcisi olabilirsiniz; sadece biraz daha uzun sürecek. Veri bilimi, yaşam boyu öğrenmeyi gerektirir, bu nedenle öğrenmeyi asla gerçekten bitirmeyeceksiniz. Daha iyi bir soru, \"Veri bilimcisi olmak için yeterli bilgiye sahip olup olmadığımı nasıl ölçebilirim?\" olabilir. Açık verileri kullanarak veri bilimi projelerini tamamlamak için kendinize sorun. Ne kadar çok pratik yaparsanız, o kadar çok öğreneceksiniz ve kendinize o kadar güveneceksiniz. Veri bilimcisi olarak beceri setinizin iyi örnekleri olarak gösterebileceğiniz birkaç projeniz olduğunda, alana girmeye hazırsınız.\nVeri bilimini kendi başıma nasıl öğrenebilirim?\nOdaklandığınız ve motive olduğunuz sürece veri bilimini kendi başınıza öğrenmek mümkündür. Neyse ki, birçok çevrimiçi kurs ve eğitim kampı mevcut. Veri bilimi hakkında sizi ilgilendiren şeyleri belirleyerek başlayın. Görselleştirmelere yöneliyorsanız, onları öğrenmeye başlayın. Sizi heyecanlandıran bir şeyle başlamak, o ilk adımı atmak için sizi motive edecektir. Nereden başlamak istediğinizden emin değilseniz, Python öğrenmeyi deneyin. Programlama dillerine mükemmel bir giriş niteliğindedir ve bir veri bilimcisi olarak faydalı olacaktır. Seçtiğiniz konuyla ilgili eğiticiler veya Udemy kursları üzerinde çalışarak başlayın. İlginizi çeken becerilerde bir temel oluşturduktan sonra, sahada birisiyle konuşmak yardımcı olabilir. İşverenlerin hangi becerileri aradığını öğrenin ve bu becerileri öğrenmeye devam edin. Kendi başınıza öğrenirken, pratik öğrenme hedefleri belirlemek sizi motive edebilir.\nBir veri bilimcisi hangi becerileri bilmelidir?\nBir veri bilimcisi birçok beceri gerektirir. Veri biliminin temel direkleri olan istatistiksel analiz ve matematik hakkında güçlü bir anlayışa ihtiyaçları vardır. Bu kavramları iyi anlamak, veri biliminin temel önermelerini anlamanıza yardımcı olacaktır. Makine öğrenimine aşinalık da önemlidir. Makine öğrenimi, büyük veri kümelerinde kalıpları bulmak için değerli bir araçtır. Büyük veri kümelerini yönetmek için veri bilimcilerin veritabanlarına aşina olması gerekir. Yapılandırılmış sorgu dili (SQL), veri bilimcileri için sahip olunması gereken bir beceridir. Ancak, ilişkisel olmayan veritabanlarının (NoSQL) popülaritesi artıyor, bu nedenle veritabanı yapılarının daha iyi anlaşılması faydalıdır. Veri Biliminde baskın programlama dili Python'dur - ancak R de popülerdir. Bu dillerden en az birinde temel almak iyi bir başlangıç noktasıdır. Son olarak, bulguları iletmek için veri bilimcileri görselleştirme bilgisine ihtiyaç duyar. Veri görselleştirmeleri, karmaşık verileri erişilebilir bir şekilde paylaşmalarına olanak tanır.\nPython nedir?\nPython, genel amaçlı, nesne yönelimli, üst düzey bir programlama dilidir. İster yapay zeka veya finans alanında çalışıyor olun, ister web geliştirme veya veri bilimi alanında kariyer yapıyor olun, Python öğrenebileceğiniz en önemli becerilerden biridir. Python'un basit sözdizimi özellikle masaüstü, web ve iş uygulamaları için uygundur. Python'un tasarım felsefesi okunabilirliği ve kullanılabilirliği vurgular. Python, işleri yapmanın yalnızca bir yolu (ve tercihen tek bir açık yolu) olması gerektiği fikri üzerine geliştirildi; bu, katı bir kod standardizasyonu düzeyiyle sonuçlanan bir felsefe. Çekirdek programlama dili oldukça küçüktür ve standart kitaplık da büyüktür. Aslında, Python'un en büyük faydalarından biri, programcılar için çeşitli görevlere uygun farklı araçlar sağlayan geniş kütüphanesidir.\nPython ın limitleri nelerdir?\nPython yaygın olarak kullanılan, genel amaçlı bir programlama dilidir, ancak bazı sınırlamaları vardır. Python yorumlanmış, dinamik olarak yazılmış bir dil olduğundan, C gibi derlenmiş, statik olarak yazılmış bir dile kıyasla yavaştır. Bu nedenle Python, hız o kadar önemli olmadığında kullanışlıdır. Python'un dinamik tip sistemi ayrıca diğer bazı programlama dillerinden daha fazla bellek kullanmasını sağlar, bu nedenle yoğun bellek kullanan uygulamalar için uygun değildir. Python kodunu çalıştıran Python sanal motoru, tek iş parçacıklı çalışır ve eşzamanlılığı programlama dilinin başka bir sınırlaması haline getirir. Python, bazı oyun geliştirme türleri için popüler olsa da, daha yüksek bellek ve CPU kullanımı, yüksek kaliteli 3D oyun geliştirme için kullanımını sınırlar. Bununla birlikte, bilgisayar donanımı gitgide daha iyi hale geliyor ve Python'un hız ve bellek sınırlamaları gitgide daha az alakalı hale geliyor.\nPython hangi işlerde kullanılır?\nPython is a popular language that is used across many industries and in many programming disciplines. DevOps engineers use Python to script website and server deployments. Web developers use Python to build web applications, usually with one of Python's popular web frameworks like Flask or Django. Data scientists and data analysts use Python to build machine learning models, generate data visualizations, and analyze big data. Financial advisors and quants (quantitative analysts) use Python to predict the market and manage money. Data journalists use Python to sort through information and create stories. Machine learning engineers use Python to develop neural networks and artificial intelligent systems.\nKaggle ne için kullanılır?\nKaggle, fikirleri paylaşmak, ilham almak, diğer veri bilimcileriyle rekabet etmek, yeni bilgiler ve kodlama hileleri öğrenmek ve ayrıca gerçek dünyadaki veri bilimi uygulamalarının çeşitli örneklerini görmek için kullanılan bir web sitesidir.\nKaggle'ı kullanmak ücretsiz mi?\nKaggle Hizmetleri ücretsiz olarak sunulabilir ancak bazı Hizmetleri kullanmak için parasal bir ücret talep edilebilir.\nKaggle için tipik kullanım durumları nelerdir?\nKaggle, analiz edilmesi gerektiğini düşündükleri verilere sahip işletmeler için en iyisidir. Kaggle'ın en önemli yararı, bu şirketlerin verileriyle nasıl çalışacağını bilen birini kolayca bulabilmeleridir; bu, sorunu çözmeyi, sistemlerinde neyin yanlış olduğunu bulmaya çalışmaktan çok daha kolay hale getirir.\nKaggle'daki popüler yarışmalar nelerdir?\nKaggle'da birçok farklı yarışma türü mevcuttur. Mikroskop görüntülerinde kanser hücrelerini tahmin etmekten, herhangi bir gündeki fazla mesai değişiklikleri için uydu görüntülerini analiz etmeye kadar her konuda bir yarışmaya katılabilirsiniz.\nÖrnekler şunları içerir:\nBeygir gücü ve kat edilen mesafe gibi özelliklere göre araba fiyatlarını tahmin etme\nEyaletlere göre oylama modellerini tahmin etme\nHangi ülkelerde en fazla ormansızlaşmaya sahip olduğunu görmek için uydu görüntülerini analiz etme\nKaggle yeni başlayanlar için iyi bir platform mu?\nKaggle ve tipik veri bilimi arasındaki farklılıklara rağmen, Kaggle yeni başlayanlar için harika bir öğrenme aracı olabilir. Her yarışma bağımsızdır. Veri toplamanıza gerek yoktur, bu da sizi diğer becerilere odaklanmak için serbest bırakır.\nKaggle nasıl çalışır?\nKaggle'daki her yarışmanın kendisiyle ilişkili bir veri seti ve ulaşmanız gereken bir hedefi vardır (örneğin, konut fiyatlarını tahmin edin veya kanser hücrelerini tespit edin).\nVerilere mümkün olduğunca sık erişebilir ve tahmin modelinizi oluşturabilirsiniz. Yine de çözümünüzü bir kez gönderdikten sonra, onu gelecekteki gönderimler için kullanamazsınız.\nBu, herkesin birbiriyle rekabet ederken aynı noktadan başlamasını sağlar, bu nedenle, sorunu çözmeye çalışan diğerlerinden daha fazla hesaplama gücüne sahip olanlara verilen hiçbir avantaj yoktur.\nYarışmalar, karmaşıklık düzeyine, ne kadar sürdüğüne, para ödülü olup olmamasına vb. bağlı olarak farklı kategorilere ayrılır, böylece farklı deneyim seviyelerine sahip kullanıcılar aynı arenada birbirleriyle rekabet edebilir.\nKaggle'da bir yarışmaya nasıl girilir?\nBir yarışmaya girmek için kayıt süreci çok basittir: Çoğu yarışma, yarışmacılardan her mücadelenin sonunda belirli kriterleri karşılayan kodu göndermelerini ister. Ancak, rakiplerin hangi algoritmaları kullandıklarını açıklamalarını veya işlerin nasıl yürüdüğü hakkında girdi sağlamalarını istedikleri zamanlar olabilir.\nKaggle yarışmaları nasıl para kazandırır?\nKaggle'daki birçok şirket çözüm arıyor, bu nedenle bazı yarışmalarda ödül vardır. Çözümünüz yeterince güçlüyse, çok para kazanabilirsiniz!\nBu yarışmalardan bazıları sadece eğlence veya öğrenme amaçlıdır, ancak yine de kazananları nakit veya ticari ödüllerle ödüllendirir.\nKaggle'da rekabet etmek için hangi araçları kullanmalıyım?\nRakiplerin güvendiği en önemli araç Python programlama dilidir. Tüm veri bilimcilerinin %60'ından fazlası tarafından kullanılmaktadır, bu nedenle arkasında son derece büyük bir topluluğa sahiptir. Ayrıca son derece sağlamdır ve başlamanıza yardımcı olacak veri işleme, ön işleme ve keşif için birçok farklı pakete sahiptir.\nTensorFlow, makine öğrenimi meraklılarının Kaggle yarışmalarını çözmek için kullandığı bir başka popüler araçtır. Mümkün olan en iyi sonuçları elde etmek için modellerin hızlı prototiplenmesine olanak tanır.\nPython ve Tensorflow'a ek olarak R (istatistiksel bir programlama dili), Git (sürüm kontrolü) ve Bash (komut satırı arayüzü) gibi başka araçlar da kullanılır.\nSorunları çözmek için Kaggle kullanmanın temel faydası nedir?\nKaggle, size birinci sınıf bir veri bilimcisi olmanız için gerekli araçları sağlamayı amaçlamaktadır. Size gerçek zamanlı olarak gerçek verilere erişim sağlarlar, böylece dünya çapında şirketlerin karşılaştığı sorunlara benzer sorunları çözme alıştırması yapabilirsiniz.\nKaggle, en güncel bilgilere sahip olmanız için sitelerini sürekli güncellemektedir.\nYeni başlayanlar Kaggle’dan nasıl faydalanabilir?\nKaggle, yeni başlayanlara makine öğrenimi hakkında daha fazla bilgi edinmenin bir yolunu sunar ve nerede olurlarsa olsunlar becerilerini kullanmalarına olanak tanır.\nKaggle'ı kullanmak, yeni başlayanların sektörde neler olup bittiğini görmelerine, trendleri takip etmelerine ve işler değiştikçe araçları konusunda uzman olmalarına olanak tanır.\nAyrıca, yeni başlayanlar veya belirli kavramlar hakkında tazeleme kursu isteyenler veya başlamak için yardıma ihtiyaç duyanlar için ücretsiz eğitim materyali sunar.\nKaggle'ı kullanmakla kim ilgilenir?\nHazır birçok öğretici ve veri seti ile Makine Öğrenimi meraklıları Kaggle ile çok ilgilenecektir.\nKaggle, Makine öğrenimi hakkında daha fazla bilgi edinmek, öğrendiklerini uygulamak ve diğer veri bilimcilerle rekabet etmek için mükemmel bir yerdir. Bu onların zanaatlarında daha iyi olmalarına yardımcı olacaktır.\nÇalışmalarında makine öğrenimini kullanmak isteyen veri analistleri, satış rakamlarını tahmin etme veya müşteri davranışlarını tahmin etme gibi işle ilgili görevlerin performansını iyileştirmek için araçlar seçerken Kaggle'a başvurabilir.\nEk olarak, üçüncü taraf çözümler arayan işletmeler, Kaggle'ın ihtiyaç duydukları hizmeti sunan kapsamlı şirketler listesinden yararlanabilir.\nKaggle hala popüler mi?\nKaggle, Muhteşem makine öğrenimi modelleri oluşturmak için diğer veri bilimcileriyle etkileşim kurmak, bağlantı kurmak ve işbirliği yapmak için harika bir ekosistem.\nYıllar içinde Kaggle, eğlenceli beyin egzersizlerinden para ödülleri veren ve katılımcıları sıralayan ticari yarışmalara kadar uzanan yarışmalar düzenleyerek popülerlik kazanan bir platform oldu ve günümüzde de bu popülerliğini hala sürdürmektedir.\n\n\nBu kurs herkes içindir!\n\"Kaggle - Veri Bilimi Alanında Daha İyi Bir Profil Oluşturun\" kursu herkes içindir!\nDaha önce deneyiminiz yoksa sorun değil! Bu kurs, yeni başlayanlardan profesyonellere kadar (tazeleme amaçlı) herkese öğretmek için ustalıkla tasarlanmıştır.\n\n\nBu kurs ile Ne öğreneceksin?\nBu kursta en baştan başlayıp örneklerle \"Kaggle\" ın sonuna kadar gideceğiz.\nKurs sırasında aşağıdaki konuları göreceksiniz:\n\n\nVeri Bilimi Nedir?\nVeri Biliminin Bileşenleri Nelerdir?\nVeri Bilimi İle Ne Yapmayı Amaçlıyoruz?\nVeriden Anlamlı Bilgiyi Nasıl Çıkarırız?\nVeri Biliminde Proje Süreci Nasıl İşliyor?\nGerçek Hayattan Projeler İle Kavramların Pekiştirilmesi\nGerçek Hayattan Örneklere Devam\nKurstan En İyi Şekilde Nasıl Verim Alabilirim?\nMeraklılarına Doküman Tavsiyeleri\nVeriyi Görmek Ve Okumak Nasıl Olur?\nPopülasyon Ve Örneklem\nGözlem Birimi\nDeğişken Ve Türleri\nÖlçek Türleri\nAritmetik Ortalama\nMedyan\nMod\nÇeyrekler\nMerkezi Eğilim Neden Önemlidir?\nİstatistikte Veri Desenleri\nDeğişim Aralığı\nStandart Sapma\nVaryans\nStandart Hata\nÇarpıklık\nBasıklık\nİstatistiksel Düşünce Modelleri Ve Bileşenlerinin İncelenmesi\nVerinin Belirlenmesi Ve Tanımlanması\nVerinin Düzenlenmesi Ve Planlanması\nVerinin Gösterimi\nVerinin Gösterimi – Frekans Tablosu\nVerinin Gösterimi – Histogram\nVerinin Gösterimi – Pasta Grafik\nVerinin Gösterimi – Çubuk Grafik\nVerinin Gösterimi – Çizgi Grafik\nVerinin Çözümlenmesi Ve Yorumlanması\nPython Bootcamp Tanıtım\nMeraklılarına Doküman Tavsiyeleri\nAnaconda Windows İşletim Sistemi Kurulum\nAnaconda Linux İşletim Sistemi Kurulum\nJupyter Notebook’u İnceleme\nJupyter Lab’ı İnceleme\nPython For Beginners Kodlamaya İlk Adımlar\nBuilt-in Fonksiyon\nPython Programming Lambda Fonksiyonu\nLocal Ve Global Değişkenler\nPython Bootcamp Sınıfların(Class) Özellikleri\nSınıfların Örneklemesi(Attributes)\nMachine Learning Python Örneklemlerin Özellikleri\nSınıf İçinde Fonksiyon Yazma\nMiras(Inheritance) Yapıları\n‘if’ İfadelerinin Yapısı\nListe Elemanlarına Ulaşma – İndexleme Ve Dilimleme\nBoolean Mantıksal İfadelerde İşlem Önceliği\nKaggle Nedir?\nKaggle’a Kaydolma ve Üye Giriş Prosedürleri\nKaggle Ana sayfasını Tanıma\nKaggle’da Yarışmalar\nKaggle’da Veri Setleri\nKaggle’da Kod Bölümünü İnceleme\nKaggle’da Tartışma Nedir?\nKaggle’da Kurslar\nKaggle’da Kullanıcılar Arasındaki Sıralama\nBlog Ve Dökümantasyon Bölümleri\nKaggle’da Kullanıcı Sayfası İnceleme\nKaggle İçerisindeki Hazine\nKaggle Üzerinde Notebook Yayınlama\nKaggle'da Başarıya Ulaşmak İçin Neler Yapılmalıdır?\n\n\n\n\nGüncel kursum ile kendinizi güncel tutma şansınız olacak. Ayrıca, öğrenmenizi desteklemek ve sorularınızı yanıtlamak için sürekli olarak hazır olacağımı söylemekten mutluluk duyuyorum.\n\n\nNeden bu kursu almalısınız?\nCevabımız basit: Öğretimin kalitesi.\nKaydolduğunuzda, OAK Academy'nin deneyimli geliştiricilerin uzmanlığını hissedeceksiniz.\n\n\nVideo ve Ses Üretim Kalitesi\nTüm videolarımız, size en iyi öğrenme deneyimini sağlamak için yüksek kaliteli video ve ses olarak oluşturulur/üretilir.\nBu kurs ile aşağıdakileri elde edeceksiniz:\nKursa Ömür Boyu Erişim\nSoru-Cevap bölümünde Hızlı ve Kolay Destek\nİndirilmeye Hazır Udemy Bitirme Sertifikası\nHer türlü soruyu yanıtlayarak tam destek sunuyoruz.\nÖğrenmeye hazırsanız:\n\"Veri Bilimi, Makine Öğrenimi, Kaggle için Python Programlama\nMakine Öğrenimi (Machine Learning) ve Veri Bilimi(Data Science) için Python, İstatistik, Numpy, Pandas ve Kaggle'ı öğren \" isimli,\nKursumuzda görüşürüz!",
      "target_audience": [
        "Veri bilimi ile ilgilenen ve kendini geliştirmek isteyen herkes",
        "Veri bilimi için gerekli olan NumPy ve Pandas Kütüphanesini öğrenmek isteyen",
        "Veri bilimi için programlama diline geçmeden önce veri biliminin genel mantığını anlamak isteyenler",
        "Veri bilimi alanında kariyer hedefi olanlar",
        "Python Programlamayla daha önce tanışmamış olup, sıfırdan programlama öğrenmek isteyenler.",
        "Kaggle ile Veri Bilimi, Makine Öğrenimi, Python konularında özgeçmişini geliştirmek isteyenler",
        "Python Programlama Dili ve Veri bilimi alanında kendini geliştirmek isteyenler",
        "Başka bir dilde programlama tecrübesi olup Python öğrenmek isteyenler",
        "Python'ı temel seviyeden bilip, ileri seviye Python öğrenmek isteyenler",
        "Yapay zeka, Machine Learning(Makine Öğrenmesi) ve Data Science(Veri Bilimi) ile ilgili herkes",
        "Data Science (Veri bilimi) alanında kariyer hedefi olanlar",
        "Python ile veri bilimi(data science) öğrenmek isteyen"
      ]
    },
    {
      "title": "人工知能（AI）を搭載したTwitterボットを作ろう【Seq2Seq+Attention+Colab】",
      "url": "https://www.udemy.com/course/twitter-bot/",
      "bio": "ディープラーニングを用いた自然言語処理技術を活用し、対話が可能なTwitterボットを構築するコースです。Attentionを導入したSeq2SeqのモデルをGoogle Colaboratoryで訓練し、生成された文章を自動投稿します。",
      "objectives": [
        "Seq2Seqを用いた対話モデルの構築。",
        "Attentionの導入による自然な応答文の生成。",
        "再帰型ニューラルネットワーク（RNN）の実装。",
        "Twitter APIの使い方。",
        "Twitterボットのデプロイ方法。",
        "自然言語処理の基礎。",
        "PyTorchの使い方。"
      ],
      "course_content": {
        "コースの概要とTwitter API": [
          "教材の使用方法",
          "イントロダクション",
          "コースの概要",
          "Twitter API登録",
          "Google Colaboratoryの使い方",
          "Twitter APIの使用"
        ],
        "RNNとSeq2Seq": [
          "セクション2の教材",
          "Section2の概要",
          "ニューラルネットワークとディープラーニング",
          "PyTorchの基礎",
          "再帰型ニューラルネットワーク（RNN）",
          "LSTMとGRU",
          "Seq2Seq"
        ],
        "自然言語処理の基礎": [
          "セクション3の教材",
          "Section3の概要",
          "単語の分散表現",
          "分散表現の実装",
          "テキストデータの前処理"
        ],
        "モデルの訓練": [
          "セクション4の教材",
          "Section4の概要",
          "使用する対話データ",
          "対話データの作成",
          "Seq2Seqモデルの訓練 Part1",
          "Seq2Seqモデルの訓練 Part2",
          "Seq2Seqモデルの訓練 Part3"
        ],
        "Attentionの導入": [
          "セクション5の教材",
          "本セクションの注意点（お詫び）",
          "Section5の概要",
          "過学習対策",
          "入力のパディング",
          "データの前処理",
          "Attentionの概要",
          "Attentionの導入 Part1",
          "Attentionの導入 Part2"
        ],
        "Twitterボットのデプロイ": [
          "このセクションの教材を紹介します。",
          "Section6の概要",
          "モデルの訓練",
          "チャットボットのテスト",
          "システムの概要",
          "デプロイ時の注意点",
          "Twitterボットのデプロイ Part1",
          "Twitterボットのデプロイ Part2",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "何らかのプログラミング経験があった方が望ましいです。",
        "Google Colaboratoryを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。",
        "海外のサービスを利用するので、英語に抵抗感が小さい方が望ましいです。",
        "Twitter APIを使用するために、Twitterアカウントが必要になります。",
        "Twitterに一定時間間隔で投稿する機能を実装する方は、Herokuの無料サービスを利用するためにクレジットカードの登録が必要になります（登録しなくても受講は可能です）。"
      ],
      "description": "人工知能（AI）を搭載したTwitterボットを構築するコースです。\nSeq2Seq、Attentionなどのディープラーニング技術を使ってモデルを訓練し、Twitterへの投稿や返答が可能なボットを構築します。\nまた、このために必要な基礎としてTwitter APIの使い方、ディープラーニング用フレームワークPyTorchの使い方、 基本的な自然言語処理などを学びます。\n独自の人工知能ボットを構築し、世界に公開できるようになりましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\nコースの内容は以下の通りです。\nSection1. 講座の概要とTwitter API\n→ コースの概要を把握し、Twitter APIを設定します。\nSection2. RNNとSeq2Seq\n→ ディープラーニングの関連技術、再帰型ニューラルネットワーク（RNN）とSeq2Seqを学びます。Seq2Seqは、系列(sequence)を 受け取り、別の系列へ変換するモデルで、自然言語処理でよく利用されます。文章などの入力を圧縮するencoderと、出力を展開するdecoderからなりますが、機械翻訳、文章要約、対話システムなどに応用されています。\nSection3. 自然言語処理の基礎\n→ 自然言語をニューラルネットワークで扱う方法を学びます。\nSection4. モデルの訓練\n→ Seq2Seqを使い、チャットボット用のモデルを訓練します。\nSection5. Attentionの導入\n→ Seq2SeqのモデルにAttensionという技術を導入します。Attentionは、時系列データの特定の部分に 注意を向けるように学習させていく方法で、より自然な応答文の生成を可能にします。\nSection6. Twitterボットのデプロイ\n→ 訓練したモデルをデプロイし、Twitterボットを構築します。\n\n\n本コースはディープラーニング用フレームワークとしてPyTorchを使用します。\nPyTorchはオープンソースの機械学習ライブラリで、簡潔さ、柔軟性、速度のバランスに優れているため人気が急上昇中です。\nまた、簡潔な記述が可能なため、最新の研究成果の実装によく使われています。\n\n\n開発環境にはGoogle Colabを利用するので、環境構築にはほとんど手間がかかりません。\nGPUが無料で利用できるので、コードの実行時間も短縮できます。",
      "target_audience": [
        "人工知能を使ってTwitterボットを作りたい方。",
        "独自の会話エンジンを作りたい方。",
        "人工知能を学んだけど、活かし方が分からない方。",
        "自然言語処理、特にSeq2SeqやAttentionについて学びたい方。",
        "PyTorchによる自然言語処理の実装を学びたい方。"
      ]
    },
    {
      "title": "ChatGPTとWhisperではじめるPythonローコード開発入門",
      "url": "https://www.udemy.com/course/chatgpt_whisper/",
      "bio": "動画・音声ファイルからWhisperで音声認識してChatGPTで議事録要約したと、Python Flaskでローカルに音声認識システムWebアプリを構築してみる。",
      "objectives": [
        "会議をレコーディングした動画ファイルから議事録要点メモを自動生成する方法",
        "ZOOMでレコーディングを行い、動画ファイルをローカルで作成する方法",
        "PythonからOpenAIのWhisperモジュールを利用して音声ファイルに対し音声認識を行う方法",
        "ChatGPTのAPIをPythonから利用し会議内容の要点を出力させる方法",
        "FFMPEGをPythonから利用し、動画ファイルから音声ファイルを作成する方法",
        "Python Flaskの環境構築方法",
        "Whisper_MICのデプロイ方法",
        "Python FlaskのWebアプリでAjaxリクエストを出す方法",
        "Python FlaskのWebアプリでAjaxリクエストでWhisper音声認識の結果取得を行う方法"
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "動画（.mp4）ファイルから音声（.wav）ファイル抽出": [
          "ZOOMでレコーディング",
          ".mp4から.wav抽出",
          "※補講　ZOOMで録画したMP4リソース (Gemini Proでスクリプトは生成）"
        ],
        "Whisperで音声認識": [
          "PythonからWhisperを利用して音声認識を行う"
        ],
        "ChatGPTで音声認識テキストの要点サマリを取得する": [
          "gpt-3.5-turboをpythonから呼び出し、会議の音声認識テキストから要点まとめを出力させる",
          "ChatGPTに聞いてみた、議事録作成プロンプトの改善。",
          "議事録ダウンロード",
          "議事録を英語・中国語に翻訳"
        ],
        "（上級編）音声認識システム・Webアプリを作る": [
          "Flask環境の構築",
          "ミニマムなFlaskアプリ",
          "Whisper_MICをセットアップする際の注意事項。レクチャー12でgit cloneした後にやっていただくこと。",
          "Whisper_MIC",
          "12_Flask画面パーツ",
          "Stable Diffusionでfavicon",
          "Bootstrap/Set Interval/Style",
          "Ajax request",
          "最終的に作るもの",
          "システム構成",
          "CondaBat/WhisperWeb",
          "Whisperとファイル連携",
          "仕上げ"
        ]
      },
      "requirements": [
        "Pythonの基礎文法知識",
        "Google Colaboratoryの基本的な利用方法",
        "Googleアカウント、OpenAIのAPI利用アカウントのセットアップ",
        "ローカルで動かす場合、CPUは8コア以上メモリ16GB以上積んでいるPCを推奨（もっと安いPCでも動きはします）"
      ],
      "description": "◇この講座でできるようになること\n・（中級者向け）ZOOMやTeamsなどのオンライン会議レコーディングファイルもしくは音声ファイルからの\n議事録自動作成（Colab)をPythonでモジュールとAPIの呼び出しのみ（非常に少ないコード）で行います。\n\n\n・（中～上級者向け）Python Flaskを用いてローカル環境（インターネット接続なし）で動作する本格的な音声認識システムを\n構築できます。バックエンドはOpenAIのWhisperモデルなので、認識精度はかなり高いです。\n\n\n◇この講座の構成\n動画ファイル or 音声ファイルのアップロード\n動画ファイルからの音声ファイル作成\n音声ファイルからのテキスト抽出（音声認識）\n音声認識テキストからの要点抽出（自動要約）←ChatGPT(gpt3.5/gpt4.0)にプロンプト生成してもらいました。\n要点抽出結果のダウンロード\nFlask環境の構築\nミニマムなFlaskアプリ\nWhisper_MIC\nFlask画面パーツ\nStable Diffusionでfavicon\nBootstrap\nAjax\nデモ\nシステム構成\nWhisper_MICとファイル連携\n仕上げ",
      "target_audience": [
        "ChatGPTの活用方法に興味のあるPython初級～中級者",
        "Whisperで音声認識をさせてみたいPython初級～中級者"
      ]
    },
    {
      "title": "Credit Score - Módulo 1: Regressão Logística em python",
      "url": "https://www.udemy.com/course/formacao-data-science-criacao-de-um-credit-score-com-python/",
      "bio": "Aprenda a técnica mais usada para prever inadimplência",
      "objectives": [
        "Formação Data Science: Criação de um Credit Score com Python",
        "Criação de um Credit Score com Python",
        "Regressão Logística em Python"
      ],
      "course_content": {
        "Data Understanding and Data Preparation": [
          "Motivação",
          "SetUp",
          "Preparação do DataFrame",
          "Data Understanding",
          "Data Preparation: Feature Selection - Parte 1",
          "Data Preparation: Feature Selection - Parte 2",
          "Data Preparation: Feature Selection - Parte 3",
          "Data Preparation: Feature Selection - Parte 4"
        ],
        "Modelagem e Avaliação do Modelo": [
          "Ajuste do modelo",
          "Revisão do processo",
          "Diagnóstico das features finais",
          "Modelo Final",
          "Cálculo do Score",
          "Avaliação do modelo",
          "Avaliação OOT",
          "Finalmente o deploy"
        ]
      },
      "requirements": [
        "python básico"
      ],
      "description": "Seja bem vindo!\nO credit score é um método consagrado pelo mercado para avaliar o risco de inadimplência em todo tipo de financiamento. É esta metodologia que orienta as decisões dos maiores bancos, financeiras e operadoras de cartão de crédito em todo o mundo.\n\n\nMotivos para adquirir o curso:\n1 - Conhecer o passo-a-passo de construção de um modelo de Credit Score\n2 - O curso é hands-on, em que o aluno consegue reproduzir tudo aprendido\n3 - Todo material desenvolvido no curso ficará disponível para o aluno\n4 - Curso em português\n5 - Voltado para aplicação prática\n\n\nO curso é voltado para pessoas interessadas em conhecer como os Bancos criam os modelos para discriminar o perfil de pagamento de seus clientes. Iremos aprender o passo-a-passo da técnica mais utilizada para construção de um modelo de Credit Score (Regressão Logística) utilizando Python!\nVocê irá aprender todo pipeline de construção de um modelo, desde o entendimento e preparação do dado, a seleção de variáveis e o ajuste de um modelo de regressão logística.\n\n\nDe uma forma didática e com muitos detalhes, o aluno terá acesso aos notebooks em python de todos os programas desenvolvidos!\n\n\nBasicamente, a metodologia de credit scoring consiste em reunir informações sobre o tomador de crédito e usá-las para calcular quais são as chances dele conseguir pagar o financiamento no futuro.\nO cálculo do risco de crédito envolve uma série de dados a respeito do consumidor, entre elas idade, sexo, profissão, estado civil, número de dependentes, endereço, renda, etc.\nAlém disso, entram também informações públicas, como o índice de inadimplência por região, dados do Censo, pesquisas referentes ao mercado de trabalho, etc.\nE o mais importante:\nDados relativos ao comportamento de crédito daquele consumidor.\nIsso inclui valores de débitos em aberto, existência de ação judicial, quantidade de consultas realizadas, débitos inadimplidos por empresas credoras, etc.\nO sistema de credit score usa fórmulas matemáticas e ferramentas estatísticas para processar toda essa informação, atribuindo uma pontuação (nota) para a pessoa que está pedindo um empréstimo ou abrindo um crediário no comércio.\nQuanto maior a nota, menor é o risco que esta pessoa representa para o caixa do seu negócio.",
      "target_audience": [
        "Interessados em conhecer os segredos envolvidos na construção de IA pelos bancos",
        "Interessados na criação de um Credit Score com Python"
      ]
    },
    {
      "title": "【1時間で把握】AI「超」入門講座 -プログラミング、数学無しで速習するAI-",
      "url": "https://www.udemy.com/course/ai-very-basic/",
      "bio": "AIを何から学んでいいか分からない方のためのガイド的なコースです。AIの基礎から最新の生成AIまで概要を解説します。 1時間でAI技術を幅広く学び、全体像を把握し活用のイメージを得ることができます。",
      "objectives": [
        "AI技術を幅広く学び、全体像を把握します。",
        "AI技術を活用するイメージを得ます。",
        "AI技術を学び始めるためのガイドを得ます。",
        "AIをビジネスの進化や新たなサービスの創出に活かすための基礎知識を得ます。"
      ],
      "course_content": {
        "【1時間で把握】AI「超」入門講座": [
          "教材の使用方法",
          "イントロダクション",
          "AIって何？",
          "生成AIの躍進",
          "AGIとAIの未来",
          "AIで遊ぼう！",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "プログラミングや数学の知識、経験は不要です。",
        "人工知能、機械学習の技術的な知識は不要です。",
        "2025年2月の環境で解説しています。最新の環境と異なる可能性があります。"
      ],
      "description": "『【1時間で把握】AI「超」入門講座』は、ChatGPTなどの生成AIを含むAI技術全般について、プログラミングや数学の知識がなくても素早く概要を把握することができる講座です。\nAIは今や定型業務の自動化だけでなく、複数のツールや情報源を連携させたプロジェクト管理、意思決定のサポート、新しいアイデアの提案まで行えるようになっています。\nこのような進化したAI技術は、ビジネス、起業、クリエイティブな活動など、様々な場面で既に活躍を始めています。\n本講座では、AI技術を基礎から幅広く学び、実際の活用事例を通じて業務効率化や新たな価値創出の可能性を探ります。\n1時間という短い時間ですが、AI技術の可能性を広く理解し、ビジネスの進化や新たなサービスの創出に活かすための基礎知識を提供します。",
      "target_audience": [
        "誰でも受講可能な、AI初心者向けの講座です。",
        "何からAIを学び始めていいか分からず、ガイドが欲しい方。",
        "AIの発展をキャッチアップしたい方。",
        "AIの未来に想像力を働かせたい方。"
      ]
    },
    {
      "title": "Detecção de objetos com Darknet Yolo",
      "url": "https://www.udemy.com/course/deteccao-de-objetos-com-darknet-yolo/",
      "bio": "Aprende a detectar objetos da melhor forma possível!",
      "objectives": [
        "Visão Computacional",
        "Detecção de Objetos",
        "OpenCV",
        "Python"
      ],
      "course_content": {
        "Curso Darknet YOLO": [
          "Introdução",
          "Preparação dos materiais",
          "Buildando o Darknet YOLO",
          "Usando o Darknet YOLO",
          "Usando o YOLO com Python e OpenCV"
        ],
        "Treinando uma nova classe": [
          "Coletando as imagens",
          "Criando as anotações",
          "Treinando e testando a nova classe",
          "Treinando uma nova classe"
        ]
      },
      "requirements": [
        "OpenCV",
        "Python"
      ],
      "description": "Fala galera, sejam todos bem vindos ao meu curso de Darknet Yolo, nesse curso eu vou estar ensinando como configurar, buildar e usar o OpenCV e odetector de objetos Darknet YOLO, da maneira mais fácil e prática possível, com as práticas mais modernas utilizando Python.\nDurante o curso teremos as seguintes aulas:\n01 - INTRODUÇÃO;\n02 - PREPARAÇÃO DOS MATERIAIS;\nINSTALAR VISUAL STUDIO – FERRAMENTAS DE BUILD;\nINSTALAR CUDA;\nINSTALAR CUDNN;\nINSTALAR CMAKE;\nBUILDAR/INSTALAR OPENCV;\nBAIXAR MATERIAIS DO DARKNET;\n03 – BUILDANDO O DARKNET;\nBAIXAR PROJETO DARKNET;\nCONFIGURAR PROJETO COM CMAKE;\nBUILDAR DARKNET COM VISUAL STUDIO;\n04 – USANDO O DARKNET;\nBAIXAR ARQUIVOS DE PESOS JÁ TREINADOS;\nRODAR OS TESTES DO DARKNET;\n05 – USANDO O YOLO COM PYTHON E OPENCV;\nPEGAR ARQUIVOS JÁ TREINADOS;\nINSTALAR O OPENCV NO PYTHON. PIP INSTALL PYTHON-OPENCV\nCARREGAR OS PESOS E FAZER A DETECÇÃO;\n06 – TREINANDO UMA NOVA CLASSE;\nCOLETAR AS IMAGENS PARA TREINAMENTO;\nCRIAR ARQUIVOS DE ANOTAÇÕES DO LABEL DO OBJETO;\nORGANIZAR AQUIVOS PARA TREINAMENTO;\nTREINAR REDE;\nTESTAR PESOS CRIADOS;\n07 – COLETANDO AS IMAGENS;\nCOLETANDO VÁRIAS IMAGENS COM OPENCV;\nSALVAR IMAGENS 'RAW' PARA CRIAR AS ANOTAÇÕES;\n08 – CRIANDO AS ANOTAÇÕES;\nABRINDO AS IMAGENS COM PYTHON E OPENCV;\nDESENHANDO O 'BOX' DO OBJETO;\nCRIANDO O ARQUIVO TXT DE ANOTAÇÃO COM A POSIÇÃO DA 'BOX' DO OBJETO E A CLASSE;\n09 – TREINANDO A NOVA CLASSE;\nORGANIZANDO OS DADOS PARA FAZER O TREINAMENTO.\nTREINAR A REDE;\n10 – TESTANDO A NOVA CLASSE;\nPEGAR OS ARQUIVOS DE PESOS CRIADOS;\nTESTAR ELES COM PYTHON E OPENCV;\nNos vamos aprender a usar o YOLO junto com Python e OpenCV, e também o CUDA da NVIDIA, pra gente estar usando a nossa placa de vídeo para acelerar o processamento das nossas imagens e como treinar uma nova classe a partir de fotos.\nVamos estar aprendendo desde como baixar o código fonte de cada projeto, configurar e utilizar da melhor maneira o detector de objetos YOLO.\nEntão se você quer aprender visão computacional, detecção de objetos em alta velocidade com CUDA, esse é o curso pra você!",
      "target_audience": [
        "Desenvolvedores de visão computacional"
      ]
    },
    {
      "title": "Python ile Algoritmalar (Bol Teori, Bol Kod)",
      "url": "https://www.udemy.com/course/python-ile-algoritmalar/",
      "bio": "Her Yönüyle Algoritmalar",
      "objectives": [
        "Algoritmalar",
        "Sıralama Algoritmaları",
        "Arama Algoritmaları",
        "Graflar",
        "Graf algoritmaları",
        "sıkıştırma algoritmaları",
        "şifreleme algoritmaları",
        "avl ağaçları",
        "B ve B+ Ağaçları"
      ],
      "course_content": {
        "Sıralama Algoritmaları (Sorting Algorithms)": [
          "Bubble Sort Konu Anlatımı (Teorik Anlatım)",
          "Ortam Hazırlanması (Windows)",
          "Bubble Sort Python Kodu Yazımı",
          "Selection Sort Konu Anlatımı (Teorik Anlatım)",
          "Selection Sort Python Kodu",
          "Insertion Sort Konu Anlatımı (Teorik Anlatım)",
          "Insertion Sort Python Kodu",
          "Merge Sort Konu Anlatımı (Teorik Anlatım)",
          "Merge Sort Python Kodu",
          "Sıralama Algoritmaları Örnek - (Çalışma Zamanlarını Kıyaslama)",
          "Quick Sort (Hızlı Sıralama) Algoritması Konu Anlatımı (Teorik anlatım)",
          "Quick Sort Python Kodu",
          "Heapify ve Max Heap Veri Yapısı (Yardımcı Konu)",
          "Min Heap Veri Yapısı (Yardımcı Konu)",
          "Heap Sort Python Kodu",
          "Heap Sort Konu Anlatımı (Teorik Anlatım)",
          "Sıralama Algoritmaları Örnek 2",
          "Quick Sort Iterative (Örnek için ek ders)"
        ],
        "Arama Algoritmaları (Searching Algorithms)": [
          "Linear Search (Lineer Arama Algoritması) - Kod - teori karışık",
          "Binary Search (İkili Arama Algoritması) - Teorik Anlatım",
          "Binary Search Algoritması Python Kodu (Kod Yazımı)",
          "Jump Search Algoritması Konu Anlatımı (Teorik Anlatım)",
          "Jump Search Algoritması Python Kodu"
        ],
        "Graflar": [
          "Graf Nedir? (Teorik Anlatım)",
          "Graph Yapısını Python Üzerinde İfade Etmek",
          "Graph Üzerinde İki Nokta Arasındaki Yolu Bulma",
          "Graph'daki İki Nokta Arasındaki Bütün Yolları Bulma",
          "Graph Üzerinde İki Nokta Arasındaki En kısa Yolu Bulma",
          "Şu ana Kadar Olan Kodlar (Bölüm İçin)",
          "Graf Yapısını Class Olarak İfade Etmek",
          "Graf Class'ını Geliştirelim"
        ],
        "Graf Algoritmaları": [
          "BFS Algoritması Nedir? (Teorik)",
          "BFS Algoritması Konu Anlatımı",
          "BFS Algoritması Yönlü Graf Örneği",
          "BFS Algoritması Python Kod Yazımı",
          "BFS ile En Kısa Yol Bulma (Ağırlıksız Graflarda)",
          "BFS En Kısa Yol Bunla Kod Yazımı",
          "DFS Algoritması Konu Anlatımı",
          "DFS Algoritması Yönlü Graf Örneği",
          "DFS Algoritması Python Kodu (iterative)",
          "DFS Algoritması Kod Yazımı (Recursive)"
        ],
        "Minimum Spanning Tree (Asgari Tarama Ağacı) Algoritmaları": [
          "Prim's Algoritması Örnek 1",
          "Python ile Ağırlıklı Graf Yapısı Oluşturmak",
          "Ağırlıklı Grafları Matplotlib ile görselleştirme",
          "Python Ağırlıklı Graf Kodu için basit bir menü yazımı",
          "Python ile Prim's Algoritması Uygulaması",
          "Kruskal Algoritması"
        ],
        "En Kısa Yol Bulma Algoritmaları (Shortest Path Algorithms)": [
          "Dijkstra Algoritması"
        ]
      },
      "requirements": [
        "Basit düzeyde Python Bilgisi",
        "Veri Yapıları hakkında bilgi sahibi olmak"
      ],
      "description": "Hayatımızın her alanına yön veren algoritmalar yazılımcıların en çok bilmeleri gereken konuların başında gelir. Özellikle iş hayatında, gerek uygulama alanında gerekse de mülakatlarda en çok ihtiyaç duyacağımız olgu algoritmalardır. Kursumuz dahilinde Bilgisayar mühendisliği ve yazılım mühendisliği bölümlerinde anlatılan algoritmalara yer verilmiştir.\n\nKursumuzda her konunun anlatımı ikiye bölünmüştür. Birinci parça teorik anlatımdır. Teorik anlatımın ardından python programlama dili ile kod yazımı satır satır gösterilmektedir. Doğal olarak programlama sürecinde python veri yapıları kullanılmaktadır.",
      "target_audience": [
        "Yazılım öğrenmek isteyen ve python'a ilgi duyan herkes..."
      ]
    },
    {
      "title": "Python. Gráficos interactivos con Plotly y Dash en Python",
      "url": "https://www.udemy.com/course/plotly-dash-graficos-interactivos/",
      "bio": "Plotly y Dash. Aprende a visualizar tus datos con gráficos interactivos mediante las librerías plotly y dash en Python.",
      "objectives": [
        "Aprenderás a utilizar Plotly para crear gráficos de barras, gráficos de burbujas, mapas de calor, etc",
        "Aprenderás a utilizar Dash para crear gráficos interactivos",
        "Aprenderás a crear aplicaciones web donde incluir tus gráficos interactivos",
        "Aprenderás a crear capas de presentación para tu aplicación gráfica interactiva",
        "Aprenderás a conectar multiples entradas y salidas mediante un dashboard"
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Instalación"
        ],
        "Introducción a los datos en Python": [
          "Visualización de datos en Python",
          "Numpy",
          "Pandas",
          "Ejercicio con Pandas y Numpy"
        ],
        "Plotly": [
          "Introducción a plotly",
          "Scatterplot en Plotly",
          "Gráfico lineal en Plotly",
          "Gráfico lineal con datos de un fichero CSV",
          "Gráfico de barras en Plotly",
          "Gráfico de burbujas en Plotly",
          "Ejercicio con plotly",
          "Gráficos de caja en Plotly",
          "Histogramas en Plotly",
          "Gráficos de distribución en Plotly",
          "Gráficos de mapa de calor en Plotly"
        ],
        "Dash": [
          "Introducción a Dash",
          "Textos y gráficos en Dash",
          "Estilos en Dash",
          "Incluir gráfico plotly en Dash - parte 1",
          "Incluir gráfico plotly en Dash - parte 2",
          "Incluir gráfico plotly en Dash - parte 3",
          "Componentes HTML en Dash",
          "Componentes CORE en Dash",
          "Formatear texto en Dash",
          "Ayuda sobre los componentes en Dash",
          "Callback para unir componentes en Dash",
          "Callback con 2 entradas y una salida en Dash",
          "Callback con multiples salidas en Dash",
          "Ejercicio con callback",
          "Callback con estado",
          "Actualizar capa de presentación"
        ],
        "Sección adicional": [
          "Clase extra"
        ]
      },
      "requirements": [
        "Conocimiento básico de Python"
      ],
      "description": "En este curso aprenderás a utilizar Python para crear gráficos interactivos con las librerías plotly y dash.\nAprenderás a recoger datos de ficheros CSV y visualizarlos en vistosos gráficos interactivos.\nAprenderás a crear gráficos de barras, gráficos lineales, gráficos de burbujas, mapas de calor, etc.\nTodo está explicado mediante ejemplos para facilitar el aprendizaje.\nPodrás obtener un certificado de la realización de este curso.\nTienes una garantía de devolución de 30 días, en el caso de que no quedes satisfecho con el curso.\nApúntate hoy y nos vemos en el curso!",
      "target_audience": [
        "Personas interesadas en aprender a crear gráficos en Python de forma muy sencilla",
        "Desarrolladores que quieran aprender a crear gráficos interactivos en Python"
      ]
    },
    {
      "title": "Inteligência Artificial e Machine Learning com JavaScript",
      "url": "https://www.udemy.com/course/inteligencia-artificial-e-machine-learning-com-javascript/",
      "bio": "Curso voltado para desenvolvedores",
      "objectives": [
        "Machine Learning, Deep Learning, Processamento de Linguagem Natural, Visão Computacional, Redes Neurais Artificiais, Análise Classificativa, Análise Preditiva, Leitura e Manipulação de Modelos, Plotagem de Dados e Exemplos Práticos de Inteligência Artificial com JavaScript."
      ],
      "course_content": {
        "Introdução ao Curso": [
          "01-Apresentação do Curso",
          "02-Introdução a Inteligência Artificial - Parte 1",
          "03-Introdução a Inteligência Artificial - Parte 2"
        ],
        "Rede Neural Feedforward": [
          "01-Neurônio Natural",
          "02-Neurônio Artificial",
          "03-Função Somatória",
          "04-Gradiente Descendente",
          "05-Feedforward - Parte 1",
          "06-Feedforward - Parte 2",
          "07-Chamada da Função",
          "08-Executando a Rede Neural Artificial",
          "09-Múltiplas Entradas na Rede"
        ],
        "Funções de Ativação": [
          "01-Tangente Hiperbólica",
          "02-Função Sigmóide",
          "03-Função ReLU",
          "04-Função Leaky ReLU",
          "05-Função Binary Step",
          "06-Configurando a Função - Parte 1",
          "07-Configurando a Função - Parte 2"
        ],
        "Regressão Linear Simples": [
          "01-Fórmula da Regressão Linear",
          "02-Cálculo dos Produtos",
          "03-Cálculo dos Quadrados",
          "04-Cálculo Somatório",
          "05-Cálculo da Média",
          "06-Cálculo dos Resultados",
          "07-Executando a Regressão Linear",
          "08-Regressão com Orientação a Objetos",
          "09-Modelo Pré-treinado"
        ],
        "Regressão Linear Multivariada": [
          "01-Reduzindo os Valores em Um",
          "02-Executando a Regressão Multivariada"
        ],
        "Naive Bayes Probabilístico": [
          "01-Teorema de Bayes",
          "02-Cálculos da Fórmula de Bayes",
          "03-Construindo as Funções do Teorema - Parte 1",
          "04-Construindo as Funções do Teorema - Parte 2",
          "05-Construindo as Funções do Teorema - Parte 3",
          "06-Executando o Naive Bayes",
          "07-Naive Bayes Orientado a Objetos",
          "08-Instanciando o Objeto",
          "09-Executando a Instância"
        ],
        "Naive Bayes Classificativo": [
          "01-Adaptando para Classificação"
        ],
        "K-Nearest Neighbors": [
          "01-Fórmula do K-Nearest Neighbors",
          "02-Algoritmo do KNN",
          "03-Executando a Classificação",
          "04-KNN com Orientação a Objetos",
          "05-Executando a Instância",
          "06-Classes no Formato Texto"
        ],
        "Clusterização com K-Means": [
          "01-Fórmula do K-Means",
          "02-Construindo as Funções - Parte 1",
          "03-Construindo as Funções - Parte 2",
          "04-Construindo as Funções - Parte 3",
          "05-Executando o Agrupamento",
          "06-K-Means com Orientação a Objetos"
        ],
        "Aprendizado por Reforço": [
          "01-Codificando as Funções - Parte 1",
          "02-Codificando as Funções - Parte 2",
          "03-Codificando as Funções - Parte 3",
          "04-Executando a Clusterização",
          "05-Feedback Negativo e Positivo"
        ]
      },
      "requirements": [
        "Conhecimentos básicos em JavaScript."
      ],
      "description": "Finalmente você terá um curso de Inteligência Artificial voltado para desenvolvedores e não para Cientistas de Dados. Aprenda os principais fundamentos dessa tecnologia e aplique em seus sistemas Web, Desktop e Mobile com JavaScript. Curso completo e com avanços gradativos respeitando o ritmo de aprendizado. Você aprenderá sobre as metodologias de Aprendizado de Máquina e sobre os principais algoritmos de Machine Learning. Tudo com exemplos práticos e alguns casos reais para fixar o conteúdo da maneira correta. Conheça a tecnologia mais badalada do momento e tenha esse diferencial no seu currículo, não perca mais tempo e embarque no fantástico mundo da Inteligência Artificial!\n\n\n\n\n\n\n\n\n* Introdução ao Curso de Inteligência Artificial e Machine Learning com JavaScript\nHistória da inteligência artificial, conceitos, métodos e aplicações.\n\n\n* Redes Neurais Artificiais do Tipo Feedforward (Função de Aproximação)\nNeurônio natural e neurônio artificial, função somatória, gradiente descendente com método de descida do gradiente, inputs, outputs, valores de busca, taxa de erro, épocas de treinamento, função de ativação para formatação de resultados, pesos e sinapses artificiais.\n\n\n* Funções de Ativação (Formatação)\nCálculos da tangente hiperbólica, função sigmoide com resultado na curva sigmoidal, unidade linear retificada com e sem vazamento e passo binário.\n\n\n* Regressão Linear Simples\nCálculos dos produtos de X por Y, quadrados de X, somatório de X, média de X, fórmula da regressão linear aplicada aos resultados, treinamento de máquina, predição, salvamento e carregamento de modelos pré-treinados e orientação a objetos no cálculo matemático.\n\n\n* Regressão Linear Multivariada\nRegressão linear multivariada com múltiplas entradas em uma única saída de informação.\n\n\n* Naive Bayes Probabilístico\nEliminação de elementos duplicados, retorno de classes, contagem de textos coincidentes, organização de classes e entradas em objeto JSON, cálculo de frequência, contagem de classes, somatório de classes, cálculo total individual e geral, cálculo de ocorrência, aplicação do teorema de Bayes.\n\n\n* Naive Bayes Classificativo\nAdaptação do teorema de Bayes probabilístico para cálculo classificativo.\n\n\n* K-Nearest Neighbors (KNN)\nSubtrações e quadrados dos eixos X e Y, soma dos quadrados, radiciação, treinamento e predição por grau de proximidade numérica.\n\n\n* Clusterização (Agrupamento de Dados) com K-Means\nExportação de módulo, média dos eixos de X e Y para o grupo, cálculo dos centroides para X e Y, elemento mínimo, retorno de índice, comparação de arrays, atualização de grupo, formatação dos grupos como vetores de uma matriz e agrupamento final.\n\n\n* Aprendizado por Reforço\nSalvamento e leitura dos índices dos centroides por meio de feedbacks positivos e negativos.\n\n\n* Árvore de Decisão (Decision Tree)\nConstrutor de classe, proporção das classes para um determinado valor de eixo, proporção dividida pelo total, logaritmo na base 2 de uma divisão, produto da divisão pelo logaritmo, cálculo da multiplicação atual menos a posterior, ganho de informação, cálculo de entropia e predição classificativa.\n\n\n* Rede Neural Artificial com Arquitetura Perceptron Multicamadas (Multilayer Perceptron - MLP)\nTransformando um feedforward em perceptron multicamadas com configurações de construção de rede. Bias, nós de entrada, interação e saída, atualização de pesos multiplicativos em matrizes, treinamento e execução de um multilayer perceptron.\n\n\n* Cálculos Estatísticos\nElemento mínimo e máximo, soma, média, mediana, produto, quadrado, cubo, valor absoluto, variância padrão, variância com tendência, variância sem tendência, desvio padrão, desvio com tendência, desvio sem tendência, raiz quadrada, multiplicação convencional e matricial, subtração, transposição, seleção aleatória, adição, divisão, logaritmos, logaritmo na base 2, aproximação para baixo, aproximação padrão, aproximação para cima, expressão e filtro.\n\n\n* Rede Neural Artificial (RNA) com Fórmula Fixa\nFórmula matemática para a construção de redes neurais artificiais, camada de entrada, camada oculta, camada de saída, épocas de treinamento, taxa de erro e aprendizagem, função de ativação, aleatoriedade em pesos, gradiente descendente, função sigmoidal, neurônios artificiais e sinapse artificial.\n\n\n* Manipulação de Arquivos Estruturados no Formato CSV\nConversão de CSV para objeto JSON e abjeto vetorial.\n\n\n* Aprendizado de Máquina (Machine Learning) no Front-End com Layout HTML\nÁrvore de decisão, k-nearest neighbors, naive bayes, rede neural e regressão linear no front-end com layout HTML e eventos em JavaScript.\n\n\n* Plotagem de Dados para Análise de Informações\nGráfico line, scatter, bar, pie e bubble.\n\n\n* Redes Neurais Artificiais Sofisticadas\nSofisticação em redes neurais artificiais.\n\n\n* Aprendizado Supervisionado\nAplicações de algoritmos de aprendizado supervisionado.\n\n\n* Aprendizado Autônomo\nExemplo de aprendizado autônomo no front-end por meio de clusterização.\n\n\n* Processamento de Linguagem Natural (NLP)\nProcessamento de linguagem natural para o reconhecimento de padrões em textos e caracteres. Identificação de indivíduos através da escrita e análise de sentimentos por meio de computação cognitiva com o teorema de bayes.\n\n\n* Visão Computacional\nRedes neurais convolucionais pré-treinadas para a classificação de imagens no front-end.\n\n\n* Máquina de Vetores de Suporte (Support Vector Machine)\nDefinição dos vetores de suporte, margens, hiperplano, gamma e classificação binária.\n\n\n* Regressão Logística\nCálculo regressivo para casos de classificação de dados.\n\n\n* Regressão Polinomial\nPropriedade degree para o grau da curva de melhor ajuste e aplicação do cálculo de regressão em dados com distribuição caótica e não linear.\n\n\n* Regressão Linear Multivariável (Regressão Linear Múltipla)\nReconhecimento de padrões numéricos em múltiplas entradas e múltiplas saídas.\n\n\n* Análise Classificativa de Dados com Pacotes NPM\nPacotes NPM para análise classificativa com o teorema de bayes, k-nearest neighbors e árvore de decisão.\n\n\n* Análise Regressiva de Dados com Pacote NPM\nPacote NPM para análise regressiva com regressão linear múltipla.\n\n\n* Agrupamento (Clusterização) com Pacotes NPM\nPacotes NPM para clusterização de dados com k-means.\n\n\n* Análise Preditiva (Classificação e Regressão) com Pacotes NPM para RNA\nPacotes NPM para análise classificativa e regressiva de dados com redes neurais artificiais em distribuições lineares e não lineares.\n\n\n* Redes Neurais Recorrentes (RNN)\nRedes neurais recorrentes para a análise de séries temporais. Rede neural recorrente com e sem intervalo de tempo, memória de longo e curto prazo e unidades recorrentes bloqueantes. Reconhecimento de padrão sequencial por ordenação e posicionamento de dados.\n\n\n* Deep Learning (O Aprendizado Profundo)\nRedes neurais profundas com múltiplas camadas de interação nos dados.\n\n\n* Exemplos Práticos\nCálculo salarial, precificação de imóveis, predição de cotações futuras para o dólar, bitcoin e ações da bolsa de valores.\n\n\n* Conclusão e Encerramento\nConclusão e encerramento do conteúdo das aulas.",
      "target_audience": [
        "Desenvolvedores iniciantes ou experientes que desegem aprender Inteligência Artificial com JavaScript."
      ]
    },
    {
      "title": "Prérequis MACHINE LEARNING — Python | Numpy | Mathématiques",
      "url": "https://www.udemy.com/course/prerequis-ml-dl-indispensables/",
      "bio": "Apprenez, en moins d'une journée, les concepts indispensables de Mathématiques, Python et Numpy pour le Machine Learning",
      "objectives": [
        "Les concepts essentiels de Mathématiques pour le Machine Learning",
        "Un crash course d'Algèbre Linéaire",
        "Un niveau de maitrîse avancé des listes en Python (Slicing / List-Comprehension / Multi-Level Indexing)",
        "Tour complet des fonctions indispensables de Numpy"
      ],
      "course_content": {
        "Introduction": [
          "Ce que vous devez savoir sur ce cours",
          "Révisez les Bases de Python en 10 minutes TOP-CHRONO",
          "Mise en Place de l'Environnement de Travail et Conseils pour le Cours"
        ],
        "Domptez les Listes en Python": [
          "Révisions et approfondissement des notions de bases sur les Listes en Python",
          "[INDISPENSABLE] Le Liste Slicing en Python",
          "[OPTIONNEL] Advanced Liste Slicing",
          "[INDISPENSABLE] Les List-Comprehensions en Python",
          "Guide du Multi Level Indexing en Python pour le Machine Learning"
        ],
        "Crash-Course d'Algèbre Linéaire pour le Machine Learning en Python": [
          "Introduction sur l'Algèbre Linéaire",
          "Tout ce qu'il faut savoir sur les Vecteurs + Démo Python",
          "A VOIR IMPERATIVEMENT avant de regarder la suite !",
          "Tout ce qu'il faut savoir sur les Matrices + Démo Python",
          "ZOOM sur la Mutliplication Matricielle codée à la main en Python",
          "LE CODE POUR LA MULTIPLICATION MATRICIELLE",
          "Numpy Dot Product & Performances"
        ],
        "Maitrisez Numpy -- Le couteau suisse du Machine Learning en Python": [
          "[INDISPENSABLE] Numpy Reshape -- Clairement Expliqué",
          "Numpy Broadcasting -- Découvrez le côté obscur de Numpy",
          "[INDISPENSABLE] Numpy Masking",
          "Numpy Sum -- Comprendre les arguments axis et keepdims",
          "[INDISPENSABLE] Advanced Numpy Slicing",
          "9 EXERCICES pour Perfectionner son Slicing avec Numpy"
        ],
        "Les Concepts de Mathématiques Essentiels pour Machine Learning & Deep Learning": [
          "[INDISPENSABLE] Les fonctions usuelles à connaître",
          "Fonctions à plusieurs variables + Visualisation Interactive en 3D avec Python",
          "Les Dérivées",
          "Coquille dans la vidéo précédente à la 57ème minute",
          "Statistiques Descriptives + Inégalité de Chebischev",
          "[INDISPENSABLE] La loi Normale - Tout ce qu'il faut connaître",
          "Probabilité, Bayes Rules et Démo Python"
        ],
        "BONUS": [
          "Mes conseils carrière pour percer en IA et en Data Science",
          "Continuez votre apprentissage au meilleur prix grâce à ces coupons exclusifs"
        ]
      },
      "requirements": [
        "Un niveau basique en Python (les fondamentaux de Python ne sont pas couverts dans ce cours)",
        "Être motivé·es ;)"
      ],
      "description": "L’objectif de ce cour est simple : enseigner en moins d’une journée tous les prérequis pour se lancer sans encombres dans le Machine Learning.\n\n\nAu menu, trois piliers : Python, Numpy et Mathématiques.\n\n\nPython spécifiquement pour le ML et le DL\n\n\n• Les 4 fonctions fantastiques de listes indispensables pour gagner du temps.\n• Le List-Slicing en Python n’aura plus de secrets pour vous (explications + moyens Mnémotechniques + exercices).\n• Advanced List-Slicing (au menu : Step-Slicing, Reverse Slicing, Negative Step Slicing et Slice Insert + Slice Delete).\n• Les List-Comprehension en Python  (explications pas à pas pour maîtriser ce concept ultrapratique à vie).\n• Multi-Level Indexing (mes raccourcis pour se repérer en plusieurs dimensions).\n• Matrix Multiplication avec les listes (vraiment important qu’on l’explique en code Python simple afin de bien ancrer le concept et le fonctionnement)\n\n\nNumpy (l’engin qui fait tourner Scikit-Learn, Pandas et Matplolib et a inspiré Tensorflow  (de Google) et Pytorch (de Facebook)\n\n\n• Linear Algebra avec Numpy, pourquoi Numpy est plus rapide que Python pur (+ le TP qui vous le prouvera en comparant les performances de vitesse de Numpy et de Python)\n• Broadcasting & Element Wise Operations & Conseils pour optimiser la performance (comprenez : pourquoi Numpy est indispensable au ML en Python).\n• 50 nuances de Numpy Advanced Slicing (faites ce que vous voulez de vos matrices et tenseurs pour ne plus jamais devoir aller sur Stack Overflow pour réussir à faire ce que vous voulez).\n• Les mystères de Tensor numpy.Sum et les arguments Axis & Keepdims enfin expliqués clairement (et le moyen mnémotechnique pour ne jamais oublier quel est l’axe 0 et l’axe 1).\n• Numpy Reshape Ninja (domptez la méthode reshape et le fameux -1 qui bloquent tant de débutant·es).\n\n\n\n\nMathématiques spécifiquement pour démarrer en Maths et DL\n\n\n• Algèbre Linéaire, Vecteur, Matrice, Tenseur (tous les éléments essentiels du ML et du Deep Learning).\n• Normes d’un vecteur L1 et L2 (ultra important pour les modèles de Régressions, linéaires et logistiques et pour les Réseaux de Neurones)\n• Distance Euclidienne (savoir la calculer ; important pour les KNN et les Systèmes de Recommandations).\n• Produit Scalaire (a.k.a. le dot product, connaître la formule et savoir l’implémenter.\n• Différencier Dimension Numpy et Dimension Mathématiques (pour que ce point confus devienne clair comme de l’eau de roche).\n• Multiplication Matricielle (tout pour maîtriser l’opération la plus importante du Deep Learning, expliqué algorithmiquement).\n• Probabilités & Bayes Rules (comprendre la Bayes Rules et savoir la retrouver de tête ; indispensable pour le ML).\n• Comprendre la corrélation (interpréter numériquement et visuellement).\n• Fonctions Usuelles (dont exponentielle et logarithme) avec visualisation interactive d’une surface en 3D avec Python.\n• Concept de Dérivées (expliqué simplement, juste ce qu’il faut pour pouvoir comprendre le Deep Learning et la descente de Gradient).\n• Tout ce qu’il faut savoir de la loi Normale (Gaussienne).\n• Les Statistiques Descriptives et comment les comprendre intuitivement (indispensable, car on les utilise à chaque début de projet ML et Data Science en Python).\n\n\nLe but n’est pas de faire de vous des expert·es en Python, Maths et Numpy. Le but est de vous donner les armes nécessaires pour progresser dans votre carrière en ML sans confusion et sans douter de vous.\n\n\nAprès ce cours, vous pourrez continuer à apprendre les concepts dont vous aurez besoin quand vous les rencontrerez car vous aurez déjà acquis les concepts clefs pour démarrer.\n\n\nPlus besoin de faire 6 semestres de cours de Mathématiques à l’université, une journée suffit.\nPlus besoin de bloquer quand on rencontre un message d’erreur qui parle de shape, de broadcast, de slice ou de dimension.\nPlus besoin de passer 2 heures à trouver comment manipuler votre liste pour obtenir le résultat que vous voulez.\n\n\nATTENTION, ce cours parle de Machine Learning et de Deep Learning avec Python mais n’est pas un cours de ML ou DL.\nEgalement bon à savoir, ce cours n’inclus pas :\n• Eigenvalues & Eigenvectors & SVD ;\n• De méthodologie Machine Learning ou Deep Learning à proprement parler ;\n• Ce n’est pas un cours PYTHON, vous devez connaître les fondamentaux de Python (listes, boucles, if, fonctions, a minima).\n\n\nSi vous connaissez tout ce que j’ai listé plus haut, ce qui peut être considéré comme les “bases des bases”, alors je tiens à vous dire que vous avez tout ce qu’il faut pour réussir. Ayez confiance en vous !\n\n\nSi des points aiguisent votre curiosité ou vous sont peu ou pas connus, alors ce cours est fait pour vous !",
      "target_audience": [
        "Parfait si l'on souhaite faire carrière dans les sciences de données."
      ]
    },
    {
      "title": "Deployment of Machine Learning Models",
      "url": "https://www.udemy.com/course/deployment-of-machine-learning-models-l/",
      "bio": "Deployment of Machine Learning Models",
      "objectives": [
        "Define and understand the different deployment scenarios, being it Edge or Server deployment",
        "Understand the constraints on each deployment scenario",
        "Be able to choose the scenario suitable to your practical case and put the proper system architecture for it",
        "Deploy ML models into Edge and Mobile devices using TLite tools",
        "Deploy ML models into Browsers using TFJS",
        "Define the different model serving qualities and understand their settings for production-level systems",
        "Define the landscape of model serving options and be able to choose the proper one based on the needed qualities",
        "Build a server model that uses Cloud APIs like TFHub, Torchhub or TF-API and customize it on custom data, or even build it from scratch",
        "Serve a model using Flask, Django or TFServing, using custom infrastructure or in the Cloud like AWS EC2 and using Docker containers",
        "Convert different models built in any framework to a common runtime format using ONNX",
        "Understand the full ML development cycle and phases",
        "Be able to define MLOps, model drift and monitoring"
      ],
      "course_content": {
        "Introduction": [
          "Deployment course intro",
          "Course contents and overview",
          "Deployment pipeline",
          "Deployment constraints",
          "Deployment scenarios"
        ],
        "Device Deployment": [
          "Model compression overview",
          "Pruning",
          "Distillation",
          "Quantization",
          "Compression pipelines",
          "Convolution Factorization",
          "1x1 Convolution",
          "Depth-wise separable convolution",
          "Group convolution and 1x1 group convolution",
          "ConDenseNet",
          "ResNet, ResNext and 1x1 skip connections",
          "InceptionNet and 1x1 bottleneck",
          "SqueezeNet",
          "MobileNet v1",
          "ShuffleNet",
          "MobileNet v2",
          "Cheat Sheet: Optimized pre-trained models vs Convolution types",
          "NASNet",
          "MobileNet v3",
          "EfficientNet",
          "TFLite overview and converter process",
          "Rasperry Pi",
          "TFLite + Rasperry Pi",
          "Intel Movidius",
          "TFLite + Android",
          "Android Image Classification App on Static images",
          "Android Image Classification App on Camera Feed",
          "Android Object Detection App on Camera feed",
          "Browser based deployment using TFJS",
          "Device deployment wrap up"
        ],
        "Server Deployment": [
          "Client server overview and model options",
          "Cloud based deployment and TFHub",
          "Object detection use case with TF-API Blackbox Model Garden",
          "TF-API Whitebox scenario: Fine tune on custom data for Masks Detection",
          "TF-API From scratch whitebox Yolov5 and DETR on SF Street Signs Detection",
          "Serving qualities",
          "Serving landscape",
          "Flask",
          "Django on AWS EC2",
          "TFServing Native Deployment",
          "Docker",
          "TFServing + Docker Deployment"
        ],
        "Wrap-up": [
          "ONNX",
          "MLOPs",
          "Conclusion"
        ],
        "Material": [
          "Slides"
        ]
      },
      "requirements": [
        "Machine Learning Basics, including model building process",
        "Deep learning basics and neural networks training process",
        "Computer vision basics, including ConvNets, transfer learning and pre-trained models architectures"
      ],
      "description": "This course is for AI and ML Engineers, Practitioners and Researchers who already built an awesome Deep Learning model, and they have a great idea for an app. But they discovered that it is not straight forward to deploy their model in a production App. Another example, say you want to build a robot that uses the Camera sensor to perceive the surrounding environment, build a map of it and eventually navigate it. Here also you discover that you still have a long Journey to go after your model is already performing great on your training machine. Finally, Software Engineers, who have their primary job is to build a working system or an app, often find themselves in a situation where they need to integrate an AI model in their software, which happens a lot today with the expansion of AI applications. They might get this model from a research team in their firm or company, or even use an API or pre-trained model on the internet to do their task.\nWe cover all those deployment scenarios, covering the journey from working trained model to an optimized deployed model. Our focus will be on CV deployment mainly. We cover Mobile deployment like on Android devices, Edge deployment on Embedded boards like Rasperry Pi, and Browser deployment where your AI model is running in the browser like Chrome, Edge, Safari or any other browser. Also, we cover server deployment scenarios, which are often found in highly scalable apps and systems with millions of users, and also in industrial scenarios like AI visual inspection in factories.\nWhile the course is mostly practical, focusing on “How” things are done and the best way of doing it, we cover also some theoretical parts about the “what” and “why” those techniques are used.\nThis requires sometimes to understand new types of convolution operations that are optimized for speed and memory, or understanding some model compression techniques that makes them suitable for Embedded and Edge deployments, which was not in scope during building the initial model that was already performing great.",
      "target_audience": [
        "Software Engineers",
        "Data Scientists",
        "Computer Vision Engineers",
        "Machine Learning Engineers"
      ]
    },
    {
      "title": "強化学習: ＡＩでブロック崩しを学習させよう。Advantage Actor-Critic（A2C）で学ぶ応用編",
      "url": "https://www.udemy.com/course/advantage-actor-critic/",
      "bio": "Actor-Criticをゲームで学ぶ強化学習コースを体験してみよう。",
      "objectives": [
        "Actor-Critic によるデュアルネットワークの仕組み（AlphaZeroネットワーク）",
        "同期分散処理アルゴリズム",
        "A2Cによるブロック崩しの学習のさせ方",
        "強化学習の応用",
        "方策勾配法等"
      ],
      "course_content": {
        "コースの紹介": [
          "紹介"
        ],
        "強化学習のおさらい_基本用語": [
          "強化学習のおさらい_基本用語：概要",
          "強化学習のおさらい_基本用語1",
          "強化学習のおさらい_基本用語2",
          "強化学習のおさらい_基本用語3"
        ],
        "強化学習のおさらい_アルゴリズム": [
          "強化学習のおさらい_アルゴリズム_概要",
          "動的計画法1_MDP",
          "30-20_動的計画法2_例",
          "動的計画法3_例MDP",
          "MonteCarlo",
          "TD学習-TD誤差",
          "Sarsa",
          "Q学習",
          "Deep Q Network",
          "方策勾配法",
          "Reinforce"
        ],
        "A2C": [
          "A2C_概要",
          "Actor-Critic",
          "Baselines",
          "Advantage",
          "A3C",
          "A2C",
          "A2Cの損失関数_方策損失",
          "A2Cの損失関数_AdvantageとEntropy",
          "A2Cの損失関数_損失関数の内訳"
        ],
        "Spots_Story": [
          "Sampling サンプリング",
          "Reflect 反映",
          "MonteCarlo モンテカルロ法",
          "True state value 真の状態価値",
          "Exlore 探索",
          "Entropy エントロピー",
          "Advantage アドバンテージ",
          "Loss 損失"
        ],
        "環境の準備": [
          "環境の準備"
        ],
        "ブロックくずしの学習": [
          "ブロック崩しの学習：概要",
          "プログラムの構造",
          "初期設定",
          "学習済みモデル",
          "モデルの設定1",
          "モデルの設定2",
          "モデルの設定3",
          "モデルの設定4",
          "モデルの設定5",
          "モデルの設定6",
          "Sampling",
          "サンプリングのイメージ",
          "Reflect",
          "True_State_Value",
          "割引報酬和のイメージ",
          "calctate1_Inference",
          "calcrate2_Advantage",
          "calctate3_Entropy",
          "更新",
          "テストPlay",
          "実行1_GrobalSettings",
          "実行2_HyperParameters",
          "実行3_Instance",
          "実行4_train",
          "学習結果",
          "自分で学習させた後のブロック崩しの画面をQ＆Aに貼り付けてみましょう"
        ],
        "補足：テトリス学習の難しさ": [
          "テトリスの歴史",
          "テトリスの例",
          "テトリスの学習モデル",
          "AlphaGoについて"
        ]
      },
      "requirements": [
        "Udemyで強化学習に関するコースを受講された方。",
        "ディープラーニングについての簡単な知識があることが前提となります。",
        "Googleアカウントの取得"
      ],
      "description": "強化学習アルゴリズム Advantage Actor-Critic（A2C）を使って、ブロック崩しゲームを経験ゼロの状態から自動で学習させていく方法を紹介します。Advantage Actor-Critic のネットワークモデルは、AlphaGo Zero でも使われているもので方策と価値と同時に学習できます。更に「同期処理」という方法からGPUを効率的に利用でき、数日かかっていた学習うが数時間でできるようになっています。ネットワークモデルの部分は、続編のAlphaGo Zeroのコースの基礎となりますので受講しておくようにしましょう。\nまた漫画Spot's storyで、A2Cの学習の流れを分かりやすく解説しています。わからなくなったときは数式やプログラムと一緒に見比べてみましょう。\n\n\nモデルの学習時間：30分～数時間\n保存データの読み込みから再生まで1分程度と、時間がかかりません。\nGoogle Colab 上で実行しますので、様々なツールの用意は不要です。またお使いのパソコンの環境に依存しません。\nPythonコードとPyTorchフレームワークの教材で実行できます。ChatGPTの強化学習でも利用されている考え方で、データサイエンス・ＡＩ学習中の方にもお薦めです。",
      "target_audience": [
        "強化学習に興味のある方",
        "ブロック崩しＡＩに挑戦したが動作できなかった方",
        "DQN(Deep-Q-Network)の次を目指したい方",
        "強化学習でGPUを有効活用したい方"
      ]
    },
    {
      "title": "아빠가 들려주는 [엑셀 데이터 시각화] 따라하기",
      "url": "https://www.udemy.com/course/ez-excel-chart/",
      "bio": "엑셀의 새로운 발견",
      "objectives": [
        "엑셀을 이용해서 데이터를 차트로 만드는 법"
      ],
      "course_content": {
        "기본 막대 차트": [
          "1. 기본 차트 만들기",
          "2. 기본 차트 편집하기(1)",
          "3. 기본차트 편집하기 (2)",
          "4. (특집) 다양한 메뉴의 특성",
          "5. 축 꾸미기",
          "(특강) 만들어진 차트를 한글, 워드에 삽입하는 방법"
        ],
        "막대차트의 응용": [
          "6. 막대 차트의 변형들",
          "7. 추석 음식 칼로리",
          "8. 서열변수로 처치 전후 비교하기"
        ],
        "Line Chart_꺽은선형 차트": [
          "9. Line Chart_꺽은선형",
          "막대차트와 꺽은선형 차트에 오차막대 넣기",
          "10. dumbbell plot",
          "11. lolli pop chart",
          "12. Bar and Area Chart_OECD 물가비교",
          "13. Pie Chart Doughnut Chart_원형과 도넛형"
        ],
        "Scatter Plot_분산형 차트 산점도": [
          "14. Scatter Plot_분산형",
          "15. Scatter Plot_분산형",
          "16. Scatter Plot_분산형",
          "17. spaghetti plot 한국 미세 먼지",
          "18. Dot plot, Jitter plot_점도표",
          "19A. Bubble Chart_거품형",
          "19B. Bubble Chart_거품형",
          "20. Pie Chart, Doughnut Chart 원차트 도넛차트"
        ],
        "추가적으로 꼭 알아두면 좋은 것들": [
          "21. Chart in Powerpoint",
          "22. Chart to Picture_차트를 그림으로 전환",
          "24. Treemap and Sunburst",
          "25. Histogram and Pareto Chart_히스토그램과 파레토 차트",
          "26. box plot",
          "28. Data Bars_데이터 막대",
          "27. heat map_색조",
          "29. Waffle chart 점 막대 차트",
          "30. Population Pyramid 인구 피라미드",
          "31. LIkert chart Butterfly (tornado) plot",
          "32. Data Combination과 서식 파일",
          "33. 한국 지도",
          "(종합) Line Chart_꺽은선형 연습",
          "(종합) 홈페이지에서 배우기"
        ]
      },
      "requirements": [
        "엑셀 가끔 사용한다.",
        "차트를 쉽고 빨리 만들고 싶다.",
        "눈에 끌리는 차트를 만들고 싶다."
      ],
      "description": "오랜 친구였던 엑셀을 이용해서\n놀라운 데이터 시각화의 기술을 배웁니다.\n클릭 몇 번 따라 하다 보면, 자신도 모르는 사이에 훌륭한 차트가 완성되어 있습니다.\n차트를 만들고 프레젠테이션하고 저장하는 실제적인 방법을 배웁니다.\n여러분의 데이터를 시각화 하는 즐거움을 느끼게 될 것입니다.",
      "target_audience": [
        "엑셀 가끔 사용하는 연구자, 학생, 직장인",
        "멋있는 차트를 만들고 싶은 사람",
        "우연히 차트를 만들고 자신이 한 것이 무엇인지 알고 싶은 사람 (이런 사람 생각보다 많음)"
      ]
    },
    {
      "title": "Introducción a SAP - INTENSIVO ESPAÑOL!",
      "url": "https://www.udemy.com/course/intro-sap-intensivo/",
      "bio": "Conoce el ERP más utilizado y más completo!",
      "objectives": [
        "Conocerás SAP, qué es, para qué sirve, por qué es tan popular?",
        "Evolución de la herramienta y sus ventajas actuales",
        "Conceptos básicos de estructura y sus datos",
        "Interfaz básica, comienza a usar tu sistema SAP"
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Historia de SAP",
          "Introducción a Módulos y Versiones de SAP",
          "Nota Importante: Udemy",
          "Conceptos preliminares"
        ],
        "Conceptos Preliminares": [
          "Conoce ERP, SAP, ABAP y Arquitectura cliente-servidor",
          "Módulos de SAP",
          "Conceptos prácticos"
        ],
        "Interacción en SAP": [
          "Acceso a SAP",
          "Interfaz de SAP",
          "Navegamos por SAP",
          "Ayudas en SAP",
          "Interacción Básica"
        ],
        "Estructura, entidades y transacciones": [
          "Estructura organizativa",
          "Concepto Datos Maestros",
          "Explorando Datos Maestros",
          "Concepto Datos Transaccionales",
          "Explorando Datos Transaccionales"
        ],
        "Clase Extra!": [
          "Clase Extra!"
        ]
      },
      "requirements": [
        "No necesitas conocer la herramienta!"
      ],
      "description": "En este curso verás una introducción a SAP desde CERO!\nEl ERP más popular y usado entre empresas multinacionales, entidades gubernamentales y más!\nQué es? Por qué es tan popular? Qué módulos se usan? Qué es ABAP?\nAl terminar, sabrás todo eso y aprenderás los conceptos más importante y comprenderás por qué es el más usado a nivel mundial entre compañías líderes.\n\n\nEn este curso verás:\n- Qué es ERP? Cómo funciona y por qué es tan usado?\n- Origen y Evolución de SAP\n- La necesidad de SAP y su evolución\n- Versiones de SAP, repaso\n- Módulos más usados\n- Interfaz inicial\n- Navegación en SAP GUI\n- Conceptos organizativos y de estructura de SAP\n- Conceptos de Datos Maestros\n- Conceptos de Datos Transaccionales\n\n\nTe mostraré en la práctica usos de:\n\n\nSAP Logon, Inicio de sesión en sistema/s SAP\nPantalla principal, pantalla inicial de SAP GUI\nInterfaz de SAP GUI, pantalla inicial y comprensión de uso\nNavegación a través de transacciones\nFavoritos y manejo de los mismos\nUso de las ayudas de SAP, consultar en a herramienta y en web\nNavegación de Datos Maestros\nNavegación de Datos Transaccionales\n\n\nEstos ejemplos son parte de la práctica habitual en una posición que se desempeña con SAP (más allá del módulo específico).\nAdemás para algunos conceptos verás la descripción teórica y luego su uso en la práctica\n\n\nÉxitos y concentración para este curso!\nInstructor: Adrian Javier Taguico - Business Intelligence Developer",
      "target_audience": [
        "Analistas de Negocio",
        "Desarrolladores de Negocio",
        "Administración de Empresas",
        "Estudiantes de sistemas",
        "Gerentes de gestión y administración"
      ]
    },
    {
      "title": "【한글자막】 Machine Learning 라이브러리 수학적 기초",
      "url": "https://www.udemy.com/course/best-ml-math/",
      "bio": "머신러닝에 필요한 라이브러리의 수학개념들을 이해하고 모델링 설정과 더 강한 솔루션을 개발할 수 있도록 필수 선형대수와 NumPy, TensorFlow, PyTorch를 활용한 미적분 실습을 진행합니다",
      "objectives": [
        "모든 Machin Learning 및 Data Sciencedml 기초가 되는 중요한 수학 과목인 선형 대수와 미적분학의 기초 이해",
        "가장 중요한 세 가지 세 가지 Python 텐서 라이브러리인 NumPy, TensorFlow 및 PyTorch를 모두 사용하여 텐서를 조작합니다.",
        "머신러닝과 데이터 사이언스에 필수적인 벡터와 행렬 계산을 활용하는 방법",
        "고유벡터, SVD, PCA를 활용하여 복잡한 데이터의 차원을 가장 유익한 요소로 축소하는 방법",
        "심화 기술 (예, 유사역행렬) 및 기본 기술 (소거법)를 활용한 미지수에 대한 해결",
        "파이썬의 interactive code 데모를 통해 미적분 원리의 상세 이해",
        "연쇄 법칙과 같은 심화 미분 법칙 상세 이해",
        "머신러닝 비용 함수의 편도함수를 TensorFlow와 PyTorch를 이용하여 뿐만 아니라 직접 계산",
        "그래디언트에 대한 정확한 이해와 경사하강법을 통해 ML 실행에 있어서 이의 필수성을 이해",
        "주어진 곡선의 하위면적을 계산하기 위한 적분의 활용",
        "최신 머신러닝 논문 세부 내용을 더 상세하게 이해할 수 있게 됨",
        "딥러닝에 사용되는 것을 포함하여, 머신러닝 알고리즘의 원리에 대한 이해"
      ],
      "course_content": {
        "선형대수를 위한 데이터 구조": [
          "소개",
          "선형대수란?",
          "선형방정식 시스템 plot 그리기",
          "선형대수 연습문제",
          "텐서",
          "스칼라",
          "벡터와 벡터의 전치",
          "노름 벡터와 단위 벡터",
          "기저, 직교, 정규직교 벡터",
          "행렬 텐서",
          "일반적인 텐서 표기법",
          "대수 데이터 구조 연습문제"
        ],
        "텐서 계산": [
          "부분 소개",
          "텐서의 전치",
          "아마다르 곱을 포함한 기초 텐서 연산",
          "텐서 리덕션",
          "내적",
          "텐서 계산 연습문제",
          "대입을 통한 선형계 해법",
          "소거법을 통한 선형계 해법",
          "선형계 시각화"
        ],
        "행렬성질": [
          "부분 소개",
          "Frobenius의 일반적인 기준",
          "행렬곱",
          "대칭 및 단위 행렬",
          "행렬 곱 연습문제",
          "역행렬",
          "대각행렬",
          "직교행렬",
          "직교행렬 연습문제"
        ],
        "고유벡터와 고유값": [
          "부분 소개",
          "행렬 적용하기",
          "아핀변환",
          "고유벡터와 고유값",
          "행렬 판별식",
          "더 큰 행렬의 판별식",
          "판별식 연습문제",
          "판별식과 고유값",
          "고유값 분해",
          "고유벡터와 고유값 활용"
        ],
        "머신러닝을 위한 행렬 계산": [
          "부분 소개",
          "특이값 분해",
          "SVD를 통한 데이터 압축",
          "무어-펜로즈 유사역행렬",
          "유사역행렬을 활용한 회귀",
          "대각합 연산",
          "주성분 분석 (PCA)",
          "선형대수 심화 학습자료"
        ],
        "극한값": [
          "부분 소개",
          "미분 들어가기",
          "적분 들어가기",
          "소진법",
          "무한소의 계산",
          "미적분 적용",
          "극한값 계산",
          "극한값 연습문제"
        ],
        "도함수와 미분": [
          "부분 소개",
          "델타 논법",
          "극한값으로부터의 미분",
          "미분 표기법",
          "상수의 미분",
          "제곱수 법칙",
          "상수 곱 법칙",
          "합의 법칙",
          "미분 법칙 연습문제",
          "곱의 법칙",
          "몫 규칙",
          "연쇄 법칙",
          "미분 법칙 심화 연습문제",
          "Function Chain에서의 제곱수 법칙"
        ],
        "자동미분": [
          "부분 소개",
          "자동 미분이란?",
          "PyTorch를 활용한 자동미분",
          "TensorFlow를 활용한 자동미분",
          "텐서 그래프의 직선 방정식",
          "자동미분을 활용한 머신러닝"
        ],
        "편도함수 계산": [
          "부분 소개",
          "편도함수란 무엇인가?",
          "편도함수 연습문제",
          "자동미분을 활용한 편도함수 계산",
          "편도함수 심화학습",
          "편도함수 심화 연습문제",
          "편도함수 표기법",
          "편도함수를 위한 연쇄 법칙",
          "다변수 연쇄 법칙 연습문제",
          "회귀 Point-by-Point 학습",
          "이차 비용 함수의 그래디언트",
          "비용함수의 그래디언트 하강",
          "평균제곱오차의 그래디언트",
          "역전파",
          "고차 편도함수",
          "고차 편도함수 연습문제"
        ],
        "적분계산": [
          "부분 소개",
          "이진 분류",
          "오차 행렬",
          "ROC 곡선",
          "적분이란 무엇인가",
          "적분 법칙",
          "부정적분 연습문제",
          "정적분",
          "파이썬을 활용한 수치적분",
          "정적분 연습문제",
          "ROC 곡선의 하위면적 (AUC) 구하기",
          "미적분 심화 학습자료",
          "축하합니다!"
        ]
      },
      "requirements": [
        "파이썬이나 그에 준하는 객체 지향 프로그래밍 언어 지식 (모든 코드 시연은 파이썬으로 이루어집니다)",
        "중학교 수준의 수학 지식 (수량적 정보 다루기, 차트 이해, 간단한 방정식 재배열)"
      ],
      "description": "데이터 사이언스가 되기 위한 필수 수학 지식!\n선형대수, 텐서 계산, 행렬 성질, 극한 등 선형대수와 미적분학에서 필요한 수학 개념만 쏙쏙 골라 듣는 강의!\n머신러닝 알고리즘과 데이터 사이언스 모델 속 수학 개념!\n차트를 이해하고 간단한 방정식 문제를 해결(중학교 수준)할 수 있는 수준이라면 누구나 따라올 수 있습니다!\n많은 실습과제와 파이썬 코드, 연습문제 포함\n\n\n머신 러닝(Machine Learning)을 공부하는데 있어 이 수학 강의가 꼭 필요한 이유\nScikit-learn과 Keras와 같은 높은 수준의 라이브러리 덕분에 데이터 사이언스를 처음 배우는 것은 어렵지 않습니다.\n그러나 이 라이브러리들의 수학적 알고리즘을 이해하는 것은 여러분에게 무한한 가능성을 열어줍니다.\n딥러닝의 대가이신 Jon Krohn 박사님이 진행하는 이 수업은, 머신러닝 알고리즘과 데이터 사이언스 모델 속 수학 개념(선형대수와 미적분학)에 대한 정확한 이해를 다룹니다.\n이 강의를 통해 처음 배우거나 잊어버린 수학 개념을 되살리는데 많은 도움을 받을 수 있습니다.\n또한, 강의에서 가장 중요한 Python 텐서 라이브러리인 NumPy, TensorFlow, PyTorch를 모두 사용하여 텐서를 조작합니다.\n\n\n머신 러닝 전문가가 되기 위해 이 강의에서 배울 수학 지식\n1. 선형대수 데이터 구조\n2. 텐서 계산\n3. 행렬 성질\n4. 고유벡터와 고유값\n5. 머신러닝을 위한 행렬 계산\n6. 극한값\n7. 도함수와 미분\n8. 자동 미분\n9. 편도함수 계산\n10. 적분 계산\n\n\n수석 데이터 과학자이자 1위 베스트셀러 작가 Dr Jon Krohn과 Ligency Team이 전하는 한 마디\n한국 수강생 여러분들 안녕하세요?\n\n\n수학은 데이터 사이언스와 머신러닝의 핵심입니다. 따라서, 데이터 사이언스의 최고 전문가가 되기 위해서는, 대부분의 관련된 수학에 대한 전반적인 이해가 반드시 필요합니다.\n모델링 설정부터 새롭고 더 강한 솔루션을 개발하는 것까지, 이 모든 이면에 있는 수학을 이해하는 것은 여러분의 커리어에 극적인 영향을 끼칠 수 있습니다.\n\n\n중학교 수학 수준의 차트를 이해하고 간단한 방정식을 재배열하는 것들이 가능하다면 여러분은 이 강의의 모든 수학 과목을 따라올 모든 준비가 되어 있습니다.\n모든 코드 시연은 파이썬으로 이루어지니 해당 언어로 학습하거나, 혹은 실습 예제와 함께 다른 객체 지향 프로그래밍 언어를 사용하는 것도 도움이 될 것입니다.\n\n\n각 강의에 걸쳐서, 여러분들에게 수많은 실습 과제, 파이썬 코드 실현, 그리고 당신의 수학 실력을 업그레이드 시켜 줄 실용적인 연습문제들이 주어집니다.\n\n\n그렇다면, 최고의 데이터 과학자로 거듭나실 준비가 되셨습니까? 곧 강의에서 만나도록 합시다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n- Ligency Team",
      "target_audience": [
        "머신러닝 알고리즘 교육 및 활용을 위해 높은 수준의 소프트웨어 라이브러리 (예를 들어, scikit-learn, Keras, TensorFlow)를 사용 중이며, 능력을 더 키우기 위해 기초에 대한 이해를 넓히고 싶으신 분",
        "머신러닝 알고리즘을 생산 시스템으로 활용하기 위해 탄탄한 기초를 다지고 싶으신 소프트웨어 개발자",
        "해당 과목에 대한 이해를 넓혀 이를 전문 영역으로 확장하고 싶으신 데이터 과학자",
        "데이터 분석가 혹은 데이터 과학자나 데이터/ML 엔지니어를 꿈꾸는 A.I. 열정가이며, 완전 기초부터 철저히 이 분야에 대한 깊은 이해를 다지고 싶으신 분 (매우 현명한 선택입니다!)"
      ]
    },
    {
      "title": "Apprendre la Data Science et Machine Learning en Python",
      "url": "https://www.udemy.com/course/data-science-et-machine-learning-en-python/",
      "bio": "Data science, Numpy, Pandas, Matplotlib, Seaborn, SciKit Learn, Apprentissage supervisé, Apprentissage non supervisé",
      "objectives": [
        "Utilisez Python pour la science des données et l’apprentissage automatique",
        "Apprendre à utiliser NumPy pour les données numériques",
        "Apprendre à utiliser Pandas pour l’analyse des données",
        "Apprendre à utiliser Matplotlib pour la visualisation des données",
        "Apprendre à utiliser Seaborn pour les graphiques statistiques",
        "Apprentissage supervisé et non supervisé",
        "Mettre en œuvre des algorithmes d’apprentissage automatique (Machine learning)",
        "Utiliser SciKit-Learn pour les tâches d’apprentissage automatique",
        "Régression linéaire",
        "Régression logistique",
        "K Voisins les plus proches",
        "Arbres de décision",
        "Arbres de forêts aléatoires",
        "K-Mean clustering",
        "Analyse en composantes principales"
      ],
      "course_content": {},
      "requirements": [
        "Une certaine expérience en programmation Python. Mais ne vous inquiétez pas, ce cours vous propose aussi une formation complète en Python."
      ],
      "description": "Formation Complète Data Science et Machine Learning avec Python\nDevenez Data Scientist et Maîtrisez l’Apprentissage Automatique avec Python\nÊtes-vous prêt à acquérir les compétences les plus recherchées dans la tech et l’analyse de données ? Cette formation complète en Data Science et Machine Learning avec Python vous guidera pas à pas, même si vous partez de zéro, pour devenir un expert capable de transformer des données en décisions stratégiques.\nPourquoi choisir cette formation ?\nLe métier de Data Scientist figure parmi les plus demandés et les mieux rémunérés. Grâce à cette formation unique, vous apprendrez à :\nAnalyser et manipuler des données complexes avec Python.\nCréer des visualisations impactantes et interactives.\nDévelopper et entraîner des modèles prédictifs avancés.\nMaîtriser les principales bibliothèques Python en Data Science.\nUn programme complet et progressif\nAvec plus de 100 vidéos HD, des notebooks Jupyter détaillés, des exemples concrets et des exercices pratiques, vous progresserez étape par étape jusqu’à devenir autonome.\nVoici un aperçu de ce que vous allez maîtriser :\nProgrammation et traitement des données\nProgrammation avec Python orienté Data Science\nManipulation des tableaux numériques avec NumPy\nGestion et analyse de données tabulaires avec Pandas\nLecture et traitement des fichiers CSV et Excel\nVisualisation de données\nCréation de graphiques professionnels avec Matplotlib\nAnalyse exploratoire et visualisations avancées avec Seaborn\nMachine Learning supervisé et non supervisé avec Scikit-Learn\nRégression linéaire et régression logistique\nAlgorithmes de classification : K-Nearest Neighbors, Arbres de décision, Forêts aléatoires\nMéthodes de clustering : K-Means\nRéduction de dimensions avec l’Analyse en Composantes Principales (PCA)\nÉvaluation et optimisation des modèles\nProjets pratiques et cas concrets\nTout au long de la formation, vous mettrez en pratique vos compétences sur des projets réels, afin de consolider votre apprentissage et enrichir votre portfolio professionnel.\nÀ qui s’adresse cette formation ?\nCette formation est conçue pour :\nLes débutants motivés qui veulent entrer dans le domaine de la Data Science.\nLes développeurs Python souhaitant apprendre l’analyse de données et le Machine Learning.\nLes professionnels souhaitant évoluer vers des métiers de Data Analyst ou Data Scientist.\nCe que vous allez obtenir :\nAccès illimité et à vie à tous les modules et futures mises à jour.\nDes supports de cours téléchargeables et réutilisables.\nDes certificats de fin de formation pour valoriser vos compétences sur votre CV et LinkedIn.\nUne garantie satisfait ou remboursé de 30 jours, sans risque.\nInscrivez-vous dès aujourd’hui\nRejoignez cette formation complète et devenez un expert en Data Science et Machine Learning avec Python, prêt à saisir les opportunités du marché.\nCommencez votre parcours vers la maîtrise de la Data Science dès maintenant !",
      "target_audience": [
        "Ce cours est destiné aux personnes souhaitant apprendre la l'analyse des données, la Data Science et le machine learning à l'aide de Python."
      ]
    },
    {
      "title": "Análisis de Sentimientos en Redes Sociales con Python",
      "url": "https://www.udemy.com/course/analisis-de-sentimientos-en-redes-sociales-con-python/",
      "bio": "Procesamiento del Lenguaje Natural, API de Twitter y Técnicas de extracción de datos mediante Scrapping y Selenium",
      "objectives": [
        "Programacion en Python",
        "Analizar datos en redes sociales",
        "Técnicas de visualización de datos",
        "Uso de APIs",
        "Automatización Web",
        "WebScrapping",
        "Procesamiento del Lenguaje Natural"
      ],
      "course_content": {
        "Introducción": [
          "Recursos",
          "Introducción",
          "¿Por que son importantes los datos?",
          "Cómo extraer información desde la web",
          "Herramientas utiles"
        ],
        "Aprende a Programar en Python": [
          "Variables en Python",
          "Listas en Python",
          "Uso de Strings",
          "Condicionales",
          "Bucles en Python",
          "Funciones",
          "Funciones Recursivas",
          "Funciones Lambda",
          "Clases en Python",
          "Lectura y escritura de archivos",
          "Uso de Try - Except"
        ],
        "Python Programacion Orientada a Objetos": [
          "Clases & Instancias",
          "Variables de Instancias & Variables de Clases",
          "Herencia",
          "Metodos de Clases"
        ],
        "Uso de Numpy": [
          "¿Como crea un Array?",
          "Operaciones con Arrays",
          "Manipulación de Arrays y Filtros",
          "Métodos útiles",
          "Estadística con Numpy",
          "Manipulación de imágenes"
        ],
        "Pandas": [
          "Introducción a Pandas",
          "Introducción a los DataFrames",
          "Selección de datos en DataFrames",
          "Filtro de datos en DataFrames",
          "Agrupaciones de datos en Pandas",
          "Agrupaciones y Filtros de datos"
        ],
        "Web Scrapping y Selenium": [
          "Introducción a HTML",
          "Introducción a Selenium",
          "Instalacion de Selenium",
          "Selección de elementos con Selenium",
          "Log in Facebook",
          "Scraping en yhaoo finance con Selenium",
          "Introducción a BeautifulSoup y requests",
          "Herramientas útiles en BeautifulSoup y requests",
          "Scraping en yhaoo finance con BeautifulSoup"
        ],
        "Extracción de Información a través de APIs": [
          "Peticiones HTTP",
          "JSON y XML",
          "API de Twitter",
          "Uso de Postman. API REST",
          "Uso de Filtros API Twitter.",
          "Uso de Requests para Twitter"
        ],
        "Procesamiento del Lenguaje Natural": [
          "Introduciòn a NLP y Analisìs de sentimiento",
          "Funciones utiles en TextBlob",
          "Análisis de sentimientos en yahoo Finance",
          "Modelo de Machine Learning con TextBlob",
          "Introducción Practica a NLTK",
          "Ejemplo usando NLTK",
          "Clasificador Bayesiano"
        ],
        "Visualización y Almacenamiento": [
          "Pickle",
          "Introducción a Matplotlib",
          "Visualización de datos con Matplotlib",
          "Visualización de datos con Matplolib II",
          "Visualización de datos con Matplolib III",
          "Nube de Palabras"
        ],
        "Análisis de Sentimiento en Twitter": [
          "Extracción de Información en Twitter",
          "Limpieza de datos",
          "Almacenamiento y Análisis de Tweets",
          "Clasificación de los Tweets",
          "Visualización del Sentimiento de Los Tweets"
        ]
      },
      "requirements": [
        "Tener ganas de aprender",
        "Ser una persona proactiva en el aprendizaje"
      ],
      "description": "¿Quieres aprender Python desde cero?\n¿Te gustaría extraer y analizar datos de redes sociales para entender qué piensa la gente sobre una marca, un producto o un tema?\nEn este curso práctico aprenderás a recolectar datos, procesarlos y analizar sentimientos en redes sociales usando Python y herramientas profesionales.\nNo necesitas experiencia previa: te llevamos de la mano, paso a paso.\n¿Qué vas a aprender?\nEste curso está diseñado para que pases de cero a analizar datos reales en redes sociales:\nProcesamiento de datos: aprende las principales formas de extraer información.\nPython básico: domina los conceptos esenciales para programar.\nPandas: manipula y transforma datos fácilmente.\nScraping y Selenium: extrae información web con ejemplos prácticos.\nAPIs: conecta con la API de Twitter y trae datos listos para analizar.\nProcesamiento de Lenguaje Natural: usa NLTK y TextBlob para entender textos y sentimientos.\nVisualización de datos: transforma información en gráficos claros con Matplotlib.\nEjemplo práctico: analiza el sentimiento de tweets en un proyecto real.\n¿Por qué este curso?\nPorque no solo aprenderás a programar: aprenderás a usar Python para obtener y procesar información que tiene valor real.\nTe llevarás ejemplos prácticos, código listo para usar y la habilidad de trabajar con datos del mundo real.\n\"La información no tiene valor si no sabes interpretarla.\"\n¿Qué conseguirás?\nAprender Python con enfoque práctico.\nAnalizar sentimientos y opiniones en redes sociales.\nDesarrollar habilidades muy demandadas en análisis de datos y marketing digital.\nEmpieza hoy\nCada día que pasa sin entender los datos que mueven las redes, pierdes oportunidades.\nAprende Python y descubre cómo convertir información en conocimiento accionable.",
      "target_audience": [
        "Personas interesadas en el Análisis de sentimiento",
        "Personas del Area de Marketing que quieran ampliar sus conocimientos en el mundo de la programación",
        "Desarolladores en Python interesados por el procesamiento del lenguaje Natural",
        "Personas curiosas que les interese aprender una nueva herramienta de negocio"
      ]
    },
    {
      "title": "Microsoft Pacote Office Essencial & Power BI Iniciantes",
      "url": "https://www.udemy.com/course/microsoft-office-primeiros-passos/",
      "bio": "Microsoft Pacote Office Essencial & Power BI Iniciantes",
      "objectives": [
        "MS Word básico e Avançado",
        "MS Excel básico e avançado",
        "MS Power Point básico r Avançado",
        "Fórmulas e Funções básicas e Avançadas",
        "Design de Gráficos",
        "Criação de Gráficos",
        "Modelagem de Gráficos",
        "Tabela Dinâmica",
        "Muito mais!!!!"
      ],
      "course_content": {},
      "requirements": [
        "Usuário de computador, Plataforma Windows e muita vontade aprender."
      ],
      "description": "1-Salvando Um documento no Word\n2-Formatação Colar,recortar, copiar Word\n3-Formatação de Texto Word\n4-Formatação de Paragrafo Word\n5-Formatação de estilos Word\n6-Inserção de paginas Word\n7-Inserção Tabelas no Word\n8-Inserção Tabelas no Word soma\n9-Inserção de imagem Word\n10-Inserção de clipart Word\n11-Inserção de formas word\n12-Inserção de Smart Art word\n13-Inserção de hiperlink word\n14-cabeçalho e Rodapé Word\n15-Numero de paginas e Caixa de texto Word\n16-Partes rápidas e word ART word\n17-Margens das folhas Word\n18-Configurações de paginas word\n19-Tabela Formulário - Parte 1\n20-Tabela Formulário Parte -2\n21- Tabela com calculo\n22-Tabelas Personalizadas\n\n\nMs Office Excel\n1-Introdução ao Microsoft Excel\n2-Introdução Microsoft Excel- salvar arquivo\n3-Introdução aos conceitos de Fórmulas Excel\n4-Trabalhando com Formulas aritméticas Excel\n5-Função-SE 2 Condições Excel\n6-Função-SE 3 Condições Excel\n7-Função cont-se 1 condição Excel\n8-Função cont-es 2 condição Excel\n9-Função procv Excel\n10-Função proch Excel\n11-Função proc Excel\n12-Função =hoje 1,2,3 condições\n13-Função concatenar unir dois textos Excel\n14-Função concatenar três textos Excel\n15-Função Agora e Função Combin Excel\n16-Função MED,MAX,MIN, DIA UTEIS TRABALHO Excel\n17-Função E Vinculada a Função SE Excel\n18-Função ou Vinculada a Função SE Excel\n19-Função ou isolada Excel\n20-Função somar produtos Excel\n21-Função soma-se Excel\n22-Função DATAM Excel\n23-Função SE ERRO Excel\n24-Função aleatório e aleatório entre Excel\n25-Função Arrumar texto Excel\n26-Função dia trabalho total Excel\n27-Função Substituir l 1 condição Excel\n28-Função Substituir infinitas condições Excel\n29-Função mudar texto Excel\n30-Função Extrair texto Excel\n30-Função taxa A.M -A.A E VF Excel\n31-Função PGTO A.M -A.A E VF Excel\n32-Função NPER A.M -A.A E VF Excel\n33-Função VP -Quitação empréstimos Excel\n34-Função VP -Resgate de aplicação Excel\n35-Função Cont valores 1 e 2 condição Excel\n36-Funçao Cont Valores 1 e 2 Condição Excel\n37-Função DATADIF dia, mês, ano Excel\n38- Colocando Filtro tabela Excel\n39-Criando tabela e gráficos - Parte 1\n40-Criando tabelas e formatando gráficos parte 2\n41-Criando tabelas e formatando gráficos parte 3\n42-Validação de dados, impedindo erros Excel\n43- Colocando senhas na planilha Excel\n\n\nMs Office Power Point\n0 - Apresentação do Curso\n1- Introdução ao Power Point\n1-1 Introdução a Guia Inicio Power Point\n1-2 Introdução Guia Inserir - Power Point\n1-3 Introdução a Guia Design\n1-4 Introdução a guia Animação\n1- Introdução ao Power Point\n2- Criando Slides\n3-Editando Slides\n4 - Colocando Vídeo no Slide\n5- Configurando Animação e Efeitos\n6 - Regulando tempo do Slides\n7 - Configurando Plano de Fundo\n8 -Formatando Titulo\n9 -Formatando Imagens\n10 - Animação em texto\n11 -Animação de texto sobre imagem\n12 - Animando carro no Power Print\n13-Efeito Mola no texto\n14- Inserindo uma  imagem Gif\n\n\nBônus - Curso de Power BI Iniciantes",
      "target_audience": [
        "Estudantes e Profissionais que desejam aprender Pacote office"
      ]
    },
    {
      "title": "중간관리자가 꼭 알아야 하는 머신러닝과 빅데이터 기법",
      "url": "https://www.udemy.com/course/machine-learning-bigdata/",
      "bio": "4차 산업혁명 시대에 꼭 필요한 빅데이터 전문가",
      "objectives": [
        "어려운 수학이나 통계학을 사용하지 않고, 데이터 분석의 기본이론을 직관적으로 이해할 수 있습니다.",
        "직접 알고리즘을 통한 프로그래밍을 디자인할 수 없지만, 데이터 사이언티스트의 설명을 이해하고 그들과 의사소통을 하는 토대를 마련할 수 있습니다.",
        "자신의 업무지식에 데이터분석의 장점을 결합하여 더 나은 방향으로 프로젝트를 이끄는 중간관리자로서의 역량을 갖출 수 있습니다.",
        "여러가지 비즈니스 문제를 빅데이터와 머신러닝을 이용해 풀어내는 방법을 습득할 수 있습니다."
      ],
      "course_content": {},
      "requirements": [
        "중학교 교육 수준의 수학적 지식"
      ],
      "description": "4차 산업혁명에 맞춰 자신의 디지털 경쟁력을 높이고 싶다면  '중간관리자가 꼭 알아야 하는 머신러닝과 빅데이터기법'으로\n지금부터 시작해 보십시요!\n\n\n프로그래밍이나 수학을 하지 않고, 엑셀을 이용해 데이터 사이언스로 여러가지의 비즈니스 문제를 풀어낼 수 있습니다!\n4주간의 학습으로 머신러닝과 데이터사이언스의 필요성에 대한 훨씬 더 강한 확신 및 어렵지 않게 관련 내용을 배우고 이해할 수 있을 것입니다.\n\n\n1. 머신러닝과 빅데이터를 활용한 데이터 사이언스 이해\n- 빅데이터와 머신러닝의 기본적 개념 및 지식 이해\n- 데이터 분석 모델 유형 학습\n\n\n2. 지도학습(supervisded learing) 배우기\n- 의사결정나무(classification tree)\n- 로지스틱 회귀분석(logistic regression)\n- 서포트 벡터 머신(support vector machine)\n\n\n3. 인공신경망과 비지도 학습(unsupervised learing) 배우기\n- 커널을 적용시킨 서포트 백터 머신, 인공신경망(Artificial Neural Neywork)\n- 최접근 이웃(K-nearest neighbor), 클러스터링(Clustering)\n\n\n4. 여러 머신러닝 방법을 결한합 Ensemble 배우기\n- 텍스트마이닝(Text mining), 소셜네트워크 분석\n- 머신러닝 활용시 고려사항",
      "target_audience": [
        "머신러닝과 빅데이터에 대하여 관심이 많은 사람",
        "데이터 관련 업무를 하지 않지만, 데이터 관련 업무를 하는 사람들과 원활한 커뮤니케이션을 하고 싶은 사람",
        "수학, 통계학, 프로그래밍을 잘 모르지만, 머신러닝, 빅데이터가 일상&비즈니스에서 일어나는 문제를 어떻게 풀어내는지 기본 과정을 이해하고 싶은 사람",
        "데이터를 다루는 중간관리자로 업무 진행과정을 점검하고 큰 안목에서 새로운 방향을 찾고자 하는 사람"
      ]
    },
    {
      "title": "LangChain 101 para Iniciantes (OpenAI / ChatGPT / LLMOps)",
      "url": "https://www.udemy.com/course/langchain-python-portuguese/",
      "bio": "Aprenda o básico sobre LangChain construindo aplicações Python impulsionadas por LLM com OpenAI, HuggingFace e Chroma!",
      "objectives": [
        "Domine o básico do LangChain e os fundamentos dos Modelos de Linguagem de Grande Escala (LLMs) de líderes do setor como OpenAI e HuggingFace.",
        "Adquira proficiência na criação, chamada e encadeamento de prompts para aplicações eficazes e interativas.",
        "Desenvolva uma compreensão sobre chatbots conversacionais dentro do LangChain, além de explorar funcionalidades de memória para respostas sofisticadas.",
        "Aprenda a aplicar técnicas LLM em documentos e projetos pessoais, abrindo o caminho para a aplicação real do conhecimento adquirido no curso."
      ],
      "course_content": {
        "Introdução": [
          "Bem-vindo a este curso!",
          "Leia antes de começar"
        ],
        "LangChain 101": [
          "Começando com LangChain e OpenAI",
          "Chamando Prompts com LLMs",
          "Usando diferentes Modelos de Linguagem de Grande Escala",
          "Modelagem e Encadeamento de Prompts",
          "Usando Cadeias Sequenciais Simples",
          "Agentes de Ação",
          "Humano como Ferramenta",
          "Planejar e Executar Agentes",
          "Memória e Chat Bots",
          "Armazenando e Recuperando Histórico de Conversas",
          "Carregando e Recuperando Documentos em Cadeia"
        ]
      },
      "requirements": [
        "Experiência básica de programação com Python!"
      ],
      "description": "Preparado para um mergulho eletrizante no universo da tecnologia de linguagem? Prepare-se para entrar de cabeça no mundo maneiro do LangChain com \"LangChain 101 para Iniciantes (OpenAI / ChatGPT / LLMOps)\". Aqui, você vai aprender a mandar bem usando o LangChain e Modelos de Linguagem de Grande Porte (LLMs) para criar suas próprias aplicações em Python.\n\n\nO objetivo deste curso é moleza - te dar todas as ferramentas para começar sua aventura no LangChain. Vamos te mostrar como usar diferentes LLMs dos gigantes do mercado, OpenAI e HuggingFace, e desvendar o truque de chamar prompts, criar templates e ligar tudo isso para montar um sistema interativo e firmeza.\n\n\nMas calma que tem mais! Vamos nos aprofundar no mundo dos chatbots e descobrir como a memória funciona no LangChain. Pra fechar com chave de ouro, um tutorial detalhado sobre como aplicar esses LLMs poderosos nos seus próprios documentos.\n\n\nEste curso não é só informativo — é diversão garantida. Usamos memes, exemplos do dia a dia e uma pegada descontraída para fazer desta jornada no mundo do LangChain algo super prazeroso.\n\n\nDá um chega pra lá naqueles cursos chatos e longos que são puro blá-blá-blá. Este aqui é direto ao ponto, perfeito para desenvolvedores Python que querem um atalho para o mundo do LangChain e LLMs. Sabemos que seu tempo é ouro, então condensamos tudo que é essencial em uma horinha top.\n\n\n\"LangChain 101 para Iniciantes\" é o seu passaporte para entender e botar a mão na massa com o LangChain. Ao final deste curso, você não só vai entender tudinho sobre LangChain, mas também estará pronto para encarar seu próximo projeto com um arsenal novinho em folha.\n\n\nNão fica aí parado — bora criar o futuro juntos. Mergulhe nesse mundo incrível do LangChain e Modelos de Linguagem de Grande Porte e se divirta muito pelo caminho!",
      "target_audience": [
        "Desenvolvedores Python de qualquer nível de habilidade interessados em construir aplicações Python impulsionadas por LLM com o LangChain"
      ]
    },
    {
      "title": "直感！深層学習　７ステップで作る Python AI 株価予測",
      "url": "https://www.udemy.com/course/7-python-ai/",
      "bio": "LSTMでGoogle/Amazon/Apple/Microsoft/IBMの株価を予測した上で、ChatGPTでも使われているtransformerアーキテクチャを使った東証グロース株の株価予測をおこなう。",
      "objectives": [
        "Python Pytorchを用いた株価予測AIの実装ハンズオン",
        "IBM/Apple/Microsoft/Google/Amazonの株価予測",
        "Python PandasのDataFrameを使ったデータ抽出方法",
        "Matplotlibを使った株価の可視化方法",
        "単純パーセプトロンを用いた線形回帰",
        "全結合型ニューラルネットワークを用いたSIN波の予測",
        "LSTMによる時系列データの回帰",
        "Google Colaboratoryの小技",
        "深層学習モデルを用いたバイナリーオプションのバックテスト",
        "深層学習モデルを用いた投資戦略のバックテスト（クオンツトレーディングへ）"
      ],
      "course_content": {},
      "requirements": [
        "Pythonの基礎文法の習得"
      ],
      "description": "直感！深層学習　７ステップで作る Python AI 株価予測\n〜Python Pytorchを用いた株価予測AIの実装ハンズオン〜\n\n\n2022/6月現在、米国の政策金利の引き上げによる物価上昇や景気後退、戦争・天災・感染症など世の中は不確実性が増しており、一寸先は闇なのか、一寸先は光なのか、予測困難な状況と思います。\n\n\nそんな中で、我々サラリーマンが将来を少しでも自分の手で予測し、不確かな時代を生き抜く為には自己投資、つまり最先端技術を学習するための継続的学習を行いながら自分の手で立てた仮説を元に、人任せにしない資産運用をしていくことが求められると思います。\n\n\n本講座ではPythonの基礎文法は学んだ、という方に向けて、transformerを利用した時系列解析にチャレンジします。Pytorch/Matplotlib/pandasなどのライブラリを用いて、2000年から2010年までのAmazon/IBM/Apple/Microsoft/Googleの株価を予測するハンズオンを行います。\n\n\n本講座をきっかけに仮説に基づくAI予測モデルの作成をご自身で行い、不確かな将来を予測する一助となれば幸いです。\n\n\n■□■□■□■□■□\n目次\n\n\nStep.1 Google Colaboratoryの小技\n\n\nStep.2 Matplotlibを使った株価の可視化方法\n\n\nStep.3 単純パーセプトロンを用いた線形回帰\n\n\nStep.4 全結合型ニューラルネットワークを用いたSIN波の予測\n\n\nStep.5 LSTMによるIBM/Apple/Microsoft/Google/Amazonの株価予測, 深層学習モデルを用いたバイナリーオプション取引のバックテスト\n\n\nStep.6 投資戦略\n\n\nStep.7 深層学習モデルを用いた投資戦略のバックテスト（クオンツトレーディングへ）\n\n\nStep.8 ChatGPTでも使われているtransformerアーキテクチャを使った東証グロース株の株価予測\n\n\n■□■□■□■□■□",
      "target_audience": [
        "Pythonの基礎文法を一通り終えて応用的な内容を学びたい人",
        "Pytorch初心者でデータ分析に興味がある人",
        "深層学習の実世界での応用に興味がある人",
        "深層学習を用いた回帰分析に興味がある人",
        "株式取引（システムトレード）に興味がある人"
      ]
    },
    {
      "title": "強化学習を学ぼう！Pythonで迷路問題やブラックジャックを強化学習させたエージェントを作っていこう！",
      "url": "https://www.udemy.com/course/python-rl/",
      "bio": "強化学習の1手法であるQ学習を学び、その上でPythonでQ学習を実装していこう！迷路の最適ルートを見つけるエージェントそしてブラックジャックで最適な行動をするエージェントを作っていこう！",
      "objectives": [
        "強化学習の基礎",
        "Q学習のアルゴリズム",
        "Q学習をPythonで実装する方法",
        "Q学習を用いて迷路の最適ルートを見つけるエージェントを作る方法",
        "Q学習を用いてブラックジャックの最適行動を取るエージェントを作る方法",
        "Pythonの基礎"
      ],
      "course_content": {},
      "requirements": [
        "Pythonの基礎から学んでいくのでプログラミングの経験は不要です"
      ],
      "description": "本コースでは強化学習について学んでいきます。\n\n\n強化学習はこのAI時代に必要不可欠な知識で様々なところで使われています。\n\n\nこのコースでは、まず強化学習について学び、強化学習の中でも一般的な手法であるQ学習のアルゴリズムを学んでいきます。\n\n\n基礎を理解した後はQ学習をPythonで実装し仕組みを理解し、最終的に迷路の最適ルートを見つけるエージェントとブラックジャックにおいて最適行動を取るエージェントを作っていきます。\n\n\n非常に強力な強化学習を理解して使いこなせるようになりましょう！",
      "target_audience": [
        "強化学習の仕組みに興味がある方",
        "Q学習の実装方法に興味がある方",
        "迷路問題やブラックジャックなどの問題に対して最適な行動を取るエージェントを作ってみたい方"
      ]
    },
    {
      "title": "Mathematik-Grundlagen für Machine Learning & Data Science",
      "url": "https://www.udemy.com/course/mathematik-grundlagen-ml/",
      "bio": "Differential- & Integralrechnung, Lineare Algebra und Statistik",
      "objectives": [
        "Die Teilnehmer verstehen nach Abschluss des Kurses die Mathematik hinter Machine Learning und Data Science.",
        "Erkennen, dass auch scheinbar komplexe Zusammenhänge verständlich werden, wenn sie nur einfach erklärt werden."
      ],
      "course_content": {
        "Einleitung": [
          "Vorstellung",
          "Motivation",
          "Kursüberblick"
        ],
        "Mathematik und Machine Learning/Data Science": [
          "Was ist Machine Learning?",
          "Regression & Classification",
          "Quiz",
          "Funktion",
          "Quiz",
          "Lineare Algebra in Kürze",
          "Quiz",
          "Logistische Regression",
          "Logistische Regression - Fortsetzung",
          "Quiz",
          "Fehler",
          "Quiz",
          "Neuronales Netz",
          "Quiz",
          "Data Scientist",
          "Exkurs",
          "Zusammenhang zwischen Mathematik und Machine Learning & Data Science"
        ],
        "Differential- und Integralrechnung": [
          "Einführung in die Differentialrechnung",
          "Grenzwert",
          "Quiz",
          "Ableitung",
          "Quiz",
          "Monotonie und Wendepunkt",
          "Quiz",
          "Aufgaben Wendepunkt",
          "Extremwerte",
          "Quiz",
          "Newton Verfahren",
          "Aufgaben Differentialrechnung",
          "Kurvendiskussion",
          "Aufgaben Kurvendiskussion",
          "Aufgaben Extrema (Textaufgaben)",
          "Einführung in die Integralrechnung",
          "Integral und Stammfunktion",
          "Quiz",
          "Hauptsatz der Differential- & Integralrechnung",
          "Quiz",
          "Eigenschaften der Integrale",
          "Quiz",
          "Zusammenfassung Differential- & Integralrechnung",
          "Aufgaben Integralrechnung",
          "Aufgaben Integralrechnung (Textaufgaben)"
        ],
        "Lineare Algebra": [
          "Einführung in die Lineare Algebra",
          "Vektor",
          "Vektor-Operationen",
          "Aufgaben Vektoren Addition",
          "Aufgaben Vektoren Skalarprodukt",
          "Aufgaben Vektoren Kreuzprodukt",
          "Aufgaben Vektoren Betrag",
          "Quiz",
          "Matrix",
          "Matrizen-Operationen",
          "Aufgaben Matrizen Addition Subtraktion",
          "Aufgaben Matrizen Multiplikation",
          "Aufgaben Matrizen Inverse",
          "Quiz",
          "Matrix-Vektor-Produkt",
          "Eigenwert und Eigenvektor",
          "Quiz",
          "Determinante",
          "Aufgaben Determinate",
          "Quiz",
          "Erzeugendensystem, Basis, lineare Unabhängigkeit, Rang",
          "Quiz",
          "Anwendung Classification",
          "Zusammenfassung Lineare Algebra",
          "Zusatzmaterial Geraden und Ebenen",
          "Zusatzaufgaben Geraden und Ebenen"
        ],
        "Statistik": [
          "Einführung in die Statistik und Stochastik",
          "Grundgesamtheit und Stichprobe",
          "Mittelwert und Median",
          "Quiz",
          "Varianz und Standardabweichung",
          "Quiz",
          "T-Test",
          "Quiz",
          "Chi-Square Test",
          "Fehler 1. Art und 2. Art",
          "Quiz",
          "Wahrscheinlichkeit",
          "Binomialverteilung und Poisson-Verteilung",
          "Aufgaben Binomialkoeffizient",
          "Aufgaben Urnenmodell",
          "Bewertung diagnostischer Tests",
          "Bayes Theorem",
          "Zusammenfassung Statistik",
          "Aufgaben Wahrscheinlichkeitsverteilung",
          "Aufgaben Stochastik",
          "Aufgaben Wahrscheinlichkeit für Intervall",
          "Aufgaben Hypothesentest"
        ],
        "Handout, Quellen und weiteres Material": [
          "Handout Differential- und Integralrechnung",
          "Handout Lineare Algebra",
          "Handout Statistik",
          "Quellen und weiteres Material"
        ]
      },
      "requirements": [
        "Generelle Mathematik-Grundkenntnisse aus der Schule sind hilfreich, aber nicht notwendig.",
        "Englisch-Kenntnisse sind von Vorteil, weil teilweise das Material auf Englisch ist. Kurs -Sprache ist Deutsch."
      ],
      "description": "Mathematik Grundlagenkurs, der die wichtigen Teilgebiete Differential- & Integralrechnung, Lineare Algebra und Statistik umfasst. Dabei wird der Bezug zu Machine Learning & Data Science hergestellt.\nIdeal für alle, die die Mathematik-Grundlagen erlernen, wiederholen oder vertiefen möchten.\nIdeal für alle, die sich für Machine Learning & Data Science interessieren. Hier spielt nämlich die Mathematik eine wichtige Rolle.",
      "target_audience": [
        "Dieser Kurs eignet sich für jeden, der die mathematischen Grundlagen begreifen möchte, die hinter Machine Learning und Data Science stecken.",
        "Mathematik ist für viele eine große Hürde. Das muss nicht so sein!",
        "Für alle, die sich für künstliche Intelligenz, Machine Learning und Data Science interessieren."
      ]
    },
    {
      "title": "Data Science em R: ETL parte 2 - Relacionamento entre Dados",
      "url": "https://www.udemy.com/course/etlpart2/",
      "bio": "Data Integration - Aprenda a relacionar diferentes bancos de dados sem sair do R",
      "objectives": [
        "Maior proficiência em Linguagem R",
        "Relacionar Diferentes bancos de Dados",
        "Aprenderá como realizar Joins usando diferentes caminhos",
        "Saberá como identificar e como usar as Chaves para relacionar os diferentes bancos",
        "Aprenderá como realizar filtros em um banco com base em informações de outro banco",
        "Saberá adicionar variáveis de outro banco a um banco original, sem danificar os dados."
      ],
      "course_content": {
        "Introdução": [
          "Seja muito bem vindo(a)!",
          "Antes de iniciarmos...",
          "Visão geral do Curso",
          "Dados Relacionados - Introdução",
          "Explicando os Dados",
          "As Variáveis Conectoras",
          "Possíveis Relações Existentes",
          "Chave Primária",
          "Chave Estrangeira ou Externa",
          "Chaves Compostas",
          "Definindo as chaves no banco",
          "Tipos de Relacionamentos",
          "Exercícios sobre a Seção 1"
        ],
        "Mutate Joins": [
          "Inner Join",
          "Left Join",
          "Right Join",
          "Full Join e inversões",
          "Multate Join - Exemplo Real",
          "Chaves Múltiplas",
          "Chaves Diferentes com mesmo nome",
          "Chaves Iguais com Nomes diferentes",
          "Outras implementações Equivalentes",
          "Exercícios sobre Mutating Join"
        ],
        "Filtering Joins": [
          "Filtering Joins - semi join",
          "Filtering - Anti join",
          "Evitando problemas nos Joins",
          "Exercícios Filtering Joins"
        ],
        "Set Operations": [
          "Set Operations - Intersect",
          "Set Operation - Union",
          "Set Operations - Set Diff."
        ],
        "Projeto": [
          "Explicação do Projeto",
          "Solução do Projeto"
        ],
        "Aula Bônus": [
          "Aula Bônus",
          "Trilha de Aprendizado para a carreira em Data Science"
        ]
      },
      "requirements": [
        "Sugiro se familiarizar nos meus cursos de Linguagem R e curso de ETL parte 1"
      ],
      "description": "Está tentando seguir carreira como Analista de Dados ou Data Sciente?\nMuito raramente você receberá dados em uma única planilha, mas sim deverá buscar soluções de problemas usando DIFERENTES bases de dados. Então você precisa dominar ferramentas para relacionar tabelas e buscar a informação desejada.\n\n\nAo final deste curso você será capaz de:\nIdentificar possíveis chaves para o relacionamento entre tabelas\nAplicar joins e merges para relacionar diferentes bases\nAplicar filtros aos dados usando informações externas\nMaior proficiência no R\n\n\nPara quem serve este curso?\nProfissionais de TI e de áreas associadas, interessados em se aprofundar em Estatística e aplicá-la no mundo empresarial.\nEstudantes de graduação, mestrado e doutorado precisando aprender estatística para provas universitárias ou para pesquisas científicas.\n\"Concurseiros\" interessados em \"matar\" a prova de Estatística.\n\n\nSobre o Professor\nMeu nome é Isaías Lira, bacharel em Estatística, Consultor em Análise Estatística de Dados, pesquisador e estudioso da área de Estatística Aplicada no Mercado Financeiro, escritor de livro em Estatística, Data Scientist, Pos-graduado em Docência Superior e este curso é um importante dentro de minha lista de cursos.\n\n\nQual o diferencial deste curso?\nCurso 100% pratico\nUsaremos dados reais\nTudo mostrado passo a passo\nAprofundamento na ferramenta de análise de dados mais respeitada no mercado: o R.\nEstrutura: o curso esta cuidadosamente estruturado para que em cada aula você tenha a clareza de cada assunto abordado\nAbordagem simplificada: focamos naquilo que é mais importante, numa linguagem simples, direta, com vários exemplo reais\n\n\nInicie agora e conclua quando bem desejar! Sem pressão! Respeitaremos o seu próprio ritmo e estaremos aqui para tirar suas dúvidas.\n\n\nEntão, se você quer aprender a relacionar dados em diferentes planilhas, seja você quem for, este é o caminho mais fácil que conheço!\nJunte-se a nós nesta grande aventura e dê leve sua carreira para um outro nível!\nO mercado profissional precisa de você, então aprenda isto e seja útil para as grandes empresas.\nPor que não aprender a Relacionar Dados?\nVamos iniciar?",
      "target_audience": [
        "Leigos interessados em juntar diferentes planilhas de dados em uma apenas",
        "Leigos interessados em aprender a Relacionar planilhas de dados usando o R",
        "Estudantes e Profissionais de TI ou qualquer pessoa que desejar Relacionar Diferentes bancos de dados para a tomada de decisão empresarial"
      ]
    },
    {
      "title": "Data Cleaning avec Pandas pour le Machine Learning [Python]",
      "url": "https://www.udemy.com/course/apprenez-pandas/",
      "bio": "Passez à la vitesse supérieure dans votre travail de Machine Learning / Data Science avec Python et Pandas",
      "objectives": [
        "Maîtriser l'outil le plus utile pour faire de la Data Science ou du Machine Learning en Python : la librairie PANDAS",
        "La méthode Pas à Pas afin de préparer vos Datasets pour faire du Machine Learning en Python",
        "Les 5 choses à faire directement après avoir importé votre Dataset avec Pandas",
        "Ne plus tomber dans le piège qui fait perdre des heures chaque jours aux Data Scientists inexpérimenté·e·s",
        "Les méthodes adéquates pour extraire de l'information des types de données les plus fréquents ULTRA-RAPIDEMENT (même les Dates)",
        "Les 3 différentes manières de gérer les \"Missing Values\" pour que vous puissiez faire face à toutes les situations",
        "Ce que sont les \"Dummy Variables\", \"One-Hot Encoding\" et \"N-1 Encoding\" ainsi que comment les faire vous même",
        "Comment corriger les erreurs de code comme des pros",
        "Et bien plus encore,"
      ],
      "course_content": {
        "Introduction, Installation & Conseils pour tirer le meilleur parti de ce cours!": [
          "Bienvenue ! Vous avez fait un excellent choix!",
          "Comment installer Google Colab, un environnement de développement complet!",
          "Progressez plus vite et tirez le plus de ce cours en suivant ces 4 conseils!"
        ],
        "Les 4 points à connaître absolument quand on débute Pandas": [
          "Qu'est ce qu'est \"la Data\" et quel-est notre objectif dans ce cours?",
          "Lire un fichier CSV et la solution aux 4 problèmes les plus rencontrés",
          "Les 5 étapes à faire tout de suite après l’ouverture d’un fichier .CSV",
          "Maîtrisez le concept de \"inplace\" qui rend confus tous les débutants!",
          "Révisez rapidement le concept de \"inplace\" avec cette vidéo"
        ],
        "Votre première mission : Extraire l'Information Utile depuis les Données Brutes": [
          "Ce que vous allez apprendre dans cette section",
          "Extraire de l'Information Numérique depuis des Chaînes de Caractères",
          "Extraire de l'Information Catégorique depuis des Valeurs Numériques",
          "Extraire de l'Information Numérique depuis des Dates ou des Heures",
          "Extraire de l'information catégorique depuis des Dates ou des Heures (Débutant)",
          "Gérer les concepts encodés simplement grace à cette recette de code Python",
          "Extraire de l'Information Catégorique depuis des Dates (Intermédiaire)",
          "Extraire de l'Information Catégorique depuis des Dates ou des Heure (Avancé)"
        ],
        "Votre seconde mission : Nettoyer et Finaliser la Préparation du Dataset": [
          "Ce que vous allez apprendre dans cette section",
          "Apprenez à Supprimer les Doublons",
          "Les \"Valeurs Manquantes\" apprenez à gérer le fléau du Data Scientist",
          "Les \"Dummy Variables\" ou comment encoder les colonnes catégoriques",
          "Supprimer les colonnes inutiles ou redondantes",
          "Ne tombez plus dans le piège ! Comment sauvegarder correctement vos DataFrames",
          "Comprendre enfin les Random Seeds et comment les utiliser",
          "Apprenez à faire des \"Split Train / Test / Valid\" stratifiées comme les pros"
        ],
        "Mettez vos nouvelles compétences à l'épreuve sur ces 3 datasets": [
          "Bravo d'être arrivé⸱e jusqu'ici! Maintenant passons aux examens finaux!",
          "[Challenge Final] Le Dataset des Ventes de Vêtements Vintages",
          "[Challenge Final] Le Dataset des prix des Diamants",
          "[Challenge Final] Le Dataset du Titanic & Participer à un concours Kaggle"
        ],
        "Bonus et Corrections des Exercices et Challenges": [
          "Mes conseils carrière pour percer en IA et en Data Science",
          "[Correction][Exercice] Convertir les \"Strings\" en Nombres",
          "[Correction][Exercice] Convertir les Nombres en Catégories",
          "[Correction][Exercice] Convertir les Dates en Catégories (Débutant)",
          "[Correction][Exercice] Convertir les Dates en Catégories (Intermédiaire)",
          "[Correction][Exercice] Gérer les Valeurs Manquantes",
          "[Correction][Challenge Final] Le Dataset des Ventes de Vêtements Vintages",
          "[Correction][Challenge Final] Le Dataset des prix des Diamants",
          "[Correction][Challenge Final] Le Dataset du Titanic & Concours Kaggle",
          "Continuez votre apprentissage au meilleur prix grâce à ces coupons exclusifs"
        ]
      },
      "requirements": [
        "Connaître les bases de Python est obligatoire.",
        "Ce cours comporte plus de 10 heures de code live alors soyez prêt à mettre la main à la pâte et coder!",
        "Attention c'est un cours sur l'étape cruciale de nettoyage du dataset avec Pandas, pas un cours de Machine Learning avec Sci-Kit Learn"
      ],
      "description": "Est-ce que tu t’es déjà demandé ce qui permettait à certains apprentis Data Scientist de progresser ULTRA-VITE alors que le domaine est ULTRA-DUR ?\n\n\nLa dure réalité, c’est que tous les moyens d’apprendre la Data Science ne sont pas égaux.\n\n\nLe pire scénario serait de passer tout son temps à apprendre la théorie et les maths derrière les algos de Machine Learning sans jamais passer à la pratique.\n\n\nLa première erreur que commettent beaucoup de gens, c’est de se concentrer sur la partie évidente du Machine Learning et de la Data Science sans jamais réaliser que 80% du travail de Data Scientist consiste à préparer et à nettoyer les données. Le vrai problème c’est donc de ne pouvoir être bon/très bon qu'à 20% car on n'a en fait pas appris à devenir efficace sur ces 80% du travail.\n\n\nSi les apprenti·e·s Data Scientists et les Data Scientists juniors veulent devenir meilleurs dans leur activité alors ils doivent nécessairement devenir efficaces dans la préparation et le nettoyage des données.\n\n\nLa librairie Python Pandas a été créée afin de pouvoir effectuer ULTRA-SIMPLEMENT des manipulations complexes de préparation et de nettoyage de données.\n\n\nÀ la fin de ce cours, tu seras capable d'effectuer les 80% les plus importants de ton travail de Data Scientist 10 fois plus rapidement, ce qui améliorera ton confort de travail immédiatement.\n\n\nPar exemple, lors d'un cours de Machine Learning ou d'un bootcamp Data Science, plutôt que d'être perdu dans la documentation de Pandas et Stack Overflow, tu pourras passer plus de temps à te concentrer la partie Machine Learning et donc à progresser en Data Science.\n\n\nOu bien imagine que tu passes un entretien où l'on te demande de coder pour prouver tes compétences. Au lieu de passer la plupart de ton temps à te battre pour rendre tes données \"clean\", tu pourras réaliser des analyses plus détaillées et passer plus de temps à peaufiner les résultats de tes modèles, ce qui impressionnera tes recruteurs.\n\n\nDans une vision long terme également, ce cours pose des fondations solides grâce auxquelles tu pourras continuer à t'améliorer en autonomie en Pandas et en Python.\n\n\nLe vrai challenge c'est que Pandas est une librairie très intimidante quand on débute, et beaucoup de Data Scientist débutant·e·s décident de n'apprendre que les utilisations les plus basiques. Il s'agit là de la seconde erreur que commettent beaucoup de gens.\n\n\nLa réalité est simple : Pandas est un outil et le meilleur moyen pour maîtriser un outil c'est de s'en servir !\n\n\nDurant plus de 10 heures de vidéo où je code sous tes yeux, tu auras l'occasion d'apprendre le processus de nettoyage de données pas à pas et je te montrerai les pièges à éviter ainsi que des astuces méconnues mais terriblement efficaces.\n\n\nJ'y ai aussi inclus plus de 3 heures d'exercices corrigés afin que tu puisses t'entraîner à ton rythme !\n\n\nSi tu es un·e débutant·e, alors ce cours est fait pour toi et te permettra d'accélérer grandement ton apprentissage de ce domaine passionnant, le seul prérequis étant que tu connaisses les bases de Python.\n\n\nMais ce cours te conviendra aussi si tu as déjà commencé ton premier stage / emploi de Data Scientist et que tu constates que tu passes beaucoup de temps à te gratter la tête en essayant de nettoyer tes données ; en effet, dans ce cours nous couvrirons bien plus que les bases.\n\n\nOn parle ici d'une vraie méthodologie pour nettoyer les données ainsi que d'un éventail de techniques de nettoyage pour te préparer aux situations les plus courantes que tu rencontreras sur le terrain.\n\n\nSi tu as plusieurs années d'expérience et/ou que tu recherches un cours Pandas pour manipuler des Time-Series alors ce cours ne sera probablement pas pour toi.\n\n\nCe cours n'est pas non plus un cours de théorie du Machine Learning ou de Data Science, donc si c'est ce que tu recherches tout de suite, alors ce cours-ci n'est pas pour toi (mais un autre à venir sûrement !).\n\n\nDans tous les cas, tu peux toujours jeter un oeil aux vidéos disponibles en aperçu gratuitement pour avoir une idée plus détaillée du contenu du cours.\n\n\nSi après ça tu te demandes encore si ce cours est fait pour toi, le plus simple reste tout simplement d'essayer: Udemy et moi sommes heureux de t'offrir un remboursement inconditionnel de 30 jours si le cours ne te satisfait pas pleinement. Comme ça, aucun risque pour toi et tu as tout à y gagner !",
      "target_audience": [
        "Tout·e·s les débutant·e·s motivé·e·s en Data Science, Machine Learning & Intelligence Artificielle qui veulent accélerer leur progression",
        "Toutes les personnes qui ont compris que la préparation des données représente plus de 80% du métier de Data Scientist"
      ]
    },
    {
      "title": "Inteligência Artificial: Algoritmos Genéticos com Python",
      "url": "https://www.udemy.com/course/inteligencia-artificial-algoritmos-geneticos/",
      "bio": "Aprenda Algoritmos Genéticos na teoria e prática utilizando a linguagem Python!",
      "objectives": [
        "Utilizar Algoritmos Genéticos para resolver os mais variados problemas.",
        "Utilizar a linguagem Python para implementar Algoritmo Genéticos."
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas",
          "Apresentação do instrutor",
          "Perguntas"
        ],
        "Algoritmos Genéticos - Teoria": [
          "O que são Algoritmos Genéticos?",
          "Evolução e seleção natural",
          "Introdução a Genética",
          "História dos Algoritmos Genéticos",
          "Algoritmos Evolucionários",
          "Características dos Algoritmos Genéticos",
          "Terminologia",
          "Motivação",
          "Esquema de um Algoritmo Genético Básico",
          "Fluxograma de um Algoritmo Genético",
          "Representação do cromossomo",
          "Inicialização da população",
          "Função de avaliação",
          "Seleção dos pais",
          "Seleção dos pais - Método da roleta",
          "Crossover",
          "Mutação",
          "Superindivíduo",
          "Avaliação negativa ou zero",
          "Crossover uniforme",
          "Mutação novamente",
          "Tamanho da população",
          "Elitismo",
          "Seleção por torneio"
        ],
        "Linguagem Python": [
          "Interpretador Python",
          "Operadores e variáveis",
          "Manipulando strings",
          "Estruturas de dados",
          "Condicionais e Loops",
          "Módulo random",
          "Criando funções",
          "Entrada de dados"
        ],
        "Problema OneMax": [
          "OneMax - Gerando a população",
          "OneMax - Função de avaliação",
          "OneMax - Seleção dos pais",
          "OneMax - Crossover",
          "OneMax - Mutação",
          "OneMax - Finalização"
        ],
        "Problema Crack Password": [
          "Crack Password - Função de avaliação",
          "Crack Password - Gerando a população",
          "Crack Password - Score da população",
          "Crack Password - Seleção dos pais",
          "Crack Password - Crossover",
          "Crack Password - Mutação",
          "Crack Password - Finalização"
        ],
        "Considerações finais": [
          "Parabéns!!",
          "Aula bônus"
        ]
      },
      "requirements": [
        "Recomenda-se lógica de programação."
      ],
      "description": "Que tal aprender na prática uma técnica poderosa para resolver problemas complexos?\nAlgoritmo Genético é uma técnica que se inspira na natureza para encontrar soluções para problemas difíceis de serem resolvidos por técnicas tradicionais. Nesse curso você irá aprender sobre Algoritmos Genéticos na teoria e prática através de aulas dinâmicas e didáticas!\nAlgoritmos Genéticos é uma ferramenta fundamental para que você possa atacar problemas difíceis de serem resolvidos. Esse curso é destinado para quem quer aprender mais sobre a área da Computação Inteligente e Inteligência Artificial, mais precisamente Computação Bio-Inspirada.\nEm várias áreas os Algoritmos Genéticos estão sendo utilizados tais como: petróleo e gás, música, telecomunicações, área médica e muito mais! Algoritmo Genético possui uma grande aplicabilidade tornando-o uma ferramenta poderosa para atacar problemas complexos de otimização.\nNesse curso utilizaremos a linguagem Python para implementar Algoritmos Genéticos. A linguagem Python é de fácil aprendizado e possui recursos poderosos que irão facilitar a nossa implementação.\nO curso é 100% em vídeo-aulas, possui direito a certificado e o instrutor Marcos Castro estará a sua disposição para tirar quaisquer dúvidas caso você precise! O que está esperando? Cadastre-se agora mesmo no curso e faça um upgrade do seu conhecimento!",
      "target_audience": [
        "Alunos de graduação e pós-graduação de computação.",
        "Pessoas que querem aprender uma técnica poderosa para problemas complexos de otimização.",
        "Pessoas que querem aprender sobre Inteligência Artificial.",
        "Pessoas que querem aprender sobre Computação Bio-Inspirada.",
        "Pessoas que querem aprender sobre Algoritmos Genéticos.",
        "Pessoas que querem utilizar a linguagem Python para implementar Algoritmos Genéticos."
      ]
    },
    {
      "title": "ChatGPT Masterclas para profesionales: automatiza tu trabajo",
      "url": "https://www.udemy.com/course/formacion-avanzada-en-chatgpt-y-llms-aplicaciones-practicas/",
      "bio": "Todo sobre ChatGPT: Dominando Prompts, Optimización de Productividad y Aplicaciones Prácticas en el Mundo Empresarial",
      "objectives": [
        "Prompt engineering con ChatGPT",
        "Fundamentos de ChatGPT",
        "Seguridad y Protección de datos con ChatGPT",
        "IA Generativa y su aplicación en diferentes industrias",
        "Aplicaciones y Extensiones para ChatGPT",
        "Auto-GPT: la IA que superó a ChatGPT",
        "Modelos LLM Open-Source",
        "Incrementar las capacidades de ChatGPT con LangChain",
        "ChatGPT para automatizar el trabajo",
        "Creación de contenido y Copywritting",
        "Maximizar el alcance de nuestras redes sociales con ChatGPT",
        "Productividad en la oficina con ChatGPT"
      ],
      "course_content": {
        "Introducción al curso": [
          "Introducción a la plataforma de Udemy"
        ],
        "Introducción a ChatGPT": [
          "OpenAI: la compañía detrás del algoritmo de ChatGPT",
          "Introducción a ChatGPT",
          "Laboratorio: Primeros pasos con ChatGPT",
          "+200 Prompts con Awesome ChatGPT Prompts",
          "AIPRM la extensión para optimizar el uso de ChatGPT",
          "Ventajas de ChatGPT y diferencias con ChatBot convencionales",
          "Limitaciones de ChatGPT"
        ],
        "ChatGPT4: el modelo más avanzado de OpenAI": [
          "ChatGPT4 La evolucion de ChatGPT",
          "Ventajas y limitaciones de ChatGPT4",
          "Acceso a ChatGPT4 a traves de Bing y ChatGPT Plus"
        ],
        "Como hacer un uso efectivo de ChatGPT": [
          "Prompts efectivos en ChatGPT",
          "Técnicas y proceso para generar Prompts efectivos",
          "Técnicas para evitar la ambiguedad en los Prompts",
          "Marco general para ChatGPT"
        ],
        "Aplicaciones y Extensiones de ChatGPT": [
          "La extensión AIPRM para ChatGPT",
          "Merlin el asistente de ChatGPT para todas las webs"
        ],
        "Dando acceso a internet a ChatGPT": [
          "Dando acceso a internet ChatGPT a traves de WebChatGPT",
          "Browsing Alpha GPT para acceder a información en tiempo real de int"
        ],
        "IA Generativa": [
          "Introducción a la IA Generativa y a sus aplicaciones ChatGPT, DALLE y MidJourney",
          "Modelos discriminativos vs modelos generativos",
          "Empresas de IA Generativa",
          "GANs Generative Adversarial Networks",
          "Modelos basados en Transformers",
          "Variational Auto Encoders y espacio latente",
          "Desafios de la IA Generativa",
          "Awesome Generative AI: Listado de +100 herramientas y modelos de IA Gen",
          "Cuestionario"
        ],
        "Casos de uso de IA Generativa y ChatGPT en diferentes industrias": [
          "Introducción a la aplicación de IA Generativa y ChatGPT en diferentes industrias",
          "Casos de uso de IA generativa en Adobe y BMW",
          "Casos de uso de IA generativa en Salesforce, Snapchat y Duolingo",
          "Caso de Uso Aplicado: Generando Trailers integramente con IA Generativa"
        ],
        "ChatGPT para automatizar el trabajo": [
          "Utilizando ChatGPT para resumir y simplificar información compleja",
          "Adaptar el contenido a una determinada audiencia mediante ChatGPT",
          "Resume rápidamente videos",
          "ChatGPT para organizar información, generar tablas y recono entidade"
        ],
        "Creación de contenido y Copywritting": [
          "Generando articulos, blogs y optimizando el SEO con ChatGPT",
          "Generación de anuncios con ChatGPT y DALL-E",
          "Generando los guiones para nuestros videos de Youtube, Tik Tok, etc",
          "Generando una campaña de redes sociales para nuestro producto",
          "Automatización y mejora del SEO con ChatGPT"
        ]
      },
      "requirements": [
        "No hay"
      ],
      "description": "¡Prepárate para sumergirte en el emocionante mundo de ChatGPT y la Inteligencia Artificial Generativa con este curso de Udemy! En este completo programa, te adentrarás en el mundo de ChatGPT, la potente herramienta de IA que está revolucionando la forma en que interactuamos con el lenguaje natural.\n\n\nA lo largo del curso, explorarás el arte del Prompt Engineering, aprendiendo estrategias efectivas para diseñar y ajustar los prompts de manera que obtengas respuestas coherentes y precisas. Dominarás las técnicas para maximizar el potencial de ChatGPT y generar resultados impactantes en cada interacción.\n\n\nLa seguridad y la protección de datos son aspectos críticos en el ámbito de la IA, y aquí aprenderás las mejores prácticas para garantizar la confidencialidad y privacidad de la información durante tus interacciones con ChatGPT. Descubrirás técnicas y herramientas para salvaguardar los datos sensibles y mantener la integridad en todo momento.\n\n\nSumergiéndote en el campo de la IA generativa, explorarás las aplicaciones de ChatGPT en diversas industrias y sectores. Desde el marketing y la publicidad hasta la redacción creativa y la asistencia virtual, descubrirás cómo aprovechar el poder de ChatGPT para mejorar tus procesos y optimizar tus tareas diarias.\n\n\nAdemás, conocerás aplicaciones y extensiones especializadas que te permitirán ampliar las capacidades de ChatGPT. Aprenderás a personalizar y adaptar el modelo según tus necesidades específicas, mejorando su rendimiento y precisión en cada contexto.\n\n\nExploraremos los últimos avances en el campo de la IA generativa, incluido Auto-GPT, la IA que ha superado a ChatGPT en términos de capacidad y generación de texto. Estarás al tanto de las últimas innovaciones y te prepararás para aprovechar al máximo estas tecnologías emergentes.\n\n\nEl curso también abordará cómo utilizar ChatGPT para automatizar tareas y optimizar tu flujo de trabajo. Descubrirás cómo aprovechar la potencia de la IA para agilizar procesos y maximizar tu productividad, permitiéndote centrarte en tareas más estratégicas y creativas.\n\n\nNo importa cuál sea tu campo de especialización, el curso te equipará con habilidades valiosas en creación de contenido y copywriting. Descubrirás técnicas avanzadas para generar textos persuasivos y cautivadores con la ayuda de ChatGPT, mejorando tus habilidades de comunicación y alcanzando nuevos niveles de impacto.\n\n\n¡No te pierdas esta oportunidad de adquirir habilidades especializadas en ChatGPT! Inscríbete ahora en este curso  y desbloquea todo el potencial de la generación de texto asistida por IA.",
      "target_audience": [
        "Cualquier persona que quiera aprender acerca de ChatGPT",
        "Cualquier persona que quiera hacer un uso efectivo de ChatGPT",
        "Cualquier persona que quiera aplicar ChatGPT en su día a día",
        "Cualquier empresa que quiera integrar ChatGPT en sus aplicaciones empresariales"
      ]
    },
    {
      "title": "Data Science avec Python, SQL, FastAPI, Streamlit & Docker",
      "url": "https://www.udemy.com/course/data-science-avec-python-sql-fastapi-streamlit-docker/",
      "bio": "De la Modélisation SQLAlchemy à l'API et à la Data App : maîtrisez Python grâce un projet 100% pratique, réel et complet",
      "objectives": [
        "Développer, tester et publier une API professionnelle avec FastAPI, de la logique métier jusqu’au déploiement en ligne.",
        "Concevoir un SDK Python pour consommer une API, le transformer en package et le publier sur PyPI.",
        "Analyser et visualiser les données retournées par l’API dans des notebooks Jupyter pour répondre à des questions business.",
        "Créer une application Streamlit interactive connectée à l’API pour exposer dynamiquement les résultats aux utilisateurs.",
        "Gérer un projet tech de manière professionnelle avec Git et GitHub (versioning de code, README, debug, ...).",
        "Documenter chaque composant du projet (API, SDK, analyse) pour faciliter l’utilisation et la collaboration."
      ],
      "course_content": {},
      "requirements": [
        "Notions basiques en Python (fonctions, structures de données, structures conditionnelles et boucles)",
        "Une connaissance élémentaire de Git et GitHub (clonage, commit, push)."
      ],
      "description": "Description du cours\nVous rêvez de devenir un Data Consultant polyvalent, capable de gérer un projet de bout en bout ? Ce cours est fait pour vous !\nPlongez dans une aventure 100% pratique et immersive, où vous incarnez un consultant missionné par CineData Insights, une entreprise fictive qui veut transformer des données brutes sur les films en une plateforme intelligente.\nVotre mission : concevoir un véritable écosystème data moderne autour du cinéma en passant par trois grandes étapes :\nModélisation et centralisation des données avec SQLite,\nConstruction d’une API REST avec FastAPI, sécurisée, documentée, conteneurisée avec Docker  et déployée dans le cloud,\nCréation d’une application de visualisation Streamlit alimentée en temps réel par l’API.\nUn projet captivant et immédiatement réutilisable pour votre portfolio professionnel, vos entretiens ou vos missions Freelance.\n\n\nCe que vous allez apprendre\n\n\nConcevoir une base de données relationnelle à partir de fichiers CSV\nCréer une API RESTful robuste avec FastAPI et SQLAlchemy\nDéployer votre API sur Render ou en local avec Docker\nCréer un SDK Python pour interagir avec votre API et le publier sur PyPI (The Python Package Index)\nInterroger l’API depuis un notebook Python pour faire de la Data Analysis\nDévelopper une application web Streamlit connectée à votre API\nPrésenter des insights cinéma interactifs à vos utilisateurs finaux\nGérer un projet data complet, de A à Z, comme un vrai pro\n\n\nPourquoi suivre ce cours ?\nVous en avez assez des tutoriels qui ne vont pas au bout des choses ? Ici, vous construisez un système complet.\nVous voulez des compétences recherchées sur le marché ? Ce projet couvre :\n- FastAPI, SQLAlchemy, SQLite,\n- Streamlit, SDK Python, Docker, VSCode,\n- Git, GitHub, Rédaction/Documentation technique,\n- Cloud & bonnes pratiques de déploiement.\nVous cherchez un projet fort pour votre portfolio ? C’est l’exemple parfait à mettre sur votre GitHub.\nVous aimez apprendre et créez des projets ? Apprendre avec un cas concret et Fun, c’est encore mieux.\n\n\nY a-t-il des exigences ou prérequis pour ce cours ?\nUne bonne base en Python est nécessaire (manipulation de fichiers, fonctions, classes).\nQuelques connaissances en SQL et en REST API sont un plus, mais pas obligatoires : tout est expliqué pas à pas.\nÊtre à l’aise avec l’environnement de développement (Jupyter, éditeur de code, terminal).\n\n\nÀ qui ce cours s'adresse-t-il ?\nAux développeurs Python qui veulent aller au-delà de l’analyse de données classique\nAux data analysts ou data engineers souhaitant apprendre à construire des APIs\nAux freelances et consultants qui veulent livrer des projets concrets de bout en bout\nÀ toute personne cherchant un projet moderne, réaliste et impressionnant à ajouter à son portfolio",
      "target_audience": [
        "Aux développeurs Python souhaitant créer et publier des APIs professionnelles.",
        "Aux data scientists et analystes qui veulent valoriser leurs modèles via une API.",
        "Aux passionnés de Data Engineering, MLOps ou produits data-driven.",
        "À toute personne souhaitant maîtriser le cycle de vie complet d’un projet API : de l'idée à la mise en production."
      ]
    },
    {
      "title": "Machine Learning y Ciencia de Datos con Python",
      "url": "https://www.udemy.com/course/practical-machine-learning-and-data-science-with-python/",
      "bio": "Numpy, Pandas, Matplotlib,Seaborn,Plotly, Scikit-Learn, Jupyter, Web Scraping, Google Colab, Redes Neuronales",
      "objectives": [
        "Los fundamentos de Machine Learning y la Ciencia de Datos con un enfoque práctico"
      ],
      "course_content": {},
      "requirements": [
        "Python, algebra lineal, cálculo matemático"
      ],
      "description": "Este es un curso práctico de Machine Learning y Ciencia de Datos con Python en Español. Este curso está dirigido principalmente más no exclusivamente para la comunidad de habla hispana explicando los conceptos que son generados en ingles en español.\nEl curso se caracteriza por ofrecer los conceptos de forma concisa enfocándose en la aplicación práctica de los mismos con muchos ejemplos ilustrativos.\nEl curso requiere de un conocimiento previo del lenguaje de programación en Python así como conocimientos de algebra lineal, cálculo matemático así como uso del sistema operativo Windows.\nEl curso trata de forma ilustrativa los siguientes tópicos:\n- Configuración del entorno de trabajo para el Machine Learning y Data Science.\n- Uso de Jupyter Notebook, Jupyter Lab y Sublime.\n- Revisión del Web Scraping.\n- Recopilación de data y conexión a bases de datos MySQL y SQlite.\n- Principales librerías para Data Science: Numpy, Pandas, Matplotlib, Seaborn y Plotly.\n- Scikit-Learn en Machine Learning.\n- Conceptos de Machine Learning y diferentes algoritmos para clasificación y regresión.\n- Redes Neuronales Artificiales.\n- Machine Learning en la web con Google Colab.\n- Aplicaciones prácticas.\n\n\nEl alumno tiene la oportunidad de formular preguntas o dudas al instructor en cualquier momento a través de los foros de preguntas y respuestas, o por correo electrónico.",
      "target_audience": [
        "Profesionales o estudiantes con dominio de Python que quieran aprender sobre Machine Learning y la Ciencia de Datos"
      ]
    },
    {
      "title": "Máster de Especialista en Ciencia de Datos con el Lenguaje R",
      "url": "https://www.udemy.com/course/master-especialista-ciencia-datos-lenguaje-r/",
      "bio": "Aprenda a desarrollar proyectos de Machine Learning y Deep Learning con el lenguaje R. Data Science de básico a Experto.",
      "objectives": [
        "Aplicar técnicas de análisis y visualización de datos en un conjunto de datos complejo para problemas de machine learning con el lenguaje de programación R.",
        "Aplicar técnicas de tratamiento de datos en un conjunto de datos para mejorar la robustez y métrica de salida de los diferentes algoritmos de machine learning.",
        "Comprender los diferentes mecanismos y técnicas para aplicar analítica predictiva en problemas de machine learning e interpretar la salida dada por los modelos.",
        "Utilizar librerías específicas del lenguaje de programación R como Caret para trabajos de Machine Learning",
        "Desarrollar y analizar proyectos de machine learning, Aprendizaje Supervisado, como regresión, clasificación y multiclase con R con el lenguaje de programación.",
        "Desarrollar y analizar proyectos de machine learning de Aprendizaje No Supervisado con el lenguaje de programación R",
        "Utilizar las técnicas más avanzadas necesarias para desarrollar modelos de Deep Learning de última generación con el lenguaje de programación R.",
        "Aprenderá sobre las redes neuronales FeedForward y cómo desarrollarlas con el lenguaje de programación R y Keras.",
        "Diseñar y Desarrollar Redes Neuronales Convolucionales para proyectos avanzados con el lenguaje de programación R y Keras.",
        "Diseñar y Desarrollar Redes Neuronales Recurrentes para problemas de secuencias o tiempo con el lenguaje de programación R."
      ],
      "course_content": {
        "Introducción a Udemy y bienvenida al curso": [
          "Requisitos previos: Programación en el lenguaje R",
          "Consejos y recomendaciones para usuarios de Udemy",
          "Bloque Machine Learning: Descripción de contenidos",
          "Bloque Deep Learning: Descripción de contenidos",
          "Machine Learning",
          "La plataforma R como nuestro entorno de machine learning.",
          "Competencias en Deep Learning",
          "¡Preséntate!",
          "Para saber más..."
        ],
        "Lenguaje de Programación R y librerías": [
          "Lenguaje de programación R",
          "Primeros pasos con la plataforma R.",
          "Asignaciones con R.",
          "Estructura de datos.",
          "Estructuras de Control.",
          "Uso de Funciones.",
          "Paquetes.",
          "Conjunto de datos Estándar.",
          "Conjunto de Datos mlbench.",
          "Uso de Jupyter como alternativa a RStudio",
          "Tutorial Jupyter Notebook",
          "Para saber más..."
        ],
        "Fase de Análisis de Datos": [
          "Fase de Análisis de Datos",
          "Sesión de teoría - Fuente de datos",
          "Sesión de teoría - Estadística descriptiva",
          "Sesión de teoría - Visualización de datos",
          "Cargar un conjunto de datos.",
          "Estadística descriptiva.",
          "Funciones head(), dim() y sapply ()",
          "Funciones cbind(), summary() y sd()",
          "Funciones skewness() y cor()",
          "Visualización de datos.",
          "Gráficos univarible: Histograma y Densidad.",
          "Gráficos univariable: Boxplot, Barplot.",
          "Gráficos Multivariable: Correlación y Despersión.",
          "Gráficos Multivariables: Densidad y Boxplot.",
          "Para saber más...",
          "Cuestionario de la Unidad"
        ],
        "Fase de tratamiento de datos.": [
          "Fase de tratamiento de datos",
          "Sesión de teoría - Background",
          "Sesión de Teoría - ¿Por qué realizar escalamiento a nuestros datos?",
          "Sesión de teoría - Tipos de escalamiento de datos",
          "Sesión de teoría - Análisis de Componentes Principales (PCA)",
          "Sesión de teoría - Métodos de remuestreo",
          "Sesión de teoría - Evaluación de métricas",
          "Preprocesamiento de datos para machine learning",
          "Escalamiento y Centrado de Datos.",
          "Estandarización y Normalización.",
          "Transformación de Box-Cox y Yeo-Jhonson.",
          "Métodos de Remuestreo.",
          "Métodos de Remuestreo: Porcentaje y Boostrap.",
          "Validación Cruzada y Derivados.",
          "Métricas para Clasificación y Regresión.",
          "Para saber más...",
          "Cuestionario de la Unidad"
        ],
        "Fase de modelado": [
          "Fase de modelado",
          "Sesión de teoría - Feautre Selection",
          "Sesión de teoría - Algoritmos de Machine Learning",
          "Sesión de teoría - Algortimos según Taxonomía",
          "Feature Selection en machine learning",
          "Feature selection basada en correlacion",
          "Feature selection basada en conocimiento.",
          "Algoritmos de machine learning.",
          "Algoritmos LiR y LoR.",
          "Algoritmos LDA y ReR.",
          "Algoritmos k-NN y NB.",
          "Algoritmos SVM y CART.",
          "Para saber más...",
          "Cuestionario de la Unidad"
        ],
        "Fundamentos de Redes Neuronales - Teoría": [
          "Materiales",
          "Unidad Fundamental de aprendizaje - La neurona",
          "Cómo trabaja una neurona",
          "Multilayer Perceptron",
          "Cómo opera el MLP",
          "Backpropagation",
          "Simulación de una arquitectura de red neuronal",
          "Parámetros en redes neronales",
          "Coste, sesgo y activación",
          "Simulación de backpropagation",
          "Análisis del perceptrón multicapa",
          "Análisis de construcción del Perceptron Multicapa",
          "Para saber más..."
        ],
        "Fundamentos de Redes Neuronales - Práctica": [
          "Nuestra primera red neuronal - Instalar librerías",
          "Nuestra primera red neuronal - Crear los datos X e y",
          "Nuestra primera red neuronal - Crear la red neuronal",
          "Desarrollar un MLP para Tidy data - Cargar datos",
          "Desarrollar un MLP para Tidy data - Desarrollar la red neuronal secuencial",
          "Desarrollar un MLP para Tidy data - Evaluar y hacer predicciones",
          "Evaluar el rendimiento de los modelos - Verificación automática",
          "Evaluar el rendimiento de los modelos - Verificación manual",
          "Evaluar el rendimiento de los modelos - validación cruzada",
          "Optimización de parámetros - Evaluar modelos con una función",
          "Optimización de parámetros - Optimización un parámetro",
          "Optimización de parámetros - Optimización de múltiples parámetros",
          "Para saber más...",
          "Evaluación de la unidad temática"
        ],
        "Redes Neuronales Convolucionales - Teoría": [
          "Background",
          "Fundamentos de las CNNs",
          "Operación Convolución",
          "Operación Pooling",
          "Capas Fully-Connected",
          "GPUs para mejorar el rendimiento",
          "Conclusiones sobre CNNs",
          "Para saber más..."
        ],
        "Redes Neuronales Convolucionales - Práctica": [
          "Operación convolución",
          "Operación Convolución - Estudio de linea base",
          "Operación Convolución - Operación convolución",
          "Operación Convolución - Modelo de línea base",
          "Nuestra primera CNN - Procesamiento de imágenes",
          "Nuestra primera CNN - Modelo de línea base",
          "Nuestra primera CNN - Red neuronal convolucional",
          "Nuestra primera CNN - CNN más profunda",
          "Reconocimiento de objetos - Contexto",
          "Reconocimiento de objetos - CNN de modelo base",
          "Reconocimiento de objetos - Arquitectura CNN profunda",
          "Para saber más...",
          "Evaluación de la unidad temática"
        ],
        "Redes Neuronales Recurrentes - Teoría": [
          "Background",
          "Introducción",
          "Redes Feed Forward Vs Redes neuronales recurrentes",
          "Redes Neuronales Recurrentes",
          "Redes LSTM",
          "Para saber más..."
        ]
      },
      "requirements": [
        "Para la realización de este curso (Máster de especialista en Ciencia de datos con el lenguaje R) no ser requieren grandes conocimientos previos, ya que la formación se acomete desde un nivel de usuario 0.",
        "Durante el curso trabajaremos con la última versión del programa, pero no te preocupes si tienes una versión anterior, ya que las distintas versiones difieren muy poco entre sí. Si existe algún cambio importante entre las distintas versiones hablaremos de ello durante la formación.",
        "Para la realización de este curso no vas a necesitar el equipo informático más potente del mercado, ya que el software empleado en la formación se encuentra perfectamente optimizado y su uso es muy fluido en todo tipo de equipos, tanto en PC como en Mac.",
        "Cuando compres el curso vas a poder acceder a las clases cuando y donde quieras. El curso se queda en tu cuenta de Udemy para siempre. :)",
        "El más importante requisito para realizar este curso es el entusiasmo y la motivación por aprender nuevas habilidades que aumenten tus competencias profesionales."
      ],
      "description": "Máster de Especialista en Ciencia de Datos con el Lenguaje R.\nAprenda a desarrollar proyectos de Machine Learning y Deep Learning con el lenguaje R. Data Science de básico a Experto.\nInstructores: PhD. Manuel Castillo.\nRequisitos previos: Antes de realizar el curso se recomienda encarecidamente tener conocimientos de Programación en R. Este es el curso continuación del también curso de Udemy llamado:\nProgramación con el Lenguaje Estadístico R. De 0 a Experto. Aprenda el Lenguaje de Programación Estadístico R. Curso Completo desde Básico hasta Avanzado.\n\n\nDescripción del Curso:\nEl curso de “Máster de especialista en Ciencia de Datos con el lenguaje R” tiene dos bloques principales de estudio:\nEl primer bloque se centra en un subcampo específico de aprendizaje automático llamado modelado predictivo y clustering. Este es el campo del aprendizaje automático que es el más útil en la industria y el cual se utilizar la librería de aprendizaje automático Caret en lenguaje de programación R por su gran rendimiento y facilidad en su uso.\nA diferencia del campo más amplio del aprendizaje automático que podría utilizarse con datos en cualquier formato, el modelado predictivo y clustering se centra principalmente en datos tabulares, llamados técnicamente Tidy Data (por ejemplo, tablas de números como en una hoja de cálculo).\nEl segundo bloque se centra en el aprendizaje profundo. En este curso trataremos la librería Keras de R para Deep Learning y cómo usarla para desarrollar y evaluar modelos de Deep Learning. En este curso, descubriremos las técnicas, código y habilidades de Deep Learning que luego puede llevar a sus propios proyectos de Machine Learning.\nLa librería Keras envuelve la complejidad de la computación numérica de Theano y TensorFlow proporcionando una API concisa que usaremos para desarrollar nuestra propia red neuronal y modelos Deep Learning. Además, trataremos las habilidades de Deep Learning para llevar esta nueva tecnología asombrosa a nuestros propios proyectos.\n\n\nContenidos del Curso:\nMÓDULO I: Introducción\nConceptos básicos de machine learning.\nLa plataforma R como nuestro entorno de machine learning.\nConclusiones\nMÓDULO II: Programación con R\nPrimeros pasos con la plataforma R.\nLenguaje de programación R.\nConjunto de datos Estándar.\nMÓDULO III: Análisis de datos\nCargar un conjunto de datos.\nEstadística descriptiva.\nVisualización de datos.\nMÓDULO IV: Tratamiento de datos\nPreprocesamiento de datos para machine learning.\nMétodos de remuestreo para estimar la precisión del modelo.\nEvaluación de las métricas.\nMÓDULO V: Fase de modelado\nFeature Selection en machine learning\nFeature Importance\nAlgoritmos de Machine Learning.\nMÓDULO VI. Redes Neuronales.\nCurso sobre Multilayer Perceptron\nRedes Feed Forward\nDesarrollar nuestra primera red neuronal con Keras.\nEvaluar el rendimiento de los modelos.\nProyecto: Problema de clasificación multiclase.\nProyecto: Problema de regresión.\nMÓDULO VII. Redes Neuronales Convolucionales\nFundamentos de las CNNs\nOperación convolución y Pooling\nCapas totalmente conectadas\nBackpropagation y Gadiente descendiente\nCoste, sesgo y activación.\nCapas totalmente conectadas\nPadding y Stride.\nMÓDULO VIII. Redes Neuronales Recurrentes\nCurso intensivo en redes neuronales recurrentes.\nModelos de perceptrones multicapa para problemas de series de tiempo.\nModelos LSTM para problemas de series temporales.\nProyecto: Clasificación secuencial de reseñas de películas.\nProyecto: Generación de texto.\nCaracterísticas del Curso:\nRecuerda que esta formación incluye lecciones en vídeo fullHD con audio de estudio (compatible con TV, PC, Mac, tablet y smartphone), artículos didácticos, actividades, proyectos paso a paso, recursos descargables, links de interés, acceso de por vida, certificado de finalización, tutorización online, y una exclusiva comunidad de aprendizaje privada que nos ayudamos aportando nuestras experiencias en el foro de comunicación del curso.\nCon esta formación disfrutarás aprendiendo desde dónde quieras, sin tener que desplazarte, sin horarios, con quién quieras, según tus necesidades y disponibilidad. Aprenderás con un instructor avalado por miles da alumnos satisfechos en todo el mundo (comentarios certificados). Conocerás las técnicas, métodos, trucos y flujos de trabajo de este sector creativo. El docente te transmitirá su sabiduría y conocimientos con pasión a la vez que las explicaciones concisas, claras, sencillas y con un enfoque profesional en cada clase. Podrás conseguir un  certificado homologado personalizado y firmado por tu instructor en cada formación. De está forma podrás compartir tu título en tu portafolio, currículo, en redes sociales...\nCon la alta definición de los vídeos (vídeo fullHD y audio de estudio) conseguirá no te perder detalle. Podrás ver las clases las veces que requieras para recordar y perfeccionar tus habilidades como diseñador. Tendrás la posibilidad de preguntar, pedir opinión y ayuda al instructor, además de compartir tu experiencia de aprendizaje con los demás alumnos del curso, tan apasionados como tú, repartidos por todo el mundo. Seleccionamos cuidadosamente los contenidos y producimos cada curso para garantizar una experiencia de aprendizaje online integral y de la máxima calidad.\n\n\n¿A qué esperas?, este curso es ideal para ti, atrévete a convertirte en un experto. Adelante, nos vemos dentro de la formación.",
      "target_audience": [
        "Aquellos usuarios del programa que quieran ampliar el dominio de mismo y conocer múltiples trucos, consejos y recursos para esta herramienta.",
        "Principalmente aquellos que quieran aumentar sus posibilidades de empleabilidad, contratación y/o promocionar dentro de su sector.",
        "Entusiastas de la Inteligencia Artificial y, sobre todo, de Ciencia de Datos",
        "Desarrolladores de modelos de Machine learning y Deep learning"
      ]
    },
    {
      "title": "深度学习经典（论文精讲-源码解读）",
      "url": "https://www.udemy.com/course/dl-paper/",
      "bio": "论文详解+项目复现",
      "objectives": [
        "掌握当下深度学习经典论文思想",
        "掌握论文核心知识点与应用领域",
        "熟练使用深度学习框架进行论文复现",
        "掌握大型开源项目源码架构",
        "掌握自然语言处理核心论文-BERT模型",
        "掌握NLP核心架构-transformer",
        "掌握NLP主流attention机制",
        "熟练掌握BERT架构源码与实现细节",
        "基于BERT模型构建自然语言处理通用框架",
        "掌握物体检经典论文-MaskRcnn",
        "掌握MaskRcnn项目源码架构",
        "熟练将自己的图像识别与检测任务应用到mask rcnn架构中",
        "熟练使用maskRcnn进行项目开发",
        "掌握计算机视觉经典论文及其项目复现",
        "掌握自然语言处理经典论文及其源码复现",
        "课程内容均包括论文思想分析及其源码解读"
      ],
      "course_content": {
        "课程介绍与BenchMark导读": [
          "课程介绍",
          "论文与开源项目的重要性"
        ],
        "NLP必备经典论文-BERT论文解读": [
          "论文讲解思路概述",
          "BERT模型摘要概述",
          "模型在NLP领域应用效果",
          "预训练模型的作用",
          "输入数据特殊编码字符解析",
          "向量特征编码方法",
          "BERT模型训练策略",
          "论文总结分析",
          "数据代码下载"
        ],
        "自然语言处理通用框架BERT原理解读": [
          "BERT任务目标概述",
          "传统解决方案遇到的问题",
          "注意力机制的作用",
          "self-attention计算方法",
          "特征分配与softmax机制",
          "Multi-head的作用",
          "位置编码与多层堆叠",
          "位置编码与多层堆叠",
          "BERT模型训练方法",
          "训练实例",
          "数据代码下载"
        ],
        "谷歌开源项目BERT源码解读与应用实例": [
          "BERT开源项目简介",
          "项目参数配置",
          "数据读取模块",
          "数据预处理模块",
          "tfrecord制作",
          "Embedding层的作用",
          "加入额外编码特征",
          "加入位置编码特征",
          "mask机制",
          "构建QKV矩阵",
          "完成Transformer模块构建",
          "训练BERT模型",
          "数据代码下载"
        ],
        "基于BERT的中文情感分析实战": [
          "训练BERT中文分类模型",
          "读取处理自己的数据集",
          "训练BERT中文分类模型",
          "数据代码下载"
        ],
        "基于BERT的中文命名实体识别实战": [
          "命名实体识别数据分析与任务目标",
          "NER标注数据处理与读取",
          "构建BERT与CRF模型",
          "数据代码下载"
        ],
        "BERT基础补充-词向量模型": [
          "词向量模型通俗解释",
          "模型整体框架",
          "训练数据构建",
          "CBOW与Skip-gram模型",
          "负采样方案",
          "数据代码下载"
        ],
        "物体检测经典框架MaskRcnn论文解读": [
          "物体检测通用框架论文整体概述",
          "MaskRcnn创新点介绍",
          "网络结构分析",
          "总结概述"
        ],
        "物体检测框架-MaskRcnn项目介绍与配置": [
          "Mask-Rcnn开源项目简介",
          "开源项目数据集",
          "参数配置",
          "数据代码下载"
        ],
        "MaskRcnn网络框架源码详解": [
          "FPN层特征提取原理解读",
          "FPN网络架构实现解读",
          "生成框比例设置",
          "基于不同尺度特征图生成所有框",
          "RPN层的作用与实现解读",
          "候选框过滤方法",
          "Proposal层实现方法",
          "DetectionTarget层的作用",
          "正负样本选择与标签定义",
          "RoiPooling层的作用与目的",
          "RorAlign操作的效果",
          "整体框架回顾"
        ]
      },
      "requirements": [
        "熟悉Python,熟悉深度学习"
      ],
      "description": "深度学习经典论文解读与项目实战课程旨在帮助同学们掌握当下深度学习领域最核心论文思想及其源码实现。所选论文均是计算机视觉与自然语言处理领域最流行和通用算法，主要内容包括四大核心部分：1.论文核心思想解读；2.论文细节知识点精讲；3.论文代码复现与应用；4.大型开源项目源码解读；整体风格通俗易懂，所有论文均结合实战项目展开，理论与实战应用完美结合，适合进阶提升与转行就业的同学们。",
      "target_audience": [
        "人工智能方向进阶提升的同学们"
      ]
    },
    {
      "title": "RAG-Agenten: Baue Apps & GPTs mit APIs, MCP, LangChain & n8n",
      "url": "https://www.udemy.com/course/rag-agenten-baue-apps-gpts-mit-apis-mcp-langchain-n8n/",
      "bio": "KI Agenten & LLMs mit RAG: n8n, LangChain, LangGraph, Flowise, MCP & mehr – mit ChatGPT, Gemini, Claude, DeepSeek & Co",
      "objectives": [
        "Einführung in RAG-Workflows & Tools wie NotebookLM von Google mit wichtigen Tipps",
        "LLM‑Grundlagen & RAG-Technologien: ChatGPT, Claude, Gemini, Deepseek, Llama, Mistral, xAI, Grok, Function Calling, Vektordatenbanken & Embeddings & Chunking)",
        "ChatGPT Basics & Modell‑Management: Interface, Modelle, Einstellungen, GPTs, OpenAI Playground & Test‑Time‑Compute",
        "RAG‑Chatbots mit Custom GPTs bauen: Datenaufbereitung von PDFs, HTML‑Webseiten, YouTube‑Videos, CSV‑Datenquellen & Schreibstil‑Anpassung",
        "Open‑Source‑RAG mit Ollama & AnythingLLM: Installation, Modelle, Chunking, Embeddings optimieren & lokalen Bot erstellen",
        "Agenten‑Funktionen & Multi‑LLM‑Integration: Systemprompts, Temperatursteuerung, Websuche, Scraping & KI Agenten‑Capabilities mit Flowise/LangGraph",
        "OpenAI API & Flowise für RAG‑Agenten: Preise, Projekt‑Setup, DSGVO, Playground vs. Response API, Node.js‑Installation, Flowise‑Marketplace & OpenAI‑Assistant",
        "Erweiterte Flowise‑Workflows: Web‑Scraping, Embeddings, Vektordatenbank, HTML‑Splitter, JSON‑Import/Export & Tool‑Agent mit E‑Mail, Kalender, Airtable, Webhooks",
        "Eigene Chatbot‑UI & Self‑Hosting: Frontend‑Entwicklung, Ollama & LangChain, Render‑Hosting, Replit‑Branding, WordPress‑Integration & Flowise‑Einstellungen",
        "RAG‑Agenten mit n8n: Lokale Installation, Interface, Trigger/Aktionen, Pinecone‑Automatisierung via Google Drive, Workflows & AI‑Agent‑Node",
        "Flowise & n8n kombinieren & vermarkten: RAG‑Lead‑Bots, Webseiten‑Integration, CSS‑Branding, Verkauf, Marketing, Kundengewinnung & Angebotsstrategien",
        "Spezielle RAG‑Strategien: n8n MCPs mit Claude Desktop, Webhooks, GPT Actions, Cache‑Augmented Generation, GraphRAG, LightRAG & Contextual Retrieval",
        "Sicherheit, Datenschutz & rechtliche Rahmenbedingungen: Jailbreaks, Prompt Injections, Data Poisoning, Censorship, DSGVO‑Basics, EU AI‑Act & Copyright",
        "Strategien führender KI‑Anbieter & im Vergleich: OpenAI, Anthropic, Microsoft, Google xAI, Metas LlaMA, Deepseek, Mistral & Co"
      ],
      "course_content": {
        "Einführung: Tipps, Vorstellung & der einfachste Start mit RAG – NotebookLM": [
          "Willkommen!",
          "Kurs Überblick",
          "Wichtige Tipps für den Kurs",
          "Erklärung der Links für den Kurs",
          "Wichtige Links",
          "Dozentenvorstellung: Arnold Oberleiter (Arnie)",
          "Schneller Einstieg in RAG: Nutze NotebookLM von Google"
        ],
        "Grundlagen: LLMs, RAG, Vektordatenbanken & das ChatGPT-Interface erklärt": [
          "Darum geht es in diesem Abschnitt",
          "LLMs erklärt: ChatGPT, Claude, Gemini, Deepseek, Llama, Mistral & mehr.",
          "Function Calling: wie LLMs mit APIs kommunizieren dank den \"Tools\"",
          "Vektordatenbanken, Embedding-Modelle und Retrieval-Augmented Generation (RAG)",
          "Mehr technische Details",
          "ChatGPT Basics: Interface, Modelle, Einstellungen, GPTs und OpenAI Playground",
          "Test Time Compute erklärt: Modelle wie OpenAI o1, o3 oder Deepseek R1",
          "Recap: Das solltest du dir merken"
        ],
        "RAG ganz einfach – mit ChatGPT und Custom GPTs umsetzen": [
          "Das lernst du in diesem Abschnitt",
          "Erster RAG-Bot aus PDFs mit GPTs: Daten vorbereiten & Systemprompts",
          "HTML-Webseite in einen RAG-Chatbot verwandeln",
          "RAG-Bot aus einem YouTube-Video erstellen",
          "Trainiere ChatGPT an deinem Schreibstil dank Retrieval-Augmented Generation",
          "CSV-Datei als Datenquelle für einen RAG-Bot nutzen",
          "Was du alles mit GPTs machen kannst",
          "Recap: Was du gelernt hast"
        ],
        "RAG umsetzen mit Open-Source-LLMs: AnythingLLM & Ollama": [
          "Das lernst du in diesem Abschnitt",
          "Ollama-Grundlagen: Installation, Modelle, Befehle & Hardware-Voraussetzungen",
          "AnythingLLM Grundlagen: Integration mit Ollama, Chunking & Embedding optimieren",
          "Lokalen RAG-Chatbot erstellen mit AnythingLLM und Ollama",
          "Sprache & Verhalten mit Systemprompts und Temperatur gezielt steuern",
          "Agenten-Funktionen im Überblick: Websuche, Scraping & mehr",
          "Das Wichtigste auf einen Blick zum Ollama und AnythingLLM Rag"
        ],
        "RAG-Chatbots & Agenten mit der OpenAI API: LangChain & LangGraph in Flowise": [
          "Das erwartet dich in diesem Abschnitt",
          "OpenAI API erklärt: Preise, Projekt-Setup, Verwaltung & DSGVO",
          "OpenAI Playground und Response API: RAG so einfach wie möglich",
          "LangChain vs. LangGraph vs. Flowise",
          "Node.js installieren und verwalten für Flowise",
          "Installation von Flowise mit Node.js und Updates machen",
          "Flowise Interface, Marketplace & OpenAI Assistant: Langchain leicht gemacht",
          "RAG-Chatflow mit Web Scraping, Embeddings, Vektordatenbank und HTML-Splitter",
          "Flows als Jason exportieren und importieren",
          "Eigene Chatbot UI: Interface & Frontend für Flowise machen",
          "Technische Details und Infos zu Rag & Top K (Ist Rag überflussig)",
          "RAG-Chatbot lokal betreiben mit Ollama & LangChain (Datensicherheit)",
          "Tool-Agent in Flowise: E-Mails, Kalender, Airtable, Webhooks & mehr",
          "Pinecone-Vektordatenbank zum Tool-Agent für RAG mit Supabase und Postgres",
          "Probleme bei Pinecone Embeddings",
          "Prompt Engineering: Systemprompts für KI-Agenten und Rag Agenten",
          "KI-Agenten mit mehreren LLMs und RAG",
          "Sequenzielle Agenten mit Human-in-the-Loop und agentischem RAG",
          "Recap: Die wichtigsten Learnings"
        ],
        "RAG-Chatbots & Agenten mit n8n erstellen": [
          "Das lernst du in diesem Abschnitt: n8n!",
          "Lokale Installation von n8n mit Node.js und das Interface",
          "n8n-Updates machen lokal über Node.js",
          "n8n Basics: Trigger, Aktionen, Nodes, Modelle und mehr",
          "n8n & RAG: Pinecone-Datenbank automatisch mit Google Drive aktualisieren",
          "n8n-Workflows einfach exportieren & importieren (JSON-Format)",
          "RAG-Chatbot bauen mit AI-Agent-Node, Vektordatenbank und mehr",
          "Zusätzliche Tools für deinen RAG-Agenten im Überblick",
          "Webseite zu RAG-Chatbot durch HTML-Requests und Scraping",
          "Dein Überblick am Ende des Abschnitts"
        ],
        "RAG-Apps mit Flowise & n8n: Hosten und verkaufen leicht gemacht": [
          "Was lernen wir in diesem Abschnitt?",
          "Flowise auf Render hosten: Schritt für Schritt",
          "Einfacher Rag Chatbot in Flowise mit dem OpenAI Assistent",
          "Chatbot Branding auf Replit verbessern und anpassen",
          "Rag-ChatBot in Wordpress Seite einbauen",
          "Weitere Einstellungen deiner LangChain-App mit Flowise",
          "n8n hosten: Self-Hosting mit Render & andere Optionen",
          "n8n RAG-Lead-Bot als Standalone-App mit einer veröffentlichten URL",
          "n8n RAG-Bot in Webseiten integrieren: HTML, WordPress & Branding mit CSS",
          "Rag-Agenten verkaufen: Marketing, Kundengewinnung, Angebot, Verkauf, Boni & mehr",
          "Recap zum Hosting und Verkauf von Rag-Agenten"
        ],
        "Erweiterte Workflows: Webhooks, MCPs, Claude, GPTs, RAG & Chunking Strategien": [
          "Das erwartet dich: Spezielle Workflows, fortgeschrittene RAG Techniken & MCP",
          "n8n MCPs in Claude Desktop (Model Context Protocol) MCP Server & MCP Client",
          "Code für Claude Desktop und das Model Context Protocol (MCP)",
          "ChatGPT mit n8n über Webhooks verknüpfen für KI-Automatisierungen",
          "Code für GPT Actions",
          "Flowise mit n8n verbinden: Webhooks & Google Sheets per JavaScript einbinden",
          "Cache-Augmented Generation (CAG)",
          "GraphRAG (Microsoft) Präzisere RAG-Ergebnisse durch Wissensgraphen",
          "LightRAG: Schnelle & kostengünstige Alternative zu GraphRAG",
          "Contextual Retrieval: RAG verbessern durch die Chunking Strategie von Anthropic",
          "Die passende RAG-Strategie finden: GraphRAG, LightRAG, CAG, oder Contextual RAG?",
          "Recap zu speziellen Workflows, fortgeschrittenen RAG-Strategien & MCP"
        ],
        "Probleme, Sicherheit und Copyrights bei Rag-Agenten": [
          "Das sehen wir uns an und die ersten Probleme im Überblick",
          "Sicherheitsprobleme mit Telegram in n8n",
          "Jailbreaks: Angriffe auf LLMs und deine Agenten mit Prompts",
          "Prompt Injections als Angriff auf Agenten und LLMs",
          "Data Poisoning, Backdoor Attacks und Zensuren",
          "Copyrights & Urheberrechte von generierten Daten der Workflows",
          "Datenschutz für eigene Daten und Kundendaten, DSGVO, EI-AI-Act",
          "Weitere Infos zur DSGVO und dem EU-KI-Act",
          "Deine GPTs können \"gehackt\" werden",
          "DSGVO Basics",
          "DSGVO: Die wichtigsten Infos in einem großen Artikel",
          "EU AI-Act: Die wichtigsten Infos in einem großen Artikel",
          "Rechtsgrundlagen-KI-v2.0",
          "Rückblick: Wichtige Punkte, die du dir merken solltest"
        ],
        "Wie geht es weiter?": [
          "Recap, Dankeschön und wie geht es weiter?",
          "Bonus"
        ]
      },
      "requirements": [
        "Keine Vorkenntnisse nötig, alles wird Schritt für Schritt gezeigt"
      ],
      "description": "Eines der wichtigsten Konzepte in der KI-Welt heißt RAG – Retrieval-Augmented Generation!\nDu musst LLMs Wissen geben!\nDoch wie baust du selbst leistungsfähige RAG-Chatbots und intelligente KI-Agenten, um deine Geschäftsprozesse und privaten Projekte zu optimieren?\nIn diesem Kurs erfährst du es – umfassend und verständlich erklärt, mit ChatGPT, Claude, Google Gemini, Open-Source-LLMs, LangGraph/Flowise, n8n und mehr!\n\n\nGrundlagen: LLMs, RAG & Vektordatenbanken\nBaue ein solides Fundament für deine KI-Projekte:\nVertiefe dein Wissen über LLMs: ChatGPT, Claude, Gemini, Deepseek, Llama, Mistral und viele mehr.\nVerstehe, wie Function Calling und API-Kommunikation bei LLMs funktioniert.\nErfahre, wie Vektordatenbanken und Embedding-Modelle das Herzstück von RAG bilden.\nMeistere das ChatGPT-Interface, GPT-Modelle, Einstellungen und den OpenAI Playground.\nLerne wichtige Konzepte wie Test Time Compute (OpenAI o1, o3, Deepseek R1).\nEntdecke, wie Googles NotebookLM funktioniert und nutze es effektiv für RAG-Projekte.\nEinfache RAG-Umsetzungen mit ChatGPT & Custom GPTs\nGestalte deine ersten KI-Anwendungen schnell und unkompliziert:\nErstelle deinen ersten RAG-Bot aus PDFs mit Custom GPTs.\nVerwandeln HTML-Webseiten und YouTube-Videos in interaktive RAG-Chatbots.\nTrainiere ChatGPT auf deinen persönlichen Schreibstil mithilfe von RAG.\nNutze CSV-Daten für intelligente Chatbots und entdecke die Möglichkeiten von Custom GPTs.\nRAG mit Open-Source-LLMs: AnythingLLM & Ollama\nSteige in die Welt lokaler KI ein:\nInstalliere und nutze Ollama: lerne Modelle, Befehle und Hardware-Anforderungen kennen.\nIntegriere AnythingLLM effektiv mit Ollama, optimiere Chunking und Embeddings.\nBaue lokale RAG-Chatbots und steuere Sprache sowie Verhalten gezielt mit Systemprompts und Temperatur-Einstellungen.\nNutze Agenten-Funktionen wie Websuche, Scraping und vieles mehr.\nFlowise: RAG mit LangChain & LangGraph leicht gemacht\nNutze die Kraft der OpenAI-API für professionelle Anwendungen:\nBeherrsche die OpenAI API, Preismodelle, DSGVO-Konformität und das Projektsetup.\nErstelle effiziente RAG-Anwendungen über den OpenAI Playground und Response APIs.\nLerne Flowise installieren, Updates durchführen und meistere das Interface inklusive Marketplace und OpenAI Assistant.\nErstelle umfassende RAG-Chatflows inklusive Web Scraping, Embeddings, HTML-Splitter und Vektordatenbanken.\nEntwickle ein eigenes Chatbot UI und manage Flowise technisch detailliert.\nNutze lokale KI-Sicherheit mit Ollama & LangChain sowie Tool-Agenten in Flowise (z. B. E-Mails, Kalender, Airtable).\nKombiniere Pinecone-Vektordatenbanken mit Supabase und Postgres.\nMeistere Prompt Engineering und sequenzielle Agenten mit Human-in-the-Loop-Verfahren.\nn8n: KI-Automationen & RAG-Agenten erstellen\nNutze n8n als mächtige Automatisierungsplattform für deine KI-Projekte:\nLerne lokale Installation, Updates und n8n-Basics kennen.\nAutomatisiere deine Pinecone-Datenbank-Updates mit Google Drive.\nEntwickle RAG-Chatbots mit AI-Agent-Nodes, Vektordatenbanken und Zusatztools.\nErstelle automatisierte Chatbots aus Webseiten durch HTML-Requests und Scraping.\nHosting, Verkauf & Monetarisierung deiner RAG-Agenten\nBringe deine KI-Projekte professionell auf den Markt:\nHoste Flowise und n8n-Apps einfach auf Plattformen wie Render und integriere diese in Webseiten (HTML, WordPress).\nGestalte professionelle Chatbots mit eigenem Branding und biete sie als Dienstleistungen oder eigenständige Lösungen an.\nEntwickle erfolgreiche Marketing- und Verkaufsstrategien für deine KI-Agenten.\nFortgeschrittene Workflows & spezielle RAG-Techniken\nSetze auf professionelle, innovative Technologien:\nLerne fortgeschrittene Techniken wie Webhooks, MCPs mit Claude, GPT Actions und n8n-Integration kennen.\nVerstehe das MCP (Model context protocol) und baue MCP Server und MCP Client in n8n und Claude Desktop.\nErkunde innovative RAG-Strategien wie Cache-Augmented Generation (CAG), GraphRAG (Microsoft), LightRAG und Contextual Retrieval von Anthropic.\nOptimire Chunking, Embedding und Top-K für deine RAG Apps.\nWähle die richtige Strategie für deine Projekte und optimiere dein RAG-Ergebnis.\nSicherheit, Datenschutz & rechtliche Grundlagen\nSchütze deine KI-Projekte effektiv:\nErkenne Sicherheitsrisiken (Telegram, Jailbreaks, Prompt Injections, Data Poisoning).\nSichere deine KI gegen Angriffe und beachte Copyrights bei generierten Daten.\nVertiefe dein Wissen zu DSGVO und EU AI-Act, um rechtssicher zu agieren.\nWerde Experte für KI-Automationen, AI-Agenten & RAG!\nNach diesem Kurs bist du optimal vorbereitet, um RAG-Chatbots, KI-Agenten und Automationen aufzubauen, zu optimieren und erfolgreich zu vermarkten.",
      "target_audience": [
        "Privarpersonen, die an KI und Automatisierung interessiert sind und eigene RAG-Agenten bauen möchten",
        "An Unternehmer die effizienter werde wollen, Geld sparen möchten oder ein KI-Business aufbauen wollen",
        "An alle, die etwas neues lernen wollen und tief in RAG-Agenten einblicken wollen",
        "Jeder, der Rag endlich verstehen will und Aufgaben automatisieren möchte"
      ]
    },
    {
      "title": "Data Science dalam Satu Minggu",
      "url": "https://www.udemy.com/course/data-science-dalam-satu-minggu/",
      "bio": "Menguasai Dasar-dasar Data Science dengan Cepat & Efisien dalam satu minggu! Kursus Dirancang untuk Orang Sibuk",
      "objectives": [
        "Melakukan analisis statistik pada jenis data yang anda akan temukan di dunia nyata",
        "Memahami strategi dan tools untuk melakukan rekayasa fitur (feature engineering)",
        "Menerapkan One-Hot Encoding dan normalisasi data",
        "Memahami perbedaan antara normalisasi dan standardisasi data",
        "Menangani data yang hilang (missing value) menggunakan Pandas",
        "Mengubah tipe data pada Pandas DataFrame",
        "Mendefinisikan fungsi dan menerapkannya pada kolom di Pandas DataFrame",
        "Menerapkan berbagai operasi dan pemfilteran pada Pandas DataFrame",
        "Menghitung dan menampilkan peta panas (heatmap) dari matriks korelasi",
        "Melakukan visualisasi data menggunakan Seaborn dan Matplotlib",
        "Membuat plot garis tunggal, diagram lingkaran, dan beberapa subplot menggunakan Matplotlib",
        "Membuat pairplot, countplot, dan peta panas (heatmap) dari matriks korelasi menggunakan Seaborn",
        "Membuat distribusi plot (distplot), histogram dan grafik sebar (scatter plot)",
        "Memahami dasar-dasar regresi dalam Machine Learning",
        "Memelajari cara mengoptimalkan parameter model menggunakan metode Jumlah Kuadrat Terkecil (least sum of squares)",
        "Melakukan pemisahan data latih dan uji menggunakan SKLearn",
        "Membuat visualisasi data dan melakukan analisis data eksploratif",
        "Membangun, melatih, dan menguji model regresi pertama-mu di Scikit-Learn",
        "Mengukur kinerja model regresi Machine Learning yang telah dilatih",
        "Memahami teori dan intuisi di balik algoritma boosting",
        "Melatih algoritma XG-boost di Scikit-Learn dalam konteks pemodelan regresi",
        "Melatih beberapa model klasifikasi Machine Learning seperti Logistic Regression, Support Vector Machine, K-Nearest Neighbors, dan Random Forest Classifier",
        "Mengukur performa model yang telah dilatih menggunakan berbagai Key Performance Indicators (KPI) seperti akurasi, presisi, recall, skor F1, AUC, dan ROC.",
        "Melakukan perbandingan kinerja model klasifikasi menggunakan berbagai KPI.",
        "Menerapkan AutoGluon untuk menyelesaikan masalah jenis regresi dan klasifikasi",
        "Menggunakan AutoGluon untuk membangun model AI/ML hanya dengan beberapa baris kode",
        "Menampilkan plot performa berbagai model di papan peringkat model",
        "Mengoptimalkan hyperparameter model regresi dan klasifikasi menggunakan SK-Learn",
        "Pelajari perbedaan antara berbagai strategi pengoptimalan hyperparameter seperti grid search, random search, dan Bayesian optimization.",
        "Melakukan pengoptimalan hyperparameter menggunakan Scikit-Learn.",
        "Memahami bias-variance trade-off serta regularisasi L1 dan L2"
      ],
      "course_content": {
        "Informasi Kursus & Starter Pack Data Science": [
          "Pesan Selamat Datang",
          "Perkenalan dan Tips Sukses Kursus",
          "Skema Pembelajaran",
          "Apa Itu Data Science",
          "Profil, Edukasi, Pengalaman, Pekerjaan, & Tech Seorang Data Scientist",
          "Apa yang Dikerjakan Data Scientist",
          "Apa yang Dicari Perekrut Kerja",
          "Apa saja jenis pekerjaan Data Science yang tersedia"
        ],
        "Day 1: Data Wrangling, EDA, dan Rekayasa-Fitur": [
          "Pesan Selamat Datang",
          "Tinjauan Proyek, EDA & Data Wrangling",
          "Tugas 1. Impor Dataset dan Lakukan Analisis Data Statistik Dasar",
          "Latihan 1",
          "Tugas 2. Menghadapi Data Yang Hilang (Missing Values)",
          "Latihan 2",
          "Tugas 3. One-Hot-Encoding",
          "Latihan 3",
          "Penskalaan Fitur",
          "Tugas 4. Normalisasi dan Standardisasi",
          "Latihan 4",
          "Tugas 5. Operasi Filtering Pandas",
          "Latihan 5",
          "Tugas 6. Menerapkan EDA pada Kedua Kelas Kategori",
          "Latihan 6",
          "Tugas 7. Pandas dengan Fungsi",
          "Latihan 7",
          "Tugas 8. Histogram dan Korelasi",
          "Latihan 8",
          "Final Capstone Project",
          "Solusi Final Capstone Project",
          "Kesimpulan Day 1"
        ],
        "Day 2: Visualisasi Data Yang Efektif Dalam Data Science": [
          "Pesan Selamat Datang",
          "Tinjauan Proyek",
          "Visualisasi Data 101",
          "Tugas 1. Plot Pie Chart dengan Matplotlib",
          "Latihan 1",
          "Latihan 2",
          "Plot Single & Multiple Line Plots dengan Matplotlib",
          "Plot Scatterplot dengan MatplotlibEnter Video Project Name",
          "Latihan 3",
          "Plot Histogram dengan Matplotlib",
          "Latihan 4",
          "Seaborn Part 1",
          "Latihan 5",
          "Seaborn Part 2",
          "Latihan 6",
          "Final Capstone Project",
          "Solusi Final Capstone Project",
          "Kesimpulan Day 2"
        ],
        "Day 3: Analisis Regresi Dalam Data Science": [
          "Pesan Selamat Datang",
          "Tinjauan Proyek",
          "Apa Itu Regresi",
          "Apa Itu XGBoost dan Mengapa",
          "Tugas 1. Impor Library dan Data",
          "Latihan 1",
          "Tugas 2. EDA dan Visualisasi Data",
          "Latihan 2",
          "Tugas 3. Persiapan Data sebelum Pelatihan Model",
          "Latihan 3",
          "Tugas 4. Latih dan Evaluasi Algoritma XGBoost",
          "Latihan 4",
          "Final Capstone Project",
          "Solusi Final Capstone Project",
          "Kesimpulan Day 3"
        ],
        "Day 4: Analis Klasifikasi Dalam Data Science": [
          "Pesan Selamat Datang",
          "Tinjauan Proyek",
          "Metrik Model Klasifikasi",
          "Tugas 1. Impor Library dan Data",
          "Latihan 1",
          "Tugas 2. Visualisasi Data",
          "Latihan 2",
          "Tugas 3. Feature Importance",
          "Tugas 4. Regresi Logistik",
          "Latihan 3",
          "Tugas 5. Support Vector Machine",
          "Tugas 6. Random Forest Classifier",
          "Tugas 7. KNN",
          "Latihan 4",
          "Tugas 8. Naive Bayes",
          "Latihan 5",
          "Tugas 9. Membandingkan Model Klasifikasi",
          "Tugas 10. Kata Penutup",
          "Final Capstone Project",
          "Solusi Final Capstone Project - Part 1",
          "Solusi Final Capstone Project - Part 2",
          "Solusi Final Capstone Project - Part 3",
          "Kesimpulan Day 4"
        ],
        "Day 5: Data Science Dengan AutoPilot": [
          "Pesan Selamat Datang",
          "Tinjauan Proyek",
          "AutoGluon",
          "Tugas 1. Import AutoGluon",
          "Latihan 1",
          "Tugas 2. Lakukan EDA",
          "Latihan 2",
          "Tugas 3. Visualisasi Data",
          "Latihan 3",
          "Tugas 4. Latih Model Regresi dengan AutoGluon",
          "Tugas 5. Evaluasi Kinerja Model Terlatih",
          "Latihan 4",
          "Final Capstone Project",
          "Solusi Final Capstone Project",
          "Kesimpulan Day 5"
        ],
        "Day 6: Optimasi Model": [
          "Pesan Selamat Datang",
          "Tinjauan Proyek",
          "Hiperparameter 101",
          "Strategi Optimasi",
          "Tugas 1. Impor Library dan Data",
          "Latihan 1",
          "Tugas 2. Data Cleaning",
          "Tugas 3. Visualisasi Data",
          "Latihan 2",
          "Tugas 4. Pemisahan Data Latih dan Uji",
          "Tugas 5. Latih Model XGBoost",
          "Latihan 3",
          "Tugas 6. Optimasi Model dengan Grid Search",
          "Latihan 4",
          "Tugas 7. Optimasi Model dengan Random Search",
          "Tugas 8. Optimasi Model dengan Bayesian Search",
          "Final Capstone Project",
          "Solusi Final Capstone Project",
          "Kesimpulan Day 6"
        ],
        "Day 7: Deep Learning": [
          "Tinjauan Proyek - Klasifikasi Makanan dengan AI",
          "Demo 1. Datarobot - Unggah & Eksplorasi Data",
          "Demo 2. Datarobot - Latih Model",
          "Demo 3. Datarobot - Explainable AI"
        ]
      },
      "requirements": [
        "Keterampilan pemrograman dasar dengan Python"
      ],
      "description": "Apakah Anda ingin mempelajari Data Science dan membangun aplikasi yang menarik dan aplikatif dengan Cepat dan Efisien?\nApakah Anda tidak memiliki background terkait Data Science dan ingin masuk ke bidang ini dan mencari kursus yang mencakup semua dasar-dasar yang Anda butuhkan?\nApakah Anda calon pengusaha yang ingin memaksimalkan pendapatan bisnis dan mengurangi biaya dengan Data Science tetapi tidak tahu cara mencapainya dengan cepat dan efisien?\n\n\nJika jawabannya ya untuk pertanyaan-pertanyaan sebelumnya, maka kursus ini tepat untuk Anda!\nData Science adalah salah satu bidang teknologi paling menarik saat ini!\nBidang ini menawarkan peluang dan prospek karir yang sangat menjanjikan.\nData Science telah diadopsi secara luas di banyak sektor seperti perbankan, kesehatan, transportasi, teknologi, dan banyak lagi.\nDalam bisnis, Data Science diterapkan untuk mengoptimalkan proses bisnis, memaksimalkan pendapatan, dan mengurangi biaya.\nKursus ini bertujuan untuk memberi Anda pengetahuan tentang aspek-aspek penting dari Data Science dalam satu minggu dan dengan cara yang praktis, mudah, cepat, dan efisien.\nKursus ini berbeda dan lebih baik dari kursus-kursus lainnya dalam banyak hal.\nDalam kursus ini, anda tidak akan hanya mendapatkan ilmu secara satu arah, tapi anda juga akan mendapatkan kesempatan untuk mengerjakan latihan, kuis, dan proyek-proyek capstone.\nSetiap hari, kita akan meluangkan waktu 1-2 jam bersama untuk menguasai topik Data Science.\nPertama, kita akan memulai kursus dengan starter pack penting Data Science guna menguasai konsep-konsep penting Data Science, termasuk siklus hidup proyek Data Science, apa yang dicari perekrut kerja, dan jenis pekerjaan apa saja yang tersedia.\nSelanjutnya, kita akan memahami analisis data eksploratif dan teknik visualisasi menggunakan Pandas, Matplotlib, dan Seaborn.\nBerikutnya, kita akan belajar tentang dasar-dasar regresi, kita akan belajar cara membuat, melatih, menguji, dan menerapkan model regresi menggunakan Scikit Learn.\nKemudian, kita akan belajar tentang berbagai strategi optimasi hyperparameter seperti grid search, random search, dan Bayesian optimization.\nSelanjutnya, kita akan mempelajari cara melatih beberapa algoritma klasifikasi seperti Logistic Regression, Support Vector Machine, K-Nearest Neighbors, Random Forest Classifier, dan Naïve Bayes di SageMaker dan SK-Learn.\nLalu, kita juga akan membahas terkait topik Data Science dengan Autopilot! Kita akan mempelajari cara menggunakan AutoGluon untuk membuat prototipe beberapa model AI/ML dan men-deploy model yang terbaik.\n\n\nJadi untuk siapa kursus ini?\nKursus ini menargetkan siapa pun yang ingin mendapatkan pemahaman mendasar tentang Data Science dan memecahkan masalah bisnis dunia nyata yang praktis.\n\n\nDalam kursus ini:\nAnda akan mendapatkan pengalaman belajar berbasis proyek praktis. Kita akan membangun lebih dari sepuluh proyek Data Science bersama-sama.\nAnda akan memiliki akses ke semua kode dan slide.\nAnda akan mendapatkan sertifikat penyelesaian yang dapat Anda posting di profil LinkedIn Anda untuk menunjukkan keahlian Anda dalam Data Science kepada calon pemberi kerja.\nSemua ini dilengkapi dengan jaminan uang kembali 30 hari, jadi Anda dapat mencoba kursus tanpa risiko apapun!\n\n\nLihat video pratinjau dan outline untuk mendapatkan gambaran tentang proyek yang tercakup dalam kursus ini.\nDaftar sekarang agar dapat segera mengaplikasikan ilmu Data Science untuk keperluanmu!",
      "target_audience": [
        "Kursus ini ditargetkan untuk siapa saja yang ingin mendapatkan pemahaman mendasar tentang Data Science dan memecahkan masalah bisnis dunia nyata yang praktis",
        "Data Scientist pemula yang ingin meningkatkan karir dan membangun portofolio mereka",
        "Konsultan berpengalaman yang ingin melakukan tranformasi bisnis dengan memanfaatkan Data Science",
        "Penggemar teknologi yang bersemangat dan baru dalam Data Science & AI serta ingin mendapatkan pengalaman praktis"
      ]
    },
    {
      "title": "Análise de dados 3 em 1: Excel, Power BI e Python",
      "url": "https://www.udemy.com/course/analise-dados/",
      "bio": "Aprenda os principais softwares para análise e ciência de dados usados no mercado: domine o business intelligence",
      "objectives": [
        "Aplicar funções de estatística para análise de dados e tomada de decisão",
        "Construir e interpretar gráficos e tabelas em Excel",
        "Criar dashboards do zero em Power BI: importar, transformar, visualizar e analisar dados",
        "Dominar as principais bibliotecas do Python para manipulação de dados: NumPy e Pandas",
        "Usar a biblioteca MatPlotLib, em Python, para visualização gráfica de dados",
        "Usar a ferramenta do Power Query no Excel para trabalhar com bases de dados"
      ],
      "course_content": {
        "Introdução": [
          "Apresentação do pacote 3 em 1 e boas-vindas!"
        ],
        "Power BI: criando e publicando dashboards para gestão e análise de dados": [
          "Apresentação do professor e do módulo - Dashboard com Power BI",
          "Material do módulo",
          "Como baixar e instalar a versão desktop do Power BI",
          "Apresentação do Power Query",
          "Apresentação do Power Pivot e Power View",
          "Dashboard completo 1",
          "Dashboard completo 2",
          "Dashboard completo 3",
          "Dashboard completo 4",
          "Dashboard completo 5 e encerramento"
        ],
        "Excel - estatística para análise de dados": [
          "Apresentação do instrutor e do módulo",
          "Apresentação do case e descrição do conjunto de dados",
          "Principais medidas resumo",
          "Separatrizes - os quartis",
          "Assimetria e curtose",
          "Construindo e interpretando boxplots",
          "Outliers: os pontos fora da curva",
          "Modelagem da incerteza",
          "Como construir e interpretar histogramas",
          "Histograma avançado - tabela de frequências",
          "Modelando dados usando Funções Densidade de Probabilidade (PDFs)",
          "Histogramas comparados para identificar parâmetros da PDF teórica",
          "Modelagem para tomada de decisões",
          "Usando Solver para diminuir erro da modelagem",
          "Comparando aderência dos dados com outras distribuições de probabilidade",
          "Comparando aderência dos dados com PDF gama",
          "Fazendo previsões e análises usando a modelagem teórica da PDF",
          "Antes de continuar, nos ajude a te ajudar :-)",
          "Aplicabilidade do conteúdo do curso para outros casos e situações"
        ],
        "Excel - visualização de dados": [
          "Apresentação da seção - gráficos no Excel",
          "Gráfico de colunas e barras",
          "Gráfico de pizza",
          "Gráfico de linha",
          "Histograma",
          "Gráfico de dispersão",
          "Gráfico de Pareto",
          "Exemplo problema resolvido usando gráficos",
          "Manipulação de gráficos",
          "Linha de tendência linear",
          "Linha de tendência polinomial",
          "Linha de tendência Exponencial/Logarítmica",
          "Outras linhas de tendência",
          "Composição de gráficos com linhas de tendência",
          "Interpretando resultados com linhas de tendência"
        ],
        "Python: principais bibliotecas para tratamento, visualização e análise de dados": [
          "Apresentação do instrutor e do curso",
          "Instalando o Python (Anaconda)",
          "Instalando uma IDE (Visual Studio Code)",
          "Usando o Python na nuvem ( Google Collaboratory)",
          "Apresentação do case para aplicação do conteúdo do curso",
          "Apresentação dos dados",
          "Análise - preparação 1",
          "Análise - preparação 2",
          "Análise - outliers",
          "Análise - histograma",
          "Regressão linear",
          "Análise - regressão",
          "Encerramento do módulo"
        ],
        "Excel Power Query: automatizando tarefas de Extract, Transform and Load (ETL)": [
          "Apresentação da seção: Excel para tratamento de dados no Power Query",
          "ETL no Excel - usando o Power Query 1",
          "ETL no Excel - usando o Power Query 2",
          "ETL no Excel - usando o Power Query 3"
        ],
        "Seção BÔNUS - Cursos Pelo Menor Preço da Udemy": [
          "Acesse nossos cursos com desconto + Bônus"
        ]
      },
      "requirements": [
        "Não há pré-requisitos para este pacote de cursos"
      ],
      "description": "Olá! Você está prestes a embarcar em uma jornada de aprendizado transformadora com nosso pacote de cursos 3 em 1 sobre análise de dados. Através de vídeo-aulas práticas, descontraídas e diretas ao ponto, você vai dominar as três ferramentas mais essenciais no mundo dos dados: Python, Excel e Power BI. Cada seção na Udemy é um curso completo, e você pode assistir aos cursos na ordem que desejar:\n\n\nAnálise, visualização e inteligência artificial em Python\nEstatística para análise de dados em Excel\nVisualização de dados no Excel\nCriando dashboards em Power BI\nCURSO EXTRA: manipulação de dados com Power Query\n\n\nCom o conhecimento adquirido, você se tornará um profissional de business intelligence indispensável em sua empresa.\nVídeo-aulas com abordagem prática, descontraída e direta ao ponto sobre aplicações de ferramentas de ESTATÍSTICA E ANÁLISE DE DADOS (data analysis) para resolver um case real ao longo do curso. O foco é em TOMAR MELHORES DECISÕES sobre fenômenos que envolvem incerteza, como é o caso de muitos trabalhos em escritório hoje em dia.\nNo módulo de Excel, você explorará estatísticas, análises e visualizações de dados, aprendendo a tomar decisões informadas em diversos contextos profissionais. No Power BI, você se aprofundará na manipulação de bancos de dados, criação de dashboards e interpretação de dados, utilizando ferramentas poderosas como Power Pivot e Power Query. Já no módulo de Python, você dominará uma linguagem de programação completa, desde a importação até a visualização e análise de dados, incluindo uma introdução ao machine learning com regressão linear.\nAlém disso, oferecemos um bônus especial: Excel Power Query. Aqui, você aprenderá a realizar processos ETL (Extract, Transform and Load), importar dados de diversas fontes e automatizar tarefas no Excel, poupando tempo e aumentando sua eficiência.\nEste pacote de cursos é ideal para profissionais de todas as áreas que desejam tomar melhores decisões através da análise de dados. Empreendedores, advogados, administradores, biólogos, médicos - qualquer um que lide com dados pode se beneficiar desses conhecimentos. Você terá acesso aos materiais das aulas para revisar e praticar os conceitos aprendidos, tornando-se um analista de dados habilidoso e confiante.\nNossos instrutores são:\nGuilherme, engenheiro eletricista, doutor em engenharia elétrica, professor universitário e consultor em estatística aplicada, será seu guia no módulo de Excel para análise de dados.\nDiego Moro, engenheiro mecânico e doutor em engenharia mecânica, liderará o módulo de visualização de dados no Excel.\nFábio Ricardo, especialista em Power BI, conduzirá o módulo sobre essa ferramenta poderosa da Microsoft.\nEduardo Alberti, engenheiro de computação e especialista em machine learning, estará à frente do módulo de Python.\nPrepare-se para uma jornada empolgante de aprendizado, onde você será capacitado a manipular, visualizar e interpretar dados de maneira eficaz. O objetivo do curso é tornar o aluno apto a aplicar as técnicas estatísticas ensinadas ao longo do curso, extrapolar o raciocínio para várias aplicações do dia-a-dia de diversas áreas e PRINCIPALMENTE analisar e interpretar os resultados dos dados.\nEstá preparado para começar esta jornada? Nos vemos nas aulas!",
      "target_audience": [
        "Analistas e profissionais de análise de dados para diversas áreas",
        "Interessados em entrar para o mundo da Ciência de Dados, ou mesmo que queiram aperfeiçoar seus conhecimentos",
        "Controllers e planejadores de áreas diversas como engenharia, contabilidade, finanças, etc",
        "Pessoas que tem tem interesse em começar na área de análise de dados/big data",
        "Pessoas buscando especialização em softwares requisitados pelo mercado (office e python)"
      ]
    },
    {
      "title": "【初心者向け】Stable Diffusion web UIの拡張機能ControlNetで重要な9の技術を実践で学ぼう",
      "url": "https://www.udemy.com/course/stable-diffusion-controlnet/",
      "bio": "ジェネレーティブAI（画像生成AI）大人気のStable Diffusionで人気の拡張機能ControlNetの使い方を9つに絞って学習します。あまり使わないプリプロセッサーは省くことで、本当に必要な生成技術を身につけることができます。",
      "objectives": [
        "StableDiffusionでのControlNetの使い方",
        "高度な画像生成スキル",
        "入力した画像の一部だけ修正する方法",
        "画質を上げる、アップスケーリングの方法",
        "入力画像の奥行きを震度マップに変換し、それをベースに画像を生成する方法",
        "入力画像から棒人間を検出して、それをベースに画像を生成する方法など"
      ],
      "course_content": {
        "1.はじめに": [
          "1-1_この講座の対象者ついて",
          "1-2_この講座で学べること"
        ],
        "2.ControlNetについて": [
          "2-1_そもそもControlNetって何？",
          "2-2_ControlNetをインストールする",
          "2-3_Control Net用モデルをインストールする",
          "2-4_Control Netのパラメータ設定画面について",
          "2-5.この講座で使用しているデータまとめ"
        ],
        "3.Control Netを使いこなせ": [
          "3-0.レクチャー内で使用している画像を配布します。",
          "3-1_これはヤバい!?指定したポーズを99%再現できる「DW openpose」",
          "3-2_絵の色だけを変えるのは「Lineart」で超簡単！",
          "3-3_絵心のない人の最強の味方!「scribble」で落書きをアートに",
          "3-4_元絵に最も近いトレースが可能な「soft edge」",
          "3-5_Hey,Siri.のように、画像に指示を与えることができる「ip2p」",
          "3-6_元絵のイメージを壊さずに細部を書き込みたいなら「tile_resample」",
          "3-7_イラストから建物やインテリアを再現する「MLSD」",
          "3-8_マスクで画像の一部を思い通りに修正できる「Inpaint」",
          "3-9_顔を固定して別の構図の画像を生成できる神機能「reference_only」"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Stable Diffusionを導入済み"
      ],
      "description": "この講座は「ジェネレーティブAI（画像生成AI）入門【Stable Diffusion】-プロンプトでハイクオリティな画像制作が可能」の補足教材です。\n補講とお考えください。\nそのため、上記講座をすでに受講済みの方が対象です。\nよくご確認の上、受講お願いします。\n\n\n＜講座内容＞\nControlNetは、lllyasvielによって開発されたStableDiffusion web UIの拡張機能です。これは、ノイズから高品質の画像を生成する生成的敵対ネットワーク（GAN）の一種であるStable Diffusion Modelに基づいています。\n\n\nこの技術はStable Diffusion web UI「AUTOMATIC1111」にたった二週間程度で搭載されました。\n現在では一般的に「ControlNet」というと、このAUTOMATIC1111の拡張機能としての「ControlNet」を指して使います。\nControlNetは、「画像生成AIにおける二度目の革命」と言われるほど非常に高いポテンシャルと画期的な機能を搭載しており、さまざまな機能によって、例えばtxt2imgにおけるガチャ要素を極限まで排除できます。\nリアルなポートレート、3Dキャラクター、ファンタジー風景、ドット絵、抽象的な芸術など、さまざまなスタイルの画像を作成するために使用されています。\n\n\nControlNetに搭載されている機能の中から９つを厳選して学習します。\n\n\nSoftEdge：入力画像から大まかな線画を作成し、それをベースに新たに画像を生成(cannyとの違いはアルゴリズム)\nmlsd：直線を検出しそれをベースに新たに画像を生成（主にインテリアや建物に使用）\nOpenpose：入力画像からキーポイントを検出(棒人間)、それをベースに新たに画像を生成\nScribble：手書きのラフ画をベースに新たに画像を生成\nInpaint：入力した画像の一部だけ修正できる\nInstruct Pix2Pix：「Instruct Pix2Pix」で画像を指示通り書き換える\nLineart：入力画像を線画に変換し、それをベースに新たに画像を生成\nTile：画質を上げる、アップスケーリング機能\nreference_only：顔を固定して別の構図の画像を生成\nしかし、実際に使ってみると、どのようなときにどのようなモデルを使えばいいのかわかりにくいのも事実です。\nですから、この講座では、Controlnetの15程度ある機能の中から、9の主要な使い方を70分で解説していきます。\n\n\nこの講座を完全に受講し終わると、あなたの画像生成技術は強固たるものになるでしょう！！",
      "target_audience": [
        "Stable Diffusionで高度な画像生成をしたい方"
      ]
    },
    {
      "title": "【データサイエンス入門】Pythonとpolarsによるデータの前処理",
      "url": "https://www.udemy.com/course/python-polars-preprocess/",
      "bio": "日本初のpolars解説コース！DXやAIに必要不可欠なデータの前処理を最先端パッケージのpolarsで実施します！pandasに取って代わる可能性があるpolarsの使い方をマスターしてデータの前処理をサクサクッとやりましょう！！",
      "objectives": [
        "データ分析プロジェクトにおける前処理の重要性",
        "Pythonの基礎",
        "polarsの使い方",
        "データの前処理の具体的な方法"
      ],
      "course_content": {
        "当コースの紹介": [
          "資料",
          "概要",
          "全体像"
        ],
        "pandasとpolarsの比較": [
          "①インデックス_説明",
          "①インデックス_コーディング",
          "②統一性_説明",
          "②統一性_コーディング",
          "③ベクトル操作_説明",
          "③ベクトル操作_コーディング",
          "④処理速度_説明",
          "④処理速度_コーディング",
          "⑤パッケージ対応_説明",
          "⑤パッケージ対応_コーディング",
          "⑥情報量_説明"
        ],
        "①環境構築：Google Colaboratory": [
          "補足",
          "Google Colaboratoryってなに？？",
          "Colabを利用するための準備",
          "Colabの基本的な使い方",
          "当コースの受講方法"
        ],
        "②Python": [
          "概要"
        ],
        "②Python：データ型": [
          "データ型ってなに？？",
          "int型",
          "float型",
          "str型",
          "bool型"
        ],
        "②Python：リスト": [
          "リストってなに？？",
          "リストの作成",
          "リストの要素抽出"
        ],
        "②Python：辞書": [
          "辞書ってなに？？",
          "辞書の作成",
          "辞書の要素抽出"
        ],
        "②Python：条件分岐処理": [
          "条件分岐処理ってなに？？",
          "条件の判定",
          "ifとelse",
          "ifとelifとelse",
          "概要"
        ],
        "②Python：繰り返し処理": [
          "繰り返し処理ってなに？？",
          "for",
          "リスト内包表記"
        ],
        "②Python：関数": [
          "関数ってなに？？",
          "関数の作成"
        ]
      },
      "requirements": [
        "プログラミング初心者でもOK！！",
        "インターネットが使用できるパソコン（OSはなんでもOK）"
      ],
      "description": "※当コースは，前作「AIエンジニアが教えるPythonによるデータの前処理」の内容をpolarsでアレンジしたものになります．（numpyとplotnineは当コースの対象外です。）\n当コースは，データの前処理に特化しています．\n近年はDXやAIが話題になっており，実に様々な方々が興味を持っている分野だと思います．\nDXやAIによる成果に焦点が当たる場合が多いですが，その成果が出る前には必ずデータの前処理をする必要があります．\nデータの前処理は，データの読み込み，加工，結合，可視化など実に様々な工程を何回も繰り返すことで，徐々に完成に近づいていきます．\nそのことが原因で，データの前処理には多大な時間（データ分析プロジェクト全体の70％～80％程度）が費やされるのです．\nそんな多大な時間が費やされるデータの前処理ですが，後工程の成果物につながる重要な工程ですので，できるだけ速く正確に実施する必要があります．\nデータの前処理は，今まではPythonのpandasというパッケージがデファクトスタンダードでした。\nところがpandasは、コーディングが難しく、扱うのが難しいという欠点があります。\nそのようなpandasに取って代わる可能性があるのがpolarsというパッケージです！\npolarsはpandasと比較し、以下のようなメリットがあります。\nインデックスがない！\n書きやすい！\n高速！\npolarsを利用すれば今まで時間がかかっていたデータの前処理をサクサクッと実施することができます。\n当コースでは，そんな最先端のパッケージであるpolarsについて詳細に説明します．\nまたpolarsだけでなく，環境構築やPythonの基礎についても丁寧に説明しますので，今までプログラミングをしたことがない初心者でも全く問題ないです．\n講師が基礎から丁寧に解説しますので，気楽に一歩一歩着実に学習し，前処理マスターを目指しましょう！！\n\n\n◆本コースの目的◆\nデータの前処理のほぼすべて（80%程度）に対応すること\n\n\n◆本コースの特徴◆\nとにかく現場主義！！\nコーディングはリアルタイム形式！！\nコードだけでなく，イメージも！！\n\n\n\n◆本コースの内容◆\nコース紹介\n概要\n当コース受講における注意\n全体像\n環境構築\nGoogle Colaboratoryを利用するための準備\nGoogle Colaboratoryの基本的な使い方\n当コースの受講方法\nPython\nデータ型\nリスト\n辞書\n条件分岐処理\n繰り返し処理\n関数\nクラス\nパッケージ\npolars\nデータの入出力\nメソッドチェーン\nデータフレーム処理\n文字列処理\n繰り返し処理\n欠損値処理\n総合演習",
      "target_audience": [
        "DXやAIに興味がある方",
        "Pythonによるデータの前処理を勉強したい方",
        "pandasを学習したが、polarsに乗り換えたい方",
        "データの前処理を効率的にしたい方"
      ]
    },
    {
      "title": "Artificial Intelligence in Arabicالذكاء الصناعي مبتدئ لمحترف",
      "url": "https://www.udemy.com/course/artificial-intelligence-in-arabic/",
      "bio": "تعلم مبادئ الذكاء الصناعي عن طريق ١٠ مشاريع عملية",
      "objectives": [
        "Numpy, pandas, matplotlib, seaborn المكتبات المشهورة",
        "Scikit Learn and Keras",
        "Regression, classification and deep learning"
      ],
      "course_content": {
        "INTRODUCTION": [
          "Introduction and Welcome Message",
          "Course Overview"
        ],
        "AI AND MACHINE LEARNING OVERVIEW": [
          "Introduction - What is Machine Learning and AI?",
          "Introduction - What is Machine Learning and AI? - Part 2"
        ],
        "INSTALLATION AND SETUP [OPTIONAL]": [
          "Anaconda Setup & Installation",
          "What are Jupyter Notebook?",
          "How to run a Jupyter Notebook? Part #1",
          "How to run a Jupyter Notebook? Part #2"
        ],
        "REGRESSION": [
          "Simple Linear Regression - Intuition",
          "Simple Linear Regression - Sum of Least Squares",
          "Project #1 - Part #1",
          "Project #1 - Part #2",
          "Project #1 - Part #3",
          "Project #1 - Part #4",
          "Project - Part #5",
          "Project #1 - Part #6",
          "Project #2 - Part #1",
          "Project #2 - Part #2",
          "Project #2 - Part #3",
          "Project #2 - Part #4",
          "Project #2 - Part #5",
          "Project #2 - Part #6"
        ],
        "CLASSIFICATION": [
          "Logistic Regression - Intuition part #1",
          "Logistic Regression - Project #1 - Part #2",
          "Confusion Matrix Overview",
          "Logistic Regression - Project #1 - Part #1",
          "Logistic Regression - Project #1 - Part #2",
          "Logistic Regression - Project #1 - Part #3",
          "Logistic Regression - Project #1 - Part #4",
          "Logistic Regression - Project #1 - Part #5",
          "Logistic Regression - Project #1 - Part #6",
          "Logistic Regression - Project #1 - Part #7",
          "Logistic Regression - Project #1 - Part #8",
          "Support Vector Machines - Intuition",
          "Support Vector Machines - Parameters Optimization",
          "Cancer Detection Overview",
          "Project - Part #1",
          "Project - Part #2",
          "Project - Part #3",
          "Project - Part #4",
          "Project - Part #5",
          "Project - Part #6",
          "Project - Part #7",
          "Project - Part #8"
        ],
        "DEEP LEARNING": [
          "Deep Learning - Intuition",
          "What is an Image and how to represent it digitally?",
          "Artificial Neural Networks Basics",
          "Convolution Neural Networks Overview",
          "Convolution",
          "RELU",
          "Max pooling Layer",
          "Dropouts",
          "CNN Projects - Part #1",
          "CNN Projects - Part #2",
          "CNN Projects - Part #3",
          "CNN Projects - Part #4",
          "CNN Projects - Part #5"
        ]
      },
      "requirements": [
        "كمبيوتر أو لابتوب",
        "مباديء البرمجه بلغه البايثون",
        "هذا الكورس للمبتدئين في الذكاء الصناعي - ليس هناك متطلبات سابقه"
      ],
      "description": "كورس كامل لتعليم مبادئ الذكاء الصناعي بالبايثون للمبتدئين وحتى المستوى المتقدم. ستتعلم في هذا الكورس البرمجة باستخدام لغة بايثون عن طريق إنشاء 10 مشاريع عمليه.\nسواء كنت هاوياً طالباً أو مبرمجاً, فإن هذا الكورس سيساعدك علي فهم أساسيات الذكاء الصناعي و الوصول إلى مستوى محترف\n**** يرجى ملاحظة أن الكورس قيد التطوير. سنقوم بإضافة محتوى جديد على أساس منتظم ****",
      "target_audience": [
        "اي شخص يريد تعلم مباديء الذكاءالصناعي"
      ]
    },
    {
      "title": "互联网业务数据分析",
      "url": "https://www.udemy.com/course/ghxxyjan/",
      "bio": "帮助学员用数据解决实际业务问题",
      "objectives": [
        "建立数据思维，形成对数据分析的系统理解，能够体系化看待数据，通过数据驱动增长",
        "数据核心模块：数据建模、数据处理、数据分析、数据采集四大能力模块全方位方法论输入，实现数据驱动增长",
        "9个重点数据分析方法，助力“寻找发力点”",
        "帮助学员充分的理解业务数据分析的工作方法和流程"
      ],
      "course_content": {
        "「恭喜，数据课即将开始」": [
          "布棉老师有话说",
          "相关「书籍/工具」推荐"
        ],
        "「课程导论」": [
          "课程介绍",
          "如何运用数据指导业务？",
          "这门课能解决什么问题？",
          "总结"
        ],
        "【模块一】（上）指标建模": [
          "模块导读",
          "概述：指标建模",
          "认识常见的数据指标",
          "1.1 DAU &amp; MAU",
          "1.2 如何定义新增？",
          "1.3 如何理解留存？",
          "1.4 渠道来源怎么看？",
          "2.1 PV、UV、转化率、访问深度",
          "2.2 访问时长",
          "2.3 弹出率（Bounce Rate）",
          "3 业务相关的数据指标",
          "小结：没有绝对的对错，只求彼此的认同"
        ],
        "【模块一】（下）指标建模": [
          "Step 1 拆解业务模块",
          "Step 2 判断模块类型",
          "Step 3 根据模块类型，选取数据指标",
          "案例：iMoney 数据指标选取",
          "案例：闲鱼 数据指标选取",
          "案例：土巴兔（早期）数据指标选取",
          "总结"
        ],
        "【模块二】（上）数据工具": [
          "模块导读",
          "概述：数据工具",
          "1 如何选择合适的数据工具",
          "1.1 根据业务核心划分",
          "1.2 根据公司阶段划分",
          "小结：根据业务需求，选择数据工具",
          "2 掌握常见的数据分析“套路”",
          "2.1 计数统计：快速验证",
          "2.2 流量导向：渠道依赖",
          "2.3 内容导向：质量第一",
          "2.4 用户导向：用户为王",
          "2.5 业务导向：商业本质",
          "小结：成为数据工具的主人",
          "本章总结"
        ],
        "【模块二】（下）数据处理": [
          "模块导读",
          "导入文本文档",
          "格式化—简单的分列",
          "格式化—复杂的分列",
          "数据清洗（筛选、排序、去重）",
          "数据的二次处理（以留存为例）",
          "快速呈现：数据透视表",
          "表不如图：Excel 常见图表",
          "数据可视化（Circle Packing、Beeswarm）",
          "数据可视化（借助高德地图进行地理位置可视化）",
          "5 个数据工具特色功能展示"
        ],
        "【模块三】数据分析基础": [
          "模块导读",
          "概述：数据分析",
          "如何进行对比分析",
          "如何进行多维度拆解",
          "【案例】数据涨跌异动如何处理？",
          "漏斗观察的分析方法",
          "【案例】如何评估渠道质量，确定投放优先级？",
          "分布分析的方法",
          "用户留存的分析方法",
          "【案例】功能/内容上线后，如何评估？"
        ],
        "【模块四】数据分析进阶": [
          "模块导读",
          "用户画像的分析方法",
          "【案例】如何高质量拉新？",
          "如何进行归因查找",
          "【案例】如何精准运营推送？",
          "路径挖掘的分析方法",
          "行为序列的分析方法",
          "【案例】如何辅助产品设计？",
          "【案例】羊毛党盛行，如何查出谁在薅？",
          "总结：回归业务的数据分析"
        ],
        "【模块五】数据采集": [
          "模块导读",
          "概述：数据采集",
          "数据埋点与数据需求文档",
          "明确埋点需求（想清楚）",
          "形成需求文档（讲明白）",
          "数据采集实战",
          "其他类型的数据采集方法",
          "总结：数据采集"
        ]
      },
      "requirements": [
        "1年及以上互联网业务从业人员，或者对互联网业务有一定了解的其他行业人员"
      ],
      "description": "模拟一线互联网数据赋能业务，解决实际的业务问题\n帮助学员用数据解决实际业务问题\n全面了解数据科学：什么是数据科学，数据科学职位介绍，CRISP-DM简介\n运用数据分析工具Python：Python基本语法知识、Python中的报错和异常、数据可视化库：Matplotlib & Seaborn\n机器学习初步建模、调试与预估：Scikit-learn算法库介绍、正则化方法提升模型表现、A/B测试分析方法\n认识数据分析师的能力模型：数据分析师必备硬技能、数据分析师必备软技能、数据变量的类型\n围绕核心算法模型体系化学习：包括统计学、机器学习、等数据分析工作核心算法模型、机器学习在数据分析中应用、线性回归在数据分析中的实操\n熟练掌握Excel、SQL、R语言三大数据分析工具的核心技能：Excel函数的基本知识与可视化、SQL核心语句与进阶用法、R的数据分析及可视化\n课程导师 - 张涛\n神策数据副总裁。曾就职于腾讯、豌豆荚、AcFun，历任产品经理、产品总监、事业部总经理\n在豌豆荚，见证产品从 10W 走向 1000W 日活，自己所负责的应用搜索使用者占日活用户的 80%。后期负责豌豆洗白白，成功将日活大盘拉升将近 25%。 在 AcFun，联合产品、运营及市场渠道团队做了很多有意思的点子。日活大盘从接手时的 50W，在一年半时间内提升 9 倍",
      "target_audience": [
        "日常工作中需要进行数据指标搭建、观测数据等工作，同时需要从数据中找到发力点制定策略的市场从业者、产品",
        "需要快速提升数据思维和数据分析技能，通过数据驱动业务增长实现精细化运营的业务人"
      ]
    },
    {
      "title": "Phân tích và xử lý dữ liệu với phần mềm R",
      "url": "https://www.udemy.com/course/phan-mem-r/",
      "bio": "Phân tích và xử lý dữ liệu thống kê sử dụng phần mềm R",
      "objectives": [
        "Cách phân tích và xử lý dữ liệu; phân tích thống kê trên R",
        "Phương pháp trình bày số liệu bằng đồ thị",
        "Xây dựng các mô hình dự báo thống kê",
        "Code mẫu trên R để dễ dàng tham khảo và thực hành",
        "Hệ thống bài tập, project thực hành",
        "Hỏi đáp thắc mắc trong phần Q&A"
      ],
      "course_content": {
        "Giới thiệu về R và các thiết lập cơ bản": [
          "Code R và số liệu cho bài giảng",
          "Cài đặt R và R-studio",
          "Khởi động và màn hình làm việc",
          "Các thiết lập cơ bản; Cài đặt package",
          "Các tính toán cơ bản trên R",
          "Các thiết lập và tính toán cơ bản trên R"
        ],
        "Cấu trúc dữ liệu: Vector, ma trận, factor": [
          "Code R và số liệu cho bài giảng",
          "Véc-tơ (Vector)",
          "Các phép toán logic",
          "Ma trận",
          "Cấu trúc Factor",
          "Chuyển đổi giữa các định dạng dữ liệu",
          "Cấu trúc dữ liệu: Vector, ma trận, factor"
        ],
        "Thiết lập hàm số trong R": [
          "Code R và số liệu cho bài giảng",
          "Thiết lập hàm số trong R",
          "Thiết lập hàm số: Tham số mặc định - Optional argument",
          "Thiết lập hàm số: Trả về nhiều đầu ra",
          "Làm việc với vector"
        ],
        "Cấu trúc dữ liệu: List và data frame": [
          "Code R và số liệu cho bài giảng",
          "Dữ liệu list",
          "Dữ liệu data frame",
          "Cấu trúc dữ liệu: List và data frame"
        ],
        "Ghép nối data frame": [
          "Code R và số liệu cho bài giảng",
          "Nối data frame dùng rbind và cbind",
          "Nối data frame bằng hàm merge (inner join, outer join, left join, right join)",
          "Làm việc với data frame"
        ],
        "Sử dụng package dplyr trong phân tích và xử lý số liệu": [
          "Code R và số liệu cho bài giảng",
          "Sử dụng các hàm số select, filter, rename, arrange; Pipe operator",
          "Sử dụng các hàm số group_by, summarise, mutate",
          "Join các bảng trong Dplyr",
          "Phân tích và xử lý số liệu với dplyr"
        ],
        "Số liệu dạng ký tự (Character) và dạng ngày (Date and time)": [
          "Code R và số liệu cho bài giảng",
          "Số liệu dạng ký tự (Character)",
          "Số liệu dạng ngày (Date)"
        ],
        "Import/ Export từ Excel và các nguồn dữ liệu khác": [
          "Code R và số liệu cho bài giảng",
          "Import file csv, xlsx từ Excel vào môi trường R",
          "Export từ môi trường R ra file text, csv, excel"
        ],
        "Cấu trúc if-else if-else; Vòng lặp for": [
          "Code R cho bài giảng",
          "Cấu trúc điều kiện: If-else if-else",
          "Sử dùng hàm số if_else, case_when; hàm cut",
          "Cấu trúc vòng lặp for",
          "Sử dụng các hàm số apply, lapply, sapply",
          "Chuẩn hóa biến số"
        ],
        "Thực hiện phân tích thống kê trên R": [
          "Code R cho bài giảng",
          "Tính toán thống kê cơ bản",
          "Phân tích phân bố của từng biến số; biểu đồ phân tán, biểu đồ boxplot",
          "Phân tích tương quan giữa các biến số: Hệ số tương quan, kiểm định tương quan",
          "Tính toán với phân phối xác suất",
          "Chọn mẫu ngẫu nhiên: Hàm sample, sample.int",
          "Kiểm định Binomial (Binomial test) với tỷ lệ",
          "Kiểm định student t - one sample",
          "Kiểm định student t - two sample",
          "Phân tích ANOVA - kiểm định F-test",
          "Phân tích thống kê trên R"
        ]
      },
      "requirements": [
        "Có kỹ năng tin học cơ bản",
        "Có máy tính cá nhân để thực hành trên phần mềm"
      ],
      "description": "Nếu bạn đang tìm kiếm một khóa học đầy đủ và dễ hiểu nhất về phần mềm R, thì đây sẽ là khóa học hoàn hảo cho bạn. Khóa học gồm có các video bài giảng hướng dẫn một cách chi tiết về cách sử dụng phần mềm R trong phân tích thống kê và xử lý dữ liệu. Khóa học cũng có hệ thống bài tập và project để các bạn có thể thực hành và kiểm tra lại kiến thức của mình.\nChỉ cần bỏ ra từ 10$ để nắm bắt được những kiến thức và kỹ năng giúp bạn tự tin trong công việc và gây ấn tượng với nhà tuyển dụng. Bạn cũng sẽ có trách nhiệm hơn trong việc hoàn thành khóa học và giúp ủng hộ mình tiếp tục làm khóa học hoàn thiện hơn.\nKhóa học sẽ chia thành các phần chính sau:\n- Giới thiệu về phần mềm R, cách thiết lập môi trường làm việc và cài đặt.\n- Các cấu trúc dữ liệu cơ bản trong R: véc-tơ, ma trận, danh sách (list), data frame.\n- Xử lý số liệu dạng ký tự và dạng ngày tháng.\n- Sử dụng dplyr trong phân tích và xử lý số liệu.\n- Import và export dữ liệu từ Excel vào R và ngược lại.\n- Trình bày số liệu bằng biểu đồ.\n- Phân tích thống kê trên R.\n- Các cấu trúc lập trình cơ bản trong R: vòng lặp for, vòng lặp while, điều kiện (if then else), tạo hàm số.\n- Xây dựng các mô hình dự báo thống kê (hồi quy tuyến tính, hồi quy logistic,...).",
      "target_audience": [
        "Bất cứ ai quan tâm đến lĩnh vực khoa học số liệu hoặc cần nâng cao kỹ năng về phân tích và xử lý số liệu",
        "Muốn tìm hiểu về phân tích số liệu, xây dựng mô hình thống kê bằng phần mềm R"
      ]
    },
    {
      "title": "Visualização de Dados-Data Science: R Markdown e Dashboard",
      "url": "https://www.udemy.com/course/markdown-e-dashboard/",
      "bio": "Conte uma história com os seus dados",
      "objectives": [
        "Contar uma história com os dados",
        "Apresentar os resultados estatísticos em Relatórios no R Markdown",
        "Apresentar os resultados estatísticos em Painéis Gráficos (Dashboards)",
        "Ser entendido pelo usuário final",
        "Diferentes tipos de Dashboards",
        "Exportar todo o seu trabalho para diferentes formatos (.doc, .pdf, HTML, link online) tudo de forma automática."
      ],
      "course_content": {
        "Introdução": [
          "Seja muito bem vindo(a)",
          "Uma Visão Geral sobre o Curso",
          "Aviso Inicial",
          "Observação: problemas com a biblioteca \"xlsx\" (resolvido)"
        ],
        "Criando Relatórios no R": [
          "R Markdown - Criando",
          "R Markdown - Texto - Títulos e Comentários",
          "R Markdown - Texto - Dados, formatação e citações",
          "R Mardown - Texto - Dados, formatação e citações - parte 2",
          "R Markdown - Texto - Tópicos",
          "R Markdown - Inserindo trechos de códigos",
          "R Markdown - Parâmetros Echo e Fig.Cap",
          "R Markdown - Configuração Global",
          "R Markdown - Mostrando Tabelas - parte 1",
          "R Markdown - Mostrando Tabelas - parte 2",
          "Mostrando Gráficos",
          "Gráfico Pizza e Barras",
          "Mapas",
          "Formatos de Saída - parte 1",
          "Formatos de Saída - parte 2",
          "Exercício Proposto #1 (Atividade de Fixação)",
          "Solução para o Exercício Proposto #1"
        ],
        "Criando Dashboards de maneira simples": [
          "Dashboard introdução",
          "Antes de iniciar a próxima aula...",
          "Dashboard - exemplo 1",
          "Dashboard - Exemplo 2 - fill",
          "Dashboard - Exemplo 3",
          "Dashboard - Exemplo 4",
          "Dashboard - Alterando orientação",
          "Dashboard - Compartilhando",
          "Dashboard - Abas",
          "Exercício Proposto #2 (Atividade de Fixação)",
          "Solução para o Exercício Proposto #2"
        ],
        "Aula Bônus": [
          "Aula Bônus",
          "Trilha de Aprendizado para a carreira em Data Science"
        ]
      },
      "requirements": [
        "É aconselhável ter feito meu curso de Introdução á Linguagem R",
        "É aconselhável ter feito meu curso de Gráficos com Estilo no R",
        "É aconselhável ter feito meu curso de Mapas no R"
      ],
      "description": "Sobre o Professor\nMeu nome é Isaías Lira, bacharel em Estatística, Consultor em Análise Estatística de Dados, pesquisador e estudioso da área de Estatística Aplicada no Mercado Financeiro, escritor de livro em Estatística, Data Scientist, Pos-graduado em Docência Superior e este curso é um importante dentro de minha lista de cursos.\nQual a vantagem de fazer este curso?\nNós estamos vivendo o melhor momento para as carreiras de Analista de Dados, Cientista de Dados e correlatas. A cada dia as empresas armazenam grandes massas de dados como nunca antes. E o que fazer com estes dados? Como transformá-los em informações úteis para as decisões de crescimento da empresa? É isso que este curso atinge, como transformar dados brutos em algo que possa ser entendido pelas empresas.\nÉ por isto que apesar de crises em outras áreas, vagas e mais vagas são lançadas todos os dias para profissionais que tenham as habilidades que ensinamos neste curso e atualmente não são ocupadas nem mesmo 20% delas, por não haver profissionais competentes para isto.\nEste curso trabalha exatamente formas de comunicar seus resultados estatísticos de maneira eficiente para seus gestores, clientes ou equipe de trabalho, pois eles não estão interessados no caminho (técnicas, ferramentas de análise, etc), eles precisam de informação que pode melhorar de alguma forma seus produtos e serviços.\n\n\nPara quem é este curso?\nCriamos este curso para você\nEstudante (graduação, mestrado, doutorado) das áreas de Tecnologia (Ciência da Computação, Estatística, Engenharia da Computação, etc.) que deseja ocupar as milhares de vagas em aberto.\nProfissionais de outras áreas querendo ampliar sua carreira aprendendo as habilidades mais desejadas pelas empresas dos últimos tempos.\nO que aprenderei neste curso?\nAo final deste curso você saberá contar uma história de seus dados usando:\nRelatórios (R Markdown)\nDashboards\nQual o diferencial deste curso?\nCurso 100% practical course\nUsaremos dados reais\nPrática intensiva (bootcamp) em R\nAvançar seus conhecimentos na principal ferramenta de análises de dados do momento, o R.\nAbordagem/linguagem simples\nTudo mostrado passo a passo\nEntão se você não deseja ficar mais procurando por emprego, ou ser obrigado a ficar na sua mesma cansativa rotina por mais anos a frente, então junte-se a nós neste desafio de aprender a profissão de hoje e do futuro.",
      "target_audience": [
        "Leigos interessados em construir Relatórios e Dashboards (painéis) para mostrar resultados a partir dos dados",
        "Estudantes de TI",
        "Profissionais de TI",
        "Qualquer pessoa interessada em entrar na carreira de Data Science."
      ]
    },
    {
      "title": "Python深度学习与Tensorflow2实战（2020新版）",
      "url": "https://www.udemy.com/course/tensorflow2020/",
      "bio": "tensorflow2版本实战",
      "objectives": [
        "Tensorflow基础操作",
        "Tensorflow核心Api",
        "数据集制作方法",
        "图像数据与文本数据预处理实战",
        "图像识别模型构建",
        "文本分类模型构建",
        "神经网络基础",
        "卷积神经网络原理",
        "递归神经网络",
        "对抗生成网络架构及其实战",
        "CycleGan图像融合",
        "基于Tensorflow构建各大经典网络模型",
        "基于TF的开源项目实战"
      ],
      "course_content": {
        "tensorflow安装与简介": [
          "课程简介",
          "Tensorflow2版本简介与心得",
          "Tensorflow2版本安装方法",
          "tf基础操作展示",
          "课程数据代码下载（谷歌网盘）"
        ],
        "神经网络原理解读与整体架构": [
          "深度学习要解决的问题",
          "深度学习应用领域",
          "计算机视觉任务",
          "视觉任务中遇到的问题",
          "得分函数",
          "损失函数的作用",
          "前向传播整体流程",
          "返向传播计算方法",
          "神经网络整体架构",
          "神经网络架构细节",
          "神经元个数对结果的影响",
          "正则化与激活函数",
          "神经网络过拟合解决方法"
        ],
        "搭建神经网络进行分类与回归任务": [
          "任务目标与数据集简介",
          "建模流程与API文档",
          "网络模型训练",
          "模型超参数调节与预测结果展示",
          "分类模型构建",
          "tf.data模块解读",
          "模型保存与读取实例"
        ],
        "卷积神经网络原理与参数解读": [
          "卷积神经网络应用领域",
          "卷积的作用",
          "卷积特征值计算方法",
          "得到特征图表示",
          "步长与卷积核大小对结果的影响",
          "边缘填充方法",
          "特征图尺寸计算与参数共享",
          "池化层的作用",
          "整体网络架构",
          "VGG网络架构",
          "残差网络Resnet",
          "感受野的作用"
        ],
        "猫狗识别实战": [
          "猫狗识别任务与数据简介",
          "卷积网络涉及参数解读",
          "网络架构配置",
          "卷积模型训练与识别效果展示"
        ],
        "图像数据增强实例": [
          "数据增强概述",
          "图像数据变换",
          "猫狗识别任务数据增强实例"
        ],
        "训练策略-迁移学习实战": [
          "迁移学习的目标",
          "迁移学习策略",
          "Resnet原理",
          "加载训练好的经典网络模型",
          "Callback模块与迁移学习实例",
          "tfrecords数据源制作方法",
          "图像数据处理实例"
        ],
        "递归神经网络与词向量原理解读": [
          "RNN网络架构解读",
          "词向量模型通俗解释",
          "模型整体框架",
          "训练数据构建",
          "CBOW与Skip-gram模型",
          "负采样方案"
        ],
        "基于TensorFlow实现word2vec": [
          "任务流程解读",
          "模型定义参数设置",
          "文本词预处理操作",
          "训练batch数据制作",
          "损失函数定义与训练结果展示"
        ],
        "基于RNN模型进行文本分类任务": [
          "任务目标与数据介绍",
          "RNN模型输入数据维度解读",
          "数据映射表制作",
          "embedding层向量制作",
          "数据生成器构造",
          "双向RNN模型定义",
          "自定义网络模型架构",
          "训练策略指定",
          "训练文本分类模型"
        ]
      },
      "requirements": [
        "熟悉Python即可"
      ],
      "description": "课程主要包括两大模块（原理和实战），首先会通俗讲解深度学习中各大经典网络架构并基于tensorflow2版本进行实例演示，详解网络模型训练方法与策略。项目实战全部基于真实数据集与实际任务进行展开，零基础入门深度学习与TF框架并进行进阶提升！",
      "target_audience": [
        "人工智能深度学习方向的同学们"
      ]
    },
    {
      "title": "Học máy (Machine learning) và ứng dụng",
      "url": "https://www.udemy.com/course/ly-thuyet-hoc-may/",
      "bio": "Tìm hiểu về các thuật toán Machine learning cơ bản và phương pháp xây dựng mô hình Machine learning",
      "objectives": [
        "Hiểu về các thuật toán Machine Learning cơ bản",
        "Biết cách áp dụng các thuật toán trong từng dự án/ bài tập nhất định",
        "Các bước xây dựng mô hình và thực hiện dự báo",
        "Mẫu code lập trình cho từng thuật toán"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Machine learning là gì?",
          "Phần mềm R"
        ],
        "Mô hình hồi quy tuyến tính": [
          "Hồi quy tuyến tính đơn biến",
          "Hồi quy tuyến tính đa biến",
          "Thực hành hồi quy tuyến tính trên excel",
          "Thực hành hồi quy tuyến tính trên phần mềm R",
          "Code mẫu cho bài giảng"
        ],
        "Mô hình hồi quy Logistic": [
          "(Optional) Phương pháp ước lượng hợp lý cực đại",
          "Hồi quy Logistic",
          "Ước lượng mô hình và minh họa trên excel",
          "Kiểm định mô hình: Đo lường sai số dự báo",
          "Kiểm định mô hình: Đường ROC, chỉ số AUC",
          "Thực hành hồi quy Logistic với phần mềm R",
          "So sánh hồi quy tuyến tính và hồi quy Logistic",
          "Code mẫu cho bài giảng"
        ],
        "Phương pháp xây dựng mô hình Machine learning": [
          "Hiện tượng quá khớp (Overfitting) trong Machine learning",
          "Phương pháp lựa chọn và xây dựng mô hình - kiểm chứng chéo",
          "Hồi quy Ridge và Hồi quy LASSO",
          "Code mẫu cho bài giảng"
        ],
        "Mô hình cây quyết định (Decision Tree)": [
          "Mô hình cây quyết định",
          "Xây dựng mô hình và dự báo",
          "Thuật toán ước lượng mô hình",
          "Mô hình Bagging và Random Forest",
          "Thực hành mô hình cây quyết định trên phần mềm R",
          "Code mẫu cho bài giảng"
        ],
        "Mô hình Láng riềng gần nhất (k-Nearest Neighbor - kNN)": [
          "Mô hình Láng riềng gần nhất (k-Nearest Neighbor - kNN)",
          "Thực hành mô hình k-NN trên phần mềm R",
          "Code mẫu cho bài giảng"
        ],
        "Thực hành Học giám sát - Số liệu Titanic - Dự báo khả năng sống sót": [
          "Dự báo số liệu Titanic"
        ],
        "Học không giám sát (Unsupervised learning): Phân cụm thứ bậc, phân cụm k-means": [
          "Học giám sát và học không giám sát",
          "Phân cụm thứ bậc",
          "Phân cụm K-means",
          "Thực hành phân cụm thứ bậc với phần mềm R",
          "Thực hành phân cụm K-means với phần mềm R",
          "Code mẫu cho bài giảng"
        ]
      },
      "requirements": [
        "Toán học cơ bản bậc THPT",
        "Hiểu biết về đại số tuyến tính, xác suất thống kê bậc đại học sẽ có ích, tuy nhiên các kiến thức cần thiết sẽ được ôn lại ở phần đầu khóa học"
      ],
      "description": "Học máy (Machine learning) đang ngày càng trở nên phổ biến và được ứng dụng rộng rãi. Chúng được sử dụng trong các hệ thống máy tính của Google, Facebook, ứng dụng trong nhận diện khuôn mặt, nhận diện chữ viết, xe tự lái,...\nTrong khóa học này, chúng ta sẽ cùng tìm hiểu về các thuật toán Machine learning cơ bản để xem làm thế nào để dạy máy tính học từ số liệu có sẵn.\nCác thuật  toán và hướng dẫn thực hành được trình bày gồm:\nMô hình hồi quy tuyến tính\nMô hình hồi quy Logistic\nMô hình cây quyết định\nMô hình k-NN\nMô hình học không giám sát (Phân cụm thứ bậc, phân cụm K-means)\nPhương pháp xây dựng và kiểm định mô hình\nCác thuật toán khác sẽ được cập nhật trong thời gian tới.\n\n\nImage Credit: Omelchenko/Shutterstock",
      "target_audience": [
        "Sinh viên có xu hướng về khoa học máy tính, khoa học dữ liệu, phân tích kinh doanh",
        "Bất cứ ai muốn tìm hiểu về các thuật toán học máy (Machine learning) và cách mà máy tính học từ dữ liệu"
      ]
    },
    {
      "title": "AI Engineering Bootcamp: From Beginner to Expert [Arabic]",
      "url": "https://www.udemy.com/course/ai-engineering-bootcamp-from-beginner-to-expert-arabic/",
      "bio": "From Zero to AI Hero: Machine Learning, Deep Learning, NLP, Computer Vision & GenAI — Message Me for a Private Discount!",
      "objectives": [
        "Introduction",
        "Statistics Fundamentals",
        "Python Basics Overview",
        "Processing & Visualization",
        "Basics of Machine Learning – Linear and Polynomial Regression",
        "Data Preparation and Overfitting Control in Machine Learning",
        "Logistic Regression and Model Evaluation",
        "Decision Trees and Naive Bayes",
        "K-Nearest Neighbors and Support Vector Machines",
        "Feature Selection and Dimensionality Reduction",
        "Ensemble Learning Techniques: Bagging and Boosting",
        "Unsupervised Machine Learning",
        "Clustering and advanced models",
        "Anomaly Detection",
        "Deep Learning - MLPs",
        "Deep Learning: Overfitting, Regularization, and Network Optimization",
        "TensorFlow and Model Fine-Tuning",
        "Core Concepts and Techniques in NLP",
        "Text Representation & Encoding Techniques in NLP",
        "Sequential Data Modeling with RNNs and its variants",
        "Sequence Modeling with RNNs and Attention Mechanisms",
        "Transformers in depth",
        "Image Processing and Computer Vision",
        "From MLPs to CNNs",
        "CNN Family and Transfer Learning Techniques",
        "Generative Adversarial Networks (GANs) - Concepts and Applications",
        "Generative AI",
        "HuggingFace and its toolkits",
        "LLMs, and fine-tuning using advanced methods",
        "Prompt Engineering",
        "Vector Databases",
        "Chat with data, RAG, Chatbots and more"
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Access Materials & Resources": [
          "Materials & Resources"
        ],
        "Mathematics": [
          "Statistics - Part 1",
          "Statistics - Part 2",
          "Statistics - Part 3 & Linear Algebra",
          "Finish Mathematics & Prepare Our Environment"
        ],
        "Python": [
          "Python - Part 1",
          "Python - Part 2 & NumPy"
        ],
        "Preprocessing": [
          "Pandas - Part 1",
          "Pandas Part 2 & Labs",
          "Visualization in Python",
          "Feature Engineering",
          "Feature Transformation"
        ],
        "Machine Learning": [
          "Linear Regression & Gradient Descent",
          "Finish GD & Overfitting vs. Underfitting & Regularization",
          "Apply Regression in practice & Intro to Classfication",
          "Classification metrics & Logistic/SoftMax Regression & KNN",
          "Naive Bayes & SVM & Decision Trees",
          "Ensemble Learning (Voting, Bagging, Boosting)",
          "Clustering & K-Means & DBSCAN & Dimensionality Reduction",
          "Feature Selection in depth & Churn Project",
          "End-to-End Classification Project",
          "Anomaly Detection Project using Dimensionality Reduction",
          "Gaussian Mixture Model in depth"
        ],
        "Deep Learning - MLPs": [
          "Neural Networks & MLPs in depth",
          "Activation Functions & Project",
          "End-to-End Project using ANN",
          "Finish Projects & Intro to NLP"
        ],
        "NLP": [
          "Classical NLP & End-to-End Projects",
          "Word Embeddings in depth",
          "RNN & GRU & LSTM in depth",
          "NLP Projects",
          "RNN with Attention",
          "Transformers in depth - part 1",
          "Transformers in depth - part 2 & Hugging Face intro",
          "Hugging Face in depth & Intro to Computer Vision"
        ],
        "Computer Vision": [
          "Image Processing & CNNs",
          "CNNs & Projects",
          "Transfer Learning & Intro to Object Detection",
          "Object Detection",
          "AutoEncoders & GANs"
        ],
        "LLMs": [
          "LLMs & Prompt Engineering & Model Training",
          "Fine-Tuning LLMs & ONNX & Quantization & Vector Databases",
          "LangChain & RAG & Chatbots"
        ]
      },
      "requirements": [
        "Just the basic knowledge of any programming language."
      ],
      "description": "Let's make it easy! Message me on WhatsApp for smooth payment and special discounts — my number is in my profile.\n\nAI Engineering Mastery: From Zero to Hero\nMaster AI from Fundamentals to Advanced Deep Learning, NLP, Computer Vision, and Generative AI with Real-World Projects\nCourse Description:\nArtificial Intelligence is transforming industries and opening new career opportunities. This comprehensive course is based on recorded live sessions and is designed to take you from beginner to advanced AI engineer by covering both foundational concepts and cutting-edge technologies.\nThese sessions were originally conducted live, ensuring an interactive teaching style, real-world discussions, and in-depth explanations. Now, they are fully available as on-demand recordings, allowing you to learn at your own pace, revisit lessons anytime, and follow a structured step-by-step approach.\nWhether you are new to programming or already familiar with AI basics, this course provides hands-on experience with industry-standard tools like Python, TensorFlow, and Hugging Face. You will work on real-world projects to solidify your skills and prepare for real-life AI challenges.\nWhat You Will Learn:\n1. Foundations of AI & Machine Learning\nCore concepts in statistics and linear algebra for AI\nPython essentials: Data structures, control flow, and object-oriented programming\nKey libraries: NumPy, Pandas, Matplotlib, and Seaborn\nHands-on projects: Titanic Survival Prediction and California Housing Project\n2. Core Machine Learning Techniques\nLinear and polynomial regression\nData preparation, feature selection, and overfitting control\nDecision trees, K-nearest neighbors (KNN), Naïve Bayes, and support vector machines (SVM)\nEnsemble methods: Bagging, boosting, and advanced evaluation techniques\nClustering methods for unsupervised learning\n3. Deep Learning & Neural Networks\nNeural network architecture and implementation\nOverfitting control, regularization, and optimization techniques\nTensorFlow for deep learning and model fine-tuning\nApplied deep learning: Titanic Survival Prediction\n4. Natural Language Processing (NLP)\nCore concepts and text encoding techniques\nSequential data modeling with RNNs, GRU, and LSTMs\nTransformer models and attention mechanisms\nAdvanced NLP frameworks: Hugging Face, BERT, and T5\nRetrieval-Augmented Generation (RAG) and LangChain integration\n5. Computer Vision & Image Processing\nConvolutional neural networks (CNNs)\nTransfer learning and image classification techniques\nObject detection models: RCNN, Fast-RCNN, and YOLO\nGenerative Adversarial Networks (GANs) and their applications\n6. Generative AI & Practical Implementations\nGenerative AI concepts and model deployment\nPrompt engineering techniques for language models\nBuilding AI-driven applications using Streamlit and other frameworks\nWhy Take This Course?\nComprehensive Learning Path: From AI fundamentals to advanced applications.\nPractical Projects: Gain hands-on experience with real-world datasets.\nIndustry-Ready Skills: Learn the tools and techniques used in leading AI applications.\nStructured and Accessible: Suitable for both beginners and experienced professionals.\nPortfolio Development: Build AI projects that showcase your expertise.\nWho This Course Is For:\nBeginners seeking a clear and practical introduction to AI.\nSoftware developers and engineers looking to integrate AI into their applications.\nData scientists and analysts want to expand their deep learning and NLP expertise.\nEntrepreneurs and tech enthusiasts aiming to understand and apply cutting-edge AI.\nBy the end of this course, you will have a solid understanding of AI engineering principles and the ability to develop advanced models for a variety of real-world use cases.\nEnroll today and begin your journey toward becoming an AI engineer.",
      "target_audience": [
        "Anyone with interest in AI Field",
        "Data Analysts",
        "Data Scientists",
        "Statisticians",
        "Software Developers",
        "Computer Science Students"
      ]
    },
    {
      "title": "Lógica Fuzzy com Python: O Guia para Iniciantes",
      "url": "https://www.udemy.com/course/logica-fuzzy-com-python-o-guia-para-iniciantes/",
      "bio": "Entenda a teoria básica e implemente sistemas fuzzy com a biblioteca skfuzzy",
      "objectives": [
        "Entender os conceitos teóricos da lógica fuzzy, bem como: variáveis linguísticas, antecedentes, consequente, pertinência, fuzzificação e defuzzificação",
        "Aprender os cálculos de defuzzificação utilizando os seguintes métodos: centroide, bisector, MOM, SOM e LOM",
        "Implementar sistemas fuzzy utilizando a biblioteca skfuzzy",
        "Simular um sistema fuzzy para definir o porcentual de gorjeta que seria dado em um restaurante",
        "Simular um sistema fuzzy para configurar o poder de sucção de um aspirador de pó",
        "Implementar agrupamento de dados utilizando o algoritmo fuzzy c-means"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Recursos para download"
        ],
        "Teoria básica": [
          "Introdução",
          "Aplicações de lógica fuzzy",
          "Primeiro entendimento",
          "Variáveis linguísticas e pertinência",
          "Etapas para inferência fuzzy",
          "Cálculos para defuzzificação"
        ],
        "Sistemas fuzzy - implementação": [
          "Introdução",
          "Exemplo das gorjetas - bibliotecas",
          "Exemplo das gorjetas - antecedentes",
          "Exemplo das gorjetas - consequente",
          "Exemplo das gorjetas - regras",
          "Exemplo das gorjetas - defuzzificação",
          "Funções fuzzy - sigmoide, gaussiana e PI",
          "EXERCÍCIO - exemplo do aspirador de pó 1",
          "Exemplo do aspirador de pó 2",
          "Exemplo do aspirador de pó 3",
          "Exemplo das gorjetas - hard fuzzy 1",
          "Exemplo das gorjetas - hard fuzzy 2",
          "Exemplo das gorjetas - hard fuzzy 3",
          "Exemplo das gorjetas - hard fuzzy 4",
          "Exemplo das gorjetas - hard fuzzy 5",
          "Exemplo das gorjetas - hard fuzzy 6",
          "Exemplo das gorjetas - hard fuzzy 7",
          "Exemplo das gorjetas - hard fuzzy 8",
          "Exemplo das gorjetas - hard fuzzy 9",
          "Outros cálculos para defuzzificação",
          "EXERCÍCIO - exemplo do aspirador de pó hard fuzzy"
        ],
        "Agrupamento com fuzzy": [
          "Introdução",
          "Introdução à agrupamento",
          "Carregamento da base de dados",
          "Pré-processamento da base de dados",
          "Agrupamento com fuzzy c-means",
          "Escolha do número de grupos",
          "Interpretação do agrupamento"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Programação básica em Python"
      ],
      "description": "A Lógica Fuzzy (difusa) é uma técnica que pode ser utilizada para modelar o processo de raciocínio humano em computadores, podendo ser utilizada em diversas áreas, como: automação industrial, medicina, marketing, automação residencial, dentre outras. Um exemplo clássico é a utilização em equipamentos industriais, que podem ter a temperatura regulada automaticamente a medida que o equipamento esquenta ou esfria. Outros equipamentos que podem utilizar essa técnica são: aspiradores de pó (regulagem do poder de sucção de acordo com a superfície e o nível de sujeira), máquinas de lavar louças e roupas (ajuste da quantidade de água e detergente/sabão), câmeras fotográficas (definição automática do foco), ar condicionado (configuração da temperatura de acordo com o ambiente) e micro-ondas (ajuste da potência de acordo com o tipo do alimento).\nPara levar você até essa área, neste curso você aprenderá a teoria básica sobre lógica fuzzy e principalmente implementará sistemas fuzzy simples utilizando a biblioteca skfuzzy, tudo passo a passo e utilizando a linguagem Python! Confira abaixo as três partes do curso:\n\n\nParte 1: Teoria básica sobre lógica fuzzy. Você aprenderá tópicos como: variáveis linguísticas, antecedentes, consequente, funções de pertinência, fuzzificação e cálculos matemáticos para defuzzificação\nParte 2: Implementação de sistemas fuzzy. Você implementará dois exemplos: cálculo do percentual de gorjeta que seria dado em um restaurante (baseado na qualidade da comida e na qualidade do atendimento) e cálculo do poder de sucção de um aspirador de pó (baseado na dificuldade da superfície e na quantidade de sujeira). Utilizaremos duas abordagens de implementação: a primeira utilizando os recursos mais automáticos da biblioteca skfuzzy e a segunda utilizando os recursos manuais da biblioteca\nParte 3: Agrupamento com Fuzzy c-means. Vamos analisar os dados de cartão de crédito para agrupar os clientes baseado no limite de crédito e os gastos no cartão. Você entenderá como a lógica fuzzy pode ser utilizada na área de Machine Learning (Aprendizagem de Máquina)\nAo final do curso, você poderá criar seus próprios projetos utilizando lógica fuzzy!",
      "target_audience": [
        "Qualquer pessoa interessada em lógica fuzzy",
        "Alunos de graduação e pós-graduação que cursam disciplinas de Inteligência Artificial ou Ciência de Dados",
        "Cientistas de Dados que queiram aumentar seus conhecimentos em algoritmos de inteligência artificial"
      ]
    },
    {
      "title": "[OpenCV] 파이썬 딥러닝 영상처리 프로젝트 - 손흥민을 찾아라!",
      "url": "https://www.udemy.com/course/opencv-son/",
      "bio": "OpenCV)로 이미지와 영상을 처리하고, 딥러닝 모듈을 활용하여 얼굴, 눈, 다양한 사물을 식별하고 인식하는 재미있는 프로젝트를 이론과 함께 배우는 과정입니다.",
      "objectives": [
        "OpenCV 이미지, 동영상 처리",
        "OpenCV dnn(Deep Learning) 이해와 실습",
        "이미지에서 물체식별(Object Detection)",
        "이미지, 동영상에서 물체식별(Object Detection)",
        "이미지, 동영상에서 물체인식(Object Recognition)",
        "YOLO 등 다양한 Computer Vision 기법"
      ],
      "course_content": {
        "OpenCV와 영상처리의 기본": [
          "OpenCV와 강의소개",
          "래스터(비트맵)와 벡터이미지",
          "OpenCV 설치하기"
        ],
        "이미지 가공하기": [
          "이미지 픽셀 좌표체계",
          "이미지에 그리기",
          "이미지 변형하기",
          "이미지 마스킹(Masking)",
          "이미지 채널(Channel)조작"
        ],
        "Haar방식 얼굴, 눈 식별(Face, eye Detection)": [
          "Haar-cascade Detection이란?",
          "Haar방식을 이용한 Face Detection",
          "Haar방식 Face Detection GUI 프로그램",
          "Haar방식 Face Detection 동영상 처리",
          "Haar방식 Face Detection 동영상 GUI 프로그램"
        ],
        "딥러닝(OpenCV dnn)을 이용한 얼굴 식별(Face Detection)": [
          "OpenCV dnn 딥러닝 모듈",
          "dnn 딥러닝 방식을 이용한 Face Detection",
          "dnn 딥러닝 방식 Face Detection GUI 프로그램",
          "dnn 딥러닝 방식 Face Detection 동영상 처리",
          "dnn 딥러닝 방식 Face Detection 동영상 GUI 프로그램"
        ],
        "YOLO를 이용한 사물 식별(Object Detection)": [
          "YOLO란 무엇인가?",
          "YOLO 사물 식별(Object Detection) 프로그램",
          "YOLO 사물 식별 동영상 프로그램"
        ],
        "face_recognition을 이용한 얼굴 인식": [
          "얼굴 인식(Face recognition) 정보 추출",
          "얼굴 인식(Face recognition) 프로그램",
          "얼굴 인식(Face recognition) GUI 프로그램",
          "얼굴 인식(Face recognition) 동영상 프로그램",
          "얼굴 인식(Face recognition) 프로그램 최적화"
        ],
        "[특별강의] Face Recognition강화하기": [
          "Face Detection 3대 기법",
          "OpenCV dnn Face Detection 코드해설 1",
          "OpenCV dnn Face Detection 코드해설 2",
          "Face_Recognition 라이브러리 설치"
        ],
        "[특별강의] Face Landmark와 Alignment": [
          "Face Landmark란?",
          "Face Landmark 코드해설",
          "Face Alignment 소개하기",
          "Face Alignment 코드해설 1",
          "Face Alignment 코드해설 2",
          "Face Recognition 인식률 높이기"
        ]
      },
      "requirements": [
        "열심히 배우고자 하는 의지",
        "파이썬 프로그램 기초지식",
        "파이썬 데이터 가공, 시각화 프로그램 경험"
      ],
      "description": "머신러닝, 딥러닝을 배워서\n실전에서 어떻게 활용할까요?\n딥러닝이 영상에서 손흥민 선수를 찾아 준다면\n재미있지 않을까요?\nComputer Vision분야에서 OpenCV와 딥러닝을\n활용하는 방법과 예제를 같이 배웁니다.\n\n\n- 강의소개\n인공지능, 머신러닝, 딥러닝을 배우고 강의하면서 이론적인 기초를 다지는 것이 중요한 만큼 실전에서 활용할 능력을 키우는 것도 중요하다고 생각했습니다.\n그래서 인공지능, 머신러닝, 딥러닝을 사용하는 대표적인 영역인 Computer Vision분야의 프로젝트를 준비하게 되었습니다.\n대표적인 이미지, 영상처리 소프트웨어 라이브러리인 OpenCV와 딥러닝 모듈인 dnn 그리고 다양한 기법과 모듈을 활용하여\n\n이미지와 영상처리의 기본을 배우고\n얼굴, 눈 그리고 다양한 물체를 식별하고\n이미지와 영상 속에서 원하는 사람을 학습을 통해 찾아내는\n재미있는 과제를 이론과 함께 한단계 씩 배워나갈 수 있도록 강의를 구성했습니다.\n과정을 마치고나면 다양한 Computer Vision 딥러닝 프로젝트를 꿈꾸게 될 것입니다.\n저 역시 과정을 만들면서 침입탐지, 졸음방지, 숫자나 글씨인식, 감정확인, 나이와 성별인식 등 여러 가지 아이디어를 만들고자하는 생각이 들었습니다.\n\n\n- 프로젝트 소개\n먼저 이미지와 영상을 다루는 기법에 대해서 배우고 출발해야겠지요?\n딥러닝을 본격적으로 활용하기에 앞서 OpenCV의 핵심 기법을 차근차근 배워나갑니다.\n\n\n\n\n이제 이미지와 영상에서 얼굴과 눈을 식별(Face, eye Detection)해 볼까요?\nOpenCV와 Haar, 딥러닝이 우리를 도와줄 것입니다.\n\n\n\n\n최신 ComputerVison 기술이 이미지와 영상 속에서 사람을 인식(Face Recognition)합니다.\n영화와 뉴스에 나오는 얼굴인식 기술을 직접 배우고 활용해 보세요.\n\n\n얼굴만 인식(Face Recognition)하는 것이 아니고 다양한 사물(Object Recognition)을 찾을 수 있습니다.\nYOLO와 그 친구들이 이미지와 영상 속에서 원하는 물체를 찾아줍니다.\n\n\n\n\n특별강의\n'[OpenCV] 파이썬 딥러닝 영상처리 프로젝트 - 손흥민을 찾아라!' 강의에는 '얼굴인식(Face recognition)을 강화하는 내용의 'Face Landmark와 Alignment' 단원을 추가했습니다.\n\n\n- 어떤 툴을 사용하나요?\n이 강의에서 다루는 툴은 어떤 것들이 있을까요?\n이 강의는 대표적인 ComputerVision 소프트웨어 라이브러리인 OpenCV와 파이썬을 기반으로 합니다.\n이 외에도 몇가지 유용한 소프트웨어를 설치하는데 강의 속에서 하나씩 설명드립니다.\n\n\n\n- 궁금해요!\nQ. 이 강의는 어떤 특징을 가지고 있나요?\nA. 딥러닝, 머신러닝을 실전에서 활용하는 방법을 고민했습니다.\n이 과정은 대표적인 분야인 Computer Vision관련된 이론 설명 뿐 아니라 실전 프로젝트를 통해서 딥러닝을 배우게 됩니다.\n\n\nQ. 비전공자도 들을 수 있나요?\nA. 딥러닝이나 데이터 과학은 꼭 전산을 전공한 분만 할 수 있는 분야가 아닙니다.\n여러분의 열정만 있다면 충분히 배우고 활용할 수 있는 내용입니다.",
      "target_audience": [
        "딥러닝을 실전에서 활용하고 싶은 분",
        "딥러닝을 이용한 영상처리에 대해 배우고 싶은 분",
        "Computer Vision과 관련한 프로젝트를 준비하는 분",
        "OpenCV를 이해하고 활용하고자 하는 분",
        "딥러닝 영상처리 최신 기법을 배우고자 하는 분"
      ]
    },
    {
      "title": "IA ACADEMY - Curso de ChatGPT e Inteligência Artificial",
      "url": "https://www.udemy.com/course/ia-academy-curso-de-chatgpt-e-inteligencia-artificial/",
      "bio": "Aprenda conceitos de Inteligência Artificial, como ela funciona e como explorar os melhores recursos do mercado.",
      "objectives": [
        "Criar produtos digitais completos e gerar ideias",
        "Agilize a sua criação de conteúdo",
        "Crie copys, roteiros e scripts:",
        "Economize incontáveis horas de trabalho chato e repetitivo",
        "Elabore estratégias lucrativas",
        "Otimize times e processos"
      ],
      "course_content": {
        "Introdução": [
          "Módulo 01",
          "Qual o meu objetivo com o curso",
          "Como tirar o máximo proveito"
        ],
        "Módulo 02": [
          "Aula 01 - Big Data",
          "Aula 02 - Machine Learning",
          "Aula 03 - Inteligência Artificial",
          "Aula 04 - ChatGPT"
        ],
        "Módulo 03": [
          "Aula 05 - Cases",
          "Aula 06 - Startups disruptivas de AI"
        ],
        "Módulo 04": [
          "Aula 07 - Hackeando o ChatGPT",
          "Aula 08 - Copywriting",
          "Aula 09 - Copywriting",
          "Aula 10 - Copywriting",
          "Aula 11 - Copywriting",
          "Aula 12 - Design",
          "Aula 13 - Deisgn",
          "Aula 14 - Deisgn",
          "Aula 15 - Deisgn",
          "Aula 16 - Deisgn",
          "Aula 17 - Edição de Vídeo",
          "Aula 18 - Edição de Vídeo",
          "Aula 19 - Edição de Vídeo",
          "Aula 20 - Edição de Vídeo",
          "Aula 21 - Otimização de Marketing",
          "Aula 22 - Otimização de Marketing",
          "Aula 22 - Otimização de Marketing",
          "Aula 23 - Otimização de Marketing",
          "Aula 24 - Avatares Digitais",
          "Aula 25 - Otimização de Marketing",
          "Aula 26 - Produtividade",
          "Aula 27 - Produtividade",
          "Aula 28 - Produtividade",
          "Aula 29 - Produtividade"
        ],
        "Módulo 05": [
          "Aula 30 - Como fazer dinheiro com Inteligência Artificial",
          "Aula 31 - Como fazer dinheiro com Inteligência Artificial 02",
          "Aula 32 - Como fazer dinheiro com Inteligência Artificial 03",
          "Aula 33 - Como fazer dinheiro com Inteligência Artificial 04"
        ],
        "Módulo 06": [
          "Aula 34 - Pensar no hoje olhando para o futuro",
          "Aula 35 - Como ser insubstituível",
          "Aula 36 - Aproveitando as oportunidades"
        ]
      },
      "requirements": [
        "Conhecimento básico em ChatGPT e demais ferramentas de Inteligência Artificial."
      ],
      "description": "O Marketing Digital como conhecemos está passando por uma drástica mudança. O ChatGPT é apenas o começo dessa revolução.\nExistem várias outras ferramentas de inteligência artificial ainda desconhecidas por muitos, mas que podem impulsionar seus resultados digitais em até 10x ou mais.\n\n\nE essas novas ferramentas de IA vieram para ficar e mudar para sempre o mercado digital, e todos os profissionais do digital que não se adaptarem, irão perder espaço no mercado e terão dificuldades de se posicionar no mercado.\n\n\nA I.A. Academy é um curso que vai te guiar por todo o universo da inteligência artificial, desde os conceitos básicos até as últimas tendências do mercado. Nós organizamos todo o conteúdo de forma clara e objetiva, para que você possa aprender de maneira eficiente e aplicar os conhecimentos em sua realidade profissional.\n\n\nCom a I.A. Academy, você terá acesso às melhores ferramentas de inteligência artificial e aprenderá exatamente como utilizá-las de forma correta, economizando horas de trabalho em tarefas repetitivas e chatas, permitindo que você se concentre nas coisas mais importantes, como criar estratégias e ser mais criativo.\n\n\nA I.A. Academy é a oportunidade perfeita para você se tornar um profissional diferenciado com conhecimentos em inteligência artificial e se destacar no mercado.",
      "target_audience": [
        "Profissionais de Marketing",
        "Empresários",
        "Estrategistas Digitais",
        "Influenciadores e criadores de conteúdo"
      ]
    },
    {
      "title": "Transformerを詳しく学ぼう！ -PyTorchで実装するAttention、Transformer-",
      "url": "https://www.udemy.com/course/learning_transformer/",
      "bio": "生成AI、大規模言語モデル（LLM）のベースとなる技術、「Transformer」について詳しく学ぶ講座です。Python、PyTorchを使って必要なユニットを順を追って実装し、最終的にTransformerを組み立てます。",
      "objectives": [
        "Transformerの仕組みを基礎から学びます。",
        "Python、PyTorchを使い、Transformerを構築する方法を学びます。",
        "Attention、EncoderやDecoderなどのTransformerの構成要素について学びます。",
        "Transfomerのコードの読み書きができるようになります。",
        "生成AI、大規模言語モデル（LLM）の背景の仕組みを学ぶことができます。"
      ],
      "course_content": {
        "Transformerの概要": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "Transformerの概要",
          "開発環境について",
          "PyTorchの概要",
          "PyTorchの使い方",
          "セクション1の演習"
        ],
        "Attentionの仕組み": [
          "セクション2の教材",
          "Section2の概要",
          "Attentionの概要",
          "Scaled Dot-Product Attention",
          "Multi-HeadAttention",
          "セクション2の演習"
        ],
        "Transformerにおける埋め込み": [
          "セクション3の教材",
          "Section3の概要",
          "Token Embedding",
          "Positional Encoding",
          "Position-wise Feed-Forward Networks",
          "Layer Normalization",
          "セクション3の演習"
        ],
        "Transformerを組み立てる": [
          "セクション4の教材",
          "Section4の概要",
          "Encoderの構築",
          "Decoderの構築",
          "Transformerの構築",
          "Transformerの訓練",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "コードを動かすためにGoogle Colaboratoryを使用しますが、ローカル環境はWindowsでもMacでも大丈夫です。",
        "2023年11月の環境で解説しています。最新の環境と異なる可能性があります。",
        "Googleのアカウント開設が必要です。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "高校レベル以上の数学の知識があるのが望ましいです。",
        "「AIの使いこなし方」の解説はありません。",
        "バックプロパゲーション（誤差逆伝播法）、損失関数、最適化アルゴリズムなどの、深層学習の基礎の解説は省略します。",
        "フレームワークPyTorchの使い方の解説は最低限です。"
      ],
      "description": "「Transformerを詳しく学ぼう！」は、生成AIのベースとなる技術、「Transformer」について詳しく学ぶ講座です。\nTransformerがどのような仕組みで機能しており、生成AIの躍進を支えているのかを掘り下げていきます。\n理解を深めるために、本講座ではフレームワークPyTorchを使ってTransformerの実装にトライします。\n\n\nTransformerをベースにした大規模言語モデル（LLM）は現在様々な分野で驚異的な性能を発揮し、幅広く活用されています。\n特にGPT-3.5やGPT-4が使われているChatGPTは、自然言語を使った対話により自然な文章を生成可能なので、大きな注目を集めています。\nLLMは様々なタスクをこなせる汎用性を備えており、これまで人間しかできなかった様々なタスクを任せることが可能になってきています。\n\n\n本講座では、最初にTransformerの概要を学んだ上で、Attentionの仕組み、埋め込みなどについて順を追って学んでいきます。\nそして、最後にここまでの内容を踏まえてTransformerを組み立てます。\nTransformerを詳しく学び、生成AIに対する深い洞察力を身につけましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! 人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. Transformerの概要\n→ Transformerの概要や、開発環境について学びます。\nSection2. Attentionの仕組み\n→ TransformerのベースであるAttentionの仕組み、実装について学びます。\nSection3. Transformerにおける埋め込み\n→ Transformerにおける入力のベクトル化について学びます。\nSection4. Transformerを組み立てる\n→ ここまでの内容を踏まえて、PyTorchを使いTransformerを組み立てます。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "Transformerの仕組みを基礎から学びたい方。",
        "生成AIの動作原理を基礎から知りたい方。",
        "AI技術のトレンドに追随したい方。",
        "Transformersなどの既存のライブラリを使わずに、Transomerの実装にトライしたい方。",
        "これから本格的に大規模言語モデル（LLM）を学びたい方。"
      ]
    },
    {
      "title": "Machine Learning A-Z: Projektbasiertes Lernen im Bereich KI",
      "url": "https://www.udemy.com/course/machine-learning-projektbasiert/",
      "bio": "Lerne Python für Machine Learning und Data Science: Regression, Klassifikation, NLP, Neuronale Netze mit TensorFlow uvm.",
      "objectives": [
        "Entwickle deine eigenen Machine-Learning-Modelle in Python",
        "Keine Programmierkenntnisse erforderlich, du lernst alles Notwendige",
        "Arbeite an realen Projekten aus dem Bereich Machine Learning (Kundenkaufverhalten vorhersagen, Immobilienpreise prognostizieren, ...)",
        "Lerne, wie du mithilfe von Machine Learning wertvolle Erkenntnisse aus echten Daten gewinnen kannst",
        "Verstehe, welche Machine-Learning-Algorithmen du in welchen Fällen brauchen wirst",
        "Arbeite mit den wichtigsten Python-Bibliotheken im Bereich Machine Learning: Scikit-learn, TensorFlow, Keras, XGBoost, NLTK uvm.",
        "Verstehe alle Konzepte mithilfe von vielen Praxisbeispielen"
      ],
      "course_content": {
        "Einführung": [
          "Herzlich willkommen!",
          "Grundbegriffe - Teil 1",
          "Grundbegriffe - Teil 2",
          "Grundbegriffe - Teil 3",
          "Hier findest du alle Datensätze, Code-Beispiele und Vorlagen",
          "Ordnerstruktur und Einführung in Google Colab"
        ],
        "Erste Schritte mit Python": [
          "Variablen und bedingte Anweisungen - Teil 1",
          "Variablen und bedingte Anweisungen - Teil 2",
          "Praxisaufgabe 1 - Vorlage",
          "Praxisaufgabe 1 - Lösung",
          "Datentypen und Schleifen - Teil 1",
          "Datentypen und Schleifen - Teil 2",
          "Benachrichtigung von Google Colab",
          "Praxisaufgabe 2 - Vorlage",
          "Praxisaufgabe 2 - Lösung",
          "Funktionen",
          "Praxisaufgabe 3 - Vorlage",
          "Praxisaufgabe 3 - Lösung",
          "Funktionen mit Rückgabewert und Bibliotheken",
          "Erinnerung: Den verlinkten Ordner aus Lektion 5 herunterladen UND entpacken",
          "Weitere Bibliotheken (Pandas/Seaborn)",
          "Praxisaufgabe 4 - Vorlage",
          "Praxisaufgabe 4 - Lösung"
        ],
        "Trainiere deine ersten KI-Modelle!": [
          "Lineare Regression (Reloaded)",
          "Lineare Regression in Python - Teil 1",
          "Lineare Regression in Python - Teil 2",
          "Lineare Regression in Python - Teil 3",
          "Entscheidungsbaum (Reloaded)",
          "Entscheidungsbaum in Python - Teil 1",
          "Entscheidungsbaum in Python - Teil 2",
          "(Optional) Mathematische Vertiefung - Methode der kleinsten Quadrate",
          "(Optional) Mathematische Vertiefung - Gini-Unreinheit"
        ],
        "Projekt 1 - Kundenkaufverhalten und Unternehmensgewinne vorhersagen": [
          "Projektvorlage in Python",
          "Projektlösung in Python - Teil 1",
          "Projektlösung in Python - Teil 2"
        ],
        "Multiple Lineare Regression": [
          "Multiple Lineare Regression - Intuition",
          "Multiple Lineare Regression in Python - Teil 1",
          "Multiple Lineare Regression in Python - Teil 2",
          "Multiple Lineare Regression in Python - Teil 3"
        ],
        "Projekt 2 - Auswirkungen von Marketinginvestitionen auf den Tourismussektor": [
          "Projektvorlage in Python",
          "Projektlösung in Python"
        ],
        "Polynomiale Regression": [
          "Polynomiale Regression - Intuition",
          "Polynomiale Regression in Python - Teil 1",
          "Polynomiale Regression in Python - Teil 2",
          "Polynomiale Regression in Python - Teil 3"
        ],
        "Projekt 3 - Analyse des Einflusses von Schlaf auf unser emotionales Wohlbefinden": [
          "Projektvorlage in Python",
          "Projektlösung in Python"
        ],
        "Decision Tree Regression": [
          "Decision Tree Regression - Intuition",
          "Modellvalidierung und Hyperparameteroptimierung - Intuition",
          "Decision Tree Regression in Python - Teil 1",
          "Decision Tree Regression in Python - Teil 2",
          "Decision Tree Regression in Python - Teil 3",
          "Decision Tree Regression in Python - Teil 4",
          "Kreuzvalidierung - Intuition",
          "Decision Tree Regression in Python - Teil 5",
          "Weitere Metriken - MSE und RMSE",
          "(Optional) - Mathematische Vertiefung - Decision Tree Regression (Costfunction)"
        ],
        "Projekt 4 - Ermittlung von Immobilienpreisen in Washington": [
          "Projektvorlage in Python",
          "Projektlösung in Python"
        ]
      },
      "requirements": [
        "Es sind keine Programmierkenntnisse in Python nötig.",
        "Du lernst alles, was du wissen musst."
      ],
      "description": "Bist du fasziniert von Machine Learning und Data Science? Dann tauche mit diesem Kurs in die spannende Welt der Daten ein und erlebe, wie viel Spaß es macht, komplexe Probleme mit intelligenten Technologien zu lösen!\nIch werde dir Schritt für Schritt die wichtigsten Konzepte beibringen, um dir den optimalen Einstieg zu ermöglichen.\nZusätzlich erhältst du in diesem Kurs die Möglichkeit, an 14 realen Python-Projekten zu arbeiten. Mit diesen Projekten wirst du die erlernten Konzepte vertiefen und ihre praktische Anwendung erleben.\nNach Beendigung des Kurses kannst du alle Projekte in dein Projektportfolio aufnehmen, um beispielsweise potenziellen Arbeitgebern zu demonstrieren, an welchen spannenden Projekten du gearbeitet und welche wertvollen Fähigkeiten du erworben hast.\nIn diesen Projekten geht es unter anderem um folgende Themen:\nKundenkaufverhalten und Unternehmensgewinne vorhersagen\nUntersuchung der Auswirkungen von Marketingausgaben auf den Tourismussektor\nAnalyse des Einflusses von Schlaf auf unser emotionales Wohlbefinden\nPrognose von COVID-19-Neuinfektionen und Aktienkursen\nZielgruppenidentifikation für die Expansion in neue Märkte\nAutomatisierte Kundenbewertungsanalyse im Bereich E-Commerce\nVorhersage der Trinkwasserqualität mithilfe eines Random Forest Classifiers\nDieser Kurs deckt die wichtigsten Themen im Bereich Machine Learning und Data Science ab:\nRegression:\nLineare Regression\nMultiple Lineare Regression\nPolynomiale Regression\nDecision Tree Regression\nRandom Forest Regression\nXGBoost Regression\nTime Series Regression\nKlassifikation:\nDecision Tree Classifier\nLogistische Regression\nKNN - K-Nächste-Nachbarn\nSVM - Support Vector Machine\nNaiver Bayes-Klassifikator\nK-Means Clustering\nNLP - Natural Language Processing:\nTokens erstellen\nPart-of-speech tagging\nLemmatisierung\nCount-Features erstellen\nKünstliche neuronale Netze - Deep Learning mit TensorFlow und Keras:\nFunktionsweise von Neuronen\nZusammensetzung: Input Layer, Hidden Layers, Output Layer\nAktivierungsfunktionen\nBatch-Größen und Epochen\nBackpropagation-Algorithmus\nWeitere Konzepte:\nVisualisierung und Analyse von Daten\nData Preprocessing und Data Pipelines\nKreuzvalidierung\nHyperparameteroptimierung\nFeature Engineering\nRegressionsmetriken: MAE, MSE, RMSE, ...\nKlassifikationsmetriken: Accuracy, Precision, Recall, F1-Score, ...\nWichtigsten Python-Bibliotheken:\nScikit-learn\nPandas\nNumPy\nMatplotlib\nSeaborn\nXGBoost\nTensorFlow\nKeras\nNLTK",
      "target_audience": [
        "Alle, die sich für Machine Learning, Data Science und Künstliche Intelligenz interessieren."
      ]
    },
    {
      "title": "Phân tích và trực quan hóa dữ liệu với Tableau",
      "url": "https://www.udemy.com/course/phan-tich-va-truc-quan-hoa-du-lieu-voi-tableau/",
      "bio": "Phân tích dữ liệu, Trực quan hóa dữ liệu, Khoa học dữ liệu",
      "objectives": [
        "Phát triển tư duy phân tích và kỹ năng sử dụng dữ liệu hiệu quả",
        "Làm chủ các thao tác xử lý, làm sạch và kết nối dữ liệu từ nhiều nguồn",
        "Xây dựng các dashboard tương tác, chuyên nghiệp bằng Tableau.",
        "Biết cách kể chuyện bằng dữ liệu để truyền tải insight cho người xem",
        "Sẵn sàng cho các vai trò liên quan đến phân tích hoặc trực quan hóa dữ liệu."
      ],
      "course_content": {
        "Làm quen với Tableau": [
          "Làm quen với Tableau",
          "Làm quen với Tableau (Thực hành)"
        ],
        "Kết nối và chuẩn bị dữ liệu (Data Preparation)": [
          "Kết nối và chuẩn bị dữ liệu (Data Preparation)",
          "Kết nối và chuẩn bị dữ liệu (Thực hành)"
        ],
        "Trực quan hóa dữ liệu (các biểu đồ cơ bản)": [
          "Tạo các biểu đồ cơ bản",
          "Tạo các biểu đồ cơ bản (Thực hành)"
        ],
        "Phân nhóm, tập hợp, sắp xếp, bộ lọc, tham số, phân cấp dữ liệu": [
          "Phân nhóm, tập hợp, sắp xếp, bộ lọc, tham số, phân cấp dữ liệu",
          "Phân nhóm, tập hợp, sắp xếp, bộ lọc, tham số, phân cấp dữ liệu (Thực hành)"
        ],
        "Tính toán trong Tableau (Calculated Fields)": [
          "Tính toán trong Tableau (Calculated Fields)",
          "Tính toán trong Tableau (Thực hành)"
        ],
        "Các biểu đồ nâng cao": [
          "Các biểu đồ nâng cao",
          "Các biểu đồ nâng cao (Thực hành)"
        ],
        "Phân tích mô tả (Descriptive Analytics) với Tableau": [
          "Phân tích mô tả (Descriptive Analytics) với Tableau",
          "Phân tích mô tả (Descriptive Analytics) với Tableau (Thực hành)"
        ],
        "Xây dựng Dashboard tương tác (Interactive Dashboard)": [
          "Xây dựng Dashboard tương tác (Interactive Dashboard)",
          "Xây dựng Dashboard tương tác (Thực hành)"
        ],
        "Sử dụng Dashboard kể chuyện với dữ liệu (Data Storytelling)": [
          "Sử dụng Dashboard kể chuyện với dữ liệu (Data Storytelling)",
          "Sử dụng Dashboard kể chuyện với dữ liệu (Thực hành)"
        ],
        "Hướng dẫn triển khai dự án cuối khóa (Capstone Project)": [
          "Hướng dẫn triển khai dự án cuối khóa (Capstone Project)"
        ]
      },
      "requirements": [
        "Không cần kinh nghiệm hay kiến thức cơ bản nào."
      ],
      "description": "Khóa học giúp người học phát triển tư duy phân tích và kỹ năng sử dụng dữ liệu hiệu quả. Cụ thể, sau khóa học, học viên sẽ:\nHiểu rõ tầm quan trọng của phân tích và trực quan hóa dữ liệu trong phân tích và ra quyết định.\nLàm chủ các thao tác tiền xử lý, làm sạch và kết nối dữ liệu từ nhiều nguồn.\nBiết cách tạo các biểu đồ phù hợp để truyền đạt thông tin hiệu quả từ cơ bản đến nâng cao.\nBiết cách sử dụng Tableau để thực hiện phân tích mô tả và đánh giá các bộ dữ liệu\nPhân loại được các loại Dashboard phổ biến và nắm được qui trình xây dựng Dashboard\nXây dựng các dashboard tương tác, chuyên nghiệp bằng Tableau.\nBiết cách sử dụng Dashboard kể chuyện bằng dữ liệu (Data storytelling) để truyền tải insight cho người xem.\nBiết cách triển khai dự án về phân tích và trực quan hóa dữ liệu qua Capstone Project\nSẵn sàng cho các vai trò liên quan đến phân tích hoặc trực quan hóa dữ liệu như Phân tích kinh doanh, phân tích tài chính, phân tích Marketing, phân tích khách hàng",
      "target_audience": [
        "Người mới bắt đầu tìm hiểu về phân tích và trực quan hóa dữ liệu",
        "Sinh viên các trường đại học, nhất là khối ngành kinh tế, kinh doanh",
        "Nhân viên văn phòng có liên quan đến báo cáo, tổng hợp dữ liệu",
        "Chuyên viên Thống kê, chuyên viên Phân tích dữ liệu"
      ]
    },
    {
      "title": "Algoritmos Genéticos em R",
      "url": "https://www.udemy.com/course/algoritmos-geneticos-em-r/",
      "bio": "Construa passo a passo um algoritmo de Inteligência Artificial aplicado no cenário de transporte de produtos!",
      "objectives": [
        "Aprenda na teoria e na prática os principais conceitos sobre os algoritmos genéticos, tais como: indivíduo, população, crossover/reprodução, mutação, função de avaliação/fitness e seleção de indivíduos",
        "Implemente um algoritmo genético passo a passo no R para resolver um problema real de transporte de mercadorias",
        "Visualize as soluções do algoritmo genético utilizando gráficos",
        "Utilize o algoritmo genético integrado com uma base de dados no MySql"
      ],
      "course_content": {
        "Introdução": [
          "Problema a ser resolvido",
          "Conteúdo do curso",
          "Algoritmos evolucionários x algoritmos genéticos",
          "Mais sobre Inteligência Artificial"
        ],
        "Algoritmos genéticos passo a passo": [
          "Instalação do R e RStudio",
          "Classe produtos",
          "Classe indivíduo I",
          "Classe indivíduo II",
          "Função de avaliação",
          "Crossover/reprodução - teoria",
          "Crossover/reprodução - implementação",
          "Mutação",
          "Inicialização da população",
          "Avaliação da população",
          "Melhor indivíduo",
          "Soma das avaliações",
          "Seleção dos indivíduos - teoria",
          "Seleção dos indivíduos - implementação",
          "Construção de nova geração",
          "Algoritmo genético completo I",
          "Algoritmo genético completo II",
          "Algoritmo genético completo III",
          "Gráfico das soluções",
          "Instalação do MySql",
          "Criação da tabela de produtos no MySql",
          "Algoritmo genético com banco de dados",
          "Biblioteca GA em R I",
          "Biblioteca GA em R II"
        ],
        "Considerações finais": [
          "Considerações finais",
          "Código fonte completo",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "É recomendado conhecimento sobre lógica de programação, principalmente estruturas condicionais e de repetição",
        "Conhecimentos básicos em R são desejáveis, embora seja possível acompanhar o curso sem saber essa linguagem com profundidade",
        "Noções sobre orientação a objetos são necessárias, principalmente conceitos como classe, objeto, atributo e método",
        "Não são necessários conhecimentos prévios sobre Inteligência Artificial",
        "Não são necessários conhecimentos prévios sobre banco de dados"
      ],
      "description": "Os algoritmos genéticos são uma importante área da Inteligência Artificial que são responsáveis pela resolução de problemas complexos, tendo como base encontrar soluções para problemas de otimização e busca. Existem várias aplicações práticas deste tipo de algoritmo, as quais podem ser aplicadas na resolução de problemas em cenários comerciais do dia a dia. Um exemplo clássico é a resolução do problema de choque de horários de professores em uma escola, no qual existem diversas combinações de horários e aulas e o objetivo é construir a grade de horário dinamicamente de acordo com a quantidade de aulas e a disponibilidade de cada professor. Outros exemplos são: empresas de telecomunicações podem projetar novas redes óticas, transportadoras podem planejar melhor a rota de entrega de mercadorias, investidores podem escolher os melhores investimentos; dentre várias outras.\n\nBaseado nisso, neste curso você vai aprender na teoria e principalmente na prática como desenvolver do zero um algoritmo genético aplicado em um cenário real de uma transportadora. Neste contexto, nós seremos consultores de uma empresa de transporte que possui vários produtos a serem transportados, porém, a empresa possui somente um caminhão disponível e com espaço limitado de armazenamento. Nosso objetivo será desenvolver um algoritmo que consiga gerar a melhor combinação dos produtos que devem ser transportados, levando em consideração o fato de que a transportadora quer ganhar o máximo de dinheiro possível com o frete e ocupando o espaço disponível no caminhão.\nEsse tipo de algoritmo é baseado em encontrar soluções cada vez melhores a partir da evolução das gerações anteriores, sendo fundamentado nos processos naturais de evolução. E para chegar em nosso objetivo, você vai aprender os principais conceitos sobre essa técnica de inteligência artificial, tais como: população, indivíduo, crossover/reprodução e mutação. Ao final do curso, você terá um algoritmo genético completo que conseguirá resolver o problema da transportadora, o qual pode ser aplicado para outros cenários comerciais. Utilizaremos a linguagem R para a programação das funções e desenvolveremos tudo passo a passo e com muitos detalhes, para que você tenha uma visão bem clara e didática de como esses algoritmos conseguem resolver problemas reais do cotidiano. Além disso, teremos um bônus no qual você vai aprender como criar uma tabela de produtos no MySql e aplicar nosso algoritmo utilizando os dados de uma base de dados, o que pode facilitar a adaptação do código para utilização em ambientes comerciais. Por fim, este material pode ser considerado de nível iniciante para quem está entrando tanto na área de Inteligência Artificial quanto na área de algoritmos genéticos. Porém, caso você seja de nível mais avançado, este curso poderá servir como uma ótima fonte de consulta e revisão dos conceitos.\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial",
        "Pessoas interessadas em resolver problemas reais utilizando algoritmos genéticos"
      ]
    },
    {
      "title": "PyTorch ile Derin Öğrenme",
      "url": "https://www.udemy.com/course/pytorch-ile-derin-ogrenme/",
      "bio": "PyTorch kütüphanesi ile Derin Öğrenme Projeleri Oluşturma",
      "objectives": [
        "PyTorch Kütüphanesi ile Derin Öğrenme"
      ],
      "course_content": {
        "Giriş": [
          "Giriş",
          "Kurulumlar",
          "Jupyter Notebook ve Lab ilk Dokunuşlar"
        ],
        "Numpy Kütüphanesi": [
          "Numpy Kütüphanesi - Array Oluşturma",
          "Numpy Kütüphanesi - zeros, ones ve linspace Kullanımı",
          "Numpy Kütüphanesi - Rastgele Veri Üretme",
          "Numpy Kütüphanesi - Vektörde Veriye Erişme",
          "Numpy Kütüphanesi - Matrislerde Veriye Erişme",
          "Numpy Kütüphanesi - Matematiksel İşlemler"
        ],
        "Pandas Kütüphanesi": [
          "Pandas Kütüphanesi - Seriler",
          "Pandas Kütüphanesi - DataFrames",
          "Pandas Kütüphanesi - DataFrames -drop, loc, iloc",
          "Pandas Kütüphanesi - DataFrames - Şartlı Filtreleme",
          "Pandas Kütüphanesi - DataFrames",
          "Pandas Kütüphanesi - read_csv, to_csv metodları",
          "Pandas Kütüphanesi - groupby",
          "Pandas Kütüphanesi - Bazı önemli metodlar",
          "Numpy Kütüphanesi - Web'den ve Dosyalardan Veri Okuma"
        ],
        "PyTorch Temelleri": [
          "PyTorch Kütüphanesi",
          "PyTorch - Kurulum ve Tensör Oluşturma",
          "PyTorch Kütüphanesi - tensor,Tensor, arange, linspace",
          "PyTorch Kütüphanesi - Rastgele Sayı Oluşturma",
          "PyTorch Kütüphanesi - view ve reshape metodları",
          "PyTorch Kütüphanesi - Matematiksel İşlemler",
          "PyTorch Kütüphanesi - Matematiksel İşlemler -2"
        ],
        "Maknine Öğrenmesi": [
          "Makine Öğrenmesi Nedir?",
          "Overfitting ve Underfitting",
          "Sınıflandırma için Doğruluk Metrikleri",
          "Regresyon için Doğruluk Metrikleri",
          "Unsupervised (Gözetimsiz) Öğrenme Nedir?"
        ],
        "Yapay Sinir Ağları (Artificial Neural Networks)": [
          "Bölüm İçeriği",
          "Perceptron Model",
          "Çok Katmanlı Sinir Ağları",
          "Aktivasyon Fonksiyonları",
          "Çoklu Sınıflandırma için Aktivasyon Fonksiyonları",
          "Cost Fonksiyonu ve Gradient Descent",
          "Backpropagation",
          "PyTorch ile Gradient Alma",
          "PyTorch ile Lineer Regresyon-1",
          "PyTorch ile Lineer Regresyon-2",
          "PyTorch'da Veri Setleri ile İşlem Yapma"
        ],
        "Proje -1 Iris Veri Seti İçin Derin Öğrenme Modeli Oluşturma": [
          "Genel Bilgi ve Veri Setini Alma",
          "Model Oluşturma ve Parametrelerle Sonuç Alma",
          "Modeli Test Verisinde Deneme"
        ],
        "Evrişimsel Sinir Ağları": [
          "Evrişimsel Sinir Ağları - CNN",
          "MNIST Veri Seti",
          "MNIST Veri Setinin İndirilmesi",
          "MNIST Veri Setinin Görselleştirilmesi",
          "MNIST Veri Seti İçin Model Oluşturulması",
          "MNIST Veri Seti İçin Model Oluşturulması - 2",
          "MNIST Veri Seti İçin Modelin Eğitilmesi",
          "MNIST Veri Seti İçin Oluşturulan Model Sonuçlarının Görselleştirilmesi",
          "MNIST Veri Seti Modelinin Değenlendirilmesi",
          "Konvülüsyon Nedir?",
          "Konvülüsyon Katmanları"
        ]
      },
      "requirements": [
        "Temel Python bilgisi"
      ],
      "description": "Facebook tarafından geliştirilen PyTorch kütüphanesi en temel seviyeden başlayarak projeler ile örneklendirilerek bilgilerinize sunulmuştur. Kursun içeriği temel olarak aşağıda paylaşılmıştır:\n1. Kurulum\n2. Numpy Kütüphanesi\n3. Pandas Kütüphanesi\n4. PyTorch Temelleri\n5. Makine Öğrenmesi\n6. Yapay Sinir Ağları-Örnek Proje\n7. Evrişimsel Sinir Ağları -Örnek Proje\n8.Doğal Dil İşleme - Örnek Proje\nVideolarda anlatılan uygulamalar ve ek dosyalar paylaşılmıştır. Ödev ve quizler eklenecektir.Katılımcıların yorum ve önerileri doğrultusunda ilave video dersleri hazırlanmaktadır.",
      "target_audience": [
        "Veri bilimine meraklı, başlangıç seviyesindeki Python geliştiricileri"
      ]
    },
    {
      "title": "Curso de series temporales multivariantes con R y Python",
      "url": "https://www.udemy.com/course/curso-de-series-temporales-multivariantes-con-r-y-python/",
      "bio": "Aprende a analizar series de tiempo multivariantes con casos prácticos como el análisis de datos del mercado financiero",
      "objectives": [
        "Introducción al mundo multivariante de las series temporales",
        "Implementación de los análisis en R y Python",
        "Estudio de Precios del mercado financiero",
        "Estudios de los mercados de USA, Filipinas, Sudáfrica",
        "Estudio de datos de calidad del aire",
        "Estudios de ingeniería y calidad de sensores",
        "¿Cómo analizar series de tiempo multivariantes en la práctica?",
        "Modelo VAR vector autorregressive model para series de tiempo multivariantes",
        "Causalidad de Granger",
        "Pronosticar múltiples series de tiempo"
      ],
      "course_content": {},
      "requirements": [
        "Es recomendable haber cursado anteriormente el curso de series temporales con R y Python",
        "Es opcional haber cursado anteriormente el curso de estadística multivariante con R y Python",
        "Se necesitan conocimientos básicos de programación en R y en Python",
        "Disponer de un ordenador con conexión a internet para utilizar R y Python"
      ],
      "description": "El mundo del análisis de Series Temporales o Series de Tiempo cada vez va tomando más y más fuerza. Y es que muchas veces nos encontramos con aplicaciones prácticas que dependen del tiempo de alguna manera, por ejemplo, cuando estamos analizando los datos del reciente virus COVID19 que está afectando a todo el planeta, tendremos datos diarios de casos activos, casos nuevos detectados, o incluso muertes en cada uno de esos días. Estos datos son importantísimos a la hora de pronosticar de cara al futuro qué va a pasar, si van a subir o van a bajar esos casos.\nPero, ¿para qué nos sirve esto? Pues para mucho más de lo que te imaginas. Porque saber aproximadamente lo que va a pasar en el futuro nos puede dar una idea de si esto significará que el sistema sanitario va a colapsarse pronto, y esto nos permite tomar medidas urgentes antes de que realmente pase esa situación de colapso que puede ser una emergencia realmente desastrosa para la sociedad. Por otro lado, puede significar que se ha logrado controlar la situación lo suficiente como para comenzar la desescalada del confinamiento. En fin, como ves, tener una idea cercana del futuro más próximo nos permite actuar con antelación, y tomar medidas de emergencia para evitar desastres mayores.\nEl análisis de series temporales también es muy utilizado en Finanzas y Economía, usualmente para analizar datos del mercado financiero. En este curso vamos a tratar con muchos dataset de datos reales de precios o variables macroeconómicas de diferentes mercados: USA, Filipinas, Sudáfrica, etc, y lo veremos paso a paso tanto con R como con Python.\n¿Qué diferencia hay entre este curso y un curso regular de series de tiempo univariantes?\n¡EL ASPECTO MULTIVARIANTE!\nAsí es, como bien sabes nuestro mundo no es univariante, es multivariante, muchas veces tendremos a nuestra disposición múltiples datos, en nuestro caso múltiples series temporales que se co-relacionan entre sí y proporcionan información valiosa unas a otras. Por ejemplo, para un vendedor de cócteles que está estudiando las ventas diarias de su chiringuito de la playa, será interesante estudiar la serie temporal de la temperatura del ambiente, la serie de cócteles diarios vendidos, la serie temporal de los precios, la de las ganancias, la serie de cantidad de cócteles ofertados, la serie de la cantidad de sillas dispuestas en la arena, etc. Todas estas series son información relevante y muchas de ellas se relacionan entre sí, por eso, para estudiarlas, debemos hacer uso de las técnicas para el análisis de series temporales multivariantes.\nEn este curso cubriremos desde los conceptos más básicos del campo de las series de tiempo univariantes (para que lo tengas todo a mano en un solo curso), hasta el concepto de serie de tiempo multivariante, sus propiedades, su modelización, tanto en R como en Python, y más de 10 casos prácticos diferentes de series temporales multivariantes para que puedas poner en práctica todos estos conocimientos.\nAdemás, tendrás todo el código fuente desde el minuto cero, plantillas de código para utilizar en tus propios análisis, acceso a una comunidad exclusiva de estudiantes, que como tú, buscan aprender acerca del análisis de series temporales, y más de 15 horas de vídeo de alta calidad con todas las explicaciones necesarias para aplicar por ti mismo estos conocimientos.\nNos vemos en clase y espero que disfrutes del Curso de series temporales multivariantes con R y Python.",
      "target_audience": [
        "Estudiantes de ingenierías, medicina o economía que busquen entender las correlaciones basadas en el tiempo y los modelos de series temporales",
        "Estudiantes de estadística que quieran profundizar en el análisis de tiempo",
        "Ingenieros de IA y ML que quieran conocer acerca del análisis de series temporales",
        "Estudiantes de doctorado que quieran conocer acerca del análisis de series temporales",
        "Empresas o usuarios que quieran hacer análisis de finanzas, evolución de datos médicos, y en general de cualquier información que dependa del tiempo"
      ]
    },
    {
      "title": "تحليل البيانات بأستخدام بايثون",
      "url": "https://www.udemy.com/course/data-analysis/",
      "bio": "تحليل البيانات من الصفر الي الاحتراف",
      "objectives": [
        "سوف تتعلم ماهو تحليل البيانات و ما هي اهميته",
        "سوف تتعلم الاحصاء و الرياضيات اللازمة قبل البدء في محتوي الدورة",
        "سوف تتعلم المكتبات اللازمة في بايثون لتحليل البيانات",
        "سوف تتعلم المراحل اللازمة لتحليل البيانات بداية من تنظيف و اعداد البيانات الي عرضها بيانيا و تحليلها"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "hey..!",
          "The Content Of Course"
        ],
        "Statistics": [
          "The Mean",
          "Mode",
          "std",
          "median",
          "IQR"
        ],
        "Python Libraries": [
          "Install Anaconda",
          "Files",
          "Numpy Part 1",
          "Numpy Part 2",
          "Numpy Part 3",
          "Numpy Part 4",
          "Pandas Part 1",
          "Pandas Part 2",
          "Pandas Part 3",
          "Pandas Part 4",
          "Pandas Part 5",
          "Pandas Part 6",
          "Pandas Part 7",
          "Pandas Part 8",
          "Pandas Part 9",
          "Pandas Part 10",
          "Pandas Part 11",
          "Pandas Part 12",
          "Matplotlib Part 1",
          "Matplotlib Part 2",
          "Matplotlib Part 3",
          "Matplotlib Part 4",
          "Matplotlib Part 5",
          "Matplotlib Part 6",
          "Matplotlib Part 7",
          "Matplotlib Part 8",
          "Matplotlib Part 9",
          "Seaborn"
        ],
        "Data Analysis Process": [
          "Understand Your Data",
          "Data Cleaning",
          "Data Preprocessing"
        ],
        "Projects": [
          "Project 1",
          "Project 2"
        ]
      },
      "requirements": [
        "اساسيات لغة البرمجة بايثون فقط"
      ],
      "description": "السلام عليكم و رحمة الله و بركاته\nاهلا بكم في دورة تحليل البيانات ب استخدام لغة البرمجة بايثون\nفي هذه الدورة سوف نتعرف ما المقصود بتحليل البيانات و ما هي اهميته و كيف نستفاد منه ثم سوف ننتقل الي القسم الثاني و هو\nالخاص ب تعلم الرياضيات و الاحصاء اللازمة سوف نشرحها بشكل سهل و بسيط ان شاء الله و محتواه هو :\n- شرح المتوسط الحسابي\n- شرح الوسط الحسابي\n- شرح شرح الانحراف المعياري\n- شرح ما هو IQR\nثم سوف ندخل في القسم الثالث و فيه سوف نتعلم المكتبات التي سوف يتم استخدمها في تحليل البيانات و التي سنعمل بها و محتواها :\n- مكتبة numpy\n- مكتبة pandas\n- مكتبة matplotlib\n- بعض من sklearn\nثم ندخل بعد ذلك في القسم الاخير و هو الخاص ب مراحل تحليل البيانات و التي سوف نتعلم فيه ما هي مراحل تحليل البيانات و\nنتدرب عليهم و محتواها :\n- تنظيف البيانات (data cleaning)\n- معالجة البيانات (data preprocessing)\n- عرض البيانات (data visualization)\nثم اخيرا نقوم بالعمل علي مشاريع لنطبق عليها كل ما تعلمناه في هذه الدورة , سوف نقوم بالتطبيق علي مشروعين سوف نعمل عليهم من البداية الي النهاية  :\n- المشروع الاول : بيانات لدرجات اختبارات لطلاب\n- المشروع الثاني : بيانات خاصة ب مواصفات عدد من الوحدات السكانية\nو في المشروعين سوف نطبق عليهم ما تعلمناه خلال الدورة و سوف نتعلم اشياء اخري جديدة\nاتمني لكم التوفيق و النجاح",
      "target_audience": [
        "اي شخص يريد ان يتعلم تحليل البيانات باستخدام بايثون"
      ]
    },
    {
      "title": "ChatGPT: Yapay Zeka ile Sohbet İpuçları ve Taktikleri",
      "url": "https://www.udemy.com/course/sifirdan-chatgpt-egitimi/",
      "bio": "Yapay Zeka Rehberliğinde Sohbet Becerilerinizi Geliştirin: ChatGPT ile İletişim Sanatı",
      "objectives": [
        "ChatGPT'yi kullanmayı öğreneceksiniz.",
        "ChatGPT ile neler yapabildiğinizi öğreneceksiniz.",
        "ChatGPT ile işlerinizi kolaylaştırmayı öğreneceksiniz.",
        "ChatGPT ile kazancınızı ve verimliliğinizi arttırmayı öğreneceksiniz.",
        "ChatGPT ile kodlama yapmayı ve program yazmayı öğreneceksiniz.",
        "ChatGPT ile problem çözmeyi öğreneceksiniz.",
        "Yapay zeka mantığını öğreneceksiniz.",
        "DALL-E'yi öğreneceksiniz.",
        "DALL-E ile neler yapabildiğinizi öğreneceksiniz."
      ],
      "course_content": {
        "Giriş": [
          "Giriş",
          "OpenAI Nedir?",
          "Yapay Zeka Nedir?",
          "Geleceğin İşleyişine Şekil Veren Yapay Zeka!",
          "ChatGPT Nedir?",
          "ChatGPT ile Para Kazanma",
          "DALL-E Nedir?"
        ],
        "ChatGPT'ye Giriş": [
          "ChatGPT'ye Giriş",
          "ChatGPT Arayüzü",
          "Soru Sorma ve Sohbet Etme"
        ],
        "ChatGPT ile İşlerimizi Kolaylaştırma": [
          "Tavsiye İsteme ve Plan Yaptırma",
          "Direkt Cevaplar Alma ve Araştırma Yapma",
          "Paragrafın Ana Düşüncesini Bulma, Roman ve Şiir Yazdırma",
          "Matematik Soruları Çözdürme",
          "Maddeler Halinde Slayt için Tanımlar Alma",
          "Kodlama Yaptırma",
          "Kodları Düzelttirme",
          "Tanıtım Metni Yazdırma",
          "Çeviri Yaptırma",
          "Özet Çıkarma",
          "SEO İşlemi Yaptırma ve Anahtar Kelime Buldurma",
          "Hızlı Slayt Oluşturma",
          "Türev, İntegral Çözdürme ve Çalışma Soruları Hazırlatma",
          "İngilizce Öğrenmek için ChatGPT Kullanımı",
          "Makale Yazdırma",
          "Mail Yazdırma",
          "Instagram Gönderi Metni Hazırlatma ve Hashtag Önerileri",
          "Ürün Açıklaması Yazdırma, Marka İsmi Buldurma ve Alt Başlık Önerisi",
          "CV Hazırlatma ve Kariyer Hedefi Yazdırma",
          "Diyet Listesi Hazırlatma",
          "Egzersiz Listesi Hazırlatma",
          "Ders Çalışma Programı Hazırlatma",
          "FMEA Raporu Hazırlatma",
          "KAIZEN Raporu Hazırlatma",
          "Üretim İş-Akış Şeması Hazırlatma",
          "\"Hello World\" Yazdırmanın 10 Yolu"
        ],
        "Diğer Yapay Zeka Modelleri": [
          "DALL-E",
          "Midjourney",
          "VALL-E",
          "BlueWillow",
          "SlidesAI",
          "Leonardo AI",
          "Eğitimde Yapay Zeka"
        ]
      },
      "requirements": [
        "Herhangi bir ön gereksinim yoktur, herkes bu eğitime katılabilir."
      ],
      "description": "Bu eğitimde, OpenAI tarafından geliştirilen ChatGPT aracılığıyla doğal dil işleme alanındaki becerilerinizi geliştireceksiniz. Aynı zamanda da ChatGPT teknolojisi ile birlikte doğal dil işleme alanında kendinizi geliştirerek, gündelik dilde, işletmelerde, müşteri hizmetleri ve daha birçok alanda kullanılacak yapay zeka destekli sohbet uygulamaları tasarlama becerisi kazanacaksınız. Ayrıca, ChatGPT'nin endüstriyel uygulamalarına da dair örnekler ve fikirler sunulacak ve kurs sonunda, kendi başınıza yapay zeka destekli çeşitli uygulamalar oluşturabileceksiniz. Kurs boyunca öğreneceğiniz beceriler arasında, ChatGPT'nin girdi ve çıktı formatlarının anlaşılması, ChatGPT'nin özelliklerinin ve işlevlerinin kullanımı, ChatGPT ile birlikte çalışarak yapay zeka destekli uygulamalar oluşturma, ChatGPT'nin endüstriyel uygulamalarının keşfi ve daha fazlası yer almaktadır. Doğal dil işleme alanında çalışan veya yapay zeka teknolojilerine ilgi duyan herkes için bu eğitim harika bir fırsat olacaktır. Umarız hazırladığımız bu eğitim sizlere faydalı olur, eğitimde görüşmek üzere!\nChatGPT, OpenAI tarafından geliştirilen ve diyalog konusunda uzmanlaşmış bir prototip yapay zekâ sohbet robotudur. Chatbot, hem denetimli hem de takviyeli öğrenme teknikleriyle ince ayar yapılmış büyük bir dil modelidir. İnce ayarı yapılan temel model, GPT-3'ün geliştirilmiş bir sürümü olan OpenAI'nin GPT-3.5 dil modelidir. ChatGPT, insan konuşmalarını taklit etmenin ötesinde görevleri yerine getirebilen çok yönlü bir sohbet robotudur. Bilgisayar programları, müzik, tele-oyunlar, peri masalları ve öğrenci kompozisyonları yazabilir. Test sorularını yanıtlayabilir, şiir ve şarkı sözleri yazabilir, bir Linux sistemini taklit edebilir, bir sohbet odasını simüle edebilir, oyun oynayabilir ve bir ATM'yi simüle edebilir. Eğitim verileri programlama dilleri ve internet fenomenleri hakkında bilgi içerir. Öncülü InstructGPT'den farklı olarak ChatGPT, karşı olgusal istemleri kabul ederek ve potansiyel olarak rahatsız edici çıktıları filtreleyerek zararlı ve aldatıcı yanıtları azaltmaya çalışır. Ayrıca önceki yönlendirmeleri hatırlar ve kişiselleştirilmiş bir terapist olarak kullanılabilir.\nOpenAI, yapay zeka ve makine öğrenimi teknolojileri üzerine araştırma, geliştirme ve dağıtım yapan bir araştırma şirketidir. Şirket, 2015 yılında Elon Musk, Sam Altman, Greg Brockman ve diğerleri tarafından kurulmuştur ve yapay zeka teknolojilerinin olumlu yönlerini keşfetmek ve geliştirmek amacıyla faaliyet göstermektedir. OpenAI, açık kaynaklı yapay zeka teknolojileri geliştirerek, yapay zeka alanındaki gelişmelere katkıda bulunmak istemektedir. Şirket, özellikle doğal dil işleme, görüntü işleme, oyun oynama, robotik ve diğer alanlarda çalışmalar yürütmekte ve yapay zeka teknolojilerinin toplumun faydasına kullanılmasını teşvik etmektedir.",
      "target_audience": [
        "ChatGPT'yi öğrenmek isteyenler",
        "ChatGPT'yi merak edenler",
        "İşlerini kolaylaştırmak isteyenler",
        "Kazanç ve verimliliğini arttırmak isteyenler",
        "Yapay zeka alanına ilgi duyanlar",
        "Yazılım ve programlamaya ilgi duyanlar"
      ]
    },
    {
      "title": "เรียน Python Data Structures and Algorithms ฉบับปูพื้นฐาน",
      "url": "https://www.udemy.com/course/pythondsa/",
      "bio": "เรียนเขียนโปรแกรม Python Data Structures and Algorithms ฉบับ Python Data Structures and Algorithms Zero to Hero",
      "objectives": [
        "ผู้เรียนจะเข้าใจเนื้อหาของโครงสร้างข้อมูลและอัลกอริทึมด้วยการเขียนโปรแกรมภาษา Python",
        "ผู้เรียนจะได้รับความเข้าใจอย่างถี่ถ้วนเกี่ยวกับเนื้อหาของโครงสร้างข้อมูลและอัลกอริทึมด้วยการเขียนโปรแกรมภาษา Python",
        "ผู้เรียนสามารถนำโครงสร้างข้อมูลและอัลกอริทึมไปต่อยอดประยุกต์ใช้งานจริงด้วยการเขียนโปรแกรมภาษา Python",
        "ผู้เรียนสามารถนำความรู้ที่ได้ไปประยุกต์ใช้ทำ Project ต่าง ๆ ในการเรียนและการทำงานจริงได้"
      ],
      "course_content": {
        "Recursions in Python เขียนโปรแกรมด้วยการวนซ้ำตัวเองแบบอัตโนมัติ": [
          "Recursion Exercise 1: Iterative Products Delivery",
          "Recursion Exercise 2: Recursive Products Delivery",
          "Recursion Exercise 3: Calculating Factorial",
          "Recursion Exercise 4.1 Assign Arguments",
          "Recursion Exercise 4.2 Global Mutable State",
          "Recursion Exercise 4.3 A List is an example of a Recursive Data Structure",
          "Recursion Exercise 5.1: List Input of a Recursive Data Structure",
          "Recursion Exercise 5.2: List Input of a Recursive Data Structure",
          "Recursion Exercise 6: Fibonacci"
        ],
        "Stacks in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบสแตก": [
          "Stack Exercise 1: Creating Stack using list Built-in --> List Functions",
          "Stack Exercise 2: Creating Stack using list Built-in --> stack = Empty",
          "Stack Exercise 3: Creating Stack using list Built-in --> Automatics",
          "Stack Exercise 4: Python Stack Implementation --> Creating Stack Class",
          "Stack Exercise 5: Coverting Decimal Numbers to Binary Numbers Using Stacks"
        ],
        "Queues in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบคิว": [
          "Queue Exercise 1: Creating Queue using list Built-in",
          "Queue Exercise 2: Creating Queue using list Built-in --> Automatics",
          "Queue Exercise 3: Python Queue Implementation --> Creating Queue Class",
          "Queue Exercise 4: Cicular Queue Implementation"
        ],
        "Deque in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบเดค": [
          "Deque Exercise 1 - 3: Creating Deque and Deque Operations 1 - 3"
        ],
        "Linked Lists in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบลิงก์ลิสต์": [
          "Linked Lists and Big O Notation",
          "Linked List Exercise 1: Singly Linked Lists",
          "Linked List Exercise 2: Doubly Linked Lists",
          "Linked List Exercise 3: Circular Linked Lists"
        ],
        "Trees in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบต้นไม้": [
          "Understanding Trees Data Structures",
          "Applications of Tree Data Structures",
          "Binary Trees and Tree Traversals",
          "Binary Search Tree"
        ],
        "Graph in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบกราฟ": [
          "Understanding Graph Data Structures",
          "Applications of Graph Data Structure",
          "Graph Search Algorithms",
          "Graph Exercise 1: Basic Graph",
          "Graph Exercise 2: Breadth-First Search and Exercise 3: Depth-First Search"
        ],
        "ตะลุยโจทย์ Python Recursion": [
          "Factorial Functions",
          "Drawing the English Ruler",
          "Recursion Binary Search Algorithms",
          "Recursion The Sum of a List of Numbers",
          "Recursion List Sum",
          "Recursion Fibonacci Functions",
          "Recursion Sum of Integer Numbers",
          "Recursion Sum of the Integers",
          "Recursion Harmonic Sum",
          "Recursion Geometric Sum",
          "Recursion Value of A to the Power B",
          "Recursion Greatest Common Divisor"
        ],
        "ตะลุยโจทย์ Python Arrays": [
          "Dynamic Arrays",
          "Implementing Dynamic Arrays",
          "Storing High Scores for a Game",
          "Caesar Cipher using Array-Based Sequences",
          "Tic Tac Toe"
        ],
        "ตะลุยโจทย์ Python Stacks": [
          "Stacks FILO First In Last Out",
          "Stacks Reversing Data using a Stack",
          "Stacks an Algorithm for Matching Delimiters"
        ]
      },
      "requirements": [
        "ผู้เรียนไม่จำเป็นต้องมีความรู้ด้านการเขียนโปรแกรมมาก่อน คุณจะได้เรียนรู้ทุกสิ่งที่คุณอยากเรียน"
      ],
      "description": "หลักสูตร เรียนเขียนโปรแกรม Python Data Structures and Algorithms ด้วยตัวเอง ฉบับคนไม่เคยเขียนโปรแกรม\nสามารถเรียนได้ทุกคน ไม่จำเป็นต้องมีความรู้ด้านการเขียนโปรแกรมมาก่อน\nเนื้อหาการเรียน Python Data Structures and Algorithms\nแบ่งเป็น 14 ส่วน\nส่วนที่ 1: Recursions in Python เขียนโปรแกรมด้วยการวนซ้ำตัวเองแบบอัตโนมัติ\n1. Recursion Exercise 1: Iterative Products Delivery\n2. Recursion Exercise 2: Recursive Products Delivery\n3. Recursion Exercise 3: Calculating Factorial\n4. Recursion Exercise 4.1 Assign Arguments\n5. Recursion Exercise 4.2 Global Mutable State\n6. Recursion Exercise 4.3 A List is an example of a Recursive Data Structure\n7. Recursion Exercise 5.1: List Input of a Recursive Data Structure\n8. Recursion Exercise 5.2: List Input of a Recursive Data Structure\n9. Recursion Exercise 6: Fibonacci\nส่วนที่ 2: Stacks in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบสแตก\n10. Stack Exercise 1: Creating Stack using list Built-in --> List Functions\n11. Stack Exercise 2: Creating Stack using list Built-in --> Stack = Empty\n12. Stack Exercise 3: Creating Stack using list Built-in --> Automatics\n13. Stack Exercise 4: Python Stack Implementation --> Creating Stack Class\n14. Stack Exercise 5: Coverting Decimal Numbers to Binary Numbers Using Stacks\nส่วนที่ 3: Queues in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบคิว\n15. Queue Exercise 1: Creating Queue using list Built-in\n16. Queue Exercise 2: Creating Queue using list Built-in --> Automatics\n17. Queue Exercise 3: Python Queue Implementation --> Creating Queue Class\n18. Queue Exercise 4: Circular Queue Implementation\nส่วนที่ 4: Deque in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบเดค\n19. Deque Exercise 1 - 3: Creating Deque and Deque Operations 1 - 3\nส่วนที่ 5: Linked Lists in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบลิงก์ลิสต์\n20. Linked Lists and Big O Notation\n21. Linked List Exercise 1: Singly Linked Lists\n22. Linked List Exercise 2: Doubly Linked Lists\n23. Linked List Exercise 3: Circular Linked Lists\nส่วนที่ 6: Trees in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบต้นไม้\n24. Understanding Trees Data Structures\n25. Applications of Tree Data Structures\n26. Binary Trees and Tree Traversals\n27. Binary Search Tree\nส่วนที่ 7: Graph in Python เขียนโปรแกรมด้วยโครงสร้างข้อมูลและอัลกอริทึมแบบกราฟ\n28. Understanding Graph Data Structures\n29. Applications of Graph Data Structure\n30. Graph Search Algorithms\n31. Graph Exercise 1: Basic Graph\n32. Graph Exercise 2: Breadth-First Search and  Exercise 3: Depth-First  Search\nส่วนที่ 8: ตะลุยโจทย์ Python Recursion\n33. Factorial Functions\n34. Drawing the English Ruler\n35. Recursion Binary Search Algorithms\n36. Recursion The Sum of a List of Numbers\n37. Recursion List Sum\n38. Recursion Fibonacci Functions\n39. Recursion Sum of Integer Numbers\n40. Recursion Sum of the Integers\n41. Recursion Harmonic Sum\n42. Recursion Geometric Sum\n43. Recursion Value of A to the Power B\n44. Recursion Greatest Common Divisor\nส่วนที่ 9: ตะลุยโจทย์ Python Arrays\n45. Dynamic Arrays\n46. Implementing Dynamic Arrays\n47. Storing High Scores for a Game\n48. Caesar Cipher using Array-Based Sequences\n49. Tic Tac Toe\nส่วนที่ 10: ตะลุยโจทย์ Python Stacks\n50. Stacks FILO First In Last Out\n51. Stacks Reversing Data using a Stack\n52. Stacks an Algorithm for Matching Delimiters\nส่วนที่ 11: ตะลุยโจทย์ Python Queues\n53. Queues FIFO First In First Out\n54. Queues Priority Queue\n55. Queues Circular Queue\nส่วนที่ 12: ตะลุยโจทย์ Python Deques\n56. Deques Double-Ended Queues\nส่วนที่ 13: ตะลุยโจทย์ Python Linked Lists\n57. Linked List VS Array\n58. A Single Linked List\n59. Stack a Single Linked List\n60. Queue with a Single Linked List\n61. Circularly Linked Lists\n62. Doubly Linked Lists\n63. Deque with a Doubly Linked List\n64. The Positional List ADT\n65. Sorting a Positional List\n66. Maintaining Access Frequencies\nส่วนที่ 14: ตะลุยโจทย์ Python Trees\n67. Introduction to Trees\n68. Tree Traversals\n69. Pre/In/Post-Order Traversals\n70. Binary Search Tree\n71. Breadth First Traversal\n72. Count Leaf Nodes\n73. Finding Root to Leaf Paths",
      "target_audience": [
        "ผู้เริ่มต้นเรียนรู้การเขียนโปรแกรม นักพัฒนาโปรแกรม โปรแกรมเมอร์ ที่สนใจงานด้าน Data Science"
      ]
    },
    {
      "title": "Weltneuheit: Google Bard von A bis Z (+ Vergleich: ChatGPT)",
      "url": "https://www.udemy.com/course/google-bard-kurs/",
      "bio": "Der weltweit erste deutschsprachige Google Bard Kurs: Lerne alles über Googles ChatGPT Konkurrenten & KI-Tool (AI)",
      "objectives": [
        "Du lernst ALLES über Google Bard – von A bis Z.",
        "Du erfährst, wie du Google Bard in Deutschland nutzen und einsetzen kannst.",
        "Du wirst Google Bard von Null auf Hundert verstehen und einsetzen lernen.",
        "Du lernst die Top Use-Cases en Detail kennen und kannst sie 1:1 nachmachen.",
        "Du lernst, wie du mit Google Bard eigene Business aufbauen kannst.",
        "Du lernst, wie du mit Google Bard dein SEO professionell aufbaust.",
        "Du lernst, wie du Google Bard als Chatbot-Technologie effektiv in deinem Business und Marketing einsetzen kannst.",
        "Dich erwartet eine praxisnahe Anleitung, wie du Google Bard in verschiedenen Bereichen deines Business und Marketing einsetzen kannst."
      ],
      "course_content": {
        "Einstieg in den Kurs": [
          "Das erwartet dich in diesem Kurs",
          "So funktioniert dieser Kurs",
          "Bevor wir starten ...",
          "Zusätzliche Ressourcen",
          "So loggst du dich in Google Bard ein",
          "Quick View: Was kann Google Bard – und wie profitierst du davon?"
        ],
        "So konntest du Google Bart vor dem Launch nutzen": [
          "Google Bard in Deutschland nutzen VOR dem offiziellen Launch – So geht's!",
          "Wie du Google Bard schon jetzt auf Deutsch nutzen kannst"
        ],
        "Kickstart ins Thema: Die Top Features mit Google Bard": [
          "#1: Content kreieren auf einem neuen Level – so geht's!",
          "#2: Landingpages und ganze Websites auf Knopfdruck erstellen",
          "#3: SEO (Suchmaschinenoptimierung) leicht gemacht",
          "#4: Konkurrenzanalyse – So scannt Google Bard deine Konkurrenz für dich",
          "#5 E-Mails verfassen & direkt per Gmail versenden",
          "#6: Kreatives Schreiben – Codes, Programmierung, Poesie, Songs und mehr",
          "#7 – Businessplan schreiben mit Google Bard",
          "Weiterer Austausch",
          "#8 – Finanzanalysen: Deine Investments mit Bards Hilfe optimieren"
        ],
        "Businessmodelle aufbauen mit Google Bard": [
          "E-Book-Business mit Google Bard: Passives Einkommen per Amazon, etc.",
          "Online-Kurs-Business: Produziere Kurse mit Google Bard"
        ],
        "Persönliche Hilfen von Google Bard": [
          "Der perfekte Urlaub in 20 Sekunden organisiert: Reisepläne, Buchungen und mehr",
          "Gesund mit Google Bard: Ernährungspläne, Sportunterstützung und mehr"
        ],
        "Mehr Wissen rund um Google Bard": [
          "Bard Activity: Was verrät es über dich?",
          "FAQs & Update Historie",
          "Help- und Support-Features"
        ],
        "Kursabschluss": [
          "Das hast du gelernt – und das wirst du noch lernen ...",
          "Rechtliche Hinweise",
          "[Off-Topic] BONUSLEKTION: Die größten Vorteile einer Selbstständigkeit"
        ]
      },
      "requirements": [
        "Du benötigst keine Voraussetzungen für diesen Kurs."
      ],
      "description": "ChatGPT verursachte einen Hype, den man vorher nicht gekannt hat: In nur 5 Tagen (!) knackte das Tool von OpenAI die 1 Mio. Nutzer-Marke.\nWas nun folgt, wird diesen Rekord alt aussehen lassen: Kein geringerer Tech-Gigant als Google ist mit seinem AI-Tool \"Google Bard\" auf dem Vormarsch – und wird ChatGPT aller Wahrscheinlichkeit nach aus dem Markt drängen.\nDennoch bleiben tausende Fragezeichen:\nWas kann das Tool besser als ChatGPT?\nWird es dir deine KOMPLETTE Arbeit abnehmen?\nKannst du damit wirklich Geld verdienen, dein Marketing verbessern und und und?\nKannst du dank Google Bard GESÜNDER leben? Deine Reisen planen? Was geht damit privat?\nFragen über Fragen. Doch das Gute:\nIn diesem Kurs findest du ALLE Antworten darauf.\nDu lernst, wie du dein Business mit Google Bard aufbauen kannst. Du lernst, wie SEO, wie Marketing, wie Copywriting und viele andere Aufgaben in Sekunden gelöst werden.\nDu lernst, wie du deine Konkurrenz analysierst und ihre Schwächen ausmachst, um sie zu übertrumpfen.\nDu lernst, wie du deine privaten Ziele erreichst – mithilfe von Googles KI!\nUnd ja, all das funktioniert. Es ist nicht übertrieben, genau das zu versprechen. Du wirst in der Lage sein, all das zu tun – und wenn du es geschickt anwendest, arbeitest du nach diesem Kurs vielleicht nicht \"gar nicht mehr\" – aber zumindest erheblich weniger, freier und ohne Zeitdruck.\nAlso: Wenn du den ChatGPT Hype verpasst oder nie so ganz verstanden hast: Das hier ist eine andere Liga – und du kannst noch ganz vorn dabei sein.\nDu kannst Google Bard nutzen, bevor all deine Konkurrenten, Kollegen oder Mitarbeiter sich an das Tool heran wagen. Vor all dem wirst du der Experte zum Thema sein.\nBist du bereit dazu?\nDann nichts wie los: Schreibe dich noch heute in den Kurs ein und lege los.\nNatürlich hast du eine lupenreine 30-tägige Geld-zurück-Garantie sowie meinen üblichen 24/7 Support bei Fragen via E-Mail oder auf dieser Plattform.\nIch freue mich auf dich – und hoffe, wir sehen uns schon gleich im Kurs.\nDein Alex Schreiner",
      "target_audience": [
        "Jeder, der Google Bard vor allen Anderen nutzen und verstehe möchtest."
      ]
    },
    {
      "title": "①米国AI開発者がやさしく教える深層学習超入門第一弾【Pythonで実践】",
      "url": "https://www.udemy.com/course/deeplearning1/",
      "bio": "ニューラルネットワークとPytorchの基本",
      "objectives": [
        "深層学習の理論を深く理解することができます",
        "深層学習の基本的なモデル/学習をスクラッチで実装できるようになります",
        "Pytorchを使ってモデルを構築することができます",
        "GPUを使って深層学習モデルを学習できるようになります"
      ],
      "course_content": {
        "紹介": [
          "紹介",
          "深層学習について",
          "本講座の資料とコードについて",
          "補足教材"
        ],
        "環境準備": [
          "本セクションの補足(本講座用のDocker imageについて)",
          "環境構築概要(Docker + JupyterLab)",
          "M1チップをお使いの方へ",
          "DockerHubアカウント作成",
          "Windowsユーザへの補足",
          "Docker環境構築",
          "Dockerの基本操作",
          "次レクチャー補足",
          "JupyterLabの基本操作"
        ],
        "Tensor": [
          "PytorchとTensor",
          "Tensor作成【Python】",
          "Tensor操作と便利関数【Python】",
          "行列の演算【Python】",
          "Broadcasting",
          "Broadcasting【Python】",
          "まとめ"
        ],
        "ロジスティック回帰からニューラルネットワークへ": [
          "ロジスティック回帰(復習)",
          "最急降下法(復習)",
          "ベクトル/行列表記",
          "計算グラフ",
          "計算グラフを使った損失関数の勾配計算",
          "Autograd(自動微分)",
          "Autogradによる勾配計算【Python】",
          "中間ノードの勾配【Python】",
          "自動微分を無効化する【Python】",
          "まとめ"
        ],
        "多項ロジスティック回帰とニューラルネットワーク": [
          "多項ロジスティック回帰(復習)",
          "多クラス分類の損失関数(復習)",
          "MNISTデータセットで多項ロジスティック回帰【Python】",
          "Softmaxと交差エントロピー実装【Python】",
          "学習ループ仕上げ【Python】",
          "まとめ"
        ],
        "ミニバッチ(Mini-batch)学習": [
          "ミニバッチ(Mini-batch)学習とは",
          "ミニバッチ学習で学習【Python】",
          "次レクチャーのコード修正",
          "学習データと検証データの分割【Python】",
          "まとめ"
        ],
        "MLP(Multi Layer Perceptron)": [
          "2層のニューラルネットワーク(MLP)",
          "活性化関数",
          "ReLU",
          "MLP実装【Python】",
          "まとめ"
        ],
        "誤差逆伝播(Backpropagation)": [
          "ニューラルネットワークの学習の流れ",
          "出力層の誤差逆伝搬",
          "(補足)バイアス項の勾配",
          "隠れ層の誤差逆伝播",
          "ReLU層の逆伝搬",
          "逆伝搬の実装【Python】",
          "Autogradと結果が一致することを確認【Python】",
          "MLPをスクラッチ学習【Python】",
          "回帰モデルの逆伝搬",
          "次レクチャーの補足",
          "回帰モデルの逆伝搬【Python】",
          "Refactoring",
          "まとめ"
        ],
        "GPU": [
          "GPUについて",
          "Goole Colabの使い方",
          "GPU上でTensorを演算"
        ],
        "nnモジュール": [
          "torch.nnについて",
          "nn.LinearとF.relu",
          "nn.Linear【Python】",
          "モデル作成(nn.<クラス>+nn.<関数>)【Python】",
          "モデル作成(nn.<クラス>のみ)【Python】",
          "モデル作成(nn.Sequential)【Python】",
          "モデル学習",
          "モジュール/パラメータのイテレーション",
          "まとめ"
        ]
      },
      "requirements": [
        "線形代数と微分の基礎知識があると良いです",
        "事前に統計学講座と機械学習講座を受講しておくことを強くお勧めします",
        "Pythonの実装については，Pythonの基礎知識およびデータサイエンスに必要なライブラリの知識が必要です",
        "Pythonの知識がなくても本講座で深層学習の理論を学習することができます"
      ],
      "description": "深層学習の基礎をゼロから学べます．学習した理論をPythonでスクラッチで実装し，理論x実装の相乗効果で確実に深層学習を習得できます．\nまた，Pytorchを使用して深層学習のモデル学習も行うので，実務にも即応用できる内容です．\n(3部構成で，本講座は「第一弾」となっており，主にニューラルネットワークの基本やPytorchの基本的な使い方を解説しています．)\n【特徴】\n- 現役のAI開発者から学ぶ\n- 実際の現場でどのように使うのかを解説\n- 深層学習の事前知識は不要\n- 完全体系的に学ぶ\n- GPU不要．第一弾は全てローカルPCだけで実行可能\n- アルゴリズムのスクラッチ実装により完全に理解して進める\n- 数式を丁寧に解説\n- 図を多用しイメージで学ぶ\n- Pytorchでの実装も紹介\n- 学習したことをすぐに実データに適用可能\n- DockerとJupyterLabを使った本格データサイエンス環境 (Dockerを使って簡単環境構築)\n- これ1本で理論x実装が同時に，着実に学べる\n\n\n深層学習の理論とPythonの実装のレクチャーは別になっているため，理論だけを学習することも可能です．そのためPythonを知らなくても本講座で深層学習を学ぶことができます．\n\n\nPythonの実装のレクチャーは，Pythonの基礎知識とデータサイエンスに必要なPython(NumpyやMatplotlibなど)の知識が必要です．\nMacを使って講義を進めますが，環境が作れればWindowsでも問題ありません．\nDockerとJupyterLabを使った本格的なデータサイエンスの環境を使いますが，WindowsでDocker環境を作れれば，全く同じ環境を構築することができます．(Windowsでの環境構築のサポートはしておりません．あらかじめご了承ください)",
      "target_audience": [
        "AI開発やデータサイエンスに興味がある人",
        "データサイエンスのコンペ等に出たい人",
        "研究や授業で深層学習を勉強する必要がある人",
        "深層学習の基本を学びたい人",
        "これからAI開発のキャリアを目指している人"
      ]
    },
    {
      "title": "Ultimate Web Scraping for Data Science",
      "url": "https://www.udemy.com/course/ultimate-web-scraping-for-data-science/",
      "bio": "A complete guide for basic to advanced web scraping",
      "objectives": [
        "Learn the fundamentals, types, ethical considerations, advantages, and alternatives to web scraping.",
        "Understand how to create, explore, and utilize soup objects with Beautiful Soup, Requests, and pandas, culminating in a mini-project.",
        "Acquire skills in using Selenium for automating interactions with web pages, including locating elements, handling dropdowns, infinite scrolling, and dynamic co",
        "Master explicit and implicit waits, working with iframes and alerts, and optimizing scraping workflows for efficiency and reliability.",
        "Build two end-to-end projects, including scraping Yahoo Finance for stock data and extracting real estate listings, applying all learned skills in practical"
      ],
      "course_content": {
        "Introduction": [
          "Welcome Note & Course Structure"
        ],
        "Introduction to Web Scraping": [
          "Introduction to Web Scraping",
          "What is Web Scraping?",
          "Types of Web Scraping",
          "1.3 Ethical Considerations of Web Scraping",
          "Advantages of Web Scraping",
          "Disadvantages of Web Scraping",
          "Alternatives to Web Scraping"
        ],
        "Setting up Python Environment": [
          "Environment Setup",
          "About Anaconda",
          "Common Anaconda Prompts",
          "Creating a Project Environment and Kernel"
        ],
        "Primer On Web": [
          "Primer On Web",
          "Client Server Architecture",
          "HTTP Request & Response - Pt 1",
          "HTTP Request & Response - Pt 2",
          "HTTP Methods",
          "HTTP Status Codes",
          "Web Technologies"
        ],
        "Mastering Requests Library": [
          "Web Interaction with Requests Module",
          "About Requests",
          "Working with GET Method",
          "Working with POST Method",
          "Working with PUT and DELETE methods",
          "Working with HTTP Headers",
          "Working with Response Object",
          "Working with Public API"
        ],
        "Beautiful Soup": [
          "About Beautiful Soup",
          "Creating a Soup Object",
          "Exploring the Soup Object - 1",
          "Exploring the Soup Object - 2",
          "Exploring the Soup Object - 3",
          "Soup Object using Requests",
          "Mini Project using Beautiful Soup, Requests & Pandas - 1",
          "Mini Project using Beautiful Soup, Requests & Pandas - 2",
          "Mini Project using Beautiful Soup, Requests & Pandas - 3",
          "5.5.4 - Mini Project using Beautiful Soup, Requests & Pandas - 4"
        ],
        "Selenium": [
          "Web Automation using Selenium",
          "About Selenium",
          "Getting Started with Selenium",
          "Getting Started with Selenium",
          "Strategies for Locating Web Elements",
          "Understanding XPath",
          "Basic Interaction with Web Elements",
          "Basic Interaction with Web Elements",
          "Working with Dropdowns",
          "Working with MultiSelect",
          "Basic Scrolling",
          "Infinite Scrolling",
          "Advanced Web Interactions - Intro",
          "Explicit Waits",
          "Implicit Waits",
          "Working with IFrames",
          "Working with Alerts - 1",
          "Working with Alerts - 2",
          "Best Practices & Optimization - 1",
          "Best Practices & Optimization - 2"
        ],
        "Working with Captcha": [
          "Agenda",
          "8.1 - Understanding Captchas",
          "8.2 - Preventing Captchas",
          "8.3 - Handling Captchas (Theory)",
          "8.4 - Handling Captchas using input()",
          "8.5.1 - Handling Captchas using Modules",
          "8.5.2 - Handling Captchas using Modules - 2",
          "8.6 - Best Practices & Takeaways"
        ],
        "Scrapy": [
          "About Scrapy Module",
          "9.1.1 - Introduction to Scrapy",
          "9.1.2 - Installation",
          "9.1.3 - Basic Setup & Project Structure",
          "9.1.4 - Running a Spider",
          "9.2 - Spiders",
          "9.2.1 - Definition of Spider",
          "9.2.2 - Spider in Scrapy",
          "9.2.3 - Anatomy of Spider",
          "9.2.3 - Anatomy of Spider",
          "9.2.4 - Types of Spiders",
          "9.3 - Working with Scrapy",
          "9.3.1 - Scrapy Shell - 1",
          "9.3.1.2 - Scrapy Shell - 2",
          "9.3.2 - Scrapy Spider with Python",
          "9.4 - Advanced Features",
          "9.4.1 - Custom Spider Settings",
          "9.4.2 - Data & Item Pipelines",
          "9.4.3 - User-Agent Rotation & Proxy Usage",
          "9.4.4 - Login Pages",
          "9.4.5 - Handling APIs",
          "9.5 - Mini Project",
          "9.6 - Best Practices"
        ],
        "Real World Projects - Yahoo Finance Stocks": [
          "Project Intro",
          "Action Plan",
          "Prerequisites",
          "Prerequisites [Continued]",
          "Scraping the Data - 1",
          "Scraping the Data - 2",
          "Scraping the Data - 3",
          "Scraping the Data - 4",
          "Scraping the Data - 5",
          "Cleaning the Data - 1",
          "Cleaning the Data - 2",
          "Cleaning the Data - 3",
          "Restructuring the Code - 1",
          "Restructuring the Code - 2"
        ]
      },
      "requirements": [
        "A computer with an internet connection and Python installed.",
        "This course is beginner-friendly, and all concepts will be explained from the ground up.",
        "Familiarity with Python, including variables, loops, and functions, is recommended but not mandatory."
      ],
      "description": "In an era where data drives decisions, the ability to extract valuable information from websites is an indispensable skill. \"Webscraping for Data Science\" is your comprehensive guide to mastering webscraping, empowering you to turn raw web data into actionable insights.\nThis course is designed to take you from the basics to advanced concepts, ensuring you can confidently scrape both static and dynamic websites. You'll start with the fundamentals, exploring the types of webscraping, ethical considerations, and best practices. As you progress, you'll delve into practical tools like Beautiful Soup and Selenium, learning to navigate web pages, handle complex elements like dropdowns and infinite scrolling, and interact with dynamic content.\nWhat sets this course apart are the hands-on projects. You’ll build two real-world applications: scraping stock market data from Yahoo Finance and gathering real estate listings. These projects will reinforce your skills and provide a portfolio-worthy showcase of your abilities.\nThis course is ideal for aspiring data scientists, analysts, marketers, or anyone interested in working with web data. Basic Python knowledge is helpful but not mandatory, as we guide you step-by-step through each concept.\nBy the end of this course, you’ll have the expertise to extract and manipulate online data for data science, research, or business purposes.\nJoin us today and unlock the power of webscraping to advance your career and stand out in your league!",
      "target_audience": [
        "Aspiring Data Scientists and Analysts: Individuals looking to enhance their data collection skills and integrate webscraping into their data science workflows.",
        "Beginner Programmers: Learners with basic Python knowledge who want to explore webscraping as a new skill.",
        "Professionals in Marketing and Business: Those seeking to gather web data for market research, competitor analysis, or business intelligence.",
        "Students and Enthusiasts: Anyone curious about extracting and working with online data, regardless of their background."
      ]
    },
    {
      "title": "ხელოვნური ინტელექტის პრაქტიკული კურსი: Chatgpt, Midjourney",
      "url": "https://www.udemy.com/course/chatgpt-midjourney/",
      "bio": "როგორ გამოვიყენოთ ChatGPT და Midjourney ყოველდღიურად, პრობლემების გადასაჭრელად",
      "objectives": [
        "გამოიყენებ 2 ხელოვნურ ინტელექტს სრულყოფილად",
        "შეძლებ ულამაზესი სურათების გენერირებას სოც. ქსელისთვის, საიტისთვის,ბლოგისთვის. ყველგან, სადაც ლამაზი ვიზუალი გჭირდება",
        "შეძლებ ChatGPT გამოიყენო შენს ყოველდღიურ ცხოვრებაში: სამსახურში, პირადი იდეების გენერირებისათვის",
        "მიიღებ მზა იდეებს, როგორ შექმნა ბიზნესი ავტომატურ რეჟიმზე ხელოვნური ინტელექტით",
        "ავტომატური იმეილების დაგზავნა, პრეზენტაციების მომზადება, პროცესების ავტომატიზაცია",
        "მიღებული ცოდნით სამუშაოს მოძიება ონლაინ, კომპიუტერის დახმარებით (ონლაინ დასაქმება)",
        "მზა ბრძანებები, რომლებიც ავტომატურად შეასრულებენ წინასწარ განსაზღვრულ მოქმედებებს",
        "300 + Prompt-ი საჩუქრად",
        "1 უფასო სატელეფონო კონსულტაციის შესაძლებლობა კურსის ავტორთან",
        "წვდომა დახურულ ჯგუფზე, სადაცმუდმივად იდება განახლებები პრაქტიკული ხელოვნური ინტელექტის მიმართულებით"
      ],
      "course_content": {
        "შესავალი კურსში: რას ვისწავლით და როგორ მუშაობს AI ?": [
          "შესავალი, რა არის და როგორ მუშაობს ხელოვნური ინტელექტი ? Midjourney, ChatGPT",
          "რას შევძლებთ კურსის დასრულების შემდეგ და როგორ უნდა გავაიროთ კურსი ?"
        ],
        "Midjourney - ხელოვნური ინტელექტი,რომელიც ქმნის სურათებს, გრაფიკულ გამოსახულებებს": [
          "Midjourney - უფასო ვერსიის აქტივაცია, დისქორდი, Private სერვერი, Prompts",
          "Prompt-ების ოპტიმიზაცია, კარგი პრომპტების სია, ხარისხი, ქაოსი, ვარირება: U, V, S",
          "Prompt-ების ოპტიმიზაცია, ნაწილი N 2",
          "საკუთარი ან ნებისმიერი სურათის, დამუშავება, 2 სურათის შეერთება AI-ს მეშვეობით",
          "ახალი ლექცია - განახლებული ფუნქციები მიდჯერნიში (10.27.2023)"
        ],
        "ChatGPT სრულად, ანუ როგორ გამოვიყენოთ ჩათჯიპიტი სამსახურსა და ყოველდღიურად": [
          "OpenAI - CahtGPT-ის შემქნელი სისტემა, მუშაობის პრინციპები, პროგრამული ენები",
          "ChatGPT პრაქტიკულად: ბრძანებები, ინტეგრაცია სხვა სისტემებთან, ,,ღია გასაღები\"",
          "პრაქტიკული მაგალითები, 30 იდეა, თუ სად გამოვიყენოთ ახლავე ChatGPT",
          "DALL-E - დალი ანუ AI, რომელიც ქმნის ურათების, ChatGPT-ის შემქნელებისაგან"
        ],
        "Prompt Engineering - ის საფუძვლები": [
          "რა არის ბრძანებების ინჟინერია, ანუ პრომპტ ინჟინერია - რა მნიშვნელობა აქვს AI-ში?",
          "AIPRM პლაგინი ChatGPT-იში ჩასაშენებლად და ბრძანების გენერაციის გამარტივებისათვის",
          "Role Prompting, Examples - როლური ბრძანებები, მაგალითების მითითება",
          "Prompts for Copywriting - ბრძანებები ტექსტების გენერიებისათვის: ბლოგი, სტატია...",
          "100 კარგი პრომპტი ,,სტორითელინგისა\" და ,,კოპირაითინგისთვის\"",
          "საიტები პრომპტების გენერირებისათვის ან გასაყიდად"
        ],
        "ახალი AI სისტემები და საიტები, განსხვავებული ფუნქციებით": [
          "სურათით ვიდეოს შექმნა, ამოძრავება. ანუ სურათის გაცოცხლება AI-ით: Kaiber AI",
          "მიდჯერნის უფასო ალტერნატივა, ანუ Playground AI - სურთების გენერატორი AI",
          "ვიდეოების გენერაცია მხოლოდ დაწერილი ტექსტიდან, ანუ რევოლუციური Pictory AI"
        ],
        "პრაქტიკული გამოყენება, შეჯამება და დასაქმება მიღებული ცოდნით, AI-ს დახმარებით": [
          "როგორ დავსაქმდეთ ან მივიღოთ შეკვეთა, რომელსაც AI-ს დახმარებით შევასრულებთ ?",
          "შეჯამება მიღებული ცოდნის, ჩვენი მომავალი ურთიერთობა :)"
        ]
      },
      "requirements": [
        "კურსი გათვლილია სრულიად დამწყები ადამიანისათვის ამ დარგში",
        "კომპიუტერი",
        "ინტერნეტი",
        "ჩაი ან ყავა მუშაობისას სურვილისამებრ :)"
      ],
      "description": "ხელოვნური ინტელექტი ყველას გაგვიგია, მაგრამ ამ კურსში მე გიჩვენებ, პირადად შენ როგორ გამოიყენო პრაქტიკულად ის ყოველდღიურ ცხოვრებაში. ასევე გიჩვენებ მაგალითებს, იდეებს, თუ როგორ გაიმარტივო ცხოვრება ამ ინოვაციით, ანუ როგორ უბრძანო და გააკეთებინო ხელოვნურ ინტელექტს ნებისმიერი რამ, რაც გსურს.\n\nმერწმუნე, მას უკვე ძალიან ბევრი რამის გაკეთება შეუძლია შენთვის :) შეგიძლია სამსახურის საქმის უდიდესი ნაწილი სწორედ მას გააკეთებინო, ან ბიზნეს იდეები მოაწოდებინო, ან პროცესების ავტომატიზაცია, ანუ შენს ნაცვლად კეთება ,,შეუკვეთო\".\nთან ხელოვნური ინტელექტი უკვე ისეთი ჭკვიანია, რომ ვერავინ მიხვდება, შენს ნაცვლად ის რომ მუშაობს. მოკლედ, ძალიან ჭკვიანი მეგობარი და ამავე დროს, უსიტყვო შემსრულებელი შეგიძლია შეიძინო ხელოვნური ინტელექტის სახით, რომელთან ერთადაც უამრავი იდეის განხორციელებას შეძლებ.\n\nვისთვის არის ეს კურსი:\nეს კურსი ნებისმიერი ადამიანისთვისაა, რომელიც თანამედროვე ცხოვრებით ცხოვრობს - მუშაობს,იყენებს ციფრულ ტექნოლოგიებს, სოციალური ქსელებს, იმეილს, აქვს მიმოწერა უცხოელებთან. ხელოვნური ინტელექტის სისტემას პრაქტიკულად ნებისმიერი მიმართულებით შეუძლია ჩვენი დახმარება: დაწყებული პირადი ასისტენტობით, გაგრძელებული რჩევებით პირადი ცხოვრების, დიეტის, ან თუნდაც სავარჯიშო სისტემის შესახებ.\nთუმცა ყველაზე მეტად ეს კურსი ალბათ იმ ადამიანებს გამოადგებათ, ვისაც მარტივად ბევრი საქმის გაკეთება სურს. ხელოვნურ ინტელექტს შეუძლია უამრავი ადამიანის საქმე მარტომ გააკეთოს, შემოგვთავაზოს შესრულებული სამუშოას რამოდენიმე განსხვავებული ვერსია. ჩვენი ამოცანა კი მიღებული შედეგებიდან სასურველი ვარიანტის ამორჩევაა.\n\nმთავარია ცოდნა, თუ როგორც ვუბრძანოთ ხელოვნურ ინტელექტს, რომ შეასრულოს ის, რაც ჩვენ გვინდა. ამაში კი ჩვენი კურსი ზედმიწევნით დაგეხმარება.\n\nეს კურსი გზამკვლევი იქნება შენთვის ამ საინტერესო გზაზე. გზაზე, სადაც ბევრი ,,ვაუ რა მაგარია\" შეგვხვდება, გზაზე, რომელიც უამრავ იდეას მოგაწოდებს და მოგამზადებს იმ უდიდესი რევულუციისათვის, რომელსაც ხელოვნური ინტელექტი ქვია.\n\nგისურვებ ბევრ წარმატებას ამ საინტერესო და ემოციებით სავსე გზაზე.",
      "target_audience": [
        "კურსი შექმნილია ყველა იმ ადამიანისათვის,რომელსაც თანამედროვე ტექნოლოგიებით დიდი ნახტომის გაკეთება სურს ცხოვრებაში"
      ]
    },
    {
      "title": "Microsoft Power BI in Arabic مايكروسوف بور بي أي",
      "url": "https://www.udemy.com/course/microsoft-power-bi-in-arabic/",
      "bio": "Microsoft Power BI in Arabic مايكروسوف بور بي أي",
      "objectives": [
        "Barcahrts إنشاء",
        "Treemaps إنشاء",
        "Donut Chart إنشاء",
        "Piecharts إنشاء"
      ],
      "course_content": {
        "Section 2: Your First Bar Chart": [
          "Installation",
          "Section 1 challenge",
          "OfficeSupplies",
          "2. التحدي الاول",
          "3.توصيل dataset بال power PI - CSV File",
          "4.استكشاف Navigation bar",
          "5. استخدام Drill up & down",
          "6. استخدام Drill up & Down more advanced",
          "7. تلوين ال charts",
          "8. اضافة calculated coloumn",
          "9. formating ال chart و add labels"
        ],
        "Timeseries, Aggregation, and Filters": [
          "Long-Term-Unemployment-Statistics",
          "2. التعامل مع time series",
          "3.فهم مصطلح aggregation and granularity",
          "4.تطبيق Area and stacked chart",
          "Creating an area chart & learning about highlighting",
          "5.استخدام filters and slicer"
        ],
        "Maps, Scatterplots and Interactive BI Reports": [
          "AmazingMartEU2Geo",
          "1. التعامل مع اكتر من table",
          "2.فهم inner.outer.left.right join",
          "3.التعامل مع ال Duplicates in joins",
          "4.استخدام join on multiple fields",
          "5. استخدام map_2",
          "6.الفرق بين calculated column and measure",
          "7.استخدام scatter",
          "8. تطبيق conditional formatting",
          "9.تجميع ال charts و filter و slicer",
          "10.اضافة Dount chart و تعديل الشكل"
        ],
        "Creating an Interactive Business Intelligence Report": [
          "P6-UK-Bank-Customers",
          "1. insert new dataset",
          "2. اول خطوه في ال visualization",
          "3.عرض percentage of gender",
          "4. انشاء bins و age distribution",
          "5. انشاء balance distribution",
          "6. انشاء Treemap",
          "7. انشاء Customer segment dashboard",
          "8. التحكم في الinteractivity لل report",
          "9. تحليل ال BI report"
        ],
        "Leveraging Custom Visuals": [
          "36. The Challenge: Visualizing the European Debt Crisis",
          "2. اضافة custom visualization",
          "3. فهم Chord chart و التطبيق عليه",
          "4. انشاء ال second chord و تلوينه",
          "5.اضافة treemap",
          "6. استكشاف ال visualization و تحليلها"
        ]
      },
      "requirements": [
        "معرفة أساسيات الكمبيوتر"
      ],
      "description": "تعليم ال data visualization عبر Microsoft Power BI و انشاء فرص لك او لصانعي القرارات حتي تستكشف  ال data patterns مثل customer purchase behavior, sales, trends or production bottlenecks\n\n\nسوف تتعلم كل المميزات الخاصه ب power BI التي تسمح لك بالاستكشاف و التجربه و تصليح و تحضير البيانات بسهوله و سرعه و بشكل جميل\n\n\nاستخدام power BI لتحليل و visualize البيانات\n\n\nتوصيل power BI بمختلف ال datasets\n\n\nاستخدام Drill Down و Drill UP في ال Visualization الخاصه بك و حساب البيانات في مختلف الأشكال Various charts, plots and maps\n\n\nتحويل ال Row Data ل Data Visualizations باستخدام ال Powe BI\n\n\nلان كل section غير معتمد على الآخر يمكنك البدأ في اي section تريده\n\n\nكل section يحتوي علي dataset مختلفه و التدريب عليه سيجعلك تنفيذ ما تعلمته للتو\n\n\nالمحتوي يتم تطبيقه على اخر نسخه من ال Power BI حتى تتمكن من رفع مهاراتك و تزويدها",
      "target_audience": [
        "You should take this course if want to learn Power BI completely from scratch",
        "You should take this course if you know some Power BI skills but want to get better",
        "You should take this course if you are good with Microsoft Power BI and want to take your skills to the next level and truly leverage the full potential of Power BI"
      ]
    },
    {
      "title": "Visualización de datos en Python: Mpl, Seaborn, Plotly, Dash",
      "url": "https://www.udemy.com/course/visualizacion-de-datos-en-python/",
      "bio": "Domina la visualización de datos en Python con las librerías matplotlib, seaborn, plotly y dash",
      "objectives": [
        "Explorar conjuntos de datos visualmente en Python.",
        "Crear interfaces web para presentar visualmente resultados.",
        "Dominar las librerías más importantes de visualización de datos en Python (matplotlib, seaborn, plotly y dash).",
        "Sintetizar conjuntos de datos para su presentación a personas de perfil no técnico."
      ],
      "course_content": {
        "Bienvenida": [
          "Bienvenida & introducción",
          "Preparando el entorno",
          "Serie de cursos sobre ciencia de datos y machine learning",
          "Nuestro catálogo completo de cursos",
          "Síguenos en redes sociales"
        ],
        "Matplotlib": [
          "Una breve introducción a matplotlib",
          "Gráfica lineal",
          "Nuestra primera gráfica",
          "Anatomía de una gráfica en matplotlib",
          "Las clases Figure y Axes",
          "Pyplot",
          "Interfaz orientada a objetos",
          "Añadir anotaciones a la gráfica",
          "Dibujar formas en la gráfica",
          "Dibujar líneas en la gráfica",
          "Manipular los ejes de la gráfica"
        ],
        "Exploración de datos con matplotlib: set de datos Iris": [
          "Presentación del set de datos",
          "Carga del set de datos",
          "Gráfica circular",
          "¿Cuántos registros tenemos de cada clase?",
          "Modificando el estilo de la gráfica",
          "Gráfica de puntos",
          "¿Podemos diferenciar las especies por sus pétalos?",
          "Gráficas en 3 dimensiones",
          "¿Ayuda conocer la longitud del sépalo?",
          "Diagrama de caja",
          "¿Cuál es el rango de valores de cada característica?",
          "Diagrama de violín",
          "Distribución de los valores de las características",
          "Diagrama de barras",
          "Múltiples gráficas",
          "¿Tienen las distintas especies características diferentes?",
          "Estilos globales"
        ],
        "Manipulación de imágenes en matplotlib": [
          "Cargar imágenes en matplotlib",
          "Escala de grises vs. RGB",
          "Mapas de colores",
          "Crear estructuras de gráficas complejas",
          "Crear histogramas de color para una imagen",
          "Aumentar la resolución de una imagen",
          "Guardar imágenes o gráficas en un archivo local"
        ],
        "Seaborn": [
          "Introducción a Seaborn",
          "Gráficas a nivel Figure vs gráficas a nivel Axes",
          "DataFrames de Pandas",
          "Modificar el estilo de las gráficas"
        ],
        "Exploración de datos con Seaborn: set de datos del Titanic": [
          "Presentación del set de datos",
          "Cargar el set de datos",
          "Gráficas de densidad",
          "¿Quién estuvo en el Titanic? - Parte 1",
          "¿Quién estuvo en el Titanic? - Parte 2",
          "¿Cuánto pagaron los viajeros?",
          "¿Contribuye haber pagado más a sobrevivir?",
          "¿Dónde se hospedaron?",
          "¿Cuáles son las probabilidades de sobrevivir?"
        ],
        "Exploración de datos en Seaborn: especies de pingüino": [
          "Carga del set de datos",
          "La clase PairGrid",
          "¿Cómo podemos diferenciar las especies de pingüino?",
          "La clase JointGrid y las gráficas marginales",
          "Identificar pingüinos con gráficas conjuntas"
        ],
        "Exploración de datos en Seaborn: número mensual de vuelos": [
          "Carga del set de datos",
          "Formato de datos ancho vs largo",
          "Mostrar la evolución en la cantidad de vuelos"
        ],
        "Plotly": [
          "Introducción a Plotly",
          "Plotly express"
        ],
        "Exploración de datos en Plotly: dirección e intensidad del viento": [
          "Gráfica polar",
          "Presentación y carga del set de datos",
          "¿Hacia dónde sopla el viento? ¿Con qué intensidad?"
        ]
      },
      "requirements": [
        "Conocimientos muy básicos de Python."
      ],
      "description": "Aprende a sintetizar conjuntos de datos complejos fácilmente de forma visual. En este curso desarrollarás esta habilidad básica de la ciencia de datos (visualización de datos), explorando conjuntos de datos reales con las herramientas más populares de Python (matplotlib, seaborn, plotly y dash). Aprenderás extraer la información más relevante de los datos y a presentarla con una gran variedad de gráficas y diagramas a personas de perfil no técnico.\n\n\nAprende a extraer conocimiento visual de datos complejos para la toma de decisiones con Python.\n\n\n- Master the main visualization libraries in Python for Data Science.\n- Discover and extract the most important knowledge from complex data.\n- Learn to build web interfaces with diagrams to present important results to a wider audience.\n\n\nDomina una habilidad básica de la ciencia de datos.\n\n\nEn el curso explorarás 8 conjuntos de datos diferentes. Aprenderás a entender su contenido y a responder preguntas construyendo una gran variedad de gráficas, básicas y avanzadas. Esta es una habilidad básica en la ciencia de datos ya que los profesionales de este área analizan y modelan datos para asistir la toma de decisiones y resolver problemas complejos. La visualización de datos es una parte fundamental de este proceso, guiando el análisis del científico de datos y presentando su resultado de forma que personas con perfiles diversos puedan entenderlos.\nPara la presentación de resultados, crearemos una interfaz web con la librería plotly que mostrará en tiempo real la información más relevante de una página web: visitas, tipos de usuario, duración de las sesiones, compras, etc.\nAl terminar el curso, dominarás todas estas herramientas con fluidez y serás capaz de analizar visualmente tus propios conjuntos de datos y extraer la información más relevante de ellos.",
      "target_audience": [
        "Aspirantes a científicos de datos que quieren dominar esta habilidad fundamental del campo.",
        "Analistas de datos que quieren aprender a descubrir información relevante de los datos.",
        "Profesionales que necesitan comunicar datos complejos de forma visual a terceras personas.",
        "Estudiantes en las áreas de programación, ciencias o negocios que quieren ser capaces de presentar información compleja visualmente."
      ]
    },
    {
      "title": "R Programlama: R Programını R ile Veri Analizi Yaparak Öğren",
      "url": "https://www.udemy.com/course/r-programlama-r-programn-r-ile-veri-analizi-yaparak-ogren/",
      "bio": "Veri bilimi ve machine learning dünyasına R ile giriş yapın. R'ı uygulamalı öğrenin R programlamada profesyonelleşin!",
      "objectives": [
        "R programlama dilini anlayacak",
        "R'ın temel işleyiş ve fonksiyonları hakkında bilgi sahibi olacak",
        "R'daki paketler vasıtasıyla kendi alanınızda daha fazla uzmanlaşma imkanı",
        "R dilini uygulamalı eğitimimiz ile aktif olarak kullanmayı",
        "R Konsol ve R Stüdyo",
        "Nesnelere Değer Atama ve Aritmetik İşlemler",
        "Değişkenler",
        "Vektörler",
        "Listeler",
        "Matrisler",
        "Dizinler",
        "Faktörler",
        "Data Frame",
        "If ve Else Fonksiyonları",
        "Loop Döngüleri",
        "Fonksiyonlar",
        "R Paketleri",
        "Grafikler ve Şemalar",
        "Veri Manipülasyonu",
        "Doğrusal Regresyon",
        "Çoklu Regresyon",
        "Karar Ağaçları",
        "Ki-Kare Testleri ve daha fazlası"
      ],
      "course_content": {
        "R Programlamaya Giriş": [
          "Neden R Programlama Dilini Öğrenelim?",
          "R Programına Giriş ve R'ın Temel Özellikleri",
          "R Programlama Hakkında"
        ],
        "R Konsol ve R Studio": [
          "R ve R Stüdyoyu Yükleme",
          "R Konsol ve R Studio"
        ],
        "Temel Kod Yazim Kurallari ve Uygulamalar": [
          "Nesnelere Değer Atama ve Aritmetiş İşlemler",
          "Değişkenler",
          "Vektörler"
        ],
        "Veri Türleri ve Veri Yönetimi": [
          "Listeler",
          "Matrisler",
          "Dizinler",
          "Faktörler",
          "Veri Çerçeveleri (Data Frames)",
          "Operatörler",
          "If ve Else Fonksiyonları",
          "Loop Döngüleri",
          "Fonksiyonlar",
          "R Paketleri",
          "R'a Veri Aktarımı",
          "Veri Manipülasyonu"
        ],
        "Grafikler ve Şemalar": [
          "Grafikler ve Şemalar"
        ],
        "İstatistiksel Metodlar": [
          "Temel İstatistiksel Fonksiyonlar",
          "Normal Olasılıksal Dağılım",
          "Korelasyon",
          "T - Test",
          "Doğrusal Regresyon",
          "Çoklu Doğrusal Regresyon",
          "Ki-Kare Testleri"
        ],
        "Uygulamalı Öğrenme Egzersizleri": [
          "Karar Ağaçları",
          "Uygulamalı Öğrenme Egzersizleri -1",
          "Uygulamalı Öğrenme Egzersizleri - 2",
          "Uygulamalı Öğrenme Egzersizleri -3"
        ],
        "Extra": [
          "R Programlama: R Programını R ile Veri Analizi Yaparak Öğren"
        ]
      },
      "requirements": [
        "Temel Seviyede Bilgisayar kullanımı",
        "Öğrenme arzusu",
        "Tek ihtiyacınız olan bilgisayarınız ve sizsiniz! Haydi hemen kayıt olun ve öğrenmeye başlayın"
      ],
      "description": "Herkese merhabalar,\nR Programlama: R Programını R ile Veri Analizi Yaparak Öğren kursumuza hoşgeldiniz.\nR Programlama kursu, veri analizi alanında uzmanlaşmak isteyenlerin ilk başlangıç noktası olabilecek nitelikte bir kurs.\nR programını diğer yazılım programlarından farklı kılan en önemli özellik, R programının hem yazılım, hem veri tabanı, hem istatistik, hem de veri madenciliği ve sosyal network analizi alanlarında aynı anda çok güçlü analiz teknikleri ve görselleştirme imkanları sunmasıdır.\nKurs kimlere hitap ediyor?\nİster programlamada ister R'da yeni olun, R programlama kursumuz, çok kısa sürede herkesi R'da etkin hale getirmeyi planlamaktadır.\nEn temel seviyeden başlayarak adım adım ilerlediğimiz kursumuz ile;\nR programlama dilini anlayacak ,\nR'ın temel işleyiş ve fonksiyonları hakkında bilgi sahibi olacak,\nR'daki paketler vasıtasıyla kendi alanınızda daha fazla uzmanlaşma imkanına sahip olacaksınız.\nBu eğitimle yalnızca R programlama dilinin nasıl çalıştığı konusunda ayrıntılı bir fikir sahibi olmakla kalmayacak aynı zamanda R programlama dili ile ilgili en çok karşılaştıgınız temel sorularınızına da cevaplar bulacaksınız.\nEğitimimiz hem R programlama diline yeni giriş yapacaklar hem de aktif meslek hayatında R programını sürdüren ve bilgilerini tazelemek isteyen yani tüm R meraklıları için harika bir kaynak.\nBu eğitime;\nVeri analizine merak duyan öğrenciler,\nNicel çalışmalar yürütmek isteyen akademisyenler,\nİstatistikçiler,\nBüyük veri yani big data ile uğraşan analistler,\nŞirketlerindeki karlılığı arttırmak isteyen özel şirket yöneticileri\nR programlama dilini öğrenmek isteyen yazılımcılar ve R'a ilgi duyan herkes katılabilir.\nEğitimde hangi konuları ele aldık;\nR Konsol ve R Stüdyo,\nNesnelere Değer Atama ve Aritmetik İşlemler,\nDeğişkenler,\nVektörler,\nListeler,\nMatrisler,\nDizinler,\nFaktörler,\nData Frame,\nIf ve Else Fonksiyonları,\nLoop Döngüleri,\nFonksiyonlar,\nR Paketleri\nGrafikler ve Şemalar,\nVeri Manipülasyonu,\nDoğrusal Regresyon,\nÇoklu Regresyon,\nKarar Ağaçları,\nKi-Kare Testleri ve daha fazlası\nKursiyerlerimiz,\nSoru&Cevap bölümünde hızlı cevaplar alabilecek,\nKursu bitiren tüm kursiyerlerimiz kurs bitirme sertifikalarını Udemy'den indirebilecek\nDaha fazla zaman kaybetmeyin ve R Programını R ile Veri Analizi Yaparak Öğren kursumuza siz de kayıt olun!\nKursta görüşmek üzere!",
      "target_audience": [
        "R programlama dilini öğrenmek isteyenler",
        "Veri analizine merak duyan öğrenciler",
        "Veri bilimi alanında bir kariyer hedefleyenler",
        "R programlamayı uygulamalı olarak öğrenmek isteyenler",
        "Nicel çalışmalar yürütmek isteyen akademisyenler",
        "İstatistikçiler",
        "Big Data ile uğraşan analistler",
        "Şirketlerindeki karlılığı arttırmak isteyen özel şirket yöneticileri",
        "R programlama dilini öğrenmek isteyen yazılımcılar ve R'a ilgi duyan herkes"
      ]
    },
    {
      "title": "Sumarização de Textos com Processamento de Linguagem Natural",
      "url": "https://www.udemy.com/course/sumarizacao-de-textos-com-processamento-de-linguagem-natural/",
      "bio": "Entenda a teoria e implemente passo a passo três algoritmos para sumarização de textos com o Python!",
      "objectives": [
        "Entender a teoria e os cálculos matemáticos dos algoritmos de sumarização de textos",
        "Implementar passo a passo com o Python os seguintes algoritmos de sumarização: baseado em frequência, baseado em distância e o clássico algoritmo de Luhn",
        "Utilizar as seguintes bibliotecas para sumarização de textos: sumy, pysummarization e BERT summarizer",
        "Sumarizar artigos extraídos de páginas web e feed de notícias",
        "Gerar resumos de textos no idioma português",
        "Utilizar as bibliotecas NLTK e spaCy e o Google Colab para suas implementações de processamento de linguagem natural",
        "Criar visualizações em HTML para apresentação dos resumos dos textos"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Introdução a processamento de linguagem natural",
          "Mais sobre Inteligência Artificial",
          "Recursos para download"
        ],
        "Algoritmo baseado em frequência": [
          "Introdução",
          "Teoria",
          "Pré-processamento do texto 1",
          "Pré-processamento do texto 2",
          "Frequência das palavras",
          "Frequência proporcional das palavras",
          "Tokenização de sentenças",
          "Geração do resumo",
          "Visualização do resumo com HTML",
          "Extração de texto da internet",
          "Função para sumarizar os textos",
          "Função para visualização do resumo",
          "Sumarização de vários textos",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Conclusão"
        ],
        "Algoritmo de Luhn": [
          "Introdução e teoria básica",
          "Preparação do ambiente",
          "Implementação 1",
          "Implementação 2",
          "Implementação 3",
          "Implementação 4",
          "Implementação 5",
          "Extração de texto da internet",
          "Leitura de feed de notícias",
          "Nuvem de palavras",
          "Extração de entidades nomeadas",
          "Sumarização de artigos de feed de notícias",
          "Arquivo HTML com os resultados",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Conclusão"
        ],
        "Sumarização com similaridade do cosseno": [
          "Introdução",
          "Preparação do ambiente",
          "Similaridade entre sentenças 1",
          "Similaridade entre sentenças 2",
          "Matriz de similaridade",
          "Sumarização dos textos",
          "Extração de texto da internet",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Conclusão"
        ],
        "Bibliotecas para sumarização de textos": [
          "Introdução",
          "Preparação do ambiente",
          "Biblioteca sumy",
          "Biblioteca pysummarization",
          "Biblioteca BERT summarizer",
          "EXERCÍCIO",
          "Solução o exercício",
          "Avaliação de algoritmos de sumarização",
          "Conclusão",
          "Aula adicional: sumarização abstrativa"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Básico da linguagem Python"
      ],
      "description": "A área de Processamento de Linguagem Natural - PLN (Natural Language Processing - NLP) é uma subárea da Inteligência Artificial que tem como objetivo tornar os computadores capazes de entender a linguagem humana, tanto escrita quanto falada. Alguns exemplo de aplicações práticas são: tradutores entre idiomas, tradução de texto para fala ou fala para texto, chatbots, sistemas automáticos de perguntas e respostas, geração automática de descrições para imagens, adição de legendas em vídeos, classificação de sentimentos em frases, dentre várias outras! Outro exemplo importante de aplicação é a sumarização automática de documentos, que consiste em gerar resumos de textos. Vamos supor que você precise ler um artigo com 50 páginas, porém, não possui tempo suficiente para ler o texto integral. Nesse caso, você pode utilizar um algoritmo de sumarização para gerar um resumo deste artigo. O tamanho deste resumo pode ser configurável, ou seja, você pode transformar 50 páginas em um texto com somente 20 páginas que contenha somente os pontos mais importantes do texto!\nBaseado nisso, este curso apresenta a teoria e principalmente a prática de três algoritmos de sumarização de textos: (i) baseado em frequência, (ii) baseado em distância e o (iii) famoso e clássico algoritmo de Luhn, que foi um dos primeiros esforços nessa área. Durante as aulas, implementaremos passo a passo cada um desses algoritmos utilizando tecnologias modernas, como a linguagem de programação Python, as bibliotecas NLTK (Natural Language Toolkit) e spaCy e o Google Colab, o que garantirá que você não terá problemas com instalações ou configurações de softwares na sua máquina local.\nAlém de implementar os algoritmos, você também aprenderá como extrair notícias de blogs e de feed de notícias, bem como gerar visualizações interessantes dos resumos utilizando HTML! Após a implementação manual dos algoritmos, temos um módulo adicional no qual você utilizar bibliotecas específicas para sumarizar documentos, como por exemplo: sumy, pysummarization e BERT summarizer. Ao final do curso, você saberá tudo o que precisa para criar seus próprios algoritmos de sumarização!",
      "target_audience": [
        "Pessoas interessadas em processamento de linguagem natural e sumarização de textos",
        "Pessoas interessadas nas bibliotecas spaCy e NLTK",
        "Alunos de graduação e pós-graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial",
        "Cientistas de Dados que queiram aumentar seus conhecimentos em processamento de linguagem natural",
        "Profissionais interessados em desenvolver soluções profissionais de sumarização de textos"
      ]
    },
    {
      "title": "Deep Learning: Neuronale Netze mit TensorFlow 2.0 und Keras",
      "url": "https://www.udemy.com/course/machine-und-deep-learning-mit-keras-und-python/",
      "bio": "Programmiere mehrere (10+) Neuronale Netze mit Tensorflow 2, Keras und Python! Erforsche Machine Learning in der Praxis!",
      "objectives": [
        "Entwickle ein Neuronales Netz das Preise vorhersagen kann",
        "Entwickle ein Neuronales Netz das Alter und Geschlecht in Echtzeit (in Videos) vorhersagen kann",
        "Entwickle ein Neuronales Netz das Aktienkurse vorhersagen kann",
        "Entwickle ein Neuronales Netz das Hunde und Katzen vorhersagen kann",
        "Entwickle ein Neuronales Netz das Ziffern vorhersagen kann",
        "Entwickle ein Neuronales Netz das die Stimmung in Texte vorhersagen kann",
        "Entwickle ein Neuronales Netz für Object Detection",
        "Entwickle ein Neuronales Netz für Image Segmentation",
        "Praktische Anwendung von Deep Learning Projekte im Berufsleben!",
        "Das Komplexe Thema Deep Learning (Supervised Learning) verstehen",
        "Von A-Z das beliebte Deep Learning Framework Keras mit TensorFlow lernen",
        "Lerne wie du die Genauigkeit von Neuronale Netze erhöhen kannst",
        "Lerne wie du Keras Modelle untersuchen und optimieren kannst",
        "Lerne TensorBoard kennen",
        "Lerne State-of-the-art Netzwerke kennen (R-CNN & Mask R-CNN)"
      ],
      "course_content": {},
      "requirements": [
        "Lust etwas neues zu lernen :)"
      ],
      "description": "Das sagen Teilnehmer über diesen Kurs:\n\"Sehr aktiver Dozent der sich um die Kursteilnehmer und den Kurs kümmert. Der Tensorflow Kurs hat viele beispiele was mir geholfen hat Tensorflow und Keras besser zu verstehen. Ebenfalls sehr gut waren auch die Begriff erklärungen die einem sehr helfen ML als beginner zu lernen.\"  - Ibrahim Akkulak\n\"Ich würde den Kurs auf jeden Fall weiter empfehlen. Mehr Content als gedacht und sehr viele Erklärungen. Top!\"  - Erik Andrè Thürsam\n\"Der Kurs gefällt mir ganz gut und bringt viele Beispiele ein. Der Saif beantwortet Fragen super schnell und ist sehr hilfsbereit. Empfehle den Kurs sehr für alle die Deep Learning mit vielen Praxisbeispielen lernen möchten.\"  - Simon Behrens\n\n\nDeep Learning ist eines der angesagtesten Themen weit und breit. Insbesondere wird Deep Learning und Künstliche Neuronale Netze in vielen Technologien in deinem Umfeld eingesetzt, um dir ein noch angenehmeres Leben zu ermöglichen.\nMithilfe diesen Praxis-Kurs bringe ich dir bei wie man Deep Learning mithilfe von Keras, Tensorflow und Python einsetzt. Du wirst eine gute Mischung von Theorie und Praxis in diesen Kurs erhalten. Viele der Techniken werden anhand von echten Praxis Projekte dir vermittelt.\nWarum solltest du Keras lernen? Keras wird von den \"Big Five\" Unternehmen wie Apple, Google, Facebook, Amazon und Microsoft in vielen ihrer Produkte eingesetzt, um Machine Learning noch effizienter zu nutzen! Ebenfalls werde ich ihn auch immer auf dem neusten Stand der Technik und Wissenschaft halten.\nLerne wie du Keras meisterst und schreibe dich JETZT ein!",
      "target_audience": [
        "Softwareentwickler, Data Scientists und Machine Learning Experten",
        "Alle die Keras und die Welt von Deep Learning erkunden möchten",
        "Studenten der Informatik, Bioinformatik, IT-Sicherheit, Mathematik etc.",
        "Python Entwickler"
      ]
    },
    {
      "title": "【한글자막】 Apache Spark 와 Python으로 빅 데이터 다루기",
      "url": "https://www.udemy.com/course/best-apache-spark-python/",
      "bio": "【전세계 81만 수강생 보유 TOP강사!】 데스크탑 또는 Scala가 포함된 Hadoop에서 대규모 데이터 세트를 분석하는 20개 이상의 실습 예제가 포함된 Apache Spark 튜토리얼!",
      "objectives": [
        "Spark 3에서 DataFrames 및 구조적 스트리밍 사용하기",
        "빅데이터 분석 문제를 Spark 문제로 프레임화",
        "Amazon의 Elastic MapReduce 서비스를 사용하여 Hadoop YARN이 있는 클러스터에서 작업 실행하기",
        "데스크톱 컴퓨터 또는 클러스터에 Apache Spark 설치 및 실행하기",
        "Spark의 Resilient Distributed Datasets를 사용하여 많은 CPU에서 대규모 데이터 세트 처리 및 분석하기",
        "Spark를 사용하여 너비 우선 검색과 같은 반복 알고리즘 구현하기",
        "MLLib 머신 러닝 라이브러리를 사용하여 일반적인 데이터 마이닝 질문에 답하기",
        "Spark SQL을 사용하여 구조화된 데이터로 작업하는 방법 이해하기",
        "Spark Streaming을 통해 실시간으로 연속적인 데이터 스트림을 처리하는 방법 이해하기",
        "클러스터에서 실행되는 대규모 작업 조정 및 문제 해결하기",
        "브로드캐스트 변수와 어큐뮬레이터를 사용하여 Spark 클러스터의 노드 간에 정보 공유하기",
        "GraphX 라이브러리가 네트워크 분석 문제에 어떻게 도움이 되는지 이해하기"
      ],
      "course_content": {},
      "requirements": [
        "이 강의는 개인용 컴퓨터 사용이 가능 해야 하며, Windows를 사용하지만 샘플 코드는 Linux에서도 작동 합니다.",
        "일부 사전 프로그래밍 또는 스크립팅 경험이 필요합니다. (Python 기초 강의 선행을 추천드립니다)",
        "Python 경험은 많은 도움이 되지만 이 강의를 진행 하면서 배워 가도 충분합니다."
      ],
      "description": "Spark와 Python을 함께 배우는 강의!\n20개 이상의 실제 예시 포함!\nSpark의 기초부터 시작하여 다양한 응용까지 All in one!\nAmazon 및 IMDb의 전 엔지니어이자 선임 관리자로부터 배우는 실습 위주 수업!\n*프로그래밍을 처음 접한다면 수업을 진행하기 어려울 수 있습니다. Python 기초 강의를 먼저 수강하시는 것을 추천합니다*\n\n\nApache Spark 와 Python으로 빅 데이터 다루기 강의를 선택해야 하는 이유\n데이터 분석 문제를 Spark로 프레이밍 하는 기술을 배우고, 20개 이상의 실습 예제를 통해서 완벽히 마스터 할 수 있습니다.\n수강 후에는 몇 분만에 클라우드에서 GB 크기의 정보를 분석하는 코드를 실행 할 수 있게 됩니다.\n이 강의는 친숙한 Python 프로그래밍 언어를 사용합니다.\n(만약 Spark에서 최고의 성능을 얻기 위해 Scala를 사용하고 싶다면 다른 강의가 더 적합 할 수 있습니다.)\n이 강의에는 재미있는 실습이 포함 되어 있습니다. Spark를 사용하여 영화 등급 데이터와 책의 텍스트를 분석하는 몇 가지 간단한 예로 시작해서 기본기를 배운 후에는, 더 복잡하고 흥미로운 작업을 진행합니다. 백만개의 영화 등급을 사용하여 서로 유사한 영화를 찾을 것이고, 이 과정에서 여러분들이 좋아할 만한 새로운 영화를 발견할 수도 있을 것입니다! 여러분은 슈퍼히어로의 사회적 그래프를 분석하고 가장 \"인기 있는\" 슈퍼히어로가 누구인지 배우고 슈퍼히어로 사이의 \"Degree of Separation\"를 찾는 시스템을 개발할 것입니다. 모든 마블 슈퍼히어로들은 스파이더맨과 얼마나 연결되어 있을까요?\n이 강의를 통해 그 답을 찾을 수 있습니다.\n또한, 이 강의는 실습 위주의 강의입니다. Amazon의 Elastic MapReduce 서비스를 사용하여 자체 시스템과 클라우드 모두에서 실제 코드를 함께 작성, 분석 및 실행할 때 강사와 함께 대부분의 시간을 보내게 됩니다. 7시간 분량의 영상 내용이 포함되어 있으며, 20개 이상의 실제 예시는 복잡성이 증가함에 따라 스스로 구축하고 실행하고 연구할 수 있습니다.\n\n\n\n\nApache Spark 와 Python으로 빅 데이터 다루기 세부 커리큘럼\nSpark 3에서 DataFrames 및 구조적 스트리밍 사용하기\n빅데이터 분석 문제를 Spark 문제로 프레임화\nAmazon의 Elastic MapReduce 서비스를 사용하여 Hadoop YARN이 있는 클러스터에서 작업 실행하기\n데스크톱 컴퓨터 또는 클러스터에 Apache Spark 설치 및 실행하기\nSpark의 Resilient Distributed Datasets를 사용하여 많은 CPU에서 대규모 데이터 세트 처리 및 분석하기\nSpark를 사용하여 너비 우선 검색과 같은 반복 알고리즘 구현하기\nMLLib 머신 러닝 라이브러리를 사용하여 일반적인 데이터 마이닝 질문에 답하기\nSpark SQL을 사용하여 구조화된 데이터로 작업하는 방법 이해하기\nSpark Streaming을 통해 실시간으로 연속적인 데이터 스트림을 처리하는 방법 이해하기\n클러스터에서 실행되는 대규모 작업 조정 및 문제 해결하기\n브로드캐스트 변수와 어큐뮬레이터를 사용하여 Spark 클러스터의 노드 간에 정보 공유하기\nGraphX 라이브러리가 네트워크 분석 문제에 어떻게 도움이 되는지 이해하기\n\n\nAmazon 및 IMDb의 전 엔지니어이자 선임 관리자 Frank Kane 강사의 한마디!\n완전히 업데이트 된 새로운 강의로 출시되었습니다!\nSpark 3, 더 많은 실습, DataFrames 및 Structured Streaming에 대해 더 중점적으로 업데이트되었습니다.\nSpark SQL, Spark Streaming과 같은 최신 Spark 기술과 Gradient Boosted Trees와 같은 고급 모델도 다룰 것입니다.\n\"빅 데이터\" 분석은 아주 인기있고 매우 가치 있는 기술입니다. 이 강의는 빅 데이터에서 가장 인기 있는 기술을 알려줍니다. 바로 Apache Spark 입니다. 아마존, 이베이, NASA JPL 및 Yahoo를 포함한 고용주는 모두 Spark를 사용하여 내결함성 Hadoop 클러스터 전반에 걸쳐 방대한 데이터 세트에서 의미를 빠르게 추출합니다. 여러분은 앉은 자리에서 Windows 시스템을 사용하여 동일한 기술을 배우게 될 것인데, 이는 생각보다 어렵지 않습니다.\n\n\n여러분의 일정에 따라 여러분의 속도로 진행하세요. 이 강의는 Spark SQL, Spark Streaming, GraphX를 비롯한 다른 Spark 기반 기술에 대한 개요로 마무리됩니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\nApache Spark로 빅 데이터를 처리하는 것은 오늘날의 기술 세계에서 중요한 기술입니다. 지금 등록하고 이 강의를 즐겨보시기를 바랍니다!\n\n\n-Frank\n\n\nP.S. 제 강의에 대한 한 수강생의 리뷰를 소개해 드립니다:\n\" Frank Kane과 함께 \"Apache Spark 및 Python으로 빅 데이터 다루기\"를 공부 했습니다. 제 회사에서 서비스를 위한 빅 데이터 플랫폼을 구축하는데 큰 도움이 되었으며, 이 강의를 추천합니다! \" - Cleuton Sampaio De Melo Jr.",
      "target_audience": [
        "빅 데이터 분석에서 가장 인기 있는 기술을 배우고자 하는 프로그래머",
        "Spark를 사용하여 거대한 데이터 세트를 구축하고 의미를 추출하는 방법을 배우고 싶은 분",
        "소프트웨어 개발 작업에 대량의 데이터 처리가 필요한 분",
        "데이터공학이나 빅 데이터 분야에서 새로운 커리어를 쌓고 싶은 분"
      ]
    },
    {
      "title": "Creación de Reportes Visuales con RMarkdown",
      "url": "https://www.udemy.com/course/creacion-de-reportes-visuales-con-rmarkdown/",
      "bio": "Genera tus informes en diferentes formatos desde RStudio utilizando el paquete RMarkdown",
      "objectives": [
        "A crear informes de forma automatizada utilizando el paquete RMarkdown, ya sea en formato HTML, powerpoint, Word o PDF",
        "Convertirás tus datos en información utilizando lenguaje R",
        "Podrás crear gráficos atractivos utilizando tanto comandos básicos de R como la librería ggplot2",
        "A insertar imágenes, hipervínculos y te mostraré técnicas básicas para dar formato a los textos que desees incluir en tu informe",
        "Aprenderás también a utilizar parámetros dentro de RMarkdown que te permitan seleccionar la información a desplegar en tus reportes visuales",
        "Conocerás algunas técnicas de limpieza y pre-procesamiento datos, mismas que podrás aplicar antes de generar tus reportes",
        "Podrás detectar las palabras que aparecen más frecuentemente en un texto, mediante la aplicación de la técnica de las nubes de palabras",
        "Aprenderás acerca del diagrama de Pareto, una de las herramientas más utilizadas en el área de Control de Calidad",
        "Obtén los scripts creados con RMarkdown junto con los archivos a analizar al momento de crear los reportes de manera automática"
      ],
      "course_content": {
        "Introducción al Curso Creacion de Reportes Visuales con RMarkdown": [
          "Bienvenido(a) al Curso de Creación de Reportes Visuales con RMarkdown",
          "Que es y para qué sirve R Markdown?",
          "Descarga la versión 3.6.3 de R",
          "Instalación de R y RStudio",
          "Paneles de RStudio",
          "Instalando paquetes en RStudio",
          "Instalando Versiones Anteriores de Paquetes en RStudio",
          "Versiones de paquetes utilizados en este curso"
        ],
        "Incluyendo texto, imágenes e hipervínculos al Reporte": [
          "Indice de Comandos de RMarkdown",
          "Scripts incluidos en este curso",
          "Dando formato a los textos",
          "Incluyendo caracteres especiales",
          "Tablas en R Markdown",
          "Chunks",
          "Insertando hipervínculos",
          "Insertando imágenes",
          "Creando un Documento Académico Sencillo y comandos adicionales",
          "Mostrando el Documento Académico en Dos Columnas",
          "Cambiando el Tipo y Tamaño de Letra en un documento PDF"
        ],
        "Preprocesamiento básico de datos": [
          "Lectura y creación de archivos csv en R",
          "Vectores en Lenguaje R",
          "Matrices en Lenguaje R",
          "Valores perdidos y filas duplicadas",
          "Algunas técnicas de reemplazo de valores perdidos",
          "Detección de outliers",
          "Re-escalando los valores",
          "Manejo de filas y columnas en dataframes",
          "Categorización de información numérica",
          "Creación de tablas de frecuencias",
          "Filtros en lenguaje R",
          "Creación de Tablas Interactivas en R"
        ],
        "Principales gráficos utilizados en el análisis de datos": [
          "Histogramas",
          "Diagramas de dispersión",
          "Matrices de correlación",
          "Gráficos de burbujas",
          "Diagramas de caja y bigotes",
          "Gráficos de barras",
          "Gráficos de barras apiladas",
          "Gráficos circulares",
          "Mapas de rectángulos",
          "Diagrama de Pareto",
          "Series de tiempo",
          "Nubes de palabras",
          "Visualizando Información de Tablas Cruzadas",
          "Clustering Jerárquico Teoría",
          "Clustering Jeráquico en R",
          "Guardando los resultados del agrupamiento jerárquico",
          "Acomodo de gráficos",
          "Generación de reportes utilizando parámetros"
        ],
        "Tipos de salida para el reporte visual": [
          "Creación de reportes en HTML",
          "Compartiendo archivos de tipo HTML",
          "Creación de reportes con formato Word",
          "Creación de reportes con formato PDF",
          "Agregando más elementos a la Presentación de PowerPoint",
          "Creando una Plantilla de PowerPoint para utilizarla con RMarkdown",
          "Automatizando la Creación de los Reportes Visuales en Windows",
          "Creación de reportes en forma de presentación de Powerpoint"
        ]
      },
      "requirements": [
        "Tener Instalado Windows en tu computadora",
        "En cuanto al conocimiento, no existe ningún requisito, ya que te explicaré muy detalladamente tanto los comandos del lenguaje R, como las técnicas de preprocesamiento de datos y la teoría detrás de los gráficos que vamos a crear",
        "El software de programación que se utiliza en este curso es totalmente gratuito",
        "Se requiere tener instalado Word y PowerPoint"
      ],
      "description": "Bienvenido al Curso Creación de Reportes Visuales con Rmarkdown\nTe gustaría poder generar tus informes semanales, quincenales o mensuales, sin necesidad de estar abriendo cada uno de los archivos y generando gráficas y más gráficas, una y otra vez, invirtiendo una buena cantidad de tiempo, el cuál podrías estar aprovechando en otras actividades más productivas?\nNo te agradaría tener la facilidad de generar tu informe en diferentes formatos, tales como HTML para mostrarlo en un sitio web, en PowerPoint para utilizarlo en alguna presentación, o bien en PDF o Word para enviarlo por correo, con solo seleccionar el tipo de salida en RStudio?\nSi has respondido afirmativamente a estas preguntas, este curso es para ti!\nEn este curso, no solo veremos como dar formato a tus informes, sino que además te explicaré algunas técnicas de preprocesamiento de datos en R para que lleves a cabo la limpieza de los mismos antes de generar los informes, ya que este paso es el más importante de todo el análisis.\nTe explicaré como crear algunas de las gráficas más utilizadas, tanto con comandos básicos de R, como con una librería llamada ggplot2, con la que se obtienen gráficos más profesionales, así como la manera de insertar imágenes e hipervínculos\nAdicional a esto, te mostraré como puedes generar informes que contengan única y exclusivamente la información de tu interés con solo indicarle el valor de la variable que quieres que se despliegue\nObtén los scripts creados con RMarkdown junto con los archivos a analizar al momento de crear los reportes de manera automática",
      "target_audience": [
        "Personas con o sin experiencia en lenguaje R",
        "Interesados en el análisis de datos, incluyendo el preprocesamiento de los mismos",
        "Que quieran causar un impacto positivo en su empresa o negocio, mediante la creación de informes que puedan ser generados periódicamente dentro de RStudio"
      ]
    },
    {
      "title": "Workshop Teknik Visualisasi Data dengan Power BI",
      "url": "https://www.udemy.com/course/workshop-teknik-visualisasi-data-dengan-power-bi/",
      "bio": "Visualisasi Data dengan Power BI, Power Query, DAX, untuk Keputusan Bisnis, Sosial, dan Ekonomi",
      "objectives": [
        "Mengenal Power BI dan Power Query",
        "Melakukan Import dan Transformasi Data",
        "Langkah-Langkah Dasar Visualisasi Data",
        "Formatting Data dan Membuat Report",
        "Filter, Slicer, Focus Mode, dan Conditional Formatting",
        "Mengenal Power Query dan Perintah-Perintah Transformasi Data",
        "Group, Merge, Format, dan Ekstraksi Data",
        "Model, Relasi Antar Tabel, Calculated Column, dan Fitur Power Query Lain",
        "Penggunaan Measure Tool",
        "Related, Smart Narratives, Calculate, dan Fungsi Aggregate",
        "Report dan Presentasi"
      ],
      "course_content": {
        "Pengantar": [
          "Pengantar",
          "Bagaimana mendapatkan e-Certificate?",
          "Memulai Power BI"
        ],
        "Langkah Awal Membuat Report": [
          "Mengimpor Data",
          "Menyimpan Report",
          "Langkah Dasar Visualisasi Data",
          "Teknik Dasar Formatting Data",
          "Membuat Report",
          "Refresh Data",
          "Kuis Pertanyaan Dasar tentang Power BI"
        ],
        "Filter dan Formatting": [
          "Filter Menggunakan Slicer",
          "Focus Mode dan Conditional Formatting",
          "Tugas Membuat Report"
        ],
        "Bekerja dengan Data": [
          "File Data Sales",
          "Mengenal Power Query",
          "Tipe Data Numerik pada Power BI",
          "Group dan Menggabung Tabel",
          "Format pada Column",
          "Ekstraksi Data",
          "Conditional Column",
          "Model dan Relasi Antar Tabel",
          "Calculated Column",
          "Fitur-Fitur Power Query Lainnya yang Penting",
          "Measure",
          "Column dan Measure Tools",
          "Kuis Seputar Data"
        ],
        "Report Lebih Lanjut": [
          "Menggunakan Related",
          "Tabel Produk",
          "Dates dan Drilldown",
          "Smart Narratives",
          "Fungsi Calculate",
          "Fungsi-Fungsi Aggregate",
          "Publish dari MS Excel ke dalam Power BI"
        ],
        "Report dan Presentasi": [
          "Canvas dan Wallpaper",
          "Image di dalam Report",
          "New Page",
          "Page Navigation",
          "Format Button",
          "Format Card",
          "Kuis Akhir Seputar Power BI"
        ]
      },
      "requirements": [
        "Memiliki Power BI yang dapat diunduh secara gratis"
      ],
      "description": "Anda bisa mengubah deretan data menjadi visual dengan langkah-langkah yang mudah melalui video course ini.\n\n\nBagaimana caranya membuat dashboard visual untuk presentasi data yang mudah? Mulailah dari video course ini. Video ini adalah online course yang paling lengkap, to-the point, dan mudah dipahami untuk mempelajari cara membuat visualisasi data menggunakan Power BI di Udemy. Tidak hanya itu, semua penjelasan di dalam video course ini disampaikan dalam Bahasa Indonesia dengan pendekatan jargon-jargon awam yang dapat dipahami oleh semua orang. Tidak memandang apakah Anda ingin mengambil profesi sebagai analis atau pemiliki perusahaan besar atau ingin mempelajari strategi mengolah data secara visual, video course ini dirancang tentu saja untuk Anda. Dalam kursus ini, kami akan mengajari Anda mengubah deretan data dan tabel menjadi tampilan visual secara efektif dan singkat, tepat, serta jelas.\nDilengkapi dengan berjam-jam video course, kursus komprehensif ini mengupas cara mengoperasikan Power BI, Power Query, dan DAX.\nVideo course  ini akan mengajarkan Anda memahami cara mentransformasi data sehingga bisa dilihat secara visual dengan setiap bab dilengkapi screencast yang mengajarkan kiat-kiat, contoh kasus, serta slide dan ilustrasi, serta penjelasan-penjelasan yang menarik. Karena mengupas teknik visualisasi data untuk semua orang,  maka video course ini tidak sulit dipahami oleh siapapun.\nPertama-tama, kami akan memperkenalkan kepada Anda apa itu Power BI, kemudian, Anda akan mendapatkan materi-materi tentang:\nMengenal Power BI dan Power Query\nMelakukan Import dan Transformasi Data\nLangkah-Langkah Dasar Visualisasi Data\nFormatting Data dan Membuat Report\nFilter, Slicer, Focus Mode, dan Conditional Formatting\nMengenal Power Query dan Perintah-Perintah Transformasi Data\nGroup, Merge, Format, dan Ekstraksi Data\nModel, Relasi Antar Tabel, Calculated Column, dan Fitur Power Query Lain\nPenggunaan Measure Tool\nRelated, Smart Narratives, Calculate, dan Fungsi Aggregate\nReport dan Presentasi\nJangan khawatir tentang kualitas video course ini sebab Udemy menawarkan garansi 30 hari uang kembali tanpa syarat. Jika Anda tidak puas, silakan ajukan refund tanpa syarat.",
      "target_audience": [
        "Peneliti dan Analis Data",
        "Pemilik perusahaan dan marketing yang membutuhkan data secara visual",
        "Sales dan Marketing"
      ]
    },
    {
      "title": "画像生成ＡＩの理論と実践：Stable Diffusion の中では何が起こっているのか、イラストで解説",
      "url": "https://www.udemy.com/course/stable-diffusion-and-rogic/",
      "bio": "画像生成ＡＩの中では一体、何が起こっているのでしょうか？DiffusionモデルからTransformerまで、画像生成をしながら、その理論をイラストで学びます。ツール・GPU・高級PCは不要です。",
      "objectives": [
        "Stable Diffusionの理論をイラストで学びます。論文の内容を分かりやすく解説します。",
        "画像生成技術の応用も学びます。Image to Image や、Inpainting は必見です。",
        "Stable Diffusionの構成要素であるVAEや潜在空間、U-Net、CLIPについて学びます。",
        "Attention is All You Need の論文にあるTransformerについて、イラストで解説します。",
        "Python言語に触れることができます。"
      ],
      "course_content": {
        "コースの紹介と受講のための手続き": [
          "このコースについて",
          "受講対象者",
          "必要なもの",
          "Google Colabの利用",
          "質問してみましょう",
          "このコースの進め方"
        ],
        "Stable Deffusionはじめの一歩": [
          "概要",
          "Stable Deffusionとは Part1",
          "Stable Deffusionとは Part2",
          "Google Colabへの臨時対応について",
          "はじめの一歩",
          "教材について",
          "いろいろなモデル",
          "肖像画の生成",
          "肖像画の生成_教材の実行",
          "課題：肖像画の生成",
          "商用利用と著作権"
        ],
        "プロンプトの入力": [
          "プロンプト概要",
          "教材修正のお願い",
          "単語と文章で入力",
          "ネガティヴ・プロンプト",
          "課題：ネガティヴ・プロンプトを使用した画像の生成",
          "優先順位",
          "画質向上キーワード",
          "構図、画角、視線",
          "強調記号",
          "クロップと比率",
          "おもしろプロンプト集",
          "課題：プロンプト集を利用した画像の生成"
        ],
        "オプションの指定": [
          "オプションの指定概要",
          "シード値の固定",
          "画像サイズの指定",
          "影響度",
          "論文から読み解くguidance scale",
          "推論回数",
          "出力画像数",
          "課題：オプションを指定した画像の生成"
        ],
        "応用編": [
          "応用編　概要",
          "Image To Image",
          "image2image 教材の実行 Part1",
          "image2image Part2 画像URLの取り方",
          "image2image Part3 アルファー・チャンネルの削除",
          "image2image Part4",
          "image2image Part5",
          "image2image Part6",
          "image2image: 追加レクチャーについて",
          "image2image: 顔写真の目を閉じさせる",
          "image2image: 顔写真を西洋絵画の肖像画へ",
          "参考動画：StyleGANでリアルタイムシミュレーション（ベクトルを直接操作してみる）",
          "課題：Image To Image",
          "Inpainting Part1",
          "Inpainting Part2",
          "Inpainting 教材の実行",
          "課題：Inpainting を使った画像の生成",
          "NSFW と Safety Checker",
          "課題：手書きスケッチからアニメ調画像の生成"
        ],
        "Hello Pyton": [
          "Hello Python 概要",
          "Hello Python 教材",
          "Hello World",
          "変数（そして配列と辞書）",
          "制御（条件分岐と繰り返し）",
          "関数（Xが決まればYが決まるもの）",
          "課題提出：関数",
          "Class Part1",
          "Class Part2",
          "課題提出：デコーダークラスの作成",
          "Numpyの利用 Part1（行列の計算）",
          "Numpyの利用 Part2（正規分布の生成）"
        ],
        "第２部　理論編": [
          "第２部 理論編 概要",
          "StableDiffusion",
          "StableDiffusionの三大構造",
          "モデル",
          "記号に慣れよう Part1",
          "記号に慣れよう Part2",
          "数式の追加について"
        ],
        "拡散確率モデル 概要": [
          "拡散確率モデル 概要",
          "拡散モデルへようこそ！",
          "拡散プロセス Part1",
          "拡散プロセス Part2",
          "拡散プロセスの実行 Part1",
          "拡散プロセスの実行 Part2",
          "拡散プロセスの実行 Part3",
          "拡散プロセスの実行 Part4",
          "補講：数学的背景",
          "逆拡散プロセス",
          "逆拡散プロセスの実行 Part1",
          "逆拡散プロセスの実行 Part2",
          "補講：数学的背景",
          "分散スケジュール Part1",
          "分散スケジュール Part2",
          "補講：数学的背景",
          "補講：分散スケジュールの処理内容について",
          "拡散モデルの学習",
          "学習の実行 Part1",
          "学習の実行 Part2",
          "課題：学習の実行結果",
          "補講：数学的背景 1",
          "補講：数学的背景 ２",
          "ガウス分布",
          "ガウス分布の実践 Part1",
          "ガウス分布の実践 Part2",
          "ポアンカレのパン (Poincare's Bread)",
          "マルコフ連鎖",
          "変分推論"
        ],
        "VAE(Variational Auto Encoder)：変分オートエンコーダー": [
          "VAE概要",
          "オートエンコーダー",
          "オートエンコーダーの構造",
          "我ウニのトゲ先に在り",
          "変分オートエンコーダー",
          "我ナマコの表面に在り。",
          "リパラメタライゼーション・トリック",
          "VAEの概念図",
          "VAEとDiffusionモデル",
          "学習中の潜在変数の分布",
          "コーヒーブレーク_結局潜在変数zとは？",
          "鏡の国から潜在空間を考える",
          "潜在空間を覗いてみよう_Part1",
          "潜在空間を覗いてみよう_Part2",
          "課題：潜在空間の可視化"
        ],
        "U-Net": [
          "UNet 概要",
          "UNetとは",
          "UNetの構造",
          "畳み込み",
          "畳み込みを体験してみよう",
          "AutoEncoderとしてのU-Net",
          "UNet教材"
        ]
      },
      "requirements": [
        "インターネットとマウスが使えること",
        "ニューラルネットワークについての解説がありますので、さわって覚える人工知能「ディープラーニング編」を受講されていますと、わかりやすいです。"
      ],
      "description": "画像生成ＡＩの中でも、一般の人たちが自由に使えるがStable Diffusion について、どのような仕組みになっているのか、イラストで解説していきます。主に、機械学習入門者を対象としていますが、すぐに動かせる教材を用意しておりますので、興味のある方なら、どなたでも受講可能です。コース前半（第１部）は、まだStable Diffusionを触ったことのない方のためによういしました。既に、Stable Diffusionを動かしたことのある方は、コース後半（第２部）から受講してもいいでしょう。ただし、第１部の「肖像画の生成」と「Inpainting」は必見です。\nStable Diffusionを動かすためには、特殊なツールをパソコンにインストールしたり、GPUというハードウェア・アクセラレータが必要ですが、この講座では、Google Colaboratory という、Google社の提供する、無料の環境で動かしますので、事務用のノートパソコンでも動かせます。\n最後に、Attention と、それによって構成されるTransformer についても学びます。ChatGPTもこのアーキテクチャーを使っています。一度挫折した人も、ここでやり直しましょう。",
      "target_audience": [
        "ＡＩで生成される写真画像やイラストに興味のある方。",
        "画像生成ＡＩの理論に興味のある方"
      ]
    },
    {
      "title": "Python RPA crie Robôs com Interface GUI + Projeto ChatGPT",
      "url": "https://www.udemy.com/course/python-rpa-crie-robos-com-interface-grafica/",
      "bio": "Aprenda criar robôs de automação de processos com interface gráfica + Projeto ChatGPT com a API da OpenAI e Tkinter",
      "objectives": [
        "Aprenda criar interfaces gráficas de usuário (GUIs) para seus projetos de Python, tornando-os mais fáceis de usar e interativos.",
        "Aprenda criar telas de widgets e recursos, como botões, caixas de seleção, menus e muito mais, que podem ser usados para criar projetos completos",
        "Aprenda criar um clone do ChatGPT, vamos criar o código no PyCharm e converter o código em um arquivo executável para ser usado em forma de programa do Windows",
        "Aprenda criar robôs com Tkinter e expanda suas habilidades de programação e torna-se mais atraente para empregadores.",
        "Aprenda como criar arquivos executáveis",
        "Sinta-se confiante e seguro usando o Python"
      ],
      "course_content": {
        "Interface Gráfica - Primeiros Passos": [
          "Instalando o PyCharm",
          "Importante",
          "Primeira Tela - Olá, mundo!",
          "Dicas",
          "Rótulos",
          "Button",
          "Imagens em Boão e Plano de Fundo",
          "Entry",
          "Exercício Calculadora",
          "Checkbutton Aula 1",
          "Checkbutton Aula 2",
          "Radiobutton",
          "Messagebox",
          "Combobox",
          "Listbox",
          "Treeview - Criando e Adicionando Itens",
          "Treeview, Excluir. Alterar e Exportar"
        ],
        "Projeto - Criar Email Aniversariantes com Python e Outlook": [
          "O que vamos aprender",
          "Dica",
          "Instalando Pandas, Nunpy e datetime, tratando dados",
          "Criando Interface Gráfica, populando Treeview com aniversariantes e botão deleta",
          "Cadastrando e Alterando Novos Aniversariantes",
          "Criando Emails em Massa com Python e Outlook",
          "Criando arquivo executável"
        ],
        "Projeto - Gerar Certificados com Python e Word e Interface Gráfica": [
          "O que vamos aprender",
          "Dica",
          "Criando Treeview e Populando com os Dados do Excel",
          "Criando Botões tela e passando os dados da Treeview para Entry",
          "Gerando Certificado",
          "Gerando Certificado em Massa",
          "Criando um Arquivo Executável"
        ],
        "Projeto - Extraindo Cotações": [
          "O que vamos aprender",
          "Dica",
          "Baixando e Instalando o Chrome Driver",
          "Criando Tela Interface Grafica e Extraindo o Dolar do Google",
          "Pesquisando pelo Valor do Euro",
          "Criando Opção de Pesquisar por Qualquer Moeda",
          "Extraindo Cotações - Ocultando o Chorme Dirver",
          "Criando um Arquivo Executável"
        ],
        "Projeto - Extraindo Dados de Tabelas da WEB": [
          "O que vamos aprender",
          "Dica",
          "Abrindo Site rpachallengeocr e imprimindo Dados da Tabela",
          "Extraindo Dados de Todas as Páginas",
          "Criando Interface Gráfica e Populando Informações na Treeview da Web",
          "Extraindo Dados de Tabela da Web e Ocultando o Google Chrome",
          "Gerando o Arquivo Executável"
        ],
        "Projeto - Preencher Formulários da Web": [
          "O que vamos aprender",
          "Preenchendo Formulario do Servey Monkey",
          "Criando Interface Grafica e Populando com Dados do Excel",
          "Preenchendo Formularios da Web em Massa com Interface Grafica",
          "Incluir, Alterar e Excluir Registro",
          "Projeto Preencher Formulário"
        ],
        "Projeto Executavel ChatGPT": [
          "O que vamos aprender",
          "Primeiros Passos",
          "Criando o ChatGPT aula 1",
          "Criando o ChatGPT aula 2",
          "Criando o arquivo executável"
        ],
        "Mensagem Final do Curso": [
          "Mensagem Final do Curso"
        ]
      },
      "requirements": [
        "Conhecimento básico do Python (variáveis, tipos básicos de dados, funções, condicionais e loops)",
        "Vontade de aprender"
      ],
      "description": "Tá cheio de ideias de programas RPA para desktop e não sabe como começar? Quer iniciar sua carreira como desenvolvedor de Robôs com Interface Gráfica? Este curso de Python RPA - Crie Robôs com Interface Gráfica vai te ensinar na prática como criar e programar seus programas, usando a linguagem Python.\n\n\nO curso é ideal para qualquer pessoa que deseja desenvolver suas habilidades em programação e criar interfaces gráficas de usuário (GUIs) incríveis e interativas. Com nosso curso online, você terá acesso a aulas práticas e instruções fáceis de seguir e poderá aplicar o que você aprendeu.\n\n\nVocê começará com os conceitos básicos, como criar janelas e widgets, e avançará para tópicos mais avançados. Este curso é projetado para ajudá-lo a desenvolver suas habilidades e se tornar um programador Tkinter proficiente. Inscreva-se agora e dê o próximo passo na sua jornada de programação com Tkinter!\n\n\nPara quem é este curso?\nEste curso é literalmente para qualquer pessoa, de cientistas de dados a estudantes, médicos, músicos e novos programadores em potencial.\n\n\nPreciso de conhecimento prévio de Python?\nSim. Você precisa conhecer o básico do Python, que são variáveis, tipos de dados, funções, condicionais e loops. Este curso não cobre isso porque você pode encontrar esse conteúdo facilmente no YouTube.\n\n\nEste curso cobre Python 2 ou Python 3?\nPython 3.\n\n\nQual IDE/editor é usado no curso?\nUsamos o PyCharm Community que está se tornando um padrão hoje em dia devido aos recursos de compartilhamento e colaboração que o IDE oferece, que são especialmente úteis quando você ainda está aprendendo. No entanto, você é livre para usar seu IDE favorito.\n\n\nComo serão criados os robôs e como poderei usa-los?\nCriaremos todos os robôs no PyCharm Community e depois vamos transformar os códigos em um arquivo executável para você pode usar todos os robôs em forma de um programa, como se fosse um programa do Windows.\n\n\nO curso expira?\nNão. Depois de comprar o curso, ele é seu. Você receberá todas as atualizações futuras gratuitamente também.\n\n\nSatisfação garantida ou seu dinheiro de volta\n\"E se eu não gostar do curso?” A Udemy oferece uma garantia de reembolso, essa é mais uma garantia de qualidade e um incentivo a mais para você começar já! Após a compra você terá 30 dias para testar o produto, e se não gostar, basta solicitar o reembolso.\nJunte-se a mais de 7 mil alunos que já fizeram e aprovaram meus outros cursos! Comece agora mesmo esse curso!",
      "target_audience": [
        "A qualquer pessoa que queira aprender Python do Básico ao Avançado em Pouco Tempo"
      ]
    },
    {
      "title": "دبلومة بايثون للتعلم العميق | Python Deep Learning Diploma",
      "url": "https://www.udemy.com/course/python-deep-learning-diploma/",
      "bio": "الخطوة الثالثة في رحلتك لاحتراف \"علم البيانات\"، أفضل بداية لأي حد عاوز يتعلم \"الشبكات العصبية والتعلم العميق\" في بايثون",
      "objectives": [
        "مبادئ التعلم العميق | Deep Learning Foundations",
        "الشبكات العصبية الاصطناعية | Artificial Neural Networks (ANN) Basics",
        "الشبكات العصبية الإلتفافية | Convolutional Neural Network (CNN) Basics",
        "الشبكات العصبية المتكررة | Recurrent Neural Network (RNN) Basics",
        "مواضيع متقدمة في التعلم العميق | Advanced Topics (Auto Encoders, Transfer Learning, & Reinforcement Learning)",
        "مشاريع وتطبيقات عملية على التعلم العميق في بايثون | Python Deep Learning Projects"
      ],
      "course_content": {
        "مقدمة عامة عن الدورة التدريبية | Course Introduction": [
          "مقدمة عامة عن الدورة التدريبية Course Introduction",
          "التعريف بالدورة التدريبية Course Description",
          "أهداف الدورة التدريبية Course Objectives",
          "الفئة المستهدفة من التدريب ومتطلبات التدريب Course Audience & Prerequisites",
          "مواضيع ومحاور الدورة التدريبية Course Main Topics",
          "الأدوات والتقنيات المستخدمة Course Toolkit",
          "التعريف بدبلومة بايثون للتعلم العميق Python Deep Learning Diploma Overview"
        ],
        "----- COURSE(01) | DEEP LEARNING FOUNDATIONS -----": [
          "مقدمة عامة عن التعلم العميق Deep Learning Introduction",
          "تعريف التعلم العميق What is Deep Learning",
          "أهمية التعلم العميق Why Deep Learning",
          "تطبيقات التعلم العميق Deep Learning Applications",
          "تطبيق عملي: تصنيف الصور باستخدام التعلم العميق Deep Learning Case-study",
          "مقدمة عن الشبكات العصبية الاصطناعية Artificial Neural Networks (ANNs) Overview",
          "إزاي الكمبيوتر بيتعلم How do Machines Learn?",
          "إزاي البني آدم بيتعلم How do Humans Learn?",
          "أساسيات الشبكات العصبية الاصطناعية Artificial Neural Networks (ANNs) Basics",
          "بناء الشبكات العصبية الاصطناعية Artificial Neural Networks (ANNs) Building",
          "تدريب الشبكات العصبية الاصطناعية Artificial Neural Networks (ANNs) Training",
          "أنواع الشبكات العصبية الاصطناعية Artificial Neural Networks (ANNs) Architectures",
          "تطبيق عملي: أول مشروع لك في التعلم العميق Your Very First Deep Learning Project",
          "إزاي تتابع كل جديد في الذكاء الاصطناعي والتعلم العميق PaperwithCode"
        ],
        "----- COURSE(02) | ARTIFICIAL INTELLIGENCE APPLICATIONS (CASE-STUDIES) -----": [
          "مقدمة عن الدورة التدريبية Course Introduction",
          "نظرة سريعة لتطبيقات الذكاء الاصطناعي AI Apps Overview",
          "مبادئ معالجة اللغات الطبيعية Natural Language Processing (NLP) Basics",
          "تطبيق عملي: معالجة اللغات الطبيعية - التعلم العميق NLP using Deep Learning",
          "مبادئ تنبؤ السلاسل الزمنية Time-series Forecasting (TSF) Basics",
          "تطبيق عملي: تنبؤ السلاسل الزمنية - التعلم العميق TSF using Deep Learning",
          "مبادئ الرؤية بالحاسب Computer Vision (CV) Basics",
          "تطبيق عملي: الرؤية بالحاسب - التعلم العميق Computer Vision using Deep Learning",
          "مبادئ أنظمة التوصية Recommendation Systems (RS) Basics"
        ],
        "----- COURSE(03) | ARTIFICIAL NEURAL NETWORK (ANN) BASICS -----": [
          "مقدمة عن الدورة التدريبية Course Introduction",
          "مراجعة سريعة على مبادئ الشبكات الاصطناعية العصبية ANNs Review",
          "الأوزان والإنحياز في الشبكات العصبية الاصطناعية Weights & Biases in ANNs",
          "دالة التفعيل في الشبكات العصبية الاصطناعية Activation Functions in ANNs",
          "تطبيق عملي: دوال التفعيل Activation Functions in ANNs Case-study",
          "مراجعة سريعة على مبادئ الشبكات الاصطناعية العصبية ANNs Review",
          "مقدمة عن تدريب وتهيئة الشبكات العصبية Intro to ANNs Training & Optimizing",
          "مقدمة عامة عن تدريب وتعلم الشبكات العصبية ANNs Training",
          "مراجعة سريعة على مفاهيم الرياضيات Derivatives, Partial Derivatives, & Chain Rule",
          "مقدمة سريعة عن دوال الخطأ Loss Functions Overview",
          "مقدمة سريعة عن الانحدار التدريجي Gradient Descent Overview",
          "مقدمة سريعة عن الانتقال العكسي Backpropagation Overview",
          "دوال الخطأ في الشبكات العصبية الاصطناعية Loss Functions in ANNs",
          "الانحدار التدريجي في الشبكات العصبية الاصطناعية Gradient Descent (GD) in ANNs",
          "الاستمثال في الشبكات العصبية الاصطناعية Optimizers in ANNs",
          "تطبيق عملي: دوال الخطأ والاستمثال Losses & Optimizers in ANNs Case-study",
          "تقنيات التنظيم في الشبكات العصبية الاصطناعية Regularization Techniques in ANNs",
          "خاتمة الشبكات العصبية الاصطناعية ANNs Conclusion"
        ],
        "----- COURSE(04) | CONVOLUTIONAL NEURAL NETWORK (CNN) BASICS -----": [
          "مقدمة عامة عن الشبكات العصبية الالتفافية Convolution Neural Network (CNN) Basics",
          "تطبيق عملي: الشبكات العصبية الالتفافية CNNs Case-study - MNIST Dataset",
          "مثال توضيحي للشبكات العصبية الإلتفافية CNN Explainer (Demo)",
          "معمارية الشبكات العصبية الالتفافية CNNs Architecture - The Convolutional Layer",
          "معمارية الشبكات العصبية الالتفافية CNNs Architecture - The Pooling Layer",
          "تطبيق عملي: الرؤية بالحاسب باستخدام الشبكات العصبية الالتفافية Computer Vision"
        ],
        "----- COURSE(05) | RECURRENT NEURAL NETWORK (RNN) BASICS -----": [
          "مقدمة عامة عن الشبكات العصبية التكرارية Recurrent Neural Network (RNN) Basics",
          "معماريات الشبكات العصبية التكرارية RNNs Architectures (LSTM / GRU)",
          "تطبيق عملي: تنبؤ السلاسل الزمنية باستخدام الشبكات العصبية التكرارية Time-series"
        ],
        "----- COURSE(06) | ADVANCED TOPICS IN DEEP LEARNING -----": [
          "مقدمة مواضيع متقدمة في التعلم العميق Intro to Advanced Topics in Deep Learning",
          "نموذج الشبكات التوليدية العدائية Generative Adversarial Networks (GANs) Model",
          "نموذج شبكات التشفير التلقائي Autoencoders Networks (AEs) Model",
          "أساسيات المحولات ومراجعة معالجة اللغات الطبيعية Transformers Basics & NLP Recap",
          "نظرة سريعة على معمارية المحولات Transformers Architecture Overview",
          "تطبيق عملي: استخدام النماذج الجاهزة مع المحولات Transformers using HuggingFace",
          "مواضيع متنوعة Misc. Topics: Diffusion Models, Transfer Learning, & Generative AI"
        ],
        "----- COURSE(00) | SUPPLEMENTARY COURSES (OPTIONAL) -----": [
          "الدورات التكميلية Supplementary Courses (إختياري)"
        ],
        "مكتبات تحليل البيانات في بايثون | Python Data Analysis Crash Course (اختياري)": [
          "تحليل البيانات في بايثون في 5 دقايق Python Data Analysis in a Nutshell",
          "المكتبات الأساسية لتحليل البيانات في بايثون Python Libraries for Data Analysis",
          "إنشاء المصفوفة NumPy Arrays Creation",
          "معلومات المصفوفة Inspecting NumPy Array",
          "التعديل في المصفوفة NumPy Array Manipulation",
          "الوصول للبيانات NumPy Subsetting, Slicing & Indexing",
          "العمليات الحسابية والإحصائية NumPy Arrays Math & Statistics Operations",
          "إنشاء هياكل البيانات Pandas Data Structures",
          "التعامل مع الملفات Pandas File I/O",
          "معلومات عن هياكل البيانات Pandas Information",
          "الوصول للبيانات Pandas Subsetting, Slicing & Indexing",
          "العمليات الإحصائية Pandas Statistical Operations",
          "إنشاء الرسومات لتصوير البيانات في بايثون Creating Matplotlib Plots",
          "تعديل الرسومات في بايثون Customizing Matplotlib Plots",
          "تصوير البيانات الإحصائية في بايثون Seaborn Statistical Visualization"
        ],
        "مبادئ الإحصاء لعلم البيانات | Statistics for Data Science": [
          "مقدمة عامة عن الإحصاء Statistics",
          "ليه الإحصاء والاحتمالات مهمة لعالم البيانات؟ Why Statistics",
          "الفرق بين المجتمع والعينة Population vs. Sample",
          "يعني إيه بيانات What is Data?",
          "إيه أنواع البيانات اللي بنتعامل معاها Data Types",
          "أساسيات الإحصاء الوصفية Descriptive Statistics Basics",
          "حساب المتوسطات Mean, Median, & Mode",
          "المتغير العشوائي Random Variable",
          "قياس مدى التباعد Five-Numbers Summary",
          "الإنحراف المعياري والتباين Variance & Standard Deviation",
          "الأشكال الإحصائية Shape Measures",
          "القيم الشاذة والمتطرفة Outliers",
          "مقدمة عامة عن الإحتمالات Probabilities",
          "يعني إيه إحتمالات What is Probabilities",
          "تجربة الإحتمالات Experimental Probabilities",
          "إحتمالية عدم وقوع الحدث Event Complement",
          "المجموعات وعلاقات الأحداث Sets & Events (Union & Intersection)",
          "الإحتمال المشروط Conditional Probability",
          "التوزيعات الإحتمالية Probability Distributions",
          "مقدمة عامة عن الإحصاء الإستدلالي Statistical Inference",
          "إختيار العينة Sampling",
          "التوزيع الطبيعي القياسي Standard Normal Distribution",
          "مجالات الثقة الإحصائية Confidence Intervals",
          "إختبار الفرضيات الإحصائية Hypothesis Testing"
        ]
      },
      "requirements": [
        "دبلومة بايثون لتحليل البيانات | Python Data Analysis Diploma",
        "دبلومة بايثون لتعلم الآلة | Python Machine Learning Diploma",
        "أساسيات برمجة بايثون | Python Programming Basics",
        "مكتبات تحليل البيانات في بايثون | Python Data Analysis Libraries (NumPy, Pandas, Matplotlib, & Seaborn)",
        "مكتبات تعلم الآلة في بايثون | Python Machine Learning Libraries (Sci-kit Learn)",
        "أساسيات الإحصاء | Statistics Basics"
      ],
      "description": "دبلومة بايثون للتعلم العميق | Python Deep Learning Diploma\nدبلومة التعلم العميق باستخدام بايثون هي الخطوة الثالثة والأخيرة في رحلتنا في مجال علم وتحليل البيانات والذكاء الإصطناعي، وهي مبادرة نسعى من خلالها إلى إثراء المحتوى العربي في هذا المجال من خلال إعداد دورة تدريبية شاملة بشكل تفاعلي وتطبيقي لكل مواضيع وتخصصات هذا المجال .. وبنحاول إن التدريب يكون مناسب للمبتدئين ولأي شخص يرغب في بدء العمل كمحلل بيانات Data Analyst / عالم بيانات Data Science باستخدام بايثون Python واحتراف هذا المجال من الصفر.\n\n\nالدبلومة بتتميز بالآتي:\n- التدريب تفاعلي وقائم على النقاشات مع الطلاب\n- خطة واضحة ومنظمة للبدء في المجال من الصفر وحتى احترافه\n- 6 كورسات في كورس واحد\n- أكثر من 30 ساعة تدريبية\n- تطبيقات عملية ومشاريع Case-studies\n- تحميل ملفات التدريب والأكواد Course Materials\n- المحتوى متاح مدى الحياة\n- شهادة بنهاية التدريب\n\n\nبنشرح في الدبلومة التقنيات والأدوات الرئيسية لأي عالم بيانات باستخدام بايثون:\nمبادئ التعلم العميق | Deep Learning Foundations\nالشبكات العصبية الاصطناعية | Artificial Neural Networks (ANN) Basics\nالشبكات العصبية الإلتفافية | Convolutional Neural Network (CNN) Basics\nالشبكات العصبية المتكررة | Recurrent Neural Network (RNN) Basics\nمواضيع متقدمة في التعلم العميق | Advanced Topics (Auto Encoders, Transfer Learning, & Reinforcement Learning)\nمشاريع وتطبيقات عملية على التعلم العميق في بايثون | Python Deep Learning Projects\n\n\n---\n= (*) تحذير هام: تم بذل مجهود كبير بفضل الله وتوفيقه من قبل م. مصطفى عثمان في إعداد هذا المحتوى الذي يقدم بصفة شخصية لك مقابل الاشتراك، رجاء عدم نسخه أو استخدامه بعيداً عن الموقع أو الإتجار به لإن ذلك يعرضك للمسائلة أمام الله عز وجل .. شكراً لتفهمك، وشكراً لاهتمامك بما نقدمه",
      "target_audience": [
        "أي حد لسة هيبدأ في مجال علم وتحليل البيانات وعاوز يبدأ بداية موفقة",
        "اللي بدأ في تعلم الآلة وحابب يتعلم ويحترف التعلم العميق وعلم البيانات"
      ]
    },
    {
      "title": "Come funziona ChatGpt Ai generativa + Midjouney",
      "url": "https://www.udemy.com/course/come-funziona-chatgpt-ai-generativa-midjouney/",
      "bio": "Impara ad utilizzare i principali strumenti di AI e capisci come cambia il mondo del lavoro",
      "objectives": [
        "Chatgpt e Midjourney spiegati passo passo: Video tutorial pratici su come usare i servizi in diversi ambiti di utilizzo, da strumenti di lavoro, al marketing,",
        "i nuovi servizi che usano AI: Tanti nuovi servizi stanno uscendo, avrai una panoramica dei servizi per la produttività, creazione dei contenuti, automazione e t",
        "I campi di utilizzo e nuove opportunità: Come viene utilizzata questa tecnologia in tanti campi, da HR, a Legal, da tech a ecommerce e custumer support",
        "I nuovi lavori e sviluppi futuri per i business: In tutti i settori questa tecnoligia verrà implementata tramite API, capirai il funzionamento di base, come ver"
      ],
      "course_content": {
        "Introduzione": [
          "Introduzione"
        ],
        "Capitolo 1 - AI Generativa": [
          "Introduzione AI Generativa",
          "Gruppo Facebook"
        ],
        "ChatGPT": [
          "Introduzione ChatGpt",
          "Come utilizzare ChatGPT - tutorial",
          "Apprfondimenti e link utili"
        ],
        "Midjourney, Dall-E": [
          "Introduzione MidJourney, Dall-E e generatori di immagini",
          "Come utilizzare Midjouney - tutorial part 1",
          "Come utilizzare Midjouney - part 2"
        ],
        "Prompt": [
          "I prompt: la competenza più richesta per pensare come una macchina",
          "Link Utili"
        ],
        "Servizi AI": [
          "Come vengono sviluppati i servizi",
          "I servizi principali disponibili nel mercato"
        ],
        "Campi di Utilizzo": [
          "Campi e settori di utilizzo"
        ],
        "Rischi": [
          "Rischi legati all'utilizzo di AI Generativa"
        ],
        "Reference": [
          "Reference, link utili",
          "Lista di link"
        ]
      },
      "requirements": [
        "Non è necessario avere competenze pregresse, questo corso ti guida passo passo nella comprensione della tematica"
      ],
      "description": "Come funzionano i i nuovi strumenti di AI ?\nNon si parla altro di ai generativa, Chatgpt, MidJouney, Dall-e e altri strumenti utili.\nSONO MOLTO POTENTI e avranno un impatto su tutti i settori e il mondo del lavoro in generale.\n\n\nPARTECIPA ALLE LEZIONI E SARAI GUIDATO PASSO PASSO:\n- Lezioni di teoria e pratica\n- Comprendi come evolve il mercato e le nuove competenze richieste\n- L'impatto sui diversi settori\n- fai domande, testa, conosci, sviluppa nuova idee\n\n\nCOSA IMPAREREMO:\n- come usare gli strumenti per generare testi, rapporti, immagini, video e tanto altro\n- i servizi già presenti sul mercato per contenuti, automazione\n- come. funziona la tecnologia sottostante\n- le nuove professionalità e skills richieste in questo settore\n- l'impatto di questa tecnologia su tutte le industrie\n\n\nÈ importante in questo momento capire subito le potenzialità, rischi e opportunità di questi strumenti.\nChi conosce questi strumenti avrà un vantaggio su tanti aspetti lavorativi e su come integrarli nei diversi business.\n\nPER CHI è:\n- curiosi\n- liberi professionisti\n- imprenditori digitali\n- creativi\n- aziende tradizionali\n\nDa quando è uscito ChatGPT a Dicembre non si parla di altro. Ma cosa sta succedendo?\nMicrosoft è pronta a investire 10 Miliardi e Google sta tremando. Questo perchè questa nuova tecnologia innovativa crea nuove possibilità e servizi in diversi campi.\nChi sa capire questa tecnologia e le sue future applicazioni avrà una visione chiara dei nuovi scenari lavorativi e come i business utilizzeranno questa tecnologia in diversi ambiti.\nSe vuoi essere al passo e capire come utilizzarla al meglio e conoscere i diversi servizi e campi di utilizzo è una grande opportunità di stare al passo con i tempi.\n\n\nTI ASPETTIAMO, Stai con noi un passo avanti a tutti",
      "target_audience": [
        "Avere le competenze tecniche per utilizzare gli strumenti AI: ChatGPT, Mid-Jounery",
        "Capire in quali ambiti e settori questa tecnologia avrà un impatto profondo",
        "Sviluppare le proprie competenze tecniche per il mercato del lavoro"
      ]
    },
    {
      "title": "Aprende Ciencia de datos en Python en 7 días- ¡Novedad 2025!",
      "url": "https://www.udemy.com/course/ciencia-de-datos-en-python-en-7-dias/",
      "bio": "¡Domina los fundamentos de la Ciencia de Datos rápida y eficientemente en una semana! Directo al grano para aprender",
      "objectives": [
        "Realizar análisis estadísticos de conjuntos de datos reales",
        "Tratar con datos faltantes usando pandas",
        "Comprender las estrategias y herramientas de ingeniería de características",
        "Representar diagramas de distribución (distplot), histogramas y diagramas de dispersión",
        "Comprender la diferencia entre normalización y estandarización",
        "Cambiar los tipos de datos de DataFrames de Pandas",
        "Definir una función y aplicarla a una columna de DataFrames de Pandas",
        "Visualizar datos utilizando las librerías Seaborn y Matplotlib",
        "Representar pairplots, countplots y mapas térmicos de correlación con Seaborn",
        "Construir, entrenar y probar nuestro primer modelo de regresión en Scikit-Learn",
        "Aplicar AutoGluon para resolver problemas de tipo regresión y clasificación"
      ],
      "course_content": {
        "Introducción": [
          "Aprende Ciencia de Datos en 7 días",
          "Bienvenidos al curso de ciencia de datos",
          "Un pequeño regalo para ti",
          "Introducción, Buenas Prácticas y Trucos para el Éxito",
          "Temario del Curso",
          "¿Qué es la Ciencia de Datos?",
          "Perfil, formación, experiencia y salario típicos de un científico de datos",
          "¿Qué hacen REALMENTE los científicos de datos?",
          "¿Qué buscan los reclutadores en los aspirantes a científicos de datos?",
          "¿Cuales son los trabajos en ciencia de datos disponibles?",
          "Cómo clonar los datos para seguir el curso"
        ],
        "Día 1: Manejo de Datos, Análisis Exploratorio (EDA) e Ingeniería de Variables": [
          "Día 1: Mensaje de Bienvenida",
          "Recursos del día 1",
          "Introducción al Proyecto y Data Wrangling",
          "Tarea de Programación 1: Importar los datos y obtener un resumen estadístico",
          "Ejercicio 1 [Opcional]",
          "Tarea de Programación 2: Tratar los datos faltantes",
          "Ejercicio 2 [Opcional]",
          "Tarea de Programación 3: Realizar una codificación binaria (one-hot)",
          "Ejercicio 3 [Opcional]",
          "Escalado de variables: normalización y estandarización",
          "Tarea de Programación 4: Realizar escalados (normalización y estandarización)",
          "Ejercicio 4 [Opcional]",
          "Tarea de Programación 5: Operaciones y Filtrado en Pandas",
          "Ejercicio 5 [Opcional]",
          "Tarea de Programación 6: Realizar un EDA básico en ambas clases",
          "Ejercicio 6 [Opcional]",
          "Tarea de Programación 7: Funciones con Pandas",
          "Ejercicio 7 [Opcional]",
          "Tarea de Programación 8: Histogramas y Correlaciones",
          "Ejercicio 8 [Opcional]",
          "Proyecto Final del Día 1",
          "Fin del Día 1"
        ],
        "Día 2: Visualización de datos eficaz en Ciencia de Datos": [
          "Día 2: Mensaje de Bienvenida",
          "Recursos del día 2",
          "Resumen del Proyecto y Objetivos Clave de Aprendizaje",
          "Introducción a la Visualización de Datos",
          "Tarea de Programación 1: Representar diagramas de pastel con Matplotlib",
          "Ejercicio 1 [Opcional]",
          "Tarea de Programación 2: Diagrama de Líneas Simple y Múltiple",
          "Ejercicio 2 [Opcional]",
          "Tarea de Programación 3: Representar nubes de puntos",
          "Ejercicio 3 [Opcional]",
          "Tarea de Programación 4: Representar histogramas",
          "Ejercicio 4 [Opcional]",
          "Tarea de Programación 5: Seaborn Parte 1",
          "Ejercicio 5 [Opcional]",
          "Tarea de Programación 6: Seaborn Parte 2",
          "Ejercicio 6 [Opcional]",
          "Proyecto Final Día 2",
          "Fin Día 2"
        ],
        "Día 3: Análisis de Regresión en Ciencia de Datos": [
          "Día 3: Mensaje de Bienvenida",
          "Recursos del Día 3",
          "Resumen del Proyecto y Objetivos Claves de Aprendizaje",
          "¿Qué es la regresión?",
          "¿Qué es XG-Boost?",
          "Tarea de Programación 1: Cargar las librerías y conjuntos de datos",
          "Ejercicio 1 [Opcional]",
          "Tarea de Programación 2: Análisis Exploratorio de los Datos (EDA) y Visualizació",
          "Ejercicio 2 [Opcional]",
          "Tarea de Programación 3: Preparar los datos antes de entrenar el modelo",
          "Ejercicio 3 [Opcional]",
          "Tarea de Programación 4: Entrenar el modelo de XGBoost",
          "Ejercicio 4 [Opcional]",
          "Proyecto Final Día 3",
          "Fin del Día 3"
        ],
        "Día 4: Análisis de Clasificación en Ciencia de Datos": [
          "Día 4: Mensaje de Bienvenida",
          "Recursos del Día 4",
          "Introducción y Resumen del Proyecto",
          "KPIs en Modelos de Clasificación",
          "Tarea de Programación 1: Importar las librerías y los datasets",
          "Ejercicio 1 [Opcional]",
          "Tarea de Programación 2: Realizar Visualización de Datos",
          "Ejercicio 2 [Opcional]",
          "La Regresión Logística",
          "Tarea de Programación 3: Representar las características importantes",
          "Tarea de Programación 4: Entrenar y evaluar un modelo de clasificación logístico",
          "Ejercicio 3 [Opcional]",
          "Las Máquinas de Soporte Vectorial",
          "Tarea de Programación 5: Entrenar y evaluar las máquinas de soporte vectorial",
          "Los Bosques Aleatorios",
          "Tarea de Programación 6: Entrenar y evaluar modelos de clasificación de bosques",
          "K Nearest Neighbours",
          "Tarea de Programación 7: Entrenar y evaluar un clasificador K-Nearest Neighbors",
          "Ejercicio 4 [Opcional]",
          "Naïve Bayes",
          "Tarea de Programación 8: Entrenar y evaluar un modelo de clasificación Naïve Bay",
          "Ejercicio 5 [Opcional]",
          "Tarea de Programación 9: Comparar modelos de clasificación",
          "Tarea de Programación 10: Conclusiones Finales",
          "Proyecto Final del Día 4",
          "Fin del Día 4"
        ],
        "Día 5: Ciencia de Datos en Modo Piloto Automático": [
          "Día 5: Mensaje de Bienvenida",
          "Recursos del Día 5",
          "Introducción y resumen del proyecto",
          "AutoGluon",
          "Tarea de Programación 1: Importar AutoGluon, Librerías Clave y Datasets",
          "Ejercicio 1 [Opcional]",
          "Tarea de Programación 2: Realizar Análisis Exploratorio de Datos (EDA)",
          "Ejercicio 2 [Opcional]",
          "Tarea de Programación 3: Visualización de los datos",
          "Ejercicio 3 [Opcional]",
          "Tarea de Programación 4: Entrenar Modelos de Regresión en Piloto Automático",
          "Tarea de Programación 5: Evaluar Modelos de Regresión Entrenados",
          "Ejercicio 4 [Opcional]",
          "Proyecto Final del Día 5",
          "Fin Día 5"
        ],
        "Día 6: Optimización de Modelos": [
          "Día 6: Mensaje de Bienvenida",
          "Recursos del Día 6",
          "Resumen del Proyecto",
          "Hiperparámetros",
          "Estrategias de Optimización",
          "Tarea de Programación 1: Importar librerías y datasets",
          "Ejercicio 1 [Opcional]",
          "Tarea de Programación 2: Realizar limpieza de los datos",
          "Tarea de Programación 3: Visualización de los Datos",
          "Ejercicio 2 [Opcional]",
          "Tarea de Programación 4: Preparar los datos para entrenar el modelo",
          "Tarea de Programación 5: Entrenar el algoritmo de XG-Boost (sin optimización)",
          "Ejercicio 3 [Opcional]",
          "Tarea de Programación 6: Optimización con GridSearchCV",
          "Ejercicio 4 [Opcional]",
          "Tarea de Programación 7: Optimización por Búsqueda Aleatoria",
          "Tarea de Programación 8: Optimización por Búsqueda Bayesiana",
          "Proyecto Final del Día 6",
          "Fin del Día 6"
        ],
        "Día 7: Deep Learning": [
          "Tarea 1: Resumen del Proyecto",
          "Tarea 2: Cargar y Explorar el Dataset",
          "Tarea 3: Entrenar un modelo de redes neuronales profundos",
          "Tarea 4: IA Explicable y comprender los modelos",
          "Fin del Día 7"
        ],
        "Enhorabuena por completar el curso!": [
          "Felicidades por terminar el curso",
          "BONUS"
        ]
      },
      "requirements": [
        "Haber completado el curso de Python de la A a la Z para tener conocimientos previos de programación",
        "Haber realizado algunos cursos de la ruta de Matemáticas Avanzadas de Frogames Formación para tener una base de esta materia y así entender mejor los algoritmos que se explicarán durante el curso",
        "Tener un ordenador con conexión a internet y con cualquier sistema operativo instalado y saber utilizarlo a nivel de usuario"
      ],
      "description": "¡Data Science es ahora uno de los campos de la tecnología más candentes para estar! Este campo está lleno de oportunidades y perspectivas profesionales.\nLa Ciencia de Datos está muy extendida en muchos sectores, como la banca, la sanidad, el transporte y la tecnología. En los negocios, la Ciencia de Datos se aplica para optimizar los procesos empresariales, maximizar los ingresos y reducir los costes.\nEste curso tiene como objetivo proporcionarte el conocimiento de los aspectos críticos de la Ciencia de Datos en una semana y de una manera práctica, fácil, rápida y eficiente.\nEste curso es único y excepcional en muchos aspectos. Incluye varias oportunidades de práctica en forma de tareas, cuestionarios y proyectos finales.\nCada día, pasaremos de 1 a 2 horas juntos y dominaremos un tema de Ciencia de Datos.\nEn primer lugar, vamos a empezar con el paquete de inicio esencial de Ciencia de Datos y dominar los conceptos clave de Data Science, incluyendo el ciclo de vida del proyecto de Ciencia de Datos, lo que buscan los reclutadores y qué puestos de trabajo están disponibles.\nA continuación, comprenderemos el análisis exploratorio de datos y las técnicas de visualización utilizando las bibliotecas Pandas, Matplotlib y Seaborn.\nEn la siguiente sección, aprenderemos los fundamentos de la regresión. Veremos cómo construir, entrenar, probar y desplegar modelos de regresión utilizando la biblioteca Scikit-Learn.\nPara continuar, aprenderemos sobre estrategias de optimización de hiperparámetros, como la búsqueda en cuadrícula, la búsqueda aleatoria y la optimización bayesiana.\nA continuación, aprenderemos a entrenar varios algoritmos de clasificación como la regresión logística, la máquina de vectores de soporte, K-Nearest Neighbors, el clasificador Random Forest y Naïve Bayes utilizando las bibliotecas SageMaker y Scikit-Learn.\nSeguiremos cubriendo la Ciencia de Datos en AutoPilot. Aprenderemos a usar la librería AutoGluon para crear prototipos de múltiples modelos AI/ML y desplegar el mejor.\nEcha un vistazo a los vídeos de vista previa y al esquema para hacerte una idea de los proyectos que cubriremos.\n¡Apúntate hoy y aprovechemos juntos el poder de la Ciencia de Datos!\n¡Nos vemos en clase!",
      "target_audience": [
        "Alumnos principiantes en el mundo del Data Science que deseen dar sus primeros pasos en el análisis de datos con Python",
        "Trabajadores aspirantes a empresarios que quieran maximizar los ingresos de su negocio y reducir costes con la Ciencia de Datos"
      ]
    },
    {
      "title": "Machine Learning Bootcamp w języku Python cz.III - Ćwiczenia",
      "url": "https://www.udemy.com/course/machine-learning-bootcamp-w-jezyku-python-cwiczenia/",
      "bio": "Opanuj Machine Learning w Pythonie: Zaawansowane ćwiczenia i techniki w trzeciej części Bootcampu ML!",
      "objectives": [
        "rozwiązać ponad 100 ćwiczeń z uczenia maszynowego w języku Python",
        "radzić sobie z rzeczywistymi problemami występującymi w data science",
        "radzić sobie z rzeczywistymi problemami występującymi w uczeniu maszynowym",
        "pracować z bibliotekami numpy, pandas, scikit-learn",
        "pracować z dokumentacją",
        "zagwarantowane wsparcie instruktora"
      ],
      "course_content": {
        "Konfiguracja (opcjonalnie)": [
          "Info",
          "Wprowadzenie do Google Colab",
          "Instalacja Anacondy - Windows 10",
          "Wprowadzenie do programu Spyder",
          "Instalacja Anacondy - Linux (Ubuntu)"
        ],
        "Wskazówki": [
          "Kilka słów od autora"
        ],
        "Starter": [
          "Ćwiczenie 0",
          "Rozwiązanie 0"
        ],
        "Ćwiczenia 1-10": [
          "Ćwiczenie 1",
          "Rozwiązanie 1",
          "Ćwiczenie 2",
          "Rozwiązanie 2",
          "Ćwiczenie 3",
          "Rozwiązanie 3",
          "Ćwiczenie 4",
          "Rozwiązanie 4",
          "Ćwiczenie 5",
          "Rozwiązanie 5",
          "Ćwiczenie 6",
          "Rozwiązanie 6",
          "Ćwiczenie 7",
          "Rozwiązanie 7",
          "Ćwiczenie 8",
          "Rozwiązanie 8",
          "Ćwiczenie 9",
          "Rozwiązanie 9",
          "Ćwiczenie 10",
          "Rozwiązanie 10"
        ],
        "Ćwiczenia 11-20": [
          "Ćwiczenie 11",
          "Rozwiązanie 11",
          "Ćwiczenie 12",
          "Rozwiązanie 12",
          "Ćwiczenie 13",
          "Rozwiązanie 13",
          "Ćwiczenie 14",
          "Rozwiązanie 14",
          "Ćwiczenie 15",
          "Rozwiązanie 15",
          "Ćwiczenie 16",
          "Rozwiązanie 16",
          "Ćwiczenie 17",
          "Rozwiązanie 17",
          "Ćwiczenie 18",
          "Rozwiązanie 18",
          "Ćwiczenie 19",
          "Rozwiązanie 19",
          "Ćwiczenie 20",
          "Rozwiązanie 20"
        ],
        "Ćwiczenia 21-30": [
          "Ćwiczenie 21",
          "Rozwiązanie 21",
          "Ćwiczenie 22",
          "Rozwiązanie 22",
          "Ćwiczenie 23",
          "Rozwiązanie 23",
          "Ćwiczenie 24",
          "Rozwiązanie 24",
          "Ćwiczenie 25",
          "Rozwiązanie 25",
          "Ćwiczenie 26",
          "Rozwiązanie 26",
          "Ćwiczenie 27",
          "Rozwiązanie 27",
          "Ćwiczenie 28",
          "Rozwiązanie 28",
          "Ćwiczenie 29",
          "Rozwiązanie 29",
          "Ćwiczenie 30",
          "Rozwiązanie 30"
        ],
        "Ćwiczenia 31-40": [
          "Ćwiczenie 31",
          "Rozwiązanie 31",
          "Ćwiczenie 32",
          "Rozwiązanie 32",
          "Ćwiczenie 33",
          "Rozwiązanie 33",
          "Ćwiczenie 34",
          "Rozwiązanie 34",
          "Ćwiczenie 35",
          "Rozwiązanie 35",
          "Ćwiczenie 36",
          "Rozwiązanie 36",
          "Ćwiczenie 37",
          "Rozwiązanie 37",
          "Ćwiczenie 38",
          "Rozwiązanie 38",
          "Ćwiczenie 39",
          "Rozwiązanie 39",
          "Ćwiczenie 40",
          "Rozwiązanie 40"
        ],
        "Ćwiczenia 41-50": [
          "Ćwiczenie 41",
          "Rozwiązanie 41",
          "Ćwiczenie 42",
          "Rozwiązanie 42",
          "Ćwiczenie 43",
          "Rozwiązanie 43",
          "Ćwiczenie 44",
          "Rozwiązanie 44",
          "Ćwiczenie 45",
          "Rozwiązanie 45",
          "Ćwiczenie 46",
          "Rozwiązanie 46",
          "Ćwiczenie 47",
          "Rozwiązanie 47",
          "Ćwiczenie 48",
          "Rozwiązanie 48",
          "Ćwiczenie 49",
          "Rozwiązanie 49",
          "Ćwiczenie 50",
          "Rozwiązanie 50"
        ],
        "Ćwiczenia 51-60": [
          "Ćwiczenie 51",
          "Rozwiązanie 51",
          "Ćwiczenie 52",
          "Rozwiązanie 52",
          "Ćwiczenie 53",
          "Rozwiązanie 53",
          "Ćwiczenie 54",
          "Rozwiązanie 54",
          "Ćwiczenie 55",
          "Rozwiązanie 55",
          "Ćwiczenie 56",
          "Rozwiązanie 56",
          "Ćwiczenie 57",
          "Rozwiązanie 57",
          "Ćwiczenie 58",
          "Rozwiązanie 58",
          "Ćwiczenie 59",
          "Rozwiązanie 59",
          "Ćwiczenie 60",
          "Rozwiązanie 60"
        ],
        "Ćwiczenia 61-70": [
          "Ćwiczenie 61",
          "Rozwiązanie 61",
          "Ćwiczenie 62",
          "Rozwiązanie 62",
          "Ćwiczenie 63",
          "Rozwiązanie 63",
          "Ćwiczenie 64",
          "Rozwiązanie 64",
          "Ćwiczenie 65",
          "Rozwiązanie 65",
          "Ćwiczenie 66",
          "Rozwiązanie 66",
          "Ćwiczenie 67",
          "Rozwiązanie 67",
          "Ćwiczenie 68",
          "Rozwiązanie 68",
          "Ćwiczenie 69",
          "Rozwiązanie 69",
          "Ćwiczenie 70",
          "Rozwiązanie 70"
        ]
      },
      "requirements": [
        "Ukończone kursy ze ścieżki Python Developer na tym koncie instruktorskim",
        "Ukończone kursy ze ścieżki Data Scientist na tym koncie instruktorskim",
        "Ukończenie poprzednich części serii Machine Learning Bootcamp"
      ],
      "description": "\"Machine Learning Bootcamp w języku Python cz.III - Ćwiczenia\" to intensywny kurs, którego głównym celem jest umocnienie i rozwijanie umiejętności związanych z uczeniem maszynowym poprzez praktykę. Kurs ten jest odpowiedni dla osób, które mają już pewne doświadczenie z Pythonem (rekomendowany kurs Programowanie w języku Python - od A do Z) i uczeniem maszynowym (rekomendowane kursy Machine Learning Bootcamp w języku Python cz.I oraz Machine Learning Bootcamp w języku Python cz.II) i chcą je poszerzyć.\nKurs ten składa się z serii ćwiczeń, które pokrywają różne aspekty uczenia maszynowego, od podstawowych do zaawansowanych. Ćwiczenia zostały zaprojektowane tak, aby umożliwić uczestnikom stosowanie teorii do praktyki, co pozwoli na lepsze zrozumienie i utrwalenie kluczowych koncepcji. Każde ćwiczenie zawiera szczegółowe rozwiązanie, które umożliwia uczestnikom porównanie swojego podejścia z optymalnym, a także zrozumienie, dlaczego dane podejście jest najlepsze.\n\"Machine Learning Bootcamp w języku Python cz.III - Ćwiczenia\" to doskonały kurs dla tych, którzy chcą udoskonalić swoje umiejętności w uczeniu maszynowym poprzez intensywną praktykę. Dzięki temu kursowi, uczestnicy będą mogli zwiększyć swoją pewność siebie w stosowaniu uczenia maszynowego do rozwiązywania rzeczywistych problemów.\n\n\nUczenie maszynowe – Gdy dane uczą maszyny myśleć\nUczenie maszynowe (machine learning) to dziedzina sztucznej inteligencji, która pozwala komputerom uczyć się na podstawie danych i podejmować decyzje bez wyraźnego zaprogramowania. Zamiast sztywnych reguł, modele uczą się wzorców i zależności, co umożliwia im przewidywanie, klasyfikowanie i rozpoznawanie złożonych struktur. Uczenie maszynowe znajduje zastosowanie między innymi w rekomendacjach, rozpoznawaniu obrazów, analizie tekstu i autonomicznych systemach.",
      "target_audience": [
        "Osoby uczące się uczenia maszynowego",
        "Junior Data Scientists / Junior ML Engineers",
        "Analitycy danych chcący przejść do ML",
        "Programiści chcący wejść w świat ML",
        "Studenci kierunków technicznych"
      ]
    },
    {
      "title": "Machine Learning com Spark e Pyspark: o Curso Completo",
      "url": "https://www.udemy.com/course/machine-learning-com-spark-e-pyspark/",
      "bio": "Domine a Criação e Tunning de Modelos de Machine Learning Utilizando Spark e Python!",
      "objectives": [
        "Aprenda Otimização de Hiper Parâmetros de Modelos",
        "Saiba Criar Pipelines de Machine Learning",
        "Domine Técnicas de Pré-Processamento de dados",
        "Veja na Prática a Criação de Modelos de Regressão, Classificação e Clusters",
        "Produza Assobiadores Robustos",
        "Avalie a Performance de Modelos",
        "Importe Dados",
        "Persista Modelos",
        "Utilize Técnicas como MultiLayer Perceptron, Random Forest e Regressão Logística"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Introdução",
          "Por que Machine Learning com Spark?"
        ],
        "Conceitos Gerais de Machine Learning": [
          "Introdução",
          "Introdução Parte II",
          "Classificação",
          "Regressão",
          "Agrupamentos",
          "Sistemas de Recomendação",
          "Regressão Linear",
          "Regressão Logística",
          "Categorical Encoding",
          "Feature Scalling"
        ],
        "Preparação de Ambiente": [
          "Atenção: sobre o ambiente para executar o curso!",
          "Escolhendo o Ambiente",
          "LINUX: Introdução sobre Instalação com VM Linux",
          "Downloads Necessários",
          "Instalando VM Ubuntu",
          "Instalando Spark",
          "Bibliotecas Adicionais",
          "Rodando Exemplos na Linha de Comando",
          "Instalando e Configurando Jupyter Notebooks",
          "WINDOWS: Orientações de Instalação e Configuração",
          "NUVEM: Databricks Community Edition"
        ],
        "Importação de Dados": [
          "Dados Utilizados Durante o Curso",
          "Material para Download",
          "Introdução a Importação de Dados no Spark",
          "Formato LIBSVM",
          "Exemplos de Importações Diversas",
          "Importando LIBSVM"
        ],
        "Engenharia de Atributos e Pré-Processamento": [
          "Vetorização de Atributos com VectorAssembler",
          "Geração de Características com PCA (Principal component analysis)",
          "Binarização de Atributos",
          "Indexação de Texto com StringIndexer",
          "Índice para Texto com IndexToString",
          "Categorical Encoding com One Hot Encoding",
          "Tratando Valores Ausentes com Imputer",
          "Expansão de Atributos com PolynomialExpansion",
          "Normalização de Dados com Normalizer",
          "Padronização de Dados com StandarScaler",
          "Padronização de Dados com RobustScaler",
          "Padronização de Dados com MinMaxScaler",
          "Padronização de Dados com MaxAbsScaler",
          "Discretização de Dados",
          "Transformação com RFormula",
          "Divisor de Vetores com VectorSlicer",
          "Seleção de Atributos com ChiSqSelector (qui-quadrado)",
          "Seleção de Atributos com UnivariateFeatureSelector"
        ],
        "Regressão com Spark": [
          "Regressão Linear Múltipla com Spark",
          "Métodos Diversos de Regressão",
          "Regressão com RandomForest (Florestas Aleatórias)"
        ],
        "Classificação Binária e Multi Classe com Spark": [
          "Classificação Logística",
          "Classificação com NaiveBayes",
          "Classificação com Rede Neural Artificial (Multi Layer Perceptron)"
        ],
        "Agrupamentos com Spark": [
          "Agrupamentos com Kmeans",
          "Agrupamento Hierárquico com HierarchicalBisecting"
        ],
        "Associadores com Spark": [
          "Associadores com FP-Growth"
        ],
        "Construindo Pipelines de Machine Learning": [
          "Construindo Pipelines com Spark"
        ]
      },
      "requirements": [
        "Conhecimentos Básicos de Python"
      ],
      "description": "Faça uma super imersão em Machine Learning com Spark utilizando bibliotecas nativas!\nNa era \"Big Data\" o Spark se tornou a principal ferramenta de processamento de dados no mundo devido a sua capacidade de processar volumes massivos de dados com alta performance, se tornando uma ferramenta essencial para Cientistas e Engenheiros de Dados. Sua arquitetura distribuída permite processar dados utilizando paralelismo e memória, persistindo dados quando necessário. Além disso o Spark é capaz de importar dados de praticamente qualquer fonte, bem como também exportar dados processados para os principais formatos e bancos de dados utilizados.\nDo ponto de vista profissional, conhecer Spark é uma das habilidades mais importantes ao lado de Machine Learning e Python. E o melhor disso é o que Spark já traz tudo isso. Você pode utilizar Spark com Python, através do Pyspark, e você pode criar modelos de Machine Learning utilizando as próprias bibliotecas do Spark.\nNeste curso prático, você vai dominar o uso do Spark para Machine Learning:\nAprenda os conceitos gerais de Machine Learning\nConheça o Processo de Importação de Dados\nDomine técnicas de pré-processamento, como substituição de valores faltantes\nAprenda técnicas de engenharia de atributos, como normalização de dados e codificação de categorias\nCrie modelos de Regressão e Classificação, utilizando Redes Neurais, Random Forest e outras\nAvalie a performance de seus modelos\nCrie Clusters e avalia a performance\nProduza regras de associação com itens frequentes\nFaça o tunning de Hiper Parâmetros de Modelos\nCria fluxos de processamento de Machine Learning utilizando Pipelines\ne muito mais!\nVocê ainda vai encontrar material do curso para baixar: scripts, slides e dados de exemplo.",
      "target_audience": [
        "Cientistas de Dados",
        "Engenheiros de Dados",
        "Engenheiros de Machine Learning",
        "Analistas de Dados"
      ]
    },
    {
      "title": "【한글자막】 R 프로그래밍 A-Z™: 직접 코딩하며 배우는 R 프로그래밍 !",
      "url": "https://www.udemy.com/course/best-r-coding/",
      "bio": "R과 R 스튜디오로 프로그래밍을 배우기. 실전 연습 문제로 데이터 분석, 데이터 과학, 통계 분석, 패키지, 함수, GGPlot2",
      "objectives": [
        "R 프로그래밍을 잘 하는 방법",
        "R 스튜디오 사용법",
        "프로그래밍의 핵심 원칙",
        "R에서 벡터를 만드는 방법",
        "변수를 만드는 방법",
        "R의 정수형, 실수형, 논리형, 문자형 등 여러 자료형",
        "R에서 while() 루프 및for() 루프를 만드는 방법",
        "R에서 행렬을 만들고 사용하는 방법",
        "matrix() 함수, rbind() 및 cbind()",
        "R에서 패키지를 설치하는 방법",
        "R 스튜디오를 내 취향대로 사용자 정의하는 방법",
        "큰 수의 법칙 이해",
        "정규 분포 이해",
        "R에서 통계 데이터를 다루는 연습",
        "R에서 금융 데이터를 다루는 연습",
        "R에서 스포츠 데이터를 다루는 연습"
      ],
      "course_content": {
        "힘차게 출발해 봅시다": [
          "R 프로그래밍 과정에 오신 것을 환영합니다!",
          "Udemy 리뷰 업데이트",
          "R 및 R 스튜디오 설치 (Mac & 윈도우)",
          "보너스: 학습 경로",
          "연습 – 흥미진진해요!",
          "자료 받기",
          "몇 가지 추가 자료!!",
          "보너스: Hadley Wickham과 인터뷰",
          "더 좋은 데이터 과학자가 되는 지름길!"
        ],
        "핵심 프로그래밍 원칙": [
          "이 섹션에 오신 것을 환영합니다. 여러분이 배울 내용을 소개합니다!",
          "변수의 유형",
          "변수 사용하기",
          "논리형 변수 및 연산자",
          "“While” 루프",
          "콘솔 사용하기",
          "\"For\" 루프",
          "\"If\" 문",
          "섹션 복습",
          "숙제: 큰 수의 법칙",
          "핵심 프로그래밍 원칙"
        ],
        "R의 기본 개념": [
          "이 섹션에 오신 것을 환영합니다. 여러분이 배울 내용을 소개합니다!",
          "벡터란 무엇인가?",
          "벡터를 만들어 봅시다",
          "[] 대괄호 사용하기",
          "벡터화 연산",
          "벡터화 연산의 힘",
          "R의 함수",
          "R의 패키지",
          "섹션 복습",
          "숙제: 재무제표 분석",
          "R의 기본 개념"
        ],
        "행렬": [
          "이 섹션에 오신 것을 환영합니다. 여러분이 배울 내용을 소개합니다!",
          "프로젝트 개요: 농구 트렌드",
          "행렬",
          "첫번째 행렬 만들기",
          "차원 명명하기",
          "Colnames() 과 Rownames()",
          "행렬 연산",
          "Matplot()으로 시각화하기",
          "서브셋 만들기",
          "서브셋 시각화",
          "첫번째 함수 만들기",
          "농구 인사이트",
          "섹션 복습",
          "숙제: 농구 자유투",
          "행렬"
        ],
        "데이터 프레임": [
          "이 섹션에 오신 것을 환영합니다. 여러분이 배울 내용을 소개합니다!",
          "프로젝트 요약: 인구 통계학적 분석",
          "데이터를 R로 가져오기",
          "데이터셋 탐색하기",
          "$ 기호 사용하기",
          "데이터 프레임 기본 연산",
          "데이터 프레임 필터링",
          "qplot 소개",
          "Qplot으로 시각화하기: 파트 I",
          "데이터 프레임 만들기",
          "데이터 프레임 병합하기",
          "Qplot으로 시각화하기: 파트 II",
          "섹션 복습",
          "숙제: 세계 트렌드",
          "데이터 프레임"
        ],
        "GGPlot2를 사용한 고급 시각화": [
          "이 섹션에 오신 것을 환영합니다. 여러분이 배울 내용을 소개합니다!",
          "프로젝트 개요: 영화 등급",
          "그래픽의 문법 - GGPlot2",
          "요인이란 무엇인가?",
          "시각적 요소",
          "층으로 플롯 만들기",
          "시각적 요소 무시하기",
          "매핑 대 설정",
          "히스토그램과 밀도 차트",
          "시작층 팁",
          "통계적 변환",
          "패싯 사용하기",
          "좌표",
          "테마를 추가하여 완벽하게 만들기",
          "섹션 복습",
          "숙제: 영화 국내 총매출 %",
          "GGPlot2를 사용한 고급 시각화"
        ],
        "숙제 풀이": [
          "숙제 풀이법 섹션 2: 큰 수의 법칙",
          "숙제 풀이법 섹션 3: 재무제표 분석",
          "숙제 풀이법 섹션 4: 농구 자유투",
          "숙제 풀이법 섹션 5: 세계 트렌드",
          "숙제 풀이법 섹션 6: 영화 국내 총매출 % (파트 1)",
          "숙제 풀이법 섹션 6: 영화 국내 총매출 % (파트 2)",
          "감사 보너스 비디오"
        ],
        "보너스 튜토리얼": [
          "박스플롯",
          "*** 당신만의 특별 보너스 ***",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "사전 지식이나 경험이 필요하지 않습니다. 성공하고자 하는 열정만 가지고 오세요!"
      ],
      "description": "R과 R스튜디오로 프로그래밍 배우기!\n재미있고 흥미로운 데이터 사이언스!\n실전 연습문제로 따라가는 직관적인 강의!\n\n\nR 프로그래밍 A-Z™: 직접 코딩하며 배우는 R 프로그래밍 강의를 선택해야 하는 이유\nR에서 프로그래밍 하는 방법을 배우고 싶으신가요?\n너무 복잡한 R 강의들에 지치셨나요?\n재미있고 흥미로운 방법으로 데이터 싸이언스에 더 깊게 파고들고 싶으신가요?\n\n\n그렇다면, 직접 코딩하며 R 프로그래밍을 배우세요!\n\n\n시중에 R 코스와 강의들이 많이 있습니다. 하지만 R은 매우 가파른 학습 곡선을 갖고 있어서 종종 버겁게 느껴집니다. 이 코스는 다릅니다!\n\n\n이 코스는 진정한 단계별 코스입니다. 새로운 튜토리얼마다 배운 것을 구현하고 그 다음 단계로 나아갑니다\n\n\n모든 강의마다 바로 적용할 수 있는 유용한 개념을 배웁니다. 그리고 가장 좋은 점은 생생한 실제 사례를 통해 배울 수 있다는 것입니다.\n\n\n강의에 포함된 실전 연습 문제 및 훈련에서는 여러 가지 실생활 분석 문제의 해결법을 배웁니다. 몇 가지는 같이 풀어보고, 몇 가지는 숙제로 풀게 될 것입니다.\n\n\n결론적으로, 이 코스는 어떤 기술 수준에 있더라도 상관없이 배울 수 있도록 구성되었으며, 프로그래밍이나 통계학적 배경 지식이 없을 지라도 이 코스를 성공적으로 마칠 수 있습니다.\n\n\nR 프로그래밍 A-Z™: 직접 코딩하며 배우는 R 프로그래밍 강의에서 이런 내용을 배울 수 있습니다\nR 스튜디오를 사용하는 방법\n프로그래밍의 핵심 원칙\nR에서 벡터를 만드는 방법\n변수를 만드는 방법\nR의 정수형, 실수형, 논리형, 문자형 여러 자료형\nR에서 while() 루프 및for() 루프를 만드는 방법\nR에서 행렬을 만들고 사용하는 방법 배우기\nR에서 행렬을 만들고 사용하는 방법\nmatrix() 함수, rbind() 및 cbind()\nR에서 패키지를 설치하는 방법\n\n\n물리학과 수학 그리고 데이터 사이언스 강사 Kirill Eremenko의 한마디!\n한국 수강생 여러분 안녕하세요?\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n그럼 수업에서 만나요!\n감사합니다.\n\n\nKirill Eremenko 드림",
      "target_audience": [
        "R에서 프로그래밍 하는 방법을 배우고 싶은 분",
        "너무 복잡한 R 코스에 지친 분",
        "직접 코딩하며 R을 배우고 싶은 분",
        "흥미로운 도전을 좋아하는 분",
        "이 코스에 포함된 숙제를 열심히 할 준비가 된 분"
      ]
    },
    {
      "title": "Tıpta Yapay Zeka: Gerçek Dünya Projeleri",
      "url": "https://www.udemy.com/course/tpta-yapay-zeka-beyin-mr-goruntusunden-tumor-segmentasyonu/",
      "bio": "Yapay Zeka: Keras ve Python ile ileri seviye Computer Vision ve Neural Networks - 2020",
      "objectives": [
        "U-Net Algoritmasını kullanırken karşılaşılan boyut sorunlarını çözmeyi",
        "İleri seviye veri analizi ve görselleştirmeyi",
        "Numpy, pandas, seaborn, matplotlib gibi kütüphaneleri gerçek hayat projelerinde kullanmayı",
        "İleri seviye Keras optimizasyonunu",
        "Keras gibi ileri seviye Python kütüphanelerini kullanarak derin öğrenme modeli tasarlamayı",
        "U-Net algoritmasının mantığını",
        "İleri seviye derin öğrenme modelleri (U-Net) ve bu modellerin gerçek hayatta nerelerde kullanıldığını",
        "Python ile ileri düzey kodlamasını"
      ],
      "course_content": {
        "Giriş": [
          "Giriş",
          "ÖNEMLİ UYARI"
        ],
        "Diyabetik Retinopati Teşhisi ( Transfer Learning - EfficientNet B5, APTOS )": [
          "Kurs planı",
          "Veri seti",
          "Diğer veri setleri",
          "Diyabetik retinopati nedir, sınıflandırması nasıl yapılır?",
          "Pandas ile csv belgesini okuma",
          "Görüntüleri okuma",
          "Ön işleme: Gaussian blur - Threshold",
          "Ön işleme: Kontur bulma - görüntüyü kırpma",
          "Ön işleme: CLAHE",
          "Ön işleme: Median Blur",
          "CLAHE-Median Blur araştırma",
          "Ön işleme kodlarını toplama",
          "Sınıflandırma verisi ön işleme",
          "Test-Eğitim verisi ayırma - Veri çoğaltma (Keras Data Augmentation)",
          "(Teorik) Transfer Learning nedir?",
          "EfficientNet B5 ile Transfer Learning - 1",
          "Multi-label vs. Multi-class Sınıflandırma",
          "Multi-label araştırma",
          "EfficientNet B5 ile Transfer Learning - 2",
          "DR ve Yapay Zeka"
        ],
        "Optik Koherens Tomografiyle (OCT) Hastalık Teşhisi (Sınıflandırma) (Yükleniyor)": [
          "OCT nedir, veri seti",
          "Kurs Kodu",
          "Görüntüleri aktarma - flow_from_directory()",
          "Model oluşturma ve eğitim (Transfer learning)",
          "İkinci model",
          "Doğruluk(Accuracy) ve Kayıp(Loss) grafiği",
          "Veriler için for döngüsü",
          "Hata Matrisi(Confusion Matrix)",
          "ROC Eğrisi",
          "Oklüzyon(Kapatma) Tabanlı Isı Haritası (Occlusion Sensitivity)",
          "Oklüzyon(Kapatma) - Kod 1",
          "Oklüzyon(Kapatma) - Kod 2",
          "Oklüzyon(Kapatma) - Kod 3"
        ],
        "Beyin Tümörü Segmentasynu (U-Net , BraTS)": [
          "Kurs planı",
          "U-Net Nedir?",
          "Veri seti",
          "Veri gözlemi ve ön işlemeye giriş",
          "Array formuna çevirme ve görselleştirme",
          "Eğitim(Train) verileri için definasyon",
          "Segmentasyon görüntülerini inceleme",
          "Segmentasyon görüntüleri için definasyon hazırlama",
          "Modeli oluşturma ve eğitme",
          "Modelle tümör tahmini",
          "Tümör kırpma",
          "Kırpma için definasyon",
          "Kırpılan görüntüler için for döngüsü",
          "Kırpılan görüntülerle model eğitimi",
          "Orijinal kırpma definiasyonu",
          "Son model",
          "Tahminleri birleştirip karşılaştırma",
          "Sonuçları görselleştirme"
        ],
        "(OPSİYONEL) Numpy": [
          "#1 Numpy array oluşturma",
          "# 2 Nupmy array özellikleri",
          "# 3 Boyut özellikleri",
          "# 4 Array birleştirme (Stack)",
          "# 5 Array Ayırma (Split)",
          "# 6 Sıralama işlemleri",
          "# 7 Index işlemleri"
        ]
      },
      "requirements": [
        "Numpy, Seaborn, Pandas, Matplotlib gibi veri bilimi kütüphaneleri hakkında en az orta düzey bilgi",
        "Keras, Tensorflow kütüphanelerinde en az CNN yazabilme",
        "Genel olarak makine öğrenmesi optimizasyonu nasıl yapılır",
        "Pythonda modül, loop, fonksiyon kullanımını"
      ],
      "description": "İleri seviye Derin Öğrenme kursu ile hem Residual Networks, Transfer Learning, Autoencoders ve Generative Adversarial Networks konularının mantığını hem de Python kütüphanelerinden olan Pytorch ve Keras ile kodlamasını öğreneceğiz.\nNeden Python?\nPython 2018 IEEE araştırmasına göre dünya çapında en çok kullanılan ve tercih edilen programlama dili.\nPython kolay öğrenilebilirliği sayesinde kodlamaya yeni başlayanların ilk tercihi oluyor.\nPython open source (açık kaynak) olması nedeni ile Facebook yada Google gibi dünyanın en büyük şirketleri tarafından destekleniyor.\nVeri bilimi, makine öğrenmesi yada yapay zeka denince akla ilk olarak Python dili geliyor. Bu durumda Python'ın dünya çapında büyük bir kitlesinin olmasına neden oluyor.\nPython öğrenmesi en kolay olan dillerin başında geliyor.\nKariyer açısından Python en çok fırsata sahip dillerinden biri.",
      "target_audience": [
        "veri bilimine meraklı",
        "python geliştirmeciler",
        "sağlıkçılar",
        "radyolojistler",
        "doktorlar",
        "yazılımcılar"
      ]
    },
    {
      "title": "Streamlit : Déployer son app de Machine Learning sur le web",
      "url": "https://www.udemy.com/course/streamlit-deployer-son-app-de-machine-learning-sur-le-web/",
      "bio": "Créez rapidement une superbe application web et déployez votre modèle d’IA dans le monde entier avec Python !",
      "objectives": [
        "Savoir utiliser Streamlit",
        "Développer et déployer son application Data afin de partager ses modèles de Machine Learning sur le web",
        "Scrapper de la Data en temps réel grâce à une API (Yahoo Finance)",
        "Utilisation de Streamlit Cloud",
        "Créer des visuels attrayants avec les librairies interactives de Python",
        "Créer une interface utilisateur attractive (UI / UX)",
        "Structurer son programme Python pour du développement web",
        "Savoir optimiser une application Streamlit (Cache / Session / Form...)",
        "Utilisation de Git et Github",
        "Surpasser le Jupyter Notebook et donner vie à son projet Data"
      ],
      "course_content": {
        "Introduction": [
          "Message de bienvenue !",
          "Présentation de la formation",
          "Qu'est ce que Streamlit ?",
          "Ce que vous apprendrez dans ce cours",
          "Quizz initial"
        ],
        "Préparation de son environnement de travail": [
          "Installation + téléchargement du répertoire Github",
          "Présentation du code",
          "Installation de l'environnement virtuel"
        ],
        "Les fondations de Streamlit": [
          "Présentation",
          "Exercice partie 1 - les fondamentaux de Streamlit",
          "Exercice partie 2 - les fondamentaux de Streamlit",
          "Projet final partie 1 - les fondamentaux"
        ],
        "Interaction avec l'utilisateur (UI / UX)": [
          "Présentation",
          "Exercice Partie 1 - Interaction",
          "Exercice Partie 2 - Interaction",
          "Projet Partie 1 - Interaction",
          "Projet Partie 2 - Interaction"
        ],
        "Visualisation avec Streamlit": [
          "Présentation",
          "Exercices - visualisation",
          "Projet - visualisation"
        ],
        "Features avancées": [
          "Présentation",
          "Form",
          "Session",
          "Cache"
        ],
        "Déploiement de son application sur le web": [
          "Streamlit Cloud"
        ],
        "Conclusion": [
          "Conclusion"
        ]
      },
      "requirements": [
        "Une connaissance élémentaire du language de programmation Python est requise pour mieux comprendre les concepts abordés dans cette formation. De simples connaissances suffisent.",
        "Aucune compétence en développement web et/ou en data engineering n'est nécessaire. L'ensemble des concepts sont abordés depuis le début.",
        "Aucune expérience dans le cloud n'est requise. Vous apprendrez tout ce qu'il est utile de savoir pour la partie déploiement / mise en production."
      ],
      "description": "Avez-vous déjà ressenti la frustration d'avoir développé un super modèle de Machine Learning sur votre Jupyter Notebook et de ne jamais pouvoir le confronter à une utilisation réelle ?\n\n\nC'est la proposition de valeur de Streamlit et de cette formation:\nPouvoir déployer votre projet Data sur le web afin que le monde entier puisse l'utiliser grâce à votre propre application web !\n\n\nAinsi, l'ensemble de vos projets Data vont prendre vie !\n\n\nVous allez ainsi pouvoir :\nPartagez votre superbe classificateur d'images afin que d'autres personnes puissent utiliser votre modèle en y téléchargeant leurs propres images.\nDéployez en temps réel le score de sentiment des derniers tweets d'Elon Musk avec du NLP.\nOu encore réaliser des dashboards interactifs à destination de vos équipes en entreprise avec un système d'authentification pour restreindre l'accès à seulement quelques personnes.\n\n\nJ'ai développé ce cours après que des dizaines de personnes m'aient contacté pour me demander comment j'avais fait pour développer une application web de réservation de trains en temps réel, utilisée par plus de 10 000 personnes. Car oui on peut utiliser streamlit pour tous types d'applications et non seulement des applications data / IA !\n\n\nBref, des centaines de cas d'usage sont possibles avec streamlit !\nCe qui est formidable dans tout ça, c'est qu'il suffit uniquement d'avoir des connaissances en Python.\nEt qu'aucune compétence en Développement web, en Data Engineering ou même en cloud n'est nécessaire.\n\n\nCe cours est scindé en 2 parties :\nUne partie exercice où nous verrons l'ensemble des fondamentaux de Streamlit, depuis la connection à un système de base de donnée, en passant par la création de l'interface puis finalement la partie sur le déploiement dans le cloud !\nUne seconde partie destinée au projet de formation : Développement et mise en production d'une application de tracking et d'analyse des actions du S&P5O0 avec notamment la visualisation de l'évolution du cours des actions et le calcul d'indicateurs de performances. Les données seront requêtées via une API.\nFaites passer vos projets data à l'étape supérieure avec Streamlit !\n\n\nBonne formation :)",
      "target_audience": [
        "Des personnes s'intéressant à la Data et à Python mais qui sont frustrés de ne jamais pouvoir partager leurs modèles de Machine Learning autour d'eux !",
        "Des Data Scientist en entreprise qui souhaitent partager leurs travaux de Machine Learning ou des dashboards en interne pour leurs collaborateurs.",
        "Une personne qui a une idée de projet d'application web et qui souhaite développer un MVP en quelques heures !",
        "Tous bons Data Sientists !"
      ]
    },
    {
      "title": "Masterclass - Visualização de Dados | Especial Eleições",
      "url": "https://www.udemy.com/course/masterclass-visualizacao-de-dados-especial-eleicoes/",
      "bio": "Treinamento focado em dados de eleições do Brasil",
      "objectives": [
        "Visualização de Dados",
        "Análises gráficas",
        "Framework Matplotlib",
        "Framework Seaborn",
        "Framework Plotly",
        "Framework Pandas",
        "Manipular dados de eleições"
      ],
      "course_content": {
        "Introdução": [
          "Apresentação do curso",
          "Aviso"
        ],
        "Análise Macro das Eleições": [
          "#01 - Importação dos Dados",
          "#02 - Estruturando as análises",
          "#03 - Análise dos Prefeitos eleitos 01",
          "#04 - Análise dos Prefeitos eleitos 02",
          "#05 - Análise dos Prefeitos eleitos 03",
          "#06 - Análise dos Vereadores eleitos 01",
          "#07 - Análise correlação dos eleitos 01",
          "#08 - Análise correlação dos eleitos 02",
          "#09 - Análise Tridimensional 01",
          "#10 - Análise Tridimensional 02",
          "#11 - Análise Tridimensional 03"
        ]
      },
      "requirements": [
        "Python básico"
      ],
      "description": "Eleições acontecem no mundo inteiro, exceto países não democráticos. E esse processo gera muitas informações, como quantidade de eleitos, quantidade de votos, ausentes e muitas outras informações.\nEsse Masterclass tem como objetivo analisar esses dados e retirar insights sobre esse processo.\nVamos analisar os dados das eleições de 2020, na qual era ano eleitoral para prefeituras.\nNesse Masterclass vamos focar em gerar análises gráficas que realmente encantam o usuário e mais do que isso, gerar valor para estratégias em partidos políticos.\n\n\nProgramação é uma disciplina totalmente prática, de forma que, apenas a leitura de livros e/ou acompanhamento de vídeos não desenvolve todas as habilidades necessárias.\nA demanda por programadores Python nunca esteve tão alta, afinal, Python é uma das linguagens mais utilizadas no mundo e requisito para se trabalhar com Ciência de Dados e Inteligência Artificial. Inclusive, podemos considerar Python como uma linguagem padrão para esta análise de dados, tendo em vista seu amplo ecossistema de bibliotecas, que englobam desde a manipulação e tratamento de dados até mesmo o deploy de modelos. Não podemos esquecer, neste sentido, que o Python é uma linguagem de aplicação geral.\nPor ser uma linguagem de programação versátil, simples de aprender e muito poderosa, Python possui recursos que, apesar de simples de se utilizar, tornam o aprendizado muito divertido.\n\n\nCaso tenha ficado interessado, seja bem vindo!!!",
      "target_audience": [
        "Desenvolvedores iniciantes em Python, Cientistas de Dados ou qualquer pessoa que queira usar Python para analisar dados."
      ]
    },
    {
      "title": "Guida al text mining e alla sentiment analysis con R",
      "url": "https://www.udemy.com/course/text-mining-e-sentiment-analysis-con-r/",
      "bio": "Una guida al text mining e alla sentiment analysis con R in lingua italiana",
      "objectives": [
        "Analizzare e trattare testi tramite le funzioni base e tm",
        "Standardizzare un testo",
        "Applicare procedure supervisionate e non supervisionate a corpus di documenti",
        "Estrarre e analizzare tweet",
        "Utilizzare varie stringhe e pacchetti per la gestione dei testi in R",
        "Creare word cloud e rappresentazioni grafiche di documenti",
        "Analizzare il sentiment di un testo con metodi supervisionati e non",
        "Effettuare alcune analisi qualitative con RQDA"
      ],
      "course_content": {
        "Introduzione al corso": [
          "Come ottenere il rimborso del corso in caso di problemi",
          "CODICE"
        ],
        "Basi di R": [
          "Installare R",
          "Installare RStudio",
          "Personalizzare e utilizzare RStudio",
          "Utilizzare altri IDE",
          "R: pro e contro",
          "Commentare il codice",
          "Operazioni matematiche di base",
          "Creazione di oggetti",
          "Le parentesi",
          "Tipi di variabili in statistica",
          "Le strutture dati in R",
          "Vettori",
          "Matrici",
          "Array",
          "Liste",
          "Fattori",
          "Dataframe",
          "Date",
          "Convertire le strutture dati",
          "R base versus tidyverse",
          "Operatori relazionali",
          "Files csv",
          "Files Excel",
          "Files txt",
          "Subsetting",
          "La famiglia apply",
          "Manipolazione dati con dplyr",
          "Altri pacchetti per la manipolazione dati",
          "Unire due dataset"
        ],
        "Le basi del text mining": [
          "Introduzione al text mining",
          "Utilizzi dell'analisi del linguaggio",
          "Strutture dati per l'analisi testi",
          "I problemi nel trattamento del linguaggio",
          "Le fasi dell'analisi testi"
        ],
        "Gestire le stringhe": [
          "Le librerie per il trattamento del linguaggio con R",
          "Gestione delle stringhe con R",
          "Codice per la gestione delle stringhe in R",
          "Codice per la gestione delle stringhe in R / seconda parte",
          "Le espressioni regolari"
        ],
        "Importazione dati": [
          "Formati dati e fonti comuni nel text mining"
        ],
        "Text mining con R base": [
          "Introduzione al text mining con R base",
          "Codice per l’analisi di testi tramite le funzioni base",
          "Codice per l’importazione e analisi di un corpus"
        ],
        "Text mining con tm": [
          "Il pacchetto tm",
          "Importazione dati",
          "Pulizia e analisi del testo con tm",
          "Importazione di un corpus di documenti",
          "Analisi di base di un corpus",
          "Creare le matrici"
        ],
        "Machine learning supervisionato sui testi": [
          "L'uso del machine learning per l'analisi dei testi",
          "Metodi supervisionati",
          "Metodi di regressione",
          "La regressione logistica",
          "Codice per la regressione logistica sui testi con R",
          "Probabilità e metodi bayesiani",
          "Codice per il Naive Bayes sullo spam",
          "Decision Trees",
          "Codice per gli alberi di decisione"
        ],
        "Machine learning non supervisionato sui testi": [
          "Metodi non supervisionati",
          "Clustering",
          "Codice per il clustering sui testi",
          "LDA e topic models",
          "Codice per i topic models con R"
        ],
        "Social Media Mining e analisi sui testi": [
          "Creazione di un account Twitter per sviluppatori",
          "Il pacchetto rtweet",
          "Analisi sui tweet con il pacchetto tm"
        ]
      },
      "requirements": [
        "Nozioni introduttive su R"
      ],
      "description": "Questo corso è dedicato a chi si avvicina al mondo del text mining e della sentiment analysis per la prima volta, pur avendo delle basi di programmazione e analisi dati con R. Non si tratta di un corso divulgativo generico sul text mining e sulla sentiment analysis, ma di un corso che vuole spiegare le basi dell'analisi dei testi tramite il linguaggio di programmazione R.\nSe non sai ancora programmare con R, purtroppo questo corso non è quello giusto per te, ma puoi dare un'occhiata al mio corso base.\nSe invece stai cercando esempi e casi per capire in maniera semplice le tecniche base per effettuare un'analisi di text mining o scoprire il sentiment dei tuoi testi con R, sei nel posto giusto. R è uno dei linguaggi di programmazione più diffusi quando si parla di analisi dati, e comprende una serie di pacchetti e funzioni che possono aiutarci sia nel text mining descrittivo che nel text mining predittivo.\n\nIl text mining descrittivo \"descrive\" un testo a partire dalle parole che lo compongono, mentre il text mining predittivo utilizza le caratteristiche di un gruppo di testi per effettuare delle predizioni, ad esempio se un'email è spam o no, oppure se un testo è stato scritto o meno da un autore, oppure, per tornare alla sentiment analysis, se un commento è positivo o negativo.\nPer prima cosa partiamo capendo come mai il text mining e la sentiment analysis sono tanto importante, e quali sono gli usi che se ne fanno, e le lingue più analizzate (spoiler: c'è anche l'italiano).\nAnalizzare un testo non è come analizzare un dataset: il testo va prima trasformato in qualcosa che il computer possa capire: imparerai quindi le tecniche più importanti per sintetizzare un testo, preprocessarlo, normalizzarlo e rappresentarlo.\nImparerai poi a importare un documento o un corpus in R, preprocessarlo e analizzarlo, creando anche delle rappresentazioni grafiche.\nOltre al pacchetto base ci sono molti pacchetti per il text mining: il più importante per le analisi di base è di sicuro tm.\nUna volta chiarite queste parti introduttive, ci dedichiamo alle tecniche di machine learning applicate al text mining, che ci permettono a partire da un corpus o da un testo, di effettuare delle predizioni.\nUno degli strumenti per l'analisi più interessante è Twitter: in questo corso imparerai a estrarre dei tweet e ad analizzarli. Oltre ai pacchetti per il trattamento testi, come tm, e per l'estrazione dati, esistono ancora moltissimi pacchetti per il text mining che imparerai a utilizzare con questo corso, non solo per il text mining ma anche per la sentiment analysis. Vedremo quindi, dato un testo, come predire in maniera automatica tramite varie tecniche di machine learning, se il testo è positivo o negativo, tramite metodi supervisionati e non supervisionati.\nIl corso si chiude con una parte sulla rappresentazione grafica dei testi e alcuni cenni sui metodi di analisi qualitativa CAQDAS.\n\n\n***Attenzione, questo corso al momento non comprende una parte relativa agli esercizi, che sarà aggiunta a breve con modalità che saranno chiarite nella Bonus Section",
      "target_audience": [
        "Studenti con almeno alcune nozioni introduttive su R"
      ]
    },
    {
      "title": "(IIBA-CBAP) Certified Business Analysis Course.",
      "url": "https://www.udemy.com/course/iiba_cbap-preparation-course-arabic-english/",
      "bio": "دورة تحليل الأعمال الأحترافية المستوى الثالث.",
      "objectives": [
        "To help you Pass the IIBA-CBAP exam .",
        "To Understand the key concepts of business analysis.",
        "To Understand the business analysis core concept model .",
        "To Guide practices related to 30 business analysis tasks in six knowledge areas .",
        "To Understand 50 business analysis tools and techniques.",
        "To Understand the five business analysis perspectives: Agile, Business Intelligence.",
        "To Understand the Information Technology, Business Architecture, and Business Process Management."
      ],
      "course_content": {
        "Course introduction +المادة العمية": [
          "CBAP Course Introduction 2024",
          "Study plan مرفق المواد العلمية"
        ],
        "1- Introduction.": [
          "Introduction.",
          "Introduction Quiz"
        ],
        "2- Business analysis key concepts.": [
          "Key concepts Part one",
          "Key Concepts Part two",
          "Business analysis key concepts."
        ],
        "6- Strategy analysis .": [
          "Strategy analysis Overview",
          "1- Current state part one",
          "1-Analyze Current state Part Two",
          "2-Define Future part one",
          "2-Define Future State Part Two",
          "3-Assess Risks",
          "4-Change Strategy Part one",
          "4-Change Strategy Part Two",
          "4-Change Strategy Part Three",
          "Strategy analysis Quiz"
        ],
        "3- Business analysis planning and Monitoring": [
          "BA Planning introduction",
          "1 - Plan BA Approach part one .",
          "1-Plan BA Approach Part Two",
          "2-Plan Stakeholders Approach part one",
          "2-Plan Stakeholders Approach part two",
          "3-Plan BA Governance Part one",
          "3-Plan BA Governance Part two",
          "4-Plan BA information Approach",
          "5-Identify Business Analysis Performance Improvements.",
          "Business analysis planning and Monitoring"
        ],
        "4- Elicitation and Collaboration.": [
          "Elicitation and Collaboration introduction",
          "1-Prepare for Elicitation",
          "2-Conduct Elicitation",
          "3-Confirm Elicitation results",
          "4- Communicate Business Analysis Information",
          "5 -Manage Stakeholder Collaboration.",
          "Elicitation and Collaboration."
        ],
        "7- Requirements analysis and design definition": [
          "Requirements analysis and design definition introduction",
          "1-Specify and Model Requirements",
          "2- Verify Requirements",
          "3- Validate Requirements.",
          "4- Define Requirements Architecture",
          "5- Define Design Options",
          "6- Analyze Potential Value and Recommend Solution.",
          "5-User stories",
          "Requirements Analysis and Design Definition Quiz."
        ],
        "5- Requirement life cycle management .": [
          "Requirements life cycle introduction",
          "1- Trace Requirements",
          "2- Maintain Requirements",
          "3-Prioritize Requirements",
          "4-Assess Requirements Changes",
          "5 Approve Requirements.",
          "6-Business rule analysis",
          "13-Prioritization",
          "Requirement life cycle management."
        ],
        "8- Solution Evaluation .": [
          "Solution Evaluation introduction",
          "1- Measure Solution Performance",
          "2- Analyze Solution Measures",
          "3 Assess Solution Limitations",
          "4- Assess Enterprise Limitations",
          "5 - Recommend Actions to Increase Solution Value.",
          "Solution Evaluation"
        ],
        "9- Underlying Competencies.": [
          "1- Underlying competencies overview",
          "2-Analytical thinking and Problem solving",
          "3- Behavioral Characteristics",
          "4-Business Knowledge.",
          "5-Communication Skills",
          "6-Interaction Skills",
          "7-Tools and Technology",
          "Underlying Competencies."
        ]
      },
      "requirements": [
        "An experience in business analysis( 5 years )",
        "High school degree ."
      ],
      "description": "IIBA_CBAP (Business analysis course)\n· This CBAP certification training helps you to master the highest skills of business analysis including advanced documentation, effective planning, and the design of business solutions. Covering the core concept model of business analysis and the six knowledge areas of the BABOK® Guide Version 3, this course prepares you to ace the IIBA-CBAP exam.\nWho can attend this course?\nBusiness analysts.\nBusiness development mangers.\nProject managers.\nTechnical offices team.\nPortfolio managers.\nBusiness persons.\nProgram managers.\nFinance Managers.\nAccounting.\nMedicine team members.\nIT Specialists.\nPlanners\nCost estimator.\n\n\nWhat are the objectives of this course?\nPass the IIBA-CBAP exam .\nUnderstand the key concepts of business analysis\nUnderstand the business analysis core concept model .\nGuide practices related to 30 business analysis tasks in six knowledge areas .\nUnderstand 50 business analysis tools and techniques.\nUnderstand the five business analysis perspectives: Agile, Business Intelligence, Information Technology, Business Architecture, and Business Process Management.\n\n\nWhat will you learn?\nThe knowledge and skills required to be an effective and result-oriented business analyst.\nThe principles and practices of business analysis.\nTo demonstrate your continued dedication to the profession through recertification requirements.\nTo make your competence known and recognized by peers and management.\nTo follow established standards that are outlined in the Business Analysis Body of Knowledge (BABOK®) version 3.0\nTo achieve reliable, quality results with enhanced efficiency and consistency.\nDevelop the following proficiencies that are the measurement criteria for the competencies required to attain CBAP® Level 3:\nAdvanced Knowledge - Skills and Knowledge have been fully developed through execution of work ranging from small well scoped work to addressing more complex, unstructured challenges or opportunities. Skills and knowledge required for the competency have become second nature.\nGuides Practice - This is a seasoned practitioner that is sought after for their expertise and guidance in solving or addressing business challenges or opportunities.\nCreates Rules - Actively provides insight to situations that fall within and outside of his/her domain or sphere of influence. In some cases, this will mean addressing new, unstructured business challenges or opportunities.\n\n\n\n\nUnit 1:- Introduction to IIBA CBAP® version 3.0 Certification Program\n· Introduction to IIBA® CBAP Certification Program\n· Purpose of the BABOK® v 3.0 Guide\n· What is Business Analysis?\n· Who is a Business Analyst\n· Structure of the BABOK® v 3.0 Guide\nUnit 2:- Business Analysis Key Concepts\n· The Business Analysis Core Concept Model .\n· Key Terms.\n· Requirements Classification Schema.\n· Stakeholders.\n· Requirements and Design.\nUnit 3:- Business Analysis Planning and Monitoring\n· Overview of Business Analysis Planning and Monitoring .\n· Core Concept Model in Business Analysis Planning and Monitoring.\n· Plan Business Analysis Approach.\n· Plan Stakeholder Engagement.\n· Plan Business Analysis Governance.\n· Plan Business Analysis Information Management .\n· Identify Business Analysis Performance Improvements.\n\n\nUnit 4:- Elicitation and Collaboration\n· Overview of Elicitation and Collaboration\n· Core Concept Model in Elicitation and Collaboration\n· Prepare for Elicitation\n· Conduct Elicitation\n· Confirm Elicitation Results\n· Communicate Business Analysis Information\n· Manage Stakeholder Collaboration\n\n\nUnit 5:- Requirements Lifecycle Management\n· Overview of Requirements Lifecycle Management\n· Core Concept Model in Requirements Lifecycle Management\n· Trace Requirements\n· Maintain Requirements\n· Prioritize Requirements\n· Assess Requirements Changes\n· Approve Requirements\n\n\nUnit 6:- Strategy Analysis\n· Overview of Strategy Analysis\n· Core Concept Model in Strategy Analysis\n· Analyze Current State\n· Define Future State\n· Assess Risks\n· Define Change Strategy\nUnit 7:- Requirements Analysis and Design Definition\n· Overview of Requirements Analysis and Design Definition\n· Core Concept Model in Requirements Analysis and Design Definition\n· Specify and Model Requirements\n· Verify Requirements\n· Validate Requirements\n· Define Requirements Architecture\n· Define Design Options\n· Analyze Potential Value and Recommend Solution\nUnit 8:- Solution Evaluation\n· Overview of Solution Evaluation\n· Core Concept Model in Solution Evaluation\n· Measure Solution Performance\n· Analyze Performance Measures\n· Assess Solution Limitations\n· Assess Enterprise Limitations\n· Recommend Actions to Increase Solution Value\nUnit 9:- Underlying Competencies\n· Overview of Underlying Competencies\n· Analytical Thinking and Problem Solving\n· Behavioral Characteristics\n· Business Knowledge\n· Communication Skills\n· Interaction Skills\n· Tools and Technology.\n\n\nUnit 10:- Techniques\n· Acceptance and Evaluation Criteria\n· Backlog Management\n· Balanced Scorecard\n· Benchmarking and Market Analysis\n· Brainstorming\n· Business Capability Analysis\n· Business Cases\n· Business Model Canvas\n· Business Rules Analysis\n· Collaborative Games\n· Concept Modelling\n· Data Dictionary\n· Data Flow Diagrams\n· Data Mining\n· Data Modelling\n· Decision Analysis\n· Decision Modelling\n· Document Analysis\n· Estimation\n· Financial Analysis\n· Focus Groups\n· Functional Decomposition\n· Glossary\n· Interface Analysis\n· Interviews\n· Item Tracking\n· Lessons Learned\n· Metrics and Key Performance Indicators\n· Mind Mapping\n· Non-Functional Requirements Analysis\n· Observation\n· Organizational Modelling\n· Prioritization\n· Process Analysis\n· Process Modelling\n· Prototyping\n· Reviews\n· Risk Analysis and Management\n· Roles and Permissions Management\n· Root Cause Analysis\n· Scope Modelling\n· Sequence Diagrams\n· Stakeholder List, Map or Personas\n· State Modelling\n· Survey or Questionnaire\n· SWOT Analysis\n· Use Cases and Scenarios\n· User Stories\n· Vendor Assessment\n· Workshops\nUnit 11:- Perspectives\n· Overview of Perspectives\n· Agile\n· Business Intelligence\n· Information Technology\n· Business Architecture\n· Business Process Management.\n\n\n\n\n\n\nNB. Copying the course contents is NOT permitted for any educational or commercial purpose.\nNB. Copying the course contents is NOT permitted for any educational or commercial\nCourse ID : 3582249\nCourse Certificate: Get an Udemy certificate by completing the entire course.",
      "target_audience": [
        "Business analysts.",
        "Business development mangers.",
        "Project managers.",
        "Technical offices team.",
        "Portfolio managers.",
        "Business persons.",
        "Program managers.",
        "Finance Managers.",
        "Accounting.",
        "Medicine team members.",
        "IT Specialists.",
        "IIBA - ECBA Holders.",
        "IIBA - CCBA Holders."
      ]
    },
    {
      "title": "Inteligência Artificial com PHP-ML",
      "url": "https://www.udemy.com/course/inteligencia-artificial-com-php-ml/",
      "bio": "Inteligência Artificial com a Linguagem de Programação PHP e a Biblioteca PHP-ML",
      "objectives": [
        "Inteligência Artificial, Machine Learning, Deep Learning, Matemática e Estatística com PHP-ML",
        "Associação, Classificação, Regressão, Clusterização, Análise de Dados, Matemática e Estatística"
      ],
      "course_content": {
        "Introdução ao Curso": [
          "01-Apresentação do Curso de Inteligência Artificial com PHP-ML",
          "02-Introdução a Biblioteca PHP-ML"
        ],
        "Análise Associativa (Associação)": [
          "01-Instalação da Biblioteca de Inteligência Artificial PHP-ML",
          "02-Construindo e Executando um Algoritmo de Associação com o PHP-ML",
          "03-Apriori com Um e com Múltiplos Elementos como Resposta",
          "04-Apriori com Múltiplas Classes na Passagem de Parâmetros"
        ],
        "Análise Classificativa (Classificação)": [
          "01-Classificação com Support Vector Machine",
          "02-Classificação com o SVM (SVC) de Múltiplos Valores na Predição",
          "03-Classificação com o K-Nearest Neighbors",
          "04-Classificação com o KNN Utilizando Mais Exemplos de Amostra",
          "05-Classificação com o Naive Bayes"
        ],
        "Análise Regressiva (Regressão)": [
          "01-Utilizando os Mínimos Quadrados no Reconhecimento de Padrões",
          "02-Aplicando a Regressão em uma Distribuição Desordenada",
          "03-Caso de Uso da Regressão no Reconhecimento de Padrões em Dados Desordenados"
        ],
        "Clusterização (Agrupamento)": [
          "01-Agrupamento com o Algoritmo K-Means",
          "02-K-Means com Mais de Dois Grupos de Clusterização",
          "03-Agrupamento com o Algoritmo DBSCAN",
          "04-Eliminando Grupos Vazios no DBSCAN como no K-Means"
        ],
        "Análise Métrica (Métricas)": [
          "01-Calculando a Acurácia na Comparação de Dois Vetores",
          "02-Tirando a Métrica com a Matriz de Confusão",
          "03-Matriz de Confusão com Valores Texto",
          "04-Tirando Métricas com o Relatório de Classificação"
        ],
        "Estruturação com Pipeline": [
          "01-Executando dois Algoritmos Diferentes com o Pipeline",
          "02-Otimizando o Algoritmo Pipeline"
        ],
        "Redes Neurais Artificiais (Perceptron)": [
          "01-Construindo e Executando uma Rede Neural Aritifical Perceptron",
          "02-Ensinando as Operações Lógicas para a Rede Perceptron",
          "03-Múltiplas Entradas na Rede Neural Artificial Perceptron",
          "04-Trabalhando com Classes String na Rede Neural",
          "05-Configurando as Interações da Rede Neural Perceptron",
          "06-Configurando a Taxa de Aprendizagem da Rede Neural Perceptron",
          "07-Configurando as Funções de Ativação da Rede Neural Perceptron",
          "08-Configurando a Estrutura da Camada Oculta da Rede"
        ],
        "Cross Validation (Validação Cruzada)": [
          "01-Construindo uma Validação Cruzada (Cross Validation) com RandomSplit",
          "02-Construindo uma Validação Cruzada (Cross Validation) com StratifiedRandomSpli"
        ],
        "Seleção de Recursos": [
          "01-Feature Selection com Variance Threshold",
          "02-Feature Selection com Select K Best"
        ]
      },
      "requirements": [
        "Conhecimentos Básicos em PHP"
      ],
      "description": "Se você é um desenvolvedor WEB PHP e não sabe como entrar no mundo da Inteligência Artificial este curso é pra você. Tenha esse diferencial no seu currículo e domine uma habilidade que poucos desenvolvedores dominam no mercado. Desenvolva algoritmos de Machine Learning e Deep Learning utilizando a linguagem que você está acostumado a trabalhar e embarque nesse fantástico mundo da Inteligência Artificial.",
      "target_audience": [
        "Desenvolvedores iniciantes ou experientes que queiram aprender Inteligência Artificial com PHP"
      ]
    },
    {
      "title": "Processamento de Linguagem Natural com BERT e Python",
      "url": "https://www.udemy.com/course/bert-python-processamento-linguagem-natural/",
      "bio": "Aplique o algoritmo revolucionário de PLN e Deep Learning do Google para tarefas do mundo real! Crie um sistema de Q&A",
      "objectives": [
        "Crie um sistema de perguntas e respostas (Q&A) que pode ser utilizado em fóruns de pesquisas",
        "Ligue o BERT à uma Rede Neural Convolucional especializada em Processamento de Linguagem Natural para classificação de sentimentos",
        "Entenda a história do BERT e por que ele mudou a área de Processamento de Linguagem Natural (PLN)",
        "Use as ferramentas de tokenização fornecidas com o BERT para pré-processar textos com eficiência",
        "Use a camada BERT como incorporação para conectá-la ao seu próprio modelo de Processamento de Linguagem Natural (PLN)",
        "Use o BERT como um modelo pré-treinado e depois ajuste-o para obter melhores resultados",
        "Obtenha modelos disponíveis no Tensorflow Hub, a plataforma onde você pode obter modelos já treinados",
        "Use o Google Colab e o Tensorflow 2.0 para suas implementações de IA"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Recursos para download"
        ],
        "Teoria sobre o BERT": [
          "O que é BERT",
          "Camada de embeddings",
          "Ideia geral da arquitetura BERT",
          "Redes neurais recorrentes para PLN",
          "Arquitetura Transformer",
          "Transformer: mecanismo de atenção 1",
          "Transformer: mecanismo de atenção 2",
          "Transformer: mais detalhes",
          "Arquitetura BERT",
          "Pré-treinamento BERT",
          "Revisão da teoria"
        ],
        "BERT como tokenizador: classificação de sentimentos": [
          "Introdução a redes neurais convolucionais",
          "Redes neurais convolucionais para texto",
          "Importação das bibliotecas",
          "Carregamento dos arquivos",
          "Limpeza dos textos",
          "Tokenização",
          "Criação da base de dados",
          "Criação do modelo",
          "Treinamento do modelo",
          "Avaliação do modelo"
        ],
        "BERT como embedding: classificação de sentimentos": [
          "Pré-processamento da base de dados",
          "Entradas para o BERT 1",
          "Entradas para o BERT 2",
          "Criação do modelo",
          "Treinamento e avaliação do modelo"
        ],
        "Aplicação de perguntas e respostas (Q&A) com BERT": [
          "Introdução e importação das bibliotecas",
          "Pré-processamento da base de dados",
          "Camada Squad",
          "Modelo completo",
          "Treinamento do modelo 1",
          "Treinamento do modelo 2",
          "Avaliação do modelo 1",
          "Avaliação do modelo 2",
          "Avaliação do modelo 3",
          "Pré-processamento dos textos",
          "Tokenização do contexto",
          "Criação das entradas para o modelo",
          "Previsões com textos 1",
          "Previsões com textos 2",
          "Material Complementar",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Básico da linguagem Python",
        "Orientação a objetos",
        "É desejável que você já tenha tido algum contato com a API Keras do TensorFlow"
      ],
      "description": "A área de Processamento de Linguagem Natural - PLN (Natural Language Processing - NLP) é uma subárea da Inteligência Artificial que tem como objetivo tornar os computadores capazes de entender a linguagem humana, tanto escrita quanto falada. Alguns exemplo de aplicações práticas são: tradutores entre idiomas, tradução de texto para fala ou fala para texto, chatbots, sistemas automáticos de perguntas e respostas, sumarização de textos, geração automática de descrições para imagens, adição de legendas em vídeos, classificação de sentimentos em frases, dentre várias outras!\nDentro do contexto de Processamento de Linguagem Natural, a arquitetura BERT (Bidirectional Encoder Representations from Transformers) tem ganhado muita atenção dos desenvolvedores e atualmente é considerada como o modelo de Machine Learning mais eficiente nessa área! Muitos pesquisadores a consideram como um marco na área de PLN, mudando um pouco o paradigma de como as aplicações são implementadas.\nAtualmente, o setor de Inteligência Artificial está cada vez mais necessitando de soluções de Processamento de Linguagem Natural, ou seja, aprender essa área juntamente com a arquitetura BERT pode ser a chave para trazer soluções reais para necessidades presentes e futuras. Baseado nisso, este curso foi projetado para quem deseja crescer ou iniciar uma nova carreira na área de Processamento de Linguagem Natural, obtendo uma sólida experiência nessa área utilizando modernas técnicas de Deep Learning e Redes Neurais Artificiais!\nAproveitaremos a enorme quantidade de dados de texto disponíveis on-line (duas bases de dados reais) e exploraremos duas das principais técnicas de PLN, o que lhe dará o poder necessário para enfrentar com êxito qualquer desafio do mundo real! Além de aprender a teoria, você também desenvolverá três estudos de caso:\nCriação de um classificador de sentimentos utilizando dados do Twitter e a integração de um tokenizador BERT com Redes Neurais Convolucionais\nO segundo estudo de caso é semelhante ao primeiro, porém, utilizaremos a camada de embedding do BERT para integração com uma Rede Neural Convolucional para classificar sentimentos\nCriação de um sistema de perguntas e respostas (Q&A - Questions and Answers) utilizando o BERT! A ideia é fazer uma pergunta sobre um determinado texto e o algoritmo vai indicar onde está a resposta para a nossa pergunta, muito similar com o que ocorre nos fóruns de pesquisa\nUtilizaremos tecnologias modernas, como a linguagem Python, o TensorFlow 2.0 e o Google Colab, garantindo que você não tenha problemas com instalações ou configurações de softwares na sua máquina local.",
      "target_audience": [
        "Pessoas interessadas em deep learning (aprendizagem profunda)",
        "Pessoas interessadas em Processamento de Linguagem Natural",
        "Analistas de dados que queiram aumentar seu conhecimento na área de deep learning (aprendizagem profunda)",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial",
        "Qualquer pessoa que queira iniciar uma nova carreira e ter uma sólida experiência em PLN, adicionando estudos de casos eficientes ao seu portfólio"
      ]
    },
    {
      "title": "机器学习实训营（算法推导+代码复现）",
      "url": "https://www.udemy.com/course/tangyudi-ml/",
      "bio": "机器学习原理与代码复现",
      "objectives": [
        "掌握机器学习经典算法原理推导",
        "掌握机器学习算法代码复现方法（Python版）",
        "掌握机器学习算法复现流程与常规套路",
        "掌握机器学习中核心数学知识点",
        "熟练使用Python进行算法实验",
        "掌握线性回归算法原理与代码复现",
        "掌握逻辑回归算法原理与代码复现",
        "掌握神经网络算法原理与代码复现",
        "掌握聚类算法原理与代码复现",
        "掌握关联规则算法原理与代码复现",
        "掌握决策树算法原理与代码复现",
        "掌握降维算法原理与代码复现",
        "掌握贝叶斯算法原理与代码复现",
        "掌握word2vec算法原理与代码复现",
        "掌握推荐系统算法原理与代码复现"
      ],
      "course_content": {
        "线性回归原理推导": [
          "回归问题概述",
          "误差项定义",
          "独立同分布的意义",
          "似然函数的作用",
          "参数求解",
          "梯度下降通俗解释",
          "参数更新方法",
          "优化参数设置",
          "课程数据代码下载（谷歌网盘）"
        ],
        "线性回归代码实现": [
          "线性回归整体模块概述",
          "初始化步骤",
          "实现梯度下降优化模块",
          "损失与预测模块",
          "数据与标签定义",
          "训练线性回归模型",
          "得到线性回归方程",
          "整体流程debug解读",
          "多特征回归模型",
          "非线性回归"
        ],
        "逻辑回归原理推导": [
          "逻辑回归算法原理",
          "化简与求解"
        ],
        "逻辑回归代码实现": [
          "多分类逻辑回归整体思路",
          "训练模块功能",
          "完成预测模块",
          "优化目标定义",
          "迭代优化参数",
          "梯度计算",
          "得出最终结果",
          "鸢尾花数据集多分类任务",
          "训练多分类模型",
          "准备测试数据",
          "决策边界绘制",
          "非线性决策边界"
        ],
        "聚类算法-Kmeans&Dbscan原理": [
          "KMEANS算法概述",
          "KMEANS工作流程",
          "KMEANS迭代可视化展示",
          "DBSCAN聚类算法",
          "DBSCAN工作流程",
          "DBSCAN可视化展示"
        ],
        "Kmeans代码实现": [
          "Kmeans算法模块概述",
          "计算得到簇中心点",
          "样本点归属划分",
          "算法迭代更新",
          "鸢尾花数据集聚类任务",
          "聚类效果展示"
        ],
        "决策树原理": [
          "决策树算法概述",
          "熵的作用",
          "信息增益原理",
          "决策树构造实例",
          "信息增益率与gini系数",
          "预剪枝方法",
          "后剪枝方法",
          "回归问题解决"
        ],
        "决策树代码实现": [
          "整体模块概述",
          "递归生成树节点",
          "整体框架逻辑",
          "熵值计算",
          "数据集切分",
          "完成树模型构建",
          "测试算法效果"
        ],
        "集成算法原理": [
          "随机森林算法原理",
          "随机森林优势与特征重要性指标",
          "提升算法概述",
          "stacking堆叠模型"
        ],
        "集成算法实例": [
          "集成算法实例概述",
          "ROC与AUC指标",
          "基础模型",
          "集成实例",
          "Stacking模型",
          "效果改进"
        ]
      },
      "requirements": [
        "熟悉Python语言",
        "有一定的大学数学基础，了解即可，课程风格通俗易懂"
      ],
      "description": "Python机器学习实训营（原理推导+代码复现）课程旨在帮助同学们在机器学习领域打下坚实基础。课程注重算法原理讲解与数学公式推导并基于Python语言给出完整的代码实现，从零开始实现每一模块功能（非调用工具包）通过代码实例演示算法工作流程与实现方法。整体风格通俗易懂，建议同学们在学习过程中先掌握算法原理，基于数学推导公式进行代码复现与实战演练。",
      "target_audience": [
        "人工智能方向的同学们",
        "准备加入机器学习方向的同学们"
      ]
    },
    {
      "title": "TensorFlow 2.0: 关于全新TensorFlow的完整指南",
      "url": "https://www.udemy.com/course/tensorflow-chinese/",
      "bio": "利用TensorFlow 2.0构建精彩的深度学习和人工智能应用（英语授课）",
      "objectives": [
        "如何在数据科学中使用Tensorflow 2.0",
        "Tensorflow 1.x和Tensorflow 2.0之间的重要差异",
        "如何在Tensorflow 2.0中实现人工神经网络",
        "如何在Tensorflow 2.0中实现卷积神经网络",
        "如何在Tensorflow 2.0中实现递归神经网络",
        "如何在Tensorflow 2.0中构建你自己的迁移学习应用",
        "如何通过强化学习（深度-Q网络）来构建股票市场交易机器人",
        "如何在Tensorflow 2.0中构造机器学习流水线",
        "如何通过TensorFlow Data Validation和TensorFlow Transform进行数据验证和数据集预处理",
        "将TensorFlow 2.0模型放入生产",
        "如何利用Flask和TensorFlow 2.0创造一个Fashion API",
        "如何通过RESTful API为TensorFlow模型提供服务"
      ],
      "course_content": {
        "引言": [
          "欢迎来到TensorFlow 2.0 课程! 了解课程结构和TF工具箱",
          "课程体系 & Colab工具箱"
        ],
        "TensorFlow 2.0 基础": [
          "从TensorFlow 1.x 到 TensorFlow 2.0",
          "常量, 变量, 张量",
          "张量运算",
          "字符串"
        ],
        "人工神经网络": [
          "项目设置",
          "数据预处理",
          "构建人工神经网络",
          "构建人工神经网络",
          "评估人工神经网络",
          "人工神经网络测验",
          "家庭作业: 人工神经网络",
          "家庭作业解答: 人工神经网络"
        ],
        "卷积神经网络": [
          "项目设置 & 数据预处理",
          "构建卷积神经网络",
          "训练和评估卷积神经网络",
          "卷积神经网络测验",
          "家庭作业: 卷积神经网络",
          "家庭作业解答: 卷积神经网络"
        ],
        "递归神经网络": [
          "项目设置 & 数据预处理",
          "构建递归神经网络",
          "训练和评估递归神经网络",
          "递归神经网络测验"
        ],
        "迁移学习和微调": [
          "什么是迁移学习?",
          "项目设置",
          "数据预处理",
          "加载 MobileNet V2 模型",
          "冻结预训练模型",
          "为预训练模型添加自定义头",
          "定义迁移学习模型",
          "编译迁移学习模型",
          "图像数据生成器",
          "迁移学习",
          "评估迁移学习结果",
          "微调模型定义",
          "编译微调模型",
          "微调",
          "评估微调结果",
          "迁移学习测验"
        ],
        "深度强化学习理论": [
          "什么是强化学习?",
          "贝尔曼方程",
          "马尔可夫决策过程 (MDP)",
          "Q-学习直觉力",
          "时间差分",
          "深度Q-学习直觉力 - 步骤 1",
          "深度Q-学习直觉力 - 步骤 2",
          "经验回放",
          "动作选择策略"
        ],
        "用于股票市场交易的深度强化学习": [
          "项目设置",
          "AI 交易员 - 步骤 1",
          "AI 交易员 - 步骤 2",
          "AI 交易员 - 步骤 3",
          "AI 交易员 - 步骤 4",
          "AI 交易员 - 步骤 5",
          "数据集加载模块函数",
          "状态创建模块函数",
          "加载数据集",
          "定义模型",
          "训练循环 - 步骤 1",
          "训练循环 - 步骤 2"
        ],
        "使用TensorFlow Data Validation (TFDV)进行数据验证": [
          "项目设置",
          "加载污染数据集",
          "创建数据集 Schema",
          "计算测试集统计信息",
          "使用TensorFlow Data Validation进行异常检测",
          "为生产准备 Schema",
          "保存 Schema",
          "下一步做什么? TEXT"
        ],
        "使用TensorFlow Transform (TFT)进行数据集预处理": [
          "项目设置",
          "初始数据集预处理",
          "数据集元数据",
          "预处理函数",
          "数据集预处理流水线",
          "下一步做什么? TEXT"
        ]
      },
      "requirements": [
        "一些数学基础，比如了解对差分、梯度有所了解",
        "Python基础"
      ],
      "description": "欢迎来到TensorFlow 2.0！\n刚刚发布的TensorFlow 2.0引入了诸多功能来简化模型的开发和维护过程。在教学方面，通过将许多复杂概念进行简化来增进人们的理解。从工业界的角度，模型变得更容易理解、维护和开发。\n深度学习是人工智能发展最快的领域之一。在过去几年中，我们已经证实深度学习模型，即使是最简单的模型，也能够解决非常困难和复杂的问题。如今，随着深度学习的流行语时代成为过去时，人们正在不断释放其威力和潜能，用来改进他们的产品。\n本课程的结构设计涵盖包括从神经网络建模，训练，到将模型投入生产环境的全部主题。\n在课程的第1部分，您会了解到贯穿我们整个课程的技术栈（第1节），以及TensorFlow 2.0库的基础和语法（第2节）。\n在课程的第2部分，我们将进入激动人心的深度学习领域。在这部分的课程中，您将亲手实现若干类型的神经网络（全连接神经网络（第3节），卷积神经网络（第4节），递归神经网络（第5节））。在这部分的尾声，第6节，您将学习并创建这些神经网络的迁移学习应用，这些应用在“猫狗分类”数据集上取得了目前最为领先(SOTA)的结果。\n在完成课程第2部分，并最终掌握如何实现神经网络之后，您将在课程的第3部分学习如何利用强化学习，尤其是深度-Q学习，来构造自己的股票市场交易机器人模型。\n课程第4部分全部是关于TensorFlow Extended (TFX)的内容。在这部分课程中，您会学习如何处理数据，并创建用于生产的数据流水线。在第8节，我们将通过TensorFlow Data Validation库查看数据集是否存在异常，在这之后的第9节，我们会通过TensorFlow Transform库来构造数据预处理流水线。\n在课程第10节，您会通过Flask Python库和训练好的模型，来学习和创建自己的Fashion API。在这一节中，您将更好的了解如何通过互联网向一个模型发送请求。但是在这个阶段，以模型为中心的体系并不能扩展到能够接受数百万的请求。那么当我们进入第11节，在这部分课程中，您将学习如何通过TensorFlow Serving库来改进我们前一节的解决方案。您将轻松学习并创建能够支持每日数百万请求的图像分类API！\n当前，在Android和iOS应用中使用深度学习模型正在变得逐渐流行，但神经网络需要大量的耗电以及资源！这时，TensorFlow Lite库就要发挥作用了。在课程第12节，您将学习对神经网络进行优化和转换，以适应移动设备的要求。\n在本课程的尾声，即课程第5部分，在第13节中您将学习如何通过TensorFlow 2.0库，将任意神经网络的训练分布到多个GPU，甚至是服务器上。",
      "target_audience": [
        "希望学习Tensorflow 2.0的深度学习工程师",
        "希望扩展其深度学习技能的人工智能工程师",
        "希望进入激动人心的深度学习和人工智能领域的计算机科学家",
        "希望将AI技能提升一个台阶的数据科学家",
        "希望扩展到应用领域的AI专家",
        "希望进入令人激动的深度学习和人工智能领域的Python开发者",
        "科技和自动化领域的工程师",
        "希望引领浪潮的商界和公司",
        "希望从事数据科学、机器学习、或人工智能的技术专业的学生",
        "任何对人工智能怀有激情的人们"
      ]
    },
    {
      "title": "Formação Engenheiro de IA Generativa 2025: IA na Prática",
      "url": "https://www.udemy.com/course/formacao-engenheiro-de-ia-generativa-ia-na-pratica/",
      "bio": "Torne-se expert em IA Generativa: Python, OpenAI, Gemini, HuggingFace, LangChain, N8N, Langgraph, Cursor, MCP e mais!",
      "objectives": [
        "Entender diferenças, vantagens e limitações de OpenAI, Gemini, HuggingFace, Mistral, Cohere e Groq para escolher o modelo mais adequado a cada projeto.",
        "Desenvolver chatbots, assistentes de voz, storybooks, quizzes interativos, landing pages e aplicações multimodais usando LLMs.",
        "Sair do básico ao intermediário em Python, aprendendo a manipular dados, integrar APIs, estruturar projetos e desenvolver aplicações com Gradio e Streamlit.",
        "Criar projetos de geração de texto, imagens, áudios e chatbots e usar Assistants API para análise de dados e automações inteligentes.",
        "Aplicar análise de sentimentos, classificação de texto, FAQ em português e visão computacional (remoção de background, detecção de objetos, OCR, etc.).",
        "Compreender a arquitetura, vantagens e desafios do RAG, e implementar pipelines completos com Pinecone e N8N, integrando dados externos ao modelo.",
        "Aprender LangChain, LangGraph, CrewAI, Agno e LlamaIndex, dominando o uso de chains, agents, memory, workflows e multiagentes.",
        "Usar N8N e Langflow para criar workflows de geração de texto, imagem, áudio e agentes conversacionais sem precisar programar do zero.",
        "Instalar e rodar Ollama e LM Studio para trabalhar com modelos como DeepSeek, sem depender exclusivamente de APIs na nuvem.",
        "Versionar projetos com GitHub, criar pipelines de dados, deployar agentes multiagentes e disponibilizar aplicações de IA para uso real em empresas e projetos pe"
      ],
      "course_content": {
        "Introdução": [
          "Apresentação do Curso",
          "Apresentação do Instrutor",
          "Dicas para o Curso",
          "O que há de novo no curso (Novos conteúdos!)"
        ],
        "Introdução ao Lovable": [
          "O que é o Lovable",
          "Principais Recursos",
          "Aplicabilidade"
        ],
        "Parte 1 - Modelos LLM (Gemini, OpenAI, HuggingFace)": [
          "Apresentação da Seção do Gemini",
          "Apresentação da Seção do OpenAI",
          "Apresentação da Seção do HuggingFace",
          "Qual LLM escolher?"
        ],
        "Gemini - Crie Apps, Storybooks, Vídeos, etc": [
          "O que é o Gemini",
          "Gemini Canvas",
          "Conhecendo a Plataforma",
          "Gerando Storybooks",
          "Desenvolvendo uma Landing Page",
          "Desenvolvendo um Quiz Interativo sobre Programação",
          "Conhecendo o Whisk",
          "Criando o Primeiro Experimento com Whisk",
          "Conhecendo o Flow",
          "Vídeo Gestor em uma Reunião"
        ],
        "Primeiros Passos com Python": [
          "Instalação e Configuração do Python",
          "Ambiente Virtual de Desenvolvimento e Pip",
          "Introdução a Versionamento com Git e Github"
        ],
        "Engenharia de Promtps na Prática (Python e Groq)": [
          "Por que o Groq?",
          "Configuração do Ambiente",
          "Explorando o Jupyter Lab",
          "Compreendendo as Roles",
          "Entendendo os Parâmetros",
          "Boas Práticas de Prompting I",
          "Estruturando o Output",
          "Usando Condições",
          "Usando a Técnica Few Shot",
          "Usando Multi Passos",
          "Usando a Técnica CoT",
          "Trabalhando com Sumarização de Dados",
          "Complementando Texto",
          "Transformação Textual",
          "Análise Textual",
          "Professor por um Dia: Ensinando a IA com Prompts"
        ],
        "OpenAI - GPT-5 Novidades": [
          "Apresentando o GPT-5",
          "Explorando Modelos do GPT-5",
          "Configuração do Ambiente",
          "Mudanças em Parâmetros",
          "Desenvolvendo Novo Exemplo",
          "Usando a Tool Preamble",
          "Exemplo Final"
        ],
        "OpenAI - Geração de Texto, Imagens, Audios e Chatbots": [
          "Criando a Conta OpenAI",
          "Geração de Texto",
          "Desenvolvimento de Chatbots",
          "Explorando Assistants",
          "Análisando Dados com Assistants",
          "Geração e Classificação de Imagens",
          "Transcrição e Sintetização de Voz",
          "Assistente Virtual de Voz"
        ],
        "HuggingFace - Visão Computacional e Processamento de Linguagem Natural": [
          "Conhecendo o HuggingFace",
          "Removendo o Background de Imagens",
          "Usando o Gradio",
          "Deploy da App",
          "Detecção de Objetos",
          "Gerando Texto a partir de Imagens",
          "Classificação de Imagens",
          "Rodando Modelo Kokoro (TTS - text to speech)",
          "Configuração do Ambiente (PLN)",
          "Análise de Sentimentos",
          "Análise de Sentimentos em Português",
          "Utilizando um Dataframe",
          "Classificando Texto",
          "Classificando Texto em Português",
          "Modelo de Pergunta e Resposta",
          "Desenvolvendo um FAQ",
          "Interface com o Gradio",
          "QA em Português"
        ],
        "Integração com LLM Alternativas": [
          "Configuração do Ambiente",
          "Usando os Serviços de AI do Groq no Python",
          "Usando os Serviços de AI do Gemini no Python",
          "Usando os Serviços de AI da Mistral no Python",
          "Usando os Serviços de AI da Cohere no Python"
        ]
      },
      "requirements": [
        "Conexão estável com a internet – necessária para acessar ferramentas online, APIs e realizar integrações em tempo real.",
        "Um bom computador – preferencialmente com pelo menos 8GB de RAM, para rodar ambientes de desenvolvimento, ferramentas low-code e alguns modelos locais de IA.",
        "Vontade de aprender e se atualizar – o curso é completo e traz passo a passo, mesmo para quem está começando.",
        "Importante: todos os requisitos técnicos e de conhecimento necessários serão ensinados no próprio curso.",
        "Ou seja, você não precisa ter experiência prévia com Python, APIs ou LLMs — vamos construir juntos essa base desde o início."
      ],
      "description": "Esta formação é um guia completo e prático para dominar Modelos de Linguagem (LLMs), plataformas de IA generativa e ferramentas de integração, desde a introdução aos principais provedores até a criação de projetos reais com Python, LangChain, N8N, Langflow, HuggingFace, Gemini, OpenAI e muito mais.\nO aluno aprenderá a escolher o modelo certo, criar aplicações inteligentes e integrar IA em soluções do mundo real, explorando desde fundamentos de Python até arquiteturas avançadas como RAG e sistemas multiagentes.\nComo o aluno se torna expert em IA Generativa\nComeça do zero com bases sólidas: fundamentos de Python, Git/GitHub e conceitos de APIs e LLMs.\nExplora os principais provedores de IA: Gemini, OpenAI, HuggingFace, Mistral e Cohere, aprendendo a escolher o modelo certo para cada projeto.\nCria projetos práticos desde o início: chatbots, assistentes de voz, FAQs, análise de sentimentos, visão computacional e geração de imagens.\nDomina ferramentas Low-Code e No-Code: Langflow e N8N para criar fluxos e integrações com RAG e Human in the Loop.\nAvança para arquiteturas complexas: LangChain, LangGraph, CrewAI, Agno e LlamaIndex para sistemas multiagentes, chats com documentos e pipelines inteligentes.\nIntegra IA a aplicações do mundo real: interfaces em Gradio e Streamlit, conectando modelos a APIs e automações.\nExecuta modelos localmente: Ollama e LM Studio, garantindo autonomia e privacidade.\nConsolida com projetos finais completos: chat com documentos jurídicos, assistente de voz inteligente, workflows no N8N, sistemas multiagentes e aplicações Gradio.\nForma mentalidade de engenheiro de IA: pensar em arquitetura, escolha de ferramentas e deploy de soluções inteligentes.\nEstrutura do Curso por Seções\nSeção 2 – Introdução aos Provedores de LLM\nApresentação das principais plataformas de IA: Gemini, OpenAI e HuggingFace.\nComparação prática entre modelos: prós, contras e casos de uso.\nCritérios para escolher a LLM mais adequada para cada projeto.\nSeção 3 – Gemini: Criação de Aplicações Inteligentes\nIntrodução ao Gemini: visão geral da plataforma.\nGemini Canvas: experimentação rápida de protótipos.\nCriação de Storybooks, Landing Pages e Quizzes interativos.\nUso do Whisk e Flow para estruturar fluxos de IA.\nProjeto prático: vídeo com gestor em reunião gerado por IA.\nSeção 4 – Fundamentos de Python\nInstalação, configuração e boas práticas.\nCriação de ambientes virtuais e uso do Pip.\nIntrodução ao Git e GitHub para versionamento de projetos.\nSeção 5 – OpenAI: Texto, Imagens, Áudio e Chatbots\nCriação e configuração de conta OpenAI.\nGeração de texto e construção de chatbots.\nUso do Assistants API para análise de dados e fluxos inteligentes.\nGeração e classificação de imagens com DALL·E.\nTranscrição e síntese de voz com Whisper e TTS.\nProjeto prático: Assistente Virtual de Voz.\nSeção 6 – HuggingFace: Visão Computacional e PLN\nIntrodução à comunidade e modelos do HuggingFace.\nManipulação de imagens: remoção de background, classificação e detecção de objetos.\nUso do Gradio para criação de interfaces rápidas.\nProcessamento de linguagem natural: análise de sentimentos, classificação de texto, FAQ e QA em português.\nProjeto prático: sistema de perguntas e respostas com Gradio.\nSeção 7 – Integração com LLMs Alternativas\nUso de Groq, Gemini, Mistral e Cohere via Python.\nCriação de fluxos híbridos para comparar performance entre modelos.\nSeção 8 – Ferramentas Low Code (Langflow e N8N)\nApresentação do Langflow e do N8N.\nComparação entre as ferramentas: quando usar cada uma.\nSeção 9 a 11 – Langflow e N8N na Prática\nLangflow: instalação, interface, construção de fluxos.\nN8N: criação de Workflows com LLMs para geração de texto, imagem, áudio e integração com Google e Telegram.\nIntrodução ao conceito de Human in the Loop.\nImplementação de RAG no N8N: arquitetura, vantagens e projeto prático com Pinecone.\nSeção 12 a 18 – Orquestradores de LLM\nIntrodução aos principais orquestradores: LangChain, Langgraph, Agno, CrewAI e LlamaIndex.\nLangChain: prompt templates, chains, memory, tools e agentes.\nLangGraph: workflows complexos, paralelização, roteamento e multiagentes.\nAgno: criação de agentes com instructions e reasoning.\nCrewAI: desenvolvimento e deploy de sistemas multiagentes.\nLlamaIndex: integração com pandas, RAG, embeddings e agentes avançados.\nProjetos práticos em cada orquestrador, incluindo chat com documentos, agentes analistas de dados, sistemas multiagentes e deploy em aplicações reais.\nSeção 19 a 21 – Ferramentas Complementares (Cursor e MCP)\nCursor AI: instalação, agentes, integração com MCP, uso de imagens e voz.\nMCP (Model Context Protocol): servidores, clientes, arquitetura e integração no Cursor.\nProjeto prático: notícias integradas no MCP com Cursor.\nSeção 22 – Execução Local de Modelos LLM\nUso do Ollama e LM Studio.\nExecução de modelos como DeepSeek de forma local.\nSeção 23 a 24 – Python Fundamentos e Intermediário\nTipos de dados, funções, estruturas de repetição e condicionais.\nListas, tuplas, sets, dicionários.\nProgramação funcional, orientação a objetos e assíncrona.\nManipulação de arquivos, regex e decoradores.\nSeção 25 – Integração com APIs\nConceitos de REST, HTTP e requisições com Python.\nCriação de interfaces com Streamlit para consumir APIs.\nSeção 26 – Gradio\nIntrodução ao Gradio.\nCriação de interfaces interativas com diferentes entradas e saídas.\nCustomização de UI e integração com modelos de IA.\nProjeto final: aplicações completas em Gradio.\nDiferenciais do Curso\nPrático desde o início: quase todas as seções possuem projetos aplicados.\nCobertura ampla: do básico ao avançado em Python + IA.\nIntegração real: OpenAI, Gemini, HuggingFace, N8N, Langflow, LangChain e muito mais.\nProjetos completos: chat com documentos, FAQ em português, workflows no N8N, multiagentes com CrewAI, aplicações Gradio e deploy em produção.\nTransformação completa: ao final, o aluno sai preparado para projetar, implementar e integrar soluções de IA generativa em qualquer contexto real.",
      "target_audience": [
        "Desenvolvedores e Engenheiros de Software Que desejam dominar LLMs, orquestradores e APIs para criar aplicações de IA modernas e robustas.",
        "Cientistas e Analistas de Dados Que querem aplicar RAG, análise de sentimentos, classificação de texto e visão computacional em projetos reais.",
        "Profissionais de Automação e Low-Code/No-Code Que buscam integrar IA em fluxos de trabalho usando N8N, Langflow e outras ferramentas low-code.",
        "Gestores de Inovação e Empreendedores Que desejam criar produtos digitais com IA, explorar novas oportunidades de negócio e otimizar processos internos.",
        "Estudantes e Profissionais em Transição de Carreira Que querem se especializar em IA Generativa, construir um portfólio prático e se destacar em um mercado em rápida expansão"
      ]
    },
    {
      "title": "【한글자막】 Pandas 및 Python 을 이용한 데이터 분석 : 마스터 클래스",
      "url": "https://www.udemy.com/course/best-pandas-python/",
      "bio": "Python, Pandas, Numpy, Matplotlib 그리고 Seaborn Libraries로 데이터 분석 및 시각화하기 | DataFrames를 병합, 연결하고 날짜 및 텍스트 데이터 처리",
      "objectives": [
        "데이터를 관리, 정렬 및 시각화하는 고급 파이썬 도구 마스터",
        "과학적 컴퓨팅을 위한 넘파이, 데이터 분석을 위한 판다스 등 파이썬 주요 라이브러리 사용 방법",
        "맷플롯립 및 씨본 라이브러리를 통해 데이터를 시각화하고 인사이트를 얻어 정보에 입각한 결정 내리기",
        "피처 엔지니어링을 통한 대용량 데이터 세트 관리, 머신 러닝 및 데이터 사이언스에 적용하기 위한 데이터 정리",
        "히트맵, 상관관계 분석, 산점도, 파이 차트, 페어 플롯, 벤다이어그램, 3D 플롯, 히스토그램, 워드 클라우드 및 군집 플롯 생성"
      ],
      "course_content": {
        "강의 소개, 성공 팁과 주요 학습 결과": [
          "강의 소개와 환영 인사",
          "소개, 성공을 위한 주요 팁",
          "데이터가 21세기의 금이 된 이유",
          "데이터가 21세기의 금이 된 이유"
        ],
        "판다스 시리즈 기초": [
          "판다스 시리즈 기초 구글 코랩 노트북",
          "판다스 시리즈 노트북 소개",
          "판다스 시리즈를 기본 인덱스로 정의하기",
          "판다스 시리즈를 기본 인덱스로 정의하기: 미니 챌린지 해설",
          "판다스 시리즈를 사용자 정의 인덱스로 정의하기",
          "판다스 시리즈를 사용자 정의 인덱스로 정의하기: 미니 챌린지 해설",
          "판다스 시리즈를 파이썬 사전으로 정의하기",
          "판다스 시리즈를 파이썬 사전으로 정의하기: 미니 챌린지 해설",
          "판다스 시리즈 속성",
          "판다스 시리즈 속성: 미니 챌린지 해설",
          "판다스 메서드",
          "판다스 메서드: 미니 챌린지 해설",
          "판다스로1-D CSV 들여오기",
          "판다스로1-D CSV 들여오기: 미니 챌린지 해설",
          "판다스 시리즈와 내재된 파이썬 기능들",
          "판다스 시리즈와 내재된 파이썬 기능들: 미니 챌린지 해설",
          "판다스 시리즈 분류와 정리",
          "판다스 시리즈 분류와 정리: 미니 챌린지 해설",
          "판다스 시리즈에서 수학 연산하기",
          "판다스 시리즈에서 수학 연산하기: 미니 챌린지 해설",
          "판다스 시리즈에 주어진 요소가 있는지 확인하기",
          "판다스 시리즈에 주어진 요소가 있는지 확인하기: 미니 챌린지 해설",
          "판다스 시리즈 인덱싱",
          "판다스 시리즈 인덱싱: 미니 챌린지 해설",
          "판다스 시리즈 슬라이싱",
          "판다스 시리즈 슬라이싱: 미니 챌린지 해설",
          "판다스 시리즈 복습과 결론"
        ],
        "판다스 데이터프레임 기초": [
          "판다스 데이터프레임 기초 구글 코랩 노트북",
          "판다스 데이터프레임 정의하기",
          "판다스 데이터프레임 정의하기: 미니 챌린지 해설",
          "판다스로 2-D CSV와 HTML 데이터 읽기",
          "판다스로 2-D CSV와 HTML 데이터 읽기: 미니 챌린지 해설",
          "CSV에 데이터프레임 쓰기",
          "CSV에 데이터프레임 쓰기: 미니 챌린지 해설",
          "판다스 데이터프레임 인덱스 세팅하고 재세팅하기",
          "판다스 데이터프레임 인덱스 세팅하고 재세팅하기: 미니 챌린지 해설",
          "데이터프레임에서 열 선택하기",
          "데이터프레임에서 열 선택하기: 미니 챌린지 해설",
          "데이터프레임에서 열 추가하고 지우기",
          "데이터프레임에서 열 추가하고 지우기: 미니 챌린지 해설",
          ".log()을 이용한 레이블 기반 요소 선택",
          ".log()을 이용한 레이블 기반 요소 선택: 미니 챌린지 해설",
          "정수 기반 요소 선택 .iloc()",
          "정수 기반 요소 선택 .iloc(): 미니 챌린지 해설",
          "판다스 브로드캐스팅 작업",
          "판다스 브로드캐스팅 작업: 미니 챌린지 해설",
          "판다스 데이터프레임 분류와 정리",
          "판다스 데이터프레임 분류와 정리: 미니 챌린지 해설",
          "판다스 데이터프레임과 기능",
          "판다스 데이터프레임과 기능: 미니 챌린지 해설",
          "데이터프레임을 사용한 판다스 작업",
          "데이터프레임을 사용한 판다스 작업: 미니 챌린지 해설",
          "기능 엔지니어링과 누락된 데이터 집합 처리",
          "기능 엔지니어링과 누락된 데이터 집합 처리: 미니 챌린지 해설",
          "데이터프레임 데이터 유형 바꾸기",
          "데이터프레임 데이터 유형 바꾸기: 미니 챌린지 해설",
          "판다스 데이터프레임 복습과 결론"
        ],
        "데이터프레임 연결, 병합과 결합": [
          "데이터프레임 연결, 병합과 결합 구글 코랩 노트북",
          "데이터프레임 연결",
          "데이터프레임 미니 챌린지 해설",
          "멀티인덱싱으로 연결하기",
          "멀티인덱싱 미니 챌린지 해설",
          "데이터프레임 병합",
          "데이터프레임 병합 미니 챌린지 해설"
        ],
        "판다스 다중인덱싱과 그룹별 검색": [
          "판다스 멀티인덱싱과 그룹으로 묶기 구글 코랩 노트북",
          "멀티인덱싱과 그룹으로 묶기 소개",
          "이커머스 데이터 집합 가져와서 탐색하기",
          "이커머스 데이터 집합 가져와서 탐색하기 미니 챌린지 해설",
          "그룹으로 묶기 연산",
          "그룹으로 묶기 연산 미니 챌린지 해설",
          "멀티인덱스 데이터프레임 생성하기",
          "멀티인덱스 데이터프레임 생성하기 미니 챌린지 해설",
          "멀티인덱싱 연산 파트 1",
          "멀티인덱싱 연산 파트 1 미니 챌린지 해설",
          "멀티인덱싱 연산 파트 2",
          "멀티인덱싱 연산 파트 2 미니 챌린지 해설",
          "복습과 결론"
        ],
        "판다스와 Matplotlib으로 데이터 시각화하기": [
          "판다스와 Matplotlib으로 데이터 시각화하기 구글 코랩 노트북",
          "Matplotlib으로 데이터 시각화하기 소개",
          "기본 선 그래프",
          "기본 선 그래프: 미니 챌린지 해설",
          "야후 경제에서 바로 데이터 다운로드하기",
          "야후 경제에서 바로 데이터 다운로드하기: 미니 챌린지 해설",
          "다중 그래프",
          "다중 그래프: 미니 챌린지 해설",
          "Subplots",
          "Subplots: 미니 챌린지 해설",
          "산점도",
          "산점도: 미니 챌린지 해설",
          "원형 그래프",
          "원형 그래프: 미니 챌린지 해설",
          "히스토그램",
          "히스토그램: 미니 챌린지 해설",
          "최종 방탈출 챌린지",
          "최종 방탈출 챌린지: 해설",
          "복습과 결론"
        ],
        "판다스와 Seaborn으로 데이터 시각화하기": [
          "판다스와 Seaborn으로 데이터 시각화하기 구글 코랩 노트북",
          "Seaborn 산점도와 카운트 플롯",
          "Seaborn 산점도와 카운트 플롯: 미니 챌린지 솔루션",
          "Seaborn 페어플롯과 히트맵",
          "Seaborn 페어플롯과 히트맵: 미니 챌린지 해설"
        ],
        "판다스 와 날짜/시간": [
          "판다스와 날짜/시간 코랩 노트북",
          "데이트타임 노트북 소개",
          "파이썬 데이트타임 모듈",
          "파이썬 데이트타임 모듈 미니 챌린지 해설",
          "판다스를 이용해서 날짜와 시간 구하기",
          "판다스를 이용해서 날짜와 시간 구하기 미니 챌린지 해설",
          "판다스 데이트타임 실용적 프로젝트 파트 1",
          "판다스 데이트타임 실용적 프로젝트 파트 1 미니 챌린지 해설",
          "판다스 데이트타임 실용적 프로젝트 파트 2",
          "판다스 데이트타임 실용적 프로젝트 파트 2 미니 챌린지 해설",
          "판다스와 데이터 시각화",
          "판다스와 데이터 시각화 미니 챌린지 해설",
          "복습과 결론"
        ],
        "판다스와 텍스트 데이터": [
          "코랩 스켈레톤: 판다스와 텍스트 데이터",
          "판다스와 텍스트 데이터 개요",
          "텍스트 데이터 로딩해서 기초 데이터 탐색하기",
          "텍스트 데이터 로딩해서 기초 데이터 탐색하기 미니 챌린지 해설",
          "대문자, 소문자 텍스트 데이터 변환",
          "대문자, 소문자 텍스트 데이터 변환 미니 챌린지 해설",
          "텍스트 데이터로 하는 판다스 연산 – 파트 1",
          "텍스트 데이터로 하는 판다스 연산 – 파트 1 미니 챌린지 해설",
          "텍스트 데이터로 하는 판다스 연산 – 파트 2",
          "텍스트 데이터로 하는 판다스 연산 – 파트 2 미니 챌린지 해설",
          "텍스트에서 구두점 제거",
          "텍스트에서 구두점 제거 미니 챌린지 해설",
          "텍스트에서 불용어 제거",
          "텍스트에서 불용어 제거 미니 챌린지 해설",
          "텍스트 토큰화",
          "텍스트 토큰화 미니 챌린지 해설",
          "데이터 시각화",
          "데이터 시각화 미니 챌린지 해설",
          "워드클라우드 텍스트 데이터 시각화",
          "워드클라우드 텍스트 데이터 시각화 미니 챌린지 해설",
          "판다스의 텍스트 데이터 복습과 결론"
        ],
        "부록: 파이썬 프로그래밍 기초 단기 속성 과정": [
          "부록: 파이썬 프로그래밍 기초 단기 속성 과정 노트북",
          "파이썬 기초: 변수 지정",
          "파이썬 기초: 수학 연산하기",
          "파이썬 기초: 조작 순서",
          "파이썬 기초: 출력 작업",
          "파이썬 기초: 사용자 입력 가져오기",
          "파이썬의 데이터 유형: 불값",
          "파이썬의 데이터 유형: 리스트",
          "파이썬의 데이터 유형: 사전",
          "파이썬의 데이터 유형: 문자열",
          "파이썬의 데이터 유형: 튜플",
          "파이썬의 데이터 유형: 집합",
          "비교/논리 연산자와 조건문 – 파트 #1",
          "비교/논리 연산자와 조건문 – 파트 #2",
          "비교/논리 연산자와 조건문 – 파트 #3",
          "비교/논리 연산자와 조건문 – 파트 #4",
          "반복문: For반복문",
          "반복문: 범위",
          "반복문: While 반복문",
          "반복문: 반복 끝내기",
          "반복문: 중첩 반복문",
          "반복문: 리스트 컴프리헨션",
          "기능: 내재된 기능",
          "기능: 사용자 정의 기능",
          "기능: 람다 기능",
          "기능: 맵",
          "기능: 필터",
          "파일 다루기: 텍스트",
          "파일 다루기: CSV",
          "넘파이: 넘파이 기초",
          "넘파이: 내재된 메서드와 기능들",
          "넘파이: 모양 길이 유형",
          "넘파이: 수학 연산",
          "넘파이: 슬라이싱과 인덱싱",
          "넘파이: 요소 선택"
        ]
      },
      "requirements": [
        "프로그래밍에 대한 기초 지식이 없어도 수강이 가능합니다.",
        "데이터 분석에 대한 사전 지식이 없어도 수강이 가능합니다."
      ],
      "description": "판다스 와 파이썬 을 이용한 데이터 분석 마스터 클래스!\n판다스와 데이터 프레임을 사용하여 데이터를 분석!\nMatplotlib와 Seaborn으로 데이터 시각화 하기!\n날짜 및 텍스트 데이터 처리!\n\n\nPandas 및 Python 을 이용한 데이터 분석 : 마스터 클래스 강의를 선택해야 하는 이유\n데이터 혁명이 도래했습니다! 21세기의 새로운 핵심은 데이터입니다.\n\n\n오늘날 수많은 기업은 막대한 양의 데이터에 접근할 수 있으며 이러한 데이터에서 가치 있는 인사이트 얻을 수 있는 기업이 경쟁에서 살아남습니다. 데이터를 분석하는 속도가 중요해진 것입니다.\n기업은 데이터를 통해 수익을 증대하고, 프로세스를 개선하고, 비용을 절감할 수 있습니다.\n\n\n데이터는 금융, 은행, 의료, 운송 및 기술 분야 등 다양한 산업에서 활용됩니다.\n이 강의는 데이터 분석에 대한 주요 지식을 실용적이면서 쉽고 재미있게 제공합니다. 또한 이 강의를 듣는 학생들은 실제 데이터 세트를 활용하며 실무를 경험할 수 있습니다.\n\n\n이 강의에서는 Pandas Series 와 DataFrames 를 사용하여 데이터를 분석하고 DataFrames을 병합, 연결 및 결합하는 법을 알아볼 것입니다. Matplotlib 그리고 Seaborn 으로 데이터를 시각화하는 방법도 알아볼 것입니다. 또한 날짜 및 텍스트 데이터를 처리하는 방법에 대해서도 알아보겠습니다.\n\n\nPandas 및 Python 을 이용한 데이터 분석 : 마스터 클래스 강의 세부 커리큘럼\n데이터를 관리, 정렬 및 시각화하는 고급 파이썬 도구 마스터\n과학적 컴퓨팅을 위한 넘파이, 데이터 분석을 위한 판다스 등 파이썬 주요 라이브러리 사용 방법\n맷플롯립 및 씨본 라이브러리를 통해 데이터를 시각화하고 인사이트를 얻어 정보에 입각한 결정 내리기\n피처 엔지니어링을 통한 대용량 데이터 세트 관리, 머신 러닝 및 데이터 사이언스에 적용하기 위한 데이터 정리\n히트맵, 상관관계 분석, 산점도, 파이 차트, 페어 플롯, 벤다이어그램, 3D 플롯, 히스토그램, 워드 클라우드 및 군집 플롯 생성\n\n\nLigency Team의 한마디!\n한국 수강생 여러분들 안녕하세요?\n\"Pandas 및 Python 을 이용한 데이터 분석 : 마스터 클래스\"에 오신 것을 환영합니다!\n\n\n이 강의는 Python과 데이터 분석을 이제 막 시작했거나 데이터 시각화를 제대로 배워 경력을 쌓고 싶은 분들 모두에게 적합한 강의입니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n데이터 시각화를 배울 준비가 되셨나요? 지금 바로 등록하세요!\nSee you inside!\n\n\n- Ligency Team",
      "target_audience": [
        "데이터 조작 및 분석 툴과 대한 기본적인 이해를 바탕으로 금융, 은행, 의료 및 기술 분야에 적용하고자 하는 초급자, 숙련된 파이썬 프로그래머 및 데이터 과학자",
        "주요 지표 시각화, 비즈니스 프로세스 최적화, 수익 극대화, 비용 절감을 위해 파이썬 기능을 활용하고자 하는 데이터 분석가",
        "경력 향상 및 데이터 과학 포트폴리오를 위해 실무 경험을 쌓고자 하는 데이터 분석가",
        "실무 경험을 쌓고자 하는 데이터에 열정을 가진 분",
        "데이터의 힘으로 수익 극대화, 비용 절감, 비즈니스 최적화를 이루고자 하는 비전 있는 비즈니스 오너"
      ]
    },
    {
      "title": "DeepSeek 深度求索：AIGC 推进工作效率跃迁",
      "url": "https://www.udemy.com/course/deepseek-aigc/",
      "bio": "DeepSeek 多领域应用精讲：解锁 AIGC 在工作中的无限可能",
      "objectives": [
        "掌握 DeepSeek 及 AIGC 工具的高效应用技巧：通过课程学习，能够熟练运用 DeepSeek 以及相关的 AIGC 工具",
        "了解避免使用 DeepSeek 过程中的常见误区：课程中会明确指出 DeepSeek 用户必须注意的三大雷区，帮助学员在实际使用过程中规避这些潜在问题，确保能够稳定、高效地利用该工具，",
        "提升职场综合竞争力与创新能力：借助 DeepSeek 等 AIGC 工具，学员可以更快速地完成各类工作任务，有更多的时间和精力去思考创新性的解决方案和策略，从而在职场中展现出更强的竞争力。",
        "掌握AIGC（人工智能、大数据、增强学习、云计算）相关技术和工具"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "第一章 DeepSeek 是这个时间段 AIGC 大模型的第一选择",
          "第二章 DeepSeek 基础对话的 5 个提问黄金法则",
          "第三章 DeepSeek 进阶对话的万能公式",
          "第四章 DeepSeek 应用必须注意的3大雷区",
          "第五章 服务器总是繁忙？10 个渠道体验满血DeepSeek",
          "第六章 DeepSeek+PPT：内容材料处理好帮手",
          "第七章 DeepSeek+Excel：数据处理的 3大应用场景",
          "第八章 DeepSeek+Kimi：快速制作一份PPT",
          "第九章 DeepSeek+XMind：快速制作项目流程图",
          "第十章 DeepSeek+剪影：制作视频人人可以上手"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "无经验"
      ],
      "description": "在人工智能技术飞速发展的今天，掌握高效工具已成为职场竞争力的核心。本课程《DeepSeek 深度求索：AIGC 推进工作效率跃迁》聚焦国产通用人工智能领军者——DeepSeek，通过理论与实战结合，助您解锁AI驱动的效率革命，实现从基础到精通的跨越式提升。\nDeepSeek 作为中国科技公司研发的通用人工智能（AGI）大模型，凭借开源推理模型 DeepSeek-R1 和媲美ChatGPT的 V3模型，在复杂任务处理中展现卓越能力。\n课程将深度解析如何通过 “万能提问公式” 与 “指令型大模型” 技巧，让AI精准理解需求，规避“正确的废话”，最大化输出价值。\n- 智能生成：一键生成高质量文本（如通知、报告）、代码补全，告别重复劳动；\n- 数据分析：结合Excel处理海量数据，无需编程基础即可完成运营分析；\n- 跨工具联动：与PPT、XMind、剪映等无缝衔接，快速产出专业级文档、思维导图与视频；\n- 行业应用：从电商物流方案优化（如“进口无忧”案例）到营销目标拆解，DeepSeek 提供精准决策支持。\n本课程由 AI & 办公软件实战专家 Adam常亚南老师亲授。常老师拥有丰富的行业经验，是金山办公最有价值专家、微软 & 领英生成式 AI 认证专家，同时也是电商公司数据分析师、金山稻壳金牌 KVP、PPT 定制设计师以及 AI 深度玩家。他的实战经验和专业背景将为学员提供深入浅出的指导：\n- 权威认证：三节课 IP 讲师、微软及领英生成式AI认证专家、金山办公最有价值专家（KVP）；\n- 行业经验：电商公司数据分析师、金山稻壳金牌PPT定制设计师，深谙职场痛点；\n- 技术前瞻性：AI深度玩家，长期探索大模型在办公场景的落地应用，擅长以通俗语言拆解复杂技术。\n常老师将以 真实案例（为切入点，手把手教学员将DeepSeek融入日常工作流，实现“技术-场景-成果”的闭环。\n从入门到精通的三大跃迁\n1. 技能提升：\n- 掌握DeepSeek核心功能，包括智能对话、文本生成、代码辅助与跨平台协作；\n- 学习“立角色-述问题-定目标-补要求”四步提示词公式，精准操控AI输出。\n2. 实战应用：\n- 快速制作专业PPT、Excel报告、思维导图及短视频，效率提升50%以上；\n3. 避坑指南：\n- 识别AI应用三大雷区，掌握替代平台（秘塔搜索、火山引擎等）的灵活调用。\n这门课程不仅是工具教学，更是一场思维升级——让DeepSeek成为您的“数字同事”，突破能力边界，在AI时代抢占先机！",
      "target_audience": [
        "职场新人与初级职场人士：工作中更加得心应手，提高工作效率，为自己的职业发展打下坚实基础",
        "内容创作者与营销从业者：提供创意灵感，优化工作流程，从而更高效地完成各项任务",
        "企业管理者与团队负责人：在团队中推广和应用 AIGC 工具，提升团队的协作效率和创新能力，从而推动企业的发展"
      ]
    },
    {
      "title": "[FR] Masterclass IA : De zéro à héros de l'IA",
      "url": "https://www.udemy.com/course/masterclass-en-ingenierie-de-lia-de-zero-a-heros-de-lia/",
      "bio": "Maîtrisez l’ingénierie de l’IA : créez et déployez des solutions IA avec projets réels et apprentissage pratique (AI)",
      "objectives": [
        "Créez des modèles d’IA avec Python, TensorFlow et PyTorch pour développer des systèmes intelligents capables de résoudre des problèmes concrets",
        "Prétraitez, nettoyez et analysez des données complexes pour garantir une qualité optimale lors de l'entraînement des modèles d’IA et de machine learning.",
        "Entraînez, évaluez et optimisez des modèles d’apprentissage automatique pour des tâches telles que la régression, la classification et le regroupement",
        "Concevez, implémentez et ajustez des réseaux de neurones, y compris les CNN et RNN, pour des applications avancées en IA",
        "Appliquez des techniques de traitement du langage naturel (NLP) pour analyser, interpréter et générer des textes semblables à ceux produits par des humains",
        "Exploitez l’apprentissage par transfert pour adapter des modèles d’IA pré-entraînés à de nouvelles tâches, en réduisant le temps et les ressources",
        "Déployez des modèles d’IA à l’aide d’API évolutives et d’outils de conteneurisation comme Docker pour une intégration fluide dans les applications",
        "Surveillez les performances des modèles d’IA, détectez les dérives et mettez en place un réentraînement pour garantir une fiabilité continue.",
        "Résolvez des défis commerciaux et techniques réels à l’aide d’approches pilotées par l’IA et de systèmes intelligents",
        "Développez des projets d’IA de bout en bout, de l’idéation et du prototypage jusqu’au déploiement et à la maintenance à long terme"
      ],
      "course_content": {},
      "requirements": [
        "Connaissances de base en programmation : Une familiarité avec Python est recommandée mais non obligatoire.",
        "Curiosité et enthousiasme : Une passion pour l’IA et une volonté d’apprendre sont essentielles.",
        "Accès à un ordinateur : Un ordinateur avec une connexion Internet et une puissance suffisante pour les tâches liées à l’IA.",
        "Aucune expérience préalable en IA requise : Le cours commence par les concepts fondamentaux et progresse graduellement.",
        "Compétences de base en mathématiques : Compréhension des notions de mathématiques de niveau lycée (par exemple, algèbre, statistiques de base).",
        "Connexion Internet stable : Pour accéder aux supports de cours, outils et projets pratiques.",
        "Outils facultatifs : Installation de Python, Jupyter Notebook et des bibliothèques IA pertinentes (des instructions sont fournies dans le cours).",
        "Esprit ouvert : Soyez prêt à explorer, expérimenter et créer des applications d’IA concrètes."
      ],
      "description": "Ce cours est traduit par l'IA de l'anglais vers l'espagnol afin que vous puissiez apprendre des technologies de pointe dans votre langue maternelle.\nBienvenue à la Masterclass en Ingénierie de l’IA : De Zéro à Héros de l’IA !\nCe cours complet est conçu pour vous emmener dans une aventure passionnante, du niveau débutant à celui d’ingénieur en IA accompli, avec toutes les compétences nécessaires pour construire, entraîner et déployer des solutions d’intelligence artificielle. Que vous partiez de zéro ou cherchiez à renforcer vos connaissances, cette masterclass vous offre une feuille de route pas à pas vers la réussite.\nDans cette formation, vous commencerez par les bases de l’IA : programmation en Python, prétraitement des données et concepts fondamentaux du machine learning. Ensuite, vous explorerez des sujets avancés tels que les réseaux neuronaux, le deep learning, le traitement du langage naturel (NLP) et la vision par ordinateur. Vous gagnerez également une expérience pratique avec des frameworks IA de pointe comme TensorFlow, PyTorch et Hugging Face pour créer des solutions prêtes pour la production.\nCette masterclass met l’accent sur des compétences pratiques, avec des projets réels intégrés à chaque module. Vous apprendrez à résoudre des problèmes concrets à l’aide des technologies d’IA, à optimiser vos modèles et à déployer des solutions évolutives.\nPourquoi choisir cette masterclass en ingénierie de l’IA ?\nProgramme adapté aux débutants : Commencez de zéro et progressez jusqu’au niveau expert\nProjets pratiques en IA : Construisez de vraies applications pour des défis du monde réel\nMaîtrise des frameworks d’IA : Apprenez TensorFlow, PyTorch et Hugging Face\nFormation complète : Python, machine learning, deep learning, NLP et déploiement\nParcours De Zéro à Héros : Un chemin structuré pour maîtriser pleinement l’IA\nÀ la fin de cette masterclass, vous aurez non seulement acquis des compétences solides en ingénierie de l’IA, mais serez aussi prêt à innover, diriger des projets IA et transformer votre organisation ou startup grâce à l’intelligence artificielle.\nQue vous soyez un futur ingénieur IA, un passionné d’IA ou une personne souhaitant entrer dans ce domaine en pleine croissance, cette masterclass est votre ressource ultime pour passer De Zéro à Héros de l’IA.\nRejoignez la révolution de l’IA dès aujourd’hui – Inscrivez-vous à la Masterclass en Ingénierie de l’IA : De Zéro à Héros de l’IA et faites le premier pas vers la maîtrise de l’intelligence artificielle!",
      "target_audience": [
        "Futurs ingénieurs en IA : Personnes souhaitant lancer leur carrière en IA grâce à des compétences pratiques et des projets concrets.",
        "Data scientists & analystes : Professionnels cherchant à approfondir leur expertise en création et déploiement de modèles d’IA.",
        "Développeurs logiciels : Programmeurs désireux d’intégrer des capacités d’IA dans leurs applications et systèmes.",
        "Personnes en reconversion : Individus issus de milieux non techniques prêts à se tourner vers l'industrie de l’IA.",
        "Étudiants en master : Étudiants en science des données, informatique ou domaines connexes recherchant des compétences pratiques en IA.",
        "Entrepreneurs tech : Fondateurs et CTO explorant l’IA pour l’innovation produit et la croissance de leur entreprise.",
        "Passionnés d’IA : Toute personne passionnée par l’IA souhaitant construire des systèmes intelligents à partir de zéro.",
        "Professionnels du business : Dirigeants cherchant à comprendre l’IA pour prendre des décisions stratégiques et développer leur organisation."
      ]
    },
    {
      "title": "Grundlagen der Statistik | Einführung in die Statistik",
      "url": "https://www.udemy.com/course/grundlagen-der-statistik-einfuhrung-in-die-statistik/",
      "bio": "Einführung in die Grundlagen der Statistik mit Beispielen in Excel, R und Python",
      "objectives": [
        "Grundbegriffe der Statistik verstehen und sicher anwenden.",
        "Datenverteilungen anhand von Lage- und Streuungsparametern beschreiben können.",
        "Verständliche Visualisierungen von Daten (in Excel, R oder Python) erstellen.",
        "Die Inhalte des Kurses in Excel, R oder Python anwenden."
      ],
      "course_content": {
        "Kursbeschreibung und Begrüßung": [
          "Kursbeschreibung und Begrüßung"
        ],
        "Erste Grundbegriffe": [
          "Grundbegriffe",
          "Quizfragen zu Lektion: Grundbegriffe"
        ],
        "Häufigkeiten": [
          "Häufigkeiten",
          "Quizfragen zu Lektion: Häufigkeiten"
        ],
        "Lageparameter": [
          "Lageparameter",
          "Quizfragen zu Lektion: Lageparameter"
        ],
        "Streuungsparameter": [
          "Streuungsparameter",
          "Quizfragen zu Lektion: Streuungsparameter"
        ],
        "Datenvisualisierung": [
          "Datenvisualisierung",
          "Quizfragen zu Lektion: Datenvisualisierung"
        ],
        "Konzentrationsmaße": [
          "Konzentrationsmaße",
          "Quizfragen zu Konzentrationsmaßen"
        ],
        "Korrelation und Kausalität": [
          "Korrelation",
          "Kausalität",
          "Quizfragen zu Korrelation und Kausalität"
        ],
        "Zusammenfassung und Abspann": [
          "Zusammenfassung und Abspann"
        ],
        "Excel-Tutorials": [
          "Häufigkeiten I",
          "Häufigkeiten II",
          "Lageparameter",
          "Streuungsparameter",
          "Datenvisualisierung",
          "Konzentration",
          "Korrelation"
        ]
      },
      "requirements": [
        "Für die Kursinhalte sind keine Vorkenntnisse notwendig.",
        "Für die Anwendungen in Excel, R und Python sind grundlegende Kenntnisse des jeweiligen Programms (installieren, aufrufen etc.) hilfreich."
      ],
      "description": "Dieser Kurs vermittelt die Grundlagen der (univariaten) Statistik. Möchten Sie mit Daten arbeiten, haben aber noch keine Vorkenntnisse im Bereich Statistik, ist dieser Kurs für Sie ideal geeignet.\nDer Kurs beginnt mit der Klärung von wichtigen statistischen Grundbegriffen um eine gemeinsame Basis für die folgenden Lerneinheiten zu legen. Danach starten wir mit den typischen Schritten einer ersten Datenanalyse und beginnen mit der Bestimmung von absoluten und relativen Häufigkeiten. In den Einheiten zu Lage- und Streuungsparametern lernen Sie die Verteilungen von Merkmalen zu beschreiben und im Kapitel zu Datenvisualisierung besprechen wir u.a. wie man die Ergebnisse einer Datenanalyse grafisch präsentieren kann. In der Lerneinheit zu Konzentrationsmaßen nutzen wir u.a. Lorenzkurven und den Gini-Koeffizient zur Beurteilung von Ungleichheit. Die beiden letzten Lerneinheiten beschäftigen sich mit der Analyse des Zusammenhangs zweier Merkmale sowie dem Unterschied zwischen statistischen Zusammenhängen und Kausalität.\nAlle vermittelten Inhalte werden von Video-Tutorials in Excel, R und Python begleitet, die die direkte Umsetzung durch die Teilnehmerinnen und Teilnehmer des Kurses ermöglichen. Jede Lerneinheit wird durch ein Quiz zur Vertiefung der erlernten Inhalte abgeschlossen:\n\n\nAgenda des Kurses:\n\n\nStatistische Grundbegriffe\nHäufigkeiten\nLageparameter\nStreuungsparameter\nDatenvisualisierung\nKonzentrationsmaße\nKorrelation\nKausalität\n\n\nÜbersicht über die vermittelten Begriffe und Konzepte:\nGrundgesamtheit | Population | Stichprobe | Stichprobenumfang | Repräsentativität | Zufallsauswahl | Merkmal | Variable | Merkmalsausprägung | Variablenausprägung | Daten | Skalenniveau | Nominalskala | Ordinalskala | Kardinalskala | Metrische Skala | Absolute Häufigkeit | Relative Häufigkeit | Kumulierte absolute Häufigkeit | Kumulierte relative Häufigkeit | Lageparameter | Modus | Modalwert | Median | (arithmetischer) Mittelwert | Streuungsparameter | Spannweite | Varianz | Standardabweichung | Quantile | Quantilsabstand | Interquartilsabstand | Quantilsverhältnisse | Säulendiagramm | Balkendiagramm | Kreisdiagramm | Liniendiagramm | Histogramm | Boxplot | Relative Konzentration | Absolute Konzentration | Lorenzkurve | Gini-Index | Gini-Koeffizient | Konzentrationsrate | Streudiagramm | Scatterplot | Korrelation | Kausalität | Korrelationskoeffizient",
      "target_audience": [
        "Statistik-Interessierte, die in Beruf, Studium oder Alltag mit Daten arbeiten, aber keine Vorkenntnisse in Statistik oder Datenanalyse haben."
      ]
    },
    {
      "title": "Reconhecimento de Emoções com TensorFlow 2.0 e Python",
      "url": "https://www.udemy.com/course/reconhecimento-emocoes-tensorflow-20-python/",
      "bio": "Utilize Visão Computacional, Deep Learning e Redes Neurais Convolucionais para reconhecer emoção em imagens e vídeos",
      "objectives": [
        "Implemente um detector de emoções utilizando modernas técnicas de Deep Learning com Redes Neurais Convolucionais, utilizando o TensorFlow 2.0",
        "Aprenda a detectar emoções de imagens e vídeos"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Recursos para download"
        ],
        "Reconhecimento de emoções em imagens": [
          "Introdução a reconhecimento de emoções",
          "Arquivos Google Drive",
          "Reconhecimento de emoção 1",
          "Reconhecimento de emoção 2",
          "Reconhecimento de emoção 3",
          "Reconhecimento de emoção 4",
          "Reconhecimento de emoção 5",
          "Reconhecimento de emoção 6",
          "Reconhecimento de emoção 7",
          "Solução para a tarefa",
          "Reconhecimento de emoção 8",
          "Captura de foto pela webcam"
        ],
        "Reconhecimento de emoção com redes neurais convolucionais": [
          "Introdução a redes neurais convolucionais",
          "Reconhecimento com redes neurais convolucionais 1",
          "Reconhecimento com redes neurais convolucionais 2",
          "Reconhecimento com redes neurais convolucionais 3",
          "Reconhecimento com redes neurais convolucionais 4",
          "Reconhecimento com redes neurais convolucionais 5",
          "Reconhecimento com redes neurais convolucionais 6",
          "Reconhecimento com redes neurais convolucionais 7",
          "Reconhecimento com redes neurais convolucionais 8",
          "Reconhecimento com redes neurais convolucionais 9",
          "Reconhecimento com redes neurais convolucionais 10",
          "Reconhecimento com redes neurais convolucionais 11",
          "Reconhecimento com redes neurais convolucionais 12",
          "Reconhecimento com redes neurais convolucionais 13",
          "Reconhecimento com redes neurais convolucionais 14",
          "Reconhecimento com redes neurais convolucionais 15",
          "Reconhecimento com redes neurais convolucionais 16",
          "Reconhecimento com redes neurais convolucionais 17",
          "Reconhecimento com redes neurais convolucionais 18",
          "Outras arquiteturas de redes neurais convolucionais",
          "Comparação e carregamento do melhor modelo",
          "Reconhecimento de emoções em vídeos",
          "Carregamento de imagens a partir de diretório",
          "Data Augmentation",
          "Transfer Learning com VGG16",
          "Implementação arquitetura Inception"
        ],
        "Anexo I - Redes Neurais Artificiais": [
          "Perceptron de uma camada",
          "Redes multicamada - função soma e função de ativação",
          "Redes multicamada - cálculo do erro",
          "Descida do gradiente",
          "Cálculo do parâmetro delta",
          "Ajuste dos pesos com backpropagation",
          "Bias, erro, descida do gradiente estocástica e mais parâmetros",
          "Funções de ativação I",
          "Funções de ativação II"
        ],
        "Considerações finais": [
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "É recomendado conhecimento básico sobre lógica de programação, principalmente estruturas condicionais e de repetição (if e for)",
        "Conhecimentos básicos sobre Python",
        "Conhecimentos sobre redes neurais artificiais são desejáveis (no final do curso está disponível um anexo com a teoria básica sobre redes neurais)"
      ],
      "description": "Dentro da área da Visão Computacional existe a sub-área de reconhecimento/deteção de emoções, que visa identificar emoções específicas que pessoas podem expressar em imagens ou vídeos. Alguns exemplos de aplicações são: alertar condutores de veículos que podem estar distraídos, personagens de jogos podem interagir com o usuário de acordo com a emoção expressada, monitoramento de pacientes em hospitais, avaliação do interesse dos alunos em aplicações de educação a distância, sistemas de vigilância e principalmente na área de marketing; sendo possível entender o que os consumidores estão sentindo sobre determinados produtos ou serviços.\nE para levar você até essa área, neste curso você desenvolverá passo a passo Redes Neurais Convolucionais utilizando o TensorFlow 2.0 e o Python para detectar emoções em vídeos e imagens! O sistema será capaz de detectar as seguintes emoções: raiva, alegria, tristeza, nojo, surpresa, medo e também se uma face não está expressando nenhuma dessas emoções. Utilizaremos modernas técnicas de Deep Learning (Aprendizagem Profunda) para o desenvolvimento dos exemplos do curso, usando a base de dados FER3 que é uma das bases de dados mais utilizadas para treinamento de sistemas de reconhecimento de emoção, que inclusive faz parte dos desafios do Kaggle!\nO objetivo principal deste curso é que você tenha uma visão prática de como utilizar o TensorFlow 2.0 para reconhecimento de emoções, portanto, nós mostraremos somente uma intuição básica sobre a teoria do algoritmo. Este curso é para todos os níveis, ou seja, se este for o seu primeiro contato com a área de Visão Computacional você conseguirá acompanhar o curso. Da mesma forma, se você já tem experiência na área também aproveitará o conhecimento adquirido com o desenvolvimento do projeto prático.\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial",
        "Pessoas interessadas na área de visão computacional utilizando o Python, Deep Learning e TensorFlow",
        "Pessoas interessadas em reconhecimento de emoções de imagens e vídeos",
        "Alunos de graduação que cursam disciplinas de Computação Gráfica, Processamento Digital de Imagens ou Inteligência Artificial"
      ]
    },
    {
      "title": "Aprendizagem por Reforço com Augmented Random Search (ARS)",
      "url": "https://www.udemy.com/course/inteligencia-artificial-augmented-random-search-ars/",
      "bio": "Implemente passo a passo em Python um poderoso modelo de Inteligência Artificial para ensinar um agente caminhar!",
      "objectives": [
        "Teoria sobre a técnica ARS (Augmented Random Search)",
        "Implementação passo a passo de uma inteligência artificial para controlar um robô em um ambiente simulado"
      ],
      "course_content": {},
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Programação básica em Python",
        "Conhecimentos sobre instalação de softwares básicos, porém, durante o curso será mostrado o processo de instalação das ferramentas utilizadas",
        "Noções de Orientação a Objetos, como: classes, objetos, atributos e métodos"
      ],
      "description": "Neste curso você vai aprender um novo tipo de inteligência artificial, que é quase tão poderosa quanto o algoritmo usado pelo Google Deep Mind para treinar uma IA caminhar e correr por um ambiente! O nome dessa técnica é Augmented Random Search (Pesquisa Aleatória Aumentada), foi criada em 2018 e é em média 15 vezes mais rápida do que algoritmos tradicionais!\nEsse algoritmo está dentro da área de Aprendizagem por Reforço, que é um tipo de aprendizagem usado em sistemas multi-agente no qual os agentes devem interagir no ambiente e aprenderem por conta própria, ganhando recompensas positivas quando executam ações corretas e recompensas negativas quando executam ações que não levem para o objetivo. A inteligência artificial aprende sem nenhum conhecimento prévio, adaptando-se ao ambiente e encontrando as soluções sozinha!\nE para levar você até essa área, neste curso você terá uma visão teórica e principalmente prática sobre o treinamento da simulação de um robô que precisa aprender a andar em um ambiente. Usaremos a técnica ARS (Augmented Random Search), o Python como linguagem de programação e o Gym como ambiente de simulação. O conteúdo do curso está dividido em duas partes:\nTeoria sobre ARS (Augmented Random Search)\nConstrução passo a passo da inteligência artificial para controlar o robô. Implementaremos o algoritmo ARS totalmente do zero, sem o uso de nenhuma biblioteca de aprendizagem de máquina!\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em novas tecnologias de inteligência artificial",
        "Pessoas interessadas em simular robôs caminhando com aprendizagem por reforço",
        "Pessoas interessadas no algoritmo ARS (Agumented Random Search)",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial"
      ]
    },
    {
      "title": "Pengenalan Pembelajaran Mesin (Intro to Machine Learning)",
      "url": "https://www.udemy.com/course/intro-to-machine-learning/",
      "bio": "Belajar untuk Menggunakan NumPy, Pandas, Matplotlib, Scikit-Learn, Pembelajaran Mesin atau Machine Learning, dan lainnya",
      "objectives": [
        "Learn how Machine Learning REALLY works",
        "Learn to Use Python for Machine Learning",
        "Implement Machine Learning Algorithms",
        "Make robust Machine Learning models",
        "Have a great intuition of many Machine Learning Algorithms and Models",
        "Learn how to pre-process data",
        "Understand the mathematics behind Machine Learning",
        "Build powerful Machine Learning models and know how to combine them to solve any problem",
        "Use SciKit-Learn for Machine Learning Tasks",
        "Build computational models from scratch to make predictions",
        "Learn to use NumPy for Numerical Data",
        "Learn to use Matplotlib for Python Plotting",
        "Perform Linear and Logistic Regressions in Python",
        "Make predictions using linear regression and polynomial regression",
        "Classify data using K-Means clustering, KNN, and Naive Bayes",
        "Understand and implement Perceptron in Python",
        "You will Improve your skills with practice activities throughout the course",
        "Be able to create Machine Learning algorithms in Python, using NumPy and scikit-learn",
        "You will learn the skill set and power of Python to analyze data, create state of the art visualization and use of machine learning algorithms to facilitate decision making",
        "Create a value to your skill"
      ],
      "course_content": {
        "Apakah Anda siap untuk belajar Pembelajaran Mesin? Mari kita mulai!": [
          "Introduction to Course",
          "Introduction to Machine Learning",
          "Type of Learning",
          "Applications of Machine Learning"
        ],
        "Persiapan and Instalasi Python Anaconda": [
          "Install Python Anaconda (Windows)",
          "Anaconda Prompt",
          "Anaconda Linux",
          "Jupyter"
        ],
        "Data Preprocessing: Konversi data mentah menjadi set data bersih": [
          "Introduction to Preprocessing Data",
          "Preprocess Case",
          "Required Libraries",
          "Load Data",
          "Imputation",
          "Categorical Column Map",
          "Normalization",
          "Split Test Train",
          "Preprocess Template",
          "Preprocess Template for Classification"
        ],
        "Klasifikasi dan Regresi.": [
          "Regression Intuition",
          "Classification Intuition"
        ],
        "KNN: k- Nearest Neighbors Algorithm": [
          "Introduction to KNN",
          "Euclid Distance",
          "Challenge",
          "Solution",
          "Implementation of KNN"
        ],
        "Naive Bayes": [
          "Probability",
          "Bayes Theorem",
          "Naive Bayes",
          "Naive Bayes Part 2",
          "Notes",
          "Implementation of Naive Bayes"
        ],
        "Perceptron": [
          "Perceptron Intuition",
          "Perceptron Implementation"
        ],
        "Linear and Polynomial Regression": [
          "Linear Regression Intuition",
          "Polynomial Regression Intuition",
          "Linear Regression Implementation"
        ],
        "Logistic Regression": [
          "Logistic Regression Intuition",
          "Logistic Regression Implementation"
        ]
      },
      "requirements": [
        "A computer (Windows, Mac, or Linux) and passion to be successful",
        "Any 64-bit operating system with at least 4GB to 8GB RAM for this course. Furthermore, install Python 3 and Jupyter Notebooks on their systems",
        "A strong interest in technology and AI enthusiastic",
        "Algebra & Calculus"
      ],
      "description": "*Apa kamu siap untuk menjadi Machine Learning Engineer? Atau apa kamu tertarik untuk belajar materi Machine Learning? Tunggu apa lagi? Ini adalah pelajaran yang cocok untukmu!*\n\n\n*Saat ini, teknologi berevolusi dan berkembang pesat tanpa henti. Apalagi, didukung dengan adanya era pembelajaran komputer generasi ke-5 yang melahirkan adanya Artificial Intelligence atau Kecerdasan Buatan, yang mengharuskan individu untuk memiliki skill tambahan agar lebih kompetitif dan lebih mahir ketimbang yang lain. Dalam kursus ini, anda akan belajar mengenai Artificial Intelligence atau kecerdasan buatan yang sangat diminati di berbagai industri yang tak terhitung jumlahnya. Machine Learning adalah tiket kelas satu ke karier paling menarik di AI.*\n\n\n*Pembelajaran mesin atau Machine Learning menyatukan ilmu komputer dan statistik untuk membangun daya prediksi. Anda akan menjelajahi banyak algoritma berbeda selama kursus ini yang akan mencakup banyak pemrosesan data dan penanganannya. Dan lebih lagi mengenai regresi linier dan logistik yang menghasilkan beberapa prediksi.*\n\n\n*Kami akan memandu Anda langkah demi langkah dalam Pembelajaran Mesin atau Machine Learning. Dengan setiap tutorial, anda akan mengembangkan keterampilan baru dan meningkatkan pemahaman Anda tentang Pembelajaran Mesin.*\n\n\n*Kursus ini akan menjadi panduan Anda untuk belajar bagaimana menggunakan kekuatan Python untuk menganalisis data, membuat visualisasi yang indah, dan menggunakan algoritma pembelajaran mesin yang kuat!*\n\n\n*Kursus ini dirancang oleh profesional Data Scientist dan Insinyur Pembelajaran Mesin (Machine Learning Engineer), sehingga kami dapat membagikan pengetahuan baik teori, algoritma, dan kode perpustakaan. Tenang saja, kami akan membantu anda untuk mempelajari itu semua dengan cara semudah mungkin.*\n\n\n*Kursus yang menyenangkan dan mengasyikkan ini membuat anda secara tidak langsung dapat menyelami Algoritma Pembelajaran Mesin. Selain itu, tentu saja dikemas dengan latihan praktis. Jadi, anda tidak hanya akan mempelajari teorinya, tetapi anda juga akan mendapatkan praktik langsung membangun model anda sendiri.*\n\n\n*Daftarkan diri anda di kursus Pengenalan Pembelajaran Mesin dan mulailah karirmu menjadi seorang Machine Learning Engineer!*",
      "target_audience": [
        "Anyone interested in Machine Learning",
        "Students who have at least high school knowledge in math and who want to start learning Machine Learning",
        "Any students in college who want to start a career in Machine Learning",
        "Any data analysts who want to level up in Machine Learning",
        "People who are not satisfied with their job and who want to become a Machine Learning Engineer"
      ]
    },
    {
      "title": "③米国AI開発者がやさしく教える深層学習超入門第三弾(自然言語処理)【Pythonで実践】",
      "url": "https://www.udemy.com/course/deeplearning3/",
      "bio": "自然言語処理の深層学習の基礎(RNN)",
      "objectives": [
        "自然言語処理の深層学習の理論を深く理解することができます",
        "深層学習のRNN系のモデル/学習をスクラッチで実装できるようになります",
        "深層学習の応用的な知識を使ってより高精度なモデルを構築できるようになります",
        "GPUを使って深層学習モデルを学習できるようになります"
      ],
      "course_content": {
        "紹介": [
          "紹介",
          "本講座の資料とコードについて",
          "補足教材"
        ],
        "環境準備": [
          "本セクションの補足(本講座用のDocker imageについて)",
          "環境構築概要(Docker + JupyterLab)",
          "M1チップをお使いの方へ",
          "DockerHubアカウント作成",
          "Windowsユーザへの補足",
          "Docker環境構築",
          "Dockerの基本操作",
          "次レクチャー補足",
          "JupyterLabの基本操作"
        ],
        "RNN": [
          "系列データの概要",
          "RNNモデルの概要",
          "RNNの順伝搬(前半)",
          "RNNの順伝搬(後半)",
          "RNNの順伝搬【Python】",
          "RNNのモデル構築【Python】",
          "nn.RNN【Python】",
          "RNNの逆伝搬(前半)",
          "RNNの逆伝搬(後半)",
          "RNNの逆伝搬【Python】",
          "RNNの逆伝搬のテスト【Python】",
          "様々なRNN",
          "まとめ"
        ],
        "Word Embedding": [
          "word embeddingとword2vec",
          "CBOW概要",
          "CBOWのモデル構造",
          "Negative Sampling",
          "Skip-gram",
          "GloVe",
          "Word Embedding手法比較",
          "Gensim【Python】",
          "Spacy【Python】",
          "fastText【Python】",
          "embedding layer",
          "embedding layer【Python】",
          "まとめ"
        ],
        "ゲート付きRNN": [
          "ゲート付きRNN",
          "UGRNN",
          "UGRNN【Python】",
          "GRU",
          "LSTM",
          "LSTM【Python】",
          "PytorchのLSTM【Python】",
          "まとめ"
        ],
        "さらなる工夫": [
          "Bidirectional RNN",
          "BiRNN【Python】",
          "BiRNNModel【Python】",
          "Deep RNN",
          "Deep RNN【Python】",
          "まとめ"
        ],
        "NER": [
          "NER概要",
          "次レクチャーの修正",
          "NERのデータ準備【Python】",
          "padding",
          "padding【Python】",
          "モデル実装【Python】",
          "次レクチャーの修正",
          "NER学習【Python】",
          "次レクチャーの修正",
          "NER結果確認【Python】",
          "まとめ"
        ],
        "トピック分類": [
          "トピック分類概要",
          "次レクチャーの補足",
          "トピック分類のデータ確認【Python】",
          "辞書作成【Python】",
          "DataLoader作成【Python】",
          "embedding matrix作成【Python】",
          "モデル構築【Python】",
          "学習ループ実装【Python】",
          "まとめ"
        ],
        "seq2seq": [
          "seq2seq概要",
          "image captioning",
          "機械翻訳",
          "トークンの選択手法",
          "beam search",
          "beam searchの改善",
          "エラー分析",
          "Teacher forcing",
          "次レクチャーの補足",
          "機械翻訳のデータ準備(前半)【Python】",
          "機械翻訳のデータ準備(後半)【Python】",
          "機械翻訳のモデル構築【Python】",
          "機械翻訳の学習【Python】",
          "機械翻訳の結果確認【Python】",
          "beam search実装【Python】",
          "まとめ"
        ],
        "LLM": [
          "言語モデルとは",
          "LLM",
          "scaling laws",
          "Transformer",
          "Positional Encoding",
          "Attention機構",
          "feed forward",
          "その他の主要構成要素",
          "LLMの学習プロセス概要",
          "まとめ"
        ]
      },
      "requirements": [
        "線形代数と微分の基礎知識があると良いです",
        "事前に統計学講座と機械学習講座を受講しておくことを強くお勧めします",
        "事前に第一弾(基本的なニューラルネットワーク)および第二弾(画像系の深層学習)を受講ください",
        "Pythonの実装については，Pythonの基礎知識およびデータサイエンスに必要なライブラリの知識が必要です",
        "Pythonの知識がなくても本講座で深層学習の理論を学習することができます"
      ],
      "description": "※本講座は全３部構成である深層学習超入門の\"第三弾\"です\n自然言語処理の深層学習の基礎をゼロから学べます．学習した理論をPythonでスクラッチで実装し，理論x実装の相乗効果で確実に深層学習を習得できます．\nまた，Pytorchを使用して深層学習のモデル学習も行うので，実務にも即応用できる内容です．\n(全3部構成で，本講座は「第三弾」となっており，主に系列データの深層学習であるRNNの基本や少し応用的なアルゴリズム/テクニックを解説しています．)\n【特徴】\n- 現役のAI開発者から学ぶ\n- 実際の現場でどのように使うのかを解説\n- 完全体系的に学ぶ\n- アルゴリズムのスクラッチ実装により完全に理解して進める\n- 数式を丁寧に解説\n- 図を多用しイメージで学ぶ\n- Pytorchでの実装も紹介\n- 学習したことをすぐに実データに適用可能\n- DockerとJupyterLabを使った本格データサイエンス環境 (Dockerを使って簡単環境構築)\n- これ1本で理論x実装が同時に，着実に学べる\n\n\n深層学習の理論とPythonの実装のレクチャーは別になっているため，理論だけを学習することも可能です．そのためPythonを知らなくても本講座で深層学習を学ぶことができます．\n\n\nPythonの実装のレクチャーは，Pythonの基礎知識とデータサイエンスに必要なPython(NumpyやMatplotlibなど)の知識が必要です．\nMacを使って講義を進めますが，環境が作れればWindowsでも問題ありません．\nDockerとJupyterLabを使った本格的なデータサイエンスの環境を使いますが，WindowsでDocker環境を作れれば，全く同じ環境を構築することができます．(Windowsでの環境構築のサポートはしておりません．あらかじめご了承ください)",
      "target_audience": [
        "AI開発やデータサイエンスに興味がある人",
        "データサイエンスのコンペ等に出たい人",
        "研究や授業で深層学習を勉強する必要がある人",
        "深層学習の基本を学びたい人",
        "これからAI開発のキャリアを目指している人"
      ]
    },
    {
      "title": "Memulai Tableau dari Nol untuk Pengolah Data Pemula",
      "url": "https://www.udemy.com/course/tableau-untuk-pemula/",
      "bio": "Jalur Singkat Mengolah Data, Membuat Dashboard, Merancang Story Pakai Tableau untuk Siapapun, tidak Harus Pro!",
      "objectives": [
        "Mengunduh dan menginstall Tableau",
        "Garis besar menggunakan Tableau bagi yang masih awam",
        "Mengambil sumber data dari MS Excel",
        "Membuat visualisasi data secepat kilat",
        "Memanfaatkan filter dan sortir data",
        "Bekerja dengan Worksheet dan membandingkannya dengan MS Excel",
        "Penataan Rows dan Columns pada Tableau",
        "Analisis terhadap data penjualan",
        "Menggunakan Color dan membuat hirarki data yang baik",
        "Melakukan presentasi menggunakan Presentation Mode",
        "Membuat Dashboard yang interaktif dan bisa dipraktikkan siapapun",
        "Menyusun Story untuk visual storytelling"
      ],
      "course_content": {
        "Pendahuluan": [
          "Introduksi",
          "Bagaimana Mendapatkan e-Certificate",
          "Video Course akan Dimulai!",
          "Mengunduh dan Menginstall Tableau"
        ],
        "Garis Besar Menggunakan Tableau": [
          "Connect to a File",
          "Membuka File MS Excel",
          "Membuat Sheet",
          "Visualisasi Data",
          "Kuis Pengantar Tableau"
        ],
        "Tableau bagi Pengguna MS Excel": [
          "Mempersiapkan MS Excel",
          "Memasukkan Data pada MS Excel",
          "Data Harus Rapi dan Valid",
          "Sheet pada MS Excel"
        ],
        "Mengambil Data dari SQL": [
          "Mengawali Pekerjaan Menggunakan SQL",
          "Membuat Tabel Data",
          "Menambah Data ke dalam Tabel",
          "Meng-Update Data",
          "Menghapus Data",
          "Join Data",
          "Bekerja dengan File CSV",
          "Tugas Menghubungkan Tableau dengan File CSV"
        ],
        "Dasar-Dasar Menggunakan Tableau": [
          "Mengenal Tipe Data pada Tableau",
          "Refresh Data Source",
          "Menggunakan Filter untuk Sortir Data",
          "Menggunakan Wildcard",
          "Worksheet pada Tableau",
          "Menata Rows dan Columns pada Sheet",
          "Perbandingan Antara Tableau dan MS Excel"
        ],
        "Analisis Data Menggunakan Tableau": [
          "Analisis Terhadap Sales",
          "Menggunakan Color",
          "Mengubah Isi Redaksi Tooltip",
          "Geografi pada Chart",
          "Membuat Hirarki",
          "Kuis Seputar Analisis Data"
        ],
        "Presentasi Data": [
          "Tombol Presentation Mode",
          "Menambahkan Animasi",
          "Membuat Dashboard",
          "Menyusun Story",
          "Menambahkan Teks pada Story",
          "Simpan dalam Bentuk Powerpoint",
          "Kuis Seputar Presentasi Data"
        ],
        "Bekerja dengan Dokumen": [
          "Menggunakan Copy",
          "Presentasi dalam Format PDF",
          "Penutup"
        ]
      },
      "requirements": [
        "Memiliki Tableau Desktop versi 2020 atau yang terbaru"
      ],
      "description": "Apakah Anda percaya kalau data bisa membawa PERUBAHAN BESAR? Kalau percaya, maka video course ini UNTUK ANDA!\n\n\nVideo ini adalah online course yang paling lengkap, to-the point, dan mudah dipahami untuk mengolah data memakai TABLEAU di UDEMY! Semua penjelasan disampaikan dalam Bahasa INDONESIA.\nTidak memandang apakah Anda belum pernah bekerja dengan data sebelumnya, atau sudah mengetahui cara paling dasar membuat pie chart, video course ini dirancang tentu saja untuk Anda! Dalam kursus ini, kami akan mengajari Anda menggunakan Tableau untuk seluruh kebutuhan olah data secara efektif dan singkat, tepat, serta jelas!\nDilengkapi dengan berjam-jam video course, quiz, dan artikel, kursus komprehensif ini tidak membutuhkan pengalaman apapun! Cukup Tableau Desktop yang bisa dimiliki siapapun. Kalau belum punya, cukup beli yang baru saja!\nVideo course  ini akan mengajarkan Anda mengolah data memakai Tableau dengan setiap bab dilengkapi screencast yang mengajarkan langkah-langkah, perintah, dan menu-menu pada Tableau dengan disertai penjelasan-penjelasan yang menarik! Tunggu apa lagi, ayo belajarlah dengan cara  yang terbaik untuk Anda!\nKami akan memulainya dengan cara mengunduh dan menginstall Tableau. Lantas, kami akan membantu Anda membuat desain-desain chart yang lebih kompleks dan mengupas langkah-langkah praktis lainnya.\nTopik yang akan dibahas kemudian adalah:\nMengunduh dan menginstall Tableau\nGaris besar menggunakan Tableau bagi yang masih awam\nMengambil sumber data dari MS Excel\nMembuat visualisasi data secepat kilat\nMemanfaatkan filter dan sortir data\nBekerja dengan Worksheet dan membandingkannya dengan MS Excel\nPenataan Rows dan Columns pada Tableau\nAnalisis terhadap data penjualan\nMenggunakan Color dan membuat hirarki data yang baik\nMelakukan presentasi menggunakan Presentation Mode\nMembuat Dashboard yang interaktif dan bisa dipraktikkan siapapun\nMenyusun Story untuk visual storytelling\n\n\nAyo, tunggu apa lagi! Jangan khawatir tentang kualitas video course ini sebab kami menawarkan GARANSI 30 HARI UANG KEMBALI TANPA SYARAT. Betul! Jika Anda tidak puas, silakan ajukan refund tanpa syarat. Tetapi kami bisa mengatakan kepada Anda bahwa video course ini adalah yang terlengkap dan terbaik tentang ilmu olah data menggunakan Tableau untuk semua golongan. Tidak percaya? Buktikan sendiri!",
      "target_audience": [
        "Analisis Data",
        "Peneliti yang sering memanfaatkan statistik",
        "Pengambil kebijakan berdasarkan data",
        "Marketing dan R&D (litbang) perusahaan"
      ]
    },
    {
      "title": "Análise de Dados com Python e Pandas",
      "url": "https://www.udemy.com/course/analise-de-dados-com-python-e-pandas/",
      "bio": "Domine a Análise de Dados: De Numpy e Pandas a Streamlit e Bancos de Dados, tudo com Python na prática!",
      "objectives": [
        "Aprenda os conceitos básicos da linguagem, como sintaxe, estruturas de controle e funções, essenciais para análise de dados.",
        "Domine o uso de Numpy para operações numéricas e Pandas para organizar, limpar e transformar dados.",
        "Crie gráficos impactantes com Matplotlib, Seaborn e Plotly para apresentar seus resultados de maneira clara e atraente.",
        "Aprenda a criar dashboards dinâmicos e interativos para visualização em tempo real de suas análises.",
        "Conecte-se a bancos de dados SQL e aprenda a extrair e manipular dados diretamente de bases como MySQL e PostgreSQL.",
        "Aplique todos os conceitos aprendidos em projetos reais, como análise de dados financeiros ou de vendas, culminando em um projeto final."
      ],
      "course_content": {
        "Introdução": [
          "Apresentação",
          "Apresentação do Instrutor",
          "Link para Nossa Comunidade",
          "Estrutura do Curso (Não Pule Essa Aula)"
        ],
        "Primeiros Passos": [
          "Instalação e Configuração do Python",
          "Ipynb x Py, Ambiente de Desenvolvimento, Pip",
          "Introdução a Versionamento com Git e Github"
        ],
        "Numpy Hands On": [
          "Introdução ao Numpy",
          "Criando Arrays com Dimensões",
          "Usando Indexação",
          "Fatiando Arrays",
          "Funções Universais",
          "Copy e View",
          "Aplicando o Reshape",
          "Iterando Arrays",
          "Aplicando Join",
          "Usando o Split",
          "Pesquisando em Arrays",
          "Consolidando os Conhecimentos",
          "Mini Projeto 1 - Caça ao Tesouro e Jogo da Velha"
        ],
        "Pandas - Hands On": [
          "Utilizando Estrutura Series",
          "Utilizando Estrutura Dataframe",
          "Analisando Dataframe",
          "Operações em Dataframe",
          "Importando Arquivo CSV",
          "Análise de Insights em Arquivo CSV",
          "Criando uma Planilha",
          "Analisando Dados da Planilha",
          "Criando e Importando JSON",
          "Analisando Dados do JSON",
          "Exporta Arquivo CSV para Banco de Dados",
          "Explorando Insights na Tabela com SQL",
          "Mini Projeto 2 - Dashboard de Compras com Pandas e Streamlit (Parte 1)",
          "Mini Projeto 2 - Dashboard de Compras com Pandas e Streamlit (Parte 2)",
          "Mini Projeto 2 - Dashboard de Compras com Pandas e Streamlit (Parte 3)"
        ],
        "Pandas - Transformação de Dados": [
          "Importando os Dados",
          "Transformando Dados Numéricos",
          "Transformando Dados Numéricos II",
          "Transformando Dados Textuais",
          "Transformando Dados Textuais II"
        ],
        "Estatística Aplicada": [
          "Conceitos Iniciais",
          "Definindo os Dados",
          "Medidas de Posição",
          "Medidas de Dispersão",
          "Medidas de Forma",
          "Entendendo a Correlação",
          "Compreendendo os Gráficos",
          "Histograma, BoxPlot e Scatter Plot",
          "Gráfico de Barras",
          "Gráfico de Linhas"
        ],
        "Análise Exploratória dos Dados": [
          "Importando os Dados",
          "Preparando os Dados",
          "Unindo Dataframe",
          "Tratando Valores Ausentes",
          "Distribuição Variáveis Categóricas",
          "Distribuição Variáveis Numéricas",
          "Filtros e Agrupamento",
          "Tabelas de Contigência",
          "Teste do Qui-Quadrado",
          "Correlação entre Variáveis",
          "Tratando Outliers",
          "EDA Automatizado",
          "O Analista Investigativo e o CEO Curioso"
        ],
        "DataViz - Fundamentos": [
          "Instalando o Matplotlib",
          "Criando um Gráfico de Linha",
          "Criando um Gráfico de Barra",
          "Criando um Gráfico de Dispersão",
          "Utilizando Histogramas",
          "Insights Datasets I",
          "Insights Datasets II",
          "Utilizando Fig e Subplot",
          "Reunindo 4 Gráficos em uma Figura",
          "Instalando o Seaborn",
          "Criando Gráfico HeatMap",
          "Criando Gráfico PairPlot",
          "Criando Gráfico ViolinPlot",
          "Instalando o Plotly",
          "Visualizações Interativas I",
          "Visualizações Interativas II",
          "Instalando o Folium",
          "Plotagem de Mapas",
          "Utilizando um Dataset"
        ],
        "Streamlit - Mini Projeto 3 - Desenvolvimento de Dashboard de Vendas": [
          "Criando Ambiente Virtual de Desenvolvimento",
          "Importando o Dataset",
          "Estruturando o Dashboard",
          "Criando Métricas",
          "Construindo a Tabela de Receitas por Estado",
          "Construindo o Gráfico de Receitas por Estado",
          "Construindo a Tabela de Receita Mensal",
          "Construindo o Gráfico de Receita Mensal",
          "Receitas por Estado em Gráfico de Barra",
          "Receitas por Categoria",
          "Receitas por Vendedores",
          "Quantidade de Vendas por Vendedores",
          "Adicionando Filtros",
          "Adicionando Página do Dataset",
          "Filtrando Colunas e Linhas",
          "Filtrando Colunas e Linhas II",
          "Download do Dataset",
          "Preparando a Aplicação",
          "Versionando a Aplicação",
          "Realizando o Deploy"
        ],
        "Integração com Banco de Dados (SQLite, PostgreSQL, MongoDB)": [
          "Criando o Banco de Dados e a Tabela",
          "Inserindo e Lendo Dados",
          "Atualizando e Excluindo Dados",
          "Criando uma Aplicação Web",
          "Utilizando o SQLAlchemy",
          "Criando uma Aplicação Desktop",
          "Lendo e Inserindo Dados no PostgreSQL",
          "Atualizando e Excluindo Dados no PostgreSQL",
          "Lendo e Inserindo Dados no MongoDB",
          "Atualizando e Excluindo Dados no MongoDB"
        ]
      },
      "requirements": [
        "Saber navegar no computador e utilizar ferramentas como editores de texto e navegadores de internet.",
        "O curso começa com os fundamentos do Python, então você pode ser iniciante na programação.",
        "O curso exige dedicação e prática contínua para assimilar os conceitos e aplicá-los em projetos reais."
      ],
      "description": "Neste curso, você aprenderá a dominar as principais ferramentas e bibliotecas do Python para análise de dados, desde os fundamentos da linguagem até a criação de dashboards interativos. Através de uma abordagem prática, você será capaz de realizar análises avançadas, trabalhar com grandes volumes de dados e apresentar resultados de forma clara e eficiente.\nO que você vai aprender:\nFundamentos de Python para Análise de Dados:\nSintaxe e estrutura básica do Python\nControle de fluxo, funções e manipulação de dados\nTrabalhando com Numpy:\nManipulação de arrays multidimensionais\nOperações matemáticas e lógicas com Numpy\nIndexação, slicing e operações vetorizadas\nManipulação e Análise de Dados com Pandas:\nEstruturas de dados: DataFrames e Series\nLeitura e escrita de arquivos CSV, Excel, JSON e SQL\nLimpeza e transformação de dados: tratamento de missing values, duplicatas, conversão de tipos\nOperações de agregação, filtragem e agrupamento\nTransformação de dados com funções de mapeamento e aplicação\nVisualização de Dados:\nCriação de gráficos com Matplotlib e Seaborn\nVisualizações interativas com Plotly\nComo escolher o gráfico certo para a sua análise\nDesenvolvimento de Dashboards com Streamlit:\nCriação de interfaces interativas com Streamlit\nIntegração de gráficos e tabelas dinâmicas\nConstrução de dashboards para visualização de resultados em tempo real\nConexão e Manipulação de Dados em Bancos de Dados:\nConexão com bancos de dados SQL (MySQL, PostgreSQL)\nConsultas SQL básicas e avançadas\nExtração e transformação de dados diretamente de bancos de dados\nProjetos Práticos:\nAplicação dos conceitos em projetos reais de análise de dados\nAnálise de dados financeiros, de vendas ou qualquer outro domínio de sua escolha\nDesenvolvimento de um projeto final que envolva Numpy, Pandas, visualização de dados e Streamlit\nAo final deste curso, você será capaz de realizar análises de dados completas, apresentar insights visuais impactantes e criar dashboards interativos, aplicando o poder do Python e suas bibliotecas em situações do mundo real.",
      "target_audience": [
        "Pessoas sem experiência prévia em programação que desejam aprender Python e aplicá-lo na análise de dados.",
        "Interessados em adquirir habilidades para analisar dados e tomar decisões baseadas em dados.",
        "Profissionais que buscam uma base sólida para entrar no campo da ciência de dados, começando pelo Python e suas bibliotecas essenciais.",
        "QueProfissionais que desejam expandir seus conhecimentos para a análise e visualização de dados usando Python.",
        "Profissionais que querem utilizar Python para automatizar tarefas, criar relatórios interativos e analisar dados para melhorar processos de negócios."
      ]
    },
    {
      "title": "Curso de STATA Completo - Do Básico ao Avançado",
      "url": "https://www.udemy.com/course/curso-de-stata-completo-do-basico-ao-avancado/",
      "bio": "Aprenda a abrir e tratar banco de dados e a calcular estatísticas descritivas",
      "objectives": [
        "O que é e pra que serve o Stata",
        "Abrir e tratar um banco de dados",
        "Principais comandos",
        "Estatística descritiva"
      ],
      "course_content": {
        "Introdução": [
          "Prévia do curso",
          "Por que o Stata?",
          "Sobre o curso",
          "Qual versão do Stata é a certa pra mim?",
          "Como baixar e instalar o Stata"
        ],
        "Iniciação ao Stata": [
          "Interface",
          "Do-file - Script",
          "Abreviações e sensibilidade",
          "Máscaras",
          "Configurações",
          "Diretórios",
          "Log-file - Gravando resultados",
          "Buscando ajuda",
          "Sintaxe - Estrutura dos comandos"
        ],
        "Principais comandos": [
          "Scripts e banco de dados do curso",
          "Operadores aritméticos, relacionais e lógicos",
          "Excluir variáveis e observações",
          "Renomear variáveis",
          "Legenda e rótulos de variáveis",
          "Alterar conteúdo de variáveis",
          "Criar variáveis - Parte 1",
          "Criar variáveis - Parte 2"
        ],
        "Estatísticas descritivas": [
          "Tipos de variáveis",
          "Variáveis discretas e categóricas",
          "Variáveis contínuas"
        ],
        "Integração com o Python": [
          "Como usar o Python no Stata"
        ],
        "Bônus": [
          "Link para redes sociais e outros cursos"
        ]
      },
      "requirements": [
        "Possuir o software Stata."
      ],
      "description": "Este curso possui aulas com explicações em vídeo sobre o Stata, um pacote de software completo e integrado que fornece tudo o que um cientista de dados precisa para: manipular e visualizar dados, calcular estatísticas, fazer análises econométricas e elaborar relatórios automatizados.\nNeste curso, além de conhecer os principais comandos do Stata para realizar tratamentos em base de dados, você vai aprender na prática como excluir variáveis e observações; renomear, inserir legendas e alterar o conteúdo de variáveis; e criar variáveis a partir de variáveis existentes. Tudo isso usando a base de dados da PNAD, a Pesquisa Nacional por Amostra de Domicílios do IBGE.\n\n\nMais benefícios do Stata:\n. O Stata é rápido, preciso e fácil de usar.\n. Possui excelentes recursos gráficos. O Stata facilita a geração de gráficos de vários estilos e com qualidade de publicação.\n. Pesquisa verdadeiramente reproduzível. O Stata é o único pacote estatístico que possui um controle de versão integrado. Isso significa que se você escreveu um script para realizar uma análise nos anos 80, esse mesmo script pode ser executado e produzirá os mesmos resultados hoje. Da mesma forma, o Stata poderá executar qualquer coisa que você fizer hoje daqui a 30 anos.\n. Integração com o Python. A partir da versão 16, você pode utilizar qualquer pacote do Python no Stata e também pode transferir, sem nenhum problema, dados e resultados entre o Stata e o Python.\n\n\nNão perca tempo, faça já a sua inscrição.\nAguardo você!",
      "target_audience": [
        "Estudantes em fase de elaboração de TCC: monografia, dissertação ou tese.",
        "Pesquisadores que desejam produzir artigos de alta qualidade.",
        "Cientistas de dados."
      ]
    },
    {
      "title": "Algoritmos Genéticos em Java",
      "url": "https://www.udemy.com/course/algoritmos-geneticos-em-java/",
      "bio": "Construa passo a passo um algoritmo de Inteligência Artificial aplicado no cenário de transporte de produtos!",
      "objectives": [
        "Aprenda na teoria e na prática os principais conceitos sobre os algoritmos genéticos, tais como: indivíduo, população, crossover/reprodução, mutação, função de avaliação/fitness e seleção de indivíduos",
        "Implemente um algoritmo genético passo a passo em Java para resolver um problema real de transporte de mercadorias",
        "Visualize as soluções do algoritmo genético utilizando gráficos",
        "Utilize o algoritmo genético integrado com uma base de dados no MySql"
      ],
      "course_content": {
        "Introdução e conteúdo do curso": [
          "Problema a ser resolvido",
          "Conteúdo do curso",
          "Algoritmos evolucionários e algoritmos genéticos",
          "Mais sobre Inteligência Artificial"
        ],
        "Algoritmos genéticos passo a passo": [
          "Instalação do Java e Netbeans",
          "Classe produtos",
          "Classe indivíduo I",
          "Classe indivíduo II",
          "Função de avaliação",
          "Crossover/reprodução - teoria",
          "Crossover/reprodução - implementação",
          "Mutação",
          "Inicialização da população",
          "Avaliação da população",
          "Melhor indivíduo",
          "Soma das avaliações",
          "Seleção dos indivíduos - teoria",
          "Seleção dos indivíduos - implementação",
          "Construção de nova geração",
          "Algoritmo genético completo I",
          "Algoritmo genético completo II",
          "Algoritmo genético completo III",
          "Gráfico das soluções",
          "Instalação do MySql",
          "Criação da tabela de produtos no MySql",
          "Algoritmo genético com banco de dados",
          "Biblioteca JGAP I",
          "Biblioteca JGAP II",
          "Biblioteca JGAP III",
          "Biblioteca JGAP IV"
        ],
        "Considerações finais": [
          "Considerações finais",
          "Código fonte completo",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "É recomendado conhecimento sobre lógica de programação, principalmente estruturas condicionais e de repetição",
        "Conhecimentos básicos em Java são desejáveis, embora seja possível acompanhar o curso sem saber essa linguagem com profundidade",
        "Noções sobre orientação a objetos são necessárias, principalmente conceitos como classe, objeto, atributo e método",
        "Não são necessários conhecimentos prévios sobre Inteligência Artificial",
        "Não são necessários conhecimentos prévios sobre banco de dados"
      ],
      "description": "Os algoritmos genéticos são uma importante área da Inteligência Artificial que são responsáveis pela resolução de problemas complexos, tendo como base encontrar soluções para problemas de otimização e busca. Existem várias aplicações práticas deste tipo de algoritmo, as quais podem ser aplicadas na resolução de problemas em cenários comerciais do dia a dia. Um exemplo clássico é a resolução do problema de choque de horários de professores em uma escola, no qual existem diversas combinações de horários e aulas e o objetivo é construir a grade de horário dinamicamente de acordo com a quantidade de aulas e a disponibilidade de cada professor. Outros exemplos são: empresas de telecomunicações podem projetar novas redes óticas, transportadoras podem planejar melhor a rota de entrega de mercadorias, investidores podem  escolher os melhores investimentos; dentre várias outras.\nBaseado nisso, neste curso você vai aprender na teoria e principalmente na prática como desenvolver do zero um algoritmo genético aplicado em um cenário real de uma transportadora. Neste contexto, nós seremos consultores de uma empresa de transporte que possui vários produtos a serem transportados, porém, a empresa possui somente um caminhão disponível e com espaço limitado de armazenamento. Nosso objetivo será desenvolver um algoritmo que consiga gerar a melhor combinação dos produtos que devem ser transportados, levando em consideração o fato de que a transportadora que ganhar o máximo de dinheiro possível com o frete e ocupando o espaço disponível no caminhão.\nEsse tipo de algoritmo é baseado em encontrar soluções cada vez melhores a partir da evolução das gerações anteriores, sendo fundamentado nos processos naturais de evolução. E para chegar em nosso objetivo, você vai aprender os principais conceitos sobre essa técnica de inteligência artificial, tais como: população, indivíduo, crossover/reprodução e mutação. Ao final do curso, você terá um algoritmo genético completo que conseguirá resolver o problema da transportadora, o qual pode ser aplicado para outros cenários comerciais. Utilizaremos a linguagem Java para a programação das funções e desenvolveremos tudo passo a passo e com muitos detalhes, para que você tenha uma visão bem clara e didática de como esses algoritmos conseguem resolver problemas reais do cotidiano. Além disso, teremos um bônus no qual você vai aprender como criar uma tabela de produtos no MySql e aplicar nosso algoritmo utilizando os dados de uma base de dados, o que pode facilitar a adaptação do código para utilização em ambientes comerciais. Por fim, este material pode ser considerado de nível iniciante para quem está entrando tanto na área de Inteligência Artificial quanto na área de algoritmos genéticos. Porém, caso você seja de nível mais avançado, este curso poderá servir como uma ótima fonte de consulta e revisão dos conceitos.\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial",
        "Pessoas interessadas em resolver problemas reais utilizando algoritmos genéticos"
      ]
    },
    {
      "title": "Data Science con Python – Visualización Matplotlib & Seaborn",
      "url": "https://www.udemy.com/course/data-science-con-python-visualizacion-matplotlib-seaborn/",
      "bio": "Domina las librerías de visualización más potentes de Python para Data Science y domina la Ciencia de Datos.",
      "objectives": [
        "Crear potentes visualizaciones con las librerías Matplotlib y Seaborn para el análisis de la información.",
        "Analizar series temporales y realizar previsiones.",
        "Automatizar sus tareas cotidianas con Python.",
        "Dominar el lenguaje de propósito general Python desde cero, incluyendo su instalación.",
        "Comprender y profundizar en el flujo completo de un proyecto de Data Science para convertirse en científico de datos.",
        "Aprender todos los conceptos de estadística necesarios para poder analizar los datos que le rodean.",
        "Adquirirá un conocimiento extenso en Data Science que podrá aplicar de inmediato a un precio muy asequible en comparación con otros programas."
      ],
      "course_content": {
        "Introducción al Análisis de Datos con Python": [
          "Bienvenida / Información importante",
          "¿Qué es Python y qué nos proporciona para el análisis de datos?",
          "Instalación Python + Jupyter",
          "Información importante para realizar los ejercicios",
          "Importar librerías y fuentes de datos",
          "Visualización básica con Matplotlib",
          "Visualización básica con Matplotlib - Caso Práctico"
        ],
        "Visualización de datos en Python - Matplotlib": [
          "Consejos para la visualización de datos",
          "Introducción a la librería Matplotlib",
          "Creación de un gráfico de línea, bar, scatter",
          "Personalización de gráficos (título, etiquetas, ticks, leyenda, límites de ejes,",
          "Creación de box & whiskers plot",
          "Creación de un histograma y CDF",
          "Gráfico de media móvil",
          "Visualización de gráficos múltiple (subplots)",
          "Aplicación de estilos",
          "Creación de gráficos a partir de objeto groupby",
          "Creación de histogramas en 2D",
          "Creación de mapas geográficos con basemap"
        ],
        "Visualización de datos en Python - Seaborn": [
          "Introducción a la librería Seaborn",
          "Seaborn - Creación de Regresión Lineal",
          "Seaborn - Stripplot",
          "Seaborn - Swarmplot",
          "Seaborn - Violinplot",
          "Seaborn - Jointplot",
          "Seaborn - Pairplot",
          "NOTA MÉTODO CORRELACIÓN",
          "Seaborn - Correlación con heatmap"
        ],
        "Series temporales en Python": [
          "Series temporales: Extracción y parsing",
          "Series temporales: Filtrado",
          "Series temporales: Remuestreo",
          "Series temporales: Interpolación",
          "Visualización de series temporales",
          "Previsiones basadas en datos históricos"
        ],
        "PROYECTO DATA SCIENCE - ANÁLISIS DE DATOS CON VISUALIZACIÓN": [
          "PROYECTO DATA SCIENCE: ANÁLISIS DE DATOS CON MATPLOTLIB & SEABORN"
        ],
        "Ejecución e interconexión de Python con otras plataformas": [
          "Generación de scripts de python y automatización de tareas",
          "Uso de Python en herramienta de Business Intelligence Power BI"
        ],
        "Fundamentos del lenguaje Python (OPCIONAL)": [
          "Variables en Python",
          "Creación de listas, extracción y modificación de datos",
          "Conceptos avanzados de creación de listas",
          "Uso de funciones en Python (in-built)",
          "Creación de funciones en Python y argumentos flexibles",
          "Funciones lambda",
          "Métodos en Python",
          "Cómo crear diccionarios en Python",
          "Uso de función zip para creación de diccionarios en base a listas",
          "Comparadores en Python",
          "Bucles en Python",
          "Comprensión de listas en python"
        ],
        "Conceptos Estadísticos para el Análisis de Datos (OPCIONAL)": [
          "Variables y conceptos básicos",
          "Varianza de una variable",
          "Correlación de variables",
          "Histogramas",
          "Análisis con percentiles",
          "Funciones densidad de probabilidad",
          "Cálculo de previsiones (forecast) y media móvil"
        ],
        "CONCLUSIONES Y CLASE EXTRA": [
          "Siguientes Pasos",
          "Clase Extra",
          "Recursos Extra"
        ]
      },
      "requirements": [
        "Ninguno, se utilizará el lenguaje Python para seguir el curso y se enseñará su instalación desde cero y bloques opcionales para adquirir los fundamentos del lenguaje si no los posee previamente."
      ],
      "description": "¿Quiere aprender a crear visualizaciones impactantes con las que dominar el área de Data Science?\nAl finalizar este curso podrá crear sorprendentes visualizaciones con base estadística de una manera muy sencilla con Python y sus librerías Matplotlib y Seaborn, lo que le hará pasar al siguiente nivel en el análisis de datos para obtener conclusiones que provoquen alto impacto en su entorno.\nAdemás, será capaz de analizar series temporales y crear previsiones basadas en tendencias y estacionalidades, algo muy útil para cualquier reto de negocio.\nAprenderá también a automatizar sus tareas diarias, puesto que Python es un lenguaje que le permite explotar áreas adicionales al Data Science.\nNo necesita conocer previamente Python o estadística, puesto que habrá bloques opcionales enfocados en enseñarle Python desde cero y los fundamentos estadísticos si lo necesita.\nEste curso tendrá un enfoque eminentemente práctico, se explicará paso a paso y en detalle cada nueva funcionalidad, pero el objetivo es que sea capaz de aplicar los nuevos conocimientos ejecutando los múltiples casos prácticos reales propuestos para poner a prueba las destrezas adquiridas.\nA su vez, tendrá a su disposición un material extenso de consulta y todos los scripts de Python explicados durante esta especialización de tal manera que le sea muy sencillo reutilizarlos para su caso de uso concreto.\nEs el momento de que pase a la acción, prepárese para un futuro dominado por los datos adquiriendo una habilidad muy importante para poder destacar sobre el resto y conseguir sacar el máximo provecho de la información.\nApúntese a la carrera profesional de mayor potencial del siglo XXI.\n---\nEscuche de otros alumnos por qué este es el curso de Visualización en Data Science MEJOR VALORADO en español:\n\"Excelente Instructor... el desarrollo del tema es muy secuencial... bien estructurado y fácil de seguir... se entiende muy bien... lo recomiendo\" -- Juan Carlos Murcia\n---\n*Este curso forma parte de una carrera en Data Science complementada con cursos adicionales.",
      "target_audience": [
        "Toda persona que quiera potenciar su perfil adquiriendo habilidades de análisis de datos con gran futuro.",
        "Estudiantes que quieran aprender desde cero una habilidad muy demandada en cualquier sector desde un punto de vista práctico.",
        "Personas que quieran asombrar a su audiencia con un enfoque analítico generando conclusiones que marcan la diferencia.",
        "Analistas que quieran profundizar en Python y las librerías Matplotlib y Seaborn para crear potentes visualizaciones que le aporten la clave del éxito."
      ]
    },
    {
      "title": "ChatGPT para Ciência de Dados e Machine Learning",
      "url": "https://www.udemy.com/course/chatgpt-para-ciencia-de-dados-e-machine-learning/",
      "bio": "Use o ChatGPT para agilizar a execução de projetos de Ciência e Análise de Dados, Aprendizagem de Máquina e IA",
      "objectives": [
        "Utilizar o ChatGPT como um co-piloto em seus projetos de Ciência de Dados e Machine Learning",
        "Implementar projetos sem digitar uma linha sequer de código, pois o ChatGTP fará a geração da codificação",
        "Extrair insights de bases de dados com a ajuda do ChatGTP",
        "Utilizar o ChatGTP para gerar código em Python, desde o carregamento dos dados até a análise dos resultados",
        "Gerar código em Python para projetos de processamento de linguagem natural"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Iniciando o ChatGTP",
          "ChatGTP para DS e ML",
          "Recursos para download"
        ],
        "Análise e exploração de dados": [
          "Estatísticas básicas",
          "Valores faltantes",
          "Outliers",
          "Relação entre pares",
          "Gráficos - atributos categóricos",
          "Gráficos - atributos numéricos",
          "Gráficos dinâmicos"
        ],
        "Machine learning": [
          "Atributos categóricos - LabelEncoder",
          "Dados desbalanceados",
          "Atributos categóricos - OneHotEncoding",
          "Transformação de escala",
          "Divisão da base de dados",
          "Algoritmos e avaliação",
          "Validação cruzada",
          "Tuning dos parâmetros",
          "Seleção de atributos",
          "Modelo final",
          "EXERCÍCIO - regressão",
          "Solução 1",
          "Solução 2",
          "Solução 3",
          "Solução 4",
          "Base de dados de tweets",
          "Pré-processamento dos textos",
          "Classificação de sentimentos"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação",
        "Programação básica em Python",
        "Básico sobre Machine Learning"
      ],
      "description": "Este curso abrange uma jornada empolgante na aplicação do ChatGPT no campo da Ciência de Dados e Machine Learning. Ao longo deste programa, você explorará a capacidade do ChatGPT como uma ferramenta valiosa na análise de dados, no pré-processamento e na construção de modelos de aprendizado de máquina sem precisar digitar uma linha sequer de código!\nNa primeira parte, mergulharemos nas técnicas fundamentais de análise de dados. Você aprenderá como extrair informações estatísticas cruciais de seus conjuntos de dados, lidar com valores ausentes e identificar e tratar valores atípicos (outliers). Exploraremos as relações entre as variáveis e a representação visual de dados categóricos e numéricos. Além disso, você terá a oportunidade de criar gráficos interativos, tornando a exploração de dados mais envolvente e informativa. Na segunda parte, nos aprofundaremos no campo do machine learning e você aprenderá a lidar com atributos categóricos usando técnicas como o LabelEncoder e o OneHotEncoding. Abordaremos o desafio de conjuntos de dados desbalanceados e discutiremos a importância da transformação de escala. Você também ganhará experiência na divisão eficaz de bases de dados, seleção de algoritmos apropriados e métodos de avaliação. A validação cruzada, tuning de parâmetros e seleção de atributos são partes essenciais do processo de modelagem, e você terá a oportunidade de aprimorar suas habilidades nessas áreas.\nAo concluir este curso, você estará equipado com habilidades avançadas em ciência de dados e machine learning, capacitado para aplicar o ChatGPT de forma eficaz em projetos do mundo real. Este programa oferece uma oportunidade única de melhorar suas habilidades analíticas e se destacar no campo da ciência de dados e do aprendizado de máquina. Prepare-se para alcançar um novo patamar em sua carreira profissional!",
      "target_audience": [
        "Profissionais que desejam explorar como o ChatGPT pode ser integrado em suas análises de dados e atividades de modelagem de machine learning",
        "Profissionais que trabalham no desenvolvimento de modelos de machine learning e desejam entender como o ChatGPT pode ser uma ferramenta valiosa no processo",
        "Alunos que buscam adquirir conhecimentos em análise de dados e machine learning, incorporando o ChatGPT em seu conjunto de habilidades",
        "Pessoas com conhecimentos técnicos em programação que desejam expandir suas habilidades em análise de dados e machine learning com a ajuda do ChatGPT",
        "Indivíduos que trabalham com análise de dados e desejam melhorar suas técnicas e abordagens usando o ChatGPT",
        "Entusiastas que desejam explorar o uso do ChatGPT como uma ferramenta de apoio em suas atividades de aprendizado de máquina"
      ]
    },
    {
      "title": "따라하며 익히는 파이썬 데이터수집 마스터",
      "url": "https://www.udemy.com/course/python_crawling/",
      "bio": "파이썬 설치부터 크롤링 마스터까지 with 데이터공방",
      "objectives": [
        "꼭 필요한 파이썬 문법을, 누구보다 쉽게 배웁니다.",
        "데이터 수집, 크롤링의 정수! 핵심 꿀팁까지 알게 됩니다.",
        "selenium을 이용한 브라우저 조작, 입력, 클릭을 할 수 있습니다.",
        "HTML에서 원하는 것을 찾을 수 있습니다(Feat BeautifulSoup)",
        "데이터 수집 결과를 엑셀 파일로 저장할 수 있습니다."
      ],
      "course_content": {
        "준비하기": [
          "강의 및 강사(\"데이터공방\") 소개",
          "파이썬 설치하기",
          "크롤링 방법 장단점 비교 설명",
          "크롤링은 합법? 불법? 판례로 살펴본 크롤링",
          "쥬피터노트북 살펴보기"
        ],
        "파이썬 익히기": [
          "컴퓨터와 소통하기",
          "숫자 데이터 다루기",
          "문자 데이터 다루기",
          "여러 개의 데이터 다루기(리스트)",
          "데이터 병합하기(리스트 합치기)",
          "반복 작업하기(for 반복문)",
          "조건에 따라 작업 진행하기(if 조건문)",
          "문자 데이터 자유자재로 사용하기(f-string, 문자열 포매팅)",
          "문자 데이터 내 맘대로 정리하기"
        ],
        "크롤링 기초": [
          "크롤링 준비하기(2023 New)",
          "브라우저 열기",
          "웹 페이지 접속하기 &URL 살펴보기",
          "얼렁뚱땅 HTML 살펴보기",
          "HTML 에서 원하는 정보 가져오기( BeautifulSoup.select() )",
          "태그에서 필요한 값 추출하기"
        ],
        "넷플릭스 크롤링(1page 크롤링)": [
          "넷플릭스 오리지널 페이지 살펴보기",
          "크롤링 계획 설계하기",
          "섹션 파트 나누기",
          "프로그램 파트 찾기1_섹션 제목 찾기",
          "프로그램 파트 찾기2_프로그램",
          "프로그램 정보 수집하기",
          "모든 프로그램 정보 수집하기(with 반복문)",
          "엑셀 파일에 저장하기"
        ],
        "인스타 크롤링": [
          "인스타그램 페이지 살펴보기",
          "인스타그램 크롤링 계획 설계하기",
          "로그인 하기",
          "태그 검색하기",
          "게시글 클릭하기",
          "다음 게시글 클릭하기",
          "[게시글 정보 수집] - 본문내용",
          "[게시글 정보 수집] - 좋아요 수",
          "[게시글 정보 수집] - 작성 일시",
          "여러 게시글 반복 수집하기 feat.오류점검하기",
          "수집 데이터 엑셀 파일에 저장하기"
        ],
        "유튜브 크롤링": [
          "유튜브 크롤링 소개",
          "인기영상 리스트 수집하기1",
          "인기영상 리스트 수집하기2",
          "영상정보 수집하기1(제목, 조회수, 업로드 일자)",
          "영상정보 수집하기2(좋아요, 싫어요, 채널명)",
          "댓글수집하기1-총댓글수확인하기",
          "댓글수집하기2-댓글가져오기",
          "(코드정리)원하는 만큼 댓글 가져오기"
        ]
      },
      "requirements": [
        "직접 타이핑하며 진행할 컴퓨터가 있으면 됩니다.",
        "프로그램 경험은 필요하지 않고, 과정 진행시 필요한 부분을 설명드리며 진행합니다."
      ],
      "description": "- 시행 착오는 제가 모두 겪었습니다. 저의 노하우를 쉽고, 빠르게 알려드리겠습니다.\n- 활용도가 낮은 것은 덜어내고, 사용도가 가장 높은 핵심들로만 눌러 담았습니다.\n- 그냥 보고 듣는 강의가 아니라, 하나 하나 타이팡 하면서 실습할 수 있도록 구성하였습니다.\n\n\n\n\nQ&A\nQ. 비 전공자도 들을 수 있나요?? 프로그래밍 언어 해본적이 없는데..\nA. 비전공자를 위한 강의로, 프로그램 설치부터 하나 하나 진행합니다. 괜히 어려운 용어나 언제 사용할지 모르는 명령어들은 덜어내고, 당장 활용도 높고 앞으로도 계속 사용할 명령어 위주로 구성하였습니다. 처음하셔도 충분히 진행 가능합니다.\n\n\nQ. 다른 강의와의 차이점은?\nA. 가능한 라이브코딩 환경에 맞추어 빈 파일에 하나하나 타이핑해가며 진행합니다. 이미지로 설명이 꼭 필요한 부분은 PPT 장표로 추가 설명을 진행합니다.\nPPT만 보고 지나가는 강의가 아닌.  이미 입력한 코드만 읽어주는 강의가 아닌.\n하나 하나 직접 입력하고 실행하고, 에러도 보고 결과도 살펴보는 완전 실전 활용을 위한 강의입니다.",
      "target_audience": [
        "인터넷에서 데이터 수집이 필요한 기획자, 마케터",
        "무작정 Ctrl + C, Ctrl + V 를 무한 반복하는 업무에 자괴감이 드는 분",
        "쇼핑몰 등에서 시장 동향 파악이 필요하신 분",
        "고객 VOC 나 최신 트렌드 등에 대해 발빠르게 수집하고 대응하려고 하는 분",
        "컴퓨터에 작업을 시키고, 진짜 중요한 일에 시간과 정성, 노력을 투자하고 싶으신 분"
      ]
    },
    {
      "title": "ChatGPTパーフェクトマスター講座 【豊富な機能の活用+データ生成のテクニック】を基礎から応用まで学ぼう",
      "url": "https://www.udemy.com/course/perfect-chatgpt/",
      "bio": "OpenAI社が提供するAIチャットサービス「ChatGPT」の使い方を徹底的に学ぶ講座です。 最先端の生成AIで、文章、画像などのデータを扱えるようになりましょう。ChatGPTをビジネス、教育、創作活動などで活用したい方におすすめです。",
      "objectives": [
        "OpenAI社が提供するAIチャットサービス「ChatGPT」の使い方を徹底的に学びます。",
        "ChatGPTの全体像、そしてその可能性について体験と共に学びます。",
        "ChatGPTに的確に質問をし、回答を評価する方法を学びます。",
        "ChatGPTの様々な機能、活用を順を追って学びます。",
        "ChatGPTを様々なタスクに応用し、実践的なスキルを習得します。",
        "GPTs、iPhoneアプリ、デスクトップアプリ、API（OpenAI Playground上で）などについて学びます。"
      ],
      "course_content": {
        "ChatGPTの概要と基本的な使い方": [
          "教材の使用方法",
          "Section1で使うWebページとプロンプト",
          "イントロダクション",
          "講座の概要",
          "ChatGPTとは？",
          "OpenAIのアカウント作成",
          "ChatGPTの体験",
          "セクション1の演習"
        ],
        "ChatGPTの様々な機能": [
          "Section2の概要",
          "ChatGPTの基本設定",
          "ChatGPTをカスタマイズする",
          "Googleドライブとの接続",
          "注: Windows版デスクトップアプリについて",
          "iPhoneアプリ、デスクトップアプリの使い方",
          "GPTsの使い方",
          "セクション2の演習"
        ],
        "ChatGPTの応用": [
          "Section3で使うWebページとプロンプト",
          "Section3の概要",
          "APIを利用する",
          "ビジネスにおける応用",
          "教育における応用",
          "創作活動における応用",
          "ChatGPTの課題",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "2024年6月の環境で解説しています。最新の環境と異なる可能性があります。",
        "人工知能、機械学習の技術的な知識は不要です。",
        "ローカル環境はWindowsでもMacでも大丈夫です。",
        "OpenAIのアカウント開設が必要です。",
        "Open AIの無料のプランでも受講できますが、無料の場合一部の機能が利用できません。",
        "ChatGPT Plus（20＄/月）に加入すれば、講座の内容を全て網羅できます。"
      ],
      "description": "「ChatGPTパーフェクトマスター講座」は、OpenAI社が提供するAIチャットサービス「ChatGPT」の使い方を徹底的に学ぶ講座です。\n最先端の生成AIを扱えるようになりたい方におすすめです。\n\n\nChatGPTは人間の会話のような自然なやりとりが可能で、文章の生成や要約、質問応答、翻訳など、幅広い用途で活用できます。\nAIモデルには「ChatGPT-3.5」、「ChatGPT-4」に加え、「GPT-4o」も利用可能です。\nGPT-4oはマルチモーダルモデルで、テキストだけでなく画像や音声、動画の入力にも対応しています。\n\n\n本講座では、最初にChatGPTの概要を学んだ上で、様々な機能、活用を順を追って学んでいきます。\nさらに、GPTs、デスクトップアプリ、API（OpenAI Playground上で）などを試しながら、実践的なスキルを習得します。\nChatGPTをマスターし、様々なデータを創造する力を身につけましょう。\n\n\n講座の内容は以下の通りです。\nSection1. ChatGPTの概要と基本的な使い方\n→ ChatGPTの概要と、基本的な使い方について学びます。\nSection2. ChatGPTの様々な機能\n→ ChatGPTの様々な機能を一通り学びます。\nSection3. ChatGPTの応用\n→ ChatGPTを様々なタスクに応用します。",
      "target_audience": [
        "ChatGPTをビジネス、教育、創作活動などで活用したい方。",
        "AIのサポートにより文章作成、画像生成を効率化したい方。",
        "ChatGPTの機能を一通り修得したい方。",
        "生成AIの新たな可能性を模索したい方。",
        "AI技術のトレンドに追随したい方。"
      ]
    },
    {
      "title": "【基礎から学ぶ】自然言語処理から大規模言語モデルLLMへ~Pythonで実践してみよう",
      "url": "https://www.udemy.com/course/llm_python/",
      "bio": "ChatGPT/生成AIの基本技術でもある「大規模言語モデル(LLM)」について学び、これからのAI社会における基礎を身につけましょう！PythonとGoogle ColabでLLMのファインチューニングに挑戦します",
      "objectives": [
        "自然言語処理の基本",
        "機械学習・ディープラーニングの基本",
        "単語分散表現",
        "畳み込みニューラルネットワークCNN",
        "RNN, LSTM",
        "エンコーダ, デコーダ",
        "Transformerの構造",
        "大規模言語モデルLLMとは",
        "事前学習済みLLMモデルを使ってみよう",
        "事前学習済みLLMモデルのファインチューニング"
      ],
      "course_content": {
        "紹介": [
          "コース紹介",
          "サンプルコードのダウンロード",
          "コース準備レクチャー"
        ],
        "自然言語処理の基礎": [
          "自然言語処理の分野",
          "形態素解析",
          "Bag-of-Words",
          "TF-IDF",
          "単語分散表現（Word2Vec）",
          "コサイン類似度"
        ],
        "ディープラーニングの基礎": [
          "ニューラルネットワーク",
          "目的関数",
          "活性化関数",
          "確率的勾配降下法",
          "ミニバッチ学習",
          "Epochとイテレーション",
          "誤差逆伝播法",
          "勾配消失とRELU",
          "CNN①",
          "CNN②",
          "RNN",
          "LSTM"
        ],
        "Transformer": [
          "系列変換",
          "エンコーダ・デコーダ",
          "Transformerのアーキテクチャ",
          "エンコーダ-位置埋め込み",
          "セルフアテンション",
          "エンコーダ-マルチヘッドアテンション",
          "エンコーダ-フィードフォワード層と活性化関数",
          "エンコーダ-残差結合",
          "デコーダ"
        ],
        "大規模言語モデルLLM": [
          "大規模言語モデルLLMとは",
          "GPTモデル",
          "BERTモデル",
          "T5モデル",
          "多言語対応",
          "トークナイゼーション",
          "事前学習済みモデルの小規模化",
          "RLHF（害意のないモデルにする手法）",
          "再学習",
          "PEFTによるファインチューニング"
        ],
        "LLMの演習①~事前学習済みモデルの使用": [
          "演習の内容",
          "データのダウンロード",
          "テキスト分類①",
          "テキスト分類②",
          "テキスト分類③",
          "質疑応答",
          "文章の要約"
        ],
        "LLMの演習②~事前学習済みモデルのファインチューニング（感情分析）": [
          "データセットの読み込み",
          "トークン化",
          "事前学習モデルの指定",
          "PEFTの設定",
          "再学習の設定",
          "メトリクスの設定と再学習の実施",
          "評価（混同行列の作成）"
        ],
        "LLMの演習③~独自データの使い方": [
          "独自データの読み込み",
          "独自データのエンコーディング"
        ],
        "ボーナスレクチャー": [
          "ボーナス"
        ]
      },
      "requirements": [
        "簡単なPythonプログラミング経験",
        "Google Colaboratoryを使うためのGoogleアカウント"
      ],
      "description": "本コースは、自然言語処理の基礎から大規模言語処理LLM時代への流れを説明しつつ、LLMの事前学習済みモデルを使用し、ファインチューニングの演習までを行うコースとなっています。\n大規模言語モデルLLMはChatGPTを始めとして、今ではさまざまな場面で使われる技術になってきましたが、実際にその裏側の技術についてはよくわからないという方も多いかと思います。\nなので、本コースを通じて、大規模言語モデルとはどのようなものなのか、今までの自然言語処理からどのように発展してきたのか、どのように大規模言語モデルをファインチューニングするのか、Pythonで実践することでを学び、これからの加速する時代に備えていきましょう！\n\n\n目次\n自然言語処理の基礎\nディープラーニングの基礎\nTransformer\n大規模言語モデル(LLM)\nPythonでLLMを使う演習\n事前学習済みモデルの使用\n事前学習済みモデルのファインチューニング\n独自データの使用方法\n\n\n対象\nChatGPTなどの生成AIに興味はあるが、その裏側の技術はよくわからないという人\n大規模言語モデルを使ってみたい人\n簡単に事前学習済みのファインチューニングにチャレンジしたい人\n\n\n注意\nすでに業務などで大規模言語モデルを扱っている方には向きません（LLM初心者向け）\nGoogle Colaboratoryの無料アカウントを使って演習を行っています。もし有料アカウントや、自前のGPU環境がある方はそちらをお使いください\nディープラーニングの基礎パートは他コースでも使用している動画になりますので、ご了承ください",
      "target_audience": [
        "大規模言語モデルLLMというワードは知っているが実際にはよくわからないという方",
        "ChatGPTなどの生成AIの基礎となるLLMの技術に興味がある方",
        "LLMの事前学習済みモデルを使ってみたい方、ファインチューニングしてみたい方"
      ]
    },
    {
      "title": "Langchain: Crie Agentes de IA e Apps com LLMs e LlamaIndex",
      "url": "https://www.udemy.com/course/langchain-desenvolva-agentes-e-aplicacoes-ia-com-llms/",
      "bio": "Domine OpenAI, LangChain, LlamaIndex, Groq, RAG, N8N, Modelos LLMs, HuggingFace e a Criação de Agentes Inteligentes",
      "objectives": [
        "Criar chatbots personalizados usando os modelos da OpenAI.",
        "Utilizar function calling para integrar modelos com sistemas externos.",
        "Gerar e editar imagens com DALL·E e trabalhar com áudio usando Whisper.",
        "Construir prompts eficazes e otimizados com LangChain.",
        "Estruturar e interpretar saídas de modelos usando output parsers.",
        "Implementar memória em interações para criar diálogos mais contextuais.",
        "Integrar RAG (Retrieval-Augmented Generation) para acessar informações externas.",
        "Criar agentes autônomos que realizam tarefas complexas e dinâmicas.",
        "Aplicar boas práticas de LangChain para fluxos eficientes e escaláveis."
      ],
      "course_content": {},
      "requirements": [
        "Conhecimentos básicos de programação: Familiaridade com pelo menos uma linguagem como Python é essencial para acompanhar as implementações práticas.",
        "Entendimento básico de APIs: Saber consumir e integrar APIs facilitará a interação com ferramentas como OpenAI e LangChain.",
        "Curiosidade e vontade de aprender: Estar disposto a explorar novas tecnologias e conceitos, mesmo que sejam desafiadores no início."
      ],
      "description": "Este curso foi desenvolvido para proporcionar uma experiência prática e profunda no uso de modelos de linguagem, ferramentas avançadas e estratégias de implementação voltadas para a criação de soluções baseadas em inteligência artificial. A seguir, apresentamos os tópicos que serão abordados:\nSeção 1: OpenAI e Suas Ferramentas Poderosas\nIntrodução aos Modelos de Linguagem da OpenAI:\nCompreenda os fundamentos dos modelos como GPT-4, suas capacidades, limitações e potenciais de aplicação.\nConstruindo Chatbots Personalizados:\nAprenda a criar chatbots sofisticados e altamente customizáveis para atender às necessidades específicas do usuário.\nFunction Calling:\nEntenda como utilizar o recurso de function calling para integrar modelos a sistemas externos e realizar chamadas dinâmicas de funções.\nExplorando Imagens com DALL·E:\nDescubra como gerar, editar e utilizar imagens criadas com DALL·E em soluções práticas.\nTrabalhando com Áudio:\nExplore o potencial das ferramentas de reconhecimento e síntese de voz da OpenAI, como Whisper e outros recursos inovadores.\nMelhores Práticas de Integração:\nSaiba como conectar as ferramentas OpenAI de maneira eficiente a outras tecnologias e APIs.\nSeção 2: Fundamentos e Ferramentas do LangChain\nIntrodução ao LangChain:\nDescubra como o LangChain facilita a integração de LLMs em fluxos de trabalho complexos.\nModelos (Models):\nConfigure e gerencie LLMs e seus parâmetros para diferentes necessidades.\nTemplates de Prompts:\nCrie e otimize prompts utilizando as classes de prompt template para maximizar a eficácia do modelo.\nAnálise de Saída (Output Parser):\nAprenda a estruturar e interpretar as respostas dos modelos para garantir a consistência dos resultados.\nMemória:\nExplore como implementar memória em interações, permitindo conversas contextuais e mais naturais.\nRAG (Retrieval-Augmented Generation):\nIntegre bancos de dados externos e estratégias de recuperação de informações para enriquecer as respostas do modelo.\nEstratégias de Depuração:\nIdentifique e corrija problemas em fluxos construídos com LangChain.\nSeção 3: Boas Práticas e Criação de Agentes Inteligentes\nPráticas Avançadas com LangChain:\nTécnicas para aumentar a eficiência e a precisão dos fluxos, com foco em escalabilidade.\nConstrução de Agentes Inteligentes:\nDesenvolva agentes autônomos que realizam tarefas complexas, como consultas dinâmicas, execução de ações e tomada de decisões.\nOtimização de Fluxos:\nMelhore a performance e a integração dos agentes em diferentes sistemas.\nGestão de Recursos e Monitoramento:\nAprenda a monitorar e ajustar o uso de modelos e agentes para otimizar custos e desempenho.\nCases Reais e Aplicações Práticas:\nEstudo de casos reais e demonstrações práticas para inspirar e guiar implementações futuras.",
      "target_audience": [
        "Desenvolvedores de software que desejam integrar inteligência artificial em aplicações e fluxos de trabalho.",
        "Profissionais de tecnologia e dados interessados em soluções inovadoras baseadas em LLMs e automação.",
        "Empreendedores e líderes de projetos que buscam criar produtos ou serviços inteligentes com IA.",
        "Entusiastas de inteligência artificial que querem entender e dominar ferramentas avançadas como OpenAI e LangChain.",
        "Educadores e pesquisadores interessados em aplicar agentes e modelos de linguagem em contextos acadêmicos ou de aprendizado."
      ]
    },
    {
      "title": "はじめてのベイズ統計【PyMC3+Colab】-確率･統計の基礎からベイズ推定のPython実装まで-",
      "url": "https://www.udemy.com/course/bayesian/",
      "bio": "機械学習と親和性の高い、ベイズ統計の初心者向けコースです。確率･統計の基礎から初めて、ベイズ推定によるA/Bテスト、線形回帰などを学びます。Google Colaboratory環境でライブラリPyMC3を使い、ベイズ推定を実装します。",
      "objectives": [
        "ベイズ統計の基礎的な知識を学びます。",
        "Python、PyMC3で記述されたベイズ推定のコードが読めるようになります。",
        "自分の力で、ベイズ推定を実装する力が身に付きます。",
        "確率･統計の基礎、ベイズの定理を理解できるようになります。",
        "ライブラリPyMC3の扱い方を学びます。",
        "ベイズ推定を使った簡単なA/Bテストを実装できるようになります。"
      ],
      "course_content": {
        "ベイズ統計の概要": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "ベイズ統計の概要",
          "開発環境について",
          "LaTeXの基礎",
          "演習"
        ],
        "確率･統計の基礎": [
          "セクション2の教材",
          "Section2の概要",
          "確率の基礎",
          "基本的な統計量",
          "正規分布",
          "共分散と相関係数",
          "尤度",
          "演習"
        ],
        "ベイズ統計の基礎": [
          "セクション3の教材",
          "Section3の概要",
          "ベイズの定理",
          "最尤推定",
          "PyMC3の基礎",
          "演習"
        ],
        "ベイズ統計の応用": [
          "セクション4の教材",
          "Section4の概要",
          "ベイズ推定の実装",
          "二項分布の利用",
          "PyMC3によるA/Bテスト",
          "演習"
        ],
        "ベイズ統計と機械学習": [
          "セクション5の教材",
          "Section5の概要",
          "機械学習の概要",
          "ベイズ推定による線形回帰 Part1",
          "ベイズ推定による線形回帰 Part2",
          "ベイズ推定による分類",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Google Colaboratoryを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。",
        "何らかのプログラミング経験があった方が望ましいです。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "高校レベル以上の数学の知識が必要です。",
        "機械学習やデータサイエンス、深層学習について詳しい解説はありません。"
      ],
      "description": "「はじめてのベイズ統計」は、ベイズ統計の基礎を学ぶ初心者向け講座です。\nGoogle Colaboratory環境で、Pythonのコードを書きながらベイズ統計について学びます。\n\n\nベイズ統計は、「ベイズの定理」を基本的な考え方とする統計学で、社会で広く活用されています。\nまた、人工知能、機械学習との親和性が近年注目を集めています。\n本講座では、最初にベイズ統計の概要、開発環境であるGoogle Colaboratoryの基礎を学んだ上で、確率･統計を基礎から学びます。\nさらに、ベイズ統計の基礎、応用へと進み、最後に機械学習と関連付けます。\n\n\nベイズ統計はビジネスの現場だけではなく、情報、医療、保健、脳科学、宇宙論など様々な領域で応用が可能です。\nPyMC3などのライブラリなどを活用しながら、ベイズ統計を楽しく学んでいきましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! 人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. ベイズ統計の概要\n→ ベイズ統計の概要、および開発環境などについて学びます。\nSection2. 確率･統計の基礎\n→ ベイズ統計の基礎として、確率･統計を学びます。\nSection3. ベイズ統計の基礎\n→ 「ベイズの定理」をベースにベイズ統計を基礎から学びます。\nSection4. ベイズ統計の応用\n→ ベイズ統計を使い、様々な問題に対処する方法を学びます。\nSection5. ベイズ統計と機械学習\n→ 機械学習を、ベイズ統計と関連付けて学びます。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "ベイズ統計に興味があるけど、学び方が分からない方。",
        "ベイズ統計の難しい数式に辟易した方。",
        "ベイズ推定のコードをPython、PyTorchを使って書けるようになりたい方。",
        "仕事上、ベイズ統計の知識が必要になった方。",
        "ベイズ統計で何らかの問題を解決したい方。"
      ]
    },
    {
      "title": "Google Cloud Platform pour Data Engineers : Projet pratique",
      "url": "https://www.udemy.com/course/elt-bigquery-gcp/",
      "bio": "ELT avec BigQuery, GCS, Airflow, Python et SQL - Projet réel sur GCP, de l'ingestion des données au Machine Learning.",
      "objectives": [
        "Comprendre les concepts clés de l'ingénierie des données et la différence entre ETL et ELT afin de mieux structurer les flux de données dans vos projets.",
        "Explorer GCP et utiliser les services Data & Analytics, comme BigQuery, Cloud Storage et Cloud Composer, pour bâtir des pipelines de données efficaces.",
        "Extraire et stocker des données dans Google Cloud Storage en automatisant le téléchargement de fichiers PARQUET de données brutes à l’aide d'un script Python.",
        "Charger et transformer des données dans BigQuery, en concevant des datasets et des tables optimisés pour des analyses avancées.",
        "Orchestrer et automatiser un pipeline ELT avec Apache Airflow (Google Composer), en planifiant et surveillant l’exécution des flux de données.",
        "Analyser les données avec SQL dans BigQuery, en créant des Vues et en répondant à des questions Métier sur la demande du marché, le comportement des clients, ..",
        "Créer des rapports interactifs avec des Notebooks BigQuery et Python, pour visualiser et interpréter les tendances de manière efficace.",
        "Construire, Evaluer des modèles de Machine Learning avec BigQuery ML et réaliser des prédictions en utilisant uniquement SQL"
      ],
      "course_content": {
        "Introduction – Lancement du Cours": [
          "Présentation du cours et des objectifs",
          "Scénario du Projet : Mission complète pour un Consultant Data Engineer",
          "Objectifs, Prérequis et Public cible du Cours"
        ],
        "Bases Essentielles de la Data Engineering à connaître pour comprendre ce cours": [
          "Comprendre le concept de Data Warehouse",
          "ETL vs ELT : Quelle différence et quel impact ?",
          "De ETL à ELT : L'évolution de l'ingénierie des données dans le cloud"
        ],
        "Premiers Pas avec Google Cloud Platform (GCP)": [
          "Créer un compte GCP et explorer la console",
          "Créer un projet GCP et épingler les services clés",
          "Présentation des Services GCP utilisés dans ce projet"
        ],
        "Extraction des Données vers Google Cloud Storage (GCS)": [
          "Ressources du projet",
          "Installation de l’environnement et des dépendances sur Cloud Shell",
          "Création d’un Bucket GCS et upload du projet",
          "Exploration des fichiers sources et réflexion sur leur téléchargement automatisé",
          "Limites du script simple de téléchargement des fichiers sources de données",
          "Mise en place et exécution du Script d’extraction des données vers GCS"
        ],
        "Chargement et Structuration des Données dans BigQuery": [
          "Introduction à Google BigQuery et son rôle dans un pipeline ELT",
          "Création d’un Dataset et de Tables dans BigQuery",
          "Réflexion sur la Méthode à adopter pour charger les données de GCS vers BigQuery",
          "Analyse des Schéma des fichiers Parquet téléchargés dans GCS",
          "Ma solution pour l'exercice de chargement des données dans une database SQLite",
          "Mise en place et exécution du Script de chargement des données dans BigQuery",
          "Vérification des résultats et conclusion de la phase Load du pipeline ELT"
        ],
        "Transformation des Données dans BigQuery": [
          "Pourquoi transformer les données ? Objectifs et enjeux",
          "Créer et gérer des datasets BigQuery avec Python",
          "Exécution du pipeline de transformation et validation des résultats"
        ],
        "Orchestration du Pipeline ELT avec Cloud Composer (Airflow)": [
          "Introduction à l’orchestration des workflows de Data Engineering",
          "Comprendre un DAG Airflow à travers un exemple pratique",
          "Présentation et explication du code du DAG du pipeline ELT",
          "Création et Configuration d'un Service Cloud Composer (Airflow)",
          "Déploiement du DAG sur Google Cloud Composer et monitoring sur Airflow UI",
          "Résumé et prochaines étapes pour un Data Engineer avancé"
        ],
        "Analyse des Données et Création de Vues SQL dans BigQuery": [
          "Utilisation des Vues SQL pour répondre à des questions Business",
          "Analyse de la demande du marché, la saisonnalité et du Comportement des clients",
          "Utilisation de ChatGPT pour comprendre et améliorer un code SQL",
          "Analyse tarifaire et financière des trajets en taxi",
          "Benchmark concurrentiel et performance opérationnelle"
        ],
        "Reporting et Visualisation avec les Notebooks Python dans BigQuery": [
          "Introduction aux Notebooks Python intégrés à BigQuery",
          "Création de rapports interactifs sur la demande et le comportement client",
          "Reporting des tendances et performances financières dans les Notebooks"
        ],
        "Machine Learning avec SQL dans BigQuery ML": [
          "Introduction à BigQuery ML et ses cas d’usage",
          "Préparation des données et création des tables Train et Test dans BigQuery",
          "Construction d’un modèle Boosted Tree Regressor et analyse des résultats",
          "Entraînement d’un modèle Random Forest et comparaison des performances",
          "Évaluation des modèles sur un jeu de test et choix du meilleur modèle",
          "Prédictions sur de nouvelles données et analyse de l’importance des variables"
        ]
      },
      "requirements": [
        "Connaissance basique de SQL : Une compréhension des requêtes SQL de base (SELECT, WHERE, GROUP BY, JOIN) sera un plus pour l’analyse dans BigQuery.",
        "Notions de base en Python : Vous devez savoir écrire et exécuter des scripts simples (boucles, conditions, manipulations de fichiers).",
        "Un compte Google Cloud Platform (GCP) : Nous verrons ensemble comment en créer un gratuitement, mais vous aurez besoin d’un compte pour pratiquer.",
        "Une connexion Internet stable : Puisque nous travaillons sur le cloud, une bonne connexion est nécessaire pour suivre le cours et exécuter les exercices pratiques."
      ],
      "description": "I/ Description du cours\n\n\nLes entreprises gèrent aujourd’hui d’énormes volumes de données et ont besoin de solutions robustes pour collecter, transformer et analyser ces données efficacement. Google Cloud Platform (GCP) offre un écosystème puissant permettant de mettre en place des pipelines de données performants et évolutifs.\nCe cours, entièrement basé sur la pratique, vous guidera dans la construction d’un pipeline ELT (Extract, Load, Transform) complet en exploitant BigQuery, Google Cloud Storage (GCS), Apache Airflow, Python et SQL. Vous travaillerez sur un projet réel et suivrez les étapes essentielles d’un Data Engineer en entreprise, de l’ingestion des données jusqu’à l’analyse avancée et la modélisation prédictive avec des algorithmes de Machine Learning.\n\n\nII/ Ce que vous allez apprendre\n\n\nIngestion des données dans Google Cloud Storage (GCS) et chargement dans BigQuery\nTransformation des données et gestion des performances dans BigQuery\nOrchestration et automatisation des pipelines avec Apache Airflow\nNettoyage et manipulation des données avec Python et SQL\nAnalyse des données dans BigQuery pour répondre à des problématiques Business\nConstruction et évaluation de modèles de Machine Learning directement dans BigQuery\nRéalisation d’inférences et exploitation des résultats pour la prise de décision\nBonnes pratiques pour optimiser les coûts et la performance sur GCP\nIII/ Pourquoi suivre ce cours ?\n\n\nApproche 100 % pratique : mise en œuvre d’un projet réel de bout en bout\nUtilisation des technologies et concepts recherchés en entreprise : GCP, BigQuery, Airflow, ELT, SQL, Machine Learning\nCours structuré comme un projet industriel pour acquérir une expérience concrète\nMises à jour et accès à vie\nÀ la fin de ce cours, vous serez en mesure de concevoir et déployer un pipeline de données sur GCP, d’analyser des données pour répondre à des questions stratégiques et de mettre en place des modèles prédictifs exploitables en production.\nInscrivez-vous dès maintenant et développez vos compétences en ingénierie des données et en analyse avancée sur Google Cloud Platform (GCP).",
      "target_audience": [
        "Les Data Engineers souhaitant renforcer leurs compétences en ELT et en orchestration avec Cloud Composer (Airflow) sur GCP, mais aussi aller au-delà des pipelines en développant leur expertise en Data Analysis et Machine Learning pour devenir des spécialistes complets de la Data.",
        "Les Data Analysts et Data Scientists désireux de mieux comprendre les pipelines de données et d’exploiter BigQuery pour l’analyse avancée et le Machine Learning.",
        "Les Développeurs et Ingénieurs Logiciels voulant se spécialiser dans le traitement des données et l’optimisation des workflows data.",
        "Les Étudiants et personnes en reconversion qui veulent apprendre à manipuler des données à grande échelle avec des outils cloud modernes.",
        "Les Consultants et Freelancers souhaitant proposer à leurs clients des solutions complètes de valorisation des données, allant de l’ingestion à l’analyse, et se démarquer sur le marché avec une expertise en Data Engineering sur GCP.",
        "Les personnes en recherche d'emploi dans la DATA qui veulent enrichir leur portfolio avec un projet complet afin d’attirer l’attention des recruteurs."
      ]
    },
    {
      "title": "LangChainを学ぼう！ -手軽に実現するLLM（大規模言語モデル）アプリ開発の効率化-",
      "url": "https://www.udemy.com/course/langchain-llm/",
      "bio": "LLM、生成AIの利用を強力にサポートするライブラリ「LangChain」を学ぶ講座です。最初にLanChainの概要を学んだ上で、基礎、様々な機能、応用を順を追って学んでいきます。開発環境はGoogle Colaboratoryです。",
      "objectives": [
        "LangChainを使ったLLMアプリ構築を基礎から体験と共に学びます。",
        "LangChainが持つ様々な機能の使い方を学びます。",
        "LangChainの様々な応用を学びます。",
        "LangChainの全体像、そしてその可能性について学びます。"
      ],
      "course_content": {
        "LangChainの概要": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "LangChainの概要",
          "開発環境について",
          "OpenAIのアカウント作成",
          "LangChainの動作確認",
          "セクション1の演習"
        ],
        "LangChainの基礎": [
          "セクション2の教材",
          "Section3の概要",
          "LangChain Expression Language",
          "シンプルなLangChainアプリ",
          "セクション2の演習"
        ],
        "LangChainの様々な機能": [
          "セクション3の教材",
          "Section3の概要",
          "Streaming",
          "Agents",
          "Chains",
          "Memory",
          "セクション3の演習"
        ],
        "LangChainの応用": [
          "セクション4の教材",
          "Section4の概要",
          "ngrokの設定",
          "シンプルなチャットボット",
          "翻訳アプリ",
          "Streamlit Community Cloudへの登録",
          "アプリのデプロイ",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "2024年2月の環境で解説しています。最新の環境と異なる可能性があります。",
        "コードを動かすためにGoogle Colaboratoryを使用しますが、ローカル環境はWindowsでもMacでも大丈夫です。",
        "OpenAIとGoogleのアカウント開設が必要です。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "ChatGPT APIの利用は2024.2時点で有料で、クレジットカードの登録が必要です。上限金額を設定することが可能です。",
        "Webアプリの構築、公開のためにStreamlitというフレームワークを使います。"
      ],
      "description": "「LangChainを学ぼう！」は、LLM（大規模言語モデル）の利用を強力にサポートするライブラリ「LangChain」の使い方を学ぶ講座です。\nLLMを使った独自のアプリを開発したい方におすすめです。\n\n\nLangChainは様々な機能を有しており、LLMアプリの可能性を広げ、開発を効率化します。\nプロンプトの管理と最適化や、外部データを用いた回答の生成などを容易に実現します。\nまた、OpenAI社のモデルだけではなくGoogle社のPalmやMeta社のLlamaなど、様々なLLMを使い分けることができます。\n\n\n本講座では、最初にLangChainの概要を学んだ上で、基礎、様々な機能、応用を順を追って学んでいきます。\nLangChainを使いこなし、独自のLLMアプリを効率的に開発できるようになりましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! 人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. LangChainの概要\n→ LangChainの概要や、開発環境について学びます。\nSection2. LangChainの基礎\n→ LangChainを使ったシンプルなアプリを開発し、LangChainの基礎を学びます。\nSection3. LangChainの様々な機能\n→ LLMアプリ開発を強力にサポートする、LangChainの様々な機能について学びます。\nSection4. LangChainの応用\n→ LangChainを使い、様々な有用なアプリを開発します。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "LangChainを基礎から体験ベースで学びたい方。",
        "LLMを業務や趣味で活用したい方。",
        "LangChainによりLLMアプリ開発を効率化したい方。",
        "AI技術のトレンドに追随したい方。",
        "LangChainを活用した新たなサービスを作りたい方。",
        "LLMアプリ構築を手軽に楽しみたい方。",
        "LangChainを自分のサービスに取り入れたい方。",
        "LLMの新たな可能性を模索したい方。"
      ]
    },
    {
      "title": "Machine Learning Bootcamp w języku Python cz.II - od A do Z",
      "url": "https://www.udemy.com/course/machine-learning-bootcamp-w-jezyku-python-ii/",
      "bio": "Praktyczne wprowadzenie do uczenia maszynowego w języku Python: zasady, techniki i modele dla uczenia nadzorowanego!",
      "objectives": [
        "wprowadzenie do uczenia nienadzorowanego",
        "metody grupowania (clustering): algorytm K-średnich wraz z implementacją, grupowanie hierarchiczne, DBSCAN",
        "redukcja wymiarowości: algorytm PCA wraz z implementacją, algorytm t-SNE",
        "metody asocjacyjne: reguły asocjacyjne, algorytm Apriori",
        "detekcja anomalii: algorytm Local Outlier Factor, algorytm Isolation Forest",
        "detekcja anomalii w szeregach czasowych: biblioteka Prophet (Facebook)"
      ],
      "course_content": {
        "-----UCZENIE NIENADZOROWANE-----": [
          "Uczenie Nienadzorowane - Intro",
          "Wprowadzenie",
          "Uczenie nienadzorowane"
        ],
        "-----KLASTERYZACJA-----": [
          "Klasteryzacja/Analiza skupień - Intro",
          "Klasteryzacja/Analiza skupień",
          "Klasteryzacja/Analiza skupień - zastosowanie",
          "Klasteryzacja/Analiza skupień - typy algorytmów"
        ],
        "Repozytorium kursu - Github": [
          "Repozytorium kursu - Github"
        ],
        "Algorytm K-średnich": [
          "Metryka Minkowskiego (euklidesowa, Manhattan)",
          "Algorytm K-średnich - wykład",
          "Algorytm K-średnich - implementacja",
          "Algorytm K-średnich - biblioteka scikit-learn",
          "Algorytm K-średnich - wybór optymalnej ilości klastrów",
          "Algorytm K-średnich - metoda łokcia",
          "Algorytm K-średnich - wady i zalety",
          "Test"
        ],
        "Grupowanie hierarchiczne": [
          "Grupowanie hierarchiczne - wykład",
          "Grupowanie hierarchiczne - metryki (euklidesowa, Manhattan, kosinusowa)",
          "Grupowanie hierarchiczne - ćwiczenie",
          "Test"
        ],
        "Algorytm DBSCAN": [
          "DBSCAN - wykład",
          "DBSCAN - wykład - rodzaje punktów",
          "DBSCAN - wykład - algorytm",
          "DBSCAN - ćwiczenie",
          "Test"
        ],
        "Klasteryzacja - porównanie algorytmów": [
          "Porównanie algorytmów - wykład",
          "Porównanie algorytmów - ćwiczenie",
          "Test"
        ],
        "-----REDUKCJA WYMIAROWOŚCI-----": [
          "Redukcja wymiarowości"
        ],
        "PCA - Analiza Głównych Składowych": [
          "PCA - Analiza Głównych Składowych - wykład",
          "PCA - Analiza Głównych Składowych - wektory i wartości własne",
          "PCA - Analiza Głównych Składowych - implementacja",
          "PCA - Analiza Głównych Składowych - breast cancer data",
          "PCA - Analiza Głównych Składowych - MNIST data",
          "PCA - Analiza Głównych Składowych - CIFAR data",
          "PCA - Analiza Głównych Składowych - Wine dataset",
          "PCA - Analiza Głównych Składowych - rekonstrukcja obrazu",
          "Test"
        ],
        "t-SNE": [
          "t-SNE - wykład",
          "t-SNE - przykłady",
          "t-SNE - ćwiczenie",
          "Test"
        ]
      },
      "requirements": [
        "Ukończone kursy ze ścieżki Python Developer na tym koncie instruktorskim",
        "Ukończone kursy ze ścieżki Data Scientist na tym koncie instruktorskim",
        "Podstawy matematyki i statystyki",
        "Chęć nauki uczenia maszynowego od podstaw"
      ],
      "description": "Witamy w drugiej części kursu Machine Learning Bootcamp! Tym razem skupiamy się w 100% na uczeniu nienadzorowanym (unsupervised learning) – jednym z najważniejszych filarów nowoczesnej analizy danych i eksploracji wzorców w zbiorach bez etykiet.\nJeśli znasz już podstawy Pythona oraz masz za sobą kurs o uczeniu nadzorowanym (cz. I), teraz czas na praktyczne opanowanie technik takich jak klasteryzacja, redukcja wymiarów, analiza skupień, PCA, DBSCAN, hierarchiczne grupowanie, t-SNE i wiele więcej. Kurs prowadzony jest w formie bootcampu – czyli nauczysz się wszystkiego od podstaw, krok po kroku, na praktycznych przykładach.\nW kursie znajdziesz:\npełne wprowadzenie do uczenia nienadzorowanego\nporównanie i wybór odpowiednich algorytmów do różnych typów danych\nimplementację algorytmów w Pythonie przy użyciu bibliotek takich jak scikit-learn, seaborn, pandas, matplotlib i numpy\nliczne projekty i case study z prawdziwego świata (np. segmentacja klientów, analiza tekstu)\npraktyczne wskazówki, jak interpretować i wizualizować wyniki\nTo idealny kurs dla analityków danych, przyszłych data scientistów, studentów kierunków technicznych i wszystkich, którzy chcą rozwinąć kompetencje w obszarze sztucznej inteligencji bez nadzoru. Dołącz teraz i wejdź na wyższy poziom analizy danych z Pythonem!\n\n\nUczenie nienadzorowane – Odkrywaj ukryte wzorce w danych\nUczenie nienadzorowane to gałąź uczenia maszynowego, w której algorytmy analizują dane bez wcześniejszych etykiet czy oznaczeń. Celem jest znalezienie struktury, grup lub zależności w zbiorze danych. Przykładowe techniki to klasteryzacja, redukcja wymiarowości czy analiza skupień. Uczenie nienadzorowane znajduje zastosowanie między innymi w segmentacji klientów, wykrywaniu anomalii i eksploracji danych.",
      "target_audience": [
        "Początkujący Data Scientists / Data Analyst / Machine Learning Engineers",
        "Programiści i Inżynierowie Oprogramowania",
        "Analitycy Biznesowi i Finansowi",
        "Studenci kierunków technicznych lub ekonomicznych",
        "Pasjonaci AI i Uczenia Maszynowego"
      ]
    },
    {
      "title": "Python自然语言处理-BERT实战",
      "url": "https://www.udemy.com/course/python-bert/",
      "bio": "NLP-BERT实战",
      "objectives": [
        "掌握NLP当下核心算法模型",
        "熟练掌握Transformer网络架构",
        "熟悉注意力机制的作用（Attention）",
        "熟练掌握BERT模型原理及应用",
        "熟练使用谷歌开源项目BERT",
        "基于BERT开源模型构建自己的项目",
        "将预训练模型应用到自己的任务中",
        "熟悉当下NLP常规解决方案"
      ],
      "course_content": {
        "自然语言处理通用框架BERT原理解读": [
          "课程简介",
          "BERT任务目标概述",
          "课程数据代码下载（谷歌网盘）",
          "传统解决方案遇到的问题",
          "注意力机制的作用",
          "self-attention计算方法",
          "特征分配与softmax机制",
          "Multi-head的作用",
          "位置编码与多层堆叠",
          "transformer整体架构梳理",
          "BERT模型训练方法",
          "训练实例"
        ],
        "谷歌开源项目BERT源码解读与应用实例": [
          "BERT开源项目简介",
          "项目参数配置",
          "数据读取模块",
          "数据预处理模块",
          "tfrecord制作",
          "Embedding层的作用",
          "加入额外编码特征",
          "加入位置编码特征",
          "mask机制",
          "构建QKV矩阵",
          "完成Transformer模块构建",
          "训练BERT模型"
        ],
        "项目实战-基于BERT的中文情感分析实战": [
          "中文分类数据与任务概述",
          "读取处理自己的数据集",
          "训练BERT中文分类模型"
        ],
        "项目实战-基于BERT的中文命名实体识别实战": [
          "命名实体识别数据分析与任务目标",
          "NER标注数据处理与读取",
          "构建BERT与CRF模型"
        ],
        "必备基知识点-word2vec模型通俗解读": [
          "词向量模型通俗解释",
          "模型整体框架",
          "训练数据构建",
          "CBOW与Skip-gram模型",
          "负采样方案"
        ],
        "必备基础-Tensorflow实现word2vec模型": [
          "数据与任务流程",
          "数据清洗",
          "batch数据制作",
          "网络训练",
          "可视化展示"
        ],
        "必备基础-RNN网络架构与情感分析应用实例": [
          "RNN网络模型解读",
          "NLP应用领域与任务简介",
          "项目流程解读",
          "加载词向量特征",
          "正负样本数据读取",
          "构建LSTM网络模型",
          "训练与测试效果"
        ],
        "必备基础-医学糖尿病数据命名实体识别": [
          "数据与任务介绍",
          "整体模型架构",
          "数据-标签-语料库处理",
          "输入样本填充补齐",
          "训练网络模型",
          "医疗数据集（糖尿病）实体识别"
        ]
      },
      "requirements": [
        "熟悉Python",
        "熟悉深度学习与Tensorflow"
      ],
      "description": "Python自然语言处理-BERT模型实战课程旨在帮助同学们快速掌握当下NLP领域最核心的算法模型BERT的原理构造与应用实例。通俗讲解BERT模型中所涉及的核心知识点（Transformer,self-attention等），基于google开源BERT项目从零开始讲解如何搭建自然语言处理通用框架，通过debug源码详细解读其中每一核心代码模块的功能与作用。最后基于BERT框架进行中文情感分析与命名实体识别等主流项目实战。",
      "target_audience": [
        "人工智能方向的同学们",
        "自然语言处理方向的同学们"
      ]
    },
    {
      "title": "[ES] Desarrollo IA y Python: Megaclase con 300+ Proyectos",
      "url": "https://www.udemy.com/course/desarrollo-ia-y-python-megaclase-con-300-proyectos/",
      "bio": "Formación en Machine Learning, Deep Learning, Ciencia de Datos, Visión por Computadora, PLN, Chatbots y Apps con IA",
      "objectives": [
        "Domina Python desde cero, incluso sin experiencia previa.",
        "Comprende los fundamentos de IA, machine learning y deep learning.",
        "Crea y lanza aplicaciones de IA reales con Python.",
        "Usa bibliotecas clave como TensorFlow, PyTorch y OpenCV.",
        "Desarrolla habilidades prácticas con 100 proyectos de IA y Python.",
        "Aprende análisis de datos, visualización y preprocesamiento.",
        "Crea apps con IA como chatbots, sistemas de recomendación y más.",
        "Gana experiencia en entrenamiento, evaluación y ajuste de modelos.",
        "Comprende aspectos éticos y prácticos del desarrollo de IA.",
        "Crea un portafolio de proyectos en IA y Python para mostrar tu talento."
      ],
      "course_content": {
        "Semana 1: Fundamentos de programación en Python": [
          "Introducción a la Semana 1: Fundamentos de programación en Python",
          "Día 1: Introducción a Python y configuración del entorno de desarrollo",
          "Día 2: Control de flujo en Python",
          "Día 3: Funciones y módulos",
          "Día 4: Estructuras de datos (Listas, Tuplas, Diccionarios, Conjuntos)",
          "Día 5: Trabajo con cadenas de texto",
          "Día 6: Manejo de archivos",
          "Día 7: Código pythónico y trabajo de proyecto",
          "Diapositivas y código para el curso"
        ],
        "Semana 2: Fundamentos de la Ciencia de Datos": [
          "Introducción a la Semana 2: Fundamentos de la Ciencia de Datos",
          "Día 1: Introducción a NumPy para computación numérica",
          "Día 2: Operaciones avanzadas con NumPy",
          "Día 3: Introducción a Pandas para la manipulación de datos",
          "Día 4: Limpieza y preparación de datos con Pandas",
          "Día 5: Agregación y agrupamiento de datos en Pandas",
          "Día 6: Visualización de datos con Matplotlib y Seaborn",
          "Día 7: Proyecto de Análisis Exploratorio de Datos (EDA)"
        ],
        "Semana 3: Matemáticas para el Aprendizaje Automático": [
          "Introducción a la Semana 3: Matemáticas para el Aprendizaje Automático",
          "Día 1: Fundamentos de Álgebra Lineal",
          "Día 2: Conceptos avanzados de álgebra lineal",
          "Día 3: Cálculo para el Aprendizaje Automático (Derivadas)",
          "Día 4: Cálculo para el Aprendizaje Automático (Integrales y Optimización)",
          "Día 5: Teoría de la probabilidad y distribuciones",
          "Día 6: Fundamentos de estadística",
          "Día 7: Mini proyecto basado en matemáticas – Regresión lineal desde cero"
        ],
        "Semana 4: Probabilidad y Estadística para el Aprendizaje Automático": [
          "Introducción a la Semana 4: Probabilidad y Estadística para el Aprendizaje Autom",
          "Día 1: Teoría de la probabilidad y variables aleatorias",
          "Día 2: Distribuciones de probabilidad en el aprendizaje automático",
          "Día 3: Inferencia estadística - Estimación e intervalos de confianza",
          "Día 4: Pruebas de hipótesis y valores p",
          "Día 5: Tipos de pruebas de hipótesis",
          "Día 6: Análisis de correlación y regresión",
          "Día 7: Proyecto de análisis estadístico – Análisis de datos del mundo real"
        ],
        "Semana 5: Introducción al Aprendizaje Automático": [
          "Introducción a la Semana 5: Introducción al Aprendizaje Automático",
          "Día 1: Fundamentos del Aprendizaje Automático y Terminología",
          "Día 2: Introducción al Aprendizaje Supervisado y Modelos de Regresión",
          "Día 3: Modelos de regresión avanzados – Regresión polinómica y regularización",
          "Día 4: Introducción a la clasificación y regresión logística",
          "Día 5: Evaluación de modelos y validación cruzada",
          "Día 6: Algoritmo k-Vecinos más cercanos (k-NN)",
          "Día 7: Mini proyecto de aprendizaje supervisado"
        ],
        "Semana 6: Ingeniería de características y evaluación de modelos": [
          "Introducción a la Semana 6: Ingeniería de características y evaluación de modelo",
          "Día 1: Introducción a la ingeniería de características",
          "Día 2: Escalado y normalización de datos",
          "Día 3: Codificación de variables categóricas",
          "Día 4: Técnicas de selección de características",
          "Día 5: Creación y transformación de características",
          "Día 6: Técnicas de evaluación de modelos",
          "Día 7: Validación cruzada y ajuste de hiperparámetros"
        ],
        "Semana 7: Algoritmos avanzados de aprendizaje automático": [
          "Introducción a la Semana 7: Algoritmos avanzados de aprendizaje automático",
          "Día 1: Introducción al aprendizaje en conjunto (Ensemble Learning)",
          "Día 2: Bagging y Bosques Aleatorios (Random Forests)",
          "Día 3: Boosting y Gradient Boosting",
          "Día 4: Introducción a XGBoost",
          "Día 5: LightGBM y CatBoost",
          "Día 6: Manejo de datos desequilibrados",
          "Día 7: Proyecto de apredizaje en conjunto Comparación de modelos en datos reales"
        ],
        "Semana 8: Ajuste y optimización de modelos": [
          "Introducción a la Semana 8: Ajuste y optimización de modelos",
          "Día 1: Introducción al ajuste de hiperparámetros",
          "Día 2: Búsqueda en cuadrícula (Grid Search) y búsqueda aleatoria (Random Search)",
          "Día 3: Ajuste avanzado de hiperparámetros con optimización bayesiana",
          "Día 4: Técnicas de regularización para la optimización de modelos",
          "Día 5: Validación cruzada y técnicas de evaluación de modelos",
          "Día 6: Ajuste automatizado de hiperparámetros con GridSearchCV y RandomzedSearch",
          "Día 7: Proyecto de optimización – Construcción y ajuste de un modelo final"
        ],
        "Semana 9: Fundamentos de redes neuronales y aprendizaje profundo": [
          "Introducción a la Semana 9: Fundamentos de redes neuronales y aprendizaje profun",
          "Día 1: Introducción al aprendizaje profundo y redes neuronales",
          "Día 2: Propagación hacia adelante y funciones de activación",
          "Día 3: Funciones de pérdida y retropropagación",
          "Día 4: Descenso de gradiente y técnicas de optimización",
          "Día 5: Construcción de redes neuronales con TensorFlow y Keras",
          "Día 6: Construcción de redes neuronales con PyTorch",
          "Día 7: Proyecto de redes neuronales – Clasificación de imágenes en CIFAR-10"
        ],
        "Semana 10: Redes Neuronales Convolucionales (CNNs)": [
          "Introducción a la Semana 10: Redes Neuronales Convolucionales (CNNs)",
          "Día 1: Introducción a las Redes Neuronales Convolucionales (CNNs)",
          "Día 2: Capas convolucionales y filtros",
          "Día 3: Capas de agrupamiento (Pooling) y reducción de dimensionalidad",
          "Día 4: Construcción de arquitecturas CNN con Keras y TensorFlow",
          "Día 5: Construcción de arquitecturas CNN con PyTorch",
          "Día 6: Regularización y aumento de datos para CNNs",
          "Día 7: Proyecto de CNN – Clasificación de imágenes en Fashion MNIST o CIFAR-10"
        ]
      },
      "requirements": [
        "No se requiere experiencia previa en programación o inteligencia artificial.",
        "Una computadora con acceso a internet para programar y trabajar en los proyectos.",
        "Disposición para aprender y experimentar con conceptos de Python e inteligencia artificial.",
        "Familiaridad básica con el uso de una computadora e instalación de software.",
        "Interés en la inteligencia artificial, el aprendizaje automático y la automatización.",
        "Mentalidad orientada a la resolución de problemas y al aprendizaje práctico.",
        "Opcional: tener configurado Google Colab o Jupyter Notebook para ejecutar código en Python."
      ],
      "description": "Sumérgete en el Bootcamp definitivo de Desarrollo en IA y Python, diseñado para principiantes y futuros ingenieros de inteligencia artificial. Este curso integral te lleva desde cero experiencia en programación hasta dominar Python, machine learning, deep learning y aplicaciones impulsadas por IA mediante 100 proyectos del mundo real. Ya sea que desees iniciar una carrera en IA, mejorar tus habilidades como desarrollador o crear herramientas de automatización de vanguardia, este curso te brinda experiencia práctica con implementaciones reales.\nComenzarás aprendiendo Python desde cero, cubriendo desde la sintaxis básica hasta funciones avanzadas. A medida que avances, explorarás técnicas de ciencia de datos, visualización y preprocesamiento para preparar conjuntos de datos para modelos de IA. El curso presenta algoritmos de machine learning, enseñándote a construir modelos predictivos, analizar patrones y tomar decisiones con inteligencia artificial. Trabajarás con TensorFlow, PyTorch, OpenCV y Scikit-Learn para crear aplicaciones que procesen texto, imágenes y datos estructurados.\nA lo largo del curso, desarrollarás chatbots, sistemas de recomendación, analizadores de sentimientos y herramientas de automatización usando datos reales. Obtendrás conocimientos en procesamiento de lenguaje natural (PLN), visión por computadora y aprendizaje por refuerzo, dominando cómo se aplica la IA en distintas industrias. También aprenderás sobre ética en IA, optimización de modelos y estrategias de despliegue, asegurando que sepas escalar proyectos de IA de forma eficiente.\nAl finalizar el curso, contarás con 100 proyectos prácticos que demuestran tus habilidades en desarrollo de IA, automatización y aprendizaje automático. Ya sea que quieras lanzar una startup basada en IA, potenciar tu currículum con habilidades demandadas o automatizar procesos empresariales, este curso te ofrece todo lo necesario. Únete ahora y domina Python y el desarrollo de IA, desbloqueando infinitas oportunidades en la industria tecnológica.",
      "target_audience": [
        "Principiantes absolutos sin experiencia previa en programación o inteligencia artificial.",
        "Aspirantes a ingenieros de IA que buscan una base sólida en Python e IA.",
        "Estudiantes y profesionales que desean experiencia práctica con proyectos reales de IA.",
        "Desarrolladores que quieren hacer la transición hacia la IA y el aprendizaje automático desde otras áreas.",
        "Entusiastas de los datos que quieren aplicar Python en aplicaciones impulsadas por IA.",
        "Emprendedores y profesionales que desean aprovechar la IA para automatizar procesos.",
        "Aficionados a la tecnología que quieren explorar Python e IA mediante proyectos prácticos.",
        "Educadores y formadores que buscan recursos estructurados para enseñar IA y Python.",
        "Investigadores y analistas que desean mejorar sus habilidades en IA y ciencia de datos.",
        "Cualquier persona interesada en aprender desarrollo de IA mediante un enfoque basado en proyectos."
      ]
    },
    {
      "title": "Python para Data Science do Zero Absoluto ao Domínio em 5h",
      "url": "https://www.udemy.com/course/linguagempython/",
      "bio": "O curso mais simples e objetivo para quem deseja iniciar a carreira de Data Science em Python",
      "objectives": [
        "Linguagem Python para Data Science",
        "Entender como usar os códigos de forma não-mecânica, mais criticamente, e especialmente como modificá-los.",
        "Manipulação de Dicionários",
        "Manipulação de Tuplas",
        "Manipulação de Strings em Python",
        "List Comprehensios",
        "Manipulação de Listas",
        "Controles de Fluxo - Processo de Decision Making (IF, ELSE, ELIF)",
        "Sequências",
        "Impressões",
        "Ambiente Jupyter",
        "Como construir suas próprias funções em Python",
        "Construção de Loops com For, While, Passa e Break"
      ],
      "course_content": {
        "Introdução": [
          "Seja muito bem vindo(a)!",
          "Bem Vindo",
          "Instalando o Python - parte 1",
          "Instalando o Python - parte 2",
          "Ambiente Jupyter",
          "Exercício 1",
          "Usando o Python como Calculadora",
          "Exercício 2",
          "Variáveis e Identificadores",
          "Tipos de variáveis",
          "Exercício 3",
          "Imprimindo Coisas",
          "Exercício 4"
        ],
        "Strings": [
          "String - parte 1",
          "String - parte 2",
          "String - parte 3",
          "Exercício Proposto #1 - Questões - Aplicação Real - Strings em Python",
          "Exercício Proposto #1 - Solução",
          "String - parte 4",
          "String - parte 5",
          "String - parte 6",
          "String - parte 7"
        ],
        "Listas": [
          "Lista - parte 1",
          "Lista - parte 2",
          "Lista - parte 3",
          "Lista - parte 4"
        ],
        "Conjuntos": [
          "Conjuntos"
        ],
        "Dicionários": [
          "Dicionário - parte 1",
          "Dicionário - parte 2 (detalhes importantes)",
          "Dicionário - parte 3 (modificando um dicionário)",
          "Dicionário - parte 4 (aplicando filtros no dicionário)",
          "Dicionário - parte 5 (consultas no dicionário)",
          "Dicionário - parte 6 (Get)",
          "Dicionário - parte 7 (Copy)"
        ],
        "Tuplas": [
          "Tuplas"
        ],
        "Variáveis Boleanas": [
          "Variáveis Lógicas"
        ],
        "Controle de Fluxo - Decision Making": [
          "IF",
          "Else",
          "Elif (*)",
          "Range (sequências)"
        ],
        "Loops": [
          "For",
          "While",
          "Pass e Break",
          "While + For"
        ],
        "List Comprehensions": [
          "List Comprehensions"
        ]
      },
      "requirements": [
        "Não existe pré-requisito, qualquer pessoa poderá fazer este curso."
      ],
      "description": "Olá!!! Tudo bem com você?!!\n\nMeu nome é Isaías Lira, sou Bacharel em Estatística, Especialista em Docência Superior e Consultor em Análise de Dados e quero muito que a Estatística deixe de ser um problema para você e passe a ser uma nova HABILIDADE para sua carreira profissional ... Vamos lá?!!\n\nPor que criei este curso?\n\nData Scientist (Cientista de Dados, profissional em Análise de Dados) foi classificado como o primeiro emprego no Glassdoor e o salário médio de um cientista de dados é mais de $ 120,000 nos Estados Unidos e é sem dúvida a função com vagas sobrando e sem gente capacitada para preenchê-la. É a carreira mais valiosa no momento, pois permite resolver alguns dos problemas mais interessantes do mundo.\nE se você já programa em outra linguagem, saiba que  uma das principais linguagens para Data Scientist é o Pyhton por ser\nGratuito;\nCódigo aberto e de alto nível;\nGrande comunidade;\nSimples de usar, pois usa a linguagem interpretada;\nSuportado na maioria das plataformas sem problemas (Windows, Linux, Macintosh, Solaris e outros);\nUsado por grandes empresas para implementar algoritmos de Inteligência Artificial, posições no mapa, computação gráfica outras milhares de funcionalidades;\nO Python é amplamente usado para Big Data para grandes massas de dados\nTem integrações com quase tudo (SQL, Power BI, Java, etc).\nPython é a linguagem líder de muitos cientistas de dados\nOs engenheiros de Python têm alguns dos maiores salários do setor\n\n\n\n\nPor que não dar este grande salto para Data Science?\nEste curso é avaliado em milhares de dólares, mas agora você pode aprender toda essa informação por um preço simbólico!\nCom muito conteúdo em vídeo, vários exercícios, didática simplificada e abordagem inovadora, fizeram deste curso um dos cursos mais abrangentes e mais procurados para ciência de dados e aprendizagem de máquinas na Udemy com língua Portuguesa!\n\n\nVamos ensinar-lhe como programar em Python para resolver problemas reais das empresas.\n\n\nEste curso é diferente por que é o mais simples neste tema! É verdadeiramente um passo a passo para quem quer começar do zero até o ponto de fazer análises de dados usando o R de forma independente, sem dependente dos outros.\nÉ um curso 100% prático, onde você vai:\n1 -  Partir do absoluto zero (zero conhecimento sobre programação, zero conhecimento sobre Estatística, zero conhecimento sobre matemática)\n2 - Evoluir a cada aula com desafios analíticos da vida real das empresas\n3 - Até chegar a um nível de domínio em Python (dominando os principais objetos desta linguagem).\n\n\nDesta forma, mesmo que você tem pavor de números, terá sucesso neste curso!\nNão posso esperar para vê-lo na aula...\nInscreva-se no curso e torne-se cientista de dados hoje! O que você tem a perder?\nForte abraço e estou ansioso para conhecer você!",
      "target_audience": [
        "Leigos interessados em aprender a Linguagem Python para a carreira em TI, Data Science",
        "Profissionais e Estudantes de TI",
        "Profissionais de outras áreas querendo dar um Upgrade na carreira",
        "Profissionais procurando novos desafios",
        "Pessoas interessadas em aprender algo novo e de extrema necessidade no mercado"
      ]
    },
    {
      "title": "【한글자막】 NLP : Python 으로 배우는 자연어 처리",
      "url": "https://www.udemy.com/course/global-top-100-nlp-python-246/",
      "bio": "Machine Learning, spaCy, NLTK, SciKit-Learn, Deep Learning 등을 사용하여 자연어 처리를 수행하는 방법을 배웁니다.",
      "objectives": [
        "Python으로 텍스트 파일 작업하는 방법",
        "Python으로 PDF 파일 작업하는 방법",
        "텍스트에서 패턴 검색을 위한 정규 표현식 활용",
        "초고속 토큰화를 위한 spaCy 사용",
        "어간 추출 및 표제어 추출",
        "단어 집합과 검색",
        "품사 태깅을 사용한 원시(raw) 텍스트 파일 자동 처리",
        "개체명 인식 이해",
        "spaCy로 POS(품사 태깅) 및 NER(개체명 인식) 시각화",
        "SciKit-Learn(사이킷런)을 통한 텍스트 분류",
        "토픽 모델링을 위한 잠재 디리클레 할당",
        "비음수 행렬 분해",
        "Word2Vec 알고리즘 사용",
        "감성 분석을 위한 NLTK 사용",
        "딥러닝을 사용한 자신만의 챗봇 만들기"
      ],
      "course_content": {
        "강의 소개": [
          "강의 개요 - 절대 이 강의를 스킵하지 마세요(중요 정보 있음!)",
          "Quick Check (체크 필수!)",
          "설치 및 설정 강의",
          "커리큘럼 개요",
          "FAQ - 자주 묻는 질문"
        ],
        "Python 텍스트 기초": [
          "파이썬 텍스트 기초 소개",
          "파이썬으로 텍스트 파일 작업하기(1)",
          "파이썬으로 텍스트 파일 작업하기(2)",
          "PDF 작업하기",
          "정규 표현식(1)",
          "정규 표현식(2)",
          "파이썬 텍스트 기초 - 평가",
          "파이썬 텍스트 기초 - 해설"
        ],
        "자연어 처리 기초": [
          "자연어 처리 소개",
          "spaCy 설치 및 둘러보기",
          "자연어 처리란?",
          "spaCy 기초",
          "토큰화(1)",
          "토큰화(2)",
          "어간 추출",
          "표제어 추출",
          "불용어",
          "단어 집합과 검색(1)",
          "단어 집합과 검색(2)",
          "자연어 처리 기초 - 평가",
          "자연어 처리 기초 - 해설"
        ],
        "품사 태깅과 개체명 인식": [
          "섹션 소개 : 품사 태깅과 개체명 인식",
          "품사 태깅",
          "품사의 시각화",
          "개체명 인식(1)",
          "개체명 인식(2)",
          "개체명 인식의 시각화",
          "문장 분류",
          "섹션 평가",
          "섹션 평가 - 풀이"
        ],
        "텍스트 분류": [
          "텍스트 분류 입문",
          "머신 러닝의 개요",
          "분류 평가 방법",
          "혼동 행렬",
          "Scikit-Learn 입문 - Scikit-Learn 사용법",
          "Scikit-Learn 입문 - 코드 작성 1부",
          "Scikit-Learn 입문 - 코드 작성 2부",
          "텍스트 특징 추출의 개요",
          "텍스트 특징 추출 - 코드 작성 훈련",
          "텍스트 특징 추출 - 코드 작성 2부",
          "텍스트 분류 코드 작성 프로젝트",
          "텍스트 분류 평가의 개요",
          "텍스트 분류 평가의 해답"
        ],
        "의미론과 감성 분석": [
          "의미론과 감성 분석 소개",
          "의미론과 단어 벡터의 개요",
          "spaCy로 구현하는 의미론과 단어 벡터",
          "감성 분석 개요",
          "NLTK로 구현하는 감성 분석",
          "영화 리뷰 프로젝트로 하는 감성 분석",
          "감성 분석 프로젝트 과제",
          "감성 분석 프로젝트-솔루션"
        ],
        "토픽 모델링": [
          "토픽 모델링 강의 소개",
          "토픽 모델링의 개요",
          "잠재 디리클레 할당의 개요",
          "파이썬으로 잠재 디리클레 할당 수행하기(1)",
          "파이썬으로 잠재 디리클레 할당 수행하기(2)",
          "비음수 행렬 분해 개요",
          "파이썬을 사용한 비음수 행렬 분해",
          "토픽 모델링 평가 프로젝트 개요",
          "토픽 모델링 평가 프로젝트 솔루션"
        ],
        "NLP를 위한 딥러닝": [
          "NLP를 위한 딥러닝 개요",
          "기본 퍼셉트론 모델",
          "신경망 개요",
          "케라스 기초 (1)",
          "케라스 기초 (1)",
          "순환 신경망(RNN) 개요",
          "LSTM, GRU, 텍스트 생성",
          "Keras, 파이썬, LSTM을 이용한 텍스트 생성(1)",
          "Keras, 파이썬, LSTM을 이용한 텍스트 생성(2)",
          "Keras와 LSTM을 이용한 텍스트 생성(3)",
          "챗봇 개요",
          "파이썬으로 챗봇 만들기(1)",
          "파이썬으로 챗봇 만들기(2)",
          "파이썬으로 챗봇 만들기(3)",
          "파이썬으로 챗봇 만들기(4)"
        ],
        "보너스 섹션: THANK YOU!": [
          "보너스 강의"
        ]
      },
      "requirements": [
        "Python에 대한 기본 지식",
        "Python 패키지",
        "인터넷 환경"
      ],
      "description": "Welcome to the best Natural Language Processing course on the internet!\n\n\n안녕하세요! Jose Portilla입니다.\n특별히 한국의 수강생분들을 만나기 위해 한국어 자막을 준비했습니다.\n강의를 들으시고 궁금하신 점은 언제든 Q&A에 남기실 수 있지만 Q&A는 꼭 영어로 남겨주세요.\n\n\n이 강의는 Python프로그래밍 언어와 함께 자연어 처리 사용법을 배우고자 하는 분들이 온라인으로도 완벽하게 배우실 수 있도록 설계되었습니다. 이 강의에서 우리는 Python으로 NLP의 세계적 수준의 실무자가 되기 위해 배워야 할 모든 것을 다룰 것입니다. 기본 사항부터 시작하여 Python으로 텍스트 및 PDF 파일을 열고 작업하는 방법과 정규 표현식을 사용하여 텍스트 파일 내에서 맞춤 패턴을 검색하는 방법을 알아보겠습니다.\n\n\n우리는 자연어 처리의 기초, Python용 NLTK(Natural Language Toolkit), 초고속 토큰화를 위한 최신 spaCy, 구문 분석, 개체명 인식, 표제어 추출을 배웁니다. 또한 형태소 분석, 표제어, 불용어, 구문 일치, 토큰화 등과 같은 기본적인 NLP 개념을 이해할 것입니다!\n\n\n다음으로 우리는 당신의 Python 스크립트가 지능형 언어 시스템을 구축하는 데 필수적인 명사, 동사 및 형용사와 같은 적절한 품사에 텍스트의 단어를 자동으로 할당할 수 있는 품사 태깅을 다룰 것입니다. 또한 텍스트 정보를 제공함으로써 코드가 돈, 시간, 회사, 제품 등과 같은 개념을 자동으로 이해할 수 있도록 하는 개체명 인식에 대해서도 배웁니다.\n\n\n최첨단 시각화 라이브러리를 통해 이러한 관계를 실시간으로 볼 수 있습니다. 그런 다음 Machine Learning을 이해하고 텍스트 분류를 수행하기 위한 Scikit-Learn으로 Machine Learning 시스템을 자동으로 구축합니다. 우리는 그것을 통해 긍정적 또는 부정적인 영화 리뷰를 구분하거나, 스팸과 합법적인 이메일 메시지를 결정할 수 있습니다.\n\n\n우리는 이 지식을 토픽 모델링과 같은 자연어 처리를 위해 더 복잡한 자율 학습 방법으로 확장할 것입니다. 여기서 기계 학습 모델은 원시(raw) 텍스트 파일에서 주제와 주요 개념을 감지합니다. 이 과정에는 NLTK 라이브러리를 사용한 텍스트의 감정 분석, Word2Vec 알고리즘을 사용한 의미론적 단어 벡터 생성 및 딥 러닝을 사용하여 자체 채팅 봇을 구축하는 것과 같은 최첨단 고급 주제에 대한 전체 섹션이 포함되어 있습니다!\n\n\n이 모든 것이 30일 환불 보장과 함께 제공되므로 부담 없이 강의를 시작해보세요.\n\n\n당신도 NLP 전문가가 되십시오!\n\n\nI will see you inside the course,\nJose",
      "target_audience": [
        "자연어 처리 사용에 관심 있는 Python개발자"
      ]
    },
    {
      "title": "医療者のためのPythonデータ解析",
      "url": "https://www.udemy.com/course/medical-data-analysis-python/",
      "bio": "Pythonの基礎, 医学統計(重/ロジスティック回帰, 検定), 機械学習を健康診断や糖尿病のデータで実践",
      "objectives": [
        "Pythonによる医療データ解析に必要な手法",
        "Pythonの基本的なメソッド",
        "numpyの有用なメソッド",
        "pandasのSeries, DataFrame",
        "numpy, pandasによる基礎統計量算出",
        "データの読み書き",
        "データの前処理",
        "データの整形",
        "医療データの可視化方法",
        "統計を用いた医療データ解析方法"
      ],
      "course_content": {
        "Pythonの基礎": [
          "Lecture1: pythonの基礎"
        ],
        "numpy": [
          "numpyの基礎"
        ],
        "pandas": [
          "Series",
          "DataFrame",
          "pandasでの基礎統計量関連",
          "データの読み書き",
          "aggregation",
          "重複値・欠損値の扱い",
          "その他のmethod"
        ],
        "データ解析の基礎": [
          "groupby",
          "merge"
        ],
        "可視化": [
          "matplotlib(pyplot)",
          "seaborn",
          "pandasを用いたプロット"
        ],
        "統計を用いたデータ解析": [
          "線形回帰",
          "ロジスティック回帰",
          "ランダムフォレスト",
          "XGboost",
          "t検定",
          "生存曲線",
          "正規分布"
        ]
      },
      "requirements": [
        "PCを持っていること",
        "Python 3, jupyter notebookを使用できる環境にあること"
      ],
      "description": "【本講座の特徴】\n医療データ解析において必要なメソッドと解析方法のエッセンスを身に付けていきます。\n主に実際の医療データを用いる為、体系的なカリキュラムを、より実践的に学ぶことが出来ます。\nPythonの基礎から扱う為、初学者でも安心して受講することが出来ます。\n\n\n「統計を用いたデータ解析」において学べる解析手法\n- 重回帰分析\n- ロジスティック回帰分析\n- ランダムフォレスト\n- XGboost\n- t検定\n- 生存曲線\n- 正規分布",
      "target_audience": [
        "pythonを用いた医療データ解析を行いたい医療従事者・学生",
        "プログラミング初心者も受講可能"
      ]
    },
    {
      "title": "Deep Learning y Computer Vision en TensorFlow: 10 Proyectos",
      "url": "https://www.udemy.com/course/deep-learning-para-computer-vision-con-python-y-tensorflow/",
      "bio": "Detecta tumores, juega Atari y reconoce violencia con redes neuronales, Transfer Learning y Deep RL en Computer Vision",
      "objectives": [
        "Entender los conceptos fundamentales del procesamiento de imágenes, útil para posteriormente entender Deep Learning, esto utilizando OpenCV",
        "Entender los principios por los que Machine Learning funciona para aplicarlos en la creación de redes neuronales",
        "Implementar soluciones innovadoras de Deep Learning en problemas del mundo real",
        "Aprender a utilizar TensorFlow como herramienta principal en la construcción de diferentes soluciones basadas en redes neuronales"
      ],
      "course_content": {
        "Generalidades del curso": [
          "tu instructor y consejos para sacarle el máximo al curso",
          "GitHub y Grupo de Facebook del curso"
        ],
        "Introducción al Procesamiento de Imágenes": [
          "Procesamiento de Imágenes en un curso de Deep Learning?",
          "Instalación de Anaconda",
          "Creación de un entorno de programación",
          "Instalación de OpenCV",
          "Qué es una imagen?",
          "Tipos de Imágenes comunes",
          "La librería de procesamiento de imágenes, OpenCV",
          "Representación de una imagen en Python",
          "Recuento de una imagen en Python",
          "Operaciones básicas con imágenes",
          "Operaciones entre imágenes en Python",
          "Histograma de una imagen",
          "El método de Otsu",
          "Operación de convolución entre imágenes",
          "Filtrado de imágenes en Python",
          "El vector gradiente discreto",
          "El vector gradiente en Python"
        ],
        "Introducción al Machine Learning tradicional": [
          "Tipos de aprendizaje de maquina o ML",
          "Fundamentos de clasificación en Machine Learning 1",
          "Fundamentos de clasificación en Machine Learning 2"
        ],
        "Nuestro primer clasificador para reconocer lunares de piel": [
          "Problema que vamos a resolver",
          "Generación del dataset de características",
          "Visualización del dataset en el espacio de características",
          "Relación entre los pesos del modelo y la función de costo",
          "Encontrando el hiperplano óptimo",
          "Error de entrenamiento",
          "Predicción para una imagen",
          "Como sería un proyecto completo de detección de cancer en lunares"
        ],
        "redes neuronales para reconocimiento de caracteres escritos a mano": [
          "La librería más importante del curso, Tensorflow",
          "El problema de detectar caracteres en imágenes y el dataset MNIST",
          "HOG para características de forma",
          "Dataset de características con HOG",
          "La red neuronal",
          "Funciones de costo de redes neuronales y optimización iterativa",
          "Definición del modelo con Tensorflow",
          "Entrenamiento y evaluación del modelo",
          "La matriz de confusión",
          "Implementación de la matriz de confusión en Python"
        ],
        "La red neuronal convolucional para detectar tumores cerebrales": [
          "La red neuronal convolucional (CNN)",
          "Nuestro entorno para Deep Learning - Kaggle",
          "lectura del dataset en memoria",
          "Definición del modelo",
          "Callbacks y entrenamiento",
          "Evaluación del Modelo",
          "Si tienes problemas con TensorBoard en Kaggle",
          "Visualización del entrenamiento con TensorBoard",
          "Escogiendo el mejor checkpoint",
          "Overfitting",
          "CNN como extractor de características",
          "Déjale saber a otros lo que piensas del curso :)"
        ],
        "Qué ven las redes neuronales convolucionales? - ML interpretable": [
          "Utilización de modelos pre-entrenados",
          "implementación de un sistema pre-entrenado",
          "GRAD-CAM",
          "Implementación de GRAD-CAM en python"
        ],
        "Transfer Learning para la detección de Covid": [
          "Modelos para transfer learning",
          "Implementación de la CNN desde cero",
          "Mejorando los resultados con transfer learning"
        ],
        "Image Search para encontrar la evolución de un Pokemon": [
          "Comparación de embeddings",
          "Generación de embeddings para el dataset de imágenes",
          "Implementación del image search"
        ],
        "Deep Clustering para detección de expresiones faciales": [
          "Kmeans clustering con características convolucionales",
          "Generación del dataset de características convolucionales",
          "Implementación de Kmeans clustering",
          "Quieres obtener resultados más evidentes?"
        ]
      },
      "requirements": [
        "Python básico, funciones, ciclos... Numpy. Matemáticas básicas de colegio.",
        "se recomienda tomar el curso de computer vision y machine learning con python, ya que trata en mayor profundidad los temas de procesamiento de imágenes y ML tradicional, sin embargo no es obligatorio, al principio se hará un resumen de estos temas"
      ],
      "description": "Imagina crear, en pocos días, una inteligencia artificial que detecte tumores o enseñe a una consola Atari a batir récords, sin ser experto en matemáticas. El secreto está en proyectos guiados paso a paso, esto disparará tu motivación y retención.\n¿Qué vas a conseguir?\n\n\nDominar Deep Learning e IA con TensorFlow desde cero, usando explicaciones que cualquier principiante puede entender a la primera.\nConstruir 10 proyectos reales: detector de tumores, diagnóstico Covid con Transfer Learning, agente Atari autónomo, detector de violencia en vídeo y más, para impresionar a reclutadores con tu portafolio de proyectos de Inteligencia Artificial.\nAprender con metodología 100 % práctica, probada para multiplicar la retención hasta 15 veces frente a clases teóricas con presentaciones aburridas.\n\n\n¿Por qué te importa?\nEmpresas  buscan talento en IA más que nunca: las vacantes que piden TensorFlow crecieron un 34 % en el último año y pagan hasta un 25 % más que la media STEM. Además, la tecnología de redes neuronales ya supera a radiólogos en ciertas tareas de diagnóstico, de modo que estas habilidades abren puertas que transforman carreras y cambian vidas.\n\n\nRequisitos\nSolo Python básico y ganas de experimentar—el resto (instalación de librerías, datasets y scripts) lo instalamos juntos en el curso",
      "target_audience": [
        "Personas con conocimiento básico de python con deseo de entrar al mundo del Machine Learning/ Data Science/Inteligencia Artificial"
      ]
    },
    {
      "title": "みんなのデータサイエンス講座 -Python、Colab、Kaggleで基礎から学び親しむ「データ」の世界-",
      "url": "https://www.udemy.com/course/learning-ds/",
      "bio": "初心者向けのデータサイエンスのコースです。PythonやGoogle Colaboratory、Pandasなどを使って、プログラミングや確率・統計、機械学習の基礎を学びましょう。最後には、Kaggleを使って実践的な課題に取り組みます。",
      "objectives": [
        "データサイエンスの基礎を学びます。",
        "様々なタイプのデータに親しむことができるようになります。",
        "「データ」に対して俯瞰的な視点を身につけ、社会におけるデータの重要性について理解できるようになります。",
        "Pythonの基礎的なプログラミング技術が身につきます。",
        "NumPy、matplotlib、Pandasなどのツールの扱い方を学びます。",
        "確率・統計の基礎を学びます。",
        "Kaggleを使って実践的なデータサイエンスの課題に取り組めるようになります。",
        "様々な機械学習のアルゴリズムを扱えるようになります。"
      ],
      "course_content": {
        "データサイエンスの概要": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "データサイエンスの概要",
          "Pythonとデータサイエンス",
          "学習の心構え",
          "開発環境について",
          "演習"
        ],
        "Pythonの基礎": [
          "セクション2の教材",
          "Section2の概要",
          "Pythonの基礎1",
          "Pythonの基礎2 Part1",
          "Pythonの基礎2 Part2",
          "Pythonの基礎3",
          "Pythonの基礎4",
          "演習"
        ],
        "データサイエンスのツール": [
          "セクション3の教材",
          "Section3の概要",
          "NumPyの基礎",
          "matplotlibの基礎",
          "Pandasの基礎",
          "演習"
        ],
        "確率と統計": [
          "セクション4の教材",
          "Section4の概要",
          "確率の基礎",
          "基本的な統計量",
          "正規分布",
          "共分散と相関係数",
          "ベイズの定理",
          "演習"
        ],
        "機械学習": [
          "セクション5の教材",
          "Section5の概要",
          "機械学習の概要",
          "回帰",
          "k平均法",
          "サポートベクターマシン",
          "決定木",
          "演習"
        ],
        "データサイエンスの実践": [
          "セクション6の教材",
          "Section6の概要",
          "Kaggleの概要",
          "Kaggleの設定",
          "Kaggleの実践",
          "演習",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "プログラミングが全くの未経験でも問題ありません。",
        "中学-高校レベルの数学で十分です。高度な数学は必要ありません。",
        "Google ColaboratoryやKaggleを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "ディープラーニング（深層学習）は扱いません。ディープラーニングについて学びたい方には他のコースをお勧めします。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。"
      ],
      "description": "みんなのデータサイエンス講座は、誰に対しても開かれた初心者向けのデータサイエンス講座です。プログラミングや数学の事前知識はほとんど必要ありません。\n難解な数式やプログラミングが学習の妨げであった方でも、問題なく学習できます。\n必要なコードは、データサイエンスの分野で最もメジャーな言語のPythonで記述します。Pythonについては、基礎から丁寧に解説します。\n本コースはこのPythonを使ってデータサイエンスの基礎を丁寧に学びますが、最後にはKaggleを使って実践的な課題への取り組み方まで学びます。\nデータサイエンスのコードの記述には、Google Colaboratoryという開発環境を使います。これにより、初心者の方が躓きやすい環境設定が大幅に楽になります。\n本コースは、Udemyの受講生数が数万人に及ぶ経験豊富な講師が指導します。文系や非エンジニアの方にもお勧めです。\nデータに基づくロジカルな思考は、社会における様々な場面であなたをサポートします。様々な種類のデータに、親しめるようになりましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\nコースの内容は以下の通りです。\nSection1. データサイエンスの概要\n→ データサイエンスの概要、および開発環境であるGoogle Colaboratoryについて学びます。\nSection2. Pythonの基礎\n→ プログラミング言語、Pythonの基礎について学びます。\nSection3. データサイエンスのツール\n→ データサイエンスにおいて有用なツール、NumPy、matplotib、Pandasについて学びます。\nSection4. 確率と統計\n→ データサイエンスおいて重要な、確率・統計の基礎を学びます。\nSection5. 機械学習\n→ 様々な機械学習の手法の、特性と実装を学びます。\nSection6. データサイエンスの実践\n→ Kaggleを使い、現実的な問題に取り組みます。\n\n\nその他コースの特徴は、以下通りです。\n- 理論よりも体験を、手を動かすことを重視します。\n- 可能な限り、簡単な数学を用いて解説します。\n- 必要な数学はグラフィカル、直感的に解説します。\n- 数学用語や専門用語を避け、なるべく平易な言葉で説明します。\n- 難しい概念は、細かく分解して少しずつ学習します\n- プログラミング初心者、未経験者でも大丈夫です。プログラミング言語Pythonを基礎から学びます。\nなお、大学レベル以上の数学や、深い理論の解説は行いませんのでご注意ください。",
      "target_audience": [
        "データサイエンスに興味があるけど、最初のとっかかりが分からない方。",
        "データの扱い方に関する基礎的な知識を得て、様々な種類のデータに親しめるようになりたい方。",
        "データサイエンス関連の分厚い書籍、難解な数式に辟易した方。",
        "仕事上、データに深く関わる必要に迫られた方。",
        "数学、プログラミングがデータサイエンスの学習の障壁になっている方",
        "データサイエンスの学習を通してPythonプログラミングを身に付けたい方",
        "文系の方、非エンジニアの方にもおすすめです"
      ]
    },
    {
      "title": "超速入門!【データサイエンスへの最初の一歩】PythonとSparkで学ぶデータ分析のための前処理と分散処理 一気見講座",
      "url": "https://www.udemy.com/course/spark-python-crush-course/",
      "bio": "【データサイエンス/データエンジニアリングシリーズ】最強のビッグデータ処理エンジンApache Spark~ABC人材のためのPythonで行う分散処理と前処理 を一挙に習得しよう！",
      "objectives": [
        "Spark(PySpark)で実際に現場で使われる技法が一挙に学べます",
        "構造化データに対するデータエンジニアリング",
        "非構造化データに対するデータエンジニアリング",
        "ExcelをSparkを使ってデータエンジニアリングしてみよう(Pandas to Spark)",
        "PDFをSparkを使ってデータエンジニアリングしてみよう(six to Saprk)",
        "分散処理とは何か？Sparkとは何か？",
        "実際の開発で気をつけるべきことは何か？",
        "関数の羅列ではなく、「現場ではどの様に使われるか？」も解説します"
      ],
      "course_content": {
        "紹介": [
          "講座タイトル",
          "本コースの概要",
          "講師紹介",
          "本コースがビッグデータ基盤のどこに当たるのか？",
          "環境構築"
        ],
        "環境構築と基本操作(DataFrame)": [
          "本セクションの目次",
          "分散処理とは？",
          "PySparkとは",
          "ノートブックとは？",
          "Spark(PySpark)がデータ操作で利用するもの",
          "データ読み込み",
          "データフレームを操作する",
          "カラムナーフォーマット/行指向フォーマット",
          "パーティションとダイナミックパーティション",
          "スモールファイルとデータスキュー",
          "セクション2小テスト"
        ],
        "PySpark基本操作(SQLとDataFrame)": [
          "本セクションの目次",
          "ビッグデータ世界のDDL",
          "ビッグデータ世界のDMLとは？",
          "分析関数を練習してみよう(agg関数)",
          "分析関数を利用してみよう(Window関数その１)",
          "分析関数を練習してみよう(LAG/Lead関数",
          "分析関数を練習してみよう(ピボットテーブル",
          "SparkのRDDを使って1レコードつづ処理してみよう",
          "セクション3小テスト",
          "Lead関数を使って一つ先のデータと比べて人口がどれくらい増えているのか？を算出してみましょう"
        ],
        "非構造データのラングリング(エクストラ)": [
          "本セクションの目次",
          "データラングリングとは？",
          "テーブル形式を含まないExcelのラングリング",
          "PDFのラングリングを行ってみよう",
          "ラングリングで気をつけること",
          "セクション4小テスト",
          "データセット(ensyu.jso)についてデータの重複を行いつつハッシュ値(UUID)をカラムに付与してみましょう。"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの知識があることが好ましいです",
        "SQLを理解しているとさらに飲み込みやすいと思います"
      ],
      "description": "現役のデータエンジニアがレクチャーします！\n\n\nAIや機械学習を行う際に最も時間のかかる作業は、データの準備とそれらの管理です。これらの作業のことをデータエンジニアリングと呼びます。実に８０％以上の時間をデータエンジニアリング(データサイエンスのための前処理など)に割いてるのが現状です。\n本コースではApache Sparkを使ったデータエンジニアリングについて学びます。\n\n\nポイント：\n本コースでは分散処理のデファクトとなりつつあるSparkについて学びます。\nApache Sparkはビッグデータ処理で多く使われている分散処理エンジンです。\n今回はPythonと組み合わせた実際の現場で使われるPySparkを使った操作を一挙にまとめました。\n\n\n特徴：\nデータエンジニアリングよりの講座です。\n難しいいサイエンスや数学は出てきませんが、データの3職種のうちの一つである「データエンジニア」のためのコースです。\n普段Pythonを使っている方やこれからAIやビッグデータの分野にエンジニアとして参画してデータを自在に操りたいという方にはぴったりです\n\n\nソースコードや解説は以下のGitHubリポジトリにあります。\n動画内ではGitHubの資料に加え補足をしながら解説を進めています。",
      "target_audience": [
        "非構造のデータ(Excel、PDF、動画ファイル)に対するデータエンジニアリングを学びたい方"
      ]
    },
    {
      "title": "Aprende a Crear Robots de Inversión con Python.",
      "url": "https://www.udemy.com/course/aprende-a-crear-robots-de-inversion-con-python/",
      "bio": "Aprende las bases del Trading Algoritmico y el procesamiento de datos financieros",
      "objectives": [
        "Desarollar estrategias de inversión",
        "Como implementar un algortimo de inversión",
        "Extracción y Tratamiento de datos financieros",
        "Programación en Python",
        "Visualización de datos financieros"
      ],
      "course_content": {},
      "requirements": [
        "Ser una persona proactiva en el aprendizaje",
        "Tener ganas de aprender"
      ],
      "description": "¿Te gustaría aprender a crear robots de inversión? ¿Quieres aprender a invertir de forma inteligente?\nEn este curso te enseñamos desde cero a crear tus robots usando Python. El curso está dividido en 6 módulos:\nProgramación en Python, veremos los fundamentos de la programación haciendo uso de uno de los lenguajes mas populares en la actualidad\nProcesamiento de datos con pandas. Aprenderemos a manipular  y transformar datos de forma sencilla utilizando pandas\nUso de APIs Financieras, veremos como podemos extraer datos financieros de diferentes fuentes y como podemos realizar ordenes de compra y venta\nIndicadores Técnicos. Analizaremos diferentes indicadores técnicos que nos ayudarán para elaborar nuestros algoritmo de inversión\nBacketesting. Analizaremos como podemos probar si nuestra estrategia es rentable\nCreación de un bot desde cero. Usaremos todos los conceptos aprendidos en el curso para ver como podemos crear nuestro robot de inversión que nos permita invertir de forma automática.",
      "target_audience": [
        "Personas interesadas en los mercados financieros",
        "Personas que quieran aprender a implementar algoritmos de trading",
        "Estudiantes de Informatica",
        "Personas que desean Usar Python para optimizar sus inversiones",
        "Programadores que desean aprender como utilizar python en el mundo financiero."
      ]
    },
    {
      "title": "Big Data - Les fondamentaux",
      "url": "https://www.udemy.com/course/big-data-les-fondamentaux/",
      "bio": "Les fondamentaux de la révolution Big Data et Data Science",
      "objectives": [
        "•Présenter les grands enjeux du Big Data avec le vocabulaire approprié.",
        "•Contribuer utilement à un projet Big Data et mobiliser les expertises techniques appropriées.",
        "•Proposer des innovations liées au Big Data et décrire les conditions de sa mise en application."
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Le big data et ses contributeurs": [
          "Définition",
          "Objectifs",
          "Qui fait le big data ?",
          "Qui fait le big data ? (2)"
        ],
        "L'environnement du big data": [
          "Le Big Data et ses contributeurs",
          "Les grandes technologies liés au Big Data (Partie 1)",
          "Les grandes technologies liés au Big Data (Partie 2)",
          "Les grandes technologies liés au Big Data (Partie 3)",
          "Les grandes technologies liés au Big Data (Partie 4)"
        ]
      },
      "requirements": [
        "Pas de connaissance préalable. Mais il est utile de se former, en parallèle, en informatique, statistique et économie pour aller plus loin et retirer tous les bénéfices de cet enseignement."
      ],
      "description": "La révolution des données est en marche. Pour bénéficier de toutes les opportunités du Big Data, plongez dans l'écosystème des Data Science ! Ce cours présente tous les éléments fondamentaux à la fois techniques et économiques. Il vous permet d'acquérir des bases solides et d'appréhender le champ des possibles de la révolution Big Data dans tous les domaines.",
      "target_audience": [
        "Le cours s'adresse à tous les publics. Au sein du Collège de Paris, il est dispensé au niveau Master"
      ]
    },
    {
      "title": "成為初級資料分析師 | Python 資料科學應用",
      "url": "https://www.udemy.com/course/python-data-science/",
      "bio": "以成為初級資料分析師（Junior Data Analyst）為最終目標的 Python 資料科學應用課程",
      "objectives": [
        "起步走",
        "Python 程式設計常用技巧",
        "網頁資料擷取",
        "網頁資料擷取排程與分享資料",
        "NumPy 101",
        "Pandas 101",
        "Pandas 專題"
      ],
      "course_content": {
        "起步走 | Getting Started": [
          "投影片連結",
          "Colab 連結",
          "軟體介紹 - Google Colaboratory",
          "軟體介紹 - Miniconda",
          "移除不必要的 Python 版本及原因",
          "安裝軟體 - Miniconda",
          "建立環境",
          "安裝套件"
        ],
        "Python 程式設計常用技巧 | Common Python Programming Skills": [
          "投影片連結",
          "大綱",
          "自訂函數",
          "錯誤與例外",
          "彈性參數",
          "隨堂練習1",
          "匿名函數",
          "迭代函數",
          "其他常用的迭代函數",
          "List Comprehensions",
          "隨堂練習2",
          "Generators1",
          "隨堂練習3",
          "Generators2",
          "常用文字方法1",
          "常用文字方法2"
        ],
        "網頁資料擷取 | Web Scraping 101": [
          "投影片連結",
          "網頁資料擷取的環境設定",
          "網頁資料擷取的先修知識",
          "網頁資料擷取的核心任務1",
          "網頁資料擷取的核心任務2",
          "網頁資料擷取的核心任務3",
          "擷取 JSON 格式網頁資料1",
          "擷取 JSON 格式網頁資料2",
          "隨堂練習1",
          "隨堂練習2",
          "擷取 XML 格式網頁資料1",
          "擷取 XML 格式網頁資料2",
          "擷取 HTML 格式網頁資料1",
          "擷取 HTML 格式網頁資料2",
          "擷取 HTML 格式網頁資料3",
          "擷取 HTML 格式網頁資料4",
          "擷取 HTML 格式網頁資料5",
          "隨堂練習3",
          "隨堂練習4",
          "擷取 HTML 格式網頁資料6",
          "擷取 HTML 格式網頁資料7",
          "擷取 HTML 格式網頁資料8",
          "隨堂練習5",
          "隨堂練習6.1",
          "隨堂練習6.2",
          "隨堂練習6.3",
          "擷取 HTML 格式網頁資料9",
          "瀏覽器自動化1",
          "瀏覽器自動化2",
          "瀏覽器自動化3",
          "瀏覽器自動化4",
          "瀏覽器自動化5",
          "瀏覽器自動化6",
          "隨堂練習7",
          "隨堂練習8",
          "瀏覽器自動化7"
        ],
        "網頁資料擷取排程與分享資料 | Web Scraping 102": [
          "投影片連結",
          "如何排程網頁資料擷取1",
          "如何排程網頁資料擷取2",
          "如何排程網頁資料擷取3",
          "創建 Web API 分享資料"
        ],
        "NumPy 101 | NumPy 101": [
          "投影片連結",
          "為什麼資料分析師需要 NumPy1",
          "隨堂練習1",
          "為什麼資料分析師需要 NumPy2",
          "NumPy 基礎1",
          "NumPy 基礎2",
          "陣列處理1_ndarray 的屬性",
          "陣列處理2_ndarray 的屬性",
          "陣列處理3_重塑外觀",
          "陣列處理4_印出陣列",
          "陣列處理5_複製陣列",
          "陣列處理6_合併陣列",
          "陣列處理7_拆分陣列",
          "陣列運算1",
          "隨堂練習2",
          "隨堂練習3",
          "陣列運算2_聚合函數"
        ],
        "Pandas 101 | Pandas 101": [
          "投影片連結",
          "隨堂練習1",
          "Pandas 解決了什麼問題",
          "Pandas 基礎1_pandas 中的 Series",
          "Pandas基礎2_pandas 中的 DataFrame",
          "Pandas基礎3_pandas 中的 Index",
          "Series 與 DataFrame 的基礎技巧1",
          "Series 與 DataFrame 的基礎技巧2",
          "Series 與 DataFrame 的基礎技巧3",
          "Series 與 DataFrame 的基礎技巧4",
          "Series 與 DataFrame 的基礎技巧5",
          "Series 與 DataFrame 的基礎技巧6",
          "隨堂練習2",
          "Series 與 DataFrame 的基礎技巧7",
          "Series 與 DataFrame 的基礎技巧8",
          "奧運獎牌排行練習1",
          "奧運獎牌排行練習2",
          "奧運獎牌排行練習3",
          "奧運獎牌排行練習4",
          "DataFrame 的進階操作1",
          "DataFrame 的進階操作2",
          "DataFrame 的進階操作3",
          "DataFrame 的進階操作4",
          "DataFrame 的進階操作5",
          "美國普查練習1",
          "美國普查練習2",
          "美國普查練習3",
          "美國普查練習4",
          "美國普查練習5"
        ],
        "Pandas專題 | Pandas Project": [
          "投影片連結",
          "觀察處理前資料",
          "盤點單張試算表處理步驟",
          "隨堂練習1",
          "隨堂練習2",
          "隨堂練習3",
          "隨堂練習4",
          "盤點多張試算表處理步驟1",
          "隨堂練習5",
          "盤點多張試算表處理步驟2",
          "隨堂練習6",
          "盤點多張試算表處理步驟3",
          "隨堂練習7",
          "隨堂練習8",
          "隨堂練習9",
          "輸出"
        ]
      },
      "requirements": [
        "具備 Python 程式設計基礎",
        "理解 Python 程式設計語法",
        "有自己的桌上型或筆記型電腦",
        "有網際網路"
      ],
      "description": "這門課程是「成為初級資料分析師」的其中一門課，在 20 小時的教學影片之中內容包含這些主題：\n起步走\nPython 程式設計常用技巧\n網頁資料擷取\n網頁資料擷取排程與分享資料\nNumPy 101\nPandas 101\nPandas 專題：資料處理",
      "target_audience": [
        "想要成為初級資料分析師（Junior Data Analyst）的學員",
        "對資料科學感興趣的初級 Python 開發人員"
      ]
    },
    {
      "title": "Generative AI Beginner to Advance",
      "url": "https://www.udemy.com/course/generative-ai-beginner-to-advance/",
      "bio": "A Complete Guide to Building, Deploying, and Optimizing Generative AI with Langchain and Huggingface",
      "objectives": [
        "Gain hands-on expertise in Generative AI by working with a variety of tools, including ChatGPT, Stable Diffusion, Llama, and others.",
        "Master advanced prompt engineering techniques for multimodal AI engines to generate accurate and valuable outputs from Generative AI systems.",
        "Learn advanced workflows with Generative AI, including Retrieval-Augmented Generation (RAG), model fine-tuning, and working with AI agents.",
        "Automate content creation at no cost using open-source models.",
        "Prepare for interviews to land top positions in the field of Generative AI with targeted strategies and insights.",
        "Gain in-depth understanding of Artificial Intelligence concepts and explore the inner workings of various Generative AI (Gen AI) models. 4o",
        "Learn to generate AI art and create photorealistic images of humans for free using open-source tools. Create AI influencers, marketing materials, and design ele",
        "Master the use of ChatGPT and the latest models like GPT-4, DALL-E 3, and others to enhance content creation, data analysis, brainstorming, social media posts,",
        "Learn to build applications powered by Generative AI, utilizing APIs and running AI models directly on your computer for greater control and customization.",
        "Learn how to implement practical use cases of Generative AI in organizations to streamline operations, enhance creativity, and drive innovation."
      ],
      "course_content": {
        "Introduction to the Course": [
          "Overview of the course & content"
        ],
        "Introduction to Generative AI and overview": [
          "What is generative AI ?",
          "Why we should learn generative models ?",
          "Recent advancements and use case of generative AI",
          "What are different types of Generative AI models",
          "How to Train Generative AI Models: Life cycle",
          "Limitations of Generative AI"
        ],
        "Text Preprocessing and Word Embedding": [
          "Basic Terminologies and text processing importance",
          "Text Cleaning : punctuation and white space",
          "Text Tokenization",
          "Remove stop words",
          "Lemmatization and Stemming",
          "Normalization and Text segemntation",
          "Parts of Speech (POS) Tagging ,Named Entity Recognition (NER)",
          "One-Hot Encoding",
          "Bag of Words (BoW)",
          "TF-IDF (Term Frequency-Inverse Document Frequency):",
          "Word2Vec",
          "Word Embedding overview",
          "Text Preprocessing and Word Embedding"
        ],
        "Neural Network": [
          "Human Brain vs Perceptron",
          "Perceptron working and components",
          "Multilayer perceptron",
          "forward and backward progation in neural network",
          "Chain Updation formula",
          "How to name weight, biea and output",
          "Chain rule",
          "Vanishing gradient Problem",
          "Exploding gradient problem",
          "Neural Network"
        ],
        "Activation Function": [
          "Sigmoid and TanH Activation Function",
          "Relu and its variants",
          "Softmax and swish activation fucntion",
          "Activation Function"
        ],
        "Loss Functions": [
          "MAE, MSE, Huber Loss function",
          "Binary and categorical Loss Function",
          "Loss Functions"
        ],
        "Optimizers": [
          "Introduction to optimizers",
          "Batch, stochastic, mini batch gradient descent optimizers",
          "SGD with Momentum and Adagrad",
          "RMS prop and Adam optimizers",
          "Optimizers"
        ],
        "RNN": [
          "RNN introduction",
          "Backpropogation through time (BPTT)",
          "Types of RNN",
          "Problems in Rnn and its Solution",
          "RNN"
        ],
        "LSTm": [
          "Long Short-Term Memory (LSTM) Networks",
          "Why to Prefer GRU over LSTM",
          "LSTm"
        ],
        "GRU": [
          "Gated Recurrent Unit (GRU)",
          "Bi directional RNN",
          "GRU"
        ]
      },
      "requirements": [
        "Familiarity with programming languages like Python, including libraries such as TensorFlow or PyTorch, is beneficial.",
        "Basic skills in data preprocessing, manipulation, and analysis using tools like pandas and NumPy.",
        "Knowing how to run models on cloud platforms or local machines with GPUs will be helpful.",
        "A willingness to explore, experiment, and apply Generative AI across various fields is important for making the most out of this domain."
      ],
      "description": "Unlock the full potential of Generative AI with our comprehensive course, \"Generative AI Beginner to Advance.\" This carefully designed program guides you from foundational concepts to advanced techniques, offering hands-on experience to develop essential skills in the field of Generative AI.\nBeginning with the basics, the course introduces key concepts, making it accessible even for those with limited AI knowledge. As you advance, you'll explore complex topics such as building, deploying, and optimizing AI models. By leveraging powerful tools like Langchain and Huggingface, you'll learn to create robust AI solutions applicable to real-world use cases.\nThe course is highly practical, providing numerous opportunities to work directly with Generative AI models. You'll discover how to generate text, images, and more, while mastering fine-tuning techniques for specific tasks. By the end of the program, you will have built, optimized, and deployed AI models, gaining the confidence to incorporate these technologies into your projects or professional work.\nThis course is ideal for AI enthusiasts, developers, data scientists, and professionals seeking to transition into the exciting field of Generative AI. Whether you're a beginner or an experienced AI practitioner, this course equips you with the tools and insights necessary to excel in this transformative technology.\nWith a strong emphasis on practical applications and hands-on learning, the \"Generative AI Mastery Course with Langchain and Huggingface\" will empower you to harness the full potential of Generative AI and apply it effectively across various industries.",
      "target_audience": [
        "Beginners in AI: Individuals with a basic understanding of programming and a desire to explore AI and machine learning concepts can start learning Generative AI from scratch.",
        "Data Scientists and ML Engineers: Professionals already working in data science or machine learning who want to deepen their knowledge and explore Generative AI models like GPT, Stable Diffusion, and GANs.",
        "Software Developers: Developers interested in integrating AI into their applications or transitioning to AI-based roles will benefit from learning Generative AI techniques and tools.",
        "Creatives and Designers: Content creators, marketers, or designers looking to leverage AI for generating images, text, or other media can learn to harness the power of Generative AI for automation and creative workflows."
      ]
    },
    {
      "title": "DP-900 - Fundamentos de Dados do Microsoft Azure",
      "url": "https://www.udemy.com/course/microsoft-azure-dp-900-data-fundamentals/",
      "bio": "Domine os Fundamentos de Bancos de Dados e Soluções de Armazenamento no Microsoft Azure",
      "objectives": [
        "Compreender os conceitos fundamentais sobre bancos de dados relacionais e não relacionais no Azure.",
        "Identificar diferentes tipos de dados (estruturados, semiestruturados e não estruturados) e suas utilizações.",
        "Aplicar práticas de modelagem e normalização de dados.",
        "Utilizar as principais ferramentas e serviços de armazenamento de dados do Azure, como SQL Database, Cosmos DB e Data Lake."
      ],
      "course_content": {
        "Introdução à Certificação DP-900": [
          "Boas-vindas ao Curso",
          "O que é a Certificação DP-900",
          "Conhecendo o Microsoft Azure",
          "O que você não vai aprender neste curso",
          "O que você vai aprender nesse curso",
          "Revisão da seção"
        ],
        "Conceitos Básicos de Dados": [
          "Bancos de Dados Relacionais",
          "Dados Estruturados",
          "Dados Semiestruturados",
          "Dados não Estruturados",
          "Modelagem de Dados",
          "DML, DDL, DCL",
          "Normalização de Dados",
          "Resumo da Seção"
        ],
        "Azure SQL Database": [
          "Modelos de Licenciamento e Preços",
          "Criando e Configurando um Banco de Dados no Azure",
          "Conectando o SQL Server Management Studio (SSMS) ao Azure SQL Database",
          "Relacionamentos e Integridade Referencial",
          "Constraints: Garantindo a Integridade dos Dados",
          "Backup, Recuperação"
        ],
        "Conclusão": [
          "Conclusão do Curso"
        ]
      },
      "requirements": [
        "Nenhum conhecimento prévio em Microsoft Azure é necessário.",
        "Conhecimento básico de bancos de dados pode ser útil, mas não obrigatório.",
        "Acesso a uma conta gratuita ou de estudante no Microsoft Azure para praticar os conceitos abordados."
      ],
      "description": "Este curso foi desenvolvido para oferecer uma compreensão completa dos conceitos fundamentais de dados no Microsoft Azure, especificamente para preparar você para a certificação DP-900. Ao longo do curso, você explorará os principais serviços de dados do Azure. Cada aula foi projetada para proporcionar uma abordagem prática e objetiva, facilitando a absorção dos conceitos, mesmo para quem nunca teve contato com a plataforma Azure.\nVocê aprenderá a diferenciar entre dados estruturados, semiestruturados e não estruturados, além de explorar como esses diferentes tipos de dados são gerenciados no Azure. Também discutiremos conceitos importantes de modelagem de dados e normalização, fundamentais para quem trabalha com bancos de dados. Durante o curso, você será apresentado a bancos de dados relacionais e não relacionais e entenderá como aplicar esses conceitos no Azure.\nO curso é ideal para iniciantes que querem começar a trabalhar com a plataforma Azure e também para profissionais que buscam expandir seus conhecimentos na área de dados, preparando-se para a certificação DP-900. Você terá acesso a simulados de exame, dicas práticas e revisões que ajudarão na sua preparação para o exame oficial.\nAo final deste curso, você estará preparado para realizar o exame DP-900 com confiança, tendo compreendido as principais soluções de dados no Azure e como elas podem ser aplicadas em cenários reais. Além disso, estará apto a aplicar os conhecimentos adquiridos em suas atividades profissionais. Não é necessário conhecimento prévio em Azure ou bancos de dados, tornando o curso acessível a todos.",
      "target_audience": [
        "Estudantes e profissionais de TI que desejam iniciar suas atividades no ecossistema de dados do Azure.",
        "Pessoas que estão se preparando para a certificação DP-900.",
        "Interessados em aprender mais sobre os fundamentos de bancos de dados e serviços de dados na nuvem."
      ]
    },
    {
      "title": "Der Pandas Komplettkurs - 2025",
      "url": "https://www.udemy.com/course/der-pandas-komplettkurs/",
      "bio": "Pandas in dessen vollumfänglicher Funktionalität: Installation, DataFrame, Queries, Series, Indexing, Values, Accessors.",
      "objectives": [
        "Die vollumfängliche Funktionalität von Pandas",
        "Eigene DataFrames / Series erstellen",
        "DataFrames speichern um diese weiterverarbeiten zu können",
        "DataFrames einlesen",
        "Die richtige Indexierung von Daten eines DataFrames",
        "Selektion von bestimmten Daten eines DataFrames",
        "Pandas Merge Funktion ausführlich kennenlernen",
        "Advanced Pandas Funktionen kennenlernen",
        "EDA mit Pandas und Plotly"
      ],
      "course_content": {
        "Einführung": [
          "Kursübersicht (Inhalt)",
          "Kursstruktur (Aufbau)"
        ],
        "Entwicklungsumgebung einrichten": [
          "Anaconda Download",
          "Environment einrichten",
          "Environment Troubleshooting",
          "Jupyter Notebook"
        ],
        "Pandas Basics": [
          "Kapitelübersicht: Pandas Basics",
          "Pandas Library installieren",
          "Einführung Pandas Series",
          "Einführung Pandas DataFrane",
          "DataFrame (CSV) einlesen",
          "DataFrame (CSV) speichern",
          "ÜBUNG: Pandas Basics"
        ],
        "Pandas Indexing": [
          "Kapitelübersicht: Pandas Indexing",
          "Indexing: Accessoren",
          "Indexing: Index basiert (.iloc)",
          "Indexing: Label basiert (.loc)",
          "Indexing: Index manipulieren",
          "ÜBUNG: Pandas Indexing"
        ],
        "Pandas Selecting Data": [
          "Kapitelübersicht: Pandas Selecting",
          "Selecting: Einfache Selektion",
          "Selecting: Multiple Selektion",
          "Selecting: Built-In Funktionen - I",
          "Selecting: Built-In Funktionen - II",
          "Selecting: Built-In Funktionen - III",
          "Selecting: Query Fuktion",
          "ÜBUNG: Pandas Selecting"
        ],
        "Pandas Summary Functions": [
          "Kapitelübersicht: Summary Functions",
          "Summary Functions auf DataFrame",
          "Summary Functions auf Series",
          "ÜBUNG: Summary Functions"
        ],
        "Pandas Daten zuweisen": [
          "Kapitelübersicht: Daten zuweisen",
          "Assign: Neue Spalte einfügen",
          "Assign: Neue Zeile (von DataFrame)",
          "Assign: Neue Zeile (von Dictionary)",
          "ÜBUNG: Daten zuweisen"
        ],
        "Pandas: Grouping & Sorting": [
          "Kapitelübersicht: Grouping & Sorting",
          "Gruppieren: Single Index",
          "Gruppieren: Multi Index",
          "Sortieren: DF's sortieren und ordnen",
          "ÜBUNG: Grouping & Sorting"
        ],
        "Pandas Datatypes und missing Values": [
          "Kapitelübersicht: Datatypes & Missing Values",
          "Datentypen",
          "Missing Values",
          "ÜBUNG: Datatypes & Missing Values"
        ],
        "Pandas Renaming & Kombinieren": [
          "Kapitelübersicht: Renaming & Kombinieren",
          "Renaming: Spalte umbenennen",
          "Renaming: Axen umbenennen",
          "DataFrames kombinieren: .concat",
          "DataFrames kombinieren: .join",
          "ÜBUNG: Renaming & Kombiniere"
        ]
      },
      "requirements": [
        "Grundlegende Programmierkenntnisse mit der Programmiersprache Python",
        "Keinerlei Vorkenntnisse mit Pandas"
      ],
      "description": "Pandas ist DAS Analyse-Tool im Jahr 2023. Egal ob im Bereich Datenbanken oder Webentwicklung, vorallem aber Data Science und Machine Learning. Bei Pandas handelt es sich um eine elegante Mischung aus Python und SQL, welches dir erlaubt, zielgerichtete und komplexe Abfragen an dein Datensatz zu stellen. Pandas baut auf dem Table Prinzip auf, wobei es hier speziell um sogenannte DataFrames geht.\nDiese DataFrames beinhalten Spalten und diese Spalten beinhalten wiederrum Werte unterschiedlichster Datentypen. Das coole an Pandas? Es kann mit all dem perfekt umgehen und egal welcher Use Case dir gerade einfällt, du kannst mit Sicherheit sagen, dass Pandas eine passende Lösung dafür bieten kann.\nIn diesem Kurs behandeln wir Pandas von A - Z. Begonnen bei der Installation von Jupyter Notebook über die Installation von Pandas mittels dem Python Paket Manager PIP, gefolgt von Basic Abfragen des DataFrames bis hin zu komplexen Abfragen unterschiedlicher DataFrames und Merges über mehrere DataFrames hinaus.\nDazwischen kümmern wir uns noch um sehr hilfreiche Best-Practice Methoden die du so im Alltag eines Data Scientist finden wirst und auch advanced Methoden mit denen du komplexere Operationen auf einzelne Spalten oder das komplette DataFrame ausführen kannst.\nAls Bonus habe ich dir ein Plotly Kapitel mit ausgearbeitet und aufgenommen. So kannst du deine Daten nicht nur optimal verarbeiten, sondern im Anschluss daran auch grafisch darstellen und präsentieren.\nNach diesem Kurs bist du mehr als vorbereitet und definitiv in der Lage, komplett selbständig Datensätze analysieren zu können. Damit du dich von der Qualität des Kurses selbst überzeugen kannst, habe ich dir ein paar Lektionen kostenlos freigeschalten :-).",
      "target_audience": [
        "Python Entwickler",
        "Data Scientists",
        "Machine Learning Engineer",
        "NLP Entwickler",
        "Datenbankentwickler",
        "Statistiker",
        "Informatik Studenten",
        "An jeden der Lust hat Pandas zu lernen :-)"
      ]
    },
    {
      "title": "SQL 개발자 전문 자격증, SQLD 완벽대비",
      "url": "https://www.udemy.com/course/sql-sqld/",
      "bio": "SQLD 준비를 위한 최선의 선택",
      "objectives": [
        "SQLD 자격증 취득 과정에 필요한 안내사항 및 개발환경 설정",
        "데이터 모델링",
        "데이터 모델과 성능",
        "SQL의 기본적인 내용"
      ],
      "course_content": {
        "SQL 개발자 (SQLD) 자격증 따기 Part.1 시험안내 및 SQL Developer 설치 및 사용": [
          "시험안내 및 준비과정",
          "SQL Developer소개 및 Oracle XE 설치방법 안내",
          "Oracle XE, SQL Developer 설치 및 테스트-1",
          "Oracle XE, SQL Developer 설치 및 테스트-2"
        ],
        "SQL 개발자 (SQLD) 자격증 따기 Part.2-1 데이터 모델링의 이해": [
          "데이터 모델링, 특징, 단계에 대한 설명",
          "ERD작성 단계에 대한 설명",
          "외부, 개념, 내부 스키마에 대한 설명",
          "엔터티 도출, 특징, 종류에 대한 설명",
          "속성의 개념, 특징, 종류, 관계의 개념, 종류, 관계차수에 대한 설명",
          "식별, 비식별 관계의 개념, 엔터티 식별자의 주식별자, 종류에 대한 설명",
          "데이터 모델링의 이해 확인 문제 풀이"
        ],
        "SQL 개발자 (SQLD) 자격증 따기 Part.2-2 데이터 모델과 성능": [
          "정규화의 개념과 설명, 정규화 단계에 대한 설명",
          "제1정규화, 제2정규화, 제3정규화의 개념과 특징에 대한 설명",
          "BCNF정규화, 정규화 예제에 대한 설명",
          "정규화 문제점 예제와 튜닝에 대한 설명",
          "반정규화 개념과 수행해야 될 경우, 기법들에 대한 설명",
          "테이블 병합, 분산 데이터베이스의 개념, 투명성, 장단점에 대한 설명",
          "기출문제 풀이",
          "데이터 모델링의 이해 기출문제 풀이-1",
          "데이터 모델링의 이해 기출문제 풀이-2"
        ],
        "SQL 개발자 (SQLD) 자격증 따기 Part.3-1 SQL_기본": [
          "DB의 종류(계층형, 네트워크형, 관계형), DBMS의 개념과 종류에 대한 설명",
          "DDL, DML, DCL, TCL명령 종류에 대한 설명과 실습",
          "DDL, DML, DCL, TCL명령 종류에 대한 구체적인 실습",
          "트랜잭션 개념, 특징, SQL문 실행과정(파싱, 실행, 인출)에 대한 설명",
          "DESC명령어, 제약 조건(기본키, 외래키, default, not null), On Delete Cascade옵션에 대한 설명",
          "DESC명령어, 제약 조건(기본키, 외래키, default, not null)에 대한 구체적인 실습",
          "제약 조건(on cascade), alter table의 컬럼 추가, 변경, 삭제, 제약조건 삭제에 대한 구체적인 실습",
          "뷰의 개념, 특징, 장단점에 대한 설명과 구체적 실습",
          "INSERT,SELECT,NOLOGGING,UPDATE,DELETE, TRUNCATE문의 설명과 INSERT의 실습",
          "NOLOGGING,UPDATE,DELETE, TRUNCATE문의 실습",
          "ORDER BY, DISTINCT, ALIAS, SQL연산자, LIKE, 와일드카드, BETWEEN AND, IN()에 대한 설명",
          "ORDER BY, DISTINCT,ALIAS, SQL연산자, LIKE, 와일드카드, BETWEEN AND, IN()에 대한 구체적 실습"
        ],
        "[HD]SQL 개발자 (SQLD) 자격증 따기 Part.3-2 SQL_기본": [
          "NULL관련 함수, GROUP BY구문, HAVING구문, 집계함수에 대한 설명",
          "NULL관련 함수, GROUP BY구문, HAVING구문, 집계함수에 대한 구체적 실습",
          "SELECT문의 실행순서, 형변환, DUAL테이블, 내장(문자형함수에 대한 설명)",
          "내장(숫자형함수, DECODE(함수, CASE문에 대한 설명)",
          "DUAL테이블, 내장(문자형, 날짜형함수 실습",
          "내장(숫자형함수, DECODE(함수, CASE문 실습",
          "ROWNUM, ROWID, WITH구문에 대한 설명",
          "GRANT, REVOKE, COMMIT, ROLLBACK, SAVEPOINT에 대한 설명",
          "ROWNUM, ROWID, WITH구문에 대한 구체적 실습",
          "GRANT, REVOKE, COMMIT, ROLLBACK, SAVEPOINT에 대한 구체적 실습",
          "기출 문제 풀이",
          "기출 문제-37회 풀이-1",
          "기출 문제-37회 풀이-2"
        ],
        "SQL 개발자 (SQLD) 자격증 따기 Part.4-1 SQL_활용": [
          "EQUI조인, INNER조인, 해시조인에 대한 설명",
          "INTERSECT연산, NON EQUI조인, OUTER조인, CROSS조인에 대한 설명",
          "조인 및 실습을 위한 테이블 초기화 및 데이터 삽입에 대한 설명",
          "EQUI(등가)조인, INNER JOIN, HASH JOIN, QUERY 실행계획, 컬럼의 모호성에 대한 실습",
          "INTERSECT연산, OUTER조인, CROSS조인에 대한 실습",
          "UNION, UNION ALL차이, MINUS연산, 계층형 데이터 조회에 대한 설명",
          "계층형 데이터 조회, LEVEL, LPAD()로 트리구현, CONNECT BY키워드에 대한 설명",
          "UNION, UNION ALL, MINUS, LEVEL, LPAD(), CONNECT BY에 대한 실습",
          "단일, 다중, 스칼라SUBQUERY의 차이 및 연산자 ANY, SOME, ALL, EXISTS 대한 설명",
          "단일, 다중, 스칼라SUBQUERY의 차이 및 연산자 ANY, SOME, ALL, EXISTS 대한 실습",
          "확인 문제 풀이"
        ]
      },
      "requirements": [
        "SQLD 자격증 취득이 필요한 사람 누구나 수강이 가능합니다"
      ],
      "description": "[SQLD 준비를 위한 최선의 선택]\n\n\n본 과정은 SQLD 자격증을 준비하기 위한 사람들이 활용하실 수 있는 최적의 강의입니다. SQLD 자격증 취득 과정에 필요한 안내사항부터 시작하여 데이터모델링, 데이터 성능, SQL 기초 이론 및 활용에 대해 체계적으로 학습합니다.\n\n\n본 과정의 커리큘럼은 다음과 같습니다.\n\n\n\n\n[SQL 개발자 (SQLD) 자격증 따기 Part.1 시험안내 및 SQL Developer 설치 및 사용]\n\n\n시험안내 및 준비과정\nSQL Developer소개 및 Oracle XE 설치방법 안내\nOracle XE, SQL Developer 설치 및 테스트-1\nOracle XE, SQL Developer 설치 및 테스트-2\n\n\n[SQL 개발자 (SQLD) 자격증 따기 Part.2-1 데이터 모델링의 이해]\n\n\n데이터 모델링, 특징, 단계에 대한 설명\nERD작성 단계에 대한 설명\n외부, 개념, 내부 스키마에 대한 설명\n엔터티 도출, 특징, 종류에 대한 설명\n속성의 개념, 특징, 종류, 관계의 개념, 종류, 관계차수에 대한 설명\n식별, 비식별 관계의 개념, 엔터티 식별자의 주식별자, 종류에 대한 설명\n데이터 모델링의 이해 확인 문제 풀이\n\n\n[SQL 개발자 (SQLD) 자격증 따기 Part.2-2 데이터 모델과 성능]\n\n\n정규화의 개념과 설명, 정규화 단계에 대한 설명\n제1정규화, 제2정규화, 제3정규화의 개념과 특징에 대한 설명\nBCNF정규화, 정규화 예제에 대한 설명\n정규화 문제점 예제와 튜닝에 대한 설명\n반정규화 개념과 수행해야 될 경우, 기법들에 대한 설명\n테이블 병합, 분산 데이터베이스의 개념, 투명성, 장단점에 대한 설명\n기출문제 풀이\n데이터 모델링의 이해 기출문제 풀이-1\n데이터 모델링의 이해 기출문제 풀이-2\n\n\n[SQL 개발자 (SQLD) 자격증 따기 Part.3-1 SQL_기본]\n\n\nDB의 종류(계층형, 네트워크형, 관계형), DBMS의 개념과 종류에 대한 설명\nDDL, DML, DCL, TCL명령 종류에 대한 설명과 실습\nDDL, DML, DCL, TCL명령 종류에 대한 구체적인 실습\n트랜잭션 개념, 특징, SQL문 실행과정(파싱, 실행, 인출)에 대한 설명\nDESC명령어, 제약 조건(기본키, 외래키, default, not null), On Delete Cascade옵션에 대한 설명\nDESC명령어, 제약 조건(기본키, 외래키, default, not null)에 대한 구체적인 실습\n제약 조건(on cascade), alter table의 컬럼 추가, 변경, 삭제, 제약조건 삭제에 대한 구체적인 실습\n뷰의 개념, 특징, 장단점에 대한 설명과 구체적 실습\nINSERT,SELECT,NOLOGGING,UPDATE,DELETE, TRUNCATE문의 설명과 INSERT의 실습\nNOLOGGING,UPDATE,DELETE, TRUNCATE문의 실습\nORDER BY, DISTINCT, ALIAS, SQL연산자, LIKE, 와일드카드, BETWEEN AND, IN()에 대한 설명\nORDER BY, DISTINCT,ALIAS, SQL연산자, LIKE, 와일드카드, BETWEEN AND, IN()에 대한 구체적 실습\n\n\n[SQL 개발자 (SQLD) 자격증 따기 Part.3-2 SQL_기본]\n\n\nNULL관련 함수, GROUP BY구문, HAVING구문, 집계함수에 대한 설명\nNULL관련 함수, GROUP BY구문, HAVING구문, 집계함수에 대한 구체적 실습\nSELECT문의 실행순서, 형변환, DUAL테이블, 내장(문자형함수에 대한 설명)\n내장(숫자형함수, DECODE(함수, CASE문에 대한 설명)\nDUAL테이블, 내장(문자형, 날짜형함수 실습\n내장(숫자형함수, DECODE(함수, CASE문 실습\nROWNUM, ROWID, WITH구문에 대한 설명\nGRANT, REVOKE, COMMIT, ROLLBACK, SAVEPOINT에 대한 설명\nROWNUM, ROWID, WITH구문에 대한 구체적 실습\nGRANT, REVOKE, COMMIT, ROLLBACK, SAVEPOINT에 대한 구체적 실습\n기출 문제 풀이\n기출 문제-37회 풀이-1\n기출 문제-37회 풀이-2\n\n\n[SQL 개발자 (SQLD) 자격증 따기 Part.4-1 SQL_활용]\n\n\nEQUI조인, INNER조인, 해시조인에 대한 설명\nINTERSECT연산, NON EQUI조인, OUTER조인, CROSS조인에 대한 설명\n조인 및 실습을 위한 테이블 초기화 및 데이터 삽입에 대한 설명\nEQUI(등가)조인, INNER JOIN, HASH JOIN, QUERY 실행계획, 컬럼의 모호성에 대한 실습\nINTERSECT연산, OUTER조인, CROSS조인에 대한 실습\nUNION, UNION ALL차이, MINUS연산, 계층형 데이터 조회에 대한 설명\n계층형 데이터 조회, LEVEL, LPAD()로 트리구현, CONNECT BY키워드에 대한 설명\nUNION, UNION ALL, MINUS, LEVEL, LPAD(), CONNECT BY에 대한 실습\n단일, 다중, 스칼라SUBQUERY의 차이 및 연산자 ANY, SOME, ALL, EXISTS 대한 설명\n10단일, 다중, 스칼라SUBQUERY의 차이 및 연산자 ANY, SOME, ALL, EXISTS 대한 실습\n확인 문제 풀이\n\n\n본 강의로 SQLD 자격증 준비를 한 번에 마스터하시기 바랍니다",
      "target_audience": [
        "SQLD 자격증을 취득하고 싶은 모든 분"
      ]
    },
    {
      "title": "Data Structure and Problem Solving |الشامل في هياكل البيانات",
      "url": "https://www.udemy.com/course/data-structure-and-problem-solving/",
      "bio": "تعلم البرمجة بالاسلوب السليم و اتقن هياكل البيانات و تدرب علي خوارزميات اختبارت مقابلات العمل و كتابة الكود بكفائة",
      "objectives": [
        "Data Structures",
        "Problem-solving skills and Algorithm questions",
        "Coding interviews.",
        "Big O Notation",
        "Complexity Analysis"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "What Are Data Structures?"
        ],
        "Complexity Analysis": [
          "What is Complexity Analysis?",
          "Complexity Analysis Key Terms",
          "Memory 1",
          "Memory 2",
          "Memory 3",
          "Big O Notation",
          "Big O Part 2",
          "Big O Part 3",
          "Big O more video contents (optional)",
          "Big O Key Term",
          "Logarithm",
          "Logarithm 2",
          "Code Example ( Guess and Check )",
          "Code Example Proplem",
          "Code Example 2 (Approximate Solution)",
          "Log n time Example",
          "Code Example 3 (Bisection Search)"
        ],
        "Arrays": [
          "Static Array",
          "Static Array 2",
          "Dynamic Array",
          "Array implementation",
          "Array insert",
          "RemoveAt",
          "ArrayList members",
          "Array Indexer",
          "Array Summary (very important)"
        ],
        "LinkedList": [
          "Linked List deep explain",
          "Node implementation",
          "List Traversal",
          "List Size",
          "Linked List Implementation",
          "Insert Last",
          "Remove First",
          "Remove Last",
          "getAt",
          "Remove At",
          "Insert At",
          "Doubly Linked List",
          "DLL Insert",
          "DLL Remove",
          "Exercise - List Reverse",
          "Linked List Summary (very important)"
        ],
        "HashTable": [
          "what is HashTable?",
          "how hashtable works",
          "HashTable Function",
          "Using hashtable in C#",
          "hashtable implementation 1",
          "hashtable implementation 2",
          "hashtable implementation 3",
          "Using Dictionary in C# (optional)"
        ],
        "Queue And Stack": [
          "Queue And Stack Introduction",
          "Stack",
          "Stack based on Linked List",
          "Stack from scratch push",
          "Stack pop function",
          "Queue",
          "Queue Implementation"
        ],
        "String": [
          "string",
          "string builder",
          "string built in methods (optional)"
        ],
        "Trees": [
          "Tree intro",
          "Binary Tree",
          "Binary Search tree",
          "Tree Node implementation",
          "BST Insert",
          "BST Remove (Advanced and optional)",
          "Recursion",
          "BST Traversal (Advanced)",
          "BST LookUp",
          "Log n binary tree"
        ],
        "Building Trees": [
          "Build tree node",
          "Remove Tree Node",
          "Tree Class",
          "Tree Traversals",
          "BreadthFirst Implementation",
          "Depth First"
        ],
        "Interview Questions Level1": [
          "Introduction",
          "Two Number Sum",
          "Validate Subsequence",
          "sorted squared array 1",
          "sorted squared array 2",
          "count characters",
          "Tournament Winner",
          "Tournament Winner Solution",
          "Remove Duplicates From LinkedList",
          "anagram 1",
          "anagram 2",
          "Palindrome",
          "Binary Search Recursive",
          "Binary Search iterative."
        ]
      },
      "requirements": [
        "Programming Knowledge with C# or any language"
      ],
      "description": "Data Structures? They're here. Algorithms? Covered. Lots of questions with well-explained solutions?\nIf you're nervous about your first coding interview, or anxious about applying to your next job, this is the course for you. I got tired of interviewers asking tricky questions that can only be answered if you've seen the problem before, so I made this course! This video course will teach you the most common interview questions that you'll see in a coding interview, giving you the tools you need to ace your next whiteboard interview.\nCoding interviews are notoriously intimidating, but there is one method to become a better interviewer - and that is practice! Practicing dozens of interview questions is what makes the difference between a job offer for a $120k USD and another rejection email. This course is going to not only give you dozens of questions to practice on, but it will also make sure you understand the tricks behind solving each question, so you’ll be able to perform in a real interview.\n\n\nIn this course, you'll get:\nClear, well-diagramed explanations for every single problem to make sure you understand the solution\nAn overview of the most important data structures to know about. These are presented for people without a CS degree.\nA huge collection of common algorithm questions, including everything from 'reversing a string' to 'determine the width of a BST'\nSensible strategies for tackling systems design problems\nInsider tips on answering what interviewers area really looking for\nMy goal in this course is to help you defeat those interviewers who ask nasty algorithm questions. Sign up today, and be the cutting edge engineer who will be prepared to get a high paying job",
      "target_audience": [
        "Study programming professionally",
        "Success in technical interviews",
        "Learn data structures in C# language",
        "Practice Programming",
        "Gain A Computer Science Knowledge in Simple Way",
        "Understand Complexity Analysis"
      ]
    },
    {
      "title": "Mempelajari Algoritma",
      "url": "https://www.udemy.com/course/mempelajari-algoritma/",
      "bio": "Mempelajari Algoritma",
      "objectives": [
        "Memahami konsep dasar algoritma, termasuk dynamic connectivity dan union-find.",
        "Menguasai cara menganalisis algoritma untuk menemukan solusi masalah secara efektif.",
        "Mengetahui berbagai jenis algoritma dan aplikasinya dalam pemrograman dan kehidupan sehari-hari.",
        "Mempelajari dan menerapkan algoritma sorting yang populer dan sering digunakan."
      ],
      "course_content": {
        "Introduction": [
          "Introduction to Algorithm"
        ],
        "Union-Find": [
          "Dynamic Connectivity",
          "Quick Find",
          "Quick Union",
          "Union-Find Application",
          "Quiz"
        ],
        "Analysis Of Algorithm": [
          "Introduction",
          "Observation",
          "Math Model",
          "Order of Growth",
          "Theory of Algorithm",
          "Quiz"
        ],
        "Stack & Queue": [
          "Stack",
          "Resizing Array",
          "Queue",
          "Generics",
          "Iterators",
          "Stack & Queue Application",
          "Quiz"
        ],
        "Simple Sorting": [
          "Sorting Introduction",
          "Selection Sort",
          "Insertion Sort",
          "Shellsort",
          "Shuffling",
          "Convex Hull + Epilogue"
        ],
        "Quiz": [
          "Quiz"
        ]
      },
      "requirements": [
        "Sebelum mempelajari Course ini, kalian harus memahami dasar-dasar pemrograman, aljabar, serta pernah menggunakan bahasa pemrograman."
      ],
      "description": "Mempelajari algoritma merupakan hal yang sangat penting diketahui, terutama untuk para software developer. Belajar algoritma melatih kita untuk menemukan solusi atas suatu masalah, mulai dari masalah dalam pemrograman dan masalah dalam kehidupan sehari-hari. Kita akan mempelajari algoritma mulai dari dynamic connectivity serta alogritma paling simpel yaitu union-find. Selain itu, kalian juga akan mempelajari cara menganalisa algoritma. Jadi, kalian bisa mengetahui konsep dasar dari masing-masing alogritma yang sudah dipelajari. Di akhir pembelajaran, kita akan mempelajari algoritma yang paling populer yaitu sorting algorithm.\n\n\nMempelajari algoritma merupakan hal yang sangat penting diketahui, terutama untuk para software developer. Belajar algoritma melatih kita untuk menemukan solusi atas suatu masalah, mulai dari masalah dalam pemrograman dan masalah dalam kehidupan sehari-hari. Kita akan mempelajari algoritma mulai dari dynamic connectivity serta alogritma paling simpel yaitu union-find. Selain itu, kalian juga akan mempelajari cara menganalisa algoritma. Jadi, kalian bisa mengetahui konsep dasar dari masing-masing alogritma yang sudah dipelajari. Di akhir pembelajaran, kita akan mempelajari algoritma yang paling populer yaitu sorting algorithm.\n\n\nMempelajari algoritma merupakan hal yang sangat penting diketahui, terutama untuk para software developer. Belajar algoritma melatih kita untuk menemukan solusi atas suatu masalah, mulai dari masalah dalam pemrograman dan masalah dalam kehidupan sehari-hari. Kita akan mempelajari algoritma mulai dari dynamic connectivity serta alogritma paling simpel yaitu union-find. Selain itu, kalian juga akan mempelajari cara menganalisa algoritma. Jadi, kalian bisa mengetahui konsep dasar dari masing-masing alogritma yang sudah dipelajari. Di akhir pembelajaran, kita akan mempelajari algoritma yang paling populer yaitu sorting algorithm.",
      "target_audience": [
        "Intermediate"
      ]
    },
    {
      "title": "大規模言語モデル（LLM）・生成系AIをディープラーニングの成り立ちから学びPythonで動かしてみよう！",
      "url": "https://www.udemy.com/course/llm-ai-python/",
      "bio": "大規模言語モデル（LLM）や生成系AIの流れに乗り遅れるな！パーセプトロン→ディープラーニング→Transformer→GPTモデルまでの流れを総ざらい！概要を理解した後はPythonで動かしてみよう！",
      "objectives": [
        "パーセプトロン、ニューラルネットワーク、ディープラーニングの基礎理解",
        "Transformerからはじまる大規模言語モデルの成り立ち、そしてOpenAI、Google、Metaがしのぎを削る各種大規模言語モデルへの理解",
        "テキスト生成だけでなく画像生成AIへの理解",
        "Pythonによる各種生成系AIの動かし方を理解する"
      ],
      "course_content": {},
      "requirements": [
        "PC",
        "Pythonの経験があると良い",
        "データサイエンスの基礎があると良い"
      ],
      "description": "このコースでは、話題の大規模言語モデル（LLM）・生成系AIについて解説していきます！\n\n\n昨今様々な企業がAIの研究開発にしのぎを削っており日々ものすごい進化をとげていますので、この時代の流れに遅れをとらないようにAIについてキャッチアップしていきましょう！\n\n\nこのコースでは、最初にアニメーションで各モデルの概要について学んでいきます。\n・パーセプトロン\n・ディープラーニング\n・Transformer\n・GPTモデル\n・PaLM\n・LLaMA\n・DALL・E\n\n\nちょっと小難しい内容も入ってきますが、完璧に理解しなくてもなんとなく理解しておけば大丈夫です。\n\n\nそして概要を理解した後は、実際にPythonを使って手を動かしながら各モデルを動かしていきます。\nとりあえず手を動かして動かしてみることが大事ですのでガシガシ触っていきましょう！\n\n\nそれほどPythonにおいて複雑な内容は出てきませんが、基礎的な部分はわかっている前提で話が進んでいきますのである程度Pythonを触ったことある方が望ましいです。\n\n\nそれではAIの世界に触れていきましょう！",
      "target_audience": [
        "ChatGPTをはじめとする最近のAIの流れについていきたい方",
        "大規模言語モデル（LLM）や生成系AIについて興味がある方",
        "OpenAIの提供するAPIの各種機能の使い方を知りたい方"
      ]
    },
    {
      "title": "[ES] Certificado de Explorador en Ingeniería de IA",
      "url": "https://www.udemy.com/course/es-certificado-de-explorador-en-ingenieria-de-ia/",
      "bio": "Construye tu base en IA con Python, Ciencia de Datos, Matemáticas y Fundamentos de Machine Learning",
      "objectives": [
        "Escribir código Python limpio para aplicaciones de IA utilizando variables, bucles, funciones y POO",
        "Analizar y manipular datos con Pandas y NumPy",
        "Visualizar conjuntos de datos con Matplotlib y Seaborn",
        "Visualizar conjuntos de datos con Matplotlib y Seaborn",
        "Aplicar teoría de la probabilidad y estadística a la resolución de problemas de IA",
        "Explicar cómo funcionan y se entrenan los modelos de aprendizaje automático",
        "Construir y evaluar modelos básicos de ML usando Scikit-learn",
        "Desarrollar una base sólida para avanzar en temas de IA y aprendizaje automático"
      ],
      "course_content": {
        "Introducción al curso y al instructor": [
          "Qué aprenderás en el Curso de Certificación de Explorador en Ingeniería de IA"
        ],
        "Fundamentos de programación en Python para Inteligencia Artificial": [
          "Día 1: Introducción a Python y configuración del entorno",
          "Día 2: Control de flujo en Python",
          "Día 3: Funciones y módulos",
          "Día 4: Estructuras de datos (Listas, Tuplas, Diccionarios, Conjuntos)",
          "Día 5: Trabajo con cadenas de texto",
          "Día 6: Manejo de archivos",
          "Día 7: Código Pythonic y proyecto práctico",
          "Recursos para proyectos en formación"
        ],
        "Fundamentos de Ciencia de Datos para Inteligencia Artificial": [
          "Día 1: Introducción a NumPy para cálculo numérico",
          "Día 2: Operaciones avanzadas con NumPy",
          "Día 3: Introducción a Pandas para manipulación de datos",
          "Día 4: Limpieza y preparación de datos con Pandas",
          "Día 5: Agrupación y agregación de datos en Pandas",
          "Día 6: Visualización de datos con Matplotlib y Seaborn",
          "Día 7: Proyecto de análisis exploratorio de datos (EDA)",
          "Recursos para proyectos en formación"
        ],
        "Matemáticas para Machine Learning e Inteligencia Artificial": [
          "Día 1: Fundamentos de álgebra lineal",
          "Día 2: Conceptos avanzados de álgebra lineal",
          "Día 3: Cálculo para ML (Derivadas)",
          "Día 4: Cálculo para ML (Integrales y Optimización)",
          "Día 5: Teoría de la probabilidad y distribuciones",
          "Día 6: Fundamentos de estadística",
          "Día 7: Mini proyecto matemático – Regresión lineal desde cero",
          "Recursos para proyectos en formación"
        ],
        "Probabilidad y estadística para Machine Learning e IA": [
          "Día 1: Teoría de la probabilidad y variables aleatorias",
          "Día 2: Distribuciones de probabilidad en ML",
          "Día 3: Inferencia estadística – Estimación e intervalos de confianza",
          "Día 4: Pruebas de hipótesis y valores p",
          "Día 5: Tipos de pruebas de hipótesis",
          "Día 6: Correlación y análisis de regresión",
          "Día 7: Proyecto de análisis estadístico – Análisis de datos reales",
          "Recursos para proyectos en formación"
        ],
        "Introducción al Machine Learning": [
          "Día 1: Conceptos básicos y terminología del ML",
          "Día 2: Introducción al aprendizaje supervisado y modelos de regresión",
          "Día 3: Modelos de regresión avanzados – Polinomiales y regularización",
          "Día 4: Introducción a clasificación y regresión logística",
          "Día 5: Evaluación de modelos y validación cruzada",
          "Día 6: Algoritmo de los vecinos más cercanos (k-NN)",
          "Día 7: Mini proyecto de aprendizaje supervisado",
          "Recursos para proyectos en formación"
        ],
        "Evaluación final y felicitaciones": [
          "Cuestionario final",
          "¡Felicidades y mucho éxito!"
        ]
      },
      "requirements": [
        "No se requiere experiencia previa en programación o IA — este curso es apto para principiantes",
        "Una computadora (Windows, macOS o Linux) con acceso a Internet",
        "Ganas de aprender y experimentar con nuevos conceptos",
        "Familiaridad básica con matemáticas de secundaria (el álgebra y la aritmética ayudan pero no son obligatorias)",
        "Capacidad para instalar software como Python, Jupyter Notebook y las bibliotecas necesarias (te guiaremos paso a paso)",
        "Curiosidad por cómo funciona la IA y pasión por resolver problemas",
        "Compromiso para completar las lecciones y ejercicios prácticos",
        "Opcional: Un cuaderno o herramienta digital para tomar notas y fórmulas clave"
      ],
      "description": "¿Estás listo para dar tu primer paso en la Inteligencia Artificial y convertirte en Ingeniero de IA?\nEl Curso de Certificación de Explorador en Ingeniería de IA es tu puerta de entrada al emocionante y creciente mundo de la IA, el aprendizaje automático y la ciencia de datos. Diseñado para principiantes, este curso práctico te proporciona las habilidades fundamentales que necesitas para comenzar tu camino como desarrollador o creador de productos con IA.\nComenzarás con los Fundamentos de Programación en Python para IA. Python es el lenguaje más popular en el mundo de la inteligencia artificial hoy en día. Aprenderás a escribir código limpio, entender variables, bucles, funciones y programación orientada a objetos, sentando las bases para construir aplicaciones reales de IA.\nDespués, te adentrarás en los Fundamentos de Ciencia de Datos para IA, donde explorarás el preprocesamiento de datos, la visualización y el análisis exploratorio (EDA) con herramientas como Pandas, NumPy y Matplotlib. Saber trabajar con datos es esencial en IA, y esta sección te brindará experiencia práctica lista para el mundo laboral.\nLuego, dominarás las Matemáticas para Machine Learning e IA — una base clave para cualquier profesional de IA serio. Cubriremos álgebra lineal, cálculo y operaciones matriciales de forma intuitiva y orientada a la aplicación, ayudándote a desarrollar pensamiento analítico sólido.\nTambién abordarás las Probabilidades y Estadísticas para Machine Learning, fundamentales para entender cómo los modelos de IA aprenden a partir de datos. Aprenderás sobre el teorema de Bayes, distribuciones, desviación estándar, intervalos de confianza y pruebas de hipótesis — todo con ejemplos centrados en IA que facilitan la comprensión.\nFinalmente, entrarás en el mundo del Machine Learning. En la introducción al aprendizaje automático, conocerás cómo funcionan algoritmos como la regresión lineal, la clasificación y el clustering. Usarás Scikit-learn para entrenar y evaluar modelos básicos, obteniendo experiencia directa en la construcción de flujos de trabajo de ML.\nAl finalizar el Curso de Certificación de Explorador en Ingeniería de IA, tendrás un conocimiento sólido de los conceptos fundamentales de la inteligencia artificial y estarás preparado para avanzar a temas más complejos como el deep learning, el procesamiento de lenguaje natural (NLP) y el desarrollo de productos con IA. Ya seas estudiante, desarrollador, profesional en transición o entusiasta de la tecnología, este curso te ofrece una ruta clara y estructurada para construir tu base en IA.\n- No se requiere experiencia previa\n- Incluye proyectos prácticos\n- Certificado de finalización\n- Ideal para principiantes en IA, aspirantes a científicos de datos y futuros gestores de productos IA\nDa tu primer paso hacia el futuro — únete a miles de estudiantes y comienza hoy tu camino para convertirte en un ingeniero de IA certificado.",
      "target_audience": [
        "Futuros ingenieros de IA y científicos de datos que comienzan desde cero",
        "Gerentes de producto y líderes técnicos que buscan comprender los fundamentos de la IA",
        "Estudiantes que se preparan para programas avanzados en IA o aprendizaje automático",
        "Profesionales que hacen la transición hacia roles enfocados en IA",
        "Cualquier persona que quiera explorar el mundo de la IA sin experiencia previa en programación o ciencia de datos"
      ]
    },
    {
      "title": "Analyse de données avec Pandas et Python",
      "url": "https://www.udemy.com/course/analyse-de-donnees-avec-pandas-et-python/",
      "bio": "Analysez les données rapidement et facilement avec la puissante bibliothèque pandas de Python !",
      "objectives": [
        "Effectuez une multitude d'opérations sur les données dans la bibliothèque populaire \"pandas\" de Python, notamment le regroupement, le pivotement, la jointure...",
        "Apprenez des centaines de méthodes et d'attributs sur de nombreux objets pandas",
        "Posséder une solide compréhension de la manipulation des ensembles de données 1D, 2D et 3D",
        "Résoudre les problèmes courants dans les ensembles de données brisés ou incomplets"
      ],
      "course_content": {
        "Installation et configuration": [
          "Télécharger anaconda",
          "Installer la distribution Anaconda",
          "Créer un environnement conda et installer pandas et Jupyter Notebook",
          "Créer un environnement conda et installer pandas et Jupyter Notebook partie-2",
          "Déballer le matériel de cours + Le processus de démarrage et d'arrêt",
          "Introduction à l'interface Jupyter Notebook",
          "Types de cellules et modes de cellules dans Jupyter Notebook",
          "Exécution de cellules de code dans Jupyter Notebook",
          "Raccourcis clavier populaires dans Jupyter Notebook",
          "passer des objets pandas aux fonctions intégrées de python",
          "Importer des bibliothèques dans Jupyter Notebook"
        ],
        "Series": [
          "Créez Jupyter Notebook pour le module de la série",
          "Créer un objet series à partir d'une liste python",
          "Créer un objet series à partir d'un dictionnaire",
          "Introduction aux attributs",
          "Introduction aux méthodes",
          "Paramètres et Arguments",
          "Importer des Séries avec la méthode read_csv",
          "Utilisez les méthodes head et tail pour renvoyer les lignes du début-fin",
          "Passer des objets pandas aux fonctions intégrées de python",
          "Accéder à plus d'attributs de séries",
          "Utilisez la méthode sort_values pour trier une série",
          "Utilisez le paramètre inplace pour muter définitivement une structure de données",
          "Utilisez la méthode sort_index pour trier l'index d'un objet pandas Series",
          "Utilisez le mot-clé IN de Python pour vérifier l'inclusion dans les valeurs",
          "Extraire les valeurs des séries par position d'index",
          "Extraire les valeurs de la série par étiquette d'index",
          "Utilisez la méthode get pour récupérer une valeur pour une étiquette d'index",
          "Méthodes mathématiques sur les objets de series",
          "Utilisez les méthodes idxmax et idxmin pour trouver l'indice",
          "Utilisez la méthode value_counts pour voir le nombre de valeurs uniques",
          "Utilisez la méthode apply pour appeler une fonction sur chaque valeur de série",
          "La méthode map"
        ],
        "Cadres de données-DataFrames 1": [
          "Introduction au module DataFrames",
          "Méthodes et attributs partagés entre les séries et les DataFrames",
          "Différences entre les méthodes partagées"
        ],
        "Bonus : Introduction et Installation de Hadoop": [
          "Aperçu et histoire de Hadoop",
          "Installation de Hadoop [pas à pas] partie-1",
          "Installation de Hadoop [pas à pas] partie-2",
          "Vue d'ensemble de l'écosystème Hadoop"
        ]
      },
      "requirements": [
        "Expérience de base/intermédiaire avec Microsoft Excel ou un autre tableur (fonctions communes, vlookups, tableaux croisés dynamiques, etc.)",
        "Expérience de base avec le langage de programmation Python",
        "Solide connaissance des types de données (chaînes, entiers, virgules flottantes, booléens) etc."
      ],
      "description": "Bienvenue au cours Pandas le plus complet disponible sur Udemy ! Un excellent choix pour les débutants et les experts qui cherchent à étendre leurs connaissances sur l'une des bibliothèques Python les plus populaires au monde !\nAnalyse de données avec Pandas et Python offre de tutoriels vidéo approfondis sur la boîte à outils d'analyse de données la plus puissante disponible aujourd'hui. Les leçons comprennent :\nl'installation\n\n\ntrier\n\n\nle filtrage\n\n\nle regroupement\n\n\nagrégation\n\n\ndédoublonnage\n\n\npivoter\n\n\nbroyage\n\n\nsuppression\n\n\nfusionner\n\n\nvisualisation\net bien d'autres choses encore !\n\n\nPourquoi apprendre les pandas ?\nSi vous avez passé du temps dans un logiciel de feuille de calcul comme Microsoft Excel, Apple Numbers ou Google Sheets et que vous êtes désireux de passer au niveau supérieur en matière d'analyse de données, ce cours est fait pour vous !\nAnalyse de données avec Pandas et Python vous présente la populaire bibliothèque Pandas construite sur le langage de programmation Python.\nPandas est un outil puissant qui vous permet de faire tout et n'importe quoi avec des ensembles de données colossaux : analyser, organiser, trier, filtrer, pivoter, agréger, nettoyer, calculer, et bien plus encore !\nJe l'appelle \"Excel aux stéroïdes\" !\nJe vous guiderai pas à pas à travers Pandas, de l'installation à la visualisation ! Nous couvrirons des centaines de méthodes, d'attributs, de caractéristiques et de fonctionnalités différentes qui se trouvent dans cette formidable bibliothèque. Nous nous plongerons dans des tonnes d'ensembles de données différents, courts et longs, brisés et intacts, pour démontrer l'incroyable polyvalence et efficacité de ce package.\nAnalyse de données avec Pandas et Python est fourni avec des dizaines de jeux de données que vous pouvez utiliser. Plongez-y et suivez mes leçons pour constater à quel point il est facile de se lancer avec Pandas !\nQue vous soyez un nouvel analyste de données ou que vous ayez passé des années (*trop longtemps*) dans Excel, Analyse de données avec Pandas et Python vous offre une introduction incroyable à l'une des boîtes à outils de données les plus puissantes du moment !",
      "target_audience": [
        "Développeurs Python débutants intéressés par la science des données",
        "Analystes de données et analystes d'affaires",
        "Utilisateurs d'Excel cherchant à apprendre un logiciel plus puissant pour l'analyse de données"
      ]
    },
    {
      "title": "Introdução a Data Science no R com exemplos",
      "url": "https://www.udemy.com/course/introducao-a-data-science-no-r-com-exemplos-gratuito/",
      "bio": "Gráficos, análise de dados, regressão. Entenda em um contexto geral como funciona a ESTATÍSÍTICA",
      "objectives": [
        "Entender o que é R",
        "Aprender sobre o básico de visualização de dados",
        "Estruturar um data frame",
        "Gráficos estatísticos",
        "Noções de correlação e regressão"
      ],
      "course_content": {
        "Introdução": [
          "Introdução",
          "Dicas Iniciais",
          "Resumo das dicas",
          "O que é o R?",
          "Download",
          "Conhecendo o Software",
          "Matematica e objetos",
          "Pacotes e funções",
          "Funções e dicas"
        ],
        "Análise exploratoria e descritiva": [
          "Estudos iniciais",
          "Selecionando variaveis",
          "Gráfico de barras",
          "Histograma",
          "Média, Mediana, Moda etc",
          "Boxplot"
        ],
        "Correlação e Regressão": [
          "Gráfico de dispersão",
          "Correlação de Pearson",
          "Aula bônus: Aprenda mais PAGANDO MENOS"
        ]
      },
      "requirements": [
        "Nenhum conhecimento prévio é necessario"
      ],
      "description": "Este curso é meticulosamente desenhado para desvendar o mundo da estatística e suas aplicações multifacetadas, consolidando algumas das ferramentas mais cruciais para a análise de dados em um único programa educacional abrangente. Com um foco prático, os participantes irão explorar áreas fundamentais, incluindo:\n\n\n- **Interpretação de Dados:** Aprenda a decifrar e entender o significado por trás dos números e das tendências.\n- **Análise Exploratória e Descritiva:** Descubra técnicas para inspecionar, limpar e modelar dados, fornecendo insights preliminares e resumos estatísticos detalhados.\n- **Regressão:** Domine os métodos de regressão para prever e examinar relações causais entre variáveis.\n\n\nConcebido especificamente para iniciantes, este curso não presume qualquer conhecimento prévio em programação ou na linguagem R, oferecendo uma introdução acessível e hands-on à estatística. Embora muitos dos conceitos abordados sejam complexos e possam justificar cursos dedicados, este programa é singular em sua abordagem, apresentando exemplos práticos que demonstram as aplicações das ferramentas de análise de dados.\n\n\nO objetivo é fornecer uma experiência de aprendizado rica e envolvente, onde os alunos possam aplicar conceitos teóricos a estudos de caso da vida real. Isso não apenas solidifica o entendimento dos princípios estatísticos, mas também ilustra o poder e a flexibilidade da estatística em resolver problemas reais e gerar insights valiosos.\n\n\nEste curso é um convite para explorar o potencial da estatística aplicada, equipando os alunos com as habilidades necessárias para analisar, interpretar e apresentar dados de maneira eficaz. Seja você um estudante procurando fortalecer sua base teórica, um profissional aspirando a aprimorar suas habilidades analíticas ou simplesmente alguém curioso sobre o impacto da estatística no mundo ao redor, este curso serve como um trampolim para o domínio da análise de dados.\n\n\nAo concluir o curso, os participantes estarão bem posicionados para aplicar suas novas habilidades em diversos contextos profissionais e acadêmicos, abrindo portas para oportunidades de carreira em campos que dependem de análise de dados e tomada de decisões baseadas em evidências. Prepare-se para embarcar em uma jornada educacional que irá transformar sua maneira de ver e trabalhar com dados.",
      "target_audience": [
        "Acadêmicos e profissionais que estejam interessados em conhecer análise de dados"
      ]
    },
    {
      "title": "【初心者向け】生成系AI時代のPython×自動化！Function Callingを使って煩雑な作業を自動化しよう！",
      "url": "https://www.udemy.com/course/ai-python-function-calling/",
      "bio": "ChatGPTのFunction Calling機能を使ってGmailの自動化やスクレイピングなどの処理を日本語で指示出ししておこなってくれるようにします。またCloud Functionsを使って処理を自動化していきます。",
      "objectives": [
        "Pythonの基礎",
        "スクレイピングの基礎",
        "PythonでGmail送信を行う方法",
        "Cloud Functionsを使ってAPIを作ってみたい方",
        "Cloud Schedulerでプログラムを自動定期実行してみたい方",
        "Function Callingを使って独自のエージェントを作って自動化してみたい方"
      ],
      "course_content": {
        "はじめに": [
          "イントロダクション"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Seabornについて学ぼう！",
          "Python構文の復習"
        ],
        "スクレイピング": [
          "スクレイピングをしてみよう！",
          "特定のWebページに存在するURLを全て抽出してみよう！",
          "スクレイピングのユースケースを見てみよう！"
        ],
        "PythonでGmailを操作！": [
          "アプリパスワードの取得",
          "PythonからGmailを操作してメールを送信してみよう！"
        ],
        "Cloud Functions（Cloud Run 関数）を使って自動定期実行できるようにしてみよう！": [
          "Google Cloudの登録方法",
          "【注意】Cloud Functionsの名称変更について",
          "Google Cloud Functionsに簡単な関数をデプロイしてみよう！",
          "作ったAPIを叩いて出力を確認してみよう！",
          "スクレイピングの関数をCloud Functionsにデプロイしてみよう！",
          "Cloud Schedulerを使って自動定期実行の設定をしてみよう！"
        ],
        "Functin Callingを使ってみよう！": [
          "OpenAIのAPIキーを取得しよう！",
          "【注意】httpxのバージョンに起因するエラーについて",
          "Function Callingの凄さ",
          "Function Callingを動かしてみよう！①",
          "Function Callingを動かしてみよう！②",
          "Function Callingを動かしてみよう！③"
        ],
        "Functin Callingを使って様々な操作を自動化してみよう！": [
          "名前に対応するメールアドレスを返す関数を定義しよう！",
          "メールを送信する関数を定義しよう！",
          "特定のページの情報を抽出してそれをExcelに直してメールに添付して送ってみよう！",
          "Function Callingの処理の中で独自で作った関数を定義しよう！",
          "Function Callingの各種設定を進めていこう！",
          "Function Callingを搭載したGPTモデルに指示出しをした結果を見てみよう！",
          "Excel送付の結果を見てみよう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学ぶので事前知識は不要です"
      ],
      "description": "このコースではPythonでできる様々な自動化方法を見ていきます。\n\n\nまず、PythonでスクレイピングやGmail送信などを行う方法を学んでいきます。\n\n\n続いてGoogle Cloudの提供するCloud FunctionsとCloud Schedulerという機能を使ってPythonの処理をクラウドにデプロイし自動定期実行するような処理を作っていきます。\n\n\n最後にChatGPTのFunction Callingという機能を使って日本語で指示出しをしてそれを理解した上でスクレイピングやGmail送信をしてくれるエージェントを作っていきます。\n\n\n現在、Pythonを使えば自動化できないことはないくらい便利な世の中になっています。\nぜひこのコースで学んだことを活かして日々の煩雑な業務から解放されましょう！",
      "target_audience": [
        "生成AI時代にPythonで様々な作業を自動化してみたい方",
        "PythonでGmailを操作して送信してみたい方",
        "Pythonでスクレイピングをしてみたい方",
        "Google CloudのCloud FunctionsやCloud Schedulerを使って自動定期実行を実践してみたい方",
        "Function Callingを使って独自のエージェントを作ってみたい方"
      ]
    },
    {
      "title": "生成AIのアルゴリズム徹底解説（最尤推定編）",
      "url": "https://www.udemy.com/course/generative-ai-mle/",
      "bio": "生成AIのアルゴリズムを理解したい方のための数学基礎講座です。インタラクティブな資料と丁寧な解説を通じて、数学力向上を目指します。",
      "objectives": [
        "生成モデルの構築方法",
        "1次元データの生成モデル（ポアソン分布、正規分布）",
        "2次元データの生成モデル（2次元正規分布）",
        "最尤推定のアルゴリズム"
      ],
      "course_content": {
        "当コースの紹介": [
          "添付資料",
          "概要_",
          "補足：可視化アプリについて",
          "補足：colabについて"
        ],
        "ポアソン分布": [
          "必要資料",
          "観測データ",
          "様々な生成モデル",
          "観測データの尤度_単数",
          "観測データの尤度_複数",
          "対数尤度",
          "最尤推定_1",
          "最尤推定_2",
          "最尤推定_3",
          "生成モデル",
          "データ数による最尤推定の精度の推移",
          "可視化アプリ"
        ],
        "正規分布": [
          "必要資料",
          "観測データ",
          "様々な生成モデル",
          "観測データと生成モデルの比較",
          "最尤推定_1",
          "最尤推定_2",
          "最尤推定_3",
          "対数尤度とスコア関数の可視化",
          "生成モデル",
          "データ数による最尤推定の精度の推移",
          "可視化アプリ"
        ],
        "2次元正規分布_補足": [
          "必要資料",
          "2次元のデータ",
          "共分散",
          "相関係数_1",
          "相関係数_2",
          "2次元正規分布_1",
          "2次元正規分布_2",
          "2次元正規分布_3"
        ],
        "2次元正規分布": [
          "必要資料",
          "観測データ",
          "様々な生成モデル",
          "観測データと生成モデルの比較",
          "最尤推定_1",
          "最尤推定_2",
          "最尤推定_3",
          "生成モデル",
          "データ数による推定値の精度の推移_1",
          "データ数による推定値の精度の推移_2",
          "可視化アプリ"
        ],
        "総括_": [
          "次回作"
        ]
      },
      "requirements": [
        "google アカウントが必要（colabを利用するため）",
        "微積分、確率統計の基本知識があったほうが望ましいです。"
      ],
      "description": "ChatGPTやStable Diffusionなど、話題の生成AIの「中身」が気になりませんか？\n\n\n当コースでは、生成AIの心臓部とも言える最尤推定のアルゴリズムを、一切の省略なく解説します。\n単なる使い方講座ではなく、その裏側で動作する数理を理解することで、生成AIへの深い洞察が得られます。\n\n\n◆本コースの特徴◆\n\n\nGoogle Colabによるアニメーションや独自開発の可視化アプリで「見える化」\n数式だけでは掴みにくい概念も、インタラクティブなGoogle Colabによるアニメーションや可視化アプリを使って直感的に理解できます。\nパラメータを変更すると即座に結果が表示され、「なるほど！」という体験ができます。\n\n\n徹底的な丁寧さ\n「ここは分かりますよね？」という省略は一切なし。\n基礎から応用まで、全ての過程を丁寧に説明します。\n数学が苦手な方でも着実に理解を深められるよう、細かいステップで解説します。\n\n\n実践的な理解\n理論だけでなく、実際のAIモデルでどのように使われているのかまで解説。学んだ内容と実際のAI技術とのつながりが分かります。\n\n\n◆こんな方にオススメ◆\n・AIエンジニアとして一歩先を行きたい方\n・生成AIの仕組みを本質から理解したい方\n・AIの研究開発に携わりたい方\n・数学的な裏付けを持ってAIを使いたい方\n\n\n表面的な使い方だけでなく、その裏側で動く仕組みまで理解することで、AIツールをより効果的に活用できるようになります。\n生成AI時代を生き抜くための本質的な知識を、ぜひ当コースで習得してください。",
      "target_audience": [
        "生成AIなどの最新トピックを学びたい方",
        "生成AIの仕組みを本質から理解したい方",
        "AIの可能性を理解し、実践的なスキルを身につけたい方",
        "数学的な裏付けを持ってAIを使いたい方"
      ]
    },
    {
      "title": "【한글자막】 ChatGPT 와 파이썬을 활용한 데이터 사이언스 및 데이터 분석",
      "url": "https://www.udemy.com/course/chatgpt-for-data-science-and-data-analysis-in-python-korean/",
      "bio": "AI 를 활용하여 데이터 사이언스 프로젝트 수행, 데이터 분석, 데이터 시각화, 리포팅까지 빠르게 처리하자!",
      "objectives": [
        "ChatGPT 프롬프트를 효율적으로 설계해 단계를 덜 거치고 원하는 결과를 얻는 법을 배웁니다.",
        "ChatGPT 와 그 외 생성형 AI 툴을 활용해 데이터 사이언스 프로젝트를 시작하는 법을 배워 시작 시간을 최대 90%까지 줄입니다.",
        "ChatGPT 와 생성형 AI 기술을 활용해 데이터 사이언스프로젝트 수행하는 법을 익혀 프로젝트 실행 시간을 절반까지 줄입니다.",
        "파이썬, Tableau, PowerBI 에서 멋진 데이터 시각화 자료와 보고를 순식간에 작성합니다.",
        "프롬프트 엔지니어링 의 기본 원칙 및 데이터 사이언스 분야에서의 중요성을 이해하고 설명할 수 있습니다.",
        "Google Colab 을 활용해 파이썬 프로그래밍과 데이터 분석을 효율적으로 수행하는 법을 배웁니다.",
        "ChatGPT 를 활용해 분석 데이터를 준비하고 정제하는 법을 익혀 데이터 전처리 단계를 간소화합니다.",
        "ChatGPT 를 효율적으로 활용해 범주형 데이터를 수치형으로 변환할 수 있습니다.",
        "ChatGPT 를 활용해 기술적 데이터 분석을 수행하는 법을 배우고, 정보에 입각한 의사 결정 결과를 해석합니다.",
        "ChatGPT 를 활용해 특성 엔지니어링 기법을 구현하는 법을 익힙니다.",
        "ChatGPT 를 활용해 탐색적 데이터 분석을 수행하는 법을 배워 데이터에 숨은 패턴과 인사이트를 발견합니다.",
        "ChatGPT 로 질적 데이터를 분석하는 법을 익혀 비수치형 데이터에서 가치 있는 해석을 도출합니다.",
        "데이터 분석 결과를 바탕으로 ChatGPT 를 활용해 명료하고 종합적인 보고를 작성할 수 있습니다."
      ],
      "course_content": {
        "프롬프트 엔지니어링 소개": [
          "기분 좋은 시작!",
          "Google Colab 소개",
          "ChatGPT를 마스터하기 위한 프롬프트 엔지니어링 중요 원칙",
          "프롬프트 엔지니어링 중요원칙 정리시트",
          "연습 시간: ChatGPT의 프롬프트 엔지니어링을 통한 비즈니스 데이터 분석 향상",
          "다음 주제를 정하기 위한 강의 설문"
        ],
        "ChatGPT를 통한 설문 분석": [
          "더 나은 의사결정을 위한 데이터 준비 테크닉",
          "ChatGPT로 데이터 준비하기",
          "ChatGPT를 활용한 범주형 데이터 인코딩",
          "연습 시간: 효율적인 비즈니스 데이터 준비를 위한 ChatGPT 적용",
          "비즈니스 인사이트 도출을 위한 기술 데이터 분석",
          "ChatGPT 및 Python을 사용한 반복적 특성 엔지니어링",
          "ChatGPT를 사용한 특성 생성: 데이터 디코딩하기",
          "ChatGPT를 co-pilot으로 사용하여 탐색적 데이터 분석하고 인사이트를 간소화하기",
          "ChatGPT를 이용한 정성적 데이터 분석 간소화: 텍스트 분류",
          "텍스트 분류에 ChatGPT 사용하기: 감정 분석에 대한 심층 분석",
          "연습 시간: ChatGPT로 SMILE 트위터 감정 데이터 세트 살펴보기",
          "ChatGPT로 데이터 분석 보고서 작성 및 이해관계자와의 커뮤니케이션하기"
        ],
        "OpenAI API": [
          "데이터분석을 위해 ChatGPT API 셋업하고 활용하기",
          "OpenAI API 요금",
          "연습: OpenAI API 설정 및 첫 API 프롬프트 실행하기",
          "ChatGPT 프롬프트 최적화하기: 구글 클라우드를 사용한 API 테스팅",
          "구조화된 데이터 추출을 위해 GPT-4 API에서 함수 호출 적용하기"
        ],
        "사례 연구 - 이커머스 고객 이탈 예측": [
          "ChatGPT를 활용하여 이커머스 고객이탈 예측하기 : 단계별 가이드",
          "고객이탈에 대한 이해 및 ChatGPT로 이탈 고객 식별하기",
          "향상된 특성 엔지니어링을 위한 생각의 나무 기법 적용",
          "연습 시간: 생각의 나무 기법을 적용하여 특성 엔지니어링하기",
          "특성 엔지니어링 중 반복적인 작업 간소화 및 ChatGPT 결과 검증하기",
          "ChatGPT로 특성 엔지니어링하기",
          "탐색적 데이터 분석: ChatGPT를 통한 시각적 검사 및 스팟 확인",
          "ChatGPT로 모델 구축하기: 데이터 전처리 및 클래스 불균형 처리하기",
          "예측 모델링을 위한 ChatGPT: 지표 선택 및 간단한 기준선 설정하기",
          "ChatGPT를 통한 모델 선택: 중복 극복 및 효율성 향상",
          "연습 시간: 지표 선택 및 간단한 기준선 설정에 ChatGPT 활용하기",
          "ChatGPT를 사용한 교차 검증 및 모델 선택",
          "ChatGPT로 학습 곡선 그리기 및 모델 성능 진단하기",
          "이커머스 이탈 예측의 최종 모델 학습, 해석 및 트레이드 오프",
          "섹션 연습"
        ],
        "보너스 강의": [
          "랭체인 - 기대하세요! - 랭체인을 통한 효율적인 데이터 분석"
        ],
        "축하합니다!! 상품을 잊지 마세요 :)": [
          "보너스: 최고 연봉을 잠금 해제하는 방법 (라이브 교육)",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "파이썬 (Python) 기초 지식",
        "ChatGPT 계정",
        "인터넷 연결"
      ],
      "description": "이 강의는 유데미 강좌 중 \"ChatGPT for Data Science and Data Analysis in Python\"와 동일한 강의이며, 한국어 자막이 기존 강의와 다르게 전문 한글 자막이 제공됩니다. 또한 강의 내용에 대한 질문은 Q&A에 영어로 남겨주시면 오리지널 강사님으로부터 답변을 받으실 수 있습니다. 강의 내용 외의 문의는 한국어로 남겨주셔도 되며, 웅진씽크빅 글로벌에서 매일 확인하여 답변드리고 있으니 편하게 질문해주세요! :)\n\n\nAI 의 힘을 활용해 데이터 사이언스 프로젝트의 효율을 높이고 싶나요?\nChatGPT 와 생성형 AI 기술을 활용해 효율적인 데이터 사이언스 워크플로를 설계하고 멋진 데이터 시각화 자료를 만드는 법을 배우고 싶나요?\n데이터 사이언티스트, 프로젝트 관리자, 기업가로서 AI 툴을 활용해 데이터 사이언스 프로젝트를 시작하고 효율적으로 수행하고 싶나요?\n\n\n위 질문에 하나라도 ‘예’라고 답했다면, 이 강의는 여러분을 위한 겁니다!\nOpenAI 에서 개발한 ChatGPT 는 데이터 준비, 특성 엔지니어링, 데이터 분석, 보고 생성 등 다양한 데이터 사이언스 업무에 응용할 수 있는 고급 언어 모델입니다. 본 ‘【한글자막】 ChatGPT 와 파이썬을 활용한 데이터 사이언스 및 데이터 분석’ 강의는 여러분이 ChatGPT 를 적극 활용해 데이터 사이언스 프로젝트를 빠르게 수행하도록 도와줄 겁니다.\n데이터 사이언스는 꾸준히 수요가 많은 분야 중 하나로, 여러 산업 분야에 걸쳐 수많은 취업 기회를 제공합니다. ChatGPT 와 같은 AI 기술의 등장으로 오늘날에는 데이터 사이언스 프로젝트를 더 효율적으로 수행해 시간과 노력을 크게 절감할 수 있게 됐습니다. 그 방법을 우리가 알려드리겠습니다.\n\n이 강의가 특별한 이유는 다음과 같습니다:\n\n\n응용 위주: 프롬프트 엔지니어링에서 텍스트 분류까지, 현실 세계의 데이터 사이언스 에 ChatGPT 를 응용하는 법을 배웁니다.\n단계별 가이드: 각 모듈이 이전 모듈을 토대로 설계돼 있어 데이터 사이언스 프로젝트의 여러 단계에 ChatGPT 를 활용하는 법을 종합적으로 이해할 수 있습니다.\n협력 학습: ChatGPT 를 활용해 어느 데이터 사이언스 프로젝트에나 필수인 팀 의사소통 능력을 증진하는 법을 배웁니다.\n\n\n무엇을 배우게 될까요?\n\n\n최적의 결과를 내주는 효율적인 ChatGPT 프롬프트 를 설계하는 법\nChatGPT 로 데이터 사이언스  프로젝트를 시작해 시작 시간을 최대 90%까지 줄이는 법\nChatGPT와 생성형 AI 기술을 데이터 사이언스 프로젝트 수행에 활용해 프로젝트 실행 시간을 절반까지 줄이는 법\n파이썬, Tableau, PowerBI에서 멋진 시각화 자료와 보고를 순식간에 작성하는 법\n\n\n이 강의에는 다음이 포함됩니다:\n\n\n모든 코드와 강의 자료를 받을 수 있습니다.\n링크드인 프로필에 게시해 데이터 사이언스 분야에서의 ChatGPT 활용 능력을 뽐낼 수 있도록 강의 수료 인증서를 드립니다.\n30일 이내 환불이 보장되므로 위험 부담 없이 수강하세요!\n미리보기 영상과 개요를 통해 앞으로 떠날 신나는 여정에 대해 알아보세요.\n지금 바로 등록해 함께 데이터 사이언스 에 혁신을 일으켜 보아요!",
      "target_audience": [
        "데이터 분석가 나 데이터 사이언티스트 를 희망하는 분",
        "데이터를 활용해 의사 결정을 내리는 기업가, 디지털 마케터, SNS 관리자, 제품 관리자"
      ]
    },
    {
      "title": "MediaPipe・OpenCV・Pythonで体験する画像認識技術の世界【初学者向け】",
      "url": "https://www.udemy.com/course/computervision_mediapipe/",
      "bio": "機械学習（深層学習）技術は既にここまで民主化されている！Google社製のMediaPipeライブラリを使って高精度なAI画像認識をお手軽に体験してみよう！",
      "objectives": [
        "OpenCVの基本的な使い方が学べます",
        "MediaPipeの基本的な使い方が学べます",
        "Streamlitの基本的な使い方が学べます",
        "画像処理（画像認識）技術の基本的な概念が学べます",
        "動画データに対する処理の基本が学べます",
        "MediaPipeを用いた顔検出が学べます",
        "MediaPipeを用いた手の検出が学べます",
        "MediaPipeを用いた3次元顔ランドマーク検出が学べます",
        "MediaPipeを用いた姿勢推定が学べます",
        "MediaPipe・OpenCV・Streamlit・Pythonを使った簡易的な画像認識アプリ開発"
      ],
      "course_content": {
        "紹介": [
          "コースの紹介",
          "レビューに関するお願い",
          "本コースで使用したライブラリのバージョン情報"
        ],
        "環境構築": [
          "Anacondaについて",
          "Anacondaの導入(Mac)",
          "Anacondaの導入(Win)",
          "VSCodeについて",
          "VSCodeの導入(Mac)",
          "VSCodeの導入(Win)",
          "Anacondaで仮想環境を作る",
          "VSCodeにおけるPythonの実行環境の設定",
          "VSCodeの設定やターミナルが上手く機能しない場合"
        ],
        "MediaPipeの概要とインストール": [
          "MediaPipeとは",
          "【重要】MediaPipeのバージョン指定インストールについて",
          "MediaPipeのインストールとインポート"
        ],
        "OpenCVを使った画像処理の基礎": [
          "はじめに",
          "画像処理とは",
          "デジタル画像処理における画素（ピクセル）値の考え方",
          "OpenCVとは",
          "OpenCVのインストール",
          "OpenCVのインポート",
          "OpenCVで画像の読み込みと画像情報の抽出",
          "OpenCVで画像を保存",
          "OpenCVで画像の色変換",
          "OpenCVで画像にテキストの書き込み",
          "OpenCVで画像に図形の書き込み",
          "OpenCVで画像のトリミング・リサイズ",
          "OpenCVで画像の回転・上下左右反転",
          "OpenCVで画像の平滑化処理（基本概念）",
          "OpenCVで画像の平滑化処理（プログラム）",
          "本セクションで用いる動画データのダウンロード先",
          "OpenCVで動画の再生",
          "OpenCVでWebカメラによる動画の再生"
        ],
        "セクション6および7のソースコードのダウンロード": [
          "セクション6および7のソースコードのダウンロード"
        ],
        "MediaPipeで静止画像を使った画像認識": [
          "本セクションで用いる画像データのダウンロード先",
          "静止画像からの顔検出①",
          "静止画像からの顔検出②",
          "静止画像からの顔検出③",
          "静止画像からの3次元顔ランドマーク検出",
          "静止画像からの手の検出",
          "静止画像からの姿勢推定",
          "静止画像からの姿勢・3次元顔ランドマーク・手の同時検出"
        ],
        "MediaPipeで動画を使った画像認識": [
          "本セクションで用いる動画データのダウンロード先",
          "動画データを取り扱う際の補足事項",
          "動画からの顔検出",
          "動画からの姿勢・3次元顔ランドマーク・手の同時検出",
          "Webカメラからの手の検出"
        ],
        "【実践1】AIパーソナルトレーナーを作ってみよう！": [
          "本セクションで用いる動画データのダウンロード先",
          "動画データを取り扱う際の補足事項",
          "アプリケーションの概要",
          "本セクションのソースコードのダウンロード",
          "AIパーソナルトレーナーアプリ実装①",
          "腕立て伏せの回数自動カウントアルゴリズムについて",
          "AIパーソナルトレーナーアプリ実装②",
          "2点間の直線から離れた点の距離の算出について",
          "AIパーソナルトレーナーアプリ実装③",
          "AIパーソナルトレーナーアプリ実装④"
        ],
        "Streamlitの基礎": [
          "本セクションを学ぶ上での事前確認事項",
          "Streamlitの概要",
          "Streamlitのインストールとインポート",
          "Streamlitの起動（および終了）とText（タイトルや文字）の追加と表示",
          "画像の表示",
          "動画の再生",
          "インタラクティブ機能（ボタン）",
          "インタラクティブ機能（ファイルアップローダー）",
          "インタラクティブ機能（ラジオボタン）",
          "インタラクティブ機能（チェックボックス）",
          "インタラクティブ機能（セレクトボックス）",
          "インタラクティブ機能（マルチセレクト）",
          "インタラクティブ機能（スライダー）",
          "インタラクティブ機能（サイドバー）",
          "インタラクティブ機能（プログレスバー）"
        ],
        "【実践2】バーチャル背景動画作成アプリを作ってみよう！": [
          "本セクションで用いる画像と動画データのダウンロード先",
          "動画データを取り扱う際の補足事項",
          "アプリケーションの概要",
          "本セクションのソースコードのダウンロード",
          "バーチャル背景動画作成アプリ実装①",
          "バーチャル背景動画作成アプリ実装②",
          "バーチャル背景動画作成アプリ実装③",
          "バーチャル背景動画作成アプリ実装④"
        ]
      },
      "requirements": [
        "Pythonの基本操作が出来ることを前提としています",
        "ターミナルコマンドの基本的な理解があることを前提としています",
        "Pythonの外部モジュール（ライブラリ）をインストールする手順(pipコマンドなど)を理解している",
        "Webカメラを起動するレクチャーを受講するにはWebカメラ付きのPCもしくは外付けのWebカメラが必要となります"
      ],
      "description": "Pythonの基礎を学び終えたらそろそろ画像処理・画像認識の世界を体験してみませんか？\n\n\nこの講座では、Pythonを使った画像処理・画像認識の基礎とこれらの技術を使ったアプリ開発について学べます。\n特に、画像処理を行うためのデファクトスタンダードライブラリであるOpenCV、機械学習（深層学習）技術が搭載されているパワフルなライブラリMediaPipeの環境構築や基本操作について解説します。\nまた、PythonだけでWebアプリを作ることが出来るStreamlitの環境構築や基本操作についても解説していきます。\n\n\n実践編では、画像処理（画像認識）技術を使った”AIパーソナルトレーナーアプリ”と”バーチャル背景動画作成アプリ”の開発にチャレンジしていきます。\n\n\n本講座を学ぶことで、画像処理の基本的な概念から各種画像処理ライブラリの基本操作、そしてこれらの技術を組み合わせたアプリ開発までを一気に体験していただけます。\n\n\n\n\n□講座の特徴\n・Pythonの基礎は学んだが次に何をすれば良いかまだ決まっていない\n・画像処理（画像認識）を使ってどんな応用が出来るのか興味がある\n・StreamlitをWebアプリの開発に興味がある\n上記に当てはまる方はこの講座に向いていると思います。\n\n\n□講座で取り扱わない内容\n・画像処理（画像認識）の理論的な内容は扱いません\n・機械学習（深層学習）の理論的な内容は扱いません\n・データサイエンスに特化したPythonライブラリ（ pytorch, tensorflowなど）は扱いません\n※上記内容についてはこの講座では扱わない内容ですので、ご注意ください。",
      "target_audience": [
        "Pythonの基礎を学んだが次に何をすれば良いかわからない人",
        "画像処理や画像処理技術を学び始めたい方",
        "OpenCVの基本的な使い方に関心がある人",
        "MediaPipeの基本的な使い方に関心がある人",
        "Streamlitの基本的な使い方に関心がある人",
        "動画データに対する処理技術に関心がある人",
        "MediaPipe・OpenCV・Streamlit・Pythonを使った簡易的な画像認識アプリ開発を体験してみたい人"
      ]
    },
    {
      "title": "Kelas Data Analyst Python 2025 & Project (New Update: + SQL)",
      "url": "https://www.udemy.com/course/kelas-analisis-data-dan-visualisasi-data-python-terbaru/",
      "bio": "Bahasa Python Untuk Analisis Data dan Visualisasi Data, Disertai Kuis, Latihan, Project. Update Terbaru Penambahan SQL.",
      "objectives": [
        "Mengenal Google Colaboratory dan Cara Menggunakannya",
        "Dapat Menggunakan Library Numpy dan Struktur Data Array untuk Analisis Data",
        "Dapat Menggunakan Library Pandas dan Struktur Data Series & Dataframe untuk Analisis Data dan Visualisasi Data",
        "Dapat Menggunakan Library Matplotlib, Seaborn dan Plotly untuk Membuat Berbagai Macam Visualisasi Data",
        "Mengenal BPS dan Kaggle sebagai Sumber Data untuk Dilakukan Analisa",
        "Dapat Membuat Project-project Analisis Data dan Menyampaikannya Pada Orang Lain",
        "Menggunakan Platform Medium untuk Membuat Artikel Analisa Data"
      ],
      "course_content": {
        "Pengenalan dan Persiapan Kelas": [
          "Pengenalan Kelas Analisis Data dan Visualisasi Data Python",
          "Tutorial Menggunakan Platform Udemy (Q&A Section)",
          "Terhubung di LinkedIn",
          "Ayo Kita Mulai! (Panduan Kelas)",
          "Pekerjaan Data Analyst di Indonesia dan Tujuan Kelas/Course"
        ],
        "Google Colaboratory": [
          "Mengenal Google Colab",
          "Tampilan Google Colab",
          "Library Bawaan Google Colab dan Upload File ke Google Drive",
          "GAME START!"
        ],
        "[TRAINING GROUND] Python Dasar": [
          "Overview Python Dasar",
          "Tipe Data Number",
          "Kuis Tipe Data Number",
          "Variabel",
          "Kuis Variabel",
          "Tipe Data String",
          "Kuis Tipe Data String",
          "Fungsi Print dan String Formatting",
          "Kuis Fungsi Print dan String Formatting",
          "Tipe Data List",
          "Kuis Tipe Data List",
          "Mutable dan Immutable",
          "Kuis Mutable dan Immutable",
          "Tipe Data Dictionary",
          "Kuis Tipe Data Dictionary",
          "Tipe Data Boolean dan Operator Perbandingan",
          "Kuis Tipe Data Boolean dan Operator Perbandingan",
          "Tipe data Tuple dan Set",
          "Kuis Tipe Data Tuple dan Set",
          "Built-in Function",
          "Kuis Built-in Function",
          "Pernyataan Kondisional (if elif else)",
          "Kuis Pernyataan Kondisional",
          "Operator Logika",
          "Kuis Operator Logika",
          "Pengulangan (Loop Statement)",
          "Kuis Pengulangan (Loop)",
          "Fungsi range dan enumerate",
          "Kuis fungi range dan enumerate",
          "List Comprehension",
          "Kuis List Comprehension",
          "Fungsi",
          "Kuis Fungsi",
          "Perbedaan Built-in Function, Method dan Fungsi",
          "Kuis Perbedaan Built-in Function, Method dan Fungsi",
          "Module/Library/Package",
          "Kuis Module/Library/Package"
        ],
        "[MISSION 1] NumPy: Array": [
          "Overview Mission 1",
          "Mengenal Library NumPy",
          "Kuis Mengenal Library NumPy",
          "Membuat Array dari List",
          "Kuis Membuat Array dari List",
          "Membuat Array dari Fungsi",
          "Kuis Membuat Array dari Fungsi",
          "Indexing dan Slicing pada Array",
          "Kuis Indexing dan Slicing pada Array",
          "Reassignment dan Operasi Matematika pada Array",
          "Kuis Reassignment dan Operasi Matematika pada Array",
          "Manipulasi Bentuk Array",
          "Kuis Manipulasi Bentuk Array",
          "Attribute dan Fungsi Statistik Array",
          "Kuis Attribute dan Fungsi Statistik Array",
          "Latihan NumPy Array",
          "Solusi Latihan NumPy Array",
          "Mission 1 Completed!"
        ],
        "[MISSION 2] NumPy: Fungsi Universal dan Module Random": [
          "Overview Mission 2",
          "Fungsi Universal NumPy",
          "Kuis Fungsi Universal NumPy",
          "Latihan Fungsi Universal NumPy",
          "Solusi Latihan Fungsi Universal NumPy",
          "Distribusi Probabilitas (Penjelasan Intuitive)",
          "Kuis Distribusi Probabilitas",
          "Membuat Array Random",
          "Kuis Membuat Array Random",
          "Membuat Array Random Sesuai Distribusi",
          "Kuis Membuat Array Random Sesuai Distribusi",
          "Random Seed",
          "Kuis Random Seed",
          "Latihan Module Random NumPy",
          "Solusi Latihan Module Random NumPy",
          "Mission 2 Completed!"
        ],
        "[MISSION 3] Pandas: Pengenalan Pandas dan Series": [
          "Overview Mission 3",
          "Mengenal Library Pandas",
          "Kuis Mengenal Library Pandas",
          "Membuat Series",
          "Kuis Membuat Series",
          "Indexing dan Slicing pada Series",
          "Kuis Indexing dan Slicing pada Series",
          "Operasi dan Fungsi pada Series",
          "Kuis Operasi dan Fungsi pada Series",
          "Latihan Series",
          "Solusi Latihan Series",
          "Mission 3 Completed!"
        ],
        "[MISSION 4] Pandas: DataFrame": [
          "Overview Mission 4",
          "Membuat DataFrame 1: Dari List dan Array",
          "Kuis Membuat DataFrame 1",
          "Membuat DataFrame 2: Dari Dictionary",
          "Kuis Membuat DataFrame 2",
          "Mengakses Kolom DataFrame",
          "Kuis Mengakses Kolom DataFrame",
          "Mengakses Baris DataFrame",
          "Kuis Mengakses Baris DataFrame",
          "Indexing dan Slicing DataFrame",
          "Kuis Indexing dan Slicing DataFrame",
          "Mengubah Nama Kolom, Baris dan Isi DataFrame",
          "Kuis Mengubah Nama Kolom, Baris dan Isi DataFrame",
          "Menambahkan Kolom dan Baris DataFrame",
          "Kuis Menambahkan Kolom dan Baris DataFrame",
          "Menghapus Baris dan Kolom pada DataFrame",
          "Kuis Menghapus Baris dan Kolom pada DataFrame",
          "Cara Menggabungkan Dataframe (Concat, Merge dan Join)",
          "Latihan Pandas: DataFrame",
          "Solusi Latihan Pandas: DataFrame",
          "Mission 4 Completed!"
        ],
        "[MISSION 5] Pandas: Input Output (I/O) dan Dataset Review": [
          "Overview Mission 5",
          "Dataset",
          "Kuis Dataset",
          "I/O Pandas: Menghubungan Google Colab dengan Google Drive",
          "I/O Pandas: Membuka dan Menulis Data",
          "Kuis Pandas I/O",
          "Head, Tail dan Sample",
          "Kuis Head, Tail dan Sample",
          "Pandas Options Display",
          "Kuis Pandas Options Display",
          "Method Info dan Macam Dtype",
          "Kuis Method Info dan Macam Dtype",
          "Method Describe dan Statistik",
          "Kuis Method Describe dan Statistik",
          "DataFrame API Reference",
          "Latihan Pandas I/O dan Dataset Review",
          "Solusi Latihan Pandas I/O dan Dataset Review",
          "Mission 5 Completed!"
        ],
        "[MISSION 6] Pandas: Analisis Data": [
          "Overview Mission 6",
          "Filtering DataFrame Part 1",
          "Kuis Filtering 1",
          "Filtering DataFrame Part 2",
          "Kuis Filtering 2",
          "Filtering Menggunakan Query",
          "Grouping Dataframe Part 1",
          "Kuis Grouping 1",
          "Grouping Dataframe Part 2",
          "Kuis Grouping 2",
          "Pivot Table",
          "Kuis Pivot Table",
          "Nilai Unik",
          "Kuis Nilai Unik",
          "Mengurutkan DataFrame",
          "Kuis Mengurutkan DataFrame",
          "Menggunakan Fungsi pada Series dan DataFrame",
          "Kuis Menggunakan Fungsi",
          "Mengenal Medium.com",
          "Latihan: Membuat Artikel Analisa Data",
          "Mission 6 Completed!"
        ],
        "[MISSION 7] Pandas: Pembersihan Data": [
          "Overview Mission 7",
          "Pengelanan Data Cleaning",
          "Kuis Pengenalan Data Cleaning",
          "Data Kosong/Missing Data Part 1",
          "Kuis Data Kosong 1",
          "Data Kosong/Missing Data Part 2 + Library Missingno",
          "Kuis Data Kosong 2",
          "Data Duplikat",
          "Kuis Data Duplikat",
          "Data Error/Tidak Sesuai Part 1",
          "Kuis Data Error/ Tidak Sesuai",
          "Data Error/Tidak Sesuai Part 2",
          "Kuis Data Error/ Tidak Sesuai",
          "Kesalahan Tipe Data",
          "Kuis Kesalahan Tipe Data",
          "Latihan Pandas: Pembersihan Data",
          "Solusi Latihan Pandas: Pembersihan Data",
          "Mission 7 Completed!"
        ]
      },
      "requirements": [
        "Laptop/Komputer dan Koneksi Internet. Tidak diperlukan pengetahuan dasar."
      ],
      "description": "Selamat datang di kelas Analisis dan Visualisasi Data dengan Python bersama saya, Risdan Kristori. Di kelas ini, kita akan membahas tools yang digunakan dalam analisis data menggunakan Python, mulai dari NumPy, Pandas, hingga Matplotlib, Seaborn, dan Plotly untuk visualisasi data.\nBagi Anda yang masih baru dalam dunia pemrograman Python, jangan khawatir. Kami telah menyiapkan materi Python dasar yang dapat diakses melalui link yang kami sediakan. Ini akan membantu Anda memahami fondasi Python sebelum melangkah lebih jauh dalam analisis data.\nSelama mengikuti kelas ini, Anda akan diberikan kuis dan latihan untuk menguji pemahaman Anda. Setiap latihan dilengkapi dengan pembahasan, sehingga Anda bisa belajar dari setiap kesalahan dan memperbaiki pemahaman Anda. Tak hanya itu, Anda juga akan diajak membuat proyek data analisis yang menggunakan data-data menarik dari BPS dan Kaggle. Proyek-proyek ini bisa Anda gunakan sebagai portfolio dalam membangun karier di dunia data science.\nKami menggunakan Google Colab, platform berbasis cloud yang memudahkan Anda untuk belajar tanpa perlu repot-repot melakukan instalasi. Anda bisa belajar kapanpun dan dimanapun, cukup dengan menggunakan laptop atau komputer yang tersedia.\nAgar pengalaman belajar lebih seru dan interaktif, kelas ini dirancang dalam bentuk permainan. Setiap materi disusun dalam bentuk misi, di mana Anda akan menyelesaikan step-by-step tutorial, menjawab kuis, dan mengerjakan latihan atau project di setiap akhir misi. Setelah menyelesaikan misi, Anda akan mendapatkan poster completion card sebagai penghargaan.\nSertifikat penyelesaian dari UDEMY juga tersedia bagi Anda yang berhasil menyelesaikan kelas ini.  Sertifikat ini dapat kalian gunakan sebagai lampiran di CV kalian.\nSaya telah mengajar lebih dari seribu orang di Udemy dan mendapatkan ulasan positif. Dengan pengalaman ini, saya merancang kelas ini agar Anda mendapatkan pengalaman belajar yang efektif dan menyenangkan.\nJadi, tunggu apa lagi? Segera daftar dan mulai perjalanan Anda dalam dunia analisis data dengan Python!\n\n\nMAJOR UPDATE MATERI KELAS\nTerdapat tambahan materi SQL Berikut:\nMateri SQL dibagi menjadi dua bagian besar:\nSection 21 - SQL PART 1: Dasar-dasar SQL & PostgreSQL\nPengenalan SQL\nMenjalankan Container PostgreSQL\nPerintah Help\nPerintah PSQL - DATABASE\nPerintah PSQL - TABLE\nTipe Data PostgreSQL\nTipe Data Number\nTipe Data Character\nTipe Data Date & Boolean\nPerintah SQL - INSERT INTO\nPerintah SQL - SELECT FROM\nSQL Constraint - PRIMARY KEY\nSQL Constraint - UNIQUE\nSQL Constraint - NOT NULL\nSQL Constraint - CHECK\nSQL Constraint - DEFAULT\nPerintah PSQL - ALL RELATIONS\nMenjalankan Perintah SQL Melalui File\nPerintah SQL - ORDER BY\nPerintah SQL - DISTINCT\nSection 22 - SQL PART 2: Query Lanjutan & Relasi Antar Tabel\nMembuat Table products\nPerintah SQL - WHERE\nWHERE dan Operator Logika\nWHERE dan BETWEEN\nWHERE dan LIKE / ILIKE\nWHERE dan IN\nGROUP BY\nGROUP BY dan HAVING\nLIMIT\nFungsi dan Operator Matematika\nFungsi String dan Fungsi Date\nFungsi Manipulasi Data dan Fungsi Administrasi\nAlias dengan SQL - AS\nPerintah SQL - DELETE\nPerintah SQL - UPDATE\nPerintah SQL - ALTER\nSQL Constraint - FOREIGN KEY\nMembuat Table transactions\nJOIN dalam SQL\nMacam-macam JOIN\nJadi di kelas ini Terdapat 2 Materi Yaitu Python dan SQL ++ PROJECT, Tunggu apalagi, segera dapatkan!!\nSampai jumpa di kelas,\nRisdan Kristori\nInstructor Bayou Data",
      "target_audience": [
        "Kelas ini di desain untuk siapapun yang tertarik dengan data analysis tanpa perlu basic apapun."
      ]
    },
    {
      "title": "역학조사관을 위한 통계",
      "url": "https://www.udemy.com/course/ez-epidem/",
      "bio": "역학 조사관들만을 위한 실제적인 통계",
      "objectives": [
        "역학조사에 필요한 기본적인 통계적 개념",
        "역학조사에 활용할 수 있는 통계적 도구의 실제 사용법"
      ],
      "course_content": {
        "역학조사관을 위한 통계- 공통 과목": [
          "도입",
          "더 크다는 것을 어떻게 판단할까?(2024년 6월 14일강의 녹화)",
          "1과. 여자의 비율이 늘었군요",
          "3과. 10 개 학교의 집단 감염 사고",
          "4과. 상관성과 인과성",
          "4과, 상관성이 인과성이 되려면"
        ],
        "2020-21년도 역학조사 연보-를 보면서": [
          "2020-21년도 역학조사 연보-를 보면서"
        ],
        "실습강의-직접 따라해 보고 익히세요. 실제 역학 조사를 할 때 다시 한번 더 보세요.": [
          "실습1",
          "실습 강의 실황 - epidemic curve 그리기 엑셀과 R로",
          "실습2 네이버 폼에서 날짜 계산 역학곡선 그리기",
          "실습3 구글 설문지에서 날짜 계산 역학곡선 그리기",
          "실습4 역학곡선 활용하기",
          "엑셀의 셀을 이용한 epidemic curve - 최근에 약간 인기있는 디자인인듯합니다.",
          "5과. 쉽게 하기1. 엑셀로 여러 계산을 한꺼번에",
          "6과. 쉽게 하기- R 을 이용한 도구"
        ],
        "기존의 강의들": [
          "실습 강의 실황 - 오즈비/위험비 구하기",
          "5과. 쉽게 하기2. 설문지를 엑셀로"
        ],
        "역학 논문에서 사용되는 통계": [
          "6과. 로지스틱 회귀분석"
        ]
      },
      "requirements": [
        "컴퓨터, 엑셀"
      ],
      "description": "역학 조사관들은 통계 전공자도 아니고, 수학전공자도 아닙니다.\n불을 끄는 소방관과도 같이, 전장의 군인과도 같이\n짧은 시간에 조사하고 보고서를 써야 합니다.\n역학 조사관만을 위한 통계적 개념을 짧은 시간에 마스터 하도록 합니다.\n역학 조사관만을 위한 무료이며 편리한 도구를 개발하여 소개합니다.\n실제 작성된 다양한 보고서와 논문을 바탕으로\n목표가 분명한 강의입니다.",
      "target_audience": [
        "역학조사관"
      ]
    },
    {
      "title": "深度强化学习2.0 (Deep Reinforcement Learning 2.0)",
      "url": "https://www.udemy.com/course/deep-reinforcement-learning-chinese/",
      "bio": "深度Q-learning，策略梯度，演员评论家模型以及DDPG模型的完美结合",
      "objectives": [
        "Q-Learning",
        "深度Q-Learning",
        "策略梯度",
        "演员评论家模型",
        "深度确定性策略梯度（DDPG）",
        "双延迟DDPG",
        "深度强化学习的基本技术",
        "如何运用最先进的AI技术训练模型来解决最具有挑战性的问题"
      ],
      "course_content": {
        "第一部分 - 基础": [
          "欢迎 (Welcome)",
          "在我们开始之前有一些资源分享给大家 (Some resources)",
          "Q-Learning",
          "深度Q-Learning",
          "策略梯度 (Policy Gradient)",
          "演员评论家模型 (Actor-Critic)",
          "AI模型的结构构架 (Taxonomy of AI models)",
          "优势：使用DRL的五大优势 (Bonus: 5 Advantages of DRL)",
          "优势：RL算法图"
        ],
        "第二部分- 双延迟DDPG模型的理论": [
          "介绍以及模型的初始化 (Introduction and Initialization)",
          "Q-Learning的部分",
          "策略学习的部分 (The Policy Learning part)",
          "整个训练过程 (The whole training process)"
        ],
        "第三部分 - 双延迟DDPG模型的实现": [
          "完整的模型实现的代码文件夹 (The whole code)",
          "开始 (Beginning)",
          "实现 - 第一步",
          "实现 - 第二步",
          "实现 - 第三步",
          "实现 - 第四步",
          "实现 - 第五步",
          "实现 - 第六步",
          "实现 - 第七步",
          "实现 - 第八步",
          "实现 - 第九步",
          "实现 - 第十步",
          "实现 - 第十一步",
          "实现 - 第十二步",
          "实现 - 第十三步",
          "实现 - 第十四步",
          "实现 - 第十五步",
          "实现 - 第十六步",
          "实现 - 第十七步",
          "实现 - 第十八步",
          "实现 - 第十九步",
          "实现 - 第二十步"
        ],
        "The Final Demo!": [
          "实例 - 训练",
          "实例 - 推演"
        ],
        "附件 1 - 人工神经网络模型 (Artificial Neural Networks)": [
          "课程计划 (Plan of Attack)",
          "神经元 (The Neuron)",
          "激活方法 (Activation Function)",
          "神经网络是如何运作的？",
          "神经网络模型是如何学习的？",
          "梯度下降 (Gradient Descent)",
          "随机梯度下降 (Stochastic Gradient Descent)",
          "反向传播 (Back-propagation)"
        ],
        "附件 2 - Q-Learning": [
          "课程计划 (Plan of Attack)",
          "什么是深度学习? (What is Reinforcement Learning?)",
          "贝尔曼方程 (The Bellman Equation)",
          "计划 (The Plan)",
          "马尔可夫决策过程 (Markov Decision Process)",
          "策略 vs 计划 (Policy vs Plan)",
          "惩罚法则 (Living Penalty)",
          "Q-Learning的教程",
          "临时差异 (Temporal Difference)",
          "Q-Learning的视觉呈现"
        ],
        "附件 3 - 深度Q-Learning (Deep Q-Learning)": [
          "课程计划 (Plan of Attack)",
          "深度Q-Learning教程 - 第一步",
          "深度Q-Learning教程 - 第二步",
          "经验重演 (Experience Replay)",
          "行动选择策略 (Action Selection Policies)"
        ]
      },
      "requirements": [
        "一些基础的数学知识，比如，什么是差异化或者梯度",
        "一些编程知识（类以及对象）"
      ],
      "description": "欢迎来到深度强化学习2.0！\n在这个课程中，我们回学习并且实现一个新的AI模型，较早双延迟DDPG。它是包括了当前最先进的人工智能技术，包括连续性双深度Q-learning，策略梯度，以及演员评论家模型。这个模型非常的强大，利用它，我们可以在课程中第一次解决最具有挑战性的AI问题（训练一个蚂蚁/蜘蛛，以及一个半人形机器人，让它走路或者跑过原野）。\n为了构建这个模型，我们分成三步来处理：\n第一部分：基础讲解\n在这一部分中，我们会学习人工智能的所有必须基础部分。这部分之后，大家可以掌握AI的基础知识，其中包括，Q-Learning,深度Q-learning,策略梯度，演员评论家模型以及更多。\n第二部分：双延迟DDPG理论\n这一部分中我们会深入学习整个模型背后的理论知识。大家会通过一系列的视觉呈现幻灯片，清楚看到完整的AI构建以及训练的过程。不仅大家可以学到理论知识的细节，同时还可以构建坚实的AI学习以及运作的理论基础。第一部分中的理论基础，结合第二部分的细节解释，会让这些高不可攀的技术，在你面前变得唾手可得。最终大家会成为，少数一批最先掌握这门技术的人。\n第三部分：双延迟DDPG的实现\n我们会从最基础开始构建这个模型，一步一步，通过互动的部分，这也是这一课程新增加的一个亮点，大家可以自己练习代码的实现部分，跟我们一起进行模型的实现。通过这些练习，大家不再只是被动地跟着课程走，而是主动地、更有效地提高技术。最后还有一点很重要的是，我们所有的实现部分都会放在Colaboratory中来做，也叫做Google Colab，这是一个完全免费的开源的人工智能平台，让大家可以进行编码，训练AI模型，而免去在自己的机器上安装各种资源包的困扰。换句话说，大家在执行代码的时候，可以百分百的确信，可以最后拿到蜘蛛以及半人形机器人的训练视频。",
      "target_audience": [
        "想要进一步学习AI技术的大数据科学家",
        "想要拓展知识领域的AI专家",
        "在科技和自动化领域工作的工程师",
        "想要在商业游戏中获得领先的企业家以及公司",
        "学习技术课程，并且想要未来从事数据科学，机器学习，或者人工智能领域工作的学生",
        "其他对人工智能有兴趣的人"
      ]
    },
    {
      "title": "MCPでAIと世界をつなごう！【Claude Desktop/Claude Code】",
      "url": "https://www.udemy.com/course/mcp-claude/",
      "bio": "Model Context Protocol（MCP）を活用してLLM（大規模言語モデル）と外部システムを接続しましょう。チャットボットから次の段階へ。Claude DesktopとClaude Codeで生成AIの可能性を広げます。",
      "objectives": [
        "Model Context Protocol（MCP）を使って、LLM（大規模言語モデル）と外部世界をつなぐ方法を学びます。",
        "AIモデルが外部のリソースに標準化された方法でアクセスできるModel Context Protocol（MCP）の基礎を学びます。",
        "Claude DesktopやClaude Codeを通じてAIを様々なシステムやデータソースと接続する方法を学びます。",
        "実際のワークフローに深く統合された強力なAIアシスタントを構築する方法を学びます。",
        "Claude DesktopやClaude Codeの設定方法を学びます。"
      ],
      "course_content": {
        "MCPの基礎とClaude Desktopの導入": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "MCPとは？",
          "Claude Desktopのインストール",
          "Claude Desktopを使ってみよう！",
          "外部アプリとの連携",
          "セクション1の小テスト"
        ],
        "Claude Codeの導入とMCPの可能性": [
          "Section2の概要",
          "Claude Codeとは？",
          "「Claude Codeの設定」で使用するコマンド、設定",
          "Claude Codeの設定",
          "Claude Codeを使ってみよう！ Part1",
          "Claude Codeを使ってみよう！ Part2",
          "Claude Codeを使ってみよう！ Part3",
          "セクション2の小テスト"
        ],
        "MCPの応用": [
          "Section3の概要",
          "MCPの活用",
          "データベースにアクセスする",
          "「Web検索の結果をローカルに保存する」で使用するコマンド、設定",
          "Web検索の結果をローカルに保存する",
          "「Zapier MCPの利用」で使用するコマンド、設定",
          "Zapier MCPの利用",
          "最後に",
          "セクション3の小テスト"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "最新の情報をカバーしていない可能性があります。2025年7月までの情報を元にした講座です。",
        "Claudeの無料プランでも受講可能です。ただし、無料プランにはある程度の制限があります。有料プランに入った方が望ましいです。",
        "プログラミングの経験がある程度あるのが望ましいですが、無くても受講可能です。",
        "コードの読み方、書き方に関する解説はありません。",
        "環境はWindowsでもMacでも、Claude Desktopが動作すれば大丈夫です。",
        "Brave Search APIやZapier MCPなどの外部サービスを使いますが、これらは無料プランで大丈夫です。"
      ],
      "description": "「MCPでAIと世界をつなごう！【Claude Desktop/Claude Code】」は、Model Context Protocol（MCP）を活用してAIと外部システムを連携させ、AI活用の可能性を飛躍的に拡張したいエンジニア、開発者、そしてAI活用の最前線を探求したいすべての方のための講座です。\n\n\n本講座では、Anthropic社が提唱したModel Context Protocol（MCP）を使いこなし、Claude DesktopやClaude Codeを通じてAIを様々なシステムやデータソースと接続する技術を学びます。\nMCPとは、AIモデルが外部のリソース（ファイルシステム、データベース、API、開発ツールなど）に安全かつ標準化された方法でアクセスできるようにするプロトコルです。\nこの技術により、Claudeは単なるチャットボットから、実際のワークフローに深く統合された強力なAIアシスタントへと進化します。\nAIをより実用的に活用したい方、開発ワークフローにAIを統合したい方、次世代のAI活用技術をいち早く習得したい方に最適です。\n\n\n講座の内容は以下の通りです。\nSection1. MCPの基礎とClaude Desktopの導入\n→ Model Context Protocol（MCP）の概念、仕組み、従来のAI活用との違いを解説します。また、Claude Desktopを導入し基本的な設定と操作方法についても学びます。\nSection2. Claude Codeの導入とMCPの可能性\n→ Claude Codeを導入し、MCPを活用した開発環境を構築します。\nSection3. MCPの応用\n→ MCPを様々な場面で応用し、強力なAIアシスタントを構築します。",
      "target_audience": [
        "Model Context Protocol（MCP）を学び、LLMと外部サービスをつなぎたいエンジニア、プログラマー、クリエイターの方。",
        "GmailやGoogle Calendar、SlackなどのサービスとLLMを統合したい方。",
        "AIを使った仕事の生産性を飛躍的に高めたいビジネスマンの方。",
        "AI時代の新しい働き方・開発手法をいち早く取り入れたい方。",
        "開発やビジネスのワークフローにAIを統合したい方。"
      ]
    },
    {
      "title": "(`24 가을 개정)ChatGPT 활용법, 생성 AI 프롬프트 엔지니어링 A to Z-인공지능의 이해와 활용",
      "url": "https://www.udemy.com/course/maso-ds-gpt-onc84/",
      "bio": "챗 GPT, Midjourney, MS Designer 등 생성형 인공지능 도구를 누구보다 먼저 정복하고 프롬프트 엔지니어링에 입문하여 AI 시대의 선구자가 되는 과정",
      "objectives": [
        "ChatGPT를 비롯한 생성형 AI에 대한 이해와 실무 적용 방안",
        "ChatGPT를 구성하는 인공지능과 언어 처리 모델의 작동 원리 이해",
        "생성형 AI 툴을 활용하여 구체적인 성과를 창출하는 프롬프트 엔지니어링 역량",
        "midjourney, MS Designer 등 여러 가지 생성형 AI 툴의 활용 방안"
      ],
      "course_content": {},
      "requirements": [
        "실습 위주의 강의이기 때문에 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기를 함께 준비해주시면 좋습니다.",
        "또한 Windows OS 기반으로 실습이 진행되므로, Windows 환경에서의 강의 수강을 추천해드립니다.",
        "강의 내용 중 ChatGPT의 API 키 발급과 Midjourney 서비스 이용은 유료 결제가 필요한 부분입니다. 하지만 강의 수강에는 필수 사항이 아니며, 해당 부분의 실습은 선택적으로 참여하실 수 있습니다. 이 강의의 주요 목표는 다양한 생성형 AI 툴의 활용 방법과 그 가능성을 이해하고, 이를 통해 업무에 어떻게 적용할 수 있는지에 대한 인사이트를 제공하는 것입니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n\nChat GPT의 활용법부터 생성 AI 프롬프트 이해를 위한 완벽 가이드!\n\n\nAI시대의 파도, 휩쓸릴 것인가 앞서나갈 것인가?\n코로나-19 바이러스가 가져온 변화가 끝날 무렵, 세상은 다시 크게 변하기 시작했습니다.\n바둑 AI의 바둑계 평정, 작문 AI의 문학상 심사 통과, 디자인 AI의 등장 등 이미 조짐은 보였지만,\nOpenAI의 Chat GPT가 세상에 발표되고 그 변화는 수면 위로 올라오게 되었습니다.\n1억 명의 사람들이 GPT에게 말을 걸기까지 걸린 시간은 단 2달.\n2024년 이용자 20억 명 돌파!\n지금껏 세상을 바꿔 온 수많은 서비스들이 있었지만, Chat GPT는 그 기준을 바꾸고 있습니다.\n온 세상이 인공지능 이야기를 하고 있지만, 그에 대한 시각은 모두가 다를 것입니다.\n인공지능 도구는 단순히 신기한 장난감일까요?\n아니면 생산성에 혁명을 가져올 4차 산업혁명의 핵심 기술일까요?\n사실 인공 지능을 활용해 생산성을 얻는 방법은 지금도 나오고 있지만, 모든 것은 여러분이 사용하기에 따라 달라질 것입니다.\n인공지능이 혁신적인 것은 맞지만, 어디까지나 사람이 사용하는 도구이기 때문입니다.\n마소캠퍼스의 <ChatGPT 활용법, 생성 AI 프롬프트 엔지니어링 A to Z >강의는\n시대의 변화 속에서 여러분이 살아남고, 달라진 시대의 주인이 될 수 있도록 도와드리기 위해 제작되었습니다.\n인공지능을 생산성 향상의 도구로서 활용하기 위해 인공지능의 작동 원리에 대한 이해와 활용 방법에 대해 익히고,\nChat GPT를 포함해 대표적인 생성형 인공지능 도구들을 실습해보며 누구보다 빠르게 인공지능과 친해질 수 있도록 도와드립니다.\nChat GPT와 그래픽 디자인 도구 Midjourney, Designer에서 최상의 결과물을 얻을 수 있는 효과적인 언어 입력 방법을 알아보고,\n특정 요구사항에 맞게 응답을 맞춤설정하는 고급 기술을 살펴보면, 이들이 제공하는 무한한 가능성이 눈에 보이기 시작할 것입니다.\n인공 지능이 시대의 주인이 아니라, 인공 지능을 가장 먼저 능숙하게 사용하는 여러분이 시대의 주인이 될 것입니다.\n\n\nChatGPT 활용법, 생성 AI 프롬프트 엔지니어링 A to Z 강의를 듣고 나면\n마소캠퍼스의 < ChatGPT 활용법, 생성 AI 프롬프트 엔지니어링 A to Z > 강의를 듣고 나면,\n여러분께서는 다음과 같은 역량을 확보하실 수 있습니다.\n\n인공지능에 대한 이해와 ChatGPT 실무 적용 방안\n생성형 AI 기술과 언어 처리 모델의 작동 원리 이해\n생성형 AI 툴을 활용하여 구체적인 성과를 창출하는 프롬프트 엔지니어링 역량\nChatGPT, midjourney 등 여러가지 생성형 인공지능 툴의 활용 방안\n입이 떡 벌어지게 놀라운 성능으로 엄청난 주목을 받고 있는 인공지능!\n계속 입 벌리고 계세요. 마소캠퍼스가 다 떠먹여드립니다!\n\n\n본 강의를 통해 가장 먼저 인공지능 기술과 친해지고 실제로 여러 가지 생성형 AI 도구들을 사용해 엄청난 업무 효율 상승을 경험하고, 실제 생활에도 적용할 방안을 고려할 수 있습니다.\n\n\nSTEP 1. 생성형 AI 개념과 작동 프로세스 이해하기\n더 이상 만화나 영화에서 보던 상상 속의 존재가 아닌 인공지능! 인공지능이 어떤 원리로 구현되고 작동해 결과를 내놓는지 이해하면 활용도도 높아집니다.\nSTEP 2. 챗 GPT가 어떻게 우리 말을 알아듣고 답변하지?\n어떻게 컴퓨터가 인간의 언어를 이해하고, 올바른 답을 찾아 답변할 수 있는지, 그 시작부터 현재의 혁명적인 도약에 이르기까지 발달 과정을 살펴봅니다.\nSTEP 3. 생성형 AI에게 내 일 대신 부탁하기\n간단한 조사, 분석을 넘어 긴 글 창작하기, 디테일한 그래픽 디자인, 프로그래밍과 같은 고급 업무까지!\n생성형 AI의 능력은 무엇을 상상하셨든 그 이상입니다.\nSTEP 4. 이미 강력한 생성형 AI 툴에 날개 달아주기\n인공지능 툴 활용 능력을 더해 주는 팁들!\n관심이 많은 만큼 빠르게 개발된 수많은 기법들과 부가 프로그램을 소개합니다.\n\n\n-\n[ 강 사 소 개 ]\n\n\n김 진\n現 마소캠퍼스 대표\n서울대학교 MBA 졸업\n오라클, 네이버를 거쳐 중국 네이버 개발 아웃소싱 센터를 설립 및 지휘하였으며, 서울대 MBA 졸업 후 글로벌 모바일 기업인 Obigo로 옮겨 데이터 분석에 기반한 성과 관리 시스템 도입 등 국내외 다양한 사업 영역을 개척하였습니다. 2010년에는 게임웹진 플레이포럼 M&A 후 데이터 분석과 디지털 마케팅을 실무에 본격 도입해 코리안클릭 수치 기준으로 월 평균 활성유저(MAU) 238만, 월 평균 페이지뷰(PV)수 1,700만을 달성하였습니다. 개발자, 전문 경영인의 길을 걸어온 사업가로서 폭넓은 경험과 IT 기술을 융합해 현재는 기업의 ROI를 높여줄 실무 전문가 교육에 힘 쓰고 있습니다.",
      "target_audience": [
        "인공지능 시대에 꼭 필요한 생성형 인공지능 활용에 대한 기초 지식을 얻고 싶으신 분",
        "인공지능을 단순한 화제거리로 넘기지 않고 실제로 생산적인 도구로 사용하고 싶으신 분",
        "누구보다도 높은 업무 효율을 생성형 AI를 활용하여 누구보다도 먼저 경험하고 싶으신 분",
        "IT업계로 창업/이직/입사 등 커리어를 쌓고 싶은 모든 분"
      ]
    },
    {
      "title": "Pythonによるビジネスに役立つデータ収集入門（Webスクレイピング・Web API・ChatGPT API編）",
      "url": "https://www.udemy.com/course/python-web-scraping-api/",
      "bio": "初心者向けのWebスクレイピングとWeb APIのコースです。Pythonのデータ収集関連のライブラリを活用し、世界中のWebページからデータを自動収集します。またChatGPT APIも活用し、収集したデータの要約にもチャレンジします。",
      "objectives": [
        "WebスクレイピングやWeb APIを用いて、自動的にデータを収集できるようになります。",
        "WebスクレイピングやWeb APIでデータを取得・抽出し、そのデータを整形・グラフ化・保存する方法を習得できます。",
        "ChatGPT APIを使って、Webスクレイピングで取得したデータを要約する方法が学べます。",
        "Pythonの文法を理解し、基本的なプログラミング技術を習得できます。",
        "実践的な演習問題を通じてデータ収集の理解を深めることができます。"
      ],
      "course_content": {},
      "requirements": [
        "プログラミングやPythonは未経験でも問題ありません。Pythonについて、このコースで必要な知識は学べるよう、初心者向けの補講のレクチャーも用意しております。",
        "講師はWindowsの環境で解説しておりますが、Mac（M1～M4を除く）でも同様に進めていくことができます。",
        "講師はAnacondaでのPython3環境を構築し、JupyterLabを元に解説を進めておりますが、別のPython3環境でも進めていくことができます。",
        "AnacondaでのPython3の環境構築、JupyterLabの使い方についての講義も提供しております。",
        "ChatGPT API（OpenAI API）の利用には、現在（2024年12月時点）で最低5ドル分のクレジットの購入が必要です。無料枠は廃止されていますので、ご了承ください。",
        "なおQ&Aフォームでは、コースで取り扱っていないトピックについてはお答えできませんので、ご理解賜りますようお願い申し上げます。"
      ],
      "description": "データの収集と活用がビジネスの成功に欠かせない時代、効率的なデータ収集方法を学びたいと思ったことはありませんか？しかし、「プログラミングは難しそう」「仕事が忙しく、勉強にさける時間もほとんどない」と感じることも多いでしょう。そこでこのコースでは、初心者でも安心して学べる「Python」を使って、ビジネスで役立つデータを効率的に収集する方法を基礎から解説します。\n\n\n近年、インターネット上には製品の販売状況や市場動向に関するデータなど、ビジネスに役立つデータが多く存在していますが、これらのデータを効率的に集めるスキルを持つ人はまだ少数です。手作業でのデータ収集は時間がかかり、ミスも増えやすく、せっかくのデータが活用されないままになってしまうこともあります。このコースでは、初心者でも理解しやすいPythonを使用し、効率的なデータ収集方法を学びます。\n\n\nPythonはシンプルで学びやすいプログラミング言語であり、多くのライブラリを活用することで、少ないコードで効率的にデータ収集を行うことが可能です。本コースでは、Webページからのデータを自動的に収集するためのPythonライブラリの使い方に特化し、ビジネスに直結した実用的なスキルを身につけることができます。\n\n\n本コースの特徴:\n初心者向けに徹底解説: Pythonの基本を丁寧に説明し、最小限のトピックで最速の習得を目指します。プログラミング未経験の方でもすぐに始められる内容です。\nビジネスに応用可能なスキル: 実際のビジネスにおいて、データを取得したいWebページは、様々なものがあります。Webページの構造の違いや変更に対応し、様々なWebページからデータを収集するためのノウハウを提供します。\n実用的な事例をもとに学習: 実際のビジネスシーンでのデータ収集の活用例を取り上げ、学んだスキルがどのように役立つかを具体的にイメージできるようにします。\n\n\n本コースを通じて、データ収集にかかる時間を大幅に短縮し、ビジネスの意思決定や成長に必要なデータを効率よく手に入れる方法を学ぶことができます。今すぐ始めて、データを活用したビジネスの成長をサポートするスキルを手に入れましょう！\n\n\n【このコースで扱うトピック】\n1. Python超入門\nPython 初心者でもこのコースの内容が理解できるよう、Pythonの基本から丁寧に解説を進めていきます。できるだけ短い時間で理解できるよう、後のデータ収集に関する内容を理解する上で必要最低限のトピックに絞っています。\n\n\n2. Webスクレイピングによるデータ収集の自動化\n自動収集対象のデータやWebページの仕組みを解説し、その後、Webスクレイピングに必要な知識として、WebページからHTMLデータのダウンロード方法、ダウンロードしたHTMLから必要なデータを抽出する方法、抽出したデータの保存方法について、順に解説します。これらのトピックを通じて、まずはスクレイピングに欠かせない基礎的な知識を身に付けて頂いた上で、実際にWebページからデータを取得していきます。\n\n\n3. Web APIによるオープンデータの自動収集\nそしてWebスクレイピングを学んだ後は、次にWeb APIの使い方についても確認していきます。本コースでは、e-statという政府統計のポータルサイトが提供しているWeb APIを使って、オープンデータである統計データを取得する方法を紹介します。オープンデータは、営利・非営利問わず二次利用が可能な公開データで、政府や公的機関だけでなく、近年では民間企業でも活用されています。\n\n\n4. Web APIから取得したオープンデータの処理・可視化\nまたWebページやWeb APIから収集したデータは、時にはきれいに整っておらず、すぐに使える状態になかったり、不要なデータも含まれていて使いにくい状態にあったりすることがあります。このコースでは、データ収集だけでなく、集めたデータについて、実際にビジネスの現場で利用できるよう、これを活用できる状態に処理し、可視化する方法についても学んでいきます。\n\n\n5. ChatGPT APIによる収集データの要約\n最後に、これまでに学んだWebスクレイピングとWeb APIの知識を組み合わせて、有効活用する方法を学びます。技術的な記事が掲載されているWebページから、Webスクレイピングで順次、記事データを取得し、取得した記事データをChatGPT APIに渡して、要約を取得していきます。\n\n\nこのコースでは、これらのデータ収集に欠かせないトピックをカバーすることにより、様々なWebページやWeb APIからのデータ取得に応用の利く技術を身に付けて頂けるようデザインされています。",
      "target_audience": [
        "WebスクレイピングやWeb APIによるデータ収集をビジネスに活用されたい方",
        "WebスクレイピングやWeb APIによるデータ収集を趣味に活用されたい方",
        "WebスクレイピングやWeb APIに興味があるが、始め方がわからない方",
        "Webサイトから効率的にデータを取得する方法を学習されたい方"
      ]
    },
    {
      "title": "【한글자막】 인공 지능 (AI) 으로 비즈니스 해결하기",
      "url": "https://www.udemy.com/course/best-ai-business/",
      "bio": "AI 솔루션을 이용해 현실의 어떤 비즈니스에서든 다음 세 가지 과제를 해결할 수 있습니다. 1) 비즈니스 과정 최적화 2) 비용 최소화 3) 수익 극대화",
      "objectives": [
        "비즈니스 과정 최적화",
        "일반 AI 프레임워크 완전 정복",
        "Q 러닝의 구현",
        "모델 저장 및 불러오기",
        "최적화 모델 구축",
        "조기 종료의 구현",
        "효율성 극대화",
        "수익 극대화",
        "비용 최소화",
        "톰슨 샘플링의 구현",
        "딥 Q 러닝의 구현",
        "AI의 활용한 최적의 결정",
        "맨 처음부터 AI 환경 구축하기",
        "온라인 러닝의 구현",
        "인공 두뇌 구축",
        "후회 분석의 구현"
      ],
      "course_content": {},
      "requirements": [
        "고등학교 교육과정 수준의 수학",
        "기초 Python 지식"
      ],
      "description": "AI 솔루션을 이용해 현실의 비즈니스 과제 해결!\n3단계로 진행하는 비즈니스 최적화 및 사례 연구!\n\n\n인공 지능 (AI) 으로 비즈니스 해결하기 강의를 선택해야 하는 이유\n비즈니스를 최적화하고, 수익성을 최대화 하기 위해 AI를 배우려고 하신다면, 포트폴리오에 추가할 비즈니스 사례 연구를 찾고 계신다면, 기업을 AI 비즈니스로 전환하고자 하신다면 이 강의를 선택하세요.\n\n\n3개의 파트로 진행 되는 이 강의에서는 Q러닝, 딥 Q러닝, 톰슨 샘플링 기법을 사용하여 아래의 비즈니스 사례 연구를 진행합니다.\n파트 1 - 비즈니스 과정 최적화 사례 연구: 전자 상거래 창고 흐름의 최적화 AI 솔루션 : Q 러닝\n파트 2 - 비용 최소화 사례 연구 : 데이터 센터에서의 에너지 소비 비용의 최소화 AI 솔루션 : 딥 Q 러닝\n파트 3 - 수익 극대화 사례 연구: 온라인 소매 비즈니스의 수익 극대화 AI 솔루션: 톰슨 샘플링\n\n\n이 과정을 마치고나면 인공지능을 이용하여 어떤 비즈니스에서든 아래의 세 가지 과제를 해결할 수 있습니다.\n비즈니스 과정 최적화\n비용 최소화\n수익 극대화\n\n\n세 가지 사례 연구를 진행하며 과제 해결을 위해 아래의 세 가지 별도 AI를 구축 하시게 될 겁니다.\n파트 1 - 과정 최적화에서는 전자 상거래에서의 창고 흐름의 최적화를 위해 AI를 구축합니다.\n\n\n파트 2 - 비용 최소화에서는, Google이 DeepMind로 이루어낸 성과와 같이 데이터 센터에서의 에너지 소비 비용을 50% 이상 절감하기 위해 더욱 심화된 AI를 구축하겠습니다!\n\n\n파트 3 - 수익 극대화에서는 온라인 소매 비즈니스의 수익을 극대화해 10억 달러 이상의 수익을 창출할 수 있도록 다른 종류의 AI를 구축하게 될 겁니다!\n\n\n이 강의에서는 비즈니스를 위한 인공지능과 관련된 책을 제공합니다.\n“비즈니스를 위한 인공 지능에 대한 모든 것이 담긴 100쪽 분량의 책!”.\n\n\n책:\n책은 다음과 같은 내용을 포함합니다:\n아름답고 깨끗한 LaTeX로 쓰인 100쪽 분량의 명확한 설명\n상세히 기술된 수학적 설명을 포함한 모든 AI 개요 및 이론\n강의의 세 가지 사례 연구 및 솔루션\nQ 러닝, 딥 Q 러닝 및 톰슨 샘플링을 포함한 세 가지 AI 모델\n코드 템플릿\n연습을 위한 과제 및 풀이법\n모델 저장과 불러오기 및 조기 종료 등과 같은 많은 추가적인 팁과 기법\n\n\n결론:\n이 강의 과정은 업계 최고 수준의 연봉을 보장하는 AI 분야에서의 취업을 원하시거나, 자신만의 사업을 시작하고자 하시는 분들에게 안성맞춤입니다.\n\n\n여러분의 커리어에 날개를 달아 줄 궁극의 AI 강의 과정 — 비즈니스를 위한 인공 지능을 통해, 오늘 여러분의 커리어를 한 단계 끌어 올리세요.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n강의에서 만나요!",
      "target_audience": [
        "비즈니스를 최적화하고, 효율성과 수익성을 최대화하기 위해 AI를 활용하는 방법을 배우고자 하시는 사업 관계자 분들",
        "고용인들에게 어떤 프로젝트를 제공할 수 있을지를 고민하고 계시는 AI 전문직 종사자 분들",
        "포트폴리오에 추가할 비즈니스 사례 연구를 물색하고 계시는 데이터 과학자 지망생 분들",
        "비즈니스 문제의 해결을 위해 머신 러닝과 인공 지능을 활용하는 법에 관심이 있으신 기술 애호가 분들",
        "기업을 AI 주도적 비즈니스로 전환하고자 하시는 컨설턴트 분들"
      ]
    },
    {
      "title": "ChatGPT & Kunstmatige Intelligentie (AI) in het Nederlands",
      "url": "https://www.udemy.com/course/chatgpt-kunstmatige-intelligentie-ai-in-het-nederlands/",
      "bio": "Introductie over ChatGPT & MidJourney: Leer hoe je kunstmatige intelligentie (AI) gebruikt zonder programmeerervaring.",
      "objectives": [
        "Wat ChatGPT is, en waarvoor je het kunt gebruiken",
        "Hoe ChatGPT is ontstaan, en waar de kansen liggen voor AI?",
        "Wat de limitaties zijn van ChatGPT",
        "Verschillende use-cases en toepassingen uitgewerkt voor ChatGPT",
        "Je leert hoe je ChatGPT het meest effectief kunt toepassen in je dagelijkse leven",
        "Hoe je MidJourney kunt gebruiken om digitale kunst te genereren"
      ],
      "course_content": {},
      "requirements": [
        "Werkend internet"
      ],
      "description": "ChatGPT is een revolutionaire AI-chatbot die gebaseerd is op de GPT-3.5-architectuur van OpenAI. Deze chatbot heeft de mogelijkheid om natuurlijke taal te begrijpen en te produceren, wat betekent dat het menselijke conversaties kan nabootsen en vragen kan beantwoorden op een manier die lijkt op de manier waarop mensen met elkaar praten. Deze cursus is bedoeld voor beginners die geïnteresseerd zijn in het leren hoe ze ChatGPT kunnen gebruiken en de mogelijkheden van deze baanbrekende technologie willen ontdekken.\nDeze cursus is opgedeeld in verschillende modules die stapsgewijs worden gepresenteerd. In de eerste module leer je de basisprincipes van ChatGPT en hoe het werkt. Je leert hoe je ChatGPT kunt gebruiken om conversaties te genereren en hoe je het kunt trainen om specifieke taken uit te voeren. Je zult ook kennismaken met enkele van de toepassingen van ChatGPT in verschillende sectoren, zoals klantenservice, marketing en onderwijs.\nVervolgens ga je dieper in op de technologie achter ChatGPT en leer je hoe je het kunt aanpassen en optimaliseren voor specifieke toepassingen. Je leert hoe je datasets kunt verzamelen en gebruiken om het model te trainen, en hoe je de prestaties van het model kunt meten en verbeteren. Daarnaast leer je hoe je ChatGPT kunt integreren met andere technologieën en platforms om geavanceerde toepassingen te creëren.",
      "target_audience": [
        "Individuen die over ChatGPT willen leren zonder voorkennis",
        "Individuen die over ChatGPT willen leren met enige voorkennis",
        "Marketeers die productiever en creatiever willen werken",
        "Experts in Excel die productiever en creatiever willen werken",
        "Individuen die over MidJourney willen leren om digitale kunst te maken"
      ]
    },
    {
      "title": "Machine Learning sem Código e sem Matemática",
      "url": "https://www.udemy.com/course/machine-learning-sem-codigo-sem-matematica/",
      "bio": "Aprendizagem de máquina para todos! Google Vertex AI, Data Robot AI, Obviously AI, Big ML, Microsoft Azure e Orange!",
      "objectives": [
        "Construa modelos de machine learning para serem utilizados em problemas reais sem uma única linha de código e sem conhecimentos de matemática",
        "Utilize as principais ferramentas do mercado aplicadas em problemas de classificação, regressão e previsão de séries temporais",
        "Implemente machine learning nas seguintes ferramentas: Google Vertex AI, Data Robot AI, Obviously AI, Big ML, Microsoft Azure e Orange",
        "Aprenda como fazer o deploy de modelos de machine learning"
      ],
      "course_content": {},
      "requirements": [
        "Não há nenhum pré-requisito, porém, o aproveitamento será melhor caso você conheça o básico sobre aprendizagem de máquina",
        "Não é necessário nenhuma experiência com programação ou com matemática"
      ],
      "description": "Se você quer aprender aprendizagem de máquina, mas se sente intimidado ou intimidada com programação ou com fundamentos matemáticos, este curso é para você!\nVocê vai aprender a trabalhar com seis ferramentas que não exigem nenhum conhecimento prévio de programação de computadores, tão pouco conhecimentos avançados de matemática! Este curso foi projetado para que você consiga criar projetos práticos de forma rápida e fácil, sem uma única linha de código sequer. Além de ser indicado para iniciantes, é útil para alunos com conhecimentos intermediários ou avançados, que precisam aumentar a produtividade mas que ao mesmo tempo não possuem tempo para implementar código do zero. Com apenas alguns cliques, é possível executar análise exploratória de dados, construir, treinar, testar e colocar modelos de machine learning em produção!\nVamos abordar 6 ferramentas que são amplamente utilizadas no mercado: Google Vertex AI, Data Robot AI, Obviously AI, Big ML, Microsoft Azure Machine Learning e Orange! Todos os projetos serão desenvolvidos com calma e tudo passo a passo, para que você consiga aproveitar ao máximo o conteúdo. Existe um exercício juntamente com a solução ao final de cada seção, dessa forma você pode praticar os passos de cada ferramenta! São mais de 30 aulas e 5 horas de vídeos!",
      "target_audience": [
        "Pessoas interessadas em criar modelos de aprendizagem de máquina reais sem uma única linha de código",
        "Pessoas interessadas em iniciar seus estudos em aprendizagem de máquina e Ciência de Dados",
        "Alunos que possuam pouca ou nenhuma experiência com programação ou matemática",
        "Alunos de graduação e pós-graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial"
      ]
    },
    {
      "title": "Detecção de Movimentos com Python e OpenCV",
      "url": "https://www.udemy.com/course/deteccao-movimentos-python-opencv/",
      "bio": "Implemente um contador de veículos e um detector de distanciamento social utilizando algoritmos de subtração de fundo!",
      "objectives": [
        "Entender a teoria básica sobre subtração de fundos aplicado em detecção de movimentos",
        "Implementar os algoritmos MOG, GMG, KNN e CNT com o OpenCV, bem como comparar a qualidade e desempenho",
        "Melhorar a qualidade dos vídeos utilizando técnicas de pré-processamento, como operações morfológicas e desfoque",
        "Implementar um detector de movimento para monitoração de ambientes",
        "Implementar um detector de distanciamento social para verificar a existência de aglomerações",
        "Implementar um contador de carros e caminhões utilizando vídeos de rodovias"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre Visão Computacional",
          "Recursos para download"
        ],
        "Subtração de fundos": [
          "Subtração de fundos - introdução",
          "Filtragem mediana temporal - intuição",
          "Instalação das ferramentas",
          "Filtragem mediana temporal – implementação 1",
          "Filtragem mediana temporal – implementação 2",
          "Filtragem mediana temporal – implementação 3",
          "Outros algoritmos: MOG, GMC, KNN e CNT",
          "Referências complementares",
          "Técnicas para pré-processamento de imagens",
          "MOG, GMC, KNN e CNT – implementação 1",
          "MOG, GMC, KNN e CNT – implementação 2",
          "MOG, GMC, KNN e CNT – implementação 3",
          "MOG, GMC, KNN e CNT – implementação 4",
          "MOG, GMC, KNN e CNT – implementação 5",
          "Comparativo de qualidade 1",
          "Comparativo de qualidade 2",
          "Comparativo de desempenho"
        ],
        "Projetos práticos": [
          "Detecção de movimentos 1",
          "Detecção de contornos - intuição",
          "Detecção de movimentos 2",
          "Distanciamento social",
          "Contador de veículos 1",
          "Contador de veículos 2",
          "Contador de veículos 3",
          "Contador de veículos 4",
          "Contador de veículos 5"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Programação básica em Python"
      ],
      "description": "A detecção de movimentos é uma sub-área da Visão Computacional que tem o objetivo de identificar movimentos em vídeos ou em tempo real. Esse tipo de aplicação pode ser muito útil principalmente para sistemas de vigilância, nos quais é necessário detectar movimentos suspeitos como um ladrão tentando entrar na casa. Existem várias outras aplicações, como por exemplo: análise de tráfego em rodovias, detecção e contagem de pessoas, rastreamento de animais, contagem de ciclistas, dentre outros. Um sistema de controle de tráfego pode utilizar essas técnicas para identificar o número de carros e caminhões que passam pela rodovia diariamente e em determinados horários, para então realizar um planejamento de manutenção na pista.\nE para levar você até essa área, neste curso você aprenderá na prática como utilizar algoritmos de subtração de fundo para detectar movimentos em vídeos, tudo passo a passo e utilizando a linguagem Python! Confira abaixo os principais tópicos que você aprenderá, bem como os projetos práticos:\nIntuição teórica básica sobre a subtração de fundos e os principais algoritmos: MOG (Mixture of Gaussians), GMG (Godbehere, Matsukawa e Goldbert), KNN (K Nearest Neighbors) e CNT (Count)\nComparativo de qualidade e desempenho de cada algoritmo\nProjeto prático 1: detector de movimento para monitorar ambientes\nProjeto prático 2: detector de distanciamento social para identificar possíveis aglomerações de pessoas\nProjeto prático 3: contador de carros e caminhões em rodovias\nAo final do curso, você poderá criar seus próprios projetos de detecção de movimentos!",
      "target_audience": [
        "Pessoas interessadas em implementar detectores de movimento ou contadores de objetos em vídeos",
        "Alunos de graduação e pós-graduação que cursam disciplinas de Computação Gráfica, Processamento Digital de Imagens ou Inteligência Artificial",
        "Cientistas de Dados que queiram aumentar seus conhecimentos em Visão Computacional"
      ]
    },
    {
      "title": "Bootcamp MLOps: CI/CD para Modelos",
      "url": "https://www.udemy.com/course/bootcamp-de-devops-a-mlops-transicion-hacia-la-ingenieria-p/",
      "bio": "Del Dato al Despliegue — Aprende MLOps Construyendo un Proyecto Real de Machine Learning con MLflow, Docker y Kubernetes",
      "objectives": [
        "Comprender el ciclo de vida completo de un proyecto de machine learning desde el procesamiento de datos hasta el despliegue en producción.",
        "Configurar y utilizar MLflow para el seguimiento de experimentos.",
        "Aplicar técnicas de ingeniería de datos y características en notebooks de Jupyter.",
        "Empaquetar modelos de ML utilizando FastAPI y desplegarlos con Docker y Kubernetes.",
        "Construir interfaces visuales con Streamlit y conectarlas a modelos en producción.",
        "Automatizar pipelines de ML con GitHub Actions y gestionar imágenes de contenedores con DockerHub.",
        "Implementar modelos en producción con Seldon Core.",
        "Supervisar modelos en producción usando Prometheus y Grafana.",
        "Aplicar GitOps para entrega continua utilizando ArgoCD.",
        "Integrar prácticas de DevOps en flujos de trabajo de machine learning (MLOps)"
      ],
      "course_content": {
        "Introduction": [
          "¿Qué es MLOps?",
          "Historia de la Evolución de MLOps, LLMOps y AgenticAIOps",
          "Comparando Tres Enfoques de la IA",
          "Casos de Estudio en MLOps - Aprendiendo de los Pioneros",
          "Comparando DevOps y MLOps",
          "Emergencia del Rol de Ingeniero MLOps"
        ],
        "Caso de Uso y Configuración del Entorno": [
          "Introducción al Módulo",
          "Caso de Uso - Predicción de Precios de Viviendas - Regresión",
          "Repositorio Git para el Curso",
          "Comprendiendo Prácticas ML de Extremo a Extremo y MLOps",
          "Visión General de la Configuración del Entorno",
          "Configuración de Docker / Podman con Compose",
          "Lanzamiento de MLflow para Seguimiento de Experimentos",
          "Comprensión de la Estructura y Directorio del Proyecto",
          "Configuración de Entorno Virtual de Python con UV",
          "Trabajo con Notebooks de Jupyter",
          "Resumen"
        ],
        "De los Datos a los Modelos - Ciencia de Datos, Ingeniería de Características y E": [
          "Introducción al Módulo",
          "Aprendiendo Ingeniería de Datos",
          "Análisis Exploratorio de Datos",
          "Comprensión de Conceptos de Ingeniería de Características",
          "Creando Nuevas Características para el Predictor de Precios de Viviendas",
          "Preparación para la Experimentación de Modelos",
          "División de Datos con x_train, y_train, x_test, y_test",
          "Definición de Algoritmos y Parrillas de Hiperparámetros",
          "Ejecución de Experimentos para Encontrar el Mejor Modelo e Hiperparámetros",
          "Resumen del Módulo"
        ],
        "Construcción de Imágenes de Contenedores": [
          "Introducción al Módulo",
          "Transición del Científico de Datos al Ingeniero ML / MLOps",
          "Ejecución de Tareas de Ingeniería de Características y Preprocesamiento",
          "Construcción y Entrenamiento del Modelo Final con Configuraciones de los Científ",
          "Empaquetado del Modelo con FastAPI y Aplicaciones Cliente de Streamlit",
          "Escritura de Dockerfile para Empaquetar el Modelo con FastAPI",
          "Depuración y Validación del Modelo FastAP",
          "Empaquetado y Pruebas de la Aplicación Streamlit",
          "Infraestructura de Servido de Modelos con Docker Compose",
          "Resumen"
        ],
        "Configurando Flujo de Trabajo CI MLOps con GitHub Actions": [
          "Introducción al Módul",
          "DAGs, GitHub Actions y nuestro Flujo CI MLOps",
          "Comprendiendo la Sintaxis de GitHub Actions",
          "Escribiendo y Ejecutando Nuestro Primer Workflow",
          "Añadiendo Pasos de Datos e Ingeniería con Entrenamiento de Modelos",
          "Paso de Entrenamiento con MLFlow para Seguimiento",
          "Paso para Construcción y Publicación de Imagen con Docker",
          "Configuración de Token y Publicación en DockerHub",
          "Flujo CI MLOps Modular y Multietapa",
          "Resumen"
        ],
        "Construcción de Infraestructura Escalable de Inferencia en Producción con Kubern": [
          "Introducción al Módulo",
          "Diseño de Infraestructura Escalable para Inferencia de Modelos",
          "Introducción a Kubernetes para ML",
          "Conceptos Básicos de Kubernetes - Pods, Deployments y Servicios",
          "Forma más Simple de Crear un Clúster de 3 Nodos con KIND",
          "Despliegue de Aplicación Streamlit con Kubernetes",
          "Exposición de App Streamlit con NodePort",
          "Creación de Servicio para Modelo Empaquetado con FastAPI",
          "Conexión de Streamlit y Modelo usando DNS de Kubernetes",
          "Forma Fácil de Generar Manifiestos YAML de Kubernetes",
          "Resumen"
        ]
      },
      "requirements": [
        "Conocimientos básicos de DevOps, incluyendo Docker, Git y CI/CD.",
        "Conocimientos básicos de DevOps, incluyendo Docker, Git y CI/CD.",
        "Experiencia básica con la línea de comandos y manejo de terminal.",
        "Idealmente, experiencia previa trabajando con Kubernetes (aunque se explican los conceptos clave durante el curso)."
      ],
      "description": "Nota: Este curso ha sido traducido del inglés al español con la ayuda de inteligencia artificial para facilitar el acceso a una audiencia hispanohablante.  (AI)\n\nEste bootcamp práctico está diseñado para ayudar a Ingenieros DevOps y profesionales de infraestructura a realizar la transición hacia el creciente campo de MLOps. Con la rápida integración de la IA y el aprendizaje automático en las aplicaciones modernas, MLOps se ha convertido en el puente esencial entre los modelos de machine learning y los sistemas de producción.\nEn este curso, trabajarás en un caso de uso del mundo real — predicción de precios de viviendas — y lo llevarás desde el procesamiento de datos hasta el despliegue en producción sobre Kubernetes. Comenzarás configurando tu entorno con Docker y MLFlow para el seguimiento de experimentos. Comprenderás el ciclo de vida del machine learning y obtendrás experiencia práctica en ingeniería de datos, ingeniería de características y experimentación de modelos utilizando notebooks de Jupyter.\nLuego, empaquetarás el modelo con FastAPI y lo desplegarás junto a una interfaz de usuario basada en Streamlit. Escribirás workflows de GitHub Actions para automatizar tu pipeline de ML para CI y utilizarás DockerHub para publicar tus contenedores de modelos.\nEn etapas posteriores, construirás una infraestructura de inferencia escalable utilizando Kubernetes, expondrás servicios y conectarás interfaces frontend y backend mediante descubrimiento de servicios. Explorarás la implementación de modelos a nivel de producción con Seldon Core y supervisarás tus despliegues con paneles de Prometheus y Grafana.\nFinalmente, explorarás la entrega continua basada en GitOps usando ArgoCD para gestionar y desplegar cambios en tu clúster de Kubernetes de forma limpia y automatizada.\nAl finalizar este curso, estarás equipado con el conocimiento y la experiencia práctica para operar y automatizar flujos de trabajo de machine learning utilizando prácticas de DevOps — preparándote para roles profesionales en MLOps e Ingeniería de Plataformas de IA.",
      "target_audience": [
        "Ingenieros DevOps que buscan expandir sus habilidades hacia el campo de MLOps.",
        "Profesionales de infraestructura interesados en automatizar flujos de trabajo de machine learning.",
        "Desarrolladores o arquitectos de software que quieren entender cómo desplegar modelos de ML en producción.",
        "Estudiantes o autodidactas que desean adquirir experiencia práctica en el ciclo de vida completo de proyectos de ML aplicando prácticas de DevOps."
      ]
    },
    {
      "title": "Inteligencia Artificial (IA) con ChatGPT",
      "url": "https://www.udemy.com/course/inteligencia-artificial-ia-con-chatgpt/",
      "bio": "Aprende sobrbe la tecnología de la IA y su capacidad para ayudarnos a resolver problemas.",
      "objectives": [
        "Fomentar la curiosidad y el interés de los jóvenes en la inteligencia artificial",
        "Habilidades técnicas relacionadas con la inteligencia artificial, como programación y análisis de datos, para que puedan crear soluciones y aplicaciones",
        "Fomentar valores éticos para comprender la importancia de la responsabilidad y la ética en el desarrollo de la inteligencia artificial",
        "Promover la colaboración y el trabajo en equipo para que puedan desarrollar soluciones de ia"
      ],
      "course_content": {},
      "requirements": [
        "Deseos de aprender sobre IA"
      ],
      "description": "La inteligencia artificial es una rama de la informática que busca desarrollar algoritmos y programas que imiten la inteligencia humana y puedan resolver problemas de manera autónoma. En las últimas décadas, esta tecnología ha experimentado un enorme crecimiento, gracias al aumento de la capacidad de procesamiento y almacenamiento de datos, así como al avance en algoritmos y técnicas de aprendizaje automático.\nEn la actualidad, la inteligencia artificial tiene aplicaciones en una amplia variedad de campos, desde la industria y el comercio hasta la medicina y la investigación científica. Esta tecnología puede ayudar a las empresas y organizaciones a procesar grandes cantidades de datos, predecir comportamientos de los usuarios y mejorar la personalización de servicios y productos.\nEn términos educativos, la importancia de la inteligencia artificial radica en que esta tecnología puede mejorar la calidad del aprendizaje en diferentes niveles educativos. Por ejemplo, la inteligencia artificial puede personalizar el contenido de aprendizaje, adaptando el material a las necesidades individuales de cada estudiante. Asimismo, puede permitir una mayor interacción entre estudiantes y profesores a través de chats o asistentes virtuales.\nPor otro lado, existen ciertas preocupaciones éticas y sociales en torno al impacto de la inteligencia artificial en el empleo y la privacidad de los usuarios. Es importante abordar estas cuestiones de manera responsable y ética para asegurar los beneficios de esta tecnología sin comprometer los derechos de las personas.\nEn resumen, aprender sobre inteligencia artificial es importante para entender cómo esta tecnología está transformando el mundo en el que vivimos y para aprovechar sus beneficios en diversos campos, incluyendo el educativo. Es fundamental tener en cuenta los aspectos éticos y sociales de la inteligencia artificial para asegurar que su uso sea responsable y beneficioso para la sociedad en su conjunto.",
      "target_audience": [
        "Profesionales del sector tecnológico que trabajan en el desarrollo de soluciones de inteligencia artificial para empresas y organizaciones",
        "Investigadores y académicos que estudian y exploran nuevas aplicaciones y técnicas de inteligencia artificial.",
        "Estudiantes que están interesados en aprender sobre la inteligencia artificial y desarrollar habilidades técnicas relacionadas con la misma.",
        "Empresas y organizaciones que utilizan la inteligencia artificial para mejorar y automatizar procesos en diferentes áreas, como la atención al cliente, el análisis de datos o la gestión de la cadena de suministro",
        "Sector público que puede utilizar la inteligencia artificial para mejorar servicios y políticas públicas, como el diagnóstico médico o la detección de fraude."
      ]
    },
    {
      "title": "ChatGPT Projeleri Geliştirme",
      "url": "https://www.udemy.com/course/chatgpt-projeleri-gelistirme/",
      "bio": "Python dilinde ChatGPT projesi gerçekleştirin",
      "objectives": [
        "Python Dilinde ChatGPT için bir asistan uygulaması yapabilecek",
        "Tkinter Modülünü kullanarak görsel uygulama yapacak",
        "Python temel fonksiyonlarını pratik edecek",
        "ChatGPT kullanımını deneyimleyecek"
      ],
      "course_content": {
        "ChatGPT Bot Yapalım - Python": [
          "Uygulama Tanıtımı",
          "1. Python Kurulumu",
          "2. Visual Studio Code Kurulumu",
          "3. Gerekli Kütüphaneler",
          "4. OpenAI Kayıt Olma",
          "5. Projenin Açılması",
          "6. Text Widget",
          "7. Scrollbar Ekleme",
          "8. Entry Widget",
          "9. Button Widget",
          "10. API Key Bölümü",
          "11. API Key Gizle/Göster",
          "12. API Key Dosyaya Kayıt",
          "13. API Key Kaydetme",
          "14. Hata Yakalama",
          "15. Giriş ve Cevap Kısımlarını Temizleme Butonu",
          "16. API Key Kontrol",
          "17. ChatGPT ile İlk İletişim",
          "18. Cevabı Düzenleme"
        ],
        "Sesli Asistan Yapıyoruz - Python": [
          "1. Uygulama Tanıtım",
          "2. Projenin Oluşturulması ve Gerekli Modüllerin Kurulması",
          "3. Speech to Text",
          "4. Text to Speech",
          "5. Projeye Odaklanıyoruz",
          "6. Projenin Tamamlanması"
        ],
        "Chat GPT Web Clone Yapalım - Python": [
          "1. Proje Tanıtımı",
          "2. Gradio Kütüphanesi Uygulama Örnekleri -1",
          "3. Gradio Kütüphanesi Örnekleri -2",
          "4. Görsel Arayüz Tanıtımı",
          "5. OpenAI ile Bağlantı"
        ],
        "Sesli Komut ve Metinden Resim Üretiyoruz": [
          "1. Metinden Resim Oluşturup Kaydetme",
          "2. Metinden Web Browser üzerinde Resim Oluşturma",
          "Sesli komutla İşlevselliğimizi Artıralım"
        ],
        "Discord Bot Yapıyoruz - Python": [
          "Proje Tanıtım",
          "1. Discord Sunucusu Kurulması",
          "2. Bot ile İlk Etkileşim",
          "3. Bot ile Şartlı İfadelerle Etkileşim",
          "4. Bot Her Mesaja Cevap Veriyor",
          "5. Bot Kendisine Sorulan Sorulara Cevap Veriyor",
          "6. Botu Replit ile Canlıya Alalım"
        ],
        "Django Projesi Oluşturuyoruz": [
          "Proje Tanıtım",
          "1. Projemizi Hazırlıyoruz",
          "2. Projemizin URL Ayarları",
          "3. Projemizin views ayarları",
          "4. Projemizi Tamamlıyoruz"
        ],
        "Python ile Hava Durumu Uygulaması Yaptırma": [
          "Hava Durumu Uygulaması Yapalım"
        ],
        "Flask ile Rastgele Emoji Gösterici Web Sayfası Yapalım": [
          "1. Proje Tanıtım",
          "Projenin Gerçekleştirilmesi"
        ],
        "PyQt5 ile Web Browser Yapıyoruz": [
          "Proje Tanıtım",
          "Projemimi Gerçekleştiriyoruz"
        ],
        "Chat GPT-4": [
          "Chat GPT-4 ile Neler Değişti?",
          "Ücretsiz Olarak GPT-4'ü Denemek",
          "GPT-4 ile İnternet Hızı bilgisini veren Python Kodu Alalım"
        ]
      },
      "requirements": [
        "Temel Python dilini bilmek iyi olacaktır ama zorunlu değildir."
      ],
      "description": "Türkiye Chat GPT'yi Türkçe Kaynaktan Öğrenecek?\n\n\nMart 2023 sonuna kadar her hafta bir proje ekleyerek toplam 10 özgün projenin adım adım anlatımını yapacağım.?\n\n\nİlk 5 proje tamamlandı.\n\n\nProje 1: Chat GPT Bot Yapıyoruz\nProje 2: Chat GPT ile Sesli Asistan Yapma\nProje 3 : Chat GPT Web Clone Yapıyoruz\nProje 4: Sesli Komutla Yapay Zekaya Resim Yaptırıyoruz\nProje 5: Discord Bot Yapıyoruz:\n\n\nChatGPT, OpenAI tarafından ilk olarak 30 Kasım 2022’de kullanıma sunulan bir yapay zeka sohbet robotudur. ChatGPT, yapılan konuşmalardaki sözcükleri analiz ederek, kullandığı zengin metin veri havuzu içerisinden bir sonraki sözcüğü tahmin eder. Böylece bir insanla konuşuyormuşcasına doğal yazılı cevaplar ve uzun metinler üretebilir. Bunları gerçekleştirebilmek için derin öğrenmeye sahip GPT-3 dil modelinden faydalanır.\nSorduğunuz sorular ve aldığınız cevaplar sohbet geçmişinizde görünecektir. Fakat yeni bir sohbet başlatmak isterseniz, Reset Thread seçeneğine tıklayarak konuşmayı sıfırlayabilirsiniz. Aldığınız cevaplarla ilgili geri bildirimde bulunmak için metnin yanındaki beğen veya beğenme (thumbs up – thumbs down) butonlarını kullanabilirsiniz.\nKonuşmaya başlayabilmek için ChatGPT sayfasına gidin ve mail adresinizi girdikten sonra telefon numaranızı girerek doğrulama işlemini gerçekleştirin. İletişim bilgilerinizi ve kullanım amacınızı paylaştıktan sonra üyelik işleminizi tamamlayabilirsiniz. Ardından kullanıcı dostu arayüzü sayesinde ChatGPT’yi kısa süre içerisinde ücretsiz olarak kullanmaya başlayabilirsiniz. Herhangi bir mesajlaşma uygulamasında olduğu gibi metin kutusuna istediğinizi yazıp gönderebilir ve kısa bir süre içerisinde de cevap alabilirsiniz.\n\n\nChat GPT ile özgün bir şiir yazabilir, zorlu bir matematik problemini çözebilir veya bulamadığınız bir kaynağı onun sayesinde kolayca bulabilirsiniz. Uygulama ayrıca birebir çeviri yapabiliyor.\nHatta bir dönem çocuklar ödevlerini Chat GPT'ye yaptırdığı için okullarında problem bile yaşamıştı. Bununla beraber uygulama yazılımcılara da hitap ediyor yeni bir program geliştirmek isterseniz uygulama sayesinde kodlamalar yapabilirsiniz.\n\n\nBir çok alanda sorulan sorulara oldukça insansı cevaplar veren ChatGPT için gelin beraber kullanıcı dostu arayüze sahip bir uygulama yapalım.",
      "target_audience": [
        "Yapay zeka konusuna meraklı herkes"
      ]
    },
    {
      "title": "Máster en IA y Computación Cuántica: De Cero a Experto",
      "url": "https://www.udemy.com/course/computacion-cuantica/",
      "bio": "Machine Learning práctico, Deep Learning, algoritmos cuánticos y aplicaciones híbridas IA-CQ.",
      "objectives": [
        "Domina IA y Machine Learning: aprende fundamentos, aprendizaje supervisado/no supervisado y crea modelos reales desde cero.",
        "Construye modelos de Deep Learning: entrena redes neuronales, CNNs y RNNs con TensorFlow y PyTorch para visión, NLP y aplicaciones de IA.",
        "Comprende Computación Cuántica: estudia Qubits, Superposición, Entrelazamiento y circuitos cuánticos con Qiskit e IBM Quantum.",
        "Implementa algoritmos cuánticos: desarrolla Grover, Shor y circuitos variacionales para resolver problemas reales.",
        "Entrena IA con Computación Cuántica: mejora modelos de IA con QML usando aceleraciones cuánticas y mapeo de características.",
        "Crea chatbots y sistemas NLP: diseña asistentes de voz y modelos de análisis de sentimientos impulsados por IA para aplicaciones reales.",
        "Desarrolla IA para finanzas y trading: predice mercados, optimiza carteras y mejora gestión de riesgos con IA y Quantum AI.",
        "Explora criptografía cuántica: implementa distribución de claves cuánticas (QKD) y cifrado resistente a computadoras cuánticas.",
        "Crea sistemas de detección de fraude: entrena IA para identificar transacciones fraudulentas y amenazas cibernéticas.",
        "Construye apps híbridas IA-Cuántica: combina IA y computación cuántica para innovar en salud, finanzas y ciencia de datos."
      ],
      "course_content": {
        "Introducción al curso de Maestría en IA y Computación Cuántica": [
          "Introducción rápida a la computación cuántica",
          "Aprende Python desde cero – Tutorial rápido"
        ],
        "Introducción a la IA y la Computación Cuántica": [
          "Lección 1: Descripción del curso y requisitos previos",
          "Lección 2: Fundamentos de la IA",
          "Lección 3: Fundamentos de la Computación Cuántica"
        ],
        "Profundización en Inteligencia Artificial (IA)": [
          "Lección 4: Aprendizaje automático y frameworks de IA",
          "Lección 5: Aprendizaje profundo con TensorFlow y PyTorch",
          "Lección 6: Aprendizaje por refuerzo"
        ],
        "Profundización en Computación Cuántica": [
          "Lección 7: Mecánica cuántica para principiantes",
          "Lección 8: Circuitos y puertas cuánticas",
          "Lección 9: Algoritmos cuánticos"
        ],
        "IA y Computación Cuántica juntas": [
          "Lección 10: Cómo la IA se beneficia de la Computación Cuántica",
          "Lección 11: Procesamiento de datos cuánticos para la IA",
          "Lección 12: Redes neuronales cuánticas"
        ],
        "Aplicaciones avanzadas": [
          "Lección 13: Casos de uso reales de IA y Computación Cuántica",
          "Lección 14: Técnicas de optimización de IA cuántica"
        ]
      },
      "requirements": [
        "Este curso está diseñado para principiantes absolutos, por lo que no se requiere experiencia previa en IA o Computación Cuántica.",
        "Conocimientos básicos de programación (se recomienda Python, pero no es obligatorio).",
        "Una computadora con acceso a internet (Windows, macOS o Linux).",
        "Familiaridad con matemáticas de nivel preparatoria/secundaria superior (Álgebra, Probabilidad y Álgebra Lineal básica).",
        "Interés en la Inteligencia Artificial, el Aprendizaje Automático y la Computación Cuántica.",
        "Disposición para aprender y experimentar con ejercicios prácticos de programación."
      ],
      "description": "Descubre el poder de la Inteligencia Artificial (IA) y la Computación Cuántica (CQ) con este curso práctico y completo diseñado para principiantes absolutos y profesionales que quieran explorar la próxima generación de tecnologías de cómputo. Este curso cubre Machine Learning (ML), Deep Learning (DL), Redes Neuronales, Mecánica Cuántica, Aprendizaje Cuántico (QML) y Aplicaciones Híbridas IA-CQ, dotándote de las habilidades para crear proyectos del mundo real.\nMientras la IA sigue transformando industrias como la salud, finanzas, ciberseguridad y automatización, la Computación Cuántica revoluciona la forma en que resolvemos problemas complejos mediante la superposición, el entrelazamiento y las puertas cuánticas. Este curso está estructurado para ayudarte a dominar los fundamentos de la IA antes de sumergirte en Algoritmos Cuánticos, IA Cuántica y Sistemas Híbridos IA-CQ.\n¿Por qué tomar este curso?\nAprende IA, Machine Learning, Deep Learning y Redes Neuronales desde cero.\nComprende los principios de la Computación Cuántica incluyendo Qubits, Superposición, Entrelazamiento y Circuitos Cuánticos.\nDomina el Aprendizaje Cuántico (QML) con Redes Neuronales Cuánticas (QNNs) y Optimización Cuántica.\nAdquiere experiencia práctica con TensorFlow, PyTorch, Qiskit, IBM Quantum y OpenAI.\nImplementa aplicaciones potenciadas por cuántica para descubrimiento de fármacos, finanzas y optimización de carteras.\nDesarrolla pericia en simulaciones cuánticas impulsadas por IA para acelerar la analítica de big data y el deep learning.\nLo que aprenderás:\nFundamentos de IA y Machine Learning\nIntroducción a la Inteligencia Artificial, Aprendizaje Supervisado y no Supervisado.\nPráctica de Deep Learning con TensorFlow y PyTorch.\nDesarrolla chatbots con IA, reconocimiento de imágenes y modelos de detección de fraudes.\nImplementa Reinforcement Learning para sistemas de IA autoaprendientes.\nComputación Cuántica y Algoritmos Cuánticos\nComprende los Bits Cuánticos (Qubits), Puertas Cuánticas, Superposición Cuántica y Entrelazamiento.\nAprende Diseño de Circuitos Cuánticos y Medición Cuántica.\nImplementa Algoritmos Cuánticos como la Búsqueda de Grover, el Algoritmo de Shor y Clasificadores Cuánticos Variacionales (VQC).\nAprendizaje Cuántico (QML) y Aplicaciones Híbridas IA-CQ\nExplora la IA mejorada por cuántica, Métodos de Kernel Cuántico y Circuitos Cuánticos Variacionales.\nEntrena Redes Neuronales Cuánticas (QNNs) para tareas de deep learning.\nImplementa modelos de ML potenciados por cuántica para finanzas, descubrimiento de fármacos y ciberseguridad.\n¿Para quién es este curso?\nPrincipiantes que desean dominar IA, Machine Learning, Deep Learning y Computación Cuántica.\nDesarrolladores de Software y Científicos de Datos interesados en IA Cuántica y Aplicaciones Híbridas IA-CQ.\nInvestigadores de IA y Entusiastas de la Computación Cuántica que exploran Redes Neuronales Cuánticas y QML.\nProfesionales de Tecnología que desean hacer la transición a Computación Cuántica e Investigación en IA.\nTecnologías Cubiertas\nPython, TensorFlow, PyTorch, OpenAI, IBM Quantum, Qiskit, D-Wave, Scikit-Learn, NumPy, Pandas\nAlgoritmos Cuánticos, Redes Neuronales Cuánticas, Circuitos Cuánticos Variacionales, Criptografía Cuántica\nReinforcement Learning, Procesamiento de Lenguaje Natural (PLN), IA para Ciberseguridad, IA para la Salud, IA para Finanzas\nEste curso te brinda todo lo necesario para convertirte en un experto en IA y Computación Cuántica, asegurando que estés listo para el futuro de la Computación Cuántica impulsada por IA.",
      "target_audience": [
        "Principiantes y Entusiastas – Para quienes son nuevos en IA o Computación Cuántica y buscan una experiencia de aprendizaje práctica y estructurada.",
        "Desarrolladores de Software e Ingenieros – Aquellos que desean integrar IA y Computación Cuántica en aplicaciones y sistemas reales.",
        "Científicos de Datos e Ingenieros de Machine Learning – Profesionales que buscan mejorar sus habilidades en IA y explorar el Aprendizaje Automático Cuántico (QML).",
        "Entusiastas de la Computación Cuántica – Personas interesadas en comprender la mecánica cuántica, los circuitos cuánticos y los algoritmos cuánticos.",
        "Investigadores y Académicos en IA – Estudiantes o profesionales que estudian Redes Neuronales, Aprendizaje por Refuerzo, IA Cuántica y Circuitos Cuánticos Variacionales (VQC).",
        "Profesionales de Tecnología y Expertos en TI – Individuos que buscan hacer la transición hacia roles en Computación Cuántica impulsada por IA.",
        "Emprendedores e Innovadores – Líderes de negocios que quieren aprovechar soluciones cuánticas impulsadas por IA en finanzas, ciberseguridad, descubrimiento de fármacos y optimización.",
        "Estudiantes y Egresados – Estudiantes universitarios o recién graduados que desean especializarse en IA, Computación Cuántica o sus aplicaciones híbridas."
      ]
    },
    {
      "title": "Deep Learning A-Z™：人工神经网络实践",
      "url": "https://www.udemy.com/course/deep-learning-chinese/",
      "bio": "跟着两位机器学习与数据科学专家，学习用Python创建深度学习算法。包含模板。(英文原音)",
      "objectives": [
        "理解人工神经网络背后的直觉",
        "在实践中应用人工神经网络",
        "理解卷积神经网络背后的直觉",
        "在实践中应用卷积神经网络",
        "理解递归神经网络背后的直觉",
        "在实践中应用递归神经网络",
        "理解自组织映射背后的直觉",
        "在实践中应用自组织映射",
        "理解玻尔兹曼机背后的直觉",
        "在实践中应用玻尔兹曼机",
        "理解自编码器背后的直觉",
        "在实践中应用自编码器"
      ],
      "course_content": {
        "欢迎来到深度学习A-Z !": [
          "什么是深度学习?",
          "安装 Python",
          "下载课程相关数据集"
        ],
        "--------------------- 第1部分 ---------------------": [
          "欢迎来到第一部分"
        ],
        "感知ANN": [
          "学习计划",
          "神经元",
          "激活函数",
          "神经网络的工作原理",
          "神经网络的学习原理",
          "梯度下降法",
          "随机梯度下降",
          "反向传播"
        ],
        "建立ANN": [
          "学习本课程的先决条件",
          "怎样下载数据集",
          "商业问题描述",
          "安装Keras",
          "建立ANN",
          "建立ANN - 步骤 2",
          "建立ANN - 步骤 3",
          "建立ANN - 步骤 4",
          "建立ANN - 步骤 5",
          "建立ANN - 步骤 6",
          "建立ANN - 步骤 7",
          "建立ANN - 步骤 8",
          "建立ANN - 步骤 9",
          "建立ANN - 步骤 10"
        ],
        "作业挑战 - 我们需要和那位顾客说再见吗 ?": [
          "作业指导",
          "作业解答"
        ],
        "评估，改进和调节ANN": [
          "评估ANN",
          "改进ANN",
          "调节ANN"
        ],
        "作业挑战 - 让我在领奖台上退一步": [
          "作业指导"
        ],
        "-------------------- 第2部分 --------------------": [
          "欢迎来到第2部分 - 卷积神经网络"
        ],
        "感知CNN": [
          "CNN需要什么",
          "学习计划",
          "什么是卷积神经网络?",
          "步骤 1 - 卷积运算",
          "步骤 1(b) - ReLu层",
          "步骤 2 - 池化",
          "步骤 3 - 压平",
          "步骤 4 - 全连接",
          "总结",
          "归一化函数(Softmax)与交叉熵"
        ],
        "建立CNN": [
          "怎样下载数据集",
          "安装Keras",
          "CNN介绍",
          "建立CNN - 步骤 1",
          "建立CNN - 步骤 2",
          "建立CNN - 步骤 3",
          "建立CNN - 步骤 4",
          "建立CNN - 步骤 5",
          "建立CNN - 步骤 6",
          "建立CNN - 步骤 7",
          "建立CNN - 步骤 8",
          "建立CNN - 步骤 9",
          "建立CNN - 步骤 10"
        ]
      },
      "requirements": [
        "高中数学水平",
        "基本的Python编程知识"
      ],
      "description": "*** 如Kickstarter所示 ***\n人工智能正呈指数级增长。这点毫无疑问。自动驾驶汽车的驾驶里程已经能够达到数百万英里，IBM Watson对患者的诊断比许多医生都好，谷歌Deepmind的AlphaGo在Go上击败了世界围棋冠军 - 围棋是一种直觉起着关键作用的游戏。\n但是，随着人工智能的进一步发展，需要解决的问题就越复杂。只有深度学习可以解决这些复杂的问题，这就是为什么它是人工智能的核心。\n--- 为什么选择Deep Learning A-Z？---\n以下是我们认为Deep Learning A-Z™真正与众不同的五个原因，并因此从众多其他培训计划中脱颖而出：\n1.强大的结构\n我们聚焦的第一件也是最重要的事情就是为课程提供一个强大的结构。深度学习是非常广泛和复杂的，要走出这个迷宫，你需要一个明确的全球视野。\n这就是为什么我们将教程分为两册，分别代表深度学习的两个基本分支：有监督深度学习和无监督深度学习。每一册都关注三种独特的算法，我们发现这是掌握深度学习的最佳结构。\n2.直觉教程\n很多课程和书籍只是用理论、数学和编码对你狂轰滥炸...但他们忘了解释或许是最重要的部分：你为什么要做自己正在做的事情。这就是这门课程如此不同的地方。我们专注于为深度学习算法背后的概念开发一种直观的*感觉*。\n学习我们的直觉教程，你将有信心在本能层面上理解所有技术。一旦你开始动手编码练习，你会亲眼发现你的体验会变得更有意义。这是一套改变游戏规则的课程。\n3.令人振奋的项目\n你是否厌倦了以过度使用的过时数据集为基础开发的课程？\n对吧？好了，快来体验下我们的课程吧。\n在本课程中，我们将研究真实的数据集，以解决实际的业务问题。（绝对不是我们在每门课程中看到的那种无聊的虹膜或数字分类数据集）。在本课程中，我们将解决六个现实世界的挑战：\n· 解决客户流失问题的人工神经网络\n· 用于图像识别的卷积神经网络\n· 预测股票价格的递归神经网络\n· 调查欺诈的自组织映射\n· 创建推荐系统的玻尔兹曼机(Boltzmann Machine)\n· 接受挑战，助力赢得Netflix百万美金大奖的堆叠自编码器(Stacked Autoencoder)*\n*堆叠自编码器是深度学习中的一种全新技术，几年前根本还不存在这种技术。我们还没有在哪儿见到过这种方法能被以足够的深度进行解释。\n4.动手编码\n在Deep Learning A-Z™中，我们与您一起编码。每套实用教程都是从一张白纸开始的，让我们从零开始编写代码。通过这种方式，你可以顺着完全理解代码是如何组合在一起的，以及每行代码的含义。\n此外，我们将以这种方式有目的地构建代码，以便你可以下载并将其应用于自己的项目中。此外，我们会逐步解释在何处以及如何修改代码以插入你的数据集，根据你的需要定制算法，以获得你所需要的输出。\n这是一门自然延伸至你职业生涯的课程。\n5.课程内支持\n你是否上过一门课程或阅读过一本书，虽然有问题但无法联系到作者？\n好了，这门课程可不同哦。我们完全致力于使这门课程成为世界上最具破坏性和最强大的深度学习课程。当你需要我们的帮助时，我们有责任时刻为你解疑答惑。\n事实上，由于我们身体上也需要进食和睡眠，因此我们组建了一支专业的数据科学家团队来帮助我们。无论您何时提出问题，最多48小时内即可得到我们的回复。\n无论你的问题有多复杂，我们都会帮你解答。归根结底，我们希望你成功。\n--- 工具 ---\nTensorflow和Pytorch是深度学习中最受欢迎的两个开源库。在本课程中，这两个库你都会学习到！\nTensorFlow由谷歌开发，用于他们的语音识别系统、新的谷歌照片产品、Gmail、谷歌搜索等等。使用Tensorflow的公司包括AirBnb、Airbus、Ebay、Intel、Uber等。\nPyTorch同样强大，目前正由Nvidia和一流大学（斯坦福、牛津、巴黎高科）的研究人员进行开发。使用PyTorch的公司包括Twitter、Saleforce和Facebook。\n那么哪个更好？为什么？\n在本课程中，你将有机会使用这两种库，并明白何时Tensorflow更好，以及何时PyTorch更好。在整个教程中，我们将两者进行比较，并为你提供某些情况下最有用的提示和想法。\n有趣的是，这两个库都只有1年多的历史。正因如此，我们才会说：在这门课程中，我们将教你最前沿的深度学习模型和技巧。\n--- 更多工具 ---\nTheano 是另一个开源深度学习库。它的功能与Tensorflow非常相似，但是我们仍然会介绍它。\nKeras 是一个实现深度学习模型的令人难以置信的库。它充当Theano和Tensorflow的封装器。感谢Keras，我们可以只使用几行代码就能创建功能强大且复杂的深度学习模型。这可以让你全面了解你正在创建的内容。由于这个库，你所做的一切都看起来如此清晰和有条理，你会真正理解你正在做的事情。\n--- 更多工具 ---\nScikit-learn 最实用的机器学习库。我们主要利用它：\n· 通过最相关的技术k-折交叉验证(k-Fold Cross Validation)来评估我们模型的性能\n· 通过有效的参数调整来改进我们的模型\n· 预处理我们的数据，以便我们的模型可以在最佳条件下学习\n当然，我们也必须提到常见怀疑。整个课程以Python为基础，在每一部分中，你将有数小时的宝贵动手实践编码体验。\n此外，在整个课程中，我们将使用Numpy进行大量计算并操作高维数组，使用Matplotlib绘制富有洞察力的图表，并使用Pandas最高效地导入和操作数据集。\n--- 这门课程是面向谁的？---\n你也知道，在深度学习领域有很多不同的工具。在本课程中，我们一定会向你展示最重要和最先进的工具，这样当你完成Deep Learning AZ™时，你的技能就处于当今技术的最前沿。\n如果你是深入学习的初学者，那么你会发现这门课程非常有用。Deep Learning A-Z™是围绕特殊编码蓝图方法构建的，这意味着你不会陷入不必要的复杂编程或数学中，而是将在课程的早期阶段就能应用深度学习技术。你将从头开始构建您的知识，并将看到你学完每套教程后自己将变得越来越有自信。\n如果你已经拥有深度学习经验，那么你会发现这门课程令人耳目一新、令人鼓舞且非常实用。在Deep Learning AZ™中，你将掌握一些最前沿的深度学习算法和技术（其中一些甚至一年前都不存在）。学习本课程，你将直面现实世界的商业挑战，从而获得大量宝贵的实践经验。此外，在课程中，你会找到探索新的深度学习技能和应用的灵感。\n--- 真实案例研究 ---\n掌握深度学习不仅仅是了解直觉和工具，你还能将这些模型应用于实际场景，并为业务或项目获得实际可测量的结果。正因如此，在本课程中我们将介绍六个令人激动的挑战：\n#1 流失建模问题\n在本部分中，你将解决银行的数据分析挑战。你将获得一个包含该银行客户大量样本的数据集。为了制作这个数据集，银行收集了诸如客户ID、信用评分、性别、年龄、年资、余额、客户是否活跃、有无信用卡等信息。在6个月的期间内，银行观察了这些客户是否离开或留在银行。\n你的目标是根据上面给出的地理人口统计和交易信息建立一个人工神经网络，预测是否有任何个人客户将离开银行或留在银行（客户流失）。此外，还会要求你根据离开的可能性对银行的所有客户进行排名。要做到这一点，你需要使用基于概率方法的正确的深度学习模型。\n如果你能成功完成此项目，你将为银行创造重要的附加价值。通过应用你的深度学习模型，银行可以显著减少客户流失。\n#2 图像识别\n在本部分中，你将创建一个能够检测图像中各种对象的卷积神经网络。我们将实现此深度学习模型，以识别一组图片中的一只猫或一只狗。但是，此模型可以重复使用以检测其他任何内容，我们将向你展示如何操作 - 只需更改输入文件夹中的图片即可。\n例如，你将能够在一组脑图像上训练相同的模型，以检测它们是否包含肿瘤。但是如果你想让它能够检测猫和狗，那你可以直接拍张猫或狗的照片，然后你的模型就会预测你养了只什么宠物。我们甚至对Hadelin的狗进行了测试！\n#3 股票价格预测\n在本部分中，你将创建一个最强大的深度学习模型。甚至可以这么说，你将创建最接近“人工智能”的深度学习模型。为什么这么说？因为这个模型会有长期记忆，就像我们人类一样。\n作为深度学习一个分支的递归神经网络(RNN)有助于实现这一点。经典的RNN具有短时记忆功能，并且正是由于这个原因它既不流行也不强大。但最近对递归神经网络的一项重大改进导致LSTM（长短期记忆RNN）颇为流行，这已经完全改变了竞争环境。我们非常高兴能在我们的课程中加入这些尖端的深度学习方法！\n在这一部分中，你将学习如何实现这个超级强大的模型，我们将接受挑战，用它来预测真正的谷歌股票价格。斯坦福大学的研究人员已经面临类似的挑战，我们的目标是至少与他们一样好。\n#4 欺诈检测\n根据Markets＆Markets最近发布的一份报告，到2021年，欺诈检测和预防市场的规模将达到3319亿美元。这是一个巨大的行业，对高级深度学习技能的需求只会增长。这就是为什么我们在课程中加入了该案例研究。\n即第2册的第一部分 - 无监督深度学习模型。其业务挑战是检测信用卡申请中的欺诈。你将为银行创建深度学习模型，你会得到一个数据集，其中包含申请高级信用卡客户的信息。\n这是客户填写申请表时提供的数据。你的任务是检测这些申请中的潜在欺诈行为。这意味着，在挑战结束时，你将能够明确列出那些可能在申请中作弊的的客户。\n#5 & 6 推荐系统\n从Amazon产品建议到Netflix电影推荐 - 好的推荐系统在今天的世界中非常有价值。能够创造推荐系统的专家是世界上收入最高的数据科学家。\n我们将研究一个与Netflix数据集具有完全相同功能的数据集：海量电影，及对看过的电影进行了评分的成千上万名用户。与Netflix数据集完全相同，从1到5分进行打分，这让推荐系统的构建比只是评“喜欢”或“不喜欢”更复杂。\n你最终的推荐系统将能够对客户未看过的电影进行打分预测。相应地，通过将预测从5到1分进行打分，你的深度学习模型将能够为每个用户推荐应该观看哪些电影。创建如此强大的推荐系统是一个相当大的挑战，所以我们会给自己两次机会。这意味着我们将使用两种不同的深度学习模型来构建推荐系统。\n我们的第一个模型是Deep Belief Networks，复杂的玻尔兹曼机(Boltzmann Machine)将在第5部分中介绍。然后我们的第二个模型将使用强大的自动编码器(AutoEncoders)，这是我个人的最爱。你会被其简洁和强悍所震惊。\n而且你甚至可以将它用于你自己或你的朋友。电影列表一目了然，因此你只需要对已经看过的电影进行打分，在数据集中输入你的评分，执行你的模型，然后就瞧好吧！如果不知道想在Netflix上看什么电影，推荐系统会准确地告诉你哪天晚上你会喜欢哪些电影！\n--- 总结 ---\n总之，这是一个令人兴奋的培训计划，满满的都是直觉教程、实践练习和真实案例研究。\n我们对深度学习充满热情，希望能在课堂上见到你哦！\nKirill & Hadelin",
      "target_audience": [
        "对深度学习感兴趣的人",
        "至少具有高中数学知识并希望开始进行深度学习的学生",
        "任何了解机器学习或深度学习基础知识（包括线性回归或逻辑回归等经典算法以及人工神经网络等更高级的主题），但希望了解更多知识并探索深度学习所有不同领域的中级水平人士",
        "任何对编码不甚熟悉但对深度学习感兴趣并希望在数据集上轻松应用深度学习的人士",
        "任何想要开始从事数据科学职业的在校大学生",
        "任何想要在深度学习中更上一层楼的数据分析师",
        "任何对自己的工作不满意并希望成为数据科学家的人士",
        "任何想要通过使用强大的深度学习工具为其业务创造附加价值的人士",
        "任何想要了解如何在其企业中利用深度学习的指数技术的企业主",
        "任何希望利用最前沿的深度学习算法颠覆行业认知的企业家"
      ]
    },
    {
      "title": "ChatGPT・生成AI時代の今だからこそ学びたい！人工知能・機械学習入門講座（教師あり学習編）",
      "url": "https://www.udemy.com/course/pmyzrhnp/",
      "bio": "ChatGPT・DALL·E・Midjourneyといった生成AI時代の今こそ学ぶ！自分のキャリアを切り開くための、Google Colab、PythonとScikit-learnによる、人工知能・機械学習の仕組み",
      "objectives": [
        "教師あり学習によるAIモデル開発スキルが身に付く（プログラミングスキル（Python、Scikit-learn、Pandas、Matplotlib等各種ライブラリ含む）、開発プロセス完遂スキル（事前準備（データの整形等含む）、学習、評価、改善））",
        "深層学習や強化学習など、教師あり学習以外のAIモデル開発の学習効率が上がる（他の学習方法との差分（深層学習ならTensorFlow等のライブラリ利用方法等）のみ学習でOK）",
        "普段使っているAIサービスに対する疑問が晴れてスッキリする（ChatGPTが誤った回答を返すことがあるのはなぜ？、Amazonのお勧めに求めていない商品がレコメンドされることがあるのはなぜ？、Googleフォト上で別人を同一人物と認識されることがあるのはなぜ？）",
        "AIエンジニアで構成されるチームや組織のマネジメントスキルが上がる（プロジェクトの問題解決力アップ、エンジニアのアサイン力アップ（スキルレベルの見極め）、リスクマネジメント力アップ）",
        "最小二乗法、決定木、サポートベクターマシン（SVM）といった教師あり学習で使用される主要なアルゴリズムの仕組みが理解できる"
      ],
      "course_content": {
        "コース概要": [
          "本コース受講にあたって",
          "自己紹介",
          "本コースのねらい",
          "本コースの内容"
        ],
        "人工知能・機械学習概要": [
          "人工知能とは",
          "機械学習とは",
          "機械学習の種類",
          "機械学習のプロセス",
          "機械学習に必要なスキル",
          "Google Colabとは",
          "Pythonとは",
          "Scikit-learnとは",
          "機械学習を学ぶ心構え"
        ],
        "機械学習ハンズオン理論編（教師あり学習）": [
          "回帰とは①（概要）",
          "回帰とは②（モデル作成の仕組み（最小二乗法））",
          "分類とは①（概要）",
          "分類とは②（モデル作成の仕組み（決定木））",
          "分類とは③（モデル作成の仕組み（サポートベクターマシン（SVM）（線形分類）））",
          "分類とは④（モデル作成の仕組み（サポートベクターマシン（SVM）（非線形分類）））",
          "事前準備プロセスのポイント①（データ整形）",
          "事前準備プロセスのポイント②（データ分割）",
          "評価プロセスのポイント①（回帰モデル評価）",
          "評価プロセスのポイント②（分類モデル評価）",
          "改善プロセスのポイント①（標準化）",
          "改善プロセスのポイント②（多重共線性）",
          "改善プロセスのポイント③（過学習）"
        ],
        "機械学習ハンズオン実践編①（教師あり学習（回帰））": [
          "目的定義",
          "事前準備（データ収集）",
          "事前準備（データ整形）",
          "事前準備（データ分割）",
          "学習",
          "評価",
          "改善①（標準化）",
          "改善②（計算手順変更（偏最小二乗法（PLS）））"
        ],
        "機械学習ハンズオン実践編②（教師あり学習（分類））": [
          "目的定義",
          "事前準備（データ収集）",
          "事前準備（データ整形）",
          "事前準備（データ分割）",
          "学習",
          "評価",
          "改善①（ハイパーパラメータ調整（グリッドサーチ））",
          "改善②（計算手順変更（サポートベクターマシン（SVM）））"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "（ハンズオン含め全セクション受講されたい方）オブジェクト指向プログラミングの基礎知識",
        "（ハンズオン以外の概要、理論編セクションのみ受講されたい方）無し"
      ],
      "description": "＜コースの概要＞\n本コースは前半の概要編と理論編で人工知能・機械学習の基礎と教師あり学習によるモデル作成の仕組みを学びます。\nその後、後半の実践編で、Google Colabの環境で、PythonとScikit-learnを使用し回帰モデル作成、分類モデル作成の一連のプロセス（事前準備、学習、評価、改善　（標準化、ハイパーパラメータ調整、アルゴリズム変更（PLS、SVM）））をハンズオンで実施することで、学んだ理論を実践で使えるスキルに引き上げていきます。\nまた、スキルだけではなく、人工知能・機械学習を学ぶ際の心構えを含め、ご自身のキャリアを切り開いていくために必要な考え方、マインド面のポイントも合わせてお伝えしていきます。\n\n\n＜他教材との違い＞\n本コースと他教材（書籍やYoutube動画教材等）との違いは以下の通りです。\n・１本完結型コースであるためご自身でネット検索やマニュアル確認等を行う手間がかからない。\n・モデル作成の仕組みや、なぜそのコードを使用するのか等、解説する技術や手順一つとってもその理由や背景を詳細に説明しているため途中で止まらずに受講できる。\n・全レクチャー動画ダウンロード可能なため、場所を問わずどこからでも受講できる。\n・全ハンズオンで使用するデータセットや完成版のコード等を添付しているため、コーディングミスによる原因調査等、余計な手間がかからない。\n\n\n＜コース受講後の姿＞\n本コース受講後には以下のスキルを自然と身に付けることができます。\n・教師あり学習によるAIモデル開発スキルが身に付く\n・プログラミングスキル（Python、Scikit-learn、Pandas、Matplotlib等各種ライブラリ含む）\n・開発プロセス完遂スキル（事前準備（データの整形等含む）、学習、評価、改善）\n・深層学習や強化学習など、教師あり学習以外のAIモデル開発の学習効率が上がる\n・他の学習方法との差分（深層学習ならTensorFlow等のライブラリ利用方法等）のみ学習でOK\n・普段使っているAIサービスに対する疑問が晴れてスッキリする\n・ChatGPTが誤った回答を返すことがあるのはなぜ？\n・Amazonのお勧めに求めていない商品がレコメンドされることがあるのはなぜ？\n・Googleフォト上で別人を同一人物と認識されることがあるのはなぜ？\n・AIエンジニアで構成されるチームや組織のマネジメントスキルが上がる\n・プロジェクトの問題解決力アップ\n・エンジニアのアサイン力アップ（スキルレベルの見極め）\n・リスクマネジメント力アップ\n\n\n＜コースの内容＞\n本コースの内容は以下の通りです。\nコース概要\n本コース受講にあたって\n自己紹介\n本コースのねらい\n本コースの内容\n人工知能・機械学習概要\n人工知能とは\n【キーワード】特化型、汎用型（AGI）\n機械学習とは\n【キーワード】大規模言語モデル(LLM)、OpenAI、生成AI、ChatGPT、家賃予測モデル\n機械学習の種類\n【キーワード】教師あり学習、教師なし学習、深層学習、強化学習、アンサンブル学習、最小二乗法、k-means、Transformer（GPT）、Q学習、ブースティング\n機械学習のプロセス\n機械学習に必要なスキル\nGoogle Colabとは\n【キーワード】Google Colab、Jupyter Notebook、PyCharm、Spyder、VSCode\nPythonとは\n【キーワード】Python、R、Julia、C++、JavaScript\nScikit-learnとは\n【キーワード】Scikit-learn、Pandas、Matplotlib、NumPy\n機械学習を学ぶ心構え\n機械学習ハンズオン理論編（教師あり学習）\n回帰とは①（概要）\n【キーワード】最小二乗法、勾配降下法、決定木、ランダムフォレスト、ニューラルネットワーク\n回帰とは②（モデル作成の仕組み（最小二乗法））\n分類とは①（概要）\n【キーワード】単純パーセプトロン（誤差逆伝播法含む）、ロジスティック回帰（最尤推定法含む）、サポートベクターマシン（SVM）\n分類とは②（モデル作成の仕組み（決定木））\n【キーワード】ジニ係数、利得計算\n分類とは③（モデル作成の仕組み（サポートベクターマシン（SVM）（線形分類）））\n分類とは④（モデル作成の仕組み（サポートベクターマシン（SVM）（非線形分類）））\n【キーワード】カーネル関数、カーネルトリック\n事前準備プロセスのポイント①（データ整形）\n事前準備プロセスのポイント②（データ分割）\n【キーワード】2分割（ホールドアウト法）、3分割\n評価プロセスのポイント①（回帰モデル評価）\n【キーワード】決定係数 (R^2)、平均二乗誤差(MSE)、平均絶対誤差(MAE)\n評価プロセスのポイント②（分類モデル評価）\n【キーワード】正解率(Accuracy)、適合率(Precision)、再現率(Recall)、F1値(F1-score)、混同行列(Confusion Matrix)\n改善プロセスのポイント①（標準化）\n改善プロセスのポイント②（多重共線性）\n【キーワード】相関係数(Correlation Coefficient)、VIF(Variable Inflation Factor)、手動削除、Lasso回帰、PCA（主成分分析）、PLS（偏最小二乗法）、Ridge回帰、データセット変更\n改善プロセスのポイント③（過学習）\n【キーワード】検証用データの導入（k-分割交差検証含む）、ハイパーパラメータ調整による、モデル複雑さ調整、計算手順（アルゴリズム）変更\n機械学習ハンズオン実践編①（教師あり学習（回帰））\n目的定義\n事前準備（データ収集）\n事前準備（データ整形）\n事前準備（データ分割）\n学習\n評価\n改善①（標準化）\n改善②（計算手順変更（偏最小二乗法（PLS）））\n機械学習ハンズオン実践編②（教師あり学習（分類））\n目的定義\n事前準備（データ収集）\n事前準備（データ整形）\n事前準備（データ分割）\n学習\n評価\n改善①（ハイパーパラメータ調整（グリッドサーチ））\n改善②（計算手順変更（サポートベクターマシン（SVM）））\nボーナスレクチャー\nボーナスレクチャー",
      "target_audience": [
        "教師あり学習によるAIモデル開発スキルを身に付けたい方",
        "深層学習や強化学習など、教師あり学習以外のAIモデル開発の土台となる知識やスキルを身に付けたい方",
        "普段使っているAIサービスに対する疑問を解消してスッキリしたい方",
        "AIエンジニアで構成されるチームや組織のマネジメントスキルを身に付けたい方"
      ]
    },
    {
      "title": "Ciência de Dados: Fundamentos de Regressão e AI",
      "url": "https://www.udemy.com/course/scikitlearn/",
      "bio": "Descubra como utilizar ferramentas para análise preditiva de dados e aprimore suas habilidades em Machine Learning!",
      "objectives": [
        "Domine o aprendizado de máquina em Python para Regressão de Dados",
        "Faça previsões precisas",
        "Crie modelos robustos de aprendizado de máquina",
        "Use o aprendizado de máquina para fins pessoais ou profisssionais",
        "Tenha um ótimo domínio de muitos modelos de Machine Learning"
      ],
      "course_content": {
        "Introdução ao Machine Learning": [
          "Introdução"
        ],
        "Processamento de Dados": [
          "Importando um Dataset",
          "Visualização de Dados",
          "Limpeza de Dados (Remoção de Outliers)",
          "Padronização e Normalização de Dados"
        ],
        "Realizando Regressões com o Scikit-Learn": [
          "Simple Linear Regression",
          "Multiple Linear Regression",
          "Polynomial Regression",
          "RANSAC Regression",
          "K-Nearest Neighbors Regression",
          "Support Vector Machines Regression",
          "Decision Tree Regression",
          "Random Forest Regression",
          "Extremely Randomized Trees Regression",
          "Stochastic Gradient Descent Regression",
          "Light GBM Regression",
          "Multi-layer Perceptron Regression"
        ],
        "Aprendizados Complementares": [
          "Full Multivariate Polynomial Regression Regression",
          "Huber Regressor + TheilSen Regressor",
          "Multiple Linear Regression - TheilSenRegressor"
        ],
        "Considerações Finais do Curso": [
          "Considerações Finais do Curso"
        ]
      },
      "requirements": [
        "Apenas um nível de matemática e estatística do ensino médio."
      ],
      "description": "Por que você deve fazer este curso?\nVocê sabia que a área de Machine Learning é um dos grandes pilares da Indústria 4.0? Sim! Nos auxilia criando Gêmeos Digitais, entendendo melhor os processos, melhorando a eficiência, reduzindo custos, minimizando impactos ambientais, além de ser uma poderosa ferramenta na área de Pesquisa e Desenvolvimento de novos produtos e processos.\nNão perca esta oportunidade de surfar na crista da onda e estar entre os TOP 10 na Área. Aprenda a criar algoritmos de Regressão de Dados usando Machine Learning em Python.\nTudo rodando na nuvem (Google Colab), sem precisar instalar nada no seu computador! E ainda por cima usando códigos Open Source FREE!\nVamos orientá-lo no mundo do aprendizado de máquina, utilizando Tutoriais e Templates que você poderá reutilizar em seus casos! Na vida real! No seu trabalho! Em cada tópico deste curso lhe forneceremos um Notebook completo para você rodar no Google Colab ou em seu Jupyter Notebook e os Datasets necessários.\nVocê desenvolverá novas habilidades e melhorará sua compreensão desta área desafiada. Este curso pode ser concluído fazendo os tutoriais Python e respondendo pequenos Quizes no final de cada capítulo.\nEste curso é divertido e empolgante e, ao mesmo tempo, mergulhamos profundamente na Aprendizado de Máquina / Machine Learning com foco na área de Regressão de Dados.\nEstá curso está estruturado com os seguintes tópicos:\nIntrodução ao Machine Learning\nProcessamento de Dados\nVisualização de Dados\nLimpeza de Dados (Remoção de Outliers)\nPadronização e Normalização de Dados\nUtilização do SciKit-Learn\nTrabalhando com Pipelines\nTrabalhando com Grid Search\nTrabalhando com Cross-Validation\nSimple Linear Regression\nMultiple Linear Regression\nPolynomial Regression\nRANSAC Regression\nK-Nearest Neighbors Regression\nSupport Vector Machines Regression\nDecision Tree Regression\nRandom Forest Regression\nExtremely Randomized Trees Regression\nStochastic Gradient Descent Regression\nLight GBM Regression\nMulti-layer Perceptron Regression",
      "target_audience": [
        "Qualquer pessoa interessada em Machine Learning.",
        "Qualquer aluno que esteja cursando uma Faculdade e que queira iniciar uma carreira em Ciência de Dados.",
        "Alunos que tenham no mínimo conhecimento de matemática do ensino médio e que queiram começar a aprender Machine Learning.",
        "Qualquer analista de dados que deseja subir de nível no Machine Learning.",
        "Qualquer pessoa que queira agregar valor aos seus negócios usando ferramentas poderosas de aprendizado de máquina.",
        "Qualquer pessoa que não esteja satisfeita com seu trabalho e que queira se tornar um Cientista de Dados."
      ]
    },
    {
      "title": "Adobe Firefly meistern: KI in Photoshop, Express & ChatGPT",
      "url": "https://www.udemy.com/course/adobe-firefly-meistern-ki-in-photoshop-express-chatgpt/",
      "bio": "Adobe & KI: Firefly, Express, Photoshop & Illustrator! Der Midjourney & Stable Diffusion Konkurrent +Prompt Engineering",
      "objectives": [
        "Text zu Bild [Text to Image]: Erstelle beeindruckende Bilder mit der Adobe Firefly Web-App",
        "Adobe Firefly: Lerne, wie man die auf KI basierten Firefly-Werkzeuge von Adobe vewendet",
        "Ständig die neusten Updates von Adobe Firefly und deren KI",
        "Generative Füllung [Generative Fill]: Hinzufügen, entfernen und erweitern von Bildern mit der Adobe Firefly Web-App",
        "Texteffekte: Text in Kunstwerke verwandeln mit der Adobe Firefly",
        "Generative Farbe: Ändern der Farbpalette deiner Vektorgrafiken",
        "KI-Kunstfertigkeit verbessern: Erstelle ein beeindruckendes Portfolio von KI-generierten Meisterwerken",
        "Prompt-Engineering: Lerne, wie du Aufforderungen richtig formulieren musst, um die gewünschten Ergebnisse zu erzielen.",
        "Verstehe die Technologie von Diffusion Modellen, dadurch lernst du noch besser damit zu arbeiten",
        "Photoshop KI-Werkzeuge: Lerne, wie man die Firefly-Updates für die Photoshop-App, wie die generative Füllung, verwendet",
        "Adobe Express: KI-basierte Tools von Adobe für noch kreativere Projekte",
        "ChatGPT zum schreiben von Adobe Firefly Prompts",
        "Adobe Illustrator für Vektor Datein verwenden"
      ],
      "course_content": {
        "Einführung": [
          "Willkommen!",
          "Kurs Überblick",
          "WICHTIG: Mein Ziel & was du vom Kurs erwarten kannst",
          "Was ist die neue künstliche Intelligenz \"Adobe Firefly\"?",
          "Firefly ist aus der Beta raus und Version 2 ist da!",
          "Das Diffusion Model einfach erklärt",
          "Unterschiede von Adobe Firefly zu Midjourney und Stable Diffusion",
          "Wichtige Links",
          "Dozentenvorstellung: Arnold Oberleiter (Arnie)"
        ],
        "Adobe Firefly: Die Basics": [
          "Adobe Firefly: Die Plattform von Adobe",
          "Was darfst Du mit der künstlichen Intelligenz von Adobe erschaffen?",
          "Text to Image: Die Bildgeneration in Firefly [Prompts kopieren, Styles...]",
          "Nach dem Erstellen: Downloaden, Favoriten & Variationen erstellen & bearbeiten",
          "Generative fill: Das \"Inpainting\" von Adobe Firefly [Generative Füllung]",
          "Texteffekte der Ai von Adobe",
          "Vector Datein in anderen Farben erstellen mit KI & die Farbenlehre",
          "Recap & gemeinsames Projekt: Kombiniere die Tools und erstelle ein Thumbnail",
          "Was bedeutet Lernen & bist auch du ein guter Lerner?"
        ],
        "Updates": [
          "Adobe Firefly ist nicht mehr in Beta: Alles was du wissen musst",
          "Adobe Firefly Version 2 ist da!"
        ],
        "Prompt Engineering in Firefly und ChatGPT als Gehilfe": [
          "Basics vom Prompt Engineering in Diffusion Models [Midjourney kann helfen]",
          "Spickzettel: Was sollst du in Prompts einbauen?",
          "ChatGPT als Prompt-Generator für Adobe Firefly",
          "Dein ChatGPT Prompt Generator für Adobe Firefly zum kopieren",
          "Lernerfahrung mit ChatGPT & Adobe Firefly: Kombiniere LLMs und Diffusion Modelle"
        ],
        "Adobe Express: All in One Plattform für Social Media & mehr": [
          "Adobe Express: Die Plattform im Überblick",
          "Bild und Text Generierung in Adobe Express mit Firefly",
          "Erstellen wir zusammen ein Instagram Reel mit KI Schrift in Adobe Express"
        ],
        "KI in Adobe Photoshop": [
          "Installiere die Creative Cloud & Photoshop Beta",
          "Firefly in Photoshop Beta: Die ersten Versuche",
          "Photoshop mit KI: Wähle Dinge aus und entferne oder ersetze sie",
          "Photoshop mit KI: Schnelles Ausbessern von Fehlern dank diesem KI-Tool",
          "WICHTIG: Zusammenfassung der KI-Tools in Photoshop und gemeinsames Projekt"
        ],
        "Weitere Anwendungsfälle & beantwortung von Fragen": [
          "Mockups in Adobe Firefly erstellen"
        ],
        "Alternativen Zu Firefly im Test und direkten Vergleich": [
          "Alternativen zu Adobe Fierefly im Test: Midjourney, Stable Diffusion, Dall-E",
          "In und Outpainting: Midjourney, leonardo & Firefly! Der Vergleich",
          "Fazit: Adobe Firefly, Dall-E, Stable Diffusion [Leonardo.AI] oder Midjourney?"
        ],
        "Künstliche Intelligenz in Adobe Illustrator": [
          "Künstliche Intelligenz in Adobe Illustrator [Farben verändern von Vektoren]"
        ],
        "Wie geht es weiter & Ein Blick in die Zukunft": [
          "Wie könnte die zukunft von Adobe Firefly aussehen?",
          "Wie geht es weiter & Mein Dnake!",
          "Bonus"
        ]
      },
      "requirements": [
        "Keine Voraussetzungen nötig du lernst alles im Kurs",
        "Zugang zu Adobe Creative Cloud ist von vorteil (Testen funktioniert auch gratis)"
      ],
      "description": "Willkommen zu \"Adobe Firefly Meistern: KI in Photoshop, Express & ChatGPT\": Enthülle und erweitere deine kreative Genialität!\nIn diesem Kurs wirst du in die revolutionäre Welt der Adobe Firefly Technologie eingeführt, ein Ökosystem, das Künstliche Intelligenz (KI) mit Photoshop, Express und Illustrator vereint, um deine kreative Vision zu einer realen Meisterleistung zu transformieren.\nStell dir vor, du kannst beeindruckende Kunstwerke und Designs erschaffen, die weit über herkömmliche Methoden hinausgehen.\n\n\nDieser Kurs wird eine unerschöpfliche Quelle innovativer Techniken sein, die deine kreativen Konzepte in erstaunliche Realitäten verwandeln:\n\n\nText zu Bild: Schenke deinen Worten visuelle Pracht. Lerne, wie du mit der Adobe Firefly Web-App lebendige Bilder aus Text kreierst und beeindruckende Narrative gestaltest.\nGenerative Füllung & Farbe: Manipuliere und erweitere deine Designs mit müheloser Perfektion. Entdecke die Möglichkeiten der generativen Füllung und Farbpalette, um dynamische und visuell ansprechende Kunstwerke zu schaffen.\nKI-Kunstfertigkeit Verbessern: Baue ein Portfolio von KI-generierten Kunstwerken auf, das selbst den kritischsten Betrachter in Erstaunen versetzt.\nPrompt-Engineering: Beherrsche die Kunst der Prompt-Formulierung, um die besten Ergebnisse aus deinen KI-Projekten zu erzielen.\nChatGPT für schnelle Prompts: Lerne, wie du ChatGPT zu einer Prompt Maschine für Adobe Firefly machst.\nIn-Depth Technologie Verständnis: Tauche ein in die Welt der Diffusionsmodelle, um ein tiefes Verständnis und eine gesteigerte Kompetenz im Umgang mit KI-Technologien zu entwickeln.\nPhotoshop & Express Werkzeuge: Erweitere dein Wissen in den Adobe Firefly-Updates für Photoshop und Express, und nutze KI-Tools, um deine kreativen Projekte auf ein neues Level zu heben.\n\n\nDieser Kurs ist für alle da, ob Einsteiger oder Profi, und bietet eine umfassende Einführung in die neuesten Entwicklungen in der Welt der KI-gestützten Kunst und Design.\n\n\nIn \"Adobe Firefly Meistern: KI in Photoshop, Express & ChatGPT\" wirst du:\n\n\nDie Macht der Adobe Firefly-Tools nutzen, um atemberaubende künstlerische Werke zu erschaffen.\nLernen, wie du mit KI die Grenzen dessen, was im Bereich der digitalen Kunst möglich ist, neu definierst.\nDeine Projekte und Designs mit innovativen Technologien und Techniken aufwerten, die Zeit sparen und beeindruckende Ergebnisse liefern.\nNeuartige Einkommensströme erschließen, indem du lernst, wie du deine kreativen Fähigkeiten mit KI-Tools von Adobe skalieren kannst.\nDieser Kurs ist ideal für kreative Köpfe, Designer, Marketingprofis und Unternehmer, die ihre kreativen Horizonte erweitern und die transformative Kraft der Adobe Firefly KI-Technologie für sich nutzen wollen.\nNutze diese Gelegenheit, die grenzenlosen Möglichkeiten von Adobe Firefly zu entdecken und deine kreative Vision zum Leben zu erwecken.\nMelde dich noch heute für \"Adobe Firefly Meistern: KI in Photoshop, Express & ChatGPT\" an und werde zum Meister der KI-gestützten digitalen Kunst und Design!",
      "target_audience": [
        "Künstler, Designer, Fotografen und Personen die die neueste KI-Technologie erlernen möchten.",
        "Jeder, der mit Bild, Text, Foto oder Vectoren schneller arbeiten möchte",
        "Fotografen, die KI in ihre Arbeit einbinden möchten",
        "Digitale Künstler und Illustratoren, die ihren kreativen Prozess verbessern und innovative Techniken mit KI-gestützten Werkzeugen erforschen möchten.",
        "Grafikdesigner, die sich von der Masse abheben wollen",
        "Marketing- und Werbefachleute, die mit Hilfe von KI-Kunst und Fotografie mehr Aufmerksamkeit möchten"
      ]
    },
    {
      "title": "【2024年ノーベル賞】ホップフィールドネットワークとボルツマンマシン -深層学習の源流を基礎から学ぶ-",
      "url": "https://www.udemy.com/course/hopfield-boltzmann/",
      "bio": "Pythonを使った実装演習を通じて、ホップフィールドネットワークとボルツマンマシンモデルの動作原理を実践的に学びます。現代のAIブームの源流となったモデルを学び、ニューラルネットワークの本質的な理解を深めましょう。",
      "objectives": [
        "2024年ノーベル物理学賞の対象、ホップフィールドネットワークとボルツマンマシンの仕組みを基礎から学びます。",
        "Pythonを使い、ホップフィールドネットワーク、およびボルツマンマシンを構築する方法を学びます。",
        "ホップフィールドネットワーク、ボルツマンマシンと物理学の接点について学びます。",
        "ホップフィールドネットワーク、ボルツマンマシンの数学的背景およびアルゴリズムについて学びます。",
        "深層学習、ニューラルネットワークの源流を学びます。"
      ],
      "course_content": {
        "ホップフィールドネットワークとボルツマンマシンの概要": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "ニューラルネットワークの歴史",
          "ホップフィールドネットワークの概要",
          "ボルツマンマシンの概要"
        ],
        "ホップフィールドネットワークの実装": [
          "セクション2の教材",
          "Section2の概要",
          "シンプルなホップフィールドネットワークの実装",
          "（補足）「外積」という言葉の意味について",
          "Pythonのクラスでホップフィールドネットワークを実装する",
          "ホップフィールドネットワークによるノイズ除去",
          "ホップフィールドネットワークによる手書き数字（MNIST）の復元"
        ],
        "ボルツマンマシンの実装": [
          "セクション3の教材",
          "Section3の概要",
          "ボルツマンマシンをPythonのクラスで実装する",
          "ボルツマンマシンの動作",
          "制限ボルツマンマシンをPythonのクラスで実装する",
          "制限ボルツマンマシンの動作",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "コードを動かすためにGoogle Colaboratoryを使用しますが、ローカル環境はWindowsでもMacでも大丈夫です。",
        "2024年11月の環境で解説しています。最新の環境と異なる可能性があります。",
        "Googleのアカウント開設が必要です。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "高校レベル以上の数学の知識があるのが望ましいです。",
        "ある程度機械学習の知識があるのが望ましいです。"
      ],
      "description": "「ホップフィールドネットワークとボルツマンマシン」は、2024年のノーベル物理学賞を受賞したニューラルネットワークモデルの基礎を学ぶ講座です。\n人工知能の歴史に興味がある方、ニューラルネットワークの原理を根本から理解したい方におすすめです。\n\n\nホップフィールドネットワークとボルツマンマシンは、1980年代に考案された画期的な人工神経回路モデルです。\nこれらは物理学の概念を取り入れたアプローチで、現代のディープラーニングの理論的基盤となりました。\n\n\n本講座では、理論的な説明だけでなく、Pythonを使った実装演習を通じて、これらの歴史的なモデルの動作原理を実践的に学びます。\n講座の前半では基礎概念を丁寧に解説し、後半では実装演習を通じて理解を深めていきます。\n現代のAIブームの源流となったモデルを学び、ニューラルネットワークの本質的な理解を深めましょう。\n\n\n講座の内容は以下の通りです。\nSection1. ホップフィールドネットワークとボルツマンマシンの概要\n→ 両者の概要と基礎理論を学びます。\nSection2. ホップフィールドネットワークの実装\n→ Pythonでホップフィールドネットワークを実装し、パターン記憶の仕組みを体験します。\nSection3. ボルツマンマシンの実装\n→ Pythonでボルツマンマシンを実装し、確率的な学習の原理を理解します。",
      "target_audience": [
        "2024年ノーベル物理学賞の対象となった、ホップフィールドネットワークとボルツマンマシンの仕組みを基礎から学びたい方。",
        "AI技術の源流を学びたい方。",
        "AIの歴史に興味がある方 。",
        "AIと物理学の融合について学びたい方。",
        "AI技術を包括的に学びたい方。"
      ]
    },
    {
      "title": "Alteryx na Prática",
      "url": "https://www.udemy.com/course/alteryx-na-pratica/",
      "bio": "Esse curso é para quem quer manipular dados de uma maneira simples e fácil.",
      "objectives": [
        "Manipulação da ferramenta Alteryx na prática",
        "Criar fluxos na ferramenta ALteryx",
        "Fazer ETL e mineração de dados com a ferramenta Alteryx",
        "Analise e tratamento de dados com Alteryx"
      ],
      "course_content": {
        "Introdução": [
          "Introdução"
        ],
        "Input/Output data": [
          "Aula 1",
          "Aula2",
          "Aula3",
          "Aula4"
        ],
        "Preparation": [
          "Aula5",
          "Aula6",
          "Aula7",
          "Aula8",
          "Aula9",
          "Aula10",
          "Aula11",
          "Aula12",
          "Aula13"
        ],
        "Join": [
          "Aula14",
          "Aula 15",
          "Aula 16",
          "Aula 17",
          "Aula 18"
        ],
        "Projeto 01": [
          "Roteiro do Projeto",
          "Projeto 01 - Desenvolvimento",
          "Projeto 01 - Desenvolvimento"
        ],
        "Parse": [
          "Aula 19",
          "Aula 20"
        ],
        "Transform": [
          "Aula 21",
          "Aula 22",
          "Aula 23",
          "Aula 24"
        ],
        "Projeto 02": [
          "Projeto 02 - Roteiro",
          "Projeto 02 - Desenvolvimento"
        ],
        "In-DB": [
          "Aula 25"
        ],
        "Developer": [
          "Aula 26",
          "Aula 27"
        ]
      },
      "requirements": [
        "Ter curiosidade e vontade de aprender!"
      ],
      "description": "Esse curso é para quem quer manipular a ferramenta Alteryx em suas principais funcionalidades e utiliza-lá em seu melhor potencial.  Além da utilização da ferramenta para mineração, análise, visualização, higienização, ETL, e padronização de dados, Requisição a APIs, leitura de bases de dados, conversão de dados, tudo isso e muito mais dentro dessa ferramenta extremamente incrível e versátil.",
      "target_audience": [
        "Desenvolvedores iniciantes",
        "Pessoas que querem uma maneira fácil de tratar dados",
        "Pessoas que não conhecem de programação mas que precisam transformar dados em informação de alguma forma"
      ]
    },
    {
      "title": "【PyMCで学ぶ】データサイエンスのための実践ベイズ統計モデリング",
      "url": "https://www.udemy.com/course/pymc-bayes/",
      "bio": "包括的な理論解説とPyMCによる実装で実践的なベイズ統計モデリングのスキルを身に付けよう",
      "objectives": [
        "確率、ベイズ統計学の入門(様々な確率分布、条件付き確率)から応用(各種統計モデル、モデル選択など)まで含めた体系的な知識",
        "様々な統計モデル(線形モデル、一般化線形モデル、階層ベイズ)についての特徴やモデルの詳細を理解できる",
        "PyMCによるベイズ統計学・統計モデリングの実装を通して、実践的なスキルを身に付ける",
        "Bayesian ABテスト、ロバスト線形回帰、階層ベイズなど実用的な統計モデリングの実装"
      ],
      "course_content": {
        "はじめに": [
          "コース概要",
          "コースで使用するデータ"
        ],
        "ベイズ統計の基礎": [
          "確率とは?",
          "記述統計",
          "期待値・分散",
          "条件付き確率・同時確率・ベイズの定理",
          "様々な確率分布"
        ],
        "関数サンプリング・関数近似": [
          "MCMC",
          "MCMCの実際",
          "ラプラス近似",
          "変分推論"
        ],
        "ベイズ推論": [
          "統計モデル",
          "Black-Box Model / White-Box Model",
          "ベイズ推論の流れ",
          "PPL",
          "グラフィカルモデル",
          "HDI"
        ],
        "Bayesian A/B Test": [
          "デジタルマーケティング用語",
          "Bayesian A/B Test【理論編】",
          "Bayesian A/B Test【実践編】データ理解",
          "Bayesian A/B Test【実践編】モデリング",
          "Bayesian A/B Test【実践編】評価・解釈"
        ],
        "線形回帰(LM)": [
          "線形モデル【理論編】",
          "線形モデル【実践編】データ理解",
          "線形モデル【理論編】モデリング",
          "線形モデル【理論編】評価・解釈",
          "ロバスト線形回帰【理論編】",
          "ロバスト線形回帰【実践編】データ理解",
          "ロバスト線形回帰【実践編】線形回帰のモデリング",
          "ロバスト線形回帰【実践編】線形回帰による予測",
          "ロバスト線形回帰【実践編】ロバスト線形回帰のモデリング",
          "ロバスト線形回帰【実践編】モデル比較"
        ],
        "モデル選択": [
          "PPC",
          "AIC",
          "WAIC",
          "モデル選択【実践編】データ理解",
          "モデル選択【実践編】モデリング",
          "モデル選択【実践編】Linear PPC",
          "モデル選択【実践編】モデリング quadratic",
          "モデル選択【実践編】Quadratic PPC",
          "モデル選択【実践編】WAIC"
        ],
        "一般化線形モデル(GLM)": [
          "一般化線形モデル(理論編)",
          "Poisson回帰【実践編】データ理解",
          "Poisson回帰【実践編】モデリング",
          "Poisson回帰【実践編】評価・解釈",
          "Negative Binomial回帰【実践編】データ理解",
          "Negative Binomial回帰【実践編】モデリング",
          "Negative Binomial回帰【実践編】評価・解釈"
        ],
        "階層ベイズ・変分推論": [
          "階層ベイズ【理論編】",
          "階層ベイズ【実践編】データ理解",
          "階層ベイズ【実践編】モデリング",
          "階層ベイズ【実践編】評価・解釈",
          "ADVI【実践編】"
        ],
        "統計モデリング演習": [
          "概要説明",
          "統計モデリング演習1(EDA)",
          "統計モデリング演習2(データの前処理)",
          "統計モデリング演習3(統計モデリング)",
          "統計モデリング演習4(結果の確認)",
          "統計モデリング演習5(予測)"
        ]
      },
      "requirements": [
        "関連講座の【PythonとStanで学ぶ】仕組みが分かるベイズ統計学入門を修了している",
        "統計学の基本的な知識やベイズ統計の基本的な知識が身に付いている",
        "理論的な背景も含めて理解したい場合には大学レベルの数学",
        "Pythonの基本的なスキル",
        "Pandas, Matplotlib, Seabornなどデータサイエンス系のライブラリを使いこなせる"
      ],
      "description": "【ベイズ統計学とは？】\nベイズ統計学とは\"あらゆる事象を確率的にとらえ、データの性質や生成過程に基づいてモデルを設計し、データに基づいて答えを出していく\"学問です。\n\n\nベイズ統計学はその柔軟性から応用範囲が非常に広く、パラメータ推定、統計モデリング、ABテスト、時系列モデル、因果推論など様々な分野に応用されています。またベイズ統計は推論の流れがどのような場合でも同じ手続きを踏むため、一度身に付ければ、非常にシンプルな思考で様々な分析を行う事ができます。また予測の不確実性を出すことができることも特徴の1つです。\n\n\n【ベイズ統計学の難しさ】\n一方で、ベイズ統計には特有の難しさがあります。例えば、機械学習や深層学習と比べると一つ一つ自分の手でモデルを作成する必要がある為、確率分布に関する高度な知識や理解が必要です。これに加えて、ベイズ統計学にまつわる理論は数学的に高度で、抽象的なものも多く、本当に自分が理解できているか雲をつかむような感覚に襲われるかもしれません。またベイズ統計で用いられるMCMCは計算機科学の知識が必要となり、理解するには統計学とはまた異なるバックグラウンドの学問の理解が必要です。このように、ベイズ統計は有用ではあるのですが、入門のハードルが高くまだ世の中一般に広く普及しているとは言えません。\n\n\nこのような現状を打破すべく、過去にベイズ統計やMCMCの原理や仕組みを理解できる講座として、\n【PythonとStanで学ぶ】仕組みが分かるベイズ統計学入門\nを出しました。この講座によりベイズ統計の仕組みや原理などをしっかり理解する事ができます。\n\n\n【本講座について】\n本講座は上記の講座を修了し、更なるステップアップを目指される方向けの実践講座となっています。この講座では理論編と実践編に大きく分かれています。\n理論編\n理論編ではまず、確率統計、ベイズ統計学の復習から入り、理論的な基礎を固めます。そして、ベイズ推論の流れ、統計モデル、線形モデル、一般化線形モデルなどの解説を順に行います。この講座ではMCMCに原理について説明はしませんが、より実用上の観点からMCMCの収束や収束後の事後分布の評価、  MCMC以外の手法(ラプラス近似、変分推論)の紹介、Pros / Consの比較を行います。またモデル選択の為のPPC(事後確率予測チェック)や情報量基準などの評価手法についての解説を行います。\n実践編\n続く実践編では、理論編で解説した内容をPPLを用いて実際に実装していきます。特に、PPL(確率的プログラミング言語)における人気のパッケージとしてPyStanと双璧を成すPyMCを使った実践的なベイズ統計モデリングを学びます。例えば、統計的検定の文脈におけるBayesianABテスト、統計モデルで一般に使われる線形モデル、一般化線形モデル、階層ベイズモデルの実際のモデリングを行います。また、理論編で解説をした、PPCやWAICといった指標の計算も行い、モデル選択も可能となります。また大規模なデータではMCMCが重くなることもあるのでもう1つのパラメータ推定手法としての変分推論も実践していきます。\n\n\n【人事の方/マネージャークラスの方へ】\n本コースは次のような使い方が可能です。\n・社内でレベルの高いAI人材を育成したい\n・手の動く実践的なデータサイエンススキルを社員に身に付けてもらいたい。\n・組織のアナリティクスのケイパビリティを強化したい\n\n\n【本講座を修了する事で得られるスキル】\n・ベイズ統計学の基礎から応用まで含めた体系的な理論知識\n・統計モデリングにおいて実務上必要になってくる判断スキル\n・PyMCによる実践的な統計モデリングのスキル",
      "target_audience": [
        "データサイエンスに興味を持ち、今後、統計モデリングに関わっていきたい方",
        "ベイズ統計学の体系的な知識とPyMCによる実践的なスキルを身に付けたい方"
      ]
    },
    {
      "title": "Aprenda Python do Zero Criando 10 Projetos de IA Generativa",
      "url": "https://www.udemy.com/course/aprenda-python-do-zero-criando-projetos-de-ia-generativa/",
      "bio": "Construa Aplicações Inteligentes com Python, IA Generativa e as Principais APIs do Mercado (OpenAI, DeepSeek)",
      "objectives": [
        "Programar em Python com segurança, clareza e boas práticas",
        "Criar aplicações práticas com modelos de IA Generativa (LLMs)",
        "Integrar e utilizar OpenAI, DeepSeek, HuggingFace e LangChain",
        "Desenvolver interfaces com Streamlit e Gradio",
        "Construir 10 projetos práticos: 5 mini projetos + 5 projetos completos"
      ],
      "course_content": {},
      "requirements": [
        "Conhecimento básico de informática (instalar programas, usar terminal, etc.)",
        "Nenhuma experiência prévia em programação é obrigatória, mas será útil se você já teve algum contato com lógica de programação ou scripts simples",
        "Ter um computador com acesso à internet e permissões para instalar softwares como Python, Node.js, Docker e editores de código"
      ],
      "description": "Este curso foi criado para quem deseja aprender Python do zero e avançar até a construção de aplicações completas com Inteligência Artificial Generativa.\n\n\nCom foco em projetos práticos e integração com modelos modernos como OpenAI, DeepSeek, HuggingFace e LangChain, você desenvolverá habilidades sólidas para atuar com IA, automações e criação de agentes inteligentes.\n\n\nConteúdo Programático\n1. Fundamentos do Python (Do Zero ao Avançado)\nVocê começará aprendendo os conceitos essenciais da linguagem Python, incluindo:\nInstalação do Python e configuração do ambiente\nTipos de dados, variáveis, operadores, listas, tuplas, dicionários e sets\nCondições, laços (for e while), funções e escopo\nList comprehensions, argumentos (*args, **kwargs) e funções lambda\nManipulação de arquivos e entrada de dados\nProgramação funcional, expressões regulares e decorators\nIntrodução à programação assíncrona, metaclasses e type hints\n\n\n2. Projeto: Criação de Mini Aplicações com Python\nDesenvolva mini aplicações para consolidar os conceitos aprendidos, utilizando práticas modernas de programação com Python puro.\n\n\n3. Integração com Modelos de IA via DeepSeek (Local e Groq)\nExplore o uso de modelos de linguagem grandes rodando localmente e via nuvem:\nInstalação e configuração do Ollama com o modelo DeepSeek\nIntegração com o LM Studio\nAcesso à DeepSeek via Groq com Python\nDesenvolvimento de interfaces web para chatbots com Streamlit\nImplementação de memória em conversas com IA\n\n\n4. Integração com OpenAI e Desenvolvimento de Agentes Inteligentes\nAprenda a trabalhar com a API da OpenAI:\nConfiguração de ambiente com a API do ChatGPT\nGeração de texto e imagem, classificação e análise de dados\nUso de Function Calling e Assistants\nCriação de agentes com memória e recuperação de documentos\n\n\n5. Criação de Aplicações com LangChain e Arquitetura RAG\nAprofunde-se na criação de aplicações com LangChain e o conceito de RAG (Retrieval-Augmented Generation):\nUso de Document Loaders, Text Splitting, Embeddings e Vector Stores\nCriação de sistemas que pesquisam, processam e respondem com base em documentos\n\n\n6. Visão Computacional com HuggingFace\nIntegração com modelos gratuitos para aplicações de visão computacional:\nRemoção de fundo de imagens\nDetecção, classificação e descrição de imagens\nGeração de texto a partir de imagem\n\n\n7. Processamento de Linguagem Natural (PLN) com HuggingFace\nAplique modelos de IA em textos, com foco no idioma português:\nAnálise e classificação de sentimentos\nCriação de sistemas de perguntas e respostas (FAQ)\nAnálise de dados em DataFrames\nIntegração com interfaces no Gradio\n\n\n8. Projetos Reais com IA Generativa\nVocê vai criar 5 mini projetos práticos e 5 projetos completos passo a passo, incluindo:\n\n\nMini Projetos:\nChat com interface web usando Streamlit + DeepSeek\nDesenvolvimento de chatbots com OpenAI\nAnálise de dados com Assistants\nConverse com seus documentos com RAG\nRemoção de background de imagens (Visão Computacional)\n\n\nProjetos Completos:\nChatbot Financeiro com Streamlit e OpenAI – Análise de ativos e atendimento inteligente\nAssistente de Voz com OpenAI – Transcrição e geração de voz\nTranscrição de Áudio com OpenAI – Extração de texto de áudios e vídeos\nChatbot Completo com DeepSeek e LangChain – IA conversacional integrada\nChatPDF – Converse com seus Documentos com RAG + Streamlit\n\n\nDestaque-se no mercado e domine a IA Generativa!\n\nInscreva-se no curso !",
      "target_audience": [
        "Iniciantes em programação que desejam aprender Python do zero de forma prática e aplicada",
        "Desenvolvedores júnior ou pleno que querem aplicar IA Generativa em projetos reais",
        "Profissionais de dados, automação ou TI interessados em integrar modelos de IA em suas soluções",
        "Empreendedores e criadores de produtos digitais que buscam aplicar inteligência artificial em suas plataformas",
        "Estudantes de tecnologia que desejam construir um portfólio sólido com projetos reais",
        "Entusiastas de IA e inovação que querem aprender como funcionam as principais ferramentas do ecossistema atual: OpenAI, DeepSeek, LangChain e HuggingFace"
      ]
    },
    {
      "title": "医師が教えるR言語での医療データ分析入門：R言語で作業自動化～エクセルデータの自動処理とパワーポイント作成～",
      "url": "https://www.udemy.com/course/dr_r_automation/",
      "bio": "エクセルファイルのデータを読み込むスキルと、データから定型のパワーポイントプレゼン資料をR言語で生成して、毎日の業務や報告を楽にしよう！",
      "objectives": [
        "R言語によるエクセルデータの取り込み",
        "R言語とRマークダウンを利用したパワーポイントファイルの作成方法",
        "効率的にR言語のスクリプトを書くためのノウハウ",
        "PURRRパッケージの使い方入門"
      ],
      "course_content": {},
      "requirements": [
        "R言語、RStudioの利用経験",
        "「医師が教えるR言語での医療データ分析入門」で解説した内容のうち、インポートとRマークダウンに関する部分の知識"
      ],
      "description": "注：セール対象外のコースとなるため、いつ購入いただいても価格は変わりません\n\n\n本コースは、ある程度R言語とRstudioを触ったことがあるという方向けに、日本国内で一般的に仕事をしているとよく出会う「エクセルファイル」の読み込み方法や、多量の同じ形のエクセルファイルをR言語で効率的に処理する方法を提示します。また、読み込んだデータから、自動的に「パワーポイント」ファイルを生成する方法をお伝えします。\n\n\nこれらのテクニックを組み合わせると、\n毎月大量の報告書（エクセルファイル）をまとめる作業で困っている。\n毎月、数字を置き換えるだけの報告書の作成にものすごく時間がかかって困っている。\n等の問題解決に役立ちます。\n\n\nまた、エクセルファイルやパワーポイントファイルの入出力でけでなく、PURRRという、tidyverseの中では比較的とっつきづらいパッケージの使い方についても踏み込んで解説しているため、Rで反復計算をしている場合に、遅くて困っているなどという方の問題解決のヒントになるかもしれません。\n\n\nそれでは、コースでお会いしましょう！",
      "target_audience": [
        "R言語でいろいろなことをやってみたいという方",
        "データサイエンスに興味をもつ医療職",
        "日々の業務の提携レポート（パワーポイントファイル）を自動出力したいというビジネスマン"
      ]
    },
    {
      "title": "机器学习项目课：从基础到搭建项目",
      "url": "https://www.udemy.com/course/jtgvanky/",
      "bio": "手把手带你搭建一个推荐系统",
      "objectives": [
        "掌握机器学习的核心概念及相关的Python编程技能",
        "理解不同模型类型在技术上的权衡，通常用作解答人工智能、机器学习和算法工程师职位面试中的问题",
        "真正理解机器学习的核心和基础：数据建模，数据清理，过度拟合，交叉验证和性能指标等",
        "掌握建模技术：K-means和逻辑回归等",
        "掌握更复杂的算法：SVM，随机森林和决策树等",
        "掌握Python在机器学习领域的核心工具：Sckit-learn，Numpy和Pandas等",
        "如果您正在求职阶段，完成本课程您将获得一个推荐系统项目，适合电子商务，O2O和许多互联网行业公司的求职"
      ],
      "course_content": {
        "课程设计和结构介绍": [
          "课程设计和结构介绍"
        ],
        "第一模块：理论课": [
          "本节内容安排",
          "课程总体框架",
          "机器学习基本概念：数据和模型（第一节）",
          "机器学习基本概念：数据和模型（第二节）",
          "机器学习基本概念：数据和模型（第三节）",
          "基本模型：逻辑回归（第一节）",
          "基本模型：逻辑回归（第二节）",
          "基本模型：K-均值",
          "性能指标",
          "过拟合和交叉验证",
          "总结",
          "第一模块作业",
          "第一模块作业解析"
        ],
        "第一模块：实战课": [
          "本节代码下载",
          "本节内容安排",
          "Jupyter Notebook安装",
          "环境配置",
          "基本Python操作和Numpy（第一节）",
          "基本Python操作和Numpy（第二节）",
          "Scikit-learn介绍",
          "运行逻辑回归（第一节）",
          "运行逻辑回归（第二节）",
          "数据清洗示例"
        ],
        "第一模块：项目课": [
          "本节代码下载",
          "Python教程介绍",
          "Numpy",
          "Pandas"
        ],
        "第二模块：理论课": [
          "本节内容安排",
          "决策树",
          "决策树的算法",
          "节点拆分",
          "决策树的步骤和总结",
          "权衡偏差和方差（第一节）",
          "权衡偏差和方差（第二节）",
          "权衡偏差和方差（第三节）",
          "随机森林（第一节）",
          "随机森林（第二节）",
          "支持向量机（第一节）",
          "支持向量机（第二节）",
          "支持向量机（第三节）",
          "支持向量机（第四节）",
          "支持向量机（第五节）",
          "第二模块作业",
          "第二模块作业解析"
        ],
        "第二模块：实战课": [
          "本节代码下载",
          "本节内容安排",
          "自助法（第一节）",
          "自助法（第二节）",
          "自助法（第三节）",
          "单节点树（第一节）",
          "单节点树（第二节）",
          "单节点树（第三节）",
          "随机森林（第一节）",
          "随机森林（第二节）",
          "随机森林（第三节）",
          "随机森林（第四节）",
          "支持向量机（第一节）",
          "支持向量机（第二节）",
          "支持向量机（第三节）",
          "支持向量机（第四节）",
          "支持向量机（第五节）"
        ],
        "第二模块：项目课": [
          "本节代码下载",
          "开始搭建推荐系统项目",
          "项目介绍（第一节）",
          "项目介绍（第二节）",
          "项目实现具体细节（第一节）",
          "项目实现具体细节（第二节）",
          "代码框架介绍（main.py）",
          "代码框架介绍（README, Preprocessing）",
          "代码框架介绍（Databaseinterface.py, Webserver.py）",
          "尝试自己进行编程"
        ],
        "第三模块：理论课": [
          "本节内容安排",
          "推荐系统介绍（第一节）",
          "推荐系统介绍（第二节）",
          "几种推荐的方式",
          "推荐系统算法的输入和输出",
          "显式响应和隐式响应",
          "信任、新颖、多样性和商业化",
          "基于内容的过滤（第一节）",
          "基于内容的过滤（第二节）",
          "基于内容的过滤（第三节）",
          "基于用户的协同过滤（第一节）",
          "基于用户的协同过滤（第二节）",
          "基于用户的协同过滤（第三节）",
          "基于商品的协同过滤（第一节）",
          "基于商品的协同过滤（第二节）",
          "矩阵因式分解的协同过滤（第一节）",
          "矩阵因式分解的协同过滤（第二节）",
          "推荐系统的评估"
        ],
        "第三模块：实战课": [
          "本节代码下载",
          "本节内容安排",
          "玩具问题及基本设置（第一节）",
          "玩具问题及基本设置（第二节）",
          "预测（第一节）",
          "预测（第二节）",
          "提升基准模型（第一节）",
          "提升基准模型（第二节）",
          "奇异值分解（第一节）",
          "奇异值分解（第二节）",
          "矩阵因式分解的随机梯度下降",
          "随机梯度下降的优化过程"
        ],
        "第三模块：项目课": [
          "本节代码下载",
          "本节内容安排",
          "Main.py和Webserver.py",
          "RecEngine.py",
          "RecEngine.py、UserAnalyzer.py和Ranker.py",
          "Learners（第一节）",
          "Learners（第二节）",
          "Models（第一节）",
          "Models（第二节）",
          "完善项目代码"
        ]
      },
      "requirements": [
        "至少对一种编程语言有基本了解",
        "具有高中数学基础",
        "最好对Python有基本了解，但不是必需的"
      ],
      "description": "课程介绍\n这是一门项目课。老师会在课程演示编程的全过程，并带你完成一个推荐系统的项目。完成本课程后，你将对机器学习算法的核心概念有全面深刻的理解。本课程旨在帮助同学们从基础计算机科学知识转向机器学习专业。\n\n授课老师会将理论与实战相结合，将机器学习算法的相关理论，以及实现每种算法的编程过程，有机地结合在一起进行教学。此外，老师将演示搭建推荐系统的每一个编程步骤，确保您可以在老师的指导下完成项目。如果您正在求职阶段，还可以将这个项目经验添加到简历中，赢得招聘官的青睐！\n\n这门课是从BitTiger广受欢迎的人工智能直通车课程进行截取的，我们剪辑出了最精华的内容呈现给你。由于原课程是直播授课的形式，讲座中可能会包含少量学生当场的提问和回答。\n---------------------------------------------------------------------\n\n\n为什么我要选择BitTiger？\nBitTiger是来自硅谷的终身学习平台，我们的教学团队有上百名来自世界顶尖科技公司的资深技术专家和教育创新者。在BitTiger的过去三年中，我们已经教学过数千名学生。我们的学生已经在 京东，腾讯，百度，谷歌和Facebook等世界知名公司工作。现在，我们首次尝试视频课程的形式，与世界分享知识。\n---------------------------------------------------------------------\n\n\n为什么我要上这门课？\n机器学习和人工智能正在给我们工作方式带来本质性的改变：通过自动化任务，使预测变得更准确，并能允许在短时间内处理大量数据集。本课程带您走向科技的前沿，通过搭建一个推荐系统的项目，更好地抓住新兴的机会，成为一名优秀的数据科学家、人工智能工程师、机器学习工程师或算法工程师。\n\n首先，老师将详细讲解每种算法的理论基础，以及模型之间的技术权衡，帮助你更好地理解算法模型，攻克较难的面试问题。 其次，课程还将帮助您搭建和实施一个真正的推荐系统。由于推荐系统是电子商务、O2O和其他互联网行业中非常通用的应用，这个项目将为您赢得面试官的青睐！\n---------------------------------------------------------------------\n\n\n谁应该报名这门课？\n这门课对于有计算机科学或者软件工程的相关背景的同学来说，是一门很好的课程，可以帮助您有效地将机器学习添加到现有的技能组合中，并为您申请相关工作做好准备。 如果您正在寻找实用的编程示范和项目搭建，这门课将非常适合您，您可以快速实施自己的算法，并构建所需的项目经验。\n---------------------------------------------------------------------\n\n\n课程的内容安排是什么样的？\n该课程分为三个模块：\n\n\n第1模块 - 机器学习基础知识\n掌握基本的机器学习概念，包括：数据准备，建模，性能指标，过度拟合和交叉验证\n掌握机器学习所需的Python工具，包括：Numpy，Scikit-Learn和Pandas\n学习建模基础知识并部署基本模型，包括：Logistic回归和K-Means\n\n\n第2模块 - 高级机器学习模型+项目开始\n实现更复杂的算法，包括：SVM，随机森林和决策树\n了解决策树模型的细微差别，包括：单节点树和节点拆分\n使用优化器改进模型，包括：bootstrap聚合和偏差变化权衡\n\n\n第3模块 - 推荐系统的优化+项目完成\n掌握推荐系统背后的理论，包括：推荐系统设计，基于内容的过滤和协同过滤\n在老师的带领下建立推荐系统\n熟悉不同的模型间如何协同工作，从而掌握优化推荐系统的准确性的方法。涉及到的模型包括：K近邻模型，聚类模型，相似度模型等\n\n\n每个模块由三节大课组成：\n理论课：老师会介绍算法的理论基础，系统设计和技术权衡\n实战课：教师会在编程时会共享屏幕，展示实现每个算法的具体步骤\n代码课：教师会逐步带领你完成推荐系统的项目\n---------------------------------------------------------------------\n\n\n上完这门课程会获得什么？\n本课程将带你探索当下最流行的机器学习技术，及在真实数据集上的实际应用，并带你完成一个完整的推荐系统的项目。同学们完成课程和项目搭建之后，不仅能真正理解机器学习的核心概念，掌握相关的Python编程技能，以及复杂的算法，还能将机器学习的项目经历添加到简历中，获得面试官的青睐。这门课以课程为基础，专注于在短时间内，帮助已经拥有计算机编程基础经验的同学，获得真正的硬实力。\n---------------------------------------------------------------------\n还在等什么？立即注册，开始您的刷题之旅，掌握软件工程师职业生涯所需的算法技能！\n----------------------------------------------------------------------",
      "target_audience": [
        "对机器学习及其实际应用感兴趣的同学",
        "具有计算机科学基础背景、并希望专注于机器学习的同学",
        "正在准备机器学习相关职位面试的同学",
        "学习过机器学习基础知识、但希望通过真正的行业项目，认识更高级的模型和实际应用的同学",
        "希望可以学会机器学习相关技能、从而转到相关行业的同学"
      ]
    },
    {
      "title": "【한글자막】 Machine Learning 실전 개발 | 8개의 실용 프로젝트",
      "url": "https://www.udemy.com/course/best-ml-8-real-project/",
      "bio": "현실에서 이용하는 데이터 셋을 사용하여 딥러닝과 머신 러닝 모델을 직접 개발하고 8개의 실용 프로젝트를 진행하며 실무 능력을 향상 시킬 수 있는 강의",
      "objectives": [
        "딥 러닝의 현실 용례",
        "머신 러닝의 현실 용례",
        "인공 신경망을 사용하여 자동차 판매량을 예측하는 법",
        "인공 신경망을 사용하여 이미지를 분류하는 법",
        "LE-NET 심층 신경망을 사용하여 교통 표지판을 분류하는 법",
        "전이 학습을 사용하여 CNN 이미지를 분류하는 법",
        "PROPHET 시계열 예측 패키지를 사용하여 범죄를 예측하는 법",
        "PHROPHET 시계열 예측 패키지를 사용하여 시장 상황을 예측하는 법",
        "자연어 처리 모델을 사용하여 리뷰를 분석하는 법",
        "자연어 처리 모델을 사용하여 스팸 필터를 개발하는 법",
        "유저 기반 협업 필터링을 사용하여 추천 시스템을 개발하는 법"
      ],
      "course_content": {},
      "requirements": [
        "기초 딥 러닝과 머신 러닝 지식",
        "인터넷에 연결된 PC"
      ],
      "description": "8개의 실용 프로젝트로 학습하는 머신러닝 실전 개발!\n현실에서 이용되는 데이터셋을 사용해서 실용적인 모델을 직접 개발!\n\n\nMachine Learning 실전 개발 | 8개의 실용 프로젝트를 선택해야 하는 이유\n이 강의의 목적은 수강생들에게 딥 러닝과 머신 러닝에 대한 지식과 핵심을 실용적이면서 쉽고 재미있게 전달하는 것입니다. 이 강의에서 수강생들은 현실에서 이용되는 데이터셋을 사용해서 실용적인 딥 러닝과 머신 러닝 모델을 직접 개발하게 됩니다. 또한 전 강의에 걸쳐 여러 기술을 실용적인 관점에서 다룹니다.\n\n\n이 강의는 딥 러닝과 머신 러닝 모델에 대한 기본적인 이해를 원하는 수강생을 대상으로 이루어졌습니다. 강의를 듣기에 앞서 기초 프로그래밍 지식을 갖출 것이 권고됩니다. 허나 이는 이 수업에서만 다뤄질 것이며, 그렇기에 해당 강의는 아무런 요구 사항이 없으며 기본 프로그래밍 지식을 갖췄다면 누구에게나 열려 있습니다.\n\n\n이 강의를 마치신 수강생들은 딥 러닝과 머신 러닝 모델에 대해 통달할 것이며, 현실에서 마주하는 문제를 해결하기 위해 강의에서 배운 기술을 즉시 적용할 수 있을 겁니다.\n\n\nMachine Learning 실전 개발 | 8개의 실용 프로젝트는 이렇게 진행 됩니다\n딥 러닝 기술을 학습시켜서 이미지 분류 작업을 할 수 있도록 만들기\n최첨단 페이스북 Prophet 시계열 예측 패키지를 사용해 예측 모델을 개발하여 미래 원자재 가격과 같은 미래 사건을 예측하기\n자연어 처리 모델을 개발하여 소비자 리뷰를 분석하고 스팸 메시지를 식별할 수 있게 만들기\n아마존과 넷플릭스에서 이용되는 영화 추천 시스템과 같은 추천 시스템을 개발하기\n\n\nLigengy Team의 한마디!\n한국 수강생 여러분 안녕하세요?\n딥 러닝과 머신 러닝은 현재 가장 인기가 많은 기술 분야입니다! 해당 분야는 기회와 전도유망한 직업이 넘쳐나고 있어요. 머신/딥 러닝 기술은 오늘날 은행업, 헬스케어, 운송과 기술 분야 등에서 널리 이용되고 있습니다.\n\n\n머신 러닝은 컴퓨터가 경험을 통해 학습할 수 있도록 해주는 알고리즘을 다루는 학문입니다. 경험을 통해 (예: 더 많은 훈련용 데이터) 컴퓨터는 끊임없이 성능을 올릴 수 있습니다. 딥 러닝은 다층 신경망 기술을 활용하는 머신 러닝의 하위 분야입니다. 딥 러닝은 사람의 뇌로부터 영감을 받아 생물학적 뉴런의 작동방식을 모방합니다. 계층적인 심층 신경망은 수많은 인공 뉴런들이 층처럼 쌓이면서 연결되어 형성됩니다. 더 많은 숨겨진 레이어가 신경망에 추가될수록 심층 신경망의 “깊이”는 더욱 깊어짐에 따라 훨씬 더 복잡한 비선형 관계를 구현할 수 있게 됩니다. 딥 러닝은 자율주행 자동차, 얼굴인식과 음성인식, 그리고 헬스케어 앱 등에서 폭넓게 이용되고 있습니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n강의에서 만나요!\n- Ligengy Team",
      "target_audience": [
        "데이터 과학을 현실 용례에 적용해 보고 싶은 데이터 과학자",
        "실습 과제를 통해 딥 러닝을 학습하고자 하는 학생 및 모든 분",
        "포트폴리오에 프로젝트를 더 추가하고 싶은 머신 러닝 관련 종사자"
      ]
    },
    {
      "title": "Машинное обучение: из грязи в Kaggle-князи",
      "url": "https://www.udemy.com/course/ittensive-python-machine-learning-zero2hero/",
      "bio": "Регрессия, классификация, ансамбли и глубокие нейросети",
      "objectives": [
        "Процесс и модели машинного обучения",
        "Ансамбли бэггинга, бустинга, стекинга",
        "Обучение с учителем: 3 больших задачи Kaggle-соревнований",
        "Линейная и нелинейная регрессия",
        "Кластеризация и классификация",
        "Регрессия и предсказание данных",
        "Распознавание и сегментация изображений"
      ],
      "course_content": {
        "Часть 1. Процесс машинного обучения": [
          "Задачи машинного обучения",
          "Задачи машинного обучения",
          "Модель и процесс машинного обучения",
          "Что такое ETL",
          "Процесс машинного обучения",
          "Что такое EDA",
          "Подготовка данных",
          "Подготовка данных",
          "Разбиение выборки",
          "Оптимизация гиперпараметров",
          "Латинский квадрат (гиперкуб)",
          "Оптимизация гиперпараметров через Парзеновские деревья",
          "Недообучение и переобучение",
          "Смещение, разброс и ошибка данных",
          "Обучение модели",
          "Использование HDF"
        ],
        "Метрики и модели": [
          "Метод максимального правдоподобия",
          "Метод наименьших квадратов",
          "Метод наименьших квадратов",
          "Аппроксимация пропусков в данных",
          "Аппроксимация данных",
          "Среднеквадратичная ошибка",
          "Метрики и расстояния",
          "Метрики и расстояния"
        ],
        "Часть 2. Практикум: Предсказание энергопотребления зданий": [
          "Процесс ETL",
          "Интерполяция и экстраполяция",
          "Оценка модели",
          "Линейная регрессия",
          "Линейная регрессия по часам"
        ],
        "Практикум: Оптимизация памяти и обогащение данных": [
          "Оптимизация потребления памяти",
          "EDA: исследование зависимостей",
          "Заполнение пропусков в данных",
          "Параметрическая модель энергопотребления"
        ],
        "Модели линейной регрессии": [
          "Линейная регрессия и L1/L2-регуляризация",
          "Изотоническая регрессия",
          "Линейная регрессия",
          "BIC и AIC",
          "Полиномиальная регрессия",
          "Линеаризация регрессии",
          "Нелинейная регрессия"
        ],
        "Практикум: Конкурентные модели регрессии": [
          "Обогащение данных",
          "Иерархия моделей",
          "Оптимизация регрессии",
          "Конкурентные модели регрессии"
        ],
        "Практикум: Ансамбль линейной регрессии": [
          "Экспорт и импорт данных",
          "Ансамбль регрессионных моделей",
          "Расчет результатов",
          "Рассчитать данные по энергопотреблению"
        ],
        "Часть 3. Метрики и модели классификации": [
          "Точность и полнота",
          "F-мера",
          "ROC AUC и Gini",
          "Оценка Каппа Коэна",
          "Взвешенная квадратичная Каппа",
          "Логистическая функция потерь",
          "Метод ближайших соседей"
        ],
        "Практикум: Задача страхового скоринга": [
          "Страховой скоринг",
          "F1 и Каппа оценки классификации",
          "Метод ближайших соседей",
          "kNN скоринг"
        ],
        "Простые модели классификации": [
          "Наивный Байес",
          "Логистическая регрессия",
          "Дерево принятия решения",
          "Опорные векторы"
        ]
      },
      "requirements": [
        "Основы машинного обучения",
        "Основы математической статистики",
        "Продвинутый Python"
      ],
      "description": "Внимание: для доступа к курсам ITtensive на Udemy напишите, пожалуйста, на support@ittensive.com с названием курса или группы курсов, которые хотите пройти.\n\n\nБольшой практический курс по всем аспектам машинного обучения на Python в решении задач соревнования Kaggle. Курс состоит из 4 больших частей:\nВведение в машинное обучение\nПоследовательно пройдем все этапы работы с данными: от видов задач и их постановки до работы с моделями машинного обучения для минимизации предсказательной ошибки. Дополнительно рассмотрим фундаментальные основы построения моделей машинного обучения, базовые метрики и наиболее простые модели - линейную и логистическую регрессии.\nРегрессия и предсказание данных\nРассмотрим базовые линейные модели и все практические аспекты применения линейной регрессии для предсказания числовых показателей энергопотребления ASHRAE.\nОсобенности процесса анализа данных (ETL): загрузка, очистка, объединение наборов данных с pandas.\nПроведение исследовательского анализа данных для поиска зависимостей: EDA.\nИспользование sklearn для линейной регрессии.\nИнтерполяция и экстраполяция данных.\nРасчет метрики качества RMSLE для моделей линейной регрессии.\nОптимизация линейной регрессии: выбор наилучших параметров и гиперпараметров.\nОптимизация потребления памяти при работе с большими данными.\nЗапасные модели линейной регрессии.\nАнсамбли линейной регрессии для уточнения предсказания.\nЭкспорт и импорт данных, включая промежуточные.\nКлассификация и ансамбли\nРазберем метрики и модели классификации, а затем отработаем прикладные подходы к классификации данных с помощью моделей и ансамблей машинного обучения для страхового скоринга Prudential.\nМетрики классификации: точность, полнота, F1, квадратичная каппа и матрица неточностей.\nОчистка данных и оптимизация потребления памяти.\nКластеризация данных и метод ближайших соседей.\nПростая и иерархическая логистическая регрессия.\nМетод ближайших соседей и поиск оптимальной модели.\nМетод опорных векторов: SVM.\nДерево принятия решения и случайный лес (бэггинг).\nXGBoost и градиентный бустинг.\nLightGBM и CatBoost\nАнсамбль стекинга для голосования и выбора лучшего результата.\nНейросети и глубокое обучение\nРазберем сегментацию и классификацию изображений облаков с помощью сверточных, пирамидальных, остаточных и полносвязных нейронных сетей.\nМетрики точности: оценка F1 и коэффициент Дайса.\nОчистка данных и обработка изображений.\nЗагрузка и сохранение моделей и данных в HDF5.\nДвухслойный и многослойный перцептрон.\nНейросети со сверточными слоями и слоями подвыборки.\nФункции активации, инициализация и оптимизаторы нейросетей.\nПреобразование и дополнение (аугментация) бинарных данных.\nLeNet, AlexNet, GoogLeNet.\nVGG, Inception, ResNet, DenseNet.\nСегментация изображений с MobileNet, Unet, PSPNet и FPN.\nАнсамбль нейросетей.",
      "target_audience": [
        "Аналитики Python, изучающие машинное обучение",
        "Программисты больших данных",
        "Исследователи больших данных"
      ]
    },
    {
      "title": "Segmentação de Imagens com Python de A a Z",
      "url": "https://www.udemy.com/course/segmentacao-imagens-python-a-z/",
      "bio": "Tudo o que você precisa saber sobre Segmentação de Imagens e Vídeos! Desde técnicas básicas até arquiteturas modernas!",
      "objectives": [
        "Entenda a intuição básica sobre os principais algoritmos de segmentação de imagens, tanto os mais básicos quanto os mais avançados",
        "Implemente segmentação utilizando algoritmos básicos de processamento de imagens, como: limiarização, contornos, bordas, regiões, clusters, watershed e cores",
        "Implemente segmentação em imagens e vídeos utilizando arquiteturas modernas, como por exemplo: Mask R-CNN, U-Net e DeepLab",
        "Aplique segmentação de imagens utilizando as principais abordagens, como por exemplo: segmentação de instância, segmentação semântica e segmentação panóptica",
        "Utilize imagens de diversos cenários naturais do dia-a-dia, além de imagens microscópica e médicas",
        "Melhore a precisão dos resultados utilizando o PointRend",
        "Utilize data augmentation para aumentar a quantidade de imagens em bases de dados pequenas",
        "Realize o treinamento de uma rede neural para segmentar objetos personalizados"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Visão Computacional",
          "Recursos para download"
        ],
        "Segmentação com abordagens clássicas": [
          "Introdução",
          "O que é segmentação",
          "Técnicas e tipos de segmentação",
          "Imagens e pixels",
          "Limiarização - intuição",
          "Importação das bibliotecas",
          "Limiarização - implementação",
          "Tipos de limiarização - intuição",
          "Tipos de limiarização - implementação",
          "Tomografia computadorizada",
          "EXERCÍCIO - imagem infravermelha e separação de fundo",
          "Solução para o exercício 1",
          "Solução para o exercício 2",
          "Método do Otsu - intuição",
          "Método de Otsu - implementação 1",
          "Método de Otsu - implementação 2",
          "Limiarização adaptativa - intuição",
          "Limiarização adaptativa - implementação",
          "Limiarização adaptativa gaussiana - intuição",
          "Limiarização adaptativa gaussiana - implementação",
          "Operações morfológicas - intuição",
          "Segmentação com contornos",
          "Segmentação baseada em bordas - intuição",
          "Operador Sobel - intuição",
          "Operador Sobel - implementação",
          "Canny Edge - intuição",
          "Canny Edge - implementação",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Fechamento e detecção de contornos",
          "Mascaramento de imagen - intuição",
          "Mascaramento de imagem - implementação",
          "Segmentação baseada em região - intuição",
          "Segmentação baseada em região - implementação 1",
          "Segmentação baseada em região - implementação 2",
          "Segmentação baseada em região - implementação 3",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Segmentação baseada em clusters - intuição",
          "Segmentação baseada em clusters - implementação 1",
          "Segmentação baseada em clusters - implementação 2",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Segmentação com watershed - intuição",
          "Segmentação com watershed - implementação 1",
          "Segmentação com watershed - implementação 2",
          "Segmentação com watershed - implementação 3",
          "Segmentação com watershed - implementação 4",
          "Segmentação com watershed - implementação 5",
          "Sobreposição e numeração de segmentos",
          "Segmentação baseada em cores - intuição",
          "Segmentação baseada em cores - implementação 1",
          "Segmentação baseada em cores - implementação 2",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Segmentação baseada em cores - implementação 3"
        ],
        "Segmentação de instâncias com Mask RCNN": [
          "Introdução",
          "Mask R-CNN - intuição",
          "Aviso sobre atualização no Colab",
          "Modelo pré-treinado 1",
          "Modelo pré-treinado 2",
          "Modelo pré-treinado 3",
          "Modelo pré-treinado 4",
          "Modelo pré-treinado 5",
          "Modelo pré-treinado 6",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Contagem de objetos",
          "Treinamento personalizado - balões 1",
          "Treinamento personalizado - balões 2",
          "Treinamento personalizado - balões 3",
          "Treinamento personalizado - balões 4",
          "Treinamento personalizado - balões 5",
          "Treinamento personalizado - balões 6",
          "Treinamento personalizado - balões 7",
          "Treinamento personalizado - balões 8",
          "Treinamento personalizado - balões 9",
          "Passos para treinamento com imagens personalizadas",
          "Segmentação em vídeos 1",
          "Segmentação em vídeos 2",
          "Segmentação em vídeos 3",
          "Segmentação em vídeos 4",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Melhorando a precisão com PointRend 1",
          "Melhorando a precisão com PointRend 2",
          "Melhorando a precisão com PointRend 3",
          "Melhorando a precisão com PointRend 4",
          "EXERCÍCIO",
          "Solução para o exercício"
        ],
        "Segmentação semântica": [
          "Introdução",
          "U-NET - intuição",
          "Imagens microscópicas 1",
          "Imagens microscópicas 2",
          "Imagens microscópicas 3",
          "Imagens microscópicas 4",
          "Imagens microscópicas 5",
          "Imagens microscópicas 6",
          "Imagens microscópicas 7",
          "Métricas para avaliação",
          "Imagens microscópicas 8",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Imagens microscópicas 9",
          "Imagens médicas 1",
          "Imagens médicas 2 - data augmentation",
          "Imagens médicas 3 - data augmentation",
          "Imagens médicas 4 - data augmentation",
          "Imagens médicas 5",
          "Imagens médicas 6",
          "Imagens médicas 7",
          "Imagens médicas 8",
          "Imagens médicas 9",
          "EXERCÍCIO",
          "Solução para o exercício",
          "DeepLab - intuição",
          "Segmentação com DeepLab 1",
          "Segmentação com DeepLab 2",
          "Segmentação com DeepLab 3",
          "Segmentação com DeepLab 4",
          "Segmentação com DeepLab 5"
        ],
        "Segmentação panóptica": [
          "Introdução",
          "Segmentação panóptica - intuição",
          "Segmentação panóptica - implementação 1",
          "Segmentação panóptica - implementação 2",
          "Segmentação panóptica - implementação 3",
          "Segmentação panóptica - implementação 4",
          "Segmentação panóptica - implementação 5"
        ],
        "ANEXO 1 - Redes neurais artificiais": [
          "Perceptron de uma camada",
          "Redes multicamada - função soma e função de avaliação",
          "Redes multicamada - cálculo do erro",
          "Descida do gradiente",
          "Cálculo do parâmetro delta",
          "Ajustes dos pesos com backpropagation",
          "Bias, erro, descida do gradiente estocástica e mais parâmetros"
        ],
        "ANEXO 2 - Redes neurais convolucionais": [
          "Introdução a redes neurais convolucionais 1",
          "Introdução a redes neurais convolucionais 2",
          "Etapa 1 - operador de convolução (introdução)",
          "Etapa 1 - operador de convolução (cálculos)",
          "Etapa 2 - pooling",
          "Etapa 3 - flattening",
          "Etapa 4 - rede neural densa"
        ],
        "ANEXO 3 - Autoencoders": [
          "Introdução a autoencoders",
          "Tipos de autoencoders"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação",
        "Programação básica em Python"
      ],
      "description": "A Segmentação de Imagens é uma sub-área da Visão Computacional que se refere ao processo de separar e/ou extrair informações úteis de imagens ou vídeos para facilitar sua posterior análise. Existem várias aplicações práticas e comerciais que são desenvolvidas utilizando essas técnicas, como por exemplo: carros autônomos detectam e identificam os objetos na rua (pedestres, semáforos, veículos) para gerar a próxima instrução, médicos detectam tumores graves e células cancerígenas rapidamente, indústrias conseguem identificar peças defeituosas antes de montar um eletrônico, cientistas podem identificam áreas de desmatamento, dentre várias outras aplicações. Os profissionais de visão computacional podem ter salários similares aos das outras áreas de Machine Learning, iniciando em R$ 5.000 mensais numa posição inicial e chegando até R$ 15.000 numa posição sênior.\nPara levar você até essa área, neste curso você terá uma visão principalmente prática sobre as principais e mais modernas técnicas de segmentação de imagens! Este curso é de A à Z por apresentar desde conceitos mais básicos até técnicas mais modernas e avançadas, de modo que ao final você terá todas as ferramentas necessárias para construir soluções de segmentação de imagens que podem ser aplicadas em problemas reais! O curso está dividido em quatro partes que abordam tecnologias diferentes de segmentação de imagens. Na parte 1 você aprenderá os algoritmos mais básicos que utilizam recursos da área de processamento digital de imagens, enquanto que nas partes 2, 3 e 4 você será introduzido à arquiteturas modernas de Deep Learning que apresentam os melhores resultados!\nVeja abaixo alguns dos projetos/tópicos que serão implementados passo a passo:\n\nAlgoritmos básicos de processamento digital de imagens, como por exemplo: limiarização simples, limiarização adaptativa, método de Otsu, segmentação baseada em bordas e contornos, operador de Sobel, Canny Edge, segmentação baseada em região e clusters, segmentação com watershed e segmentação por cores utilizando RGB e HSV\nSegmentação de imagens e vídeos contendo cenas do cotidiano, além de imagens microscópicas e médicas\nSegmentação utilizando as modernas arquitetura Mask R-CNN, U-Net, DeepLab e RETR da área de Deep Learning (Aprendizagem Profunda)\nMelhoria da precisão dos algoritmos utilizando PointRend\nTreinamento de uma rede neural convolucional para detecção e segmentação de objetos personalizados\nUso de data augmentation para aumentar a quantidade de imagens em bases de dados pequenas\nEntenda as diferenças na teoria e na prática dos tipos de segmentação: instância, semântica e panóptica\nCada tipo de problema requer técnicas diferentes para sua solução, portanto, conhecendo a maior parte dos algoritmos de segmentação você saberá quais técnicas utilizar nos mais variados tipos de cenários! Durante o curso, vamos utilizar a linguagem de programação Python e o Google Colab para que você aproveite o curso da melhor maneira possível! São mais de 150 aulas e mais de 20 horas de vídeos!",
      "target_audience": [
        "Pessoas interessadas em Visão Computacional e Segmentação de Imagens e Vídeos",
        "Alunos de graduação e pós-graduação que estão cursando disciplinas sobre Visão Computacional, Inteligência Artificial, Processamento Digital de Imagens ou Computação Gráfica",
        "Pessoas que querem implementar seus próprios projetos utilizando técnicas de Segmentação de Imagens",
        "Cientistas de Dados que queiram aumentar o seu portfólio de projetos"
      ]
    },
    {
      "title": "Control de Avance de proyectos de construcción con Power BI",
      "url": "https://www.udemy.com/course/construction-analytics-control-de-avance-con-power-bi/",
      "bio": "Aprende a crear un modelo dinámico de información para el seguimiento y control de avance de obras civiles con Power BI",
      "objectives": [
        "A crear un modelo analítico que permite realizar seguimiento y control de avance de proyecto de construcción.",
        "Utilizar el Análisis de Datos para contribuir con la gestión de proyectos de construcción.",
        "A medir el avance de proyectos en general.",
        "A crear un flujo de datos dinámicos entre Microsoft Project - Excel - Power Query - Power BI.",
        "A aplicar Business Intelligence para seguimiento y control de avance de obra.",
        "Power Query y Power BI al máximo."
      ],
      "course_content": {
        "Introducción": [
          "Presentación General",
          "Filosofía del curso",
          "Los cursos online",
          "¡No califiques el curso antes de tiempo!"
        ],
        "Microsoft Project como fuente de datos": [
          "Cronograma del proyecto en project",
          "Plantilla de exportación de datos de avance",
          "Plantilla de exportación de datos del proyecto global"
        ],
        "Conexión con la fuente de datos": [
          "Conexión con la fuente de datos usando Power Query"
        ],
        "Transformación y creación del modelo de datos con Power Query": [
          "Transformación de las tablas de avance de proyecto",
          "Combinación de las tablas del modelo de datos",
          "Transformaciones de datos en la nueva tabla",
          "Transformaciones finales en el modelo resultante",
          "Prueba de funcionalidad del modelo de datos"
        ],
        "Cálculos DAX para el avance del proyecto con Power BI": [
          "Cálculo del Avance General del proyecto",
          "Cálculo del Avance por Especialidad de Obra",
          "Cálculo de Días del proyecto",
          "Cálculo de la Variación del avance entre actualizaciones",
          "Conteo de actividades del proyecto",
          "Conteo de actividades por estado"
        ],
        "Visualización analítica del avance del proyecto con Power BI": [
          "Formato del fondo del panel de gráficos",
          "Colocación de Tarjetas de datos Globales",
          "Gráficos de Avance General y variación del Avance",
          "Gráfico de la Curva S de avance de proyecto",
          "Gráfico avance por Especialidades de Obra",
          "Título dinámico del Dashboard",
          "Prueba de funcionalidad de actualización del informe",
          "Hoja Detalle por actividades",
          "Publicado y compartido del Informe analítico de avance de proyecto"
        ],
        "Resumen del Informe": [
          "Resumen del Informe"
        ]
      },
      "requirements": [
        "Conocimientos previos de Microsoft Project.",
        "Un poco de Planificación, seguimiento y control de Obras civiles.",
        "Viene bien tener experiencia en Power BI."
      ],
      "description": "El sector de la construcción Civil no escapa de la digitalización de la gestión empresarial, el Building Information Modeling conocido como BIM es una realidad en los proyectos de construcción, sin embargo, toda la planificación y modelado se vuelven nada si no es acompañada por un correcto proceso de seguimiento y control de avance, que se integre con BIM y que acompañe la metodología LEAN Construcction y para resolver este requerimiento está el análisis de datos y el Business Intelligence, para ello disponemos de plataformas analíticas como el Microsoft Power BI.\nEn este curso verás como de forma dinámica y 100% funcional y aplicable a los proyectos BIM y LEAN Construction y con las herramientas que utilizan a diario como Microsoft Project y Excel, que combinadas con los poderosos Power Query y Power BI se logra desarrollar un informe analítico que facilita el seguimiento y control del avance de obra.\nEste informe es gráfico, dinámico, compartido, objetivo y lo más importante de todo automático y así la información es manejada por todos los involucrados en un proyecto de construcción civil.\nCon lo que aprenderás en este curso podrás implementar en proyectos en general, dinámicas de seguimiento de avance usando los datos y herramientas de la era de la información.",
      "target_audience": [
        "Ingenieros Civiles.",
        "Analistas de Datos.",
        "Usuarios de Building Information Modeling (BIM).",
        "Consultores y Analistas de Inteligencia de Negocios."
      ]
    },
    {
      "title": "Bootcamp Avanzado MLOps |Machine Learning Operation Hands-on",
      "url": "https://www.udemy.com/course/bootcamp-de-mlops-machine-learning-operations-hands-on/",
      "bio": "Curso avanzado y aplicado de MLOps con MLFlow, Scikit-learn, CI/CD, Azure, FastAPI, Gradio, SHAP, Docker, DVC, Flask",
      "objectives": [
        "Conceptos básicos y fundamentos de MLOps",
        "Niveles de implantación del MLOps",
        "Seguimiento de experimentos y registro de modelos con MLFlow.",
        "Automatización del ciclo de vida del modelo con Pycaret",
        "Interpretabilidad de modelos y deriva de datos.",
        "Docker",
        "Desarrollo de APIs con FastAPI",
        "Desarrollo de una aplicaciones web con Gradio y Flask",
        "Despliegue en Cloud de modelos",
        "Azure"
      ],
      "course_content": {
        "Introducción al curso": [
          "Introducción al curso",
          "Como aprovechar al máximo el curso",
          "Material del curso"
        ],
        "Retos y evolución del Machine Learning": [
          "Introducción al Machine Learning",
          "Beneficios del Machine Learning",
          "Fundamentos del MLOps",
          "Fundamentos de DevOps y DataOps"
        ],
        "Fundamentos de MLOps": [
          "Problemas que resuelve el MLOps",
          "Componentes del MLOps",
          "Caja de herramientas de MLOps"
        ],
        "Etapas del MLOps": [
          "Etapas del MLOps"
        ],
        "Instalación de herramientas y librerías": [
          "Como instalar librerías y preparar el entorno",
          "Fundamentos de Jupyter Notebook",
          "Instalación de Docker y Ubuntu"
        ],
        "Productivización y estructuración de proyectos de ML": [
          "Cookiecutter para la gestión de la estructura del modelo de Machine Learning",
          "Librerías y herramientas para la gestión de principio a fin del proyecto",
          "Poetry para la gestión de dependencias",
          "Makefile para ejecución automatizada de tareas",
          "Hydra para gestionar archivos de configuración YAML",
          "Hydra aplicado a un proyecto de Machine Learning",
          "Verificar y corregir el código automáticamente antes del Commit en Git",
          "Corrección con Black y Flake8 en el pre-commit",
          "Corrección con Isort e Iterrogate en el Pre-commit e integración con Giit",
          "Generar documentación automáticamente del proyecto de ML"
        ],
        "Fase 1 de MLOps: Diseño de la solución": [
          "Diseño e implementación de Volere"
        ],
        "Fase 2 de MLOps: Automatización del ciclo del modelo de ML": [
          "Fundamentos del AutoML",
          "Desarrollo de un modelo de principio a fin con Pycaret",
          "EDA y Preprocesamiento avanzado con Pycaret",
          "Desarrollo de modelos avanzados (XGBoost, CatBoost, LightGBM) con Pycaret",
          "Despliegue en producción con Pycaret"
        ],
        "Fase 2 de MLOps: Registro y versionado del modelo con MLFlow": [
          "Registro y versionado de modelos con MLFlow",
          "Registro de un modelo de Scikit-Learn con MLFlow",
          "Registro del modelo de Pycaret con MLFlow"
        ],
        "Versionado de datos con DVC": [
          "1. Introducción a DVC",
          "Comandos y proceso de DVC",
          "Laboratorio práctico de DVC",
          "Pipelines de DVC"
        ]
      },
      "requirements": [
        "Conocimientos básicos de Python y de Machine Learning"
      ],
      "description": "Si estás buscando un curso práctico, avanzado y aplicado para aprender las tecnologías de MLOps, has venido al lugar correcto.\nSegún una encuesta de Algorithmia, el 85% de los proyectos de Machine Learning no llegan a producción. Además, el mercado de MLOps no para de crecer. Se estimó en $23,2 mil millones para el 2019 y se proyecta que alcance los $126 mil millones para 2025. Por ello, el formarte en MLOps te dará numerosas oportunidades laborales y profesionales.\nEste curso está diseñado para aprender todo lo relacionado con MLOps, desde el desarrollo, registro y versionado de modelos hasta la monitorización, CI/CD, despliegue en cloud, productivización, model serving y puesta en producción mediante APIs y aplicaciones web.\nCon la formación teórica, las guías de estudio descargables, los ejercicios prácticos y los laboratorios aplicados a casos de uso reales este es el único curso que necesitarás para aprender a implementar un ciclo completo de MLOps.\nPara ello, te guiaremos a través de las competencias de MLOps, compartiendo explicaciones claras y útiles consejos profesionales.\n¿Qué incluye el curso?\nConceptos básicos y fundamentos de MLOps. Desafíos en la gestión tradicional del ciclo de vida del ML. Cómo MLOps aborda los problemas de subir a producción un modelo\nNiveles de implantación del MLOps\nToolbox completo de MLOps. Aprenderemos algunas de las herramientas más novedosas de MLOps.\nInstalación de herramientas.\nSeguimiento de experimentos y registro de modelos con MLFlow.\nAutomatización del ciclo de vida del modelo con Pycaret. Pycaret permite automatizar y facilitar gran parte del ciclo de MLOps, como el versionado de modelos, entrenamiento, evaluación y despliegue de modelos.\nInterpretabilidad de modelos y deriva de datos.\nVersionado de modelos\nDocker. Aprenderemos a encapsular y distribuir fácilmente una aplicación de Machine Learning a través de un contenedor de Docker.\nPuesta en producción de modelos.\nDesarrollo de APIs con FastAPI. Aprenderemos a desarrollar una API para que podamos integrar nuestro modelo de ML en herramientas o software empresariales.\nDesarrollo de una aplicaciones web con Gradio. Aprenderemos a desarrollar una aplicación web para que cualquier usuario de negocio pueda hacer uso del modelo.\nDesarrollo de aplicación con Flask y despliegue en cloud mediante containers. Aprenderemos a desarrollar una aplicación de ML con Flask y HTML, a sitribuirla a traves de un container de Docker y a ponerla en producción en Azure.\nDespliegue en el Cloud de Azure de modelos. Aprenderemos a desplegar modelos en el cloud a través de imágenes de Docker, Blob Storage o Azure Machine Learning.\n\n\n\n\nÚnete hoy y obtén acceso inmediato y de por vida a:\n• Guía de formación de MLOps (e-book en PDF)\n• Archivos, códigos y recursos descargables\n• Laboratorios aplicados a casos de uso reales\n• Ejercicios prácticos y cuestionarios\n• Recursos como: Cheatsheets y resúmenes\n• Soporte experto 1 a 1\n• Foro de preguntas y respuestas del curso\n• 30 días de garantía de devolución de dinero\n\n\nSi estás listo para mejorar sus habilidades de MLOps, aumentar tus oportunidades laborales y convertirte en un profesional en ciencia de datos, te esperamos.",
      "target_audience": [
        "Ingenieros de ML y científicos de datos interesados en ML Ops",
        "Profesionales de ML que desean implementar modelos en producción",
        "Cualquier persona interesada en desarrollar APIs en FastAPI o Flask",
        "Cualquiera que quiera aprender los conceptos básicos de Docker, Azure o MLFlow"
      ]
    },
    {
      "title": "Maîtriser les LLMs avec LangChain (et Python)",
      "url": "https://www.udemy.com/course/bootcamp-langchain-avec-python/",
      "bio": "Apprendre LangChain en construisant rapidement des applications d'IA générative (avec Python, OpenAI et Mistral)",
      "objectives": [
        "Apprendre à créer des applications d'IA générative avancées en utilisant le framework LangChain et les modèles de pointe de HuggingFace.",
        "Développer des compétences pour créer des applications de chatbot personnalisé avec une mémoire avec LangChain et LangGraph.",
        "Développer des pipelines RAG (Retrieval-Augmented Generation) pour améliorer les performances et la précision des modèles génératifs LLMs.",
        "Apprendre à incorporer de manière transparente les modèles pré-entraînés de HuggingFace dans les applications Langchain."
      ],
      "course_content": {
        "Introduction aux LLMs et à Langchain": [
          "Qu'est-ce que l'IA Générative et les LLMs ?",
          "Qu'est-ce que LangChain ?"
        ],
        "Les composants clés de Langchain": [
          "COURS COMPLET PYTHON (30 JOURS)",
          "Notice de téléchargement du contenu du cours (Code Python + Datasets)",
          "Google Colab + Avertissements",
          "Modèles : Comment connecter des modèles LLM à LangChain ?",
          "Chaînes de LangChain",
          "Théorie - Que sont les agents, les tools et la mémoire ?"
        ],
        "LangChain - Construire un agent IA de Chatbot (de A à Z) avec LangGraph": [
          "Introduction",
          "Définition des tools (outils)",
          "Utilisation des modèles de langage (LLMs)",
          "Création et exécution de l'Agent IA",
          "Diffusion des messages",
          "Mise en mémoire avec LangGraph",
          "Chatbot final (assemblage bout à bout des précédentes étapes)"
        ],
        "RAG avec LangChain": [
          "Introduction RAG (Retrieval Augmented Generation)",
          "Retrieval Augmented",
          "Generation"
        ],
        "Projet Questions-Réponses avec un fichier PDF": [
          "Charger un PDF de 80 pages",
          "Réponses aux questions avec RAG (avec utilisation de Hugging Face)"
        ],
        "BONUS": [
          "Inscription Newsletter Mon Shot Data (pour les plus curieux)"
        ]
      },
      "requirements": [
        "Familiarité avec Python. Ce cours ne couvre pas les bases de Python mais utilise le langage Python."
      ],
      "description": "Dans ce cours, tu plongeras dans le monde de l'IA générative avec les LLMs (Large Language Models), en explorant le potentiel de la combinaison de LangChain avec Python.\n\n\nCe cours complet est conçu pour t'apprendre à exploiter RAPIDEMENT la puissance de la bibliothèque LangChain pour des applications LLMs. Il te permettra d'acquérir les compétences et les connaissances nécessaires pour développer des solutions LLM de pointe pour une gamme variée de sujets.\n\n\nLangchain est un framework pour faire évoluer les LLMs comme ChatGPT avec des sources de données externes et des APIs pour améliorer les capacités.\nLes composants clés de LangChain, tels que les chaînes, les modèles, les outils et les agents seront présentés, ainsi que la manière de les utiliser pour développer des solutions NLP robustes.\nLe concept de RAG (Retrieval-Augmented Generation) sera exploré, y compris les processus de stockage et de récupération de l'information. Tu apprendras à mettre en œuvre des magasins vectoriels et à comprendre l'importance des embeddings et la manière de les utiliser efficacement. Nous montrerons également comment utiliser RAG pour interagir avec des documents PDF et des pages web.\nEn outre, tu auras l'occasion d'explorer l'intégration d'agents et d'outils, comme l'utilisation de LLM pour effectuer des recherches sur le web et récupérer des informations récentes.\n\n\nEn guise de projet, tu apprendras à créer un chatbot personnalisé qui cherche sur le web et dotée d'une mémoire pour les questions-réponses. De plus, tu appliqueras le RAG pour lire et questionner n'importe quel type de PDFs.\n\n\nTu apprendras :\nCe qu'est LangChain et comment il élargit ce que les assistants d'IA peuvent exploiter\nIntégrer LangChain à OpenAi, MistralAI et Hugging Face de manière transparente\nL'utilisation de templates de prompt pour standardiser les requêtes\nConnecter des sources de données telles que des documents, des embeddings, des bases de données vectorielles\nGérer le contexte et la mémoire avec les embeddings\nOutils et agents pour renforcer OpenAI, par exemple l'exécution de code\nUtilisation pratique de ChromaDB, la base de données vectorielle de LangChain\nGénération de texte en continu avec LangChain\nÀ la fin de ce module, tu seras équipé pour commencer à construire des applications Langchain qui connectent OpenAI ou d'autres LLMs à des données externes précieuses pour des réponses plus pertinentes.\n\n\nAvertissements :\nJ'utilise à de nombreuses reprises l'API de OpenAI qui n'est pas gratuite, mais je propose et mets en place également différentes solutions gratuites (API MistralAI et modèles LLMs open-source sur Hugging Face)",
      "target_audience": [
        "Les débutants qui souhaitent entamer une carrière dans l'IA - aucune expérience préalable n'est nécessaire pour profiter des opportunités d'emploi croissantes dans le domaine de l'IA.",
        "Les étudiants désireux d'acquérir les compétences pratiques en matière d'IA que les employeurs recherchent pour se démarquer.",
        "Les codeurs qui souhaitent assurer l'avenir de leur carrière en se lançant dans le développement d'une IA de pointe.",
        "Les cadres et les dirigeants qui souhaitent exploiter l'IA pour dynamiser leur entreprise.",
        "Les professionnels du Machine Learning et de la Data Science qui souhaitent évoluer vers des rôles spécialisés dans l'IA générative et les réseaux de neurones.",
        "Les développeurs souhaitant créer des applications réelles basées sur l'IA."
      ]
    },
    {
      "title": "Künstliche Intelligenz - einfach erklärt für Einsteiger",
      "url": "https://www.udemy.com/course/ki-kuenstliche-intelligenz-ai-artificial-intelligence/",
      "bio": "Grundlagen zu Agenten- und Multiagentensystemen, Neuronalen Netzen, Deep Learning, Machine Learning & Computer Vision",
      "objectives": [
        "Sie lernen die Strukturen und Aufbau moderner Systeme der künstlichen Intelligenz (KI/AI) kennen und verstehen.",
        "Sie lernen eine starke und schwache KI zu unterscheiden.",
        "Sie lernen, was \"Deep Learning\" ist.",
        "Sie lernen, was \"Machine Learning\" ist.",
        "Was ist die Struktur eines Problems.",
        "Sie lernen etwas über Vorwärts- und Rückwärtsverkettungen.",
        "Erfahren Sie mehr über Wahrscheinlichkeiten in Expertensystemen.",
        "Sie lernen das menschliche Neuron kennen.",
        "Welche Schichten in Deep-Learning-Netzen gibt es.",
        "Sie lernen maschinelles Sehen / Computer Vision kennen und verstehen."
      ],
      "course_content": {
        "Einführung": [
          "Einführung",
          "Quiz-Fragen",
          "Downloads"
        ],
        "Geschichte der KI": [
          "Geschichtlicher Hintergrund",
          "Quiz-Fragen",
          "Downloads"
        ],
        "Der allgemeine Problemlöser": [
          "Der allgemeine Problemlöser",
          "Quiz-Fragen",
          "Downloads"
        ],
        "Expertensysteme": [
          "Expertensysteme",
          "Quiz-Fragen",
          "Downloads"
        ],
        "Neuronale Netze, Agenten- und Multiagentensysteme": [
          "Neuronale Netze",
          "Quiz-Fragen",
          "Downloads"
        ],
        "Maschinelles lernen, Deep Learning, Computer Vision": [
          "Maschinelles lernen, Deep Learning, Computer Vision",
          "Quiz-Fragen",
          "Downloads"
        ],
        "BONUS: Hörbuch Download": [
          "Download"
        ]
      },
      "requirements": [
        "Keine Vorraussetzungen auf dem Gebiet der KI/AI nötig. Es wird alles verständlich im Detail erklärt."
      ],
      "description": "Dieser Videokurs über künstliche Intelligenz richtet sich an Einsteiger und ist so aufgebaut, dass Ihnen die Grundlagen im Rahmen der geschichtlichen Entwicklung der KI vermittelt werden. Aus diesem Grund beginnt unsere Reise mit dem Punkt \"Einführung und geschichtlicher Hintergrund der KI\".\nThemen und Inhalte der Lektionen:\nI. Einführung und geschichtlicher Hintergrund\nWas ist KI – eine philosophische Betrachtung\nStarke und Schwache KI\nDer Turing Test\nDie Geburt der KI\nDie Ära der großen Erwartungen\nDas Einholen der Realität\nWie man einer Maschine das Lernen beibringt\nVerteilte Systeme in der KI\nDeep Learning, Machine Learning, Natural Language Processing\nII. Der allgemeine Problemlöser\nBeweisprogramm - Logical Theorist\nBeispiel aus “Human Problem Solving“ (Simon)\nDie Struktur eines Problems\nIm diesem Abschnitt greifen wir zunächst die anfänglichen Techniken der KI auf. Sie lernen dabei die Konzepte und berühmte Beispielsysteme kennen, die diese frühe Phase der Euphorie auslösten.\nIII. Expertensysteme\nFaktenwissen und heuristisches Wissen\nFrames, Slots und Filler\nVorwärts- und Rückwärtsverkettung\nDas MYCIN Programm\nWahrscheinlichkeiten in Expertensystemen\nBeispiel - Wahrscheinlichkeit von Haarrissen\nIn diesem Abschnitt behandeln wir Expertensysteme, die ähnlich zu den allgemeinen Problemlösern nur spezielle Probleme behandeln. Aber dafür exzessiv auf Regeln und Fakten in Form einer Wissensbasis zugreifen.\nIV. Neuronale Netze\nDas menschliche Neuron\nSignalverarbeitung eines Neurons\nDas Perceptron\nDieser Abschnitt läutet die Rückkehr zu der Idee ein, das menschliche Gehirn nachbauen zu können und so in Form von neuronalen Netzen der digitalen Informationsverarbeitung zugänglich zu machen. Wir betrachten die frühen Ansätze und stellen heraus, welche Ideen noch gefehlt haben, um neuronalen Netzen zum Durchbruch zu verhelfen.\nV. Maschinelles Lernen (Deep Learning & Computer Vision)\nBeispiel – Kartoffelernte\nDas Geburtsjahr des Deep Learning\nSchichten von Deep-Learning-Netzen\nMaschinelles Sehen / Computer Vision\nConvolutional Neural Network.\nDie Idee eines Agenten und ihr Zusammenspiel in einem Multi-Agenten-System wird im fünften Abschnitt beschrieben. Ein solches System dient im Wesentlichen dazu, Komplexität auf mehrere Instanzen zu verteilen.\nDer sechste Abschnitt behandelt den Durchbruch der mehrschichtigen neuronalen Netze, maschinelles Lernen, maschinelle Sehen (Computer Vision), Spracherkennung und einige weitere Anwendungen der heutigen KI.",
      "target_audience": [
        "Für interessierte Studenten, Forscher, Anfänger und Fortgeschrittene auf dem Gebiet der künstlichen Intelligenz (KI) / Artificial Intelligence (AI).",
        "Menschen, die sich grundsätzlich über das Thema künstliche Intelligenz informieren wollen."
      ]
    },
    {
      "title": "ChatGPT Sıfırdan Zirveye 2024: Kazanç ve Verimliliği Artırın",
      "url": "https://www.udemy.com/course/chatgpt-sifirdan-zirveye-kazanc-ve-verimliliginizi-artirin/",
      "bio": "Sıfırdan ileri seviye ChatGPT dil modelleme programını öğrenin! Chat GPT ile kazanç yöntemleri ve daha fazlası...",
      "objectives": [
        "En temelden başlayarak, etkin pratik uygulamalar üzerinde ChatGPT'yi uzman seviyesine kadar öğreneceksiniz.",
        "İstediğiniz konu ile ilgili yazmak istediğiniz bir metni özgün bir şekilde sadece bir komut cümlesi ile oluşturacak ve potansiyel kazanca dönüştüreceksiniz.",
        "ChatGPT ile neler yapıldığını ve nasıl kazanç sağlanılacağını öğrenecek, etkin ve profesyonel bir şekilde kullanmaya başlayacaksınız.",
        "Hızlı bir şekilde kaliteli uygulamalar oluşturabilecek ve kazanca dönüştürebileceksiniz.",
        "Öğrendiklerinizi uygulama dersleri ile zihninizde iyice pekiştireceksiniz.",
        "Yalnızca birkaç kelimelik komut girerek saniyeler içerisinde satırlarca kodun nasıl oluşturulduğuna şahit olacaksınız.",
        "Özellikle son derslere doğru Chat GPT'ye hakim olduğunuzu hissedeceksiniz.",
        "İşyerinizde çalışma arkadaşlarınızdan daima birkaç adım önde olabileceksiniz.",
        "Okulunuzda diğer öğrencilere göre daha hızlı öğrenebileceksiniz.",
        "Sorduğunuz doğru sorular sayesinde zaman harcamadan kaliteli içerikler oluşturabileceksiniz.",
        "Prompt mühendisliği tekniklerini öğreneceksiniz."
      ],
      "course_content": {
        "ChatGPT'ye Giriş": [
          "Bu Kursta Neler Öğreneceğiz?",
          "Yapay Zeka Nedir?",
          "Yapay Zekanın Tarihçesi ve Gelişimi",
          "Yapay Zeka İnsanlarla Makineler Arasındaki Etkileşimi Nasıl Artırdı?",
          "Chatbotların Evrimi",
          "ChatGPT'nin Chatbot Teknolojisindeki Yeri ve Önemi",
          "ChatGPT Nedir?",
          "ChatGPT'nin Geçmişine Bakalım",
          "GPT Teknolojisinin Gelişimi: Detaylı İnceleme",
          "ChatGPT ile Google Arasındaki Fark",
          "Yeni Bir Devrim: ChatGPT 4o",
          "ChatGPT İle Neler Yapılabilir?",
          "Değerlendirme"
        ],
        "ChatGPT'nin Kullanımını Öğreniyoruz": [
          "ChatGPT Üyeliği Nasıl Açılır?",
          "ChatGPT Arayüzü Kullanımını Öğrenelim",
          "Custom Instructions: ChatGPT’yi Özelleştirin",
          "Prompt Yazarken İşinizi Kolaylaştıracak 7 Klavye Kısayolu",
          "ChatGPT'den Maximum Verim Elde Etmek İçin Sorularımızı Nasıl Sormalıyız?",
          "Değerlendirme"
        ],
        "ChatGPT Plus'a Geçiş": [
          "ChatGPT Plus'a Nasıl Geçilir ve Bizleri Neler Bekliyor?",
          "ChatgPT 3.5 ve 4 Arasındaki Farkları Keşfedelim - Kapsamlı Bir Karşılaştırma",
          "Explore GPTs Özelliğini İnceleyelim",
          "Değerlendirme"
        ],
        "ChatGPT ile Nasıl Kazanç Sağlanılabilir?": [
          "ChatGPT ile Para Kazanma Yöntemleri",
          "Metin Yazarlığı Yapma",
          "Ödev: Etkileyici Reklam Sloganları Oluşturma",
          "YouTube İçerikleri Oluşturma",
          "Ödev: Seyahat Vlog Konsepti Geliştirme",
          "Hikaye / Metin / Senaryo Yazma",
          "Uygulama: Sıfırdan Bir Roman Senaryosu Yazalım",
          "Uygulama: Bir Kitabın Özetini Yazdıralım",
          "Ödev: Kısa Polisiye Hikaye Önerisi",
          "Kompozisyon Yazma ve Revizyonlarını Yapma",
          "Uygulama: Bir Konu Hakkında Kısa Bir Kompozisyon Yazdıralım",
          "Dil Çeviri Hizmetleri Verme",
          "SEO Hizmeti Verme",
          "Ödev: Anahtar Kelime Araştırması ve Optimizasyonu",
          "Yazılım Kodu Oluşturma ve Satışını Yapma",
          "Ödev: Basit Python Kodu Oluşturma",
          "Uygulama: Hesap Makinesi Uygulaması Oluşturalım",
          "Uygulama: Hisse Senedinden Edilen Kar / Zararı Canlı Takip Eden Yazılım Yazalım",
          "ChatGPT ile Ürettiğiniz İşleri Satabileceğiniz Freelance Siteler",
          "ChatGPT'den Yatırım Tavsiyesi Alınabilir mi? YENİ!!!",
          "Ödev: Kripto Para Araştırması",
          "Değerlendirme"
        ],
        "ChatGPT ile İşlerimizi Nasıl Kolaylaştırabiliriz?": [
          "Yeni İşinize Hazırlanmak İçin ChatGPT'yi Kullanın",
          "Ödev: Mülakat Teknikleri Geliştirme",
          "ChatGPT ile Özgeçmiş ve Ön Yazı Oluşturalım",
          "Ödev: Özgeçmiş ve Ön Yazı İyileştirme",
          "Öğrenciler İçin ChatGPT",
          "Ödev: Araştırma Makalesi Konusu Belirleme",
          "İş Hayatınıza Yardımcı Olması İçin ChatGPT Nasıl Kullanılabilir?",
          "Ödev: Ürün Sunumu Stratejileri",
          "Uygulama: İşletmelerin G.Ekipman Verimliliğini Ölçmek İçin Excel VBA Oluşturalım",
          "ChatGPT’den Sağlığımız Konusunda Nasıl Yardım Alabiliriz?",
          "Uygulama: ChatGPT ile Beslenme Planı Yapın ve Kalorileri Ölçün",
          "Değerlendirme"
        ],
        "ChatGPT'yi Veri Bilimi ve Analizi İçin Nasıl Kullanabiliriz?": [
          "ChatGPT ile Veri Bilimi ve Analizine Giriş",
          "Veri Temizleme İşlemi Yapalım",
          "Duygu Analizi Yapalım",
          "Keşifçi Veri Analizi Nasıl Yapılır?",
          "Veri Görselleştirme İşlemi Yapalım",
          "Korelasyon Analizini Nasıl Yaparız?",
          "Doğrusal Regresyon Modeli Kuralım"
        ],
        "Prompt Mühendisliği Teknikleri: Daha İyi Promptlar Yazın": [
          "Prompt Mühendisliği Nedir?",
          "Promptları Hazırlama ve İyileştirme Süreci",
          "Prompt Türleri",
          "Hazırlama Promptu",
          "Görev Ayrıştırma Tekniği",
          "Cevap Vermeden Önce Soran Çıktı Almak",
          "Yapıcı Eleştirmen Tekniği",
          "Ters Yönlendirme Tekniği",
          "Sonsuz Döngü",
          "Değerlendirme"
        ],
        "Diğer Alternatif Yapay Zeka Modelleriyle Tanışalım": [
          "ChatGPT'ye Alternatif Yapay Zeka Modelleri Tanıyalım",
          "DALL-E 2: Metinleri ve Resimlerinizi Eşsiz Görsellere Çevirin",
          "GptExcel: Yapay Zekaya Excel Formülleri Hazırlatın",
          "Değerlendirme"
        ],
        "Bizi Bekleyen Potansiyel Gelecek: Neler Değişecek?": [
          "Yapay Zeka ve Chatbot Teknolojisinin Potansiyel Gelecekteki Gelişmeleri",
          "ChatGPT Birçok Şeyi Değiştiriyor",
          "ChatGPT ve Benzeri Platformların Yok Edeceği Söylenen Meslekler",
          "Siz Neler Düşünüyorsunuz?",
          "Değerlendirme"
        ],
        "Kursu Bitirdiniz (E-KİTAP HEDİYESİ)": [
          "Tebrikler..",
          "ChatGPT'ye Yazdırdığım E-Kitabımı Sizlere Hediye Ediyorum.."
        ]
      },
      "requirements": [
        "Bir masaüstü, dizüstü bilgisayar, tablet veya akıllı telefon",
        "Temel bilgisayar, tablet veya telefon kullanım bilgisi",
        "Gün içerisinde ayırabileceğiniz birkaç dakika",
        "Kuvvetli bir öğrenme isteği"
      ],
      "description": "Bu kursta ilerledikçe, ChatGPT'nin nasıl çalıştığını daha iyi anlayacak ve yazdığınız metinleri nasıl işlediğine ve ürettiğine dair kapsamlı bilgilere sahip olacaksınız. Dil çevirisi, metin yazarlığı, SEO planları, yazılım kodu oluşturma gibi ihtiyaçlarınızı karşılayan birçok görevi hızlıca gerçekleştirmek için ChatGPT'de neler yapmanız gerektiğini öğreneceksiniz, bu dil modelinde fırsatların sonsuz olduğunu hissedeceksiniz. ChatGPT'nin performansını optimize etmeye dair bilmeniz gereken teknikleri öğreneceksiniz.\nChatGPT'nin teknik yönlerini öğrenmenin yanı sıra, bu dil modeli için çeşitli gerçek dünya uygulamalarını da göreceksiniz. Örneğin, dakikalar hatta saniyeler içinde nasıl dil çevirisi yapacağınızı, kompozisyon yazdıracağınızı, python kodu oluşturacağınızı uygulamalı olarak öğrenecek ve bunun gibi hızlıca gelir akışları oluşturacak işler için ChatGPT'nin nasıl kullanılabileceğini anlayacaksınız. Ayrıca Chat GPT'nin kişisel gelişiminiz için nasıl kullanılabileceğini de görecek ve eksiğiniz olduğunu düşündüğünüz konularda kendinizi geliştireceksiniz.\nKurs boyunca, öğrendiğiniz bilgileri uygulamalı alıştırmalar aracılığıyla uygulamaya koyma fırsatına sahip olacaksınız. Bu alıştırmalar, Chat GPT'yi kullanma konusunda pratik yapmanızı ve farklı ortamlarda nasıl kullanabileceğinizi görmenizi sağlayacaktır.\nBu kursun sonunda, ChatGPT'yi kendi işlerinizde etkin bir şekilde kullanmak ve kariyerinizi ilerletmek için donanımlı hale gelecek, istediğiniz herhangi bir konuda hızlıca sıfırdan kaliteli ürünler ortaya çıkarabilecek ve bu ürünler veya hizmetler sayesinde para kazanabileceksiniz.\nBu Eğitimde Neler Bulacağım?\nChatGPT ' nin tanımı\nChatGPT hayatımıza neler katacak?\nChatGPT'nin geçmişi\nGoogle ile ChatGPT arasındaki fark\nChatGPT ile neler yapılabilir?\nChatGPT üyeliği nasıl açılır?\nChatGPT nasıl kullanılır?\nChatGPT'den maximum verim elde etmek için sorularımızı nasıl sormalıyız?\nChatGPT ile para kazanma yöntemleri\nİşletmelere metin yazarlığında yardımcı olmak\nİçerik oluşturucularına YouTube içeriklerinde yardımcı olmak\nHikaye / Metin / Senaryo Yazma\nDil çeviri hizmetleri verme\nSEO Hizmeti Verme\nYazılım Kodu Oluşturma ve Satışını Yapma\nChatGPT ile ürettiğiniz işleri satabileceğiniz freelance siteler\nYeni işinize hazırlanmak için Chat GPT'yi kullanmak\nÖğrenciler için ChatGPT\nİş hayatınıza yardımcı olması için ChatGPT Nasıl Kullanılabilir?\n\n\nSon olarak belirtmek isterim ki bu dil modelleme programı için yoğun araştırmalar yapıp deneyimler elde ettiğim bu kurs ve içeriği hakkında sorularınız, sorunlarınız ve fikirleriniz varsa bunları bana gün içerisinde istediğiniz saatte belirtmeniz beni mutlu edecektir. Bilgiler ve fikirler, paylaştıkça çoğalır...",
      "target_audience": [
        "ChatGPT hakkında bilgisi olmayıp öğrenmek isteyenler",
        "ChatGPT'yi duymuş olup profesyonelleşmek isteyenler",
        "İş hayatında daha üst pozisyonlar için kendine şans yaratmak isteyenler",
        "Okul hayatını kolaylaştırmak ve kendini geleceğe hazırlamak isteyen öğrenciler",
        "Kendine ek gelir kapısı açmak isteyenler",
        "Hızlı ve kolay bir şekilde gelirlerinizi artırmak isteyenler",
        "Prompt mühendisliğini öğrenmek isteyenler"
      ]
    },
    {
      "title": "모두를 위한 ChatGPT Part 3 - ChatGPT로 퀀트 투자 전략 만들기",
      "url": "https://www.udemy.com/course/quant-investment-using-chatgpt-part3/",
      "bio": "올웨더, 듀얼모멘텀, 변동성돌파전략 및 나만의 퀀트 투자 전략을 만들어보자",
      "objectives": [
        "ChatGPT를 이용해서 퀀트투자 전략을 만드는 방법",
        "다양한 퀀트 투자 전략(변동성 돌파전략, 듀얼모멘텀 전략, 올웨더 전략)",
        "주식 데이터를 수집하고 분석하는 방법",
        "투자 아이디어를 백테스트로 검증하는 방법"
      ],
      "course_content": {
        "ChatGPT로 퀀트 투자 전략 만들기 강의 개요": [
          "ChatGPT를 이용한 퀀트투자 전략 만들기 개요",
          "퀀트 투자란?"
        ],
        "퀀트 투자의 기본개념 익히기": [
          "퀀트 투자의 기본 개념 익히기 - 주식데이터의 기본 구성, CAGR, MDD, Sharpe ratio"
        ],
        "퀀트 분석을 위한 주식 데이터를 수집해보자 - FinanceDataReader": [
          "코드 10줄로 시작하는 손쉬운 금융 데이터 크롤링 라이브러리 - FinanceDataReader 소개",
          "Python 실습을 위한 구글 코랩 Colab 소개",
          "Colab 실습 - FinanceDataReader로 주식 데이터를 데이터프레임 형태로 받아오자",
          "Colab 실습 - ChatGPT를 이용해서 FinanceDataReader와 판다스(Pandas) 활용하기",
          "Colab 실습 - ChatGPT를 이용해서 FinanceDataReader와 판다스(Pandas) 활용하기 - 코드 리뷰"
        ],
        "주식 데이터를 다양한 관점으로 분석해보자": [
          "Colab 실습 - 코스피 코스닥 전종목을 섹터(Sector)를 기준으로 분석해보자"
        ],
        "ChatGPT를 이용해서 퀀트투자 전략을 만들어보자 - 단기 투자 전략": [
          "ChatGPT를 이용해서 가장 많이 상승한 날과 가장 많이 하락한 날을 찾아서 해당 날에 매수하는 전략 만들기",
          "ChatGPT를 이용해서 가장 많이 상승한 날과 가장 많이 하락한 날을 찾아서 해당 날에 매수하는 전략 만들기 - 코드 리뷰",
          "래리 윌리엄스의 변동성 돌파 전략",
          "Colab 실습 - 래리 윌리엄스의 변동성 돌파 전략"
        ],
        "ChatGPT를 이용해서 퀀트투자 전략을 만들어보자 - 장기 투자 전략": [
          "세계 최고의 투자자 레이 달리오의 올웨더 전략",
          "Colab 실습 - 올웨더 투자 전략 구성 및 백테스트",
          "게리 안토니치의 듀얼 모멘텀 전략",
          "Colab 실습 - 듀얼 모멘텀 전략 구현 및 백테스팅"
        ]
      },
      "requirements": [
        "[모두를 위한 ChatGPT Part 2 - ChatGPT를 이용한 데이터분석과 판다스 활용] 수강 경험 혹은 그에 준하는 Python과 판다스(Pandas)에 대한 기초지식"
      ],
      "description": "ChatGPT를 이용해서 퀀트투자 전략을 만드는 법을 학습할 수 있는 강의입니다. ChatGPT를 이용해서 나만의 퀀트 투자 전략을 만들어 보세요.\n\n\nChatGPT를 이용해서 주식 투자 전략을 만들수 있다면?\nChatGPT를 이용해서 나만의 퀀트투자 전략을 만들어보세요.\nChatGPT를 이용해서 퀀트투자 전략을 만드는 방법\n다양한 퀀트 투자 전략의 아이디어(변동성 돌파전략, 듀얼 모멘텀 전략, 올웨더 전략)와 해당 전략들을 과거 데이터로 백테스팅해보기\n주식 데이터를 수집하고 분석하는 방법\n\n\n이런 분들께 추천드려요!\n퀀트 투자 전략을 만들어보고 싶은 분\nChatGPT를 효율적으로 사용하는 방법을 학습하고 싶은 분\nChatGPT가 만들 변화된 미래를 먼저 경험하고 싶은 분\n퀀트 투자를 위해 주식 데이터를 수집하고 분석하는 법을 학습하고 싶은 분\n\n\n예상 질문 Q&A\nQ. 퀀트 투자란 무엇인가요?\nA. 퀀트 투자(Quantitative Investment)(=계량 투자)는 기존의 인간의 직관과 분석에 기반한 투자 방법론이 아니라 컴퓨터와 데이터 분석을 이용해서 투자를 집행하는 투자 방법론입니다. 컴퓨터의 발전에 힘입어 많은 투자회사와 투자자들이 퀀트투자 방법론을 연구하고 이로 인한 투자성과를 만들어내고 있습니다.\n\n\nQ. ChatGPT를 이용한 퀀트 투자의 장점은 무엇인가요?\nA. 기존에 퀀트 투자를 수행하기 위해서는 Python 코드 작성방법과 판다스(Pandas) 라이브러리 사용법을 학습해야만 했습니다. 하지만 ChatGPT를 이용하면 검증하고자하는 투자 아이디어를 한국어 문장으로 작성해서 ChatGPT에게 요청하면, ChatGPT가 판다스 라이브러리를 이용한 Python 코드를 작성해주기 때문에 판다스 라이브러리와 Python 학습에 대한 진입장벽이 완화되었습니다.\n\n\nQ. 그렇다면 이제 Python 코드 작성방법과 판다스 라이브러리를 학습할 필요가 없나요?\nA. ChatGPT가 자동으로 Python 코드를 작성해주긴 하지만 ChatGPT가 작성해준 Python 코드를 분석하고, ChatGPT에게 더 명확하게 작업을 요청하기 위해서, Python 코드 작성 방법과 판다스 라이브러리 사용법을 학습하면 ChatGPT를 200% 활용할 수 있습니다.",
      "target_audience": [
        "퀀트 투자 전략을 만들어보고 싶은 분",
        "ChatGPT를 다양하게 활용하는 방법을 학습하고 싶은 분",
        "퀀트 분석을 위한 주식 데이터를 수집하는 방법을 학습하고 싶은 분"
      ]
    },
    {
      "title": "Geração de Vídeos com Inteligência Artificial",
      "url": "https://www.udemy.com/course/geracao-de-videos-com-inteligencia-artificial/",
      "bio": "Explore o potencial da IA generativa para criar vídeos incríveis! Gere vídeos em diversos estilos e formatos",
      "objectives": [
        "Compreender o que é a geração de vídeos por IA, seus diferentes tipos e como podem ser usados",
        "Explorar ferramentas modernas como Kling, PixVerse, Runway, InVideo e várias outras",
        "Gerar vídeos em estilos variados, desde realismo até animações e desenhos",
        "Aprender a extrair o máximo das soluções proprietárias e de código aberto",
        "Melhorar os resultados utilizando engenharia de prompt e outras técnicas",
        "Obter mais controle sobre o resultado final usando imagens ou vídeos de referência",
        "Usar suas próprias imagens para criar vídeos e aprender como gerar imagens do zero com IA",
        "Produzir vídeos completos sobre qualquer tema usando apenas uma descrição textual",
        "Aprender como gerar e editar vídeos para diferentes plataformas e formatos",
        "Criar avatares de IA e dar vida a retratos e outras imagens estáticas"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre IA",
          "Recursos para download",
          "Contexto histórico",
          "Aplicações, desafios e ética",
          "Tipos de vídeos"
        ],
        "Explorando as ferramentas": [
          "Acesso às ferramentas",
          "Hotshot",
          "Engenharia de prompts",
          "Hailuo AI",
          "Dream machine",
          "PixVerse",
          "Kling AI",
          "Invideo AI",
          "Genmo",
          "Pyramid flow",
          "CogVideo X",
          "Kaiber AI",
          "Código em Python",
          "Resultados",
          "Outras ferramentas"
        ],
        "Imagem/vídeo para vídeo": [
          "Primeiro exemplo",
          "Links para ferramentas de geração de imagem",
          "CGDream e Piclumen - gerar imagens",
          "Leonardo.ai - gerar imagens",
          "Ideogram - imagens com textos",
          "Seaart",
          "PixVerse",
          "Dream machine",
          "Kling",
          "Código em Python",
          "Resultados obtidos",
          "Vídeo para vídeo",
          "Outros resultados"
        ],
        "Estudos de caso": [
          "Anúncio ou vídeo institucional",
          "Acesso às ferramentas para criação de animações e desenhos",
          "Animações e desenhos - txt2vid",
          "Animações e desenhos - img2vid",
          "Mais resultados para animações e desenhos",
          "Animações e desenhos - interpolação",
          "Animações e desenhos - vid2vid",
          "Estórias completas - FocalML",
          "Outras abordagens e ferramentas para animações",
          "Edição profissional - CapCut",
          "Avatares de IA - studio.D-ID",
          "Alternativas para criação de avatares de IA",
          "Retratos animados (Live Portrait)",
          "Resultados retratos"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Nenhum pré-requisito"
      ],
      "description": "Neste curso vamos explorar o fascinante mundo da inteligência artificial generativa e aprender a criar vídeos impressionantes, desde animações cativantes até vídeos institucionais e promocionais. Utilizando uma abordagem prática e acessível, o curso foca no uso gratuito das principais ferramentas modernas disponíveis, permitindo que você aproveite ao máximo essas tecnologias.\nComeçaremos com os fundamentos, explicando o que é a geração de vídeos por IA, seus diferentes tipos, como classificá-los e os casos de uso mais relevantes. Você entenderá os benefícios e desafios dessa tecnologia e irá adquirir a intuição necessária para escolher as melhores abordagens para cada projeto ou situação.\nVocê será guiado pelas ferramentas proprietárias mais populares, como Kling AI, PixVerse, Dream Machine, MiniMax, Hotshot e InVideo. Descubra como utilizá-las e veja exemplos práticos de como gerar vídeos impressionantes a partir de simples descrições textuais. Na sequência, você aprenderá com detalhes como usar a engenharia de prompt para melhorar a geração de vídeos e explorar palavras-chave que elevam o nível dos resultados. Para quem busca liberdade e personalização, exploraremos também soluções open source modernas para geração de vídeo, como Genmo e Stable Video Diffusion.\nAlém de criar vídeos inteiros do zero, você aprenderá a usar como referência suas próprias imagens (imagem-para-vídeo) ou vídeos (vídeo-para-vídeo), controlando o estilo do vídeo e guiando o seu resultado final. Para a geração dessas imagens de referência, vamos explorar ferramentas poderosas como Leonardo AI e Ideogram, mostrando detalhadamente como usá-las para criar as imagens iniciais que irão aumentar a qualidade e controle do vídeo final.\nNa seção de desenvolvimento de estudos de caso, você colocará em prática tudo o que aprendeu ao longo do curso. Exploraremos projetos práticos como a criação de anúncios ou vídeos institucionais que combinam criatividade e profissionalismo. Mergulharemos no processo de criação de animações e desenhos, permitindo que você explore estilos artísticos e crie vídeos que se destacam pela originalidade e impacto visual. Por fim, vamos ensinar como dar vida a retratos e também como criar avatares de IA, que possuem inúmeras possibilidades de aplicação no mundo real. Esses estudos de caso foram projetados para consolidar seus conhecimentos e ampliar sua capacidade criativa com a IA generativa.\nSeja para redes sociais, campanhas promocionais ou projetos criativos, você irá explorar diferentes formatos e estilos de vídeo, aprendendo a adaptar-se a cada necessidade. E como um bônus, mostraremos como editar gratuitamente seus vídeos finais utilizando softwares de edição, aplicando ajustes, efeitos e cortes para torná-los ainda mais profissionais. Embora isso não seja o foco principal do curso, essas habilidades extras garantirão que você tenha maior controle e profissionalismo sobre o produto final.\nEste curso é a porta de entrada perfeita para quem deseja aproveitar o potencial da IA generativa sem complicações e com total liberdade criativa. Comece agora e descubra como transformar suas ideias em vídeos incríveis!",
      "target_audience": [
        "Criadores de Conteúdo e Produtores de Vídeo: Profissionais que desejam aprimorar suas habilidades de produção, explorando ferramentas avançadas de IA para auxiliar na criação de vídeos únicos e impactantes.",
        "Especialistas em Marketing e Publicidade: Profissionais em busca de novas estratégias para criar vídeos promocionais envolventes, campanhas de branding e anúncios otimizados para várias plataformas digitais.",
        "Artistas Visuais e Cineastas Independentes: Interessados em expandir sua criatividade, utilizando tecnologias emergentes para transformar ideias em vídeos cativantes e inovadores.",
        "Profissionais de outras áreas: Pessoas que desejam integrar vídeos imersivos diferenciados ou elementos narrativos visuais em seus projetos digitais, como em jogos, conteúdos educativos, vídeos institucionais e vários outros.",
        "Entusiastas de Tecnologia e Inteligência Artificial: Pessoas curiosas sobre o uso da IA generativa em vídeos e interessadas em explorar as infinitas possibilidades criativas dessa tecnologia em constante evolução."
      ]
    },
    {
      "title": "Detecção e Reconhecimento Facial com Python",
      "url": "https://www.udemy.com/course/deteccao-reconhecimento-facial-python/",
      "bio": "Detecte e reconheça faces de imagens, vídeos e webcam utilizando a linguagem Python e as bibliotecas OpenCV e Dlib",
      "objectives": [
        "Diferencie detecção e reconhecimento facial",
        "Detecte faces usando Haarcascade, HOG (Histogram of Oriented Gradients), MMOD (Max-Margin Object Detection), e SSD (Single Shot Multibox Detector)",
        "Detecte e reconheça faces de imagens, vídeos e webcam usando as bibliotecas OpenCV e Dlib",
        "Reconheça faces usando Eigenfaces, Fisherfaces, LBPH (Local Binary Patterns Histrograms), e modernas técnicas de Deep Learning",
        "Avalie os algoritmos de reconhecimento facial para escolher o melhor de acordo com os seus objetivos"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Detecção x reconhecimento",
          "Recursos para download",
          "Mais sobre Visão Computacional"
        ],
        "Detecção de faces": [
          "OpenCV e Dlib",
          "Imagens e pixels",
          "Haarcascade - intuição",
          "Carregamento da imagem",
          "GPU no Google Colab",
          "Detecção de faces com haarcascade",
          "Redimensionamento da imagem",
          "Parâmetros haarcascade 1",
          "Parâmetros haarcascade 2",
          "Detecção de olhos",
          "Detecção de sorrisos, relógios, corpos e carros",
          "HOG (Histogram of Oriented Gradients) – intuição",
          "Detecção de faces com HOG",
          "Parâmetro upsampling",
          "Max-Margin Object Detection (MMOD) – intuição",
          "Detecção de faces com MMOD",
          "Single Shot MultiBox Detector (SSD) – intuição",
          "Detecção de faces com SSD 1",
          "Detecção de faces com SSD 2",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Detecção de faces em vídeos 1",
          "Detecção de faces em vídeos 2",
          "Detecção de faces em vídeos 3",
          "Detecção de faces em vídeos 4",
          "Detecção de faces em vídeos 5",
          "Detecção de faces pela webcam"
        ],
        "Reconhecimento facial": [
          "Eigenfaces - intuição",
          "Base de dados Yalefaces",
          "Eigenfaces - implementação 1",
          "Eigenfaces - implementação 2",
          "Eigenfaces - implementação 3",
          "Eigenfaces - implementação 4",
          "Eigenfaces - implementação 5",
          "Fisherfaces - intuição",
          "Fisherfaces - implementação",
          "LBPH - intuição",
          "LBPH - implementação 1",
          "LBPH - parâmetros",
          "LBPH - implementação 2",
          "Deep learning com Dlib 1",
          "Deep learning com Dlib 2",
          "Deep learning com Dlib 3",
          "Deep learning com Dlib 4",
          "Deep learning com Dlib 5",
          "Deep learning com Dlib 6",
          "Biblioteca face recognition 1",
          "Biblioteca face recognition 2",
          "Biblioteca face recognition 3",
          "Biblioteca face recognition 4",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Biblioteca face recognition 5",
          "Alinhamento e elementos faciais",
          "Reconhecimento facial em vídeos",
          "Projeto: captura de faces pela webcam",
          "Projeto: algoritmos tradicionais",
          "Projeto: algoritmos de deep learning"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação",
        "Programação básica em Python"
      ],
      "description": "A detecção de faces é uma sub-área da Visão Computacional que visa detectar o rosto das pessoas em imagens ou vídeos. Smartphones e câmeras digitais usam esses recursos para selecionar pessoas em uma foto, geralmente colocando um retângulo ao redor do rosto. Esse tipo de aplicação tem ganhado bastante relevância em sistemas de segurança, nos quais é necessário identificar se há pessoas em um ambiente para que o alarme seja acionado. Por outro lado, o reconhecimento facial visa reconhecer o rosto das pessoas para por exemplo identificar se uma pessoa está ou não presente em um ambiente. É importante destacar as diferenças entre as técnicas de detecção e reconhecimento de faces: enquanto a primeira apenas indica se uma face está presente, a segunda indica de quem é a face detectada.\nNeste curso passo a passo usando a linguagem de programação Python, você aprenderá como detectar e reconhecer rostos a partir de imagens, vídeos e webcam; utilizando desde as técnicas mais básicas até as mais avançadas! Veja abaixo os tópicos que serão abordados:\n\n\nDetecção de faces usando Haarcascade, HOG (Histogram of Oriented Gradients), MMOD (Max-Margin Object Detection) e SSD (Single Shot Multibox Detector)\nDetecção de outros objetos, como olhos, sorrisos, relógios, corpos e carros\nReconhecimento de faces usando Eigenfaces, Fisherfaces, LBPH (Local Binary Patterns Histograms) e técnicas avançadas de Deep Learning\nComo comparar o desempenho dos algoritmos\nCriação de seu conjunto de dados personalizado capturando rostos via webcam\nTodas as implementações serão feitas passo a passo usando o Google Colab online, ou seja, você não precisa se preocupar em instalar e configurar as ferramentas na sua própria máquina! São mais de 60 aulas e 8 horas de vídeos!",
      "target_audience": [
        "Pessoas interessadas em detecção e reconhecimento de faces utilizando as bibliotecas OpenCV e Dlib",
        "Alunos de gradução ou pós-graduação que estejam cursando disciplinas da área de Visão Computacional, Inteligência Artificial ou Ciência de Dados",
        "Cientistas de dados que queiram aumentar seu portfólio",
        "Iniciantes na área de Visão Computacional"
      ]
    },
    {
      "title": "【한글자막】 현대 인공지능 (AI) 마스터 클래스 : 6개의 프로젝트 구축하기",
      "url": "https://www.udemy.com/course/best-modern-ai/",
      "bio": "금융, 기술, 예술 및 의료 분야에서 발생하는 실제 문제들을 AI를 활용하여 해결하는 방법에 대해 학습하는 실습 위주 강의",
      "objectives": [
        "인공지능(AI)의 혁명이 바로 여기 있습니다!",
        "Tensorflow 2.0 서빙으로 AI 기반 이모션 모델을 배포하고 모델을 통해 사고해 봅니다.",
        "설명 가능한 AI의 개념을 이해하고 인공신경망의 블랙박스 개념을 파악해 그 숨겨진 레이어를 GradCam 기술로 시각화해 봅니다.",
        "병원에서 뇌종양 감시 프로세스를 자동화하고 최적화를 위해 사용하는 딥러닝 모델을 개발해 봅니다.",
        "ResNets와 ResUnet 네트워크를 활용해서 뇌종양을 감지하고 국소화하는 AI 모델을 구축하고 연습해 봅니다(의료 애플리케이션)",
        "세분화 모델과 ResUnet 네트워크의 상태에 대한 이론과 직관을 이해해 봅니다.",
        "AWS 세이지메이커의 XGBoost 알고리즘을 이용해 고객의 신용 카드 채무 불이행을 예측하는 Ai 모델을 구축, 교육, 전개해 봅니다.",
        "하이퍼 파라미터 최적화를 사용해서 XGBoost 모델 매개 변수를 최적화해 봅니다.",
        "마케팅 전략 최적화를 위해서, 고객 시장 세분화를 통해 비즈니스 애플리케이션에 AI를 적용해 봅니다.",
        "아트 생성을 위한 딥드림 알고리즘의 기초와 수학을 이해해 봅니다.",
        "TF 2.0에서 Keras API를 이용해 AI 기반 아트 작품을 만들기 위해 최첨단 딥드립 알고리즘을 교육, 개발, 테스트해 봅니다.",
        "구글의 콜랩에서 GPU와 TPU의 강력한 기능을 활용해서 ANN 모델을 개발합니다."
      ],
      "course_content": {
        "소개": [
          "소개와 환영 메시지",
          "소개, 중요 팁과 우수 사례",
          "강의 개요와 주요 학습 결과",
          "필요 준비물"
        ],
        "감정 AI": [
          "프로젝트 소개와 환영 메시지",
          "과제 #1 – 연구문제 진술과 경영 사례 이해하기",
          "과제 #2 – 라이브러리와 데이터 집합 가져오기",
          "과제 #3 – 이미지 시각화 수행하기",
          "과제 #4 – 이미지 확대하기",
          "과제 #5 – 데이터 일반화와 스케일링 수행하기",
          "과제 #6 – 인공신경망(ANNs) 이론과 직감 이해하기",
          "과제 #7 – ANNs 훈련과 경사 하강 알고리즘 이해하기",
          "과제 #8 – 합성곱 신경망과 ResNets 이해하기",
          "과제 #9 – RestNet을 만들어 얼굴 주요 특징점 검출하기",
          "과제 #10 – 얼굴 주요 특징점 검출 모델 컴파일하고 훈련시키기",
          "과제 #11 – 훈련된 ResNet 모델 성능 평가",
          "과제 #12 – 얼굴 표정(감정) 데이터 집합 가져오고 둘러보기",
          "과제 #13 – 얼굴 표정 탐지를 위해 이미지 시각화하기",
          "과제 #14 – 이미지 확대하기",
          "과제 #15 – 얼굴 표정 분류 모델 만들고 훈련하기",
          "과제 #16 – 핵심성과지표 분류기 이해하기",
          "과제 #17 – 얼굴 표정 분류기 모델 평가하기",
          "과제 #18 – 두 모델에서 예측하기: 1. 주요 얼굴 특징점, 2. 감정",
          "과제 #19 – 전개를 위해 훈련된 모델 저장하기",
          "과제 #20 – TensorFlow 2.0 Serving에서 학습된 모델 제공",
          "과제 #21 – 두 모델 전개하고 추론하기"
        ],
        "보건 서비스에서의 AI": [
          "프로젝트 소개와 환영 메시지",
          "과제 #1 – 연구문제 진술",
          "과제 #2 – 라이브러리와 데이터 집합 시각화하기",
          "과제 #3 – 데이터 집합 시각화하고 돌아보기",
          "과제 #4 – ResNet과 CNNs에 대한 직관 이해하기",
          "과제 #5 – 전이 학습에 대한 이론 및 직관 이해하기",
          "과제 #6 – 뇌 종양을 탐지하기 위한 분류기 모델 훈련시키기",
          "과제 #7 – 훈련된 분류기 모델 성능 평가",
          "과제 #8 – ResUnet 분할 모델 직관 이해하기",
          "과제 #9 – 분할 모델을 만들어 뇌종양 국소화하기",
          "과제 #10 – ResUnet 분할 모델 훈련시키기",
          "과제 #11 – 훈련된 ResUNet 분할 모델 성능 평가"
        ],
        "비즈니스(마케팅)에서의 AI": [
          "프로젝트 소개와 환영 메시지",
          "과제 #1 – 마케팅 AI 애플리케이션 이해하기",
          "과제 #2 – 라이브러리와 데이터 집합 가져오기",
          "과제 #3 – 탐색적 데이터 분석 수행하기 (파트 #1)",
          "과제 #4 – 탐색적 데이터 분석 수행하기 (파트 #2)",
          "과제 #5 – K-평균 클러스터링 알고리즘에 대한 이론 및 직관 이해하기",
          "Elbow Method를 적용하여 최적 클러스터 수 구하기",
          "과제 #7 – K-평균 클러스터링 알고리즘 적용하기",
          "과제 #8 – 주성분 분석에 대한 직관 이해하기",
          "과제 #9 – 오토인코더에 대한 이론과 직관 이해하기",
          "과제 #10 – 오토인코더 적용하고 클러스터링 수행하기"
        ],
        "비즈니스(재무)와 AutoMI에서의 AI": [
          "프로젝트 소개와 환영 메시지",
          "아마존 웹 서비스(AWS) 참고 사항",
          "과제 #1 – 연구문제 진술과 사업 사례 이해하기",
          "과제 #2 – 라이브러리와 데이터 집합 가져오기",
          "과제 #3 – 데이터 집합 시각화 및 탐색하기",
          "과제 #4 – 데이터 정리하기",
          "과제 #5 – XG-부스트 알고리즘에 대한 이론과 직관 이해하기",
          "과제 #6 – XG-부스트 알고리즘 주요 단계 이해하기",
          "과제 #7 – Scikit-Learn을 이용해서XG-부스트 알고리즘 훈련하기",
          "과제 #8 – 격자 탐색하고 하이퍼파라미터 최적화하기",
          "과제 #9 – AWS SageMaker의 XG-부스트 이해하기",
          "과제 #10 – AWS SageMaker의 XG-부스트 훈련시키기",
          "과제 #11 – 모델 전개하고 추론하기",
          "과제 #12 – AWS 오토파일럿을 이용해서 모델 훈련시키고 전개하기 (최소한의 코딩 필요)"
        ],
        "크리에이티브 AI": [
          "프로젝트 소개와 환영 메시지",
          "과제 #1 – 연구문제 진술과 사업 사례 이해하기",
          "과제 #2 – 훈련된 가중치로 모델 가져오기",
          "과제 #3 – 이미지를 가져와서 병합하기",
          "과제 #4 – 훈련된 모델을 실행하고 활성화 탐색하기",
          "과제 #5 – 딥드림 알고리즘에 대한 이론과 직관 이해하기",
          "과제 #6 – TF 2.0의 기울기 연산 이해하기",
          "과제 #7 – 딥드림 알고리즘 구현 파트 #1",
          "과제 #8 – 딥드림 알고리즘 구현 파트 #2",
          "과제 #9 – 딥드림 알고리즘을 적용해 이미지 생성하기",
          "과제 #10 – 딥드림 비디오 생성하기"
        ],
        "코딩없이 만드는 설명 가능한 AI": [
          "설명 가능한 AI 데이터 집합 다운로드와 데이터로봇 링크",
          "음식 인식 AI프로젝트 개요",
          "데이터로봇 데모 1 – 데이터 집합 업로드하고 탐색하기",
          "데이터로봇 데모 2 – AI/ML 모델 훈련시키기",
          "데이터로봇 데모 3 – 설명 가능한 AI"
        ],
        "AW, S3, SageMaker 단기 강좌": [
          "AWS와 클라우드 컴퓨팅은 무엇인가?",
          "주요 기계 학습 요소와 AWS 구경하기",
          "지역 및 가용 영역",
          "아마존 S3",
          "EC2 및 식별/접근 관리 (IAM)",
          "AWS 프리 티어 계정 세팅과 개요",
          "AWS SageMaker 개요",
          "AWS SageMaker 설명",
          "AWS SageMaker 스튜디오 개요",
          "AWS SageMaker 스튜디오 설명",
          "AWS SageMaker 모델 전개"
        ],
        "완강을 축하합니다! 선물 받아가는 것을 잊지 마세요!": [
          "보너스: ML 및 AI를 위한 Cloud 기술(쿠폰 동봉)",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "프로그래밍에 대한 기본 지식이 있으면 좋지만 필수적인 건 아닙니다."
      ],
      "description": "현대 인공지능(AI) 마스터 클래스!\n감정, 의료, 사업/마케팅 등 총 6개의 프로젝트를 이용한 문제 해결 코스!\n프로그래밍 지식 없이도 따라갈 수 있는 기초부터 탄탄한 강의!\n실제 데이터 세트를 활용한 실습 경험 제공!\n\n\n현대 인공지능 (AI) 마스터 클래스를 선택해야 하는 이유\n현대의 AI 응용의 핵심에 대한 지식을 실용적이고 쉽고 재밌게 제공하는 것입니다. 이 과정은 수강생들에게 실제 데이터 세트를 활용한 실습 경험을 제공합니다. 감성 AI, 설명 가능한 AI, 창의적인 AI, 건강관리, 비즈니스, 금융 분야 AI의 응용 등 다양한 새로운 주제와 응용 분야에 대해 다룰 것입니다.\n이 과정은 데이터 과학을 근본적으로 이해하고, 실질적인 문제를 해결하고자 하는 AI 실무자, 데이터 과학자 지망생, 테크 매니아, 컨설턴트를 위한 과정입니다. 이 코스는 아래와 같은 사람들을 위해 제작되었습니다:\n· AI를 활용해 사업을 혁신하고자 하는 노련한 컨설턴트들.\n· 커리어를 향상시키고 포트폴리오를 쌓고자 하는 AI 실무자들.\n· 수익 극대화, 비용 절감, 비즈니스 최적화를 원하는 비전 있는 사업가들.\n· AI에 열정이 있고 실무 경험을 하고 싶은 테크 매니아들.\n\n\n이 강의의 특별한 점은, Tensorflow 2.0과 AWS 세이지메이커를 사용해 모델을 교육하고 배포한다는 것입니다. 또한 모델 구축, 교육, 하이퍼 파라미터를 다루는 AI/ML 워크플로우의 다양한 요소를 다룹니다. 더불어, 머신 러닝, 딥러닝, 컴퓨터 비전 등 AI의 주요 측면을 모두 다룰 수 있도록 세심하게 설계되었습니다.\n\n\n현대 인공지능 (AI) 마스터 클래스 구성\n# 최신 업데이트: 제로 코딩으로 본 설명 가능한 AI에 대한 연구 추가\n· 프로젝트#1(감성 AI) : AI를 이용한 감정 분류 및 얼굴 포인트 감지\n· 프로젝트#2(의료 분야의 AI) : AI를 이용한 뇌종양 검출 및 위치 파악\n· 프로젝트#3(사업/마케팅에서의 AI) : 자동 인코더와 비지도 기계학습 알고리즘을 활용한 쇼핑몰 고객 세분화\n· 프로젝트#4(사업/재무에서의 AI): AWS 세이지메이커의 XG-Boost 알고리즘(오토파일럿)을 이용한 신용카드 채무 불이행 예측\n· 프로젝트#5(창의적인 AI): AI로 만드는 예술작품\n· 프로젝트#6(설명가능한 AI) : AI 블랙박스의 특성 파악\n\n\n교수 및 250,000명 이상의 수강생을 보유한 베스트셀러 강사 Dr. Ryan Ahmed와 Ligency Team이 전하는 한 마디\n한국 수강생 여러분들 안녕하세요?\n인공지능(AI)의 혁명이 바로 여기 있습니다!\n\n\n“전 세계 인공지능 시장은 43.9%의 성장에 힘입\n어 약 337조 원 규모로 커졌습니다. AI의 분야 중 하나인 딥러닝은 42.5% 이상의 잠재적인 성장률\n을 가지고 있습니다.”\n\n\nAI는 컴퓨터가 의사 결정, 추론, 텍스트 이해, 그리고 시각적 인식 같은 인간의 지능을 모방하는 과학입니다. AI는 머신 러닝, 로봇 공학, 그리고 컴퓨터 비전 같은 여러 하위 분야를 포함하는 더 넓은 개념입니다.\n\n\n기업들이 경쟁력을 갖추고 급성장하기 위해선, AI의 힘을 이용해 프로세스를 개선하고 비용을 절감하면서 수익을 높여야 합니다. 오늘날, AI는 많은 분야에서 광범위하게 구현되고 있으며, 은행업에서 의료, 운송, 기술에 이르기까지 모든 산업을 변화시키고 있습니다.\n\n\n최근 들어 AI 인재에 대한 수요가 기하급수적으로 증가했고 이는 더 이상 실리콘 밸리에 국한되지 않습니다! 포브스에 따르면, AI 기술은 가장 수요가 많은 기술 중 하나라고 합니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n강의에서 만나요!",
      "target_audience": [
        "AI를 활용해 사업을 혁신하고자 하는 노련한 컨설턴트들.",
        "커리어를 향상시키고 포트폴리오를 쌓고자 하는 AI 실무자들.",
        "수익 극대화, 비용 절감, 비즈니스 최적화를 원하는 비전 있는 사업가들."
      ]
    },
    {
      "title": "Processamento de Linguagem Natural com Deep Learning",
      "url": "https://www.udemy.com/course/processamento-linguagem-natural-deep-learning-python/",
      "bio": "Crie um tradutor de idiomas e um classificador de sentimento com Transformer e Redes Convolucionais no TensorFlow 2.0",
      "objectives": [
        "Crie um Transformer, nova arquitetura criada pelo Google para qualquer tarefa de sequência para sequência (por exemplo, um tradutor de idiomas)",
        "Crie uma Rede Neural Convolucional especializada em Processamento de Linguagem Natural para qualquer tarefa de classificação (análise de sentimentos, por exemplo)",
        "Personalize os métodos de treinamento de redes neurais no TensorFlow 2.0",
        "Aprenda a criar camadas personalizadas no TensorFlow 2.0",
        "Use o Google Colab e o Tensorflow 2.0 para suas implementações de Inteligência Artificial",
        "Entenda como os algoritmos de inteligência artificial fazem com que os computadores dêem sentido à linguagem humana",
        "Entenda sobre o mecanismo de atenção, por trás dos algoritmos de PLN mais novos e mais poderosos"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Slides + recursos"
        ],
        "Redes neurais convolucionais para PLN - intuição": [
          "Introdução a redes neurais convolucionais",
          "Imagem para texto",
          "Redes neurais convolucionais para PLN"
        ],
        "Redes neurais convolucionais para PLN - implementação": [
          "Importação das bibliotecas",
          "Carregamento da base de dados",
          "Limpeza de dados 1",
          "Limpeza de dados 2",
          "Limpeza de dados 3",
          "Limpeza de dados 4",
          "Tokenização",
          "Padding (preenchimento)",
          "Divisão da base de dados",
          "Construção do modelo 1",
          "Construção do modelo 2",
          "Configuração dos parâmetros da rede neural",
          "Treinamento da rede neural",
          "Avaliação do modelo 1",
          "Avaliação do modelo 2",
          "Previsões com novos textos"
        ],
        "Arquitetura Transformer - intuição": [
          "Redes neurais recorrentes para PLN",
          "Arquitetura Transformer",
          "Mecanismo de atenção 1",
          "Mecanismo de atenção 2",
          "Mais detalhes sobre a arquitetura"
        ],
        "Arquitetura Transformer - implementação": [
          "Importação das bibliotecas e base de dados",
          "Limpeza dos dados",
          "Tokenização",
          "Remoção de sentenças muito longas",
          "Padding e batches",
          "Embedding",
          "Mecanismo de atenção 1",
          "Mecanismo de atenção 2",
          "Encoder 1",
          "Encoder 2",
          "Decoder 1",
          "Decoder 2",
          "Transformer 1",
          "Transformer 2",
          "Treinamento 1",
          "Treinamento 2",
          "Treinamento 3",
          "Treinamento 4",
          "Avaliação 1",
          "Avaliação 2"
        ],
        "Anexo I - Redes Neurais Artificiais": [
          "Perceptron de uma camada",
          "Redes multicamada - função soma e função de ativação",
          "Redes multicamada - cálculo do erro",
          "Descida do gradiente",
          "Cálculo do parâmetro delta",
          "Ajuste dos pesos com backpropagation",
          "Bias, erro, descida do gradiente estocástica e mais parâmetros",
          "Funções de ativação I",
          "Funções de ativação II"
        ],
        "Anexo II - Redes neurais recorrentes": [
          "O que são redes neurais recorrentes",
          "Problema do gradiente desaparecendo (vanish gradient problem)",
          "Long short term memory - LSTM",
          "Intuição prática",
          "Variações de LSTM"
        ],
        "Considerações finais": [
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Básico da linguagem Python",
        "Orientação a objetos",
        "É desejável que você já tenha tido algum contato com a API Keras do TensorFlow"
      ],
      "description": "A área de Processamento de Linguagem Natural - PLN (Natural Language Processing - NLP) é uma subárea da Inteligência Artificial que tem como objetivo tornar os computadores capazes de entender a linguagem humana, tanto escrita quanto falada. Alguns exemplo de aplicações práticas são: tradutores entre idiomas, tradução de texto para fala ou fala para texto, chatbots, sistemas automáticos de perguntas e respostas, sumarização de textos, geração automática de descrições para imagens, adição de legendas em vídeos, classificação de sentimentos em frases, dentre várias outras!\nAtualmente, este setor está cada vez mais necessitando de soluções de Processamento de Linguagem Natural, ou seja, aprender essa área pode ser a chave para trazer soluções reais para necessidades presentes e futuras. Baseado nisso, este curso foi projetado para quem deseja crescer ou iniciar uma nova carreira na área de Processamento de Linguagem Natural, obtendo uma sólida experiência nessa área utilizando modernas técnicas de Deep Learning e Redes Neurais Artificiais!\nAproveitaremos a enorme quantidade de dados de texto disponíveis on-line (duas bases de dados reais) e exploraremos duas das principais técnicas de PLN, o que lhe dará o poder necessário para enfrentar com êxito qualquer desafio do mundo real! O curso está dividido em duas partes:\nCriação de um classificador de sentimentos utilizando dados do Twitter e Redes Neurais Convolucionais\nCriação de um tradutor de idiomas, passando como entrada um texto em Inglês e tendo como retorno um texto em Português. Neste estudo de caso desenvolveremos passo a passo a arquitetura Transformer desenvolvida pelo Google\nUtilizaremos tecnologias modernas, como a linguagem Python, o TensorFlow 2.0 e o Google Colab, garantindo que você não tenha problemas com instalações ou configurações de softwares na sua máquina local.\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em deep learning (aprendizagem profunda)",
        "Pessoas interessadas em Processamento de Linguagem Natural",
        "Analistas de dados que queiram aumentar seu conhecimento na área de deep learning (aprendizagem profunda)",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial",
        "Qualquer pessoa que queira iniciar uma nova carreira e ter uma sólida experiência em PLN, adicionando estudos de casos eficientes ao seu portfólio"
      ]
    },
    {
      "title": "Python Programlama Kullanarak Veri Bilimi: Pandas A-Z™",
      "url": "https://www.udemy.com/course/python-programlama-kullanarak-veri-bilimi-pandas-a-ztm/",
      "bio": "Pandas'da uzman ol: Python ile Data Science (Veri Bilimi), Machine Learning (Makine Öğrenmesi) için Pandas kütüphanesi",
      "objectives": [
        "Python Anaconda Windows İşletim Sistemi Kurulum",
        "Python Anaconda Linux İşletim Sistemi Kurulum",
        "Python Jupyter Notebook’u İnceleme",
        "Jupyter Lab’ı İnceleme",
        "Meraklılarına python, pandas, data analiz, Doküman Tavsiyeleri",
        "Pandas Kütüphanesi Tanıtım",
        "Liste İle Python Pandas Serisi Oluşturma",
        "Sözlük İle Pandas Serisi Oluşturma",
        "Numpy Array’i İle Pandas Serisi Oluşturma",
        "Seri İçindeki Nesne Türleri",
        "Pandas Serilerinin Temel Özelliklerini İnceleme",
        "Pandas Serileri Üzerine En Sık Uygulananan Metodlar",
        "Pandas Serilerini İndexleme Ve Dilimleme",
        "Liste İle python Pandas DataFrame’i Oluşturma",
        "NumPy Array’i İle Pandas DataFrame’i oluşturma",
        "Sözlük İle Pandas DataFrame’i oluşturma",
        "Pandas DataFrame'lerinin Özelliklerini İnceleme",
        "Pandas DataFrame’lerinde Eleman Seçim İşlemleri 1",
        "Pandas DataFrame’lerinde Üst Düzey Eleman Seçimi: loc ve iloc Yapısı",
        "Pandas DataFrame’lerinde Koşullu İşlemler İle Elaman Seçimi",
        "Pandas DataFrame’lerine Sütun Ekleme",
        "Pandas Data Frame’lerinden Satır ve Sütun Çıkarma",
        "Pandas Dataframelerinde Boş(Null) Değerler",
        "Boş(Null) Değerleri Düşürme: Dropna() Fonksiyonu",
        "Boş(Null) Değerleri Doldurma: Fillna() Fonksiyonu",
        "Pandas DataFrame’lerinde İndex Ayarı",
        "Pandas DataFrame’lerinde Multi-İndex Ve İndex Hiyerarşisi",
        "Multi-İndex'li Pandas DataFrame'lerde Eleman Seçme İşlemi",
        "Multi-İndex'li DataFrame'lerde xs() Fonksiyonunu Kullanarak Eleman Seçme İşlemi",
        "Pandas Dataframe’lerini Birleştirme: Concat () Fonksiyonu",
        "Pandas Dataframe’lerini Birleştirme: Merge() Fonksiyonu",
        "Pandas Dataframe’lerini Birleştirme: Join() Fonksiyonu",
        "Seaborn Kütüphanesi İçerisinden Veri Seti Yükleme",
        "Veri Setini İnceleme",
        "Pandas DataFrame’lerinde Toplulaştırma Fonksiyonları",
        "Veri Setini İnceleme 2",
        "Pandas Dataframe’lerinde Gruplama İşlemleri Ve Toplulaştırma Fonksiyonlarının Birlikte Koordineli Kullanımı",
        "Seviye Toplulaştırma Fonksiyonları: Aggregate() Fonksiyonu",
        "İleri Seviye Toplulaştırma Fonksiyonları: Filter() Fonksiyonu",
        "İleri Seviye Toplulaştırma Fonksiyonları: Transform() Fonksiyonu",
        "İleri Seviye Toplulaştırma Fonksiyonları: Apply() Fonksiyonu",
        "Veri Setini İnceleme 3",
        "Pivot Tablolar",
        "Çalışma Dosyalarına Erişme Ve Dosyaları Hazır Hale Getirme",
        "Csv ve Txt Dosyaları İle Veri Girişi",
        "Excel Dosyaları İle Veri Girişi",
        "CSV Uzantılı Dosya Çıktısı Alma",
        "Excel Dosyası Olarak Çıktı Alma"
      ],
      "course_content": {
        "Python Kurulumlar(Anaconda Navigator, Jupyter Notebook, Jupyter Lab)": [
          "Anaconda Windows İşletim Sistemi Kurulum",
          "Anaconda Linux İşletim Sistemi Kurulum",
          "Kurs Notebook Project Dosya Linkleri",
          "Jupyter Notebook’u İnceleme",
          "Jupyter Lab’ı İnceleme",
          "Meraklılarına Python Pandas Doküman Tavsiyeleri",
          "Python Pandas hakkında Sık Sorulan Sorular"
        ],
        "Pandas Kütüphanesi Giriş": [
          "Pandas Kütüphanesi Tanıtım",
          "Quiz"
        ],
        "Pandas Kütüphanesinde Seri Yapıları": [
          "Liste İle Python Pandas Serisi Oluşturma",
          "Sözlük İle Pandas Serisi Oluşturma",
          "Numpy Array’i İle Pandas Serisi Oluşturma",
          "Seri İçindeki Nesne Türleri",
          "Pandas Serilerinin Temel Özelliklerini İnceleme",
          "Pandas Serileri Üzerine En Sık Uygulanan Metodlar",
          "Pandas Serilerini İndexleme Ve Dilimleme",
          "Quiz"
        ],
        "Pandas Kütüphanesinde DataFrame Yapıları": [
          "Liste İle python Pandas DataFrame’i Oluşturma",
          "NumPy Array’i İle Pandas DataFrame’i oluşturma",
          "Sözlük İle Pandas DataFrame’i oluşturma",
          "Pandas DataFrame'lerinin Özelliklerini İnceleme",
          "Quiz"
        ],
        "DataFrame Yapılarında Eleman Seçim İşlemleri": [
          "Pandas DataFrame’lerinde Eleman Seçim İşlemleri 1.Ders",
          "Pandas DataFrame’lerinde Eleman Seçim İşlemleri 2.Ders",
          "Pandas DataFrame’lerinde Üst Düzey Eleman Seçimi: loc ve iloc Yapısı 1.Ders",
          "Pandas DataFrame’lerinde Üst Düzey Eleman Seçimi: loc ve iloc Yapısı 2.Ders",
          "Pandas DataFrame’lerinde Üst Düzey Eleman Seçimi: loc ve iloc Yapısı 3.Ders",
          "Pandas DataFrame’lerinde Koşullu İşlemler İle Elaman Seçimi",
          "Quiz"
        ],
        "Pandas DataFrame'i Üzerinde Yapısal İşlemler": [
          "Pandas DataFrame’lerine Sütun Ekleme",
          "Pandas Data Frame’lerinden Satır ve Sütun Çıkarma",
          "Pandas Dataframelerinde Boş(Null) Değerler",
          "Boş(Null) Değerleri Düşürme: Dropna() Fonksiyonu",
          "Boş(Null) Değerleri Doldurma: Fillna() Fonksiyonu",
          "Pandas DataFrame’lerinde İndex Ayarı",
          "Quiz"
        ],
        "Multi-Index'li DataFrame Yapıları": [
          "Pandas DataFrame’lerinde Multi-İndex Ve İndex Hiyerarşisi",
          "Multi-İndex'li Pandas DataFrame'lerde Eleman Seçme İşlemi",
          "Multi-İndex'li DataFrame'lerde xs() Fonksiyonunu Kullanarak Eleman Seçme İşlemi",
          "Quiz"
        ],
        "Pandas DataFrame'inde Yapısal Birleştirme İşlemleri": [
          "Pandas Dataframe’lerini Birleştirme Concat () Fonksiyonu",
          "Pandas Dataframe’lerini Birleştirme: Merge() Fonksiyonu 1. Ders",
          "Pandas Dataframe’lerini Birleştirme: Merge() Fonksiyonu 2. Ders",
          "Pandas Dataframe’lerini Birleştirme: Merge() Fonksiyonu 3. Ders",
          "Pandas Dataframe’lerini Birleştirme: Merge() Fonksiyonu 4. Ders",
          "Pandas Dataframe’lerini Birleştirme: Merge() Fonksiyonu 5. Ders",
          "Pandas Dataframe’lerini Birleştirme: Join() Fonksiyonu",
          "Quiz"
        ],
        "DataFrame Üzerine Uygulanabilecek Fonksiyonlar": [
          "Seaborn Kütüphanesi İçerisinden Veri Seti Yükleme",
          "Veri Setini İnceleme 1",
          "Pandas DataFrame’lerinde Toplulaştırma Fonksiyonları",
          "Veri Setini İnceleme 2",
          "Gruplama İşlemleri, Toplulaştırma Fonksiyonlarının Birlikte Koordineli Kullanımı",
          "İleri Seviye Toplulaştırma Fonksiyonları: Aggregate() Fonksiyonu",
          "İleri Seviye Toplulaştırma Fonksiyonları: Filter() Fonksiyonu",
          "İleri Seviye Toplulaştırma Fonksiyonları: Transform() Fonksiyonu",
          "İleri Seviye Toplulaştırma Fonksiyonları: Apply() Fonksiyonu",
          "Quiz"
        ],
        "Pandas Kütüphanesinde Pivot Tablolar": [
          "Veri Setini İnceleme 3",
          "Pivot Tablolar",
          "Quiz"
        ]
      },
      "requirements": [
        "Temel Python Programlama Dili Bilgisi",
        "Temel Numpy Kütüphanesi Bilgisi",
        "Temel Matematik bilgisi",
        "Kurs videolarını eksiksiz, sonuna kadar ve sırayla izlemek.",
        "İnternet Bağlantısı",
        "Cep telefonu, bilgisayar veya tablet gibi dersi izleyebileceğiniz herhangi bir cihaz.",
        "Öğrenme kararlılığı ve sabır."
      ],
      "description": "Merhabalar,\n\"Python Programlama Kullanarak Veri Bilimi: Pandas A-Z™\" kursuna hoşgeldiniz\nPandas'da uzman ol: Python ile Data Science (Veri Bilimi), Machine Learning (Makine Öğrenmesi) için Pandas kütüphanesi\n21. Yüzyılın en popüler mesleklerinden birisi olarak görülen veri bilimi için gerekli olan PANDAS Kütüphanesinin mantığını kavramaya çalışacağımız bu eğitim ile bir çok gerçek hayat uygulaması üzerinden çalışma yapacağız. Pandas, pandas python, python pandas, python pandas numpy, numpy pandas, pandas numpy, python numpy pandas, pandas bootcamp, numpy pandas matplotlib\nKurs içeriği gerçek hayat senaryoları ile oluşturulmuştur ve sıfırdan başlayanları PANDAS Kütüphanesi kapsamında ileriye taşımayı hedeflemektedir.\nPANDAS Veri bilimi alanında en çok kullanılan kütüphanelerden bir tanesidir.\nEvet, Veri bilimi ihtiyaçlarının 2026 yılına kadar 11,5 milyon iş fırsatı yaratacağını biliyor musunuz?\nVeri bilimi kariyerleri için ortalama maaşın 100.000 dolar olduğunu biliyor musunuz?\nVeri Bilimi Kariyerleri Geleceği Şekillendiriyor.\nVeri bilimi ve Makine öğrenimi (data science and machine learning) olmadan yaşamımızın hayalini kurmak zordur. Kelime tahmin sistemi, e-posta filtreleme ve Amazon'un Alexa'sı ve iPhone'nun Siri'si gibi sanal kişisel yardımcılar, makine öğrenimi algoritmalarına ve matematiksel modellere dayalı olarak çalışan teknolojilerdir.\nVeri bilimi ve Makine öğrenimi yalnızca kelime tahmin sistemi veya akıllı telefon ses tanıma özelliği için fayda sağlamaz. Makine öğrenimi ve veri bilimi, yeni sektörlere ve yeni sorunlara sürekli olarak uygulanır.\nÖzetle Devlet güvenliğinden, günlük hayatta kullandığımız uygulamalara kadar hemen hemen her alanda veri bilimi uzmanlarına ihtiyaç vardır. Milyonlarca işletme ve devlet dairesi, başarılı olmak ve müşterilerine daha iyi hizmet vermek için büyük verilere güveniyor. Dolayısıyla veri bilimi kariyerleri yüksek talep görüyor.\nİşverenin en çok talep ettiği becerilerden birini öğrenmek istiyorsanız?\nPython programlama dilini kullanarak Machine learning ve deep learning alanında pandas kütüphanesini kullanmak istiyorsanız?\nVeri bilimine giden yolda kendinizi geliştirmek istiyor ve ilk adımı atmak istiyorsanız. Her durumda, doğru yerdesiniz!\n\"Python Programlama Kullanarak Veri Bilimi: Pandas A-Z™\" kursunu sizin için tasarladık.\nDerste, gerçek hayattan örnekler ile konuları kavramış olacaksınız. Bu kurs ile adım adım Pandas kütüphanesini öğreneceksiniz.\nVeri Bilimi dünyasının kapısını aralayacak ve bundan sonrası için daha derine inme kabiliyetine sahip olacaksınız.\nBu Pandas kursu herkes içindir!\nDaha önce deneyiminiz yoksa sorun değil! Bu kurs, yeni başlayanlardan profesyonellere kadar herkese (bir tazeleme olarak) öğretmek için ustalıkla tasarlanmıştır.\nKurs süresince aşağıdaki konuları öğreneceksiniz:\nAnaconda Windows İşletim Sistemi Kurulum\nAnaconda Linux İşletim Sistemi Kurulum\nJupyter Notebook’u İnceleme\nJupyter Lab’ı İnceleme\nMeraklılarına Doküman Tavsiyeleri\nPandas Kütüphanesi Tanıtım\nListe İle Python Pandas Serisi Oluşturma\nSözlük İle Pandas Serisi Oluşturma\nNumpy Array’i İle Pandas Serisi Oluşturma\nSeri İçindeki Nesne Türleri\nPandas Serilerinin Temel Özelliklerini İnceleme\nPandas Serileri Üzerine En Sık Uygulananan Metodlar\nPandas Serilerini İndexleme Ve Dilimleme\nListe İle python Pandas DataFrame’i Oluşturma\nNumPy Array’i İle Pandas DataFrame’i oluşturma\nSözlük İle Pandas DataFrame’i oluşturma\nPandas DataFrame'lerinin Özelliklerini İnceleme\nPandas DataFrame’lerinde Eleman Seçim İşlemleri 1\nPandas DataFrame’lerinde Üst Düzey Eleman Seçimi: loc ve iloc Yapısı\nPandas DataFrame’lerinde Koşullu İşlemler İle Elaman Seçimi\nPandas DataFrame’lerine Sütun Ekleme\nPandas Data Frame’lerinden Satır ve Sütun Çıkarma\nPandas Dataframelerinde Boş(Null) Değerler\nBoş(Null) Değerleri Düşürme: Dropna() Fonksiyonu\nBoş(Null) Değerleri Doldurma: Fillna() Fonksiyonu\nPandas DataFrame’lerinde İndex Ayarı\nPandas DataFrame’lerinde Multi-İndex Ve İndex Hiyerarşisi\nMulti-İndex'li Pandas DataFrame'lerde Eleman Seçme İşlemi\nMulti-İndex'li DataFrame'lerde xs() Fonksiyonunu Kullanarak Eleman Seçme İşlemi\nPandas Dataframe’lerini Birleştirme: Concat () Fonksiyonu\nPandas Dataframe’lerini Birleştirme: Merge() Fonksiyonu\nPandas Dataframe’lerini Birleştirme: Join() Fonksiyonu\nSeaborn Kütüphanesi İçerisinden Veri Seti Yükleme\nVeri Setini İnceleme\nPandas DataFrame’lerinde Toplulaştırma Fonksiyonları\nVeri Setini İnceleme 2\nPandas Dataframe’lerinde Gruplama İşlemleri Ve Toplulaştırma Fonksiyonlarının Birlikte Koordineli Kullanımı\nSeviye Toplulaştırma Fonksiyonları: Aggregate() Fonksiyonu\nİleri Seviye Toplulaştırma Fonksiyonları: Filter() Fonksiyonu\nİleri Seviye Toplulaştırma Fonksiyonları: Transform() Fonksiyonu\nİleri Seviye Toplulaştırma Fonksiyonları: Apply() Fonksiyonu\nVeri Setini İnceleme 3\nPivot Tablolar\nÇalışma Dosyalarına Erişme Ve Dosyaları Hazır Hale Getirme\nCsv ve Txt Dosyaları İle Veri Girişi\nExcel Dosyaları İle Veri Girişi\nCSV Uzantılı Dosya Çıktısı Alma\nExcel Dosyası Olarak Çıktı Alma\nPandas\nPandas Python\nPython pandas numpy\nNumpy pandas\nPython Numpy pandas\nNumpy pandas matplotlib\nGüncel kursum ile kendinizi güncel tutma ve Pandas becerileri ile donatma şansınız olacak. Ayrıca, öğrenmenizi desteklemek ve sorularınızı yanıtlamak için sürekli olarak hazır olacağımı söylemekten mutluluk duyuyorum.\nNeden bu kursu almak istiyorsunuz?\nCevabımız basit: Öğretimin kalitesi.\nİster makine öğrenimi, ister finans alanında çalışıyor olun, ister web geliştirme veya veri bilimi alanında kariyer yapıyor olun, Python ve veri bilimi(Data Science) öğrenebileceğiniz en önemli becerilerden biridir. Python'ın basit söz dizimi özellikle masaüstü, web ve iş uygulamaları için uygundur.\nOAK Academy 'deki Python eğitmenleri, yazılım geliştirmeden veri analizine kadar her konuda uzmandırlar ve her seviyedeki öğrencilere yönelik etkili, samimi eğitimleriyle bilinirler.\nEğitmenlerimiz Python programlama dili gibi her alanda yukarıda anlatıldığı şekilde eğitim kalitesi sunmaktadır.\nLondra merkezli OAK Academy, çevrimiçi bir eğitim şirketidir. OAK Academy, 1000 saatin üzerinde video eğitim derslerinin bulunduğu Udemy platformunda Bilişim, Yazılım, Tasarım, İngilizce, Portekizce, İspanyolca, Türkçe ve bir çok farklı dilde geliştirme alanında eğitim vermektedir. OAK Akademi, yeni dersler yayınlayarak hem eğitim seri sayısını artırmakta hem de güncellenerek daha önce yayınlanmış derslerin tüm yeniliklerinden öğrencilerini haberdar etmektedir.\nKaydolduğunuzda, OAK Academy'nin deneyimli geliştiricilerin uzmanlığını hissedeceksiniz. Öğrencilerin hocalarımıza ilettikleri sorular hocalarımız tarafından en geç 48 saat içerisinde cevaplanmaktadır.\nVideo ve Ses Üretim Kalitesi\nTüm videolarımız, size en iyi öğrenme deneyimini sağlamak için yüksek kaliteli video ve ses olarak oluşturulur/üretilir.\nBu kursta şunlara sahip olacaksınız:\nKursa Ömür Boyu Erişim\nSoru-Cevap bölümünde Hızlı ve Kolay Destek\nİndirilmeye Hazır Udemy Bitirme Sertifikası\nHer türlü soruyu yanıtlayarak tam destek sunuyoruz.\n\n\n\"Python Programlama Kullanarak Veri Bilimi: Pandas A-Z™\" kursu.\nHemen gelin! Kursta görüşürüz!",
      "target_audience": [
        "Veri bilimi için gerekli olan Pandas Kütüphanesini öğrenmek isteyen",
        "Python Programlama Dili ve Veri bilimi alanında kendini geliştirmek isteyenler",
        "Veri bilimi alanında kariyer hedefi olanlar"
      ]
    },
    {
      "title": "Python Programlama Kullanarak Veri Bilimi: NumPy | A-Z™",
      "url": "https://www.udemy.com/course/python-programlama-kullanarak-veri-bilimi-numpy-a-ztm/",
      "bio": "Python'da uzman ol: Python ile Data Science (Veri Bilimi), Machine Learning (Makine Öğrenmesi) için Numpy kütüphanesi",
      "objectives": [
        "Python Anaconda Windows İşletim Sistemi Kurulum",
        "Python Anaconda Linux İşletim Sistemi Kurulum",
        "Python Jupyter Notebook’u İnceleme",
        "Python Jupyter Lab’ı İnceleme",
        "Python ve NumPy meraklılarına Doküman Tavsiyeleri",
        "NumPy Kütüphanesi Tanıtım",
        "Python’da NumPy’ın Gücü",
        "Numpy Array() Fonksiyonu İle NumPy Array’i Oluşturma",
        "Python Zeros() Fonksiyonu İle NumPy Array’i Oluşturma",
        "PthyonOnes() Fonksiyonu İle NumPy Array’i Oluşturma",
        "Python Full() Fonksiyonu İle NumPy Array’i Oluşturma",
        "Python Arange() Fonksiyonu İle NumPy Array’i Oluşturma",
        "Python Eye() Fonksiyonu İle NumPy Array’i Oluşturma",
        "Python Linspace() Fonksiyonu İle NumPy Array’i Oluşturma",
        "Python Random() Fonksiyonu İle NumPy Array’i Oluşturma",
        "NumPy Array’inin Özellikleri",
        "Numpy Array’ini Yeniden Şekillendirme: Reshape() Fonksiyonu",
        "Numpy Array’inin En Büyük Elemanını Tespit Etme: Max(), Argmax() Fonksiyonları",
        "Numpy Array’inin En Küçük Elemanını Tespit Etme: Min(), Argmin() Fonksiyonları",
        "Numpy Array’inin En Küçük Elemanını Tespit Etme: Min(), Argmin() Fonksiyonları",
        "Tek Boyutlu Numpy Array’lerini Bölme: Split() Fonksiyonu",
        "İki Boyutlu Numpy Array’lerini Bölme: Split(), Vsplit, Hsplit() Fonksiyonu",
        "Numpy Array’lerini Sıralama: Sort() Fonksiyonu",
        "Numpy Array’lerini İndexleme",
        "Tek Boyutlu Numpy Array’lerini Dilimleme",
        "İki Boyutlu Numpy Array’lerini Dilimleme",
        "Python Tek Boyutlu Array’lerde Değer Atama İşlemi",
        "İki Boyutlu Array’lerde Değer Atama İşlemi",
        "Tek Boyutlu Arrray’lere Fancy İndex İle İşlem Yapma",
        "İki Boyutlu Arrray’lere Fancy İndex İle İşlem Yapma",
        "Fancy İndex ile Normal İndex’lemeyi birlikte kullanma",
        "Fancy İndex ile Normal Dilimlemenin birlikte kullanma",
        "Karşılaştırma Operatörleri İle İşlemler",
        "Numpy Kütüphanesi’nde Aritmetik İşlemler",
        "Numpy Kütüphanesi’nde İstatistiksel İşlemler",
        "Numpy İle İkinci Dereceden Denklem Çözümü",
        "Veri bilimi her yerdedir.",
        "Daha iyi veri bilimi uygulamaları, şirketlerin gereksiz maliyetleri azaltmalarını, bilgi işlemi otomatikleştirmelerini ve pazarları analiz etmelerini sağlıyor.",
        "Temel olarak veri bilimi, rekabetçi bir küresel ortamda ilerlemenin anahtarıdır.",
        "İster makine öğrenimi, ister veri madenciliği, ister veri analizi ile ilgileniyor olun, Udemy'de size uygun bir kurs vardır.",
        "Python ile veri bilimi (data science)",
        "What is data science? We have more data than ever before. But data alone cannot tell us much about the world around us.",
        "Python, Veri bilimi, Data science, Makine öğrenmesi, Python veri bilimi, İleri seviye python, machine learning (makine öğrenmesi)",
        "İstatistik, Python, Temel istatistik, İstatistik, Veri analizi, Python ile veri analizi, Data science Python’a geçmeden temel istatistik ile veri bilimi",
        "Veri bilimi, veri bilimi için python, veri bilimi okulu, veri bilimine giris, veri madenciliği bilimi analizi ve r programlama, r ile veri bilimi, python veri",
        "Makine öğrenimi yalnızca kelime tahmin sistemi veya akıllı telefon ses tanıma özelliği için fayda sağlamaz.",
        "Makine öğrenimi, yeni sektörlere ve yeni sorunlara sürekli olarak uygulanır.",
        "İster pazarlamacı, ister video oyunu tasarımcısı, ister programcı olun, Udemy'de makine öğrenimini işinize uygulamanıza yardımcı olacak bir kurs vardır.",
        "Makine öğrenimi olmadan yaşamımızın hayalini kurmak zordur.",
        "Machine Learning( makine öğrenmesi), deep learning, veri bilimi hayatın her alanında kullanılan teknolojilerdir."
      ],
      "course_content": {},
      "requirements": [
        "Temel Python bilgisi",
        "Temel Matematik bilgisi",
        "Kurs videolarını eksiksiz, sonuna kadar ve sırayla izlemek.",
        "Cep telefonu, bilgisayar veya tablet gibi dersi izleyebileceğiniz herhangi bir cihaz.",
        "Python ile data science (veri bilimi) öğrenme arzusu",
        "Python numpy kütüphanesi ile veri bilimi öğrenme isteği",
        "Numpy kütüphanesi ile ver analizi (data analysis) nasıl yapılır öğrenme isteği",
        "Machine learning (makine öğrenmesi), deep learning ve big data öğrenme isteği",
        "İnternet Bağlantısı",
        "Öğrenme kararlılığı ve sabır"
      ],
      "description": "\"Python Programlama Kullanarak Veri Bilimi: NumPy | A-Z™\" kursumuza hoşgeldiniz.\nPython'da uzman ol: Python ile Data Science (Veri Bilimi), Machine Learning(Makine Öğrenmesi) için Numpy kütüphanesi\n21. Yüzyılın en popüler mesleklerinden birisi olarak görülen veri bilimi için gerekli olan NumPy Kütüphanesinin mantığını kavramaya çalışacağımız bu eğitim ile bir çok gerçek hayat uygulaması üzerinden çalışma yapacağız\nKurs içeriği gerçek hayat senaryoları ile oluşturulmuştur ve sıfırdan başlayanları NumPy Kütüphanesi kapsamında ileriye taşımayı hedeflemektedir.\nNumpy Veri bilimi alanında en çok kullanılan kütüphanelerden bir tanesidir.\nEvet, Veri bilimi ihtiyaçlarının 2026 yılına kadar 11,5 milyon iş fırsatı yaratacağını biliyor musunuz?\nVeri bilimi kariyerleri için ortalama maaşın 100.000 dolar olduğunu biliyor musunuz?\nVeri Bilimi Kariyerleri Geleceği Şekillendiriyor.\nVeri bilimi ve Makine öğrenimi olmadan yaşamımızın hayalini kurmak zordur. Kelime tahmin sistemi, e-posta filtreleme ve Amazon'un Alexa'sı ve iPhone'nun Siri'si gibi sanal kişisel yardımcılar, makine öğrenimi algoritmalarına ve matematiksel modellere dayalı olarak çalışan teknolojilerdir.\nVeri bilimi ve Makine öğrenimi (Machine Learning) yalnızca kelime tahmin sistemi veya akıllı telefon ses tanıma özelliği için fayda sağlamaz. Makine öğrenimi ve veri bilimi, yeni sektörlere ve yeni sorunlara sürekli olarak uygulanır.\nÖzetle Devlet güvenliğinden, günlük hayatta kullandığımız uygulamalara kadar hemen hemen her alanda veri bilimi uzmanlarına ihtiyaç vardır. Milyonlarca işletme ve devlet dairesi, başarılı olmak ve müşterilerine daha iyi hizmet vermek için büyük verilere güveniyor. Dolayısıyla veri bilimi kariyerleri yüksek talep görüyor.\nİşverenin en çok talep ettiği becerilerden birini öğrenmek istiyorsanız?\nPython programlama dilini kullanarak Machine learning (Makine Öğrenmesi) ve deep learning (Derin Öğrenme) alanında Numpy kütüphanesini kullanmak istiyorsanız?\nVeri bilimine giden yolda kendinizi geliştirmek istiyor ve ilk adımı atmak istiyorsanız. Her durumda, doğru yerdesiniz!\n\"Python Programlama Kullanarak Veri Bilimi: NumPy | A-Z™\" kursunu sizin için tasarladık.\nDerste, gerçek hayattan örnekler ile konuları kavramış olacaksınız. Bu kurs ile adım adım Numpy kütüphanesini öğreneceksiniz.\nVeri Bilimi dünyasının kapısını aralayacak ve bundan sonrası için daha derine inme kabiliyetine sahip olacaksınız.\nBu Numpy kursu herkes içindir!\nDaha önce deneyiminiz yoksa sorun değil! Bu kurs, yeni başlayanlardan profesyonellere kadar herkese (bir tazeleme olarak) öğretmek için ustalıkla tasarlanmıştır.\nVeri bilimi her yerdedir. Daha iyi veri bilimi uygulamaları, şirketlerin gereksiz maliyetleri azaltmalarını, bilgi işlemi otomatikleştirmelerini ve pazarları analiz etmelerini sağlıyor. Temel olarak veri bilimi, rekabetçi bir küresel ortamda ilerlemenin anahtarıdır.\nKurs süresince aşağıdaki konuları öğreneceksiniz:\nAnaconda Windows İşletim Sistemi Kurulum\nAnaconda Linux İşletim Sistemi Kurulum\nJupyter Notebook’u İnceleme\nJupyter Lab’ı İnceleme\nMeraklılarına Doküman Tavsiyeleri\nNumPy Kütüphanesi Tanıtım\nPython’da NumPy’ın Gücü\nArray() Fonksiyonu İle NumPy Array’i Oluşturma\nZeros() Fonksiyonu İle NumPy Array’i Oluşturma\nOnes() Fonksiyonu İle NumPy Array’i Oluşturma\nFull() Fonksiyonu İle NumPy Array’i Oluşturma\nArange() Fonksiyonu İle NumPy Array’i Oluşturma\nEye() Fonksiyonu İle NumPy Array’i Oluşturma\nLinspace() Fonksiyonu İle NumPy Array’i Oluşturma\nRandom() Fonksiyonu İle NumPy Array’i Oluşturma\nNumPy Array’inin Özellikleri\nNumpy Array’ini Yeniden Şekillendirme: Reshape() Fonksiyonu\nNumpy Array’inin En Büyük Elemanını Tespit Etme: Max(), Argmax() Fonksiyonları\nNumpy Array’inin En Küçük Elemanını Tespit Etme: Min(), Argmin() Fonksiyonları\nNumpy Array’lerini Birleştirme: Concatenate() Fonksiyonu\nTek Boyutlu Numpy Array’lerini Bölme: Split() Fonksiyonu\nİki Boyutlu Numpy Array’lerini Bölme: Split(), Vsplit, Hsplit() Fonksiyonu\nNumpy Array’lerini Sıralama: Sort() Fonksiyonu\nNumpy Array’lerini İndexleme\nTek Boyutlu Numpy Array’lerini Dilimleme\nİki Boyutlu Numpy Array’lerini Dilimleme\nTek Boyutlu Array’lerde Değer Atama İşlemi\nİki Boyutlu Array’lerde Değer Atama İşlemi\nTek Boyutlu Arrray’lere Fancy İndex İle İşlem Yapma\nİki Boyutlu Arrray’lere Fancy İndex İle İşlem Yapma\nFancy İndex ile Normal İndex’lemeyi birlikte kullanma\nFancy İndex ile Normal Dilimlemenin birlikte kullanma\nKarşılaştırma Operatörleri İle İşlemler\nNumpy Kütüphanesi’nde Aritmetik İşlemler\nNumpy Kütüphanesi’nde İstatistiksel İşlemler\nNumpy İle İkinci Dereceden Denklem Çözümü\nPython ile veri bilimi, data analiz\nPython numpy\nMachine Learning (Makine Öğrenmesi)\nData anlaysis (veri analizi)\nBig Data\nPython ile istatistik, temel istatistik\nPython Data analysis, big data\nGüncel kursum ile kendinizi güncel tutma ve Numpy becerileri ile donatma şansınız olacak. Ayrıca, öğrenmenizi desteklemek ve sorularınızı yanıtlamak için sürekli olarak hazır olacağımı söylemekten mutluluk duyuyorum.\nNeden bu kursu almak istiyorsunuz?\nCevabımız basit: Öğretimin kalitesi.\nİster makine öğrenimi, ister finans alanında çalışıyor olun, ister web geliştirme veya veri bilimi alanında kariyer yapıyor olun, Python ve veri bilimi(Data Science) öğrenebileceğiniz en önemli becerilerden biridir. Python'ın basit söz dizimi özellikle masaüstü, web ve iş uygulamaları için uygundur.\nOAK Academy 'deki Python eğitmenleri, yazılım geliştirmeden veri analizine kadar her konuda uzmandırlar ve her seviyedeki öğrencilere yönelik etkili, samimi eğitimleriyle bilinirler.\nEğitmenlerimiz Python programlama dili gibi her alanda yukarıda anlatıldığı şekilde eğitim kalitesi sunmaktadır.\nLondra merkezli OAK Academy, çevrimiçi bir eğitim şirketidir. OAK Academy, 1000 saatin üzerinde video eğitim derslerinin bulunduğu Udemy platformunda Bilişim, Yazılım, Tasarım, İngilizce, Portekizce, İspanyolca, Türkçe ve bir çok farklı dilde geliştirme alanında eğitim vermektedir. OAK Akademi, yeni dersler yayınlayarak hem eğitim seri sayısını artırmakta hem de güncellenerek daha önce yayınlanmış derslerin tüm yeniliklerinden öğrencilerini haberdar etmektedir.\nKaydolduğunuzda, OAK Academy'nin deneyimli geliştiricilerin uzmanlığını hissedeceksiniz. Öğrencilerin hocalarımıza ilettikleri sorular hocalarımız tarafından en geç 48 saat içerisinde cevaplanmaktadır.\nUdemy, yeni verileri nasıl görselleştireceğinizi ve bunlara nasıl yanıt vereceğinizi öğrenmenize ve ayrıca yenilikçi yeni teknolojiler geliştirmenize yardımcı olacak yüksek puan alan veri bilimi kursları sunmaktadır. İster makine öğrenimi, ister veri madenciliği, ister veri analizi ile ilgileniyor olun, Udemy'de size uygun bir kurs vardır.\nVideo ve Ses Üretim Kalitesi\nTüm videolarımız, size en iyi öğrenme deneyimini sağlamak için yüksek kaliteli video ve ses olarak oluşturulur/üretilir.\nBu kursta şunlara sahip olacaksınız:\nKursa Ömür Boyu Erişim\nSoru-Cevap bölümünde Hızlı ve Kolay Destek\nİndirilmeye Hazır Udemy Bitirme Sertifikası\nHer türlü soruyu yanıtlayarak tam destek sunuyoruz.\n\n\n“Python Programlama Kullanarak Veri Bilimi: NumPy | A-Z™” kursu.\nHemen gelin! Kursta görüşürüz!\nEnglish Version:\nHello dear,\n\nPython instructors on Udemy specialize in everything from software development to data analysis and are known for their effective, friendly instruction for students of all levels.\nUdemy offers highly-rated data science courses that will help you learn how to visualize and respond to new data, as well as develop innovative new technologies. Whether you’re interested in machine learning, data mining, or data analysis, Udemy has a course for you.\nFor every topic, the instructor first teaches the theory then helps you implement it from scratch. This taught me both the \"why\" and the \"how\", and I believe that this is an effective way to learn. Thank you for a great course!\nData science is everywhere. Better data science practices are allowing corporations to cut unnecessary costs, automate computing, and analyze markets. Essentially, data science is the key to getting ahead in a competitive global climate.\nWhat is Data Science?\nWe have more data than ever before. But data alone cannot tell us much about the world around us. We need to interpret the information and discover hidden patterns. This is where data science comes in. Data science uses algorithms to understand raw data. The main difference between data science and traditional data analysis is its focus on prediction. Data science seeks to find patterns in data and use those patterns to predict future data. It draws on machine learning to process large amounts of data, discover patterns, and predict trends. Data science includes preparing, analyzing, and processing data. It draws from many scientific fields, and as a science, it progresses by creating new algorithms to analyze data and validate current methods.\n\nLearn more about Python\nWhether you work in machine learning or finance or are pursuing a career in web development or data science, Python is one of the most important skills you can learn. Python's simple syntax is especially suited for desktop, web, and business applications. Python's design philosophy emphasizes readability and usability. Python was developed upon the premise that there should be only one way (and preferably one obvious way) to do things, a philosophy that has resulted in a strict level of code standardization. The core programming language is quite small and the standard library is also large. In fact, Python's large library is one of its greatest benefits, providing a variety of different tools for programmers suited for many different tasks.\n\nPython vs R:\nPython is a general-purpose, object-oriented, high-level programming language. Whether you work in artificial intelligence or finance or are pursuing a career in web development or data science, Python is one of the most important skills you can learn. Python's simple syntax is especially suited for desktop, web, and business applications. Python's design philosophy emphasizes readability and usability. Python was developed on the premise that there should be only one way (and preferably, one obvious way) to do things, a philosophy that resulted in a strict level of code standardization. The core programming language is quite small and the standard library is also large. In fact, Python's large library is one of its greatest benefits, providing different tools for programmers suited for a variety of tasks.\n\nPython and R are two of today's most popular programming tools. When deciding between Python and R, you need to think about your specific needs. On one hand, Python is relatively easy for beginners to learn, is applicable across many disciplines, has a strict syntax that will help you become a better coder, and is fast to process large datasets. On the other hand, R has over 10,000 packages for data manipulation, is capable of easily making publication-quality graphics, boasts superior capability for statistical modeling, and is more widely used in academia, healthcare, and finance.\nWhat is machine learning?\nMachine learning describes systems that make predictions using a model trained on real-world data. For example, let's say we want to build a system that can identify if a cat is in a picture. We first assemble many pictures to train our machine learning model. During this training phase, we feed pictures into the model, along with information around whether they contain a cat. While training, the model learns patterns in the images that are the most closely associated with cats. This model can then use the patterns learned during training to predict whether the new images that it's fed contain a cat. In this particular example, we might use a neural network to learn these patterns, but machine learning can be much simpler than that. Even fitting a line to a set of observed data points, and using that line to make new predictions, counts as a machine learning model.\nWhat is machine learning used for?\nMachine learning is being applied to virtually every field today. That includes medical diagnoses, facial recognition, weather forecasts, image processing, and more. In any situation in which pattern recognition, prediction, and analysis are critical, machine learning can be of use. Machine learning is often a disruptive technology when applied to new industries and niches. Machine learning engineers can find new ways to apply machine learning technology to optimize and automate existing processes. With the right data, you can use machine learning technology to identify extremely complex patterns and yield highly accurate predictions.\nDoes machine learning require coding?\nIt's possible to use machine learning without coding, but building new systems generally requires code. For example, Amazon’s Rekognition service allows you to upload an image via a web browser, which then identifies objects in the image. This uses a pre-trained model, with no coding required. However, developing machine learning systems involves writing some Python code to train, tune, and deploy your models. It's hard to avoid writing code to pre-process the data feeding into your model. Most of the work done by a machine learning practitioner involves cleaning the data used to train the machine. They also perform “feature engineering” to find what data to use and how to prepare it for use in a machine learning model. Tools like AutoML and SageMaker automate the tuning of models. Often only a few lines of code can train a model and make predictions from it. A\n\nHope you enjoy the course,\n\nSee you in the course",
      "target_audience": [
        "Veri bilimi için gerekli olan NumPy Kütüphanesini öğrenmek isteyen",
        "Python Programlama Dili ve Veri bilimi alanında kendini geliştirmek isteyenler",
        "Veri bilimi alanında kariyer hedefi olanlar",
        "Python ile veri bilimi(data science) öğrenmek isteyen",
        "Python ile Machine learning(makine öğrenmesi) temellerini oluşturmak isteyen",
        "Data science (veri bilimi) kariyer hedefi olanlar",
        "Python ile veri bilimi, veri analizi, makine öğrenmesi, deep learning hakkında iş planı yapmak isteyenler"
      ]
    },
    {
      "title": "Learn Algorithms And Data Structure From Zero To Hero in JS",
      "url": "https://www.udemy.com/course/learn-algorithms-and-data-structure-from-zero-to-hero-in-js/",
      "bio": "Algorithms and data structure using JavaScript with implementations from zero to expert in ARABIC",
      "objectives": [
        "Learn Algorithms In JavaScript",
        "Learn Data Structure In JavaScript",
        "Learn Recursion",
        "Learn Problem Solving Skills",
        "Learn Linked List in JavaScript",
        "Learn Binary Search Tree In JavaScript",
        "Learn Stack and Queue In JavaScript",
        "Learn Sorting Algorithms In JavScript",
        "Learn Searching Algorithms In JavaScript",
        "Learn Graph in JavaScript"
      ],
      "course_content": {
        "Algorithms Concepts": [
          "Introduction",
          "2-What is Algorithm",
          "3-Time and Space Complexity",
          "4-Big O Notation",
          "5-Array and Object Big O",
          "6-fibonacci sequence",
          "7-factorial of number",
          "8-Prime number",
          "9-Power of Two",
          "10-What is recursion",
          "11-Recursion Fibonacci",
          "12-Recursion Factorial",
          "13-Linear search algorithm",
          "14-Binary Search algorithm",
          "15-bubble sort",
          "16-bubble sort solution",
          "17-Insertion sort",
          "18-Insertion sort solution",
          "19-Quick sort",
          "20-Quick sort solution",
          "21-Merge Sort",
          "22-Merge sort solution"
        ],
        "Data Structure Concepts": [
          "23-Introduction",
          "24-Arrays",
          "25-Objects",
          "26-Set",
          "27-Map",
          "28-Stack overview",
          "29-Stack implementation",
          "30-Queue Overview",
          "31-Queue implementation",
          "32-Optimized Queue",
          "33-Cicular Queue Overview",
          "34-Circular queue implementation",
          "35-Linked List Introduction",
          "36-Linked List Class",
          "37-Linked List prepend",
          "38-Linked List print",
          "39-Linked List Append",
          "40-Linked List Insert",
          "41-Linked List Remove with index",
          "42-Linked List Remove Node with value",
          "43-Linked List Search",
          "44-Linked List Reverse",
          "45-Linked List With Tail and Head Overview",
          "46-Linked list with head and tail implementation",
          "47-Implement stack using linked list",
          "48-Implement queue using linked list",
          "49-Douply linked list",
          "50-Hash table overview",
          "51-Hash table hash function",
          "52-Hash table set,get,remove functions",
          "53-Hash table display and test",
          "54-Hash table collision",
          "55-Tree overview",
          "56-Binary Search tree overview",
          "57-Binary search tree classes",
          "58-Binary search tree insert",
          "59-Binary search tree search",
          "60-Binary Search Tree Depth First Search (PreOrder)",
          "61-Binary Search Tree Depth First Search (InOrder)",
          "62-Binary Search Tree Depth First Search (PostOrder)",
          "63-Binary Search Tree Breadth First Search",
          "64-Binary Search Tree Min and Max",
          "65-Binary Search Tree Delete node",
          "66-Graph overview",
          "67-Adjacency Matrix of a graph",
          "68-Adjacency List of a graph",
          "69-Graph Add Vertex and Edge",
          "70-Graph Display and HasEdge",
          "71-Graph Remove Edge and vertex"
        ]
      },
      "requirements": [
        "Basic Knowledge of JavaScript and ES6"
      ],
      "description": "فى هذا الكورس سوف اقوم بمساعدك على فهم الخوراميات Algorithms  وهياكل البيانات data structure  من البدايه حتى الاحتراف سوف نقوم فى بدايه الامر بتعلم الاتى\n-Introduction\n-The Algorithm meaning\n-Time and space complexity\n-Big O notation\n-Fibonacci sequence\n-Factorial of number\n-prime number\n-Recursion meaning\n-Recursion fibonacci\n-Recursion factorial\n-linear search algorithm\n-binary search algorithm\n-bubble sort with implementation\n-insertion sort with implementation\n-Quick sort with implementation\n-Merge sort with implementation\nوكل هذا بالنسبه ل ال algorithms  اما مايخص ال data structure سوف نتعلم الاتى :\n-Introduction\n-Arrays\n-Objects\n-Maps\n-Sets\n-Stack overview with implementation\n-Queue overview with implementation\n-Optimized Queue\n-Circular Queue with implementation\n-Linked list introduction\n-Linked list classes\n-Linked list append\n-Linked list print values\n-Linked list prepend\n-Linked list insert\n-Linked list remove with index\n-Linked list remove with value\n-Linked list search\n-Linked list reverse\n-Linked list with tail and head\n-Implement stack using linked list\n-Implement queue using linked list\n-Doubly linked list\n-Hash table overview\n-Hash table function\n-Hast table set function\n-Hash table get function\n-Hash table remove function\n-Hash table display function\n-Hash table collision\n-Tree overview\n-Binary search tree overview\n-Binary search tree classes\n-Binary search tree insert\n-Binary search tree search\n-Binary Search Tree Depth First Search (PreOrder)\n-Binary Search Tree Depth First Search (InOrder)\n-Binary Search Tree Depth First Search (PostOrder)\n-Binary Search Tree Breadth First Search\n-Binary Search Tree Min and Max\n-Binary Search Tree Delete node\n-Graph overview\n-Adjacency Matrix of a graph\n-Adjacency List of a graph\n-Graph Add Vertex and Edge\n-Graph Display and HasEdge\n-Graph Remove Edge and vertex\nسوف نقوم بتعلم جميع الاجزاء السابقه بشرح المفهوم نظريا ثم كتابه الكود بشكل عملى لكى اضمن فهمك للمفهوم بشكل مثالى .. ادعوكم للاشتراك فى الكورس وسوف يجعلك تتقن الخورازميات وهياكل البيانات بشكل مثالى من البدايه خالص للاحتراف باذن الله تعالى.",
      "target_audience": [
        "All Developers who want to learn algorithms and data structure concepts"
      ]
    },
    {
      "title": "Data Analytics Masterclass: From Basics to Insights",
      "url": "https://www.udemy.com/course/data-analytics-masterclass-from-basics-to-insights/",
      "bio": "Hands-on Training in Excel, Python, and Power BI",
      "objectives": [
        "Data Analysis Proficiency",
        "Excel Mastery",
        "Python Programming Skills",
        "Data Visualization and Reporting:",
        "Power BI"
      ],
      "course_content": {
        "Introduction to Data Analysis": [
          "Data Analysis Program",
          "What is Data Analysis? (1)",
          "What is Data Analysis? (2)",
          "The Role of Data Analytics",
          "The Data Ecosystem and Languages for Data Professionals (1)",
          "The Data Ecosystem and Languages for Data Professionals (2)",
          "The Data Ecosystem and Languages for Data Professionals (3)",
          "Quiz"
        ],
        "Excel Essentials": [
          "Introduction of Excel (1)",
          "Introduction of Excel (2)",
          "Introduction of Excel (3)",
          "Introduction of Excel (4)",
          "Exercise: Excel 101",
          "Filtering and Sorting Data",
          "Filtering and Sorting Data Exercise",
          "introduction Formulas",
          "Arithmetic Formulas & Applying Formulas to Text",
          "Cell References",
          "Formulas Exercise",
          "Crunching Numbers With Excel Functions",
          "Crunching Numbers With Excel Functions Assignment",
          "Conditional Calculations",
          "Conditional Calculations assignment",
          "Date and Time Functions",
          "Date and Time functions assignment",
          "Text Functions",
          "Text Functions Assignment",
          "IF functions",
          "VLOOKUP and HLOOKUP and XLOOKUP",
          "Exercise Logical and Lookup Functions",
          "Data Visualization 1",
          "Data Visualization 2",
          "Exercise Data Visualization",
          "Pivot Tables",
          "Exercise Pivot Tables",
          "Project 1",
          "Project 2",
          "Final Project"
        ]
      },
      "requirements": [
        "No Prior Coding Experience Required:"
      ],
      "description": "Are you ready to embark on a journey into the world of data analysis and visualization? Welcome to the Data Analytics Masterclass, a comprehensive course designed to equip you with the essential skills and knowledge needed to harness the power of data for informed decision-making and problem-solving.\nIn today's data-driven world, the ability to analyze and interpret data is a fundamental skill that can supercharge your career and transform the way you approach challenges. Whether you're a business professional, a recent graduate, or someone looking to pivot into a data-focused role, this course provides the roadmap to success.\n\nWhat You'll Learn:\nData Analysis Foundations: Begin with an exploration of what data analysis is and why it matters. Understand the role of data analytics in various industries and domains.\nPractical Tools and Techniques: Dive into hands-on training with industry-standard tools such as Microsoft Excel, Python, and Power BI. Master Excel functions, pivot tables, and data sorting. Explore Python's data manipulation capabilities and learn how to handle and analyze data efficiently. Create compelling data visualizations using Power BI.\nReal-world Projects: Apply your newly acquired skills to real-world projects. Build an interactive Excel dashboard, conduct data analysis using Python, and create informative Power BI reports. Gain practical experience that you can showcase to potential employers or clients.\nData-driven Decision Making: Discover how to transform raw data into actionable insights. Learn to make data-driven decisions, track performance, and communicate findings effectively.\nCareer Enhancement: Whether you're seeking career advancement or starting a new journey, this course will enhance your marketability. Data analysis skills are in high demand across various industries, and this course will help you stand out.\nLifelong Learning: Cultivate a mindset of continuous learning in the dynamic field of data analytics. Be prepared to adapt to new technologies and stay ahead in your career.",
      "target_audience": [
        "Beginners in Data Analysis",
        "Students and Recent Graduates",
        "Professionals Seeking Data Skills",
        "Career Changers",
        "Self-learners and Lifelong Learners"
      ]
    },
    {
      "title": "[FR] Méga Classe IA & Python : 300+ Projets Pratiques",
      "url": "https://www.udemy.com/course/fr-mega-classe-ia-python-300-projets-pratiques/",
      "bio": "Formation en Machine Learning, Deep Learning, Data Science, Vision par ordinateur, NLP, Chatbots et applis IA",
      "objectives": [
        "Apprenez Python depuis zéro, même sans expérience préalable",
        "Comprenez les bases de l’IA, du machine learning et du deep learning",
        "Créez et déployez des applications IA réelles avec Python",
        "Utilisez les bibliothèques IA comme TensorFlow, PyTorch et OpenCV",
        "Développez vos compétences via 100 projets pratiques IA et Python",
        "Apprenez l’analyse, la visualisation et le traitement des données",
        "Créez des applis IA : chatbots, systèmes de reco, outils d’automatisation",
        "Maîtrisez l’entraînement, l’évaluation et l’optimisation des modèles",
        "Comprenez les enjeux éthiques et pratiques du développement IA",
        "Constituez un portfolio IA/Python pour montrer vos compétences"
      ],
      "course_content": {
        "Semaine 1 : Bases de la programmation Python pour l’intelligence artificielle": [
          "Introduction à la semaine 1 – Bases de Python",
          "Jour 1 : Introduction à Python et configuration de l’environnement de développem",
          "Jour 2 : Contrôle du flux dans Python",
          "Jour 3 : Fonctions et modules",
          "Jour 4 : Structures de données (Listes, Tuples, Dictionnaires, Ensembles)",
          "Jour 5 : Manipulation des chaînes de caractères",
          "Jour 6 : Gestion des fichiers",
          "Jour 7 : Code Pythonique et travail sur projet",
          "Diapositives et code du cours"
        ],
        "Semaine 2 : Notions essentielles en science des données pour l’IA": [
          "Introduction à la semaine 2 – Science des données",
          "Jour 1 : Introduction à NumPy pour les calculs numériques",
          "Jour 2 : Opérations avancées avec NumPy",
          "Jour 3 : Introduction à Pandas pour la manipulation de données",
          "Jour 4 : Nettoyage et préparation des données avec Pandas",
          "Jour 5 : Agrégation et regroupement des données avec Pandas",
          "Jour 6 : Visualisation des données avec Matplotlib et Seaborn",
          "Jour 7 : Projet d’analyse exploratoire des données (EDA)"
        ],
        "Semaine 3 : Mathématiques pour le machine learning et l’IA": [
          "Introduction à la semaine 3 – Mathématiques pour le ML",
          "Jour 1 : Fondamentaux de l’algèbre linéaire",
          "Jour 2 : Concepts avancés en algèbre linéaire",
          "Jour 3 : Calcul différentiel pour le ML",
          "Jour 4 : Calcul intégral et optimisation",
          "Jour 5 : Théorie des probabilités et distributions",
          "Jour 6 : Fondamentaux en statistiques",
          "Jour 7 : Mini projet mathématique – Régression linéaire depuis zéro"
        ],
        "Semaine 4 : Probabilités et statistiques pour le ML et l’IA": [
          "Introduction à la semaine 4 – Probabilités et statistiques",
          "Jour 1 : Variables aléatoires et théorie des probabilités",
          "Jour 2 : Distributions de probabilité dans le ML",
          "Jour 3 : Inférence statistique – Estimation et intervalles de confiance",
          "Jour 4 : Tests d’hypothèse et valeurs p",
          "Jour 5 : Types de tests d’hypothèse",
          "Jour 6 : Corrélation et régression",
          "Jour 7 : Projet d’analyse statistique – Analyse de données réelles"
        ],
        "Semaine 5 : Introduction au machine learning": [
          "Introduction à la semaine 5 – ML",
          "Jour 1 : Bases du machine learning et terminologie",
          "Jour 2 : Apprentissage supervisé et modèles de régression",
          "Jour 3 : Régressions avancées – polynomiale et régularisation",
          "Jour 4 : Classification et régression logistique",
          "Jour 5 : Évaluation des modèles et validation croisée",
          "Jour 6 : Algorithme des k-plus proches voisins (k-NN)",
          "Jour 7 : Mini projet d’apprentissage supervisé"
        ],
        "Semaine 6 : Ingénierie des caractéristiques et évaluation des modèles": [
          "Introduction à la semaine 6 – Feature Engineering",
          "Jour 1 : Introduction à l’ingénierie des caractéristiques",
          "Jour 2 : Normalisation et mise à l’échelle des données",
          "Jour 3 : Encodage des variables catégorielles",
          "Jour 4 : Techniques de sélection de caractéristiques",
          "Jour 5 : Création et transformation de caractéristiques",
          "Jour 6 : Méthodes d’évaluation des modèles",
          "Jour 7 : Validation croisée et réglage des hyperparamètres"
        ],
        "Semaine 7 : Algorithmes de ML avancés": [
          "Introduction à la semaine 7 – Algorithmes avancés",
          "Jour 1 : Introduction à l’apprentissage ensembliste",
          "Jour 2 : Bagging et forêts aléatoires",
          "Jour 3 : Boosting et Gradient Boosting",
          "Jour 4 : Introduction à XGBoost",
          "Jour 5 : LightGBM et CatBoost",
          "Jour 6 : Gérer les données déséquilibrées",
          "Jour 7 : Projet – Comparaison de modèles sur données réelles"
        ],
        "Semaine 8 : Réglage et optimisation des modèles": [
          "Introduction à la semaine 8 – Optimisation",
          "Jour 1 : Introduction au tuning des hyperparamètres",
          "Jour 2 : Grid Search et Random Search",
          "Jour 3 : Optimisation bayésienne",
          "Jour 4 : Techniques de régularisation",
          "Jour 5 : Validation croisée et évaluation",
          "Jour 6 : Tuning automatisé avec GridSearchCV et RandomizedSearchCV",
          "Jour 7 : Projet – Construction et réglage du modèle final"
        ],
        "Semaine 9 : Réseaux de neurones et bases du deep learning": [
          "Introduction à la semaine 9 – Deep Learning",
          "Jour 1 : Concepts de base en deep learning",
          "Jour 2 : Propagation avant et fonctions d’activation",
          "Jour 3 : Fonctions de perte et rétropropagation",
          "Jour 4 : Descente de gradient et techniques d’optimisation",
          "Jour 5 : Création de réseaux avec TensorFlow et Keras",
          "Jour 6 : Création de réseaux avec PyTorch",
          "Jour 7 : Projet – Classification d’images avec CIFAR-10"
        ],
        "Semaine 10 : Réseaux de neurones convolutifs (CNNs)": [
          "Introduction à la semaine 10 – CNNs",
          "Jour 1 : Introduction aux CNNs",
          "Jour 2 : Couches convolutives et filtres",
          "Jour 3 : Couches de pooling et réduction de dimension",
          "Jour 4 : Architectures CNN avec Keras/TensorFlow",
          "Jour 5 : Architectures CNN avec PyTorch",
          "Jour 6 : Régularisation et augmentation de données",
          "Jour 7 : Projet CNN – Classification Fashion MNIST ou CIFAR-10"
        ]
      },
      "requirements": [
        "Aucune expérience préalable en programmation ou en intelligence artificielle n'est requise",
        "Un ordinateur avec un accès à Internet pour coder et travailler sur les projets",
        "Une volonté d’apprendre et d’expérimenter avec les concepts de Python et de l’IA",
        "Une familiarité de base avec l’utilisation d’un ordinateur et l’installation de logiciels",
        "Un intérêt pour l’intelligence artificielle, le machine learning et l’automatisation",
        "Un esprit orienté résolution de problèmes et apprentissage pratique",
        "Optionnel : une configuration Google Colab ou Jupyter Notebook pour exécuter du code Python"
      ],
      "description": "Plongez dans le bootcamp ultime en IA et développement Python, conçu pour les débutants et les futurs ingénieurs en IA. Ce cours complet vous emmène de zéro expérience en programmation à la maîtrise de Python, du machine learning, du deep learning, et des applications basées sur l’IA à travers 100 projets réels. Que vous souhaitiez démarrer une carrière en IA, améliorer vos compétences en développement ou créer des outils d’automatisation avancés, ce cours vous offre une expérience pratique avec des implémentations concrètes.\nVous commencerez par apprendre Python depuis les bases, en couvrant tout, de la syntaxe simple aux fonctions avancées. Au fil de votre progression, vous explorerez des techniques de science des données, de visualisation de données, et de prétraitement pour préparer des jeux de données destinés aux modèles IA. Le cours introduit ensuite les algorithmes de machine learning, vous enseignant comment construire des modèles prédictifs, analyser des motifs, et prendre des décisions guidées par l’IA. Vous travaillerez avec TensorFlow, PyTorch, OpenCV, et Scikit-Learn pour créer des applications IA capables de traiter du texte, des images et des données structurées.\nEn avançant, vous développerez des chatbots, des systèmes de recommandation, des analyseurs de sentiments, et des outils d’automatisation à partir de données du monde réel. Vous acquerrez une expertise en traitement du langage naturel (NLP), en vision par ordinateur, et en apprentissage par renforcement, en maîtrisant les applications de l’IA dans divers secteurs industriels. Le cours aborde également l’éthique de l’IA, l’optimisation des modèles, et les stratégies de déploiement, vous assurant de savoir comment mettre à l’échelle vos projets IA de façon efficace.\nÀ la fin du cours, vous disposerez de 100 projets pratiques qui démontrent vos compétences en développement IA, automatisation et machine learning. Que vous cherchiez à lancer une startup basée sur l’IA, à booster votre CV avec des compétences recherchées, ou à automatiser des processus métier, ce cours vous offre tout ce dont vous avez besoin. Rejoignez-nous et devenez expert en développement Python et IA, en ouvrant la porte à d’innombrables opportunités dans le secteur technologique.",
      "target_audience": [
        "Débutants absolus sans aucune expérience en programmation ou en intelligence artificielle",
        "Futurs ingénieurs IA souhaitant acquérir une base solide en Python et en IA",
        "Étudiants et professionnels désirant une expérience pratique avec des projets IA concrets",
        "Développeurs en reconversion vers l’IA et le machine learning depuis d’autres domaines",
        "Passionnés de données voulant utiliser Python pour des applications basées sur l’IA",
        "Entrepreneurs et professionnels souhaitant exploiter l’IA pour automatiser leurs activités",
        "Passionnés de technologie désireux d’explorer Python et l’IA à travers des projets pratiques",
        "Enseignants et formateurs à la recherche de ressources structurées pour enseigner l’IA et Python",
        "Chercheurs et analystes souhaitant renforcer leurs compétences en IA et en science des données",
        "Toute personne intéressée par l’apprentissage du développement IA via une approche par projets"
      ]
    },
    {
      "title": "KNIME 3.7: Datenanalyse/Datenverarbeitung+ Machine Learning",
      "url": "https://www.udemy.com/course/knime-dv-da-ml/",
      "bio": "KNIME Analytics - Datenverarbeitung / Datenanalyse / Desktopanwendung bauen / Machine Learning / Übungsprojekte",
      "objectives": [
        "KNIME Analytics vielseitig für praktische Anwendungen einsetzen",
        "Datenverarbeitung mit KNIME Analytics",
        "Arbeit KNIME Analytics in Kombination mit EXCEL / CSV / Datenbanken / uvm.",
        "Praxisbeispiele für den Einsatz von KNIME Analytics die den Büroalltag vereinfachen",
        "Machine Learning mit Hilfe von KNIME + Praxisbeispiele (Autoverkauf / Versicherung / Online Shop)",
        "Visualisierung von Daten und Analyseergebnissen"
      ],
      "course_content": {
        "Einleitung": [
          "Herzlich Willkommen!",
          "How to get KNIME",
          "Get Started - Die KNIME Oberfläche kennenlernen",
          "Backgroundwissen: Exkurs Java-Datentypen",
          "Unser erster Workflow",
          "Unser erster Workflow - Praktikum/Selfmade"
        ],
        "Basic Nodes": [
          "Excel-Reader",
          "File-Reader",
          "CSV-Reader",
          "Table-Creator, Table-Reader und PMML-Reader (\"Predictive Model Markup Language\")",
          "Row Filter + Column Filter",
          "Excel-Writer",
          "Excel-Sheet-Appender",
          "CSV-Writer",
          "Table-Writer + PMML-Writer",
          "Praxisprojekt: Aufgabenstellung",
          "Praxisprojekt: Lösung"
        ],
        "Advanced Nodes": [
          "Automatischer E-Mail-Versand mit dem \"Send Email\" Node",
          "Automatischer E-Mail-Versand mit dem \"Send Email\"-Node --- Praktikum/Selfmade",
          "\"Column Rename",
          "Constant Value Column",
          "Math Formula",
          "Number-to-String + String-to-Number",
          "String Manipulation",
          "String Replacer",
          "Missing-Value Handling",
          "Joiner",
          "Rule Based Row Filter",
          "Rule Engine",
          "Sorter",
          "Column Resorter",
          "RowID Node",
          "Add Empty Rows",
          "Group By",
          "Transpose",
          "Pivottabellen in KNIME",
          "Praxisprojekt: Benötigte Knoten",
          "Praxisprojekt: Aufgabenstellung",
          "Praxisprojekt: Lösung"
        ],
        "Datenbank-Interaktion mit KNIME Analytics": [
          "Download des MySQL-Installer",
          "MySQL Installation",
          "MySQL Workbench - Get Started",
          "Database-Connection und Lesen unserer Tabelle mit SQL-Statement mit KNIME",
          "Einführung: Arbeit mit Datenbanken in KNIME",
          "Arbeit mit DB-Data in KNIME",
          "Datenbank-Interaktion ohne SQL-Statement",
          "UPDATE TABLE mit dem \"DB Update\" Knoten",
          "Datenbanktabelle anhand von Excel-Tabelle mit KNIME erstellen und bearbeiten",
          "Vorbereitung auf das Praxisprojekt",
          "Praxisprojekt: Aufgabenstellung",
          "Praxisprojekt: Lösung"
        ],
        "Workflow Control - Variablen": [
          "Workflow-Variablen",
          "Table-Row to Variable",
          "Table-Column to Variable",
          "Variablen bearbeiten mit Java-Code oder Math Formula Knoten",
          "Variable to Table-Column und Variable to Table-Row"
        ],
        "Workflow Control - Schleifen": [
          "Generic Loop",
          "Counting Loop",
          "Column List loop",
          "Table-Row to Variable Loop",
          "List Files Knoten",
          "Praxisprojekt: Aufgabenstellung",
          "Praxisprojekt: Lösung"
        ],
        "Desktopanwendung bauen - Workflows vom Desktop aus starten": [
          "Desktopanwendung - Workflow erstellen + Verstehen der Funktionsweise",
          "Desktopanwendung - Erstellen der Batch-Datei"
        ],
        "Visualisierung": [
          "Get Started",
          "Pie Chart",
          "Stacked Are Chart",
          "Sunburst Chart",
          "Scatter Plot",
          "Datenvorbereitung für Visualisierung"
        ],
        "Data Analytics + Machine Learning mit KNIME": [
          "Vorbereitung / Preprocessing",
          "Fehlervermeidung / Fehlinterpretationen",
          "Machine Learning basierte Fahrzeugempfehlung für unseren Kunden",
          "Lineare und Polynomiale Regression - Kunde dem passenden Verkäufer zuordnen",
          "Decision Tree - Bezahlmethode unserer Kunden bestimmen",
          "Arbeit mit PMML-Modellen",
          "Einkaufswagenanalyse / Association Rule Learner - Bsp. Versicherungen",
          "Praxisprojekt: Aufgabenstellung",
          "Optional: Praxisprojekt: Konzepte",
          "Praxisprojekt: Lösung - Marketing mit Hilfe von Machine Learning",
          "Auf Wiedersehen!"
        ]
      },
      "requirements": [
        "Keine Programmierkenntnisse nötig",
        "Grundlegende Computerkenntnisse (Dateien herunterladen, .zip-Dateien entpacken, Excel/CSV-Dateien erstellen o.ä)"
      ],
      "description": "Download der Software - Getting started\nKennenlernen von KNIME Analytics und dem Prinzip des Baus von Workflows mit vielfältigen Einsatzmöglichkeiten\nDas Konzept \"Workflow\" und \"Node\" verstehen und in der Praxis anwenden\nBauen von Datenverarbeitungsprozessen mit Hilfe von Knoten\nVerbesserung der Prozesse im Unternehmen durch den Einsatz von KNIME Analytics\nBetrachtung einzelner Knoten (Zum Beispiel Eingabe / Ausgabe / Filteroptionen / Arbeit mit unterschiedlichen Datentypen)\nAutomatisierter E-Mail Versand mit dem \"Send E-Mail\"-Node\nArbeit mit Datenbanken am Beispiel mit einer eigenen MySQL Datenbank\nWorkflow Steuerung durch Schleifen und Variablen - Prinzipien des Programmierens auch in der visuellen Programmierung mit Workflows möglich.\nVisualisierung von Daten und Analyseergebnissen als attraktiver Output für User und Kunden\nDesktopanwendung bauen welche sich unkompliziert ausführen lassen.\n\"Machine Learning\" anhand realitätsnaher Beispiele verstehen und lernen die in der Praxis anzuwenden (Autoverkauf / Versicherung / Online Shop)\n\n\nx x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x\nKurs basiert auf der Knime Version 3.7 - Einige Knoten sehen daher mittlerweile anders aus. Auf den Lerneffekt des Kurses hat dies aber nur einen geringen Einfluss. Auch alle Möglichkeiten die hier gezeigt werden, bestehen in den neuen KNIME-Versionen weiter - können aber zum Beispiel minimal anders konfiguriert werden oder sind in einem neuen/veränderten Knoten zusammengefasst.\n\n\nIch freue mich sehr auf deine Teilnahme und über dein Interesse am Lernen mit einer großartigen Software wie KNIME Analytics\n\n\nHerzlich Willkommen\nDein Simon",
      "target_audience": [
        "Menschen, die mit vielen Daten, Excel-Tabellen und Dateien arbeiten und sich den Büroalltag vereinfachen möchten",
        "Data Science Interessierte, die ihr theoretisches Wissen praktisch mit einem interaktiven Tool umsetzen wollen",
        "Data Analysten"
      ]
    },
    {
      "title": "【Streamlit+Colab】人工知能Webアプリを手軽に公開しよう！-Pythonで構築し即時公開するAIアプリ-",
      "url": "https://www.udemy.com/course/ai-web-app/",
      "bio": "人工知能、機械学習Webアプリを手軽に構築し、公開する方法を学ぶ講座です。Google Colaboratory環境でStreamlitを使った人工知能Webアプリを構築し、Streamlit Cloud、GitHubを使って公開します。",
      "objectives": [
        "フレームワークStreamlitを使って、様々な人工知能Webアプリを構築し、公開できるようになります。",
        "Streamlit全般の基礎的な知識を学びます。",
        "Streamlit Cloud、GitHubを使って人工知能Webアプリをデプロイする方法を学びます。",
        "様々なWebアプリのUIを、Streamlitを使って実装する方法を学びます。",
        "データをブラウザ上で可視化する方法を学びます。",
        "独自のAIモデルを訓練し、Webアプリに組み込む方法を学びます。"
      ],
      "course_content": {
        "Streamlitの概要": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "Streamlitの概要",
          "開発環境について",
          "最初のStreamlitアプリ",
          "演習"
        ],
        "Streamlitの様々な機能": [
          "セクション2の教材",
          "Section2の概要",
          "Pandasの基礎",
          "データの可視化",
          "ページのUI",
          "キャッシュの利用",
          "演習"
        ],
        "様々な人工知能Webアプリの開発": [
          "セクション3の教材",
          "Section3の概要",
          "画像認識アプリ Part1",
          "画像認識アプリ Part2",
          "自然言語処理アプリ",
          "演習"
        ],
        "人工知能Webアプリの公開": [
          "セクション4の教材",
          "Section4の概要",
          "Streamlit Cloudへの登録",
          "モデルの訓練",
          "Webアプリの構築",
          "アプリのデプロイ",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Google Colaboratoryを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。",
        "GitHubのアカウントが必要になります。",
        "機械学習やデータサイエンス、深層学習について詳しい解説はありません。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。"
      ],
      "description": "「人工知能Webアプリを手軽に公開しよう！」は、人工知能、機械学習Webアプリを手軽に公開する方法を学ぶ講座です。\nGoogle Colaboratory環境で、「Streamlit」を使ったWebアプリを作成します。\n\n\nStreamlitとは、WebアプリをPythonのみで手軽に公開できるフレームワークです。\nPandas の DataFrame や、 matplotlibなどで作成したグラフを埋め込むことができて、データ分析結果を簡単に表示することができます。\n簡潔かつ使いやすいUIが実装可能で、様々なタイプのアプリに対応できます。\nさらに、Streamlit Cloudを使えば、構築したアプリをクラウド上で公開することが可能です。\nアプリを公開するコストが大きく抑えられるため、Streamlitは現在人気が急上昇中です。\n\n\n本講座では、このようなStreamlitの基本的な扱い方を学んだ上で、様々なWebアプリを公開します。\n人工知能、機械学習に取り組んだ成果を、Webアプリとして公開できるようになりましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! AIRS-Lab】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. Streamlitの概要\n→ Streamlitの概要、および開発環境について学びます。\nSection2. Streamlitの様々な機能\n→ Streamlitが持つ豊富な機能の全体像、および一部の詳細を解説します。\nSection3. 様々な人工知能Webアプリの開発\n→ Streamlitを使い、様々な人工知能Webアプリを開発します。\nSection4. 人工知能Webアプリの公開\n→ 「Streamlit Cloud」を使い、人工知能Webアプリを公開します。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "人工知能Webアプリの手軽な開発、公開方法を学びたい方。",
        "データ分析の結果を手軽にメンバーとシェアしたい方。",
        "様々な種類のデータを、ブラウザ上でで可視化する方法を学びたい方。",
        "学んだAI技術を活かしてWebアプリを作りたい方。",
        "データを扱う仕事をしているけど、Webアプリの構築は敷居が高いと感じている方。",
        "自分で構築、訓練したAIモデルを、多くの人に使ってもらいたい方。"
      ]
    },
    {
      "title": "Analiza danych w środowisku R",
      "url": "https://www.udemy.com/course/analiza-danych-w-srodowisku-r/",
      "bio": "Manipulacja, modelowanie i wizualizacja danych w praktyce",
      "objectives": [
        "Zobaczysz, na czym polega obróbka danych i jak zautomatyzować ten proces",
        "Przeprowadzisz obliczenia statystyczne na zbiorach danych, a następnie je zautomatyzujesz",
        "Zapoznasz się z zagadnieniem modelowania statystycznego",
        "Będziesz wizualizować dane, wyniki oraz uzyskasz wykresy statystyczne",
        "Nauczysz się wykonywać aplikację webową dla powyższych czynności"
      ],
      "course_content": {
        "R offline na PC": [
          "Wstęp + materiały dodatkowe",
          "Krótko co to jest R, instalacja R oraz Rstudio, ustawienie Rstudio"
        ],
        "Składnia": [
          "R jako kalkulator",
          "Rodzaje obiektów (zmiennych), wymuszanie typu",
          "Wektor, macierz, lista",
          "Faktor",
          "Ramka danych data.frame()",
          "Działania wektorowe",
          "If, ifelse",
          "Pętla: for, while"
        ],
        "Manipulacja danymi": [
          "Wczytanie danych - pliki .txt, .csv. xls, .xlsx, sprzedaz.csv",
          "Agregacja danych",
          "Filtrowanie danych",
          "Sortowanie danych",
          "Łączenie danych",
          "Pakiet dplyr",
          "Brakujące obserwacje"
        ],
        "Analiza danych i modelowanie statystyczne": [
          "Zmienna losowa i jej rozkład",
          "Wybrane rozkłady zmiennej losowej",
          "Korelacja i regresja",
          "Analiza szeregu czasowego - dekompozycja, średnia ruchoma",
          "Prognozowanie"
        ],
        "Podstawowe wykresy": [
          "Wykresy w technice tradycyjnej, formatowanie i personalizacja wykresu",
          "Nowoczesne wykresy z pakietem ggplot2",
          "Htlmwidgets",
          "Mapy z ggplot"
        ],
        "Aplikacja webowa RShiny": [
          "Prezentacja wyników w Rshiny"
        ]
      },
      "requirements": [
        "Chęć do nauki!"
      ],
      "description": "Obierz kurs na sprawniejszą analizę danych\nW dobie rozwoju technologii informatycznych i bazodanowych firmy gromadzą coraz więcej danych związanych z różnymi obszarami funkcjonowania przedsiębiorstwa. Praca z danymi powoli staje się codziennością działów marketingu i sprzedaży, w których konieczna okazuje się umiejętność szybkiego analizowania masowych informacji dotyczących profilu i zachowań klientów, źródeł ruchu na stronach WWW czy produktów przynoszących największe przychody w danym kanale dystrybucji. Kto potrafi błyskawicznie przetworzyć te dane i wyciągnąć z nich trafne wnioski, ten zyskuje przewagę konkurencyjną. Nic dziwnego, że rynek pracy jak gąbka chłonie specjalistów w zakresie analizy oraz wizualizacji danych.\nSprzymierzeńcem w tych działaniach jest program R, czyli środowisko do obliczeń statystycznych, oraz współpracujące z nim R-Studio, stanowiące zestaw narzędzi do odzyskiwania danych utraconych z wewnętrznych i zewnętrznych nośników. Umiejętność sprawnego posługiwania się tym oprogramowaniem pozwala w bardzo elastyczny i indywidualny sposób przeprowadzać niezwykle zaawansowane analizy oraz profesjonalne wizualizacje danych. Co istotne, praca z nimi nie wymaga posiadania dużej wiedzy z dziedziny programowania — skupia się przede wszystkim na problemach stricte związanych z analizą. Niniejszy kurs video pozwala na szybkie rozpoczęcie samodzielnego działania w R-Studio i pokazuje możliwości, jakie oferuje środowisko R.\n\nW trakcie niniejszego kursu video:\nZobaczysz, na czym polega obróbka danych i jak zautomatyzować ten proces.\nPrzeprowadzisz obliczenia statystyczne na zbiorach danych, a następnie je zautomatyzujesz.\nZapoznasz się z zagadnieniem modelowania statystycznego.\nBędziesz wizualizować dane, wyniki oraz uzyskasz wykresy statystyczne.\nCo więcej...\nNauczysz się wykonywać aplikację webową dla powyższych czynności.\nAnaliza danych w środowisku R. Manipulacja, modelowanie i wizualizacja danych w praktyce kończy się na poziomie podstawowym. Jego słuchacz zdobędzie bazową wiedzę z obszaru statystyki opisowej oraz pracy w środowisku R i narzędziu R-Studio, dzięki czemu będzie w stanie samodzielnie ją rozwijać.\n\nWitaj w programie R\nProgram, środowisko albo — jeszcze inaczej — język R to oprogramowanie typu open source, co oznacza, że rozwijają go sami użytkownicy, a korzystanie z niego jest nieodpłatne. Współpracuje z komputerami zarówno z Linuksem, jak i z Windowsem oraz macOS. Dostarcza szeroką gamę technik statystycznych (takich jak modelowanie liniowe i nieliniowe, klasyczne testy statystyczne, analiza szeregów czasowych, klasyfikacja czy grupowanie) oraz graficznych. Powszechnie korzysta się z niego w biznesie, bioinformatyce czy medycynie — do badań klinicznych. Jest na tyle popularny, że producenci komercyjnych pakietów statystycznych (na przykład SAAS lub Statistica) oferują dedykowane mechanizmy, dzięki którym ich oprogramowanie współpracuje z R.\n\nDowiedz się, czym jest i jak działa pakiet R\nKurs, dzięki któremu opanujesz podstawy pracy z językiem R oraz narzędziem R-Studio, trwa cztery godziny. W tym czasie dowiesz się, czym jest środowisko R i R-Studio i jak je zainstalować na swoim komputerze. Poznasz składnię programu R: rodzaje obiektów, wymuszanie typu zmiennej, wektor, macierz, listę faktor, ramkę danych data.frame, działania wektorowe, if oraz pętlę. Będziesz manipulować danymi — wczytywać je, agregować, filtrować, sortować i łączyć. Wykonasz analizę danych — i poznasz przy tym kolejne pojęcia: zmienną losową, jej rozkład i wybrane rozkłady, korelację i regresję oraz analizę szeregu czasowego (dekompozycja, średnia ruchoma, prognozowanie). Zobaczysz podstawowe wykresy wykonywane w technice tradycyjnej, dowiesz się, na czym polega formatowanie i personalizacja wykresu, poznasz nowoczesne wykresy z pakietem ggplot2, htmlwidgets i mapy z ggplot. Zaznajomisz się również z budową webowej aplikacji R Shiny.\n\nTylko dla wtajemniczonych\nOsoba korzystająca z programu R może zajmować się wszystkim, co dotyczy danych i ich obróbki, analiz statystycznych czy wizualizacji. Poszerzając samodzielnie zakres wiedzy, będzie potrafiła budować modele statystyczne bazujące na zmiennych losowych i ich rozkładach, wykonywać na własne potrzeby różnego rodzaju symulacje, tworzyć modele predykcyjne i inne eksperymenty w ramach uczenia maszynowego oraz automatyzować wymienione czynności.",
      "target_audience": [
        "Dla Ciebie, jeśli chcesz zacząć przygodę z językiem R"
      ]
    },
    {
      "title": "Aprende lenguaje R con Rstudio Cloud desde cero",
      "url": "https://www.udemy.com/course/aprende-lenguaje-r-desde-cero-con-rstudio-cloud/",
      "bio": "No necesitas saber programación: Aprenderás a manipular, estructurar, procesar y graficar datos con Rstudio Cloud",
      "objectives": [
        "Aprenderás el manejo de la plataforma online Rstudio Cloud",
        "Aprenderás la estructura y el flujo para gestion de proyectos en Rstudio Cloud",
        "Aprenderás los fundamentos de la creación y ejecución de scripts en Rstudio Cloud",
        "Aprenderás la definición de variables para el tratamiento de datos en Rstudio Cloud.",
        "Aprenderás a defnir correctamente ciclos repetitivos y el flujo de control en los scripts de R",
        "Aprenderás a instalar paquetes, también a usar funciones pre-establecidas en Rstudio.",
        "Aprenderás a importar datos desde fuera y dentro de Rstudio Cloud.",
        "Aprenderás a preparar datos importados para el procesameinto con Rstudio",
        "Aprenderás a crear gráficos para el análisis visual de datos en Rstudio Cloud.",
        "Tendrás apoyo activo de Preguntas y Respuestas.",
        "En la última sección del Curso, diviértete jugando y comprobando tu nivel de aprendizaje"
      ],
      "course_content": {
        "Introducción a la plataforma Rstudio Cloud": [
          "Indicaciones generales del curso",
          "Introducción a lenguaje R",
          "Revisión de la plataforma online RStudio Cloud",
          "Revisión general del IDE Rstudio Cloud",
          "Uso de consola, primeros pasos en R, con Rstudio Cloud",
          "Gestión de Proyectos y su flujo de trabajo en RStudio Cloud"
        ],
        "Aprendiendo a crear scripts en R con RStudio Cloud": [
          "Uso de variables y tipos de datos básicos en R",
          "Uso de Operadores en lenguaje R",
          "Introducción al uso de vectores en R: Crear, extraer, y actualizar datos",
          "Operaciones con vectores, filtros y comparativas de los elementos de un vector",
          "Trabajando con matrices en R y una introducción al algebra lineal",
          "Operaciones con matrices en R: Ejercicios avanzados con operaciones matriciales",
          "Uso de factores en lenguaje R",
          "Fundamentos de graficación en R",
          "Crear gráficos con plot en R, introducción al análisis visual de datos",
          "Clases de gráficos básicos en R: Crear Histogramas, Barras y Series de tiempo",
          "Uso de Data Frames en R y la Importación de datos de fuentes externas",
          "Definición de Ciclos y flujo de control en los scripts de R"
        ],
        "Proyecto: Evolución de la pandemia a nivel Global": [
          "Propuesta y descripción del proyecto práctico: Impacto global de la pandemia",
          "Datos actualizados de la pandemia",
          "Línea de tiempo de contagios por la pandemia",
          "Línea de tiempo de decesos por la pandemia"
        ],
        "Juega y Mide tus conocimientos de R": [
          "Prueba la experiencia de tu aprendizaje con este curso de forma divertida"
        ]
      },
      "requirements": [
        "Saber navegar por internet y crear cuentas de usuario en portales",
        "Tener conocimientos basicos de matemáticas",
        "No se necesita ninguna instalación ni del IDE ni del lenguaje R, todo se manejará de forma online",
        "No hacen falta conocimientos previos de programación",
        "La interfaz de desarrollo RStudio Cloud y su gestor de proyectos es totalmente gratuita"
      ],
      "description": "Lenguaje R  y Rstudio Cloud se están posicionando por muchas razones como uno de las herramientas con más acogida para el análisis de datos a nivel global, y porque además son muy fáciles de aprender.\nEl lenguaje R está pensado para cálculos estadísticos, cálculos matemáticos y creación de gráficos de una manera fácil y rápida. R también está ganando terreno como el lenguaje de programación usado para el ciencia de datos, Big Data y la Inteligencia Artificial.\nEn este curso te iré mostrando paso a paso cómo ir creando scripts para el análisis de datos de forma muy sencilla. Todo esto, con  RStudio  Cloud que es un entorno de desarrollo integrado (IDE) para el lenguaje de programación R, junto con otros lenguajes y formatos de códigos; y ahora, lo tenemos disponible totalmente en la nube dedicado a la computación estadística y de gráficos en múltiples formatos de visualización e interactividad. Incluye: una consola, editor de scripts que apoya la ejecución de código, así como herramientas para el trazado, la depuración y la gestión del espacio de trabajo, el cual puede ser compartido con otros colaboradores de forma online.\nNo sé nada de programación. ¿Puedo aprender R con Rstudio Cloud? Sí. Este curso asume que no tienes conocimientos previos de programación. Para cada uno de los términos y sentencias, primero lo explicaremos académicamente. Luego lo usamos prácticamente en un ejemplo de código del mundo real y lo reutilizamos en ejercicios hasta que aprendas todo de forma idónea.\n¿Que herramientas necesito para aprender R con este curso?\nSólo necesitas estar conectado a internet, R ha evolucionado tanto que dispone ya de su propia plataforma online, para que crees, gestiones y almacenes todos tus proyectos. Aquí aprenderás a crear tu cuenta para que uses Rstudio Cloud de forma gratuita.",
      "target_audience": [
        "Personas interesadas en aprender lenguaje R con o sin conocimientos previos de programación ni estadística",
        "Personas interesadas en aprender el manejo de una de las plataformas mas usadas a nivel global para el tratamiento de datos de forma online."
      ]
    },
    {
      "title": "Machine Learning con Python para Trading",
      "url": "https://www.udemy.com/course/machine-learning-con-python-para-trading/",
      "bio": "Análisis de los mercados Financieros, Técnicas de Inteligencia Artificial aplicadas a la Bolsa. Análisis de sentimiento",
      "objectives": [
        "Programación en Python",
        "Análisis de datos Financieros",
        "Creación de Modelos de Machine Learning enfocados al Trading",
        "Extracción y Manipulación de datos Financieros",
        "Estrategias para invertir de forma Inteligente"
      ],
      "course_content": {
        "¿Que es Machine Learning?": [
          "Recursos",
          "Introducción",
          "¿Que es Machine Learning?",
          "Tipos de Aprendizaje",
          "¿Que es Scikit Learn?"
        ],
        "Prgramación en Python": [
          "Google Colab",
          "Variables en Python",
          "Métodos con Strings",
          "Listas en Python",
          "Condicionales",
          "Bucles",
          "Lectura y Escritura de Archivos en Pyrhon",
          "Funciones en Python",
          "Funciones Recursivas",
          "Clases en Python",
          "Uso de Try-Except"
        ],
        "Python Programacion Orientada a Objetos": [
          "Clases & Instancias",
          "Variables de Instancias & Variables de Clases",
          "Herencia",
          "Metodos de Clases"
        ],
        "Introducción a Pandas": [
          "Introducción a Pandas",
          "¿Que es un DataFrame?",
          "Selección de datos en DataFrames",
          "Filtros en DataFrames",
          "Agrupaciones de Datos",
          "Agrupaciones y Filtro de Datos. Ejemplo Real"
        ],
        "Numpy": [
          "¿Como crear un Array?",
          "Operaciones con Arrays",
          "Manipulación de Arrays y Filtros",
          "Métodos útiles",
          "Estadística con Numpy",
          "Manipulación de imágenes"
        ],
        "Visualización de datos": [
          "Introducción Matplotlib",
          "Graficos en Matplotlib",
          "Graficos en Matplotlib II",
          "Gráficos en Matplotlib III"
        ],
        "Extracción y Manipulación de Datos Financieros.": [
          "Extracción de datos",
          "Clase Práctica de Extracción de datos",
          "Preprocesamiento y Transformación de los Datos",
          "Ejemplo Práctico del Preprocesamiento de los Datos",
          "Kalman Filter"
        ],
        "Conceptos Básicos en Inversión": [
          "Introducción a la inversión",
          "¿Que son Tendencias?",
          "¿Que es el Volumen?",
          "Soporte, Resistencias y Volatilidad"
        ],
        "Análisis de Datos Financieros": [
          "¿Cómo Invertir de Forma Inteligente?",
          "Cálculo de la tasa de Rentabilidad de una Acción",
          "¿Cómo crear un Portfolio de Inversiones?",
          "Estacionalidad en Empresas",
          "Medidas de Riesgo. Convarianza y Correlación",
          "¿Como diversificar correctamente?",
          "¿Como asignar el capital a las empresas correctamente?",
          "Análisis de Montecarlo"
        ],
        "Crear Modelos de Machine Learning con Series Temporales": [
          "¿Que es una serie Temporal?",
          "Etapas necesarias para la creación de un Modelo",
          "¿Como Crear un Training Set a partir de una Serie temporal?",
          "Creación de un Traning Set.Ejemplo Práctico",
          "Validación del Modelo"
        ]
      },
      "requirements": [
        "Ser una persona proactica con ganas de aprender"
      ],
      "description": "¿Podemos predecir el mercado?\nNo vamos a venderte humo: el mercado no es una bola de cristal.\nPero sí podemos usar datos y Machine Learning para tomar decisiones más inteligentes.\nEso es exactamente lo que aprenderás en este curso:\nanalizar mercados financieros, crear modelos predictivos y diseñar estrategias para maximizar beneficios.\n¿Qué vas a aprender?\nOlvídate de la teoría vacía. Este curso es 100% práctico y te lleva de la mano desde cero:\nMachine Learning básico: cómo funcionan los modelos que usan los profesionales.\nPython desde cero: el lenguaje más usado en finanzas y trading algorítmico.\nPandas y Numpy: manipula y analiza datos como un experto.\nVisualización con Matplotlib: identifica patrones y tendencias a simple vista.\nExtracción de datos financieros: APIs y técnicas para conseguir la información que importa.\nSeries temporales: la base para cualquier predicción de mercado.\nDeep Learning aplicado al trading: crea redes neuronales que aprenden del mercado.\nAnálisis de sentimiento: conecta con Twitter y mide cómo las emociones impactan los precios.\nWeb scraping y correlación: descubre relaciones ocultas entre empresas y activos.\nY lo mejor: te llevas todo el código listo para usar y adaptar a tus estrategias.\n¿Por qué este curso?\nPorque el trading del futuro no se hace con corazonadas, se hace con datos.\nDejarás de “intuir” y empezarás a construir estrategias sólidas.\n\"El mayor riesgo es no asumir ninguno.\" – Mark Zuckerberg\n¿Qué conseguirás?\nDejar de operar a ciegas: usarás modelos que procesan miles de datos por ti.\nCrear estrategias más inteligentes y con mayor potencial de rentabilidad.\nIncorporar herramientas avanzadas que usan los analistas profesionales.\nEmpieza hoy\nEl mercado no espera. Cada día sin modelos ni datos, es un día donde operas con desventaja.\nInscríbete y aprende a invertir con inteligencia, no con corazonadas",
      "target_audience": [
        "Personas interesadas en el Mundo de Machine Learning",
        "Desarolladores en Python que quieran aprender Trading",
        "Personas interesadas en la inversion",
        "Estudiantes de Ciencia de datos que quieran aprender a invertir"
      ]
    },
    {
      "title": "Introdução a Machine Learning e Deep Learning",
      "url": "https://www.udemy.com/course/introducao-a-machine-learning-e-deep-learning/",
      "bio": "Teoria e Prática da Inteligência Artificial com Python em Finanças",
      "objectives": [
        "O que é inteligência artificial",
        "Onde aplicar a inteligência artificial",
        "Como funciona a inteligência artificial",
        "Desafios da Inteligência artificial",
        "O que é Machine Learning",
        "O que é Deep Learning",
        "Tipos de Inteligência Aritificial",
        "Como aplicar a Inteligência Artificial",
        "Importância da linguagem Python na IA",
        "Aprendizagem supervisionada",
        "Introdução as Redes Neurais Artificiais",
        "Preparação da base de dados para treinamento",
        "Coleta e preparação da base de dados",
        "Obtenção de gráficos analíticos e estatatísticos",
        "Regressão Linear",
        "Regressão Polinomial",
        "Simulação de RNA",
        "Introdução as simulações das Redes LSTM"
      ],
      "course_content": {
        "Introdução": [
          "Introdução",
          "Sobre o professor",
          "O que é inteligência artificial",
          "Onde se aplica a inteligência artificial - IA"
        ],
        "Tipos da Inteligência Artificial": [
          "Machine Learning e Deep Learning",
          "Sobre a inteligência artificial",
          "Machine learning",
          "Deep Learning - DP"
        ],
        "Etapas e Categorias da Aprendizagem de Máquina": [
          "Etapas do Machine Learning e Deep Learning",
          "Tipos de machine learning",
          "Machine learning supervisionado",
          "Machine learning não supervisionado",
          "Aprendizado por reforço",
          "Processamento de linguagem natural"
        ],
        "Linguagem Python": [
          "Porque utilizar Python",
          "Importância da linguagem Python",
          "Ecossistema Python para Inteligência Artificial",
          "Python no Colaboratory - Colab"
        ],
        "Preparação para Estudos e Aplicações": [
          "Livros importantes",
          "Assuntos de estudo prático",
          "Definição do nosso problema de estudo"
        ],
        "Preparação da Base de Dados": [
          "Carregamento da base de dados",
          "Atualização yfinace - Adj Close",
          "Como selecionar os dados",
          "Plotar dados em gráficos"
        ],
        "Estatísticas Básicas": [
          "Estatística descritiva",
          "Medidas de dispersão"
        ],
        "Modificando os Dados": [
          "Rescaling, Standardization e Normalization",
          "Rescaling dos dados",
          "Fórmula do MinMax",
          "Standartization dos dados",
          "Normalization dos dados",
          "Retornando a escala original dos dados"
        ],
        "Dados para Aprendizado Supervisionado": [
          "Preparando a base de dados",
          "Variável target - alvo - dos dados",
          "Matriz de variáveis independentes",
          "Obtendo retornos financeiros dos dados",
          "Concatenando os dados"
        ],
        "Gráficos de Análises": [
          "Gráficos básicos dos dados",
          "Histograma dos dados",
          "Dados outliers",
          "Gráficos de densidade de probabilidades"
        ]
      },
      "requirements": [
        "Conhecimentos básicos em python"
      ],
      "description": "As aplicações de Inteligência Artificial (IA) com Python têm desempenhado um papel significativo no setor financeiro, trazendo uma série de benefícios e transformando a forma como as instituições lidam com dados e tomam decisões. Aqui está um resumo da importância dessas aplicações em finanças:\n\n\n1. Tomada de Decisão Baseada em Dados:\n- A IA com Python capacita as instituições financeiras a tomar decisões mais informadas e precisas, utilizando algoritmos avançados para analisar grandes conjuntos de dados. Isso resulta em estratégias mais eficazes de investimento, gestão de riscos aprimorada e decisões mais fundamentadas.\n\n\n2. Previsão de Mercado e Tendências:\n- Algoritmos de machine learning e modelos de IA são utilizados para prever movimentos de mercado, identificar tendências e realizar análises preditivas. Isso auxilia investidores, traders e gestores de ativos na identificação de oportunidades e na mitigação de riscos.\n\n\n3. Detecção de Fraudes e Segurança:\n- Sistemas de IA são empregados para detectar padrões suspeitos e atividades fraudulentas em transações financeiras. Essa capacidade de análise em tempo real contribui para a segurança das transações e a proteção contra atividades fraudulentas.\n\n\n4. Gestão de Portfólio Automatizada:\n- Algoritmos de IA e aprendizado de máquina são usados para criar e otimizar automaticamente portfólios de investimento. Esses sistemas automatizados podem ajustar dinamicamente as alocações de ativos com base em condições de mercado em constante mudança.\n\n\n5. Atendimento ao Cliente e Chatbots:\n- A IA é aplicada em chatbots e assistentes virtuais para melhorar o atendimento ao cliente. Essas soluções são capazes de responder a consultas, fornecer informações sobre contas e até mesmo realizar transações simples, melhorando a eficiência e a experiência do cliente.\n\n\n6. Análise de Sentimento e Mídia Social:\n- Algoritmos de análise de sentimento são empregados para avaliar o impacto de notícias, mídia social e eventos globais nos mercados financeiros. Isso permite uma compreensão mais abrangente das influências externas nos investimentos.\n\n\n7. Customização de Produtos Financeiros:\n- A IA possibilita a personalização de produtos financeiros com base nas preferências individuais dos clientes. Isso inclui o desenvolvimento de estratégias de investimento personalizadas e a oferta de produtos adaptados às necessidades específicas de cada cliente.\n\n\n8. Otimização de Processos Internos:\n- Internamente, as instituições financeiras utilizam IA para otimizar processos operacionais, como gerenciamento de riscos, conformidade regulatória, automação de tarefas e análise de dados.\n\n\nEm resumo, as aplicações de IA com Python em finanças estão revolucionando a forma como as organizações do setor abordam a análise de dados, a tomada de decisões e a interação com os clientes. Elas proporcionam eficiência, precisão e insights valiosos, impulsionando a inovação e a competitividade no cenário financeiro.\nE neste curso você irá aprender os fundamentos de todo esse maravilho e interessante campo de estudo!\nInscreva-se agora mesmo!\nBem-vindo(a) a comunidade!",
      "target_audience": [
        "Todos os públicos interessados em Inteligência Artificial"
      ]
    },
    {
      "title": "Bootcamp 2026: Comprender y Crear Agentes IA Profesionales",
      "url": "https://www.udemy.com/course/bootcamp-2025-comprender-y-crear-agentes-ia-profesionales/",
      "bio": "De cero a nivel profesional: CrewAI, LangGraph, Multi-Agentes, Flows, etc.",
      "objectives": [
        "Qué papel juegan los Agentes de IA en la Revolución de la IA Generativa.",
        "¿Cuál es la mejor framework para construir tu Agente IA?",
        "Aprende a construir Agentes IA básicos, intermedios y avanzados.",
        "Aprende CrewAI de la forma correcta: desde Crews básicas hasta Flows avanzados",
        "Aprender LangGraph de la forma correcta: desde Agentes básicos hasta Subgraphs.",
        "Casos reales de Agentes de IA que te inspirarán.",
        "Cómo construir Agentes IA que gestionan tu email y herramientas a medida.",
        "Cómo construir Agentes de IA avanzados que recuerdan quién eres y qué quieres.",
        "Cómo construir Multi-Agentes avanzados capaces de reemplazar equipos de personas.",
        "Cómo mejorar tu Agente de IA con Human-in-the-loop y otras técnicas avanzadas.",
        "El proceso para construir un Agente de IA desde cero: desde la entrevista inicial con el cliente hasta la aplicación final.",
        "Cómo diseñar un plan para introducir Agentes de IA en tu empresa."
      ],
      "course_content": {
        "Presentación del Programa": [
          "Mira lo que nuestros alumnos dicen sobre nuestros bootcamps",
          "¿Es recomendable cursar también nuestro Bootcamp sobre IA Generativa?",
          "Rutas y Ritmos de Aprendizaje: Consejos para encontrar tu camino ideal",
          "[NUEVO] ¡Celebramos 45.000 alumnos! Te regalamos 4 eBooks de IA Generativa",
          "[NUEVO] Consejo para el Alumno Estresado",
          "Este bootcamp te ayudará a avanzar profesionalmente",
          "¿Qué vas a construir a lo largo de este programa? (Proyectos con CrewAI)",
          "¿Qué vas a construir a lo largo de este programa? (Proyectos con LangGraph)",
          "Oportunidades que te abrirá este programa",
          "Materiales incluidos en el programa",
          "¿A quién está dirigido este programa?",
          "¿Qué hace este programa diferente de los demás?",
          "Distínguete como Honor Student",
          "Presentación del director del programa",
          "Comparte tus progresos",
          "REGRESA CON FRECUENCIA: Actualizamos este programa muy a menudo"
        ],
        "Consejos para los alumnos: el secreto para completar este programa con éxito": [
          "Consejos para los alumnos",
          "Consejos prácticos para los alumnos",
          "El SECRETO para completar este programa con éxito",
          "[NUEVO] Nota: Contenidos del Bootcamp #1"
        ],
        "PARTE 1: COMPRENDIENDO TODO EL POTENCIAL DE LOS AGENTES IA": [
          "Recordatorio: Consejo para el Alumno Estresado",
          "Nota sobre la Parte 1: ¿Es esta parte adecuada para ti?",
          "IA Generativa y Agentes IA",
          "Qué son los Agentes IA y los Multi-Agentes IA",
          "Agentes IA",
          "Multi-Agentes"
        ],
        "El Mercado de los Agentes IA": [
          "El Mercado de los Agentes IA"
        ],
        "Beneficios clave que aportan los Agentes IA": [
          "Beneficios clave que aportan los Agentes IA"
        ],
        "Casos de Uso de los Agentes IA": [
          "Casos de Uso de los Agentes IA"
        ],
        "Cómo crear un Plan para Introducir Agentes IA en tu Empresa": [
          "Cómo crear un Plan para Introducir Agentes IA en tu Empresa"
        ],
        "Trabajando con Agentes IA: Mejores Prácticas": [
          "Trabajando con Agentes IA: Mejores Prácticas"
        ],
        "Desafíos y Limitaciones de los Agentes IA": [
          "Desafíos y Limitaciones de los Agentes IA"
        ],
        "Regulación de los Agentes IA": [
          "Regulación de los Agentes IA"
        ]
      },
      "requirements": [
        "No son necesarios conocimientos técnicos previos.",
        "Los estudiantes con algunos conocimientos previos mejorarán su preparación profesional."
      ],
      "description": "Los creadores del Bootcamp de IA Generativa Nº 1 a nivel mundial (Bootcamp 2026 IA Generativa, LLM Apps, Agentes IA, Cursor AI, con más de 45,000 alumnos de más de 154 países), presentan ahora este Bootcamp 2026: Comprende y Construye Agentes de IA Profesionales.\n\n\n¿Qué dicen los principales expertos sobre el potencial de los Agentes de IA:\n“Los Agentes de IA van a provocar la mayor revolución en la informática.\" — Bill Gates, Fundador de Microsoft.\n“Los agentes de IA se convertirán en nuestros asistentes digitales. Harán nuestras vidas más fáciles y eficientes.\" — Jeff Bezos, Fundador de Amazon.\n“La era de los Agentes de IA ha llegado.\" — Jensen Huang, Fundador de Nvidia.\n\n\n¿Por qué unirse a este Bootcamp:\n“Las ofertas de trabajo para IA Generativa están creciendo 3.5 veces más rápido que todos los trabajos.\" (PwC 2024 Global Barometer)\n“Los trabajos que requieren habilidades en IA Generativa ofrecen hasta un 25% más de salario.\" (PwC 2024 Global Barometer)\nCon la confianza de más de 45,000 estudiantes de 154 países — nuestro anterior Bootcamp de IA Generativa fue clasificado como Nº 1 a nivel mundial.\n\n\n¿Qué hace especial a este Bootcamp:\nNo se requiere conocimiento previo de Agentes de IA.\nPara aquellos que lo necesiten, incluye una guía rápida para aprender a programar en la nueva era de la IA Generativa.\nEs el paso ideal después de cursar nuestro Bootcamp 2026: Generative AI, LLM Apps, AI Agents, Cursor AI.\n\n\nEn la Parte 1, aprenderás las claves de los Agentes de IA, así como su potencial para revolucionar empresas, startups y empleo:\nCómo encajan los Agentes de IA en la Revolución de la IA Generativa.\nQué son los Agentes de IA y los Multi-Agentes.\nEl enorme mercado de los Agentes de IA.\nLos principales beneficios de los Agentes de IA.\nCasos de uso de los Agentes de IA.\nCómo diseñar un plan para introducir Agentes de IA en tu empresa.\nCuáles son los principales desafíos y limitaciones de los Agentes de IA.\nRegulaciones y Agentes de IA: lo que necesitas saber.\nEl futuro de los Agentes de IA.\nCasos reales de Agentes de IA que te inspirarán.\nInforme actualizado: Estado de la Revolución de la IA Generativa.\n\n\nEn la Parte 2, aprenderás a construir Agentes de IA de distintos niveles (sencillo, medio y avanzado) con las frameworks principales del mercado hoy:\nAnálisis de las principales frameworks para construir Agentes IA: AutoGen, LangGraph, CrewAI.\nLas tres etapas del proceso de aprendizaje recomendado para construir Agentes IA.\nMotivos por los que CrewAI emerge como la framework más adecuada para el aprendizaje inicial.\nEstadísticas de adopción de CrewAI: quién la usa y para qué.\nConstrucción de agentes IA sencillos y de nivel medio con CrewAI.\nGuía rápida para aprender CrewAI.\nCómo utilizar LLMs alternativos con CrewAI y Groq.\nPrimeros Agentes IA con CrewAI: Crew simple y Crew full-stack.\nUltimas actualizaciones y features de CrewAI.\nFlows: la nueva feature que permite crear Agentes IA avanzados con CrewAI.\nIntegrar CrewAI con herramientas nativas, externas y personalizadas.\nMemoria a corto plazo y a largo plazo en CrewAI.\nMemoria de entidad y de usuario en CrewAI.\nRAG en CrewAI.\nEvent Listeners en CrewAI.\nFingerprinting en CrewAI.\nCómo mejorar la performance de Agentes IA con CrewAI.\nTesting Agentes IA en CrewAI.\nTraining Agentes IA en CrewAI.\nLa nueva plataforma de deployment y observability de CrewAI.\nCómo integrar CrewAI con aplicaciones enterprise como Salesforce, Hubspot, etc.\nInstrucciones para instalar los proyectos error-free.\nProyecto básico con una Crew de Agentes IA.\nCrew de Agentes IA para planificar y gestionar un proyecto de marketing.\nMulti-model Crew de Agentes IA para preparar reuniones de venta.\nFlow con Crew de Agentes IA para gestionar tu correo electrónico.\nFlow con dos Crews de Agentes IA para asistir a SDRs (Sales Development Representatives, agentes de pre-venta).\nPor qué LangGraph es la framework líder para construir Agentes de IA de nivel profesional hoy en día.\nPor qué el equipo de LangChain decidió crear la framework LangGraph para construir mejores Agentes de IA.\nGrados de Comportamiento Agente.\n¿Qué es un Graph en LangGraph?\nCómo aprender LangGraph de la manera correcta: from painful to joyful.\nEntendiendo los componentes de una aplicación LangGraph.\nGuía rápida para aprender LangGraph.\nProyecto multi-agente básico con LangGraph.\nAI Agents Routing con Conditional Edges.\nAgentes de IA que recuerdan tu conversación: memoria a corto plazo.\n¿Qué hay en la mente del Agente de IA? El State Schema.\nCómo cambiar lo que está en la mente del Agente de IA: Reducers.\nConversaciones privadas y públicas: cómo construir Agentes de IA con Múltiples State Schemas.\nEficiencia de memoria: cómo evitar un alto uso de tokens en Agentes de IA.\nPersistencia de memoria: cómo guardar la memoria de tu Agente de IA en una base de datos externa.\nCómo mejorar tu Agente de IA con Human-in-the-loop.\nBreakpoints: el momento adecuado para añadir Human-in-the-loop.\nHuman-in-the-loop: cómo añadir un approval step.\nHuman-in-the-loop: cómo cambiar lo que está en la mente del Agente de IA.\nHuman-in-the-loop: cómo hacer debugging de Agentes de IA.\nParallelization: cómo tu Agente de IA puede ejecutar más de una tarea al mismo tiempo.\nCómo puedes construir Multi-Agentes con sub-graphs.\nOperaciones Map-Reduce: cómo dominar una de las técnicas clave para Agentes de IA.\nEl proceso para construir un Agente de IA desde cero: desde la entrevista inicial con tu cliente hasta la aplicación final.\nCómo construir una aplicación avanzada de Multi-Agente: automatizando el trabajo de un equipo de investigación de mercado.\nMemoria a corto plazo vs. Memoria a largo plazo en Agentes de IA.\nCómo construir Agentes de IA con memoria a largo plazo: recuerdan quién eres, tus conversaciones anteriores y cómo deseas que se comporten.\nCómo gestionar Agentes de IA con Memory Schemas complejos usando TrustCall.\nCómo construir un Agente de IA avanzado con memoria a largo plazo: un increíble asistente personal que gestiona proactivamente tu lista de tareas pendientes.\nCómo usar listeners avanzados para hacer debugging en tus Agentes de IA.\n\n\nÚnete hoy: Toma tu lugar entre los pioneros de la revolución de los Agentes de IA. ¡No pierdas esta oportunidad, inscríbete ahora antes de que cambien las condiciones!",
      "target_audience": [
        "Estudiantes y profesionales con y sin experiencia previa.",
        "Estudiantes sin conocimientos previos interesados en aprovechar las oportunidades profesionales que abre el área de la Inteligencia Artificial.",
        "Ejecutivos interesados en introducir la Inteligencia Artificial en su empresa.",
        "Profesionales de Machine Learning, Deep Learning y Data Science interesados en ampliar sus oportunidades profesionales en el área de la IA Generativa y las Aplicaciones LLM.",
        "Desarrolladores de aplicaciones de software interesados en ampliar sus oportunidades profesionales aprendiendo a desarrollar aplicaciones de Inteligencia Artificial Generativa y Aplicaciones LLM."
      ]
    },
    {
      "title": "【Python×協調フィルタリング】レコメンドで使われる協調フィルタリングのアルゴリズムを学びPythonで実装！",
      "url": "https://www.udemy.com/course/python-recommend/",
      "bio": "レコメンドロジックにはどんな種類があるのかを学び最もよく使われる協調フィルタリングについて理解してPythonで実装していこう！映画の評価データやジョークの評価データを使って協調フィルタリングを実装してみよう！",
      "objectives": [
        "レコメンドロジックの種類を学ぶ",
        "協調フィルタリングの仕組みを学ぶ",
        "Pythonを初歩から学ぶ",
        "映画の評価データを題材にした協調フィルタリングの実装方法を学ぶ",
        "ジョークの評価データを題材にした協調フィルタリングの実装方法を学ぶ"
      ],
      "course_content": {
        "レコメンドの基本": [
          "紹介",
          "協調フィルタリングとその他のレコメンドロジックについて学ぼう！",
          "コサイン類似度について学ぼう！"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Seabornについて学ぼう！",
          "Python構文の復習"
        ],
        "Pythonで協調フィルタリングを実装してみよう！": [
          "MovieLensとは",
          "MovieLensを確認してみよう！",
          "PythonでMovieLensの中身を確認してみよう！",
          "データの加工集計：pivot_tableを使ってデータ展開してみよう！",
          "Pythonでユーザー同士のコサイン類似度を算出してみよう！",
          "協調フィルタリングで予測：ユーザー2と他のユーザーのコサイン類似度を全て計算しよう！",
          "協調フィルタリングで予測：Sorted関数とLambdaの使い方",
          "協調フィルタリング：ユーザー2に近い上位50件のユーザーを元にアイテムの評価を予測"
        ],
        "協調フィルタリングの処理を改善してみよう！": [
          "今までの処理のおさらい",
          "重み付け平均を取ってみよう",
          "欠損値を0埋めではなくてUserごとの平均値で埋めてみよう"
        ],
        "ユーザーがジョークを評価するデータを使って協調フィルタリングを実装してみよう！": [
          "ジョークのデータセット",
          "ジョークのデータセットについて確認",
          "ジョークのデータセットをインポートして前処理",
          "【次の動画の注意点】",
          "ジョークのデータセットに協調フィルタリングを適用してみよう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学ぶのでPythonが初めてでも問題ありません",
        "PCの基本的なスキル",
        "レコメンドロジックへの興味"
      ],
      "description": "本コースでは、レコメンドロジックについて学んでいきます。\n\n\n普段私達が使っている多くのサービスにはレコメンド機能が搭載されています。\n\n\nそんなレコメンドロジックにはどんなものがあるのか？\nその中でも特に有名な協調フィルタリングとはどんな手法なのか？\n理解していきましょう！\n\n\nそして理解した後は実際にPythonで協調フィルタリングを実装していきましょう！\n扱うデータは映画の評価データとジョークの評価データです。\n\n\nぜひ協調フィルタリングを自分のものにしてください！",
      "target_audience": [
        "レコメンドロジック・協調フィルタリングに興味のある人",
        "Pythonを使って協調フィルタリングを実装してみたい人"
      ]
    },
    {
      "title": "Chat Bot Con Inteligencia Artificial",
      "url": "https://www.udemy.com/course/chat-bot-con-inteligencia-artificial/",
      "bio": "Crea tu sistema conversacional con Python e Inteligencia artificial",
      "objectives": [
        "Aprenderás lo básico y necesario de Python para este curso",
        "Aprenderás inicios de inteligencia artificial",
        "Aprenderás a usar librerías Python poco conocidas como cpickle",
        "Aprenderás a manejar json como base de datos para el proyecto",
        "Aprenderás las definiciones de machine learning o aprendizaje maquina",
        "Aprenderás las definiciones de deep learning o aprendizaje profundo",
        "Aprenderás como las bases de python",
        "Aprenderás como implementar redes neuronales"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Presentacion"
        ],
        "Bases de Python": [
          "Que es pyhton",
          "Variables",
          "Operadores Aritmeticos",
          "Operadores Bit a Bit",
          "Operadores Relacionales",
          "Operadores de Asignacion",
          "Operadores Logicos",
          "Metodos",
          "Funciones",
          "Clases",
          "Objetos",
          "Ciclos (Loops)"
        ],
        "Inteligencia Artificial": [
          "¿Que es inteligencia Artificial?",
          "Fundamentos Básicos"
        ],
        "Machine Learning": [
          "¿Que es Machine Learning?",
          "Fundamentos ML"
        ],
        "Deep Learning": [
          "¿Que es Deep Learning?"
        ],
        "PROYECTO: CHAT BOT CON REDES NEURONALES": [
          "Bienvenida al proyecto !",
          "PROYECTO PARTE 1: IMPORTACION DE LIBRERIAS NECESARIAS",
          "PROYECTO PARTE 2: USO DE LA BASE DE DATOS Y LIMPIEZA DE LA DATA",
          "PROYECTO PARTE 3: CREACION DE LA RED NEURONAL ARTIFICIAL",
          "PROYECTO PARTE 4: CULMINACION DEL CHAT-BOT"
        ],
        "EJECUCION FINAL DEL PROYECTO": [
          "CHAT BOT ENTRENADO CON GPU"
        ]
      },
      "requirements": [
        "Recomiendo tener noción de Python para saltarse dicha sección",
        "Los requisitos principales son: ser constante y tener muchas ganas de aprender algo nuevo!",
        "Es de suma importancia tener instalado las siguiente ide: Visual Studio Code"
      ],
      "description": "En este curso obtendrás los conocimientos básicos de Python, y de inteligencia artificial (machine y deep learning). Conocerás como implementar Python con redes neuronales y como crear un Chat Bot desde cero.\nEl curso contiene todo lo necesario para que puedes salir adelante con las bases de IA, y de esta manera crear tus propios chatbots a tu medida y gusto según lo que necesites .\nCabe destacar que gracias a este curso se te hará mas fácil comprender como se integran los bots en distintas plataformas, ya que daré esa información a medida que avance los videos en las secciones del proyecto.\nAdemás, este cuso posee ejemplos didácticos y muy intuitivos para que puedan tener una visión mas grafica y mucho mejor de lo que se trata de explicar.\nLos videos del curso en su mayoria son de buena calidad visual y auditiva y conllevan información recopilada durante mucho tiempo, con evidencias y casos reales que sustentas la inteligencia artificial desde sus orígenes hasta la capacidad que posee para realizar actividades eficazmente.\n\n\nGracias al contenido de este curso conocerás la inteligencia artificial desde un ámbito conversacional a través de chat bots que permite enviar respuestas certeras a preguntas complejas. De esta manera podras generar variedades de bots para distintas plataformas como telegram, discord, WhatsApp.\nSolo necesitaras implmentar el api para poner obtener la data y responder con información predictiva.",
      "target_audience": [
        "Este curso es para todo aquel que esta interesado en los procesos de chat automatizados",
        "Este curso es para todo aquel que esta interesado en adentrarse en la inteligencia artificial",
        "Este curso es para todo aquel desea conocer mas sobe la potencia de Python"
      ]
    },
    {
      "title": "Pratik Yapay Zeka Eğitimi",
      "url": "https://www.udemy.com/course/pratik-yapay-zeka-egitimi/",
      "bio": "Python, R, Google Colab, UIPath, Power BI'yı kullanarak Pratik Yapay Zeka uygulamaları yazın.",
      "objectives": [
        "Yapay zeka teknolojileri ve kullanım alanları hakkında gerekli temel bilgilere sahip olun",
        "Python, R, UIPath, Power BI ve mobil uygulama programlamacılıyla ilgili tecrübe edinin",
        "Makine Öğrenmesi, Derin Öğrenme, Robotik Vizyon ile yeni uygulamalar yapın",
        "Veri Bilimi ve Keşifsel Veri Bilimi (Exploratory Data Science) ile uygulamalar hazırlayın",
        "FB Prophet paketiyle gelecekteki ürün satışları, kur ve sanal para tahminlerinde bulunmayı öğrenin",
        "Dijital Resimlerden Nesne belirleme, yüz ve kimlik belirleme, ses klonlama tekniklerini öğrenin",
        "Python Bokeh ile otomatik web dökümanlari ve sunumlar yapmayı öğrenin"
      ],
      "course_content": {},
      "requirements": [
        "Bilgisayar ve internet bağlantısının olması gerekir."
      ],
      "description": "Pratik Yapay Zeka Eğitimi'nde yapay zeka teknolojileri ve kullanım alanları hakkında gerekli temel bilgiler, örneklerle anlatılmaktadır. Eğitimin amacı:\n• Yapay Zeka teknolojileri ve kullanım alanları hakkında gerekli temel bilgiler vermek.\n• Bilişim teknolojilerinin içerisinde nasıl kullanıldığını göstermek\n• Örnek programlarla ve projelerle Endüstri 4.0’e hazırlanmanızı sağlamak\n• Python, R, Google Colab, UIPath, Power BI'yı kullanarak Yapay Zeka'yı öğrenin.\n• Bilgiyle ve tecrübeyle yoğrulmuş, uzaktan yapılan yeni bir eğitimini tanıştırmak.\nHedef Katılımcılar: Yeni mezun olmuş üniversiteliler, lise öğrencileri, yöneticiler, girişimciler, kendini geliştirmek isteyen herkes.",
      "target_audience": [
        "Python'a yeni başlayan öğrenciler, R, UIPath, Power BI gibi programlar öğrenmek isteyenler."
      ]
    },
    {
      "title": "가장 많이 쓰는 통계법을 가장 쉽게 하는 방법",
      "url": "https://www.udemy.com/course/ezstatistics/",
      "bio": "클릭 몇 번으로 다양한 통계, 다양한 그래프를 쉽게 만드세요",
      "objectives": [
        "통계를 빨리 간단히 배우고 싶은 분",
        "복잡한 것은 싫고 단순한 것을 좋아하는 분",
        "복잡한 논문, 연구하고 싶지 않고, 가장 기본적인 통계만 사용하실 분",
        "간단한 도구로 많은 흔히 사용하는 통계를 하기 원하시는 분"
      ],
      "course_content": {
        "가장 많이 쓰는 통계법을 가장 쉽게 하는 방법": [
          "소개",
          "기술통계",
          "상관분석",
          "한번에 만드는 다양한 데이터 시각화",
          "한번에 행하는 다양한 추론 통계들",
          "요약, 그리고 꼭 알아야 할 지식들"
        ]
      },
      "requirements": [
        "인터넷 연결되는 컴퓨터"
      ],
      "description": "기초 통계 강의의 단골 제목들을 한 시간 이내에 배웁니다.\n간단한 4개의 도구를 이용해서 기술통계와 추론 통계, 그리고 데이터 시각화까지 완성합니다.\n데이터만 로딩하면 거의 바로 완성됩니다.\n간단한 것을 더이상 복잡하게 하지 마세요.\nCorrelation(상관분석)\nt-test(독립 t 검정), ANOVA(분산 분석), MW( test맨위트니 검정) KW test(크루스칼 왈리스 검정)\nChi-square test (continuity correction) (카이제곱 검정-연속성 수정)\nFisher Exact test(피셔의 정확 검정)",
      "target_audience": [
        "기초 통계를 빨리 배우고 싶은 분"
      ]
    },
    {
      "title": "[ES] Masterclass IA: De Cero a Héroe de la IA",
      "url": "https://www.udemy.com/course/masterclass-de-ingenieria-en-ia-de-cero-a-heroe-de-la-ia/",
      "bio": "Domina la Ingeniería en IA: Construye, entrena y despliega soluciones escalables con proyectos reales (AI)",
      "objectives": [
        "Crea modelos de IA usando Python, TensorFlow y PyTorch para desarrollar sistemas inteligentes capaces de resolver problemas del mundo real.",
        "Preprocesa, limpia y analiza conjuntos de datos complejos para garantizar una entrada de alta calidad en el entrenamiento de modelos de aprendizaje automático e",
        "Entrena, evalúa y optimiza modelos de aprendizaje automático para tareas como regresión, clasificación y agrupamiento.",
        "Diseña, implementa y ajusta redes neuronales, incluyendo CNNs y RNNs, para aplicaciones avanzadas de inteligencia artificial.",
        "Aplica técnicas de Procesamiento de Lenguaje Natural (PLN) para analizar, interpretar y generar texto con características humanas.",
        "Aprovecha el aprendizaje por transferencia para adaptar modelos de IA preentrenados a nuevas tareas, reduciendo el tiempo y los recursos de desarrollo.",
        "Despliega modelos de IA utilizando APIs escalables y herramientas de contenedorización como Docker para una integración fluida en aplicaciones.",
        "Supervisa el rendimiento de los modelos de IA, detecta desviaciones en los datos y establece flujos de trabajo de reentrenamiento para garantizar una fiabilidad",
        "Resuelve desafíos empresariales y técnicos del mundo real utilizando enfoques impulsados por IA y sistemas inteligentes.",
        "Desarrolla proyectos de IA de extremo a extremo, desde la ideación y el prototipado hasta el despliegue y el mantenimiento a largo plazo."
      ],
      "course_content": {},
      "requirements": [
        "Conocimientos básicos de programación: Se recomienda tener familiaridad con Python, aunque no es obligatorio.",
        "Curiosidad y entusiasmo: Una pasión por la inteligencia artificial y disposición para aprender son esenciales.",
        "Acceso a una computadora: Una computadora con conexión a internet y suficiente capacidad de procesamiento para tareas de inteligencia artificial.",
        "No se requiere experiencia previa en IA: El curso comienza con conceptos fundamentales y avanza gradualmente.",
        "Habilidades matemáticas básicas: Comprensión de conceptos matemáticos a nivel de secundaria (por ejemplo, álgebra, estadística básica).",
        "Una conexión a internet estable: Para acceder al material del curso, las herramientas y los proyectos prácticos.",
        "Herramientas opcionales: Instalación de Python, Jupyter Notebook y bibliotecas de IA relevantes (se proporciona orientación en el curso).",
        "Mentalidad abierta: Esté dispuesto a explorar, experimentar y construir aplicaciones de IA del mundo real."
      ],
      "description": "Este curso está traducido mediante IA del inglés al español para que puedas aprender tecnologías de vanguardia en tu idioma nativo.\n\n¡Bienvenido a la Masterclass de Ingeniería en IA: ¡De Cero a Héroe de la IA! Este curso integral de IA está diseñado para llevarte en un emocionante viaje desde un principiante en IA hasta convertirte en un Ingeniero de IA seguro, equipado con las habilidades para construir, entrenar y desplegar soluciones de Inteligencia Artificial. Ya sea que empieces desde cero o busques consolidar tu experiencia en IA, esta Masterclass te proporciona la hoja de ruta paso a paso que necesitas para tener éxito.\nEn esta Masterclass de Ingeniería en IA, comenzarás con los fundamentos de la IA, explorando la programación en Python, el preprocesamiento de datos y los conceptos básicos del aprendizaje automático. A medida que avances, te adentrarás en temas avanzados de IA como redes neuronales, aprendizaje profundo, procesamiento de lenguaje natural (PLN) y visión por computadora. También obtendrás experiencia práctica con los marcos de IA más avanzados, como TensorFlow, PyTorch y Hugging Face, para crear soluciones de IA listas para producción.\nEsta Masterclass de IA pone énfasis en habilidades prácticas de IA, con proyectos del mundo real integrados en cada módulo. Aprenderás a resolver problemas empresariales reales utilizando tecnologías de IA, optimizar modelos de IA y desplegar soluciones escalables.\n¿Por qué elegir la Masterclass de Ingeniería en IA?\nCurrículo de IA amigable para principiantes: Comienza desde cero y conviértete en un experto\nProyectos prácticos de IA: Construye aplicaciones de IA reales para desafíos del mundo real\nDomina los marcos de IA: Aprende TensorFlow, PyTorch y Hugging Face\nFormación integral en IA: Cubre Python, Aprendizaje Automático, Aprendizaje Profundo, PLN y Despliegue de IA\nHoja de ruta \"De Cero a Héroe de la IA\": Ruta de aprendizaje estructurada para dominar la IA por completo\nAl finalizar esta Masterclass de Ingeniería en IA, no solo habrás dominado las habilidades de ingeniería en IA, sino que también estarás capacitado para innovar, liderar proyectos de IA y generar transformación con soluciones de IA en tu organización o startup.\nYa seas un aspirante a Ingeniero de IA, un entusiasta de la IA, o alguien que busca ingresar a la industria de la Inteligencia Artificial, esta Masterclass de IA es tu recurso definitivo para pasar de Cero a Héroe de la IA.\nÚnete a la Revolución de la IA Hoy – Inscríbete en la Masterclass de Ingeniería en IA: De Cero a Héroe de la IA y da el primer paso hacia el dominio de la IA!",
      "target_audience": [
        "Futuros ingenieros de IA: Personas que desean iniciar una carrera en inteligencia artificial adquiriendo habilidades prácticas y trabajando en proyectos del mundo real.",
        "Científicos y analistas de datos: Profesionales que buscan ampliar su experiencia mediante la construcción y el despliegue de modelos de inteligencia artificial.",
        "Desarrolladores de software: Programadores interesados en integrar capacidades de inteligencia artificial en sus aplicaciones y sistemas.",
        "Personas en transición profesional: Individuos de sectores no técnicos que están listos para incorporarse a la industria de la inteligencia artificial.",
        "Estudiantes de posgrado: Estudiantes de ciencia de datos, informática o campos relacionados que buscan conocimientos prácticos en inteligencia artificial.",
        "Emprendedores tecnológicos: Fundadores y CTOs que exploran la inteligencia artificial para la innovación de productos y el crecimiento empresarial.",
        "Entusiastas de la IA: Cualquier persona apasionada por la inteligencia artificial que desee construir sistemas inteligentes desde cero.",
        "Profesionales del mundo empresarial: Líderes que buscan comprender la inteligencia artificial para la toma de decisiones estratégicas y el crecimiento organizacional."
      ]
    },
    {
      "title": "Pythonによる機械学習実践演習~線形回帰からCNNやRNNなどの最新DeepLearningアルゴリズムまで~",
      "url": "https://www.udemy.com/course/python-v/",
      "bio": "本コースは、機械学習を用いたデータ分析のコースです。機械学習をする前の基本的な統計処理から、最近流行りのディープラーニングまで学ぶことができます。Jupyter notebookを用いて、手を動かしながら解説していきます。",
      "objectives": [
        "機械学習を用いたデータ分析の流れが理解できます。",
        "Deep Learning(CNNやRNN)を実装できます。",
        "教師あり学習、教師なし学習をそれぞれ理解することができます。",
        "データの前処理について学ぶことができます。",
        "scikit-learn, chainer, tensorflowの使い方をマスターできます。"
      ],
      "course_content": {
        "はじめに": [
          "イントロダクション",
          "コースの概要",
          "環境構築"
        ],
        "機械学習の概要": [
          "Lesson0 Section2の概要",
          "Lesson1 機械に学習させるとは",
          "Lesson2 教師あり学習と教師なし学習",
          "Lesson3回帰と分類",
          "Lesson4 機械学習を用いたデータ分析の流れ",
          "Lesson5 まとめ"
        ],
        "教師あり学習（回帰）": [
          "Lesson0 Section3の概要",
          "lesson1 回帰とは",
          "lesson2.1 データの準備",
          "lesson2.2 pandasを使ったデータの理解",
          "lesson3 sklearnによる線形回帰",
          "lesson4 重回帰分析",
          "Lesson5 まとめ"
        ],
        "教師あり学習（分類）": [
          "Lesson0 Section4の概要",
          "lesson1.1 分類とは",
          "lesson1.2 Logistic Regressionとは",
          "lesson 2.1 データの準備",
          "lesson2 pandasとmatplotlibでデータを理解する",
          "lesson3 Logistic Regression(実装)",
          "lesson4.1 SVM",
          "lesson4.2 SVMの実装"
        ],
        "教師なし学習": [
          "Lesson0 Section5の概要",
          "Lesson1 教師なし学習とは",
          "lesson2.1 データの準備",
          "lesson2.2 pandasとmatplotlibでデータを理解する",
          "lesson3.1 主成分分析(PCA)",
          "lesson3.2 主成分分析(PCA)の実装",
          "lesson4.1 k-means",
          "lesson4.2 k-meansの実装"
        ],
        "Neural Network": [
          "Lesson0 Section6の概要",
          "Lesson1.1 Neural Network",
          "Lesson1.2 Back propergation",
          "Lesson2.1 画像データ",
          "Lesson2.2 データの準備(p)",
          "Lesson3.1 chainerの使い方(説明)",
          "Lesson3.1 chainerの使い方(実装)",
          "lesson3.2 chainerによる多層パーセプトロンの実装1",
          "lesson3.3 chainerによる多層パーセプトロンの実装2",
          "lesson4.1 tensorflowの使い方",
          "lesson4.2 tensorflow用いた多層パーセプトロンの実装1",
          "lesson4.3 tensorflowを用いた多層パーセプトロンの実装2"
        ],
        "Deep Learning": [
          "Lesson0 Section7の概要",
          "lesson1 Deep Learningとは",
          "lesson2.1 Convolutional neural network1",
          "lesson3 データの準備",
          "lesson4.1 chainerを用いたCNNの実装1",
          "lesson4.2 tensorflowを用いたCNNの実装1",
          "lesson4.3 tensorflowを用いたCNNの実装2",
          "Lesson5.1 Recurrent Neural Networkとは",
          "Lesson5.2 時系列データの準備(p)",
          "Lesson5.3 chainerによるLSTMの実装_1(p)",
          "Lesson5.3 chainerによるLSTMの実装_2(p)"
        ]
      },
      "requirements": [
        "初歩的な高校数学の知識が必要",
        "基本的なpythonの知識が必要",
        "基本的なプログラミング文法の学習経験（入門レベルで構いません）"
      ],
      "description": "※各sectionごとのコースの流れと理論の概要についての説明講義のみ無料でプレビューにて公開してあります。受講する前に一度視聴して、レベル感などを確かめてから受講を決定されることをお勧めします。\n\n\n本コースは、機械学習の仕組みから、chainer、tensorflowを用いたDeepLearningの実装までカバーした講座です。\nこんな方にオススメ\n機械学習がよくわからない\nビジネスで機械学習を応用したい\nDeep Learningを実際に動かしながら学びたい\n\n\n受講するメリット\n\n教科書では学びにくい実装の部分を、一緒に手を動かしながら学習できます。\n複雑な数理やアルゴリズムはあえてスキップしているので、直感的な理解が得られます。\n機械学習だけでなく、データ分析全体の流れを理解できます。\n\n\n学習のステップ\n機械学習とは何かを理解します。\nデータ分析の流れを理解します。\n教師あり学習を理解・実装できるようになります。\n教師なし学習を理解・実装できるようになります。\nニューラルネットワークについて、理解・実装できるようになります。\nDeep Learningを理解、実装できるようになります。\n\n\n以上のステップでは、各セクションで機械学習を用いたデータ分析の流れに沿うことで、繰り返し学習を行い、現場ですぐに使える知識と技術を学んでいきます。\n\n実装の講義では、データ分析の現場で頻繁に利用されているJupyter notebook上でPythonを実装していきます。",
      "target_audience": [
        "ある程度プログラミング言語は触ったことがあり、機械学習を仕事に応用したり、教養として機械学習を学びたい方。"
      ]
    },
    {
      "title": "C++ ile Görüntü İşleme (OpenCV)",
      "url": "https://www.udemy.com/course/goruntu-isleme/",
      "bio": "Görüntü İşlemenin Temellerinden, Görüntüleri Anlamlandırma Yolunda...",
      "objectives": [
        "Matris ve Piksel Kavramı",
        "Kanallar",
        "Matris Çizim İşlemleri",
        "Matriste Konumlar Üzerine Çalışma",
        "Boyutlandırma",
        "Görüntü Kavramı Tanımı ve Tarihi",
        "Görüntü Formatları ve İşlemleri",
        "Renk Uzayları",
        "Morfoloji ve İşlemleri",
        "Trackbar Kullanımı",
        "Filtreler",
        "Vektörler",
        "Histogram",
        "RNG ve Rastgele Çevreleme",
        "Kontur",
        "Afin Geometrisi ve Döndürme",
        "Perspektif ve Kuş Bakışı Kavramları",
        "Şerit Bulma",
        "Çizgi ve Daire Tespiti",
        "Mouse İşlemleri",
        "Webcam Okuma"
      ],
      "course_content": {
        "Genel Bilgiler, Tanıtım ve Tarihçe": [
          "C++ ile Görüntü İşleme (OpenCV)",
          "OpenCV Tarihçesi, Neler Yapılabilir?",
          "Kurstaki Verimi Artırmak"
        ],
        "Kurulum İşlemleri": [
          "OpenCV Kurulumu",
          "Visual Studio Kurulumu",
          "OpenCV Kütüphanesini Dahil Etmek"
        ],
        "Matris İşlemleri": [
          "Matris ve Piksel Kavramı",
          "Matris ve Pencere Oluşturma",
          "Kanallar",
          "Matriste Çizim İşlemlerİ -1",
          "Matriste Çizim İşlemleri -2",
          "Matriste Çizim İşlemleri -3",
          "Matriste Yazı Yazdırma İşlemi",
          "Matrisin Satır ve Sütun Sayısını Öğrenme",
          "Belirli Konumda İşlem Yaptırmak",
          "Klonlama ve Kopyalama",
          "Animasyon Yapalım",
          "Boyutlandırma",
          "Piksellere Karışık Değerler Atama"
        ],
        "Görüntü Okuma ve Yazma": [
          "Görüntü Kavramı",
          "Görüntü Okuma",
          "Görüntü Formatları, Görüntü Yazma ve Görüntü Kalitesi Ayarlama",
          "Resimlerde Renk Dönüşümü",
          "Video Açma",
          "Webcam Kullanımı",
          "Video FPS Değerini Pencereye Yazdırma",
          "Videoda Değişken Gösterme ve Değerini Anlık Arttırma",
          "Byte Kavramı ve Piksellerin İçerisine Ulaşmak -1",
          "Byte Kavramı ve Piksellerin İçerisine Ulaşmak -2",
          "Byte Kavramı ve Piksellerin İçerisine Ulaşmak -3"
        ],
        "Zeros, Ones ve Eyes": [
          "Zeros",
          "Ones",
          "Eye"
        ],
        "Piksel İşlemleri": [
          "Gri Formattaki Görüntünün Yoğunluğunu Değiştirmek",
          "RGB Formattaki Renklere Ulaşmak ve İşlemek"
        ],
        "Bitwise İşlemler": [
          "Negatif Görüntüye Ulaşmak"
        ],
        "Binary Dönüşüm ve Morfolojik İşlemler": [
          "Binary Dönüşümü",
          "Farklı Bir Binary Dönüşümü",
          "Morfoloji Kavramı",
          "Aşındırma",
          "Yayma",
          "Kapama",
          "Açma",
          "TOPHAT ve BLACKHAT",
          "Gradient",
          "GUİ Trackbar: Tanıyalım",
          "GUİ Trackbar: Gelişelim"
        ],
        "Filtre": [
          "Filtre Kavramı",
          "Bulanıklaştırma",
          "Medyan Filtresi",
          "Gauss Filtresi",
          "Bilateral Filtre",
          "Canny Kenar Bulma",
          "Binary + Canny = ?"
        ],
        "Vektörler": [
          "Vektör ve İteratör",
          "Nasıl Oluşturulur?",
          "Kullanım, Değer Atama ve Ekranda Gösterme",
          "push_back(), pop_back() ve Silme",
          "Vektörü Sergilemek",
          "Herhangi Bir Değere Ulaşma",
          "Takas (SWAP)"
        ]
      },
      "requirements": [
        "Temel C++ Bilgisi",
        "Temel Arduino Bilgisi",
        "Arduino ya da Raspberry Pi (3 ve üzeri)(İsteğe Bağlı)"
      ],
      "description": "Merhabalar,\nC++ ile Görüntü İşleme  (OpenCV) kursu ile C++ yazılım dilinin diğer yazılım dillerine göre daha sistemli çalışmasından yararlanarak, OpenCV kütüphanesi ile uygulamalı projeler gerçekleştireceğiz. Kurs içerisinde en temel matris konularından, en ileri nesne tanıma uygulamaları dahil iyi bir temel atabilecek, görüntüleri anlamlandırabilecek ve işleyebileceksiniz. Her bir içerik öğrenciyi sıkmadan, eğlendirerek öğretmek amacıyla oluşturuldu. Kurs içerisinde ki kavram başlıkları ile basit bir giriş yapıp, bölüm konuları ile öğrenip ve bölüm sonu kazanımları ile neleri öğrendiğimizi anlayacağız. Dahası, anlam yüklediğimiz görüntülere ek olarak elektroniğinde gücünden faydalanıp, gömülü sistem projeleri de gerçekleştireceğiz.\nŞimdiden aramıza hoş geldin.\nSaygılarımla,\nYılmaz",
      "target_audience": [
        "Veri Bilimine Meraklı Olanlar",
        "Görüntü İşleme Öğrenmek İsteyenler",
        "Görüntüleri Anlamlandırmak İsteyenler",
        "OpenCV Kütüphanesini Öğrenmek İsteyenler"
      ]
    },
    {
      "title": "Ciência de Dados: do Zero ao Mercado de Trabalho!",
      "url": "https://www.udemy.com/course/ciencia_de_dados/",
      "bio": "Domine Ferramentas, Técnicas e Projetos Práticos para se Destacar no Mundo da Ciência de Dados com Python!",
      "objectives": [
        "Entender os conceitos básicos de ciência de dados e da área de dados como um todo.",
        "Familiarizar-se com o ambiente de trabalho em ciência de dados.",
        "Instalar as principais ferramentas de ciência de dados, como Anaconda e Jupyter Notebook, e utilizá-las de forma eficaz.",
        "Revisar conceitos essenciais de cálculo, estatística e álgebra linear.",
        "Aprender as noções básicas das bibliotecas NumPy, Pandas, Matplotlib e Seaborn.",
        "Obter dados de diversas fontes.",
        "Implementar estratégias de limpeza de dados e tratamento de valores ausentes, assim como aplicar estratégias de transformação e encoding de variáveis.",
        "Compreender os fundamentos da aprendizagem de máquina e os principais algoritmos.",
        "Estudar em profundidade algoritmos de machine learning, como regressão linear, regressão logística, árvores de decisão, random forest, k-NN e SVM.",
        "Desenvolver projetos completos em ciência de dados. No total serão 25 projetos completos resolvidos passo a passo.",
        "Realizar o deploy de modelos de machine learning em aplicações web utilizando Flask.",
        "Acompanhar dicas profissionais e atualizações da área de ciência de dados periodicamente."
      ],
      "course_content": {
        "Apresentação e Preparação do Ambiente": [
          "O curso \"Ciência de Dados: do Zero ao Mercado de Trabalho\" - Apresentação",
          "Apresentação",
          "O que é Ciência de Dados",
          "Conteúdo Programático - O que veremos ao longo do curso?",
          "Que sou eu?",
          "Preparação do Ambiente",
          "ATENÇÃO para Instalação no Windows",
          "Instalação no Ambiente Windows",
          "Instalação no Ambiente Linux (e MacOS)",
          "Conhecendo o Ambiente de Ciência de Dados",
          "Materiais do Módulo, Links úteis, Bibliografia e Finalização do Módulo 1"
        ],
        "O processo de Ciência de Dados e os Principais Pacotes": [
          "Introdução ao Processo de Ciência de Dados e principais pacotes",
          "Estudo de Caso: Avaliação de Crédito (Credit Score)",
          "Python Open Data Science Stack",
          "Principais pacotes: Numpy",
          "Principais Pacotes: MatplotLib",
          "Principais Pacotes: Scipy",
          "Principais Pacotes: Pandas",
          "Principais Pacotes: Scikit-Learn",
          "Principais Pacotes: Statsmodels",
          "Principais Pacotes: Seaborn",
          "Materiais do Módulo, Links úteis, Bibliografia e Finalização do Módulo 2"
        ],
        "Noções Básics de Matemática (Cálculo, Álgebra Linear e Estatítica)": [
          "CÁLCULO: Introdução ao Cálculo",
          "CÁLCULO: Funções",
          "CÁLCULO: Limites",
          "CÁLCULO: Derivada",
          "CÁLCULO: Aplicações de Derivada",
          "ÁLGEBRA LINEAR: Introdução à Álgebra Linear",
          "ÁLGEBRA LINEAR: Vetores",
          "ÁLGEBRA LINEAR: Matrizes",
          "ÁLGEBRA LINEAR: Aplicações da Álgebra Linear - Parte 1",
          "ÁLGEBRA LINEAR: Aplicações da Álgebra Linear - Parte 2",
          "ESTATÍSTICA: Introdução à Estatística",
          "ESTATÍSTICA: Tipos de Dados",
          "ESTATÍSTICA: Medidas de Tendência Central",
          "ESTATÍSTICA: Medidas de Dispersão",
          "ESTATÍSTICA: Distribuição de Probabilidade",
          "ESTATÍSTICA: Estatística Inferencial",
          "ESTATÍSTICA: Amostragem e Estimação",
          "ESTATÍSTICA: Teste de Hipótese",
          "ESTATÍSTICA: Regressão Linear",
          "ESTATÍSTICA: Anova",
          "Materiais do Módulo, Links úteis, Bibliografia e Finalização do Módulo 3"
        ],
        "Noções de Numpy": [
          "Introdução ao Numpy",
          "Noções Básicas de Numpy",
          "Operações Básicas com Numpy",
          "Trabalhando com Array Numpy",
          "Limpeza de Dados e Estatística com Numpy",
          "Álgebra Linear com Numpy",
          "Materiais do Módulo, Links úteis, Bibliografia e Finalização do Módulo 4"
        ],
        "Noções de Pandas": [
          "Introdução ao Pandas",
          "Explorando as Bases do Pacote Pandas",
          "Séries",
          "Dataframes",
          "Groupby",
          "Mesclar, Juntar e Concatenar",
          "Principais Funções e Métodos",
          "Visualização de Dados com o Pandas",
          "Materiais do Módulo, Links úteis, Bibliografia e Finalização do Módulo 5"
        ],
        "Visualização de Dados com Matplotlib e Seaborn": [
          "Introdução aos Pacotes Matplotlib e Seaborn",
          "MatPlotLib - Gráficos Básicos",
          "MatPlotLib - Gráficos mais elaborados",
          "Seaborn - Principais gráficos",
          "Como escolher um gráfico?",
          "Materiais do Módulo, Links úteis, Bibliografia e Finalização do Módulo 6"
        ],
        "Obtendo Dados": [
          "Introdução: Dados Estruturados vs Semiestruturados vs Não-estruturados",
          "Obtendo Dados Estruturados",
          "Obtendo Dados Semi-Estruturados",
          "Materiais do Módulo, Links úteis, Bibliografia e Finalização do Módulo 7"
        ],
        "Estratégias de Limpeza de Dados": [
          "Principais Estratégias de Limpeza de Dados",
          "Projeto 01 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 02 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 03 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 04 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 05 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 06 - Parte 01 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 06 - Parte 02 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 06 - Parte 03 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 06 - Parte 04 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 06 - Parte 05 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 06 - Parte 06 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 06 - Parte 07 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 06 - Parte 08 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 07 - Parte 01 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 07 - Parte 02 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 07 - Parte 03 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 07 - Parte 04 - Estratégias de Limpeza e Valores Ausentes",
          "Projeto 07 - Parte 05 - Estratégias de Limpeza e Valores Ausentes",
          "Materiais do Módulo, Links úteis, Bibliografia e Finalização do Módulo 8"
        ],
        "Transformação e Encoding de Variáveis": [
          "Introdução a transformação e encoding de variáveis",
          "Projeto 08 - Count/Frequency Encoding",
          "Projeto 09 - Label Encoding",
          "Projeto 10 - One Hot Encoding",
          "Materiais do Módulo, Links úteis, Bibliografia e Finalização do Módulo 9"
        ],
        "Aprendizagem de Máquina (Machine Learning)": [
          "Introdução à Aprendizagem de Máquina",
          "Como a máquina aprende?",
          "Como REALMENTE a máquina aprende?",
          "O que é um MODELO de Machine Learning?",
          "Quais são os tipos CLÁSSICOS de Machine Learning?",
          "Quais são os tipos de Machine Learning de REFORCEMENT LEARNING ?",
          "Quais são os tipos de Machine Learning de ENSEMBLE METHODS ?",
          "Quais são os tipos de Machine Learning de REDES NEURAIS ARTIFICIAIS ?",
          "Como escolher o algoritmo de Machine Learning \"IDEAL\" ?",
          "Conhecendo um Algoritmo de Machine Learning ...",
          "O processo de aprendizagem: Sistema de Recomendação de Filmes",
          "O processo de aprendizagem: Overfitting, Underfitting, Viés e Variância",
          "Materiais do Módulo, Links úteis, Bibliografia e Finalização do Módulo 10"
        ]
      },
      "requirements": [
        "Ter conhecimentos básicos de programação (preferencialmente em Linguagem Python).",
        "Possuir noções básicas de inglês técnico, especialmente terminologia relacionada a ciência de dados e programação (devido aos principais conjuntos de dados usados e métodos do Python serem em Inglês).",
        "Estar disposto a aprender de forma autônoma, complementando o conteúdo do curso com leituras adicionais e prática.",
        "Dispor de um computador com capacidade para instalar e executar ferramentas de ciência de dados como Anaconda e Jupyter Notebook.",
        "Entender conceitos fundamentais de organização de dados, incluindo modelagem de dados básica (não fundamental, apenas desejável)."
      ],
      "description": "Bem-vindo(a) ao curso de Ciência de Dados: do Zero ao Mercado de Trabalho!\nA profissão de Cientista de Dados é uma das mais procuradas e bem remuneradas no mercado atual. Com uma demanda crescente em diversas áreas, desde tecnologia até saúde e finanças, a Ciência de Dados se tornou uma habilidade essencial para quem deseja se destacar no mundo profissional. Segundo a IBM, a demanda por cientistas de dados crescerá 28% até 2025, e continuará crescendo, em média 38% até 2030, segundo dados do último \"Estudo Panorama das Carreiras 2030\" da TOTVS, tornando-se assim uma das carreiras mais promissoras da década.\nNeste curso abrangente, você aprenderá tudo o que precisa para iniciar sua carreira em Ciência de Dados, desde os conceitos básicos até a aplicação prática no mercado de trabalho. Nosso objetivo é fornecer uma formação completa, preparando você para enfrentar desafios reais e desenvolver soluções inovadoras usando Ciência de Dados.\nAprenda os conceitos fundamentais de ciência de dados, instale e configure Anaconda e Jupyter Notebook, e revise matemática essencial (cálculo, estatística e álgebra linear). Utilize bibliotecas como NumPy, Pandas, Matplotlib e Seaborn para análise e visualização de dados. Desenvolva 25 projetos práticos, incluindo 9 completos, e implemente modelos de machine learning em aplicações web usando Flask. Acompanhe atualizações semanais com dicas profissionais e novidades da área.\nPara realizar esse curso, é fundamental que você tenha conhecimentos básicos de programação (preferencialmente da linguagem Python) e inglês técnico básico para leitura; noções de organização de dados e experiência com planilhas ou bancos de dados são desejáveis. O fundamental é que você tenha vontade de aprender de forma autônoma e prática!\nEste curso é ideal para desenvolvedores iniciantes, analistas de negócios, profissionais de TI, estudantes de tecnologia, pesquisadores, e profissionais de marketing. Também é perfeito para gestores, executivos, cientistas, engenheiros, empreendedores e entusiastas de dados. Ciência de dados é uma área interdisciplinar e abrangente, aplicável em diversas profissões e setores.\nPor que escolher este curso?\nConteúdo abrangente e atualizado, cobrindo todas as etapas do processo de Ciência de Dados.\nProjetos práticos e reais que preparam você para o mercado de trabalho (no total, serão 25 projetos ao longo do curso!)\nFerramentas e técnicas gratuitas baseadas na linguagem Python.\nMódulo final com contribuições frequentes, com dicas profissionais e atualizações na área de Ciência de Dados.\nTransforme sua carreira com o curso \"Ciência de Dados: do Zero ao Mercado de Trabalho!\" e esteja preparado para as oportunidades que essa área promissora oferece.\nInscreva-se agora e comece sua jornada rumo ao sucesso no mercado de trabalho!",
      "target_audience": [
        "Desenvolvedores iniciantes que desejam entrar na área de ciência de dados.",
        "Analistas de negócios que querem usar dados para tomar decisões mais informadas.",
        "Profissionais de TI que buscam expandir suas habilidades em análise de dados e machine learning.",
        "Estudantes universitários de cursos relacionados a tecnologia, estatística, matemática, engenharia e áreas afins.",
        "Pesquisadores em diversas áreas que desejam aplicar técnicas de ciência de dados em seus projetos.",
        "Profissionais de marketing que querem entender melhor os dados de clientes e campanhas.",
        "Gestores e executivos que buscam uma compreensão mais profunda de como a ciência de dados pode beneficiar suas organizações.",
        "Cientistas e engenheiros que desejam adquirir habilidades práticas em análise de dados.",
        "Empreendedores e startups que querem utilizar ciência de dados para melhorar seus negócios.",
        "Educadores e acadêmicos que desejam incorporar ciência de dados em seus currículos.",
        "Profissionais de saúde interessados em aplicar técnicas de análise de dados em estudos clínicos e pesquisa médica.",
        "Economistas e profissionais de finanças que buscam entender e aplicar análise de dados para previsões econômicas e financeiras.",
        "Entusiastas de dados que querem aprender sobre ciência de dados por interesse pessoal e desenvolvimento profissional contínuo."
      ]
    },
    {
      "title": "【한글자막】 TensorFlow 2.0 : 딥러닝 모델 구현 마스터 패키지",
      "url": "https://www.udemy.com/course/best-keras-api-tensorflow-20/",
      "bio": "신경망 모델링부터 모델 학습, 그리고 실제 서비스 운영까지! TensorFlow 2.0으로 딥러닝을 구현하기 위해 알아야 할 모든 것",
      "objectives": [
        "데이터 사이언스에서 TensorFlow 2.0을 사용하는 방법",
        "TensorFlow 1.x와 Tensorflow 2.0의 주요 차이점",
        "TensorFlow 2.0에서 인공 신경망을 구현하는 법",
        "TensorFlow 2.0에서 CNN을 구현하는 법",
        "TensorFlow 2.0에서 RNN을 구현하는 법",
        "TensorFlow 2.0으로 자신만의 전이 학습 애플리케이션을 구축하는 법",
        "강화학습(Deep Q-Learning) 모델을 통해 주식 거래 봇을 만드는 방법",
        "TensorFlow 2.0에서 머신러닝 데이터 파이프라인을 구축하는 법",
        "Tensorflow 변환을 사용하여 데이터 유효성 검사 및 데이터셋 전처리를 수행하는 법",
        "TensorFlow 2.0로 구현한 모델을 실제 서비스에서 운영하는 법",
        "Flask와 TensorFlow 2.0으로 실제 패션 API를 만드는 방법",
        "RESTful API가 있는 TensorFlow 모델을 서빙하는 방법"
      ],
      "course_content": {
        "소개": [
          "텐서플로우 2.0 강의에 오신 것을 환영합니다! 구조와 TF 툴킷에 대해 알아보기",
          "강의 커리큘럼 & 코랩 툴킷",
          "보너스: 텐서플로우의 10가지 장점",
          "보너스: 학습 계획"
        ],
        "텐서플로우 2.0의 기초": [
          "텐서플로우 1.x에서 텐서플로우 2.0에 이르기까지",
          "상수, 변수, 텐서",
          "텐서를 이용한 연산하기",
          "문자열"
        ],
        "인공 신경망": [
          "프로젝트 환경 설정",
          "데이터 전처리",
          "인공 신경망의 구축하기",
          "인공 신경망의 학습하기",
          "인공 신경망의 평가하기",
          "퀴즈 1: 인공 신경망 퀴즈",
          "연습 문제: 인공 신경망",
          "연습 문제 답안: 인공 신경망"
        ],
        "컨볼루션 신경망": [
          "프로젝트 환경 설정 & 데이터 전처리",
          "컨볼루션 신경망의 구축하기",
          "컨볼루션 신경망의 학습과 평가하기",
          "퀴즈 2: 컨볼루션 신경망 퀴즈",
          "연습 문제: 컨볼루션 신경망",
          "연습 문제 답안: 컨볼루션 신경망"
        ],
        "순환 신경망": [
          "프로젝트 환경 설정 & 데이터 전처리",
          "순환 신경망의 구축하기",
          "순환 신경망의 학습과 평가하기",
          "퀴즈 3: 순환 신경망 퀴즈"
        ],
        "전이학습과 미세 조정": [
          "전이학습이란 무엇인가?",
          "프로젝트 환경 설정",
          "데이터 전처리",
          "MobileNet V2 모델 불러오기",
          "사전학습 모델의 동결하기",
          "사전학습 모델에 커스텀 헤드 추가하기",
          "전이학습 모델 정의하기",
          "전이학습 모델 컴파일링하기",
          "이미지 데이터 생성기",
          "전이학습",
          "전이학습의 평가",
          "미세 조정 모델의 정의하기",
          "미세 조정 모델 컴파일링하기",
          "미세 조정",
          "미세 조정 결과의 평가하기",
          "퀴즈 4: 전이학습 퀴즈"
        ],
        "딥 강화학습 이론": [
          "강화학습이란 무엇인가?",
          "벨만 방정식",
          "마르코프 결정 과정 (MDP)",
          "Q 러닝의 개요",
          "시간차",
          "딥 Q 러닝의 개요 - 단계 1",
          "딥 Q 러닝의 개요 - 단계 2",
          "경험 재현",
          "행동 선택 정책"
        ],
        "주식 시장 거래를 위한 딥 강화학습": [
          "프로젝트 환경 설정",
          "AI 트레이더 - 단계 1",
          "AI 트레이더 - 단계 2",
          "AI 트레이더 - 단계 3",
          "AI 트레이더 - 단계 4",
          "AI 트레이더 - 단계 5",
          "데이터 세트 로더 함수",
          "상태 생성자 함수",
          "데이터 세트 불러오기",
          "모델 정의하기",
          "학습 루프 - 단계 1",
          "학습 루프 - 단계 2"
        ],
        "텐서플로우 데이터 검증(TFDV)을 이용한 데이터의 검증": [
          "프로젝트 환경 설정",
          "환경 오염 데이터 세트 불러오기",
          "데이터 세트 스키마 생성하기",
          "테스트 세트 통계의 계산하기",
          "텐서플로우 데이터 검증을 활용한 이상 감지하기",
          "프로덕션을 위한 스키마 준비하기",
          "스키마 저장하기",
          "다음엔 뭘 배우게 될까요?"
        ],
        "텐서플로우 트랜스폼(TFT)을 이용한 데이터 세트 전처리": [
          "프로젝트 환경 설정",
          "초기 데이터 세트 전처리하기",
          "데이터 세트 메타데이터",
          "전처리 함수",
          "데이터 세트 전처리 파이프라인",
          "다음엔 뭘 배우게 될까요?"
        ]
      },
      "requirements": [
        "미분이나 기울기 같은 기본적인 수학 개념",
        "파이썬 기초 문법에 대한 사전 학습"
      ],
      "description": "모델 개발 및 유지 보수 프로세스를 단순화해주는 TensorFlow 2.0의 최신 기능들\nTensorFlow 2.0을 통해 핵심적인 신경망 모델들을 학습시키고, 실제 서비스로 운영하는 방법\nTensorFlow Extended(TFX)로 자신만의 데이터 파이프라인을 구축하는 법\n\n\n—\n\n\n[딥러닝과 TensorFlow 2.0 최신 기술 총집합]\n최근 출시된 TensorFlow 2.0은 딥러닝 모델 개발 및 유지 관리 프로세스를 단순화하는 많은 기능을 도입했습니다. 이러한 기능 추가 덕분에 신경망의 복잡한 개념을 단순화하여 쉽게 이해할 수 있도록 교육할 수 있게 됐고, 실제 현업에서는 모델들을 훨씬 더 잘 이해하고 유지 보수 하기가 쉬워졌습니다.\n\n\n이 코스에서는 이러한 TensorFlow 2.0의 추가된 기능들을 통해 딥러닝 최신 모델들을 실제로 구현하는 법에 대해 학습합니다. 신경망 모델링부터, 실제 데이터를 통해 모델을 학습시키고, 학습된 모델을 배포하여 서비스로 운영하는 과정까지 모든 주제를 다룹니다.\n\n\n\n\n[TensorFlow 2.0 최신 기능 학습과 신경망 모델 구현을 위한 최적의 커리큘럼]\n본 강의는 TensorFlow 2.0을 이용해 각종 딥러닝 신경망 모델을 구현하는 과정에서 가장 직관적으로 이해하기 쉽게 설명합니다. 본 코스는 아래의 내용으로 구성되어 있습니다.\n\n\n파트 1 : 코스 전체에서 사용할 기술 스택과 TensorFlow 2.0 라이브러리의 기본 개념 및 구문에 대해 학습합니다\n파트 2 : 딥러닝 모델들에 대해 깊이 있게 학습합니다. ANN, CNN, RNN 등 대표적인 딥러닝 모델들에 대해 학습합니다. 신경망 모델을 개와 고양이 데이터로 학습시켜 분류를 하기 위한 전이 학습 응용 프로그램을 실제로 만들어봅니다.\n파트 3 : 강화학습, 특히 Deep Q-Learning 신경망을 사용하여 자신만의 주식 거래 봇을 만드는 과정을 실습해봅니다.\n파트 4 : TensorFlow Extended(TFX)의 모든것을 배웁니다. 데이터를 직접 다루고, 자신만의 데이터 파이프라인을 구축하기 위한 방법을 배웁니다. TensorFlow에 내장된 데이터 유효성 검사 라이브러리를 통해 데이터셋에 이상이 있는지 확인하는 방법을 배운 뒤, TensorFlow 변환 라이브러리로 자신만의 데이터 전처리 파이프라인을 구축합니다.\n파트 4에서는 Flask를 사용하여 패션 API를 만드는 실습도 진행합니다. 실습을 통해 인터넷 환경에서 모델을 요청하는 방법에 대해 잘 이해하게 됩니다. 이후에 TensorFlow 서빙 라이브러리를 사용하여 수백만 개 이상의 요청을 처리할 수 있는 이미지 분류 API를 만들어봅니다.\n파트 5 : 여러개의 GPU나 TensorFlow 2.0 라이브러리를 활용해 실제 서버를 사용하여 분산학습 시키는 방법을 배웁니다.\n\n\n위 내용을 통해 TensorFlow 2.0의 주요 기능들과, 신경망 모델의 구현 및 데이터 파이프라인 구축에 대한 모든 것을 학습하실 수 있습니다.\n\n\n\n\n[200만 수강생의 데이터 사이언스 학습을 도운 Ligency Team의 한 마디]\n한국 수강생 여러분 안녕하세요!\n전문 데이터 사이언티스트들로 구성된 교육 기관, Ligency Team입니다.\n저희의 [TensorFlow 2.0 : 딥러닝 모델 구현 마스터 패키지] 코스에 오신 것을 환영합니다!\n\n\n딥 러닝은 인공 지능에서 가장 빠르게 성장하는 분야 중 하나입니다. 지난 몇 년 간, 가장 단순한 딥 러닝 모델 조차도 매우 어렵고 복잡한 작업을 해낼 수 있다는 것이 입증되었습니다. 이제 딥 러닝은 단순한 유행어였던 시기를 지나, 제품을 개선하는 데에서도 엄청난 성능과 잠재력을 보여주고 있습니다.\n\n\n이 코스는 신경망을 모델링하고 학습시키는 것부터 실제 운영하기까지의 모든 주제를 다룹니다. 딥러닝 모델에 대한 학습이 필요하신 분들은 이 코스를 통해 많은 도움을 얻을 수 있습니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n이외에 더 자세한 내용은 강의에서 더 자세히 알려드리겠습니다.\n강의에서 만나요!\n- Ligency Team",
      "target_audience": [
        "TensorFlow 2.0을 배우고 싶어하는 딥러닝 엔지니어",
        "딥러닝 기술 스택을 넓히고자 하는 인공지능 엔지니어",
        "딥러닝 및 인공지능의 흥미로운 영역으로 커리어를 전환하고 싶은 프로그래머",
        "AI 기술을 업그레이드하고 싶은 데이터 사이언티스트",
        "딥러닝 및 인공지능 영역으로 커리어를 만들어 가고 싶은 Python 개발자",
        "인공지능 시장에서 앞서 가고 싶은 비즈니스맨과 회사",
        "데이터 사이언스, 머신 러닝 또는 인공지능 쪽의 직업을 갖고 싶은 취업준비생"
      ]
    },
    {
      "title": "KNIME Analytics Platform per Data Scientists, corso base",
      "url": "https://www.udemy.com/course/knime-analytics-platform-per-data-scientists-corso-base/",
      "bio": "Implementare gli algoritmi di machine learning senza usare codice",
      "objectives": [
        "Conoscere KNIME Analytics Platform e le sue caratteristiche principali.",
        "Analizzare i dati, visualizzarli e ricavarne conoscenza, salvare le elaborazioni e creare dei report per presentare la sintesi del tuo lavoro.",
        "Imparare le principali tecniche di machine learning e utilizzarle con KNIME senza scrivere codice.",
        "Imparare ad accedere ai dati con KNIME, in qualsiasi posizione si trovino (file, rete, database)"
      ],
      "course_content": {
        "Introduzione a KNIME Analitics Platform e accesso ai dati": [
          "Presentazione",
          "Introduzione al corso",
          "Informazioni utili per il vostro feedback",
          "Installazione",
          "Installare una Extension",
          "Installazione delle Extensions",
          "KNIME Workbench",
          "KNIME Workbench - Welcome Page e KNIME Hub",
          "Workbench e KNIME Hub",
          "KNIME Workbench - Workflow Editor e Node Explorer",
          "Workflow Editor - Customizzazione",
          "Workflow Editor, riquadro di ricerca e Node Explorer",
          "KNIME Explorer",
          "Le finestre Outline e Description",
          "La Console",
          "KNIME Explorer, Outline e Console",
          "I nodi nel Node Explorer",
          "KNIME Examples e KNIME Hub in dettaglio",
          "KNIME Examples e KNIME Hub",
          "Creare un Workflow Group e un Workflow",
          "KNIME Hub",
          "Il Workflow e gli stati dei nodi",
          "Annotazioni e commenti in un Workflow",
          "Annotazioni e commenti",
          "La struttura dei dati in KNIME",
          "Esportare ed importare un Workflow e un Workflow Group",
          "Leggere (e scrivere) file in KNIME",
          "I Mount Point in KNIME",
          "Il CSV Reader in dettaglio",
          "Il Table Reader",
          "Excel Reader",
          "Excel Reader",
          "Accesso ai dati di un database",
          "Accesso ai dati di un database"
        ],
        "Manipolazione e aggregazione dei dati": [
          "Il nodo Row Filter - prima parte",
          "Il nodo Row Filter - seconda parte",
          "Il nodo Row Filter",
          "Il nodo Column Filter",
          "Manipolazione di dati, numeri, stringhe e regole - parte prima",
          "Rule Engine",
          "Manipolazione di dati, numeri, stringhe e regole - parte seconda",
          "Il nodo Column Expression",
          "Cos'è l'aggregazione dei dati",
          "Aggregazione dei dati con il nodo GroupBy - prima parte",
          "Aggregazione dei dati con il nodo GroupBy - seconda parte",
          "Il nodo Group By",
          "Il nodo Group By",
          "Il nodo Pivoting - prima parte",
          "Il nodo Pivoting - seconda parte",
          "Il nodo Pivoting",
          "Join, Inner Join, Left e Right Outer join, Full Outer Join",
          "Il nodo Joiner: Left Outer Join, Right Outer Join, Full Outer Join",
          "Il nodo Joiner, altri aspetti di configurazione",
          "Il nodo Joiner",
          "il nodo Concatenate",
          "I Metanode e i Components",
          "Metanode e Component"
        ],
        "Visualizzazione e Mining dei dati": [
          "Il nodo Data Explorer",
          "Esplorazione bivariata interattiva utilizzando il nodo Scatter Plot",
          "Creare viste interattive per la visualizzazione dei dati",
          "Data mining",
          "Data mining",
          "Learner & Predictor"
        ],
        "Algoritmi per il data mining": [
          "Classificazione col Decision Tree - caricamento dati e pre-processing",
          "Classificazione col Decision Tree - Learner, Predictor, PMML Writer",
          "Classificazione col Decision Tree - Validazione con Scorer e ROC Curve",
          "Utilizzare un modello di predizione",
          "Regressione lineare - preparazione e analisi del dataset",
          "Regressione lineare - Learner e Predictor in azione",
          "Decision Tree",
          "Logistic Regression",
          "Logistic Regression",
          "Logistic Regression VS Decisione Tree",
          "Clustering utilizzando K-Means",
          "Clustering",
          "K-Means in KNIME",
          "Cluster Assignement",
          "Cluster Assigner"
        ],
        "Salvare le elaborazioni e creare un report": [
          "Scrivere i propri dati su un Database",
          "Utilizzare un database",
          "Scrivere i propri dati su un file",
          "Creare un report con BIRT"
        ],
        "Aggiornamenti del corso relativi alla versione KNIME 5.1": [
          "KNIME Analytics Platform 5.1: download e installazione",
          "KNIME 5.1: La nuova UI/UX",
          "La Nuova UI/UX",
          "KNIME 5.1 Preferences panel",
          "KNIME 5.1: Node Repository, Space Explorer e Quick node adding",
          "KNIME 5.1: Modern UI Configure, Execute, Cancel e Reset",
          "Uso dei component in KNIME 5.1",
          "KNIME 5.1: Modern UI, Node Monitor ed Execute and open view",
          "KNIME 5.1 Modern UI K-AI, KNIME AI Assistent",
          "KNIME AI Assistant"
        ],
        "Esempi e casi d'uso per KNIME Analytics Platform": [
          "Introduzione alla sezione",
          "Elenco dei casi d'uso e degli esempi",
          "Credit Scoring - Introduzione",
          "Credit Scoring - Il Workflow",
          "Credit Scoring",
          "Credit Scoring - Deployment",
          "Churn Analysis - Introduzione",
          "Churn Analysis - Il Workflow",
          "Validazione incrociata",
          "Churn Analysis - Deployment",
          "Market Basket Analysis - Introduzione",
          "Market Basket Analysis - Il Workflow",
          "Market Basket Analysis - Deployment",
          "Market Basket Analysis: confidence, supporto e lift",
          "Fraud detection - Introduzione",
          "Fraud detection",
          "Fraud detection - Il Workflow (Scenario 1)",
          "Fraud detection - Deployment (Scenario 1)",
          "Fraud detection - Il Workflow (Scenario 2, prima parte)",
          "Fraud detection - Il Workflow (Scenario 2, seconda parte)",
          "Fraud detection - Deployment (Scenario 2)",
          "Time Series - Introduzione",
          "Lag column",
          "Time Series - Il Workflow (1° parte)",
          "Time Series - Il Workflow (2° parte)",
          "Inventory optimization",
          "Inventory optimization - Supply Chain Dashboard Inventory Valuation",
          "Inventory optimization - Supply Chain Dashboards Stockouts",
          "Inventory optimization - Supply Chain Dashboards Cycle Time (parte 1°)",
          "Inventory optimization - Supply Chain Dashboards Cycle Time (parte 2°)",
          "Inventory optimization - ABC Analysis Coefficient of Variability Approach",
          "ABC e XYZ",
          "Inventory optimization - ABC Analysis Naive Approach",
          "Anomaly detection - Introduzione (parte 1°)",
          "Anomaly detection - Introduzione (parte 2°)",
          "Anomaly detection - Introduzione (parte 3°)",
          "Anomaly detection - Ispezione visiva dei dati (parte 1°)",
          "Anomaly detection - Ispezione visiva dei dati (parte 2°)",
          "Anomaly detection - Autoregressive model - Workflow di Training",
          "Anomaly detection - Autoregressive model - Workflow di Deployment",
          "Anomaly detection - Control Chart",
          "Anomaly detection",
          "Reccomendation engine - Introduzione",
          "Reccomendation engine - Il workflow",
          "BIG DATA in KNIME Analytics Platform",
          "Customer segmentation - Introduzione",
          "Customer segmentation - Il workflow",
          "Punteggio silhouette"
        ],
        "Materiale extra": [
          "Cheat Sheets"
        ]
      },
      "requirements": [
        "Avere un computer con almeno uno dei seguenti sistemi operativi: Windows, macOS, Linux; potrebbe essere necessario un profilo di amministratore, per l'installazione",
        "Conoscenza delle principali tecniche utilizzate nel machine learning: Supervised e Unsupervised Classification, Clustering",
        "Non serve conoscere alcun linguaggio di programmazione"
      ],
      "description": "Questo corso di rivolge alle persone che manipolano i dati per la loro attività (studenti, professionisti) e vorrebbero utilizzare gli algoritmi di machine learning per il data mining ma non hanno voglia o tempo di imparare un linguaggio di programmazione, come R o Python.\nFortunatamente ci sono strumenti che permettono di raggiungere gli stessi obiettivi, senza utilizzare una riga di codice (a meno che non si voglia proprio farlo).\nTra questi, sicuramente, KNIME Analytics Platform, o più semplicemente KNIME® è il più conosciuto e utilizzato in questo ambito.\nKNIME® è un ambiente completo e Open Source per l'analisi dei dati e il machine learning, che permette l'uso degli algoritmi di data mining più diffusi all'interno di un Workbench visuale, grazie all'utilizzo di componenti software, detti nodi, che combinati in maniera opportuna, permettono di elaborare qualsiasi base di dati.\nIl corso si compone di otto sezioni:\n\n\nIntroduzione all'applicativo KNIME Analytics Platform, i nodi, il Workflow, l'accesso ai dati memorizzati in files, in rete e su un database\nManipolazione e trasformazione dei dati e tecniche di aggregazione\nVisualizzazione dei dati, creazione di viste interattive per l'analisi dei dati\nAlgoritmi di data mining con KNIME: classificazione supervisionata, regressione lineare,  clustering\nSalvataggio dei risultati delle proprie elaborazione su files o su databases e generazione di report\nAggiornamenti del corso relativi alla versione KNIME 5.1\nEsempi e casi d'uso per KNIME Analytics Platform\nMateriale Extra\nLa sezione \"Esempi e casi d'uso per KNIME Analytics Platform\" è un'espansione recente del corso, un corso nel corso, che riporta alcune applicazioni di KNIME Analytics Platform nei più svariati ambiti (gli esempi sono mostrati utilizzando la versione 5.3.2 di KNIME Analytics Platform):\n\n\nCredit scoring: vedremo, nei panni di un impiegato di una banca, come valutare l'affidabilità di un cliente che chiede un prestito, sulla base di alcune informazioni anagrafiche e contabili relativi ai precedenti rapporti finanziari.\nChurn analysis: nei panni di un operatore di telecomunicazioni, impareremo come predire la probabilità di abbandono di un cliente\nMarket basket analysis: siamo i gestori di un supermercato e ci interessa sapere, ogni volta che un cliente compra un certo tipo di articoli, qual è l'articolo che più spesso si trovano ad acquistare altri clienti nelle sue condizioni. Questa esigenze risponde alla regola: 'Se hai questo nel carrello, allora devi avere anche questo...\"\nFraud detection: stavolta vedremo due approcci differenti che sono richiesti dalla natura del problema che vogliamo risolvere; in alcuni casi, infatti, potremo contare su osservazioni che possiamo etichettare come anomalie, perché fanno parte del nostro dataset, mentre in altri non sappiamo che caratteristiche queste possano avere, ma sappiamo come distinguerle dalle osservazioni normali. Il dataset che utilizzeremo è relativo ad un gestore di carte di credito che è interessato a evidenziare le transazioni fraudolente...\nTime series: la predizione di una grandezza che evolve nel tempo è sempre stato un tema affascinante. Adesso, con gli strumenti di machine learning (e con KNIME Analytics Platform), abbiamo la possibilità di riuscire, anche noi a realizzare questo scopo. Il dataset che useremo è relativo ai consumi energetici dell'Irlanda, in un periodo specificato e vedremo come predire i consumi di alcuni cluster di clienti (volutamente si approccerà la tecnica utilizzando alcune semplificazioni, ad esempio, non verrà tenuto conto della stagionalità. Ricordiamo che, dopotutto, questo è un corso base...)\nInventory optimization: la gestione della logistica, in alcuni tipi di business è cruciale per il successo di una azienda. In questo esempio vedremo come possiamo, anche in questo caso, approcciare il tutto utilizzando KNIME\nAnomaly detection: stavolta vedremo un caso particolare di rilevamento di una anomalia, che scaturisce dall'analisi delle misure di alcuni sensori montati su un motore elettrico che ci permetteranno, in ottica preventiva, di individuare il momento esatto in cui sta per iniziare una deriva del suo funzionamento che lo porterà, inevitabilmente, alla rottura.\nReccomendation engine: questa tecnica di machine learning è pervasiva e la vediamo utilizzata su molti siti di e-commerce e piattaforme di streaming (non facciamo nomi). L'esempio che vedremo ci permetterà di raccomandare a un utente, alcuni titoli di film sulla base di alcune preferenze che ha espresso.\nCustomer Segmentation: questa tecnica permette di creare dei clusters dei clienti di una azienda sulla base delle loro caratteristiche demografiche, di consumo e di interazione con la stessa. È una attività che può essere eseguita con diversi approcci, ma noi analizzeremo una implementazione con k-Means e punteggio silhouette, utilizzando un dataset da cui ricaveremo cinque tipologie di clienti su cui cucire la nostre offerte commerciali.\nIn tutte le sezioni si utilizzerà KNIME®, mostrando alcune implementazioni di data mining con dati pubblici.\nPer migliorare la fruizione del corso e trarne il massimo profitto, sono state aggiunte diverse sezioni con Quiz, per verificare il vostro apprendimento e sono stati corretti i sottotitoli generati automaticamente in molte lezioni.\n\n\nNOTE dell'autore:\nKNIME® è un marchio registrato e il logo e il marchio OPEN FOR INNOVATION® sono utilizzati da KNIME AG su licenza di KNIME GmbH e sono registrati negli Stati Uniti. KNIME® è anche registrato in Germania.\nL'autore non é collegato in alcun modo all'azienda.\nIl corso è stato sviluppato sulla traccia del corso self paced [L1-DS] KNIME Analytics Platform for Data Scientists: Basics, disponibile, in lingua inglese, sul sito di KNIME.\nLa sezione \"Esempi e casi d'uso per KNIME Analytics Platform\" è stata elaborata, in buona parte, prendendo dei workflow di esempio dalla cartella Examples, disponibile sull'Hub di KNIME e da articoli pubblicati sul blog di KNIME.\nGli esempi mostrati durante le lezioni sono tutti disponibili sul sito KNIME Hub, cui si rimanda nelle risorse presenti alla fine di ogni lezione del corso.",
      "target_audience": [
        "Studenti di Ingegneria, Statistica, Matematica",
        "Professionisti che nel lavoro hanno a che fare con i dati e che finora hanno utilizzato Excel o MS Access per le loro analisi",
        "Curiosi e appassionati di data mining, che non vogliono impare un linguaggio di programmazione per usare le tecniche di machine learning."
      ]
    },
    {
      "title": "파이썬으로 배우는 실무 데이터 분석",
      "url": "https://www.udemy.com/course/data-analysis-suminw/",
      "bio": "파이썬 기본 문법, 자료 구조, Pandas, Scikit-learn, 머신러닝, 데이터 분석 기초 학습",
      "objectives": [
        "파이썬 문법을 이해하고 프로그래밍을 시작할 수 있습니다.",
        "기본적인 데이터 분석 방법을 활용해 실무에서 분석하는 법을 배우게 됩니다.",
        "데이터 분석 뿐만 아니라 머신러닝을 시작할 수 있습니다.",
        "오픈소스나 캐글의 코드를 보고 이해하며 나에게 맞는 데이터를 적용할 수 있습니다."
      ],
      "course_content": {
        "강의 및 파이썬 소개": [
          "인트로",
          "강의 목표",
          "파이썬 소개 및 환경 셋팅"
        ],
        "파이썬 문법 - 자료형 및 제어문": [
          "1. 자료구조란? / 숫자, 문자 자료형",
          "2. 리스트, 튜플 자료형",
          "3. 딕셔너리, 집합, 불 자료형",
          "4. if문",
          "5. for문",
          "6. while문"
        ],
        "파이썬 라이브러리 활용": [
          "라이브러리 소개",
          "PANDAS 1 - 판다스 소개 및 활용",
          "PANDAS 2 - 데이터 선택1",
          "PANDAS 3 - 데이터 선택2 / 데이터 변경",
          "PANDAS 4 - 결측 데이터",
          "PANDAS 5 - 연산, 합치기, 묶기",
          "PANDAS 6 - 데이터 구조 변경하기, 피봇 테이블, 파일 입출력",
          "NUMPY 1 - 넘파이 소개 및 활용",
          "NUMPY 2 - 통계 함수 활용",
          "MATPLOTLIB 소개 및 활용"
        ],
        "데이터 분석 실습": [
          "데이터 분석 소개",
          "데이터 확인",
          "시각화",
          "groupby 함수, 결측치, 이상치 확인, 상관관계",
          "피쳐 엔지니어링 및 마무리"
        ],
        "머신러닝 실습": [
          "머신러닝, 딥러닝 소개",
          "머신러닝 분류 소개",
          "실습 1 - 데이터 소개 및 EDA",
          "실습 2 - 결측치, 이상치 처리",
          "실습 3 - 데이터 분리",
          "실습 4 - 모델 개발"
        ],
        "데이터 크롤링 강의 소개 (강의 추천)": [
          "데이터 크롤링 강의 소개 (강의 추천)"
        ]
      },
      "requirements": [
        "프로그래밍 경험이 필요하지 않습니다. 시작부터 배우게 됩니다.",
        "인터넷을 실행할 수 있는 컴퓨터만 있으면 됩니다."
      ],
      "description": "데이터가 중요하다고 하여 관심이 있지만, 시도하고 싶다면 어떻게 해야 할까요?\n\n\n아래의 질문들은 데이터 분석 업무를 하면 항상 주변에서 듣고 있는 질문입니다.\nㄴ 데이터 분석을 나도 할 수 있을까?\nㄴ 비전공자인데, 데이터 분석, 머신러닝은 어렵지 않을까요?\nㄴ 개발을 전혀 모르는데 괜찮을까요?\n\n\n\"우선 시작해봐요!\"라고 말할 수 있을 만큼 누구나 쉽게 따라 할 수 있습니다.\n\n\n<학습 내용>\n1. 파이썬 기초 문법 학습 : 직접 실습하면서 프로그래밍을 이해\n2. 데이터 분석 : 분석을 하기 위한 라이브러리부터 실제 데이터를 통한 학습\n3. 머신러닝 : 간단한 머신러닝 모델을 통해 기본원리 학습\n+ 수업 자료를 통해서 스스로 학습하고 복습할 수 있는 자신감\n+ 업무에 자주 쓰이는 함수를 배우고 소소한 꿀팁 공유\n\n\n<수강 후 기대효과>\n1. 파이썬 문법을 이해하고 다른 언어도 자신감있게 배울 수 있습니다.\n2. 기본적인 데이터 분석 방법을 활용해 실무에서 활용하는 데이터로 분석이 가능합니다.\n3. 오픈소스나 캐글의 코드를 보고 이해하며 나에게 맞는 데이터를 적용할 수 있습니다.",
      "target_audience": [
        "데이터 과학에 관심이 있는 초보 python 개발자",
        "데이터 분석, 머신러닝이 궁금하고 배우고 싶으신 분들",
        "데이터 분석이나 시각화 업무를 시작하고 싶은 분들",
        "새로운 IT 분야에 도전하고 싶은 분들"
      ]
    },
    {
      "title": "Criação de Dashboards com Metabase",
      "url": "https://www.udemy.com/course/criacao-de-dashboards-com-metabase/",
      "bio": "Aprenda a criar suas visualizações de dados com Metabase e Google BigQuery",
      "objectives": [
        "Conhecer como funciona uma plataforma de construção de dashboards",
        "Entender e criar cada tipo de gráfico oferecido pelo Metabase",
        "Instalar do zero o Metabase localmente",
        "Conectar o Metabase a bancos de dados do BigQuery",
        "Criar Perguntas dentro do Metabase, sem Linguagem SQL",
        "Criar gráficos baseados em Linguagem SQL",
        "Criar modelos de dados",
        "Aprender a combinar dados dentro da plataforma do Metabase",
        "Criar campos calculados (colunas customizadas)",
        "Criar SQL snippets",
        "Criar variáveis em SQL",
        "Criar filtros de dados",
        "Criar dashboards",
        "Mudar o estilo de gráficos e abaspara deixar seu relatório perfeito!"
      ],
      "course_content": {
        "Apresentação do Curso": [
          "Apresentação",
          "Mensagem Inicial IMPORTANTE! Veja até o final :)",
          "Módulos",
          "Ferramentas e Dicas"
        ],
        "Metabase": [
          "Definição",
          "INSTALAÇÃO - ATENÇÃO",
          "Documentação",
          "Interface",
          "Coleções"
        ],
        "Google BigQuery": [
          "Definição: o que é o Google BigQuery? (do curso de SQL :)",
          "Cadastro no BigQuery",
          "Interface da Plataforma",
          "Explicação de algumas tabelas que usaremos (do curso de SQL :)",
          "Upload de Tabelas no BigQuery: na prática!",
          "Upload de Tabelas no Metabase: na prática!"
        ],
        "Introdução a SQL (bônus)": [
          "Comandos de Seleção (teoria)",
          "Comandos de Seleção (prática)",
          "Limit e Distinct (prática)",
          "Operadores (teoria)",
          "Operadores (prática)",
          "Apelidos (teoria)",
          "Apelidos (prática)",
          "Comandos de Restrição (teoria)",
          "Comandos de Restrição (prática)",
          "Comandos Condicionais (teoria)",
          "Comandos Condicionais (prática)",
          "Comandos de Agrupamento e Ordenação (teoria)",
          "Comandos de Agrupamento e Ordenação (prática)",
          "Relacionamento de Tabelas (teoria)",
          "Relacionamento de Tabelas (prática)",
          "Exercícios Propostos",
          "Exercícios Resolvidos"
        ],
        "SQL: Funções de Agregação (bônus)": [
          "Definição: o que são Funções de Agregação?",
          "Principais Funções (teoria)",
          "Parte I (prática)",
          "Parte II (prática)",
          "Exercícios Propostos",
          "Exercícios Resolvidos"
        ],
        "Tipos de Gráficos": [
          "Tabela",
          "Barra",
          "Linha",
          "Pizza",
          "Área",
          "Combo",
          "Tabela Dinâmica",
          "Funil",
          "Detalhe",
          "Dispersão",
          "Cascata",
          "Número",
          "Tendência",
          "Indicador",
          "Progresso",
          "Mapa"
        ],
        "Tópicos Avançados": [
          "Colunas Customizadas",
          "JOINs",
          "Filtros SQL: Parte I",
          "Filtros SQL: Parte II",
          "Modelos",
          "SQL Snippets",
          "Exportar Dados",
          "Administrador",
          "Atualizando o Metabase"
        ],
        "Dashboards & Projetos": [
          "Explicando o Projeto",
          "Primeira Página: Geral",
          "Segunda Página: Pedidos & Produtos",
          "Terceira Página: Usuários",
          "Última Página: Logística"
        ]
      },
      "requirements": [
        "Você não precisa ser da área de exatas para realizar esse curso",
        "Vontade de aprender",
        "Força de Vontade"
      ],
      "description": "SOBRE O CURSO\n\n\nEsse NÃO é mais um curso complicado, sem explicações claras ou exemplos práticos para o mercado de trabalho.\n\n\nEsse curso É um jeito simples de você aprender a criar suas visualizações de dados, dos primeiros conceitos até os mais avançados, com uma ferramenta gratuita.\n\n\nVocê não precisa obrigatoriamente ter experiência na área de Dados ou exatas para acompanhar todo o curso, que foi pensado com didática simples e módulos progressivos para você avançar com segurança!\n\n\nComece hoje a explorar a área de Business Intelligence e Ciência de Dados com tranquilidade. Mesmo que já esteja na área, essa é a oportunidade para você melhorar suas habilidades com o conhecimento de mais uma ferramenta.\n\n\nCada vez mais o mercado de trabalho exige de vários profissionais o conhecimento sobre criação de gráficos e dashboards! Aprenda a construí-los e utilizar suas informações para melhor tomada de decisão.\n\n\nLEMBRE-SE: A área de dados é a MAIS QUENTE do mercado atualmente. Então investir em seu desenvolvimento é a melhor escolha para sua carreira de sucesso.\n\n\nAbaixo a trilha ideal em direção ao sucesso na área de dados:\nLinguagem SQL para Análise de Dados.\nCriação com Dashboards com Metabase (este curso que você está, mas não é um problema começar por ele).\nPython: Manipulação de Dados com Pandas.\nMachine Learning: Clusterização com Linguagem Python.\nMachine Learning: Classificação com Linguagem Python.\nMachine Learning: Regressão com Linguagem Python.\n\n\nSOBRE O INSTRUTOR\nMe chamo Caio Avelino, e o conhecimento que vou dividir com você nesse curso foi adquirido, principalmente, com minha experiência no mercado de trabalho. Atuo nas áreas de Business Intelligence, Ciência de Dados e Inteligência Artificial há anos e tive a oportunidade de desenvolver minhas habilidades em diversas startups.\n\n\nAté mais!",
      "target_audience": [
        "Iniciantes e Curiosos sobre Business Intelligence",
        "Alunos de Ciência de Dados que gostariam de aprender Metabase",
        "Funcionários de uma empresa, de qualquer área, que gostariam de aprender a construir dashboards incríveis",
        "Analistas de BI com interesse em utilizar SQL para construção de análises e dashboards personalizados, sem as limitações dos Softwares que permitem apenas arrastar e soltar gráficos",
        "Qualquer pessoa, de qualquer área que deseja entrar no Mundo de Dados"
      ]
    },
    {
      "title": "ビジネスマンがデータサイエンスを活かすための統計学入門【統計検定®2級対策】",
      "url": "https://www.udemy.com/course/2-ozduze/",
      "bio": "ビジネスでデータサイエンスを活用したい方のための統計学基礎講座です。特にA/Bテストなどの仮説検定に必要な知識を習得できます。短時間で統計検定3級〜2級の基礎を身に付けたい方へ。",
      "objectives": [
        "記述統計から推測統計まで、統計学の基礎的な事項を理解できる。",
        "統計検定2級に挑戦するにあたり、ベースとなる知識を得られる。",
        "ビジネスシーンにおいて、統計的手法をどう活かすかの選択ができる。",
        "仮説検定等の統計的推測に関する概念を正しく理解でき、p値の意味や解釈方法などを人に説明できる。"
      ],
      "course_content": {
        "紹介": [
          "はじめに",
          "目次のご紹介",
          "補助教材「確率分布可視化ツール」のご案内",
          "補助教材「統計検定２級演習問題」のご案内",
          "資料のダウンロードはこちらから",
          "おまけ｜統計検定2級のチートシートのご案内"
        ],
        "記述統計": [
          "記述統計と推測統計について",
          "平均値と中央値",
          "最頻値",
          "分位数とその活用例",
          "度数と度数分布表の見方"
        ],
        "データの散らばりの指標": [
          "期待値",
          "分散と標準偏差",
          "不偏性と不偏分散",
          "変動係数"
        ],
        "確率と確率分布": [
          "独立な試行",
          "条件付き確率",
          "確率変数",
          "確率変数の期待値や分散について",
          "確率密度関数",
          "ベルヌーイ分布",
          "二項分布",
          "正規分布",
          "正規分布の特徴と標準正規分布",
          "二項分布の正規近似",
          "中心極限定理"
        ],
        "相関と回帰": [
          "相関係数",
          "相関係数の限界",
          "回帰分析",
          "決定係数",
          "最小二乗法"
        ],
        "統計的推測": [
          "帰無仮説と対立仮説",
          "有意水準と棄却域",
          "p値の解釈",
          "サンプルサイズ設計ツールのご紹介",
          "仮説検定の流れ",
          "検定統計量と標準誤差の関係",
          "ビジネスでの統計学の活かし方",
          "点推定と区間推定",
          "信頼区間の解釈",
          "母平均の推定の外観",
          "母平均の推定の具体例",
          "母平均の検定",
          "t分布について",
          "母平均の差の検定",
          "等分散の仮定",
          "ウェルチのt検定",
          "母比率の推定",
          "母比率の検定",
          "母比率の差の検定"
        ],
        "最後に": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "高校数学がわかっていれば前提条件はございません。"
      ],
      "description": "記述統計から統計的推測まで、統計検定3級~2級レベルの統計学の基礎的な事項を体系的に解説しつつ、ビジネスの現場で統計学をどう活かすのかという視点から事例を多めに用意した講座になります。統計学を始めて学ぶ方でも、高校数学の知識があれば理解いただける内容です。確率分布に関しては、青の統計学のシミュレーションツールを使いつつ、効率的に学習いただけます。",
      "target_audience": [
        "データサイエンスを業務に活かしたいビジネスマン",
        "統計検定3級や2級に挑戦したい方",
        "統計学をこれから学ぶ方"
      ]
    },
    {
      "title": "【한글자막】 PySpark 로 빅데이터 분석하기 with Python",
      "url": "https://www.udemy.com/course/best-pyspark-spark-python/",
      "bio": "【전세계 수강생 250만명!】 최신 빅데이터 기술! Spark Streaming, Machine Learning, Spark 2.0 DataFrames 등을 포함하여 Python에서 Spark를 사용하는 방법 학습하",
      "objectives": [
        "Python과 Spark를 함께 사용하여 빅데이터 분석하기",
        "새로운 Spark 2.0 DataFrame 신텍스을 사용하는 방법 알아보기",
        "실제 상황을 모방한 컨설팅 프로젝트를 진행하기",
        "로지스틱 회귀로 고객 이탈 분류하기",
        "분류를 위해 랜덤 포레스트와 함께 Spark 사용하기",
        "Spark의 Gradient Boosted Tree 사용 방법 알아보기",
        "Spark의 MLlib를 사용하여 강력한 기계 학습 모델 만들기",
        "DataBricks 플랫폼에 대해 알아보기",
        "빅데이터 분석을 위한 Amazon Web Services EC2 설정하기",
        "AWS Elastic MapReduce 서비스 사용 방법을 알아보기",
        "Spark 환경에서 Linux의 성능을 활용하는 방법을 알아보기",
        "Spark와 자연어 처리를 사용하여 스팸 필터 구축하기",
        "Spark Streaming을 사용하여 실시간 트윗 분석하기"
      ],
      "course_content": {
        "코스 소개": [
          "소개",
          "강의 개요 (자료에서 강의에 필요한 모든 자료파일을 다운받으세요)",
          "자주 하는 질문 (FAQ)",
          "Spark란? 왜 Python인가?"
        ],
        "Spark로 Python 설정하기": [
          "설정 개요",
          "설치 섹션 관련 참고 사항"
        ],
        "Databricks 설정": [
          "권장 설정",
          "데이터브릭 설정"
        ],
        "VirtualBox 설정": [
          "로컬설치 VirtualBox 1부",
          "로컬설치 VirtualBox 2부",
          "PySpark 설정"
        ],
        "AWS EC2 PySpark 설정": [
          "AWS EC2 설정 가이드",
          "EC2 인스턴스 생성하기",
          "Mac 또는 Linux에서의 SSH",
          "EC2에 설치하기"
        ],
        "AWS EMR 클러스터 설정": [
          "AWS EMR 설정"
        ],
        "Python 단기 특강": [
          "파이썬 단기 특강 소개",
          "Jupyter Notebook 개요",
          "파이썬 단기 특강 1부",
          "파이썬 단기 특강 2부",
          "파이썬 단기 특강 3부",
          "파이썬 단기 특강 연습문제",
          "파이썬 단기 특강 연습문제 해설"
        ],
        "Spark DataFrame 기초": [
          "Spark DataFrames 소개",
          "Spark DataFrame 기초 1부",
          "Spark DataFrame 기초 2부",
          "Spark DataFrame 기본 작업",
          "Groupby 및 Aggregate 작업",
          "누락된 데이터",
          "날짜 및 타임스탬프"
        ],
        "Spark DataFrame 프로젝트 연습문제": [
          "DataFrame 프로젝트 연습문제",
          "DataFrame 프로젝트 연습문제 해설"
        ],
        "MLlib2개 강의와 함께하는 머신러닝 소개": [
          "머신러닝 및 ISLR 소개",
          "MLlib를 사용한 Spark 및 Python을 사용한 머신러닝"
        ]
      },
      "requirements": [
        "모든 언어의 일반 프로그래밍 기술(Python 선호)",
        "로컬 컴퓨터의 20GB 여유 공간(또는 AWS용 강력한 인터넷 연결)"
      ],
      "description": "최신 빅데이터 기술 Spark와 Python 완벽 마스터!\n실제 상황과 유사한 연습과 모의 컨설팅 프로젝트 포함!\n데이터 분석 능력과 속도를 높일 수 있습니다!\n\n\nPySpark 로 빅데이터 분석하기 with Python을 선택해야 하는 이유\n최신 빅 데이터 기술, Spark에 대해 알아보세요! 그리고 가장 인기 있는 프로그래밍 언어 중 하나인 Python과 함께 사용하는 방법을 배워보세요!\nSpark는 Hadoop MapReduce보다 최대 100배 더 빠르게 수행할 수 있고, 그에 따라 이 기술에 대한 수요는 폭발적으로 증가하고 있습니다! Spark 2.0 데이터프레임 framework가 나온 지 얼마 되지 않았기 때문에 여러분들은 취업 시장에서 가장 지식이 풍부한 사람 중 한 명이 될 수 있습니다!\n이 강의는 Python의 단기 과정으로 기본을 가르치고 최신 Spark 2.0 syntax로 Spark DataFrames를 사용하는 방법을 계속 학습할 것입니다. 이 작업을 마치면 DataFrame syntax 및 Spark와 함께 MLlib Machine Library를 사용하는 방법을 살펴볼 것입니다. 각각의 모든 강의를 통해 실제 문제를 해결하기 위해 새로운 기술을 사용해야 하는 실제 상황으로 바로 들어갈 수 있는 연습과 모의 컨설팅 프로젝트도 강의에서 만나 보실 수 있을 것입니다!\n\n\n\n\nPySpark 로 빅데이터 분석하기 with Python 세부 커리큘럼\nPython과 Spark를 함께 사용하여 빅데이터 분석하기\n새로운 Spark 2.0 DataFrame 신텍스을 사용하는 방법 알아보기\n실제 상황을 모방한 컨설팅 프로젝트를 진행하기\n로지스틱 회귀로 고객 이탈 분류하기\n분류를 위해 랜덤 포레스트와 함께 Spark 사용하기\nSpark의 Gradient Boosted Tree 사용 방법 알아보기\nSpark의 MLlib를 사용하여 강력한 기계 학습 모델 만들기\nDataBricks 플랫폼에 대해 알아보기\n빅데이터 분석을 위한 Amazon Web Services EC2 설정하기\nAWS Elastic MapReduce 서비스 사용 방법을 알아보기\nSpark 환경에서 Linux의 성능을 활용하는 방법을 알아보기\nSpark와 자연어 처리를 사용하여 스팸 필터 구축하기\nSpark Streaming을 사용하여 실시간 트윗 분석하기\n\n\n전세계 수강생 250만명! Jose Portilla 강사의 한마디!\n안녕하세요! Jose Portilla입니다.\n특별히 한국의 수강생분들을 만나기 위해 한국어 자막을 준비했습니다.\n\n\n가장 가치 있는 기술 중 하나는 방대한 데이터 세트를 분석하는 능력이며, 이 강의는 그에 가장 적합한 기술 중 하나에 대한 속도를 높이도록 특별히 설계되었습니다. 바로 Apache Spark입니다! 최고의 테크 회사인 구글, 페이스북, 넷플릭스, 에어비앤비, 아마존, NASA, 그리고 더 많은 사람들이 모두 빅 데이터 문제를 해결하기 위해 Spark 를 사용하고 있습니다!\n\n\n최신 빅 데이터 기술, Spark에 대해 알아보세요! 그리고 가장 인기 있는 프로그래밍 언어 중 하나인 Python과 함께 사용하는 방법을 배워보세요!\nSpark SQL, Spark Streaming과 같은 최신 Spark 기술과 Gradient Boosted Trees와 같은 고급 모델도 다룰 것입니다.\n\n\n이 강의를 마친 후에는 이력서에 Spark와 PySpark를 넣는 것에 자신감이 생길 것입니다!\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n이 강의는 30일 전액 환불이 보장되며 LinkedIn 수료증도 함께 제공됩니다\nPython, Spark 및 빅 데이터의 세계로 뛰어들 준비가 되었나요?\n이 강의는 바로 여러분을 위한 것입니다!\n\n\n강의에서 만나요,\n-Jose",
      "target_audience": [
        "Python을 알고 있고 빅데이터에 사용하는 방법을 배우고 싶은 분",
        "다른 프로그래밍 언어에 매우 익숙하고 Spark를 배우고 싶은 분"
      ]
    },
    {
      "title": "Snowflakeによるデータ分析の基礎~データ抽出／SnowSight, AWS QuickSightによる可視化~",
      "url": "https://www.udemy.com/course/snowflake-aws-analysis/",
      "bio": "SnowflakeでSQLを使ったデータ抽出やその可視化、ダッシュボード作成、そしてAWS Quicksightと連携した可視化にチャレンジしましょう！",
      "objectives": [
        "Snowflakeを使ってデータの抽出・分析を行う方法",
        "Snowflakeワークシートを使ったSQLによるデータ抽出",
        "Snowsightによるデータの可視化",
        "Snowflakeによるダッシュボードの作成",
        "AWS Quicksightと連携したダッシュボードの作成"
      ],
      "course_content": {
        "イントロダクション": [
          "コース紹介",
          "コース準備レクチャー",
          "サンプルクエリのダウンロード",
          "データウェアハウス・データベース",
          "メタデータ",
          "クラウド",
          "データウェアハウス業界とSnowflake",
          "Snowflakeのドキュメンテーション",
          "Snowflakeの特徴①",
          "Snowflakeの特徴②",
          "ER図とテーブル定義書",
          "データ抽出とBIによる可視化"
        ],
        "Snowflakeのセットアップ": [
          "Snowflakeのトライアルの説明",
          "Snowflakeのインターフェース①",
          "Snowflakeのインターフェース②",
          "用語の説明",
          "使用するデータの説明",
          "UIによるデータベース・スキーマ・テーブルの操作"
        ],
        "SQLによるデータ抽出": [
          "全レコード・特定行数のレコードの抽出",
          "Whereによる条件フィルタ",
          "集計関数",
          "distinctによるユニーク抽出",
          "group byによる集計①",
          "order byによるソート",
          "group byによる集計②",
          "Having句によるフィルタ",
          "Joinによるデータ結合①",
          "Joinによるデータ結合②",
          "Union, Union Allによる結合（行方向）の説明",
          "Case式",
          "With句とWindow関数①",
          "With句とWindow関数②"
        ],
        "SnowSightによるデータの可視化": [
          "Snowflakeにおけるデータ可視化について",
          "クエリ結果の統計",
          "スコアカード",
          "折れ線グラフ",
          "棒グラフ",
          "散布図",
          "ヒートグリッド",
          "ダッシュボード"
        ],
        "SnowflakeとAWS Quicksightの連携による可視化": [
          "AWS QuickSightについて",
          "SnowflakeとAWS QuickSightの連携",
          "（実践）データベースとテーブルの作成",
          "（実践）ウェアハウスの作成",
          "ユーザとロールの作成／権限の付与",
          "デフォルトロールの付与",
          "AWS QuickSightでのSnowflakeデータの読み込み",
          "QuickSightの画面の説明",
          "QuickSightでの可視化①",
          "QuickSightでの可視化②",
          "QuickSightでの可視化③"
        ],
        "ボーナスレクチャー": [
          "ボーナス"
        ]
      },
      "requirements": [
        "AWSアカウント、Snowflakeアカウントが必要です（見るだけでもOK）"
      ],
      "description": "最近のデータサイエンスブームの中で、Snowflakeはクラウドネイティブなデータウェアハウス製品として、多くの会社で採用されてきています。データ分析のためSnowflakeに興味がある方も増えているかと思いますが、自分で勉強しようにも自分でSnowflakeのようなデータウェアハウスを扱うというのはかなりハードルが高いものです。\nそこでこのコースでは、Snowflakeを使ってデータを抽出するためのSQLの基礎から、GUI上での簡単な可視化、そして他のクラウドサービスであるAWSのQuicksightと連携した可視化・ダッシュボード作成などを、一緒にハンズオン形式で学んでいきます。\nぜひこの機会にSnowflakeを学び、これからのキャリアに活かしていきましょう！\n\n\n本コースの内容\nイントロダクション\nSnowflakeとは\nSnowflakeのセットアップ\nSQLによるデータ抽出\nSnowSightによる可視化\nAWS QuickSightとの連携と可視化\n\n\n前提条件\n特に受講上の前提条件はありません。SQLやデータベースの知識はあるにこしたことないですが、なくても問題ありません。\nPCのOSはMac, Windows, Linuxなんでも構いません。\n\n\n注意事項\n本コースに従って実際にハンズオンを行う場合はSnowflakeのアカウント、AWSのアカウントが必要です（もちろん見るだけでも構いません）。Snowflake, AWSともに初月は無料枠がありますが、使いすぎると課金される可能性があるので、ご了承ください\nAWSのアクセス（IAM）まわりの話はいたしませんので、ご了承ください\nSnowflakeでのデータベース作成といったデータロードまわりの説明はいたしませんので、ご了承ください（興味がある方は、姉妹編の「Snowlflakeによるデータエンジニアリングの基礎」をご覧ください）\n本コースは、Snowflakeを使ったデータ抽出や可視化の基礎に関するコースで、あくまで初学者向けのコースになっております。ある程度の経験がある方は対象外ですのでご注意ください\nクライアントツールであるSnowsqlは使わずGUIのワークシートを使って操作します\n1ヶ月間はキャンセル可能ですので、もし間違って購入したり、想定と違う場合はキャンセルするようにしてください\n\n\nそれでは、Snowflakeをお楽しみください！",
      "target_audience": [
        "Snowflakeで分析をする必要がある方",
        "BIツールで可視化をしてみたい方",
        "AWSとSnowflakeの連携をしてみたい方",
        "SQLによるデータ抽出を学びたい方",
        "データサイエンス初心者"
      ]
    },
    {
      "title": "Veri Sihirbazlığı: R ile Makine Öğrenmesi Temelleri",
      "url": "https://www.udemy.com/course/bilgisayar-ogretmeninden-r-ile-makine-ogrenmesi-temelleri/",
      "bio": "Veri Sihirbazlığı: R ile Makine Öğrenmesi Kursu",
      "objectives": [
        "Makine Öğrenmesi Hakkında Bilgi Sahibi Olacaklar",
        "Big Data İle Nasıl Çalışacaklarını Öğrenecekler",
        "Temel Yazılım Bilgisine Sahip Olacaklar",
        "Yapay Zeka ile İstatistik Nasıl Yapılacak Bu Konuda Eğitilecekler"
      ],
      "course_content": {
        "R Temelleri": [
          "R Yükleme Adımları ve Hello Word",
          "Değişkenlere Giriş",
          "Değişkenlerle Temel Matematik İşlemleri",
          "Operatörler"
        ],
        "Mantıksal R": [
          "While Döngüsü",
          "For Döngüsü",
          "Koşullar"
        ],
        "Vectors": [
          "Vektörler",
          "Vektör Yaratma ve Komut Sistemi"
        ],
        "Fonksiyonlar | Modüller": [
          "Fonksiyonlar",
          "Factor | Pivot ve Summary Fonksiyonları",
          "Arrays",
          "Modules"
        ],
        "Matrix Kavramı": [
          "Matrix Nedir ?",
          "Matrix İşlemler",
          "Matrix Manipüle"
        ],
        "Data Frame": [
          "Data Frame Nedir ?",
          "Çevireçler",
          "Veri Seti Yükleme",
          "Korelasyon",
          "Hızlı Fonksiyonlar",
          "Hata Kodları",
          "R Çalışma Dizini Mantığı ve Manipülasyonları"
        ],
        "Grafikler": [
          "Plot Grafiği",
          "Geom Point",
          "GGPLOT ile Grafik Konumlandırma",
          "Color Model",
          "Derinlemesine Grafikler",
          "Multi Grafikler",
          "Geom Bars"
        ],
        "Makine Öğrenmesi": [
          "Makine Öğrenmesi Nedir ?",
          "Regresyon Nedir ?",
          "Regresyon Doğrusu Cep Telefonu Fiyat Endeksi",
          "Ev Kira Endeksi Algoritması",
          "Kirayı Tahmin Et",
          "Karar Ağaçları",
          "Makine Öğrenmesi ile Diyabet Olma Olasılığını Hesapla",
          "Ham veri Üzerine Diyabet Analizi",
          "En Yakın Komşu Algoritması",
          "KNN ile Köpek Cinsi Tahmin Algoritması",
          "Genel Tekrar ve K Ortalama Algoritması",
          "2 Kümeli veri Analizi",
          "Birliktelik Analizi",
          "2500 Kalemden Oluşan Market Fişi Oluşturma",
          "Farklı Fişteki Verileri Tek Fişte Toplama",
          "En Yüksek Oranda Satın Alınan Fiş Miktarını Bulma",
          "Apriori Algoritması",
          "Final Uygulaması",
          "Bayes Algoritması",
          "Reel Data ile Bayes",
          "Hatalı verileri Manipüle Etme",
          "Hatalı Verilerin Ham Veriye Etkisi",
          "Data Parse",
          "Algoritma Final ~ Tahmin Yapma Sistemi"
        ]
      },
      "requirements": [
        "Bilgisayar",
        "İnternet",
        "Temel Düzeyde Matematik (Ders içerisinde bilmediğinizi varsayıp matematik dersleri de veriliyor )"
      ],
      "description": "Kurs Açıklaması: Veri Sihirbazlığı: R ile Makine Öğrenmesi Kursu\nVeri Sihirbazlığı: R ile Makine Öğrenmesi Kursu, veri analizinde ustalaşmak ve makine öğrenme alanında başarılı projeler geliştirmek isteyenler için tasarlanmış kapsamlı bir eğitim programıdır. Bu eğlenceli ve interaktif kurs, R dilini kullanarak veri sihirbazlığı yapmanızı ve verileri büyülü bir şekilde değerli bilgilere dönüştürmenizi sağlar.\nNeden Bu Kurs? Veri, günümüzde iş dünyasında ve bilimsel araştırmalarda olağanüstü bir öneme sahiptir. Bu kurs, veri analizine meraklı herkesi R dilini kullanarak veri sihirbazına dönüştürerek, verileri büyülü bir şekilde çözümleyip değerli içgörülere dönüştürmeyi öğretmeyi amaçlamaktadır.\nKursun İçeriği\nVeri Önişleme ve Temizleme: Gerçek dünya verileri çoğu zaman karmaşıktır ve analiz öncesi temizlenmesi gereken önemli sorunlar içerir. Bu bölümde, veri temizleme teknikleri ve veri önişleme adımları ile kirlilikten arındırılmış veri kümesine nasıl ulaşacağınızı öğreneceksiniz.\nDenetimli Öğrenme: Denetimli öğrenme algoritmalarını kullanarak, etiketli veri setlerinden tahminlerde bulunmak ve sınıflandırma yapmak mümkündür. Karar ağaçları, destek vektör makineleri ve doğrusal regresyon gibi temel algoritmaları öğrenerek, etkili tahmin modelleri oluşturacaksınız.\nDenetimsiz Öğrenme: Etiketlenmemiş veri setlerinden anlam çıkarmak için denetimsiz öğrenme algoritmaları kullanılır. Bu bölümde, kümeleme tekniklerini ve boyut azaltma yöntemlerini öğrenerek, verilerde gizli yapıları keşfetmek için kendi büyülü algoritmalarınızı geliştireceksiniz.\nModel Değerlendirme ve Ayarlamalar: Makine öğrenmesi projelerinde başarı için modelleri doğru bir şekilde değerlendirmek ve ayarlamak çok önemlidir. Bu bölümde, hata metrikleri, çapraz doğrulama ve hiperparametre ayarlamaları gibi tekniklerle modellerinizin performansını en üst düzeye çıkarmayı öğreneceksiniz.\nKimler Katılmalı? Bu kurs, veri analizine ilgi duyan, iş dünyasında veri bilimi ve yapay zeka alanında kariyer yapmak isteyen veya sadece veri sihirbazlığına olan merakını geliştirmek isteyen herkes için uygundur. Katılımcıların temel düzeyde R diline hakim olmaları önerilir, ancak bu kurs, R dilinin temellerini hızla öğrenmek isteyenler için de uygun bir başlangıç noktasıdır.\nSonuç Veri Sihirbazlığı: R ile Makine Öğrenmesi Kursu, sizleri veri analitiği ve makine öğrenme yolculuğunda büyülü bir serüvene davet ediyor. R dilini kullanarak veri sihirbazlığı yapmanın büyülü dünyasını keşfetmek ve veriyle dolu hayal gücünüzü gerçeğe dönüştürmek için bu eğitim programına hemen katılın!",
      "target_audience": [
        "Öğrenciler",
        "Yüksek Lisan Öğrencileri",
        "Doktora Öğrencileri",
        "Yapay Zekaya Merakı Olup Nereden Başlayacağını Bilmeyenler",
        "Yeni Mezunlar",
        "Python dilini bilen bireyler daha hızlı öğrenebilir"
      ]
    },
    {
      "title": "Windows10で学ぶAI画像認識（Mask RCNNモデル）",
      "url": "https://www.udemy.com/course/aimask-r-cnnwindows10/",
      "bio": "AI 講座（ ディープラーニング 画像認識 tensorflow keras python opencv windows 動画 ）",
      "objectives": [
        "ＡＩ画像認識モデルとはどういうものか？MaskRCNNモデルを題材に学習します。",
        "仮想環境の構築方法、Windows10で一から構築していきます。",
        "MaskRCNNモデルの理論",
        "ディープラーニングのモデルと実際のプログラムの関係"
      ],
      "course_content": {
        "（１）画像認識のデモンストレーション": [
          "（１）－１デモンストレーション",
          "（１）－２ 講座内容"
        ],
        "(２) Pythonで動画をＡＩ処理するプログラムの概要": [
          "（２）－１MaskRCNNモデルの出力",
          "（２）－２ 動画のループ",
          "（２）－３－１ピクセル値",
          "（２）－３－２ピクセル値（赤色）",
          "（２）－３－３ピクセル値（赤色の続きと緑色）",
          "（２）－３－４ピクセル値（青色とマスク行列）"
        ],
        "(３) 静止画でMaskRCNNモデルを実行する": [
          "(３) –１ Anacondaのダウンロード",
          "(３) –２ Anacondaのインストール",
          "(３) –３ Pythonの仮想環境の構築(仮想環境の新規作成)",
          "(３) –４ Pythonの仮想環境の構築(CPU版・パッケージのインストール)",
          "(３) –５ MaskRCNNのセットアップ（Gitインストール)",
          "(３) –６ COCOとVisualStudioのインストール(Cython)",
          "(３) –７ 静止画で実行(Demo.ipynbを動かしてみる)",
          "（３）－８ ３つのノートブック(Samples2)"
        ],
        "(４) リアルタイムに映像でMaskRCNNモデルを実行する": [
          "（４） –１－１ Webカメラの使い方",
          "（４）–１－２ Webカメラで動画実行CPU版",
          "(４) –２ スマホカメラの場合(CPU版)",
          "(４) –３ GPU版_仮想環境の構築(ドライバ)",
          "(４) –４－１ GPU版_仮想環境構築(パッケージのインストール)",
          "(４) –４－２ GPU版_仮想環境構築(パッケージのインストール)",
          "(４) –５ GPU版_Webカメラで動画実行"
        ],
        "(５) MaskRCNNモデルの解説": [
          "(５) MaskRCNNモデルの解説"
        ],
        "(６) その他（【追加】ディープラーニング早わかり資料）": [
          "ディープラーニング早わかり資料+おしまいの挨拶"
        ]
      },
      "requirements": [
        "ＡＩや画像認識に関心がある人"
      ],
      "description": "■Windows10で、AI画像認識について学んでいきます。\nMask RCNNモデルを題材にしています。\n（マスク アールシーエヌエヌ モデル）\n\n\n■（１）（２）章で、まずは、ＡＩの画像認識とはどういうものなのかを説明していきます。\n（２）章の説明では、そもそも動画のプログラムとはどんなものなのか？画像は何でできているのか？画像のピクセル値を、実際に出力してみています。\nディープラーニングは、畳み込み演算をはじめとして、内部的にいろいろな処理があるのですが、私自身、自分の目で画像の中のピクセル値を見てみたことで、ディープラーニングのニューラルネットワークの層がそれぞれ何をやっているのか、あっそういうことか！？と非常に手に取るようにイメージできるようになりました。ですから、みなさんにも是非と、画像のピクセル値を実際に見てみることをお勧めしています。\n（２）章で詳しく説明しています。\n\n\n■（３）章から、画像認識のMask RCNNモデルを、実際に動かしていきます。仮想環境の構築から始めていきます。\n（３）章が写真(静止画）で、（４）章が動画で動かしてみるという内容になっています。\n（３）章は、特に丁寧に解説していますので、手順通りやれば動かせると思います。是非、トライしてみてください。\nこの部分は、Pythonプログラムをダウンロードして動かすという内容なので、Pythonプログラムを書けなくても大丈夫です。\n実際の画面の映像をお見せしながら説明していきますので、本やWebサイトだけの情報より、わかりやすいと思います。\nできるだけ多くの方に実行していただけるようOS・言語・フレームワーク等は、なるべくメジャーなもの・普及しているものを選びんでいます。（Python、Windows10、Tensorflow、Jupyter、Anaconda）\n\n\n■画像認識のMask RCNNは、面白いモデルだと思います。\nみなさんにも、是非、この面白さが伝わるとうれしいです。\n\n\n■（４）章で、動画ベースでも処理できるようにしていきます。\nGPU搭載のWidowsPCでの実行やWebカメラ・スマホカメラの使い方についても、できるかぎり丁寧に解説しています。\n\n\n■（５）章は、より理論を深く知りたいという方のために、Mask RCNNモデルの中身や、モデルの理論とプログラムの関係についても解説しています。\n理論は図や写真をもとに、数式を使わずに説明していますので、とっかかりとしてイメージをつかめるように工夫して説明しています。\nMask RCNNモデルの全体像が一目でわかるような「全体図」も作成しています。\n巨大なモデルの仕組みを要約するのは、私自身、大変でしたが、わかりやすい「全体図」になっていると思いますので、是非、見てみてください\n内容が深くなってきますと、日本語での解説も少なくなってきますので、是非、この講座も参考にしていただけたらと思います。\n\n\n■（５）章では、また、Mask RCNNの理論が、どのようにプログラミングと対応しているのか、導入部分ですが解説をしています。\nもしかしたらMask RCNNモデルのプログラムを解読するような強者もでてくるかもしれないと思って、GitHubにMask RCNNモデルの「中身の」プログラムをわかりやすい形にしたジュピターノートブックも載せていますので、力が余ってる人は、Mask RCNNモデルの「中身の」プログラムも見てみてください。\n\n\nこの講座を検索するためのキーワード\n深層学習 ディープラーニング 画像認識 人工知能  コンピュータビジョン　 anaconda tensorflow keras python jupyter opencv windows windows10 AI",
      "target_audience": [
        "ＡＩに関心がある人",
        "ＡＩエンジニアになりたい人"
      ]
    },
    {
      "title": "Visualização de Dados com Python",
      "url": "https://www.udemy.com/course/visualizacao-de-dados-com-python-y/",
      "bio": "Aprenda de forma prática e objetiva a criar os mais diversos gráficos com Python, Matplotlib, Pandas, Bokeh e muito mais",
      "objectives": [
        "Você será capaz de entender os conceitos para visualizar dados com Python",
        "Você será capaz de criar gráficos dos mais diferentes tipos com Python",
        "Você será capaz de fazer uso de diferentes bibliotecas Python para visualização de dados",
        "Você será capaz decidir quais tipos de gráficos fazer uso com os seus dados e qual biblioteca utilizar"
      ],
      "course_content": {
        "Apresentação": [
          "Sobre o curso",
          "Informações Importantes"
        ],
        "Visualização de Dados": [
          "O que vamos aprender nesta seção?",
          "Somente estatística não basta",
          "A visualização de dados é importante",
          "O ecossistema Python para visualização de dados",
          "Conceitos iniciais sobre visualização de dados",
          "Mão na massa geek!",
          "Recapitulando"
        ],
        "Matplotlib: Essencial": [
          "O que vamos aprender nesta seção?",
          "Introdução ao Matplotlib",
          "Prática: Preparação ao ambiente",
          "Prática: Nosso primeiro gráfico com Matplotlib",
          "Prática: Ajustando atributos do gráfico",
          "Prática: Múltiplos conjuntos de dados no gráfico",
          "Prática: Múltiplos gráficos em uma figura",
          "Prática: Criando gráfico de barras",
          "Prática: Criando gráfico histograma",
          "Prática: Criando gráfico de pizza",
          "Prática: Salvando a imagem do gráfico",
          "Recapitulando"
        ],
        "Pandas para Visualização de Dados": [
          "O que vamos aprender nesta seção?",
          "Introdução ao Pandas",
          "Prática: Preparação do ambiente",
          "Prática: Nosso primeiro gráfico com Pandas",
          "Prática: Gráfico de barras com Pandas",
          "Prática: Histograma com Pandas",
          "Prática: Gráfico de pizza com Pandas",
          "Prática: Salvando imagens dos gráficos com Pandas",
          "Recapitulando"
        ],
        "Seaborn: Essencial": [
          "O que vamos aprender nesta seção?",
          "Introdução ao Seaborn",
          "Prática: Preparação do ambiente",
          "Prática: Nosso primeiro gráfico com Seaborn",
          "Prática: Gráfico de barras com Seaborn",
          "Prática: Histograma com Seaborn",
          "Prática: Gráfico de pizza com Seaborn",
          "Prática: Salvando imagens dos gráficos com Seaborn",
          "Recapitulando"
        ],
        "Bokeh: Essencial": [
          "O que vamos aprender nesta seção?",
          "Introdução ao Bokeh",
          "Prática: Preparação ao ambiente",
          "Prática: Nosso primeiro gráfico com Bokeh",
          "Prática: Histograma com Bokeh",
          "Prática: Gráfico de pizza com Bokeh",
          "Prático: Salvando imagens dos gráficos com Bokeh",
          "Prática: Gráfico de barras com Bokeh",
          "Recapitulando"
        ],
        "Plotly: Essencial": [
          "O que vamos aprender nesta seção?",
          "Introdução ao Plotly",
          "Prática: Preparação do ambiente",
          "Prática: Nosso primeiro gráfico com Plotly",
          "Prática: Gráfico de barras com Plotly",
          "Prática: Histograma com Plotly",
          "Prática: Gráfico de pizza com Plotly",
          "Prática: Salvando imagens dos gráficos com Plotly",
          "Recapitulando"
        ],
        "Encerramento": [
          "Recapitulando",
          "Quais os próximos passos?"
        ]
      },
      "requirements": [
        "Necessário ter feito o curso Programação para Leigos da Geek University ou ter conhecimentos equivalentes",
        "Necessário ter feito o curso Algoritmos e Lógica de Programação da Geek University ou ter conhecimentos equivalentes",
        "Necessário ter feito o curso Programação em Python da Geek University ou ter conhecimentos equivalentes",
        "Necessário ter computador com sistema operacional atualizado nas últimas versões, ou o Windows, ou o Linux (Ubuntu), ou o Mac",
        "Necessário ter acesso à Internet para baixar softwares"
      ],
      "description": "Python é uma linguagem de programação extremamente poderosa e amplamente utilizada na Ciência de Dados e Inteligência Artificial.\nJá há algum tempo o mercado considera os dados como sendo o novo petróleo. Mas não adianta ter dados brutos, eles precisam ser limpos, processados, analisados e apresentados de forma que tragam insights valiosos para pessoas e empresas.\nEste curso apresenta de forma simples, direta e prática todo o poder da linguagem Python, na sua versão 3.11, para criar gráficos dos mais variados com as principais bibliotecas Python para visualização de dados.\nDentre todos os conteúdos do curso você aprenderá:\n- Somente estatística não basta;\n- A visualização de dados é importante;\n- O ecossistema Python para visualização de dados;\n- Conceitos iniciais sobre visualização de dados;\n- Introdução à biblioteca Matplotlib;\n- Utilização do Matplotlib para criar e visualizar diferentes tipos de gráficos;\n- Realizar ajustes e configurações nos gráficos do Matplotlib;\n- Introdução à biblioteca Pandas;\n- Utilização do Pandas para criar e visualizar diferentes tipos de gráficos;\n- Introdução à biblioteca Seaborn;\n- Utilização do Seaborn para criar diferentes tipos de gráficos;\n- Introdução à biblioteca Bokeh;\n- Utilização do Bokeh para criar diferentes tipos de gráficos;\n- Introdução à biblioteca Plotly;\n- Utilização do Plotly para criar diferentes tipos de gráficos;\n- E muito mais!\nChegou a hora de você dar vida aos dados!\nConte sempre com a Geek University!",
      "target_audience": [
        "Desenvolvedores que querem criar gráficos para suas aplicações com Python",
        "Administradores de empresas/sistemas que querem apresentar dados de forma visual com Python",
        "Pessoas interessadas em aprender a criar gráficos com Python e suas principais bibliotecas"
      ]
    },
    {
      "title": "Machine Learning desde cero",
      "url": "https://www.udemy.com/course/machine-learning-desde-cero-c/",
      "bio": "Aprende a programar en Python y realiza pronósticos precisos para tomar decisiones informadas",
      "objectives": [
        "Aprenderás los fundamentos y técnicas clave del Machine Learning para resolver problemas del mundo real.",
        "Dominarás la implementación y ajuste de modelos supervisados y no supervisados para obtener resultados precisos y relevantes.",
        "Explorarás técnicas de Aprendizaje Profundo para aplicaciones prácticas.",
        "Evaluarás y optimizarás modelos utilizando métricas de rendimiento, validación cruzada y ajuste de hiperparámetros.",
        "Aplicarás el Machine Learning en diversos contextos y construirás soluciones completas desde la preparación de datos hasta la presentación de resultados."
      ],
      "course_content": {
        "Introducción al Machine Learning": [
          "Introducción al Curso",
          "Evaluación del Curso",
          "Fundamentos de Machine Learning y su importancia",
          "Tipos de Aprendizaje",
          "Proceso de Desarrollo de un Modelo",
          "Preparación y Exploración de Datos"
        ],
        "Nivelación de Estadística": [
          "Conceptos Básicos",
          "Clases de Variables",
          "Probabilidad",
          "Medidas de Tendencia Central",
          "Deciles y Cuartiles",
          "Medidas de Dispersión",
          "Covarianza y Correlación",
          "Distribuciones de Probabilidad",
          "Asimetría y Curtosis",
          "Ley de los Grandes Números y Teorema Central del Límite",
          "Intervalo de Confianza"
        ],
        "Python Básico": [
          "Instalar Python y Anaconda",
          "Crear un Entorno de Trabajo",
          "Interfaz",
          "Tipos de Datos",
          "Cadenas de Texto",
          "Transformación de Tipo de Dato",
          "Condicionales y Operadores de Comparación",
          "Listas y Tuplas",
          "Ciclo While",
          "Ciclo For",
          "Diccionarios",
          "Gestionar el Directorio",
          "Importar y Exportar Datos de Excel",
          "Ejercicio"
        ],
        "Modelos Supervisados": [
          "Regresión Lineal y Logística",
          "Árboles de decisión y bosques aleatorios",
          "Caso Práctico y Ensamble"
        ],
        "Modelos No Supervisados": [
          "Agrupamiento con K-Medias",
          "PCA"
        ],
        "Aprendizaje Profundo (Deep Learning)": [
          "Redes neuronales artificiales"
        ],
        "Evaluación y Optimización de Modelos": [
          "Métricas de Evaluación de Modelos",
          "Consideraciones éticas y desafíos en Machine Learning"
        ]
      },
      "requirements": [
        "No se necesita experiencia previa."
      ],
      "description": "Te doy la bienvenida al curso de Machine Learning! Si estás buscando adentrarte en el emocionante mundo del aprendizaje automático y desarrollar habilidades en el análisis predictivo y la toma de decisiones basada en datos, este curso es perfecto para ti. A lo largo de los módulos, te guiaremos desde los conceptos fundamentales hasta un nivel intermedio en Machine Learning.\nEn el Módulo 1, te sumergirás en los fundamentos de Machine Learning y comprenderás su importancia en diversos campos. Aprenderás sobre los diferentes tipos de aprendizaje automático y explorarás el proceso de desarrollo de modelos.\nPor otro lado en el modulo 2 incluiremos una nivelación en estadística que te servirá para recordar y cimentar las bases del machine learning mientras que en el modulo 3 aprenderás a instalar y ejecutar instrucciones en Python el cual es uno de los programas más utilizados para utilizar aplicar Machine Learning.\nEn el Módulo 4, nos adentraremos en los modelos supervisados. Aprenderás sobre regresión lineal y logística, árboles de decisión y bosques aleatorios. También exploraremos métodos de ensamble para mejorar el rendimiento de los modelos.\nEn el Módulo 5, nos enfocaremos en los modelos no supervisados. Te sumergirás en el mundo del agrupamiento (clustering), el análisis de componentes principales (PCA) y los algoritmos de asociación para descubrir patrones y realizar recomendaciones.\nEl Módulo 6 se dedica al Aprendizaje Profundo (Deep Learning). Aprenderás sobre redes neuronales artificiales. Exploraremos aplicaciones prácticas del Aprendizaje Profundo.\nFinalmente, en el Módulo 7, te sumergirás en la evaluación y optimización de modelos. Aprenderás sobre métricas de evaluación, técnicas de validación cruzada y sintonización de hiperparámetros. También discutiremos consideraciones éticas y desafíos en Machine Learning.\nAl finalizar este curso, habrás adquirido una base sólida en Machine Learning y estarás preparado para abordar desafiantes proyectos de análisis de datos. Nuestra metodología práctica, con una combinación de teoría y ejercicios, te permitirá aplicar tus conocimientos en situaciones reales. ¡Únete a nosotros y desbloquea el poder del Machine Learning para impulsar tu carrera y tomar decisiones informadas basadas en datos!",
      "target_audience": [
        "Profesionales que quieran dominar Machine Learning",
        "Personas que quieran realizar pronósticos utilizando inteligencia artificial",
        "Estudiantes que necesiten el manejo de Machine Learning para cuestiones laborales."
      ]
    },
    {
      "title": "공공데이터(오픈데이터) API 사용법",
      "url": "https://www.udemy.com/course/api-cxvt/",
      "bio": "오픈 공공 데이터를 다양한 프로그래밍 언어로 호출하고 활용하는 법",
      "objectives": [
        "API 개념과 JSON 개념을 배울 수 있다.",
        "JSON 형태의 데이터 다룰 수 있다.",
        "공공데이터 포널 이용 및 데이터 요청할 수 있다.",
        "파이썬에서의 JSON 데이터 처리를 배울 수 있다.",
        "SQLite3를 배울 수 있다."
      ],
      "course_content": {
        "공공 데이터 (오픈 데이터) API 제대로 배우기 Part.1 JSON 데이터 처리": [
          "강의개요",
          "강의에서 사용된 프로그램 버전",
          "공공데이터 API 이용하기 -전체적인 흐름 미리보기",
          "API 개념이해",
          "JSON 개념이해",
          "JSON 객체 vs JSON 배열",
          "JSON 데이터를 다루기위한 JS 기본 사용법1",
          "JSON 데이터를 다루기위한 JS 기본 사용법2",
          "중첩된 JSON 데이터 다루기",
          "중첩된 JSON 데이터 다루기 - 반복문을 이용한 카테고리 출력",
          "JSON 데이터 객체와 문자열로 변환하기",
          "JSON 데이터를 웹페이지로 출력하기(1)",
          "JSON 데이터를 웹페이지로 출력하기(2)",
          "JSON 데이터를 웹페이지로 출력하기(3)",
          "JSON 데이터를 웹페이지로 출력하기(4)"
        ],
        "공공 데이터 (오픈 데이터) API 제대로 배우기 Part.2 JAVA, JSP": [
          "공공데이터 포털 사이트 이용방법",
          "자바(이클립스)에서 공공API 요청 및 출력(1)",
          "자바(이클립스)에서 공공API 요청 및 출력(2)",
          "JSON 데이터 웹페이지 테이블로 출력하기 with getJSON(1)",
          "JSON 데이터 웹페이지 테이블로 출력하기 with getJSON(2)",
          "자바(이클립스)에서 공공API 요청 및 출력(3)",
          "7. Servlet JSP vs JSON 연동하기(1)",
          "Servlet JSP vs JSON 연동하기(2) - 실습",
          "Servlet JSP vs JSON 연동하기(3) - 실습",
          "Servlet JSP vs JSON 연동하기(4) - 공공데이터 포털사이트 JSON 연동1",
          "Servlet JSP vs JSON 연동하기(4) - 공공데이터 포털사이트 JSON 연동2",
          "JSON 데이터를 출력시키는 BS 테이블 클래스 연습하기(1)",
          "JSON 데이터를 출력시키는 BS 테이블 클래스 연습하기(2)",
          "ASP, PHP 에서의 공공API 요청 및 JSON 결과 데이터 파싱 가이드",
          "부트스트랩 반응형 테이블"
        ],
        "공공 데이터 (오픈 데이터) API 제대로 배우기 Part.3 Python": [
          "파이썬에서의 JSON 데이터 처리",
          "파이썬에서 제공하는 JSON 기본 모듈",
          "JSON 문자열을 객체로 변환 및 출력",
          "딕셔너리 자료구조와 반복문(1)",
          "딕셔너리 자료구조와 반복문(2)",
          "딕셔너리 자료구조와 반복문(3)",
          "딕셔너리 자료구조와 반복문(4)",
          "딕셔너리 자료구조와 반복문(5)",
          "딕셔너리 자료구조와 반복문(6)",
          "공공 데이터 API 사용을 위한 파이썬 라이브러리(1)",
          "공공 데이터 API 사용을 위한 파이썬 라이브러리(2)",
          "urllib.parse를 이용하여 password 변경해보기",
          "쿼리스트링 urlencode 메서드",
          "URL 문자열 변환 - 한글 인코딩 디코딩 quote, unquote",
          "파이썬 모듈 설치",
          "공공데이터 API를 이용하여 제공받은 JSON 데이터를 CSV 파일로 저장하기(1)",
          "공공데이터 API를 이용하여 제공받은 JSON 데이터를 CSV 파일로 저장하기(2)",
          "공공데이터 API를 이용하여 제공받은 JSON 데이터를 CSV 파일로 저장하기(3)"
        ],
        "공공 데이터 (오픈 데이터) API 제대로 배우기 Part.4 API와 DB": [
          "SQLite3 데이터베이스 사용하기(1)",
          "SQLite3 데이터베이스 사용하기(2)",
          "csv 파일에 들어있는 데이터를 sqlite DB에 저장하기1",
          "csv 파일에 들어있는 데이터를 sqlite DB에 저장하기2",
          "sqlite DB에서 데이터 삭제하기"
        ]
      },
      "requirements": [
        "데이터와 처리와 관련된 간단한 기본 지식이 있으시면 좋습니다"
      ],
      "description": "[오픈 공공 데이터를 다양한 프로그래밍 언어로 호출하고 활용하는 법] 본 과정은 공공 데이터 포털에서 제공하는 다양한 오픈 데이터를 여러 프로그래밍 언어에서 어떻게 호출하고, 호출된 결과로 제공받는 JSON 데이터를 어떻게 사용할 수 있는지에 대해서 다양한 언어로 학습해보는 과정입니다. 해당 과정은 아래와 같은 커리큘럼으로 구성되어 있습니다.\n\n\n<교육 내용>\n[공공 데이터 (오픈 데이터) API 제대로 배우기 Part.1 JSON 데이터 처리]\n강의개요\n강의에서 사용된 프로그램 버전\n공공데이터 API 이용하기 - 전체적인 흐름 미리보기\nAPI 개념이해\nJSON 개념이해\nJSON 객체 vs JSON 배열\nJSON 데이터를 다루기위한 JS 기본 사용법1\nJSON 데이터를 다루기위한 JS 기본 사용법2\n중첩된 JSON 데이터 다루기\n중첩된 JSON 데이터 다루기 - 반복문을 이용한 카테고리 출력\nJSON 데이터 객체와 문자열로 변환하기\nJSON 데이터를 웹페이지로 출력하기(1)\nJSON 데이터를 웹페이지로 출력하기(2)\nJSON 데이터를 웹페이지로 출력하기(3)\nJSON 데이터를 웹페이지로 출력하기(4)\n\n\n[공공 데이터 (오픈 데이터) API 제대로 배우기 Part.2 JAVA, JSP]\n공공데이터 포털 사이트 이용방법\n자바(이클립스)에서 공공API 요청 및 출력(1)\n자바(이클립스)에서 공공API 요청 및 출력(2)\nJSON 데이터 웹페이지 테이블로 출력하기 with getJSON(1)\nJSON 데이터 웹페이지 테이블로 출력하기 with getJSON(2)\n자바(이클립스)에서 공공API 요청 및 출력(3)\nServlet JSP vs JSON 연동하기(1)\nServlet JSP vs JSON 연동하기(2) - 실습\nServlet JSP vs JSON 연동하기(3) - 실습\nServlet JSP vs JSON 연동하기(4) - 공공데이터 포털사이트 JSON 연동1\nServlet JSP vs JSON 연동하기(4) - 공공데이터 포털사이트 JSON 연동2\nJSON 데이터를 출력시키는 BS 테이블 클래스 연습하기(1)\nJSON 데이터를 출력시키는 BS 테이블 클래스 연습하기(2)\nASP, PHP 에서의 공공API 요청 및 JSON 결과 데이터 파싱 가이드\n부트스트랩 반응형 테이블\n\n\n[공공 데이터 (오픈 데이터) API 제대로 배우기 Part.3 Python]\n파이썬에서의 JSON 데이터 처리\n파이썬에서 제공하는 JSON 기본 모듈\nJSON 문자열을 객체로 변환 및 출력\n딕셔너리 자료구조와 반복문(1)\n딕셔너리 자료구조와 반복문(2)\n딕셔너리 자료구조와 반복문(3)\n딕셔너리 자료구조와 반복문(4)\n딕셔너리 자료구조와 반복문(5)\n딕셔너리 자료구조와 반복문(6)\n공공 데이터 API 사용을 위한 파이썬 라이브러리(1)\n공공 데이터 API 사용을 위한 파이썬 라이브러리(2)\nurllib.parse를 이용하여 password 변경해보기\n쿼리스트링 urlencode 메서드\nURL 문자열 변환 - 한글 인코딩 디코딩 quote, unquote\n파이썬 모듈 설치\n공공데이터 API를 이용하여 제공받은 JSON 데이터를 CSV 파일로 저장하기(1)\n공공데이터 API를 이용하여 제공받은 JSON 데이터를 CSV 파일로 저장하기(2)\n공공데이터 API를 이용하여 제공받은 JSON 데이터를 CSV 파일로 저장하기(3)\n\n\n[공공 데이터 (오픈 데이터) API 제대로 배우기 Part.4 API와 DB]\nSQLite3 데이터베이스 사용하기(1)\nSQLite3 데이터베이스 사용하기(2)\ncsv 파일에 들어있는 데이터를 sqlite DB에 저장하기1\ncsv 파일에 들어있는 데이터를 sqlite DB에 저장하기2\nsqlite DB에서 데이터 삭제하기",
      "target_audience": [
        "공공 데이터 포털의 오픈 데이터를 사용해보고자 하는 자",
        "공공 API 호출 및 결과 데이터를 파싱하는 것에 대해서 학습하고자 하는 자"
      ]
    },
    {
      "title": "Reinforcement Learning de cero a maestro - IA en Python (ES)",
      "url": "https://www.udemy.com/course/reinforcement_learning_principiante_maestro_1/",
      "bio": "Inteligencia artificial (AI) para la toma de decisiones. Aprendizaje por refuerzo - (Deep) Reinforcement Learning",
      "objectives": [
        "Comprender qué es el Reinforcement Learning y las tareas para las que es más adecuado.",
        "Algoritmos básicos del Reinforcement Learning",
        "Deep Reinforcement Learning (algoritmos de Reinforcement Learning combinados con redes neuronales)",
        "Métodos de gradiente de política",
        "Implementar algoritmos de Reinforcement Learning totalmente desde cero.",
        "Conocer las diferentes familias de métodos de Reinforcement Learning, sus ventajas e inconvenientes.",
        "Comprender fundamentalmente el proceso de aprendizaje de cada algoritmo.",
        "Ser capaz de implementar nuevos algoritmos al verlos en artículos científicos."
      ],
      "course_content": {
        "Módulo de bienvenida": [
          "Bienvenida",
          "Cursos de la serie sobre Reinforcement Learning",
          "Estructura del curso",
          "Preparación del entorno [Importante]",
          "Conecta conmigo en redes sociales"
        ],
        "El proceso de decisión de Markov (MDP)": [
          "Elementos comunes a las tareas de control",
          "Proceso de decision de Markov (PDM)",
          "Tipos de proceso de decisión de Markov",
          "Trayectoria y episodio",
          "Recompensa vs retorno",
          "Factor de descuento",
          "Política de actuación",
          "Valor de un estado y q-valor",
          "Ecuaciones de Bellman",
          "Resolver un proceso de decisión de Markov",
          "Preparación - PDM en código",
          "PDM en código - Parte 1",
          "PDM en código - Parte 2"
        ],
        "Programación dinámica": [
          "Introducción a la programación dinámica",
          "Iteración de valor",
          "Preparación - Iteración de valor",
          "Implementación - Iteración de valor 1",
          "Implementación - Iteración de valor 2",
          "Implementación - Iteración de valor 3",
          "Implementación - Iteración de valor 4",
          "Implementación - Iteración de valor 5",
          "Iteración de política",
          "Preparación - Iteración de política",
          "Implementación - Iteración de política 1",
          "Iteración de política: Evaluación de política",
          "Implementación - Iteración de política 2",
          "Iteración de política: Mejora de política",
          "Implementación - Iteración de política 3",
          "Implementación - Iteración de política 4",
          "Iteración de política generalizada (IPG)"
        ],
        "Métodos Monte Carlo": [
          "Introducción a los métodos Monte Carlo",
          "Resolviendo tareas de control con métodos Monte Carlo",
          "Monte Carlo con estrategia on-policy",
          "Preparación - Monte Carlo con estrategia on-policy",
          "Implementación - Monte Carlo con estrategia on-policy 1",
          "Implementación - Monte Carlo con estrategia on-policy 2",
          "Implementación - Monte Carlo con estrategia on-policy 3",
          "Preparación - MC de alpha constante",
          "Implementación - MC de alpha constante",
          "Monte Carlo con estrategia off-policy",
          "Preparación - Monte Carlo con estrategia off-policy",
          "Implementación - Monte Carlo con estrategia off-policy 1",
          "Implementación - Monte Carlo con estrategia off-policy 2",
          "Implementación - Monte Carlo con estrategia off-policy 3"
        ],
        "Métodos de diferencias temporales (TD)": [
          "Métodos de diferencias temporales",
          "Resolviendo tareas de control con métodos de diferencias temporales",
          "Comparativa métodos MC y DT",
          "SARSA",
          "Preparación - SARSA",
          "Implementación - SARSA 1",
          "Implementación - SARSA 2",
          "Q-Learning",
          "Preparación - Q-Learning",
          "Implementación - Q-Learning 1",
          "Implementación - Q-Learning 2",
          "Ventajas de los métodos de diferencias temporales"
        ],
        "Diferencias temporales en n pasos": [
          "Diferencias temporales en n pasos",
          "¿Dónde encajan los métodos en n pasos?",
          "¿Cómo afecta n al aprendizaje?",
          "SARSA en n pasos",
          "Aprendizaje con SARSA en n pasos",
          "Preparación - n-step SARSA",
          "Implementación - n-step SARSA"
        ],
        "Espacios de estados continuos": [
          "Preparación - Tareas clásicas de control en código",
          "Tareas clásicas de control en código",
          "Trabajando con espacios de estados continuos",
          "Agregación de estados",
          "Preparación - Espacios de estados continuos",
          "Implementación - Agregación de estados 1",
          "Implementación - Agregación de estados 2",
          "Implementación - Agregación de estados 3",
          "Tile Coding",
          "Implementación - Tile Coding 1",
          "Implementación - Tile Coding 2",
          "Implementación - Tile Coding 3"
        ],
        "Breve introducción a las redes neuronales": [
          "Aproximadores de funciones",
          "Redes neuronales",
          "Neuronas artificiales",
          "Cómo representar una red neuronal",
          "Optimización de la red neuronal",
          "Descenso gradiente estocástico"
        ],
        "Deep SARSA": [
          "Deep SARSA",
          "Optimización de la red neuronal (Deep Q-Network)",
          "Memoria de reproducción",
          "Red target",
          "Preparación - Deep SARSA",
          "Implementación - Deep SARSA 1",
          "Implementación - Deep SARSA 2",
          "Implementación - Deep SARSA 3",
          "Implementación - Deep SARSA 4",
          "Implementación - Deep SARSA 5",
          "Implementación - Deep SARSA 6",
          "Implementación - Deep SARSA 7",
          "Implementación - Deep SARSA 8",
          "Implementación - Deep SARSA 9",
          "Implementación - Deep SARSA 10"
        ],
        "Deep Q-Learning": [
          "Deep Q-Learning",
          "Preparación - Deep Q-Learning",
          "Implementación - Deep Q-Learning 1",
          "Implementación - Deep Q-Learning 2",
          "Implementación - Deep Q-Learning 3"
        ]
      },
      "requirements": [
        "Ser capaz de programar en Python de forma fluida.",
        "Conocer las bases del álgebra lineal y el cálculo diferencial (operar con vectores y matrices, hallar derivadas, etc.)",
        "Conocer las bases de la estadística y teoría de la probabilidad (media, varianza, correlación, etc.)"
      ],
      "description": "Este es el curso más completo de Reinforcement Learning en español. En él conocerás los fundamentos del Reinforcement Learning (aprendizaje por refuerzo), uno de los tres paradigmas de la inteligencia artificial moderna. En él implementarás desde cero algoritmos adaptativos que resuelven tareas de control en base a la experiencia. También aprenderás a combinar estos algoritmos con técnicas de Deep Learning (aprendizaje profundo) y redes neuronales, dando lugar a la rama conocida como Deep Reinforcement Learning (aprendizaje por refuerzo profundo).\nEste curso es el primero de la serie \"Reinforcement Learning de principiante a maestro\" y te dará las bases necesarias para que seas capaz de comprender nuevos algoritmos a medida que vayan apareciendo. También te preparará para los siguientes cursos de esta serie, en los que profundizaremos mucho más en distintas ramas del Reinforcement Learning y veremos algunos de los algoritmos más avanzados que existen.\nEl curso está enfocado a desarrollar habilidades prácticas. Por eso, después de conocer los conceptos más importantes de cada familia de métodos, implementaremos uno o más de sus algoritmos en libretas de código, desde cero.\n\n\nEste curso está dividido en tres partes y abarca los siguientes temas:\n\n\nParte 1 (Métodos tabulares):\n- Proceso de decisión de Markov\n- Programación dinámica (dynamic programming)\n- Métodos Monte Carlo (Monte Carlo methods)\n- Métodos de diferencias temporales (SARSA, Q-Learning)\n- Bootstrapping en n pasos\n\n\nParte 2 (Adaptación a espacios de estados continuos):\n- Agregación de estados\n- Tile Coding\n\n\nParte 3 (Deep Reinforcement Learning):\n- Deep SARSA\n- Deep Q-Learning\n- REINFORCE\n- Advantage Actor-Critic / A2C (método actor crítico por ventaja)",
      "target_audience": [
        "Desarrolladores de software que quieren encontrar un empleo en Machine Learning.",
        "Estudiantes que quieren desarrollar habilidades prácticas en el campo del Machine Learning.",
        "Investigadores y académicos que quieran potenciar sus capacidades para escribir código en el campo de la IA."
      ]
    },
    {
      "title": "Python Data Science A-Z: Python ile Veri Bilimi",
      "url": "https://www.udemy.com/course/python-data-science-a-z-python-ile-veri-bilimi/",
      "bio": "Gerçek Hayat Projeleri ile Veri Bilimi öğrenin ve Yapay Zekaya Giriş Yapın",
      "objectives": [
        "Yapay zeka için sağlam bir temel atmış olacaksınız",
        "Veri bilimi için gerekli kütüphaneleri öğreneceksiniz",
        "Makine öğrenimine başlamaya hazır olacaksınız",
        "CV'nize Data Scientist yazabileceksiniz"
      ],
      "course_content": {
        "Kurulumlar": [
          "Anaconda Kurulumu"
        ],
        "Numpy": [
          "Numpy Nedir",
          "Numpy Giriş",
          "Numpy Metotları",
          "Numpy Indexlemeler",
          "Arange ve Linspace",
          "Karşılaştırma ,Mantıksal Operatörler",
          "Aritmetik İşlemler",
          "Transpoz Alma ve Diğer İşlemler",
          "Numpy Metotları 2",
          "Reshape Flatten ve Ravel",
          "Matrisleri Birleştirme"
        ],
        "Pandas": [
          "Giriş ve Csv Dosyası Oluşturma",
          "DataFrame Oluşturma",
          "Pandas Metotları",
          "Pandas Metotları ve Filtreleme",
          "Indexleri Değiştirme",
          "Handle Missing Values(Eksik Değerleri Doldurma)",
          "Pandas Replace Metodu",
          "Pandas Metotları 2",
          "Pandas Groupby Kullanımı",
          "Pandas Concat Kullanımı",
          "Pandas Merge Metodu",
          "Pandas Pivot ve Pivot Table Kullanımı",
          "Pandas Melt Kullanımı",
          "Pandas Crosstab Kullanımı"
        ],
        "Pandas Time Series": [
          "Pandas Time Series Giriş ve Metotlar",
          "Pandas Time Series Indexleme",
          "Date Range ve Asfreq Metodu",
          "To Datetime Kullanımı",
          "Period ve Asfreq Kullanımı",
          "Period Range Kullanımı",
          "Shift ve Tshift Kullanımı"
        ],
        "Feature Engineering": [
          "Feature Engineering Giriş",
          "Aykırı Değerleri Bulma ve Kaldırma",
          "Standart Deviation Kullanarak Aykırı Değerleri Kaldırma",
          "IQR Kullanarak Aykırı Değerleri Kaldırma"
        ],
        "Matplotlib": [
          "Matplotlib Giriş",
          "Matplotlib Grafik Çizdirme",
          "Grafik Çizdirme ve Parametreler",
          "Birden Fazla Grafik Çizdirme",
          "Bar Plot Çizimi",
          "Histogram Çizimi",
          "Pie Chart Kullanımı",
          "Scatter Plot Çizimi",
          "Subplot Kullanımı"
        ],
        "Seaborn": [
          "Seaborn Giriş ve Line Plot",
          "Bar Plot Çizimi",
          "Histogram Çizimi",
          "BoxPlot Çizimi",
          "Scatter Plot Çizimi",
          "Heatmap Kullanımı",
          "Subplot Kullanımı"
        ],
        "Proje 1 : Covid 19": [
          "Giriş",
          "Datasetimizi Düzenleme",
          "Datasetimizi Düzenleme ve Toplama Vaka Sayısını Gösterme",
          "Plotly ile Görselleştirme",
          "Ödev",
          "Datasetimiz Düzenleme ve İyileşen ve Ölüm Sayısını Gösterme(Ödev Çözümü)",
          "Dünya Haritası Çizimi",
          "Günlük Vaka Sayısını Gösterme"
        ],
        "Proje 2 : Süpermarket Satış Analizi": [
          "Giriş",
          "Dataseti Düzenleme ve Month Sütunu Ekleme",
          "Dataseti Düzenleme ve Year Sütunu Ekleme",
          "Aylara ve Yıllara Göre Görselleştirme",
          "Müşteri İsimlerine Göre Görselleştirme",
          "Kategoriye Göre Görselleştirme"
        ]
      },
      "requirements": [
        "Sıfırdan İleri Seviyeye Komple Python kursunu almış olmak veya Python temellerini bilmek",
        "Güçlü bir öğrenme isteği"
      ],
      "description": "Python Data Science A-Z: Python ile Veri Bilimi kursumuza hoş geldiniz!\n- Bu kursla  Python ile Data Science(Veri Bilimi) öğrenmenin keyfini çıkaracaksınız.\n\n\n- Neden Python Öğrenmeliyiz\nPython kolaylıkla öğrenildiği için kodlamaya yeni başlayanlar genelde Pythonu tercih ediyor .\nYapay Zekada diğer dillere nazaran en çok Python kullanılıyor.\nPython açık kaynak bir dil olduğu için bir çok büyük firma tarafından destekleniyor.\nPython geliştiricilerinin maaşları diğer dillerin geliştiricilerinden daha yüksektir.\nDünyada en hızlı büyüyen sektörlerden birisine giriş yapabilme fırsatı yakalayabileceksiniz\nHem daha okunaklı, hem daha temiz kodsal söz dizimine sahiptir.\nPython’un buna benzer özelliklerinden dolayı, dünya çapında ün sahibi büyük kuruluşlar ( Google, Yahoo! vb.) bünyelerinde herzaman Python programcılarına ihtiyaç duyuyor. Son zamanlarda Google bu dile çok ciddi bir yatırım yapmaktadır\n\n\nPython programlama dilleri arasında işlemesi ve öğrenmesi en kolay dillerden biridir. Sözdiziminin açıkça tanımlanması yazımını; basit arayüzü ise, okunabilirliğini kolaylaştırmaktadır. Python’un standart kütüphanelere erişim yeteneği de bir diğer avantajıdır. UNIX, Windows ve Macintosh gibi platformlara arabirim değişikliği gerektirmeden taşınabilir.\n-Neden Bu Kursa Kaydolmalıyız\nTeorik anlatımın yanında neredeyse her bölümde projeler yapıyoruz.\nKursta projeler yaptığımız için kenidinizi inanılmaz derecede geliştirdiğinizi göreceksiniz.\nPython geliştiricilerinin maaşları diğer dillerin geliştiricilerinden daha yüksektir.\nKursta gerçek hayat projeleri yaptığımız için algoritma yeteneğinizi iyi bir şekilde geliştireceksiniz\n\n\nKurs boyunca öğreneceğimiz konular :\nNumpy\nPandas\nPandas Time Series\nFeature Engineering\nMatplotlib\nSeaborn\nCovid 19 Veri Analizi Projesi\nSüpermarket Satış Analizi Projesi\n\n\n\n\nHazırsanız hemen başlayalım!",
      "target_audience": [
        "Data Science(Veri Bilimi) alanında kendini geliştirmek isteyenler",
        "Python dilinde ve Yapay zeka alanında uzmanlaşmak isteyenler"
      ]
    },
    {
      "title": "KI-Stimmen & DeepFakes: AI Videos & Voice Cloning Business",
      "url": "https://www.udemy.com/course/ki-stimmen-deepfakes-ai-videos-bussines-und-privat/",
      "bio": "Deep Fakes: Machine learning, Voice-Over, Midjourney, Generative AI, Social Media Marketing, Instagram, ChatGPT & Geld",
      "objectives": [
        "Alles zum Thema KI-Stimmerstellung",
        "Wie man mit Elevenlabs arbeitet",
        "Wie man mit Murf AI arbeitet",
        "Was Huggingface ist und wie sich die gratis und Open-Source Lösungen schlagen",
        "Lerne, wie man Lippen/Mundbewegungen für ausländische Filmsynchronisationen ändert",
        "Stimme klonen",
        "TTS (Text-to-Speech)",
        "Erzeugen von Videos mit sprechenden Köpfen mit AI (künstliche Intelligenz)",
        "Ein Bild einer Person in ein bewegtes Video umwandeln (Motion Copying)",
        "Ändern, was jemand in einem Video sagt",
        "Alles zum Thema Text to Speech von Facebook, Meta, Google und Amazon",
        "Lerne die besten Tools kennen",
        "Erstelle Videos, für Social Media wie Instagram, Tiktok, Youtube oder Twitter"
      ],
      "course_content": {
        "Einführung": [
          "Willkommen!",
          "Kurs Überblick",
          "Mein Ziel was dich erwartet und ein kleiner Tipp",
          "Straten wir beim Problem: Was wurde früher gemacht",
          "Kurzer Überblick: Einige Tools und wofür sind sie relevant",
          "Erster Blick: Was ist möglich",
          "Nützliche Links",
          "Dozentenvorstellung: Arnold Oberleiter (Arnie)"
        ],
        "Aktuelle Herausforderung: Menschliche Stimmen sind selten und teuer": [
          "Kosten und Logistische Schwierigkeiten",
          "Mehrsprachige Inhalte: schwierig zu finden & Freelancer Kosten im Überblick"
        ],
        "ChatGPT Crash Kurs": [
          "ChatGPT Crash Kurs: Alles Wichtige im Schnelldurchlauf",
          "Was bedeutet Lernen & bist auch du ein guter Lerner"
        ],
        "Der Weg zur Lösung [Elevenlabs, murf.io, audyo, lovo, Facebook, Google, Amazon]": [
          "Eleven Labs: Alles was du zum wohl bekanntesten Tool wissen musst",
          "Update: Elevenlabs Speech to Speech!",
          "Murf AI: EIne gute Alternative",
          "Audyo Ai: Einfach, jedoch einige Nachteile",
          "Lovo AI: Alternative zu Murf.ai",
          "Meta (Facebook), Google, Amazon und Bark auf HuggingFace"
        ],
        "Anwendungsszenarien mit Beispiel": [
          "Beispiel 1: Werbung und Produktbeschreibung für eine Armbanduhr",
          "Beispiel 2: Erklärvideos erstellen mit ElevenLabs",
          "Beispiel 3: Voicover für Youtube [mehrere Sprachen möglich]"
        ],
        "Spezifische Anwendungsfälle in verschiedenen Branchen": [
          "Hörbücher: Trainiere deine eigenen stimmen in ElevenLabs",
          "Podcast: Umwandeln in Text und dann weitere Distribution in andere Sprachen",
          "Kundensupport: Antworten erstellen für einen Anrufbeantworter"
        ],
        "Praxisnahe Fallbeispiele: Kann man Kosten sparen?": [
          "Fallbeispiel 1: Skalierung eines Verlages durch neue Sprachen",
          "Fallbeispiel 2: Unternehmen Intigriert Text to Speech in den Kundensupport"
        ],
        "Deepfakes: Lasst uns Blödsinn machen!": [
          "Worum geht es ab hier, BLÖDSINN und DeepFakes",
          "Schritt Nr. 1: Klone die Stimme die du brauchst in ElevenLabs",
          "Schritt 2: Suche eine passende Video-Stelle und dein Audio",
          "WAV2LIP: JEDER wird das sagen, was du willst",
          "Erstelle Perfekte Midjourney Bilder dank ChatGPT 4 {Midjouerney Crash Kurs]",
          "Bild sprechen lassen mit WAV2LIP [funktioniert nicht immer perfekt]",
          "[Midjourney] Bilder sprechen lassen und animieren mit D-ID",
          "Wozu soll und darf ich diese Technologie verwenden",
          "Face Swap Videos [Verwandle dich]",
          "Der einfache Weg zu Faceswap (mit Seaart)"
        ],
        "Audio und Video verbessern mit AI Tools": [
          "Audio verbessern mit Adobe Podcast Enhancer: Erstelle Studio-Sound [Gratis]",
          "Videos verbessern mit AI-Upscaling Tools"
        ],
        "Danke und wie geht es weiter": [
          "Rekapitulation und mein DANKE!",
          "Bonus"
        ]
      },
      "requirements": [
        "Keine Voraussetzungen nötig"
      ],
      "description": "Willkommen zu \"KI-Stimmen & Deep Fakes\": Entdecke und skaliere Deine kreative Kraft!\"\nIn diesem Kurs tauchst Du ein in die faszinierende Welt der künstlichen Intelligenz, Text-zu-Sprache und DeepFakes.\nDu bekommst Einblicke in modernste KI-Technologien wie ChatGPT, Midjourney und WAV2LIP, um Dein kreatives Potenzial zu entfesseln dein Business zu skalieren un dadurch mehr Geld zu verdienen.\nStell Dir vor, Du kannst atemberaubende Videos erstellen, die alle Grenzen sprengen.\n\n\nMit diesem Kurs gewinnst Du eine Fülle von innovativen Techniken, um Deine kreativen Ideen Wirklichkeit werden zu lassen:\n\n\nStimmenklon - Gib Deinen Gedanken Leben. Lerne, wie Du jede gewünschte Stimme imitieren kannst und erstelle unvergessliche Geschichten.\nVideo-Voiceover-Manipulation - Gestalte die Realität nach Deinem Willen. Meistere die Kunst der Video-Voiceover-Bearbeitung und schaffe fesselnde Inhalte, die Dein Publikum fesseln.\nSkalieren von deinem Unternehmen durch Text-to-speech\n\n\nMein Kurs bietet für jeden etwas, egal ob Anfänger oder erfahrener Profi.\nDu lernst, wie man KI-Tools wie ElevenLabs, Murf AI, Voice to Lip, ChatGPT und Midjourney effektiv einsetzt, und wirst Teil einer unterstützenden Community von Gleichgesinnten.\n\n\nIn \"KI-Stimmen & Deep Fakes\" wirst Du:\n\n\nDie Techniken des Stimmenklonens meistern und KI-Tools wie ChatGPT und Midjourney für atemberaubende Kreationen nutzen.\nLernen, wie Du Text-to-Speech-Technologien wie ElevenLabs, Murf, Facebook [Meta] und Amazon optimal einsetzen kannst.\nEntdecken, wie Du Text-to-Speech zur Skalierung Deines Unternehmens einsetzen kannst, um Zeit und Kosten zu sparen.\nNeue Einkommensquellen in der Welt der DeepFakes erschließen, ob als Filmemacher, Content Creator, Voiceover-Künstler oder Social-Media-Influencer.\nDu lernst die Technologie Wave 2 Lip kennen.\n\"KI-Stimmen & Deep Fakes\" ist ideal für kreative Köpfe, Influencer, Marketingprofis und Unternehmer, die ihren kreativen Horizont erweitern und die transformative Kraft der KI-Technologie nutzen wollen.\n\n\nNutze diese Chance, die fesselnde Kraft von Text-zu-Sprache und KI-Technologien wie ChatGPT und Midjourney zu nutzen, um Deine kreative Vision zum Leben zu erwecken.\n\n\nMelde Dich noch heute für \"KI-Stimmen & Deep Fakes: Dein kreativer Booster\" an und werde zum Meister der DeepFakes und Text-to-Speech!",
      "target_audience": [
        "An Unternehmer, die effizienter werde wollen und Geld sparen möchten",
        "Privatpersonen, die sich für neue Technologie Interessieren",
        "An Jeden, der neude Dinge ausprobieren möchte",
        "Leute, die coole Videos erstellen möchten"
      ]
    },
    {
      "title": "[ES] Bootcamp de IA Práctica y Certificación en 7 Días",
      "url": "https://www.udemy.com/course/bootcamp-de-ia-practica-y-certificacion-en-7-dias/",
      "bio": "De Cero a IA: Guía para Principiantes para Crear y Desplegar Proyectos de IA (AI)",
      "objectives": [
        "Crea, entrena y despliega modelos de machine learning para clasificación, regresión y tareas de NLP en aplicaciones reales.",
        "Domina conceptos clave de IA: redes neuronales, preprocesamiento de datos, evaluación de modelos y procesamiento de texto.",
        "Despliega modelos de IA como servicios web con Flask y publícalos en la nube en plataformas como Heroku.",
        "Usa modelos preentrenados y técnicas de transferencia para tareas rápidas de NLP y clasificación de imágenes."
      ],
      "course_content": {
        "Introducción al Curso": [
          "Introducción al Curso",
          "Recursos del Curso"
        ],
        "Día 1: Fundamentos de Python para IA": [
          "Introducción al Día 1: Fundamentos de Python para IA",
          "Introducción a la Programación en Python",
          "Fundamentos de Python",
          "Trabajando con Listas y Diccionarios",
          "Introducción a NumPy",
          "Introducción a Pandas",
          "Proyecto Práctico: Manipulación Básica de Datos y Manejo de Archivos",
          "Día 1: Ejercicio de Programación"
        ],
        "Día 2: Análisis Exploratorio de Datos (EDA)": [
          "Introducción al Día 2: Análisis Exploratorio de Datos (EDA)",
          "Carga e Inspección de Datos",
          "Manejo de Datos Faltantes",
          "Transformación de Datos e Ingeniería de Características",
          "Visualización de Datos con Matplotlib y Seaborn",
          "Estadísticas Descriptivas",
          "Proyecto Práctico: Análisis Exploratorio de Datos en un Conjunto Real",
          "Día 2: Ejercicio de Programación"
        ],
        "Día 3: Introducción al Aprendizaje Automático (ML)": [
          "Introducción al Día 3: Introducción al Aprendizaje Automático (ML)",
          "¿Qué es el Aprendizaje Automático?",
          "Aprendizaje Supervisado y Preparación del Conjunto de Datos",
          "Construcción de un Modelo de Regresión Lineal",
          "Evaluación del Modelo",
          "Escalado de Características y Regularización",
          "Proyecto Práctico: Predicción de Precios de Viviendas usando Regresión Lineal",
          "Día 3: Ejercicio de Programación"
        ],
        "Día 4: Modelos de Clasificación en Aprendizaje Automático": [
          "Introducción al Día 4: Modelos de Clasificación en Aprendizaje Automático",
          "¿Qué es la Clasificación?",
          "Regresión Logística para Clasificación",
          "Construcción de un Clasificador de Regresión Logística",
          "Evaluación del Modelo de Clasificación",
          "Visualización de la Frontera de Decisión",
          "Proyecto Práctico: Detección de Spam Usando Regresión Logística",
          "Día 4: Ejercicio de Programación"
        ],
        "Día 5: Introducción a Redes Neuronales y Deep Learning": [
          "Introducción al Día 5: Introducción a Redes Neuronales y Deep Learning",
          "¿Qué es una Red Neuronal?",
          "Introducción a los Frameworks de Deep Learning",
          "Visión General del Conjunto de Datos MNIST",
          "Construcción de una Red Neuronal Simple para Clasificación MNIST",
          "Evaluación de la Red Neuronal",
          "Comprendiendo las Funciones de Activación",
          "Proyecto Práctico: Clasificación de Dígitos Manuscritos usando Redes Neuronales",
          "Día 5: Ejercicio de Programación"
        ],
        "Día 6: Construcción de un Modelo de Análisis de Sentimientos usando NLP": [
          "Introducción al Día 6: Análisis de Sentimientos con NLP",
          "Introducción al Procesamiento de Lenguaje Natural (NLP)",
          "Análisis de Sentimientos: Comprendiendo la Clasificación de Texto",
          "Preprocesamiento de Texto",
          "Uso de Modelos Preentrenados para NLP (Hugging Face)",
          "Construcción de un Modelo de Análisis de Sentimientos con TensorFlow",
          "Evaluación del Modelo",
          "Proyecto Práctico: Análisis de Sentimientos Usando Modelos Preentrenados de NLP",
          "Día 6: Ejercicio de Programación"
        ],
        "Día 7: Despliegue de un Modelo de IA como Servicio Web": [
          "Introducción al Día 7: Despliegue de un Modelo de IA como Servicio Web",
          "Introducción a Flask para el Desarrollo Web",
          "Creación de una Interfaz Web para tu Modelo",
          "Despliegue de la Aplicación Flask en Heroku",
          "Pruebas del Servicio Web",
          "Día 7: Ejercicio de Programación"
        ]
      },
      "requirements": [
        "No se requiere conocimiento previo de programación: El curso comienza desde lo básico en Python, por lo que no necesitas experiencia previa.",
        "Uso básico de la computadora: Los estudiantes deben saber navegar en su computadora, instalar software y usar un navegador web.",
        "Conocimientos básicos de matemáticas: Será útil entender álgebra y nociones básicas de álgebra lineal (matrices, vectores).",
        "Computadora con acceso a internet: Se necesita una laptop o computadora de escritorio para instalar software, descargar datos y seguir las lecciones."
      ],
      "description": "Este curso está traducido mediante IA del inglés al español para que puedas aprender tecnologías de vanguardia en tu idioma nativo.\nBienvenido al \"Bootcamp de 7 Días de Desarrollo Práctico de IA: Construye Proyectos de IA Reales Desde Cero\", un curso diseñado para principiantes absolutos que desean adentrarse en el mundo de la inteligencia artificial (IA). Este curso es ideal para quienes tienen poca o ninguna experiencia previa en programación o IA, pero poseen la curiosidad y motivación para aprender. Ya seas estudiante, estés cambiando de carrera o simplemente tengas interés en construir tu primer proyecto de IA, este curso está estructurado para llevarte de cero conocimientos a desplegar modelos de IA en el mundo real.\nDurante 7 días, construirás proyectos todos los días, comenzando con lo básico de la programación en Python hasta desplegar un modelo de IA completamente funcional en la web. Cada día está lleno de proyectos prácticos, aplicaciones reales e instrucciones fáciles de seguir para que no solo adquieras conocimientos teóricos, sino también habilidades aplicables de inmediato en el mundo real.\nLo que aprenderás:\nEste curso cubre todo lo que necesitas para empezar en el desarrollo de IA. Cada día se centra en un nuevo tema, construyendo progresivamente sobre lo aprendido anteriormente. Aquí tienes una breve visión general de lo que puedes esperar:\nDía 1: Fundamentos de Python para IA\nComenzamos con la base: programación en Python. Python es el lenguaje más popular para IA, y al finalizar el Día 1 entenderás la sintaxis básica, tipos de datos, flujo de control y cómo usar librerías esenciales como NumPy y Pandas. También construirás tu primer programa sencillo, preparando el terreno para los proyectos de IA que vienen.\nDía 2: Análisis Exploratorio de Datos (EDA)\nLos datos son el pilar de la IA, y antes de entrenar modelos, debes saber analizarlos. En el Día 2 aprenderás a limpiar, manipular y visualizar datos. Usando librerías como Matplotlib y Seaborn, explorarás conjuntos de datos, manejarás datos faltantes y visualizarás relaciones entre características. Trabajarás con datos reales para descubrir patrones ocultos.\nDía 3: Introducción al Aprendizaje Automático (Machine Learning)\nEn el Día 3, nos sumergimos en el aprendizaje automático con un enfoque en regresión lineal. Aprenderás los fundamentos del aprendizaje supervisado, incluyendo cómo dividir tu conjunto de datos en entrenamiento y prueba, entrenar un modelo y evaluar su desempeño. Al final del día, construirás tu primer modelo predictivo para predecir variables continuas como precios de viviendas.\nDía 4: Modelos de Clasificación en Machine Learning\nLuego, abordarás problemas de clasificación usando regresión logística. Ya sea prediciendo si un correo electrónico es spam o clasificando la pérdida de clientes, este día te enseñará a construir un modelo de clasificación y evaluarlo con métricas como precisión, recall y exactitud. También interpretarás matrices de confusión para analizar el rendimiento de tu modelo.\nDía 5: Redes Neuronales y Deep Learning\nEl Día 5 introduce el fascinante mundo de las redes neuronales. Construirás una red neuronal feedforward simple para clasificar dígitos manuscritos usando el conjunto de datos MNIST. Trabajarás con librerías como TensorFlow o PyTorch y aprenderás conceptos clave como funciones de activación, retropropagación y entrenamiento de modelos de deep learning.\nDía 6: Procesamiento de Lenguaje Natural (NLP)\nEl Día 6 se centra en el Procesamiento de Lenguaje Natural (NLP), donde construirás un modelo de análisis de sentimientos usando datos de texto. Aprovecharás modelos preentrenados de Hugging Face o crearás el tuyo propio con TensorFlow para clasificar texto como positivo o negativo. Aprenderás sobre preprocesamiento de texto, tokenización y transferencia de aprendizaje en NLP.\nDía 7: Despliegue de un Modelo de IA como Servicio Web\nEn el último día, aprenderás a desplegar tus modelos de IA como servicios web usando Flask. Integrarás tus modelos en una aplicación web para que los usuarios puedan interactuar a través del navegador. Además, desplegarás tu app en plataformas en la nube como Heroku. Al final del día, tendrás una aplicación web impulsada por IA accesible para cualquier usuario.\n¿Para quién es este curso?\nPrincipiantes absolutos: No se requiere conocimiento previo en programación o IA. Este curso está pensado para ser amigable para principiantes.\nEstudiantes: Si estudias IA, aprendizaje automático o ciencia de datos, este curso te proporcionará experiencia práctica esencial para afianzar tus conocimientos.\nPersonas en transición de carrera: Si deseas cambiar de carrera hacia IA o aprendizaje automático, este curso te dará una base sólida para comenzar tu viaje.\nEntusiastas y aficionados: Si simplemente tienes curiosidad por la IA y deseas construir proyectos por diversión, este curso ofrece instrucciones fáciles de seguir.\n¿Por qué tomar este curso?\nEste curso no se basa solo en teoría: ¡es acción pura! Construirás proyectos reales para tu portafolio en tan solo una semana. Cada día está lleno de ejercicios prácticos de codificación y creación de proyectos que hacen que aprender desarrollo de IA sea sencillo y accesible. Ya sea para impulsar tu carrera, impresionar a empleadores o explorar el mundo de la IA por interés personal, este curso está diseñado para que tu aprendizaje sea dinámico, interactivo y gratificante.\n¿Listo para construir proyectos de IA desde cero en solo 7 días? ¡Empecemos!",
      "target_audience": [
        "Este curso está diseñado para principiantes absolutos que desean aprender desarrollo de IA, pero tienen poca o ninguna experiencia previa en programación o machine learning. Es perfecto para personas curiosas sobre cómo funciona la IA y que quieren obtener experiencia práctica construyendo proyectos de IA reales desde cero. Ya seas estudiante, estés cambiando de carrera o seas un entusiasta, este curso ofrece una guía paso a paso que hace accesibles los conceptos complejos de IA. Si estás motivado a aprender a construir y desplegar modelos de IA, incluso sin una formación técnica, ¡este curso es para ti!"
      ]
    },
    {
      "title": "파이썬(Python) 딥러닝(Deep Learning,DL) 프로젝트 - 딥러닝 모델 입문",
      "url": "https://www.udemy.com/course/maso-ds-python-onc73/",
      "bio": "딥러닝(Deep Learning)의 개념을 완벽히 정리하여 실제로 활용해보는 입문 과정! 텐서플로(Tensorflow)와 케라스(Keras)를 활용하여 실제로 파이썬 환경에서 딥러닝 모델을 구현까지!",
      "objectives": [
        "딥러닝의 학습 원리인 순전파와 역전파에 대한 이해",
        "딥러닝 개념과 퍼셉트론 개념 이해",
        "이해 기반의 딥러닝 활용 실습으로 실제 활용 능력 확보",
        "파이썬 가상 환경과 Keras 활용 능력"
      ],
      "course_content": {
        "강의 소개": [
          "DLE0001 강의 소개"
        ],
        "머신 러닝과 딥러닝": [
          "DLE0101 머신 러닝의 개념",
          "DLE0102 머신 러닝과 딥러닝의 차이",
          "DLE0103 딥러닝의 데이터셋 나누기",
          "DLE0104 딥러닝의 평가 지표"
        ],
        "딥러닝의 개념": [
          "DLE0201 딥러닝의 개념",
          "DLE0202 딥러닝의 역사"
        ],
        "퍼셉트론": [
          "DLE0301 퍼셉트론",
          "DLE0302 다층 퍼셉트론",
          "DLE0303 다층 퍼셉트론의 구현"
        ],
        "퍼셉트론 실습": [
          "DLE0401 퍼셉트론 실습_목표 설정",
          "DLE0402 퍼셉트론 실습_OR 게이트",
          "DLE0403 퍼셉트론 실습_AND 게이트",
          "DLE0404 퍼셉트론 실습_XOR 게이트"
        ],
        "딥러닝의 필수요소": [
          "DLE0501 딥러닝의 필수요소",
          "DLE0502 활성화 함수",
          "DLE0503 손실 함수, 옵티마이저, 에포크"
        ],
        "딥러닝 맛보기 실습": [
          "DLE0601 딥러닝 맛보기 실습 – 모델 정의",
          "DLE0602 딥러닝 맛보기 실습 – 폐암 수술 환자의 생존율 예측"
        ],
        "딥러닝의 구성 요소": [
          "DLE0701 딥러닝의 구성 요소",
          "DLE0702 활성화 함수의 종류",
          "DLE0703 손실 함수의 종류",
          "DLE0704 구성 요소 심화"
        ],
        "순전파와 역전파": [
          "DLE0801 순전파와 역전파",
          "DLE0802 순전파 학습 모델",
          "DLE0803 순전파 회귀 모델",
          "DLE0804 순전파 분류 모델",
          "DLE0805 역전파 학습 모델"
        ],
        "딥러닝의 문제점과 해결 방안": [
          "DLE0901 딥러닝의 문제점",
          "DLE0902 과적합 문제와 해결",
          "DLE0903 기울기 소실 문제와 해결",
          "DLE0904 성능 저하 문제와 해결"
        ]
      },
      "requirements": [
        "본 강의는 기본적인 파이썬 활용 능력을 요구합니다.",
        "마소캠퍼스의 [파이썬(Python) 실무 데이터 분석 프로젝트] 강의들을 먼저 수강하시는걸 추천드립니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n딥러닝이 대체 뭐길래?\n우리는 아침에 일어나면 스마트폰의 음성 인식 서비스에게 날씨를 물어보는 것으로 하루를 시작합니다.\n아침에 출근하면서 Ai가 그린 그림과 소설 등이 대회에서 수상한 소식을 들으며,\n업무 중 긴장되는 해외 고객과의 대화를 번역기를 활용해 위기를 넘깁니다.\n점심 시간에 옆자리 직원이 신차를 주문한다는 자랑에 배가 아파 괜히 자율주행 기술에 대한 불신을 나타냅니다\n이 모든 것들이 딥러닝을 통해 실현된 기술이며, 딥러닝이 가져온 변화 중에선 아주 일부에 불과합니다.\n알파고 대국과 함께 전 세계인의 관심이 딥러닝에 집중된지 어느덧 10년, 단 10년 만에 세상은 놀랄 만큼 변했으며,\n새로운 빅테크 기업들이 눈부신 실적을 내는 것이 매일 경제지에 올라옵니다.\n그렇다면 대체 딥러닝이 뭐길래 이렇게 많은 변화를 가져온걸까요?\n딥러닝이란 인공지능 기술로 구현한 사람의 두뇌라 볼 수 있습니다.\n눈, 코, 입, 피부 등으로 감지한 자극이 뇌에 전달되어 신호로 인식되는 것처럼\n디지털화된 정보가 몇 가지 단계를 거쳐 컴퓨터가 자율적으로 판단하고, 결론을 도출합니다.\n물론 첨단 기술의 하나이므로 설계에는 상당한 연구와 숙련자의 지식이 필요합니다.\n하지만, 일반적인 사용의 경우에는 그렇지 않습니다.\n파이썬의 최대 장점 중 하나인 무료로 설치 가능한 모듈에는 이미 딥러닝을 구현할 수 있는 모듈이 개발되었으며, 실제로 많은 사람들이 활용하고 있습니다.\n많은 사람들이 사용할 수 있다는 건, 당신도 충분히 활용 가능하다는 의미입니다.\n그래서 마소캠퍼스에서는 누구나 딥러닝에 쉽게 입문할 수 있도록 [파이썬(Python) 딥러닝(Deep Learning,DL) 프로젝트 - 텐서플로(Tensorflow) 입문] 강의를 통해 딥러닝의 개념과 작동 원리를 제작하였습니다.\n그야말로 혁명적인 생산성 향상을 가져오기 위해, 당신도 딥러닝에 입문해보세요!\n\n\n[파이썬(Python) 딥러닝(Deep Learning,DL) 프로젝트 - 텐서플로(Tensorflow) 입문] 강의를 듣고 나면,\n여러분께서는 다음과 같은 역량을 확보하실 수 있습니다.\n인공 지능, 머신 러닝, 딥러닝의 개념 파악\n딥러닝의 구성 요소와 모델의 원리 이해\n딥러닝의 학습 원리 및 오차 수정 방식 이해\n파이썬 가상 환경 구축과 Keras 활용 능력\n\n\n분야에 상관 없이 압도적인 생산성 향상을 가져다 주는 딥러닝!\n딥러닝을 “제대로” 활용하기 위해 개념부터 완벽하게 잡고 가는 과정!\n\n\n-\n\n\n[ 강 사  소 개 ]\n\n\n김 진 숙\n現 마소캠퍼스 수석 교수\n컴퓨터시스템 공학 석사\n김진숙 교수는 마소캠퍼스에서 빅데이터 부분 수석 교수로 빅데이터(R, 파이썬), HTML5/CSS3, JQueryMobile, 스크래치, 앱인벤터, IoT 등의 최신 IT 관련 기술 과정들까지 다양한 기업과 기관의 수강생들을 대상으로 열정 넘치는 강의를 이어가고 있습니다. 김진숙 교수는 스마트팜 IoT 프로젝트, 카 셰어링 앱 프로젝트 등 다수 프로젝트 지도 경력까지 겸비한 전문가입니다.\n-",
      "target_audience": [
        "인공지능의 업무 활용을 시도하고 싶은 실무자",
        "IT업계로 창업/이직/입사 등 커리어를 쌓고 싶은 모든 사람",
        "사업에 인공지능을 도입하고 싶은 경영자, 실무자",
        "딥러닝 역량을 쌓기 위해 첫 단추부터 제대로 시작하고 싶은 모든 사람"
      ]
    },
    {
      "title": "数据分析初阶课",
      "url": "https://www.udemy.com/course/rztppjgm/",
      "bio": "熟练掌握三大数据分析工具的核心技能",
      "objectives": [
        "认识数据分析师的能力模型",
        "围绕核心算法模型体系化学习",
        "熟练掌握Excel、SQL、R语言三大数据分析工具的核心技能",
        "数据分析师必备硬技能"
      ],
      "course_content": {
        "「零」课程导论": [
          "讲师介绍",
          "课程介绍（上）",
          "课程介绍（下）"
        ],
        "「第一周」带你走进数据分析师的世界": [
          "「本周导读」",
          "1.1 数据分析的定义",
          "1.2 数据分析的价值",
          "2.1 数据团队与数据分析师",
          "2.2「案例」数据分析驱动的业务全流程",
          "3.1 数据分析师必备硬技能",
          "3.2 数据分析师必备软技能（上）",
          "3.2 数据分析师必备软技能（下）",
          "4.1 数据分析师的能力模型",
          "4.2 数据分析师的职位晋升",
          "5.1 数据的类型",
          "5.2 变量的类型",
          "6.1「案例」数据分析工作流程",
          "「本周总结」",
          "「本门课程的学习姿势」"
        ],
        "「第二周」Excel与可视化初步": [
          "「本周导读」",
          "1. 强大的数据分析工具Excel",
          "「案例介绍」",
          "2.1 Excel函数的基本知识",
          "2.2 数据处理类Excel函数",
          "2.3 数据分析类Excel函数",
          "3.1 数据透视表",
          "4.1 数据可视化",
          "4.2 Excel作图",
          "5. Power BI 作图基础",
          "Power BI 使用指南",
          "「本周总结」"
        ],
        "「第三周」MySQL安装": [
          "安装文档",
          "SQL基础知识"
        ],
        "「第三周」SQL在数据分析中的应用": [
          "「本周导读」",
          "「案例」SQL在数据分析中的应用",
          "1.SQL核心语句",
          "1.1 数据查询与过滤",
          "1.2 数据聚合",
          "1.3 数据表间连接",
          "1.4 数据的增、改、删",
          "2. SQL进阶用法",
          "3.1 「案例」供应商营业额分析",
          "3.2 「案例」网店销售趋势分析",
          "「本周总结」"
        ],
        "「第四周」统计基础": [
          "「本周导读」",
          "1.1 统计知识的力量",
          "1.2 课程内容总览",
          "2.1 案例介绍",
          "3.1 什么是概率",
          "3.2 概率分布",
          "3.3 概率分布举例",
          "4.1 方差与标准方差",
          "4.2 四分位数与百分位数",
          "4.3 提升度和杠杆量",
          "5.1 中心极限定理和正态分布",
          "6.1 假设检验的思路",
          "6.2 假设检验的步骤",
          "7.1 A/B测试的思路",
          "7.2 A/B测试的步骤",
          "7.3 A/B测试的工作流程",
          "「本周总结」",
          "「延伸阅读」"
        ],
        "「第五周」R语言": [
          "「本周导读」",
          "1. R语言的简介",
          "「R的安装」",
          "2. 基本数据类型",
          "3. 基本数据结构",
          "4. 读写数据",
          "5. R的数据处理",
          "「查看数据」",
          "「函数的搜索和使用查询」",
          "6. R的数据分析",
          "7. 控制流",
          "「自定义函数与R软件包」",
          "8.1 R的可视化（ggplot2）",
          "8.2 「案例」R的数据可视化",
          "「本周总结」"
        ],
        "「第六周」机器学习初步": [
          "「本周导读」",
          "1. 机器学习简介",
          "2 机器学习在数据分析中应用",
          "3.1 决策树的理论基础",
          "3.2 决策树的算法实现",
          "4.1 线性回归的基本概念",
          "4.2 实操步骤及重要概念R^2",
          "4.3 线性回归在数据分析中的实操",
          "5. K-means聚类",
          "6. 机器学习的挑战",
          "「本周总结」"
        ],
        "「第七周」数据分析综合实践": [
          "「本周导读」",
          "1. R-markdown",
          "2. dplyr",
          "3. 数据探索工作指导",
          "4. 综合项目",
          "5. 项目分析报告PPT呈现示例"
        ],
        "回顾总结": [
          "课后寄语"
        ]
      },
      "requirements": [
        "适用于0-2年的数据分析师"
      ],
      "description": "在互联网行业中，提升核心竞争力，数据分析能力是必备技能\n我们经过大量调研总结出三条规律：\n1. 薪资水平越高，岗位对数据分析能力的要求越高；\n2. 越是大厂，对数据分析能力的要求越高；\n3. 在初级岗位中，大厂对数据分析能力的要求也没有降低，甚至与小厂的要求差距更大！\n为此，我们特别开发了本门课程，覆盖数据分析的必备硬技能和软技能，进行体系化学习，熟练掌握常用数据分析工具。\n课程导师 - 张宇晖：\n美国国家强磁场实验室理论物理博士。曾就职于文思海辉（美国）、微软（美国）、滴滴（中国），历任数据科学家、高级数据与应用科学家、策略运营专家。其中，在微软期间，他担任一个500人团队的核心数据科学家。而在滴滴快捷出行事业群工作期间，他负责或参与各种数据驱动及标签项目的车主运营端对接，将负责的司机衰退项目推广到全国一半体量的城市，并且与数据团队合作进行了统一的数据驱动运营。\n这门课程适合谁：成为高薪数据分析人才\n1.0-2年数据分析从业者，基本功不扎实，对业务不熟悉希望通过学习获得系统的知识体系，提升业务分析能力；\n2.产品/运营/会计等，想通过学习数据分析完成能力提升获取高薪；\n3.0-5年运营、营销、产品人，不了解如何利用数据工具，高效获取、呈现数据的学员。",
      "target_audience": [
        "希望了解如何利用数据工具，高效获取、呈现数据的0-5年运营、营销、产品人员",
        "需要补充基础数据分析能力的产品/运营/会计等职能",
        "需要夯实基本功，对业务不熟悉希望通过学习获得系统的知识体系，提升业务分析能力的0-2年数据分析人员"
      ]
    },
    {
      "title": "Dados de saúde pública com Python",
      "url": "https://www.udemy.com/course/dados-de-saude-publica-com-python/",
      "bio": "Aprenda a extrair dados de saúde no Brasil diretamente do banco de dados oficial do governo e visualizá-los em Python!",
      "objectives": [
        "Baixar bancos de dados públicos da saúde no Brasil",
        "Converter arquivos do formato DATASUS para CSV",
        "Limpar a base de dados",
        "exportar para CSV a nova base"
      ],
      "course_content": {
        "Introdução": [
          "Aula Introdutória",
          "Dados abertos da saúde no Brasil",
          "O que é o SINAN?",
          "Qual plataforma utilizaremos?",
          "Preparação do ambiente"
        ],
        "Buscando os dados": [
          "Extraindo a base de dados do curso",
          "Transformando DBC em CSV no TabWin"
        ],
        "Limpeza do banco de dados no Google Colab": [
          "Transformando o CSV em Dataframe",
          "Subindo o banco de dados no Google Colab",
          "Quais colunas vamos manter?",
          "Decodificação dos dados - Sim ou Não",
          "Decodificação dos dados - Formato de Data",
          "Decodificação dos dados - Colunas únicas",
          "Decodificação dos dados - Idade",
          "Decodificação dos dados - Municípios e IBGE6",
          "Decodificação dos dados - Ocupação e UF",
          "Decodificação dos dados - Renomeando colunas",
          "Exportando a nova tabela"
        ]
      },
      "requirements": [
        "Não será necessária nenhuma experiência prévia em Python. O curso abordará com detalhes como fazer cada etapa",
        "Os programas utilizados não necessitam de instalação, um deles é diretamente na nuvem e o outro é um executável bastante leve"
      ],
      "description": "Neste curso você aprenderá a buscar dados oficiais da saúde no Brasil, acessando o site do DataSUS, os quais estão em um formato próprio do governo. Utilizaremos um programa chamado TabWin para transformá-los em CSV, o qual é muito mais fácil de utilizar. Após, iremos escrever um script em Python no Google Colab, o qual deixará o banco com uma cara amigável e fácil de analisar.\n\n\nNão é necessário que seja instalado nenhum software no computador antecipadamente.\n\n\nO banco de dados utilizado é o de Acidentes com Animais Peçonhentos no Brasil do ano de 2017, o qual é criado a partir do Sistema de Informação de Agravos de Notificação (SINAN). Este banco possui quase 100 colunas, contendo informações muito valiosas para o entendimento da saúde no Brasil, como qual o tipo de animal causador do acidente, qual a data do acidente, qual a idade e sexo do paciente, ocupação, município de ocorrência, além de outros dados. São mais de 200 mil casos.\n\n\nTudo que é ensinado no curso pode ser aplicado a qualquer banco extraído do SINAN, alterando alguns valores, o que permite com que você possa explorar muitos dados sobre a saúde no Brasil, como Intoxicações Exógenas, Dengue, Zika, Chikungunya, Febre Amarela, Febre Maculosa, Febre do Nilo, Hepatites, entre muitas outras.\n\n\nEspero que goste!",
      "target_audience": [
        "Iniciantes em Python que desejam especializar seus conhecimentos em dados da saúde Brasileira",
        "Pessoas interessadas em transformar os dados da saúde do Brasil em informações",
        "Jornalistas de dados que buscam informações sobre o Brasil"
      ]
    },
    {
      "title": "Pandas Descomplicado: Um Guia Prático para Iniciantes",
      "url": "https://www.udemy.com/course/pandas-descomplicado-um-guia-pratico-para-iniciantes/",
      "bio": "Python para Data Science: Desenvolva habilidades essenciais com Pandas, com exercícios práticos resolvidos passo a passo",
      "objectives": [
        "Criar, fatiar e manipular Series no Pandas, explorando desde operações básicas até o agrupamento",
        "Desenvolver habilidades avançadas na criação e manipulação de Dataframes, dominando técnicas de acesso e operações complexas",
        "Representar dados visualmente, criando gráficos envolventes e explorando técnicas essenciais de formatação",
        "Colocar seu conhecimento à prova com desafios práticos, fortalecendo suas habilidades em manipulação e análise de dados",
        "Explorar o poder do agrupamento em dados numéricos e categóricos, além de realizar operações avançadas para análises mais sofisticadas"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre Análise de Dados",
          "Recursos para download"
        ],
        "Series": [
          "Instalação do pandas",
          "Criação de series",
          "Fatiamento - slicing",
          "Cópia, conversão e concatenação",
          "Acesso com loc",
          "Acesso com iloc",
          "Ordenação",
          "Contagem",
          "Filtragem",
          "Operações matemáticas",
          "Operações com strings",
          "Agrupamento numérico",
          "Agrupamento categórico",
          "Valores faltantes",
          "Funções",
          "EXERCÍCIO",
          "Solução"
        ],
        "Dataframe": [
          "Criação de dataframes",
          "Exploração do dataframe",
          "Acesso com loc e iloc",
          "Apagar linhas e colunas",
          "Linhas duplicadas",
          "Valores faltantes",
          "Contagem",
          "Ordenação",
          "Filtragem",
          "Renomear e ordenar",
          "Criação de colunas",
          "Atributos categóricos",
          "Agregação",
          "Agrupamento",
          "Agrupamento com agregação",
          "Agrupamento com transform",
          "Tabelas pivot",
          "Concatenação e junção",
          "Conversão para datas",
          "Índices com datas",
          "Importação e exportação",
          "EXERCÍCIO",
          "Solução"
        ],
        "Visualização de dados": [
          "Gráfico de linha",
          "Formatação",
          "Sub-gráficos",
          "Gráfico de barra e pizza",
          "Gráfico de dispersão",
          "Histograma",
          "EXERCÍCIO",
          "Solução"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação",
        "Programação básica em Python"
      ],
      "description": "Bem-vindo ao curso \"Pandas Descomplicado\", uma jornada abrangente projetada para iniciantes interessados em explorar e dominar a biblioteca Pandas no contexto da análise de dados. Este curso foi cuidadosamente estruturado para proporcionar uma compreensão sólida dos fundamentos e técnicas avançadas do Pandas, capacitando os participantes a manipular dados com confiança e eficiência. Confira abaixo os módulos e tópicos principais\nSeção 1: Series\nIniciamos com a instalação do Pandas e a criação de Series, a estrutura unidimensional essencial para armazenar dados. Ao longo do módulo, exploramos conceitos fundamentais como fatiamento, cópia, acesso com iloc e loc, ordenação, filtragem, operações matemáticas e manipulações com strings. Abordamos também tópicos avançados, incluindo agrupamento numérico e categórico, tratamento de valores faltantes, funções e desafios práticos.\nSeção 2: Dataframe\nDando continuidade, mergulhamos na criação e exploração de Dataframes, estruturas vitais para análise de conjuntos de dados mais complexos. Este módulo abrange tópicos como acesso com iloc e loc, manipulação de linhas e colunas, tratamento de dados duplicados e valores faltantes, ordenação, filtragem avançada, criação e manipulação de colunas, agregação, tabelas pivot, concatenação, junção e técnicas de importação/exportação. Incluímos desafios práticos para reforçar a aprendizagem.\nSeção 3: Visualização de Dados\nNo último módulo, exploramos a visualização de dados com o Pandas. Cobrimos a criação de gráficos de linha, barras, pizza, dispersão e histogramas, além de técnicas avançadas de formatação e subgráficos. O módulo inclui um desafio prático para aplicar as habilidades recém-adquiridas na representação visual de dados.\nAo concluir este curso, os participantes estarão equipados com as habilidades práticas necessárias para utilizar o Pandas de forma eficaz na análise de dados. Prepare-se para uma experiência de aprendizado envolvente e prática, capacitando você a enfrentar desafios do mundo real na manipulação e interpretação de conjuntos de dados.",
      "target_audience": [
        "Pessoas que estão dando os primeiros passos na programação Python e desejam entrar no mundo da análise de dados de forma prática",
        "Estudantes ou profissionais em início de carreira na área de ciência de dados que buscam uma compreensão sólida das manipulações de dados com Pandas",
        "Profissionais que já possuem conhecimentos básicos em Python e desejam aprimorar suas habilidades em manipulação e análise de dados utilizando o Pandas",
        "Alunos que buscam uma introdução prática à manipulação de dados para complementar seus estudos em estatística ou disciplinas relacionadas",
        "Desenvolvedores que desejam expandir suas habilidades para incluir análise de dados, utilizando o Pandas como uma ferramenta essencial em seus projetos"
      ]
    },
    {
      "title": "Séries Temporais com Redes Neurais Artificiais e Linguagem R",
      "url": "https://www.udemy.com/course/series-temporais-com-redes-neurais-artificiais-e-linguagem-r/",
      "bio": "Aplicado em Ciência de Dados, Estatística, Economia, Engenharia, Machine Learning, Administração, Bioestatística...",
      "objectives": [
        "Conceitos de Séries Temporais (Estacionaridade, Autocorrelação, Passeio Aleatório, Ruído Branco, Média Móvel, Covariância, Processo Estocástico...0",
        "Conceitos de Redes Neurais Artificiais (Neurônio Artificial, Perceptron, Aprendizagem, Descida do Gradiente, Algoritmo Backpropagation, Funções de Ativação...)",
        "Redes Neurais Artificiais para Séries Temporais",
        "Rede Neural FF para Séries Temporais",
        "Rede Neural MLP para Séries Temporais",
        "Rede Neural RBF para Séries Temporais",
        "Rede Neural Recorrente para Séries Temporais",
        "Rede Neural ELM para Séries Temporais",
        "Fundamentos da Linguagem R",
        "Projeto Real com Séries Temporais",
        "Tratamento dos Dados",
        "Análise da Série Temporal"
      ],
      "course_content": {
        "Introdução": [
          "Boas vindas e apresentação do instrutor",
          "Apresentação do curso e da plataforma de estudos"
        ],
        "Fundamentos da linguagem R": [
          "Conhecendo a Linguagem R",
          "Instalação do R e RStudio",
          "Conhecendo o RStudio",
          "Apresentação do RStudioCloud",
          "Primeiros passos no RStudio",
          "Operadores Matemáticos",
          "Variáveis",
          "Vetores",
          "Fatores",
          "Matriz",
          "Cálculo com matrizes",
          "Data Frame e Listas",
          "Instalação e carregamento de Pacotes",
          "Importação de arquivos",
          "Estrutura condicional",
          "Estrutura de repetição",
          "Criação de Funções"
        ],
        "Conceitos de Séries Temporais": [
          "Introdução às Séries Temporais",
          "Primeiros passos de séries temporais no R",
          "Covariância",
          "Processo estocástico",
          "Estacionaridade",
          "Testes de Estacionaridade no R",
          "Passeio aleatório",
          "Passeio aleatório no R",
          "Autocorrelação e Ruído Branco",
          "Autocorrelação no R",
          "Decomposição e filtragem",
          "Decomposição no R",
          "Média móvel",
          "Média móvel no R",
          "Métricas de desempenho"
        ],
        "Redes Neurais Artificiais – Conceitos Gerais": [
          "Neurônio Biológico e neurônio artificial.",
          "Evolução das redes neurais.",
          "Perceptron",
          "Funções de ativação",
          "Aprendizagem nas redes neurais",
          "Aprendizagem com descida do gradiente",
          "Cálculos dos erros em redes neurais",
          "Topologias das redes neurais artificiais",
          "Algoritmo Backpropagation",
          "Definição dos parâmetros"
        ],
        "Séries Temporais com Redes Neurais Artificiais": [
          "Conceitos de Séries Temporais com Redes Neurais Artificiais",
          "Séries Temporais com Redes Neurais Feed Forward – parte 1",
          "Séries Temporais com Redes Neurais Feed Forward – parte 2",
          "Séries Temporais com Redes Neurais Feed Forward – parte 3",
          "Séries Temporais com Redes Neurais Feed Forward – parte 4",
          "Séries Temporais com Redes Neurais MLP (Deep Feed Forward) – parte 1",
          "Séries Temporais com Redes Neurais MLP (Deep Feed Forward) – parte 2",
          "DESAFIO 1",
          "RESOLUÇÃO DESAFIO 1 – parte 1",
          "RESOLUÇÃO DESAFIO 1 – parte 2",
          "Redes Neurais com Função de Ativação de Base Radial (RBF)",
          "Séries Temporais com Redes Neurais GRNN / RBF – parte 1",
          "Séries Temporais com Redes Neurais GRNN / RBF – parte 2",
          "DESAFIO 2: Rede RBF",
          "RESOLUÇÃO DESAFIO 2: Rede RBF",
          "Redes Neurais Recorrentes",
          "Séries Temporais com Redes Neurais Recorrentes – parte 1",
          "Séries Temporais com Redes Neurais Recorrentes – parte 2",
          "Redes Neurais com Máquinas de Aprendizagem Extremo (ELM)",
          "Séries Temporais com Redes de Máquinas de Aprendizagem Extremo (ELM) – parte 1",
          "Séries Temporais com Redes de Máquinas de Aprendizagem Extremo (ELM) – parte 2"
        ],
        "Projeto Real de Séries Temporais com Redes Neurais Artificiais": [
          "Extração e preparação dos dados",
          "Tratamento dos dados",
          "Criação da Série Temporal",
          "Análise da Série Temporal",
          "Projeto: Rede FF",
          "Projeto: Rede MLP",
          "Projeto: Rede RBF",
          "Projeto: Rede ELM",
          "Projeto: Rede Recorrente"
        ],
        "Finalização do curso": [
          "Encerramento"
        ],
        "Referências e links úteis": [
          "Referências e links úteis (gratuitos)"
        ]
      },
      "requirements": [
        "Não há pré-requisito"
      ],
      "description": "Com este curso você irá dominar as principais técnicas de análises de séries temporais utilizando cinco algoritmos de Redes Neurais Artificiais, tanto teoricamente como na prática, em linguagem R, uma das ferramentas mais poderosa e popular em análises estatísticas.\nO diferencial desse curso é que iremos obter o embasamento teórico das séries temporais e Redes Neurais Artificiais, faremos na prática todos os tratamentos e testes estatísticos necessários e aplicaremos os conhecimentos em dados reais. Não é um curso onde somente serão apresentados os comandos utilizados, tudo será explicado detalhadamente.\nPara atender a todos os alunos, sem importar a área e o nível de conhecimento, as duas primeiras seções são referentes aos fundamentos da Linguagem R e fundamentos de Estatística.\nO curso é apresentado no sistema operacional Windows, mas usuários do Linux e Mac acompanham tranquilamente.\nTodas as aulas são explicadas passo a passo, de forma clara e objetiva. A análise de série temporal, além de ser um estudo sensacional, está cada dia mais presente no mercado de trabalho e em pesquisas científicas. Diversas áreas que trabalham com análise de dados, necessitam de análises de séries temporais com o objetivo de previsão e entendimento dos dados, e aplicar corretamente as séries temporais é fundamental para obter as melhores previsões.\nTenho certeza que a sua visão sobre séries temporais irá mudar após esse curso.",
      "target_audience": [
        "Estatístico",
        "Economista",
        "Cientista de Dados",
        "Administrador",
        "Matemático",
        "Pesquisador",
        "Biólogo",
        "Geógrafo",
        "Bioestatístico",
        "Físico",
        "Machine Learning",
        "Oceanógrafo",
        "Meteorologista",
        "Astrônomo"
      ]
    },
    {
      "title": "Artificial Intelligence Masterclass Bahasa",
      "url": "https://www.udemy.com/course/artificial-intelligence-masterclass-bahasa/",
      "bio": "Masuki era baru Model Hybrid AI yang dioptimalkan oleh Deep NeuroEvolution, dengan toolkit lengkap model ML, DL & AI",
      "objectives": [
        "Cara Membangun AI",
        "Cara Membangun Sistem Cerdas Hibrid",
        "Fully-Connected Neural Networks",
        "Convolutional Neural Networks",
        "Recurrent Neural Networks",
        "Long Short-Term Memory (LSTM) Neural Networks",
        "AutoEncoder",
        "Variational AutoEncoders",
        "Mixed Density Networks",
        "Deep Reinforcement Learning",
        "Policy Gradient",
        "Genetic Algorithms",
        "Evolution Strategies",
        "Covariance Matrix Adaptation Evolution Strategy (CMA-ES)",
        "Controllers",
        "Meta-Learning",
        "Deep NeuroEvolution"
      ],
      "course_content": {
        "Pendahuluan": [
          "Selamat Datang!",
          "Pendahuluan + Struktur Kursus + Demo",
          "Tiga Sumber Daya Terbaik Anda",
          "Unduh Sumber Daya di sini",
          "Temui instruktur Anda!"
        ],
        "Langkah 1 - Artificial Neural Network": [
          "Selamat Datang di Langkah 1 - Artificial Neural Network",
          "Plan of Attack",
          "Neuron",
          "Fungsi Aktivasi",
          "Bagaimana cara kerja Neural Network?",
          "Bagaimana Neural Network belajar?",
          "Gradient Descent",
          "Stochastic Gradient Descent",
          "Backpropagation"
        ],
        "Langkah 2 - Convolutional Neural Network": [
          "Selamat Datang di Langkah 2 - Convolutional Neural Network",
          "Plan of Attack",
          "Apa Itu Convolutional Neural Network?",
          "Langkah 1 - Operasi Konvolusi",
          "Langkah 1 Lanjutan - Lapisan ReLU",
          "Langkah 2 - Pooling",
          "Langkah 3 - Flattening",
          "Langkah 4 - Full Connection",
          "Kesimpulan",
          "Softmax & Cross-Entropy"
        ],
        "Langkah 3 - AutoEncoder": [
          "Selamat Datang di Langkah 3 - AutoEncoder",
          "Plan of Attack",
          "Apa Itu AutoEncoder?",
          "Catatan tentang Bias",
          "Melatih AutoEncoder",
          "Overcomplete Hidden Layers",
          "Sparse AutoEncoder",
          "Denoising AutoEncoder",
          "Contractive AutoEncoder",
          "Stacked AutoEncoder",
          "Deep AutoEncoder"
        ],
        "Langkah 4 - Variational AutoEncoder": [
          "Selamat Datang di Langkah 4 - Variational AutoEncoder",
          "Pengantar VAE",
          "Variational AutoEncoders",
          "Trik Reparameterisasi"
        ],
        "Langkah 5 - Implementasi CNN-VAE": [
          "Selamat Datang di Langkah 5 - Mengimplementasi CNN-VAE",
          "Pengantar Langkah 5",
          "Inisialisasi semua parameter dan variabel kelas CNN-VAE",
          "Membangun bagian Encoder dari VAE",
          "Membangun bagian \"V\" dari VAE",
          "Membangun bagian Decoder dari VAE",
          "Mengimplementasi operasi pelatihan model",
          "Kode Lengkap",
          "Implementasi dengan Keras"
        ],
        "Langkah 6 - Recurrent Neural Network": [
          "Selamat Datang di Langkah 6 - Recurrent Neural Network",
          "Plan of Attack",
          "Apa Itu Recurrent Neural Network?",
          "Permasalahan Vanishing Gradient",
          "LSTM",
          "Intuisi Praktis LSTM",
          "Variasi LSTM"
        ],
        "Langkah 7 - Mixture Density Network": [
          "Selamat Datang di Langkah 7 - Mixture Density Network",
          "Perkenalan MDN-RNN",
          "Mixture Density Networks",
          "Visualisasi VAE + MDN-RNN"
        ],
        "Langkah 8 - Implementasi MDN-RNN": [
          "Selamat Datang di Langkah 8 - Implementasi MDN-RNN",
          "Inisialisasi semua parameter dan variabel kelas MDN-RNN",
          "Membangun RNN - Mengumpulkan parameter",
          "Membangun RNN - Membuat sel LSTM dengan Dropout",
          "Membangun RNN - Menyiapkan Input, Target, dan Output dari RNN",
          "Membangun RNN - Mendapatkan Output Deterministik dari RNN",
          "Membangun MDN - Mendapatkan Input, Hidden Layer dan Output dari MDN",
          "Membangun MDN - Mendapatkan parameter MDN",
          "Mengimplementasi operasi pelatihan model (Bagian 1)",
          "Mengimplementasi operasi pelatihan model (Bagian 2)",
          "Kode Lengkap",
          "Implementasi dengan Keras"
        ],
        "Langkah 9 - Reinforcement Learning": [
          "Selamat Datang di Langkah 9 - Reinforcement Learning",
          "Apa Itu Reinforcement Learning?",
          "Implementasi Pseudo Reinforcement Learning untuk Model Dunia Penuh",
          "Kode Lengkap"
        ]
      },
      "requirements": [
        "Matematika tingkat SMA",
        "Sedikit pengalaman coding"
      ],
      "description": "Apakah Anda tertarik pada Artifical Intelligence? Ingin belajar membuat model AI yang sangat powerful dan bahkan bermain melawannya? Terdengar menarik bukan?\nJika ya, kursus AI Masterclass adalah pilihan yang tepat untuk Anda. Melalui kursus ini, anda akan mendapatkan segala ilmu yang anda butuhkan mengenai Model Hybrid AI dan seluruh komponen-komponen pembangunnya. Anda akan mendapatkan panduan langkah demi langkah dan roadmap lengkap yang akan membantu Anda membangun Model Hybrid AI anda sendiri dari awal.\nDalam kursus ini, kami akan mengajari Anda cara mengembangkan model AI yang paling kuat berdasarkan Sistem Cerdas Hybrid yang paling kuat. Sejauh ini model ini terbukti sebagai AI terbaik yang pernah dibuat mengalahkan pendahulunya di semua kompetisi AI dengan skor yang sangat tinggi.\nModel Hybrid ini tepatnya dinamakan dengan Model Dunia Penuh (Full World Model), dan menggabungkan semua model canggih dari berbagai cabang AI, termasuk Deep Learning, Deep Reinforcement Learning, Policy Gradient, dan bahkan, Deep NeuroEvolution.\nDengan mendaftar di kursus ini, Anda akan memiliki kesempatan untuk mempelajari cara menggabungkan model di bawah ini untuk mencapai sistem AI dengan kinerja terbaik:\nFully-Connected Neural Networks\nConvolutional Neural Networks\nRecurrent Neural Networks\nLong Short-Term Memory (LSTM) Neural Networks\nVariational AutoEncoders\nMixed Density Networks\nGenetic Algorithms\nEvolution Strategies\nCovariance Matrix Adaptation Evolution Strategy (CMA-ES)\nParameter-Exploring Policy Gradients\nDitambah banyak lainnya\n\nOleh karena itu, melalui kursus ini Anda tidak hanya mendapatkan pembelajaran sederhana terkait AI tetapi anda akan mendapatkan berbagai modul AI yang sangat kuat dalam satu paket toolkit. Anda dapat mengunduh toolkit ini dan menggunakannya untuk membangun sistem cerdas hibrid. Model Hybrid telah menjadi pemenang dalam berbagai perlombaan AI, jadi Anda sudah harus mempelajari cara menanganinya.\nSelain itu, kami juga akan memberikan Anda seluruh codebase yang ditulis menggunakan dua framework AI yang sangat populer: TensorFlow dan Keras. Jadi, kapan pun Anda ingin membangun AI untuk aplikasi tertentu, Anda dapat mengambil model yang Anda perlukan di toolkit, dan menggunakannya kembali untuk berbagai proyek!\nTunggu apa lagi? Segera daftarkan diri anda dalam kursus ini untuk memulai perjalanan dalam menguasai masa depan AI - Model Hybrid AI.",
      "target_audience": [
        "Siapa pun yang tertarik dengan Artificial Intelligence, Deep Learning, or Machine Learning"
      ]
    },
    {
      "title": "【한글자막】 Apache Spark 와 Scala로 빅 데이터 다루기",
      "url": "https://www.udemy.com/course/best-scala-apache-spark/",
      "bio": "【전세계 81만 수강 TOP강사!】 Desktop 또는 Scala가 포함된 Hadoop에서 대규모 데이터 세트를 분석하는 20개 이상의 실습 예제가 포함된 Apache Spark 튜토리얼!",
      "objectives": [
        "빅데이터 분석 문제를 Apache Spark 스크립트로 프레임화",
        "Scala 프로그래밍 언어를 사용하여 분산 코드 개발",
        "파티셔닝, 캐싱 및 기타 기술을 통해 Spark 작업 최적화",
        "Hadoop 클러스터에서 Spark 스크립트 구축, 디플로이 및 실행",
        "Spark Streaming으로 연속적인 데이터 스트림 처리",
        "SparkSQL, DataSets 및 DataFrames를 사용하여 구조화된 데이터 변환",
        "GraphX를 사용하여 그래프 구조 순회 및 분석",
        "Spark의 머신 러닝으로 방대한 데이터 세트 분석"
      ],
      "course_content": {
        "시작하기": [
          "Udemy 101: 이 강의를 최대한 활용하기",
          "ml-100k 데이터세트에 대한 대체 다운로드 링크",
          "경고: 다음 강의에서 JAVA 16을 설치하지 마세요",
          "강의 자료 IntelliJ 및 Scala 소개 및 설치",
          "Apache Spark 소개",
          "Spark 기본",
          "Spark 3의 새로운 기능"
        ],
        "스칼라 단기집중 강의 [선택사항]": [
          "[활동] 스칼라 기초",
          "[연습] 스칼라의 흐름 제어",
          "[연습] 스칼라에서의 함수",
          "[연습] 스칼라의 데이터 구조"
        ],
        "RDD(Resilient Distributed Datasets) 사용하기": [
          "RDD(The Resilient Distributed Dataset)",
          "등급 히스토그램의 예시",
          "스파크 내부",
          "키/값 RDD 및 연령별 평균 친구 예시",
          "[활동] 평균 친구 연령별 실행 예시",
          "위치별 RDD 및 최소 온도 필터링 예시",
          "[활동] 최저 온도 예제 실행 및 최대 온도로 수정",
          "[활동] Flatmap()을 이용한 단어 발생 횟수 세기",
          "[활동] 정규 표현식으로 단어 수 스크립트 개선하기",
          "[활동] 단어 개수 결과 정렬하기",
          "[연습] 고객이 지출한 총 금액 찾기",
          "[연습] 결과를 확인하고 총 지출 금액별로 정렬",
          "내 결과 및 구현 확인"
        ],
        "SparkSQL, DataFrames 및 DataSets": [
          "SparkSQL 소개",
          "[활동] SparkSQL 사용하기",
          "[활동] DataSet 사용하기",
          "[연습] DataSet을 사용하여 \"연령별 친구\" 예제 구현",
          "[정답 해설] 데이터 세트가 있는 연령별 친구 예제",
          "[활동] Dataset을 이용한 단어 개수 예제",
          "[활동] 데이터 세트로 최저 온도 예제 다시 보기",
          "[연습] Datasets로 \"Total Spent by Customer\" 문제 구현",
          "[정답 해설] 데이터 세트에 대한 고객의 총 지출액"
        ],
        "스파크 프로그램의 고급 사례": [
          "[활동] Hive를 사용하여 가장 인기 있는 영화 찾기",
          "[활동] 방송 변수를 사용하여 영화 이름 표시",
          "[활동] 소셜 그래프에서 가장 인기 있는 슈퍼히어로 찾기",
          "[연습] 가장 잘 알려지지 않은 슈퍼히어로 찾기",
          "[정답 해설] 가장 잘 알려지지 않은 슈퍼히어로 찾기",
          "슈퍼히어로의 분리도: 너비 우선 검색 소개",
          "슈퍼히어로의 분리도: 누산기 및 Spark에서 BFS 구현",
          "[활동] 슈퍼히어로의 분리도: 코드를 복습하고 실행해 보세요!",
          "Spark 캐시() 및 지속()의 항목 기반 협업 필터링",
          "[활동] Spark의 클러스터 관리자를 사용하여 유사한 영화 스크립트 실행",
          "[연습] 유사 영화의 품질 향상"
        ],
        "클러스터에서의 스파크 실행": [
          "[활동] spark-submit을 사용하여 Spark 드라이버 스크립트 실행",
          "[활동] SBT로 드라이버 스크립트 패키징",
          "[연습] SBT로 스크립트 패키징 및 spark-submit으로 로컬 실행",
          "[정답 해설] SBT 및 spark-submit 사용",
          "Amazon Elastic MapReduce 소개",
          "EMR의 백만개 평점으로부터 유사한 영화 만들기",
          "파티셔닝",
          "클러스터에서 실행하기 위한 모범 사례",
          "종속성 문제 해결 및 관리"
        ],
        "Spark ML을 통한 머신 러닝": [
          "MLLib 소개",
          "[활동] MLLib를 사용하여 추천 영화 제작하기",
          "MLLib를 사용한 선형 회귀",
          "[활동] Spark로 선형 회귀 실행하기",
          "[연습] Spark의 의사결정나무로 부동산 가치 예측하기",
          "[정답 해설] Spark의 의사결정트리로 부동산 예측"
        ],
        "Spark Straming 소개": [
          "Spark Streaming 소개",
          "[활동] 트위터 인기 해시태그 실시간 모니터링",
          "구조화된 스트리밍",
          "[활동] 실시간 로그 분석을 위한 Structured Streaming 활용하기",
          "[연습] 구조적 스트리밍을 사용한 창 작업",
          "[정답 해설] 30초 창의 상위 URL"
        ],
        "GraphX 소개": [
          "GraphX Pregel 및 Pregel을 사용한 너비 우선 탐색",
          "Spark GraphX와 함께 Pregel API 사용",
          "[활동] GraphX를 사용한 슈퍼히어로의 분리도"
        ],
        "여러분이 해냈습니다! 향후 계획": [
          "더 알아보기 및 커리어 팁",
          "보너스 강의: 더 많은 강의를 탐색해보세요!",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "일부 사전 프로그래밍 또는 스크립팅 경험이 필요합니다. Scala의 단기 집중 강의가 포함되어 있지만 이를 선택하려면 프로그래밍의 기초를 알아야 합니다.",
        "데스크탑 PC와 인터넷 연결이 필요합니다. 이 강의는 Windows를 염두에 두고 만들어졌지만 MacOS 또는 Linux에 익숙한 사용자 또한 동일한 도구를 사용할 수 있습니다.",
        "이 강의에 필요한 소프트웨어는 무료로 제공되며 다운로드 및 설치 과정 또한 안내해 드리겠습니다."
      ],
      "description": "Spark와 Scala를 함께 배우는 강의!\n20개 이상의 실제 예시 포함!\nSpark의 기초부터 시작하여 다양한 응용까지 All in one!\n스칼라 단기 집중 강의 포함!\nAmazon 및 IMDb의 전 엔지니어이자 선임 관리자로부터 배우는 실습 위주 수업!\n*프로그래밍을 처음 접한다면 수업을 진행하기 어려울 수 있습니다. 프로그래밍 기초 강의를 먼저 수강하시는 것을 추천합니다*\n\n\nApache Spark 와 Scala로 빅 데이터 다루기 강의를 선택해야 하는 이유\n데이터 분석 문제를 Spark로 프레이밍 하는 기술을 배우고, 20개 이상의 실습 예제를 통해서 완벽히 마스터 할 수 있습니다.\n수강 후에는 몇 분만에 클라우드에서 GB 크기의 정보를 분석하는 코드를 실행할 수 있게 됩니다.\nSpark는 Scala 프로그래밍 언어를 사용할 때 가장 잘 작동하며, 이 강의는 스칼라 단기 집중 강의를 포함하므로 빠르게 배울 수 있습니다.\n(만약 Python에 더 익숙한 사용자라면 다른 강의를 추천 드립니다)\n\n\n이 강의에는 재미있는 실습이 포함 되어 있습니다. Spark를 사용하여 영화 등급 데이터와 책의 텍스트를 분석하는 몇 가지 간단한 예로 시작해서 기본기를 배운 후에는, 더 복잡하고 흥미로운 작업을 진행합니다. 백만개의 영화 등급을 사용하여 서로 유사한 영화를 찾을 것이고, 이 과정에서 여러분들이 좋아할 만한 새로운 영화를 발견할 수도 있을 것입니다! 여러분은 슈퍼히어로의 사회적 그래프를 분석하고 가장 \"인기 있는\" 슈퍼히어로가 누구인지 배우고 슈퍼히어로 사이의 \"Degree of Separation\"를 찾는 시스템을 개발할 것입니다. 모든 마블 슈퍼히어로들은 스파이더맨과 얼마나 연결되어 있을까요?\n이 강의를 통해 그 답을 찾을 수 있습니다.\n또한, 이 강의는 실습 위주의 강의입니다. Amazon의 Elastic MapReduce 서비스를 사용하여 자체 시스템과 클라우드 모두에서 실제 코드를 함께 작성, 분석 및 실행할 때 강사와 함께 대부분의 시간을 보내게 됩니다. 7시간 분량의 영상 내용이 포함되어 있으며, 20개 이상의 실제 예시는 복잡성이 증가함에 따라 스스로 구축하고 실행하고 연구할 수 있습니다.\n\n\n\n\nApache Spark 와 Scala로 빅 데이터 다루기 세부 커리큘럼\n빅데이터 분석 문제를 Apache Spark 스크립트로 프레임화\nScala 프로그래밍 언어를 사용하여 분산 코드 개발\n파티셔닝, 캐싱 및 기타 기술을 통해 Spark 작업 최적화\nHadoop 클러스터에서 Spark 스크립트 구축, 디플로이 및 실행\nSpark Streaming으로 연속적인 데이터 스트림 처리\nSparkSQL, DataSets 및 DataFrames를 사용하여 구조화된 데이터 변환\nGraphX를 사용하여 그래프 구조 순회 및 분석\nSpark의 머신 러닝으로 방대한 데이터 세트 분석\n\n\nAmazon 및 IMDb의 전 엔지니어이자 선임 관리자 Frank Kane 강사의 한마디!\n완전히 업데이트 된 새로운 강의로 출시되었습니다!\nSpark 3, IntelliJ, 구조적 스트리밍 및 DataSet API에 대한 더 강력한 초점을 위해 완전히 업데이트되어 다시 녹음되었습니다.\nSpark SQL, Spark Streaming과 같은 최신 Spark 기술과 Gradient Boosted Trees와 같은 고급 모델도 다룰 것입니다.\n\"빅 데이터\" 분석은 아주 인기있고 매우 가치 있는 기술입니다. 이 강의는 빅 데이터에서 가장 인기 있는 기술을 알려줍니다. 바로 Apache Spark 입니다. 아마존, 이베이, NASA JPL 및 Yahoo를 포함한 고용주는 모두 Spark를 사용하여 내결함성 Hadoop 클러스터 전반에 걸쳐 방대한 데이터 세트에서 의미를 빠르게 추출합니다. 집에서 자신의 Windows 시스템을 사용하여 동일한 기술을 배우게 될 텐데, 생각하는 것보다 쉬울 것이며 Amazon 및 IMDb의 전 엔지니어이자 수석 관리자에게 배우게 될 것입니다.\n\n\n여러분의 일정에 따라 여러분의 속도로 진행하세요. 이 강의는 Spark SQL, Spark Streaming, GraphX를 비롯한 다른 Spark 기반 기술에 대한 개요로 마무리됩니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n지금 등록하고 이 강의를 즐겨보세요!\n-Frank\n\n\nP.S. 제 강의에 대한 한 수강생의 리뷰 하나를 소개해 드립니다:\n\"나는 Frank의 \"Apache Spark 2 with Scala - Hands On with Big Data!\" 강의를 통해 처음으로 Spark를 공부했습니다. Scala에 대한 지식과 가장 중요한 Spark 응용 프로그램의 실제 사례를 얻는 것은 저에게 훌륭한 출발점이 되었습니다. 모든 관련 Spark 핵심 개념, RDD, 데이터 프레임 및 데이터 세트, Spark Streaming, AWS EMR에 대한 이해를 주었습니다. 완강 후 몇 개월 만에, 저는 이 강의에서 얻은 지식을 사용하여 현재 회사에서 주로 Spark 응용 프로그램 작업을 제안했습니다. 그 이후로 나는 계속해서 Spark로 작업했습니다. Frank는 개념을 잘 단순화하고 강의 방식은 따라하고 계속하기 쉽기 때문에 나는 Frank 강의를 강력히 추천합니다! \" - 조이 파허티",
      "target_audience": [
        "클러스터에서 빅 데이터 처리의 세계로 자신의 기술을 확장하려는 소프트웨어 엔지니어",
        "Scala로 Spark를 다루고 싶은 프로그래머나 모든 분"
      ]
    },
    {
      "title": "ChatGPT 고급 활용법 - 남들보다 100배 더 잘 쓰는 프롬프트 엔지니어링 비법 클래스",
      "url": "https://www.udemy.com/course/maso-ds-gpt-onc78/",
      "bio": "비 IT 전공자도 쉽게 배울 수 있는 프롬프트 엔지니어링! Instruction, Context, Fine-Tuning, Zeroshot/Fewshot learning, 하이퍼 파라미터 미세 조정까지!",
      "objectives": [
        "ChatGPT를 비롯한 생성 AI, 언어 모델 및 파라미터 등 필수 개념",
        "ChatGPT의 잠재력을 극대화하고 콘텐츠 생성 및 커뮤니케이션을 더욱 효율적이고 효과적으로 만드는 방법",
        "원하는 비즈니스 환경에서 chatGPT를 호출하여 편리하게, 효과적으로 작업하는 역량",
        "ChatGPT의 힘을 효과적으로 사용하기 위한 중요한 기술인 프롬프트 엔지니어링"
      ],
      "course_content": {
        "강의 소개": [
          "학습 내용 안내"
        ],
        "인공지능이 던진 문화충격": [
          "인공지능이 던진 문화충격"
        ],
        "생성 AI와 언어모델의 이해": [
          "식별형 AI와 생성형 AI는 어떻게 다른가",
          "언어 모델은 똑똑한 말 한스와 같다"
        ],
        "사람처럼 말하는 인공지능의 원리": [
          "인공신경망의 판단 방법과 파라미터(1)",
          "인공신경망의 판단 방법과 파라미터(2)"
        ],
        "챗GPT 훈련과 생성 AI 마켓의 이해": [
          "chatGPT의 3단계 공부법",
          "생성형 AI의 종류와 마켓 트렌드"
        ],
        "ChatGPT와 친해지기": [
          "chatGPT 처음 써봐요",
          "chatGPT로 아이디어와 콘텐츠 초안 만들기"
        ],
        "목적 있는 사용 - 정보와 마케팅에 활용": [
          "목적 있는 사용 – 정보 탐색과 요약",
          "목적 있는 사용 – 마케팅에 활용(1)",
          "목적 있는 사용 – 마케팅에 활용(2)"
        ],
        "목적 있는 사용 - 학습과 코딩": [
          "목적 있는 사용 – 효과적인 학습",
          "목적 있는 사용 – 프로그래밍 코딩"
        ],
        "챗GPT를 3배 더 업그레이드하는 플러그인(1)": [
          "GPT는 반드시 영어로 – 프롬프트 지니",
          "구글 검색엔진과 결합 – chatGPT for Google",
          "이메일 자동 답변 – ChatGPT Writer",
          "유튜브 동영상 한 방 요약 – Youtube summary with chatGPT",
          "모든 웹에서 chatGPT 사용하기 – Merlin"
        ],
        "챗GPT를 3배 더 업그레이드하는 플러그인(2)": [
          "한국어로 읽고 복사하기 – chatGPT Optimizer",
          "질문 이력 관리와 다운로드 – Superpower chatGPT",
          "잘 쓴 프롬프트를 내 것으로 – AIRPM for chatGPT",
          "빈 칸 채우기로 완성하는 프롬프트 – WebChatGPT 인터넷"
        ]
      },
      "requirements": [
        "실습 위주의 강의이기 때문에 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기를 함께 준비해주시면 좋습니다.",
        "또한 Windows OS 기반으로 실습이 진행되므로, Windows 환경에서의 강의 수강을 추천해드립니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n\n\n고물가, 금리인상, 주가하락... 암울한 시대 한줄기 빛 ChatGPT!\n직장 동료들과의 점심 시간, 수업 끝나고 동기들과 먹는 학식 자리, 친구들과의 단톡방과 SNS까지.\n온 세상에서 ChatGPT에 대한 이야기가 나오기까지는 단 두 달이면 충분했습니다.\n신기한 것들은 매일같이 나오고, 유튜브 덕분에 접근도 쉬워진 요즘 왜 유독 챗 GPT에 사람들은 열광할까요?\n물론 챗GPT가 매우 놀라운 성능을 보여주고 있기도 하지만,\nGPT가 세상에 변화를 가져올 거라 믿기 때문일지도 모릅니다.\n실제로 아주 많은 변화를 가져오고 있기도 합니다.\n마이크로소프트는 일찍부터 Chat GPT 개발사인 OpenAI에 투자해 일찌감치 Bing, MS Office와 Office 365에 GPT 연동 서비스를 개발했고,\n구글 Chrome과 워크스페이스에서도 연동 플러그인을 통해 ChatGPT를 만날 수 있습니다.\n심지어 카카오톡에서도 친구 지피티와 대화하고, 질문할 수 있습니다.\n이미 여러분이 사용해온 많은 업무 도구들에도 같은 변화가 일어나고 있습니다.\n단순히 복잡도를 늘리는 게 아닌, 훨씬 똑똑하고 효율적으로 사용할 수 있는 변화들입니다.\n본 과정은 챗 GPT를 단순히 신기하고 재밌는 물건이 아닌,\n실제로 여러분이 일상에서 하는 의사결정, 업무, 과제 등 모든 면에서\n놀라울 정도로 효율을 높여 주는 도구로 사용하는 방법을 안내해드리고자 제작되었습니다.\n챗 GPT의 등장 배경부터 기초 사용 방법,\n위에서 소개해 드린 여러 가지 도구와의 연동 방법과 질문에 목적에 부합하는 대답을 얻을 수 있는 전문적인 사용 방법까지 충실하게 구성하였습니다.\n코로나 팬데믹이 끝났지만 사회와 경제는 여전히 어렵고, 앞으로도 어려워질 전망이라고 합니다. 이런 시대에 챗 지피티가 사람들의 입에 많이 오르내리는 것은 우연이 아닐 것입니다.\n챗 지피티는 세상을 바꿀 것입니다.\n여러분도 본 과정을 통해 챗 지피티가 가진 희망찬 능력을 자기 것으로 만들어 보세요.\n인공 지능을 잘 활용하는 당신이 세상의 새로운 희망이 될 수 있습니다.\n\n\n생성형 AI의 프롬프트 엔지니어링 기술 소개\n생성형 AI 시장이 거대 언어 모델 중심으로 엄청난 속도로 진화하고 있습니다.\n이러한 시장 상황에서 생성형 AI에 대한 대중의 높아진 관심을 기반으로 인공지능 모델을 제대로 활용할 수 있는 다양한 활용 사례에 대한 소비자 요구가 높아지고 있습니다.\n이러한 요구 사항은 ChatGPT와 같은 AI 모델에게 정확한 답변을 이끌어내는 방법을 사용해서 달성이 가능한데,\n이러한 방법을 ‘프롬프트 엔지니어링(Prompt Engineering)’이라 부르며, 자연어 처리 분야에서 전도유망한 새로운 인공지능 활용 역량입니다.\n\n\n“ChatGPT를 위해 훌륭한 프롬프트를 작성하는 것은 활용도가 굉장히 높은 기술이며 약간의 자연어로 프로그래밍하는 것의 초기 사례이다.\n(Writing a really great prompt for a chatbot persona is an amazingly hig-leverage skill and an early example of programming in a little bit of natural language)”\n– OpenAI 대표 샘 알트만\n\n프롬프트 엔지니어링이란 ChatGPT와 같은 인공지능 모델에게 한국어와 같은 일반 언어를 사용해서 질문을 잘 해서 효과적으로 인공지능을 활용하는 방법입니다.\n이 기법은 인공지능으로부터 최상의 답변을 얻어내기 위해서 최적의 단어와 같은 언어 입력값들에 대한 가장 좋은 조합을 찾는 작업입니다.\n이렇게 인공지능에게 한국어와 같은 언어로 질문을 잘 하는 전문 담당자를 ‘프롬프트 엔지니어’라고 부르며, 해외 기업 중심으로 수요가 급증하고 있는 신규 직업입니다. 구글이 투자하고, OpenAI 경쟁사로 기대되는 Anthropic AI란 회사는 올해 초 프름프트 엔지니어 채용 공고에서 무료 연봉 범위를 25만불 ~ 33만불을 제시했는데, 이는 한국 원화로 환산하면 3억 2천만원 ~ 4억 3천만원 정도가 됩니다. 이뿐만 아니라 프롬프트 엔지니어들이 자신들의 프롬프트를 사고 파는 프롬프트 마켓플레이스라는 서비스들 역시 급격히 증가하고 있습니다.\nchatGPT 고급 활용법 강좌에서는 인공지능 모델의 모든 성능을 이끌어낼 수 있는 프롬프트 엔지니어링에 대해서 개념부터 고급 기법까지 제시하면서,\n여러분이 좋은 프롬프트를 만들어내고 활용할 수 있는 ‘프롬프트 엔지니어’로 성장할 수 있는 고급 활용 비법을 제시합니다.\n\n\n강의 특징\n언어 처리 모델의 대명사인 ChatGPT는 의미 있는 콘텐츠를 만들고 쉽게 소통할 수 있게 해주는 획기적인 도구입니다.\n그러나 모든 도구와 마찬가지로 올바른 사용법을 익히고 그 힘을 활용하는 방법을 이해해야 합니다.\n\n\nSTEP 1. ChatGPT를 뒷받침하는 기본 개념 공략하기\n언어 모델, 생성 AI 및 모든 것을 가능하게 하는 원리를 이해하면서 여정을 시작합니다.\n“똑똑한 말 한스” 및 “FIFA 선수 카드”와 같은 기발한 예를 통해 인공지능을 뜯어봅니다.\nSTEP 2. ChatGPT의 잠재력을 최대한 끌어내기\n비즈니스 아이디어 생성에서 마케팅 캠페인 계획, 대화식 학습에서 프로그래밍 코딩에 이르기까지\nChatGPT의 다양한 기능과 이를 최대한 활용하는 방법을 살펴봅니다.\n우리는 쉽게 창의력을 발휘하고 콘텐츠 제작과 커뮤니케이션을 새로운 차원으로 끌어올릴 것입니다.\nSTEP 3. API로 활용 범위를 무한히 확장하기\nGoogle Spreadsheet 및 Docs와 같은 다른 도구에 ChatGPT를 연결하는건 어떨까요?\n몇 가지 지시만으로 ChatGPT는 비즈니스 현장에서 든든한 비서가 될 것입니다.\nSTEP 4. 프롬프트 엔지니어링으로 구체적인 명령 수행하기!\n완벽한 프롬프트를 만들고, 좋은 질문을 하고, 상황에 맞는 프롬프트를 처리하는 기술을 살펴봅니다.\nChatGPT에 필요한 것을 정확히 지시하고 성능을 미세 조정하는 하이퍼파라미터를 통해 ChatGPT의 전문가가 될 수 있습니다.\n\n\n-\n\n\n[ 강 사 소 개 ]\n\n\n최 정 아\n現 마소캠퍼스 콘텐츠랩 이사\n연세대학교 경영학 석사\nYSCEC의 웹마스터로서 연세-게이오(日)-릿쿄(日)-푸단(中) 대학의 YKLP 사업에 초기부터 합류해 성공적으로 론칭시킨 국제 원격교육 전문가입니다. 이후 플레이포럼 편집장으로 자리를 옮겨 MAU 238만 명의 커뮤니티를 7년간 운영하면서 최대 900만 뷰를 달성한 디지털 콘텐츠를 제작했습니다. 언어학, 정보학, 경영학 학위를 소지한 다재다능한 디지털마케팅 전문가로서 데이터를 활용해 디지털 플랫폼에서 최고의 퍼포먼스를 이뤄냈습니다. 효과적인 데이터 마케팅 방법을 다룬 도서를 다수 출간하여 모두 경제경영 분야 베스트셀러에 오른 검증된 지식을 공유하고 있습니다.",
      "target_audience": [
        "인공 지능 시대에 꼭 필요한 체계적인 Chat GPT 활용 지식을 얻고 싶으신 분",
        "인공 지능을 단순히 신기한 장난감이 아닌 실제로 생산적인 도구로 사용하고 싶으신 분",
        "확실한 인공지능 사용법을 익혀 누구보다도 높은 업무 효율을 경험하고 싶으신 분",
        "전문적인 프롬프트 엔지니어의 길을 희망하는, 2020년대를 겪고 있는 모든 분"
      ]
    },
    {
      "title": "Deep Learning: Visão Computacional, CNNs e Transfer Learning",
      "url": "https://www.udemy.com/course/deep-learning-redes-convolucionais-e-transfer-learning/",
      "bio": "Domine o estado da arte da inteligência artificial para classificação de imagens com Python (Keras e Tensorflow)",
      "objectives": [
        "Teoria por trás de redes convolucionais",
        "Visualização de redes convolucionais",
        "Como implementar redes convolucionais com Keras (Tensorflow nos bastidores)",
        "Como treinar super-redes neurais a partir da transferência de aprendizagem",
        "Teoria por trás de transferência de aprendizagem"
      ],
      "course_content": {
        "Introdução": [
          "Visão Geral do Curso",
          "Aplicações de Deep Learning para Visão Computacional",
          "Instalação de Pré-Requisitos, Material do Curso e Google Colab",
          "Links Relevantes",
          "Aquecimento - Treinando um Classificador de Raças de Cachorros"
        ],
        "(Opcional) Revisão de Machine Learning e Redes Neurais": [
          "Sobre Esta Unidade",
          "Terminologias e Visão Geral de Machine Learning",
          "Primeiras Intuições sobre Redes Neurais",
          "Como as Redes Neurais Aprendem",
          "Funcões de Ativação em Redes Neurais"
        ],
        "Teoria sobre Redes Neurais Convolucionais (CNNs)": [
          "Visão Geral sobre Redes Convolucionais",
          "Visualizando Redes Convolucionais",
          "Referências Complementares"
        ],
        "Implementação de Redes Convolucionais com o Keras": [
          "Visão Geral",
          "Importando e Visualizando os Dados",
          "Normalizando os Dados de Entrada",
          "Implementando uma Camada Densamente Conectada",
          "Correção: Utilizando Dados Normalizados",
          "Camada Convolucional do Keras - Primeiras Intuições",
          "Implementando Camada Convolucional",
          "Finalizando o Modelo Convolucional",
          "Correção: Inclusão de Função de Ativação",
          "Visualizando Predições",
          "(Bônus) Visualizando Camadas Convolucionais",
          "(Bônus) Correção no Último Código",
          "Implementando CNNs - Fashion MNIST"
        ],
        "Transferência de Aprendizagem (Transfer Learning)": [
          "Visão Geral sobre Transferência de Aprendizagem (Transfer Learning)",
          "Histórico de Modelos Transferência de Aprendizagem",
          "Carregando Imagens no Keras",
          "Implementação - Visão Geral",
          "Link da Implementação de Transferência de Aprendizagem",
          "Implementação - Baixando a Base de Dados",
          "Implementação - Carregando as Imagens com ImageDataGenerator",
          "Implementação - Declarando o Modelo",
          "Implementação - Treinando o Modelo",
          "Implementação - Visualizando Predições",
          "Implementação - Revisão"
        ],
        "Melhores Práticas": [
          "Visão Geral Melhores Práticas",
          "Lidando com Overfitting",
          "Melhorando Performance e Velocidade",
          "Lidando com a Dissipação e Explosão de Gradientes",
          "Implementação em Código das Melhores Práticas"
        ]
      },
      "requirements": [
        "Básico de redes neurais",
        "Básico sobre machine learning"
      ],
      "description": "Olá aluno! Meu principal objetivo neste curso é ensinar vocês à treinarem modelos de redes convolucionais para classificação de imagens. Além disso, pretendo compartilhar a teoria por trás para que vocês entendam o que ocorre nos bastidores. Por fim, um terceiro objetivo que tenho aqui é ensinar vocês boas práticas para treinamento de modelos estado da arte - esta parte eu aprendi com o pessoal da Fast AI na Universidade de San Francisco. Em especial, vocês perceberão que o estado da arte para treinamento de problemas de classificação de imagens somente é possível graças ao uso de transferência de aprendizagem (transfer learning). Com este método é possível fazermos uso de super redes neurais campeãs em competições de visão computacional e transferir seu poder de extração de características para outros problemas.\n\n\nOBS: Estou tornando público um curso que demorei mais de dois anos para desenvolver - à princípio o foco não era a Udemy mas gostaria de deixar ele no ar em alguma plataforma. Como perceberão nos vídeos, ele foi gravado aos poucos, e ainda sinto que há algumas partes faltando, mas se esperar até este dia chegar, ele nunca ficará pronto :) portanto, já vou torná-lo público, ir coletando feedbacks e melhorando quando necessário.",
      "target_audience": [
        "Iniciantes em redes neurais que gostariam de aprender sobre aplicações em visão computacional",
        "Programadores que gostariam de criar modelos de classificação"
      ]
    },
    {
      "title": "Spring Boot ile Elasticsearch Kullanım Klavuzu",
      "url": "https://www.udemy.com/course/spring-boot-elasticsearch-kullanm-klavuzu/",
      "bio": "Elasticsearch ile Verinin gücünü keşfedin ve Bu alanın uzmanı olun.",
      "objectives": [
        "Elasticsearch nasıl ortaya çıkmış ve hangi sorunları çözüm üretiyor?",
        "Güçlü ve Hızlı bir arama motoru nasıl oluşturulur?",
        "Karmaşık Full-Text Search nasıl yapılır?",
        "Elasticsearch terminolojisine hakim olun ve uygulamalarınızda kullanın"
      ],
      "course_content": {
        "Giriş": [
          "Ben kimim ve neler yapıyorum?",
          "Bu Eğitimde neler öğreneceksiniz?"
        ],
        "Elasticsearch Mimarisini Anlamak": [
          "Güncel Mimariyi anlamak",
          "Apache Lucene adaptasyonu",
          "Apache Lucene Full-Text Search",
          "Apache Lucene nasıl çalışır?",
          "Yatay Genişleme ile Performans Artışı",
          "Elasticsearh' ün Doğuşu ve Component",
          "Elasticsearch Node ve Shard Kavramları",
          "Inter Node Communication ve Cluster kavramı",
          "Elasticsearch, Primary Shard ve Replica Shard Kavramları",
          "Fault Tolarence ve Çözüm önerileri",
          "Replica Shard ve Primary Shard yapsının çalışma yapısı ve dönüşümleri",
          "Scope Creep ve çözüm yöntemi"
        ],
        "Kurulum": [
          "Kurulum öncesi dikkat - Docker",
          "Elasticsearch \"Mutli Node\" Kurulumu",
          "Elasticsearch \"Single Node\" kurulumu",
          "Kibana ve Örnek dataların kullanımı"
        ],
        "Elasticsearch Terimlerini Anlamak": [
          "Node, Primary Shard - Replica Shard ve Cluster Nedir?",
          "Index Nedir?",
          "Data Stream Nedir?",
          "Text Analysis Nedir?",
          "Inverted Index Nedir?",
          "Mapping Nedir?",
          "Relevancy Nedir?"
        ],
        "Dökümanları Yönetmek | Managing Document": [
          "Döküman oluşturma",
          "Dökümanları güncellemek",
          "Dökümanları Silmek",
          "Mapping, Data Type Detayları"
        ],
        "Elasticsearch Arama | Searching for Data": [
          "Search nedir, nasıl çalışır?",
          "Query DSL Kavramı, Query Context ve Filter Context",
          "Search Request ve Response",
          "Term Query",
          "Prefix Query",
          "Range Query",
          "WindCard Query",
          "Fuzzy Query",
          "Pagination",
          "Sorting",
          "Full Text | Match Query",
          "Full Text | Match Phrase Query",
          "Full Text | Match Boolean Prefix Query"
        ],
        "Aggregations": [
          "Full Text | Multi-Match Query",
          "Aggregation nedir?",
          "Metrik aggregation nedir?",
          "Bucket aggregation nedir?",
          "Global aggregation"
        ],
        "Spring Boot - Elasticsearch Entegrasyonları": [
          "Spring Boot projesi başlatmak",
          "Elasticsearch configurasyonları | ClientConfig & YML",
          "Elasticsearch Spring Boot bağlantısını test emek",
          "Document sınıflarının oluşturulması | Object Mapping",
          "Respository Interface' i ve Servis katmanının entegrasyonu",
          "Control Katmanının Entegrasyonu",
          "SwaggerUI implemantasyonu",
          "Projeyi Çalıştırmak ve Veri Girişlerini kontrol etmek"
        ],
        "Spring Boot Elasticsearch Repositories": [
          "ElasticRepository Core Concept",
          "Defining Query Methods",
          "Query Methods | Term & Match Query",
          "ElasticRepository Query Keywords",
          "Repository Query Return Types"
        ],
        "Kapanış": [
          "Kapanış ve Tavsiyeler"
        ]
      },
      "requirements": [
        "Herhangi bir yazılım dilini biliyor olmak(C#, Java)"
      ],
      "description": "Merhaba ve hoş geldiniz! Bu Elasticsearch eğitim serisi, Elasticsearch'in derinliklerine dalmak ve onu hızla öğrenip kullanmanızı sağlayacak mükemmel bir kaynaktır. Bu ders, Elasticsearch mimarisini, kurulumunu, kullanımını, full-text aramalarını ve daha fazlasını kapsayan kapsamlı bir rehberdir. Elastic Stack ve ELK Stack gibi diğer teknolojilerle tanışmak isteyenler için mükemmel bir başlangıç noktasıdır.\n\n\nElasticsearch, son derece popüler bir arama motorudur ve CV'nize mükemmel bir katkı sağlayacaktır - diğer arama motorları veya çerçevelerle (Apache Lucene, Apache Solr, Algolia, vb.) zaten tanışmış olsanız bile.\n\n\nBu Elasticsearch kursu, teori ve uygulama temelli bir yaklaşımı birleştirir. Belirli sorguları nasıl gerçekleştireceğinizi göstermeden önce gerekli teoriyi önceden öğreneceksiniz. Bu, güçlü Elasticsearch sorguları yazmayı sadece bilmekle kalmayıp, ilgili teoriyi de anlamanızı sağlar. Bu rehber boyunca, Elasticsearch'in nasıl çalıştığını derinlemesine anlayacaksınız.\n\n\nKurs tamamen sıfırdan başlar ve Elasticsearch hakkında hiçbir bilgi veya deneyim gerektirmez. Elasticsearch'in en önemli yönlerini baştan sona ele alacağız. Bu kursu tamamladıktan sonra, Elasticsearch'i Google Arama gibi bir tam metin arama motoru oluşturmak, büyük miktarda veri için veri analitiği yapmak, Elasticsearch'i bir zaman serisi veritabanı (TSDB) olarak kullanmak gibi birçok amaç için kullanabileceksiniz.\n\n\nElastic Stack'in diğer ürünleriyle birleştirildiğinde,  Kibana gibi, başka birçok özelliği de açığa çıkaracaksınız:\n\n\n- Elasticsearch yapısı\n- Elasticsearch Kurulum ve Kullanımı\n- Full-text search\n- Spring Boot Kurulum ve Kullanımı\n- Spring Boot ve Elasticsearch entegrasyonları ve sorgular\n\n\nBu eğitim serisi, Elasticsearch'i anlamak ve etkili bir şekilde kullanmak isteyen herkes için idealdir. Hazır mısınız Elasticsearch ile yolculuğunuza başlamak için?",
      "target_audience": [
        "Büyük veri kümelerinin hızlı, ölçeklenebilir araması ve analiziyle görevlendirilmiş herhangi bir teknoloji uzmanı.",
        "Elasticsearch'ü öğrenmek isteyen geliştiriciler."
      ]
    },
    {
      "title": "【Artifacts】Claudeパーフェクトマスター講座 -高性能な生成AIを、基礎から応用まで学ぼう！-",
      "url": "https://www.udemy.com/course/claude-3-ai/",
      "bio": "Anthropic社が提供するAIモデル「Claude 」について学ぶ講座です。Claudeの強力な機能「Artifacts」と共に、AIと協業するスキルを身につけましょう。インタラクティブなUIで、様々なコンテンツ作成にトライします。",
      "objectives": [
        "Anthropic社が提供するAI、Claudeの使い方を基礎から体験と共に学びます。",
        "Claudeの拡張機能、Artifactsによるインタラクティブなコンテンツ作成を学びます。",
        "Claude、そしてArtifactsの様々な応用を学びます。",
        "ClaudeおよびArtifactsの全体像、そしてその可能性について学びます。",
        "Claudeによる高精度のテキスト生成、画像認識について学びます。",
        "Claudeをビジネス、創作活動、教育などに活用する方法を学びます。",
        "Claudeの長所、短所について学びます。"
      ],
      "course_content": {},
      "requirements": [
        "2024年10月の環境で解説しています。最新の環境と異なる可能性があります。",
        "人工知能、機械学習の技術的な知識は不要です。",
        "ローカル環境はWindowsでもMacでも大丈夫です。",
        "Anthropicのアカウント開設が必要です。",
        "Claudeの無料プランでも受講可能ですが、Claudeの使用回数にかなり制限があります。",
        "有料のClaude Pro（20$/月）へ登録すれば、制限がかなり緩和されます。"
      ],
      "description": "「【Artifacts】Claudeパーフェクトマスター講座」は、Anthropic社が提供するAIアシスタント「Claude」の使い方を徹底的に学ぶ講座です。\n最先端の生成AIを扱えるようになりたい方におすすめです。\n\n\nClaudeは人間の会話のような自然なやりとりが可能で、文章の生成や要約、質問応答、翻訳に加え、コーディング支援やデータ分析など、幅広い用途で活用できます。\n本講座では特に、Claudeの強力な機能である「Artifacts」の使用方法に焦点を当てています。\nArtifactsを使うことで、インタラクティブなコンテンツ作成、リアルタイム表示と編集、プレビューなどが可能になります。\nこれにより、プログラミングやデータ分析タスク、レポート作成などの生産性が大幅に向上します。\n\n\n本講座では、最初にClaudeの概要を学んだ上で、Artifactsを含む様々な機能、活用法を順を追って学んでいきます。\nClaudeをマスターし、生成AIと効果的に協業するスキルを身につけましょう。\n\n\n講座の内容は以下の通りです。\nSection1. Claudeの概要と基本的な使い方\n→ Claudeの概要と、基本的な使い方について学びます。\nSection2. Artifactsの活用\n→ Claudeの強力な機能であるArtifactsの使い方を詳しく学びます。\nSection3. Claudeの応用\n→ Claudeを様々なタスクに応用し、生成AIと協業するスキルを身につけます。",
      "target_audience": [
        "高性能な大規模言語モデル（LLM）を自在に操りたい方",
        "Claudeを基礎から体験ベースで学びたい方。",
        "Claudeを業務や趣味で活用したい方。",
        "AIのサポートにより文章作成、画像認識を効率化したい方。",
        "生成AI技術のトレンドに追随したい方。",
        "Artifactsを使いこなしたい方"
      ]
    },
    {
      "title": "人工智能A-Z™: 学习如何创造一个AI (Artificial Intelligence A-Z)",
      "url": "https://www.udemy.com/course/artificial-intelligence-az-chinese/",
      "bio": "结合数据科学、机器学习和深度学习的威力，来为现实世界的应用创造一个强大的AI！(英文原音)",
      "objectives": [
        "构建一个AI",
        "理解人工智能背后的理论",
        "创造一部虚拟的自动驾驶车",
        "创造一个AI来闯关游戏",
        "用AI解决实际生活中的问题",
        "精通当前最先进的AI模型",
        "Q学习",
        "深度Q学习",
        "深度卷积Q学习",
        "A3C"
      ],
      "course_content": {
        "欢迎来到本课程!": [
          "为什么选择AI?",
          "课程结构",
          "安装 Anaconda"
        ],
        "---------- 第0部分 - 强化学习基础 ----------": [
          "欢迎来到第0部分 - 强化学习基础"
        ],
        "Q学习直觉力": [
          "攻克计划",
          "什么是强化学习?",
          "贝尔曼方程",
          "“计划”",
          "马尔可夫决策过程",
          "策略 vs 计划",
          "增加一项 \"生命惩罚\"",
          "Q学习直觉力",
          "时间差分"
        ],
        "Q学习可视化": [
          "Q学习可视化"
        ],
        "---------- 第1部分 - 深度Q学习 ----------": [
          "欢迎来到第1部分 - 深度Q学习"
        ],
        "深度Q学习直觉力": [
          "攻克计划",
          "深度Q学习直觉力 - 学习",
          "深度Q学习直觉力 - 行动",
          "经验回放",
          "动作选择策略"
        ],
        "深度Q学习实现": [
          "攻克计划",
          "哪里获取课程资源",
          "准备开始",
          "自动驾驶车- 步骤 1",
          "自动驾驶车- 步骤 2",
          "自动驾驶车- 步骤 3",
          "自动驾驶车- 步骤 4",
          "自动驾驶车- 步骤 5",
          "自动驾驶车- 步骤 6",
          "自动驾驶车- 步骤 7",
          "自动驾驶车- 步骤 8",
          "自动驾驶车- 步骤 9",
          "自动驾驶车- 步骤 10",
          "自动驾驶车- 步骤 11",
          "自动驾驶车- 步骤 12",
          "自动驾驶车- 步骤 13",
          "自动驾驶车- 步骤 14",
          "自动驾驶车- 步骤 15",
          "自动驾驶车- 步骤 16"
        ],
        "深度Q学习可视化": [
          "自动驾驶车 - 第1关",
          "自动驾驶车 - 第2关",
          "自动驾驶车 - 第3关",
          "自动驾驶车 - 第4关",
          "挑战解决方案"
        ],
        "---------- 第2部分 - 深度卷积Q学习 ----------": [
          "欢迎来到第2部分 - 深度卷积Q学习"
        ],
        "深度卷积Q学习直觉力": [
          "攻克计划",
          "深度卷积Q学习直觉力",
          "资格迹"
        ]
      },
      "requirements": [
        "高中数学",
        "基础Python知识"
      ],
      "description": "*** 如您在KICKSTARTER所见 ***\n学习重要的AI概念，以及直觉力训练，帮助您快速跟进AI所有方面。课程包括：\n· 如何在没有Python编程经验的情况下开始创造AI。\n· 如何将AI与OpenAI Gym相融合，使得学习尽可能有效。\n· 如何优化您的AI，使之在现实世界发挥最大潜能。\n以下是您将通过本课程收获的:\n\n\n1. 从AI初学者到专家的全部技能 – 学习为一系列用途编写完善的AI代码。实际上，我们会与您一起来编写代码。每一次教程都是从空白文档开始，我们会从零开始编写代码。这样您可以步步跟进，并且准确理解代码是如何组织，以及每一行代码的含义。\n2. 代码模板 – 除此之外，对于在本课程构建的每一个AI，您都将获得可下载的Python代码模板。这会使得构建真正独一无二的AI就像改动几行代码那般简单。如果您释放想象力，会拥有无尽的潜力。\n3. 直觉力教程 – 当绝大多数课程只是用艰深的理论来进行轰炸，以提高您的学习，我们则旨在帮助您不仅要理解正在解决的事情，而且要深入领悟如此做法的原因。因此，我们不会扔给您复杂的数学公式，而是专注培养您编写AI代码的直觉力，通过一行行的代码来收获优秀的应用成果。\n4. 现实世界的解决方案 – 您不仅仅会在1个游戏中实现目标，您将会挑战3个游戏！每一个模块都拥有不同的结构和难度，意味着您会拥有相当的技能来构建适应任何真实生活环境的AI，而非只是像其他大多数课程一样，仅留下通过考试的记忆而遗忘掉课程内容。真正的实践会磨练出您完美的技能。\n5. 课程内支持 – 我们真心承诺将本课程打造为最亲近学生、成果最为丰厚的AI课程。这要求我们出现在您需要帮助的任何时刻。因此我们组建了一个专业的数据科学家团队，为您的学习之旅提供支持，这意味着您会在不超过48小时之内收到我们的回应。",
      "target_audience": [
        "任何对人工智能、机器学习或深度学习感兴趣的人。"
      ]
    },
    {
      "title": "【한글자막】 Deep Reinforcement Learning :딥 강화형 러닝 2.0",
      "url": "https://www.udemy.com/course/best-deep-reinforcement-learning/",
      "bio": "AI의 모든 기본(Q러닝, 딥 Q러닝, 정책 그래디언트, 액터 크리티)에 대해 배우고 깊이 있는 트윈 딜레이 DDPG 이론과 실행에 대해 배웁니다",
      "objectives": [
        "Q러닝",
        "딥 Q러닝",
        "정책 그래디언트",
        "액터 크리틱",
        "심층 확정적 정책 그래디언트(DDPG)",
        "트윈 딜레이 DDPG(TD3)",
        "딥 강화형 러닝의 기초 기술",
        "까다로운 가상 애플리케이션 이상의 최첨단 AI 모델을 실행하는 방법"
      ],
      "course_content": {
        "파트 1 - 기초": [
          "도전을 환영합니다!",
          "소개",
          "시작하기 전에",
          "보너스 : 학습 경로",
          "Q러닝",
          "딥 Q러닝",
          "정책 그래디언트",
          "액터 크리틱",
          "AI 모델 분류",
          "보너스 : DRL의 다섯 가지 이점",
          "보너스 : RL 알고리즘 맵",
          "머티리얼 가져오기"
        ],
        "파트 2 - Twin Delayed DDPG 이론": [
          "도입 및 초기화",
          "Q러닝 파트",
          "정책 학습 파트",
          "전체 훈련 과정"
        ],
        "파트 3 - Twin Delayed DDPG 실행": [
          "실행을 포함한 전체 코드 폴더",
          "시작",
          "실행 - 1단계",
          "실행 - 2단계",
          "실행 - 3단계",
          "실행 - 4단계",
          "실행 - 5단계",
          "실행 - 6단계",
          "실행 - 7단계",
          "실행 - 8단계",
          "실행 - 9단계",
          "실행 - 10단계",
          "실행 - 11단계",
          "실행 - 12단계",
          "실행 - 13단계",
          "실행 - 14단계",
          "실행 - 15단계",
          "실행 - 16단계",
          "실행 - 17단계",
          "실행 - 18단계",
          "실행 - 19단계",
          "실행 - 20단계"
        ],
        "파이널 데모": [
          "데모 - 트레이닝",
          "데모 - 추론"
        ],
        "별첨 1 - 인공신경망": [
          "학습 계획",
          "뉴런",
          "활성화 함수",
          "신경망 작동 방법",
          "신경망 학습 방법",
          "경사하강법",
          "확률적 경사하강법",
          "역전파"
        ],
        "별첨 2 - Q러닝": [
          "학습 계획",
          "강화형 머신러닝이란?",
          "벨맨 방정식",
          "계획",
          "마르코프 의사결정 과정",
          "정책 vs 계획",
          "리빙 페널티",
          "Q러닝 직관",
          "시간적 차이",
          "Q러닝 시각화"
        ],
        "별첨 3 - 딥 Q러닝": [
          "학습 계획",
          "딥 Q러닝 직관 - 1단계",
          "딥 Q러닝 직관 - 2단계",
          "경험 리플레이",
          "액션 선택 정책"
        ],
        "축하합니다!! 상품을 잊지 마세요 :)": [
          "챌린지를 완료하신 것을 진심으로 축하드립니다!",
          "보너스: 최고 연봉을 잠금 해제하는 방법 (라이브 교육)",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "미분 또는 그래디언트 정도의 기초 수학 지식",
        "프로그래밍 지식(클래스 및 오브젝트)"
      ],
      "description": "기초부터 이론, 실행까지 DDPG에 대한 모든 것!\n똑똑한 AI 모델 트윈 딜레이 DDPG에 대해 학습해보세요!\n\n\nDeep Reinforcement Learning :딥 강화형 러닝 2.0 강의를 선택해야 하는 이유\n한국 수강생 여러분들 안녕하세요?\n딥 강화형 러닝 2.0에 오신 걸 환영합니다!\n\n\n이 강의에서는 더블 딥 Q러닝, 정책 그래디언트, 액터 크리틱 등 인공지능 분야의 최첨단 기술이 결합된 똑똑한 AI 모델인 트윈 딜레이 DDPG에 대해 배우고 실행합니다. 이 모델은 꽤 강력해 가장 까다로운 가상 AI 애플리케이션(개미 및 거미, 반 휴머노이드에게 걷고 달릴 수 있도록 훈련하는 것)을 배워볼 수 있습니다.\n\n\n이 모델을 효과적으로 배우기 위해 강의를 세 파트로 나누었습니다 :\n\n\n● 파트 1: 기초\n이 강의를 들으며 AI를 이해하고 마스터할 수 있도록 인공지능의 모든 기본에 대해 공부하겠습니다. 여기에는 Q러닝, 딥 Q러닝, 정책 그래디언트, 액터 크리티 등이 포함됩니다.\n\n\n● 파트 2: 트윈 딜레이 DDPG 이론\n파트 2에서는 모델의 이론에 대한 깊이 있는 연구를 진행할 것입니다. 일련의 시각화된 슬라이드를 통해 AI의 전체 구축 및 훈련 과정을 명확하게 볼 수 있습니다. 여러분은 이론을 자세히 배울 뿐만 아니라 AI가 어떻게 학습하고 작동하는지에 대한 직관을 형성하게 될 것입니다. 파트 1의 기본 원리는 파트 2의 심화 이론과 결합되어 있습니다. 여러분은 심화된 모델을 접하고 이 모델을 마스터할 수 있는 극소수의 사람들 중 하나가 될 것입니다.\n\n\n● 파트 3: 트윈 딜레이 DDPG 실행\n파트 3에서는 모델을 처음부터 단계별로 실행해 볼 것입니다. 그리고 대화형 세션을 통해 모델을 구현하는 동안 많은 코딩 연습을 할 수 있습니다. 이를 통해 여러분은 수동적으로 강의를 따라오는 게 아니라 적극적으로 스킬을 연마할 수 있을 것입니다. 마지막으로, 우리는 콜라보토리(Colaboratory) 또는 구글 코랩(Google Colab)에서 전체적으로 코딩을 실행할 것입니다. 구글 코랩은 완전 무료의 오픈 소스 AI 플랫폼입니다. 패키지 없이도 AI를 코딩하고 훈련시킬 수 있습니다. 실행 버튼을 누르면 AI가 훈련을 시작하고 최종적으로 여러분은 거미와 휴머노이드가 뛰어 노는 비디오를 100% 만들 수 있습니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n지금 등록하고 여러분의 지식과 능력을 한 단계 더 업그레이드 시키세요\n강의에서 만나요!\n\n\n-Ligency Team",
      "target_audience": [
        "AI 기술을 한 단계 발전시키고자 하는 데이터 과학자",
        "애플리케이션 분야 확장을 원하는 AI 전문가",
        "기술 및 자동화 분야에 종사하는 엔지니어",
        "경쟁에서 앞서나가고자 하는 기업가와 기업",
        "데이터 과학, 머신러닝, 인공지능의 분야에서 커리어를 쌓고자 하는 기술 관련 프로그램 수강생",
        "인공지능에 대해 열정적인 사람"
      ]
    },
    {
      "title": "如何培养工作中的数据思维，用数据分析业务问题？",
      "url": "https://www.udemy.com/course/awvhygtb/",
      "bio": "帮助你解决工作中最常见的数据问题，培养数据思维",
      "objectives": [
        "构建更准确的数据观，了解日常工作流程与分类，了解各环节数据的应用方法，学习不同工具的快速应用",
        "了解数据指标的分类，明确各类数据指标的特点，学会制定数据指标，搭建基本的数据体系",
        "了解数据体检的内涵、定义、重要意义和应用场景，掌握如何进行数据体检、基本步骤的含义和具体操作",
        "了解有哪些导致线上数据变化的常规原因，掌握线上数据变化的常规验证流程，明白定位复杂因素的分析思路",
        "了解传统企业数字化转型的阶段和常见难点，了解贝壳如何搭建数据系统，并在推行应用以赋能业务效率"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "数据思维在日常工作中的应用": [
          "数据的基本属性是什么？",
          "定义问题：通过量化让问题定义更清晰",
          "分析问题：通过数据完成拆分与问题分析",
          "解决问题：利用数据工具提升效率",
          "总结问题：利用数据做好复盘与汇报",
          "小结与建议"
        ],
        "数据指标与案例拆解": [
          "北极星指标",
          "关键指标",
          "分析指标",
          "反向指标",
          "贝壳数据指标案例分析",
          "装潢公司筛选数据分析案例",
          "章节小结"
        ],
        "怎么做数据体检": [
          "什么是数据体检？",
          "思考商业模式 / 业务流程",
          "数据项整理",
          "数据提取",
          "深入分析",
          "整合结论出规划",
          "章节小结"
        ],
        "数据分析实操方法": [
          "数据分析实际是在做什么",
          "快方法：快速假设、验证",
          "慢方法：逐步拆分深入，边探索边假设边分析",
          "4.小结"
        ],
        "案例：从贝壳数字化看数据驱动": [
          "传统企业数字化概述",
          "数据采集：贝壳业务三要素",
          "搭建系统：贝壳的内网系统",
          "分析数据：日常数据跟进分析",
          "总结、展望与启发"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "具备基础的数据分析能力"
      ],
      "description": "你是否会经常被问项目的数据收益？\n经常希望通过数据化方式来汇报但又不知如何入手？\n碰到业务中的数据“意外”又不知道原因是什么？\n想要帮助业务体系做数字化，但又不知如何切入？\n遇到这些问题是因为你缺乏“数据思维”。无数据、不决策。将数据思维应用到工作汇报、工作内容中，能够让你在工作中更游刃有余\n本课程能够帮助你培养数据思维，你将学会如何将数据融入工作中。同时你还能学会业务中如何构建数据指标和体系，如何应对日常工作中的数据分析工作，以及如何帮助企业做数字化转型。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。\n未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "需要分析业务数据的新手数据分析师",
        "需要分析业务数据的新手产品运营",
        "需要分析业务数据的业务运营人员"
      ]
    },
    {
      "title": "Machine Learning para Competições Kaggle - Especial COVID-19",
      "url": "https://www.udemy.com/course/machine-learning-competicoes-kaggle-covid-19-coronavirus/",
      "bio": "Atenda ao chamado da Casa Branca e ajude a comunidade científica e os profissionais de saúde na pandemia de COVID-19",
      "objectives": [
        "Como trabalhar com bases de dados específicas para competições Kaggle",
        "Como resolver problemas de recuperação de informação, regressão e diagnóstico por imagens para ajudar a comunidade científica na pandemia de COVID-19",
        "Desenvolva insights que permitam construir modelos de Machine Learning aplicados em problemas reais",
        "Aprenda exploração de dados voltados para desafios reais",
        "Crie vários tipos de gráficos para ajudar na compreensão e análise dos dados",
        "Utilize técnicas modernas para recuperação de informações em documentos de texto",
        "Utilize regressão para prever o número de mortes por COVID-19",
        "Utilize técnicas modernas de deep learning; como redes neurais convolucionais e transfer learning, para diagnosticar pacientes com COVID-19 utilizando imagens de Raio X"
      ],
      "course_content": {},
      "requirements": [
        "Familiaridade com os conceitos básicos e algoritmos de Machine Learning",
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Programação básica em Python"
      ],
      "description": "De acordo com o CDC (Centers for Disease Control and Prevention), o novo coronavírus de 2019 é um vírus identificado como a causa de um surto de doença respiratória detectado pela primeira vez em Wuhan, na China. Desde o início, muitos dos pacientes do surto em Wuhan teriam algum vínculo com um grande mercado de frutos do mar e animais silvestres. Um número crescente de pacientes supostamente não teve exposição ao mercado de animais, indicando a ocorrência de disseminação de pessoa para pessoa. O vírus já se espalhou para praticamente todos os países do mundo, causando muitas mortes e sérios problemas na economia. Devido a isso, a Casa Branca dos Estados Unidos junto com pesquisadores e líderes do Allen Institute for AI, Chan Zuckerberg Initiative (CZI), Georgetown University’s Center for Security and Emerging Technology (CSET), Microsoft, e o National Library of Medicine (NLM) at the National Institutes of Health lançaram uma base de dados com artigos publicados sobre o COVI-19, SARS-CoV-2 e vírus do grupo dos coronavírus.\nA base de dados possui mais de 30.000 artigos científicos sobre essas doenças, sendo que o objetivo principal é ajudar pesquisadores e profissionais da saúde obterem informações relevantes sobre esses assuntos. Leia alguns trechos do chamado (call to action) da Casa Branca: \"A Casa Branca se une a essas instituições ao emitir um apelo à ação dos especialistas em inteligência artificial da nação para desenvolver novas técnicas de mineração de texto e dados que podem ajudar a comunidade científica a responder perguntas científicas de alta prioridade relacionadas ao COVID-19\", \"Precisamos nos unir como empresas, governos e cientistas e trabalhar para trazer nossas melhores tecnologias para a biomedicina, epidemiologia, IA e outras ciências. O recurso e desafio da literatura COVID-19 estimulará esforços que podem acelerar o caminho para soluções em COVID-19\", \"Uma das aplicações mais imediatas e impactantes da IA é a capacidade de ajudar cientistas, acadêmicos e tecnólogos a encontrar as informações corretas em um mar de artigos científicos para impulsionar a pesquisa mais rapidamente\", \"É difícil para as pessoas revisarem manualmente mais de 20.000 artigos e sintetizarem suas descobertas. Avanços recentes em tecnologia podem ser úteis aqui\".\nComo essa base de dados foi postada como um desafio no Kaggle, é uma ótima oportunidade para testar as habilidades adquiridas em cursos iniciais, e ainda aprender novas habilidades necessárias para resolver problemas reais. Entretanto, fazer essa transição entre um ambiente educacional e aquele que encontramos no Kaggle, que imita os desafios que devemos encontrar no mercado de trabalho, tende a ser um degrau muito grande, pois a natureza dos dados e dos problemas propostos aumenta de complexidade num nível que os cursos básicos não contemplam. Pensando nisso, este curso tem o objetivo de preencher essa lacuna na formação dos cientistas de dados, mostrando detalhadamente como abordar os desafios, passando pelas fases de exploração e tratamento de dados, escolha de abordagem de solução, construção de um modelo, treinamento e validação. O entendimento desse processo é o primeiro passo para que os competidores possam desenvolver melhorias e começar sua escalada rumo ao topo dos rankings.\nAlém da base de dados descrita acima, neste curso também focaremos em mais duas bases de dados relacionadas ao COVID-19. Com isso, o curso está dividido em três partes:\nRecuperação de informações de bases de dados de artigos: vamos usar a base de dados dos artigos científicos e aplicar várias técnicas de mineração de textos e processamento de linguagem natural, utilizando bibliotecas como NLTK (Natural Language Toolkit, spaCy, WordCloud e fuzzywuzzy. Focaremos na etapa de preparação e visualização dos textos, como por exemplo: contagem de termos frequentes, nuvem de palavras e aplicação de algoritmos para agrupamento, como o k-means! Implementaremos também sistemas de busca em textos que levam em consideração palavras-chave e similaridade entre documentos utilizando TF-IDF (Term Frequency - Inverse Document Frequency)\nPrevisões de mortes por COVID-19: utilizaremos outra base de dados do Kaggle para prever as mortes diárias, utilizando algoritmos de regressão\nDiagnóstico de pacientes com COVID-19 por meio do Raio-X do tórax: vamos utilizar modernas técnicas de Deep Learning com o TensorFlow 2.0, ou seja, redes neurais convolucionais e transferência de aprendizagem (transfer learning) para classificar imagens de pacientes doentes e saudáveis!\nOs códigos serão desenvolvidos utilizando a linguagem Python linha por linha e com o Google Colab, de forma que você entenda todas as análises necessárias para participar dessas competições!",
      "target_audience": [
        "Pessoas que já estejam num nível intermediário de sua formação em Ciência de Dados, e que agora estejam procurando aprender a usar suas habilidades em desafios reais",
        "Analistas de dados que queiram aumentar seu conhecimento na área de Machine Learning",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial",
        "Qualquer pessoa interessada em Inteligência Artificial"
      ]
    },
    {
      "title": "Chatgpt 5: A Inteligência Artificial e Muitas outras IAs",
      "url": "https://www.udemy.com/course/chatgpt35-openai-aprenda-a-usar-essa-poderosa-ferramenta/",
      "bio": "IAs, Chatgpt 5 Atualizado, Sora, Leonardo, Rendernet, Seaart, e outras ferramentas de IA. Atualizado constantemente.",
      "objectives": [
        "CHATGPT",
        "OUTRAS IA DISPONÍVEIS para fotos, vídeos, som, imagens",
        "Diferentes formas de uso e benefícios do CHATGPT",
        "Uso ético e responsável",
        "Limitações do Sistema",
        "Resolvendo Problemas",
        "Auxiliando em Estudos",
        "Auxiliando no trabalho",
        "Criando roteiros",
        "Escrevendo textos",
        "Obtendo novas ideias para seu projeto",
        "Resumos e Correção Gramatical",
        "Traduções",
        "Criando scripts para códigos de programação."
      ],
      "course_content": {},
      "requirements": [
        "Não é necessário"
      ],
      "description": "Atualizado Inteligencia Artificial, Chatgpt Openai IA e mais, muito mais. Com apostila.\nMais de 12 ferramentas. Várias Ferramentas de Inteligencia Artificial. Leonardo, Rundiffusion, TTsmaker, Sora, Seaart, Runway, Imagine, Rendernet e muitas outras.\nChatgpt Versão gratuita e ilimitada demonstrando toda sua pontencialidade.\nChatgpt Versão paga com novos recursos e o Dall-e - gerador de imagem através de texto e Sora\nCurso Avançado em Inteligência Artificial: Domine as Ferramentas do Futuro!\nSeja bem-vindo ao curso que está moldando o futuro da interação humano-máquina! Em nossa jornada, mergulharemos nas últimas inovações em Inteligência Artificial, explorando as versões mais recentes do ChatGPT da OpenAI.\nO Que Você Pode Esperar:\nAtualizações Constantes: Esteja à frente no campo em constante evolução da IA! Nosso curso é uma fonte dinâmica de conhecimento, atualizado regularmente para incorporar as últimas mudanças e adições nas ferramentas que moldarão o futuro.\nVariedade de Ferramentas: Além das estrelas principais, exploraremos outras IA disponíveis para fotos, vídeos, som e imagens. Amplie suas habilidades e descubra novas fronteiras da criatividade.\nDestaque do Conteúdo:\nInício Rápido: Desde a criação da conta até as nuances do login e senha, guiamos você passo a passo no uso eficiente das ferramentas.\nÉtica e Limitações: Aprenda a utilizar a IA de maneira ética, compreendendo suas limitações e desafios.\nCustos e Opções Gratuitas: Entenda os custos envolvidos para os interessados na opção paga.\nProjetos Prontos: Explore vários projetos prontos para aplicar suas habilidades recém-adquiridas em situações do mundo real.\nAplicações em Diversos Campos: Desde a criação de blogs até a preparação para vestibulares, explore uma ampla gama de aplicações práticas para a IA.\nPorque Esperar? Comece Agora a Transformação da Sua Jornada em Inteligência Artificial!",
      "target_audience": [
        "Desenvolvedores",
        "Python",
        "Estudantes",
        "Universitários",
        "Entusiastas de Inteligência Artificial"
      ]
    },
    {
      "title": "PyTorch 파이토치로 배우는 딥러닝 기초편",
      "url": "https://www.udemy.com/course/pytorch-u/",
      "bio": "초보자 한국어 튜토리얼부터 예제로 배우는 실습까지 누구나 쉽게 이해할 수 있는 Pytorch",
      "objectives": [
        "1. Pytorch를 통해 딥러닝을 이해 할 수 있다.",
        "2. Pytorch를 활용해 다양한 API를 호출 할 수 있다.",
        "3. 인공신경망의 기본원리를 배운다.",
        "4. 데이터 구성, 모델 학습, 모델 평가에 대한 방법을 Pytorch를 통해 실습한다."
      ],
      "course_content": {},
      "requirements": [
        "Python에 대한 기본 지식이 필요합니다."
      ],
      "description": "[강의 소개]\n본 과정에서는 인공지능의 기초 이론을 배우고 Pytorch를 통해 실습해 봅니다.\nPythorch로 딥러닝을 처음 배우는 비전공자 및 관련 업계에 관심이 있는 취업준비생도 딥러닝을 이해하고 다양한 API를 호출할 수 있게 됩니다.\n이번 강의를 통해 인공지능의 핵심 영역을 파악하여 개발자로서의 역량을 키워 봅시다!\n\n\n\n\n[본 강의를 수강해야 하는 이유]\n1. Pytorch를 통해 딥러닝을 이해 할 수 있다.\n2. Pytorch를 활용해 다양한 API를 호출 할 수 있다.\n3. 인공신경망의 기본원리를 배운다.\n4. 데이터 구성, 모델 학습, 모델 평가에 대한 방법을 Pytorch를 통해 실습한다.\n\n\n\n\n[본 강의의 대상]\n1. 인공지능에 대해 관심이 있는 사람 누구나\n2. Python에 대한 기본 지식이 있는 사람\n3. 딥러닝을 처음 배우는 비전공자 및 관련 업계에 관심이 있는 취업준비생\n\n\nPyTorch(파이토치)로 딥러닝의 필수사항과 기능들을 쉽게 배워봅시다!\n1강에서 뵙겠습니다.\n\n\n- ITGO",
      "target_audience": [
        "1. 인공지능에 대해 관심이 있는 사람 누구나",
        "2. Python에 대한 기본 지식이 있는 사람"
      ]
    },
    {
      "title": "AI dla programistów: ChatGPT od A do Z",
      "url": "https://www.udemy.com/course/chatgpt-od-a-do-z-ai-dla-programistow/",
      "bio": "AI to Twoje nowe narzędzie pracy - naucz się współpracować z AI i ChatGPT, by programować szybciej i mądrzej.",
      "objectives": [
        "Przykładowe pytania, które możesz zadać AI, aby uzyskać lepsze odpowiedzi",
        "Tworzyć dane i transferować je do kodu w wybranym przez Ciebie języku",
        "Jak prosić o kompromisowe rozwiązania i po co?",
        "Jak sprawić, by odpowiedź była bardziej przyjazna?"
      ],
      "course_content": {
        "Wstęp": [
          "Czym jest prompt? Kim jest prompt engineer?",
          "FAQ (Najczęściej Zadawane Pytania)"
        ],
        "Podstawy": [
          "Model AI: Wybieramy Optymalną Wersję dla Twoich Zadań",
          "Czym jest model AI? [dogłębna analiza dla ciekawych]",
          "Znaczenie KONTEKSTU w komunikacji i uczeniu się [SUPER WAŻNA LEKCJA]",
          "Przykłady precyzowania kontekstu [ĆWICZENIE]",
          "Pamięć AI",
          "Pamięć AI [NOTATKA]"
        ],
        "Kontrolowanie tonu odpowiedzi sztucznej inteligencji": [
          "Autorefleksja - pytanie do analizy",
          "Custom instruction | Personalizowanie odpowiedzi - BIO",
          "Tłumacz jak dla... [reguły i role]",
          "Tego Ci nie wolno! [ograniczenia]",
          "Naśladuj... [przykłady]",
          "Custom instructions [NOTATKA]"
        ],
        "Kontrola długości i formatu odpowiedzi": [
          "Kontrolowanie długości odpowiedzi sztucznej inteligencji",
          "Kontrolowanie formatu odpowiedzi",
          "Praktyczny przykład kontrolowania długości i formatu odpowiedzi",
          "Pytanie do pytania [SUPER przydatne]",
          "Krok po kroku...",
          "Inne przykłady formatowania"
        ],
        "Sztuka zadawania trafnych pytań": [
          "5 zasad trafnego pytania dla sztucznej inteligencji",
          "5 zasad trafnego pytania [NOTATKA]",
          "Jak sprawić, by to AI tworzyła pytania? Po co się męczyć? :-)",
          "Hej AI to Ty dbaj o kontekst..."
        ],
        "Uczymy się programowania z AI": [
          "Sensej Kodu - GPTs tłumaczący kod linia po linii",
          "Wykorzystaj GPT do Debugowania Kodu",
          "Tworzenie elegenackiego kodu z opisowymi nazwami zmiennych i metod",
          "Spraw, by ta część, była 'opcjonalna'",
          "O czym pamiętać tworząc programy?",
          "Tłumaczenie kodu z jednego języka na drugi...",
          "Dopasowywanie wzorców w formularzach - regex",
          "Pytaj o kompromisy - trade-offs",
          "Stosuj zasadę pareto by poznać 'śmietankę' wiadomości"
        ],
        "Odpalenie lokalnego modelu na własnym PC": [
          "Jak za darmo i offline korzystać z AI na komputerze?"
        ],
        "Visual Studio Code": [
          "Wtyczka nr 1, która jest darmowa i możesz w niej przetestować nawet GPT-4",
          "Edytowanie kodu z edytora, szybkie dodawanie kontekstu",
          "Inne darmowe pluginy AI"
        ],
        "GPTs": [
          "GPTs - czym jest?",
          "Jak praktycznie wykorzystać @mention?",
          "Wyszukiwarka GPTs",
          "GPTS: Youtube Summarizer",
          "GPTs: Mindmapy"
        ],
        "Różności": [
          "AI z dostępem do Internetu za darmo?!",
          "Tool dla programistów z GPT-4 i wyszukiwarką!",
          "Darmowy GPT-4 od Microsoftu!",
          "Arena - ranking modeli - szybkie spojrzenie na najlepsze modele",
          "Narzędzie do tworzenia kodu ze zdjęć",
          "Słuchawka"
        ]
      },
      "requirements": [
        "Podstawy programowania - nie musisz potrafić programować, jak napisałeś już hello world to odnajdziesz się w kursie :-)"
      ],
      "description": "Chcesz pisać kod szybciej, sprawniej i bez frustracji?\nZastanawiasz się, jak wykorzystać AI do programowania?\nTen kurs został stworzony właśnie dla Ciebie.\nCo zyskasz dzięki temu kursowi?\nTen praktyczny kurs pokaże Ci, jak używać ChatGPT do wsparcia programowania, niezależnie od języka, w którym kodujesz. Po jego ukończeniu:\nBędziesz pisać kod szybciej i pewniej\nNauczysz się efektywnego komunikowania się z AI\nZrozumiesz, jak uczynić z ChatGPT pełnoprawnego partnera w kodowaniu\n\n\nCzego się nauczysz?\nSzybki start z ChatGPT\nJak w kilka minut skonfigurować ChatGPT do współpracy z Tobą jako programistą?\nSztuka skutecznego promptowania\nDowiesz się, jak zadawać pytania, aby AI generowało dokładne i pomocne odpowiedzi. Każdy prompt to narzędzie – naucz się je tworzyć jak profesjonalista.\nZgłębianie wiedzy z zakresu programowania\nKorzystaj z wiedzy ChatGPT, by uczyć się nowych technologii, wzorców projektowych i algorytmów.\nDebugowanie z pomocą AI\nSzybkie znajdowanie i naprawianie błędów w kodzie dzięki analizie ChatGPT.\nPisanie czytelnego, eleganckiego kodu\nZobacz, jak ChatGPT może pomóc Ci uporządkować, uprościć i udokumentować kod.\nWspółpraca z AI\nDoświadcz, jak wygląda prawdziwe partnerstwo – Ty piszesz kod, a AI pomaga, podpowiada i wspiera Twoje decyzje.\nRóżne sposoby rozwiązania problemu\nOtrzymuj od ChatGPT alternatywne podejścia do zadań – ucz się, wybieraj i rozwijaj się.\n\n\nDla kogo jest ten kurs?\nDla każdego, kto programuje – niezależnie od poziomu.\nNieważne, czy dopiero zaczynasz przygodę z kodem, czy masz już lata doświadczenia – sztuczna inteligencja zrewolucjonizuje Twój workflow.\nTen kurs jest także dla osób, które chcą:\nnauczyć się jak działa ChatGPT w praktyce\nzyskać konkretną przewagę w codziennym programowaniu\nzrozumieć, jak skutecznie komunikować się z AI\nGWARANCJA\nPonad 350,000 uczy się już ze mną :)\nDołącz i Ty - bez ryzyka.\nMasz aż 30 dni na zwrot, jeśli kurs nie spełni Twoich oczekiwań – choć jestem przekonany, że je przewyższy.\nZanim kupisz – sprawdź darmowe lekcje i zobacz, jak wygląda współpraca z AI w praktyce.\nDOŁĄCZ TERAZ\ni odkryj, jak ChatGPT i AI mogą usprawnić Twoje programowanie już dziś.",
      "target_audience": [
        "Kurs dla początkujących programistów, którzy chcą usprawnić swój proces kodowania i nauki programowania."
      ]
    },
    {
      "title": "Custom GPT - Crie o seu próprio Chatbot com o GPT!",
      "url": "https://www.udemy.com/course/custom-gpt-crie-o-seu-proprio-chatbot-com-o-gpt/",
      "bio": "Aprenda do básico ao avançado sobre criação de Custom GPT, utilizando Capabilities e Actions com APIs",
      "objectives": [
        "Criação de GPT personalizado (Custom GPT)",
        "Configurações avançadas do Custom GPT",
        "Capabilities do GPT",
        "Utilização de Actions no Custom GPT",
        "Prompts para refinamento de instruções do bot",
        "Análise e geração de arquivos com GPT"
      ],
      "course_content": {
        "Introdução": [
          "Introdução do curso",
          "Apresentação do curso",
          "O que é Custom GPT?",
          "Custom GPT x GPT tradicional",
          "Loja de Custom GPT",
          "Criando o nosso primeiro Custom GPT",
          "Explorando a interface de criação",
          "Repositório do curso (arquivos)",
          "Link do repositório",
          "Download dos slides",
          "Conclusão",
          "Como aprender programação mais rápido e ter sucesso na carreira",
          "Teste para saber sua dificuldade com programação"
        ],
        "Fundamentos do Custom GPT": [
          "Introdução da seção",
          "Alterando o nome via prompt",
          "Alterando imagem do Custom GPT",
          "Salvando as alterações no seu Custom",
          "Voltando a tela de edição de Chat",
          "Excluindo o GPT",
          "Conclusão"
        ],
        "Configurações avançadas do Custom GPT": [
          "Introdução da seção",
          "Conhecendo a aba Configure",
          "Personalização avançada de instruções",
          "Alterando os conversation starters",
          "Utilizando Knowledge com Custom GPT",
          "Knowledge com arquivos JSON",
          "Informações exclusivas nas instruções",
          "Modos de compartilhamento",
          "Explorando o compartilhamento Everyone",
          "Avaliando e reportando Custom GPTs",
          "Limitando respostas",
          "Conclusão da seção"
        ],
        "Capabilities": [
          "Introdução da seção",
          "O que são capabilities?",
          "Web browsing",
          "Busca na web ou na Knowledge do GPT",
          "Capability para imagens",
          "Interpretando código e gerando arquivos no Custom GPT",
          "Conclusão da seção"
        ],
        "Actions (Acessando APIs pelo Custom GPT)": [
          "Introdução da seção",
          "O que são actions?",
          "Explorando a aba create new action",
          "Criando a chave da API",
          "Testando action com API",
          "URL da política de privacidade",
          "Informações adicionais do Custom GPT",
          "Conclusão da seção",
          "Construindo um Chatbot Personalizado com GPT"
        ],
        "Conclusão do curso": [
          "Fechamento e próximos passos"
        ]
      },
      "requirements": [
        "ChatGPT Plus - é obrigatório"
      ],
      "description": "Seja bem-vindo ao curso de Custom GPT!\n\n\nCom os conhecimentos aqui adquiridos você criará o seu próprio Chat GPT, para qualquer nicho ou público alvo. Você aprenderá a deixá-lo ainda mais inteligente, através de:\n\n\nPrompts avançados;\nConfigurações específicas;\nArquivos enviados ao GPT;\nConsultas a APIs;\ne muito mais!\nIsso deixará seu GPT ser mais específico, resolvendo os problemas que você tem, e não tão genérico como é o Chat GPT convencional. Permitindo que você crie chatbots para usos específicos, como por exemplo: aprender programação ou ajudar um cliente a escolher o produto que melhor lhe atende.\n\n\nSeu próprio ChatGPT também pode facilitar suas pesquisas no trabalho, estágio, faculdade, criação de conteúdo e assim ganhar tempo para desenvolver outras tarefas do seu dia.\n\n\nExploraremos juntos todos os recursos do Custom GPT, a nova ferramenta de criação de chatbots personalizados da OpenAI, alguns deles são:\n\n\nPrompts para refinar e selecionar respostas;\nKnowledege com diversos tipos de arquivos;\nConversation Starters;\nCapabilities (Web browsing, Dall-e, Code interpreter);\nActions (Acesso de APIs pelo Custom GPT);\nPadrão OpenAPI;\n\n\nAo longo do curso criaremos um projeto, onde implementaremos recursos no nosso chatbot a medida que aprendemos novas funcionalidades, tornando o processo 100% prático!\n\n\nTemos também uma equipe especializada para tirar qualquer dúvida sua sobre o curso, o acesso é vitalício e no fim você ganha um certificado de conclusão.\n\n\nEstá pronto para criar chatbots customizados e avançados? Te espero no curso!",
      "target_audience": [
        "Quem quer criar seu próprio Custom GPT",
        "Quem quer aprender sobre ChatGPT",
        "Estudantes de prompt engineering"
      ]
    },
    {
      "title": "Apprendre l'analyse et la visualisation de données en Python",
      "url": "https://www.udemy.com/course/apprendre-lanalyse-et-la-visualisation-de-donnees-en-python/",
      "bio": "Apprenez à analyser les données rapidement et facilement en Python en réalisant des projets réels.",
      "objectives": [
        "Avoir un niveau de compétence intermédiaire en programmation Python.",
        "Utilisez l'environnement de bloc-notes Jupyter.",
        "Utilisez la bibliothèque Numpy pour créer et manipuler des tableaux.",
        "Utilisez la bibliothèque Pandas pour bien créer et structurer des données.",
        "Apprenez à travailler avec divers formats de données en Python, notamment : CSV, HTML et MS Excel.",
        "Créez des visualisations de données à l'aide des bibliothèques Matplotlib et Seaborn en python.",
        "Apprenez la méthodologie d’analyse de données pour répondre à des problématiques précises",
        "Avoir un portefeuille de divers projets d'analyse de données",
        "Apprenez à nettoyer les données pour qu’elles soient exploitables"
      ],
      "course_content": {
        "Introduction": [
          "Installation d'Anaconda - Mac OS",
          "Installation d'Anaconda - Windows",
          "Prise en main du noteBook Jupyter"
        ],
        "La bibliothèque Numpy": [
          "Bienvenue à la section Numpy",
          "Introduction",
          "Création de vecteurs à partir de liste Python",
          "Création de matrices",
          "Création de tableaux de trois dimensions",
          "La fonction arange()",
          "Attributs principaux d'un objet array",
          "La méthode reshape()",
          "La méthode resize()",
          "Concaténation de deux tableaux",
          "Construction automatique de tableaux Numpy",
          "La fonction linspace()",
          "Création de tableaux aléatoires",
          "Méthodes de calcul sur les tableaux Numpy",
          "Indexation des tableaux Numpy - Partie 1",
          "Indexation des tableaux bidimensionnels",
          "Tableaux et opérateurs de comparaison",
          "Modifications des tableaux Numpy selon des conditions",
          "Binariser une matrice",
          "Opérations sur les tableaux unidimensionnels",
          "Opérations sur les matrices",
          "EXERCICES NumPy",
          "Corrigé des exercices Numpy - Partie 1 -",
          "Corrigé des exercices Numpy - Partie 2 -",
          "CONCLUSION"
        ],
        "La bibliothèque Pandas": [
          "Bienvenue à la section Pandas",
          "Introduction",
          "Les séries en Pandas",
          "Série Pandas comme dictionnaire",
          "Modification d'une série pandas",
          "Construction de Dataframes",
          "Créer un Dataframe à partir de plusieurs séries pandas",
          "Créer un Dataframe à partir d'une matrice Numpy",
          "Modifier un dataframe",
          "Sélectionner les données d'un Dataframe",
          "Sélectionner par tranche les données d'un Dataframe",
          "Sélection conditionnelle des données d'un Dataframe",
          "Sélection des données d'un Dataframe selon plusieurs conditions",
          "Réinitialisation et modification des indices dans un Dataframe",
          "Multindex",
          "Acceder à un dataframe multiindexé",
          "Création et accès aux données d'un dataframe multiindexé - Partie 2",
          "Combinaison de dataframes",
          "Groupement des données",
          "Tableaux croisés dynamiques",
          "Quelques opérations en Pandas",
          "Traitement des données manquantes",
          "EXERCICES 1: exploration des données des pays dans le monde",
          "CORRIGÉ DES EXERCICES 1",
          "EXERCICES 2"
        ],
        "Lecture et écriture des données à l'aide de Pandas": [
          "INTRODUCTION",
          "Lecture et écriture d'un fichier CSV",
          "Lecture et écriture d'un fichier Excel - Partie 1",
          "Lecture et écriture d'un fichier Excel - Partie 2",
          "Lecture d'une page HTML"
        ],
        "La bibliothèque Matplotlib": [
          "Bienvenue à la section Matplotlib",
          "Introduction",
          "Représentations graphiques avec Matplotlib",
          "Représentation graphique de type courbe",
          "Axes et titre d'une représentation graphique",
          "Réglage du tracé et des axes",
          "Figure, subplots et axes - Partie 1",
          "Figure, subplots et axes - Partie 2",
          "Exercice de création de parcelles",
          "Histogrammes",
          "Comparaison de plusieurs histogrammes",
          "Représentation graphique de type boite à moustaches",
          "Nuages de points et courbes en 3D",
          "Représentation en 3D des fonctions à deux variables"
        ],
        "La bibliothèque Seaborn": [
          "Bienvenue à la section Seaborn",
          "Introduction",
          "Représentation graphique d'une distribution de variables quantitatives",
          "La fonction seaborn.catplot()",
          "Représentation graphique d'une distribution de variable qualitative",
          "Croisement de deux variables quantitatives",
          "Croisement de deux variables qualitatives",
          "Croisement d'une variables quantitative et une variable qualitative",
          "Multivariables: croisement de trois variables",
          "Etude des corrélations",
          "Etude des corrélations - Partie 2",
          "Représentation d'un tableau croisé dynamique",
          "Régression linéaire"
        ],
        "PROJET 1: ANALYSE DES DONNÉES NETFLIX": [
          "Introduction",
          "Nettoyage des données et traitement des valeurs manquantes",
          "Analyse descriptive des données NETFLIX - Partie 1",
          "Analyse descriptive des données NETFLIX - Partie 2",
          "Analyse descriptive des données NETFLIX - Partie 3",
          "Analyse descriptive des données NETFLIX - Partie 4",
          "Analyse descriptive des données NETFLIX - Partie 5",
          "Analyse descriptive des données NETFLIX - Partie 6",
          "Analyse descriptive des données NETFLIX - Partie 7",
          "Analyse descriptive des données NETFLIX - Partie 8",
          "Analyse descriptive des données NETFLIX - Partie 9",
          "Analyse descriptive des données NETFLIX - Partie 10"
        ],
        "PROJET 2: ANALYSE DES DONNÉES DES UNIVERSITÉS AMÉRICAINES": [
          "Introduction",
          "Nettoyage des données et traitement des valeurs manquantes - Partie 1",
          "Nettoyage des données et traitement des valeurs manquantes - Partie 2",
          "Nettoyage des données et traitement des valeurs manquantes - Partie 3",
          "Analyse des données - Partie 1",
          "Analyse des données - Partie 2",
          "Analyse des données - Partie 3",
          "Analyse des données - Partie 4",
          "Analyse des données - Partie 5",
          "Analyse des données - Partie 6"
        ]
      },
      "requirements": [
        "Les bases en Python"
      ],
      "description": "Formation Complète : Analyse et Visualisation de Données avec Python\nMaîtrisez les Outils Essentiels de l’Analyse de Données et Donnez Vie à Vos Données\nVous souhaitez apprendre à manipuler, nettoyer, analyser et visualiser vos données en Python ? Vous cherchez une formation complète qui vous guide pas à pas avec des exemples concrets et des jeux de données réels ?\nCette formation est la référence en langue française pour devenir autonome en analyse de données et data visualisation avec Python.\nPourquoi suivre cette formation ?\nAujourd’hui, savoir analyser et visualiser des données est une compétence indispensable pour évoluer en data science, business intelligence, marketing digital ou tout domaine lié à la prise de décision basée sur les données.\nDans cette formation, vous apprendrez à maîtriser les bibliothèques Python les plus puissantes et les plus populaires :\nNumPy pour le calcul scientifique et les tableaux multidimensionnels.\nPandas pour la manipulation, le nettoyage et l’analyse avancée de données tabulaires.\nMatplotlib et Seaborn pour créer des visualisations impactantes et professionnelles.\nUn programme complet et progressif\nTout au long de la formation, vous travaillerez sur des projets réels et des datasets inspirants, tels que :\nL’analyse des données de Netflix.\nL’exploration des données des universités américaines.\nDes jeux de données variés pour pratiquer vos compétences.\nVoici quelques exemples de ce que vous allez apprendre :\nInstaller et utiliser Jupyter Notebook pour vos projets d’analyse.\nLire, filtrer, organiser et traiter des données avec Pandas DataFrames et Series.\nNettoyer les données et gérer les valeurs manquantes.\nFusionner, concaténer et agréger des datasets.\nRéaliser des analyses statistiques et des calculs avancés avec NumPy.\nCréer des visualisations claires et percutantes : courbes, histogrammes, boxplots, diagrammes circulaires.\nUtiliser Seaborn pour des graphiques élégants et interactifs.\nPour qui est cette formation ?\nCe cours s’adresse à :\nLes débutants en Python qui veulent se spécialiser en analyse de données.\nLes développeurs qui souhaitent ajouter une compétence en data analysis à leur profil.\nLes étudiants, professionnels, entrepreneurs qui veulent tirer parti de la puissance de Python pour exploiter leurs données.\nCe que vous allez obtenir :\nDes explications claires et progressives, même si vous débutez.\nPlusieurs projets complets basés sur des cas réels.\nDes exercices pratiques et des notebooks téléchargeables.\nUn accès illimité à vie et toutes les mises à jour futures.\nUn certificat de formation pour valoriser vos compétences sur votre CV et LinkedIn.\nPassez à l’action dès maintenant\nApprenez à analyser, interpréter et visualiser des données avec Python et devenez un professionnel de la data science prêt à relever les défis de demain.\nInscrivez-vous aujourd’hui et commencez votre parcours vers la maîtrise de l’analyse de données en Python.",
      "target_audience": [
        "Développeurs Python intéressés par l'analyse de données et sciences de données",
        "Intéressé par l’analyse de données",
        "Intéressé par la data science"
      ]
    },
    {
      "title": "Super Academia Data Science - 5 cursos em 1",
      "url": "https://www.udemy.com/course/super-academia-data-science/",
      "bio": "Tudo sobre Data Science reunido em um único lugar - Python, Visualização no Python, R e WEKA",
      "objectives": [
        "Entendendo o R",
        "Primeiros passos com o R",
        "Objetos no R",
        "Tipos de objetos: Matrizes, Listas",
        "Identificação de valores faltantes e especiais",
        "Salvar uma workspace",
        "Acesso pelo R-studio",
        "Entendimento dos diferentes tipos de pacotes",
        "Trabalhando com leitura de arquivos externos",
        "Lendo um arquivo na web",
        "Selecionando dados",
        "Gráficos (análise de dados e apresentação)",
        "Tipos de gráficos: Histogramas, Ramo e Folha, Box-plot, Gráfico de dispersão,Gráfico de barras, Setores",
        "Variáveis qualitativas: Nominais e Ordinais",
        "Análise univariada e bivariada",
        "Teste de uma distribuição normal",
        "Comparação de duas médias",
        "Regressão linear simples",
        "Mineração de dados com o R",
        "Instalação do R-studio e R",
        "Vetores,Data frames,Funções",
        "Workspace do r(área de trabalho)",
        "Leitura de uma workspace",
        "Pacotes do R",
        "Uso dos comandos library, intall package,require",
        "Leitura através do R-studio",
        "Sumarizando dados",
        "Uso dos conectores lógicos",
        "Exportando gráficos",
        "Programação: Comando FOR, Criando funções pelo R-studio, Uso de Estatísticas",
        "Variáveis quantitativas: Discretas e Continuas",
        "Teste de hipóteses",
        "Teste chi-quadrado para aderência",
        "Comparação de médias múltiplas pelo teste de Tukey",
        "Regressão linear múltipla",
        "Uso do Google Vis ( biblioteca gráfica do Google)",
        "Desenvolver programas usando a linguagem Python",
        "Manipular estruturas condicionais",
        "Mineração de arquivos com Python",
        "Manipular estruturas de repetição",
        "Realizar operações matemáticas usando Python",
        "Manipular strings",
        "Realizar operações lógicas",
        "Python",
        "Visualizar de dados com Python",
        "Conhecer a biblioteca MATPLOTLIB PYPLOT",
        "Construir gráficos de linhas, barras, dispersão e boxplot",
        "Contexto da Mineração de Dados - Descoberta de conhecimento em banco de dados, Aplicações práticas",
        "Entender o impacto da mineração de dados, Quais são os dados de entrada e saída na Mineração de Dados",
        "Aprender as técnicas de Mineração de Dados (Conceitos Básicos, Aprendizado de Máquina)",
        "Trabalhar com as técnicas: CLASSIFICAÇÃO, INDUÇÃO DE REGRAS, REGRAS DE ASSOCIAÇÃO, AGRUPAMENTO(CLUSTER) , REDES NEURAIS",
        "Utilizar os algoritmos: ÁRVORES DE DECISÃO, APRIORI, KMEANS,ETC",
        "Aprendizado Bayesiano (Operacionalização do conhecimento minerado e sua interpretação)",
        "Validação do conhecimento descoberto",
        "Aprendendo a utilizar o WEKA: uma ferramenta Java para Classificação, Associação, Clustering e Previsão",
        "Explanação de Interfaces Visuais para interpretação e divulgação do conhecimento (Mineração Visual)",
        "Entendimento e apresentação sobre MINERAÇÃO VISUAL- uso da biblioteca D3js",
        "Trabalhando Widget: Color, Distributions, Pivot Table",
        "Trabalhando Widget: Feature Statistics, Data Sample",
        "Trabalhando com Widget: Paint Data",
        "Trabalhando com Widget: Outliers ,Scatter Plot",
        "Trabalhando com: Create Class",
        "Trabalhando com: Select By data index",
        "Trabalhando com: Edit Domain",
        "Trabalhando com: Freeviz",
        "Trabalhando com: Árvore de Decisão",
        "Trabalhando com: Árvore de Decisão",
        "Trabalhando com: Cluster - Imagens"
      ],
      "course_content": {
        "Apresentação": [
          "Apresentação",
          "Conheça os instrutores",
          "Conheça a plataforma da Udemy",
          "INFORMAÇÕES IMPORTANTES - Leia antes de iniciar o curso"
        ],
        "Python básico": [
          "Introdução ao Python",
          "Instalando Python",
          "Instalando Python (prática)",
          "Resolvendo problemas na instalação",
          "Sublime text",
          "Google Colab (ambiente para desenvolvimento alternativo)",
          "Comentários",
          "Operações matemáticas",
          "Variáveis",
          "Operadores",
          "Operadores relacionais",
          "Estruturas condicionais",
          "Comando else",
          "Comando elif",
          "Estruturas de repetição",
          "Comando for",
          "Comando range",
          "Comando input",
          "Objetos",
          "Strings parte 1",
          "Strings parte 2",
          "Funções",
          "Arquivos",
          "Lista parte 1",
          "Lista parte 2",
          "Dicionários",
          "Dicionários (aula prática)",
          "Números aleatórios",
          "Tratamento de exceções"
        ],
        "Visualização de dados com Python": [
          "Introdução",
          "Gráfico de linhas",
          "Inserindo legendas em gráficos",
          "Gráfico de barras",
          "Comparando gráfico de barras",
          "Scatterplot",
          "Marcadores, cores e tipos de linhas",
          "Inserindo pontos em gráficos de linhas",
          "Documentação do MATPLOTLIB.PYPLOT",
          "Salvando figuras",
          "Estudo de caso: crescimento da população",
          "Crescimento da população",
          "O que é boxplot?",
          "Boxplot",
          "Estudo de caso: Bioinformática - comparando genomas",
          "Estudo de caso: Bioinformática - comparando genomas parte 1",
          "HTML",
          "Estudo de caso: Bioinformática - comparando genomas parte 2",
          "Estudo de caso: Bioinformática - comparando genomas parte 3",
          "Estudo de caso: Bioinformática - comparando genomas parte 4"
        ],
        "LINGUAGEM R - Operações com Dados": [
          "Apresentação do Curso e Instalação do R",
          "R-Studio, Trabalhando com operações básicas, Help do R, Trabalhando com Vetores",
          "Operações com Objetos do R, Trabalhando com Vetores",
          "Trabalhando com Matrizes",
          "Data Frame, Listas, Trabalhando com Workspace, Funções, Trabalhando com Pacotes",
          "Leitura de arquivos externos, Sumarizando Dados (medidas estatísticas)",
          "Gráficos no R: Histograma, Box-Plot, Ramo e Folhas, Barras, Setores",
          "Programação, Análise Uni e BI variada, Uso de Var. Qualitativas e Quantitativas",
          "Teste de Hipóteses e Regressão Linear e Múltipla",
          "Mineração de Dados e Google VIS",
          "Responda nossa pergunta"
        ],
        "ORANGE DATA SCIENCE 100% VISUAL": [
          "Entendendo o funcionamento da IDE do ORANGE",
          "Instalação do ORANGE",
          "Trabalhando com arquivos e utilizando: DATA TABLE, SELECT ROWS, SELECT COLUMNS",
          "Trabalhando Widget: Color, Distributions, Pivot Table, Feature Statistics, Data",
          "Trabalhando com Widget::Paint Data , Outliers ,Scatter Plot",
          "Trabalhando com: Create Class,Select By data index,Edit Domain",
          "Trabalhando com: Freeviz",
          "Trabalhando com Árvore de Decisão",
          "Trabalhando com: Cluster - Imagens",
          "Trabalhando com: Correlação",
          "Trabalhando com: Cluster – K-means",
          "Trabalhando com: Cluster - K-mens - Parte 02",
          "Final do ORANGE Data Science - Explorer, Visual - Roadmap ONE"
        ],
        "Mineração de Dados com WEKA": [
          "Entendendo Sobre Mineração de Dados",
          "Instalação da Ferramenta WEKA",
          "Entendendo as Tarefas de Mineração de Dados",
          "Algoritmos de Classificação - Parte 01",
          "Algoritmos de Classificação - WEKA - Parte 02",
          "Algoritmos de Classificação - WEKA - Parte 03",
          "Algoritmo de Agrupamento",
          "Algoritmo Redes Neurais e Agrupamento",
          "Mineração Visual dos Dados"
        ]
      },
      "requirements": [
        "Sem nenhum pré-requisito"
      ],
      "description": "As grandes empresas estão em busca de profissionais que saibam tratar e trabalhar dados, permitindo que novos insights sejam descobertos e aplicados ao seu negócio.\nCriamos a SUPER ACADEMIA DATA SCIENCE para facilitar a sua necessidade de aprender as tecnlogias que estão atualmente sendo utilizadas pelas corporações. Destacamos PYTHON, R e WEKA neste cenário\n\n\nR\nNo Nosso curso de Linguagem R o objetivo principal é permitir que aspectos básicos com ênfase no entendimento da linguagem R como sua estrutura e a forma de operação sejam compreendidos. O curso foi preparado e estruturado para que desde o iniciante até o mais avançado em técnicas estatísticas aprenda a trabalhar com a ferramenta R. O material pode ser acompanhado utilizando o R instalado em outros sistemas operacionais, tal como Windows ou Linux.\nDurante o curso, o aluno terá que assistir as videoaulas e praticar diretamente no seu computador.\nA ementa sumarizada é:\nO que é a Linguagem R, Instalação da Ferramenta, Aprimoramento do Uso do R-Studio, Entendimento do Uso dos Objetos no R (Vetor, Matriz, Data Frame, Lista e Funções),Uso de Pacotes no R, Leitura de Arquivos no R, Sumarizando Dados, Gráficos com o R, Análise Estatística e o Uso Geral da Estatística, Uso de componentes como Mineração de Dados e o GOOGLE VIS.\nTodo o curso de Linguagem R tem MATERIAL PRÓPRIO, um texto com tudo passo a passo, único e bem articulado.\nVocê entenderá os algoritmos e poderá praticar com suas bases de dados, seja arquivo texto ou banco de dados.\nORANGE\nO ORANGE é uma das poucas ferramentas de mercado, totalmente construida em python, que o analista de dados  pode trabalhar de forma totalmente visual, com um amplo aspecto de atendimento a diversas demandas na área de mineração de dados por meio do uso de  algoritmos de Machine Learning.\nASPECTOS PRESENTES:\nAprendizado de máquina de código aberto e visualização de dados para iniciantes e especialistas. Fluxos de trabalho de análise de dados interativos com uma grande caixa de ferramentas\nexecute análise de dados simples com visualização inteligente de dados. Explore distribuições estatísticas, gráficos de dispersão ou mergulhe mais fundo com árvores de decisão, agrupamentos hierárquicos. Até seus dados multidimensionais podem se tornar sensíveis em 2D, especialmente com classificações e seleções inteligentes de atributos.\nExploração interativa de dados para análise qualitativa rápida com visualizações limpas. A interface gráfica do usuário permite que você se concentre na análise exploratória de dados em vez codificação, enquanto padrões inteligentes tornam extremamente fácil a criação rápida de protótipos de um fluxo de trabalho de análise de dados. Coloque widgets na tela, conecte-os, carregue seus conjuntos de dados e colete os insights!\nUse vários complementos disponíveis no Orange para extrair dados de fontes de dados externas.\nWEKA\nAtualmente, a mineração de dados se mostra fundamental para a descoberta de novas informações e conhecimento, formatados em regras e padrões, a partir de grandes bases de dados. Nesta perspectiva, torna-se importante o desenvolvimento de um raciocínio crítico acerca dos principais conceitos, problemas e algoritmos relacionados à área de mineração de dados. Esta abordagem visa uma sintonia com as tendências empregadas atualmente no mercado no uso desta tecnologia de modo a preparar o futuro profissional a avaliar e, sobretudo, facilitar seu entendimento no  emprego de metodologias e tecnologias avançadas.\nO curso aborda o tema Mineração de Dados, através de aulas práticas e teóricas, utilizando-se de técnicas avançadas de descoberta de conhecimento, os quais provém a capacidade de descobrir novas informações, formatadas em regras e padrões, oriundas da análise de grandes bases de dados. Nesta perspectiva, o desenvolvimento de um raciocínio crítico acerca dos principais conceitos, problemas e algoritmos relacionados a área de Mineração de Dados é a principal habilidade adquirida por quem conclui o curso.\n\nO conteúdo visto é praticado na ferramenta WEKA, que é gratuita e de fácil entendimento.\nSão 6 laboratórios totalmente práticos que você pode realizar durante o curso, detalhados e explicados passo a passo.\n\nVocê entenderá os algoritmos e poderá praticar com suas bases de dados, seja arquivo texto ou banco de dados.\nContará com um Framework integrado que apresenta os resultados estatísticos.\nPYTHON\nNeste curso você também verá Python. Python é uma linguagem de programação de alto nível que vem sendo adota em todas as grandes universidades do mundo todo. Neste curso você aprenderá conceitos básicos da linguagem Python, como estruturas condicionais e de repetição, manipulação de strings, listas e arquivos. Tudo isso apresentado com uma metodologia simples, direta e sem enrolação.",
      "target_audience": [
        "Estudantes, Profissionais da área de dados, Estatísticos",
        "Programadores Python interessados em aperfeiçoar seus conhecimentos"
      ]
    },
    {
      "title": "Tableau Desktop - Intermediário - Business Intelligence",
      "url": "https://www.udemy.com/course/tableau-desktop-intermediario-rwalter/",
      "bio": "O curso intermediário de Tableau para Business Intelligence e Visualização de Dados!",
      "objectives": [
        "Joins, Union, Blending, Relacionamentos",
        "Heatmap, Totalizadores, Hierarquias, Gráfico de Eixo Duplo e Cálculos de Tabela",
        "Linhas e Faixas de Referência",
        "Distribuição de Referência",
        "Gráficos de Caixa",
        "Mapas com múltiplas camadas",
        "Cálculos de Tabela e Level of Detail (LOD) - FIXED, INCLUDE e EXCLUDE",
        "Dashboards interativos com uso de Ações, Ações de Destaque, direcionamento para URL, alteração de Parâmetros e Sets",
        "Compartilhamento e recursos do Server",
        "Compartilhamento de dashboards por e-mail",
        "Layouts para uso de dashboards no celular",
        "Parâmetros, Grupos, Conjuntos e Storytelling",
        "Fluxo de Caixa com Waterfall Charts"
      ],
      "course_content": {
        "Preparação de Ambiente para Tableau Desktop": [
          "Instalação do Tableau Desktop",
          "Criação de conta no Tableau Online"
        ],
        "Conexão e Preparação dos Dados": [
          "Conexão com Planilhas Excel",
          "Conexão com Google Sheets",
          "Conexão Em tempo real vs Extração",
          "O que são Joins? Inner Join",
          "Left, Right e Outer Join",
          "Join na nossa base de dados",
          "Union",
          "Blending",
          "Relacionamentos",
          "Campos Calculados nos Relacionamentos e Joins",
          "Viz da Seção: Market Basket Analysis"
        ],
        "Heatmap, Totalizadores, Hierarquias, Gráfico de Eixo Duplo e Cálculos de Tabela": [
          "Heatmap",
          "Totais e Subtotais de Tabelas",
          "Possíveis melhorias no Heatmap",
          "Hierarquias",
          "Gráfico de Eixo Duplo",
          "Rótulos individuais",
          "Cálculos de tabela rápida para totais acumulados, percentual do total e mais",
          "Linha de Referência e Faixas de Referência",
          "Distribuição de Referência",
          "Gráficos de Caixa",
          "Viz da Seção: Fluxo de Caixa Líquido"
        ],
        "Mapas": [
          "Mapas com múltiplas camadas",
          "Ajuste de locais",
          "Marcador de Destaques",
          "Viz da Seção: Mapa de Acidentes"
        ],
        "Cálculos de Tabela e Level of Detail (LOD)": [
          "Cálculos de Tabela Rápido",
          "FIXED",
          "EXCLUDE",
          "INCLUDE",
          "Viz da Seção: KPIS + Sparklines"
        ],
        "Dashboards Interativos": [
          "Montar o Dashboard",
          "Visualizações como filtros, e como ignorá-las?",
          "Configurações das Ações",
          "Configurações das Ações - Hover, Select, Menu",
          "Ações de Destaque, direcionar para URL, alteração de Parâmetros e Sets",
          "Viz da Seção: Avaliações de Celulares na Amazon"
        ],
        "Compartilhamento e recursos do Server": [
          "Montar o Dashboard e Publicação do Dashboard no Tableau Online",
          "Exibições, Alertas, Métricas, Comentários e Downloads",
          "Inscrição e acompanhamento por e-mail",
          "Compartilhamento e Tableau Embedded",
          "Publicação de fontes de dados e Agendamento das extrações",
          "Viz da Seção: Dashboard no seu bolso"
        ],
        "Parâmetros, Grupos, Conjuntos e Storytelling": [
          "Parâmetros como Filtros",
          "Parâmetros como Campo Calculado",
          "Grupos",
          "Conjuntos",
          "Storytelling",
          "Viz da Seção: San Francisco Salaries Simulator"
        ]
      },
      "requirements": [
        "Sistema operacional Windows ou OS X",
        "Conexão com Internet"
      ],
      "description": "O propósito desta curso é desenvolver as suas habilidades de Tableau adquiridas no nosso curso básico! O meu objetivo é prover para você um tutorial abrangente, mas simples de entender, e que demonstra todos os passos necessários para que você possa desenvolver seus dashboards e evoluir para um nível pleno de domínio e se consolidar no mundo de analytics :)\nO Tableau é uma das plataformas de BI e visualização de dados mais populares do mundo e uma ferramenta poderosa para analistas das diferentes áreas de negócios, cientistas de dados e profissionais de Business Intelligence.\nEste é um curso super prático, projetado para ensiná-lo os melhores recursos para você criar seus conteúdos e compartilhá-los em um ambiente corporativo.\nComeçaremos com uma introdução rápida à plataforma Tableau e, em seguida, conectaremos o nosso conjunto de dados. A partir daí, vamos explorar recursos para desenvolvimento de visualizações, filtragem e agrupamento, definiremos cálculos e parâmetros personalizados, e finalmente, vamos aprender formas muito valiosas de compartilhar os seus conteúdos com os usuários!\n\n\nOs conteúdos serão abordados com alguns cases que você pode adicionar ao seu portfólio, como Market Basket Analysis, Fluxo de Caixa com Waterfall chart, Avaliações de Celulares na Amazon, Mapa de Acidentes, KPIS + Sparklines, Dashboards no celular e San Francisco Salaries Simulator.\n\n\nAo final do curso, você terá um conhecimento completo do Tableau e poderá se sentir seguro e confiante para adicionar novas habilidades ao seu currículo profissional.\n\n\nEspero que você possa tirar o maior proveito deste curso e se desenvolver como profissional!\nBom curso! :D",
      "target_audience": [
        "Pessoas das diversas áreas de negócio",
        "Desenvolvedores de Business Intelligence",
        "Analistas de Dados",
        "Cientistas de Dados",
        "Pessoas que queiram aprender sobre Visualização de Dados"
      ]
    },
    {
      "title": "Corso pratico di Machine Learning con R",
      "url": "https://www.udemy.com/course/corso-pratico-di-machine-learning/",
      "bio": "Inizia la tua carriera di Data Scientist imparando a costruire modelli di regressione, classificazione e clustering.",
      "objectives": [
        "Realizzare modelli di Machine Learning in autonomia, per problemi di classificazione, regressione e clustering, sia in casi supervisionati che non",
        "Saprai come usare algoritmi di Linear Regression (semplice, multipla e non lineare), Logistic Regression, LDA, QDA, KNN e K-Means",
        "Imparerai a valutare i risultati di un modello di Machine Learning",
        "Saprai come scegliere il modello di Machine Learning più appropriato per il caso in esame",
        "Imparerai ad usare il linguaggio di programmazione R in RStudio"
      ],
      "course_content": {
        "Benvenuto": [
          "Benvenuti!",
          "Obiettivi del corso"
        ],
        "Il tuo primo modello di Machine Learning": [
          "Installazione strumenti",
          "Dati",
          "Modello",
          "Training",
          "Previsioni",
          "Un modello di ML in 4 passi",
          "Il tuo primo modello di Machine Learning in R"
        ],
        "Panoramica sul Machine Learning": [
          "Presentazione della Sezione",
          "Cosa è il Machine Learning?",
          "Casi d'uso reali",
          "Tipi di Machine Learning - per apprendimento",
          "Tipi di Machine Learning - per output",
          "Algoritmi",
          "Gli Errori nel Machine Learning",
          "Gli Errori nel Machine Learning - Bias e Varianza",
          "Panoramica sul Machine Learning"
        ],
        "Simple Linear Regression": [
          "Introduzione alle Sezioni sulla Regressione",
          "Altri modelli di Machine Learning",
          "Comando lm - input",
          "Comando lm - output",
          "SLR - Definizione",
          "SLR - Modello",
          "SLR - Minimi Quadrati",
          "Significato dei coefficienti",
          "Intervalli di confidenza",
          "Riepilogo Finale",
          "Simple Linear Regression"
        ],
        "Multiple Linear Regression": [
          "Introduzione alla Sezione",
          "Definizione MLR",
          "Importare dati da fonti esterne",
          "Breve esplorazione del dataset",
          "Inizia il viaggio",
          "Un modello di MLR",
          "Confronto tra 4 modelli",
          "Interpretazione del modello di MLR",
          "Multiple Linear Regression",
          "Qual è il modello migliore per prevedere le vendite?"
        ],
        "Interazione nella Multiple Regression": [
          "Aldilà di un grande potere",
          "Come implementare le Sinergie in R",
          "La formula delle Sinergie",
          "Altri modelli",
          "Il p-value",
          "Interazione nella MLR"
        ],
        "Non linearità nella Multiple Regression": [
          "Descrizione delle non linearità nella MLR",
          "Come costruire un modello quadratico in R",
          "Come rappresentare un modello quadratico in R",
          "[bonus] Come studiare 10 modelli in una volta sola!",
          "Trattazione teorica delle non linearità",
          "Non Linearità nella Multiple Linear Regression"
        ],
        "Scelta delle Variabili": [
          "Contesto della Scelta delle Variabili",
          "Numero di variabili",
          "Significatività e p-value",
          "Numero Modelli",
          "Metodo Forward",
          "Metodo Backward",
          "Metodo Ibrido",
          "Scelta Finale",
          "Scelta delle variabili"
        ],
        "Valutazione del Modello - Parte 1": [
          "Valutare un modello",
          "Test Error",
          "Metodi Indiretti",
          "AIC",
          "Non solo BIC",
          "Due modi per calcolare il Cp di Mallows",
          "Forward e Backward in un colpo solo!",
          "Valutazione del Modello - Parte I"
        ],
        "Valutazione del Modello - Parte 2": [
          "L'importanza della Cross Validation",
          "Validation Set 1 - Calcolo MSE",
          "Validation Set 2 - Calcolo Ripetuto",
          "Validation Set 3 - Plot e Limiti",
          "Leave One Out Cross Validation",
          "LOO CV in R",
          "I limiti della LOO CV",
          "k-fold Cross Validation",
          "I vantaggi della k-fold CV",
          "Come eseguire la k-fold CV in R",
          "Valutiamo n modelli con un ciclo \"for\"",
          "Come visualizzare i risultati della k-fold CV",
          "Valutazione del Modello - Parte II",
          "Predire l'età di un albero dalla sua altezza",
          "Chi è Grande?"
        ]
      },
      "requirements": [
        "Un computer su cui installare R e RStudio (free)",
        "Propensione al pensiero algoritmico",
        "Conoscenza di base della statistica descrittiva (concetti di media, deviazione standard, ...) e della notazione matematica (sommatoria, uso degli indici, …)",
        "Una minima esperienza di programmazione (con qualsiasi linguaggio) aiuterà ad avanzare nel corso più velocemente"
      ],
      "description": "Questo corso ha un solo focus: abilitare all'uso del Machine Learning in R.\n\nTutto dunque orbita attorno all'obiettivo di consentire agli studenti di realizzare i loro modelli di Machine Learning in autonomia, usando R. Per raggiungere questo risultato sono stati inseriti molti tutorial, dove si eseguono tutti i passi uno alla volta. Al tempo stesso ci sono delle sessioni teoriche che consentono di capire i principi dietro i vari algoritmi o strategie.\nCon questo corso imparerai i principi alla base del Machine Learning, gli algoritmi più diffusi ed i comandi R per poter creare modelli sia per problemi di Regressione, sia di Classificazione, sia di Clustering.\nCiò che distingue spesso un Data Scientist mediocre da uno eccellente è la sua capacità di valutare e scegliere i modelli migliori. Per questo motivo nel corso verranno insegnate e messe in pratica tecniche specifiche proprio per fare questo.\nNel complesso presenteremo ed utilizzeremo 8 diversi algoritmi, potrai seguire più di 11 ore di video suddivise in oltre 120 lezioni. Avrai inoltre a disposizione quasi 300 pagine di slide in formato pdf che potrai scaricare divise per sezioni e consultare in ogni momento. Anche il codice sorgente degli script R che realizzeremo durante il corso sarà a tua disposizione, e potrai scaricarlo ed usarlo nella tua console di R. Infine, per facilitare l'apprendimento, ho realizzato degli appositi Quiz di fine Sezione. Grazie ai Quiz potrai ricordare più facilmente quanto studiato durante la Sezione e quindi imparare di più e meglio ;)\nCon questo corso apprenderai quelle competenze concrete che ti servono per applicare il Machine Learning a problemi reali.\nSpero di vederti presto nel corso!\nLuca-",
      "target_audience": [
        "Chi vuole diventare un Data Scientist, ed ha bisogno di sviluppare la parte di Machine Learning",
        "Data Scientist Junior che vogliono rafforzarsi nel Machine Learning e R",
        "Chiunque voglia creare sistemi di Machine Learning, anche senza diventare un Data Scientist",
        "Chi vuole capire i principi del Machine Learning in maniera pratica e concreta",
        "Chi vuole imparare ad usare R per fare Machine Learning"
      ]
    },
    {
      "title": "【한글자막】 Python 의 모든 것: 실전 문제로 배우는 파이썬",
      "url": "https://www.udemy.com/course/best-python-data-science/",
      "bio": "파이썬 프로그래밍 코스 | 통계적 분석과 데이터 마이닝 및 Seaborn데이터 시각화 학습",
      "objectives": [
        "파이썬 상에서 프로그래밍하는 법",
        "Jupyter Notebook 상에서 코드 완성하는 법",
        "프로그래밍의 핵심 원리",
        "변수 생성하는 법",
        "정수형, 실수형, 논리연산, 문자열 등의 파이썬 데이터 타입",
        "while 루프 및 for 루프 생성하는 법",
        "파이썬 패키지 설치법",
        "큰 수의 법칙에 대한 이해"
      ],
      "course_content": {
        "강의에 오신 것을 환영합니다!": [
          "도전을 환영합니다!",
          "파이썬 설치하기 (Windows & MAC)",
          "보너스: 학습 경로",
          "추가 자료"
        ],
        "주요 프로그래밍 원칙": [
          "변수의 종류",
          "변수 사용하기",
          "불리언 변수와 연산자",
          "\"While\" 루프",
          "\"For\" 루프",
          "\"If\" 문",
          "파이썬에서 코드 들여쓰기",
          "주요 내용 복습",
          "과제: 큰 수의 법칙",
          "Core Programming Principles"
        ],
        "파이썬의 핵심": [
          "리스트가 무엇인가요?",
          "리스트 만들기",
          "[ ]를 사용해 데이터 읽기",
          "슬라이싱하기",
          "파이썬의 튜플",
          "파이썬의 함수",
          "파이썬의 패키지",
          "파이썬의 넘파이와 배열",
          "배열 슬라이싱하기",
          "주요 내용 복습",
          "과제: 재무제표 분석",
          "Fundamentals of Python"
        ],
        "행렬": [
          "프로젝트 미리보기: 농구 트렌드",
          "행렬",
          "첫 행렬 만들어보기",
          "파이썬의 딕셔너리",
          "행렬의 연산",
          "첫 시각화",
          "확장적 시각화",
          "처음으로 함수 만들어보기",
          "심화 함수 디자인하기",
          "프로농구 통계를 통한 인사이트",
          "주요 내용 복습",
          "과제: 농구 자유투",
          "Matrices"
        ],
        "데이터 프레임": [
          "파이썬으로 데이터 불러오기",
          "데이터 세트 탐색하기",
          "데이터 프레임 열 이름 바꾸기",
          "Pandas에서 데이터 프레임 부분 집합 구하기",
          "데이터 프레임의 기본 연산",
          "데이터 프레임 필터링하기",
          ".at()와 .iat() 사용하기 (심화 튜토리얼)",
          "Seaborn에 대해서",
          "Seaborn으로 시각화 Part1",
          "파이썬의 키워드 인자 (심화 튜토리얼)",
          "주요 내용 복습",
          "과제: 전 세계 트렌드",
          "Data Frames"
        ],
        "시각화 심화 과정": [
          "범주형 데이터 타입이란?",
          "조인트 그래프 이용하기",
          "히스토그램",
          "파이썬에서의 누적 히스토그램",
          "커널 밀도 추정 만들기",
          "Subplot 함수의 기능과 사용방법",
          "바이올린 플롯 vs 박스 플롯",
          "패싯 그리드 만들기",
          "좌표 및 대각선",
          "보너스: 파이썬에서 대시보드 구축하기",
          "보너스: 대시보드 스타일링 팁",
          "보너스: 마지막 작업",
          "주요 내용 복습",
          "과제: 영화 수익 비율",
          "Advanced Visualization"
        ],
        "과제 풀이법": [
          "과제 풀이법 섹션 2: 큰 수의 법칙",
          "과제 풀이법 섹션 3: 재무제표 분석 (파트 1)",
          "과제 풀이법 섹션 3: 재무제표 분석 (파트 2)",
          "과제 풀이법 섹션 4: 농구 자유투",
          "과제 풀이법 섹션 5: 세계 동향 (파트 1)",
          "과제 풀이법 섹션 5: 세계 동향 (파트 2)",
          "과제 풀이법 섹션 6: 영화 수익 비율 (파트 1)",
          "과제 풀이법 섹션 6: 영화 수익 비율 (파트 2)",
          "감사 비디오 메시지"
        ],
        "축하합니다!! 상품을 잊지 마세요 :)": [
          "챌린지를 완료하신 것을 진심으로 축하드립니다!",
          "보너스: 최고 연봉을 잠금 해제하는 방법 (라이브 교육)",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "사전 지식이나 경험이 필요하지 않습니다. 오직 열정만 가지고 시작하세요!"
      ],
      "description": "초보부터 중급까지 실제사례로 파이썬 배우기!\n이전에 배운 내용을 기반으로 다음 강의를 진행하는 촘촘한 커리큘럼!\n스스로 풀어보는 연습문제로 분석하는 힘을 길러보세요!\n\n\nPython 의 모든 것: 실전 문제로 배우는 파이썬 강의를 선택해야 하는 이유\n파이썬으로 프로그래밍하고 싶으신 분들, 복잡한 파이썬 강의에 배우기를 포기하셨던 분들, 실전으로 파이썬을 배우고 싶으신 분들을 위해서 이 코스를 만들었습니다. 사전 지식이나 경험이 전혀 필요하지 않습니다. 오직 열정만 가지고 시작하세요!\n\n\n세상에는 이미 많은 파이썬 강의들이 있습니다.\n그러나, 수강생들은 파이썬의 방대한 학습량에 종종 좌절하고는 하죠. 이 강의는 다릅니다!\n차근차근 배워나갈 수 있는 강의입니다. 매 강의는 이전에 배운 내용을 기반으로 한 발짝씩 더 나아갑니다.\n\n\n따라서, 강의에서 배운 개념을 실전에서 바로 적용할 수 있게 됩니다. 가장 중요한 건, 실제 사례를 통해 배운다는 점입니다.\n\n\n풍부한 실생활 예제를 통해 분석하는 힘을 기를 수 있을 겁니다. 강의 중에 함께 예제를 풀거나, 여러분 스스로 과제를 완성하면서 말이죠.\n한 마디로, 이 강의는 모두에게 열려있습니다. 프로그래밍이나 통계학에 대한 경험이 없어도 쉽게 배우실 수 있을 거예요!\n\n\n\n\nPython 의 모든 것: 실전 문제로 배우는 파이썬 강의에는 이런 개념을 담고 있습니다\n• 프로그래밍의 핵심 원리\n• 변수 생성하는 법\n• Seaborn 데이터 시각화하는 법\n• 히스토그램, 커널 밀도 그래프, 바이올린 그래프 생성 및 스타일 바꾸는 법\n• 정수형, 실수형, 논리연산, 문자열 등의 파이썬 데이터 타입\n• while 루프 및 for 루프 생성하는 법\n• 등 그 외 다수\n\n\n물리학과 수학 그리고 데이터 사이언스 강사 Kirill Eremenko의 한마디!\n한국 수강생 여러분들, 안녕하세요?\n실전으로 배우는 파이썬 프로그래밍 코스에 오신 것을 환영합니다!\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n데이터 사이언스 업계에서 역량을 더욱 마음껏 발휘할 수 있도록 파이썬의 모든 것을 배워보세요!\n강의에서 만나뵙길 기대합니다.\n\n\n진심을 담아,\nKirill Eremenko",
      "target_audience": [
        "파이썬으로 프로그래밍하고 싶으신 분들",
        "복잡한 파이썬 강의에 배우기를 포기하셨던 분들",
        "실전으로 파이썬을 배우고 싶으신 분들",
        "다양한 도전을 원하시는 분들",
        "한 섹션마다 과제를 열심히 해낼 수 있는 분들"
      ]
    },
    {
      "title": "【AI 자막】 LLM 엔지니어링 : AI 인공지능 및 대규모 언어 모델 및 에이전트 마스터하기!",
      "url": "https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models-korean/",
      "bio": "8주 만에 LLM 엔지니어 되기: 8개의 LLM 애플리케이션을 구축하고 배포하며 생성형 AI와 핵심 이론 개념을 마스터합니다.",
      "objectives": [
        "프로젝트 1: 기업 웹사이트를 지능적으로 스크래핑하고 탐색하여 AI 기반 브로셔 생성기를 제작합니다.",
        "프로젝트 2: UI 및 기능 호출을 지원하는 항공사용 멀티모달 고객 지원 에이전트를 구축합니다.",
        "프로젝트 3: 오픈 소스 및 폐쇄 소스 모델을 활용하여 오디오에서 회의록과 실행 항목을 생성하는 도구를 개발합니다.",
        "프로젝트 4: Python 코드를 최적화된 C++로 변환하여 성능을 60,000배 향상시키는 AI를 제작합니다.",
        "프로젝트 5: RAG을 활용해 회사와 관련된 모든 내용을 전문가 수준으로 이해하는 AI 지식 근로자를 개발합니다.",
        "프로젝트 6: 캡스톤 파트 A – Frontier 모델을 활용해 간단한 설명으로부터 제품 가격을 예측합니다.",
        "프로젝트 7: 캡스톤 파트 B – Frontier 모델과 경쟁할 수 있도록 미세 조정된 오픈 소스 모델을 활용해 가격 예측을 실행합니다.",
        "프로젝트 8: 캡스톤 파트 C – 여러 에이전트가 협력하며 특가 상품을 발견하고 알림을 제공하는 자율 멀티 에이전트 시스템을 구축합니다.",
        "주어진 비즈니스 문제에 대해 LLM을 선택, 학습, 적용하여 전체 솔루션을 설계하고 개발합니다.",
        "RAG, 미세 조정, 에이전틱 워크플로우와 같은 최신 기술을 비교하고 대조하여 LLM 솔루션의 성능을 개선합니다.",
        "최신 Frontier 모델 10개와 오픈 소스 LLM 10개를 평가하여 주어진 작업에 가장 적합한 선택을 할 수 있도록 합니다."
      ],
      "course_content": {
        "1주차 - 첫 번째 LLM 제품 구축: 주요 모델 및 Transformer 탐색": [
          "1일차 - LLM 엔지니어링에 바로 뛰어들기",
          "1일차 - Windows 및 Mac에서 로컬 LLM 배포를 위해 Ollama 셋업하기",
          "1일차 - 로컬 LLM의 힘을 발휘하기: Ollama를 사용하여 스페인어 튜터 만들기",
          "1일차 - LLM 엔지니어링 로드맵: 8주 만에 초보에서 마스터로",
          "1일차 - LLM 애플리케이션 구축: 챗봇, RAG, 에이전틱 AI 프로젝트",
          "1일차 - 월스트리트에서 AI의 세계로: Ed Donner가 LLM 엔지니어가 된 여정",
          "1일차 - 여러분의 LLM 개발 환경 설정: 툴과 모범 사례",
          "1일차 - Mac 셋업 가이드: LLM 프로젝트를 위한 Jupyter Lab과 Conda",
          "1일차 - LLM 엔지니어링을 위한 Anaconda 설정: Windows 설치 가이드",
          "1일차 - LLM 프로젝트를 위한 대체 Python 설정: Virtualenv vs. Anaconda 가이드",
          "1일차 - LLM 개발을 위한 OpenAI API 설정: 키, 가격 및 모범 사례",
          "1일차 - API 키를 안전하게 저장하기 위한 .env 파일 생성",
          "1일차 - 즉각적인 만족 프로젝트: AI 기반 웹 페이지 요약기 만들기",
          "1일차 - OpenAI의 GPT-4와 Beautiful Soup을 사용한 텍스트 요약 구현",
          "1일차 - 1일차 마무리: LLM 엔지니어링의 기억해갈 키 포인트와 다음 단계",
          "2일차 - LLM 엔지니어링 마스터하기: AI 개발을 위한 핵심 기술과 도구",
          "2일차 - Frontier 모델 이해하기: GPT, Claude, 오픈 소스 LLM",
          "2일차 - Ollama를 사용한 로컬 LLM 추론 방법: Jupyter를 활용한 Python 튜토리얼",
          "2일차 - 실습 LLM 작업: 텍스트 요약을 위한 OpenAI와 Ollama 비교",
          "3일차 - Frontier AI 모델: GPT-4, Claude, Gemini, LLAMA 비교",
          "3일차 - 주요 LLM 비교: 강점과 비즈니스 응용점",
          "3일차 - GPT-4와 O1 Preview 비교: 성능의 주요 차이점",
          "3일차 - 창의성과 코딩: GPT-4o의 캔버스 기능 활용하기",
          "3일차 - Claude 3.5의 정렬 및 아티팩트 생성: 심층 분석",
          "3일차 - AI 모델 비교: 기발하고 분석적인 작업을 위한 Gemini vs Cohere 비교",
          "3일차 - Meta AI와 Perplexity 평가: 모델 출력의 미세한 차이",
          "3일차 - LLM 리더십 챌린지: 창의적인 프롬프트를 통한 AI 모델 평가",
          "4일차 - 리더십 우승자 공개: 재미있는 LLM 챌린지",
          "4일차 - AI의 여정 탐색: 초기 모델에서 Transformer까지",
          "4일차 - LLM 파라미터 이해: GPT-1에서 조단위 가중치 모델까지",
          "4일차 - GPT 토큰화 설명: 대형 언어 모델이 텍스트 입력을 처리하는 방식",
          "4일차 - 컨텍스트 윈도우가 AI 언어 모델에 미치는 영향: 토큰 제한 설명",
          "4일차 - AI 모델 비용 탐색: API 가격 책정 vs. 채팅 인터페이스 구독",
          "4일차 - LLM 컨텍스트 윈도우 비교: GPT-4 vs Claude vs Gemini 1.5 Flash",
          "4일차 - 4일차 마무리: 주요 포인트와 실용적인 인사이트 정리",
          "5일차 - OpenAI API와 Python을 사용한 AI 기반 마케팅 브로셔 만들기",
          "5일차 - JupyterLab 튜토리얼: AI 기반 회사 브로셔를 위한 웹 스크래핑",
          "5일차 - LLM의 구조화된 출력: AI 프로젝트를 위한 JSON 응답 최적화",
          "5일차 - 브로셔 콘텐츠에 대한 응답 생성 및 포맷팅",
          "5일차 - 최종 조정: JupyterLab에서 Markdown 최적화 및 스트리밍",
          "5일차 - 멀티샷 프롬프트 마스터하기: AI 프로젝트에서 LLM 신뢰성 향상",
          "5일차 - 과제: 여러분만의 맞춤형 LLM 기반 튜터 개발하기",
          "5일차 - 1주차 마무리: 성취 및 다음 단계"
        ],
        "2주차 - 멀티모달 챗봇 구축: LLM, Gradio UI 및 에이전트 활용": [
          "1일차 - 여러 AI API 마스터하기: LLM 엔지니어를 위한 OpenAI, Claude, Gemini",
          "1일차 - AI 응답 스트리밍: Python에서 실시간 LLM 출력 구현",
          "1일차 - OpenAI와 Claude API를 사용한 적대적 AI 대화 생성 방법",
          "1일차 - AI 도구: 개발자를 위한 Transformer와 Frontier LLM 탐색",
          "2일차 - Gradio로 AI UI 구축: LLM 엔지니어를 위한 빠른 프로토타이핑",
          "2일차 - Gradio 튜토리얼: OpenAI GPT 모델을 위한 인터랙티브 AI 인터페이스 만들기",
          "2일차 - Gradio UI에서 GPT와 Claude로 스트리밍 응답 구현",
          "2일차 - Gradio로 멀티모델 AI 챗 인터페이스 구축: GPT vs Claude",
          "2일차 - 고급 AI UI 구축: OpenAI API에서 Chat 인터페이스까지 Gradio로",
          "3일차 - AI 챗봇 구축: 고객 지원 어시스턴트를 위한 Gradio 마스터하기",
          "3일차 - OpenAI & Gradio로 대화형 AI 챗봇 만들기: 단계별 가이드",
          "3일차 - 멀티샷 프롬프트와 컨텍스트 확장을 통한 챗봇 향상",
          "3일차 - AI 도구 마스터하기: LLM이 내 컴퓨터에서 코드를 실행할 수 있게 하기",
          "4일차 - LLM과 AI 도구 사용하기: 대규모 언어 모델의 기능 향상",
          "4일차 - AI 항공사 어시스턴트 만들기: OpenAI GPT-4로 도구 구현",
          "4일차 - LLM에 맞춤 도구 장착하는 방법: OpenAI 함수 호출 튜토리얼",
          "4일차 - AI 도구 마스터하기: API로 고급 LLM 기반 어시스턴트 구축",
          "5일차 - 멀티모달 AI 어시스턴트: 이미지 및 소리 생성 통합",
          "5일차 - 멀티모달 AI: JupyterLab에서 DALL-E 3 이미지 생성 통합",
          "5일차 - 멀티모달 AI 에이전트 만들기: 오디오 및 이미지 도구 통합",
          "5일차 - 멀티모달 AI 어시스턴트 만들기: 툴과 에이전트 통합"
        ],
        "3주차 - 오픈소스 생성 AI: HuggingFace를 활용한 자동화 솔루션 구축": [
          "1일차 - Hugging Face 튜토리얼: 오픈소스 AI 모델 및 데이터셋 탐색",
          "1일차 - HuggingFace Hub 탐색: AI 개발자를 위한 모델, 데이터셋 및 공간",
          "1일차 - Google Colab 소개: 머신러닝을 위한 클라우드 주피터 노트북",
          "1일차 - Hugging Face와 Google Colab 통합: 비밀 키 및 API 키 설정",
          "1일차 - Google Colab 마스터하기: Hugging Face를 사용한 오픈소스 AI 모델 실행",
          "2일차 - Hugging Face 트랜스포머: Python에서 AI 작업을 위한 파이프라인 사용",
          "2일차 - Hugging Face 파이프라인: Transformers 라이브러리를 통한 AI 작업 간소화",
          "2일차 - HuggingFace 파이프라인 마스터하기: ML 작업을 위한 효율적인 AI 추론",
          "3일차 - 오픈소스 AI에서의 토크나이저 탐색: Llama, Phi-2, Qwen, Starcoder",
          "3일차 - AI에서의 토큰화 기법: LLAMA 3.1 모델을 위한 AutoTokenizer 사용",
          "3일차 - 토크나이저 비교: 오픈소스 AI 모델을 위한 Llama, PHI-3, QWEN2",
          "3일차 - Hugging Face 토크나이저: 고급 AI 텍스트 생성을 위한 준비",
          "4일차 - Hugging Face 모델 클래스: 오픈소스 AI 모델에 대한 추론 실행",
          "4일차 - Hugging Face 트랜스포머: Bits & Bytes로 LLM 로딩 및 양자화",
          "4일차 - Hugging Face 트랜스포머: 오픈소스 AI 모델로 농담 생성",
          "4일차 - Hugging Face 트랜스포머 마스터하기: 모델, 파이프라인 및 토크나이저",
          "5일차 - Frontier & 오픈소스 모델 결합: 오디오-텍스트 요약",
          "5일차 - Hugging Face & OpenAI를 사용한 AI 기반 회의록 생성",
          "5일차 - 합성 테스트 데이터 생성기 만들기: 비즈니스를 위한 오픈소스 AI 모델"
        ],
        "4주차 - LLM 쇼다운: 코드 생성 및 비즈니스 작업을 위한 모델 평가": [
          "1일차 - 올바른 LLM 선택하기: 오픈 소스와 폐쇄 소스 모델 비교",
          "1일차 - 친칠라 스케일링 법칙: LLM 파라미터와 훈련 데이터 크기 최적화",
          "1일차 - LLM 벤치마크의 한계: 과적합과 훈련 데이터 유출",
          "1일차 - 대규모 언어 모델 평가: 6개의 차세대 벤치마크 공개",
          "1일차 - HuggingFace OpenLLM 리더보드: 오픈 소스 언어 모델 비교",
          "1일차 - LLM 리더보드 마스터하기: 오픈 소스와 폐쇄 소스 모델 비교",
          "2일차 - LLM 비교: 언어 모델 평가를 위한 Top 6개 리더보드",
          "2일차 - 특화된 LLM 리더보드: 사용 사례에 맞는 최적 모델 찾기",
          "2일차 - LLAMA vs GPT-4: 코드 생성용 대규모 언어 모델 벤치마킹",
          "2일차 - 인간 평가 언어 모델: LM Sys 챗봇 아레나 이해하기",
          "2일차 - 대규모 언어 모델의 상업적 응용: 법률에서 교육까지",
          "2일차 - 코드 변환 프로젝트를 위한 Frontier와 오픈 소스 LLM 비교",
          "3일차 - Frontier 모델을 활용한 고성능 C++ 코드 생성",
          "3일차 - 코드 생성용 Top LLM 비교: GPT-4 vs Claude 3.5 Sonnet",
          "3일차 - 대형 언어 모델을 이용한 파이썬 코드 최적화: GPT-4 vs Claude 3.5",
          "3일차 - 코드 생성의 함정: 대규모 언어 모델이 오류를 낼 때",
          "3일차 - 초고속 코드 생성: Claude가 파이썬보다 13,000배 더 빠른 이유",
          "3일차 - 대규모 언어 모델을 이용한 코드 생성용 Gradio UI 구축",
          "3일차 - C++ 코드 생성 최적화: GPT와 Claude의 성능 비교",
          "3일차 - GPT-4와 Claude 코드 생성 성능 비교",
          "4일차 - 코드 생성을 위한 오픈 소스 LLM: Hugging Face 엔드포인트 탐색",
          "4일차 - 코드 생성 모델을 위한 HuggingFace 추론 엔드포인트 사용법",
          "4일차 - 코드 생성용 Frontier LLM과 오픈 소스 모델 통합",
          "4일차 - 코드 생성 비교: GPT-4, Claude, CodeQuen LLM",
          "4일차 - LLM 코드 생성 마스터하기: 기법과 모델 선택",
          "5일차 - LLM 성능 평가: 모델 중심 vs 비즈니스 중심 지표",
          "5일차 - LLM 코드 생성 마스터하기: 파이썬 개발자를 위한 고급 도전 과제"
        ],
        "5주차 - RAG 마스터하기: 벡터 임베딩과 LangChain으로 고급 솔루션 구축": [
          "1일차 - RAG 기초: 외부 데이터를 활용하여 LLM 응답 개선하기",
          "1일차 - DIY RAG 시스템 구축: 검색-증강 생성 구현하기",
          "1일차 - 벡터 임베딩 이해하기: RAG 및 LLM 검색의 핵심",
          "2일차 - LangChain 소개: LLM 애플리케이션을 위한 RAG 구현 간소화하기",
          "2일차 - LangChain 텍스트 분할기 튜토리얼: RAG 시스템을 위한 청크 최적화하기",
          "2일차 - 벡터 데이터베이스 준비하기: OpenAI 임베딩과 Chroma를 활용한 RAG",
          "3일차 - 벡터 임베딩 마스터하기: LLM 엔지니어링을 위한 OpenAI와 Chroma 활용",
          "3일차 - 임베딩 시각화하기: t-SNE로 다차원 공간 탐색하기",
          "3일차 - RAG 파이프라인 구축하기: LangChain으로 벡터에서 임베딩으로",
          "4일차 - RAG 파이프라인 구현하기: LangChain으로 LLM, 검색기, 메모리 통합",
          "4일차 - 검색-증강 생성 마스터하기: LLM 통합 실습",
          "4일차 - RAG 파이프라인 마스터하기: 효율적인 RAG 시스템 구축하기",
          "5일차 - RAG 시스템 최적화하기: 문제 해결 및 일반적인 오류 수정하기",
          "5일차 - 벡터 저장소 교체하기: LangChain RAG 파이프라인에서 FAISS와 Chroma 비교하기",
          "5일차 - LangChain의 비밀 풀기: RAG 파이프라인 구축의 이면",
          "5일차 - RAG 디버깅하기: LangChain에서 컨텍스트 검색 최적화하기",
          "5일차 - 나만을 위한 AI 지식 노동자 만들기: 생산성 향상을 위한 RAG 활용하기"
        ],
        "6주차 - 프론티어 대형 언어 모델을 LoRA/QLoRA로 미세 조정하기": [
          "1일차 - 대형 언어 모델 세부 조정: 추론에서 훈련까지",
          "1일차 - LLM 세부 조정을 위한 데이터셋 찾기 및 제작: 출처 및 기법",
          "1일차 - LLM을 위한 제품 설명 데이터 세부 조정 기술",
          "1일차 - 제품 설명에 대한 LLM 세부 조정을 위한 데이터 큐레이션 기술",
          "1일차 - LLM 성능 평가: 모델 중심 vs 비즈니스 중심 지표",
          "2일차 - LLM 배포 파이프라인: 비즈니스 문제에서 생산 솔루션까지",
          "2일차 - 프롬프트, RAG, 세부 조정: 각 방법을 사용하는 시점",
          "2일차 - LLM 프로덕션화: 대규모 AI 모델 배포를 위한 모범 사례",
          "2일차 - 모델 훈련을 위한 대규모 데이터셋 최적화: 데이터 큐레이션 전략",
          "2일차 - LLM 훈련을 위한 균형 잡힌 데이터셋 만들기: 큐레이션 기법",
          "2일차 - 데이터셋 큐레이션 마무리: 가격-설명 상관관계 분석",
          "2일차 - HuggingFace에 고품질 데이터셋 업로드하기",
          "3일차 - 피처 엔지니어링과 Bag of Words 기법: NLP를 위한 ML 베이스라인 구축",
          "3일차 - ML 베이스라인 모델: 간단한 예측 함수 구현",
          "3일차 - 아마존 제품 가격 예측 모델을 위한 피처 엔지니어링 기법",
          "3일차 - LLM 성능 최적화: 고급 피처 엔지니어링 전략",
          "3일차 - LLM 세부 조정을 위한 선형 회귀: 베이스라인 모델 비교",
          "3일차 - Bag of Words NLP: 텍스트 분석을 위한 Count Vectorizer 구현",
          "3일차 - 서포트 벡터 회귀 vs 랜덤 포레스트: 머신러닝 대결",
          "3일차 - 전통적인 ML 모델 비교: 랜덤 모델에서 랜덤 포레스트까지",
          "4일차 - Frontier 모델 평가: 베이스라인 프레임워크와 성능 비교",
          "4일차 - 인간 vs AI: Frontier 모델에서 가격 예측 성능 평가",
          "4일차 - GPT-4o Mini: 가격 추정 작업을 위한 Frontier AI 모델 평가",
          "4일차 - GPT-4와 Claude 비교: 가격 예측 작업에서 모델 성능",
          "4일차 - Frontier AI 역량: LLM이 전통적인 ML 모델을 능가하는 사례",
          "5일차 - OpenAI를 통한 LLM 세부 조정: 데이터 준비, 훈련 및 평가",
          "5일차 - LLM 세부 조정을 위한 JSONL 파일 준비하기",
          "5일차 - GPT 세부 조정 작업 시작하기: OpenAI API를 통한 단계별 가이드",
          "5일차 - LLM 세부 조정: Weights & Biases로 훈련 손실 및 진행 상황 추적하기",
          "5일차 - 세부 조정된 LLM 평가 지표: 훈련 및 검증 손실 분석",
          "5일차 - LLM 세부 조정의 도전 과제: 모델 성능 향상이 이루어지지 않을 때",
          "5일차 - Frontier LLM 세부 조정: 최적화를 위한 도전 과제 및 모범 사례"
        ],
        "7주차 - 가격 예측에서 Frontier 모델과 경쟁할 수 있도록 미세 조정된 오픈소스 모델": [
          "1일차 - 파라미터 효율적인 파인튜닝 마스터하기: LoRa, QLoRA & 하이퍼파라미터",
          "1일차 - LoRA 어댑터 소개: 저랭크(Low-Rank) 적응 설명",
          "1일차 - QLoRA: 대형 언어 모델의 효율적인 파인튜닝을 위한 양자화",
          "1일차 - LLM 최적화: QLoRA 파인튜닝의 R, Alpha, 타겟 모듈",
          "1일차 - 파라미터 효율적인 파인튜닝: Hugging Face를 사용한 LLM을 위한 PEFT",
          "1일차 - LLM 양자화하는 법: 8비트 정밀도로 모델 크기 축소하기",
          "1일차 - 더블 양자화 & NF4: 4비트 LLM 최적화를 위한 고급 기법",
          "1일차 - PEFT 모델 탐색: LLM 파인튜닝에서 LoRA 어댑터의 역할",
          "1일차 - 모델 크기 요약: 양자화된 모델과 파인튜닝된 모델 비교",
          "2일차 - LLM 파인튜닝을 위한 최적의 기본 모델 선택 방법",
          "2일차 - 최적의 기본 모델 선택: HuggingFace LLM 리더보드 분석",
          "2일차 - 토크나이저 탐색: LLAMA, QWEN 및 다른 LLM 모델 비교",
          "2일차 - LLM 성능 최적화: Llama 3.1 기본 모델 로딩 및 토크나이징",
          "2일차 - LLM 양자화 영향: 성능 지표 및 오류 분석",
          "2일차 - LLM 비교: 파라미터 효율적인 튜닝에서 GPT-4 vs LLAMA 3.1",
          "3일차 - QLoRA 하이퍼파라미터: 대형 언어 모델을 위한 파인튜닝 마스터하기",
          "3일차 - 모델 훈련에서 Epochs와 배치 사이즈 이해하기",
          "3일차 - 학습률, 그래디언트 누적, 최적화 기법 설명",
          "3일차 - 파인튜닝을 위한 훈련 과정 설정하기",
          "3일차 - LoRA 4비트 양자화 파인튜닝을 위한 SFTTrainer 구성하기",
          "3일차 - LLM 파인튜닝: QLoRA로 훈련 과정 시작하기",
          "3일차 - Weights & Biases로 훈련 모니터링 및 관리",
          "4일차 - 훈련 비용 절감하기: 효율적인 파인튜닝 전략",
          "4일차 - 효율적인 파인튜닝: QLoRA 훈련을 위한 작은 데이터셋 사용",
          "4일차 - Weights & Biases 차트를 사용하여 LLM 파인튜닝 진행 상황 시각화",
          "4일차 - 고급 Weights & Biases 도구와 Hugging Face에 모델 저장하기",
          "4일차 - 엔드 투 엔드 LLM 파인튜닝: 문제 정의부터 훈련된 모델까지",
          "5일차 - LLM 훈련의 네 가지 단계: 순전파부터 최적화까지",
          "5일차 - QLoRA 훈련 과정: 순전파, 역전파 및 손실 계산",
          "5일차 - 모델 훈련에서 소프트맥스와 교차 엔트로피 손실 이해하기",
          "5일차 - 파인튜닝 모니터링: LLM 훈련 분석을 위한 Weights & Biases",
          "5일차 - 포디움 재조명: 모델 성능 지표 비교",
          "5일차 - 비즈니스 지표에 대한 우리 고유의 파인튜닝된 LLM 평가",
          "5일차 - 결과 시각화: GPT-4를 이겼을까?",
          "5일차 - 하이퍼파라미터 튜닝: PEFT로 LLM 정확도 향상"
        ],
        "8주차 - 모델과 협업하는 자율 다중 에이전트 시스템 구축": [
          "1일차 - 미세 조정에서 다중 에이전트 시스템으로: 차세대 LLM 엔지니어링",
          "1일차 - 자동화된 거래 탐색 시스템을 위한 다중 에이전트 AI 아키텍처 구축",
          "1일차 - Modal 공개: 서버리스 모델을 클라우드에 배포",
          "1일차 - 클라우드에서 LLAMA 실행: 대형 모델 효율적으로 운영하기",
          "1일차 - 서버리스 AI 가격 API 구축: Modal로 단계별 가이드",
          "1일차 - 다수의 프로덕션 모델 준비: 고급 RAG 솔루션을 위한 준비",
          "2일차 - 에이전틱 워크플로우 구현: Frontier 모델과 벡터 저장소를 활용한 RAG",
          "2일차 - 에이전틱 워크플로우 구현: Frontier 모델과 벡터 저장소를 활용한 RAG",
          "2일차 - 벡터 공간 시각화: 데이터 탐색을 위한 고급 RAG 기법",
          "2일차 - RAG를 위한 3D 시각화 기법: 벡터 임베딩 탐색",
          "2일차 - 유사 제품 찾기: LangChain 없이 RAG 파이프라인 구축",
          "2일차 - RAG 파이프라인 구현: 검색 기법으로 LLM 강화",
          "2일차 - 랜덤 포레스트 회귀: 가격 예측을 위한 트랜스포머 및 ML 사용",
          "2일차 - 앙상블 모델 구축: LLM, RAG, 랜덤 포레스트 결합",
          "2일차 - 마무리: 다중 에이전트 시스템과 RAG 통합 완료",
          "3일차 - 구조화된 출력으로 AI 에이전트 강화: Pydantic & BaseModel 가이드",
          "3일차 - RSS 피드 스크래핑: AI 기반 거래 선택 시스템 구축",
          "3일차 - AI의 구조화된 출력: 상세한 거래 선택을 위한 GPT-4 구현",
          "3일차 - AI 워크플로우 최적화: 정확한 가격 인식을 위한 프롬프트 정제",
          "3일차 - 자율 에이전트 마스터하기: 다중 에이전트 AI 워크플로우 설계",
          "4일차 - 에이전틱 AI의 5가지 특징: 자율성, 계획, 기억",
          "4일차 - 에이전틱 AI 시스템 구축: 알림을 위한 Pushover 통합",
          "4일차 - 에이전틱 AI 구현: 자동화된 워크플로우를 위한 계획 에이전트 만들기",
          "4일차 - 에이전트 프레임워크 구축: LLM과 Python 코드 연결",
          "4일차 - 에이전틱 워크플로우 완성: 비즈니스 애플리케이션에 맞게 확장",
          "5일차 - 자율 AI 에이전트: 사람의 인풋 없이 지능형 시스템 구축",
          "5일차 - Gradio를 활용한 AI 에이전트: 자율 시스템을 위한 고급 UI 기법",
          "5일차 - Gradio UI 마무리: 우리의 에이전틱 AI 솔루션",
          "5일차 - AI 에이전트 UI 향상: 실시간 로그 시각화를 위한 Gradio 통합",
          "5일차 - 결과 분석: 에이전트 프레임워크 성능 모니터링",
          "5일차 - AI 프로젝트 회고하기: LLM 엔지니어로 거듭난 8주간 여정"
        ]
      },
      "requirements": [
        "이 강의는 Python으로 진행됩니다. Python의 기초를 다루지 않으므로, Python에 대한 기본 지식이 필요합니다."
      ],
      "description": "[꼭 읽어주세요] 한글 AI 자막 강의란?\n유데미의 한국어 [자동] AI 자막 서비스로 제공되는 강의입니다.\n강의에 대한 질문사항은 강사님이 확인하실 수 있도록 Q&A 게시판에 영어로 남겨주시기 바랍니다.\n\n\n생성형 AI와 LLM 마스터하기: 8주간의 실습 여정\n\n\nAI 실무 프로젝트를 통해 커리어를 발전시키고,\n이 분야의 베테랑인 Ed Donner 강사님이 이끄는 강의를 통해 생성형 AI와 최첨단 기술을 마스터합니다.\n20개 이상의 혁신적인 모델을 실험하며, RAG, QLoRA, 에이전트와 같은 최신 기술을 익혀보세요!\n\n\n1. 무엇을 배우나요?\n\n\n최첨단 모델과 프레임워크를 사용해 고급 생성형 AI 제품을 개발합니다.\nFrontier 및 오픈 소스 모델을 포함한 20개 이상의 혁신적인 AI 모델을 실험합니다.\nHuggingFace, LangChain, Gradio와 같은 플랫폼을 능숙하게 활용합니다.\nRAG(검색 기반 생성), QLoRA 미세 조정, 에이전트와 같은 최신 기술을 구현합니다.\n실무 기반의 AI 애플리케이션을 제작합니다:\n텍스트, 음성, 이미지와 상호작용하는 멀티모달 고객 지원 에이전트\n공유 드라이브 데이터를 기반으로 기업 질문에 답할 수 있는 AI 지식 근로자\n소프트웨어를 최적화해 성능을 60,000배 개선하는 AI 프로그래머\n보지 못한 제품의 가격을 정확히 예측하는 이커머스 애플리케이션\n추론에서 학습으로 전환, Frontier 및 오픈 소스 모델을 모두 미세 조정합니다.\nUI와 고급 기능을 갖춘 AI 제품을 프로덕션에 배포합니다.\nAI와 LLM 엔지니어링 역량을 강화해 업계의 최전선에 자리합니다.\n\n\n2. 프로젝트 소개:\n\n\n프로젝트 1: 기업 웹사이트를 지능적으로 스크래핑하고 탐색하는 AI 기반 브로셔 생성기.\n프로젝트 2: UI와 기능 호출을 사용하는 항공사 멀티모달 고객 지원 에이전트.\n프로젝트 3: 오디오에서 회의록과 실행 항목을 생성하는 오픈 소스 및 폐쇄 소스 모델 기반 도구.\n프로젝트 4: Python 코드를 최적화된 C++로 변환하여 성능을 60,000배 향상시키는 AI.\n프로젝트 5: RAG를 사용하여 회사 관련 모든 정보에 대한 전문가가 되는 AI 지식 근로자.\n프로젝트 6: 캡스톤 파트 A – Frontier 모델을 사용하여 간단한 설명으로부터 제품 가격 예측.\n프로젝트 7: 캡스톤 파트 B – Frontier와 가격 예측에서 경쟁하기 위한 미세 조정된 오픈 소스 모델.\n프로젝트 8: 캡스톤 파트 C – 모델과 협력하여 특가 상품을 발견하고 알림을 제공하는 자율 에이전트 시스템.\n\n\n3. 왜 이 강의인가요?\n\n\n실습 중심 학습: 실무에서 사용할 수 있는 AI 애플리케이션을 직접 구축하며 배우는 가장 효과적인 학습 방식.\n최신 기술 습득: RAG, QLoRA, 에이전트와 같은 최신 프레임워크와 기술을 선도적으로 익힙니다.\n접근성 높은 콘텐츠: 모든 수준의 학습자를 위해 설계되었습니다. 단계별 안내, 실습 과제, 치트시트, 다양한 리소스를 제공합니다.\n고급 수학 불필요: 실질적인 응용에 초점을 맞춰 미적분이나 선형대수 지식 없이도 LLM 엔지니어링을 마스터할 수 있습니다.\n\n\n4. 강사 소개\n안녕하세요, 저는 Ed Donner 입니다. 20년 이상의 경력을 가진 AI 및 기술 분야의 기업가이자 리더입니다.\nAI 스타트업을 설립하고 성공적으로 매각했으며, 또 다른 스타트업을 창업하여 전 세계 주요 금융기관 및 스타트업에서 팀을 이끌어 왔습니다.\n이 흥미로운 분야로 더 많은 사람을 이끌고, 업계의 선두주자가 될 수 있도록 돕는 것에 열정을 가지고 있습니다.\n\n\n5. 강의 커리큘럼\n\n\n1주차: 기초 및 첫 번째 프로젝트\nTransformer의 기본 개념을 학습합니다.\n주요 Frontier 모델 6개를 실험합니다.\n웹을 스크래핑하고 판매 브로셔를 생성하는 비즈니스 AI 제품을 만듭니다.\n\n\n2주차: Frontier API와 고객 서비스 챗봇\nFrontier API를 탐색하고 3가지 주요 모델과 상호작용합니다.\n텍스트, 이미지, 오디오와 상호작용하며 툴이나 에이전트를 활용하는 챗봇을 개발합니다.\n\n\n3주차: 오픈 소스 모델 활용\nHuggingFace를 통해 오픈 소스 모델을 탐구합니다.\n번역부터 이미지 생성까지 10가지 생성형 AI 사용 사례를 해결합니다.\n회의록과 액션 아이템을 생성하는 제품을 구축합니다.\n\n\n4주차: LLM 선택과 코드 생성\nLLM간의 차이점을 이해하고, 주어진 비즈니스 작업에 가장 적합한 LLM을 선택하는 방법을 배웁니다.\nLLM을 사용하여 코드를 생성하고, Python 코드를 C++로 변환하는 제품을 구축하여 성능을 60,000배 이상 향상시킵니다.\n\n\n5주차: RAG (검색 기반 생성)\nRAG을 마스터하여 여러분의 솔루션의 정확도를 개선합니다.\n벡터 임베딩에 능숙해지고, 인기 있는 오픈 소스 벡터 데이터스토어에서 벡터를 탐색합니다.\n시장의 실제 제품과 유사한 풀 비즈니스 솔루션을 구축합니다.\n\n\n6주차: 트레이닝으로 전환\n추론에서 트레이닝으로 전환합니다.\nFrontier 모델을 미세 조정해 실제 비즈니스 문제를 해결합니다.\n자신만의 특화된 모델을 구축하여 여러분의 AI 여정에서 중요한 이정표를 달성합니다.\n\n\n7주차: 고급 트레이닝 기술\nQLoRA 미세 조정과 같은 고급 학습 기술을 배웁니다.\n특정 작업에서 Frontier 모델을 능가하는 오픈 소스 모델을 학습합니다.\n기술을 한 단계 더 발전시키는 도전적인 프로젝트를 해결합니다.\n\n\n8주차: 배포 및 최종화\nUI가 완성된 상업용 제품을 프로덕션에 배포합니다.\n에이전트를 활용해 기능을 확장합니다.\n첫 번째 프로덕션화된, 에이전트화된, 미세 조정된 LLM 모델을 배포합니다.\nAI와 LLM 엔지니어링의 마스터한 것을 기념하고, 여러분의 커리어의 다음 단계에 대비합니다.",
      "target_audience": [
        "생성형 AI와 LLM 분야에 진입하고자 하는 열정적인 AI 엔지니어 및 데이터 사이언티스트 지망생들",
        "빠르게 변화하는 AI 환경에서 경쟁력을 유지하고자 하는 전문가들",
        "실용적이고 실습 중심의 경험을 통해 고급 AI 애플리케이션을 개발하고자 하는 개발자들"
      ]
    },
    {
      "title": "【한글자막】 Python : 통계 분석을 위한 파이썬",
      "url": "https://www.udemy.com/course/best-python-statistics/",
      "bio": "파이썬으로 응용 통계 마스터 : 통계 및 머신 러닝 프로젝트 해결, 시각적 출력 및 그래픽 탐색을 통합하여 결과를 해석하고 시각화, 가설을 검증하고 효율적으로 검정을 구현하여 실제 현실 문제를 해결하기",
      "objectives": [
        "데이터에 대한 더 깊은 인사이트",
        "파이썬을 사용하여 일반적 또는 복잡한 통계 및 머신 러닝 관련 프로젝트 해결",
        "시각적 출력 및 그래픽 탐색을 통합하여, 결과를 해석하고 시각화하는 방법",
        "파이썬으로 가설을 검증하고 효율적으로 검정을 구현하는 방법",
        "데이터 분석 탐색(데이터 로딩, 아웃라이어, 1D분포 등)",
        "특성화(평균 중간값 모드, 폭, 왜도 및 첨도, 백분위수 등)",
        "확률(확률분포, 확률 함수, 경험적 분포, 샘플링 및 중심극한정리 등)",
        "가설검증(기본검증, 비율 검증 등)"
      ],
      "course_content": {
        "서론": [
          "소개",
          "설정",
          "BONUS: Learning Path",
          "실시간으로 진행하는 설치 및 검증",
          "코딩 편집기",
          "실시간 코딩 편집기 비교",
          "파일 관리"
        ],
        "데이터 분석 탐색": [
          "데이터 로딩",
          "데이터 로딩 - 실례",
          "데이터셋 준비 - 실습 예제",
          "이상치 처리 - 실습 예제",
          "분포 개요",
          "히스토그램(막대 그래프) - 실습 예제",
          "1차원 군집 - 실습 예제",
          "1차원 박스 및 바이올린 - 실습 예제",
          "1차원 경험적 CDF 및 판다스 설명 - 실습 예제",
          "고차원 분포 개요",
          "n차원 산점도 행렬 - 실습 예제",
          "n차원 상관관계 - 실습 예제",
          "2차원 히스토그램, 등고선 및 KDE - 실습 예제",
          "n차원 산점도 확률 - 실습 예제",
          "탐색적 데이터 분석 요약"
        ],
        "특성화": [
          "서론 - 왜 특성화를 신경써야 하는가?",
          "평균 중간값 모드 - 실례",
          "폭 - 실례",
          "왜도 및 첨도 - 실례",
          "백분위수 - 실례",
          "다변수 분포 - 실례",
          "요약"
        ],
        "확률": [
          "확률 복습",
          "확률분포 소개",
          "확률분포 - 실례",
          "확률함수 및 경험적 분포",
          "경험적 분포 - 실례",
          "샘플링 및 중심극한정리 소개",
          "샘플링 분포 - 실례",
          "Extra Writeup: More resources on sampling distributions",
          "중심극한정리 - 실례",
          "요약"
        ],
        "가설검증": [
          "가설검증 소개",
          "동기부여 로드된 주사위 - 실례",
          "기본검증",
          "기본검증 예제 - 소행성 충돌",
          "비율검증 소개",
          "비율검증 예제 - 선거 조작",
          "피어슨 카이제곱 검증 - 실습 예제",
          "분포 비교 - Kolmogorow-Smirnow 및 Anderson-Darling 검증",
          "Extra Writeup: All the ways to do A/B testing!",
          "요약"
        ],
        "결론": [
          "결론",
          "추가: 유의성 집착 - 하지 말아야 할 것!",
          "추가 정보: 가우스 과정 소개",
          "추가 실습 - 우주 충돌",
          "추가 실습 - 차량 배출가스 기준",
          "추가 실습 - 당뇨병 진단",
          "추가 실습 - 매출에 대한 수치적 불확실성"
        ],
        "완강을 축하합니다! 선물 받아가는 것을 잊지 마세요!": [
          "보너스: ML 및 AI를 위한 Cloud 기술(쿠폰 동봉)",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "프로그래밍 기초 지식 혹은 Python 코딩 경험"
      ],
      "description": "파이썬 통계 분석의 모든 것!\n실제 현실의 예제를 이용한 응용 통계!\n복잡한 통계 및 머신러닝을 쉽게 설명!\n시각적 출력 및 그래픽 탐색 등 시각화 포함!\n\n\nPython : 통계 분석을 위한 파이썬을 선택해야 하는 이유\n이 코스는 실제 통계와 데이터 과학의 세계에 깊이 들어감으로써 여러분을 성공으로 이끌도록 구성되었습니다.\n\n\n1. 실제 현실의 예제를 통해 배우기: 이론적인 내용만 계속 공부한 나머지 실제 현실에 적용하기 어려워하는 대신, 여기서는 응용 통계에 집중합니다. 이론을 파이썬으로 바로 적용해서 일반적인 문제를 풀면서 여러분이 앞서 나가기 위해 필요한 지식과 기술들을 얻을 수 있습니다.\n\n\n2. 프리젠테이션에 사용하기 좋은 결과물: 숫자를 계산하는 건 쉬울 뿐더러, 빠르게 사람이 아니라 컴퓨터의 일이 되고 있습니다. 사람이 하는 일은 결과를 해석하고 시각화하는 것이므로, 우리는 여기에 크게 중점을 두고 학습 과정에 시각적 출력 및 그래픽 탐색을 통합했습니다. 또한 보고서, 짧은 논문 및 프리젠테이션에서 사용할 수 있는 멋진 시각화 팁을 추가 보너스 콘텐츠로 드립니다. 다른 사람들보다 확실히 눈에 띌 겁니다.\n\n\n3. 현대적인 도구 및 학습 과정: 여기는 개념을 익히기 위해 진저리나게 몇 시간 동안 손으로 문제를 푸는 학교가 아닙니다. 여기서는 문제를 풀 때 최신의 기술과 코드 라이브러리를 사용합니다. 우리를 최대한 생산적이고 효율적으로 만들어주는 최신 소프트웨어의 기능을 활용합니다. 업계는 로켓을 쏘는데 바퀴를 재발명하려고 하지 마세요.\n\n\n\n\nPython : 통계 분석을 위한 파이썬은 이렇게 진행 됩니다\n파이썬을 사용하여 일반적 또는 복잡한 통계 및 머신 러닝 관련 프로젝트 해결\n시각적 출력 및 그래픽 탐색을 통합하여, 결과를 해석하고 시각화하는 방법\n파이썬으로 가설을 검증하고 효율적으로 검정을 구현하는 방법\n데이터에 대한 더 깊은 인사이트\n\n\n안녕하세요 한국의 수강생 여러분들,\n통계 분석을 위한 파이썬 코스에 오신 것을 환영합니다!\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n강의에서 만나요!\n- Ligency Team",
      "target_audience": [
        "업무 능력에 통계 분석을 추가하려는 데이터 과학자",
        "머신 러닝에 뛰어들기 전 통계적 기초를 좀 더 쌓고 싶은 데이터 과학자",
        "연구, 대학원 공부 또는 비즈니스를 위해 응용 통계를 배우고 싶어하는 학생"
      ]
    },
    {
      "title": "Azure Data Factory desde cero",
      "url": "https://www.udemy.com/course/azure-data-factory-desde-cero/",
      "bio": "Aprenda a usar Azure Data Factory desde cero para configurar canalizaciones de datos automatizadas hacia y desde fuentes",
      "objectives": [
        "Aprenderá a usar Azure Data Factory para componer servicios de almacenamiento, movimiento y procesamiento de datos",
        "Podrá identificar la opción correcta de implementación de Azure SQL Server, el modelo de compra y el nivel de servicio según los requisitos",
        "Comprenderá los componentes clave y las ventajas de Azure Data Factory. Podrá crear, programar y monitorear canalizaciones simples.",
        "Aprenderá a crear una canalización de datos del mundo real en Azure Data Factory (ADF).",
        "Aprenderá cómo transformar datos usando flujos de datos en Azure Data Factory (ADF) y cargarlos en Azure Data Lake Storage Gen2"
      ],
      "course_content": {},
      "requirements": [
        "Se requiere una cuenta de Azure. Si no tiene una, crearemos una cuenta gratuita en el curso.",
        "Conceptos básicos de T-SQL y bases de datos",
        "No se requiere experiencia en Azure, lo guiaré a través de todo lo necesario para aprender este curso"
      ],
      "description": "Azure Data Factory es la plataforma que resuelve estos escenarios de datos. Se trata de un servicio de integración de datos y ETL basado en la nube que le permite crear flujos de trabajo orientados a datos a fin de coordinar el movimiento y la transformación de datos a escala.\n¿Cómo funciona?\nData Factory contiene una serie de sistemas interconectados que proporcionan una plataforma completa de un extremo a otro para los ingenieros de datos.\nConectar y recopilar\nLas empresas tienen datos de varios tipos que se encuentran en orígenes locales dispares, en la nube, estructurados, no estructurados y semiestructurados, que llegan todos según distintos intervalos y velocidades.\nTransformar y enriquecer\nCuando los datos están presentes en un almacén de datos centralizado en la nube, procese o transforme los datos recopilados mediante flujos de datos de asignación de ADF.\nConceptos de nivel superior\nUna suscripción de Azure puede tener una o varias instancias de Azure Data Factory (o factorías de datos). Azure Data Factory consta de los siguientes componentes principales.\nPipelines\nActividades\nConjuntos de datos\nServicios vinculados\nFlujos de datos\nIntegration Runtime\nEstos componentes funcionan juntos para proporcionar la plataforma en la que pueda crear flujos de trabajo basados en datos con pasos para moverlos y transformarlos.\nCanalización\nUna factoría de datos puede tener una o más canalizaciones. La canalización es una agrupación lógica de actividades para realizar una unidad de trabajo. Juntas, las actividades de una canalización realizan una tarea.\n\n\nNuestro curso te permite aprender a tu ritmo. Si quieres aprender Azure Data Factory, uno de los ofertantes top de la nube requerido por muchas empresas en el mundo, este curso te brindara el conocimiento necesario.\nÚnete a la comunidad de DataHackers, con más de 50 mil alumnos aprendiendo de temas de Data, Analytics y Cloud.\n\n\nAprende, Aplica y Crece con DataHack.",
      "target_audience": [
        "Estudiantes universitarios en busca de una carrera en Ingeniería de Datos",
        "Ingenieros de datos/desarrolladores de almacenamiento de datos que actualmente trabajan en tecnologías locales u otras plataformas en la nube como AWS o GCP que desean aprender tecnologías de Azure",
        "Arquitectos de datos que buscan comprender la pila de ingeniería de datos de Azure",
        "Científicos de datos que quieran ampliar sus conocimientos a la ingeniería de datos",
        "Principiantes en Plataforma Azure",
        "Cualquiera que desee comenzar su carrera como ingeniero de datos de Azure"
      ]
    },
    {
      "title": "Statistik für Data Science und Business Analytics",
      "url": "https://www.udemy.com/course/statistik-fur-data-science-und-business-analytics/",
      "bio": "Statistik zur Anwendung im Beruf: deskriptive und Inferenzstatistik, Hypothesentests, datengestützte Entscheidungen",
      "objectives": [
        "Grundlagen der Statistik",
        "Unterschiedliche Datentypen zielführend nutzen",
        "Daten visuell darstellen",
        "Maßzahlen der zentralen Tendenz, Asymmetrie und Streuung berechnen",
        "Korrelation und Kovarianz berechnen",
        "Verschiedene Verteilungsarten einsetzen",
        "Konfidenzintervalle schätzen",
        "Hypothesentests durchführen",
        "Datengestützte Entscheidungen treffen",
        "Statistik im Rahmen von Data Science"
      ],
      "course_content": {},
      "requirements": [
        "Es sind keine Vorkenntnisse vonnöten. Wir beginnen mit den Grundlagen und bauen dann Stück für Stück darauf auf. Alles Notwendige ist im Kurs enthalten.",
        "Interesse und Motivation zu lernen und zu üben."
      ],
      "description": "Statistik und datengestützte Entscheidungen sind inzwischen in jeder Branche angekommen. Ihre Kenntnis bietet vielfältige Karrieremöglichkeiten – ob im Marketing oder in der Business Intelligence, ob als Data Analyst oder Data Scientist.\nWorauf also warten?\nIn unserem Kurs „Statistik für Data Science und Business Analytics“ rüsten wir unsere Teilnehmer mit der entsprechenden Grundkompetenz aus.\nObendrein geben wir ihnen noch umfassende Berechnungsvorlagen in Excel mit auf den Weg. Ein perfekter Einstieg also!\nWir bringen Licht ins Dunkel und vermitteln das notwendige Wissen, um komplexe statistische Analysen nachvollziehen zu können, und zeigen ihre Anwendung in interessanten Praxisbeispielen.\nUnser Kursversprechen:\n· Einfach zu verstehende Inhalte\n· Umfassende Themenpunkte\n· Praxisnahe Erläuterungen\n· Fokus auf relevantes Fachwissen\n· Nützliche Übungen und Begleitmaterial\n· Datengestützte Lehrmethodik\n· Effiziente Einführung in die Statistik-Fachsprache\n· Inklusive Varianten der Datenvisualisierung\n· Illustration der Kernmethoden quantitativer Forschung\nZu vielen dieser Punkte finden sich online Erklärungen. Eine Unmenge sogar. Nicht so recht fündig wird man aber bei der Suche nach einem vollständigen Kurs mit entsprechender Lehrstruktur, der vermittelt, warum bestimmte statistische Tests denn eigentlich so oft angewendet werden.\nMit Software-Paketen und Programmiersprachen lassen sich nunmehr viele der Vorgänge in der Statistik automatisieren. Kritisches, hinterfragendes Denken bleibt jedoch unabdingbar – und genau diese Fähigkeit fördert unser Kurs im Hinblick auf die Arbeit mit Daten. Schließlich verhält es sich bei Computern und Code wie mit Schiffen auf dem Meer: Selbst die beeindruckendsten Fortbewegungsmittel müssen von ihrem Kapitän – in diesem Fall uns als angehende Data Scientists und Business Intelligence Analysts – entsprechend ausgerichtet und navigiert werden, um sie sicher ans Ziel bringen.\nLehren aus Leidenschaft\nIm Zuge von vier Monaten harter Arbeit haben wir einen Statistikkurs zusammengestellt, der wertvolles Wissen auf so unterhaltsame wie praxisnahe Weise vermittelt. Wir möchten unsere Teilnehmer begeistern! Neben ansprechenden Animationen und spannenden Inhalten wartet unser Kurs auch mit Quizfragen, nützlichen Übungen und Begleitmaterialien sowie einem Glossar mit allen wichtigen Begriffen aus der Welt der Statistik auf.\nWie unterscheidet sich unser Kurs von anderen Statistikseminaren?\n· Hoher Qualitätsanspruch mit HD-Videos und -Animationen – und kein Sammelsurium langatmiger Lehrvideos\n· Geschrieben von einem versierten Mathematiker und Statistiker mit internationaler Arbeitserfahrung\n· Umfassende Lehrinhalte zu allen wichtigen Themen der Statistik und Vermittlung von Fähigkeiten essenziell für verschiedenste Berufsbilder in Marketing, Business Intelligence, Datenanalyse und Data Science\n· Ausführliche Fallstudien zum Festigen des Erlernten\n· Jederzeit ein offenes Ohr bei Fragen oder Hinweisen – und Antworten innerhalb von zwei Arbeitstagen\n· Dynamische Kursstruktur ohne Überfordern, ohne langwierige Umschweife\nWarum sind diese Fähigkeiten wichtig?\nEinkommensmöglichkeiten: Mitarbeiter mit Data-Science-Expertise sind äußerst begehrt, ihre Stellen hervorragend dotiert. Und dieser Trend wird sich alles andere als rückläufig entwickeln, denn immer mehr Unternehmen möchten sich das Potenzial der ihnen vorliegenden Daten besser zunutze machen.\nAufstiegschancen: Wer statistische Modelle beherrscht, wird seine Geschäftsstandpunkte und -ideen leicht quantitativ untermauern können. Die Karriereleiter erklimmt sich so um einiges leichter.\nZukunftssicherheit: Die Nachfrage nach Fachkräften, die mit Zahlen und Daten arbeiten, sie modellieren und interpretieren können, wächst exponentiell. Gleichzeitig ersetzt die Automatisierung immer mehr Arbeitsplätze. Data-Science-Experten sitzen dabei aber stets am längeren Hebel.\nWeiterentwicklung: „Langeweile“ kommt nicht vor im Statistikvokabular. Neue, spannende Herausforderungen warten jeden Tag darauf, von uns entschlüsselt zu werden, und erweitern unseren Horizont.\nFür diesen Kurs gilt natürlich die Udemy-Garantie zur Erstattung des Kurspreises innerhalb von 30 Tagen. Wir sind aber sicher, dass jeder einzelne Teilnehmer weit mehr als 30 Tage an Nutzen aus diesem Kurs ziehen wird.\nViel Spaß und viel Erfolg!",
      "target_audience": [
        "Teilnehmer mit Interesse an einer Karriere in der Data Science",
        "Teilnehmer mit Interesse an einer Karriere in der Business Intelligence",
        "Business Analysts",
        "Führungskräfte",
        "Teilnehmer, die sich für die Arbeit mit Zahlen und quantitative Analyse begeistern",
        "Teilnehmer, die tiefer in die Statistik und ihre Anwendung im Geschäftskontext eintauchen möchten",
        "Teilnehmer mit Interesse an einer Einführung in die Statistik",
        "Teilnehmer, die die Grundlagen der Statistik erlernen möchten"
      ]
    },
    {
      "title": "数据科学和商业分析中的统计学",
      "url": "https://www.udemy.com/course/statistics-for-data-science-chinese/",
      "bio": "办公需要的统计学：描述性和推理性统计、假设检验、回归分析",
      "objectives": [
        "理解统计学基本知识",
        "学会与不同类型的数据打交道",
        "如何划分不同类型的数据",
        "计算集中趋势、不对称性和变异性的标准",
        "计算相关和协方差",
        "分辨处理不同类型的分布",
        "估算置信区间",
        "进行假设检验",
        "用数据驱动的决策",
        "理解回归分析的原理",
        "进行回归分析",
        "使用和理解虚拟变量",
        "理解数据科学中的概念包括Python和R语言！"
      ],
      "course_content": {},
      "requirements": [
        "完全不需要经验 我们将从基础开始 逐步建立你的知识体系 一切都包含在课程当中",
        "学习和实践的意愿"
      ],
      "description": "统计学是您想进入的行业的推动力吗？ 您想成为营销分析师、商业智能分析师、数据分析师数据科学家吗？\n那好，那你来对了地方！\n这里为您提供了数据科学和商业分析的统计学，还有Excel表格中的模版。\n从这里开始，这是个完美的开始！\n你很快就能学到一些基础知识，可以帮助你理解复杂的数据分析，并直接运用到现实生活的情况中。我们的课程有以下特点：\n· 通俗易懂\n· 容易理解\n· 实用性强\n· 切中要点\n· 配套齐全\n· 数据驱动\n· 带你进入数据科学的世界\n· 教你学会数据可视化\n· 向你揭示量化研究的要点\n众所周知，上述许多要点已经有许多在线课程讲过成千上万次了。然而，几乎不可能有一个结构化的课程能让你理解，为什么某些特定的统计学检验方法使用的频率这么高。现代软件包和编程语言可以让很多工作自动化，但这门课程将为您提供更有价值的东西——批判思维的能力。计算机和编程语言就像海上的船只。它们会您带到理想目的地，但是你们，有抱负的数据科学家或BI分析师们才是掌舵人，是你们将这些船驶向正确的方向。\n教学是我们的热情所在\n我们努力了四个多月，创造了最好的统计学课程，为您提供最大的价值。我们希望您取得成功，所以我们的课程会尽可能地吸引人。 高质量的动画、精湛的课程材料、测验问题、讲义、课程笔记，以及涵盖您将学习的所有新术语的词汇表，订阅课程即可获得这些。\n本课程与其他的统计学课程的区别在哪里？我们有\n· 高质量制作——高清视频和动画（并不是一堆无聊的演讲！）\n· 博学的导师（我们的导师是世界顶级的数学家和统计学家）\n· 完整的培训——课程将涵盖您成为营销分析师、商业智能分析师、数据分析师或数据科学家所需的所有统计学课题和技能\n· 广泛的案例研究将帮助您巩固学到的知识\n· 优秀的支持——如果你不理解某个概念或者想联系我们，您将在1个工作日内收到答复\n· 动态的安排——我们不想浪费您的时间！导师为整个课程安排了很好的节奏\n为什么要学习这些技能？\n1. 薪资/收入——数据科学领域的职业是最受当今企业界欢迎的职业。而且，鉴于大多数企业开始意识到使用数据的优势，这种趋势只会继续增长\n2. 升职——如果您精通统计学，就能够通过定量证据来支持您的业务创意，这是职业发展的一条简单途径\n3. 保障未来——正如我们所说，对理解数字和数据并能够解释数字和数据的人的需求呈指数级增长; 你可能已经听说过，很多工作即将被自动化取代，对不对？那么，数据科学的职业是执行自动化，而不是被自动化\n4. 成长——这不是一份无聊的工作。每一天，你都将面临不同的挑战，测试现有的技能 ，要求您学习新的东西\n请记住，该课程附带Udemy的30天无条件退款保证。何乐而不为呢？因为我们确信这门课程将为您提供巨大的价值。\n让我们一起开始学习吧！",
      "target_audience": [
        "想从事数据科学的人",
        "想从事商业智能的人",
        "商业分析师",
        "企业经理人",
        "热衷于数字和数量分析的人",
        "想了解统计学奥义及其在商业世界中的运用的人",
        "想开始学习统计学的人",
        "想学习统计学基础的人"
      ]
    },
    {
      "title": "Deep Learning con Python e PyTorch: Teoria e Pratica",
      "url": "https://www.udemy.com/course/deep-learning-python-pytorch/",
      "bio": "Esplora le basi del machine learning, immergiti nelle reti neurali e PyTorch per realizzare progetti concreti.",
      "objectives": [
        "Ripasso di Python",
        "Introduzione a PyTorch",
        "Basi del Deep Learning",
        "Lavorare con i Dati in PyTorch",
        "Costruire e Addestrare Modelli di Deep Learning con PyTorch",
        "Test e Valutazione del Modello",
        "Costruire una Rete Neurale Convoluzionale"
      ],
      "course_content": {},
      "requirements": [
        "Raccomandato: Conoscenza Base di Python",
        "Consigliato: Nozioni Base di Statistica e Probabilità",
        "Corso creato su sistema operativo Windows. Le nozioni all'interno possono essere applicate anche usando MacOS",
        "Mentalità Aperta e Motivazione all'Apprendimento"
      ],
      "description": "Diventa un esperto di deep learning con Python e PyTorch.\nStai cercando di entrare nel mondo dell'intelligenza artificiale ma non sai da dove iniziare? Questo corso ti accompagnerà passo dopo passo, dalle basi fino alle applicazioni avanzate del deep learning, con esempi pratici e progetti reali.\nPerché Questo Corso è Diverso? Non ti limiterai a guardare teoria: in ogni lezione costruirai qualcosa di concreto. Partiamo dai concetti fondamentali spiegati in modo chiaro, per poi applicarli subito nella pratica. È come costruire una casa: prima le fondamenta solide, poi mattone dopo mattone fino al tetto.\nCosa Imparerai?\nFondamenti di PyTorch: inizia il tuo viaggio con una solida comprensione di PyTorch, il framework di deep learning scelto dai professionisti dell'intelligenza artificiale per i suoi potenti strumenti e la sua flessibilità.\nPrincipi del Deep Learning: acquisirai una profonda comprensione delle reti neurali, dei tensor, delle funzioni di attivazione, delle funzioni di perdita e molto altro, costruendo una base solida su cui innestare le tue conoscenze future.\nProgetto Pratico: metti in pratica ciò che hai imparato sviluppando un progetto reale complesso, sperimentando la potenza del deep learning applicata ad un problema concreto.\nPreparazione per il Futuro: al di là delle competenze tecniche, otterrai le risorse, gli strumenti e i consigli per continuare il tuo apprendimento nel deep learning, mantenendoti sempre all'avanguardia in questo campo in rapida evoluzione.\nA Chi è Rivolto Questo Corso?\nPer programmatori Python che vogliono entrare nel mondo dell'AI;\nPer studenti universitari che cercano applicazioni pratiche della teoria;\nPer professionisti IT che desiderano aggiungere il deep learning al loro toolkit.\nPrerequisiti:\nConoscenza base di Python (cicli, funzioni, liste), all'interno è presente un ripasso veloce;\nFondamenti di matematica (algebra lineare e calcolo non richiesti ma utili);\nTanta curiosità e voglia di sperimentare.\nIl Tuo Percorso di Apprendimento:\nInizierai con progetti semplici ma funzionanti;\nGradualmente affronterai sfide più complesse;\nConcluderai con un portfolio di progetti reali da mostrare.\nIscriviti oggi e inizia il tuo percorso per diventare un esperto di deep learning.\nNon perdere questa opportunità unica di acquisire le competenze del futuro!",
      "target_audience": [
        "Sviluppatori e Programmatori",
        "Laureati e Studenti in Discipline Scientifiche",
        "Professionisti del Settore Data Science",
        "Appassionati di Tecnologia"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第二部 - 人機對話大師：打造流暢AI互動系統，實現無縫交流",
      "url": "https://www.udemy.com/course/generative-ai-speechai/",
      "bio": "LangChain，chatGPT，Streamlit，Generative AI，Artificial Intelligence，natural language processing, RAG, LLM, Python",
      "objectives": [
        "使用Generative AI生成式人工智能實現語音回覆人類",
        "了解如何使用RAG增強檢索生成功能加載信息",
        "了解如何將語音與文字的互相轉換",
        "了解如何實現與AI近乎實時的自然對話",
        "了解制定網站，並以此為根據回答用戶提問"
      ],
      "course_content": {},
      "requirements": [
        "一台電腦",
        "基礎的Python知識",
        "學習過Generative AI第一部"
      ],
      "description": "如何通過Python和AI技術實現實時語音交互？—— 一站式課程讓你成為技術達人！\n在當前的科技時代，實時語音交互技術正在變得越來越普及。從智能家居到線上客服，語音技術的應用無處不在。你是否也想掌握這項技術，開發自己的語音交互應用？今天，我們為你推薦一門全面深入的課程——“AI實時語音交互應用開發”，助你從零到一，掌握這項核心技術。\n課程亮點\n學習Python，打好基礎\nPython作為最流行的編程語言之一，其簡單易用性和強大的功能使其成為AI開發的首選工具。在本課程中，我們將幫助你快速回顧Python基礎，確保你能輕鬆應對後續內容。\n探索LangChain和Groq，開啟AI新篇章\nLangChain和Groq是當前AI領域的前沿技術，尤其在處理複雜任務和大規模數據方面表現出色。通過我們的課程，你將了解如何利用這些技術構建高效的AI系統。\n實時語音轉文字，實現無縫交互\n我們將教你如何通過麥克風獲取用戶語音，並將其轉換為文字，為後續的智能問答奠定基礎。\n智能問答，精準回應\n結合ChatGPT等大語言模型，打造一個能夠精準理解並回應用戶提問的智能系統，讓你的應用更加智能化和人性化。\n高質量文字轉語音，讓回覆更生動\n通過先進的語音合成技術，將文本回覆轉換為自然語音，使用戶體驗更加生動和真實。\n使用Streamlit開發美觀易用的網頁App\nStreamlit是一款快速構建數據應用的工具。我們將幫助你將以上所有功能集成到一個美觀、操作簡便的網頁應用中，優化用戶體驗。\n為什麼你需要這門課程？\n全面系統：從基礎到高級，涵蓋語音處理、AI問答、網頁開發的完整流程。\n前沿技術：掌握當前最流行的AI和語音技術，讓你站在科技前沿。\n實戰經驗：通過實際項目操作，積累寶貴的開發經驗。\n本課程將逐步引導你掌握所需技術，並提供實戰專案訓練，最終構建出一個人機實時對話系統。跟著學習，成為人工智能對話領域的佼佼者！現在就加入課程，開啟人機交互的嶄新紀元！",
      "target_audience": [
        "對人工智能和機器學習感興趣的學員",
        "想要了解生成式人工智能技術及其應用的學員",
        "想要了解語音對話系統的學員",
        "想要了解如何使用LangChain製作LLM應用程式的學員",
        "想要了解如何使用RAG技術的學員"
      ]
    },
    {
      "title": "Curso intensivo programador IA machine learning python",
      "url": "https://www.udemy.com/course/programador-ai-en-machine-learning-con-python-2023-espanol/",
      "bio": "Domina el Machine Learning con Python: Curso 100% práctico en español para convertirte en programador de ML",
      "objectives": [
        "Comprender como las máquinas aprenden.",
        "Adquirir una comprensión sólida de los conceptos básicos de machine learning, como los algoritmos de aprendizaje supervisado y no supervisado.",
        "Desarrollar habilidades sólidas de programación en Python.",
        "Evaluar y mejorar modelos de machine learning utilizando optimización de hiperparámetros."
      ],
      "course_content": {},
      "requirements": [
        "Se recomienda tener conocimiento en algún lenguaje de programación pero si no lo tienes no te preocupes los conceptos básicos de python que se enseñaran en el curso bastarán para aprender a programar un algoritmo de machine learning."
      ],
      "description": "Aprende Machine Learning con Python en español\nCurso intensivo de 8 horas para dominar la programación de modelos inteligentes\n\n\nDescubre el apasionante mundo del Machine Learning a través de este curso paso a paso. Aprenderás a programar en Python utilizando el entorno de Google, mientras te familiarizas con las técnicas fundamentales de programación en Machine Learning. No se requiere experiencia previa en programación, ya que el curso proporciona los conceptos básicos necesarios para utilizar las librerías de Machine Learning. A lo largo de las 8 horas de instrucción, desarrollarás un sólido entendimiento de las ecuaciones matemáticas aplicadas en el Machine Learning y cómo implementarlas en Python.\n\n\n¿Para quién es este curso?\nEstá dirigido a profesionales que deseen obtener un panorama completo de la Inteligencia Artificial y el Machine Learning en menos de 8 horas. También es ideal para estudiantes de carreras relacionadas con sistemas, ciencia de datos y ciencia de la computación. Tanto programadores juniors, mid, seniors y expertos que busquen conocimientos precisos y práctica en Inteligencia Artificial y Machine Learning pueden beneficiarse de este curso.\n\n\n¿No tengo conocimientos de programación?\nEl curso proporciona un enfoque paso a paso para utilizar algoritmos de Machine Learning y comprender el funcionamiento de la Inteligencia Artificial en las máquinas. Si sigues el curso, podrás realizar los ejemplos por ti mismo, aunque es posible que algunos conceptos necesiten reforzarse con otras fuentes. Sin embargo, este curso te brindará una visión general sólida del funcionamiento actual de la Inteligencia Artificial.\"",
      "target_audience": [
        "Estudiantes, programadores, profesionales que deseen iniciar con los conocimientos en programación en algoritmos de machine learning."
      ]
    },
    {
      "title": "[ES] Bootcamp Agentes IA: Crea Chatbots Inteligentes",
      "url": "https://www.udemy.com/course/bootcamp-de-agentes-de-ia-crea-chatbots-inteligentes/",
      "bio": "Crea agentes de IA, bots de automatización, asistentes y flujos inteligentes con modelos locales, sin necesidad de APIs",
      "objectives": [
        "Crea agentes de IA para automatizar tareas y chats sin depender de APIs externas, mejorando la eficiencia del flujo de trabajo.",
        "Desarrolla modelos de IA que entienden, procesan y generan respuestas humanas, creando sistemas de conversación dinámicos.",
        "Implementa bots de automatización que realizan tareas repetitivas y gestionan agendas sin intervención manual.",
        "Usa bases de datos locales como FAISS para almacenar y procesar conocimiento, eliminando la dependencia de APIs en la nube.",
        "Integra funciones de voz a texto y texto a voz en agentes de IA para lograr interacción manos libres.",
        "Diseña chatbots de IA con memoria a largo plazo mediante almacenamiento local para mantener contexto entre conversaciones.",
        "Desarrolla asistentes de IA web con Streamlit, creando interfaces interactivas para automatización en tiempo real.",
        "Crea lectores de documentos de IA que extraen, resumen y responden preguntas de PDFs sin servicios en la nube.",
        "Construye rastreadores de finanzas personales que analizan gastos, aconsejan presupuestos y generan informes localmente.",
        "Mejora modelos de IA con técnicas de ingeniería de prompts para respuestas más precisas y personalizadas."
      ],
      "course_content": {
        "Día 1: Introducción a Agentes de IA - Curso Práctico": [
          "Objetivos del Día 1: Introducción a Agentes de IA y Herramientas",
          "¿Qué son los Agentes de IA?",
          "¿Por qué usar Ollama para Agentes de IA?",
          "Configuración de Ollama",
          "Descargar un Modelo para Agentes de IA",
          "Conceptos Básicos de Python para IA (Opcional)",
          "Construir un Agente de IA Simple",
          "Agregar Memoria al Agente de IA",
          "Crear una Interfaz Web para el Agente de IA"
        ],
        "Día 2: Creación de un Asistente Personal de IA - Curso Práctico de Agentes de IA": [
          "Objetivos del Día 2: Creación de un Asistente Personal de IA",
          "Instalar Dependencias",
          "Construir el Asistente de Voz de IA",
          "Cómo Funciona el Asistente de IA",
          "Ejecutar el Asistente de IA",
          "Crear un Asistente de Voz de IA Basado en Web"
        ],
        "Día 3: Agente de Web Scraping Potenciado por IA- Curso Práctico de Agentes de IA": [
          "Objetivos del Día 3: Agente de Web Scraping Potenciado por IA",
          "Instalar Dependencias",
          "Construir el Web Scraper de IA",
          "Cómo Funciona el Web Scraper de IA",
          "Ejecutar el Web Scraper de IA",
          "Almacenar Datos Extraídos en una Base de Datos Vectorial"
        ],
        "Día 4: Lector de Documentos y Bot de Preguntas y Respuestas Potenciado por IA": [
          "Objetivos Día 4: Lector de Documentos y Bot de Preguntas IA",
          "Instalar Dependencias",
          "Construir el Lector de Documentos de IA",
          "Cómo Funciona el Lector de Documentos de IA",
          "Ejecutar el Lector de Documentos de IA",
          "Habilitar la Descarga de Archivos de Reportes Resumidos por IA"
        ]
      },
      "requirements": [
        "¡No se necesita experiencia previa en IA! Conocer programación básica en Python es útil, pero no obligatorio, ya que se cubrirán los conceptos esenciales a lo largo del curso.",
        "Una computadora (Windows, macOS o Linux) con acceso a internet para instalar las herramientas necesarias, ejecutar modelos de IA localmente y desarrollar aplicaciones interactivas impulsadas por IA.",
        "Tener familiaridad con herramientas de línea de comandos como Terminal o Command Prompt es útil, pero no obligatorio, ya que se proporcionarán instrucciones paso a paso para todas las configuraciones.",
        "Una comprensión básica de lógica, resolución de problemas y pensamiento estructurado ayudará a diseñar flujos de trabajo de IA y a automatizar tareas de manera eficiente.",
        "Tener algo de conocimiento sobre conceptos de aprendizaje automático es beneficioso pero no necesario; se introducirán los fundamentos de la IA y sus aplicaciones prácticas de forma progresiva.",
        "Disposición para experimentar, depurar y iterar en proyectos de IA para adquirir experiencia práctica en la construcción, prueba y perfeccionamiento de herramientas de automatización inteligente.",
        "Paciencia y curiosidad para explorar tecnologías de IA, aprender técnicas de ingeniería de prompts y construir agentes de IA funcionales con casos de uso reales.",
        "Una mentalidad abierta para adoptar soluciones impulsadas por IA, automatizar tareas diarias y mejorar la eficiencia mediante asistentes y bots de automatización.",
        "Tener conocimientos básicos de JSON, procesamiento de texto o web scraping es útil pero no necesario; todos los conceptos relevantes se explicarán mediante proyectos prácticos.",
        "¡No se necesita software costoso ni servicios en la nube! Todos los agentes de IA y bots de automatización se construirán utilizando herramientas de código abierto y métodos de ejecución local."
      ],
      "description": "Este curso está traducido mediante IA del inglés al español para que puedas aprender tecnologías de vanguardia en tu idioma nativo.\nLa inteligencia artificial está transformando la manera en que trabajamos, automatizamos tareas e interactuamos con la tecnología. Este curso está diseñado para ayudar a los estudiantes a construir agentes de IA, bots de automatización, asistentes de chat y sistemas de gestión de tareas utilizando herramientas de código abierto, sin depender de APIs externas ni de servicios en la nube. Tanto si eres un principiante que explora el mundo de la inteligencia artificial como si eres un desarrollador que busca integrar IA en aplicaciones del mundo real, este curso ofrece un enfoque práctico para construir soluciones de automatización impulsadas por IA.\nA lo largo del curso, los estudiantes adquirirán experiencia práctica en el desarrollo de asistentes inteligentes capaces de procesar texto, responder a consultas de usuarios, automatizar tareas repetitivas y gestionar flujos de trabajo de manera eficiente. El enfoque estará en implementar chatbots inteligentes, gestores de tareas, lectores de documentos, web scrapers y asistentes personales de productividad. Aprovechando modelos de IA locales, bases de datos vectoriales y técnicas de procesamiento de lenguaje natural, los alumnos aprenderán a crear soluciones de IA que funcionan completamente en sus propios dispositivos, sin necesidad de APIs en la nube.\nEl curso comienza con una introducción a los agentes de IA, cubriendo los conceptos fundamentales de procesamiento de lenguaje natural, flujos de automatización y ejecución de tareas. Los estudiantes construirán chatbots capaces de mantener conversaciones significativas y conservar la memoria de interacciones anteriores. Al integrar modelos de IA con bases de datos vectoriales locales como FAISS, aprenderán a almacenar y recuperar información de manera eficiente, permitiendo a sus agentes de IA responder consultas complejas basadas en conocimiento almacenado. A medida que avanza el curso, los alumnos desarrollarán bots de automatización de tareas capaces de programar, organizar y priorizar actividades utilizando inteligencia de máquina.\nUno de los aspectos clave del curso es la creación de lectores de documentos impulsados por IA que extraen, resumen y responden preguntas a partir de archivos PDF. Los estudiantes implementarán un sistema de IA que procesa y recupera información relevante, habilitando funcionalidades inteligentes de búsqueda y preguntas y respuestas en documentos. Además, construirán un web scraper impulsado por IA que extrae texto de sitios web, resume contenido y almacena información valiosa en una base de datos vectorial para su posterior consulta. Estas técnicas de automatización de IA pueden aplicarse en diferentes áreas como investigación, inteligencia empresarial y generación de contenido.\nA medida que los estudiantes progresen en el curso, trabajarán en proyectos que integran la IA en herramientas de productividad diaria. Desarrollarán asistentes personales de IA que ayudan con la programación de actividades, recordatorios y gestión de flujos de trabajo. También se abordará la priorización de tareas mediante IA, donde los estudiantes entrenarán modelos capaces de analizar fechas límite y asignar niveles de importancia a diferentes actividades. Al finalizar el curso, los estudiantes tendrán una comprensión sólida sobre cómo construir agentes de IA capaces de automatizar tareas complejas, mejorar la productividad y gestionar flujos de trabajo basados en datos.\nEste curso está dirigido a desarrolladores de software, analistas de datos, entusiastas de la IA y cualquier persona interesada en construir soluciones de automatización basadas en inteligencia artificial. No se requiere experiencia previa en IA, ya que todos los conceptos se introducen de manera progresiva mediante implementaciones paso a paso. Los estudiantes adquirirán experiencia práctica con herramientas de IA, modelos de machine learning y frameworks de automatización, convirtiendo este curso en una opción ideal para quienes desean integrar la IA en aplicaciones reales. Todos los proyectos se construyen utilizando software de código abierto y se ejecutan localmente, garantizando privacidad, seguridad y control total sobre los sistemas de automatización.\nAl finalizar el curso, los estudiantes contarán con los conocimientos y habilidades prácticas para crear chatbots, bots de automatización, lectores de documentos, web scrapers y asistentes personales inteligentes impulsados por IA. Estarán capacitados para desarrollar soluciones de IA que optimicen flujos de trabajo, aumenten la productividad y automaticen tareas repetitivas de manera eficiente. Este curso proporciona una base sólida en automatización impulsada por IA y equipa a los alumnos con la capacidad de diseñar, construir y desplegar agentes de IA para diversos casos de uso.",
      "target_audience": [
        "Principiantes y entusiastas de la tecnología que quieran explorar la IA y construir asistentes inteligentes sin experiencia previa en machine learning o programación.",
        "Desarrolladores de software e ingenieros que buscan integrar automatización impulsada por IA en sus aplicaciones, optimizar flujos de trabajo y crear asistentes personalizados.",
        "Emprendedores y dueños de negocios que desean aprovechar la automatización con IA para atención al cliente, gestión de tareas y eficiencia empresarial.",
        "Freelancers y profesionales que quieren mejorar su productividad desarrollando bots de automatización de tareas y asistentes personales impulsados por IA.",
        "Analistas de datos e investigadores interesados en utilizar IA para automatizar la extracción, el análisis y la síntesis de datos para obtener mejores insights.",
        "Estudiantes y aprendices apasionados por la inteligencia artificial, deseosos de adquirir experiencia práctica construyendo agentes de IA y herramientas de automatización.",
        "Creadores de contenido y especialistas en marketing que buscan automatizar la generación de contenido, la gestión de redes sociales y el engagement con su audiencia mediante IA.",
        "Aficionados a la IA e innovadores que disfrutan experimentando con herramientas de código abierto para desarrollar asistentes personalizados y sistemas de automatización.",
        "Cualquier persona curiosa sobre la IA y la automatización que quiera aprender aplicaciones prácticas sin depender de APIs complejas ni servicios en la nube.",
        "Desarrolladores que están haciendo la transición hacia IA y automatización, en busca de experiencia práctica construyendo agentes inteligentes mediante métodos de ejecución local."
      ]
    },
    {
      "title": "深度学习框架-PyTorch实战系列",
      "url": "https://www.udemy.com/course/pytorch-best/",
      "bio": "PyTorch框架实战",
      "objectives": [
        "掌握深度学习必备经典算法",
        "掌握深度学习框架PyTorch核心模块使用方法",
        "熟练使用PyTorch框架进行实际开发",
        "熟练应用PyTorch框架构建图像识别项目",
        "熟练应用PyTorch框架构建自然语言处理项目",
        "掌握文字识别OCR原理及其项目构建方法",
        "掌握视频分析与3D卷积原理及实战方法",
        "掌握文本分类方法及其网络架构",
        "熟练应用PyTorch模板进行实际项目工作",
        "掌握GAN网络架构原理",
        "熟练使用cycleGan进行图像合成"
      ],
      "course_content": {
        "PyTorch框架基本处理操作": [
          "PyTorch实战课程简介",
          "PyTorch框架发展趋势简介",
          "框架安装方法（CPU与GPU版本）",
          "PyTorch基本操作",
          "课程数据代码下载（谷歌网盘）",
          "自动求导机制",
          "线性回归DEMO-数据与参数配置",
          "线性回归DEMO-训练回归模型",
          "补充：常见tensor格式",
          "补充：Hub模块简介"
        ],
        "神经网络实战分类与回归任务": [
          "气温数据集与任务介绍",
          "按建模顺序构建完成网络架构",
          "简化代码训练网络模型",
          "分类任务概述",
          "构建分类网络模型",
          "DataSet模块介绍与应用方法"
        ],
        "卷积神经网络原理与参数解读": [
          "卷积神经网络应用领域",
          "卷积的作用",
          "卷积特征值计算方法",
          "得到特征图表示",
          "步长与卷积核大小对结果的影响",
          "边缘填充方法",
          "特征图尺寸计算与参数共享",
          "池化层的作用",
          "整体网络架构",
          "VGG网络架构",
          "残差网络Resnet",
          "感受野的作用"
        ],
        "图像识别核心模块实战解读": [
          "卷积网络参数定义",
          "网络流程解读",
          "Vision模块功能解读",
          "分类任务数据集定义与配置",
          "图像增强的作用",
          "数据预处理与数据增强模块",
          "Batch数据制作"
        ],
        "迁移学习的作用与应用实例": [
          "迁移学习的目标",
          "迁移学习策略",
          "加载训练好的网络模型",
          "优化器模块配置",
          "实现训练模块",
          "训练结果与模型保存",
          "加载模型对测试数据进行预测",
          "额外补充-Resnet论文解读",
          "额外补充-Resnet网络架构解读"
        ],
        "递归神经网络与词向量原理解读": [
          "RNN网络架构解读",
          "词向量模型通俗解释",
          "模型整体框架",
          "训练数据构建",
          "CBOW与Skip-gram模型",
          "负采样方案"
        ],
        "新闻数据集文本分类实战": [
          "任务目标与数据简介",
          "RNN模型所需输入格式解析",
          "项目配置参数设置",
          "新闻数据读取与预处理方法",
          "LSTM网络模块定义与参数解析",
          "训练LSTM文本分类模型",
          "Tensorboardx可视化展示模块搭建",
          "CNN应用于文本任务原理解析",
          "网络模型架构与效果展示"
        ],
        "对抗生成网络架构原理与实战解析": [
          "对抗生成网络通俗解释",
          "GAN网络组成",
          "损失函数解释说明",
          "数据读取模块",
          "生成与判别网络定义"
        ],
        "基于CycleGan开源项目实战图像合成": [
          "CycleGan网络所需数据",
          "CycleGan整体网络架构",
          "PatchGan判别网络原理",
          "Cycle开源项目简介",
          "数据读取与预处理操作",
          "生成网络模块构造",
          "判别网络模块构造",
          "损失函数：identity loss计算方法",
          "生成与判别损失函数指定",
          "额外补充：VISDOM可视化配置"
        ],
        "OCR文字识别原理": [
          "OCR文字识别要完成的任务",
          "CTPN文字检测网络概述",
          "序列网络的作用",
          "输出结果含义解析",
          "CTPN细节概述",
          "CRNN识别网络架构",
          "CTC模块的作用"
        ]
      },
      "requirements": [
        "熟悉Python",
        "熟悉深度学习"
      ],
      "description": "深度学习框架-PyTorch实战课程旨在帮助同学们快速掌握PyTorch框架核心模块使用方法与项目应用实例，让同学们熟练使用PyTorch框架进行项目开发。课程内容全部以实战为导向，基于当下计算机视觉与自然语言处理中经典项目进行实例讲解，通过Debug模式详解项目中每一行代码的作用与效果，整体风格通俗易懂。",
      "target_audience": [
        "人工智能方向的同学们",
        "深度学习方向的同学们"
      ]
    },
    {
      "title": "Основы Искусственного Интеллекта",
      "url": "https://www.udemy.com/course/artintel/",
      "bio": "Практически всё, что нужно знать для жизни в новом дивном мире",
      "objectives": [
        "Сможете свободно оперировать ключевыми понятиями ИИ, понимать сильные и слабые стороны различных подходов, легко отличать фейки от прорывных новостей в волне хайпа",
        "Узнаете, на что способен ИИ в таких областях, как государственное управление, здравоохранение, безопасность, транспорт, промышленность, коммерция, творчество, наука, образование",
        "Поймёте, где и как применять ИИ уже сейчас или в ближайшие месяцы"
      ],
      "course_content": {},
      "requirements": [
        "Общий здравый смысл"
      ],
      "description": "Вы разберётесь в теме ИИ за 1.5 месяца\nСможете свободно оперировать ключевыми понятиями ИИ, понимать сильные и слабые стороны различных подходов, легко отличать фейки от прорывных новостей в волне хайпа. Вы узнаете, на что способен ИИ в таких областях, как государственное управление, здравоохранение, безопасность, транспорт, промышленность, коммерция, творчество, наука, образование. Вы поймёте, где и как применять ИИ уже сейчас или в ближайшие месяцы.",
      "target_audience": [
        "Всем, кто смотрит в будущее и хочет жить в мире с искусственными интеллектуальными системами"
      ]
    },
    {
      "title": "Curso Snowflake: Análisis y Visualización de Datos",
      "url": "https://www.udemy.com/course/curso-snowflake-analisis-y-visualizacion-de-datos/",
      "bio": "Flavio, te llevará paso a paso para transformar, analizar y visualizar datos en Snowflake como un profesional.",
      "objectives": [
        "Comprender la arquitectura y funcionamiento de Snowflake.",
        "Importar, transformar y modelar datos dentro de Snowflake.",
        "Aplicar técnicas de optimización para mejorar el rendimiento de las consultas.",
        "Realizar análisis exploratorio y estadístico con Snowflake.",
        "Integrar Snowflake con Python para análisis de datos y machine learning.",
        "Conectar Snowflake con herramientas de visualización como Power BI o Tableau.",
        "Aplicar Snowflake en casos prácticos reales de análisis de datos."
      ],
      "course_content": {
        "Introducción": [
          "Bienvenido a DataBoosters",
          "Presentación del Instructor"
        ],
        "Fundamentos de Snowflake": [
          "Introducción a snowflake",
          "Creación de cuenta y recorrido por snowflake",
          "Primeros pasos en Snowflake",
          "Gestión de usuarios, roles y permisos",
          "Almacenamiento y organización de datos"
        ],
        "Gestión y Transformación de Datos": [
          "Carga de datos",
          "Carga de datos Cloud",
          "Transformaciones SQL Introducción",
          "Transformaciones SQL Diseño de Querys",
          "Transformaciones SQL Practica Diseño de Querys",
          "Transformacion SQL - String",
          "Transformaciones SQL - Date",
          "Transformaciones SQL - Integer",
          "Automatización de carga de datos con Snowpipe"
        ],
        "Modelado de Datos": [
          "Introducción al modelado de datos",
          "Modelado dimensional"
        ],
        "Optimización de Consultas": [
          "Optimización de Consultas SQL",
          "Optimización de consultas SQL Clustering",
          "Optimización de consultas SQL Planes de Ejecución",
          "Vistas materializadas",
          "Monitoreo de recursos"
        ],
        "Análisis Exploratorio y Estadístico": [
          "Consultas SQL avanzadas",
          "Consultas avanzadas SQL Widow Function",
          "Funciones avanzadas Pivot y Qualified en Snowflake",
          "Funciones Avanzadas Unpivot",
          "Funciones Avanzadas Having",
          "Funciones Avanzadas Qualify",
          "Visualización en Snowsight"
        ],
        "Integración con Programación (Python)": [
          "Conexión con Python",
          "Automatización con Python",
          "Uso de Snowpark"
        ],
        "Análisis Predictivo y Machine Learning con Python": [
          "Preparación de datos para ML",
          "Integración con herramientas de ML",
          "Ejecución de scripts de ML"
        ],
        "Conexión a Herramientas de Visualización": [
          "Conexión a Power BI",
          "Conexión a Looker Studio"
        ],
        "Casos Prácticos de snowflake": [
          "Caso práctico 1: Python - Automatización de análisis de datos",
          "Caso práctico 2: Python - Machine Learning con Snowflake",
          "Caso práctico 3: Power BI."
        ]
      },
      "requirements": [
        "Conocimientos básicos de SQL.",
        "No se requiere experiencia previa en Snowflake."
      ],
      "description": "Domina Snowflake desde lo básico hasta su aplicación en análisis y visualización de datos.\nEn la era del Big Data, las empresas necesitan herramientas eficientes para almacenar, procesar y analizar grandes volúmenes de datos. Snowflake se ha convertido en una de las plataformas de almacenamiento y análisis en la nube más poderosas y utilizadas por empresas líderes. Este curso te enseñará a gestionar, transformar y visualizar datos con Snowflake, permitiéndote obtener insights valiosos de manera rápida y eficiente.\nComenzaremos con los fundamentos de Snowflake, explorando su arquitectura y sus ventajas sobre otros sistemas de bases de datos en la nube. Aprenderás a importar, transformar y modelar datos, asegurando estructuras optimizadas para análisis y reportes.\nLuego, nos enfocaremos en la optimización de consultas, donde aprenderás a mejorar el rendimiento y reducir costos al ejecutar consultas eficientes. También trabajaremos con análisis exploratorio y estadístico, utilizando funciones avanzadas para analizar tendencias y patrones en los datos.\nAdemás, exploraremos la integración de Snowflake con Python, lo que te permitirá automatizar procesos, aplicar modelos de machine learning y realizar análisis más profundos. Por último, aprenderás a conectar Snowflake con herramientas de visualización como Power BI y Tableau, facilitando la creación de dashboards interactivos y reportes ejecutivos.\nEste curso es ideal para analistas de datos, científicos de datos, desarrolladores y profesionales de business intelligence que buscan dominar Snowflake y aplicarlo en el mundo real.\n¡Inscríbete ahora y conviértete en un experto en Snowflake, optimizando tu trabajo con datos en la nube!",
      "target_audience": [
        "Analistas de datos que desean trabajar con Snowflake.",
        "Científicos de datos que buscan realizar análisis y machine learning con Snowflake.",
        "Profesionales de business intelligence que quieren conectar Snowflake con herramientas de visualización."
      ]
    },
    {
      "title": "Snowflake AI/ML実践ハンズオン ~ Snowpark・Cortex AI・ML関数によるデータ活用~",
      "url": "https://www.udemy.com/course/snowflake-ai-ml-cortex-snowpark/",
      "bio": "Snowflakeで始めるAI/ML開発コースです。Snowflake MLやCortex AI、Snowpark、Streamlitなどを使い、データ準備からモデル構築、活用まで体験し、実践スキルを習得しましょう！",
      "objectives": [
        "Snowflakeによるデータの扱い",
        "Snowflake Streamlitによるデータの可視化・アプリ化",
        "SnowparkによるPythonでのモデル構築",
        "Cortex AIの使い方",
        "SnowflakeのML Pipeline構築",
        "Snowflakeにおけるタスク設定方法",
        "Snowflakeにおけるストアドプロシージャの設定"
      ],
      "course_content": {
        "コース紹介": [
          "コース紹介",
          "サンプルコード・データのダウンロード",
          "コース準備レクチャー"
        ],
        "イントロダクション": [
          "Snowflakeについて",
          "3大クラウド",
          "データウェアハウス",
          "Snowflakeユーザーガイド",
          "Snowflakeの特徴",
          "料金体系の補足",
          "SnowflakeでAI/MLをする理由",
          "Snowparkとは？"
        ],
        "Snowflakeのセットアップ": [
          "セットアップ",
          "インターフェース",
          "データベース・スキーマ・テーブル・権限まわり",
          "データベース・テーブル・ウェアハウスの準備",
          "データの確認"
        ],
        "Snowflake ML関数／ Cortex AI入門：SQLでAIを活用しよう": [
          "演習内容の説明",
          "時系列予測モデルの作成①",
          "時系列予測モデルの作成②",
          "異常検知",
          "Cortex : Complete",
          "Cortex : Translate",
          "Cortex : Summarize"
        ],
        "Snowpark入門": [
          "ノートブックの説明",
          "デモの説明",
          "Snowparkの練習①：Session",
          "Snowparkの練習②：SnowparkデータフレームとPandasデータフレーム",
          "Snowparkの練習③：フィルタ・集計・テーブルへの格納",
          "ノートブックのスケジューリング",
          "ローカルデータの使用"
        ],
        "Snowparkによるカスタムモデルの作成": [
          "演習内容の説明",
          "テーブルの作成",
          "データの前処理①",
          "データの前処理②",
          "モデリングと評価",
          "モデルの登録"
        ],
        "Snowflake Streamlitによるアプリ化": [
          "演習内容の説明",
          "Streamlitの準備",
          "データフレームの表示",
          "グラフの表示",
          "（参考）Streamlitの文法"
        ],
        "SnowflakeにおけるMLパイプライン構築": [
          "演習内容の説明",
          "ストアドプロシージャの作成（練習）①",
          "ストアドプロシージャの作成（練習）②",
          "ストアドプロシージャの作成（練習）③",
          "ストアドプロシージャの呼び出し",
          "ワークフロー作成の準備",
          "ストアドプロシージャの作成①",
          "ストアドプロシージャの作成②",
          "ストアドプロシージャの登録",
          "タスクの設定",
          "タスクの実行結果の確認",
          "Streamlitアプリへの反映",
          "無駄にお金がかからないように①",
          "無駄にお金がかからないように②"
        ],
        "おわりに": [
          "終わりに"
        ]
      },
      "requirements": [
        "基本的なPython, SQL言語の使い方がわかるとよいです",
        "Snowflakeのアカウントが必要になります"
      ],
      "description": "本コースは、データ活用の場面で求められるAI/ML技術と、クラウドデータプラットフォームの代表格であるSnowflakeを組み合わせた実践スキルを習得できるコースです。\n\n本講座では、SQLだけで利用できるCortex AIから、Pythonベースの開発環境Snowpark、そしてアプリケーション構築のためのStreamlitまで、Snowflakeのエコシステムを活用したAI/ML開発の全工程を体験します。\n\n理論だけでなく、実際に手を動かしながらデータ準備からモデル構築、実用アプリケーションの開発まで一貫して学ぶことで、現場ですぐに活かせる実践スキルを身につけることができます。\n\n内容:\nイントロダクション:\nAI/MLとSnowflakeの基本概念から、データ分析基盤としてのSnowflakeの位置づけ、AI/ML開発における活用シナリオなどを理解し、本コースの全体像を把握します。\nSnowflakeのセットアップ:\nSnowflake環境の構築から必要なデータセットの準備まで、開発をスムーズに始めるための基盤を整えます。\nSnowflake ML/Cortex AI入門：SQLでAIを活用しよう:\nSQLの知識だけで生成AI機能を活用できるCortex AIとML関数の使い方を学びます。テキスト分析、予測モデルなど、複雑なコーディングなしで実現できる機能を実践的に体験し、ビジネスデータへの応用方法を習得します。\nSnowpark入門：カスタムモデルを作ろう:\nPythonベースのSnowparkを使用してカスタムAI/MLモデルを構築する方法を学びます。データの前処理からモデルのトレーニング、評価、最適化まで、データサイエンスのワークフローを実践的に体験し、自社のビジネス課題に特化したモデル開発スキルを習得します。\nStreamlitによるアプリ化:\n構築したモデルをStreamlitを使って対話型Webアプリケーションとして実装する方法を学びます。データの可視化、ユーザーインターフェースの設計、モデル結果の解釈支援など、エンドユーザーが実際に活用できるアプリケーション開発スキルを習得します。\nSnowflakeにおけるMLパイプライン構築:\nデータ前処理からモデル学習、推論、評価まで、ストアドプロシージャとタスクの設定による一連のMLパイプラインをSnowflake上で構築する方法を学びます。\n\n本コースの対象と狙い:\nSQLの基本知識を持ち、AI/ML技術を業務に取り入れたいデータアナリストやBI担当者\nSnowflakeの基本的な利用経験があり、さらに高度な活用法を学びたい方\nデータサイエンスやAI/MLの基礎知識があり、Snowflakeでの実装方法を習得したい方\nクラウドデータプラットフォームを活用した最新のデータ分析手法を学びたいIT担当者\n組織のデータ活用を推進する立場にあり、AI/MLの実用的な導入方法を模索している方\n\n本コースを受講することで、Snowflakeを活用したAI/ML開発工程を理解し、データからインサイトを抽出するためのモデル構築、そしてビジネス価値を創出するアプリケーション開発まで、一貫したスキルセットを習得できます。ハンズオン重視の内容で、現場ですぐに活用できる知識を提供します。\n\n本コース「Snowflake × AI/ML 実践ハンズオン」では、最新のデータプラットフォームを活用したAI開発をハンズオン形式で学ぶことができます。SQLによる簡単なAI機能の活用から、機械学習モデル開発、そしてアプリケーション構築まで、現代のデータプロフェッショナルに求められる幅広いスキルセットを効率的に習得できるでしょう。\n\n理論だけでなく実践を重視した本コースを通じて、あなたのデータ活用スキルを次のレベルへと引き上げ、組織におけるデータドリブンな意思決定や価値創出に貢献しましょう。Snowflakeの可能性を最大限に引き出し、AI時代のデータ活用をリードする人材へと成長するための第一歩を、今すぐ踏み出してください！",
      "target_audience": [
        "Snowflakeを使ったことがあり、一歩先のレベルに進みたいデータアナリスト・データサイエンティスト",
        "機械学習やAI活用にも興味があるデータエンジニア",
        "Snowflakeでどんなことができるか知っておきたいマネージャーや管理職",
        "これからSnowflakeを使ったデータ活用を行う必要がある方"
      ]
    },
    {
      "title": "Data Science em R: ETL parte 3 - Text Mining",
      "url": "https://www.udemy.com/course/manipulacao-de-strings-no-r-para-data-science/",
      "bio": "Manipulação e Transformação de Texto",
      "objectives": [
        "Criar strings no R",
        "Conhecer as expressões especiais no R",
        "Aprender sobre vetores de strings",
        "Combinar diferentes strings",
        "Visualizar e transformar strings em dados úteis",
        "Modificar textos",
        "Mostrar palavras específicas na string",
        "Trabalhar com repetições de strings no R",
        "Detectar padrões específicos na string",
        "Extrair informações específicas na string",
        "Substituir partes específicas de uma string",
        "Separar strings em diferentes tipos"
      ],
      "course_content": {
        "Introdução": [
          "Seja muito bem vindo(a)!",
          "Antes de iniciarmos...",
          "Visão geral",
          "Introdução",
          "Bibliotecas"
        ],
        "Objetivos": [
          "Criação de Strings",
          "Criação de Strings - Expressões Especiais",
          "Criação de Strings - Vetores de Strings",
          "Combinação de Strings",
          "Combinação de Strings - usando condições",
          "Combinação de Strings - reunindo elementos de um vetor de strings",
          "Criando subgrupos de strings",
          "Captando e Transformando as Datas (obtidas de strings)",
          "Modificando Strings",
          "Mostrando palavras específicas - parte 1",
          "Mostrando palavras específicas - parte 2",
          "Repetições em Strings"
        ],
        "Detectando padrões": [
          "Detectando padrões - Contagem",
          "Detectando padrões - Begins with...",
          "Detectando padrões - Ends",
          "Lecture 18 - Detect matches - or",
          "Detect matches - no",
          "Detect matches in Data Frames Tibbles",
          "Observação Importante sobre a aula anterior",
          "Detect matches in Data Frames - New variables"
        ],
        "Extraindo Correspondências": [
          "Extratc matchs"
        ],
        "Substituindo Correspondências": [
          "Replacing matches"
        ],
        "Separando Strings": [
          "Splitting"
        ],
        "Procurando Padrões - Pontos Especiais": [
          "Find Matches",
          "Exercício Proposto #1 (Atividade de Fixação) - Questões",
          "Exercício Proposto #1 - Solução"
        ],
        "Projeto de Aplicação": [
          "Etapas do Projeto"
        ],
        "Aula Bônus": [
          "Aula Bônus",
          "Trilha de Aprendizado para a carreira em Data Science"
        ]
      },
      "requirements": [
        "Indico fazer antes meu Curso de Linguagem R do zero"
      ],
      "description": "Por que você precisa fazer este?\n\nQuer ser um Data Science de sucesso? Tudo começa com os dados, portanto você precisará PREPARAR CORRETAMENTE os bancos de dados de diferentes formatos e diferentes origens. Além disto, grande parte desses dados estarão de forma DESESTRUTURADA e muitas vezes em formato de STRINGS. Então você precisa aprender as ferramentas mais importantes para manipular essas strings e só assim conseguir estruturar seu banco de dados no próprio R, a principal ferramente de análise de dados do momento.\nQuais os benefícios deste curso? O que vou poder fazer quando terminar?\nConseguir dominar as principais ferramentas para manipular Strings\nQual(s) o(s) diferencial deste curso?\nAprofundamento: ao invés de você ter um curso \"geral\", você terá o passo a passo em detalhes, para que seguindo o mesmo caminho você consiga ter os mesmos resultados.\nAbordagem Simplificada: não adiantaria nada eu saber muita coisa se não soubesse passar isto para você. Então tive sempre esta preocupação, por isso fiz uma pós-graduação em Docência Superior que me ajudou muito na questão de simplificar ao máximo para que qualquer pessoa consiga aprender, independente da sua área de atuação..\nPara quem é este curso?\nProfissionais de Ti que desejam entrar para a área de Data Science\nPesquisadores\nQualquer profissional interessando em estruturar bancos de dados para depois analisá-los\nQuem é o instrutor?\nIsaias Lira - Data Science, Bacharel em Estatística, pós-graduado em Docência Superior, atuou como estatístico em empresas e hoje presta consultorias e treinamentos em Estatística aplicada para profissionais e empresas.\nQual o risco de consumir informação? O que você perde investindo em você mesmo?\nEntão faça acontecer! Junte-se a nossa comunidade e entre para a profissão do futuro!\nAtt Isaias Lira - Data Scince",
      "target_audience": [
        "Leigos interessados em selecionar dados importantes para tomada de decisões, a partir de textos.",
        "Profissionais de TI e quaisquer outros que desejarem Analisar bancos de Dados"
      ]
    },
    {
      "title": "Visualização de dados com Python",
      "url": "https://www.udemy.com/course/visualizacao-dados-python/",
      "bio": "Obtenha insights poderosos a partir de gráficos e figuras",
      "objectives": [
        "Independência na demonstração visual (gráficos e figuras) de grandes volumes de dados usando Python",
        "Produzir e customizar gráficos para as mais diversas finalidades",
        "Adaptar a demonstração visual de dados para diferentes problemas de negócios e acadêmicos",
        "Dominar as boas práticas para visualizações elegantes e didáticas de dados"
      ],
      "course_content": {
        "Materiais e arquivos do curso": [
          "Arquivos para as práticas",
          "Contato com o ministrante"
        ],
        "Princípios básicos do Python": [
          "Apresentação",
          "Colab",
          "Print e comentários",
          "Variáveis",
          "Palavras reservadas",
          "Tipos de dados",
          "Converter tipo de dados",
          "Operadores aritméticos",
          "Operadores relacionais",
          "Operadores lógicos",
          "Estruturas condicionais",
          "Loops",
          "Funções",
          "Listas",
          "Tuplas",
          "Sets",
          "Dicionários",
          "List comprehension",
          "Enumerate",
          "Lambda",
          "Map",
          "Reduce",
          "Filter",
          "Pandas",
          "matplotlib"
        ],
        "Introdução a visualização de dados": [
          "Visualização de dados",
          "Estética e tipos de dados - parte 1",
          "Estética e tipos de dados - parte 2",
          "Estética e tipos de dados - parte 3",
          "Estética e tipos de dados - parte 4",
          "Coordenadas e eixos- parte 1",
          "Coordenadas e eixos- parte 2",
          "Escalas de cor",
          "Tipos de visualizações",
          "Passos",
          "Boas práticas"
        ],
        "Matplotlib": [
          "Introdução",
          "Criando arquivo no colab",
          "Primeiro gráfico",
          "Mudando a aparência da linha",
          "Alterando título e eixos",
          "Alterando título e eixos",
          "Alterando os 'ticks'",
          "Adicionando anotações",
          "Adicionando novas linhas",
          "Adicionando legendas",
          "Finalizando o gráfico",
          "Gráfico de pontos",
          "Finalizando o gráfico de pontos",
          "Outros recursos do matplotlib",
          "Gerando gráfico de temperaturas - parte 1",
          "Gerando gráfico de temperaturas - parte 2",
          "Redimensionando o gráfico",
          "Inserindo grid",
          "Inserindo linha horizontal",
          "Inserindo linha vertical",
          "Ajustando a legenda e as linhas",
          "Pintando área do gráfico",
          "Alterando o estilo do gráfico",
          "Salvando o gráfico",
          "Usando o pandas",
          "Scatter plot usando colunas do pandas",
          "Histograma usando colunas do pandas",
          "Histograma usando colunas do pandas 2",
          "Subplots parte 1",
          "Subplots parte 2",
          "Subplots parte 3",
          "Estética e tipos de dados - Começando",
          "Estética e tipos de dados - Escala discreta",
          "Estética e tipos de dados - Escala contínua",
          "Estética e tipos de dados - Linhas",
          "Coordenadas",
          "Eixos",
          "Gráficos de barras",
          "Dotplot",
          "Histograma",
          "Boxplot",
          "Gráfico de setores",
          "Gráfico de barras agrupadas e empilhadas"
        ],
        "Seaborn": [
          "Introdução",
          "Carregando datasets",
          "Criando seu primeiro gráfico",
          "Criando o seu próxim gráfico",
          "Usando funções do matplotlib",
          "Definindo o estilo dos gráficos",
          "Estética",
          "Paletas de cores",
          "Gráfico de barras",
          "Pointplot",
          "Dotplot",
          "Histograma",
          "Gráfico de distribuição acumulada",
          "Gráfico de densidade",
          "Boxplot",
          "Gráfico de violino",
          "Boxenplot",
          "Stripplot e swarmplot",
          "Heatmap",
          "Pairplot",
          "Jointplot"
        ],
        "Plotly": [
          "Introdução",
          "Instalação",
          "Datasets do plotly",
          "Primeiro gráfico",
          "Gráfico com dataframe",
          "Paletas de cor",
          "Customizando o gráfico",
          "Estética",
          "Gráfico de linhas",
          "Gráfico de área",
          "Scatter plot 3D",
          "Gráfico de barras",
          "Barras empilhadas e agrupadas",
          "Histograma",
          "Boxplot",
          "Gráfico de violino",
          "Strip plot",
          "Joint plots",
          "Gráfico de setores",
          "Sunburst",
          "Treemap",
          "Gráficos geoespaciais"
        ],
        "Outras visualizações: geoespaciais, wordcloud e missings": [
          "Visualizações geoespaciais com Folium",
          "Wordcloud",
          "Visualização de missings com missingno"
        ]
      },
      "requirements": [
        "Não existem pré-requisitos obrigatórios, mas conhecimento básico de lógica de programação computacional é desejável, , visando aumentar o aproveimento do curso pelo aluno (a)"
      ],
      "description": "Torne-se um especialista em visualização de dados através da linguagem Python. Com este curso, você será capaz de transmitir suas ideias por meio de visualização de dados, você construirá gráficos elegantes, dominará os conceitos, as boas práticas e será um dos raros profissionais preparados para gerar a visualização adequada para responder as perguntas que os dados podem explicar.\nO curso é bastante prático, com um módulo teórico para compreensão geral do assunto e todos os demais programando. O conteúdo tem foco nas três bibliotecas mais populares de visualização de dados do Python: o matplotlib, o seaborn e o plotly, e terá um tópico extra para conteúdos adicionais importantes, como visualização de dados geoespaciais, visualização de textos e visualização de dados faltantes (missings).\nAo longo do curso, você construirá gráficos de todos os tipos para dados de diversas dimensões usando a robustez e agilidade computacional da linguagem Python, entenderá o que eles representam, saberá em que situações utilizá-los e será capaz de explorá-los e analisá-los.\nCaso você tenha interesse no curso, mas não tenha conhecimento prévio em Python, isso não será um empecilho. O curso tem um módulo opcional de Python básico. O módulo tem como objetivo ensinar a dar os primeiros passos no Python e torná-lo capaz de fazer todo o curso sem dificuldades com a linguagem.",
      "target_audience": [
        "Analistas de dados, cientistas de dados, analistas de BI, analistas de negócio, estatísticos, pesquisadores em geral. Empreendedores e profissionais de administração, economia, marketing que desejam enriquecer o currículo."
      ]
    },
    {
      "title": "모두를 위한 대규모 언어모델 LLM Part2 - 랭체인(LangChain)으로 나만의 ChatGPT 만들기",
      "url": "https://www.udemy.com/course/llm-part2-langchain-chatgpt/",
      "bio": "대규모 언어 모델 LLM과 랭체인(LangChain)으로 나만의 ChatGPT를 만들어보자!",
      "objectives": [
        "랭체인(LangChain) 라이브러리의 기초개념과 활용 방법",
        "Retrieval-Augmented Generation(RAG)의 개념",
        "Retrieval-Augmented Generation(RAG) 구현의 다양한 활용 사례들",
        "Retrieval-Augmented Generation(RAG)으로 나만의 ChatGPT를 만드는 법"
      ],
      "course_content": {
        "랭체인(LangChain)이란": [
          "랭체인(LangChain)이란",
          "랭체인(LangChain) Quickstart 예제를 통해 랭체인 맛보기",
          "Retrieval-Augmented Generation(RAG) 개념 소개",
          "RAG 실습 - RAG로 ChatPDF 만들기"
        ],
        "외부 텍스트를 불러와보자 - Document Loaders 모듈": [
          "WebBaseLoader - url로부터 HTML 텍스트를 읽어오기",
          "CSVLoader, DirectoryLoader - csv 파일, 폴더 안에 텍스트를 읽어오기",
          "HTMLLoader, JSONLoader, MarkdownLoader - HTML, JSON, Markdown 파일 안에 텍스트를 읽어오기",
          "PDFLoader - PDF 파일 안에 텍스트 읽어오기"
        ],
        "텍스트를 작은 의미 단위로 나눠보자 - Document transformers 모듈": [
          "텍스트와 HTML을 더 작은 의미단위로 나누기",
          "프로그래밍 코드와 마크다운 텍스트를 적절한 의미단위로 나누기 & 토큰(Token) 단위로 텍스트를 나누기"
        ],
        "텍스트를 벡터(Vector)로 변환하고 저장해보자 - 임베딩(Embedding)과 벡터 스토어(Vector Stores)": [
          "임베딩(Embedding)의 개념과 장점",
          "Embedding & Vector stores - 임베딩을 수행하고 임베딩 결과를 DB하고 DB에서 질문과 연관된 문서 찾아오기"
        ],
        "LLM과 벡터 스토어를 연동해보자 - Retriever": [
          "Retriever를 통해 RAG 구현 완성하기"
        ],
        "다양한 임베딩(Embedding) 모델을 연동해보자": [
          "HuggingFaceEmbeddings - 무료 임베딩(Embedding) 모델 연동하기"
        ],
        "이전 대화내역을 기억하고 활용해보자 - 메모리(Memory)": [
          "랭체인(LangChain)으로 챗봇(Chatbot) 만들어보기 (1/2)",
          "랭체인(LangChain)으로 챗봇(Chatbot) 만들어보기 (2/2)"
        ],
        "나만의 ChatGPT 만들기 실습 1 - 판사GPT(JudgeGPT) 만들기": [
          "판사GPT(JudgeGPT) 만들기 실습 (1/2)",
          "판사GPT(JudgeGPT) 만들기 실습 (2/2)",
          "심화 실습 - Compression & 2-Depth 구현 - 판사GPT(JudgeGPT)"
        ],
        "나만의 ChatGPT 만들기 실습 2 - 특허GPT(PatentGPT) 만들기": [
          "특허GPT(PatentGPT) 만들기 실습",
          "심화 실습 - Compression & 2-Depth 구현 - 특허GPT(PatentGPT)"
        ],
        "랭체인(LangChain)으로 엔티티 추출(Entity Extraction)을 진행해보자": [
          "랭체인(LangChain)을 이용한 엔티티 추출(Entity Extraction) 실습"
        ]
      },
      "requirements": [
        "Python 사용 경험",
        "선수강의 [모두를 위한 대규모 언어 모델 LLM(Large Language Model) Part 1 - Llama 2 Fine-Tuning 해보기] 수강경험"
      ],
      "description": "랭체인(LangChain) 라이브러리의 개념과 활용 방법을 학습하고, 랭체인(LangChain) 라이브러리를 이용해서 나만의 ChatGPT를 만들어보는 강의입니다.\n\n이런 분들께 추천드려요!\n랭체인(LangChain) 라이브러리의 개념과 활용법을 학습하고 싶은 분\n나만의 ChatGPT를 만들어보고 싶은 분\n\n\n예상 질문 Q&A\nQ. 랭체인(LangChain)이 무엇인가요?\nA. 랭체인(LangChain) 라이브러리는 자연어 처리(NLP)와 관련된 다양한 기능을 제공하는 파이썬 라이브러리입니다. 이 라이브러리의 주요 목적은 대화형 AI 시스템을 구축하고 연구하는 데 있어 유용한 도구를 제공하는 것입니다. 여기에는 다음과 같은 특징들이 포함됩니다.\n1. 챗봇 구축: LangChain은 챗봇과 대화형 AI 시스템을 구축하기 위한 도구를 제공합니다. 이를 통해 사용자는 자신만의 챗봇을 쉽게 만들 수 있습니다.\n2. 다양한 NLP 기능: 이 라이브러리는 텍스트 생성, 요약, 번역과 같은 다양한 자연어 처리 기능을 포함하고 있습니다.\n3. 플러그 앤 플레이 아키텍처: 사용자는 LangChain을 사용하여 기존의 NLP 모델이나 시스템과 쉽게 통합할 수 있습니다. 이를 통해 다양한 언어 모델과 기능을 손쉽게 결합할 수 있습니다.\n4. 확장성 및 커스터마이징: LangChain은 사용자가 자신의 요구사항에 맞게 시스템을 커스터마이즈하고 확장할 수 있도록 설계되었습니다. 이는 연구자나 개발자들에게 매우 유용한 특징입니다.\n5. 연구 및 개발 지원: LangChain은 연구자와 개발자들이 새로운 대화형 AI 모델을 실험하고 개발하는 데 도움을 줍니다.\n이 라이브러리는 대화형 AI와 관련된 연구 및 개발에 관심이 있는 개발자, 연구자, 학생들에게 매우 유용한 도구입니다. LangChain을 통해 사용자는 복잡한 NLP 시스템을 보다 쉽게 구축하고 실험할 수 있습니다.\n\n\nQ. 선수지식이 필요한가요?\nA. 본 [모두를 위한 대규모 언어 모델 LLM(Large Language Model) Part 2 - 랭체인(LangChain)으로 나만의 ChatGPT 만들기] 강의는 랭체인(LangChain) 라이브러리와 LLM을 이용해서 나만의 ChatGPT를 만드는 방법을 다루고 있습니다. 따라서 Python, 자연어처리, LLM에 대한 기초지식을 가지고 있다는 가정하에 강의가 진행됩니다. 자연어처리와 LLM에 대한 기초 지식이 부족하다면 선행 강의인 [모두를 위한 대규모 언어 모델 LLM(Large Language Model) Part 1 - Llama 2 Fine-Tuning 해보기] 강의를 먼저 수강하시길 바랍니다.",
      "target_audience": [
        "랭체인(LangChain) 라이브러리의 개념과 활용법을 학습하고 싶은 분",
        "나만의 ChatGPT를 만들어보고 싶은 분",
        "딥러닝 연구 관련 직종으로 취업을 원하시는 분",
        "인공지능/딥러닝 관련 연구를 진행하고 싶은 분",
        "인공지능(AI) 대학원을 준비 중이신 분"
      ]
    },
    {
      "title": "دورة تحليل البيانات الكاملة من قواعد البيانات إلى الداشبورد",
      "url": "https://www.udemy.com/course/data_analysis_mobarki/",
      "bio": "رحلة تصميم داشبورد متكاملة من مرحلة اعداد البيانات في قواعد البيانات إلى مرحلة عرضها و اتمتتها و تحسين الاداء",
      "objectives": [
        "معرفة الرحلة كاملة لانشاء داشبورد من البدأ حتى النتيجة النهائية",
        "التعامل مع قواعد البيانات في إطار خاص بتحليل البيانات",
        "ربط البيانات من مصادر او جداول مختلفة",
        "تعلم كيفية رفع البيانات إلى اداة صناعة الداشبورد POWER BI",
        "تعلم متى نستخدم الرسم البياني المناسب",
        "تجارب عملية لصناعة داشبورد من مصادر بيانات مختلفة مثل اكسل مباشرة أو قواعد البيانات"
      ],
      "course_content": {
        "مقدمة عن سلسلة تحليل البيانات": [
          "فكرة دورة تحليل البيانات",
          "لماذا احتاج تعلم تحليل البيانات بواسطة انشاء داشبورد",
          "المخرج النهائي من سلسلة تحليل البيانات",
          "ماذا ساتعلم في هذه الدورة",
          "الأمثلة و التحديات"
        ],
        "مفاهيم أساسية في تحليل البيانات": [
          "ماهو الداشبورد",
          "دور الداشبورد في ذكاء الاعمال",
          "مفهوم Data Driven",
          "قواعد البيانات و لغة SQL",
          "أختبر فهمك لجزء المفاهيم الاساسية"
        ],
        "الإعداد لأول تقرير": [
          "خارطة الطريق",
          "إصدارات Power BI",
          "تنصيب Power BI",
          "تحدي تنصيب Power Bi"
        ],
        "مراحل تحميل, اكتشاف, رفع البيانات": [
          "تحميل بيانات التطبيق الأول",
          "استكشاف البيانات بواسطة Excel",
          "استكشاف تكرار البيانات بواسطة Excel",
          "لمحة حول استكشاف البيانات بواسطة kaggle",
          "رفع البيانات إلى Power BI",
          "ما المقصود باستكشاف البيانات",
          "تحدي جزء البيانات"
        ],
        "مرحلة التمهيد للجزء العملي لاول تقرير": [
          "أهم مكونات Power Bi",
          "هدف التقرير",
          "مراحل تصميم التقرير",
          "التعرف على الدوال"
        ],
        "إنتاج أول تقرير - تطبيقي": [
          "بطاقة عدد الطلاب - new measure",
          "مجموع الدرجات للطلاب - Average + New Column",
          "تصنيف الطلاب - IF - Grouping",
          "تصنيف الحضور - SWITCH - Grouping",
          "اعمار الطلاب - FORMAT",
          "اضافة نص بجانب رقم - Format - 2",
          "Card تنسيق",
          "Column Chart تنسيق",
          "Tree map & Pie Cart تنسيق",
          "استراتيجية تكرار العناصر",
          "تحليل الطلاب بشكل منفرد | Table",
          "إضافة صورة إلى التقرير",
          "إضافة نص - عنوان التقرير",
          "العلاقة و التأثير - Edit Interactions",
          "تنسيق عناصر التقرير",
          "تحليل التقرير - النتيجة النهائية",
          "ملخص أول تقرير - توصيات التحدي"
        ],
        "القصة الكاملة في الحياة العملية": [
          "النظرة الشاملة",
          "مراحل القصة الكاملة",
          "التوسع في مراحل القصة الكاملة",
          "المرحلة الأولى في الحياة العملية : السؤال",
          "المرحلة الثانية في الحياة العملية : مصادر البيانات",
          "المرحلة الثالثة و الرابعة : الاستخراج و التخزين",
          "المرحلة الخامسة: العرض",
          "المرحلة السادسة : الإجابة"
        ],
        "قواعد البيانات من وجهة نظر تحليل البيانات - نظري": [
          "مقدمة قواعد البيانات العلائقية",
          "الهدف من قواعد البيانات",
          "قاعدة البيانات العلائقية",
          "هيكل قاعدة البيانات",
          "ماهي Tables + Views",
          "من قاعدة البيانات إلى التقرير",
          "مثال لقاعدة البيانات العلائقية",
          "أبرز أجزاء الجدول"
        ],
        "تطبيق عملي لاول داشبورد من قواعد البيانات": [
          "تنزيل قاعدة البيانات",
          "تنصيب SQL Server",
          "تنصيب SMSS",
          "جولة في SSMS",
          "إستكشاف قاعدة البيانات - Tables",
          "إستكشاف قاعدة البيانات - Views",
          "VIEW إضافة عمود جديد داخل",
          "ربط التقرير بقاعدة البيانات",
          "خطة تنفيذ التقرير و المتطلبات",
          "معرفة عدد العملاء - DISTINCTCOUNT",
          "عدد الطلبات - Count",
          "Summarization",
          "إجمالي المبيعات - sum",
          "مبيعات المناطق - Tree Map",
          "Line Chart - المخطط الزمني للمبيعات",
          "slicer - الفلترة الشهرية السنوية",
          "مبيعات العملاء",
          "عدد طلبات العملاء",
          "التحليل الفردي للطلبات",
          "تنسيق التقرير",
          "مراجعة خطوات تطبيق التحدي"
        ],
        "الجزء العملي لقواعد البيانات": [
          "محطة جديدة في رحلة تحليل البيانات",
          "الهدف من هذا القسم",
          "مقدمة قواعد البيانات عملي",
          "مدخل Select, From, Where",
          "كيف تعمل الاستعلامات select, from,where",
          "استخدامات Select",
          "استخدامات FROM",
          "استخدامات where",
          "تحديد كل الاعمدة - Select All Columns",
          "تحدي select all",
          "حل تحدي select all",
          "استعراض كود الحل",
          "الاستعلام عن اعمدة محددة select column",
          "تحدي الاستعلام عن اعمدة محددة select column",
          "حل تحدي الاستعلام عن اعمدة محددة select column",
          "الكود",
          "select distinct القيم الفريدة",
          "تحدي القيم الفريدة select distinct",
          "حل تحدي تحديد القيم الفريدة select distinct",
          "الكود",
          "select TOP",
          "تحدي select TOP",
          "حل تحدي select TOP",
          "الكود",
          "تحدي alias الاسم المستعار",
          "حل تحدي alias الاسم المستعار",
          "الكود",
          "primary key and foreign key - المفاتيح",
          "مثال فائدة primary key and foreign key",
          "Join 2 Tables - ربط جدولين - Graphical Query Designer",
          "Join - code - alias",
          "Code & Graphical Query Designer",
          "LEFT JOIN & FULL JOIN",
          "شرح إضافي JOIN CODE",
          "Join ربط جدولين - Code",
          "تعديل الـ VIEW - DataSet",
          "DataSet Quiz",
          "Join 3 Table - Graphical Query Designer",
          "Join 3 Table - Code",
          "تحدي ربط اربع جداول و اضافة عمود مع اعادة التسمية",
          "حل تحدي اضافة الجدول الرابع",
          "تحدي Join",
          "حل تحدي join",
          "الكود",
          "فكرة LEFT JOIN",
          "فكرة FULL JOIN",
          "مدخل إلى Where",
          "where نفي قيمة معينة",
          "Where اكبر من و أصغر من",
          "Where اكثر من فلتر AND",
          "where تحقق اي من الشروط OR",
          "where - between",
          "where - in - اكثر من قيمة في نفس العمود",
          "Where - Like جزء من النص",
          "Where - Null القيم الفارغة",
          "where - not - نفي او عكس الاستعلام",
          "Order By الترتيب التصاعدي و التنازلي",
          "Group By",
          "الهدف من تعلم الاستعلامات"
        ]
      },
      "requirements": [
        "تتطلب الدورة وجود جهاز حاسب آلي",
        "لا تتطلب معرفة سابقة في قواعد البيانات لانها تغطي مايخص تحليل البيانات في قواعد البيانات",
        "لا تتطلب خبرة سابقة في ادوات تصوير البيانات لانها تغطي جزء استخدام ادوات تحليل البيانات"
      ],
      "description": "ابدأ رحلتك الاحترافية: من إنشاء أول داشبورد في يوم عملك الأول إلى إتقان 6 مراحل متكاملة تشمل إعداد بيئة العمل، تحديد متطلبات المشروع، جمع البيانات من قواعد البيانات، عرضها وأتمتتها باستخدام أدوات متقدمة، مع تحسين الأداء وتسليم المشاريع المتكاملة في بيئة الأعمال والحياة العملية.\nبدل دراستك لـ قواعد البيانات و برامج ذكاء الاعمال .. أبدأ بالتعلم التطبيقي و اكتسب المعرفة من التدريبات العملية\nفي هذا المساق التدريبي الشامل، سنأخذ بيدك خطوة بخطوة لبناء مسار مهني في مجال تحليل البيانات. يبدأ التدريب بتأسيس بيئة عمل احترافية، حيث تتعلم\nكيفية تحديد متطلبات المشروع بدقة وتحليلها لتلبية احتياجات العمل بفعالية.\nومن ثم، تنتقل إلى مرحلة جمع البيانات من مصادر متعددة، مما يضمن لك الحصول على معلومات دقيقة وشاملة للتحليل.\nعرض البيانات بشكل بصري مبسط يمكن أن يحول الأرقام إلى قصص ملهمة ورؤى استراتيجية. لذلك، سنركز على استخدام أدوات متقدمة تساعدك في تحويل البيانات الخام إلى تقارير ولوحات معلومات تفاعلية تسهم في اتخاذ قرارات مبنية على الأدلة. كما سنتناول كيفية أتمتة عمليات استخراج البيانات وتحسين الأداء لضمان تقديم مشاريع متكاملة في بيئة الأعمال المتطورة باستمرار.\nأدوات العمل الرئيسية التي سنستخدمها خلال الدورة تشمل:\n• Power BI: أداة تحليل وعرض البيانات التي تتيح لك إنشاء تقارير ولوحات معلومات تفاعلية تسهل عملية فهم وتحليل المعلومات.\n• SQL Server: نظام إدارة قواعد البيانات الذي يدعم تخزين واسترجاع البيانات باستخدام لغة SQL، مما يساعدك على التعامل مع كميات كبيرة من البيانات بكفاءة.\n• SSMS (SQL Server Management Studio): بيئة تطوير وإدارة لقواعد بيانات SQL Server، تُستخدم لتنفيذ الاستعلامات وإدارة الخوادم بكفاءة.\n• Excel: برنامج جداول بيانات شهير من مايكروسوفت يُستخدم لتحليل البيانات وإنشاء المخططات والتقارير التي تدعم اتخاذ قرارات استراتيجية.\nانضم إلينا لتطوير مهاراتك واكتساب المعرفة اللازمة لتحويل البيانات إلى استراتيجيات ناجحة، وبناء مستقبل مهني يرتكز على الإبداع والابتكار في بيئة الأعمال التنافسية.",
      "target_audience": [
        "أي شخص لديه بيانات و يرغب في استخراج المعرفة منها",
        "مناسبة للمهتمين بمجال تحليل البيانات",
        "مناسبة للموظفين الذين يعملون في مجال تحليل البيانات",
        "مناسبة للطلاب في مجال تحليل البيانات",
        "للموظفين الذي يحصلون على بيانات كثيرة و يرغبون في تحليلها"
      ]
    },
    {
      "title": "ゼロからはじめるR言語での可視化とPython言語での可視化",
      "url": "https://www.udemy.com/course/r-data-visualization/",
      "bio": "R言語とPython言語のデータ可視化の初歩",
      "objectives": [
        "データの集計・可視化ができるようになる。",
        "データ解析の概念がわかるようになる。",
        "探索的データ解析ができるようになる。",
        "Pythonでの集計・可視化ができるようになる"
      ],
      "course_content": {
        "Rプログラミング入門": [
          "Rのダウンロード・インストール",
          "R紹介とhead関数とhelp関数",
          "Rでの計算とデータ構造",
          "データ型と要約関数",
          "Rの比較演算子",
          "データフレームの扱い方",
          "ディレクトリ移動とデータの入出力",
          "Rパッケージ関連",
          "for文による繰り返し処理",
          "sample関数によるサンプリング"
        ],
        "Rによる可視化基礎": [
          "質的変数の可視化",
          "量的変数の可視化",
          "散布図行列",
          "stars関数による可視化",
          "parcoord関数による可視化",
          "rglパッケージによる三次元の可視化",
          "tabplotパッケージによる可視化"
        ],
        "Rによる高度な可視化": [
          "ggplot2パッケージによる一次元の量的変数の可視化",
          "ggplot2パッケージによる二次元の量的変数の可視化",
          "ggplot2パッケージによる一次元の質的変数の可視化",
          "ggplot2パッケージによる二次元の質的変数の可視化",
          "ggplot2パッケージによる質的変数と量的変数の可視化",
          "散布図行列の発展",
          "平行座標プロットの発展版",
          "階層構造があるデータの可視化"
        ],
        "データ変換技術": [
          "filter関数による行の抽出",
          "select関数による列の抽出",
          "mutate関数による列の作成",
          "group_by関数とsummarize関数",
          "パイプ演算子"
        ],
        "欠損値の対応(基礎)": [
          "欠損値の集計と可視化",
          "欠損値の対応1(リストワイズ法)"
        ],
        "探索的データ解析の実例": [
          "人事データの探索的データ解析"
        ],
        "多変量解析・機械学習": [
          "機械学習概説",
          "単回帰・重回帰入門(単回帰編)",
          "単回帰・重回帰入門(重回帰編)",
          "重回帰演習",
          "主成分分析(次元削減)",
          "クラスター解析",
          "判別分析",
          "決定木による回帰1(前半)",
          "決定木による回帰1(後半)",
          "決定木による回帰2",
          "Randomforestによる回帰",
          "xgbooostによる回帰",
          "決定木による分類",
          "Randomforestによる分類",
          "xgboostによる分類"
        ],
        "自然言語解析入門(日本語テキスト)": [
          "Twitterからのデータ取得",
          "日本語テキストの前処理と形態素解析とwordcloud",
          "TwitterAPIの使い方の発展とそのデータ解析",
          "日本語での用例索引",
          "日本語文書でのトピックモデル1",
          "日本語文書でのトピックモデル2"
        ],
        "機械学習と探索的データ解析、POSデータの解析": [
          "機械学習と探索的データ解析1",
          "機械学習と探索的データ解析2",
          "機械学習と探索的データ解析3",
          "機械学習と探索的データ解析4",
          "機械学習と探索的データ解析5",
          "機械学習と探索的データ解析6",
          "POSデータからの来店予測",
          "購買品目と顧客属性と過去の来店回数からの来店予測1",
          "購買品目と顧客属性と過去の来店回数からの来店予測2",
          "購買品目と顧客属性と過去の来店回数からの来店予測3"
        ],
        "欠損値対応(おまけ)": [
          "欠損値の対応2(ペアワイズ法・完全情報最尤推定法)",
          "欠損値の対応3(miceパッケージでの代入法)",
          "欠損値の対応4(miceパッケージでの代入法)"
        ]
      },
      "requirements": [
        "基本的なWindowsやMacの使い方(ドラックアンドドロップによるファイル移動など)"
      ],
      "description": "本講義は、R言語とPython言語での可視化について解説させていただきます。\nR言語とPython言語の割合は、7:3くらいです。\n\nデータ可視化の全体像を、コーディングせずに、動画だけ見てざっくりと、「どういうデータをどう可視化するか」、を知りたい人向けの講座です。\n\n2021年8月現在、だんだん、Rのパッケージが使えなくなったり、Rの環境構築が難しくなってきています。そしてそれの変化に対して、対応することが最近できておりません。Pythonはまだ動くものが多いと思います。\n\n今までは、Rをダウンロード・インストールして、コードを手で打ちながら学んでいただくことができていましたが、今では少し厳しいです。\n本講座は、Rでの可視化部分の動画を見ていただくくらいしか、価値がなくなってしまいました。\n\n一方で、データを集計・可視化して理解したいという初心者の方が、ExcelでもRでもPythonでも使える普遍的な知識を得るためにはまだ使えるかと思います。データを集計・可視化して理解したい方は、本講座のRかPythonの可視化の動画をご覧ください。その部分は未だに役に立つと思います。\n\nいろいろ動画をアップはしましたが、\n以下が2021年8月現在でもおすすめの動画です。\n特におすすめの動画には☆をつけてあります。\n\n～おすすめの可視化コンテンツ～\n\n【R言語編】\nーRによる可視化基礎ー(基本的な可視化方法です)\n☆質的変数の可視化\n☆量的変数の可視化\n☆散布図行列\n☆stars関数による可視化\n☆parcoord関数による可視化\nrglパッケージによる三次元の可視化\ntabplotパッケージによる可視化\n\nーRによる高度な可視化ー(よりきれいな可視化方法です)\n☆ggplot2パッケージによる一次元の量的変数の可視化\n☆ggplot2パッケージによる二次元の量的変数の可視化\n☆ggplot2パッケージによる一次元の質的変数の可視化\n☆ggplot2パッケージによる二次元の質的変数の可視化\n☆ggplot2パッケージによる質的変数と量的変数の可視化\n☆散布図行列の発展\n☆平行座標プロットの発展版\n階層構造があるデータの可視化\n\n～おすすめのデータ変形コンテンツ～\nーデータ変換技術ー(後々この章の内容は重要になってきます)\nfilter関数による行の抽出←今後R言語をやらないなら見なくてよいです\nselect関数による列の抽出←今後R言語をやらないなら見なくてよいです\nmutate関数による列の作成←今後R言語をやらないなら見なくてよいです\n☆group_by関数とsummarize関数\n\nー探索的データ解析ー(データに対する探索的な解析アプローチです)\n人事データの探索的データ解析\n\n～おすすめの機械学習コンテンツ(機械学習に興味ある人向け)～\n機械学習概説\n☆単回帰・重回帰入門(単回帰編)\n単回帰・重回帰入門(重回帰編)\n重回帰演習\n☆主成分分析(次元削減)\n☆クラスター解析\n判別分析\n決定木による回帰1(前半)\n決定木による回帰1(後半)\n決定木による回帰2\nRandomforestによる回帰\nxgboostによる回帰\n決定木による分類\nRandomforestによる分類\nxgboostによる分類\n\n機械学習と探索的データ解析1\n機械学習と探索的データ解析2\n機械学習と探索的データ解析3\n機械学習と探索的データ解析4\n機械学習と探索的データ解析5\n機械学習と探索的データ解析6\n\n～おすすめのPythonでの可視化コンテンツ～\n【Python言語編】\n\n☆データ集計と可視化1\n☆データ集計と可視化2\n\n～おすすめのデータ変形～\n☆グループごとの集計\n☆質的変数からダミー変数を作成する方法\n\nとりあえず、RやPythonでどんなことができるか、全体像をつかんでいただけたらと思います。\n\n本講座では、学生に対しては、無料で学習アカウントを提供しています(2018年1月より)\n希望の方は、machine.learning.r@gmail.com まで、大学のメールアドレスより件名を「Udemyアカウント希望」として、お名前・ご所属名を添えてご連絡ください。",
      "target_audience": [
        "データ可視化の概要を学んでみたい方"
      ]
    },
    {
      "title": "Programação em R Studio - R para iniciantes",
      "url": "https://www.udemy.com/course/programacao-em-r-para-iniciantes/",
      "bio": "Aprenda a Programar em R - aprenda a linguagem usada para Análise de Dados, Data Science, Machine Learning e Estatística",
      "objectives": [
        "Programar em Linguagem R",
        "Trabalhar com Vetores, Matrizes, Listas e Arrays",
        "Trabalhar com Data Frames no R",
        "Carregar Bibliotecas Externas",
        "Resolver problemas usando Programação R",
        "Criar os próprios Programas R",
        "Realizar Gráficos no R",
        "Cruzar Informação usando Merges e Joins",
        "Compreender boas práticas de Código R"
      ],
      "course_content": {
        "Introdução": [
          "Bem-vindos!",
          "Uma Nota para os Estudantes do Brasil"
        ],
        "Instalando o R e o R Studio": [
          "Instalar o R Base",
          "Instalar o R Studio",
          "Perguntas Básicas sobre o R"
        ],
        "Usando o R como Calculadora e Introdução": [
          "[Slides] - Introdução ao R",
          "[Slides] - Operações Matemáticas e Objectos",
          "Usando o R como Calculadora",
          "Quiz - Usando o R como Calculadora",
          "Vamos à Prática! - Exercícios R como Calculadora"
        ],
        "Vetores e o Ambiente R": [
          "[Slides] - Vetores",
          "[Slides] - Operações com Vetores",
          "[Slides] - Particularidades de Operações com Vetores",
          "Criando Vetores e Explorando o Ambiente",
          "Seleccionar Elementos e Indexar Vetores",
          "Operações com Vetores",
          "Objetos retornados por Funções e Argumentos Extra",
          "Casos Especiais em Operações (NA, NaN, Inf)",
          "Operadores de Comparação com Vetores",
          "Propriedade Names",
          "Modificar Elementos de Vetores",
          "Quiz - Vetores e Ambiente R",
          "Exercício de Código - Vetores",
          "Vamos à Prática! - Exercícios de Vetores e Ambiente"
        ],
        "Tipos de Dados no R": [
          "[Slides] - Tipos de Dados",
          "Tipos de Dados ao Nível da Classe e ao Nível do Sistema",
          "Funções de Teste de Tipo de Dados",
          "Conversões de Tipo de Dados",
          "Fatores",
          "Datas",
          "Quiz - Tipos de Dados R",
          "Exercício de Código - Tipos de Dados",
          "Vamos à Prática! - Exercícios de Tipos de Dados"
        ],
        "Arrays": [
          "[Slides] - Arrays e Matrizes",
          "Introdução a Arrays",
          "Indexar e Modificar Arrays",
          "Operações com Arrays",
          "Dimnames e outros Atributos de Arrays",
          "Combinar Arrays",
          "Quiz - Arrays",
          "Exercício de Código - Arrays",
          "Vamos à Prática! - Exercícios de Arrays"
        ],
        "Matrizes": [
          "Criação de Matrizes",
          "Operações de Matrizes",
          "Quiz - Matrizes",
          "Exercício de Código - Matrizes",
          "Vamos à Prática! - Exercícios de Matrizes"
        ],
        "Introdução a Data Frames": [
          "[Slides] - Data Frames e Listas",
          "Criar Data Frames",
          "Indexar e Modificar Data Frames",
          "Expandir Data Frames",
          "Removendo Elementos das Data Frames",
          "Quiz - Data Frames",
          "Exercício de Código - Data Frames"
        ],
        "Listas": [
          "Criar Listas",
          "Indexar e Modificar Listas",
          "Adicionar e Remover Elementos de Listas",
          "Combinar Listas",
          "Quiz - Listas R",
          "Exercício de Código - Listas",
          "Vamos à Prática! - Exercícios de Listas"
        ],
        "Secção Intervalo": [
          "Intervalo"
        ]
      },
      "requirements": [
        "Computador com pelo menos 4 GB de Ram"
      ],
      "description": "Está interessado em aprender uma linguagem de programação mas não sabe por onde começar? Ou é um analista de dados que quer acrescentar o R ao seu arsenal de conhecimento?\n\n\nMuitos analistas de dados são capazes de aumentar de forma exponencial a sua produtividade ao aprenderem a programar - além de aprenderem a automatizar processos, a capacidade de manipular dados com código permite a abertura de um mundo novo alem dos tradicionais limites do volume de dados. Com a explosão dos métodos de aprendizagem online e a necessidade de aprendizagem contínua por parte dos profissionais no mundo moderno, a capacidade de manipular linguagens de programação torna-se fulcral para profissionais que se querem destacar - principalmente num mundo em que os dados ganham cada vez mais relevância.\n\n\nEste curso foi totalmente desenhado para iniciantes e permite uma introdução detalhada à programação R. Vamos abordar todos os temas fulcrais do R como os seus objeitos, perceber a interface do R Studio e ainda analisar alguns datasets de fontes completamente diferentes. As aulas serão de tipologias diferentes para nos ajudar a consolidar os conceitos:\nAulas introdutórias com slides sobre os objectos R.\nAulas de programação conjunta em que os alunos seguirão o professor na implementação das diversas funções R.\nExercício de código com feedback imediato e exercícios de código realizados no próprio ambiente R do aluno.\nAnálise de data frames com problemas concretos.\n\n\nEste curso foi desenhado com o foco em dois conceitos: Conhecimento nos objetos base do R e exercício práticos que permitem a criação de bons hábitos de programação e de resolução de problemas.\n\n\nNo fim do curso, a expectativa é que os alunos sejam capazes de analisar os seus próprios datasets e realizar as tarefas mais comuns de um analista de dados no R como agregar, filtrar, ordenar ou combinar informação. Além disto, irão aprender todos os detalhes dos objectos base do R que permitem um conhecimento muito profundo da linguagem como vetores, matrizes ou arrays.\n\n\nAlguns exemplos concretos que os alunos deste curso conseguem fazer depois de terminarem as aulas:\nCarregar ficheiros CSV e Excel para o R;\nRealizar histogramas de dados numéricos.\nFiltrar Data Frames.\nCombinar Data Frames diferentes usando o conceito de merge.\n\n\nJunte-se a milhares de profissionais e estudantes nesta jornada de conhecimento e descubra o poder desta linguagem estatística grátis que permite um aumento de produtividade exponencial!\n\n\nEste curso será constantemente actualizado com base no feedback dos estudantes.\n\n\n[Atribuição Ícone da Capa de Curso: Start Up Graphic Design, Bricklay from the Noun Project]",
      "target_audience": [
        "Cientistas de Dados",
        "Analistas de Dados",
        "Iniciantes de Programação",
        "Curiosos acerca do R",
        "Programadores R Iniciantes"
      ]
    },
    {
      "title": "Introduction to Python for Machine Learning (In Indonesian)",
      "url": "https://www.udemy.com/course/introduction-to-python-for-machine-learning-in-indonesian/",
      "bio": "Pelajari cara menggunakan NumPy, Pandas, Seaborn, Matplotlib, Plotly, Machine Learning, dan banyak lagi!",
      "objectives": [
        "Pelajari bagaimana pembelajaran mesin benar-benar bekerja",
        "Belajar Menggunakan Python untuk Pembelajaran Mesin",
        "Memiliki pemahaman mendasar tentang bahasa pemrograman Python",
        "Belajarlah untuk membuat program Python sendiri",
        "Gunakan Python untuk Pembelajaran Mesin",
        "Menerapkan Dasar-Dasar Pembelajaran Mesin",
        "Belajar menggunakan NumPy untuk Data Angka",
        "Belajar menggunakan Pandas untuk Analisis Data",
        "Belajar menggunakan Matplotlib untuk Python Plotting",
        "Belajar menggunakan Seaborn untuk plot statistik",
        "Gunakan Plotly untuk visualisasi dinamis interaktif",
        "Dapatkan keterampilan Python prasyarat untuk pindah ke cabang tertentu - Pembelajaran Mesin, Pembelajaran Dalam, Ilmu Data, dll.",
        "Pahami baik Python 2 dan Python 3",
        "Buat nilai untuk keterampilan Anda"
      ],
      "course_content": {
        "Selamat datang di kursus": [
          "Introduction",
          "Pengantar Lembut untuk Python untuk Pembelajaran Mesin",
          "Mengapa Python adalah bahasa populer untuk Pembelajaran Mesin"
        ],
        "Bekerja dengan Notebook IPython": [
          "Halo Notebook IPython",
          "Halo IPython Notebook (Kode Langsung)",
          "Jelajahi Python Slide",
          "Jelajahi Python (Kode Langsung)",
          "String dan Fungsi 1",
          "String dan Fungsi 2",
          "String dan Fungsi 3",
          "Kode Kalkulator",
          "Pengantar OOP",
          "Operasi Matriks Lanjut dalam OOP",
          "Fungsi Matriks dalam OOP",
          "Working with strings"
        ],
        "NumPy": [
          "Manfaat Numpy",
          "Pemasangan Array",
          "Operasi Array",
          "Mengiris dan Mengindeks Array",
          "Operasi NumPy",
          "NumPy vs Python",
          "Fungsi Bawaan NumPy",
          "Advanced NumPy Part I",
          "Advanced NumPy Part II",
          "Mathematics to NumPy",
          "Numpy Functions"
        ],
        "Pandas": [
          "Why pandas",
          "Pandas DataFrame",
          "Pandas Series",
          "Importing Data",
          "Advanced Pandas",
          "Pandas"
        ],
        "Plotly": [
          "Intro to Plotly",
          "Univariate Plotting",
          "Bivariate Plotting",
          "Multivariate Plotting",
          "Plotly review"
        ],
        "Outro": [
          "Outro_Introduction to Python for Machine Learning"
        ]
      },
      "requirements": [
        "Komputer (Windows, Mac, atau Linux) dan hasrat untuk sukses!",
        "Sistem operasi 64-bit apa pun dengan setidaknya 4GB RAM untuk Kursus ini.",
        "Siswa harus menginstal Python 3 dan Jupyter Notebooks di sistem mereka.",
        "Harus memiliki pengetahuan pemrograman"
      ],
      "description": "Phyton bisa dibilang merupakan bahasa pemrograman utama dengan tingkat perkembangan yang pesat. Phyton bisa berkembang pesat dan cepat karena memiliki bahasa pemrograman yang cenderung 'ramah' dibanding lain nya. Dengan struktur sintaksis yang sederhana sehingga mudah dipelajari. Bahkan seseorang dengan pengetahuan pemrograman yang sangat mendasar pun dapat memahami Phyton dengan mudah. Fitur yang mudah dipahami serta perpustakaan pendukung menjadikan Phyton yang terbaik diantara pemrograman lain nya. Phyton memiliki banyak suplai siap pakai yang telah teruji dapat melakukan program berat. Poin tersebut merupakan poin plus dari bahasa pemrograman Phyton.\nKarena memiliki pusat informasi yang sangat besar, Phyton dapat mengerjakan koding lebih cepat. Ada pusat informasi dalam komputasi ilmiah, perhitungan numerik secara cepat, serta implementasi algoritma. Phyton dianggap lebih baik karena dapat mengerjakan proyek tadi dengan lebih cepat. Berbicara mengenai Machine Learning. Phyton banyak digunakan dalam komunitas Machine Learning dengan aplikasi pendukung seperti Tensorflow, PyTorch, Keras, Caffe dan lain nya.\nSaat ini banyak orang sedang belajar Phyton karena merupakan bahasa pemrograman yang paling populer. Jika anda sedang mencari kursus Phyton yang membahas dasar-dasar Phyton, anda berada di tempat yang tepat ! Video ini akan menunjukkan kepada anda peng-aplikasian Phyton. Phyton adalah bahasa pemrograman terbaik untuk dipelajari bagi para ekspert maupun pemula. Phyton tidak serumit apa yang anda bayangkan, merupakan bahasa pemrograman yang cukup mudah dipelajari, Phyton memiliki cara penggunaan yang 'alami' untuk sekelas bahasa pemrograman, membuatnya menjadi salah satu bahasa pemrograman yang mudah dipelajari dan di pahami.",
      "target_audience": [
        "Programmer yang ingin memulai dengan Python untuk Pembelajaran Mesin.",
        "Pemula dan Siapa pun tertarik dengan Pembelajaran Mesin.",
        "Pemrogram beralih bahasa ke Python.",
        "Pemrogram Python tingkat menengah yang ingin meningkatkan keterampilan mereka!",
        "Siswa yang memiliki setidaknya pengetahuan sekolah menengah dalam matematika dan yang ingin mulai belajar Machine Learning.",
        "Setiap siswa di perguruan tinggi yang ingin memulai karir di Machine Learning oleh Learning Python.",
        "Orang-orang yang tidak puas dengan pekerjaan mereka dan yang ingin belajar Python menjadi seorang Machine Learning Engineer."
      ]
    },
    {
      "title": "Geminiを詳しく学ぼう！ -Googleの最新マルチモーダル生成AIを使いこなす-",
      "url": "https://www.udemy.com/course/gemini-ai/",
      "bio": "Google社が提供する大規模言語モデル、Geminiについて学ぶ講座です。Geminiは画像や動画、音声などを扱えるマルチモーダルモデルで、様々な入力データを一度に扱うことができます。本講座では様々な機能、活用を順を追って学びます。",
      "objectives": [
        "Google社が提供するAI、Geminiの使い方を基礎から体験と共に学びます。",
        "Geminiが持つ様々な機能の使い方を学びます。",
        "Geminiの様々な応用を学びます。",
        "Geminiの全体像、そしてその可能性について学びます。",
        "GeminiとGoogle社の各サービスとの連携について学びます。"
      ],
      "course_content": {},
      "requirements": [
        "2024年3月の環境で解説しています。最新の環境と異なる可能性があります。",
        "人工知能、機械学習の技術的な知識は不要です。",
        "ローカル環境はWindowsでもMacでも大丈夫です。",
        "Googleのアカウント開設が必要です。",
        "有料の「Gemini Advanced」を使用するために、支払い方法の登録が必要です。2900円/月ですが、2ヶ月の無料期間があります。",
        "無料のGeminiでも受講可能ですが、性能が落ちます。"
      ],
      "description": "「Geminiを詳しく学ぼう！」は、Google社が提供するAIモデル「Gemini」（ジェミニ）の使い方を学ぶ講座です。\nGoogleの最新のAIを扱えるようになりたい方におすすめです。\n\n\nGeminiはマルチモーダルモデルなので、テキストだけでなく画像や動画、音声も扱うことができます。\n数学や物理学などの分野の複雑なタスクに対応可能なだけではなく、様々なプログラミング言語でコードの理解、生成が可能です。\n「Gemini Nano」「Gemini Pro」「Gemini Ultra」の3種類のモデルが用意されています。\n\n\n本講座では、最初にGeminiの概要を学んだ上で、様々な機能、活用を順を追って学んでいきます。\nまた、OpenAI社のGPT-4と比較した際の得手不得手も解説します。\nGeminiを使いこなし、様々なタスクを効率化できるようになりましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! 人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. Geminiの概要\n→ Geminiの概要と、基本的な使い方について学びます。\nSection2. Geminiの様々な機能\n→ 生成AIを活用した、Geminiの様々な機能について学びます。\nSection3. Geminiの活用\n→ 様々なGeminiの活用方法を解説します。",
      "target_audience": [
        "Geminiを基礎から体験ベースで学びたい方。",
        "Geminiを業務や趣味で活用したい方。",
        "AIのサポートにより文章作成、画像作成を効率化したい方。",
        "AI技術のトレンドに追随したい方。",
        "AIの新たな可能性を模索したい方。",
        "GmailなどのGoogle社のサービスと、AIを連携させたい方。"
      ]
    },
    {
      "title": "PySpark pour Data Engineer et Data Scientist avec 2 projets",
      "url": "https://www.udemy.com/course/pyspark-formation/",
      "bio": "Maîtriser PySpark avec 2 projets réels pour devenir Data Engineer, Data Scientist ou Data Analyst.",
      "objectives": [
        "Acquérir des compétences solides avec PySpark, sans prérequis nécessaires.",
        "Éviter les pièges de débutants et maîtriser les bonnes pratiques.",
        "Réussir ses examens, certifications et tests techniques sur PySpark.",
        "Obtenir un certificat de formation à la fin du cours.",
        "Avoir les connaissances nécessaires sur PySpark pour postuler à des offres d'emploi.",
        "Avoir une compréhension solide des notions clés en PySpark.",
        "Réaliser des projets personnels et professionnels avec PySpark.",
        "Réaliser des missions en freelance avec PySpark.",
        "Acquérir les compétences nécessaires pour travailler avec des entreprises qui utilisent PySpark.",
        "Maîtriser les concepts essentiels en PySpark pour devenir Data Engineer, Data Scientist ou Data Analyst."
      ],
      "course_content": {
        "Démarrer avec PySpark pour Data Engineer, Scientist et Analyst avec 2 projets": [
          "Présentation de la formation"
        ],
        "Démarrer avec la formation PySpark pour Data Engineer, Analyst et Scientist": [
          "Comment utiliser Google Colab ou Kaggle"
        ],
        "Projet Data Engineer / Analyst : Traitement de données de football avec PySpark": [
          "Présentation du projet",
          "Source des données",
          "Installer PySpark sur Google Colab",
          "Importer les données de football avec PySpark",
          "Stocker les données sur Google Drive pour les importer plus facilement",
          "Renommer et supprimer des colonnes de tableaux de données PySpark",
          "Ajouter de nouvelles colonnes dans un tableau de données PySpark",
          "Avant d'aller plus loin...",
          "Filtrer un tableau de données PySpark (Filter)",
          "Regrouper des données et calculer de nouvelles colonnes (Group By)",
          "Faire une jointure entre deux tableaux de données PySpark (Join)",
          "Créer de nouvelles colonnes synthétiques (withColumn)",
          "Faire des opérations sur des colonnes",
          "Utiliser les Window Functions de PySpark pour obtenir des rangs",
          "Créer un tableau final contenant les meilleures équipes de chaque saison",
          "Fin du projet + Télécharger le code PySpark",
          "Télécharger le code Python du projet"
        ],
        "Projet Data Scientist / Analyst : Faire du Machine Learning avec PySpark": [
          "Introduction au projet de Machine Learning et importation des données",
          "Traiter les valeurs manquantes dans les données avec PySpark",
          "Recoder les colonnes catégorielles",
          "Calculer des statistiques descriptives avec PySpark pour analyser les données",
          "Analyser la relation entre des colonnes en les croisant",
          "Transformer les colonnes catégorielles en colonnes binaires",
          "Créer le modèle de Machine Learning avec Spark MLlib",
          "Effectuer des prédictions avec un modèle entraîné",
          "Analyser les performances du modèle de Machine Learning avec Spark MLlib",
          "Fin du projet + Télécharger le code PySpark",
          "Télécharger le code Python du projet"
        ],
        "Conclusion et conseils": [
          "Fin du cours !",
          "Mes autres cours Udemy"
        ]
      },
      "requirements": [
        "Aucun prérequis n'est nécessaire pour suivre ce cours, nous verrons tout ensemble de A à Z."
      ],
      "description": "Maîtriser PySpark pour devenir Data Engineer, Data Scientist ou Data Analyst\nCe cours a pour objectif de vous former au framework PySpark sur Python très utilisée par les Data Engineer, Data Scientist et Data Analyst pour traiter des volumes importants de données.\nAcquérir des compétences fondamentales en PySpark\nPlus besoin de partir à la chasse aux informations sur Google, l'essentiel de votre apprentissage est concentré dans ce cours.\nApprendre rapidement pour une montée en compétence efficace\nCe cours est conçu pour vous familiariser avec PySpark de manière rapide et efficace. En seulement quelques heures et à travers deux projets, vous posséderez les connaissances nécessaires pour vous démarquer.\nCours récent et régulièrement mis à jour\nMise à jour récemment, cette formation est en phase avec les compétences actuellement recherchées en PySpark par les entreprises.\nÉviter les pièges de débutants\nLe cours met en lumière les meilleures pratiques d'un développeur PySpark expérimenté pour vous permettre de produire un code de qualité professionnelle.\nRéussir ses examens, tests techniques et certifications en PySpark\nLe contenu du cours est structuré de manière à vous préparer efficacement à vos examens universitaires, certifications et tests techniques liés à PySpark.\nPouvoir décrocher un poste en entreprise ou faire des missions freelance\nPySpark est parmi les frameworks les plus convoités en entreprise comme en freelance. Se former à cette librairie ouvre la porte à de nombreuses opportunités professionnelles.\nSe former à des métiers en forte demande\nAujourd'hui, la demande en Data Scientists, Data Engineers, Data Analysts et autres professions liées au Big Data est en hausse. C'est le moment propice pour se former à ces professions en apprenant à maîtriser PySpark.\nTravailler pour les plus grandes entreprises\nDes entreprises de renom telles qu'Uber, Netflix, Airbnb, Amazon, Meta (anciennement Facebook), Twitter, mais aussi des entreprises françaises telles que Renault, Air France-KLM, Orange, TotalEnergies, AXA, et Capgemini, sont actuellement à la recherches de professionnels compétents en PySpark.\nObtenir un certificat de fin de formation\nUn certificat attestant que vous avez suivi et complété le cours vous sera remis à la fin de la formation.",
      "target_audience": [
        "Personnes qui n'ont pas ou peu d'expérience en programmation et qui cherchent à apprendre PySpark.",
        "Personnes qui visent à travailler pour les plus grandes entreprises qui utilisent PySpark.",
        "Personnes qui souhaitent candidater pour des offres d'emploi ou des missions freelance qui nécessitent la maîtrise de PySpark."
      ]
    },
    {
      "title": "Deep Learning aplicado: Despliegue de modelos TensorFlow 2.0",
      "url": "https://www.udemy.com/course/deep-learning-despliegue-tensorflow-mirko-rodriguez/",
      "bio": "Despliega desde cero un modelo de Deep Learning de alta disponibilidad para Producción usando TensorFlow 2.0 - API REST",
      "objectives": [
        "Realizar el despliegue paso a paso de modelos de clasificación de imágenes usando TensorFlow 2.0.",
        "Realizar despliegues en ambientes de Desarrollo (DEV) usando Python + TensorFlow 2.0 y Flask en servidores Cloud (Google Cloud Platform - GCP).",
        "Realizar despliegues en ambientes de Producción (PROD) usando Python + TensorFlow 2.0 + TensorFlow Serving + Docker + Swarm y FastAPI.",
        "Realizar llamadas batcheras al modelo y monitorear servidores a través de Prometheus y Grafana.",
        "Entender las consideraciones de dominio técnico a tomar en cuenta para desplegar modelos Deep Learning para el procesamiento de imágenes."
      ],
      "course_content": {
        "El despliegue de modelos Deep Learning": [
          "¿Por qué desplegar modelos?",
          "Despliegue en Desarrollo vs Producción",
          "Construcción de Modelos: Flujo End-to-End",
          "El Framework TensorFlow 2.0"
        ],
        "El modelo Deep Learning a desplegar": [
          "Recursos de la sección",
          "Modelo Deep Learning a desplegar",
          "[Opcional] Construcción del modelo Deep Learning a desplegar",
          "[Opcional] *Actividad: Construir modelo Deep Learning a desplegar"
        ],
        "El Ambiente de despliegue": [
          "Recursos de la sección",
          "El Servidor de despliegue",
          "Configuración del Servidor de despliegue",
          "*Actividad: Crear Servidor de despliegue",
          "*Actividad: Configurar Servidor de despliegue"
        ],
        "----------------- DESPLIEGUE DEL MODELO -----------------": [
          "Tipos de despliegue",
          "Proceso de despliegue"
        ],
        "DESPLIEGUE EN DESARROLLO:": [
          "Recursos para el despliegue en Desarrollo"
        ],
        ".::. Python + TF2.0 + Flask": [
          "Plan de ataque",
          "Paso 1: Construcción del Modelo",
          "Paso 2: Implementación el Servicio Web (REST)",
          "*Actividad: Implementar el Servicio Web 1",
          "*Actividad: Implementar el Servicio Web 2",
          "Paso 3: Creación del Cliente Web",
          "*Actividad: Crear el Cliente Web (cURL)",
          "*Actividad: Crear el Cliente Web (Postman)",
          "*Actividad: Crear el Cliente Web (Angular - Ajax)"
        ],
        "DESPLIEGUE EN PRODUCCIÓN:": [
          "Recursos para el despliegue en Producción"
        ],
        "¿Qué es Docker?": [
          "¿Qué es Docker y por qué debemos usarlo?",
          "*Actividad: Instalar y configurar Docker"
        ],
        ".::. Docker + TensorFlow Serving + FastAPI": [
          "Plan de ataque",
          "Paso 1: Construcción del Modelo",
          "Paso 2: Implementación del Servicio Web (REST)",
          "*Actividad: Implementar el Servicio Web 1",
          "*Actividad: Implementar el Servicio Web 2",
          "*Actividad: Implementar el Servicio Web 3",
          "Paso 3: Creación del Cliente Web",
          "*Actividad: Crear el Cliente Web (cURL)",
          "*Actividad: Crear el Cliente Web (Postman)",
          "*Actividad: Crear el Cliente Web (Angular - Ajax)"
        ],
        ".::. Docker + Swarm + TensorFlow Serving + FastAPI": [
          "Plan de ataque",
          "Paso 1: Construcción del Modelo",
          "Paso 2: Implementación del Servicio Web (REST)",
          "*Actividad: Implementar el Servicio Web 1",
          "*Actividad: Implementar el Servicio Web 2",
          "Paso 3: Creación del Cliente Web",
          "*Actividad: Crear el Cliente Web (cURL)",
          "*Actividad: Crear el Cliente Web (Postman)",
          "*Actividad: Crear el Cliente Web (Angular - Ajax)"
        ]
      },
      "requirements": [
        "Poseer una cuenta de Google.",
        "Conocimientos básicos de Cloud Computing.",
        "Conocimientos básicos de programación en Python.",
        "Conocimientos básicos de construcción de modelos Deep Learning usando TensorFlow 2.0."
      ],
      "description": "Bienvenido a este curso 100% práctico y aplicado en el que podrás aprender de forma intuitiva, guiada y paso-a-paso el despliegue de modelos Deep Learning para ambientes de Desarrollo y principalmente para Producción en escenarios de alto desempeño usando la librería TensorFlow 2.0 y la creación de servicios REST.\n\n\nEstructura temática:\n¿Por qué desplegar modelos Deep Learning?\nDespliegue en Desarrollo vs Producción\nServidores de despliegue en la Nube: Google Cloud Platform (GCP) y CentOS\nDespliegue de modelos en la nube como Servicio Web REST desde cero (APIs)\nGestor de contenedores Docker para despliegues en Producción (Docker Swarm, TensorFlow Serving)\nImplementación de llamadas al Servicio Web desde cero\nConsideraciones técnicas para el despliegue de modelos Deep Learning\nDevOps y Machine Learning / MLOps | IAOps | XXOps\nInteroperabilidad de modelos: ONNX.\nDespliegue Customizado vs Plataformas\n\n\n100% práctico:\nEl curso prioriza el desarrollo de algoritmos en sesiones de laboratorio y actividades de programación 100% hands-on con los que podrás reproducir cada una de las líneas de código con explicaciones muy bien detalladas, sin descuidar los fundamentos teóricos de cada uno de los conceptos descritos.\n\n\nHerramientas:\nTodas las herramientas necesarias para el curso se podrán configurar directamente en la nube de Google; por tanto, no será necesario invertir tiempo en instalaciones de herramienta de forma local.\nEl curso se desarrolla con las herramientas más populares y de alta madurez del ecosistema de Python 3.0 como:\nTensorFlow 2.0\nTensorFlow Serving\nFlask\nFastAPI\nEl despliegue se realiza utilizando la nube de Google (Google Cloud Platform - GCP) en la que se configura paso a paso una máquina virtual (virtual machine) usando la distribución Linux CentOS como sistema operativo del servidor. Además, se utilizan para el despliegue los siguientes frameworks, librerías y herramientas:\nDocker\nDocker Swarm\nSwagger\nPromethous y grafana (Monitoreo)",
      "target_audience": [
        "Interesados en aprender a desplegar modelos de Deep Learning desde cero.",
        "Científicos de Datos e Ingenieros de Software que quieran entender el paso a paso del despliegue de modelos Deep Learning y cómo se relaciona con el proceso de construcción de modelos.",
        "Emprendedores que quieran generar disrupción usando algoritmos de Inteligencia Artificial en sus procesos."
      ]
    },
    {
      "title": "TIBCO Spotfire Cloud, do Básico ao Avançado",
      "url": "https://www.udemy.com/course/tibco-cloud-spotfire-do-basico-ao-avancado/",
      "bio": "Crie gráficos poderosos e Dashboards incríveis com a solução TIBCO Cloud Spotfire",
      "objectives": [
        "Ferramenta Spotfire, com aulas em Português do Brasil",
        "Aprenda a efetuar manipulações poderosas de seus dados, e extrair conhecimento de forma visual, com gráficos objetivos",
        "Dashboard",
        "TIBCO Cloud Spotfire"
      ],
      "course_content": {
        "Introdução": [
          "Introdução",
          "Recursos da plataforma",
          "Repositório do curso",
          "Acessando o repositório do curso"
        ],
        "Fundamentos do Spotfire": [
          "Aviso de mudança no portal para download do Spotifire",
          "Instalação do Spotfire",
          "Apresentação da interface do TIBCO Spotfire",
          "Importação de dados e criando seu primeiro Dashboard",
          "Acessando a Biblioteca do Spotfire Cloud",
          "Trabalhando com Banco de Dados Externo",
          "Dados estáticos em Painéis disponibilizados na Biblioteca Cloud"
        ],
        "Conhecendo as Visualizações (Gráficos) - Parte 1": [
          "Gráfico de barras - Conhecendo as opções básicas de uma visualização - Parte 1",
          "Gráfico de barras - Conhecendo as opções básicas de uma visualização - Parte 2",
          "Gráfico de Pizza",
          "Gráficos de Linhas",
          "Páginas e Grafico de Arvore",
          "Tabelas",
          "Tabela Cruzada(Tabela Dinâmica)",
          "Tabela Gráfica e Tabela Resumo",
          "Conclusão do capítulo"
        ],
        "Filtros e Marcações": [
          "Usando Filtros",
          "Usando Marcações",
          "Relacionando Tabelas diferentes para aplicação de filtros e marcações"
        ],
        "Trabalhando com Colunas Calculadas": [
          "Coluna calculada e introdução a expressões",
          "Função OVER(Agrupamento) e mais funções matemátcias",
          "Funções de manipulação de texto",
          "Funções de manipulação de Data",
          "Funções lógicas com IF e CASE",
          "Conclusão do capítulo"
        ],
        "Transformando dados usando a Tela de Dados": [
          "Entendendo melhor a Tela de Dados",
          "Tipos de Joins [ Atenção: aula extraída de outro curso, mas conteúdo essêncial]",
          "Joins no Spotfire(Adicionando Colunas)",
          "Adicionando Linhas no Spotfire(União de Tabelas)",
          "Unpivo(Transposição) de dados(Conversão de Colunas para linhas)"
        ],
        "Conhecendo as Visualizações (Gráficos) - Parte 2": [
          "Gráfico de Combinação e Gráfico de Dispersão",
          "Mapa gráfico",
          "Gráfico de Calor e Coordenadas paralelas",
          "Gráfico de KPI e Gráfico de Caixa"
        ],
        "Criando painéis interativos": [
          "Área de texto",
          "Refinando o Painel - Parte 1",
          "Refinando o Painel - Parte 2",
          "Refinando o Painel - Parte 3",
          "Refinando o Painel - Parte 4",
          "Conclusão do curso"
        ]
      },
      "requirements": [
        "Computador com Windows 7 ou superior",
        "Dedicação"
      ],
      "description": "Nesse curso você aprenderá a usar do software TIBCO Cloud Spotfire, uma ferramenta incrível para análise de dados e geração de informações estatísticas de forma visual, com paineis(dashboards) poderosos e objetivos, permitindo o acesso a informações fundamentais para tomadas de decisões.\nVocê aprenderá desde o básico, como carregar dados na ferramenta, tarefas de transformações estruturais e específicas, partindo depois para geração de informações estatísticas, e por fim a criação de visualizações(gráficos) dinâmicos, objetivos e ricos em informações, com possibilidade de disponibilização dos mesmos no ambiente Cloud da TIBCO. Durante todo esse processo, você utilizará bases de dados próximas a realidade, para simular um ambiente o mais próximo possível do seu trabalho.\nNenhum conhecimento técnico é requerido, a ferramenta trabalha de forma prática e simples, com isso você conseguirá utilizar todos os potenciais da ferramenta, para extrair o máximo que seus dados tem a oferecer, sem necessidade de aprender a codificar.\nA TIBCO é uma empresa com mais de 20 anos de mercado, criadora de diversas ferramentas para uso de computação em nuvem, entre elas o Spotfire, uma incrível ferramente para análise de dados.\nVenha nesse cursos aprender sobre a ferramenta TIBCO Cloud Spotfire, melhorar como profissional, e fazer para do mundo Big Data.\nA estrutura do curso segue uma curva de aprendizagem coerente, permitindo você ir se adaptando aos poucos na ferramenta, a medida de incrementamos os conhecimentos da plataforma e com isso vamos gerando painéis cada vez mais complexos.\n\n\nAtenção: O Curso não cobre integração com R, Python e JavaScript, pois são conhecimentos próprios, que requerem toda uma base anterior, o que deixaria bem confuso para alunos sem esses conhecimentos prévios.",
      "target_audience": [
        "Iniciantes em B.I. e Ciência de Dados"
      ]
    },
    {
      "title": "직장인맞춤 | ChatGPT 로 배우는 초단기 파이썬 코딩 | 실전 문제 13개 | 판다스, 크롤링 포함",
      "url": "https://www.udemy.com/course/code_with_chatgpt/",
      "bio": "더이상 코딩 배우지 마세요! 코딩 한번도 안해본 직장인들을 위한, 코드를 작성하지 않아도 되는 코딩강의 | 지루한 개념공부는 No, 실전문제 13개를 풀어가며 문제해결에 필요한 부분만 배운다!",
      "objectives": [
        "코드 작성 없이 코딩 하는법",
        "ChatGPT 활용하는 법",
        "파이썬 기본 개념",
        "판다스",
        "크롤링(스크레이핑)"
      ],
      "course_content": {
        "인트로": [
          "강의소개",
          "파이썬 설치",
          "쥬피터 노트북 소개",
          "ChatGPT 소개"
        ],
        "파이썬": [
          "(추가내용) ChatGPT의 한글능력 상승으로 이제 간단한 작업은 구글번역을 사용하지 않으셔도 됩니다!",
          "파이썬 실전문제 1",
          "파이썬 실전문제 2",
          "파이썬 연습문제"
        ],
        "판다스": [
          "판다스 소개",
          "판다스 실전문제 1",
          "판다스 실전문제 2",
          "판다스 실전문제 3",
          "판다스 실전문제 4",
          "판다스 실전문제 5",
          "판다스 연습문제",
          "오류 등 대처 방법"
        ],
        "크롤링": [
          "크롤링 소개",
          "크롤링 실전문제 1",
          "크롤링 실전문제 2",
          "크롤링 실전문제 3",
          "크롤링 연습문제"
        ],
        "마무리": [
          "마무리"
        ]
      },
      "requirements": [
        "경험이 필요하지 않습니다!"
      ],
      "description": "ChatGPT로 새롭게 바뀐 코딩 패러다임\n더이상 코딩 배우지 마세요! 코딩 한번도 안해본 직장인들을 위한, 코드를 작성하지 않아도 되는 코딩강의!\n코딩 노가다 없이 AI에게 잘 명령하는 법만 배우면 끝! 코딩의 새로운 패러다임!\n지루한 코딩 문법 이젠 외우지 않습니다!\n실전문제 13(3+6+4)개를 풀어가며 문제해결에 필요한 부분만 배운다!\n\n\n챗GPT가 등장함으로 인해서 사람이 할일이 엄청나게 줄어들었어요. 이제 저희같은 비전공자들이 할거는 AI에게 어떻게 명령하는지만 배우면 되고요, 이거를 위해서 아주아주 간단한 코딩 지식과 여기에 나와있는것처럼 문제파악하는법 그리고 논리 정리하는법만 준비하시면 됩니다. 이런 프로세스에 맞도록 기존의 코딩 강의들이 개념을 습득하고 연습문제를 풀어보는 방식이었다면 이 강의는 실전문제부터 먼저 보고 Chat gpt를 활용하여 정답을 얻은 후, AI가 짜준 코드를 보면서 이해가 필요한 개념들만 콕콕 찝어서 배울 수 있게 진행됩니다.",
      "target_audience": [
        "코드 작성 없이 코딩 배우고 싶으신 분들",
        "빠른 시간안에 문제 해결하고 싶으신 분들",
        "직장 업무에 필요한 실전문제로 코딩 배우고 싶으신 분들",
        "ChatGPT 활용법을 배우고 싶으신 분들"
      ]
    },
    {
      "title": "O Guia Completo sobre GANs: Redes Adversárias Generativas",
      "url": "https://www.udemy.com/course/guia-completo-gans-redes-adversarias-generativas/",
      "bio": "Deep Learning e Visão Computacional em projetos fascinantes com uma das tecnologias mais revolucionárias do mundo!",
      "objectives": [
        "Entenda a intuição básica sobre as GANs",
        "Gerar imagens de dígitos (0 - 9) utilizando DCGAN e WGAN",
        "Transformar imagens de satélites em mapas utilizando a arquitetura Pix2Pix",
        "Transformar zebras em cavalos utilizando a arquitetura CycleGAN",
        "Transferir estilos entre imagens",
        "Aplicar super resolução para melhorar a qualidade de imagens utilizando a arquitetura ESRGAN",
        "Criar novos rostos de pessoas com alta qualidade e definição utilizando ProGAN e StyleGAN",
        "Gerar imagens por meio de descrições textuais",
        "Restaurar fotos antigas utilizando GFP-GAN",
        "Completar partes faltantes de imagens utilizando a arquitetura Boundless",
        "Gerar deepfakes para trocar rostos com SimSwap"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Introdução à GANs",
          "Funcionamento básico",
          "Mais sobre Visão Computacional",
          "Recursos para download"
        ],
        "DCGAN e WGAN": [
          "DCGAN - intuição",
          "Base de dados MNIST",
          "Construção do gerador",
          "Construção do discriminador",
          "Cálculo do erro",
          "Função para treinamento",
          "Visualização dos resultados",
          "EXERCÍCIO e solução",
          "WGAN - intuição 1",
          "WGAN - intuição 2",
          "WGAN-GP - intuição",
          "Preparação do ambiente",
          "Wassertein loss",
          "Gradient penalty",
          "Treinamento",
          "Treinamento e visualização",
          "EXERCÍCIO e solução"
        ],
        "cGAN - Pix2Pix e CycleGAN": [
          "cGAN - intuição",
          "Pix2Pix - intuição",
          "Base de dados de mapas",
          "Pré-processamento das imagens 1",
          "Pré-processamento das imagens 2",
          "Carregamento dos dados",
          "Construção do gerador 1",
          "Construção do gerador 2",
          "Construção do gerador 3",
          "Construção do discriminador 1",
          "Construção do discriminador 2",
          "Geração das imagens dos mapas",
          "Treinamento 1",
          "Treinamento 2",
          "Visualização dos resultados",
          "Pix2Pix pré-treinada com PyTorch",
          "Base de dados de fachadas",
          "Visualização dos resultados",
          "Desenho para foto 1",
          "Desenho para foto 2",
          "Dia para noite",
          "EXERCÍCIO e solução",
          "CycleGAN - intuição",
          "Aviso sobre atualização da URL do dataset",
          "Bases de dados de maçãs e laranjas",
          "Pré-processamento",
          "Carregamento das imagens",
          "Gerador e discriminador",
          "Função de perda",
          "Otimizadores e checkpoint",
          "Função para o treinamento",
          "Treinamento e resultados",
          "CycleGAN pré-treinada com PyTorch",
          "Cavalo para zebra",
          "Transferência de estilo",
          "Estilos de Van Gogh, Cezanne e Ukiyo-e",
          "EXERCÍCIO e solução"
        ],
        "SRGAN e ESRGAN": [
          "SRGAN - intuição",
          "ESRGAN - intuição",
          "Modelo pré-treinado",
          "Imagens de teste",
          "Super resolução",
          "Avaliação do resultado - PSNR",
          "Melhorando os resultados",
          "EXERCÍCIO e solução"
        ],
        "ProGAN e StyleGAN": [
          "ProGAN - intuição",
          "Modelo pré-treinado",
          "Geração de faces de pessoas",
          "Transformação de rostos 1",
          "Transformação de rostos 2",
          "EXERCÍCIO e solução",
          "StyleGAN - intuição",
          "Importação das bibliotecas",
          "Modelo pré-treinado",
          "Geração das imagens",
          "Visualização dos resultados",
          "Transformação de rostos",
          "Geração de gatos e carros",
          "EXERCÍCIO e solução"
        ],
        "StackGAN - texto para imagem": [
          "StackGAN - intuição",
          "Modelo pré-treinado",
          "Encoder e legendas",
          "Visualização dos resultados",
          "Geração de imagens de pássaros",
          "EXERCÍCIO e solução"
        ],
        "Outras aplicações e tipos de GANs": [
          "BigGAN para várias categorias",
          "Modelo pré-treinado",
          "Carregamento das categorias",
          "Geração das imagens",
          "Interpolação entre imagens",
          "GFP-GAN para restauração de fotos antigas",
          "Modelo pré-treinado",
          "Restauração de fotos",
          "Boundless para extensão de imagens",
          "Processamento da imagem",
          "Visualização dos resultados",
          "SimSwap para deepfake",
          "Modelo pré-treinado",
          "Troca de rostos",
          "Adicional: GANs em vídeos"
        ],
        "Anexo 1: Redes neurais artificiais": [
          "Fundamentos biológicos",
          "Perceptron de uma camada",
          "Redes multicamada - função soma e função de ativação",
          "Redes multicamada - cálculo do erro",
          "Descida do gradiente",
          "Cálculo do parâmetro delta",
          "Ajuste dos pesos com backpropagation",
          "Bias, erro, descida do gradiente estocástica e mais parâmetros"
        ],
        "Anexo 2: Redes neurais convolucionais": [
          "Introdução à redes convolucionais 1",
          "Introdução à redes convolucionais 2",
          "Etapa 1 - operador de convolução (introdução)",
          "Etapa 1 - operador de convolução (cálculo)",
          "Etapa 2 - pooling",
          "Etapa 3 - flattening",
          "Etapa 4 - rede neural densa"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação",
        "Programação básica em Python",
        "Conhecimentos sobre redes neurais são desejáveis, porém não obrigatórios"
      ],
      "description": "As GANs (Generative Adversarial Networks - Redes Adversárias Generativas) são consideradas uma das tecnologias mais modernas e fascinantes dentro da área de Deep Learning e Visão Computacional. Elas tem ganhado bastante destaque na mídia por terem a característica de gerarem conteúdo falso (fake). Um dos exemplos mais clássicos é a criação de pessoas que não existem no mundo real para transmitirem telejornais e lerem as notícias, ou seja, a GAN consegue criar uma pessoa para falar com o telespectador. Essa tecnologia é considerada uma revolução na área de Inteligência Artificial por produzir resultados de alta qualidade, mantendo-se como um dos temas mais populares e relevantes.\nPara levar você até essa área, neste curso você terá uma visão teórica básica e principalmente prática sobre as principais e mais modernas arquiteturas de GANs! Este curso é considerado um guia completo pelo fato de apresentar desde conceitos mais básicos até técnicas mais modernas e avançadas, de modo que ao final você terá todas as ferramentas necessárias para construir seus próprios projetos! Veja abaixo alguns dos projetos que serão implementados passo a passo:\n\nGeração dos dígitos de 0 até 9\nTransformação de imagens de satélite em imagens no formato de mapas, no estilo do Google Maps\nTransformação de desenhos (ou somente rabiscos) em fotos de alta qualidade\nGerar zebras utilizando images de cavalos\nTransferir estilos entre imagens, utilizando pinturas de artistas famosos como Van Gogh, Cezanne e Ukiyo-e\nAumentar a resolução de imagens com baixa qualidade (super resolução)\nGerar deepfakes (faces falsas) com alta qualidade\nGerar imagens de gatos e carros que não existem no mundo real\nCriar imagens por meio de descrições textuais\nRestaurar fotos antigas\nCompletar partes faltantes de imagens\nTrocar o rosto de pessoas que estão em ambientes diferentes\nPara implementar esses projetos, você aprenderá várias arquiteturas diferentes de GANs, como por exemplo: DCGAN (Deep Convolutional Generative Adversarial Network), WGAN (Wassertein GAN), WGAN-GP (Wassertein GAN-Gradient Penalty), cGAN (conditional GAN), Pix2Pix (Image-to-Image), CycleGAN (Cycle-Consistent Adversarial Network), SRGAN (Super Resolution GAN), ESRGAN (Enhanced Super Resolution GAN), ProGAN (Progressively Growing GAN), StyleGAN (Style-Based Generator Architecture for GANs), StackGAN (Stacked GANs), AttnGAN (Fine-Grained Text to Image Generation with Attentional GANs), BigGAN, GFP-GAN (Generative Facial Prior GAN), GAN ilimitada (Boundless) e SimSwap (Simple Swap).\nDurante o curso, vamos utilizar a linguagem de programação Python e o Google Colab on-line, ou seja, você não precisa se preocupar com instalações e configurações de bibliotecas na sua própria máquina! São mais de 110 aulas e 16 horas de vídeos!",
      "target_audience": [
        "Pessoas interessadas em criar aplicações complexas utilizando GANs",
        "Alunos de graduação e pós-graduação que estão cursando disciplinas sobre Visão Computacional, Inteligência Artificial, Processamento Digital de Imagens ou Computação Gráfica",
        "Pessoas que querem implementar seus próprios projetos utilizando técnicas de Visão Computacional",
        "Cientistas de Dados que queiram aumentar o seu portfólio de projetos"
      ]
    },
    {
      "title": "Certification Science des données: De Débutant à Expert",
      "url": "https://www.udemy.com/course/certification-science-des-donnees/",
      "bio": "Acquérir une première expérience du Big Data, Python et l'analyse des données",
      "objectives": [
        "Comprendre le rôle stratégique de la gestion des données pour l’entreprise",
        "Identifier ce qu’est la donnée, et en quoi consiste le fait d’assurer la qualité de données",
        "Synthétiser le cycle de vie de la donnée",
        "Assurer l’alignement des usages métiers avec le cycle de vie de la donnée",
        "Découvrir les bonnes pratiques en matière de contrôle de qualité des données",
        "Familiarisez- vous avec les bibliothèques d'apprentissage automatique de Python, notamment scikit -learn, ...",
        "Assurer la mise en oeuvre de la gouvernance de la donnée",
        "Maitriser les bases de l’analyse business",
        "Choisir des indicateurs et comprendre les données associées",
        "Apprendre les bases du langage ainsi que des concepts avancés",
        "Sauvegarde des informations dans des bases de données",
        "Automatise des tâches répétitives",
        "Crée des fonctions pour automatiser des tâches",
        "Découvre la librairie standard de Python",
        "Maîtrise les différents opérateurs Python",
        "Teste des conditions avec les structures conditionnelles"
      ],
      "course_content": {
        "INTRODUCTION": [
          "Bienvenue !!",
          "Dr. Firas Partenaire formateur Udemy",
          "Présentation rapide : \"Qui suis-je ?\"",
          "Les méthodes et outils pédagogiques de la formation",
          "FAQ Udemy",
          "Bienvenue sur Udemy ! Présentez-vous !",
          "Introduction"
        ],
        "PART 1 - BIG DATA & DATA SCIENCE": [
          "Approche quantitative Vs Approche qualitative",
          "Définir les types d’objets mesurés",
          "Types d'études statistiques",
          "Connaissances, Compétences, Statistiques et Logiciels",
          "Les meilleurs logiciels de statistiques et analyse de données",
          "Le cycle de vie de la donnée",
          "Les données externes",
          "Le sens de la donnée",
          "Les nouvelles sources de données",
          "Big data,Smart data,Dark data,Fast data,Open data",
          "Qu’est-ce que la cartographie des données",
          "Pourquoi ce processus est-il capital ?",
          "Le sens de la donnée",
          "Deep Learning VS machine learning",
          "Big data-Smart data-Dark data-Fast data-Open data",
          "Big data vs Business Intelligence",
          "Données structurées et non structurées",
          "Stockage distribué",
          "Théorème de CAP",
          "Python et les données",
          "R ou PYTHON : Comment choisir ?",
          "L'écosystème de Python",
          "Schéma d’une API prédictive avec Python"
        ],
        "PART 2 - PYTHON": [
          "Introduction Python",
          "Installation Python 3.8.3",
          "Exécuter le programme Python",
          "Les fonctions",
          "Les opérations de base",
          "Les opérations spécifiques à Python",
          "Ordre et priorité",
          "Les types de nombre part-1",
          "Les types de nombre part-2",
          "Fonction INPUT",
          "Manipulation de chaine de caractère",
          "Manipulation de chaine de caractère part-2",
          "Changer les types avec les fonctions prédéfini avec Python",
          "Changer les types dans le input",
          "Les variables",
          "Changer les types des variables",
          "Les règles pour la création des variables",
          "Opérations sur place",
          "Type boolean",
          "Lancer l'éditeur de code Atom",
          "Les structures de contrôle",
          "Plusieurs conditions de contrôle",
          "Plusieurs conditions de contrôle Part-2",
          "Plusieurs conditions de contrôle Part-3",
          "Les conditions logiques",
          "Exercice avec les conditions",
          "Correction Exercice avec les conditions",
          "Structure de contrôle avec boucle While",
          "Structure de contrôle avec boucle While Part-2",
          "Structure de contrôle avec boucle While Part-3",
          "Création des listes",
          "Manipulation de la liste Part-1",
          "Manipulation de la liste Part-2",
          "Manipulation de la liste Part-3",
          "Manipulation de la liste Part-4",
          "Les recherches dans une liste",
          "Les fonctions dans les listes",
          "Application des méthodes sur les listes",
          "Exercice avec les listes",
          "EXERCICE : manipulation des listes",
          "Manipulation des listes avec les boucles",
          "La boucle FOR Part-1",
          "La boucle FOR Part-2",
          "La boucle FOR Part-3",
          "Création des dictionnaires",
          "Chercher la valeur d'une clé",
          "Mettre une liste dans un dictionnaire",
          "Ajouter un nouveau clé à un dictionnaire",
          "Recherche d'une clé",
          "Méthode Get",
          "Méthode KEYS",
          "Exercice avec la manipulation des dictionnaires",
          "Exercice avec les dictionnaires",
          "Définition d'une fonction",
          "Création d'une fonction",
          "Utilisation de RETURN dans une fonction",
          "Exercice: Fonction",
          "Exercice avec une fonction",
          "Les types d'erreurs dans Python"
        ],
        "PART 3 - Analyse de données avec Python": [
          "Télécharger anaconda",
          "Installer la distribution Anaconda",
          "Créer un environnement conda et installer pandas et Jupyter Notebook",
          "Créer un environnement conda et installer pandas et Jupyter Notebook partie-2",
          "Déballer le matériel de cours + Le processus de démarrage et d'arrêt",
          "Introduction à l'interface Jupyter Notebook",
          "Types de cellules et modes de cellules dans Jupyter Notebook",
          "Exécution de cellules de code dans Jupyter Notebook",
          "Raccourcis clavier populaires dans Jupyter Notebook",
          "Passer des objets pandas aux fonctions intégrées de python",
          "Importer des bibliothèques dans Jupyter Notebook",
          "Créez Jupyter Notebook pour le module de la série",
          "Créer un objet series à partir d'une liste python",
          "Créer un objet series à partir d'un dictionnaire",
          "Introduction aux attributs",
          "Introduction aux méthodes",
          "Paramètres et Arguments",
          "Importer des Séries avec la méthode read_csv",
          "Utilisez les méthodes head et tail pour renvoyer les lignes du début-fin",
          "Passer des objets pandas aux fonctions intégrées de python",
          "Accéder à plus d'attributs de séries",
          "Utilisez la méthode sort_values pour trier une série",
          "Utilisez le paramètre inplace pour muter définitivement une structure de données",
          "Utilisez la méthode sort_index pour trier l'index d'un objet pandas Series",
          "Utilisez le mot-clé IN de Python pour vérifier l'inclusion dans les valeurs",
          "Extraire les valeurs des séries par position d'index",
          "Extraire les valeurs de la série par étiquette d'index",
          "Utilisez la méthode get pour récupérer une valeur pour une étiquette d'index",
          "Méthodes mathématiques sur les objets de series",
          "Utilisez les méthodes idxmax et idxmin pour trouver l'indice",
          "Utilisez la méthode value_counts pour voir le nombre de valeurs uniques",
          "Utilisez la méthode apply pour appeler une fonction sur chaque valeur de série",
          "La méthode map",
          "Introduction au module DataFrames",
          "Méthodes et attributs partagés entre les séries et les DataFrames",
          "Différences entre les méthodes partagées"
        ],
        "PART 4 - DevOps : La plateforme Docker": [
          "Aperçu de Docker",
          "Démarrer avec Docker",
          "Démonstration - Configuration et installation de Docker",
          "Commandes de base de Docker",
          "Démonstration - Commandes Docker",
          "Docker Run",
          "Démo - Caractéristiques avancées de l'exécution de Docker Partie-1",
          "Démo - Caractéristiques avancées de l'exécution de Docker Partie-2",
          "Démo - Caractéristiques avancées de l'exécution de Docker Partie-3",
          "Images Docker",
          "Démo - Création d'une nouvelle image Docker Partie-1",
          "Démo - Création d'une nouvelle image Docker Partie-2",
          "Variables d'environnement",
          "Commande VS point d'entrée",
          "Docker Compose",
          "Intro - Application de vote",
          "Démo - Application de vote",
          "Registre Docker",
          "Moteur Docker",
          "Démo - Docker PID",
          "Stockage Docker",
          "Démo Stockage Docker partie-1",
          "Démo Stockage Docker partie-2",
          "Mise en réseau de Docker",
          "Docker sur Windows",
          "Démo - Docker sur Windows",
          "Orchestration de conteneurs",
          "Docker Swarm",
          "Introduction Kubernetes"
        ],
        "Obtenir le certificat": [
          "Obtenir le certificat"
        ],
        "BONUS": [
          "Bonus"
        ]
      },
      "requirements": [
        "Aucune connaissance technique particulière n’est nécessaire"
      ],
      "description": "Cette formation en Science des données: De Débutant à Expert est conçue pour les professionnels souhaitant acquérir une première expérience en matière de Big Data, de Python et d'analyse des données. Les participants pourront acquérir les compétences nécessaires pour devenir des experts en science des données, ainsi qu'une certification de réussite de la formation.\nIntroduction à la science des données\nComprendre les bases de la science des données et ses applications dans le monde professionnel\nApprendre les techniques de collecte de données et de préparation de données\nIntroduction à Python pour la science des données\nApprendre les bases de Python pour la science des données\nUtilisation de Python pour le nettoyage et la manipulation des données\nUtilisation de bibliothèques Python pour la visualisation des données\nAnalyse des données avec Python\nComprendre les techniques d'analyse des données et leur application à l'aide de Python\nUtilisation de bibliothèques Python pour l'analyse de données\nUtilisation de techniques d'apprentissage automatique pour l'analyse de données\nIntroduction au Big Data\nComprendre les concepts de base du Big Data\nIntroduction aux technologies de stockage et de traitement de données Big Data\nAnalyse de données Big Data avec Python\nApprendre à analyser des données Big Data à l'aide de Python\nUtilisation de bibliothèques Python pour l'analyse de données Big Data\nProjets pratiques\nMettre en pratique les compétences acquises grâce à des projets pratiques\nUtilisation de données réelles pour l'analyse de données\nExamen final\nÉvaluation des connaissances et des compétences acquises tout au long de la formation\nCertification de réussite de la formation pour les participants qui réussissent l'examen délivré par Udemy\nDans l'ensemble, cette formation en Science des données: De Débutant à Expert est conçue pour aider les professionnels à acquérir des compétences en matière de Big Data, de Python et d'analyse de données. Les participants pourront acquérir une expérience pratique grâce à des projets pratiques et seront évalués à travers un examen final pour obtenir leur certification de réussite de la formation.\nLa formation se déroulera sous forme de cours théorique & pratique, d'exemples concrets et d'ateliers pour permettre aux participants de mettre en pratique les concepts appris. Des exercices, des mises en situation et des études de cas seront utilisés pour renforcer les connaissances.\n\n\nRessources d’apprentissage complémentaires :\nAtelier en ligne\nDocumentation\nConsultez des exemples de tableaux de bord, de rapports et de fichiers de bureau.\nEnfin, je m'engage à vous fournir la formation la plus complète possible sur Udemy pour vous permettre de réussir dans votre apprentissage.\nJe m'engage à répondre rapidement à vos questions pour vous aider à comprendre les concepts de la formation.\nJe vais ajouter des cas pratiques sur demande pour vous donner des exemples concrets de ce que vous apprenez.\nJe vais vous accompagner avec des cas pratiques et d'autres ressources utiles pour vous aider à mettre en pratique ce que vous apprenez.\nCes ajouts de vidéos seront, bien entendu, gratuits si vous avez acquis la formation.\nComment me contacter ? Je reste disponible dans la rubrique Question/Réponses d'Udemy pour répondre à vos questions.\nÀ la fin de ce cours, si vous le suivez en entier et réussissez l'ensemble des quizz : Obtenez votre certification électronique à insérer dans votre CV et profil LinkedIn.\nIl ne me reste que plus qu'à vous souhaiter une bonne formation !\nDr. Firas",
      "target_audience": [
        "Ce cours a pour objectif de donner les outils nécessaires et essentiels à l'analyse de données recueillis dans le cadre des expériences."
      ]
    },
    {
      "title": "Pack Complet data Analyse avec Excel & Python",
      "url": "https://www.udemy.com/course/pack-complet-data-analyse-avec-excel-python-2022/",
      "bio": "Passez d'excel à python et améliorez votre productivité",
      "objectives": [
        "Automatiser Excel avec un code Python propre et puissant",
        "Utilisez Excel comme interface utilisateur graphique (GUI) et exécutez votre code Python avec Excel.",
        "Apprenez Excel de A à Z",
        "Apprendre les bases de python",
        "Apprendre les bases de python pandas"
      ],
      "course_content": {
        "Introduction": [
          "Bienvenue !!",
          "Dr. Firas Partenaire formateur Udemy",
          "Présentation rapide : \"Qui suis-je ?\"",
          "Les méthodes et outils pédagogiques de la formation",
          "FAQ Udemy",
          "Bienvenue sur Udemy ! Présentez-vous !",
          "Interface Excel et barre de titre",
          "Liste des principaux raccourcis clavier Excel"
        ],
        "MODULE - EXCEL": [
          "Interface Excel et barre de formule",
          "Interface Excel et feuille",
          "Interface Excel et manipulation des cellules - part 1",
          "Interface Excel et manipulation des cellules - part 2",
          "Insertion des données avec l'auto-compilation",
          "Changer la largeur et la hauteur de la cellule",
          "Utilisation des modèles prédéfinis sur Excel",
          "Les différents formats de ma cellule",
          "Comment formater ma cellule",
          "Copier la mise en forme et la coller dans un autre emplacement - Part 1",
          "Copier la mise en forme et la coller dans un autre emplacement - Part 2",
          "Créer un tableau à l'intérieur de EXCEL",
          "Utilisation des fonctions sur EXCEL",
          "Fonction de recherche, remplacement, insertion, suppression",
          "Le HELP d'EXCEL",
          "Manipulation des feuilles",
          "Les fonctions complémentaires",
          "Le formatage conditionnel",
          "Condition Si, Alors",
          "Comment protéger ma feuille et mon classeur Excel",
          "Filtre et trie",
          "Filtres avancés",
          "Validation des données",
          "Création des graphes",
          "Les modes d'affichages",
          "Masquer, Fractionner, Figer les colonnes et les lignes",
          "Mise en page pour impression",
          "Affichage personnalisés des données",
          "Impression",
          "Correction orthographe",
          "Exercice 1",
          "Correction Exercice 1",
          "Exercice 2",
          "Correction Exercice 2",
          "Exercice 3",
          "Correction Exercice 3",
          "Exercice 4",
          "Correction Exercice 4",
          "Introduction atelier",
          "Les données VS Les informations",
          "Créer mon tableau de données",
          "La variante et le pourcentage",
          "Lire avec les codes couleurs",
          "Tries et filtres",
          "Filtre par TOP 10",
          "Les tableaux croisés dynamique Part-1",
          "Les tableaux croisés dynamique Part-2",
          "Les tableaux croisés dynamique Part-3",
          "Les tableaux croisés dynamique Part-4",
          "Graphique Croisé Dynamique",
          "Graphique Croisé Dynamique- Part - 2",
          "Graphique Croisé Dynamique- Part - 3",
          "Graphique Croisé Dynamique- Part - 4"
        ],
        "MODULE - PYTHON": [
          "Introduction",
          "Support de cours",
          "Installation Python 3.8.3",
          "Exécuter le programme Python",
          "Les fonctions",
          "Les opérations de base",
          "Les opérations spécifiques à Python",
          "Ordre et priorité",
          "Les types de nombre part-1",
          "Les types de nombre part-2",
          "Fonction INPUT",
          "Manipulation de chaine de caractère",
          "Manipulation de chaine de caractère part-2",
          "Changer les types avec les fonctions prédéfini avec Python",
          "Changer les types dans le input",
          "Les variables",
          "Changer les types des variables",
          "Les règles pour la création des variables",
          "Opérations sur place",
          "Type boolean",
          "Lancer l'éditeur de code Atom",
          "Les structures de contrôle",
          "Plusieurs conditions de contrôle",
          "Plusieurs conditions de contrôle Part-2",
          "Plusieurs conditions de contrôle Part-3",
          "Les conditions logiques",
          "Structure de contrôle avec boucle While",
          "Structure de contrôle avec boucle While Part-2",
          "Structure de contrôle avec boucle While Part-3",
          "Création des listes",
          "Manipulation de la liste Part-1",
          "Manipulation de la liste Part-2",
          "Manipulation de la liste Part-3",
          "Manipulation de la liste Part-4",
          "Les recherches dans une liste",
          "Les fonctions dans les listes",
          "Application des méthodes sur les listes",
          "Manipulation des listes avec les boucles",
          "La boucle FOR Part-1",
          "La boucle FOR Part-2",
          "La boucle FOR Part-3",
          "Création des dictionnaires",
          "Chercher la valeur d'une clé",
          "Mettre une liste dans un dictionnaire",
          "Ajouter un nouveau clé à un dictionnaire",
          "Recherche d'une clé",
          "Méthode Get",
          "Méthode KEYS",
          "Définition d'une fonction",
          "Création d'une fonction",
          "Utilisation de RETURN dans une fonction",
          "Les types d'erreurs dans Python"
        ],
        "Excel avec Python Pandas": [
          "Télécharger anaconda",
          "Installer la distribution Anaconda",
          "Créer un environnement conda et installer pandas et Jupyter Notebook",
          "Créer un environnement conda et installer pandas et Jupyter Notebook partie-2",
          "Déballer le matériel de cours + Le processus de démarrage et d'arrêt",
          "Introduction à l'interface Jupyter Notebook",
          "Types de cellules et modes de cellules dans Jupyter Notebook",
          "Exécution de cellules de code dans Jupyter Notebook",
          "Raccourcis clavier populaires dans Jupyter Notebook",
          "Importer des bibliothèques dans Jupyter Notebook",
          "Créez Jupyter Notebook pour le module de la série",
          "Créer un objet series à partir d'une liste python",
          "Créer un objet series à partir d'un dictionnaire",
          "Introduction aux attributs",
          "Introduction aux méthodes",
          "Paramètres et Arguments",
          "Importer des Séries avec la méthode read_csv",
          "Utilisez les méthodes head et tail pour renvoyer les lignes du début-fin",
          "Passer des objets pandas aux fonctions intégrées de python",
          "Accéder à plus d'attributs de séries",
          "Utilisez la méthode sort_values pour trier une série",
          "Utilisez le paramètre inplace pour muter définitivement une structure de données",
          "Utilisez la méthode sort_index pour trier l'index d'un objet pandas Series",
          "Utilisez le mot-clé IN de Python pour vérifier l'inclusion dans les valeurs",
          "Extraire les valeurs des séries par position d'index",
          "Extraire les valeurs de la série par étiquette d'index",
          "Utilisez la méthode get pour récupérer une valeur pour une étiquette d'index",
          "Méthodes mathématiques sur les objets de series",
          "Utilisez les méthodes idxmax et idxmin pour trouver l'indice",
          "Utilisez la méthode value_counts pour voir le nombre de valeurs uniques",
          "Utilisez la méthode apply pour appeler une fonction sur chaque valeur de série",
          "La méthode map"
        ],
        "Obtenir le certificat": [
          "Obtenir le certificat"
        ],
        "BONUS": [
          "Bonus"
        ]
      },
      "requirements": [
        "Aucune expérience en programmation requise. Vous apprendrez tout ce que vous devez savoir"
      ],
      "description": "La formation Pack Complet data Analyse avec Excel & Python est un pack complet pour apprendre à maîtriser l'analyse de données avec Excel et Python. En suivant cette formation en ligne, vous découvrirez les secrets pour analyser des données complexes, extraire des informations précieuses et prendre des décisions éclairées.\nModule 1 : Introduction à l'analyse de données\nIntroduction à l'analyse de données\nLes différents types d'analyse de données\nLes outils pour l'analyse de données\nModule 2 : Analyse de données avec Excel\nLes bases de l'utilisation d'Excel pour l'analyse de données\nLes fonctions Excel pour l'analyse de données\nLa création de graphiques et de tableaux croisés dynamiques avec Excel\nModule 3 : Analyse de données avec Python\nIntroduction à Python pour l'analyse de données\nLes bibliothèques Python pour l'analyse de données (NumPy, Pandas, Matplotlib)\nLa manipulation de données avec Python\nModule 4 : Analyse de données avancée avec Excel et Python\nL'analyse statistique avec Excel et Python\nLa création de modèles de prédiction avec Excel et Python\nLa visualisation de données avancée avec Excel et Python\nModule 5 : Cas pratiques d'analyse de données\nÉtudes de cas pratiques pour l'analyse de données avec Excel et Python\nComment analyser et interpréter les résultats de l'analyse de données\nÀ la fin de la formation, vous serez capable de maîtriser l'analyse de données avec Excel et Python. Vous serez en mesure d'utiliser les fonctions et les outils avancés d'Excel et de Python pour manipuler et analyser des données complexes, créer des graphiques et des tableaux croisés dynamiques, et créer des modèles de prédiction pour prendre des décisions éclairées. Vous serez également en mesure d'analyser et d'interpréter les résultats de l'analyse de données pour identifier des tendances et des opportunités.\n\n\nLe cours couvre les sujets suivants :\nCréation d'un environnement python\nImportation d'Excel dans Python\nAgrégation de données à partir de plusieurs fichiers\nFractionnement des données en plusieurs fichiers\nInteragir avec votre OS de manière programmatique\nAutomatisation des fonctions Excel les plus populaires telles que vlookup, sumif, countif, etc.\nReproduire des visualisations Excel\nAutomatiser les tableaux croisés dynamiques\n\n\nNotez bien :\nLa formation se déroulera sous forme de cours théorique & pratique, d'exemples concrets et d'ateliers pour permettre aux participants de mettre en pratique les concepts appris. Des exercices, des mises en situation et des études de cas seront utilisés pour renforcer les connaissances.\n\n\nRessources d’apprentissage complémentaires :\nAtelier en ligne\nDocumentation\nConsultez des exemples de tableaux de bord, de rapports et de fichiers de bureau.\nEnfin, je m'engage à vous fournir la formation la plus complète possible sur Udemy pour vous permettre de réussir dans votre apprentissage.\nJe m'engage à répondre rapidement à vos questions pour vous aider à comprendre les concepts de la formation.\nJe vais ajouter des cas pratiques sur demande pour vous donner des exemples concrets de ce que vous apprenez.\nJe vais vous accompagner avec des cas pratiques et d'autres ressources utiles pour vous aider à mettre en pratique ce que vous apprenez.\nCes ajouts de vidéos seront, bien entendu, gratuits si vous avez acquis la formation.\nComment me contacter ? Je reste disponible dans la rubrique Question/Réponses d'Udemy pour répondre à vos questions.\nÀ la fin de ce cours, si vous le suivez en entier et réussissez l'ensemble des quizz : Obtenez votre certification électronique à insérer dans votre CV et profil LinkedIn.\n\nDr. Firas",
      "target_audience": [
        "Les gros utilisateurs d'Excel curieux d'automatiser leur travail à l'aide de Python.",
        "Les personnes qui sont fatiguées de travailler avec des macros boguées et des feuilles de calcul volumineuses."
      ]
    },
    {
      "title": "Álgebra Linear para Data Science e Machine Learning",
      "url": "https://www.udemy.com/course/algebra-linear-para-data-science-e-machine-learning/",
      "bio": "Entenda os conceitos de Álgebra Linear e aplique-os em Inteligência Artificial e Ciência de Dados",
      "objectives": [
        "Compreender a importância da Álgebra Linear para Ciência de Dados e Machine Learning",
        "Explorar conceitos fundamentais como escalares, vetores, matrizes e tensores",
        "Representar dados e resolver sistemas lineares com métodos algébricos",
        "Identificar propriedades e realizar operações essenciais com vetores e matrizes",
        "Entender transformações lineares, como escalonamento, rotação e cisalhamento",
        "Calcular autovetores, autovalores e utilizar decomposições de matrizes (Eigendecomposition e SVD)",
        "Implementar a Análise de Componentes Principais (PCA) para redução de dimensionalidade",
        "Codificar operações de Álgebra Linear em Python com bibliotecas especializadas",
        "Utilizar Álgebra Linear em aplicações reais de Machine Learning",
        "Praticar com exercícios teóricos e desafios aplicados para consolidar o aprendizado"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre DS e ML",
          "Recursos para download"
        ],
        "Conceitos iniciais": [
          "Definição",
          "Equação linear",
          "Escalares, vetores, matrizes e tensores",
          "Instalação das bibliotecas",
          "Escalares e vetores - implementação",
          "Matrizes e tensores - implementação",
          "Sistemas lineares",
          "Sistemas lineares - implementação",
          "Representação de dados 1",
          "Representação de dados 2",
          "Representação de dados - implementação 1",
          "Representação de dados - implementação 2",
          "Questões"
        ],
        "Vetores": [
          "Propriedades 1",
          "Propriedades 2",
          "Plotagem",
          "Normas",
          "Regularização",
          "Vetor unitário e vetor base",
          "Vetor transposto",
          "Vetor ortogonal e ortonormal",
          "Questões"
        ],
        "Matrizes": [
          "Propriedades 1",
          "Propriedades 2",
          "Normas",
          "Matriz transposta e simétrica",
          "Matriz diagonal e identidade",
          "Matriz inversa",
          "Determinante",
          "Matriz ortogonal",
          "Questões"
        ],
        "Operações": [
          "Operações 1",
          "Operações 2",
          "Operações com escalares",
          "Operações de redução",
          "Elemento a elemento",
          "Multiplicação matricial",
          "Produto vetorial/escalar/interno",
          "Regra do cosseno",
          "Questões"
        ],
        "Transformações": [
          "Transformações 1",
          "Transformações 2",
          "Transformações 3",
          "Matrizes de espelhamento e escalonamento",
          "Matrizes de cisalhamento e rotação",
          "Determinantes",
          "Matrizes inversas e sistemas lineares",
          "Eigenvectors e eigenvalues 1",
          "Eigenvectors e eigenvalues 2",
          "Eigendecomposition",
          "Singular value decomposition (SVD)",
          "Matriz pseudoinversa de Moore-Penrose",
          "Principal component analysis (PCA)",
          "Questões"
        ],
        "Aplicações": [
          "Sistema linear - intuição",
          "Sistema linear - implementação",
          "Rede neural - intuição",
          "Rede neural - implementação",
          "Eigendecomposition - intuição",
          "Eigendecomposition - implementação",
          "Singular value decomposition – intuição",
          "Singular value decomposition – implementação",
          "PCA - intuição",
          "PCA - implementação",
          "Semelhança entre dados – intuição",
          "Semelhança entre dados – implementação",
          "EXERCÍCIOS",
          "Solução 1",
          "Solução 2"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Conhecimento básico em Python (estruturas de dados, funções e manipulação de arrays)",
        "Noções básicas de matemática (operações fundamentais e manipulação de equações)",
        "Nenhuma experiência avançada em Álgebra Linear é necessária"
      ],
      "description": "A Álgebra Linear é um dos fundamentos essenciais para quem deseja atuar com Ciência de Dados e Inteligência Artificial. Seja na manipulação de grandes conjuntos de dados, na construção de modelos preditivos ou na implementação de algoritmos de Machine Learning, a compreensão dessa área matemática é indispensável. Este curso foi estruturado para oferecer uma abordagem intuitiva e prática dos conceitos mais importantes, combinando teoria e implementações em Python para garantir que você aprenda aplicando.\nO curso é dividido em seis seções, cada uma abordando um aspecto fundamental da Álgebra Linear. Começamos com uma introdução aos conceitos básicos, onde explicamos a importância dessa disciplina e como ela se conecta com Data Science e Machine Learning. Aqui, são apresentados elementos como escalares, vetores, matrizes e tensores, além da instalação das bibliotecas necessárias para a programação em Python. Também exploramos a representação de dados e como os sistemas lineares são utilizados para resolver problemas matemáticos.\nNa segunda seção, aprofundamos o estudo dos vetores, suas propriedades e aplicações. Vetores são componentes fundamentais na manipulação de dados, na normalização de variáveis e até mesmo na definição de espaços multidimensionais usados em modelos preditivos. Você aprenderá sobre normas, vetores unitários, vetores ortogonais e ortonormais, além de visualizar essas estruturas de maneira intuitiva através de gráficos.\nEm seguida, exploramos as matrizes, que são amplamente utilizadas na representação de dados e no processamento de grandes volumes de informações. Conheceremos as principais propriedades das matrizes, suas normas, transposição, inversão e decomposições fundamentais para diversas aplicações. Esses conceitos são indispensáveis para o funcionamento de redes neurais, regressões lineares e técnicas de redução de dimensionalidade.\nA quarta seção é dedicada às operações envolvendo vetores e matrizes. Aprenderemos sobre multiplicação matricial, produtos vetoriais e escalares, operações de redução e a regra do cosseno, conceitos essenciais para o cálculo de semelhança entre dados e manipulação eficiente de estruturas matemáticas.\nEm seguida, abordamos as transformações lineares, um conceito-chave para muitas aplicações avançadas de Machine Learning. Estudaremos como matrizes podem ser usadas para operações como espelhamento, escalonamento, rotação e cisalhamento, além de introduzirmos conceitos essenciais como autovetores, autovalores e decomposições de matrizes. Técnicas como Eigendecomposition, Singular Value Decomposition (SVD) e Principal Component Analysis (PCA) são exploradas aqui, sendo ferramentas indispensáveis para a compressão de dados e a remoção de redundâncias em modelos de aprendizado.\nPor fim, a sexta seção é inteiramente focada em aplicações práticas de Álgebra Linear no contexto de Ciência de Dados e Inteligência Artificial. Vamos implementar sistemas lineares, explorar como redes neurais utilizam esses conceitos matemáticos, aprofundar a Eigendecomposition e a SVD, além de aplicar a PCA para análise e redução de dimensionalidade. Também trabalharemos com técnicas para medir semelhança entre dados estruturados, garantindo que você saiba utilizar esses conhecimentos para resolver problemas reais. A seção finaliza com exercícios para consolidar seu aprendizado.\nAo concluir este curso, você terá um domínio sólido da Álgebra Linear aplicada à Ciência de Dados e Machine Learning, sabendo não apenas a teoria, mas também como implementá-la em Python. Se você busca desenvolver uma base matemática forte para trabalhar com IA e dados de maneira profissional, este curso é um passo essencial na sua jornada.",
      "target_audience": [
        "Profissionais e estudantes de Ciência de Dados, Machine Learning e Inteligência Artificial que desejam aprofundar seus conhecimentos matemáticos",
        "Desenvolvedores e programadores que querem entender e aplicar Álgebra Linear em Python",
        "Pesquisadores e acadêmicos interessados na base matemática por trás de redes neurais e algoritmos de IA",
        "Engenheiros e analistas de dados que precisam manipular, transformar e reduzir dimensionalidade em conjuntos de dados",
        "Qualquer pessoa que deseja compreender os fundamentos matemáticos da IA e aplicá-los de forma prática"
      ]
    },
    {
      "title": "Deep Learning w języku Python - Konwolucyjne Sieci Neuronowe",
      "url": "https://www.udemy.com/course/deep-learning-w-jezyku-python/",
      "bio": "Praktyczne wprowadzenie do Konwolucyjnych Sieci Neuronowych (CNN): Budowanie i trenowanie modeli głębokiego uczenia!",
      "objectives": [
        "zrozumienie intuicji stojącej za sztucznymi sieciami neuronowymi",
        "zrozumienie intuicji stojącej za konwolucyjnymi sieciami neuronowymi",
        "elementy składowe sztucznych sieci neuronowych (ANN)",
        "elementy składowe konwolucyjnych sieci neuronowych (CNN)",
        "implementacja sieci neuronowej od zera (python)",
        "budowa sztucznych sieci neuronowych w Keras i TensorFlow",
        "klasyfikacja obrazów przy pomocy sieci ANN i CNN",
        "dogłębna analiza działania sieci CNN",
        "case study I: klasyfikacja obrazów - pies czy kot?",
        "case study II: klasyfikacja obrazów - dron, samolot pasażerski czy helikopter?"
      ],
      "course_content": {},
      "requirements": [
        "Ukończone kursy ze ścieżki Python Developer na tym koncie instruktorskim",
        "Ukończone kursy ze ścieżki Data Scientist na tym koncie instruktorskim",
        "Znajomość języka Python",
        "Podstawy uczenia maszynowego",
        "Wprowadzenie do sieci neuronowych"
      ],
      "description": "Chcesz poznać tajniki konwolucyjnych sieci neuronowych i zbudować własne modele deep learning? Ten kurs to praktyczny przewodnik po jednej z najważniejszych technologii we współczesnej sztucznej inteligencji – CNN, czyli konwolucyjnych sieciach neuronowych. Dzięki nim możliwe są przełomowe osiągnięcia w dziedzinie rozpoznawania obrazów, analizy wideo, medycyny, autonomicznych pojazdów i wielu innych obszarów.\nW trakcie kursu krok po kroku nauczysz się, jak:\nDziała architektura CNN i czym różni się od klasycznych sieci neuronowych\nBudować modele konwolucyjne w Pythonie z użyciem bibliotek takich jak TensorFlow i Keras\nWykorzystać warstwy konwolucyjne, poolingowe i gęste do tworzenia zaawansowanych modeli\nTrenować sieci na rzeczywistych zbiorach danych (np. MNIST, CIFAR-10)\nZastosować techniki poprawiające skuteczność modeli, jak augmentacja danych, dropout czy batch normalization\nDiagnozować i poprawiać błędy modeli oraz unikać overfittingu\nKurs zawiera liczne ćwiczenia praktyczne, projekty i wyjaśnienia krok po kroku – idealny dla osób, które chcą zdobyć solidne fundamenty w deep learningu oraz rozpocząć przygodę z analizą danych wizualnych.\nNie musisz być ekspertem! Wystarczy podstawowa znajomość Pythona i chęć nauki, by zanurzyć się w świat inteligentnych algorytmów i samodzielnie zbudować pierwszą konwolucyjną sieć neuronową. Dołącz do kursu i zdobądź umiejętności, które otwierają drzwi do kariery w AI!\n\n\nTensorFlow – Moc obliczeń dla sztucznej inteligencji\nTensorFlow to otwartoźródłowa biblioteka do uczenia maszynowego i głębokiego uczenia, stworzona przez Google. Umożliwia łatwe budowanie, trenowanie i wdrażanie modeli AI na różnych platformach – od serwerów po urządzenia mobilne. Dzięki elastycznej architekturze i wsparciu dla GPU i TPU, TensorFlow jest popularnym wyborem wśród badaczy, inżynierów i firm rozwijających nowoczesne rozwiązania oparte na danych.\n\n\nKeras – Prostota tworzenia potężnych sieci neuronowych\nKeras to wysokopoziomowa biblioteka do budowy i trenowania modeli głębokiego uczenia, działająca jako interfejs dla TensorFlow. Zaprojektowana z myślą o prostocie i czytelności kodu, pozwala szybko prototypować zaawansowane sieci neuronowe przy minimalnym wysiłku programistycznym. Keras wspiera zarówno badania naukowe, jak i zastosowania produkcyjne, oferując intuicyjne API i bogaty zestaw narzędzi do analizy i wizualizacji modeli.",
      "target_audience": [
        "Osoby wchodzące w świat Data Science, AI/ML",
        "Entuzjaści sztucznej inteligencji (AI)",
        "Inżynierowie uczenia maszynowego",
        "Analitycy danych i badacze",
        "Początkujący i średniozaawansowani programiści Pythona",
        "Studenci kierunków technicznych i informatycznych"
      ]
    },
    {
      "title": "Aprende Apache Kafka desde cero con Python y Power BI",
      "url": "https://www.udemy.com/course/aprende-apache-kafka-desde-cero-con-python-y-power-bi/",
      "bio": "Descubre los fundamentos de Apache Kafka y aprende a analizar datos en tiempo real con Python y Power BI",
      "objectives": [
        "Entender los conceptos fundamentales de Apache Kafka",
        "Conocer la arquitectura y todos los componentes que conforman Kafka",
        "Instalar, configurar y desplegar un entorno de Apache Kafka",
        "Administrar los recursos de un clúster de Kafka a través de CLI",
        "Configurar el cliente de Python para Apache Kafka",
        "Procesar datos en streaming y aplicar transformaciones en Python para estructurar la información a analizar en BI",
        "Desarrollar reportes en Power BI que representen información en tiempo real mediante el procesamiento de datos en streaming en Kafka",
        "Implementar proyectos completos que utilicen Python para transformar datos que se ingesten en tiempo real en Kafka"
      ],
      "course_content": {},
      "requirements": [
        "No se requiere experiencia previa. En el curso aprenderás todo lo que necesitas saber para crear todo tipo de soluciones con Apache Kafka"
      ],
      "description": "¿Qué objetivo tiene el curso?\nEl objetivo principal del curso es que empezando desde cero, aprendas a desplegar, configurar y trabajar en un entorno de Apache Kafka que te permita analizar datos en tiempo real en tu empresa o proyecto actual. Obtendrás conocimientos fundamentales sobre Kafka y su integración con Python para implantar soluciones de analítica avanzada que permitan tomar decisiones basadas en información recibida en tiempo real.\n\n\n¿Qué es Apache Kafka?\nApache Kafka es una plataforma de transmisión de datos de código abierto, fundamental para gestionar flujos masivos de información en tiempo real. Es ampliamente adoptado en el mundo empresarial, de hecho más del 80% de las Fortune 100, incluyendo empresas como Box, Goldman Sachs y Target, confían en Kafka. Destaca por su eficiencia y escalabilidad, siendo esencial en arquitecturas modernas que requieren análisis instantáneo de datos en tiempo real. En esencia, Kafka facilita la transmisión continua y el procesamiento inmediato de datos, en contraste con el procesamiento por lotes convencional.\nLa versatilidad de Kafka abarca una amplia gama de casos de uso, desde la ingesta y procesamiento de eventos en tiempo real hasta la integración de sistemas, análisis de datos en streaming, monitoreo y mucho más. Se aplica en sectores como IoT, telecomunicaciones, banca, logística e industria, ofreciendo soluciones para monitoreo, optimización y gestión en tiempo real.\n\n\nCaracterísticas Principales de Apache Kafka\nEscalabilidad: Kafka es altamente escalable y puede manejar grandes volúmenes de datos y flujos de trabajo distribuidos escalando horizontalmente si es necesario con la posibilidad de añadir más nodos a un clúster.\nLatencia: Ofrece una baja latencia, permitiendo la transmisión y procesamiento rápido de datos en tiempo real. Es esencial para aplicaciones que requieren respuestas rápidas a eventos.\nArquitectura: Se basa en un modelo de publicación-suscripción, donde los productores generan y envían mensajes a topics, y los consumidores se suscriben a dichos topics para recibir y procesar los datos en tiempo real. Este enfoque distribuido posibilita la flexibilidad y la escalabilidad, permitiendo que múltiples productores y consumidores operen de manera simultánea y colaborativa.\nTolerancia a Errores: La arquitectura de Kafka permite configurar entornos productivos de tal manera que si algunos de los nodos de un clúster fallan, el sistema sigue siendo operativo y no pierde datos gracias a la replicación y almacenamiento duradero.\nRetención de Datos: Los datos se procesan y se almacenan pudiendo ser replicados para evitar pérdidas de datos en caso de fallos de infraestructura. Sin embargo, para su correcto funcionamiento es importante configurar correctamente los parámetros que definen durante cuánto tiempo se debe retener la información.\nEcosistema Flexible. Tiene un ecosistema extensible y es compatible con una gran variedad de conectores y herramientas, permitiendo la integración con otras tecnologías y sistemas.\nMonitoreo y Administración. Existen herramientas que permiten monitorear y administrar los clústers de Kafka, proporcionando visibilidad sobre el estado y el rendimiento del sistema. Además el uso de este tipo de herramientas agiliza muchísimo la operativa y libera tiempo para que los expertos en datos se centren exclusivamente en aportar valor, y se olviden de la gestión y monitoreo de la infraestructura, dejándole toda esa parte a softwares nos mandarán alertas, avisos, y realizará de forma automática toda la gestión y seguimiento de nuestro entorno de Kafka\n\n\n¿En qué va a ayudarte este curso?\nEntender los conceptos fundamentales de Apache Kafka. Conocerás los principios fundamentales que constituyen la esencia de Apache Kafka. Entenderás su arquitectura, comprenderás la importancia de los topics y las particiones, conocerás el papel esencial de productores y consumidores, y en definitiva de todos los componentes que conforman Kafka.\nInstalar y Configurar un entorno de Apache Kafka. Explorarás cada paso necesario para poner en marcha un entorno de Apache Kafka. Abordaremos detalles cruciales como configuración de propiedades, requisitos del sistema y resolución de problemas comunes, asegurando que lo dejamos todo listo para que los proyectos reales que vamos a desarrollar se ejecuten sin ningún problema.\nInteractuar con Kafka a través de CLI. Aprenderás los comandos clave para la creación, descripción y gestión de topics, productores, consumidores, y mucho más. Obtendrás las habilidades necesarias para administrar clústeres de Kafka directamente desde la línea de comandos, proporcionando una base práctica para el trabajo diario con la plataforma.\nTrabajar con el Cliente de Python de Apache Kafka. Aprenderás a instalar y configurar el cliente de Python para Kafka y te sumergirás en la producción y consumo de mensajes utilizando este lenguaje. Implementarás proyectos completos que utilicen Python para transformar datos que se ingesten en tiempo real en Kafka.\nCrear y Diseñar Estructuras de Datos con Python y Kafka. Descubrirás cómo crear productores y consumidores eficientes en Python capaces de leer datos de múltiples orígenes y transmitir información en tiempo real para que sea procesada y analizada con algoritmos de machine learning, inteligencia artificial o cualquier herramienta de business intelligence. Poder trabajar con Kafka des de proyectos desarrollados en Python permite llevar a otro nivel los desarrollos actuales, pasando de poder procesar la información por lotes cada X tiempo, a hacerlo en real time y en consecuencia pudiendo tomar mejores decisiones de negocio en las empresas, reduciendo prácticamente a cero la latencia entre la obtención del dato y la toma de las decisiones.\nVisualizar Datos en Tiempo Real con Power BI, Kafka y Python. Crearás reportes en Power BI capaces de representar todo tipo de información en tiempo real en sus gráficos. Y todo ello lo harás diseñando soluciones reales que te permitan llevar la información a herramientas de Business Intelligence como Power BI, a través del procesado de datos en streaming con Kafka, y realizando la limpieza y transformación de datos que sea pertinente en Python.\n\n\nContenido y Descripción General\nEl curso es apto para todos los niveles. Empezaremos definiendo los conceptos fundamentales de Apache Kafka y descubriendo los componentes que conforman la plataforma, entendiendo en qué puede ayudarnos en nuestra vida laboral o en nuestros proyectos. Aunque eso no significa que no tratemos funcionalidades avanzadas o que nos quedemos en el nivel inicial, de hecho, el curso va incrementando la dificultad y en los ejercicios prácticos de cada módulo iremos utilizando todo lo aprendido en las clases anteriores.\nTodo el proceso de aprendizaje gira entorno a la aplicación de Apache Kafka en el mundo empresarial, y te proporcionará una inmersión completa en plataforma, abordando desde los conceptos fundamentales hasta la implementación práctica en situaciones de negocio reales.\nA través de módulos que abarcan desde la comprensión esencial de la arquitectura de Kafka, hasta el diseño de soluciones reales que te permitan consumir información en Power BI, procesando los datos en streaming en Kafka, y realizando la limpieza y transformación que sea pertinente en Python. Obtendrás los conocimientos y habilidades necesarias para convertirte en todo un experto en la plataforma y aprovechar al máximo su potencial en tus proyectos.",
      "target_audience": [
        "Todos quienes deseen descubrir porque Apache Kafka es una de las platafromas de streaming de datos más utilizada por organizaciones de todo el mundo para analizar información en tiempo real",
        "Apasionados del mundo del data que estén interesados en comprender y adoptar sistemas de análisis de datos en real-time",
        "Interesados en obtener una visión global de Apache Kafka, una plataforma con infinidad de posibilidades, tanto a nivel conceptual como a nivel práctico",
        "Interesados en diseñar soluciones de analítica en tiempo real con Apache Kafka para resolver necesidades concretas de sus empresas o proyectos en los que esten involucrados",
        "Estudiantes que quieran destacar y convertirse en expertos en una habilidad cada vez más relevante en el mercado laboral"
      ]
    },
    {
      "title": "ChatGPT desde cero",
      "url": "https://www.udemy.com/course/chatgpt-desde-cero/",
      "bio": "Dominando la Inteligencia Artificial: Una Guía Práctica para Interactuar con ChatGPT",
      "objectives": [
        "Fundamentos del Modelo: Descubre la ciencia y tecnología detrás de ChatGPT y cómo ha revolucionado el campo de la inteligencia artificial.",
        "Interacción Dinámica: Aprende a comunicarte y manipular ChatGPT para obtener respuestas precisas y contenidos generados automáticamente.",
        "Aplicaciones Prácticas: Explora las versátiles utilidades de ChatGPT, desde chatbots personalizados hasta generación de contenido creativo.",
        "Integración en Proyectos: Adquiere habilidades para implementar ChatGPT en tus propias iniciativas, ya sean comerciales, académicas o personales.",
        "Tendencias y Futuro: Entiende las potencialidades futuras de los modelos de lenguaje y cómo pueden influir en la evolución de diversos sectores y industrias."
      ],
      "course_content": {
        "Introduction": [
          "Introducion a ChatGPT",
          "¿Que es y como funciona Chat GPT?",
          "Cómo crear una cuenta de chat GPT?",
          "Nuestro Primer Chat"
        ],
        "Ingenieria de Prompts": [
          "¿Que son los Prompts?",
          "¿Que es Ingenieria de Prompts?",
          "Iterar",
          "Pre Disponer a ChatGPT: Priming",
          "Identidad: Chat GPT actua como...",
          "Listas y Tablas",
          "Tono de los Prompts",
          "Comparar"
        ],
        "Ejemplos de uso practicos": [
          "Maquina de ideas",
          "Crear emails profesionales",
          "Crear contenido para Redes Sociales",
          "Crear contenido para Youtube",
          "Escribir un libro",
          "Usar ChatGPT como traductor",
          "Creacion de contenido para BLOGs",
          "Crear Curriculum - Hoja de Vida",
          "Prepararse para una entrevista",
          "Escribir canciones",
          "Crear un PODCAST",
          "Planificar viajes"
        ]
      },
      "requirements": [
        "¡Nada más que tu pasión y curiosidad! Si tienes ganas de sumergirte en el fascinante mundo de la inteligencia artificial, este es tu punto de partida. No te preocupes si no tienes experiencia en programación o tecnología; hemos diseñado este curso pensando en ti. Si puedes navegar por internet y tienes hambre de aprendizaje, ya estás listo. ¡Equipa tu mente con entusiasmo, asegúrate de tener tu dispositivo conectado y prepárate para una travesía tecnológica que te cambiará la vida! ¡Vamos, el futuro te está llamando!"
      ],
      "description": "Bienvenido a \"ChatGPT desde cero\", tu guía definitiva para comprender y dominar una de las herramientas de inteligencia artificial más revolucionarias del siglo XXI. En este curso, te llevaremos de la mano a través del fascinante mundo de los modelos de lenguaje de OpenAI, centrándonos especialmente en el impresionante ChatGPT.\n¿Eres un principiante que apenas escucha sobre ChatGPT? Perfecto, estás en el lugar correcto. Empezaremos desde los fundamentos:\n¿Qué es GPT?\n¿Cómo funciona la inteligencia artificial detrás de él?\nCasos de uso Practicos\nCon ejemplos prácticos y explicaciones sencillas, te introduciremos al núcleo de esta tecnología.\nPero eso no es todo. A medida que avances, exploraremos juntos las infinitas aplicaciones y potencialidades de ChatGPT. Desde la creación de chatbots personalizados hasta la generación automática de contenidos, las posibilidades son inmensas. Además, te proporcionaremos herramientas y técnicas para que puedas integrar ChatGPT en tus propios proyectos, ya sea para negocios, investigación o simplemente por curiosidad.\nA lo largo de este curso, no sólo aprenderás sobre la teoría detrás de ChatGPT, sino que también tendrás la oportunidad de interactuar directamente con el modelo, haciendo que tu experiencia de aprendizaje sea interactiva y dinámica. Con tutoriales paso a paso, aseguramos que, al finalizar, tengas la confianza y habilidad para utilizar ChatGPT de manera efectiva.\n\"ChatGPT desde cero\" es más que un simple curso; es tu pasaporte hacia el futuro de la comunicación y la inteligencia artificial. Atrévete a sumergirte en este viaje tecnológico y descubre cómo ChatGPT está redefiniendo la forma en que interactuamos con las máquinas y, en última instancia, con el mundo que nos rodea.\n¡Inscríbete ahora y comienza tu aventura con ChatGPT!",
      "target_audience": [
        "¡Este curso es para visionarios como tú! Ya seas un entusiasta de la tecnología, un emprendedor buscando innovar, un educador deseoso de integrar las últimas tendencias en IA en su enseñanza, o simplemente alguien curioso sobre cómo las máquinas \"piensan\" y \"conversan\", este curso te abrirá las puertas a un mundo de posibilidades. No necesitas ser un experto en programación, solo necesitas pasión y la voluntad de aprender. Si estás listo para ser pionero en la próxima ola de innovaciones digitales, \"ChatGPT desde cero\" está hecho especialmente para ti. ¡Únete a nosotros en esta emocionante travesía!"
      ]
    },
    {
      "title": "【初心者向け】Pythonで感情分析AIや大規模言語モデル（LLM）を使った様々な種類のチャットボットを作ろう！",
      "url": "https://www.udemy.com/course/python-chatbot/",
      "bio": "Pythonを使ってシンプルなルールベースのチャットボットから単語を調べて答えを返してくれるチャットボットや感情分析をして励ましてくれるチャットボット、そしてLLMを搭載して「しりとり」をしてくれるチャットボットなどを作っていこう！",
      "objectives": [
        "Pythonの基礎",
        "チャットボットの作り方",
        "大規模言語モデルGPTのAPIの使い方",
        "Transformersの感情分析AIの使い方",
        "Streamlitとngrokを使ったWebアプリの作り方"
      ],
      "course_content": {
        "はじめに": [
          "はじめに"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Seabornについて学ぼう！",
          "Python構文の復習"
        ],
        "名前と挨拶を返した後はオウム返しを繰り返すルールベースのチャットボットを作っていこう！": [
          "名前を入力したら時間帯をふまえて挨拶を返す処理を作っていこう！",
          "ユーザーのインプットをそのままオウム返しする処理を作っていこう！"
        ],
        "形態素解析し固有名詞を取り出しWikipediaで調べた結果を返してくれるチャットボットを作っていこう！": [
          "Wikipediaライブラリの使い方を見ていこう！",
          "Wikipediaの処理を関数化していこう！",
          "形態素解析の処理を書いていこう！",
          "チャットボットのメインの処理を書いて完成させよう！"
        ],
        "感情分析をAIで行い負の感情なら偉人の名言と共に励ますチャットボットを作っていこう！": [
          "【次のレクチャー注意】一部コードで誤っている部分がございます",
          "感情分析用のAIモデルを使えるようにしていこう！",
          "感情分析と名言抽出のロジックを記載しチャットボットを完成させよう！"
        ],
        "大規模言語モデル（LLM）を使って「しりとり」をしてくれるチャットボットを作っていこう！": [
          "OpenAIのAPIキーを取得しよう！",
          "【注意】httpxのバージョンに起因するエラーについて",
          "しりとりの条件を書いていこう！",
          "GPTのAPIから返答を得る処理を書いていこう！",
          "チャットボットを完成させていこう！"
        ],
        "Streamlitを使ってチャットボットをWebアプリ化してみよう！": [
          "ngrokのAPIキーを取得しよう！",
          "【次のレクチャーの注意】ライブラリのバージョン",
          "ngrokの認証を通そう！",
          "Streamlitのコード部分を書いていこう！",
          "Streamlitのアプリを立ち上げて公開してみよう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学びますので特に必要ありません"
      ],
      "description": "このコースでは、Pythonを使ってチャットボットを作っていきます！\n\n\n・まずはじめに挨拶とオウム返しをするルールベースのシンプルなチャットボット\n・続いて、固有名詞を抽出してWikipediaで調べて結果を返してくれるチャットボット\n・続いて、感情分析をAIで行い負の感情であれば励ましてくれるチャットボット\n・最後に、大規模言語モデル（LLM）を用いて「しりとり」をしてくれるチャットボット\nを作っていきます！\n\n\nそして最終的に感情分析チャットボットをStreamlitとngrokでWebアプリ化していきますよ！\n\n\nぜひ色んなチャットボットを作ってみてください！",
      "target_audience": [
        "色んな種類のチャットボットを作ってみたい方",
        "簡易的なチャットボットWebアプリの作り方に興味がある方"
      ]
    },
    {
      "title": "Hızlandırılmış Python ve Makine Öğrenmesi ile Borsa Tahmini",
      "url": "https://www.udemy.com/course/python-ve-makine-ogrenmesi-ile-borsa-tahmini/",
      "bio": "Makine öğrenmesi ile borsa tahmini, 0'dan kendi algoritmamızı geliştirmek",
      "objectives": [
        "Makine öğrenmesi ve python ile borsa tahmini",
        "Lineer regresyon matematiği, feature scaling, r^2 error hesabı",
        "Optimizasyon algoritmaları (Batch gradient descent, Normal equation)",
        "Pandas,Numpy,Matplotlib(Python)"
      ],
      "course_content": {
        "Giriş": [
          "Kurs Tanımıtı, Giriş ve Öneriler",
          "Gerekli Modül ve Programların Kurulumu",
          "pip install İşlemlerindeki Hata"
        ],
        "Scikit Learn ile Borsa Tahmini": [
          "ASK-BID de Hata",
          "Özellik (Feature) Oluşturma, Veri Analizi, Train Test Split ve Feature Scaling",
          "Algoritmamızı Oluşturma, Görselleştirme ve Tahminimize İlk Bakış",
          "BTC Tahmin-Gerçek Karşılaştırılması"
        ],
        "Investing Üzerinden Analiz": [
          "33.Satır Hakkında Düzeltme",
          "Veri Analizi, Verileri Kullanabileceğimiz Formata Dönüştürme",
          "Algoritmamızı Bitirip Görselleştirme, MinMax ve StandardScaler Kullanımı"
        ],
        "Lineer Regresyon Matematiği, Makina Öğrenmesinde Algoritma Mantığı": [
          "Lineer Regresyon Giriş, Hipotez ve Cost Fonksiyonu",
          "Batch Gradient Descent Algoritması",
          "Normal Denklemi, Çoklu Lineer Regresyon",
          "r2 Error Hesabı, Basitleştirilmiş Lineer Regresyon Formülü"
        ],
        "0'dan Kendi Lineer Regresyon Algoritmamızı Yazmak": [
          "Train Test Split ve Bias Terimi Eklemek",
          "addones() Fonksiyonunda Hata",
          "Min-Max Scaler ve Normal Denklemi",
          "Batch Gradient Descent Denklemi",
          "r2 Error Fonksiyonu ve Parametreleri Göster Fonksiyonu",
          "Görselleştirme ve Tahmin Fonksiyonları Eklenmesi"
        ],
        "Devam Vidyoları İçin (Önemli)": [
          "Kursun Devam Vidyoları"
        ],
        "Öneriler": [
          "Öneriler"
        ]
      },
      "requirements": [
        "Temel Python Bilgisi"
      ],
      "description": "Öncelikle herkese merhabalar.\n\n\nBu kursun amacı, makine öğrenmesi hakkında merakı olan herkes için detayıyla giriş yapmak ve size kod ezberletmeden mantığını oturtmak. Kursta sadece bir algoritma anlatacağım (lineer regresyon), fakat kursu bitirdiğiniz zaman sadece 2-3 satır kod ezberlemiş değil, makine öğrenmesinin alt yapısına, çalışma prensibine ve temelini iyi anlayacaksınız. Öncelikle scikit-learn kütüphanesini kullanarak eski bitcoin verilerini kullanıp gelecekte ne olabileceğini tahmin etmeye çalışacağız. Bunu yaptıktan sonra, investing üzerinden Türk borsaları, Türk hisseleri üzerinden ayrı bir tahmin yapacağız. Ardından, makine öğrenmesinin temellerinin ve algoritmamızın matematiğini anlatacağım, matematiğini anlamanız önemli çünkü bu matematiği koda dökeceğiz. Bunlardan sonra ise, hiç bir makine öğrenmesi kütüphanesi kullanmadan (from scratch) tüm kodu, yani kendi algoritmamızı sıfırdan yazacağız. Kodu yazmadan önce size tüm matematiğinden  Bunu kendimiz yaparken, lineer regresyonun matematiğini, yapılan error hesaplarını, feature scalingi, kullanılan algoritmaları ve tüm temelini oturtacağız. Kısacası; kendimiz için ufak bir makine öğrenmesi (lineer regresyon) kütüphanesi yazacağız. Eğer temelini iyi öğrenir ve ezber yapmazsanız, ileride öğreneceğiniz yeni algoritmalarda sorun yaşamazsınız ve hafızanızda unutulmayacak bir yere kazımış olursunuz.",
      "target_audience": [
        "Makine öğrenmesi, kodlama ve veri analizi merakları olan öğrenciler"
      ]
    },
    {
      "title": "Máster Deep Learning - Inteligencia Artificial con Python",
      "url": "https://www.udemy.com/course/master-redes-neuronales-deep-learning-con-tensorflow-2021/",
      "bio": "Domina Deep Learning desde cero con Python y Tensorflow 2 creando potentes redes neuronales con inteligencia artificial.",
      "objectives": [
        "Dominar las técnicas de Deep Learning desde cero y con explicaciones sencillas.",
        "Profundizar en los conceptos de Inteligencia Artificial, Machine Learning y Deep Learning.",
        "Conocer los diferentes tipos de Redes Neuronales, valorar cuál es el más adecuado y optimizarlas.",
        "Creación de Redes Neuronales Artificiales (ANN) con Tensorflow para aplicarlas en su proyecto de inicio a fin.",
        "Creación de Redes Neuronales Convolucionales (CNN) con Tensorflow siendo capaz de crear proyectos basados en imágenes.",
        "Creación de Redes Neuronales Recurrentes (RNN) con Tensorflow para trabajar con secuencias de datos como previsiones temporales o secuencias de texto.",
        "Creación de Redes Neuronales enfocadas en aprendizaje no supervisado para abordar proyectos de clusterización, detección de anomalías o reducción de dimensiones",
        "Predecir el futuro gracias a los modelos de Machine Learning para conseguir la ventaja competitiva.",
        "Dar un enorme valor añadido tanto en su compañía como en el ámbito personal.",
        "Adquirirá un conocimiento extenso en la tecnología puntera de Inteligencia Artificial que podrá aplicar de inmediato a su día a día."
      ],
      "course_content": {
        "Introducción a Deep Learning": [
          "Bienvenida / Información importante",
          "¿Qué es Machine Learning y Deep Learning?",
          "Instalación de entorno Python y librerías Deep Learning",
          "NOTA: Actualización de scripts Tensorflow 2.x",
          "Aprendizaje supervisado",
          "¿Qué es el overfitting / underfitting en el aprendizaje supervisado?",
          "Evaluación de rendimiento de modelos - Métricas de Clasificación",
          "Evaluación de rendimiento de modelos - Métricas de Regresión",
          "Aprendizaje no supervisado",
          "DESCARGA DATASETS & SCRIPTS CASOS PRÁCTICOS"
        ],
        "Redes neuronales artificiales (ANN)": [
          "¿Qué es una neurona y el modelo perceptrón?",
          "¿Qué son las redes neuronales?",
          "Funciones de activación",
          "Funciones de activación en modelos multiclase",
          "Funciones de Coste y de Gradiente Descendente",
          "Propagación hacia atrás (backpropagation)",
          "Claves para crear redes neuronales efectivas",
          "¿Qué nos proporciona Tensorflow y Keras?",
          "Regresión con Keras - Presentación caso práctico",
          "Regresión con Keras - Importación de librerías y fuentes",
          "Regresión con Keras - Análisis de datos (EDA) + Preprocesado (I)",
          "NOTA MÉTODO CORRELACIÓN",
          "Regresión con Keras - Análisis de datos (EDA) + Preprocesado (II)",
          "Regresión con Keras - División Train / Test",
          "Regresión con Keras - Escalado",
          "Regresión con Keras - Creación de modelo",
          "Regresión con Keras - Entrenamiento del modelo",
          "Regresión con Keras - Evaluación y Predicción",
          "Clasificación binaria con Keras - Presentación caso práctico",
          "Clasificación binaria con Keras - Importación de librerías y fuentes",
          "Clasificación binaria con Keras - Análisis de datos (EDA) + Preprocesado",
          "Clasificación binaria con Keras - División Train / Test",
          "Clasificación binaria con Keras - Escalado",
          "Clasificación binaria con Keras - Creación de modelo",
          "Clasificación binaria con Keras - Entrenamiento del modelo",
          "NOTA ENTRENAMIENTO CLASIFICACIÓN BINARIA - TENSORFLOW >2.16",
          "Clasificación binaria con Keras - Evaluación y Predicción",
          "Clasificación multiclase con Keras - Presentación caso práctico",
          "Clasificación multiclase con Keras - Importación de librerías y fuentes",
          "Clasificación multiclase con Keras - Análisis de datos (EDA) + Preprocesado (I)",
          "Clasificación multiclase con Keras - Análisis de datos (EDA) + Preprocesado (II)",
          "Clasificación multiclase con Keras - División Train / Test",
          "Clasificación multiclase con Keras - Escalado",
          "Clasificación multiclase con Keras - Creación de modelo",
          "Clasificación multiclase con Keras - Entrenamiento del modelo",
          "Clasificación multiclase con Keras - Evaluación y Predicción",
          "Clasificación multiclase con Keras - Monitorización con Tensorboard"
        ],
        "Redes neuronales convolucionales (CNN)": [
          "Introducción a las redes neuronales convolucionales (CNN)",
          "¿Qué son los filtros de imagen y los kernels?",
          "Capas convolucionales en una CNN",
          "Capas pooling en una CNN",
          "Clasificación imágenes Blanco y Negro - Presentación caso práctico",
          "Clasificación imágenes Blanco y Negro - Importación de librerías y fuentes",
          "Clasificación imágenes Blanco y Negro - Preprocesado",
          "Clasificación imágenes Blanco y Negro - Creación del modelo",
          "Clasificación imágenes Blanco y Negro - Entrenamiento del modelo",
          "Clasificación imágenes Blanco y Negro - Evaluación y Predicción",
          "Clasificación imágenes RGB - Presentación caso práctico",
          "Clasificación imágenes RGB - Importación de librerías y fuentes",
          "Clasificación imágenes RGB - Preprocesado",
          "Clasificación imágenes RGB - Creación del modelo",
          "Clasificación imágenes RGB - Entrenamiento del modelo",
          "Clasificación imágenes RGB - Evaluación y Predicción"
        ],
        "Redes neuronales recurrentes (RNN)": [
          "Introducción a las redes neuronales recurrentes (RNN)",
          "Neuronas LSTM",
          "Creación de batches en RNN",
          "Forecast RNN - Presentación caso práctico",
          "Forecast RNN - Importación de librerías y fuentes",
          "Forecast RNN - Preprocesado",
          "Forecast RNN - División Train / Test",
          "Forecast RNN - Escalado",
          "Forecast RNN - Creación Generador Serie Temporal",
          "Forecast RNN - Creación del modelo",
          "Forecast RNN - Entrenamiento del modelo",
          "Forecast RNN - Evaluación y Predicción"
        ],
        "Redes neuronales en Aprendizaje No Supervisado": [
          "Introducción a las redes neuronales en aprendizaje no supervisado",
          "¿Qué son los autoencoders en una red neuronal?",
          "NN No Supervisado - Presentación caso práctico",
          "NN No Supervisado - Importación de librerías y fuentes",
          "NN No Supervisado - Preprocesado",
          "NN No Supervisado - Escalado",
          "NN No Supervisado - Estimación número de clusters",
          "NN No Supervisado - Creación del modelo",
          "NN No Supervisado - Entrenamiento del modelo",
          "NN No Supervisado - Evaluación y Predicción de clusters"
        ],
        "DESPLIEGUE DE SOLUCIONES DE MACHINE LEARNING / DEEP LEARNING": [
          "¿Cómo desplegamos un modelo de Deep Learning?",
          "Caso práctico despliegue de un proyecto Deep Learning"
        ],
        "Conclusiones": [
          "Conclusiones",
          "Próximos Pasos",
          "Clase Extra",
          "Recursos Extra"
        ]
      },
      "requirements": [
        "Se recomienda tener conocimientos básicos de Python, aunque la explicación de Deep Learning y redes neuronales será desde cero."
      ],
      "description": "¿Quieres dominar las técnicas más avanzadas de Deep Learning y crear potentes Redes Neuronales desde cero con Inteligencia Artificial?\n---\nEscucha de otros alumnos por qué este es el curso de INTELIGENCIA ARTIFICIAL y DEEP LEARNING MEJOR VALORADO en español:\n\"Me está gustando mucho este curso porque está muy bien explicado ; Detalles con mucha claridad. Es un curso muy adecuado para gente que empieza y te hace sentar las bases. Muchas gracias profesor!! Muy práctico y con templates realizados para poder aplicar de inmediato .Excelente\" -- Honorino Fernández (5 estrellas)\n\n\n\"Sin duda es un gran curso de redes neuronales, está muy bien explicado y hay mucha teoría de por medio\" -- Luis Hernández (5 estrellas)\n\n\n\"Recomendado, he aprendido muchísimo. Ahora a desarrollar proyectos propios y a ganar experiencia aplicando los conocimientos obtenidos en el curso\" -- Alberto Matogo (5 estrellas)\n---\nEl objetivo de este curso es darte una guía fácil de entender para que puedas acometer tus proyectos de Inteligencia Artificial con técnicas Deep Learning y el framework Tensorflow / Keras y Python.\nTensorflow es una librería open source creada originalmente por Google para computación numérica utilizando grafos y flujos de datos. Nos permite crear redes neuronales con las que realizar un modelado de los datos aprendiendo de nuestras fuentes para poder realizar predicciones automáticas, emulando el comportamiento de las neuronas en los seres humanos.\nTensorflow es utilizada por las más potentes compañías alrededor del mundo como Airbnb, Ebay, Dropbox, Snapchat, Twitter, Uber, SAP, Qualcomm, IBM, Intel y por supuesto Google.\nEn este curso aprenderás desde cero todo lo necesario para convertirte en un maestro de Inteligencia Artificial y Deep Learning, instalaremos paso a paso el framework de Python y las librerías necesarias para que finalmente seas capaz de crear redes neuronales automáticas (ANN), redes neuronales convolucionales (CNN) para tratamiento de imágenes, redes neuronales recurrentes (RNN) para trabajar con secuencias de datos como previsiones temporales y redes neuronales en aprendizaje no supervisado para acometer proyectos de clusterización, detección de anomalías, etc.\nAl finalizar el curso podrás crear potentes proyectos de Deep Learning a nivel profesional siendo capaz de extraer el máximo provecho a tus datos.\nEste curso tendrá un enfoque eminentemente práctico, cada bloque contendrá casos prácticos explicados paso a paso para que entiendas y apliques de inmediato el proceso a seguir en un proyecto de Inteligencia Artificial y Deep Learning con Python.\nTendrás a tu disposición un material extenso de consulta y todos los scripts de Python explicados durante esta especialización de tal manera que le sea muy sencillo reutilizarlos para tu caso de uso concreto. Mi objetivo es que cuando finalice el curso puedas aplicarlo de inmediato a tu situación particular.\nNo tienes nada que perder, tendrás una garantía de 30 días para asegurar que estás 100% satisfecho con el material, mi objetivo es aportarte valor con todos estos conocimientos y si no es así siéntete libre de solicitar la devolución, aunque estoy seguro de que cumplirá tus expectativas.\nEs el momento de que pases a la acción, tomando este curso conseguirás dominar la tecnología más puntera de Deep Learning, lo cual supone obtener una habilidad muy importante para poder destacar sobre el resto y conseguir sacar el máximo provecho de tus datos y de tu tiempo con inteligencia artificial.",
      "target_audience": [
        "Toda persona que quiera aprender las tecnologías punteras de Machine Learning y Deep Learning.",
        "Toda persona que quiera profundizar desde cero en el uso de las últimas versiones de Keras y Tensorflow 2.",
        "Analistas de datos que quieran equiparse con un conocimiento avanzado para ejecutar sus proyectos de Machine Learning.",
        "Estudiantes que quieran obtener habilidades que le abrirán puertas en el mercado laboral y la inteligencia artificial.",
        "Cualquier persona que quiera predecir el futuro y crear potentes proyectos para solucionar múltiples problemas que existen en nuestro entorno."
      ]
    },
    {
      "title": "Pythonによる異常検知【画像データ編】",
      "url": "https://www.udemy.com/course/python-image-anomaly-detection/",
      "bio": "画像データの異常検知をGoogle Colaboratoryを使って実践しましょう！One Class SVMとオートエンコーダそれぞれの手法で挑戦します。",
      "objectives": [
        "Pythonによる画像データの扱い",
        "機械学習やディープラーニングの基礎知識",
        "異常検知での評価手法",
        "オートエンコーダによる異常検知手法",
        "One Class SVMによる異常検知手法"
      ],
      "course_content": {
        "コース紹介": [
          "コース紹介",
          "資料・データのダウンロード",
          "コース準備レクチャー"
        ],
        "異常検知のイントロダクション": [
          "ビジネスにおける異常検知",
          "異常検知におけるデータの特徴と機械学習手法",
          "異常検知の用途と計算コスト",
          "画像データの扱い方"
        ],
        "画像データの異常検知手法": [
          "One Class SVM",
          "オートエンコーダ"
        ],
        "機械学習・ディープラーニングの基礎（参考）": [
          "機械学習を実施するときの流れ",
          "ランダムフォレスト",
          "SVM",
          "k近傍法（kNN）",
          "精度評価とCross Validation",
          "混同行列",
          "Precision, Recall",
          "ROC曲線とAUC",
          "PR曲線とAUC",
          "ニューラルネットワーク",
          "勾配降下法",
          "確率的勾配降下法",
          "ミニバッチ学習",
          "Epoch, Iteration",
          "逆誤差伝播法",
          "勾配消失とRELU",
          "モデリングをするときに",
          "畳み込みニューラルネットワーク（CNN）①"
        ],
        "Pythonによる画像異常検知の実践": [
          "演習内容の紹介",
          "One Class SVMによる異常検知の実践①",
          "One Class SVMによる異常検知の実践②",
          "One Class SVMによる異常検知の実践③",
          "オートエンコーダによる異常検知の実践①",
          "オートエンコーダによる異常検知の実践②",
          "オートエンコーダによる異常検知の実践③",
          "オートエンコーダによる異常検知の実践④",
          "オートエンコーダによる異常検知の実践⑤"
        ],
        "終わりに": [
          "演習のコメントと参考文献"
        ],
        "ボーナスレクチャー": [
          "ボーナス"
        ]
      },
      "requirements": [
        "簡単なPythonプログラミング"
      ],
      "description": "本コースでは、画像データに対する異常検知手法を学びます。\n異常検知はビジネスのさまざまな分野でニーズの高い分野です。One Class SVMやオートエンコーダといった基本的な異常検知技術を活用し、画像データに潜む異常検知をPythonで実践しましょう！（メインはオートエンコーダです）\n\n\n本コースの内容\n画像データの処理手法\n機械学習やディープラーニングの基礎\nOne Class SVMを用いた異常検知の演習\nオートエンコーダを使用した異常検知の演習\n\n\n実行環境等\n本コースではGoogle Colaboratoryを使用します。ただし、自前の環境で実施していただいても構いません\n演習に使うデータやサンプルコードはカリキュラムの中でダウンロード可能です。\n\n\n本コースはPythonの基本的なスキルがあれば誰でも実践することができる内容となっていますし、2時間半に満たないコースですから週末や夜間にまとめて実施することも可能です。\nこの機会にぜひPythonで実施できるようになり、自身のスキルアップに活かしていきましょう！",
      "target_audience": [
        "Pythonによる画像データの扱い",
        "画像データの異常検知を行う時の手法",
        "One Class SVMによる異常検知",
        "オートエンコーダによる異常検知"
      ]
    },
    {
      "title": "Análise e mineração de texto + Classificação de emoção (NLP)",
      "url": "https://www.udemy.com/course/analise-e-mineracao-de-texto-classificacao-de-emocao-nlp/",
      "bio": "Aprenda manipular dados de textos",
      "objectives": [
        "Criar um modelo de Machine Learning",
        "Minerar textos",
        "Análises gráficas",
        "Linguagem de processamento natural",
        "Analisar dados de textos",
        "REGEX (Expressões regulares)"
      ],
      "course_content": {
        "Introdução": [
          "Abertura",
          "Introdução"
        ],
        "Exploração dos Dados & EDA": [
          "#01 - Importação dos dados",
          "#02 - Overview sobre soluções de NLP",
          "#03 - Ajustando os dados",
          "#04 - Minerando Datas 01",
          "#05 - Minerando Datas 02",
          "#06 - Minerando Geo-Localização 01",
          "#07 - Minerando Geo-Localização 02",
          "#08 - Minerando Geo-Localização 03",
          "#09 - Minerando Geo-Localização 04",
          "#10 - Other Features"
        ],
        "Mineração de Textos": [
          "#11 - Feature Target - Class Balance",
          "#12 - Quantidade de Palavras",
          "#13 - WordCloud / Nuvem de Palavras 01",
          "#14 - WordCloud / Nuvem de Palavras 02",
          "#15 - Rank de Palavras",
          "#16 - Remoção de Textos duplicados",
          "#17 - Stop Words [ Teoria ]",
          "#18 - Extração do Radical [ Teoria ]",
          "#19 - Expressões Regulares -REGEX [ Teoria ]",
          "#20 - Frequência NLTK [Teoria]"
        ],
        "Tratamento dos Dados": [
          "#21 - Introdução",
          "#22 - Removendo links",
          "#23 - Ajustando para minúsculo",
          "#24 - Retirar caractere especial",
          "#25 - Retirar emojis",
          "#26 - Retirar hashtag",
          "#27 - Retirar valores numérico",
          "#28 - Remoção StopWords",
          "#29 - Extração do Radical",
          "#30 - Tokenização"
        ],
        "Construção do Modelo": [
          "#31 - Divisão dos Dados",
          "#32 - Divisão das tabelas",
          "#33 - Construção do Modelo",
          "#34 - Avalição do Modelo: Matriz de Confusão",
          "#35 - Avalição do Modelo: Relatório de Classificação",
          "#36 - Testando a previsão do modelo",
          "#37 - Upgrade na previsão",
          "#38 - Fechamento"
        ]
      },
      "requirements": [
        "Python Básico",
        "Conhecimentos em Machine Learning"
      ],
      "description": "Análise e mineração de texto + Classificação de emoção (NLP)\nNesse treinamento vamos explorar a mineração e análise de textos e criar um modelo de Machine Learning para classificação a emoção de textos usando dados reais.\nIremos utilizar os seguintes frameworks:\nPandas;\nNumpy;\nMatplotlib;\nSeaborn;\nPlotly;\nRE;\nNLTK;\nYellowbrick;\nSklearn;\nWordCloud;\nEntre outros.\nComo vai funcionar nossa dinâmica?\nIremos importar dados extraindo do Twitter e começar uma mineração geral nos dados.\n\n\nVamos entender da região de onde foi extraindo esses dados\nVamos minerar informações de textos\nVamos criar um modelo para classificar as emoções\nObs: Essa solução pode ser adapta para criar um produto ou serviço baseado em dados !!!\n\n\nPorque aprender a criar soluções?\n\nProgramação é uma disciplina totalmente prática, de forma que, apenas a leitura de livros e/ou acompanhamento de vídeos não desenvolve todas as habilidades necessárias.\nA demanda por programadores Python nunca esteve tão alta, afinal, Python é uma das linguagens mais utilizadas no mundo e requisito para se trabalhar com Ciência de Dados e Inteligência Artificial. Inclusive, podemos considerar Python como uma linguagem padrão para análise de dados, tendo em vista seu amplo ecossistema de bibliotecas, que englobam desde a manipulação e tratamento de dados até mesmo o deploy de modelos. Não podemos esquecer, neste sentido, que o Python é uma linguagem de aplicação geral.\nPor ser uma linguagem de programação versátil, simples de aprender e muito poderosa, Python possui recursos que, apesar de simples de se utilizar, tornam o aprendizado muito divertido.\nBons estudos!",
      "target_audience": [
        "Analista de Dados",
        "Cientistas de Dados",
        "Engenheiro de Dados",
        "Estudantes",
        "Analistas de Negócios",
        "Entusiastas por Machine Learning",
        "Interessados em Inteligência Artificial"
      ]
    },
    {
      "title": "Python金融分析与量化交易实战",
      "url": "https://www.udemy.com/course/python-jr/",
      "bio": "金融分析-量化实战",
      "objectives": [
        "掌握Python数据分析与处理核心技能",
        "熟练应用Python工具包进行数据处理任务",
        "掌握Python统计分析分析必备知识点",
        "熟练应用Python工具包处理时间序列数据",
        "掌握量化交易必备核心技能",
        "熟练应用Python进行股票与因子数据处理",
        "掌握Ricequant量化平台核心使用方法",
        "熟练应用Ricequant平台构建策略模型",
        "掌握策略分析常用方法与技能",
        "熟练应用进行回测选股任务",
        "掌握策略分析方法与各指标含义",
        "熟练将策略应用到历史数据中进行回测评估"
      ],
      "course_content": {
        "介绍": [
          "课程内容与大纲介绍",
          "Python环境配置与基本操作",
          "Python库安装工具",
          "Notebook工具使用",
          "Python简介",
          "Python数值运算",
          "Python字符串操作",
          "索引结构",
          "本章数据代码下载"
        ],
        "Python核心操作": [
          "List基础结构",
          "List核心操作",
          "字典基础定义",
          "字典的核心操作",
          "Set结构",
          "赋值机制",
          "判断结构",
          "循环结构",
          "函数定义",
          "模块与包",
          "异常处理模块",
          "文件操作"
        ],
        "Python类与习题实例": [
          "类的基本定义",
          "类的属性操作",
          "时间操作",
          "Python练习题-1",
          "Python练习题-2",
          "Python练习题-3"
        ],
        "Python科学计算库-Numpy基本操作": [
          "Numpy工具包概述",
          "数组结构",
          "属性与赋值操作",
          "数据索引方法",
          "数值计算方法",
          "排序操作",
          "数组形状",
          "数组生成常用函数",
          "随机模块",
          "读写模块",
          "本章数据代码下载"
        ],
        "Python数据分析处理库-Pandas": [
          "Pandas工具包使用简介",
          "数据信息读取与展示",
          "索引方法",
          "groupby函数使用方法",
          "数值运算",
          "merge合并操作",
          "pivot数据透视表",
          "时间操作",
          "apply自定义函数",
          "常用操作",
          "字符串操作",
          "本章数据代码下载"
        ],
        "金融数据时间序列分析": [
          "金融时间序列数据统计分析",
          "序列变化情况分析计算",
          "连续指标变化情况分析",
          "时间序列重采样操作",
          "短均与长均计算实例",
          "指标相关情况分析",
          "本章数据代码下载",
          "回归方程与相关系数实例"
        ],
        "双均线交易策略实例": [
          "金叉与死叉介绍",
          "买点与卖点可视化分析",
          "本章数据代码下载（需PC登录）",
          "策略收益效果分析",
          "均线调参实例"
        ],
        "策略收益与风险评估指标解析": [
          "回测收益率指标解读",
          "年化指标分析",
          "本章数据代码下载",
          "最大回撤区间",
          "夏普比率的作用",
          "阿尔法与贝塔概述",
          "数据代码下载"
        ],
        "量化交易与回测平台解读": [
          "量化交易概述",
          "量化交易所需技能分析",
          "Ricequant交易平台简介",
          "本章数据代码下载"
        ],
        "Ricequant回测选股分析实战": [
          "策略任务分析",
          "股票池筛选",
          "策略效果演示与指标分析",
          "定时器功能与作用",
          "本章数据代码下载"
        ]
      },
      "requirements": [
        "零基础即可"
      ],
      "description": "Python金融分析与量化交易实战课程旨在帮助同学们快速掌握Python数据分心核心技能与交易交易系统策略部署与回测分析。全部课程内容皆以实战为主，通俗讲解数据分析常用方法与经典解决方案。主要包括三大核心模块：1.Python数据科学必备工具包实战；2.金融数据分析处理与分析实例；3.量化交易平台策略分析实战。整体风格通俗易懂，零基础即可入门，适合准备转行就业与进阶提升的同学们。",
      "target_audience": [
        "对Python，数据分析，金融分析等方向感兴趣的同学们"
      ]
    },
    {
      "title": "Lean Six Sigma Green Belt | لين 6 سيجما الحزام الأخضر",
      "url": "https://www.udemy.com/course/certified-lean-six-sigma-green-belt-1/",
      "bio": "متوافق مع الهيكل المعرفي لحزام 6 سيجما الأخضر المعتمد دوليًا | إكسيل و ميني تاب | اختبارات قصيرة واختبارات تدريبية",
      "objectives": [
        "Take the lead in Lean Six Sigma field via: powerful lectures + hands-on practice + punch of quizzes + assignments +full graduation exams",
        "Gain the Trust of Your Peers: Get Hands-on Expertise on 100+ Lean and Six Sigma Tools and Techniques",
        "Master the usage for statistical programs like: MINITAB and EXCEL for six sigma calculations",
        "Test your knowledge via hundreds of questions in Quizzes designed for each project step.",
        "Prepare yourself for the international LSSGB certification exam using high standards certification exams"
      ],
      "course_content": {},
      "requirements": [
        "No prerequisite is needed, do not worry if you are starting from scratch."
      ],
      "description": "دورة حزام سيجما الأخضر المعتمد في اللين (Lean Six Sigma) - باللغة العربية\nطور مهاراتك وحوّل العمليات!\nهل ترغب في تعزيز خبراتك في تحسين العمليات وتصبح ركيزة أساسية في مؤسستك؟ انضم إلى دورتنا المعتمدة لحزام سيجما الأخضر في اللين (Lean Six Sigma Green Belt) باللغة العربية اليوم! يوفر لك هذا البرنامج الشامل الأدوات والمعرفة اللازمة لزيادة الكفاءة والجودة والإنتاجية في مختلف القطاعات.\nنظرة عامة على الدورة\nبرنامج حزام سيجما الأخضر المعتمد هو تجربة تدريبية ديناميكية تجمع بين مبادئ الإدارة الرشيقة (Lean) ومنهجية سيجما ستة (Six Sigma). سيتعلم المشاركون كيفية تحديد وإزالة الهدر، وتقليل التباين في العمليات، وتحسين سير العمل. سواء كنت مبتدئًا في Lean Six Sigma أو تسعى للتقدم في مسارك المهني، فهذه الدورة مصممة لتزويدك بالمهارات اللازمة لإحداث تأثير ملموس.\nالأهداف الرئيسية للتعلم\nإتقان أساسيات الإدارة الرشيقة (Lean) ومنهجية سيجما ستة (Six Sigma).\nفهم وتطبيق إطار عمل DMAIC (التحديد، القياس، التحليل، التحسين، التحكم).\nاستخدام نهج قائم على البيانات لتحديد أولويات فرص التحسين.\nتطبيق أدوات Lean لتبسيط العمليات والتخلص من الهدر.\nالاستفادة من الأساليب الإحصائية لتحليل الأداء وتوجيه عملية اتخاذ القرار.\nقيادة وإدارة مشاريع Lean Six Sigma لتحقيق نتائج مستدامة.\nالاستعداد لاجتياز اختبار شهادة حزام سيجما الأخضر.\nهيكلة الدورة\nتشمل هذه الدورة التفاعلية:\nمحاضرات تفاعلية: دروس شاملة حول مبادئ Lean Six Sigma.\nتمارين عملية: أنشطة تطبيقية لتعزيز الفهم العميق للمفاهيم الأساسية.\nدراسات حالة: تطبيقات واقعية لمبادئ Lean Six Sigma.\nورش عمل: جلسات تعاونية مع مدربين متمرسين.\nلمن هذه الدورة؟\nهذه الدورة مثالية للمهنيين المسؤولين عن تحسين العمليات، بما في ذلك:\nمحترفي ضمان الجودة (QA) ومراقبة الجودة (QC).\nمديري العمليات والمهندسين.\nمديري المشاريع والمحللين التجاريين.\nالمتخصصين في سلسلة التوريد.\nالمهتمين بالتحسين المستمر.\nسواء كنت تبدأ رحلتك أو ترغب في صقل مهاراتك، فهذه الدورة مصممة لك!\nالمتطلبات المسبقة\nلا يُشترط خبرة سابقة في Lean Six Sigma. كل ما تحتاجه هو فهم أساسي للعمليات التجارية ورغبة في التعلم.\nالشهادة\nعند إتمام الدورة واجتياز اختبار الشهادة، سيحصل المشاركون على شهادة حزام سيجما الأخضر المعتمد من Udemy.\nماذا ستتعلم؟\nإتقان شامل: تعلم أكثر من 100 أداة وتقنية في Lean Six Sigma.\nإتقان الإحصاء: تجربة عملية باستخدام أدوات مثل MINITAB وExcel.\nالاستعداد للاختبار: التحضير لاجتياز اختبار شهادة LSSGB من خلال اختبارات تدريبية مكثفة.\nتطبيقات واقعية: اختبار المعرفة وتطبيقها من خلال التمارين والأنشطة.\nكن رائدًا في Lean Six Sigma\nلا تفوت الفرصة للارتقاء بمسارك المهني وأن تصبح خبيرًا في تحسين العمليات. سجل اليوم وانضم إلى صفوف محترفي حزام سيجما الأخضر المعتمدين، وساهم في تحقيق نجاح ملموس في مؤسستك!",
      "target_audience": [
        "Operation engineers curious about Operational excellence and process improvement.",
        "Management delegates curious about data driven decision making.",
        "Quality Control QC staff curious about process improvement and statistical quality control SQC..",
        "Quality Assurance QA personnel curious about process improvement.",
        "Project managers in organizations curious about six sigma methodology in project management."
      ]
    },
    {
      "title": "모두를 위한 대규모 언어 모델 LLM Part 1 - Llama 2 Fine-Tuning 해보기",
      "url": "https://www.udemy.com/course/llm-part-1-llama-2-fine-tuning/",
      "bio": "LLM(Large Language Model) 기초 개념부터 고성능 LLM인 Llama 2를 나만의 데이터셋에 파인튜닝(Fine-Tuning)까지!",
      "objectives": [
        "대규모 언어 모델 LLM(Large Language Model)의 기초 개념",
        "Llama 1 모델에 대한 자세한 설명",
        "Llama 2 모델에 대한 자세한 설명",
        "고성능 LLM인 Llama 2 모델을 내가 원하는 데이터셋에 Fine-Tuning하는 방법",
        "OpenAI API를 이용해서 GPT를 나만의 데이터셋에 Fine-Tuning하는 방법"
      ],
      "course_content": {
        "LLM(Large Language Model) 개요": [
          "LLM(Large Language Model)[대규모 언어 모델]이란",
          "기업별 대표 LLM 사용 및 비교해보기 - ChatGPT, 구글 Bard, 네이버 CLOVA X, Meta(Facebook) Llama 2",
          "LLM 용어 정리 - 토큰화(Tokenization)",
          "LLM 용어 정리 - 인컨텍스트 러닝(In-context learning)",
          "LLM 용어 정리 - 창발 능력(Emergent Abilities)",
          "LLM 용어 정리 - 온도(Temperature)"
        ],
        "Llama 1 모델 리뷰": [
          "Llama 1 모델 논문 리뷰",
          "Byte Pair Encoding (BPE) 알고리즘 개념 소개"
        ],
        "Llama 2 모델 리뷰": [
          "Llama 2 모델 논문 리뷰 - Overview",
          "Llama 2 모델 논문 리뷰 - Introduction",
          "Llama 2 모델 논문 리뷰 - Pretraining",
          "Llama 2 모델 논문 리뷰 - Fine-tuning",
          "Llama 2 모델 논문 리뷰 - Safety",
          "Llama 2 모델 논문 리뷰 - Discussion & Conclusion"
        ],
        "Alpaca 모델 리뷰": [
          "Alpaca 모델 리뷰 - Llama 1을 Fine-Tuning한 경량 오픈소스 LLM 모델"
        ],
        "Parameter-Efficient Fine-Tuning (PEFT)": [
          "Parameter-Efficient Fine-Tuning (PEFT) 개요",
          "LoRA(Low-Rank Adaptation of Large Language Models) 기법 리뷰",
          "PEFT 실습 1 - RoBERTa Token Classification 모델에 LoRA 적용하기 (BioNLP2004 데이터셋)",
          "Prefix-Tuning 기법 리뷰",
          "PEFT 실습 2 - T5 Sentiment Classification 모델에 Prefix-Tuning 적용하기",
          "P-Tuning(GPT Understands, Too) 기법 리뷰",
          "PEFT 실습 3 - RoBERTa Semantic Similarity 모델에 P-Tuning 적용하기 (MRPC 데이터셋)",
          "Prompt Tuning(The Power of Scale for Parameter-Efficient Prompt Tuning) 기법 리뷰",
          "PEFT 실습 4 - BLOOMZ Casual Language Modeling 모델에 Prompt Tuning 적용하기"
        ],
        "Llama 2 가지고 놀기 - KorQuad 데이터셋 Fine-Tuning": [
          "Llama 2 Fine-Tuning 프로젝트 개요 - KorQuad 데이터셋",
          "Llama 2 Fine-Tuning을 위한 KorQuad 데이터셋 소개",
          "Llama 2 Fine-Tuning을 위한 형태로 KorQuad 데이터셋 정제하기",
          "Llama 2 Fine-Tuning 예제 1 - Llama 2를 KorQuad 데이터셋에 맞게 Fine-Tuning 하기",
          "Llama 2 Fine-Tuning 예제 1 - KorQuad 데이터셋에 Fine-Tuning된 Llama 2 예측(Inference) 및 Ch"
        ],
        "인류 최강의 LLM - GPT 모델 리뷰": [
          "GPT-1 (2018) 모델 논문 리뷰 - Overview",
          "GPT-1 (2018) 모델 논문 리뷰 - Introduction",
          "GPT-1 (2018) 모델 논문 리뷰 - GPT가 해결한 다양한 자연어처리 Task 정리",
          "GPT-1 (2018) 모델 논문 리뷰 - Framework",
          "GPT-1 (2018) 모델 논문 리뷰 - Task-specific input transformations",
          "GPT-1 (2018) 모델 논문 리뷰 - Model specifications, Supervised fine-tuning",
          "GPT-2 (2019) 모델 논문 리뷰 - Overview",
          "GPT-2 (2019) 모델 논문 리뷰 - Introduction",
          "GPT-2 (2019) 모델 논문 리뷰 - Approach",
          "GPT-2 (2019) 모델 논문 리뷰 - Experiments",
          "GPT-2 (2019) 모델 논문 리뷰 - Generalization vs Memorization",
          "GPT-2 (2019) 모델 논문 리뷰 - Discussion & Conclusion",
          "GPT-3 (2020) 모델 논문 리뷰 - Introduction",
          "GPT-3 (2020) 모델 논문 리뷰 - Approach"
        ],
        "OpenAI API를 통한 GPT Fine-Tuning": [
          "GPT-3.5 Turbo Fine-Tuning 실습 - 기초 예제로 OpenAI API를 통한 Fine-Tuning 프로세스를 익혀보자",
          "GPT-3.5 Fine-Tuning을 위한 형태로 KorQuad 데이터셋 정제하기",
          "GPT-3.5를 KorQuad 데이터셋에 Fine-Tuning & Fine-Tuning된 GPT-3.5 예측(Inference)"
        ],
        "프롬프트 엔지니어링(Prompt Engineering)": [
          "Chain-of-Thought Prompting 기법 리뷰",
          "효율적인 프롬프트 작성을 위한 18가지 전략 (1/2)",
          "효율적인 프롬프트 작성을 위한 18가지 전략 (2/2)"
        ],
        "OpenAI API를 이용해서 임베딩(Embedding) 수행해보기": [
          "임베딩(Embedding)의 개념과 장점",
          "OpenAI API에서 제공하는 임베딩 모델들",
          "OpenAI API를 이용한 임베딩(Emedding)의 7가지 활용사례(Use cases) 살펴보기 (1/4)",
          "OpenAI API를 이용한 임베딩(Emedding)의 7가지 활용사례(Use cases) 살펴보기 (2/4)",
          "OpenAI API를 이용한 임베딩(Emedding)의 7가지 활용사례(Use cases) 살펴보기 (3/4)",
          "OpenAI API를 이용한 임베딩(Emedding)의 7가지 활용사례(Use cases) 살펴보기 (4/4)",
          "OpenAI API 임베딩 모델의 제한사항 및 잠재위험"
        ]
      },
      "requirements": [
        "Python 사용경험",
        "선수강의 [예제로 배우는 딥러닝 자연어 처리 입문 NLP with TensorFlow - RNN부터 BERT까지] 수강경험"
      ],
      "description": "LLM(Large Language Model)의 기초 개념과 고성능 LLM인 Llama 2 모델을 내가 원하는 데이터셋에 Fine-Tuning하는 방법을 학습합니다.\n\n\n이런 분들께 추천드려요!\n대규모 언어 모델 LLM(Large Language Model)의 개념과 활용법을 학습하고 싶은 분\n나만의 데이터셋에 최신 LLM을 Fine-Tuning 해보고 싶은 분\n\n\n예상 질문 Q&A\nQ. LLM(Large Language Model)이 무엇인가요?\nA. LLM은 \"Large Language Model\"의 약자로, 대규모 데이터 세트에서 훈련된 인공지능 언어 모델을 의미합니다. 이러한 모델은 자연어 처리(NLP, Natural Language Processing) 작업에 널리 사용되며, 텍스트 생성, 분류, 번역, 질문 응답, 감정 분석 등 다양한 작업을 수행할 수 있습니다.\n일반적으로 LLM은 수백만 개 이상의 매개변수(parameter)를 가지고 있으며, 이는 모델이 다양한 언어 패턴과 구조를 학습할 수 있게 해줍니다. 그 결과로, LLM은 상당히 정교하고 자연스러운 텍스트를 생성할 수 있습니다.\n예를 들어, GPT (Generative Pre-trained Transformer) 시리즈와 같은 모델은 OpenAI에 의해 개발되었고, 이는 대표적인 LLM의 한 예입니다. 이러한 모델은 웹 페이지, 책, 논문, 기사 등의 큰 텍스트 데이터셋에서 훈련되며, 그 후에는 다양한 자연어 처리 작업에 적용될 수 있습니다.\nLLM은 현재 많은 상업적 응용 프로그램에서 사용되고 있으며, 챗봇, 검색 엔진, 자동 번역 서비스, 컨텐츠 추천 등 다양한 분야에서 그 가치가 인정되고 있습니다. 하지만 이러한 모델은 여전히 고도의 전문성을 필요로 하는 작업에는 한계가 있을 수 있으며, 잘못된 정보 생성, 편향성, 이해 부족 등의 문제도 있을 수 있습니다.\n\n\nQ. 선수지식이 필요한가요?\nA. 본 [모두를 위한 대규모 언어 모델 LLM(Large Language Model) Part 1 - Llama 2 Fine-Tuning 해보기] 강의는 최신 LLM 모델의 상세한 설명과 사용법을 다루고 있습니다. 따라서 딥러닝과 자연어처리에 대한 기초지식을 가지고 있다는 가정하에 강의가 진행됩니다. 딥러닝과 자연어처리에 대한 기초지식이 부족하다면 선행 강의인 [예제로 배우는 딥러닝 자연어 처리 입문 NLP with TensorFlow - RNN부터 BERT까지] 강의를 먼저 수강하시길 바랍니다.",
      "target_audience": [
        "대규모 언어 모델 LLM(Large Language Model)의 개념과 활용법을 학습하고 싶은 분",
        "나만의 데이터셋에 최신 LLM을 Fine-Tuning 해보고 싶은 분",
        "딥러닝 연구 관련 직종으로 취업을 원하시는 분",
        "인공지능/딥러닝 관련 연구를 진행하고 싶은 분",
        "인공지능(AI) 대학원을 준비 중이신 분"
      ]
    },
    {
      "title": "사무직 직장인 맞춤 | 실전예제로 배우는 파이썬 10시간 완성 | 판다스+크롤링+머신러닝",
      "url": "https://www.udemy.com/course/6-pthfaw/",
      "bio": "실전예제로 배우는 [1.5시간 판다스 + 2.5시간 크롤링 + 6시간 머신러닝] 완성",
      "objectives": [
        "판다스 - 데이터프레임, 필터, 그룹바이, 머지, 컨캣",
        "크롤링 - Beautifulsoup, requests, selenium, HTML",
        "머신러닝 - 아래 내용들",
        "데이터전처리",
        "선형회귀",
        "오버샘플링, 언더샘플링",
        "로지스틱회귀",
        "분류모델의 성능확인",
        "서포트 벡터 머신",
        "결정트리, 앙상블 모델",
        "교차검증, 크로스밸리데이션",
        "그리드서치",
        "파이프라인"
      ],
      "course_content": {
        "판다스 시작!": [
          "판다스 소개"
        ],
        "데이터프레임 확인하기": [
          "데이터 불러오기",
          "데이터 생김새 확인하는 법",
          "컬럼, 로우, 인덱스",
          "데이터 정렬하는 방법"
        ],
        "판다스 필터": [
          "필터 만들기",
          "필터 적용하기",
          "파이썬에서 COUNTIF, SUMIF 실행하기"
        ],
        "데이터프레임 결과물 저장하기": [
          "CSV파일로 저장하기"
        ],
        "판다스 그룹바이": [
          "groupby"
        ],
        "판다스 어플라이": [
          "apply"
        ],
        "판다스 컨캣, 머지": [
          "concat",
          "merge"
        ],
        "실전연습문제!": [
          "문제 풀기 전 데이터 정리",
          "1번 문제",
          "2번 문제",
          "3번 문제",
          "4번 문제",
          "5번 문제"
        ],
        "무료강의인 '실전예제로 더하는 파이썬/판다스 플러스 알파' 듣고 오세요!": [
          "무료강의인 '실전예제로 더하는 파이썬/판다스 플러스 알파' 듣고 오세요!"
        ],
        "크롤링 시작!": [
          "인트로"
        ]
      },
      "requirements": [
        "(무료강의) 쉽고 재밌는 파이썬 기초 30분 완성 강의",
        "(무료강의) 실전예제로 더하는 파이썬/판다스 플러스 알파"
      ],
      "description": "사무직 직장인 여러분 여러분이 찾던 코딩강의 여기 있습니다.\n이해하기 쉬운 설명 + 함께 타이핑하는 실습으로 재밌게 배우고 업무시간을 줄여봐요.\n-------------------\n주위에서 코딩이 중요하다, 파이썬이 대세다 이런 말 많이 들어보셨죠? 회사에서도 자기계발로 필요하다고 교육 들으셨던 경험도 있으셨을거고요. 하지만 두꺼운 전공책처럼 이해하기 어려운 내용들만 나와서 이건 내 길이 아니다 라고 금방 그만 두셨던 경험도 분명 있으셨을거라고 생각합니다. 그래서 준비했습니다. 컴퓨터 비전공 사무직 직장인 여러분들의 입장에서 필요한 것만 쉽게 배우는 파이썬 강의입니다. 어떻게 믿냐고요? 제가 바로 그 컴퓨터 비전공 사무직 직장인입니다.\n---------------------\n무료 강의인\n-쉽고 재밌는 파이썬 기초 30분 완성\n듣고 오세요!\n---------------------\n이 강의는 총 10시간(1.5+2.5+6)으로 이루어져 있습니다!\n- 실전예제로 배우는 1.5시간 판다스\n이 강의는 엑셀과 유사한 작업을 할 수 있지만 엑셀보다 더 재밌는 판다스 강의입니다.\n판다스 여러 명령어의 개념을 배우고 직접 실습합니다.\n실제로 회사에서 사용할만한 실전문제도 5개 준비되어 있습니다.\n※ 판다스 강의 들으신 후 무료강의인 '실전예제로 더하는 파이썬/판다스 플러스 알파' 듣고 오세요!\n\n\n- 실전예제로 배우는 2.5시간 크롤링\n크롤링(스크레이핑)의 개념을 배우고 직접 실습합니다.\n\n\n- 실전예제로 배우는 6시간 머신러닝\n이 강의는 지금까지 배운 것들의 피날레가 될 강의입니다.\n머신러닝의 개념을 배우고 직접 실습합니다.\n---------------------\n필요한 것만 배우겠습니다. 여러분도 하실 수 있습니다!\n---------------------\n판다스 배우는 개념:\n데이터 확인\n컬럼, 로우, 인덱스\n정렬\n필터\n파이썬에서 COUNTIF, SUMIF 실행하기\n저장하기\ngroupby\napply\nconcat\nmerge\n\n\n크롤링 배우는 개념:\nrobots.txt\nrequests\nHTML 배우기\nBeautifulsoup (find, find_all, get_text)\nRegular Expressions (Regex) (findall)\n셀레늄 메뉴 클릭\n셀레늄 드랍박스\n셀레늄 자바스크립트\n셀레늄 팝업창\n셀레늄 키입력\n\n\n머신러닝 배우는 개념:\n머신러닝의 분류(Regression, Classification)\n머신러닝의 절차\nFeature와 Label\n샘플링(Undersampling, Oversampling)\n스케일러(Standard Scaler, MinMax Scaler)\nFitting(Underfitting, Overfitting)\nTrain Set, Test Set\nPreprocessing 컨셉(Fit, Transform)\nReplace, LabelEncoder\n원핫인코딩(get_dummies)\n원핫인코딩(Sklearn, Array, Sparse matrix)\nColumn Transformer(make_column_transformer)\nLinear Regression 개념(Loss Function, RMSE, R square)\nRegularization 모델(Lasso, Ridge, ElasticNet)\nSGD Regressor (Learning Rate, Gradient Descent)\nUndersampling 개념(Random Undersampler, Nearmiss)\nimbalanced learn\nNearmiss 실습 중 NaN 값 처리하기\nOversampling 개념(Random Oversampler, SMOTE, Boarderline Smote)\nLogistic Regression 컨셉(Sigmoid)\nOVR, Multinominal (Activation, Optimization, Probability)\nHyperparameter (solver, multi_class)\nAccuracy Score\nPrecision Score\nRecall Score\nPrecision VS Recall\nF1 Score\nSVM 개념\nSupport Vector, Hyperplane, Margin, Soft margin, C\n커널(kernel, linear, poly, rbf)\n감마(gamma)\nDecision Tree 이론\nRandom Forest Classifier 이론 (oob score)\nTrain/Test Split의 문제점\nCross-validation Score\nGridSearchCV\nHalvingGridSearchCV\nPipeline\nKmeans Clustering\n-------------------",
      "target_audience": [
        "저와 같은 사무직 직장인",
        "업무를 빠르고 효율적으로 끝내고 싶으신 분"
      ]
    },
    {
      "title": "医師が教えるR言語での医療データ分析入門 -発展編(集計)： 集計表と公的なデータから レポートを作ってみよう！",
      "url": "https://www.udemy.com/course/r-for-meds-summarytable-and-parameter-report/",
      "bio": "国立感染症研究所のデータを例にして、複雑なエクセルファイルからレポートを自分の手で1から作り上げよう！",
      "objectives": [
        "R言語を利用してデータをグループ集計する方法。",
        "R言語を利用してTIdyverseの関数のみでTable1等の論文で利用する集計表を作成する方法。",
        "R言語を利用してArsenalパッケージを利用して集計表を簡単に作成する方法。",
        "国立感染症研究所の公開データを利用して集計レポートを作成する方法。",
        "そのままではRに取り込めない、結合等が多用されたエクセルファイルをRに取り込む方法の1例。",
        "RmarkdownでGUIを利用したパラメーター設定を行う方法（Parametarized Reportの作成方法)"
      ],
      "course_content": {
        "はじめに": [
          "本コースの概要"
        ],
        "集団での集計の基本": [
          "テーブルワンとは",
          "集計をイメージで理解する",
          "プロジェクトフォルダのダウンロード",
          "データ作成",
          "数値の集計(基本:個数、和、算術平均)",
          "シンプルな書き方での演算(attach)",
          "シンプルな書き方での演算(dplyr::summarise)",
          "summariseの中で動く特別な関数",
          "全体集計の実践",
          "全体集計の実践-解説",
          "全体集計:Arsenalのイメージの解説",
          "全体集計:Arsenalの実践と日本語化1",
          "全体集計:Arsenalの実践と日本語化2",
          "全体集計:Arsenalでのコントロールを使いまわす方法。",
          "集団集計の解説1(group_byのイメージでの理解)",
          "集団集計の解説2(group_byのアニメーションでの理解)",
          "集団集計(group_byの効果の確認)",
          "集団集計(group_byで集計してみよう）",
          "変換の全体像",
          "gather <-> pivot_longer",
          "spread <-> pivot_wider",
          "arsenalでのグループ集計のイメージと復習",
          "集団集計(ArsenalのRでの実践1)",
          "集団集計(ArsenalのRでの実践2)",
          "セクションの課題",
          "課題解説 Tidyverse",
          "課題解説Arsenal",
          "おまけ:パワーポイントでの出力",
          "補足：Tidyverseでの課題解説でのsummarise_atの動作"
        ],
        "公開されているデータの分析(インポートから加工)": [
          "全体像の解説",
          "コースで利用しているプロジェクトフォルダのダウンロード",
          "データのダウンロード方法の解説",
          "データの実際のダウンロード",
          "データクリーニングの全体像",
          "ファイルの読み込み",
          "1行目、2行目の処理",
          "病名の抽出方法",
          "列名の抽出のための確認",
          "スライド列のチェック方法",
          "列のチェック1:行方向に抽出",
          "列のチェックの実践2:列方向に抽出",
          "tibble内でのmap関数の利用をイメージで",
          "列名の設定",
          "データの縦持ちへの変換のイメージ",
          "データの縦持ちへの変換",
          "データの縦持ちへの変換(詳細)",
          "週数の「総数」を分離する",
          "週数の数字化とungroup()",
          "データの完成と課題",
          "課題解答―スクリプトの関数化",
          "グループ内での前後比較:スライドでのイメージ",
          "グループ内での前後比較:Rでの実践",
          "課題回答"
        ],
        "日本地図データの表示": [
          "スクリプトファイル",
          "日本の白地図データの取得",
          "パッケージsfのインストールとデータの読み込み",
          "日本の地図の描画",
          "県別に連続値で塗り分ける"
        ],
        "公開されているデータの分析(レポート生成)": [
          "レポート作成―基本の形",
          "レポート作成―パワーポイントの出力サイズ調整",
          "レポート作成―パラメターを変更するということ",
          "レポート作成―YAMLでのパラメターの設定",
          "パラメーターの設定方法をイメージでとらえる",
          "レポートの生成の課題",
          "課題回答―ループでレポートを生成してみる",
          "GUIの設定",
          "GUIの種類",
          "補足：GUIの種類",
          "GUIで値を読み込んで利用するには",
          "最終課題:GUIレポートの作成",
          "最終課題回答:GUIレポートの作成(病名リストの作成とGUI部分の作成)",
          "最終課題回答:GUIレポートの作成(レポート本体の解説1)setupチャンクの解説",
          "最終課題回答:GUIレポートの作成(レポート本体の解説2)課題2の解説",
          "最終課題回答:GUIレポートの作成(レポート本体の解説3)"
        ],
        "まとめ": [
          "ありがとうございました"
        ]
      },
      "requirements": [
        "R言語の基礎知識",
        "R",
        "R Studio"
      ],
      "description": "注：セール対象外のコースとなるため、いつ購入いただいても価格は変わりません\n\n\n本コースでは、\n基本：\n・テーブルワン(集計表)をtidyverseの関数を利用して作成する\n・テーブルワン(集計表)をarsenalを利用して作成する\n実践：\n・国立感染症研究所が公開しているオープンデータを分析に使える形に加工する\n・国立感染症研究所のオープンデータからパワーポイント形式のレポートを作成する\n・レポート内容をGUI（マウス操作）で変更できるレポートを作成する\n・（おまけ）日本地図をggplot2で描画する\nについて学びます。\n\n\n本コースでは、基本コースで紹介しきれなかった、データをグループ化して集計するdplyrのsummarise関数の活用方法を、論文等の最初の表としてよく利用されるテーブルワン（集計表）の作成を通して学び、習得していきます。\nまた、tidyverseに含まれる関数のみでテーブルワンを作成した後は、同じことが表集計専用のパッケージ(arsenal)を利用すると簡単にできることを例示、解説し、目的に沿ったパッケージの選択の必要性について体験します。\n\n\n実践編としては、基本で学んだ内容を活用しつつ、国立感染症研究所が公開している、都道府県、感染症別の定点当たり報告数に関するエクセルデータをダウンロードし、分析に使える形へ加工することを通して、tidyverseでのデータ加工の習熟を目指します。\n\n\nさらに、加工したtidyなデータを利用して、GUI(マウス操作）で、レポートの内容を選択して出力する方法をお示しして、非Rユーザーと簡便にレポートを共有する例をお示しします。\n\n\n（おまけとして、日本地図のggplot2での描画についても、簡単に、公開データのダウンロードから、描画までを解説しています。）",
      "target_audience": [
        "R言語でデータの加工、前処理を実務で使いたい人",
        "ある程度Tidyverseを利用したデータの取得と加工について理解している人"
      ]
    },
    {
      "title": "Copilot Business Intelligence: De Analista a Estratega de IA",
      "url": "https://www.udemy.com/course/copilot-el-uso-de-iagen-en-business-intelligence/",
      "bio": "Domina la IA para Automatizar Análisis, Crear Dashboards en Power BI y Convertir Datos en Decisiones Estratégicas",
      "objectives": [
        "Transformar su rol de un técnico que responde a solicitudes a un estratega que guía la toma de decisiones con IA.",
        "Utilizar Copilot y la IA Generativa para automatizar tareas repetitivas y de bajo valor, liberando tiempo para el análisis profundo y la estrategia.",
        "Diseñar, generar y establecer metas para esquemas de KPIs complejos y modelos de datos eficientes en una fracción del tiempo.",
        "Construir dashboards interactivos en Power BI y generar narrativas persuasivas con la asistencia de la IA para comunicar hallazgos a audiencias no técnicas.",
        "Liderar proyectos de Business Intelligence impulsados por IA, validando sus habilidades a través de un proyecto final que simula un desafío de consultoría."
      ],
      "course_content": {
        "Introducción": [
          "presentación"
        ],
        "La Nueva Frontera: IA, Datos y el Futuro del Business Intelligence": [
          "La IA ya está aquí: De Netflix a tu CRM.",
          "El Terremoto en la Empresa: Por qué el 75% de las compañías de BI adoptarán IA",
          "Presentando a tu nuevo copiloto ¿Qué es la IA Generativa y por qué es un cambio?",
          "Ambiente de interacción con Copilot",
          "La información que proviene de las valoraciones"
        ],
        "Arsenal del Analista Moderno: Fundamentos de IA Generativa": [
          "El Cerebro de la Máquina: Entendiendo Redes Neuronales, GANs y Transformers",
          "El Ecosistema de IA: Conociendo a los Titanes (Copilot, ChatGPT, Gemini)"
        ],
        "Las técnicas de Ingeniería de Prompts (prompt engineering)": [
          "El Arte de la Pregunta: Introducción al Prompt Engineering.",
          "Especificidad en los prompts",
          "Contextualización en los prompts",
          "Formulación iterativa en los prompts",
          "Evitando los Peligros: Sesgos y Ética en la IA Generativa.",
          "Tu Hoja de trucos de la Ingeniería de prompts",
          "Estrategia y Diseño con Copilot"
        ],
        "El Flujo de Trabajo de BI 2.0: Estrategia y Diseño con Copilot": [
          "La Inteligencia de Negocios (Business Intelligence)",
          "Arquitectura Inteligente: Usando IA para Definir Estructuras y Modelos de Datos.",
          "El Fin del Lienzo en Blanco: Generando Esquemas de KPIs para cualquier área",
          "Matriz de indicadores clave de desempeño",
          "Más Allá de las Metas Arbitrarias: Fijando Objetivos de Indicadores con IA.",
          "Matriz de indicadores clave de desempeño con metas o benchmark",
          "Análisis y Visualización Aumentada"
        ],
        "Despedida": [
          "Despedida",
          "Consolida las ideas y el aprendizaje"
        ]
      },
      "requirements": [
        "Este no es un curso para aprender BI desde cero, sino para potenciar y acelerar las habilidades existentes con IA Generativa.",
        "Está dirigido a profesionales que ya poseen una base en análisis de datos o Business Intelligence y buscan evolucionar sus capacidades.",
        "Se necesita acceso a una computadora con conexión estable a internet."
      ],
      "description": "¿Pasas horas en tareas repetitivas de BI mientras la revolución de la IA redefine el futuro del análisis de datos? ¿Te preocupa que tus habilidades queden obsoletas? Este curso es tu respuesta. No es otro tutorial de software; es tu plan de acción para convertirte en un líder indispensable en la era de la inteligencia artificial.\nDiseñado por un Científico de Datos y consultor estratégico de BI, este curso te llevará paso a paso a través del uso práctico de Microsoft Copilot para transformar tu flujo de trabajo. Aprenderás a dialogar con tus datos, a generar esquemas de KPIs complejos en segundos, a diseñar modelos de datos eficientes y a crear visualizaciones y narrativas que impacten directamente en la estrategia de negocio. Dejarás de ser un constructor de informes para convertirte en el arquitecto de la inteligencia empresarial. Este programa te equipará con las habilidades para optimizar procesos, identificar nuevas oportunidades comerciales y comunicar tus hallazgos con una claridad y un impacto sin precedentes.\nÚnete a cientos de profesionales que ya están asegurando su futuro. Con casos prácticos del mundo real y evaluaciones basadas en escenarios que simulan desafíos empresariales reales, saldrás de este curso no solo con un certificado, sino con la confianza y las habilidades para liderar proyectos de BI impulsados por IA. Inscríbete ahora y da el salto definitivo de analista a estratega.",
      "target_audience": [
        "Profesionales de Business Intelligence: Analistas de BI, gerentes de datos y cualquier profesional que trabaje con datos y desee incorporar la IA generativa en sus procesos.",
        "Científicos de Datos: Expertos en datos que buscan expandir sus habilidades en IA y aplicar técnicas de IAGen para mejorar el análisis predictivo y descriptivo.",
        "Estrategas de Negocios: Líderes empresariales y consultores que desean comprender cómo la IA puede transformar la inteligencia de negocios y la toma de decisiones estratégicas."
      ]
    },
    {
      "title": "Machine Learning avec Python - de Zéro à Réseaux de Neurones",
      "url": "https://www.udemy.com/course/formation-machine-learning-python-reseaux-de-neurones/",
      "bio": "Apprenez le Machine Learning par la pratique en partant de Zéro. Maîtrisez le Datascience appliqué au Machine Learning.",
      "objectives": [
        "Maîtriser les concepts de base du Machine Learning",
        "Travailler sur 4+ Datasets réels",
        "Apprendre les bases du datascience",
        "Utiliser Jupyter Notebook",
        "Comprendre la régression linéaire",
        "Comprendre la classification",
        "Comprendre les réseaux de neurones",
        "Implémenter des algorithmes de Machine Learning"
      ],
      "course_content": {
        "Bienvenue": [
          "Introduction au machine learning",
          "Prérequis (Important)",
          "Structure de la formation",
          "Code sources"
        ],
        "Installation": [
          "Introduction",
          "Installation d'anaconda",
          "Installation des modules: Interface graphique",
          "Installation des modules: Invité de commandes"
        ],
        "Initiation au Datascience": [
          "Introduction",
          "Initiation au Datascience",
          "Initiation à Jupyter Notebook",
          "Initiation à Numpy - partie 1",
          "Initiation à Numpy - partie 2",
          "Initiation à Matplotlib",
          "Initiation à Pandas"
        ],
        "Le dataset": [
          "Présentation",
          "Télechargement et traitement",
          "Site de téléchargement du dataset",
          "Visualisation",
          "Analyse des caractéristiques"
        ],
        "Projet: Datascience": [
          "Présentation",
          "Site de téléchargement du dataset",
          "Implémentation: Partie 1",
          "Implémentation: Partie 2",
          "Implémentation: Partie 3"
        ],
        "### Partie 1: Régression": [
          "Introduction"
        ],
        "Régression linéaire simple": [
          "Introduction",
          "Le dataset",
          "Équation de droite",
          "Implémentation: équation de droite",
          "Droite optimale",
          "Démonstration solution optimale",
          "Coéfficients optimaux",
          "Implémentation : coéfficients coéfficients - Partie 1",
          "Implémentation : coéfficients coéfficients - Partie 2",
          "Comprendre la solution",
          "Implémentation scikit-learn"
        ],
        "Régression linéaire multiple": [
          "Introduction",
          "De régression linéaire simple à multiple",
          "Équation",
          "Implémentation: équation",
          "Visualisation",
          "Présentation du dataset",
          "Site de téléchargement du dataset",
          "Exploration - Partie 1",
          "Exploration - Partie 2",
          "Implémentation: modèle prédictif",
          "Implémentation: scikit-learn"
        ],
        "Évaluation des performances": [
          "Introduction",
          "Évaluation des performances",
          "RMSE",
          "R_squared",
          "Dataset d'entraînement et de test",
          "Évaluation des performances"
        ],
        "### Partie 2: Classification": [
          "Introduction"
        ]
      },
      "requirements": [
        "Vous aurez besoin d'un ordinateur avec Windows, MacOS ou Linux.",
        "Avoir des connaissances de base en Python nécessaire!",
        "Avoir des connaissances en Mathématique niveaux lycée",
        "Être motivé à apprendre :)"
      ],
      "description": "Apprenez le Machine Learning de manière pratique et développez votre premier réseaux de neurones!\nCette formation est l'une des formations la plus élaborée sur Udemy qui va vous permettre d'apprendre le Machine Learning très facilement! Le machine learning a gagné en popularité ces 5 dernières années et permet de développer des applications qui n'étaient pas possible au préalable. Que vous soyez débutant, ou que vous souhaitez vous perfectionner  en machine learning, Cette formation va vous permettre d'acquérir les concepts fondamentaux qui vont vous permettre de développez des algorithmes de machine learning.\nNous allons commencer à apprendre les concepts de base qui vont vous permettre de bien débuter avec le machine learning.\nVous serez capable de comprendre le fonctionnement et l'implémentation d'algorithmes de machine learning à partir de zéro mais aussi avec la librairie scikit-learn.\nLa meilleure manière d'apprendre est par la pratique! Vous allez trouver dans cette formation plusieurs projets pratiques pour complémenter votre apprentissage.\nAvec cette formation, vous aurez accès à 80+ vidéos sur le machine learning, le code source de chaque concept abordé et des projets utilisant des datasets réels.\n\n\nNous allons couvrir des concepts comme:\nInstallation des outils nécéssaires\nInitiation au datascience\nLa régression linéaire simple\nLa régression linéaire multiple\nEvaluation de modèles de régression\nLa régression logistique\nLes réseaux de neurones\nEvaluation des modèles de classification\nTravailler sur 4+ datasets réels\net bien d'autres\nCes concepts vous seront présentés de manière simple et concise. Vous aurez des bases solides pour par la suite vous perfectionner et aller encore plus loin vers des domaines comme le deep learning (apprentissage profond).\nInscrivez-vous aujourdhui et découvrez les merveilles du Machine Learning en développant des compétences solides de manière pratique et amusante.",
      "target_audience": [
        "Vous débutez en Machine Learning",
        "Vous connaissez le Datascience et souhaitez apprendre le Machine Learning",
        "Vous connaissez Python et souhaitez apprendre le Machine Learning",
        "Vous avez les bases mais souhaitez vous perfectionner",
        "Vous souhaitez apprendre à utiliser scikit-learn"
      ]
    },
    {
      "title": "Imagens Avançadas com IA Generativa e Stable Diffusion",
      "url": "https://www.udemy.com/course/imagens-avancadas-com-ia-generativa-stable-diffusion/",
      "bio": "Dominando a Criação de Imagens Profissionais: Explore projetos reais com Inteligência Artificial na Interface Gráfica",
      "objectives": [
        "Gerar imagens complexas utilizando somente a interface gráfica do Stable Diffusion",
        "Configurar os parâmetros do Stable Diffusion para obter diferentes resultados",
        "Criar imagens utilizando modelos disponibilizados pela comunidade OpenSource",
        "Criar capas para livros",
        "Gerar imagens com alto grau de realismo",
        "Criar personagens envolventes",
        "Adicionar, editar ou excluir elementos de imagens existentes",
        "Transformar imagens simples em complexas utilizando apenas rabiscos",
        "Criar logos para empresas, bem como adesivos e estampas para camisetas",
        "Utilizar IA generativa para uso criativo, gerando ilusões a partir de logos ou outros tipos de imagens"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre Visão Computacional",
          "Recursos para download",
          "Introdução ao Stable Diffusion",
          "Sagemaker Studio Lab e ngrok",
          "Preparação da interface",
          "Recomendações erros comuns",
          "Geração das primeiras imagens",
          "Parâmetros",
          "Prompts negativos",
          "Resolução e proporção das imagens",
          "Gerador de prompts com ChatGPT",
          "Geração de imagens profissionais",
          "Vieses dos modelos"
        ],
        "Capas para livros": [
          "Introdução",
          "Prompt inicial",
          "Palavras-chave",
          "Seletor de estilos",
          "Variações",
          "Upscale e salvar imagem",
          "Finalização da capa",
          "Livro de ficção científica 1",
          "Livro de ficção científica 2",
          "Livro de ficção científica 3",
          "Livro de fantasia épica",
          "Livro de não ficção",
          "Capas na horizontal",
          "Criação de cenários",
          "Aviso sobre alteração de link",
          "Imagens com textos",
          "Código no Google Colab"
        ],
        "Imagens realistas": [
          "Primeiras imagens",
          "Fotografias",
          "Modelos realistas 1",
          "Modelos realistas 2",
          "Melhorando rostos, mãos e olhos",
          "Estilos de fotografia",
          "Poses e ações",
          "Enquadramentos",
          "Fundo ou ambiente",
          "Iluminação",
          "Ângulos",
          "Configurações da câmera",
          "Filtros e efeitos",
          "Prompts completos",
          "Upscale para fotos realistas",
          "Poses com controlnet"
        ],
        "Criação de personagens": [
          "Panda astronauta - introdução",
          "Panda astronauta - primeiros testes",
          "Panda astronauta - estilos",
          "Panda astronauta - ação e local",
          "Panda astronauta - mais estilos",
          "A Feiticeira",
          "O Mago",
          "Outros modelos 1",
          "Outros modelos 2",
          "Rostos consistentes com Reactor",
          "Variações de imagens"
        ],
        "Edição de imagens": [
          "Inpainting - introdução",
          "Inpainting na prática",
          "Adicionar, modificar e excluir objetos",
          "Edição de imagens realistas",
          "Outpainting",
          "IP Adapter"
        ],
        "Imagens simples em complexas": [
          "Inpainting sketch",
          "Extensão Photopea",
          "Geração de cenários",
          "Scribble e Lineart - intuição",
          "Rascunhos em imagens complexas",
          "Imagens de arquitetura",
          "Rascunhos em personagens",
          "Rascunhos em produtos",
          "Imagens com rabiscos e linhas",
          "Maior grau de realismo",
          "Detecção de bordas"
        ],
        "Artes vetoriais e logos": [
          "Introdução",
          "Logo para cafeteria 1",
          "Logo para cafeteria 2",
          "Outras logos e textos",
          "Pós-processamento do logo",
          "Adesivos/stickers",
          "Arte para camisetas"
        ],
        "Uso criativo": [
          "Introdução",
          "Uso criativo",
          "Ilusões com logos",
          "Outras ilusões"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Nenhum pré-requisito, pois é utilizada a interface gráfica para geração das imagens. Está disponível um código pronto para iniciar a interface"
      ],
      "description": "Este curso mergulha fundo no fascinante mundo da inteligência artificial generativa, com foco especial na poderosa técnica conhecida como Stable Diffusion utilizando interface gráfica. Aprenda a dominar essa tecnologia revolucionária para criar imagens impressionantes, desde capas de livros até personagens encantadores e muito mais. Com uma abordagem prática e orientada para resultados, você será guiado por uma jornada de aprendizado que abrange desde os conceitos básicos até técnicas avançadas de manipulação de imagens. Confira abaixo o que você aprenderá:\n\n\n1. Fundamentos da IA Generativa e Stable Diffusion\n- Introdução abrangente ao Stable Diffusion e sua aplicação em imagens geradas por IA.\n- Exploração do SageMaker Studio Lab e ngrok para configuração eficiente do ambiente de desenvolvimento.\n- Preparação da interface e solução de erros comuns para um fluxo de trabalho suave.\n- Utilização de parâmetros e prompts negativos para refinar a geração de imagens.\n- Entendimento do viés dos modelos e sua influência na geração de conteúdo.\n\n2. Design de Capas de Livros\n- Guia passo a passo para criar capas de livros atrativas usando IA generativa.\n- Seleção e manipulação de estilos através de prompts iniciais e palavras-chave.\n- Exploração de variações e upscale para garantir qualidade de impressão.\n- Utilização de técnicas de pós-processamento, como adição de textos sobre a arte final.\n- Personalização de capas para diferentes gêneros literários, desde ficção científica a fantasia épica.\n- Geração de imagens com textos legíveis e de cenários criativos e diversos.\n- Criação de outros tipos de capas em diferentes tamanhos, que podem ser usados por exemplo para thumbnails de vídeos ou capas de artigos.\n\n3. Criação de Imagens Realistas\n- Técnicas avançadas para gerar imagens realistas.\n- Aperfeiçoamento de detalhes como rostos, mãos e olhos para um aspecto mais autêntico.\n- Exploração de estilos de fotografia, poses, ângulos, enquadramentos e iluminação para criar composições visualmente cativantes.\n- Utilização de prompts completos e upscale para obter imagens realistas de alta qualidade.\n- Personalização de poses com ControlNet para maior controle sobre a imagem final.\n\n\n4. Desenvolvimento de Personagens:\n- Criação de personagens únicos, desde pandas astronautas até feiticeiras e magos.\n- Experimentação com diferentes estilos e ações para dar vida aos personagens.\n- Utilização do ReActor para garantir rostos consistentes e variações de imagens.\n- Exploração de técnicas avançadas de edição para refinamento e personalização.\n\n\n5. Edição Avançada de Imagens\n- Introdução ao inpainting e técnicas de edição avançada.\n- Adição, modificação e exclusão de qualquer objeto na imagem para obter uma manipulação precisa.\n- Exploração do outpainting e do IP Adapter para expandir as possibilidades criativas e realizar mudanças estruturais complexas de maneira prática.\n\n\n6. Transformando imagens simples em complexas\n- Técnicas para dar vida a rabiscos e ilustrações simples, transformando-os em instantes em arte complexas e refinadas.\n- Utilização de abordagem imagem-para-imagem para aumentar o grau de realismo e o nível de detalhes em qualquer imagem já existente.\n- Exploração do uso de modelos ControlNet para transformar o estilo da imagem.\n\n\n7. Criação de Logos e imagens vetorizadas\n- Criação de logos profissionais para qualquer tipo de empresa, entidade ou marca.\n- Aperfeiçoamento da logo com o uso de técnicas de pós-processamento, deixando-a pronta para uso profissional.\n- Exploração de técnicas para criar adesivos, estampa para camisetas e outras formas de material promocional.\n\n\n8. Uso Criativo de Imagens\n- Técnica para obter controle total sobre a composição da imagem.\n- Aplicação criativa de imagens geradas em diversas áreas, incluindo ilusões a partir de logos, formas geométricas, textos e outras formas de expressão artística.\n\n\nAo concluir este curso, você estará equipado com as habilidades necessárias para utilizar a IA generativa e Stable Diffusion em uma variedade de contextos criativos, desde design de capas de livros até criação de personagens e ilustrações personalizadas. Curso totalmente prático utilizando interface gráfica para geração das imagens!",
      "target_audience": [
        "Designers Gráficos: Profissionais que desejam expandir suas habilidades de design usando técnicas avançadas de inteligência artificial generativa para criar imagens únicas e envolventes",
        "Artistas Visuais: Pessoas com interesse em explorar novas formas de expressão artística e expandir seu repertório criativo através do uso de tecnologias emergentes.",
        "Desenvolvedores de Jogos: Indivíduos envolvidos na criação de jogos eletrônicos que buscam integrar elementos visuais originais e cativantes em seus projetos.",
        "Profissionais de Marketing e Publicidade: Especialistas em marketing que buscam explorar novas formas de criar conteúdo visual atraente e envolvente para campanhas publicitárias e de branding.",
        "Entusiastas de Inteligência Artificial: Indivíduos interessados no cruzamento entre arte e tecnologia, que desejam explorar as possibilidades criativas oferecidas pela inteligência artificial generativa e Stable Diffusion."
      ]
    },
    {
      "title": "Formación en ciencia de datos con R",
      "url": "https://www.udemy.com/course/formacion-en-ciencia-de-datos-con-r/",
      "bio": "Ciencia de datos con R y Tidyverse",
      "objectives": [
        "Aprenderás los fundamentos de la programación con el lenguaje R con un curso 100% práctico.",
        "Aprenderás los fundamentos de las Ciencias de los Datos con un curso fácil de seguir y práctico.",
        "Aprenderás a ejecutar tareas del Ciclo de la Ciencia de Datos con R como Importar, Ordenar, Transformar y Visualizar datos, calcular métricas y sacar insights.",
        "Aprenderás las tareas más comúnes de la Ciencia de Datos como trabajar con múltiples bases de datos, múltiples formatos de datos, etc.",
        "Aprenderás los pasos que debes seguir para contestar a las principales preguntas de Ciencia de Datos, a través de la resolución de ejemplos 100% prácticos"
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Comandos básicos de R",
          "El ciclo de la ciencia de datos - Importar datos",
          "El ciclo de la ciencia de datos - Ordenar datos",
          "El ciclo de la ciencia de datos - Transformar datos"
        ],
        "Entrecruce de bases de datos distintas": [
          "Entrecruce de bases de datos",
          "Ejercício Práctico - Importando datos",
          "Ejercício Práctico - Join entre tablas",
          "Ejercício Práctico - Join en Rstudio",
          "Ejercício Práctico - Datos reales"
        ],
        "Explorando datos reales": [
          "Entrecruce de datos",
          "Calculo de metricas",
          "Visualización de datos con ggplot2 - Scatterplot",
          "Visualización de datos con ggplot2 - Barplot",
          "Mejorando la visualización: cambio de tema, título, ejes."
        ],
        "Exportando gráficas": [
          "gráficas en alta resolución con PNG"
        ],
        "Clase Extra": [
          "Clase Extra"
        ]
      },
      "requirements": [
        "Curso para principiantes en el lenguaje R y en Ciencia de Datos",
        "Curso para personas que ya tuvieron algún contacto con el lenguaje R y con la Ciencia de datos, pero que aún necesitan practicar"
      ],
      "description": "El profesional de Ciencia de Datos se ha convertido en uno de los perfiles más buscados por empresas de tecnología. Y el lenguaje R es una de las más importantes en este mundo de la ciencia de datos.\n\n\nY la única manera de aprender a hacer ciencia de datos es haciendo ciencia de datos. La práctica lleva al conocimiento.\n\n\nEn este curso vas a aprender que es el ciclo de la ciencia de datos y como utilizar R para analizar datos.\n\n\nVas a aprender a importar y ordenar bases de datos.\nVas a aprender como cruzar informaciones de bases de datos distintas\nVas a aprender como transfrmar datos y calcular métricas\nVas a aprender como crear visualizaciones de las métricas y como personalizar los gráficos\nVas a aprender a exportar tus gráficos a figuras de alta resolución en formato PNG\n\n\nTodo esto de manera 100% práctica, utilizando bases de datos reales\n\n\nDurante el curso vamos a analizar datos de COVID19 con origen en diferentes fuentes de datos, vamos a calcular metricas y dibujarlas para entender que informaciones las bases de datos contienen. Estas informaciones son útiles a la hora de tomar decisiones.\n\n\nUtilizaremos el Rstudio y el Rstudio cloud. Asumimos que el alumno conoce estas herramientas y si no conoce indicamos que pueda asistir nuestro curso anterior \"Ciencia de datos para todos los publicos\".",
      "target_audience": [
        "Personas con interés por Excel, SPSS, Power BI, Tableau u otras tecnologícas para análisis de datos",
        "Personas con interés por Machine Learning o Inteligencia Artificial",
        "Personas con interés por Ciencia de datos",
        "Personas con interés por Lenguajes de Programación",
        "Personas con interés por Bases de Datos",
        "Personas con interés por Visualización de Datos"
      ]
    },
    {
      "title": "Inglês e Inteligência Artificial: Pronúncia Perfeita",
      "url": "https://www.udemy.com/course/ingles-inteligencia-artificial-pronuncia-perfeita/",
      "bio": "Aprenda a pronúncia e entonação correta do inglês aplicada na terminologia da Inteligência Artificial!",
      "objectives": [
        "Entenda a pronúncia básica do inglês, desde o segredo das 20 vogais até os 5 fonemas mais essenciais do inglês (\"The Magic Five\")",
        "Aprenda como pronunciar corretamente as principais terminologias da Inteligência Artificial em inglês",
        "Aprenda conceitos teóricos sobre as principais áreas da Inteligência Artificial, como: sistemas especialistas, aquisição de conhecimento, buscas, algoritmos genéticos, lógica nebulosa, raciocínio baseado em casos, sistemas multiagente, aprendizagem de máquina, redes neurais, processamento de linguagem natural, visão computacional e robótica",
        "Descubra truques e exercícios para treinar sua pronúncia de inglês no dia-a-dia"
      ],
      "course_content": {
        "Introdução": [
          "Boas vindas - Jones",
          "Boas vindas - Rebeca",
          "Mais sobre Inteligência Artificial"
        ],
        "As 20 vogais": [
          "Introdução aos 20 sons das vogais",
          "O som secreto do schwa - parte 1",
          "O som secreto do schwa - parte 2",
          "A vogal \"A\"",
          "A vogal \"E\"",
          "A vogal \"I\"",
          "A vogal \"O\"",
          "A vogal \"U\"",
          "Semi-vogal \"Y\"",
          "Combinações de vogais com \"W\"",
          "Resumo do som das vogais"
        ],
        "The Magic Five": [
          "Palavras terminadas com consoante",
          "Palavras terminadas com \"E\"",
          "Palavras terminadas com \"M\" e \"N\"",
          "Palavras terminadas com \"L\" e \"LE\"",
          "Palavras terminadas com \"TH\""
        ],
        "Pronúncia da terminologia da inteligência artificial": [
          "Termos gerais - teoria",
          "Termos gerais - pronúncia",
          "Sistemas especialistas - teoria",
          "Sistemas especialistas - pronúncia",
          "Aquisição de conhecimento - teoria",
          "Aquisição de conhecimento - pronúncia",
          "Buscas - teoria",
          "Buscas - pronúncia",
          "Algoritmos genéticos - teoria",
          "Algoritmos genéticos - pronúncia",
          "Lógica nebulosa - teoria",
          "Lógica nebulosa - pronúncia",
          "Raciocínio baseado em casos - teoria",
          "Raciocínio baseado em casos - pronúncia",
          "Sistemas multiagente - teoria",
          "Sistemas multiagente - pronúncia",
          "Aprendizagem de máquina - teoria",
          "Aprendizagem de máquina - pronúncia",
          "Naive bayes - teoria",
          "Naive bayes - pronúncia",
          "Árvores de decisão - teoria",
          "Árvores de decisão - pronúncia",
          "Aprendizagem baseada em instâncias - teoria",
          "Aprendizagem baseada em instâncias - pronúncia",
          "Regressão logística - teoria",
          "Regressão logística - pronúncia",
          "Máquinas de vetores de suporte - teoria",
          "Máquinas de vetores de suporte - pronúncia",
          "Redes neurais artificiais - teoria",
          "Redes neurais artificiais - pronúncia",
          "Aprendizagem de máquina - outros termos teoria",
          "Aprendizagem de máquina - outros termos pronúncia",
          "Processamento de linguagem natural - teoria",
          "Processamento de linguagem natural - pronúncia",
          "Visão computacional - teoria",
          "Visão computacional - pronúncia",
          "Robótica - teoria",
          "Robótica - pronúncia",
          "Outros termos - teoria",
          "Outros termos - pronúncia",
          "Profissões IA - teoria",
          "Profissões IA - pronúncia",
          "Ferramentas para IA - teoria",
          "Ferramentas para IA - pronúncia",
          "Aula bônus!"
        ]
      },
      "requirements": [
        "Para um melhor aproveitamento do curso, é interessante que você já conheça um pouco sobre Inteligência Artificial. Porém, você consegue acompanhar tranquilamente sem este conhecimento",
        "Não são necessários conhecimentos prévios de inglês"
      ],
      "description": "Artificial intelligence, breadth-first search, heuristics, fuzzyfication, supervised learning, naïve bayes, random forest, nearest neighbors, hyperbolic tangent, neural networks, backpropagation, gradient descent, hidden layers e vários outros termos técnicos são difíceis de pronunciar? Você sabia que atualmente a maioria dos empregos ligados à Inteligência Artificial requerem o inglês? E isso acontece pelo fato de que as grandes empresas do mercado estão no exterior; e mesmo empresas do Brasil podem ter contato com equipes estrangeiras. Por esse motivo é muito importante saber inglês nesta área, principalmente como pronunciar corretamente as terminologias técnicas.\nE para levar você até esta área, neste curso você aprenderá a pronúncia básica do inglês juntamente com a pronúncia da terminologia das principais áreas da Inteligência Artificial! Você aprenderá a teoria sobre os conceitos de cada área e logo depois como pronunciar as palavras de forma correta! O curso é dividido em duas partes básicas:\nPronúncia básica do inglês\nPronúncia dos termos de IA em inglês\n\n\nVocê aprenderá a pronúncia correta das principais áreas, como por exemplo:\nSistemas especialistas (Expert Systems)\nAquisição de conhecimento (Knowledge Aquisition)\nBuscas (Search)\nAlgoritmos genéticos (Genetic Algorithms)\nLógica nebulosa (Fuzzy Logic)\nRaciocínio baseado em casos (Case Base Reasoning)\nSistemas multiagente (Multi-agent Systems)\nAprendizagem de máquina (Machine Learning) (naïve bayes, árvores de decisão, instâncias, regressão logística, máquinas de vetores de suporte e redes neurais artificiais)\nProcessamento de linguagem natural (Natural Language Processing)\nVisão computacional (Computer Vision)\nRobótica (Robotics)\nProfissões (Professions)\nFerramentas para IA (Tools for AI)\nEste curso pode ser categorizado para todos os níveis, ou seja, tanto para pessoas que estão iniciando ou são avançadas tanto na área de Inglês quanto na área de Inteligência Artificial!\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas que querem aprender como pronunciar corretamente as terminologias da Inteligência Artificial",
        "Pessoas que querem se destacar no mercado conquistando um inglês de alta qualidade",
        "Pessoas interessadas em Inteligência Artificial",
        "Pessoas que querem melhorar sua pronúncia em inglês"
      ]
    },
    {
      "title": "데이터분석 준전문가(ADsP) 자격증 합격하기",
      "url": "https://www.udemy.com/course/adsp-cal/",
      "bio": "ADsP 데이터분석 준전문가 자격증 대비를 위한 시험 준비 코스",
      "objectives": [
        "ADsP 데이터분석 준전문가 자격증 취득 관련 모든 내용을 학습합니다."
      ],
      "course_content": {
        "[HD]데이터분석 준전문가(ADsP) 자격증 따기 - 1과목 데이터 이해(2020)": [
          "ADSP자격증 1강목록 및 강의 계획",
          "ADSP자격증 2강Ⅰ-1-1 데이터의 개념",
          "ADSP자격증 3강Ⅰ-1-1 데이터의 개념2",
          "ADSP자격증 4강Ⅰ-1-2 데이터베이스의 개념",
          "ADSP자격증 5강Ⅰ-1-3 데이터베이스의 활용",
          "ADSP자격증 6강Ⅰ-1-3 데이터베이스의 활용2",
          "ADSP자격증 7강Ⅰ-2-1 빅데이터의 개념",
          "ADSP자격증 8강Ⅰ-2-1 빅데이터의 개념2",
          "ADSP자격증 9강Ⅰ-2-2 비즈니스 모델",
          "ADSP자격증 10강Ⅰ-2-3 빅데이터의 문제점과 해결방안",
          "ADSP자격증 11강Ⅰ-3-1 데이터 사이언스란?",
          "ADSP자격증 12강Ⅰ-4-1 DBMS와 SQL",
          "ADSP자격증 13강Ⅰ-4-2 데이터에 관련된 기술",
          "ADSP자격증 14강Ⅰ-4-3 빅데이터 분석기술",
          "ADSP자격증 15강Ⅰ-4-4 데이터 관한 기타 내용"
        ],
        "[HD]데이터분석 준전문가(ADsP) 자격증 따기 - 2과목 데이터 분석 기획(2020)": [
          "ADSP자격증 1강Ⅱ-1-1 데이터 분석의 계획 수립 방향성",
          "ADSP자격증 2강Ⅱ-1-2 분석 방법론",
          "ADSP자격증 3강Ⅱ-1-2 분석 방법론2",
          "ADSP자격증 4강Ⅱ-1-2 분석 방법론3",
          "ADSP자격증 5강Ⅱ-1-2 분석 방법론4",
          "ADSP자격증 6강Ⅱ-1-3 분석 과제 발굴",
          "ADSP자격증 7강Ⅱ-1-3 분석 과제 발굴2",
          "ADSP자격증 8강Ⅱ-1-3 분석 과제 발굴3",
          "ADSP자격증 9강Ⅱ-1-3 분석 과제 발굴4",
          "ADSP자격증 10강Ⅱ-1-4 프로젝트 관리방안",
          "ADSP자격증 11강Ⅱ-2-1 마스터 플랜 수립 프레임 워크",
          "ADSP자격증 12강Ⅱ-2-1 마스터 플랜 수립 프레임 워크2",
          "ADSP자격증 13강Ⅱ-2-2 분석 거버넌스 체계 수립",
          "ADSP자격증 14강Ⅱ-2-2 분석 거버넌스 체계 수립2",
          "ADSP자격증 15강Ⅱ-2-2 분석 거버넌스 체계 수립3",
          "ADSP자격증 16강Ⅱ-2-2 분석 거버넌스 체계 수립4",
          "ADSP자격증 17강Ⅱ-2-2 분석 거버넌스 체계 수립5"
        ],
        "[HD]데이터분석 준전문가(ADsP) 자격증 따기 - 3과목 데이터 분석1 (통계이론 Part.1) (2020)": [
          "ADSP 자격증 Ⅰ-1-1 통계학이란?",
          "ADSP 자격증 Ⅰ-1-2 모수통계학과 비모수 통계학",
          "ADSP 자격증 Ⅰ-2-1 자료분석",
          "ADSP 자격증 Ⅰ-2-2 기술통계량을 이용한 자료분석",
          "ADSP 자격증 Ⅰ-3-1 경우의 수",
          "ADSP 자격증 Ⅰ-3-1 경우의 수2",
          "ADSP 자격증 Ⅰ-3-2 확률이란?",
          "ADSP 자격증 Ⅰ-3-3 조건부확률과 독립사건",
          "ADSP 자격증 Ⅰ-3-4 베이즈 정리",
          "ADSP 자격증 Ⅰ-3-5 사건의 독립성",
          "ADSP 자격증 Ⅰ-4-1 확률분포란?",
          "ADSP 자격증 Ⅰ-4-2 이산확률분포란?",
          "ADSP 자격증 Ⅰ-4-3 이항분포",
          "ADSP 자격증 Ⅰ-4-4 포아송분포",
          "ADSP 자격증 Ⅰ-5-1 연속확률분포",
          "ADSP 자격증 Ⅰ-5-2 정규분포",
          "ADSP 자격증 Ⅰ-5-3 표준정규분포",
          "ADSP 자격증 Ⅰ-5-4 정규근사",
          "ADSP 자격증 Ⅰ-5-5 지수분포"
        ],
        "[HD]데이터분석 준전문가(ADsP) 자격증 따기 - 3과목 데이터 분석1 (통계이론 Part.2) (2020)": [
          "ADSP 자격증 Ⅰ-6-1 결합확률분포",
          "ADSP 자격증 Ⅰ-6-1 결합확률분포2",
          "ADSP 자격증 Ⅰ-6-2 확률변수의 독립성",
          "ADSP 자격증 Ⅰ-6-2 확률변수의 독립성2",
          "ADSP 자격증 Ⅰ-7-1 표집분포",
          "ADSP 자격증 Ⅰ-7-1 표집분포2",
          "ADSP 자격증 Ⅰ-7-2 모집단 추정(모평균)",
          "ADSP 자격증 Ⅰ-7-2 모집단 추정(모평균2)",
          "ADSP 자격증 Ⅰ-7-3 모집단 추정2(모비율)",
          "ADSP 자격증 Ⅰ-8-1 신뢰구간과 가설검정",
          "ADSP 자격증 Ⅰ-8-2 두 집단에 대한 추론",
          "ADSP 자격증 Ⅰ-8-2 두 집단에 대한 추론2",
          "ADSP 자격증 Ⅰ-9-1 모분산추정",
          "ADSP 자격증 Ⅰ-9-1 두 집단의 모분산 추정"
        ],
        "[HD]데이터분석 준전문가(ADsP) 자격증 따기 - 3과목 데이터 분석2 (R프로그래밍) (2020) (完)": [
          "R프로그래밍",
          "데이터마이닝",
          "분석방법1 : 성과분석",
          "분석방법2 : 로지스틱 회귀법",
          "분석방법3 : 의사결정나무",
          "분석방법4 : 앙상블",
          "분석방법5 : 인공지능",
          "분석방법6 : 군집분석"
        ]
      },
      "requirements": [
        "ADsP 자격증 취득을 희망하시는 모든 분들에게 강의를 추천 드립니다."
      ],
      "description": "데이터의 중요성이 더더욱 강조되는 시대입니다. 이런 시대인 만큼, 데이터 분석 및 데이터 리터러시 역량을 완벽하게 갖춘 인재로 스스로를 준비해가는 게 너무 중요하다고 생각됩니다. 그래서, ADsP 데이터분석 준전문가 자격증같은 선택이 아니라 필수인 시대입니다.\nADsP 데이터분석 준전문가 자격증은 데이터의 중요성이 더욱 강조되는 요즘같은 시대에 더 빛을 발휘할 수 있는 자격증입니다. 본 강의는 ADsP 자격증 취득을 위한 시험을 준비하면서 공부해야 하는 모든 내용들을 코스 하나로 다 담아봤습니다.\n본 강의는 다음의 내용들로 구성되어 있습니다.\n\n\nADSP자격증 1강목록 및 강의 계획\nADSP자격증 2강Ⅰ-1-1 데이터의 개념\nADSP자격증 4강Ⅰ-1-2 데이터베이스의 개념\nADSP자격증 5강Ⅰ-1-3 데이터베이스의 활용\nADSP자격증 7강Ⅰ-2-1 빅데이터의 개념\nADSP자격증 9강Ⅰ-2-2 비즈니스 모델\nADSP자격증 10강Ⅰ-2-3 빅데이터의 문제점과 해결방안\nADSP자격증 11강Ⅰ-3-1 데이터 사이언스란?\nADSP자격증 12강Ⅰ-4-1 DBMS와 SQL\nADSP자격증 13강Ⅰ-4-2 데이터에 관련된 기술\nADSP자격증 14강Ⅰ-4-3 빅데이터 분석기술\nADSP자격증 15강Ⅰ-4-4 데이터 관한 기타 내용\nADSP자격증 1강Ⅱ-1-1 데이터 분석의 계획 수립 방향성\nADSP자격증 2강Ⅱ-1-2 분석 방법론\nADSP자격증 6강Ⅱ-1-3 분석 과제 발굴\nADSP자격증 10강Ⅱ-1-4 프로젝트 관리방안\nADSP자격증 11강Ⅱ-2-1 마스터 플랜 수립 프레임 워크\nADSP자격증 13강Ⅱ-2-2 분석 거버넌스 체계 수립\n\n\nADSP 자격증 Ⅰ-1-1 통계학이란?\nADSP 자격증 Ⅰ-1-2 모수통계학과 비모수 통계학\nADSP 자격증 Ⅰ-2-1 자료분석\nADSP 자격증 Ⅰ-2-2 기술통계량을 이용한 자료분석\nADSP 자격증 Ⅰ-3-1 경우의 수\nADSP 자격증 Ⅰ-3-2 확률이란?\nADSP 자격증 Ⅰ-3-3 조건부확률과 독립사건\nADSP 자격증 Ⅰ-3-4 베이즈 정리\nADSP 자격증 Ⅰ-3-5 사건의 독립성\nADSP 자격증 Ⅰ-4-1 확률분포란?\nADSP 자격증 Ⅰ-4-2 이산확률분포란?\nADSP 자격증 Ⅰ-4-3 이항분포\nADSP 자격증 Ⅰ-4-4 포아송분포\nADSP 자격증 Ⅰ-5-1 연속확률분포\nADSP 자격증 Ⅰ-5-2 정규분포\nADSP 자격증 Ⅰ-5-3 표준정규분포\nADSP 자격증 Ⅰ-5-4 정규근사\nADSP 자격증 Ⅰ-5-5 지수분포\n\n\nADSP 자격증 Ⅰ-6-1 결합확률분포\nADSP 자격증 Ⅰ-6-2 확률변수의 독립성\nADSP 자격증 Ⅰ-7-1 표집분포\nADSP 자격증 Ⅰ-7-2 모집단 추정(모평균)\nADSP 자격증 Ⅰ-7-3 모집단 추정2(모비율)\nADSP 자격증 Ⅰ-8-1 신뢰구간과 가설검정\nADSP 자격증 Ⅰ-8-2 두 집단에 대한 추론\nADSP 자격증 Ⅰ-9-1 모분산추정\nADSP 자격증 Ⅰ-9-1 두 집단의 모분산 추정\n\n\nR프로그래밍\n데이터마이닝\n분석방법1 : 성과분석\n분석방법2 : 로지스틱 회귀법\n분석방법3 : 의사결정나무\n분석방법4 : 앙상블\n분석방법5 : 인공지능\n분석방법6 : 군집분석",
      "target_audience": [
        "ADSP 자격증 준비하는 사람 누구나",
        "데이터분석 공부를 희망하는 사람 누구나"
      ]
    },
    {
      "title": "Qlik Sense Cloud für Business Intelligence und Data Science",
      "url": "https://www.udemy.com/course/qlik-sense-cloud-fur-business-intelligence-und-data-science/",
      "bio": "Werden auch Sie zum Qlik Sense Entwickler. Alles was Sie brauchen, um professionelle Dashboards zu erstellen.",
      "objectives": [
        "Erstellung von professionellen Dashboard",
        "Verarbeitung von Daten mit Hilfe von Qlik Sense",
        "Praktischer Einsatz von Qlik Sense in der verschiedenen Unternehmensbereichen",
        "Zielgruppen gerechte Visualisierung",
        "Erstellung von Karten in Qlik Sense",
        "Verwendung der Qlik Cloud",
        "Implementierung von professionellen Visualisierungen"
      ],
      "course_content": {
        "Einführung": [
          "Herzlich Willkommen",
          "Was ist Qlik und wie benutze ich Qlik",
          "Qlik Help und Kaggle"
        ],
        "Erstes Dashboard": [
          "Einführung in das Kapitel",
          "Eine App erstellen und erste Daten einlesen",
          "Eine erste Tabelle erstellen",
          "Balkendiagramm, Kreisdiagramm und Liniendiagramm erstellen",
          "KPIs und Set Analysis",
          "Datenaktualisierung für die Karte",
          "Eine Karte erstellen",
          "Buttons und Navigation erstellen",
          "Text und Pivot-Tabelle erstellen",
          "Kapitelzusammenfassung",
          "Abschlussquiz"
        ],
        "Praktisches Beispiel \"Dashboard Autoreinigung\"": [
          "Einführung in die Daten",
          "App erstellen und einlesen der Daten",
          "Startseite erstellen",
          "Arbeitsblätter und Navigation erstellen",
          "Datentransformation im Qlik Dateneditor",
          "Überfällige Reinigungen visualisieren",
          "Fahrzeugranking erstellen",
          "Flag und weitere Diagramme erstellen",
          "Karte mit mehreren Ländern erstellen",
          "Filterleiste und KPIs erstellen",
          "Monatsformat programmieren und Diagramme erstellen",
          "Datentransformation für Fortgeschrittene",
          "Daten in der App automatisch aktualisieren",
          "Kapitelzusammenfassung",
          "Abschlussquiz"
        ],
        "Praktisches Beispiel \"Finanzdashboard\"": [
          "Einführung in das Kapitel",
          "Aktienkurse einladen über den Datenmanager",
          "Tabelle transformieren über den Datenmanager",
          "Liniendiagramm erstellen mit variabler Auswahl",
          "Kurssteigung berechnen",
          "Boxplot-Diagramm erstellen",
          "Inline Tabelle erstellen",
          "Sankey-Diagramm erstellen",
          "Eigene Aktien analysieren",
          "Storytelling in Qlik Sense",
          "Kapitelzusammenfassung",
          "Abschlussquiz"
        ]
      },
      "requirements": [
        "Keine Vorkenntnisse notwendig, du lernst von der ersten Anmeldung bis hin zur Erstellung von Komplexen Anwendungen alles was du brauchst.",
        "Qlik Sense Cloud (Professional-Lizenz) oder Qlik Sense Desktop."
      ],
      "description": "Werden auch Sie zum Profi Qliker.\n\n\nDieser Kurs geht auf wichtige Visualisierungen in der Cloud Version von Qlik Sense ein. Diese ermöglichen es Ihnen, ein umfangreiches und professionelles Dashboard in der Praxis zu erstellen.\nDer Kurs geht auch auf die Programmierung und Datentransformationen in Qlik Sense ein und erklärt diese anhand von praktischen Beispielen mit einem realen Datenbeispiel. In diesem Kurs werden Sie zwei Dashboards erstellen und werden besser in der Erstellung von Dashboards mit jeder Lektion.\nIm ersten Dashboard starten wir bei den Basics. Es werden keine Erfahrungen vorausgesetzt. Auch alle, die bereits Erfahrung mit älteren Qlik Versionen gesammelt haben, können hier lernen, wie Qlik Sense in der Cloud funktioniert.\nIm zweiten Dashboard analysieren wir für eine Autovermietung, ob auch alle Fahrzeuge rechtzeitig gereinigt wurden. Dafür tauchen wir tief in die Daten ein und arbeiten auch mit komplexeren Visualisierungen.\n\n\nFolgende Inhalte bietet dieser Kurs:\nUmgang mit der Qlik Cloud\nErstellung von Dashboards\nDaten laden in Qlik\nDaten aktualisieren in Qlik\nVerschiedene Diagramme erstellen (Balken,- Kreis-, Liniendiagramm)\nTabellen erstellen und bedingte Formatierung einfügen\nKPI Boxen implementieren und Kennzahlen mit Formeln erstellen\nFunktionsweise von Filtern\nWie erstellt man eine Navigationsleiste, um zwischen Arbeitsblättern zu wechseln\nWie erstellt man eine Karte und fügt Standorte hinzu\nBasisprogrammierung im Qlik Sense Dateneditor und Datenmanager\nFortgeschrittene Programmierung im Qlik Sense Dateneditor  (join, mapping, resident, distinct, store, left, concatenate, if, where)",
      "target_audience": [
        "An alle mit Qlik Sense professionelle Dashboards erstellen wollen",
        "Daten Analysten",
        "BI-Entwickler",
        "Data Scientists",
        "Data Engineers",
        "Projekt Manager"
      ]
    },
    {
      "title": "PySpark na Prática: Domine Ciência de Dados em Grande Escala",
      "url": "https://www.udemy.com/course/pyspark-na-pratica-domine-ciencia-de-dados-em-grande-escala/",
      "bio": "PySpark para processamento de dados em larga escala e análise exploratória. Do básico ao avançado! Do ETL ao ML!",
      "objectives": [
        "Você vai aprender a criar funções Python para manipulação de dados em larga escala.",
        "Vamos abordar técnicas de análise de dados avançadas para que você possa extrair insights valiosos de grandes conjuntos de dados.",
        "Você vai aprender a importar e manipular dados complexos de diferentes fontes, incluindo arquivos CSV, JSON, XML, entre outros.",
        "Vamos ensinar funções janelas avançadas, que são essenciais para manipulação e cálculo de dados em movimento, como médias móveis, percentuais e tendências.",
        "Vamos abordar técnicas de agrupamento de dados para que você possa segmentar seus dados de maneira mais eficiente e identificar padrões ocultos.",
        "Você vai aprender a construir indicadores e KPIs personalizados para avaliar o desempenho de seus negócios ou projetos."
      ],
      "course_content": {
        "Boas-Vindas e Primeiros Passos": [
          "Bem-Vindo(a)!",
          "Avisos importantes!",
          "Instalação do Anaconda no Windows",
          "Instalação do Anaconda no Mac",
          "Overview Jupyter Lab",
          "Overview Google Colab"
        ],
        "Introdução ao PySpark": [
          "Baixe os DataSets que serão usados no curso",
          "Criando um DataFrame",
          "SELECT: Selecionando dados de uma tabela",
          "SELECT: Exercícios",
          "FILTER: Filtrando dados de uma tabela",
          "FILTER: Exercícios",
          "WITHCOLUMN: Adicionando ou Modificando Colunas",
          "WITHCOLUMN: Exercícios",
          "FUNÇÕES DE TEXTO: Manipulando Strings com Funções",
          "FUNÇÕES NUMÉRICAS: Manipulando Números com Funções",
          "FUNÇÕES DE DATA: Trabalhando com Datas com Funções",
          "FUNÇÕES: Exercícios",
          "Python para Todos: da introdução à prática"
        ],
        "Manipulação de Dados em PySpark": [
          "ORDER BY: Classificando e Ordenando os Dados da Tabela",
          "ORDER BY: Exercícios",
          "GROUP BY: Agrupando os dados de uma tabela",
          "GROUP BY: Exercícios",
          "AGGREGATE: Agregando Dados com Funções de Soma, Média, Contagem, Mínimo e Máximo",
          "AGGREGATE: Exercícios",
          "O jeito mais fácil de resolver os BUGs no código!",
          "JOINS: Cruzando Dados com Left, Right, Inner, Full, Semi e Anti Joins",
          "ALIAS: Alterando o Nome das Colunas e nomeando DataFrames",
          "JOINs e ALIAS: Exercícios",
          "UNION ALL e DROP_DUPLICATES: Unindo DataFrames e Removendo Duplicatas",
          "UNION e DROP_DUPLICATES: Exercícios",
          "FUNÇÕES DE COLUNA: Manipulando Colunas com Funções"
        ],
        "Técnicas Avançadas de Manipulação de Dados": [
          "PIVOT e UNPIVOT: Transformando Dados com as Funções Pivot e Unpivot",
          "PIVOT e UNPIVOT: Exercícios",
          "SQL: Executando Consultas SQL em Spark",
          "EXPORTANDO UM DATAFRAME: Salvando um DataFrame em Diferentes Formatos",
          "CRIANDO UM DATAFRAME: Criando um DataFrame a partir de um schema",
          "CONVERSÃO DE SPARK PARA PANDAS: Convertendo um DataFrame Spark para Pandas"
        ],
        "Análise Avançada de Dados": [
          "UDF: Criando Funções Personalizadas",
          "UDF: Exercícios",
          "WINDOW: Utilizando Funções de Janelas",
          "WINDOW: Exercícios"
        ],
        "Desafio": [
          "Datasets usados no Pratique!",
          "Pratique!",
          "Resolução do desafio",
          "Tarefa"
        ],
        "Continuar aprendendo gratuitamente": [
          "Onde aprender mais",
          "[BÔNUS] Cursos gratuitos de Python, SQL, SAS e muito mais"
        ]
      },
      "requirements": [
        "Não se preocupe se você não tem nenhum conhecimento em Python, SQL ou análise de dados! Esse curso foi projetado para ser acessível a todos, independentemente do seu nível de habilidade. Não há pré-requisitos para se inscrever, apenas a vontade de aprender e a curiosidade em trabalhar com dados em larga escala. Nós fornecemos todos os materiais e recursos necessários para ajudá-lo a se tornar um especialista em PySpark. Não deixe que a falta de experiência o impeça de adquirir novas habilidades e avançar em sua carreira de ciência de dados. Inscreva-se agora e comece sua jornada de aprendizado!"
      ],
      "description": "Em um mundo cada vez mais movido a dados, é fundamental que profissionais de diversas áreas tenham conhecimentos em ferramentas de análise e manipulação de grandes conjuntos de dados. E nesse contexto, o PySpark é uma das principais ferramentas utilizadas por cientistas de dados, engenheiros de dados e analistas que precisam lidar com dados em larga escala.\nPor isso, se você deseja se tornar um profissional completo na área de ciência de dados, aprender PySpark é fundamental. E não é apenas por ser uma das principais ferramentas de análise de dados, mas também por uma série de outras vantagens que esse conhecimento pode trazer para sua carreira.\nUma das principais vantagens é a capacidade de lidar com grandes volumes de dados de forma mais eficiente. Com o PySpark, é possível trabalhar com dados distribuídos em clusters, o que permite uma análise mais rápida e eficaz de grandes conjuntos de dados. Essa habilidade é cada vez mais valorizada pelas empresas que precisam lidar com dados em larga escala, especialmente em setores como finanças, saúde e tecnologia.\nAlém disso, o PySpark oferece uma série de recursos avançados para análise de dados, como funções janelas avançadas e agrupamento de dados. Essas ferramentas permitem uma análise mais aprofundada e detalhada dos dados, o que pode levar a insights valiosos para a empresa ou organização em que você trabalha.\nOutra vantagem de aprender PySpark é a possibilidade de construir indicadores e KPIs mais precisos e personalizados. Com as ferramentas certas, é possível criar indicadores específicos para cada área da empresa, o que ajuda a monitorar o desempenho em tempo real e tomar decisões mais estratégicas.\nE, por fim, é importante destacar que a especialização em PySpark pode abrir portas para diversas carreiras promissoras em ciência de dados, como engenheiro de dados, analista de big data e cientista de dados. Todas essas profissões têm em comum a necessidade de lidar com grandes conjuntos de dados, e o PySpark é uma das principais ferramentas utilizadas para essa finalidade.\nEm resumo, aprender PySpark é fundamental para quem deseja se destacar no mercado de trabalho atual e se tornar um profissional completo em ciência de dados. Com essa ferramenta em seu arsenal, você poderá lidar com dados em larga escala com mais eficiência, criar indicadores mais precisos e personalizados e ter acesso a diversas carreiras promissoras em ciência de dados. Então não perca mais tempo e comece agora mesmo a aprender PySpark!",
      "target_audience": [
        "Os alunos ideais para este curso são aqueles que desejam se tornar profissionais em análise de dados e ciência de dados, ou que já possuem conhecimento básico nessas áreas e desejam aprimorar suas habilidades em PySpark. Este curso é para aqueles que desejam trabalhar com grandes volumes de dados e se destacar em áreas como finanças, marketing, saúde, ciência, tecnologia, entre outras. Além disso, este curso é destinado a pessoas que desejam seguir carreira em tecnologia, pois o PySpark é uma das ferramentas mais utilizadas atualmente em empresas de tecnologia para processamento e análise de dados em larga escala. O curso é especialmente útil para profissionais que desejam ter um conhecimento mais profundo em análise de dados e machine learning para solucionar problemas complexos em suas organizações. Se você está procurando avançar em sua carreira em ciência de dados, ou está interessado em aprender a trabalhar com grandes volumes de dados, este curso é ideal para você."
      ]
    },
    {
      "title": "Edu3Labs Destekleri ile ChatGPT Eğitimi",
      "url": "https://www.udemy.com/course/chatgpt-egitimi/",
      "bio": "Yapay Zeka, ChatGPT, Programlama",
      "objectives": [
        "ChatGPT Teknolojisini Kullanmayı",
        "ChatGPT'ye girilecek suflelerin oluşturulmasını",
        "Günlük hayatına ChatGPT'yi entegre etmeyi",
        "ChatGPT'ye rol atayarak istediği işlevi yaptırmayı"
      ],
      "course_content": {},
      "requirements": [
        "Programala bilgisi gerekmez. Her yaştan birey kursu izleyebilir"
      ],
      "description": "Edu3Labs destekleri ile karşınıza bir ChatGPT eğitimi ile çıkmaktayız.\n\nChatGPT, doğal dil işleme alanında büyük bir ilerleme ve başarı sağlayan OpenAI tarafından geliştirilen bir dil modelidir. Bu model, GPT-3.5 mimarisine dayanmaktadır ve geniş bir metin veri kümesi kullanılarak eğitilmiştir.\nChatGPT, kullanıcılarla doğal bir dil arayüzü sağlayarak, çeşitli konularda sohbet edebilen ve sorulara cevap verebilen bir yapay zeka modelidir. Model, insan gibi yanıtlar üretebilir, anlamlı cümleler oluşturabilir ve karmaşık soruları analiz edebilir.\nEğitim süreci, büyük bir veri kümesi kullanılarak gerçekleştirilir. Bu veri kümesi, çeşitli kaynaklardan elde edilen metinleri içerir. Model, bu metinleri analiz eder, metin içindeki kalıpları ve bağlantıları öğrenir ve ardından kullanıcının girdisine dayanarak tahminler yapabilir.\nEğitim süreci, milyonlarca parametrenin ayarlanması ve optimize edilmesini içerir. Bu süreç, modelin doğruluğunu artırmak için tekrarlanan denemeleri ve ayarlamaları gerektirir. Sonuç olarak, ChatGPT, geniş bir dil becerisi kazanır ve bir dizi konuda genel bir anlayışa sahip olur.\nChatGPT'nin başarılarına rağmen, model hala bazı sınırlamalarla karşı karşıyadır. Özellikle, doğru cevapları garanti edemeyebilir ve bazen yanıltıcı veya yanlış bilgiler verebilir. Bu nedenle, modelin çıktılarını değerlendirmek ve gerektiğinde doğrulamak önemlidir.\nOpenAI, ChatGPT'yi sürekli olarak geliştirmek ve kullanıcı geri bildirimlerini dikkate alarak iyileştirmeler yapmak için çalışmalarını sürdürmektedir. Böylece, gelecekte daha etkileyici ve güvenilir bir sohbet deneyimi sunmayı hedeflemektedir.",
      "target_audience": [
        "Yapay Zeka'ya meraklı"
      ]
    },
    {
      "title": "R e R Studio: análise de dados para pesquisadores iniciantes",
      "url": "https://www.udemy.com/course/r-rstudio/",
      "bio": "Análise, visualização e interpretação de dados - tome decisões como um cientista de dados profissional",
      "objectives": [
        "Como baixar e instalar o R e o R Studio.",
        "Como o R trabalha com comandos bases e pacotes de funções",
        "Análises estatísticas descritivas",
        "Como baixar conjuntos de dados para trabalhar",
        "Teste de hipóteses e interpretação de resultados.",
        "Análise de Regressão e de variância (ANOVA)"
      ],
      "course_content": {
        "Introdução": [
          "Introdução EngeHUB",
          "1.1 Apresentação da instrutora",
          "1.2 Como instalar o R e o RStudio",
          "1.3 Painéis e familiarização com o RStudio"
        ],
        "Elementos básicos": [
          "2.1 Aritmética (operadores)",
          "2.2 Objetos",
          "2.3 Instalação de pacotes",
          "2.4 Criação de variáveis"
        ],
        "Manipulação e utilização de dados": [
          "3.1 Criação de sequências e repetições de dados - Vetores",
          "3.2 Operações com matrizes",
          "3.3 Importação de dados",
          "3.4 Atividade prática do módulo 3"
        ],
        "Estatística descritiva": [
          "Teoria sobre tipos de variáveis",
          "4.1 Conjunto de dados mtcars",
          "4.2 Medidas de posição e dispersão",
          "4.3 Gráficos no R",
          "4.4 Pacotes gráficos no R (ggplot2)",
          "4.5 Atividades práticas módulo 4"
        ],
        "Probabilidade e testes de hipóteses": [
          "Antes de continuar, nos ajude a te ajudar :-)",
          "Teoria sobre distribuições de probabilidade",
          "5.1 Distribuições de probabilidade discretas - Poisson e Binomial",
          "5.2 Distribuição de probabilidade contínua - Normal",
          "5.3 Função Sample()",
          "Teoria sobre testes de hipóteses",
          "5.4 Testes de hipótese paramétricos",
          "5.5 Atividades práticas do módulo 5"
        ],
        "Correlação e análise de regressão (simples e múltipla)": [
          "Teoria sobre regressão linear",
          "6.1 Coeficiente de correlação",
          "6.2 Modelo de regressão linear simples",
          "6.3 Regressão múltipla",
          "6.4 Atividades práticas do módulo 6"
        ],
        "Análise de Variância (ANOVA)": [
          "Teoria sobre ANOVA",
          "7.1 One-way ANOVA - modelos DIC e BDC",
          "7.2 Two-way ANOVA - modelo fatorial com 2 fatores",
          "7.3 Análise de comparações múltiplas",
          "7.4 Atividades práticas do módulo 7"
        ],
        "Cases completos para prática": [
          "8.1 Atividade final 1 - análise descritiva",
          "Atividade final 2 - ANOVA",
          "Atividade final 3 - regressão"
        ],
        "Seção BÔNUS - Cursos Pelo Menor Preço da Udemy": [
          "Acesse nossos cursos com desconto + Bônus"
        ]
      },
      "requirements": [
        "Não é necessária experiência anterior com o software ou programação",
        "Não é necessária experiência anterior com o software ou programação"
      ],
      "description": "Analisar dados está no cerne do trabalho de muitas áreas atualmente. Como saber se há significância estatística em uma hipótese levantada? Como visualizar dados de forma a ter insights e tomar melhores decisões? Como realizar testes de hipótese para afirmar que fatores, de verdade, influenciam o resultado de um experimento?\nCurso prático e direto ao ponto que apresenta os primeiros passos para usar o software R e seus comandos com objetivo de tornar o aluno autônomo na manipulação so software. As video-aulas visam que o aluno aprenda a programar em R e como usá-lo para uma análise de dados eficaz e eficiente.\nO objetivo do curso é tornar o aluno apto a aplicar as técnicas estatísticas ensinadas ao longo do curso, extrapolar o raciocínio para várias aplicações do dia-a-dia de diversas áreas e PRINCIPALMENTE analisar e interpretar os resultados dos dados.\nDemonstraremos desde a instalação e configuração do software necessário para um ambiente de programação estatística e a descrever os conceitos da linguagem de programação genérica conforme eles são implementados em uma linguagem estatística para os níveis iniciais.\nO curso cobre questões práticas em computação estatística que inclui programação em R, leitura de dados em R, acesso a pacotes R e organização e comentários de código R. Tópicos em análise de dados estatísticos fornecerão exemplos de trabalho.\nAo final do curso você estará apto a importar dados para o software, tratar dados, visualizar e analisar os dados de forma a tomar decisões sobre o que está estudando. Ainda, o curso apresenta um passo a passo de como realizar testes de hipóteses e ANOVA, bem como interpretar seus resultados para tomar decisões assertivas e com relevância estatística --> NADA DE FAKE NEWS!\nEsses conhecimentos são úteis para qualquer pesquisador que precise publicar artigos com análises estatísticas, ou mesmo analistas de dados em empresas de diversas áreas.\nExemplos práticos serão apresentados com intuito de conhecer algumas ferramentas estatísticas como análise descritiva de dados, análise de regressão e análise de variância.",
      "target_audience": [
        "Não é necessária experiência anterior com o software ou programação",
        "Engenheiros ou analistas de dados",
        "Estudantes de engenharia",
        "Qualquer pessoa que queira aprender a usar uma poderosa ferramenta gratuita para tomar melhores decisões"
      ]
    },
    {
      "title": "Generative AI: Learn about the next AI frontier",
      "url": "https://www.udemy.com/course/generative-ai-ar/",
      "bio": "The Good, the Bad and the Ugly",
      "objectives": [
        "Generative AI definition, areas of applications, mappings like txt2txt, img2txt, txt2img and txt2voice",
        "How ChatGPT works, and the underlying tech behind like GPT, Large-Scale Language Models (LLM) and Transformers",
        "How Latent Diffusion, StableDiffusion and DALL-E systems work",
        "Generative Adversarial Networks (GANs) and Variational Auto Encoder (VAE)",
        "The good, bad and ugly faces of GenAI, and how to adapt to the new tech",
        "Build ChatGPT clone using OpenAI API and Streamlit",
        "Build NLP applications using OpenAI API like Summarization, Text Classification and fine tuning GPT models",
        "Build NLP applications using Huggingface transformers library like Language Models, Summarization, Translation, QA systems and others",
        "Build Midjourney clone application using OpenAI DALL-E and StableDiffusion on Huggingface"
      ],
      "course_content": {},
      "requirements": [
        "AI, ML and Deep Learning foundations",
        "NLP: RNN, LSTM, Transformers basics",
        "CV: ConvNets"
      ],
      "description": "Hello and Welcome to a new Journey in the vast area of Generative AI\n\n\nGenerative AI is changing our definition of the way of interacting with machines, mobiles and computers. It is changing our day-to-day life, where AI is an essential component.\n\n\nThis new way of interaction has many faces: the good, the bad and the ugly.\n\n\nIn this course we will sail in the vast sea of Generative AI, where we will cover both the theoretical foundations of Generative models, in different modalities mappins: Txt2Txt, Img2Txt, Txt2Img, Img2Txt and Txt2Voice and Voice2Text. We will discuss the SoTA models in each area at the time of this course. This includes the SoTA technology of Transformers, Language models, Large LM or LLM like Generative Pre-trained Transformers (GPT), paving the way to ChatGPT for Text Generation, and GANs, VAE, Diffusion models like DALL-E and StabeDiffusion for Image Generation, and VALL-E foe Voice Generation.\n\n\nIn addition, we will cover the practical aspects, where we will build simple Language Models, Build a ChatGPT clone using OpenAI APIs where we will take a tour in OpenAI use cases with GPT3.5 and ChatGPT and DALL-E. In addition we will cover Huggingface transformers and StableDiffusion.\n\n\nHope you enjoy our journey!",
      "target_audience": [
        "AI/ML Practitioners, Developers, Engineers and Researchers",
        "NLP Engineers or Researchers",
        "CV Engineers or Researchers",
        "Data Scientists"
      ]
    },
    {
      "title": "AI Mastering Course ( Machine & Deep Learning ) in Arabic",
      "url": "https://www.udemy.com/course/ai-mastering-course-in-arabic/",
      "bio": "الكورس الشامل و الكامل في مجال الذكاء الاصطناعي من التأسيس للاحتراف إن شاء الله",
      "objectives": [
        "سوف تتعلم ما هو مجال الذكاء الاصطناعي و ما هي فروعه",
        "سوف تتعلم ما هو تخصص تعلم الالة و انواعه",
        "سوف تتعلم المواضيع المتعلقة بالاحصاء و الرياضيات و الجبر بشكل سهل و بسيط و بدون تعقيد",
        "سوف تتعلم البرمجة من الصفر حتي تصبح مبرمج محترف",
        "سوف تتعلم كيف تجعلك الكمبيوتر يتعلم و كيف تدربه",
        "سوف تعمل علي مشاريع عملية",
        "سوف تتعلم ما هو التعلم العميق",
        "سوف تتعلم الشبكات العصبية و انواعها",
        "سوف تقوم بمشاريع متقدمة"
      ],
      "course_content": {},
      "requirements": [
        "لا تحتاج الي اي خبرة او معرفة بأي شيء فقط يجب ان تستعين بالله"
      ],
      "description": "السلام عليكم ورحمه الله وبركاته ،\nاهلا بكم في الكورس الاحترفي لتعلم مجال تعليم الالة و التعلم العميق و هما اهم تخصصات مجال الذكاء الاصطناعي و هو التخصص الاكثر طلبا في سوق العمل و صاحب اكبر راتب في مجال البرمجيات و التكنولوجيا ،\nباذن الله في هذا الكورس سوف ابني لك اولا الاساسيات الرياضية التي تحتاجها للبداء في المجال و بالاخص في فرع الجبر و الاحصاء ،\nثم سوف تتعلم البرمجة من الصفر حتي الاحتراف ان شاء الله ثم سوف ندخل في عالم المكتبات التي سوف نحتاج اليها في لغة البرمجة بايثون مثل :\n- مكتبة نمباي للعمليات الرياضية\n- مكتبة بانداس للتعامل مع البيانات و الجداول و الملفات\n- مكتبة ماتبلوتليب للرسوم و رسم الاشكال الاحصائية\n- مكتبة سيبورن للرسوم ايضا\nثم سوف ننتقل الي شرح خوارزميات تعلم الالة و معادلاتها الرياضية و التي سوف نشرح كل جزءًا فيها بالتفصيل و بطريقة سهلة ليس بها اي تعقيدات لكي تستطيع فهمها مهما كان مستواك في الرياضيات و بعد نهاية شرح كل خوارزمية بمعادلاتها سوف نطبق عليها بالكود و نعمل علي مشروع حتي نفهم كل التفاصيل و المراحل اثناء التطبيق و العمل و هذه هي المواضيع التي سوف نتطرق اليها :\n- خوارزميات التوقع\n- خوارزميات التصنيف\n- الشبكات العصبية\n- التقسيمات ( العناقيد )\n- تكنيكات و خوارزميات حديثة\nثم سننتقل الي التعلم العميق و التي سوف نري كيف نتعامل مع النصوص و الصور و الشبكات العصبية بعمق و سوف نقوم بعمل تطبيقات متقدمة مثل التعرف علي صور اشعة المرضي و تحليل اراء المستخدمين حول منتج معين و التعرف علي الوجوه والكثير من التطبيقات الهامة و المتقدمة\nاتمني منكم ان تستفادوا من هذا الكورس و ان تستمتعوا بهذه الرحلة كما استمتع انا بشرح هذا الكورس و اتمني لكم التوفيق الدائم",
      "target_audience": [
        "هذا الكورس لاي شخص يريد ان يتعلم مجال الذكاء الاصطناعي من الصفر بشكل صحيح و تأسيس قوي"
      ]
    },
    {
      "title": "Formação Data Warehouse com Redshift, BigQuery e SnowFlake",
      "url": "https://www.udemy.com/course/data-warehouse/",
      "bio": "Aprenda Engenharia de Dados e Big Data com Ferramentas de Data Warehouse Modernas e na Nuvem",
      "objectives": [
        "Modelagem de Dados para Data Warehouse",
        "Fundamentos de Snowflake, como time travel, streams e tasks",
        "Fundamentos de Redshift, como sortekeys, Distkey e Diststyle",
        "Fundamentos de Bigquery, como Cluster, Partições e Projetos",
        "Técnicas Avançadas de SQL: Windows Functions, CTEs, Pivots etc.",
        "Boas Práticas na Construção e Modelagem de Data Warehouses",
        "Fundamentos e Conceitos de Data Warehouse para Big Data"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Apresentação",
          "O que é um Data Warehouse",
          "Observações sobre conta AWS",
          "Informações Importantes",
          "Atenção! Material do Curso"
        ],
        "Fundamentos de DataWarehouse Moderno": [
          "Fatos sobre Data Warehouses",
          "Diferenças entre Bancos de Dados Operacionais e Analíticos",
          "Diferenças entre Data Warehouse Clássico do Moderno",
          "Armazenamento por Linha Versus Coluna",
          "Conceitos Gerais de Cluster",
          "Particionamento e Replicação",
          "Tolerância a Falhas",
          "Fundamentos de DataWarehouse Moderno"
        ],
        "Modelagem de Dados em DataWarehouse": [
          "Considerações Sobre Modelagem",
          "Modelo Relacional",
          "Modelando na 3FN",
          "Tipos de Relacionamentos",
          "Modelo Dimensional",
          "Chave Substituta",
          "Dimensional Snowflake",
          "Galaxy Schema",
          "Flat Table",
          "Modelo Data Vault",
          "Modelagem de Dados em DataWarehouse"
        ],
        "Comparando Redshift, Bigquery e SnowFlake": [
          "Comparação"
        ],
        "Modelo de Dados Usado no Curso": [
          "Modelo Northwind"
        ],
        "Conhecendo Redshift: Conceitos e Prática": [
          "Introdução ao Redshift",
          "Sortkey, Distkey e Cache",
          "Serverless versus Provisionado",
          "Atividade Prática",
          "Criando uma instância e um Banco de Dados",
          "Criando Objetos e Populando",
          "Testando Sortkey e Distkey",
          "CTE e Função de Janela",
          "Analyze",
          "Planos de Execução",
          "Vacuum",
          "Analyse Compression",
          "Consultando Dados Externos Redshift Spectrum",
          "Criando Configurações",
          "Vinculano Dados Externos",
          "Consultando Dados Externos",
          "Carregando Dados com Copy",
          "Configurando e Importando",
          "Views Parte I",
          "Views Parte II",
          "Boas Práticas"
        ],
        "Conhecendo BigQuery: Conceitos e Prática": [
          "Introdução ao BigQuery",
          "Particionamento",
          "Cluster de Tabelas",
          "Criando o Projeto",
          "Criando Objetos e Populando",
          "Primeiras Consultas",
          "Consultando Partições",
          "Quando usar Partition e Cluster",
          "Criando uma Tabela Pivot",
          "Cálculo da Média com Sub Consulta",
          "Criando Tabelas pelo Console Web",
          "Tabelas Externas",
          "Views",
          "Criando Views"
        ],
        "Conhecendo SnowFlake: Conceitos e Prática": [
          "Apresentação e Edições",
          "VirtualWarehouse",
          "Cache e Clustering",
          "Criando uma Conta no Snowflake",
          "Criando um Warehouse",
          "Criando Objetos e Populando",
          "Views",
          "Criando Views",
          "Produtos Mais Vendidos por Categoria",
          "Consultando Produtos Mais Vendidos por Categoria",
          "Total e Média de Vendas por Mes",
          "Carregando Dados Externos com Copy",
          "Executando Copy",
          "TimeTravel e Fail-safe",
          "Implementando TimeTravel",
          "Conhecendo Tasks",
          "Criando Tasks",
          "Criando uma DAG com Duas Tasks",
          "Streams e CDC",
          "Streams na Prática"
        ],
        "Projeto: DW com CDC de Staging": [
          "Apresentação",
          "Etapas",
          "Criando os Objetos",
          "Criando Streams",
          "Stream da Fato",
          "Criando Stream da Fato",
          "Testando o DW",
          "Criando Tasks e Testando",
          "Considerações Sobre o Grão (Nível de Detalhes)"
        ],
        "Check list para seu Projeto": [
          "Checklist Parte I",
          "Checklist Parte II",
          "Checklist Parte III",
          "Checklist Parte IV"
        ]
      },
      "requirements": [
        "Conhecimentos Básicos em SQL e Banco de Dados"
      ],
      "description": "O que é um data warehouse? É um sistema de armazenamento de dados que é projetado para permitir a análise de informações de negócios de maneira mais eficiente. Ele é um repositório centralizado de dados que são extraídos, transformados e carregados de várias fontes de dados para fornecer informações úteis e estratégicas para a tomada de decisões em uma organização. Ele é fundamental para a empresa possua dados gerenciais de qualidade para a tomada de decisão.\nNeste curso, além dos fundamentos, você vai conhecer três das principais ferramentas de Data Warehouse:\nSnowflake: data warehouse nativo da nuvem que oferece escalabilidade, segurança e desempenho sem a necessidade de gerenciar infraestrutura física. Ele usa uma arquitetura de banco de dados em nuvem que separa o armazenamento de dados do processamento de consultas, permitindo que os usuários dimensionem cada camada independentemente.\nRedshift: data warehouse baseado em nuvem que permite armazenar e analisar grandes volumes de dados usando SQL. Ele usa uma arquitetura em cluster massivamente paralela para processar consultas de forma rápida e eficiente, permitindo que os usuários executem análises de dados em tempo real. O Redshift é altamente escalável e pode ser facilmente dimensionado para lidar com conjuntos de dados cada vez maiores.\nBigQuery: serviço de data warehouse baseado em nuvem que permite armazenar e analisar grandes volumes de dados usando SQL. Ele usa uma arquitetura de processamento em coluna para permitir consultas de dados rápidas e escaláveis, permitindo que os usuários executem análises em tempo real em grandes conjuntos de dados\nO que você vai aprender neste curso:\nFudandamentos de Datawarehouse, como clusters, replicação, particionamento, armazenamento colunar, tolerância a falhas\nModelo de Dados para Datawarehouses: Modelos dimensinais star e snowflake, modelo relacional, Galaxy Schema e outros\nFundamentos e aplicações em Redshift: Conceitos como sortkey, distkey, diststyle, cache. Criação de consultas utilizando CTEs. Planos de Execução, vinculação a dados externos, importação com copy, views e views materializadas\nFundamentos e aplicações em BigQuery: Criação de Projetos, Tavela Pivot, partições, tabelas externas, view  emais\nFundamentos e aplicações em Snowflake: Virtualwarehouse, cache, clustering,  views, time travel, fail-safe, taks, streams e muito mais\nCriação de um projeto prático: carga de dados do staging de forma incremental para um Data Warehouse, utilizando CDC, streams e tasks\nChecklist comentado: dicas e truques para você considerar no seu projeto.\nO curso inclui ainda:\nMaterial de apoio, como scritps para criação de objetos de banco de dados\nSlides das aulas em formato pdf",
      "target_audience": [
        "Engenheiros de Dados, Analistas de Dados, Cientista de Dados e Administradores de Dados"
      ]
    },
    {
      "title": "NumPyro で学ぶ ベイズ統計モデリング 【基礎編】",
      "url": "https://www.udemy.com/course/numpyro-basic/",
      "bio": "Google Colaboratory で実践する統計モデリング",
      "objectives": [
        "ベイズ統計や統計モデリングの基礎",
        "確率プログラミングの基礎",
        "統計モデルの構築方法や評価方法",
        "事後予測チェック / 情報量基準",
        "一般化線形モデル / 一般化線形混合モデル",
        "マルコフ連鎖モンテカルロ法の概要"
      ],
      "course_content": {
        "イントロダクション": [
          "はじめに",
          "コース紹介",
          "実行環境の確認",
          "ここまでのまとめ"
        ],
        "統計モデリング / 確率プログラミング": [
          "統計モデリングの基礎",
          "MCMC とは？",
          "確率プログラミングの基礎",
          "Google Colaboratory での実践１",
          "事後予測チェック",
          "Google Colaboratory での実践２",
          "ここまでのまとめ"
        ],
        "ゼロ過剰ポアソン分布": [
          "ゼロ過剰ポアソン分布",
          "広く使える情報量基準（WAIC）",
          "ここまでのまとめ"
        ],
        "線形回帰": [
          "線形回帰",
          "Google Colaboratory での実践１",
          "Google Colaboratory での実践２",
          "ここまでのまとめ"
        ],
        "ロジスティック回帰": [
          "ロジスティック回帰",
          "Google Colaboratory での実践",
          "ここまでのまとめ"
        ],
        "ポアソン回帰": [
          "ポアソン回帰",
          "Google Colaboratory での実践",
          "ここまでのまとめ"
        ],
        "一般化線形混合モデル": [
          "一般化線形混合モデル",
          "Google Colaboratory での実践",
          "ここまでのまとめ"
        ],
        "モデルによる予測とベイズ決定": [
          "一般化線形混合モデル",
          "Google Colaboratory での実践１",
          "ベイズ決定",
          "Google Colaboratory での実践２",
          "ここまでのまとめ"
        ],
        "マルコフ連鎖モンテカルロ法": [
          "メトロポリス・ヘイスティング法の概要",
          "ハイブリッド・モンテカルロ法の概要",
          "NUTSの概要",
          "おわりに"
        ]
      },
      "requirements": [
        "Python を使ったデータ解析の基礎知識（グラフが書ける程度）",
        "確率・統計の基礎知識",
        "期待値・事前分布・事後分布・尤度などの用語が理解できること"
      ],
      "description": "Python のパッケージである NumPyro を使って統計モデリングと確率プログラミングの基礎を学びます。最初は、分布へのあてはめといった簡単な例題からスタートして、段階的に一般化線形モデル（GLM）や一般化線形混合モデル（GLMM）といったモデルの概要を理解できるようになることを目指します。\n\n\nNumPyro は、JAX と呼ばれる高速なバックエンドを持っていることが特徴の確率プログラミングのパッケージであり、モデルのパラメータ推定などを高速に行えるのが、大きな特徴のひとつになっています。また、NumPyro は Python のパッケージであることから、Python の経験者にとっては、比較的少ない学習コストで統計モデリングや確率プログラミングという新しい世界を覗いてみることができることも大きなメリットのひとつとなっています。\n\n\nNumPyro の最新バージョンは現在のところ 0.6.0 ですが（2021年6月現在）、動作は安定しており、普通に利用するには大きな問題はないものと考えていますが、パッケージがまだまだ発展途上であることには注意が必要です。業務等での利用の際には十分にご注意下さい。\n\n\nまた、NumPyro に関しては、和書などの日本語の情報が少ないため、わからないことが出てきた場合には、ある程度英語で情報を読み解く力が必要になります。その点にもご注意下さい。\n\n\nなお、本講座で使用している NumPyro のバージョンは 0.6.0 です。\n\n\n【注意点】\n本講座ではできるだけ理論的な側面と実装的な側面の両方の説明をするようにしていますが、理論的な側面を十分に理解するには確率分布等に関する予備知識が必要となります。必要な予備知識に関しては、動画の始めの方でご紹介していますので、予めご確認下さい。また、本講座公開後のレビュー等から推察されるレベル感としては、何らかのベイズ統計モデリングに関する書籍を少し読まれたくらいの方が復習として利用されるのが最もフィットするような印象を持っています。「完全にゼロからのスタートだと少し難しいかもしれない」といった趣旨のご意見を頂いています。\n\n\nまた、本講座の中で紹介している例題は、既に公開済みの講座である「PyMC3 で学ぶ統計モデリングの基礎」とほぼ同じ例題ですが、利用している確率プログラミングのパッケージが異なります。なお、講座「PyMC3 で学ぶ統計モデリングの基礎」は、前半に「予測における確率分布の重要性」などの解説を含んでいます。\n\n\nまた、こちらで配布しているコードは Google Colaboratory 専用のコードになっているため、比較的簡単な操作でコードを動かしてみることができるようになっています。",
      "target_audience": [
        "統計モデリング・確率プログラミングに興味がある人",
        "GLM や GLMM について知りたい人",
        "ベイズ統計に興味がある人"
      ]
    },
    {
      "title": "Bioestadística con RStudio para Investigación/Tesis de Salud",
      "url": "https://www.udemy.com/course/bioestadistica-con-rstudio-para-investigacion-tesis-de-salud/",
      "bio": "Aprende a realizar análisis estadístico con RStudio para investigaciones o tesis de ciencias de la salud",
      "objectives": [
        "Utilizar el programa RStudio con fluidez",
        "Preparar una base de datos para realizar el análisis estadístico",
        "Estadística descriptiva incluyendo el cálculo de estimados",
        "Elaboración de gráficos que te ayudarán a visualizar los datos",
        "Pruebas de hipótesis paramétricas",
        "Pruebas de hipótesis no paramétricas",
        "Comprender en que situaciones utilizar pruebas estadísticas",
        "Hojas de texto con el código de análisis en RStudio"
      ],
      "course_content": {},
      "requirements": [
        "No existe ningún requisito. Aprenderás todo lo necesario en este curso."
      ],
      "description": "Aprende como realizar análisis estadísticos en RStudio para estudios biomédicos o de ciencias de la salud paso a paso. Ya seas estudiante o profesional con interés en aprender a realizar análisis estadísticos con RStudio pero sin un claro punto de partida este curso es perfecto para ti. Los conocimientos adquiridos en este curso te servirán tanto para realizar análisis de datos de trabajos de investigación y tesis. Además, cada análisis explicado utiliza como ejemplo una pregunta de investigación biomédica de tal forma que sea aplicable.\n\n\nEspecíficamente aprenderás a realizar los mismos análisis que realizamos al día a día los investigadores biomédicos como por ejemplo:\nInstalación de R y RStudio e Interfaz\nIntroducción a los fundamentos de RStudio.\nCreación de diagramas para graficar datos incluyendo plots de nubes de puntos, histogramas, diagramas circulares o diagramas de caja y bigotes con la librería ggplot2.\nImportación y exportación de bases de datos\nCreación, cálculo y transformación de variables.\nCálculo de estimados descriptivos como frecuencias absolutas relativas, medidas de tendencia central y dispersión.\nRealización de pruebas paramétricas como Chi Cuadrado, T de Student y ANOVA.\nRealización de pruebas no paramétricas como Fisher, U de Mann-Whitney y Kruskall Wallis.\n\n\nBONUS\nCon la adquisición del curso además tendrás acceso a los códigos en RStudio para que puedas realizar tus propios análisis.\nBases de datos para que puedas realizar los ejemplos de las clases\nCertificado que puedes compartir en Linkedlin\nForo de la comunidad para preguntas",
      "target_audience": [
        "Cualquier persona interesada en analizar datos con R"
      ]
    },
    {
      "title": "SQL e Banco de Dados para DataScience, sem mistérios!",
      "url": "https://www.udemy.com/course/sql-banco-de-dados-datascience/",
      "bio": "Aprenda como tratar os seus dados utilizando SQL Puro e prepare o seu set de dados para DataScience e Machine Learning!",
      "objectives": [
        "Preparar um set de dados no Banco de Dados para DataScience",
        "Medidas Estatísticas para DataScience - Moda, Média, Mediana, Desvio Padrão, Coeficiente de Variação, etc.",
        "Modelagem Colunar para DataScience",
        "Importação de Arquivos",
        "Exportação de Arquivos",
        "Subqueries Avançadas",
        "CTE",
        "Windows Functions",
        "Rollap Cube",
        "Criação de um Banco de Dados",
        "Instalação do Postgres SQL"
      ],
      "course_content": {
        "Introducao": [
          "Introdução, Download e Instalação"
        ],
        "Criando e configurando o Banco": [
          "Criando o Primeiro Banco de Dados",
          "Datas - Trabalhando com DateStyle",
          "Criando o Banco de Dados do Projeto"
        ],
        "Funções de Agregação - Introdução": [
          "Introdução a Funções de Agregação"
        ],
        "Medidas Estatísticas": [
          "Estatística - MÉDIA",
          "Entendendo as Principais Medidas Estatísticas",
          "Concluindo a Análise Estatística",
          "Modelagem de Banco de Dados x Modelagem para Data Science e B.I",
          "Importação de Arquivos CSV e MODA",
          "AMPLITUDE de um Set",
          "Mais Medidas Estatísticas - DESVIO PADRÃO e VARIÂNCIA",
          "Calculando a MEDIANA",
          "Calculando o COEFICIENTE DE VARIAÇÃO",
          "Calculando a MODA com funções nativas",
          "Exportando Bancos Relacionais para Formatos Colunares"
        ],
        "Projeto Prático - Automatizando um Relatório": [
          "Arquitetura do Ambiente",
          "Entendendo a estrutura da sincronização",
          "Programando a sincronização",
          "Sincronizando Registros Deletados",
          "Exercícios - Salários",
          "Criando variáveis Dummy para Machine Learning",
          "Introdução aos filtros",
          "Filtros de Contadores",
          "Formatando Strings"
        ],
        "Encerramento": [
          "Encerramento do curso"
        ]
      },
      "requirements": [
        "Conhecimento básico de SQL",
        "Meu curso \"O Curso completo de Banco de Dados e SQL Sem Mistérios\" ou um conhecimento similar."
      ],
      "description": "Se você gostou do meu Best Seller - O Curso Completo de Bancos de Dados e SQL sem Mistérios, você com toda certeza irá gostar desse curso!\nEm SQL e Banco de Dados para DataScience eu dou uma visão mais estatística e avançada não esquecendo a didática tão falada no meu primeiro curso. Em resumo: Aspectos avançados tornam-se simples em diversos bancos de dados modelados exclusivamente para você!\nAprenda como importar um set de dados e também como exportar um set de dados do banco de dados para um formato colunar extremamente utilizado para Data Science e Machine Learning!\nRetire medidas estatísticas do seu banco de dados, como, Média, Moda, Mediana, Desvio Padrão e Coeficiente de Variação, tudo isso com muita simplicidade, em selects simples!\nAprenda as Window Functions e eleve as suas análises a outro nível!\nFormate colunas de números e strings!\nProcure por palavras com expressões regulares!\nPrepare-se para o futuro! Bancos de Dados e SQL para Data Science!\nVejo vocês nas aulas!\n\n\nSe você gostou do meu Best Seller - O Curso Completo de Bancos de Dados e SQL sem Mistérios, você com toda certeza irá gostar desse curso!\nEm SQL e Banco de Dados para DataScience eu dou uma visão mais estatística e avançada não esquecendo a didática tão falada no meu primeiro curso. Em resumo: Aspectos avançados tornam-se simples em diversos bancos de dados modelados exclusivamente para você!\nAprenda como importar um set de dados e também como exportar um set de dados do banco de dados para um formato colunar extremamente utilizado para Data Science e Machine Learning!\nRetire medidas estatísticas do seu banco de dados, como, Média, Moda, Mediana, Desvio Padrão e Coeficiente de Variação, tudo isso com muita simplicidade, em selects simples!\nAprenda as Window Functions e eleve as suas análises a outro nível!\nFormate colunas de números e strings!\nProcure por palavras com expressões regulares!\nPrepare-se para o futuro! Bancos de Dados e SQL para Data Science!\nVejo vocês nas aulas!",
      "target_audience": [
        "Universitários",
        "Iniciantes em Bancos de Dados",
        "Iniciantes em Data Science"
      ]
    },
    {
      "title": "Python: Machine Learning",
      "url": "https://www.udemy.com/course/python-machine-learning-desde-cero/",
      "bio": "Román, con más de 20 años desarrollando modelos de clasificación y regresión te enseñará todo sobre Machine Learning",
      "objectives": [
        "Herramientas para el procesamiento y visualización de datos.",
        "Evaluación de modelos de clasificación.",
        "Evaluación de modelos de regresión.",
        "Regresión lineal, regresión polinomial, regresión logística y más.",
        "Árboles de decisión.",
        "Redes neuronales.",
        "Deep learning con Keras."
      ],
      "course_content": {
        "Introducción": [
          "Bienvenido a Numpi",
          "Presentación",
          "Jupyter Notebooks (Archivos descargables)",
          "Instalación",
          "Instalación por Consola",
          "Introducción a Jupyter",
          "Google Colab"
        ],
        "Introducción a Python": [
          "Variables numérica",
          "Variables String y booleanas",
          "Estructuras",
          "IF ELSE",
          "Ciclo WHILE",
          "Ciclo FOR",
          "Funciones",
          "POO"
        ],
        "Herramientas para el procesamiento y visualización de datos": [
          "Numpy",
          "Pandas",
          "Matplotlib",
          "Scikit-Learn",
          "Keras",
          "Matemáticas y Estadística"
        ],
        "Machine learning": [
          "Introducción a Machine Learning",
          "Evaluación de Modelos de Clasificación",
          "Evaluación de Modelos de regresión",
          "Regresión Lineal",
          "Regresión Polinomial",
          "Regresión Logística",
          "Clasificador de Naive Bayes",
          "Arboles de decision",
          "KNN",
          "Kmeans",
          "Máquinas de Soporte Vectorial",
          "Análisis de Componentes Principales",
          "Regularización de Modelos Lineales",
          "Optimizacion de Hiperparámetros"
        ],
        "Deep Learning": [
          "Introducción a la redes Neuronales/Percetron S.",
          "BackPropagation",
          "Perceptron Multicapas",
          "Deep Learmimg con Keras",
          "Redes Convolucionales con Keras(Teoría)",
          "Redes Convolucionales con Keras(Pract.)"
        ],
        "Terminaste": [
          "Cierre del curso",
          "Clase extra"
        ]
      },
      "requirements": [
        "Conceptos básicos de Python."
      ],
      "description": "Este curso se sumerge en los conceptos básicos del aprendizaje automático utilizando un lenguaje de programación conocido y accesible, Python.\nEn este curso, revisaremos dos componentes principales:\nPrimero, aprenderá sobre el propósito del aprendizaje automático y dónde se aplica al mundo real.\nEn segundo lugar, obtendrá una descripción general de los temas de Machine Learning, como el aprendizaje supervisado frente al no supervisado, la evaluación de modelos y los algoritmos de Machine Learning.\n¡Inscríbete a este curso y vuélvete un experto en Machine Learning con Python!\n\n\nMachine Learning es una nueva herramienta clave que posibilitará el desarrollo de un futuro mejor para el hombre brindando inteligencia a robots, coches y casas. Las Smart Cities, el IOT ya se están volviendo una realidad y también las aplicaciones de Machine Learning en Asistentes como Siri, las recomendaciones de Netflix o Sistemas de Navegación en Drones. Para los ingenieros o informáticos es una disciplina fundamental para ayudar a crear y transitar este nuevo futuro.\n\n\nEl 89% de los estudiantes del curso también ha mejorado su situación laboral.\n¡Inscríbete ahora y desarrolla esa habilidad que te hace falta!\n\n\nPython es un fenomenal primer lenguaje, como si es tu segundo, tercero o enésimo lenguaje. Su curva de aprendizaje es menos áspera que otros, dispone de miles de librerías que permiten en unas pocas líneas de código hacer lo que nos propongamos. Te permite evolucionar rápidamente, además de profundizar en tareas más complejas, según vas adquiriendo soltura.\n\n\n¡INSCRÍBETE AHORA y empieza a potenciar tu carrera!",
      "target_audience": [
        "Cualquiera interesado en aprender Machine Learning.",
        "Estudiantes que tienen un conocimiento de matemáticas que quieran aprender acerca del Machine Learning con Python.",
        "Estudiantes de universidad que busquen especializarse y aprender a ser Data Scientists.",
        "Cualquier persona que no esté satisfecha con su propio trabajo y busque empezar a trabajar como un Data Scientist profesional."
      ]
    },
    {
      "title": "NumPy+matplotlib実践トレーニング -機械学習、深層学習の基礎として学ぶデータの操作と可視化-",
      "url": "https://www.udemy.com/course/numpy-matplotlib/",
      "bio": "機械学習、深層学習（ディープラーニング）で非常に有用なツール、NumPyとmatplotlibを練習するコースです。Colaboratory環境を使用します。Pythonで効率よくデータを操作し、可視化できるようになりましょう。",
      "objectives": [
        "NumPy、matplotlib全般の基礎的な知識を学びます。",
        "NumPyの配列の扱い方を学び、様々なデータの加工ができるようになります。",
        "matplotlibを使い、様々なグラフでデータを可視化できるようになります。",
        "NumPyで簡単な機械学習が実装できるようになります。",
        "matplotlibが動作する背景についての知識が身につきます。",
        "深層学習、機械学習でデータを扱うための基礎が身につきます。"
      ],
      "course_content": {
        "NumPyとmatplotlibの概要": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "NumPyとmatplotlibの概要",
          "開発環境について",
          "NumPyとmatplotlibの実演",
          "演習"
        ],
        "Numpyの基礎": [
          "セクション2の教材",
          "Section2の概要",
          "NumPyの基礎1",
          "NumPyの基礎2",
          "NumPyの基礎3",
          "NumPyの基礎4"
        ],
        "matplotlibの基礎": [
          "セクション3の教材",
          "Section3の概要",
          "matploblibの様々なグラフ",
          "Pyplotインターフェイスとオブジェクト指向インターフェイス",
          "matplotlibの構造"
        ],
        "NumPyの実践トレーニング": [
          "セクション4の教材",
          "Section4の概要",
          "NumPyによる確率/統計 Part1",
          "NumPyによる確率/統計 Part2",
          "NumPyによる多項式回帰",
          "NumPyによるニューラルネットワーク"
        ],
        "matplotlibの実践トレーニング": [
          "セクション5の教材",
          "Section5の概要",
          "3Dグラフの描画",
          "matplotlibによるアニメーション",
          "matplotlibによるシミュレーション",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "中学-高校レベルの数学で十分です。高度な数学は必要ありません。",
        "Google Colaboratoryを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。",
        "機械学習、データサイエンスについての解説はありません。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。"
      ],
      "description": "「NumPy+matplotlib実践トレーニング」は、機械学習、深層学習（ディープラーニング）で非常に有用なツール、NumPyとmatplotlibを練習する講座です。\n\n\nNumPyはPythonの拡張モジュールで、深層学習などの機械学習で頻繁に使用されます。\n多次元配列を強力にサポートし、内部はC言語で実装されているため高速に動作します。\nまた、大規模な数学関数ライブラリを持っており、シンプルな表記で効率的なデータの操作を可能にします。\nmatplotlibはNumPyと同じくPythonの外部モジュールで、グラフの描画や画像の表示、アニメーションの作成などで使用されます。\n機械学習ではデータを可視化することがとても重要なので、matplotlibは様々な場面で活躍します。\n\n\n本講座では、このようなNumPy、matplotlibの扱い方を学んだ上で、トレーニングを重ねます。\n本格的に深層学習、機械学習に取り組むためのベースとして、NumPy、matplotlibのスキルを磨きましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! AIRS-Lab】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. NumPyとmatplotlibの概要\n→ NumPyとmatplotlibの概要、および開発環境について学びます。\nSection2. NumPyの基礎\n→ NumPyについて、主に配列の基礎的な操作を学びます。\nSection3. matplotlibの基礎\n→ matplotlibについて、主に様々なグラフの表示方法を学びます。\nSection4. NumPyの実践トレーニング\n→ NumPyについて、より実践的な機能を学び機械学習へつなげていきます。\nSection5. matplotlibの実践トレーニング\n→ matplotlibについてより深く理解し、データ可視化のスキルを身に付けます。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "機械学習を実装するための基礎としてNumPy、matplotlibを学びたい方。",
        "効率よくデータの加工、可視化を行いたい方。",
        "本格的に深層学習、機械学習に取り組むための ベースを身につけたい方。",
        "数学をデータに適用する基礎を身につけたい方。",
        "様々な種類のデータを、様々な方法で可視化する方法を学びたい方。",
        "仕事上、データに深く関わる必要に迫られた方。"
      ]
    },
    {
      "title": "Big Data Analytics con Python e Spark 2.4: il Corso Completo",
      "url": "https://www.udemy.com/course/big-data-analytics-con-python-e-spark/",
      "bio": "Impara ad analizzare e processare i Big Data con Python e Spark ( PySpark )",
      "objectives": [
        "Utilizzare Python e Spark per Analizzare i Big Data",
        "Utilizzare MLlib per Creare Modelli di Machine Learning con i Big Data",
        "Installare e Configurare PySpark su una Macchina Virtuale",
        "Installare e Configurare PySpark con Amazon EC2",
        "Creare un Cluster di Macchine per PySpark con Amazon EMR",
        "Utilizzare gli Amazon Web Service (AWS) per l'Analisi di Big Data",
        "Imparare ad Utilizzare DataBricks per l'Analisi di Big Data",
        "Utilizzare l'RDD per Elaborare Dati in Parallelo",
        "Utilizzare il DataFrame per Processare Dati in Maniera Efficiente",
        "Utilizzare Spark Streaming per elaborare flussi di dati in Tempo Reale",
        "Creare un Modello di Sentiment Analysis con il Dataset di Yelp (5 GB !)",
        "Processare Tweets pubblicati su Twitter in Tempo Reale"
      ],
      "course_content": {
        "Introduzione": [
          "Cosa sono i Big Data ?",
          "Domande Frequenti",
          "I vantaggi dei Big Data",
          "Le tecnologie per i Big Data: Spark",
          "Le tecnologie per i Big Data: Hadoop MapReduce",
          "Leggi questo prima di iniziare !"
        ],
        "Installazione di Spark in locale con VirtualBox": [
          "Usare VirtualBox per Creare una Macchina Virtuale",
          "Installare Ubuntu sulla Macchina Virtuale",
          "Installare Pip e Jupyter Notebook",
          "Installare Java e Scala",
          "Installare Spark sulla Machina Virtuale"
        ],
        "Installazione di Spark su AWS EC2": [
          "Creare una Macchina Virtuale con AWS EC2",
          "Installare Spark sulla Machina Remota",
          "Non dimenticare questo !"
        ],
        "Creare un Cluster con AWS EMR": [
          "Creazione di un Cluster con AWS EMR (Elastic Map Reduce)"
        ],
        "Utilizzare Spark con DataBricks": [
          "Utilizzare Spark con DataBricks",
          "Importare i Notebook su DataBricks"
        ],
        "Il Resilient Distributed Dataset (RDD)": [
          "Introduzione al RDD",
          "Azioni del RDD",
          "MapReduce sul RDD",
          "Trasformazioni sul RDD",
          "RDD con chiave e valore"
        ],
        "(Laboratorio) Analisi di 22.5 Milioni di Recensioni su Amazon": [
          "Procuriamoci il Dataset",
          "Contiamo il numero di valutazioni",
          "Contiamo il numero di libri",
          "Contiamo il numero di valutazioni per libro",
          "Troviamo i 10 libri più valutati",
          "Calcoliamo la valutazione media per ogni libro",
          "Troviamo i 10 libri con la valutazione più alta",
          "Troviamo i 10 recensori più critici"
        ],
        "Il DataFrame": [
          "Introduzione al DataFrame",
          "Creazione di un DataFrame",
          "Modificare lo Schema di un DataFrame",
          "Operare su Righe e Colonne",
          "Filtri, Aggregazione e Ordinamento",
          "Query SQL su un DataFrame",
          "(Opzionale) Query SQL di Selezione"
        ],
        "(Laboratorio) Analisi di 28 milioni di Recensioni di Film": [
          "Procuriamoci il Dataset MovieLens",
          "Creiamo il DataFrame",
          "Correggiamo lo Schema",
          "Contiamo il numero di Recensioni Totali e la Media per Utente",
          "Troviamo l'Utente che ha Scritto più Recensioni",
          "Troviamo i 10 Film che hanno ricevuto più Recensioni",
          "Troviamo i 10 Film con le Recensioni più Positive e più Negative",
          "Troviamo le 10 Recensioni più Recenti",
          "Troviamo i Film più Visti ogni Anno",
          "Aggiungiamo Titolo e Genere alla lista dei Film più Visti"
        ],
        "(Laboratorio) Time Series - Analisi delle Azioni di Apple": [
          "Procuriamoci il Valore Giornaliero delle Azioni di Apple dal 1980 a Oggi",
          "Creiamo il DataFrame e Correggiamo lo Schema",
          "Troviamo i Valori Massimi e Minimi",
          "Troviamo i giorni in cui il Valore è stato inferiore ai 100 $",
          "Troviamo il Valore Massimo per ogni Anno",
          "Troviamo l'Anno con i Volumi Maggiori",
          "Calcoliamo la Variazione delle Azioni dopo il rilascio dell'iPhone"
        ]
      },
      "requirements": [
        "Nessun prerequisito particolare è richiesto, solo passione e voglia di imparare a lavorare con i Big Data"
      ],
      "description": "Impara a utilizzare le Ultime Tecnologie per l'Analisi dei Big Data con il linguaggio di Programmazione più popolare al mondo - Spark e Python !\nSiamo entrati nell'era dei Big Data, oggi i dati sono il nuovo petrolio e sapere come elaborarli e analizzarli vuol dire avere un posto di lavoro garantito in un futuro molto prossimo e un vantaggio competitivo enorme rispetto ai rivali in affari.\nIn questo corso impareremo a lavorare con i Big Data utilizzando Spark, il framework per il calcolo distribuito più popolare al mondo, usato in produzione da giganti come Amazon, Microsoft, Oracle, Verizon e Cisco.\n\n\nCosa faremo durante il corso ?\nNella prima sezione del corso introdurre l'argomento Big Data, vedendo cosa sono, da dover arrivano e come possono essere sfruttati.\nVedremo quali sono le principali tecnologie utilizzate per i Big Data: Apache Hadoop, Hadoop MapReduce e Spark, chiarendone le differenze, i punti deboli e i punti di forza.\nNella seconda sezione vedremo come installare e configurare Spark su una macchina locale, prima usando VirtualBox per creare una macchina simulata sulla quale installare Ubuntu, poi creando una macchina remota sfruttando gli Amazon Web Service, nello specifico AWS EC2.\nNella terza sezione impareremo a creare un cluster di macchine con Spark e lo faremo in due modi differenti:\nUsando AWS EMR (Elastic MapReduce)\nUsando DataBricks, piattaforma per l'analisi dei Big Data co-fondata dallo stesso creatore di Spark.\nNella quarta sezione studieremo la principale struttura dati di Spark: il Resilient Distributed Dataset (RDD), introducendo la teoria del suo funzionamento per poi eseguire qualche esercizio pratico per studiarne le API.\nNella quinta sezione ci sporcheremo le mani con il primo laboratorio in cui analizzeremo un dataset contenente 22.5 milioni di recensioni di prodotti su Amazon.\nNella sesta sezione introdurremo una struttura dati a più alto livello che Spark mette a disposizione dalle sue versioni più recenti: il DataFrame, parleremo brevemente della suo funzionamento per poi vedere come può essere utilizzato nella pratica. Vedremo anche come creare una tabella SQL partendo da un DataFrame per poi interrogarla con query di selezione.\nNella settima sezione svolgeremo un secondo laboratorio, usando un DataFrame per analizzare ben 28 milioni di recensioni di film.\nNell'ottava sezione parleremo di serie storiche (time series) e analizzeremo le azioni di Apple dal 1980 ad oggi.\nNella nona sezione parleremo di Machine Learning, scoprendo come funziona e a cosa serve e studiando i due modelli di base rispettivamente per modelli di Regressione e Classificazione:\nLa Regressione Lineare\nLa Regressione Logistica\nAl termine di questa sezione introdurremo il modulo MLlib (Machine Learning Library) di Spark, il quale ci permette di costruire modelli di Machine Learning distribuiti.\nNelle sezioni dieci e undici vedremo come utilizzare il modulo MLlib con le sue API per il Dataframe, per risolvere semplici problemi di regressione e classificazione, come:\nStimare il valore di abitazioni partendo dalle loro caratteristiche\nRiconoscere un tumore al seno maligno da un'agobiopsia\nNella sezione dodici utilizzeremo le conoscenze acquisite sul Machine Learning e MLlib per costruire un modello di Sentiment Analysis utilizzando il dataset di Yelp, il quale contiene oltre 5 GB di recensioni di locali e attività commerciali.\nPer addestrare il modello di Machine Learning sull'intero dataset così grande utilizzeremo un cluster AWS EMR, imparando a configurare un cluster e a importare grandi quantità di dati nel Hadoop File System (HDFS) da un bucket S3 utilizzando l'utility s3-dist-cp.\nNella nona sezione introdurremo uno delle estensioni più hot di Spark: Spark Streaming, che ci permette di analizzare ed elaborare flussi di dati in tempo reale !\nNella decima sezione svolgeremo un progetto usando Spark Streaming e le API di Twitter: monitoreremo tutti i tweets pubblicati in tempo reale, relativi ad un determinato argomento selezionato da noi, e creeremo un grafico interattivo con gli hashtags più popolari !\n\n\nPerché seguire questo corso ?\nI Big Data sono il futuro, sapere come sfruttarli sarà un vantaggio enorme, sia per un professionista che per un imprenditore, non perdere questa occasione !",
      "target_audience": [
        "Chiunque voglia imparare a elaborare grandi quantità di dati in maniera distribuita",
        "Chiunque voglia imparare a sfruttare il vantaggio competitivo dei Big Data"
      ]
    },
    {
      "title": "Python pour la Data Science et le Machine Learning en 4h",
      "url": "https://www.udemy.com/course/formation-python-data-science/",
      "bio": "Maîtriser Python pour la Data Science, le Machine Learning et l'IA en partant de zéro en seulement 4 heures.",
      "objectives": [
        "Acquérir des compétences solides en Python pour la Data Science et le Machine Learning, sans prérequis nécessaires.",
        "Réaliser des projets à la hauteur de ceux menés dans les entreprises ou les universités, en utilisant Python.",
        "Recevoir un certificat à la fin de la formation, attestant de votre compétence en Python.",
        "Écrire un code de qualité professionnelle en adoptant les meilleures pratiques de codage.",
        "Réussir ses examens, certifications et tests techniques avec Python pour la Data Science.",
        "Maîtriser les concepts essentiels pour devenir un Data Scientist / Machine Learning Engineer.",
        "Installer Python, Anaconda, Spyder et Jupyter Notebook sans aucun bug.",
        "Éviter les pièges de débutants en Python, Data Science et Machine Learning.",
        "Maîtriser la programmation Python comme un Data Scientist / Machine Learning Engineer expérimenté.",
        "Être capable de mener des missions de Data Science et de Machine Learning en tant que freelance, en utilisant Python.",
        "Découvrir les bibliothèques Python les plus utilisées dans le domaine de la Data Science comme Pandas, Scikit-Learn, NumPy, Matplotlib, Seaborn, SciPy, etc.",
        "Acquérir les compétences nécessaires pour travailler avec des entreprises qui utilisent Python (Amazon, Intel, Google, Meta, Netflix, Renault, Orange, etc.)."
      ],
      "course_content": {
        "Démarrer avec Python : Apprendre à programmer en Python en partant de zéro": [
          "Présentation : Apprendre la Data Science avec Python en 4 heures de A à Z",
          "Installation de Anaconda, Spyder et Jupyter Notebook",
          "Lien pour télécharger Anaconda, Spyder et Jupyter Notebook",
          "Présentation de l'interface de développement Python",
          "Présentation du projet de Data Science et Machine Learning avec Python"
        ],
        "Traitement des données et manipulations avec Pandas": [
          "Importation des données avec Python et bonnes pratiques avec Pandas",
          "Code pour importer les données sur Python avec Pandas",
          "Modification des noms sur les tableaux de données",
          "Traitement des valeurs manquantes (très important !)",
          "Recodage des données",
          "Avant de continuer...",
          "Télécharger le code Python"
        ],
        "Statistiques pour l'analyse de données": [
          "Obtenir les effectifs, les fréquences et les pourcentages",
          "Créer des tableaux statistiques",
          "Moyenne, écart-type, médiane, quartiles, minimum et maximum",
          "Télécharger le code Python"
        ],
        "Visualisation avancée des données, graphiques avec Matplotlib et Seaborn": [
          "Créer un diagramme à barres (seaborn countplot)",
          "Automatiser les diagrammes à barres avec une fonction Python",
          "Créer un histogramme pour les variables quantitatives (seaborn histplot)",
          "Graphiques croisés : comparer deux variables qualitatives",
          "Graphiques croisés : comparer une variable quantitative avec une qualitative",
          "Télécharger le code Python"
        ],
        "Tests d'hypothèses (ou tests statistiques) avec SciPy": [
          "Qu'est-ce qu'un test d'hypothèse / test statistique ?",
          "Analyse bivariée de deux variables qualitatives",
          "Analyse bivariée d'une variable quantitative avec une variable qualitative",
          "Avant de continuer...",
          "Test du Khi-Deux d'indépendance pour analyser la relation des variables",
          "Test de Shapiro-Wilk pour analyser la normalité des variables",
          "Test de Mann-Whitney pour analyser la relation des variables non-paramétriques",
          "Test de Student pour analyser la relation des variables paramétriques",
          "Télécharger le code Python"
        ],
        "Machine Learning : Faire des prédictions avec Scikit-Learn": [
          "Introduction : Régression logistique",
          "Transformation des données en variables binaires",
          "Répartir les données en données d'entraînement et de test",
          "Créer le modèle de Machine Learning",
          "Faire des prédictions à l'aide du Machine Learning",
          "Evaluer les performances du modèle avec une matrice de confusion",
          "Analyse ROC des prédictions réalisées",
          "Télécharger le code Python final"
        ],
        "Conclusion, conseils et remerciements": [
          "Fin du cours : merci de votre attention !",
          "Mes autres cours Udemy"
        ]
      },
      "requirements": [
        "Aucun prérequis n'est nécessaire pour suivre ce cours, nous verrons tout ensemble de A à Z."
      ],
      "description": "Programmer en Python pour la Data Science, le Machine Learning, la DataViz et l'Intelligence Artificielle\nCe cours a pour objectif de vous initier à la programmation en Python en lien avec les concepts essentiels du Big Data (Data Science, Machine Learning, IA, etc.). Il ne requiert aucun prérequis et vous permet d'atteindre un niveau solide en seulement 4 heures de formation.\nAcquérir des bases solides\nPlus besoin de partir à la chasse aux informations sur Google, l'essentiel de votre apprentissage est concentré dans ce cours.\nGagner du temps\nCe cours est conçu pour vous familiariser avec la Data Science et Python de manière rapide et efficace. Vous pourrez ainsi atteindre un niveau solide en seulement 4 heures de cours.\nUne formation qui va à votre rythme\nLes concepts sont présentés progressivement, à travers des exemples concrets issus de projets d'entreprises et d'universités, vous permettant d'appliquer ce que vous avez appris.\nCours récent et régulièrement mis à jour\nMis à jour récemment, ce cours est en adéquation avec les compétences actuellement recherchées par les entreprises.\nÉviter les pièges de débutants\nCe cours détaille les bonnes pratiques d'un Data Scientist expérimenté pour rédiger un code de qualité professionnelle.\nPréparation réussie pour vos examens, certifications et tests techniques sur Python\nLes exercices inclus dans ce cours constituent un excellent moyen de préparation pour vos examens, certifications et tests techniques en entreprise.\nTravailler pour les plus grandes entreprises\nDes entreprises prestigieuses telles qu'Intel, Google, Netflix, Spotify, Meta, mais aussi Renault, la SNCF, Orange, Total, Capgemini, sont actuellement à la recherche de Data Scientists expérimentés maîtrisant Python.\nSe former à des métiers actuellement recherchés\nAujourd'hui, la demande en Data Scientists, Data Engineers et autres professions liées au Big Data est élevée. C'est donc le moment idéal pour se former à ces métiers en forte demande.\nObtenir un certificat de fin de formation\nUn certificat attestant que vous avez suivi et complété le cours vous sera remis à l'issue de la formation.",
      "target_audience": [
        "Personnes qui n'ont pas ou peu d'expérience en programmation et qui cherchent à apprendre Python et la Data Science en partant de zéro.",
        "Personnes qui visent à travailler pour les plus grandes entreprises qui utilisent Python (Intel, Google, Meta, Netflix, Renault, Orange, Total, Thales, Dassault Aviation, Capgemini...).",
        "Personnes qui souhaitent candidater pour des offres d'emploi ou des missions freelance qui nécessitent la maîtrise de Python."
      ]
    },
    {
      "title": "Data Analytics using Python [2025] with 9 Projects in HINDI",
      "url": "https://www.udemy.com/course/data-analytics-using-python-with-9-projects-in-hindi/",
      "bio": "Master the Art of Data Analytics with Python in the Latest Techniques and Real-world Projects",
      "objectives": [
        "Understand the fundamental concepts and principles of data analytics.",
        "Learn how to manipulate, clean, and preprocess data using Python.",
        "Gain proficiency in using popular Python libraries for data analysis, such as NumPy, Pandas, and Matplotlib.",
        "Perform exploratory data analysis (EDA) to uncover patterns, trends, and relationships in datasets.",
        "Apply statistical methods and techniques to analyze data and draw meaningful conclusions.",
        "Develop skills in data visualization and create compelling charts, graphs, and visual representations.",
        "Understand the importance of data ethics and privacy in data analytics.",
        "Develop a portfolio of real-world data analytics projects to showcase your skills and expertise. Course Outline: Module 1: Introduction to Data Analytics and P"
      ],
      "course_content": {},
      "requirements": [
        "Basic understanding of programming concepts is recommended, but not mandatory.",
        "Familiarity with Python programming language is beneficial but not required."
      ],
      "description": "** Course updated on May 19, 2025. **\nThe Data Analytics using Python [2025] course is designed to equip participants with the necessary skills and knowledge to perform data analysis and gain valuable insights using Python programming language. This course is specifically tailored for the year 2025 and incorporates the latest tools, techniques, and industry best practices in data analytics. Through hands-on projects, participants will have the opportunity to apply their learning and develop practical data analytics skills.\nCourse Duration: This is an intensive 15+ hours course that covers a wide range of topics related to data analytics using Python. The course is structured in a way that allows participants to progress from foundational concepts to advanced techniques gradually.\nThe course is designed for students who are new to data analytics and Python. No prior experience with either is required. The course is taught by experienced data scientists who use a clear and engaging teaching style.\nThe course includes nine hands-on projects that give students the opportunity to apply what they have learned. The projects cover a variety of topics, including:\nProject 1 - Imputing Data Employee Salary\nProject 2 - Data Cleaning and Imputing Missing Values in FIFA19 Dataset\nProject 3- Virat Kohli Performance Analysis\nProject 4 -Movie Recommender System\nProject 5- Smartwatch Data Analysis\nProject 6- Analyzing the Growth of Indian Startups\nProject 7 - Fake News Detection using Python and Machine Learning\nProject 8 - Data Cleaning on Feedback Dataset\nProject 9 -  Hotel Demand Booking Dataset\n\n\nThe course is designed to help students develop the skills they need to become data analysts. By the end of the course, students will be able to:\nCollect and clean data\nAnalyze data using statistical and machine learning methods\nVisualize data in a clear and informative way\nBuild data models that can be used to make predictions\nThe Data Analytics using Python [2025] with 9 Projects course is a valuable resource for students who are interested in learning more about data analytics and Python. The course is comprehensive, hands-on, and taught by experienced data scientists.\nHere are some of the benefits of taking this course:\nLearn the basics of data analysis and Python\nApply what you learn in nine hands-on projects\nDevelop the skills you need to become a data analyst\nGet hands-on experience with popular data science tools and libraries\nLearn from experienced data scientists",
      "target_audience": [
        "Students and graduates seeking to enhance their data analytics skills",
        "Data analysts and data scientists",
        "Business analysts",
        "IT professionals/ Software Developers",
        "Anyone who wants to pursue career in Data Science and Analytics"
      ]
    },
    {
      "title": "Prompt Engineering: ChatGPT y otras AI para la productividad",
      "url": "https://www.udemy.com/course/prompt-engineering-chatgpt-y-otras-ai-para-la-productividad/",
      "bio": "Domina ChatGPT, Midjourney y otras AI para que tu productividad se incremente en el día a día",
      "objectives": [
        "Dominar las diferentes técnicas de prompting para ser más productivo con ChatGPT",
        "Entender el estado actual de los modelos de LLM's y cómo se pueden usar en nuestro día a día",
        "Desarrollar estrategias de estudio al rededor de chatGPT",
        "Investigar nuevas herramientas de Inteligencia artificial y cómo nos pueden ser útiles"
      ],
      "course_content": {
        "Introducción al curso": [
          "Presentación del Instructor Camilo Duarte",
          "Qúe es ChatGPT",
          "Qué es un LLM’s",
          "Qué es Prompt Engineering"
        ],
        "Prompts": [
          "Introducción a la sección 2",
          "Cuál es la estructura de un prompt",
          "Protección de datos y Confidencialidad",
          "Role Prompting (Actúa cómo)",
          "Zero Shot Prompting y Few shot prompting",
          "Chain of thoughts (CoE) Cadena de pensamientos",
          "Zero Shot Chain of thoughts",
          "Estructura de salida (Json, mapas mentales, Outline, Csv, Xls, Markdown, .ICS)"
        ],
        "Prompts avanzados": [
          "Introducción a la sección 3",
          "Sesgos y trampas de los LLM's",
          "Hiperparametros",
          "Generated Knowledge y Integration Knowledge",
          "De menos a Más",
          "Iterar"
        ],
        "Prompt Hacking": [
          "Introducción a la sección 4",
          "Role play Jailbreak",
          "Inyección de prompt",
          "Fuga de prompt",
          "Cómo detectar si un texto fue generado por una AI",
          "Medidas Defensivas"
        ],
        "Casos de Uso para la productividad": [
          "Introducción a la sección 5",
          "Conectar chatgpt a internet",
          "Copy redes sociales",
          "SEO para vender productos en linea",
          "Resumir textos",
          "Asistente personal",
          "Enviar y responder correos",
          "Emails Corporativos (HTML + CSS)",
          "Entrevistador tecnico",
          "Traductor avanzado",
          "Entrenador y nutricionista personal",
          "Planificador de viajes",
          "Medidor de sentimientos (Comentarios, tweets, posts)",
          "Creador de podcast",
          "Crear código"
        ],
        "Casos de Uso para estudiantes": [
          "Introducción a la sección 6",
          "ChatGPT Como mentor o tutor",
          "Experto en Active Recall",
          "Correcion de estilos",
          "Crear canciones-versos-poemas",
          "Prepararse para una entrevista",
          "Busqueda avanzada de trabajo"
        ],
        "Otras herramientas de AI para incrementar tu productividad": [
          "Introducción a la sección 7",
          "Whisper los oidos de la AI",
          "TOME app para crear ppts",
          "Dalle 2, Adobe Firefly, Stable Difussion, Midjourney y MS designer",
          "ChatPDF",
          "Eleven Labs Texto a Audio",
          "Adobe podcast"
        ],
        "Despedida del curso": [
          "Hasta Luego y Bonus"
        ]
      },
      "requirements": [
        "No se requiere experiencia o conocimientos previos, solo la disposición de aprender una herraienta que va a estar involucrada en nuestras vidas de aquí en adelante"
      ],
      "description": "¡Bienvenidos al curso de ChatGPT en español!\nChatGPT se está convirtiendo en una herramienta para la productividad que todos vamos a tener que aprender, así cómo en su momento fue Word o Excel, en este curso te voy a llevar paso a paso por todas las características que cuenta chatGPT. Este curso de chatGPT en español se centra en la productividad, vamos a ver cómo podemos utilizar la herramienta en nuestro día a día, existen varios casos de negocio para poner a prueba los límites de la herramienta.\nEn este curso, no solo aprenderás a usar la herramienta de inteligencia artificial de ChatGPT, sino que también aprenderás a utilizar la técnica avanzada de Prompt Engineering para sacar el mayor provecho de la herramienta y aumentar tu productividad.\nDurante el curso, te guiaré paso a paso para que puedas entender cómo funciona ChatGPT, cómo utilizar sus funciones y cómo aplicar las técnicas de Prompt Engineering para obtener mejores resultados en tus solicitudes.\nUna de las ventajas de este curso es que proporcionaré casos de uso específicos para empresarios y estudiantes, para que puedas aplicar fácilmente lo que aprendas en tu vida diaria. Aprenderás cómo utilizar ChatGPT para redactar correos electrónicos, informes, cartas de presentación y cualquier otro tipo de contenido que necesites para tu trabajo o estudio. También te mostraré cómo utilizar ChatGPT para realizar investigaciones y proyectos de una manera más rápida y efectiva.\nEn resumen, si estás interesado en aprender ChatGPT y en aprovechar al máximo sus capacidades, este curso es para ti. Únete hoy y comienza a aprender de una manera emocionante e interactiva para mejorar tu productividad y potenciar tus habilidades. ¡Te espero en clase!",
      "target_audience": [
        "Este curso es dirigido a emprendedores y empresarios que buscan optimizar su tiempo de trabajo y mejorar sus estrategias de automatización de procesos y generación de contenido",
        "Profesionales en áreas de tecnología, este curso puede ser muy útil para aquellos que trabajan en campos relacionados con la tecnología, como la programación, la ingeniería de software, la inteligencia artificial y la ciencia de datos",
        "Estudiantes, aquellos que quieran implementar la AI para mejorar su desempeño académico"
      ]
    },
    {
      "title": "Uczenie Maszynowe - Drzewa Decyzyjne i Lasy Losowe - Python",
      "url": "https://www.udemy.com/course/uczenie-maszynowe-python/",
      "bio": "Efektywne wykorzystanie Drzew Decyzyjnych i Lasów Losowych w analizie danych i podejmowaniu decyzji!",
      "objectives": [
        "podstawy uczenia maszynowego, rodzaje uczenia maszynowego i główne problemy",
        "jak działa algorytm drzew decyzyjnych (klasyfikacja i regresja)",
        "elementy składowe drzew decyzyjnych",
        "implementacja drzewa decyzyjnego od zera w języku Python",
        "budowa modeli drzew decyzyjnych i lasów losowych przy użyciu biblioteki scikit-learn",
        "ocena i optymalizacja modeli",
        "problemy uczenia maszynowego: niedouczenie, przeuczenie",
        "2 x case study"
      ],
      "course_content": {
        "Wstęp do Uczenia Maszynowego": [
          "Czym jest uczenie maszynowe?",
          "Rodzaje uczenia maszynowego i główne problemy"
        ],
        "Drzewa Decyzyjne - Wstęp": [
          "Klasyfikacja - przykład drzewa decyzyjnego - zbiór Iris",
          "Definicja i terminologia",
          "Budowa drzewa decyzyjnego",
          "Roadmap, wady i zalety drzew decyzyjnych"
        ],
        "Drzewa Decyzyjne - rzut oka na pierwszy model drzewa": [
          "Załadowanie danych",
          "Eksploracja danych cz. 1",
          "Eksploracja danych cz. 2",
          "Przygotowanie danych do modelu",
          "Budowa modelu drzewa decyzyjnego",
          "Budowa grafu drzewa decyzyjnego",
          "Automatyzacja budowy modelu drzew decyzyjnych"
        ],
        "Drzewa Decyzyjne - elementy składowe": [
          "Wskaźnik Giniego vs. Entropia",
          "Zysk Informacyjny",
          "Zysk Informacyjny - Przykład"
        ],
        "Klasyfikacja - implementacja drzewa decyzyjnego": [
          "Implementacja drzewa decyzyjnego - lekkie wprowadzenie cz. 1",
          "Implementacja drzewa decyzyjnego - lekkie wprowadzenie cz. 2",
          "Implementacja drzewa decyzyjnego - cz. 1",
          "Implementacja drzewa decyzyjnego - cz. 2",
          "Implementacja drzewa decyzyjnego - cz. 3",
          "Predykcja na podstawie modelu"
        ],
        "Niedouczenie i przeuczenie modelu": [
          "Przykład modelu niedouczonego i przeuczonego",
          "Przykład modelu niedouczonego i przeuczonego cz.2",
          "Wybór optymalnego modelu dzięki metodzie przeszukiwania siatki (Grid Search)"
        ],
        "Klasyfikacja - Case studies": [
          "Model predykcji choroby serca",
          "Model rezygnacji klientów - Churn Modelling cz. 1",
          "Model rezygnacji klientów - Churn Modelling cz. 2"
        ],
        "Drzewa Decyzyjne - Regresja": [
          "Model regresji drzew decyzyjnych"
        ],
        "Lasy Losowe - Uczenie Zespołowe": [
          "Uczenie Zespołowe (Ensemble Learning)",
          "Model lasu losowego",
          "Model lasu losowego - Iris dataset"
        ],
        "BOUNS": [
          "Bonus"
        ]
      },
      "requirements": [
        "Ukończone kursy ze ścieżki Python Developer na tym koncie instruktorskim",
        "Ukończone kursy ze ścieżki Data Scientist na tym koncie instruktorskim",
        "Podstawy statystyki i matematyki",
        "Wprowadzenie do uczenia maszynowego",
        "Środowisko Python do analizy danych"
      ],
      "description": "Chcesz nauczyć się jednych z najpopularniejszych algorytmów uczenia maszynowego? Ten kurs jest dla Ciebie! Drzewa decyzyjne oraz lasy losowe (Random Forest) to potężne narzędzia wykorzystywane w klasyfikacji i regresji, szczególnie tam, gdzie liczy się przejrzystość działania modelu i dobre wyniki bez konieczności skomplikowanej inżynierii cech.\nW tym praktycznym kursie poznasz od podstaw, jak działają drzewa decyzyjne i lasy losowe – zarówno od strony teoretycznej, jak i praktycznej, w języku Python. Omówimy najważniejsze pojęcia, takie jak entropia, zysk informacyjny, overfitting, pruning, bootstrap, bagging czy ważność cech. Przeprowadzimy Cię krok po kroku przez cały proces budowy modelu – od przygotowania danych, przez trenowanie i testowanie modelu, aż po ocenę wyników i optymalizację hiperparametrów.\nNie musisz mieć doświadczenia z machine learning – wystarczy podstawowa znajomość Pythona. Kurs zawiera praktyczne ćwiczenia i projekty z użyciem bibliotek takich jak scikit-learn, pandas i matplotlib, które pomogą Ci zbudować solidne podstawy w analizie danych i predykcji. Zapisz się i naucz się budować modele, które podejmują decyzje na podstawie danych!\n\n\nScikit-learn – Klasyczne uczenie maszynowe w zasięgu ręki\nScikit-learn to popularna biblioteka open source dla języka Python, oferująca zestaw narzędzi do klasycznego uczenia maszynowego. Zawiera gotowe algorytmy do klasyfikacji, regresji, klasteryzacji, redukcji wymiarowości oraz oceny modeli. Dzięki prostemu i spójnemu API, Scikit-learn doskonale sprawdza się w szybkich eksperymentach, edukacji i tworzeniu produkcyjnych rozwiązań opartych na danych.",
      "target_audience": [
        "Studenci informatyki, matematyki, analizy danych lub pokrewnych kierunków, którzy chcą zrozumieć i zastosować techniki uczenia maszynowego w praktyce.",
        "Początkujący analitycy danych i osoby wchodzące w świat Data Science, które chcą nauczyć się modeli drzew decyzyjnych i lasów losowych z wykorzystaniem języka Python.",
        "Programiści Pythona, którzy chcą poszerzyć swoje umiejętności o obszar uczenia maszynowego i analizy danych.",
        "Specjaliści ds. BI i analitycy biznesowi, którzy chcą lepiej zrozumieć działanie algorytmów predykcyjnych i zastosować je w analizie danych.",
        "Osoby przygotowujące się do ról takich jak: Data Analyst, Data Scientist, Machine Learning Engineer, które chcą zbudować solidne podstawy modeli drzewiastych.",
        "Pasjo­naci AI/ML i samoucy, którzy interesują się praktycznym zastosowaniem algorytmów klasyfikacji i regresji opartych na drzewach.",
        "Inżynierowie i naukowcy danych pracujący nad projektami wymagającymi interpretowalnych modeli, takich jak explainable AI (XAI)."
      ]
    },
    {
      "title": "Réalise un projet de Machine Learning avec Python en 2h",
      "url": "https://www.udemy.com/course/machine-learning-realiser-son-projet-en-python/",
      "bio": "Forme-toi rapidement aux différentes étapes des projets en Machine Learning avec Python pour la Data Science",
      "objectives": [
        "Devenir rapidement opérationnel en Machine Learning",
        "Se familiariser avec Python pour la Data Science",
        "Obtenir un cadre de résolution de problèmes en Data Science avec Python",
        "Résoudre un problème concret grâce au Machine Learning Python",
        "Utiliser et améliorer des algorithmes couramment utilisés",
        "Comprendre les challenges qu'un data scientist peut rencontrer"
      ],
      "course_content": {
        "Introduction au Machine Learning": [
          "Présentation du cours",
          "Data Science vs. Machine Learning",
          "Les différentes étapes d'un projet de Machine Learning"
        ],
        "Préparer son environnement de travail": [
          "Télécharger les logiciels de développement pour la Data Science",
          "Installer les librairies Python nécessaires au Machine Learning",
          "Lien pour télécharger les données",
          "Télécharger les données"
        ],
        "Explorer les données": [
          "Découvrir l'interface de l'IDE",
          "Charger les données dans l'IDE",
          "Manipuler les données en Python",
          "Feature engineering en Data Science",
          "Interpréter les mesures sur les données",
          "Créer des graphiques pour la visualisation de données",
          "Etudier la corrélation entre variables"
        ],
        "Préparer les données pour les algorithmes de Machine Learning": [
          "Etudier la variable prédite",
          "Séparer les données en train et test set",
          "Nettoyer les données grâce aux pipelines"
        ],
        "Entrainer ses modèles de Machine Learning": [
          "Focus sur la régression linéaire",
          "Entrainer son premier modèle de Machine Learning",
          "Tester la performance de son modèle de Machine Learning",
          "Focus sur les Random Forest Regressor",
          "Entrainer un autre modèle de Machine Learning",
          "Améliorer ses modèles avec la Grid Search",
          "Réussir ta reconversion en Data"
        ],
        "Transmettre ses résultats": [
          "Synthétiser les résultats importants"
        ],
        "Conclusion du cours": [
          "Résumé des différentes étapes d'un projet en Machine Learning",
          "Votre feedback sur le cours",
          "Session bonus"
        ]
      },
      "requirements": [
        "Connaissances en Python",
        "Bases en mathématiques et algèbre linéaire",
        "Être intéressé par la Data Science et le Machine Learning"
      ],
      "description": "En seulement 2 heures, tu sauras réaliser un projet de Machine Learning, du début à la fin.\nTu connaitras toutes les étapes d’un projet en Data Science et comment les mener à bien avec Python.\n\n\n--> Les e-mails privés\nLa Data est un domaine d'opportunités mais nécessite de solides compétences et certifications. J'aide les personnes qui veulent se reconvertir dans la Data, mais qui n'ont pas suivi les études adaptées, en leur proposant des programmes pratiques pour monter en compétences et se construire un profil recherché.\nEn t'inscrivant à ces e-mails, tu recevras toutes les infos sur les prochains cours live que j'organise (réservés aux membres), les nouvelles formations, mais également des réductions exclusives pour te former à moindre coût.\nPour rejoindre les e-mails privés (c'est gratuit !):\nRecherche l'URL suivante : \"school.damiench .com\" (en supprimant l'espace)\nSur LinkedIn : Damien Chambon\n\n\nJusqu’à présent, tu as sans doute appris beaucoup de choses sur la théorie du Machine Learning mais tu n'as aucune idée de comment les appliquer à des cas concrets.\nTu souhaites peut-être incorporer du Machine Learning dans tes projets professionnels pour améliorer tes résultats mais cela semble insurmontable.\nEn continuant comme ça, tu peux continuer à te documenter sur le Machine Learning sans passer à la pratique et perdre ainsi un temps fou. Pire, il se peut même que tu te décourages de cette discipline et que tu abandonnes.\n\n\nLe vrai problème, c’est qu’il y a beaucoup de choses à prendre en compte dans un projet de Data Science, de la collecte des données, à leur préparation, au choix du modèle en passant par l’optimisation de l’algorithme.\n\n\nLa solution à tout ça, c’est un plan clair avec des instructions simples à suivre, applicables à tout projet de Machine Learning et qui te permettent d'avoir des résultats le plus rapidement possible.\n\n\nC’est pourquoi j’ai voulu créer une formation complète, qui détaille toutes les étapes des projets de Machine Learning, du début à la fin, en les implémentant directement en Python.\nAttention, cette formation est intense, de nombreux concepts techniques sont couverts, ainsi que plusieurs librairies et fonctions Python. Il faut que tu sois motivé.\nIl faudra suivre avec attention les différentes étapes que je vais te présenter pour t’assurer que le résultat final soit intéressant.\n\n\nAprès avoir complété cette formation, tu sauras comment résoudre un problème grâce au Machine Learning et Python. Tu découvriras à quel point cette discipline peut être puissante.\nPeu importe le jeu de données qu'on pourra te confier : tu sauras comment utiliser des algorithmes de Machine Learning, simplement en suivant les différentes étapes présentées ici.\nUne fois embauché, tu auras de plus en plus d’idées de comment l’appliquer dans ta vie professionnelle.\n\n\nDans cette formation, tu découvriras la puissante technique qu’est le feature engineering.\nTu apprendras 3 techniques utilisées, simples mais puissantes, pour explorer des données.\nTu découvriras comment automatiser la préparation des données grâce à 4 outils utilisés par les data scientists.\nEnfin, tu apprendras comment améliorer significativement tes modèles, de manière automatique, avec une méthode très robuste.\n\n\nSi tu connais actuellement peu de modèles de Machine Learning, pas de soucis, j’explique l’intuition derrière les modèles que j’utilise. Cette formation convient aussi à ceux qui n’ont que quelques bases en Python car le code est expliqué au fur et à mesure.\nCe cours est un véritable guide pour tout projet de Machine Learning en Python.\n\n\nOn se retrouve dans la formation.\nA tout de suite,\nDamien",
      "target_audience": [
        "Débutants en Machine Learning et Data Science qui souhaitent être rapidement opérationnels",
        "Personnes qui souhaitent se reconvertir en Data Science"
      ]
    },
    {
      "title": "인공지능 기초 이론-머신러닝, 딥러닝에 대하여",
      "url": "https://www.udemy.com/course/oholopvt/",
      "bio": "실습으로 배우는 머신러닝과 딥러닝 개념 및 활용]",
      "objectives": [
        "머신러닝과 딥러닝의 개념과 정의",
        "머신러닝 용어와 각종 라이브러리",
        "선형 및 다중 회귀 모델",
        "로지스틱 회귀 모델",
        "의사결정나무",
        "랜덤 포레스트",
        "knn",
        "퍼셉트론",
        "행렬 기본과 인공신경망",
        "오차 역전파와 출력층",
        "CNN과 RNN"
      ],
      "course_content": {},
      "requirements": [
        "머신러닝과 딥러닝을 처음 접하는 사람들을 위한 강의입니다",
        "파이썬 및 기초통계에 대한 이해가 있으신 분들이 수강하시면 좋습니다"
      ],
      "description": "[실습으로 배우는 머신러닝과 딥러닝 개념 및 활용]\n본 코스는 머신러닝과 딥러닝의 기본적인 개념과 이론을 학습하실 수 있는 강의입니다. 강의를 통해 머신러닝 및 딥러닝의 핵심적인 이론 및 주요 모델들에 대한 이해 및 실습을 통한 활용 방법을 배우실 수 있습니다.\n대략적인 머신러닝과 딥러닝의 개념 및 이론들에 대한 지식이 필요한 분들은 모두 수강할 수 있지만, 가능하면 파이썬과 기초 통계 및 행력 등 수학적 지식에 대한 기본적인 이해와 활용이 가능하신 분들이 수강하시면 좋습니다.\n본 코스는 다음과 같은 내용들로 구성되어 있습니다.\n\n\n[목차]\n<머신러닝>\n머신러닝 개념 및 정의\n머신러닝 용어 및 라이브러리 정리\n선형 회귀 모델\n다중 선형 회귀\n선형 회귀 모델 구현, colab 설명\n로지스틱 회귀 모델 구현\n의사 결정 나무 구현\n랜덤 포레스트 구현\nknn 구현\ntrain valid test 데이터 나누기\n데이터 전처리\n최종 실습 - 타이타닉\n\n\n<딥러닝>\n딥러닝 개념 및 정의\n퍼셉트론\nXOR 문제\n코랩 사용법\n행렬 기본\n신경망\n오차 역전파\n출력층\n신경망 실습\nCNN 개념\nCNN 실습\nRNN 개념\nRNN 실습\n\n\n머신러닝과 딥러닝 학습이 필요하신 분들은 본 강의를 통해 많은 도움 얻어가시기 바랍니다.",
      "target_audience": [
        "머신러닝에 대한 개념이 궁금한 사람",
        "머신러닝 모델을 내 손으로 직접 구현해보고 싶은 사람",
        "딥러닝 모델과 신경망에 대한 학습이 필요한 사람"
      ]
    },
    {
      "title": "Super Curso Business Intelligence + SQL + Databricks: 3 em 1",
      "url": "https://www.udemy.com/course/super-curso-business-intelligence-sql-databricks-3-em-1/",
      "bio": "Aprenda neste curso os conceitos de BI, a Linguagem SQL na Prática e a solução de Big Data o Databricks",
      "objectives": [
        "Visualização para explorar resultados de consultas de diferentes perspectivas",
        "Construção de gráficos e Dashboards",
        "Unificação de dados em diversos formatos: texto, JSON, PARQUET, dentre outros",
        "Trabalhada por administrador da plataforma, analista de dados, cientista de dados e engenheiro de dados com diversas funcionalidades",
        "Aprendizado processamento distribuído em SPARK",
        "Entendo o que é Databricks File System (DBFS) seu sistema de arquivos",
        "Entendo sobre Cluster",
        "Aprendendo a gerenciar e criar Notebooks em R, SCALA, Python e SQL",
        "Executando scripts multilinguagens",
        "Gerenciando a ingestão de dados e análise de dados, gerando gráficos e dashboards",
        "Construindo na versão community",
        "Trabalhando com a biblioteca dbutils Python",
        "Integrando o Databricks ao Power BI",
        "Conceitos Básicos de Business Intelligence",
        "Fundamentos de Business Intelligence",
        "O que é um Data Warehouse",
        "O que é Staging Area, ETL, OLAP, Data Mart, Data Mining, Big Data",
        "BI (Business Intelligence) para Concursos",
        "Resolução de 50 questões de BI dos Principais Concursos",
        "Resumo BI em formato PDF com detalhes sobre todos os assuntos",
        "50 questões dos principais concursos públicos",
        "O que é Data Mining",
        "Definição sobre Big Data",
        "Consultar dados com SQL em Banco de Dados",
        "Restringir e Classificar Dados utilizando a linguagem SQL",
        "Inserir Dados com SQL no Banco de Dados",
        "Editar Dados com SQL no Banco de Dados",
        "Excluir Dados com SQL no Banco de Dados",
        "Utilizar a Linguagem SQL no Oracle",
        "Aprender o SQL para uso nos bancos de dados padrão ANSI",
        "Exploração de Dados"
      ],
      "course_content": {},
      "requirements": [
        "É importante que você conheça um pouco de Python, R, Scala, SQL, não haverá treinamento destas linguagens neste curso",
        "Importante conhecer execução de scripts em Python, R, Scala, SQL",
        "Noção Básica de Banco de Dados"
      ],
      "description": "Seja bem vindo a este incrível curso conceitos de BI, a Linguagem SQL na Prática e a solução de Big Data o Databricks,\nAqui neste treinamento você irá ter:\nResumo Business Intelligence\nAprenda os principais conceitos que te fará entender de forma objetiva e simples o que é BI (Business Intelligence). Entenda para que serve, como utilizar, a arquitetura, quais estruturas participam de um BI, quais ferramentas de BI gratuitas e pagas, e além disto você que está estudando para concursos gerais ou de TI terá acesso a um material direto com os termos mais cobrados dentro da área, seja Staging Area, Modelo Dimensional, OLTP, OLAP, ETL, Tabela Dimensão, Tabela Fato, Dashboard, Mineração de Dados, Big DATA, além de 50 questões de concursos comentadas.\n\n\nSQL na Prática\nUm curso prático para quem deseja abrir as portas para oportunidades em bancos de dados, a linguagem SQL é a principal linguagem quando falamos de consultas e manipulação em bancos relacionais como Oracle e SQL Server. Este curso é totalmente prático e trás os principais recursos para você que está no zero ou é iniciante no assunto, te preparando para utilizar da melhor forma os dados no principais SGBDS (Oracle, SQL Server, Postgres). Aprenda  realizar SELECT, WHERE, JOIN e muito mais.\n\n\nDatabricks\nAqui nesta parte você entrará em um nível mais avançado pensando em Exploração de Dados. O Databricks é uma solução voltada a manipulação de grandes dados, Big Data. É uma solução completa que possibilita o processamento através do Spark para uso de DataLakes, Aprendizagem de máquinas e manipulação com grandes dados. Neste treinamento aprenda com exemplos e práticas como utilizar o Databricks.\nEntão comece agora os conceitos de BI, a Linguagem SQL na Prática e a solução de Big Data o Databricks.\nVamos comecar?",
      "target_audience": [
        "Estudantes e profissionais de computação, Informática, estatística, data science, analista de dados, engenheiro de dados",
        "Profissionais de TI",
        "Concurseiros",
        "Profissionais que querem iniciar na área de Business Intelligence e BIG DATA"
      ]
    },
    {
      "title": "MCP: Baue Agenten mit Claude, Cursor, Flowise, Python & n8n",
      "url": "https://www.udemy.com/course/mcp-baue-agenten-mit-claude-cursor-flowise-python-n8n/",
      "bio": "Model Context Protocol: Entwickle KI-Agenten mit Python, n8n & LangChain – Server, Clients, Tools, Ressourcen & Prompts",
      "objectives": [
        "Einführung ins Model Context Protokoll (MCP), praktische Tipps zum Kursstart & wie LLMs durch Tools, Prompts und Ressourcen erweitert werden können",
        "MCP‑Grundlagen & Tool‑Integration in Claude Desktop: JSON‑Struktur verstehen, Server‑Typen vergleichen, Setup mit Node.js & Installation über den MCP‑Installer",
        "Eigene Workflows mit Claude Desktop bauen: Zugriff auf lokale Anwendungen, Integration von Datenbanken & API‑Key‑Anbindung für sichere Verbindungen",
        "Cursor & Vibe Coding mit MCP verknüpfen: Python‑Installation über pyenv, Cursor‑Interface verstehen, mit OpenAI oder Claude verbinden & MCPs flexibel verwenden",
        "API‑Keys & Zugriffskontrolle: Einrichtung für OpenAI, OpenRouter & mehr, Unterschiede in der Preisstruktur, Limitationen & Projekt‑Setup in Cursor verstehen",
        "MCP‑Server in n8n lokal hosten: Node.js Installation, Basics wie Trigger, Aktionen, MCP‑Client vs. Host verstehen & eigenen Server sicher konfigurieren",
        "n8n‑MCP‑Server erweitern: Verbindung zu Claude, Cursor oder GitHub‑Nodes herstellen, Zapier‑Funktionen kostenlos integrieren & Tools hinzufügen",
        "Vektordatenbanken in MCP einbinden: Pinecone automatisch über Google Drive verwalten, Workflows exportieren, RAG‑Agenten mit Vektorsuche entwickeln",
        "HTTP‑Anbindung & DSGVO‑konformes Hosting: HTTP‑Requests an MCP‑Server schicken, wenn kein offizielles MCP vorliegt, Hosting‑Lösungen & Best Practices",
        "MCP in Flowise, LangChain & LangGraph einsetzen: Flowise-Installation, Interface verstehen, Unterschiede zwischen Agenten‑Plattformen & Anwendungsbeispiele",
        "Tool‑Agenten mit MCP: Zugriff auf E‑Mails, Kalender, Airtable, Web‑Scraping & Pinecone-Datenbanken in Flowise integrieren für skalierbare Automatisierung",
        "Flowise AI Agents V2 & neue Möglichkeiten: Funktionen, LangGraph nutzen, SQLite als Record Manager verwenden & Tool‑Agenten mit Vektorzugriff kombinieren",
        "Spezial‑Workflows mit MCP erstellen: Sprachsteuerung für LLMs, Automatisierung in Blender, individuelle Bilderstellung über OpenAI & n8n Workflows",
        "Python‑MCP‑Server selbst entwickeln: Grundlagen der Server‑Programmierung, GitHub‑Repo verstehen, Tools einbinden & den MCP Inspector nutzen",
        "Eigene Prompt‑Vorlagen & Ressourcen definieren: Mit dem modelcontextprotocol Python SDK eigene Prompts und Datenstrukturen verwalten und Claude damit verbinden",
        "SSE‑Endpunkte für den MCP Server bauen: Echtzeit‑Verbindungen herstellen, eigene Tools über Events ansprechen & häufige Fehler bei der Server‑Entwicklung",
        "Sicherheitslücken im MCP verstehen & vermeiden: Tool‑Poisoning, MCP Rug Pulls, Jailbreaks & Prompt Injections erkennen und sichere MCP‑Strategien einsetzen",
        "Datenschutz, DSGVO & rechtliche Rahmenbedingungen beim MCP: Rechte & Pflichten beim Hosting, Datenverarbeitung & Einsatz von LLM‑Tools rechtlich absichern"
      ],
      "course_content": {
        "Einführung: Überblick, Tipps & das Model Context Protokoll verstehen": [
          "Willkommen!",
          "Kurs Überblick",
          "Wichtige Tipps für den Kurs",
          "Erklärung der Links für den Kurs",
          "Wichtige Links",
          "Dozentenvorstellung: Arnold Oberleiter (Arnie)",
          "Das Model Context Protokoll erklärt: Gib LLMs Tools, Prompts & Ressourcen",
          "Prompt Engineering Basics & Systemprompts"
        ],
        "MCP Basic Workflows mit Claude Desktop": [
          "Das lernst du in diesem Abschnitt zu den MCP-Basics",
          "Model Context Protokoll (MCP): Offizielle Dokumentation im Überblick",
          "Setup: Node.js, NVM und Claude Desktop schnell installiert",
          "Claude Desktop: Überblick über Interface & Einstellungen",
          "MCP in Claude Desktop integrieren – per JSON-Datei",
          "Mehrere MCP-Server schnell einrichten mit dem MCP Installer",
          "Quick-Tipp: Finde mehr MCP Server & Clients noch schneller auf GitHub",
          "MCP-Server im Überblick (Datenbanken, Prompts, Tools) & Zapier All-in-One-MCP",
          "Claude Desktop Zugriff zum Computer-Use geben und im Web klicken",
          "MCP-Server mit API-Key-Anbindung: So richtest du die Verbindung ein",
          "Recap zu Claude Desktop und MCP-Basics: Das solltest du dir merken"
        ],
        "MCP in Cursor integrieren & Python installieren – so geht’s": [
          "Das sehen wir uns in diesem Abschnitt an: Python, Cursor, Vibe Coding & API-Keys",
          "Python installieren & Versionen verwalten mit pyenv",
          "Cursor installieren: Interface kennenlernen & erstes Vibe Coding",
          "Cursor mit jedem MCP-Server verbinden: Zapier kostenlos nutzen, GitHub & mehr",
          "API Key erstellen: OpenAI API, Openrouter, Preise, Projekt-Setup, Verwaltung",
          "Limitationen des Model Context Protocols mit Cursor als Client",
          "Recap zu Cursor und dem MCP"
        ],
        "MCP in n8n: Eigenen Server erstellen, Hosting, Sicherheit & mehr": [
          "Das erwartet dich im n8n- & MCP-Abschnitt",
          "Lokale Installation von n8n mit Node.js und das Interface im Überblick",
          "Probleme beim Starten oder Installieren von n8n mit nvm lösen",
          "n8n-Updates machen lokal über Node.js",
          "n8n Basics: Trigger, Aktionen, Nodes MCP Client und Host",
          "MCP-Server erstellen in n8n und die Google Cloud Console",
          "n8n-MCP-Server mit verschiedenen Hosts verbinden: Claude, Cursor, n8n, Windsurf",
          "MCP-Server absichern: Authentifizierung richtig einrichten",
          "Tools für deinen MCP-Server hinzufügen & Zapier kostenlos in Claude nutzen",
          "Pinecone Vectordatenbank automatisch über Google Drive erstellen für n8n MCP",
          "Probleme bei Pinecone Embeddings",
          "n8n-Workflows einfach exportieren & importieren (JSON-Format)",
          "RAG-Agent bauen und Vektordatenbank im MCP-Server einbinden",
          "HTTP-Requests an den MCP-Server anschließen, wenn es keine MCPs gibt",
          "n8n DSGVO-konform hosten: Lösungen & Beispiele für gehostete KI-Apps",
          "GitHub-MCP-Server verknüpfen mit n8n dank der Community-Node",
          "Recap: Das solltest du dir merken"
        ],
        "MCP in Langchain, LangGraph & Flowsie": [
          "Das lernen wir in diesem Abschnitt",
          "MCP in LangChain, LangGraph und Flowise: Der Unterschied",
          "Installation von Flowise mit Node.js und Updates machen",
          "Flowise Interface & Marketplace: LangGraph leicht gemacht",
          "Tool-Agent in Flowise mit MCP: E-Mails, Kalender, Airtable, Websuche & mehr",
          "Pinecone-Vektordatenbank zum Tool-Agent für RAG (mit SQLite Record Manager)",
          "Flowise AI Agents V2 mit MCP",
          "Weitere Möglichkeiten in Flowise",
          "Recap zu LangChain / Flowise"
        ],
        "Spezielle Workflows: Automatisierung mit Blender, Bildgenerierung & mehr": [
          "Das sehen wir uns in diesem Abschnitt an",
          "Mit deinem LLM & MCP-Server sprechen – so geht’s per Spracheingabe",
          "Blender automatisieren mit MCP, Claude und Python",
          "MCP-Server für Bilderstellung erstellen (OpenAI API, n8n)",
          "Hast du coole MCP-Server oder Workflow-Ideen? Teile sie mit uns!"
        ],
        "MCP-Server selbst programmieren – Schritt für Schritt in Python": [
          "Das lernst du hier: MCP-Server mit Python & TypeScript programmieren",
          "Überblick über den Python-Code & das GitHub-Repository",
          "MCP Server in Python programmieren (Tools aufrufen) & der MCP Inspector",
          "Resources zum Python MCP-Server hinzufügen für Claude (Vibe Coding mit Cursor)",
          "Prompt-Templates zu deinem Server hinzufügen mit modelcontextprotocol python-sdk",
          "Claude mit eigenem Python-MCP-Server verbinden & Prompt Template Struktur",
          "Weitere Möglichkeiten, Tipps & die größten Fehler bei eigenen Servern",
          "Python-MCP-Server als Server-Sent-Events (SSE) Endpunkt nutzen",
          "Recap: Das solltest du dir merken"
        ],
        "Sicherheit, Datenschutz, DSGVO & Probleme bei MCP": [
          "Das lernen wir in diesem Abschnitt",
          "Einfaches Beispiel von einem Server, der Blödsinn macht",
          "Tool Poisoning, MCP Rug Pull und weitere Sicherheitslücken",
          "Typische Angriffe auf LLMs: Jailbreaks, Prompt Injections & Data Poisoning",
          "Rechtliche Grundlagen: Datenschutz, DSGVO & der EU AI Act im Überblick.",
          "Authentifizierung und API-Keys",
          "Vermeide versehentliches Löschen & ungewollten Vollzugriff für deinen Server",
          "Gesamtes Recap und mein DANKE",
          "Bonus"
        ]
      },
      "requirements": [
        "Keine Vorkenntnisse nötig, alles wird Schritt für Schritt gezeigt"
      ],
      "description": "Das Model Context Protocol (MCP) ist eine der spannendsten neuen Technologien im Bereich KI-Automatisierung und KI Agenten.\nDenn Large Language Models brauchen mehr als nur Prompts – sie brauchen Kontext, Tools und externe Ressourcen.\nMit MCP kannst du genau das bereitstellen.\n\nDoch wie funktioniert das in der Praxis?\nWie baust du eigene MCP‑Server?\nWie nutzt du Clients wie Claude Desktop, Cursor, n8n oder Flowise?\n\nUnd wie lässt sich das Ganze automatisieren, absichern, eigene Server erstellen und in KI‑Projekt einbauen?\n\n\nIn diesem Kurs lernst du es – Schritt für Schritt, klar erklärt, mit vielen Beispielen und direkt umsetzbar.\n\n\nGrundlagen: Das Model Context Protocol verstehen und einsetzen\nErhalte einen umfassenden Überblick über das MCP-Konzept, seine Funktionsweise und Einsatzmöglichkeiten.\nVerstehe, wie Tools, Prompts und Ressourcen über MCP an LLMs wie Claude, GPT oder Flowise angebunden werden.\nStarte direkt mit nützlichen Tipps, Materialien und einem eigenen Kurs-Hub voller Ressourcen und Link-Sammlungen.\nLerne die wichtigsten Prinzipien des Prompt Engineerings und wie Systemprompts im MCP-Kontext funktionieren.\n\n\nMCP in Claude Desktop integrieren und erste Server einrichten\nInstalliere Claude Desktop mit Node.js und NVM und konfiguriere erste eigene Serverstrukturen.\nNutze JSON-Dateien und den offiziellen MCP-Installer, um Tools, Datenbanken oder eigene APIs anzubinden.\nVerstehe verschiedene Server-Typen (Tool-Server, Prompt-Server, Datenbank-MCPs) und deren Anwendungsfälle.\nVerbinde Claude Desktop mit deinem lokalen System oder Online-Diensten und aktiviere API-Key-geschützte Funktionen.\n\n\nMCP mit Cursor, Vibe Coding und Python kombinieren\nRichte Cursor als flexiblen Client ein, verbinde ihn mit bestehenden MCP-Servern (z. B. Claude oder OpenAI)\nund erkunde die Limitierungen und Möglichkeiten im Vergleich zu Claude Desktop.\nNutze Vibe Coding und Python-gestützte Konfigurationen zur individuellen Erweiterung deiner MCP-Struktur.\nVerwalte API-Keys effizient, verstehe Preisstrukturen und realisiere dein eigenes Cross-Tool MCP-Setup.\n\n\nMCP-Server mit n8n erstellen, hosten und automatisieren\nLerne, wie du n8n lokal installierst, konfigurierst und als vollwertige MCP-Plattform nutzt.\nErstelle Trigger, Actions und verwende Custom Nodes für die Verbindung mit Claude, Cursor, GitHub oder Google Drive.\nIntegriere Pinecone und andere Vektordatenbanken für RAG-Agenten direkt in deinen MCP-Server.\nNutze Authentifizierungsoptionen und DSGVO-konforme Hosting-Strategien für deine eigenen Deployments.\n\n\nMCP in Flowise, LangChain und LangGraph nutzen\nInstalliere Flowise und erfahre, wie du mit Agent V2 komplexe Tool-Workflows (z. B. E-Mail, Kalender, Airtable, Websuche) erstellst.\nVerwende LangGraph zur Steuerung mehrstufiger Agentenprozesse mit klarer Rollenverteilung und Tool-Ausführung.\nVerwalte Pinecone-Datenbanken über SQLite, kombiniere LangChain-Funktionen und baue skalierbare Automatisierungen.\nNutze den Flowise Marketplace und kreiere eigene Assistants mit vollem MCP-Zugriff.\n\n\nSpezial‑Workflows und kreative MCP‑Projekte\nBaue Sprachschnittstellen zu deinem LLM auf und steuere deine KI mit Spracheingaben über MCP.\nAutomatisiere 3D‑Prozesse in Blender mithilfe von Claude, Python und deinem eigenen MCP‑Server.\nNutze die OpenAI API in Verbindung mit n8n zur Erstellung automatisierter Bild‑Workflows.\nTeile Ideen mit der Community und erhalte Inspiration für unkonventionelle oder kreative Anwendungen.\n\n\nEigene MCP‑Server in Python programmieren\nLerne, wie du mit Python und TypeScript eigene MCP‑Server schreibst – inklusive Ressourcen, Prompts und Tool‑Handling.\nVerwende das modelcontextprotocol Python SDK und entwickle eigene Prompt‑Templates mit Claude‑Kompatibilität.\nNutze den MCP Inspector zur Serverdiagnose und erweitere dein Setup um Server‑Sent‑Event‑Endpunkte (SSE).\nVermeide typische Fehler und erhalte Best Practices für eigene Serverprojekte, die zuverlässig laufen und sicher bleiben.\n\n\nSicherheit, Datenschutz und rechtliche Grundlagen\nErkenne und verstehe Bedrohungen wie Tool Poisoning, Jailbreaks, Prompt Injections oder den sogenannten MCP Rug Pull.\nSichere deinen MCP‑Server mit API‑Keys, Authentifizierung und Zugriffskontrolle ab.\nBeachte Datenschutzgrundlagen wie DSGVO, den EU AI Act und Herausforderungen beim Hosting generativer KI.\nErhalte konkrete Beispiele und Empfehlungen, wie du rechtlich und technisch auf der sicheren Seite bleibst.\n\n\nNach dem Kurs…\n...bist du in der Lage, MCP‑basierte Agenten zu bauen, zu hosten, zu programmieren oder in Tools wie Claude, n8n, Cursor oder Flowise zu integrieren.\nDu weißt, wie du MCP‑Server sicher erstellst, sinnvoll kombinierst, für deine Projekte nutzt und sogar als Dienstleistung anbietest.\nEgal ob für dein Business oder deine eigenen Ideen – dieser Kurs gibt dir die volle Kontrolle über das MCP‑Ökosystem.",
      "target_audience": [
        "KI‑Entwickler, Tech‑Tüftler und Automatisierungs‑Nerds, die das Model Context Protocol (MCP) verstehen, eigene Server bauen oder bestehende Clients wie Claude, Cursor, n8n oder Flowise erweitern wollen.",
        "Privatpersonen und KI‑Enthusiasten, die endlich verstehen möchten, wie LLMs durch Tools, Prompts und Ressourcen erweitert werden – und selbst erste MCP‑Agenten zum Laufen bringen wollen.",
        "Unternehmer und Selbstständige, die MCP‑basierte KI‑Workflows nutzen möchten, um Routineaufgaben zu automatisieren, Prozesse effizienter zu gestalten oder ein eigenes KI‑Serviceangebot zu schaffen.",
        "Softwareentwickler & Prompt-Engineers, die an der Schnittstelle zwischen LLM‑APIs, Tool‑Integration und Workflow‑Automatisierung arbeiten und MCP für eigene Projekte einsetzen möchten.",
        "Technik‑Begeisterte & KI‑Neulinge, die Tools wie Claude Desktop, Cursor, n8n oder Flowise kombinieren und tief in das MCP‑Ökosystem eintauchen wollen."
      ]
    },
    {
      "title": "Pacote Office Iniciantes & Power BI Iniciantes",
      "url": "https://www.udemy.com/course/pacote-office-iniciantes/",
      "bio": "Aprenda tudo que precisa dentro do nosso curso Pacote Office Iniciantes & Power BI Iniciantes",
      "objectives": [
        "Ms Office Word / Ms Office Excel / Ms Office Power Point",
        "VBA",
        "Macros",
        "Tabela e Gráfico dinâmico",
        "Modelagem Gráficos",
        "Dicas e Truques"
      ],
      "course_content": {
        "Ms Office Word": [
          "0-Introdução ao Microsoft Word",
          "1-Salvando Um documento no Word",
          "2-Formatação Colar,recortar, copiar Word",
          "3-Formatação de Texto Word",
          "5-Formatação de estilos Word",
          "6-Inserção de paginas Word",
          "7-Inserção Tabelas no Word",
          "8-Inserção Tabelas no Word soma",
          "9-Inserção de imagem Word",
          "10-Inserção de clipart Word",
          "11-Inserção de formas word",
          "12-Inserção de Smart Art word",
          "13-Insercção de hiperlink word",
          "14-cabeçalho e Rodapé Word",
          "15-Numero de paginas e Caixa de texto Word",
          "16-Partes rápidas e word art word",
          "17-Margens das folhas Word",
          "18-Configurações de paginas word",
          "19-Tabela Formulário - Parte 1",
          "20-Tabela Formulário Parte -2",
          "21- Tabela com calculo",
          "22-Tabelas Personalizadas",
          "23-Criando Mala Direta no Word"
        ],
        "Projeto autoformas - Microsoft word": [
          "1 - Criando layout com Autoforma dentro do Microsoft Word",
          "2 -Inserindo tabelas e informações na Autoforma -Word"
        ],
        "Conceito ABNT - Microsoft Word": [
          "1 - Margens ABNT - Microsoft Word",
          "2 - Fontes padrões ABNT - Microsoft Word",
          "3 - Espaçamento entre linhas ABNT - Microsoft Word",
          "4 - Espaçamento títulos e subseções ABNT - Microsoft Word",
          "5 - Recuo para citação acima de 3 linhas ABNT - Microsoft Word",
          "6 - Notas rodapé ABNT - Microsoft Word",
          "7 - Recuo paragrafo ABNT - Microsoft Word",
          "8 - Numeração de títulos ABNT - Microsoft Word",
          "9 - Capa de rosto e Sumario ABNT - Microsoft Word"
        ],
        "Dicas e truques Microsoft Word": [
          "1 - Destacando um trecho no Microsoft word - Dicas e truques word",
          "2 - Como fazer calculo no Microsoft Word - Dicas e truques Word",
          "3 - Destacando uma frase no Microsoft word - Dicas e truques de Word",
          "4 - Encontrar as ultimas modificações no microsoft word - word",
          "5 - Criando texto onde quiser na pagina Microsoft word - Diocas e truques word",
          "6 - Data e hora automático no microsoft word - Dicas e truques de word",
          "7 - Convertendo word em pdf - Dicas e truques word",
          "8 - Convertendo maiúscula e minúsculas Microsoft word - Dicas e truques word",
          "9 - Revelando formatação e tabulações ocultas no mirosoft word - Dicas e truques",
          "10 - Protegendo documento no microsoft word - Dicas e truques word",
          "11 - Deletando palavras inteiras com Atalho - Dicas e truques Microsoft word",
          "12 - Pesquisa web dentro do Microsoft Word -Dicas e truques Microsoft word",
          "13 - Como limpar formatação do Microsoft word - Dicas e truques Microsoft word",
          "14 - Diga ao Microsoft word o que deve fazer - Dicas e truques Microsoft word",
          "15 - Destacar palavra!frase!seção no Microsoft word - Dicas e truques Microsoft",
          "16 - Inserindo link no Microsoft word - Dicas e truques Microsoft word",
          "17 - Definido fontes e formatação padrão Microsoft word - Dicas e truques Micros",
          "18 - Usando Ditar automático Microsoft word - Dicas e truques Microsoft word",
          "19 - Assinado documento digital Microsoft word - Dicas e truques Microsoft word",
          "20 -Colocando Microsoft word em módulo de foco - Dicas e truques Microsoft word",
          "21 - Preenchimento relâmpago dentro Microsoft word para testar fontes - Dicas e",
          "22 - Como traduzir texto no Microsoft word - Dicas e truques Microsoft word",
          "23 - Utilizando templates prontos dentro do Microsoft word - Dicas e truques",
          "24 - Estatística de legibilidade Microsoft word - Dicas e truques Microsoft word",
          "25 - Definindo pasta padrão de salvamento Microsoft word - Dicas e truques micro",
          "26 -colocando logo tipo no cabeçalho - Dicas e truques Microsoft word",
          "27 - Como fazer Microsoft word ler nosso em voz alta - Dicas e truques Microsoft",
          "28 - Criando linhas Automáticas Microsoft Word - Dicas e truques",
          "29 - Atalho para aumentar fonte Microsoft word - Dicas e truques",
          "30 - Como extrair imagens de um documento word - Dicas e truques",
          "31 - Como substituir todas imagens do documento word - Dicas e truques",
          "32 - Como numerar tabelas Microsoft word - Dicas e truques",
          "33 - Criando texto em duas colunas Microsoft word - Dicas e truques",
          "34 - Gravando macro formatação Microsoft word - Dicas truques",
          "35 - Transpondo tabelas via Excel - Dicas e truque Microsoft word",
          "36 - Currículo no Microsoft word - Dicas e truques",
          "37- Utilizando comando reduzir paginas Microsoft word - Dicas e truques",
          "38 - Como fazer capturas de telas no Microsoft word - Dicas e truques"
        ],
        "Ms Office Excel": [
          "1-Introdução ao Microsoft excel",
          "2-Introdução Microsoft excel- salvar arquivo",
          "3-Introdução aos conceitos de Fórmulas excel",
          "Funções Aritmética Excel 2019",
          "5-Função-SE 2 Condições excel",
          "6-Função-SE 3 Condições excel",
          "7-Função cont.se 1 condição excel",
          "8-Função cont.ses 2 condição excel",
          "9-Função procv excel",
          "10-Função proch excel",
          "11-Função proc excel",
          "12-Função =hoje 1,2,3 condições",
          "13-Função concatenar unir dois textos excel",
          "14-Função concatenar três textos excel",
          "15-Função Agora e Função Combin excel",
          "16-Função MED,MAX,MIN, DIA UTEIS TRABALHO excel",
          "17-Função E Vinculada a Função SE excel",
          "18-Função ou Vinculada a Função SE excel",
          "19-Função ou isolada excel",
          "20-Função somar produtos excel",
          "21-Função soma se excel",
          "22-Função DATAM excel",
          "23-Função SE ERRO excel",
          "24-Função aleatório e aleatório entre excel",
          "25-Função Arrumar texto excel",
          "26-Função dia trabalho total excel",
          "27-Função Substituir l 1 condição excel",
          "28-Função Substituir infinitas condições excel",
          "29-Função mudar texto excel",
          "30-Função Extrair texto excel",
          "30-Função taxa A.M -A.A E VF excel",
          "31-Função PGTO A.M -A.A E VF excel",
          "32-Função NPER A.M -A.A E VF excel",
          "33-Função VP -Quitação empréstimos excel",
          "34-Função VP -Resgate de aplicação excel",
          "35-Função Cont valores 1 e 2 condição excel",
          "36-Função Cont Valores 1 e 2 Condição excel",
          "37-Função DATA DIF dia, mês, ano Excel",
          "38- Colocando Filtro tabela excel",
          "39-Criando tabela e gráficos - Parte 1",
          "40-Criando tabelas e formatando gráficos parte 2",
          "41-Criando tabelas e formatando gráficos parte 3",
          "42-Validação de dados, impedindo erros excel",
          "43- Colocando senhas na planilha excel",
          "44 -Usando hiperlink na planilha"
        ],
        "Gráficos Microsoft Excel": [
          "148 - INTRODUÇÃO GRÁFICO DE COLUNAS Excel 2019",
          "149 - GRAFICO BARRAS 2D E 3D Excel 2019",
          "150 - GRAFICO PIZZA 2D E 3D -Excel 2019",
          "151 - GRAFICO DE DISPERSÃO Excel 2019",
          "152 - GRAFICO DE AÇÕES Excel 2019",
          "153 - GRAFICO DE HIERARQUIA Excel 2019",
          "154 - GRAFICO EXPLOSÃO Excel 2019",
          "155 - GRAFICO HISTOGRAMA Excel 2019",
          "156 - GRAFICO DE PARETO Excel 2019",
          "157 - GRAFICO DE CASCATA Excel 2019",
          "158 - GRAFICO DE COMBINAÇÃO Excel 2019",
          "159 - GRAFICO COM FILTROS DE CONTROLE Excel 2019",
          "160 - GRAFICO PLOT BOX Excel 2019",
          "161 - MINI GRAFICO Excel 2019",
          "162 - GRAFICO FUNIL 6 SIGMA Excel 2019",
          "163 - GRAFICO LINHA 1 - Excel 2019",
          "164 - GRAFICO LINHA 2 - Excel 2019",
          "165 - GRAFICO LINHA 3 - Excel 2019",
          "166 - GRAFICO LINHAS 4 Excel 2019",
          "167 - GRAFICOS DISPERSAO Excel 2019",
          "168 - GRAFICO MAPA Excel 2019",
          "168.1 - GRAFICO MULTI CATEGORIAS Excel 2019",
          "170 - GRAFICO TERMOMETRO Excel 2019",
          "171 - GRAFICO VELOCIMETRO Excel 2019",
          "172 - GRAFICO VELOCIMETRO Excel 2019 - 2",
          "173 - GRAFICO AVATAR Excel 2019",
          "174 - GRAFICO PROGRESSIVO Excel 2019",
          "176 - GRAFICO DINAMICO COM CONTROLE DE VALORES ISOLADOS Excel 2019",
          "180 - GRAFICO DISPERSÃO COM CONDICIONAL Excel 2019",
          "181-1 GRAFICO ICEBERG Excel 2019"
        ],
        "Design de Gráficos - Microsoft Excel 2019": [
          "1 - Apresentação gráfico Pizza - Excel 2019",
          "2 - Apresentação gráfico colunas agrupadas Excel 2019",
          "3 - Apresentação gráficos colunas Excel 2019",
          "4 - Apresentação gráficos colunas avançado Excel 2019",
          "5 - Apresentação gráfico pizza metas Excel 2019"
        ],
        "Trabalhando com Macros Microsoft Excel": [
          "1 - INTRODUÇÃO MACROS Excel 2019",
          "2-MACRO DE FILTRAGEM Excel 2019 (2)",
          "3 - MACRO DE IMPRESSÃO ARQUIVOS Excel 2019",
          "4 -MACRO VINCULANDO TABELA E GRAFICO Excel 2019",
          "5 - MACROS RELATIVA E NAO RELATIVAS Excel 2019",
          "6 - FORMULARIO MACRO CLIENTES Excel 2019 (1)",
          "7 - FORMULARIO FORNECEDORES MACRO RELATIVA E ABSOLUTA Excel 2019",
          "8 - CADASTRO CLIENTES NAO LINEAR - PARTE 1 -Excel 2019",
          "9 - MACRO DE LIMPAR CELULA Excel 2019"
        ],
        "Tabela Dinâmica - Microsoft Excel": [
          "1 - Apresentação tabela Dinâmica - Excel 2019",
          "2- Apresentando layout tabela dinâmica -Excel 2019",
          "3 -Layout de segmentação de dados - Excel 2019",
          "4 - Analise da linha do tempo -Excel 2019",
          "5 - Formatação condicional tabela dinâmica -Excel 2019",
          "6 - Gráfico dinâmico tabela dinâmica - Excel 2019"
        ],
        "Bônus Analise técnica de Dados Excel 2019": [
          "1 - Classificação de Dados Excel 2019",
          "2 - Auto Filtro Excel 2019",
          "3 - Analise técnica de dados Filtro avançado Excel 2019",
          "4 - Analise técnica de Dados Excel 2019",
          "5 - Análise técnica de dados Subtotais Excel 2019"
        ]
      },
      "requirements": [
        "Usuário de computador, Plataforma Windows e muita vontade aprender."
      ],
      "description": "Ms Office Word\n1-Salvando Um documento no Word\n2-Formatação Colar,recortar, copiar Word\n3-Formatação de Texto Word\n4-Formatação de Paragrafo Word\n5-Formatação de estilos Word\n6-Inserção de paginas Word\n7-Inserção Tabelas no Word\n8-Inserção Tabelas no Word soma\n9-Inserção de imagem Word\n10-Inserção de clipart Word\n11-Inserção de formas word\n12-Inserção de Smart Art word\n13-Inserção de hiperlink word\n14-cabeçalho e Rodapé Word\n15-Numero de paginas e Caixa de texto Word\n16-Partes rápidas e word ART word\n17-Margens das folhas Word\n18-Configurações de paginas word\n19-Tabela Formulário - Parte 1\n20-Tabela Formulário Parte -2\n21- Tabela com calculo\n22-Tabelas Personalizadas\n\n\nMs Office Excel\n1-Introdução ao Microsoft Excel\n2-Introdução Microsoft Excel- salvar arquivo\n3-Introdução aos conceitos de Fórmulas Excel\n4-Trabalhando com Formulas aritméticas Excel\n5-Função-SE 2 Condições Excel\n6-Função-SE 3 Condições Excel\n7-Função cont-se 1 condição Excel\n8-Função cont-es 2 condição Excel\n9-Função procv Excel\n10-Função proch Excel\n11-Função proc Excel\n12-Função =hoje 1,2,3 condições\n13-Função concatenar unir dois textos Excel\n14-Função concatenar três textos Excel\n15-Função Agora e Função Combin Excel\n16-Função MED,MAX,MIN, DIA UTEIS TRABALHO Excel\n17-Função E Vinculada a Função SE Excel\n18-Função ou Vinculada a Função SE Excel\n19-Função ou isolada Excel\n20-Função somar produtos Excel\n21-Função soma-se Excel\n22-Função DATAM Excel\n23-Função SE ERRO Excel\n24-Função aleatório e aleatório entre Excel\n25-Função Arrumar texto Excel\n26-Função dia trabalho total Excel\n27-Função Substituir l 1 condição Excel\n28-Função Substituir infinitas condições Excel\n29-Função mudar texto Excel\n30-Função Extrair texto Excel\n30-Função taxa A.M -A.A E VF Excel\n31-Função PGTO A.M -A.A E VF Excel\n32-Função NPER A.M -A.A E VF Excel\n33-Função VP -Quitação empréstimos Excel\n34-Função VP -Resgate de aplicação Excel\n35-Função Cont valores 1 e 2 condição Excel\n36-Funçao Cont Valores 1 e 2 Condição Excel\n37-Função DATADIF dia, mês, ano Excel\n38- Colocando Filtro tabela Excel\n39-Criando tabela e gráficos - Parte 1\n40-Criando tabelas e formatando gráficos parte 2\n41-Criando tabelas e formatando gráficos parte 3\n42-Validação de dados, impedindo erros Excel\n43- Colocando senhas na planilha Excel\n\n\nMs Office Power Point\n0 - Apresentação do Curso\n1- Introdução ao Power Point\n1-1 Introdução a Guia Inicio Power Point\n1-2 Introdução Guia Inserir - Power Point\n1-3 Introdução a Guia Design\n1-4 Introdução a guia Animação\n1- Introdução ao Power Point\n2- Criando Slides\n3-Editando Slides\n4 - Colocando Vídeo no Slide\n5- Configurando Animação e Efeitos\n6 - Regulando tempo do Slides\n7 - Configurando Plano de Fundo\n8 -Formatando Titulo\n9 -Formatando Imagens\n10 - Animação em texto\n11 -Animação de texto sobre imagem\n12 - Animando carro no Power Print\n13-Efeito Mola no texto\n14- Inserindo uma  imagem Gif",
      "target_audience": [
        "Desenhistas, estudantes, todos que desejam utilizar as principais ferramentas do Pacote Office."
      ]
    },
    {
      "title": "Natural Language Processing für Data Science mit Python",
      "url": "https://www.udemy.com/course/natural-language-processing-mit-python/",
      "bio": "Lerne Machine Learning, SpaCy, NLTK, SciKit-Learn, Deep Learning, und mehr für Natural Language Processing",
      "objectives": [
        "Lerne, wie man in Python mit Textdateien arbeitet",
        "Lerne, wie man in Python mit PDF-Dateien arbeitet",
        "Verwende Regular Expressions für Mustersuche im Text",
        "Verwende SpaCy für ultra schnelle Tokenisierung",
        "Erfahre mehr über Stemming und Lemmatisierung",
        "Verstehe Wortschatz-Abgleich mit SpaCy",
        "Verwende Part of Speech Tagging, um Rohtext-Dateien automatisch zu verarbeiten",
        "Verstehe Named Entity Recognition",
        "Visualisiere POS und NER mit SpaCy",
        "Verwende SciKit-Learn zur Textklassifizierung",
        "Verwende Latent Dirichlet Allocation für Themenmodellierung (Topic Modelling)",
        "Erfahre mehr über Non-negative Matrix Factorization",
        "Verwende den Algorithmus Word2Vec",
        "Verwende NLTK für Stimmungsanalysen",
        "Verwende Deep Learning, um deinen eigenen Chat Bot zu erstellen"
      ],
      "course_content": {
        "Einführung": [
          "Willkommen zum Kurs NLP",
          "Hinweise zum Kurs",
          "Kursplan",
          "Kursmaterialien",
          "Einführung zur Installation",
          "Python und Anaconda Installation",
          "Wichtig Kurseinrichtung! Python Pakete mit Jupyter Notebook installieren",
          "FAQ - Frequently Asked Questions"
        ],
        "Python Textgrundlagen": [
          "Einführung in Python Textgrundlagen",
          "Arbeiten mit Textdateien mit Python - Teil 1",
          "Arbeiten mit Textdateien mit Python - Teil 2",
          "Arbeiten mit Textdateien mit Python - Teil 3",
          "Wichtig: PyPDF2-Version fixieren",
          "Arbeiten mit PDFs",
          "Regular Expressions - Teil 1",
          "Regular Expressions - Teil 2",
          "Python Textgrundlagen - Assessment Überblick",
          "Python Textgrundlagen - Assessment Lösungen"
        ],
        "Natural Language Processing Grundlagen": [
          "Einführung in Natural Language Processing",
          "Spacy Einrichtung und Überblick",
          "Was ist Natural Language Processing?",
          "SpaCy Grundlagen",
          "SpaCy Grundlagen - Teil 2",
          "Tokenisierung - Teil 1",
          "Tokenisierung - Teil 2",
          "Stemming",
          "Lemmatisierung",
          "Stopp-Wörter",
          "Phrasen-Matching und Wortschatz - Teil 1",
          "Phrasen-Matching und Wortschatz - Teil 2",
          "NLP Grundlagen Assessment Überblick",
          "NLP Grundlagen Assessment Lösungen"
        ],
        "Part of Speech Tagging und Named Entity Recognition": [
          "Einführung zum Abschnitt über POS und NER",
          "Part of Speech Tagging",
          "Visualisierung von Part of Speech",
          "Named Entity Recognition - Teil 1",
          "Named Entity Recognition - Teil 2",
          "Visualisierung von Named Entity Recognition",
          "Satzsegmentierung",
          "Part Of Speech Assessment - Überblick",
          "Part Of Speech Assessment - Lösungen"
        ],
        "Textklassifizierung": [
          "Einführung in Textklassifizierung",
          "Machine Learning Überblick",
          "Klassifikationskennzahlen",
          "Konfusionsmatrix",
          "Scikit-Learn Primer - Wie man SciKit-Learn verwendet",
          "Scikit-Learn Primer - Code Along Teil 1",
          "Scikit-Learn Primer - Code Along Teil 2",
          "Text Feature Extraction Überblick",
          "Text Feature Extraction - Code Along Implementierungen",
          "Text Feature Extraction - Code Along - Teil 2",
          "Textklassifizierung Code Along Projekt",
          "Textklassifizierung Assessment - Überblick",
          "Textklassifizierung Assessment - Lösungen"
        ],
        "Semantik und Stimmungsanalyse": [
          "Einführung in Semantik und Stimmungsanalyse",
          "Überblick über Semantik und Wortvektoren",
          "Semantik und Wortvektoren mit SpaCy",
          "Semantik und Wortvektoren mit SpaCy - Teil 2",
          "Stimmungsanalyse Überblick",
          "Stimmungsanalyse mit NLTK",
          "Stimmungsanalyse Code Along Filmbewertung Projekt",
          "Stimmungsanalyse Projekt Assessment",
          "Stimmungsanalyse Projekt Assessment- Lösungen"
        ],
        "Themenmodellierung": [
          "Einführung in den Abschnitt Themenmodellierung",
          "Überblick über Themenmodellierung",
          "Latent Dirichlet Allocation Überblick",
          "Latent Dirichlet Allocation mit Python - Teil 1",
          "Latent Dirichlet Allocation mit Python - Teil 2",
          "Non-negative Matrix Factorization Überblick",
          "Non-negative Matrix Factorization mit Python",
          "Themenmodellierung Projekt - Überblick",
          "Themenmodellierung Projekt - Lösungen"
        ],
        "Deep Learning für NLP": [
          "Einführung in Deep Learning für NLP",
          "Das Basic Perceptron Modell",
          "Einführung in Neuronale Netzwerke",
          "Unabhängige Normalisierung",
          "Keras Grundlagen - Teil 1",
          "Keras Grundlagen - Teil 2",
          "Rekurrente Neuronale Netzwerke Überblick",
          "LSTMs, GRU, und Textgenerierung",
          "Textgenerierung mit LSTMs mit Keras und Python - Teil 1",
          "Textgenerierung mit LSTMs mit Keras und Python - Teil 2",
          "Textgenerierung mit LSTMs mit Keras und Python - Teil 3"
        ],
        "Meilenstein Projekt": [
          "Einführung Abschlussprojekt",
          "Chat Bots Überblick",
          "Chat Bots erstellen mit Python - Teil 1",
          "Chat Bots erstellen mit Python - Teil 2",
          "Chat Bots erstellen mit Python - Teil 3",
          "Chat Bots erstellen mit Python - Teil 4"
        ],
        "Hurra! :-)": [
          "Vielen Dank!",
          "Bonus Lektion",
          "Wir freuen uns über Bewertungen :-) Danke!"
        ]
      },
      "requirements": [
        "Beherrsche die Grundlagen von Python",
        "Habe die Rechte, Python Packages auf dem Computer zu installieren",
        "Internetverbindung"
      ],
      "description": "Willkommen zum Natural Language Processing Kurs! Dieser Kurs wurde als deine vollständige Online-Anleitung entworfen, um dir die Verwendung von Natural Language Processing mit der Programmiersprache Python zu erklären.\n\n\n\"Es wird alles sehr verständlich erklärt und die Stimme ist sehr angenehm.\" (★★★★★L. Lafleur)\n\n\nWir beginnen mit den Grundlagen, du wirst lernen wie man Text- und PDF-Dateien mit Python öffnet und damit arbeitet, und lernen wie man Regular Expressions verwendet, um nach benutzerdefinierten Mustern innerhalb von Textdateien zu suchen.\nDanach sehen wir uns die Grundlagen von Natural Language Processing an. Dafür werden wir die Natural Language Toolkit Bibliothek für Python verwenden, sowie die neueste Version der SpaCy Bibliothek für schnelle Tokenisierung, Parsing, Entity Recognition und Lemmatisierung von Text.\nDu wirst fundamentale NLP Konzepte verstehen, wie zum Beispiel Wortstammerkennung (Stemming), Lemmatisierung, Stopp-Wörter, Phrasenabgleich, Tokenisierung und mehr!\nDanach schauen wir uns Part-of-Speech Tagging an, wobei deine Python Skripte in der Lage sein werden, Wörter im Text automatisch den zugehörigen Sprachbestandteilen (z.B. Nomen, Verben und Adjektive) zuzuordnen, was ein wesentlicher Bestandteil beim Erstellen intelligenter Sprachsysteme ist.\nWir werden auch mehr über Named Entity Recognition erfahren, was es deinem Code möglich macht, Konzepte wie Geld, Zeit, Unternehmen, Produkte und mehr zu verstehen, nur auf Basis der Textinformation.\nDurch aktuellste Visualisierungs-Bibliotheken können wir diese Beziehungen in Echtzeit beobachten.\nDann werden wir dazu übergehen, Machine Learning mit Scikit-Learn zu verstehen, um Textklassifizierung auszuführen. Unter anderem werden wir die automatische Erstellung von Machine Learning Systemen behandeln, die positive von negativen Filmkritiken unterscheiden können, oder Spam von echten Emails.\nWir werden dieses Wissen weiter vertiefen und durch komplexere unüberwachte Lernmethoden für NLP, wie Themenmodellierung, wobei unsere Machine Learning Modelle Themen und grobe Konzepte aus rohen Textdaten herausarbeiten können.\nDieser Kurs deckt auch fortgeschrittene Themen ab, wie die Stimmungsanalyse von Text mit der NLTK Bibliothek, und die Erstellung von semantischen Wortvektoren mit dem Algorithmus Word2Vec.\nIn diesem Kurs gib es einen ganzen Abschnitt für aktuellste fortgeschrittene Themen, wie Deep Learning zur Erstellung deines eigenen Chat Bots!\nAll das bekommst du mit einer 30 Tage Geld-zurück-Garantie, daher kannst du den Kurs risikofrei ausprobieren! Worauf wartest du noch?\nWir sehen uns im Kurs,\nRené\n\n\n\n\n\n\n* Dieser Kurs erfordert, dass du dir Anaconda herunterlädst. Wenn du Udemy-Business-Nutzer bist, kläre bitte vor dem Herunterladen mit deinem Arbeitgeber, ob die Installation erlaubt ist.",
      "target_audience": [
        "Python Entwickler, die sich für die Verwendung von Natural Language Processing interessieren"
      ]
    },
    {
      "title": "Machine Learning: Otimização de Hiperparâmetros com Python",
      "url": "https://www.udemy.com/course/machine-learning-otimizacao-de-hiperparametros-com-python/",
      "bio": "Aplicado em Ciência de Dados, Análise de Dados, Estatística, Economia, Engenharia, Machine Learning...",
      "objectives": [
        "Otimização de Hiperparâmetros de algoritmos de Machine Learning",
        "Grid Search",
        "Random Search",
        "Otimização Bayesiana",
        "Pré-processamento dos Dados",
        "Parâmetros e Hiperparâmetros",
        "Principais Hiperparâmetros de Árvore de Decisão, Random Forest, XGBoost, SVR ....",
        "Conceitos de Machine Learning",
        "Conceitos de Python"
      ],
      "course_content": {
        "Introdução": [
          "Boas vindas e apresentação do instrutor",
          "Apresentação do curso e da plataforma de estudos"
        ],
        "Fundamentos da Linguagem Python": [
          "A Linguagem Python",
          "Conhecendo o Google Colaboratory",
          "Instalação do Anaconda Python",
          "Conhecendo o Jupyter Notebook",
          "Primeiros passos",
          "Operadores Matemáticos",
          "Importações de bibliotecas e pacotes",
          "Estrutura condicional",
          "Estrutura de Repetição",
          "Listas, Tuplas e Dicionários",
          "Criação de Funções",
          "Função Lambda e função map",
          "List Comprehensions",
          "Arrays (Vetores e matrizes)"
        ],
        "Fundamentos de Machine Learning": [
          "Conceitos de Machine Learning",
          "Etapas para criação dos algoritmos",
          "Algoritmos de Classificação",
          "Algoritmos de Regressão",
          "Algoritmos de Agrupamento",
          "Algoritmos de associação",
          "Métricas de desempenho",
          "Criação de algoritmos no Python"
        ],
        "Otimização de hiperparâmetros: Classificação": [
          "Parâmetros e hiperparâmetros",
          "Regressão Logística",
          "Principais hiperparâmetros em Regressão Logística",
          "Ajuste manual: Regressão Logística: Parte 1",
          "Ajuste manual: Regressão Logística parte 2",
          "Árvore de Decisão (Decision Tree)",
          "Random Forest",
          "Principais hiperparâmetros em árvore de decisão e Random Forest",
          "Grid Search: conceitos",
          "Análise, Exploração e Tratamento dos Dados",
          "Pré-processamento dos dados",
          "Grid Search em árvore de decisão",
          "Random Search: conceitos",
          "Random Search em árvore de decisão",
          "Otimização Bayesiana: conceitos",
          "Otimização Bayesiana em árvore de decisão",
          "XGBoost",
          "Principais hiperparâmetros no XGBoost",
          "Tratamento dos dados",
          "Grid Search para XGBoost parte 1",
          "Grid Search para XGBoost parte 2",
          "Random Search para XGBoost",
          "Otimização Bayesiana para XGBoost"
        ],
        "Otimização de hiperparâmetros: Regressão": [
          "Máquinas de Vetores de Suporte (SVM)",
          "Análise, Exploração e tratamento dos dados",
          "Análise da Correlação Linear",
          "Pré-processamento",
          "Sem otimizar hiperparâmetros",
          "Principais hiperparâmetros do algoritmo SVR",
          "Grid Search para SVR",
          "Random Search para SVR",
          "Otimização Bayesiana para SVR"
        ],
        "Finalização do curso": [
          "Encerramento"
        ],
        "Referências Bibliográficas": [
          "Referências e links úteis"
        ]
      },
      "requirements": [
        "Não há pré-requisitos, porém é recomendado conhecer Machine Learning em nível básico."
      ],
      "description": "Com esse curso você terá a oportunidade de conhecer as principais técnicas de ajuste dos hiperparâmetros: Grid Search, Random Search e Otimização Bayesiana. Estas técnicas proporcionam a automatização das escolhas dos melhores hiperparâmetros dos algoritmos de Machine Learning, fazendo com que a criação do algoritmo seja mais rápida e eficiente e os resultados sejam os melhores possíveis.\nO diferencial desse curso é que iremos obter o embasamento teórico de maneira objetiva e teremos muitas aulas práticas sobre a otimização dos hiperparâmetros utilizando a linguagem Python e exemplificando através de datasets retirados de repositórios de dados. Todas as etapas serão explicadas, desde a obtenção dos datasets, como o tratamento, pré-processamento e a otimização dos hiperparâmetros.\nSerão explicados as características e os objetivos dos principais hiperparâmetros dos algoritmos de Machine Learning utilizados no curso.\nNão é um curso onde somente serão apresentados os comandos utilizados, tudo será explicado detalhadamente.\nPara atender a todos os alunos, sem importar a área e o nível de conhecimento, as duas primeiras seções são referentes aos fundamentos da Linguagem Python e conceitos de Machine Learning.\nO curso é apresentado no sistema operacional Windows, mas usuários do Linux e Mac acompanham tranquilamente. Será utilizado o Google Colaboratory, mas como opção podem ser utilizados também o Jupyter Notebook, Spyder e Pycharm.",
      "target_audience": [
        "Cientista de Dados",
        "Analista de Dados",
        "Estatístico",
        "Matemático",
        "Pesquisador",
        "Estudante de Ciência de Dados",
        "Economista",
        "Engenheiro"
      ]
    },
    {
      "title": "安心して学べるAWSデータレイク入門：S3からQuickSightまでステップバイステップ",
      "url": "https://www.udemy.com/course/awsdatalake/",
      "bio": "「データレイクとは？どうすればいいの？」という入門者の方が基礎からハンズオンで学ぶことでデータレイクの全体像を体感できる内容にしました。S3、Glue、Athena、QuickSightを使用したデータ分析基盤を始めるための入門コースです。",
      "objectives": [
        "データレイクの基礎と全体像について",
        "スモールスケールでのデータ分析基盤の構築ノウハウ",
        "Amazon S3にデータを保存する方法",
        "クエリサービスAmazon Athenaを用いたSQLによる集計方法",
        "BIツールAmazon QuickSightを使用してデータを可視化する方法",
        "AWS Glueを利用したETL処理とデータカタログの実装方法",
        "AWS IAMによるアクセス管理"
      ],
      "course_content": {
        "はじめに": [
          "このコースの学習内容について",
          "コースの注意事項",
          "コースの全体像"
        ],
        "データレイクの基本": [
          "このセクションで伝えたいこと",
          "データ基盤とは？",
          "データレイクとはなにか？",
          "データレイクの全体像と関連するAWSサービス"
        ],
        "ハンズオンの概要と準備": [
          "本コースで扱う構築事例",
          "AWS IAMについて",
          "ハンズオンの準備 Part1 IAMユーザーを作成する",
          "ハンズオンの準備 Part2 IAMロールを作成する"
        ],
        "S3 -データをストレージに保存-": [
          "Amazon S3ってなに？",
          "使用するサンプルデータ",
          "S3にバケットを作成",
          "ハンズオン用のフォルダを作成する",
          "データをアップロードする"
        ],
        "Glue -データの変換とカタログ化-": [
          "AWS Glueってなに？",
          "Glueジョブの基本設定",
          "S3のデータを抽出",
          "Change Schemaをつかったデータの変換",
          "SQL Queryによるデータの変換",
          "変換処理の結果をS3へロード",
          "Glueジョブを実行する",
          "注意事項: Glueジョブの実行について",
          "データカタログを作成する"
        ],
        "Athena -データ分析 Part1 アドホックな集計-": [
          "Amazon Athenaってなに？",
          "Athenaをはじめる",
          "ガイド",
          "SQLでデータを取得（SELECT, FROM, WHERE, LIMIT）",
          "集約関数を使ってみる（COUNT, SUM, AVG, MAX, MIN）",
          "AthenaのSQL関数活用（少し休憩しましょう）",
          "行をグループ化して集計（GROUP BY）",
          "グループ化した結果に条件を指定する（HAVING）",
          "検索結果を並べ替えてみる（ORDER BY）",
          "小テスト：SQLで簡単な分析をしてみよう",
          "サブクエリで複雑な問い合わせに対応",
          "サブクエリに名前をつける（WITH句）",
          "Athenaのデータ型（少し休憩しましょう）",
          "テーブルを結合（JOIN）",
          "複数のSQLクエリの結果を結合（UNION, UNION ALL）",
          "条件分岐でデータを変換してみる（CASE式）",
          "ウィンドウ関数で高度な操作",
          "SQLクエリ実行時に遭遇する一般的なエラー",
          "ビューを作成して仮想テーブルを保存しておく"
        ],
        "QuickSight -データ分析 Part2 ダッシュボードで可視化-": [
          "Amazon QuickSightってなに？",
          "QuickSightへサインアップ",
          "Athenaと連携してデータセットを作成",
          "分析でグラフを作成",
          "パラメータとコントロールの作成",
          "フィルタを作成",
          "寄与率を分析",
          "計算フィールドを追加してみる",
          "機械学習を活用した予測",
          "What-if 分析",
          "テキストの編集",
          "ダッシュボードの公開"
        ],
        "総括とこれから": [
          "本コースのまとめと次のステップ"
        ]
      },
      "requirements": [
        "AWSアカウント：任意（ハンズオンセクションで実際に操作を行いたい場合）",
        "OSの制限なし"
      ],
      "description": "データレイクでデータ分析基盤をはじめるための入門コース\nこのコースでは、データレイクのコンセプトについての理解から始め、クラウドサービスAWSを実際に操作して統合データ基盤の構築から活用までをステップバイステップで学びます。\n\n\nまずデータレイクのコンセプトを理解してから、実際に手で動かして学ぶことで、データレイクに関連するAWSサービスの知見を得ることと、データレイクの全体像を効率的に知ることを目的としています。\nデータ分析のためにはデータレイクってきくけど、そもそもデータレイクって何？や、データ基盤とデータレイクのイメージはわかるけど、具体的にどうしていけばいいのといった課題をAWSを使い学んでいくことができます。\n\n\n■本コースの内容\nデータレイクの基本\n最初にデータレイクとは何か、そしてデータ基盤としての重要性について詳しく解説します。このセクションを通じて、データレイクの概念を理解し、以降のハンズオンに向けた基礎知識を構築します。\nハンズオンの概要と準備\nこのセクションでは、データレイクの構築を行うための具体的な手順と、必要な事前準備（IAM設定含む）について説明します。これにより、スムーズに実践的な学習を進められるようになります。\nS3 -データをストレージに保存-\nAmazon S3を用いたデータの保存方法に焦点を当て、AWSサービスを実際に操作しながらデータのアップロードと管理を学びます。\nGlue -データの変換とカタログ化-\nAWS Glueを使用して、保存したデータを抽出・変換、ロードし、カタログ化する工程を学びます。このプロセスを通じて、データの整理とアクセスの効率化を理解します。\nAthena -データ分析 Part1 アドホックな集計-\nAmazon Athenaを利用したデータ分析を実践し、SQLクエリを用いてデータの集計や検索を行います。\nQuickSight -データ分析 Part2 ダッシュボードで可視化-\n最後に、QuickSightを使用してデータを可視化し、ダッシュボードを作成します。これにより、分析結果を効果的にプレゼンテーションできるようになります。\n\n\nこれらステップで、資料や実践的なセクションを通じて、わかりやすくイメージしやすい内容になっています。\nまた、本コースはGUIベースの操作を中心に進めるため、技術的な深い知識がなくても効率的に学習できます。\nコースを通じて、データレイクの全体像を掴み、データ保存から活用までの一連の流れを実装することが目標です。\n完了時には、データレイクに関する基本的な知識と技術が身についているはずです。\n\n\nデータエンジニアリングの世界を楽しみましょう！",
      "target_audience": [
        "データレイクの基本概念を学びたい初心者の方",
        "AWSでスモールなデータ基盤構築を検討しているデータエンジニア",
        "データレイクをビジネスに活用し、簡単な分析を試みたいと考える非エンジニアの方",
        "AWSのサービス（S3, Glue, Athena, QuickSight）を使ってみたい方"
      ]
    },
    {
      "title": "Machine Learning",
      "url": "https://www.udemy.com/course/machine-learning-u/",
      "bio": "Algoritmi di classificazione",
      "objectives": [
        "Distinguere le varie tipologie di problemi che il Machine Learning è in grado di risolvere, con esempi di applicazioni concrete",
        "Comprendere la differenza tra problemi di regressione e classificazione, con approfondimento di questi ultimi",
        "Tecniche di costruzione dei principali algoritmi di classificazione e metriche di valutazione"
      ],
      "course_content": {
        "Introduzione al Machine Learning e al concetto di classificazione": [
          "Breve introduzione al Machine Learning",
          "Apprendimento Supervisionato e Non Supervisionato",
          "Cos'è un problema di classificazione"
        ],
        "Algoritmi di Classificazione": [
          "K-Nearest Neighbours",
          "Naive Bayes Classifier",
          "Logistic Regression",
          "Support Vector Machine",
          "Decision Tree",
          "Random Forest"
        ],
        "Come misurare le performance degli algoritmi": [
          "Confusion Matrix",
          "ROC curve",
          "Funzione di Perdita"
        ],
        "Conclusione": [
          "Ricapitolando"
        ]
      },
      "requirements": [
        "Conoscenza dei concetti base di statistica predittiva (saranno comunque ripresi nel corso delle lezioni)",
        "Familiarità con alcuni termini tipici degli algoritmi di Machine Learning"
      ],
      "description": "Cos'è il Machine Learning e cosa si intende per 'algoritmi di classificazione'? Questo corso si propone di rispondere a queste domande attraverso due approcci, rispettivamente teorico e tecnico: da un lato, saranno forniti esempi di business cases concreti che dimostrino il valore aggiunto che modelli di Machine Learning possono conferire alle aziende; dall'altro, il corpus del corso sarà focalizzato sui modelli matematici che caratterizzano i principali algoritmi di classificazione, offrendo in ogni caso esempi intuitivi e di facile comprensione.\nAl termine di questo corso, gli studenti saranno in grado di apprezzare a pieno le potenzialità di questi strumenti,  oltre ad aver accumulato conoscenze e vocabolario necessari per approcciare un problema di classificazione dei dati con strumenti di Machine Learning.",
      "target_audience": [
        "Studenti universitari di materie economiche/scientifiche",
        "Chiunque sia curioso di approfondire alcune possibili applicazioni del Machine Learning",
        "Chiunque voglia approfondire la parte statistica e matematica dietro gli algoritmi di classificazione"
      ]
    },
    {
      "title": "ディープラーニング：SONYニューラルネットワークコンソール（NNC)による深層学習入門",
      "url": "https://www.udemy.com/course/sony-nnc/",
      "bio": "人工知能の勉強を始めるのなら、まずはここから。挫折経験者・文系でも大丈夫！マウス操作で入門者から機械学習・ Deep Learning（CNN・RNN）エンジニア・データサイエンティストの業務効率アップまで使える最強ツール",
      "objectives": [
        "機械学習の基礎知識と考え方の基本が身につき、画像認識などを実際に実装出来るようになる",
        "パーセプトロン、ニューラルネットワーク基礎から、CNN、RNNのようなディープラーニング（深層学習）の知識を網羅し、分類問題・回帰問題を実装できるようになる",
        "自分でニューラルネットワークを作成し実際に機械学習の仕組みを構築できるようになる",
        "ソニーのニューラルネットワークコンソールの使い方をマスターし業務に応用できるようになる",
        "機械学習エンジニア、データサイエンティストのシステム設計・検証などの業務効率アップ"
      ],
      "course_content": {},
      "requirements": [
        "Windows8.1以上(64bit)のOSを搭載したPC",
        "Macや、Linuxの場合は仮想環境とWindows8.1(64bit)のOS",
        "インターネットに接続できる環境とGoogle Chromeのようなブラウザ"
      ],
      "description": "この講座は深層学習（Deep Learning：ディープラーニング）を\nSONYのニューラルネットワークコンソール（以下NNC）を使ってを学ぶ講座です。\n\n\nNNCの最大の特徴は、プログラミングの知識がなくても容易にまた、\n無料で本格的な深層学習のシステムを構築することが出来る極めて画期的なツールであることです。\n\n\nどのくらい手軽かというと、NNCはすでにPython言語などで実装された深層学習のデータを読み取ったり、\n逆にNNCで作成した学習データをPython言語やC++言語でも容易に利用できるようになっています。\n\n\nそのため入門者だけではなく、本格的に業務などでAIや機械学習のシステムを構築・運用している人にとっても\nプロトタイピングやシステム設計などの時間と手間が節約できる大変役立つツールになっています。\n\n\n第三次AIブームの今、各業界で注目を浴びているこの技術を難しい数式や本格的プログラミング抜きで学んでみませんか？\n\n\nまた、このコースを終えると以下のようなスキルが身につきます。\n\n\nニューラルネットワークの基礎\n深層学習とは何か、根本的な理解\n自己符号化（Auto Encoder）\n畳み込みニューラルネットワーク（CNN：Convolutional Neural Network） を使って画像の分類・解析ができる\n再帰型ニューラルネットワーク:（RNN：Recurrent Neural Network） による時系列のある深層学習の実装方法が身につく\n\n\nそのため本講座で対象となる受講者は以下の通りです。\n\n\n深層学習に興味があるが数学やプログラミングの知識がない\n本で深層学習を学ぼうとしたが書籍が難しすぎて挫折した\nすでにPython言語などで深層学習を実装しているが作業をより効率化させたい\n\n\n本コースはこのような入門者をターゲットに作成されていますが、すでに深層学習を学びPython言語などでシステムを作っているが、\nより効率的なシステム開発を行いたい上級者にも満足して学んでもらえる内容になっています。",
      "target_audience": [
        "人工知能や深層学習に興味があり、学習したいと思っているものの数学やプログラミングの知識を持ち合わせていない",
        "ニューラルネットワーク・深層学習をすでに利用しているエンジニア・データサイエンティスト",
        "機械学習を学習している大学生・大学院生",
        "人工知能・深層学習などについて学びたいビジネスパーソン・エグゼクティブ",
        "深層学習の一種であるCNN、RNNを実際に詳しく体験してみたい初心者"
      ]
    },
    {
      "title": "Aprende R: Curso de Introducción a Data Science",
      "url": "https://www.udemy.com/course/aprende-r/",
      "bio": "Ciencia de datos con tidyverse",
      "objectives": [
        "Los estudiantes que toman este curso lograrán ver R como un lenguaje, al entender su gramática, estructura y sintáxis.",
        "Como trabajar con bases de datos muy grandes (Big Data)",
        "Manipular y transformar bases de datos con las funciones de tidyverse",
        "Generar visualizaciones de calidad",
        "Aplicar modelos estadísticos"
      ],
      "course_content": {},
      "requirements": [
        "Una computadora",
        "Instalar R y Rstudio",
        "4 gb de RAM"
      ],
      "description": "Este curso introductorio de R enseña los principios básicos y la lógica del lenguaje de R. Estudiantes después aprenderán a trabajar con los paqutes más actualizados del tidyverse para data wrangling, limpieza y transformación de bases de datos, generación de gráficos y reportes y también aprenderán a implementar algunos modelos con R.",
      "target_audience": [
        "Estudiantes cursando carreras de, pero no limitados a Economía, Matemática, Sociología, Estadística, Ingeniería, Business Intelligence, Data Science",
        "Profesionistas que desean aumentar sus capacidades aprendiendo nuevas habilidades",
        "Personas considerando comenzar una carrera de Data Science",
        "Cualquiera que esté interesado en temas como Big Data, Machine Learning, Data Wrangling, Visualización de datos, Análisis de Datos"
      ]
    },
    {
      "title": "【計算して実感する】 データサイエンスのための数学入門",
      "url": "https://www.udemy.com/course/math_for_datascience/",
      "bio": "豊富な例題を解き、Numpyと手計算の両方で数学を習得しよう",
      "objectives": [
        "データサイエンスに必要な数学を網羅的に学べる",
        "高校時代に習ったが忘れてしまった数学を復習できる",
        "データサイエンスにおける実際の数学の活用事例を知ることができる",
        "Numpyを用いてMSE, 正規方程式, 勾配降下法など重要な概念をスクラッチから実装できる"
      ],
      "course_content": {
        "はじめに": [
          "講座概要"
        ],
        "方程式の基礎": [
          "方程式"
        ],
        "数列の基礎": [
          "数列とは",
          "等差数列の和",
          "等比数列の和",
          "和の記号Σ"
        ],
        "関数の基礎": [
          "関数とは",
          "様々な関数",
          "冪乗の計算",
          "対数の計算",
          "三角関数の基礎",
          "三角関数の加法定理",
          "関数の組み合わせ"
        ],
        "ベクトルの基礎": [
          "ベクトルとは",
          "ベクトル空間",
          "ベクトルの内積",
          "ベクトルの1次結合",
          "ベクトルの1次独立"
        ],
        "確率論の基礎": [
          "確率とは",
          "確率の種類",
          "和事象・積事象・余事象",
          "条件付き確率・同時確率",
          "ベイズの定理",
          "期待値・分散",
          "期待値・分散の性質",
          "確率分布",
          "最尤推定"
        ],
        "微分・積分の基礎": [
          "極限の基礎",
          "微分とは",
          "微分係数",
          "極値の求め方",
          "積の微分",
          "合成関数の微分",
          "偏微分",
          "多変数関数の微分",
          "積分とは",
          "微分と積分",
          "様々な積分"
        ],
        "線形代数の基礎": [
          "行列とは",
          "行列の和・差",
          "行列の積",
          "様々な行列",
          "逆行列",
          "連立方程式と行列",
          "行列とベクトル"
        ],
        "データサイエンス演習": [
          "演習用データの配布",
          "MSEの計算（理論）",
          "MSEの計算(実践)",
          "最小二乗法 正規方程式 (理論)",
          "最小二乗法 正規方程式 (実践)",
          "最小二乗法 勾配降下法 (理論)",
          "最小二乗法 勾配降下法 (実践)",
          "情報エントロピー(理論)",
          "情報エントロピー(実践)",
          "ジニ不純度(理論)",
          "ジニ不純度(実践)",
          "様々な距離(理論)",
          "様々な距離(実践)"
        ]
      },
      "requirements": [
        "中学レベルの数学",
        "昔、高校で数学を習っている(ただし、忘れていてもOK)",
        "Pythonのプログラミングスキル"
      ],
      "description": "【本講座の概要】\n本講座はデータサイエンスを学ぶための数学力を身に付けるための講座です。\n普段、Scikit-learnやDeep Learningのライブラリ(TensorFlowやPyTorch)を利用している時は数学的な要素をライブラリが数学を上手くラップしてくれているので、そこまで数学を意識しないかもしれません。\n\n\nしかし、モデルの単純なfitで上手く行かない場合やモデルの中身を理解しようとすると途端に様々な数学が出てきます。\nこの場合に数学力が無いと自分の手で検証してみる、自分の足で一歩踏み出す、こういう事が難しくなります。\n\n\n\"自然は数学の言葉で書かれている\"とガリレオ・ガリレイは言いましたが、数学は自然科学やデータサイエンスを学ぶ上での共通言語のような存在です。\n\n\nこの為、数学の基礎を身に付けることが全ての出発点になるわけです。しかし、数学はいざ学ぼうと思っても数学の世界は広大です。どこから手を付けてよいのか、何を学べばよいのかも自明ではありません。数学の広大な世界を学んでいるうちにいつの間にか、データサイエンスを学ぶために数学を学ぶという本来の目的からずれてしまうかもしれません。\n\n\n本講座はデータサイエンスを学びたい人が必要な数学をなるべく効率よく、しかし網羅的に学べるようにカリキュラムを組んでいます。データサイエンスでは様々な数学が出てきます。関数、ベクトル、微分・積分、行列、確率論。\n\n\n本講座ではデータサイエンスに必要な数学に絞って解説をしています。また必要以上に高度な数学を学ぶ必要はありません。数学は基本的な事をしっかりと理解し、これを実践できるという事が大変重要です。難しそうな数学は単純にこれの組み合わせである事が多い為、基本的な要素を理解する、これが重要なのです。\n\n\nこの講座を受講する事で、データサイエンスに必要な数学力を最短・最速で学ぶことが可能です数学を効率よく学ぶにはインプットとアウトプットの両方が大切です。\n\n\n分かっていると、手が動かせるは別の次元の事なのです。この為、この講座では多くの例題を通して、アウトプットの機会を設けています。この時に、分かっていたつもりの事が実は理解が曖昧だったという事も分かります。\n\n\nまたこの講座はデータサイエンスのための数学入門です。\n最後のセクションでは学んできた数学をデータサイエンスに紐づけるために、データサイエンス演習のセクションを設けています。\n\n\nこのセクションは確率・微分・方程式など学習してきた内容を組み合わせてMSE, 勾配降下法や情報エントロピー・Gini不純度といったデータサイエンス頻出の内容を理解します。また、ただ分かるではなくデータサイエンスでは実装が求められるのでこれらをNumpyを使って実装していきます。\n\n\nこれらの演習を通して、データサイエンスで数学を使える状態に持っていきます。\nこの講座を完了するころには以前よりも数学に自信が付き、なおかつデータサイエンスの背後で動いているアルゴリズムについてより深い理解度や実装ができるようになっているはずです。\n\n\n\n\n【人事の方/マネージャークラスの方へ】\n本コースは次のような使い方が可能です。\n・社内で数学の基礎がしっかりしたAI人材を育成したい\n・効率よくプロレベルのデジタル人材を育成したい\n\n\n本コースはデータサイエンスのライブラリを表面的にツールとして使える人材ではなく、背後にある数学、アルゴリズムをしっかり理解できる人材に育てるために活用する事ができます。実際のＤＸの現場ではライブラリを使えば簡単に解決、こういうシーンは少なく、背後の数学を理解し、適切なモデル選択や必要に応じてスクラッチからの実装、損失関数の設計をできる人材が求められます。したがって、こういった基礎力は間違いなく重要になってきます。\n\n\n【対象者とゴール】\nこのコースは入門レベルであり、対象者は昔、高校時代に数学を学習したはずだが多くを忘れている方がデータサイエンスに入門する為の講座です。\n\n\n本コースのゴールは2つあります。\n1. データサイエンスに必要な数学の基礎をしっかり身に付ける\n2. 勾配降下法や情報エントロピー、不純度、KLダイバージェンスといった教科書によく出て内容を背後の数学とアルゴリズムを理解した上でNumpyなどで自力で実装できる実装力を身に付ける",
      "target_audience": [
        "データサイエンスに入門したいので必要な数学を学び直したい方",
        "既にデータサイエンスの職に従事しているが全てをライブラリ任せにしている方",
        "ディープラーニングのE資格にチャレンジする前に数学の基礎を固めておきたい方",
        "論文などのアルゴリズムを実装したいが数学が難しくて実装を諦めている方"
      ]
    },
    {
      "title": "Artificial Intelligence – Computer Vision w języku Python",
      "url": "https://www.udemy.com/course/artificial-intelligence-computer-vision/",
      "bio": "Odkryj moc sztucznej inteligencji: Computer Vision dla zaawansowanej analizy obrazów i rozpoznawania wzorców!",
      "objectives": [
        "praca z biblioteką OpenCV",
        "operacje na obrazie przy pomocy języka Python",
        "detekcja krawędzi i praca z konturami",
        "detekcja, rozpoznawanie i segmentacja obiektów",
        "skaner dokumentów - implementacja",
        "optyczne rozpoznawanie ocen - implementacja",
        "image scraping - budowa zbioru obrazów do modeli",
        "klasyfikacja obrazów",
        "klasyfikacja wieloetykietowa obrazów",
        "algorytm YOLOv3 - You Only Look Once",
        "framework Mask R-CNN - segmentacja obiektów",
        "Tensorflow Hub + Transfer Learning"
      ],
      "course_content": {},
      "requirements": [
        "Ukończone kursy ze ścieżki Python Developer na tym koncie instruktorskim",
        "Ukończone kursy ze ścieżki Data Scientist na tym koncie instruktorskim",
        "Podstawy matematyki i algebry liniowej",
        "Podstawy biblioteki NumPy",
        "Podstawowa wiedza z zakresu Sztucznej Inteligencji lub Machine Learning (mile widziana, ale niekonieczna)"
      ],
      "description": "Artificial Intelligence – Computer Vision w języku Python to praktyczny kurs, który wprowadza Cię w fascynujący świat wizji komputerowej – jednej z najdynamiczniej rozwijających się dziedzin sztucznej inteligencji. Kurs został zaprojektowany z myślą o osobach, które chcą nauczyć się tworzyć inteligentne aplikacje potrafiące \"widzieć\", analizować obrazy i wideo oraz podejmować decyzje na podstawie danych wizualnych.\nPodczas kursu nauczysz się, jak wykorzystywać biblioteki Python, takie jak OpenCV, NumPy, a także jak stosować głębokie uczenie z użyciem TensorFlow i Keras do zadań związanych z rozpoznawaniem obrazów, detekcją obiektów, segmentacją, śledzeniem ruchu czy analizą wideo w czasie rzeczywistym.\nDowiesz się między innymi:\nJak działa wizja komputerowa i gdzie znajduje zastosowanie (medycyna, motoryzacja, przemysł, bezpieczeństwo)\nJak przetwarzać i analizować obrazy cyfrowe\nJak wykorzystywać modele głębokiego uczenia do klasyfikacji i detekcji obiektów\nJak budować własne projekty CV krok po kroku\nKurs zawiera liczne ćwiczenia, projekty praktyczne oraz przykłady kodu, które umożliwiają szybkie opanowanie umiejętności i zastosowanie ich w realnych projektach. Niezależnie od tego, czy jesteś studentem, programistą, inżynierem, czy pasjonatem AI – ten kurs pomoże Ci postawić pewne kroki w świecie Computer Vision z Pythonem!\n\n\nOpenCV – Komputerowe widzenie na wyciągnięcie ręki\nOpenCV (Open Source Computer Vision Library) to otwartoźródłowa biblioteka służąca do przetwarzania obrazów i analizy wideo. Umożliwia wykonywanie złożonych operacji z zakresu widzenia komputerowego, takich jak wykrywanie obiektów, rozpoznawanie twarzy, analiza ruchu czy segmentacja obrazu. Dzięki wsparciu dla C++, Pythona oraz integracji z innymi bibliotekami AI, OpenCV jest szeroko stosowane w badaniach, przemyśle i aplikacjach mobilnych.\n\n\nTensorFlow – Moc obliczeń dla sztucznej inteligencji\nTensorFlow to otwartoźródłowa biblioteka do uczenia maszynowego i głębokiego uczenia, stworzona przez Google. Umożliwia łatwe budowanie, trenowanie i wdrażanie modeli AI na różnych platformach – od serwerów po urządzenia mobilne. Dzięki elastycznej architekturze i wsparciu dla GPU i TPU, TensorFlow jest popularnym wyborem wśród badaczy, inżynierów i firm rozwijających nowoczesne rozwiązania oparte na danych.\n\n\nKeras – Prostota tworzenia potężnych sieci neuronowych\nKeras to wysokopoziomowa biblioteka do budowy i trenowania modeli głębokiego uczenia, działająca jako interfejs dla TensorFlow. Zaprojektowana z myślą o prostocie i czytelności kodu, pozwala szybko prototypować zaawansowane sieci neuronowe przy minimalnym wysiłku programistycznym. Keras wspiera zarówno badania naukowe, jak i zastosowania produkcyjne, oferując intuicyjne API i bogaty zestaw narzędzi do analizy i wizualizacji modeli.",
      "target_audience": [
        "Data Scientists / AI Developers",
        "Inżynierowie uczenia maszynowego",
        "Inżynierowie systemów wizyjnych (CV)",
        "Programiści Pythona",
        "Studenci kierunków technicznych",
        "Hobbyści i pasjonaci sztucznej inteligencji"
      ]
    },
    {
      "title": "Apache Kafka: Real-Time Streaming für Big Data",
      "url": "https://www.udemy.com/course/apache-kafka-grundlagen/",
      "bio": "Lerne Streaming mit dem Apache Kafka Ecosystem für Big Data (mit Fallbeispielen)",
      "objectives": [
        "Verstehen von Apache Kafka Ökosystem, Architektur, Kernkonzepten und Operationen",
        "Erstellen und Empfangen von Nachrichten an/von Kafka und verwandten Servern",
        "Verstehe die Kafka Grundlagen wie Topics, Broker, Consumer, Producer, Broker",
        "Erstellen deine eigne Producer und Consumer in Python, um mit Kafka zu interagieren",
        "Verwende Kafka Connect als Schnittstelle zu deinen Datenbanken und Systemen",
        "Programmiere einen echten Twitter-Producer",
        "Wende das gelernte in Fallstudien und Praxisprojekten an",
        "Verstehe fortgeschrittenen Konzepte wie Zookeper, Replikation, Partitionen und Gruppen"
      ],
      "course_content": {
        "Einleitung": [
          "Willkommen im Apache Kafka Kurs",
          "Hinweise zum Kurs",
          "Was ist Kafka?",
          "Warum Kafka?",
          "FAQs - Häufig gestellte Fragen",
          "Kursmaterialien",
          "Merkblätter"
        ],
        "Installation": [
          "Willkommen zum Kursabschnitt \"Installation\"",
          "Installationsübersicht",
          "Windows Installation Docker Desktop",
          "Git Bash für Windows",
          "Mac OS Installation (Docker)",
          "Linux Installation (Docker)"
        ],
        "Linux Crashkurs": [
          "Willkommen zum Kursabschnitt \"Linux Crashkurs\"",
          "Linux Crashkurs Teil 1",
          "Linux Crashkurs Teil 2",
          "Linux Übungsaufgaben",
          "Linux Lösungen"
        ],
        "Apache Kafka Schnellstart": [
          "Willkommen zum Kursabschnitt \"Kafka Schnellstart\"",
          "Übersicht",
          "Zookeeper",
          "Kafka Broker",
          "Kafka Cluster Setup",
          "Kafka Cluster Verbinden",
          "Kafka Topics",
          "Kafka Producer",
          "Kafka Consumer",
          "Wiederholung Apache Kafka Schnellstart",
          "Übungsaufgaben",
          "Lösungen"
        ],
        "Kafka fortgeschritten": [
          "Willkommen zum Kursabschnitt \"Kafka fortgeschritten\"",
          "Kafka Replikation Übersicht",
          "Kafka Replikation Beispiel",
          "Kafka Offset",
          "Kafka Partitionen Übersicht",
          "Kafka Partitionen Beispiel (Teil 1)",
          "Kafka Partitionen Beispiel (Teil 2)",
          "Kafka Consumer Groups Übersicht",
          "Kafka Consumer Groups Beispiel (Teil 1)",
          "Kafka Consumer Groups Beispiel (Teil 2)",
          "Fallbeispiel Banktransfers Einleitung",
          "Fallbeispiel Banktransfers Umsetzung",
          "Zusammenfassung der fortgeschrittenen Themen",
          "Wiederholung zum Abschnitt Kafka Fortgeschritten",
          "Übungsaufgaben",
          "Lösungen"
        ],
        "Kafka Connect": [
          "Willkommen zum Kursabschnitt \"Kafka Connect\"",
          "Kafka Connect - Einführung",
          "Kafka Connect - Beispiel",
          "Kafka Connect - Transformation",
          "Kafka Connect - Verteilter Modus",
          "Kleine Wiederholung zu Kafka Connect",
          "Kafka Connect - Fallbeispiel",
          "Kafka Connect - Fallbeispiel Umsetzung",
          "Übungsaufgabe",
          "Lösungen"
        ],
        "Kafka Programmierung mit Python": [
          "Willkommen zu unserem Abschlussprojekt",
          "Kafka Programmierung - Einführung",
          "Kafka Programmierung - Python Setup",
          "Kafka Programmierung - Python Consumer",
          "Kafka Programmierung - Python Producer",
          "Praxisprojekt - Twitter mit Python und Kafka - Einführung",
          "Praxisprojekt - Twitter mit Python und Kafka - Teil 1",
          "Praxisprojekt - Twitter mit Python und Kafka - Teil 2",
          "Übungsaufgaben",
          "Lösungen"
        ],
        "Schluss": [
          "Danke",
          "Bonus Lektion",
          "Wir freuen uns über Bewertungen :-) Danke!"
        ]
      },
      "requirements": [
        "Es ist von Vorteil etwas Kenntnisse über Linux-Befehle zu haben",
        "Grundlagen von Python, Java oder eine andere Progamiersprache für das Kapitel Programmierung",
        "Eine aktuelle Windows / Mac / Linux PC mit mindestens 4 GB RAM, 5 GB Speicherplatz"
      ],
      "description": "Erfolgreiches Lernen von Apache Kafka: schneller, effektiver Einstieg.\nDu hast sicherlich schon viel über Apache Kafka gehört und möchtest nun in die Tiefe gehen, weißt aber nicht genau, wo du beginnen sollst? Dieser Kurs ist genau das Richtige für dich! Hier erhältst du alle entscheidenden Grundlagen in praxisnahen Beispielen vermittelt.\n\n\nWarum Apache Kafka?\nApache Kafka hat sich als führende Plattform für verteiltes Daten-Streaming in der Welt der Big Data etabliert. Es wird von mehr als 33% der Fortune 500-Unternehmen sowie von DAX-Unternehmen wie Volkswagen, Netflix, Airbnb, Uber und LinkedIn in der Produktion eingesetzt.\n\n\nWas du in diesem Kurs lernen wirst:\nGrundlegende Konzepte von Apache Kafka: Verstehen, wie Kafka funktioniert und wie Nachrichten gesendet und empfangen werden.\nInstallation und Betrieb von Kafka-Servern: Lerne, wie du Kafka aufsetzt, betreibst und Cluster bereitstellst.\nAnwendung von Produzenten und Consumern: Vertiefe dich in die Nutzung von Produzenten und Konsumenten in Kafka.\nIntegration mit anderen Technologien: Erfahre, wie Kafka mit Echtzeitanwendungen und Big Data-Technologien interagiert und erforsche Verbindungen und Schnittstellen zu anderen Systemen und Datenbanken.\nAnbindung (Python): Lerne, wie du dich mit Kafka mithilfe von Python verbindest.\n\n\nUnsere Lernstruktur:\nKafka Schnellstart: Einstieg in die Grundkonzepte von Kafka.\nFortgeschrittene Themen: Vertiefung in komplexere Aspekte von Kafka.\nIntegration und Schnittstellen: Verbindung mit anderen Systemen und Datenbanken und Programmiersprachen\nPraktische Anwendungen: Erstellung von eigenen Projekten und Nutzung von Konnektoren zur Datenübertragung.\n\n\nGarantierte Zufriedenheit:\nWir bieten eine 30-tägige Geld-zurück-Garantie. Zögere nicht länger! Melde dich jetzt an und wir freuen uns darauf, dich im Kurs zu begrüßen.\n\n\n\n\n\n\n* Dieser Kurs erfordert möglicherweise, dass du dir Java, Zookeeper, Kafka und Docker Desktop herunterlädst. Wenn du Udemy-Business-Nutzer bist, kläre bitte vor dem Herunterladen mit deinem Arbeitgeber, ob die Installation erlaubt ist.",
      "target_audience": [
        "• Entwickler, die Apache Kafka Grundlagen erlernen, einen Kafka Cluster starten und ihre erste Anwendung schreiben möchten",
        "• Architekten, die verstehen wollen, wie Apache Kafka in ihre Lösungsarchitektur passt",
        "• Jeder, der die vollständige Theorie der Funktionsweise von Apache Kafka als verteiltes System erlernen möchte"
      ]
    },
    {
      "title": "Python para Ciencia de Datos y Machine Learning",
      "url": "https://www.udemy.com/course/python-para-ciencia-de-datos/",
      "bio": "Análisis de datos hecho de una forma sencilla usando uno de los lenguajes de programación más populares: Python!",
      "objectives": [
        "Al finalizar el curso, el estudiante podrá utilizar las herramientas más importantes de Python para hacer ciencia y análisis de datos",
        "Programar algoritmos de aprendizaje de máquina (Machine Learning) para hacer predicciones de forma automática",
        "Procesar texto mediante técnicas de procesamiento de lenguaje natural (NLTK)",
        "Procesar información para extraer información relevante y valiosa de bases de datos"
      ],
      "course_content": {
        "Introducción": [
          "Introducción"
        ],
        "Anaconda y Jupyter": [
          "Instalando Anaconda en Windows",
          "Introducción a Jupyter",
          "Uso de Jupyter"
        ],
        "Conceptos básicos de Python": [
          "Introducción a Python",
          "Listas",
          "Tuples",
          "Ciclo For",
          "Condicionales y ciclo for",
          "Aleatorios, funciones y ciclo while",
          "Diccionarios"
        ],
        "Numpy y Pandas": [
          "Introducción a Numpy",
          "Operaciones con Numpy",
          "Introducción a Pandas",
          "Pandas + Excel"
        ],
        "Visualización de Datos": [
          "Gráfico de Barras",
          "Gráfico de línea e histograma",
          "Gráfico de dispersión, ejemplo #1",
          "Gráfico de dispersión, ejemplo # 2"
        ],
        "Aprendizaje de máquina": [
          "Aprendizaje supervisado y algoritmo Naive Bayes",
          "Máquinas de Vector Soporte",
          "Árboles de decisión",
          "Métodos compuestos - ensemble"
        ],
        "Procesamiento de Lenguaje Natural": [
          "Introducción a NLTK",
          "Stopwords y Stemmers",
          "Ejemplo de textos con NLTK",
          "Introducción a reseñas de películas [Ejemplo NLTK]",
          "Pre procesamiento de textos",
          "Visualización de datos de textos",
          "Entrenamiento de un clasificador Naive Bayes",
          "Uso real del clasificador Naive Bayes"
        ]
      },
      "requirements": [
        "Tener un computador con internet",
        "Tener conocimientos básicos de programación",
        "Tener ganas de aprender ciencia de datos"
      ],
      "description": "Este es un curso que pretende mostrarle al estudiante las herramientas necesarias para todo el ciclo de la ciencia de datos y machine learning, usando el lenguaje de programación de Python. Se recomienda tener algunas nociones de programación, pero a lo largo del curso se introducirán los temas necesarios para lograr hacer ciencia de datos abarcando temas sencillos como exploración de datos en gráficas hasta aprendizaje de máquinas y análisis de sentimientos en texto escrito en lenguaje natural.",
      "target_audience": [
        "Cualquier persona que desee aprender sobre ciencia de datos con Python"
      ]
    },
    {
      "title": "모두를 위한 ChatGPT Part 4 - ChatGPT와 실습으로 배우는 크롤링",
      "url": "https://www.udemy.com/course/crawling-using-chatgpt-part4/",
      "bio": "ChatGPT를 이용해서 다양한 웹사이트를 크롤링 해보자",
      "objectives": [
        "ChatGPT를 이용한 크롤링 방법",
        "다양한 웹사이트를 크롤링하는 방법",
        "크롤링을 위한 Requests, BeautifulSoup, Selenium 라이브러리 사용법",
        "크롤링의 원리와 내가 원하는 웹사이트를 크롤링하는 방법"
      ],
      "course_content": {
        "크롤링 개요": [
          "크롤링이란",
          "크롤링의 동작원리",
          "크롤링을 위한 Python 라이브러리들 - Requests, BeautifulSoup, Selenium",
          "ChatGPT를 이용한 크롤링 개요"
        ],
        "크롤링 실습을 위한 환경 구성": [
          "크롤링을 위한 실습환경 구성 개요",
          "Python 실습을 위한 구글 코랩 Colab 소개",
          "로컬 환경에서 Python과 셀레니움 실습을 위한 Anaconda 설치"
        ],
        "Requests, BeautifulSoup 라이브러리 기초": [
          "ChatGPT를 이용한 Requests 라이브러리 사용법 학습",
          "ChatGPT를 이용한 BeautifulSoup 라이브러리 사용법 학습"
        ],
        "크롤링 실습 1 - 네이버 크롤링": [
          "ChatGPT를 이용한 키워드에 상위노출된 네이버 블로그 글제목 크롤링",
          "ChatGPT를 이용한 네이버 뉴스 제목 크롤링",
          "ChatGPT를 이용한 네이버 증권 종목토론실 크롤링",
          "ChatGPT를 이용한 네이버 증권 종목뉴스 크롤링"
        ],
        "동적인 페이지에 대한 크롤링을 위한 셀레니움 기초와 실습": [
          "셀레니움 실습을 위한 chromedriver 다운로드",
          "ChatGPT를 이용한 셀레니움 라이브러리 기초 학습 예제 1 - 구글 검색결과 제목 크롤링",
          "ChatGPT를 이용한 셀레니움 라이브러리 기초 학습 예제 2 - 스크롤 내리기",
          "ChatGPT를 이용한 키워드에 상위노출된 네이버 블로그 글제목 크롤링 (셀레니움을 통한 스크롤 다운 추가)",
          "ChatGPT와 셀레니움을 이용한 네이버 쇼핑 크롤링"
        ],
        "크롤링 실습 2 - 쿠팡 크롤링": [
          "ChatGPT를 이용한 쿠팡 상품정보 크롤링"
        ],
        "크롤링 실습 3 - 유튜브 크롤링": [
          "ChatGPT를 이용한 유튜브 채널 크롤링"
        ],
        "크롤링 실습 4 - 구글 이미지 검색 크롤링": [
          "ChatGPT를 이용한 구글 이미지 검색 크롤링"
        ]
      },
      "requirements": [
        "크롤링을 학습하고자 하는 의지"
      ],
      "description": "ChatGPT를 이용한 웹사이트 크롤링 방법을 학습할 수 있는 강의입니다. ChatGPT가 만들 변화된 미래를 미리 경험해보세요.\n\n\n코딩을 몰라도 크롤링이 가능하다?\nChatGPT가 만들 변화된 미래를 경험해보세요.\nChatGPT를 이용한 크롤링 방법을 학습합니다.\n크롤링을 위한 Requests, BeautifulSoup, Selenium 라이브러리 사용법\nChatGPT를 이용한 네이버, 네이버증권, 쿠팡 크롤링 실습\n\n\n이런 분들께 추천드려요!\n크롤링을 수행하고 싶은 직장인\nChatGPT를 효율적으로 사용하는 방법을 학습하고 싶은 분\nChatGPT가 만들 변화된 미래를 먼저 경험하고 싶은 분\n\n\n예상 질문 Q&A\nQ. 크롤링이 무엇인가요?\nA. 크롤링(crawling)은 웹 페이지에서 데이터를 수집하는 프로세스를 의미합니다. 크롤러(또는 스파이더라고도 함)라는 자동화된 소프트웨어는 인터넷 상의 웹 페이지를 방문하고, 해당 페이지의 정보와 하이퍼링크를 추출하여 다른 웹 페이지로 이동하는 과정을 반복합니다. 이를 통해 웹의 거대한 정보 저장소에서 원하는 정보를 찾을 수 있습니다.\n크롤링은 검색 엔진이 인터넷의 웹 페이지를 색인화하고 사용자가 원하는 정보를 찾을 수 있도록 도와주는 주요 기술입니다. 또한, 데이터 분석, 마케팅 리서치, 경쟁 분석 등 다양한 분야에서 활용되며, 이를 통해 사람들이 웹에서 필요한 정보를 쉽게 찾을 수 있게 됩니다.\n\n\nQ. ChatGPT를 이용한 크롤링의 장점은 무엇인가요?\nA. 기존에 크롤링을 수행하기 위해서는 Python 코드 작성 방법과 Requests, BeautifulSoup, Selenium 라이브러리 사용법을 학습해야만 했습니다. 하지만 ChatGPT를 이용하면 Python 코드를 직접 작성하지 않고도 한국어 문장으로 분석하고자 하는 내용을 작성해서 ChatGPT에게 요청하면, ChatGPT가 크롤링에 필요한 Python 코드를 작성해주기 때문에 Python 학습에 대한 진입장벽이 사라졌습니다.\n\n\nQ. 그렇다면 이제 Python 코드 작성 방법과 Requests, BeautifulSoup, Selenium 라이브러리를 학습할 필요가 없나요?\nA. ChatGPT가 자동으로 Python 코드를 작성해주긴 하지만 ChatGPT가 작성해준 Python 코드를 분석하고, ChatGPT에게 더 명확하게 작업을 요청하기 위해서, 기본적인 Python 코드 작성 방법과 Requests, BeautifulSoup, Selenium 라이브러리 기초를 학습하면 ChatGPT를 200% 활용할 수 있습니다.",
      "target_audience": [
        "크롤링을 수행하고 싶은 직장인",
        "ChatGPT를 효율적으로 사용하는 방법을 학습하고 싶은 분",
        "ChatGPT가 만들 변화된 미래를 먼저 경험하고 싶은 분"
      ]
    },
    {
      "title": "Hızlandırılmış 5 Saatlik Pandas ve Python ile Veri Analizi",
      "url": "https://www.udemy.com/course/pandas-ve-python-ile-veri-analizi/",
      "bio": "Baştan Sona Pandas ile Veri Bilimi | Hızlandırılmış Python | CSV Dosyalarında Data Madenciliği | Jupyter ve Anaconda",
      "objectives": [
        "Veri Analizi",
        "Hızlandırılmış Python",
        "Pandas Kütüphanesi",
        "Dataframe ve Seri Komutları",
        "1D 2D 3D Veri Setleri ile Çalışma",
        "Anaconda ve Jupyter Notebook Kullanımı",
        "CSV, Excel Dosyaları Analizi"
      ],
      "course_content": {
        "Giriş ve Kurulum": [
          "Pandas Nedir?",
          "Kursta Kullanacaklarımız",
          "MacOS - Anaconda Indirme ve Kurulum",
          "MacOS - Terminal",
          "Windows - Anaconda Indirme",
          "Windows - Anaconda Kurulum",
          "Windows - Anaconda Prompt",
          "Not Alma - Quizlet",
          "MacOS - Anaconda Environment",
          "MacOS - Jupyter Notebook Açalım",
          "Windows - Anaconda Environment",
          "Windows - Jupyter Notebook Açalım"
        ],
        "Jupyter Arayüzü ve Notebook Özellikleri": [
          "Jupyter Arayüzü",
          "Notebook Arayüzü",
          "Edit ve Command Modu",
          "Hücre Çalıştırma"
        ],
        "Hızlandırılmış Python Kursu": [
          "Bölüm Bilgilendirmesi",
          "Python Veri Tipleri (Data Types)",
          "Python Veri Tipleri Uygulamalı",
          "Değişkenler (Variables)",
          "Listeler",
          "Sozluk (Dictionary)",
          "Operasyonlar ve Karşılaştırmalar",
          "if Örneği",
          "Mantık ve Karşılaştırma",
          "For Döngüsü",
          "For Döngüsü 2",
          "While Döngüsü",
          "Python Fonksiyonlar"
        ],
        "CSV Dosyaları ve Kaynaklar": [
          "Bölüm Bilgilendirmesi",
          "CSV Dosyaları Nedir?",
          "CSV Dosyalarını İndirin"
        ],
        "Pandas Serileri": [
          "Serilere Giriş",
          "Serilerde String ile Indexleme",
          "Serilerde Özellikler (Attributes)",
          "Serilerde Metodlar (Methods)",
          "Parametreler",
          "'usecols' ve 'squeeze' Parametreleri",
          "CSV Okuma - read_csv( ) Metodu",
          "Python Gömülü Fonksiyonlar (Built-in Functions)",
          "Serilerde Sıralama - sort_values( ) Metodu",
          "'inplace' Parametresi",
          "Index'e Göre Sıralama - sort_index( ) Metodu",
          "Seri ve Liste Benzerlikleri",
          "Serilerde Label ile Ulaşmak",
          "get( ) Metodu",
          "Null Değerler ve .count( ) Metodu",
          "Max-Min Özellikleri",
          "apply( ) Metodu",
          "map( ) Metodu"
        ],
        "Pandas Dataframe": [
          "Dataframe Nedir?",
          "Dataset Okuma - Oluşturma ve Kaggle",
          "Dataframe Değerlerine Erişme",
          "Dataframe Özellikleri (Attributes)",
          "Sütun İsimleri ve Erişim",
          "Dataframe'lerde 2 Görev!",
          "Sütun Ekleme ve Silme",
          "Dataframe'lerde Matematiksel İşlemler",
          "value_counts( ) Metodu - DF",
          "Null Değerleri Silme - dropna( ) Metodu",
          "Null Değerleri Doldurma - fillna( ) Metodu",
          "Dataframe'lerde Sıralama - sort_values( ) Metodu"
        ]
      },
      "requirements": [
        "Temel programlama bilgisi (Önerilir)"
      ],
      "description": "En Kapsamlı Online Pandas Kursuna Hoşgeldiniz!\nNeden Pandas?\nVeriler her geçen gün daha anlamlı hale geliyor. Verileri analiz edebilmek ve anlam çıkarabilmek bu günlerde en çok aranan özelliklerden birisi. Eskiden veri madenciliği işlemlerini Excel gibi programlarla yapabiliyorduk. Artık Python ve Pandas kullanarak çok daha fazla veriyle ve çok daha hızlı bir şekilde çalışabiliyoruz.\nİster veri bilimcisi(Data Scientist), ister makine öğrenme mühendisi(machine learning engineer), ister istatikçi olun, Python ve Pandas size verilerle yapabileceğiniz bütün işlemleri (import, clean, join/merge/concatenate, manipulate, process) çok daha hızlı ve verimli bir şekilde yapma imkanı sunacak.\n\n\nPandas öğrenmek için önce Python uzmanı olmam gerekiyor mu?\nHayır. Temel seviyede veri tiplerini ve değişkenleri bilmek yeterli. Bu kurstaki \"Hızlandırılmış Temel Python\" adındaki bölümde Pandas kullanabilmek için bilmeniz gereken tüm Python konuları anlatılmıştır.\n\nJupyter ve Anaconda kurulumlarını ve kullanımlarını öğrenebileceksiniz. Fakat kursu izlerken dilediğiniz IDE'yi kullanabilirsiniz.\n\n\nNeden Bu Kurs?\nSimple Academy ekibi olarak kurslarımızı en kapsamlı şekilde hazırlıyor ve güncel tutabilmek için elimizden geleni yapıyoruz. Aynı zamanda sorularınıza anında cevap bulabileceksiniz.\nSadeliği ve kaliteyi misyonumuz olarak konumlandırdığımız için, kurslarımızda bilgi kirliliğine rastlamayacak ve gerek animasyonlu anlatımlarımız gerek ise eğlenceli alıştırmalarımızla öğrenmek istediğiniz konuyu en etkili şekilde öğrenceksiniz.\nHer kursumuzda 30 gün içinde para iadesi sunuyoruz. Memnun kalmadığınız anda hiç soru sormadan iade edebilirsiniz.",
      "target_audience": [
        "Veri Bilimi Öğrenmek İsteyenler",
        "Pandas ve Pyton ile Veri Madenciliği Yapmak İsteyenler"
      ]
    },
    {
      "title": "Python para Data Science e Analytics - Do Zero ao Avançado",
      "url": "https://www.udemy.com/course/python-para-data-science-e-analytics/",
      "bio": "Comece sua trajetória para se tornar um cientista de dados e estar entre os profissionais mais procurados do mercado",
      "objectives": [
        "Analises de Dados avançadas usando Python",
        "Técnicas de Visualização de Dados",
        "Manipulação de dados usando Python",
        "Principais bibliotecas do Python usadas para Data Science",
        "Modelagem Preditiva usando técnicas Estatísticas",
        "Machine Learning"
      ],
      "course_content": {
        "Módulo Básico - Análise Exploratória de Dados": [
          "Materiais Módulo Básico",
          "Python no Mercado de Trabalho",
          "Download IDE e Conceitos Básicos Jupyter",
          "Tipos de Variáveis em Python",
          "Funções e Métodos",
          "Listas e Dicionários",
          "Fechamento Parte 1",
          "Numpy e Pandas",
          "Métodos Básicos de Dataframes",
          "Segmentação de Dados",
          "Cruzamento de Dados",
          "Funções Definidas pelo Usuário",
          "Loops",
          "Operadores Condicionais",
          "Visualização de Dados",
          "Projeto Final - Análise Exploratória de Dados",
          "Projeto Final - Parte Prática"
        ],
        "Módulo Intermediário - Modelagem Estatística": [
          "Materiais Módulo Intermediário",
          "Data Cleaning e Data Preparation - Teoria",
          "Data Cleaning e Data Preparation - Prática",
          "Detecção de Outliers - Teoria",
          "Detecção de Outliers - Prática",
          "Tratamento de Variáveis Categóricas - Teoria",
          "Tratamento de Variáveis Categóricas - Prática",
          "Conceitos de Modelagem",
          "Regressão Linear - Teoria",
          "Regressão Linear - Prática",
          "Regressão Logística - Teoria",
          "Regressão Logística - Pratica",
          "K means Clustering - Teoria",
          "K Means Clustering - Prática",
          "Projeto Final - Resolução de Problema Usando Modelagem Preditiva"
        ],
        "Módulo Avançado - Machine Learning": [
          "Materiais - Módulo Avançado",
          "SVM - Support Vector Machines - Teoria",
          "SVM - Support Vector Machines - Prática",
          "Naive Bayes - Teoria",
          "Naive Bayes - Prática",
          "Árvore de Decisão - Teoria",
          "Árvore de Decisão - Prática",
          "Bagging e Boosting",
          "Random Forest - Teoria",
          "Random Forest - Prática",
          "Gradient Boosting , XGBoost e LGBM - Teoria",
          "Gradient Boosting , XGBoost e LGBM - Prática",
          "Feature Selection - Teoria",
          "Feature Selection - Prática",
          "Cross Validation - Teoria",
          "Cross Validation - Prática",
          "Salvando Modelos com Pickle -Teoria",
          "Salvando Modelos com Pickle - Prática"
        ],
        "Fechamento do Curso": [
          "Encerramento e Próximos Passos"
        ],
        "Apêndice 1 - Automatizando planilhas excel usando Python": [
          "Materiais - Apêndice 1",
          "Construção do Código",
          "Automatizando o Script"
        ],
        "Apêndice 2 - Conceitos de Estatística": [
          "Estatística - Materiais",
          "Estatística - Teoria",
          "Estatística - Prática"
        ]
      },
      "requirements": [
        "Não é necessário experiência com programação",
        "Do Zero ao Avançado"
      ],
      "description": "Neste curso você aprenderá o necessário de Python, a linguagem mais usada dentro do mundo de Data Science e Analytics, para realizar análises de dados de grandes volumes de informação.\nAprenda a manipular dados com facilidade e criar visualizações que permitam extrair os melhores insights dos seus dados.\nAprenda ainda a automatizar trabalhos envolvendo planihas Excel para ganhar mais eficiência em suas análises e tarefas rotineiras.\n\n\nTrabalhe com várias fontes de dados, e processe milhões de registros com facilidade.\n\n\nAprendendo Python para Analytics e Data Science você fará parte do seleto grupo de profissionais mais procurados do mercado, os cientistas de dados Python. Este perfil vem sendo altamente procurado e atualmente as empresas possuem mais vagas do que profissionais especializados para preenchê-las.\nSe pensa em mudar de carreira, comece com um curso que ensina diretamente aquilo que o mercado procura. Aprenda com quem já possui anos de experiência no mercado de Data Science e Analytics\nImpressione no trabalho com análises avançadas e hacks para produtividade.\n\n\n\n\nCientista de dados foi classificado como o trabalho número 1 no Glassdoor e o salário médio de um cientista de dados é mais de $ 120,000 nos Estados Unidos! Data Science é uma carreira gratificante que permite resolver alguns dos problemas mais interessantes do mundo! Além disso, muitas empresas no Brasil já estão começando a expandir suas áreas de data analytics.\nEste curso foi concebido para principiantes com alguma experiência de programação ou desenvolvedores experientes que procuram dar um salto em direção à ciência dos dados!\n\n\nVá do zero ao avançado passando pelos seguintes assuntos:\n\n\nAnálise Exploratória de Dados:\n\n\nIntrodução ao Python\nFunções básicas\nNumpy e Pandas\nDataframes\nLoops\nOperadores Condicionais\nFunções Definidas pelo Usuário\nVisualização de Dados\nProjeto Final de Análise Exploratória de Dados\n\n\nModelagem Estatística:\n\n\nData Cleaning e Data Preparation\nDetecção de Outliers\nTratamento de Variáveis Categóricas\nConceitos de Modelagem\nRegressão Linear\nRegressão Logística\nK means Clustering\nProjeto final de modelagem estatística\n\n\nMachine Learning:\n\n\nSVM - Support Vector Machines\nNaive Bayes\nÁrvore de Decisão\nBagging e Boosting\nRandom Forest\nGradient Boosting, XGBoost e LGBM\nFeature Selection\nCross Validation\nSalvando modelos com Pickle",
      "target_audience": [
        "Para quem quer entrar no mercado de dados e começar a atuar com Data Science ou Analytics",
        "Analistas que querem melhorar suas habilidades",
        "Desenvolvedores que querem entrar na área de Dados",
        "Iniciantes que querem mudar de carreira e começar na área"
      ]
    },
    {
      "title": "Spark und Python für Big Data und Data Science mit PySpark",
      "url": "https://www.udemy.com/course/spark-und-python-fur-big-data-mit-pyspark/",
      "bio": "Lerne Apache Spark 2.3 mit Python einzusetzen (mit Machine Learning und Streaming)",
      "objectives": [
        "Verwende Python und Spark zusammen, um Big Data zu analysieren.",
        "Lerne, wie Du die neue Spark 2.0 DataFrame-Syntax verwenden",
        "Arbeite an Consulting-Projekten, die reale Situationen nachahmen",
        "Kundenabwanderung mit Logistischer Regression klassifizieren",
        "Spark mit Entscheidungsbäumen für die Klassifizierung verwenden",
        "Lernen, wie Sparks Gradient Boosted Trees verwendet wird",
        "Verwende MLlib von Spark, um leistungsstarke Machine Learning-Modelle zu erstellen",
        "Einrichtung von Amazon Web Services EC2 für Big Data-Analyse",
        "Erfahren, wie Du AWS Elastic MapReduce Service verwenden kannst",
        "Erstelle einen Spam-Filter mit Spark und Natural Language Processing",
        "Verwende Spark Streaming, um Tweets in Echtzeit zu analysieren"
      ],
      "course_content": {
        "Einführung in den Kurs": [
          "Willkommen im Kurs",
          "Hinweise zum Kurs",
          "Kurs Übersicht",
          "Kursmaterialien",
          "Merkblätter",
          "Häufig gestellte Fragen",
          "Big Data Übersicht",
          "Spark Übersicht"
        ],
        "Alternative 1: Lokale Spark + Python Installation": [
          "Willkommen zur lokalen PySpark Einrichtung",
          "Windows - Installation mit Docker Desktop",
          "Windows - WSL aktualisieren",
          "Windows - Git Bash als Terminal",
          "MAC - Lokale PySpark Installation",
          "Linux - Docker Desktop Installation",
          "Spark Docker Container Installation"
        ],
        "Python Crashkurs": [
          "Python Crashkurs",
          "Einführung in den Python Crashkurs",
          "Jupyter Notebook Übersicht",
          "Python Crashkurs Teil 1",
          "Python Crashkurs Teil 2",
          "Python Crashkurs Teil 3",
          "Python Crashkurs Teil 4",
          "Python Crashkurs Übungen",
          "Python Crashkurs Übungen - Lösungen"
        ],
        "Spark DataFrame Grundlagen": [
          "Willkommen zu den DataFrames",
          "Einführung in DataFrame Grundlagen",
          "Spark DataFrame Grundlagen Teil 1",
          "Spark DataFrame Grundlagen Teil 2",
          "Spark DataFrame Operationen",
          "GroupBy",
          "Fehlende Werte",
          "Timestamps"
        ],
        "Spark DataFrame Projekt Übung": [
          "Willkommen zum Übungsprojekt",
          "DataFrame Projekt Aufgabe",
          "DataFrame Projekt Lösungen",
          "Spark DataFrames Beratungsprojekt - Aufgabe",
          "Spark DataFrames Beratungsprojekt - Lösungen"
        ],
        "Einführung in Machine Learning mit MLlib": [
          "Willkommen zum Machine Learning Abschnitt",
          "Machine Learning Einführung",
          "Einführung in Machine Learning und ISLR",
          "Machine Learning mit Spark und Python mit MLlib",
          "Machine Learning Quiz"
        ],
        "Lineare Regression": [
          "Lineare Regression Theorie",
          "Wiederholung: Daten und Funktionen",
          "Lineare Regression Dokumentation Beispiel",
          "Regression Evaluierung",
          "Lineare Regression Beispiel Code Along",
          "Lineare Regression Beratungsprojekt Aufgabe",
          "Lineare Regression Beratungsprojekt Aufgabe - Lösungen"
        ],
        "Logistische Regression": [
          "Logistische Regression Theorie",
          "Logistische Regression Dokumentation Beispiel",
          "Logistische Regression Code Along",
          "Logistische Regression Beratungsprojekt",
          "Logistische Regression Beratungsprojekt - Lösungen"
        ],
        "Entscheidungsbäume und Random Forests": [
          "Entscheidungsbäume Einführung",
          "Baum Methoden Dokumentationsbeispiel",
          "Baum Methoden Code Along - Teil 1",
          "Baum Methoden Code Along - Teil 2",
          "Baum Methoden Beratungsprojekt Aufgabe",
          "Baum Methoden Beratungsprojekt Aufgabe - Lösung"
        ],
        "K-means Clustering": [
          "K-Means-Clustering Einführung",
          "K-Means-Clustering Dokumentationsbeispiel",
          "K-Means-Clustering Code Along",
          "K-Means-Clustering Beratungsprojekt - Aufgabe",
          "K-Means-Clustering Beratungsprojekt - Aufgabe - Lösungen"
        ]
      },
      "requirements": [
        "Allgemeine Programmierkenntnisse in jeder Sprache (vorzugsweise Python)",
        "20 GB freier Speicherplatz auf Deinem lokalen Computer (oder alternativ eine starke Internetverbindung für AWS)"
      ],
      "description": "Lerne die neueste Big Data Technologie - Spark! Und lerne es mit einer der beliebtesten Programmiersprachen, Python!\nEine der wertvollsten technologischen Kompetenzen ist die Fähigkeit, große Datenmengen zu analysieren. Dieser Kurs wurde speziell dafür entwickelt, Dich auf eine der besten Technologien für diese Aufgabe, Apache Spark, vorzubereiten! Die Top-Technologie-Unternehmen wie Google, Facebook, Netflix, Airbnb, Amazon, NASA und mehr verwenden alle Spark, um ihre Big-Data-Probleme zu lösen! Spark kann bis zu 100x schneller als Hadoop MapReduce ausgeführt werden, was zu einer Explosion der Nachfrage nach dieser Fähigkeit geführt hat!\nDieser Kurs vermittelt die Grundlagen mit einem Crash-Kurs in Python und lehrt weiterhin, wie man Spark DataFrames mit der  Spark 2.0-Syntax verwendet! Sobald wir das besprochen haben, werden wir sehen, wie man die MLlib Machine Library mit der DataFrame-Syntax und Spark verwendet. Während jeder Lektion bekommst Du Übungen und simulierte Beratungs-Projekte, die Dich direkt in eine reale Situation bringen, in der Du deine neuen Fähigkeiten einsetzen kannst, um ein echtes Problem zu lösen!\nWir befassen uns auch mit den neuesten Spark-Technologien, wie Spark SQL, Spark Streaming und erweiterten Modellen wie Gradient Boosted Trees!\n\n\n\"Der Kurs hat ein sehr gutes Level und als Anfänger in Big Data komme ich sehr gut mit. Der Kursleiter erklärt alles sehr genau und man kann ihm sehr gut folgen.\" (★★★★★ W. Surala)\n\n\nNachdem Du diesen Kurs absolviert hast, kannst Du selbstbewusst Spark und PySpark in Deinen Lebenslauf schreiben! Dieser Kurs hat auch eine volle 30 Tage Geld-zurück-Garantie!\nWenn Du bereit bist, in die Welt von Python, Spark und Big Data einzutauchen, dann ist dies der richtige Kurs für Dich!\n\n\n\n\n\n\n* Dieser Kurs erfordert, dass du dir Docker-Desktop bzw. die Toolbox und evtl. Anaconda herunterlädst. Wenn du Udemy-Business-Nutzer bist, kläre bitte vor dem Herunterladen mit deinem Arbeitgeber, ob die Installation erlaubt ist.",
      "target_audience": [
        "Jemand, der Python kennt und gerne die Verwendung für Big Data lernen würde",
        "Jemand, der mit einer anderen Programmiersprache vertraut ist und Spark lernen möchte"
      ]
    },
    {
      "title": "KI Kurs: ChatGPT, Prompt Engineering, ML, AI und GPT-4 API",
      "url": "https://www.udemy.com/course/ki-kurs-lernen/",
      "bio": "In diesem Kurs: ChatGPT, Prompt Engineering, GPT-4 API, Programmierung mit KI, Maschinelles Lernen (ML), DeepsSeek-R1",
      "objectives": [
        "Machinelles Lernen verstehen",
        "Die Technologie hinter ChatGPT",
        "ChatGPT im Marketing",
        "ChatGPT im Beruf"
      ],
      "course_content": {
        "Einführung": [
          "Einführung",
          "Setup für den Kurs"
        ],
        "Maschinelles Lernen: Grundlagen": [
          "Maschinelles Lernen: Wie funktionieren LLM ML-Systeme, wie ChatGPT?",
          "Maschinelles Lernen: Was sind GPT (Generative Pre-trained Transformer)?",
          "Maschinelles Lernen: GPT-3 vs. GPT-4 - Erklärung und Vergleich"
        ],
        "ChatGPT: Grundlagen und Prompt-Vorlagen": [
          "ChatGPT: Ein Konto anlegen",
          "ChatGPT: Einen neuen Chat starten",
          "ChatGPT: Interface und Aufbau",
          "ChatGPT: Modifizierung von Prompts und Antworten (Tone Modifiers)"
        ],
        "ChatGPT: Prompt Engineering und Anleitung": [
          "ChatGPT: Was ist Prompt Engineering",
          "ChatGPT: Die Grenzen der KI",
          "ChatGPT: Der richtige Kontext (Prompt Priming)",
          "ChatGPT: Klare Definition der Aufgabe",
          "ChatGPT: Die Länge des Prompts",
          "ChatGPT: Imagine-as-Prompting (Person oder Beruf)",
          "ChatGPT: Ursache und Wirkung (Causa Aequat Effectum) / Aufschlüsselung",
          "ChatGPT: Mehrfach-Antworten",
          "ChatGPT: Prompt-Prompting",
          "ChatGPT: Prompt-Bibliothek",
          "ChatGPT: Formatierung der Antworten (Tabelle, HTML5, Markdown usw.)",
          "ChatGPT: Reverse Prompting"
        ],
        "ChatGPT: Bildung - Lektorate, Texte kürzen, Daten organisieren, Lernen": [
          "ChatGPT: Die alternative Suchmaschine",
          "ChatGPT: Vokabeln lernen",
          "ChatGPT: Begriffsdefinition",
          "ChatGPT: Essay-Outline",
          "ChatGPT: Texte korrigieren und Lektorate (Grammatik, Rechtschreibung usw.)",
          "ChatGPT: Schreibempfehlung",
          "ChatGPT: Daten organisieren",
          "ChatGPT: Quiz erstellen",
          "ChatGPT: Aufgabenblatt anlegen",
          "ChatGPT: Lehrplan entwickeln",
          "ChatGPT: Unterricht planen"
        ],
        "ChatGPT: Medien - Content Creation, Social Media, Copywriting, SEO, Videoskripte": [
          "ChatGPT: SEO - Linkarchitektur",
          "ChatGPT: SEO - Keyword-Recherche",
          "ChatGPT: SEO - Inhaltsverzeichnis / Ratgeber-Outline",
          "ChatGPT: SEO - Themen ausführen",
          "ChatGPT: SEO - Title Tag und Meta Description",
          "ChatGPT: SEO - Content-Optimierung",
          "ChatGPT: SEO - Mitbewerber analysieren",
          "ChatGPT: SEO - Content-Gaps identifizieren",
          "ChatGPT: SEO - SEO-freundliche URLs erstellen",
          "ChatGPT: Content - Content-Ideen",
          "ChatGPT: Content - Repurposing",
          "ChatGPT: Content - Produktbeschreibungen",
          "ChatGPT: Video - Skript erstellen",
          "ChatGPT: Video - Titel",
          "ChatGPT: Social Media - Hashtag-Vorschläge",
          "ChatGPT: Social Media - Influencer-Kampagnen - Outline erstellen"
        ],
        "ChatGPT: Beruf - Recherche, Job-Suche, Datenanalyse, Brainstorming, Organisation": [
          "ChatGPT: Markt-Recherche",
          "ChatGPT: Brainstorming",
          "ChatGPT: Unternehmensplan erstellen",
          "ChatGPT: Projektplanung",
          "ChatGPT: Bewerbungsschreiben"
        ],
        "ChatGPT: Programmierung - Web Apps mit KI programmieren": [
          "ChatGPT: Code generieren",
          "ChatGPT: Debugging"
        ],
        "GPT-4 API: Eine Anwendung erstellen (mit Python)": [
          "GPT-4 API: Server aufsetzen",
          "GPT-4 API: Anwendung erstellen",
          "GPT-4 API: Weitere Vorschläge"
        ],
        "Prompt Vorlagen für ChatGPT, DeepSeek, Claude Sonnet und Gemini": [
          "Prompt Vorlagen für ChatGPT, DeepSeek, Claude Sonnet und Gemini"
        ]
      },
      "requirements": [
        "Es werden keine speziellen Voraussetzungen benötigt"
      ],
      "description": "Willkommen zum ChatGPT-Kurs, der Ihnen alles beibringt, was Sie über die effektive Nutzung von ChatGPT wissen müssen! Dieser Kurs wurde entwickelt, um Ihnen die notwendigen Fähigkeiten zu vermitteln, um ChatGPT optimal zu nutzen, sei es für persönliche Projekte, berufliche Anwendungen oder kreative Ideen.\nKursübersicht:\nEinführung in ChatGPT\nVerständnis der Grundlagen: Wie funktioniert ChatGPT?\nÜberblick über die Anwendungsbereiche von ChatGPT in verschiedenen Branchen.\nPraktische Anwendungsfälle\nSchreiben von Texten: Tipps und Tricks zur Verbesserung der Textqualität.\nKreative Anwendungen: Generierung von Ideen, Geschichten und mehr.\nAnpassung und Feinabstimmung\nPersonalisierung von ChatGPT für Ihre speziellen Bedürfnisse.\nFeinabstimmung von Modellen für branchenspezifische Anforderungen.\nIntegration von ChatGPT in Projekte\nEinbindung von ChatGPT in Ihre Arbeitswelt.\nBest Practices für die nahtlose Anwendung.\nEffiziente Kommunikation mit ChatGPT\nRichtiges Formulieren von Anfragen: Maximierung der Antwortqualität.\nUmgang mit Einschränkungen und Herausforderungen.\nEthik und Verantwortung in der Nutzung von ChatGPT\nSensibilisierung für mögliche Bias-Probleme.\nVerantwortungsbewusster Einsatz von KI-Technologien.\nAktuelle Entwicklungen und Zukunftsaussichten\nEinblick in die neuesten Updates und Funktionen von ChatGPT.\nAusblick auf zukünftige Entwicklungen in der Welt der KI-gesteuerten Kommunikation.\nZielgruppe:\nEntwickler\nContent-Ersteller\nForscher\nUnternehmer\nAlle, die ihre Kenntnisse im Bereich der KI und natürlichen Sprachverarbeitung erweitern möchten.\nVoraussetzungen:\nGrundlegende Kenntnisse in Programmierung und Interesse an künstlicher Intelligenz werden empfohlen, sind jedoch nicht zwingend erforderlich.\nDieser Kurs bietet Ihnen die Werkzeuge und das Verständnis, um ChatGPT effektiv in verschiedenen Kontexten zu nutzen und von den vielfältigen Möglichkeiten dieser fortschrittlichen Sprach-KI-Technologie zu profitieren. Melden Sie sich jetzt an und werden Sie ein Experte in der Anwendung von ChatGPT!",
      "target_audience": [
        "Privatpersonen",
        "Selbstständige und Freiberufler",
        "Arbeitnehmer und Unternehmen"
      ]
    },
    {
      "title": "人工知能・対話ができる人型モデル講座【Unreal Engine5】 -ゲームエンジンの可能性-",
      "url": "https://www.udemy.com/course/unreal-engine5-human/",
      "bio": "会話型AI(Convai)とゲームエンジン(Unreal Engine 5)連携させ、会話(英語)ができるリアリスティックな人型モデルを作成する講座です。今後の社会に大きな影響を与える技術を先んじて学び、将来の可能性を体験しましょう。",
      "objectives": [
        "Conversational AI【Convai】を体験ベースで学びます。",
        "Unreal Engine 5のインストール・基本操作を学ぶことができます。",
        "Unreal Engineの機能であるMetahumanを活用方法を学ぶことができます。",
        "ConvaiとUnreal Engineを連携し会話ができる人型モデル【Human】を作成します。",
        "会話型AI・ゲームエンジンの可能性をご体験いただけます。"
      ],
      "course_content": {
        "紹介": [
          "コースの紹介",
          "コースの説明"
        ],
        "Conversational AI：Convaiの導入": [
          "Convaiアカウント作成",
          "Convaiの基本操作"
        ],
        "ゲームエンジン：Unreal engine 5の導入": [
          "環境構築：Unreal Engine 5のインストール",
          "UE5の基礎：プロジェクトの作成",
          "UE5の基礎：カメラ・インターフェース操作について"
        ],
        "Humanの作成": [
          "Pluginのインストール",
          "Pluginの有効化",
          "Humanプロジェクト"
        ],
        "オリジナルHumanの作成": [
          "Quixel Bridge：Metahumanのインポート",
          "Humanの設定：Blueprint",
          "Humanの設定：キャラクターの性格設定",
          "おわりに"
        ]
      },
      "requirements": [
        "PCスペック(OS:Windows, CPU:core-i7以上, メモリ:16GB以上,SSD:1TB以上,GPU:RTX2080以上)",
        "※講師のPC(OS:Windows10, CPU:ryzen9, メモリ:16GB, SSD:1TB, GPU:RTX3070)",
        "gmailアカウント"
      ],
      "description": "ChatGPTやStableDiffusionといったテキスト・画像生成AIはかなり一般的になってきましたが、会話ができるAIは一般的ではないと思われます(2023年3月現在)。このコースでは難しい数式やコードを使わず、会話型AI(Convai)と、Epic社が提供するゲーム(フォートナイト)を作成しているゲームエンジン(Unreal Engine)を使い、ノンゲームの会話ができる人型モデルを作成します。\n\n\n【注意点①】\n当コースでは会話ができる人型モデルを【Human】と称します。\n\n\n【注意点②】\n当コースは【ChatGPTの会話版】とも称されるConvaiとUnreal EngineをAPI連携することで、会話ができる人型モデル【Human】を作成します。本格的に深層学習やコーティングによるプログラミンを行う訳ではありませんので、それらを期待する学習者を対象としていません。一方でプログラミングなどの事前知識は不要ですので文系の方、ITに知見がない方でもPCのスペックが足りていれば、安心してご受講いただくことができます。\n\n\n【注意点③】\nConvaiは日本語対応しておらず、英語・スペイン語に対応しています。実際のHumanとの会話は英会話になります。講師は純国産の日本人でありネイティブではありません。単語の読み方や発音が気になる方はご受講をご遠慮ください。",
      "target_audience": [
        "AIに関する知識をキャッチアップしたい方。",
        "Unreal Engineやゲーム開発に興味がある方。",
        "会話型AIを活用して将来アプリ開発や社会に影響を与えたい方。",
        "Unreal Engine をはじめて触る方",
        "Unreal Engine 初学者"
      ]
    },
    {
      "title": "Phân tích dữ liệu bằng R cho người mới bắt đầu",
      "url": "https://www.udemy.com/course/phan-tich-du-lieu-bang-r-cho-nguoi-moi-bat-au/",
      "bio": "Data analysis using R for beginners",
      "objectives": [
        "Các bước cần làm trong phân tích dữ liệu",
        "Ngôn ngữ R cơ bản",
        "Biến đổi dữ liệu",
        "Phân tích thống kê mô tả",
        "Phân tích thống kê suy luận: kiểm định t, phân tích ANOVA, phân tích tương quan",
        "Vẽ đồ thị và biểu đồ"
      ],
      "course_content": {
        "Giới thiệu": [
          "Giới thiệu về bản thân",
          "Khóa học này dành cho ai?",
          "Tại sao bạn nên học khóa học này?",
          "Nội dung của khóa học",
          "Mục tiêu của khóa học",
          "Học khóa học này như thế nào?"
        ],
        "Giới thiệu về phân tích dữ liệu": [
          "Giới thiệu",
          "Dữ liệu là gì?",
          "Phân tích dữ liệu là gì?",
          "Các bước trong phân tích dữ liệu",
          "Ứng dụng của phân tích dữ liệu",
          "Tóm tắt"
        ],
        "Phần mềm R và RStudio": [
          "Giới thiệu",
          "Phần mềm R và RStudio là gì?",
          "Cài đặt phần mềm R và RStudio trên máy Mac",
          "Cài phần mềm R và RStudio trên máy Windows",
          "Viết câu lệnh đầu tiên",
          "Phần mềm gõ tiếng Việt",
          "Giao diện của RStudio - Phần 1",
          "Giao diện của RStudio - Phần 2",
          "Tạo project và file R",
          "Gói phần mềm trong R",
          "Tóm tắt"
        ],
        "Giới thiệu về dữ liệu trong R": [
          "Giới thiệu",
          "Cách nhập dữ liệu chữ và số trong R",
          "Cách viết tiêu đề và comments trong R",
          "Biến, cách viết tên biến và loại dữ liệu trong R - Lý thuyết",
          "Tạo biến trong R",
          "Cách viết tên biến",
          "Tạo biến có kiểu dữ liệu khác nhau",
          "Vector, ma trận, tập dữ liệu và list là gì?",
          "Tạo và làm việc với vector",
          "Tạo và làm việc với ma trận - Phần 1",
          "Tạo và làm việc với ma trận - Phần 2",
          "Tạo và làm việc với tập dữ liệu",
          "Tạo vào làm việc với list",
          "Chuyển ma trận thành tập dữ liệu và ngược lại",
          "Chuyển tập dữ liệu thành list và ngược lại",
          "Tóm tắt",
          "Chọn đáp án đúng",
          "Bài tập"
        ],
        "Nhập dữ liệu vào R": [
          "Giới thiệu",
          "Đọc dữ liệu sẵn có trong R",
          "Nhập dữ liệu file csv",
          "Nhập dữ liệu file excel",
          "Tìm hiểu đặc điểm của dữ liệu",
          "Tóm tắt"
        ],
        "R cơ bản": [
          "Giới thiệu",
          "Các phép tính cơ bản trong R",
          "Điều kiện (Conditionals): toán tử quan hệ - Phần 1",
          "Điều kiện (Conditionals): toán tử quan hệ - Phần 2",
          "Điều kiện (Conditionals): toán tử logic - Phần 1",
          "Điều kiện (Conditionals): toán tử logic - Phần 2",
          "Điều kiện (Conditionals): mệnh đề điều kiện (if statements)",
          "Điều kiện (Conditionals): mệnh đề else (else statments)",
          "Điều kiện (Conditionals): mệnh đề else if (else if statements)",
          "Điều kiện (Conditionals): mệnh đề ifelse",
          "Điều kiện (Conditionals): Biến đổi dữ liệu với mệnh đề ifelse",
          "Vòng lặp (loop): giới thiệu",
          "Vòng lặp (loop): while loop",
          "Vòng lặp (loop): for loop 1",
          "Vòng lặp (loop): for loop 2",
          "Hàm (function): giới thiệu",
          "Hàm (function): hàm sẵn có trong R",
          "Hàm (function): hàm tự viết",
          "Họ hàm apply (apply family): giới thiệu",
          "Họ hàm apply (apply family): hàm apply",
          "Họ hàm apply (apply family): hàm lapply",
          "Họ hàm apply (apply family): hàm sapply",
          "Họ hàm apply (apply family): hàm tapply",
          "Họ hàm apply (apply family): hàm vapply",
          "Họ hàm apply (apply family): hàm mapply",
          "Các hàm thống kê - Phần 1",
          "Các hàm thống kê - Phần 2",
          "Hàm tạo chuỗi (seq)",
          "Tạo chuỗi số tự nhiên",
          "Tạo bảng chữ cái",
          "Hàm tạo giá trị lặp lại: rep()",
          "Hàm replicate()",
          "Hàm lấy mẫu: sample()",
          "Lấy nhiều mẫu: kết hợp hàm sample() và hàm replicate()",
          "Tìm và thay thế: grep(), grepl(), sub(), gsub() - Phần 1",
          "Tìm và thay thế: grep(), grepl(), sub(), gsub() - Phần 2",
          "Biến ngày tháng - Phần 1",
          "Biến ngày tháng - Phần 2",
          "Tóm tắt"
        ],
        "Biến dổi dữ liệu": [
          "Giới thiệu",
          "Nhập dữ liệu và loại tiêu đề của bảng",
          "Chuyển đổi loại dữ liệu của biến - Phần 1",
          "Chuyển đổi loại dữ liệu của biến - Phần 2",
          "Sắp xếp thứ tự các nhóm của biến",
          "Chọn các biến",
          "Lọc các nhóm của biến - Phần 1",
          "Lọc các nhóm của biến - Phần 2",
          "Đổi tên biến",
          "Đổi tên nhóm của biến",
          "Phân tích và xử lý dữ liệu bị khuyết (NA) - Phần 1",
          "Phân tích và xử lý dữ liệu bị khuyết (NA) - Phần 2",
          "Phân tích và xử lý giá trị vô cùng (Inf)",
          "Định dạng biến ngày tháng",
          "Chuyển hàng thành cột và ngược lại (transpose)",
          "Chuyển dữ liệu kiểu rộng (wide format) thành kiểu dài (long format) và ngược lại",
          "Kết hợp dữ liệu: giới thiệu",
          "Kết hợp dữ liệu: inner_join, left_join, right_join, full_join semi_join",
          "Kết hợp dữ liệu: dùng nhiều cột chung (multiple key columns)",
          "Kết hợp dữ liệu bằng cbind() và rbind()",
          "Nhập và kết hợp nhiều file dữ liệu - Phần 1",
          "Nhập và kết hợp nhiều file dữ liệu - Phần 2",
          "Tóm tắt"
        ],
        "Gói phần mềm dplyr": [
          "Giới thiệu",
          "Giới thiệu các câu lệnh cơ bản của gói phần mềm dplyr",
          "Lựa chọn biến - câu lệnh select()",
          "Lọc dữ liệu - câu lệnh filter()",
          "Sắp xếp dữ liệu - câu lệnh arrange()",
          "Thêm cột và tính toán - câu lệnh mutate()",
          "Chọn biến và tính toán - câu lệnh transmutate()",
          "Tính các giá trị thống kê - câu lệnh summarise()",
          "Tính các giá trị thống kê theo nhóm - câu lệnh group_by()",
          "Hủy nhóm - câu lệnh ungroup()",
          "Đổi tên biến",
          "Đổi tên các nhóm của biến",
          "Đổi vị trí các biến",
          "Tóm tắt"
        ],
        "Phân tích thống kê mô tả (descriptive statistics)": [
          "Giới thiệu",
          "Phân tích thống kê và phân tích thống kê mô tả là gì?",
          "Kiểm tra phân phối của mẫu - giới thiệu",
          "Kiểm tra phân phối của mẫu - biểu đồ tần suất",
          "Kiểm tra phân phối của mẫu - qqplot",
          "Phân tích và xử lý giá trị ngoại lai - giới thiệu",
          "Xác định giá trị ngoại lai (outliers)",
          "Loại giá trị ngoại lai",
          "Thay giá trị ngoại lai bằng trung bình",
          "Tính các giá trị thống kê - giới thiệu",
          "Tính các giá trị thống kê cho một biến",
          "Tính các giá trị thống kê cho nhiều biến",
          "Tính các giá trị thống kê dùng summarise(across())",
          "Làm tròn các giá trị thống kê",
          "Tính tỉ lệ giữa trung bình của hai nhóm",
          "Lưu kết quả phân tích thống kê thành file excel",
          "Tóm tắt"
        ],
        "Vẽ đồ thị và biểu đồ": [
          "Giới thiệu",
          "Các loại đồ thị, biểu đồ",
          "Gói phần mềm ggpubr",
          "Vẽ đồ thị",
          "Vẽ biểu đồ cột",
          "Vẽ biểu đồ cột nằm ngang",
          "Vẽ biểu đồ hình tròn",
          "Vẽ biểu đồ phân tán",
          "Vẽ đồ thị có độ lệch chuẩn",
          "Vẽ biểu đồ cột có độ lệch chuẩn (SD)",
          "Vẽ biểu đồ có sai số chuẩn (SE) và khoảng tin cậy (CI)",
          "Tinh chỉnh tên biểu đồ và các trục",
          "Tinh chỉnh legend",
          "Lưu đồ thị/biểu đồ",
          "Kết hợp các đồ thị và biểu đồ",
          "Tóm tắt"
        ]
      },
      "requirements": [
        "Không cần kinh nghiệm. Chỉ cần có kiến thức cơ bản về toán. Nếu biết một chút tiếng Anh sẽ rất tốt, nếu không cũng không có vấn đề gì."
      ],
      "description": "Mục đích của khóa học\nKhóa học này được thiết kế nhằm giúp người học xây dựng nền tảng vững chắc trong phân tích dữ liệu bằng phần mềm R – một công cụ mạnh mẽ và phổ biến trong nghiên cứu khoa học và phân tích dữ liệu.\nKết quả sẽ đạt được sau khóa học\nSau khi hoàn thành khóa học, người học sẽ:\nBiết cài đặt thành công phần mềm R và RStudio trên cả Windows và Mac.\nHiểu rõ giao diện làm việc của RStudio và biết cách thao tác hiệu quả trong môi trường này.\nLàm chủ các bước cơ bản về phân tích dữ liệu bằng R.\nHiểu rõ các khái niệm cốt lõi về dữ liệu và các phương pháp phân tích dữ liệu.\nTự tin viết và áp dụng các câu lệnh cơ bản trong R, thông qua các ví dụ thực tế có tính ứng dụng cao.\nTự tin thực hiện các thao tác biến đổi dữ liệu như lọc, kết hợp, đổi tên biến, chuyển đổi kiểu dữ liệu, xử lý dữ liệu ngày tháng.\nBiết thực hiện phân tích thống kê mô tả: kiểm định phân phối chuẩn, xử lý giá trị ngoại lai, tính toán các chỉ số thống kê, và vẽ đồ thị và biểu đồ.\nHiểu bản chất và ứng dụng được các phương pháp thống kê suy luận cơ bản trong R.\nChuẩn bị báo cáo kết quả phân tích một cách khoa học và có thể trình bày chuyên nghiệp.\nVề giảng viên\nTiến sỹ Lâm Nguyễn là một giảng viên và nghiên cứu viên với nền tảng học thuật vững chắc trong lĩnh vực công nghệ sinh học, sinh học, và phân tích thống kê. Anh đã hoàn thành chương trình Thạc sĩ và Tiến sĩ tại Đại học Flinders (Úc). Anh cũng tốt nghiệp khóa học sau đại học về Công nghệ sinh học tại Đại học Mahidol (Thái Lan), Đại học Osaka (Nhật Bản). Trước đó anh tốt nghiệp Cử nhân Công nghệ sinh học tại Đại học Quốc Gia Hà Nội.\nVới kiến thức vững chắc, kinh nghiệm giảng dạy và nghiên cứu, Lâm Nguyễn có cách truyền đạt đơn giản, dễ hiểu và đi vào bản chất. Các bài giảng có sự kết hợp giữa lý thuyết và thực hành, và được xây dựng dựa trên đời sống thực tế. Niềm đam mê với, nghiên cứu khoa học, viết code, phân tích dữ liệu và học tập suốt đời chính là động lực để anh xây dựng khóa học này, giúp người học nắm chắc lý thuyết và thành thạo kỹ năng phân tích dữ liệu bằng R.\nBạn có thể liên hệ với Lâm Nguyễn qua facebook hoặc Youtube để có thêm thông tin hoặc Voucher giảm giá (qua đường link ở dưới ảnh của giảng viên trên Udemy - Click vào Lam Nguyen dưới chữ Instructor để đến phần giới thiệu về giảng viên).",
      "target_audience": [
        "Người tìm hiểu về phân tích dữ liệu, sinh viên, học viên và người làm nghiên cứu"
      ]
    },
    {
      "title": "너무 쉬운 엑셀 피벗 테이블",
      "url": "https://www.udemy.com/course/pivot_table/",
      "bio": "피벗 테이블, 딱 한시간만 따라 하면 됩니다.",
      "objectives": [
        "피벗 테이블의 재미를 배웁니다.",
        "최소 시간으로 가장 효율적으로 데이터를 정리합니다.",
        "데이터를 만나면 일단 반가운 마음이 생깁니다.",
        "엑셀의 함수보다 더 쉬운 피벗 테이블의 기능을 능숙하게 사용하게 됩니다.",
        "피벗 테이블에서 발생하기 쉬운 에러들을 사전에 예방하는 방법을 배웁니다."
      ],
      "course_content": {
        "예제 1 - 어렵고 복잡한 날짜 데이터 분석을 쉽게 배워 보자.": [
          "1. 피벗 테이블 일단 맛보기",
          "1-1. 날짜와 월과 분기와 년 - 과거 버전 사용자를 위한 보충 영상",
          "2. 보고서 레이 아웃과 부분합_subset 구하기"
        ],
        "예제 1 - 날짜 데이터 분석의 응용편, 흔히 사용하지는 않지만 알면 도움될 내용": [
          "6. 년도별 월별 분석과 heat map(1)",
          "7. 년도별 월별 분석과 heat map(2)",
          "8. 요일별분석",
          "9. calender plot",
          "10. word powerpoint hwp에 붙여 넣기"
        ],
        "예제 2 다양한 분석 - 메르스 발생 데이터 분석하기": [
          "(부록) 한국 메르스 데이터를 통해서 살펴본 에러나기 쉬운 경우",
          "날짜별 발생 건수를 그래프로 그리기(epidemic curve)",
          "8. 메르스 데이터 기초분석",
          "3. 꺽은선 차트와 필터와 슬라이서",
          "4. 두 명목 변수의 분석과 시간표시 막대",
          "5. 명목변수와 연속변수의 분석"
        ],
        "(부록) 다시 생각해 보기": [
          "(부록) 피벗 테이블 몸풀기, 쉽게 하는 R 피벗 테이블",
          "(부록) 네이버폼에서 수집한 날짜 문제의 해결 + 시간대별로 피벗하기"
        ],
        "예제 3 데이터 가지고 놀기 - 섬진강댐 데이터 분석": [
          "12. 섬진강댐 데이터 분석(1)",
          "13. 섬진강댐 데이터 분석(2)",
          "14. 섬진강댐 데이터 분석(3)"
        ]
      },
      "requirements": [
        "평소 엑셀을 사용하는 시간이 많다",
        "데이터의 양이 많다."
      ],
      "description": "접근하기 어려웠던 피벗 테이블을 정말 쉽고, 간단하게 배웁니다.\n가장 핵심적이고, 활용도 높은 기능들을 딱 1 시간에 배우게 됩니다.\n완전 초보자를 위한, 그러나 높은 수준의 기능들을\n2가지 실제 데이터를 사용해서 쉽게 배웁니다.\n\n\nR이나 파이썬 사용자도 꼭 배우시기를 강력히 추천합니다. 쉬운 길을 어렵게 가지 마세요.\n피벗 테이블을 배우면 데이터 분석이 재미있어 집니다.",
      "target_audience": [
        "많은 데이터를 다루는 데이터 과학자",
        "R이나 Python은 잘 다루지만 엑셀에 익숙지 않은 사람",
        "엑셀을 다루는 직장인- 특히 함수를 잘 모르는-"
      ]
    },
    {
      "title": "Corso pratico di Pandas e Python con esempi per data mining",
      "url": "https://www.udemy.com/course/python-pandas-il-corso-base-con-esempi-per-tutti/",
      "bio": "Se non conosci Python e Pandas questo corso ti guida passo passo alla loro comprensione con esempi chiari e replicabili",
      "objectives": [
        "Installare, configurare ed utilizzare python, Jupyter notebook e pandas",
        "Scaricare file CSV di datasets da fonti esterne trasformandoli in dataframe",
        "Le fondamenta della libreria pandas per python",
        "A manipolare i dataframe per migliorare la produttività e preparare al meglio i dati per elaborazioni successive come il machine learning"
      ],
      "course_content": {
        "Introduzione": [
          "Introduzione al corso",
          "Struttura del corso",
          "Velocità lezioni e note",
          "Istruzioni per scaricare gli esempi"
        ],
        "Installazione degli strumenti di lavoro": [
          "Scaricare l'interprete python",
          "Installare l'interprete python",
          "Verificare l'avvenuta installazione",
          "Scaricare Visual Studio Code",
          "Installare Visual Studio Code",
          "Installare le estensioni",
          "La cartella progetti di python",
          "Organizzazione di un progetto con python",
          "Il virtual environment",
          "Aggiornamento venv e sintassi MacOs/Linux",
          "Testare il tutto"
        ],
        "Le basi del linguaggio python": [
          "Modalità interattiva",
          "Le preferenze di visual studio code",
          "Importanza nel commentare il codice",
          "Calcolatrice con python",
          "Gli errori in python",
          "Variabili e costanti. Materiale didattico.",
          "La definizione di variabile",
          "Come stampare il tipo di una variabile",
          "I tipi di variabili in python",
          "Un esempio di utilizzo delle variabili",
          "Classificazione delle variabili",
          "Costanti ed assegnazione unica",
          "Casting. Materiale didattico,",
          "Idea di casting",
          "Funzione int()",
          "Funzione float()",
          "funzione srt()",
          "Input da tastiera, esempio di casting",
          "Matematica con python. Materiale didattico",
          "Una introduzione alla matematica di python",
          "Le espressioni matematiche",
          "Selezione di funzioni matematiche",
          "Stringhe. materiale didattico",
          "La definizione di stringa",
          "Come manipolare le stringhe",
          "I metodi della classe string",
          "I caratteri di escape",
          "Condizioni if else. Materiale didattico",
          "Costrutto if else",
          "Operatori relazionali",
          "Gli if annidati",
          "L'alternativa multipla if elif",
          "Gli operatori logici e booleani",
          "Cicli. Materiale didattico",
          "Una introduzione ai cicli",
          "Ciclo for parte A",
          "Ciclo for parte B",
          "Il ciclo for con le stringhe",
          "Ciclo while",
          "Ciclo do while in python",
          "I cicli annidati",
          "Funzioni. Materiale didattico",
          "Una introduzione alle funzioni",
          "la definizione di funzione",
          "Il passaggio dei parametri",
          "Lo scope delle variabili",
          "Le funzioni ricorsive",
          "Funzioni lambda"
        ],
        "Le strutture dati del python": [
          "Liste, tuple e tabelle. Materiale didattico.",
          "La definizione di lista",
          "Come accedere alle liste",
          "Le operazioni con le liste - parte A",
          "Le operazioni con le liste - parte B",
          "Le operazioni con le liste - parte C",
          "Le liste con le funzioni",
          "Le tuple e le tabelle",
          "Set e dizionari. Materiale didattico",
          "I set",
          "I dizionari",
          "Eccezioni. Materiale didattico",
          "Le eccezioni con le liste",
          "Le eccezioni con data input",
          "Le eccezioni: esempio completo"
        ],
        "Introduzione alla oop di python": [
          "Classi ed oggetti. Materiale didattico.",
          "Introduzione alla programmazione ad oggetti",
          "Le classi e gli oggetti",
          "L'ereditarietà"
        ],
        "Salvare progetti python con Github": [
          "Creazione di un repository su Github",
          "Clonare il progetto in Visual Studio Code e Commit"
        ],
        "Github Copilot": [
          "Introduzione a github copilot",
          "Come funziona github copilot",
          "Attivare github copilot",
          "Github copilot modalità chat",
          "Github copilot modalità file"
        ],
        "Introduzione a Pandas e prime esercitazioni": [
          "Materiale didattico per la sezione 6",
          "Introduzione a Pandas",
          "File CSV e data sets",
          "Installazione dell'ambiente di sviluppo",
          "Primi passi con Pandas A",
          "Primi passi con Pandas B",
          "Primi passi con Pandas C"
        ],
        "Le serie di Pandas": [
          "Materiale didattico per la sezione 7",
          "Le serie di Pandas A",
          "Le serie di Pandas B",
          "Compendio serie"
        ],
        "Il dataframe di Pandas": [
          "Materiale didattico per la sezione 8",
          "Modificare il dataframe",
          "Sottoinsiemi di dataframe",
          "Operare con i dataframe"
        ]
      },
      "requirements": [
        "Non è necessario conoscere il linguaggio pyhon. Imparerai a programmare nei primi capitoli del corso."
      ],
      "description": "Questo corso nasce con l'intento di insegnarti in modo pratico attraverso esempi concreti l'utilizzo e le potenzialità della libreria pandas. La libreria pandas ha avuto un grande successo con l'avvento della data science grazie alla sua facilità di utilizzo, alle sue prestazioni (è un wrapper di funzioni in linguaggio c ottimizzato e alla sua versatilità. Non solo data science, la libreria pandas è il tuo partner ideale se devi trattare dati tabellari per analisi matematiche successive oppure di natura statistica. Il corso è pensato per neofiti assoluti che hanno sentito parlare della libreria ma non hanno avuto il modo di studiarla e applicarla, se sei un neofita anche del linguaggio python non ti ti devi preoccupare perché tutta la prima parte del corso è dedicata alla comprensione di questo bellissimo linguaggio, sempre con esempi chiari e concreti. Il corso è suddiviso in dieci sezioni (capitoli) della durata di oltre dieci ore, tutte le lezioni pratiche sono corredate da esempi di codice che potrai comodamente scaricare ed utilizzare a tuo piacimento. Che tu sia un neofita assoluto oppure tu abbia dei rudimenti di python e pandas, questo è il corso che fa per te. Ti aspetto nel corso \"Python Pandas il corso base con esempi per tutti\".",
      "target_audience": [
        "Imparare la programmazione python",
        "Imparare le fondamenta della libreria pandas",
        "Imparare ad importare data sets in formato CSV",
        "Imparare ad ottimizzare e manipolare i dataframe per migliorare la produttività"
      ]
    },
    {
      "title": "データサイエンスのためのストリーミング前処理入門　PythonとSparkで始めるビッグデータストリーミング処理入門",
      "url": "https://www.udemy.com/course/python-spark-streaming/",
      "bio": "【データサイエンス/データエンジニアリングシリーズ】PythonとSparkでストリーミング処理を行ってみよう",
      "objectives": [
        "PySparkを使ったビッグデータストリーミング処理を学びます",
        "メッセージキュー(今回はApache Kafkaを使います)とストリーミング処理エンジン(Pyspark)の組み合わせを学びたい方",
        "Avroフォーマットなどストリーミングの開発に頻繁に使われるフォーマットについて学びます",
        "ケーススタディで実務を例に取ったデータエンジニアリングの流れで紹介",
        "データサイエンスのためのストリーミングにおける前処理について学習することができます"
      ],
      "course_content": {
        "紹介": [
          "講座タイトル",
          "本コースの概要",
          "講師自己紹介",
          "本コースがビッグデータ基盤のどこに当たるのか？"
        ],
        "環境構築": [
          "環境構築",
          "PySparkとは"
        ],
        "Kafka(メッセージキュー)基礎知識": [
          "本セクションの目次",
          "メッセージキューとエコシステム",
          "セクション2で構築した環境の説明",
          "クラウドonメッセージキュー",
          "メッセージキューがあると嬉しいのはなぜ？",
          "セクション3の小テスト"
        ],
        "Spark Structured Streaming とは？": [
          "本セクションの目次",
          "Spark.Structured Streamingとは？",
          "Kafkaとの組み合わせはどんなことに使われる？",
          "他のストリーミングツール",
          "セクション4小テスト"
        ],
        "【クイックスタート】メッセージキュー(Kafka)とPySpark Streaming": [
          "本セクションの目次",
          "コンポーネントの起動",
          "データの送信と確認",
          "データの送信と確認(コンソール)",
          "データの送信と確認(ファイルシンク)",
          "データの送信と確認（メッセージキューチェーン）",
          "データの送信と確認（メモリシンク）",
          "各シンクの使い分け",
          "pyspark-topic2からデータを読み取りjsonフォーマットでシンクするプログラムを書いてみましょう"
        ],
        "Kafka with Avroで脱初心者": [
          "本セクションの目次",
          "Avroフォーマット",
          "前方互換と後方互換と完全互換",
          "メッセージキューとAvroを連携してみよう",
          "Avroファイルの読み書き",
          "Avroで前方互換をやってみよう"
        ],
        "IoTツール、Kafka、PySparkを組み合わせてみよう": [
          "本セクションの目次",
          "組み合わせ概要説明",
          "Web画面からのデータ送信",
          "ウィンドウ処理",
          "DIKWモデル",
          "UUIDの付与処理とイベント時間の付与",
          "セクション７コース理解小テスト"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎知識があると良いです",
        "次のコースを学んでいると理解がスムーズです「データサイエンスのための前処理入門PythonとSparkで学ぶビッグデータエンジニアリング(PySpark) 速習講座」"
      ],
      "description": "現役のデータエンジニアがレクチャーします！\n\n\nAIや機械学習を行う際に最も時間のかかる作業は、データの準備とそれらの管理です。これらの作業のことをデータエンジニアリングと呼びます。実に８０％以上の時間をデータエンジニアリング(データサイエンスのための前処理や仕組み構築)に割いてるのが現状です。\n本コースではApache Sparkを使ったストリーミングのデータエンジニアリングについて学びます。\n\n\nポイント：\n本コースでは分散処理のデファクトとなりつつあるSparkについて学びます。\nApache Sparkはビッグデータ処理で多く使われている分散処理エンジンです。\n今回はPythonと組み合わせたPySparkを使ったストリーミング処理の講座です。\n\n\nストリーミング処理の基本から、Avroフォーマット、Webアプリケーションにおけるユーザのトラッキングとストリーミングの一連の流れをこのコース一つで学ぶことが可能です。\n\n\n特徴：\nデータエンジニアリングよりの講座です。\n難しいいサイエンスや数学は出てきませんが、データの3職種のうちの一つである「データエンジニア」のためのコースです。\n普段Pythonを使っている方やこれからAIやビッグデータの分野にエンジニアとして参画してデータを自在に操りたいという方にはぴったりです\nストリーミング処理を勉強してみたい方(メッセージキュー、ストリーミングについて学びたい方)\n\n\nソースコードや解説は以下のGitHubリポジトリにあります。\n動画内ではGitHubの資料に加え補足をしながら解説を進めています。",
      "target_audience": [
        "IoT開発やWebサイトのユーザーの行動履歴のトラッキングなどストリーミング処理を学びたい方",
        "データサイエンスで頻繁に行われる、ストリーミングにおける前処理を知りたい方"
      ]
    },
    {
      "title": "ChatGPT cursus / workshop in het Nederlands",
      "url": "https://www.udemy.com/course/chatgpt-in-het-nederlands/",
      "bio": "Leer alles over kunstmatige intelligentie (KI), artificial intelligence (AI), en chatbots. Inclusief oefeningen!",
      "objectives": [
        "Begrijpen wat Kunstmatige Intelligentie (KI) is",
        "Inzicht krijgen in de geschiedenis en concepten van chatbots",
        "Kennis verwerven over ChatGPT",
        "Ontdekken van de mogelijkheden van ChatGPT",
        "Toepassen van ChatGPT in verschillende contexten (zoals je bedrijf of je werk)",
        "Actief aan de slag: verschillende oefeningen met ChatGPT"
      ],
      "course_content": {
        "Introductie": [
          "Inleiding tot Kunstmatige Intelligentie (KI) en Chatbots",
          "Wat is ChatGPT?",
          "Wat kun je met ChatGPT doen?"
        ],
        "Kern - informatie": [
          "ChatGPT in klantenservice",
          "ChatGPT in onderwijs",
          "ChatGPT in gezondheidszorg",
          "ChatGPT in marketing",
          "ChatGPT in onderzoek",
          "Beperkingen en ethiek"
        ],
        "Kern - oefenen": [
          "Werken met ChatGPT",
          "Creatief schrijven",
          "Creatief schrijven",
          "Problemen oplossen en vragen stellen",
          "Problemen oplossen en vragen stellen",
          "Gesprekken simuleren",
          "Gesprekken simuleren"
        ],
        "Slot": [
          "Afsluiting"
        ]
      },
      "requirements": [
        "Geen kennis vereist"
      ],
      "description": "In deze cursus leer jij alles over ChatGPT, kunstmatige intelligentie (KI), artificial intelligence (AI) en chatbots. We geven jou algemene informatie over wat KI is en hoe het werkt, maar we gaan ook samen oefenen met ChatGPT zodat jij het leert gebruiken voor jouw werk, persoonlijke leven of studie.\nDeze cursus biedt jou een diepgaande verkenning van ChatGPT en de wereld van kunstmatige intelligentie. Je gaat niet alleen begrijpen wat KI en AI precies inhouden, maar je krijgt ook praktische ervaring met het effectieve gebruik van de krachtige tool, ChatGPT.\nWe beginnen met een overzicht van de basisbegrippen van kunstmatige intelligentie en hoe het zich door de jaren heen heeft ontwikkeld. Daarna duiken we dieper in ChatGPT, een geavanceerd taalmodel dat jou veel te bieden heeft. Je leert hoe ChatGPT is opgebouwd, hoe het getraind wordt en welke mogelijkheden het voor jou heeft.\nMaar we gaan verder dan alleen theoretische kennis. Samen gaan we hands-on oefeningen en praktische opdrachten uitvoeren om ChatGPT daadwerkelijk te gebruiken. Jij gaat ontdekken hoe je ChatGPT kunt inzetten om jouw werkprocessen te optimaliseren, persoonlijke taken te automatiseren en zelfs jouw studie-efficiëntie te verhogen. Door real-world scenario's te verkennen, ontwikkel jij de vaardigheden om effectief met ChatGPT te communiceren en het te integreren in verschillende aspecten van jouw leven.\nOf je nu een professional bent die op zoek is naar nieuwe manieren om productiever te zijn, een nieuwsgierig individu dat de mogelijkheden van KI wil verkennen, of een student die wil profiteren van geavanceerde tools, deze cursus biedt jou de kennis en praktische vaardigheden om het volledige potentieel van ChatGPT te benutten.",
      "target_audience": [
        "Deze cursus is bedoeld voor een breed publiek (studenten, ondernemers, medewerkers) met interesse in Kunstmatige Intelligentie, en specifiek ChatGPT."
      ]
    },
    {
      "title": "2024 빅데이터분석기사 자격증 마스터 패키지 - 필기(개념) + 실기(파이썬 Python)를 한번에!",
      "url": "https://www.udemy.com/course/rfjhluyv/",
      "bio": "[빅분기 실기 대비] 혼자서도 필기부터 실기까지 한번에 준비할 수 있도록 빅데이터 분석 기사 시험의 핵심 개념을 큰 틀에서부터 체계적으로 알려드립니다.",
      "objectives": [
        "빅데이터 분석 기사 필기 시험에 필요한 개념을 배웁니다.",
        "빅데이터 분석 기사 실기 시험에 필요한 파이썬 기본 문법을 배웁니다.",
        "빅데이터 분석 기사 실기 시험에 필요한 개념을 배웁니다.",
        "빅데이터 분석 기사 실기 모의고사 및 기출 문제를 풀이합니다."
      ],
      "course_content": {
        "빅분기 필기+실기 합격 패키지": [
          "자료1. 패키지 소개",
          "자료2. 4주/5주 스터디 플랜",
          "자료3. 강의안 : 필기 + 실기 + 파이썬 기초 특강",
          "자료3. 5주 스터디 노트 : 필기"
        ],
        "빅데이터 분석 기사(필기) - 기본 개념": [
          "빅데이터 분석 기사 시험 및 강의 소개",
          "빅데이터 분석 기획",
          "빅데이터 탐색 1",
          "빅데이터 탐색 2",
          "빅데이터 탐색 3",
          "빅데이터 탐색 4",
          "빅데이터 모델링 1",
          "빅데이터 모델링 2",
          "빅데이터 결과 해석"
        ],
        "빅분기 실기를 위한 파이썬 기초 특강": [
          "파이썬 소개",
          "파이썬 데이터 타입",
          "파이썬 연산자, 흐름제어",
          "파이썬 함수",
          "파이썬 클래스",
          "파이썬 패키지 - Numpy 배열과 벡터",
          "파이썬 패키지 - Pandas 자료구조",
          "파이썬 패키지 - Matplotlib 시각화"
        ],
        "빅데이터 분석 기사(실기)": [
          "빅데이터 분석 기사 실기 - 소개",
          "빅데이터 분석 기사 실기 - 제 1 유형 Part 1",
          "빅데이터 분석 기사 실기 - 제 1 유형 Part 2",
          "빅데이터 분석 기사 실기 - 제 1 유형 Part 3",
          "빅데이터 분석 기사 실기 - 제 1 유형 Part 4",
          "빅데이터 분석 기사 실기 - 제 2 유형",
          "빅데이터 분석 기사 실기 - 제 3 유형",
          "빅데이터 분석 기사 실기 - 기출 문제 풀이 Part 1",
          "빅데이터 분석 기사 실기 - 기출 문제 풀이 Part 2",
          "빅데이터 분석 기사 실기 - 모의고사 문제 풀이"
        ]
      },
      "requirements": [
        "빅데이터 분석 기사 필기/실기 시험에 필요한 개념과 파이썬 문법부터 시작합니다."
      ],
      "description": "빅데이터 분석 기사 자격증 취득을 위한 시험 대비 강의입니다.\n빅데이터 분석 기사는 국가 기술 자격증으로 필기와 실기 시험이 있습니다.\n\n필기 총 80문항(객관식, OMR 카드 제출)\n- 빅데이터 분석기획\n- 빅데이터 탐색\n- 빅데이터 모델링\n- 빅데이터 결과해석\n\n실기 3개 유형(CBT, Computer Based Test를 통해 제출, 파이썬/R)\n- 데이터 전처리\n- 머신러닝\n- 통계\n\n\n빅데이터 분석 기사는 최근 출제 경향이 바뀌고 있습니다.\n이전에는 필기와 실기 모두 책을 달달 외워서 단순 암기를 하거나, 코드를 외워서 풀 수 있는 문제가 나왔습니다.\n\n그런데 이제는 개념을 이해하고 있어야 풀 수 있는 문제로 바뀌고 있습니다. 즉, 단순 암기가 아니라 개념을 제대로 이해하는 방향으로 공부해야 한다는 말입니다. 특히 실기를 준비하시는 비전공자 분들의 경우 코드를 외우는 것이 아니라 코드의 개념과 내용을 이해하는 방향으로 공부하시는게 반드시 필요합니다.\n\n\n본 강의에서는 빅데이터 분석 기사 필기와 실기 시험에서 모두 필요한 핵심 개념을 제대로 이해하실 수 있도록 큰 틀을 먼저 설명해드립니다. 그리고나서 꼭 알아야 하는 개념과 많이들 어려워 하시는 개념 위주로 알기 쉽게 정리해드립니다. 이후 개념서를 통해 독학하시면 보다 더 효과적으로 시험에 대비하실 수 있습니다.\n\n\n본 강의에서는 빅데이터 분석 기사 실기 시험에 필요한 데이터 전처리, 머신러닝, 통계분석도 다룹니다.\n\n\n또한 파이썬 기본 문법도 설명해드립니다. 실기를 준비하시는 분들 중 파이썬이 처음이신 분들은 파이썬 기본 문법을 먼저 들으신 후 이후 섹션을 수강하시면 됩니다. (파이썬 기본 문법을 이미 알고 계신 분들은 해당 섹션은 넘어가셔도 됩니다.)\n\n\n빅데이터 분석 기사는 필기 시험 합격 후 2년 동안 실기 시험을 보실 수 있습니다. 본 강의는 한 번 수강 신청하시면 평생 소장이니 혹여나 실기 시험을 재응시하셔야할 경우 언제든 다시 보실 수 있습니다.\n\n\n수강생 여러분의 빅데이터 분석 기사 필기+실기 자격증 취득을 응원합니다!\n강의에서 뵙겠습니다. 감사합니다.\n\n\n[강의 개요 및 순서]\n1. 빅데이터 분석 개요\n2. 빅데이터 분석 기사 필기 개념 정리\n3. 파이썬 문법 정리\n4. 실기1: 데이터 전처리\n5. 실기2: 머신러닝 모델 - 예측\n6. 실기3: 통계 검정\n7. 빅데이터 분석 기사 실기 모의고사, 기출문제 풀이",
      "target_audience": [
        "빅데이터 분석 기사 시험을 준비하는 수험생"
      ]
    },
    {
      "title": "Pengenalan Artificial Neural Network (ANN) untuk Pemula",
      "url": "https://www.udemy.com/course/artificial-neural-network-ann/",
      "bio": "ANN, Algoritma, Perceptron Algorithm, Backpropagation Neural Network, Performance Evaluation, Self-Organizing Map",
      "objectives": [
        "Pelajar dapat memahami dasar algoritma ANN (Artificial Neural Network) dan dapat menerapkannya untuk memecahkan masalah yang nyata."
      ],
      "course_content": {},
      "requirements": [
        "Memiliki pengetahuan tentang matematika dasar"
      ],
      "description": "Materi ini menjelaskan tentang pengenalan ANN(Artificial Neural Network) yang merupakan representasi dari otak manusia. Materi ini terdapat dua paradigma pembelajaran, yaitu supervised learning dan unsupervised learning  dengan perceptron, backpropagation neural network dan algoritma self-organizing map. Pada bagian terakhir, terdapat teknik untuk dimension reduction dan Principal Component Analysis (PCA). Semua materi akan dijelaskan menggunakan slide dan beberapa komputasi tangan untuk setiap algoritma. Materi ini dapat diselesaikan dalam 2.5 jam. Pada akhir kursus ini, siswa akan memahami algoritma dasar ANN dan menerapkannya untuk memecahkan masalah yang nyata.",
      "target_audience": [
        "Pelajar yang ingin belajar tentang ANN (Artificial Neural Network)"
      ]
    },
    {
      "title": "Fondamentaux de l’actuariat",
      "url": "https://www.udemy.com/course/fondamentaux-de-lactuariat/",
      "bio": "Apprendre les bases de l’actuariat, Data Science du risque et de l’assurance.",
      "objectives": [
        "- dialoguer avec des actuaires dans le cadre de projets liés à l’industrie du risque, de la finance ou de l’assurance",
        "- présenter les principaux modèles de calcul actuariels",
        "- appréhender les bases de la science actuarielle et en parler en utilisant le vocabulaire approprié",
        "- effectuer des calculs simples et notamment des estimations de tarifs ou de provisions"
      ],
      "course_content": {
        "Introduction": [
          "Présentation du cours"
        ],
        "Introduction générale": [
          "Le métier d'actuaire"
        ],
        "Place de l'actuaire dans l'assurance": [
          "Activités de l'assurance et autres",
          "Tarification",
          "Provisionnement",
          "Assurance de personnes"
        ],
        "Gestion financière et transfert de risque": [
          "Gestion financière",
          "Réassurance"
        ],
        "Modélisation des risques et réglementation": [
          "Réglementation : Solvabilité 2",
          "Réglementation : IFRS"
        ],
        "Vers de nouvelles pratiques": [
          "Data science et machine learning"
        ]
      },
      "requirements": [
        "Pas de prérequis"
      ],
      "description": "Grâce à cette formation à l’actuariat, vous allez apprendre les bases de la Data Science du risque et de l’assurance. Tous les fondamentaux de l’actuariat sont présentés afin d’appréhender les grands modèles statistiques de la science actuarielle. En liaison avec l’association Diffusion Internationale de l’Actuariat Français, le Collège de Paris délivre un certificat « fondamentaux de l’actuariat » aux étudiants qui complètent ce cours sur Udemy.",
      "target_audience": [
        "Toute personne s’intéressant aux métiers du risque, de l’assurance ou de la finance."
      ]
    },
    {
      "title": "ODI(Oracle Data Integrator)12C Beginner To Expert",
      "url": "https://www.udemy.com/course/odioracle-data-integrator12c-beginner-to-expert/",
      "bio": "KM,Odiref,Loops,ODITools,Mappings ve daha fazlası",
      "objectives": [
        "ODI'de Mapping,Package,Procedure Nasıl Yaratılır",
        "Knowloadge Moduller Nelerdir Nasıl Yazılır",
        "OdiRef Functionslar Nelerdir Nasıl Kullanılır",
        "ODIToolslar Nelerdir Nasıl Kullanılır",
        "Jyton Nedir",
        "Agent Tipleri Kurulumları ve Farkları",
        "Repository Tipleri ve Kurulumları",
        "Looplar Nasıl Yaratılır"
      ],
      "course_content": {
        "Kursa Giriş": [
          "Neden ODI 12C?",
          "Kurs içeriği"
        ],
        "Kurulumlar": [
          "ODI Demo Kurulum",
          "ODI Demo Tanıtım ve Kalan Kurulumlar",
          "Hyper-V Nedir,Neden Kurmayı Tercih Edebilirsiniz?",
          "Hyper-V Sunucu Kurulumu",
          "Shared Folder Ayarları (Kurulum Dosyaları İçin Transfer Ayarları)",
          "Kurulum Yapılacak Araçlar ve İndirme Yöntemleri",
          "Java Kurulumu",
          "Oracle 19C DB Kurulumu",
          "ODI Studio Kurulum",
          "Repository Kurulumları",
          "Agent Kurulumları",
          "SQL Developer Kurulum",
          "SQL Server Kurulum"
        ],
        "ODI Studio Kullanımı": [
          "ODI Studio Arayüz Tanıtımı",
          "DB User ve Yetki Tanımlamaları",
          "Topology Tanımlamaları",
          "Model Tanımlamaları",
          "İlk Mapping DB to DB",
          "Flat File To DB",
          "Filter Component",
          "Distinct Component",
          "Aggregate Component",
          "Expression Component",
          "Join Component",
          "Set Component",
          "Lookup Component",
          "Sort Component",
          "Split Component",
          "Pivot Component",
          "Unpivot Component",
          "Subquery Component",
          "Simulation Özelliği",
          "DB To Flat File Mapping Örneği",
          "Mappingdeki Logical Katmanın Detayları",
          "Package Nedir?",
          "Scenario Nedir?",
          "Procedure ve İlk Örnek",
          "Procedure İle Mapping Yapımı",
          "Procedurede ODITools ve Diğer Teknolojiler",
          "Variables Nedir Tipleri Nelerdir?",
          "Mappin İçinde Variable Kullanımı",
          "Basic Loop Örneği",
          "Gelişmiş Loop Örneği",
          "Reusable Mappings",
          "Versionlama",
          "Sequences",
          "User Functions",
          "Operator Tanıtım",
          "Find Odi Object",
          "Security Tanıtım",
          "Load Plan",
          "Main Package",
          "Schedule Seçenekleri",
          "Context-Logical-Pyhsical İlişkisi"
        ],
        "Package Toolbox&Tüm ODI Toollar": [
          "File Tools",
          "Export Tools",
          "FTP Tools",
          "Diğer Toollar-1",
          "Diğer Toollar-2",
          "MetaData ve SAP Toolları",
          "OdiSendMail Tool",
          "Diğer Toollar-3",
          "Diğer Toollar-4",
          "Trigger Tools",
          "OdiSqlUnload Tool",
          "OdiOSCommand Tool"
        ],
        "Knowladge Modüller ve Odiref Functionlar": [
          "LKM ve IKM Nedir?",
          "CKM,XKM,JKM,RKM,SKM Nedir?",
          "JKM Örnek Uygulama",
          "OdiRef Fonksiyonlara Giriş",
          "OdiRef ile Knowladge Modul Geliştirme"
        ],
        "İleri Seviye Örnekler": [
          "CDC Örneği",
          "SCD Type-2 Mapping Örneği",
          "Jyton Nedir ve Örneği",
          "Multiple Flat File To DB Örneği"
        ],
        "İleri Seviye Konular": [
          "Agent Nedir Tipleri Nelerdir",
          "Agent Stop ve Start Etme(Standolone)",
          "Odi Studio Hızlandırma",
          "Teknolojiler ve Özellikleri",
          "Languages ve Özellikleri",
          "Repositoryler",
          "Teşekkür & Kapanış"
        ]
      },
      "requirements": [
        "Bilgisayar",
        "SQL"
      ],
      "description": "Merhaba,\n\n\nODI, yani Oracle Data Integrator, veri entegrasyonu ve yönetimi için geliştirilmiş güçlü bir araçtır. ODI, farklı veri kaynakları arasında veri akışlarını kolayca yönetmek, dönüştürmek ve izlemek için kullanılır. Özellikle büyük veri projelerinde ve karmaşık veri entegrasyon senaryolarında, veri hareketlerini optimize etmek ve iş süreçlerini otomatize etmek için ideal bir çözümdür. ODI, kullanıcılarına grafiksel kullanıcı arayüzü ve esnek script yazma yetenekleri sunarak, hem yeni başlayanlar hem de deneyimli kullanıcılar için uygun bir çalışma ortamı sağlar.\n\n\nBu sıfırdan ileri seviye ODI12c eğitim serisi, Oracle Data Integrator 12c hakkında detaylı ve kapsamlı bir rehber olarak her zaman sizinle olacak.ODI12c'nin temelinden başlayarak ileri seviye konseptlere kadar geniş bir yelpazede bilgiye sahip olacaksınız.\n\n\nODI kurulumu zor olarak adlandırılan bir ELT aracıdır fakat bu seri içerisinde iki farklı kurulum yöntemi göreceksiniz ve bunlardan en az birini sorunsuz kurup kursu takip edebileceksiniz.\n\n\nKurs içeriğinde, Knowledge Moduller (IKM, LKM, JKM, XKM, RKM, SKM) konularıyla başlayarak ODIref fonksiyonlarına, Jython script yazımına, Agent yapılandırmalarına, Repository yönetimine, Package oluşturma ve yönetimine, Load Plan tasarlama gibi konulara detaylı bir şekilde değiniceğiz.\n\n\nAyrıca ODIToolsların her biri üzerine tek tek konuşacağız.\n\n\nBu kurs sadece ODI12c'nin mevcut özelliklerini ve fonksiyonlarını öğretmekle kalmayacak, aynı zamanda kurs katılımcılarının geri bildirimlerine göre güncellenecek bir yapıya sahiptir. Eğer sizin de ODI12c ile ilgili bir sorununuz veya talebiniz varsa, bu sorunları kurs içeriğine dahil ederek kursun her zaman güncel ve yaşayan bir kaynak olmasını sağlayacağım.\n\n\nBu eğitim serisi sayesinde ODI12c'nin derinliklerine inerek, veri entegrasyonu ve yönetimi konusunda uzmanlaşacaksınız.\n\n\nGeri bildirimleriniz benim için çok önemli bu yüzden lütfen kursu değerlendirmeyi unutmayın ve eksik noktaları iletmekten çekinmeyin",
      "target_audience": [
        "Data Engineer",
        "Data Scientist",
        "Veri alanında çalışan herkes"
      ]
    },
    {
      "title": "【初心者向け】生成AIの様々な活用法！ChatGPTを使ってExcel関数とマクロ(VBA)の自動作成をしていこう！",
      "url": "https://www.udemy.com/course/gpt-excel/",
      "bio": "生成AI(ChatGPT)の様々な活用法について学ぼう！生成AIに関する基礎を学び、文章生成・企画出しなどに使える適切なプロンプトを学ぼう！最終的にExcel関数やマクロ(VBA)を生成AIで作成しExcel業務を効率化してみよう！",
      "objectives": [
        "生成AIを用いて、文章を効率的に作成できるようになる",
        "生成AIを用いて、企画や改善方法の案を出し、その内容を深めることができるようになる",
        "生成AIを用いて、事前知識がない内容でも、Excelを用いた作業ができるようになる",
        "生成AIを用いて、ITツールを用いた業務改善ができるようになる"
      ],
      "course_content": {
        "はじめに": [
          "イントロダクション"
        ],
        "生成AIの活用方法について知ろう！": [
          "生成AIの活用方法"
        ],
        "生成AIを使って様々な文章を作成してみよう！": [
          "文章作成"
        ],
        "生成AIを使って企画・アイディア出しをしてみよう！": [
          "企画・アイディア出し"
        ],
        "生成AIを文章要約や理解の補助に使ってみよう！": [
          "文章要約・理解の補助"
        ],
        "生成AIを使ったツール活用とExcelの基礎について学ぼう！": [
          "生成AIを用いたツール活用"
        ],
        "生成AIを使ってExcel作業を効率化してみよう！": [
          "Excelの作成方針相談"
        ],
        "生成AIを使ってExcelの関数を作成してみよう！": [
          "Excel関数の作成"
        ],
        "生成AIを使ってマクロ（VBA）を組んでみよう！": [
          "マクロ（VBA）の利用と作成",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "特に要件はありませんが、業務の中で表計算ツールやチャットツールなどのITツールを用いて業務を行っていることが望ましいです"
      ],
      "description": "このコースでは、生成AIの活用方法について学んでいきます！\n\n\nまず生成AIを利用する上でおさえておいて知識についてザックリ概要を学んでいきます。\n\n\nその後に文章生成・文章要約や企画・アイディア出しなど日々の業務に生成AIを使うノウハウを学んでいただきます。\n\n\nその上でExcelの関数やマクロ(VBA)を生成し、Excel業務を最大限効率化する方法を学んでいきます。\n\n\n要所要所で演習を挟んでいるので適宜動画を止めて演習に取り組んでみて下さい。\nまた、かなり初心者向けに作っているので冗長だなと感じる部分もあるかもしれません。必要のない箇所は適宜飛ばしながら、ぜひ自分に必要なエッセンスだけ吸収してください！\n\n\n普段の業務に生成AIを取り入れて仕事を効率化していきましょう！",
      "target_audience": [
        "ChatGPTなどの生成AIを使って普段の業務を効率化していきたい方",
        "Excelの計算やマクロ作成をChatGPTなどの生成AIを使って効率化していきたい方"
      ]
    },
    {
      "title": "R NA PRÁTICA: Data Wrangling com R para Ciência de Dados",
      "url": "https://www.udemy.com/course/r-na-pratica-ciencia-de-dados/",
      "bio": "Introdução aos fundamentos de R + Data Wrangling com R para ciência de dados na prática",
      "objectives": [
        "Dominar os principais conceitos e elementos da linguagem R;",
        "Criar gráficos elegantes e informativos com base graphics, lattice graphics e ggplot2 graphics;",
        "Desenvolver relatórios dinâmicos e elegantes para análises de dados com RMarkdown e seus templates;",
        "Tornar-se independente em manipulação e análise de dados com a linguagem R na filosofia do tidyverse;",
        "Ciclo da descoberta e extração de conhecimento de dados através do uso do R."
      ],
      "course_content": {
        "Preparativos": [
          "Apresentação R na Prática",
          "Introdução",
          "Preparando o Computador Windows",
          "Preparando o Computador Linux Ubuntu",
          "Conhecendo a IDE do RStudio"
        ],
        "R Básico: Introdução": [
          "Elementos Essenciais",
          "Lista 01 - Elementos essenciais",
          "Operadores e Sequências: Parte 01",
          "Operadores e Sequências: Parte 02",
          "Tarefa sobre operadores e sequências",
          "If, else if",
          "loop (for, while e repeat)"
        ],
        "R Básico: Objetos": [
          "Introdução",
          "Vetores",
          "Matrizes e Arrays: Parte 01",
          "Matrizes e Arrays: Parte 02",
          "Matrizes e Arrays: Parte 03",
          "Caracteres: Parte 01",
          "Caracteres: Parte 02",
          "Caracteres: Parte 03",
          "Data frames e Listas: Parte 01",
          "Data frames e Listas: Parte 02",
          "Data frames e Listas: Parte 03",
          "Classes e Coerção",
          "Datas: Parte 01",
          "Datas: Parte 02"
        ],
        "R Básico: Funções": [
          "Funções Nativas (Prontas)",
          "Funções Customizadas (Criação)",
          "Família Apply",
          "Família Apply Melhorada (pacote plyr)",
          "Case 01: Preparação de Funções: Parte 01",
          "Case 01: Preparação de Funções: Parte 02",
          "Case 01: Preparação de Funções: Parte 03"
        ],
        "R Básico: Gráficos": [
          "Base Graphics: Parte 01",
          "Base Graphics: Parte 02",
          "Base Graphics: Parte 03",
          "Base Graphics: Parte 04",
          "Base Graphics: Parte 05",
          "Base Graphics: Parte 06",
          "Lattice Graphics",
          "ggplot Graphics: Parte 01",
          "ggplot Graphics: Parte 02",
          "ggplot Graphics: Parte 03",
          "ggplot Graphics: Parte 04"
        ],
        "R Intermediário: Novos Conceitos": [
          "Tidyverso e Operador %>%",
          "O Pacote dplyr + %>%",
          "Tidy Data e o Pacote tidyr",
          "Tibbles"
        ],
        "R Intermediário: Descoberta de Conhecimento (Ciclo)": [
          "Situação Problema",
          "Obtenção de Dados: De Pacotes e Clipboard",
          "Obtenção de Dados: TXT e CSV",
          "Obtenção de Dados: Excel e ODS",
          "Obtenção de Dados: SPSS e SAS",
          "Obtenção de Dados: Banco de Dados - Introdução",
          "Obtenção de Dados: Banco de Dados - Access e Excel via ODBC",
          "Obtenção de Dados: Banco de Dados - SQL Server 2016",
          "Obtenção de Dados: Banco de Dados - MySQL",
          "Extra: Big Data Com data.table",
          "Case 02: Preparação de Dados",
          "Case 02: Preparação de Dados: Solução - Parte 01",
          "Case 02: Preparação de Dados: Solução - Parte 02",
          "Análise de Dados: Parte 01",
          "Análise de Dados: Parte 02",
          "Visualização de Dados: Parte 01",
          "Visualização de Dados: Parte 02",
          "Comunicação de Resultados (R Markdown): Parte 01",
          "Comunicação de Resultados (R Markdown): Parte 02",
          "Case 03 - Análise dados do Censo - Parte 01",
          "Case 03 - Análise dados do Censo - Parte 02",
          "O Ciclo R na Prática (never ends!)"
        ],
        "Extras": [
          "Múltiplos arquivos de dados - Etapa do R",
          "Atualizações de ferramentas R, rtools e RStudio/Posit"
        ]
      },
      "requirements": [
        "Computador com acesso à internet.",
        "Vontade de aprender e alguma noção de lógica de programação"
      ],
      "description": "A linguagem R é uma das que mais cresce atualmente no mundo das linguagens de programação científicas. Esta linguagem tem sido uma das mais requisitadas por empresas, centros de pesquisa e por recrutadores das áreas de analytics e data science. Isso graças ao poder de processamento, aos recursos e à sua capacidade de expansão. R é uma linguagem científica, cross-plataforma, orientada a objetos, free e open source com uma comunidade de desenvolvedores e colaboradores global extremamente ativa.\nO conceito Data Wrangling é um tanto genérico em nosso português brasileiro, mas poderia ser traduzido como disputa/briga/luta de dados. Esta disputa está intimamente ligada ao processo de transformação de dados e isso inclui: obtenção, transformação, limpeza, agregação, visualização e criação de bases limpas para fins de Analytics na Ciência de Dados.\nO R na Prática é um curso cuidadosamente elaborado para ajudar a todos que desejam aprender, melhorar, atualizar seus conhecimentos em R e assim se destacar na descoberta de conhecimentos através de dados. Nossa abordagem é um mix de teoria e prática unidos e aplicados a situações reais de análise de dados. Iniciaremos com os fundamentos básicos de R e na sequência varreremos o ciclo de descoberta de conhecimentos que vai desde a obtenção dos dados à apresentação de resultados visando sempre a descoberta de conhecimentos.\nAo final do curso de R na Prática você será capaz de dominar conteúdos como:\nOperadores, sequências, funções, loops, família apply e gráficos dos sistemas base, lattice e ggplot2;\nAgregação, transformação, estatística descritiva de dados e tabelas de frequências;\nDominará a criação de códigos otimizados em R com o moderno operador pipe \"%>%\" e os pacotes do tidyverse;\nTerá domínio sobre o processo de obtenção de conhecimento a partir de dados passando pelo ciclo de análise de situação problema, obtenção de dados, preparação, análise, visualização e comunicação de resultados com R Markdown;\nSerá capaz de resolver cases de estudo e problemas com dados e situações reais.\nTerá um vasto material de consulta com amostras de códigos e bases de dados de exemplos de todas as video aulas para reforçar seus conhecimentos e aplicações no dia-a-dia.\nTudo isso em um ciclo desenhado especialmente para que você saiba a trilha certa a seguir e seu aprendizado em R e suas aplicações seja gradual e contínuo.",
      "target_audience": [
        "Interessados em aprender/praticar R.",
        "Pesquisadores, estudantes de faculdades e universidades.",
        "Profissionais e praticantes de ciência de dados."
      ]
    },
    {
      "title": "A-Z™ | Object Detection-Segmentasyon | Görüntü İşleme | 2023",
      "url": "https://www.udemy.com/course/a-ztm-object-detection-segmentasyon-goruntu-isleme-2023/",
      "bio": "Tüm Yolo Serileri - Tensorflow 1/2 - Detectron2 - MMDetection - PaddleDetection - DETR - PointRend - SAHI - Mask R-CNN",
      "objectives": [
        "NOT : Bu kurs tamamen uygulama içerir. Kesinlikle teori içermez. Proje ve uygulama üzerine oluşturulmuştur. Herşeyi sıfırdan yapıyoruz.",
        "NOT: Bu alan ile ilgili projeniz varsa ve benim teori ile işim yok ben kendi verilerim ile uygulama yapmak istiyorum diyorsanız doğru yeredesiniz. Hoşgeldiniz",
        "Derin öğrenme ve Evrişimsel Sinir Ağlarının Teorisini Öğreneceğiz.",
        "YOLO Ailesinde olan Tüm Algoritmalarla Özel (Custom) Verilerde Nasıl Nesne Tespiti Yapılacağını Öğreneceğiz.",
        "Tensorflow 1 ve 2 ile Modern Algoritmalarda Özel (Custom) Veriler ile Nasıl Nesne Tespiti Yapılacağını Öğreneceğiz.",
        "Detectron2 ile Faster R-CNN Algoritmasın'da Özel (Custom) Veriler ile Nasıl Nesne Tespiti Yapılacağını Öğreneceğiz.",
        "MMDetection ToolBox ile Özel (Custom) Veriler ile Nasıl Nesne Tespiti Yapılacağını Öğreneceğiz",
        "DETR ile Özel (Custom) Veriler ile Nasıl Nesne Tespiti Yapılacağını Öğreneceğiz",
        "PaddleDetection ile Özel (Custom) Veriler ile Nasıl Nesne Tespiti Yapılacağını Öğreneceğiz",
        "HaarCascade ile Özel (Custom) Veriler ile Nasıl Nesne Tespiti Yapılacağını Öğreneceğiz.",
        "Türk Yapımı ve Gurur Kaynağı Olan SAHI Algoritmasının Ne Olduğunu ve Kullanmayı Öğreneceğiz.",
        "Detectron2 ile Mask R-CNN Algoritmasında Özel (Custom) Veriler ile Nasıl Segmentasyon (Maskeleme) Yapılacağını Öğreneceğiz.",
        "MMDetection ToolBox ile Özel (Custom) Veriler ile Nasıl Segmentasyon Yapılacağını Öğreneceğiz",
        "PointRend ile Özel (Custom) Veriler ile Nasıl Segmentasyon Yapılacağını Öğreneceğiz",
        "Yolov7 ile Özel (Custom) Veriler ile Nasıl Segmentasyon Yapılacağını Öğreneceğiz",
        "Yolov8 ile Özel (Custom) Veriler ile Nasıl Segmentasyon Yapılacağını Öğreneceğiz"
      ],
      "course_content": {
        "Giriş": [
          "Kurs Tanıtımı | Almadan Önce Mutlaka İzleyin !!!!!",
          "Kursa Nasıl Çalışmalıyız | Aldıktan Sonra Mutlaka İzleyin !!!!! | Önemli",
          "Kaynaklar"
        ],
        "Yolov3 ile Nesne Tanıma": [
          "Giriş",
          "Veriyi Hazırlama",
          "Model Eğitimi + Model Testi"
        ],
        "Yolov4 ile Nesne Tanıma": [
          "Giriş",
          "YoloV4 için Veri Etiketleme",
          "Yolov4 Dosyaları Hazırlama",
          "YoloV4 Eğitim + Test",
          "Yolov4 Local'de Test (Webcam - Real Time)"
        ],
        "Yolov5 ile Nesne Tanıma": [
          "Veriyi Hazırlama",
          "Model Eğitimi + Model Testi",
          "Localde Test",
          "Test Videosu"
        ],
        "Yolov6 ile Nesne Tanıma": [
          "Veriyi Hazırlama + Model Eğitimi + Model Testi"
        ],
        "Yolov7 ile Nesne Tanıma": [
          "Veriyi Hazırlama + Model Eğitimi + Model Testi"
        ],
        "Yolov8 ile Nesne Tanıma": [
          "Giriş + Veriyi Hazırlama",
          "Model Eğitimi + Model Testi"
        ],
        "YoloR ile Nesne Tanıma": [
          "Veriyi Hazırlama + Model Eğitimi + Model Testi"
        ],
        "YoloX ile Nesne Tanıma": [
          "Giriş",
          "YoloX Nedir | Tanıtım",
          "YoloX için Veri Etiketleme",
          "YoloX Eğitim",
          "YoloX Test",
          "YoloX Test Videosu"
        ],
        "Detectron2 ile Nesne Tanıma": [
          "Detectron2 Nedir ?",
          "Veriyi Hazırlama + Model Eğitimi + Model Testi"
        ]
      },
      "requirements": [
        "Öğrenme Arzusu ve Azim",
        "Temel Python Bilgisi",
        "Temel Seviyede Derin Öğrenme Bilgisi ve Konulara Aşinalık",
        "Temel Düzeyde Matematik Bilgisi"
      ],
      "description": "A-Z™ | Object Detection-Segmentasyon | Görüntü İşleme | 2023\nKursumuzda klasik ve derin öğrenme tabanlı yöntemlerini kullanarak kendi (custom) verilerimiz ile Nesne tespiti ve Segmentasyon çalışmaları yapıp tecrübe sahibi olacağız.\nÖğreneceğiniz algoritmalar ve toolboxlar günümüzdeki en popüler algoritmalardır.\nBu kurs tamamen uygulama içerir. Kesinlikle teori içermez.\nProje ve uygulama üzerine oluşturulmuştur.\nBu alan hakkında bilginiz yoksa ağır gelebilir.\nBu alan ile ilgili projeniz varsa ve benim teori ile işim yok ben kendi verilerim ile uygulama yapmak istiyorum diyorsanız doğru yeredesiniz. Hoşgeldiniz.\nA-Z™ | Object Detection-Segmentasyon | Görüntü İşleme | 2023 Kursu İçeriği\nGiriş Bölümü\nDerin Öğrenme Teori\nCNN (Convolutional Neural Networks) Teori\nEk Teori\nYolov3 ile Nesne Tanıma | Özel (Custom ) Veri\nYolov4 ile Nesne Tanıma | Özel (Custom ) Veri\nYolov5 ile Nesne Tanıma | Özel (Custom ) Veri\nYolov6 ile Nesne Tanıma | Özel (Custom ) Veri\nYolov7 ile Nesne Tanıma | Özel (Custom ) Veri\nYolov8 ile Nesne Tanıma | Özel (Custom ) Veri\nYoloR ile Nesne Tanıma | Özel (Custom ) Veri\nYoloX ile Nesne Tanıma | Özel (Custom ) Veri\nDetectron2  ile Nesne Tanıma | Özel (Custom ) Veri\nTensorflow 1 ile Nesne Tanıma | Özel (Custom ) Veri\nTensorflow 2 ile Nesne Tanıma | Özel (Custom ) Veri\nMMDetection ile Nesne Tanıma | Özel (Custom ) Veri\nPaddle Detection ile Nesne Tanıma | Özel (Custom ) Veri\nDETR ile Nesne Tanıma | Özel (Custom ) Veri\nHaarCascade ile Nesne Tanıma | Özel (Custom ) Veri\nSAHI KÜTÜPHANESİ | Türk Yapımı ve Gurur Kaynağı\nYolov7 ile Segmentasyon | Özel (Custom ) Veri\nYolov8 ile Segmentasyon | Özel (Custom ) Veri\nDetectron2  ile Segmentasyon | Özel (Custom ) Veri\nMMDetection ile Segmentasyon | Özel (Custom ) Veri\nPointRend  ile Segmentasyon | Özel (Custom ) Veri",
      "target_audience": [
        "Görüntü işleme ve Bilgisayarlı Görü konusunda uzmanlaşmak isteyenler",
        "Geleceğin mesleklerinde yetkin olmak isteyen herkes",
        "Yapay zekaya ilgi duyan herkes",
        "Derin öğrenme konusundaki teorik ve uygulama bilgisiyle gerçek hayat problemlerini çözmek isteyenler",
        "Derin öğrenme yöntemleri ile nesne tespitinin ve sınıflandırmanın nasıl yapılacağını öğrenmek isteyenler",
        "Görüntü işlemenin Python ile nasıl kodlanacağını öğrenmek isteyenler",
        "Dünyada en çok kullanılan Object Detection ve Segmentasyon Algoritmalarını kullanmak ve tecrübe sahip olmak isteyenler"
      ]
    },
    {
      "title": "ChatGPT: Curso Completo do Básico ao Avançado",
      "url": "https://www.udemy.com/course/chatgpt-curso-completo-do-basico-ao-avancado-2023-g/",
      "bio": "Domine o ChatGPT: Aprenda a utilizar o ChatGPT para melhorar seu Marketing, vender mais e criar diálogos eficientes!",
      "objectives": [
        "ChatGPT do zero ao avançado",
        "Como ganhar dinheiro com o ChatGPT",
        "Como usar o ChatGPT para criar conteúdo para marketing e vendas",
        "Como melhorar seu Marketing com ChatGPT",
        "Como aumentar sua produtividade com o ChatGPT",
        "Como criar excelentes Copys com o ChatGPT",
        "Como utilizar o ChatGPT para melhorar seu Copywriting",
        "Melhorar o SEO do seu site, criar descrições chamativas para seu e-commerce na Amazon, mercado livre, Dropshipping, com ChatGPT",
        "Como se manter atualizado sobre notícias e eventos atuais em todo o mundo",
        "Como funciona a inteligência artificial e aprendizado de máquina",
        "Como usar o ChatGPT para criar roteiro de vídeos no Youtube, encontrar as melhores palavras chaves, títulos e tags",
        "Como usar o ChatGPT para fins educacionais e de aprendizagem",
        "Como trabalhar utilizando o ChatGPT como seu parceiro"
      ],
      "course_content": {},
      "requirements": [
        "Não é necessário nenhum conhecimento prévio para participar do curso",
        "Qualquer pessoa que deseja aprender a utilizar essa incrível tecnologia a seu favor"
      ],
      "description": "O ChatGPT é uma das mais avançadas tecnologias de inteligência artificial, capaz de fornecer respostas precisas e personalizadas para diversas perguntas e tópicos. Este curso abrangente foi projetado para ajudar você a aproveitar ao máximo as capacidades do ChatGPT, aprendendo a usá-lo para obter respostas, soluções e insights em diferentes contextos.\n\n\nVocê está procurando um Curso completo de ChatGPT que vai te ensinar tudo que precisa para se tornar um especialista e master em ChatGPT, certo?\nVocê encontrou o curso de ChatGPT certo!\nCom as habilidades e estratégias que vai aprender aqui no nosso curso de ChatGPT, você pode:\nUTILIZAR o ChatGPT para vender mais\nCONSEGUIR desenvolver estratégias de marketing e criação de conteúdo com êxito\nAPLICAR o ChatGPT em diferentes contextos, como pesquisa, trabalho, educação e comunicação escrita.\nDOMINE de uma vez por todas esses conceitos e saiba como essa tecnologia dará mais liberdade e segurança para você gerar riqueza!\n\n\nQueremos te ajudar a facilitar sua vida e estar exposto ao FUTURO DA INTERNET: A Inteligência Artificial\nPrometemos fazer tudo o que pudermos para ajudá-lo a dominar todas estas estratégias e conceitos do ChatGPT, auxiliando profissionais de todas as áreas que desejam aprender como usar o ChatGPT para obter informações e insights úteis, desde profissionais de marketing e vendas até pesquisadores, educadores e profissionais de tecnologia.\nVocê irá aprender tópicos como:\nIntrodução ao ChatGPT e como ele funciona\nComo interagir com o ChatGPT e fazer perguntas\nComo usar o ChatGPT para obter respostas sobre diversos tópicos\nComo utilizar o ChatGPT para ganhar dinheiro\nComo utilizar o ChatGPT para criar conteúdo na internet (Youtube, Instagram, Tiktok...)\nComo usar o ChatGPT para aprimorar a escrita e comunicação interpessoal\nComo usar o ChatGPT para fins educacionais e de aprendizagem\nComo usar o ChatGPT para criar conteúdo para marketing e vendas\nExplorando futuras possibilidades de aplicação do ChatGPT em diferentes áreas e setores.\nE MUITO MAIS!\nO QUE VOCÊ RECEBE AO SE INSCREVER NO CURSO COMPLETO DE CHATGPT?\nAcesso vitalício ao curso e todas as atualizações\nSuporte personalizado e respostas às suas perguntas\nCertificado de conclusão Udemy - que podes incluir no teu currículo\nGarantia de devolução do dinheiro de 30 dias - se não gostar do curso podes pedir o reembolso de 100%\nPARA QUEM É O CURSO?\nO curso é ideal para profissionais de todas as áreas que desejam aprender como usar o ChatGPT para obter informações e insights úteis, desde profissionais de marketing e vendas até pesquisadores, educadores e profissionais de tecnologia. O curso também é adequado para estudantes que desejam melhorar suas habilidades de pesquisa e comunicação escrita.\nO conteúdo abordado no treinamento é ideal para qualquer tipo de estudante. Desde aquele que tem 0 conhecimento de ChatGPT até para aquele que já se aventurando no mundo da Inteligência artificial e quer ampliar seu conhecimento.\nIndicado para todos: Desde iniciantes até avançados.\n\n\nAo concluir este curso, você estará apto a usar o ChatGPT de forma eficaz para obter respostas, soluções e insights em diferentes contextos. Você também terá uma compreensão mais profunda da inteligência artificial e do aprendizado de máquina, bem como das possibilidades e limitações do ChatGPT. Com essas habilidades, você estará mais bem preparado para enfrentar os desafios e oportunidades do mundo moderno.",
      "target_audience": [
        "Para todos que almejam ganhar dinheiro com o ChatGPT",
        "Para pessoas que querem ser mais produtivas",
        "Para pessoas que produzem conteúdo nas redes sociais",
        "Para qualquer pessoas que deseja se manter atualizada em tecnologias que envolvam Inteligência Artificial",
        "Qualquer pessoa que queira aprender e colocar em prática a ferramenta do ChatGPT"
      ]
    },
    {
      "title": "Data Analytics with Python - Hindi",
      "url": "https://www.udemy.com/course/data-analytics-with-python/",
      "bio": "Essential Skills for Aspiring Data Analysts",
      "objectives": [
        "Python Fundamentals: Learn Python basics, including syntax, data types, and functions for efficient data analysis coding.",
        "Data Manipulation and Analysis: Gain proficiency in NumPy and pandas for manipulating and analyzing data of any size or complexity.",
        "Exploratory Data Analysis (EDA): Explore datasets, identify patterns, and visualize insights for informed decision-making.",
        "Applied Data Analytics Skills: Develop hands-on skills in data cleaning, preprocessing, and analysis through practical projects."
      ],
      "course_content": {},
      "requirements": [
        "Basic Computer Literacy: Familiarity with using a computer and navigating the operating system.",
        "No Prior Programming Experience Needed: The course starts from scratch, making it suitable for beginners.",
        "Access to a Computer: Learners should have access to a computer or laptop with internet connectivity.",
        "Python Installation: Prior to the course, students should have Python installed on their computer (instructions will be provided).",
        "Eagerness to Learn: An open mind and willingness to dive into the world of data analytics with Python."
      ],
      "description": "Mastering Data Analysis with Python: From Fundamentals to Advanced Techniques\n\n\nAre you ready to dive deep into the realm of data analysis and unlock the potential of Python as your go-to tool? Our comprehensive course offers a holistic learning experience tailored to equip you with the skills and knowledge essential for success in the dynamic field of data analytics.\n\n\nBeginning with an exploration of the fundamental principles of business and data, you'll gradually immerse yourself in the world of Python programming through interactive sessions and hands-on exercises. From mastering Python basics and syntax to understanding advanced concepts such as object-oriented programming and NumPy, each module is meticulously crafted to build a strong foundation and enhance your analytical capabilities.\n\n\nAs you progress through the course, you'll unravel the power of data manipulation and analysis using industry-standard libraries like pandas, gaining practical insights into handling real-world datasets with ease. Through guided projects and lab sessions, you'll have the opportunity to apply your newfound skills to solve complex data challenges and derive actionable insights.\n\n\nWhether you're a seasoned professional looking to upskill or a newcomer eager to explore the world of data, this course is designed to cater to learners of all backgrounds and levels of expertise. Join us on this exciting journey and unleash the full potential of data analysis with Python!\n\n\nMajor Topics Covered:\nIntroduction to Business and Data: Understanding the role of data in driving business decisions.\nPython Basics and Jupyter Notebooks: Exploring the fundamentals of Python programming and interactive computing.\nBasic Python Syntax and Conditional Programming: Mastering syntax fundamentals and conditional logic.\nFunctions and Sequences: Understanding the principles of functions and sequences in Python.\nObject-Oriented Programming (OOP) and NumPy: Delving into object-oriented programming concepts and leveraging NumPy for numerical computing.\npandas Library and Data Manipulation: Exploring data manipulation techniques using the pandas library.\nWorking with Files and Data Importing: Managing files and importing data from various sources.\nData Cleaning and Preprocessing: Learning techniques for cleaning and preprocessing raw data for analysis.\nExploratory Data Analysis (EDA): Conducting exploratory data analysis to gain insights and identify patterns.\nAdvanced Topics: Data Gathering, Linear Algebra, and APIs: Exploring advanced topics such as data gathering techniques, linear algebra operations, and working with APIs.\nCapstone Project: Applying acquired skills to a real-world data analysis project, from data cleaning to visualization and interpretation.\n\n\n\n\nEnroll now and embark on your journey to mastering data analysis with Python!",
      "target_audience": [
        "Students and Graduates: University students or recent graduates seeking practical skills in data analytics.",
        "Career Changers: Professionals from diverse backgrounds aiming to transition into the field of data analysis.",
        "Self-Learners: Anyone with a passion for data and a desire to learn Python for data analysis purposes.",
        "Professionals Seeking Skill Enhancement: Those already working in data-related roles who wish to enhance their Python and data analysis skills.",
        "Aspiring Data Analysts: Individuals looking to kickstart or advance their career in data analysis."
      ]
    },
    {
      "title": "Искусственный Интеллект на кончиках пальцев",
      "url": "https://www.udemy.com/course/ai_at_the_fingertips/",
      "bio": "Введение в Искусственный Интеллект",
      "objectives": [
        "Вы узнаете суть и смысл Искусственного Интеллекта и приготовитесь к жизни с ИИ-системами"
      ],
      "course_content": {
        "Что такое Искусственный Интеллект и зачем он вам нужен": [
          "Логистика курса",
          "Как учиться на курсе, если вы — «гуманитарий»",
          "Для чего нам Искусственный Интеллект",
          "Откуда возник Искусственный Интеллект",
          "Что нам ждать от Искусственного Интеллекта",
          "Что такое Искусственный Интеллект и зачем он вам нужен"
        ],
        "О технологиях ИИ. Часть 1": [
          "Алгоритмы поиска",
          "Методы извлечения, представления и обработки знаний",
          "Интеллектуальный анализ данных",
          "Обработка естественного языка",
          "Символьный подход, логика и нетрадиционные логики",
          "Эволюционные алгоритмы",
          "Квазибиологический подход",
          "О технологиях ИИ. Часть 1"
        ],
        "О технологиях ИИ. Часть 2": [
          "Машинное обучение",
          "Искусственные нейронные сети",
          "ЭС и СППР",
          "Многоагентные системы и роевой интеллект",
          "Робототехника",
          "Введение в нейрофизиологию",
          "Философия сознания",
          "О технологиях ИИ. Часть 2"
        ],
        "Будущее уже рядом": [
          "Где используется Искусственный Интеллект",
          "Как стать экспертом по Искусственному Интеллекту",
          "Смежные технологии",
          "Вперёд в будущее"
        ]
      },
      "requirements": [
        "Общие знания об устройстве мира"
      ],
      "description": "Что же такое этот пресловутый искусственный интеллект? Сегодня вокруг этого термина столько мифов и неправильного понимания, что зачастую отделить правду от вымысла очень сложно. Особенно масла в огонь невежества подливают журналисты и деятели массовой культуры, которые занимаются созданием мифов. В итоге у нас с одной стороны есть мифы про терминаторов, Скайнет и Матрицу, а с другой стороны считается, что искусственный интеллект создать в принципе невозможно. Но правда в том, что искусственные интеллектуальные системы уже существуют и успешно замещают людей во многих профессиях. И дальше всё будет только серьёзнее. Так что знать, что это такое, куда развиваются систем искусственного интеллекта и что нас ожидает сейчас и в ближайшем будущем — всё это насущная необходимость любого современного человека.\nСтудент, успешно прошедший курс, будет полноценно ориентироваться в современных технологиях искусственного интеллекта. Он сможет выступать экспертом для СМИ, консультантом для предпринимателей и компаний, которые планируют внедрять в свою деятельности методы искусственного интеллекта.",
      "target_audience": [
        "Всем, кто смотрит в яркое и сияющее будущее"
      ]
    },
    {
      "title": "Foundational Mathematics for Data Science | Arabic",
      "url": "https://www.udemy.com/course/mathematics-for-machine-learning-arabic/",
      "bio": "Foundational Essentials: Linear Algebra, Probability, and Statistics for Data Science",
      "objectives": [
        "Linear Algebra for Machine Learning",
        "Operations on Vectors & Matrices",
        "Linear Transformation in Linear Algebra",
        "Eigen Values & Eigen Vectors",
        "Probability for Data Science & Machine Learning",
        "Statistics for Data Science & Machine Learning",
        "Different Methods to deal with each type of variables",
        "How to deal and analyze with Numerical Variables",
        "How to deal and analyze with Categorical Variables"
      ],
      "course_content": {},
      "requirements": [
        "No prerequisites for this course"
      ],
      "description": "This course \"Foundational Mathematics for Data Science\" provides a comprehensive understanding of linear algebra, statistics, and probability essential for those delving into the realms of machine learning and data science. It stands out as a unique resource in Arabic, offering interactive, application-based training with thorough explanations, catering to beginners' levels to achieve an excellent grasp of the subjects.\nSuitable for novices without prerequisites, this course caters to individuals interested in AI, its associated mathematics, data analysts, data scientists, and AI engineers.\n\n\nWhat you will learn:\n\n\nLinear Algebra:\nIntroduction and Importance\nSystem of Linear Equations\nVectors and Operations\nVector Norm\nDot Product\nMatrices and Matrix Operations\nVector Spaces\nLinear Combinations\nVector Spans\nVectors Linear Independence\nBasis of Space\nLinear Transformation\nDeterminant\nSystem of Linear Equation Solutions\nGauss-Jordan Elimination\nInverse\nEigenvalues and Eigenvectors\nPCA (Principal Component Analysis)\nProbability & Statistics:\nImportance and Relevance\nProbability vs. Statistics\nEmpirical and Theoretical Probability\nJoint, Marginal, and Conditional Probability Distribution\nRandom Experiment\nRandom Variables\nStatistics\nSampling Methods\nNumerical Variables and Visualization Techniques\nStatistical Tools\nCategorical Variables and Visualization Techniques\nProbability Distributions\n\n\nWhether you're an AI enthusiast, developer, student, or data scientist, this course will empower you with the foundational knowledge of mathematics needed for data science.\nJoin us now and embark on an enriching learning journey that will set you on the path in the AI field.\nEnroll today!",
      "target_audience": [
        "Data Analysts",
        "Data Scientists",
        "Software Developers",
        "Computer Science Students",
        "Anyone with interest in Data Science, and Machine Learning"
      ]
    },
    {
      "title": "【Hands Onで学ぶ】 PyTorchによるGANs入門",
      "url": "https://www.udemy.com/course/hands-on-pytorch-gans/",
      "bio": "DCGANからSelf-Attention GANまで様々なGANsを理解しよう",
      "objectives": [
        "GANsの理解に必要な数学(統計学 / 線形代数)を理解できる",
        "GANsの理論の基本的な内容を理解できる(アーキテクチャ/訓練プロセス/損失関数など)",
        "GANsのモデル構築、損失関数、訓練プロセスの一連の流れをPyTorchを用いて実装し、理解できる。",
        "GANsの代表的なモデル(DCGAN / Wasserstein GAN / Cycle GAN / Self-Attention GANなど)を理解、実装できる。",
        "Google Colab上でGoogleドライブと連携させながら、GANsを学習させることができる。"
      ],
      "course_content": {
        "はじめに": [
          "コースの概要説明"
        ],
        "GANの基礎": [
          "統計学の基礎とGANsの基礎理論",
          "実装の方針"
        ],
        "DCGAN": [
          "DCGAN(理論)",
          "ユーティリティの実装",
          "DCGAN(Generator実装)",
          "DCGAN(Discriminator実装)",
          "DCGAN(訓練実装 前半)",
          "DCGAN(訓練実装 後半)"
        ],
        "Conditional GAN": [
          "Conditional GAN(理論)",
          "Conditional GAN(実装)"
        ],
        "Wasserstein GAN": [
          "Wasserstein GAN(理論)",
          "Wasserstein GAN(Weight Clipping 実装)",
          "Wasserstein GAN(Gradient Penalty 実装)"
        ],
        "Cycle GAN": [
          "Cycle GAN(理論)",
          "Cycle GAN(データセット)について補足",
          "Cycle GAN(データセット準備)",
          "Cycle GAN(データセット実装)",
          "Cycle GAN(Generator 実装)",
          "Cycle GAN(Discriminator 実装)",
          "Cycle GAN(オプティマイザ 損失関数 LRスケジューラー)",
          "Cycle GAN(訓練実装　前半 )",
          "Cycle GAN(訓練実装 後半)",
          "Cycle GAN 訓練のプロセス"
        ],
        "Self-Attention GAN": [
          "Self-Attention GAN(理論)",
          "Self-Attention GAN(データセット準備)",
          "Self-Attention GAN(Attention Map作成)",
          "Self-Attention GAN(Hinge損失)",
          "Self-Attention GAN(モデル 訓練実装)"
        ],
        "ボーナスレクチャー": [
          "講義で使用したipynbファイル",
          "講義で使用したパワーポイント"
        ]
      },
      "requirements": [
        "必須条件：Pythonの基本的な文法",
        "必須条件：PyTorchで機械学習・深層学習の実装ができる",
        "前提条件：大学初等レベルの数学力",
        "前提条件：【Hands Onで学ぶ】PyTorchによる深層学習入門を受講済み"
      ],
      "description": "【このコースは誰に向けたものか？】\n本コースは、【Hands Onで学ぶ】PyTorchによる深層学習入門を受講して、PyTorchで深層学習を実装できるようになった方を対象に、\n深層学習の１つの分野であるGANs(Generative Adversarial Networks)について学んでいく講座です。\n\n\nGANsとは生成器と識別器という敵対する２つの深層学習のモデルを相互に訓練していくことで、本物そっくりな画像などを生成することができる技術で、深層学習の分野の中でもホットなトピックな為、毎年、多くの論文が投稿されています。\n\n\nそこで、本講座ではGANsって最近よく聞くから気になっているけど、実際どういうものなのか知りたいという方に向けて、\nGANsの理論とPyTorchによる実装の両面からGANsについて理解することができます。\n\n\n\n\n【何が学べる？】\nGANsの理論と実装の両面を基礎からしっかり押さえていきます。\nGANsの理論の基礎を理解するためにはある程度の数学が必要です。(例えば、統計学や線形代数など)\nこの為、必要に応じて逐次数学的な解説を加えながら、GANsの理論の基礎を学んでいきます。\n\n\nまた実際にコードを実装する面ではPyTorchという深層学習のフレームワークを使って、GANのモデルをスクラッチから実装を行います。\nプログラムを書くことで、実際に手を動かしながらGANsについて理解を深めていきます。\n\n\nGANsはプログラミングの量が多いのですが、本講座では講師が０から受講生と一緒にコードを書いていくため、\nステップバイステップでGANsの実装が可能です。\n\n\nGANsの訓練は比較的時間がかかるので、今回、GPUを使用することができる\nGoogle Colabを用いていきます、訓練データや訓練のパラメーターなどはGoogleドライブと連携し、\nドライブの中から読みだすもしくはデータを書きだすため、Google ColabとGoogleドライブとの連携についても学びます。\n\n\n\n\n以下に本講座を受講することで学べることを列挙しました。\n・GANsの理解に必要な数学(統計学 / 線形代数)を理解できる\n・GANsの理論の基本的な内容を理解できる(アーキテクチャ/訓練プロセス/損失関数など)\n・GANsのモデル構築、損失関数、訓練プロセスの一連の流れをPyTorchを用いて実装し、理解できる。\n・GANsの代表的なモデル(DCGAN / Wasserstein GAN / Cycle GAN / Self-Attention GANなど)を理解、実装できる。\n・Google Colab上でGoogleドライブと連携させながら、GANsを学習させることができる。",
      "target_audience": [
        "GANsの基本的な内容を習得し、自分でモデルを組んだり、論文の追試をしたい人",
        "PyTorchによる深層学習を始めて、次に何を学ぼうか悩んでいる人",
        "研究開発職で自分の分野にGANsを適用してみたいと思っている人",
        "GANsの色々なモデルを実装してみたい人"
      ]
    },
    {
      "title": "Introduzione all'Intelligenza Artificiale",
      "url": "https://www.udemy.com/course/introduzione-allintelligenza-artificiale/",
      "bio": "Fondamenti di Intelligenza Artificiale, Machine Learning e Deep Learning",
      "objectives": [
        "Gli scopi dell' Intelligenza Artificiale",
        "Tipi di Learning",
        "Algoritmi del Machine Learning",
        "Flusso di Lavoro del Machine Learning"
      ],
      "course_content": {},
      "requirements": [
        "Non è necessario avere alcuna esperienza in merito. Il corso si propone, nella giungla del W.E.B. in cui gli argomenti e i temi relativi all'INTELLIGENZA ARTIFICIALE risultano essere molteplici ma trattati spesso in modo poco chiaro ed eccessivamente prolisso, di dare agli studenti un' INFARINATURA INIZIALE, per comprendere in modo semplice e chiaro i CONCETTI CHIAVE dell' INTELLIGENZA ARITIFICIALE e dei suoi SOTTOINSIEMI. In questo modo si potranno acquisire le conoscenze di BASE relative al tema dell' INTELLIGENZA ARTIFICIALE, e si sarà in grado di potere approcciare un tipo di studi ulteriore e più complesso."
      ],
      "description": "Un video corso dedicato all'ABC dell'Intelligenza Artificiale. In questo video  corso gli studenti apprenderanno i fondamenti dell'Intelligenza Artificiale, gli scopi e i tipi di Intelligenza Artificiale, i suoi sottoinsiemi; verrà dato spazio a concetti relativi ai vari tipi di \"Learning\":\nSupervisionato\nNon Supervisionato\nSemi Supervisionato\nRinforzato,\ndunque ai concetti di Classificazione, Regressione e Clustering, (quindi agli algoritmi del Machine Learning ad essi correlati).\nVi sarà anche  una piccola sezione dedicata al Deep Learning ed alle reti neurali profonde( Convoluzionali e Ricorrenti).\nIl video corso ha un'architettura grafica costituita da slides, schemi e grafici il cui obiettivo è quello di facilitare la comprensione dei contenuti  in modo da rendere l' apprendimento semplice fruibile facile ed intuitivo, nonché praticamente immediato.\nNella \" giungla del web\" è, infatti, possibile, trovare un'enorme quantità di siti web o links che trattano il tema relativo all'Intelligenza Artificiale, ma è difficile riuscire a trovarne qualcuno che riesca a facilitare la comprensione o a trasmetterne l'insegnamento considerando chi sia l'utente o studente finale, quindi chi, in realtà, ha voglia di imparare ma si ritrova a dovere fare i conti con concetti preparati ed esposti per chi , la maggior parte delle volte, ha già un'infarinatura iniziale o competenze di statistica matematica o programmazione che facilitano in modo non indifferente il compito.\nEbbene, questo video corso parte da zero, è l' \"ABC\" dell' Intelligenza Artificiale. E' l'esatto manuale per chi non ha conoscenza specifica né di base dell'Intelligenza Artificiale, ma ne ha comunque sentito parlare e ne è rimasto affascinato e, pertanto, intende acquisire gli strumenti di base per potere poi, eventualmente, approfondirli dal punto di vista statistico-matematico o della programmazione, ambiti che qui verranno appositamente tralasciati proprio per evitare il caos dell'apprendimento.",
      "target_audience": [
        "Principianti, curiosi di INTELLIGENZA ARTIFICIALE & Machine Learning"
      ]
    },
    {
      "title": "Machine Learning | Sistema de recomendação com Python",
      "url": "https://www.udemy.com/course/machine-learning-sistema-de-recomendacao-com-python/",
      "bio": "Aprenda a criar um sistema de recomendação com dados de livros",
      "objectives": [
        "Criar um sistema de recomendação",
        "Criar um modelo de Machine Learning, aprendizado não supervisionado",
        "Visualização de dadoos",
        "Manipular dados",
        "Buscar imagens na internet a partir de um Link"
      ],
      "course_content": {},
      "requirements": [
        "Python básico",
        "Conhecimentos em Pandas, Matplotlib"
      ],
      "description": "Machine Learning | Sistema de recomendação com Python\n\n\nNesse treinamento vamos criar um sistema de recomendação usando dados de livros, desde a aquisição dos dados até a criação do modelo de Machine Learning e criar um simulador para deixar a experiência mais intuitiva.\nIremos utilizar os seguintes frameworks:\nPandas;\nNumpy;\nMatplotlib;\nSeaborn;\nScipy;\nRequests;\nSklearn;\nPillow;\nEntre outros.\nComo vai funcionar nossa dinâmica?\nPrimeiramente vamos importar os dados para nosso ambiente, serão 3 bases de dados que iremos precisar fazer o cruzamento e entendimento, em seguida:\n\n\nAnalise Exploratória dos dados (EDA)\nCriação do Modelo de Machine Learning (Aprendizado não supervisionado)\nEntendimento do algoritmo (calculo manual)\nUm relatorio com as fotos de capas dos livros para ilustrar o sistema de recomendação\nObs: Essa solução pode ser adapta para criar um produto ou serviço baseado em dados.\n\n\nPorque aprender a criar um sistema de recomendação?\nOs Sistemas de Recomendação estão muito presentes em nossas vidas atualmente. A Amazon, aliás, é uma das melhores empresas que utilizam essa ferramenta.\n\n\nPorque aprender ciência de dados?\nProgramação é uma disciplina totalmente prática, de forma que, apenas a leitura de livros e/ou acompanhamento de vídeos não desenvolve todas as habilidades necessárias.\nA demanda por programadores Python nunca esteve tão alta, afinal, Python é uma das linguagens mais utilizadas no mundo e requisito para se trabalhar com Ciência de Dados e Inteligência Artificial. Inclusive, podemos considerar Python como uma linguagem padrão para análise de dados, tendo em vista seu amplo ecossistema de bibliotecas, que englobam desde a manipulação e tratamento de dados até mesmo o deploy de modelos. Não podemos esquecer, neste sentido, que o Python é uma linguagem de aplicação geral.\nPor ser uma linguagem de programação versátil, simples de aprender e muito poderosa, Python possui recursos que, apesar de simples de se utilizar, tornam o aprendizado muito divertido.\n\n\nBons estudos!",
      "target_audience": [
        "Analista de Dados",
        "Cientistas de Dados",
        "Engenheiro de Dados",
        "Estudantes de Dados",
        "Estudantes de Programação",
        "Entusiastas da área"
      ]
    },
    {
      "title": "【한글자막】 Computer Vision (컴퓨터 비전) : 마스터 클래스",
      "url": "https://www.udemy.com/course/best-computer-vision/",
      "bio": "컴퓨터 비전의 세계에 들어가기 위해 알아야 할 모든 것을 실습하며 배우세요! 컴퓨터 비전 알고리즘에 대한 기본적 직관을 익히고 파이썬과 구글 Colab을 사용하여 프로젝트들을 단계별로 구현할 것입니다.",
      "objectives": [
        "얼굴 감지를 위한 캐스케이드 및 HOG 분류기의 기본적 직관 이해하기",
        "OpenCV 및 Dlib 라이브러리를 사용하여 얼굴 감지 구현하기",
        "자동차, 시계, 눈 및 사람의 전신과 같은 객체를 OpenCV를 사용하여 감지하는 방법 배우기",
        "3 개의 얼굴 감지기 결과 비교하기: 하르 캐스케이드, HOG(그래디언트 방향 히스토그램), CNN(합성곱 신경망)",
        "이미지와 웹캠을 사용한 얼굴 감지하기",
        "얼굴 인식을 위한 LBPH 알고리즘의 기본적 직관 이해하기",
        "OpenCV 및 Dlib 라이브러리를 사용하여 얼굴 인식 구현하기",
        "이미지와 웹캠을 사용한 얼굴 인식하기",
        "객체 트래킹을 위한 KCF 및 CSRT 알고리즘에 대한 기본적 직관 이해하기",
        "OpenCV 라이브러리를 사용하여 영상에서 객체를 트래킹하는 방법 배우기",
        "퍼셉트론, 활성화 함수, 가중치 업데이트, 역전파, 경사하강법 등의 신경망의 기반이 되는 이론에 대해 알아야 할 모든 것 배우기",
        "이미지를 분류하는 밀집 신경망 구현하기",
        "신경망을 구축하기 위해 이미지에서 픽셀 및 특성 추출 방법 배우기",
        "합성곱 신경망의 기반이 되는 이론을 배우고 파이썬과 텐서플로를 사용하여 구현하기",
        "이미지를 분류할 때 뛰어난 결과를 얻기 위해 전이 학습과 파인 튜닝 구현하기",
        "합성곱 신경망을 사용하여 이미지 및 영상의 감정 분류하기: 행복, 분노, 혐오, 두려움, 놀람 및 중립",
        "선형 및 합성곱 오토인코더를 사용하여 이미지 압축하기",
        "현재 가장 강력한 알고리즘 중 하나인 YOLO를 사용하여 영상의 이미지에서 객체를 감지하기",
        "OpenCV를 사용하여 영상의 제스처와 움직임을 인식하기",
        "딥드림으로 환각적인 이미지 만드는 법 배우기",
        "스타일 전이로 유명한 예술가를 되살리는 방법 배우기",
        "GAN(생성적 적대 신경망)을 사용하여 실제 현실에는 존재하지 않는 이미지 만들기",
        "이미지 및 영상에서 유용한 정보를 추출하기 위해 이미지 세그멘테이션 구현하기"
      ],
      "course_content": {},
      "requirements": [
        "프로그래밍 논리",
        "파이썬 프로그래밍 기본"
      ],
      "description": "OpenCV, Dlib 등 라이브러리를 이용한 컴퓨터 비전 마스터 클래스!\n14개의 주요 컴퓨터 비전 기술을 단계적으로 구현!\n인공지능의 한 분야인 컴퓨터 비전을 배워보세요!\n\n\nComputer Vision (컴퓨터 비전) : 마스터 클래스를 선택해야 하는 이유\n컴퓨터 비전은 인간의 눈과 비슷한 방식으로 시각적 데이터를 처리, 분석 및 식별할 수 있는 시스템을 만드는 데 초점을 맞춘 인공 지능의 한 분야입니다. 보안, 마케팅, 의사 결정 및 생산과 같은 다양한 분야에 상업용 응용 프로그램이 많이 있습니다. 컴퓨터 비전은 스마트폰에서는 얼굴인식으로 기기를 잠금 해제하는 데, 자율주행차에서는 보행자를 탐지하고 다른 자동차로부터 안전한 거리를 유지하는 데, 보안 카메라에서는 주위에 있는 사람들에게 알람을 울려야 하는지 판단하는 데 사용됩니다.\n\n\n이 코스에서는 컴퓨터 비전의 세계에 들어가기 위해 알아야 할 모든 것을 배울 것입니다. 여러분은 14개의 주요 컴퓨터 비전 기술을 단계적으로 구현하는 법을 배우게 됩니다. 컴퓨터 비전에 대해 들어 본 적이 전혀 없는 분이라도 이 코스를 수료하면 모든 분야를 실제적이고 개략적으로 알게 될 것입니다.\n\n\n여러분은 컴퓨터 비전 알고리즘에 대한 기본적 직관을 익히고 파이썬과 구글 Colab을 사용하여 프로젝트들을 단계별로 구현할 것입니다.\n\n\nComputer Vision (컴퓨터 비전) : 마스터 클래스 세부 커리큘럼\nOpenCV 및 Dlib 라이브러리를 사용하여 이미지 및 영상에서 얼굴 감지하기\nOpenCV 및 Dlib 라이브러리를 사용하여 얼굴을 인식시키기 위해 LBPH 알고리즘을 학습시키는 방법을 배우기\nKCF 및 CSRT 알고리즘을 사용하여 영상에서 객체 트래킹하기\n인공 신경망의 기반이 되는 전체 이론을 배우고 이론을 이미지 분류에 적용하기\n이미지 분류를 위해 합성곱 신경망 구현하기\n전이 학습과 파인 튜닝을 사용하여 합성곱 신경망의 결과를 향상시키기\n신경망을 사용하여 이미지 및 영상에서 감정 감지하기\n오토인코더 및 텐서플로를 사용하여 이미지를 압축하기\n컴퓨터 비전에서 가장 강력한 기술 중 하나인 YOLO를 사용하여 객체를 감지하기\nOpenCV를 사용하여 영상에서 제스처와 움직임 인식하기\n딥드림 기술을 사용하여 환각적인 이미지 만들기\n스타일 전이를 사용하여 이미지들의 스타일을 합치기\nGAN(생성적 적대 신경망)을 사용하여 현실에 존재하지 않는 이미지 만들기\n이미지 세그멘테이션을 사용하여 이미지에서 유용한 정보 추출하기\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n강의에서 만나요,\nLigency Team",
      "target_audience": [
        "컴퓨터 비전을 배우기 시작하는 초보자",
        "인공 지능과 관련된 과목을 공부하고 있는 학부생",
        "컴퓨터 비전을 사용하여 자신의 문제를 해결하고자 하는 사람",
        "컴퓨터 비전 프로젝트를 개발하는 회사에서 일하기를 원하는 학생",
        "컴퓨터 비전의 모든 분야와 그 기술을 사용하여 풀 수 있는 문제을 알고 싶어하는 사람",
        "인공 지능이나 컴퓨터 비전에 관심 있는 사람 누구나",
        "포트폴리오를 업그레이드하려는 데이터 과학자",
        "실제 프로젝트에 컴퓨터 비전을 적용하는 방법을 이해하고자 하는 전문가"
      ]
    },
    {
      "title": "Ciencia de Datos con R",
      "url": "https://www.udemy.com/course/ciencia-de-datos-con-r/",
      "bio": "Aprende a adquirir, organizar, combinar, limpiar y presentar datos de diferentes fuentes y sistemas de almacenamiento.",
      "objectives": [
        "Este curso te enseñara a programar en R",
        "La Sintaxis de R",
        "Las Estructuras de Datos en R utilizadas en el análisis de datos",
        "Las Estructuras de Control en R",
        "Todo lo necesario que necesitas saber sobre las funciones en R",
        "Todo lo que querías aprender sobre los paquetes en R",
        "A utilizar RStudio en las diferentes fases del flujo de trabajo",
        "Importar Datos en R con readr, readxl y haven",
        "Visualizar Datos en R con ggplot2",
        "Dominar los paquetes del ecosistema Tidyverse",
        "A interactuar con Sistemas Gestores de Bases de Datos desde R"
      ],
      "course_content": {},
      "requirements": [
        "No es imprescindible tener nociones ni del lenguaje de programación R, ni sobre estadística. Sin embargo, es necesario disponer de un ordenador con conexión a Internet para realizar el curso."
      ],
      "description": "CURSO ONLINE CON ACCESO PARA SIEMPRE\nEl objetivo del Curso online Ciencia de Datos con R es ayudarte a aprender las herramientas más importantes en R que te permitirán abordar un proyecto típico en Ciencia de Datos.\nUn curso 100 % práctico a partir del manejo de una máquina virtual individualizada que te permitirá practicar las técnicas clave para afrontar una amplia variedad de tareas en el análisis de datos:\nProgramación en R y uso de RStudio\nCaptura y almacenamiento de la información\nTransformar datos brutos en información lista para su análisis.\nVisualización de la información.\nComunicación de nuestros resultados.\nEs un curso innovador que utiliza herramientas avanzadas como RStudio, un IDE que nos facilitará los procesos de trabajo en las diferentes tareas de un proyecto de Ciencia de Datos y Tidyverse un conjunto de paquetes que abarcan todo el flujo de trabajo en el análisis de datos, fáciles de aprender y usar.\nNo esperes más y descubre por qué la Ciencia de Datos es el \"trabajo mas sexy del siglo XXI\", mejora tus conocimientos y da un salto adelante en tu carrera profesional.",
      "target_audience": [
        "Indicado especialmente para todo aquel que quiera aprender el lenguaje de programación R, el más utilizado por los Data Scientist.",
        "Dirigido principalmente a alumnos que quieren aprender a analizar datos con R.",
        "Enfocado fundamentalmente a todos los estudiantes que quieran aprender las diferentes fases en un proyecto típico de Ciencia de Datos.",
        "Especialmente aconsejado si queremos aprender a adquirir, organizar, combinar, limpiar, almacenar y presentar datos provenientes de diferente fuentes y sistemas de almacenamiento"
      ]
    },
    {
      "title": "直感！Pytorchで始める深層学習実装入門（導入編）",
      "url": "https://www.udemy.com/course/pytorch_nn/",
      "bio": "導入編：ニューラルネットワークの仕組みと実装",
      "objectives": [
        "ニューラルネットワークの仕組み",
        "Pytrochを用いたニューラルネットワークの実装方法",
        "深層学習の基礎",
        "単純パーセプトロンの仕組み・実装方法",
        "多層パーセプトロンの仕組み・実装方法"
      ],
      "course_content": {
        "直感！Python Pytorchで始める深層学習実装入門 導入編": [
          "本講座のご紹介",
          "環境構築(Colabの説明)",
          "環境構築(Colabセットアップ)",
          "単純パーセプトロン説明",
          "単純パーセプトロン実装",
          "単純パーセプトロンサマリ",
          "線形回帰、ロジスティック回帰への拡張",
          "線形回帰、ロジスティック回帰の実装",
          "多層パーセプトロンの説明",
          "多層パーセプトロンの実装"
        ]
      },
      "requirements": [
        "Pythonの基本文法の理解",
        "高校1年生レベルの数学の知識"
      ],
      "description": "本講座では、Google Colaboratory(Colab)の環境を利用しながら実際に手を動かしてPytorchで単純パーセプトロン・多層パーセプトロンを実装し、ネットワークが自動学習できるように拡張していきます。ニューラルネットワークがどのような仕組みで訓練・推論を行っているのかの理解を深めることができます。\n\n\nPytorchの書籍や公式チュートリアルで挫折してしまった方が、もう一度深層学習にチャレンジしたいと思うきっかけになればと思い、極力平易な言葉での解説に徹しました。\n\n\n※実践編にてCNN/RNN/BERTなどについても解説しておりますが、本講座には含まれませんのでご注意ください。\n\n\n[目次]\n\n\n01_直感!PythonPytorchで始める深層学習実装入門ハンズオン紹介\n\n\n02_Colaboratory説明\n\n\n03_Colaboratoryハンズオン\n\n\n04_単純パーセプトロン説明\n\n\n05_単純パーセプトロン実装\n\n\n06_単純パーセプトロンサマリ\n\n\n07_線形回帰、ロジスティック回帰、勾配降下法の説明\n\n\n08_線形回帰、ロジスティック回帰、勾配降下法の実装\n\n\n09_多層パーセプトロンの説明\n\n\n10_多層パーセプトロンの実装\n\n\n[前提知識]\n\n\n・Pythonの基礎文法\n\n\n・高校1年生レベルの数学の理解を前提",
      "target_audience": [
        "データサイエンスに興味を持つ初級Python開発者",
        "Python/Pytorchでのニューラルネットワーク実装ができるようになりたい方",
        "深層学習の実装に興味のある方"
      ]
    },
    {
      "title": "Python Geração de PDF: de Iniciante a Vencedor (ReportLab)",
      "url": "https://www.udemy.com/course/python-reportlab-de-iniciante-a-vencedor/",
      "bio": "Gerar dinamicamente arquivos PDF usando Python e ReportLab",
      "objectives": [
        "Gerar dinamicamente um arquivo PDF utilizando Python",
        "Abordagem prática com exemplos reais",
        "Explicação passo a passo"
      ],
      "course_content": {
        "Gerar o PDF Palms Hotel": [
          "Introdução",
          "Parte 1 - Construir a estrutura base",
          "Tabelas ReportLab",
          "Parte 2 - Fazer o rodapé",
          "Tabelas ReportLab e seus estilos",
          "Parte 3 - Fazer o cabeçalho",
          "Imagens, Tabelas de ReportLab e seus estilos",
          "Parte 4 - Construir a estrutura do corpo do documento",
          "Tabelas ReportLab e seus estilos",
          "Parte 5 - Fazer a secção com informação sobre o hotel",
          "Parágrafos em ReportLab",
          "Parte 6 - Fazer a secção com a descrição",
          "Objectos do tipo Paragraph e ParagraphStyle",
          "Parte 7 - Fazer a secção com os contactos",
          "Parágrafos em ReportLab",
          "Estilos de uma tabela ReportLab",
          "Parte 8 - Fazer a secção com a lista de preços",
          "Parágrafos, Tabelas de ReportLab e seus estilos.",
          "Exercício 1 - Adicionar sombreado a texto",
          "Estilos de uma Tabela de ReportLab",
          "Exercício 2 - Adicionar texto em Árabe",
          "Fontes suportadas em ReportLab",
          "Exercício 3 - Registar uma Font Family",
          "Exercício 4 - Adicionar Cinco Estrelas!",
          "Exercício 5 - Perguntas Frequentes",
          "Exercício 6 - Debug Código ReportLab",
          "Exercício 7 - Django App"
        ]
      },
      "requirements": [
        "Vontade de aprender!",
        "Conhecimentos básicos da linguagem Python 3"
      ],
      "description": "Este curso tem uma abordagem prática, é resultado de trabalhos que fiz para clientes meus no passado bem como videos que publiquei para o meu canal de youtube.\nAo longo deste curso irei propor vários documentos PDF, tentarei sempre que os mesmos se pareçam o mais profissional possível e irei ensinar passo a passo e em detalhe como fazer os mesmos.\nCada proposta de arquivo PDF que apresento aqui, pode tomar cerca de 2 meses para que eu consiga estruturar de forma a que você possa digerir mais facilmente o conteúdo e também que possa praticar o que aprendeu várias vezes. Seja paciente pois irei actualizar este curso com frequência!\n\n\nVocê irá aprender:\nComo alterar o tamanho de letra;\nAlterar a cor do texto;\nUsar fontes do tipo True Type Font;\nComo inserir imagens num arquivo PDF;\nCriar tabelas;\nCriar parágrafos;\nAdicionar marcas de água;\nRodar o texto;\nRodar imagens;\nProteger o arquivo PDF com palavra passe;\nPrevenir que outras pessoas possam imprimir o arquivo;\nInserir radio buttons;\nInserir check boxes;\nInserir drop down lists;\nInserir áreas de texto;\nAdicionar JavaScript ao seu arquivo PDF;\nExporte arquivos PDF dentro de um aplicativo Django;\ne mais!\n\n\nVocê não aprenderá apenas sobre o ReportLab aqui! Além disso, você aprenderá como pensar, como estruturar o seu código, como torná-lo bonito e fácil para que todos entendam o seu trabalho, porque no final das contas essas habilidades são as que fazem as empresas quererem você!\n\n\nEspero que goste do meu trabalho, darei o meu melhor para torná-lo um vencedor :)",
      "target_audience": [
        "Pessoas que precisam de gerar arquivos PDF dinamicamente",
        "Desenvolvedores Python",
        "Analístas de dados",
        "Data Scientists"
      ]
    },
    {
      "title": "Classificação de Áudio com Python: O Guia Completo",
      "url": "https://www.udemy.com/course/classificacao-de-audio-com-python-guia-completo/",
      "bio": "Deep Learning aplicado em áudios! Classificação de sons ambientais, emoções, comandos de voz e transcrição de áudio!",
      "objectives": [
        "Entender os principais conceitos relacionados à processamento de áudio, como: taxa de amostragem, amplitude, ondas, frequência, decibel, dentre outros",
        "Como utilizar a Transformada de Fourier e o Coeficiente Cepstral de Frequência Mel (MFCC) para extrair características de áudios",
        "Visualizar o gráfico de onda e espectrogramas de arquivos de áudio",
        "Treinar redes neurais convolucionais com o TensorFlow para classificar diversos tipos de áudios",
        "Classificar 10 categorias de sons ambientais: ar condicionado, buzina, crianças, latido, perfuração, motor, tiro de arma, britadeira, sirene e música de rua",
        "Utilizar a arquitetura YAMNet para classificar 521 eventos de aúdio",
        "Treinar a arquitetura YAMNet utilizando transferência de aprendizagem para classificar o canto de 5 espécies de pássaros",
        "Classificar 10 emoções pela fala: tristeza, surpresa, nojo, neutro, nervosismo, medo, felicidade e calmo",
        "Treinar uma rede neural para classificar 8 comandos de voz",
        "Transcrição de áudio utilizando a biblioteca SpeechRecognition",
        "Transcrever áudios do WhatsApp"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Recursos para download",
          "Classificação de áudio",
          "O que são sinais de áudio",
          "Amostragem do sinal de áudio",
          "Tipos de sinais de áudio",
          "Extração de recursos de áudio"
        ],
        "Carregamento e processamento de áudio": [
          "Introdução",
          "Importação das bibliotecas",
          "Carregamento de arquivo mono",
          "Carregamento de arquivo stereo",
          "Taxa de amostragem",
          "Tipos de reamostragem",
          "Separação harmônico-percussiva",
          "Detecção de início e sintetização de click",
          "Gráfico de onda (wave plot)",
          "Transformada de Fourier - intuição",
          "Transformada de Fourier com Librosa",
          "Visualização de espectrograma",
          "Coeficiente Cepstral de Frequência Mel (MFCC)",
          "MFCCs com Librosa",
          "Espectrograma em decibéis",
          "Normalização média cepstral"
        ],
        "Classificações de sons ambientais": [
          "Introdução",
          "Importação das bibliotecas",
          "Base de dados UrbanSound8K 1",
          "Base de dados UrbanSound8K 2",
          "Base de dados UrbanSound8K 3",
          "Visualização dos dados",
          "Gráfico de ondas",
          "Espectrogramas de STFT",
          "Espectrogramas de MFCCs",
          "Extração de características MFCCs",
          "Preparação dos dados",
          "Estrutura da rede neural",
          "Treinamento da rede neural",
          "Avaliação da rede neural",
          "Testes com arquivos de áudio"
        ],
        "Classificação de sons com YAMNet": [
          "Introdução",
          "Eventos de áudio 1",
          "Eventos de áudio 2",
          "Eventos de áudio 3",
          "Eventos de áudio 4",
          "Canto de pássaros 1",
          "Canto de pássaros 2",
          "Canto de pássaros 3",
          "Canto de pássaros 4",
          "Canto de pássaros 5",
          "Canto de pássaros 6",
          "Canto de pássaros 7",
          "Canto de pássaros 8"
        ],
        "Classificação de emoções pela fala": [
          "Introdução",
          "Base de dados RAVDESS",
          "Tratamento da base de dados",
          "Visualização dos dados",
          "Gráfico de ondas e espectrogramas",
          "Extração de características MFCCs",
          "Construção e treinamento da rede neural",
          "Avaliação da rede neural",
          "Testes com arquivos de áudio"
        ],
        "Reconhecimento de comandos de voz": [
          "Introdução",
          "Base mini speech commands 1",
          "Base mini speech commands 2",
          "Visualização dos dados",
          "Extração das características MFCCs",
          "Preparação dos dados",
          "Construção e treinamento da rede neural",
          "Avaliação da rede neural",
          "Testes com arquivos de áudio"
        ],
        "Transcrição de áudio": [
          "Introdução",
          "Transcrição com speech recognition - bibliotecas",
          "Transcrição com speech recognition - primeiro teste",
          "Transcrição com speech recognition - remoção de ruído",
          "Transcrição com speech recognition - microfone",
          "Transcrição com speech recognition - WhatsApp"
        ],
        "ANEXO 1: Redes neurais artificiais": [
          "Fundamentos biológicos",
          "Perceptron de uma camada",
          "Redes multicamada - função soma e ativação",
          "Redes multicamada - cálculo do erro",
          "Descida do gradiente",
          "Cálculo do parâmetro delta",
          "Ajuste dos pesos com backpropagation",
          "Bias, erro, descida do gradiente estocástica e mais parâmetros"
        ],
        "ANEXO 2: Redes neurais convolucionais": [
          "Introdução a redes neurais convolucionais 1",
          "Introdução a redes neurais convolucionais 2",
          "Etapa 1 – operador de convolução (introdução)",
          "Etapa 1 – operador de convolução (cálculos)",
          "Etapa 2 – pooling",
          "Etapa 3 – flattening",
          "Etapa 4 – rede neural densa"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação",
        "Programação básica em Python",
        "Conhecimentos sobre Machine Learning são desejáveis mas não obrigatórios"
      ],
      "description": "A área de Processamento de Linguagem Natural - PLN (Natural Language Processing - NLP) é uma subárea da Inteligência Artificial que tem como objetivo tornar os computadores capazes de entender a linguagem humana, tanto escrita quanto falada. Alguns exemplo de aplicações práticas são: tradutores entre idiomas, tradução de texto para fala ou fala para texto, chatbots, sistemas automáticos de perguntas e respostas, sumarização de textos, geração automática de descrições para imagens, adição de legendas em vídeos, classificação de sentimentos em frases e áudios, dentre várias outras! Dentro desta área existe a classificação de áudio, que consiste em identificar sons específicos em áudios. Alguns exemplos são: identificação de sons do ambiente (carros, buzina, latidos, sirenes, etc), classificação de estilos musicais, transcrição de texto, reconhecimento de emoções pela fala e reconhecimento de comandos de voz, muito utilizado pelos assistentes virtuais.\nAtualmente, o setor comercial está cada vez mais necessitando de soluções de Processamento de Linguagem Natural voltadas ao áudio, ou seja, aprender essa área pode ser a chave para trazer soluções reais para necessidades presentes e futuras. Baseado nisso, este curso foi projetado para quem deseja crescer ou iniciar uma nova carreira na área de Processamento de Linguagem Natural, trabalhando especificamente com a classificação de arquivos de áudio! O curso está dividido em sete partes:\n\n\nNa parte 1 você aprenderá os conceitos teóricos sobre a área de áudio, como por exemplo: o que são sinais de áudio, sinal analógico e digital, amplitude, ondas, frequência, decibel, taxa de amostragem e principalmente, como representar o áudio para ser enviado para algoritmos de aprendizagem de máquina\nNa parte 2 serão implementados na prática vários dos conceitos abordados na primeira parte! Alguns exemplos são: carregamento e execução de arquivos de áudio, separação harmônica-percursiva, sintetização de cliques, Transformada de Fourier, Coeficiente Cepstral de Frequência Mel e geração de gráfico de ondas e espectrogramas. Ao final deste módulo, você saberá como extrair dados dos áudios para envio para algoritmos de aprendizagem de máquina. Será utilizada a biblioteca Librosa\nNa parte 3, vamos utilizar a base UrbanSound8K para classificar os seguintes sons ambientais: ar condicionado, buzina de carro, crianças brincando, latidos de cachorro, perfuração, motor em marcha lenta, tiros de arma, britadeira, sirene e música de rua. Faremos o treinamento de uma rede neural convolucional utilizando o TensorFlow, e ao final, vamos enviar um áudio e a rede neural será capaz de classificar qualquer uma dessas categorias\nNa parte 4, vamos utilizar a arquitetura pré-treinada YAMNet para classificar 521 diferentes eventos de áudio! Logo após, utilizaremos transferência de aprendizagem para classificar o canto de 5 espécies diferentes de pássaros\nNa parte 5 utilizarmos a base de dados RAVDESS para classificar as seguintes emoções de áudios: tristeza, surpresa, nojo, neutro, medo, felicidade e calmo\nNa parte 6 você entenderá o básico sobre como funciona um assistente de voz! Por meio da base mini-speech-commands, vamos treinar uma rede neural para classificar 8 tipos diferentes de comandos\nPor fim, na parte 7 utilizaremos a biblioteca SpeechRecognition para realizar a transcrição de áudio, ou seja, você fala e o algoritmo faz a transcrição em formato textual!\nTodos os códigos serão implementados passo a passo, com detalhes e utilizando o Google Colab. Com isso, você não precisa se preocupar com instalações e configurações de softwares na sua própria máquina! São mais de 90 aulas e mais de 12 horas de vídeos passo a passo!",
      "target_audience": [
        "Pessoas interessadas em classificação de áudio e processamento de linguagem natural",
        "Alunos de graduação e pós-graduação que estejam cursando disciplinas sobre Inteligência Artificial",
        "Cientistas de Dados que tenham interesse em aumentar seu portfólio de projetos"
      ]
    },
    {
      "title": "データサイエンス実戦講座［第４回］ベイズ統計の基礎と”量が質を凌駕する”パラレルワールド",
      "url": "https://www.udemy.com/course/4-mgpqnb/",
      "bio": "近年、統計学の主流となりつつあるベイズ統計学について、基本的な考え方をわかりやすく徹底的に解説します。ベイズの定理に集約された概念は、機械学習やAIとの親和性が高く、データサイエンスの世界の共通言語を習得することができます。",
      "objectives": [
        "自然現象や社会現象のメカニズムを分析するデータサイエンスの様々な手法について、複数のコースに分けて1つずつ習得していきます。古典的な頻度論の統計学から最新のディープラーニングまで、原理の理解と実務への応用を目指します。",
        "近年、注目を集めているベイズ統計学の基礎を学習します。現象を分析するという目的は頻度論の統計学と同じですが、ベイズでは母集団と標本の捉え方が真逆で、パラレルワールドの統計学という視点で見ると理解がしやすくなります。本コースではその基本原理を詳しく解説します。",
        "頻度論の世界観では現象の特徴量を指す母数は未知の真値で、標本データを分析することで母数の存在範囲と観測頻度を推定します。一方、ベイズ統計では母数は確率変数で、データを集めて分析を重ねることで母数の確率密度分布を推定精度が高くなります。これが”量が質を凌駕する”の意味で、機械学習やＡＩにも通じる概念を学びます。",
        "パラレルワールドを支配するベイズの定理について学びます。本来は２つの事象に関する条件付き確率の交換法則ですが、これを原因と結果、仮説とデータ、事前分布と事後分布の関係式に拡張することで、結果から原因の究明、データから仮説の検証、母数の初期分布（事前分布）から母数の確率密度分布（事後分布）の推定が可能になります。",
        "データを観測するたびに母数の確率密度分布を逐次推定するベイズ推定の基本原理について解説します。共役分布を用いて解析的に推定する手法と、マルコフ連鎖モンテカルロ（MCMC）法を用いて数値近似する手法があり、例題と面白いクイズを通じて理論の理解と統計分析についての認識を深めます。"
      ],
      "course_content": {},
      "requirements": [
        "高校レベルの数学力があれば十分です。なくても理解できるよう丁寧に解説しています。",
        "正確を期すために数理モデルは示しますが、直感的な理解と解釈を重視してグラフや図による説明を主体にします。"
      ],
      "description": "ベイズ統計学の理解するうえで重要な３つのポイントを解説します。\n１)　パラレルワールドの統計学：頻度論とベイズの世界観の違いから、分析目標は同じでもアプローチが真逆になることを把握します。\n２．ベイズの定理：定理の意味を理解し、原因の究明、仮説の検証、母集団の特徴量の分布推定に拡張するロジックを学習します。\n３．ベイズ推定：新たにデータを得るたびに母数の確率分布を逐次推定するロジックを理解し、統計分析ソフトJASPを用いて現実の問題に適用するスキルを習得します。",
      "target_audience": [
        "学業や業務でデータ分析を必要としている方、将来データアナリストを目指す方、データサイエンスに興味のある方であればどなたでも。 データ分析の初心者から学び直しの中級者。"
      ]
    },
    {
      "title": "A-Z™ | Projelerle Yapay Zeka ve Bilgisayarlı Görü | +20 Saat",
      "url": "https://www.udemy.com/course/a-ztm-projelerle-yapay-zeka-ve-bilgisayarli-goru-20-saat/",
      "bio": "PyTorch - TensorFlow - FastAi - OpenCV - YOLO - TensorFlow 1/2 - Detectron2 - Flask/Heroku - TF Lite - TensorRT - SAHI",
      "objectives": [
        "Derin öğrenme ve Evrişimsel Sinir Ağlarının Teorisini Öğreneceğiz.",
        "A-Z - Pytorch ile Makine Öğrenmesi ve Derin Öğrenme Algoritmalarının Nasıl Kodlanacağı Öğreneceğiz.",
        "A-Z - Tensorflow ile Derin Öğrenme Algoritmalarının Nasıl Kodlanacağı Öğreneceğiz.",
        "FastAİ ile Hızlı Bir Şekilde Nasıl Model Eğitileceği Öğreneceğiz.",
        "OpenCV Kütüphanesini Kullanarak Temel Görüntü İşleme Fonksiyonlarını Öğreneceğiz.",
        "Convolutional Neural Networks Algoritması Kullanarak Görüntü Sınıflandırmanın Pytorch - TensorFlow - FastAİ ile Nasıl Yapılacağını Öğreneceğiz.",
        "Pytorch - TensorFlow - FastAİ ile sıfırdan Yapay Sinir Ağlarının Nasıl İnşa Edileceğini Öğreneceğiz.",
        "YOLO Ailesinde olan Tüm Algoritmalarla Özel (Custom) Verilerde Nasıl Nesne Tespiti Yapılacağını Öğreneceğiz.",
        "Tensorflow 1 ve 2 ile Modern Algoritmalarda Özel (Custom) Veriler ile Nasıl Nesne Tespiti Yapılacağını Öğreneceğiz.",
        "Detectron2 ile Faster R-CNN Algoritmasın'da Özel (Custom) Veriler ile Nasıl Nesne Tespiti Yapılacağını Öğreneceğiz.",
        "HaarCascade ile Özel (Custom) Veriler ile Nasıl Nesne Tespiti Yapılacağını Öğreneceğiz.",
        "Detectron2 ile Mask R-CNN Algoritmasında Özel (Custom) Veriler ile Nasıl Segmentasyon (Maskeleme) Yapılacağını Öğreneceğiz.",
        "Türk Yapımı ve Gurur Kaynağı Olan SAHI Algoritmasının Ne Olduğunu ve Kullanmayı Öğreneceğiz.",
        "Tensorflow ile Bonus Projeler Yapacağız.",
        "Gradio ile Eğittiğimiz Modelleri Web'de Nasıl Test Edilir onu Öğreneceğiz.",
        "Weights & Biases (WandB) ile Tensorflow / Pytorch'da Modellerimizi Görselleştirip Nasıl Analiz Edileceğini Öğreneceğiz.",
        "Resim Sınıflandırma ile Bir Oyunu Yapay Zekaya Nasıl Oynatılacağını Öğreneceğiz.",
        "DeepSort ile Nesne Tanıma Algoritmalarında Nesne Takibi Nasıl Yapılır Onu Öğreneceğiz.",
        "Nesne Tanıma Algoritmalarında Nesne Sayma (Counting) Nasıl Yapılır Onu Öğreneceğiz.",
        "TensorRT Ne Olduğunu Öğreneceğiz.",
        "TensorRT ile Nesne Tespiti Algoritmalarında Optimizasyon - FPS Arttırma Nasıl Yapılır Öğreneceğiz.",
        "Görüntü Verilerinde Metin Tanıma Nasıl Yapılır Öğreneceğiz.",
        "Eğittiğimiz YoloV4 ve YoloV5 Algoritmalarını Android'de Nasıl Çalıştıracağımızı Öğreneceğiz.",
        "Tensorflow ile Lite Object Detection Modellerinde Eğitim Yapıp Android'de Çalıştıracağız.",
        "Eğittiğimiz Sınıflandırma Modellerini Flask ile Web'de Çalıştırıp Heroku ile Serverlar'da Deploy (Dağıtım) Edeceğiz.",
        "Eğittiğimiz Object Detection Modellerini Flask ile Web'de Çalıştırıp Heroku ile Serverlar'da Deploy (Dağıtım) Edeceğiz."
      ],
      "course_content": {},
      "requirements": [
        "Öğrenme Arzusu ve Azim",
        "Temel Python Bilgisi",
        "Temel Seviyede Derin Öğrenme Bilgisi ve Konulara Aşinalık",
        "Temel Düzeyide Matematik Bilgisi"
      ],
      "description": "A-Z™ | Projelerle Yapay Zeka ve Bilgisayarlı Görü\nKursumuzda klasik ve derin öğrenme tabanlı yöntemlerini kullanarak nesne tespiti, sınıflandırma ve takibinin nasıl yapıldığını öğrenip, Tensorflow - Pytorch - Fastai - Opencv kütüphaneleriyle gerçek hayat projeleri yapacağız.\nProjelerle Yapay Zeka ve Bilgisayarlı Görü Kursu İçeriği\nGiriş Bölümü\nDerin Öğrenme Teori\nCNN (Convolutional Neural Networks) Teori\nEk Teori\nPytorch ile Derin Öğrenme\nTensorflow ile Derin Öğrenme\nFastAi ile Derin Öğrenme\nOpencv\nTensorflow ile Trafik İşaretlerini Sınıflandırma\nGradio ile Web Tabanlı Test\nTensorflow ve Pytorch'da Weights & Biases (WandB) | Özel Veri\nOyunda Yapay Zeka | Bir Oyunu Modelin Kendi Oynaması\nObject Detection - Nesne Tanıma ve Segmentasyon  | 2. Kısım\nYoloV4 ile Nense Tanıma\nYoloV5 ile Nense Tanıma\nYoloR ile Nense Tanıma\nYoloX ile Nense Tanıma\nDetectron2 ile Nense Tanıma | Özel Veri | Faster R-CNN -Facebook Al\nTensorflow 1 ile Nense Tanıma | Özel Veri | SSD MobileNet\nTensorflow 2 ile Nense Tanıma | Özel Veri | EfficientDet ve CenterNet HourGlass\nHaarCascade ile Nesne Tanıma | Özel Veri\nSAHI KÜTÜPHANESİ | Türk Yapımı ve Gurur Kaynağı\nDeepSort - Nesne Takibi | Özel Model/Veri\nDetectron2 ile Segmentasyon (Mask R-CNN) | Özel Veri - Facebook Al\nMask R-CNN\nMetin Tanıma\nCounting - Nesne Tanıma Algoritmalarında Nesne Sayma\nTensorRT - Optimizasyon | 3. Kısım\nTensorRT | Yolov4 - Object Detection için FPS Arttırma - Jetson Nano\nAndroid- Tensorflow / Lite  | 4. Kısım\nTensorflow Lite - Android App - Yolov4 | Özel Model/Veri\nTensorflow Lite - Android App - Yolov5 | Özel Model/Veri\nTensorflow Lite - Android App - Object detection - İmage Classification\nFlask - Heroku ile Web'de Deployment (İmage Classification) | Özel Model/Veri\nFlask - Heroku ile Web'de Deployment (Object Detection) | Özel Model/Veri",
      "target_audience": [
        "Görüntü işleme konusunda uzmanlaşmak isteyenler",
        "Geleceğin mesleklerinde yetkin olmak isteyen herkes",
        "Yapay zekaya ilgi duyan herkes",
        "Derin öğrenme konusundaki teorik ve uygulama bilgisiyle gerçek hayat problemlerini çözmek isteyenler",
        "Python programlama dili ile Pytorch - Fastai - Opencv - TensorFlow/Keras kütüphanelerini kullanarak kendi derin öğrenme modelini tasarlamak isteyenler",
        "Derin öğrenme yöntemleri ile nesne tespitinin ve sınıflandırmanın nasıl yapılacağını öğrenmek isteyenler",
        "Görüntü işlemenin Python ile nasıl kodlanacağını öğrenmek isteyenler",
        "Dünyada en çok kullanılan yapay zeka kütüphanelerinden olan Pytorch - Fastai - TensorFlow/Keras kütüphanesini sıfırdan öğrenmek isteyenler"
      ]
    },
    {
      "title": "Data Science: Correlação no R, do zero ao avançado em 5h",
      "url": "https://www.udemy.com/course/correlacaoemr/",
      "bio": "Correlação. Pearson. Spearman. Data Science. Data Analysis. Big Date. Data Mining. Processamento de dados estatísticos.",
      "objectives": [
        "Correlacionar diferentes tipos de variáveis",
        "Coeficiente de Correlação de Pearson",
        "Testes de Significância de correlações",
        "Intensidade da Correlação",
        "Correlação de Spearman",
        "Correlação de Kendall",
        "Correlação Ponto Bi-serial",
        "Correlação Parcial",
        "Análise Gráfica de Correlações"
      ],
      "course_content": {
        "Introdução": [
          "Seja muto bem vindo(a)!",
          "Introdução",
          "Importando os dados",
          "Tratamento de Dados"
        ],
        "Correlação entre Numérica x Numérica": [
          "Verificando Correlações Graficamente (parte 1)",
          "Verificando Correlações Graficamente (parte 2)",
          "Verificando Correlações Graficamente (parte 3)",
          "Verificando Correlações Graficamente (parte 4)",
          "Verificando a Suposição de Normalidade (Introdução)",
          "Verificando a Suposição de Normalidade pelo Histograma",
          "Verificando a Suposição de Normalidade pelo QQplot (FICA PRETO NO FIM)",
          "Editando o QQplot",
          "Verificando a Normalidade pelo Gráfico de Envelope da Normal (introdução)",
          "Criando no R a função para o gráfico de Envelope",
          "Verificando a Normalidade por Testes Estatísticos",
          "Coeficiente de Correlação Linear de Pearson (introdução)",
          "Coeficiente de Correlação Linear de Pearson no R",
          "Coeficiente de Determinação",
          "Matriz de Correlação de Pearson",
          "Direção da Correlação",
          "Testando a Significância das Correlações",
          "Coeficiente de Correlação de Spearman (Rho)",
          "Coeficiente Tau de Kendall"
        ],
        "Correlação Ordinal x Ordinal": [
          "Correlação entre duas variáveis ordinais"
        ],
        "Correlação entre Numérica x Ordinal": [
          "Numérica x Ordinal"
        ],
        "Correlação entre Nominal x Nominal": [
          "Introdução",
          "Criando uma Tabela de Contingência no R",
          "Analisando as Frequências Observadas e Esperadas",
          "A Estatística Qui-Quadrado",
          "Estudando o p-valor do Teste Qui-Quadrado de Independência",
          "Correção de Continuidade de Yates",
          "Teste Exato de Fisher",
          "Medidas de Associação",
          "Análise de Concordância Kappa"
        ],
        "Correlação Nominal x Ordinal": [
          "Nominal x Ordinal - Análise das Frequências Esperadas",
          "Nominal x Ordinal - Parte 2",
          "Dicotômica x Ordinal"
        ],
        "Correlação entre Nominal x Numérica": [
          "Correlação entre Nominal x Numérica"
        ],
        "Correlação Parcial": [
          "Correlação Parcial (parte 1)",
          "Correlação Parcial (parte 2)",
          "Correlação Parcial (parte 3)"
        ],
        "Aula Bônus": [
          "Aula Bônus: o próximo passo",
          "Trilha de Aprendizado para a carreira em Data Science"
        ]
      },
      "requirements": [
        "Aconselho fazer meu curso de Linguagem R do zero"
      ],
      "description": "Olá!!! Tudo bem com você?!!  Neste curso onde você aprenderá de forma simples, fácil e indo direto ao ponto, a como executar os Testes Estatísticos de Comparação de Dois Grupos para a correta tomada de decisões.\nMeu nome é Isaías M. Lira, sou Consultor e Bacharel em Estatística, Especialista em Docência Superior e Consultor em Análise de Dados e quero muito que a Estatística deixe de ser um problema para você e passe a ser uma nova HABILIDADE para sua carreira profissional ... vamos lá?!!\n\nPor que criei este curso?\nData Scientist (Cientista de Dados, Análise de Dados) foi classificado como o primeiro emprego no Glassdoor e com salário médio de mais de $ 120,000 nos Estados Unidos e é sem dúvida a função com vagas sobrando e sem gente capacitada para preenchê-la. É a carreira mais valiosa no momento, pois permite resolver alguns dos problemas mais interessantes do mundo.\n\nE se você já programa em outra linguagem, saiba que a principal linguagem para Data Scientist é o R. Por que não dar este grande salto para Data Science?\nEste curso é avaliado em milhares de dólares, mas agora você pode aprender toda essa informação por um preço simbólico!\nCom muito conteúdo em vídeo, vários exercícios, didática simplificada e abordagem inovadora, fizeram deste curso um dos cursos mais abrangentes para ciência de dados e aprendizagem de máquinas na Udemy com língua Portuguesa!\nCorrelacionar dados é uma necessidade constante de quem procura soluções de problemas. Em qualquer área, será sempre de altíssimo valor o profissional que sabe buscar soluções de problemas encontrando as variáveis que estão mais correlacionadas com este problema.\n\nPorém, existem detalhes importantíssimos que fazem uma análise de correlação ser confiável ou não... E é isto que vou mostrar neste curso: o que você precisa saber para correlacionar variáveis.\nAlém disto, tudo será feito no R, que é considerada hoje uma das principais ferramentas de análise de dados estatísticos.\nFaça acontecer, invista em você, tenha as qualidades e habilidades que o mercado de HOJE precisa!\nO que você tem a perder?\n\nObs: Uma grande dificuldade das pessoas é juntar tudo numa ordem lógica (saber o que aprender primeiro, segundo, etc.), então pensando nisto queria te situar na ORDEM DOS CURSOS:\n#1: Curso sobre o R\n#2: Visualização de Dados no R\n#3: Mapas no R\n#4: Correlação no R\n#5: Curso de SPSS\n#6: Regressão Linear no SPSS-R-Excel\n#7: Comparação de Dois Grupos no SPSS\nDevido às atualizações de aperfeiçoamento, estes nomes podem ser alterados o que pode dificultar sua procura aqui no Udemy, então logado no Udemy faça:  \"Meus Cursos\" > Clique no curso MEU em que vc está matriculado > Nas aulas clique em \"Ir ao Painel\" > \"Visão geral\" > No fim tem Instrutor e clique em meu nome > Ok. veja a relação completa de meus cursos.\nForte abraço e estou ansioso para conhecer você!",
      "target_audience": [
        "Leigos interessados em calcular a Correlação entre eventos (variáveis) no R",
        "Profissionais de TI, Professores, Mestrandos, Doutorandos ou qualquer profissional que desejar aprender a Correlacionar dados estatísticos."
      ]
    },
    {
      "title": "Yeni Başlayanlar İçin Veri Bilimine Giriş",
      "url": "https://www.udemy.com/course/yeni-baslayanlar-icin-veri-bilimine-giris/",
      "bio": "Veri bilimi dünyasına yeni nesil uzaktan öğrenme teknikleriyle basit ve etkili bir başlangıç",
      "objectives": [
        "Veri bilimi dünyasının hangi adımları geçerek bugünlere geldiğini öğreneceksiniz.",
        "Veri bilimi çalışırken gerekli olabilecek kaynakları tek bir derste görebileceksiniz.",
        "Bilgi Piramidi, veri bilimi uygulama adımları vb. konsept içerikler ile temel eğitim.",
        "Spesifik makine öğrenimi örnekleri ve uygulamalarıyla ile temel eğitim.",
        "Veri Görselleştirme örnekleri ve uygulamaları ile görsel çalışmalara başlayabileceksiniz."
      ],
      "course_content": {},
      "requirements": [
        "Veri bilimi ve yapay zeka konusunda meraklı olmak.",
        "Öğrendikleriniz pratiğe dökebileceğiniz bir bilgisayar"
      ],
      "description": "Yeni nesil uzaktan öğrenme teknikleri ile R* programlama dilini beraber kullanarak veri biliminde  uzmanlaşacağınız kurs setimizin ilk dersine hoşgeldiniz!\nYeni Başlayanlar için Veri Bilimine Giriş\nVeri Bilimi için \"R\" Programlama\nVeri Bilimi için İstatistik\nMakine Öğrenimi (Machine Learning)\nVeri Görselleştirme (Data Visualization)\nVeri Madenciliği  (Data Mining )\nDerin Öğrenme (Deep Learning)\nVeri bilimi alanında yüksek lisanslı veri profesyoneliyle beraber veri bilimine hem rahat hem de ayakları yere basan bir giriş yapacaksınız!\nBu ders ile veri bilimine giriş yaparken sektöre dair bilgiler edinirken, akademik ve teorik alt yapınızı da hazırlayacaksınız.\n\n\nKurstan maksimum verimde faydalanabilmek için:\n• Videolara iliştirdiğimiz kaynakları mutlaka kontrol edin.\n• R kodlarını .txt file hallerini indirip R-Script'inizde kullanın ve ardından kendiniz yazın\n• Makine öğrenimi bilgileriniz ile sektör kullanımları arasındaki bağları sorun\n• Ders ile alakalı olsun olmasın herhangi bir sorunuzda iletişime geçmekten çekinmeyin! Data Forest ekibi olarak her zaman destek olmaya hazırız\n\n\nBu kursta:\nVeri Bilimi Dünyasına Giriş\n• Neden Veri Bilimi Öğrenmeliyiz?\n• Veri Biliminin Tarihi\n• Veri Bilimi Neden Popular Oldu?\n• Büyük veri, Big Data Nedir? Dünyada Ne Kadar Veri Üretiliyor\n\n\nVeri Bilimi Toolkit\n• R ve R-Studio Programlarını İndirme\n• SQL Öğrenme Kaynağı\n• Anaconda – Python Programlarını İndirme\n• Lisans Ücretli Veri Bilimi Platformlarına Örnek\n• Kod Deposu: Github\n• Online Veri Bilimi Platformu Kaggle’a Giriş\n• Distributed (Dağıtık) Hesaplama Yapısı Hadoop\n• Google Dataset Search Nedir?\n• R Programlama Örneğine Giriş\n• R ile Veri Keşfi Örneği\n• R ile Veri Ön İşleme ve Görselleştirme\n• R ile Makine Öğrenimi ve Tahmin Analitiği\n\n\nMakine Öğrenimi Temelleri\n• Bilgi Piramidi Nedir?\n• Veri Bilimi Uygulamaları Şeması\n• Makine Öğrenimi Nedir?\n• Sektörel Örnekler\n• Multi – disipliner Makine Öğrenimi Kullanımları\n• Lineer Regresyona Giriş\n• Lineer Regresyon Parametreleriyle Optimizasyon\n• Sınıflandırma Örneği: Lojistik Regresyon\n• Lojistik Regresyon Temelleriyle Sınıflandırma Metrikleri\n• Yapay Sinir Ağlarına Giriş\n• Aktivasyon Fonksiyonları ve Backpropagation\n• Derin Öğrenme Örnekleri\n• Kümeleme Giriş\n• Kümeleme Çeşitlerinde Performans Metrikleri\n\n\nBONUS\n• Karar Ağaçlarına Giriş\n• Karar Ağaçları Parametreleri\n• R’da Karar Ağaçları Uygulaması\n• Veri Görselleştirme: Histogram\n• R’da Histogram Uygulaması\n• Veri Görselleştirme: Alluvial Flow-Sankey Diagramı\n• R’da Alluvial Flow-Sankey Diagramı Uygulaması\n• Veri Görselleştirme: Bubble Scatter Grafiği\n• R’da Bubble Scatter Grafiği Uygulaması\n• R’da Lineer Regresyon Uygulaması\n• R’da Lojistik Regresyon Uygulaması\n• R’da DBSCAN Kümeleme Uygulaması\n• Yapay Sinir Ağları - XOR Problem Çözümü\n---------------------------------------------------------------\n\n\n*Python derslerimiz için de bizi takipte kalın!",
      "target_audience": [
        "Veri bilimine meraklı",
        "Başlangıç düzeyindeki R geliştiricileri",
        "Kariyerini veri bilimi ve yapay zeka alanlarına yönlendirmek isteyen çalışanlar",
        "Makine Öğrenimi konusunda meraklı"
      ]
    },
    {
      "title": "Iniciación a Computer Vision con Machine/Deep Learning en R",
      "url": "https://www.udemy.com/course/iniciacion-a-computer-vision-con-machine-deep-learning-en-r/",
      "bio": "Entra en el mundo de la Visión por Computador reconociendo números manuscritos usando Machine y Deep Learning",
      "objectives": [
        "El curso se centra en el reconocimiento automático de números en la escritura manual. A través de este tipo de imágenes (números escritos a mano), vamos a ver diversas operaciones, métodos y algoritmos para clasificar los números manuscritos y predecir e interpretar nuevas imágenes. Además, aprenderás a utilizar R y plataformas de Deep Learning como H2O o TensoFlow."
      ],
      "course_content": {
        "INTRODUCCIÓN": [
          "Introducción",
          "Presentación David Manero",
          "Objetivos del Curso"
        ],
        "¿DE QUÉ HABLAMOS?": [
          "Computer Vision",
          "Machine Learning",
          "Deep Learning",
          "Reconocimiento de Escritura"
        ],
        "PREPARACIÓN": [
          "¿Qué es R? ¿Y RStudio?",
          "Instalación de R y RStudio en Mac",
          "Paquete Caret",
          "¿Qué es H20? ¿Y TensorFlow?",
          "Instalación H2O",
          "Instalación Tensor Flow",
          "Instalación de librerías necesarias"
        ],
        "FUNDAMENTOS DE R": [
          "Aviso",
          "Conociendo a R parte 1",
          "Conociendo a R parte 2",
          "Operadores",
          "Objetos: vectores parte 1",
          "Objetos: vectores parte 2",
          "Objetos: dataframe parte 1",
          "Objetos: dataframe parte 2",
          "Objetos: dataframe parte 3",
          "Objetos: listas",
          "Objetos: series de tiempo",
          "Bucles Explicación",
          "Bucles parte I",
          "Bucles parte II",
          "Funciones",
          "Visualización Básica",
          "Ejemplo uso de paquete Caret: SPAM"
        ],
        "LOS DATOS: MNIST": [
          "¿Qué es MNIST?",
          "Explorando los datos MNIST parte 1",
          "Explorando los datos MNIST parte 2"
        ],
        "MÉTODOS MACHINE LEARNING": [
          "Machine Learning para clasificar los dígitos MNIST",
          "¿Cómo funciona Naïve Bayes?",
          "Método Naïve Bayes sobre MNIST",
          "¿Qué es NZV (Near-Zero Value)? ¿Y PCA (Principal Component Analysis)?",
          "¿Cómo funciona Random Forest?",
          "Método Random Forest sobre MNIST",
          "Práctica con Naïve Bayes",
          "Práctica con Random Forest",
          "¿Cómo funciona SVM (Support Vector Machine)?",
          "Método SVM sobre MNIST",
          "¿Cómo funcionan las Redes Neuronales?",
          "Método Neuranet sobre MNIST",
          "Práctica Redes Neuronales",
          "¿Qué es SVD (Singular Value Decomposition)?",
          "¿Cómo funciona KNN (K-Nearest Neighbours)?",
          "Método SVD-KNN sobre MNIST",
          "Práctica con SVM",
          "¿Qué es HOG (Histogram of Oriented Gradients)?",
          "Método HOG-KNN sobre MNIST",
          "Práctica con K-NN"
        ],
        "PLATAFORMAS DEEP LEARNING": [
          "Deep Learning para clasificar los dígitos de MNIST",
          "¿Cómo funciona H2O?",
          "Método en H2O sobre MNIST",
          "Práctica Regular DNN",
          "¿Qué es Unsupervised Bottle-Neck?",
          "Método no supervisado en H2O sobre MNIST",
          "Práctica DNN-Encoder",
          "¿Cómo funciona Softmax Regression?",
          "Método TensorFlow sobre MNIST"
        ],
        "RESULTADOS": [
          "Comparativa de los resultados",
          "Kaggle y MNIST"
        ],
        "BONUS - Aplicación Reconocimiento de Números": [
          "Presentación App MNIST",
          "Archivos e instalación de librerías",
          "Dibujar el plot",
          "Dibujar la matriz",
          "Guardar modelos y convertir matriz",
          "Calcular predicciones",
          "Predicción total",
          "Mejoras de la app"
        ],
        "CONCLUSIONES": [
          "Resumen del curso",
          "Próximos pasos",
          "Despedida"
        ]
      },
      "requirements": [
        "Aunque se proporcionan unas bases de R, es recomendable conocerlo un poco. Los conceptos Matemáticos y Estadísticos utilizados se explicarán, pero conviene tener alguna base."
      ],
      "description": "La Visión por Computador o Computer Vision (en inglés) es uno de los primeros objetivos que tuvo la programación desde sus inicios y, sobre todo, desde que se planteó la utilización del procesado automático en las cadenas de montaje.\nDesde discriminar la madurez de las frutas por su color, hasta reconocer patrones biométricos, pasando por los pulsómetros ópticos, o el reconocimiento de matrículas. Las utilidades de la Visión por Computador están sólo limitadas por la imaginación humana.\nEn los últimos años, con el aumento del conocimiento en la denominada Ciencia de los Datos, se han desarrollados nuevos (y no tan nuevos) métodos de Aprendizaje para que sean las máquinas las que puedan tomar decisiones en base al procesado de la imagen que sus ojos tecnológicos les proporciona.\nEl Machine Learning y, el siguiente paso, el Deep Learning ha supuesto una ventaja mayor si cabe en la autonomía de las máquinas.\nTrabajaremos con un famoso set de datos denominado MNIST, y que contiene 60.000 ejemplos de números manuscritos con su correspondiente etiqueta del número que representan. Cada número esta formado por una matriz de píxeles de 28x28 con valores entre 0 y 255 para la intensidad del trazo.\nEn el curso vamos a analizar una buena cantidad de métodos y algoritmos de Machine Learning, como Naïve Bayes, Random Forest, Support Vector Machine, K Nearest Neighbours o Redes Neuronales y sistemas de pre-procesado de la información, como PCA, SVD o HOG.\nTambién trabajaremos algunos sistemas de Deep Learning, como H2O o Tensor Flow (de Google) para el tratamiento de esta información de imágenes.\nEspero que os guste el curso y que disfrutéis aprendiendo los entresijos de la Visión por Computador y el Aprendizaje Profundo y Automático.",
      "target_audience": [
        "Si te interesa la Ciencia de los Datos, la Visión por Computador, el Machine Learning o Aprendizaje Automático y el Deep Learning o Aprendizaje Profundo, ¡¡¡éste es tu curso!!!"
      ]
    },
    {
      "title": "L'Intelligence Artificielle pour l'Entreprise",
      "url": "https://www.udemy.com/course/intelligence-artificielle-pour-le-business/",
      "bio": "Créez des IA pour résoudre des problèmes réels du monde de l'entreprise",
      "objectives": [
        "Comment optimiser les processus business",
        "Comment implémenter un algorithme de Q-Learning",
        "Comment créer un modèle d'optimisation",
        "Comment maximiser l'efficacité de processus",
        "Comment minimiser les coûts de votre business",
        "Comment implémenter un algorithme de Deep Q-Learning",
        "Comment créer un environnement d'IA à partir de zéro",
        "Comment créer une IA",
        "Vous aurez un framework général de création d'IA s'appliquant à tous types de problèmes",
        "Comment enregistrer et réutiliser une IA",
        "Comment implémenter un algorithme de \"Early Stopping\"",
        "Comment maximiser les revenus de votre business",
        "Comment implémenter un algorithme Thompson Sampling",
        "Comment utiliser l'IA pour prendre les meilleures décisions",
        "Comment implémenter un algorithme d'apprentissage en ligne",
        "Comment faire une \"Regret Analysis\" avec l'IA"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Le livre Intelligence Artificielle pour le Business"
        ],
        "--------------- CHAPITRE 1 - OPTIMISATION DES PROCESSUS BUSINESS ---------------": [
          "Bienvenue dans le Chapitre 1 - Optimisation des Processus Business"
        ],
        "Cas d'usage": [
          "Minimiser les coûts - Etape 1",
          "Minimiser les coûts - Etape 2",
          "Minimiser les coûts - Etape 3"
        ],
        "Solution en IA": [
          "Bienvenue dans la Section Intuition",
          "Plan d'attaque",
          "Deep Q-Learning Intuition",
          "Experience Replay",
          "Stratégies de Sélection d'Action"
        ],
        "Implémentation": [
          "Optimisation des Processus Business - Étape 5",
          "Instructions d'installation",
          "Les templates de code",
          "Optimisation des Processus Business - Étape 6",
          "Optimisation des Processus Business - Étape 7",
          "Optimisation des Processus Business - Étape 8",
          "Optimisation des Processus Business - Étape 9",
          "Optimisation des Processus Business - Étape 10",
          "Optimisation des Processus Business - Étape 11",
          "Optimisation des Processus Business - Étape 12",
          "Optimisation des Processus Business - Étape 13",
          "Optimisation des Processus Business - Étape 14",
          "Optimisation des Processus Business - Étape 15",
          "Optimisation des Processus Business - Étape 16",
          "Optimisation des Processus Business - Étape 17",
          "Optimisation des Processus Business - Étape 18",
          "Optimisation des Processus Business - Étape 19",
          "Optimisation des Processus Business - Étape 20"
        ],
        "Exercice": [
          "Consigne de l'exercice",
          "Solution de l'exercice"
        ],
        "--------------- CHAPITRE 2 - MINIMISER LES COUTS ---------------": [
          "Bienvenue dans le Chapitre 2 - Minimiser les coûts"
        ],
        "Mise en oeuvre": [
          "Les templates de code",
          "Minimiser les coûts - Etape 4",
          "Minimiser les coûts - Etape 5",
          "Minimiser les coûts - Etape 6",
          "Minimiser les coûts - Etape 7",
          "Minimiser les coûts - Etape 8",
          "Minimiser les coûts - Etape 9",
          "Minimiser les coûts - Etape 10",
          "Minimiser les coûts - Etape 11",
          "Minimiser les coûts - Etape 12",
          "Minimiser les coûts - Etape 13",
          "Minimiser les coûts - Etape 14",
          "Minimiser les coûts - Etape 15",
          "Minimiser les coûts - Etape 16",
          "Minimiser les coûts - Etape 17",
          "Minimiser les coûts - Etape 18",
          "Minimiser les coûts - Etape 19",
          "Minimiser les coûts - Etape 20",
          "Minimiser les coûts - Etape 21",
          "Minimiser les coûts - Etape 22",
          "Minimiser les coûts - Etape 23",
          "Minimiser les coûts - Etape 24",
          "Minimiser les coûts - Etape 25",
          "Minimiser les coûts - Etape 26",
          "Minimiser les coûts - Etape 27",
          "Minimiser les coûts - Etape 28",
          "Minimiser les coûts - Etape 29",
          "Minimiser les coûts - Etape 30",
          "Minimiser les coûts - Etape 31",
          "Minimiser les coûts - Etape 32",
          "Installation de Keras",
          "Minimiser les coûts - Etape 33",
          "Minimiser les coûts - Etape 34",
          "Minimiser les coûts - Etape 35",
          "Minimiser les coûts - Etape 36"
        ]
      },
      "requirements": [
        "Mathématiques niveau lycée",
        "Connaissances basiques en Python"
      ],
      "description": "Structure du cours :\nChapitre 1 - Optimisation des Processus Business\nÉtude de cas : Optimisation des flux de déplacement dans un entrepôt de e-commerce\nSolution en IA : Q-Learning\nChapitre 2 - Réduction des coûts\nÉtude de cas : Minimisation de la consommation d'énergie d'un Data Center\nSolution en IA : Deep Q-Learning\nChapitre 3 - Maximisation des profits\nÉtude de cas : Maximisation des revenues dans un e-commerce\n\n\nApplications réelles du monde de l'entreprise :\nL'Intelligence Artificielle a TROIS grandes applications pour n'importe quel business :\nL'optimisation des processus business\nLa réduction des coûts\nLa maximisation des profits\nNous allons vous montrer exactement comment réaliser ces applications au travers de cas d'usages réels du monde de l'entreprise.\nPour chaque application, on va créer une IA pour résoudre un cas concret :\nDans le chapitre 1 - Optimisation des Processus Business - nous allons créer une IA qui va optimiser les flux de déplacement dans l'entrepôt d'un business de e-commerce.\nDans le chapitre 2 - Réduction des coûts - nous allons créer une IA plus avancée qui va minimiser la consommation d'énergie d'un Data Center de plus de 50% ! Exactement ce qu'a fait Google avec DeepMind très récemment.\nDans le chapitre 3 - Maximisation des profits - nous allons créer une IA un peu différente qui va maximiser les profits d'un business de e-commerce en créant une plus-value de plus de 1 milliard de dollars !!!\n\n\nEt nous ne nous sommes pas arrêtés là.\nPour la première fois, nous avons préparé un e-book exceptionnel de plus de 100 pages qui contient tout le matériel de Intelligence Artificielle pour le Business !\n\n\nL'e-book :\nCe livre contient :\n100 pages d'explications détaillées, rédigées proprement en LaTeX.\nToute la théorie et intuition (maths incluses) expliquées en détail.\nLes trois cas d'usages développés dans le cours ainsi que leurs solutions.\nLes trois modèles d'IA (Q-Learning, Deep Q-Learning, Thompson Sampling).\nLes templates de code.\nLe framework général de travail pour développer une nouvelle IA.\nDes tonnes de trucs et astuces (comme le Early Stopping, Enregistrer/Charger des modèles, etc.)\n\n\nConclusion :\n\n\nSi vous voulez décrocher un des jobs dans l'industrie la mieux rémunérée, ou si vous souhaitez démarrer une start-up en IA, alors ce cours est pour vous ! Devenez un expert en IA et accélérez votre carrière dans cette industrie du futur !",
      "target_audience": [
        "Vous avez un profil orienté business et cherchez à utiliser l'IA pour optimiser votre business, sa rentabilité, et son efficacité",
        "Vous avez une expérience en IA et souhaitez proposer des projets à vos employés",
        "Vous souhaitez devenir Data Scientist et enrichir votre portfolio avec des projets concrets",
        "Vous êtes intéressé par le Machine Learning et l'Intelligence Artificielle et souhaitez enrichir vos connaissances pour résoudre des problèmes business",
        "Vous êtes consultant et souhaitez accompagner les entreprises dans leur transition vers l'utilisation de l'IA"
      ]
    },
    {
      "title": "Power BI: Análisis y Visualización de Datos (Básico)",
      "url": "https://www.udemy.com/course/power-bi-analisis-y-visualizacion-de-datos-basico/",
      "bio": "Curso Introductorio de Power BI permite conocer las funciones básicas para el análisis, manipulación y visualización.",
      "objectives": [
        "Aprenderás todos los fundamentos de Power BI desde cero",
        "Transformarás datos en asombrosas visualizaciones interactivas de una manera muy dinámica: Todo esto con herramientas gratuitas.",
        "Tendrás el conocimiento y la habilidad requeridos para indagar más allá de las funciones de Power BI y encontrar soluciones a problemas complejos.",
        "Reforzarás todo lo aprendido con casos 100% prácticos.",
        "Tienes disponible la base de datos del curso para practicar."
      ],
      "course_content": {
        "Introducción": [
          "¿Qué es Power BI?",
          "Descargar e Instalar Power BI",
          "¿Qué aprenderás en este curso?"
        ],
        "Obtener Datos": [
          "Conociendo la Interfaz de Power BI",
          "Conexión de los Datos"
        ],
        "Creando Nuestro Dashboard": [
          "Creando Nuestro Reporte"
        ],
        "Editor Power Query": [
          "Combinar Tablas",
          "Actualizar Datos",
          "Modificar Datos"
        ]
      },
      "requirements": [
        "PC / Notebook",
        "Motivación e Interés por aprender y practicar."
      ],
      "description": "Power BI es un conjunto de herramientas que pone el conocimiento al alcance de todos y nos brinda acceder a nuestros datos de forma segura y rápida generando grandes beneficios, el curso se centra en la siguiente temática.\n\n\nConocer y manejar las herramientas de Microsoft Power BI.\nAprenderás a realizar análisis de datos.\nAprenderás a crear gráficos dinámicos.\nAprenderás a crear informes interactivos para realizar análisis de tendencias y oportunidad a partir de los datos de nuestra empresa.\nRealizar visualizaciones de cuadros de mando y crear presentaciones dinámicas.\nConstruir Dashboard o paneles de control con Power BI.\nCrear y analizar llamativas visualizaciones interactivas,\nDashboard entorno de trabajo desde dispositivos.\n\n\nEn este curso te enseñare el manejo, manipulación y visualización de datos con Power BI logrando crear gráficas, paneles y reportes.\nEl mundo está lleno de datos y es fundamental saber como analizarlos y presentarlos para extraer valor de ellos. Esta es una habilidad que los empleadores valoran cada día más.\nTe garantizo que este curso es todo lo que necesitas para aprender a analizar y presentar grandes volúmenes de datos.\nEl enfoque de los proyectos del curso es totalmente práctico, y con cada nuevo proyecto contarás con nuevos recursos, guías y archivos necesarios para desarrollar distintos reportes, en donde al instante podrás aplicar lo que estás aprendiendo. Asimismo, contarás con soporte directo del instructor, así como de un foro de preguntas y respuestas donde podrás participar con tus compañeros del curso.\n\n\nPreguntas frecuentes:\n1. ¿Necesito un software especializado o de pago para poder tomar el curso?\nR: No. Solo necesitas instalar la paquetería de Power BI en su versión gratuita.\n2. ¿Dónde obtengo la paquetería de Power BI?\nR: En el curso te enseñamos de donde descargarla y como instalarla.\n3. ¿Necesito algún conocimiento previo para tomar el curso?\nR: No, el curso esta diseñado para empezar desde cero y llevarte de la mano por cada uno de los temas.\n4. ¿Qué podré hacer después del curso?\nR: Analizar grandes volúmenes de datos para generar propuestas de alto valor y presentarlas en gráficos visualmente atractivos.",
      "target_audience": [
        "Estudiantes y profesionales que quieran aprender a utilizar Power BI",
        "Estudiantes y profesionales que quieran entrar en el mundo del manejo, manipulación y visualización de datos"
      ]
    },
    {
      "title": "Machine Learning y Data Science con PySpark: cero a experto",
      "url": "https://www.udemy.com/course/machine-learning-y-data-science-con-pyspark-cero-a-experto/",
      "bio": "Curso completo para aprender a aplicar Machine Learning y Data Science al Big Data con Python y Apache Spark",
      "objectives": [
        "Introducción a big data y fundamentos de Apache Spark",
        "Machine Learning en cloud con Databricks",
        "Spark Streaming y predicciones en tiempo real",
        "Modelos de aprendizaje automático de Spark ML",
        "Ingeniería y preprocesamiento de datos con Spark",
        "Machine Learning avanzado con PySpark",
        "Fundamentos de Machine Learning con PySpark",
        "Funciones avanzadas con Apache Spark",
        "Spark Dataframes",
        "Spark Koalas",
        "Databricks y MlFlow"
      ],
      "course_content": {
        "Introducción al curso": [
          "Como aprovechar al máximo el curso",
          "Material del curso"
        ],
        "Introducción a Apache Spark y Big Data": [
          "Introducción a Apache Spark y Big Data",
          "Cómo se ejecuta Apache Spark",
          "Ecosistema de Apache Spark y documentación oficial",
          "Funcionamiento, administración de clústeres y arquitectura de Spark"
        ],
        "Instalación de Spark y herramientas de Machine Learning": [
          "Descarga de Spark, Anaconda y Java",
          "Configuración de las variables de entorno",
          "Ejecución de Spark en el Prompt y Jupyter notebooks"
        ],
        "Spark DataFrames y Apache Spark SQL": [
          "Fundamentos y ventajas de los DataFrames",
          "Características de los DataFrames y fuentes de datos",
          "Crear un DataFrame en PySpark",
          "Operaciones con DataFrames en PySpark",
          "Diferentes tipos de joins en DataFrames",
          "Consultas SQL en PySpark",
          "Funciones avanzadas para cargar y exportar datos en PySpark",
          "Ejercicio Práctico: Spark DataFrames y Apache Spark SQL",
          "Solución Ejercicio práctico"
        ],
        "Funciones avanzadas de PySpark": [
          "Funciones avanzadas y optimización del rendimiento",
          "BroadCast Join y almacenamiento en cache",
          "User Defined Functions (UDF) y funciones avanzadas de SQL",
          "Manejo e imputación de valores faltantes"
        ],
        "Machine Learning con PySpark": [
          "Fundamentos de Machine Learning con PySpark",
          "Componentes de PySpark Machine Learning",
          "Etapas del desarrollo de un modelo de Machine Learning",
          "Importación y análisis exploratorio de los datos",
          "Preprocesamiento de los datos con PySpark",
          "Entrenamiento del modelo de machine learning en PySpark",
          "Evaluación del modelo de Machine Learning"
        ],
        "Ejercicio práctico de Machine Learning con PySpark": [
          "Ejercicio práctico Machine Learning con Spark parte I",
          "Solución al ejercicio práctico parte I",
          "Ejercicio práctico 2 Machine Learning con Spark",
          "Solución Ejercicio práctico 2",
          "Ejercicio práctico 3 Machine Learning con Spark",
          "Solución Ejercicio práctico 3"
        ],
        "Ingeniería de características": [
          "Fundamentos de Ingeniería de características con Spark",
          "Normalización de variables con Spark",
          "Variables categóricas StringIndexer y OneHotEncoder",
          "Variables categóricas VectorIndexer e IndexToString",
          "Imputación de variables faltantes",
          "Selección de variables con Variance ThresholdSelector y UnivariateFeat",
          "Reducción de la Dimensionalidad"
        ],
        "Modelos de clasificación con Spark Machine Learning": [
          "Regresión logística",
          "Arboles de decisión",
          "Random Forest",
          "Gradient Boosting Tree",
          "Clasificador de Perceptrón multicapa",
          "Linear Suport Vector Machine",
          "Clasificación multiclase con One vs Rest Classifier",
          "Naive Bayes"
        ],
        "Modelos de Regresión con Spark Machine Learning": [
          "Regresión lineal y Regresión lineal Generalizada",
          "Decision Tree Regressor y Random Forest Regressor",
          "Gradient-boosted Tree Regressor",
          "Análisis de supervivencia con Survival Regressor",
          "Factorization machines regressor"
        ]
      },
      "requirements": [
        "No"
      ],
      "description": "Si estás buscando un curso práctico, completo y avanzado para aprender Machine Learning y Data Science con Big Data utilizando PySpark, has venido al lugar correcto.\nEste curso está diseñado para aprender todo lo relacionado con el Machine Learning y Data Science en Spark como modelos de aprendizaje automático de clasificación, regresión, clustering, NLP, Pipelines y técnicas para la ingeniería de datos y preprocesamiento. También te enseñaremos a programar en PySpark y las buenas prácticas para trabajar con Big Data, visualización de datos o analítica avanzada. Finalmente, aprenderás las últimas tecnologías que han permitido impulsar el Machine learning con Spark como MLFlow, Databricks, Spark ML o Spark Koalas.\n\n\nEste curso es para científicos de datos o aspirantes a científicos de datos que desean obtener capacitación práctica, con las últimas tecnologías y aplicable al mundo real en PySpark (Python para Apache Spark)\n\n\nEl Big Data ha revolucionado el campo del Machine Learning, permitiendo entrenar modelos sobre grandes cantidades de datos. El Machine Learning convencional con Python se ha quedado obsoleto y nuevas tecnologías como Apache Spark han cobrado gran relevancia. Este curso te enseñará todo lo que necesitas saber para posicionarte en el mercado laboral del Machine Learning y aprenderás una de las habilidades más demandadas para ingenieros de datos y científicos de datos.\n\n\nEn este curso te enseñaremos todas las habilidades de Machine Learning con PySpark, partiendo desde las bases hasta las funcionalidades más avanzadas. Para ello utilizaremos presentaciones visuales en Power Point, compartiendo explicaciones claras y útiles consejos profesionales.\nCada sección tendrá una parte de teoría y de revisión de conceptos, así como también de código a lo largo de actividades, casos de uso reales y proyectos prácticos. Además incorpora ejercicios aplicados para que pongas en práctica lo aprendido así como las soluciones a cada ejercicio.\nCon la formación teórica, las guías de estudio descargables, los ejercicios prácticos y los casos de uso reales, este es el único curso que necesitarás para aprender Machine Learning con PySpark\n\n\nEste curso desarrolla los siguientes apartados:\nIntroducción a big data y fundamentos de Apache Spark\nInstalación de Apache Spark y librerías accesorias como Anaconda, Java, etc\nSpark Dataframes\nFunciones avanzadas con Apache Spark\nFundamentos de Machine Learning con PySpark\nMachine Learning avanzado con PySpark\nIngeniería y preprocesamiento de datos con Spark\nModelos de aprendizaje automático de Spark ML\nClasificación en Spark ML\nRegresión en Spark ML\nClustering en Spark ML\nSpark Streaming y predicciones en tiempo real\nDatabricks y MLFlow\nMachine Learning en cloud con Databricks\nSpark Koalas\n\n\nSi está listo para mejorar tus habilidades, aumentar tus oportunidades laborales y convertirte en un experto en Big Data Science, únete hoy y obtén acceso inmediato y de por vida a lo siguiente:\n• Guía completa de Machine learning con Spark (e-book en PDF)\n• Archivos de proyecto descargables\n• Ejercicios prácticos y cuestionarios\n• Recursos de Spark ML como: Cheatsheets y resúmenes\n• Soporte experto 1 a 1\n• Foro de preguntas y respuestas del curso\n• 30 días de garantía de devolución de dinero\n¡Nos vemos allí!",
      "target_audience": [
        "Científicos de datos interesados en aprender PySpark",
        "Desarrolladores de PySpark que buscan fortalecer sus habilidades de Machine Learning y ciencia de datos",
        "Desarrolladores de Python que necesitan trabajar con big data",
        "Cualquiera que quiera aprender habilidades avanzadas de big data",
        "Cualquiera que conozca Python y quiera avanzar en un procesamiento de datos más rápido",
        "Cualquiera que quiera hacer carrera como ingeniero de datos, analista de datos, científico de datos",
        "Cualquiera que quiera aprender tecnología de vanguardia en procesamiento de datos"
      ]
    },
    {
      "title": "データサイエンス実戦講座［第２回］仮説検定の徹底理解とp値によるリスク対策（前編）",
      "url": "https://www.udemy.com/course/2p-uofbx/",
      "bio": "統計学の中で最もよく使われる仮説検定の原理を理解して、現実の問題解決のための３つのスキル（①アクションプランとリスク対策の立案、➁パラメトリック検定とノンパラメトリック検定の併用、③統計解析ソフトの活用）を手に入れよう。",
      "objectives": [
        "自然現象や社会現象のメカニズムを分析するデータサイエンスの様々な手法について、複数のコースに分けて1つずつ習得していきます。古典的な頻度論の統計学から最新のディープラーニングまで、原理の理解と実務への応用を目指します。",
        "第２回目のコースは仮説検定です。統計学のなかで最もよく使われる手法ですが、誤解や誤用がとても多く、アメリカ統計協会は『p値と統計的有意性に関する声明』を発表して警鐘を鳴らしています。本コースでは仮説検定のロジックを解きほぐして分かりやすく説明します。",
        "仮説検定には、母集団に正規分布などを仮定するパラメトリック検定と、何も仮定しないノンパラメトリック検定があります。統計学の基礎レベルでは前者しか扱わないのが普通ですが、現実には正規分布に従わない現象や、母集団の分布が分からない場合も多々あります。本コースでは問題に応じて両方の手法が使えるように学習します。",
        "ＪＡＳＰというフリーの統計解析ソフトを演習問題で使用します。アムステルダム大学が開発したソフトで、メニューは日本語化されています。仮説検定ではパラメトリックとノンパラメトリックの手法が利用できます。豊富な機能を持ち、ベイズ統計の手法も使えますので、日々の勉学や実務にも役立つスキルを身に着けることができるでしょう。",
        "仮説検定だけに特化した内容です。パラメトリック検定とノンパラメトリック検定の両方を合わせると手法がとても多くなるため、前編（今回）と後編（次回）に分けました。前編では仮説検定のロジック解説、リスク対策の考え方、１サンプルの検定までを扱い、後編では２サンプルの検定、分散分析、分割表の検定を扱います。"
      ],
      "course_content": {
        "1. 仮説検定の３つのポイント": [
          "1-1 仮説検定の３つのポイントの解説とデータサイエンスの中での位置づけ"
        ],
        "2. 仮説検定の目的": [
          "2-1 仮説検定から得られる情報",
          "2-2 意思決定と行動選択"
        ],
        "3. 仮説検定の種類と選択方法": [
          "3-1 適切な検定手法の選択",
          "3-2 仮説検定とサンプルサイズ",
          "3-3 統計解析ソフト"
        ],
        "4. 正規性の検定": [
          "4-1 正規性の検定方法",
          "4-2 演習：正規性の検定"
        ],
        "5. １サンプルの代表値の検定": [
          "5-1 １サンプル問題と検定手法の選択",
          "5-2 １サンプルＺ検定",
          "5-3 １サンプルｔ検定",
          "5-4 １サンプル符号検定",
          "5-5 ウィルコクスン符号付き順位検定",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "高校レベルの数学力があれば十分ですが、必須ではありません。 正確を期すために数理モデルは示しますが、直感的な理解と解釈を重視してグラフや図による説明を主体にします。"
      ],
      "description": "データサイエンス実戦講座の第２回のテーマは仮説検定です。統計学の中でも実務で最もよく使われる手法のひとつで、例えば製品の改良開発が成功か失敗かの二者択一の仮説を立てて、統計学の視点から判定を下します。検定の原理を理解して現実世界の問題解決に活かすためのポイントは次の３つです。\n①アクションプランとリスク対策の立案・・・検定とは仮説の発生頻度の推定であり、仮説の「真偽」と判定の「正誤」は分かりません。問題解決には「真と偽」×「正と誤」＝４つのケースに対するアクションプランとリスク対策が必要で、これらを立案する方法が習得できます。\n➁パラメトリック検定とノンパラメトリック検定の併用・・・現実に起こる社会現象や自然現象のデータは正規分布しているとは限りません。このため、母集団に正規分布などを仮定するパラメトリック検定だけでなく、歪んだ分布や外れ値のある分布に適用できるノンパラメトリック検定も必要で、両者を併用する２段構えの分析力が身に付きます。\n③統計解析ソフトの活用・・・多くの手法を知っていても使えなければ意味がありません。アムステルダム大学が開発したフリーの統計解析ソフトJASPを駆使して、実戦的な演習問題を通して応用力が養えます。\n今回のコース（前編）では仮説検定の基礎理論と１サンプルの検定、次回の後編では２サンプル以上の手法を扱います。\nデータサイエンスといえば機械学習やディープラーニングのさまざまな手法や、注目の生成ＡＩを実現する大規模言語モデルが思い浮かぶでしょう。しかし、その礎となっているのはデータ分析の技術です。それは百年以上も前から自然・社会・人文科学の進歩を支えてきた古典的（頻度論的）統計学であり、かつては異端扱いされながらもビッグデータ時代の訪れとともに蘇ったベイズ統計学です。最新のデータサイエンスを学ぶためには、まず統計学の基礎をしっかり押さえておきましょう。",
      "target_audience": [
        "学業や業務でデータ分析を必要としている方、将来データアナリストを目指す方、データサイエンスに興味のある方であればどなたでも。 データ分析の初心者から学び直しの中級者。"
      ]
    },
    {
      "title": "Python ile Yapay Zeka ve Machine Learning Algoritmaları",
      "url": "https://www.udemy.com/course/python-ile-yapay-zeka-ve-machine-learning-algoritmalar/",
      "bio": "(ÜCRETSİZ KOD AÇIKLAMADA) Makine Öğrenmesinde yatan matematiğiyle öğrenip Python'da uygulayın",
      "objectives": [
        "Yapay Zeka Algoritmalarının günlük hayatımızdaki yeri ve kullanım alanları",
        "Algoritmaların matematiksel ve mantıksal açıklamaları",
        "Python'da Fonksiyonel ve Scikit-Learn üzerinden bu algoritmalarının kullanımı",
        "Veri Madenciliği ve Makine Öğrenmesi uygulamaları"
      ],
      "course_content": {
        "Giriş": [
          "Kurs Öncesi Gereksinimler",
          "Kurs Tanıtımı",
          "Tüm Kurs Kaynakları (Kodlar ve .csv Dosyaları)",
          "Yapay Zeka Kullanım Alanları ve Alt Başlıkları",
          "Ekstra Öğrenim ve Pekiştirme için Kaynaklar"
        ],
        "Linear Regression": [
          "Linear Regression Teorik",
          "Optimizasyon Algoritması : Gradient Descent",
          "Linear Regression (Boya göre Kilo tahmini) Fonksiyonel Python Kodları",
          "Aşırı Öğrenme (OverFitting) Kavramı",
          "Linear Regression (Ev fiyat tahmini) Scikit-Learn Kodları",
          "Polynomial Regression, Regularization ve Kategorik Verilerin Manipülasyonu",
          "Bonus: Excel İle Linear Regresyon (Bira Talep tahmini) Ve Seasonality Kavramı",
          "Linear Regression Pekiştirme Soruları"
        ],
        "K-Nearest Neighbors (KNN)": [
          "KNN Teorik",
          "KNN (Bitkilerin Türünü Tahmin Etme) Python Fonksiyonel Kodları",
          "KNN (Diyabet Hastalığı Tahmini) Scikit-Learn Kodları Ve Cross-Validation Yöntemi",
          "KNN Pekiştirme Soruları"
        ],
        "Naive Bayes": [
          "Naive Bayes Teorik",
          "Naive Bayes (Boy Ve Kiloya Göre Cinsiyet Tahmini) Fonksiyonel Kodları",
          "Naive Bayes (E-Mail Spam Ayırma) Scikit-Learn Kodları Ve Confusion Matrix",
          "Naive Bayes Pekiştirme Soruları"
        ],
        "Logistic Regression": [
          "Logistic Regression Teorik",
          "Logistic Regression (Banka Kredi) Scikit-Learn",
          "Logistic Regression (Diyabet) Scikit-Learn ve Confusion Matrix",
          "Logistic Regression Pekiştirme Soruları"
        ],
        "Support Vector Machines": [
          "SVM Teorik",
          "SVM Scikit-Learn",
          "SVM Resim işleme ve El-Yazısı Tahmini",
          "SVM ve PCA ile Yüz Tanıma Algoritması",
          "SVM Pekiştirme Soruları"
        ],
        "Ağaç Bazlı Algoritmalar": [
          "Decision Trees Teorik",
          "Decision Trees (Beyzbolcu maaş tahmini) Scikit-Learn",
          "Ensemble Methods Teorik",
          "Random Forests (İnsan Kaynakları Örneği) Parameter Tuning (Grid Search)",
          "Data Leakage, Pipeline Method, Algorithm Tuning (GridSearch)",
          "Tree-Based Algorithms Pekiştirme Soruları"
        ],
        "Unsupervised Learning Algoritmaları": [
          "Unsupervised Learning Tanıtım ve K-Means Clustering Teorik",
          "K-Means (Müşteri Segmentasyonu) Fonksiyonel Python kodları",
          "K-Means (Müşteri Segmentasyonu) Scikit-Learn",
          "Hierarchical Clustering Ve DBSCAN Teorik",
          "Hierarchical Clustering (Covid-19'dan etkilenen Ülkeler) ve DBSCAN Scikit-Learn",
          "Principal Component Analysis (PCA) Teorik",
          "PCA Scikit-Learn",
          "Unsupervised Learning Algoritmaları Pekiştirme Soruları"
        ]
      },
      "requirements": [
        "Giriş seviyesinde Python (Temel Syntax, if else, değişken oluşturma vb.)",
        "Lise düzeyi Matematik",
        "Giriş seviyesinde Olasılık ve İstatistik",
        "İngilizce"
      ],
      "description": "KURSTAN ÜCRETSİZ YARARLANMAK İÇİN: Kursu isteyen herkese ücretsiz vermek istiyorum ancak 2 saatten uzun bir kurs olduğu için Udemy'ye ücretsiz koyamıyorum. Süresiz ücretsiz kod oluşturamadığım için kahraman2639 kullanıcı adım ile LinkedIn üzerinden ulaşan herkese en kısa sürede dönüş yapıp güncel ücretsiz kodunu vereceğim.\nGünlük hayatımızda oldukça büyük bir yere sahip birçok Makine Öğrenmesi Algoritmalarını basit bir dilde, aşamalı şekilde anlattığım kursumda birçok farklı alandan örnekler ile hem yazılım geliştirme, hem veri bilimi, hem de yapay zeka alanlarında kendinizi geliştirebilirsiniz.\nKurstaki her bir bölümde farklı bir Makine öğrenmesi algoritmasını, öncelikle teorik olarak daha sonra fonksiyonel ve Python’un scikit-learn kütüphanesi üzerinden anlatacağım. Makine öğrenmesini tam olarak öğrenmek için sadece temel algoritmaları değil, veri bilimiyle ilgili birçok farklı kavramı, anomalileri ve doğrulama yöntemlerini de yaklaşık 7 saatlik kursun bütününe yayarak kademeli şekilde açıklayacağım.\nKursun ilk bölümünde Linear Regresyon algoritmasını “Boy-Kilo tahmini” , “Ev Fiyat tahmini” ve “Talep tahmini” gibi basit linear regresyon uygulamalarını yapacak ve Makine öğrenmesinin en temel kavramlarından bahsedeceğim.\nİkinci bölümde bir başka popüler algoritma olan K-Nearest Neighbors algortimasında Biyolojik farklı bitki türlerini, özelliklerine göre sınıflandıracak sonrasında da bazı Kan değerleri verilen hastaların diyabet hastası olup olmadığını tahmin edecek bir algortima geliştireceğiz.\nSonraki bölümümüz Naïve Bayes’te matematiğin olasılık konusunda bilgilerimizi tazeleyecek daha sonrasında E-Mail kutumuzdaki Spamları önceden tespit edip bizler için ayırabilecek bir algoritma geliştireceğiz.\nDördüncü algoritmamız Logistic Regresyon ile Belirli banka müşterilerine risk analizi yapıp kredi verilip verilmemesi gerektiğine karar verebilecek bir sınıflandırma algortimasını anlatacağım\nEn çok ilgi çekebileceğini düşündüğüm beşinci bölümümüzde Support Vector Machine ile El yazısıyla yazılmış numaraları birbirinden ayırabilen bir algoritma, sonrasında da telefonlarımızdan da bildiğimiz bir yüz tanıma algoritması geliştireceğiz.\nSonraki Bölümde, içerisinde birçok alt konu başlığı içeren Ağaç Bazlı Algoritmalara göz atacağız. Bu bölümde Beyzbol oyuncularının kazandıkları maaşları tahmin edecek sonrasında İnsan kaynakları departmanı için bir işe alım algoritması yazacağız. Bu bölümde, diğer öğrendiğimiz algoritmaları karşılaştıracak ve kendi projemiz için en uygun parametreleri ve algoritmaları bulma yöntemlerini öğreneceğiz.\nSon Bölüm olan Gözetimsiz Öğrenme Algoritmalarında birkaç farklı kümeleme algoritmasını kullanarak Reklam ajansları için Müşteri segmentasyonu yapacak, sonrasında COVID-19 pandemisinde birbirlerine çok benzer etkiler gösteren ülkeleri birbiriyle eşleştireceğiz.\nTüm Bölümlerin sonunda öğrendiğiniz algoritmaları pekiştirebileceğiniz güzel mülakat ve sınav sorularını çözebilecek ve eksiğiniz varsa ayrıntılı çözümlerimi bulabileceksiniz. Yazdığım tüm kodları sizler ile paylaşacağım. Kursu tamamladıktan sonra Yapay Zeka, Veri bilimi ve Makine Öğrenmesi gibi alanlarda oldukça fazla bilgiye ve fikre sahip olacağınıza emin olabilirsiniz. Tabi ki yanlış anlattığımı ya da yeterince iyi anlatamadığımı düşündüğünüz yerlerde her zaman yorumlar aracılığıyla görüşlerinizi veya sorularınızı paylaşabilir, tatmin olmazsanız Udemy’nin iade politikasıyla kursu 30 gün içerisinde gönül rahatlığıyla iade edebilirsiniz. Bu kısa ama dolu kursumuza başlamadan önce hepinize başarılar diliyorum.",
      "target_audience": [
        "Veri bilimine ve yapay zekaya meraklı, başlangıç düzeyindeki Python Geliştiricileri"
      ]
    },
    {
      "title": "Mineração e Análise de Dados do Facebook",
      "url": "https://www.udemy.com/course/mineracao-e-analise-de-dados-do-facebook-com-python/",
      "bio": "Utilize Python e técnicas de Ciência de Dados e Inteligência Artificial para extrair e analisar sua página do Facebook!",
      "objectives": [
        "Extrair dados da sua página do Facebook utilizando a Graph API",
        "Extrair e analisar informações como: dados básicos da página, visualizações, cliques, engajamento, impressões e posts",
        "Aplicar técnicas de processamento de linguagem natural para analisar seus posts no Facebook",
        "Utilizar análise de sentimentos para analisar positividade e negatividade nos comentários feitos pelos usuários",
        "Agrupar os fãs da página por idioma, cidade, país, idade e gênero",
        "Imprimir vários tipos de gráficos para analisar as informações da página do Facebook",
        "Encontrar relações entre as curtidas e descurtidas da página",
        "Visualizar as ações positivas e negativas dos usuários",
        "Comparar a distribuição de conteúdo pago, orgânico e viral",
        "Utilizar séries temporais para prever o número futuro de fãs da página com o algoritmo ARIMA",
        "Utilizar a ferramenta Facebook Prophet para prever o engajamento futuro da página",
        "Extrair e analisar o texto dos posts e o texto dos comentários feitos pelos fãs da página"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Recursos para download",
          "Mais sobre Análise de Dados"
        ],
        "Extração de dados básicos da página": [
          "Introdução",
          "Criação de APP no Facebook",
          "Exploração da Graph API",
          "Obtenção de token temporário",
          "Obtenção de token permanente",
          "Dados básicos da página",
          "Número de fãs por data",
          "Fãs por idioma",
          "Fãs por cidade",
          "Fãs por país",
          "Fãs por idade e gênero",
          "Relação entre curtidas e descurtidas",
          "Motivos das descurtidas"
        ],
        "Visualizações, cliques, engajamento e impressões": [
          "Introdução",
          "Visualização de abas",
          "Cliques nas informações de contato",
          "Cliques em como chegar",
          "Engajamento na página - cliques",
          "Engajamento por tipo",
          "Check-in na página",
          "Ações positivas por tipo",
          "Ações negativas por tipo",
          "Visualizações por hora do dia",
          "Curtidas pagas e não pagas",
          "Impressões pagas, orgânicas e virais",
          "Série temporal - ARIMA",
          "Decomposição da série temporal",
          "Previsões de dados futuros",
          "Avaliação da série temporal",
          "Gráfico das previsões",
          "Série temporal com Facebook Prophet 1",
          "Série temporal com Facebook Prophet 2"
        ],
        "Análise dos posts": [
          "Introdução",
          "Reações nos posts",
          "Reprodução de vídeos",
          "Stories por tipo",
          "Extração dos textos dos posts",
          "Pré-processamento dos textos",
          "Nuvem de palavras",
          "Pesquisa nos posts",
          "Agrupamento dos posts por data",
          "Extração dos comentários dos posts",
          "Pré-processamento dos comentários",
          "Análise de sentimento nos comentários"
        ],
        "ANEXO: Classificador de sentimentos com textos do Twitter": [
          "Bibliotecas e base de dados",
          "Pré-processamento dos textos 1",
          "Pré-processamento dos textos 2",
          "Pré-processamento da base de dados",
          "Tratamento da classe",
          "Construção do classificador e treinamento",
          "Testes com frases",
          "Avaliação do algoritmo"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e estrutura de repetição",
        "Programação básica utilizando a linguagem Python",
        "Não são necessários conhecimentos sobre o LinkedIn"
      ],
      "description": "O Facebook é uma das redes sociais mais populares do mundo, que permite que você converse com amigos, compartilhe mensagens, links, fotos e vídeos. Além dos perfis pessoais, é possível que as empresas criem páginas de negócios para divulgação e venda de produtos e serviços, as quais são utilizadas exclusivamente para fins comerciais. Os usuários (ou fãs) podem curtir e seguir as páginas e receber atualizações sobre a empresa, sendo também possível a criação de anúncios para divulgar a empresa.\nDentro deste contexto, é importante que as empresas saibam como utilizar os dados dessa rede social a seu favor. Para isso, o próprio Facebook disponibiliza uma API (chamada de Graph API) para a extração de várias informações relevantes sobre a sua página, sendo possível aplicar técnicas de Ciência e Análise de Dados para extrair insights importantes e interessantes sobre diversas métricas, como engajamento, visualizações, distribuições de conteúdo, dentre várias outras! Abaixo você pode observar os principais tópicos que serão implementados passo a passo:\nExtrair dados da sua página do Facebook utilizando a Graph API\nExtrair e analisar informações como: dados básicos da página, visualizações, cliques, engajamento, impressões e posts\nAgrupar os fãs da página por idioma, cidade, país, idade e gênero\nEncontrar relações entre o número de curtidas e descurtidas\nVisualizar informações importantes sobre o engajamento da página\nVisualizar as ações positivas e negativas dos fãs da página\nComparar as impressões de conteúdo pago, orgânico e viral\nUtilizar séries temporais com o algoritmo ARIMA para prever o número de novos futuros fãs\nUtilizar a ferramenta Facebook Prophet para prever o engajamento futuro da página\nExtrair as reações dos fãs ao posts da página, como por exemplo o número de likes\nExtrair os textos dos posts e aplicar técnicas de processamento de linguagem natural, como por exemplo, gerar nuvem de palavras com os termos mais frequentes e realizar buscas por palavras chave\nExtrair os textos dos comentários escritos pelos fãs da página com o objetivo de aplicar técnicas de mineração de sentimentos, para assim analisar se os textos são positivos ou negativos\nDurante o curso, vamos utilizar a linguagem de programação Python e também o Google Colab, ou seja, não é necessário gastar tempo instalando ou configurando ferramentas. Você conseguirá acompanhar o curso tendo um navegador simples e uma conexão com a Internet! Este é o curso ideal caso seja seu primeiro contato com análise de dados de redes sociais! Importante: o estudo de caso do curso será a página da IA Expert Academy, porém, é necessário que você possua uma página do Facebook ou então seja administrador de uma para conseguir executar os scripts passo a passo!",
      "target_audience": [
        "Qualquer pessoa interessada em análise de dados utilizando dados de redes sociais",
        "Pessoas interessadas na aplicação de técnicas de Inteligência Artificial e Ciência de Dados em dados extraídos de redes sociais",
        "Pessoas interessadas em extração de dados de redes sociais",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial, Ciência de Dados ou Análise de Dados",
        "Pessoas que queiram conhecer melhor informações de suas páginas do Facebook"
      ]
    },
    {
      "title": "Pentaho Data Integration - PDI",
      "url": "https://www.udemy.com/course/pentaho-data-integration-pdi/",
      "bio": "Aprenda a utilizar o PDI para facilitar integração de dados e criação de informações",
      "objectives": [
        "Você será capaz de extrair dados de bancos de dados diversos, planilhas excel ou libreoffice, arquivos csv e txt, e web server json.",
        "Será capaz de transformar os dados extraidos, alterando o tamanho e tipos, ajustes de caracteres, operações matemáticas em linha e em colunas, realizar Joins, Unions, usar código java e javascript no fluxo de dados.",
        "Também será possível criar saidas de planilhas, txt, csv, e tabelas em bancos de dados."
      ],
      "course_content": {
        "Introdução": [
          "INFORMATIVO DE ATUALIZAÇÃO DO CURSO",
          "I0101 Repositório do GitHub - Apresentação",
          "Caminho para o Repositório do GitHub",
          "I0102 - Infraestrutura Necessária",
          "I0103 - Instalação do OpenJDK8 no Windows",
          "I0104 - Instalação do PostgreSQL no Windows",
          "I0203 - Instalação do OpenJDK8 no Linux",
          "I0204 - Instalação do PostgreSQL no Linux",
          "I0105 - Instalação do PDI - Windows",
          "I0205 - Instalação do PDI - Linux Ubuntu",
          "I0106 - Introdução a Interface do Pentaho Data Integration",
          "I0107 - Drivers dos banco de Dados - onde colocar?"
        ],
        "Inputs - Entradas": [
          "A0101 - Microsoft Excel input",
          "A0102 - Text file input",
          "A0103 - Data grid",
          "A0104 - CSV file input",
          "A0105 - Table input",
          "A0106 - Generate rows"
        ],
        "Transform - Modificadores": [
          "B0101 - Select values",
          "B0102 - Add constants",
          "B0103 - Add sequence",
          "B0104 - Concat fields",
          "B0105 - Split fields",
          "B0106 - String operations",
          "B0107 - Sort rows",
          "B0108 - Unique rows",
          "B0109 - Calculator",
          "B0110 - Replace in string",
          "B0111 - Strings cut"
        ],
        "Flow - Fluxo": [
          "C0101 - Dummy (do nothing)",
          "C0102 - Append streams",
          "C0103 - Filter rows",
          "C0104 - Java filter",
          "C0105 - Switch / case"
        ],
        "Scripting - Usando Scripts SQL, JavaScript, e Java": [
          "D0101 - Execute SQL script",
          "D0102 - Modified javaScript value",
          "D0103 - User defined java class"
        ],
        "Consumindo Serviços WEB": [
          "E0101 - REST client - JSON",
          "E0102 - REST client - XML"
        ],
        "Joins - Lift, Right, Inner e Full": [
          "F0101 - Merge join"
        ],
        "Statistics - Funções de Agregação de valores": [
          "G0101 - Group by"
        ],
        "Output - Saídas": [
          "H0101 - Text file output",
          "H0102 - Microsoft Excel output",
          "H0103 - Table output",
          "H0104 - Insert update"
        ],
        "Jobs - Orquestação de uma sequência de transformações": [
          "J0101 - Utilizando Jobs"
        ]
      },
      "requirements": [
        "Conhecimento básico em SQL ou Uso de Planilhas eletrônicas."
      ],
      "description": "Temos como objetivo de no final do curso você ser capaz de instalar o PDI, extrair de diversas fontes de dados, realizar transformações e cruzamento de dados entre essas diversas fontes e gerar uma informação útil para você ou seu cliente em diversos formatos.\n\n\nOnde veremos:\nAs transformações e seus componentes que alteram o fluxo de dados, realizando ajustes, cruzamentos e operações matemáticas entre os campos;\nVeremos um resumo das principais fontes de dados;",
      "target_audience": [
        "Qualquer pessoa que quer usar uma ferramenta poderosa para tratamento de dados e livrar-se de planilhas e queries extensas.."
      ]
    },
    {
      "title": "Estadística inferencial en SPSS",
      "url": "https://www.udemy.com/course/estadistica-inferencial-en-spss/",
      "bio": "Aprenda los procedimientos para analizar e interpretar correlación, regresión, ji cuadrado, y ANOVA",
      "objectives": [
        "Produndización del conocimiento de SPSS",
        "Habilidad para evaluar si los resultados son estadísticamente significativos",
        "• Habilidad para reconocer y determinar las pruebas estadísticas apropiada según los datos que se disponga",
        "• Habilidad para comprender, calcular, e interpretar el tamaño de los efectos y los intervalos de confianza",
        "• Conocer cómo se escriben los resultados de los análisis estadísticos usando las normas APA"
      ],
      "course_content": {},
      "requirements": [
        "Haber participado de un curso introductoria en estadística",
        "Acceso al programa SPSS (muy recomendable)"
      ],
      "description": "En este curso el participante aprenderá a ejecutar diferentes pruebas estadísticas en SPSS, correlación, regresión, ji cuadrado, t test, ANOVA.\nCada clase ilustrará cómo analizar un prueba estadística en SPSS.\nEl curso focaliza de manera simple y precisa (paso a paso) la explicación de los resultados que se van obteniendo.\nFinalmente, en este curso usted perfeccionará sus capacidades relativas a cómo analizar un número importante de procedimientos estadísticos en SPSS; interpretar los resultados de las aplicación de diferentes pruebas estadísticas; y aprender a redactar los resultados usando el formato APA.",
      "target_audience": [
        "• Estudiantes que buscan ayuda en SPSS, especialmente sobre cómo analizar e interpretar los resultados de los análisis estadísticos",
        "• Profesionales que deseen aumentar sus capacidades estadísticas",
        "Cualquier persona que desees mejorar sus habilidades para analizar datos"
      ]
    },
    {
      "title": "360° Dijital Pazarlama & Web Scraping A-Z™",
      "url": "https://www.udemy.com/course/social-media-scraping-and-web-scraping-from-zero-to-hero/",
      "bio": "Web Scraping İle Sıfırdan Zirveye - Market Ve Pazar Araştırması Yaparak Satışlarınızı Arttırın!",
      "objectives": [
        "Web Scraping",
        "Social Media Scraping",
        "Basic Data Analysis",
        "Web Resarch",
        "Social Media Marketing",
        "Data Collection",
        "Instagram Marketing",
        "Twitter Marketing",
        "Social Media Analysis",
        "Linkedin Scraping"
      ],
      "course_content": {
        "Giriş": [
          "Eğitim içeriği,neler yapacağız ?",
          "Web Scraping nedir ?",
          "Web Scraping kullanım alanları nelerdir ?"
        ],
        "UiPath İle Web Scraping": [
          "Trivago Üzerinden En Uygun Otel Araştırması - UiPath",
          "Google Haberler Üzerinden Son Dakika Covid-19 Haberlerinin Araştırması - UiPath"
        ],
        "Power BI İle Web Scraping": [
          "Yorumbudur.com Üzerinden Ürün Yorumlarının Araştırması - Power BI",
          "Amazon Üzerinden Ürün Yorumlarının Araştırması - Power BI"
        ],
        "Google Chrome Extension İle Web Scraping": [
          "İstanbul'daki Araba Tamircilerinin Araştırması - Google Chrome Extensions",
          "Google Scholar Üzerinden Akademik Makale Araştırması - Google Chrome Extensions"
        ],
        "Python BeautifulSoup Kütüphanesi ile Web Scraping": [
          "Arabam.com Üzerinden Araba Fiyatları Pazar Araştırması - Python BeautifulSoup"
        ],
        "Instagram Web Scraping": [
          "İnstagram Üzerinden Veri Çekerek Hedef Kitlemize Nasıl Ulaşırız ? - Osintgram"
        ],
        "Twitter Web Scraping": [
          "Twitter'da Markanız Veya Rakipleriniz Hakkında Ne Konuşuluyor ? - Twint"
        ],
        "Market Araştırması İçin Google Trends Kullanımı": [
          "Google Trends Kullanımı Ve Market Araştırması"
        ],
        "Keyword Tool Kullanarak Web Sitesi Optimizasyonu": [
          "Keyword Tool Kullanımı Ve Web Sitesi Optimizasyonu"
        ],
        "Social Mention Kullanarak Sosyal Medya Ürün Araştırması": [
          "Social Mention Kullanımı Ve Sosyal Medya Ürün Araştırması"
        ]
      },
      "requirements": [
        "Temel bilgisayar kullanımı",
        "İnternet erişimi"
      ],
      "description": "Web Scraping bugünlerde en çok konuşulan konulardan biri haline geldi, piyasada her zaman bir tüketici olarak işlevleriyle sınırlı kalacağınız için işlerin nasıl yapıldığını size hiçbir şey göstermeyen birçok ücretli araç var.\nBu eğitim süresince hem kod yazarak hem kod yazmadan sizlere pazar-market,akademik araştırmalarınız için nasıl veri çekileceğini göstereceğim.\nPeki bu eğitim kapsamında hangi projeleri gerçekleştireceğiz ?\nTatil yapmayı planlayanlar için en uygun otel araştırılması\nÜrün almayı planlayanlar için yorumbudur sitesi üzerinden ürün yorumlarının araştırılması\nAkademiden asla kopamayanlara Google Scholar üzerinden literatürün araştırılması\nİnstagramda keşif ve takipçi analizi yapmak isteyenlere İnstagram üzerinden veri çekilmesi\nSon dakika Covid-19 haberlerinden haberdar olmak isteyenlere Google Haberler üzerinden Covid-19 haberlerinin araştırılması (ürün veya rakipleriniz ile ilgili güncel haberlerden haberdar olabilirsiniz ve rakiplerinizi analiz edebilirsiniz)\nİstanbul’da arabası bozulup yolda kalanlar için İstanbul’daki araba tamircilerinin Google Haritalar araştırılması (firma iletişim konum web sitesi vb. gibi iletişim bilgilerinin elde edilmesi)\nHangi marka ürün hangi fiyata gidiyor diye merak edenlere Pazar araştırılması\nMarkam hakkında ne konuşuluyor diye merak edenlere Twitter üzerinden veri çekilmesi\nUdemy ücretsiz eğitim kuponlarının Twitter kullanılarak araştırılması\nÜniversite tercihi yapacak adaylar için Youtube üzerinden “Bilgisayar Mühendisliği” bölümü araştırması\nDerin öğrenme modelleri için veri nasıl toplanılır diye merak edenlere Image Scraping\nLinkedin ağını büyütmek isteyenlere Linkedin Connection Scraping\nBu kursu diğerlerinden farklı kılan nedir ve neden kayıt olmalısınız?\nİlk olarak, bu en güncel kurstur. Python 3.7, UiPath,Power BI,Google Chrome Extension kullanacaksınız\nTürkçe kaynak eksikliği çok fazla.Türkçe kaynak eğitim arayanlar bu kurs tam size göre :)\nNasıl profesyonel bir web kazıyıcı olunacağına dair adım adım ayrıntılı bir kılavuza sahip olacaksınız.\n\n\nJavaScript web sitelerini sıyırmak için BeautifulSoup nasıl kullanacağınızı öğreneceksiniz ve sizi temin ederim ki, bu kursta yapacağım gibi Web Scraping işlemini gerçekten nasıl kullanacağınızı öğreten herhangi bir öğretici bulamazsınız.\nUdemy'den 30 gün para iade garantisi\nBu nedenle , araç setine web kazıma eklemek isteyen bir veri analisti veya yapılandırılmamış HTML web sayfalarından yapılandırılmamış verilerin nasıl çıkarılacağını öğrenmek isteyen bir başkası olun ve ardından bazı veri analizlerini uygulamak için bu verileri yapılandırılmış bir şekilde geri depolayın. o zaman bu kursa katılabilirsiniz.",
      "target_audience": [
        "Veri bilimine meraklı",
        "Sosyal medya (instagram,twitter,youtube) üzerinden veri çekmek isteyenler",
        "Web sitesi üzerinden veri çekmek isteyenler",
        "Pazar araştırması yapmak isteyenler",
        "Literatür araştırması yapmak isteyenler",
        "Veri analizini öğrenmek isteyenler",
        "Linkedin ağını büyütmek isteyenler"
      ]
    },
    {
      "title": "Statistics in R - R الإحصاء وتحليل البيانات باستخدام",
      "url": "https://www.udemy.com/course/statistics-in-r-r/",
      "bio": "Statistics in R",
      "objectives": [
        "R ستكون قادرا على التعامل مع البيانات وتحليلها وتمثيلها وتنفيذ الاختبارات الإحصائية بكل سهولة في",
        "R ستتعلم أساسيات الإحصاء وتطبيقها عمليا في",
        "بإذن الله بنهاية هذا الكورس ستكتسب مهارة جديدة تمكّنك من العمل الحر"
      ],
      "course_content": {
        "Taste of R - R مدخل إلى": [
          "Introduction المقدمة",
          "Why R, instal R, R Studio, R interface واجهة البرنامج"
        ],
        "Basic Commands in R - الأوامر الأساسية": [
          "Basic Commands 1 - 2 الأوامر الأساسية",
          "Basic Commands 2 - الأوامر الأساسية 2"
        ],
        "Data and Matrices - البيانات والمصفوفات": [
          "Functions to build a data frame - الوظائف والأكواد لبناء بيانات",
          "Data Manipulation - استكشاف وتغيير البيانات",
          "الأسئلة - الجزء الأول"
        ],
        "Descriptive Statistics & Plots - الإحصاء الوصفي والرسوم البيانية": [
          "Descriptive Statistics - الإحصاء الوصفي",
          "Plots - الرسوم البيانية والجداول"
        ],
        "Inferential Statistics 1 - 2 الإحصاء الاستدلالي \\الاستنباطي": [
          "Theory - الجزء النظري",
          "T-Test and ANOVA",
          "Chi-Square, Correlation, OR, RR"
        ],
        "Inferential Statistics 2 - 2 الإحصاء الاستدلالي \\الاستنباطي": [
          "Regression Theory - الجزء النظري",
          "Linear Regression [Simple and Multiple]",
          "Logistic Regression [Simple and Multiple]",
          "Other Forms of Regression [Cox, Multinomial, Polynomial]",
          "الأسئلة - الجزء الثاني"
        ],
        "R Hackathon - السباق البرمجي الإحصائي": [
          "Mix and Tricks - R اختصارات وحيل في",
          "R Hackathon - السباق البرمجي الإحصائي"
        ],
        "Bonus - Dplyr": [
          "Dplyr"
        ]
      },
      "requirements": [
        "هذا الكورس لا يحتاج معرفة سابقة وسنبدأ من الصفر"
      ],
      "description": "* يهدف هذا الكورس لإثراء المحتوى العربي فيما يتعلق بالإحصاء واستخدام R\n* سنبدأ من الصفر وسنتعلم الأوامر البرمجية والإحصاء من الألف إلي الياء\n* سيكون الكورس باللغة العربية\n* اعتمدت التكرار والمراجعة لإيصال المعلومة بكل سهولة\n* الكورس مقسم لسبعة أقسام: المقدمة, الأساسيات, بناء البيانات وتجهيزها, الإحصاء الوصفي, الرسوم البيانية, الإحصاء الاستنباطي 1, الإحصاء الاستنباطي 2 وأخيرا السباق البرمجي الإحصائي",
      "target_audience": [
        "هذا الكورس موجه للطلاب والباحثين والأكاديميين والعاملين في المجال الصحي"
      ]
    },
    {
      "title": "R Programming: Análisis avanzado para Data Science",
      "url": "https://www.udemy.com/course/analisis-de-datos-con-r-programming/",
      "bio": "Regresión lineal, series de tiempo, gráficos avanzados y mucho más.",
      "objectives": [
        "Dataframes y limpieza de datos.",
        "Gráficos avanzados.",
        "Regresión Lineal múltiple.",
        "Series de tiempo."
      ],
      "course_content": {
        "Introducción": [
          "Bienvenido a DataBoosters",
          "Presentación del curso",
          "Revisión del temario del curso",
          "¿Qué es el análisis de datos?",
          "Consideraciones importantes",
          "Rstudio no es R",
          "Archivos descargables"
        ],
        "Dataframes y limpieza de datos": [
          "Repaso DataFrames",
          "Accediendo a datos (Attach)",
          "Añadir/Quitar columnas y filas pt1",
          "Añadir/Quitar columnas y filas pt2",
          "Ordenando DataFrames",
          "Filtrando DataFrames"
        ],
        "Limpieza de datos": [
          "Librerías Necesarias",
          "Uniendo Bases de datos",
          "dplyr Select y Filter",
          "dplyr Mutate",
          "dplyr Arrange y operador %>%",
          "tidyr_gather",
          "tidyr_spread_separate_unite"
        ],
        "Gráficos avanzados": [
          "Introducción a ggplot2",
          "Añadir capas a un grafico",
          "Transformaciones estadísticas",
          "Gráficos condicionales y personalización",
          "Gráficos de líneas",
          "Gráficos de barras",
          "Histogramas",
          "Gráficos de cajas y bigotes",
          "Consideraciones finales al graficar"
        ],
        "Regresión Lineal múltiple": [
          "Introducción Regresión multilíneal",
          "Matriz de Correlación pt1",
          "Matriz de Correlacion pt2",
          "Modelo multilineal",
          "Modelos exponenciales"
        ],
        "Series de tiempo": [
          "Manejo de fechas",
          "Introducción a series de tiempo",
          "Procesando datos - serie de tiempo pt1",
          "Procesando datos - serie de tiempo pt2",
          "Modelo predictivo - serie de tiempo"
        ],
        "Termino del curso": [
          "Cuestionario final",
          "Clase extra"
        ]
      },
      "requirements": [
        "Conocimientos básicos en el lenguaje de programación R."
      ],
      "description": "¿Qué es R? ¿Qué es RStudio?\nEl término R se usa para referirse tanto al lenguaje de programación como al software que interpreta los scripts escritos con él.\nRStudio es actualmente una forma muy popular no solo de escribir sus scripts R sino también de interactuar con el software R. Para funcionar correctamente, RStudio necesita R y, por lo tanto, ambos deben estar instalados en su computadora.\n\n\n¿Por qué aprender R?\nLa curva de aprendizaje puede ser más pronunciada que con otro software, pero con R, los resultados de su análisis no se basan en recordar una sucesión de señalar y hacer clic, sino en una serie de comandos escritos, ¡y eso es algo bueno! Por lo tanto, si desea rehacer su análisis porque recopiló más datos, no tiene que recordar en qué botón hizo clic y en qué orden para obtener los resultados, solo tiene que ejecutar su secuencia de comandos nuevamente.\n\nTrabajar con scripts hace que los pasos que usó en su análisis sean claros, y el código que escribe puede ser inspeccionado por otra persona que puede brindarle comentarios y detectar errores.\n\n\nTrabajar con guiones te obliga a tener una comprensión más profunda de lo que estás haciendo y facilita tu aprendizaje y comprensión de los métodos que utilizas.\n\n\nR se integra con otras herramientas para generar manuscritos a partir de su código. Si recopila más datos o corrige un error en su conjunto de datos, las cifras y las pruebas estadísticas en su manuscrito se actualizan automáticamente.\n\n\nCon más de 10 000 paquetes que se pueden instalar para ampliar sus capacidades, R proporciona un marco que le permite combinar enfoques estadísticos de muchas disciplinas científicas para adaptarse mejor al marco analítico que necesita para analizar sus datos. Por ejemplo, R tiene paquetes para análisis de imágenes, GIS, series temporales, genética de poblaciones y mucho más.",
      "target_audience": [
        "Estudiantes que deseen aprender un software estadístico.",
        "Profesionistas que se dedican al análisis de datos."
      ]
    },
    {
      "title": "Reti Neurali Demistificate",
      "url": "https://www.udemy.com/course/reti-neurali-demistificate/",
      "bio": "Capire la matematica dei principali algoritmi di Deep Learning",
      "objectives": [
        "Concetto di Deep Learning e Reti Neurali",
        "Struttura base di una Rete Neurale",
        "Concetti matematici e statistici alla base di reti neurali",
        "Strategie di ottimizzazione"
      ],
      "course_content": {
        "Introduzione al Deep Learning": [
          "Come collocare Intelligenza Artificiale, il Machine Learning e il Deep Learning",
          "Cos'è il Deep Learning"
        ],
        "Reti Neurali": [
          "Cosa sono e come sono fatte le reti neurali",
          "A cosa servono le reti neurali",
          "Perché le reti neurali consentono un apprendimento profondo"
        ],
        "Come costruire una rete neurale da zero": [
          "Capire la matematica di una rete neurale",
          "Metodo di discesa del gradiente",
          "Backpropagation",
          "Parametri, iperparametri e strategie di ottimizzazione"
        ],
        "Conclusioni e riflessioni": [
          "Ricapitolando"
        ]
      },
      "requirements": [
        "Buona conoscenza di algebra lineare",
        "Buona conoscenza di concetti base di derivazione e ottimizzazione"
      ],
      "description": "In questo corso parleremo dei principali algoritmi di Deep Learning: le reti neurali. In particolare, analizzeremo la struttura di una rete neurale, il suo funzionamento e la matematica che c'è dietro. La struttura del corso prevede:\nUn introduzione al concetto di Deep Learning\nDescrizione delle Reti Neurali, delle loro applicazioni e delle loro caratteristiche\nCostruzione da zero di una Rete Neurale utilizzando dati reali\nStrategie di ottimizzazione dell'algoritmo\nDescrizione di alcuni elementi tipici delle Reti Neurali\nL'idea è quella di fissare i concetti chiave delle Reti Neurali, in modo da applicarli alle diverse tipologie di questa famiglia di algoritmi.",
      "target_audience": [
        "Studenti universitari di materie scientifiche",
        "Appassionati di Data Science e Machine Learning"
      ]
    },
    {
      "title": "Machine Learning in R: Curso Completo de Regressão Linear",
      "url": "https://www.udemy.com/course/regressaolinearnor/",
      "bio": "Domine o Modelo Preditivo mais usado nas empresas e pesquisas",
      "objectives": [
        "Entender de uma vez por todas o que é Regressão Linear",
        "Entender de uma vez por todas para que serve Regressão Linear",
        "Como preparar os dados antes de aplicar a Regressão Linear",
        "Interpretar os resultados de uma Regressão Linear",
        "Realizar o estudo da acurácia do modelo gerado",
        "Estudar os resíduos do modelo",
        "Aprender a modelar situações reais"
      ],
      "course_content": {
        "Introdução": [
          "Seja muito bem vindo(a)!",
          "Começando a conversa",
          "Introdução",
          "Algoritmos de Previsão",
          "Regressão Linear",
          "Regressão Linear - O que é e para que serve?",
          "Tipos de Regressão Linear",
          "Questões sobre a Primeira Seção"
        ],
        "Preparando os Dados": [
          "Preparação dos Dados para a Regressão Linear - parte 1",
          "Preparação dos Dados para a Regressão Linear - parte 2",
          "Preparação dos Dados para a Regressão Linear - parte 3",
          "Preparação dos Dados para a Regressão Linear - parte 4",
          "Ponto Decisivo",
          "Exercícios sobre a Seção 2"
        ],
        "Estudando as Correlações": [
          "COMUNICADO",
          "Estudando as Correlações",
          "Alternativas para Correlações - parte 1",
          "Alternativas para Correlações - parte 2",
          "Alternativas para Correlações - parte 3",
          "Alternativas para Correlações - parte 4",
          "Alternativas para Correlações - parte 5",
          "Alternativas para Correlações - parte 6"
        ],
        "Gerando o Modelo de Regressão": [
          "O Método dos Mínimos Quadrados",
          "Obtendo o modelo inicial",
          "Análise de Variância do Modelo",
          "Testes Individuais para os Parâmetros",
          "Interpretação dos Coeficientes",
          "Observação: Quando uma das variáveis independentes é uma variável dummy",
          "Grau de Importância das Variáveis",
          "Intervalos de Confiança",
          "Verificando a Bondade de Ajuste do Modelo",
          "Comparando modelos"
        ],
        "Estudando os Outliers, Pontos influentes e pontos de alavanca": [
          "Outliers - parte 1",
          "Outliers - parte 2",
          "Outliers - parte 3",
          "Pontos Influentes - Intro",
          "Distância de Cook",
          "DFBETA (parte 1)",
          "DBBETA (parte 2)",
          "DFBETA (parte 3)",
          "DFBETA (parte 4)",
          "DFFIT - parte 1",
          "DFFIT - parte 2",
          "Alavancagem",
          "CVR",
          "Casos Influentes - Resumo",
          "Natureza das variáveis",
          "Pacote necessário",
          "Suposição de Multicolinearidade",
          "Minha opinião pessoal"
        ],
        "Verificando as Suposições teóricas do Modelo de Regressão Linear": [
          "Homocedasticidade",
          "Resíduos Normais",
          "Observação Importante (Test Durbin Watson)",
          "Suposição de Resíduos Aleatórios",
          "Suposição de Independência",
          "Suposição de Linearidade",
          "Se as suposições são violadas",
          "Usando o modelo"
        ],
        "Projeto": [
          "Explicando o Projeto",
          "Observação sobre o Projeto",
          "Solução para o Projeto"
        ],
        "Aula Bônus": [
          "Aula Bônus",
          "Trilha de Aprendizado para a carreira em Data Science"
        ]
      },
      "requirements": [
        "Seria bom fazer antes os meus cursos: Linguagem R do zero e Introdução à Estatística"
      ],
      "description": "Por que fazer este curso nos próximos 30 dias?\nAprender sobre Algoritmos de Machine Learning tem sido essencial para quem deseja ter seu espaço nas grandes empresas, pois são eles fazem com que computadores tomem decisões baseadas em algoritmos, encontrando informações interessantes em meio a uma grande quantidade de dados.\nHoje, cada vez mais ocorre um aumento na quantidade de dados e conforme são os algoritmos são alimentados com mais dados, aprendem a reconhecer padrões e fornecer insights relevantes para as organizações.\nMas como o programa reconhece esses padrões?\nPara tentarem descobrir padrões ou prever resultados, as ferramentas de aprendizagem de máquina tentam descobrir equações (modelos matemáticos) que ajudem a extrair algum significado de um conjunto de dados. É por isso que o termo “modelagem” é tão recorrente em textos e discussões sobre machine learning.\nPortando, este curso visa APROFUNDAR o estudo do zero ao avançado nos modelos de Regressão Linear, considerado o mais usado na busca por padrões.\n\n\nQue tipo de resultado eu tenho com esta técnica?\nSaber quais variáveis interferem no comportamento de uma variável específica. ex: O que interfere na quantidade de novos clientes? Investimento com publicidade? Diversidade de produtos?\n\n\nPrevisão de variável numérica com base em outras. Ex: prever o faturamento com base no investimento com publicidade, horas extras, quantidade de funcionários, e etc.\n\n\nConstruir uma equação matemática que descreva o mundo real. Ex. com base em informações de um produto, pode-se calcular o valor mais provável de unidades a serem vendidas (demanda).\nNão é por acaso que este tema será tratado com cada vez mais frequência nas empresas que desejam crescer ainda mais, e por que você vai ficar de fora?\n\n\nPara quem serve este curso?\nProfissionais de TI e de áreas associadas, interessados em se aprofundar em Estatística e aplicá-la no mundo empresarial.\nEstudantes de graduação, mestrado e doutorado precisando aprender estatística para provas universitárias ou para pesquisas científicas.\n\"Concurseiros\" interessados em \"matar\" a prova de Estatística.\n\n\nSobre o Professor\nMeu nome é Isaías Lira, bacharel em Estatística, Consultor em Análise Estatística de Dados, pesquisador e estudioso da área de Estatística Aplicada no Mercado Financeiro, escritor de livro em Estatística, Data Scientist, Pos-graduado em Docência Superior e este curso é um importante dentro de minha lista de cursos.\n\n\nQual o diferencial deste curso?\nCurso 100% pratico\nUsaremos dados reais\nTudo mostrado passo a passo\nAprofundamento na ferramenta de análise de dados mais respeitada no mercado: o R.\nEstrutura: o curso esta cuidadosamente estruturado para que em cada aula você tenha a clareza de cada assunto abordado\nAbordagem simplificada: focamos naquilo que é mais importante, numa linguagem simples, direta, com vários exemplo reais.\n\n\nInicie agora e conclua quando bem desejar! Sem pressão! Respeitaremos o seu próprio ritmo e estaremos aqui para tirar suas dúvidas.\nO mercado profissional precisa de você, então aprenda isto e seja útil para as grandes empresas.\nEntão, se você quer aprender sobre Regressão Linear, seja você quem for, este é o caminho mais fácil que conheço!\nVamos iniciar?",
      "target_audience": [
        "Leigos interessados em explicar eventos do mundo real a partir de fórmulas matemáticas simples",
        "Estudantes, Profissionais de TI ou qualquer pessoa interessada em Aprender e Aplicar Regressão Linear na prática"
      ]
    },
    {
      "title": "Aplikasi Data Science Dengan Mudah Menggunakan Python",
      "url": "https://www.udemy.com/course/aplikasi-data-science-dengan-mudah-menggunakan-python/",
      "bio": "Dasar Coding, Data Wrangling, Data Missing, Data Visualization, Menentukan Best Customer dengan Python",
      "objectives": [
        "Mampu Mengaplikasikan Dasar Coding Pada Python",
        "Mampu Memahami Data Wrangling (Data Preparation) Dengan Python",
        "Mampu Mengatasi Data Missing",
        "Mampu Membuat Data Visualization dengan Python",
        "Menerapkan Data Science Untuk Menentukan Best Costumer dengan Metode RFM"
      ],
      "course_content": {
        "PENDAHULUAN": [
          "Apa Yang Akan Anda Dapat Dari Kursus Ini?",
          "Apa Yang Dimaksud Dengan Data Science?",
          "Mengenal Python",
          "Instalasi Python",
          "Menggunakan Anaconda Navigator",
          "Mengenal Jupyter Notebook"
        ],
        "DASAR CODING PADA PYTHON": [
          "Code Hello World",
          "Penulisan Syntax Pada Python",
          "Comment Pada Python",
          "Variabel dan Tipe Data",
          "Print Tipe Data",
          "Kuis 1 Dasar Coding Pada Python"
        ],
        "LIST OPERATION": [
          "List Function",
          "String As List",
          "Tuples",
          "Dictionaries",
          "Kuis 2 Dictionaries"
        ],
        "OPERASI MATEMATIKA": [
          "Operasi Matematika Dasar",
          "Mengenal Operator Modulus",
          "Kuis 3 Operasi Matematika"
        ],
        "FUNGSI IF PADA PYTHON": [
          "Empat Jenis IF Statement",
          "IF Statement",
          "IF...ELSE",
          "IF ELIF ELSE",
          "Nested IF",
          "IF dengan Input Number",
          "Kuis 4 IF pada Python"
        ],
        "LOOPING PADA PYTHON": [
          "Mengenal Istilah Looping dan Penggunaan WHILE",
          "Penggunaan FOR",
          "Penggunaan FOR dengan ACCES ELEMENT",
          "Kuis 5 Looping Pada Python"
        ],
        "MENGENAL FUNGSI": [
          "Mengenal Fungsi Pada Bahasa Pemrogaman Python",
          "Fungsi Dengan Parameter",
          "Penggunaan Return Value",
          "Kuis 6 Mengenal Fungsi"
        ],
        "IMPORT PACKAGE DAN MEMANGGIL MODUL PADA PYTHON": [
          "Import Package",
          "Import dengan Modul Rename",
          "Import Sebagian Fungsi dan Semua Isi Modulus"
        ],
        "DATA WRANGLING DENGAN PYTHON": [
          "Apa Yang Dimaksud dengan Data Wrangling?",
          "Membuat dan Membaca File CSV",
          "Melakukan Akses Data Kolom dan Baris",
          "Menampilkan Data dalam Range Tertentu",
          "Menampilkan Informasi Statistik"
        ],
        "MEMERIKSA DATA MISSING": [
          "Apa Yang Dimaksud Dengan Data Missing?",
          "Pengecekan Nilai Null",
          "Menghapus Nilai Null",
          "Mengisi Data Missing dengan Nilai Mean",
          "Mengisi Data Missing dengan Nilai Median"
        ]
      },
      "requirements": [
        "Memiliki PC yang bisa diinstal Anaconda Navigator"
      ],
      "description": "Profesi Data Scientist harus memiliki pemahaman yang luas meliputi ilmu statistik, programming, scripting, dan ilmu yang memahami tentang perilaku bisnis. Data scientist memiliki tugas untuk melakukan pencarian dan penggabungan data beserta analisisnya. Tugas-tugas tersebut sangat sulit dilakukan jika tidak memiliki kemampuan statistik yang bagus. Selain itu data scientist harus dapat melakukan programming untuk mengolah data tersebut ke dalam komputer. Data scientist juga perlu memiliki keahlian soft skill dalam menyampaikan suatu hasil analisa dengan jelas dan tepat.\nProspek karir dari data scientist pun dapat dikatakan menjanjikan untuk kedepannya. Dengan melihat kemajuan teknologi yang terus berkembang di setiap tahunnya, kebutuhan data scientist tentunya juga akan meningkat. Diperkirakan untuk 10 tahun kedepan banyak lowongan data scientist yang akan dibuka oleh perusahaan-perusahaan yang terjun di bidang teknologi informasi.\nSalah satu programming language yang banyak digunakan seorang Data Scientist adalah Python. Python memang tengah naik daun di Indonesia. Bukan hanya perusahaan, kalangan akademisi juga mengandalkan Python untuk merampungkan penelitian mereka dalam berbagai bidang. Misalnya robotika, data science, ekonomi, dan komputasi sains.\nPython adalah bahasa pemrograman interpretatif yang bisa dipasang pada berbagai platform, khususnya platform yang berfokus pada keterbacaan kode. Data science, internet of things (IoT), dan machine learning merupakan beberapa hal yang berkaitan langsung dengan Python. Para programmer biasa menggunakan Python untuk membuat prototype, scripting guna mengelola infrastruktur, maupun pembuatan website dalam skala besar.\nKursus Aplikasi Data Science Dengan Mudah Menggunakan Python ini didesain untuk pemula, bahkan untuk Anda yang belum pernah sama sekali mengenal Python sekalipun. Mulai dari awal Instalasi hingga aplikasi untuk menyelesaikan permasalahan yang memerlukan problem Solving.  Beberapa Hal Yang Akan dibahas antara lain:\nApa itu Data Science\nMengenal Python dan Tahapan Instalasinya\nDasar Coding Pada Python\nList Operation\nOperasi Matematika\nFungsi IF pada Python\nLooping Pada Python\nMengenal Fungsi\nImport Package dan Module\nData Wrangling\nData Missing\nVisualisasi Data dengan Python\nAplikasi Data Science : Menentukan Best Costumer dengan Metode RFM (Recency Frequency Monetary)",
      "target_audience": [
        "Pengembang Python Pemula yang ingin tahu Ilmu Data (Data Science)",
        "Mahasiswa yang ingin menyelesaikan suatu Project / Tugas Akhir",
        "Peserta umum yang ingin Memiliki Kompetensi menjadi Data Scientist"
      ]
    },
    {
      "title": "Aprende Ciencia de datos desde cero con Python",
      "url": "https://www.udemy.com/course/aprende-ciencia-de-datos-con-python/",
      "bio": "Visualización y Manipulación de datos. Aprende a Manejar Pandas , Numpy y Matplotlib. Conceptos básicos en Estadística",
      "objectives": [
        "Aprender a programar en Python",
        "Librerías mas Empledas en Ciencia de Datos",
        "Aprender el Análisis de los Datos y como se puede extraer valor de los mismos",
        "Conceptos Estadísticos básicos usados en Ciencia de datos",
        "Visualización de datos con Matplotlib y Seaborn.",
        "Resolución de Problemas Prácticos"
      ],
      "course_content": {
        "Introducción a la Ciencia de datos": [
          "Introducción",
          "Google Colab",
          "Instalación de Anaconda",
          "Análisis Exploratorio de los datos"
        ],
        "Programación Básica en Python": [
          "Variables",
          "Condicionales",
          "Operaciones con Strings",
          "Bucles",
          "Funciones",
          "Funciones Recursivas",
          "Funciones Lambda",
          "Clases",
          "Uso de Try y Except",
          "Lectura y Escritura de Archivos en Python",
          "EJERCICIOS"
        ],
        "Estructuras de datos en Python": [
          "Listas en Python",
          "Introducción a los Vectores en Python",
          "Vectores en Python",
          "Arrays en Numpy",
          "Operaciones de filtrado en Vectores",
          "Funciones útiles",
          "Tuplas en Python"
        ],
        "Introducción a Pandas": [
          "Introducción a Pandas",
          "Introducción a los DataFrames",
          "Selección de datos en DataFrames",
          "Filtros en DataFrames",
          "Agrupaciones de datos",
          "Agrupaciones y Filtros. Ejemplo Real"
        ],
        "Visualización de los datos y Estadística Básica": [
          "Introduccion a Matplotlib",
          "Estadística Básica. Medidas de dispersión y de Asimetría",
          "Introducción a la Estadística. Media, Moda y Mediana",
          "Estadística Básica.Cálculos en Python",
          "Distribuciones de Proabilidad",
          "Visualización mas comunes en Ciencia de datos I",
          "Visualización mas comunes en Ciencia de datos II",
          "Visualización mas comunes en Ciencia de datos III"
        ],
        "Ejemplo Real. Predicción del precio de las viviendas": [
          "Introducción a Kaggle",
          "Predicción del precios de la Viviendas I",
          "Predicción del precio de las Viviendas II",
          "Exploración detallada de los datos",
          "Explorando Notebooks en Kaggle"
        ],
        "[MODULO EXTRA]": [
          "Mapas de Calor",
          "Lectura de HTML con Pandas"
        ]
      },
      "requirements": [
        "Tener ganas de aprender"
      ],
      "description": "En este curso veremos todo lo relacionado con el uso de los datos. Aprendemos a programar en Python y manejaremos diferentes librerías que nos permitirán  manipular y visualizar la información. Al finalizar el curso Participaremos en una competición en Kaggle donde diferentes técnicas vistas a lo largo del curso para predecir el precio de un conjunto de Viviendas en base a 80 Características\nEl curso esta dividido en 5 módulos:\nEmpezaremos con una Introducción a la Ciencia de datos, donde veremos su uso en la actualidad y las fases que debemos seguir para resolver los problemas mas comunes.\nEn el segundo Aprenderemos a programar usando Python\nEn el tercero nos focalizaremos en las diferentes estructuras de datos que tenemos en Python para así poder trabajar con la información de una manera eficiente\nEn el cuarto módulo aprenderemos a utilizar  Pandas, una de las librerías mas empleadas en ciencia de Datos.\nEn el quito Módulo veremos diferentes técnicas para poder visualizar toda esta información de manera sencilla e intuitiva, con ejemplos reales y además explicaremos conceptos básicos de Estadística\nEn el último Módulo , nos centraremos en resolver un problema real participando en una competición en Kaggle, donde podrás aplicar todos los conceptos aprendidos.\n\n\nEl curso está pensando para que cualquier persona sin experiencia previa pueda aprender. Iremos paso a paso e iremos gradualmente aumentando la complejidad.\nVerás que en muy poco tiempo aprenderás mucho ya que el curso está pensando para que sea sencillo y práctico.\nEn este curso te voy a contar lo fundamental para que puedas empezar a aplicar la ciencia de datos en tus proyectos.",
      "target_audience": [
        "Personas que quieran aprender ciencia de datos",
        "Estudiantes que quieran aprender a programar en Python",
        "Personas que tengas interés en extraer información de los datos",
        "Estudiantes de ciencia de datos que quieran obtener formación complementaria",
        "Personas de Areas no Tecnicas que quieran introducirse en este mundo."
      ]
    },
    {
      "title": "データサイエンス実戦講座［第１回］統計学の基礎と「統計的有意性」の終焉",
      "url": "https://www.udemy.com/course/issds_datascience_001/",
      "bio": "統計学の基礎から最新の機械学習やディープラーニングまで、データサイエンスの多種多様な手法を学んで研究開発やビジネスの問題を解決する能力を獲得しよう",
      "objectives": [
        "改訂しました（2024/3/14）。映像と音声をすべて録り直しました。講義内容は基本的に変えていませんが、細部を手直ししました。自然現象や社会現象のメカニズムを分析するデータサイエンスの様々な手法について、複数のコースに分けて1つずつ習得していきます。",
        "第1回目のコースは統計学の基礎です。母集団と標本、記述統計と推測統計、さまざまな確率分布、中心極限定理、平均値や分散の推定、仮説検定などについて、頻度論の考え方に基づく統計学の基礎理論を丁寧に解説します。",
        "頻度論による統計学は今から100年ほど前に生まれました。コンピュータなど無い時代なので、統計学者は数学的に扱えるように様々な仮定のもとに理論を構築しました。例えば母集団は正規分布している等ですが、実際の現象には当てはまらないケースもあります。分析手法の前提条件と現実の問題に適用する上での注意点について学習します。",
        "いま大きな話題になっているのが仮説検定です。アメリカ統計協会(ASA)は2016年に発表した「p値に関する声明」の中でp値の誤用が多いことに注意を喚起しており、2019年には機関誌で“統計的に有意と言うのはやめよう”と提言しています。p値の意味と検定結果の正しい解釈を学びます。",
        "すべてのコース、または、あなたに必要なコースを選択し、実務レベルの演習問題を解いていくことで、大学での研究や企業のビジネスの現場で遭遇する問題に対して、最善の意思決定と行動選択を可能にするデータ分析という強力な武器を手に入れることができます。"
      ],
      "course_content": {
        "紹介": [
          "はじめに（改訂版）",
          "統計学（頻度論）の基礎（１）歴史と分析の目的（改訂版）",
          "統計学（頻度論）の基礎（２）母集団と標本（改訂版）",
          "統計学（頻度論）の基礎（３）頻度分布と確率分布（改訂版）",
          "中心極限定理（改訂版）",
          "仮説検定の考え方（改訂版）",
          "アメリカ統計協会の声明（改訂版）",
          "第１回のまとめ（改訂版）",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "高校レベルの数学力があれば十分ですが、必須ではありません。",
        "正確を期すために数理モデルは示しますが、直感的な理解と解釈を重視してグラフや図による説明を主体にします。"
      ],
      "description": "データサイエンスには科学という名称が付いていますが、真理を探究するといった学問ではありません。問題を解決して対策を実行するための意思決定と行動選択の根拠を与えてくれる、有能な道具であり強力な武器です。道具や武器は使ってこそ意味があります。分析手法を勉強して理解するところで満足せず、大学の研究や企業の実務で直面する現実の問題を解決する実戦力を獲得することが本講座の目的です。\nデータサイエンスには、百年前に生まれた統計学から近年その価値が再認識されているベイズ統計学、注目の機械学習やディープラーニング、最先端のチャットボット技術まで、多種多様なデータ分析手法があります。残念ながら万能な手法というものはないので、多くの手法をマスターする必要があります。そして、積極的に複数の分析手法を適用することで、複雑な問題を様々な角度から解明して、本質に迫ることが可能になります。\n本講座では、複雑な数式やプログラミングはできるだけ避け、フリーのデータ分析ソフトを利用して実務レベルの演習問題を解いてゆくことで実戦力を養います。",
      "target_audience": [
        "学業や業務でデータ分析を必要としている方、将来データアナリストを目指す方、データサイエンスに興味のある方であればどなたでも。",
        "データ分析の初心者から学び直しの中級者。"
      ]
    },
    {
      "title": "NLP实战-Huggingface神器",
      "url": "https://www.udemy.com/course/nlp-huggingface/",
      "bio": "自然语言处理实战系列",
      "objectives": [
        "掌握NLP领域核心算法",
        "熟练使用transformer进行建模",
        "快速完成NLP应用任务与模型训练",
        "熟练使用Huggingface完成自己的应用项目",
        "熟练应用transformers包进行预训练模型训练"
      ],
      "course_content": {
        "Huggingface与NLP介绍解读": [
          "Huggingface与NLP介绍解读",
          "数据代码下载"
        ],
        "Transformer工具包基本操作实例解读": [
          "1-工具包与任务整体介绍",
          "2-NLP任务常规流程分析",
          "4-AttentionMask配套使用方法",
          "3-文本切分方法实例解读",
          "5-数据集与模型",
          "6-数据Dataloader封装",
          "7-模型训练所需配置参数",
          "8-模型训练DEMO"
        ],
        "第三章：Transformer核心架构": [
          "1-transformer原理解读"
        ],
        "第四章：BERT系列算法解读": [
          "1-BERT模型训练方法解读",
          "2-ALBERT基本定义",
          "3-ALBERT中的简化方法解读",
          "4-RoBerta模型训练方法解读",
          "5-DistilBert模型解读"
        ],
        "第五章：文本标注工具与NER实例": [
          "1-文本标注工具Doccano配置方法",
          "2-命名实体识别任务标注方法实例",
          "3-标注导出与BIO处理",
          "4-标签处理并完成对齐操作",
          "5-预训练模型加载与参数配置",
          "6-模型训练与输出结果预测"
        ],
        "第六章：文本预训练模型构建实例": [
          "1-预训练模型效果分析",
          "2-文本数据截断处理",
          "3-预训练模型自定义训练"
        ],
        "第七章：GPT系列算法": [
          "1-GPT系列算法概述",
          "2-GPT三代版本分析",
          "3-GPT初代版本要解决的问题",
          "4-GPT第二代版本训练策略",
          "5-采样策略与多样性",
          "6-GPT3的提示与生成方法",
          "7-应用场景CODEX分析",
          "8-DEMO应用演示"
        ],
        "第八章：GPT训练与预测部署流程": [
          "1-生成模型可以完成的任务概述",
          "2-数据样本生成方法",
          "3-训练所需参数解读",
          "4-模型训练过程",
          "5-部署与网页预测展示"
        ],
        "第九章：文本摘要建模": [
          "1-中文商城评价数据处理方法",
          "2-模型训练与测试结果",
          "3-文本摘要数据标注方法",
          "4-训练自己标注的数据并测试"
        ],
        "第十章：图谱知识抽取实战": [
          "1-应用场景概述分析",
          "2-数据标注格式样例分析",
          "3-数据处理与读取模块",
          "4-实体抽取模块分析",
          "5-标签与数据结构定义方法",
          "6-模型构建与计算流程",
          "7-网络模型前向计算方法",
          "8-关系抽取模型训练"
        ]
      },
      "requirements": [
        "熟悉深度学习与pytorch框架即可"
      ],
      "description": "通俗讲解NLP领域当下各大主流模型，全部基于transformer架构展开分析与应用。全程基于huggingface神器进行实战，快速上手完成NLP领域各核心项目，内容全面覆盖各大实际应用场景，主要包括分类模型，生成模型，NER，关系抽取，文本大模型，摘要与对话等业务场景。全程实例演示文本数据处理方法及其建模应用流程，从数据处理开始到加载预训练模型及配置参数与训练过程，全流程讲解如何使用Huggingface工具包完成各领域NLP任务。",
      "target_audience": [
        "AI方向的同学们"
      ]
    },
    {
      "title": "Fundamentos de Ciência de Dados em Python",
      "url": "https://www.udemy.com/course/fundamentos-de-ciencia-de-dados-em-python/",
      "bio": "Os primeiros passos para iniciar sua carreira na profissão mais promissora do Século XXI",
      "objectives": [
        "O que é Ciência de Dados",
        "Introdução à Linguagem Python",
        "Principais bibliotecas Python para uso de estatística e manipulação de dados",
        "Fundamentos de carga e manipulação de dados com Pandas",
        "Estatística Descritiva",
        "Medidas de Tendência ao Centro",
        "Medidas de Dispersão",
        "Distribuições",
        "Introdução ao Teste de Hipótese",
        "Teste Z",
        "Teste T",
        "Teste Chi Quadrado",
        "Teste F (ANOVA)",
        "Correlação",
        "Covariância",
        "Coeficiente de Matthews (Phi)",
        "Principais tipos de gráficos estatísticos",
        "Erros Comuns em Estatística"
      ],
      "course_content": {
        "Introdução": [
          "Bem-vindo ao curso de Ciência de Dados em Python",
          "Conteúdo Programático",
          "O que é Ciência de Dados.",
          "Configurando o Ambiente Python",
          "Executando códigos em Python",
          "Verificando a Configuração do Ambiente",
          "Introdução à Linguagem Python",
          "Python: Biblioteca NumPy",
          "Python: Biblioteca Pandas",
          "Exame - Parte 1 - Introdução",
          "Questionário 02 - Resolução (Opcional)"
        ],
        "Estatística Descritiva e Distribuições": [
          "Estatística Descritiva - Parte 01",
          "Estatística Descritiva - Parte 02",
          "Demonstração Prática de Estatística Descritiva",
          "Exame - Parte 2.1 - Estatística Descritiva",
          "Questionário 03 - Resolução (Opcional)",
          "Medias: Aritmética, Ponderada, Geométrica e Harmônica",
          "Introducão à Distribuições",
          "Demonstração Prática de Obliquidade e Curtose",
          "Exame 2.2 - Introdução a Distribuição",
          "Questionário 04 - Resolução (Opcional)",
          "Distribuição Normal",
          "Demonstração Prática sobre Distribuições Normais",
          "Exame Prático - Seção 2 - Estatística Descritiva e Distribuições"
        ],
        "Teste de Hipótese": [
          "Introdução ao Teste de Hipótese",
          "Teste de Hipótese Z",
          "Demonstração Prática de Teste de Hipotese Z",
          "Exame - Parte 3.1 - Teste de Hipótese e Teste Z",
          "Questionário 05 - Resolução (Opcional)",
          "Teste de Hipótese T",
          "Demonstração Prática de Teste de Hipotese T",
          "Teste de Hipótese Chi Quadrado",
          "Demonstração Prática de Teste de Hipotese Chi Quadrado",
          "Teste de Hipótese F (ANOVA)",
          "Demonstração Prática de Teste de Hipotese F (ANOVA)",
          "Exame - Parte 3.2 - Principais tipos de teste de hipótese",
          "Questionário 06 - Resolução (Opcional)",
          "Trabalhando com Testes de Hipóteses",
          "Exame Prático - Seção 3 - Testes de Hipótese"
        ],
        "Correlacão": [
          "Correlação e Covariância",
          "Demonstração Prática de Correlação",
          "Tabela de Contingência e Coeficiente Phi (Matthews)",
          "Exame 4.1 - Correlação e Covariância",
          "Questionário 07 - Resolução (Opcional)",
          "Demonstração Prática de Coeficiente Phi (Matthews)",
          "Exame Prático - Seção 4 - Correlação e Covariância",
          "Questionário 08 - Resolução (Opcional)"
        ],
        "Assuntos Adicionais e Conclusão": [
          "Gráficos Estatísticos",
          "Erros mais comuns em análise e interpretação de dados",
          "Próximos Passos",
          "Projeto Final de Curso",
          "Parabéns!"
        ]
      },
      "requirements": [
        "Noção muito básica de programação"
      ],
      "description": "Este curso tem por objetivo capacitar você a começar sua carreira em Ciência de Dados. Ele vai desde o início, explicando os conceitos mais básicos, incluindo o que é Python, como instalar, como usar, sintaxe básica, etc. Aqui você aprenderá os fundamentos que ajudarão você a começar sua carreira em Ciência de Dados ou a compreender melhor como analisar e interpretar informações.\n\nEste curso não aborda a parte de Machine Learning, mas não é recomendado que você estude Machine Learning sem antes entender os conceitos básicos de estatística aplicados à Ciência de Dados. Por este motivo, idealizei este curso. Ele é baseado em diversas aulas e workshops que tenho ministrado no decorrer dos últimos anos.\nO curso contém a parte teórica e prática, com vídeos e códigos. O curso é indicado mesmo a quem não tem conhecimento prévio em álgebra linear e cálculo, pois o enfoque é em como usar estes conceitos no computador, sem preocupações com a teoria matemática por trás.\nPara mais detalhes, veja o vídeo promocional deste curso ou entre em contato.",
      "target_audience": [
        "Estudantes ou profissionais de programação",
        "Estudantes ou profissionais acadêmicos que querem entender melhor como trabalhar com dados",
        "Jornalistas interessados em trabalhar com dados",
        "Profissionais que trabalham com relatórios, Business Intelligence ou manipulação de dados",
        "Profissionais de áreas onde o uso de dados e seu entendimento é fundamental, como Marketing, Publicidade, Saúde, entre outros.",
        "Desenvolvedores iniciantes de Python curiosos sobre Ciência de Dados"
      ]
    },
    {
      "title": "파이썬(Python)과 머신 러닝으로 만들어보는 추천 엔진",
      "url": "https://www.udemy.com/course/python-recommendation-engine/",
      "bio": "파이썬(Python)으로 인기도 기반 추천, 콘텐츠 유사도 기반 추천, 협업 필터링 기반 추천 (유저와 아이템), 평점 예측 추천 등에 대해 살펴 봅니다.",
      "objectives": [
        "추천 엔진의 역사와 어떤 것인지 이해하기",
        "추천 엔진을 만드는 다양한 방법의 이론적인 이해",
        "추천 엔진을 만드는 방법 실습",
        "추천 엔진을 평가하는 방법 이해",
        "콘텐츠 기반의 추천 엔진 만들기",
        "협업 필터링 기반 추천 엔진 만들기",
        "SVD와 딥러닝 기반 추천 엔진 만들기"
      ],
      "course_content": {
        "강의 소개": [
          "강사 소개",
          "강의 소개"
        ],
        "추천 엔진 소개": [
          "추천 엔진 정의 - 매칭 문제",
          "추천 엔진 정의 - 정의와 필요성",
          "유데미 분류 체계 살펴보기",
          "추천 엔진 예",
          "추천 엔진 종류",
          "추천 엔진 세부 설명 (컨텐츠 기반, 아이템 기반)",
          "추천엔진 구현방법 (하이레벨 설명)",
          "추천엔진 소개 요약"
        ],
        "콘텐츠 기반의 추천 엔진 만들기": [
          "넷플릭스 경진대회",
          "유데미 추천 엔진 살펴보기",
          "인기도 기반 추천 엔진 개발",
          "유사도 측정 방식",
          "TF-IDF 소개",
          "TF-IDF 실습",
          "TF-IDF를 이용한 컨텐츠 기반 추천 엔진 실습"
        ],
        "협업 필터링 기반 추천 엔진 만들기": [
          "일반적인 추천 엔진 아키텍처",
          "협업 필터링 소개",
          "사용자 기반 협업 필터링 소개와 더미 데이터 실습",
          "사용자 기반 협업 필터링 실습: 무비렌즈 데이터",
          "아이템 기반 협업 필터링 소개와 더미 데이터 실습",
          "아이템 기반 협업 필터링 실습: 무비렌즈 데이터"
        ],
        "SVD & 딥러닝 추천 엔진 만들기": [
          "SVD 알고리즘 소개",
          "SVD 기반 추천 엔진 실습",
          "오토인코더 소개",
          "오토인코더 실습",
          "오토인코더 기반 추천 엔진 실습"
        ],
        "추천 엔진 개발 마무리": [
          "추천 엔진 평가 방법 소개",
          "추천 엔진 평가 방법 실습",
          "추천 엔진 개발 교훈"
        ],
        "최종 요약": [
          "최종 요약"
        ],
        "[부록] AI 시대, 성장하는 개발자/엔지니어가 되기 위한 전략 라이브 세션(녹화본)": [
          "라이브 세션 다시보기"
        ]
      },
      "requirements": [
        "추천 엔진에 대한 관심",
        "파이썬에 대한 기본적인 지식 (Pandas를 사용해본 경험)",
        "머신 러닝에 대한 기본적인 지식 (scikit-learn을 사용해본 경험)",
        "지도 기계 학습(Supervised Machine Learning)에 대한 기본적인 지식"
      ],
      "description": "안녕하세요, 29년차 실리콘 밸리 개발자 한기용 입니다.\n이번에 유데미에서 ‘파이썬과 머신러닝으로 만드는 추천엔진’ 강의를 오픈 했습니다.\n지금까지 제가 커리어를 이어오면서 가장 임팩트 있는 프로젝트가 무엇이었는지 생각해보면 바로 추천 엔진 개발이었습니다.\n\n\n[추천 엔진 개발, 왜 배워야 할까요?]\n✓ 유튜브, 아마존, 넷플릭스, 인스타그램… 성공하는 서비스에는 어떤 비밀이 있을까요?\n세계적으로 유명한 서비스에는 사용자에게 다양한 제안을 제공하는 자체 추천 시스템이 있습니다.\n\n\n사람들은 검색이 중요하다고 많이 말하지만, 저는 추천이 훨씬 더 중요하다고 생각합니다.\n실제로 서비스를 사용하는 유저들 중에 검색을 하는 사람들의 비율은 높지 않습니다.\n\n\n특히 어떤 서비스가 굉장히 많은 콘텐츠를 갖고 있는 경우, 사용자가 알아서 자기가 원하는 상품을 한번에 찾아간다는 건 굉장히 힘든 일입니다. 그렇기 때문에 상품의 수가 늘어날수록 좋은 추천 엔진이 필요합니다.\n유저의 선호도를 빠르게 파악하고 거기에 맞춰서 이 사람이 아직 원하지 않더라도 선제적으로 좋아할 것 같은 아이템들을 보여주는 것이 사용자가 더 오랫동안 서비스를 사용하게 만드는 가장 좋은 방법입니다.\n\n\n이번 강의에서는 제가 실제로 유데미에서 추천 엔진을 무에서 유로 만들어가는 과정에서 배웠던 내용들을 모두 담았습니다.여러분들이 앞으로 회사에서 혹은 개인적인 호기심으로 추천 엔진을 만든다고 한다면 꼭 알아야 되는 그런 내용들 중심으로 혼을 다해서 강의를 만들어 봤습니다. 강의에서는 파이썬을 기반으로 추천 엔진의 개요부터 개발까지 모두 다뤄볼 예정입니다.\n\n\n[한기용의 추천 엔진 개발 강의가 특별한 이유]\n✓ 실전에 바로 적용 가능한 강의입니다.\n기술적으로 매우 뛰어난 추천 엔진을 만드는 것보다는 지금 내 상황에 맞춘 최적의 추천 엔진을 만드는 방법을 배웁니다. 단순한 인기도 기반 추천 엔진부터 머신러닝까지 본인의 환경에 맞춰 최소의 비용으로 최대의 효과를 낼 수 있는 개발 방법론을 학습합니다. 강의를 통해 추천엔진을 이해하고 가장 가볍게 시작할 수 있는 방법부터 상황에 맞춰 추천 엔진을 고도화하는 과정까지 여러분만의 추천 엔진을 개발할 수 있도록 점진적으로 배워봅니다.\n\n\n✓ 실리콘 밸리 개발 경험을 압축한 강의입니다.\n야후, 유데미 등 실리콘 밸리에서 11년 동안 검색 엔진 개발을 진행하고 지난 13년간 데이터 엔지니어링을 담당하며 배운 저의 추천 엔진 개발 노하우를 모두 담았습니다. 제 실제 개발 사례 기반으로 ‘콘텐츠 기반 추천부터 협업 필터링, SVD와 딥러닝 기반 추천, 평가와 마무리’까지 이론 중심이 아닌 프로젝트와 실습 중심으로 배워봅니다.\n\n\n✓ UIUX에 대한 이해까지 얻어갈 수 있는 강의입니다.\n추천 엔진을 만들 때 무조건 알고리즘만 중요한 것은 아닙니다. 실무에서는 어떻게 UIUX를 만들어 내느냐도 굉장히 중요한 포인트이기 때문에 기술적인 내용 뿐만 아니라 제 경험을 바탕으로 어떤 형태의 UI로 만들 수 있을지에 대해서 함께 다뤄봅니다.\n\n\n[이런 분들이 들으면 좋아요]\n추천 엔진 개발에 관심이 있는 개발자, 프로덕트 매니저, 데이터 과학자\n회사에서 관련 업무를 진행하고 계시거나 앞으로 추천 시스템을 도입해야 하는 분\n이커머스 혹은 콘텐츠를 많이 다루는 서비스를 운영 중인 분\n추천 엔진이 어떤 것이고 어떻게 만들어지는지 궁금한 누구나\n\n\n[선수 지식이 필요한가요?]\n이 강의를 듣기 위해서는 다음 선수 지식이 필요합니다.\n파이썬에 대한 기본적인 지식 (Pandas를 사용해본 경험)\n머신 러닝에 대한 기본적인 지식 (scikit-learn을 사용해본 경험)\n실습에 사용되는 자료(데이터)가 제공되며, 모든 실습은 Google Colab를 기반으로 이뤄집니다.",
      "target_audience": [
        "추천 엔진 개발에 관심이 있는 개발자, 프로덕트 매니저, 데이터 과학자",
        "회사에서 관련 업무를 진행하고 계시거나 앞으로 추천 시스템을 도입해야 하는 분",
        "이커머스 혹은 콘텐츠를 많이 다루는 서비스를 운영 중인 분",
        "추천 엔진이 무엇인지 이해하고 싶은 분",
        "추천 엔진을 만드는 다양한 방법을 학습하고 싶은 분",
        "추천 엔진을 실무나 프로젝트에 사용해야 하는 분"
      ]
    },
    {
      "title": "Criando Dashboards Incríveis com Power BI e MS Project",
      "url": "https://www.udemy.com/course/criando-dashboards-incriveis-com-power-bi-e-ms-project/",
      "bio": "Revolucione Seu Gerenciamento de Projetos Criando Dashboards com Power BI, e aumente a sua produtividade.",
      "objectives": [
        "Domine o Power BI: Instale, use e crie seu primeiro dashboard.",
        "Explore o MS Project: Aprenda o básico, adicione informações essenciais do projeto e construa um cronograma sólido.",
        "Desvenda a Linguagem DAX: Domine as funções cruciais para a análise de dados no Power BI.",
        "Crie Dashboards de Excelência: Construa dashboards completos a partir do Excel, com visuais impactantes e hierarquias de tarefas.",
        "Conquiste os Riscos: Conheça as estratégias de riscos, aprenda a calcular a exposição aos riscos, usando DAX e crie uma página de riscos no seu relatório.",
        "Explore o Banco de Dados: Aprenda a carregar e transformar as informações do banco de dados Access e crie um dashboard completo com os principais indicadores de",
        "Mergulhe no Portfólio: Entenda a estratégia organizacional e crie um dashboard com métricas do portfólio, do projeto, organizacionais e cruzamentos de dados. Te",
        "Power BI Serviço: Conheça as licenças do Power BI, aprenda a compartilhar os seus dashboards e a segurança de acesso das suas informações.",
        "Conteúdo adicional: Explore as últimas novidades do Power BI, incluindo o uso da IA com o Copilot e ChatGPT."
      ],
      "course_content": {},
      "requirements": [
        "Recomendações da Microsoft: Memória RAM de 4GB ou acima, Processador 2, GHz ou acima, .NET 4.8, Windows 8.1 ou acima / Windows Server 2012 ou acima.",
        "Conhecimento básico do Office"
      ],
      "description": "Imagine um cenário onde as apresentações para suas reuniões de projetos se tornam uma tarefa simples e altamente eficaz. Adeus à frustração de procurar informações em várias fontes, lidar com perguntas inesperadas da diretoria e gastar horas preparando apresentações complexas. Bem-vinda e Bem-vindo a um novo mundo de facilidade e impacto, cortesia do Power BI!\n\n\nPor Que Este Curso É Seu Próximo Passo Essencial:\nSupere os Desafios das Reuniões: Não mais informações desencontradas! Aprenda a criar dashboards dinâmicos que exibem dados precisos e relevantes para diferentes públicos.\nDomine a Visualização de Dados: Transforme dados brutos em visuais atraentes e compreensíveis. Explore múltiplos ângulos da situação atual do projeto e tendências ao longo do tempo.\nEconomize Tempo Valioso: Adeus ao retrabalho! Atualize seus dashboards com um simples clique e gaste segundos, não horas.\n\n\nO Que Esperar do Curso:\nDescubra 9 módulos repletos de conhecimento prático e valioso:\nDomine o Power BI: Instale, use e crie seu primeiro dashboard.\nExplore o MS Project: Aprenda o básico, adicione informações essenciais do projeto e construa um cronograma sólido.\nDesvende a Linguagem DAX: Domine as funções cruciais para a análise de dados no Power BI.\nCrie Dashboards de Excelência: Construa dashboards completos a partir do Excel, com visuais impactantes e hierarquias de tarefas.\nAcompanhe os Riscos: Conheça as estratégias de riscos, aprenda a calcular a exposição aos riscos, usando DAX e crie uma página de riscos no seu relatório.\nExplore o Banco de Dados: Aprenda a carregar e transformar as informações do banco de dados Access e crie um dashboard completo com os principais indicadores de projetos.\nMergulhe no Portfólio: Entenda a estratégia organizacional e crie um dashboard com métricas do portfólio, do projeto, organizacionais e cruzamentos de dados. Tenha uma visão mais abrangente do seu portfólio e compare informações atuais do projeto com informações anteriores.\nPower BI Serviço: Conheça as licenças do Power BI, aprenda a compartilhar os seus dashboards e a segurança de acesso das suas informações.\nConteúdo Adicional: Explore as últimas novidades do Power BI, incluindo o uso da IA com o Copilot e ChatGPT.\n\n\nPor Que Escolher Este Curso:\nInstrução Prática: Aprenda fazendo, com exemplos do mundo real e projetos práticos.\nEspecialista no Assunto: Tenho experiência de mais de 20 anos em gerenciamento de projetos e portfólio, e sei quais informações os stakeholders querem ver em uma reunião de projeto.\nAcesso Vitalício: Adquira conhecimento para a vida toda, com acesso contínuo ao conteúdo do curso.\nCertificado de Conclusão: Receba reconhecimento pelo aprimoramento das suas habilidades.\n\n\nO Momento de Transformação é Agora!\nEsteja à frente da concorrência, alcance uma compreensão profunda dos seus projetos e torne-se um mestre da visualização de dados com o Power BI. Não perca esta oportunidade de se destacar no mercado e revolucionar a forma como você lida com projetos. Inscreva-se agora no curso \"Criando Dashboards Incríveis de Projetos com Power BI e MS Project\" e prepare-se para uma jornada emocionante rumo ao domínio da visualização de dados!\nSe você já sonhou em simplificar suas apresentações e elevar o impacto do seu trabalho, este curso é sua chance de tornar isso uma realidade. Transforme dados em insights, e projetos em sucesso. Seja um mestre na arte da visualização de dados com o Power BI e o MS Project.",
      "target_audience": [
        "Profissionais de gerenciamento de projetos, analistas de dados, estudantes e todos que desejam aprimorar suas habilidades de visualização e análise de dados para um gerenciamento de projetos mais eficaz."
      ]
    },
    {
      "title": "Machine Learning in R: Curso Completo de Regressão Logística",
      "url": "https://www.udemy.com/course/regressaologisticanor/",
      "bio": "Como Programar Computadores para Tomarem Decisões",
      "objectives": [
        "Fazer cruzamento de dados",
        "Realizar Recodificação de Variáveis",
        "Gerar modelos de regressão logística aos dados",
        "Estimar o risco de ocorrência de um evento com base em outras variáveis",
        "Saber avaliar o poder o modelo gerado"
      ],
      "course_content": {
        "Introdução": [
          "Seja muito bem vindo(a)!",
          "Visão Geral",
          "Introdução",
          "Logística Binária - O que é",
          "Para que serve",
          "O banco de dados",
          "Definindo o tipo de cada variável",
          "Definindo as categorias de referência",
          "Dividindo as amostras",
          "Exercícios da primeira seção"
        ],
        "Amostra de Treinamento": [
          "Cruzamento de dados",
          "Variável Quantitativa",
          "Métodos de Entrada de Variáveis",
          "Modelo Inicial",
          "Interpretação dos Coeficientes",
          "Aula 14 - Odds Ratio",
          "Exercícios sobre a segunda seção."
        ],
        "Amostra de Teste": [
          "Aplicando o Modelo (amostra teste)",
          "Tabela de Confusão",
          "Exercícios da terceira seção"
        ],
        "Projeto de Aplicação": [
          "Projeto",
          "Observação sobre o Projeto",
          "Possível Solução para o Projeto"
        ],
        "Aula Bônus": [
          "Aula Bônus",
          "Trilha de Aprendizado para a carreira em Data Science"
        ]
      },
      "requirements": [
        "É interessante que tenha feito meu curso de Linguagem R do zero",
        "É interessante que tenha feito meu curso de Regressão Linear no R"
      ],
      "description": "Por que fazer este curso nos próximos 30 dias?\nAprender sobre Algoritmos de Machine Learning, especialmente o de Regressão Logística, tem sido essencial para quem deseja ter seu espaço nas grandes empresas, pois são eles fazem com que computadores tomem decisões baseadas em algoritmos, encontrando informações interessantes em meio a uma grande quantidade de dados.\nHoje, cada vez mais ocorre um aumento na quantidade de dados e conforme são os algoritmos são alimentados com mais dados, aprendem a reconhecer padrões e fornecer insights relevantes para as organizações.\nMas como o programa reconhece esses padrões?\nPara tentarem descobrir padrões ou prever resultados, as ferramentas de aprendizagem de máquina tentam descobrir equações (modelos matemáticos) que ajudem a extrair algum significado de um conjunto de dados. É por isso que o termo “modelagem” é tão recorrente em textos e discussões sobre machine learning.\nPortando, este curso visa APROFUNDAR o estudo do zero ao avançado nos modelos de Regressão Logística, considerado o mais usado quando se pretende estimar risco (probabilidade de um evento).\n\n\nQue tipo de resultado eu tenho com esta técnica?\nPrevisão de risco: ex: qual as chances da empresa fechar com base em algumas variáveis? Quais as chances de um indivíduo ter um AVC dado algumas variáveis como hábitos de fumo, escolaridade, atividades físicas , etc.? Qual a probabilidade do cliente ser um bom pagador com base em algumas variáveis como sexo, comportamento de consumo, etc.?\n\n\nSaber quais variáveis contribuem no aumento ou diminuição do risco de acontecer um determinado evento (nova venda de um produto, um Câncer ou outra doença qualquer, a peça ser defeituosa, etc.)\n\n\nO quanto altera na probabilidade quando um indivíduo está exposto a um fator de risco (ex: qual o risco de um cliente comprar um imóvel dado que ele é do sexo masculino)\n\n\nConstruir uma equação matemática que descreva o mundo real.\n\n\n\n\nEste é um dos cursos mais desejados no momento, portanto não perca tempo e corra para aprender tudo isto da maneira mais fácil e rápida possível e consiga sua vaga neste amplo mercado.\n\n\n\n\nPara quem serve este curso?\nProfissionais de TI e de áreas associadas, interessados em se aprofundar em Estatística e aplicá-la no mundo empresarial.\nEstudantes de graduação, mestrado e doutorado precisando aprender estatística para provas universitárias ou para pesquisas científicas.\n\"Concurseiros\" interessados em \"matar\" a prova de Estatística.\n\n\nSobre o Professor\nMeu nome é Isaías Lira, bacharel em Estatística, Consultor em Análise Estatística de Dados, pesquisador e estudioso da área de Estatística Aplicada no Mercado Financeiro, escritor de livro em Estatística, Data Scientist, Pos-graduado em Docência Superior e este curso é um importante dentro de minha lista de cursos.\n\n\nQual o diferencial deste curso?\nCurso 100% pratico\nUsaremos dados reais\nTudo mostrado passo a passo\nAprofundamento na ferramenta de análise de dados mais respeitada no mercado: o R.\nEstrutura: o curso esta cuidadosamente estruturado para que em cada aula você tenha a clareza de cada assunto abordado\nAbordagem simplificada: focamos naquilo que é mais importante, numa linguagem simples, direta, com vários exemplo reais\n\n\nInicie agora e conclua quando bem desejar! Sem pressão! Respeitaremos o seu próprio ritmo e estaremos aqui para tirar suas dúvidas.\nO mercado profissional precisa de você, então aprenda isto e seja útil para as grandes empresas.\nEntão, se você quer aprender sobre Regressão Logística, seja você quem for, este é o caminho mais fácil que conheço!\nVamos iniciar?",
      "target_audience": [
        "Leigos interessados em Prever o Comportamento de Quaisquer Eventos a partir de modelos de regressão logística",
        "Estudantes, Profissionais e Apaixonados pela área de TI ou qualquer profissional interessado em Aprender regressão Logística para resolver grandes problemas."
      ]
    },
    {
      "title": "【Hands Onで学ぶ】データサイエンスのための強化学習入門",
      "url": "https://www.udemy.com/course/rl-python/",
      "bio": "抽象的で難しい強化学習をスッキリと理解できます",
      "objectives": [
        "強化学習の基礎理論と主要なアルゴリズムの全体像",
        "状態価値関数やBellman方程式の理解",
        "SARSA、Q学習などのアルゴリズムの理論と実装",
        "PyTorchを用いたDQN（Deep Q-Network）の実装"
      ],
      "course_content": {
        "はじめに": [
          "講座概要",
          "強化学習の全体像"
        ],
        "epsilon-greedy": [
          "確率の基礎",
          "指数移動平均",
          "epsilon-greedy法(理論)",
          "epsilon-greedy法(実装) 多腕バンディット part1",
          "epsilon-greedy法(実装) 多腕バンディット part2",
          "epsilon-greedy法(実装) 多腕バンディット part3"
        ],
        "強化学習の基礎知識": [
          "MDP",
          "Gymnasium",
          "Gymnasium 実装",
          "Episodicタスク・連続タスク",
          "報酬と収益",
          "状態価値関数・行動価値関数"
        ],
        "強化学習の実践": [
          "Bellman方程式 part1",
          "Bellman方程式 part2",
          "最適なポリシー",
          "方策反復法(理論)",
          "反復方策評価(実装)",
          "方策反復法(実装)",
          "価値反復法(理論)",
          "価値反復法(実装)",
          "TD法(理論)",
          "SARSA・Q学習(理論)",
          "SARSA・Q学習(実装)",
          "DQN(理論)",
          "DQN(実装) part1",
          "DQN(実装) part2",
          "DQN(実装) part3",
          "DQN(実装) part4",
          "DQN(実装) part5",
          "DQN(実装)part6"
        ],
        "ボーナスレクチャー": [
          "使用したスライドとnotebook"
        ]
      },
      "requirements": [
        "Pythonのプログラミング経験",
        "PyTorchのプログラミング経験"
      ],
      "description": "【本講座の概要】\n本講座は、強化学習の全体像や基礎理論を理解し、実務で活用できるスキルを身に付けるための講座です。\n近年、強化学習はゲームAIやロボット制御などにとどまらず、レコメンデーションシステムや自動化された意思決定など、幅広い分野で注目を集めています。データサイエンティストとしてキャリアを積んでいく上でも、強化学習の知識と実装力を武器にしたいと考えている方は少なくありません。\n一方で、こんな悩みは無いでしょうか？\n強化学習を学びたいが、まず何から手を付ければいいのか分からない\n理論はある程度学んだものの、実際にPythonでどう実装すればいいかイメージが湧かない\n多くのアルゴリズムがあるが、全体像を整理しきれず理解が断片的になってしまう\n本講座は、そんな多くの人が抱えがちな悩みに応えるために作成されました。\nこの講座では、強化学習の全体像を把握するところから学習を始めます。\nその後、理論と計算例や、Python実装を並行して進めることで、理解がより深まるよう設計されています。\n\n\n具体的には、以下のトピックをカバーしています。\n強化学習の基礎理論と主要なアルゴリズムの全体像\nepsilon-greedyやMultiArmBanditなどの基本手法\n状態価値関数やBellman方程式の理解\n方策反復法や価値反復法によるBellman方程式の解法\nTD法(SARSA、Q学習)などの強化学習でよく使われる手法の理論と実装\nPyTorchを用いたDQN（Deep Q-Network）の実装\nこの講座を受講する事で、強化学習の基礎を正しく理解した上で、Pythonを使って実際にアルゴリズムを実装する力を身に付けることができます。また、強化学習の基礎をしっかり押さえているため、他の高度なライブラリやフレームワークを利用する際にもスムーズに取り掛かることが可能です。\n\n\n【人事の方/マネージャークラスの方へ】\n本コースは次のような使い方が可能です。\n社内で、強化学習の基礎理論から実装までカバーできるAI/データサイエンス人材を育成したい\n\n\n本コースを受講いただくことで、受講者は理論から実装まで一貫して学習でき、実際のビジネス課題に強化学習を応用するための土台をしっかり固めることができます。社内全体のデータ分析スキルが底上げされます\n\n\n【対象者とゴール】\nこのコースは、Pythonを使った分析経験がある入門〜初級レベルのデータサイエンティストや、機械学習に触れてきたエンジニアの方を主な対象としています。強化学習を学ぶことによって、より高度な意思決定システムの開発に携わりたい、あるいは研究に取り入れたい方に最適です。\n本コースのゴールは3つあります。\n強化学習の基本概念とアルゴリズムの全体像を理解し、強化学習特有の専門用語や数式をしっかり理解できるようになる\n強化学習アルゴリズムをPythonで実装し、数式をコードに変換する実装力を身に付ける\n深層強化学習の入り口となる強化学習の基礎を網羅的に学ぶ",
      "target_audience": [
        "強化学習に入門したいPython初学者",
        "強化学習の実装に興味を持っているデータサイエンティスト",
        "既存のアルゴリズムに強化学習を組み合わせたいと考えている研究者"
      ]
    },
    {
      "title": "دبلومة بايثون لتعلم الآلة | Python Machine Learning Diploma",
      "url": "https://www.udemy.com/course/python-machine-learning-diploma/",
      "bio": "الخطوة الثانية في رحلتك لاحتراف \"علم البيانات\"، أفضل بداية لأي حد عاوز يتعلم ويحترف \"علم البيانات وتعلم الآلة\" في بايثون",
      "objectives": [
        "مبادئ تعلم الآلة والذكاء الاصطناعي | Machine Learning Foundations",
        "تجهيز البيانات لتعلم الآلة | Data Preprocessing for Machine Learning",
        "تعليم مراقب للآلة | Supervised Machine Learning (Regression & Classification)",
        "تعليم بدون مراقبة للآلة | Unsupervised Machine Learning (Clustering & Dimensionality Reduction)",
        "تقييم واختيار النماذج | Model Evaluation & Selection",
        "مشاريع وتطبيقات عملية على علم البيانات في بايثون | Python Data Science Projects",
        "مراجعة على بايثون ومكتبات تحليل البيانات | Python & Data Analysis Libraries Review"
      ],
      "course_content": {
        "مقدمة عامة عن الدورة التدريبية | Course Introduction": [
          "خطة الدورات التدريبية في الدبلومة Diploma Courses Roadmap",
          "المجموعة الخاصة بالتدريب Joining Telegram Group"
        ],
        "----- COURSE(01) | DATA SCIENCE & MACHINE LEARNING FOUNDATIONS -----": [
          "ملفات الدورة التدريبية ML Basics Materials",
          "مقدمة الدورة التدريبية Machine Learning Foundations Course Introduction",
          "تطبيق عملي: مشروع كامل في علم البيانات في بايثون (لا يتطلب التطبيق فقط المتابعة)",
          "يعني إيه ذكاء اصطناعي وإيه تطبيقاته؟ What is Artificial Intelligence",
          "تعريف وأهمية تعلم الآلة Machine Learning Definition",
          "علاقة علم البيانات بتعلم الآلة Data Science vs. Machine Learning",
          "أنواع وتطبيقات تعلم الآلة Machine Learning Types & Its Applications",
          "مراحل مشروع تعلم الآلة Machine Learning End-to-end Project",
          "نماذج تعلم الآلة ML Models (أخطر فيديو في تعلم الآلة والذكاء الاصطناعي)",
          "محاور ومواضيع دبلومة تعلم الآلة Machine Learning Diploma Topics",
          "إزاي تتعلم وتذاكر تعلم الآلة والذكاء الاصطناعي Machine Learning Study Guide",
          "إزاي تلاقي بيانات تتعلم وتشتغل عليها UCI ML Repo. (Datasets)"
        ],
        "----- COURSE(02) | DATA PRE-PROCESSING FOR MACHINE LEARNING -----": [
          "ملفات الدورة التدريبية Feature Engineering Materials",
          "مقدمة عامة عن تجهيز البيانات Feature Engineering Basics",
          "مثال على عملية تجهيز البيانات لنماذج تعلم الآلة Example for Feature Engineering",
          "مبادئ التحجيم والتوحيد المعياري للبيانات Feature Normalizing & Standardization",
          "تشفير وترميز البيانات التصنيفية Categorical Features Encoding",
          "تطهير البيانات والتعامل مع القيم المتطرفة Feature Cleaning & Outliers Handling",
          "تقسيم البيانات لاختنبار النماذج Data Splitting for Model Testing & Validation"
        ],
        "----- COURSE(03) | UNSUPERVISED LEARNING (CLUSTERING) -----": [
          "مقدمة عامة عن الدورة التدريبية Course Introduction"
        ],
        "مبادئ خوارزميات التصنيف والتجميع | Clustering Algorithms Basics": [
          "ملفات الدورة التدريبية All Course Materials",
          "مفاهيم أساسية عن التعلم غير المراقب Unsupervised Learning Principles"
        ],
        "خوارزمية التصنيف (التحليل العنقودي) | K-Means Algorithm (Clustering Analysis)": [
          "مقدمة عامة عن خوارزمية التصنيف K-Means Clustering Basics",
          "مثال توضيحي: خوارزمية التصنيف K-Means Clustering Python Demo",
          "مفاهيم أساسية عن خوارزمية التصنيف K-Means Clustering Principles",
          "شرح خوارزمية التصنيف K-Means Clustering Algorithm Explanation",
          "مزايا وعيوب خوارزمية التصنيف K-Means Clustering Pros. & Cons.",
          "تطبيق عملي: خوارزمية التصنيف K-Means Clustering Python Case-study"
        ],
        "التجميع الهرمي (التحليل العنقودي) | Hierarchical Algorithm (Clustering Analysis)": [
          "مقدمة عامة عن خوارزمية التجميع الهرمي Hierarchical Clustering Basics",
          "مثال توضيحي: خوارزمية التجميع الهرمي Hierarchical Clustering Python Demo",
          "مفاهيم أساسية عن خوارزمية التجميع الهرمي Hierarchical Clustering Principles",
          "شرح خوارزمية التجميع الهرمي Hierarchical Clustering Algorithm Explanation",
          "مزايا وعيوب خوارزمية التجميع الهرمي Hierarchical Clustering Pros. & Cons.",
          "تطبيق عملي: خوارزمية التجميع الهرمي Hierarchical Clustering Python Case-study"
        ],
        "التصنيف بكثافة البيانات (التحليل العنقودي) | DBSCAN (Clustering Analysis)": [
          "مقدمة عامة عن خوارزمية التصنيف بكثافة البيانات DBSCAN Basics",
          "مثال توضيحي: خوارزمية التصنيف بكثافة البيانات DBSCAN Python Demo",
          "مفاهيم أساسية عن خوارزمية التصنيف بكثافة البيانات DBSCAN Principles",
          "شرح خوارزمية التصنيف بكثافة البيانات DBSCAN Algorithm Explanation",
          "مزايا وعيوب خوارزمية التصنيف بكثافة البيانات DBSCAN Pros. & Cons.",
          "مقارنة خوارزميات التصنيف K-Means vs. DBSCAN",
          "تطبيق عملي: خوارزمية التصنيف بكثافة البيانات DBSCAN Python Case-study"
        ],
        "----- COURSE(04) | UNSUPERVISED LEARNING (DIMENSIONALITY REDUCTION) -----": [
          "ملفات الدورة التدريبية PCA Materials",
          "مقدمة عامة عن خوارزمية تحليل المكون الرئيسي PCA Basics",
          "تبسيط فكرة خوارزمية تحليل المكون الرئيسي PCA Algorithm Intuition",
          "مثال توضيحي: خوارزمية تحليل المكون الرئيسي PCA Python Demo",
          "مفاهيم أساسية عن خوارزمية تحليل المكون الرئيسي PCA Principles",
          "شرح خوارزمية تحليل المكون الرئيسي PCA Algorithm Explanation",
          "مزايا وعيوب خوارزمية تحليل المكون الرئيسي PCA Pros. & Cons.",
          "تطبيق عملي: خوارزمية تحليل المكون الرئيسي PCA Python Case-study"
        ],
        "----- COURSE(05) | SUPERVISED LEARNING (CLASSIFICATION) -----": [
          "مقدمة عامة عن الدورة التدريبية Course Introduction"
        ]
      },
      "requirements": [
        "دبلومة بايثون لتحليل البيانات | Python Data Analysis Diploma",
        "أساسيات برمجة بايثون | Python Programming Basics",
        "مكتبات تحليل البيانات في بايثون | Python Data Analysis Libraries (NumPy, Pandas, Matplotlib, & Seaborn)",
        "أساسيات الإحصاء الوصفية | Descriptive Statistics Basics"
      ],
      "description": "دبلومة بايثون لتعلم الآلة وعلم البيانات | Python Data Science & Machine Learning Diploma\nدبلومة علم البيانات باستخدام بايثون هي الخطوة الثانية في رحلتنا في مجال علم وتحليل البيانات والذكاء الإصطناعي، وهي مبادرة نسعى من خلالها إلى إثراء المحتوى العربي في هذا المجال من خلال إعداد دورة تدريبية شاملة بشكل تفاعلي وتطبيقي لكل مواضيع وتخصصات هذا المجال .. وبنحاول إن التدريب يكون مناسب للمبتدئين ولأي شخص يرغب في بدء العمل كمحلل بيانات Data Analyst / عالم بيانات Data Science باستخدام بايثون Python واحتراف هذا المجال من الصفر.\n\n\nالدبلومة بتتميز بالآتي:\n- التدريب تفاعلي وقائم على النقاشات مع الطلاب\n- خطة واضحة ومنظمة للبدء في المجال من الصفر وحتى احترافه\n- 9 كورسات في كورس واحد\n- أكثر من 45 ساعة تدريبية\n- تطبيقات عملية ومشاريع Case-studies\n- تحميل ملفات التدريب والأكواد Course Materials\n- المحتوى متاح مدى الحياة\n- شهادة بنهاية التدريب\n\n\nبنشرح في الدبلومة التقنيات والأدوات الرئيسية لأي محلل بيانات باستخدام بايثون:\nمبادئ تعلم الآلة والذكاء الاصطناعي | Machine Learning Foundations\nمراجعة على بايثون ومكتبات تحليل البيانات | Python & Data Analysis Libraries Review\nتجهيز البيانات لتعلم الآلة | Feature Engineering for Machine Learning\nتعليم مراقب للآلة | Supervised Machine Learning\nتحليل الإنحدار | Regression Analysis\nالتصنيف الإحصائي | Statistical Classification\nتعليم بدون مراقبة للآلة | Unsupervised Machine Learning\nالتحليل العنقودي | Cluster Analysis\nتقليل البيانات | Dimensionality Reduction\nتقييم واختيار النماذج | Model Evaluation & Selection\nتجهيز النماذج للتطبيقات | Model Deployment\nمشاريع وتطبيقات عملية على علم البيانات في بايثون | Python Data Science Projects\n\n\n---\nدبلومة علم وتحليل البيانات باستخدام بايثون هي مبادرة نسعى من خلالها إلى إثراء المحتوى العربي في هذا المجال من خلال إعداد دورة تدريبية شاملة بشكل تفاعلي وتطبيقي لكل مواضيع وتخصصات هذا المجال .. وبنحاول إن التدريب يكون مناسب للمبتدئين ولأي شخص يرغب في بدء العمل كمحلل بيانات Data Analyst / عالم بيانات Data Science باستخدام بايثون Python واحتراف هذا المجال من الصفر.\n= (*) تحذير هام: تم بذل مجهود كبير بفضل الله وتوفيقه من قبل م. مصطفى عثمان في إعداد هذا المحتوى الذي يقدم بصفة شخصية لك مقابل الاشتراك، رجاء عدم نسخه أو استخدامه بعيداً عن الموقع أو الإتجار به لإن ذلك يعرضك للمسائلة أمام الله عز وجل .. شكراً لتفهمك، وشكراً لاهتمامك بما نقدمه",
      "target_audience": [
        "أي حد لسة هيبدأ في مجال علم وتحليل البيانات وعاوز يبدأ بداية موفقة",
        "اللي بدأ في تحليل البيانات وحابب يتعلم ويحترف تعلم الآلة وعلم البيانات"
      ]
    },
    {
      "title": "Python para Data Science: Curso Rápido para Quem Tem Pressa!",
      "url": "https://www.udemy.com/course/python-para-data-science-parte1/",
      "bio": "Aprenda Python do Zero com um Método Prático e Eficiente para Iniciar sua Carreira em Data Science Sem Perder Tempo!",
      "objectives": [
        "Introdução ao Python: Aprenda os conceitos básicos da linguagem Python e suas aplicações em ciência de dados.",
        "Instalação do Ambiente: Configure o ambiente de desenvolvimento usando Anaconda e Jupyter Notebook em Windows e Linux.",
        "Sintaxe Básica: Entenda a sintaxe básica de Python, incluindo variáveis, operadores e estruturas de controle.",
        "Comandos Condicionais: Aprenda a usar comandos condicionais (if, else, elif) para controlar o fluxo do seu código.",
        "Estruturas de Repetição: Domine os loops (for, while) para repetir ações e processar listas de dados.",
        "Estruturas de Dados: Explore listas, strings, tuplas e dicionários para armazenar e manipular dados.",
        "Funções em Python: Crie e utilize funções para organizar e reutilizar seu código de forma eficiente.",
        "Projeto Prático: Desenvolva um projeto de ciência de dados do início ao fim, aplicando todos os conceitos aprendidos."
      ],
      "course_content": {
        "Parte 1: Apresentação": [
          "Introdução",
          "Apresentação do curso e boas práticas",
          "Por que aprender programação?",
          "Por que aprender Python?",
          "Quem sou eu?",
          "O que é Ciência de Dados (Data Science)?"
        ],
        "Parte 2: Preparação do Ambiente": [
          "Introdução à Preparação do Ambiente de Ciência de Dados",
          "Instalação no ambiente Windows",
          "Instalação no ambiente Linux"
        ],
        "Parte 3: Introdução a Linguagem Python": [
          "Carregando os Dados e finalizando a preparação do ambiente (WINDOWS)",
          "Carregando os Dados e finalizando a preparação do ambiente (LINUX)",
          "Python Básico"
        ],
        "Parte 4: Estrutura Condicional": [
          "Comandos Condicionais"
        ],
        "Parte 5: Estruturas de Repetição": [
          "Comandos de Repetição"
        ],
        "Estruturas de Dados Integradas": [
          "Estruturas de Dados Integradas (Listas, Tuplas e Dicionários)"
        ],
        "Funções": [
          "Funções"
        ],
        "O Processo de Ciência de Dados": [
          "Estudo de Caso: Credit Score"
        ],
        "Encerramento e próximos passos...": [
          "Encerramento...",
          "Próximos passos..."
        ]
      },
      "requirements": [
        "Nenhuma Experiência Prévia Necessária: O curso é projetado para iniciantes, sem necessidade de conhecimentos prévios em programação.",
        "Interesse em Ciência de Dados: Tenha curiosidade e motivação para aprender sobre ciência de dados e programação.",
        "Acesso a um Computador: Tenha acesso a um computador com Windows, Linux ou macOS para instalar os softwares necessários.",
        "Vontade de Aprender: Esteja disposto a dedicar tempo e esforço para aprender e praticar os conceitos ensinados.",
        "Instalação do Ambiente: Capacidade de seguir as instruções para instalar Anaconda e Jupyter Notebook no seu sistema."
      ],
      "description": "Python para Ciência de Dados: Curso Rápido para Quem tem Pressa!\nA programação se tornou uma habilidade essencial no mundo atual, permitindo que profissionais de diversas áreas solucionem problemas complexos e automatizem processos. Python, uma das linguagens de programação mais populares e versáteis, se destaca por sua simplicidade e poderosa aplicação na área de ciência de dados. Este curso foi desenvolvido para introduzir você ao universo da programação com Python, focando em suas aplicações na Ciência de Dados / Data Science.\n\n\nSobre o Instrutor\nO curso é ministrado pelo Prof. Dr. Dilermando Piva Junior, um renomado educador com mais de 29 anos de experiência no ensino de programação em cursos superiores no Brasil. Autor de diversos livros e centenas de artigos na área de computação, o Prof. Dr. Dilermando possui uma vasta experiência acadêmica e prática que enriquecerá sua aprendizagem.\n\n\nSobre o Curso\nPython para Ciência de Dados: Curso Rápido para Quem tem Pressa! é um curso introdutório que abrange os conceitos básicos da linguagem Python e suas aplicações em ciência de dados. Veja abaixo os principais tópicos abordados:\nIntrodução ao Python: Aprenda os conceitos básicos da linguagem Python e suas aplicações em ciência de dados.\nInstalação do Ambiente: Configure o ambiente de desenvolvimento usando Anaconda e Jupyter Notebook em Windows e Linux.\nSintaxe Básica: Entenda a sintaxe básica de Python, incluindo variáveis, operadores e estruturas de controle.\nComandos Condicionais: Aprenda a usar comandos condicionais (if, else, elif) para controlar o fluxo do seu código.\nEstruturas de Repetição: Domine os loops (for, while) para repetir ações e processar listas de dados.\nEstruturas de Dados: Explore listas, strings, tuplas e dicionários para armazenar e manipular dados.\nFunções em Python: Crie e utilize funções para organizar e reutilizar seu código de forma eficiente.\nProjeto Prático: Desenvolva um projeto de ciência de dados do início ao fim, aplicando todos os conceitos aprendidos.\n\n\nPré-requisitos do Curso\nEste curso é projetado para iniciantes e não requer experiência prévia em programação. Os únicos pré-requisitos são:\nNenhuma Experiência Prévia Necessária: O curso é acessível a todos, independentemente do nível de conhecimento em programação.\nInteresse em Ciência de Dados: Tenha curiosidade e motivação para aprender sobre ciência de dados e programação.\nAcesso a um Computador: Necessário um computador com Windows, Linux ou macOS para instalar os softwares necessários.\nVontade de Aprender: Esteja disposto a dedicar tempo e esforço para aprender e praticar os conceitos ensinados.\nInstalação do Ambiente: Capacidade de seguir as instruções para instalar Anaconda e Jupyter Notebook no seu sistema.\n\n\nPúblico-alvo\nEste curso é destinado a uma ampla gama de profissionais e entusiastas, incluindo:\nIniciantes em Programação: Pessoas sem nenhuma experiência prévia em programação que desejam aprender a programar usando Python de forma prática e aplicada.\nProfissionais em Transição de Carreira: Profissionais de diversas áreas que desejam migrar para o campo da ciência de dados e adquirir novas habilidades.\nEstudantes e Acadêmicos: Estudantes de cursos superiores ou técnicos e pesquisadores que precisam de habilidades em programação para análise de dados.\nEngenheiros e Profissionais Técnicos: Engenheiros de diversas disciplinas interessados em aplicar ciência de dados em seus projetos e profissionais técnicos que desejam automatizar processos e melhorar a análise de dados.\nProfissionais da Área de Saúde: Médicos, enfermeiros e outros profissionais de saúde que querem utilizar ciência de dados para melhorar a análise e a gestão de dados clínicos, além de pesquisadores em saúde pública.\nAnalistas de Negócios, Gestores e Empreendedores: Profissionais que trabalham com análise de dados e precisam aprimorar suas habilidades de programação, além de gestores interessados em tomar decisões informadas com base em ciência de dados.\nCuriosos e Entusiastas de Tecnologia: Pessoas com interesse geral por tecnologia e programação que desejam explorar o mundo da ciência de dados.\n\n\nVantagens de Fazer Este Curso\nAprendizado Prático e Aplicado: O curso oferece uma abordagem prática, com exemplos e exercícios que facilitam a compreensão e a aplicação dos conceitos.\nInstrutor Experiente: Aprenda com um professor renomado, com vasta experiência acadêmica e prática na área de programação e ciência de dados.\nFlexibilidade: Estude no seu próprio ritmo, com acesso vitalício ao conteúdo do curso.\nCertificação: Ao concluir o curso, você receberá um certificado de conclusão, valorizando seu currículo e suas habilidades.\nComunidade de Aprendizagem: Faça parte de uma comunidade de estudantes e profissionais que compartilham o interesse por ciência de dados e programação, promovendo networking e troca de conhecimentos.\n\n\nJunte-se a mim e inicie sua jornada na Ciência de Dados com Python!",
      "target_audience": [
        "Iniciantes em Programação: Pessoas sem nenhuma experiência prévia em programação. Indivíduos que desejam aprender a programar usando Python de forma prática e aplicada.",
        "Profissionais em Transição de Carreira: Profissionais de diversas áreas que desejam migrar para o campo da ciência de dados. Indivíduos interessados em adquirir novas habilidades para aumentar suas oportunidades de emprego.",
        "Estudantes e Acadêmicos: Estudantes de cursos superiores ou técnicos que querem complementar seus conhecimentos. Pesquisadores que precisam de habilidades em programação para análise de dados em seus estudos.",
        "Engenheiros e Profissionais Técnicos: Engenheiros de diferentes disciplinas (civil, mecânica, elétrica, etc.) interessados em aplicar ciência de dados em seus projetos. Profissionais técnicos que desejam automatizar processos e melhorar a análise de dados em seus campos.",
        "Profissionais da Área de Saúde: Médicos, enfermeiros, e outros profissionais de saúde que querem utilizar ciência de dados para melhorar a análise e a gestão de dados clínicos. Pesquisadores em saúde pública interessados em aplicar técnicas de ciência de dados em seus estudos.",
        "Analistas de Negócios, Gestores e Empreendedores: Profissionais que trabalham com análise de dados e precisam aprimorar suas habilidades de programação. Gestores que desejam entender melhor como a ciência de dados pode ser aplicada para tomar decisões informadas.",
        "Curiosos e Entusiastas de Tecnologia: Pessoas que têm interesse geral por tecnologia e programação. Entusiastas que querem explorar o mundo da ciência de dados e suas aplicações."
      ]
    },
    {
      "title": "Pythonによる因果推論と機械学習",
      "url": "https://www.udemy.com/course/python-ml-causal-inference/",
      "bio": "傾向スコアを用いたIPW法や、Meta-Learners、アップリフトモデリングなどの因果効果の推定手法を学び、Google Colaboratoryで実践しましょう！DoWhyやEconMLライブラリを使ってPythonで実装します。",
      "objectives": [
        "データに潜む擬似相関（交絡や合流点など）",
        "d分離",
        "傾向スコアとIPW",
        "DoWhyによるDAGの表現や効果の推定",
        "Meta-Learnersの理解とEconMLによる実践（S-Learner, T-Learner, X-Learner）",
        "DR-Learnerによる効果推定",
        "アップリフトモデリングの理解と実践"
      ],
      "course_content": {
        "コース紹介": [
          "コース紹介",
          "サンプルデータダウンロード",
          "コース準備レクチャー"
        ],
        "イントロダクション": [
          "バイアス",
          "擬似相関",
          "交絡とは",
          "合流点で選抜",
          "因果ダイアグラム",
          "最終的に計算したいもの",
          "ATE, ATT, ATU, CATE",
          "介入と因果ダイアグラム",
          "因果推論の用語まとめ"
        ],
        "d分離": [
          "d分離とは",
          "バックドアパスとバックドア基準",
          "d分離の例",
          "d分離の例題をやってみよう",
          "DoWhyライブラリを使った演習の説明",
          "演習：DoWhyライブラリの使い方①",
          "演習：DoWhyライブラリの使い方②",
          "演習：d分離①",
          "演習：d分離②"
        ],
        "傾向スコアを用いた効果推定": [
          "傾向スコア",
          "逆確率重み付き推定法（IPW）",
          "（参考）回帰分析による効果推定",
          "IPW①",
          "演習：IPW②"
        ],
        "Meta-Learners": [
          "IPWからMeta-Learnersへ",
          "Meta-Learnersの概要",
          "S-Learner",
          "演習：使用するデータの読み込みと確認",
          "演習：DAGの作成とIPW",
          "演習：S-Learner",
          "T-Learner",
          "演習：T-Learner",
          "X-Learner",
          "演習-X-Learner",
          "Meta-Learnersの各手法の比較"
        ],
        "DR-Learner": [
          "二重にロバストな推定法（DR法）",
          "DR-Learner",
          "演習：DR-Learner"
        ],
        "アップリフトモデリング": [
          "アップリフトモデリングとは",
          "介入対象と結果の分類",
          "スコアとアップリフト",
          "演習：アップリフトモデリング①",
          "演習：アップリフトモデリング②",
          "演習：アップリフトモデリング③",
          "演習：アップリフトモデリング④",
          "演習：アップリフトモデリング⑤",
          "演習：アップリフトモデリング⑥"
        ],
        "終わりに": [
          "参考資料"
        ]
      },
      "requirements": [
        "Pythonのプログラミング経験があるとよいですが、なくても問題ありません"
      ],
      "description": "データ分析や機械学習の分野において、正しく因果関係を理解し、データに基づく意思決定を行うことが年々重要になってきました。このような学問分野は因果推論と呼ばれ、近年注目され始めています。\nしかし、データから因果関係を知ろうとすると、そこにはさまざまなトラップが潜んでおり、正しく推定することが難しく、誤った結論につながってしまうことがあります。\nそこで本コースでは、因果推論の理論を学びながらPythonを使って実践することで、データから効果を推定する手法を学んでいきます。\n\n\nコースの概要:\nイントロと擬似相関\nデータの見方と相関関係が生まれてしまう状況を紹介します。\n\nd分離\n因果関係の特定において、変数を特定するためにd分離は重要なツールとなります。因果効果の正確な推定に向けたd分離法やざっと学びます。PythonのDoWhyパッケージを用いて演習します。\n\n傾向スコアとIPW\n傾向スコアの定義と、逆確率重み付け（Inverse Probability Weighting、IPW）を使用した、因果効果の推論手法を学びます。これにより、観測データの偏りを補正し、より正確な因果関係の推定が可能になります。PythonのDoWhyパッケージを用いて演習します。\n\nMeta-learners\nMeta-Learnersという手法を使用して、因果効果を推定する手法を学びます。EconMLというPythonパッケージを用いて、S-Learner, T-Learner, X-Learnerを実装します。\n\nアップリフトモデリング\n顧客の行動や意思決定に対する効果を評価するための手法としてアップリフトモデリングを学びます。個々の特性に応じた効果を推定するためのスキルを習得します。\n\n\n対象と前提知識\n本コースは、データサイエンティストやアナリスト、マーケターなど、データを活用する方に向けて作られています。\nPythonの基本的な知識や機械学習の基本的な理解があるとよいですが、必須ではありません。",
      "target_audience": [
        "因果推論に興味がある方",
        "データを用いて効果の検証をする必要がある方",
        "因果推論をこれから学びたいデータサイエンティストやアナリスト、マーケターの方"
      ]
    },
    {
      "title": "【超実践】SQLのデータ加工集計100本ノック！BigQueryで学ぶSQLの超実践講座！",
      "url": "https://www.udemy.com/course/sql100bq/",
      "bio": "あなたは何問解けるか！？データ分析者必見のSQLのデータ加工集計100本ノック！BigQuery上のお酒の小売データを題材にしたSQL100問に挑戦しよう！",
      "objectives": [
        "SQLの基礎について学ぶ",
        "Google CloudのBigQueryの使い方について学ぶ",
        "実践的な100本ノックを通して網羅的にSQLを復習しつつ腕試しを行う",
        "お酒の小売データを使った実践的な複雑なクエリの扱い方について学ぶ"
      ],
      "course_content": {
        "はじめに": [
          "はじめに"
        ],
        "SQL基礎": [
          "SQL概要",
          "DB-FIDDLE",
          "DB-FIDDLE使い方",
          "テーブル作成とSELECT文",
          "WHERE句",
          "集計関数",
          "GROUP BY句",
          "ORDER BY句",
          "条件分岐のCASE WHEN",
          "JOIN句",
          "JOIN句の種類とWITH句",
          "LEFT JOIN",
          "SQL構文の復習"
        ],
        "SQL100本ノック：1本目〜20本目": [
          "BigQueryの登録方法",
          "BigQueryの使い方",
          "100本ノック問題集と解答はこちらから確認してください",
          "乱数を発生させて新たなテーブルを作成しよう：ノック1本目",
          "【ノック前の注意】動画と結果を完全一致させたい場合",
          "WHERE句とORDER BY句などを使った集計：ノック2本目〜5本目",
          "LIKEを使った抽出条件絞り込み：ノック6本目〜9本目",
          "パーセンタイルや四捨五入や二乗など：ノック10本目〜15本目",
          "ユニークな値を集計しよう！：ノック16本目〜20本目"
        ],
        "SQL100本ノック：21本目〜60本目": [
          "グループごとにユニークな値を集計しよう！：ノック21本目〜24本目",
          "年・月・曜日を抽出して集計しよう！：ノック25本目〜30本目",
          "年・月の単位で集計しよう！：ノック31本目〜35本目",
          "条件分岐を使って新たな分類基準を作って集計しよう！：ノック36本目〜40本目",
          "累積売上やランク付与をやってみよう！：ノック41本目〜45本目",
          "テーブル結合をやってみよう！：ノック46本目〜47本目",
          "様々な結合方法を見ていこう！：ノック48本目〜50本目",
          "WITH句とランク関数を使った集計：ノック51本目〜52本目",
          "条件分岐を使ったカラム集計と日付の差集計：ノック53本目〜55本目",
          "HAVINGを使った条件絞り込み：ノック56本目〜58本目",
          "前年比較計算とQUALIFYを使った条件絞り込み：ノック59本目〜60本目"
        ],
        "SQL100本ノック：61本目〜100本目": [
          "相関係数の計算など：ノック61本目〜65本目",
          "【注意】66本目のノックの誤りについて",
          "DATE_ADDなどの日付の処理について見ていこう！：ノック66本目〜69本目",
          "日付の様々な処理と文字列結合：ノック70本目〜75本目",
          "様々な文字列処理を見ていこう！：ノック76本目〜80本目",
          "正規表現を使っていこう！：ノック81本目〜85本目",
          "様々な正規表現を使ってみよう！：ノック86本目〜89本目",
          "ARRAY型と日付の処理：ノック90本目〜93本目",
          "複雑な集計に挑戦しよう！①：ノック94本目〜95本目",
          "【注意】ノック96本目の問題について",
          "複雑な集計に挑戦しよう！②：ノック96本目〜97本目",
          "複雑な集計に挑戦しよう！③：ノック98本目〜100本目",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "SQLの基礎から学んでいきますのでプログラミングの経験は不要です"
      ],
      "description": "このコースではデータ分析をする際に頻出するSQLを使った加工・集計処理100問に取り組んでいきます。\n\n\nまず最初にSQLの基礎について構文を一通り学んだ後、実務でよく登場する小売データを用いて様々な処理を施していきます。\nSQLの実行環境として実務でよく使われるBigQueryを使っていきますよ！\n\n\n出来るだけ動画を見る前に自分の力で解けるか試してみることをオススメします。\n\n\n実力試しにも復習にも最適。ぜひ100問ノックに挑戦してみてください！",
      "target_audience": [
        "SQLの基礎を学びたい方",
        "100本ノックを通して実践的な力を身に付けたい方",
        "100本ノックを通して網羅的に復習したい方",
        "Google CloudのBigQueryで様々な構文を学びたい方"
      ]
    },
    {
      "title": "AIエンジニアが教えるRとtidymodelsによる機械学習と予測モデリング",
      "url": "https://www.udemy.com/course/r-tidymodels-predictive-modeling/",
      "bio": "データ分析プロジェクトの最重要タスクである予測モデリングの効率的なやり方を現役ＡＩエンジニアの立場からわかりやすく説明します．",
      "objectives": [
        "データ分析プロジェクトにおける予測モデリングの重要性",
        "Rとtidymodelsを使用するメリット",
        "機械学習と予測モデリングの概要",
        "tidymodelsによる予測モデリングの具体的な方法"
      ],
      "course_content": {
        "⓪本コースの紹介": [
          "概要",
          "モデリングと予測モデリング",
          "tidymodelsのメリット",
          "全体像",
          "参考資料",
          "コード"
        ],
        "①予測モデリング": [
          "概要",
          "機械学習ってなに？？",
          "教師あり学習",
          "教師なし学習",
          "強化学習",
          "予測モデリングってなに？？",
          "予測モデリングの全体像と目的",
          "予測モデリングの6つのSTEP",
          "予測モデリングと人間の学習プロセスの関係"
        ],
        "①予測モデリング　STEP１：探索的データ分析": [
          "探索的データ分析ってなに？？",
          "仮説立案",
          "合否基準立案"
        ],
        "①予測モデリング STEP２：データ分割": [
          "データ分割ってなに？？",
          "良いモデルの探し方",
          "データ分割の基本原則",
          "色々なデータ分割と交差検証"
        ],
        "①予測モデリング STEP３：学習ルール選定": [
          "学習ルール選定ってなに？？",
          "アルゴリズムとハイパラ",
          "tree系：決定木",
          "tree系：ランダムフォレスト",
          "tree系：勾配ブースティング",
          "linear系：線形回帰",
          "linear系：ニューラルネットワーク",
          "linear系：ディープラーニング"
        ],
        "①予測モデリング STEP4：特徴量エンジニアリング": [
          "特徴量エンジニアリングってなに？？",
          "数値変数の変換",
          "カテゴリ変数の変換",
          "欠損値の補間",
          "新特徴量の作成"
        ],
        "①予測モデリング STEP５：ハイパラチューニング": [
          "ハイパラチューニングってなに？？",
          "ハイパラ指定",
          "探索範囲指定",
          "グリッド作成",
          "学習と評価",
          "モデル選定",
          "予測値算出",
          "アンサンブル"
        ],
        "①予測モデリング STEP６：モデル検証": [
          "モデル検証ってなに？？",
          "モデル評価",
          "モデル整理",
          "モデル解釈"
        ],
        "①予測モデリング：補足": [
          "品質の低いデータからは品質の低い結果しか生まれない！！",
          "既知データと未知データは同傾向である！！",
          "analysisとassessmentは一般的な名称ではない！！"
        ],
        "②環境構築": [
          "概要",
          "Rのインストール",
          "RStudioのインストール",
          "RStudioの設定",
          "プロジェクトファイルの作成",
          "次のレクチャーの補足：windowsを使用する場合，ご注意ください．",
          "パッケージのインストール",
          ".Rprofileの作成"
        ]
      },
      "requirements": [
        "Rとtidyverseの基本的な知識（未経験でも受講可ですが，基本的な知識があるとより一層理解が深まります．）",
        "インターネットが使用できるパソコン（OSはなんでもOKですが，Windows推奨）",
        "MacのM1は非推奨（おそらく問題ないと思いますが，当コースで使用する開発環境を構築できるか未検証です．）"
      ],
      "description": "※ 本コースはRとtidyvverseが未経験でも受講できますが，Rとtidyverseの基本的な知識があるとより一層理解が深まります．\n\n\n本コースは，予測モデリングに特化しています．\n予測モデリングとは，データから予測したい項目を予測する技術のことです．\nビジネスにはとにかく不明確な問題が多いです．\n例えば\nこの部品の状態は正常か異常か？？\n今週の来客数はどれくらいだろうか？？\nこの製品はいつ頃出荷できるのだろうか？？\nみたいなことが挙げられます．\nこのような問題に対し，答えとなる予測値を算出する技術が予測モデリングです．\n例えば\nこの部品の状態は正常か異常か？？という問題に対し，異常と予測できれば，異常と予測した部品の出荷を取りやめるという方針が取れます．\nこのようにとある問題に対し，正確な予測ができるとビジネスにおいて有利な方針を取ることができるのです！\n\n\nそんな予測モデリングをするためのパッケージとしてPythonのscikit-learnが有名ですが，Rにもtidymodelsというパッケージがあります．\ntidymodels，ちょっと聞きなれないかもしれませんが，実は予測モデリングのパッケージとしてとても優秀なんです！\n予測モデリングにRとtidymodelsを使用するメリットは以下になります．\n\n\n・連携性：tidymodelsはtidyverseと相性がよく，前処理⇔モデリングの行き来をスムーズでできるため，効率的にデータ分析プロジェクトを実施することができる！！\n・収納性：構築したモデルをデータフレームに格納できる！！\n・統一性：分析コンペで人気のアルゴリズムである勾配ブースティング（XGBoost, LightGbm, CatBoost）のパッケージを統一的な文法で扱える！！\n・一貫性：tidymodelsだけで，データ分割，学習ルール選定，特徴量エンジニアリング，ハイパラチューニング，モデル検証といった予測モデリングのワークフローを実現できる！！\n\n\n本コースは，tidymodelsを利用し，予測モデリングのワークフローを習得することを目指します！\n\n\n★本コースの目的★\n機械学習の典型的な利用方法を学習し，データから予測したい項目をtidymodelsを使用して予測できるようにすること！！\n\n\n★本コースの特徴★\nとにかく現場主義！！\nコーディングはライブ形式！！\nコードだけでなく，イメージも！！\n\n★本コースの内容★\nコース紹介\n概要\nモデリングと予測モデリング\nなぜPythonのscikit-learnではなくRのtidymodelsなのか\n全体像\n機械学習と予測モデリング\n概要\n機械学習\nSTEP１：探索的データ分析\nSTEP２：データ分割\nSTEP３：学習ルール選定\nSTEP４：特徴量エンジニアリング\nSTEP５：ハイパラチューニング\nSTEP６：モデル検証\n環境構築\n概要\nRのインストール\nRStudioのインストール\nRStudioの設定\nプロジェクトファイルの作成\nパッケージのインストール\n.Rprofileの作成\ntidymodels\n概要\n{tidyverse}探索的データ分析\n{rsample}データ分割\n{parsnip}学習ルール設定\n{recipes}特徴量エンジニアリング\n{workflows}レシピ＋学習ルール\n{tune}，{dials}ハイパラチューニング\n{yardstick}モデル評価\n{broom}モデル整理\n{DALEX}モデル解釈\n総合演習\n概要\nSTEP１：探索的データ分析\nSTEP２：データ分割\nSTEP３：学習ルール選定\nSTEP４：特徴量エンジニアリング\nSTEP５：ハイパラチューニング\nSTEP６：モデル検証\n総括\nまとめ",
      "target_audience": [
        "データサイエンス，AI，機械学習に興味がある方",
        "scikit-learnで機械学習に挫折した方",
        "Rで機械学習をしてみたい方",
        "tidymodelsの使い方がよくわからない方"
      ]
    },
    {
      "title": "②米国AI開発者がやさしく教える深層学習超入門第二弾(画像認識)【Pythonで実践】",
      "url": "https://www.udemy.com/course/deeplearning2/",
      "bio": "画像系深層学習の基礎(CNN)",
      "objectives": [
        "深層学習の理論を深く理解することができます",
        "深層学習のCNNのモデル/学習をスクラッチで実装できるようになります",
        "深層学習の応用的な知識を使ってより高精度なモデルを構築できるようになります",
        "GPUを使って深層学習モデルを学習できるようになります"
      ],
      "course_content": {
        "紹介": [
          "紹介",
          "本講座の資料とコードについて",
          "補足教材"
        ],
        "環境準備": [
          "本セクションの補足(本講座用のDocker imageについて)",
          "環境構築概要(Docker + JupyterLab)",
          "M1チップをお使いの方へ",
          "DockerHubアカウント作成",
          "Windowsユーザへの補足",
          "Docker環境構築",
          "Dockerの基本操作",
          "次レクチャー補足",
          "JupyterLabの基本操作"
        ],
        "CNN (Convolutional Neural Network)": [
          "畳み込み層(Convolution Layer)",
          "畳み込み層の操作",
          "畳み込み層の実装【Python】",
          "畳み込み層のパラメータと複数channel",
          "畳み込み層の図式",
          "ストライドとパディング",
          "畳み込み層の出力サイズ",
          "CNN",
          "CNN構築【Python】",
          "CNN学習【Python】",
          "CNNと全結合層の関係",
          "まとめ"
        ],
        "プーリング層 (Pooling Layer)": [
          "Pooling Layer",
          "Max Pooling層の実装【Python】",
          "PytorchのMax Pooling【Python】",
          "Global Average Pooling (GAP)",
          "GAP実装【Python】",
          "PytorchのGAP層【Python】",
          "CNNにGAP層を適用【Python】",
          "まとめ"
        ],
        "初期の有名CNNモデル": [
          "初期の有名モデルについて",
          "LeNet",
          "LeNet実装【Python】",
          "AlexNet",
          "VGG",
          "Pytorchの組み込みモデル【Python】",
          "(補足)プログレスバー",
          "まとめ"
        ],
        "正則化": [
          "正則化について（L2正則とドロップアウト）",
          "L2正則（重み減衰）",
          "L2正則実装【Python】",
          "PytorchでL2正則【Python】",
          "L2正則で学習【Python】",
          "Dropout",
          "Dropout実装【Python】",
          "PytorchのDropout層【Python】",
          "まとめ"
        ],
        "正規化層 (バッチ正規化とレイヤー正規化)": [
          "バッチ正規化(Batch Normalization)",
          "内部共変量シフト",
          "Activationの分布",
          "Hook",
          "TensorにHookをつける【Python】",
          "Forward Hook 【Python】",
          "Backward Hook【Python】",
          "次レクチャーの補足",
          "Activation分布の可視化",
          "バッチ正規化",
          "畳み込み層におけるバッチ正規化",
          "予測時のバッチ正規化の操作",
          "バッチ正規化実装【Python】",
          "バッチ正規化層を組み込んで学習【Python】",
          "バッチ正規化と正則化",
          "レイヤー正規化(Layer Normalization)",
          "レイヤー正規化実装【Python】",
          "Layer Normalizationを組み込んで学習【Python】",
          "まとめ"
        ],
        "重み初期化": [
          "重み初期化",
          "勾配消失/爆発",
          "Xavierの初期化",
          "Kaiming初期化",
          "Xavier初期化とKaiming初期化実装【Python】",
          "PytorchによるKaiming初期化【Python】",
          "Batch Norm + Kaiming初期化【Python】",
          "まとめ"
        ],
        "応用的なOptimizer": [
          "SGDの問題点とMomentum",
          "指数移動平均(EMA)",
          "EMA実装【Python】",
          "Momentum実装【Python】",
          "PytorchでMomentumを使用【Python】",
          "RMSProp",
          "RMSProp実装【Python】",
          "PytorchでRMSPropを使用【Python】",
          "バイアス補正",
          "バイアス補正【Python】",
          "Adam",
          "Adam実装【Python】",
          "PytorchでAdamを使用【Python】",
          "まとめ"
        ],
        "さらに深いモデル": [
          "モデルをさらに深くする",
          "Skip Connection (residual connection: 残差接続)",
          "Residual Block",
          "Residual Block【Python】",
          "Point WiseとBottleneck",
          "Bottleneck実装【Python】",
          "ResNet",
          "Inception",
          "Inception Module【Python】",
          "GoogLeNet",
          "Depthwise Separable Conv",
          "MobileNet",
          "EfficientNet",
          "SEModule",
          "Swish活性化関数",
          "MBConvとEfficientNet",
          "まとめ"
        ]
      },
      "requirements": [
        "線形代数と微分の基礎知識があると良いです",
        "事前に統計学講座と機械学習講座を受講しておくことを強くお勧めします",
        "事前に第一弾(基本的なニューラルネットワーク)を受講ください",
        "Pythonの実装については，Pythonの基礎知識およびデータサイエンスに必要なライブラリの知識が必要です",
        "Pythonの知識がなくても本講座で深層学習の理論を学習することができます"
      ],
      "description": "※本講座は全３部構成である深層学習超入門の\"第二弾\"です\n画像系の深層学習の基礎をゼロから学べます．学習した理論をPythonでスクラッチで実装し，理論x実装の相乗効果で確実に深層学習を習得できます．\nまた，Pytorchを使用して深層学習のモデル学習も行うので，実務にも即応用できる内容です．\n(全3部構成で，本講座は「第二弾」となっており，主に画像系の深層学習であるCNNの基本や少し応用的なアルゴリズム/テクニックを解説しています．)\n【特徴】\n- 現役のAI開発者から学ぶ\n- 実際の現場でどのように使うのかを解説\n- 完全体系的に学ぶ\n- アルゴリズムのスクラッチ実装により完全に理解して進める\n- 数式を丁寧に解説\n- 図を多用しイメージで学ぶ\n- Pytorchでの実装も紹介\n- 学習したことをすぐに実データに適用可能\n- DockerとJupyterLabを使った本格データサイエンス環境 (Dockerを使って簡単環境構築)\n- これ1本で理論x実装が同時に，着実に学べる\n\n\n深層学習の理論とPythonの実装のレクチャーは別になっているため，理論だけを学習することも可能です．そのためPythonを知らなくても本講座で深層学習を学ぶことができます．\n\n\nPythonの実装のレクチャーは，Pythonの基礎知識とデータサイエンスに必要なPython(NumpyやMatplotlibなど)の知識が必要です．\nMacを使って講義を進めますが，環境が作れればWindowsでも問題ありません．\nDockerとJupyterLabを使った本格的なデータサイエンスの環境を使いますが，WindowsでDocker環境を作れれば，全く同じ環境を構築することができます．(Windowsでの環境構築のサポートはしておりません．あらかじめご了承ください)",
      "target_audience": [
        "AI開発やデータサイエンスに興味がある人",
        "データサイエンスのコンペ等に出たい人",
        "研究や授業で深層学習を勉強する必要がある人",
        "深層学習の基本を学びたい人",
        "これからAI開発のキャリアを目指している人"
      ]
    },
    {
      "title": "[AR] دورة ماجستير في هندسة الذكاء الاصطناعي (AI)",
      "url": "https://www.udemy.com/course/artificial-intelligence-bootcamp-arabic/",
      "bio": "إتْقِن هندسة الذكاء الاصطناعي: ابني، درّب، وانشر حلول ذكاء اصطناعي قابلة للتوسيع من خلال مشروعات واقعية وتعلُّم عملي.",
      "objectives": [
        "قم ببناء نماذج ذكاء اصطناعي باستخدام Python وTensorFlow وPyTorch لإنشاء أنظمة ذكية قادرة على حل مشكلات العالم الحقيقي",
        "قم بتهيئة البيانات وتنظيفها وتحليلها لضمان مدخلات عالية الجودة لتدريب نماذج التعلم الآلي والذكاء الاصطناعي",
        "درّب، وقيّم، وحسّن نماذج التعلم الآلي لمهام مثل الانحدار، والتصنيف، والتجميع",
        "صمّم، وطبّق، وحرّر الشبكات العصبية بدقة، بما في ذلك الشبكات الالتفافية (CNNs) والشبكات التكرارية (RNNs) لتطبيقات الذكاء الاصطناعي المتقدمة",
        "استخدم تقنيات معالجة اللغة الطبيعية (NLP) لتحليل وتفسير وإنشاء نصوص شبيهة بالنصوص البشرية",
        "استفد من التعلم بالنقل لتكييف النماذج المدربة مسبقًا لمهام جديدة، مما يقلل من وقت التطوير والموارد",
        "انشر نماذج الذكاء الاصطناعي باستخدام واجهات برمجة تطبيقات قابلة للتوسيع وأدوات الحاويات مثل Docker لتكامل سلس مع التطبيقات",
        "راقب أداء نماذج الذكاء الاصطناعي، واكتشف انحراف البيانات، وأنشئ سير عمل لإعادة التدريب لضمان الثبات والموثوقية",
        "حلّ التحديات التجارية والتقنية في العالم الحقيقي باستخدام منهجيات قائمة على الذكاء الاصطناعي وأنظمة ذكية",
        "طوّر مشاريع ذكاء اصطناعي شاملة من الفكرة والنموذج الأولي إلى النشر والصيانة طويلة المدى"
      ],
      "course_content": {
        "مقدمة عن الدورة": [
          "مقدمة في ماستر كلاس هندسة الذكاء الاصطناعي: من الصفر إلى بطل الذكاء الاصطناعي",
          "موارد الدورة – ملفات العرض التقديمي والشفرة البرمجية"
        ],
        "الأسبوع الأول: أساسيات برمجة بايثون للذكاء الاصطناعي": [
          "مقدمة عن أساسيات بايثون",
          "اليوم 1: مقدمة في بايثون وإعداد بيئة التطوير",
          "اليوم 2: التحكم في تدفق البرامج",
          "اليوم 3: الدوال والوحدات (Modules)",
          "اليوم 4: هياكل البيانات (القوائم، التابلو، القواميس، المجموعات)",
          "اليوم 5: التعامل مع السلاسل النصية",
          "اليوم 6: إدارة الملفات",
          "اليوم 7: كتابة كود بايثوني عملي ومشروع تطبيقي"
        ],
        "الأسبوع الثاني: أساسيات علوم البيانات للذكاء الاصطناعي": [
          "مقدمة عن علوم البيانات",
          "اليوم 1: مقدمة في NumPy للحسابات الرقمية",
          "اليوم 2: العمليات المتقدمة في NumPy",
          "اليوم 3: مقدمة في Pandas لمعالجة البيانات",
          "اليوم 4: تنظيف البيانات باستخدام Pandas",
          "اليوم 5: التجميع في Pandas",
          "اليوم 6: التصوير البياني باستخدام Matplotlib وSeaborn",
          "اليوم 7: مشروع تحليل بيانات استكشافية"
        ],
        "الأسبوع الثالث: الرياضيات في تعلم الآلة والذكاء الاصطناعي": [
          "مقدمة عن الرياضيات",
          "اليوم 1: أساسيات الجبر الخطي",
          "اليوم 2: مفاهيم متقدمة في الجبر الخطي",
          "اليوم 3: التفاضل في تعلم الآلة",
          "اليوم 4: التكامل والتحسين",
          "اليوم 5: نظرية الاحتمالات والتوزيعات",
          "اليوم 6: أساسيات الإحصاء",
          "اليوم 7: مشروع رياضي – الانحدار الخطي من الصفر"
        ],
        "الأسبوع الرابع: الاحتمالات والإحصاء في تعلم الآلة والذكاء الاصطناعي": [
          "مقدمة عن الاحتمالات والإحصاء",
          "اليوم 1: نظرية الاحتمالات والمتغيرات العشوائية",
          "اليوم 2: التوزيعات الاحتمالية",
          "اليوم 3: الاستدلال الإحصائي",
          "اليوم 4: اختبار الفرضيات وقيمة P",
          "اليوم 5: أنواع اختبارات الفرضيات",
          "اليوم 6: التحليل الارتباطي والانحداري",
          "اليوم 7: مشروع تحليل إحصائي باستخدام بيانات حقيقية"
        ],
        "الأسبوع الخامس: مقدمة في تعلم الآلة": [
          "مقدمة عن تعلم الآلة",
          "اليوم 1: مفاهيم ومصطلحات أساسية",
          "اليوم 2: التعلم تحت الإشراف والنماذج الانحدارية",
          "اليوم 3: النماذج الانحدارية المتقدمة",
          "اليوم 4: التصنيف والانحدار اللوجستي",
          "اليوم 5: تقييم النماذج والتحقق المتقاطع",
          "اليوم 6: خوارزمية الجار الأقرب (k-NN)",
          "اليوم 7: مشروع عملي للتعلم تحت الإشراف"
        ],
        "الأسبوع السادس: هندسة الميزات وتقييم النماذج": [
          "مقدمة عن هندسة الميزات",
          "اليوم 1: مقدمة في استخراج الميزات",
          "اليوم 2: تطبيع وتحجيم البيانات",
          "اليوم 3: ترميز البيانات الفئوية",
          "اليوم 4: تقنيات اختيار الميزات",
          "اليوم 5: إنشاء وتحويل الميزات",
          "اليوم 6: تقنيات تقييم النماذج",
          "اليوم 7: التحقق المتقاطع وضبط المعلمات"
        ],
        "الأسبوع السابع: خوارزميات تعلم الآلة المتقدمة": [
          "مقدمة عن الخوارزميات المتقدمة",
          "اليوم 1: التعلم التجميعي",
          "اليوم 2: Bagging والغابات العشوائية",
          "اليوم 3: Boosting والتعزيز التدرجي",
          "اليوم 4: مقدمة في XGBoost",
          "اليوم 5: LightGBM وCatBoost",
          "اليوم 6: التعامل مع البيانات غير المتوازنة",
          "اليوم 7: مشروع تعلم تجميعي – مقارنة النماذج"
        ],
        "الأسبوع الثامن: تحسين النماذج وضبطها": [
          "مقدمة عن الضبط والتحسين",
          "اليوم 1: ضبط المعلمات الفائقة",
          "اليوم 2: البحث الشبكي والبحث العشوائي",
          "اليوم 3: الضبط باستخدام التحسين البايزي",
          "اليوم 4: تقنيات التنظيم",
          "اليوم 5: تقييم النموذج والتحقق المتقاطع",
          "اليوم 6: ضبط آلي باستخدام GridSearchCV وRandomizedSearchCV",
          "اليوم 7: مشروع نهائي – بناء وتحسين النموذج النهائي"
        ],
        "الأسبوع التاسع: الشبكات العصبية والتعلم العميق": [
          "مقدمة في التعلم العميق",
          "اليوم 1: مقدمة في الشبكات العصبية",
          "اليوم 2: الانتشار الأمامي ودوال التنشيط",
          "اليوم 3: دوال الخسارة والتغذية العكسية",
          "اليوم 4: الانحدار التدرجي وتقنيات التحسين",
          "اليوم 5: بناء الشبكات العصبية باستخدام TensorFlow وKeras",
          "اليوم 6: بناء الشبكات باستخدام PyTorch",
          "اليوم 7: مشروع – تصنيف الصور باستخدام CIFAR-10"
        ]
      },
      "requirements": [
        "معرفة برمجية أساسية: يُفضَّل الإلمام بلغة Python، لكنه ليس شرطًا إلزاميًا.",
        "الفضول والحماس: الشغف بالذكاء الاصطناعي والرغبة في التعلم من الأمور الأساسية.",
        "الوصول إلى جهاز كمبيوتر: جهاز كمبيوتر متصل بالإنترنت وذو قدرة معالجة مناسبة لمهام الذكاء الاصطناعي.",
        "لا حاجة لخبرة سابقة في الذكاء الاصطناعي: الدورة تبدأ من المفاهيم الأساسية وتتدرج في التعمق.",
        "مهارات رياضية أساسية: فهم مفاهيم الرياضيات على مستوى المرحلة الثانوية (مثل الجبر والإحصاء البسيط).",
        "اتصال إنترنت مستقر: للوصول إلى محتوى الدورة والأدوات والمشاريع العملية.",
        "أدوات اختيارية: تثبيت Python وJupyter Notebook والمكتبات المتعلقة بالذكاء الاصطناعي (سيتم تقديم الإرشادات خلال الدورة).",
        "عقلية منفتحة: كن مستعدًا للاستكشاف والتجربة وبناء تطبيقات ذكاء اصطناعي واقعية."
      ],
      "description": "تم ترجمة هذه الدورة التدريبية باستخدام الذكاء الاصطناعي من الإنجليزية إلى الإسبانية حتى تتمكن من تعلم التقنيات المتطورة بلغتك الأم.\nمرحبًا بك في دورة \"هندسة الذكاء الاصطناعي الشاملة: من الصفر إلى بطل الذكاء الاصطناعي\"!\nهذه الدورة المتكاملة في الذكاء الاصطناعي مصممة لتأخذك في رحلة مثيرة تبدأ من مبتدئ في الذكاء الاصطناعي لتصبح مهندسًا واثقًا، مجهزًا بالمهارات اللازمة لبناء وتدريب ونشر حلول ذكاء اصطناعي قابلة للتطبيق في الواقع. سواء كنت تبدأ من الصفر أو ترغب في ترسيخ معرفتك بالذكاء الاصطناعي، فهذه الدورة تقدم لك خارطة طريق منظمة للنجاح خطوة بخطوة.\nفي هذه الدورة، ستبدأ بأساسيات الذكاء الاصطناعي، من خلال تعلم برمجة Python، معالجة البيانات، ومبادئ التعلم الآلي. ومع تقدمك، ستغوص في موضوعات متقدمة مثل الشبكات العصبية، التعلم العميق، معالجة اللغة الطبيعية (NLP)، ورؤية الحاسوب. كما ستحصل على خبرة عملية باستخدام أطر العمل المتقدمة مثل TensorFlow، PyTorch، وHugging Face لتطوير حلول ذكاء اصطناعي جاهزة للإنتاج.\nتركّز هذه الدورة على المهارات العملية، حيث يتضمن كل قسم مشروعًا واقعيًا يساعدك في تطبيق ما تعلمته. ستتعلم كيف تواجه تحديات الأعمال باستخدام تقنيات الذكاء الاصطناعي، وتحسّن نماذجك، وتنشر حلولًا قابلة للتوسيع.\nلماذا تختار دورة هندسة الذكاء الاصطناعي؟\nمنهج مناسب للمبتدئين: ابدأ من الصفر وتطور حتى تصبح خبيرًا\nمشاريع تطبيقية عملية: أنشئ تطبيقات ذكاء اصطناعي لحلول حقيقية\nإتقان أطر العمل الرئيسية: تعلّم TensorFlow، PyTorch، وHugging Face\nتدريب شامل: يشمل Python، التعلم الآلي، التعلم العميق، NLP ونشر النماذج\nخارطة طريق من الصفر إلى الاحتراف: مسار تعليمي منظم لتحقيق التميز في هندسة الذكاء الاصطناعي\nبنهاية هذه الدورة، لن تكون فقط قد أتقنت مهارات الذكاء الاصطناعي، بل ستكون مؤهلًا للابتكار، وقيادة المشاريع، وإحداث التغيير من خلال حلول AI داخل مؤسستك أو مشروعك الناشئ.\nسواء كنت مهندسًا طموحًا، أو شغوفًا بالذكاء الاصطناعي، أو تتطلع لدخول هذا المجال المتسارع، فهذه الدورة هي دليلك الشامل للانتقال \"من الصفر إلى بطل الذكاء الاصطناعي\".\nانضم لثورة الذكاء الاصطناعي اليوم – وسجل في دورة هندسة الذكاء الاصطناعي الشاملة: من الصفر إلى بطل الذكاء الاصطناعي، وابدأ أول خطوة نحو إتقان هذا المجال!",
      "target_audience": [
        "مهندسو الذكاء الاصطناعي الطموحون: الأفراد اللي عايزين يبدأوا مسيرتهم المهنية في الذكاء الاصطناعي من خلال مهارات عملية ومشروعات واقعية.",
        "علماء البيانات والمحللون: المحترفين اللي بيطمحوا لتوسيع خبراتهم في بناء ونشر نماذج الذكاء الاصطناعي.",
        "مطورو البرمجيات: المبرمجين اللي حابين يدمجوا قدرات الذكاء الاصطناعي في تطبيقاتهم وأنظمتهم.",
        "الأشخاص اللي بيغيروا مسارهم المهني: الأفراد من خلفيات غير تقنية اللي جاهزين يتحولوا لصناعة الذكاء الاصطناعي.",
        "طلاب الدراسات العليا: الطلاب في مجالات علوم البيانات، علوم الحاسب، أو المجالات ذات الصلة اللي بيدوروا على معرفة عملية في الذكاء الاصطناعي.",
        "رواد الأعمال التقنيون: المؤسسين والمديرين التقنيين اللي بيستكشفوا الذكاء الاصطناعي من أجل ابتكار المنتجات ونمو الأعمال.",
        "محبو الذكاء الاصطناعي: أي شخص عنده شغف بالذكاء الاصطناعي وعايز يبني أنظمة ذكية من الصفر.",
        "المحترفون في الأعمال: القادة اللي عايزين يفهموا الذكاء الاصطناعي علشان ياخدوا قرارات استراتيجية ويساهموا في نمو مؤسساتهم."
      ]
    },
    {
      "title": "【한글자막】 초보자를 위한 AWS SageMaker 실습 | 6개 프로젝트 구축하기",
      "url": "https://www.udemy.com/course/best-aws-sagemaker/",
      "bio": "세계적인 머신러닝, ML 클라우드 컴퓨팅 플랫폼인 AWS의 SageMaker 알고리즘 마스터 (선형 학습기, XG부스트, PCA, 이미지 분류) & SageMaker 스튜디오 학습 & 자동화 머신러닝",
      "objectives": [
        "AWS SageMaker를 활용한 AI/ML 모델 훈련 및 구현",
        "하이퍼 파라미터 최적화 검색을 통한 모델 파라미터 최적화",
        "선형 회귀 모형 개발, 훈련, 테스트 및 구현을 통한 미래 예측",
        "생산 수준 다중 다항 회귀 분석 모델을 구현해 주어진 특징을 기반으로 매장 매출 예측",
        "이미지 분류를 수행하기 위한 딥러닝 기반 모델 개발",
        "DeepAR을 사용해 미래의 제품 가격을 예측하는 시계열 예측 모델 개발",
        "SageMaker를 사용하여 정서 분석 모델을 개발 및 구현",
        "훈련된 NLP 모델을 구현하고 보안 API를 사용하여 상호 작용 및 예측",
        "SageMaker 내 알고리즘을 사용한 객체 감지 모델 훈련 및 평가"
      ],
      "course_content": {
        "소개, 수강 팁 & 모범 사례와 주요 학습 결과": [
          "강의 소개 및 인사말",
          "Udemy 리뷰 업데이트",
          "강의 팁과 모범 사례",
          "강의 개요 및 주요 학습 결과",
          "보너스 : 학습 경로"
        ],
        "AI/ML, 클라우드 컴퓨팅 소개": [
          "AWS 프리 티어 계정 설정 및 개요",
          "AI, 머신러닝, 딥러닝 소개 - 파트 #1",
          "AI, 머신러닝, 딥러닝 소개 - 파트 #2",
          "좋은 데이터 vs 나쁜 데이터",
          "AWS 및 클라우드 컴퓨팅 소개",
          "머신러닝 주요 컴포넌트 및 AWS Management Console 둘러보기",
          "AWS 리전 및 가용 영역",
          "아마존 S3",
          "아마존 EC2와 IAM",
          "AWS SageMaker 개요",
          "AWS SageMaker 세부 내용",
          "AWS SageMaker 스튜디오 개요",
          "AWS SageMaker 스튜디오 세부 내용",
          "SageMaker 모델 개발"
        ],
        "프로젝트 #1 - AWS SageMaker 선형 학습기를 사용한 급여 예측": [
          "프로젝트 개요",
          "단순 선형 회귀 직관",
          "최소 제곱합",
          "AWS SageMaker 선형 학습기 개요",
          "코딩 문제 #1A - AWS SageMaker 노트북 인스턴스(방법 #1)",
          "코딩 문제 #1B - AWS SageMaker 스튜디오 이용하기(방법 #2)",
          "코딩 문제 #2 - 주요 라이브러리 및 데이터 세트 가져오기",
          "코딩 문제 #3 - 탐색 데이터 분석",
          "코딩 문제 #4 - 데이터 세트 훈련 및 테스트",
          "코딩 문제 #5 - 사이킷런에서 선형 회귀 모델 훈련",
          "코딩 문제 #6 - 훈련된 모델 성능 평가",
          "코딩 문제 #7 - AWS SageMaker에서 선형 학습기 모델 훈련",
          "코딩 문제 #8 - SageMaker에서 모델 구현 및 엔드포인트 호출"
        ],
        "프로젝트 #2 - 의료 보험료 예측": [
          "프로젝트 개요 및 소개",
          "다중 선형 회귀 직관",
          "회귀 지표 및 KPIs - RMSE, MSE, MAE, MAPE",
          "회귀 지표 및 KPIs - R2 and Adjusted R2",
          "코딩 문제 #1 & #2 - 데이터 세트와 주요 라이브러리 가져오기",
          "코딩 문제 #3 - 탐색 데이터 분석",
          "코딩 문제 #4 - 데이터 시각화",
          "코딩 문제 #5 - 데이터 세트 훈련 및 테스트",
          "코딩 문제 #6 - 머신러닝 모델 로컬 훈련",
          "코딩 문제 #7 - AWS SageMaker에서 선형 학습기 모델 훈련",
          "코딩 문제 #8 - 모델 구현 및 엔드포인트 호출",
          "회귀 작업을 위한 인공신경망",
          "함수 활성화 - Sigmoid, RELU and Tanh",
          "다층 신경망 네트워크",
          "인공신경망 훈련 방법",
          "그래디언트 강하 알고리즘",
          "역전파 알고리즘",
          "코딩 문제 #9 - 회귀 작업을 위한 인공신경망 훈련"
        ],
        "프로젝트 #3 - AWS SageMaker XG부스트(회귀)를 사용한 가게 매출 예측": [
          "케이스 스터디 소개",
          "기초 : 편향과 분산의 차이",
          "기초 : L1 & L2 정규화 - 파트 #1",
          "기초 : L1 & L2 정규화 - 파트 #2",
          "XG부스트(익스트림 그래디언트 부스트) 알고리즘 소개",
          "부스팅이란?",
          "의사 결정 트리와 앙상블 학습",
          "그래디언트 부스트 트리 - 딥다이브 파트 #1",
          "그래디언트 부스트 트리 - 딥다이브 파트 #2",
          "AWS SageMaker XG부스트 알고리즘",
          "프로젝트 소개 및 노트북 인스턴스",
          "코딩 문제 #1 #2 #3 -데이터 세트/라이브러리 로드 및 데이터 탐색",
          "코딩 문제 #4 - 판다스를 이용해 데이터 프레임 병합 및 조작",
          "코딩 문제 #5 - 병합된 데이터 세트 탐색",
          "코딩 문제 #6 #7 - 데이터 세트 시각화",
          "코딩 문제 #8 - 데이터 훈련 준비",
          "코딩 문제 #9 - XG부스트 로컬 훈련",
          "코딩 문제 #10 - SageMaker로 XG부스트 훈련",
          "코딩 문제 #11 - XG부스트 엔드포인트 구현 및 예측",
          "코딩 문제 #12 - 하이퍼 파라미터 조정",
          "코딩 문제 #13 - 최적화된 하이퍼 파라미터로 모델 재훈련"
        ],
        "프로젝트 #4 - PCA & XG부스트(분류)를 사용한 심혈관 질환 예측": [
          "소개 및 프로젝트 개요",
          "주요 컴포넌트 분석 (PCA) 직관",
          "분류 작업을 위한 XG부스트(리뷰 강의)",
          "오차 행렬",
          "정밀도, 재현율, F1-점수",
          "Area Under Curve (AUC) and Receiver Operating Characteristics (ROC) 지표",
          "과대 적합과 과소 적합",
          "코딩 문제 #1 - SageMaker 스튜디오 노트북 설정",
          "코딩 문제 #2 & #3 - 데이터/라이브러리 가져오기 & 탐색 데이터 분석",
          "코딩 문제 #4 & #5 - 데이터 세트 시각화 & 데이터 훈련 및 테스트 준비",
          "코딩 문제 #6 - XG부스트 훈련 및 테스트 & 격자 검색(로컬 모드)",
          "코딩 문제 #7 - AWS SageMaker에서 PCA 모델 훈련",
          "코딩 문제 #8 - PCA 모델 엔드포인트 구현 및 호출",
          "코딩 문제 #9 - 분류 작업을 위한 XG부스트(SageMaker 내장) 훈련",
          "코딩 문제 #10 - 엔드포인트 구현, 추론 @ 테스트 모델"
        ],
        "프로젝트 #5 - AWS SageMaker를 사용한 교통 표지 분류 딥러닝": [
          "프로젝트 개요 및 소개",
          "컨볼루션 신경망에 대해 - 파트 #1",
          "컨볼루션 신경망에 대해 - 파트 #2",
          "CNN 성능 향상시키는 법",
          "오차 행렬",
          "레넷 네트워크 아키텍처",
          "AWS SageMaker 서비스 제한 증가",
          "코딩 문제 #1 #2 - 이미지 가져오기 및 시각화하기",
          "코딩 문제 #3 #4 - 훈련 및 테스트된 데이터 S3에 업로드",
          "코딩 문제 #5 - CNNs 구축 및 훈련",
          "코딩 문제 #6 - SageMaker로 훈련된 모델 구현"
        ],
        "프로젝트 #6 - SageMaker 스튜디오 딥다이브, 자동화 머신러닝": [
          "케이스 스터디 개요 : 비즈니스에서의 AI",
          "비즈니스에서의 AI 소개 : AWS와 함께",
          "읽을거리: 비즈니스에서 AI 적용",
          "퀴즈: 비즈니스에서 AI 적용하기",
          "보험료 프로젝트 개요",
          "단순 및 다중 선형 회귀",
          "AWS 101 [리뷰 강의/선택 사항]",
          "S3, EC2 [리뷰 강의/선택 사항]",
          "AWS SageMaker [리뷰 강의/선택 사항]",
          "회귀 지표 [리뷰 강의/선택 사항]",
          "AWS SageMaker 오토파일럿 데모 #1",
          "AWS SageMaker 오토파일럿 데모 #2",
          "AWS SageMaker 오토파일럿 데모 #3"
        ],
        "완강을 축하합니다! 선물 받아가는 것을 잊지 마세요!": [
          "보너스: ML 및 AI를 위한 Cloud 기술(쿠폰 동봉)",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "프로그래밍 기초 지식",
        "AWS 기초 지식",
        "머신 러닝 기초 지식"
      ],
      "description": "초보자를 위한 AWS SageMaker 실습 강의!\n데이터 엔지니어링 및 AWS 서비스, 머신러닝, 딥러닝을 한 강의에서 배워보세요!\n6개의 실습 위주 프로젝트 포함!\n\n\n초보자를 위한 AWS SageMaker 실습 강의를 선택해야 하는 이유\n기술 분야에서 가장 화두는 머신러닝과 딥 러닝입니다! 은행, 의료, 운송, 기술에 이르기까지 다양한 분야에서 머신러닝과 딥러닝을 채택하고 있습니다.\nAWS는 전 세계적으로 가장 널리 사용되는 머신러닝, ML 클라우드 컴퓨팅 플랫폼 중 하나입니다. Fortune지 선정 500대 기업 중 일부는 AWS로 비즈니스를 운영하고 있습니다.\nSageMaker는 데이터 과학자와 AI 실무자가 빠르고 효율적으로 AI/ML 모델을 학습 , 테스트, 구현할 수 있도록 하는 AWS 내 완전 관리형 서비스입니다.\n이 강의에서는 AWS SageMaker를 사용하여 AI/ML 모델을 만드는 방법을 배웁니다. 프로젝트에서는 비즈니스, 의료 및 기술 등 다양한 주제를 다룹니다.\n\n\n이 강의는 AWS SageMaker에 대한 기초 이해를 바탕으로 현실 문제를 해결하고자 하는 초보 개발자와 데이터 과학자를 대상으로 합니다. 머신러닝, 파이썬 프로그래밍 및 AWS 클라우드에 대한 기본 지식을 갖고 있는 분이면 좋습니다. 다음은 이 강의의 대상 수강생입니다 :\n진로를 개척하고 포트폴리오를 만들고자 하는 초보 데이터 과학자\nSageMaker를 사용한 AI/ML로 비즈니스 변혁을 꾀하는 베테랑 컨설턴트\n데이터 사이언스 & AI에 대한 열정이 가득한 분 혹은 AWS SageMaker를 사용하여 실무 경험을 쌓고자 하는 분\n\n\n초보자를 위한 AWS SageMaker 실습 강의는 아래와 같이 진행 됩니다\n실습을 통해 다음과 같은 주제를 마스터 할 수 있습니다 :\n(1) 데이터 엔지니어링 및 피처 엔지니어링,\n(2) AI/ML 모델 선택,\n(3) 비즈니스 문제 해결을 위한 적절한 AWS SageMaker 알고리즘 선택,\n(4) AI/ML 모델 구축, 학습 및 배치,\n(5) 모델 최적화 및 하이퍼 파라미터 조정\n\n\n이 강의에서는 데이터 엔지니어링, AWS 서비스 및 알고리즘, 머신/딥 러닝 기초와 같은 다양한 주제를 실무적으로 다룹니다 :\n\n\n데이터 엔지니어링: 데이터 타입, 주요 파이썬 라이브러리(판다스, 넘파이, 사이킷런, 맷플롯립 및 씨본), 데이터 분배 및 피처 엔지니어링(인풋, 비우기, 인코딩 및 정규화)\nAWS 서비스 및 알고리즘: 아마존 SageMaker, 선형 학습기(회귀/분류), 아마존 S3 스토리지 서비스, 그래디언트 부스트 트리(XG부스트), 이미지 분류, PCA, SageMaker 스튜디오 및 자동화 머신러닝\n머신러닝 및 딥러닝 기초: 피드포워드 ANN, 컨볼루션 신경망(CNN), 활성화 함수(시그마이드, RELU 및 쌍곡선 접선), 머신러닝 학습 전략(감독/비감독), 그래디언트 강하 알고리즘, 학습 속도, 역전파, 편향, 편향, 분산, 정규화(L1 및 L2) 등의 인공 신경망(ANN) 유형, 과대 적합, 드롭아웃, 특징 검출기, 풀링, 배치 정규화, 소멸 그래디언트, 오차 행렬, 정밀도, 재현율, F1-점수, 루트 평균 제곱 오차(RMSE), 앙상블 학습, 의사 결정 트리 및 랜덤 포레스트\n\n\n실습 위주 프로젝트를 통해 SageMaker의 광범위한 ML 및 DL 도구를 배울 수 있습니다 :\n프로젝트 #1: AWS SageMaker 선형 학습기를 사용하여 직원의 급여를 예측하는 간단한 회귀 모델 훈련, 테스트 및 구현합니다.\n프로젝트 #2: 의료 보험료를 예측하기 위해 다중 선형 회귀 머신러닝 모델을 학습, 테스트 및 구현합니다.\n프로젝트 #3: XG부스트 회귀 분석을 사용하여 가게 매출을 예측하고 SageMaker 하이퍼 파라미터 조정 툴을 사용하여 하이퍼 파라미터를 최적화하는 모델을 학습, 테스트 및 구현합니다.\n프로젝트 #4: SageMaker에 있는 PCA 알고리즘을 사용하여 차원 축소를 수행하고 심혈관 질환을 예측할 수 있는 XG부스트 분류 모델을 구축합니다.\n프로젝트 #5: Sagmaker와 Tensorflow를 사용하여 교통 표지 분류 모델을 개발합니다.\n프로젝트 #6: AWS SageMaker 스튜디오 딥다이브, 자동화 머신러닝, 모델 디버깅\n\n\n\n\nLigency Team의 한마디!\n# 22/04/2021 업데이트 - AWS SageMaker 오토파일럿 케이스 스터디를 추가했습니다.\n# 23/04/2021 업데이트 - 코드 스트립트 및 Q&A 버그가 업데이트 되었습니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다 :)\n\n\n이제 경력을 한 단계 더 끌어올릴 준비가 되셨습니까? 지금 등록하십시오!\n\n\n지금 바로 강의에 등록하세요! 강의에서 뵙기를 기대하고 있겠습니다.\n\n\n-Ligency Team",
      "target_audience": [
        "AI 실무자",
        "데이터 과학자 지망생",
        "기술 분야에 관심 있는 분",
        "데이터 과학 컨설턴트"
      ]
    },
    {
      "title": "120+ Ćwiczeń w języku Python - Data Science - NumPy",
      "url": "https://www.udemy.com/course/python-data-science-numpy-cwiczenia/",
      "bio": "Potęga NumPy w Data Science: 120+ praktycznych ćwiczeń w języku Python dla profesjonalistów od danych!",
      "objectives": [
        "rozwiąż ponad 120 ćwiczeń w NumPy",
        "zajmij się rzeczywistymi problemami występującymi w data science",
        "pracuj z dokumentacją i Stack Overflow",
        "gwarantowane wsparcie instruktora"
      ],
      "course_content": {
        "Konfiguracja (opcjonalnie)": [
          "Info",
          "Wprowadzenie do Google Colab",
          "Instalacja Anacondy - Windows 10",
          "Wprowadzenie do programu Spyder",
          "Instalacja Anacondy - Linux (Ubuntu)"
        ],
        "Wskazówki": [
          "Kilka słów od autora"
        ],
        "Starter": [
          "Ćwiczenie 0",
          "Rozwiązanie 0",
          "NumPy - Intro"
        ],
        "Ćwiczenia 1-10": [
          "Ćwiczenie 1",
          "Rozwiązanie 1",
          "Ćwiczenie 2",
          "Rozwiązanie 2",
          "Ćwiczenie 3",
          "Rozwiązanie 3",
          "Ćwiczenie 4",
          "Rozwiązanie 4",
          "Ćwiczenie 5",
          "Rozwiązanie 5",
          "Ćwiczenie 6",
          "Rozwiązanie 6",
          "Ćwiczenie 7",
          "Rozwiązanie 7",
          "Ćwiczenie 8",
          "Rozwiązanie 8",
          "Ćwiczenie 9",
          "Rozwiązanie 9",
          "Ćwiczenie 10",
          "Rozwiązanie 10"
        ],
        "Ćwiczenia 11-20": [
          "Ćwiczenie 11",
          "Rozwiązanie 11",
          "Ćwiczenie 12",
          "Rozwiązanie 12",
          "Ćwiczenie 13",
          "Rozwiązanie 13",
          "Ćwiczenie 14",
          "Rozwiązanie 14",
          "Ćwiczenie 15",
          "Rozwiązanie 15",
          "Ćwiczenie 16",
          "Rozwiązanie 16",
          "Ćwiczenie 17",
          "Rozwiązanie 17",
          "Ćwiczenie 18",
          "Rozwiązanie 18",
          "Ćwiczenie 19",
          "Rozwiązanie 19",
          "Ćwiczenie 20",
          "Rozwiązanie 20"
        ],
        "Ćwiczenia 21-30": [
          "Ćwiczenie 21",
          "Rozwiązanie 21",
          "Ćwiczenie 22",
          "Rozwiązanie 22",
          "Ćwiczenie 23",
          "Rozwiązanie 23",
          "Ćwiczenie 24",
          "Rozwiązanie 24",
          "Ćwiczenie 25",
          "Rozwiązanie 25",
          "Ćwiczenie 26",
          "Rozwiązanie 26",
          "Ćwiczenie 27",
          "Rozwiązanie 27",
          "Ćwiczenie 28",
          "Rozwiązanie 28",
          "Ćwiczenie 29",
          "Rozwiązanie 29",
          "Ćwiczenie 30",
          "Rozwiązanie 30"
        ],
        "Ćwiczenia 31-40": [
          "Ćwiczenie 31",
          "Rozwiązanie 31",
          "Ćwiczenie 32",
          "Rozwiązanie 32",
          "Ćwiczenie 33",
          "Rozwiązanie 33",
          "Ćwiczenie 34",
          "Rozwiązanie 34",
          "Ćwiczenie 35",
          "Rozwiązanie 35",
          "Ćwiczenie 36",
          "Rozwiązanie 36",
          "Ćwiczenie 37",
          "Rozwiązanie 37",
          "Ćwiczenie 38",
          "Rozwiązanie 38",
          "Ćwiczenie 39",
          "Rozwiązanie 39",
          "Ćwiczenie 40",
          "Rozwiązanie 40"
        ],
        "Ćwiczenia 41-50": [
          "Ćwiczenie 41",
          "Rozwiązanie 41",
          "Ćwiczenie 42",
          "Rozwiązanie 42",
          "Ćwiczenie 43",
          "Rozwiązanie 43",
          "Ćwiczenie 44",
          "Rozwiązanie 44",
          "Ćwiczenie 45",
          "Rozwiązanie 45",
          "Ćwiczenie 46",
          "Rozwiązanie 46",
          "Ćwiczenie 47",
          "Rozwiązanie 47",
          "Ćwiczenie 48",
          "Rozwiązanie 48",
          "Ćwiczenie 49",
          "Rozwiązanie 49",
          "Ćwiczenie 50",
          "Rozwiązanie 50"
        ],
        "Ćwiczenia 51-60": [
          "Ćwiczenie 51",
          "Rozwiązanie 51",
          "Ćwiczenie 52",
          "Rozwiązanie 52",
          "Ćwiczenie 53",
          "Rozwiązanie 53",
          "Ćwiczenie 54",
          "Rozwiązanie 54",
          "Ćwiczenie 55",
          "Rozwiązanie 55",
          "Ćwiczenie 56",
          "Rozwiązanie 56",
          "Ćwiczenie 57",
          "Rozwiązanie 57",
          "Ćwiczenie 58",
          "Rozwiązanie 58",
          "Ćwiczenie 59",
          "Rozwiązanie 59",
          "Ćwiczenie 60",
          "Rozwiązanie 60"
        ],
        "Ćwiczenia 61-70": [
          "Ćwiczenie 61",
          "Rozwiązanie 61",
          "Ćwiczenie 62",
          "Rozwiązanie 62",
          "Ćwiczenie 63",
          "Rozwiązanie 63",
          "Ćwiczenie 64",
          "Rozwiązanie 64",
          "Ćwiczenie 65",
          "Rozwiązanie 65",
          "Ćwiczenie 66",
          "Rozwiązanie 66",
          "Ćwiczenie 67",
          "Rozwiązanie 67",
          "Ćwiczenie 68",
          "Rozwiązanie 68",
          "Ćwiczenie 69",
          "Rozwiązanie 69",
          "Ćwiczenie 70",
          "Rozwiązanie 70"
        ]
      },
      "requirements": [
        "Ukończone kursy ze ścieżki Python Developer na tym koncie instruktorskim",
        "Ukończone kursy ze ścieżki Data Scientist na tym koncie instruktorskim",
        "Podstawowa wiedza na temat NumPy"
      ],
      "description": "To kurs, który pozwoli Ci na pogłębienie wiedzy na temat manipulacji danymi i analizy danych za pomocą biblioteki NumPy, która jest kluczowym narzędziem dla każdego specjalisty od data science pracującego z językiem Python.\nNumPy, skrót od Numerical Python, jest to biblioteka, która dostarcza wydajne struktury danych dla pracy z liczbami, szczególnie na dużych tablicach danych. Jest to podstawa dla większości pakietów Pythona używanych w data science, w tym Pandas, Matplotlib i Scikit-learn.\nKurs ten składa się z ponad 120 ćwiczeń, które pokrywają szeroki zakres tematów związanych z NumPy, od podstawowych operacji na tablicach, przez bardziej zaawansowane funkcje, takie jak indeksowanie, sortowanie, statystyka i algebra liniowa, po zastosowania NumPy w prawdziwych problemach analizy danych.\nDla każdego ćwiczenia dostępne są szczegółowe rozwiązania, które umożliwiają uczestnikom porównanie swojego podejścia z optymalnym rozwiązaniem, zrozumienie potencjalnych błędów i nauczenie się lepszego podejścia do problemu.\nTen kurs to doskonały wybór dla tych, którzy chcą opanować NumPy i stać się bardziej kompetentnymi w data science z użyciem Pythona. Bez względu na to, czy jesteś początkującym w data science, czy doświadczonym analitykiem, ten kurs pomoże Ci udoskonalić swoje umiejętności i zrozumieć, jak efektywnie wykorzystać moc NumPy.\n\n\nNumPy – Fundament obliczeń numerycznych w Pythonie\nNumPy (Numerical Python) to wydajna biblioteka do obliczeń numerycznych i pracy z wielowymiarowymi tablicami (ndarray) w Pythonie. Zapewnia szybkie operacje matematyczne, statystyczne, algebraiczne i logiczne na dużych zbiorach danych. Dzięki implementacji w C, NumPy oferuje wysoką wydajność, a jego funkcjonalność stanowi podstawę dla wielu innych bibliotek, takich jak Pandas, SciPy czy TensorFlow. Idealna do analizy danych, obliczeń naukowych i inżynieryjnych.",
      "target_audience": [
        "Początkujący programiści Python",
        "Przyszli Data Scientistci, analitycy danych i inżynierowie uczenia maszynowego",
        "Osoby przygotowujące się do rozmów kwalifikacyjnych w obszarze Data Science",
        "Studenci kierunków technicznych (informatyka, matematyka, ekonometria, inżynieria)"
      ]
    },
    {
      "title": "데이터 리터러시 - 데이터 읽고 쓰기의 기술",
      "url": "https://www.udemy.com/course/maso-ds-excel-onc39/",
      "bio": "분석에서 활용까지",
      "objectives": [
        "실무에서 익숙하게 다루는 엑셀로 데이터 분석 방법 학습",
        "데이터에 맞는 시각화를 하는 방법 학습",
        "데이터 분석을 통해 문제해결 방법을 습득하고 설득력 향상",
        "실제 데이터셋을 기반으로 직접 실습해보며 실무 능력 확보"
      ],
      "course_content": {},
      "requirements": [
        "실습 위주의 강의로, 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기 활용을 권장 드립니다.",
        "Windows OS 기반으로 실습이 진행되므로, Windows 환경에서의 강의 수강을 추천 드립니다.",
        "데이터 분석에 대한 사전 지식은 필요 없습니다.",
        "엑셀에 대한 지식이 있으면 도움이 되나, 필수 사항은 아닙니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n\n\n데이터를 읽으니 돈이 되었다!\n“영수증 드릴까요?”\n“아뇨, 버려주세요~”\n\n\n제품을 구매하면 받는 영수증. 그 안에는 고객, 단가 등 제품에 대한 데이터가 가득합니다.\n무심코 버리는 영수증처럼, 우리는 수많은 일상 속 데이터를 무심코 지나가고 있진 않을까요?\n‘데이터’는 누군가에게는 먼 존재 같지만,\n사실 일상에서 우리와 함께하는 모든 것이 데이터이며 모든 것을 데이터화 할 수 있습니다.\n이러한 데이터의 가치를 읽고 활용할 수 있다면 우리는 또다른 하나의 성과를 만들어낼 수 있을 것입니다.\n\n\n비즈니스 성공 방정식, 데이터 리터러시\n데이터 홍수라고 불릴 만큼, 비즈니스 현장에는 방대한 양의 데이터가 넘쳐나고 있습니다.\n우리가 각자의 분야에서 제 능력을 발휘하기 위해서는 이 홍수를 헤엄쳐갈 기초 체력이 필요합니다.\n바로, 데이터 리터러시 입니다.\n\n\n데이터 리터러시란, 데이터를 언어처럼 읽고 이해하고 분석하며 비판적으로 활용할 수 있는 능력을 말합니다.\n우리는 데이터를 효과적으로 이해할 때 비로소 데이터 품질을 높이고,\n보다 전문적이고 고차원적인 데이터 분석을 통해 데이터 속에 숨어있는 인사이트를 도출할 수 있습니다.\n\n\n\n\n이렇게만 하면 된다. 누구보다 빠르게, 그러나 탄탄하게!\n데이터 리터러시 완전 정복 방법\n\n\nSTEP 1. 데이터 개념부터, 데이터 기반 의사결정까지 알찬 기초 다지기\n‘데이터’라는 단어가 낯선 사람이라도 부담 없이 시작할 수 있도록 데이터 개념과 종류부터 차근차근 쌓아가며\n데이터 기반 의사결정과 데이터 중심 조직의 중요성과 의미까지 쉽게 이해할 수 있도록 합니다.\n\n\nSTEP 2. 어렵게 하지 말고 익숙한 엑셀로 데이터 분석\n파이썬, R처럼 프로그래밍 언어를 꼭 알아야 데이터 분석을 할 수 있을까요?\n아닙니다!\n실무에서 익숙하게 다루는 엑셀로 ‘제대로’ 데이터를 분석하는 법을 처음부터 끝까지 다 알려드립니다.\n\n\nSTEP 3. 우리가 주목할 것, 분석 도구 사용법❌, 데이터 분석 역량⭕\n이 강의는 단순히 엑셀의 기능을 설명하는 강의가 아닙니다.\n업무에서 마주하는 실제 비즈니스 문제들을 실제 데이터셋을 기반으로,\n데이터 수집부터 전처리, 분석, 시각화를 한번에 진행하여 인사이트를 도출하고 문제를 해결합니다.\n데이터를 어떻게 바라보고 해석, 활용할지 자연스레 익히게 되며,\n강의가 끝난 후에는 누구나 데이터 기반으로 사고하고 자신의 업무에 데이터 분석 역량을 바로 활용할 수 있을 것입니다.\n\n\n*본 과정은 MSIQ 데이터사이언스마스터/디지털마케팅마스터 자격을 보유한 마소캠퍼스 콘텐츠랩의 자체 개발 평가 문항이 포함되어 있습니다.[민간자격 등록번호 : 2020-005943(데이터사이언스)/2020-005944(디지털마케팅)]\n\n\n[ 강 사 소 개 ]\n\n\n김 진\n現 마소캠퍼스 대표\n서울대학교 MBA 졸업\n오라클, 네이버를 거쳐 중국 네이버 개발 아웃소싱 센터를 설립 및 지휘하였으며, 서울대 MBA 졸업 후 글로벌 모바일 기업인 Obigo로 옮겨 데이터 분석에 기반한 성과 관리 시스템 도입 등 국내외 다양한 사업 영역을 개척하였습니다. 2010년에는 게임웹진 플레이포럼 M&A 후 데이터 분석과 디지털 마케팅을 실무에 본격 도입해 코리안클릭 수치 기준으로 월 평균 활성유저(MAU) 238만, 월 평균 페이지뷰(PV)수 1,700만을 달성하였습니다. 개발자, 전문 경영인의 길을 걸어온 사업가로서 폭넓은 경험과 IT 기술을 융합해 현재는 기업의 ROI를 높여줄 실무 전문가 교육에 힘쓰고 있습니다.",
      "target_audience": [
        "데이터가 생소하고, 당장 데이터 보는 법부터 배우고 싶은 분들",
        "데이터에 대한 개념을 습득하고, 데이터를 읽고 활용하는 능력을 키우고 싶은 분들",
        "실무에서 자주 쓰는 엑셀로 데이터 분석하고 비즈니스 인사이트를 도출하고 싶은 분들",
        "찐-데이터셋을 분석하며 실무에 바로 적용할 수 있는 역량을 키우고 싶은 분들",
        "\"입사/직무전환/리스킬/탤런트 트랜스포메이션\"을 꿈꾸는 분들"
      ]
    },
    {
      "title": "【初心者・初級者向け】SQL・データ分析入門　-Bigquery×ハンズオン形式でスキルアップ-",
      "url": "https://www.udemy.com/course/sql-dataanalysis-for-beginner/",
      "bio": "多くの企業で採用されているクラウド環境BigQueryを使用。データ分析に欠かせないSQL技術を身に付けたいあなたへおすすめ！ウィンドウ関数も経験！ハンズオンでSQL学習していき、多くの練習問題をといていく実践形式のカリキュラム。",
      "objectives": [
        "未経験者・初心者・初級者でも SQLをかけるようになる",
        "データ分析に役立つスキルの基礎を身につけることができる",
        "データ分析スキルで重宝されるウィンドウ関数の経験ができる",
        "クラウド環境「BigQuery」を体験できる",
        "ハンズオン・練習問題でSQLを体系的に学べる"
      ],
      "course_content": {
        "はじめに": [
          "本講座について",
          "演習環境"
        ],
        "データベースとSQL": [
          "データベースとは",
          "SQLとは"
        ],
        "BigQueryの利用開始": [
          "BigQueryの環境を作る",
          "講座用資料ダウンロード",
          "サンプルデータ　概要",
          "サンプルデータ　登録",
          "補足：BigQueryのサンプルデータ"
        ],
        "基本的なSQL文": [
          "セクションの説明",
          "SQL内のコメント",
          "SQLのエラー",
          "データを抽出する基本的なSQL文 SELECT句, FROM句",
          "重複業をまとめる　DISTINCT",
          "別名に変更する　AS",
          "抽出する行数の制限　limit句",
          "抽出する行の並び替え　ORDER BY句",
          "グループ化を行う　GROUP BY句",
          "特定の条件で絞り込む　WHERE句",
          "SQLの中にSQLを書く　その１　サブクエリ",
          "SQLの中にSQLを書く　その２　WITH句"
        ],
        "【練習問題】基礎的なSQL文": [
          "練習問題１",
          "練習問題２",
          "練習問題３"
        ],
        "演算子": [
          "セクションの説明",
          "数値を計算（演算）する算出演算子",
          "値を比較する演算子",
          "真偽を確認したり、パターンを確認する論理演算子の概要",
          "論理演算子（１）AND、OR",
          "論理演算子（２）BETWEEN",
          "論理演算子（３）IN",
          "論理演算子（４）LIKE",
          "論理演算子（５） NOT",
          "データがない状態　IS NULL",
          "条件によって任意の値に関する演算子　CASE",
          "複数のSELECT文をつなげる　UNION ALL"
        ],
        "【練習問題】演算子": [
          "練習問題１",
          "練習問題２",
          "練習問題３",
          "練習問題４",
          "練習問題５"
        ],
        "テーブルの結合": [
          "セクションの説明",
          "外部結合　LEFT JOIN / RIGHT JOIN",
          "内部結合　INNER JOIN",
          "交差結合　CROSS JOIN"
        ],
        "【練習問題】　テーブルの結合": [
          "練習問題１"
        ],
        "変換関数": [
          "セクションの説明",
          "型の変換する　CAST",
          "最初のNULL値でない値を返す　COALESCE",
          "小数点を四捨五入する　ROUND()"
        ]
      },
      "requirements": [
        "プログラミング経験不要",
        "パソコンはWindows、Macどちらも可能"
      ],
      "description": "データ分析に役立つスキル、キャリアアップに繋がるスキルのデータベースを操作する言語 SQLを学習していくコースです。\n\n\n実務への参入障壁を少しでも下げたいと考え多くの企業が採用し始めているクラウド環境BigQueryですすめていきます。\nデータ分析が活躍する場面は多くあります。\nITエンジニア以外でも\n・ディレクターがWEBサイト改善の材料としてログ解析する\n・マーケッターが何かする企画する際に材料として数字を揃える\nなど、企画側で効果測定を行うなどにも役立つスキルです。 今すぐデータが欲しいというとき、自身で取得できたらどれだけ楽なことでしょう。 ですので、ITエンジニアでなくとも、学ぶメリットは非常に高いのです。\n\n\nまた、データ分析は、インターネット社会において必須なスキルであり、多くの企業で重宝されています。キャリアップ、年収アップにも繋がるスキルですので是非取り組んでいただきたいです。\n\n\n本講座は、ハンズオン形式ですすめていき、実際に、SQLを書いていただきます。その経験をもとに練習問題にチャレンジしていただき、理解度を上げていく流れです。\n\n\nレッスンは1レッスンも3分〜5分程度としている関係で細かくなってしまいっていますが、悩んでしまう箇所を何回も繰り返し視聴できたり、理解が早いところはささっと進められるように、自分のペースに合わせて進めることができる構成に力を入れてあります。\n\nこのコースは、\nSQL初心者、SQLを経験したい方\n自力でデータを抽出したい方\nデータ分析の仕事に興味がある方\nマーケティング担当者、ビジネス企画者\nディレクター、マネージャー\nに特におすすめです！\n\n\nこれからデータ分析をやってみたい、興味があるという方は、無料動画をぜひチェックしてください。",
      "target_audience": [
        "SQL初心者、または、SQLに触れたことがない方",
        "自力でデータを抽出したい方",
        "データ分析の仕事に興味がある方・就きたい方",
        "Webディレクター、Webマーケッター、Web関連で企画に携わっている方",
        "キャリアップを考えている方"
      ]
    },
    {
      "title": "Pythonによる異常検知【点データ・時系列データ編】",
      "url": "https://www.udemy.com/course/python-anomaly-detection1/",
      "bio": "ビジネスのさまざまなケースで使われている異常検知について、基礎からPythonによる実行まで幅広く学び、実際に使えるようになりましょう！本コースでは点データ・時系列データ（非画像データ）に対する異常検知手法を学びます。",
      "objectives": [
        "異常検知の概要",
        "機械学習の基礎",
        "ホテリング理論による異常検知",
        "LOFによる異常検知",
        "Isolation Forestによる異常検知",
        "One Class SVMによる異常検知",
        "kNNによる時系列データの異常検知",
        "特異スペクトル変換による時系列データの異常検知",
        "Change Finderによる時系列データの異常検知（変化点検知）"
      ],
      "course_content": {
        "本コースの紹介": [
          "本コースの紹介",
          "コードのダウンロード",
          "コース準備レクチャー"
        ],
        "異常検知の概要": [
          "ビジネスにおける異常検知の例",
          "異常検知の種類",
          "異常検知におけるデータの特徴と機械学習手法",
          "異常検知の用途と計算コスト",
          "AI業界における異常検知"
        ],
        "機械学習の基本": [
          "機械学習の流れ",
          "決定木",
          "ランダムフォレスト",
          "k近傍法（kNN）",
          "SVM",
          "精度評価（交差検証）",
          "異常検知の精度指標（混同行列）",
          "異常検知の精度指標（PrecisionとRecall）"
        ],
        "正規分布データの異常検知": [
          "ホテリング法",
          "Pythonによるホテリング法の実践①",
          "Pythonによるホテリング法の実践②"
        ],
        "非正規分布データの異常検知": [
          "Local Outlier Factor（LOF）①",
          "Local Outlier Factor（LOF）②",
          "PythonによるLOFの実践①",
          "PythonによるLOFの実践②",
          "Isolation Forest",
          "PythonによるIsolation Forestの実践①",
          "PythonによるIsolation Forestの実践②",
          "PythonによるIsolation Forestの実践③",
          "One Class SVM",
          "PythonによるOne Class SVMの実践①",
          "PythonによるOne Class SVMの実践②",
          "異常検知の結果の比較"
        ],
        "時系列データの異常検知": [
          "時系列データの異常検知と時間窓",
          "k近傍法（kNN）による異常検知",
          "Pythonによるk近傍法（kNN）の実践①",
          "Pythonによるk近傍法（kNN）の実践②",
          "Pythonによるk近傍法（kNN）の実践③",
          "特異スペクトル変換",
          "特異値分解",
          "Pythonによる特異スペクトル変換の実践①",
          "Pythonによる特異スペクトル変換の実践②",
          "Pythonによる特異スペクトル変換の実践③",
          "Pythonによる特異スペクトル変換の実践④",
          "Pythonによる特異スペクトル変換の実践⑤"
        ],
        "おわりに": [
          "教師あり学習による異常検知をする場合",
          "参考文献"
        ],
        "ボーナスレクチャー": [
          "ボーナス"
        ]
      },
      "requirements": [
        "Pythonコードを少しかけること"
      ],
      "description": "本コースでは、異常検知の基本から実践的な応用までを解説し、Pythonで実際に異常検知を実践します。\n最近は企業のデータ活用も活発になり、その中で異常検知もよく行われるようになりました。しかし、この異常検知分野はあまり書籍や解説も多くなく、あったとしても理論に偏りすぎてどうやって実践したらよいかわからないというケースもよくあります。\nそこで今回は、点データ・時系列データの異常検知に着目し、その簡単な理論の理解と実際にPython実行することを通じて、これから業務で異常検知を行うための基礎を培うことを目標としています。\n現代のデータドリブンな世界では、異常挙動やそのパターンを見い出すことは非常に重要となってきていますので、本コースを通じてその基礎スキルを身につけましょう！\n\n\nコースの内容\n異常検知の基礎知識の習得\n異常検知の基本的な概念とアプローチを学びます。ビジネスにおける異常検知やその種類について理解を深め、なぜそれが重要なのかを理解します。\n\n機械学習の基礎の確立\n機械学習の基本的なモデルや評価手法などを学習します。機械学習が異常検知の基本になりますので、必要に応じて学びます。\n\n正規分布に従うデータの異常検知\nホテリング法を用いて、正規分布に従うデータの異常検知を行います。理論と実践のバランスを保ちながら、異常検知の基本的なアプローチをマスターします。\n\n非正規分布に従うデータの異常検知\nLOF、Isolation Forest、One Class SVMなどのアルゴリズムを使用して、非正規分布に従うデータの異常検知を行います。\n\n時系列データの異常検知\nkNN、特異スペクトル変換、Change Finderなどの手法を理解し、実際にPythonで異常検知を実行できるようになります。\n\nコースの対象\nこのコースは、異常検知の基礎を身につけたいデータサイエンティストやエンジニア、ビジネスアナリストなど、データを活用するあらゆる人が対象です。\n\n\n注意点\n本コースでは画像データの異常検知は対象外となりますのでご注意ください\n間違って購入した場合は購入後30日まではキャンセル可能ですのでご活用ください\nPythonの環境構築は行いませんのでご了承ください。Python環境がない場合は、Google Colaboratoryを使用したり、Anacondaなどをインストールするのが良いかと思います",
      "target_audience": [
        "業務で異常検知モデルを作る必要がある方",
        "異常検知に興味がある勉強してみたい方",
        "基本的なPythonコーディングを学び、次のステップに進みたい方"
      ]
    },
    {
      "title": "Fundamentos Engenharia de dados e Bigdata com Azure",
      "url": "https://www.udemy.com/course/fundamentos-engenharia-de-dados-e-bigdata-com-azure/",
      "bio": "Do Zero ao Bigdata",
      "objectives": [
        "Fundamentos de Big data",
        "Fundamentos de Datalake",
        "Fundamentos de Lake house",
        "Fundamentos de engenharia de dados"
      ],
      "course_content": {
        "Introdução": [
          "Boas vindas"
        ],
        "Teoria e História da Engenharia de dados": [
          "Definição de Camadas e Arquiteturas de Dados"
        ],
        "Hands-on": [
          "Criação de Datalake e permissionamento",
          "Criação de Banco de Dados Sample",
          "Ingestão com Azure Data Factory",
          "Inestão Sakila completa",
          "Preparação Databricks",
          "Transformações silver",
          "Dicas de estudos e ferramentas",
          "Finalização"
        ]
      },
      "requirements": [
        "Conhecimento básico em dados ou programação"
      ],
      "description": "Neste curso eu mostrarei o caminho para quem deseja começar a trabalhar com Bigdata na Azure.\nVocê aprenderá todo os conceitos chaves para criar pipelines usando o que há de mais inovador no mercado de dados.\nVocê aprenderá:\n· Criação dos componentes na Azure;\n· Arquitetura base para projetos de Bigdata e Analytics;\n· Definição de camadas de dados no Data lake;\n· Diferenças entre Data warehouse, Bigdata e Lake house;\n· Ingestão de dados: Como se conectar às suas fontes de dados on-premises e trazer os dados para dentro do Data Lake na Azure.\n· Transformações e manipulações de dados com Pyspark e Spark SQL;\n· Utilização de particionamentos em formato Parquet e Delta lake;\nNo módulo Hands-on, abordaremos de forma prática a utilização básica de Azure Data Factory, Azure Data Lake Storage gen2 (ADLS gen2), Azure Databricks e muito mais.\nAbordaremos desde a parte teórica até demonstrações práticas, para facilitar o entendimento de cada step de um processo de engenharia de dados utilizando stack Azure.\nO curso ainda conta com alguns exercícios práticos de ingestão, manipulação e exploração de dados, onde você poderá praticar os conceitos aprendidos e estar preparado para os desafios profissionais de engenharia e análise de dados.\nApós concluir o curso, você estará apto a entender como funciona um sistema de Bigdata e engenharia de dados na Azure e conseguirá dar os primeiros passos em direção ao sucesso!",
      "target_audience": [
        "Iniciantes em Engenharia de dados",
        "Iniciantes em Azure"
      ]
    },
    {
      "title": "CÁLCULO PARA MACHINE LEARNING E MODELAGEM COM PYTHON",
      "url": "https://www.udemy.com/course/calculo-para-machine-learning-e-modelagem-com-python/",
      "bio": "Cálculo Diferencial e Integral para Machine Learning, Modelagem Matemática e Programação utilizando Python",
      "objectives": [
        "Expressões Algébricas",
        "Equações",
        "Funções Polinomiais, Exponenciais, Logarítmicas, trigométricas, modulares e Racionais.",
        "Funções de Ativação",
        "Modelos de Regressões (Linear, polinomial, exponencial e logarítmica)",
        "Aplicações com Python",
        "Limites",
        "Derivadas",
        "Derivada de ordem superior",
        "Derivada parcial",
        "Gradiente",
        "Descida do Gradiente",
        "Taxas",
        "Maximização e minimização",
        "Integral Indefinida",
        "Integral Definida",
        "Aplicações de Integral",
        "Método de Integração por Partes",
        "Método de integração por substituição"
      ],
      "course_content": {
        "Introdução": [
          "Boas Vindas e Apresentação do Instrutor",
          "Apresentação do curso e da plataforma de estudos"
        ],
        "Fundamentos de Python": [
          "A Linguagem Python",
          "Conhecendo o Google Colaboratory",
          "Instalação do Anaconda Python",
          "Conhecendo o Jupyter Notebook",
          "Primeiros passos",
          "Operadores Matemáticos",
          "Importações de bibliotecas e pacotes",
          "Estrutura condicional",
          "Estrutura de Repetição",
          "Listas, Tuplas e Dicionários",
          "Criação de Funções",
          "Função Lambda e função map",
          "List Comprehensions",
          "Vetores (arrays) e matrizes"
        ],
        "Fundamentos de Matemática para Cálculo": [
          "Conjuntos e Expressões Numéricas",
          "Expressões numéricas em Python",
          "Expressões Algébricas (Simplificação, Expansão e Produtos Notáveis)",
          "Expressões Algébricas (Fatoração e Divisão)",
          "Expressões Algébricas em Python",
          "Relação e Função",
          "Equação Polinomial",
          "Equações Polinomiais em Python",
          "Funções Polinomiais",
          "Funções Polinomiais em Python",
          "Funções com Geogebra e Desmos",
          "Resolução de Problemas com Funções Polinomiais",
          "Equações Exponenciais",
          "Equações Exponenciais no Python",
          "Funções Exponenciais",
          "Funções Exponenciais no Python",
          "Resolução de Problemas com Funções Exponenciais",
          "Equações Logarítmicas",
          "Equações Logarítmicas no Python",
          "Funções Logarítmicas",
          "Resolução de Problemas com Funções Logarítmicas",
          "Trigonometria",
          "Funções Trigonométricas",
          "Funções Racionais, Modulares e Composição de Funções"
        ],
        "Aplicações de Funções em Machine Learning e Modelagem": [
          "Funções de Ativação: Função Sigmóide",
          "Função Tanh e Softmax",
          "Função ReLu, LeakyReLu e ELU",
          "Regressões",
          "Modelo de regressão linear",
          "Modelo de regressão polinomial",
          "Modelo de regressão exponencial",
          "Modelo de regressão logarítmica"
        ],
        "Limites e Derivadas": [
          "Limites (análise gráfica)",
          "Cálculo de Limites",
          "Limites em Python",
          "Limites com Symbolab",
          "Conceitos de Derivadas",
          "Derivadas Fundamentais",
          "Regra do produto e do Quociente",
          "Derivadas em Python",
          "Regra da Cadeia",
          "Derivadas sucessivas",
          "Derivadas no Symbolab",
          "Aplicações de Derivadas: taxas",
          "Aplicações de Derivadas: pontos de máximo e mínimo em Python",
          "Aplicações de Derivadas: Regra de L´Hôpital",
          "Derivadas parciais",
          "Derivadas parciais em Python",
          "Vetor Gradiente e conceitos da Descida do Gradiente",
          "Cálculos sobre Descida do gradiente"
        ],
        "Integral": [
          "Conceitos de Integral",
          "Integral Indefinida",
          "Integral: Método da Substituição",
          "Integração por Partes",
          "Integral Indefinida no Python",
          "Integral no Symbolab",
          "Integral Definida",
          "Aplicações de Integral",
          "Integral definida no Python"
        ],
        "Finalização do curso": [
          "Encerramento"
        ],
        "Referências Bibliográficas": [
          "Referências e links úteis"
        ]
      },
      "requirements": [
        "Não há pré-requisito"
      ],
      "description": "Este curso aborda de forma clara e objetiva os principais conceitos de Cálculo Diferencial e Integral focado em demonstrações práticas utilizando a Linguagem de programação Python. Serão estudados os conteúdos sobre expressões, equações, funções, limites, derivadas (regra do produto, regra do quociente e regra da cadeia), derivadas sucessivas, derivadas parciais, gradiente, descida do Gradiente, modelos de regressão, integral indefinida (método da substituição e integração por partes), integral definida, aplicações de derivadas e aplicações de integral.\nAlém da demonstração do uso de Python em Cálculo, são apresentados outros softwares matemáticos, como o Desmos, Geogebra e Symbolab.\nNa segunda seção encontra-se uma apresentação dos conceitos básicos de Python no Google Colaboratory, para que aqueles que não conhecem o Python e/ou o Google Colaboratory possam acompanhar o curso com tranquilidade. Já a terceira seção do curso é sobre os fundamentos de Matemática para o Cálculo Diferencial e Integral, o qual serve como revisão dos conceitos básicos matemáticos necessários para o bom entendimento do curso.\nO curso é apresentado no sistema operacional Windows, no Google Colaboratory, mas usuários do Linux e Mac acompanham tranquilamente. Além do Google Colaboratory (Colab), pode ser utilizado o Jupyter Notebook, Visual Studio, Pycharm, Spyder ou qualquer outra IDE de Python.\nO curso não é estático, qualquer sugestão de acréscimo de conteúdo é muito bem vindo.\nBem vindos ao mundo fantástico do Cálculo Diferencial e Integral.",
      "target_audience": [
        "Cientista de dados",
        "Analista de Dados",
        "Pesquisador",
        "Machine Learning",
        "Economista",
        "Administrador",
        "Estatistico",
        "Matemático",
        "Biológico",
        "Ciências Exatas",
        "Engenheiro de Dados",
        "Físico",
        "Programador"
      ]
    },
    {
      "title": "Alteryx Designer: Curso Nivel Intermedio en Español (2 de 3)",
      "url": "https://www.udemy.com/course/alteryx-designer-curso-nivel-intermedio-en-espanol/",
      "bio": "Con base en procesos reales, integraremos herramientas, fórmulas avanzadas, flujos de limpieza, y validación de datos.",
      "objectives": [
        "Habilidades avanzadas en Alteryx Designer",
        "Utilización de Fórmulas avanzadas",
        "Validación de información",
        "Habilidad: Limpieza de información",
        "Manejo de Dirty Data",
        "Automatización de procesos",
        "Formateo de información",
        "Flujos de trabajo de mejora continua",
        "División de datos útiles",
        "Reemplazo de variables",
        "Formulación condicional avanzada y anidada",
        "Combinación de herramientas",
        "Expresiones regulares",
        "Porcentaje de Pureza"
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Consejos para Udemy.com"
        ],
        "Perspectiva General": [
          "Estructura del curso",
          "Definiciones básicas",
          "Descarga e instalación de Alteryx",
          "Obtención de licencia de Alteryx",
          "Interfaz de Alteryx"
        ],
        "Fórmulas y Funciones": [
          "Definición de Expresiones",
          "Expresiones Condicionales Avanzadas",
          "Swtich: Ejercicio Propuesto",
          "Funciones con operadores",
          "El uso de Null y Vacío",
          "Funciones de texto"
        ],
        "Transformación de datos": [
          "Funciones de fecha",
          "Fórmula multicampo",
          "Formula multi línea",
          "Expresiones Regulares"
        ],
        "Limpieza de Información Sucia \"Dirty Data\"": [
          "Definición de 'Dirty Data'",
          "Consideraciones con archivos delimitados",
          "Problemas de carga de archivos (delimitadores)",
          "Problemas de carga de archivos : Continuación",
          "Tablas de soporte"
        ],
        "Validación de Infromación": [
          "¿Por qué validar la data?",
          "Tipos de Validaciones",
          "Validaciones Personalizadas",
          "Validación y limpieza de campos críticos",
          "Validación de Montos"
        ],
        "Finalización del Curso!": [
          "Agradecimiento y recomendaciones"
        ]
      },
      "requirements": [
        "Lógica de Base de datos",
        "Definición de ETL",
        "Manejo de Información",
        "Apertura para aprender"
      ],
      "description": "Este curso permitirá a los estudiantes integrar varias herramientas de Alteryx Designer para lograr realizar procesos complejos con la información de manera sencilla, ágil y dinámica.\nEl curso inicia con un resumen de los conceptos básicos expuestos en cursos pasados a manera de recordatorio, y luego nos adentraremos en las formulas para ver su funcionamiento a un nivel profundo pero con ejemplos claros para entender la sintaxis de la herramienta.\nMás adelante, construiremos flujos de trabajo basados en situaciones reales y con base a experiencias pasadas. Tomaremos las mejores prácticas para resolver problemas comunes que la naturaleza de la información suele presentar para obtener información limpia, ordenada y de alto valor para trabajar.\nPara finalizar, al obtener información limpia, procederemos con la validación de la misma para asegurar que su grado de pureza sea el mas alto e identificar aquellos casos que necesitan ajustarse para que nuestro flujo de trabajo sea más inteligente.",
      "target_audience": [
        "Científicos de Data",
        "Trabajadores Financieros",
        "Ingenieros de Migración",
        "Specialistas de Analítica",
        "Usuarios de base de datos",
        "DbOwners",
        "Db Administrators",
        "Usuarios Avanzados de Excel"
      ]
    },
    {
      "title": "Preset - APACHE Superset: Dashboard e Visualização de Dados",
      "url": "https://www.udemy.com/course/preset-apache-superset-dashboard-e-visualizacao-de-dados/",
      "bio": "Transformando seus dados em ação - dashboards e gráficos",
      "objectives": [
        "Plataforma de exploração e visualização de dados criada com base no Apache Superset de código aberto",
        "Permite a criação de gráficos e dashboards, permitindo a construção de visualização sem código",
        "É possível executar uma análise mais profunda usando o editor SQL nativo",
        "Permite a conexão com diversas fontes de dados como Data Warehouse, Data Lake, planilhas, tudo 100% na nuvem",
        "Possui um ambiente fácil de usar, onde você cria uma workspace de trabalho e constrói seus projetos",
        "Permite carregar seus dados de diversos bancos de dados e origens diferentes, acessando os dados de forma transparente",
        "Permite a criação de gráficos (CHART) dos mais variados e com requisitos de filtros e ajustes de campos, podendo gerar novos atributos",
        "Permite que você utilize o SQL LAB para explorar seus dados via SQL",
        "Possui um fluxo de trabalho que organiza a construção das análises de dados",
        "Com o Preset - APACHE Superset é possível conectar seus dados, criar um conjunto de dados, criar gráficos, construir um painel e compartilhar seus insights",
        "Possui um espaço de trabalho para armazenamento das informações a serem desenvolvidas",
        "Permite a construção de gráficos diversos: tabela, setores, heatmap, treemap, box plot, linha, sunburst, dentre outros",
        "Permite a construção de previsões utilizando técnicas como FORECAST",
        "Permite a colaboração e compartilhamento de gráficos e dashboard"
      ],
      "course_content": {
        "Preset - APACHE Superset: Dashboard e Visualização de Dados": [
          "Apresentação - O que é o APACHE Superset",
          "INFORMAÇÕES IMPORTANTES! - Leia antes de começar o curso",
          "Entendendo sobre Preset - APACHE Superset",
          "Criação da conta no ambiente da nuvem do Preset",
          "Realizando a carga dos dados para o treinamento",
          "Criação do Chart - Tabela",
          "Criação do Chart - Treemap",
          "Criação do Chart - Série Temporal e Previsão com FORECAST",
          "Criação de uma nova coluna customizada",
          "Criação do Chart - KPI",
          "Criação do Chart - Sunburst",
          "Criação do Chart - Graph Chart - Gráfico de rede",
          "Criação do Chart - Box Plot",
          "Criação de dashboard - gerando insights e entendo as análises",
          "Criação de filtros nos dashboards",
          "Criação de query pelo SQL LAB",
          "Aula Final - entrega de atividade",
          "Vamos responder ao nosso Quiz?"
        ]
      },
      "requirements": [
        "Conhecimento elementar de SQL"
      ],
      "description": "O Preset - Apache Superset é uma ferramenta poderosa para análise e visualização de dados, que permite aos profissionais de dados criar dashboards e explorar dados de forma eficiente e intuitiva. Aprender a utilizar essa ferramenta pode trazer vários benefícios para a carreira de um profissional de dados, incluindo:\n\n\nAnálise de dados mais rápida e eficiente\nCriação de dashboards interativos e fáceis de compartilhar\nIntegração com fontes de dados diferentes, incluindo bancos de dados relacionais e NoSQL\nCom o treinamento em Preset - Apache Superset, você estará habilitado a transformar dados em insights valiosos para tomar decisões informadas e aprimorar o desempenho da sua empresa.\nNo treinamento será possível criar uma workspace com todas as informações necessárias para você para criar gráficos e dashboards. O APACHE Superset é open source, mas utilizaremos o Preset que é uma versão que embarca a ferramenta da APACHE, de forma a facilitar seu entendimento e manuseio. Ela disponibiliza gratuitamente acesso e permite que você desenvolva seus projetos na área de análise de dados sem problemas.\n\"Descubra novos insights com o Apache Superset: transforme dados em ação\"\nVenha e comece hoje mesmo a estudar esta ferramenta que ajuda analista de dados em todo o mundo a encontrar seus insights. Entender sobre visualização de dados permitirá que você monte painéis e estruturas de decisão em sua organização.",
      "target_audience": [
        "Profissionais da área de dados, estudantes, administradores, estatísticos",
        "Profissionais que desejam construir dashboards e gráficos"
      ]
    },
    {
      "title": "Python数据分析：从入门到精通",
      "url": "https://www.udemy.com/course/bittiger-python-analyst/",
      "bio": "掌握Python, 机器学习，Numpy, SQL，Matplotlib 等等成为数据分析师！",
      "objectives": [
        "达到Python编程的中级技能水平",
        "执行基本的SQL查询和其他数据库操作",
        "使用Numpy库来操作数组",
        "使用Pandas进行数据分析",
        "使用Matplotlib创建数据可视化",
        "使用Scikit进行机器学习分析",
        "使用Jupyter Notebook环境进行开发"
      ],
      "course_content": {
        "快速入门": [
          "课程结构介绍",
          "Python安装",
          "Mac系统上的Python安装",
          "Python shell以及如何运行Python程序",
          "Python IDE介绍",
          "Python的注释以运行Hello world程序"
        ],
        "基本数据类型与语法与实战": [
          "基本变量和赋值",
          "基本数据类型",
          "基本运算符、表达式和语句",
          "准备实战练习",
          "实战练习",
          "If-else表达式以及Python中的缩进",
          "循环语句：For",
          "循环语句：While",
          "实战练习",
          "循环语句：Break和Continue",
          "Python中的异常处理",
          "实战练习"
        ],
        "函数入门与实战": [
          "函数的定义和使用",
          "匿名函数",
          "变量的作用域",
          "准备实战练习",
          "实战练习"
        ],
        "高级数据类型与实战": [
          "数据类型：列表",
          "数据类型：元组",
          "数据类型：字符串",
          "数据类型：集合",
          "数据类型：字典",
          "实战练习"
        ],
        "错误/异常处理与实战": [
          "运行时错误",
          "基本的异常处理",
          "多异常处理",
          "实战练习"
        ],
        "常用函数介绍与实战": [
          "常用函数：Map(), Filter(), Reduce()",
          "常用函数：Enumerate(), zip()",
          "字符串类型常用函数",
          "实战练习",
          "列表推导式",
          "编码风格规范",
          "正则表达式",
          "Cython",
          "与Bash的交互",
          "实战练习"
        ],
        "读写操作与实战": [
          "读取和写入文本文件",
          "读取和写入CSV文件",
          "读取和写入JSON文件",
          "SQLite",
          "Pickle",
          "实战练习"
        ],
        "Anaconda安装与环境配置": [
          "Anaconda介绍",
          "Anaconda安装",
          "Anaconda环境管理",
          "Anaconda包管理"
        ],
        "Numpy基础数据处理库与实战": [
          "Numpy介绍",
          "创建Numpy数组",
          "Numpy中的数据类型",
          "Numpy中读取文本文件",
          "实战练习",
          "基本线性代数",
          "数组的索引",
          "数组的常用操作",
          "常用函数",
          "Numpy相关文档",
          "实战练习"
        ],
        "Pandas数据分析库与实战": [
          "Pandas中的两种数据类型",
          "Pandas中的I/O操作",
          "Pandas中的数据访问",
          "Pandas中数据的删除操作",
          "获取Series/DataFrame信息",
          "应用函数的方法",
          "Pandas相关文档",
          "实战练习"
        ]
      },
      "requirements": [
        "了解基本的统计知识",
        "对任何一种编程语言有过简单的了解（我们将从Python的基础讲起）",
        "一台可以操作的计算机（Mac或PC都可以）"
      ],
      "description": "课程介绍\n\n你是否希望学习当下最火最热的数据分析技能，将你的职业发展到更高水平？从营销人员，运营分析师到纯数据科学家，使用Python的数据分析技能、帮助企业根据实际数据做出明智决策已经是数据分析岗位不可缺少的技能。\n\n如果你有基本的数学技能，想要学习你的第一门编程语言，并准备好掌握核心数据分析技能 - 这门课程适合你。\n---------------------------------------------------------------------\n\n\n为什么我要选择BitTiger？\nBitTiger是来自硅谷的终身学习平台，我们的教学团队有上百名来自世界顶尖科技公司的资深技术专家和教育创新者。在BitTiger的过去三年中，我们已经教学过数千名学生。我们的学生已经在京东，腾讯，百度，谷歌和Facebook等世界知名公司工作。现在，我们首次尝试视频课程的形式，与世界分享知识。\n\n---------------------------------------------------------------------\n为什么要学习Python和数据分析技能呢？\n\nPython有望成为世界上最流行的编码语言之一，可用于各种应用程序，包括Web开发，数据分析和机器学习。\n\n随着数据收集和存储的流行，基于数据分析的业务决策能力已经被广大公司认可和广泛使用，尤其是互联网行业的功能公司。如果你具备强大的数据分析技能，那么将成为一名更有价值且更受追捧的员工。\n\n---------------------------------------------------------------------\n谁应该报名这门课？\n\n无论你是想成为一名全职开发人员，还是在从事运营或业务岗位，数据分析都是你所需要的关键技能。任何没有背景或只有初学者编码背景的人都非常适合这门课程，因为我们将从最基本的Python编码技能开始，并教你使用相关数据分析工具。\n\n---------------------------------------------------------------------\n课程的内容安排是什么样的？\n达到Python编程的中级技能水平\n了解不同的数据类型，函数，异常和错误处理，以及如何与bash交互\n学习从JSON和CSV格式等文本文件中读取和写入\n安装并学习如何使用Anaconda包管理器\n执行基本的SQL查询和其他数据库操作\n使用Numpy库来操作数组\n使用Matplotlib创建数据可视化\n使用Scikit进行机器学习分析\n使用Jupyter Notebook环境进行开发\n---------------------------------------------------------------------\n上完这门课程会获得什么？\n\n首先从零开始教你使用强大的Python编程语言所需的基本编程技巧。接下来，我们将继续教你如何使用流行的分析工具安装和基本的运行分析操作，例如：Numpy，Pandas，MatPlotlib，Scikit和Jupyter Notebook等。\n\n在每个章节中，我们还将为你提供小练习，测试你的掌握程度，夯实你的知识技能。完成本课程后，你将有信心将Python放在简历上，并为数据分析师的职业发展打下坚实的基础。\n\n---------------------------------------------------------------------\n你还在等什么？立刻报名，开始你的数据分析师职业生涯吧！\n\n---------------------------------------------------------------------",
      "target_audience": [
        "对python和数据分析感兴趣的同学",
        "想要开始数据分析师的职业生涯的同学，或者想要学习数据分析技能，以使当前的工作变得更有效的同学"
      ]
    },
    {
      "title": "Data Science Descomplicado Vol. 1: A Base Matemática",
      "url": "https://www.udemy.com/course/data-science-descomplicado-vol-1-a-base-matematica/",
      "bio": "Todos conceitos matemáticos que um cientista de dados precisa saber!",
      "objectives": [
        "Todos os conceitos matemáticos necessários para um Cientista de Dados",
        "Entender, e não decorar, conceitos matemáticos - e aprender a raciocinar de forma matemática",
        "Aplicar, através de exercícios, o conhecimento adquirido durante as aulas"
      ],
      "course_content": {
        "Introdução": [
          "Introdução do curso"
        ],
        "Geometria": [
          "Tipos de Geometria",
          "Ponto, Reta, Ângulo e Plano",
          "Geometria Plana",
          "Geometria Espacial",
          "Geometria Plana e Espacial - Recursos",
          "Geometria Plana e Espacial - Exercícios",
          "O que é Pi?",
          "Sistemas de Coordenadas",
          "Geometria Analítica: Reta e Circunferência",
          "Geometria Analítica: Cônicas",
          "Tipos de Distâncias",
          "Sistemas de Coordenadas, G.A e Distâncias - Recursos",
          "Geometria Analítica - Exercícios",
          "Trigonometria - Conceitos",
          "Trigonometria - Círculo Trigonométrico",
          "Trigonometria - Fórmulas",
          "Trigonometria - Recursos",
          "Trigonometria - Exercícios"
        ],
        "Álgebra, Equações e Funções": [
          "Álgebra, Equações e Funções - Introdução",
          "O que é um número?",
          "Zero e Infinito",
          "Zero e Infinito - Operações",
          "Conjuntos Numéricos",
          "Equação e Função",
          "Funções - Injeção, Sobrejeção e Bijeção",
          "Funções - Paridade e Periodicidade",
          "Funções - Exercícios",
          "Polinômios",
          "Módulo",
          "Fatorial e Inequação",
          "Radiciação e Exponenciação",
          "Logaritmo",
          "Logaritmo Natural",
          "Notação Sigma/Pi e Notação Científica",
          "Álgebra - Recursos",
          "Álgebra - Exercícios"
        ],
        "Cálculo": [
          "Cálculo - Introdução",
          "Limite",
          "Limites Fundamentais e Limites Laterais",
          "Derivadas",
          "Derivadas Notáveis e Derivadas Parciais",
          "Integrais",
          "Integrais Notáveis e Integrais Múltiplas",
          "Séries",
          "Séries de Taylor/Maclaurin",
          "Cálculo - Recursos",
          "Cálculo - Exercícios"
        ],
        "Vetores e Matrizes": [
          "Vetores e Matrizes - Introdução",
          "O que são vetores?",
          "Vetores vs. Escalares",
          "Operações entre Vetores",
          "Versores e Campo Vetorial",
          "Vetores - Recursos",
          "Vetores - Exercícios",
          "O que são matrizes?",
          "Tipos de Matrizes",
          "Operações entre Matrizes",
          "Matriz Inversa, Transposta, Simétrica e Diagonal",
          "Determinante",
          "Sistemas Lineares",
          "Sistemas Lineares - Regra de Cramer",
          "Matrizes - Recursos",
          "Matrizes - Exercícios"
        ],
        "Álgebra Linear": [
          "Álgebra Linear - Introdução",
          "Dependência e Independência Linear",
          "Produto Escalar",
          "Produto Vetorial",
          "Autovetores e Autovalores",
          "Álgebra Linear - Recursos",
          "Álgebra Linear - Exercícios",
          "Gradiente",
          "Divergente",
          "Rotacional",
          "Multiplicadores de Lagrange",
          "Cálculo Avançado - Recursos"
        ],
        "Probabilidade e Estatística": [
          "Probabilidade e Estatística - Introdução",
          "Diagrama de Venn",
          "Probabilidade - Conceitos",
          "Análise Combinatória - Arranjo",
          "Análise Combinatória - Permutação",
          "Análise Combinatória - Combinação",
          "Probabilidade - Recursos",
          "Probabilidade - Exercícios",
          "Estatística - Conceitos",
          "Estatística Descritiva",
          "Estatística Descritiva - Exemplo",
          "Acurácia vs. Precisão",
          "Gráficos - Linha e Barra",
          "Gráficos - Área",
          "Gráficos - Dispersão",
          "Gráficos - Bolha",
          "Gráficos - Setores",
          "Gráficos - Histograma",
          "Gráficos - Densidade",
          "Gráficos - Boxplot",
          "Gráficos - Violino",
          "Gráficos - Heatmap",
          "Gráficos - Radar",
          "Gráficos - Contorno e Superfície",
          "Estatística Básica e Gráficos - Recursos",
          "Estatística Básica e Gráficos - Exercícios",
          "Correlação",
          "Valor Esperado",
          "Valor Esperado - Exemplos",
          "Distribuição de Probabilidade",
          "Distribuição Normal",
          "Assimetria e Curtose",
          "Distribuição Uniforme",
          "Distribuição de Bernoulli e Binomial",
          "Distribuição de Poisson",
          "Distribuição Exponencial",
          "Distribuição Weibull",
          "Distribuição Beta",
          "Distribuição de Pareto",
          "Seeing Theory",
          "Distribuições - Recursos",
          "Distribuições - Exercícios",
          "Entropy, Cross-Entropy e KL Divergence pt. 1",
          "Entropy, Cross-Entropy e KL Divergence pt. 2",
          "Entropy - Recurso",
          "Inferência Frequencista - Conceitos",
          "Inferência Frequencista - Teste de Hipóteses",
          "Teste Chi2",
          "Teste Chi2 - Exemplo",
          "Teste T de Student",
          "ANOVA",
          "KS (Kolmogorov-Smirnov)",
          "Inferência Frequencista - Recursos",
          "Inferência Frequencista - Exercícios",
          "Estatística Bayesiana pt.1",
          "Estatística Bayesiana pt.2",
          "Estatística Bayesiana - Recursos"
        ]
      },
      "requirements": [
        "Matemática de Ensino Médio é recomendável, mas não essencial",
        "Computador (Windows, Mac OS ou Linux), tablet ou celular com acesso à Internet"
      ],
      "description": "Esse curso é o primeiro volume de uma tríade, que, em conjunto, trará todos os conceitos necessários para ser um bom cientista de dados.\nNessa primeira parte exploraremos todos os conceitos matemáticos utilizados por um cientista de dados - Geometria, Geometria Analítica, Vetores e Matrizes, Álgebra Linear, Funções e Equações, Cálculo, Probabilidade e Estatística, Inferência e Testes de Hipóteses, Estatística Bayesiana e muito mais!\nO curso é voltado principalmente para profissionais de áreas não-exatas entusiastas de Data Science que queiram migrar para a mesma ou obter uma compreensão maior do tema. Os conceitos são transmitidos da forma mais detalhada possível, portanto, o único conhecimento prévio necessário é o de matemática básica (ensino médio e fundamental). Mesmo se não se sentir confortável com matemática, não se preocupe: O foco do curso é compreender os conceitos, e não fazer contas e saber resolver exercícios de vestibular!\nAo final de cada tópico estão recursos extras (artigos, calculadoras online, sites interativos, vídeos) que ajudam bastante a se aprofundar nos conteúdos, recomendo bastante não pular essas lições. Igualmente importante são os exercícios (mais de 50 no total), que são muito mais focados em testar a compreensão dos conceitos matemáticos do que testar se o aluno sabe fazer contas. Separe um bom tempo e esteja bem disposto para fazer os exercícios com atenção!\nNum mundo cada vez mais digitalizado e com uma influência cada vez maior de Inteligências Artificiais, compreender o que de fato é Ciência de Dados, Machine Learning e programação é não apenas uma grande porta de entrada para uma vasta gama de oportunidades de trabalho, mas também uma educação necessária para compreender o novo mundo em que estamos vivendo. Como Cientista de Dados, acredito que tenho como dever dividir meu conhecimento e contribuir para a construção de uma sociedade em que as pessoas, de fato, possam entender a transformação digital que vivemos.\nNo segundo volume do curso veremos toda a base de programação necessária para um cientista de dados: Como funciona um computador, componentes e comparação entre computadores e sistemas operacionais, como funciona a Internet e Websites, as diferenças e aplicações de linguagens de programação, lógica de programação, estruturas de dados, banco de dados, Linux, computação em nuvem e muito mais!\nPor fim, no terceiro e último volume, mergulharemos de fato em conceitos e algoritmos de Machine Learning: com a base adquirida no volume 2, aprenderemos primeiro a programar em Python, e depois estudaremos (com a ajuda dos conceitos aprendidos no Volume 1) muuuitos conceitos de Data Science, como Regressão, Classificação, Clusterização, Reinforcement Learning, Decision Trees, SVM, XGBoost, Markov Chain Monte Carlo, PCA, Deep Learning, NLP e muuuito mais!\nQue comece nossa jornada de dados ;)\n\n\nPS. Assista na velocidade 1.25x ou 1.5x para uma melhor experiência e ignore os barulhos aleatórios que aparecem de vez em quando, gravar na quarentena tem dessas hahaha",
      "target_audience": [
        "Profissionais (principalmente de áreas não-exatas) que desejam migrar para a área de Ciência de Dados",
        "Entusiastas de Ciência de Dados e que desejam ter um conhecimento mais profundo sobre o tema",
        "Pessoas que desejam solidificar seus conhecimentos em matemática"
      ]
    },
    {
      "title": "Inteligência Artificial com JavaScript e TensorFlow.js",
      "url": "https://www.udemy.com/course/inteligencia-artificial-com-javascript-e-tensorflowjs/",
      "bio": "Aprenda a Biblioteca de IA mais Famosa do Mundo EM SUA VERSÃO MAIS RECENTE do Básico ao Avançado com JavaScript",
      "objectives": [
        "Machine Learning, Deep Learning, Redes Neurais Artificiais, Redes Neurais Convolucionais, Redes Neurais Recorrentes, K-Nearest Neighbors, Teorema de Bayes e etc",
        "Visão Computacional, Classificação de Imagens, Detecção de Objetos em Imagens e Vídeos, Processamento de Linguagem Natural e etc",
        "Desenvolvimento de Inteligência Artificial no Front-End e no Back-End",
        "Todos os principais recursos do TensorFlow partindo do zero, do básico ao AVANÇADO"
      ],
      "course_content": {
        "Apresentação do Curso": [
          "01-Apresentação do Conteúdo do Curso com Alguns Exemplos",
          "02-Apresentação da Biblioteca de Desenvolvimento de IA TensorFlow"
        ],
        "Construção do Tensor": [
          "01-Instalação do TensorFlow e Apresentação do Layout HTML",
          "02-Iniciando o Código JavaScript com a Função de Execução e Exibição",
          "03-Tensores de Uma, Duas e Três Dimensões",
          "04-Tensores de Quatro, Cinco e Seis Dimensões",
          "05-Revisando a Dimensionalidade dos Tensores",
          "06-Tipagem Explícita na Construção do Tensor",
          "07-Tensor Padrão do TensorFlow",
          "08-Revisando o Conteúdo de Construção"
        ],
        "Funções de Criação": [
          "01-Função Fill para Inicialização de Elementos",
          "02-Função Zeros para Atribuir Zeros ao Tensor",
          "03-Função Ones para Atribuir Números Um ao Tensor",
          "04-Função Linspace para Iniciar e Terminar Elementos",
          "05-Função Range para Sequências Numéricas Controladas",
          "06-Revisando as Principais Funções de Criação"
        ],
        "Manipulação de Classes": [
          "01-Transformando um Tensor Unidimensional em Escalar com asScalar",
          "02-Convertendo um Tensor Multidimensional para Unidimensional com Flatten",
          "03-Convertendo um Tensor Multidimensional para Unidimensional com as1D",
          "04-Funções as2D, as3D, as4D e as5D para a Manipulação de Dimensionalidade",
          "05-Conversão de Tipos com a Função asType",
          "06-Funções Dispose, toFloat, toInt e toBool",
          "07-Redimensionando Tensores com Reshape e ReshapeAs",
          "08-Funções expandDims, Cumsum e Squeeze",
          "09-Clonando Tensores Através do Recurso Clone",
          "10-Convertendo Classes do TensorFlow para Variáveis do JavaScript"
        ],
        "Manipulação de Elementos": [
          "01-Inserindo Zeros Antes e Depois dos Elementos com Pad",
          "02-Concatenando Tensores com o Recurso Concat",
          "03-Concatenando Tensores em um Tensor Multidimensional com Stack",
          "04-Invertendo a Posição dos Elementos com Reverse",
          "05-Dividindo um Tensor em Vários Tensores com Split",
          "06-Repetindo Elementos com a Função Tile"
        ],
        "Randomização de Elementos": [
          "01-Randomizando Elementos com randomNormal",
          "02-Randomizando Elementos com randomUniform"
        ],
        "Operações Aritméticas": [
          "01-Somando Elementos com a Função Add",
          "02-Subtraindo Elementos com a Função Sub",
          "03-Multiplicando Elementos com a Função Mul",
          "04-Dividindo Elementos com a Função Div",
          "05-Divisão Inteira de Elementos com a Função floorDiv",
          "06-Somando N Elementos com a Função addN",
          "07-Retornando o Elemento Máximo com Maximum",
          "08-Retornando o Elemento Mínimo com Minimum",
          "09-Resto da Divisão entre Dois Elementos com Mod",
          "10-Elevando os Elementos de um Tensor aos Elementos de Outro com Pow",
          "11-Quadrado da Difenreça dos Elementos com squaredDifference"
        ],
        "Cálculos Matemáticos": [
          "01-Retornando o Valor Absoluto com Abs",
          "02-Retornando o Arco Cosseno dos Elementos com Acos",
          "03-Arco Cosseno Hiperbólico com a Função Acosh",
          "04-Retornando o Arco Seno com Asin",
          "05-Arco-Seno Hiperbólico dos Elementos com Asinh",
          "06-Arco Tangente dos Elementos do Tensor com Atan",
          "07-Arco Tangente do Coeficiente dos Argumentos que Foram Passados como Parâmetro",
          "08-Arredondamento com Floor e Ceil",
          "09-Cálculo do Cosseno com a Função Cos",
          "10-Retornando o Cosseno Hiperbólico dos Elementos com Cosh",
          "11-Elevando a Constante de Euler a Cada Um dos Elementos",
          "12-Resultado da Função Exp menos 1 com Expm1",
          "13-Logaritmo Natural na Base E dos Elementos",
          "14-Invertendo os Sinais com a Função Neg",
          "15-Arredondando Números com a Função Round",
          "16-1 Dividido pela Raiz Quadrada do Elemento",
          "17-Função Sign para Retornar -1 para Negativo, 1 para Positivo e 0 para Nulo",
          "18-Seno dos Elementos do Tensor com Sin",
          "19-Calculando o Seno Hiperbólico com Sinh",
          "20-Raiz Quadrada dos Elementos do Tensor com Sqrt",
          "21-Quadrado dos Elementos com o Recurso da Função Square",
          "22-Calculando a Tangente dos Elementos com Tan"
        ],
        "Operações Matriciais": [
          "01-Multiplicação Matricial com matMul",
          "02-Multiplicando Cada Elemento de um Tensor por Todos os Elementos do Outro com",
          "03-Invertendo a Dimensionalidade com Transpose"
        ],
        "Funções de Redução": [
          "01-Função All para Verificar se Todos os Elementos são Verdadeiros",
          "02-Retornando o Elemento Máximo com Max",
          "03-Retornando o Elemento Mínimo com Min",
          "04-Retornando a Média dos Elementos com Mean",
          "05-Retornando o Produto dos Elementos com Prod",
          "06-Retornando a Soma dos Elementos com Sum"
        ]
      },
      "requirements": [
        "Conhecimentos Básicos em JavaScript"
      ],
      "description": "Utilize a mesma tecnologia que a DeepMind utilizou para derrotar o campeão mundial de Go.\nAprenda a utilizar o TensorFlow, a biblioteca de IA mais famosa do mundo e utilizada por gigantes da tecnologia e empresas multinacionais como DeepMind, Netflix, Google, Airbnb, Snapchat, Uber, Nvidia, Coca-Cola, Twitter, IBM, SAP, Dropbox, GE, Intel, Blommberg, ebay, Lenovo, Linkedin, PayPal, Qualcomm e outras. Construa algoritmos de Machine Learning e Deep Learning PROFISSIONAIS utilizando a mesma tecnologia que as grandes corporações utilizam nas suas soluções de Inteligência Artificial e tudo isso com uma única linguagem: o JavaScript!",
      "target_audience": [
        "Desenvolvedores iniciantes ou experientes que queiram embarcar no fantástico mundo da Inteligência Artificial"
      ]
    },
    {
      "title": "ブロックチェーンデータの分析をしながらSQLを学んでいこう！NFTのトランザクションを分析！",
      "url": "https://www.udemy.com/course/sql-blockchain/",
      "bio": "ブロックチェーンのデータをもとにSQLを使ってデータ分析・集計・可視化をしていこう！Dune AnalyticsをイーサリアムやNFTのデータを探索的に見てオンチェーン分析しダッシュボードを構築！",
      "objectives": [
        "ブロックチェーンの分析方法",
        "SQLの使い方",
        "Dune Analyticsの使い方",
        "NFTに関する可視化ダッシュボード"
      ],
      "course_content": {
        "はじめに": [
          "はじめに",
          "受講の際の注意点",
          "受講中に出てくるコード集",
          "ブロックチェーンとデータ分析の関係性",
          "Dune Analyticsの使い方",
          "SQL入門",
          "SQLのテスト①"
        ],
        "Dune Analyticsで探索的にデータを見ていこう！": [
          "Ethereumのトランザクションテーブルを確認してみよう！",
          "Ethereumの年ごとのトランザクション数を見てみよう！",
          "新しく学んだ構文についておさらい",
          "NFTのトランザクションデータから大きく利益をあげているアドレスを特定",
          "with句とjoin句についておさらい",
          "NFTの大きな利益をあげているアドレスの月別利益を確認",
          "CASE文で条件分岐を学ぼう！",
          "NFTの具体的な取引についてCASE文で見ていこう！",
          "SQLのテスト②"
        ],
        "Dune AnalyticsでNFTに関するダッシュボードを作成してみよう": [
          "NFTのトランザクション数を年月で集計してみよう①",
          "NFTのトランザクション数を年月で集計してみよう②",
          "CONCATとCASTのおさらい",
          "NFTの総取引金額を年月で集計してみよう",
          "直近1ヶ月で最も売れているNFTコレクション",
          "直近1ヶ月とその前の1ヶ月で伸びているNFTコレクション①",
          "直近1ヶ月とその前の1ヶ月で伸びているNFTコレクション②",
          "直近1ヶ月とその前の1ヶ月で伸びているNFTコレクション③",
          "PARTITION BY と ROW_NUMBER",
          "月ごとの最も総取引金額が大きいNFTコレクション",
          "ダッシュボード作成",
          "SQLのテスト③",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "SQLの知識は不要。初心者でも基礎から学んでいきます",
        "ブロックチェーンの知識も不要。"
      ],
      "description": "本講座では、ブロックチェーンを題材にSQLについて学んでいきます。\n\n\nブロックチェーンネットワークに公開されている取引データを分析し、その中に潜むパターンや傾向を見つけ出すための手法をオンチェーン分析と呼びます。\n\n\n従来（Web2）の領域では、通常のトランザクションデータは一般人には公開されていなかったため、なかなか大規模なトランザクションデータを分析することは出来ませんでした。\n\n\nしかし、ブロックチェーン上のトランザクションデータであれば誰でも分析できちゃうんです！\n\n\n具体的にはどんな仮想通貨やNFTの値動きや取引量、もしくは特定のウォレット（仮想通貨などをやり取りするお財布）の取引などが分析出来ちゃいます。\n\n\nSQLを学びながら最新のブロックチェーンのデータを見ていきましょう！\n\n\n当講座では、SQLの基礎から解説しますのでSQLが初心者の方でも問題ございません。\n\n\nそれではブロックチェーンの分析の世界へ足を踏み入れていきましょう！",
      "target_audience": [
        "ブロックチェーンの分析に興味のある方",
        "SQLの使い方に興味のある方"
      ]
    },
    {
      "title": "Curso Completo de Ingeniería de Agentes de IA (2025)",
      "url": "https://www.udemy.com/course/curso-completo-de-ingenieria-de-agentes-de-ia-juan-gabriel-gomila/",
      "bio": "Domina los Agentes de IA en 30 días: construye 8 proyectos reales con OpenAI Agents SDK, CrewAI, LangGraph, AutoGen, MCP",
      "objectives": [
        "Cómo aplicar la IA Agente a problemas comerciales del mundo real.",
        "Diseñar soluciones Agente con patrones de diseño probados y mejores prácticas.",
        "Conectar LLMs para colaborar utilizando los fundamentos de la IA Agente, como Herramientas, Salidas Estructuradas y Memoria.",
        "Crear aplicaciones Autónomas de IA Agente con CrewAI, incluyendo Agentes que escriben y ejecutan código.",
        "Construir rápidamente soluciones de Agente con OpenAI Agents SDK.",
        "Construir soluciones Agente robustas y repetibles con LangGraph.",
        "Ser pionero en la vanguardia de la IA Agente con AutoGen AgentChat y AutoGen Core.",
        "Desbloquear las vastas capacidades de herramientas y recursos de código abierto habilitados por el Modelo Contextual de Anthropic (MCP).",
        "Ofrecer soluciones comerciales innovadoras, basadas en la experiencia adquirida de 8 proyectos reales."
      ],
      "course_content": {
        "Semana 1": [
          "Día 1 - Demostración de Agentes Autónomos de IA: Usando N8n para Smart Homes",
          "Día 1 - Marcos de Agentes de IA Explicados: OpenAI SDK, Crew AI, LangGraph y más",
          "Día 1 - Configuración de Ingeniería de Agentes: Entendiendo Cursor IDE, UV y más",
          "Día 1 - Configuración de Windows para el Desarrollo de IA: Git, Cursor IDE y más",
          "Día 1 - Configuración de tu Mac para Proyectos de IA: GitHub, Cursor IDE y Clave",
          "Día 1 - Construyendo tu Primer Flujo de Trabajo de IA Agente con la API de OpenA",
          "Día 1 - Introducción la IA Agente: Creación de Flujos de Trabajo LLM Multinivel",
          "Día 2 - Construcción de Agentes Efectivos: Autonomía de LLM y Explicación",
          "Día 2 - 5 Patrones Esenciales de Diseño de Flujos de Trabajo para diseñar LLMs",
          "Día 2 - Comprendiendo los Patrones de Agentes vs Patrones de Flujos de Trabajo",
          "Día 3 - Orquestación de Múltiples LLMs: Comparar GPT-4, Claude, Gemini, DeepSeek",
          "Día 3 - Integración de Multi-LLM API: Comparando OpenAI, Anthropic y más Modelos",
          "Día 3 - Comparar APIs de LLM: Usando la Biblioteca Cliente de OpenAI con Claude",
          "Día 3 - Orquestación Multi-Modelo: Creando un Sistema para Evaluar Respuestas",
          "Día 3 - Conectando los Patrones Agentes con el Uso de Herramientas: Bloques",
          "Día 4 - Comparando Marcos de Agentes de IA: Simplicidad vs Potencia",
          "Día 4 - Recursos vs Herramientas: Dos Formas de Mejorar las Capacidades de LLM",
          "Día 4 - Crea un Chatbot Web que Actúe como Tú Usando Gradio y OpenAI",
          "Día 4 - Usando Gemini para Evaluar Respuestas de GPT-4: Una Pipeline Multi-LLM",
          "Día 4 - Construir de Flujos de Trabajo Agenticos con LLM: Recursos, Herramientas",
          "Día 5 - Construye tu Alter Ego Profesional: Llamadas a Funciones de LLM con Push",
          "Día 5 - Llamadas a Herramientas de LLM Desmitificadas: Cómo Procesar y Ejecutar",
          "Día 5 - Construcción de Asistentes de IA: Implementación de Herramientas",
          "Day 5 - Creating & Deploying an AI Agent: From Chat Loop to HuggingFace Spaces",
          "Day 5 - Deploying Career Conversation Chatbots to Gradio",
          "Día 5 - Resumen de la Semana de Fundamentos: Construyendo Agentes de IA Completo",
          "Proyecto 1"
        ],
        "Semana 2": [
          "Día 1 - Entendiendo Python Asíncrono: La Fundación para el OpenAI Agents SDK",
          "Día 1 - Fundamentos del OpenAI Agents SDK: Creación, Seguimiento y Ejecución",
          "Día 1 - Introducción a las Clases Agent, Runner y Trace en OpenAI Agents SDK",
          "Día 1 - Vibe Coding: 5 Consejos Esenciales para una Generación Eficiente de Code",
          "Día 1 - OpenAI Agents SDK: Comprendiendo los Conceptos Clave para el Desarrollo",
          "Día 2 - Construye Agentes de Ventas con IA con SendGrid: Herramientas y Colabora",
          "Día 2 - Llamadas Concurrentes a LLM: Implementando Asyncio para la Ejecución",
          "Día 2 - Convertir Agentes en Herramientas: Construyendo Sistemas Jerárquicos",
          "Día 2 - Flujo de Control de Agentes: Cuándo Usar Transferencias vs. Agentes",
          "Día 2 - De Llamadas de Funciones a Autonomía de Agentes: Automatización de Venta",
          "Día 2 - IA Agente para Negocios:Creación de Herramientas Interactivas de Alcance",
          "Proyecto 2",
          "Día 3 - Integración Multi-Modelo: usar Gemini, DeepSeek y Grok en OpenAI Agents",
          "Día 3 - Implementar Guardarraíles y Salidas Estructuradas para Sistemas Robustos",
          "Día 3 - Seguridad en IA en la Práctica: Implementación de Guardarraíles para LLM",
          "Día 4 - Construcción de Agentes de Investigación Profunda: Implementación",
          "Día 4 - Construcción de un Agente Planificador: Uso de Salidas Estructuradas",
          "Día 4 - Construcción de un Pipeline de Investigación con Agentes GPT4 y asínc",
          "Day 4 - Building a Deep Research Agent: Parallel Searches with AsyncIO",
          "Día 5 - Implementación de un Sistema Modular de Investigación con IA",
          "Día 5 - Aplicación de Investigación Profunda: Gradio para Visualizar y Monitoreo",
          "Día 5: Implementación de agentes de investigación inteligentes con Gradio y HF",
          "Proyecto 3"
        ],
        "Semana 3": [
          "Día 1 - Framework Crew AI: Creación de Equipos Colaborativos de Agentes de IA",
          "Día 1 - Explicación del Framework Crew AI: Agentes, Tareas y Modos de Procesamie",
          "Día 1 - Crew AI y LightLLM: Framework flexible para integrar múltiples LLMs",
          "Día 1 - Tutorial de Crew AI: Configuración de un proyecto de debate con GPT-4o",
          "Día 1 - Cómo crear un sistema de debate de IA usando Crew AI y múltiples LLMs",
          "Día 1 - Construcción de sistemas de debate de IA con CrewAI: Comparar LLMs",
          "Día 2 - Construcción de proyectos con Crew AI: Herramientas, contexto e integrar",
          "Día 2 - Construcción de sistemas de investigación financiera multiagente Crew.ai",
          "Día 2 - Potenciando agentes de IA con búsqueda web: problema del conocimiento",
          "Día 3 - Construcción de un selector de acciones con Crew AI: Sistema multiagente",
          "Día 3 - Implementación de salidas con Pydantic en Crew AI: Tutorial del agente",
          "Día 3 - Desarrollo de herramientas para Crew AI: JSON y notificaciones push",
          "Day 4 - Crew AI Memory: Vector Storage & SQL Implementation for AI Agents",
          "Día 4 - Crew AI para tareas de programación: Agentes que generan y ejecutan code",
          "Día 4 - Crea un agente de IA que escribe en Python: Implementación práctica coda",
          "Día 5 - Construcción de equipos de IA: Configura Crew AI para desarrollo",
          "Día 5 - Desarrollo colaborativo de agentes de IA para un framework de trading",
          "Día 5 - Construcción de una aplicación de trading usando GPT-4o y Claude",
          "Día 5 - De módulos individuales a sistemas completos: Técnicas avanzadas de Crew"
        ],
        "Semana 4": [
          "Día 1 - LangGraph explicado: Arquitectura basada en grafos para agentes de IA",
          "Día 1 - LangGraph explicado: Comparativa de framework, Studio y componentes",
          "Día 1 - Teoría de LangGraph: Componentes clave para construir sistemas avanzados",
          "Día 2 - Profundización en LangGraph: Gestión del estado en flujos de trabajo de",
          "Día 2 - Domina LangGraph: Cómo definir objetos de estado y utilizar reducers",
          "Día 2 - Fundamentos de LangGraph: Crear nodos, aristas y flujos de trabajo",
          "Día 2 - Tutorial de LangGraph: Construcción de un chatbot de OpenAI con grafos",
          "Día 3 - Tutorial avanzado de LangGraph: Super Steps y Checkpointing explicados",
          "Día 3 - Configuración de Langsmith y creación de herramientas personalizadas",
          "Día 3 - Tool Calling en LangGraph: Trabajando con aristas condicionales y nodos",
          "Día 3 - Checkpointing en LangGraph: Cómo mantener la memoria en conversaciones",
          "Día 3 - Construcción de memoria persistente para IA con SQLite: Gestión estados",
          "Día 4 - Integración de Playwright con LangGraph: Creación de agentes de IA web",
          "Día 4 - Crea asistentes web de IA: Playwright, LangChain y Gradio",
          "Día 4 - Agentes evaluadores para LLM: Creación de bucles de retroalimentación",
          "Día 4 - Creación de bucles de retroalimentación en LLM: patrón worker-evaluator",
          "Día 4 - Construcción de un asistente de IA con LangGraph, Gradio, automatización",
          "Día 5 - IA basada en agentes: Añade búsqueda web, sistema de archivos y Python",
          "Día 5 - Integración de herramientas de LangChain: Construcción de un asistente",
          "Día 5 - Creación de flujos de trabajo de IA: Constructores de grafos y técnicas",
          "Día 5 - Creación de sesiones de usuario aisladas en aplicaciones de Gradio",
          "Día 5 - Dentro de los bucles de retroalimentación de IA: IA evalúa y corrige",
          "Day 5 - AI Assistant Upgrades: Memory, Clarifying Questions & Custom Tools"
        ],
        "Semana 5": [
          "Día 1 - Microsoft Autogen 0.5.1: El framework de agentes de IA explicado",
          "Día 1 - AutoGen vs otros frameworks de agentes: comparación de características",
          "Día 1 - Tutorial de AutoGen Agent Chat: creación de herramientas e integración",
          "Día 1 - Componentes esenciales de IA: modelos, mensajes y agentes explicados",
          "Día 2 - AutoGen Agent Chat avanzado: características multimodales y salidas estr",
          "Día 2 - Implementación de agentes principales y evaluadores en AutoGen+LangChain",
          "Día 2 - Tutorial de headless web scraping: integración de MCP Server Fetch en AG",
          "Día 3 - AutoGen Core: la columna vertebral de las comunicaciones distribuidas",
          "Día 3 - Comunicación entre agentes en Autogen Core: manejadores de mensajes",
          "Día 3 - Registro de agentes y manejo de mensajes en AutoGenCore: ejemplos",
          "Día 3 - Agentes independientes en AutoGenCore: piedra, papel o tijera con GPT-4o",
          "Día 4 - Distributed Runtime en Autogen Core: arquitectura+componentes explicados",
          "Día 4 - Implementación de agentes de IA distribuidos con AutoGen Core y gRPC",
          "Día 4 - Construcción de sistemas de agentes distribuidos: comunicación",
          "Día 5 - Creación de agentes autónomos que escriben y despliegan otros agentes",
          "Día 5 - Implementación de mensajería entre agentes con Autogen Core y plantillas",
          "Día 5 - Creación de agentes de IA autónomos que colaboran usando Python asíncron"
        ],
        "Semana 6": [
          "Día 1 - Introducción al Model Context Protocol (MCP): conector IA de Anthropic",
          "Día 1 - Arquitectura de MCP explicada: comprensión de hosts, clients y servers",
          "Día 1 - MCP Server Studio: conectando LLMs a potentes herramientas externas",
          "Día 1 - Marketplaces de MCP Server: accede a miles de herramientas para OpenAI",
          "Día 2 - Cómo crear un servidor MCP: construcción de colecciones de herramientas",
          "Día 2 - Construye tu propio servidor MCP: código Python a herramientas accesible",
          "Día 2 - Cómo implementar un cliente MCP para integración de herramientas OpenAI",
          "Día 2 - Arquitectura MCP: construcción de sistemas cliente-servidor+herramientas",
          "Día 3 - Añadiendo memoria persistente a agentes de IA + servidores MCP Knowledge",
          "Día 3 - Configuración de Brave Search y APIs de Alpha Vantage con servidores MCP",
          "Día 3 - Configuración de APIs de datos financieros: clonar y configurar conexión",
          "Día 4 - Creación de un sistema de trading multiagente con memoria compartida",
          "Día 4 - Colaboración entre agentes: convertir un investigador en herramienta",
          "Día 4 - Agentes de trading con uso de herramientas: implementación de MCP",
          "Día 4 - OpenAI Agents SDK: desarrollo de un módulo de sistema de trading multiag",
          "Día 4 - Métodos avanzados: implementación de funciones de trading en OpenAI",
          "Día 4 - Construcción de agentes de trading resilientes: manejo de errores en IA",
          "Día 5 - Proyecto final:notificaciones push y evolución de estrategias en trading",
          "Día 5 - Panel de control de trading con IA: visualización del rendimiento",
          "Día 5 - Ingeniería de IA agentica: conclusión del curso y aplicaciones reales",
          "Día 5 - 10 consejos finales"
        ],
        "Bonus": [
          "Bonus"
        ]
      },
      "requirements": [
        "Aunque es ideal que sepas programar en Python y tengas algo de experiencia trabajando con LLMs, este curso está diseñado para una audiencia muy amplia, sin importar su nivel o experiencia previa. He incluido una carpeta completa de laboratorios de autoestudio que cubren habilidades técnicas y de programación fundamentales. Si eres nuevo en la programación, solo hay un requisito: ¡mucha paciencia!",
        "El curso funciona mejor si tienes un presupuesto pequeño para APIs, pero es totalmente opcional. Puedes completar todo el curso sin gastar en APIs. Si deseas utilizar modelos de vanguardia, el gasto típico sería inferior a $5. Puedes optar por acceder a más capacidades si te sientes cómodo gastando un poco más."
      ],
      "description": "El 2025 es el año en que los Agentes entran al mercado laboral. Este es un momento decisivo para la Inteligencia Artificial. Nunca ha sido más importante ser un experto en IA Agente, y ese es precisamente el objetivo de este curso: dotarte de las habilidades y conocimientos necesarios para diseñar, construir y desplegar Agentes de IA Autónomos, abriendo nuevas oportunidades comerciales y profesionales.\nEste es un programa intensivo de 6 semanas para dominar la IA Agente. Comenzamos construyendo una base sólida, conectando Modelos de Lenguaje Grande (LLMs) usando patrones de diseño probados. Luego, cada semana, mejoraremos nuestras habilidades con nuevos marcos: OpenAI Agents SDK, CrewAI, LangGraph y Autogen. El curso culmina con una semana completa dedicada a las impresionantes oportunidades que abre MCP.\nSobre todo, este es un curso práctico. Creo firmemente que la mejor manera de aprender es HACIENDO. ¡Así que prepárate para ponerte manos a la obra! Construiremos 8 proyectos del mundo real; algunos son sorprendentes, otros intrigantes y algunos bastante surrealistas. Pero una cosa es segura: todos son poderosas demostraciones del potencial de la IA Agente para transformar por completo el panorama empresarial.\nÚnete a mí en este viaje completo de 6 semanas. Al final, habrás dominado la IA Agente. Tendrás experiencia en todos los marcos principales. Estarás bien versado en las fortalezas y trampas de la IA Agente. Desplegarás con confianza Agentes Autónomos para resolver problemas comerciales reales. Y durante el proceso, habrás disfrutado muchísimo con la asombrosa y revolucionaria tecnología que es la IA Agente.",
      "target_audience": [
        "Bueno, tal vez esté siendo parcial, pero diría: ¡cualquiera y todos! Si te fascina el potencial de los Agentes y tienes ganas de adquirir las habilidades para crear poderosa IA Agente, entonces has llegado al lugar indicado. Aunque está más orientado a quienes tienen experiencia en programación, he diseñado el curso para que funcione para personas de cualquier formación.",
        "Estudiantes de nuestra ruta de IA que busquen llevar sus habilidades al siguiente nivel con Ingeniería de Agentes de IA"
      ]
    },
    {
      "title": "\"أساسيات البرمجة بلغة بايثون - دليل المبتدئين الشامل!\"",
      "url": "https://www.udemy.com/course/khmvvpfn/",
      "bio": "أساسيات البرمجة بلغة بايثون - تعلم Python",
      "objectives": [
        "فهم أساسيات البرمجة بلغة بايثون، بما في ذلك المتغيرات، أنواع البيانات، والعوامل.",
        "كتابة برامج بايثون بسيطة باستخدام العبارات الشرطية، الحلقات، والدوال.",
        "التعامل مع القوائم، والقواميس، وهياكل البيانات الأساسية في بايثون.",
        "تصحيح الأخطاء وتحسين الأكواد باستخدام أفضل الممارسات والمعايير البرمجية."
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "تثبيت بايثون ومحرر الاكواد"
        ],
        "Print Function": [
          "print function"
        ],
        "Data Types": [
          "انواع البيانات"
        ],
        "Variables": [
          "المتغيرات"
        ],
        "Comments": [
          "التعليقات"
        ],
        "Mathematical Operators": [
          "العمليات الرياضيه"
        ],
        "Escape Character": [
          "Escape Character"
        ]
      },
      "requirements": [
        "لا يُشترط وجود أي خبرة سابقة في البرمجة، حيث سيتم شرح كل شيء من الصفر.",
        "جهاز كمبيوتر يحتوي على اتصال انترنت"
      ],
      "description": "هذه الدورة موجهة للمبتدئين اللي حابين يتعلموا أساسيات البرمجة باستخدام لغة Python بشكل بسيط وواضح. خلال الدورة، رح نبدأ من الصفر بدون أي متطلبات سابقة في البرمجة.\n\n\nرح نتعرف على المفاهيم الأساسية مثل المتغيرات (Variables) وأنواع البيانات (Data Types) المختلفة زي الأرقام والنصوص والقوائم والقواميس. بالإضافة لذلك، رح نتعلم كيفية التعامل مع عمليات الإدخال والإخراج (Input/Output) وطريقة استخدام العمليات الحسابية والمنطقية في بناء البرامج.\n\n\nرح نتطرق كمان للجمل الشرطية (Conditional Statements) مثل if و else، والحلقات التكرارية (Loops) مثل for و while وكيفية استخدامها في إنشاء برامج أكثر تفاعلية وفعالية.\n\n\nوأخيرًا، رح نشرح كيفية كتابة الدوال (Functions) بطريقة سهلة ومبسطة، وكيفية استخدامها لإعادة استخدام الكود وتنظيمه بشكل أفضل. رح يتم شرح كل موضوع خطوة بخطوة مع أمثلة عملية وتمارين تطبيقية عشان تثبت المعلومات بشكل كامل.\n\n\nبنهاية الدورة، رح تكون قادر على كتابة برامجك الخاصة باستخدام Python وحل المشاكل البرمجية بشكل مستقل. هالدورة مصممة لتكون مدخلًا قويًا لأي شخص حابب يتعلم البرمجة باستخدام Python، وهي خطوة أساسية ومهمة للانتقال بعد ذلك لمستويات أكثر تقدمًا في البرمجة. الدورة مناسبة للطلاب، الهواة، وأي شخص عنده اهتمام بتعلم البرمجة. بالإضافة إلى ذلك، ستتعلم كيفية التفكير المنطقي وحل المشاكل بطريقة إبداعية وفعالة، واستخدام لغة بايثون في إنشاء تطبيقاتك المستقبلية. انضم الآن وابدأ رحلتك في تعلم البرمجة بلغة بايثون",
      "target_audience": [
        "أي شخص يرغب في بناء أساس قوي في البرمجة بلغة بايثون في وقت قصير.",
        "المبتدئون الذين لم يسبق لهم البرمجة ويرغبون في تعلم لغة بايثون.",
        "الطلاب الذين يستعدون لمشاريع أو مساقات تعليمية تعتمد على بايثون."
      ]
    },
    {
      "title": "【初心者向け】AIエージェントを作ってみよう！LangChain・LangGraph・LangSmithの使い方を学ぼう",
      "url": "https://www.udemy.com/course/ai-agent-langchain/",
      "bio": "LangChainで簡単なAIエージェントを作った後にLangGraphを使った複雑なワークロー構築を学びます。またLangSmithを使ってAIエージェントのワークフローを可視化していきます",
      "objectives": [
        "AIエージェントの構築方法",
        "React Agentを使ったAIエージェント構築方法",
        "LangGraphを使ったAIエージェント構築方法",
        "LangSmithを使ったAIエージェント処理状況の確認"
      ],
      "course_content": {
        "紹介": [
          "イントロダクション"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Searbornについて学ぼう！",
          "Python構文の復習"
        ],
        "LangChainを使ってシンプルな掛け算・足し算AIエージェントを作っていこう！": [
          "OpenAIのAPIキー取得方法",
          "ライブラリやAPIキーの準備",
          "各ツールの設定とAIエージェントの作成",
          "実行結果を確認してみよう！"
        ],
        "LangChainを使って応用AIエージェントを作っていこう！": [
          "News API キーの取得方法",
          "X（旧Twitter）のAPI利用の準備",
          "ライブラリやAPIの準備",
          "ニュースを取得するToolを定義しよう！",
          "要約するToolを定義しよう！",
          "TweetするToolを定義しよう！",
          "AIエージェントを作って結果を確認してみよう！"
        ],
        "LangGraphを使ってAIエージェントを作っていこう！": [
          "LangGraphに関する説明と条件分岐関数の作成",
          "call_llmノードの作成をしよう！",
          "Graph構築をしていこう！",
          "Graph描画とエージェント実行をしていこう！"
        ],
        "LangGraph × LangSmithでAIエージェントの動きを可視化しよう！": [
          "VScodeの準備とPythonの準備",
          "LangSmithのAPIキーを取得していこう！",
          "AIエージェント構築の各種ファイル準備",
          "LangSmithの設定",
          "メインファイルのコードを書いていこう！",
          "LangSmith上でAIエージェントの動きを確認してみよう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学びますのでプログラミングの知識は特に必要ありません"
      ],
      "description": "AIエージェント構築講座へようこそ！\n\n\nこの講座では今話題のAIエージェントをご自身の力でPythonを使いながら構築していきます。\n使うフレームワークはLangChain、LangGraph、LangSmith。\n\n\nこれらのフレームワークを使うことで誰でも簡単にAIエージェントを作ることができますし、AIエージェントのワークフローや処理状況もGUI上で確認できるようになります。\nLangChain、LangGraph、LangSmithで出来ることは幅広いので網羅的に説明することはしません。必要なエッセンスだけに焦点を当てて解説していきます。\n\n\nまず、非常にシンプルな足し算・掛け算を行うAIエージェントを作った後に、ニュース情報を取得したり要約したりTweetしたりできる応用AIエージェントを作っていきましょう！\n\n\nこの講座で、独自のAIエージェントを作れるようになりましょう！",
      "target_audience": [
        "AIエージェント開発に挑戦してみたい方",
        "LangChain・LangGraph・LangSmithの使い方の基礎をザッと理解したい方"
      ]
    },
    {
      "title": "Üretken Yapay Zeka (Generative AI)",
      "url": "https://www.udemy.com/course/uretken-yapay-zeka-genai/",
      "bio": "Üretken yapay zeka ve büyük dil modellerini temelinden başlayarak öğrenin ve onları kullanarak yazılım geliştirin.",
      "objectives": [
        "Üretken yapay zekayı anlayabilmek için, öncelikle onun temelini oluşturan, makine öğrenmesini ve alt kategorilerini öğreneceksiniz.",
        "Örnek makine öğrenmesi algoritmaları olarak, doğrusal regresyonu ve lojistik regresyonu öğreneceksiniz.",
        "Üretken yapay zeka için kullanılan makine öğrenme teknolojisi olan yapay sinir ağlarını anlayacaksınız.",
        "Üretken yapay zeka tanımını ve hangi amaçlarla kullanılabileceğini öğreneceksiniz.",
        "Görüntü oluşturmak için kullanılan üretken yapay zeka teknolojilerini ve örnek uygulamaları öğreneceksiniz.",
        "Doğal dil işleme alanında kullanılan üretken yapay zeka teknolojisi olan büyük dil modelini, kullanım alanlarını ve popüler uygulamalarını öğreneceksiniz.",
        "Büyük dil modelinin parçalarından birisi olan istem(prompt), onun bileşenlerini ve tekniklerini öğrenecek, amacınıza yönelik etkin istem oluşturabileceksiniz.",
        "Doğal dil işleme kavramları olan token ve kelime gömmeyi öğreneceksiniz.",
        "Büyük dil modelinin önemli yapıtaşlarından birisi olan transformer mimarisini öğreneceksiniz.",
        "Açık kaynak kodlu dil modellerini bulabileceğiniz makine öğrenmesi ve doğal dil işlemenin Github olarak nitelenen Hugging face ortamı ile tanışacaksınız.",
        "İnce ayar (fine-tuning) tekniğini öğrenecek ve uygulayabileceksiniz.",
        "Büyük dil modelini harici bilgi kaynağı ile beraber kullanmanızı sağlayacak Retrieval Augmented Generation (RAG) tekniğini öğrenecek ve uygulayabileceksiniz.",
        "Büyük dil modelinin iş akışlarında kullanmanızı sağlayacak LLM zincirlerini öğrenecek ve uygulayabileceksiniz.",
        "Büyük dil modelinin dış dünya ile iletişime girmesini sağlayan agent ve tools kavramlarını öğrenecek ve uygulayabileceksiniz.",
        "Duygu analizi, metin üretme, tercüme, soru cevaplama, özet çıkarma, metinden görüntü oluşturma gibi fonksiyonlar için uygulama geliştirebileceksiniz.",
        "Kurs boyunca öğrendiğiniz konuların, python ile kodlanarak nasıl hayata geçirilebileceğini gösteren 28 ayrı kod örneğini inceleyeceksiniz.",
        "Sohbet robotu (Chatbot) geliştirmek için kullanabileceğiniz Chat Completion API’I öğreneceksiniz ve örnek bir sohbet robotu uygulaması geliştirebileceksiniz.",
        "Görsel Dil modellerinin (Visual Language Models - VLM) mimarisini ve VLM kullanımını gösteren kod örneklerini göreceksiniz."
      ],
      "course_content": {
        "Giriş": [
          "Hoşgeldiniz",
          "Kurs İçeriği"
        ],
        "Makine öğrenmesi": [
          "Yapay zeka tanımı",
          "Makine öğrenmesi tanımı",
          "Makine öğrenmesi yöntemleri",
          "Doğrusal regresyon",
          "Uygulama: Doğrusal regresyon kod örneği",
          "Lojistik regresyon",
          "Sınıflandırma performans metrikleri",
          "Uygulama: Lojistik regresyon kod örneği",
          "Yapay sinir ağları",
          "Uygulama: Yapay sinir ağları kod örneği",
          "Makine öğrenmesi örnek uygulama alanları",
          "Makine öğrenmesi"
        ],
        "Üretken yapay zeka": [
          "Üretken yapay zeka tanımı",
          "Görüntü oluşturma",
          "Üretken yapay zeka"
        ],
        "Büyük dil modeli": [
          "Büyük dil modeli tanımı",
          "Büyük dil modeli kullanımı",
          "Büyük dil modeli eğitimi",
          "İstem",
          "Kodlayıcı ve kod çözücü modeller",
          "Büyük dil modeli kısıtlama ve sorunları",
          "Büyük dil modeli"
        ],
        "Doğal dil işleme kavramları": [
          "Token yapısı",
          "Kelime gömme",
          "Word2Vec",
          "Uygulama: Word2Vec kod örneği",
          "Doğal dil işleme kavramları"
        ],
        "Transformer": [
          "Transformer mimarisi",
          "Transformer eğitim süreci",
          "Transformer çıkarım süreci",
          "Transformer"
        ],
        "Açık kaynak kodlu dil modelleri": [
          "Hugging Face",
          "Karbon ayak izi",
          "Açık kaynak kodlu dil modelleri"
        ],
        "Uygulama: Büyük dil modeli kod örnekleri": [
          "Duygu analizi",
          "Metin üretme",
          "Tercüme",
          "Soru cevaplama",
          "Metin sınıflandırma",
          "Özet çıkarma",
          "Metindeki eksik kelimenin üretilmesi",
          "İsimlendirilmiş varlık tanıma",
          "Birden fazla atışlı istem",
          "Metinden görüntü oluşturma",
          "Model parametreleri",
          "Model parametrelerinin kullanım örnekleri",
          "Büyük dil modeli kodlama örnekleri"
        ],
        "İnce ayar eğitim": [
          "İnce ayar eğitim",
          "Uygulama: İnce ayar kod örneği",
          "PEFT",
          "İnce ayar"
        ],
        "Retrieval Augmented Generation (RAG)": [
          "RAG mimarisi",
          "Uygulama: RAG kod örneği",
          "RAG"
        ]
      },
      "requirements": [
        "Lise seviyesinde temel matematik bilgisi",
        "Temel programlama ve algoritma yazma ya da anlama becerilerinin olması",
        "Python bilgisi şart olmamakla beraber örnek kodların anlaşılması için faydalı olabilecektir."
      ],
      "description": "2023 senesi ile beraber büyük dil modellerinde yaşanan gelişmeye paralel olarak üretken yapay zekanın kullanımında büyük bir patlama yaşandı. ChatGPT, Bing, Google Bard gibi üretken yapay zeka ürünleri çok büyük kullanıcı sayılarına eriştiler. Bununla beraber bir çok kişi ve kurum da, üretken yapay zekayı kendi alanlarında nasıl kullanabileceklerini ya da fark yaratabileceklerini araştırmaya başladılar. Bu kursun amacı da tam olarak bu soruya cevap vermek, üretken yapa zeka ile neler yapılabileceğini ve nasıl yapılabileceğini göstermek.\nÜretken yapay zekanın temeli makine öğrenmesi ve yapay sinir ağlarıdır. Bu kavramları bilmek, üretken yapay zekayı tam olarak anlamak için önemli bir avantajdır. Bu kursun, herhangi bir ön bilgi gereksinimi olmadan, herkes tarafından takip edilebilir ve anlaşılabilir olmasını istediğimden, kursa  makine öğrenmesi, makine öğrenmesinin temel algoritmaları ve yapay sinir ağlarını içeren bir bölüm ile başladım.\nKursun çok önemli bir bölümü büyük dil modellerinin üzerine yoğunlaşıyor ve dil modelinin temelini oluşturan transformer mimarisi, dil modellerinin kullanımında çok etkin rolü olan istem (prompt) tasarımı gibi bölümler içeriyor. Üretken yapay zekayı kendi uygulamalarınızda kullanabilmek için temelde iki yöntem vardır: bazı büyük dil modelleri tarafından sağlanan API'lerin çağrılması ya da büyük dil modelini kendi uygulamanız içinden yükleyerek kullanmanız. Kursta her iki yöntem de anlatılıyor ama özellikle ikinci yöntem ve açık kaynak kodlu büyük dil modellerinin kullanımı üzerinde duruluyor. Kurs içinde bunu destekleyen, duygu analizi, metin üretme, tercüme, soru cevaplama, metin sınıflandırma, özet çıkarma, metinden görüntü oluşturma gibi çok sayıda doğal dil işleme fonksiyonlarını yerine getiren python kodunu beraber inceleyeceğiz. Bu sayede siz de, kendi uygulamalarınızda bu fonksiyonları rahatça gerçekleştirebileceksiniz.\nBüyük dil modellerinin sınırlarını genişleten ve bu konudaki son teknolojilerden olan RAG (Retrieval Augmented Generation), LLMChain, agent and tools yöntemlerinin de çok ilginizi çekeceğini düşünüyorum. Kurs içinde hem bu yöntemlerin altyapılarını, hem de bu yöntemler kullanılarak yazılmış uygulamaların python kodlarını bulabileceksiniz.\nKursa sonradan ilave ettiğim Ek1 bölümünde, sohbet robotu (Chatbot) uygulaması geliştirmek için kullanabileceğiniz Chat Completion API özelliklerini öğreneceksiniz. Buna ilaveten Chat Completions API kullanılarak geliştirilmiş sohbet robotu prototip uygulama kodunu beraber inceleyeceğiz. Ek2 bölümünde Görsel Dil Modellerinin (Visual Language Models - VLM) çalışma yapısını ve VLM kullanımını gösteren kod örneklerini göreceksiniz. Özellikle VLM vasıtasıyla fatura görüntüsünden, fatura bilgilerini aldığımız örneğin ilginizi çekeceğini düşünüyorum.\nBölüm sonlarındaki sınavlar, bölüm içinde anlatılanları pekiştirmenize yardımcı olacaktır. Kurs içinde anlatılanların teorik bilgi olarak kalmaması ve nasıl hayata geçirildiğini deneyimlemek için yazılmış 28 farklı python kodunu beraber inceleyeceğiz.\nÜretken yapay zekayı kendi alanınızda ve kendi uygulamalarınızda bir an önce kullanmak istiyorsanız, bu kurs sonunda bu amacınıza gerçekleştirebilecek bilgi ve beceriye sahip olacaksınız.",
      "target_audience": [
        "Üretken yapay zeka teknolojisini öğrenerek, kendi alanlarında fark yaratmak isteyen kişiler için bu kurs ilham verici bir araç olacaktır.",
        "Üretken yapay zekayı kullanarak kod geliştirmek isteyen yazılımcılar",
        "Üretken yapay zeka vasıtası ile yeni proje, ürün, iş fırsatı oluşturmak isteyen farklı rollerdeki kişiler"
      ]
    },
    {
      "title": "NumPyro で学ぶ ベイズ統計モデリング 【応用編】",
      "url": "https://www.udemy.com/course/numpyro-advanced/",
      "bio": "Google Colaboratory で実践する統計モデリング",
      "objectives": [
        "確率プログラミング（NumPyro）",
        "ベイズ統計モデリングのさまざまな応用例",
        "ロバスト線形回帰・クラスタリング・変化点検出・レイティング",
        "微分方程式のパラメータ推定・構造時系列モデルの基礎"
      ],
      "course_content": {
        "イントロダクション": [
          "コース紹介",
          "コースに関する案内と注意点"
        ],
        "ロバスト線形回帰": [
          "確率プログラミングの基礎",
          "Google Colaboratory での実践１",
          "ロバスト線形回帰",
          "Google Colaboratory での実践２",
          "ここまでのまとめ"
        ],
        "クラスタリング": [
          "クラスタリングと混合ガウスモデル",
          "Google Colaboratory での実践",
          "混合線形回帰モデル",
          "ここまでのまとめ"
        ],
        "変化点検出": [
          "変化点検出",
          "Google Colaboratory での実践",
          "ここまでのまとめ"
        ],
        "レイティング": [
          "レイティング",
          "Google Colaboratory での実践",
          "ここまでのまとめ"
        ],
        "微分方程式の逆問題": [
          "鉛直投げ上げ運動",
          "Google Colaboratory での実践１",
          "捕食者と被食者のダイナミクス",
          "乗法的誤差と対数正規分布",
          "Google Colaboratory での実践２",
          "ここまでのまとめ"
        ],
        "時系列モデリング - A": [
          "構造時系列モデルの基礎",
          "Google Colaboratory での実践",
          "変化点検出",
          "確率的ボラティリティモデル",
          "ここまでのまとめ"
        ],
        "時系列モデリング - B": [
          "scan 関数",
          "トレンドモデル",
          "構造時系列モデル",
          "ここまでのまとめ",
          "おわりに"
        ]
      },
      "requirements": [
        "Python を使ったデータ解析の基礎知識（グラフが書ける程度）",
        "確率・統計の基礎知識",
        "事前分布・事後分布・尤度・事後予測分布などの用語が理解できること"
      ],
      "description": "本コースは、主にベイズ統計の基本的な考え方を理解している皆様に向けて、ベイズ統計モデリングのさまざまな応用例を紹介するコースとなっています。最初は、線形回帰やロバスト線形回帰などの基本的な例題からスタートして、徐々に変化点検出やレイティング、微分方程式のパラメータ推定などのさまざまな応用例を見ていきます。本コースでは、こうしたさまざまな応用例を Google Colaboratory 上で動かしてゆき、たくさんのスライドとサンプルコードの両方で、統計モデリングの知識を深めてゆきます。\n\n\nまた、こうした例題には NumPyro と呼ばれる確率プログラミングのパッケージを利用します。NumPyro は、JAX と呼ばれる高速なバックエンドを持っていることが特徴の確率プログラミングのパッケージであり、モデルのパラメータ推定などを高速に行えるのが、大きな特徴のひとつになっています。また、NumPyro は Python のパッケージであることから、Python の経験者にとっては、比較的少ない学習コストで統計モデリングや確率プログラミングという新しい世界を覗いてみることができることも大きなメリットのひとつとなっています。\n\n\nNumPyro の最新バージョンは現在のところ 0.7.2 ですが（2021年9月現在）、動作は安定しており、普通に利用するには大きな問題はないものと考えています。ただ、パッケージがまだまだ発展途上であることには注意が必要です。業務等での利用の際には十分にご注意下さい。また、NumPyro に関しては、和書などの日本語の情報が少ないため、わからないことが出てきた場合には、ある程度英語で情報を読み解く力が必要になります。その点にもご注意下さい。\n\n\nなお、本コースで使用している NumPyro のバージョンは 0.7.2 です。\n\n\n【注意点】\n\n\n本コースは、基本的には既に公開されている「NumPyro で学ぶベイズ統計モデリング【基礎編】」の続編にあたる講座となりますが、基礎編の全ての内容を前提としている訳ではありません。「MCMC 」や「事前分布・事後分布」といったベイズ統計の基本的な用語に関する知識があれば、概ねコースの内容を理解できるものと想定しています。\n\n\nまた、コースの前半では、線形回帰の例題を使った NumPyro の入門的な内容も紹介していますので、Stan や PyMC3 等に少しでも触れたことのある方であれば、あまり苦労せずに中身を理解して頂くことができるのではないかと考えています。\n\n\nなお、本コースでは一部においてパッケージの実験的な機能を使っている部分がありますので、インターフェース等には将来的に変更がある可能性のある部分があります。予めご了承下さい。また、確率プログラミングの技術を広く拡散させるため、本コースで紹介しているコードをブログ等の記事で紹介する可能性が御座います。その点につきましても予めご了承頂けますと幸いです。",
      "target_audience": [
        "ベイズ統計モデリング・確率プログラミングに興味がある人",
        "ベイズ統計モデリングのさまざまな応用例に興味がある人"
      ]
    },
    {
      "title": "Data science y machine learning en Python: modelos lineales",
      "url": "https://www.udemy.com/course/data-science-python-espanol/",
      "bio": "Domina los algoritmos más populares de la ciencia de datos y machine learning en Python (regresión lineal, logística...)",
      "objectives": [
        "Implementar todos nuestros modelos desde cero, paso por paso. Aprenderás cada detalle de su teoría y funcionamiento.",
        "Entender fundamentalmente los algoritmos más populares del machine learning.",
        "Dominar las principales librerías de machine learning en Python: scikit-learn, NumPy, pandas, matplotlib, etc.",
        "Entender el ciclo de trabajo en la ciencia de datos y como resolver problemas de predicción de principio a fin.",
        "Diagnosticar y resolver problemas en nuestros modelos. Serás la persona a la que acudan tus compañeros cuando sus modelos fallen."
      ],
      "course_content": {
        "Introducción": [
          "Bienvenida",
          "Paradigmas del machine learning",
          "Nuestro catálogo completo de cursos",
          "datos y \"datapoints\"",
          "¿Qué es un modelo?",
          "Herramientas de software para machine learning",
          "Código completo",
          "Serie de cursos sobre ciencia de datos y machine learning",
          "Links al resto de cursos de la serie sobre ciencia de datos y machine learning",
          "Síguenos en redes sociales"
        ],
        "Regresión lineal simple": [
          "Breve repaso de funciones derivadas",
          "Regresión lineal simple",
          "Suposiciones del modelo",
          "Encontrar el modelo de mejor ajuste",
          "Estimación de máxima verosimilitud",
          "Estimación de máxima verosimilitud de β₀",
          "Estimación de máxima verosimilitud de β₁",
          "Estimación de máxima verosimilitud de σ²",
          "Interpretación de los parámetros obtenidos",
          "Evaluación del ajuste del modelo",
          "Mínimos cuadrados ordinarios",
          "Modelos sin ordenada al origen",
          "Evaluación de las suposiciones del modelo",
          "Enlace a la libreta de código",
          "Encontrar el modelo de mejor ajuste - Código 1",
          "Encontrar el modelo de mejor ajuste - Código 2",
          "Encontrar el modelo de mejor ajuste - Código 3",
          "Encontrar el modelo de mejor ajuste - Código 4",
          "Encontrar el modelo de mejor ajuste - Código 5"
        ],
        "Regresión lineal múltiple": [
          "Regresión lineal múltiple",
          "Hallar los parámetros β del modelo",
          "Enlace a la libreta de código",
          "Creación de nuestro primer modelo de RLM - Código 1",
          "Creación de nuestro primer modelo de RLM - Código 2",
          "Creación de nuestro primer modelo de RLM - Código 3",
          "Creación de nuestro primer modelo de RLM - Código 4",
          "Variables categóricas y variables dummy",
          "Interpretación de coeficientes de variables dummy",
          "Interacción entre variables",
          "Regresión lineal múltiple con variables categóricas - Código 1",
          "Regresión lineal múltiple con variables categóricas - Código 2",
          "Estandarización de variables",
          "Rankeo de variables predictivas en código",
          "Multicolinearidad",
          "Factor de inflación de la varianza (VIF)",
          "Tratamiento de la multicolinearidad - Código 1",
          "Tratamiento de la multicolinearidad - Código 2",
          "Tratamiento de la multicolinearidad - Código 3"
        ],
        "Predicción del precio de los diamantes": [
          "Enlace a la libreta de código",
          "Ciclo de vida de un proyecto de ciencia de datos",
          "Predicción del precio de los diamantes - Código 1",
          "Predicción del precio de los diamantes - Código 2",
          "Datos de entrenamiento, validación y testeo",
          "Predicción del precio de los diamantes - Código 3",
          "Predicción del precio de los diamantes - Código 4",
          "Predicción del precio de los diamantes - Código 5",
          "Transformaciones de las variables x e y",
          "Predicción del precio de los diamantes - Código 6",
          "Predicción del precio de los diamantes - Código 7",
          "Información mutua",
          "Predicción del precio de los diamantes - Código 8",
          "Scikit-learn y la clase Pipeline",
          "La clase ColumnTransformer",
          "La clase TransformedTargetRegressor",
          "Predicción del precio de los diamantes - Código 9",
          "Predicción del precio de los diamantes - Código 10",
          "Interpretar el coeficiente de ln(x)",
          "Interpretar los coeficientes de un modelo con ln(y)",
          "Interpretar los coeficientes de un modelo con ln(y) y ln(x)",
          "Interpretar el coeficiente de una variable dummy en modelos ln(y)",
          "Predicción del precio de los diamantes - Código 11"
        ],
        "Regresión polinómica": [
          "Sobreajuste y generalización",
          "Regresión polinómica",
          "Enlace a la libreta de código",
          "Regresión polinómica - código 1",
          "Regresión polinómica - código 2",
          "Interacciones entre variables",
          "Regresión polinómica - código 3",
          "Sobreajuste en la regresión polinómica",
          "Regresión polinómica - código 4",
          "Multicolinearidad estructural",
          "Regresión polinómica - código 5",
          "Regresión polinómica - código 6"
        ],
        "Regresión ridge": [
          "Enlace a la libreta de código",
          "Regresión ridge 1",
          "Regresión ridge 2",
          "Regresión ridge 3",
          "Regresión ridge 4",
          "Regresión ridge 5",
          "Regresión ridge - Código 1",
          "Regresión ridge - Código 2",
          "Regresión ridge - Código 3",
          "Regresión ridge - Código 4",
          "Regresión ridge - Código 5",
          "Regresión ridge - Código 6"
        ],
        "Regresión lasso": [
          "Enlace a la libreta de código",
          "Regresión lasso - 1",
          "Regresión lasso - 2",
          "Regresión lasso - 3",
          "Regresión lasso - 4",
          "Regresión lasso - 5",
          "Regresión lasso - 6",
          "Regresión lasso - 7",
          "Regresión lasso en código - 1",
          "Regresión lasso en código - 2",
          "Regresión lasso en código - 3",
          "Regresión lasso en código - 4",
          "Regresión lasso en código - 5",
          "Regresión lasso en código - 6",
          "Regresión lasso en código - 7",
          "Comparación entre regresión ridge y lasso"
        ],
        "Regresión logística": [
          "Regresión logística 1",
          "Regresión logística 2",
          "Regresión logística 3",
          "Regresión logística 4",
          "Regresión logística 5",
          "Regresión logística 6",
          "Regresión logística 7",
          "Regresión logística 8",
          "Regresión logística 9",
          "Regresión logística 10",
          "Regresión logística - Code 1",
          "Regresión logística - Code 2",
          "Regresión logística - Code 3",
          "Regresión logística - Code 4",
          "Regresión logística - Code 5",
          "Regresión logística - Code 6",
          "Regresión logística - Code 7",
          "Regresión logística - Code 8",
          "Regresión logística - Code 9",
          "Regresión logística - Code 10"
        ],
        "Clasificación de dígitos escritos a mano": [
          "Clasificación de dígitos escritos a mano - Parte 1",
          "Clasificación de dígitos escritos a mano - Parte 2",
          "Clasificación de dígitos escritos a mano - Parte 3"
        ],
        "Siguientes pasos": [
          "Conecta conmigo en redes sociales"
        ]
      },
      "requirements": [
        "Nociones básicas de Python (variables, bucles, clases, etc)",
        "Experiencia con pandas y visualización de datos ayuda pero no es necesaria."
      ],
      "description": "¿Por qué estudiar ciencia de datos?\nLas empresas tienen un problema: recolectan y guardan enormes cantidades de datos en su día a día. El problema es que no tienen las herramientas y capacidades para extraer conocimiento y tomar decisiones a partir de esos datos. Pero eso está cambiando. Desde hace algunos años, la demanda de científicos de datos ha crecido exponencialmente. Tanto es así, que el número de personas con estas habilidades no es suficiente para cubrir todas las vacantes que hay. Una búsqueda básica en Glassdoor o Indeed te revelará por qué los salarios de los científicos de datos han crecido tanto en los últimos años.\n\n\n¿Por qué este curso?\nCasi todos los cursos que existen son demasiado teóricos o demasiado prácticos. Los cursos de universidad no suelen desarrollar las habilidades necesarias para enfrentarse a problemas de ciencia de datos desde cero, ni te enseñan a utilizar el software necesario de forma fluida. Por otra parte, muchos cursos y bootcamps online enseñan a utilizar estas técnicas sin llegar a entenderlas en profundidad, pasando por la teoría de forma superficial.\n\n\nNuestro curso combina lo mejor de cada método. Por una parte, veremos de dónde surgen y por qué se utilizan estos métodos, entendiendo por qué funcionan de la forma que lo hacen. Por otra, vamos a programar estos métodos desde cero, utilizando las librerías más populares de la ciencia de datos y el machine learning en Python. Solo cuando hayas entendido exactamente cómo funciona cada algoritmo, aprenderemos a usarlos con las librerías avanzadas de Python.\n\n\nContenido del curso\nIntroducción al machine learning y a la ciencia de datos.\nRegresión lineal simple. Aprenderemos a estudiar la relación entre distintos fenómenos.\nRegresión lineal multiple. Crearemos modelos de más de una variable para estudiar el comportamiento de una variable de interés.\nRegresión lasso. Versión avanzada de la regresión lineal múltiple con la capacidad de filtrar las variables más útiles.\nRegresión ridge. Versión más estable de la regresión lineal múltiple.\nRegresión logística. Algoritmo de clasificación y detección más popular. Nos permitirá estudiar la relación entre distintas variables y unas determinadas clases de objeto.\nRegresión de Poisson. Algoritmo que nos permitirá como afectan varias variables al número de veces que ocurre un evento.\nConceptos centrales en la ciencia de datos (overfitting vs underfitting, validación cruzada, preparación de variables, etc).\n\n\n¿Tienes dudas? Recuerda que tenemos una garantía de devolución total del dinero de 30 días. Sin riesgo para ti. Así de convencidos estamos de que el curso te gustará.",
      "target_audience": [
        "Estudiantes interesados en encontrar un empleo en el campo de la ciencia de datos / machine learning.",
        "Profesionales que quieren aplicar la modelización predictiva para resolver sus problemas de negocio más complejos.",
        "Practicantes de machine learning que quieren aprender de forma profunda el funcionamiento de las técnicas que usan."
      ]
    },
    {
      "title": "R Programming: De Principiante a Avanzado",
      "url": "https://www.udemy.com/course/r-programming-desde-cero-analisis-de-datos/",
      "bio": "Jorge, con experiencia en Data Science, te enseñará programación en R desde cero hasta análisis de datos.",
      "objectives": [
        "Aprenderás a utilizar vectores, matrices y dataframes.",
        "Aprenderás a usar estructuras de control de flujo (for, if else, while y mucho más).",
        "Aprenderás a crear funciones.",
        "Aprenderás a manejar archivos (leer, exportar y mucho más).",
        "Aprenderás a crear y personalizar gráficos.",
        "Introducción al análisis exploratorio.",
        "Dataframes y limpieza de datos.",
        "Gráficos avanzados.",
        "Regresión Lineal múltiple.",
        "Series de tiempo."
      ],
      "course_content": {
        "¿Cómo está formado el curso?": [
          "Bienvenido a DataBoosters",
          "Descripción del curso"
        ],
        "P1.- R Programming: Desde cero para principiantes con R Studio - Introducción": [
          "Bienvenido al curso",
          "Revisión del temario del curso",
          "Un poco de historia",
          "Instalación",
          "La consola de R / Rstudio",
          "Archivos descargables"
        ],
        "P1.- Tipos de datos": [
          "Objetos y atributos",
          "Vectores Pt1",
          "Vectores Pt2",
          "Matrices Pt1",
          "Matrices Pt2",
          "Data Frames Pt1",
          "Data Frames Pt2",
          "Tipos especiales de datos"
        ],
        "P1.- Estructuras de control de flujo": [
          "Ciclo For",
          "If Else",
          "Ciclo While",
          "Break, Next, Repeat",
          "Ejercicio ciclo for",
          "Tip Eficiencia de un bucle"
        ],
        "P1.- Funciones": [
          "Como crear una función",
          "Función apply",
          "Función apply y dataframes",
          "Función apply personalizada",
          "Listas y función lapply",
          "Consideraciones generales apply lapply"
        ],
        "P1.- Fuentes de datos": [
          "Read table para datos tabulares",
          "Read table para csv",
          "Read csv",
          "Exportando datos",
          "Datos de Excel",
          "Otros tipos de datos"
        ],
        "P1.- Gráficos": [
          "Introducción a plot",
          "Personalización de gráficos pt1",
          "Personalización de gráficos pt2",
          "Grafica de funciones",
          "Barplots",
          "Histogramas y diagramas de cajas",
          "Exportando gráficos"
        ],
        "P1.- Análisis de datos": [
          "Análisis exploratorio de datos",
          "Análisis de los datos pt1",
          "Analisis de datos ¿Qué sigue?"
        ],
        "P2.- R Programming: Análisis avanzado para Data Science - Introducción": [
          "Bienvenido al curso",
          "Revisión del temario del curso",
          "¿Qué es el análisis de datos?",
          "Consideraciones importantes",
          "Rstudio no es R",
          "Archivos descargables"
        ],
        "P2.- Dataframes y limpieza de datos": [
          "Repaso DataFrames",
          "Accediendo a datos (Attach)",
          "Añadir/Quitar columnas y filas pt1",
          "Añadir/Quitar columnas y filas pt2",
          "Ordenando DataFrames",
          "Filtrando DataFrames"
        ]
      },
      "requirements": [
        "No se necesita experiencia en el lenguaje R."
      ],
      "description": "La ciencia de datos es un área que hoy ofrece herramientas analíticas muy poderosas a las organizaciones; aquellas que han incorporado estas prácticas rápidamente han podido obtener ventajas competitivas y tomar mejores decisiones con la información que obtienen. Ante las características actuales de sociedades generadoras de millones de datos, dominar adecuadamente el análisis de datos es una necesidad para cualquier organización.\nEste curso brinda una introducción al lenguaje R para el análisis de datos con un enfoque práctico desde el inicio. Los ejemplos y actividades son fácilmente relacionables a las tareas que un analista realiza de forma regular, tales como manipular datos y presentar gráficas o resúmenes.\nAl finalizar este curso podrás aplicar en tu organización o de manera personal las herramientas brindadas en él y al mismo tiempo, estarás preparado para cursos más avanzados de R.\n\n\nLo que aprenderás\nCreación de un ambiente de trabajo para R con R Studio\nClasificación y manipulación de datos desde una visión de ciencia de datos\nRealizar gráficas de manera muy versátil y sencilla\nProgramación básica en el lenguaje R\nSi tomas decisiones en tu empresa o deseas involucrarte en la ciencia de datos y el uso de tecnologías computacionales, este curso es para ti.\nEl análisis multivariado es muy importante y único, al tomar en cuenta al mismo tiempo las diferentes variables a las que está sujeta una entidad, la cual puede ser numérica o categórica, es decir, podemos analizar tanto datos que representan propiedades físicas o químicas, como datos que que son indicadores de una situación o estado.",
      "target_audience": [
        "Estudiantes que deseen aprender un software estadístico.",
        "Profesionistas que se dedican al análisis de datos."
      ]
    },
    {
      "title": "Python Temelleri ve Python ile Görüntü İşleme (OpenCV)",
      "url": "https://www.udemy.com/course/python-goruntu-isleme/",
      "bio": "Sıfırdan İleri Seviyeye Python, Görüntü İşleme, Makine Öğrenmesi ve Arduino Öğren.",
      "objectives": [
        "Değişkenler",
        "Standart Girdi ve Çıktılar",
        "Tip Dönüşümleri",
        "Temel Seviye JSON",
        "Dosyalama İşlemleri",
        "Döngüler",
        "Fonksiyonlar",
        "Koşullu Yapılar",
        "Liste, Demet ve Sözlükler",
        "Hata Döndürme",
        "Görüntü Kavramı",
        "Standart Görüntü Okuma, Çıktı ve Yazdırma",
        "Görüntü Boyutlandırma",
        "Temel Çizim İşlemleri",
        "Yazı Yazdırma",
        "Renk Dönüşümleri",
        "Döndürme İşlemleri",
        "Filtreler",
        "Renk Takibi",
        "Morfoloji",
        "Sınıf, nesne ve metod kavramı",
        "Nesneye yönelik programlama",
        "Kalıtım",
        "Metod",
        "Makine Öğrenmesi",
        "Yüz, El, Vücut ve Göz Tespiti",
        "Temel Düzey Arduino",
        "Makine Öğrenmesi ile Arduino Kontrol Etme",
        "Mouse İşlemleri",
        "Split ve Merge",
        "Trackbar Kullanımı"
      ],
      "course_content": {
        "Giriş": [
          "Tanıtım",
          "Python Nedir?",
          "Kurstaki Verimi Artırmak",
          "Ders Programları",
          "Bilgisayarlı Görü Maaş Skalası ve Talep"
        ],
        "Kurulum İşlemleri": [
          "Python Kurulumu",
          "Jupyter Notebook"
        ],
        "Python Temel Bilgiler": [
          "Python Ders Notları",
          "Sayısal Veri Tipleri ve Değişken Oluşturma",
          "Karaktersel Veri Tipi Ve Değişken Oluşturma Kuralları",
          "Kodlama Pratiği -1",
          "Standart Çıktı Ve Format Fonksiyonu Kullanımı",
          "Değişken Tip Dönüşümleri",
          "Soru",
          "String Kavramı Detay",
          "Listeler",
          "Sınav 2",
          "Listeler Detay",
          "Demetler",
          "Sözlükler",
          "Standart Girdi Fonksiyonu (Input)",
          "Pekiştirme 1",
          "Mantıksal Veri Tipi",
          "Mantıksal Bağlaçlar Teori",
          "Mantıksal Bağlaçlar Uygulama"
        ],
        "Python -Koşullu Yapılar": [
          "Koşullu Yapılar-1",
          "Koşullu Yapılar-2",
          "Pekiştirme 2",
          "Pekiştirme 3",
          "İç İçe Koşullu Yapı Oluşturmak",
          "Pekiştirme 4"
        ],
        "Python -Döngüler": [
          "Döngüler Hakkında Konuşalım",
          "in Yapısı",
          "For Döngüsü",
          "For Döngüsü Detay",
          "While Döngüsü",
          "range()",
          "break ve continue",
          "Pekiştirme 5",
          "While ve Else İlişkisi",
          "Pekiştirme 6",
          "Pekiştirme 7"
        ],
        "Python -Fonksiyonlar": [
          "Metot Kavramı-1",
          "Metot Kavramı-2",
          "Fonksiyon Nedir?",
          "Fonksiyon Kullanımı",
          "Değer Döndürebilen Fonksiyonlar",
          "Fonksiyon Kullanımı Detay",
          "Pekiştirme 8",
          "Pekiştirme 9",
          "Tek Parametre ile Çoklu Değer Atamak",
          "Pekiştirme 10",
          "Global ve Yerel Değişkenler",
          "Lambda Fonksiyonu",
          "Lambda Fonksiyonu Örnek",
          "Varsayılan Parametre",
          "Fonksiyonlarda Liste Parametresi"
        ],
        "Yararlı Komutlar": [
          "End",
          "Enumerate",
          "Map",
          "Çoklu Değişkene Input Değeri Atamak"
        ],
        "Modüller": [
          "Modül Kavramı ve Dosya İçerisinde Modül Kullanmak (Math)",
          "Modül Detay ve Math Modülü",
          "Modül Detay ve Date Modülü",
          "Kendi Modülümüzü Oluşturmak",
          "Tepkime Süresi (Time Modülü)"
        ],
        "Dosya İşlemleri": [
          "Dosya Açma, Yazma ve Kapama",
          "Dosya Okuma",
          "Dosyalar Detay -1",
          "Dosyalar Detay -2"
        ],
        "Hata": [
          "try, except yapısı"
        ]
      },
      "requirements": [
        "Herhangi Bir Bilgisayar",
        "Öğrenme İsteği",
        "Azim"
      ],
      "description": "Merhabalar,\nPython Temelleri ve Python ile Görüntü İşleme (OpenCV) Kursu ile Python yazılım dilini öğreneceğiz, gelişeceğiz ve uzmanlaşacağız. Gerekli altyapıyı oluşturduktan sonra günümüzün popüler Bilgisayarlı Görü olan \"OpenCV\" modülü ile resimler üzerinde işlemler gerçekleştireceğiz. Bununla da kalmayıp resimlere anlam yükleyebilmemiz  içinde Makine Öğrenmesi hakkında detaylı bilgi sahibi olacağız. Kurs içeriğinde birçok pekiştirme, sınav ve projelerde mevcut. Pekiştirmeler ile öğrendiklerimizi kavrayacağız. Sınavlar ile öğrendiklerimizi test edip, projeler ile ufkumuzu genişleteceğiz. Dahası, Numpy modülü ile de matris kavramları üzerine konuşup, bolca örnekler ile de öğrendiklerimizi uygulayarak temel görüntü işleme hakkında da detaylı bilgi sahibi olacağız.\nPython Temelleri ve Python ile Görüntü İşleme (OpenCV)  Eğitim Kursum:\nPython programlama dilini öğrenmek isteyen,\nPython programlama dilinde görüntü işleme öğrenmek isteyen,\nMakine Öğrenmesi ile nesne tanıtımı yapmak isteyenler\nVeya, yukarıdaki 3 başlık üzerinde kendini geliştirmek isteyenler için uygundur.\nKurs Sonunda:\nTemel, orta ve ileri seviye Python projelerini,\nGörüntü işleme gerektiren projelerinizi ve\nMakine öğrenmesi ile kendi nesnelerinizi tanıttığınız projeleri yapabiliyor olacaksınız.\n3 başlığı bir arada öğrenebileceğiniz kurs içeriği öğrenciyi sıkmadan, kapsamlı bir şekilde anlatıldı. Ek olarak, eğitim süreci boyunca takıldığınız yerleri sorabilir ve kısa sürede yanıt alabilirsiniz. Sürekli güncellenen içerikler ile beraber yeni teknolojileri öğrenip, kodlayabileceksiniz.\nGeleceğin teknolojileri üzerine kendimizi geliştirme ve  kod yazma yolunda şimdiden aramıza hoş geldin.\n\"Çalışmadaki devamlılık, her güçlüğü yener.\"  -Anthony Trollope\nSaygılarımla,\nYılmaz ALACA",
      "target_audience": [
        "Python Geliştiricileri",
        "Python Öğrenmek İsteyenler",
        "Görüntü İşleme Öğrenmek İsteyenler",
        "Makine Öğrenmesi Öğrenmek İsteyenler",
        "Yapay Zeka Öğrenmek İsteyenler",
        "Python ile Proje Geliştirmek İsteyen",
        "Gömülü Sistem Projeleri Yapmak İsteyenler"
      ]
    },
    {
      "title": "Deep Learning : De Zéro à la Certification Tensorflow",
      "url": "https://www.udemy.com/course/deep-learning-de-zero-a-la-certification-tensorflow/",
      "bio": "Apprendre l’Intelligence Artificielle avec Tensorflow et Réussir l’examen Tensorflow developer Certificate de Google.",
      "objectives": [
        "Apprendre à réussir l’épreuve de l’examen de Certification Tensorflow Developer de Google",
        "Comprendre chaque étape de l'entraînement d’un réseau de neurones",
        "Apprendre les mathématiques du Deep Learning de façon pratique avec du code (sans aucune longue formule mathématique)",
        "Apprendre à créer un Mini Tensorflow avec du code python pour mieux comprendre la librairie",
        "Construire des modèles avec Tensorflow 2 sur les données images, textuelles et les séries temporelles",
        "Apprendre à entraîner des réseaux neurones convolutionnels CNN pour la classification d’Images (Computer Vision)",
        "Apprendre à entraîner des réseaux de neurones récurrents RNN et les réseaux de type LSTM pour la génération de textes et l’analyse de sentiments",
        "Comprendre le concept de Transfert Learning qui permet d’utiliser des modèles pré-entraînés pour aller plus vite et avoir de meilleurs résultats",
        "Apprendre les différentes manières d'entraîner un modèle Tensorflow 2 et Keras",
        "Comprendre comment intégrer les modèles d’Intelligence Artificielle dans une application Web",
        "Acquérir les compétences nécessaires pour travailler sur des projets d’Intelligence Artificielle",
        "Acquérir les bases nécessaires pour comprendre plus tard l’architectures des modèles de langues comme GPT-4"
      ],
      "course_content": {
        "Introduction": [
          "Ce que tu apprendras dans ce cours",
          "L'examen de Certification Tensorflow",
          "Les pré-requis de la formation + Chaine Youtube + Discord",
          "Comment Utiliser Google Colab",
          "Les Notebooks de la Formation"
        ],
        "Les fondamentaux du Deep Learning": [
          "Introduction aux fondatementaux du Deep Learning",
          "Notre Premier Code Tensorflow",
          "Notre Premier Modèle",
          "Comment Evaluer l'Erreur du Modèle",
          "Recherche du Paramètre Optimal",
          "Récapitulatif et Jargon Deep Learning",
          "Dérivée d'une fonction : Intuition",
          "Dérivée d'une fonction : Code",
          "L'Erreur est une fonction composée",
          "La Règle de la chaîne : Intuition",
          "La Règle de la chaîne : Code",
          "Exercice : Règle de la chaîne",
          "Solution - Exercice sur la Règle de la chaîne",
          "Le Forward et Backward pass",
          "Les Tenseurs et leurs formes",
          "Plusieurs caractéristiques et plusieurs paramètres",
          "Somme Pondérée",
          "Produit Matriciel",
          "Dérivée du Produit Matriciel",
          "Le Paramètre Biais et sa dérivée",
          "Notre nouvelle fonction Erreur",
          "Derivée de l'Erreur par rapport au paramètre W : Explication",
          "Dérivée de l'Erreur par rapport au paramètre B : Explication",
          "Code de la dérivée de l'Erreur par rapport à W",
          "Code de la dérivée de l'Erreur par rapport à B",
          "L'Algorithme du Gradient Descent",
          "La Fonction Train - Tout mettre ensemble",
          "La Courbe d'Apprentissage - Learning Curve",
          "Faire des Prédictions avec la Fonction Predict",
          "Importer et Prétraiter les données du Boston House Price",
          "Entrainement d'un modèle sur le Boston House Price Dataset",
          "Evaluation de la Performance de notre Modèle",
          "Comparer notre Modèle à la Regression Linéaire de Sklearn",
          "On a besoin d'une Fonction Non Linéaire",
          "La Fonction Sigmoid",
          "Dérivée de la fonction Sigmoid",
          "La nouvelle Fonction Erreur avec Sigmoid",
          "La Fonction Gradient avec Sigmoid",
          "Entrainement du Premier Modèle Non Linéaire",
          "Evaluation du Modèle Non Linéaire",
          "Dés Réseaux de Neurones Profond + Tensorflow Playground",
          "Récapitulatif des Fondamentaux du Deep Learning"
        ],
        "Recréer Tensorflow": [
          "Pourquoi Recréer Tensorflow",
          "Architecture de notre Tensorflow",
          "La Classe Boite pour les Opérations",
          "La Classe Boite Paramétrée pour les Opérations avec Paramètres",
          "La Classe Dot pour le Produit Matriciel",
          "La Classe Add pour l'Ajout du Biais",
          "La Classe Sigmoid",
          "La Classe Loss pour le Calcul de l'Erreur",
          "Architecture de la Classe Dense",
          "Les Fonctions build et forward de la Classe Dense",
          "La Fonction Backward de la Classe Dense",
          "Plusieurs Couches avec la Classe Model",
          "Récupérer les dérivées des paramètres de la Classe Dense",
          "Récuperer les dérivées des paramètres dans la Classe Model",
          "Mise à jour des paramètres du Model - Optimisation",
          "Test de la mise à jour des paramètres du Model",
          "Entrainer un Modèle avec la Fonction fit",
          "Evaluer la Performance du Modèle sur les Données de Validation",
          "Test de notre Tensorflow sur le Boston Dataset",
          "Creer un Réseau de Neurones Profond avec notre Tensorflow",
          "Sauvegarder et Charger le Modèle entrainé",
          "A la Découverte du Vrai Tensorflow"
        ],
        "Deep Learning pour la classification d’Image": [
          "Introduction au Deep Learning pour la Classification",
          "Import et Exploration des Données Images du Fashion Mnist",
          "Transformer les Images en Vecteurs",
          "Transformation des Labels - One-Hot Encoding",
          "La Fonction Softmax",
          "Notre premier modèle de classification",
          "Cross Entropy ou Log loss",
          "Modèle de Classification avec Cross Entropy",
          "Le Probleme avec la fonction Sigmoid",
          "La Fonction d'Activation Relu",
          "Entrainement d'un Modèle avec la fonction d'activation Relu",
          "Overfitting expliqué",
          "Le Concept de Dropout - Intuition",
          "Reduire l'overfitting avec le Dropout",
          "L'Optimizer Adam - Le Concept de Momentum",
          "Sauvegarder son Meilleur Modèle - Le Callback ModelCheckpoint",
          "Le Callback Early Stopping",
          "Faire des Predictions avec notre meilleur Modèle",
          "Récapitulatif du Deep Learning pour la Classification d'Images"
        ],
        "Les réseaux de neurones convolutionnels CNN pour la classification d’image": [
          "Introduction et Projet",
          "Extraction des caractéristiques sur une Image",
          "Opération de Convolution - Intuition",
          "Opération de Convolution - Code",
          "Padding et Pooling",
          "La Couche Conv2D avec Tensorflow",
          "Entrainement d'un Modèle CNN",
          "Récaptitulatif sur les Réseaux de Neurones Convolutionnels",
          "Projet de Création d'une Poubelle Intelligente",
          "Visualiser quelques exemples d'Images",
          "Charger les Images avec ImageDataGenerator",
          "Entrainement du Modèle",
          "Création d'une Application Streamlit pour la Poubelle Intelligente",
          "Augmentation des données",
          "Transfert Learning - Intuition",
          "L'API Fonctionnelle de Tensorflow",
          "Transfert Learning pour l'Extraction des caractéristiques sur les Images",
          "Réentrainement d'un modèle pré-entrainé - Fine Tuning",
          "Conclusion"
        ],
        "Introduction au Natural Language Processing": [
          "Introduction",
          "Le IMDB Dataset",
          "Exploration du IMDB Dataset",
          "La Tokenisation du Corpus",
          "Le Padding et Truncating du texte expliqué",
          "Les Stopwords",
          "Extraction de Caractéristiques du texte",
          "Les Embeddings - Intuition",
          "La couche Embedding avec Tensorflow",
          "Entrainement du Premier Modèle de NLP",
          "La taille du Vocabulaire",
          "La dimension des Vecteurs Embeddings",
          "L'Architecture du Modèle",
          "La Taille Maximale des phrases et Dropout",
          "Transfert Learning pour les données textuelles",
          "Visualiser les Embeddings avec Embedding Projector"
        ],
        "La classification du texte avec les réseaux de neurones récurrents RNN et LSTM": [
          "Introduction et Projet d'Analyse de Sentiments des Tweets",
          "Exploration du Sentiment Dataset",
          "Nettoyage et Prétraitement du Texte",
          "La Stemmatisation",
          "Tokenization et Transformation en Séquences du Texte",
          "Label Encoder et Entrainement du Modèle",
          "Les Réseaux de Neurones Récurrents - Intuition",
          "Code pour créer une Couche RNN",
          "Les Modèles de type LSTM - Intuition",
          "Code pour créer une couche LSTM",
          "Utiliser d'autres Embeddings - Glove",
          "Entrainement du Modèle avec Glove Embeddings"
        ],
        "BibleGPT : Créer un modèle générateur de Texte": [
          "Introduction au Projet BibleGPT",
          "Obtenir Les données de la Bible",
          "Plan d'entrainement du model Générateur de texte",
          "Prétraitement de la donnée",
          "Mettre les données au bon format",
          "Entrainement du model générateur de texte",
          "Prediction du prochain mot",
          "Plusieurs Prédictions et Conclusion"
        ],
        "Prédire le futur : Les séries temporelles": [
          "Introduction aux Séries Temporelles",
          "Exploration du Dataset",
          "Visualisation des Séries Temporelles",
          "Approche Naive de Prédiction des témpératures futures",
          "Creer un Windowed dataset avec tfdata",
          "Séparer la donnée en données d'entrainement et de test",
          "Entrainer un Réseau de neurones profonds pour prédire les températures futures",
          "Evaluation du Modèle entrainé",
          "Entrainement d'un CNN pour les séries temporelles",
          "Evaluation du Modèle CNN pour les séries temporelles",
          "Entrainement d'un modèle RNN pour les séries temporelles",
          "Evaluation du Modèle RNN pour les séries temporelles",
          "Normalisation de la donnée et Evaluation de son Impact",
          "Entrainement et Evaluation d'un Modèle GRU",
          "Entrainement et Evaluation d'un Modèle LSTM"
        ],
        "Astuces pour réussir l’examen de certification de Tensorflow": [
          "Comment se préparer pour l'examen",
          "Configurer son environnement pour l'examen",
          "Ressources supplémentaires"
        ]
      },
      "requirements": [
        "Un ordinateur (Windows, Mac, Linux)",
        "Les notions de mathématiques, niveau Lycée",
        "Connaître les bases de Python"
      ],
      "description": "Avec l'avènement des intelligences artificielles comme ChatGPT et Midjourney, nous vivons une véritable révolution dans le monde de la technologie. Et il est devenu indispensable de posséder des compétences en intelligence artificielle pour rester compétitif sur le marché de l'emploi. Si vous cherchez à développer vos compétences en IA, ce cours est exactement ce dont vous avez besoin pour acquérir les bases nécessaires et vous positionner comme un expert dans ce domaine en pleine croissance.\nPourquoi Le deep learning avec Tensorflow et non Pytorch ?\nParce que :\nTensorFlow a été créé par Google en 2015, tandis que PyTorch est apparu en 2017. TensorFlow a donc été utilisé et testé plus longtemps dans des applications de production.\nTensorFlow est plus adapté aux projets de grande envergure. TensorFlow a été conçu pour être utilisé sur des clusters de machines, ce qui en fait un choix plus approprié pour les projets de grande envergure.\nTensorFlow offre une grande flexibilité en termes de déploiement. TensorFlow peut être utilisé pour déployer des modèles sur différents types d'appareils, y compris les ordinateurs, les serveurs, les téléphones mobiles et les dispositifs de l'internet des objets.\nTensorFlow dispose d'un écosystème plus large et est utilisé dans un large éventail d'applications, allant de la reconnaissance d'image et de la vision par ordinateur à la prédiction de séries temporelles et à la modélisation du langage naturel.\nLes bases mathématiques du Deep Learning : Pas besoin d’être un matheux\nCependant, Tensorflow encapsule plusieurs concepts mathématiques de base dont la compréhension est indispensable pour bien entrainer des réseaux de neurones.\nC’est pourquoi nous débutons cette formation par les bases mathématiques du Deep Learning, mais de façon pratique avec du code et non des formules mathématiques.\nSi vous avez le niveau Lycée en Mathématique mais pensez ne pas être fort en mathématique, ce cours vous montrera qu’avec des explication intuitives et du code, les maths sont plus facile à comprendre.\nApprendre Tensorflow en créant un Mini Tensorflow\nNous construirons brique par brique avec du code numpy un réseau de neurones et créerons même un mini Tensorflow nous même avant d’apprendre à utiliser ce Framework.\nQue ce soit les neurones, les couches de neurones, la fonction perte, l’algorithme d’optimisation et même la sauvegarde et le chargement d’un modèle, nous écrirons le code pour créer un mini framework avec les mêmes fonctions et la même interface que Tensorflow\nOrienté Projet\nCe cours est également orienté Projet. Dans chaque section, les différents concepts sont enseignés dans le contexte d’un ou plusieurs  projet précis. Pouvoir appliquer directement une notion dans un projet nous permet de mieux saisir son importance, sa pertinence et facilite la compréhension et la mémorisation.\nTensorflow developer Certificate\nLe but de ce cours est de vous apprendre les compétences indispensables pour débuter une carrière en Intelligence Artificielle et que vous réussisez l’examen de Certification Tensorflow Developer Certificate de Google. Voici quelques bénéfices d’être certifié Tensorflow developer :\nReconnaissance officielle : La certification Tensorflow Developer est une reconnaissance officielle de vos compétences en matière de développement avec Tensorflow. Cela peut vous aider à vous démarquer des autres candidats lors de la recherche d'emploi.\nValidation de vos compétences : La certification est une validation de vos compétences en matière de développement avec Tensorflow. Cela peut vous donner la confiance nécessaire pour résoudre des problèmes complexes liés à l'IA.\nÉlargissement de vos connaissances : Pour réussir l'examen de certification, vous devrez maîtriser les concepts clés de Tensorflow. Cela vous obligera à étudier et à approfondir vos connaissances en matière d'apprentissage automatique, ce qui peut être bénéfique pour votre carrière à long terme.\nAccès à une communauté : Les personnes qui ont réussi l'examen peuvent rejoindre une communauté de développeurs certifiés de Tensorflow. Cela peut vous permettre de rencontrer des personnes partageant les mêmes idées et de réseauter avec d'autres professionnels de l'IA.\nMise à jour des connaissances : L'examen de certification de Tensorflow est basé sur les dernières versions de Tensorflow et des meilleures pratiques du domaine. Cela vous permet de rester à jour sur les dernières tendances en matière d'IA et de rester compétitif sur le marché de l'emploi.\nEn somme, la certification Tensorflow Developer peut être une preuve de votre maîtrise des concepts clés de Tensorflow, qui peut aider à renforcer votre crédibilité sur le marché de l'emploi, élargir vos connaissances en IA et vous permettre de rejoindre une communauté de développeurs certifiés de Tensorflow.\nCe cours se veut être très pratique donc vous êtes invités à coder en même temps que vous regardez les vidéos. C’est la meilleure manière d’apprendre des notions qui restent. Alors, prêt à découvrir le monde de ceux qui créent les IA qui changent nos vies et être certifié ?",
      "target_audience": [
        "Etudiants, developpeurs, data scientists, Data engineers qui souhaitent acquérir des compétences pratique en Intelligence Artificielle en créant des projets avec Tensorflow",
        "Les étudiants ayant un niveau lycée en Mathématiques et qui veulent apprendre l’Intelligence Artificielle",
        "Quiconque qui souhaite apprendre les bases mathématiques du Deep Learning avec du code et des explications intuitives",
        "Toute personne désireuse de réussir l’examen de Certification Tensorflow developer Certificate par Google et faire partir du réseaux des certifiés par Google.",
        "Toute personne désireuse d’ajouter Tensorflow à son CV et montrer ses compétences sur les réseaux professionnels comme LinkedIn",
        "Toute personne désireuse de commencer une carrière en Intelligence artificielle et comprendre comment sont entrainés les IA comme GPT-4 ou ChatGPT",
        "Les entrepreneurs qui veulent comprendre comment sont entrainés les modèles d’IA et comment les utiliser dans leur business afin d’y apporter de la valeur"
      ]
    },
    {
      "title": "「音声」とAIで作文しよう！【Whisper+ChatGPT】 -AIによる音声認識とテキスト整形-",
      "url": "https://www.udemy.com/course/ai-voice-writing/",
      "bio": "OpenAIが提供する「Whisper」と「ChatGPT」を使用し、音声データからテキストを自動で生成する方法を学びます。議事録、物語、ブログ記事、新規事業の企画書などの様々なタイプの文章を、音声データから手軽に作れるようになりましょう。",
      "objectives": [
        "AIを使った音声の文字起こし、文章の整形を基礎から体験と共に学びます。",
        "Whisper API、ChatGPT APIの使い方を基礎から学びます。",
        "Pythonで書かれた音声文字起こしのコードを実行し、文章を生成する体験をします。",
        "AIによる音声文字起こし、文章整形の様々な応用を学びます。",
        "Whisperの仕組みとコードによる実装を学びます。",
        "AIによる音声文字起こし、文章の自動整形をビジネスに活用する方法を学びます。"
      ],
      "course_content": {
        "AI音声認識の概要": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "AI音声認識の概要",
          "開発環境について",
          "Whisperを使ってみよう！",
          "セクション1の演習"
        ],
        "Whisperの使い方": [
          "セクション2の教材",
          "Section2の概要",
          "Whisperの仕組み",
          "Whisper APIのはじめ方",
          "Whisper APIの使い方",
          "セクション2の演習"
        ],
        "ChatGPTの導入": [
          "セクション3の教材",
          "Section3の概要",
          "ChatGPTの概要",
          "ChatGPT APIの使い方",
          "WhisperとChatGPTの連携",
          "セクション3の演習"
        ],
        "様々な応用": [
          "セクション4の教材",
          "Section4の概要",
          "プロンプトエンジニアリングの概要",
          "議事録の自動作成",
          "物語の作成",
          "記事の生成",
          "新規事業のアイディア",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "プログラミングや数学の知識、経験は不要です。",
        "人工知能、機械学習の技術的な知識は不要です。",
        "機械学習やデータサイエンス、深層学習について詳しい解説はありません。",
        "2023年10月の環境で解説しています。最新の環境と異なる可能性があります。",
        "OpenAIおよびGoogleのアカウント開設が必要です。",
        "Whisper APIおよびChatGPT APIの利用は2023.10時点で有料で、クレジットカードの登録が必要です。上限金額を設定することが可能です。",
        "コードを動かすためにGoogle Colaboratoryを使用しますが、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。"
      ],
      "description": "『「音声」とAIで作文しよう！』では、我々が喋る「音声」を元に文章を作る方法を学びます。\n文章作成の効率を上げたい方、ビジネス文章を効率よく作成したい方、AIによる音声認識に興味がある方、AIで小説などの創作活動を行いたい方などにおすすめです。\n実際に、本コースでは議事録、物語、ブログ記事、新規事業の企画書などの作成をデモします。\n\n\n本講座では、OpenAIが提供する「Whisper」と「ChatGPT」を使用します。\nWhisperで音声データの文字起こしを行い、ChatGPTで文章を望んだ形に整えます。\nこれにより、ホワイトカラーの仕事の大部分を占める、「作文」の作業が大幅に効率化できます。\n\n\n本コースでは、最初にAI音声認識の概要、Whisperの使い方を学んだ上で、ChatGPTを導入し文章を様々な形に整えます。\n音声を使って、文章を効率的に作成できるようになりましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! 人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. AI音声認識の概要\n→ AI音声認識の概要、そして開発環境について解説します。\nSection2. Whisperの使い方\n→ Whisperを使った音声データの文字起こしについて詳しく解説します。\nSection3. ChatGPTの導入\n→ ChatGPTを導入し、文字起こしした文章を自動で整形します。\nSection4. 様々な応用\n→ 様々なスタイルで、効率的に音声から文章を作成する方法を学びます。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "音声データを使った文章生成を業務で活用したい方。",
        "Whisperを業務で活用したい方。",
        "議事録などを自動で作成したい方。",
        "音声ベースの新規ビジネスのアイディアを、企画書にまとめたい方。",
        "音声を使って物語を執筆したい方。",
        "音声記録からブログ記事を作りたい方。",
        "AI技術のトレンドに追随したい方。"
      ]
    },
    {
      "title": "Python pour la Data Science et le Machine Learning: A à Z",
      "url": "https://www.udemy.com/course/python-pour-la-data-science-et-le-machine-learning-a-z/",
      "bio": "Cours complet sur la Data Science et le Machine Learning pour maîtriser l'analyse de données et le Machine Learning",
      "objectives": [
        "Utiliser les bibliothèques scientifiques de Python, notamment NumPy, Pandas, et Matplotlib",
        "Transformer une colonne à l'aide de Pandas pour manipuler les données. Utilisez le DataFrame Sorter pour trier et normaliser une colonne numérique",
        "Analyser des données du monde réel",
        "Utiliser Pandas pour lire un jeu de données ou un DataFrame pour l'exploration. Choisissez une colonne ou une ligne pour trier le DataFrame",
        "Utiliser NumPy pour effectuer des analyses statistiques sur vos données (effectuer des comparaisons, sélectionner des éléments, remplacer des valeurs, etc.)",
        "Dessiner, adapter et analyser des courbes basées sur des exemples concrets",
        "Maîtriser des tableaux NumPy (lire un jeu de données, extraire une valeur, extraire un vecteur, extraire une matrice...)",
        "Réindexer un DataFrame",
        "Apprenez à utiliser différents frameworks en Python pour résoudre des problèmes du monde réel à l'aide du Machine Learning et de l'intelligence artificielle",
        "Faire des prédictions à l'aide de la régression linéaire, de la régression polynomiale et de la régression multivariée",
        "Apprenez les bases de la théorie du Machine Learning",
        "Apprenez à utiliser le Machine Learning en Python"
      ],
      "course_content": {
        "Rappels sur le langage Python": [
          "Bienvenue au cours",
          "Introduction à Python pour la Data Science",
          "Installation de Python pour la Data Science",
          "Qu'est-ce que Jupyter Notebook ?",
          "Installation d'Anaconda sur Windows, Mac & Ubuntu",
          "Implémentation de Python dans Jupyter",
          "Gestion des Répertoires dans Jupyter Notebook",
          "Entrée-Sortie",
          "Différents Types de Données",
          "Variables",
          "Opérateurs Arithmétiques",
          "Opérateurs de Comparaison",
          "Opérateurs Logiques",
          "Instructions Conditionnelles",
          "Boucles",
          "Séquences : Listes",
          "Séquences : Dictionnaires",
          "Séquences : N-uplets",
          "Fonctions intégrées",
          "Fonctions définis par l'utilisateur",
          "Supports de Cours: Python pour la Data Science"
        ],
        "Bibliothèques Python essentielles pour la science des données": [
          "Installation des bibliothèques",
          "Importation de bibliothèques",
          "Bibliothèque Pandas pour la Data Science",
          "Bibliothèque NumPy pour la Data Science",
          "Pandas vs NumPy",
          "Bibliothèque Matplotlib pour la Data Science",
          "Bibliothèque Seaborn pour la Data Science"
        ],
        "Fondamentaux de NumPy": [
          "Introduction au tableaux NumPy",
          "Création de tableaux NumPy",
          "Indexation des tableaux NumPy",
          "Forme du tableau",
          "Itération sur des tableaux NumPy"
        ],
        "Mathématiques pour la Science des Données": [
          ".zeros()",
          ".ones()",
          ".full()",
          "Addition d'un scalaire",
          "Soustraction d'un scalaire",
          "Multiplication par un scalaire",
          "Diviser par un scalaire",
          "Puissance",
          "Transposée",
          "Addition par éléments",
          "Soustraction par éléments",
          "Multiplication par éléments",
          "Division par éléments",
          "Multiplication matricielle",
          "Statistiques"
        ],
        "Dataframes avec Pandas et Séries": [
          "Introduction",
          "Structure de données Pandas",
          "Qu'est-ce que le DataFrame Pandas ?",
          "Qu'est-ce qu’une Série Pandas ?",
          "DataFrame et Séries",
          "Création d'un DataFrame en utilisant des listes",
          "Création d'un DataFrame à l'aide d'un dictionnaire",
          "Chargement d'un fichier csv en tant que DataFrame",
          "Changer la colonne d'index",
          "Inplace",
          "Examen du Dataframe",
          "Résumé Statistique",
          "Opérateur pour le découpage en rangs",
          "Opérateur pour l'indexation des colonnes",
          "Listes Booléennes",
          "Filtrage des lignes",
          "Filtrer les rangs en utilisant l'opérateur AND et OR",
          "Filtrer avec loc",
          "Filtrer avec iloc pour le découpage en tranches",
          "Ajout et suppression de lignes et de colonnes",
          "Triage des valeurs",
          "Exportation de DataFrame pandas en csv",
          "Concaténation de DataFrames",
          "Groupby()"
        ],
        "Introduction au Machine Learning": [
          "Qu’est-ce que le Machine Learning ?",
          "Applications du Machine Learning",
          "Méthodes de Machine Learning",
          "Qu’est-ce que l’apprentissage supervisé ?",
          "Qu’est-ce que l’apprentissage non supervisé ?",
          "Apprentissage supervisé vs apprentissage non supervisé"
        ],
        "Implémentation d’algorithmes ML en Python": [
          "Introduction",
          "Bibliothèques Python pour le Machine Learning"
        ],
        "Régression linéaire simple": [
          "Introduction à la régression",
          "Comment fonctionne la régression linéaire ?",
          "Représentation de ligne",
          "Implémentation en python : Importation de bibliothèques et de jeux de données",
          "Implémentation en python : Distribution des données",
          "Implémentation en python : Créer un objet de régression linéaire"
        ],
        "Régression linéaire multiple": [
          "Comprendre la régression linéaire multiple",
          "Implémentation en python : exploration du jeu de données",
          "Implémentation en python : codage de données catégorielles",
          "Implémentation en python : fractionnement des données en ensembles de formation",
          "Implémentation en python : Formation du modèle sur l’ensemble d’entrainement.",
          "Implémentation en python : prédiction des résultats de l’ensemble de tests",
          "Évaluation des performances du modèle de régression",
          "Erreur quadratique moyenne racine en Python"
        ],
        "Algorithmes de classification : K-Plus proches voisins": [
          "Introduction à la classification",
          "Algorithme K-Plus proches voisins (KNN)",
          "Exemple de KNN",
          "K-Nearest Neighbours (KNN) en utilisant python",
          "Implémentation en python : importation des bibliothèques requises",
          "Implémentation en python : importation du jeu de données",
          "Implémentation en python : fractionnement des données en ensembles de formation",
          "Implémentation en python : mise à l’échelle des fonctionnalités",
          "Implémentation en python : Importation du classificateur KNN",
          "Implémentation en python : Prédiction des résultats & Matrice de confusion"
        ]
      },
      "requirements": [
        "Compétences mathématiques de base",
        "Disponibilité, flexibilité et passion pour l'apprentissage",
        "Des connaissances de base en python sont un plus mais les débutants sont néanmoins les bienvenus (des rappels python sont fournis)"
      ],
      "description": "Python est reconnu comme l'un des meilleurs langages de programmation pour sa flexibilité. Il fonctionne dans presque tous les domaines, du développement Web au développement d'applications financières. Cependant, ce n'est un secret pour personne que la meilleure application de Python est dans les tâches de data science, d'analyse de données et de Machine Learning.\nBien que Python facilite l'utilisation du Machine Learning et de l'analyse de données, il sera toujours assez frustrant pour quelqu'un qui n'a aucune connaissance du fonctionnement de l'apprentissage automatique.\nSi vous avez envie d'apprendre l'analyse de données et le Machine Learning avec Python, ce cours est fait pour vous. Ce cours vous aidera à apprendre à créer des programmes qui acceptent la saisie de données et automatisent l'extraction de fonctionnalités, simplifiant ainsi les tâches du monde réel pour les humains.\nIl existe des centaines de ressources d'apprentissage automatique disponibles sur Internet. Cependant, vous risquez d'apprendre des leçons inutiles si vous ne filtrez pas ce que vous apprenez. Lors de la création de ce cours, nous avons tout filtré pour isoler les bases essentielles dont vous aurez besoin dans votre parcours d'apprentissage en profondeur.\nC'est un cours de base qui convient aussi bien aux débutants qu'aux experts. Si vous êtes à la recherche d'un cours qui commence par les bases et passe aux sujets avancés, c'est le meilleur cours pour vous.\nIl enseigne uniquement ce dont vous avez besoin pour vous lancer dans l'apprentissage automatique et l'analyse de données sans fioritures. Bien que cela aide à garder le cours assez concis, il s'agit de tout ce dont vous avez besoin pour commencer avec le sujet.",
      "target_audience": [
        "Débutants en programmation qui souhaitent étudier toutes les bibliothèques scientifiques en Python de bout en bout (Numpy, Pandas, etc.)",
        "Chercheurs intéressés par les bibliothèques Python pour la science des données",
        "Les aspirants data scientists qui veulent élargir leurs connaissances",
        "Les personnes qui veulent apprendre à analyser et à visualiser des données",
        "Programmeurs qui cherchent à ajouter le Machine Learning à leurs compétences",
        "Mathématiciens professionnels désireux d'apprendre à analyser des données par programmation",
        "Tout passionné de programmation Python souhaitant ajouter des compétences en Machine Learning à son portefeuille"
      ]
    },
    {
      "title": "Aprende Machine Learning Desde Cero con Python",
      "url": "https://www.udemy.com/course/aprende-machine-learning-desde-cero-con-python/",
      "bio": "Redes Neuronales , Aprendizaje Reforzado, Deep Learning con TensorFlow ,Keras y Scikit Learn y Técnicas de Aprendizaje",
      "objectives": [
        "Programación en Python",
        "Como programar una red neuronal",
        "Librerías mas empleadas en Machine Learning",
        "Solucionar problemas prácticos aplicando técnicas de Machine Learning",
        "Ser capaz de Analizar los problema más comunes en el Machine Learning",
        "Aprendizaje Reforzado",
        "Deep Learning"
      ],
      "course_content": {
        "Introducción al Machine Learning": [
          "Recursos",
          "Introducción",
          "¿Que es Machine Learning?",
          "Aprendizaje Supervisado, No Supersivado y Reforzado",
          "¿Que es Scikit Learn?"
        ],
        "Introducción a Python": [
          "Instalación de Visual Studio",
          "Instalación Python",
          "Google Colab",
          "Variables en Python",
          "Manejo de Strings",
          "Listas",
          "Tuplas en Python",
          "Condicionales",
          "Bucles",
          "Funciones",
          "Funciones Recursivas",
          "Funciones Lambda",
          "Clases en Python",
          "Lectura y escritura de archivos",
          "Uso de Try - Except"
        ],
        "Python Programacion Orientada a Objetos": [
          "Clases & Instancias",
          "Variables de Instancias & Variables de Clases",
          "Herencia",
          "Metodos de Clases"
        ],
        "Introducción a Pandas": [
          "Introducción a Pandas",
          "¿Que es un DataFrame?",
          "Filtros en DataFrames",
          "Agrupaciones",
          "Filtros en DataFrames Ejemplo Real",
          "Uso de Numpy",
          "Copy, Reshape y Concatenate"
        ],
        "Uso de Numpy": [
          "¿Como crear un Array?",
          "Operaciones con Arrays",
          "Manipulación de Arrays y Filtros",
          "Métodos útiles",
          "Estadística con Numpy",
          "Manipulación de imágenes"
        ],
        "Creación de un Modelo de Aprendizaje Supervisado y No supervisado": [
          "¿Como se crear un Modelo de Machine Learning?",
          "Recogida de Información.",
          "Preparación y Limpieza de datos",
          "Reducir la dimensionalidad",
          "Problemas Comunes en el Aprendizaje",
          "Validación del Modelo",
          "Curva ROC"
        ],
        "Aprendizaje Supervisado": [
          "¿Que es el Aprendizaje Supervisado?",
          "Ejemplo de Regresión",
          "Perceptron",
          "Ejemplo Práctico usando Perceptron 1",
          "Ejemplo Práctico usando Perceptron 2",
          "Ejemplo Práctico usando Perceptron 3"
        ],
        "Aprendizaje No Supersivado": [
          "¿Que es el Aprendizaje No Supervisado?",
          "K-means",
          "Ejemplo K-Means",
          "GMM Gaussian mixture model",
          "Ejemplo GMM"
        ],
        "Redes Neuronales": [
          "¿Que es una Red Neuronal?",
          "¿Como aprende una Red Neuronal?",
          "Funciones de activacion",
          "Conceptos Básicos",
          "Ejemplo de clasificaciòn usando Redes Neuronales",
          "Entrenamiento de una Red Neuronal",
          "Creación de una Red Neuronal con Tensorflow",
          "Redes Neuronales con Keras y Scikit Learn"
        ],
        "Aprendizaje Reforzado": [
          "Introducción al Apendizaje Reforzado",
          "Ejemplos de Aprendizaje Reforzado",
          "Función Valor Estado: caso deterministico",
          "Valor Estado: caso estocastico",
          "Introducciòn a Q-learning",
          "Ejemplo Práctico de Aprendizaje Reforzado Parte I",
          "Ejemplo Práctico de Aprendizaje Reforzado Parte II"
        ]
      },
      "requirements": [
        "Tener Ganas de Aprender",
        "Ser una persona proactiva en el Aprendizaje"
      ],
      "description": "Todo el mundo habla sobre Machine Learning pero ¿Entendemos realmente lo que es? ¿ Cual son las bases? ¿ Como podemos crear nuestros propios algoritmos? ¿Por que es importante conocerlo?\nEn este curso te vamos a explicar los conceptos más importante que debemos conocer sobre el Machine Learning de una forma práctica y divertida. Iremos avanzando poco a poco desde conceptos sencillos a aspectos más complejos, para que seas capas de aprender de una forma fácil e intuitiva.\nEl curso está pensando para que puedas aprender desde cero, sin necesidad de tener conocimientos previos sobre este mundo.\nEl curso está estructurado de la siguiente forma:\nProgramación Básica en Python, donde veremos  los aspectos básicos que debes manejar en Python para realizar el curso\nManejo de Pandas, que nos ayudará a todo el proecesamiento de datos previo que necesitamos para entrenar a nuestros modelos de Machine  Learning\nAprenderás Numpy, Una librería muy empleada a la hora de trabajar con vectores y matrices en Python\nIntroducción al Machine Learning. En esta sección de Introducción comprenderás por que es importante conocer esta tecnología que este revolucionando el mundo y veremos ejemplos de aplicación\n¿Como se construye un modelo de Machine Learning? Verás paso a paso lo que se necesita para que puedas crear tus Algoritmos de Machine Learning\nAprendizaje Supervisado, estudiaremos que es, como podemos usarlo e implementaremos un ejemplo desde cero usando Python\nAprendizaje No Supervisado Veremos algunos de los métodos mas empleados e implementaremos algunos ejemplos haciendo uso de librerías populares como Scikit Learn\nRedes Neuronales. En este modulo explicaremos que son las redes neuronales y como podemos implementarlas haciendo uso de librería populares como : TensorFlow ,Keras y Scikit Learn. Veremos además un ejemplo real de como solucionar un problema de clasificación en el sector de la moda, aplicando redes neuronales con TensorFlow.\nAprendizaje Reforzado, Introduciremos los conceptos básicos y veremos un ejemplo sencillo usando Grafos.\nDeep Learning, Veremos una introducción básica a que es Deep Learning e implementaremos nuestro primer ejemplo usando haciendo uso de redes neuronales convolucionales.",
      "target_audience": [
        "Personas que quieran aprender sobre Machine Learning",
        "Desarolladores en Python con interés en el Machine Learning"
      ]
    },
    {
      "title": "Deep Learning aplicado: Diagnóstico de Covid-19 en Rayos X",
      "url": "https://www.udemy.com/course/deep-learning-aplicado-diagnostico-de-covid-19-en-rayos-x/",
      "bio": "Aprende a crear y desplegar desde cero un modelo de Deep Learning para el análisis y procesamiento de imágenes médicas.",
      "objectives": [
        "Entender la intuición detrás de los modelos de Deep Learning",
        "Entender la intuición detrás de los algoritmos de Redes Neuronales Convolucionales",
        "Entender la intuición detrás del procesamiento de imágenes médicas (Rayos X de tórax) con algoritmos de Inteligencia Artificial",
        "Realizar el paso a paso para la construcción de un modelo de Deep Learning",
        "Realizar el paso a paso para el despliegue de un modelo de Deep Learning",
        "Entender las consideraciones de dominio técnico y médico para implementar proyectos de Deep Learning exitosos"
      ],
      "course_content": {
        "Introducción": [
          "Aplicaciones del Deep Learning",
          "¿Qué es Deep Learning?",
          "Bienvenida al curso"
        ],
        "Configuraciones y Prerequisitos": [
          "Recursos de la sección",
          "Configuración del Ambiente de Trabajo",
          "Obtención del Dataset de imágenes",
          "Estructura del Proyecto",
          "Actividad: Configurar el proyecto y leer imágenes"
        ],
        "Módulo 1 - Construcción del modelo Deep Learning": [
          "Plan de ataque",
          "SECCIÓN I: Preprocesamiento de Datos (Normalization & Data Augmentation)",
          "Actividad: Preprocesar los Datos",
          "SECCIÓN II: Arquitectura del Modelo",
          "Actividad: Construir la Arquitectura del Modelo",
          "SECCIÓN III: Entrenamiento del Modelo",
          "Actividad: Entrenar el Modelo",
          "SECCIÓN IV: Evaluación del Modelo",
          "Actividad: Evaluar el Modelo",
          "SECCIÓN V: Guardar el Modelo",
          "Actividad: Guardar el Modelo",
          "SECCIÓN VI: Predicciones del Modelo",
          "Actividad: Realizar predicciones con el Modelo"
        ],
        "Módulo 2 - Despliegue del modelo Deep Learning": [
          "Recursos de la sección",
          "Introducción al despliegue de modelos",
          "Configuración del Ambiente de Despliegue",
          "Actividad: Configurar el ambiente de despliegue (Servidor)",
          "Actividad: Configurar ambiente de despliegue (Herramientas)",
          "Plan de ataque del despliegue",
          "PASO 1: Construcción del Modelo",
          "PASO 2: Implementación del Servicio Web",
          "Actividad: Implementar el Servicio Web 1",
          "Actividad: Implementar el Servicio Web 2",
          "PASO 3: Creación del Cliente Web",
          "Actividad: Crear el Cliente Web (cURL)",
          "Actividad: Crear el Cliente Web (Postman)",
          "Actividad: Crear el Cliente Web (Angular - Ajax)"
        ],
        "Consideraciones técnicas y de dominio": [
          "Escenarios en un proyecto de Deep Learning",
          "Consideraciones técnicas",
          "Consideraciones de dominio",
          "Mensaje final"
        ]
      },
      "requirements": [
        "Poseer una cuenta de Google",
        "Conocimientos básicos de Cloud Computing",
        "Conocimientos básicos de programación en Python",
        "Conocimientos básicos de algoritmos de Redes Neuronales Artificiales"
      ],
      "description": "Bienvenido a este curso 100% aplicado en el que podrás aprender el paso-a-paso de la construcción y despliegue de un modelo de Deep Learning para el análisis y procesamiento de imágenes de Rayos X de tórax y clasificar imágenes de Covid-19 vs Normal.\n\n\nEstructura temática:\n¿Qué es Deep Learning?\n¿Por qué Deep Learning?\nRedes Neuronales Convolucionales\nData augmentation e Image normalization\nTransfer Learning\nModelos Pre-entrenados: DenseNet\nConstrucción y entrenamiento de un modelo de Deep Learning\nEvaluación de un modelo de Deep Learning vía métricas como: Accuracy, Sensitivity y/o Specificity\nConfiguración de ambiente en la nube para el despliegue en Google Cloud Platform + CentOS\nDespliegue de modelos en la nube como Servicio Web REST desde cero\nImplementación de llamadas al Servicio Web desde cero\nConsideraciones técnicas y de dominio en los proyectos de Deep Learning\n\n\nCurso 100% práctico:\nEl curso prioriza el desarrollo de algoritmos en sesiones de laboratorio y actividades de programación 100% hands-on con los que podrás reproducir cada una de las líneas de código con explicaciones muy bien detalladas, sin descuidar los fundamentos teóricos de cada uno de los conceptos descritos.\n\n\nHerramientas Python 3.0:\nTodas las herramientas necesarias para el curso se podrán configurar directamente en la nube de Google; por tanto, no será necesario invertir tiempo en instalaciones de herramienta de forma local.\nEl curso se desarrolla con las herramientas más populares y de alta madurez del ecosistema de Python 3.0 como:\nTensorFlow\nKeras\nPandas\nNumPy\nFlask\nEtc.\nEl despliegue se realiza utilizando la nube de Google en la que se configura paso a paso una máquina virtual (virtual machine) usando la distribución Linux CentOS como sistema operativo del servidor.",
      "target_audience": [
        "Cualquier interesando en desarrollar y desplegar modelos de Deep Learning",
        "Personal médico e investigadores cuya labor se relaciona a la aplicación de tecnologías 4.0 en el área médica",
        "Ingenieros de tecnología que quieran entender como funcionan los algoritmos de Inteligencia Artificial",
        "Científicos de Datos que quieran entender el proceso end-to-end de la construcción de un modelo de Deep Learning",
        "Emprendedores que quieran generar disrupción usando algoritmos de Inteligencia Artificial en sus procesos"
      ]
    },
    {
      "title": "Python最新基礎課程,網站開發,人臉識別,網絡爬蟲，機器學習，數據分析和自動化，遊戲，圖形化編程,鼠標鍵盤自動化",
      "url": "https://www.udemy.com/course/python-hy/",
      "bio": "本套課程詳細涵蓋了Python的基礎知識和各種應用場景,結合眾多項目應用.是從零開始學習Python快速上手的最佳課程",
      "objectives": [
        "Python零基礎入門知識,包括基本語法,數據結構,面向對象編程,模塊和包",
        "Web開發,Python數據庫操作,Excel數據分析,Flask框架,數據分析,機器學習,人臉識別,爬蟲和小遊戲開發 Excel辦公自動化和大屏數據分析可視化",
        "瀏覽器自動化,自動操作鼠標和鍵盤 Pyqt6和使用Pyqt6打造自己的Pyqt6辦公自動化處理軟件",
        "每章節之後都有相應的項目案例,用來鞏固所學知識和實際應用"
      ],
      "course_content": {},
      "requirements": [
        "零基礎的初學者"
      ],
      "description": "本套課程詳細涵蓋了Python的基礎知識和各種應用場景,結合眾多項目應用.是從零開始學習Python快速上手的最佳課程\n包含Python最新基礎課程，網絡爬蟲，機器學習，數據分析和自動化，遊戲，圖形化編程，辦公自動化,人臉識別,鼠標鍵盤自動化等。\n適合從零基礎開始學習的小伙伴,盡量會把Python基礎知識和應用部分講解完整,但是也有不完美的地方,紮實的基礎知識是學習一門編程語言的關鍵,我們在課程中會教給小伙伴們如何查找文檔自學。學習了本套課程之後會提升你的自學能力.在面對以後的新知識的時候能夠快速應對和學習",
      "target_audience": [
        "對Python感興趣的零基礎學員",
        "無須Python編程經驗,對Python感興趣的人員"
      ]
    },
    {
      "title": "Analytics Engineering en Google Cloud con DBT",
      "url": "https://www.udemy.com/course/analytics-engineering-en-google-cloud-con-dbt/",
      "bio": "Aprende este nuevo enfoque para transformar datos que ya están adoptando grandes empresas en el mundo como Spotify.",
      "objectives": [
        "Conocerás de qué trata el Analytics Engineering",
        "Aprenderás las diferencias entre los enfoques ETL y ELT",
        "Conocerás sobre BigQuery como servicio de Data Warehouse que ofrece Google Cloud",
        "Realizarás transformaciones de datos usando DBT, que es usado por grandes empresas como Spotify, GitLab, JetBlue, Hobspot, etc"
      ],
      "course_content": {
        "Introducción al curso": [
          "Presentación del curso",
          "Presentación del instructor"
        ],
        "Analytics Engineering y enfoques ETL / ELT": [
          "¿Qué es Analytics Engineering?",
          "Analogía de Analytics Engineering",
          "Enfoques ETL y ELT"
        ],
        "Fundamentos de BigQuery y DBT": [
          "BigQuery",
          "¿Qué es DBT?",
          "Creación de cuenta en DBT Cloud",
          "Creación de dataset en BigQuery y Service Account"
        ],
        "Creando mi primer proyecto en DBT Cloud": [
          "Creando proyecto en DBT Cloud",
          "Estructura de carpetas en DBT Cloud",
          "Explicación modelo : my_first_dbt_model",
          "Explicación modelo : my_second_dbt_model",
          "Explicación : schema.yml y reglas de calidad de datos",
          "Manejo de paquetes para calidad de datos : dbt_expetactions",
          "Comando : dbt build",
          "Generando la documentación para nuestro proyecto en DBT Cloud",
          "Confirmando cambios en el repositorio de GIT"
        ],
        "Segundo proyecto : Transformando datos de stackoverflow con DBT": [
          "Explicación del proyecto",
          "Creando un dataset y tablas en BigQuery",
          "Creando proyecto en DBT Cloud desde un repositorio de Github",
          "Contenido del proyecto y linaje de datos",
          "Explicación archivo sources.yml (datos crudos)",
          "Explicación contenido carpeta staging",
          "Modelo incremental stg_users",
          "Explicación contenido carpeta marts",
          "Pull Request en Github",
          "Creación de Environment y Job para ejecutar un proyecto de DBT Cloud"
        ],
        "Orquestando flujos de datos con Shipyard": [
          "Creando nueva cuenta en Shipyard",
          "Creación de Service Token en DBT Cloud y flujo de datos en Shipyard"
        ],
        "Visualización de datos en Looker Studio": [
          "Creando gráfico estadístico en Looker Studio desde BigQuery"
        ],
        "Agradecimientos y despedida": [
          "Agradecimientos y despedida del curso"
        ]
      },
      "requirements": [
        "El único requisito para llevar el curso es tener muchas ganas de aprender."
      ],
      "description": "En este curso aprenderemos un nuevo enfoque para transformar datos en nuestros Data Warehouse que ya están adoptando grandes empresas en el mundo como Spotify, GitLab, jetBlue, CANVA, y otras muchas más.\n\n\nEl temario del curso será el siguiente:\n\n\nMódulo I : Introducción al curso\nPresentación del curso\nPresentación del instructor\nMódulo II : Analytics Engineering y enfoques ETL / ELT\n¿Qué es Analytics Engineering?\nAnalogía de Analytics Engineering\nEnfoques ETL y ELT\nMódulo III : Fundamentos de BigQuery y DBT\nBigQuery\n¿Qué es DBT?\nCreación de cuenta en DBT Cloud\nCreación de dataset en BigQuery y Service Account\nMódulo IV : Creando mi primer proyecto en DBT Cloud\nCreando proyecto en DBT Cloud\nEstructura de carpetas en DBT Cloud\nExplicación modelo : my_first_dbt_model\nExplicación modelo : my_second_dbt_model\nExplicación : schema.yml y reglas de calidad de datos\nManejo de paquetes para calidad de datos : dbt_expetactions\nComando : dbt build\nGenerando la documentación para nuestro proyecto en DBT Cloud\nConfirmando cambios en el repositorio de GIT\nMódulo V : Segundo proyecto : Transformando datos de stackoverflow con DBT\nExplicación del proyecto\nCreando un dataset y tablas en BigQuery\nCreando proyecto en DBT Cloud desde un repositorio de Github\nContenido del proyecto y linaje de datos\nExplicación archivo sources.yml (datos crudos)\nExplicación contenido carpeta staging\nModelo incremental stg_users\nExplicación contenido carpeta marts\nPull Request en Github\nCreación de Environment y Job para ejecutar un proyecto de DBT Cloud\nMódulo VI : Orquestando flujos de datos con Shipyard\nCreando nueva cuenta en Shipyard\nCreación de Service Token en DBT Cloud y flujo de datos en Shipyard\nMódulo VII : Visualización de datos en Looker Studio\nCreando gráfico estadístico en Looker Studio desde BigQuery",
      "target_audience": [
        "Profesionales de Data & Analytics que deseen aprender un nuevo enfoque para transformar datos."
      ]
    },
    {
      "title": "Генеративный ИИ: Руководство по эксплуатации",
      "url": "https://www.udemy.com/course/generative_ai/",
      "bio": "Получите один из самых востребованных навыков будущего — промпт-инжиниринг, на примере ChatGPT и Midjourney",
      "objectives": [
        "Понимание сущности генеративного искусственного интеллекта",
        "Умение работать с основными системами генеративного искусственного интеллекта",
        "Знание основных характеристик различных системам генеративного искусственного интеллекта",
        "Понимание сущности промпт-инжиниринга"
      ],
      "course_content": {
        "Введение и логистика курса": [
          "Введение и логистика курса"
        ],
        "Что такое Генеративный ИИ": [
          "Что такое генеративный ИИ?",
          "Тест: Что такое ГИИ?",
          "Сравнительный анализ художественных ГИИ",
          "Тест: Сравнительный анализ художественных ГИИ",
          "ChatGPT — хайп или революция?",
          "Тест: ChatGPT",
          "Что такое промпт-инженерия?",
          "Тест: Промпт-инженерия",
          "Регистрация и работа с ChatGPT",
          "Тест: Работа с ChatGPT",
          "Регистрация и работа с Midjourney",
          "Тест: Работа с Midjourney",
          "Другие системы художественного ГИИ",
          "Тест: Другие системы художественного ГИИ",
          "Музыкальные системы ГИИ",
          "Тест: Музыкальные ГИИ",
          "Генерация текста в ChatGPT"
        ],
        "Порядок работы промпт-инженера": [
          "Принятие решения об использовании ГИИ",
          "Тест: Принятие решения об использовании ГИИ",
          "Порядок работы промпт-инженера",
          "Тест: Порядок работы промпт-инженера",
          "Целеполагание",
          "Тест: Целеполагание",
          "Генерация",
          "Тест: Генерация",
          "Фактчекинг",
          "Тест: Фактчекинг",
          "Финишная доводка",
          "Тест: Финишная доводка",
          "Генерация аудио в TEXT-TO-SPEECH"
        ],
        "Будущее экспертов и заключение": [
          "О важности настоящих экспертов в будущем",
          "Тест: О важности настоящих экспертов",
          "Заключение и направления дальнейшего обучения",
          "Прощание",
          "Генерация изображения в Midjourney"
        ],
        "Практические примеры использования моделей ГИИ": [
          "Практический пример работы с ChatGPT",
          "Практический пример использования Midjourney",
          "Практический пример генерации голоса",
          "Практический пример использования D-ID",
          "Сгенерировать видео-ролик в D-ID"
        ]
      },
      "requirements": [
        "Никаких предварительных требований к слушателям не предъявляется, всё необходимое для прохождения курса даётся непосредственно на курсе",
        "Необходим доступ в Интернет"
      ],
      "description": "Раскройте мощь генеративного искусственного интеллекта с помощью этого всеобъемлющего курса с руководством по эксплуатации для всех пользователей!\nГотовы ли вы глубоко погрузиться в мир генеративного искусственного интеллекта и изучить последние достижения в этой области? Этот всеобъемлющий курс «Генеративный искусственный интеллект: руководство по эксплуатации» предназначен для всех, кто хочет развить свои навыки в области искусственного интеллекта и вывести свои знания на новый уровень. А также этот курс для всех тех, кто уже сегодня стремится освоить одну из главных профессий ближайшего будущего.\nВы узнаете о новейших моделях искусственного интеллекта, включая ChatGPT и Midjourney, как их можно использовать, а также как правильно с ними работать для получения качественного результата.\nChatGPT — это большая языковая модель для обработки естественного языка, разработанная компанией OpenAI. Она обучена на большом объёме текстов и способна генерировать тексты, отвечать на вопросы и выполнять другие задачи, связанные с обработкой естественного языка. Модель используется для решения различных задач в области ИИ, таких как генерация текстов, анализ тональности, перевод и т. д.\nMidjourney — это генеративная модель художественного искусственного интеллекта, разработанная одноимённой компанией. Midjourney может фотореалистичные и художественные генерировать изображения по описаниям, используя входные промпты, например выражения вроде «весёлый кот с шляпой из слоёного теста», и она может создавать очень разнообразные и удивительные изображения. Midjourney является одной из самых передовых моделей генеративного искусственного интеллекта, и её технология может использоваться в различных областях, таких как дизайн, искусство, маркетинг и даже архитектура.\nМы познакомим  вас с основами генеративного искусственного интеллекта и предоставим практические упражнения, которые помогут вам применить то, чему вы научились, на реальных сценариях. Начиная с понимания основополагающих математических концепций и заканчивая внедрением передовых методов искусственного интеллекта, этот курс вооружит вас навыками и знаниями, необходимыми для того, чтобы преуспеть в этой захватывающей области.\nЯвляетесь ли вы новичком, только начинающим, или опытным профессионалом, желающим углубить свои знания, этот курс идеально подходит для всех, кто хочет овладеть генеративным искусственным интеллектом. Зарегистрируйтесь сейчас и присоединяйтесь к следующему поколению экспертов в области искусственного интеллекта!",
      "target_audience": [
        "Любые желающие научиться современным востребованным навыкам промпт-инженера"
      ]
    },
    {
      "title": "Dominando o DeepSeek: Integração de IA, App Web e Deploy",
      "url": "https://www.udemy.com/course/dominando-o-deepseek/",
      "bio": "Explorando Integrações Avançadas: Ollama, LM Studio, Hugging Face, Groq, FastAPI e N8N e App Streamlit com Deploy",
      "objectives": [
        "Utilizar a ferramenta de IA DeepSeek R1",
        "Rodar o DeepSeek localmente com Ollama, LM Studio e HuggingFace",
        "Integrar o DeepSeek em uma App Web com Streamlit",
        "Integrar o DeepSeek com LangChain",
        "Fazer o Deploy de uma Aplicação Streamlit",
        "Desenvolvimento de uma API com FastAPI sob o DeepSeek",
        "Integração com N8N"
      ],
      "course_content": {
        "Introdução": [
          "Apresentação Geral dos Tópicos",
          "Link para Nossa Comunidade",
          "Estrutura do Curso (Não Pule Essa Aula)",
          "O que é o DeepSeek",
          "Explorando a Documentação"
        ],
        "Integração com Ollama e Streamlit (Rodando Modelo Localmente)": [
          "Apresentação da Seção",
          "Instalação e Configuração do Ollama",
          "Baixando e Executando Modelo DeepSeek no Ollama",
          "Interface Web com o Streamlit (Desenvolvendo um Chat)",
          "Adicionando Memória ao Chat"
        ],
        "Integração com o LM Studio (Rodando Modelo Localmente)": [
          "Conhecendo o LM Studio",
          "Utilizando o DeepSeek no LM Studio"
        ],
        "Integração com o HuggingFace (Rodando Modelo Localmente)": [
          "Conhecendo o HuggingFace",
          "Usando o DeepSeek local com HuggingFace"
        ],
        "Integração com o Groq": [
          "Conhecendo o Groq",
          "Usando DeepSeek no Groq (Rodando o Modelo mais Poderoso)",
          "Usando o Groq e DeepSeek no Python",
          "Integrando Groq e DeepSeek na LangChain",
          "Desenvolvendo um Chat Completo com Streamlit",
          "Deploy do Projeto no Streamlit Cloud"
        ],
        "Desenvolvendo uma API com FastAPI": [
          "Introdução ao FastAPI",
          "Enviando Dados na API",
          "Usando o modelo DeepSeek em uma API"
        ],
        "Integração com N8N": [
          "Conhecendo o N8N",
          "Desenvolvendo um Agente com DeepSeek",
          "Criando um Workflow para Análise de Sentimentos",
          "Criando um Workflow para Classificação de Texto"
        ],
        "Utilização de outras LLMs": [
          "Configuração do Ambiente",
          "Usando os Serviços de AI do Groq no Python",
          "Integrando Groq e LangChain",
          "Usando Serviços de AI do Gemini no Python",
          "Integrando Gemini e LangChain",
          "Usando Serviços de AI da Mistral no Python",
          "Integrando Mistral e LangChain",
          "Usando Serviços de IA da Cohere no Python",
          "Integrando Cohere e LangChain"
        ],
        "Primeiros Passos em Python": [
          "Instalação e Configuração do Python",
          "Arquivo IPYNB x PY, PIP",
          "Introdução ao GIT"
        ],
        "Dominando a Linguagem Python": [
          "Primeiro Programa",
          "Exercício 1 - Hello World",
          "Tipos de Dados",
          "Exercício 2 - Tipos de Dados",
          "Utilizando o Input",
          "Concatenando Valores",
          "Exercício 3 - Concatenando Valores",
          "Utilizando Operadores",
          "Exercício 4 - Operadores",
          "Utilização de Strings",
          "Operações e Métodos em Strings",
          "Exercício 5 - Operações em Strings",
          "Utilizando uma Lista",
          "Exercício 6 - Listas",
          "Utilizando uma Tupla",
          "Exercício 7 - Tupla",
          "Utilizando um Set",
          "Exercício 8 - Set",
          "Utilizando um Dicionário",
          "Exercício 9 - Dicionário",
          "Trabalhando com Condições",
          "Utilizando For",
          "Utilizando While",
          "Utilizando List Comprehension",
          "Utilizando Funções",
          "Argumentos em Funções",
          "Função Recursiva",
          "Parâmetros Args e Kwargs",
          "Função Lambda",
          "O Desenvolvedor Júnior e o Especialista em Automação"
        ]
      },
      "requirements": [
        "Não há pré-requisitos"
      ],
      "description": "Neste curso, você aprenderá a integrar e usar tecnologias de ponta para desenvolver e implantar aplicações poderosas com inteligência artificial. A abordagem prática abrange desde a integração com plataformas populares até a construção de chatbots e deployment.\nTópicos Abordados:\nIntegração com Ollama\nComo integrar e usar o Ollama para automatizar workflows de inteligência artificial.\nConfiguração de ambientes para interação com modelos de linguagem e ferramentas de IA.\nIntegração com LM Studio\nConexão e uso do LM Studio para construção de modelos customizados.\nPersonalização de pipelines de dados e modelos de linguagem.\nHugging Face\nUtilização das APIs do Hugging Face para acessar uma vasta gama de modelos de NLP (Processamento de Linguagem Natural).\nTreinamento e fine-tuning de modelos para tarefas específicas.\nIntegração com Groq\nComo utilizar o Groq para acelerar inferências de IA com hardware especializado.\nImplantação de modelos em Groq para otimização de desempenho.\nDesenvolvimento com FastAPI\nCriação de APIs robustas para servir seus modelos de IA.\nConexão e interação com sistemas externos através de FastAPI.\nIntegração com N8N\nAutomação de workflows com N8N, conectando diversas ferramentas e plataformas.\nComo orquestrar processos complexos entre diferentes sistemas de IA.\nConstrução de Aplicações Web com Streamlit\nCriação de interfaces interativas para chatbots e modelos de IA.\nDesenvolvimento de dashboards e interfaces web simples e eficientes utilizando Streamlit.\nDeploy de Aplicações e Modelos\nEstratégias para realizar o deploy de suas aplicações e modelos em ambientes de produção.\nComo configurar servidores, contêineres e plataformas de nuvem para hospedar suas soluções.\nObjetivos do Curso:\nAo final deste curso, você será capaz de integrar ferramentas avançadas de IA, construir chatbots interativos com Streamlit e realizar o deploy de suas soluções em ambientes de produção de maneira eficiente e escalável.",
      "target_audience": [
        "Profissionais que desejam aprender a utilizar o DeepSeek"
      ]
    },
    {
      "title": "Ai工程师-自然语言处理实战(Python版)",
      "url": "https://www.udemy.com/course/nlp-tangyudi/",
      "bio": "NLP实战系列",
      "objectives": [
        "掌握自然语言处理必备经典算法",
        "掌握Python自然语言处理常用工具包",
        "掌握当下NLP在深度学习领域的应用与实践方法",
        "熟练使用深度学习框架搭建NLP项目",
        "熟悉Python文本处理",
        "熟练使用Python工具包进行数据预处理",
        "掌握贝叶斯算法",
        "掌握隐马尔科夫模型算法",
        "熟练使用Python进行文本分析与挖掘",
        "掌握神经网络算法",
        "掌握卷积神经网络原理",
        "掌握递归神经网络原理",
        "掌握词向量模型算法",
        "熟练使用Gensim工具包构建词向量模型",
        "熟练应用word2vec到各大自然语言处理项目",
        "掌握情感分析与分类原理及实践方法",
        "熟练使用Tensorflow框架进行文本处理",
        "熟练应用Tensorflow进行建模实战",
        "掌握多种文本分类实践方法",
        "掌握LSTM网络架构原理与应用",
        "掌握序列网络模型原理与应用",
        "搭建自己的聊天机器人",
        "构建自己的专属输入法",
        "构建生成模型进行文本生成",
        "熟练使用Keras工具包构建NLP项目"
      ],
      "course_content": {
        "课程简介": [
          "课程简介",
          "环境配置",
          "数据代码网盘下载（谷歌网盘）",
          "数据代码下载（百度网盘）"
        ],
        "NLP常用工具包实战": [
          "Python字符串处理",
          "正则表达式基本语法",
          "正则常用符号",
          "常用函数介绍",
          "NLTK工具包简介",
          "停用词过滤",
          "词性标注",
          "数据清洗实例",
          "Spacy工具包",
          "名字实体匹配",
          "恐怖袭击文本资料分析",
          "统计分析结果",
          "结巴分词器",
          "词云展示"
        ],
        "Pandas工具包实战": [
          "Pandas概述",
          "Pandas基本操作",
          "Pandas索引",
          "groupby操作",
          "数值运算",
          "对象操作",
          "对象操作",
          "merge操作",
          "显示设置",
          "数据透视表",
          "时间操作",
          "时间序列操作",
          "Pandas常用操作",
          "Pandas常用操作2",
          "Groupby操作延伸",
          "字符串操作",
          "索引进阶",
          "Pandas绘图操作",
          "大数据处理技巧"
        ],
        "案例实战：商品信息可视化与文本分析": [
          "任务概述",
          "商品类别划分",
          "商品类别可视化展示",
          "描述长度对价格的影响",
          "词云展示",
          "tf-idf结果",
          "降维可视化展示",
          "聚类与主题模型"
        ],
        "贝叶斯算法": [
          "贝叶斯算法概述",
          "贝叶斯推导实例",
          "贝叶斯拼写纠错实例",
          "垃圾邮件过滤实例",
          "贝叶斯实现拼写检查器"
        ],
        "新闻分类任务实战": [
          "文本分析与关键词提取",
          "相似度计算",
          "新闻数据与任务简介",
          "TF-IDF关键词提取",
          "LDA建模",
          "基于贝叶斯算法进行新闻分类"
        ],
        "HMM隐马尔科夫模型": [
          "马尔科夫模型",
          "隐马尔科夫模型基本出发点",
          "组成与要解决的问题",
          "暴力求解方法",
          "复杂度计算",
          "前向算法",
          "前向算法求解实例",
          "Baum-Welch算法",
          "参数求解",
          "维特比算法"
        ],
        "HMM工具包实战": [
          "hmmlearn工具包",
          "工具包使用方法",
          "中文分词任务",
          "实现中文分词"
        ],
        "走进深度学习-神经网络算法": [
          "深度学习概述",
          "挑战与常规套路",
          "用K近邻来进行分类",
          "超参数与交叉验证",
          "线性分类",
          "损失函数",
          "正则化惩罚项",
          "softmax分类器"
        ],
        "神经网络整体架构": [
          "最优化形象解读",
          "最优化问题细节",
          "反向传播",
          "整体架构",
          "实例演示",
          "过拟合解决方案"
        ]
      },
      "requirements": [
        "熟悉Python"
      ],
      "description": "AI工程师-自然语言处理实战课程旨在用最接地气的方式讲解复杂的算法原理，基于真实数据集，通过实际案例进行项目实战。整个体系内容包括200+课时，20个项目实战，完美覆盖当下热门技术与经典框架实战。学习路线主要包括三大阶段：1.掌握Python在自然语言处理领域必备工具包使用方法 2.机器学习与深度学习在NLP领域常用算法原理与应用实践 3.基于经典框架展开项目实战(Tensorflow,Keras)。",
      "target_audience": [
        "自然语言处理方向的同学们",
        "数据科学领域的同学们"
      ]
    },
    {
      "title": "Deep Learning: Convolutional Neural Networks",
      "url": "https://www.udemy.com/course/convolutional-neural-networks/",
      "bio": "Convolutional Neural Networks (CNN) in Arabic التعلم العميق والشبكات الالتفافية باللغة العربية",
      "objectives": [
        "Deep Learning",
        "Convolutional Neural Networks",
        "CNN Architectures",
        "Convolution Operation",
        "Object Detection",
        "Semantic Segmentation",
        "Instance Segmentation",
        "AlexNet VGG Inception GoogleNet ResNet DenseNet",
        "R-CNN Fast R-CNN Faster R-CNN",
        "Mask R-CNN"
      ],
      "course_content": {
        "Introduction to Convolutional Neural Network (CNN)": [
          "Introduction to Deep Learning",
          "ImageNet Challenge",
          "Drawbacks of Previous Neural Networks",
          "CNN Motivation & History"
        ],
        "CNN Properties": [
          "Local Connectivity",
          "Parameter Sharing",
          "Pooling & Subsampling"
        ],
        "Convolution Operation": [
          "Definition of Convolution",
          "Image Convolution Example",
          "Other Filters"
        ],
        "CNN Layers": [
          "Convolutional Layer",
          "Strided Convolution",
          "Strided Convolution with Padding",
          "Convolution over Volume",
          "Activation Function (ReLU)",
          "Pooling Layer",
          "Convolutional Network",
          "BatchNormalization Layer",
          "CNN Quiz"
        ],
        "CNN Architectures": [
          "Introduction to CNN Architectures",
          "LeNet-5",
          "AlexNet & ZFNet",
          "VGGNet",
          "GoogleNet (Inception Network)",
          "Inception V2, V3, V4, Inception-ResNet-v1, Inception-ResNet-v2",
          "Xception",
          "Residual Neural Network (ResNet)",
          "DenseNet"
        ],
        "CNN for Object Detection": [
          "Computer Vision Tasks",
          "Introduction to Object Localization and Detection",
          "Classification + Localization",
          "Object Detection with Sliding Window",
          "R-CNN",
          "Fast R-CNN",
          "Faster R-CNN",
          "You only look once (YOLO)"
        ],
        "CNN for Instance Segmentation": [
          "Instance Segmentation",
          "Mask R-CNN"
        ],
        "CNN for Semantic Segmentation": [
          "Semantic Segmentation",
          "Semantic Segmentation with Sliding Window",
          "Fully Convolutional Network",
          "Up-sampling with Transposed Convolution",
          "Fully Convolutional Network: Skipping Connections"
        ]
      },
      "requirements": [
        "Basic knowledge about Neural networks",
        "No programming experience needed"
      ],
      "description": "كورس لتعليم اساسيات التعلم العميق والشبكات العصبية الالتفافية للمبتدئين وحتى المستوى المتقدم\nسواء كنت طالباً فى علوم الحاسب او طالباً  فى الهندسة أو مبرمجاً وتعشق مجال الذكاء الاصطناعى , فإن هذا الكورس سيساعدك علي فهم أساسيات التعلم الشبكات العصبيه الالتفافية و الوصول إلى مستوى محترف\nوسوف يركز هذا الكورس على الجوانب النظرية وراء الخوارزميات والنماذج المنتشره هذه الايام للتعلم العميق\nThis course is focus on the theoretical aspects of the recent convolutional neural network based methods.\n\n\n###################################################################\n###################################################################\n\n\nSection 1: Introduction to Convolutional Neural Network (CNN)\nLecture 1: Introduction to Deep Learning\nLecture 2: ImageNet Challenge\nLecture 3: Drawbacks of Previous Neural Networks\nLecture 4: CNN Motivation & History\n\n\nSection 2: Convolutional Neural Network Properties\nLecture 5: Local Connectivity\nLecture 6: Parameter Sharing\nLecture 7: Pooling & Subsampling\n\n\nSection 3: Convolution Operation\nLecture 8: Definition of Convolution\nLecture 9: Image Convolution Example\nLecture 10: Other Filters\n\n\nSection 4: Convolutional Neural Network Layers\nLecture 11: Convolutional Layer\nLecture 12: Strided Convolution\nLecture 13: Strided Convolution with Padding\nLecture 14: Convolution over Volume\nLecture 15: Activation Function (ReLU)\nLecture 16: Pooling Layer\nLecture 17: Convolutional Network\nLecture 18: BatchNormalization Layer\n\n\nSection 5: Convolutional Neural Network Architectures\nLecture 19: Introduction to CNN Architectures\nLecture 20: LeNet-5\nLecture 21: AlexNet & ZFNet\nLecture 22: VGGNet\nLecture 23: GoogleNet (Inception Network)\nLecture 24: Inception V2, V3, V4, Inception-ResNet-v1, Inception-ResNet-v2\nLecture 25: Xception\nLecture 26: Residual Neural Network (ResNet)\nLecture 27: DenseNet\n\n\nSection 6:  CNN for Object Detection\nLecture 28: Computer Vision Tasks\nLecture 29: Introduction to Object Localization and Detection\nLecture 30: Classification + Localization\nLecture 31: Object Detection with Sliding Window\nLecture 32: R-CNN\nLecture 33: Fast R-CNN\nLecture 34: Faster R-CNN\nLecture 35: You only look once (YOLO)\n\n\nSection 7: CNN for Instance Segmentation\nLecture 36: Instance Segmentation\nLecture 37: Mask R-CNN\n\n\nSection 8: CNN for Semantic Segmentation\nLecture 38: Semantic Segmentation\nLecture 39: Semantic Segmentation with Sliding Window\nLecture 40: Fully Convolutional Network\nLecture 41: Up-sampling with Transposed Convolution\nLecture 42: Fully Convolutional Network: Skipping Connections",
      "target_audience": [
        "Computer Science Students: Undergraduate and Master Students",
        "Deep Learning Developers",
        "Machine Learning Developers",
        "Data Scientists",
        "Anyone who have a passion in deep learning, machine learning and AI"
      ]
    },
    {
      "title": "【TensorFlow.js入門】JavaScriptでディープラーニング・AI アプリ開発にチャレンジ！",
      "url": "https://www.udemy.com/course/tensorflowjs_intro/",
      "bio": "JavaScriptでAIアプリを開発できるようになろう！",
      "objectives": [
        "JavaScriptベースのディープラーニングライブラリTensorFlowJSの使い方を学べます",
        "MobileNetなどTensorFlowで学習済みのモデルをJavaScriptから使用する方法を学べます",
        "NodeでTensorFlowJSを動作させる手順を理解できます。",
        "AIウェブアプリをJavaScriptで作る手順を理解できます。"
      ],
      "course_content": {
        "イントロ：サンプルアプリを体験してみよう": [
          "コースの概要",
          "TensorFlowの概要",
          "公式サイトとサンプルアプリ",
          "課題：絵文字ハントにチャレンジ"
        ],
        "環境構築とサンプルコードの実行": [
          "ブラウザ用のセットアップ",
          "CDNから読み込んで動作させてみよう",
          "yarnでTensorFlow.jsをインストールしよう（Windows 10）",
          "Parcelでビルドして動作させてみよう",
          "練習課題： Parcelでビルドしてみよう",
          "Node.jsでコマンドラインから動作させてみよう",
          "練習課題： Node.jsで回帰プログラムを動作させてみよう",
          "セクションのまとめ"
        ],
        "既存モデル（MobileNet）を使用したAIウェブアプリを作ろう": [
          "セクションの概要",
          "index.htmlを作ろう",
          "index.jsを作ろう",
          "ビルドして画像分類を実行しよう",
          "課題：　MobileNetでの推定にチャレンジ"
        ]
      },
      "requirements": [
        "ソフトウェアのインストールにインターネット接続が必要です。",
        "コーディングのレクチャー視聴にはタブレットやPC画面が適しています",
        "HTMLやJavaScriptの経験があると理解が捗ります。（なくても必要な知識は解説します）"
      ],
      "description": "TensorFlowは、Google Brainチームが公開している機械学習ライブラリです。\n従来は、PythonやC, Java, Go言語などで開発を行ってきました。\nしかし、2018年にJavaScriptへの移植版も公開され、ウェブ開発者が慣れているJavaScriptを用いて、AIアプリ開発ができるようになりました。\nそれが今回学ぶTensorFlow.jsです。TensorFlow.jsを使うと、\nJavaScriptを用いた機械学習や深層学習\n既存の学習済みモデルを用いた推定や識別\nKerasやTensorFlowで開発したAIモデルを参照するウェブアプリケーションや、サーバーサイドアプリケーションの開発\nなどが可能になります。\n実行速度も高速で、今後急速に利用シーンが広がっていくでしょう。\nぜひ、この機会にJavaScriptを用いたAIアプリ開発について学んで、プロダクトの開発や、研究などに活用していきましょう。",
      "target_audience": [
        "AIを使用したウェブアプリやコマンドラインアプリをJavaScriptで実装したい方"
      ]
    },
    {
      "title": "PYTHON, Veri Bilimi ve Makine Öğrenmesi Yolculuğu",
      "url": "https://www.udemy.com/course/veri-bilimi-yolculugu/",
      "bio": "VERİ BİLİMİ & MAKİNE ÖĞRENMESİ | Python ile Numpy, Pandas, Matplotlib, Seaborn, Scikit-Learn ve Çok Daha Fazlası.",
      "objectives": [
        "Sıfırdan başlayarak bir veri bilimi projesi nasıl yapılır",
        "Veri biliminde kullanılacak makine öğrenmesi metotları",
        "Kullanılacak metotların teorik ve pratik açıklamaları",
        "25'ten fazla veri seti ile 50'den fazla veri bilimi ve makine öğrenmesi projesi",
        "Gerçek dünya verileri ile gerçekçi modellemeler ve analizler",
        "SCIKIT-LEARN, Numpy, Pandas, Matplotlib, Seaborn Kütüphaneleri",
        "Numpy ile nümerik işlemler",
        "pandas ile veri manipülasyonu ve veri analizi",
        "Matplotlib ve Seaborn ile verilerin ve istatistiksel değerlerin görselleştirilmesi",
        "Scikit-Learn ile çeşitli makine öğrenmesi metotları",
        "Regresyon analizi ile tahmin algoritmaları",
        "Sınıflandırma metotları ile gerçek dünya problemlerinin çözümü",
        "Kümeleme metotları ile verilerin ideal gruplara ayrıştırılması"
      ],
      "course_content": {
        "Merhaba...": [
          "Giriş",
          "Bu Tarz Eğitimlerin Problemleri",
          "VS Code ve Anaconda Navigator Kurulum",
          "Neden Ekranın Sağında Saçma Görseller Var?",
          "Mac & Linux İçin Always on Top",
          "VS Code Eklentileri"
        ],
        "Frankenstein'ın Canavarını Uyandırıyoruz": [
          "İlk Yapay Zekamız... \"IT IS ALIVEE !!!...\"",
          "Yapay Zeka, Makine Öğrenmesi ve Veri Bilimi Nedir",
          "Veri Bilimi Projesinin Yol Haritası"
        ],
        "PYTHON Temel Seviye (Opsiyonel)": [
          "Python'a giriş ve öğreneceklerimiz",
          "Python'a Giriş",
          "Python Veri Türleri",
          "Karşılaştırma ve Mantık Operatörleri",
          "Koşul İfadeleri (if) ve Döngüler (for, while)",
          "Fonksiyonlar ve String Metotlar",
          "Bihter Ziyagil Once Said...",
          "Tabi Siz Anneleri Tarafından Size Emanet Edilen ...",
          "1915 Çanakkale Köprüsü",
          "Köprü Geçiş Ücreti"
        ],
        "NUMPY": [
          "Numpy Giriş",
          "NUMPY Metotlar Bölüm 1",
          "NUMPY Metotlar Bölüm 2"
        ],
        "PANDAS": [
          "Pandas Giriş",
          "Pandas Serileri (pd.Series)",
          "Pandas Dataframe",
          "Pandas Dataframe Metotları Bölüm 1",
          "Pandas Dataframe Metotları Bölüm 2",
          "Dataframe'de İndeks İşlemleri",
          "Dataframe'de Küçük, Büyük ve Eşit İfadelerinin Kullanımı (<, >, ==)",
          "VE, VEYA Bağlaçları ( & | )",
          "Min Max Değerler",
          ".apply VS np.vectorize",
          "GÜNCELLEME GELDİ Vol.2",
          "Değer Sayma ve .nsmallest, .nlargest, .sample Komutları",
          "GÜNCELLEME GELDİ Vol.3",
          "Korelasyon, Değer Değiştirme ve Tekrar Eden Değerler",
          "Korelasyon Nedir",
          "GÜNCELLEME GELDİ Vol.4",
          "Verileri Gruplandırma - .groupby( )",
          "Veri Gruplandırma ve Aggregate Komutu",
          "Pandas ile Eksik Verileri İncelemek",
          "Eksik Verileri Düzenlemek ve Doldurmak",
          "Veri Setlerinin Birleştirilmesi .concat( )",
          "Veri Setlerinin Birleştirilmesi .merge( )",
          "GÜNCELLEME GELDİ Vol.4",
          "Pivot Tablolar",
          "Pandas Metin Operasyonları",
          "Tarih Operasyonları Bölüm 1",
          "Tarih Operasyonları Bölüm 2"
        ],
        "Veri Görselleştirme": [
          "Veri Görselleştirmeye Giriş",
          "MATPLOTLIB Bölüm 1 - Temel Komutlar",
          "MATPLOTLIB Bölüm 2 - Plotları Düzenlemek",
          "MATPLOTLIB Bölüm 3 - Subplot",
          "MATPLOTLOB Bölüm 4 - Eksenleri Düzenlemek",
          "SEABORN Scatter - Count Plot",
          "SEABORN Bar - Histogram - KDE",
          "SEABORN Box - Violin Plot",
          "SEABORN Pair - Joint Plot",
          "SEABORN Catplot - Facet Grid - Pair Grid",
          "SEABORN Heat Map - Cluster Map"
        ],
        "Makine Öğrenmesine Yolculuk...": [
          "Veri Analizi - Bölüm 1 - Maaş Analizi",
          "Veri Analizi - Bölüm 2 - Maaş Analizi",
          "Veri Analizi - Bölüm 3 - Maaş Analizi",
          "Şimdiye Kadar Neler Öğrendik?",
          "Scikit-Learn Bölümünde Neler Öğreneceğiz?",
          "Supervised ve Unsupervised Learning"
        ],
        "Regresyon Modelleri": [
          "Konuya Girerken...",
          "Lineer Regresyona Giriş",
          "R^2 Değeri Hakkında",
          "Lineer Regresyon - Hastane Ziyareti Analizi",
          "Lineer Regresyon - Hastane Ziyareti Bölüm 2",
          "Polinom Regresyon Teorisi",
          "Polinom Regresyon Giriş",
          "Overfitting ve Underfitting Nedir",
          "Lineer vs Polinom Regresyon - Reklam Geliri Analizi",
          "include_bias=True",
          "GÜNCELLEME GELDİ Vol.1",
          "Ev Fiyatı Tahmini - Veri Görselleştirme ve EDA",
          "Ev Fiyatı Tahmini - Model Oluşturma",
          "Ev Fiyatı Tahmini - Modelim Doğruluğunu Deneme ve Karşılaştırma",
          "Modeller Hakkında Bir Yorum ve (fit_intercept=True)",
          "Ridge - Lasso - ElasticNet",
          "Cross Validation Nedir?",
          "Cross Validation - Diyabet Verisi",
          "Grid Search - Diyabet Verisi"
        ],
        "Logistic Regression": [
          "Lojistik Regresyon Nedir? Ne İşe Yarar?",
          "Lojistik Regresyon - Efsanevi Pokemon Bulma",
          "Confusion Matrix Hakkında Kısa Bir Not",
          "Multi Class Logistic Regresyon - Balık Sınıflandırma"
        ],
        "Ağaçlı Yöntemler": [
          "Decision Tree - Balık Sınıflandırma",
          "Random Forest - Balık Sınıflandırma",
          "Random Forest Hiper Parametreler - Pilav sınıflandırma",
          "AdaBoost - Zehirli Mantar Sınıflandırma",
          "Gradient Boosting - Zehirli Mantar Sınıflandırma"
        ]
      },
      "requirements": [
        "Bilgisayar dışında bir gereksinim yok. İhtiyacınız olan her şey burada öğretilecek."
      ],
      "description": "Bu tür eğitimlerin bana göre 2 problemi var\nİzlediğiniz videonun tamamının ekranı kaplaması ve ekranlar arası sürekli geçiş yapmak\nEğitmenlerin alanlarında uzman olmaları dolayısıyla başlangıç seviyesindeki bir öğrencinin ihtiyaçlarını ve sorunlarını tam olarak anlayamıyor olmaları\nBenim de bu eğitimdeki amacım temelde bu iki problemi çözerken size bir veri bilimi projesi nasıl yapılır, hangi adımlar işlenir ve bu adımlar neden kullanılır bunu anlatmak.\nMakine öğrenmesi bölümünde konuya sizler gibi sıfırdan başlayan bir konuğum olacak ve dersleri sizinle beraber ona anlatıyormuşum gibi dinleyeceksiniz. Böylece konuyu hiç bilmeyen birinin izlerken karşılaşabileceği soruları sizin yerinize o bana sormuş olacak.\n\n\nEğitim sonunda sizi klavyeye basan robotlar yapmaktan ziyade neyi, ne için, nerede ve nasıl kullandığını bilen birisi yapmak için mümkün olduğu kadar bütün algoritmaları, kodları, parametreleri ve kodların içinde gördüğünüz diğer şeyi açıklamaya çalıştım. Fakat yine de aklınızda kalan soruları sormaktan çekinmeyin. Derslerin sürekli güncel tutulacağından ve sorularınızla şekilleneceğinden emin olabilirsiniz.\n\n\nPeki biz bu eğitimde ne işleyeceğiz\nVeri biliminde kullanılacak temel seviyede PYTHON\nSayısal operasyonları gerçekleştirmek için NUMPY\nVerilerin düzenlenmesi ve analiz için PANDAS\nVerileri görselleştirmek ve görselleri düzenlemek için MATPLOTLIB ve SEABORN\nVe son olarak makine öğrenmesi modelleri kurmak için SCIKIT-LEARN\nMakine öğrenmesi bölümünde öğreneceğimiz makine öğrenmesi modelleri de\nLineer Regresyon\nPolinom Regresyon\nRidge - Lasso - ElasticNet\nLojistik Regresyon\nDecision Tree\nRandom Forest\nAdaBoost - Gradient Boosting\nK - Nearest Neighbors\nSupport vector Machines\nK - Means Clustering\nHiyerarşik Kümeleme\nDBSCAN",
      "target_audience": [
        "Makine öğrenmesi, veri bilimi ve veri analizi ile ilgilenen, bu alanda profesyonel olarak veya hobi amaçlı ilerlemek isteyen herkes"
      ]
    },
    {
      "title": "Einführung in Business Intelligence und Big Data",
      "url": "https://www.udemy.com/course/bi-und-big-data/",
      "bio": "OLAP am Beispiel MS SQL Server und Big Data mit Hadoop",
      "objectives": [
        "Speicherstrukturen",
        "Multidimensionale Cubes & OLAP",
        "Data Mining",
        "Hadoop",
        "MapReduce",
        "HBase",
        "Hive"
      ],
      "course_content": {
        "Einleitung": [
          "1.1 – Der Kurs"
        ],
        "Business Intelligence / OLAP": [
          "2.1 – Vorbemerkungen",
          "2.2 – OLAP",
          "2.3 – OLAP-Operationen",
          "2.4 – Eine ›händische‹ Analye",
          "2.5 – Noch eine händische Analyse",
          "2.6 – Multidimensionales Projekt",
          "2.7 – Browsing",
          "2.8 – Modellerweiterungen",
          "2.Ü1 – Entwurf"
        ],
        "3 – Data Mining": [
          "3.1 – Vorbemerkungen",
          "3.2 – Ein Data Mining Projekt erstellen",
          "3.3 – Modelle",
          "3.4 – Modelle testen",
          "3.5 – Modell anwenden; Schlussbermerkungen"
        ],
        "4 – Big Data": [
          "4.1 – Hadoop Core Services",
          "4.2 – Dienste",
          "4.3 – Exkurs Linux",
          "4.4 – HDFS",
          "4.5 – HDFS-Commands",
          "4.5b – Weitere HDFS-Befehle",
          "4.7 – MapReduce",
          "4.7b – MapReduce: Codebesprechung",
          "4.7c – MapReduce: Der laufende Job",
          "4.8 – HBase",
          "4.8b – HBase Shell"
        ],
        "9 – Extras": [
          "9.1 – Zur Arbeitsumgebung (MS SQL Server Analysis Services; Hadoop & co.)",
          "9.2 – Installation von Visual Studio",
          "Bonuslektion"
        ]
      },
      "requirements": [
        "Sicherer Umgang mit dem PC",
        "Installation von Software (Beherrschung und Berechtigung)",
        "SQL-Statements mit Gruppenklauseln lesen können!",
        "Erfahrung mit dem SQL Server als Benutzer und für einfache Administrationsaufgaben",
        "Etwas Erfahrung mit Softwareenwicklung ist kein Nachteil",
        "Wichtig ist nur der Wunsch, sich das Thema zu erschließen!"
      ],
      "description": "Der Kurs bietet eine erste Heranführung an Big Data-Themen. Dabei werden zwei Hauptthemenbereiche angerissen:\nBusiness Intelligence\nDie Erzeugung und Auswertung von Analysedaten aus operativen Datenbeständen: Erstellen eines multidimensionalen Würfels (›Cube‹). Dieser Würfel wird dann einerseits mit OLAP ad hoc ausgewertet (›Browsen‹) und zum zweiten aus den Daten des Data Warehouse (DWH) im Sinne eines gezielten, proaktiven Marketings, anhand der vorhandenen Daten über bestehende Kunden eine Vorhersage getroffen, welche Empfänger aus einer zugekauften Adressliste mit größter Wahrscheinlichkeit ein Fahrrad kaufen würden (›Data Mining‹).\nDazu dient die AdventureWorksDW-Datenbank, die als Beispiel für ein Data Warehouse fungiert und auf der die Beispiele abgearbeitet werden können.\nEine virtuelle Maschine kann zur Verfügung gestellt werden, die alle nötigen Komponenten vorinstalliert hat.\nHadoop\nDer zweite Kursteil betrifft das Big Data Ökosystem ›Apache Hadoop‹ mit Hadoop und seinem Dateisystem HDFS sowie dem Dienst Yarn selbst, einerseits. Darauf wird ein MapReduce Prozess aufgesetzt, der ein Problem verteilt abarbeitet. Zum anderen werden ausgewählte Produkte aus dem Ökosystem einführend vorgestellt, wie Hbase und Hive.\nZiel des gesamten Kurses ist es, erste Einblicke und Eindrücke zu verschaffen, eine Vorstellung zu entwickeln, worum es sich bei Big Data handelt. Ziel ist es nicht, Expertenstatus in einem der genannten Gebiete zu erlangen!\nVerwendete Software:\nMS SQL Server Analysis Services\nVisual Studio Data Tools\nMultidimensionales Projekt\nAdventureWorksDW\nHadoop\nHBase\nHive\nev. Pig, Sqoop & Spark\nÜber den Autor:\nMatthias Wolf ist seit über 30 Jahren selbständig im IT-Bereich und erstellt und betreut vornehmlich Client/Server-Datenbanksysteme und allgemeine Softwareentwicklungen. Er begleitet und berät Kunden bei Eigenprojekten und übernimmt Netzwerkbetreuungen. Außerdem unterrichtet Wolf diese Themen auch seit über 20 Jahren an 2 österreichischen Fachhochschulen und ist Honorarprofessor (FH).",
      "target_audience": [
        "Alle, die an einer ersten Einführung in Business Intelligence und Big Data-Techniken interessiert sind.",
        "(Insbesondere TN des Kurses VDB des PIT-Studiengangs der FH des BFI Wien)"
      ]
    },
    {
      "title": "AI Bildgenerator: Deep Learning mit GANs & TensorFlow",
      "url": "https://www.udemy.com/course/deep-learning-und-ai-generative-neural-networks-mit-python/",
      "bio": "Entwickle eine eigene AI die Bilder generieren kann, hacke trainierte KI Modelle, uvm! Alles mit TensorFlow 2 und Keras.",
      "objectives": [
        "Verwende die neuste TensorFlow 2 Version",
        "Verstehe und verwende Generative Deep Learning Techniken",
        "Entwickle eine eigene künstliche Intelligenz mit Generativen Neuronalen Netzwerke",
        "Entwickle eine AI, die täuschend echte Bilder erzeugen kann",
        "Führe einen Angriff auf trainierte Neuronale Netzwerke aus",
        "Entwickle Modelle, die realitätsnahe Daten generieren können"
      ],
      "course_content": {
        "Kapitel 1: Einleitung des Kurses": [
          "Einleitung in den Kurs",
          "Die Software im Kurs",
          "Informationen zu der Software",
          "Windows: MSVC Compiler Installieren",
          "Windows: Installation von Anaconda",
          "Linux: Installation von Anaconda",
          "Mac: Installation von Anaconda",
          "Handbuch des Kurses",
          "Materialien des Kurses",
          "Die Einrichtung des Environments",
          "CPU: Python Pakete Installieren",
          "GPU: Python Pakete Installieren",
          "Visual Studio Code einrichten",
          "Visual Studio Code verwenden"
        ],
        "Kapitel 2 : Python Zusatzwissen": [
          "Vorwort",
          "Main Funktion",
          "Numpy und Matplotlib Einführung",
          "Slices und Weiteres zu Numpy",
          "f-Strings und Type Annotations"
        ],
        "Kapitel 3: Deep Learning Grundlagen": [
          "Machine Learning - Grundlagen",
          "Supervised Learning - Grundlagen",
          "Supervised Learning Intuition",
          "Machine Learning",
          "Was sind Neuronale Netzwerke",
          "Neuronale Netzwerke Intuition",
          "Wie lernt das Neuronale Netzwerk",
          "Der MNIST Datensatz",
          "Der Aufbau des Deep Neural Networks",
          "Deep Neural Network - Programmieren",
          "Neuronale Netzwerke",
          "Optimierung des Netzwerks",
          "Was sind Convolutional Neural Networks",
          "Conv Neural Netwrok - Programmieren",
          "Convolutional Neural Networks"
        ],
        "Kapitel 4: Generative Adversarial Networks - Theorie": [
          "Generative vs. Discriminative Algorithmen",
          "Der Allgemeine GAN Aufbau",
          "GAN im Kontext der Spieltheorie",
          "Das Generator und Discriminator Netzwerk",
          "GAN Theorie"
        ],
        "Kapitel 5-1: Generative Adversarial Networks (GAN)": [
          "Aufbau des GAN",
          "Vorbereitung des GAN",
          "Das Generator Netzwerk (GAN)",
          "Das Discriminator Netzwerk (GAN)",
          "Initialisierung des GAN",
          "Zusatz: Input der Netzwerke und der Ablauf",
          "Fertigstellung des GAN",
          "Auswertung des GAN",
          "GAN"
        ],
        "Kapitel 5-2: Deep Convolutional Generative Adversarial Network (DCGAN)": [
          "Aufbau eines DCGAN",
          "Vorbereitung des DCGAN",
          "Das Discriminator Netzwerk (DCGAN)",
          "Zusatz: UpSampling",
          "Das Generator Netzwerk (DCGAN)",
          "Fertigstellung des DCGAN",
          "Auswertung des DCGAN vs. GAN",
          "Der CIFAR-10 Datensatz",
          "CNN mit dem CIFAR10 Datensatz",
          "Musterlösung: CNN mit dem CIFAR10 Datensatz",
          "DCGAN mit dem CIFAR-10 Datensatz",
          "Auswertung des DCGAN mit dem CIFAR10 Datensatz",
          "DCGAN"
        ],
        "Kapitel 5 - 3: Conditional Generative Adversarial Network (CGAN)": [
          "Aufbau eines CGAN",
          "Vorbereitung des CGAN",
          "Das Generator Netzwerk (CGAN)",
          "Das Discriminator Netzwerk (CGAN)",
          "Fertigstellung des CGAN",
          "Auswertung des CGAN",
          "CGAN"
        ],
        "Kapitel 5 - 4: Weiteres zu GAN Modellen": [
          "Zusatz: Wissenschaftliche Artikel zu GAN",
          "Zusatz: Was ist ein CycleGAN?"
        ],
        "Kapitel 6: Generative Adversarial Attacks": [
          "Was sind Generative Adversarial Attacks",
          "Untargeted Angriff - Teil 1",
          "Untargeted Angriff - Teil 2",
          "Untargeted Angriff - Teil 3",
          "Targeted Angriff",
          "Adversarial Attacks"
        ],
        "Kapitel 7-1: Autoencoder (AE)": [
          "Was sind Autoencoder?",
          "Autoencoder Programmieren",
          "Deep Autoencoder Programmieren",
          "Convolutional Autoencoder Programmieren",
          "Autoencoder zum entfernen von Noise einsetzen"
        ]
      },
      "requirements": [
        "Python Grundlagen",
        "Mathematik Grundlagen aus dem Abitur"
      ],
      "description": "Tauche ein in die kreative Seite der Künstlichen Intelligenz – mit Generativen Neuronalen Netzwerken (GANs), Autoencodern und Adversarial Attacks. In diesem praxisorientierten Kurs lernst du, wie du mit Python, TensorFlow 2.14 und Keras eigene Deep-Learning-Modelle entwickelst, trainierst und sogar „hackst“.\nNach einer kurzen Einführung in die Grundlagen von Machine Learning und Deep Learning, baust du Schritt für Schritt eigene neuronale Netze auf – von klassischen Deep Neural Networks bis hin zu verschiedenen Arten von GANs. Du verstehst nicht nur, wie diese Modelle funktionieren, sondern setzt sie auch selbst um – mit zahlreichen spannenden Coding-Sessions.\nNeben der Generierung realistischer Daten mit Variational Autoencodern (VAE) und der Datenkomprimierung mit klassischen Autoencodern, wirst du auch lernen, wie neuronale Netze durch gezielte Adversarial Attacks ausgetrickst werden können – und wie man sich dagegen schützt.\nDieser Kurs richtet sich an alle, die ein solides Verständnis im Deep Learning aufbauen und moderne generative Modelle praktisch umsetzen möchten. Egal ob Data Science Student, KI-Enthusiast oder Entwickler – hier wirst du gefordert und gefördert.\nDas wirst du lernen:\nGrundlagen von Machine Learning & Deep Learning\nEigene Deep Neural Networks mit TensorFlow & Keras entwickeln\nAdversarial Generative Networks (GANs) verstehen und implementieren\nAdversarial Attacks: Netzwerke gezielt angreifen & absichern\nDaten komprimieren mit Autoencodern (AE)\nRealistische Daten generieren mit Variational Autoencodern (VAE)\nArbeiten in Python (über Anaconda oder andere Installationen)\nWerde jetzt Teil der KI-Zukunft – mit deinem eigenen generativen Netzwerk.\nLet’s code the future – wir sehen uns im Kurs!\n\n\nHinweis:\nPython wird im Kurs mit Anaconda installiert. Alternativ ist auch eine Einrichtung über andere Quellen möglich.",
      "target_audience": [
        "Studenten, Softwareentwickler und alle Interessierten"
      ]
    },
    {
      "title": "Machine learning y data science con scikit-learn y pyspark",
      "url": "https://www.udemy.com/course/machine-learning-y-data-science-con-scikit-learn-y-pyspark/",
      "bio": "Aprende las principales técnicas de machine learning y ciencia de datos para aplicarlas en proyectos con python",
      "objectives": [
        "Investigar que con Python también se puede hacer ciencia de datos y machine learning.",
        "Aplicar técnicas de machine learning y ciencia de datos en proyectos con python",
        "Que el alumno descubra el potencial de las técnicas de Machine Learning para el análisis de datos y sobre todo para extracción de información a partir de los datos. Es decir, sacar valor a los datos.",
        "Presentar con casos prácticas las técnicas de Machine Learning que actualmente se utilizan en soluciones de análisis de datos, tanto en Big Data como en Data Science en general.",
        "Dar a conocer una de las herramientas más fáciles de utilizar para aplicar Machine Learning a problemas reales de una manera sencilla, como es Python, Numpy y Scikit-Learn."
      ],
      "course_content": {
        "Introducción a la ciencia de datos y machine learning": [
          "Introducción",
          "Definiciones",
          "Introducción al aprendizaje automático",
          "Tipos de aprendizaje automático",
          "Aprendizaje supervisado vs no supervisado",
          "Problema del sobreentrenamiento",
          "Pasos para construir un modelo de machine learning",
          "Cuestionario de evaluación machine learning"
        ],
        "Librerías para tratamiento y visualización de datos con python": [
          "Librerías de Python para machine learning:Numpy, SciPy, Pandas",
          "Instalación anaconda + jupyter notebook",
          "Conjunto de datasets",
          "Crear nuestro propio dataset",
          "Introducción a pandas",
          "Ejemplos prácticos tratamiento de datos con pandas",
          "Librerías de visualización de datos con python",
          "Ejemplos prácticos visualización de datos",
          "Visualizacion datos con bokeh última version 0.12.10",
          "Librerías de machine learning con python",
          "Cuestionario de evaluación tratamiento y visualización de datos"
        ],
        "Scikit-learn como librería de machine learning": [
          "Introducción a scikit-learn",
          "Datasets sklearn",
          "Algoritmos de Machine Learning en scikit-learn",
          "Introducción a la regresión lineal",
          "LinearRegression como algoritmo de regresión lineal",
          "Resolver problema de predecir el tráfico web",
          "Logistic Regression como algoritmo de regresión logística",
          "LogisticRegresion gráfico",
          "Introducción a los árboles de decisión",
          "DecissionTreeClassifier como algoritmo de árboles de decision",
          "DecissionTreeRegressor como algoritmo de selección de mejores atributos",
          "SVM como algoritmo de máquinas de vectores de soporte",
          "Implementación del algoritmo SVM en scikit-learn",
          "Clasificador de dígitos con el algoritmo SVM en scikit-learn",
          "K-NN (K Nearest Neighbor) como algoritmo de clasificación supervisada",
          "Implementación de KNeighborsClassifier en scikit-learn",
          "KneighborsClassifier vs RadiusNeighborsClassifier",
          "Clustering y aprendizaje no supervisado",
          "Aplicaciones de clustering",
          "Tipos de clustering",
          "K-means como algoritmo de clustering",
          "Implementación de K-means en scikit-learn",
          "Ejemplos kmeans en scikit-learn",
          "AffinityPropagation en scikit-learn",
          "Titanic Dataset gráficos",
          "Titanic Dataset Scikit-learn",
          "Cuestionario de evaluación scikit-learn"
        ],
        "Pyspark como librería de big data y data science": [
          "Introducción al big data",
          "Introducción a Apache Spark",
          "Módulos de Apache Spark",
          "Spark para Científicos de Datos",
          "Instalación de Apache Spark",
          "Consola interactiva en pyspark",
          "SparkContext y esqueleto de una aplicación con pyspark",
          "SparkSubmit para la ejecución de scripts python",
          "SparkSubmit parte práctica",
          "Datasets y RDD con pyspark",
          "Crear un RDD en python con pyspark",
          "Operaciones sobre un RDD",
          "Transformaciones sobre un RDD",
          "Map Reduce en pyspark",
          "Funciones lambda en python",
          "Resumen operaciones pyspark",
          "Resumen operaciones map reduce",
          "Instalar y ejecutar Pyspark con docker",
          "Instalar y ejecutar Pyspark con docker",
          "Contador de palabras con pyspark",
          "Palabras más frecuentes de un texto con pyspark",
          "Leer ficheros csv",
          "Lectura ficheros json con pyspark",
          "Trabajando con Spark SQL y dataframes",
          "Resumen operaciones sql dataframes pyspark",
          "Docker compose y ejemplo cluster con pyspark",
          "MLlib como módulo de machine learning con pyspark",
          "Introducción a MLlib",
          "Ejemplo clasificación Spam con mLlib",
          "Clustering con pyspark. Algoritmo Kmeans",
          "Cuestionario de evaluación pyspark"
        ],
        "Sistemas de recomendación": [
          "Definir sistema de recomendación",
          "Tipos de sistemas de recomendación",
          "Filtros basados en contenido (Content-Based Filtering)",
          "Practica filtro basado en contenido",
          "Practica filtro basado en contenido mediante extracción de atributos",
          "Filtros colaborativos (Collaborative Filtering)",
          "Práctica filtro colaborativo",
          "Práctica filtro colaborativo csv",
          "Conclusiones",
          "Cuestionario de evaluación sistemas de recomendación"
        ],
        "Recursos y artículos": [
          "Recursos y artículos",
          "Artículos deep learning"
        ]
      },
      "requirements": [
        "Es necesario tener conocimientos básico de python.",
        "Es necesario tener instalada la distribución de Python de Anaconda, preferentemente la versión de Python3. Se usarán principalmente las librerías numpy, scipy, pandas, scikit-learn y pyspark.",
        "Es necesario tener instalado python.Trabajaremos con python 3.6"
      ],
      "description": "Este curso pretende ser una introducción a las técnicas más relevantes de Machine Learning y mostrar ejemplos de aplicación de estas técnicas. Que sirva para conocer qué técnicas existen, en qué se fundamentan y sobre qué tipos de problemas pueden aplicarse.\n\nEl enfoque será teórico-práctico y se hará uso del lenguaje de programación Python y del toolkit Scikit Learn. Se recomienda a los alumnos instalarse ANACONDA en su plataforma habitual. ANACONDA incluye Python, Scikit-Learn y Matplotlib. La versión de python que utilizaremos será la 3.6.\n\nTambién veremos pyspark como plataforma de desarrollo de aplicaciones distribuídas\nEntre los principales objetivos podemos destacar:\nIntroducir los conceptos de ciencias de datos y machine learning.\nIntroducir las principales librerías que podemos encontrar en python para aplicar técnicas de machine learning a los datos.\nIntroducir las principales librerías que podemos encontrar en python para tratamiento y visualización de datos\nDar a conocer los pasos para construir un modelo de machine learning, desde la adquisición de datos,pasando por la generación de funciones, hasta la selección de modelos.\nDar a conocer los principales algoritmos para resolver problemas de machine learning.\nIntroducir scikit-learn como herramienta para resolver problemas de machine learning.\nIntroducir pyspark como herramienta para aplicar técnicas de big data y map-reduce a los datos.\nConocer y aplicar algoritmos de machine learning con pyspark.\nIntroducir los sistemas de recomendación basados en contenidos",
      "target_audience": [
        "Desarrolladores python interesados en herramientas de machine learning y data science"
      ]
    },
    {
      "title": "Spotfire(스팟파이어)로 데이터 시각화, 분석 제대로 배우기",
      "url": "https://www.udemy.com/course/spotfire/",
      "bio": "효과적인 데이터 분석 및 시각화를 위한 Spotfire 활용법",
      "objectives": [
        "Spotfire를 통해 통찰을 얻어내는 전체 프로세스",
        "이 프로세스에서 구체적으로 활용되는 디자인 기반의 시각화 기법들과 고려사항",
        "Spotfire의 핵심 기능과 다양한 시각화 구현 방법을 알아본다.",
        "시각화 요건 정의와 스토리보드 기획"
      ],
      "course_content": {
        "[HD]데이터 시각화, 분석 Spotfire(스팟파이어) 제대로 배우기 Part.1": [
          "Spotfire 소개 및 설치",
          "Spotfire 빠르게 익히기",
          "시각화 요건 정의와 스토리보드 기획",
          "Spotfire 기본 사용법",
          "데이터 로드 방법",
          "결과물 저장 및 불러오기, 필터",
          "마킹, 데이터형식, 내보내기",
          "필터링",
          "분석의 데이터",
          "하위 집합"
        ],
        "[HD]데이터 시각화, 분석 Spotfire(스팟파이어) 제대로 배우기 Part.2": [
          "시각화 차트",
          "시각화 차트 - 테이블",
          "시각화 차트-막대그래프1",
          "시각화 차트-막대그래프2",
          "시각화 차트-막대그래프3",
          "시각화 차트-선 그래프, 파이그래프",
          "시각화 차트-폭포 차트,산점도",
          "시각화 차트-버블차트",
          "시각화 차트-3D 산점도, 트리맵",
          "시각화 차트- 크로스 테이블",
          "시각화 차트- 콤비네이션 차트, 히트맵",
          "시각화 차트- 그래픽테이블,요약테이블, KPI, 평행좌표그래프",
          "시각화 차트- 맵차트",
          "시각화 차트- 맵차트"
        ],
        "[HD]데이터 시각화, 분석 Spotfire(스팟파이어) 제대로 배우기 Part.3": [
          "데이터 시각화, 데이터 핸들링 1",
          "데이터 시각화, 데이터 핸들링 2",
          "데이터 핸들링 1",
          "데이터 핸들링 2",
          "기본 통계",
          "시계열 분석1",
          "시계열 분석2",
          "시계열 분석3",
          "회귀 분석",
          "시계열 분석, 데이터 상관성 분석",
          "데이터 상관성 분석",
          "K-평균 군집 분석1",
          "K-평균 군집 분석2",
          "상자 그래프"
        ]
      },
      "requirements": [
        "필요조건은 없습니다"
      ],
      "description": "[효과적인 데이터 분석 및 시각화를 위한 Spotfire 활용법] 본 과정은 데이터 시각화 분석 프로그램인 Spotfire를 이용하여 빅데이터 시대에 가장 효율적으로 인사이트를 발굴하기 위한 강의입니다. 데이터 시각화는 그 자체가 목적이 아니며 결국 데이터로부터 유용한 정보와 인사이트를 얻어내기 위한 과정입니다. 그 과정을 최신 데이터분석 툴을 통해 직접 실습해봅니다.\n\n\n본 과정의 커리큘럼은 다음과 같습니다.\n<[HD]데이터 시각화, 분석 Spotfire(스팟파이어) 제대로 배우기 Part.1>\n\n\nSpotfire 소개 및 설치\nSpotfire 빠르게 익히기\n시각화 요건 정의와 스토리보드 기획\nSpotfire 기본 사용법\n데이터 로드 방법\n결과물 저장 및 불러오기, 필터\n마킹, 데이터형식, 내보내기\n필터링\n분석의 데이터\n하위 집합\n<[HD]데이터 시각화, 분석 Spotfire(스팟파이어) 제대로 배우기 Part.2>\n\n\n시각화 차트\n시각화 차트 - 테이블\n시각화 차트-막대그래프1\n시각화 차트-막대그래프2\n시각화 차트-막대그래프3\n시각화 차트-선 그래프, 파이그래프\n시각화 차트-폭포 차트,산점도\n시각화 차트-버블차트\n시각화 차트-3D 산점도, 트리맵\n시각화 차트- 크로스 테이블\n시각화 차트- 콤비네이션 차트, 히트맵\n시각화 차트- 그래픽테이블,요약테이블, KPI, 평행좌표그래프\n시각화 차트- 맵차트\n시각화 차트- 맵차트\n<[HD]데이터 시각화, 분석 Spotfire(스팟파이어) 제대로 배우기 Part.3>\n\n\n데이터 시각화, 데이터 핸들링 1\n데이터 시각화, 데이터 핸들링 2\n데이터 핸들링 1\n데이터 핸들링 2\n기본 통계\n시계열 분석1\n시계열 분석2\n시계열 분석3\n회귀 분석\n시계열 분석, 데이터 상관성 분석\n데이터 상관성 분석\nK-평균 군집 분석1\nK-평균 군집 분석2\n상자 그래프\n본 강의로 데이터 분석 및 시각화에 확실하게 입문하시기 바랍니다",
      "target_audience": [
        "데이터분석 분야 및 관련 분야 취업, 시각화 툴 사용자"
      ]
    },
    {
      "title": "成為初級資料分析師 | R 程式設計與資料科學應用 | R for Data Science",
      "url": "https://www.udemy.com/course/r-essentials/",
      "bio": "以成為初級資料分析師（Junior Data Analyst）為最終目標的 R 程式設計與資料科學應用課程",
      "objectives": [
        "建立 R 與 RStudio 的開發環境",
        "認識 R 語言",
        "暸解運算符與向量",
        "暸解流程控制：條件判斷",
        "暸解流程控制：while 迴圈",
        "暸解向量操作",
        "暸解流程控制：for 迴圈",
        "暸解其他資料結構",
        "暸解程式封裝：自訂函數",
        "資料輸入輸出",
        "資料框處理",
        "資料視覺化",
        "網頁爬蟲"
      ],
      "course_content": {},
      "requirements": [
        "初學者友善",
        "有自己的桌上型或筆記型電腦",
        "有網際網路"
      ],
      "description": "這門課程是「成為初級資料分析師」的其中一門課，在 16.5 小時的教學影片之中內容包含這些主題：\n===程式設計===\n關於\n起步走\n運算符與向量\n流程控制：條件判斷\n流程控制：while 迴圈\n向量操作\n流程控制：for 迴圈\n其他資料結構\n程式封裝：自訂函數\n===資料科學應用===\n資料輸入輸出\n資料框處理\n資料視覺化\n網頁爬蟲",
      "target_audience": [
        "想要成為初級資料分析師（Junior Data Analyst）的學員"
      ]
    },
    {
      "title": "R Crashkurs - Einstieg in R Sprache & RStudio für Anfänger",
      "url": "https://www.udemy.com/course/r-crash-kurs-einstieg-in-r-sprache-rstudio-fur-anfanger/",
      "bio": "Grundlagen in R & RStudio -Einfache, kompakte & praktische Einführung in R mit vielen Beispielen in der R-Programmierung",
      "objectives": [
        "Einführung zu Programmierung und Datenanalyse mit R & RStudio",
        "Generelle Funktionsweise von R bzw. R Studio",
        "Packetmanagement und Berechnungen in R",
        "Data Typen und Datenstrukturen in R",
        "Matrizen, Listen und Datenrahmen in R",
        "Funktionen und Kontrollstrukturen in R"
      ],
      "course_content": {
        "Einführung": [
          "Einführung",
          "Was ist R und R Studio"
        ],
        "Erste Schritte - Installation von R und R Studio": [
          "Wie instaliert man R und RStudio",
          "Lab: Installation R und RStudio",
          "Einführung zu RStudio Interface",
          "Lab: Einstieg mit R ins RStudio",
          "Installation und Konfiguration von R und RStudio"
        ],
        "R Packet Managament & Berechnungen in R": [
          "Was sind die Pakete in R und Paket Management in R",
          "Packetinstallation und Packet Management",
          "Berechnungen in R",
          "Lab: Berechnungen in R",
          "Variablen in R und Zuweisung von Variablen",
          "Lab: Variablen in R und Zuweisung von Variablen"
        ],
        "Übersicht Data Typen und Datenstrukturen": [
          "Übersicht Data Typen und Datenstrukturen in R",
          "Lab: Übersicht Data Typen und Datenstrukturen",
          "Data Typen und Datenstrukturen: Vektoren in R",
          "Operationen mit Vektoren in R",
          "Lab: Operationen mit Vektoren in R",
          "Data Typen und Datenstrukturen: Faktoren",
          "Data Import zu R"
        ],
        "Matrizen, Listen und Datenrahmen": [
          "Data Typen und Datenstrukturen: Matrizen",
          "Data Typen und Datenstrukturen: Listen",
          "Lektion 22: Einführung in die Datenrahmen",
          "Lektion 23: Indizierung und Abfrage von Datenrahmen",
          "Lektion 24: Modifizierung Datenramen",
          "Lektion 25: Behandlung fehlende Werte in R"
        ],
        "Funktionen, Kontrollstrukturen und Schleife For in R": [
          "Übersicht der Funktionen in R",
          "Lab: Übersicht der Funktionen in R",
          "Lektion 28: Kontrollstrukturen (if, if else, else, while, switch, repeat, break)",
          "Lektion 29: Lab: Schleife For in R"
        ]
      },
      "requirements": [
        "Keine. Dieser Kurs ist sehr gut für die Anfänger geeignet sowie für alle, die mehr über R und RStudio wissen möchten"
      ],
      "description": "Kurshighlights:\nTauchen Sie ein in die Welt der R-Programmierung mit diesem kompakten und verständlichen R-Crashkurs. Ideal für Anfänger, bietet dieser Kurs eine knappe, aber umfassende Einführung in R, RStudio und R-Programmierung.\nKursinhalt:\nInstallation von R und RStudio\nPaketverwaltung in RStudio\nAlle Datentypen in R\nBerechnungen mit R\nVariablen in R\nVektoren in R\nMatrizen in R\nListen in R\nDatenrahmen in R\nUmgang mit fehlenden Werten in R\nFunktionen in R\nKontrollstrukturen in R\nFOR-Schleife in R\nUnd vieles mehr!\nAlle im Kurs verwendeten R-Skripte stehen Ihnen ebenfalls zur Verfügung.\nKursbeschreibung:\nDieser R-Crashkurs ist die perfekte Wahl für all jene, die bisher wenig oder gar keinen Kontakt mit skriptbasierter Programmierung in R hatten. Das Hauptziel des Kurses besteht darin, grundlegendes Wissen über die R-Sprache, RStudio und R-Programmierung zu vermitteln, um es später in den Bereichen Datenwissenschaft, maschinelles Lernen oder statistische Analysen anwenden zu können.\nWas diesen R-Kurs besonders auszeichnet, ist seine Fokussierung auf das Wesentliche und seine Kürze. Dadurch werden Sie in der Lage sein, die Grundlagen von R, RStudio und R-Programmierung schnell zu erlernen und einen reibungslosen Einstieg in diese Themenbereiche zu finden.\nZielgruppe:\nDieser R-Kurs richtet sich an Fachleute wie Datenwissenschaftler, Statistiker, Geographen, Programmierer, Sozialwissenschaftler, Geologen und alle anderen Experten, die Statistik und Datenwissenschaft in ihrem Tätigkeitsfeld einsetzen möchten. Wenn Sie bereits fortgeschrittene Kenntnisse in R besitzen und keine Einführung in die R-Programmierung benötigen, ist dieser Kurs möglicherweise nicht für Sie geeignet.\nVoraussetzungen:\nFür diesen Kurs sind lediglich ein Computer und eine Internetverbindung erforderlich. Es gibt keine speziellen Voraussetzungen oder Anforderungen.\nLassen Sie uns beginnen! Tauchen Sie ein in die Welt der R-Programmierung und erweitern Sie Ihr Wissen mit diesem kompakten und leicht verständlichen R-Crashkurs.",
      "target_audience": [
        "Anfänger in R",
        "Jeder, der an Data Science interessiert ist"
      ]
    },
    {
      "title": "Machine Learning: Clusterização com Linguagem Python",
      "url": "https://www.udemy.com/course/machine-learning-clusterizacao-com-python/",
      "bio": "Aprenda a principal técnica de aprendizado não supervisionado com o algoritmo K-Means (com Projeto)",
      "objectives": [
        "O que é Machine Learning",
        "O que é Clusterização",
        "O que é e como funciona o Jupyter Notebook",
        "Conhecer os principais tipos de aprendizado (supervisionado, não supervisionado e por esforço)",
        "Executar códigos em Python, célula por célula",
        "Aprender sobre o Método de Elbow e para quê utilizamos",
        "Entender quando aplicar transformação nos dados",
        "Aprender a aplicar a normalização",
        "Aprender a aplicar pesos para as variáveis mais importantes",
        "Aprender e executar o KMeans, principal algoritmo de clusterização",
        "Aprender um pouco mais sobre o pandas"
      ],
      "course_content": {
        "Introdução": [
          "Apresentação do Curso",
          "Mensagem Inicial IMPORTANTE! Veja até o final :)",
          "Dinâmica do Curso",
          "Estrutura do Curso: Módulos",
          "Ferramentas, Dicas e Contato"
        ],
        "Machine Learning": [
          "Definição",
          "Tipos de Aprendizado",
          "Aprendizado Supervisionado",
          "Aprendizado Não Supervisionado",
          "Aprendizado por Reforço",
          "Exemplos de Projetos"
        ],
        "Clusterização": [
          "Definição",
          "Importância",
          "Algoritmo",
          "Método de Elbow",
          "Normalização",
          "Alocação de Pesos",
          "Treinamento",
          "Alocação de Clusters",
          "Jupyter Notebook - Definição (do curso de ETL Básico com Python)",
          "Jupyter Notebook - Instalação (do curso de ETL Básico com Python)",
          "Jupyter Notebook - Visão Geral (do curso de ETL Básico com Python)",
          "Jupyter Notebook - Executando Códigos (do curso de ETL Básico com Python)"
        ],
        "Projeto": [
          "Kaggle",
          "Coleta de Dados",
          "Análise Exploratória: Parte I",
          "Análise Exploratória: Parte II",
          "Análise Exploratória: Parte III",
          "Normalização",
          "Método de Elbow",
          "Alocação de Pesos",
          "Treinamento, Alocação e Análise de Clusters"
        ],
        "Outros tópicos (bônus)": [
          "5 projetos de MACHINE LEARNING para desenvolver em uma empresa!",
          "6 ferramentas para se tornar um ANALISTA ou CIENTISTA DE DADOS!"
        ]
      },
      "requirements": [
        "Conhecimento básico de Python",
        "Muita vontade de aprender e de se destacar no mercado",
        "Você não precisa ser da área de exatas para realizar esse curso"
      ],
      "description": "COM PROJETO\nTEORIA E PRÁTICA\n\n\nSOBRE O CURSO\nEsse NÃO é mais um curso complicado, sem explicações claras ou exemplos práticos para o mercado de trabalho.\n\n\nEsse curso É um jeito simples de você aprender Machine Learning em projetos de Clusterização, dos primeiros conceitos até os mais avançados.\n\n\nVocê não precisa ter experiência na área de Dados ou exatas para acompanhar todo o curso, que foi pensado com didática simples e módulos progressivos para você avançar com segurança! E para auxiliá-lo na evolução ao longo do curso, temos um projeto do início ao fim! Porém, é interessante que você tenha já um conhecimento básico em Python.\n\n\nComece hoje a explorar a área de Ciência de Dados com tranquilidade. Mesmo que já esteja na área, essa é a oportunidade para você melhorar suas habilidades com um conhecimento novo. Machine Learning traz MUITO VALOR para o negócio com análises preditivas, que preparam a empresa para o que pode ocorrer no futuro, diferentemente do BI tradicional que trabalha com análises descritivas sobre o passado.\n\n\nCada vez mais o mercado de trabalho exige de vários profissionais o conhecimento sobre Machine Learning! Aprenda a agrupar seus clientes em diferentes clusters com o objetivo de entendê-los melhor e aplicar campanhas de marketing diferenciadas para cada grupo!\n\n\nLEMBRE-SE: A área de dados é a MAIS QUENTE do mercado atualmente. Os salários podem chegar a 22 mil reais! Então investir em seu desenvolvimento é a melhor escolha para sua carreira de sucesso. Fonte: UOL\n\n\nAbaixo a trilha ideal em direção ao sucesso na área de dados:\nSQL para Análise de Dados: do Básico ao Avançado (2024).\nCriação com Dashboards com Looker Studio.\nPython: Manipulação de Dados com Pandas.\nMachine Learning: Clusterização com Linguagem Python (curso que você está vendo).\nMachine Learning: Classificação com Linguagem Python.\nMachine Learning: Regressão com Linguagem Python.\n\n\nSOBRE O INSTRUTOR\nMe chamo Caio Avelino, e o conhecimento que vou dividir com você nesse curso foi adquirido, principalmente, com minha experiência no mercado de trabalho. Atuo nas áreas de Business Intelligence, Ciência de Dados e Inteligência Artificial há anos e tive a oportunidade de desenvolver minhas habilidades em diversas startups.\n\n\nAté mais!",
      "target_audience": [
        "Iniciantes e Curiosos sobre Machine Learning",
        "Alunos de Ciência de Dados que gostariam de aprender Clusterização",
        "Analistas de BI com interesse em utilizar Python para Machine Learning para se destacarem no mercado",
        "Qualquer pessoa, de qualquer área que deseja entrar no Mundo de Dados"
      ]
    },
    {
      "title": "顔認証システムを作ってみよう改訂版__画像から個人を特定 - 自宅で再現する本格派顔認証システム",
      "url": "https://www.udemy.com/course/_-eunkmg/",
      "bio": "パソコンとカメラだけ！ここまでできるＡＩ顔認証「さわって覚える人工知能」ディープラーニング編の拡張版 （GPU不要）",
      "objectives": [
        "顔認識・顔認証の仕組み",
        "写真画像での顔認識",
        "USBカメラでのリアルタイム顔認識",
        "顔検出の種類",
        "HoG特徴量による検出方法など",
        "顔認識・顔認証フレームワークの使い方"
      ],
      "course_content": {
        "紹介": [
          "はじめに",
          "講義の内容",
          "必要なもの",
          "受講対象者"
        ],
        "顔認識のしくみ": [
          "顔認識のしくみ",
          "顔認識をみてみよう",
          "画像認識とは（おさらい）",
          "顔認識の方法",
          "顔の見分けかた（ランドマークについて）",
          "PDF資料"
        ],
        "顔検出の種類": [
          "顔検出の種類",
          "Haar-like 特徴量",
          "Deep Neural Network",
          "Hog特徴量 Part1",
          "Hog特徴量 Part2",
          "Hog特徴量 Part3",
          "ディープラーニングについて",
          "PDF資料"
        ],
        "ブラウザで確認してみよう": [
          "ブラウザで確認してみよう",
          "画像を用意しよう",
          "Google Colabのインストール",
          "ライブラリーのインポート",
          "教材",
          "顔を検出してみよう1",
          "顔を検出してみよう2",
          "教材の不具合についてのお知らせ",
          "同一人物か判定してみよう1",
          "同一人物か判定してみよう2",
          "ランドマークの検出",
          "ランドマークのキーと値",
          "補足",
          "いろいろな顔写真で実験してみよう。"
        ],
        "USBカメラを使ってみよう：準備編": [
          "USBカメラを使ってみよう：準備編",
          "Macでの構築手順",
          "Anaconda のインストール前",
          "Anaconda のインストール",
          "補足：Windowsユーザーの方へ",
          "Python環境の構築",
          "補足：インストールに失敗する場合",
          "pip install"
        ],
        "USBカメラを使ってみよう：実行編": [
          "USBカメラを使ってみよう：実行編",
          "使用機器について",
          "カメラ画像の表示 Part1",
          "カメラ画像の表示 Part2",
          "カメラ画像の表示 Part3",
          "カメラ画像の表示 Part4",
          "顔の検出 Part1",
          "顔の検出 Part2",
          "顔の識別 Part1 （設定ファイルの作成）",
          "顔の識別 Part2（Colabで記述）",
          "顔の識別 Part3",
          "顔の識別 Part4",
          "顔の識別 Part5",
          "顔の識別 Part6",
          "フォントファイルについて",
          "名前の日本語表示 Part1",
          "名前の日本語表示 Part2",
          "出勤の確認をしてみよう Part1",
          "出勤の確認をしてみよう Part2",
          "出勤の確認をしてみよう Part3"
        ],
        "更に使いやすく": [
          "更に使いやすく",
          "チューニングしてみよう",
          "チューニングしてみよう Part2",
          "複数の顔の同時認識 + GPUマシンでの動作例",
          "GPUについて",
          "Macでの動作について",
          "python コード"
        ]
      },
      "requirements": [
        "Google アカウントの取得",
        "（可能であれば）USB接続のできるカメラ、またはPC付属のWEBカメラ"
      ],
      "description": "この講座では自宅のパソコンで顔認識（顔認証）のコードを作ることを目的としています。コンピュータでプログラムを動かしたことのない方でも動画の解説の通りに設定していけば動かせます。プログラミングの経験がある方は、パラメーターのチューニングを行ったりして改造してみましょう。必要なものはパソコンとWebカメラだけです（カメラが無くても静止画で体験することは可能です）。GPUは必要ありません（あればスムーズに動きます）。Windows、Mac、Linux(Ubuntu) などの環境で作ることができます。まず動かしてみたいという方は、教材コードをダウンロードして走らせてみましょう。\nまた、Webカメラでのリアルタイム実行はコマンドプロンプト（Macや Linuxはターミナル）上で行います。この操作に抵抗のある方は、写真画像だけとなりますが、Webブラウザ（Google Chrome）上で顔を識別プログラムを走らせることができます。チャレンジしてみてください。\nこのコースでは顔認識用の「フレームワーク」という独自のプログラムを使用しています。フレームワークとは、柱や間取りが決まった建売住宅のようなもので、一からプログラムを書くのがあまりにも手間取るので、分かり切ったところは一まとめにしているものです。これは丁度、電話機のようにボタンを押せば使えるといったものです。私たちは電話機の中身の構造はわかりませんが、電話のかけかたは教えてもらえればわかります。今回のコースはそのような感じです。そして英語に抵抗がある方は「当該目的を達成するためのボタンを押しているのだ」と思ってコード実行してみてください。\nPythonコードの教材付",
      "target_audience": [
        "画像認識に興味のある方。",
        "顔認識・顔認証に興味のある方",
        "プログラミング初級者～中級者"
      ]
    },
    {
      "title": "Classification des Nuages de Points dans CloudCompare",
      "url": "https://www.udemy.com/course/machinelearning3d/",
      "bio": "Classifiez automatiquement vos nuages de points 3D Lidar sur CloudCompare en utilisant de l'apprentissage automatique.",
      "objectives": [
        "Comprendre les fondamentaux de la classification de nuages de points 3D.",
        "Maîtriser l'utilisation du plugin 3DMASC dans CloudCompare.",
        "Appliquer la classification à différents types de données de nuages de points.",
        "Interpréter et analyser les résultats de classification ."
      ],
      "course_content": {
        "Introduction aux Nuages de Points 3D": [
          "Introduction aux Nuages de Points 3D",
          "Workflow 3D Complet",
          "Ressources et Terminologie"
        ],
        "MACHINE LEARNING 3D DANS CLOUDCOMPARE": [
          "Contenu de cette section",
          "Introduction au Machine Learning",
          "Apprentissage Supervisé VS Non-supervisé",
          "Apprentissage Ensembliste",
          "Aperçu de 3DMASC",
          "Préparation des Données",
          "Entraînement, Validation et Prédiction",
          "Segmentation par Composants Connectés",
          "Individualisation des Arbres avec TreeISO"
        ]
      },
      "requirements": [
        "Compréhension de base des nuages de points 3D et de leurs méthodes d'acquisition.",
        "Connaissance des concepts de base de l'apprentissage automatique.",
        "Accès au logiciel CloudCompare et au plugin 3DMASC (les instructions d'installation seront fournies)."
      ],
      "description": "Découvrez les fondements de la classification automatisée des nuages de points 3D avec notre cours sur CloudCompare. Apprenez à utiliser l'apprentissage automatique et le puissant plugin 3DMASC pour analyser et classifier vos données de nuages de points 3D de manière précise et efficace.\nDans ce cours complet, vous explorerez les méthodes de sélection des caractéristiques pertinentes, les techniques de prétraitement des données, et les stratégies de création et d'entraînement des modèles de classification. Vous découvrirez également comment interpréter les résultats de classification pour différentes applications, telles que la cartographie urbaine, la détection des objets et l'analyse environnementale.\nEn vous appuyant sur des exemples pratiques et des études de cas, vous développerez vos compétences en géomatique et en traitement des données 3D. Vous serez en mesure de gérer des ensembles de données volumineux, d'optimiser la précision de la classification et de visualiser les résultats de manière convaincante.\nQue vous soyez un étudiant en géomatique, un chercheur ou un professionnel travaillant avec des nuages de points 3D, ce cours vous fournira les connaissances et les compétences nécessaires pour maîtriser la classification automatisée dans CloudCompare.\nRejoignez-nous dès maintenant et découvrez comment exploiter pleinement le potentiel de la classification automatisée des nuages de points 3D pour des applications variées. Améliorez vos compétences et démarquez-vous dans votre domaine. Inscrivez-vous aujourd'hui et ouvrez de nouvelles opportunités professionnelles passionnantes !",
      "target_audience": [
        "Étudiants en doctorat, chercheurs ou professionnels en géomatique et en disciplines connexes",
        "Professionnels travaillant avec des données de nuages de points 3D et des technologies de balayage laser",
        "Scientifiques des données ou passionnés d'apprentissage automatique intéressés par la classification de données 3D",
        "Personnes souhaitant développer leurs connaissances et compétences en apprentissage automatique pour les nuages de points 3D"
      ]
    },
    {
      "title": "Machine Learning da zero con Python",
      "url": "https://www.udemy.com/course/machine-learning-da-zero-con-python/",
      "bio": "Reti Neaurali e Deep Learning con TensorFlow ,Keras e Scikit Learn.",
      "objectives": [
        "Programmare in Python",
        "Principali Tecniche di Machine Learning",
        "Utilizzare Librerie come Tensorflow, Keras, ScikitLearn",
        "tecniche di Deep Learning",
        "Validare modelli di classificazione",
        "Sviluppare progetti in maniera autonoma"
      ],
      "course_content": {
        "Introduzione": [
          "Cos'è il Machine Learning?",
          "Apprendimento supervisionato, non supervisionato e rinforzato",
          "ScikitLearn"
        ],
        "Introduzione a Python": [
          "Variabili e Assegnazione",
          "Operazioni Elementari",
          "Strutture di Dati",
          "Metodi Utili",
          "Diramazione",
          "Iterazione",
          "Funzioni",
          "Lettura & Scrittura su File",
          "Esercizi"
        ],
        "Introduzione a Numpy": [
          "cos'è Numpy?",
          "Introduzione Pratica a Numpy",
          "Generare Arrays",
          "Operazioni con Arrays",
          "Metodi Utili",
          "Statistica con Numpy",
          "Manipolazione di immagini",
          "Visualizzazione con Matplotlib"
        ],
        "Introduzione a Pandas": [
          "Serie",
          "Dataframe",
          "Lettura & Scrittura File",
          "Descrizione",
          "Group By",
          "Lavorare con valori Mancanti",
          "Label encoding & One hot encoding",
          "Visualizzazione"
        ],
        "Creazione di un modello supervised Learning & Unsupervised Learning": [
          "Come si crea un modello di Machine Learning?",
          "Raccolta dati",
          "Preparazione e Pulizia dei dati",
          "Problemi comuni nel Machine Learning",
          "Riduzione della dimensionalità",
          "Validazione di un Modello",
          "Curva ROC"
        ],
        "Supervised Learning": [
          "Introduzione all' Apprendiment Supervisionato",
          "Esempio di Regressione",
          "Perceptron",
          "Esempio pratico con Perceptron 1",
          "Esempio pratico con Perceptron 2",
          "Esempio pratico con Perceptron 3"
        ],
        "Unsupervised Learning": [
          "Introduzione all' Apprendimento non Supervisionato",
          "K-means",
          "Esempio K-means",
          "GMM Gaussian mixture model",
          "Esempio GMM"
        ],
        "Reti Neurali": [
          "Cosa sono le Reti Neurali?",
          "Esempio con Tensorflow",
          "Classificazione MNIST",
          "Classificazione MNIST con PCA",
          "Deep Learning",
          "Classificazione con Deep Learning"
        ]
      },
      "requirements": [
        "Consigliate ma non necessarie conoscenze basiche di statistica e matematica",
        "Voglia di imparare"
      ],
      "description": "Tutti parlano di Machine Learning ma capiamo davvero di cosa si tratta? Quali sono le basi? Come possiamo creare i nostri algoritmi? Perché è importante saperlo?\nIn questo corso spiegheremo i concetti più importanti che dobbiamo conoscere sul Machine Learning in modo pratico e divertente. Passeremo poco a poco da concetti semplici ad aspetti più complessi, in modo che tu possa imparare in modo facile e intuitivo.\nIl corso è progettato in modo che tu possa imparare da zero, senza la necessità di avere una conoscenza preliminare di questo mondo.\nIl corso è strutturato come segue:\nProgrammazione di base in Python, dove vedremo gli aspetti di base che devi gestire in Python per seguire il corso\n\n\nPandas handling, che ci aiuterà con tutte le precedenti elaborazioni dei dati di cui abbiamo bisogno per addestrare i nostri modelli di Machine Learning\n\n\nImparerai ad usare Numpy, una libreria ampiamente utilizzata quando lavori con vettori e matrici in Python\n\n\nIntroduzione al machine learning. In questa sezione introduttiva capirai perché è importante conoscere questa tecnologia che sta rivoluzionando il mondo e vedremo esempi di applicazioni\n\n\nCome viene costruito un modello di Machine Learning? Vedrai passo dopo passo cosa è necessario per creare i tuoi algoritmi di machine learning\n\n\nApprendimento supervisionato, studieremo cos'è, come possiamo usarlo e implementeremo un esempio da zero usando Python\n\n\nApprendimento senza supervisione Vedremo alcuni dei metodi più utilizzati e implementeremo alcuni esempi utilizzando librerie popolari come Scikit Learn\n\n\nReti neurali. In questo modulo spiegheremo cosa sono le reti neurali e come possiamo implementarle utilizzando librerie popolari come: TensorFlow, Keras e Scikit Learn. Vedremo anche un esempio reale di come risolvere un problema di classificazione nel settore della moda, applicando reti neurali con TensorFlow.\n\n\nDeep Learning, vedremo un'introduzione di base a cos'è il Deep Learning e implementeremo il nostro primo algoritmo utilizzando reti neurali convoluzionali.",
      "target_audience": [
        "Persone curiose di sapere come funziona il Machine Learning"
      ]
    },
    {
      "title": "للغة العربية NLP - Arabic Natural Language Processing",
      "url": "https://www.udemy.com/course/arabic-natural-language-processing-nlp/",
      "bio": "Arabic Natural Language Processing (للغة العربية NLP)",
      "objectives": [
        "Fundamentals of NLP and building optimization algorithms for the ARABIC LANGUAGE.",
        "Text Preprocessing.",
        "Text Classification.",
        "Classification based chatbot with Deep Neural network.",
        "Translation LSTM model, English ~ Arabic.",
        "ChatGPT similar model (Transformer Model)"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Installing Anaconda",
          "NLP Applications",
          "Course Structure",
          "Course Requirements"
        ],
        "Text Preprocessing": [
          "Tokenization with NLTK",
          "Tokenization with SPACY",
          "Multi-Word Tokenization",
          "Sentence Segmentation with SPACY",
          "Sentence Segmentation with NLTK",
          "POS Tagging (اعراب)",
          "Stop Words SPACY",
          "Stop Words NLTK",
          "Stemming NLTK",
          "Lemmatization NLTK",
          "Lemmatization SPACY",
          "Word_embedding / Word 2 Vector Part _ 1",
          "Word_embedding / Word 2 Vector Part _ 2",
          "Bag of Words",
          "TF-IDF Explanation",
          "TF-IDF Code"
        ],
        "Text Classification": [
          "Data Input",
          "Data Cleaning Part 1",
          "Data Cleaning Part 2",
          "NLTK Processes: Tokenization, Stop Words removal",
          "Data Analysis",
          "Model Training",
          "Support Vector Machine Classifier",
          "Results Evaluation"
        ],
        "Chatbot Classification based": [
          "DNN",
          "Data Creation",
          "Needed Libraries and Data Loading",
          "Text data Preparation",
          "Tranning data creation",
          "Model_building_tranning",
          "Chatbot Inference Program setup",
          "Words Clean Up, Bag of Words",
          "Chatbot testing"
        ],
        "Build Your Own ChatGPT": [
          "Transformer for ChatGPT",
          "Load_data",
          "data Preprocessing",
          "Training_data_creation",
          "Transformer model setting",
          "Training Result"
        ],
        "Build Your Own Translation Model": [
          "RNN_LSTM",
          "seq_2_seq translation",
          "Data Input",
          "Input data Preprocessing",
          "coding: Model Build Up- part1",
          "coding: Model Build Up- part2",
          "Results Review part 1",
          "Results Review part 2"
        ]
      },
      "requirements": [
        "High School Math",
        "Basic Python knowledge"
      ],
      "description": "Description\nThis is a complete course that will prepare you to use Natural Language Processing for the Arabic Language. We will cover the fundamentals of Machine Learning/ NLP and its applications for the Arabic Language, all examples are applied on Arabic Text and use Arabic Examples and recommend different methods and libraries to address the Arabic Natural language processing problem, such course is designed to reduce the time for the learner to Learn NLP for Arabic Language:\n\n\nWhat Skills will you Learn:\nIn this course, you will learn the following skills:\nUnderstand the Math behind NLP Language Algorithms.\nWrite and build Machine Learning/ NLP Algorithms for Arabic Language.\nPreprocess Text data for the machine learning step tranning.\nAnalyze Text data to extract valuable insights.\nUse opensource libraries.\n\n\nWe will cover:\nFundamentals of NLP and building optimization algorithms for the ARABIC LANGUAGE.\nText Preprocessing.\nText Classification.\nClassification based chatbot with Deep Neural network.\nTranslation LSTM model, English ~ Arabic.\nChatGPT similar model (Transformer Model).\nIf you do not have prior experience in Machine Learning OR Natural Language Processing (NLP) , that's NO PROBLEM!. This course is complete and concise, covering the fundamentals of  NLP and Applying it to the Arabic Language. Let's work together to learn NLP for the ARABIC LANGUAGE.",
      "target_audience": [
        "Anyone who wants to use NLP for the Arabic Language"
      ]
    },
    {
      "title": "深度学习模型部署与剪枝优化实例",
      "url": "https://www.udemy.com/course/deep-learning-tyd/",
      "bio": "模型部署-剪枝优化",
      "objectives": [
        "掌握深度学习框架模型部署方法",
        "使用pytorch部署深度学习模型",
        "使用tensorflow-serving部署深度学习模型",
        "掌握docker基本使用方法",
        "熟练应用docker部署深度学习环境",
        "使用docker构建深度学习应用",
        "掌握模型优化设计方法",
        "掌握mobilenet3代网络模型构建",
        "基于论文分析mobilenet三代算法",
        "将mobilenet应用到自己的实际任务中",
        "掌握经典剪枝策略与方法",
        "详解剪枝论文思想",
        "熟练使用剪枝策略在自己的模型与任务中"
      ],
      "course_content": {
        "PyTorch框架部署实践": [
          "课程简介",
          "所需基本环境配置",
          "模型加载与数据预处理",
          "接收与预测模块实现",
          "效果实例演示",
          "本章数据代码下载"
        ],
        "YOLO-V3物体检测部署实例": [
          "项目所需配置文件介绍",
          "加载参数与模型权重",
          "数据预处理",
          "返回线性预测结果",
          "数据代码下载"
        ],
        "docker实例演示": [
          "docker简介",
          "docker安装与配置",
          "阿里云镜像配置",
          "基于docker配置pytorch环境",
          "基于docker配置pytorch环境",
          "复制所需配置到容器中",
          "上传与下载配置好的项目",
          "数据代码下载"
        ],
        "tensorflow-serving实战": [
          "tf-serving项目获取与配置",
          "加载并启动模型服务",
          "测试模型部署效果",
          "fashion数据集获取",
          "加载fashion模型启动服务",
          "数据代码下载"
        ],
        "模型减枝-Network Slimming算法分析": [
          "论文算法核心框架概述",
          "BatchNorm要解决的问题",
          "BN的本质作用",
          "额外的训练参数解读",
          "稀疏化原理与效果",
          "数据代码下载"
        ],
        "模型减枝-Network Slimming实战解读": [
          "整体案例流程解读",
          "加入L1正则化来进行更新",
          "剪枝模块介绍",
          "筛选需要的特征图",
          "剪枝后模型参数赋值",
          "微调完成剪枝模型",
          "数据代码下载"
        ],
        "Mobilenet三代网络模型架构": [
          "模型剪枝分析",
          "常见剪枝方法介绍",
          "mobilenet简介",
          "mobilenet简介",
          "深度可分离卷积的作用与效果",
          "参数与计算量的比较",
          "V1版本效果分析",
          "V2版本改进以及Relu激活函数的问题",
          "倒残差结构的作用",
          "V2整体架构与效果分析",
          "V3版本网络架构分析",
          "SE模块作用与效果解读",
          "代码实现mobilenetV3网络架构",
          "PPT下载"
        ],
        "基础补充-PyTorch卷积模型实例": [
          "卷积网络参数定义",
          "网络流程解读",
          "Vision模块功能解读",
          "分类任务数据集定义与配置",
          "图像增强的作用",
          "数据预处理与数据增强模块",
          "Batch数据制作",
          "迁移学习的目标",
          "迁移学习策略",
          "加载训练好的网络模型",
          "优化器模块配置",
          "实现训练模块",
          "训练结果与模型保存",
          "加载模型对测试数据进行预测",
          "额外补充-Resnet论文解读",
          "额外补充-Resnet网络架构解读"
        ],
        "基础补充-Tensorflow2版本卷积模型实例": [
          "猫狗识别任务与数据简介",
          "卷积网络涉及参数解读开始学习",
          "网络架构配置",
          "卷积模型训练与识别效果展示"
        ]
      },
      "requirements": [
        "熟悉深度学习算法",
        "熟悉深度学习框架基本使用"
      ],
      "description": "深度学习模型部署与剪枝优化实例课程旨在帮助同学们快速掌握模型部署与优化方法。主要包括两大核心模块：1.基于深度学习框架PyTorch与Tensorflow2版本演示模型部署方法，使用docker工具简化环境配置与迁移问题；2.详解经典剪枝与模型设计论文并基于实例进行演示。整体风格通俗易懂，用最接地气的方式带领同学们快速掌握部署方法与优化实例。",
      "target_audience": [
        "人工智能，深度学习方向的用学门"
      ]
    },
    {
      "title": "Cours de Certification Professionnelle en Ingénierie de l’IA",
      "url": "https://www.udemy.com/course/cours-de-certification-professionnelle-en-ingenierie-de-lia/",
      "bio": "Maîtrisez le Deep Learning, les Transformers, le MLOps et le Développement d’Agents IA avec des Projets Concrets",
      "objectives": [
        "Ajustez et optimisez les modèles d’apprentissage automatique avec des techniques avancées",
        "Construisez et entraînez des CNN pour la classification d’images et les tâches de vision par ordinateur",
        "Développez des RNN, LSTM et GRU pour la modélisation de séries temporelles et de séquences",
        "Comprenez et implémentez des transformeurs et des mécanismes d’attention",
        "Appliquez l’apprentissage par transfert pour ajuster des modèles pré-entraînés puissants",
        "Concevez et analysez des agents d’IA pour la prise de décision autonome",
        "Utilisez TensorFlow et PyTorch pour des projets d’apprentissage profond",
        "Utilisez TensorFlow et PyTorch pour des projets d’apprentissage profond"
      ],
      "course_content": {
        "Introduction au Cours et à l’Instructeur": [
          "Ce que vous apprendrez dans le cours de certificat professionnel d'ingénieur IA"
        ],
        "Réglage et Optimisation des Modèles": [
          "Jour 1 : Introduction au Réglage des Hyperparamètres",
          "Jour 2 : Grid Search et Random Search",
          "Jour 3 : Réglage Avancé avec l’Optimisation Bayésienne",
          "Jour 4 : Techniques de Régularisation pour l’Optimisation des Modèles",
          "Jour 5 : Validation Croisée et Techniques d’Évaluation de Modèles",
          "Jour 6 : Réglage Automatisé avec GridSearchCV et RandomizedSearchCV",
          "Jour 7 : Projet d’Optimisation – Construction et Réglage d’un Modèle Final",
          "Ressources pour les projets"
        ],
        "Réseaux de Neurones Convolutifs (CNNs)": [
          "Jour 1 : Introduction aux CNNs",
          "Jour 2 : Couches Convolutives et Filtres",
          "Jour 3 : Couches de Pooling et Réduction de Dimensions",
          "Jour 4 : Construction d’Architectures CNN avec Keras et TensorFlow",
          "Jour 5 : Construction d’Architectures CNN avec PyTorch",
          "Jour 6 : Régularisation et Augmentation de Données pour CNN",
          "Jour 7 : Projet CNN – Classification d’Images sur Fashion MNIST ou CIFAR-10",
          "Ressources pour les projets"
        ],
        "Réseaux Neuronaux Récurrents (RNNs) et Modélisation de Séquences": [
          "Jour 1 : Introduction à la Modélisation de Séquences et aux RNNs",
          "Jour 2 : Comprendre l’Architecture RNN et la Rétropropagation dans le Temps (BPT",
          "Jour 3 : Réseaux à Mémoire Longue (LSTM)",
          "Jour 4 : Unités Récurrentes Gated (GRU)",
          "Jour 5 : Prétraitement de Texte et Word Embeddings pour RNN",
          "Jour 6 : Modèles Séquence à Séquence et Applications",
          "Jour 7 : Projet RNN – Génération de Texte ou Analyse de Sentiments",
          "Ressources pour les projets"
        ],
        "Transformers et Mécanismes d’Attention": [
          "Jour 1 : Introduction aux Mécanismes d’Attention",
          "Jour 2 : Introduction à l’Architecture des Transformers",
          "Jour 3 : Self-Attention et Attention Multi-Tête",
          "Jour 4 : Encodage Positionnel et Réseaux Feed-Forward",
          "Jour 5 : Pratique avec des Transformers Préentraînés – BERT et GPT",
          "Jour 6 : Transformers Avancés – Variantes de BERT et GPT-3",
          "Jour 7 : Projet Transformer – Résumé de Texte ou Traduction",
          "Ressources pour les projets"
        ],
        "Apprentissage par Transfert et Fine-Tuning": [
          "Jour 1 : Introduction à l’Apprentissage par Transfert",
          "Jour 2 : Transfert en Vision par Ordinateur",
          "Jour 3 : Techniques de Fine-Tuning en Vision",
          "Jour 4 : Transfert en Traitement du Langage Naturel (NLP)",
          "Jour 5 : Techniques de Fine-Tuning en NLP",
          "Jour 6 : Adaptation de Domaine et Défis du Transfert",
          "Jour 7 : Projet Transfer Learning – Fine-Tuning pour une Tâche Spécifique",
          "Ressources pour les projets"
        ],
        "Agents IA : Vue d’Ensemble Complète": [
          "Pratique avec AutoGen | IBM Bee | LangGraph | CrewAI | AutoGPT",
          "Pratique avec AutoGen",
          "Pratique avec le Framework IBM Bee",
          "Pratique avec LangGraph",
          "Pratique avec CrewAI",
          "Pratique avec AutoGPT"
        ],
        "Introduction et Pratique de MLOps": [
          "Introduction aux Sessions MLOps",
          "Vue d’Ensemble de MLOps et Son Importance",
          "Évolution des Opérations en ML",
          "Concepts Clés : Versioning, Automatisation, Monitoring",
          "MLOps vs. DevOps : Similitudes et Différences",
          "Pratique : Mise en Place d’une Structure de Projet MLOps (Git, Docker, Pipeline)",
          "Introduction à la Section Pipeline de la Science des Données à la Production",
          "Vue d’Ensemble du Workflow ML : Préparation des Données au Déploiement",
          "Expérimentation vs. Production",
          "Défis du Déploiement de Modèles ML",
          "Pratique : Construire un Pipeline ML de Bout en Bout",
          "Introduction à l’Infrastructure pour MLOps",
          "Présentation des Plateformes Cloud (AWS, GCP, Azure)",
          "Conteneurisation avec Docker",
          "Kubernetes pour l’Orchestration de Charges ML",
          "Configuration d’Environnements MLOps Locaux",
          "Pratique : Conteneuriser et Déployer un Modèle avec Kubernetes"
        ],
        "Examen Final et Félicitations": [
          "Examen Final",
          "Félicitations et Meilleurs Vœux"
        ]
      },
      "requirements": [
        "Avoir complété un cours d’introduction ou de niveau intermédiaire en IA ou apprentissage automatique (ou disposer de connaissances équivalentes)",
        "Solide compréhension de la programmation en Python, avec une expérience des fonctions, des classes et des bibliothèques comme NumPy et Pandas",
        "Bonne maîtrise des concepts fondamentaux de l’apprentissage automatique, y compris la régression, la classification, l’évaluation des modèles et le surapprentissage",
        "Familiarité avec les bases de l’apprentissage profond, notamment les réseaux neuronaux et les architectures de modèles de base",
        "Expérience préalable avec des outils comme Jupyter Notebook, TensorFlow ou PyTorch",
        "Connaissances pratiques des mathématiques pour l’IA, y compris l’algèbre linéaire, la probabilité et le calcul différentiel",
        "Un ordinateur (Windows, macOS ou Linux) avec une connexion Internet fiable et la capacité d’installer des outils de développement",
        "Volonté d’explorer des systèmes complexes de niveau production et d’investir du temps dans la programmation pratique, l’expérimentation de modèles et les flux de déploiement"
      ],
      "description": "Plongez dans le monde de l'ingénierie avancée en IA avec le Cours de Certification Professionnelle en Ingénierie de l’IA — votre guide complet pour maîtriser le deep learning, l’optimisation de modèles, les architectures transformers, les agents IA et le MLOps. Ce programme de niveau expert est conçu pour les apprenants prêts à passer de la théorie à la production, en construisant des systèmes d’IA de pointe à l’aide d’outils et de frameworks concrets.\nVous commencerez par le Réglage et l’Optimisation des Modèles, où vous apprendrez à ajuster les hyperparamètres grâce au Grid Search, Random Search et à l’Optimisation Bayésienne. Découvrez l’impact de la régularisation, de la validation croisée et des pipelines d’optimisation automatisés — essentiels pour améliorer la précision et l'efficacité de vos modèles.\nEnsuite, vous explorerez en profondeur les Réseaux de Neurones Convolutifs (CNN), les piliers de la vision par ordinateur. Vous apprendrez à construire des CNN depuis zéro, à utiliser les couches de convolution, de pooling et de dropout, et à les appliquer à la classification d’images, la détection d’objets, et plus encore, avec TensorFlow et PyTorch.\nDes images aux séquences — Réseaux Neuronaux Récurrents (RNN) et Modélisation Séquentielle couvre les bases de l’analyse de données temporelles. Apprenez à modéliser les séries temporelles, le texte et la parole à l’aide de RNN, LSTM et GRU, y compris comment résoudre les problèmes de gradients qui disparaissent et de dépendances à long terme.\nPuis, préparez-vous à explorer le joyau de l’IA moderne : Transformers et Mécanismes d’Attention. Apprenez comment l’auto-attention, l’attention multi-tête et l’encodage positionnel alimentent des modèles comme BERT, GPT et T5. Vous construirez des modèles transformers à partir de zéro et appliquerez des architectures pré-entraînées à des cas concrets.\nVous maîtriserez également le Transfer Learning et le Fine-Tuning, une compétence essentielle pour les ingénieurs en IA actuels. Apprenez à utiliser des modèles pré-entraînés et à les adapter à des tâches spécifiques grâce à des techniques d’extraction de caractéristiques et d’ajustement fin, ce qui permet d’économiser du temps et des données.\nLe cours comprend également une Vue d’ensemble complète des Agents IA. Vous explorerez les architectures des agents autonomes, y compris les agents réactifs, les agents orientés objectifs et les systèmes multi-agents. Découvrez comment les agents IA sont utilisés dans la prise de décision en temps réel, les jeux vidéo, les assistants personnels et les simulations basées sur des agents.\nEnfin, vous rassemblerez tout dans la section Introduction et MLOps pratique. Découvrez comment déployer, surveiller et maintenir des modèles en production avec des outils comme Docker, MLflow, Kubeflow et les pipelines CI/CD. Apprenez la gestion des versions de modèles, la reproductibilité et l’évolutivité — des compétences essentielles pour tout ingénieur IA moderne.\nÀ la fin de ce cours, vous serez capable de :\nOptimiser et déployer des modèles de deep learning en production\nConstruire des architectures CNN, RNN et à base de Transformers\nUtiliser le transfert d’apprentissage pour adapter des modèles puissants à de nouveaux domaines\nConcevoir des agents IA pour des environnements réels\nAppliquer les meilleures pratiques de MLOps pour des déploiements IA à grande échelle\nQue vous souhaitiez devenir Ingénieur Machine Learning, Chercheur en IA ou Architecte IA principal, ce cours est la passerelle ultime vers votre transformation en professionnel de l’IA.\nInscrivez-vous dès aujourd’hui et obtenez votre Certification Professionnelle en Ingénierie de l’IA — la référence en formation avancée en intelligence artificielle.",
      "target_audience": [
        "Ingénieurs en IA et praticiens du machine learning souhaitant approfondir leur expertise en réglage de modèles, apprentissage profond et déploiement",
        "Data scientists souhaitant se spécialiser dans les architectures d’apprentissage profond et les systèmes d’IA en temps réel",
        "Ingénieurs logiciels cherchant à intégrer des capacités d’IA dans des applications full-stack à l’aide de TensorFlow et PyTorch",
        "Étudiants diplômés ou chercheurs académiques en transition vers des rôles en IA au niveau industriel",
        "Professionnels de la tech souhaitant maîtriser les Transformers, MLOps et les cadres d’agents IA pour résoudre des problèmes métier complexes",
        "Toute personne ayant déjà suivi un cours d’introduction à l’IA ou au ML et souhaitant créer, ajuster et déployer en toute confiance des modèles d’IA de pointe"
      ]
    },
    {
      "title": "왕초보 데이터 분석 with R",
      "url": "https://www.udemy.com/course/beginner_with_r/",
      "bio": "R 기초, 프로젝트, 포트폴리오, 그리고 취업까지",
      "objectives": [
        "R의 기초문법을 배웁니다.",
        "R을 활용한 데이터 전처리, 시각화 등을 배웁니다.",
        "R을 활용하여 캐글데이터를 배웁니다.",
        "R을 활용하여 기초 통계를 배웁니다."
      ],
      "course_content": {
        "R 강의 소개 및 R/RStudio 설치": [
          "R 강의 소개 - Intro",
          "R과 RStudio 설치 - Mac",
          "R과 RStudio 설치 - Windows",
          "Rtools4 설치하기"
        ],
        "R 기초 문법": [
          "함수와 패키지 그리고 패키지 설치방법",
          "벡터 생성 및 데이터 타입 확인",
          "범주형(Factor) 벡터 개념 및 생성 방법 확인",
          "데이터 파일 입출력 및 dplyr 패키지를 활용한 데이터 가공 입문",
          "dplyr 패키지 활용 - Select, Mutate, Group By, Summarize, Muate, etc",
          "ggplot2 패키지 활용한 데이터 시각화 기초 1",
          "ggplot2 패키지 활용한 데이터 시각화 기초 2",
          "ggplot2 패키지 활용한 데이터 시각화 기초 3",
          "ggplot2 패키지 활용한 데이터 시각화 중급 1",
          "ggplot2 패키지 활용한 데이터 시각화 중급 2",
          "ggplot2 패키지 활용한 데이터 시각화 중급 3",
          "ggplot2 패키지 활용한 데이터 시각화 중급 4",
          "ggplot2 패키지 활용한 데이터 시각화 중급 5",
          "ggplot2 패키지 활용한 데이터 시각화 중급 6",
          "ggplot2 시각화 폰트 변경 - Mac",
          "ggplot2 시각화 폰트 변경 - Windows"
        ],
        "R을 활용한 기초통계": [
          "기초통계 - 평균, 중간값, 분산, 표준편차",
          "기초통계 - 변동계수",
          "기초통계 - 사분위수, 이상치 판별",
          "기초통계 - Z-Score",
          "기초통계 - Z-Test (One Sample T-test)",
          "기초통계 - One Sample T-Test 실습",
          "기초통계 - Two Samples T-Test (대응표본)",
          "기초통계 - Two Samples T-Test (독립표본)",
          "기초통계 - 분산분석 (일원분산분석 위주 - 이론 및 실습)"
        ],
        "데이터 수집 - 웹크롤링 및 및 API를 활용한 데이터 수집": [
          "웹 크롤링 기본편",
          "웹 크롤링 기본편2 - 위키피디아 테이블 수집",
          "웹 크롤링 기본편3 - CSS Selector 연습",
          "웹 크롤링 기본편4 - XPATH Selector 연습",
          "웹 크롤링 데이터 처리를 위한 문자열 처리 - stringr 연습",
          "웹 크롤링 데이터 처리를 위한 문자열 처리 - stringr with 정규표현식",
          "웹 크롤링 실전 1 - 온라인 쇼핑몰 (도서)",
          "웹 크롤링 실전 2 - 금융권 PDF 자료 다운로드",
          "웹 크롤링 실전 3 - Youtube API 활용한 댓글 수집"
        ]
      },
      "requirements": [
        "프로그래밍 경험 등이 필요하지 않습니다. 저와 함께 차근차근 배우게 될 것입니다."
      ],
      "description": "[공지]\n* 강의를 종료할 예정이니 신규 수강하지 말아주세요!!\n\n\nI. 강의 개요 및 목적\n- 본 강의는 취업 준비생 및 R 입문자를 위한 강의입니다.\n- 데이터 분석가에게 필요한 모든 역량을 담기 위해 노력했습니다.\n\n\nII. 강의 목차\n- 강의 개요는 아래와 같습니다.\n- 작성 기준 (2022.9.20) 보유하고 있는 콘텐츠는 약 80% 가량 됩니다.\n- 가급적 매주마다 꾸준히 올릴 예정입니다. 10월말 강의 녹화를 모두 마무리 하려고 노력중입니다.\nPART 1. 환경구축 (Windows & Mac)\nPART 2. 기초 문법\n- R 기초 문법, dplyr 패키지를 활용한 데이터 가공 예제, ggplot2를 활용한 데이터 시각화 예제\nPART 3. 기초 통계\n- 분산, 표준편차, t.test, 분산분석, 회귀분석, 로지스틱회귀분석 예제\nPART 4. 머신러닝 모델 개발\n- Caret, H2O, tidymodels를 활용한 지도학습 모형 개발 및 파라미터 튜닝\nPART 5. 캐글 프로젝트\n- 금융데이터를 활용한 캐글 대회 참여\nPART 6. 웹 크롤링 예제\n- 네이버 뉴스, Youtube API를 활용한 댓글 수집, PDF 크롤링\nPART 7. 텍스트 마이닝 예제\n- 감정 분석 예제\nPART 8. Shiny 대시보드 프로젝트 예제\n- DB 연동을 활용한 대시보드 프로젝트\nPART 9. Git 연동 및 개발 블로그\n- 소스코드 및 프로젝트 관리를 위한 Git 연동\n- Github 개발 블로그\n\n\nIII. 강의 목표\n- R을 활용하여 다양한 프로젝트를 빠른 시간내에 한번 모두 해보는 것을 목표로 한다.\n- 가급적 코드를 직접 작성하여 익히도록 한다.\n- 강사의 코드보다 보다 효율적인 코드로 업그레이드 하여 Github에 저장하도록 한다.",
      "target_audience": [
        "데이터 과학에 관심이 많은 R 사용자",
        "R 프로그래밍 입문자"
      ]
    },
    {
      "title": "Apache Nifi 2 : de Zéro à Héros",
      "url": "https://www.udemy.com/course/apache-nifi-en-francais/",
      "bio": "Formation sur Apache Nifi 2.0 pour apprendre les concepts clés, configurer des flows robuste et utiliser Nifi avec Kafka",
      "objectives": [
        "Installer et configurer Nifi",
        "utiliser les concepts principaux de Nifi : processors, process group, connections",
        "Gérer les queues Nifi",
        "Utiliser nifi pour envoyer des messages et les lire dans kafka",
        "Créer des processors custom dans Nifi.",
        "Versionner les flows avec Nifi registry"
      ],
      "course_content": {
        "Introduction": [
          "Introduction Formation",
          "Introduction à Nifi",
          "Les concepts clés et Architecture"
        ],
        "Installation": [
          "Installation de Nifi sur Windows"
        ],
        "Création d'un flow": [
          "Tour d'horizon de l'IHM",
          "Création de notre premier processor",
          "Configuration avancé d'un processor",
          "Utiliser les attributs depuis un processors et dynamic properties",
          "Tour d'horizon des processors disponibles",
          "Exercice - Enoncé",
          "Exercice - Réponse (à regarder quand même)",
          "Expression Language",
          "Quiz Expression Language",
          "Les parameter contexts",
          "Les parameter providers",
          "Gestion des queues",
          "Quiz sur Nifi"
        ],
        "Exercice : Nifi en serveur ftp": [
          "Enoncé",
          "Correction"
        ],
        "Exercice : Valider des fichiers CSV et les transformer en JSON": [
          "Enonce",
          "Correction ( à regarder )"
        ],
        "Cas d'usage : Nifi et Kafka": [
          "Exercice: Enoncé",
          "Présentation Kafka (optionnel)",
          "Topic et partition (optionnel)",
          "Installer Zookeeper (optionnel)",
          "installation kafka (optionnel)",
          "Créer un topic kafka (optionnel)",
          "Publier un message dans notre topic (optionnel)",
          "Réponse"
        ],
        "Autres": [
          "Advanced UI pour des conditions optimisées",
          "les compteurs"
        ],
        "Nifi registry : Git pour Nifi": [
          "Installer Nifi registry",
          "Utilisation de Nifi registry"
        ],
        "Créer notre propre processor": [
          "Initialisation et déploiement d'un processor custom"
        ],
        "Conclusion": [
          "Félicitations"
        ]
      },
      "requirements": [
        "Avoir Java 21 minimum d'installé",
        "Aucune expérience en programmation n'est requise",
        "Avoir un navigateur internet autre qu'internet explorer"
      ],
      "description": "NiFi est un logiciel libre de gestion de flux de données. Il permet de gérer et d'automatiser des flux de données entre plusieurs systèmes informatiques, à partir d'une interface web et dans un environnement distribué.\nNifi est basé sur le paradigme de programmation : FBP , Flow-Based Programming.\nPas besoin de savoir programmer pour utiliser Nifi grâce à son IHM web puissante qui va nous faciliter la vie.\nDans ce cours nous allons apprendre à utiliser Nifi pour créer votre propre flow de données.\nÀ l'issue de la formation vous serez à même de comprendre et d'utiliser toutes les fonctionnalités de Nifi.\nVous aurez toutes les clés en main et serez autonome pour utiliser les plus de 250 processors disponibles!\nVous allez comprendre l'ensemble des concepts les plus importants de Nifi\nAttributs\nProcess group\nVariables\nconnections\nprocessors\nTemplate\nMonitoring\nJ'ai moi-même utilisé Nifi de façon professionnelle pendant plusieurs années,  cela me permet d'être critique sur les bonnes pratiques à avoir et d'enrichir la formation avec mes propres expériences.\n\nVous souhaitez en apprendre plus sur le big data? Mes formations en Français sont disponibles.\nNifi 1.0 : Apache Nifi De A à Z - le Guide complet\nKafka: Apache Kafka pour débutant\nSpark: Apache Spark 3 pour les débutants la base du big data !\n\nCette formation n'est pas une suite de ma formation sur apache Nifi 1, mais bien une autre version mit à jour, qui présente la version 2.0 avec toutes ses nouveautés.",
      "target_audience": [
        "Personne souhaitant en apprendre d'avantage sur Apache Nifi.",
        "Data engineer",
        "Développeur et consultant en Big Data",
        "Architecte Big Data",
        "Développeur data souhaitant utiliser un meilleur outil que airflow"
      ]
    },
    {
      "title": "Python机器学习实验集锦（算法核心知识点实验分析）",
      "url": "https://www.udemy.com/course/pythonml/",
      "bio": "机器学习算法实验分析",
      "objectives": [
        "机器学习核心知识点实验分析",
        "sklearn工具包核心函数实战",
        "机器学习算法参数效果对比分析",
        "机器学习模型效果可视化展示",
        "机器学习模型融合策略对比",
        "线性回归，逻辑回归，决策树，集成算法，支持向量机等算法实验分析对比",
        "机器学习建模常用套路",
        "算法决策边界可视化展示"
      ],
      "course_content": {
        "机器学习模型评估方法": [
          "klearn工具包简介",
          "数据集切分",
          "交叉验证的作用",
          "交叉验证实验分析",
          "混淆矩阵",
          "评估指标对比分析",
          "阈值对结果的影响",
          "ROC曲线",
          "课程数据代码下载（谷歌网盘）"
        ],
        "线性回归实验分析": [
          "实验目标分析",
          "参数直接求解方法",
          "预处理对结果的影响",
          "梯度下降模块",
          "学习率对结果的影响",
          "随机梯度下降得到的效果",
          "MiniBatch方法",
          "不同策略效果对比",
          "多项式回归",
          "模型复杂度",
          "样本数量对结果的影响",
          "正则化的作用",
          "岭回归与lasso",
          "实验总结"
        ],
        "逻辑回归实验分析": [
          "逻辑回归实验概述",
          "概率结果随特征数值的变化",
          "可视化展示",
          "坐标棋盘制作",
          "分类决策边界展示分析",
          "多分类-softmax"
        ],
        "聚类算法实验分析": [
          "Kmenas算法常用操作",
          "聚类结果展示",
          "建模流程解读",
          "不稳定结果",
          "评估指标-Inertia",
          "如何找到合适的K值",
          "轮廓系数的作用",
          "Kmenas算法存在的问题",
          "应用实例-图像分割",
          "应用实例-图像分割",
          "DBSCAN算法"
        ],
        "决策树实验分析": [
          "树模型可视化展示",
          "决策边界展示分析",
          "树模型预剪枝参数作用",
          "回归树模型"
        ],
        "集成算法实验分析": [
          "构建实验数据集",
          "硬投票与软投票效果对比",
          "Bagging策略效果",
          "集成效果展示分析",
          "OOB袋外数据的作用",
          "特征重要性热度图展示",
          "Adaboost算法概述",
          "Adaboost决策边界效果",
          "GBDT提升算法流程",
          "集成参数对比分析",
          "模型提前停止策略",
          "停止方案实施",
          "堆叠模型"
        ],
        "支持向量机实验分析": [
          "支持向量机所能带来的效果",
          "决策边界可视化展示",
          "软间隔的作用",
          "非线性SVM",
          "核函数的作用与效果"
        ],
        "关联规则实战分析": [
          "关联规则概述",
          "支持度与置信度",
          "提升度的作用",
          "Python实战关联规则",
          "数据集制作",
          "电影数据集题材关联分析"
        ],
        "探索性分析-爱彼迎数据集分析与建模": [
          "数据与任务分析",
          "提取月份信息进行统计分析",
          "房价随星期变化的可视化展示",
          "房屋信息指标分析",
          "提取房屋常见设施",
          "房屋规格热度图分析",
          "预处理与建模准备",
          "随机森林与LightGBM",
          "训练与评估"
        ],
        "图像特征聚类分析实践": [
          "数据与任务流程分析",
          "图片数据导入",
          "图像特征编码",
          "数组保存与读取",
          "得出聚类结果",
          "聚类效果可视化展示"
        ]
      },
      "requirements": [
        "熟悉Python",
        "熟悉常用机器学习算法"
      ],
      "description": "Python机器学习实验集锦（算法核心知识点实验分析）课程旨在帮助同学们通过实验的方式掌握机器学习核心知识点，以sklearn为核心工具包进行实验分析，对比不同参数，策略对结果的影响。课程风格通俗易懂，全程实战，通过对结果可视化展示，讲解每一个复杂的知识点。",
      "target_audience": [
        "人工智能方向的同学们",
        "机器学习方向的同学们"
      ]
    },
    {
      "title": "Data Science mit Python - Numpy, Pandas und Plotly",
      "url": "https://www.udemy.com/course/data-science-mit-python-numpy-pandas-und-plotly/",
      "bio": "Lerne die wichtigsten Data Science Grundlagen mit Python",
      "objectives": [
        "NumPy - Numerische Operationen mit Python verstehen",
        "Auch komplexe Datentypen von NumPy richtig nutzen können",
        "Mit Pandas Datenselektion erleichtern",
        "Mit Plotly schöne Plots erstellen"
      ],
      "course_content": {
        "Einführung": [
          "Einführung"
        ],
        "Numpy": [
          "Arrays erstellen",
          "Arrays vs Python Lists",
          "Datentypen Grundlagen",
          "Shape",
          "Shapes von komplexen DTypes",
          "Benannte DTypes",
          "Slicing und Indexing",
          "Operationen von Vektoren und Matrizen",
          "Ravel und Flatten",
          "Reshape",
          "Stacks, Tiles, Konkatenation, Padding",
          "Zufall",
          "Daten laden und speichern",
          "Mehr zum Erstellen von Arrays",
          "Besondere Operationen",
          "Dataframes",
          "Series",
          "Multiindexierte und normale DataFrames erstellen",
          "Operationen und Indexierung von DataFrames",
          "Mehr wichtige Operationen auf DataFrames",
          "Einfache Statistik",
          "Reindex vs Zuweisen von Columns",
          "Fortgeschrittene Indexierung",
          "Iterieren über DataFrames",
          "Diskretisierung und Histogramme erstellen bei Floats",
          "Mehr zu Kategorien",
          "Konkatenieren von DataFrames",
          "Merge bei DataFrames",
          "Gruppieren",
          "Pivottables erstellen",
          "Stacking und Unstacking",
          "DateTime",
          "Datum und Uhrzeit als Index",
          "TimeDeltas",
          "CSV Dateien lesen und schreiben"
        ],
        "Plotly": [
          "Einleitung",
          "Graph Objects vs Dictionaries",
          "Scatter Plots mit Express",
          "Scatter Plots mit Fehlern",
          "Bar Diagramme mit Express",
          "Scatter Matrix - perfekt zum Überblick verschaffen",
          "Parallel-Graphen",
          "Animationen in Scatter Plots und mehr fortgeschrittene Themen",
          "Linien und Flächen-Plots",
          "Kuchen und Sunburst-Diagramme",
          "Histogramme erstellen",
          "Histogramme mit weiterverwendbaren Counts",
          "fortgeschrittene Histogramme",
          "Templates"
        ]
      },
      "requirements": [
        "Dieser Kurs richtet sich an Python Entwickler und setzt voraus, dass Konzepte wie Funktionen bekannt sind"
      ],
      "description": "Data Scientist - sexiest Job des 21. Jahrhunderts?\nVielleicht. Und doch muss man fit dafür sein.\nWie bei allem, ist der Anfang das Schwerste, in diesem Fall wird er aber schon vorausgesetzt.\nDieser Kurs setzt nämlich Python Kenntnisse voraus und richtet sich an alle, die die Grundlagen von Python verstanden haben.\nHiermit könnt ihr einen Fuß in Data Science setzen.\nDie wichtigsten Module dafür sind Numpy, Pandas und Plotly.\nNumpy steht für numerical Python. Arrays, Matrizen, Berechnungen, komplexe Datentypen, all das hält Python vor dem Programmierer versteckt, doch mit Numpy tut sich diese Freiheit für den Programmierer auf. Meist ist das erstmal ein Schlag, doch für Data Scientists eine Notwendigkeit, denn die Bibliothek beschleunigt vieles und lässt doch einfach eine Vielzahl an mathematischen Operationen zu.\nPandas ist eine Abkürzung für Python and Data Science - ja, ein wenig muss man es wollen. Hier wird auf einer effizienten Datenstruktur gearbeitet, den sogenannten DataFrames. Diese sind vielfältig, haben jedoch auch viele Ähnlichkeiten zu SQL und erlauben es dem Programmierer, Daten auszuwählen, zu sortieren und zu ordnen, die relevant sind.\nZu guter Letzt wagen wir einen Blick zu Plotly. Viele Data Scientists arbeiten mit Matplotlib, doch ich bin der Meinung, dass Plotly nicht nur besser aussieht, sondern auch einfacher, schneller und effizienter Grafiken erstellt. Denn darauf kommt es an: Plots, Grafiken, die die Daten direkt für Beteiligte oder Unbeteiligte erklären.\nDieser Kurs ist zudem unter aktiver Entwicklung und wird - sofern ich Requests erhalte - auch weiter entwickelt. Je nach Reichweite und Erfolg könnte ich mir auch noch andere Bibliotheken vorstellen, vor allem im Visualisierungsbereich, oder aber Praxisprojekte oder konkrete Ergänzungen für die Module. Daher - meldet euch gerne.\nUnd nun - viel Spaß!",
      "target_audience": [
        "Python-Entwickler mit Anfängerkenntnissen, die sich für Data Science interessieren"
      ]
    },
    {
      "title": "Visualização da Dados Python e R: Data Science na Prática",
      "url": "https://www.udemy.com/course/visualizacao-da-dados-python-e-r-data-science-na-pratica/",
      "bio": "O poder das principais ferramentas de Data Science do mercado",
      "objectives": [
        "Entendendo o R",
        "Primeiros passos com o R",
        "Objetos no R",
        "Tipos de objetos: Matrizes, Listas",
        "Identificação de valores faltantes e especiais",
        "Salvar uma workspace",
        "Acesso pelo R-studio",
        "Entendimento dos diferentes tipos de pacotes",
        "Trabalhando com leitura de arquivos externos",
        "Lendo um arquivo na web",
        "Selecionando dados",
        "Gráficos (análise de dados e apresentação)",
        "Tipos de gráficos: Histogramas, Ramo e Folha, Box-plot, Gráfico de dispersão,Gráfico de barras, Setores",
        "Variáveis qualitativas: Nominais e Ordinais",
        "Análise univariada e bivariada",
        "Teste de uma distribuição normal",
        "Comparação de duas médias",
        "Regressão linear simples",
        "Mineração de dados com o R",
        "Instalação do R-studio e R",
        "Vetores,Data frames,Funções",
        "Workspace do r(área de trabalho)",
        "Leitura de uma workspace",
        "Pacotes do R",
        "Uso dos comandos library, intall package,require",
        "Leitura através do R-studio",
        "Sumarizando dados",
        "Uso dos conectores lógicos",
        "Exportando gráficos",
        "Programação: Comando FOR, Criando funções pelo R-studio, Uso de Estatísticas",
        "Variáveis quantitativas: Discretas e Continuas",
        "Teste de hipóteses",
        "Teste chi-quadrado para aderência",
        "Comparação de médias múltiplas pelo teste de Tukey",
        "Regressão linear múltipla",
        "Uso do Google Vis ( biblioteca gráfica do Google)",
        "Desenvolver programas usando a linguagem Python",
        "Manipular estruturas condicionais",
        "Mineração de arquivos com Python",
        "Manipular estruturas de repetição",
        "Realizar operações matemáticas usando Python",
        "Manipular strings",
        "Realizar operações lógicas",
        "Python",
        "Visualizar de dados com Python",
        "Conhecer a biblioteca MATPLOTLIB PYPLOT",
        "Construir gráficos de linhas, barras, dispersão e boxplot"
      ],
      "course_content": {
        "Introdução": [
          "Bem-vindo",
          "Conheça a plataforma da Udemy",
          "INFORMAÇÕES IMPORTANTES - Leia antes de iniciar o curso"
        ],
        "Visualização de dados com Python": [
          "Introdução",
          "Requisitos",
          "Google Colab (ambiente para desenvolvimento alternativo)",
          "Sublime text",
          "Gráfico de linhas",
          "Inserindo legendas em gráficos",
          "Gráfico de barras",
          "Comparando gráfico de barras",
          "Scatterplot",
          "Marcadores, cores e tipos de linhas",
          "Inserindo pontos em gráficos de linhas",
          "Documentação do MATPLOTLIB.PYPLOT",
          "Salvando figuras",
          "Estudo de caso: crescimento da população",
          "Crescimento da população",
          "O que é boxplot?",
          "Boxplot",
          "Estudo de caso: Bioinformática - comparando genomas",
          "Estudo de caso: Bioinformática - comparando genomas parte 1",
          "HTML",
          "Estudo de caso: Bioinformática - comparando genomas parte 2",
          "Estudo de caso: Bioinformática - comparando genomas parte 3",
          "Estudo de caso: Bioinformática - comparando genomas parte 4"
        ],
        "LINGUAGEM R - Operações com Dados": [
          "Apresentação do Curso e Instalação do R",
          "R-Studio, Trabalhando com operações básicas, Help do R, Trabalhando com Vetores",
          "Operações com Objetos do R, Trabalhando com Vetores",
          "Trabalhando com Matrizes",
          "Data Frame, Listas, Trabalhando com Workspace, Funções, Trabalhando com Pacotes",
          "Leitura de arquivos externos, Sumarizando Dados (medidas estatísticas)",
          "Gráficos no R: Histograma, Box-Plot, Ramo e Folhas, Barras, Setores",
          "Programação, Análise Uni e BI variada, Uso de Var. Qualitativas e Quantitativas",
          "Teste de Hipóteses e Regressão Linear e Múltipla",
          "Mineração de Dados e Google VIS",
          "Responda a nossa pergunta"
        ]
      },
      "requirements": [
        "Python básico"
      ],
      "description": "As grandes empresas estão em busca de profissionais que saibam tratar e trabalhar dados, permitindo que novos insights sejam descobertos e aplicados ao seu negócio.\nPara compreender dados é necessário visualizá-los. Neste curso, você aprenderá a criar gráficos e visualizações de dados fantásticas usando duas linguagens: Python e R.\nPython é largamente utilizado na maioria das empresas de tecnologia, ele foi construído para permitir a criação de scripts na sua linguagem para geração de modelos de dados,modelos estes matemáticos e estatísticos de fácil interpretação e manipulação, permitindo que os resultados sejam exibidos assim que seus comandos sejam executados, é utilizado um interpretador Python para esta finalidade.\nCom isso pretendemos levar o  que há de mais interessante na área para que você aprenda a trabalhar com R e Python. O curso de R conta com um material próprio, apostila passo a passo para você aprender a ser um grande profissional da área.\nVocê entenderá os algoritmos e poderá praticar com suas bases de dados, seja arquivo texto ou banco de dados.\nO nosso curso conta com diversos exercícios práticos e com assuntos que são vistos na maioria das grandes empresas.\nOs professores são largamente conhecidos e estão disponíveis para atendimento das suas dúvidas pelo tempo que necessitar. Venha fazer parte desta equipe que não para de crescer.",
      "target_audience": [
        "Estudantes, Profissionais da área de dados, Estatísticos",
        "Programadores Python interessados em aperfeiçoar seus conhecimentos"
      ]
    },
    {
      "title": "[ES] DeepSeek R1 IA: 25 proyectos de IA para principiantes",
      "url": "https://www.udemy.com/course/deepseek-r1-ia-25-proyectos-de-ia-para-principiantes/",
      "bio": "Desarrollo práctico con DeepSeek: crea 25 proyectos reales de NLP y automatización desde cero",
      "objectives": [
        "Crea herramientas de procesamiento de texto con IA como resumidores.",
        "Aplica técnicas de PLN en usos reales.",
        "Instala y configura DeepSeek AI localmente.",
        "Desarrolla chatbots inteligentes para distintos sectores.",
        "Automatiza tareas con modelos de DeepSeek AI.",
        "Genera contenido y reportes asistidos por IA.",
        "Crea asistentes y depuradores de código con IA.",
        "Optimiza modelos de DeepSeek AI para mejor rendimiento.",
        "Desarrolla sistemas de recomendación con IA.",
        "Crea apps de IA prácticas sin depender de la nube."
      ],
      "course_content": {
        "Intro a DeepSeek AI: 25 Proyectos Prácticos para Desarrolladores de IA": [
          "Bienvenida al Curso – Visión general, objetivos y requisitos previos",
          "Configura DeepSeek AI: instalación, ajustes y primer test de ejecución",
          "Curso Rápido: Aprende Python desde cero"
        ],
        "Procesamiento de Texto e IA NLP": [
          "Proyecto 1: Resumidor de Texto con DeepSeek AI",
          "Proyecto 2: Generación de Texto con DeepSeek AI",
          "Proyecto 3: Corrector Gramatical y Ortográfico con DeepSeek AI",
          "Proyecto 4: Herramienta NER (Entidades Nombradas) con DeepSeek AI",
          "Proyecto 5: Análisis de Sentimientos con DeepSeek AI"
        ],
        "Chatbots y Asistentes Virtuales": [
          "Proyecto 6: Chatbot de Soporte al Cliente con DeepSeek AI",
          "Proyecto 7: Asistente Personal con DeepSeek AI",
          "Proyecto 8: Asistente Legal con DeepSeek AI",
          "Proyecto 9: Verificador de Síntomas Médicos con DeepSeek AI",
          "Proyecto 10: Bot de Recomendación de Productos para E-commerce con DeepSeek AI"
        ],
        "IA para Automatización y Productividad": [
          "Proyecto 11: Respondedor Automático de Correos con DeepSeek AI",
          "Proyecto 12: Generador de Currículums con DeepSeek AI",
          "Proyecto 13: Generador de Minutas de Reunión con DeepSeek AI",
          "Proyecto 14: Extractor de Texto de PDF Automatizado con DeepSeek AI",
          "Proyecto 15: Generador de Contenido con DeepSeek AI"
        ],
        "IA para Desarrolladores y Código": [
          "Proyecto 16: Autocompletador y Asistente de Código con DeepSeek AI",
          "Proyecto 17: Generador de Consultas SQL con DeepSeek AI",
          "Proyecto 18: Depurador de Código con DeepSeek AI",
          "Proyecto 19: Generador de Documentación con DeepSeek AI",
          "Proyecto 20: Tester de APIs con DeepSeek AI"
        ],
        "IA para Negocios y Análisis de Datos": [
          "Proyecto 21: Analizador de Feedback de Clientes con DeepSeek AI",
          "Proyecto 22: Resumidor de Noticias en Tiempo Real con DeepSeek AI",
          "Proyecto 23: Analizador de Reportes Financieros con DeepSeek AI",
          "Proyecto 24: Filtro de Solicitudes de Empleo con DeepSeek AI",
          "Proyecto 25: Resumidor de Artículos de Investigación con DeepSeek AI"
        ]
      },
      "requirements": [
        "Familiaridad con herramientas de línea de comandos (uso básico del terminal).",
        "Una computadora con al menos 8GB de RAM para ejecutar modelos de DeepSeek AI.",
        "Un entorno de Python instalado (cubriremos cómo configurarlo).",
        "Algo de experiencia en aprendizaje automático o PLN (opcional pero útil).",
        "Interés en la automatización y chatbots impulsados por IA.",
        "No se necesitan servicios en la nube: ¡todo funciona localmente!",
        "Entusiasmo por construir aplicaciones de IA del mundo real.",
        "Disposición para experimentar y explorar herramientas de IA.",
        "Acceso a un editor de código (VS Code, PyCharm o Jupyter Notebook)."
      ],
      "description": "Este curso está traducido mediante IA del inglés al español para que puedas aprender tecnologías de vanguardia en tu idioma nativo.\n\nDesbloquea el poder de DeepSeek AI con 25 proyectos prácticos\n¿Estás listo para crear aplicaciones de IA del mundo real con DeepSeek AI? Este curso te llevará de principiante a desarrollador avanzado de IA, con un enfoque en procesamiento de lenguaje natural (PLN), chatbots, automatización y aplicaciones basadas en IA—¡todo sin depender de servicios en la nube!\nDeepSeek AI es un modelo de IA de código abierto y potente que permite a los desarrolladores trabajar con automatización avanzada, generación de texto y tareas de PLN de forma local. En este curso, implementarás 25 proyectos del mundo real y obtendrás experiencia práctica aplicando IA en negocios, productividad, automatización y desarrollo de software.\nLo que aprenderás\nAl finalizar el curso, podrás:\nInstalar y configurar DeepSeek AI en tu equipo local.\nCrear aplicaciones de procesamiento de texto con IA: resumen, corrección gramatical y análisis de sentimientos.\nDesarrollar chatbots y asistentes virtuales para soporte, comercio electrónico y productividad.\nAutomatizar tareas diarias como redacción de correos, creación de currículums y resúmenes de documentos.\nImplementar herramientas de desarrollo con IA: autocompletado, depuración y generación de SQL.\nOptimizar modelos de IA para rendimiento y eficiencia locales.\nDesarrollar aplicaciones de IA para casos empresariales como análisis financiero o selección de candidatos.\nObtener experiencia práctica en PLN y automatización basada en IA con Python.\nCrear proyectos reales sin usar APIs basadas en la nube.\n¿A quién va dirigido este curso?\nIdeal para:\nDesarrolladores Python que quieran integrar IA en sus apps.\nPrincipiantes en IA y PLN que buscan experiencia práctica.\nCientíficos de datos explorando modelos de IA para texto.\nProfesionales tech que desean crear herramientas de automatización con IA.\nEmprendedores interesados en productos impulsados por IA.\nEstudiantes e investigadores trabajando sin depender de la nube.\nResumen de los proyectos del curso\nEste curso incluye 25 proyectos prácticos sobre:\nProcesamiento de texto con IA – resumen, análisis de sentimientos, generación de texto.\nChatbots y asistentes virtuales – creación de asistentes inteligentes.\nAutomatización con IA – respuestas automáticas, generación de currículums, automatización de flujos.\nIA para desarrolladores – autocompletado de código, depuración, pruebas de API.\nIA para negocios – análisis financiero, selección de personal, análisis de feedback.\n¿Por qué tomar este curso?\nProyectos prácticos para ganar experiencia real.\n¡Sin dependencia de la nube—todo corre localmente!\nImplementación paso a paso con código completo.\nCubre automatización con IA, chatbots, PLN y más.\nPerfecto para desarrolladores, estudiantes y entusiastas.\n¡Empieza a crear aplicaciones impulsadas por IA hoy!\nInscríbete ahora y desbloquea todo el potencial de DeepSeek AI con 25 proyectos reales y prácticos.",
      "target_audience": [
        "Desarrolladores de Python que buscan integrar IA en sus aplicaciones.",
        "Principiantes en IA y ML que desean experiencia práctica con PLN y automatización.",
        "Científicos de datos que exploran DeepSeek AI para procesamiento de texto y chatbots.",
        "Fundadores de startups y emprendedores que crean productos impulsados por IA.",
        "Entusiastas de la automatización que quieren optimizar flujos de trabajo con IA.",
        "Estudiantes e investigadores que experimentan con herramientas basadas en IA.",
        "Profesionales tecnológicos que desean mejorar sus habilidades en automatización con IA.",
        "Autodidactas y aficionados a la IA con ganas de explorar nuevas aplicaciones de IA."
      ]
    },
    {
      "title": "50分钟通关AI大模型原理",
      "url": "https://www.udemy.com/course/50ai-ird/",
      "bio": "人人都能懂的AI大模型科普课",
      "objectives": [
        "AIGC关键词含义",
        "AI分类与基础理论",
        "生成式AI背后关键技术",
        "AI聊天助手训练流程",
        "提示词工程科普"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "啥是“AIGC”？带你分清一堆AI技术词",
          "啥是大语言模型（LLM）？",
          "ChatGPT原理揭密！背后的黑科技Transformer模型",
          "一口气了解ChatGPT的训练过程！",
          "调教AI的秘密！提示工程：小样本提示、思维链、分步骤思考",
          "AI数据过时、编造事实、计算不准，怎么办？详解RAG、ReAct、PAL"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "无经验"
      ],
      "description": "AI大模型通常指的是在人工智能领域中，具有大量参数的深度学习模型。这些模型因为参数众多，能够捕捉到数据中的复杂模式和细微差别，从而在各种任务上展现出卓越的性能。\n这是一门人人都能懂的AI大模型科普课，50分钟速通，看了就懂了～\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "希望了解当下前沿AI技术的学员",
        "希望顺应智能时代的人才需求的学员"
      ]
    },
    {
      "title": "データサイエンスのための因果推論入門",
      "url": "https://www.udemy.com/course/causal_inference/",
      "bio": "データから意思決定へ ─ 観測データを活かす因果推論の理論と実践",
      "objectives": [
        "因果推論の基礎的な知識(因果、反実仮想、因果効果、傾向スコアなど)を獲得できる",
        "セレクションバイアス、ABテストの関係を理解し、なぜ因果推論の手法が必要かを理解できる",
        "因果効果推定のための手法の理論的背景(IPW、回帰分析、メタラーナー、DML)を理解できる",
        "Pythonで各種因果推論手法(IPW、回帰分析、メタラーナー、DML)を実装できる"
      ],
      "course_content": {
        "はじめに": [
          "講座概要",
          "使用するデータ"
        ],
        "因果推論の基礎(理論)": [
          "因果とは",
          "因果効果とは",
          "セレクションバイアスとは",
          "因果効果とバックドア基準",
          "ABテスト",
          "因果効果の種類",
          "セレクションバイアスとABテスト"
        ],
        "因果推論の手法(理論・実践)": [
          "因果効果の推定手法",
          "IPW(理論)",
          "IPW(実装) Part1",
          "IPW(実装) Part2",
          "IPW(実装) Part3",
          "IPW(実装) Part4",
          "回帰分析(理論)",
          "回帰分析(実装) Part1",
          "回帰分析(実装) Part2",
          "MetaLearner(理論)",
          "MetaLearner(実装) Part1",
          "MetaLearner(実装) Part2",
          "MetaLearner(実装) Part 3",
          "MetaLearner(実装) Part4",
          "MetaLearner(実装) Part5",
          "MetaLearner(実装) Part6",
          "DML(理論)",
          "DML(実装) Part1",
          "DML(実装) Part2"
        ],
        "ボーナスレクチャー": [
          "コースで使用したnotebook"
        ]
      },
      "requirements": [
        "Pythonのプログラミングスキル",
        "高校レベルの確率・統計の知識"
      ],
      "description": "【本講座の概要】\n本講座は、データサイエンスの現場で因果推論を活用し、施策の効果を適切に評価するスキルを習得するための講座です。\n近年、ビジネスにおいて「効果があったのか？」「施策の改善インパクトは？」といった問いへの科学的なアプローチ＝因果推論がますます重要になっています。A/Bテストはこの中で最も王道のアプローチではありますが、A/Bテストができないケースや、バイアスがある観測データから正しく意思決定を導くには、単なる相関分析では不十分です。\n一方で、こんな悩みはないでしょうか？\n機械学習や統計モデルは使えるが、施策の「効果」や「因果関係」の見方が分からない\n回帰や傾向スコアという言葉は聞いたことがあるが、実務で使える形で整理できていない\nPythonやpandasでの分析はできるが、因果推論のライブラリの使い方が分からない\n本講座は、こうした悩みを抱えるデータサイエンティストやビジネスパーソンのために設計されました。\n\n\n【この講座で学べること】\nこのコースでは、理論と実践のバランスを重視し、以下のトピックをカバーします。\n\n\n■ 因果推論の基礎理論\n「因果とは何か？」、「因果効果とは？」など因果推論における基本事項\n反実仮想（Potential Outcome）フレームワーク\nセレクションバイアスとABテスト\n■ 因果効果の推定手法（理論編）\n因果効果の推定手法 (概要)\n傾向スコアの推定とIPW（逆確率重み付け）\n回帰分析による補正\nメタラーナー（T-Learner, S-Learner, X-Learner）\nDML（Double Machine Learning）\n\n\n■ 因果推論の実践（Pythonによる実装編）\ncausallib を使ったIPWの実装\nstatsmodelsによる回帰分析の実装\neconml を使ったメタラーナー・DMLの実装\n\n\n【対象者とゴール】\nこの講座は、以下のような方を対象としています。\n自社施策やマーケティング施策の効果検証を行うビジネスパーソン\nプロダクト改善において、データドリブンな意思決定が求められるデータサイエンティスト\n因果推論の理論と実装の両面を学びたいデータ分析者・研究者\n受講の前提としては、Pythonでのデータ分析（pandasやscikit-learnなど）の基本操作に慣れている方を想定しています。また因果推論では確率、統計を用いますので、期待値や条件付き確率など高校レベルの数学を理解しておく必要があります。\n\n\n本コースのゴールは、次の通りです。\n観測データから因果効果を推定する理論的背景を理解する\nPythonによる因果推論の主要ライブラリを使いこなし、実装できる力を身に付ける\n\n\n【人事・マネージャーの方へ】\n社内のデータ活用で間違った意思決定を避けるために、因果推論はあります。\n社内のDX推進部門やデータサイエンティストが受講する事で、正しい効果検証のフレームワークを学ぶことができます。\nこの講座を通じて、メンバーは単なる相関分析ではなく、バイアスを除いた真の因果効果を見積もることができ、社内のデータ分析力と意思決定力が大きく向上します。\n\n\nビジネスに直結する「因果」の力を、ぜひこの講座で実践的に身に付けてください。",
      "target_audience": [
        "自社施策やマーケティング施策の効果検証を行うビジネスパーソン",
        "プロダクト改善において、データドリブンな意思決定が求められるデータサイエンティスト",
        "因果推論の理論と実装を体系的に学びたい分析者・研究者"
      ]
    },
    {
      "title": "Power BI para Data Science e Analytics",
      "url": "https://www.udemy.com/course/powerbi-datascience-analytics/",
      "bio": "Do Zero ao Avançado em Power BI",
      "objectives": [
        "Instalação do Power Bi Desde o Zero para dar os primeiros passos",
        "Desenvolver ETLs Completas com o Power BI",
        "Linguagem DAX do Zero ao Avançado",
        "Construir visualizações profissionais com todos os recursos do Power BI",
        "Modelagem de Dados usando Power BI",
        "Otimização dos seus Dashboards para melhor performance"
      ],
      "course_content": {
        "Introdução": [
          "Aula 0 - Materiais",
          "Boas Vindas",
          "O que é Power BI",
          "Instalação Power BI",
          "Interface Power BI"
        ],
        "ETL": [
          "O que é ETL",
          "Importando do Excel",
          "Importando de CSV",
          "Importando da Pasta",
          "Importando da Web",
          "Organização Tabelas",
          "Etapas Aplicadas",
          "Power Query pt1",
          "Power Query pt2",
          "Power Query pt3",
          "Power Query pt4",
          "Power Query pt5",
          "Agrupar Por",
          "Parametros",
          "Mesclar e Acrescentar Consultas",
          "Funções Personalizadas"
        ],
        "Modelagem": [
          "O que é modelagem",
          "Importância da Modelagem",
          "Tipos de Tabela",
          "Tipos de Cardinalidade",
          "Chave Primária e Estrangeira",
          "Tipos de Modelo",
          "Tipos de Relacionamento",
          "Otimizando o Modelo",
          "Dicas na Hora de Modelar"
        ],
        "DAX": [
          "O que é DAX",
          "Tabela de Medidas",
          "Funções de Agregação",
          "Calculate",
          "Variáveis",
          "Funções Inteligencia de Tempo pt 1",
          "Funções Inteligencia de Tempo pt 2",
          "Funções Inteligencia de Tempo pt 3",
          "Funções de Data Pt 1",
          "Funções Matemáticas",
          "Funções de Texto",
          "Funções Logicas",
          "Funções de Informação",
          "Funções Iterantes",
          "Funções de Filtro",
          "Funções de Relacionamento",
          "Funções de Tabela pt 1",
          "Funções de Tabela pt 2",
          "Funções de Tabela pt 3",
          "Funções de Tabela pt 4",
          "Operadores Logicos"
        ],
        "Visualizações": [
          "Introdução as Visualizações",
          "Caixa de Texto Inteligente",
          "Botões Formas e Imagens",
          "Painel de Seleção",
          "Tema Personalizado",
          "Gráficos de Barras e Colunas",
          "Gráfico de Linha e Área",
          "Gráfico de Coluna e Linha e Faixa de Opções",
          "Gráficos de Pizza, Anel e Treemap",
          "Gráfico de Cartão, Linhas Multiplas e Segmentador de Dados",
          "Sincronização de Filtros",
          "Gráfico de Tabela e Matriz",
          "Parametros Whatif - Analise de Cenários",
          "Dicas de Ferramentas",
          "Drill Down",
          "Drill Through",
          "Bookmarks",
          "Formatação Condicional",
          "Visuais Personalizados parte 1",
          "Visuais Personalizados parte 2",
          "Gráficos de Funil e Dispersão",
          "Gráficos de Mapa",
          "Gráfico de Indicador e KPI",
          "Efeito Visual Novel",
          "Interações entre Visuais",
          "Performance Analyzer"
        ],
        "Projeto Final": [
          "Projeto Final Parte 1",
          "Projeto Final Parte 2",
          "Projeto Final Parte 3",
          "Projeto Final Parte 4",
          "Projeto Final Parte 5",
          "Projeto Final Parte 6"
        ]
      },
      "requirements": [
        "Sem pre requisitos"
      ],
      "description": "Sabia que o Microsoft Power BI é a ferramenta de Business Intelligence mais usada no mundo, e considerada a top 1 pela Gartner consultoria. Hoje é requisito quase que obrigatório para quem quer trabalhar com análise de dados, devido à sua fácil implementação nas empresas e curva de aprendizado rápida que permite integração com diversas fontes de dados para construir Dashboards incríveis sem escrever 1 linha de código.\nO curso ensina desde conceitos básicos até avançados, passando pelos principais pontos da ferramenta e dando toda a base que alguém precisa saber para executar suas próprias análises e construir dashboards profissionais.\nCom 10 horas de duração, o curso é apresentado por um especialista certificado da Microsoft e profissional de BI com consultoria e treinamentos in-company fornecidos a diversas empresas.\nAprenda de forma prática, com dicas de uso no dia a dia, e com quem já tem certificação reconhecida pela Microsoft, vá desde a instalação do  software, importação de dados, tratamento e construção de ETLs até a construção de belas visualizações e dashboards profissionais.\nAo final do curso é proposto um projeto final para colocar em prática tudo que foi ensinado e fixar seus conhecimentos.\nO Power BI Desktop é 100% gratuito e possui curva de aprendizado muito baixa, que pode ser uma ótima forma de alavancar sua carreira.\n\n\n-------\n\n\nO curso completo de Power BI, do básico ao avançado em vídeo aulas passo a passo. Aqui você vai aprender as principais ferramentas do Power BI para não só criar dashboards e relatórios dinâmicos, mas também conseguir analisar milhares de informações de forma simples e intuitiva.\nNesse curso vamos começar do zero, desde a instalação do Power BI no seu computador e te levar passo a passo ao nível avançado, ensinando todas as ferramentas que você precisa para usar todo o potencial do Power BI para criar relatórios intuitivos e impressionantes, com gráficos, indicadores, mapas e muito mais!\nEsse curso é 100% prático, o que significa que você vai estar o tempo todo aplicando e exercitando em cada aula, para você aprender como fazer exatamente o que desenvolvemos no curso no seu computador e em qualquer caso que tenha que resolver na sua vida profissional.\nO Power BI está se tornando uma das ferramentas mais importantes do mercado de trabalho e se você quer se destacar, esse pode ser um grande diferencial na sua carreira.\n\n\nPara quem é este curso:\nSe você quer um diferencial na sua carreira, esse curso é para você\nSe você sabe que é importante se desenvolver nas mais novas ferramentas do mercado de trabalho, esse curso é para você\nSe você quer aprender Power BI, mesmo que não saiba nada ou que já tenha aprendido alguma coisa, esse curso é para você\nSe você quer aprender a analisar dados de forma simples, intuitiva e visual, esse curso é para você\nSe você quer aprender a usar o potencial do Business Intelligence para os seus desafios, esse curso é para você",
      "target_audience": [
        "Analistas que querem melhorar suas habilidades",
        "Iniciantes que querem começar em Data Science, Business Intelligence ou Analytics",
        "Desenvolvedores que querem entrar para a área de dados",
        "Gestores que precisam acompanhar melhor os dados gerados no trabalho"
      ]
    },
    {
      "title": "Curso Completo en Ética de la Inteligencia Artificial",
      "url": "https://www.udemy.com/course/programa-avanzado-en-etica-de-la-inteligencia-artificial/",
      "bio": "Construyendo una IA Responsable: Estrategias Éticas y Transparentes para el Éxito Empresarial Para Líderes y Gerentes",
      "objectives": [
        "Comprender los fundamentos de la ética de la IA",
        "Analizar los desafíos éticos específicos de la IA",
        "Desarrollar habilidades para la toma de decisiones éticas en la IA",
        "Tomar decisiones responsables e informadas sobre el desarrollo y la aplicación de la IA."
      ],
      "course_content": {
        "Presentación": [
          "Introducción",
          "Aplicaciones de la inteligencia artificial",
          "Tecnologías diseñadas",
          "Estructura del curso"
        ],
        "Regalos de bienvenida": [
          "10 Premisas de la Ética en la Inteligencia Artificial"
        ],
        "Módulo 1 | Introducción al estudio de la ética de la inteligencia artificial": [
          "Los inicios de la inteligencia artificial",
          "Los orígenes de la inteligencia artificial",
          "Definiciones de la inteligencia artificial",
          "Conferencia de 1956",
          "Categorías de las definiciones de la inteligencia artificial",
          "Inteligencia artificial e inteligencia humana",
          "Objetivos de la definición de la inteligencia artificial",
          "Neurociencia computacional y su relación con los objetivos de la IA",
          "El gran debate de la inteligencia artificial",
          "Inteligencia artificial, autonomía y ética",
          "Tipos de sistemas inteligentes",
          "Relevancia ética de sistemas débiles y fuertes",
          "Aplicaciones de la inteligencia artificial y retos éticos",
          "Desarrollos al margen de la ética de la inteligencia artificial",
          "Beneficios de la inteligencia artificial",
          "Niveles de uso de la inteligencia artificial en las empresas",
          "Las aplicaciones dotadas de inteligencia artificial",
          "Otros riesgos de la inteligencia artificial",
          "Tipos de riesgos",
          "Reflexiones de la inteligencia artificial",
          "Ética del diseño de la inteligencia artificial",
          "Principios éticos del diseño de la inteligencia artificial",
          "Principios de la inteligencia artificial",
          "Preocupación por el diseño de la inteligencia artificial",
          "Métodos técnicos de la inteligencia artificial",
          "Métodos no técnicos de la inteligencia artificial",
          "Conclusiones"
        ],
        "Módulo 2 | Aproximaciones éticas a la inteligencia artificial": [
          "Aproximaciones éticas",
          "Definición importante a considerar de la inteligencia artificial",
          "Niveles de inteligencia artificial",
          "Valores que promueve la inteligencia artificial",
          "Principios y valores propuestos por la inteligencia artificial"
        ],
        "Módulo 3 | Actualidades de la inteligencia artificial con la ética": [
          "Actualidad",
          "¿Hacia dónde se dirige la inteligencia artificial?",
          "Conclusiones"
        ],
        "Módulo 4 | Implicaciones éticas": [
          "Implicaciones de la evolución histórica de la IA e implicaciones éticas inicial",
          "Desarrollo contemporáneo de la inteligencia artificial",
          "Nuevas implicaciones éticas de la inteligencia artificial",
          "Normativas ética de la inteligencia artificial en Europa"
        ],
        "Módulo 5 | Introducción a la IA Explicable y Transparente": [
          "Introducción a la IA Explicable y Transparente",
          "Bienvenida y objetivos del módulo",
          "¿Por qué es importante para tu organización?",
          "¿Qué es la IA y por qué está en todas partes?",
          "La IA y las organizaciones"
        ],
        "Módulo 6 | Módulo 2 Principios de la Inteligencia Artificial": [
          "Bienvenido al módulo",
          "El desafío de la \"caja negra\": ¿Por qué necesitamos transparencia?",
          "¿Qué hace que un sistema de IA sea explicable?",
          "Transparencia en los datos"
        ],
        "Módulo 7 | Ejemplos a considerar": [
          "Bienvenido al módulo",
          "Transición decisiva hacia la acción",
          "Marco de la IA",
          "Herramientas y tecnologías para IA explicable"
        ]
      },
      "requirements": [
        "No se necesita experiencia previa"
      ],
      "description": "La ética en inteligencia artificial se ha vuelto un tema crucial en la era digital. La búsqueda de un uso responsable y justo de estas tecnologías es fundamental para garantizar que la IA beneficie a la sociedad en su conjunto. Esto implica abordar cuestiones como la privacidad, la equidad, la transparencia y la responsabilidad.\nUno de los mayores desafíos es el sesgo algorítmico. Los sistemas de IA pueden perpetuar y amplificar los prejuicios presentes en los datos con los que son entrenados. Esto puede llevar a decisiones injustas en áreas como la contratación, la justicia penal o el reconocimiento facial.\nLa transparencia en los sistemas de IA es esencial. Las decisiones tomadas por estos sistemas deben ser comprensibles para las personas afectadas. La falta de transparencia puede erosionar la confianza en estas tecnologías y dificultar la detección y corrección de errores.\nLos desarrolladores y las empresas tienen la responsabilidad de garantizar que los sistemas de IA se utilicen de manera ética y que se tomen medidas para mitigar los riesgos. Esto incluye la implementación de marcos éticos y la realización de auditorías para detectar y corregir sesgos.\nLa ética en inteligencia artificial es un campo en constante evolución. A medida que las tecnologías avanzan, surgirán nuevos desafíos y preguntas. Es crucial que la sociedad, los gobiernos y las empresas trabajen juntos para establecer normas y estándares que garanticen un desarrollo ético de la IA.",
      "target_audience": [
        "CEOs, gerentes y líderes de empresas que utilizan o desarrollan tecnologías de IA.",
        "Responsables de la elaboración de políticas y regulaciones relacionadas con la IA.",
        "Activistas y líderes de opinión que trabajan en temas relacionados con la ética y la responsabilidad de la IA.",
        "Aquellos que trabajan en el desarrollo de nuevas tecnologías de IA, algoritmos y aplicaciones."
      ]
    },
    {
      "title": "Fundamentos de MLOps (Machine Learning Operations) Hands On",
      "url": "https://www.udemy.com/course/fundamentos-de-mlops-machine-learning-operations-hands-on/",
      "bio": "Curso práctico y aplicado de MLOps con MLFlow, Scikit-learn, CI/CD, Pycaret, FastAPI, Gradio, SHAP, Monitorización",
      "objectives": [
        "Implantación de MLOps de extremo a extremo",
        "Model serving mediante el desarrollo de una aplicaciones web con Gradio",
        "Model serving mediante el desarrollo de APIs con FastAPI",
        "Versionado de modelos con MLFlow",
        "Interpretabilidad de modelos y deriva de datos",
        "Automatización del ciclo de vida del modelo con Pycaret",
        "Toolbox completo de MLOps",
        "Seguimiento de experimentos y registro de modelos con MLFlow",
        "Puesta en producción de modelos de Machine Learning",
        "Niveles de implantación del MLOps"
      ],
      "course_content": {
        "Introducción al curso": [
          "Como aprovechar al máximo el curso",
          "Material del curso"
        ],
        "Retos y evolución del Machine Learning": [
          "Introducción al Machine Learning",
          "Beneficios del Machine Learning",
          "Fundamentos del MLOps",
          "Fundamentos de DevOps y DataOps"
        ],
        "Fundamentos de MLOps": [
          "Problemas que resuelve el MLOps",
          "Componentes del MLOps",
          "Caja de herramientas de MLOps"
        ],
        "Etapas del MLOps": [
          "Etapas del MLOps"
        ],
        "Fase 1 de MLOps: Diseño de la solución": [
          "Diseño e implementación de Volere"
        ],
        "Fase 2 de MLOps: Automatización del ciclo del modelo de ML": [
          "Fundamentos del AutoML",
          "Desarrollo de un modelo de principio a fin con Pycaret",
          "EDA y Preprocesamiento avanzado con Pycaret",
          "Desarrollo de modelos avanzados (XGBoost, CatBoost, LightGBM) con Pycaret",
          "Despliegue en producción con Pycaret"
        ],
        "Fase 2 de MLOps: Registro y versionado del modelo": [
          "Registro y versionado de modelos con MLFlow",
          "Registro de un modelo de Scikit-Learn con MLFlow",
          "Registro del modelo de Pycaret con MLFlow"
        ],
        "Interpretabilidad de modelos": [
          "Fundamentos de interpretabilidad con SHAP",
          "Interpretando modelos de Scikit Learn con SHAP",
          "Interpretando modelos con SHAP en Pycaret"
        ],
        "Puesta en producción de modelos": [
          "Puesta en Producción de Modelos"
        ],
        "Fase 3 de MLOps: Model serving a través de APIs": [
          "Fundamentos de las APIs y FastAPI",
          "Funciones básicas, métodos y parámetros en FastAPI",
          "Método POST, Documentación Swagger y Pydantic en FastAPI",
          "Desarrollo de API para modelo de sickit-learn con FastAPI",
          "Desarrollo automatizado de la API con Pycaret"
        ]
      },
      "requirements": [
        "Conocimientos básicos de Python"
      ],
      "description": "Si estás buscando un curso práctico, conciso y aplicado para aprender las tecnologías de MLOps, has venido al lugar correcto.\nSegún una encuesta de Algorithmia, el 85% de los proyectos de Machine Learning no llegan a producción. Además, el mercado de MLOps no para de crecer. Se estimó en $23,2 mil millones para el 2019 y se proyecta que alcance los $126 mil millones para 2025. Por ello, el formarte en MLOps te dará numerosas oportunidades laborales y profesionales.\n\n\nEste curso está diseñado para aprender todo lo relacionado con MLOps, desde el desarrollo, registro y versionado de modelos hasta la monitorización, CI/CD, model serving y puesta en producción mediante APIs y aplicaciones web.\n\n\nCon la formación teórica, las guías de estudio descargables, los ejercicios prácticos y los laboratorios aplicados a casos de uso reales este es el único curso que necesitarás para aprender a implementar un ciclo completo de MLOps. Para ello, te guiaremos a través de las competencias de MLOps, compartiendo explicaciones claras y útiles consejos profesionales.\n\n\n¿Qué incluye el curso?\n\n\nConceptos básicos y fundamentos de MLOps. Desafíos en la gestión tradicional del ciclo de vida del ML. Cómo MLOps aborda los problemas de subir a producción un modelo\nNiveles de implantación del MLOps\nToolbox completo de MLOps. Aprenderemos algunas de las herramientas más novedosas de MLOps.\nSeguimiento de experimentos y registro de modelos con MLFlow.\nAutomatización del ciclo de vida del modelo con Pycaret. Pycaret permite automatizar y facilitar gran parte del ciclo de MLOps, como el versionado de modelos, entrenamiento, evaluación y despliegue de modelos.\nInterpretabilidad de modelos y deriva de datos.\nVersionado de modelos\nPuesta en producción de modelos.\nDesarrollo de APIs con FastAPI. Aprenderemos a desarrollar una API para que podamos integrar nuestro modelo de ML en herramientas o software empresariales.\nDesarrollo de una aplicaciones web con Gradio. Aprenderemos a desarrollar una aplicación web para que cualquier usuario de negocio pueda hacer uso del modelo.\n\n\nÚnete hoy y obtén acceso inmediato y de por vida a:\n• Guía de formación de MLOps (e-book en PDF)\n• Archivos, códigos y recursos descargables\n• Laboratorios aplicados a casos de uso reales\n• Ejercicios prácticos y cuestionarios\n• Recursos como: Cheatsheets y resúmenes\n• Soporte experto 1 a 1\n• Foro de preguntas y respuestas del curso\n• 30 días de garantía de devolución de dinero\n\n\nSi estás listo para mejorar sus habilidades de MLOps, aumentar tus oportunidades laborales y convertirte en un profesional en ciencia de datos, te esperamos.",
      "target_audience": [
        "Ingenieros de Machine Learning y científicos de datos interesados en MLOps",
        "Profesionales que deseen implementar modelos de Machine Lerning en producción",
        "Cualquier persona interesada en implementar MLOps en sus proyectos",
        "Cualquier persona interesada interesada en desarrollar un proyecto de extremo a extremo de MLOps"
      ]
    },
    {
      "title": "Spark mit Databricks in AWS für Data Science/Engineering",
      "url": "https://www.udemy.com/course/spark-mit-databricks-in-aws-fur-data-scienceengineering/",
      "bio": "Lerne, wie Du mit PySpark und SQL in Spark und Databricks Data Science/Engineering Aufgaben in AWS lösen kannst.",
      "objectives": [
        "Verstehe die Architektur von Apache Spark und lerne die Grundlagen zur Apache Spark Programmierung.",
        "Lerne, wie mit Hilfe der Databricks-Platform Spark-Applikationen in Python und SQL auf optimierten und gemanagten Spark-Clustern in der AWS Cloud ausgeführt werden können.",
        "Du wirst in der Lage sein die für Data Science/Engineering wichtigsten Spark APIs praktisch anzuwenden - DataFrames, Datasets, Machine Learning und Streaming haben.",
        "Du wirst in der Lage sein Spark-Cluster mit Databricks in der AWS Cloud einzurichten, auf denen du dann interaktive Notebooks, Dashboards und Jobs laufen lässt.",
        "Lerne praktisch wie mit Databricks Delta Lake Anwendungen wie klassische DWH / ETL Aufgaben mit SCD1/2 umzusetzen oder ein Data Lake aufzubauen ist.",
        "Du wirst fähig sein verschiedene Clouddienste wie Amazon Redshift oder AWS Glue mit der Databricks Plattform zu integrieren."
      ],
      "course_content": {
        "Einleitung": [
          "Einleitung"
        ],
        "Databricks Einführung": [
          "Einführung in die Databricks Plattform",
          "Databricks Community Edition [Einrichtung]",
          "Erste Schritte mit Databricks",
          "Bewertung"
        ],
        "Apache Spark Einführung": [
          "Einführung in Spark",
          "Spark Session",
          "Spark RDD",
          "Erstellung von RDDs [Übung]",
          "Architektur einer Spark Applikation",
          "Spark RDD Operationen",
          "Spark RDD Operationen [Übung]",
          "DAG"
        ],
        "Apache Spark mit Databricks": [
          "Spark mit Databricks Kapitelüberblick",
          "Spark DataFrames",
          "Spark DataFrames [Übung]",
          "Spark Datasets",
          "Spark Datasets [Übung]",
          "Spark Machine Learning",
          "Spark Machine Learning [Übung]",
          "Spark Structured Streaming",
          "Spark Structured Streaming [Übung]",
          "Databricks Dateisystem",
          "Databricks Dateisystem [Übung]",
          "Databricks Bibliotheken",
          "Databricks Bibliotheken [Übung]",
          "Apache Spark Dokumentation",
          "Databricks Dokumentation",
          "Databricks Magic-Befehle",
          "Übungsaufgabe - DataFrame Fussball Bundesliga [Aufgabenstellung]",
          "Übungsaufgabe - DataFrame Fussball Bundesliga Teil 1 [Lösung]",
          "Übungsaufgabe - DataFrame Fussball Bundesliga Teil 2 [Lösung]"
        ],
        "Databricks in AWS - Deployment, Einrichtung und Administration": [
          "Databricks Administration Überblick",
          "Databricks Account Owner",
          "Databricks Admin",
          "AWS Admin",
          "Databricks Abos",
          "Databricks mit AWS Access Keys [Einrichtung]",
          "AWS Kontokonfiguration Cross-Account Role [Einrichtung]"
        ],
        "Databricks in AWS - Anwendung": [
          "Databricks Cluster Überblick",
          "Databricks All-Purpose Cluster - Konfiguration",
          "Databricks All-Purpose Cluster - Erstellung",
          "Databricks All-Purpose Cluster - Terminierung",
          "Databricks Pools",
          "Sicherer Zugriff auf S3 Buckets mit Instanzprofil",
          "Mount S3 Bucket mit Instanzprofil",
          "Databricks Widgets [Übung]",
          "Databricks Dashboards [Übung]",
          "Databricks Dashboard Scheduling",
          "Databricks Jobs",
          "Databricks Jobs [Übung]",
          "Übungsaufgabe - Dashboard Fussball Bundesliga [Aufgabenstellung]",
          "Übungsaufgabe - Dashboard Fussball Bundesliga [Lösung]"
        ],
        "Databricks Delta Lake": [
          "Batch Verarbeitung von Delta Lake Tabellen",
          "Batch Verarbeitung von Delta Lake Tabellen Teil1 [Übung]",
          "Batch Verarbeitung von Delta Lake Tabellen Teil2 [Übung]",
          "Batch Verarbeitung von Delta Lake Tabellen Teil3 [Übung]",
          "Batch Verarbeitung von Delta Lake Tabellen Teil4 [Übung]",
          "Batch Verarbeitung von Delta Lake Tabellen Teil5 [Übung]",
          "Streaming von Delta Lake Tabellen",
          "Streaming von Delta Lake Tabellen Teil1 [Übung]",
          "Streaming von Delta Lake Tabellen Teil2 [Übung]",
          "Deletes, Updates und Merges von Delta Lake Tabellen",
          "Deletes, Updates und Merges von Delta Lake Tabellen Teil1 [Übung]",
          "Deletes, Updates und Merges von Delta Lake Tabellen Teil2 [Übung]",
          "Utilities von Delta Lake Tabellen",
          "Utilities von Delta Lake Tabellen Teil1 [Übung]",
          "Utilities von Delta Lake Tabellen Teil2 [Übung]",
          "Constraints von Delta Lake Tabellen",
          "Constraints von Delta Lake Tabellen [Übung]",
          "Kontrolle paralleler Operationen",
          "Delta Engine",
          "Übungsaufgabe - SCD1 - SQL",
          "Übungsaufgabe - SCD1 - Python - Aufgabenstellung",
          "Übungsaufgabe - SCD1 - Python - Lösung",
          "Übungsaufgabe - SCD2 - Aufgabenstellung",
          "Übungsaufgabe - SCD2 - Lösung"
        ],
        "Databricks - AWS Integrationen": [
          "Amazon Redshift als Datenquelle",
          "Amazon Redshift als Quelle [Praktischer Teil]",
          "AWS Glue als Metastore",
          "AWS Glue als Metastore [Praktischer Teil]"
        ],
        "Abschluss": [
          "Abschluss"
        ]
      },
      "requirements": [
        "Grundkenntnisse in Python und SQL",
        "Zugriff auf ein AWS Konto mit Adminrechten"
      ],
      "description": "Databricks wurde von den Apache Spark Schöpfern gegründet. Databricks stellt eine webbasierte Plattform für Datenanalysen mit Apache Spark bereit, die Data Scientists, Data Engineers, Machine-Learning Engineers und Data Analysts zusammenbringt und ist mit der AWS oder Azure Cloud integrierbar.\nDurch die zusätzlichen Features, die Databricks mitbringt sind produktive und skalierbare Data Science und Data Engineering möglich. Die Features sind eine optimierte Performance auf Apache Spark, zuverlässige und leistungsstarke Data Lakes mit Delta Lake, Interaktive Data Science und Zusammenarbeit zwischen den unterschiedlichen Beteiligten wie Data Scientists, Data Engineers, Machine-Learning Engineers usw..\nMit Databricks sind Jobs und Workflows in Produktivumgebung möglich, für die Anforderungen hinsichtlich Unternemenssicherheit ist durch End-to-End Datenschutz und Compliance gesorgt, bekannte und geläufige Tools sind ohne Probleme integrierbar und es wird ein Experten-Support durch die Apache Spark Schöpfer gegeben.\n\n\nNach erfolgreichem Abschluss des Kurses wirst du in der Lage sein mit Databricks interaktive Data Science und Data Engineering mit hoher Unternehmenssicherheit, optimierter Performance und Zuverlässigkeit auf Produktionssniveau zu betreiben und so Big Data Projekte zielführend zur Mehrwertgenerierung foranzutreiben.\n\n\nWas erwartet dich in dem Kurs?\nDu bekommst über 80 theoretische und praktische Lektionen sowie Übungsaufgaben – was mehr als 12 Stunden Videomaterial umfasst.\nDich erwarten Meilensteinprojekte mit echten Daten und Databricks-Notebooks sowohl mit Vorlagen als auch Lösungen, die du herunterladen kannst.\nDu erhältst Zugang zum Online Q&A Forum, wo entweder andere Kursteilnehmer oder ich deine Fragen beantworten werden.\nUnd schließlich erhältst du auch ein Zertifikat bei erfolgreichem Kursabschluss, das sich gut in deinem Lebenslauf macht.\n\n\nAchtung!\nDieser Kurs überschneidet sich mit meinem Kurs \"Apache Spark mit Databricks - Crashkurs\". Dieser Kurs enthält die sowohl die Lektionen des Crashkurses und noch umfangreiche weitere Lektionen für Databricks in der AWS Cloud.\n\n\n30 Tage Geld-zurück-Garantie!\nWenn du mit dem Kurs schließlich nicht zufrieden bist, kannst du ihn gerne ohne Probleme innerhalb von 30 Tagen zurückgeben und du bekommst dein Geld wieder.\n\n\nFür wen ist dieser Kurs eher nicht geeignet?\nAlle, die PySpark, Databricks oder AWS von A-Z lernen möchten – also alle Aspekte von hinten bis vorne wissen möchten – werden in diesem Kurs höchstwahrscheinlich nicht auf ihre Kosten kommen.\nDer Ansatz, der hier genommen wird ist, dass wir notwendige Spark, Databricks und AWS Features lernen werden, um schnell und mit praktischem Fokus Mehrwert durch Projekte im Data Engineering und Data Science Bereich zu generieren.",
      "target_audience": [
        "Data Engineers, Data Scientists, Machine-Learning Engineers mit und ohne Vorkenntnisses in Apache Spark",
        "Informatiker, Python-Entwickler, DWH-Entwickler mit geringen Vorkenntnisses in Apache Spark und Interesse an Data Engineering/Data Science",
        "Jeder, der Apache Spark mit Databricks lernen möchte"
      ]
    },
    {
      "title": "Curso R Programming: Manipulación Avanzada de datos",
      "url": "https://www.udemy.com/course/curso-r-programming-manipulacion-avanzada-de-datos/",
      "bio": "Jorge, experto en R, te enseña paso a paso a transformar, limpiar y combinar datos como un profesional.",
      "objectives": [
        "Comprenderán los fundamentos de la manipulación de datos en R y su relevancia en análisis de datos.",
        "Compararán y aplicarán diferentes enfoques: Base R, Tidyverse y data.table.",
        "Utilizarán funciones como select(), filter(), mutate(), summarise(), pivot_longer() y pivot_wider() para transformar datasets.",
        "Integrarán y combinarán múltiples fuentes de datos usando joins con dplyr y data.table.",
        "Dominarán técnicas de limpieza de datos, tratamiento de valores nulos y eliminación de valores atípicos.",
        "Aplicarán conocimientos avanzados como manipulación de fechas, textos y preparación de datos para modelado predictivo."
      ],
      "course_content": {
        "Bienvenida al curso": [
          "Bienvenido a DataBoosters",
          "Presentación del instructor",
          "Presentacion del curso",
          "Archivos descargables"
        ],
        "Fundamentos de la Manipulación de Datos en R": [
          "¿Qué es la manipulación de datos en R?",
          "Base R vs. Tidyverse vs. data.table",
          "Instalación y configuración de librerías",
          "Exploración inicial de datos",
          "Importación de datos desde múltiples fuentes"
        ],
        "Manipulación de Datos con dplyr": [
          "Selección de columnas con select()",
          "Renombrar y reordenar columnas con rename() y relocate()",
          "Creación de nuevas variables con mutate()",
          "Condiciones y reglas con case_when()",
          "Filtrado de datos con filter(), between(), near()",
          "Ordenamiento con arrange() y ranking con dense_rank()",
          "Agrupaciones avanzadas con group_by() y summarise()",
          "Funciones avanzadas con rowwise(), map(), y nest()"
        ],
        "Transformaciones Avanzadas de Datos": [
          "Pivoteo de datos con pivot_longer()",
          "Conversión de datos con pivot_wider()",
          "Transformación de valores faltantes con replace_na(), drop_na()",
          "Separación y unión de columnas con separate() y unite()",
          "Eliminación de valores atípicos con boxplot.stats() y z-score"
        ],
        "Integración de Datos con Joins": [
          "Introducción a Joins: Conceptos y Casos de Uso",
          "Tipos de Joins en dplyr: inner, left, right, full",
          "Optimización de Joins con data.table y merge()",
          "Casos prácticos de integración de datos con Joins"
        ],
        "Manipulación Eficiente con data.table": [
          "Introducción a data.table: diferencias con dplyr",
          "Selección y filtrado de datos con data.table",
          "Agrupaciones avanzadas con .SD y .N",
          "Optimización con setkey() y setorder()",
          "Exportación rápida con fwrite()"
        ],
        "Manipulación de Texto": [
          "Uso de stringr para manipulación de texto",
          "Búsqueda con expresiones regulares (regex)"
        ],
        "Manipulación de Fechas": [
          "Conversión de fechas y extracción de componentes",
          "Operaciones con fechas: sumas y restas"
        ],
        "Casos Prácticos y Proyecto Final": [
          "Caso práctico 1: Transformación de datos financieros",
          "Caso práctico 2: Integración de datos de redes sociales",
          "Análisis y validación de datos antes del modelado",
          "Proyecto Final: Preparación de un dataset para Machine Learning"
        ]
      },
      "requirements": [
        "No se requieren conocimientos previos de R o estadística.",
        "Idealmente, tener nociones básicas de programación o interés en análisis de datos.",
        "Tener instalado R y RStudio (explicado en el curso).",
        "Ganas de aprender y practicar con datasets reales."
      ],
      "description": "En un mundo donde los datos son el nuevo petróleo, saber manipularlos correctamente es una de las habilidades más valiosas. Este curso te ofrece una formación integral y práctica en manipulación de datos con R, desde los fundamentos hasta técnicas avanzadas aplicadas a casos reales.\nA lo largo de este curso, aprenderás a transformar, filtrar, ordenar, agrupar y combinar datasets usando herramientas modernas como el Tidyverse (dplyr, tidyr, stringr, lubridate) y la poderosa librería data.table. Compararás estos enfoques con la Base R, entendiendo sus ventajas y cuándo usarlos según tus necesidades.\nTe enseñaré cómo importar datos desde múltiples fuentes (CSV, JSON, bases de datos SQL), crear nuevas variables, eliminar valores atípicos, trabajar con texto, fechas y preparar datos de forma eficiente para el modelado. Cada lección está pensada para que pongas en práctica lo aprendido con ejemplos claros, ejercicios guiados y casos del mundo real.\nAdemás, integraremos conocimientos en proyectos prácticos como el análisis de datos financieros y la integración de datos de redes sociales, cerrando con la construcción de un pipeline completo de limpieza y transformación para un modelo de Machine Learning.\nEste curso es ideal si buscas un enfoque práctico, estructurado y actualizado para convertirte en un experto en data wrangling con R. ¡No importa si recién comienzas o si ya tienes experiencia en programación!",
      "target_audience": [
        "Estudiantes, profesionales y autodidactas interesados en la ciencia de datos o el análisis estadístico.",
        "Personas que trabajan con grandes volúmenes de información y desean automatizar tareas repetitivas.",
        "Científicos de datos en formación que quieren dominar R como herramienta de manipulación de datos.",
        "Investigadores, analistas y desarrolladores que necesitan preparar datos para proyectos de Machine Learning o visualización."
      ]
    },
    {
      "title": "Matemáticas aplicadas a los Negocios & Economía con ChatGPT",
      "url": "https://www.udemy.com/course/matematicas-aplicadas-a-los-negocios-economia-con-chatgpt/",
      "bio": "Usar la Inteligencia artificial para resolver problemas de negocios y economía",
      "objectives": [
        "Aprender Matemáticas aplicadas a los Negocios",
        "Aprender Matemáticas aplicadas a la Economía",
        "Aprender a usar Matemáticas aplicadas al entorno empresarial",
        "Aprender a usar Inteligencia Artificial a temas de Negocios y Economía",
        "Tener ejemplos soportados en Excel y temas desarrollados en Word",
        "Usar el buscador de Google para hacer operaciones matemáticas aplicadas"
      ],
      "course_content": {
        "Introducción al curso de Matemáticas aplicadas a los negocios y economía": [
          "Visión general del Curso",
          "Evaluación y pregunta sobre el curso",
          "Registrarse en ChatGPT",
          "Operaciones matemáticas en buscador de Google"
        ],
        "Funciones lineales": [
          "Tipografía matemática en Excel (inserción de símbolos)",
          "Explicación coloquial del concepto de función matemática",
          "Concepto de Función en Matemáticas",
          "Concepto de pendiente de una función",
          "Tipos de Funciones Matemáticas",
          "Función lineal"
        ],
        "Funciones no lineales": [
          "Función cuadrática",
          "Número de Euler (e)",
          "Modelo usando el número de Euler (e)",
          "Media Geométrica",
          "Modelo de crecimiento exponencial",
          "Función logarítmica",
          "Función exponencial",
          "Modelo exponencial con ChatGPT"
        ],
        "Conceptos fundamentales de Estadística": [
          "Medidas de tendencia central",
          "Medidas de dispersión",
          "Números índices"
        ],
        "Aplicaciones matemáticas a los negocios": [
          "Modelo de punto de equilibrio y utilidades",
          "Función de Demanda",
          "Función de Oferta",
          "Modelo de Equilibrio: Oferta vs Demanda",
          "Función de Demanda con ChatGPT",
          "Función de Oferta con ChatGPT",
          "Modelo de Equilibrio Oferta vs Demanda con ChatGPT",
          "Modelo equilibrio y utilidades con ChatGPT"
        ],
        "Aplicaciones matemáticas a la Economía": [
          "Modelo de crecimiento aplicado al Índice de Precios de México",
          "Deflactar e Indexar: Ejemplo aplicado a la economía mexicana",
          "Modelo de duplicación aplicado a paises (empresas)",
          "Modelo de decrecimiento exponencial"
        ],
        "Fin del curso": [
          "Conclusiones y recomendaciones"
        ]
      },
      "requirements": [
        "Tener conocimientos básicos de informática y estar interesado en establecer un negocio"
      ],
      "description": "Este es un curso fascinante porque vamos a aprender aplicar muchos conocimientos matemáticos a temas de negocios y economía. Para ello vamos a utilizar hojas de cálculo de Excel e inteligencia artificial, como ChatGPT, entre otras herramientas.\nMuchos de los conocimientos matemáticos que tenemos no les damos ningún uso. En este curso reactivarás la capacidad de aplicar tus conocimientos de secundaria y la universidad al mundo de los negocios y la economía en forma conjunta.\nEn este curso abordaremos una gran variedad de temas matemáticos y su aplicación a las ciencias económicas, es decir, a la administración y la economía. Temas como función matemáticas aplicados a las empresas, como el punto de equilibrio y utilidades: temas de economía, como inflación y devaluación; temas estadísticos, como las medidas de tendencia central; en fin, las aplicaciones fundamentales que toda personas interesada en los negocios debe comprender.\nLa idea fundamental que subyace en este curso es facilitar a los usuarios el uso de diferentes herramientas matemáticas para hacer análisis y diagnósticos mas profundos y precisos, aspecto que se facilitan con al aprendizaje de las matemáticas.\nEl usuario podrá acceder a todos los ejercicios resueltos en Excel, pero también aprenderá como utilizar diversas herramientas de inteligencia artificial para solucionarlos, como ChatGPT, entras otras técnicas.",
      "target_audience": [
        "Este curso está orientado para aquellas personas que quieran aprender a aplicar las matemáticas en el mundo de los negocios y la economía",
        "Facilitar el aprendizaje de las matemáticas usando Excel e Inteligencia artificial, como ChatGPT",
        "Optimizar el análisis de temas de negocios y economía usando inteligencia artificial"
      ]
    },
    {
      "title": "[실전] PyTorch 딥러닝 모델 만들기:인공신경망 구축",
      "url": "https://www.udemy.com/course/pytorch-c/",
      "bio": "이 강의는 PyTorch를 활용하여 딥러닝의 기초 이론을 학습하며, 주로 컴퓨터 비전과 시퀀스 데이터 처리 방법에 중점을 둡니다. 합성곱 신경망(CNN)과 순환 신경망(RNN)의 이론을 다루며, PyTorch를 활용",
      "objectives": [
        "인공신경망의 원리와 활용 방법을 배울 수 있습니다.",
        "PyTorch로 합성곱 신경망(CNN) 순환신경망(RNN) 모델을 구축할 수 있습니다.",
        "인공신경망: 데이터를 여러 클래스로 분류하는 작업과 데이터와 출력 값 간의 관계를 학습하여 수치적인 예측을 수행할 수 있습니다.",
        "합성곱 신경망(CNN:) 이미지를 특정 클래스로 분류하고, 특정 객체의 위치를 찾아내는 작업을 배울 수 있습니다.",
        "순환 신경망(RNN:) 순차적인 데이터, 시계열 데이터, 자연어 처리 등의 작업하는 방법을 배울 수 있습니다."
      ],
      "course_content": {
        "인공지능과 딥러닝 기본 원리": [
          "1. 인공지능 기본 원리와 역사",
          "2. Pytorch 특징 및 Colab 활용 실습"
        ],
        "머신러닝의 기본개념과 학습 방법": [
          "3. 머신러닝 기본 개념 및 학습 원리",
          "4. 머신러닝에서의 오차측청과 최적화 방법"
        ],
        "데이터처리와 다양한 함수": [
          "5. Loss 함수와 최적화 함수 다루기(+ 실습)",
          "6. 인공신경망 기본 원리 및 활성화 함수 학습",
          "7. 다양한 활성화 함수와 최적화 함수(+ 실습)",
          "8. 데이터에 대해 이해와 인코딩의 필요성 학습",
          "9. PyTorch의 Dataset, PyTorch의 Dataloader 클래스 학습",
          "10. 다양한 데이터 셋 활용 및 Cifar-10, Cifar-100 호출(+ 실습)"
        ],
        "딥러닝 모델 학습 시 나타나는 주요 문제": [
          "1. Overfitting & Underfitting",
          "2. Overfitting & Underfitting(+실습)",
          "3. 컴퓨터 비전 기초 이론"
        ],
        "CNN 구축": [
          "4. CNN 이론: 신경망 구조와 원리 학습, 신경망 응용법 학습",
          "5. CNN 실습: Kernel size, Stride 변경",
          "6. CNN 응용, Blocked layer vs. normal method 비교"
        ],
        "RNN 구축": [
          "7. 순환 신경망 이론, RNN 기초",
          "8. LSTM 이론, LSTM 구조",
          "9. GRU 이론, GRU 구조",
          "10. Vanila RNN 모델 실습, LSTM 실습, GRU 실습"
        ]
      },
      "requirements": [
        "누구나 수강할 수 있습니다."
      ],
      "description": "안녕하세요, ITGO 입니다.\n\n\n본 강의는 PyTorch 딥러닝 기초 이론과 응용: CNN과 RNN 구축 실전입니다.\n\n\n\n\n\n\n본 과정에서는 PyTorch를 통해 딥러닝 기초 이론을 배우고, 컴퓨터 비전 및 시퀀스 데이터 처리 방법을 배웁니다.\n\n\n인공신경망을 이해하고, 합성곱 신경망(CNN) 순환신경망(RNN) 모델을 PyTorch로 실습합니다.\n\n\n\n\n합성곱 신경망(CNN: Convolutional Neural Network)이론과 그에 필요한 기능을 PyTorch로 학습함으로써,\n\n\n이미지에 대한 특징을 추출하고, 그 특징을 기반으로 이미지를 분류하는 작업하는 방법을 배울 수 있습니다.\n\n\n\n\n순환신경망(RNN: Recurrent Neural Network)이론과 그에 필요한 기능을 PyTorch로 학습함으로써,\n\n\n순차적인 데이터, 시계열 데이터, 자연어 처리 등의 작업하는 방법을 배울 수 있습니다.\n\n\n\n\n위 모델을 활용하여 이미지 및 시퀀스 데이터에 특화된 작업을 구축할 수 있으며, 이를 결합하여 더 복잡하고 다양한 문제에 대응할 수 있는 모델도 구성할 수 있습니다.\n\n\n\n\nPyTorch 딥러닝 기초 이론과 응용: CNN과 RNN 구축 실전에 입문해 봅시다~!\n\n\n\n\n그럼 강의에서 만나요 :)",
      "target_audience": [
        "[기초] PyTorch 딥러닝 모델 만들기:인공 지능과 문법 기초' 편 수강자",
        "PyTorch에 기초 지식이 있는 사람",
        "Python에 대한 기본 지식이 있는 사람"
      ]
    },
    {
      "title": "データサイエンス実戦講座［第３回］仮説検定の徹底理解とp値によるリスク対策（後編）",
      "url": "https://www.udemy.com/course/3p-kowrm/",
      "bio": "統計学の中で最もよく使われる仮説検定の原理を理解して、現実の問題解決のための３つのスキル（①アクションプランとリスク対策の立案、➁パラメトリック検定とノンパラメトリック検定の併用、③統計解析ソフトの活用）を手に入れよう。",
      "objectives": [
        "自然現象や社会現象のメカニズムを分析するデータサイエンスの様々な手法について、複数のコースに分けて1つずつ習得していきます。古典的な頻度論の統計学から最新のディープラーニングまで、原理の理解と実務への応用を目指します。",
        "第３回目のコースは前回に引き続いて仮説検定です。統計学のなかでも実務において最もよく使われる手法です。今回のコースではパラメトリックとノンパラメトリックを合わせて8種類の仮説検定手法について、ロジックを解きほぐして分かりやすく説明します。",
        "仮説検定は相反する仮説を立てて頻度の高い方を推定するという手法です。しかし、仮説の真偽については不明であり、頻度の低い事も起こり得ます。仮説の真偽と頻度の高低を掛けた２×２＝４通りのケースについて、検定結果をもとに実戦的なリスク対策を踏まえた意思決定と行動選択の方法を学びます。",
        "仮説検定には、母集団に正規分布などを仮定するパラメトリック検定と、何も仮定しないノンパラメトリック検定があります。統計学の基礎レベルでは前者しか扱わないのが普通ですが、現実には正規分布に従わない現象や、母集団の分布が分からない場合も多々あります。本コースでは問題に応じて両方の手法が使えるように学習します。",
        "ＪＡＳＰというフリーの統計解析ソフトを演習問題で使用します。アムステルダム大学が開発したソフトで、メニューは日本語化されています。仮説検定ではパラメトリックとノンパラメトリックの手法が利用できます。豊富な機能を持ち、ベイズ統計の手法も使えますので、日々の勉学や実務にも役立つスキルを身に着けることができるでしょう。",
        "前回と今回は仮説検定の特集です。パラメトリック検定とノンパラメトリック検定の両方を合わせると手法がとても多くなるため、前編と後編に分けました。今回の後編では２サンプルの検定、分散分析、分割表の検定を対象として、実戦的な演習問題を解きながら、検定結果を実務レベルのアクションプランとリスク対策を立案する能力が養えます。"
      ],
      "course_content": {
        "仮説検定の３つのポイント": [
          "仮説検定を実務レベルの問題解決に役立てるための３つのポイントについて理解します。 １．アクションプランとリスク対策の立案 ２．パラメトリック検定とノンパラメトリ"
        ],
        "6.　２サンプルの代表値の検定": [
          "6-1　２サンプル問題と検定手法の選択",
          "6-2　対応のあるｔ検定",
          "6-3　ウィルコクスン符号付き順位検定",
          "6-4　２サンプルｔ検定",
          "6-5　マン-ホイットニー検定"
        ],
        "7.　２サンプル以上の代表値の検定": [
          "7-1　２サンプル以上の問題と検定手法の選択",
          "7-2　一元配置分散分析",
          "7-3　クラスカル-ウォリス検定"
        ],
        "8.　分割表の検定": [
          "8-1　分割表の問題と検定手法の選択",
          "8-2　適合性の検定",
          "8-3　独立性の検定"
        ],
        "9.　仮説検定のまとめ": [
          "9-1　仮説検定のまとめとp値を使わない検定",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "高校レベルの数学力があれば十分ですが、必須ではありません。コースの到達点は中級レベル以上ですが、初心者でも十分に理解できるところからスタートして、ハードルを徐々に上げながら無理なく越えられるように学習を進めます。",
        "正確を期すために数理モデルは示しますが、直感的な理解と解釈を重視してグラフや図による説明を主体にします。"
      ],
      "description": "データサイエンス実戦講座の第３回のテーマは、前回に続いて仮説検定です。統計学の中でも実務で最もよく使われる手法のひとつで、例えば製品の改良開発が成功か失敗かの二者択一の仮説を立てて、統計学の視点から判定を下します。検定の原理を理解して現実世界の問題解決に活かすためのポイントは次の３つです。\n①アクションプランとリスク対策の立案・・・検定とは仮説の発生頻度の推定であり、仮説の「真偽」と判定の「正誤」は分かりません。問題解決には「真と偽」×「正と誤」＝４つのケースに対するアクションプランとリスク対策が必要で、これらを立案する方法が習得できます。\n➁パラメトリック検定とノンパラメトリック検定の併用・・・現実に起こる社会現象や自然現象のデータは正規分布しているとは限りません。このため、母集団に正規分布などを仮定するパラメトリック検定だけでなく、歪んだ分布や外れ値のある分布に適用できるノンパラメトリック検定も必要で、これらを併用する２段構えの分析力が得られます。\n③統計解析ソフトの活用・・・多くの手法を知っていても使えなければ意味がありません。アムステルダム大学が開発したフリーの統計解析ソフトJASPを駆使して、実戦的な演習問題を通して応用力が身に付きます。\n今回のコース（後編）では２サンプルの問題、２サンプル以上の問題、分割表の問題について、パラメトリックとノンパラメトリックを併せて８種類の検定手法を扱います。\nデータサイエンスといえば機械学習やディープラーニングのさまざまな手法や、注目の生成ＡＩを実現する大規模言語モデルが思い浮かぶでしょう。しかし、その礎となっているのはデータ分析の技術です。それは百年以上も前から自然・社会・人文科学の進歩を支えてきた古典的（頻度論的）統計学であり、かつては異端扱いされながらもビッグデータ時代の訪れとともに蘇ったベイズ統計学です。最新のデータサイエンスを学ぶためには、まず統計学の基礎をしっかり押さえておきましょう。",
      "target_audience": [
        "学業や業務でデータ分析を必要としている方、将来データアナリストを目指す方、データサイエンスに興味のある方であればどなたでも。 データ分析の初心者から学び直しの中級者。"
      ]
    },
    {
      "title": "ゼロから作るAI動画生成講座 Stable Diffusion + mov2mov【初心者向け生成AI入門コース】",
      "url": "https://www.udemy.com/course/ai-stable-diffusion-mov2mov/",
      "bio": "AI動画をStable Diffusionで生成する方法を学べます。人の動画を使わないオリジナルAI動画が作れます。応用すれば自分好みのAI動画も生成可能。ネットにつながるPCがあればできます。初心者向けにわかりやすく丁寧に解説します。",
      "objectives": [
        "Stable DiffusionやAI動画について基礎的な知識を学べます。",
        "自分の動画を使ったオリジナルのAI動画生成方法を学べます。",
        "Stable Diffusionをクラウド上で立ち上げる環境の構築方法について学べます。",
        "拡張機能mov2mov2の導入方法、上手に生成する設定について学べます。",
        "Stable Diffusion、拡張方法、画像や動画生成の基礎的な使い方が学べます。",
        "自分好みの顔やモデルのAI動画を作れる応用方法が学べます。"
      ],
      "course_content": {
        "Stable Diffusionを利用したAI動画生成講座": [
          "はじめに",
          "Stable Diffusionとは",
          "この講座の概要",
          "Paperspaceの登録",
          "projectの作成",
          "projectの実行",
          "動画の作成",
          "拡張機能のインストール",
          "Stable Diffusionの設定",
          "プロンプトについて",
          "mov2movの実行"
        ]
      },
      "requirements": [
        "プログラミング知識、経験、技術的な知識は不要です。",
        "初心者向けにインストール手順などわかりやすく説明しています。",
        "入門コースの為、専門的な詳しい解説はありません。",
        "ネットにつながるパソコンがあれば大丈夫です。"
      ],
      "description": "Stable Diffusionを使ったリアルなAI動画を生成する方法について学ぶことができます。ネットにつながるパソコンがあれば生成できるクラウドのGPUを利用した方法です。Stable Diffusionや生成AIに興味がある方、開発経験やスキルのない初心者の方、これからAIについて学習したい方向けに１から丁寧に解説している入門コースです。このAI動画の作成方法を応用すれば、自分好みの動画を生成することができます。",
      "target_audience": [
        "リアルなAI動画を生成したい方",
        "Stable Diffusionを使った生成AIに興味がある方",
        "自分の容姿を変えた動画を作成したい方",
        "クラウド上でStable Diffusionを起動して軽いPCで実行したい方",
        "AI動画生成を応用して自分好みのモデルや顔でAI動画を作りたい方",
        "AIや機械学習を用いた新しい生成技術を体験したい初心者の方",
        "人の動画を利用しないAI動画の作成方法を学びたい方"
      ]
    },
    {
      "title": "(Ken Cen出品)部署Machine Learning模型-使用Python,FastAPI,Docker, EC2",
      "url": "https://www.udemy.com/course/machine-learning-pythonpipeline-fastapidocker-ec2/",
      "bio": "Python， Machine learning，Model Training，Data analysis，Pipeline，FastAPI，Docker，Amazon EC2",
      "objectives": [
        "了解從機器學習模型Machine Learning Model開發到部署的整個過程",
        "了解如何用FastAPI開發高效的Web API",
        "了解如何使用Docker封裝FastAPI",
        "了解如何將封裝的API放到AWS EC2上實現部署"
      ],
      "course_content": {
        "課程準備": [
          "課程需要工具"
        ],
        "機器學習流程 -數據分析，特徵工程，特徵提取，模型訓練": [
          "實例1 - 加州房價數據分析 - California housing data analysis",
          "Google Colab 使用速查表Cheatsheet",
          "實例1 - 加州房價-特徵值關係分析",
          "實例1 - 加州房價-特徵工程Feature Engneering",
          "實例1 - 加州房價-模型預處理&訓練 Model Preprocessing & Model Training",
          "實例1 - 加州房價-模型評估 Model Scoring & Evaluation"
        ],
        "機器學習流水線 - Machine Learning Pipeline": [
          "Pipeline管道介紹",
          "實例2- 製作第一條Pipeline管道",
          "實例3 - 兩個Transformer+1個算法的Pipeline",
          "實例4- ColumnTransformers",
          "什麼是序列化？如何使用Pickle",
          "如何使用Joblib保存已經訓練的模型"
        ],
        "FastAPI構建API接口": [
          "為什麼要學習製作API",
          "創建第一個FastAPI程式 - 並了解Requirements與Env與Uvicorn",
          "FastAPI如何實現數據驗證與可選項",
          "路徑參數與Get-Put-Delete",
          "Response Model 設定返回類型",
          "Query Parameters 查詢參數",
          "Middleware 中間軟體"
        ],
        "API預測文章類型": [
          "模型訓練-文字特徵提取",
          "文章特徵提取-API文件上傳",
          "文章特徵提取-如何在API運行模型預測信息",
          "疑問集合"
        ],
        "Docker": [
          "什麼是Docker",
          "第一次進入Container 容器 & Images 映像",
          "如何創建自己的Container和Image",
          "如何進入交互模式",
          "如何移除Container和Image",
          "什麼是Docker-compose"
        ],
        "亞馬遜EC2伺服器部署": [
          "將FastAPI打包至Docker",
          "AWS伺服器設定",
          "AWS EC2端部署Docker"
        ]
      },
      "requirements": [
        "需要一定的Python和相關framework的知識"
      ],
      "description": "嘿！你有沒有想過\n有一天你會把一個訓練好的人工智能模型部署到實際的伺服器上嗎？\n如果你曾經有過這樣的想法，那麼現在是你學習的大好時機！\n\n\n我們的課程將教你從零開始\n一步步地學會如何部署人工智能模型\n完全不需要有先前的經驗。\n\n\n首先\n我們將利用 Google Colab 平台進行模型訓練\n利用 Pipeline 技術實現模型自動化訓練。\n\n\nPipeline 是一個非常強大的工具\n它可以幫助我們將整個訓練過程連接在一起\n讓整個流程更加順暢和高效。\n\n\n接著\n我們將使用 FastAPI 框架來建立一個簡單而強大的 API\n用於接收用戶提交的數據並對其進行預測\n\n\n這樣一來\n你就可以輕鬆地將你的人工智能模型應用到真實的應用場景中\n並為用戶提供智能化的服務。\n\n\n但這還不是全部！\n我們還將運用 Docker 技術來製作 API 的 image 和 container\n\n\n這樣你就可以更加方便地部署你的 API 到任何一台伺服器上\n無需擔心環境配置和依賴問題。\n\n\n最後\n我們將把你訓練好的人工智能模型和 Docker 容器\n一同部署到亞馬遜的 EC2 伺服器上\n\n\n讓你的模型可以隨時隨地提供服務\n無論是面對數據量大\n還是用戶量多都能輕鬆應對。\n\n\n加入Ken Cen的學員隊伍\n讓我們一起學習人工智能吧！",
      "target_audience": [
        "想學習如何訓練機器學習Machine Learning Model",
        "想學習如何實現Machine Learning Pipeline",
        "想學習如何使用FastAPI接入訓練好的ML模型",
        "想學習如何使用Docker讓API用於各種操作系統和環境",
        "想學習如何在AWS EC2上部署Docker image映像"
      ]
    },
    {
      "title": "Power BI结合业务数据分析实战课",
      "url": "https://www.udemy.com/course/power-bi-e/",
      "bio": "从入门到进阶的Power BI数据分析实战课，与电商、广告和用增业务紧密结合，教你如何在实际业务中快速获取、清洗、整合和展示数据，提高工作效率和决策能力。",
      "objectives": [
        "掌握数据分析工具Power BI的核心功能和操作，从数据接入到可视化数据分析应用的各个方面",
        "提高数据获取、清洗、整合和展示的技能和效率，快速地从各种数据源导入、处理和呈现数据",
        "建立数据报表和图表，呈现数据分析的结果和洞察，使用高级可视化操作，增加数据报表的美观性和易读性",
        "提升数据分析的业务健康度，增强数据驱动的决策能力，通过数据分析工具来评估业务状况和发现问题"
      ],
      "course_content": {
        "课程导读": [
          "讲师介绍",
          "课程大纲",
          "引入讲解"
        ],
        "第1章 为什么要分析数据": [
          "课程介绍",
          "引例.",
          "电商业务的业务数据",
          "广告营销业务的业务数据",
          "用户增长业务的业务数据",
          "通过数据分析来识别机会",
          "数据分析的作用",
          "预测趋势与需求",
          "发现客户痛点",
          "竞争分析",
          "制定预算和投资计划",
          "监测业务表现",
          "通过数据分析来规避风险",
          "风险管理与数据分析的关系",
          "数据分析的应用领域",
          "数据分析在风险管理中的作用",
          "通过数据分析来进行问题诊断",
          "数据分析在问题诊断方面的作用",
          "通过数据分析来进行问题诊断的步骤",
          "数据分析从识别问题开始",
          "找到利益相关者",
          "聚焦.",
          "思考如何用数据讲故事",
          "知道你想要什么",
          "回顾之前的发现",
          "构建问题",
          "分析具体案例，找出问题所在",
          "电商业务的数据问题",
          "广告营销业务的数据问题",
          "用户增长业务的数据问题"
        ],
        "第2章 开启数据分析思路": [
          "引例：从结果指标找出过程指标",
          "电商业务的结果指标和过程指标",
          "广告营销业务的结果指标和过程指标",
          "用户增长业务的结果指标和过程指标",
          "学会提问",
          "提问是数据分析的关键步骤",
          "提问帮助确定数据分析目标",
          "提问有助于发现数据集的局限性和数据偏差",
          "提问激发创造性思维和发现新的见解",
          "为什么要熟悉业务模型",
          "熟悉业务模型的方法",
          "宏观分析",
          "微观分析",
          "熟悉业务模型需要了解的关键概念和方法",
          "系统思维",
          "价值链分析",
          "流程图",
          "SWOT分析",
          "数据分析时常用的几种思维模型",
          "结构思维",
          "时间思维",
          "演绎思维",
          "重要性思维",
          "案例分析：在业务中常用的一些业务模型",
          "电商业务：销售漏斗",
          "广告营销业务：广告收入连乘式",
          "用户增长业务：用户留存模型"
        ],
        "第3章 连接Power BI数据源": [
          "Power BI数据源连接到文件",
          "Power BI数据源支持的文件格式",
          "Power BI数据源连接到文件的方式",
          "Power BI数据源连接到文件之前的准备工作",
          "Power BI数据源连接到文件之后的数据处理",
          "Power BI数据源连接到数据库",
          "Power BI数据源支持的数据库",
          "Power BI数据源连接到数据库的步骤",
          "Power BI数据源连接到文件夹",
          "Power BI数据源如何配置和连接到文件夹",
          "Power BI数据源如何解析文件夹数据",
          "Power BI数据源如何配置自动化文件夹数据更新",
          "案例演示：准备原始数据并导入到Power BI",
          "Power BI获取原始数据来源",
          "Power BI预处理数据",
          "导入数据到Power BI",
          "Power BI数据导入数据类型设置",
          "Power BI数据导入数据质量检查",
          "（可选）Power BI数据导入数据的监控"
        ],
        "第4章 Power BI数据基础操作": [
          "Power BI中的数据整理操作",
          "管理列",
          "减少行",
          "排序.",
          "转换.",
          "Power BI中的数据转换操作",
          "表格转换操作",
          "任意列的转换操作",
          "文本型数据的格式化",
          "数字型数据的格式化",
          "日期/时间型数据的格式化",
          "Power BI中的数据表基础操作",
          "合并查询",
          "追加查询",
          "引用查询",
          "Power BI中添加列的操作",
          "常规处理",
          "从文本添加列",
          "从数字添加列",
          "从日期和时间添加列",
          "AI见解添加列",
          "案例演示：导入后在Power Query编辑器中整理数据",
          "根据原始数据分组分别建立数据表",
          "整理数据表中的数据列",
          "整理数据表中的数据项",
          "抽取基础数据表"
        ],
        "第5章 打开分析视角": [
          "引例：数据分析想要看什么？",
          "电商业务想要看什么",
          "广告营销业务想要看什么",
          "用户增长业务想要看什么",
          "数据分析中的对比视角",
          "数据分析对比视角的定义",
          "数据分析中对比视角的实施方法",
          "数据分析中对比视角的应用",
          "数据分析中的相关性视角",
          "数据分析相关性视角的定义",
          "数据分析相关性视角的实施方法",
          "数据分析相关性视角的应用",
          "数据分析中的分类视角",
          "数据分析分类视角的定义",
          "数据分析分类视角的实施方法",
          "数据分析分类视角的应用",
          "数据分析中的描述视角",
          "数据分析中描述视角的定义",
          "数据分析中描述视角的实施方法",
          "数据分析中描述视角的应用",
          "做数据分析时如何选择分析视角",
          "确定研究问题和目的",
          "提出假设并通过数据分析证明或反驳",
          "对数据集进行多角度探索",
          "了解领域知识",
          "了解数据分析的目标受众",
          "产生分析视角方案",
          "案例分析",
          "电商业务的常见报表主题方案",
          "广告营销业务的常见报表主题方案",
          "用户增长业务的常见报表主题方案"
        ],
        "第6章 Power BI可视化指标分析": [
          "引例：业务常用指标可视化",
          "电商业务常用指标",
          "广告营销业务常用指标",
          "用户增长业务常用指标",
          "在Power BI中建立可视化对象",
          "如何在Power BI中建立可视化对象",
          "常用可视化对象类型",
          "配置可视化对象的数据字段",
          "设置可视化对象的属性和格式",
          "建立可视化对象的注意事项",
          "在Power BI中配置可视化指标",
          "配置可视化指标的步骤",
          "添加数据字段",
          "其它相关考虑因素",
          "Power BI的常用可视化对象",
          "柱状图和条形图",
          "折线图",
          "堆积图",
          "饼图和环形图",
          "表格.",
          "矩阵.",
          "切片器",
          "在Power BI中调整可视化对象格式",
          "可视化对象格式概述",
          "调整可视化对象格式的步骤",
          "调整不同类型的可视化对象格式",
          "使用主题快速调整可视化对象格式",
          "调整可视化对象格式的注意事项",
          "案例演示：各个业务常用的数据可视化",
          "电商业务的常用数据可视化",
          "广告营销业务的常用数据可视化",
          "用户增长业务的常用数据可视化"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "零基础。您会学到您需要知道的一切"
      ],
      "description": "本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。\n课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "需要使用数据分析工具进行数据处理和展示的业务人员，如市场营销、销售、财务、人力资源等",
        "需要通过数据分析工具进行业务决策的管理者，如项目经理、部门主管、总监等",
        "需要学习数据分析工具的基本功能和操作的学习者，如学生、教师、自学者等"
      ]
    },
    {
      "title": "Curso de Inteligencia Artificial en el Entorno Empresarial",
      "url": "https://www.udemy.com/course/curso-de-inteligencia-artificial-en-el-entorno-empresarial/",
      "bio": "Transforma tu Negocio con Inteligencia Artificial: Estrategia, Aplicación y Liderazgo",
      "objectives": [
        "Identificar oportunidades de alto valor para aplicar la IA en tu empresa o área",
        "Desarrollar una estrategia de IA alineada con los objetivos generales de tu negocio",
        "Evaluar diferentes tipos de IA y tecnologías desde una perspectiva de aplicabilidad y valor empresarial",
        "Comprender los casos de uso más relevantes de la IA en marketing, ventas, operaciones, RH, finanzas y cadena de suministro",
        "Navegar el panorama de las plataformas y herramientas de IA (cloud y on-premise) sin necesidad de ser un experto técnico",
        "Gestionar los aspectos clave de proyectos de integración de IA, desde la planificación hasta la implementación",
        "Liderar la gestión del cambio organizacional y preparar a tu equipo para la era de la IA",
        "Abordar las consideraciones éticas y de seguridad cruciales en el uso de la IA",
        "Medir el impacto y el ROI de las iniciativas de IA en tu empresa",
        "Anticipar las tendencias futuras de la IA y preparar estratégicamente tu organización",
        "Tomar decisiones informadas sobre la adopción de IA, basadas en valor de negocio y estrategia"
      ],
      "course_content": {
        "Introducción a la Inteligencia Artificial en la Empresa": [
          "¿Por qué la IA es clave para la empresa actual?",
          "Tipos de IA y sus aplicaciones empresariales",
          "Estrategia de IA para la empresa: primeros pasos",
          "Infraestructura y recursos necesarios para la IA",
          "Gobernanza y gestión de proyectos de IA",
          "Cultura organizacional para la adopción de la IA",
          "Presentaciones de la Sección Introducción a la Inteligencia Artificial en la Emp",
          "Introducción a la Inteligencia Artificial en la Empresa",
          "El Reto del ROI: Convenciendo al Escéptico Financiero",
          "El Desafío Cultural: Gestionando un Equipo Preocupado por la IA"
        ],
        "Integración de la IA en las Áreas Funcionales de la Empresa": [
          "IA en Marketing y Ventas",
          "IA en Operaciones y Producción",
          "IA en Recursos Humanos y Gestión de Talento",
          "IA en Finanzas y Contabilidad",
          "IA en la Cadena de Suministro y Logística",
          "IA en Investigación y Desarrollo de Productos",
          "Presentaciones de la Sección Integración de la IA en las Áreas Funcionales",
          "Integración de la IA en las Áreas Funcionales de la Empresa",
          "El Dilema de la Campaña: Predicción vs. Tradición",
          "El Robot en la Fábrica: Gestionando el Factor Humano"
        ],
        "Tecnologías y Plataformas para la Integración de IA": [
          "Plataformas Cloud de IA: AWS, Azure, Google Cloud",
          "Herramientas de Desarrollo y APIs de IA",
          "Integración de IA On-premise vs. Cloud vs. Edge",
          "Bases de datos y gestión de datos para IA",
          "Seguridad y privacidad en plataformas de IA",
          "Integración de IA con sistemas y aplicaciones empresariales existentes",
          "Presentaciones de la Sección Tecnologías y Plataformas para la Integración de IA",
          "Tecnologías y Plataformas para la Integración de IA",
          "La Decisión del Arquitecto: ¿Construir a Medida o Usar una API?",
          "El Dilema de la Infraestructura: ¿Nube, On-Premise o Borde?"
        ],
        "Gestión del Cambio y Consideraciones Éticas de la IA en la Empresa": [
          "Impacto de la IA en la fuerza laboral y nuevas habilidades",
          "Ética y responsabilidad en el uso de la IA empresarial",
          "Gestión del cambio organizacional ante la IA",
          "Formación y capacitación en IA para la empresa",
          "Medición del ROI y el valor de la IA en la empresa",
          "Casos de estudio de éxito y fracaso en la integración de IA",
          "Presentaciones de la Sección Gestión del Cambio y Consideraciones Éticas",
          "Gestión del Cambio y Consideraciones Éticas de la IA en la Empresa",
          "La Propuesta de IA: Equilibrando el ROI con la Cultura Organizacional",
          "Crisis de Sesgo: Defendiendo la Ética de tu Sistema de IA"
        ],
        "El Futuro de la IA en los Negocios y Tendencias Emergentes": [
          "Tendencias clave en la IA empresarial para los próximos años",
          "El impacto profundo de la IA en diferentes industrias",
          "Preparándose estratégicamente para el futuro de la IA en su empresa",
          "Startups y nuevos modelos de negocio basados en IA",
          "Regulaciones y políticas gubernamentales sobre IA a nivel global",
          "Presentaciones de la Sección El Futuro de la IA en los Negocios y Tendencias",
          "El Futuro de la IA en los Negocios y Tendencias Emergentes",
          "El Desafío del 'AI-First': Convenciendo al Consejo de Administración",
          "La Frontera Regulatoria: Lanzando un Producto de 'Alto Riesgo'"
        ]
      },
      "requirements": [
        "Comprensión básica del entorno empresarial y los procesos de negocio",
        "Interés genuino en cómo la tecnología, específicamente la IA, puede impactar y mejorar las operaciones y estrategias de negocio",
        "No se requiere experiencia técnica previa en programación, ciencia de datos o desarrollo de IA. Este curso se enfoca en la estrategia y la aplicación desde una perspectiva de negocio"
      ],
      "description": "La Inteligencia Artificial ya no es una tecnología del futuro; es una necesidad estratégica del presente. Este videocurso está diseñado específicamente para profesionales de negocio y líderes que necesitan entender, planificar e implementar la IA para generar valor tangible en sus organizaciones. Olvídate de la jerga técnica compleja; aquí obtendrás una hoja de ruta práctica y estratégica para identificar oportunidades de IA, evaluar soluciones, gestionar proyectos, liderar el cambio organizacional y asegurar que la IA se convierta en un verdadero motor de crecimiento y eficiencia para tu negocio. Prepárate para liderar la transformación digital con confianza.\n\n\n¿Te Suena Familiar?\n\n\nTe sientes presionado a adoptar la IA, pero no sabes por dónde empezar ni cómo justificar la inversión.\nEscuchas hablar de IA en marketing, operaciones o recursos humanos, pero no tienes claro cómo aplicarla específicamente a tu área o industria.\nTe preocupa el impacto de la IA en tu equipo y la cultura organizacional, y no sabes cómo gestionar el cambio.\nTe cuesta diferenciar entre el hype de la IA y las soluciones que realmente pueden generar ROI para tu empresa.\nNecesitas evaluar proveedores o plataformas de IA, pero la complejidad técnica te abruma.\n\n\nSi te identificas con alguno de estos puntos, este curso es para ti. Te daremos las herramientas y el conocimiento estratégico para navegar el mundo de la IA empresarial con éxito.\n\n\n¿Para Quién es Este Curso?\n\n\nEste curso está pensado para profesionales ambiciosos y con visión de futuro que desean entender el impacto de la IA desde una perspectiva de negocio y estrategia, y aplicarla para impulsar el éxito organizacional:\n\n\nDirectivos y Gerentes: Obtén una visión estratégica clara y aprende a liderar iniciativas de IA a nivel ejecutivo.\nLíderes de Equipo y Project Managers: Adquiere las habilidades para identificar, planificar y gestionar proyectos de integración de IA.\nConsultores y Analistas: Amplía tu expertise y asesora a tus clientes en la aplicación de la IA para optimizar procesos y generar valor.\nProfesionales de Áreas Funcionales (Marketing, Ventas, Operaciones, RH, Finanzas, etc.): Descubre cómo la IA puede potenciar tu trabajo diario y transformar los procesos de tu departamento.\nEmprendedores: Explora cómo la IA puede ser la base de nuevos modelos de negocio o dar una ventaja competitiva a tu startup.\nProfesionales de IT: Complementa tu conocimiento técnico con una comprensión profunda del valor de negocio y la estrategia de la IA para colaborar mejor con otras áreas.\nCualquier Profesional Interesado: Si buscas comprender el impacto de la IA en el futuro del trabajo y los negocios para mantenerte relevante y liderar el cambio.\n\n\n¿Qué Lograrás al Finalizar el Curso? (Resultados Concretos)\n\n\nAl completar este videocurso, estarás capacitado para:\n\n\nIdentificar oportunidades de alto valor para aplicar la IA en tu empresa o área.\nDesarrollar una estrategia de IA alineada con los objetivos generales de tu negocio.\nEvaluar diferentes tipos de IA y tecnologías desde una perspectiva de aplicabilidad y valor empresarial.\nComprender los casos de uso más relevantes de la IA en marketing, ventas, operaciones, RH, finanzas y cadena de suministro.\nNavegar el panorama de las plataformas y herramientas de IA (cloud y on-premise) sin necesidad de ser un experto técnico.\nGestionar los aspectos clave de proyectos de integración de IA, desde la planificación hasta la implementación.\nLiderar la gestión del cambio organizacional y preparar a tu equipo para la era de la IA.\nAbordar las consideraciones éticas y de seguridad cruciales en el uso de la IA.\nMedir el impacto y el ROI de las iniciativas de IA en tu empresa.\nAnticipar las tendencias futuras de la IA y preparar estratégicamente tu organización.\nTomar decisiones informadas sobre la adopción de IA, basadas en valor de negocio y estrategia.\n\n\nRequisitos Previos\n\n\nComprensión básica del entorno empresarial y los procesos de negocio.\nInterés genuino en cómo la tecnología, específicamente la IA, puede impactar y mejorar las operaciones y estrategias de negocio.\nNo se requiere experiencia técnica previa en programación, ciencia de datos o desarrollo de IA. Este curso se enfoca en la estrategia y la aplicación desde una perspectiva de negocio.\n\n\nEstructura del Curso\n\n\nEl curso está organizado en módulos estratégicos para ofrecerte una comprensión completa y aplicable de la IA en el entorno empresarial:\n\n\nMódulo 1: Introducción a la Inteligencia Artificial en la Empresa\nMódulo 2: Integración de la IA en las Áreas Funcionales de la Empresa\nMódulo 3: Tecnologías y Plataformas para la Integración de IA\nMódulo 4: Gestión del Cambio y Consideraciones Éticas de la IA en la Empresa\nMódulo 5: El Futuro de la IA en los Negocios y Tendencias Emergentes\n\n\n¿Por Qué Elegir Este Curso?\n\n\nEnfoque Estratégico y de Negocio: A diferencia de cursos técnicos, este se centra en cómo la IA crea valor y cómo liderar su implementación desde una perspectiva ejecutiva y de gestión.\nHoja de Ruta Práctica: Te proporcionamos un marco paso a paso para pasar de la teoría a la acción, aplicable a tu contexto empresarial.\nCobertura Integral: Cubre no solo la tecnología (a nivel conceptual para managers), sino también la estrategia, los casos de uso, la gestión del cambio, la ética, la medición de valor y las tendencias futuras.\nCasos de Uso Realistas: Aprende a través de ejemplos concretos de cómo empresas líderes están utilizando la IA en diferentes áreas y sectores.\nPensado para el Líder del Futuro: Te equipa con el conocimiento necesario para tomar decisiones informadas y liderar tu organización en la era de la Inteligencia Artificial.\n\n\n¡Lleva tu Empresa a la Era de la Inteligencia Artificial! Inscríbete Ahora\n\n\nNo esperes a que la competencia te supere. La oportunidad de transformar y optimizar tu negocio con IA está aquí. Este videocurso te dará el conocimiento y la confianza para liderar esa transformación.\n\n\n¡Invierte en tu futuro y el de tu organización hoy mismo!",
      "target_audience": [
        "Cualquier Profesional Interesado: Si buscas comprender el impacto de la IA en el futuro del trabajo y los negocios para mantenerte relevante y liderar el cambio",
        "Profesionales de IT: Complementa tu conocimiento técnico con una comprensión profunda del valor de negocio y la estrategia de la IA para colaborar mejor con otras áreas",
        "Directivos y Gerentes: Obtén una visión estratégica clara y aprende a liderar iniciativas de IA a nivel ejecutivo",
        "Líderes de Equipo y Project Managers: Adquiere las habilidades para identificar, planificar y gestionar proyectos de integración de IA",
        "Consultores y Analistas: Amplía tu expertise y asesora a tus clientes en la aplicación de la IA para optimizar procesos y generar valor",
        "Profesionales de Áreas Funcionales (Marketing, Ventas, Operaciones, RH, Finanzas, etc.): Descubre cómo la IA puede potenciar tu trabajo diario y transformar los procesos de tu departamento",
        "Emprendedores: Explora cómo la IA puede ser la base de nuevos modelos de negocio o dar una ventaja competitiva a tu startup"
      ]
    },
    {
      "title": "【初心者向け】MCPサーバーをClaudeから動かしてみよう！またPythonで独自のMCPサーバーを構築していこう！",
      "url": "https://www.udemy.com/course/mcp-llm-python/",
      "bio": "今話題のMCPサーバーについて基礎からしっかり理解していこう！様々なMCPの種類を知り、Claude Desktopから実際に動かしてみよう！そして最終的に様々な角度から分析をしてくれるMCPサーバーをPythonで構築してみよう！",
      "objectives": [
        "MCPの基本概念と仕組みを理解できる",
        "MCPの代表的な種類とその活用方法を学べる",
        "既存のMCPサーバーをClaudeから呼び出して使えるようになる",
        "Pythonで独自のMCPサーバーを設計・実装できる",
        "データ分析に役立つオリジナルMCPサーバーを作れる",
        "Pythonの基礎から学べる"
      ],
      "course_content": {
        "はじめに": [
          "イントロダクション",
          "MCPとは？どんな種類がある？"
        ],
        "MCPサーバーのClaude Desktopから呼び出して使ってみよう！": [
          "このセクションで紹介する各種ページ",
          "MCPのドキュメントやGitHubリポジトリを見ていこう！",
          "MCPサーバーのcontext7の設定をカスタムコネクタからしてみよう！",
          "MCPサーバーのcontext7の威力について確認しよう！",
          "Claudeの設定ファイルを編集してcontext7を連携する方法を見ていこう！"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Searbornについて学ぼう！",
          "Python構文の復習"
        ],
        "Pythonを使ったMCPサーバーの使い方": [
          "エディタの準備とPythonの準備",
          "Pythonパッケージ・環境管理ツール「uv」の導入",
          "【注意】次のレクチャー22,23の動画のキーボード打音",
          "シンプルなMCPサーバーを立ち上げてみよう！",
          "Claude Desktopから立ち上げたMCPサーバーを使ってみよう！"
        ],
        "アップロードされたCSVに対して良い感じの分析結果を返してくれるMCPサーバーを作ってみよう！": [
          "アップロードされたファイルを読み込む関数を作っていこう！",
          "データを表示する関数や統計量を表示する関数を作っていこう！",
          "特定のカラムでグループ化して集計する関数を作っていこう！",
          "【注意】次のレクチャーにおけるコードの誤りについて",
          "2つのデータセットをジョインする関数とピボットテーブルを作成する関数を作っていこう！",
          "日付の単位で集計する関数を作っていこう！",
          "上位N件を抽出する関数と相関行列を出力する関数を作っていこう！",
          "外れ値を検出する関数を作り分析MCPサーバーを完成させていこう！",
          "分析MCPサーバーを立ち上げてClaude Desktopから実行していこう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学びますのでプログラミングの知識は特に必要ありません"
      ],
      "description": "本コースへようこそ！\n本コースでは、MCPの基礎から種類の理解、実際の利用方法、さらにPythonを用いた独自サーバーの開発までを体系的に学びます。\n\n\nMCP（Model Context Protocol）とは、Claudeをはじめとする最新のLLMモデルが外部ツールやデータにアクセスするための標準的な仕組み。\n\n\n実際にClaudeと連携してMCPを動かしながら理解を深め、最終的には データ分析に特化した優秀なMCPサーバー を構築できるようになりましょう！\n\n\nこのコースの流れは以下の通りです。\nMCPの基礎を理解する\nMCPの種類を学ぶ\nClaudeからMCPを呼び出してみる\nPythonで独自のMCPサーバーを作る\n応用：データ分析MCPサーバーの構築\n\n\n受講後には、\nMCPの基礎と仕組みを理解し、\n既存のMCPサーバーを活用でき、\n自分自身でPython製MCPサーバーを作成し、\nClaudeを通じてデータ分析タスクを自動化できる\nそんな 「MCPを自在に操れる開発者」 になれます！\n今話題のMCPについてしっかり学んでいきましょう！",
      "target_audience": [
        "MCPを使って外部ツール連携を実現したい方",
        "独自のMCPサーバーを作ってみたい方",
        "ClaudeやAIエージェントの活用に興味がある方"
      ]
    },
    {
      "title": "KI Voice-Agenten: Automation mit Vapi, ElevenLabs, n8n & MCP",
      "url": "https://www.udemy.com/course/ki-voice-agenten-automation-mit-vapi-elevenlabs-n8n-mcp/",
      "bio": "Baue & verkaufe AI-Telefon-Agenten mit Vapi, ElevenLabs, LiveKit, Fonio, n8n, LLMs, RAG, MCP, Generative KI & ChatGPT",
      "objectives": [
        "Grundlagen von Voice-Agenten: Ziele, Stärken, Schwächen und Business-Potenzial",
        "Wie Voice-Agenten technisch funktionieren: LLMs, TTS (Text-to-Speech), STT (Speech-to-Text) und die richtige Modellwahl",
        "Plattform-Überblick: Vapi, Fonio, Elevenlabs, Retell, LiveKit & weitere Anbieter im direkten Vergleich",
        "Wirtschaftlichkeit von Voice-Agenten: Kosten-Nutzen-Analyse & Business-Potenzial",
        "Alles zu Vapi – vom Anfänger bis Profi: erste Voice-Agenten, MCP-Integration, Webhooks, RAG-Anbindung und Telefon-Calls",
        "ElevenLabs für professionelle Stimmen: Creative Plattform, Prompt Engineering Masterclass & Web-Integration",
        "Systemprompts für Voice-Agenten: Best Practices, Feinjustierung und Praxisbeispiele",
        "Voice-Agenten in Webseiten einbinden & individuell mit CSS anpassen",
        "Testing, Debugging & Optimierung von Sprachagenten für bessere Gesprächsqualität",
        "n8n & Voice-Agenten: Anmeldung, API-Keys, Workflows und MCP-Tools für Automatisierungen",
        "RAG-Voice-Agenten trainieren: Daten in Vektordatenbanken hochladen & intelligente Antworten generieren",
        "MCP-Server mit Vapi und weiteren LLMs verbinden: Deepseek, Llama, Mistral & mehr",
        "KI-Automatisierungen mit Voice-Agenten erweitern: E-Mail, Google Sheets, Datenbanken & externe APIs",
        "Telefonnummern für Inbound- und Outbound-Calls hinzufügen und integrieren",
        "Produktionsreife KI-Voice-Agenten Schritt für Schritt: Praxisbeispiel Restaurant-Reservierung mit Debugging & Sentiment-Analyse",
        "DSGVO-konforme Voice-Agenten mit Fonio: Rufumleitungen, Telefonnummern-Kauf, SIP-Integration & E-Mail-Automation mit n8n",
        "Spezialfälle: Finetuning eigener LLMs, lokale Lösungen & Open-Source-Alternativen mit LiveKit und Realtime API",
        "KI-Avatare mit Stimme & Echtzeit-Interaktion: ElevenLabs, LiveKit & OpenAI Realtime API",
        "Sicherheit, Datenschutz & rechtliche Rahmenbedingungen: DSGVO, EU AI Act, Jailbreaks & Compliance"
      ],
      "course_content": {
        "Einführung: Überblick und Tipps": [
          "Willkommen!",
          "Kurs Überblick",
          "Erklärung der Links für den Kurs",
          "Wichtige Links",
          "Dozentenvorstellung: Arnold Oberleiter (Arnie)",
          "Tipps und Ziele für den Kurs"
        ],
        "Was bauen wir – und wie funktioniert die Technologie?": [
          "Das erwartet dich in diesem Abschnitt",
          "Das Ziel von Voice-Agenten: Stärken und Schwächen im Überblick",
          "Voice-Agenten verstehen: So funktioniert die Technologie dahinter",
          "Welche Modelle eignen sich für das Konstrukt: LLMs, TTS, STT",
          "Welche Plattformen gibt es für Voice-Agenten? Überblick & Vergleich",
          "Lohnen sich Voice-Agenten wirtschaftlich? Kosten-Nutzen-Analyse",
          "Recap"
        ],
        "Vapi Basics: Erste Voice-Agenten erstellen und in eine Webseite integrieren": [
          "Was dich in diesem Abschnitt erwartet",
          "Anmeldung und Überblick über Vapi",
          "Einfacher Voice-Agent auf Deutsch",
          "KI-Agent als Terminbuchungs-Assistent: ElevenLabs-Stimme & Prompt Engineering",
          "Systemprompt für Voice-Agent als Beispiel",
          "Feinjustierung des Voice-Agents",
          "KI Agent in Webseite integrieren und CSS individuell anpassen",
          "Sprach-Agent testen und verbessern",
          "Recap"
        ],
        "Voice-Agenten ausbauen: n8n, MCP, Tools & Telefonintegration": [
          "Das erwartet dich in diesem Abschnitt",
          "n8n-Anmeldung Überblick und OpenAI API-Keys",
          "n8n mit Vapi verknüpfen über MCP (Tools hinzufügen)",
          "RAG-App für Vapi Voice-Agent trainieren: Daten in Vektordatenbank hochladen",
          "Vectordatenbank mit MCP und VAPI verbinden",
          "KI-Automation erweitern: E-Mail-Workflows, Google Sheets-Datenbanken & mehr",
          "Integration: Voice-Agent mit MCP-Server und weiteren KI-Modellen verknüpfen",
          "Telefonnummern für Inbound und Outbound-Calls hinzufügen",
          "JavaScript-Variablen für dynamische Namen und genaues Datum",
          "Recap"
        ],
        "Produktionsreife KI-Voice-Agenten erstellen: Praxisbeispiel Schritt für Schritt": [
          "Das lernst du in diesem Abschnitt",
          "Welche Voice Agenten sollte man erstellen und wiviel sind sie wert?",
          "KI-gestützter Voice Agent für Restaurant-Reservierungen",
          "KI-Agent optimieren",
          "Agenten Debugging, Optimieren, Sentiment Analysen & mehr",
          "Recap"
        ],
        "Voice-Agenten mit ElevenLabs & Prompting-Masterclass": [
          "Das lernst du in dieser Sektion",
          "Überblick: ElevenLabs Creative Plattform, Voice-Agenten & Dokumentation",
          "Prompt Engineering Masterclass für KI Telefon Agenten",
          "Einfacher Elevenlabs Agent bis zur implementation in Webseite",
          "ElevenLabs und n8n verbinden – Webhooks für Tools",
          "Weitere Tools über Webhooks: n8n-Agent mit ElevenLabs verknüpfen",
          "Weitere Möglichkeiten: MCP, Telefonnummer, Outbound-Anrufe & mehr",
          "Recap: ElevenLabs-Voice-Agenten, Webhooks und n8n-Integration"
        ],
        "Fonio aus Österreich: Einfache DSGVO-konforme Lösung": [
          "In diesem Abschnitt geht es um Fonio aus Österreich",
          "Plattform und Dokumentation von Fonio im Überblick",
          "Unser erster Voice-Agent zum Testen in Fonio",
          "Empfang automatisieren mit Rufumleitungen",
          "Telefonnummern direkt in Fonio kaufen oder Sip Nummern importieren",
          "E-Mail-Automation mit Fonio und n8n (JavaScript-Variablen)",
          "Recap von Fonio"
        ],
        "Voice-Agenten-Business (Quick Start)": [
          "Voice-Agenten-Business (Quick Start)",
          "Dein erster Kunde"
        ],
        "Spezialfälle: Finetuning eigener LLMs, lokale KI-Lösungen & mehr": [
          "Überblick",
          "Finetuning für dein LLM: Lohnt sich der Aufwand wirklich?",
          "Anrufe an Menschen oder KI-Assistenten weiterleiten (ElevenLabs & Vapi)",
          "LiveKit-Überblick: Voice-Agenten mit Open-Source-Tool erstellen",
          "KI-Avatar mit Stimme in LiveKit erstellen (OpenAI Realtime API)",
          "Recap"
        ],
        "Sicherheit & Rechtliches: DSGVO und Datenschutz für Voice-Agenten": [
          "Generelle KI-Sicherheit für Voice-Agenten",
          "Rechtliches für Voice-Agenten: DSGVO, Datenschutz & Compliance",
          "Großes Recap und mein Danke!",
          "Bonus"
        ]
      },
      "requirements": [
        "Keine Vorkenntnisse nötig, alles wird Schritt für Schritt gezeigt"
      ],
      "description": "KI Voice-Agenten sind die nächste Evolutionsstufe von KI-Agenten!\n\nSie kombinieren Large Language Models (LLMs) mit Sprach-Ein- und Ausgabe (STT & TTS) und ermöglichen völlig neue Interaktionen – ob als Telefonassistent, Terminbuchungs-Tool oder Support-Agent im Kundenservice.\nDoch wie baut man eigene Voice-Agenten wirklich praxisnah auf?\nWelche Tools und Plattformen sind am besten geeignet?\nUnd wie kann man diese Agenten nicht nur technisch umsetzen, sondern auch produktionsreif machen und verkaufen?\n\n\nIn diesem Kurs erhältst du einen kompletten Überblick – von den Grundlagen bis zur Business-Implementierung.\n\n\nWas dich in diesem Kurs erwartet:\nGrundlagen & Technologie\nZiele, Stärken & Schwächen von Voice-Agenten verstehen\nWie Voice-Agenten funktionieren: LLMs, TTS (Text-to-Speech) & STT (Speech-to-Text)\nÜberblick über die wichtigsten Plattformen: Vapi, Fonio, LiveKit & Eigenlösungen\nWirtschaftliche Bewertung: Lohnt sich ein Voice-Agenten-Business wirklich?\nVapi Basics – von Null zum ersten Voice-Agent\nAlles zu Vapi: Anmeldung, Oberfläche & erste Agenten erstellen\nVoice-Agent auf Deutsch: ElevenLabs-Stimme, Terminbuchungs-Assistent & Prompt Engineering\nSystemprompts in der Praxis: Beispiele & Feinjustierung für bessere Ergebnisse\nVoice-Agent in Webseiten einbinden & mit CSS anpassen\nTesting, Debugging & kontinuierliche Verbesserung\nErweiterte Integration mit n8n, MCP & RAG\nn8n-Basics: Anmeldung, API-Keys & Workflows\nVoice-Agenten mit Vapi & n8n über MCP verbinden (Tools hinzufügen)\nRAG-App für Voice-Agenten: Daten hochladen & Vektordatenbanken einbinden\nMCP-Server mit Vapi und weiteren LLMs (Deepseek, Llama, Mistral & mehr) verknüpfen\nKI-Automationen mit E-Mail, Google Sheets & Datenbanken erweitern\nTelefonnummern für Inbound- und Outbound-Calls einrichten\nJavaScript-Variablen für dynamische Namen, Daten & personalisierte Gespräche\nProduktionsreife Voice-Agenten & Business-Praxis\nSchritt-für-Schritt-Beispiel: KI-gestützter Voice-Agent für Restaurant-Reservierungen\nDebugging, Optimierung & Sentiment-Analysen für bessere Gesprächsqualität\nWelche Voice-Agenten sind am meisten wert – und wie verkauft man sie?\nElevenLabs & Prompting-Masterclass\nElevenLabs Creative Plattform: Überblick, Stimmen & Dokumentation\nPrompt Engineering Masterclass speziell für Telefon-Agenten\nElevenLabs-Agenten bis zur Web-Integration umsetzen\nElevenLabs mit n8n & Webhooks verbinden – Tools & Automatisierungen erweitern\nWeitere Möglichkeiten: MCP, Telefonnummern, Outbound-Anrufe & mehr\nDSGVO-konforme Voice-Agenten mit Fonio\nPlattform & Dokumentation von Fonio im Überblick\nErster Voice-Agent in Fonio: Testen & Aufsetzen\nRufumleitungen & Telefonnummern direkt in Fonio kaufen oder SIP importieren\nE-Mail-Automationen mit Fonio & n8n (inkl. JavaScript-Variablen)\nSpezialfälle & Open-Source-Lösungen\nFinetuning eigener LLMs: Lohnt sich der Aufwand wirklich?\nHuman-in-the-Loop: Anrufe an Menschen oder Assistenten weiterleiten\nLiveKit-Überblick: Open-Source Voice-Agenten mit Realtime API erstellen\nKI-Avatare mit Stimme & Live-Interaktion in Echtzeit\nSicherheit & Rechtliches\nKI-Sicherheit für Voice-Agenten: Jailbreaks, Prompt Injections & Data Poisoning\nDatenschutz, DSGVO & rechtliche Rahmenbedingungen (inkl. EU AI Act & Compliance)\n\n\nDein Nutzen nach dem Kurs:\nNach diesem Kurs wirst du in der Lage sein, eigene Voice-Agenten von Grund auf zu entwickeln, mit Plattformen wie Vapi, ElevenLabs, Fonio und LiveKit zu arbeiten, diese mit Tools wie n8n, RAG & MCP zu erweitern – und sogar produktreif an Kunden zu verkaufen.\nOb für Support, Terminbuchung, Restaurant-Reservierungen oder Outbound-Calls – du wirst das komplette Wissen haben, um Voice-Agenten in der Praxis einzusetzen und gleichzeitig rechtliche und DSGVO-Vorgaben einzuhalten.\nMelde dich jetzt an und baue die Voice-Agenten der Zukunft – praxisnah, automatisiert und DSGVO-konform!",
      "target_audience": [
        "An alle, die etwas neues lernen wollen und tief in KI-Automatisierung mit Voice Agenten einblicken wollen",
        "An Unternehmer die effizienter werde wollen, Geld sparen möchten oder ein KI-Business aufbauen wollen",
        "Privarpersonen, die an KI und Automatisierung interessiert sind und eigene Agenten bauen möchten"
      ]
    },
    {
      "title": "Анализ временных рядов на Python",
      "url": "https://www.udemy.com/course/ittensive-python-time-series/",
      "bio": "Изучим регрессию, автокорреляция и рекуррентные нейросети для работы с временными рядами",
      "objectives": [
        "Теория временных рядов",
        "Описание тенденций временного ряда",
        "Прогнозирование временного ряда",
        "Линейная и нелинейная регрессия",
        "ARMA, ARIMA, SARIMA(X)",
        "ADL и VAR",
        "RNN, LSTM и GRU",
        "BiLSTM"
      ],
      "course_content": {
        "Введение": [
          "Введение"
        ],
        "Линейная регрессия и скользящие окна": [
          "Понятие временного ряда",
          "Цели анализа временных рядов",
          "Полиномиальные тренды",
          "Скользящие средние",
          "Метод экспоненциального сглаживания",
          "Анализ временных рядов",
          "Сигнал и шум"
        ],
        "Практикум: Цены на зерно": [
          "Цены на зерно",
          "Скользящее окно",
          "Экспоненциальное среднее",
          "Модель Хольта-Винтерса",
          "Частотный анализ"
        ],
        "Проект: предсказание цен": [
          "Фьючерсы на зерно"
        ],
        "Эконометрический подход": [
          "Авторегрессия",
          "Стационарность",
          "ARMA",
          "ARIMA",
          "SARIMA(X)",
          "ADL и VAR",
          "Автокорреляция"
        ],
        "Практикум: Курсы валют": [
          "ARMA",
          "ARIMA",
          "SARIMA",
          "PROPHET",
          "Auto-TS"
        ],
        "Проект: Объем экспорта": [
          "Прогнозирование объема экспорта"
        ],
        "Методология анализа временных рядов и нейросети": [
          "Анализ временных рядов",
          "Дрейф данных",
          "RNN",
          "LSTM",
          "GRU",
          "BiLSTM и ConvLSTM",
          "Рекуррентные нейросети"
        ],
        "Практикум: Активность потребителей": [
          "Потребители энергии",
          "CatBoost",
          "RNN",
          "LSTM",
          "GRU",
          "BiLSTM"
        ],
        "Курсовой проект": [
          "Моделирование временного ряда"
        ]
      },
      "requirements": [
        "Продвинутый Python",
        "Основы машинного обучения"
      ],
      "description": "Внимание: для доступа к курсам ITtensive на Udemy напишите, пожалуйста, на support@ittensive.com с названием курса или группы курсов, которые хотите пройти.\n\n\nЭто дополнительный курс программы Машинное обучение от ITtensive по анализу временных рядов. В курсе разбираются 3 практических задачи:\n1. Фьючерсы (цены) на зерно. Используя помесячные данные фьючерсов на зерно на лондонской бирже и применив ансамбль классических методов - бегущего среднего и полиномиальной регрессии - спрогнозируем цены в период сильной неопределенности.\nПроект: прогноз фьючерсов на июнь 2022 года\n2. Курсы валют. Изучим частотный и эконометрический подход для описание и прогнозирования курса доллара к рублю. Научимся раскладывать ряд на тренд, сезонность и вариацию и использовать модели ARMA, ARIMA, SARIMA, а также векторные (факторные) данные. Попробуем библиотеки Prophet и Auto-TS (автоматическое машинное обучение).\nПроект: прогноз объема экспорта в декабре 2022 года\n3. Активность потребителей электроэнергии. Разберемся с нейронными сетями и на основе достаточно стационарного ряда спрогнозируем его поведение, используя ансамбль из рекуррентных нейросетей.\nКурсовой проект: прогноз курса акций, используя рекуррентные нейросети.\nТеория по курсу включает:\nПонятие и цели анализа временного ряда\nБазовые техники - полиномиальные тренды и бегущее среднее\nМодель Хольта-Винтерса и цвета шума\nАвторегрессия и стационарность ряда\nAR/MA, ARIMA, SARIMA(X)\nADL и VAR\nМетодологию анализа временных рядов и дрейф данных\nРекуррентные нейросети\nLSTM, GRU, ConvLSTM и BiLSTM\nВ заключении посмотрим на модели WaveNet и трансформеры (механизмы внимания).",
      "target_audience": [
        "Инженеры по данным, работающие с временными сериями",
        "Разработчики Python, прогнозирующие временные ряды",
        "Ученые по данным, исследующие временные зависимости"
      ]
    },
    {
      "title": "【すぐ実践できる！】Excelデータ分析/統計解析 超入門コース【3時間速習】",
      "url": "https://www.udemy.com/course/excel_data/",
      "bio": "エクセルによる実践的なデータ分析・統計解析スキルが短期間で身に付きます。実際のビジネス事例を通して、幅広い分析手法の実行方法や注意点を丁寧に解説します。実務でExcelや統計解析によるデータ分析を活用できるようになりましょう！",
      "objectives": [
        "Excelによるデータ分析を業務で実践できる",
        "基礎的な統計解析を業務に活用できる",
        "課題ごとに適した分析手法を選び、正しく結果を解釈できるようになる",
        "Excelの基本操作を習得できる"
      ],
      "course_content": {
        "はじめに": [
          "この講座の概要"
        ],
        "関数／ピボットテーブルによる基礎集計": [
          "関数を用いた代表値の計算",
          "ピボットテーブルによるクロス集計",
          "データの結合",
          "理解度チェック"
        ],
        "グラフによる結果の可視化": [
          "グラフの種類と使い分け方",
          "棒グラフ・折れ線グラフを作る",
          "円グラフ・帯グラフを作る",
          "散布図・バブルチャートを作る",
          "ヒストグラム・箱ひげ図を作る",
          "理解度チェック"
        ],
        "相関分析": [
          "相関分析の意味と使い方",
          "相関分析の実行",
          "理解度チェック"
        ],
        "仮説検定": [
          "仮説検定の意味と使い方",
          "t検定の実行【前編】",
          "t検定の実行【後編】",
          "カイ二乗検定の実行",
          "理解度チェック"
        ],
        "回帰分析": [
          "回帰分析の意味と使い方",
          "単回帰分析の実行",
          "重回帰分析の実行",
          "特徴量エンジニアリング【前編】",
          "特徴量エンジニアリング【後編】",
          "理解度チェック"
        ],
        "統計的因果推論への招待〜総復習〜": [
          "統計的因果推論の意味と使い方",
          "対象をランダムに選んだ場合〜仮説検定の活用〜",
          "対象を意図的に選んだ場合〜回帰分析の活用〜",
          "理解度チェック"
        ],
        "おわりに": [
          "実践への心構え"
        ]
      },
      "requirements": [
        "Excelを触ったことがある方。プログラミングや高度な統計学の知識は不要です"
      ],
      "description": "本コースは、Excelを使って実務に直結するデータ分析や統計解析を効率よく身につけるための講座です。\n実際のビジネス事例を通して、基本的な関数やピボットテーブルの操作から、グラフ作成による可視化、相関分析、t検定・カイ二乗検定と言った仮説検定、単回帰分析、重回帰分析、統計的因果推論まで幅広くカバーしています。\n各分析手法の「意味」「ビジネスでの活用法」「結果を解釈する際の注意点」を丁寧に解説しているため、分析未経験の方でも安心して学習を進めることができます。\nマーケティング担当者、営業・経営企画担当者、業務改善を目指す方、Excelをもっと仕事で活用したい方などに最適なコースです。Excelのスキルを向上させ、データ分析の力を武器にキャリアアップを目指しましょう！",
      "target_audience": [
        "データ分析／統計解析の基本的な手法や考え方を学びたい方",
        "Excelによるデータ分析の実行方法を知り、業務に活用したい方"
      ]
    },
    {
      "title": "Graficos em Python",
      "url": "https://www.udemy.com/course/graficos-em-python/",
      "bio": "Apresenta Gráficos em Python usando as bibliotecas Matplotlib e Seaborn",
      "objectives": [
        "Gráficos em Python",
        "Análise de Dados",
        "Informação Estratégica",
        "Python"
      ],
      "course_content": {
        "Modulo 1 - Graficos basicos": [
          "Conhecendo o Dataset",
          "Primeiro Grafico",
          "Colocando titulo e nome nos eixos",
          "Comparação Brasil e Argentina",
          "Primeira Figura",
          "2 Graficos lado a lado",
          "4 Graficos - Personalização com For",
          "Ajustes de Graficos",
          "Customizando Graficos",
          "Graficos de barras",
          "Ajustando Cores",
          "Tick Params",
          "Salvando Graficos",
          "Primeiro grafico com Seaborn",
          "Personalizando Cores",
          "1 grafico com Plotly express",
          "Salvando grafico em html"
        ],
        "Modulo 2 - Graficos de comparação": [
          "Conhecendo o Dataset e primeiro grafico de barras",
          "Inserindo valores nas colunas",
          "Personalizando cores - Ano maior venda",
          "Colocando Texto explicativo",
          "Grafico Colunas Empilhadas - Top 7",
          "Criando Grafico Colunas empilhadas",
          "Ajustando Cores das barras",
          "Inserindo Texto de Análise Critica",
          "Data set - Colunas empilhadas Ano e Marca",
          "Grafico Empilhado por Produto e Ano",
          "Personalizando Grafico Empilhado",
          "Ajustando Legendas e Valores",
          "Graficos barra horizontais - Preparando Dataset",
          "Grafico barras horizontais - Construindo Graficos",
          "Finalizando Graficos Barras horizontais",
          "Grafico de Histograma",
          "Grafico Densidade",
          "Finalizando Grafico Densidade",
          "Grafico BoxPlot",
          "Finalizando Granfico BoxPlot"
        ],
        "Modulo 2 - Graficos de Composição": [
          "Tratando Dataset",
          "Grafico de Pizza",
          "Grafico Pizza Adequado",
          "2 Graficos de Pizza",
          "Finalizando Graficos de Pizza",
          "Grafico de Cascata",
          "Grafico Cascada Parte 2",
          "Finalizando Grafico de Cascata"
        ]
      },
      "requirements": [
        "Conhecimento Básicos em Python"
      ],
      "description": "Este curso é projetado para quem deseja dominar a criação de gráficos em Python utilizando as bibliotecas Matplotlib e Seaborn. Essas bibliotecas são ferramentas poderosas para visualização de dados, permitindo criar desde gráficos simples até visualizações complexas e customizadas. Este curso é ideal tanto para iniciantes que querem desenvolver habilidades em desenvolvimento de gráficos em python.\nVocê irá aprender gráficos simples até uma customização de graficos.\n\n\nMatplotlib: Biblioteca de Visualização de Dados em Python\nMatplotlib é uma das bibliotecas de visualização de dados mais populares e amplamente utilizadas em Python. Foi criada por John D. Hunter em 2003 e tem como objetivo principal fornecer uma maneira fácil de gerar gráficos de alta qualidade. Matplotlib é extremamente versátil, permitindo criar uma grande variedade de gráficos e visualizações com um alto grau de personalização.\nAs vantagens são:\nVersatilidade, Customização, Integração com outras bibliotecas, Subplots e Layouts e Gráficos Interativos.\n\n\n\n\n\n\nSeaborn: Biblioteca de Visualização de Dados em Python\nSeaborn é uma biblioteca de visualização de dados em Python baseada no Matplotlib. Foi criada por Michael Waskom para simplificar a criação de gráficos estatísticos e proporcionar visualizações atraentes e informativas com menos esforço de configuração. Seaborn se destaca por sua facilidade de uso, integração com Pandas e foco em visualizações estatísticas.\nAs vantagens são:\nEstilo e Estética Atraentes, Facilidade de Uso, Integração com Pandas, Visualizações Estatísticas, Gráficos Complexos com Menos Código e Temas e Paletas de Cores Predefinidos.",
      "target_audience": [
        "Proffisionais de dados ou áreas administrativas",
        "Iniciantes em Python e Data Sciencie"
      ]
    },
    {
      "title": "Linguagem R e Shiny R: Caminho de GRANDES INSIGHTS nos Dados",
      "url": "https://www.udemy.com/course/linguagem-r-e-shiny-r-o-caminho-para-grandes-insights-data-science/",
      "bio": "Conheça uma das linguagens da área de Data Science mais usadas no mundo e construa aplicações web e móvel",
      "objectives": [
        "Entendendo o R",
        "Instalação do R-studio e R",
        "Primeiros passos com o R",
        "Uso do help",
        "Objetos no R",
        "Tipos de objetos",
        "Vetores",
        "Matrizes",
        "Data frames",
        "Listas",
        "Funções",
        "Identificação de valores faltantes e especiais",
        "Workspace do r(área de trabalho)",
        "Salvar uma workspce",
        "Leitura de uma workspace",
        "Acesso pelo R-studio",
        "Pacotes do R",
        "Entendimento dos diferentes tipos de pacotes",
        "Uso dos comandos library, intall package,require",
        "Trabalhando com leitura de arquivos externos",
        "Leitura através do R-studio",
        "Lendo um arquivo na web",
        "Sumarizando dados",
        "Selecionando dados",
        "Uso dos conectores lógicos",
        "Gráficos (análise de dados e apresentação)",
        "Exportando gráficos",
        "Tipos de gráficos: Histogramas, Ramo e Folha, Box-plot, Gráfico de dispersão,Gráfico de barras, Setores",
        "Programação: Comando FOR, Criando funções pelo R-studio, Uso de Estatísticas",
        "Variáveis qualitativas: Nominais e Ordinais",
        "Variáveis quantitativas: Discretas e Continuas",
        "Análise univariada e bivariada",
        "Teste de hipóteses",
        "Teste de uma distribuição normal",
        "Teste chi-quadrado para aderência",
        "Comparação de duas médias",
        "Comparação de médias múltiplas pelo teste de Tukey",
        "Regressão linear simples",
        "Regressão linear múltipla",
        "Mineração de dados com o R",
        "Uso do Google Vis ( biblioteca gráfica do Google)",
        "O que é e porque aprender R Shiny",
        "Arquitetura de um aplicativo/painel Shiny",
        "Utilização de Objetos de Entrada Texto, Números e Data",
        "Utilização de Objetos de Entrada UPLOAD",
        "Utilização de Objetos de Saída Texto",
        "Utilização de Objetos de Saída Tabela Estática e Dinâmica",
        "Utilização de Objetos de Saída PLOTS/Gráficos",
        "Utilização de Objetos de Saída Download",
        "Aplicação de HTML em APP/Painel Shiny",
        "Definição de Layout para Aplicativo",
        "Uso de Temas",
        "Introdução a Reatividade e Publicação de Aplicativo Shiny"
      ],
      "course_content": {
        "LINGUAGEM R - Operações com Dados": [
          "Apresentação do Curso e Instalação do R",
          "INFORMAÇÕES IMPORTANTES- Leia antes de iniciar o curso",
          "R-Studio, Trabalhando com operações básicas, Help do R, Trabalhando com Vetores",
          "Operações com Objetos do R, Trabalhando com Vetores",
          "Trabalhando com Matrizes",
          "Data Frame, Listas, Trabalhando com Workspace, Funções, Trabalhando com Pacotes",
          "Leitura de arquivos externos, Sumarizando Dados (medidas estatísticas)",
          "Gráficos no R: Histograma, Box-Plot, Ramo e Folhas, Barras, Setores",
          "Programação, Análise Uni e BI variada, Uso de Var. Qualitativas e Quantitativas",
          "Teste de Hipóteses e Regressão Linear e Múltipla",
          "Mineração de Dados e Google VIS",
          "Responda nosso Quiz"
        ],
        "R SHINY - Aprenda a Construir Painéis e Aplicativos Interativos": [
          "Apresentação do Curso",
          "Avisos Importantes",
          "Entendendo o que é Shiny",
          "Conhecendo o Ambiente de Trabalho - RStudio Cloud",
          "Entendendo o Básico de um APP em Shiny",
          "UI E SERVER e Funcionamento de um APP Shiny",
          "Construindo seu Primeiro APP Shiny",
          "Desafio Prático",
          "Introdução a Estruturas de Entrada",
          "Objetos Input para Valores de Texto",
          "Objetos Input para Valores Numéricos",
          "Objetos Input para Valores Data",
          "Objetos de Seleção",
          "Objetos de Upload, Botão e Link",
          "Outros Objetos de Entrada",
          "Desafio Prático",
          "Critério de utilização Estruturas de Saída",
          "Objeto de Texto (textOutput)",
          "Objeto Tabela (tableOutput e dataTableOutput)",
          "Plots (plotOutput)",
          "Objeto de Download (downloadButton) e Download de Dados",
          "Desafio Prático",
          "Upload de Dados para uso no APP Shiny",
          "Adicionando textos e elementos HTML",
          "Desafio Prático",
          "Introdução ao Layout de um App Shiny",
          "Modelo Sidebar (Barra Lateral)",
          "Modelo Grade (GRID)",
          "Utilizando TABSETS",
          "Artigo sobre Layout no Shiny",
          "Desafio Prático",
          "Utilizando TEMAS no seu Aplicativo Shiny",
          "Link para outros Temas para App Shiny",
          "REATIVIDADE +PUBLICACAO APP DO SHINY COM DADOS",
          "Desafio Prático"
        ]
      },
      "requirements": [
        "Sem pré-requisitos"
      ],
      "description": "Você está prestes a dar um grande passo na sua carreira, isso mesmo! Se você tem interesse em DADOS e pensa em virar um Cientista de Dados ou trabalhar com BIG DATA ou ainda se destacar na obtenção de INSIGHTS sobre os dados, então você precisa aprender a utilizar a Linguagem R e o pacote de Visualização de dados SHINY R. Tudo isso você encontra aqui no treinamento: Linguagem R e Shiny R: Caminho de GRANDES INSIGHTS nos Dados\nNesse nosso treinamento, no primeiro módulo você terá acesso a um conteúdo prático da Linguagem R passando pela estrutura básica da linguagem, principais comandos, estruturas de programação básica, além de comandos que facilitam a vida quando estamos utilizando o R para o desenvolvimento de um estudo e exploração dos dados. A linguagem R é muito utilizada para processo de aprendizagem de máquina e mineração de dados, e saber seus fundamentos, será fundamental para você avançar para esse nível de obtenção do conhecimento com o R.\nNa segunda seção, trataremos de uma das principais bibliotecas de visualização e exploração de dados da linguagem R, o pacote SHINY R. De forma prática vamos te apresentar as estruturas que formam esse pacote, os elementos e como você pode construir um painel com filtros, interações, gráficos e muito mais, podendo até utilizar a linguagem HTML para interagir com os dados manipulados com a linguagem R. São muitas as opções e recursos.\nVeja nossa grade curricular e conheça tudo que você irá aprender. Estamos ansiosos para te ensinar e te ajudar a dar um grande passo na carreira.",
      "target_audience": [
        "Estatísticos, Analistas de Banco de Dados, Analistas de Dados, Analistas de BI, Estudantes da área de Dados"
      ]
    },
    {
      "title": "深度学习-Tensorflow实战系列",
      "url": "https://www.udemy.com/course/tyd-tensorflow/",
      "bio": "Tensorflow案例实战",
      "objectives": [
        "掌握tensorflow语法与常规使用方法",
        "掌握计算机视觉核心网络CNN架构",
        "掌握自然语言处理核心网络RNN架构",
        "使用tensorflow进行图像识别任务",
        "使用tensorflow进行图像识别任务",
        "使用tensorflow进行图像识别任务",
        "使用tensorflow进行验证码识别任务",
        "掌握经典神经网络网络架构",
        "掌握网络模型训练可视化展示方法",
        "掌握网络模型设计技巧"
      ],
      "course_content": {},
      "requirements": [
        "掌握深度学习基本概念",
        "熟悉Python"
      ],
      "description": "Tensorflow是谷歌开源的深度学习（包括机器学习）框架，伴随着人公智能业的兴盛其大名早已响彻云霄。本课程从Tensorflow的安装开始讲起，从基本计算结构到深度学习各大神经网络，全程案例代码实战，一步步带大家入门如何使用Tensorflow玩转深度学习。\n\n课程适合刚入门Tensorflow的同学们，全课时代码实战，希望同学们安装好Tensorflow后跟随课程动手完成每一个案例。\n\n\n数据和代码下载麻烦添加微信：digexiaozhushou 或者邮箱：474241623@qq.com  或者微博:迪哥有点愁 均可以联系 感谢大家支持！",
      "target_audience": [
        "人工智能方向爱好者"
      ]
    },
    {
      "title": "오렌지(Orange)를 활용한 코딩 없는 AI 데이터 분석 - Lv.1 데이터 마이닝의 첫 걸음",
      "url": "https://www.udemy.com/course/maso-ds-orange-onc43/",
      "bio": "복잡한 파이썬(python), 느린 엑셀(excel) 데이터 분석은 이제 그만! 노 코드 분석 도구 Orange로 쉽게 하는 데이터 사이언스의 첫걸음",
      "objectives": [
        "노코딩 인공지능 데이터분석 도구인 Orange 활용 방법",
        "데이터 분석의 기본 개념과 가장 대표적인 분석 기법들의 활용 능력",
        "다양한 데이터 소스에서의 데이터 수집 및 처리 프로세스",
        "다양한 데이터 분석 도구의 장단점과 Orange 사용의 이점 파악"
      ],
      "course_content": {
        "학습 내용 안내": [
          "AAA002 학습 내용 안내"
        ],
        "노코드 데이터 분석 도구의 필요성와 설치": [
          "AAA011 노코드 데이터 분석의 이해",
          "AAA021 오렌지 기본 기능 설치",
          "AAA022 오렌지 애드온 설치"
        ],
        "데이터 분석 워크플로우 다루기": [
          "AAA031 오렌지 사용자 인터페이스",
          "AAA032 워크플로우와 정보 패널 다루기"
        ],
        "데이터 분석 모델과 머신러닝 알고리즘: 지도학습과 비지도학습": [
          "AAA041 AI 데이터 분석을 잘 하려면",
          "AAA042 데이터 분석 프로세스",
          "AAA043 데이터 분석 모델과 알고리즘의 이해",
          "AAA044 오렌지3 알고리즘 실습",
          "AAA045 지도학습 비지도학습 강화학습"
        ],
        "다양한 소스에서 데이터 가져오기": [
          "AAA051 다양한 소스에서 데이터 가져오기와 열기",
          "AAA052 데이터 테이블 다루기",
          "AAA053 데이터 페인팅과 데이터 저장"
        ],
        "알고리즘 선택의 핵심, 데이터의 유형과 역할": [
          "AAA061 데이터 역할의 종류와 특징",
          "AAA062 데이터 유형별 특징과 변환"
        ],
        "데이터 샘플링과 정보 설정": [
          "AAA071 여러 데이터 세트의 행과 열 합치기",
          "AAA072 데이터에서 조건에 맞는 행과 열 필터링",
          "AAA073 데이터 샘플링과 모델의 실제 성능 검사"
        ],
        "기술 통계를 활용한 인사이트 도출": [
          "AAA081 기술 통계 분석",
          "AAA082 기술 통계를 활용한 인사이트 도출",
          "AAA083 피벗테이블로 데이터 요약하기"
        ],
        "확증적 데이터 분석": [
          "AAA091 확증적 데이터 분석"
        ],
        "가장 많이 쓰는 3가지 대표 분석법의 노코드 분석과 결과 읽기": [
          "AAA101 카이제곱 검정 – 월마트 맥주와 기저귀",
          "AAA102 T 검정이란",
          "AAA103 T 검정 – 이메일 제목과 기부금 실습",
          "AAA104 회귀분석 – 노벨 경제학상 사회실험"
        ]
      },
      "requirements": [
        "실습 위주의 강의이기 때문에 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기를 함께 준비해주시면 좋습니다.",
        "또한 Windows OS 기반으로 실습이 진행되므로, Windows 환경에서의 강의 수강을 추천해드립니다.",
        "본 강의는 인공지능에 관심이 생긴 누구나 바로 들어 실무에 활용할 수 있는 역량 제공을 목표로 설계된 강의로, 인공지능이나 코딩, 심지어 엑셀 실력까지도 필요하지 않습니다.",
        "오렌지는 무료로 배포되고 있는 소프트웨어이며, 다운로드부터 설치까지 하나하나 가르쳐 드리기 때문에 누구나 손쉽게 인공지능 데이터분석 환경을 구축 가능합니다. Portable 버전을 사용하면 외부 인터넷 연결 없이도 사용 가능하여, 보안 수준이 높은 근무 환경에서도 사용 가능합니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n누구나 할 수 있는 AI 데이터 분석\n개발자, 개발자 하지만 모두 같은 개발자가 아닌 것 알고 계셨나요?\n개발자에도 프론트엔드, 백엔드, 여러 분야의 엔지니어, 그리고 데이터 사이언스 개발자 등\n여러 가지 분야가 존재합니다.\n당연히 각 분야의 수요나 입문 난이도, 그에 따른 평균 연봉의 차이가 존재합니다.\n\n\n그 중에서도 특별한 것은 데이터 사이언스, 특히 머신 러닝/딥러닝 분야를 꼽을 수 있습니다.\n기본적인 코딩 역량에 더해 데이터 사이언스 지식과 인공 지능 역량까지 필요로 하여,\n각종 개발자 대상 조사에서 상위권의 연봉 수준을 차지하고 있습니다.\n물론 연봉 수준이 높다는 것은 일반적으로 아무나 할 수 있다는 뜻이 아닙니다.\n\n\n그러나, 사실은 누구나 인공지능 데이터 분석을 쉽게 수행할 수 있습니다.\n약간의 데이터사이언스 지식과 데이터를 다루는 역량,\n실무에 필요한 분석 기법과 적절한 도구 활용 능력이 있다면\n개발자 없이도 고급 인공지능 데이터 분석을 수행할 수 있습니다.\n\n\n필요한 게 너무 많아 보이신다구요?\n그래서 마소캠퍼스의 이번 강의에서 모든 것을 한번에 준비했습니다.\n이번에 소개할 강의의 사용 툴은 “Orange”입니다.\n누구나 쉽게 분석 데이터를 가져와 만지고, 인공 지능 분석까지 수행할 수 있습니다.\n개발자가 해내는 것 이상으로 자유롭게 의미 있는 분석을 해내는 오렌지는\n무료 도구이면서 각종 네트워크 보안 환경에서도 문제 없이 쓸 수 있는 도구입니다.\n\n\n데이터사이언스 개발자가 부러우셨나요?\n개발 역량이 없이도, 노코딩 도구 오렌지와\n마소캠퍼스에서 제공하는 데이터 분석 역량과 함께라면\n머신 러닝 개발자의 연봉도 꿈이 아닙니다.\n마소캠퍼스의 “코딩 없는 AI 데이터 분석” 과정의 시작인 이 강의에서\n여러분도 몰랐던 여러분의 가능성을 마음껏 펼쳐보시길 바랍니다.\n\n\n강의 특징\n본 강의는 데이터 분석에 입문하고 인공지능 분석 역량을 쉽게 얻고 싶은 모든 분들에게 적합합니다.\nOrange를 통해 복잡한 코딩 없이도 데이터 분석을 수행할 수 있는 능력을 배양할 수 있습니다.\n\n\n입문자부터 전문가까지 사용하는 오렌지!\nOrange는 데이터 사이언스 및 머신 러닝 분야 초보자에게 이상적인 학습 도구로,\n복잡한 데이터 분석 개념을 시각적이고 직관적인 방식으로 제시합니다.\n\n\n\n\n다양한 데이터 분석 및 시각화 도구 제공\nOrange는 사용자가 데이터를 쉬운 방법으로 깊이 있게 분석하고\n복잡한 데이터셋에서 의미 있는 인사이트를 추출할 수 있도록 지원합니다.\n\n\n\n\n분석 대상 데이터 수집부터 시작하는 분석\n엑셀 데이터부터 여러 가지 형식의 파일, 웹 문서 등에서 데이터를 불러와\n분석에 편한 형태로 가공하는 방법을 배워 효율적인 분석이 가능합니다.\n\n\n\n\n실전 데이터 분석 입문\n데이터 분석의 기본 개념부터 실무에 가장 많이 쓰이는 대표적인 분석 방법을 활용하여\n실전 사례 분석을 통한 데이터 사이언티스트 업무를 경험할 수 있습니다.\n\n\n코딩없는 AI 데이터 분석 강의를 듣고 나면\n마소캠퍼스의 코딩 없는 AI 데이터 분석 lv.1 데이터 마이닝 입문 강의는\n데이터 분석의 입문자부터 현직자까지 모든 분들에게 적합합니다.\n데이터 분석 기초 역량\nOrange 업무 환경 세팅 방법\n여러 가지 출처에서 데이터를 확보하고 핸들링하는 기술\n실전 프로젝트를 통해 데이터 분석 실무에 적응\n오렌지와 함께 데이터 사이언스 전문 역량을 키워 보세요.\n더 이상 코딩도, 데이터 분석도 겁내지 마세요!\n\n\n-\n\n\n[ 강 사 소 개 ]\n\n\n최 정 아\n現 마소캠퍼스 콘텐츠랩 이사\n연세대학교 경영학 석사\nYSCEC의 웹마스터로서 연세-게이오(日)-릿쿄(日)-푸단(中) 대학의 YKLP 사업에 초기부터 합류해 성공적으로 론칭시킨 국제 원격교육 전문가입니다. 이후 플레이포럼 편집장으로 자리를 옮겨 MAU 238만 명의 커뮤니티를 7년간 운영하면서 최대 900만 뷰를 달성한 디지털 콘텐츠를 제작했습니다. 언어학, 정보학, 경영학 학위를 소지한 다재다능한 디지털마케팅 전문가로서 데이터를 활용해 디지털 플랫폼에서 최고의 퍼포먼스를 이뤄냈습니다. 효과적인 데이터 마케팅 방법을 다룬 도서를 다수 출간하여 모두 경제경영 분야 베스트셀러에 오른 검증된 지식을 공유하고 있습니다.",
      "target_audience": [
        "데이터 분석에 처음 도전하는 분",
        "복잡한 코딩 없이 고급 데이터 분석까지 마스터하고 싶으신 분",
        "단순 이론이 아닌 실질적인 데이터 분석 역량을 익히고 싶으신 분",
        "엑셀의 한계를 느끼고 더 고급 분석을 원하는 분들"
      ]
    },
    {
      "title": "作曲AIと歌唱AIでつくる本格AIミュージック制作講座【音楽未経験でも簡単にできる初心者向け講座】",
      "url": "https://www.udemy.com/course/ai-music-making/",
      "bio": "AIを活用した作曲と歌唱の基本から応用までを網羅。SOUNDRAW、Synthesizer V、Studio Oneを使った実践的な手法を解説。音楽知識のない初心者でも本格的な楽曲が簡単に短時間で作れるようになります。",
      "objectives": [
        "AIを用いて短時間で高品質な楽曲を作成できるスキルを身につけます。",
        "SOUNDRAWを使ったAIによる作曲の基本的な手法が学べます。",
        "Synthesizer VでのAI歌唱の生成と調整方法が学べます。",
        "Studio Oneを用いた編集、ミックス、マスタリングの基礎が学べます。",
        "AIと人間のクリエイティビティを組み合わせた音楽制作の応用方法が学べます。",
        "AI音楽制作の基本から応用までの一通りのスキルと知識を習得します。"
      ],
      "course_content": {},
      "requirements": [
        "音楽や作曲の基本的な知識は不要です。",
        "ピアノやギターが弾けなくても大丈夫です。",
        "基本的なパソコン操作ができること。",
        "Studio OneやSynthesizer Vの起動にはある程度のPCスペックが必要です。"
      ],
      "description": "このコースでは、AIを活用して誰でも簡単に本格的なミュージックを作成できる方法を学びます。特に初心者の方に向けて、わかりやすく丁寧に解説しています。この講座を受講することで、作曲から歌唱、さらにはミックスとマスタリングまで、一通りの音楽制作プロセスをAIの力を借りて効率よく学べます。\n主要なツールとしては、SOUNDRAWでの作曲、Synthesizer Vでの歌唱、そしてStudio Oneでの編集とミックスがあります。これらのツールを使って、音楽制作の基本から応用までを網羅しています。\n音楽制作は多くの人にとって高いハードルとされがちですが、この講座を通じてAIの力を活用することで、そのハードルを大きく下げることができます。初心者でも短期間で成果を出せるように設計されています。\nさらに、この講座はただの入門コースにとどまらず、応用的なテクニックなどについても触れています。これにより、基本的なスキルを身につけた後も、さらに高度な音楽制作に挑戦することが可能です。\nこのコースは、音楽制作に興味がある方、AIと音楽の融合に興味がある方、そしてこれから音楽制作を始めたいと考えている方に最適です。ネットにつながるパソコンがあれば、どこでも学習できます。是非、この講座で音楽制作の新しい可能性を探してみてください。",
      "target_audience": [
        "AIと音楽の融合に興味がある方。",
        "音楽制作を始めたいが、どう始めればいいかわからない方。",
        "既存の音楽制作方法に飽きた、または新しい方法を探している方。",
        "法的な制約や使用許諾について学びたい方。",
        "AIを用いた音楽制作の業界動向に興味がある方。",
        "音楽制作においてAIがどのように役立つかを理解したい方。",
        "音楽制作を趣味やビジネスとして始めたい方。"
      ]
    },
    {
      "title": "DeepSeek实战指南：一小时入门应用课",
      "url": "https://www.udemy.com/course/deepseek-jt/",
      "bio": "掌握未来AI技术，深度思考与实战应用的完美结合",
      "objectives": [
        "了解DeepSeek的基本概念和核心技术",
        "掌握DeepSeek的优势，理解其在不同领域的应用潜力",
        "学会使用DeepSeek解决实际问题，提升工作效率",
        "提升对人工智能与大数据技术的认识和应用能力"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲",
          "第一章 引言：AI技术的新浪潮"
        ],
        "课程内容": [
          "第二章 10分钟上手实操指南",
          "第三章 深度思考的4大高频应用场景",
          "第四章 实战演练教学",
          "第五章 DeepSeek进阶与未来"
        ],
        "课程回顾": [
          "回顾总结"
        ]
      },
      "requirements": [
        "无经验"
      ],
      "description": "DeepSeek的横空出世打破了对AI的固有认知，如何高效利用DeepSeek在数字化浪潮中脱颖而出，掌控未来AI技术的密钥？\n为此，三节课邀请了AI指北圈发起人Daisy Wang带来本次课程，旨在帮助您全面、深入地掌握 DeepSeek这一前沿AI工具的应用技巧。\n本课程通过系统的理论讲解和丰富的实战演练，培养利用DeepSeek解决实际工作和创作中各类问题的能力，提升在AI辅助工作流程中的效率和质量。无论是从事市场营销、产品管理、数据分析还是其他领域的专业人士，或是对 AI 技术应用感兴趣的爱好者，都能通过本课程获得实际操作经验和创新思维启发，从而在各自的领域中更好地应用 AI 技术，推动业务发展和个人成长。",
      "target_audience": [
        "对AI大模型感兴趣的初学者",
        "希望利用AI提升工作效率的职场人士",
        "对DeepSeek技术感兴趣的开发者"
      ]
    },
    {
      "title": "GPTs及Assistant API快速开发AI应用实战",
      "url": "https://www.udemy.com/course/gptsassistant-apiai/",
      "bio": "GPTs及Assistant API快速开发AI应用实战",
      "objectives": [
        "了解GPTs和助理API的应用：学员将深入学习GPTs的工作原理和应用场景，以及如何利用助理API快速集成AI功能到应用中",
        "扩展技术视野：课程将介绍最新的AI技术和趋势，帮助学员扩展技术视野，了解行业发展动态",
        "建立个人作品集：学员可以将课程中的项目作为自己的作品集，展示给潜在的雇主或合作伙伴，提升个人竞争力",
        "学习本课程将帮助学员掌握最新的技术动态，提升个人竞争力。"
      ],
      "course_content": {},
      "requirements": [
        "零基础"
      ],
      "description": "OpenAI 首届开发者大会为人们带来了一些非常棒的新东西\nGPTs：创建自定义版本的 ChatGPT\nGPT Store 即将上线\nAssistants API：更接近 AI 智能体的体验\n本课程就是针对GPTs及Assistant API快速开发AI应用实战课程\n首先，缺乏实践经验和对AI大模型技术的深入理解是学员面临的首要问题。\n因此，学习GPTs和助理API的实战应用至关重要，它能够帮助学员快速掌握技术精髓，提升应用能力。\n其次，如何有效开发GPTs和API对接，也是学员需要解决的难题。\n学习本课程将提供实际操作的指导，帮助学员顺利完成技术集成。\n此外，随着技术的快速发展，如何保持对最新技术的跟进和更新，同样是学员必须面对的挑战。\n学习本课程将帮助学员掌握最新的技术动态，提升个人竞争力。\n真正做好GPTs及Assistant API快速开发AI应用实战这一方向，对于企业或品牌来说具有显著的价值。\n加强开发人员对大模型技术的学习：通过深入学习GPTs及助理API的应用实战，企业的开发人员能够掌握大模型技术的核心原理和实践技巧，提升自身的技术水平和竞争力。这不仅有助于企业构建更优秀的AI应用，还能够为企业的长远发展培养一批具备创新能力和技术实力的专业人才。\n创新驱动业务发展：GPTs和助理API作为前沿的AI技术，能够为企业带来创新性的应用解决方案，帮助企业在市场竞争中占据有利地位，实现业务的持续发展。\n提升品牌形象与科技含量：快速开发并应用GPTs及助理API的AI应用，不仅展示了企业的技术实力，也提升了品牌的科技含量和形象，增强了消费者对企业的信任和认可。\n现为某AI创业团队创始人，已拿到AI创投种子轮融资\n担任过多所大学编程实训讲师\n十六年软件开发经验\n为什么跟陆通老师学习？\n现为某AI创业团队创始人，已拿到AI创投种子轮融资\n担任过多所大学编程实训讲师\n十六年软件开发经验",
      "target_audience": [
        "AI和机器学习开发者：对于已经有一定基础的AI和机器学习开发者来说，这门课程提供了将GPTs（生成式预训练模型）和助理API应用于实际项目中的实战经验和技巧。它可以帮助他们快速掌握最新的大模型应用开发技术，提升他们的开发效率和项目质量",
        "软件工程师和开发者：对于软件工程师和开发者来说，这门课程是一个了解并应用AI技术的绝佳机会。通过学习如何快速开发AI应用，他们可以在自己的项目中集成AI功能，提升软件的智能性和用户体验",
        "产品经理和创业者：产品经理和创业者需要了解并掌握最新的技术趋势，以便在产品设计和创新中保持领先地位。这门课程可以帮助他们了解GPTs和助理API在AI应用开发中的实际应用，为他们提供灵感和思路，助力产品创新"
      ]
    },
    {
      "title": "Python para Marketing Digital",
      "url": "https://www.udemy.com/course/python-para-marketing-digital/",
      "bio": "Email Marketing, Facebook Ads y Google Form. Análisis y Visualización de datos para Marketing Digital.",
      "objectives": [
        "Programar en Python",
        "Automatizaciones con Python",
        "Análisis de datos",
        "Herramientas para hacer Email Marketing",
        "Creación de Encuestas",
        "Análisis de Audiencias",
        "Facebook Ads"
      ],
      "course_content": {
        "Programación en Python": [
          "Recursos",
          "Introducción",
          "Google Colab",
          "Variables en Python",
          "Estructuras de datos",
          "Métodos útiles",
          "Condicionales",
          "Iteración",
          "Funciones y Funciones Recursivas",
          "Lectura y Escritura de Archivos en Python"
        ],
        "Analisis de datos con Python": [
          "Series de datos",
          "¿Que es un DataFrame?",
          "Lectura de Archivos CSV",
          "Lectura de HTML con Pandas",
          "Métodos útiles",
          "Uso de GroupBy",
          "Tratamiento de valores faltantes",
          "Manejo de Variables Categóricas",
          "ScikitLearn",
          "Clusters"
        ],
        "Visualización de datos con Python": [
          "Gráficos de Barras",
          "Gráficos circulares",
          "Gráficos de Puntos",
          "Histograma",
          "Representación de Regresiones Lineales con Seaborn",
          "Regresiones no Lineales con Seaborn",
          "Representaciones de Multiples Variables",
          "Mapas de Calor",
          "Ejemplos de Gráficos con Seaborn",
          "Nubes de Palabras"
        ],
        "Encuestas": [
          "Creación de Encuestas con Google Form",
          "Análisis de Encuestas",
          "Limpieza de datos 1",
          "Limpieza de datos 2",
          "Analisis descriptivo",
          "Segmentación inteligente"
        ],
        "Email Marketing": [
          "Que es Email Marketing",
          "Introducción a Mailchimp",
          "Email Marketing con Mailchimp",
          "Creación de Landing Page con Mailchimp"
        ],
        "Campañas en Facebook": [
          "Creación cuenta Publicitaria en Facebook",
          "Pixel de Facebook",
          "Creación de Camapañas en Facebook",
          "Analisis de Campañas"
        ],
        "Articulos de Actualizacion": [
          "Tendencias Marketing 2025 con IA y Python"
        ]
      },
      "requirements": [
        "Ser una persona proactiva en el aprendizaje"
      ],
      "description": "¿Quieres aprender como mejorar tus campañas de  Marketing? ¿ Estas interesado en Aplicar Python en el Marketing Digital?\nEn este curso aprenderás como optimizar tus campañas de marketing y realizar análisis mas avanzado utilizando herramientas de Inteligencia Artificial y Analítica de datos.\nEl curso está estructurado  de manera totalmente práctica con multitud de ejemplos y ejercicios para que puedas desarrollar tus habilidades de la mejor manera. A lo largo del curso iremos avanzando desde la parte más básica de programación en Python,  luego veremos diferentes herramientas de marketing digital y finalmente uniremos los conocimientos de ambos mundos logrando así optimizar y analizar de forma mas precisa nuestras campañas y encuestas.\nLa estructura del curso es:\nProgramación Básica en Python, pensado para todas aquellas personas que quieren aprender Python\nUso de Pandas, veremos una de las librerías mas empleadas en Python para el tratamiento y manipulación de datos\nTécnicas de Clustering usando Scikit-learn\nVisualización de datos con Matplotlib y Seaborn, estudiaremos los diferentes gráficos que existen, cuales son los mejores en función de los datos que tenemos y como podemos implementarlo de manera sencilla.\nCreación y Análisis de encuestas con Google Form ,veremos como saber que quieren nuestros potenciales clientes e implementaremos segmentaciones inteligentes para optimizar nuestras campañas.\nEmail Marketing, aprenderemos como lanzar campañas de email marketing y analizarlas\nFacebook Ads con todo el conocimiento aprendido veremos como crear, medir y optimizar nuestras campañas publicitarias en Facebook",
      "target_audience": [
        "Profesionales del marketing digital que quieran aprender a programar",
        "Personas interesadas en automatizar procesos de venta",
        "Estudiantes de Informática",
        "Personas interesadas en Marketing Digital"
      ]
    },
    {
      "title": "Inteligencia Artificial para Programadores con Prisa",
      "url": "https://www.udemy.com/course/inteligencia-artificial-para-programadores-con-prisa/",
      "bio": "Introducción a la inteligencia artificial",
      "objectives": [
        "Aprenderás de manera sencilla los fundamentos de inteligencia artificial y aprendizaje de máquinas",
        "Implementarás de manera clara y conscisa algoritmos de inteligencia artificial para aplicaciones diversas.",
        "Identificarás con un lenguaje accesible la metodología adecuada para desarrollar, analizar, entrenar y probar los algoritmos",
        "Abordarás los diferentes tópicos introductorios con diferentes bases de datos y serás capaz de implementar tus propios algoritmos en tu área de interés"
      ],
      "course_content": {
        "Objetivos e Introducción al curso": [
          "Bienvenida",
          "Objetivos y Metodología de Enseñanza",
          "Introducción y contenido del curso"
        ],
        "Objetivos y metodología de trabajo": [
          "2.1. Introducción a IA y entorno de trabajo",
          "2.2. Tipos de algoritmos de IA"
        ],
        "Ciencia de datos": [
          "3.1. Manejo de datos y su importancia",
          "3.2. Problemas de calidad en los datos",
          "3.3. Imputación de datos",
          "3.4. Normalización",
          "3.5. Datos sintéticos"
        ],
        "Aprendizaje Máquina": [
          "4.1. Tipos de aprendizaje y aprendizaje máquina",
          "4.2. Medidas de distancia",
          "4.3. Metodología de desarrollo de aprendizaje máquina",
          "4.4. Reducción de dimensionalidad",
          "4.5. Entrenamiento y pruebas",
          "Validación cruzada",
          "4.6. Métodos de regresión",
          "4.7. Métricas de error para datos continuos",
          "4.8. Gradiente descendente",
          "4.9. Aprendizaje automático por k-medias",
          "4.10. Aprendizaje supervisado por vecinos cercanos (KNN)",
          "4.11. Árboles de decisión (ID3)",
          "4.12. Clasificación por bosques aleatorios"
        ],
        "Redes neuronales": [
          "5.1. Fundamentos de redes neuronales",
          "5.2. Perceptrón simple",
          "5.3. Perceptrón multicapa (MLP)",
          "5.4. Redes profundas",
          "5.5. Redes profundas convolucionales (CNN)",
          "5.6. Redes profundas recurrentes (RNN)"
        ],
        "Factores que afectan el rendimiento de un algoritmo": [
          "6.1. Preparación de los datos",
          "6.2. Velocidad de la predicción y capacidad de reentrenamiento",
          "6.3. Elección de hiperparámetros y selección del modelo",
          "6.4. Mejorar la exactitud y rendimiento del algoritmo"
        ]
      },
      "requirements": [
        "Conocimientos básicos de programación y fundamentos de python 3.x"
      ],
      "description": "*Importante: El 100% de las ganancias del presente curso se destinarán a la Asociación Mexicana de Software Embebido AC (AMESE), que es una asociación sin fines de lucro que entre otras cosas, ayuda a la formación STEM de niñas, niños, jóvenes y universitarios.\n\n\nEste curso de fundamentos de inteligencia artificial para programadores con prisa se pensó con el objetivo de presentar de manera sencilla el conocimiento adquirido que se remonta prácticamente desde que comencé la maestría en el año 2001, antes de que la inteligencia artificial fuera tan popular. Posteriormente, cuando terminé mi doctorado en el área de Sistemas Inteligentes, también en la Universidad de Liverpool (Inglaterra) en 2005, noté que hay un crecimiento enorme, pero también un gran desconocimiento de por dónde empezar de manera sencilla.\n\n\nEl área de inteligencia artificial (IA) es muy amplia y está teniendo en los últimos años un crecimiento exponencial. Sin embargo, parte de las razones por las cuales se realiza este libro en específico se debe a que habiendo tantos métodos, algoritmos, problemas y aplicaciones que pueden ser abordados desde muchas perspectivas y, por un lado, se vuelve complejo saber por dónde empezar y qué conocimientos se deben de tener al respecto, mientras que, por otro lado, en ocasiones solo se descarga un código y se ejecuta sin saber a ciencia cierta si lo que se está haciendo o si es lo correcto para ese problema en específico.\n\n\nEste curso introductorio refleja algunos temas importantes mismos que se abordan con un lenguaje accesible para poder iniciar al lector en esta fascinante área que es la inteligencia artificial, y que considero se deben de explicar. Existen más algoritmos que no se abordan en el presente curso por cuestiones de número de horas y número de prácticas.\n\n\nPor último, me gustaría aclarar que las prácticas, ejercicios y tips vertidos en este curso son solo una forma de abordar los temas de manera sencilla. Hay muchos otros estilos de programación, otras librerías y otras metodologías para explicar y programar los temas.\n\n\nAl respecto, quiero comentar que traté de realizarlo de manera práctica y clara y las prácticas están realizadas utilizando diferentes estilos de programación con ese mismo propósito, espero haber logrado mi objetivo de atraer tu interés por esta fascinante área.",
      "target_audience": [
        "Estudiantes de áreas de ingeniería y ciencias",
        "Profesionistas que deseen adentrarte en el área de inteligencia artificial"
      ]
    },
    {
      "title": "NLU - Natural Language Understanding mit PyTorch und Fastai",
      "url": "https://www.udemy.com/course/nlu-natural-language-understanding-mit-pytorch-und-fastai/",
      "bio": "Wie du mit künstlicher Intelligenz Texte und Sprache automatisch verstehen und analysieren kannst.",
      "objectives": [
        "Lerne, wie künstliche Intelligenz eingesetzt werden kann, um Text zu verstehen",
        "Wie kann ein neuronales Netz Texte verstehen?",
        "Wie kannst du mithilfe von deep learning ein Sprachmodell aufbauen?",
        "Implementiere RNNs (Recurrent Neural Networks) mit PyTorch und fastai",
        "Programmiere Multi-Layer Recurrent Neural Networks und optimiere so dein RNN Netzwerk",
        "Programmiere LSTMs (Long Short Term Memory Cells) mit PyTorch und fastai",
        "Lerne, wie du mit einem neuronale Netz Texte generieren lassen kannst!",
        "Lerne, was Tokenization bedeutet und warum du dieses Konzept für NLP verstehen solltest",
        "Lerne, was Vanishing Gradients bedeutet und wie du das Problem beheben kannst",
        "Programmiere dein eigenes Sprachmodell für Deutsch auf Basis von Wikipediatexten",
        "Erstellen deinen eigenen Klassifizierer für deutsche Twitter Postings"
      ],
      "course_content": {},
      "requirements": [
        "Du kennst dich mit der Basis-Python Programmierung aus",
        "Du hast bereits Erfahrung in der Entwicklung von Systemen für künstliche Intelligenz",
        "Du konntest bereits Erfahrungen mit PyTorch und oder fastai sammeln",
        "Du kannst mit Google Colab umgehen bzw. hast Zugang zu einer GPU"
      ],
      "description": "Natural Language Understanding (die Verarbeitung natürlicher Sprache) ist ein Teilbereich der künstlichen Intelligenz (Artificial Intelligence), der darauf aufbaut, menschliche Sprache zu verstehen und zu manipulieren.\nDie Techniken aus NLU (Natural Language Understanding) bzw. NLP (Natural Language Processing) zielen darauf ab, die Lücken zwischen menschlicher Kommunikation und den Sprachverarbeitungsfähigkeiten von Computersystemen zu schließen. Dafür setzt man eine große Anzahl verschiedener Disziplinen ein, wie unter anderem Informatik oder auch Linguistik.\nDiesen Kurs solltest du buchen, wenn du:\nselbst Texte automatisiert analysieren möchtest\nSysteme mit künstlicher Intelligenz entwickeln möchtest, die Texte klassifizieren können\nendlich verstehen willst, was sich hinter den Bezeichnungen LSTM (Long Short Term Memory) und auch RNN (Recurrent Neural Networks) verbirgt\nselbst erkennen willst, was es bedeutet, wenn die Gradienten eines neuronalen Netzes explodieren (exploding gradients) oder verschwinden (vanishing gradients).\neinen Klassifizierer für Bewertungen von Kinofilmen implementieren möchtest, der selbständig positive von negativen Reviews unterscheiden kann.\nWeitere Themen, die wir in diesem Kurs betrachten werden sind:\nTokenization, Numericalisation, Backpropagation in Time (bppt), Sub Batches, Multilayer RNNs, u.v.m.\nDie Verarbeitung natürlicher Sprache ist eine Technologie, die sich in den letzten Jahren aufgrund von immer größeren Datenmengen und höheren Rechenleistungen, enorm weiterentwickelt hat. Anwendungsgebiete für NLU (Natural Language Understanding) sind Analyse und Klassifizierung von Texten (automatische Bewertung von Produkt-Reviews), automatisierte Übersetzung von einer Sprache in eine andere (machine translation). Denn Menschen kommunizieren (schriftlich, wie mündlich) in unterschiedlichen Sprachen. Mithilfe von automatisierten Übersetzungen (machine translation) verringern die Grenzen zwischen Menschen. Doch auch hinsichtlich der Kommunikation zwischen Computersystemen und Menschen ist ein großer Anwendungsbereich von natural language understanding.  Die Sprache der Computer ist Maschinencode oder Maschinensprache - für die allermeisten der Menschen beinahe unverständlich. Doch auf der untersten Schicht besteht Kommunikation zwischen Computersystemen nicht aus Worten, sondern nur auf binären Werten (also 0 oder 1). Aus diesem Muster werden logische Aktivitäten abgeleitet.\nAus diesem Grund muss Sprache auch in diese Binärsprache übersetzt werden. Ein Computer kann sprachliche Befehle, \"Alexa, sag mir wie das Wetter morgen wird\" nicht direkt verstehen. So ein Befehl muss in die Sprache der Computer übersetzt werden. Dies funktioniert aber nicht mithilfe von einzelnen Anwendungen. Solche Sprachbefehle und Sprachsteuerungen gibt schon seit Jahrzehnten, doch diese mussten ganz genau auf das System abgestimmt werden. Erst der Einsatz von deep learning Technologien (neuronale Netze) ermöglichte Computersystemen mithilfe von künstlicher Intelligenz, tatsächlich sprachliche Befehle von unterschiedlichen Sprechern zu verstehen.\nDafür ist es jedoch erforderlich, dass aus solchen sprachlichen Befehlen zuerst die Struktur der Sprache herausgelöst wird. Was ist die gewünschte Handlung? Wer ist der Adressat der geplanten Handlung? Künstliche Intelligenz und Machine Learning hat es mit Techniken aus Natural Language Understanding ermöglicht, diese Strukturanalyse innerhalb von wenigen Sekunden durchzuführen und die dafür erforderliche Handlung in Maschinencode umzuwandeln.\nWarum ist NLP / NLU ein so wichtige Disziplin im Bereich der künstlichen Intelligenz so wichtig?\nErst die Anwendung von NLP / NLU Techniken versetzen Computer in die Lage, interaktiv mit menschlichen Anwendern in deren Sprache zu kommunizieren. So können Computer durch Natural Language Processing Texte lesen und generieren, gesprochene Sprach interpretieren, ein Sentiment über einen Text berechnen, Texte automatisiert zusammenfassen.\nTextverarbeitung mittels Natural Language Understanding ist deshalb eine derart wichtige Disziplin innerhalb von künstlicher Intelligenz, weil unstrukturierte Daten in Form von Text inzwischen global die größte Datenmenge repräsentiert. Im Bereich NLU sind Systeme künstlicher Intelligenz inzwischen in der Lage, selbständig Informationen zu korrekter Rechtschreibung, Grammatik und Syntaxregeln aus diesen unstrukturierten Informationen zu extrahieren. Hier kann Natural Language Understanding von unsupervised und semi-supervised learning Techniken profitieren.\nAnwendungsgebiete für Natural Language Understanding\nThemenerfassung und Themenmodellierung: Künstliche Intelligenz kann die Kernaussage von Texten zusammenfassen und extrahieren und so die unstrukturierten Texte in Gruppen zusammenfassen.\nKontextuelle Analyse: Aus unstrukturiertem Text wird mithilfe künstlicher Intelligenz die innere Struktur eines Textes erfasst.\nKategorisierung von Inhalt: Unstrukturierte Texte werden mithilfe künstlicher Intelligenz klassifiziert und bestimmten Kategorien zugewiesen - ähnlich wie die Klassifizierung von Bildern.\nSpeech-to-Text und Text-to-Speech: Konvertierung von gesprochenem Wort zu schriftlichen Text und umgekehrt - mithilfe künstlicher Intelligenz\nMachinelle Übersetzung (machine translation): Ein KI-System kann so auch in Echtzeit gesprochenes Wort oder Text von einer Sprache in eine anderen übersetzen.\nZusammenfassung von Texten: Mithilfe von Natural Language Processing können Kernphrasen oder Sätze aus Texten extrahiert werden, aber auch automatisch neue Zusammenfassungen in einer bestimmten Länge auf Basis von bestehenden Dokumenten generiert werden.\nNatural Language Understanding im Alltagskontext\nDie Techniken von Natural Language Understanding finden wir bereits in einer Vielzahl von Anwendungen und Situationen im täglichen Umgang mit Computern.\nDie Textinhalte von E-Mails werden mithilfe von Bayesschen Spam Filtern analysiert und klassifiziert. - Ist Ihnen auch schon aufgefallen, dass die Anzahl an zugestellten Spam-Mails in den vergangenen Jahren zurückgegangen ist? Ein Triumph von Natural Language Understanding Einsatz.\nSie können sich Sprachnachrichten von Ihrer Mobilbox direkt als Textnachricht oder E-Mail zusenden lassen. Hier ist NLU aus diem Bereich Speech-to-Text im Einsatz.\nWurden Sie auf einer Webseite bei der Navigation automatisch unterstützt, indem relevante Inhalte automatisch vorgeschlagen wurden? Ja, mithilfe von Natural Language Understanding wurden die Themen und Inhalte automatisch extrahiert und mit den von Ihnen bereits angesehenen Dokumenten abgeglichen.\nDas korrekte Verständnis für Sprache und Texte ist also nicht nur für den menschlichen Anwender ein wichtiges Element zur erfolgreichen Kommunikation. Natural Language Understanding (NLU) bzw. Natural Language Processing (NLP). Die Techniken von NLU gehen über das reine Verständnis der Struktur von Sprache hinaus, es sollen Mehrdeutigkeiten aufgelöst werden, Wörter in den gesamten Kontext gesetzt werden. Künstliche Intelligenz auf Basis von NLU-Algorithmen bearbeiten außerordentlich komplexe Themenstellungen wie semantische Interpretation von Text, die beabsichtigte Bedeutung vom geschriebenem oder gesprochenem Wort. NLU ermöglicht das Erkennen von kontextabhängiger Interpretation von Dokumenten und Rückschlüssen, wie wir die sprachliche Artikulation von Menschen verstehen können.\nDie Weiterentwicklung von NLP zu NLU hat bereits eine Menge an positiven Effekten für Verbraucher und Unternehmen gebracht. Ein Algorithmus auf Basis künstlicher Intelligenz, die in der Lage ist, Nuancen und Bedeutungen der Intonation menschlicher Sprache in verschiedensten Bereichen wie Medizin, Rechtswesen, Bildung, Technik, etc. verstehen und interpretieren kann bringt enorme Fortschritte hinsichtlich der Mensch-Maschine-Kommunikation mit sich. Vor allem auch deshalb, weil unstrukturierte Texte inzwischen die größte Menge an Daten weltweit darstellen und weiter exponentiell wachsen.\nMit Natural Language Understanding haben wir ein Werkzeug an der Hand, diese riesige Datenmenge sinnvoll zu analysieren und für unsere Anwendungen künstlicher Intelligenz zu nutzen.",
      "target_audience": [
        "Python-Entwickler",
        "Entwickler, die Systeme zur automatisierten Verarbeitung von geschriebenem Text programmieren wollen"
      ]
    },
    {
      "title": "Derinlemesine Python 4 : AI Natural Language Processing",
      "url": "https://www.udemy.com/course/derinlemesine-python-ai-natural-language-processing/",
      "bio": "Artificial Intelligence; NLTK, Spacy, Gensim ile NLP; Sklearn, Tensorflow & Keras ile Machine Learning - Text Features",
      "objectives": [
        "NLP (Natural Language Processing - Doğal Dil Süreçleme) ile Yapay Zeka ve Veri Bilimi alanında yazı türü verilerle çalışma."
      ],
      "course_content": {
        "NLTK - Tabanlılar (Basics)": [
          "Dizgecikleme (Tokenization)",
          "Süzme (Filter)",
          "Olağanlaştırma (Normalization)",
          "Eş Anlamlı (Synonym) & Karşıt Anlamlı (Antonym)",
          "N-Basıç (N-Gram)",
          "Sıklık Dağılımı (Frequency Distribution)"
        ],
        "POS (Part Of Speech - Sözcük Türleri)": [
          "Sözcük Türleri (Part Of Speech)",
          "Topaklama (Chunking) - Yalın",
          "Topaklama (Chunking) - Karmaşık"
        ],
        "Derlem / Bütünce (Corpus)": [
          "Tabanlılar (Basics)",
          "Ulamlı (Categorical)",
          "Sıklık (Frequency)",
          "Koşullu Sıklık (Conditional Frequency)",
          "Uyarlanmış Bütünce (Custom Corpus)"
        ],
        "NLTK - Özellikler ( Features)": [
          "Özellik Adları (Feature Names)",
          "Özellik Takımları (Feature Sets) - İkilik (Binary)",
          "Özellik Takımları (Feature Sets) - Sıklık (Frequency)"
        ],
        "Sınıflandırma / Kökleşileme (Classification)": [
          "Toy Bayesçi Kökleşileme (Naive Bayesian Classification)",
          "Tüm Kökleşileyiciler (All Classifiers)",
          "Sklearn Kökleşileyicilerini Kullanma"
        ],
        "NLTK - Proje": [
          "En Yaygınlar (Top Common)",
          "Kökleşileme (Classification)",
          "BOW (Bag Of Words - Sözcük Torbası)",
          "N-Basıçlar (N-Grams)"
        ],
        "Spacy - Tabanlılar (Basics)": [
          "Kurulum (Installation)",
          "Dizgecik (Token)",
          "Nesneler (Objects)",
          "Ayrıştırma (Parsing)",
          "Görsellik - Displacy"
        ],
        "Spacy - İleri (Advanced)": [
          "Eşleştirici (Matcher) - Dizgecik (Token)",
          "Eşleştirici (Matcher) - Çağrılabilir (Callable)",
          "Eşleştirici (Matcher) - Deyiş (Phrase)",
          "Ayrıştırma (Parsing)",
          "Yöney (Vector)"
        ],
        "Gensim - Tabanlılar (Basics)": [
          "Sözlük (Dictionary)",
          "BOW (Bag Of Words - Sözcük Torbası)",
          "TF*IDF (Adalgı Sıklığ * Evrik Belge Sıklığı)"
        ],
        "Gensim - İleri (Advanced)": [
          "Doc2Vec (Belgeden Yöneye)",
          "LDA (Latent Drichlet Allocation - Örtülü Driklet Yerayırması)"
        ]
      },
      "requirements": [
        "Temel düzeyde Python dili, Veri Bilimi (Data Science) gerekiyor. Ancak yazı özellikleriyle makine öğrenmesi yapanlar için Machine Learning (Düzenek Öğrenmesi) de gerekli."
      ],
      "description": "Bu eğitimde Python ile Artificial Ingelligence (Yapay Zeka) ve Natural Language Processing (Doğal Dil Süreçleme) anlatılmaktadır. NLTK , Spacy & Gensim gibi seçenekler de anlatılmaktadır. Corpus (Bütünce/Derlem), N-Grams (N-Basıçlar), Parts Of Speech (Sözcük Türleri), Bag of Words (Sözcük Torbası) gibi konular kapsanmaktadır. Yazı özelliklerinin sökülmesi gibi Machine Learning konuları da içerikte yer almaktadır. Skit-Learn, TensorFlow & Keras araçlarının yazı ile ilgili kesimleri açıklanmaktadır.\nEğitim, doğal dil süreçleme işlevlerini kapsadığı gibi yazı türü verilerin yapay zeka için hazırlanması anlamına gelen yazı özellik sökme (text feature extraction) konularını da içermektedir. Bir yönüyle yapay zekanın yazı türü veriler için uygulanması anlamında ileri bir konusu olarak işlev görmektedir.\nNLTK ile konulara başlanmaktadır. Temel özelliklerden dizgecikleme (tokenization), süzme (filter), olağanlaştırma (normalization), eşanlamı (synonym) ve karşıtanlamlı (antonym), n-basıç (n-gram), sıklık dağılımı (frequency distribution) anlatılmaktadır.\nİçerikte POS (Part of Speech - Sözcük Türleri) ile ilgili işlemler kapsanmaktadır. Ek olarak topaklama / chunking gibi konular anlatılmaktadır.\nBir Corpus (Bütünce/Derlem) oluşturma, kategorisiz (uncategorized) ve kategorili (categorized) kullanım, koşullu sıklık (conditional frequency) ve koşulsuz sıklık (uncondiontal frequency) gibi konular işlenmektedir. Buna ek olarak uyarlı bütünce / custom corpus oluşturulması da gösterilmektedir.\nNLTK ile özelllik / feature elde edilmesi anlatılmaktadır. Sonrasında özellik takımları (feature sets) için gerek ikilik / binary gerekse sıklık / frequency ile çalışılması gösterilmektedir.\nNLTK ile sınıflandırma / classification konusu işlenmektedir. Burada NLTK içinde bulıuna Naive Baesian gösterilmekte  ve tüm kökleşileme algoritmalarıyla işlemler anlatılmaktadır. NLTK ile SKLearn kütüphanesindeki sınıflandırıcıların kullanımı gösterilmektedir.\nİçerikte NLTK içe bir proje koyulmuştur. İçinde en yaygınlar / top common bulma, kökleşileme / classification, BOW (Bag of Words - Sözcükler Torbası) , N-Grams (N-Basıçlar) konuları uygulamalı olarak gösterilmektedir.\nNLTK dışında Spacy ile işlemler gösterilmektedir. Burada dizgecik / token, nesneler / objects, ayrıştırma / parsing ve görsellik / displacy gibi temel konular kapsanmaktadır. Sonrasında ileri konulardan eşleştirici / matcher kullanımı dizgecik / token; çağrılabilir / callable ve deyiş / phrase anlatılmaktadır. Son olarak ayrıştırma / parsing ve yöney / vector işlenmektedir.\nİçeriğe NLTK dışındaki araçlardan Gensim de eklenmiştir. Burada sözlük / dictionary; BOW (Bag of Words - Sözcükler Torbası) ve TF*IDF (Adalgı Sıklığ * Evrik Belge Sıklığı) anlatılmaktadır. Gensim ile ileri konulardan Doc2Vec (Belgeden Yöneye) ve LDA (Latent Drichlet Allocation - Örtülü Driklet Yerayırması) işlenmektedir.\nSKLearn adlı kütüphanede yazı / text işlemleriyle ilgili konular içeriğe koyulmuştur. Yöneyleyici (Vectorizer), SKLearn & NLTK Birlikte Kullanımı ve TF*IDF (Adalgı Sıklığ * Evrik Belge Sıklığı)  gibi konular bulunmaktadır. İleri konulardan Kökleşileyici (Classifier),  Boruyolu (Pipeline) ve Değerlendirme (Evaluation)  anlatılmaktadır.\nİçerikte Tensorflow - Yazı Özellikleri (Text Features) & Sinir Ağı (Neural Network) yer almaktadır. Buradaki konular şunlardır: Yazı Yükleme (Text Loading),  Hazır Veritakımı Yükleme İşlevleri, Özyineleyen Sinir Ağı (Recurrent Neural Network - RNN) ve Önsüreçleme (Preprocessing).\nSon bölümde Requests / İstekler adlı kütüphane kullanılarak kazıma / scraping işlemleri anlatılmaktadır. Burada HTTP üzerinden veri edinme (GET); HTML içerisindeki bağ (link) öğelerinin ayrıştırılması; emekleme / crawling ile bağlanarak içine girip o belgeleri de derinlemesine alma ve yerel bilgisayarda belli bir konuma indirme (downoad) işlemleri göstirilmektedir.\nEğitim tümüyle uygulamaları olarak yapılmaktadır. Kuramsal/Teorik konular yeri geldikçe, özet olarak verilmektedir. Python dilindeki betikliklerle yazı türü verilerle yapay zeka uygulamalarının nasıl geliştirildiği anlatılmakta; kullanılan algoritmaların nasıl geliştirildiği ve nasıl çalıştığı konusu, yalnızca onları kullanabilmek için gerektiği ölçüde anlatılmaktadır. Her yöntemin ya da algoritmanın çalışması kendi başına, bilgisayar bilimi ve matematiğin konusu olduğu için burada çok ayrıntılı olarak gösterilmemektedir.\nEğitimde Python dili ve Veri Bilimi (Data Science) en başından anlatılmamakta, temel düzeyde bilindiği var sayılmaktadır. Öte yandan bu konular yeri geldikçe uygulama olarak gösterildiği için, bu eğitimle Python ve Veri Bilimi bilgilerinin ilerletilmesi sağlanmaktadır. Bu nedenle, yapay zekayla ilgilenmeyenleri de Python dilini geliştirmek için bu eğitimi almalarını öneriyoruz. Başlardaki doğal dil süreçleme konuları için yapay zeka ya da makine öğrenmesi bilgileri gerekmese de son bölümde bu konulara girildiği için Machine Learning konusu, an azından temel düzeyde bilinmesi yararlı olur.\n\n\nEğitimdeki örnekleri GitHub sitesinde godoro-education kullanıcısı altında python-natural-language-processing adlı depoya katıldıktan sonra görebilirsiniz.",
      "target_audience": [
        "Veri Bilimi ve Yapay Zeka konusunda doğal diller ve yazı türü verilerle çalışmak isteyenler. Makine Öğrenmesi bilgisini bu alanlarda geliştirmek isteyenler."
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第 31 部 多模態融合：視覺+語言模型深入解析 (上)",
      "url": "https://www.udemy.com/course/generative_ai_31/",
      "bio": "關於多模態模型，Siglilp，Vision Transformer，Batch Norm，Layer Norm，注意力機制",
      "objectives": [
        "深入瞭解什麼是對比學習",
        "深入瞭解為什麼需要SigLIP & 什麼是Vision Transformer",
        "學會如何使用 Pytorch 編寫Siglilp Vision Transformer",
        "深入瞭解什麼是 Batch Norm 和 Layer Norm",
        "學會如何編寫多模態模型的注意力機制代碼"
      ],
      "course_content": {
        "課程環境準備": [
          "課程工具準備",
          "如何使用uv 作為包管理器和項目管理工具"
        ],
        "什麼是對比學習 & 為什麼需要SigLIP & 什麼是Vision Transformer": [
          "什麼是對比學習 & 為什麼需要SigLIP & 什麼是Vision Transformer"
        ],
        "如何使用 Pytorch 編寫Siglilp Vision Transformer": [
          "如何使用 Pytorch 編寫Siglilp Vision Transformer",
          "如何處理 Embedding 到Patches & 什麼是 Batch Norm 和 Layer Norm",
          "如何編寫多模態模型的注意力機制代碼"
        ],
        "如何處理輸入 Image 和輸入 Prompt 並合併在一起": [
          "如何處理輸入 Image 和輸入 Prompt 並合併在一起",
          "如何製作 PaliGemma 多模態模型並導入權重為推理做準備"
        ]
      },
      "requirements": [
        "一臺電腦"
      ],
      "description": "一般 AI 模型都是只能處理某個功能。例如，語言模型 & 圖像模型。\n而隨著 AI 時代的發展，多模態模型誕生了。\n它能够同時處理多種不同的輸入信息。\n\n\n本課程將介紹如下將 用戶的 Prompt & 圖像輸入，分別用 Vison Transformer 和 Tokenizer 捕捉當中的內容，同時，結合兩種的Embedding ，並輸入到 Gemma 模型當中處理。\n\n\n課程內容如下：\n什麼是對比學習 & 為什麼需要SigLIP & 什麼是Vision Transformer\n如何 Pytorch 編寫Siglilp Vision Transformer\n如何處理 Embedding 到Patches & 什麼是 Batch Norm 和 Layer Norm\n如何編寫多模態模型的注意力機制代碼\n如何處理輸入 Image 和輸入 Prompt 並合併在一起\n如何製作 PaliGemma 多模態模型並導入權重為推理做準備",
      "target_audience": [
        "AI/機器學習工程師 (AI/ML Engineers)",
        "數據科學家 (Data Scientists)",
        "深度學習研究員 (Deep Learning Researchers)",
        "對生成式 AI 有濃厚興趣的開發者 (Developers Interested in Generative AI)",
        "學生 (Students)"
      ]
    },
    {
      "title": "빅데이터분석기사 완전정복 필기편 : Part.2 빅데이터 탐색(2)",
      "url": "https://www.udemy.com/course/part2-2-l/",
      "bio": "빅데이터 탐색 통계기법 이해하기! 기술통계부터 추론통계까지 함께 배워봅시다.",
      "objectives": [
        "빅데이터 탐색",
        "통계기법의 이해",
        "기술통계",
        "추론통계",
        "예상문제 풀이",
        "데이터 탐색 과목 마무리 문제 풀이"
      ],
      "course_content": {
        "빅데이터 탐색 : 통계기법의 이해(기술통계)": [
          "기술통계(기술통계의 개념, 특징, 대푯값 개념, 중위수, 평균값, 최빈수, 사분위수 개념 및 특징, 공식)",
          "기술통계(산포도 개념, 분산, 표준편차, 범위, IQR, 사분편차, 변동계수 개념 및 특징, 공식, 첨도, 왜도 그래프)",
          "기술통계(공분산 개념, 특징, 종류, 공식, 해석방법, 상관관계 개념, 특징, 방법)",
          "기술통계(표본추출 정의, 기법, 단순무작위추출, 계통추출, 층화추출, 군집추출 개념 및 특징)",
          "기술통계(확률분포 개념, 조건부 확률 개념, 공식, 예시, 베이즈 정리 개념, 공식, 예시)",
          "기술통계(확률 개념, 조건부 확률 개념, 공식, 예시, 베이즈 정리 개념, 공식, 예시, 이상확률분포, 연속확률분포 개념, 종류)",
          "기술통계(최대우도법의 개념, 특징, 표본분포 개념 및 용어 4가지, 표본분포와 관련된 법칙 2가지)",
          "기술통계 예상문제 풀이-1",
          "기술통계 예상문제 풀이-2",
          "기술통계 예상문제 풀이-3"
        ],
        "빅데이터 탐색 : 통계기법의 이해(추론통계)": [
          "데이터 탐색-추론통계(추론통계의 개념, 특징, 점 추정 개념, 만족 조건 4가지, 구간 추정 개념, 신뢰수준, 신뢰구간 개념, 특징)",
          "데이터 탐색-추론통계(단일 모평균 추정 방법, 모분산이 알려진 경우, 알려져 있지 않은 경우, 신뢰수준 Z-분포값, T분포, 자유도 n-1)",
          "데이터 탐색-추론통계(가설의 정의, 귀무가설, 대립가설 개념, 가설검정 개념 절차, p-value 개념, 귀무가설의 채택과 기각의 의미)",
          "데이터 탐색-추론통계(가설검정 방법, 단측 검정, 양측검정 개념, 특징, 제1종 오류, 제2종 오류 개념, 용어)",
          "데이터 탐색-추론통계 예상문제 풀이-1",
          "데이터 탐색-추론통계 예상문제 풀이-2",
          "데이터 탐색 과목 마무리 문제 풀이-1",
          "데이터 탐색 과목 마무리 문제 풀이-2"
        ]
      },
      "requirements": [
        "\"한번에 합격하겠다는 의지! 데이터 통계와 데이터 보안 관련 분야 지식이 있으면 좋습니다.\""
      ],
      "description": "안녕하세요, ITGO 입니다.\n\n\n본 강의는 빅데이터분석기사 완전정복 필기편 : Part.2 빅데이터 탐색(2) 강의입니다.\n\n\n빅데이터 분석 기사는 국가 기술 자격증으로 필기와 실기 시험이 있습니다.\n\n\n본 강의는 빅데이터 분석 기사 자격증 취득을 위한 필기 시험 대비 강의입니다.\n\n\n빅데이터 분석 기사 필기 시험 핵심 개념부터 예상 문제 풀이까지 제대로 배워 한번에 합격합시다!\n\n\n\n\n누구를 위한 강의인가요?\n\n\n빅데이터 분석기사(필기) 자격증 취득을 원하시는 분들\n\n\n데이터 분석 직무로의 취업 및 이직을 준비하시는 분들\n\n\n데이터 분석에 대해 공부하고자 하시는 분들\n\n\n\n\n무엇을 배우나요?\n\n\n빅데이터 탐색\n\n\n통계기법의 이해\n\n\n기술통계\n\n\n추론통계\n\n\n예상문제 풀이\n\n\n데이터 탐색 과목 마무리 문제 풀이\n\n\n\n\n빅데이터분석기사 완전정복 필기편 : Part.2 빅데이터 탐색(2) 강의에 입문해봅시다~!\n\n\n\n\n그럼 강의에서 만나요 :)",
      "target_audience": [
        "빅데이터 분석기사(필기) 자격증 취득을 원하시는 분들",
        "데이터 분석 직무로의 취업 및 이직을 준비하시는 분들",
        "데이터 분석에 대해 공부하고자 하시는 분들"
      ]
    },
    {
      "title": "[OpenCV] 파이썬 딥러닝 영상처리 프로젝트 2 - 불량사과를 찾아라!",
      "url": "https://www.udemy.com/course/opencv-2/",
      "bio": "OpenCV로 이미지와 영상을 처리하고, 딥러닝을 활용하여 얼굴과 다양한 사물을 식별하고 인식하는 내용을 배웁니다. 졸음방지, 나이와 성별식별, 지나가는 사람 수 세기, 얼굴 추적, 불량사과와 귤을 찾아주는 YOLO",
      "objectives": [
        "OpenCV 이미지, 동영상 처리",
        "OpenCV dnn(Deep Learning) 이해와 실습",
        "이미지, 동영상에서 물체식별(Object Detection)",
        "얼굴인식 Face Recognition 강화하기",
        "이미지, 동영상에서 물체추적(Object Tracking)",
        "Face Landmark, EAR로 졸음감시",
        "딥러닝으로 나이와 성별 인식하기(Age, Gender Recognition)",
        "불량사과, 귤 등 나만의 물체인식(Custom Yolo)"
      ],
      "course_content": {
        "OpenCV와 영상 처리의 기본": [
          "OpenCV와 강의소개",
          "래스터(비트맵)와 벡터이미지",
          "OpenCV 설치하기"
        ],
        "이미지 가공하기": [
          "이미지 픽셀 좌표체계",
          "이미지에 그리기",
          "이미지 변형하기",
          "이미지 마스킹(Masking)",
          "이미지 채널(Channel)조작"
        ],
        "얼굴 인식(Face Recognition) 강화하기": [
          "Face Detection 3대 기법",
          "OpenCV dnn Face Detection 코드해설 1",
          "OpenCV dnn Face Detection 코드해설 2",
          "Face_Recognition 라이브러리 설치"
        ],
        "Face Landmark와 Alignment": [
          "Face Landmark란?",
          "Face Landmark 코드해설",
          "Face Alignment 소개하기",
          "Face Alignment 코드해설 1",
          "Face Alignment 코드해설 2",
          "Face Recognition 인식률 높이기"
        ],
        "Face Landmark 졸음감지(Drowsiness Detection)": [
          "졸음감지(Drowsness Detection) 프로젝트 소개",
          "졸음감지(Drowsness Detection) 코드해설"
        ],
        "나이와 성별 추정하기(Age and Gender Recognition)": [
          "나이와 성별 추정 프로젝트 소개",
          "Age and Gender Recognition GUI해설",
          "Age and Gender Recognition 코드해설",
          "비디오 Age and Gender Recognition"
        ],
        "Object Tracking으로 지나가는 사람 수 세기": [
          "Object Tracking 소개하기",
          "지나가는 사람 수 세기 코드해설",
          "Centroid 알고리즘 소개",
          "Centroid 알고리즘 코드해설",
          "지나가는 사람 수 세기 완성"
        ],
        "OpenCV 얼굴 추적(Face Tracking)": [
          "OpenCV 물체 추적(Object Tracking) 기법",
          "얼굴 추적(Face Tracking) 소개하기",
          "얼굴 추적(Face Tracking) 코드해설"
        ],
        "YOLO를 이용한 사물 식별(Object Detection)": [
          "YOLO란 무엇인가?",
          "YOLO 사물 식별(Object Detection) 프로그램",
          "YOLO 사물 식별 동영상 프로그램"
        ],
        "원하는 이미지로 YOLO 데이터 만들기": [
          "직접 학습한 YOLO 프로젝트 소개",
          "YOLO 이미지 데이터 만들기",
          "YOLO 학습데이터 포멧",
          "YOLO 학습데이터 생성하기",
          "불량사과 식별 YOLO데이터 생성하기"
        ]
      },
      "requirements": [
        "열심히 배우고자 하는 의지",
        "파이썬 기본지식",
        "OpenCV에 대한 이해",
        "파이썬 데이터 가공, 시각화 프로젝트 경험"
      ],
      "description": "- 프로젝트 소개\n먼저 이미지와 영상을 다루는 기법에 대해서 배우고 출발해야겠지요?\n딥러닝을 본격적으로 활용하기에 앞서 OpenCV의 핵심 기법을 차근차근 배워나갑니다.\n\n\n원하는 이미지를 모아서 가공하고 YOLO를 학습시켜서 불량사과와 귤을 식별해요.\n구글 Colab와 DarkNet을 이용하여 Custom Data Yolo의 학습 방법을 실습합니다.\n\n\n다양한 Object Tracking 기술로 빠르고 쉽게 물체를 추적해요.\n지나가는 사람 수를 세고 OpenCV Tracking기법으로 얼굴을 추적해요.\n\n\nFace Landmark, Alignment로 얼굴인식의 정확도를 높여요.\nFace Landmark와 EAR을 이용하여 졸음감지 프로젝트도 만들어 봐요.\n\n\n딥러닝으로 얼굴을 인식하고 나이와 성별까지 추정해 봅니다.\nFace Landmark, Alignment기술을 사용하면 얼굴인식이 더 높아져요.\n\n\n1. YOLO 이미지, 동영상 처리 등 기본을 배우는 'YOLO를 이용한 사물 식별(Object Detection)'단원을 포함했습니다.\n2. YOLO 학습에 사용했던 이미지를 그대로 사용해서 Keras로 학습해서 모델을 만들고 물체를 식별하는 내용입니다. YOLO와 Keras를 학습하는 내용도 배우고 서로 비교할 수도 있겠지요?\n\n- 어떤 툴을 사용하나요?\n이 강의에서 다루는 툴은 어떤 것들이 있을까요?\n이 강의는 대표적인 ComputerVision 소프트웨어 라이브러리인 OpenCV와 파이썬을 기반으로 합니다.\n이 외에도 몇 가지 유용한 소프트웨어를 설치하는데 강의 속에서 하나씩 설명드립니다.\n\n\n- 궁금해요!\nQ. 이 강의는 어떤 특징을 가지고 있나요?\nA. 딥러닝, 머신러닝을 실전에서 활용하는 방법을 고민했습니다.\n이 과정은 대표적인 분야인 Computer Vision 관련된 이론 설명 뿐 아니라\n실전 프로젝트를 통해서 딥러닝을 배우게 됩니다.\nQ. 비전공자도 들을 수 있나요?\nA. 딥러닝이나 데이터 과학은 꼭 전산을 전공한 분만 할 수 있는 분야가 아닙니다.\n여러분의 열정만 있다면 충분히 배우고 활용할 수 있는 내용입니다.",
      "target_audience": [
        "딥러닝을 실전에서 활용하고 싶은 분",
        "딥러닝을 이용한 영상처리에 대해 배우고 싶은 분",
        "Computer Vision과 관련한 프로젝트를 준비하는 분",
        "OpenCV를 이해하고 활용하고자 하는 분",
        "딥러닝 영상처리 최신 기법을 배우고자 하는 분",
        "딥러닝으로 불량품을 식별(Defect Detection)하고 싶은 분"
      ]
    },
    {
      "title": "Analiza danych - DAX ekspert w PowerBI, Power Pivot Excel",
      "url": "https://www.udemy.com/course/analiza-danych-podstawy-dax-w-powerbi-power-pivot-excel/",
      "bio": "Zostań Ekspertem Analizy Danych i Data Science. Twórz analizy, które robią wrażenie. Oszczędzaj czas i pracuj mądrzej",
      "objectives": [
        "Zwiększysz swoją wartość na rynku pracy",
        "Oszczędzisz czas spędzony na przygotowaniu raportów i analiz",
        "Poznasz podstawowe koncepcje języka DAX – kontekst wiersza, kontekst filtru, przejście kontekstu",
        "Nauczysz się tworzyć obliczenia analityczne, statystyczne i używać ich w wizualizacjach",
        "Poznasz funkcje agregujące, tablicowe, Time Intelligence i wiele innych i nauczysz się sprawnie używać ich w swoich raportach",
        "Nauczysz się dodawać kolumny obliczane do tabel, które masz w modelu danych",
        "Uzyskasz pełną kontrolę nad modelem danych",
        "Nauczysz się również dodawać za pomocą DAX-a nowe tabele",
        "Zobaczysz ciekawe przykłady użycia języka DAX w obliczeniach, wizualizacjach i formatowaniu warunkowym",
        "Po ukończeniu kursu będziesz w stanie rozwiązać większość zagadnień, z którymi spotkasz się w biznesie.",
        "Będziesz potrafił wyszukiwać i stosować rozwiązania tematów, które postawi przed Tobą biznes.",
        "Będziesz gotowy do rozpoczęcia kursu zaawansowanego z języka DAX"
      ],
      "course_content": {
        "Wstęp": [
          "Wstęp",
          "Przygotowanie pliku do ćwiczeń",
          "Model danych i relacje"
        ],
        "DAX podstawowe koncepcje": [
          "Twoje pierwsze miary!",
          "Rodzaje funkcji",
          "Kontekst wiersza i przykłady iteratorów",
          "Kontekst filtru"
        ],
        "Funkcje tablicowe": [
          "Funkcja FILTER",
          "Funkcje ALL, ALLEXCEPT i ALLSELECTED",
          "Funkcje VALUES i DISTINCT",
          "VALUES - ciekawe zastosowanie",
          "Funkcje SUMMARIZE i ADDCOLUMNS - niesamowite combo",
          "Funkcja SUMMARIZECOLUMNS - jeszcze lepsza funkcja tablicowa",
          "Funkcja TOPN",
          "Tabele statyczne",
          "Tabela kalendarza"
        ],
        "CALCULATE - najpiękniejsza funkcja DAX": [
          "Funkcja CALCULATE - podstawy",
          "Modyfikatory funkcji CALCULATE - KEEPFILTERS i ALL",
          "Modyfikatory ALL i ALLSELECTED",
          "Modyfikatory USERRELATIONSHIP i CROSSFILTER zmień relację nie zmieniając relacji",
          "Przejście kontekstu",
          "Kolejność działań CALCULATE",
          "Funkcja CALCULATETABLE"
        ],
        "Zmienne": [
          "Zmienne w kodzie DAX"
        ],
        "Funkcje tablicowe cz2": [
          "Funkcje INTERSECT i EXCEPT"
        ],
        "Time Intelligence": [
          "Funkcja DATEADD",
          "Funkcje DATESYTD, QTD, MTD",
          "Funkcja SAMEPERIODLASTYEAR, PARALLEPERIOD",
          "Funkcja DATESBETWEEN i DATESINPERIOD",
          "Miary Semiaddytywne"
        ],
        "DAX w praktyce": [
          "Maksymalna sprzedaż dzienna i data maksymalnej sprzedaży",
          "Średnia krocząca - dynamiczna liczba dni do średniej kroczącej",
          "DAX w formatowaniu warunkowym",
          "Wykres Pareto",
          "Miara jako link",
          "Segmentacja dynamiczna"
        ],
        "DAX w Power Pivot w Excelu": [
          "DAX w Power Pivot w Excelu"
        ],
        "Zakończenie.": [
          "Gratulacje i co dalej"
        ]
      },
      "requirements": [
        "Potrzebny będzie dostęp do programu PowerBI Desktop i umiejętność jego uruchomienia, żeby aktywnie uczestniczyć w kursie.",
        "Pomocne, ale niekonieczne jest posiadanie i znajomość Excela.",
        "Znajomość PowerBI ułatwi uczestnictwo w kursie, ale nie jest wymagana. Podstawową wiedzę zdobędziesz na tym kursie.",
        "Bardzo przyda się chęć do nauki i systematyczność."
      ],
      "description": "W ostatnich latach dane odgrywają coraz większą rolę. Umiejętność przetwarzania danych w informacje, opowiadania historii za pomocą danych, czyli tzw. storytelling, wizualizacja danych staje się bardzo cenna. Niezbędna jest do tego znajomość narzędzi dostępnych na rynku, które służą do tego celu. Ważnymi narzędziami są Excel z modułem Power Pivot i PowerBI.\nI właśnie DAX jest językiem używanym w tych narzędziach. Znajomość DAX-a jest koniecznością dla użytkowników chcących dostarczać wydajnych i niosących wartość decyzyjną raportów.\nW tym kursie zapoznasz się z podstawowymi koncepcjami tego języka:\nKontekstem wiersza\nKontekstem filtru\nTworzeniem kolumn obliczanych\nTworzeniem tabel obliczanych\nFunkcją CALCULATE\nNauczysz się różnych funkcji, dzięki którym będziesz w stanie rozwiązać większość problemów, z którymi zwróci się do Ciebie biznes. Będziesz w stanie, nawet z prostego modelu danych wyciągnąć niesamowitą ilość informacji.\nPoznasz dobre praktyki przy pisaniu kodu w języku DAX, dzięki czemu unikniesz wielu błędów i pułapek, które czyhają na początkujących.\nPoznasz też kilka ciekawych praktycznych zastosowań DAX-a w realnych, codziennych problemach.\nPo ukończeniu kursu, będziesz w stanie pogłębiać swoją wiedzę, czy to samodzielnie, czy też z pomocą kursów zaawansowanych. Podpowiem, jak dalej rozwijać swoje umiejętności w tej dziedzinie.\nPodpowiem też, co zrobić, żeby wiedza zdobyta na kursie nie ulotniła się po krótkim czasie!\nNiech DAX przestanie być dla Ciebie tajemnicą... Zapraszam do kursu!",
      "target_audience": [
        "Początkujących użytkowników zaczynających swoją pracę z PowerBI i Power Pivot",
        "Doświadczonych użytkowników PowerBI i Power Pivot chcących pogłębić, uporządkować i usystematyzować swoją wiedzę nt. DAX-a",
        "Osób, które chcą przenieść swoje raporty na wyższy poziom pod kątem dostarczanej informacji o procesach biznesowych",
        "Analityków, chcących czerpać coraz więcej informacji z dostępnych danych",
        "Osób, które chcą przenieść i zautomatyzować swoje raporty do PowerBI z innych platform (np. z Excela)",
        "Menadżerów, którzy pracują na PowerBI i chcą podejmować coraz lepsze decyzje na podstawie dostępnych danych",
        "Osób z obszaru analizy biznesowej, które chcą tworzyć coraz bardziej zaawansowane modele analityczne i coraz dogłębniejsze raporty"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第13部 ComfyUI 進階版 - 超真實AI室內設計設果圖製作",
      "url": "https://www.udemy.com/course/generative_ai_13/",
      "bio": "關於ComfyUI，LoRA，ControlNET，FreeU，Florence2，Sam2Segmentation，Upscaling，Stable diffusion",
      "objectives": [
        "了解ComfyUI的定義、用途及其背後的技術原理",
        "掌握如何創建和管理工作流程",
        "掌握 ControlNet、Florence2 和 Sam2Segmentation 的核心應用，從設計規劃到局部修改，提升創作效率",
        "融合 3D 圖片與普通照片，創建出具備藝術水準的室內設計效果圖"
      ],
      "course_content": {
        "ComfyUI配置": [
          "什麼是Image Generation圖片生成",
          "如何使用ComfyUI",
          "如何在iMac電腦上安裝ComfyUI",
          "如何創建第一個ComfyUI工作流"
        ],
        "如何使用ComfyUI製作室內設計效果圖": [
          "如何使用ComfyUI製作室內設計效果圖",
          "如何為客廳出室內設計效果圖"
        ],
        "如何將3D圖片(3D Max或Cinema 4D等軟體)製作成室內裝修的效果圖": [
          "如何用最簡單的Prompt輸出最高質量的圖片",
          "如何處理多個ControlNet與圖片分辨率",
          "如何放大圖片再造型室內風格",
          "如何調整LCM LoRA和FreeU",
          "如何修正LCM LoRA的Steps和CFG值",
          "如何製作超真實圖片",
          "如何選取圖片特定區域",
          "如何合併多個Mask",
          "如何修改沙發顏色"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "想成為室內設計效果圖創作的大師？本課程將帶您進入一個令人興奮且挑戰十足的學習旅程，從零開始學習使用 ComfyUI 和多種強大工具，輕鬆打造超真實的室內設計效果圖！不論您是設計愛好者還是專業人士，這門課程都將為您提供新一代 AI 驅動技術的實用技巧，帶來前所未有的創意靈感！\n課程亮點\n從零開始掌握 ComfyUI\n從基礎安裝到高階應用，手把手教您如何駕馭 ComfyUI 的每一個細節。\n深入探索 Custom Nodes 的運用，靈活結合 3D 圖片和普通照片，輕鬆轉換為高清室內設計效果圖。\nControlNet 導航裝修設計\n利用 ControlNet 精準控制室內擺設和設計預期，讓您的創作完全符合客戶需求。\n不再擔心擺設凌亂，ControlNet 幫助您創造符合規劃的和諧空間。\nFlorence2 提供強大 Prompt 創作支持\n使用 Florence2 自動生成高效 Prompt，讓 AI 精準理解您的設計意圖。\n無需苦思冥想，每個提示詞都為您帶來最佳設計效果。\nSam2Segmentation 精準圖像選擇與編輯\n想對圖片的某個部分進行微調？Sam2Segmentation 幫助您輕鬆選取目標範圍，實現局部細緻修改。\n每一處細節都經過精心打磨，呈現完美效果圖。\n實戰案例帶您完成創作\n不只教技術，還會結合實際案例，帶您完成一幅真實的室內設計效果圖。\n這個課程對於任何想要提升室內設計技能的人來說,都是一次難得的機會。從基礎到進階,從設計到渲染,我們一步步帶你掌握使用ComfyUI的全部竅門。立即報名,開啟你的AI輔助設計之旅!",
      "target_audience": [
        "數字藝術創作者",
        "AI愛好者和學習者"
      ]
    },
    {
      "title": "Расширенный\\Advanced DAX для бизнес-пользователей",
      "url": "https://www.udemy.com/course/advanced-dax-r/",
      "bio": "Углубленное владение расширенными вычислениями на DAX",
      "objectives": [
        "Использование переменных (VAR)",
        "Расширенные функции фильтрации (в частности EARLIER, а также CALCULATE со всеми модификаторами)",
        "Продвинутые логические функции (SWITCH c TRUE, COALESCE...)",
        "Аналитика во времени (Time Intelligence)",
        "Оконные вычисления (WINDOW, ORDERBY, PARTITIONBY, MATCHBY, OFFSET...)",
        "Функции обработки таблиц (вкл. разбор JOIN'ов и UNION)",
        "Функции связей (RELATED, USERELATIONSHIP...)",
        "Cложные вычисления (многоуровневые конструкции выражений\\формул)"
      ],
      "course_content": {
        "ВВЕДЕНИЕ": [
          "Введение",
          "Что Вы должны знать, понимать и уметь на DAX до начала прохождения курса",
          "О том, как мы будем учиться в этом курсе"
        ],
        "РАСШИРЕННЫЕ ЛОГИЧЕСКИЕ ФУНКЦИИ (+немного об информационных)": [
          "Воспоминания о логических функциях",
          "Вспомнить логику",
          "Информационные функции в логических вычислениях: ISBLANK,ISNUMBER,ISTEXT,ISERROR",
          "Проба информационок в логике",
          "Замена ошибок: IFERROR",
          "Проверялка на ошибки",
          "Интервальный просмотр для SWITCH: TRUE()",
          "Интервальный переключатель",
          "Подстановка из множества: COALESCE",
          "COALESCE (в Power Pivot Excel может не быть!!!)",
          "COALESCE в расчетах",
          "Логические итоги"
        ],
        "РАСШИРЕННОЕ ПОНИМАНИЕ CALCULATE и фильтров": [
          "Воспоминания о CALCULATE",
          "Припоминая CALCULATE...",
          "Фильтрация таблицами (FILTER)",
          "Не столбцами едиными: табличная фильтрация",
          "Модификаторы управления фильтрами: ALL и производные",
          "Модификация ALL'ами",
          "Разбор ALL и ALLSELECTED на виджетах\\визуалах",
          "Сохранение и переприменение фильтров: модификатор KEEPFILTERS",
          "Сохранить с переприменением",
          "Модификаторы связей: активация неактивной связи между таблицами(USERELATIONSHIP)",
          "Связист",
          "Модификаторы связей: изменение направления (CROSSFILTER)",
          "Стрелочник",
          "Связи без связей: TREATAS как модификатор для фильтрации таблицами",
          "Фильтрация таблицами без связи",
          "Вычисление таблицы: CALCULATETABLE",
          "Табличный \"CALCULATE\"",
          "Итоги CALCULATE'ов"
        ],
        "ФУНКЦИИ ФИЛЬТРАЦИИ с ФУНКЦИЯМИ СВЯЗИ": [
          "Вступление к разделу",
          "Почему связи между таблицами - это также фильтрация (LOOKUPVALUE)",
          "DAX'овский ВПРчик",
          "Функции RELATED и RELATEDTABLE",
          "От 1-ко-многим и от много-к-1",
          "Итераторы-рекурсионки: EARLIER и EARLIEST",
          "Поиграем с EARLIER",
          "Итоги этих связных фильтраций"
        ],
        "НЕПРОСТОЙ МИДКВЭЛ \"Сок для гурманов\": ОКОННЫЕ ФУНКЦИИ": [
          "Что такое окно (WINDOW)?",
          "В окна вглядываюсь я...",
          "\"Нарезка\" окон в массиве PARTITIONBY",
          "Окон много у меня...",
          "Сортированные окна: сортировка строк в окне ORDERBY",
          "Сортировщик",
          "Возврат позиции: INDEX",
          "Индексация",
          "Смещение: OFFSET",
          "Смещалка",
          "Нумерация строк: ROWNUMBER",
          "Нумерация",
          "Ранжирование: RANK",
          "По ранжиру",
          "Итоги оконных вычислений"
        ],
        "Функции работы с ДАТАМИ": [
          "Воспоминания о функциях работы с датами",
          "Вспомнить простые функции дат",
          "Вычисления определенного периода: EDATE и EOMONTH",
          "Вычислительная периодика",
          "Разница между временными промежутками: DATEDIFF",
          "Периодическая разница",
          "Количество раб.дней между датами: NETWORKDAYS",
          "Отработка",
          "Часть\\доля от года: YEARFRAC",
          "Фрактация",
          "Табличные функции среди дат: КАЛЕНДАРИ",
          "Я календарь переверну...",
          "Итоги дат"
        ],
        "АНАЛИТИКА ВРЕМЕНИ\\ОПЕРАЦИИ СО ВРЕМЕНЕМ (Time Intelligence)": [
          "Воспоминания о функциях аналитики времени",
          "Память временной аналитики",
          "Вычисления по первой\\последней дате в периоде: OPENING\\CLOSINGBALANCE...",
          "Балансировка",
          "Вытягивание из столбца дат первой\\последней даты: START\\ENDOF..., FIRST\\LAST...",
          "И начало, и конец",
          "То ли дата, то ли значение....",
          "Таблица со столбцом дат: DATES..., NEXT\\PREVIOUS..., PARALLEL\\SAME...",
          "Периодическое передвижение",
          "Итоги аналитики во времени"
        ],
        "ФУНКЦИИ ОБРАБОТКИ ТАБЛИЦ": [
          "Об обработке таблиц: а что с ними можно делать в принципе?",
          "Создание произвольной (и не только)таблицы: DATATABLE, SELECTCOLUMNS, ADDCOLUMNS",
          "Создатель",
          "Вспомним DISTINCT и VALUES",
          "Уникальность и не очень...",
          "Группировка (изменение гранулярности): GROUPBY, SUMMARIZE, SUMARIZECOLUMNS",
          "Понижатель",
          "Сшивание\\добавление строк из нескольких таблиц в 1: UNION",
          "Сшиватель",
          "Генераторы-объединители таблиц на \"декартовом движке\": GENERATE...+ CROSSJOIN",
          "Декартка",
          "Объединение таблиц через JOIN: NATURALINNERJOIN и NATURALLEFTOUTERJOIN",
          "Джойны",
          "(Не)Соответствие множеств: EXCEPT\\INTERSECT (таблицы исключений\\совпадений)",
          "Пересечься",
          "Итоги по обработке таблиц"
        ],
        "Специализация: обзор мат.-инженерно-научных, финансовых и статистических функций": [
          "Функции для специализированных предметных областей",
          "Разбор нескольких математических функций для инженерно-научных расчетов",
          "Поговорим о статистических функциях",
          "Пройдемся о понятии финансовых функций"
        ],
        "ФАКУЛЬТАТИВ: понятие ИНСТРУКЦИЙ, DAX QE и ВИЗУАЛЬНЫХ ВЫЧИСЛЕНИЙ": [
          "О чем будет данный раздел?",
          "Обзор интерфейса и логика работы DAX Query Editor",
          "Знакомство с DQE: быстрый старт",
          "КЛЮЧЕВЫЕ СЛОВА\\ИНСТРУКЦИИ в запросах DAX",
          "Ключевики",
          "Переменные: VAR",
          "Переменка",
          "Понятие визуальных вычислений (MOVINGAVERAGE, RUNNINGSUM, RANGE)",
          "Визуалки",
          "Факультативное задание в факультативе",
          "Итоги раздела"
        ]
      },
      "requirements": [
        "Наличие среды для DAX-вычислений (в идеале Power BI Desktop (бесплатное ПО) поскольку именно это ПО будет использовано в курсе, но для большинства отрабатываемых вычислений подойдет любое из приложений: Excel, Power BI или Analysis Services).",
        "Владением навыками моделирования, понимание типов ключей (столбцов\\переменных-идентификаторов) и их роли, типов связей (1-1;1-*;*-*), направления связей\\движение фильтра",
        "Знания и навыки применения DAX (в Excel, Power BI или Analysis Services) на уровне бизнес-пользователя: умение вычислять меры и столбцы, в частности с использованием мат.операций, IF, CALCULATE, агрегационных, текстовых, числовых и др. функций"
      ],
      "description": "ВНИМАНИЕ 1! Данный курс предназначен для  знакомых с DAX  бизнес-пользователей (в Power BI, Analysis Services или надстройке Power Pivot к Excel). Если Вы новичок или совсем немного знакомый с DAX, то рекомендовано:\n- либо пройти сначала курс \"Power BI: от новичка до уверенного бизнес-пользователя\",\n- либо курс \"Excel Power Query и Pivot (+BI): с 0 до бизнес-пользователя\"\nВНИМАНИЕ 2! Этот курс нацелен только на вычислениях на языке DAX (без погружения в работу Power Query, Power Pivot\\Модель и Power View\\Отчет)\nКурс хорошо подойдет и тем слушателям, которые уже умеют уверенно работать в Power Pivot\\Модель: владеющие не только моделированием (типы ключей столбцов-идентификаторов и их роль в таблицах, типы связей между таблицами, направления связей\\движение фильтра), а еще и способны осуществлять вычисления на DAX  таблиц, мер и столбцов (в частности с применением основных мат.операций, агрегационных, логических, текстовых, числовых, а также функций дат и времени...) - но хотели бы углубить свои знания и освоить расширенные вычисления на DAX\nВ основе курса официальные учебно-справочные материалы Microsoft + практический опыт автора в применении расширенных вычислений\nВ курсе основной упор на практическое применение и освоение функционала - поэтому курс содержит соответствующие практические задания (почти 50 ЗАДАНИЙ!!!), которые позволяют студентам проработать лекционный материал и освоить расширенные DAX-вычисления.\nКурс от профессионала в анализе данных: владеющего навыками обработки, анализа и визуализации данных в продуктах семейства Microsoft (Excel, Power BI); методами предиктивной аналитики в спецпрограммах (SPSS, JASP, Statistica...),  а также методами Data Science применяемых в разработке систем \"искусственного интеллекта\".\nСоздатель курса - автор популярной бизнес-литературы (доступна в крупнейших магазинах: Amazon, Ozon, ЛитРес, Ridero...). В частности, автор одного из русскоязычных бестселлеров  в категории \"Анализ данных\" - книги \"Аналитика и Data Science для не-аналитиков и даже 100% гуманитариев\", а также одной из первых книг отечественных авторов по работе с Power Query для Excel и Power BI   \"Power Query: учебное руководство. От новичка до уверенного бизнес-пользователя\";\nВ курсе НЕ БУДЕТ материала об основах и теории преобразования данных, моделировании в части соединения таблиц, построении визуализаций\\диаграмм - в курсе фокус исключительно на расширенных вычислениях на DAX и ничего более.",
      "target_audience": [
        "Аналитики (любой функции: от технарей до гуманитариев)",
        "Профессионалы разных дисциплин, уже работающие с DAX, но желающие расширить свои навыки и погрузиться в сложные вычисления и освоение продвинутых функций",
        "Студентов, прошедших более простые курсы (с нуля до основ и уровня уверенного бизнес-пользователя)"
      ]
    },
    {
      "title": "Машинное зрение: распознавание объектов на Python",
      "url": "https://www.udemy.com/course/ittensive-machine-vision-recognition/",
      "bio": "Обучение и оптимизация сверточных нейросетей для распознавания объектов на изображениях",
      "objectives": [
        "Распознавание чисел и букв на фотографиях",
        "Использование нейронных сетей на реальных данных",
        "Обработка и коррекция изображений",
        "Искусственные нейронные сети: слои, веса, обучение",
        "Модели нейронных сетей Keras/TensorFlow",
        "Использование LeNet, AlexNet, VGG и ResNet для распознавания цифр",
        "Оптимизация нейронных сетей",
        "Функции оптимизации: SGD, RMSprop, (N)adam, Adamax",
        "Перенос обучения нейронных сетей",
        "Изменение контраста, гистограммы яркости и резкость",
        "Курсовой проект: Распознавание номеров автомобилей"
      ],
      "course_content": {
        "Задачи машинного зрения": [
          "Приветствие",
          "Задачи машинного зрения"
        ],
        "Часть 1. Искусственные нейронные сети": [
          "Искусственные нейронные сети",
          "Нейросети",
          "Слои в нейросетях",
          "Нейрон смещения",
          "Функции активации",
          "Функции активации",
          "Обратное распространение ошибки",
          "Многослойный перцептрон",
          "Многослойный перцептрон"
        ],
        "Обучение нейросети": [
          "Эпохи, пакеты, итерации",
          "Пакетное обучение",
          "Свертка и подвыборка",
          "Сверточные нейросети",
          "LeNet",
          "AlexNet",
          "VGG",
          "Inception",
          "ResNet",
          "ResNeXt",
          "SE-ResNet"
        ],
        "Часть 2. Практикум: Распознавание цифр": [
          "Работа с изображениями",
          "LeNet для MNIST",
          "AlexNet для MNIST",
          "Перенос обучения",
          "ResNet для MNIST"
        ],
        "Оптимизация нейросетей": [
          "Оптимизация нейросетей по Нестерову",
          "Адаптивная оптимизация нейросетей",
          "RMSprop, adadelta, adam",
          "Оптимизация нейросетей",
          "Оптимизация нейросетей",
          "Пакетная нормализация",
          "Регуляризация обучения нейросетей",
          "Методы инициализации весов",
          "Дополнение данных",
          "Обучение нейросети",
          "Оптимизация нейросетей"
        ],
        "Практикум: Оптимизированные нейросети": [
          "Размножение изображений",
          "Оптимизация нейросети",
          "Функции оптимизации",
          "Оптимизация нейросети"
        ],
        "Часть 3: Обработка изображений": [
          "Преобразование изображений",
          "Коррекция изображений",
          "Загрузка изображений",
          "Проект: распознавание автомобильных номеров"
        ]
      },
      "requirements": [
        "Уверенное владение Python",
        "Знакомство с методами машинного обучения"
      ],
      "description": "Внимание: для доступа к курсам ITtensive на Udemy напишите, пожалуйста, на support@ittensive.com с названием курса или группы курсов, которые хотите пройти.\n\n\nПервый курс из серии Машинное зрение посвящен распознаванию изображений с помощью нейронных сетей на Python. Курс состоит из 3 больших частей:\nВведение в нейронные сети\nРазберем основы нейросетей: нейрон, слои, связи, обратное распространение ошибки и многослойный перцептрон. Изучим особенности обучения и оптимизации нейросетей.\nПогрузимся в сверточные нейросети и разберем архитектуры LeNet, AlexNet, VGG и ResNet.\nРаспознавание цифр\nПрименим теоретические знания на практике. Используем Python и Keras для создания и обучения моделей нейронных сетей для успешного распознавания рукописных цифр - набора MNIST.\nРазберем все прикладные особенности работы с нейросетями в Keras:\nОсобенности оцифрованных изображений.\nСоздание моделей и слоев.\nПреобразование форм данных (многомерных массивов).\nГенераторы и дополнение изображений.\nОбучающая, тестовая и валидационные выборки.\nФункции оптимизации и пакеты обучения.\nПрикладная оптимизация нейросети.\nВизуализация процесса обучения.\nПакетная нормализация, регуляризация и отсев.\nМетоды инициализации весов.\nРаспознавание автомобильных номеров\nИспользуем обучающую выборку из изображений цифр автомобильных номеров для распознавания реального номера автомобиля.\nЗагрузка, фильтрация и преобразование изображений.\nГенераторы обучения из директорий.\nИзменение контраста, резкости и маски гистограмм изображений.\nРаспознавание одного из 21 класса изображений - цифры и буквы.\nИспользование обученной модели на реальных данных.\nКурсовым проектом будет ваша собственная обученная нейросеть, распознающая номера автомобилей по фотографии.",
      "target_audience": [
        "Разработчики систем машинного зрения",
        "Инженеры по работе с графическими данными",
        "Научные работники и исследователи данных"
      ]
    },
    {
      "title": "Introdução às Aplicações Com Inteligência Artificial",
      "url": "https://www.udemy.com/course/introducao-as-aplicacoes-com-inteligencia-artificial/",
      "bio": "Curso prático com aplicações avançadas e recursos completos de IA e Aprendizado de Máquina para profissionais técnicos.",
      "objectives": [
        "Aplicações de IA na prática",
        "História da Inteligência Artificial",
        "Aplicações com Processamento de Linguagem Natural",
        "Tipos de aprendizado de máquina e aplicações",
        "Aplicações de IA com Visão Computacional",
        "Aplicações de IA com Voz",
        "Aplicações com Sistemas de Recomendação",
        "Aprendizado de Máquina Automatizado",
        "Manipulação de diferentes tipos de dados",
        "Pré-processamento de dados",
        "Recursos de Aprendizado de Máquina",
        "Treinamento e Avaliação de modelos"
      ],
      "course_content": {
        "Introdução": [
          "Visão geral do curso",
          "Sobre a Alana AI"
        ],
        "Introdução à Inteligência Artificial": [
          "História da Inteligência Artificial",
          "Inteligência Artificial x Robótica x Ciência de Dados",
          "O Teste de Turing",
          "Materiais complementares"
        ],
        "Introdução ao Aprendizado de Máquina": [
          "Tipos de Aprendizado de Máquina",
          "Termos utilizados no Apredizado de Máquina",
          "Aprendizado Não Supervisionado",
          "Aprendizado Supervisionado",
          "Aprendizado Semi Supervisionado",
          "Aprendizado Auto Supervisionado",
          "Aprendizado por Reforço"
        ],
        "Fluxo de Processamento, Treinamento e Avaliação": [
          "Importação e Manipulação de dados",
          "Pré-processamento de dados",
          "Seleção de características (features)",
          "Treinamento usando Scikit-learn",
          "Avaliação de modelos"
        ],
        "Ferramentas, Bibliotecas e Recursos": [
          "Scikit-learn",
          "Kaggle & Google Datasets",
          "Hugging Face",
          "Keras"
        ],
        "Aplicações com Processamento de Linguagem Natural": [
          "Introdução ao Processamento de Linguagem Natural",
          "Classificação de textos e documentos",
          "Chatbots",
          "Tradução Automática",
          "Sumarização de texto",
          "Geração de texto",
          "Recursos de Processamento de Linguagem Natural",
          "Materiais complementares"
        ],
        "Aplicações com Voz": [
          "Introdução a Voz",
          "Transcrição de Voz",
          "Geração de Voz",
          "Materiais complementares"
        ],
        "Aplicações com Visão Computacional": [
          "Introdução à Visão Computacional",
          "Introdução às Redes Neurais Convolucionais (parte 1)",
          "Introdução às Redes Neurais Convolucionais (parte 2)",
          "Reconhecimento de objetos",
          "Estimação de pose 3D",
          "Reconhecimento facial",
          "Video Tracking",
          "Geração de descrição de imagem",
          "Recursos de Visão Computacional",
          "Materiais complementares"
        ],
        "Aplicações com Sistemas de Recomendação": [
          "Introdução aos Sistemas de Recomendação",
          "Recursos de criação de Sistemas de Recomendação"
        ],
        "Aprendizado de Máquina Automatizado (AutoML)": [
          "Introdução ao Aprendizado de Máquina Automatizado (AutoML)",
          "Recursos de Aprendizado de Máquina Automatizado (AutoML)"
        ]
      },
      "requirements": [
        "Curiosidade sobre como desenvolver aplicações de Inteligência Artificial",
        "Experiência básica com Python (necessária apenas utilização dos recursos disponibilizados)"
      ],
      "description": "Nas palavras de Andrew Ng, empreendedor e cientista pioneiro em Inteligência Artificial (IA), \"IA é a nova eletricidade. Ela transformará todos os setores e criará enormes valores econômicos.\"\n\n\nNeste curso, você aprenderá o que é Inteligência Artificial (IA), explorará casos de uso e aplicações de IA, entenderá conceitos e termos de IA como aprendizado de máquina, aprendizado profundo e redes neurais. O objetivo deste curso é fornecer a você o conhecimento dos principais aspectos da IA moderna sem nenhuma matemática intimidadora e de maneira prática e fácil. O curso oferece aos alunos uma experiência direcionada usando as ferramentas e recursos utilizados por cientistas e grandes empresas que são referências na área. Ao final do curso, você terá toda a fundamentação em aplicações e bibliotecas para aprendizado de máquina, bem como conhecimento de princípios de inteligência artificial que te permitirão projetar e desenvolver seus próprios sistemas inteligentes.\n\n\nVocê verá as principais aplicações de IA nos domínios mais populares listadas abaixo com explicações e materiais de apoio:\nVisão Computacional\nProcessamento de Linguagem Natural (PLN)\nVoz\nSistemas de Recomendação\n\n\nPor fim, como contéudo extra, também será apresentado o conceito e aplicação do Aprendizado de Máquina Automatizado (AutoML) e plataformas de ML No-code. Bibliotecas de Aprendizado de Máquina Automatizado permitem que o desenvolvedor não se preocupe com a escolha e a seleção do melhor algoritmo ou hiperparâmetros, aumentando a produtividade e assertividade dos modelos.\n\n\nEsse curso é um oferecimento da Alana AI, startup pioneira em Inteligência Artificial e Processamento de Linguagem Natural aplicados ao marketing e à experiência do consumidor.",
      "target_audience": [
        "Profissionais técnicos interessados em uma visão geral de aplicações com Inteligência Artificial",
        "Programadores Python interessados em aprender como aplicar aprendizado de máquina"
      ]
    },
    {
      "title": "Python自动化办公+数据爬虫+可视化Web站点",
      "url": "https://www.udemy.com/course/python-auto/",
      "bio": "掌握一门Python，即可自动化Excel、Word、PPT、Chrome、DingDing、Spider、Web、OSFile、Email、Echarts等",
      "objectives": [
        "Python的使用",
        "Python自动化处理Excel",
        "Python自动化处理Word",
        "Python自动化处理PPT",
        "Python控制邮箱做自动化处理",
        "Python控制浏览器实现数据和表单自动化处理",
        "Python自动化管理系统文件",
        "Python爬虫开发",
        "Python开发Web网站",
        "Python自动化管理钉钉账号",
        "使用Python实现编程题要求"
      ],
      "course_content": {
        "开发环境搭建": [
          "Python的安装推荐【含源码】",
          "Python的下载和安装",
          "Anaconda的下载和安装",
          "环境变量的配置",
          "pip的在线安装安装方式",
          "pip的离线安装方式",
          "pip的加速方式",
          "conda的加速配置",
          "值得学习的几个Python库",
          "win平台上python安装scrapy",
          "Anaconda自动化安装scrapy"
        ],
        "Python基础学习": [
          "Python基础-数字【含本章源码】",
          "Python基础-字符串",
          "Python基础-列表",
          "Python基础-元组",
          "Python基础-字典",
          "Python基础-切片上",
          "Python基础-切片下",
          "Python基础-判断",
          "Python基础-循环语句",
          "Python基础-条件循环",
          "Python基础-函数",
          "Python基础-类的使用",
          "Python基础-异常处理",
          "Python基础-文件读写"
        ],
        "Python编程基础题-锻炼思维": [
          "列表生成式【含源码】",
          "字典生成式",
          "三目运算符",
          "随机数的生成",
          "字符统计",
          "生成指定长度的字符串",
          "字符串逆序",
          "生成指定长度的字符串【一行代码】",
          "字符串删减",
          "三角形的三边关系",
          "九九乘法表",
          "杨辉三角",
          "水仙花数",
          "回文数",
          "100以内的素数",
          "123报数游戏",
          "猜数字游戏"
        ],
        "Python实现Excel自动化": [
          "Excel介绍和常见格式说明【含源码】",
          "Excel的Python库介绍和安装",
          "往Excel文件中写入批量数据",
          "写入Excel的九九乘法表",
          "读取Excel文件数据",
          "Excel文件数据的追加",
          "准备部门的财务信息表",
          "数据整合，多个Excel文件数据合并成一个文件",
          "自动化计算和数据统计-上",
          "自动化计算和数据统计-下",
          "梦想中的Excel成绩表",
          "xlsx文件数据的拷贝操作",
          "xlsx文件数据的追加操作",
          "2019年新能源汽车销量Top10",
          "3D版2019年新能源汽车销量Top10",
          "nCov湖北疫情确诊人数走势图",
          "3D版nCov湖北疫情确诊人数走势图",
          "相亲对象的csv格式数据",
          "python中csv文件的读取操作",
          "python中csv文件的写入操作",
          "Excel操作csv格式文件"
        ],
        "Python实现Word自动化操作": [
          "Word自动化批处理介绍【含源码】",
          "新建Word文件并写入内容",
          "新建一个文章文档",
          "文档中插入特定尺寸的图片",
          "图片的位置关系",
          "新建表格和信息数据",
          "了解Word文档的组成结构",
          "提取文章数据的接口",
          "9.批量生成100片文章-上",
          "批量生成100篇文章-下",
          "读取Word中的文字信息",
          "读取并保存Word文件中图片",
          "Word文档渲染和格式的说明",
          "公司在职员工的数据准备",
          "在职员工证明的渲染模板",
          "了解并安装文档渲染使用到的库",
          "渲染在职员工证明的文档",
          "准备并改造雇佣合同模板",
          "高科技公司员工的雇佣合同模板",
          "准备简历模板和基础渲染",
          "数据嵌套和基础渲染",
          "所有数据的渲染和展示",
          "word文档转pdf格式文件的操作"
        ],
        "Python实现PPT自动化操作": [
          "PPT知识点介绍【含源码】",
          "PPT相关库介绍",
          "新建并理解PPT文件和幻灯片的概念",
          "PPT模板介绍",
          "幻灯片层级关系介绍",
          "占位符的使用并填充文字",
          "补充额外的文本框",
          "将所有母版新建成幻灯片",
          "PPT中插入图片",
          "表格的插入和展示",
          "好员工的信息分析和统计需求说明",
          "代码实现数据统计",
          "数据渲染到PPT幻灯片表格中",
          "市场折线渲染图",
          "年度业绩柱状图",
          "图表中的数据标识",
          "PPT和Excel的需求说明",
          "统计Excel数据中的各部门总人数",
          "统计数据渲染到PPT表格中去",
          "现有PPT母版说明",
          "将部门人数做成图表渲染到PPT中去"
        ],
        "Python实现浏览器的自动化操作": [
          "浏览器自动化操作介绍【含源码】",
          "浏览器库和驱动的安装配置",
          "上手学习selenium库",
          "selenium中常用的五种定位方式",
          "数据填充到输入框中",
          "模拟网页的点击操作",
          "从网页中提取数据",
          "隐身，无窗口模式",
          "浏览器最大化铺满屏幕",
          "破解网页的懒加载问题",
          "直接让浏览器执行js代码",
          "控制浏览器新建多个标签页",
          "标签页的管理，切换和关闭",
          "隐藏浏览器的IP地址信息",
          "网页中嵌套框架的跳转问题",
          "指定缓存文件夹和保存浏览器记录",
          "自定义目录实现用户的基础信息保存",
          "什么是浏览器的应用模式",
          "播放音乐并自动化下载-上",
          "播放音乐并自动化下载-中",
          "播放音乐并自动化下载-下",
          "直播留言，活跃直播间氛围",
          "直播留言，用海量弹幕实现轰炸"
        ],
        "即时通信工具的自动化管理": [
          "聊天工具机器人的介绍【含源码】",
          "【重要】关于几款常用聊天工具的特殊说明",
          "钉钉账号和钉钉群的介绍",
          "智能群助手介绍",
          "创建第一个智能群助手",
          "添加天气信息通知和灾害预警",
          "疫情精灵智能助手",
          "移除智能群助手",
          "Python的钉钉机器人库介绍和安装",
          "钉钉机器人发送第一条文字信息",
          "多个自定义关键词的安全设置",
          "特定IP的安全配置",
          "加密签名的配置和说明",
          "群消息类型介绍",
          "最简单的纯文本信息",
          "纯文本中的格式化消息展示",
          "链接消息的形式和发送",
          "消息中加载图片的方式",
          "Markdown语法的介绍和兼容",
          "震惊！重大考题泄露",
          "ActionCard的使用和对比",
          "多链接的活动卡片信息使用",
          "FeedCard信息流推送文章"
        ],
        "邮箱的自动化处理": [
          "邮箱知识点和目录介绍【含源码】",
          "各类邮箱类型介绍",
          "邮箱多种协议类型的介绍说明",
          "邮箱的账号密码及相关配置",
          "Python的邮箱相关库介绍和安装",
          "使用Python发送第一封邮件",
          "如何判断授权码泄露",
          "邮件一次性发送给多个收件地址",
          "收件和抄送的不同概念区分",
          "发送邮件的同时抄送给其他邮箱",
          "抄送，以及秘密抄送",
          "发送携带附件的邮件",
          "contents和attachments两个参数的详细说明",
          "支持HTML格式的Email内容",
          "邮件中的HTML格式特殊说明",
          "发送一封简洁的HTML格式邮件",
          "常用邮箱HOST地址和端口",
          "邮箱接收相关库的介绍和安装",
          "查看邮箱的第一封邮件",
          "邮件格式和字段信息说明",
          "按条件查询某类邮件",
          "将邮件保存到本地磁盘上"
        ],
        "系统文件自动化管理": [
          "系统文件自动化操作介绍【含源码】",
          "win目录文件夹介绍",
          "Linux系统目录系统介绍",
          "linux和windows的不同",
          "用户账户主目录的重要性",
          "Python的系统相关库介绍",
          "系统路径的重要性",
          "获取当前路径的方式方法",
          "Python中路径的跳出操作",
          "使用Python批量创建文件夹",
          "多层级目录的创建",
          "win和linux的创建文件方式",
          "随机创建多层目录和文件",
          "遍历读取指定路径的文件和文件夹",
          "使用Python进行改名操作",
          "移动文件到指定位置",
          "按条件过滤并删除文件",
          "检测电脑当中的空白文件夹",
          "查看你电脑中的小秘密",
          "文件的拷贝操作",
          "目录的拷贝操作"
        ]
      },
      "requirements": [
        "零基础",
        "会使用电脑",
        "会上网，例如钉钉软件 浏览器软件"
      ],
      "description": "学习Python自动化，轻松解决生活中和工作中，繁琐的大小事\n\n\n这是一门适合初学者的课，全程只有Python这一门编程语言\n\n\nPython上手简单，对新手友好，且生态极其丰富。\n但是很多人学完Python之后，往往不知道做什么，因为根本不知道Python如何于工作、生活关联起来。\n\n\nPython的生态库，有大公司都使用的Django、Numpy、Pandas、Pytorch等，也有各式各样的工具库\n例如 微信pywechat库、pygame游戏库、爬虫scrapy库、界面QT库、图表PyEcharts库等\n\n\n所以有了这门课程，将Python拓展到生活和工作的方方面面，比如办公文件、浏览器自动填充表格等。\n这些都是使用Python可以轻而易举实现的，在工作方面，极大的解放了双手。\n\n\n课程中每章，都包含了1-2实例场景，都提供本章的源码下载。\n\n\n课程从零开始，包含如下内容：\nPython基础知识点\nPython编程基础题\nExcel自动化办公\nWord自动化办公\nPPT自动化办公\n浏览器自动化批处理\n智能聊天机器人编码\n邮件的自动化接收发送处理\n系统文件的批量管理\nPython爬虫的数据自动化收集\n炫丽的可视化图表\n基于Python的Web建站\n\n\n有问题请随时留言，我们会不定期的回复和解答你们的疑问。",
      "target_audience": [
        "对数据感兴趣",
        "想学习Python的人",
        "对自动化感兴趣的Python开发人员",
        "需要重复处理表格的数据人员"
      ]
    },
    {
      "title": "Développer des applications IA avec Gemini 2.5 et Python",
      "url": "https://www.udemy.com/course/developper-des-applications-ia-avec-gemini-et-python/",
      "bio": "Apprends à construire des applications IA simples avec Python et Gemini en seulement 1 heure.",
      "objectives": [
        "Construire une application de génération de texte avec l’IA",
        "Construire une application d'interaction avec des images",
        "Construire un chatbot simple",
        "Comprendre comment utiliser Chainlit",
        "Construire différents chatbots via Chainlit"
      ],
      "course_content": {},
      "requirements": [
        "Une connaissance de base en Python est recommandée, mais aucune expérience préalable en IA n’est nécessaire. Tout sera expliqué de manière accessible et progressive."
      ],
      "description": "Développer des applications IA avec Gemini 2.5 et Python\nDécouvre le pouvoir de l'intelligence artificielle et apprends à créer des applications innovantes avec Gemini 2.5 et Python dans ce cours complet et pratique ! Conçu pour les développeurs, les passionnés de technologie et les curieux de l’IA, ce programme te guidera pas à pas dans la construction d’applications intelligentes si tu débutes dans ce domaine.\n\n\nCe que tu vas apprendre :\nGénération de texte avec l’IA : Développe une application capable de produire des textes créatifs et pertinents grâce aux modèles avancés de Gemini 2.5.\nInteraction avec des images : Crée une application d’IA qui analyse des photos et répond à des questions spécifiques sur leur contenu, ouvrant des perspectives fascinantes pour l’interprétation visuelle.\nChatbot simple : Construis un chatbot de base pour comprendre les fondamentaux de l’interaction textuelle automatisée.\nApplications avancées avec Chainlit : Allez plus loin en développant une véritable application de chatbot déclinée en trois versions professionnelles :\nUn chatbot textuel pour des conversations fluides et naturelles.\nUn chatbot photo capable d’interagir avec des images uploadées par les utilisateurs.\nUn chatbot audio pour des échanges vocaux, rendant l’expérience utilisateur encore plus immersive.\n\nPourquoi choisir ce cours ?\nÀ travers des projets concrets et des démonstrations claires, vous maîtriserez les outils et techniques nécessaires pour intégrer l’IA dans vos propres applications. Chaque module est accompagné d’explications détaillées, de codes commentés et d’exercices pratiques pour consolider vos compétences. Que vous souhaitiez enrichir votre portfolio, lancer un projet personnel ou explorer les possibilités de l’IA, ce cours est votre tremplin idéal.\n\nÀ qui s’adresse ce cours ?\nDéveloppeurs Python cherchant à se spécialiser dans l’IA.\nEntrepreneurs ou créateurs souhaitant intégrer des fonctionnalités intelligentes dans leurs produits.\nÉtudiants ou curieux désirant comprendre et appliquer les technologies d’intelligence artificielle.\n\nPrérequis :\nUne connaissance de base en Python est recommandée, mais aucune expérience préalable en IA n’est nécessaire. Tout sera expliqué de manière accessible et progressive.\n\n\nRejoins ce cours dès aujourd’hui et transforme tes idées en applications IA puissantes avec Gemini 2.5 et Python !",
      "target_audience": [
        "Développeurs Python cherchant à se spécialiser dans l’IA.",
        "Entrepreneurs ou créateurs souhaitant intégrer des fonctionnalités intelligentes dans leurs produits.",
        "Étudiants ou curieux désirant comprendre et appliquer les technologies d’intelligence artificielle."
      ]
    },
    {
      "title": "Inteligência Artificial com Excel e VBA Aprenda Criar a Sua",
      "url": "https://www.udemy.com/course/inteligencia-artificial-com-vba-crie-a-sua-e-destaque-se/",
      "bio": "Aprenda como criar sua própria Inteligência Artificial no Excel com VBA e aprimore suas Planilhas e se Destaque",
      "objectives": [
        "Este curso está em constante atualização, você sempre estará atualizado.",
        "Aprenda como criar um programa em VBA que responde perguntas dos usuários e personize de acordo com as necessidades de sua empresa",
        "Aprenda como criar uma função que cria fórmulas de acordo com perguntas dos usuários e personalize como quiser para aumentar sua produtividade.",
        "Aprenda como automatizar suas fórmulas e reduza horas de seu trabalho."
      ],
      "course_content": {
        "Introdução": [
          "Introdução"
        ],
        "Criando o Próprio Respondedor de Perguntas": [
          "O que vamos Aprender",
          "Dicas",
          "Criando Tela Perguntas",
          "Primeiros Passos no Código e Criando o Titulo da Listbox",
          "Populando as Perguntas Feitas na Listbox e Primeiros Passos no Botão Perguntar",
          "Programando Botão de Perguntas parte 1",
          "Finalizando o Cálculo de Soma, Subtração, Multiplicação e Divisão e Testando",
          "Criando Código para Encontrar a Melhor Resposta",
          "Criando Código para Encontrar a Melhor Resposta",
          "Finalizando Código de Perguntas, Exibindo Resposta e Salvando no Excel",
          "Selecionando Pergunta da Listbox e Exibindo Detalhe da Resposta",
          "Finalizando o Projetos e Testando"
        ],
        "Exercício Função que Responde Perguntas": [
          "Exercício Função que Responde Perguntas - parte 1",
          "Exercício Função que Responde Perguntas - parte 2"
        ],
        "Como programar o VBA para criar fórmulas de acordo com as perguntas do usuário": [
          "O que vamos aprender",
          "Dica",
          "Criando Fórmula de Máscara CPF com IA e VBA",
          "Criando Fórmula de SOMA com IA e VBA",
          "Criando Fórmula de CONCATENAR com IA e VBA",
          "Criando Fórmula de SEPARAR SOBRENOME com IA e VBA"
        ],
        "Automação por Comando": [
          "O que vamos aprender",
          "Dica",
          "Automação por Comando ou Palavra - parte 1",
          "Automação por Comando ou Palavra - parte 2",
          "Automação por Comando ou Palavra - parte 3",
          "Automação por Comando ou Palavra - parte 4",
          "Automação por Comando ou Palavra - parte 5",
          "Automação por Comando ou Palavra - parte 6",
          "Automação por Comando ou Palavra - parte 7",
          "Automação por Comando ou Palavra - parte 8",
          "Automação por Comando ou Palavra - parte 9",
          "Automação por Comando ou Palavra - parte 10"
        ],
        "Spreadsheet AI": [
          "Spreadsheet AI - Parte 1",
          "Explicando sobre o Spreadsheet AI e o ChatGPT"
        ],
        "Projeto Indicação Calçado": [
          "O que vamos aprender",
          "Dica",
          "Sistema de Recomendação de Calçados - parte 1",
          "Sistema de Recomendação de Calçados - parte 2",
          "Classificador de SPAM - parte 1",
          "Classificador de SPAM - parte 2"
        ],
        "Mensagem Final do Curso": [
          "Parabéns, você completou o curso com sucesso!"
        ]
      },
      "requirements": [
        "Conhecimento prévio de VBA ajuda ."
      ],
      "description": "Você está pronto para revolucionar a forma como trabalha com o Excel? Apresentamos o curso exclusivo \"Inteligência Artificial com Excel e VBA  Aprenda Criar a Sua\", projetado para profissionais como você que desejam dar um salto na eficiência e produtividade. Este curso é uma jornada para transformar suas planilhas em poderosas ferramentas de produtividade.\n\n\nO que você vai aprender:\n\n\nAssista as vídeos aulas que estão gratuitas no curso e veja com detalhes o que vamos aprender.\n\n\nCriação de uma IA Simples: Aprenda a integrar conceitos de inteligência artificial no Excel. Você será capaz de programar sua própria IA para responder perguntas.\nAutomatização de Tarefas: Automatizar tarefas repetitivas.\nPersonalização de Funções e Fórmulas: Vá além das funções padrão do Excel. Aprenda a criar fórmulas personalizadas que se adaptam especificamente às necessidades do seu trabalho.\nAumento de Produtividade: Descubra como o VBA pode economizar horas do seu dia de trabalho, permitindo que você se concentre em tarefas mais estratégicas.\n\n\nPor que escolher nosso curso?\n\n\nInstrutor Especializado: Instrutor experiente no uso do VBA para inteligência artificial, pronto para compartilhar conhecimentos práticos e dicas avançadas.\nAcesso Vitalício: Uma vez inscrito, você terá acesso vitalício ao curso e às atualizações futuras, garantindo que você sempre tenha as informações mais recentes.\nSuporte Dedicado: Tem dúvidas ou precisa de ajuda? Nossa equipe de suporte está sempre pronta para assisti-lo em sua jornada de aprendizado.\nCertificado de Conclusão: Ao finalizar o curso, você receberá um certificado, validando suas novas habilidades e conhecimentos.\n\n\nTransforme seu Trabalho com IA e VBA\nSe você quer economizar tempo, aumentar sua eficiência e ser reconhecido como um especialista em automação e análise de dados, este curso é para você. Inscreva-se hoje no \"Inteligência Artificial com VBA Crie a Sua\" e dê o primeiro passo para se tornar um profissional de destaque na era da inteligência artificial!\n\n\nSatisfação garantida ou seu dinheiro de volta\n\"E se eu não gostar do curso?” A Udemy oferece a todos os alunos uma garantia de reembolso, esse é mais um motivo e um incentivo para você começar já! Após a compra do curso, você tem 30 dias para testar o produto, e se não gostar, basta solicitar o reembolso.\n\n\nTe espero em nossa Área de Alunos.",
      "target_audience": [
        "Para todos que querem aprender com criar uma Inteligência Artificial no Excel e aumentar sua produtividade"
      ]
    },
    {
      "title": "Google Cloud Big Data and Machine Learnig Español",
      "url": "https://www.udemy.com/course/google-cloud-big-data-and-machine-learnig-espanol-gabriel-alvarado/",
      "bio": "Aprendizaje Automatico",
      "objectives": [
        "Identificar el propósito y el valor de los productos clave de macrodatos y aprendizaje automático disponibles en Google Cloud Platform",
        "Usar Cloud SQL y Cloud Dataproc para migrar las cargas de trabajo existentes de MySQL y Hadoop/Pig/Spark/Hive a Google Cloud Platform",
        "Usar BigQuery y Cloud Datalab para llevar a cabo un análisis de datos interactivo",
        "Elegir entre Cloud SQL, Bigtable y Datastore",
        "Entrenar y usar una red neuronal mediante TensorFlow",
        "Elegir entre los diferentes productos de procesamiento de datos disponibles en Google Cloud Platform"
      ],
      "course_content": {
        "Modulo 1": [
          "Intro",
          "Programa de especialización Data Engineering, Big Data, and Machine Learning",
          "Introducción a Google Cloud Platform",
          "Potencia de procesamiento para cargas de trabajo de estadísticas y de AA",
          "Demostración Cómo crear una VM en Compute Engine",
          "Almacenamiento elástico con Google Cloud Storage",
          "Compilación en la red global de Google",
          "Seguridad local frente a nativa de la nube",
          "Evolución de las herramientas de macrodatos de Google Cloud",
          "Cómo elegir el enfoque correcto para la solución",
          "Lo que puede hacer con Google Cloud Platform",
          "Actividad Explore arquitecturas de soluciones de clientes reales",
          "Cuestionario (Opcional)",
          "Funciones clave en una organización basada en los datos",
          "Lab Explore un conjunto de datos públicos de BigQuery",
          "Recursos del modulo"
        ],
        "Modulo 2": [
          "Intro",
          "Cómo las empresas usan los sistemas de recomendación Machine Learning",
          "Introducción al aprendizaje automático",
          "Desafío AA para recomendar alquileres de viviendas",
          "Enfoque Migre de un entorno local a Google Cloud Platform",
          "Demostración Cree un trabajo de Apache Spark en 10 minutos",
          "Desafío Cómo utilizar y ajustar los clústeres locales",
          "Lleve el almacenamiento fuera del cluster con Google Cloud",
          "Introduccion al lab",
          "Lab parte 1",
          "Lab parte 2",
          "Lab parte 3",
          "Recursos del módulo"
        ],
        "Modulo 3": [
          "Intro",
          "Introducción a BigQuery",
          "Use BigQuery en Google Cloud Console",
          "BigQuery Motor SQL rápido",
          "Demostración Cómo explorar datos del uso compartido de bicicletas",
          "Calidad de los datos",
          "Almacenamiento administrado de BigQuery",
          "Cómo elegir un tipo de modelo de AA para datos estructurado",
          "Cómo predecir el valor del ciclo de vida del cliente",
          "BigQuery ML Cree modelos con SQL",
          "Etapas en el ciclo de vida de los modelos de AA",
          "BigQuery ML Explicación de las funciones principales",
          "Lab Prediga las compras de visitantes con BigQuery ML",
          "parte 1",
          "parte 2",
          "Recursos del módulo"
        ],
        "Modulo 4": [
          "Intro",
          "Desafíos modernos para la canalización de datos",
          "Arquitecturas orientadas a los mensajes con Cloud PubSub",
          "Cómo diseñar canalizaciones de transmisión con Apache Beam",
          "Cómo implementar canalizaciones de transmisión en Cloud DataFlow",
          "Cómo visualizar estadísticas con Data Studio",
          "Cómo crear gráficos con Data Studio",
          "Recursos del modulo"
        ],
        "Modulo 5": [
          "Intro",
          "¿En qué casos usan el AA no estructurado las empresas",
          "¿Cómo funciona el AA con datos no estructurados",
          "Demostración AA integrado en Google Fotos",
          "Cómo comparar enfoques para el AA",
          "Demostración Cómo usar las piezas fundamentales del AA",
          "Cómo usar una IA previamente compilada para crear un chatbot",
          "Cómo personalizar modelos previamente compilados con AutoML",
          "Cómo compilar un modelo personalizado",
          "Lectura"
        ],
        "Modulo 6": [
          "Google Cloud Biga Data and Machine Learnig"
        ]
      },
      "requirements": [
        "Manejo básico de PC.",
        "Entendimiento muy básico de virtualización (No es imprescindible).",
        "Manejo de sistemas operativos.",
        "Uso de recursos de internet."
      ],
      "description": "los participantes descubrirán las capacidades de los macrodatos y del aprendizaje automático de Google Cloud Platform (GCP). Además, se proporciona una descripción general rápida de Google Cloud Platform y más detalles sobre las capacidades de procesamiento de datos.\n\n\nAl finalizar este curso, los participantes podrán hacer lo siguiente:\n• Identificar el propósito y el valor de los productos clave de macrodatos y aprendizaje automático disponibles en Google Cloud Platform\n• Usar Cloud SQL y Cloud Dataproc para migrar las cargas de trabajo existentes de MySQL y Hadoop/Pig/Spark/Hive a Google Cloud Platform\n• Usar BigQuery y Cloud Datalab para llevar a cabo un análisis de datos interactivo\n• Elegir entre Cloud SQL, Bigtable y Datastore\n• Entrenar y usar una red neuronal mediante TensorFlow\n• Elegir entre los diferentes productos de procesamiento de datos disponibles en Google Cloud Platform\n\n\nAntes de inscribirse en este curso, los participantes deben tener los siguientes:\n• Un lenguaje de consulta común, como SQL\n• Actividades de extracción, transformación y carga\n• Modelado de datos\n• Aprendizaje automático o estadísticas\n• Programación en Python\n\n\nEl principal objetivo de todo aprendiz (learner) es desarrollar la capacidad de generalizar y asociar. Cuando traducimos esto a una máquina o computadora, significa que éstas deberían poder desempeñarse con precisión y exactitud, tanto en tareas familiares, como en actividades nuevas o imprevistas.\n\n\n¿Y cómo es posible esto?\nHaciendo que repliquen las facultades cognitivas del ser humano, formando modelos que “generalicen” la información que se les presenta para realizar sus predicciones. Y el ingrediente clave en toda esta cuestión son los datos.\nEn realidad, el origen y el formato de los datos no es tan relevante, dado que el machine learning es capaz de asimilar una amplia gama de éstos, lo que se conoce como big data, pero éste no los percibe como datos, sino como una enorme lista de ejemplos prácticos.\nPodríamos decir que sus algoritmos se dividen principalmente en tres grandes categorías: supervised learning (aprendizaje supervisado), unsupervised learning (aprendizaje no supervisado) y reinforcement learning (aprendizaje por refuerzo).",
      "target_audience": [
        "Estudiantes o recién graduados que quieran iniciarse en el mundo del análisis del Big Data.",
        "IT Managers que deseen explorar una mejor manera de sacar partido a su información.",
        "Organizaciones que busquen como analizar distintas fuentes de información para una mejor toma de decisión.",
        "Profesionales que deseen adquirir nuevos conocimientos sobre el análisis del Big Data y el manejo del mismo."
      ]
    },
    {
      "title": "Machine Learning Supervisionado: Da Teoria à Prática",
      "url": "https://www.udemy.com/course/machine-learning-supervisionado-da-teoria-a-pratica/",
      "bio": "Fundamentos e Aplicações de Machine Learning Supervisionado com Python 3.0",
      "objectives": [
        "Algoritmos de classificação",
        "Algoritmos de regressão",
        "Matriz de confusão",
        "Precisão, acuraria, recall, F-Score",
        "Regressão Logística",
        "Funções de kernel",
        "Árvores de decisão",
        "Random Forest",
        "Suport Vector Machines - SVM",
        "Naive Bayes",
        "KNN",
        "Redes neurais artificiais - RNAs",
        "Lasso, Ridge e Elastic Net",
        "Regressão Polinomial",
        "Regressão Múltiplas",
        "Gradient Boosting Machines - GBM",
        "Fine Tuning",
        "Muita teoria e aplicações com Python"
      ],
      "course_content": {},
      "requirements": [
        "Fundamentos de Python",
        "Conceitos básicos de machine learning",
        "Conceitos básicos para manipulação de dados com Pandas e Numpy"
      ],
      "description": "Fundamentos e Aplicações de Machine Learning Supervisionado com Python\nA Importância no Cenário Atual\nO Machine Learning Supervisionado é uma das abordagens mais poderosas e amplamente utilizadas no campo da inteligência artificial e ciência de dados. A compreensão dos fundamentos e aplicações dessa técnica é crucial, pois ela tem o potencial de transformar dados brutos em insights valiosos e ajudar a resolver problemas complexos em diversos setores, como saúde, finanças, marketing e mais.\n\n\n1. Construção de Modelos Eficientes\nOs fundamentos do Machine Learning Supervisionado envolvem a compreensão de como treinar modelos a partir de dados rotulados, ou seja, com exemplos de entrada e saída já conhecidos. Esse aprendizado orientado permite que o modelo aprenda a mapear novas entradas para as saídas corretas, permitindo a realização de tarefas como:\nClassificação: Prever categorias (por exemplo, identificar se um e-mail é spam ou não).\nRegressão: Prever valores contínuos (como estimar o preço de uma casa com base em suas características).\nCom uma base sólida nos fundamentos, os profissionais podem construir modelos mais precisos e eficazes, aplicando as melhores práticas para otimização e ajuste.\n\n\n2. Aplicações no Mundo Real\nO aprendizado supervisionado não se limita apenas à teoria, mas tem aplicações diretas e transformadoras em diversos campos:\nSaúde: Diagnóstico médico com base em imagens ou sinais vitais, como prever doenças a partir de exames laboratoriais.\nFinanças: Análise preditiva de risco de crédito e comportamento do mercado, ajudando instituições financeiras a tomarem decisões mais informadas.\nMarketing: Segmentação de clientes e personalização de ofertas, melhorando a experiência do usuário e a conversão de vendas.\nAutomação e Indústria: Previsão de falhas em máquinas, otimização de processos e análise de dados em tempo real para melhorar a eficiência operacional.\n\n\n3. Desenvolvimento de Soluções Inteligentes\nA habilidade de aplicar Machine Learning Supervisionado de maneira eficaz permite a criação de soluções inteligentes que podem aprender e melhorar com o tempo. Isso é vital em um mundo onde a automação e a inteligência artificial estão cada vez mais presentes. O aprendizado supervisionado possibilita sistemas que:\nAprendem com exemplos históricos.\nTomam decisões de forma autônoma.\nMelhoram continuamente conforme são alimentados com novos dados.\nEssas soluções estão na base de muitas das inovações tecnológicas que moldam o futuro, como carros autônomos, assistentes virtuais e sistemas de recomendação.\n\n\n4. Relevância para Profissionais de Dados\nPara qualquer profissional que deseje se destacar no campo de data science ou inteligência artificial, entender os fundamentos e as aplicações de Machine Learning Supervisionado é essencial. O domínio dessa área proporciona um diferencial competitivo, já que muitas das tarefas mais comuns em ciência de dados e análise preditiva dependem desse tipo de aprendizado.\nAlém disso, os fundamentos fornecem a base para compreender outras técnicas avançadas de Machine Learning, como Deep Learning e Reinforcement Learning, uma vez que eles compartilham conceitos fundamentais, como a modelagem e a avaliação de desempenho.\n\n\n5. Implicações Éticas e Práticas\nCom a crescente adoção de algoritmos supervisionados, é fundamental que os profissionais também compreendam as implicações éticas e práticas do uso dessas tecnologias. Isso inclui garantir que os dados usados para treinar modelos sejam representativos, evitar viés nos resultados e interpretar corretamente as previsões feitas pelos modelos.\n\n\nOs fundamentos e aplicações de Machine Learning Supervisionado são fundamentais não apenas para criar modelos de aprendizado eficazes, mas também para implementar soluções reais que impactem positivamente diferentes indústrias. Profissionais que dominam esses conceitos têm a capacidade de aplicar inteligência artificial de forma ética e eficiente, resolvendo problemas complexos e criando um impacto significativo nas organizações e na sociedade. Portanto, a compreensão dessa técnica é crucial para quem deseja se manter competitivo no mundo moderno da ciência de dados e da inteligência artificial.\n\n\nPor isso!\nInscreva-se agora mesmo no curso!!",
      "target_audience": [
        "Engenheiros, cientistas e analistas de dados",
        "Autodidatas interessados no universo de data science - DS"
      ]
    },
    {
      "title": "Trading Algorítmico con Python en 2025",
      "url": "https://www.udemy.com/course/trading-algoritmico-con-python-full/",
      "bio": "Machine Leaning aplicado a Bolsa. Backtesting, Trading view. Uso de APIs financierias . IA y ChatGPT",
      "objectives": [
        "Crear Modelos de Inversión basados en IA",
        "Ejecutar y validar si una estrategia de Inversión es rentable",
        "Visualizar y entender datos financieros",
        "Automatizar operaciones de Inversión"
      ],
      "course_content": {
        "Introducción": [
          "Introducción"
        ],
        "Extracción de datos con (API Alpaca,Alpavantage, Polygon)": [
          "Extracción de datos y Visualización",
          "Extracción de Datos y Cálculo de Indicadores Técnicos con Alpavantage",
          "Extracción de datos de Forex y Calculo de retornos"
        ],
        "Machine Learning con Python": [
          "Extraccion de datos de SP500",
          "Clutesting usando Kmeans",
          "Predección del precio de Apple",
          "Analisis de Sentimiento",
          "Redes LSTM para predicción del precio",
          "Extracción de datos de 30 ETFs y Calculo de Retorno y Desviación Estándar",
          "Detección de Soportes y Resistencias"
        ],
        "TradingView": [
          "Backtesting",
          "Estrategia RSI",
          "Estrategia Basada en Bandas de Bollinger"
        ],
        "Backtesting y Desarollo de Estrategias": [
          "Intdoucción al backtesting con Python",
          "Estrategia basada en Momentum"
        ],
        "Análisis de Rieagos y Optimizacion de Carteras": [
          "Análisis de Riesgo Métricas",
          "Calculo Medidas de Riesgo en Python",
          "Optimizacion de Pesos y Análisis de Rendimientos"
        ],
        "ChatGPT para Trading": [
          "Usamos ChatGPT para crear un Bot de Inversión desde cero",
          "Backetesting con ChatGPT"
        ]
      },
      "requirements": [
        "Es recomendable tener nociones básicas de programación en Python"
      ],
      "description": "¿Quieres dejar de depender de la intuición y comenzar a operar con estrategias sólidas, basadas en datos y automatizadas?\nCon el curso “Trading Algorítmico con Python: Estrategias, Análisis y Automatización” aprenderás a crear tus propios algoritmos de inversión, a optimizarlos y a ponerlos en práctica como lo hacen los profesionales.\nEste no es un curso teórico. Es una experiencia práctica y transformadora que te llevará desde los fundamentos hasta la implementación de estrategias reales.\n¿Qué aprenderás?\nTrading algorítmico desde cero: cómo funcionan los mercados financieros y cómo usar Python para operar como los grandes fondos.\nAnálisis técnico y fundamental: descubre cómo combinar datos y patrones para detectar oportunidades rentables.\nBacktesting avanzado: pon a prueba tus estrategias con datos históricos antes de arriesgar tu dinero.\nOptimización y gestión del riesgo: aprende a mejorar el rendimiento de tus algoritmos y a proteger tu capital.\nTrading potenciado con IA: usa herramientas como ChatGPT y modelos de machine learning para crear y mejorar estrategias más inteligentes.\n¿Por qué este curso es diferente?\nEnfoque 100% práctico: desde el primer módulo estarás creando y ejecutando tus propios scripts.\nAprendizaje asistido con IA: te enseñamos cómo usar la inteligencia artificial para acelerar tu curva de aprendizaje.\nPlantillas listas para usar: descarga y adapta el código para que puedas implementar tus estrategias más rápido.\nGuía paso a paso: te acompañamos desde lo básico hasta la automatización completa de tus operaciones.\n¿Para quién es este curso?\nInversores que quieren automatizar sus operaciones y dejar de perder tiempo con procesos manuales.\nEntusiastas del trading que buscan entender y aplicar estrategias profesionales.\nProgramadores y analistas que quieren combinar su conocimiento técnico con el mundo financiero.\nAl finalizar, serás capaz de:\nDiseñar y programar estrategias de trading algorítmico.\nEvaluar el rendimiento de tus sistemas con pruebas históricas.\nOptimizar tus algoritmos para maximizar beneficios y reducir riesgos.\nIntegrar inteligencia artificial en tu proceso de inversión.\nTu futuro como trader algorítmico empieza hoy\nDeja de operar a ciegas y empieza a tomar decisiones basadas en datos y automatización.\nÚnete ahora y transforma tu manera de invertir.",
      "target_audience": [
        "Desarolladores en Python",
        "Entusiastas de los mercados financieros",
        "Todo Aquel quiera Automatizar sus inversiones",
        "Inversores"
      ]
    },
    {
      "title": "데이터 초보 탈출! : 핵심 용어부터 엔지니어링 입문까지",
      "url": "https://www.udemy.com/course/data-101-to-engineering/",
      "bio": "[멘토링 커피챗 이벤트 진행중] 데이터 분야 입문을 위해 핵심 용어, 관련 직군과 협업 방식, 도구와 플랫폼, 데이터 엔지니어링의 역할을 한 눈에 볼 수 있는 미니맵",
      "objectives": [
        "데이터 저장소, 관리 방식, 패러다임에 관련된 핵심 용어를 배웁니다.",
        "데이터에 관련된 직군의 종류와 역할, 협업 방식에 대해 배웁니다.",
        "데이터 엔지니어링과 파이프라인(ETL, ELT)에 대한 개념과 구성 요소에 대해 배웁니다.",
        "데이터 플랫폼 생태계를 구성하는 각 컴포넌트의 역할과 타 시스템과의 연동 방식에 대해 소개합니다."
      ],
      "course_content": {
        "커리어 성장 멘토링 이벤트 안내": [
          "이벤트 공지 및 안내"
        ],
        "Introduction": [
          "강사, 강의대상, 커리큘럼 소개",
          "강의 오버뷰"
        ],
        "데이터 분야 101": [
          "빅데이터 소개",
          "데이터 프로덕트",
          "데이터 관련 직군에 대한 이해"
        ],
        "현대 데이터 관리의 핵심 용어": [
          "DataOps, Data Quality, Data Governance, Data Democratization, Literacy, Lineage"
        ],
        "데이터 엔지니어링 입문": [
          "데이터 엔지니어링이란?",
          "데이터 처리 방식의 종류",
          "데이터 저장소(Data Warehouse, Data Mart, Data Lake, Data Lakehouse)",
          "데이터 파이프라인의 개념과 발전과정(ETL & ELT)",
          "빅데이터 아키텍처(Lambda & Kappa architecture)",
          "데이터 도구 및 플랫폼 소개"
        ],
        "데이터 엔지니어링과 데이터 프로덕트의 미래": [
          "데이터 엔지니어링과 데이터 프로덕트의 미래"
        ]
      },
      "requirements": [
        "데이터 분야에 대한 관심"
      ],
      "description": "2025년 성장에 진심인 [주니어를 위한 커리어 성장 멘토링] 이벤트 진행 중!\n새해를 맞아 커리어 고민 타파 + 성장할 사람 찾습니다!\n우아한형제들 현직자 멘토에게 배우는 실무형 유데미 강의 + 1:1 커피챗 기회\n\n\n참여 방법 : 이벤트 기간 동안 유데미 강의를 수강하고 커피챗 신청하면 - 완료!\n이벤트 기간 : 25년 2월 5일 ~ 3월 5일까지\n자세한 내용은 커리큘럼 1섹션을 확인해 주세요!\n\n\n\n\n우아한형제들의 사내 강의로도 제공되는 콘텐츠로써 전사교육팀과 함께 구성원들의 성장을 위해 기획/개발되었습니다(우아한러닝의 러닝이끄미 프로젝트로 제작된 강의)\n\n\n이 강의는 빅데이터의 정의, 데이터 관련 직군과 패러다임/핵심용어부터 데이터 엔지니어링까지 포괄적으로 다룹니다. 데이터의 중요성을 강조하며, 빅데이터의 정의와 특성, 데이터 프로덕트의 개념을 시작으로, 데이터 관련 직군의 역할과 필요한 기술을 설명합니다. 현대 데이터 관리의 핵심 용어와 개념을 체계적으로 습득하고, 데이터 엔지니어링의 정의와 데이터 파이프라인 그리고 데이터 아키텍처를 설명합니다.\n이 강의는 특정 기술을 깊게 분석하거나 다양한 아키텍처를 소개하거나 하지 않습니다. 오히려 그런 지식을 쌓기 전에 어떤 방향으로 공부를 해야하는지를 알려줄 수 있는 나침반이나 미니맵 같은 강의입니다. 데이터 초보자를 위한 완벽한 가이드로, 데이터와 관련된 복잡한 개념들을 쉽게 이해할 수 있도록 구성되어 있습니다.\n\n\n1. 데이터 분야 입문\n빅데이터의 정의, 시작과 역사에 대한 이야기도 하고 데이터 프로덕트라는 것에 대해 배웁니다.\n데이터에 연관된 직군과 그 역할에 대해서도 배우게 됩니다.\n\n\n2. 데이터 관련 패러다임이나 용어\n업무를 하다보면 많이 듣게 되거나 실제로 업무에도 적용해야 하는 데이터 관련 패러다임이나 관련 용어에 대해 설명드립니다.\n\n\n3. 데이터 엔지니어링 입문\n데이터 엔지니어링의 정의와 가치, 다양한 데이터 처리 방식에 대해 설명합니다. 데이터 플랫폼을 다루거나 아키텍처를 설계할 때 가장 중요한 데이터 웨어하우스(Data Warehouse), 데이터 마크(Data Mart), 데이터 레이크(Data Lake)에 대해서도 자세히 설명하여 실무에 도움을 주고자 합니다. 또한 데이터 플랫폼 및 도구를 분야별로 설명하여 이 분야의 전체에 대해 쉽게 오버뷰할 수 있게 합니다.",
      "target_audience": [
        "데이터나 AI 관련 프로젝트에 입문하시는 분들",
        "데이터 직군과 협업하는 모든 분들(PM, PO, 서비스 기획자, 개발자 등)",
        "데이터 분야가 부담스럽고 막막한 비전공자 분들",
        "데이터 엔지니어로 커리어를 발전시키고 싶은 분"
      ]
    },
    {
      "title": "เรียน AI Prompt Engineering ใช้ AI สร้างสรรค์งานมืออาชีพ",
      "url": "https://www.udemy.com/course/aipromptengineer/",
      "bio": "เรียน AI Prompt Engineering เขียน Prompt สั่งงาน AI สร้างสรรค์งานมืออาชีพ เปลี่ยนคนธรรมดาให้เป็นคนเก่ง Zero to Hero",
      "objectives": [
        "ผู้เรียนสามารถใช้งาน Generative AI เพื่อ Productivity X100 ในการทำงานได้อย่างมีประสิทธิภาพ",
        "ผู้เรียนสามารถเลือกใช้งานเครื่องมือ Generative AI ให้เหมาะสมกับงานที่ต้องทำได้อย่างมีประสิทธิภาพ",
        "ผู้เรียนจะได้เรียนรู้การใช้งานเครื่องมือ AI เช่น ChatGPT, Claude AI, Perplexity, Adobe Firefly, Pixverse, Haiper, Runway, Suno และเครื่องมืออื่น ๆ",
        "ผู้เรียนสามารถเขียน Prompt เพื่อสั่งงาน AI ให้แสดงผลลัพธ์ได้อย่างมีประสิทธิภาพและตรงตามโจทย์ที่ต้องการได้",
        "ผู้เรียนสามารถเขียน Prompt เพื่อสั่งงาน AI สร้างสรรค์งานเขียนต่าง ๆ เช่น บทความ งานวิจัย โฆษณาการตลาด หนังสือ และการเขียนโปรแกรม ได้อย่างมีประสิทธิภาพ",
        "ผู้เรียนสามารถเขียน Prompt เพื่อสั่งงาน AI สร้างสรรค์งานศิลปะ รูปภาพ ให้ตรงตามความต้องการได้",
        "ผู้เรียนสามารถเขียน Prompt เพื่อสั่งงาน AI สร้างสรรค์สื่อ Multimedia เช่น Video และ Music ให้ตรงตามความต้องการได้",
        "ผู้เรียนสามารถนำความรู้ที่ได้ไปประยุกต์ใช้ในการทำงานและ Projects ต่าง ๆ ได้จริง"
      ],
      "course_content": {
        "ทำไมคนที่ใช้ AI เป็นถึงสำคัญมากในยุคนี้": [
          "แนะนำคอร์สเรียน AI Prompt Engineering ใช้ AI สร้างสรรค์งานมืออาชีพ",
          "ทำไมต้องใช้ AI ให้เป็น",
          "Pain Point ของ Google นำไปสู่การเกิดขึ้นของ ChatGPT",
          "คุณค่าที่จะได้รับเมื่อใช้ AI เป็น",
          "สิ่งที่ควรระวังในการใช้งาน Generative AI"
        ],
        "ทำความรู้จักกับเครื่องมือ AI": [
          "วิวัฒนาการและควาหมายของ AI สู่ Generative AI",
          "ประเภทของเครื่องมือ Generative AI",
          "สมัครใช้งาน ChatGPT บนเว็บไซต์",
          "สมัครใช้งาน Claude AI บนเว็บไซต์",
          "สมัครใช้งาน ChatGPT, Claude ผ่าน Mobile Application"
        ],
        "Workshop 1 เทคนิคการเขียน Prompt สั่งงาน AI แบบง่าย ๆ": [
          "Example 1.1 ใช้ AI เป็นที่ปรึกษาส่วนตัว",
          "Example 1.2 ใช้ AI ให้คำแนะนำ",
          "Example 1.3 ใช้ AI สร้างรูปภาพ",
          "Example 1.4 ใช้ AI แนะนำสิ่งที่ไม่ดี"
        ],
        "Workshop 2 เทคนิคการเขียน Prompt สั่งงาน AI อย่างมืออาชีพ": [
          "Example 2.1 ใช้ AI สร้างบทละคร Part 1",
          "Example 2.1 ใช้ AI สร้างบทละคร Part 2",
          "Example 2.2 ใช้ AI สร้างกลยุทธ์การจัดงาน Part 1",
          "Example 2.2 ใช้ AI สร้างกลยุทธ์การจัดงาน Part 2",
          "Example 2.3 ใช้ AI ร่างหลักสูตรการฝึกอบรม Part 1",
          "Example 2.3 ใช้ AI ร่างหลักสูตรการฝึกอบรม Part 2"
        ],
        "Workshop 3 ใช้ AI ค้นหาข้อมูล เพื่อนำไปใช้งานและสรุปผลข้อมูลแบบมี Reference": [
          "Example 3.1 ใช้ AI ค้นหาข้อมูลและสรุปผลข้อมูลแบบมีแหล่งอ้างอิง"
        ],
        "Workshop 4 ใช้ AI สร้างงานเขียนต่าง ๆ": [
          "Example 4.1 ใช้ AI สร้างงานเขียน Email Part 1",
          "Example 4.1 ใช้ AI สร้างงานเขียน Email Part 2",
          "Example 4.1 ใช้ AI สร้างงานเขียน Email Part 3",
          "Example 4.2 ใช้ AI สร้างงานเขียน Memo Part 1",
          "Example 4.2 ใช้ AI สร้างงานเขียน Memo Part 2",
          "Example 4.2 ใช้ AI สร้างงานเขียน Memo Part 3",
          "Example 4.3 ใช้ AI สร้างงานเขียน Meeting Agenda Part 1",
          "Example 4.3 ใช้ AI สร้างงานเขียน Meeting Agenda Part 2",
          "Example 4.3 ใช้ AI สร้างงานเขียน Meeting Agenda Part 3",
          "Example 4.4 ใช้ AI สร้างงานเขียนรายงานหรือสรุปการประชุม Part 1",
          "Example 4.4 ใช้ AI สร้างงานเขียนรายงานหรือสรุปการประชุม Part 2",
          "Example 4.4 ใช้ AI สร้างงานเขียนรายงานหรือสรุปการประชุม Part 3",
          "Example 4.5 ใช้ AI สร้างงานเขียนร่างกำหนดการจัดงาน Part 1",
          "Example 4.5 ใช้ AI สร้างงานเขียนร่างกำหนดการจัดงาน Part 2",
          "Example 4.5 ใช้ AI สร้างงานเขียนร่างกำหนดการจัดงาน Part 3",
          "Example 4.6 ใช้ AI สร้างงานเขียนข้อความ Campaign ประชาสัมพันธ์ Part 1",
          "Example 4.6 ใช้ AI สร้างงานเขียนข้อความ Campaign ประชาสัมพันธ์ Part 2",
          "Example 4.6 ใช้ AI สร้างงานเขียนข้อความ Campaign ประชาสัมพันธ์ Part 3",
          "Example 4.7 ใช้ AI สร้างงานเขียนข้อความ Campaign ขายสินค้า Part 1",
          "Example 4.7 ใช้ AI สร้างงานเขียนข้อความ Campaign ขายสินค้า Part 2",
          "Example 4.7 ใช้ AI สร้างงานเขียนข้อความ Campaign ขายสินค้า Part 3",
          "Example 4.8 ใช้ AI สร้างงานเขียนบทความ Part 1",
          "Example 4.8 ใช้ AI สร้างงานเขียนบทความ Part 2",
          "Example 4.8 ใช้ AI สร้างงานเขียนบทความ Part 3"
        ],
        "Workshop 5 ใช้ AI อ่านไฟล์และเขียนสรุปงานวิจัย": [
          "Example 5.1 ใช้ AI อ่านไฟล์และเขียนสรุปงานวิจัยแบบกระชับ Part 1",
          "Example 5.1 ใช้ AI อ่านไฟล์และเขียนสรุปงานวิจัยแบบกระชับ Part 2",
          "Example 5.1 ใช้ AI อ่านไฟล์และเขียนสรุปงานวิจัยแบบกระชับ Part 3",
          "Example 5.2 ใช้ AI เขียนสรุปงานวิจัยแบบละเอียด Part 1",
          "Example 5.2 ใช้ AI เขียนสรุปงานวิจัยแบบละเอียด Part 2",
          "Example 5.2 ใช้ AI เขียนสรุปงานวิจัยแบบละเอียด Part 3"
        ],
        "Workshop 6 ใช้ AI ช่วยวิเคราะห์ข้อมูล สรุปผล และแสดงกราฟ": [
          "Example 6.1 ใช้ AI วิเคราะห์ข้อมูลด้วยการใส่ข้อมูล",
          "Example 6.2 ใช้ AI วิเคราะห์ข้อมูลสร้างกราฟผ่านไฟล์"
        ],
        "Workshop 7 ใช้ AI ช่วยบริหารจัดการโครงการ": [
          "Example 7.1 ใช้ AI ช่วยบริหารจัดการโครงการพัฒนาเกม ROV",
          "Example 7.2 ใช้ AI ช่วยบริหารจัดการโครงการ Open House"
        ],
        "Workshop 8 ใช้ AI ช่วยสร้างแบบสอบถาม": [
          "Example 8.1 ใช้ AI ช่วยสร้างแบบสอบถาม"
        ]
      },
      "requirements": [
        "ผู้เรียนต้องมีความรู้พื้นฐานด้านการใช้ภาษาในการสื่อสารกับ AI ได้"
      ],
      "description": "หลักสูตร เรียน AI Prompt Engineering ใช้ AI สร้างสรรค์งานมืออาชีพ\nสามารถเรียนได้ทุกคน ไม่จำเป็นต้องมีความรู้มาก่อน\nเนื้อหาการเรียน AI Prompt Engineering เขียน Prompt สั่งงาน AI สร้างสรรค์งานมืออาชีพ เปลี่ยนคนธรรมดาให้เป็นคนเก่ง Zero to Hero\nเป็นการเรียนแบบทำ Workshops ไปพร้อมกัน\nเรียน AI Prompt Engineering ใช้ AI สร้างสรรค์งานมืออาชีพ\nส่วนที่ 1: ทำไมคนที่ใช้ AI เป็นถึงสำคัญมากในยุคนี้\n1. แนะนำคอร์สเรียน AI Prompt Engineering ใช้ AI สร้างสรรค์งานมืออาชีพ\n2. ทำไมต้องใช้ AI ให้เป็น\n3. Pain Point ของ Google นำไปสู่การเกิดขึ้นของ ChatGPT\n4. คุณค่าที่จะได้รับเมื่อใช้ AI เป็น\n5. สิ่งที่ควรระวังในการใช้งาน Generative AI\nส่วนที่ 2: ทำความรู้จักกับเครื่องมือ AI\n6. วิวัฒนาการและความหมายของ AI สู่ Generative AI\n7. ประเภทของเครื่องมือ Generative AI\n8. สมัครใช้งาน ChatGPT บนเว็บไซต์\n9. สมัครใช้งาน Claude AI บนเว็บไซต์\n10. สมัครใช้งาน ChatGPT, Claude ผ่าน Mobile Application\nส่วนที่ 3: Workshop 1 เทคนิคการเขียน Prompt สั่งงาน AI แบบง่าย ๆ\n11. Example 1.1 ใช้ AI เป็นที่ปรึกษาส่วนตัว\n12. Example 1.2 ใช้ AI ให้คำแนะนำ\n13. Example 1.3 ใช้ AI สร้างรูปภาพ\n14. Example 1.4 ใช้ AI แนะนำสิ่งที่ไม่ดี\nส่วนที่ 4: Workshop 2 เทคนิคการเขียน Prompt สั่งงาน AI อย่างมืออาชีพ\n15. Example 2.1 ใช้ AI สร้างบทละคร Part 1\n16. Example 2.1 ใช้ AI สร้างบทละคร Part 2\n17. Example 2.2 ใช้ AI สร้างกลยุทธ์การจัดงาน Part 1\n18. Example 2.2 ใช้ AI สร้างกลยุทธ์การจัดงาน Part 2\n19. Example 2.3 ใช้ AI ร่างหลักสูตรการฝึกอบรม Part 1\n20. Example 2.3 ใช้ AI ร่างหลักสูตรการฝึกอบรม Part 2\nส่วนที่ 5: Workshop 3 ใช้ AI ค้นหาข้อมูล เพื่อนำไปใช้งานและสรุปผลข้อมูลแบบมี Reference\n21. Example 3.1 ใช้ AI ค้นหาข้อมูลและสรุปผลข้อมูลแบบมีแหล่งอ้างอิง\nส่วนที่ 6: Workshop 4 ใช้ AI สร้างงานเขียนต่าง ๆ\n22. Example 4.1 ใช้ AI สร้างงานเขียน Email Part 1\n23. Example 4.1 ใช้ AI สร้างงานเขียน Email Part 2\n24. Example 4.1 ใช้ AI สร้างงานเขียน Email Part 3\n25. Example 4.2 ใช้ AI สร้างงานเขียน Memo Part 1\n26. Example 4.2 ใช้ AI สร้างงานเขียน Memo Part 2\n27. Example 4.2 ใช้ AI สร้างงานเขียน Memo Part 3\n28. Example 4.3 ใช้ AI สร้างงานเขียน Meeting Agenda Part 1\n29. Example 4.3 ใช้ AI สร้างงานเขียน Meeting Agenda Part 2\n30. Example 4.3 ใช้ AI สร้างงานเขียน Meeting Agenda Part 3\n31. Example 4.4 ใช้ AI สร้างงานเขียนรายงานหรือสรุปการประชุม Part 1\n32. Example 4.4 ใช้ AI สร้างงานเขียนรายงานหรือสรุปการประชุม Part 2\n33. Example 4.4 ใช้ AI สร้างงานเขียนรายงานหรือสรุปการประชุม Part 3\n34. Example 4.5 ใช้ AI สร้างงานเขียนร่างกำหนดการจัดงาน Part 1\n35. Example 4.5 ใช้ AI สร้างงานเขียนร่างกำหนดการจัดงาน Part 2\n36. Example 4.5 ใช้ AI สร้างงานเขียนร่างกำหนดการจัดงาน Part 3\n37. Example 4.6 ใช้ AI สร้างงานเขียนข้อความ Campaign ประชาสัมพันธ์ Part 1\n38. Example 4.6 ใช้ AI สร้างงานเขียนข้อความ Campaign ประชาสัมพันธ์ Part 2\n39. Example 4.6 ใช้ AI สร้างงานเขียนข้อความ Campaign ประชาสัมพันธ์ Part 3\n40. Example 4.7 ใช้ AI สร้างงานเขียนข้อความ Campaign ขายสินค้า Part 1\n41. Example 4.7 ใช้ AI สร้างงานเขียนข้อความ Campaign ขายสินค้า Part 2\n42. Example 4.7 ใช้ AI สร้างงานเขียนข้อความ Campaign ขายสินค้า Part 3\n43. Example 4.8 ใช้ AI สร้างงานเขียนบทความ Part 1\n44. Example 4.8 ใช้ AI สร้างงานเขียนบทความ Part 2\n45. Example 4.8 ใช้ AI สร้างงานเขียนบทความ Part 3\nส่วนที่ 7: Workshop 5 ใช้ AI อ่านไฟล์และเขียนสรุปงานวิจัย\n46. Example 5.1 ใช้ AI อ่านไฟล์และเขียนสรุปงานวิจัยแบบกระชับ Part 1\n47. Example 5.1 ใช้ AI อ่านไฟล์และเขียนสรุปงานวิจัยแบบกระชับ Part 2\n48. Example 5.1 ใช้ AI อ่านไฟล์และเขียนสรุปงานวิจัยแบบกระชับ Part 3\n49. Example 5.2 ใช้ AI เขียนสรุปงานวิจัยแบบละเอียด Part 1\n50. Example 5.2 ใช้ AI เขียนสรุปงานวิจัยแบบละเอียด Part 2\n51. Example 5.2 ใช้ AI เขียนสรุปงานวิจัยแบบละเอียด Part 3\nส่วนที่ 8: Workshop 6 ใช้ AI ช่วยวิเคราะห์ข้อมูล สรุปผล และแสดงกราฟ\n52. Example 6.1 ใช้ AI วิเคราะห์ข้อมูลด้วยการใส่ข้อมูล\n53. Example 6.2 ใช้ AI วิเคราะห์ข้อมูลสร้างกราฟผ่านไฟล์\nส่วนที่ 9: Workshop 7 ใช้ AI ช่วยบริหารจัดการโครงการ\n54. Example 7.1 ใช้ AI ช่วยบริหารจัดการโครงการพัฒนาเกม ROV\n55. Example 7.2 ใช้ AI ช่วยบริหารจัดการโครงการ Open House\nส่วนที่ 10: Workshop 8 ใช้ AI ช่วยสร้างแบบสอบถาม\n56. Example 8.1 ใช้ AI ช่วยสร้างแบบสอบถาม\nส่วนที่ 11: Workshop 9 ใช้ AI สรุปข้อมูลคลิปบน YouTube พร้อมแปลภาษา\n57. Example 9.1 ใช้ AI สรุปข้อมูลคลิปบน YouTube พร้อมแปลภาษา\nส่วนที่ 12: Workshop 10 ใช้ AI สรุปข้อมูลบน Website พร้อมแปลภาษา\n58. Example 10.1 ใช้ AI สรุปข้อมูลบน Website พร้อมแปลภาษา\nส่วนที่ 13: Workshop 11 ใช้ AI สร้าง Mindmap\n59. Example 11.1 ใช้ AI สร้าง Mindmap\nส่วนที่ 14: Workshop 12 ใช้ AI เขียนโปรแกรม\n60. Example 12.1 ใช้ AI เขียนโปรแกรมสร้างเกมแบบธรรมดา\n61. Example 12.2 ใช้ AI เขียนโปรแกรมสร้างเกมอย่างมืออาชีพจนเล่นได้จริง\nส่วนที่ 15: Workshop 13 เทคนิคการเขียน Prompt สั่งงาน AI สร้างรูปภาพ แบบง่าย ๆ\n62. Example 13.1 ใช้ AI เขียน Prompt สร้างรูปภาพ แบบง่าย ๆ\nส่วนที่ 16: Workshop 14 เทคนิคการเขียน Prompt สั่งงาน AI สร้างรูปภาพ ด้วย Framework พื้นฐาน\n63. Example 14.1 ใช้ AI เขียน Prompt สร้างรูปภาพอาหาร\n64. Example 14.2 ใช้ AI เขียน Prompt สร้างรูปภาพสัตว์\n65. Example 14.3 ใช้ AI เขียน Prompt สร้างรูปภาพบุคคล\n66. Example 14.4 ใช้ AI เขียน Prompt ขั้นสูง สร้างรูปภาพและปรับแต่ง Poster\n67. Example 14.5 ใช้ AI เขียน Prompt ขั้นสูง สร้างรูปภาพตัวละคร Mascot\n68. Example 14.6 ใช้ AI เขียน Prompt สร้างรูปภาพพื้นหลัง Background\nส่วนที่ 17: Workshop 15 เทคนิคการเขียน Prompt สั่งงาน AI สร้างรูปภาพ ด้วย Framework ขั้นสูง\n69. Example 15.1 ใช้ AI เขียน Prompt ขั้นสูง สร้างรูปภาพสัตว์แบบลงรายละเอียด\n70. Example 15.2 ใช้ AI เขียน Prompt ขั้นสูง สร้างรูปภาพคนแบบลงรายละเอียด\n71. Example 15.3 ใช้ AI เขียน Prompt ขั้นสูง สร้างรูปคนแบบลงรายละเอียดด้วย FLUX\nส่วนที่ 18: Workshop 16 เทคนิคการเขียน Prompt สั่งงาน AI สร้าง Video\n72. Example 16.1 ใช้ AI เขียน Prompt สร้าง Video รูปบุคคล\n73. Example 16.2 ใช้ AI เขียน Prompt สร้าง Video ตัวการ์ตูน 3D Pixar\n74. Example 16.3 ใช้ AI เขียน Prompt สร้าง Video ฉาก Background ธรรมชาติ\n75. เทคนิคการเขียน Prompt สร้าง Video ด้วย Framework อย่างมืออาชีพ\n76. Example 16.4 ใช้ AI เขียน Prompt สร้าง Video ด้วย Framework อย่างมืออาชีพ\nส่วนที่ 19: Workshop 17 ใช้ AI แต่งเพลงและร้องเพลงให้ฟัง\n77. Workshop 17.1 ใช้ AI สร้างเสียงเพลงและร้องเพลงให้ฟัง แบบง่าย ๆ\n78. Workshop 17.2 ใช้ AI สร้างเสียงเพลงและร้องเพลงให้ฟัง แบบปรับแต่งได้\n79. เทคนิคการเขียน Prompt สั่งงาน AI สร้างเนื้อเพลง\n80. Workshop 17.3 ใช้ AI สร้างเสียงเพลงและร้องเพลงให้ฟังด้วยเนื้อเพลงที่แต่งขึ้น\nส่วนที่ 20: สรุปเนื้อหาการเรียน AI Prompt Engineering พร้อมแหล่งเรียนรู้เพิ่มเติม\n81. สรุปเทคนิคการเขียน Prompt สั่งงาน AI เพื่อสร้างงานเขียน\n82. สรุปเทคนิคการเขียน Prompt สั่งงาน AI เพื่อสร้างรูปภาพ\n83. สรุปเทคนิคการเขียน Prompt สั่งงาน AI เพื่อสร้าง Video\n84. แหล่งรวมเทคนิคการเขียน Prompt แบบ Best Practices และช่องทางขาย Digital Products",
      "target_audience": [
        "ผู้เริ่มต้นเรียนรู้การใช้งาน AI เพื่อการเรียนและการทำงาน พนักงานบริษัท มนุษย์เงินเดือน โปรแกรมเมอร์ นักออกแบบงานศิลปะ Creative นักการตลาด นักวิเคราะห์ข้อมูล ผู้บริหาร นักเรียน นักศึกษา อาจารย์ และผู้ที่สนใจในการใช้ AI เพิ่มความเร็วและประสิทธิภาพในการทำงานอย่างมืออาชีพ"
      ]
    },
    {
      "title": "ChatGPT Masterclass , Genius: Una Guía Completa de ChatGPT !",
      "url": "https://www.udemy.com/course/descubre-y-domina-chatgpt-4-genius-una-guia-completa/",
      "bio": "ChatGPT para principiantes y expertos: Una guía completa para iniciar o escalar un negocio con Inteligencia Artificial",
      "objectives": [
        "Chat GTP como SEO, en el comercio electrónico, traducción, Amazon y textos de venta utilizando ChatGPT",
        "Destaca frente a la competencia en tu negocio utilizando Chat GPT",
        "Técnicas para utilizar ChatGPT para crear contenido personalizado, rentable y atractivo en YouTube",
        "Cómo generar imágenes de gran calidad utilizando la tecnología Dalle-2",
        "Cómo permitir que ChatGPT acceda a información del futuro (2023) y superar las limitaciones en la información indexada que tiene actualmente",
        "Aprende a hacer más fácil tu trabajo académico generando presentaciones en PowerPoint y mapas mentales de manera casi instantánea con chat GTP",
        "Escribe tu primer cuento, poesia o novela con En Minutos!",
        "Chat GTP para aprender Ingles o cualquier idioma en modo profesional",
        "Contaras con material de apoyo en PDF para dominar DALLE-2 y CHAT GTP"
      ],
      "course_content": {
        "Descubriendo el Poder de la Inteligencia Artificial: Curso de ChatGPT Genius": [
          "Bienvenido a la IA mas avanzada del mundo : Chat GTP",
          "Pasando a Chat GTP - 4 PLUS!"
        ],
        "Conectada a internet 2023 - Complementos super útiles para Chat GTP": [
          "Cómo utilizar Chat GPT al máximo de su capacidad : los mejores plugins!"
        ],
        "Desbloqueando el Potencial de ChatGPT: Introducción a la Ingeniería de Prompts": [
          "Ingeniería de Prompts: Optimizando la Conversación con ChatGPT",
          "Construyendo Interacciones Más Inteligentes: Mejores Prompts"
        ],
        "Inteligencia Artificial para Crear y Optimizar tus Posts en Redes Sociales": [
          "Desarrolla Ideas De Negocios Con El Poder De La Inteligencia Artificial",
          "Post Perfectos: Diseña y Planifica Contenidos Atractivos para tus Redes Sociales",
          "Creando Contenido de Pago para Tus redes, GRATIS! con Chat GTP",
          "Aprende a redactar correos electrónicos como un experto, fácil y rápido"
        ],
        "ChatGPT Academy: Aprende Inglés de Manera Rápida y Eficaz con IA": [
          "Aprendizaje 2.0: Mejora tus Habilidades en Inglés con la Ayuda de ChatGPT",
          "Modo Profesional con ChatGPT: Aprende y Perfecciona tu Inglés"
        ],
        "Estudia Inteligentemente: Mejora tus Habilidades y Resultados con ChatGPT": [
          "Resúmenes Eficientes: Aprende a Crear Síntesis de Textos con Chat GTP",
          "Rápido y Fácil: Crea Diapositivas y Mapas Mentales Asombrosos en Minutos",
          "Herramientas de IA avanzadas; para Identificar Plagio y Asegurar la Originalidad"
        ],
        "Escritor 2.0 : Escribiendo Tu primera Novela, cuento o Poesía Con Chat GTP": [
          "Inspiración Artificial: Escribe tu primer LIBRO!"
        ],
        "Escribir guiones de video nunca fue tan fácil: Ahorra tiempo y mejora la calidad": [
          "Domina el Arte de Crear y Producir Podcasts en Minutos",
          "Genera guiones de video creativos y únicos para mejorar el enganche",
          "Potencia tu creatividad: Prompts y Resúmenes inteligentes para tus videos"
        ],
        "Mejora tu bienestar y salud con una dieta personalizada potenciada con IA": [
          "Crea dietas personalizadas y saludables, según tus necesidades, en MINUTOS!"
        ],
        "Inteligencia artificial para el éxito empresarial: Chat GTP en los negocios!": [
          "SEO impulsado por IA: aumenta tu visibilidad en línea y haz crecer tu negocio",
          "Aumenta tus ventas con Email Marketing : hacia el éxito empresarial",
          "Cómo crear negocios exitosos con la IA : tips y trucos para impulsar tus ideas!",
          "Cómo utilizar IA para crear una ventaja competitiva y hacer crecer tu negocio",
          "Potencia tus estrategias y procesos de ventas en E-Commerce con Chat GTP"
        ]
      },
      "requirements": [
        "None needed! Just a willingness to learn and a desire to take advantage of the absolutely amazing technology that is ChatGPT and Dalle! Internet connection and hey look- you already have that because you're reading this right now!"
      ],
      "description": "¡La tecnología del momento ! Si quieres convertirte en un experto en ChatGPT, no pierdas la oportunidad de inscribirte en el curso más completo y atractivo que encontrarás en Udemy.\nBienvenido a ChatGPT Genius, el curso más completo sobre ChatGPT/OpenAI que podrás encontrar en internet, presentado por expertos en marketing y publicidad.\nChatGPT es una herramienta increíble para emprendedores, empresas e individuos que quieran estar a la vanguardia de la tecnología y hacer crecer sus negocios en línea de manera rápida y eficiente. En nuestro curso, te enseñaremos cómo utilizamos ChatGPT y OpenAI a nivel profesional y cómo tú también puedes hacerlo.\nAl completar este curso, tendrás las habilidades necesarias para:\nUtilizar ChatGPT para crear contenido optimizado para SEO. ChatGPT te ayudará a escribir artículos que generen tráfico hacia tu sitio. Aprenderás a investigar palabras clave, estructurar el contenido de manera efectiva y utilizar las avanzadas capacidades de procesamiento de lenguaje de ChatGPT para producir copias de alta calidad que se posicionen en los primeros resultados de búsqueda.\nUtilizar ChatGPT para comercio electrónico y ventas. Aprenderás a identificar mercados objetivo y nichos rentables, destacar los puntos fuertes de tus productos y crear llamados a la acción que generen ventas.\nUtilizar ChatGPT para crear contenido extenso. ChatGPT puede ayudarte a escribir podcasts de calidad profesional en cuestión de minutos. Te enseñaremos cómo utilizar ChatGPT para investigar temas, estructurar tus episodios/ofertas y generar contenido informativo y atractivo que conecte con tu audiencia. Además, también te enseñaremos cómo utilizar OpenAI para crear otros tipos de contenido extenso, como libros electrónicos, novelas o cuentos.\n\n\nAl final de este curso, tendrás un conocimiento profesional de ChatGPT. Serás capaz de producir contenido de alta calidad de manera eficiente, lo que te permitirá aumentar tu potencial de ganancias.\nNo esperes más. Inscríbete hoy en nuestro popular de ChatGPT Genius y comienza a aprovechar el poder de la inteligencia artificial para producir contenido de alta calidad para tu negocio o tus clientes. ¡Te esperamos en el curso!",
      "target_audience": [
        "Entrepreneurs looking to produce content on the internet!",
        "Emprendedores y profesionales de negocios que buscan optimizar sus operaciones, mejorar la atención al cliente y automatizar tareas mediante el uso de ChatGPT",
        "Estudiantes y académicos que deseen aprovechar las ventajas de la inteligencia artificial en la investigación, la redacción de ensayos y la optimización del proceso de aprendizaje.",
        "Creadores de contenido, community managers y especialistas en marketing digital que desean utilizar ChatGPT para generar contenido atractivo y personalizado en sus redes sociales y plataformas de comunicación",
        "Desarrolladores y entusiastas de la tecnología que buscan ampliar sus conocimientos en IA y ChatGPT para implementar soluciones innovadoras en sus proyectos y carreras."
      ]
    },
    {
      "title": "大白话ChatGPT",
      "url": "https://www.udemy.com/course/chatgpt-hn/",
      "bio": "聊聊今年最火的ChatGPT是什么",
      "objectives": [
        "ChatGPT是什么,为何拥有这些能力和局限",
        "聊聊今年最火的ChatGPT是什么",
        "让完全不懂技术的人也能迅速理解AI",
        "ChatGPT和它背后的技术和机会"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "这是一场值得打的战争，有必要再做一个ChatGPT",
          "ChatGPT离通用型人工智能还很远",
          "ChatGPT为何是个理科很差的文科生",
          "再做一个ChatGPT，好像哥伦布第二次去新大陆",
          "AIGC来临“我”会不会失业",
          "GPT来源以及含义",
          "假如AI时代带来巨大的财富，如何分配是个问题",
          "历史告诉我们要想成为新的Leader，就要在变迁中抓住机会",
          "ChatGPT把人类和机器的交互推进了一个时代",
          "ChatGPT未来可以具体应用在哪些领域？",
          "ChatGPT到底有没有自我意识？",
          "从ChatGPT的“意识”看人类本身的意识"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "对ai有一定了解和兴趣的人"
      ],
      "description": "你是否曾经在大数据的海洋中迷失，对未知的职场世界感到迷茫？在大数据时代，职场对人才的需求正在悄然改变。为了帮助你适应这种变革，《大白话ChatGPT》课程应运而生。\n为此，三节课与王建硕老师、百姓AI携手共同带来本门课程。 本课程以通俗易懂的方式，全面解析大数据时代职场的需求，以及如何运用ChatGPT技术提升自我价值。将深入浅出地讲解大数据的基本概念和应用，让你对大数据有全面的认识。将教授如何使用ChatGPT进行自然语言处理，让机器理解你的语言，为你所用。同时也将结合大数据和ChatGPT技术，教授如何在职场中提升自我价值，成为未来的职场精英。",
      "target_audience": [
        "向往AI智能生活的普通人 对使用AI聊天技术感兴趣的人 愿意探索更多Al技术的应用场景的爱好者"
      ]
    },
    {
      "title": "【Hands Onで学ぶ】データサイエンスのための深層強化学習入門",
      "url": "https://www.udemy.com/course/drl-python/",
      "bio": "最先端の強化学習手法を学び、PyTorchで実践しよう",
      "objectives": [
        "深層強化学習の全体像、適用範囲、トレンドについて理解できる",
        "方策勾配法と方策勾配定理について理解できる",
        "深層強化学習で中心的役割を果たすActor Criticについて学べる",
        "Actor Criticの手法であるDDPG, SACの理論的背景とPyTorchによる実装"
      ],
      "course_content": {
        "はじめに": [
          "コース概要説明",
          "強化学習の復習",
          "講座で使用したソースコード"
        ],
        "方策勾配法": [
          "方策勾配法",
          "方策勾配法と連続空間",
          "方策勾配定理の証明"
        ],
        "Actor Critic": [
          "Actor Critic",
          "DDPG(I)",
          "DDPG(II)",
          "DDPG(III)",
          "DDPG(実装) part1",
          "DDPG(実装) part2",
          "DDPG(実装) part3",
          "DDPG(実装) part4",
          "DDPG(実装) part5",
          "DDPG(実装) part6",
          "DDPG(実装) part7",
          "DDPG(実装) part8",
          "DDPG(実装) part9",
          "DDPG(実装) part10",
          "DDPG(実装) part11",
          "報酬整形",
          "報酬整形(実装)",
          "SAC(I)",
          "SAC(II)",
          "SAC(III)",
          "SAC(実装) part 1",
          "SAC(実装) part 2",
          "SAC(実装) part 3",
          "SAC(実装) part 4",
          "SAC(実装) part 5",
          "SAC(実装) part 6",
          "SAC(実装) part 7",
          "SAC(実装) part 8",
          "収束のテクニック"
        ],
        "ボーナスセクション": [
          "講座で使用したnotebook",
          "講座で使用したパワーポイント"
        ]
      },
      "requirements": [
        "【Hands Onで学ぶ】データサイエンスのための強化学習入門を修了している、もしくは同等の知識"
      ],
      "description": "【本講座の概要】\n本講座は、データサイエンスで用いられる深層強化学習（DRL）の基礎を学ぶコースです。\n近年、DRL は広告入札最適化、在庫補充、レコメンデーション、ロボット制御など “自動化された意思決定” 領域で注目を集めています。 特に深層強化学習はエージェントにディープラーニングを用いることで、構造データだけでなく、画像や音声などの非構造データも入力データとすることができ、マルチモーダルなエージェントを構築することができます。\n\nしかし、一方でこのような悩みを抱えている人も少なくありません。\n\n深層強化学習は数学的に難解なため、始めたものの理解できない\n実装はできたものの学習が収束せず、どう改善すればいいか分からない\nたくさんのモデルがあり、どの深層強化学習のモデルを使えばいいのか分からない\n\n\n本講座では、入門編である【Hands Onで学ぶ】データサイエンスのための強化学習入門を修了した方向けに、 深層強化学習の基礎からしっかりと学習します。\n特に深層強化学習で中心的な役割を果たすActor Criticの手法について学び、Actor Critic FamilyであるDDPG、SACについて詳細に学びます。\n\n\nこれにより各モデルの背後でどのようなアルゴリズムが動いているのか理解できるようになります。\nまた実装は強化学習のライブラリを使わず、PyTorchによる実装を行います。\nこのため、実装量は多く、大変ではありますが、取り組みの中で、\n数式を実装に落とし込む力を身につけることができるます。\n\n\n実装の中ではTensorboardを使って学習プロセスの可視化を行ったり、\n学習を収束させるための手法である報酬整形についても学ぶことができます。\nこのため、この講座を通して、実業務に近いワークフローで深層強化学習を学ぶことができます。\n\n\nこのコースは深層強化学習の理論的な背景も紹介し、またコードも汎用性の高いコードを実装しますので中級者向けのコースとなっております。\n\n\n【人事の方／マネージャークラスの方へ】\nこの講座は以下のように使用することができます\n\n社内 DX 推進の即戦力育成\n本講座は、理論〜実装〜学習まで一気通貫で学ぶため、ビジネス課題に直結する DRL プロトタイプを最短距離で構築できます。\nハイレベルな人材の育成\n深層強化学習のような最先端の技術を学ぶことで、高度なアプリケーション開発を担える高度人材を育てることができます。\n\n\n【対象者とゴール】\n・【Hands Onで学ぶ】データサイエンスのための強化学習入門を修了し、深層強化学習に興味のあるエンジニア\n・既存のアプリケーションに機械学習ベースの最適化を組み込みたい研究者",
      "target_audience": [
        "深層強化学習に興味のあるエンジニアやデータサイエンティスト",
        "既存の研究に機械学習ベースの最適化を組み込みたい研究者",
        "より実用性の高い強化学習の手法について学びたいPython中級者"
      ]
    },
    {
      "title": "효과적인 업무 역량 강화, 파이썬(python) 비즈니스 데이터 분석 전문가 코스",
      "url": "https://www.udemy.com/course/maso-ds-python-onc89/",
      "bio": "파이썬(python)을 활용한 데이터 분석, 데이터 전처리, 시각화, 업무 자동화까지 수행할 수 있는 과정! 기초 파이썬 코딩부터 시작해서 획득한 역량을 종합적으로 활용하는 실무 프로젝트까지 수행해보자",
      "objectives": [
        "파이썬의 설치부터 가상 환경을 이용한 업무 환경 구축 방법",
        "파이썬 데이터 분석 프로세스의 기본 개념",
        "데이터 구조 파악부터 실전 분석 프로젝트까지의 파이썬 실무",
        "엑셀 데이터를 파이썬으로 손쉽게 처리하는 업무자동화 역량"
      ],
      "course_content": {
        "01. 강의 소개": [
          "[onc89] PTA0001 강의 소개",
          "[onc89] PTA0002 파이썬 설치, 아나콘다 설치와 자바 설치",
          "[onc89] PTA0003 데이터 분석을 위한 가상 개발 환경 소개",
          "[onc89] PTA0004 Jupyter Notebook 사용법"
        ],
        "02. 파이썬을 활용한 엑셀 자동화": [
          "[onc89] PTA0101 데이터 분석의 필요성",
          "[onc89] PTA0102 데이터 분석 대상의 이해",
          "[onc89] PTA0103 데이터 분석 프로세스",
          "[onc89] PTA0104 데이터 분석 도구 파이썬과 엑셀"
        ],
        "03. 데이터 구조와 생성": [
          "[onc89] PTA0201 데이터 구조와 생성",
          "[onc89] PTA0202 데이터 구조 실습",
          "[onc89] PTA0203 데이터 파악하기",
          "[onc89] PTA0204 데이터 파악 실습",
          "[onc89] PTA0205 결측값, 중복값 처리",
          "[onc89] PTA0206 전처리 실습 – 결측값",
          "[onc89] PTA0207 전처리 실습 – 중복값",
          "[onc89] PTA0208 데이터 유형 변환 및 인덱스 설정",
          "[onc89] PTA0209 데이터 변환 실습"
        ],
        "04. 데이터 선별 및 연산": [
          "[onc89] PTA0301 데이터프레임의 행과 열",
          "[onc89] PTA0302 데이터 프레임 기초 실습",
          "[onc89] PTA0303 데이터 변경 및 삭제",
          "[onc89] PTA0304 데이터 변경하기",
          "[onc89] PTA0305 산술, 비교, 일괄 연산",
          "[onc89] PTA0306 파이썬으로 연산하기"
        ],
        "05. 데이터 그룹화 및 테이블 결합": [
          "[onc89] PTA0401 데이터 추출하기",
          "[onc89] PTA0402 데이터 추출 실습",
          "[onc89] PTA0403 데이터 결합",
          "[onc89] PTA0404 데이터 결합 실습",
          "[onc89] PTA0405 데이터 피벗 테이블",
          "[onc89] PTA0406 파이썬 피벗 테이블 실습",
          "[onc89] PTA0407 데이터 결과 출력",
          "[onc89] PTA0408 파이썬 데이터 시각화 실습"
        ],
        "06. 실전 프로젝트": [
          "[onc89] PTA0501 판매 및 매출 분석 사례",
          "[onc89] PTA0502 금융 관련 데이터 분석 사례"
        ]
      },
      "requirements": [
        "실습 위주의 강의이기 때문에 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기를 함께 준비해주시면 좋습니다.",
        "또한 Windows OS 기반으로 실습이 진행되므로, Windows 환경에서의 강의 수강을 추천해드립니다.",
        "강의 교안 및 실습파일은 <00. 교재 다운로드 센터> 섹션에 존재합니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n오늘날의 직장 생활에서 코딩이 얼마나 중요한지는\n이미 모두가 잘 알고 있을 것입니다.\n데이터 분석 역량이 필수가 된 것도\n현업 종사자 및 취준생까지 누구나 느끼고 있을 것입니다.\n하지만 중요성과 접근성은 엄연히 별개라고 말하는 듯한\n코딩 입문의 높은 장벽 또한 모두가 알고 있습니다.\n\n\n그래서 마소캠퍼스에서 여러분을 위해\n'효과적인 업무 역량 강화, 파이썬 비즈니스 데이터 분석 전문가 코스’ 과정을 준비했습니다.\n본 강의는 현대 직장인들이 마주하는 데이터 중심의 업무 현실에 완벽하게 부합하는 코스입니다.\n파이썬을 통해 업무의 효율성을 극대화하고,\n데이터 분석을 손쉽게 할 수 있는 방법을 배울 수 있습니다.\n\n\n본 강의에서는 데이터 분석에 대한 이론적 이해와 함께,\n파이썬 데이터 다루기의 기본부터 실무 적용 기술까지 단계별로 배울 수 있으며,\n실제 업무에 적용할 수 있는 실무 기술을 습득하게 됩니다.\n파이썬과 엑셀을 활용한 데이터 분석은 단순한 기술이 아니라,\n업무의 생산성을 높이고, 보다 전략적인 결정을 내리는 데 필수적인 도구입니다.\n\n\n데이터의 구조와 생성, 전처리 방법, 데이터 프레임 조작 등 다양한 주제를 다루면서,\n여러분이 직접 손으로 따라할 수 있는 코드를 제공합니다.\n코딩을 한 번도 접해보지 못한 분이라도 화면만 보고 따라하실 수 있도록\n하나하나 짚어주며 진행됩니다.\n\n\n이제, 여러분도 파이썬 코딩의 실무자로 거듭나\n이 시대의 직장인이 가져야 할 중요한 역량을 갖추게 될 것입니다.\n마소캠퍼스의 강의와 함께라면, 데이터 분석은 더 이상 어렵지 않습니다.\n\n\n\n\n본 강의에서는 파이썬을 통해 누구나 쉽게 실무 코딩에 입문하고,\n엑셀 기반 업무의 단점을 개선하여 효율적으로 데이터를 분석할 수 있게 돕습니다.\n\n\n\n\n1. 실무 중심의 커리큘럼\n이 과정은 데이터 분석의 기본 이론부터 고급 실습까지 전 과정을 커버합니다.\n특히, 실제 업무에 적용할 수 있는 데이터 분석 기법을 중점적으로 다룹니다.\n\n\n2. 종합적인 데이터 분석 도구 학습\n파이썬과 엑셀을 중심으로 한 데이터 분석 도구의 사용법을 종합적으로 배웁니다.\n이를 통해 업무 효율성을 극대화할 수 있습니다.\n\n\n3. 다양한 실습 및 프로젝트 기회\n데이터 구조와 생성, 전처리, 데이터 프레임 조작 등 다양한 주제에 대한 실습을 통해 실제 데이터 분석 역량을 키우고,\n판매 및 매출 분석, 금융 데이터 분석 사례를 통해 이론과 실습을 실제 상황에 적용해 볼 수 있는 기회를 제공합니다.\n\n\n4. 업무 자동화의 실현\n파이썬을 이용한 업무 자동화 기법을 통해 엑셀 데이터 분석을 더욱 효율적으로 수행할 수 있습니다.\n이를 통해 시간을 절약하고 업무 생산성을 향상시킬 수 있습니다.\n\n\n-\n\n\n[ 강 사  소 개 ]\n정선경\n現 마소캠퍼스 수석 강사\n컴퓨터 공학 학사, 교육학 박사\n現 서울 대학교 대학 혁신센터 데이터 통합 관리부 선임연구원\n정선경 강사는 현재 서울대학교 대학혁신센터 선임연구원으로 데이터 정책 수립을 위한 기초자료 구축 업무와 동시에 강의 활동도 활발히 진행하고 있는 20년 이상의 현업 데이터 분석 전문가이자 교육 전문가이다. 한국 소프트웨어 산업협회에서 공인된 소프트웨어기술 특급기술자로서 국세청, 국가 정보자원관리원 등의 정부기관뿐만 아니라 삼성 SDS, 롯데, SK, BC카드 등 다수의 대기업에서 빅데이터 분석과 인공지능 과정을 개발하고 관련 강의를 진행하며 임직원들의 디지털 역량을 높이는 역할을 담당하고 있다. 데이터 분석 및 측정 도구 개발 뿐만 아니라 네이버 도서 검색 솔루션 개발과 디지털 컨텐츠 제작 관련 사업 이력까지 겸비한 넓은 스펙트럼의 전문 교수자로 Python과 R 프로그래밍, Spark, 인공지능, 머신러닝, 딥러닝 등이 현 전문 분야이다.\n-",
      "target_audience": [
        "데이터 분석과 파이썬 코딩에 관심있는 분",
        "현재 업무에 자동화를 적용하고 싶으신 분",
        "파이썬 사용법을 익혀 높은 업무 효율을 경험하고 싶으신 분",
        "데이터 분석 역량을 키우고 싶은 직장인",
        "취업 시장에서 자신만의 차별성을 강조하고 싶은 취준생",
        "IT업계로 창업/이직/입사 등 커리어를 쌓고 싶은 모든 분"
      ]
    },
    {
      "title": "AIへまっしぐら！Pythonアニマルズ : Go Ahead to AI, Python Animals!",
      "url": "https://www.udemy.com/course/go-ahead-python-animals/",
      "bio": "Pythonで機械学習やディープラーニングに挑戦するプログラミング入門 : Through this programming tutorial, you can try machine learning and deep learning.",
      "objectives": [
        "Pythonを使いながらPythonの魅力（コーディングの快適さ、ライブラリの豊富さ）を体験し、「今、なぜPythonなのか？」を体感できます。",
        "現時点におけるPythonライブラリの目玉機能を一通り体験し、何ができるのか理解できます。",
        "ライブラリを呼び出すのに必要な、Pythonの基本文法を学べます。"
      ],
      "course_content": {
        "はじめに : Introduction": [
          "自己紹介 : Hello!",
          "講座の目的 : Goal of This Course",
          "お勧めの視聴順 : Recommended Viewing Order"
        ],
        "Pythonのインストール : Installing Python": [
          "Pythonのインストール Windows編 : Installing Python on Windows",
          "Pythonのインストール macOS編 : Installing Python on macOS",
          "Pythonのインストール Linux編 : Installing Python on Linux",
          "トラブルシューティング～うまく動作しなかったら : Troubleshooting",
          "ファイルに保存したプログラムの実行：Execution of a Program Saved as a File",
          "トラブルシューティング : Troubleshooting",
          "モジュールのインストール（全OS共通）: Installation of Modules (for all OSes)"
        ],
        "FFT -- NumPy, SciPy, Matplotlib": [
          "FFT（高速フーリエ変換）を楽しもう : Enjoy FFT (fast Fourier transform)",
          "プログラムを見てみよう : Read the program",
          "[文法] インポート文 : [Language] Import Statements",
          "インポート文 : Import statement",
          "[文法] 文、関数 : [Language] Statements and Functions",
          "関数の引数 : Arguments of Functions",
          "[文法] 演算子 : [Language] Operators",
          "演算子 : Operators",
          "[文法] 変数、アンパック、タプル : [Language] Valuables, unpacking and tuples",
          "タプル : Tuples",
          "[文法] 文字列 : [Language] Strings",
          "文字列 : Strings",
          "[文法] インデクス : [Language] Index",
          "インデクス : Indices",
          "[文法] スライス : [Language] Slicing",
          "スライス : Slicing",
          "エピローグ : Epilogue"
        ],
        "ニューラルネットワーク : Neural Network": [
          "ニューラルネットワークで手書き文字を認識しよう : Recognize Numbers You Wrote with a Neural Network.",
          "用語を思い出して！: Memorize a term.",
          "トラブルシューティング～うまく動作しなかったら : Trouble shooting",
          "認識プログラムを見てみよう : Read the Program for Recognition.",
          "ニューラルネットワークとは : What is a neural network ?",
          "[文法] import文 (sp_user.py) : [Language] Import Statements (sp_user.py)",
          "インポート文 : import statements",
          "[文法] 起動時パラメータ、if文、真理値 : [Language] Command Line Arguments, if, Boolean",
          "比較演算子 : Comparison Operator",
          "[文法] オブジェクトとメソッド : [Language] Objects and methods",
          "オブジェクト指向 : Object Oriented",
          "[文法] リスト : [Language] List",
          "タプル : Tuples",
          "[文法] リスト、コンストラクタ : [Language] List, Constructor",
          "コンストラクタ : Constructor",
          "[文法] キーワード引数、辞書、イミュータブル : [Language] Keyword Arguments, Dictionary, Immutable",
          "[文法] プリント関数 : [Language] print() Function",
          "プリント関数 : print() Function",
          "学習プログラムを見てみよう : A program for Learning",
          "[文法] : [Language]"
        ],
        "ディープラーニング : Deep Learning": [
          "畳み込みニューラルネットワークを使おう : Try a convolutional neural network",
          "畳み込み : Convolution",
          "畳み込み演算 : Operation of Convolution",
          "プーリング : Pooling",
          "プーリング : Pooling",
          "認識プログラムを見てみよう : Read the program for recognition",
          "畳み込みニューラルネットワークを構築するプログラムを見てみよう : Read the program for building CNN",
          "[文法] 関数の定義 : [Language] Function definitions",
          "関数の定義 : Function definitions",
          "学習プログラムを見てみよう : Read the program for learning",
          "学習プログラム : Program for learning",
          "[文法] 剰余演算子%、formatメソッド : [Language] Modulo operator, format method",
          "剰余演算子 : Module operator",
          "エピローグ : Epilogue"
        ],
        "より詳しくPythonを学ぼう : Review exercise of Python": [
          "[文法] 変数、for文 : [Language] Variables, for statement",
          "[文法] for文と文字列、リスト : [Language] for statement and strings, lists",
          "[文法] for文とタプル、辞書、ファイル : [Language] for statement and tuples, dictionaries, files",
          "[文法] 引数、デフォルト引数値、位置引数、キーワード引数 : [Language] Parameters and arguments",
          "[文法] インデクス、スライス : [Language] Index, slice",
          "[文法] 文字列とインデクス、スライス : [Language] String and Slice, Index"
        ],
        "関連書籍": [
          "ボーナスレクチャー: 関連書籍 : Bonus Lecture : Our Books"
        ],
        "Appendix": [
          "Q&A"
        ]
      },
      "requirements": [
        "初歩的なパソコン操作ができる方向けです（エクスプローラーによるファイル操作、ブラウザによるダウンロードなど）。",
        "パソコン(Windows、macOS、Linuxのいずれか）を使用します。",
        "パソコンにPython3がインストールされていない場合には、インターネット経由でダウンロードします。パソコンのWebブラウザで、インターネット上のページが見られていればOK！",
        "テンソルフロー（ディープラーニングのセクションで使用）を動作させるためには、64bit CPUと、64bit対応OSが必要です。"
      ],
      "description": "ビッグデータに続き、人工知能への関心が高まり、それに伴ってPythonを使う開発案件が増えてきたと感じています。多くのIT技術者がこれから関わってゆくPython、そして人工知能技術を気軽に体験できるコースです。Python言語については体験するだけでなく、基本文法を習得します。\n開発以外の業種の方にもお勧めです。Pythonでどんなことができるのか、手軽に把握することができます。人気ライブラリを使った応用にだけ興味がある方は、Python文法解説のレクチャーをスキップして受講することもできます。\nかつてのNHK教育番組や、最近のコンテンツでは「The Grand Tour」の自動車レビューなどを参考に、楽しみながら知識を獲得できるコースを目指しました。まずは気軽に、パペットショーに笑いながらご覧頂けましたら幸いです。次に、パソコンを用意して実際にコマンドを入力してみたり、プログラムを実行してみると、より楽しいです。気になるレクチャーを、もう一度、二度、と振り返ってご覧頂くのもお勧めです。\n「ここまで配布プログラムを動かせたよ！」「配布プログラムを改造して、こんなものを作ったよ！」といったご成果を、ぜひお知らせください。楽しみにお待ちしています。",
      "target_audience": [
        "Pythonを将来は仕事で使うことになるのかな？と感じている方。",
        "Pythonを使っているプログラマが快適そうなので、自分も試してみたい方。",
        "卒業研究や修士論文研究、OJTなどでPythonを使うことを検討している方。",
        "流行のPythonをおさえておきたい方。"
      ]
    },
    {
      "title": "Data Lakehouse com Delta Lake, DuckDB e Azure Data Lake-Gen2",
      "url": "https://www.udemy.com/course/criando-um-lakehouse-com-python-deltalake-duckdb-e-azure-data-lake-sql/",
      "bio": "Criando um Lakehouse de baixo custo com Python e SQL utilizando as tecnologias mais modernas do mercado.",
      "objectives": [
        "Projetar e implementar soluções de Lakehouse combinando Data Lakes e Data Warehouses.",
        "Gerenciar e processar dados no Azure Data Lake de maneira segura e eficiente.",
        "Implementar Delta Lake para garantir a confiabilidade e integridade dos dados.",
        "Processar dados com DuckDB.",
        "Criar um Data Lakehouse com Python e SQL.",
        "Armazenamento no Azure Data Lake Storage Gen2.",
        "Arquitetura Medalhão. (Bronze, Silver e Gold)"
      ],
      "course_content": {},
      "requirements": [
        "Lógica de programação em Python",
        "Básico de SQL",
        "Um PC com internet e no mínimo 8gb de Ram"
      ],
      "description": "O curso Criando Lakehouse com Delta Lake, DuckDB e Azure Data Lake é projetado para profissionais de dados que desejam dominar o conceito de Lakehouse, combinando a flexibilidade dos Data Lakes com a estrutura e a performance dos Data Warehouses. Este curso aborda o uso de tecnologias de ponta, como Python, Delta Lake, DuckDB e Azure Data Lake, proporcionando uma compreensão profunda e prática das melhores práticas em gerenciamento de dados e análise avançada.\n\n\nDelta Lake:\nBenefícios: Delta Lake é uma camada de armazenamento que traz confiabilidade ao Data Lake, oferecendo transações ACID, gerenciamento de tempo de dados e capacidade de escalabilidade. Ele permite a criação de pipelines de dados robustos e de alta performance, garantindo a integridade e a consistência dos dados ao longo do tempo.\nDuckDB:\nBenefícios: DuckDB é um sistema de banco de dados embutido voltado para análise de dados. Sua arquitetura otimizada para consultas analíticas permite processamento de dados em memória com alta velocidade. Além disso, DuckDB pode ser facilmente integrado com Python, oferecendo uma solução poderosa e leve para análises complexas sem a necessidade de infraestrutura pesada.\nAzure Data Lake:\nBenefícios: Azure Data Lake é um serviço de armazenamento em nuvem que oferece soluções escaláveis e seguras para o gerenciamento de grandes volumes de dados. Com integração nativa com outras ferramentas da Azure, ele facilita o processamento de dados em larga escala, permitindo análises mais rápidas e insights mais profundos. Além disso, Azure Data Lake garante a conformidade e a segurança dos dados armazenados.",
      "target_audience": [
        "Qualquer pessoa da área de dados que deseje aprender sobre Data Lakehouse"
      ]
    },
    {
      "title": "[ES] De la Receta al Chef: Conviértete en Ingeniero de LLM",
      "url": "https://www.udemy.com/course/de-la-receta-al-chef-conviertete-en-ingeniero-de-llm/",
      "bio": "Domina los LLM sin código. Aprende IA con analogías sabrosas y divertidas. (AI)",
      "objectives": [
        "Comprende qué son los modelos de lenguaje grandes (LLMs) y cómo funcionan utilizando analogías del mundo real",
        "Identifica los ingredientes clave que impulsan los LLMs, como los datos de entrenamiento, la tokenización y la calidad de los datos.",
        "Explica cómo se entrenan los LLMs utilizando conceptos como lotes, épocas y funciones de pérdida.",
        "Explica cómo se entrenan los LLMs utilizando conceptos como lotes, épocas y funciones de pérdida.",
        "Personaliza modelos utilizando fine-tuning y herramientas como Hugging Face y LoRA.",
        "Evalúa el rendimiento del modelo utilizando métricas tanto cuantitativas como cualitativas.",
        "Evalúa el rendimiento del modelo utilizando métricas tanto cuantitativas como cualitativas.",
        "Crea aplicaciones completas impulsadas por LLM utilizando herramientas sin código y LangChain.",
        "Supervisa y mejora tus modelos de IA utilizando registros, bucles de retroalimentación y pruebas A/B.",
        "Supervisa y mejora tus modelos de IA utilizando registros, bucles de retroalimentación y pruebas A/B."
      ],
      "course_content": {
        "¿Qué se está cocinando? Introducción a los LLMs": [
          "Introducción a “¿Qué se está cocinando? Introducción a los LLMs”",
          "¿Qué es un modelo de lenguaje?",
          "La evolución de los LLMs – De las máquinas de escribir a los robots gourmet",
          "Cómo los LLMs “predicen la siguiente palabra” (Preparación automática de sándwic",
          "Diferencias entre LLMs y la IA tradicional (Microondas vs Cocina de Chef)",
          "Panorama de LLMs populares: GPT, Claude, Gemini, LLaMA (Tour por restaurantes)"
        ],
        "Los ingredientes importan – Entendiendo los datos": [
          "Introducción a “Los ingredientes importan – Entendiendo los datos”",
          "¿Qué son los datos de entrenamiento? (Almacenando la despensa)",
          "Tokenización – Cortar el texto en pedazos fáciles de digerir",
          "Conjuntos de datos para LLMs: Wikipedia, libros, textos web",
          "Basura entra = basura sale: la calidad de los datos importa",
          "Sesgo en los datos = Picante para unos, insípido para otros"
        ],
        "Cocinar a gran escala – Fundamentos del entrenamiento de modelos": [
          "Introducción a “Cocinar a gran escala– Fundamentos del entrenamiento de modelos\"",
          "¿Qué ocurre durante el entrenamiento del modelo? (Mezclar, hornear, ajustar)",
          "Épocas, lotes y pérdida – Las rondas de cocina",
          "GPUs y TPUs – Hornos industriales para entrenar",
          "Preentrenamiento vs Fine-tuning – Receta maestra vs Toque regional",
          "Costo del entrenamiento – La factura del supermercado de los LLMs"
        ],
        "Ingeniería de Prompts – Sazonando para el resultado perfecto": [
          "Introducción a “Ingeniería de Prompts – Sazonando para el resultado perfecto”",
          "Anatomía de un prompt – La mezcla secreta de especias",
          "Estilos de prompt:Zero-shot, Few-shot, Chain-of-Thought(Como sal, chile, hierbas",
          "Prompts de rol – “Finge que eres un barista”",
          "Optimización de prompts – De crudo a bien cocido",
          "Evaluación de prompts – Prueba de sabor para prompts"
        ],
        "Fine-Tuning – Personalizando la receta": [
          "Introducción a “Fine-Tuning – Personalizando la receta”",
          "¿Qué es el Fine-Tuning? – El toque de la abuela a una receta clásica",
          "Aprendizaje por transferencia – Usar una base de pastel y añadir el glaseado",
          "Técnicas: Fine-Tuning completo vs LoRA (Adaptación de Bajo Rango)",
          "Fine-Tuning con tus propios datos (Tu cocina, tus reglas)",
          "Herramientas para Fine-Tuning: Hugging Face, Google Colab, PEFT"
        ],
        "Evaluar LLMs – Prueba de sabor": [
          "Introducción a “Evaluar LLMs – Prueba de sabor”",
          "Por qué importa la evaluación – La revisión final del chef",
          "Métricas cuantitativas: Perplejidad, BLEU, ROUGE",
          "Métricas cualitativas: Retroalimentación humana, utilidad, relevancia",
          "Alucinaciones y errores del modelo – Sabores inesperados",
          "Detección de sesgos – Atender diferentes preferencias alimenticias"
        ],
        "Servir tu plato – Implementación de LLMs": [
          "Introducción a “Servir tu plato – Implementación de LLMs”",
          "¿Qué es la implementación? – Abrir un restaurante emergente",
          "Crear APIs con FastAPI o Flask",
          "Usar Gradio/Streamlit para interfaces demo (Presentación estilo food truck)",
          "Opciones de alojamiento: Hugging Face Spaces, AWS, GCP",
          "Escalado y monitoreo – Mantener el buffet funcionando sin problemas"
        ],
        "Crear apps con LLM – Tu propio food truck": [
          "Introducción a “Crear apps con LLM – Tu propio food truck”",
          "Casos de uso de apps: chatbots, resumidores, recomendadores",
          "Herramientas sin código: Plantillas de LangChain, GPT Builder, Voiceflow",
          "LLM + base de datos: el menú inteligente",
          "Encadenamiento con LangChain – La línea de ensamblaje de IA",
          "Proyecto: Crea una app LLM totalmente funcional con interfaz personalizada"
        ],
        "Mantenerlo fresco – Monitoreo y mejora": [
          "Introducción a “Mantenerlo fresco – Monitoreo y mejora”",
          "Bucles de retroalimentación – Como reseñas en Yelp para la IA",
          "Registro y monitoreo – Cámaras inteligentes en la cocina",
          "Pruebas A/B – ¿Qué postre gana?",
          "Deriva del modelo – Cuando el sabor cambia con el tiempo",
          "Actualización de prompts, conjuntos de datos y despliegues"
        ],
        "Convertirse en un chef maestro – Carrera en ingeniería de LLM": [
          "Introducción a “Convertirse en un chef maestro – Carrera en ingeniería de LLM”",
          "Caminos profesionales en LLM: ingeniero, arquitecto, especialista en prompts",
          "Construyendo tu portafolio – Tu libro de cocina de IA",
          "Contribuir a código abierto: conjuntos de datos, modelos, herramientas",
          "Consejos para el CV, entrevistas y preguntas técnicas",
          "Proyecto final: Crea y lanza tu propia app con LLM"
        ]
      },
      "requirements": [
        "No se requiere experiencia en programación: este curso está diseñado para principiantes absolutos.",
        "La curiosidad por la inteligencia artificial y cómo funcionan los modelos de lenguaje es más que suficiente para comenzar.",
        "Habilidades informáticas básicas como usar un navegador, subir archivos y escribir son útiles.",
        "Un portátil o computadora de escritorio con acceso a internet – no se necesita hardware sofisticado.",
        "Opcional: una clave API gratuita de OpenAI (para proyectos prácticos con GPT).",
        "Opcional: interés en crear chatbots, redactar instrucciones o explorar carreras en inteligencia artificial.",
        "Todas las herramientas utilizadas (como Gradio, Google Colab o plantillas de LangChain) son gratuitas y aptas para principiantes."
      ],
      "description": "Este curso está traducido mediante IA del inglés al español para que puedas aprender tecnologías de vanguardia en tu idioma nativo.\nDe la Receta al Chef: Conviértete en Ingeniero de LLM (Analogías Culinarias) es un curso divertido y accesible para principiantes que te enseña a dominar los Modelos de Lenguaje Extensos (LLMs) sin escribir una sola línea de código. Ya sea que sientas curiosidad por la IA, quieras entrar al mundo de los modelos de lenguaje o aspiras a ser ingeniero de LLM, este curso es tu puerta de entrada para comprender y construir con herramientas como ChatGPT, Claude, Gemini y LLaMA. Explicamos conceptos técnicos con metáforas de cocina para que pases de novato en la cocina a chef de IA en poco tiempo.\nExplorarás cómo se construyen, entrenan, implementan y evalúan los LLMs mediante analogías fáciles de entender. Imagina la tokenización como picar verduras, el entrenamiento como hornear en masa o la ingeniería de prompts como sazonar un platillo. Cada módulo introduce una nueva habilidad, desde la preparación de datos y el fine-tuning hasta la evaluación y el despliegue. Al finalizar, dominarás conceptos clave como arquitectura del modelo, preentrenamiento, aprendizaje por transferencia, optimización de prompts, métricas como perplexity y BLEU, y cómo lanzar tus propias aplicaciones con FastAPI, Gradio, Hugging Face Spaces y LangChain.\nEste curso es ideal para estudiantes, educadores, creadores, emprendedores y profesionales sin experiencia técnica que quieren aprender fundamentos de IA y construir aplicaciones reales con LLMs. Iremos paso a paso, desde “¿Qué es un modelo de lenguaje?” hasta desplegar tu propio chatbot, resumidor o recomendador. Aprenderás a usar herramientas no-code, experimentar con prompts reales, afinar modelos existentes, evaluar resultados y explorar carreras como ingeniero de prompts, gestor de productos de IA o arquitecto LLM.\nNo se requiere experiencia en programación. Aprenderás a comunicarte con LLMs usando lenguaje natural, diseñar prompts efectivos y entender el funcionamiento interno—desde la recolección de datos y la tokenización hasta la predicción del modelo y el uso de GPUs/TPUs. También abordaremos detección de sesgos, alucinaciones, bucles de retroalimentación y estrategias de mejora continua.\nAl final, tendrás una base sólida en teoría de LLMs, un portafolio de proyectos prácticos y la confianza para entrar al mundo de la IA generativa. Ya sea que quieras crear tu propio producto, unirte a una startup, contribuir a proyectos open-source o simplemente impresionar a tus amigos, este curso te llevará ahí—con un plato lleno de conocimientos y un toque divertido.\nSi estás listo para pasar de lector de recetas a chef de LLM, acompáñanos en este sabroso viaje por el mundo de los modelos de lenguaje extensos, donde cada concepto se explica con analogías deliciosas y ejemplos prácticos.",
      "target_audience": [
        "Principiantes que quieren adentrarse en el mundo de la IA sin jerga técnica.",
        "Gerentes de producto y líderes empresariales que exploran herramientas impulsadas por IA.",
        "Educadores, creadores de contenido y narradores que buscan aprovechar los LLMs.",
        "Profesionales en transición que aspiran a convertirse en ingenieros de LLM, diseñadores de prompts o especialistas en IA.",
        "Si te encanta aprender con analogías de la vida real (¡como la comida!), proyectos interactivos y creatividad práctica, este curso te resultará deliciosamente valioso."
      ]
    },
    {
      "title": "Alteryx TRIFACTA -Preparação de Dados- explorer e ajustes",
      "url": "https://www.udemy.com/course/alteryx-trifacta-preparacao-de-dados-explorer-e-ajustes/",
      "bio": "Curso 100% visual para preparação de dados, tratamento dos dados e governança de dados",
      "objectives": [
        "Preparação de dados aberta que pode se conectar a diversas fontes de dados",
        "Integração em todas as principais plataformas de dados em nuvem",
        "Decida entre ETL ou ELT, ou uma combinação ideal dos dois com base no desempenho",
        "Suporte para todas as principais nuvens, Google, AWS, Azure e on-premise",
        "Interface intuitiva e simples utilização de objetos de dados",
        "Perfilização de dados, ajudando na identificação de outliers",
        "Tratamento de dados, criação de novos campos, dentre outras tarefas",
        "Eliminação de dados nulos, inconsistências, criação de novos campos",
        "Exploração e avaliação de conteúdo e de qualidade de qualquer conjunto de dados",
        "Engenharia de dados com low-code, visual, direto na nuvem",
        "Construção, implantação e automatização de pipelines de dados",
        "Criação de flow de dados, que permite ao analista encadear suas ações de tratamento",
        "Action com os dados: Columns, Rename, Sort, Calculate, Group By, Filter Rows, Replace",
        "Action com os dados: Split, Create formula, dentre outros",
        "Exportação dos resultados automatizados"
      ],
      "course_content": {
        "Alteryx TRIFACTA - Preparação de dados - explore e qualidade": [
          "O que é o Alteryx TRIFACTA",
          "Apresentação da Ferramenta e arquitetura",
          "INFORMAÇÕES IMPORTANTES! - Leia antes de começar o curso",
          "Carregando os dados e fazendo Explorer dos dados",
          "Action Substituir - Tratamento de dados - parte 01",
          "Action Rename e Sort - Tratamento de dados - parte 02",
          "Action Move e Hide - Tratamento de dados - parte 03",
          "Action Format - Tratamento de dados - parte 04",
          "Action Calculate - Tratamento de dados - parte 05",
          "Action Create Columns From Examples - Tratamento de dados - parte 06",
          "Action Extract - Tratamento de dados - parte 07",
          "Action Split Column - Tratamento de dados - parte 08",
          "Action Merge - Tratamento de dados - parte 09",
          "Action Group By - Tratamento de dados - parte 10",
          "Action Filtro - Tratamento de dados - parte 11",
          "Aplicação de Funções de Controle",
          "Aplicação de Funções Especiais",
          "Executando o Fluxo de dados e gerando arquivo de saída",
          "Gerando o agendamento (Schedule) do Fluxo de Dados",
          "Aula Final - Atividade para entrega",
          "Responda a nossa pergunta"
        ]
      },
      "requirements": [
        "Necessário entendimento básico sobre banco de dados"
      ],
      "description": "Este curso foi criado como um dos mais práticos e principais da área de preparação de dados. O Alteryx TRIFACTA, é uma ferramenta 100% na nuvem, low-code, totalmente prática e com grande destaque no mercado. Ela é uma plataforma em nuvem aberta e interativa, que permite a capacitação de engenheiros de dados e analistas a interpretar, preparar e criar pipelines de dados para acelerar suas análises.\nAlterix Trifacta é uma ferramenta de limpeza e preparação de dados que ajuda as empresas a transformar grandes volumes de dados desestruturados em dados limpos e estruturados para análise e uso. Ele permite aos usuários explorar, limpar, transformar e visualizar seus dados de forma rápida e fácil.\nCom Alterix Trifacta, os usuários podem importar dados de diversas fontes, incluindo arquivos, bancos de dados, aplicativos e dispositivos móveis. Ele permite aos usuários visualizar e explorar seus dados com facilidade, identificando e corrigindo problemas de dados, como duplicatas, valores ausentes e erros de digitação.\nAlém disso, a ferramenta possibilita aos usuários transformar seus dados de acordo com suas necessidades, com recursos como agregação, junção, filtragem e normalização. Os usuários também podem criar e salvar fluxos de trabalho personalizados, reutilizá-los em projetos futuros e automatizar tarefas de limpeza de dados.\nOutra vantagem de Alterix Trifacta é sua capacidade de integração com outras ferramentas de análise e inteligência artificial, permitindo que os usuários importem seus dados limpos e estruturados.\nA sua principal tarefa é ler uma base de dados, identificar os principais pontos de ajustes nos dados, permitir que sejam construídas transformações nos dados e executar um pipeline de dados (fluxo de dados) gerando as informações ajustadas em qualquer fonte de dados, tudo 100% visual.\nCom isso, você comandará a governança de dados nos seus dados, pois identificará outliers, inconsistências, ausências de informações, identificações de padrões, dentre outras tarefas.\n\n\nAs principais características do Alteryx TRIFACTA são:\nExplore e avalie o conteúdo e a qualidade de qualquer conjunto de dados.\nAcelere e acompanhe transformações de dados de forma visual.\nConstrua, implante e automatize pipelines de dados.\nUtilize os fluxos de dados para definir TODAS as suas necessidades em tratamento de dados e governança de dados\nEntão venha para o nosso treinamento com o Alteryx TRIFACTA e promova a exploração sobre seus dados com alta performance.",
      "target_audience": [
        "Profissionais de TI",
        "Profissionais que querem trabalham na área de Engenharia de dados, Análise de dados, Ciência de Dados, Business Intelligence"
      ]
    },
    {
      "title": "Impara R e la Visualizzazione dei Dati tramite Grafici",
      "url": "https://www.udemy.com/course/impara-r-e-la-visualizzazione-dei-dati-tramite-grafici/",
      "bio": "Impara Tutto quello che c'è da Sapere su R e Impara a Manipolare e Creare dei Grafici Basati su Dati Reali con R",
      "objectives": [
        "Programmare in R",
        "Creare Grafici con R",
        "Creare Grafici con la Libreria Ggplot2",
        "Manipolare i Dati con R",
        "Tutto quello che Riguarda R",
        "Creare Grafici con Dati Reali"
      ],
      "course_content": {
        "Benvenuto al Corso": [
          "Benvenuto",
          "Setup"
        ],
        "Fondamenti di R": [
          "Struttura Base di un Programma",
          "Tipi di Dato",
          "Variabili",
          "Operatori di R",
          "Convertire i Tipi di Dato",
          "Input",
          "Esercizi e Soluzioni"
        ],
        "Condizioni e Cicli": [
          "Strutture Decisionali",
          "La Struttura Switch",
          "Cicli in R",
          "Istruzioni Continue e Next",
          "Esercizi e Soluzioni"
        ],
        "Funzioni e Stringhe": [
          "Funzioni in R",
          "Stringhe",
          "Lavorare con le Stringhe",
          "Esercizi e Soluzioni"
        ],
        "Tipi di Dato Complesso": [
          "Vettori",
          "Liste",
          "Matrici",
          "Array",
          "Fattori e DataFrame",
          "Esercizi e Soluzioni"
        ],
        "Grafici con R": [
          "Leggere file CSV",
          "Grafici a Torta",
          "Grafici a Barre",
          "Istogrammi",
          "Grafici a Linee",
          "Grafici a Punti",
          "Esempio con Dati Reali",
          "Esercizi e Soluzioni"
        ],
        "Grafici con ggplot2": [
          "Istogrammi con ggplot2",
          "Grafici a Barre con ggplot2",
          "Grafici a Dispersione con ggplot2",
          "Grafici a Linee con ggplot2"
        ],
        "Fine": [
          "Fine Corso"
        ]
      },
      "requirements": [
        "Nessuna esperienza di programmazione"
      ],
      "description": "In questo corso imparerete tutto sul linguaggio di programmazione R, molto in crescita negli ultimi anni, dopo aver imparato a programmare bene in R, vedremo come lavorare con i dati (Set di Dati), sia reali che creati da noi, e vedremo come visualizzare i dati tramite dei grafici di diverso genere\n\n\nAlla fine di ogni sezione sono presenti diversi esercizi che vi serviranno per valutare le competenze che avete acquisito, inoltre il corso verrà sempre aggiornato con materiale nuovo, per ampliare continuamente le vostre conoscenze, inoltre verranno anche aggiunti nuovi esercizi, anche  più difficili, in modo che vi possiate allenare\n\n\nQuindi, in questo corso imparerete;\nCome installare tutto il necessario per programmare in R\nI fondamenti di R (variabili, tipi di dato, input, output, e altro)\nCondizioni e Cicli con R (tutti i tipi di IF, switch, tutti i cicli, e altro)\nFunzioni e Stringhe (come lavorare al meglio con le funzioni e le stringhe)\nTipi di Dato complesso (vettori, listi, dataframe, matrici, e altro)\nCreare Grafici con R (leggere file CSV, grafici a torta, a barre, istogrammi, e altro)\nUsare la libreria ggplot2 (creare grafici a barre, dispersione, e altro)\nMolto Altro",
      "target_audience": [
        "Chi vuole imparare R",
        "Chi vuole imparare a Visualizzare i Dati con i Grafici",
        "Chi vuole imparare a Visualizzare i Dati con i Grafici con R",
        "Chi vuole entrare nel mondo del Data Science"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第17部 ComfyUI 進階版 - AI偶像時代",
      "url": "https://www.udemy.com/course/generative_ai_17/",
      "bio": "關於Flux， SDXL，Stable Diffusion，IC-Light，Character Sheet",
      "objectives": [
        "完全掌握如何安裝和配置 ComfyUI 的全套流程",
        "能夠輕鬆製作出自己的虛擬偶像，並調整外觀、姿態和表情",
        "自由設計你的虛擬偶像應用於各種場景用於宣傳海報",
        "如何使用Flux的功能"
      ],
      "course_content": {
        "如何安裝ComfyUI到本地電腦": [
          "如何在iMac電腦上安裝ComfyUI"
        ],
        "如何在Mac上運行第一個Flux工作流": [
          "如何在Mac上運行第一個Flux工作流",
          "如何加快Flux Workflow的速度"
        ],
        "如何處理虛擬偶像的身體和臉部": [
          "如何實現Outpainting擴圖",
          "如何製獲得人物多角度圖片",
          "如何製作自定義人物",
          "如何導入多張圖片並處理子集圖片",
          "如何高清處理人物臉部"
        ],
        "如何生成偶像": [
          "如何生成新人臉",
          "如何控制人物姿勢和動作",
          "如何把人物融入環境"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "你是否曾經想過擁有一位專屬的網絡偶像，能夠出現在任何場景中，隨時創作獨特的照片？現在，這不再是大企業或專業技術人員的專利！我們推出了一個全新的課程，手把手教你如何在本地使用ComfyUI 和 AI 技術，只需一張圖片，創造一位多場景、多表情的虛擬偶像，助你快速進入網紅時代的流量市場！\n課程亮點：\n簡單易懂，零基礎也能上手！\n無需專業編程或深度學習背景，只需跟隨我們的步驟即可輕鬆操作。\n適合個人創作者、工作室，甚至品牌運營人員。\n只需一張圖片，創造無限可能！\n使用 AI 強大的生成技術，從一張圖片出發，生成虛擬偶像在不同位置、角度和表情下的形象。\n運用多樣化場景和素材，輕鬆製作海報、宣傳圖或視頻封面。\n專業工具實戰：ComfyUI 與 LivePortrait 模型\n深入講解如何安裝和使用 ComfyUI，搭配 LivePortrait，打造個性化的 AI 人物。\n介紹如何搭配 InsightFace 等技術，強化虛擬偶像的表情和動作生成。\n多場景應用，打造你的流量帝國！\n虛擬偶像可應用於直播、短視頻、海報創意，甚至品牌代言。\n使用虛擬偶像替代真人拍攝，降低成本，提升效率。",
      "target_audience": [
        "對AI感興趣的設計者"
      ]
    },
    {
      "title": "Veri Görselleştirme ve Etkili Anlatım",
      "url": "https://www.udemy.com/course/veri-gorsellestirme-ve-etkili-anlatm/",
      "bio": "Veri Görselleştirme, Grafik Türleri, Hikayeleştirme ve Etkili Anlatım Yöntemleri",
      "objectives": [
        "Veri görselleştirmenin yapılma amacını ve izlemeniz gereken adımları öğreneceksiniz",
        "Veri görselleştirme için kullanılan grafikleri öğrenip yorumlayabilir olacaksınız",
        "Elinizdeki veriye hangi grafiğin en uygun olacağını bilebileceksiniz",
        "Daha anlaşılır ve içeriği kaliteli görselleştirmeler oluşturabileceksiniz",
        "Görselleştirmeleri hikayeleştirerek karşı tarafa daha açıklayıcı bir şekilde aktarabileceksiniz"
      ],
      "course_content": {
        "Hoşgeldin": [
          "Hoşgeldin"
        ],
        "21. YY'ın Petrolü Veri": [
          "Veri Nedir?",
          "Veri ve Görselleştirme",
          "Veriyle İletişim Kurmak",
          "Veri Tipleri Nelerdir?"
        ],
        "Grafikleri Tanımak": [
          "Grafik Tipleri Nelerdir?",
          "Dağılım Grafikleri",
          "Korelasyon Grafikleri",
          "Sıralama Grafikleri",
          "Bütün Grafikleri",
          "Evrim Grafikleri",
          "Harita Grafikleri",
          "Akış Grafikleri",
          "Diğer Grafikler"
        ],
        "Hangi Veriyle Hangi Grafik": [
          "Veriye Göre Grafiğin Önemi",
          "Numerik Verilerle Grafikleştirme",
          "Kategorik Verilerle Grafikleştirme",
          "Numerik ve Kategorik Verilerle Grafikleştirme",
          "Zaman Serileriyle Grafikleştirme",
          "Diğer Verilerle Grafik 1 - Haritalaştırma",
          "Diğer Verilerle Grafik 2 - Akış Grafikleri"
        ],
        "Doğru Görselleştirmenin Yolu": [
          "Görselleştirmenin Temeli",
          "Görselleştirmenin Yapısı",
          "Hikayeleştirme"
        ],
        "Yapbozu Tamamlamak": [
          "Bir Adım Geri",
          "Efektif Anlatım Nedir?",
          "Veri Görselleştirmedeki Manipülasyonlar ve Yanıltmacalar",
          "Grafiklerde Tasarım Hataları"
        ],
        "Bonus Detaylar ve Teknikler": [
          "Renk Körlüğü ve Görselleştirme",
          "10-20-30 Kuralı"
        ],
        "Final": [
          "Bitiş"
        ]
      },
      "requirements": [
        "Öğrenmek istiyorsanız önünüzde hiçbir engel yok demektir, herhangi bir ön bilgiye ihtiyaç duymayacaksınız"
      ],
      "description": "Herhangi bir veri görselleştirme aracı kullanarak bir grafik oluşturmak aslında çok basittir. Yapmanız gereken excelde grafik sekmesine gelmek veya chatgptye verinin ne olduğunu söyleyip grafiğin kodunu yazdırmasını sağlamaktır. Fakat iş bundan ibaret değildir. Grafik oluşturabiliyor olmak onun kesin olarak anlam taşıdığını ifade etmez. Veri görselleştirme bir bütün olarak ele alınması gereken bir süreçtir. Doğru bir veri görselleştirmeyi yapabilmek için ilk olarak veriyi tanımalısınız ve anlatım yapmak istediğiniz durumla alakalı görselleştirmeler oluşturmalısınız.\nFakat bunu nasıl yapacaksınız? İşte bu kursta size bunu nasıl yapacağınızı öğretmekle birlikte işinize yarayacak bir çok konuyu da öğretiyor olacağım.\nBu kursta aşağıdakileri öğreniyor olacaksınız:\nVeri analizinin önemini\nVerinin türlerini ve özelliklerini\nGrafik türlerinin özelliklerini ve aralarındaki farklarını\nElinizdeki veriye göre doğru grafik türünü kullanmayı\nGörselleştirme araçlarının güçlü ve güçsüz yönlerini\nVeri görselleştirme için düşünce yapınızı nasıl kurgulamanız gerektiğini\nVeri görselleştirme ile yapılan manipülasyonları ve yanıltmacaları\nVeri görselleştirmede dikkat edilmesi gereken püf noktaları\nYaptığınız görselleştirmeyi nasıl etkili anlatabileceğinizi\nYukarıdaki başlıkları öğrendiğinizde karşınızdaki müşterileriniz, çalışma arkadaşlarınız ve hedef kitleniz için efektif ve kaliteli görselleştirmeler oluşturabileceksiniz.\nAynı zamanda iş hayatınızda, internette, uygulamalarda veya herhangi bir yerde karşınıza çıkan görselleştirmeleri daha iyi yorumlayabilir olacaksınız. Eğer bu grafiklerde hatalar veya manipülasyonlar bulunuyorsa onları da tespit edebileceksiniz.\nAyrıca kursun sonunda bonus iki bölüm de sizleri bekliyor.\nİyi öğrenmeler!",
      "target_audience": [
        "Veri görselleştirmenin mantığını öğrenmek isteyenlere",
        "Veri dünyasına meraklı herkese",
        "Veri bilimi, veri analizi ve yapay zeka meraklılarına",
        "Sık sık sunum, grafik hazırlayan ve inceleyenlere"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第23部 訓練大語言模型必修 - LoRA & Quantization",
      "url": "https://www.udemy.com/course/generative_ai_23/",
      "bio": "關於LoRA（Low-Rank Adaptation）, Quantization，PTQ（Post-Training Quantization），QAT（Quantization Aware Training），SVD，PyTorch",
      "objectives": [
        "學會低秩矩陣微調原理與優勢",
        "學會針對錯誤多的數字進行 LoRA 微調",
        "學會啟用／禁用 LoRA 對比分析",
        "學會Post-Training Quantization",
        "學會Quantization Aware Training"
      ],
      "course_content": {
        "課程需要準備的工具&環境": [
          "課程工具準備",
          "如何使用uv 作為包管理器和項目管理工具"
        ],
        "如何在 大語言模型 fine-tuning 中使用LoRA": [
          "LoRA 如何實現低秩分解Low-Rank Decomposition",
          "如何使用Pytorch製作 MNIST 神經網絡",
          "如何使用訓練 BigNet 及對模型進行評估",
          "如何使用 Pytorch 實現 LoRA低秩適應"
        ],
        "PTQ 訓練後量化 & QAT 量化感知訓練": [
          "如何使用對稱量化&非對稱量化和反量化",
          "如何理解 Calbration 選擇合適的量化範圍",
          "如何使用 Pytorch 實現訓練後量化 PTQ",
          "如何使用 Pytorch 實現 QAT 量化"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "想讓您的 AI 模型在邊緣設備上跑得更快、更小、更智能？加入我們的課程，帶您從原理到實操，徹底掌握：\n參數高效、成本低\nLoRA 僅透過低秩矩陣 AAA 和 BBB 的更新，凍結原始權重，使得微調參數量相比傳統方法大幅縮減，無需重訓整個模型，省時、省算力、省錢。\nPyTorch 直擊實戰\n從 torch.nn.utils.parametrize 開始，手把手教你如何在線性層中注入 LoRA 參數化邏輯；以 MNIST 分類示範，讓你快速上手微調流程。\n細節解密、數據驗證\n不僅帶你凍結原始權重、訓練與測試，還深入探討如何對比 LoRA 啟用／禁用時的性能差異，並驗證原始權重是否真正保持不變。\n參數效率深度分析\n計算並對比原始模型參數量與 LoRA 額外引入的參數量，用數據說話，讓你更加清晰地掌握技術優勢與取捨。\n完整數學推導與程式實現\n從 SVD（奇異值分解）基礎概念，到低秩近似矩陣生成，再到 W+BA⋅scaleW + B A\\cdot\\text{scale}W+BA⋅scale 的數學邏輯，理論與實作一氣呵成。\n對稱 vs. 非對稱：深度對比兩大量化策略，掌握 S（Scale）與 Z（Zero‐Point）的配置技巧，讓零點映射更“零失真”；\nPTQ 實戰：手把手演示「訓練後量化」流程：插入觀察器、校準統計、S/Z 計算，一鍵生成 INT8 模型，輕鬆部署；\nQAT 精髓：揭開「量化感知訓練」原理，在訓練圖中插入“假量化”模塊，讓模型在訓練時就學會“自我修正”，大幅減少量化誤差；",
      "target_audience": [
        "已具備深度學習基礎，想進階優化模型的研究人員",
        "AI 工程師、ML Ops 從業者，希望降低微調成本",
        "任何對參數高效微調與模型壓縮技術感興趣的開發者"
      ]
    },
    {
      "title": "Машинное обучение без учителя на Python: полный курс",
      "url": "https://www.udemy.com/course/ittensive-python-machine-learning-unsupervised/",
      "bio": "Выигрываем хакатоны по выделению факторов (PCA, ICA, NMF, MDS, t-SNE) и кластеризации (К-средних, DBSCAN, OPTICS, SOM)",
      "objectives": [
        "Процесс и модель машинного обучения",
        "Заполнение пропусков в данных",
        "Линейная регрессия и L1/L2 регуляризация",
        "Решающие деревья и ансамбли стекинга",
        "Корреляция и взаимная информация",
        "Метод главных компонент (PCA) и Сингулярное разложение (SVD)",
        "Анализ независимых компонент (ICA)",
        "Многомерное шкалирование (MDS)",
        "t-SNE, UMAP, LargeVis",
        "K-средних, расстояние Махаланобиса и GMM",
        "Агломеративная кластеризация",
        "DBSCAN, HDBSCAN и OPTICS",
        "Самоорганизующиеся карты Кохонена",
        "Расширяющийся нейронный газ",
        "Спектральная кластеризация",
        "pAUC и поиск аномалий",
        "Тест Смирнова-Граббса",
        "Эллипсоидальная аппроксимация",
        "LOF, ABOD и COPOD",
        "iForest",
        "Классификация через кластеризацию"
      ],
      "course_content": {
        "Введение": [
          "Задачи машинного обучения",
          "Обучение без учителя",
          "Задачи машинного обучения"
        ],
        "Часть 1. Процесс машинного обучения": [
          "Модель и процесс машинного обучения",
          "Что такое ETL",
          "Процесс машинного обучения",
          "Что такое EDA",
          "Подготовка данных",
          "Подготовка данных",
          "Разбиение выборки",
          "Оптимизация гиперпараметров",
          "Недообучение и переобучение",
          "Смещение, разброс и ошибка данных",
          "Обучение модели"
        ],
        "Линейные модели": [
          "Метод максимального правдоподобия",
          "Метод наименьших квадратов",
          "Метод наименьших квадратов",
          "Аппроксимация пропусков в данных",
          "Аппроксимация данных",
          "Среднеквадратичная ошибка",
          "Метрики и расстояния",
          "Метрики и расстояния",
          "Линейная регрессия и L1/L2-регуляризация",
          "Линейная регрессия",
          "BIC и AIC"
        ],
        "Решающие деревья и ансамбли": [
          "Ансамблевые модели",
          "Дерево принятия решения",
          "Случайный лес",
          "Сверхслучайные деревья",
          "Ансамбль стекинга"
        ],
        "Часть 2. Линейное выделение факторов": [
          "Линейная регрессия для понижения размерности",
          "Выделение факторов с помощью деревьев решений",
          "\"Правило локтя\" и GMM BIC",
          "Оберточные методы",
          "Взаимная информация",
          "Понижение размерности"
        ],
        "Практикум: Исследование ожидаемой продолжительности жизни": [
          "Ожидаемая продолжительность жизни",
          "Заполнение пропусков экстраполяцией",
          "Согласованность данных",
          "Корреляция данных",
          "Важность признаков",
          "Ансамбль понижения размерности"
        ],
        "Часть 3. Матричные подходы к выделению факторов": [
          "Метод главных компонент (PCA)",
          "Сингулярное разложение (SVD)",
          "Принцип максимума энтропии",
          "Анализ независимых компонент (ICA)",
          "Матричные методы понижения размерности"
        ],
        "Практикум: Выделение факторов с помощью матриц": [
          "Метод главных компонент",
          "Сингулярное разложение",
          "Независимые компоненты",
          "Матричная факторизация",
          "Ансамбль матричных методов"
        ],
        "Часть 4. Нелинейные подходы к выделению факторов": [
          "Многомерное шкалирование (MDS)",
          "Расстояние Кульбака-Лейблера",
          "t-SNE",
          "UMAP",
          "LargeVis",
          "Нелинейное понижение размерности"
        ],
        "Практикум: Стабилизация выделения факторов": [
          "Многомерное шкалирование",
          "t-SNE",
          "UMAP",
          "Случайный ансамбль",
          "Регрессия по значимым факторам",
          "Выделение факторов и предсказание"
        ]
      },
      "requirements": [
        "Продвинутый Python",
        "Основы математической статистики"
      ],
      "description": "Внимание: для доступа к курсам ITtensive на Udemy напишите, пожалуйста, на support@ittensive.com с названием курса или группы курсов, которые хотите пройти.\n\n\nМы разберем 2 задачи с хакатонов 2020 года:\n1. По выделению факторов, в наибольшей степени влияющих на продолжительность жизни в России, с точки зрения фундаментальных и прикладных подходов к понижению размерности данных. В заключении построим ансамбль моделей для предсказания продолжительности жизни, базируясь на выделенных факторах.\n2. По прогнозу срока экспозиции объявлений с хакатона Яндекс.Недвижимости - решим ее с помощью методов кластеризации и поиска аномалий.\nКурс разбит на 7 частей. В первой части мы последовательно пройдем все этапы работы с данными: от видов задач и их постановки до работы с моделями машинного обучения для минимизации предсказательной ошибки. Дополнительно рассмотрим фундаментальные основы построения моделей машинного обучения, базовые метрики и наиболее простые модели - линейную регрессии, решающие деревья и случайный лес. А также ансамбли машинного обучения.\nВо второй части на практике разберем:\nОчистку и предобработку данных - ETL\nЛинейную регрессию для экстраполяции данных\nЛинейную регрессию с регуляризацией для выделения факторов\nИнформационные критерии понижения размерности\nВ заключении создадим ансамбль стекинга из простых моделей понижения размерности.\nТретья часть посвящена матричным методам:\nМетод главных компонент (PCA)\nСингулярное разложение (SVD)\nАнализ независимых компонент (ICA)\nПоложительно-определенные матрицы (NMF)\nУточним решение задачи обучения без учителя через матричные методы.\nВ четвертой части рассмотрим нелинейные подходы:\nМногомерное шкалирование (MDS).\nt-SNE\nUMAP\nLargeVis\nСтабилизируем ансамбль понижения размерности и используем его для предсказания продолжительности жизни в России, основываясь на наиболее важных макроэкономических показателях.\nПятая часть посвящена базовым моделям кластеризации:\nИзучите внешние и внутренние метрики кластеризации.\nРазберете модели К-средних и FOREL и потренируетесь в их применении.\nРассмотрите принципы работы агломеративной кластеризации и используете ее на практике.\nУзнаете про расстояние Махаланобиса и работу GMM.\nВ качестве задания соберем простую модель кластеризации исходных данных.\nВ шестой части перейдем к продвинутой кластеризации:\nПогрузитесь в различия моделей DBSCAN, HDBSCAN и OPTICS.\nРазберете особенности модели распространения близости.\nПосмотрите на расширяющийся нейронный газ.\nЗапустите и обучите самоорганизующиеся карты Кохонена (SOM).\nСтолкнетесь с матрицей Кирхгофа и спектральной кластеризацией.\nИ соберем ансамбль из несколько моделей кластеризации.\nВ завершении:\nИзучите поиск аномалий и метрику pAUC.\nИспользуете тест Смирнова-Граббса на практике.\nПотренируетесь в эллипсоидальной аппроксимации.\nРазберете разницу между LOF и ABOD.\nОбучите и используете модель COPOD.\nВырастите как iForest, как и расширенный лес изоляции.\nВ финале соберем свое решение задачи Хакатона 2020 года.",
      "target_audience": [
        "Аналитики Python, изучающие машинное обучение",
        "Программисты больших данных",
        "Исследователи больших данных"
      ]
    },
    {
      "title": "Intelligenza artificiale e Python: interagire con gli LLM",
      "url": "https://www.udemy.com/course/python-llm-ia/",
      "bio": "Un'introduzione concisa all'integrazione di Python con l'IA, Ollama, Mistral, le API di GPT e Llama Index",
      "objectives": [
        "Installare e utilizzare in locale gli LLM",
        "Interrogare dataframe e PDF con gli LLM direttamente dal proprio server",
        "Implementare RAG (Retrieval Augmented Generation)",
        "Utilizzare le API di GPT"
      ],
      "course_content": {
        "Interrogare con Python gli LLM installati in locale": [
          "Installare Ollama e scaricare in locale Mistral",
          "Configurare un ambiente virtuale di Python per interagire con Ollama",
          "Prime interazioni con Ollama",
          "Creare un Pandas Query Engine con Llama index",
          "Generare codice Pandas tramite Ollama e Mistral",
          "Interrogare un PDF con Llama index",
          "Retrieval Augmented Generation"
        ],
        "Interagire con GPT tramite Python e chiamate API": [
          "Interagire con il modello GPT tramite API",
          "ChatBOT per generare codice Pandas",
          "Un esempio più complesso con due file",
          "Interrogare un PDF tramite API di GPT",
          "Vector store index su più file",
          "Congratulazioni finali e anteprima gratuita della Scuola dei Dati"
        ]
      },
      "requirements": [
        "Buona conoscenza di programmazione in Python"
      ],
      "description": "Questo corso dura un'ora circa.\nÈ abbastanza per diventare un esperto di Python e LLM? Sicuramente no.\nMa grazie ad un approccio conciso e al 100% pratico, imparerai sicuramente come fare a:\n- usare Python per interagire con gli LLM, sia installati in locale e sia tramite API\n- interrogare i dati di un file excel, csv, o di qualsiasi altra fonte strutturata o semi-strutturata interpretabile dalla libreria Pandas\n- interrogare dati non strutturati come quelli contenuti all'interno di un PDF, sempre tramite modelli installati in locale\n- creare agenti intelligenti in grado di utilizzare sia le informazioni su cui sono stati addestrati e sia il contenuto di ulteriori fonti fornite da noi\n- utilizzare le API di GPT\n\n\nLe videolezioni sono corredate dai file con gli script utilizzati durante le spiegazioni.\n\nPer seguire il corso è necessario avere delle conoscenze di programmazione in Python. Ad esempio devi:\n- saper installare una libreria\n- interrogare le chiavi di un dizionario\n- passare dei parametri di input a una funzione o un metodo\n- conoscere le basi di Pandas (cos'è un Dataframe, come effettuare delle interrogazioni di base,...)\n\n\nNel corso è utilizzato il sistema operativo Windows. Se oltre a seguire le lezioni, vuoi eseguire anche tu il codice creato durante il corso, assicurati di avere un PC potente il giusto. Infatti vedremo molti esempi di come usare gli LLM direttamente dal nostro PC personale. Nelle ultime lezioni chiamerò le API di OpenAI utilizzando la mia chiave segreta a pagamento.",
      "target_audience": [
        "Chiunque sia interessato all'interazione tra Python e gli LLM",
        "Python Developer",
        "Data Analyst",
        "Data Scientist"
      ]
    }
  ]
}