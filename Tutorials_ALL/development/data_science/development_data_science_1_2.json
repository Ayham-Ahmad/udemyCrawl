{
  "courses": [
    {
      "title": "TensorFlow 2.0 Practical",
      "url": "https://www.udemy.com/course/tensorflow-2-practical/",
      "bio": "Master Tensorflow 2.0, Google’s most powerful Machine Learning Library, with 10 practical projects",
      "objectives": [
        "Master Google’s newly released TensorFlow 2.0 to build, train, test and deploy Artificial Neural Networks (ANNs) models.",
        "Learn how to develop ANNs models and train them in Google’s Colab while leveraging the power of GPUs and TPUs.",
        "Deploy ANNs models in practice using TensorFlow 2.0 Serving.",
        "Learn how to visualize models graph and assess their performance during training using Tensorboard.",
        "Understand the underlying theory and mathematics behind Artificial Neural Networks and Convolutional Neural Networks (CNNs).",
        "Learn how to train network weights and biases and select the proper transfer functions.",
        "Train Artificial Neural Networks (ANNs) using back propagation and gradient descent methods.",
        "Optimize ANNs hyper parameters such as number of hidden layers and neurons to enhance network performance.",
        "Apply ANNs to perform regression tasks such as house prices predictions and sales/revenue predictions.",
        "Assess the performance of trained ANN models for regression tasks using KPI (Key Performance indicators) such as Mean Absolute error, Mean squared Error, and Root Mean Squared Error, R-Squared, and Adjusted R-Squared.",
        "Assess the performance of trained ANN models for classification tasks using KPI such as accuracy, precision and recall.",
        "Apply Convolutional Neural Networks to classify images.",
        "Sample real-world, practical projects:",
        "Project #1: Train Simple ANN to convert Celsius temperature reading to Fahrenheit",
        "Project #2 (Exercise): Train Feedforward ANN to predict Revenue/sales",
        "Project #3: As a real-estate consultant, predict house prices using ANNs (Regression Task)",
        "Project #4 (Exercise): As a business owner, predict Bike rental usage (Regression Task)",
        "Project #5: Develop Artificial Neural Networks in the medical field to perform classification tasks such as diabetes detection (Classification task)",
        "Project #6: Develop AI models to perform sentiment analysis and analyze online customer reviews.",
        "Project #7: Train LeNet Deep Learning models to perform traffic signs classification.",
        "Project #8: Train CNN to perform fashion classification",
        "Project #9: Train CNN to perform image classification using Cifar-10 dataset",
        "Project #10: Deploy deep learning image classification model using TF serving"
      ],
      "course_content": {
        "INTRODUCTION AND COURSE OUTLINE": [
          "Introduction and Welcome Message",
          "Course Overview",
          "EXTRA: Learning Path",
          "What's AI, ML and DL",
          "Machine Learning - Big Picture",
          "Whats new in TF2 and Google Colab",
          "Whats New in TensorFlow 2.0",
          "What is Google Colab",
          "Google Colab Demo",
          "Eager Execution",
          "Keras API",
          "Get the materials"
        ],
        "BUILD YOUR FIRST SIMPLE PERCEPTRON (SINGLE NEURON) MODEL IN TF 2.0": [
          "PROJECT #1 OVERVIEW: CONVERT CELSUIS TO FAHRENHEIT",
          "PROJECT #1 What are ANNs and How they learn?",
          "PROJECT #1 Build our first ANN model",
          "PROJECT #1 TF Playground",
          "PROJECT #1 Coding Step 1 - Load TF and Data",
          "PROJECT #1 Coding Step 2 - Model Training",
          "PROJECT #1 Coding Step 3 - Model Evaluation",
          "PROJECT #2 Overview",
          "PROJECT#2: Google Colab Questions Overview",
          "PROJECT # 2 Coding Part 1",
          "PROJECT # 2 Coding Part 2",
          "PROJECT # 2 Coding Part 3"
        ],
        "BUILD A MULTI LAYER ARTIFICIAL NEURAL NETWORKS FOR REGRESSION TASKS": [
          "PROJECT #3: Overview",
          "PROJECT #3 Regression basics",
          "PROJECT #3 ANN in Action",
          "PROJECT #3 Activation functions overview",
          "PROJECT #3 MultiLayer Perceptron Network",
          "PROJECT #3 ANN Training and Epochs Definition",
          "PROJECT #3 Tensorflow Playground 3",
          "PROJECT #3 Gradient Descent",
          "PROJECT #3 Back Propagation",
          "PROJECT #3 Bias Variance Tradeoff",
          "PROJECT #3 Performance Metrics",
          "PROJECT #3 Coding part 1",
          "PROJECT #3 Coding part 2",
          "PROJECT #3 Coding part 3",
          "PROJECT #3 Coding part 4",
          "PROJECT #3 Coding part 5 - Training",
          "PROJECT #3 Coding part 6",
          "PROJECT #4 Overview",
          "PROJECT #4 Google Colab Overview",
          "PROJECT #4 Coding Part 1",
          "PROJECT #4 Coding Part 2",
          "PROJECT #4 Coding Part 3"
        ],
        "ARTIFICIAL NEURAL NETWORKS FOR CLASSIFICATION TASKS": [
          "PROJECT #5 Project Overview sentiment",
          "PROJECT #5 Tokenization and Count Vectorizer",
          "PROJECT #5 Confusion Matrix",
          "PROJECT #5 Load Dataset",
          "PROJECT #5 Data Visualization",
          "PROJECT #5 Data Tokenization",
          "PROJECT #5 Model Building and Training",
          "PROJECT #5 Model Evaluation",
          "PROJECT #6 Project Overview",
          "PROJECT #6 Google Colab Project Questions Overview",
          "PROJECT #6 Google Colab Project Questions Overview 2",
          "PROJECT #6 Project Coding Solution Part 1",
          "PROJECT #6 Project Coding Solution Part 2"
        ],
        "DEEP LEARNING FOR IMAGE CLASSIFICATION": [
          "PROJECT #7 Overview",
          "PROJECT #7 CNN Entire Network Overview",
          "PROJECT #7 Feature Detectors",
          "PROJECT #7 RELU",
          "PROJECT #7 Pooling and Downsampling",
          "PROJECT #7 Performance Improvement",
          "PROJECT #7 Coding part 1 Import Data",
          "PROJECT #7 Coding part 2 Visualization",
          "PROJECT #7 Coding part 3 Train model",
          "PROJECT #7 Coding part 4 - Evaluate model",
          "PROJECT #8 Project Overview",
          "PROJECT #8 LeNet Architecture",
          "PROJECT #8 Coding part 1",
          "PROJECT #8 Coding part 2",
          "PROJECT #8 Coding part 3",
          "PROJECT #9 Overview",
          "PROJECT #9 Questions Overview",
          "PROJECT #9 Solution Part 1",
          "PROJECT #9 Solution Part 2"
        ],
        "MODEL DEPLOYMENT USING TF SERVING": [
          "TF Serving Coding Part 1",
          "TF Serving Coding Part 2",
          "TF Serving Coding Part 3",
          "Tensorboard Example 1",
          "Tensorboard Example 2",
          "Distributed Strategy"
        ],
        "Congratulations!! Don't forget your Prize :)": [
          "Bonus Lecture"
        ]
      },
      "requirements": [
        "PC with internet connection"
      ],
      "description": "Artificial Intelligence (AI) revolution is here and TensorFlow 2.0 is finally here to make it happen much faster! TensorFlow 2.0 is Google’s most powerful, recently released open source platform to build and deploy AI models in practice.\nAI technology is experiencing exponential growth and is being widely adopted in the Healthcare, defense, banking, gaming, transportation and robotics industries. The purpose of this course is to provide students with practical knowledge of building, training, testing and deploying Artificial Neural Networks and Deep Learning models using TensorFlow 2.0 and Google Colab.\nThe course provides students with practical hands-on experience in training Artificial Neural Networks and Convolutional Neural Networks using real-world dataset using TensorFlow 2.0 and Google Colab. This course covers several technique in a practical manner, the projects include but not limited to:\n(1) Train Feed Forward Artificial Neural Networks to perform regression tasks such as sales/revenue predictions and house price predictions\n(2) Develop Artificial Neural Networks in the medical field to perform classification tasks such as diabetes detection.\n(3) Train Deep Learning models to perform image classification tasks such as face detection, Fashion classification and traffic sign classification.\n(4) Develop AI models to perform sentiment analysis and analyze customer reviews.\n(5) Perform AI models visualization and assess their performance using Tensorboard\n(6) Deploy AI models in practice using Tensorflow 2.0 Serving\nThe course is targeted towards students wanting to gain a fundamental understanding of how to build and deploy models in Tensorflow 2.0. Basic knowledge of programming is recommended. However, these topics will be extensively covered during early course lectures; therefore, the course has no prerequisites, and is open to any student with basic programming knowledge. Students who enroll in this course will master AI and Deep Learning techniques and can directly apply these skills to solve real world challenging problems using Google’s New TensorFlow 2.0.",
      "target_audience": [
        "Data Scientists who want to apply their knowledge on Real World Case Studies",
        "AI Developers",
        "AI Researchers"
      ]
    },
    {
      "title": "Intelligently Extract Text & Data from Document with OCR NER",
      "url": "https://www.udemy.com/course/business-card-reader-app/",
      "bio": "Develop Document Scanner App project that is Named entity extraction from scan documents with OpenCV, Pytesseract, Spacy",
      "objectives": [
        "Develop and Train Named Entity Recognition Model",
        "Not only Extract text from the Image but also Extract Entities from Business Card",
        "Develop Business Card Scanner like ABBY from Scratch",
        "High Level Data Preprocess Techniques for Natural Language Problem",
        "Real Time NER apps"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Project Plan",
          "Project Document",
          "Download the Resources",
          "Facing any Issue with the Course ? Here is the solution"
        ],
        "Project Setup": [
          "Install Python",
          "Install Virtual Environment",
          "Install Packages into Virtual Environment",
          "Install Tesseract OCR & Pytesseract",
          "Install spaCy",
          "Test, the packages are installed"
        ],
        "Data Preparation": [
          "Load Business Card using OpenCV & PIL",
          "Pytesseract: Extract text from Image",
          "Pytesseract: Tesseract Error",
          "Pytesseract: How Pytesseract with work ?",
          "Pytesseract: Image to text to dataframe",
          "Pytesseract: Clean Text in Dataframe",
          "Pytesseract: Draw Bounding Box around each word",
          "Extract Text and Data from all Business Card",
          "Save data in csv",
          "Labeling"
        ],
        "Data Preprocessing and Cleaning": [
          "Spacy Training Data Format",
          "Load Data and convert into Pandas DataFrame",
          "Updated Code.",
          "Cleaning Text",
          "Convert Data into spacy format",
          "Testing Entities",
          "Convert data into spacy format for all Business card text",
          "Splitting Data into Training and Testing Set"
        ],
        "Train Named Entity Recognition (NER) model": [
          "Spacy: Fill the Configuration",
          "Spacy: Prepare Data",
          "Spacy: Train NER pipeline model",
          "Spacy: Save NER Model"
        ],
        "Predictions": [
          "Import Required Libraries",
          "Clean Text Function",
          "Load Spacy NER Model",
          "Extract Text from Image and Convert into Data Frame",
          "Convert Data Frame into Content",
          "Get Named Entities from model",
          "Displacy render",
          "Tagging Each Word",
          "Join Label to tokens dataframe",
          "Join token dataframe with Pytesseract data",
          "Bounding Box and Tagging Predicted Entities",
          "Combine the BIO information",
          "Bounding Box",
          "Parsing Function",
          "Testing",
          "Parse Entitles",
          "Predictions Function",
          "Final Prediction Pipeline"
        ],
        "Improve Model Performance": [
          "Ideas to Improve model accuracy",
          "Version-2 model framework: Data Preprocessing",
          "Train Version 2 model",
          "Get Predictions from the model"
        ],
        "Document Scanner": [
          "Download the Resources",
          "What and Why Document Scanner in OpenCV ?",
          "Setup and Read Image",
          "Resize Image with same aspect ratio",
          "Edge Detection (Enhance, Blur and Canny) to Document",
          "Dilate Edges with morphological transform",
          "Find Four Point Countours (Identify Location of document)",
          "Apply Wrap transform and crop only document",
          "Document Scanner Function: Putting All together",
          "Magic Color to Image",
          "Integrate NER Predictions"
        ],
        "Document Scanner Web App": [
          "What will you Develop ?",
          "Download Web App",
          "Setting Up Web App Project",
          "Install VS Code",
          "Install Flask",
          "First Flask App",
          "Run HTML file with Flask server",
          "Our Web App design steps",
          "Step-1: Design Page: Create Navigation Bar in HTML",
          "Step-1: Create About Page",
          "Step-2: Create HTML form to Upload Image or File in HTML",
          "Step-3: How to Predict document coordinates with Python in Flask",
          "Step-2: Upload and save image Backend : create settings.py",
          "Step-2: Upload and save image Backend: save image from HTML form",
          "Step-3: Document Scanning",
          "Adjust coordinates of document using JavaScript",
          "Wrap and Crop the document and save the image",
          "Get Predictions",
          "Design Predictions page",
          "Display results in table",
          "Final"
        ],
        "Appendix": [
          "Limitations of Pytesseract"
        ]
      },
      "requirements": [
        "Should be at least beginner in Python",
        "Understand aggregation techniques with Pandas DataFrames",
        "Read, Write Images with OpenCV and Drawing Rectangles on Image",
        "Understand HTML, Boostrap"
      ],
      "description": "Welcome to Course \"Intelligently Extract Text & Data from Document with OCR NER\" !!!\nIn this course you will learn how to develop customized Named Entity Recognizer. The main idea of this course is to extract entities from the scanned documents like invoice, Business Card, Shipping Bill, Bill of Lading documents etc. However, for the sake of data privacy we restricted our views to Business Card. But you can use the framework explained to all kinds of financial documents. Below given is the curriculum we are following to develop the project.\nTo develop this project we will use two main technologies in data science are,\nComputer Vision\nNatural Language Processing\nIn Computer Vision module, we will scan the document, identify the location of text and finally extract text from the image. Then in Natural language processing, we will extract the entitles from the text and do necessary text cleaning and parse the entities form the text.\n\n\nPython Libraries used in Computer Vision Module.\nOpenCV\nNumpy\nPytesseract\nPython Libraries used in Natural Language Processing\nSpacy\nPandas\nRegular Expression\nString\n\n\nAs are combining two major technologies to develop the project, for the sake of easy to understand we divide the course into several stage of development.\nStage -1: We will setup the project by doing the necessary installations and requirements.\nInstall Python\nInstall Dependencies\nStage -2: We will do data preparation. That is we will extract text from images using Pytesseract and also do necessary cleaning.\nGather Images\nOverview on Pytesseract\nExtract Text from all Image\nClean and Prepare text\nStage -3: We will see how to label NER data using BIO tagging.\nManually Labeling with BIO technique\nB - Beginning\nI  -  Inside\nO - Outside\nStage -4: We will further clean the text and preprocess the data for to train machine learning.\nPrepare Training Data for Spacy\nConvert data into spacy format\nStage -5: With the preprocess data we will train the Named Entity model.\nConfiguring NER Model\nTrain the model\nStage -6: We will predict the entitles using NER and model and create data pipeline for parsing text.\nLoad Model\nRender and Serve with Displacy\nDraw Bounding Box on Image\nParse Entitles from Text\n\n\nFinally, we will put all together and create document scanner app.\nAre you ready !!!\nLet start developing the Artificial Intelligence project.",
      "target_audience": [
        "Anyone who wants to Develop Business Card Reader App",
        "Data Scientist, Analyst, Python Develop who want to enhance skills in NLP"
      ]
    },
    {
      "title": "Machine Learning No-Code Approach: Using Azure ML Studio",
      "url": "https://www.udemy.com/course/machine-learning-no-code-approach-using-azure-ml-studio/",
      "bio": "A hands-on approach to Machine Learning using the easy drag-n-drop environment of Azure Machine Learning Studio",
      "objectives": [
        "Examine the foundations of Supervised Machine Learning",
        "Use Azure ML Studio to create Predictive Models without code",
        "Evaluate different algorithms to find the one that works best",
        "Deploy models live to be used with new data",
        "Build a real estate model to predict house prices",
        "Experiment with the traditional Titanic Dataset to predict survival chances"
      ],
      "course_content": {
        "Welcome to the Course": [
          "Welcome",
          "Compare Machine Learning Categories",
          "Choose the correct Machine Learning Category",
          "Create a Free Azure Account",
          "Define Azure ML Studio Features"
        ],
        "Classification Using the Titanic Dataset": [
          "Introduction",
          "Load the Dataset",
          "Understand the Features",
          "Select Features",
          "Edit Metadata",
          "Split the Data",
          "Select the Algorithm",
          "Train Model",
          "Score Model",
          "Evaluate Model",
          "Exercise 1: The Iris Flower",
          "Exercise 1: The Iris Flower (Solution)",
          "Summary"
        ],
        "Refining The Classification Model": [
          "Introduction",
          "Summarize The Data",
          "Select More Features",
          "Clean Missing Data",
          "Stratify The Data",
          "Tune The Hyperparameters",
          "Evaluate Model in Depth",
          "Compare Different Algorithms",
          "Deploy The Model",
          "Exercise 2: Refining The Iris Flower",
          "Exercise 2: Refining The Iris Flower (Solution)",
          "Summary"
        ],
        "Regression Using A Real Estate Dataset": [
          "Introduction",
          "Explore The Data",
          "Clean Missing Data",
          "Edit Metadata",
          "Test Model",
          "Evaluate Model",
          "Optional - MAE and RAE Explained",
          "Exercise 3: Iowa Housing Market",
          "Exercise 3: Iowa Housing Market (Solution)",
          "Summary"
        ],
        "Refining The Regression Model": [
          "Introduction",
          "Reassess Feature Selection",
          "Hyperparameter Tuning",
          "Compare Algorithms",
          "Deploy The Model",
          "Exercise 4: Refining Iowa Housing Market",
          "Exercise 4: Refining Iowa Housing Market (Solution)",
          "Summary"
        ],
        "Conclusion": [
          "What You Have Learned",
          "Azure ML Studio",
          "Next Steps",
          "Bonus Lecture"
        ]
      },
      "requirements": [
        "Be able to work with computer files and folders",
        "Be able to use a spreadsheet application like Microsoft Excel or Google Sheets",
        "A free or paid subscription to Microsoft Azure"
      ],
      "description": "Machine Learning is the most in demand technical skill in today's business environment. Most of the time though it is reserved for professionals that know how to code.\nBut Microsoft Azure Machine Learning Studio changed that. It brings a drag-n-drop easy to use environment to anyone’s fingertips. Microsoft is known for its easy-of-use tools and Azure ML Studio is no different.\nHowever, as easy as Azure ML Studio is, if you don’t know Machine Learning, at least the basics, you won’t be able to do much with the tool. This is one of the goals of this course: To give you the foundational understanding about Machine Learning. You will get the base knowledge required to not only talk proficiently about ML, but also to put it into action and execute on business needs.\nWe will go through all the steps necessary to put together a Supervised Learning prediction model, whether you need Classification (for discrete values like “Approved” or “Nor Approved”) or Regression (for continuous values like “Salary” or “Price”).\nThe course will only require you to have basic knowledge of math including the basic operations and how to calculate average. Some exposure to Microsoft Excel would be good as during deployment of the live model, we will be using Excel to perform demonstrations.\nThis course has been designed keeping in mind technologists with no coding background as we use a “no-code approach”. It is very hands-on, and you will be able to develop your own models while learning. We will cover:\n- Basics of the main three main types of Machine Learning Algorithms\n- Supervised Learning in depth\n- Classification by using the Titanic Dataset\n- Understanding and selecting the features from the dataset\n- Changing the metadata of features to work better with ML Algorithms\n- Splitting the data\n- Selecting the Algorithm\n- Training, scoring, and evaluating the model\n- Regression by using the Melbourne Real Estate Dataset\n- Cleaning missing data\n- Stratifying the data\n- Tuning hyperparameters\n- Deploying the models to a Excel\n- Providing web service details to developers in case you want to integrate with external systems\n- Azure ML Cheat Sheet\nThe course also includes 4 assignments with solutions that will give you an extra chance to practice your newly acquired Machine Learning skills.\nIn the end you will be able to use your own datasets to help your company with data prediction or, if you just want to impress the boss, you will be able to show the new tool you have just added to your toolbelt.\nIf you are not a coder and thought there would be no place for you to ride the Machine Learning wave, think again. You can not only be part of it, but you can master it and become a Machine Learning hero with Azure ML Studio.\nEnroll today and I will see you inside!",
      "target_audience": [
        "Technology Professionals",
        "Curious about Machine Learning",
        "Not a Coder"
      ]
    },
    {
      "title": "2026 Bootcamp: Generative AI, LLM Apps, AI Agents, Cursor AI",
      "url": "https://www.udemy.com/course/bootcamp-generative-artificial-intelligence-and-llm-app-development/",
      "bio": "From zero to professional level: learn the keys to Generative AI, LLM Apps, AI Agents, and Cursor AI.",
      "objectives": [
        "Keys to AI, Generative AI, LLM Apps, and new AI Coding Assistants like Cursor AI.",
        "LLM Apps with LangChain, CrewAI, LangGraph, LangServe and LangSmith.",
        "How to build apps without coding using Cursor AI and AI Coding Assistants.",
        "How to build the new Multimodal and Multi-Agent LLM Applications.",
        "Opportunities and threats of AI for businesses, startups, and jobs.",
        "RAG Applications in Depth: Full Stack RAG Apps and Advanced Techniques.",
        "How to manage LLMOps: Observability, Evaluation, Testing, Etc.",
        "Professional opportunities opened by Artificial Intelligence.",
        "Steps to become an Artificial Intelligence Engineer.",
        "How to introduce Artificial Intelligence into your business.",
        "Keys to LLM Applications, the highest potential applications of Generative AI.",
        "Architecture of professional LLM Applications.",
        "The RAG Technique (Retrieval Augmented Generation).",
        "Artificial Intelligence Agents.",
        "Basic and advanced LangChain, LangChain LCEL, and LangChain v010. LangSmith, LangServe, LangChain Templates.",
        "LCEL (LangChain Expression Language) in depth.",
        "Basic and advanced LlamaIndex. LlamaIndex Templates.",
        "ChatGPT, OpenAI, OpenAI functions, and the OpenAI API.",
        "Large Language Models (LLM): ChatGPT, Llama2, Mistral, Falcon, etc.",
        "Vector databases: Postgres, Pinecone, Chroma, FAISS, DeepLake, etc.",
        "Full-Stack Applications: Nextjs and FastAPI.",
        "Professional deployment: Vercel and Render.",
        "Provisional deployment: Streamlit.",
        "Cloud hosting: AWS S3.",
        "How to apply the principles of Responsible AI.",
        "Daily tools of the AI Engineer: Jupyter Notebooks, Python, Terminal, Github, Codespaces, etc."
      ],
      "course_content": {
        "Program presentation": [
          "[NEW] See what our students are saying about this bootcamp.",
          "Program presentation",
          "[NEW] The Online Bootcamp: Learning Paths & Learning Rhythms by Student Profile",
          "[NEW] Gift to celebrate our 45,000 students: our Prompt Engineering ebook free!",
          "[NEW] Advanced Contents for your Second Round with the Program",
          "Please leave your review and share your experience",
          "[NEW] Advice for the Stressed Student",
          "[NEW] Generative AI: A world of opportunities. What is happening?",
          "[NEW] What will you build in this bootcamp? LLM Apps and Exercises. Take a look!",
          "[NEW] Generative AI skills will help you advance professionally",
          "Opportunities this program will open for you",
          "What will you learn in this program",
          "Materials included in the program",
          "Who is this program for",
          "What makes this program different",
          "Distinguish yourself as Honor Student",
          "Introduction of the Instructor",
          "Share your progress",
          "COME BACK OFTEN: We update this program very frequently"
        ],
        "Tips for the students": [
          "Tips for the students",
          "Practical tips for the students",
          "The secret to successfully completing this bootcamp"
        ],
        "INTRODUCTION: LLM Apps, the key to the New AI": [
          "LLM Apps, the key to the New AI",
          "LLM Apps and the Universalization of AI",
          "ChatGPT vs. LLM Apps"
        ],
        "Download the two books included with the program": [
          "Download the two books included with the program"
        ],
        "PART 1: IMPORTANCE OF ARTIFICIAL INTELLIGENCE AND GENERATIVE AI.": [
          "REMINDER: Please leave your review and share your experience",
          "REMINDER: Advice for the Stressed Student",
          "Note about Part 1: Is this Part Right for You?",
          "[NEW] Do not make these two mistakes",
          "[NEW] See the reviews of other students at this point",
          "Intro to Artificial Intelligence",
          "Artificial Intelligence: What is it? Why is so popular now? How important is it?",
          "Changes introduced by AI: Introduction"
        ],
        "AI: Changes in Employment": [
          "AI: Changes in Employment",
          "Jobs that will benefit the most from AI",
          "Jobs most affected by AI",
          "Jobs least affected by AI",
          "New professions created by AI",
          "The new AI Engineers",
          "[NEW] Data Scientist and ML Engineer vs. the new Generative AI Engineer"
        ],
        "AI: Changes in Businesses": [
          "AI: Changes in Businesses",
          "Consequences of the changes in employment",
          "Industries with high impact",
          "Industries with median impact",
          "Industries with immediate impact"
        ],
        "AI: Changes in Startups": [
          "AI: Changes in Startups",
          "Opportunities for Startups: Characteristics of the New AI",
          "Opportunities for Startups: Changes in Employment",
          "Opportunities for Startups: AI impact on Businesses",
          "Opportunities for Startups: Book “100 AI Startups”",
          "[NEW] NOTE: AI Agent Startups"
        ],
        "AI: Changes in Society": [
          "AI: Changes in Society",
          "Social changes generated by the New AI",
          "Social challenges generated by the New AI"
        ],
        "How to introduce AI in your company": [
          "How to introduce AI in your company",
          "Plan to introduce AI in your company",
          "Tech and Business Analysis to introduce AI in your company",
          "How to select the right pilot project to introduce AI in your company",
          "How to form the first AI Team in your company",
          "How to prepare the AI Strategy of your company",
          "Example: Plan to adopt a new LLM App in your company"
        ]
      },
      "requirements": [
        "No previous technical knowledge is required.",
        "Students with some prior knowledge will improve their professional preparation."
      ],
      "description": "This Online Bootcamp is a compact and accelerated version of our 400-hour in-person master's program.\n\nIt has four parts:\n- In Part 1, you will learn the keys to Artificial Intelligence and the new Generative AI, as well as its potential to revolutionize businesses, startups, and employment.\n- In Part 2, you will learn to build professional-level LLM Applications, the most potential applications of Generative AI. You will also learn how to build Advanced RAG LLM Apps, Multimodal LLM Apps, AI Agents, Multi-Agent LLM Apps, and how to manage LLMOps.\n- In Part 3, you will learn how to build traditional and Gen AI apps without coding using Cursor AI and the new AI Coding Assistants. You will learn what are AI Coding Assistants like Cursor AI, Claude AI, v0, o1, Replit Agent, etc, and how to increase their performance by combining them with tools like the Replit platform, simplified backends like Firebase, Replicate AI, Stable Fusion, or Deepgram.\n- In Part 4, you will learn how to create SaaS applications without coding using Cursor AI. You’ll also see, through two high-level real-world examples, how Generative AI is transforming the SaaS (Software as a Service) model.\n\n\nBy the end of this program, you will know how to do the following:\n\nAI AND BUSINESS\nKnow the businesses that AI puts at risk of disappearing.\nKnow the new opportunities created by AI for businesses.\nDesign a plan to introduce AI into your company.\nSelect an appropriate pilot project to introduce AI into your company.\nForm the first AI team in your company.\nPrepare your company's AI strategy.\n\n\nAI AND STARTUP\nIdentify 100 opportunities to create AI startups.\n\n\nAI AND EMPLOYMENT\nKnow the professions that AI puts at risk of disappearing.\nKnow the new professions created by AI.\n\n\nLLM APPLICATIONS, THE APPLICATIONS WITH THE GREATEST POTENTIAL OF GENERATIVE AI.\nKnow the main use cases of LLM Applications in businesses and startups.\nRAG LLM Applications.\nMultimodal LLM Applications.\nAI Agents.\nMulti-Agent LLM Applications.\n\n\nCREATION OF PROFESSIONAL LLM APPLICATIONS.\nYou will learn the Architecture of an LLM Application.\nYou will learn how to learn programming languages like Python and Javascript.\nYou will learn to work with your computer's terminal.\nYou will learn to work with Jupyter notebooks.\nYou will learn to work with code editors like Visual Studio Code.\nYou will learn to work with virtual environments.\nYou will learn to work with hidden files to save credentials.\nYou will learn how to use different LLM models (OpenAI, DeepSeek, Meta, Mistral, Anthropic, Groq, etc).\nYou will learn the RAG (Retrieval Augmented Generation) technique.\nYou will learn to use LangChain.\nYou will learn to use the LangChain Expression Language (LCEL).\nYou will learn LCEL in depth.\nYou will learn to use the new versions v010 and v020 of LangChain.\nYou will learn to use LlamaIndex.\nYou will learn to use the OpenAI API.\nYou will learn to use OpenAI's functions.\nYou will learn to use LangSmith.\nYou will learn to use LangServe.\nYou will learn to use templates of LangChain and LlamaIndex.\nYou will learn what AI Agents are and how to create them.\nYou will learn to create prototypes (demos) of LLM applications with LangChain and Streamlit.\nYou will learn to create full-stack CRUD applications with Nextjs, FastAPI, and Postgres.\nYou will learn to create professional full-stack LLM applications with LangChain, LlamaIndex, Nextjs, Tailwind CSS, FastAPI, Flask, and Postgres.\nYou will learn to use vector and traditional databases.\nYou will learn to deploy applications on Vercel and Render.\nYou will learn to use AWS S3 as a remote storage platform.\nYou will learn to use ChatGPT as a programming assistant.\nYou will learn to use GPT4-Vision and GPT4o.\nYou will learn to work with Github and Github Codespaces.\nYou will learn what LLMOps is and how to use it in your LLM Applications.\nYou will learn the principles of Responsible AI and how to use them in your LLM Applications.\nYou will learn how to build advanced RAG LLM Applications.\nYou will learn how to build the new Multimodal LLM Applications.\nYou will learn how to build the new AI Agents.\nYou will learn how to build the new Multi-Agent LLM Applications.\nYou will learn to use LangGraph.\nYou will learn to use CrewAI.\n\nAPP DEVELOPMENT WITHOUT CODING USING CURSOR AI AND THE NEW AI CODING ASSISTANTS\nCursor AI, the new AI Coding Assistants and the future of software development.\nAnalysis of Cursor AI and the top AI Coding Assistants.\nTop strategies and techniques to get the most from Cursor AI.\nThe best Cursor AI combo for beginners: custom starter template, Replit, v0, and Firebase.\nHow to build 6 complete projects without coding using Cursor AI: from a simple to-do list app, to a social network, a chatbot, a tex-to-image app, a voice-to-text app, and a basic full-stack SaaS app with authentication and payment systems.\n\nHOW GENERATIVE AI IS DISRUPTING THE SAAS BUSINESSES\nHow Generative AI is replacing major SaaS apps like Salesforce and Workday.\nHow AI Agents are killing SaaS apps.\nThe future of SaaS and Micro SaaS.\n\n\nThe Bootcamp consists of:\nMore than 650 lessons divided into sections.\nMore than 650 videos.\nMore than 320 attached presentations.\nMore than 220 practical notebooks.\n50 practical code repositories on Github.\n45 LLM applications of different difficulty levels: basic, intermediate, and advanced.\nMaterial for more than 400 hours of study and practice for the student.\n2 downloadable books valued at $50: \"Keys to Artificial Intelligence\" and \"100 AI Startups that made more than $500,000 before the first year\".\n\n\nTopics included in this Bootcamp:\nAI, Generative AI, AI Applications, LLM Applications, Multimodal LLM Applications, chatGPT, Llama2, GPT-4 Vision, GPT4o, Full-Stack Applications, LangChain, LangChain Expression Language (LCEL), LangChain v010, LangChain v020, LlamaIndex, OpenAI, OpenAI API, RAG, RAG Technique, Vector databases, Postgres, Pinecone, Chroma, DeepLake, Streamlit, Nextjs, Tailwind CSS, Vercel, FastAPI, Flask, Render, AWS S3, LangSmith, LangServe, LangChain Templates, LlamaIndex Templates, LLMOps, Responsible AI, LangGraph, CrewAI, Multi-Agent LLM Apps, AI Agents, Groq, Llama3, Mixtral, Cursor AI, Cursor, Composer, v0, Claude AI, Claude 3.5 Sonnet, o1, o1-preview, o1-mini, Replit Agent, Replit, Firebase, Supabase, Replicate AI, Stable Fusion, Deepgram, SaaS, Micro SaaS, DeepSeek.",
      "target_audience": [
        "Students and professionals with and without previous experience.",
        "Students without prior knowledge interested in taking advantage of the professional opportunities opened by the field of Artificial Intelligence.",
        "Executives interested in introducing Artificial Intelligence into their company.",
        "Machine Learning, Deep Learning, and Data Science professionals interested in expanding their professional opportunities in the area of Generative AI and LLM Applications.",
        "Software application developers interested in expanding their professional opportunities by learning to develop Generative Artificial Intelligence and LLM Applications."
      ]
    },
    {
      "title": "Deep Learning Foundation : Linear Regression and Statistics",
      "url": "https://www.udemy.com/course/linear-regression-in-python-statistics-and-coding/",
      "bio": "Learn linear regression from scratch, Statistics, R-Squared, Python, Gradient descent, Deep Learning, Machine Learning",
      "objectives": [
        "Mathematics behind R-Squared, Linear Regression,VIF and more!",
        "Deep understating of Gradient descent and Optimization",
        "Program your own version of a linear regression model in Python",
        "Derive and solve a linear regression model, and implement it appropriately to data science problems",
        "Statistical background of Linear regression and Assumptions",
        "Assumptions of linear regression hypothesis testing",
        "Writing codes for T-Test, Z-Test and Chi-Squared Test in python"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Why Statistics?",
          "Types of variables",
          "Variable Types Quiz"
        ],
        "Introduction to Linear Regression": [
          "Linear Regression Introduction",
          "R-Squared",
          "SSE_SST_SSE",
          "Cost-Function and Optimization",
          "Cost-Function in 3-d",
          "Gradient Descent Maths",
          "Gradient Descent Example"
        ],
        "coding a linear regression model from scratch": [
          "coding a linear regression model from scratch",
          "house price prediction with linear regression",
          "Effect of learning rate in gradient descent",
          "adaptive learning rates",
          "multivariate linear regression",
          "coding multivariate linear regression from scratch"
        ],
        "Basic Statistics": [
          "Linear Regression prerequisites: statistics",
          "What is hypothesis",
          "Unbiased sample estimator",
          "Histogram and Distributions",
          "P-Value and Testing hypothesis",
          "Normal Distribution Yet another example"
        ],
        "Statistical Tests": [
          "Types of Test for hypothesis",
          "Problem Statement",
          "T-Statistics",
          "T-test in python",
          "Z- Test",
          "Chi-Square Test"
        ],
        "Assumptions of linear regression": [
          "Introduction to Assumptions of Linear regression",
          "correlation and covariance",
          "Assumptions of linear regression",
          "VIF and multicollinearity",
          "upcoming-lectures"
        ],
        "Logistic Regression": [
          "Logistic regression binary classification",
          "Logistic regression multiclass classification"
        ],
        "Bonus Lectures": [
          "Eigenvalues and Eigenvectors",
          "make moving charts with python",
          "Time Series forecasting",
          "PCA for data science and Machine learning",
          "Solve a neural network on paper",
          "Training Neural network with your own images",
          "Transfer learning",
          "Entropy a Mathematical view",
          "Eyes and Face detection with python",
          "Data Science Interview Questions"
        ]
      },
      "requirements": [
        "Jupyter notebook and simple python programming"
      ],
      "description": "Hi Everyone welcome to new course which is created to sharpen your linear regression and statistical basics. linear regression is starting point for a data science this course focus is on making your foundation strong for deep learning and machine learning algorithms. In this course I have explained hypothesis testing, Unbiased estimators, Statistical test , Gradient descent. End of the course you will be able to code your own regression algorithm from scratch.",
      "target_audience": [
        "Python developers curious about data science",
        "data science and machine leaning engineers"
      ]
    },
    {
      "title": "Associate Generative AI (NCA-GENL) Exam Prep Course",
      "url": "https://www.udemy.com/course/associate-generative-ai-llms-nca-genl/",
      "bio": "Complete, Unofficial Study Guide to Pass the NCA-GENL Exam and Earn Your Generative AI Specialist Credential",
      "objectives": [
        "Machine Learning Fundamentals",
        "Deep Learning Fundamentals",
        "Generative AI and LLMs",
        "NVIDIA GPU Acceleration",
        "Prompt Engineering",
        "NCA-GENL Exam Preparation"
      ],
      "course_content": {
        "Introduction": [
          "Quick Note"
        ],
        "Introduction to Bootcamp": [
          "Introduction to Bootcamp"
        ],
        "Trustworthy AI": [
          "Introduction to AI and Generative AI",
          "Foundations of Generative AI with Demo",
          "Knowledge Check",
          "Understanding Trustworthy AI",
          "How to Minimize Bias in AI systems"
        ],
        "Machine Learning Fundamentals": [
          "Introduction to Machine Learning Fundamentals",
          "ML Fundamentals Quiz",
          "Introduction to Machine Learning",
          "Types of Machine Learning",
          "Linear Regression & Evaluation Metrics for Regression",
          "Regularization and Assumptions of Linear Regression",
          "Logistic Regression",
          "Gradient Descent",
          "Logistic Regression Implementation and EDA",
          "Evaluation Metrics for Classification",
          "Decision Tree Algorithms",
          "Loss Functions of Decision Trees",
          "Decision Tree Algorithm Implementation",
          "Overfit Vs Underfit - Kfold Cross validation",
          "Hyperparameter Optimization Techniques",
          "KNN Algorithm",
          "SVM Algorithm",
          "Ensemble Learning - Voting Classifier",
          "Ensemble Learning - Bagging Classifier & Random Forest",
          "Ensemble Learning - Boosting Adabost and Gradient Boost",
          "Emsemble Learning XGBoost",
          "Clustering - Kmeans",
          "Clustering - Hierarchial Clustering",
          "Clustering - DBScan",
          "Time Series Analysis",
          "ARIMA Hands On"
        ],
        "Fundamentals of Deep Learning": [
          "Deep Learning Fundaments - Introduction",
          "Introduction to Deep Learning",
          "Introduction to Tensorflow & Create first Neural Network",
          "Intuition of Deep Learning Training",
          "Activation Function",
          "Architecture of Neural Networks",
          "Deep Learning Model Training. - Epochs - Batch Size",
          "Hyperparameter Tuning in Deep Learning",
          "Vanshing & Exploding Gradients - Initializations, Regularizations",
          "Introduction to Convolutional Neural Networks",
          "Implementation of CNN on CatDog Dataset",
          "Transfer Learning for Computer Vision",
          "Feed Forward Neural Network Challenges",
          "RNN & Types of Architecture",
          "LSTM Architecture",
          "Attention Mechanism",
          "Transfer Learning for Natural Language Data"
        ],
        "Essentials of NLP": [
          "Introduction to NLP Section",
          "Introduction to NLP and NLP Tasks",
          "Understanding NLP Pipeline",
          "Text Preprocessing Techniques - Tokenization",
          "Text Preprocessing - Pos Tagging, Stop words, Stemming & Lemmatization",
          "Feature Extraction - NLP",
          "One Hot Encoding Technique",
          "Bag of Words & Count Vectorizer",
          "TF IDF Score",
          "Word Embeddings",
          "CBoW and Skip gram - word embeddings"
        ],
        "Large Language Models": [
          "Introduction to Large Language Models",
          "How Large Language Models (LLMs) are trained",
          "Capabilities of LLMs",
          "Challenges of LLMs",
          "Introduction to Transformers - Attention is all you need",
          "Positional Encodings",
          "Positional Encodings - Deep Dive",
          "Self Attention & Multi Head Attention",
          "Self Attention & Multi Head Attention - Deep Dive",
          "Understanding Masked Multi Head Attention",
          "Masked Multi Head Attention - Deep Dive",
          "Encoder Decoder Architecture",
          "Customization of LLMs - Prompt Engineering",
          "Customization of LLMs - Prompt Learning - Prompt Tuning & p-tuning",
          "Difference between Prompt Tuning and p-tuning",
          "PEFT - Parameter Efficient Fine Tuning",
          "Training data for LLMs",
          "Pillars of LLM Training Data: Quality, Diversity, and Ethics",
          "Data Cleaning for LLMs",
          "Biases in Large Language Models",
          "Loss Functions for LLMs"
        ],
        "Prompt Engineering for the NCA-GENL Exam": [
          "What is Prompt Engineering ?",
          "Advanced Prompt Engineering",
          "Techniques for Effective Prompts",
          "Ethical Considerations in Prompt Design for Large Language Models"
        ],
        "Data Analysis and Visualization": [
          "Data Visualization & Analysis of LLMs",
          "EDA for LLMs"
        ],
        "Experimentation": [
          "Experiment Design Principles for LLMs",
          "Techniques for Large Language Models Experimentation",
          "Data Management and Version Control for LLM experimentation"
        ]
      },
      "requirements": [
        "Basic programming experience (Python recommended)",
        "Fundamental understanding of machine learning concepts",
        "Access to a computer with internet connectivity for online learning"
      ],
      "description": "Associate Generative AI (NCA-GENL) Exam Prep • Unofficial Study Guide\nDisclaimer: This course is an independent, unofficial preparation resource for the NCA-GENL (Generative AI with LLMs – Certified Associate) exam. It is not sponsored, endorsed, or approved by NVIDIA Corporation. “NVIDIA” and the NVIDIA eye logo are registered trademarks of NVIDIA Corporation, used here only to identify the certification exam.\nWhy take this course?\nThe Generative AI landscape is evolving at break-neck speed. Passing the NCA-GENL exam validates that you can build, fine-tune, and deploy large language models (LLMs) on GPU-accelerated platforms. This course distills the official exam blueprint into bite-sized lessons, hands-on labs, and mock quizzes—so you spend your study time where it counts.\nWhat you will master\nML & DL Fundamentals – Refresh core algorithms, loss functions, and optimization techniques that underpin generative models.\nTransformer & Diffusion Architectures – Understand attention, positional encoding, and sampling strategies that power today’s LLMs and image generators.\nPrompt Engineering – Craft, evaluate, and iterate prompts for text, code, and multimodal outputs.\nProduction Workflows – Containerize models, set up monitoring, and implement cost-aware scaling policies.\nReal-World Use-Cases – Case studies in content generation, conversational AI, code completion, and design automation.\n\n\nWho should enroll\nDevelopers & Data Scientists – Add LLM capabilities to applications without reinventing the wheel.\nML Engineers & MLOps Practitioners – Learn GPU-tuned deployment patterns and observability hooks.\nAI Enthusiasts & Students – Progress from “curious” to “credentialed” with a structured roadmap.\nProfessionals pursuing the NCA-GENL badge – Follow a laser-focused study plan and practise under exam conditions.\n\n\nPrerequisites\nBasic Python (loops, functions, virtual environments)\nIntroductory ML knowledge (train/valid/test split, overfitting, metrics)\nA workstation or cloud instance with Internet access (GPU optional but recommended)\nHow the course is structured\nFast-track Theory Videos\nLab Notebooks – Run-anywhere Jupyter notebooks with step-by-step instructions.\n\n\n\n\nOutcomes you can expect\nConfidently sit—and pass—the NCA-GENL exam.\nBuild and deploy LLM-powered solutions that are fast, scalable, and maintainable.\nSpeak the language of Generative AI fluently in technical interviews and client pitches.\nReady to future-proof your skill set?\nEnroll now and start your journey toward becoming an Associate Generative AI Specialist—on your terms, at your pace.",
      "target_audience": [
        "Developers seeking to integrate generative AI capabilities into their applications.",
        "Data Scientists interested in harnessing the power of LLMs for text analysis, natural language processing, and data-driven insights.",
        "Machine Learning Enthusiasts eager to explore the forefront of AI research, text generation, and language processing technologies.",
        "AI Professionals aiming to enhance their skill set, advance their careers, and achieve the prestigious NVIDIA Generative AI with LLM Certification."
      ]
    },
    {
      "title": "Machine Learning: Natural Language Processing in Python (V2)",
      "url": "https://www.udemy.com/course/natural-language-processing-in-python/",
      "bio": "NLP: Use Markov Models, NLTK, Artificial Intelligence, Deep Learning, Machine Learning, and Data Science in Python",
      "objectives": [
        "How to convert text into vectors using CountVectorizer, TF-IDF, word2vec, and GloVe",
        "How to implement a document retrieval system / search engine / similarity search / vector similarity",
        "Probability models, language models and Markov models (prerequisite for Transformers, BERT, and GPT-3)",
        "How to implement a cipher decryption algorithm using genetic algorithms and language modeling",
        "How to implement spam detection",
        "How to implement sentiment analysis",
        "How to implement an article spinner",
        "How to implement text summarization",
        "How to implement latent semantic indexing",
        "How to implement topic modeling with LDA, NMF, and SVD",
        "Machine learning (Naive Bayes, Logistic Regression, PCA, SVD, Latent Dirichlet Allocation)",
        "Deep learning (ANNs, CNNs, RNNs, LSTM, GRU) (more important prerequisites for BERT and GPT-3)",
        "Hugging Face Transformers (VIP only)",
        "How to use Python, Scikit-Learn, Tensorflow, +More for NLP",
        "Text preprocessing, tokenization, stopwords, lemmatization, and stemming",
        "Parts-of-speech (POS) tagging and named entity recognition (NER)",
        "Understand important foundations for OpenAI ChatGPT, GPT-4, DALL-E, Midjourney, and Stable Diffusion"
      ],
      "course_content": {
        "Introduction": [
          "Introduction and Outline",
          "Are You Beginner, Intermediate, or Advanced? All are OK!"
        ],
        "Getting Set Up": [
          "Where To Get the Code",
          "How to Succeed in This Course",
          "Temporary 403 Errors"
        ],
        "Vector Models and Text Preprocessing": [
          "Vector Models & Text Preprocessing Intro",
          "Basic Definitions for NLP",
          "What is a Vector?",
          "Bag of Words",
          "Count Vectorizer (Theory)",
          "Tokenization",
          "Stopwords",
          "Stemming and Lemmatization",
          "Stemming and Lemmatization Demo",
          "Count Vectorizer (Code)",
          "Vector Similarity",
          "TF-IDF (Theory)",
          "(Interactive) Recommender Exercise Prompt",
          "TF-IDF (Code)",
          "Word-to-Index Mapping",
          "How to Build TF-IDF From Scratch",
          "Neural Word Embeddings",
          "Neural Word Embeddings Demo",
          "Vector Models & Text Preprocessing Summary",
          "Text Summarization Preview",
          "How To Do NLP In Other Languages",
          "Suggestion Box"
        ],
        "Probabilistic Models (Introduction)": [
          "Probabilistic Models (Introduction)"
        ],
        "Markov Models (Intermediate)": [
          "Markov Models Section Introduction",
          "The Markov Property",
          "The Markov Model",
          "Probability Smoothing and Log-Probabilities",
          "Building a Text Classifier (Theory)",
          "Building a Text Classifier (Exercise Prompt)",
          "Building a Text Classifier (Code pt 1)",
          "Building a Text Classifier (Code pt 2)",
          "Language Model (Theory)",
          "Language Model (Exercise Prompt)",
          "Language Model (Code pt 1)",
          "Language Model (Code pt 2)",
          "Markov Models Section Summary"
        ],
        "Article Spinner (Intermediate)": [
          "Article Spinning - Problem Description",
          "Article Spinning - N-Gram Approach",
          "Article Spinner Exercise Prompt",
          "Article Spinner in Python (pt 1)",
          "Article Spinner in Python (pt 2)",
          "Case Study: Article Spinning Gone Wrong"
        ],
        "Cipher Decryption (Advanced)": [
          "Section Introduction",
          "Ciphers",
          "Language Models (Review)",
          "Genetic Algorithms",
          "Code Preparation",
          "Code pt 1",
          "Code pt 2",
          "Code pt 3",
          "Code pt 4",
          "Code pt 5",
          "Code pt 6",
          "Cipher Decryption - Additional Discussion",
          "Real-World Application: Acoustic Keylogger",
          "Section Conclusion"
        ],
        "Machine Learning Models (Introduction)": [
          "Machine Learning Models (Introduction)"
        ],
        "Spam Detection": [
          "Spam Detection - Problem Description",
          "Naive Bayes Intuition",
          "Spam Detection - Exercise Prompt",
          "Aside: Class Imbalance, ROC, AUC, and F1 Score (pt 1)",
          "Aside: Class Imbalance, ROC, AUC, and F1 Score (pt 2)",
          "Spam Detection in Python"
        ],
        "Sentiment Analysis": [
          "Sentiment Analysis - Problem Description",
          "Logistic Regression Intuition (pt 1)",
          "Multiclass Logistic Regression (pt 2)",
          "Logistic Regression Training and Interpretation (pt 3)",
          "Sentiment Analysis - Exercise Prompt",
          "Sentiment Analysis in Python (pt 1)",
          "Sentiment Analysis in Python (pt 2)"
        ]
      },
      "requirements": [
        "Install Python, it's free!",
        "Decent Python programming skills",
        "Optional: If you want to understand the math parts, linear algebra and probability are helpful"
      ],
      "description": "Ever wondered how AI technologies like OpenAI ChatGPT, GPT-4, DALL-E, Midjourney, and Stable Diffusion really work? In this course, you will learn the foundations of these groundbreaking applications.\n\n\nHello friends!\n\n\nWelcome to Machine Learning: Natural Language Processing in Python (Version 2).\n\n\nThis is a massive 4-in-1 course covering:\n1) Vector models and text preprocessing methods\n2) Probability models and Markov models\n3) Machine learning methods\n4) Deep learning and neural network methods\n\n\nIn part 1, which covers vector models and text preprocessing methods, you will learn about why vectors are so essential in data science and artificial intelligence. You will learn about various techniques for converting text into vectors, such as the CountVectorizer and TF-IDF, and you'll learn the basics of neural embedding methods like word2vec, and GloVe.\nYou'll then apply what you learned for various tasks, such as:\n\n\nText classification\nDocument retrieval / search engine\nText summarization\nAlong the way, you'll also learn important text preprocessing steps, such as tokenization, stemming, and lemmatization.\nYou'll be introduced briefly to classic NLP tasks such as parts-of-speech tagging.\n\n\nIn part 2, which covers probability models and Markov models, you'll learn about one of the most important models in all of data science and machine learning in the past 100 years. It has been applied in many areas in addition to NLP, such as finance, bioinformatics, and reinforcement learning.\nIn this course, you'll see how such probability models can be used in various ways, such as:\n\n\nBuilding a text classifier\nArticle spinning\nText generation (generating poetry)\nImportantly, these methods are an essential prerequisite for understanding how the latest Transformer (attention) models such as BERT and GPT-3 work. Specifically, we'll learn about 2 important tasks which correspond with the pre-training objectives for BERT and GPT.\n\n\nIn part 3, which covers machine learning methods, you'll learn about more of the classic NLP tasks, such as:\n\n\nSpam detection\nSentiment analysis\nLatent semantic analysis (also known as latent semantic indexing)\nTopic modeling\nThis section will be application-focused rather than theory-focused, meaning that instead of spending most of our effort learning about the details of various ML algorithms, you'll be focusing on how they can be applied to the above tasks.\nOf course, you'll still need to learn something about those algorithms in order to understand what's going on. The following algorithms will be used:\n\n\nNaive Bayes\nLogistic Regression\nPrincipal Components Analysis (PCA) / Singular Value Decomposition (SVD)\nLatent Dirichlet Allocation (LDA)\nThese are not just \"any\" machine learning / artificial intelligence algorithms but rather, ones that have been staples in NLP and are thus an essential part of any NLP course.\n\n\nIn part 4, which covers deep learning methods, you'll learn about modern neural network architectures that can be applied to solve NLP tasks. Thanks to their great power and flexibility, neural networks can be used to solve any of the aforementioned tasks in the course.\nYou'll learn about:\n\n\nFeedforward Artificial Neural Networks (ANNs)\nEmbeddings\nConvolutional Neural Networks (CNNs)\nRecurrent Neural Networks (RNNs)\nThe study of RNNs will involve modern architectures such as the LSTM and GRU which have been widely used by Google, Amazon, Apple, Facebook, etc. for difficult tasks such as language translation, speech recognition, and text-to-speech.\nObviously, as the latest Transformers (such as BERT and GPT-3) are examples of deep neural networks, this part of the course is an essential prerequisite for understanding Transformers.\n\n\nUNIQUE FEATURES\nEvery line of code explained in detail - email me any time if you disagree\nNo wasted time \"typing\" on the keyboard like other courses - let's be honest, nobody can really write code worth learning about in just 20 minutes from scratch\nNot afraid of university-level math - get important details about algorithms that other courses leave out\n\n\nThank you for reading and I hope to see you soon!",
      "target_audience": [
        "Anyone who wants to learn natural language processing (NLP)",
        "Anyone interested in artificial intelligence, machine learning, deep learning, or data science",
        "Anyone who wants to go beyond typical beginner-only courses on Udemy"
      ]
    },
    {
      "title": "Big Data Programming Languages & Big Data Vs Data Science",
      "url": "https://www.udemy.com/course/big-data-programming-languages-big-data-vs-data-science/",
      "bio": "Big Data Programming Languages,Skills to become a Big Data Professional,Differences between Big Data & Data Science",
      "objectives": [
        "Big Data Programming Languages",
        "Programming Language Concepts",
        "Skills needed to become a Big Data Professional",
        "Differences between Big Data & Data Science",
        "Similarities Between Big Data & Data Science",
        "Challenges of Big Data"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Programming Language Concepts",
          "Skills to become a Big Data Professional",
          "Big Data Vs Data Science",
          "Programming Languages in Big Data",
          "Challenges of Big Data"
        ],
        "QUIZ": [
          "Test your Understanding"
        ]
      },
      "requirements": [
        "No pre-requisites"
      ],
      "description": "Students will learn the following topics in this course.\nBig Data Programming Languages\nProgramming Language Concepts\nSkills to become a Big Data Professional\nDifferences between Big Data &  Data Science\nSimilarities Between Big Data & Data Science\nChallenges of Big Data\nBig Data Programming Languages\nProgramming Language Concepts\nSkills to become a Big Data Professional\nDifferences between Big Data &  Data Science\nSimilarities Between Big Data & Data Science\nChallenges of Big Data\nBig Data Programming Languages\nProgramming Language Concepts\nSkills to become a Big Data Professional\nDifferences between Big Data &  Data Science\nSimilarities Between Big Data & Data Science\nChallenges of Big Data\nBig Data Programming Languages\nProgramming Language Concepts\nSkills to become a Big Data Professional\nDifferences between Big Data &  Data Science\nSimilarities Between Big Data & Data Science\nChallenges of Big Data\nBig Data Programming Languages\nProgramming Language Concepts\nSkills to become a Big Data Professional\nDifferences between Big Data &  Data Science\nSimilarities Between Big Data & Data Science\nChallenges of Big Data\nBig Data Programming Languages\nProgramming Language Concepts\nSkills to become a Big Data Professional\nDifferences between Big Data &  Data Science\nSimilarities Between Big Data & Data Science\nChallenges of Big Data\nBig Data Programming Languages\nProgramming Language Concepts\nSkills to become a Big Data Professional\nDifferences between Big Data &  Data Science\nSimilarities Between Big Data & Data Science\nChallenges of Big Data\nBig Data Programming Languages\nProgramming Language Concepts\nSkills to become a Big Data Professional\nDifferences between Big Data &  Data Science\nSimilarities Between Big Data & Data Science\nChallenges of Big Data\nBig Data Programming Languages\nProgramming Language Concepts\nSkills to become a Big Data Professional\nDifferences between Big Data &  Data Science\nSimilarities Between Big Data & Data Science\nChallenges of Big Data",
      "target_audience": [
        "Beginner level students interested to learn Big Data programming languages"
      ]
    },
    {
      "title": "2023 CORE: Data Science and Machine Learning",
      "url": "https://www.udemy.com/course/core-data-science-and-machine-learning/",
      "bio": "A complete survey of all core skills required on the job",
      "objectives": [
        "Learn all necessary core skills for Data Analysis, Data Science, and Machine Learning",
        "Understand the first principles of data science and why it is so popular and important",
        "Learn how to use, from scratch, Python, R, SQL, Tableau, and MS Excel for data science",
        "Learn about a broad range of data science and machine learning libraries and resources",
        "Build and host a personal resume and portfolio of data science projects using GitHub Pages",
        "Learn about key supporting skills like Git/version-control, Kaggle, Databases, Command Line tools, and much more!",
        "Learn how to setup development environments from scratch in R and Python",
        "Learn about important related technologies like cloud, docker, and web development,",
        "Learn to deploy a machine learning model using docker"
      ],
      "course_content": {
        "Introduction - First Principals": [
          "Introduction",
          "Course Overview",
          "Course Structure",
          "Course Philosophy",
          "First Principles - Who?",
          "First Principles - Why? 1/3",
          "First Principles - Why? 2/3",
          "First Principles - Why? 3/3",
          "Reading Assignment",
          "First Principles - What?",
          "First Principles - What? Data Analyst Example Product",
          "First Principles - What? Data Scientist Example Product",
          "First Principles - What? Machine Learning Engineer Example Product",
          "First Principles - What? Data & Sources",
          "First Principles - What? Kaggle Introduction",
          "First Principles - How?",
          "Data Science Battle Station",
          "Section Wrap Up",
          "Assignments"
        ],
        "Data Analyst - Case Study - Intro & Basic Spreadsheets": [
          "Data Analyst Overview",
          "Spreadsheets Overview",
          "Introduction to MS Excel",
          "Setting up MS Excel",
          "Overview of MS Excel",
          "Excel Templates",
          "Workbook Overview",
          "Protecting Workbooks",
          "Sharing Workbooks",
          "Operators",
          "Built-in Functions"
        ],
        "Data Analyst - Case Study - Intermediate Spreadsheets": [
          "Math - Summary Statistics",
          "Calculating Summary Statistics from Scratch",
          "Import a Text File",
          "Data Tables",
          "Summary Statistics on Tables",
          "Summary Statistics Dashboard",
          "Assignment Review",
          "Importing Data - Intermediate",
          "Lookups and Matches",
          "Calculating Churn and Customer Lifetime Value",
          "Financial Forecasting (Time Series)",
          "Data Visualization Introduction",
          "Data Visualization Excel",
          "Dashboards Best Practices",
          "Build a Dashboard",
          "Assignment Solution"
        ],
        "Data Analyst - Case Study - Advanced Spreadsheets": [
          "Importing Data - Power Query",
          "Pivot Tables",
          "Mathematical Modeling - Linear Programming",
          "Solver - Linear Programming in Excel",
          "Analysis Toolpack",
          "Visual Basic for Applications (VBA) - Introduction",
          "Spreadsheet Conclusion",
          "Complete LinkedIn Excel Assessment"
        ],
        "Data Analyst - Case Study - SQL Basics": [
          "SSI - databases",
          "SQL Text Editor - Sublime",
          "SQL Syntax",
          "Introduction to SQLite Databases",
          "SQLite Install",
          "SQLite Database Creation",
          "Basic SQL - SELECT, FROM, WHERE statements",
          "Basic SQL - BETWEEN, LIKE statements",
          "Basic SQL - AND, OR, NOT, EXISTS, NULL statements",
          "Basic SQL - ORDER BY, DISTINCT statements"
        ],
        "Data Analyst - Case Study - SQL Intermediate and Advanced": [
          "Intermediate SQL - Aggregate Functions",
          "Intermediate SQL - Joins",
          "Intermediate SQL - WITH and subqueries",
          "Advanced SQL - Inserting, Updating, and Deleting data",
          "Advanced SQL - Views",
          "Connecting SQLite to Excel",
          "Kaggle SQL Course"
        ],
        "Data Analyst - Case Study - Business Intelligence and Tableau Introduction": [
          "Introduction to Business Intelligence (BI)",
          "Why Tableau?",
          "Installing Tableau Public",
          "Tableau Overview",
          "Tableau Data Types",
          "Tableau Basic Viz",
          "Tableau Filters",
          "Connecting Tableau to OData Sources",
          "Joining Data in Tableau"
        ],
        "Data Analyst - Case Study - Tableau Intermediate and Advanced Topics": [
          "Tableau Intermediate Bar Charts",
          "Tableau Dates",
          "Tableau Visualizing Comparisons",
          "Tableau Visualizing Distributions",
          "Tableau Multiple Axis",
          "Tableau Formating",
          "Tableau Calculations and Parameters",
          "Tableau Dashboards and Stories",
          "Tableau Advanced Analysis",
          "Sharing with Tableau Public",
          "Tableau Desktop Pro Overview",
          "Assignment: Portfolio, and Resume Updates"
        ],
        "Data Scientist - Case Study - Introduction to R": [
          "Introduction to the Data Scientist (Generalist)",
          "Overview of R",
          "Intro to CRAN and installing base R",
          "Installing RStudio",
          "Overview of RStudio",
          "Calculations in Base R",
          "Objects in Base R",
          "Functions in Base R",
          "The Basics of R Scripts",
          "Base R Datasets",
          "Base R Help and Plots",
          "Installing R Packages - More on Plots and Objects",
          "Atomic Vectors",
          "Object Attributes",
          "Matrix and Array Objects",
          "Classes",
          "Factors",
          "Coercion",
          "Lists",
          "Data Frames",
          "Loading and Saving Data Part 1",
          "Loading and Saving Data Part 2",
          "Selecting Values from Data Frames",
          "Changing Values in Data Frames",
          "Sub Setting Data Frames",
          "Missing Values",
          "More on Selecting Values",
          "Programming Flow Controls"
        ],
        "Data Scientist - Case Study - Exploratory Data Analysis and the R Tidyverse": [
          "An Introduction to EDA",
          "EDA Example on Kaggle",
          "Expanding Summary Statistics - Location",
          "Location Examples in R",
          "Expanding Summary Statistics - Spread",
          "Spread Examples in R",
          "Important EDA Tools",
          "Introduction to the Tidyverse and ggplot2",
          "Tidyverse website",
          "ggplot - Mapping Aesthetics",
          "ggplot - Facets",
          "ggplot - Multiple Geom",
          "ggplot - Stat Transforms",
          "ggplot - Position Adjustments",
          "ggplot - Coord Systems",
          "ggplot - Summary",
          "ggplot - Gallery Book",
          "R Object Names",
          "dplyr - Overview",
          "dplyr - Filter",
          "dplyr - Arrange and Select",
          "dplyr - Mutate",
          "dplyr - Pipes, group_by, and summarise",
          "stringr - Basics",
          "stringr - Matching",
          "lubridate - Basics",
          "Intro to Markdown",
          "Intro to RMarkdown",
          "Quick Overview of Notebooks",
          "EDA Assignment"
        ]
      },
      "requirements": [
        "Comfortable with high school (primary school) math.",
        "It will be much easier (but not required) if you have some familiarity with some type of computer programming"
      ],
      "description": "This is an ambitious course. The goal here is simple: Only teach what you need to know for day 1 of your first data science job. No fluff, nothing out of context, no topics that are not relevant to real world applications. We will cover EVERY core topic and tool required for those new to data science: Python, R, SQL, Useful Math/Stats/Algorithms, Tableau, and Excel in depth. The course will cover skills that align with three different job types:\n- Data Analyst\n- General Data Scientist\n- Machine Learning Engineer\nYou can expect to learn from first principles the foundational topics and tools used in practice today. We will avoid topics that are not useful or are simply too advanced when starting out. Your journey will be guided by the Data Science Road Map, a collection of the best resources gathered through years of experience by the instructor.\nIn addition, we will survey every important technology required on the job including GitHub, Kaggle, the basics of cloud, web development and docker. With over 200 videos, readings, and assignments, you can be sure you will be well prepared to join the data community.\nIf you are just getting started or want to fill in some of your knowledge gaps this course is for you!",
      "target_audience": [
        "Those who feels like they don't know where to start with data science and machine learning",
        "Those tired of courses that don't show the entire picture of data science and leave them asking 'now what?'",
        "Those interested in starting a journey into the data science and machine learning career field.",
        "For those wanting to super-charge an existing skill set with the latest techniques and tools."
      ]
    },
    {
      "title": "Data Science Real-World Case Studies - Hands On Python",
      "url": "https://www.udemy.com/course/data-science-real-world-use-cases-hands-on-python/",
      "bio": "Build Data science Real world Projects in AI, ML , NLP and Time Series domain & get a job of Data Scientist/ML Engineer",
      "objectives": [
        "Gain Hands on Data Science in Machine Learning, Natural Language Processing , Time Series Analysis",
        "Develop Natural Language Processing Models for fake news detection",
        "Develop time series forecasting models to predict sales of a product"
      ],
      "course_content": {},
      "requirements": [
        "Basic knowledge of Python programming is recommended."
      ],
      "description": "Are you looking to land a top-paying job in Data Science\nOr are you a seasoned AI practitioner who want to take your career to the next level?\nOr are you an aspiring data scientist who wants to get Hands-on Data Science and Artificial Intelligence ?\n\n\nIf the answer is yes to any of these questions, then this course is for you!\nData Science is one of the hottest tech fields to be in right now! The field is exploding with opportunities and career prospects. Data Science is widely adopted in many sectors nowadays such as banking, healthcare, Airlines, Logistic and technology\nThe purpose of this course is to provide you with knowledge of key aspects of data science applications in business in a practical, easy and fun way. The course provides students with practical hands-on experience using real-world datasets\n\n\n1.Task #1 :: Predict Success of a Zomato Restaurant :  Develop an Machine Learning model to predict whether Restaurant can be success or not\n\n\n2.Task #2 ::  Predict whether News is Fake or not:   Develop a Machine Learning Model that can predict whether particular news is fake or not by applying several NLP (Natural Language Processing) Techniques\n\n\n3.Task #3 :: Predict sales of a Product:   Develop time series forecasting models to predict sales of a product..\n\n\nWhy should you take this Course?\nIt explains Projects on  real Data and real-world Problems. No toy data! This is the simplest & best way to become a  Data Scientist/AI Engineer/ ML Engineer\nIt shows and explains the full real-world Data. Starting with Understanding Life-Cycle of Project ,  importing messy data, cleaning data, merging and concatenating data, grouping and aggregating data, Exploratory Data Analysis through to preparing and processing data for Statistics, Machine Learning , NLP & Time Series and Data Presentation.\n\n\nIt gives you plenty of opportunities to practice and code on your own. Learning by doing.\nIn real-world projects, coding and the business side of things are equally important. This is probably the only course that teaches both: in-depth Python Coding and Big-Picture Thinking like How you can come up with a conclusion\nGuaranteed Satisfaction: Otherwise, get your money back with 30-Days-Money-Back-Guarantee.",
      "target_audience": [
        "One who is curious to gain Practical Skills on Data Science, AI, Machine Learning, Natural Language Processing, Time Series Analysis.."
      ]
    },
    {
      "title": "Deep Learning with TensorFlow 2.0",
      "url": "https://www.udemy.com/course/machine-learning-with-tensorflow-for-business-intelligence/",
      "bio": "Build Deep Learning Algorithms with TensorFlow 2.0, Dive into Neural Networks and Apply Your Skills in a Business Case",
      "objectives": [
        "Gain a Strong Understanding of TensorFlow - Google’s Cutting-Edge Deep Learning Framework",
        "Build Deep Learning Algorithms from Scratch in Python Using NumPy and TensorFlow",
        "Set Yourself Apart with Hands-on Deep and Machine Learning Experience",
        "Grasp the Mathematics Behind Deep Learning Algorithms",
        "Understand Backpropagation, Stochastic Gradient Descent, Batching, Momentum, and Learning Rate Schedules",
        "Know the Ins and Outs of Underfitting, Overfitting, Training, Validation, Testing, Early Stopping, and Initialization",
        "Competently Carry Out Pre-Processing, Standardization, Normalization, and One-Hot Encoding"
      ],
      "course_content": {
        "Welcome! Course introduction": [
          "Meet your instructors and why you should study machine learning?",
          "What does the course cover?",
          "What does the course cover? - Quiz",
          "Download All Resources and Important FAQ"
        ],
        "Introduction to neural networks": [
          "Introduction to neural networks",
          "Introduction to neural networks - Quiz",
          "Training the model",
          "Training the model - Quiz",
          "Types of machine learning",
          "Types of machine learning - Quiz",
          "The linear model",
          "The linear model - Quiz",
          "Need Help with Linear Algebra?",
          "The linear model. Multiple inputs",
          "The linear model. Multiple inputs - Quiz",
          "The linear model. Multiple inputs and multiple outputs",
          "The linear model. Multiple inputs and multiple outputs - Quiz",
          "Graphical representation",
          "Graphical representation - Quiz",
          "The objective function",
          "The objective function - Quiz",
          "L2-norm loss",
          "L2-norm loss - Quiz",
          "Cross-entropy loss",
          "Cross-entropy loss - Quiz",
          "One parameter gradient descent",
          "One parameter gradient descent - Quiz",
          "N-parameter gradient descent",
          "N-parameter gradient descent - Quiz"
        ],
        "Setting up the working environment": [
          "Setting up the environment - An introduction - Do not skip, please!",
          "Why Python and why Jupyter?",
          "Why Python and why Jupyter? - Quiz",
          "Installing Anaconda",
          "The Jupyter dashboard - part 1",
          "The Jupyter dashboard - part 2",
          "Jupyter Shortcuts",
          "The Jupyter dashboard - Quiz",
          "Installing TensorFlow 2",
          "Installing packages - exercise",
          "Installing packages - solution"
        ],
        "Minimal example - your first machine learning algorithm": [
          "Minimal example - part 1",
          "Minimal example - part 2",
          "Minimal example - part 3",
          "Minimal example - part 4",
          "Minimal example - Exercises"
        ],
        "TensorFlow - An introduction": [
          "TensorFlow outline",
          "TensorFlow 2 intro",
          "A Note on Coding in TensorFlow",
          "Types of file formats in TensorFlow and data handling",
          "Model layout - inputs, outputs, targets, weights, biases, optimizer and loss",
          "Interpreting the result and extracting the weights and bias",
          "Cutomizing your model",
          "Minimal example with TensorFlow - Exercises"
        ],
        "Going deeper: Introduction to deep neural networks": [
          "Layers",
          "What is a deep net?",
          "Understanding deep nets in depth",
          "Why do we need non-linearities?",
          "Activation functions",
          "Softmax activation",
          "Backpropagation",
          "Backpropagation - visual representation"
        ],
        "Backpropagation. A peek into the Mathematics of Optimization": [
          "Backpropagation. A peek into the Mathematics of Optimization"
        ],
        "Overfitting": [
          "Underfitting and overfitting",
          "Underfitting and overfitting - classification",
          "Training and validation",
          "Training, validation, and test",
          "N-fold cross validation",
          "Early stopping"
        ],
        "Initialization": [
          "Initialization - Introduction",
          "Types of simple initializations",
          "Xavier initialization"
        ],
        "Gradient descent and learning rates": [
          "Stochastic gradient descent",
          "Gradient descent pitfalls",
          "Momentum",
          "Learning rate schedules",
          "Learning rate schedules. A picture",
          "Adaptive learning rate schedules",
          "Adaptive moment estimation"
        ]
      },
      "requirements": [
        "Some basic Python programming skills",
        "You’ll need to install Anaconda. We will show you how to do it in one of the first lectures of the course.",
        "All software and data used in the course are free."
      ],
      "description": "Data scientists, machine learning engineers, and AI researchers all have their own skillsets. But what is that one special thing they have in common?\nThey are all masters of deep learning.\nWe often hear about AI, or self-driving cars, or the ‘algorithmic magic’ at Google, Facebook, and Amazon. But it is not magic - it is deep learning. And more specifically, it is usually deep neural networks – the one algorithm to rule them all.\nCool, that sounds like a really important skill; how do I become a Master of Deep Learning?\nThere are two routes you can take:\nThe unguided route – This route will get you where you want to go, eventually, but expect to get lost a few times. If you are looking at this course you’ve maybe been there.\nThe 365 route – Consider our route as the guided tour. We will take you to all the places you need, using the paths only the most experienced tour guides know about. We have extra knowledge you won’t get from reading those information boards and we give you this knowledge in fun and easy-to-digest methods to make sure it really sticks.\nClearly, you can talk the talk, but can you walk the walk? – What exactly will I get out of this course that I can’t get anywhere else?\nGood question! We know how interesting Deep Learning is and we love it! However, we know that the goal here is career progression, that’s why our course is business focused and gives you real world practice on how to use Deep Learning to optimize business performance.\nWe don’t just scratch the surface either – It’s not called ‘Skin-Deep’ Learning after all. We fully explain the theory from the mathematics behind the algorithms to the state-of-the-art initialization methods, plus so much more.\nTheory is no good without putting it into practice, is it? That’s why we give you plenty of opportunities to put this theory to use. Implement cutting edge optimizations, get hands on with TensorFlow and even build your very own algorithm and put it through training!\nWow, that’s going to look great on your resume!\nSpeaking of resumes, you also get a certificate upon completion which employers can verify that you have successfully finished a prestigious 365 Careers course – and one of our best at that!\nNow, I can see you’re bragging a little, but I admit you have peaked my interest. What else does your course offer that will make my resume shine?\nTrust us, after this course you’ll be able to fill your resume with skills and have plenty left over to show off at the interview.\nOf course, you’ll get fully acquainted with Google’ TensorFlow and NumPy, two tools essential for creating and understanding Deep Learning algorithms.\nExplore layers, their building blocks and activations – sigmoid, tanh, ReLu, softmax, etc.\nUnderstand the backpropagation process, intuitively and mathematically.\nYou’ll be able to spot and prevent overfitting – one of the biggest issues in machine and deep learning\nGet to know the state-of-the-art initialization methods. Don’t know what initialization is? We explain that, too\nLearn how to build deep neural networks using real data, implemented by real companies in the real world. TEMPLATES included!\nAlso, I don’t know if we’ve mentioned this, but you will have created your very own Deep Learning Algorithm after only 1 hour of the course.\nIt’s this hands-on experience that will really make your resume stand out\nThis all sounds great, but I am a little overwhelmed, I’m afraid I may not have enough experience.\nWe admit, you will need at least a little understanding of Python programming but nothing to worry about. We start with the basics and take you step by step toward building your very first (or second, or third etc.) Deep Learning algorithm – we program everything in Python and explain each line of code.\nWe do this early on and it will give you the confidence to carry on to the more complex topics we cover.\nAll the sophisticated concepts we teach are explained intuitively. Our beautifully animated videos and step by step approach ensures the course is a fun and engaging experience for all levels.\nWe want everyone to get the most out of our course, and the best way to do that is to keep our students motivated. So, we worked hard to ensure that students with varying skills are challenged without being overwhelmed. Each lecture builds upon the last and practical exercises mean that you can practice what you’ve learned before moving on to the next step.\nAnd of course, we are available to answer any queries you have. In fact, we aim to answer any and all question within 1 business day. We don’t just chuck you in the pool then head to the bar and let you fend for yourself.\nRemember, we don’t just want you to enrol – we want you to complete the course and become a Master of Deep Learning.\nOK, awesome! I feel much better about my level of experience now, but we haven’t discussed yours! How do I know you can teach me to become a Master of Deep Learning?\nThat’s an understandable worry, but it’s one we have no problem removing.\nWe are 365 Careers and we’ve been creating online courses for ages. We have over 3,000,000 students and enjoy high ratings for all our Udemy courses. We are a team of experts who are all, at heart, teachers. We believe knowledge should be shared and not just through boring text books but in engaging and fun ways.\nWe are well aware how difficult it is to build your knowledge and skills in the data science field, it’s so new and has grown so fast that the education sector has struggled to keep up and offer any substantial methods of teaching these topic areas. We wanted to change things – to rock the boat – so we developed our unique teaching style, one that countless students have enjoyed and thrived with.\nAnd between us, we think this course is one of our favourites, so if this is your first time with us, you’re in for a treat. If it’s not and you’ve taken one of our courses before, then, you’re still in for a treat!\nI’ve been hurt before though, how can I be sure you won’t let me down?\nEasy, with Udemy’s 30-day money back guarantee. We strive for the best and believe that our courses are the best out there. But you know what, everyone is different, and we understand that. So, we have no problem offering this guarantee, we want students who will complete and get the most out of this course. If you are one of the few who finds this course not what you wanted or expected then, get your money back. No questions, no risk, no problem.\nGreat, that takes a load of my shoulders. What next?\nClick on the ‘Buy now’ button and take that first step toward a satisfying data science career and becoming a Master of Deep Learning.",
      "target_audience": [
        "Aspiring data scientists",
        "People interested in Machine Learning, Deep Learning, Business, and Artificial Intelligence,",
        "Anyone who wants to learn how to code and build machine and deep learning algorithms from scratch"
      ]
    },
    {
      "title": "40 Real World Data Science, Machine Learning Projects 2025",
      "url": "https://www.udemy.com/course/intro-to-machine-learning-course/",
      "bio": "Learn To Build & Deploy AI, ML, DS, Deep Learning, NLP Web Apps With Python Projects Course(Flask, Django, Heruko Cloud)",
      "objectives": [
        "Students Will Understand What Is Machine Learning",
        "Why They Need To Learn Machine Learning",
        "Difference Between Machine Learning, Deep Learning, Artificial Intelligence",
        "What Are The Applications Of Machine Learning"
      ],
      "course_content": {
        "Introduction To The Course": [
          "Introduction To The Course",
          "Introduction Course Outline",
          "Course Bonuses: Cheat Sheets, Downloads, Mind maps, Guides.",
          "Udemy Course Feedback"
        ],
        "Project-1 Pan Card Tempering Detector App (With Deployment)": [
          "Introduction to Pan Card Tempering Detector App",
          "Loading Libraries and Dataset",
          "Creating the Pancard Detector with Opencv",
          "Creating the Flask App",
          "Creating Important Functions",
          "Deploy the App in Heroku",
          "Testing the Deployed Pan Card Detector",
          "Download the project files"
        ],
        "Project-2 Dog breed prediction Flask App": [
          "Introduction",
          "Importing the data and Libraries",
          "Data Preprocessing",
          "Build and Train Model",
          "Testing the Model",
          "Creating the Flask App",
          "Running the App in System",
          "Download the project files"
        ],
        "Project-3 Image Watermarking App (With Deployment)": [
          "Introduction to Image Watermarking App",
          "Importing Libraries and Logo",
          "Create Text and Image Watermark",
          "Creating the App",
          "Deploying the App in Heroku",
          "Download the project files"
        ],
        "Project-4 Traffic sign classification": [
          "Introduction",
          "Importing the Data and Libraries",
          "Image Processing",
          "Creating and Testing the Model",
          "Creating Model for Test Set",
          "Download the project files"
        ],
        "Project-5 Text Extraction From Images App": [
          "Introduction to Text Extraction From Images App",
          "Importing Libraries and Data",
          "Extracting the Test from Image",
          "Modifying the Extractor",
          "Creating the Extractor App",
          "Running the Extractor App",
          "Download the project files"
        ],
        "Project-6 Plant Disease Prediction App (With Deployment)": [
          "Introduction",
          "Importing Libraries and Data",
          "Understanding the Data",
          "Model Building",
          "Creating an App Using Streamlit",
          "Download the project files"
        ],
        "Project-7 Counting & Detecting Vehicles Flask App": [
          "Introduction",
          "Importing Libraries",
          "Transforing Images and Creating Output",
          "Creating a Flask App",
          "Download the project files"
        ],
        "Project-8 Face Swapping Deep Learning Application": [
          "Introduction",
          "Importing Libraries and Data",
          "Data Preprocessing and Creating Output",
          "Creating a Flask Application",
          "Download the project files"
        ],
        "Project-9 Bird Species Prediction App": [
          "Introduction",
          "Importing Libraries and Data",
          "Data Processing",
          "Creating ML Model",
          "Creating A Flask App",
          "Download the project files"
        ]
      },
      "requirements": [
        "Enthusiasm To Learn New Things"
      ],
      "description": "Solve Business Problems Using Data Science Practically. Learn To Build & Deploy Artificial Intelligence, Machine Learning, Data Science , Auto Ml, Deep Learning, Natural Language Processing (NLP) Web Applications Projects With Python (Flask, Django, Heruko, Streamlit Cloud).\n\n\nHow much does a Data Scientist make in the United States?\nThe national average salary for a Data Scientist is US$1,20,718 per year in the United States, 2.8k salaries reported, updated on July 15, 2021 (source: glassdoor)\n\n\nSalaries by Company, Role, Average Base Salary in (USD)\nFacebook Data Scientist makes USD 1,36,000/yr. Analyzed from 1,014 salaries.\nAmazon Data Scientist makes USD 1,25,704/yr. Analyzed from 307 salaries.\nApple Data Scientist makes USD 1,53,885/yr. Analyzed from 147 salaries.\nGoogle Data Scientist makes USD 1,48,316/yr. Analyzed from 252 salaries.\nQuora, Inc. Data Scientist makes USD 1,22,875/yr. Analyzed from 509 salaries.\nOracle Data Scientist makes USD 1,48,396/yr. Analyzed from 458 salaries.\nIBM Data Scientist makes USD 1,32,662/yr. Analyzed from 388 salaries.\nMicrosoft Data Scientist makes USD 1,33,810/yr. Analyzed from 205 salaries.\nWalmart Data Scientist makes USD 1,08,937/yr. Analyzed 187 salaries.\nCisco Systems Data Scientist makes USD 1,57,228/yr. Analyzed from 184 salaries.\nUber Data Scientist makes USD 1,43,661/yr. Analyzed from 151 salaries.\nIntel Corporation Data Scientist makes USD 1,25,930/yr. Analyzed from 131 salaries.\nAirbnb Data Scientist makes USD 1,80,569/yr. Analyzed from 122 salaries.\nAdobe Data Scientist makes USD 1,39,074/yr. Analyzed from 109 salaries.\n\n\nIn This Course, We Are Going To Work On 40 Real World Projects Listed Below:\n\n\nProject-1 Pan Card Tempering Detector App (With Deployment)\nProject-2 Dog breed prediction Flask App\nProject-3 Image Watermarking App (With Deployment)\nProject-4 Traffic sign classification\nProject-5 Text Extraction From Images App\nProject-6 Plant Disease Prediction App (With Deployment)\nProject-7 Counting & Detecting Vehicles Flask App\nProject-8 Face Swapping Deep Learning Application\nProject-9 Bird Species Prediction App\nProject-10 Intel Image Classification App\n\n\nProject-11 Sentiment Analysis App (With Deployment)\nProject-12 Attrition Rate Django App\nProject-13 Pokemon Dataset App (With Deployment)\nProject-14 Face Detection App Streamlit\nProject-15 Cats Vs Dogs Classification App\nProject-16 Customer Revenue Prediction App (With Deployment)\nProject-17 Gender From Voice Prediction App\nProject-18 Restaurant Recommendation System\nProject-19 Happiness Ranking App\nProject-20 Forest Fire Prediction App\n\n\nProject-21 Black Friday Sale Prediction\nProject-22 Sentiment Analysis Using Natural Language Processing\nProject-23 Parkinson Syndrome Prediction\nProject-24  Fake News Classifier Using NLP\nProject-25 Toxic Comment Classifier Using NLP\nProject-26 Movie Ratings Prediction (IMDB) Using NLP\nProject-27 Air Quality Prediction\nProject-28 Covid-19 Case Analysis\nProject-29 Customer Churning Prediction\nProject-30 Building A Chatbot Application (NLP)\n\n\nProject-31: Video Game Sales Prediction App\nProject-32: Car Selling Price Prediction App- Deploy On Heruku\nProject-33: Affair Prediction App - Deploy On Heruku\nProject-34: Mushroom Classification App - Deploy On Heruku\nProject-35: Mobile App Rating Prediction Django App - Deploy On Heruku\nProject-36: Heart Attack Risk Prediction With Auto ML\nProject-37: Credit Card Fraud Detection using PyCaret\nProject-38: Flight Fare Detection using Auto SK Learn\nProject-39: Petrol Price Forecasting using Auto Keras\nProject-40: Bank Customer Churn Prediction using H2O Auto ML\n\n\nThe Only Course With 40 Real World Projects In Data Science Domain.\n\n\nNote (Read This): This Course Is Worth Of Your Time And Money, Enroll Now Before Offer Expires.",
      "target_audience": [
        "Machine Learning Enthusiasts"
      ]
    },
    {
      "title": "Apache Spark with Scala - Hands On with Big Data!",
      "url": "https://www.udemy.com/course/apache-spark-with-scala-hands-on-with-big-data/",
      "bio": "Apache Spark tutorial with 20+ hands-on examples of analyzing large data sets, on your desktop or on Hadoop with Scala!",
      "objectives": [
        "Develop distributed code using the Scala programming language",
        "Transform structured data using SparkSQL, DataSets, and DataFrames",
        "Frame big data analysis problems as Apache Spark scripts",
        "Optimize Spark jobs through partitioning, caching, and other techniques",
        "Build, deploy, and run Spark scripts on Hadoop clusters",
        "Process continual streams of data with Spark Streaming",
        "Traverse and analyze graph structures using GraphX",
        "Analyze massive data set with Machine Learning on Spark"
      ],
      "course_content": {
        "Getting Started": [
          "Udemy 101: Getting the Most From This Course",
          "Alternate download link for the ml-100k dataset",
          "WARNING: DO NOT INSTALL JAVA 21+ IN THE NEXT LECTURE",
          "Introduction, and installing the course materials, IntelliJ, and Scala",
          "Introduction to Apache Spark",
          "Spark Basics",
          "Important note"
        ],
        "Scala Crash Course [Optional]": [
          "[Activity] Scala Basics",
          "[Exercise] Flow Control in Scala",
          "[Exercise] Functions in Scala",
          "[Exercise] Data Structures in Scala"
        ],
        "Using Resilient Distributed Datasets (RDDs)": [
          "The Resilient Distributed Dataset",
          "Ratings Histogram Example",
          "Spark Internals",
          "Key / Value RDD's, and the Average Friends by Age example",
          "[Activity] Running the Average Friends by Age Example",
          "Filtering RDD's, and the Minimum Temperature by Location Example",
          "[Activity] Running the Minimum Temperature Example, and Modifying it for Maximum",
          "[Activity] Counting Word Occurrences using Flatmap()",
          "[Activity] Improving the Word Count Script with Regular Expressions",
          "[Activity] Sorting the Word Count Results",
          "[Exercise] Find the Total Amount Spent by Customer",
          "[Exercise] Check your Results, and Sort Them by Total Amount Spent",
          "Check Your Results and Implementation Against Mine",
          "Quiz: RDD's"
        ],
        "SparkSQL, DataFrames, and DataSets": [
          "Introduction to SparkSQL",
          "[Activity] Using SparkSQL",
          "[Activity] Using DataSets",
          "[Exercise] Implement the \"Friends by Age\" example using DataSets",
          "Exercise Solution: Friends by Age, with Datasets.",
          "[Activity] Word Count example, using Datasets",
          "[Activity] Revisiting the Minimum Temperature example, with Datasets",
          "[Exercise] Implement the \"Total Spent by Customer\" problem with Datasets",
          "Exercise Solution: Total Spent by Customer with Datasets",
          "Quiz: SparkSQL"
        ],
        "Advanced Examples of Spark Programs": [
          "[Activity] Find the Most Popular Movie",
          "[Activity] Use Broadcast Variables to Display Movie Names",
          "[Activity] Find the Most Popular Superhero in a Social Graph",
          "[Exercise] Find the Most Obscure Superheroes",
          "Exercise Solution: Find the Most Obscure Superheroes",
          "Superhero Degrees of Separation: Introducing Breadth-First Search",
          "Superhero Degrees of Separation: Accumulators, and Implementing BFS in Spark",
          "[Activity] Superhero Degrees of Separation: Review the code, and run it!",
          "Item-Based Collaborative Filtering in Spark, cache(), and persist()",
          "[Activity] Running the Similar Movies Script using Spark's Cluster Manager",
          "[Exercise] Improve the Quality of Similar Movies"
        ],
        "Running Spark on a Cluster": [
          "[Activity] Using spark-submit to run Spark driver scripts",
          "[Activity] Packaging driver scripts with SBT",
          "[Exercise] Package a Script with SBT and Run it Locally with spark-submit",
          "Exercise solution: Using SBT and spark-submit",
          "Introducing Amazon Elastic MapReduce",
          "Creating Similar Movies from One Million Ratings on EMR",
          "Partitioning",
          "Best Practices for Running on a Cluster",
          "Troubleshooting, and Managing Dependencies",
          "Quiz: Spark on a Cluster"
        ],
        "Machine Learning with Spark ML": [
          "Introducing MLLib",
          "[Activity] Using MLLib to Produce Movie Recommendations",
          "Linear Regression with MLLib",
          "[Activity] Running a Linear Regression with Spark",
          "[Exercise] Predict Real Estate Values with Decision Trees in Spark",
          "Exercise Solution: Predicting Real Estate with Decision Trees in Spark",
          "Quiz: Spark ML"
        ],
        "Intro to Spark Streaming": [
          "The Legacy DStream API for Spark Streaming",
          "[Activity] Real-time Monitoring of the Most Popular Hashtags on X/Twitter",
          "Structured Streaming",
          "[Activity] Using Structured Streaming for real-time log analysis",
          "[Exercise] Windowed Operations with Structured Streaming",
          "Exercise Solution: Top URL's in a 30-second Window",
          "Quiz: Spark Streaming"
        ],
        "Intro to GraphX": [
          "GraphX, Pregel, and Breadth-First-Search with Pregel.",
          "Using the Pregel API with Spark GraphX",
          "[Activity] Superhero Degrees of Separation using GraphX"
        ],
        "You Made It! Where to Go from Here.": [
          "Learning More, and Career Tips",
          "Bonus Lecture: More courses to explore!"
        ]
      },
      "requirements": [
        "Some prior programming or scripting experience is required. A crash course in Scala is included, but you need to know the fundamentals of programming in order to pick it up.",
        "You will need a desktop PC and an Internet connection. The course is created with Windows in mind, but users comfortable with MacOS or Linux can use the same tools.",
        "The software needed for this course is freely available, and I'll walk you through downloading and installing it."
      ],
      "description": "Completely updated and re-recorded for Spark 3, IntelliJ, Structured Streaming, and a stronger focus on the DataSet API.\n“Big data\" analysis is a hot and highly valuable skill – and this course will teach you the hottest technology in big data: Apache Spark. Employers including Amazon, EBay, NASA JPL, and Yahoo all use Spark to quickly extract meaning from massive data sets across a fault-tolerant Hadoop cluster. You'll learn those same techniques, using your own Windows system right at home. It's easier than you might think, and you'll be learning from an ex-engineer and senior manager from Amazon and IMDb.\nSpark works best when using the Scala programming language, and this course includes a crash-course in Scala to get you up to speed quickly. For those more familiar with Python however, a Python version of this class is also available: \"Taming Big Data with Apache Spark and Python - Hands On\".\nLearn and master the art of framing data analysis problems as Spark problems through over 20 hands-on examples, and then scale them up to run on cloud computing services in this course.\n\n\nLearn the concepts of Spark's Resilient Distributed Datasets, DataFrames, and Datasets.\nGet a crash course in the Scala programming language\nDevelop and run Spark jobs quickly using Scala, IntelliJ, and SBT\nTranslate complex analysis problems into iterative or multi-stage Spark scripts\nScale up to larger data sets using Amazon's Elastic MapReduce service\nUnderstand how Hadoop YARN distributes Spark across computing clusters\nPractice using other Spark technologies, like Spark SQL, DataFrames, DataSets, Spark Streaming, Machine Learning, and GraphX\nBy the end of this course, you'll be running code that analyzes gigabytes worth of information – in the cloud – in a matter of minutes.\nWe'll have some fun along the way. You'll get warmed up with some simple examples of using Spark to analyze movie ratings data and text in a book. Once you've got the basics under your belt, we'll move to some more complex and interesting tasks. We'll use a million movie ratings to find movies that are similar to each other, and you might even discover some new movies you might like in the process! We'll analyze a social graph of superheroes, and learn who the most “popular\" superhero is – and develop a system to find “degrees of separation\" between superheroes. Are all Marvel superheroes within a few degrees of being connected to SpiderMan? You'll find the answer.\nThis course is very hands-on; you'll spend most of your time following along with the instructor as we write, analyze, and run real code together – both on your own system, and in the cloud using Amazon's Elastic MapReduce service. over 8 hours of video content is included, with over 20 real examples of increasing complexity you can build, run and study yourself. Move through them at your own pace, on your own schedule. The course wraps up with an overview of other Spark-based technologies, including Spark SQL, Spark Streaming, and GraphX.\nEnroll now, and enjoy the course!\n\n\n\"I studied Spark for the first time using Frank's course \"Apache Spark with Scala - Hands On with Big Data!\". It was a great starting point for me,  gaining knowledge in Scala and most importantly practical examples of Spark applications. It gave me an understanding of all the relevant Spark core concepts,  RDDs, Dataframes & Datasets, Spark Streaming, AWS EMR. Within a few months of completion, I used the knowledge gained from the course to propose in my current company to  work primarily on Spark applications. Since then I have continued to work with Spark. I would highly recommend any of Franks courses as he simplifies concepts well and his teaching manner is easy to follow and continue with!  \" - Joey Faherty",
      "target_audience": [
        "Software engineers who want to expand their skills into the world of big data processing on a cluster",
        "If you have no previous programming or scripting experience, you'll want to take an introductory programming course first."
      ]
    },
    {
      "title": "Power BI Step 1: Visuals & Power Query",
      "url": "https://www.udemy.com/course/power-bi-mastery-for-beginners/",
      "bio": "Power BI Fundamentals: Learn by Doing",
      "objectives": [
        "كيفية تحميل وتثبيت Power BI Desktop واستخدام واجهته.",
        "استيراد البيانات من ملفات Excel ومصادر متعددة.",
        "تنظيف وترتيب البيانات باستخدام Power Query.",
        "تطبيقات عملية على بيانات حقيقية لفهم مفاهيم التحليل بشكل تطبيقي."
      ],
      "course_content": {},
      "requirements": [
        "لا يشترط وجود أي خبرة سابقة في Power BI أو تحليل البيانات. مهارات أساسية في استخدام الكمبيوتر (مثل النسخ واللصق، تصفح الملفات، وتثبيت البرامج). من المفيد أن تكون لديك خلفية بسيطة في Excel، ولكنها ليست شرطًا أساسيًا. جهاز كمبيوتر أو لابتوب يعمل بنظام Windows (برنامج Power BI Desktop لا يعمل على نظام Mac). اتصال إنترنت مستقر لتحميل Power BI والوصول إلى مواد الكورس. الحماس والرغبة في التعلم والتطبيق العملي على أمثلة واقعية."
      ],
      "description": "هل ترغب في تعلم تحليل البيانات وصناعة التقارير التفاعلية من البداية؟ هل سمعت عن Power BI وتودّ الدخول إلى هذا العالم بخطوات بسيطة وواضحة؟\nهذا الكورس صُمم خصيصًا لك!\nسواء كنت طالبًا، موظفًا، أو حتى رائد أعمال، ستتعلم في هذا الكورس المهارات الأساسية التي تحتاجها لتحويل البيانات إلى رؤى واضحة باستخدام Power BI – أحد أقوى أدوات تحليل البيانات في العالم.\nفي هذا الكورس، سنبدأ من الصفر دون الحاجة لأي خلفية سابقة في تحليل البيانات أو البرمجة. ستتعرف على واجهة Power BI، وكيفية استيراد البيانات من مصادر مختلفة، وتنظيفها باستخدام Power Query، ثم بناء علاقات بين الجداول، وإنشاء نماذج بيانات قوية.\nبعد ذلك، سننتقل إلى مرحلة تصميم التقارير التفاعلية وإنشاء لوحات معلومات (Dashboards) جذابة تساعد على فهم البيانات واتخاذ قرارات أفضل.\nسنتناول أيضًا أساسيات لغة DAX بطريقة مبسطة، مما يمكنك من إجراء حسابات مخصصة كالمجاميع التراكمية، المتوسطات، المقارنات، والمزيد.\nكل جزء في الكورس مدعوم بأمثلة عملية وتمارين تطبيقية حتى تتأكد من فهمك الكامل للخطوات.\nبنهاية الكورس، ستكون قادرًا على:\nاستيراد وتنظيف البيانات من مصادر متعددة.\nإنشاء علاقات وربط الجداول.\nبناء تقارير ولوحات معلومات احترافية.\nاستخدام بعض صيغ DAX الأساسية لإجراء تحليلات متقدمة.\nابدأ رحلتك الآن في عالم تحليل البيانات، وافتح لنفسك أبواب فرص جديدة في سوق العمل بتعلم أداةمن أهم أدوات محللين البيانات",
      "target_audience": [
        "لأي شخص يرغب في دخول عالم تحليل البيانات من البداية. الموظفين في المجالات الإدارية أو المالية أو التسويقية الذين يرغبون في تحسين قدراتهم في تحليل البيانات واتخاذ قرارات مبنية على المعلومات. حديثي التخرج أو الطلاب الذين يسعون لاكتساب مهارة قوية مطلوبة في سوق العمل. رواد الأعمال وأصحاب المشاريع الذين يريدون فهم بياناتهم واتخاذ قرارات مدروسة. أي شخص مهتم بتعلم Power BI بطريقة عملية وسهلة دون الحاجة إلى خبرة سابقة في البرمجة أو تحليل البيانات."
      ]
    },
    {
      "title": "Kunstmatige intelligentie (AI) en machine learning",
      "url": "https://www.udemy.com/course/kunstmatige-intelligentie-ai-en-machine-learning/",
      "bio": "Waar gaat dat eigenlijk over?",
      "objectives": [
        "De basisprincipes van AI en machine learning, inclusief definities, typen en toepassingen",
        "De soorten machine learning-algoritmen, waaronder gesuperviseerd, ongecontroleerd en versterkend leren",
        "De ethische overwegingen rond het gebruik van AI en machine learning, inclusief vooringenomenheid, privacy en veiligheid",
        "De potentiële sociale en economische gevolgen van AI en machine learning bij het vormgeven van de toekomst van werk."
      ],
      "course_content": {},
      "requirements": [
        "Geen ervaring vereist."
      ],
      "description": "Een beginnerscursus voor iedereen die geïnteresseerd is in AI en machine learing. Twee zaken waar iedereen al mee te maken heeft, maar waarvan de invloed op ons leven de komende jaar nog vele malen groter gaat worden. Deze korte cursus zorgt ervoor dat je basis van AI en machine learning begrijpt en dat je mee kunt praten en denken als er gesprekken over worden gevoerd of beslissingen moeten worden genomen, zowel beroepsmatig als privé. Je leert de belangrijkste definities van AI en machine learning, maar ook wat algoritmen zijn en hoe ze werken. Met opdrachten leer je zelf ook ervaren hoe de diverse algoritmen werken. We kijken ook naar de ethische kant van AI en machine learning en de vragen waar we als maatschappij voor gesteld zullen worden en waar we met elkaar een antwoord op moeten gaan vinden. Je leert over de voordelen en de risico's van AI en machine learning en tenslotte krijg je een beeld van de belangrijkste ontwikkelingen op het gebied van AI en machine learning die de komende jaren worden verwacht. Iedere les sluit af met een aantal vragen die je een indruk geven of je de behandelde theorie hebt begrepen. De laatste opgave is een case waarin de theorie uit de cursus integraal naar voren komt.",
      "target_audience": [
        "Voor iedereen die weinig tot geen kennis heeft van Artificial Intelligence en machine learning en een algemene interesse heeft in deze technologie, datawetenschap of machine learning en hier meer van wil weten."
      ]
    },
    {
      "title": "Gerando Arquivos PDF com Python e ReportLab",
      "url": "https://www.udemy.com/course/gerando-arquivos-pdf-com-python-e-reportlab/",
      "bio": "Gerar dinamicamente arquivos PDF usando Python e ReportLab",
      "objectives": [
        "Gerar um arquivo PDF utilizando Python e ReportLab",
        "Conceitos básicos de ReportLab",
        "Registar uma nova fonte TTF",
        "Inserir imagens no arquivo PDF"
      ],
      "course_content": {
        "Introduction": [
          "Olá Mundo em ReportLab",
          "Rodar elementos no canvas",
          "Adicionar nova página ao documento",
          "Criar uma tabela simples no documento",
          "Criar um gráfico do tipo Donut",
          "Proteger o arquivo com uma palavra passe"
        ]
      },
      "requirements": [
        "Vontade de aprender!",
        "Conhecimentos base da linguagem Python 3"
      ],
      "description": "Este curso é uma introdução muito básica de como gerar arquivos PDF com Python e ReportLab.\nReportLab é um módulo de Python muito poderoso que permite gerar dinamicamente arquivos PDF, sendo usado por empresas/companhias como a Wikipédia, HP, NASA, TRUECar, entre outras.\nExistem duas versões de ReportLab:\nA versão paga que é muito cara e inacessível para muitos de nós;\nA versão gratuita (que iremos ver neste curso) que tem uma documentação muita fraca e é muito difícil encontrar informações na internet de como usar ReportLab.\nEste é o resultado da experiência que tive ao criar arquivos PDF para clientes meus bem como videos que fiz para o YouTube. Espero assim ajudar na iniciação com ReportLab :)\nEste curso é só uma introdução ao ReportLab, se gostar e quiser saber mais veja também o curso mais avançado \"Python ReportLab de Iniciante a Vencedor\".\n\n\nAqui você irá aprender:\nComo salvar um arquivo PDF em ReportLab;\nAdicionar um título ao documento;\nAdicionar uma fonte TTF;\nCriar o efeito sombra em texto;\nMudar a cor do texto;\nAdicionar uma linha, alterar sua espessura e cor;\nAdicionar um parágrafo;\nInserir uma imagem e redimensiona-la;\nAdicionar um hyperlink a uma imagem;\nDesenhar um rectangulo.\nVocê também pode ver o meu canal de YouTube (ver no meu perfil) onde ensino vários tópicos em Python, C#, Java, JavaScript, entre outras, e também os meus outros cursos aqui na Udemy :)\n\n\nEspero que goste do meu trabalho, não se esqueça de avaliar o curso e boa aprendizagem! :)",
      "target_audience": [
        "Pessoas que precisam de gerar arquivos PDF dinamicamente",
        "Desenvolvedores Python",
        "Analístas de dados",
        "Data Scientists"
      ]
    },
    {
      "title": "Базовый Python",
      "url": "https://www.udemy.com/course/ittensive-python-basic/",
      "bio": "Изучите с нуля самый востребованный язык программирования",
      "objectives": [
        "Основы работы с Python",
        "Jupyter Notebook",
        "Переменные, типы и базовые операции",
        "Циклы for и while, управляющие конструкции",
        "Срезы и диапазоны строк",
        "Одномерные и многомерные списки",
        "Базовые статистические методы",
        "Словари, кортежи и отображения",
        "Работа с файлами",
        "Модули numpy и matplotlib"
      ],
      "course_content": {},
      "requirements": [
        "Основы программирования"
      ],
      "description": "На этом курсе вы освоите программирование на языке Python и научитесь работать с данными для самостоятельно анализа. В курсе изучаются ввод и вывод данных, арифметические операции, циклы, работа со строками и массивами, функции и словари, модули для визуализации и анализа данных.\nВ курс входит 62 отдельных урока, 14 практикумов, 8 самостоятельных работ для закрепления материала и 35 задач-тренажеров. Вы сможете самостоятельно натренировать свои навыки программирования на Python.\nВашим курсовым проектом будет анализ выбранного массива данных.\n(C) Course Icon by Flat Icons",
      "target_audience": [
        "Интересующиеся программированием и анализом данных",
        "Программисты, изучающие Python с нуля",
        "Аналитики данных",
        "Программисты начального уровня, кто ищет тренировки на реальных задачах"
      ]
    },
    {
      "title": "Python per Data Analyst e Data Scientist",
      "url": "https://www.udemy.com/course/python-analisi-dati-e-machine-learning/",
      "bio": "Impara l'Analisi dei dati e il Machine Learning su Python studiando librerie come Pandas, Seaborn e Scikit-Learn",
      "objectives": [
        "Utilizzare Pandas per importare dati da varie tipologie di file (csv, excel, json, file di testo strutturati)",
        "Conoscere le principali strutture della programmazione in Python",
        "Filtrare, pulire, trasformare, aggregare e combinare i dati di un DataFrame con Pandas",
        "Effettuare il pre-processing dei dati propedeutico al Machine Learning",
        "Implementare da zero algoritmi di Machine Learning con l'ausilio della programmazione a oggetti",
        "Condurre un'analisi esplorativa dei dati corredata da opportune rappresentazioni grafiche",
        "Utilizzare scikit-learn per creare modelli efficienti di classificazione, regressione, clusterizzazione",
        "Utilizzare pipeline, tecniche di tuning dei parametri e di convalida incrociata per valutare i modelli",
        "Rappresentare dati geografici e mappe con folium",
        "Connettere Python a database relazionali e non relazionali"
      ],
      "course_content": {
        "Installiamo Python e Jupyter": [
          "Installazione e primo accesso a Jupyter"
        ],
        "Import dei dati da file con Python e Pandas": [
          "Import di file CSV",
          "Caratteristiche dei DataFrame",
          "Import di file Excel",
          "Import di file JSON",
          "Importiamo un nuovo file CSV più complesso",
          "Approfondimento: import da file strutturato"
        ],
        "Fondamenti di Python: tipi di dati, funzioni e controllo del flusso": [
          "Miglioriamo il codice della sezione precedente",
          "Configuriamo i parametri di input e output di una funzione",
          "Approfondimento su for e liste",
          "Istruzione IF in Python",
          "Funzione input, while e booleani",
          "Esercizio su funzioni, while e if",
          "Condizioni più complesse e f-string",
          "Break e continue",
          "Tipo set e gestione degli errori con try except",
          "Esercizio con gli insiemi",
          "Import di file Excel con più fogli e dizionari",
          "Analogie e differenze tra tuple e liste"
        ],
        "Analisi dei dati con Pandas": [
          "Import dei dati e presentazione del capitolo",
          "Filtrare i dati - parte 1",
          "Filtrare i dati - parte 2",
          "Aggiornamento: filtrare i dati con il metodo query",
          "Aggregare i dati - metodo groupby - parte 1",
          "Aggregare i dati - metodo groupby - parte 2",
          "Combinare i dati - metodo merge",
          "Combinare i dati - metodo concat",
          "Ordinare i dati e modificare la struttura di un DataFrame",
          "Modificare e trasformare i dati in un DataFrame",
          "Approfondimento: Pivot e unpivot dei dati",
          "Visualizzare i dati senza duplicati",
          "Approfondimento: Conversione di stringhe in liste e metodo explode"
        ],
        "Esercitazione sul Pre-processing": [
          "Esercitazione: pre-processing dei dati",
          "Soluzione pt. 1: import del file Iris",
          "Soluzione pt. 2: filtrare e ordinare i dati",
          "Soluzione pt. 3: gestire i null - parte 1",
          "Soluzione pt. 4: gestire i null - parte 2",
          "Soluzione pt. 5: gestione variabile target e suddivisione in training e test",
          "Soluzione pt. 6: valorizzazione null",
          "Soluzione pt.7 : normalizzazione dati",
          "Soluzione pt.8: aggiunta colonna e conversione dati in array di numpy"
        ],
        "Python, Database e API": [
          "Introduzione al capitolo",
          "Connessione Python e SQL Server - parte 1",
          "Connessione Python e SQL Server - parte 2",
          "Connessione Python e MongoDB",
          "API con Python - la libreria requests",
          "Un esempio di libreria per chiamare un'API specifica"
        ],
        "Machine Learning e programmazione a oggetti": [
          "Implementazione del Perceptron - parte 1",
          "Implementazione del Perceptron - parte 2",
          "Perceptron e programmazione a oggetti - parte 1",
          "Perceptron e programmazione a oggetti - parte 2",
          "Perceptron e programmazione a oggetti - parte 3",
          "Preprocessing con Scikit-Learn",
          "Algoritmi di classificazione supervisionata con Scikit-Learn",
          "Implementazione K-neighbours - parte 1",
          "Implementazione K-neighbours - parte 2"
        ],
        "Seaborn e Scikit-learn per il Machine Learning": [
          "Analisi esplorativa dei dati - calcolo dei principali indici statistici",
          "Analisi esplorativa - rappresentazioni grafiche con Seaborn",
          "Machine Learning sul dataset Titanic - studio delle variabili",
          "Machine Learning sul dataset Titanic - encoding e normalizzazione",
          "Creazione di Pipeline e convalida k-fold",
          "Ottimizzazione dei parametri",
          "Matrice di confusione",
          "Presentiamo il nostro lavoro!"
        ],
        "Algoritmi di Regressione, analisi di serie storiche e clustering": [
          "Introduzione alla regressione e prime analisi del dataset Diamonds",
          "Pre-processing del dataset Diamonds",
          "Applicazione di algoritmi di regressione lineare",
          "K-n Regressor e analisi dei residui",
          "Analisi delle serie storiche - import dei dati e controlli di qualità",
          "Analisi delle serie storiche - medie mobili e stagionalità",
          "Analisi delle serie storiche - regressione e previsioni finali",
          "Clustering",
          "Dati geografici con folium"
        ],
        "Football Analysis": [
          "Acquisizione del file e prime analisi preliminari",
          "Gestione dei ruoli e scelta delle colonne",
          "Primi risultati sui dati",
          "Analisi su campionati e ruoli",
          "Quiz finale",
          "Congratulazioni finali e anteprima gratuita della Scuola dei Dati"
        ]
      },
      "requirements": [
        "Nessuno in particolare, nel corso il software è installato sul sistema operativo Windows"
      ],
      "description": "L'obiettivo di questo corsi è fornirti uno degli strumenti più potenti e versatili per analizzare i dati: il linguaggio Python unito con alcune tra le sue importanti librerie come Pandas, Scikit-learn e Seaborn.\n\n\nCon il termine \"Analizzare i dati\" non mi riferisco soltanto alla creazione di grafici o a tecniche di Data Visualization, temi comunque importanti e oggetto di alcune lezioni. In questo corso vedremo anche e soprattutto come usare Python nell'intero processo di trasformazione dei dati in informazioni, che prevede:\n- l'acquisizione dei dati da file di formato differente;\n- la gestione dei tipi e dei dati mancanti;\n- le operazioni di trasformazione, pulizia e decodifica dei dati;\n- il preprocessing dei dati per il Machine Learning;\n- l'implementazione in Python dell'algoritmo di Machine Learning del Perceptron tramite la programmazione a oggetti;\n- l'analisi esplorativa e la rappresentazione grafica dei dati tramite la libreria seaborn;\n- l'utilizzo della libreria scikit-learn per creare modelli di classificazione supervisionata di Machine Learning;\n- le attività di tuning dei parametri, convalida dei risultati e selezione dei modelli;\n- l'esecuzione di algoritmi di regressione per predire variabili quantitative, l'analisi delle serie storiche e il clustering per raggruppare gli individui simili.\n\n\nIl corso si rivolge dunque a chiunque voglia fare un importante upgrade delle proprie skill di analisi dei dati tramite l'apprendimento di quello che è tra i linguaggi di programmazione in più rapida diffusione e richiesti dal mercato nel 2023. È perfetto ad esempio se sei uno sviluppatore SQL e vuoi allargare le tue skill tecniche da Data Analyst alla programmazione in Python o al Machine Learning. Discorso simile se al momento utilizzi Excel e vuoi superare i suoi limiti o approfondire tecniche più elaborate di analisi dei dati.\n\n\nComunque, anche se una conoscenza del settore è sicuramente d'aiuto, nelle lezioni partiremo da zero quindi anche se non hai esperienza ma hai tanta voglia di imparare potrai approcciarti per la prima volta alla programmazione tramite questo corso al 100% pratico.\n\n\nNOVITÀ! Ho aggiunto una lezione per mostrare un esempio di presentazione che espone le skill più importanti acquisite durante il corso, così potrai iniziare a creare un Portfolio di Analisi dei dati e allegare il documento ottenuto al tuo curriculum e al tuo profilo di LinkedIn e Github! Ho inserito infine un quiz finale con il quale potrai ripassare e verificare le competenze acquisite.\n\n\nI pochi minuti relativi all'installazione e l'avvio di Python e Jupyter sono relativi a un PC con sistema operativo Windows, non è mostrato come eseguire queste attività su macOS (il processo è comunque molto simile ed è facilissimo trovare in rete materiale a riguardo). Ovviamente vale sempre la raccomandazione di utilizzare un proprio PC personale (non aziendale) per installare questo e qualsiasi altro software.\n\n\nLe videolezioni sono corredate anche dai file contenenti gli script e gli esercizi visti durante le spiegazioni. Nel complesso, si tratta a tutti gli effetti di un manuale aggiuntivo di Python, Pandas e Machine Learning. Inoltre sarò sempre disponibile a rispondere a dubbi e domande sul materiale del corso, che potrai porre tramite i messaggi di Udemy o l'apposita sezione di Domande & Risposte.",
      "target_audience": [
        "Sviluppatori che vogliono acquisire competenze avanzate in Python per l'analisi dei dati e il Machine Learning.",
        "Data Analyst e professionisti del settore che desiderano ampliare le loro capacità tecniche e implementare approcci più sofisticati nell'analisi dei dati.",
        "Aspiranti Data Scientist che cercano di sviluppare una solida base di conoscenza e competenze nel campo dell'analisi dei dati e del Machine Learning.",
        "Professionisti che utilizzano strumenti come Excel e vogliono superare i limiti e sfruttare il potenziale del linguaggio Python per l'analisi dei dati."
      ]
    },
    {
      "title": "智能体-Agent实战(大模型落地实战)",
      "url": "https://www.udemy.com/course/agent-as/",
      "bio": "Agent实战",
      "objectives": [
        "熟练掌握Agent架构原理与应用实例",
        "熟悉Agent开发框架及其落地流程",
        "掌握当下主流智能体框架开发流程",
        "熟练部署自己的智能体到业务场景"
      ],
      "course_content": {
        "Agent架构解读与应用分析": [
          "1-Agent要解决的问题分析",
          "2-Agent需要具备的基本能力",
          "3-与大模型的关系与多角色交互",
          "4-框架的作用和能解决的问题",
          "5-整体总结分析",
          "6-GPTS分析一波",
          "7-经典任务分析",
          "资料下载(谷歌网盘)"
        ],
        "GPTS打造Agent实战": [
          "1-GPTS任务流程概述分析",
          "2-调用API的控制方式",
          "3-API相关配置完成",
          "4-完成指令与脚本并生成"
        ],
        "打造自己领域专属客服": [
          "1-DEMO演示与整体架构分析",
          "2-后端GPT项目部署启动",
          "3-前端助手API与流程图配置",
          "4-接入外部API的方法与流程",
          "5-引入API方法解读",
          "6-指令提示构建"
        ],
        "autogen框架实战": [
          "0-Python环境说明",
          "1-AutoGenStudio框架安装与介绍",
          "2-动作API配置方法",
          "3-国内常用API配置方法",
          "4-API接口在线测试",
          "5-工作流配置",
          "6-执行流程与结果"
        ],
        "部署与进阶应用实战": [
          "1-API生成方法",
          "2-GroupChat模块",
          "3-执行流程分析",
          "4-外接本地支持库配置方法",
          "5-加入RAG技能",
          "6-LMStudio本地下载部署模型",
          "7-调用本地模型方法与配置",
          "8-AutogenStudio本地化部署流程",
          "9-本地化部署接入应用实例",
          "10-Autogen调用SD完成设计",
          "11-Ollama环境配置与安装",
          "12-autogen接入本地模型"
        ],
        "metaGpt框架解读": [
          "1-论文概述分析",
          "2-整体框架逻辑介绍",
          "3-项目环境配置",
          "4-基础解读-动作定义方式",
          "5-基础解读-角色定义",
          "6-单动作智能体实现方法",
          "7-多动作配置方法",
          "8-定时器任务环境配置",
          "9-定时器任务流程解读分析"
        ],
        "metaGpt应用实战": [
          "0-基本Agent的组成",
          "1-Agent要完成的任务和业务逻辑定义",
          "2-问题拆解与执行流程",
          "3-检索得到重要的URL",
          "4-子问题生成总结结果",
          "5-总结与结果输出"
        ],
        "RAG检索架构分析与应用": [
          "1-RAG要完成的任务解读",
          "2-RAG整体流程解读",
          "3-召回优化策略分析",
          "4-召回改进方案解读",
          "5-评估工具RAGAS",
          "6-外接本地数据库工具"
        ],
        "斯坦福AI小镇架构与项目解读": [
          "1-整体故事解读",
          "2-要解决的问题和整体框架分析",
          "3-论文基本框架分析",
          "4-Agent的记忆信息",
          "5-感知与反思模块构建流程",
          "6-计划模块实现细节",
          "7-整体流程框架图",
          "8-感知模块解读",
          "9-思考模块解读",
          "10-项目环境配置方法解读"
        ],
        "langchain工具实例": [
          "1-langchain框架解读",
          "2-基本API调用方法",
          "3-数据文档切分操作",
          "4-样本索引与向量构建",
          "5-数据切块方法"
        ]
      },
      "requirements": [
        "熟悉基本大模型知识点即可"
      ],
      "description": "AI最火Agent系列从零开始手把手演示如何利用Agent构建各种场景应用，通俗解读其所需知识点，基于现有GPT大模型进行应用实战，将自己业务场景的经验总结成标准化的Agent执行流程，集成外部各种API工具来打造你的专属代理。\n1.每个人的人工智能=自己的需求+业务场景+工具使用+标准化流程\n2.课程教大家集成：以大模型为大脑让它根据流程来使用各种工具\n3.可以任意DIY，结合自己的需求，场景，流程，做自己的Ai产品\n4.提供全部案例模板，先把流程跑通，再去替换完成自己的任务\n5.不会过时的技术，工具软件会被替换，Agent可以随意配技能",
      "target_audience": [
        "对AI方向感兴趣准备落地的同学们"
      ]
    },
    {
      "title": "데이터사이언스 훈련소 - 웹크롤링을 활용한 분석실습",
      "url": "https://www.udemy.com/course/crawling/",
      "bio": "웹크롤링과 데이터 전처리 실습을 한 번에 배우는 데이터사이언스 강의",
      "objectives": [
        "데이터 종류에 따른 수집 방법 및 데이터의 중요성을 알 수 있다.",
        "인터넷 검색을 하면서 필요한 정보를 코딩을 통하여 쉽고 빠르게 수집할 수 있다.",
        "데이터 변환 및 축소 등에 대한 데이터 전처리를 할 수 있다.",
        "데이터 전처리 과정을 자동화 및 지능화해주는 도구인 SSDP에 대해 이해 할 수 있다."
      ],
      "course_content": {
        "강의 소개": [
          "01. OT_데이터 크롤링"
        ],
        "데이터 수집": [
          "02. 데이터 형태에 따른 수집",
          "03. 데이터 수집 방법의 종류"
        ],
        "데이터 종류별 연동 방법": [
          "04. 데이터 종류별 연동 방법",
          "05. HTTP 수집",
          "06. 로그-센서 수집",
          "07. DBMS 수집",
          "08. FTP 수집"
        ],
        "데이터 크롤링 실습": [
          "09. 데이터 크롤링 실습_Python selenium 소개",
          "10. Selenium 실습_beautifulsoup"
        ],
        "데이터 퀄리티 기준 전처리": [
          "11. OT_데이터 퀄리티 기준 전처리",
          "12. 데이터 분석의 절차",
          "13. 데이터 분석 모델"
        ],
        "데이터 품질": [
          "14. 데이터 품질",
          "15. 데이터 품질 진단 프로세스",
          "16. 좋은 데이터의 특성"
        ],
        "데이터 전처리 소개": [
          "17. 데이터 전처리란",
          "18. 데이터 전처리 절차",
          "19. SSDP",
          "20. 이상값 사례"
        ],
        "데이터 전처리 방법": [
          "21. 데이터 전처리 방법",
          "22. 데이터 전처리 방법_데이터 변환",
          "23. 데이터 전처리 방법_데이터 축소",
          "24. 데이터 전처리 방법_DataFrame 그룹 생성"
        ],
        "데이터 전처리 실습": [
          "25. 데이터 전처리 실습 1",
          "26. 데이터 전처리 실습 2",
          "27. 데이터 전처리 실습 3",
          "28. 데이터 전처리 실습 4"
        ]
      },
      "requirements": [
        "파이썬 기초 과정(친절한 파이썬 스쿨 - 입학하기)에 대한 선수 학습이 필요합니다.",
        "구글 코랩을 이용하기 때문에 컴퓨터 사양에 대한 제약은 없습니다."
      ],
      "description": "웹 상에 존재하는 데이터를 빠르고 효과적으로 수집하고 싶으신가요?\nPython Selenium을 통한 데이터 크롤링과 데이터 전처리 방법을 실습을 통해 직접 알려드립니다!\n본 과정은 중급자 대상 강의로, 기초 지식을 함양해야만 합니다.\n\n\n\n\n◾ 데이터를 수집하는 방법의 종류를 정리하여 데이터 크롤링을 학습할 수 있습니다.\n\n\n데이터의 형태에 따른 수집에 대해서 정리할 수 있다.\n데이터의 종류에 따른 연동 방법에 대해서 학습할 수 있다.\nPython Selenium으로 데이터 크롤링을 학습할 수 있다.\n\n\n◾ 좋은 데이터의 특징을 정리하여 데이터 전처리의 절차를 학습할 수 있습니다.\n\n\n데이터 분석의 절차 6단계를 정리할 수 있다.\n데이터 품질 진단 프로세스를 이해할 수 있다.\n좋은 데이터의 4가지 특성에 대해서 정리할 수 있다.\n데이터 전처리 도구인 SSDP에 대해서 학습할 수 있다.\n불필요한 데이터 제거, 결측치 처리, 데이터 전체적인 구조 파악 등에 대한 전처리 방법을 알 수 있습니다.\n불필요한 데이터 제거, 결측치 처리, 데이터 전체적인 구조 파악 등에 대한 전처리 실습을 진행해볼 수 있습니다.",
      "target_audience": [
        "파이썬 기초를 학습하신 분",
        "웹 상에 존재하는 데이터를 쉽고 빠르게 수집하고자 하는 분"
      ]
    },
    {
      "title": "Машинное обучение: регрессия и предсказание данных на Python",
      "url": "https://www.udemy.com/course/ittensive-python-machine-learning-linear-regression/",
      "bio": "Выигрываем соревнование на Kaggle по предсказанию данных с ансамблем линейной регрессии",
      "objectives": [
        "Процесс ETL: загрузка, очистка, объединение данных",
        "Построение и оценка качества модели линейной регрессии",
        "EDA: исследовательский анализ данных",
        "Обогащение данных для извлечения смысла",
        "Оптимизация потребления памяти набором данных",
        "Иерархия моделей линейной регрессии",
        "Ансамбль моделей линейной регрессии",
        "Экспорт и импорт данных в CSV и HDF5",
        "Участие в соревнование Kaggle"
      ],
      "course_content": {
        "Часть 1. Процесс машинного обучения": [
          "Задачи машинного обучения",
          "Задачи машинного обучения",
          "Модель и процесс машинного обучения",
          "Что такое ETL",
          "Процесс машинного обучения",
          "Что такое EDA",
          "Подготовка данных",
          "Подготовка данных",
          "Разбиение выборки",
          "Оптимизация гиперпараметров",
          "Латинский квадрат (гиперкуб)",
          "Оптимизация гиперпараметров через Парзеновские деревья",
          "Недообучение и переобучение",
          "Смещение, разброс и ошибка данных",
          "Обучение модели",
          "Использование HDF"
        ],
        "Линейные модели": [
          "Метод максимального правдоподобия",
          "Метод наименьших квадратов",
          "Метод наименьших квадратов",
          "Аппроксимация пропусков в данных",
          "Аппроксимация данных",
          "Среднеквадратичная ошибка",
          "Метрики и расстояния",
          "Метрики и расстояния"
        ],
        "Часть 2. Практикум: Предсказание энергопотребления зданий": [
          "Процесс ETL",
          "Интерполяция и экстраполяция",
          "Оценка модели",
          "Линейная регрессия",
          "Линейная регрессия по часам"
        ],
        "Практикум: Оптимизация памяти и обогащение данных": [
          "Оптимизация потребления памяти",
          "EDA: исследование зависимостей",
          "Заполнение пропусков в данных",
          "Параметрическая модель энергопотребления"
        ],
        "Модели линейной регрессии": [
          "Линейная регрессия и L1/L2-регуляризация",
          "Изотоническая регрессия",
          "Линейная регрессия",
          "BIC и AIC",
          "Полиномиальная регрессия",
          "Линеаризация регрессии",
          "Нелинейная регрессия"
        ],
        "Практикум: Конкурентные модели регрессии": [
          "Обогащение данных",
          "Иерархия моделей",
          "Оптимизация регрессии",
          "Конкурентные модели регрессии"
        ],
        "Ансамбли машинного обучения": [
          "Ансамблевые модели",
          "Ансамбль стекинга"
        ],
        "Практикум: Ансамбль линейной регрессии": [
          "Экспорт и импорт данных",
          "Ансамбль регрессионных моделей",
          "Расчет результатов",
          "Рассчитать данные по энергопотреблению"
        ]
      },
      "requirements": [
        "Продвинутый Python",
        "Основы математической статистики"
      ],
      "description": "Мы рассмотрим все теоретические и практические аспекты применения линейной регрессии для предсказания числовых показателей энергопотребления ASHRAE в соревновании на Kaggle вплоть до формирования конечного результата.\nКурс разбит на 2 части. В первой части мы последовательно пройдем все этапы работы с данными: от видов задач и их постановки до работы с моделями машинного обучения для минимизации предсказательной ошибки. Дополнительно рассмотрим фундаментальные основы построения моделей машинного обучения, базовые метрики и наиболее простые модели - линейную, полиномиальную и линеаризуемую регрессии.\nВо второй части разберем на практикуме:\nОсобенности процесса анализа данных (ETL): загрузка, очистка, объединение наборов данных с pandas.\nПроведение исследовательского анализа данных для поиска зависимостей: EDA.\nИспользование sklearn для линейной регрессии.\nИнтерполяция и экстраполяция данных.\nРасчет метрики качества RMSLE для моделей линейной регрессии.\nОптимизация линейной регрессии: выбор наилучших параметров и гиперпараметров.\nОптимизация потребления памяти при работе с большими данными.\nЗапасные модели линейной регрессии.\nАнсамбли линейной регрессии для уточнения предсказания.\nЭкспорт и импорт данных, включая промежуточные.\nВыгрузка результата для соревнования на Kaggle.",
      "target_audience": [
        "Аналитики Python, изучающие машинное обучение",
        "Программисты больших данных",
        "Исследователи больших данных"
      ]
    },
    {
      "title": "Machine Learning + Data Science en R",
      "url": "https://www.udemy.com/course/machine-learning-data-science-r/",
      "bio": "Realizaremos un proyecto real de Ciencia de Datos-Machine Learning para que puedas generar los conocimientos mas solidos",
      "objectives": [
        "Domina el poder del análisis predictivo: Descubre cómo predecir tendencias y comportamientos futuros utilizando técnicas avanzadas de Machine Learning en R",
        "Conviértete en un mago de los datos: Aprende a transformar información caótica en conocimiento valioso a través de la manipulación de datos con R",
        "Desarrolla algoritmos de aprendizaje automático con R para resolver problemas del mundo real, desde clasificación hasta recomendación y mucho más",
        "Genera un proyecto real para aplicar todo el conocimiento"
      ],
      "course_content": {
        "¡Bienvenida!": [
          "Un saludo de tu profe",
          "Ruta del Conocimiento"
        ],
        "Conceptos básicos": [
          "Entrando al mundo de Analytics & Science",
          "Pasos del proyecto",
          "Al que repasa Dios le ayuda"
        ],
        "Herramientas": [
          "¿Qué debemos saber para el éxito en data?",
          "Instalemos R Studio",
          "Mi nuevo entorno familiar: R Studio"
        ],
        "Definiendo los objetivos de negocio": [
          "Objetivos de Negocio + Objetivos de Data"
        ],
        "Librerías": [
          "¿Cómo entender las librerías?",
          "Librarías para lectura de data",
          "Librerías para estructuras de datos y Visuales",
          "Librerías para Análisis y ML",
          "Activando Librerías en R"
        ],
        "Dónde obtener Data Sets": [
          "Navegando en buscadores de data"
        ],
        "Carga de datos": [
          "Alistando archivos",
          "Cargando Data Sets - Abejas",
          "Cargando Data Sets - Cafe",
          "Al que repasa Dios le ayuda"
        ],
        "Entiendo los datos": [
          "Primer acercamiento a nuestros Data Frames",
          "Supuestos",
          "Navegación gráfica I",
          "Navegación gráfica II - Abejas",
          "Navegación gráfica II - Cafe"
        ],
        "Preparación de los datos": [
          "Preparación de Data Frames finales",
          "Nulos y Duplicados",
          "Atípicos y Balanceo",
          "Preparación Café/Pupa",
          "Al que repasa Dios le ayuda"
        ],
        "EDA": [
          "EDA I - Abejas",
          "EDA II - Abejas",
          "EDA I - Cafe",
          "EDA II - Cafe",
          "EDA Pupa"
        ]
      },
      "requirements": [
        "Muchas ganas y atención plena"
      ],
      "description": "¡Bienvenido al apasionante mundo de la Ciencia de Datos y Machine Learning en R! En este curso, te embarcarás en un viaje transformador para descubrir el poder de los datos y cómo convertirlos en conocimiento significativo. Aprenderás a dominar las herramientas y técnicas más avanzadas de R para analizar, visualizar y manipular datos caóticos. Además, desbloquearás el potencial de la inteligencia artificial al desarrollar modelos de aprendizaje automático capaces de predecir tendencias, clasificar información y comprender el lenguaje humano. ¡Prepárate para convertirte en un experto en la ciencia detrás de los datos y llevar tu capacidad analítica a un nivel completamente nuevo! ¿Listo para desafiar tus límites y cambiar el juego con la ciencia de datos y el aprendizaje automático en R? ¡Únete a nosotros y comienza tu emocionante aventura hacia el futuro de la tecnología y la innovación!\n\n\nLo mas importante de este curso es que haremos un proyecto real para que puedas tener conocimientos adecuados y útiles en tu vida profesional. Cada que repliques este curso que realizaremos acá, iras aumentando tu probabilidad de tener {éxito en esta área. Es fundamental que tengas toda la disposición de retarte a entender este apasionante mundo. No olvides que cualquier duda puedes contactarme para que nada obstaculice tu aprendizaje",
      "target_audience": [
        "Se dirige a toda persona que quiera aprender o potenciar su vida profesional con las tecnologías mas importantes del mundo"
      ]
    },
    {
      "title": "Maîtrise Power BI : 10 Projets Pratiques pour Visualisation",
      "url": "https://www.udemy.com/course/projets-business-intelligence-microsoft-power-bi/",
      "bio": "Maîtrisez Power BI avec 10 Projets Pratiques pour Améliorer vos Compétences en Visualisation de Données",
      "objectives": [
        "Créer des tableaux de bord interactifs et dynamiques avec Power BI en utilisant des données mondiales.",
        "Analyser et visualiser la qualité de l'air à Pékin à l'aide de techniques avancées de Power BI.",
        "Comprendre les concepts de base et avancés de la visualisation de données dans Power BI.",
        "Appliquer des techniques de benchmarking pour comparer des données à l'échelle mondiale."
      ],
      "course_content": {
        "Introduction au Cours": [
          "Introduction au Cours"
        ],
        "Projet-1 - Tableau de bord de benchmarking des données mondiales": [
          "Introduction - Tableau de bord de benchmarking des données mondiales",
          "Nettoyage des données",
          "Visualisation des données partie 1",
          "Visualisation des données partie 2",
          "Téléchargez le jeu de données du projet"
        ],
        "Projet-2 : Tableau Qualité de l'Air à Pékin : DAX et Visualisations": [
          "Introduction - Tableau Qualité de l'Air à Pékin : DAX et Visualisations",
          "Nettoyage des données",
          "Visualisation des données partie 1",
          "Visualisation des données partie 2",
          "Téléchargez le jeu de données du projet"
        ],
        "Projet-3 : Immobilier Daegu : Analyse des Avantages/Inconvénients d'Appartements": [
          "Introduction - Immobilier Daegu : Analyse des Avantages/Inconvénients d'Appartem",
          "Visualisation Partie -1",
          "Visualisation Partie -2",
          "Téléchargez le jeu de données du projet"
        ],
        "Projet-4 : Analyse des Ventes Supermarché : Power Query et DAX": [
          "Introduction - Analyse des Ventes Supermarché : Power Query et DAX",
          "Nettoyage des Données",
          "Visualisation Partie -1",
          "Visualisation Partie -2",
          "Téléchargez le jeu de données du projet"
        ],
        "Projet-5 : Analyse Données OMS COVID-19 : Power Query et DAX": [
          "Introduction",
          "Visualisation Partie -1",
          "Visualisation Partie -2",
          "Téléchargez le jeu de données du projet"
        ],
        "Projet-6 : Analyse des Défaillants Cartes de Crédit : Power Query et DAX": [
          "Introduction",
          "Nettoyage des Données",
          "Visualisation Partie -1",
          "Visualisation Partie -2",
          "Téléchargez le jeu de données du projet"
        ],
        "Projet-7 : Analyse Défection Client (Fonctions Avancées) : Modélisation des Donn": [
          "Introduction",
          "Nettoyage des Données",
          "Relations et DAX",
          "Visualisation Partie -2",
          "Téléchargez le jeu de données du projet"
        ],
        "Projet-8 : Analyse Attrition : Transformation et Visualisation des Données RH": [
          "Introduction",
          "Nettoyage des Données",
          "Visualisation Partie -1",
          "Visualisation Partie -2",
          "Téléchargez le jeu de données du projet"
        ],
        "Projet-9 : Analyse Générique de Ventes : Transformation des Données Pratique": [
          "Introduction",
          "Nettoyage des Données",
          "Création de Relations",
          "Visualisation",
          "Téléchargez le jeu de données du projet"
        ]
      },
      "requirements": [
        "Idée de base de Power BI"
      ],
      "description": "Vous souhaitez maîtriser Power BI et faire évoluer votre carrière dans l'analyse de données et l'intelligence d'affaires ? Ce cours propose 10 projets pratiques avec Power BI, axés sur des applications réelles et des scénarios du monde professionnel, vous aidant à développer des compétences essentielles pour créer des visualisations de données professionnelles. Que vous soyez débutant ou que vous cherchiez à améliorer vos compétences, ces projets vous guideront à chaque étape du processus.\nVous apprendrez à créer des tableaux de bord dynamiques et des rapports interactifs en utilisant Power Query, les fonctions DAX, et la modélisation des données. Acquérez des connaissances approfondies sur la transformation des données, les relations entre ensembles de données, et les fonctionnalités visuelles avancées. Ces projets vous permettront de transformer des données brutes en informations précieuses et exploitables pour la prise de décision. Que vous analysiez les tendances de vente, le comportement des clients, ou des données financières, vous disposerez des outils et des connaissances nécessaires pour produire des rapports visuels de qualité qui ont un impact sur le business.\nEn réalisant ces 10 projets, vous gagnerez de l'expérience pratique tout en constituant un portfolio démontrant votre capacité à résoudre des problèmes de données complexes et à créer des visualisations soignées. Ces compétences sont recherchées dans des secteurs comme la finance, le marketing, la santé, et la technologie, vous rendant plus compétitif pour des postes en science des données, analyse d’affaires, et ingénierie des données.\nCe cours convient à tous ceux qui souhaitent améliorer leurs compétences Power BI, des débutants aux utilisateurs avancés. Inscrivez-vous aujourd'hui et exploitez la puissance de la visualisation de données avec Power BI !",
      "target_audience": [
        "Débutants en Power BI"
      ]
    },
    {
      "title": "데이터분석 전문가 자격증, ADP 완벽대비",
      "url": "https://www.udemy.com/course/adp-clgr/",
      "bio": "ADP 자격증을 준비하기 위한 All in one 강의",
      "objectives": [
        "데이터 이해 및 처리 기술에 대한 기본 지식",
        "데이터 분석 기획, 데이터 분석, 데이터 시각화 업무의 프로세프",
        "과학적 의사 결정을 지원하는 직무를 수행하는 전문가를 양성",
        "분석과제 로드맵 수립, 성과 관리 등"
      ],
      "course_content": {
        "데이터분석 전문가(ADP) 자격증 따기 (필기) - 1과목 데이터 이해": [
          "ADP 자격증에 대한 소개 / 데이터의 이해",
          "데이터베이스 정의와 특징",
          "빅데이터의 이해",
          "데이터사이언스와 전략 인사이트",
          "데이터 분석 기획",
          "데이터 분석",
          "데이터 분석",
          "빅데이터의 이해 1",
          "빅데이터의 이해 2",
          "데이터 사이언스의 이해",
          "빅데이터 수집",
          "문제풀이1",
          "문제풀이2"
        ],
        "데이터분석 전문가(ADP) 자격증 따기 (필기) - 2과목 데이터처리기술 이해": [
          "데이터 처리 프로세스",
          "문제풀이"
        ],
        "데이터분석 전문가(ADP) 자격증 따기 (필기) - 3과목 데이터분석 기획": [
          "데이터 분석 기회",
          "문제풀이(1)",
          "문제풀이(2)",
          "문제풀이(3)"
        ],
        "데이터분석 전문가(ADP) 자격증 따기 (필기) - 4과목 데이터분석": [
          "통계분석1",
          "통계분석2",
          "통계분석3",
          "문제풀이",
          "정형데이터마이닝(1)",
          "정형데이터마이닝(2)",
          "정형데이터마이닝(3)",
          "정형데이터마이닝(4)",
          "정형데이터마이닝(5)",
          "정형데이터마이닝(6)",
          "정형데이터마이닝(7)",
          "기초통계량과 회귀에 관한 문제",
          "문제풀이",
          "통계기반 데이터분석 기초1",
          "통계기반 데이터분석 기초2",
          "비정형데이터마이닝1",
          "비정형데이터마이닝2"
        ],
        "데이터분석 전문가(ADP) 자격증 따기 (필기) - 5과목 데이터시각화": [
          "데이터시각화",
          "데이터시각화 차트",
          "데이터시각화 그래프"
        ]
      },
      "requirements": [
        "데이터분석에 대해 공부하고 싶은 사람은 누구나 수강 가능합니다"
      ],
      "description": "[ADP 자격증을 준비하기 위한 All in one 강의]\n\n\n비즈니스 목표 달성을 위해 내부 업무 프로세스를 기반으로 다양한 분석 기회를 발굴하여 분석의 목표를 정의하고, 분석 대상 도출 및 분석 결과 활용 시나리오를 정의하여 분석과제를 체계화 및 구체화하는 빅데이터를 분석과제 정의, 분석과제 로드맵 수립, 성과 관리 등에 대해서 학습합니다. 분석에 대한 요건을 구체적으로 도출하고, 분석과정을 설계하고, 요건을 실무 담당자와 합의 하는 요건 정의, 모델링, 검증 및 테스트, 적용하는 방식을 배우며, 다양한 데이터들을 대상으로 어떤 요소를 시각화 해야 하는지 정보 구조를 분석하며 시각화에 대한 요건을 정의하고 시나리오를 개발하는 시각화 기획, 모델링, 디자인, 구축, 배포 및 유지보수 등을 배울 수 있습니다.\n\n\n본 과정의 커리큘럼은 다음과 같습니다.\n\n\n[데이터분석 전문가(ADP) 자격증 따기 (필기) - 1과목 데이터 이해]\n\n\nADP 자격증에 대한 소개 / 데이터의 이해\n데이터베이스 의와 특징\n빅데이터의 이해\n데이터사이언스와 전략 인사이트\n데이터 분석 기획\n데이터 분석\n데이터 분석\n빅데이터의 이해 1\n빅데이터의 이해 2\n데이터 사이언스의 이해\n빅데이터 수집\n문제풀이1\n문제풀이2\n\n\n[데이터분석 전문가(ADP) 자격증 따기 (필기) - 2과목 데이터처리기술 이해]\n\n\n데이터 처리 프로세스\n문제풀이\n\n\n[데이터분석 전문가(ADP) 자격증 따기 (필기) - 3과목 데이터분석 기획]\n\n\n데이터 분석 기회\n문제풀이(1)\n문제풀이(2)\n문제풀이(3)\n\n\n[데이터분석 전문가(ADP) 자격증 따기 (필기) - 4과목 데이터분석]\n\n\n통계분석1\n통계분석2\n통계분석3\n문제풀이\n정형데이터마이닝(1)\n정형데이터마이닝(2)\n정형데이터마이닝(3)\n정형데이터마이닝(4)\n정형데이터마이닝(5)\n정형데이터마이닝(6)\n정형데이터마이닝(7)\n기초통계량과 회귀에 관한 문제\n문제풀이\n통계기반 데이터분석 기초1\n통계기반 데이터분석 기초2\n비정형데이터마이닝1\n비정형데이터마이닝2\n\n\n[데이터분석 전문가(ADP) 자격증 따기 (필기) - 5과목 데이터시각화]\n\n\n데이터시각화\n데이터시각화 차트\n데이터시각화 그래프\n\n\n본 강의로 ADP 자격증 준비를 한 번에 마스터하시기 바랍니다",
      "target_audience": [
        "데이터분석 분야 및 관련 분야 취업 및 ADP(ADsP) 자격 취득을 원하는 모두"
      ]
    },
    {
      "title": "Surpac Sıfırdan Cevher Modelleme/ Ore Modelling using Surpac",
      "url": "https://www.udemy.com/course/surpac-sfrdan-cevher-modelleme-ore-modelling-using-surpac/",
      "bio": "Sıfırdan cevher modelleme",
      "objectives": [
        "Sondaj verilerinin hazırlanması",
        "Sondaj verilerinin Surpac programında gösterilmesi",
        "Sondaj verilerinden Explicit cevher modelinin çizilmesi",
        "Surpac ile ilgili temel bilgiler cevher modelleme ve modellenen cevherin hacim ve tonaj verilerinin alınması"
      ],
      "course_content": {
        "Giriş": [
          "Surpac veri tabanı içeriği",
          "Surpac Veri Tabanı Dosyalarının Excelde Oluşturulması",
          "Surpac Çalışılacak Klasorde Başlatma",
          "Surpac Menüler ve Arka plan rengi değiştirme",
          "Surpac Database Oluşturma",
          "Sondaj Verilerinin Database Girilmesi",
          "Sondajların Litolojiye Göre Renkledirilmesi ve Surpacte Gösterilmesi",
          "Sondajların Tenör Dağılımına Göre Renklendirilmesi ve Surpacte Gösterilmesi",
          "Cevher Katı Modeli Stringlerinin Oluşturulması 1",
          "Cevher Katı Modeli Stringlerinin Oluşturulması 2",
          "Cevher Katı Modelinin Oluşturulması",
          "Cevher Katı Modelinden Hacim Değerlerinin Alınması ve Tonaj Hesaplanması",
          "Cevher Katı Modelinden Yeni Stringlerin Oluşturulması"
        ]
      },
      "requirements": [
        "Sıfırdan cevher modellemesi öğrenilecektir"
      ],
      "description": "Maden planlama ve cevher modelleme programları içinde en yaygın olarak kullanılan üç boyutlu programlardan bir tanesi surpac programıdır. Surpac programında cevher modelleme, blok model, açık ocak ve yer altı maden ocağı modelleme gibi işlemler yapılmaktadır.\nSurpac; jeolojik modelleme, maden tasarım ve üretim planlama sistemidir. Bütün önemli madencilik konularını kapsayan bir madencilik programıdır. Bu yazılım jeoloji, maden teknik, üretim planlama ve organizasyon konularında, bölgenin iyileştirilmesi için yapılacak işlemlere kadar madenciliğin bütün basamaklarında kullanılan uygulamalara sahiptir. Bütün proje verileri Surpac’ta arşivlenir ve yönetilir.\nJeologların, sınırlı bilgiler ile bir maden yatağının fiziksel karakterlerini saptamaya olanak sağlaması Surpac’ın yapabilecekleri için bir anahtardır ki 3D (3 boyutlu) güçlü grafikleri, jeoistatistik ve entegre edilmiş modelleme koşullarını kullanır.\nBu kursta sıfırdan yani sahada yapılan sondaj verilerinden yola çıkarak cevher modellemesi yapılmıştır. Sondaj verilerinin nasıl alınması gerektiği detaylı bir şekilde anlatılmıştır.\nSurpac veri tabanı oluşturma excel dosyalarının hazırlanması, hazırlanan excel dosyalarının surpac veri tabanına işlenmesi, işlenen sondaj verilerinin üç boyutlu gösterimi, litolojik gösterim ve tenör değerlerine dayalı gösterim gibi detaylar verilmiştir.\nKesit hatları hesaplanması, alınan kesit hatlarından cevher stringlerinin oluşturulması, stringlerden cevher katı modelinin oluşturulması ve cevher kütlesinin oluşturulması gibi detaylar anlatılmıştır.\nSurpac programını istenilen klasörde Work Directory olarak başlatılması, arka plan renginin değiştirilmesi, Surpac koordinat sistemi gibi detaylar anlatılmış olup bazı kritik noktalara değinilmiştir. Bu kursu aldığınızda sondaj verilerinden cevher modellemeye kadar Surpac programını kullanabilir düzeye gelinecektir.",
      "target_audience": [
        "Jeoloji Mühendisleri, Maden Mühendisleri, Mining Engineer, Geological Engineer, Geoscientists,"
      ]
    },
    {
      "title": "빅데이터 분석 | 시각화 | 머신 러닝 | 통계 검정 - Visual Python 활용",
      "url": "https://www.udemy.com/course/visual-python/",
      "bio": "IT 비전공자를 위한 데이터 분석, 시각화, 머신 러닝, 통계 검정",
      "objectives": [
        "빅데이터 분석에 대한 기본 개념을 정리합니다.",
        "빅데이터 분석에 필요한 최소한의 파이썬 개념을 익힙니다.",
        "파이썬 코드를 생성해주는 패키지를 이용해 빅데이터 분석을 수행합니다.",
        "Visual Python을 활용해 데이터 처리, 데이터 분석 및 시각화를 익힙니다.",
        "Visual Python을 활용해 머신 러닝 개념을 익히고 수행합니다.",
        "Visual Python을 활용해 통계 분석 및 검정을 수행합니다."
      ],
      "course_content": {},
      "requirements": [
        "빅데이터 분석에 대한 기본 개념부터 시작합니다."
      ],
      "description": "빅데이터 분석에 대한 기본 개념을 확립하고 데이터 분석, 시각화, 머신 러닝, 통계 검정에 대한 실습을 경험할 수 있는 강의 입니다.\n\n\n[강의 구성 및 내용]\n\n\n1. 데이터 분석 개요\n데이터 분석의 구성, 필요 역량 등을 설명하고 데이터 분석과 머신 러닝의 활용과 차이에 대해 알아봅니다.\n또한 머신 러닝의 역할과 평가 방법에 대해서도 확인합니다.\n\n\n2. 파이썬 기본 문법 및 패키지 활용\n데이터 분석을 위한 최소한의 기초적인 파이썬 문법과 데이터 분석을 위한 패키지 활용에 대한 개념을 확립합니다.\n추가적으로 IT 비전공자를 위한 데이터 분석 패키지 Visual Python을 활용한 데이터 분석을 소개합니다.\n\n\n3. Visual Python - Data Analysis\nVisual Python을 활용해 데이터 처리, 분석 및 시각화 실습을 진행합니다.\nPython 패키지 numpy, pandas, matplotlib, seaborn등을 활용합니다.\n예제 데이터를 이용해 데이터 분석 실습을 진행합니다.\n\n\n4. Visual Python - Machine Learning\nVisual Python을 활용해 머신 러닝 모델을 생성하고 데이터를 학습, 예측 및 평가 등의 작업을 수행합니다.\n지도학습(분류, 수치 예측 등), 비지도학습(군집, 차원 축소 등) 알고리즘을 학습합니다.\nPython 패키지 scikit-learn등을 활용합니다.\n예제 데이터를 이용해 머신 러닝 실습을 진행합니다.\n\n\n5. Visual Python - Statistics\nVisual Python을 활용해  확률 분포, 기술 통계를 확인 하고 통계 검정을 수행합니다.\n정규성 검정, 등분산 검정, T-검정, ANOVA, 요인 분석, 회귀 분석 등을 학습합니다.\nPython 패키지 scipy, Statsmodels 등을 활용합니다.",
      "target_audience": [
        "빅데이터 분석에 관심 있는 IT관련 비전공자",
        "데이터 처리 및 시각화에 관심 있는 사람",
        "머신 러닝 개념 및 모델 생성 및 수행에 관심 있는 사람",
        "통계 분석 및 검정에 관심 있는 사람"
      ]
    },
    {
      "title": "Python ile Metin Madenciliği, Doğal Dil İşleme",
      "url": "https://www.udemy.com/course/python-ile-metin-madenciligi-dogal-dil-isleme/",
      "bio": "Python ile Metin Madenciliği, Doğal Dil İşleme",
      "objectives": [
        "Veri Madenciliği Becerileri: Metin madenciliği, genel olarak veri madenciliği disiplininde yer alır. Öğrenciler, büyük veri setlerinden anlamlı bilgiler çıkarma",
        "Doğal Dil İşleme (NLP): Metin madenciliği, doğal dil işleme (NLP) tekniklerini kullanarak metin verilerini anlamaya odaklanır. Öğrenciler, metin analizi, kelime",
        "Bilgi Çıkarma ve Sınıflandırma: Metin madenciliği, belirli kategorilere ait metinleri tanıma ve sınıflandırma konusunda öğrencilere beceri kazandırır. Öğrencile",
        "Duygu Analizi: Metin madenciliği, metinlerdeki duygu ve hissiyatları anlama amacı güder. Bu, sosyal medya analizi, müşteri yorumlarından müşteri memnuniyetini a",
        "Özetleme: Metin madenciliği, uzun metinlerden özetler oluşturma yeteneğini içerir. Öğrenciler, metinlerin ana konularını ve önemli detaylarını belirleyerek özet",
        "Veri Görselleştirme: Metin madenciliği sonuçlarını görselleştirmek, öğrencilere etkili bir şekilde bilgi iletişim becerileri kazandırır. Öğrenciler, çubuk grafi",
        "Metin madenciliği, öğrencilere çok disiplinli bir yaklaşım sağlar ve bu alandaki beceriler, öğrencilere hem teknik hem de analitik yetenekler kazandırır."
      ],
      "course_content": {},
      "requirements": [
        "Temel düzeyde \"Python Programlama\" bilgisi",
        "Yapay Zeka, Doğal Dil İşleme konularına merak"
      ],
      "description": "Metin madenciliği ve doğal dil işleme (NLP), bilgisayar bilimleri ve yapay zeka alanlarında büyük öneme sahip olan iki temel konsepttir. Her ikisi de doğal dilin (insanların günlük dilinde kullandığı dil) anlaşılması, analizi ve işlenmesi üzerine odaklanır. İşte metin madenciliği ve doğal dil işlemenin bazı avantajları:\nMetin Madenciliği Avantajları:\nBilgi Çıkarma:\nMetin madenciliği, büyük metin verilerini analiz ederek önemli bilgileri çıkarmak için kullanılır. Bu, işletmelerin pazar trendlerini, müşteri geri bildirimlerini ve diğer önemli bilgileri anlamalarına yardımcı olur.\nDuygu Analizi:\nMetin madenciliği, duygu analizi yaparak belirli bir metin veya belge içindeki duygusal tonları anlayabilir. Bu, müşteri geri bildirimlerini, sosyal medya paylaşımlarını ve diğer metin tabanlı içerikleri değerlendirmek için kullanılır.\nTrend Analizi:\nMetin madenciliği, belirli konular veya endüstrilerdeki trendleri belirlemek için kullanılabilir. Bu, işletmelerin rekabet avantajı elde etmelerine ve stratejilerini güncellemelerine yardımcı olabilir.\nDoğal Dil İşleme (NLP) Avantajları:\nOtomatik Dil Anlama:\nDoğal Dil İşleme, bilgisayarların insan dilini anlamalarına ve yorumlamalarına olanak tanır. Bu, metin tabanlı verileri otomatik olarak analiz etmeyi ve anlamayı sağlar.\nKonuşma Tanıma:\nNLP, konuşma tanıma teknolojilerinin geliştirilmesine olanak tanır. Bu sayede, sesli komutlar, konuşma tabanlı arayüzler ve sesli asistanlar gibi uygulamalarda kullanılabilir.\nÇeviri Hizmetleri:\nDoğal Dil İşleme, dil çevirisi hizmetlerinde kullanılır. Bu, otomatik çeviri araçları ve dil engellerini aşmada yardımcı olur.\nMakine Çevirisi Gelişimi:\nNLP, makine çevirisi modellerinin geliştirilmesine katkıda bulunur. Bu sayede farklı diller arasında çeviri yapmak daha etkili hale gelir.\nMetin Sınıflandırma:\nNLP, metin sınıflandırma görevlerinde kullanılır. Örneğin, spam filtreleri, duygu analizi, haber kategorizasyonu gibi uygulamalarda metinleri otomatik olarak sınıflandırmak için kullanılabilir.\nMetin madenciliği ve doğal dil işleme, işletmelerin verilerini daha etkili bir şekilde analiz etmelerine, kullanıcı deneyimini geliştirmelerine ve bilgiye erişimlerini artırmalarına yardımcı olan güçlü araçlardır. Bu teknolojilerin kullanımı, birçok sektörde veri tabanlı karar alma süreçlerini optimize etme ve yenilik yapma potansiyelini artırabilir.",
      "target_audience": [
        "Metin madenciliği, doğal dil işleme ilgilenmek isteyen tüm herkes alabilir. Lisans, yüksek lisans ve doktora düzeyinde bu alanda eğitim almak isteyen herkese fayda sağlayacaktır"
      ]
    },
    {
      "title": "强化学习实战系列(PyTorch版)",
      "url": "https://www.udemy.com/course/rlirpcin/",
      "bio": "强化学习经典算法+案例实战",
      "objectives": [
        "掌握强化学习基本思想及其应用领域",
        "掌握强化学习主流算法原理",
        "掌握强化学习算法数学推导过程及其证明",
        "熟练使用PyTorch框架构建强化学习模型",
        "熟练使用Openai环境训练强化学习算法模型",
        "熟练基本强化学习算法进行实际项目构建",
        "掌握DQN，A3C等主流强化学习算法及其数学原理"
      ],
      "course_content": {
        "强化学习简介及其应用": [
          "课程介绍",
          "一张图通俗解释强化学习",
          "强化学习的指导依据",
          "强化学习AI游戏",
          "应用领域简介",
          "强化学习工作流程",
          "计算机眼中的状态与行为",
          "本章课件下载"
        ],
        "PPO算法与公式推导": [
          "基本情况介绍",
          "与环境交互得到所需数据",
          "要完成的目标分析",
          "策略梯度推导",
          "baseline方法",
          "OnPolicy与OffPolicy策略",
          "importance sampling的作用",
          "PPO算法整体思路解析",
          "本章课件下载"
        ],
        "策略梯度实战-月球登陆器训练实例": [
          "Critic的作用与效果",
          "PPO2版本公式解读",
          "参数与网络结构定义",
          "得到动作结果",
          "奖励获得与计算",
          "参数迭代与更新",
          "本章课件下载"
        ],
        "Q-learning算法": [
          "算法原理通俗解读",
          "目标函数与公式解析",
          "Qlearning算法实例解读",
          "Q值迭代求解",
          "DQN简介",
          "本章课件下载"
        ],
        "DQN算法实例演示": [
          "整体任务流程演示",
          "探索与action获取",
          "计算target值",
          "训练与更新",
          "本章课件下载"
        ],
        "DQN改进与应用技巧": [
          "DoubleDqn要解决的问题",
          "DuelingDqn改进方法",
          "Dueling整体网络架构分析",
          "MultiSetp策略",
          "连续动作处理方法"
        ],
        "Actor-Critic算法分析(A3C)": [
          "AC算法回顾与知识点总结",
          "优势函数解读与分析",
          "计算流程实例",
          "A3C整体架构分析",
          "损失函数整理",
          "本章课件下载"
        ],
        "A3C算法玩转超级马里奥": [
          "整体流程与环境配置",
          "启动游戏环境",
          "要计算的指标回顾",
          "初始化局部模型并加载参数",
          "与环境交互得到训练数据",
          "训练网络模型",
          "本章课件下载"
        ],
        "算法补充-卷积神经网络原理与参数解读": [
          "积神经网络应用领域",
          "卷积的作用",
          "卷积特征值计算方法",
          "得到特征图表示",
          "步长与卷积核大小对结果的影响",
          "边缘填充方法",
          "特征图尺寸计算与参数共享",
          "池化层的作用",
          "整体网络架构",
          "VGG网络架构",
          "残差网络Resnet",
          "感受野的作用"
        ],
        "基础补充-PyTorch框架基本处理操作": [
          "PyTorch框架发展趋势简介",
          "框架安装方法（CPU与GPU版本）",
          "PyTorch基本操作简介",
          "自动求导机制",
          "线性回归DEMO-数据与参数配置",
          "线性回归DEMO-训练回归模型",
          "常见tensor格式",
          "Hub模块简介"
        ]
      },
      "requirements": [
        "熟悉深度学习与Python"
      ],
      "description": "强化学习系列课程主要包括经典算法原理讲解与案例实战两大部分。通俗讲解当下主流强化学习算法思想，结合实例解读算法整理应用流程并结合案例展开代码实战。整体风格通俗易懂，适合准备入门强化学习并进阶提升的同学们。课程目录界面提供全部所需PPT,数据，代码！",
      "target_audience": [
        "人工智能方向的同学们"
      ]
    },
    {
      "title": "Data Science R: Manipule, visualize dados com R",
      "url": "https://www.udemy.com/course/data-science-r-manipule-visualize-dados-com-r/",
      "bio": "Comece a aprender Data Science por visualização e manipulação de dados com Tidyverse no R",
      "objectives": [
        "Manipular um banco de dados com um dos melhores pacotes disponíveis",
        "Excelente base de visualização PROFISSIONAL de dados com ggplot2",
        "Estatísticas descritivas",
        "Gráficos como boxplot, dispersão, gráfico de barras"
      ],
      "course_content": {
        "Introdução": [
          "Introdução",
          "Download",
          "Dicas Iniciais",
          "Resumo das dicas"
        ],
        "Manipulação de dados": [
          "Instalação dos pacotes: gapminder e dplyr",
          "Verbo Filter [dplyr]",
          "Verbo Arrange [dplyr]",
          "Verbo Mutate [dplyr]",
          "Fixação capitulo 1"
        ],
        "Visualização de dados": [
          "Instalação dos pacotes: ggplot2",
          "Gráfico de dispersão",
          "Escala log",
          "Incremento no aes()",
          "Múltiplos gráficos"
        ],
        "Resumindo e agrupando": [
          "Summarize",
          "Group_by",
          "Aula bônus: Aprenda mais PAGANDO MENOS"
        ]
      },
      "requirements": [
        "Nenhum conhecimento prévio é necessario"
      ],
      "description": "Aprofunde-se no universo da programação em R através do aclamado pacote \"tidyverse\". Este curso é uma porta de entrada para o mundo do R, projetado para fornecer uma compreensão robusta dos fundamentos da linguagem. Através de uma série de exemplos práticos, você aprenderá como manipular conjuntos de dados e extrair as informações específicas que necessita. Mais do que isso, o curso ensina a visualizar seus dados de forma profissional, utilizando os poderosos pacotes dplyr e ggplot2, essenciais para qualquer cientista de dados que deseja se destacar.\n\n\nAo mergulhar nos conteúdos do curso, você será introduzido aos principais tipos de gráficos utilizados em estatísticas para a representação de dados, incluindo gráficos de dispersão, gráficos de barras, histogramas, entre outros. Cada tipo de gráfico será abordado não apenas em termos de como criá-los, mas também em como interpretá-los e em quais situações são mais apropriados para uso.\n\n\nEste curso aborda uma gama abrangente de tópicos, tanto gerais quanto complexos, que são fundamentais para a análise de dados e que requerem um estudo detalhado e dedicado. Mesmo sendo uma introdução, o curso é projetado para dar aos alunos uma base sólida, sobre a qual eles podem construir conhecimento mais avançado. Os alunos sairão do curso não apenas com uma compreensão teórica dos princípios do R, mas também com habilidades práticas aplicáveis em análises de dados reais.\n\n\nAlém disso, o curso enfatiza a importância da prática e da experimentação. Através de exercícios e projetos, os alunos terão a oportunidade de aplicar o que aprenderam em situações do mundo real, permitindo-lhes solidificar seus conhecimentos e habilidades. Isso prepara os alunos para os desafios que encontrarão em suas carreiras profissionais, equipando-os com as ferramentas necessárias para resolver problemas complexos com eficiência e eficácia.\n\n\nPrepare-se para embarcar em uma jornada educativa que não apenas ampliará seu entendimento de análise de dados com R, mas também aprimorará sua capacidade de pensar criticamente e resolver problemas de forma criativa. Seja você um iniciante em programação ou alguém procurando aprofundar seus conhecimentos em R, este curso oferece o equilíbrio perfeito entre teoria e prática, garantindo que você esteja pronto para enfrentar os desafios do mundo dos dados.",
      "target_audience": [
        "Qualquer pessoa que tenha interesse na area de data science",
        "Quem queira conhecer o pacote de manipulação de dados \"dplyr\" do R",
        "Quem queira conhecer o pacote de visualização de dados \"ggplot\" do R"
      ]
    },
    {
      "title": "Álgebra Linear com R para Machine Learning e Modelagens",
      "url": "https://www.udemy.com/course/algebra-linear-com-r-para-machine-learning-e-modelagens/",
      "bio": "Para Machine Learning, Modelagem Matemática, Estatística, Ciência de Dados, Matemática, Engenharia, Ciências Exatas...",
      "objectives": [
        "Vetores",
        "Operações com vetores",
        "Tipos de Matrizes",
        "Operações com matrizes",
        "Matriz Inversa",
        "Determinante",
        "Equações Lineares",
        "Sistema de Equações Lineares",
        "Resoluções de sistemas lineares (método da adição, substituição, regra de Cramer e escalonamento)",
        "Regra de Cramer",
        "Regra de Sarrus",
        "Estimativa dos mínimos quadrados",
        "Autovalor e autovetor",
        "Transformação linear (homotetia, rotação, translação, cisalhamento, reflexão, alongamento, contração...)",
        "Teorema de Laplace",
        "Cofator",
        "Noções de Análise dos Componentes Principais (PCA)",
        "Teoria Matemática da Regressão Linear Múltipla",
        "Fundamentos da linguagem R"
      ],
      "course_content": {
        "Introdução": [
          "Boas vindas e apresentação do instrutor",
          "Apresentação do curso e da plataforma de estudos"
        ],
        "Fundamentos da Linguagem R": [
          "Conhecendo a Linguagem R",
          "Instalação do R e RStudio",
          "Conhecendo o RStudio",
          "Apresentação do RStudioCloud",
          "Primeiros passos no RStudio",
          "Operadores Matemáticos",
          "Variáveis",
          "Fatores",
          "Data Frame e Listas",
          "Instalação e carregamento de Pacotes",
          "Importação de arquivos",
          "Estrutura condicional",
          "Estrutura de Repetição",
          "Criação de Funções"
        ],
        "Vetores e Matrizes": [
          "Introdução à Álgebra Linear",
          "Vetores e a soma geométrica bidimensional",
          "Vetores no R",
          "Cálculo com vetores",
          "Operações com vetores no R",
          "Distância e norma no R",
          "Matrizes",
          "Criação de Matrizes no R",
          "Tipos de Matrizes no R",
          "Manipulação de matrizes no R",
          "Adição e Subtração de matrizes",
          "Multiplicação de matrizes",
          "Operações com matrizes no R",
          "Matriz Inversa",
          "Determinante",
          "Teorema de Laplace e Cofator",
          "Determinante e matriz inversa no R"
        ],
        "Sistemas Lineares": [
          "Equações",
          "Sistema de equações lineares",
          "Resolução de sistema de equações lineares: método da adição e substituição",
          "Resolução de sistema de equações lineares 3x3",
          "Resolução de sistema de equações lineares: regra de Cramer",
          "Regra de Cramer no R",
          "Resolução sistema de equações lineares: método eliminação Gauss (escalonamento)",
          "Estimativa dos mínimos quadrados",
          "Estimativa dos mínimos quadrados no R – parte 1",
          "Estimativa dos mínimos quadrados no R – parte 2",
          "Criação de um modelo de regressão linear múltipla no R"
        ],
        "Transformação Linear, Autovetores e Autovalores": [
          "Transformação linear",
          "Transformação linear no R: Homotetia",
          "Transformação linear no R: Translação",
          "Transformação linear no R: Rotação",
          "Transformação linear no R: Reflexão",
          "Transformação linear no R: Cisalhamento",
          "Transformação linear no R: Alongamento e Contração",
          "Autovetores e autovalores",
          "Autovetores e autovalores no R",
          "Análise dos componentes principais (PCA)",
          "Autovetores e autovalores na Análise dos componentes principais (PCA) no R."
        ],
        "Finalização do curso": [
          "Encerramento do Curso"
        ],
        "Referências e links úteis": [
          "Referências e links úteis (gratuitos)"
        ]
      },
      "requirements": [
        "Não há pré-requisitos"
      ],
      "description": "Este curso aborda de forma clara e objetiva os principais conceitos da Álgebra Linear focado em demonstrações práticas utilizando a Linguagem R. Serão estudados os conteúdos sobre vetores (tipos e operações), matrizes(tipos, operações e determinantes), sistemas lineares, resolução de sistemas lineares (método da adição, método da substituição, regra de Cramer e escalonamento), Teorema de Laplace, Cofator, Estimativa dos mínimos quadrados, modelo de regressão linear múltipla, transformação linear (Homotetia, Translação, Rotação, Reflexão, Cisalhamento, Dilatação, Contração, Identidade, Nula e Inversa), autovalores, autovetores e Análise dos Componentes Principais (PCA).\nSão utilizados alguns datasets para exemplificar, onde é apresentado como se utiliza a Álgebra Linear com dados reais, inclusive a análise inicial que se deve fazer nos dados. É demonstrado como a Álgebra Linear se relaciona com o Método dos Mínimos Quadrados, com a Regressão Linear Múltipla e também com a Análise dos Componentes Principais.\nA primeira seção é referente a apresentação dos conceitos básicos sobre a Linguagem R no RStudio, para que aqueles que não conhecem a linguagem R possam acompanhar o curso com tranquilidade.\nO curso é apresentado no sistema operacional Windows, no RStudio, mas usuários do Linux e Mac acompanham tranquilamente.\nTenho certeza que a sua visão sobre Álgebra Linear irá mudar após esse curso.",
      "target_audience": [
        "Estatístico",
        "Matemático",
        "Cientista de Dados",
        "Profissionais de Machine Learning",
        "Pesquisador",
        "Engenheiro",
        "Administrador",
        "Economista",
        "Estudantes de graduação e pós graduação"
      ]
    },
    {
      "title": "파이썬 Flask(플라스크)를 이용한 웹 프로젝트 만들기",
      "url": "https://www.udemy.com/course/flask-yl/",
      "bio": "웹 사이트 개발, 게임, 인공지능 다양한 분야에서 활용 가능한 파이썬 플라스크 프로그래밍 배우기",
      "objectives": [
        "파이썬 설치하기",
        "플라이크 개발환경",
        "플라이크 프로젝트 생성",
        "파이참 설치",
        "플라스크 기초",
        "플라스크 애플리케이션 팩토리",
        "블루프린트로 라우팅 함수 관리",
        "모델로 데이터 처리",
        "질문 목록과 상세기능",
        "디자인 적용 하기",
        "질문 및 폼 모듈 작성"
      ],
      "course_content": {
        "파이썬 Flask(플라스크)를 이용한 웹 프로젝트": [
          "1 플라이크의 개요",
          "2 파이썬 설치하기",
          "3 플라이크 개발환경",
          "4 플라이크 프로젝트 생성",
          "5 파이참 설치",
          "6 플라스크 기초",
          "7 플라스크 애플리케이션 팩토리",
          "8 블루프린트로 라우팅 함수 관리",
          "9 모델로 데이터 처리(1)",
          "10 모델로 데이터 처리(2)",
          "11 질문 목록과 상세기능",
          "12 질문에 답변 달기",
          "13 디자인 적용 하기",
          "14 질문 및 폼 모듈 작성"
        ]
      },
      "requirements": [
        "누구나 수강할 수 있습니다."
      ],
      "description": "안녕하세요, ITGO 입니다.\n\n\n본 강의는 파이썬 Flask(플라스크)를 이용한 웹 프로젝트 만들기 입니다.\n\n\n파이썬 플라스크 프로그래밍은 웹 사이트 개발 외에도 게임이나 인공지능 분야에도 적용 가능한 유망한 분야입니다.\n\n\n본 강의를 통해 파이썬 플라스크 프레임워크에 대한 이해 및 응용 방법을 배우실 수 있습니다.\n\n\n\n\n누구를 위한 강의인가요?\n\n\n파이썬을 이용하여 웹 사이트 개발 및 운용을 담당하시는 분\n\n\n게임 혹은 인공지능 분야 개발자\n\n\n\n\n무엇을 배우나요?\n\n\n파이썬 설치하기\n\n\n플라이크 개발환경\n\n\n플라이크 프로젝트 생성\n\n\n파이참 설치\n\n\n플라스크 기초\n\n\n플라스크 애플리케이션 팩토리\n\n\n블루프린트로 라우팅 함수 관리\n\n\n모델로 데이터 처리\n\n\n질문 목록과 상세기능\n\n\n디자인 적용 하기\n\n\n질문 및 폼 모듈 작성\n\n\n\n\n파이썬 Flask(플라스크)를 이용한 웹 프로젝트 만들기 강의에 입문해봅시다~!\n\n\n그럼 강의에서 만나요 :)",
      "target_audience": [
        "파이썬을 이용하여 웹 사이트 개발 및 운용을 담당하시는 분",
        "게임 혹은 인공지능 분야 개발자"
      ]
    },
    {
      "title": "YOLOv5目标检测：原理与源码解析",
      "url": "https://www.udemy.com/course/yolov5-principle/",
      "bio": "计算机视觉目标检测实战",
      "objectives": [
        "学会YOLOv5的实现原理",
        "读懂YOLOv5源码"
      ],
      "course_content": {
        "课程介绍": [
          "课程介绍"
        ],
        "基础篇": [
          "目标检测之任务说明",
          "目标检测之常用数据集",
          "目标检测之性能指标和计算方法"
        ],
        "实践篇": [
          "Ubuntu系统上训练PASCAL VOC数据集",
          "Windows系统上训练PASCAL VOC数据集",
          "YOLOv5 V6.0更新"
        ],
        "原理篇": [
          "YOLO目标检测基本思想",
          "YOLOv5网络架构与组件",
          "YOLOv5损失函数",
          "YOLOv5目标框回归与跨网格预测策略",
          "YOLOv5训练技巧"
        ],
        "源码解析篇1-YOLOv5项目目录结构": [
          "YOLOv5项目目录结构"
        ],
        "源码解析篇2-模型构建相关代码解析": [
          "激活函数及代码",
          "网络组件代码",
          "Detect组件代码",
          "Model类代码"
        ],
        "源码解析篇3-数据集创建相关代码解析": [
          "矩形推理与letterbox代码",
          "数据增强原理与代码",
          "自定义数据集代码",
          "数据集相关类的代码",
          "dataloader相关代码"
        ],
        "源码解析篇4-general.py代码解析": [
          "辅助函数代码",
          "自动锚框计算代码",
          "AP计算代码",
          "build_targets代码",
          "loss计算代码",
          "非极大值抑制代码"
        ],
        "源码解析篇5-辅助工具代码解析": [
          "torch_utils代码",
          "experimental代码"
        ],
        "源码解析篇6-YOLOv5使用相关代码解析": [
          "detect.py代码解析",
          "test.py代码",
          "train.py代码解析1",
          "train.py代码解析2",
          "train.py代码解析3"
        ]
      },
      "requirements": [
        "熟悉Python和PyTorch"
      ],
      "description": "Linux创始人Linus Torvalds有一句名言：Talk is cheap. Show me the code. 冗谈不够，放码过来！代码阅读是从基础到提高的必由之路。\nYOLOv5是最近推出的轻量且高性能的实时目标检测方法。YOLOv5使用PyTorch实现，含有很多业界前沿和常用的技巧，可以作为很好的代码阅读案例，让我们深入探究其实现原理，其中不少知识点的代码可以作为相关项目的借鉴。\n本课程将详细解析YOLOv5的实现原理和源码，对关键代码使用PyCharm的debug模式逐行分析解读。 本课程将提供注释后的YOLOv5的源码程序文件。\n\n\n课程分为基础篇、实践篇、原理篇和代码解析篇。在实践篇中讲述了在ubuntu和windows系统上训练PASCAL VOC数据集的方法。在基础篇中讲述了目标检测的任务说明、常用数据集、性能指标和计算方法。在原理篇中讲述了YOLOv5的网络架构与组件、损失函数、目标框回归与跨网格预测策略、训练技巧。在代码解析篇中讲述了项目目录结构、模型构建、数据集创建、目标检测、辅助工具、以及使用的相关代码。",
      "target_audience": [
        "希望学习YOLOv5目标检测的实现原理与源码的同学们和从业者"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第八部 AI之眼2 動態追蹤與分析",
      "url": "https://www.udemy.com/course/generativa_ai_08/",
      "bio": "關於YOLO， OpenCV，TorchVision",
      "objectives": [
        "掌握如何使用YOLO標記物件",
        "掌握如何使用Norfair追蹤移動的物件",
        "掌握如何結合 HSV 和慣性分類器，實現更精確的視頻分析",
        "掌握多目標追蹤、物體分類和事件檢測等高級技術"
      ],
      "course_content": {
        "課程準備": [
          "課程工具準備",
          "如何使用Poetry"
        ],
        "導入視頻 & 導入預訓練模型": [
          "如何導入和導出視頻",
          "如何製作一個Yolo Class處理導入model和檢測動作"
        ],
        "如何處理Detector": [
          "如何製作Detector的abstractmethod與staticmethod",
          "如何獲得bounding box圖片列表",
          "如何導入Detector以及製作HSV顏色模型"
        ],
        "如何獲得處理圖片以及球隊分類": [
          "如何檢查並驗證HSV過濾器",
          "如何使用ColorFilter以及裁剪球衣",
          "如何獲得最多被選中像素的Filter名稱",
          "如何從BaseClassifier到Detections",
          "如何編寫慣性分辨器彌補移動物體移動軌跡"
        ],
        "控球率等信息的獲取": [
          "如何初始化球隊",
          "Match類別是做什麼",
          "如何使用Pillow做圖",
          "如何完成Draw類",
          "如何將絕對座標轉換成相對座標",
          "如何獲得箭頭3個點以及連線功能方法製作",
          "如何調用各種method完成繪製軌跡",
          "如何繪製Ball的絕對位置中心點",
          "如何定義Player添加球員到球隊中",
          "如何處理傳球和傳球事件",
          "如何計算控球率和相關功能定義"
        ],
        "視頻輸出與對象檢測": [
          "如何繪製計數器與控球率進度條",
          "如何實現DataFrame和Detection的轉換",
          "如何更新運動估算器",
          "如何製作Run以及項目主要流程",
          "如何製作深度學習神經網絡"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "在這個數字時代，視頻分析技術已經成為 AI 和機器學習領域中不可或缺的一部分。無論是智能監控、體育比賽分析還是自動駕駛，視頻中的物體檢測和分類都是核心技術。而在這些技術中，HSV 和慣性分類器憑借其出色的色彩處理能力和穩定性，成為了工程師和研究人員的首選。\n如果你對這些技術感興趣，或者希望掌握如何在自己的項目中應用這些技術，那麼我們的課程正是為你量身打造的！在這門課程中，你將學到：\n深入了解 HSV 色彩模型：學會如何利用 HSV 模型進行精確的顏色分割和物體分類，理解 HSV 模型相比於傳統 RGB 模型的優勢所在。\n實戰應用 HSV 分類器：通過實際項目案例，學習如何在視頻中應用 HSV 分類器，進行物體的檢測和追蹤。\n掌握慣性分類器的使用技巧：學會如何利用慣性分類器，讓你的物體分類更加穩定和準確，避免因光線變化或物體遮擋造成的識別錯誤。\n從零開始到精通：即使你是初學者，我們也會從最基礎的概念開始講解，並逐步帶你進入實戰應用，最終掌握這些技術。\n無論你是想提升自己在 AI 領域的技能，還是準備開發自己的視頻分析項目，這門課程都將是你不容錯過的選擇。立即報名，讓我們一起進入視頻分析的精彩世界！",
      "target_audience": [
        "計算機視覺領域的初學者",
        "AI 和機器學習開發者",
        "計算機科學與工程專業學生",
        "自動駕駛與智能監控技術愛好者"
      ]
    },
    {
      "title": "習うより慣れよう Visual AI さわって覚える人工知能「ディープラーニング編」",
      "url": "https://www.udemy.com/course/visual-ai-deep-learning/",
      "bio": "理屈よりも感覚で！コーディングなし、難しい数式なしで、ディープラーニングをパーセプトロンから、誤差逆伝播まで解説。ビッグデータの活用方法から、学習データの作成方法も紹介します。なかなか不可解な人工知能。理屈よりまずは見て触ってみましょう。",
      "objectives": [
        "プログラムと機械学習の違い",
        "ニューラルネットワークの基本と応用",
        "ディープラーニングに関係するいろいろな言葉とその使われ方",
        "手書き数字認識で理解する画像認識の方法",
        "重みの学習推移",
        "手書き文字認識での転移学習",
        "自分の書いた手書き文字で学習させてみる"
      ],
      "course_content": {
        "はじめに": [
          "はじめに",
          "コース概要"
        ],
        "人工知能入門": [
          "プログラムとの違い",
          "Scratch でプログラム",
          "回帰分析",
          "分類問題１",
          "分類問題２(ワインの分類問題　プログラム付き)",
          "画像認識の概要"
        ],
        "ニューラルネットワーク": [
          "ニューラルネットワークとは",
          "人工ニューロン",
          "人工ニューロン-複数入力",
          "パーセプトロン",
          "活性化関数",
          "バイアスとは",
          "線形分離1",
          "線形分離2",
          "多層パーセプトロン",
          "多層パーセプトロン（補習）",
          "多層パーセプトロン（四則演算）",
          "カテゴリーデータとOne-Hot Vector",
          "過剰適合（過学習）",
          "ドロップアウト１",
          "ドロップアウト２",
          "ドロップアウト３_重み減衰(weight decay)"
        ],
        "誤差逆伝播": [
          "順伝播",
          "誤差逆伝播",
          "微分基礎1",
          "微分基礎2",
          "計算グラフ（順伝播）",
          "計算グラフ（逆伝播）",
          "誤差逆伝播を算数で_Part1",
          "誤差逆伝播を算数で_Part2",
          "誤差逆伝播を算数で_Part3",
          "誤差逆伝播を算数で_Part4",
          "誤差逆伝播を算数で_Part5",
          "誤差逆伝播を算数で_Part6",
          "誤差逆伝播を算数で_解答"
        ],
        "ディープラーニング": [
          "このセクションの概要",
          "ディープニューラルネットワーク　その１（多層パーセプトロンと隠れ層）",
          "ディープニューラルネットワーク　その２",
          "畳み込みニューラルネットワーク",
          "画像認識の実際　習うより慣れろ。まずは手書き文字の認識を体験してみよう！",
          "画像認識の実際（番外編）",
          "フィルターとは",
          "畳み込みの計算",
          "畳み込みの逆伝播",
          "プーリング",
          "コーヒータイム",
          "フィルターの学習推移",
          "クロスエントロピー"
        ],
        "転移学習": [
          "転移学習の基本",
          "転移学習の実践１　棒グラフで確率分布を見てみよう！",
          "転移学習の実践２　自分の文字を学習させてみよう！",
          "学習ツールの補足説明",
          "課題：転移学習で独自画像の再学習"
        ]
      },
      "requirements": [
        "機械学習未経験者の方は「導入編」をみておくことが望ましいです。"
      ],
      "description": "理屈よりも感覚で。プログラムや難しい数式を使わないで、体感的で視覚的にディープラーニングを学んでいきます。このコースを終えたあとには、ＡＩ技術者とディープラーニングについてある程度の会話をすることができるようになっているはずです。プログラムまでやりたくない、数学まで勉強したくないという方にオススメです。一方ディープラーニングは初心者には易しく上級者には難しい技術なので、TensorFlowやChainerなどのサンプルプログラムを動かしたけれども何が起こっているのかよく理解できなかったという方にもお薦めします。機械学習、ディープラーニングのプログラミングのコースと並行して見ていくと、より理解が深まると思います。「つかめる」ディープラーニングにして欲しい、という要望に応えられるように構成しました。\nこのコースではビデオを見るだけでなく、実際にお手元のパソコンでその動きを体験できるようにプログラムコードを用意してあります。圧縮ファイルを解凍すれば、インストールすることなくブラウザ上で動きます。\n※コース後半では、自作の手書き文字を人工知能に学習させることができるレクチャーも用意しています。ディープラーニングのすごさを体験してみてください。\nDon't think! Just feel!\n\n\nレクチャーではコーディングについての解説はありませんが、プログラムを動かせる方は是非、教材用のコードをダウンロードして動かしてみてください。ニューラルネットワークの動きを生で体験できます。教材用のコードのうち、オリジナルのコードについては質問を受け付けています。プログラム未経験の方はコードについて深く考えずに、おおまかな仕組みや具体的な計算の流れを見ていきましょう。\n【BGMについて】\nビデオでは、環境音（ノイズ）を消すために小さなBGMを流しています。",
      "target_audience": [
        "ディープラーニングを直観的に理解したい方",
        "フレームワークやネットのサンプルを動かしたけれども、どういった仕組みで動いているのか、より理解を深めたい方",
        "ディープラーニングでの手書き文字の学習を実際に手元のパソコン上で試してみたい方",
        "データサイエンスに関心を持つ初級の開発者"
      ]
    },
    {
      "title": "Visualização de dados com R",
      "url": "https://www.udemy.com/course/visualizacao-dados-r/",
      "bio": "Demonstrações visuais eficientes de informações relevantes!",
      "objectives": [
        "Fundamentos da demonstração visual de dados",
        "Construções de gráficos elegantes e intuitivos",
        "Customização gráfica flexível e personalizada",
        "Dicas de boas práticas para demonstrações gráficas",
        "Exportação de gráficos em alta resolução de qualidade"
      ],
      "course_content": {
        "Apresentação e material do curso": [
          "Apresentação e instruções do curso",
          "Material do curso"
        ],
        "Fundamentos da visualização de dados e do ggplot2": [
          "Estruturas e funcionamento do ggplot2",
          "Pacotes auxiliares e guias (sheets) do ggplot2",
          "Práticas e cuidados para produzir gráficos de qualidade"
        ],
        "Produção de gráficos com ggplot2": [
          "Preparação de dados para uso no R",
          "Gráficos de dispersão (scatterplot)",
          "Histogramas e gráfico de densidade",
          "Gráfico de barras",
          "Gráficos de colunas e de barras (2 variáveis)",
          "Gráfico de barras para comparação de médias",
          "Gráficos de dispersão para variáveis contínuas",
          "Gráficos de Boxplot",
          "Gráfico de linhas",
          "Gráfico de pontos",
          "Gráficos para visualização de erros",
          "Gráficos 3D e Multivariados",
          "Gráficos com texturas"
        ],
        "Customização da estética gráfica": [
          "Mapeamento de gráfico de dispersão",
          "Mapeamento de gráficos de barras",
          "Mapeamento de gráficos de boxplot",
          "Sistemas de coordenadas: escalas, ordem e posição de eixos gráficos",
          "Ajustes de posições dos elementos no gráfico",
          "Temas e estilo de fundo do ggplot2",
          "Rotulação dos gráficos",
          "Inserção e modificação de legendas",
          "Facetas: separações de variáveis no gráfico",
          "Inserção de texto no gráfico",
          "Inserção de imagem no texto"
        ],
        "Salvar e exportar gráficos": [
          "Salvar gráficos em alta resolução"
        ],
        "Exercícios de aprimoramento": [
          "Exercícios"
        ]
      },
      "requirements": [
        "É desejável conhecimento básico de R (ex: instalação, uso de pacotes). Porém, o conteúdo é acessível a todos os públicos."
      ],
      "description": "A visualização de dados é uma parte essencial para demonstrar informações complexas e abstratas de maneira gráfica, compreensível e objetiva. Tal visualização permite converter dados brutos em formas bem definidas que facilitam a compreensão e idenitificação de padrões, contribuindo assim para tomadas de decisões importantes no processo analítico. Por isso, a visualização de dados é fundamental em diversas áreas, incluindo a acadêmica, negócios, marketing, educação, etc. Portanto, o uso de gráficos bem construídos e estruturados permite a comunicação eficiente de informações para diferentes públicos.\n\n\nO uso da linguagem do ambiente de programação R se destaca nas mais diversas aplicações para análises estatísticas. Mas o R também fornece excelentes pacotes para criação de gráficos e figuras para demonstração visual de dados. O pacote ggplot2 é o maior destaque no R para esse propósito. Esse pacote é baseado numa gramática de gráficos versátil que permite flexibilidade de customização durante a construção gráfica.\n\n\nNeste curso você será capaz de aplicar o ggplot2 em seus dados e análises para gerar elegantes gráficos customizados de acordo com as suas necessidades. Para isso, a abordagem desse curso é focada na prática com ggplot2, objetivando de conduzir a independência na construção gráfica de alta qualidade com a facilidade e robustez do R. O conhecimento adquirido no curso te fornecerá habilidades importantes e desejadas em analistas de dados nos mais variados setores.",
      "target_audience": [
        "Pesquisadores, professores, pós-graduandos, analistas de dados, analistas de negócio, estatísticos. Empresas e profissionais em geral que desejam enriquecer o currículo."
      ]
    },
    {
      "title": "HuggingFace de A à Z avec Python",
      "url": "https://www.udemy.com/course/huggingface-python/",
      "bio": "Apprends à utiliser l'inférence HuggingFace et les Transformers, et publie en ligne tes applications IA avec Python.",
      "objectives": [
        "Comprendre ce qu’est HuggingFace, son rôle central dans la communauté IA, et explorer les ressources incroyables qu’il propose (modèles, datasets, outils).",
        "Apprendre à utiliser cette bibliothèque phare pour développer des applications IA puissantes, en exploitant des modèles pré-entraînés pour diverses tâches.",
        "Créer des applications concrètes en quelques étapes avec des projets pratiques...",
        "Construire une véritable application web interactive, accessible en ligne."
      ],
      "course_content": {
        "Environnement de code": [
          "Installer Python et VSCode",
          "COURS COMPLET PYTHON (30 JOURS)"
        ],
        "Introduction HuggingFace": [
          "Qu'est-ce que Hugging Face ?",
          "L'ecosystème de Hugging Face"
        ],
        "Transformers": [
          "Travailler avec la bibliothèque Transformers"
        ],
        "Inférence": [
          "Introduction - Inférence",
          "Génération de texte et Résumé de texte",
          "Transcription d'un audio",
          "Générer une image",
          "Détection d'objets"
        ],
        "Spaces": [
          "Qu'est-ce qu'un space ?",
          "Créer une app Gradio",
          "Création d'un space"
        ],
        "Téléchargement code Python": [
          "Code source",
          "Newsletter Mon Shot Data (pour les plus curieux)"
        ]
      },
      "requirements": [
        "Une connaissance de base en Python est recommandée, mais aucune expérience préalable en IA ou machine learning n’est nécessaire. Tout sera expliqué de manière accessible et progressive."
      ],
      "description": "Plonge dans l’univers fascinant de l’intelligence artificielle avec ce cours complet et pratique sur HuggingFace et Python ! Conçu pour les développeurs, les data scientists et les passionnés de technologie, ce programme te guide pas à pas dans la maîtrise de l’écosystème HuggingFace, une plateforme incontournable pour créer des applications IA modernes, même si tu débutes dans ce domaine.\n\n\nCe que tu vas apprendre :\nDécouverte de l’écosystème HuggingFace : Comprends ce qu’est HuggingFace, son rôle central dans la communauté IA, et explore les ressources incroyables qu’il propose (modèles, datasets, outils, spaces).\nMaîtrise de la bibliothèque Transformers : Apprends à utiliser cette bibliothèque phare pour développer des applications IA puissantes, en exploitant des modèles pré-entraînés pour diverses tâches.\nExploitation de l’inférence HuggingFace : Crée des applications concrètes en quelques étapes avec des projets pratiques :\nGénération et résumé de texte : Produis des contenus ou condens des informations automatiquement.\nTranscription audio : Transforme des fichiers vocaux en texte avec précision.\nGénération d’images : Crée des visuels à partir de descriptions textuelles grâce à l’IA.\nDétection d’objets dans une image : Identifie et localise des éléments spécifiques sur des photos.\nDéploiement d’une application en ligne avec Gradio : Va au-delà de la théorie en construisant une véritable application web interactive, que tu publieras sur un Space HuggingFace pour la rendre accessible au monde entier.\n\n\nPourquoi choisir ce cours ?\nÀ travers des projets concrets, des démonstrations claires et des exercices pratiques, tu maîtriseras les outils et techniques pour intégrer l’IA dans tes propres projets. Chaque module est accompagné d’explications détaillées et de codes commentés pour consolider tes compétences. Que tu souhaites enrichir ton portfolio, lancer une application innovante ou explorer les possibilités de l’IA, ce cours est TON tremplin idéal.\n\n\nÀ qui s’adresse ce cours ?\nDéveloppeurs Python cherchant à se spécialiser dans l’IA et le machine learning.\nData scientists ou analystes désirant exploiter des modèles pré-entraînés pour des solutions rapides.\nÉtudiants ou curieux voulant découvrir et appliquer les technologies d’intelligence artificielle avec HuggingFace.\n\n\nPrérequis :\nUne connaissance de base en Python est recommandée, mais aucune expérience préalable en IA ou machine learning n’est nécessaire. Tout sera expliqué de manière accessible et progressive.\n\n\nRejoins ce cours dès aujourd’hui et transforme tes idées en applications IA révolutionnaires avec HuggingFace et Python.\n\nLance-toi dans l’avenir de la technologie dès maintenant !!",
      "target_audience": [
        "Développeurs Python cherchant à se spécialiser dans l’IA et le machine learning.",
        "Data scientists ou analystes désirant exploiter des modèles pré-entraînés pour des solutions rapides.",
        "Étudiants ou curieux voulant découvrir et appliquer les technologies d’intelligence artificielle avec HuggingFace."
      ]
    },
    {
      "title": "Do Conceito a PRÁTICA de BI (Conceito BI + SQL + ETL TALEND)",
      "url": "https://www.udemy.com/course/bi-sql-etl-talend/",
      "bio": "Aprenda os conceitos de Business Intelligence, Linguagem SQL para Consultar os Dados e o ETL com o TALEND para Integrar.",
      "objectives": [
        "O que é Business Intelligence",
        "O que é Data Warehouse",
        "Conhecendo o talend data integration",
        "Instalação o talend data integration",
        "Estrutura de funcionamento do talend data integration",
        "Construção do DW",
        "Entendendo Levantamento de Dados com Gestores - Matriz de Necessidades",
        "Entendendo como criar um documento alinhado ( Gessotr-Sistemas) - Fonte de Dados",
        "Entendo como criar um modelo multidimensional - Dimensão e Fato",
        "Carga da staging",
        "Transformação dos dados",
        "Carga tabela staging fato",
        "Carga da dimensão",
        "Carga da dimensão tempo",
        "Carga da fato",
        "Automatização das cargas",
        "Como trabalhar com a ferramenta ETL Open Source Talend Data integration",
        "Para que funciona uma ferramenta ETL",
        "Como realizar a integração de dados dentro do Talend Data integration",
        "Principais componentes do Talend: TFILEARCHIVE, TFILEUNARCHIVE,TFILECOMPARE E TFILEOUTPUTDELIMETED ,TFILECOPY E TFILELIST,TFILEDELETE E TJAVA",
        "Mais componentes: TFILEEXIST E TMSGBOX,TFILEROWCOUNT,TAGGREGATEROW, TSORTROW E TLOGROW, TREPLACE E TFILTERCOLUMN",
        "Mais componentes: TFILTERROW,TSPLITROW,TFILEINPUTXML, TLOGCATCHER , TROWGENERATION,TDIE E TLOGROW",
        "Mais componentes:TLOGCATCHER , TROWGENERATION,TWARN E TLOGROW ,TSENDMAIL",
        "Como exportar um projeto de desenvolvimento para produção",
        "Como importar um projeto para produção",
        "Aprendendo o uso das conhecidas variáveis de contexto",
        "Conceitos Básicos de Business Intelligence",
        "Fundamentos de Business Intelligence",
        "O que é um Data Warehouse",
        "O que é Staging Area, ETL, OLAP, Data Mart, Data Mining, Big Data",
        "BI (Business Intelligence) para Concursos",
        "Resolução de 50 questões de BI dos Principais Concursos",
        "Consultar dados com SQL em Banco de Dados",
        "Restringir e Classificar Dados utilizando a linguagem SQL",
        "Inserir Dados com SQL no Banco de Dados",
        "Editar Dados com SQL no Banco de Dados",
        "Excluir Dados com SQL no Banco de Dados",
        "Utilizar a Linguagem SQL no Oracle",
        "Utilizar o SQL Developer",
        "Aprender o SQL para uso nos bancos de dados padrão ANSI"
      ],
      "course_content": {
        "Resumo BI - Fundamentos de Business Intelligence": [
          "Conhecendo o Resumo BI (Teoria BI)",
          "INFORMAÇÕES IMPORTANTES - Leia antes de iniciar o curso",
          "O que é BI",
          "Data Warehouse",
          "OLTP X OLAP",
          "Características OLAP",
          "METADADOS",
          "Staging Area",
          "Dimensões",
          "Tabela Fato",
          "ETL",
          "Modelagem Dimensional",
          "Ferramentas BI (Gratuitas e Pagas)",
          "Conhecendo Data Mining",
          "BIG DATA e Seu Objetivo",
          "Resumo BI em PDF",
          "Aula Final dos Conceitos de BI",
          "Vamos responder ao nosso Quiz?"
        ],
        "50 Questões de concurso sobre Business Intelligence": [
          "Resolução de Questões - Parte 01",
          "Resolução de Questões - Parte 02",
          "Resolução de Questões - Parte 03",
          "Resolução de Questões - Parte 04",
          "Resolução de Questões - Parte 05",
          "Resolução de Questões - Parte 06",
          "Resolução de Questões - Parte 07",
          "Resolução de Questões - Parte 08",
          "Resolução de Questões - Parte 09",
          "Resolução de Questões - Parte 10"
        ],
        "Dominando a Linguagem SQL na PRÁTICA": [
          "Introdução ao Curso SQL Prático para Oracle - Simples, Fácil e Rápido",
          "Download do Oracle e SQL Developer",
          "Link Para Download do Banco Oracle XE e do SQL Developer",
          "Instalando Oracle e o SQL Developer",
          "Link para Download dos Bancos de Treinamento e Prática",
          "Criando o Banco de Treinamento e Prática",
          "Objetivos e Ferramentas para Conexão com o Banco de Dados Oracle",
          "Conceitos Importantes de Banco de Dados",
          "Entendendo o Modelo de Dados do Banco Treinamento e Prática",
          "Recuperando Dados - Conhecendo o SELECT",
          "Expressões Aritméticas e Valores Null",
          "ALIAS ou Apelidos em Consultas",
          "Operadores de Concatenação, DISTINCT e DESCRIBE",
          "Exercícios Práticos - Recuperando Dados através de SQL",
          "Restringindo os dados com comando WHERE",
          "Operadores de Comparação 1",
          "Operadores de Comparação 2",
          "Operadores para combinar Condições Lógicas e Regras de Precedências",
          "Classificando Dados",
          "Trabalhando com Variáveis de Substituição",
          "Exercícios Práticos - Restringindo e Classificando Dados",
          "Entendendo os Comandos DML",
          "Inserindo Dados com o INSERT, Editando com UPDATE e Excluindo com DELETE",
          "Controle de Transações",
          "Exercícios Práticos - Manipulação de Dados",
          "Respostas Exercícios SQL"
        ],
        "Talend Data Integration para DW": [
          "Introdução e Instalação do Talend Data Integration",
          "Download do Talend",
          "Instalação Banco de Dados ORACLE",
          "Entendendo como levantar dados com os gestores",
          "Entendendo como identificar os dados no Banco de Dados",
          "Apresentação de todo o material do curso",
          "Construindo a Staging Area",
          "Carga das tabelas da Staging Area",
          "Construindo as Dimensões - Parte 01",
          "Construindo as Dimensões - Parte 02",
          "Construindo a Dimensão TEMPO",
          "Entendendo a Modelagem Multidimensional",
          "Construindo a Fato - Parte 01",
          "Construindo a Fato - Parte 02",
          "Automatizando a Carga do DW"
        ],
        "Talend Data Integration - ETL eintegração de Dados": [
          "Introdução ao Talend",
          "Integração e Migração: Componentes tFileArchive e tFileUnarchive",
          "Integração e Migração: Componentes tFileCopy, tFileCompary dentre outros",
          "Integração e Migração: Componentes tFileDelete, tJava, tFileExist e tMsgBox",
          "Integração e Migração: Componentes tFileRowCount, tAggregateRow, tSortRow e tLog",
          "Integração e Migração: Componentes tReplace, tFilterColumn, tFilterRow",
          "Integração e Migração: Componentes tSplitRow, tFileInputXML",
          "Integração e Migração: Componentes tRowGeneration, tDie, tLogCatcher",
          "Variável de contexto, Exportar Job, Exportar Projeto, Importar Projeto"
        ]
      },
      "requirements": [
        "Conhecimento básico de Banco de Dados",
        "Noção Básica de Informática"
      ],
      "description": "Está procurando um curso para Aprender BI (Business Intelligence) ou a Linguagem SQL na Prática ou ainda aprender a utilizar uma das melhores soluções de integração de dados e ETL, no caso o TALEND? Se essa é sua busca  Seja bem vindo ao curso Do Conceito a PRÁTICA de BI (Conceito BI + SQL + ETL TALEND). Agora se você que se tornar um profissional da área de Dados, também seja muito bem vindo ao nosso curso. Neste treinamento 3 em 1 teremos um módulo que te entrega os fundamentos básicos sobre Business Intelligence, essenciais para quem quer iniciar, e além disso é um ótimo guia para quem quer estudar para concursos da área. Teremos o módulo de SQL prático para manipulação e exploração de dados, habilidades muito utilizadas na carreira de Business Intelligence. Já com a ferramenta TALEND poderá realizar a Extração, Transformação e Carga dos dados tudo de forma visual sem precisar conhecer de linguagem de programação.\nNo módulo RESUMO BI - Fundamentos de Business Intelligence você terá um Resumo Completo e Objetivo sobre os Fundamentos de Business Intelligence (BI), é assim que podemos considerar o Resumo BI - Fundamentos de Business Intelligence. Vamos te ajudar a entender os principais conceitos de Business Intelligence como O que é BI, Data Warehouse, OLTP, OLAP, Metadados, Modelagem Dimensional, Data Mining, Big Data, proporcionando a base necessária para o profissional que quer entrar na área de BI e ao mesmo tempo servindo de um excelente guia de referência para quem precisa de um material objetivo de BI para concursos.\nAlém disso, para quem está estudando para concursos, disponibilizamos 50 Questões de Concursos Relacionados a Assuntos de BI respondidas e comentadas em vídeo.\nJá o Curso SQL na Prática para Oracle - Simples, Fácil e Rápido foi desenvolvido pensando em você que quer apreender os principais comando de Consulta e Manipulação de Dados com a Linguagem SQL. O SQL é simplesmente a linguagem de banco de dados mais solicitada e utilizada no mercado e pelas maiores organizações do mundo quando falamos de manipulação de dados em banco de dados.\nEsse conteúdo também foi preparado para você que quer trabalhar como Desenvolvedor de Sistemas, Analista de Banco de dados, Analista SQL, DBA, Business Intelligence e outros afins ligados a Banco de Dados.\nNeste treinamento você terá a oportunidade de ver na prática e também de praticar os comandos SQL explicados, visualizando os resultados da obtenção dos dados no banco de dados Oracle.\nA escolha do estudo do SQL no Oracle foi para te dar a oportunidade de já trabalhar com um dos banco de dados mais utilizado no Mundo e por consequência onde a maioria das vagas que necessitam de conhecimento de SQL existem. Apesar de utilizarmos o ORACLE, o SQL apresentado será o no padrão ANSI permitindo assim seu uso em outros bancos de dados que seguem esse padrão como SQL SERVER, Postgres, MySQL e outros.\nAlém disso também iremos utilizar o SQL Developer, interface de conexão e consulta aos dados no Oracle. O conhecimento dessa ferramenta é importante para já te inserir a uma das ferramentas utilizadas no mercado de trabalho para uso do SQL.\nVocê no fim de cada módulo terá o desafio de resolver uma série de exercícios práticos para assim te ajudar na assimilação de todo conhecimento da Linguagem SQL no ORACLE.\nO Talend Data Integration é uma solução aberta e escalável de integração de dados e qualidade de dados para integrar, limpar e perfilar todos e qualquer tipo de dados.\nPossui mais de 900 componentes pré-construídos. Trabalha com armazenamento em nuvem , integração de dados , gerenciamento de dados , gerenciamento de dados mestre , qualidade de dados, preparação de dados e software e serviços de integração empresariais.\nSe você buscar aprender a integrar bases de diversos formatos, arquivos , dentre outros, deve conhecer a ferramenta open source que mais cresce no mercado, com um Front End agradável, fácil e super simples de interagir.\n\n\nSÃO DOIS GRANDES PROFESSORES COM LARGA EXPERIÊNCIA NA ÁREA DE BUSINESS INTELLIGENCE E BANCO DE DADOS",
      "target_audience": [
        "Estudantes de Estatística, Computação e Ciência dos Dados",
        "Profissionais que utilizam ferramentas de DW, BI, Data Discovery e OLAP",
        "Analista de Sistemas",
        "Analista Desenvolvedor",
        "Programador",
        "Analista de Banco de Dados",
        "Analista de Business Intelligence",
        "Qualquer Profissional que deseja Aprender a Consultar e Manipular os dados em Banco de Dados com a Linguagem SQL e o PLSQL",
        "Estudantes ou Profissionais que estejam aprendendo Business Intelligence"
      ]
    },
    {
      "title": "Aprende a manipular datos con Polars y Python",
      "url": "https://www.udemy.com/course/aprende-a-manipular-datos-con-polars-y-python/",
      "bio": "Domina la manipulación avanzada de datos: crea, transforma y visualiza datos de forma eficiente con Polars y Python",
      "objectives": [
        "Conocer Polars y su filosofía",
        "Crear y manipular Series de Polars",
        "Leer y escribir diferentes tipos de formatos de archivos con Polars",
        "Crear y manipular los DataFrame de Polars",
        "Crear y manipular los LazyFrame de Polars",
        "Trabajar con una amplia gama de expresiones y funciones de Polars",
        "Ejecutar consultas SQL con Polars",
        "Realizar gráficas a partir de un DataFrame de Polars"
      ],
      "course_content": {},
      "requirements": [
        "En nuestro curso, no hay límites de conocimiento: solo necesitas tu curiosidad y ganas de aprender para embarcarte en el emocionante mundo de Polars."
      ],
      "description": "En este curso, aprenderás a manejar datos de manera eficiente y poderosa utilizando Polars, una innovadora biblioteca de Python diseñada para el análisis y manipulación de grandes volúmenes de datos. Polars ofrece una alternativa rápida y moderna a las bibliotecas tradicionales como Pandas, optimizando tus flujos de trabajo y mejorando el rendimiento de tus aplicaciones de datos.\n\n\nNo importa tu nivel de experiencia previa, este curso te proporcionará las herramientas y el conocimiento necesarios para convertirte en un experto en la manipulación avanzada de datos con Polars y Python. ¡Inscríbete y transforma tu forma de trabajar con datos!\n\n\n¿Qué aprenderás en este curso?\n\n\nConocer Polars y su filosofía: Descubrirás los principios fundamentales y la filosofía detrás de Polars, comprendiendo por qué es una herramienta eficaz para la manipulación de datos.\nCrear y manipular Series de Polars: Aprenderás a crear y manejar Series, las estructuras básicas de datos en Polars, facilitando el análisis y la transformación de datos.\nLeer y escribir diferentes tipos de formatos de archivos con Polars: Dominarás la importación y exportación de datos en diversos formatos como CSV, JSON y Parquet, permitiendo una integración fluida con múltiples fuentes de datos.\nCrear y manipular los DataFrame de Polars: Te convertirás en un experto en la construcción y transformación de DataFrames, la estructura principal para el manejo de datos tabulares en Polars.\nCrear y manipular los LazyFrame de Polars: Utilizarás LazyFrames para ejecutar operaciones de manera lazy, optimizando el rendimiento y eficiencia en el procesamiento de datos.\nTrabajar con una amplia gama de expresiones y funciones de Polars: Aplicarás diversas expresiones y funciones para realizar operaciones complejas y eficientes sobre los datos, aumentando la flexibilidad y capacidad de análisis.\nEjecutar consultas SQL con Polars: Integrarás la funcionalidad de SQL dentro de Polars, permitiéndote realizar consultas avanzadas y combinar el poder de SQL con la flexibilidad de Polars.\nRealizar gráficas a partir de un DataFrame de Polars: Aprenderás a visualizar tus datos mediante la creación de gráficos claros y efectivos, mejorando la comunicación de tus análisis.",
      "target_audience": [
        "Profesionales que buscan herramientas eficientes y modernas para manejar grandes volúmenes de datos.",
        "Aquellos que desean mejorar sus habilidades en la manipulación y análisis de datos con una alternativa rápida a Pandas.",
        "Expertos que quieren explorar nuevas bibliotecas y metodologías para optimizar sus flujos de trabajo.",
        "Profesionales interesados en construir y mantener pipelines de datos eficientes utilizando Polars.",
        "Aquellos que necesitan manejar datos a gran escala y optimizar el rendimiento de sus procesos de ETL (extracción, transformación y carga).",
        "Desarrolladores interesados en implementar soluciones de datos rápidas y eficientes en sus aplicaciones.",
        "Estudiantes de informática, estadística, matemáticas y disciplinas relacionadas que quieren aprender herramientas avanzadas para el análisis de datos.",
        "Analistas y consultores en BI que desean mejorar sus habilidades en la manipulación y visualización de datos para generar informes y dashboards más eficientes.",
        "Profesionales que buscan actualizarse con las últimas tecnologías en análisis de datos."
      ]
    },
    {
      "title": "画像生成系AI「Stable Diffusion」の使い方や画像生成のテクニックをPythonやAPIを使って学ぼう！",
      "url": "https://www.udemy.com/course/stable-diffusion-python/",
      "bio": "StableDiffusionをHaggingFace、DreamStudio、StableStudio、Fooocusなどを使って動かしてみよう！PythonでAPIを叩いて動かしてみよう！画像生成のテクニックを知ろう！",
      "objectives": [
        "画像生成系AIの概要",
        "Stable DiffusionをHaggingFaceやDreamStudioやStableStudioやFooocusを使って動かす方法",
        "Stable DiffusionをPythonで動かす方法",
        "プロンプトエンジニアリングのコツ"
      ],
      "course_content": {
        "画像生成系AI概要": [
          "コース紹介",
          "受講に際しての注意点",
          "HaggingFaceとStableDiffusionのリポジトリページ",
          "Stable Diffusionとは"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibについて学ぼう！",
          "Seabornについて学ぼう！"
        ],
        "Stable Diffusionを実際に使って画像生成してみよう！": [
          "HaggingFaceのDemoページから画像生成してみよう！",
          "HaggingFaceに提供されているモデルをPythonで動かしてみよう！",
          "DreamStudioから画像生成してみよう！",
          "DreamStudioのAPIを使ってみよう！",
          "DreamStudioのAPIを使ってみよう！②"
        ],
        "プロンプトエンジニアリングのコツ": [
          "画像保存ではなくて画像表示にプログラムを修正",
          "画像生成プロンプトエンジニアリングのコツ①",
          "スタイルチートシート：描画スタイル",
          "画像生成プロンプトエンジニアリングのコツ②：描画スタイル",
          "スタイルチートシート：画家のスタイル",
          "画像生成プロンプトエンジニアリングのコツ③：画家のスタイル"
        ],
        "オープンソースプログラムを使ってStableDiffusionを使ってみよう！": [
          "オープンソースのStableStudioとFooocusのリンク",
          "DreamStudioのオープンソースであるStableStudioとは？",
          "DreamStudioのオープンソースであるStableStudioを動かしてみよう！",
          "オープンソースであるFooocusを動かしてみよう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonをある程度理解していることが望ましいですが初心者でも大丈夫です"
      ],
      "description": "本コースへようこそ！\n\n\nこのコースでは話題の画像生成系AIであるStableDiffusionについて学んでいきます。\n\n\n実はStableDiffusionを動かす方法はいくつかあります。\nこの講座では\n・HaggingFaceのデモページからStableDiffusionを動かす方法\n・HaggingFaceで公開されているStableDiffusionのモデルをPythonで動かす方法\n・StabilityAIが有償公開しているDreamStudioの使い方\n・DreamStudioのAPIをPythonで使う方法\n・オープンソースStableStudioをローカルで立ち上げてStableDiffusionを動かす方法\n・オープンソースFooocusをGoogleColabで立ち上げてStableDiffusionを動かす方法\nなど様々な方法を学んでいきます。\n\n\nまた、画像生成において重要な\n・プロンプトエンジニアリング\n・画像生成する際におさえておくと便利な様々なスタイル\nなども併せて学んでいきます。\n\n\nぜひStableDiffusionを使って色んな画像を生成できるようになりましょう！",
      "target_audience": [
        "最近の画像生成系AIに興味を持っている人",
        "AIの進化に取り残されたくない人",
        "Stable Diffusionを使って色んな画像を生成してみたい人",
        "Stable Diffusionを動かす様々な方法を知りたい人"
      ]
    },
    {
      "title": "ChatGPT Marketing: Curso completo de ChatGPT",
      "url": "https://www.udemy.com/course/chatgpt-marketing-curso-completo-de-chatgpt-2023/",
      "bio": "ChatGPT: Domine o ChatGPT, Crie campanhas de Marketing com ChatGPT e alavanque suas Vendas com o Chat GPT!",
      "objectives": [
        "Aprenda a utilizar o ChatGPT para criar uma Campanha de Marketing do Zero",
        "Como produzir conteúdo no Instagram de maneira Automática com o ChatGPT",
        "Encontre seu Público Alvo com o ChatGPT",
        "Aprenda a usar o ChatGPT para criar conteúdo de marketing e vendas",
        "Descubra como criar excelentes Copys com o ChatGPT",
        "Aprenda Criar anúncios no Facebook com a Inteligência do ChatGPT",
        "Aprenda a ganhar Dinheiro no Youtube com o ChatGPT",
        "Aprenda a Fazer vídeos no Tiktok com o ChatGPT",
        "Como usar o ChatGPT para criar roteiro de vídeos no Youtube",
        "Aprenda a Usar o ChatGPT para melhorar o SEO de seu Site"
      ],
      "course_content": {
        "Boas Vindas e Primeiros Passos": [
          "Boas Vindas",
          "Download Ebook ChatGPT + 50 Prompts",
          "O que é o ChatGPT?",
          "Criando uma Conta no ChatGPT",
          "Como formular boas Perguntas/Comandos ao ChatGPT?"
        ],
        "Cronograma/Calendário abrangente de Conteúdo para impulsionar seu Marketing": [
          "Desenvolvendo um calendário de conteúdo para sua campanha de Marketing"
        ],
        "Estabelecendo o Público Alvo com auxílio do ChatGPT": [
          "Importância de ter o seu Público Alvo definido",
          "Utilizando ChatGPT para definir o Público Alvo e Avatar"
        ],
        "Criando Posts para Instagram/Facebook na Prática com o ChatGPT!": [
          "Como automatizar criação de Posts com o ChatGPT",
          "Como criar um Post para o Feed do Instagram com o ChatGPT",
          "Como criar um Post Carrossel para o Instagram com o ChatGPT",
          "Como criar um Reels e Stories com o ChatGPT"
        ],
        "Criando Artigos e Postagens para Blogs/Sites [SEO com ChatGPT]": [
          "Encontrando as Melhores Palavras Chaves e Títulos para seu Blog com ChatGPT",
          "Escrevendo um artigo para seu Site otimizado em SEO com ChatGPT"
        ],
        "Criando uma Campanha de Email Marketing na Prática com ChatGPT": [
          "Importância do Email Marketing na sua estratégia de Marketing",
          "Criando sequências de Email com o ChatGPT"
        ],
        "Criando uma Página de Vendas Completa com o ChatGPT": [
          "Criando a Copy de uma Página de Vendas Completa com o ChatGPT"
        ],
        "Criando Campanhas no Facebook e Google Ads com ChatGPT": [
          "Criando campanhas no Facebook e Instagram Ads com o ChatGPT",
          "Criando campanhas no Google Ads com o ChatGPT"
        ],
        "Criando Vídeos no Youtube com o Chatgpt": [
          "Como ter Idéias de Conteúdo Infinitas com o ChatGPT",
          "Criando roteiro/Script para um Vídeo no Youtube em segundos",
          "SEO do seu Vídeo no Youtube com o ChatGPT"
        ],
        "Criando Vídeos no Tiktok com o Chatgpt": [
          "Como ter Idéias de Conteúdo Infinitas com o ChatGPT",
          "Criando roteiro/Script para um Vídeo no Tiktok em segundos"
        ]
      },
      "requirements": [
        "Não é necessário conhecimento prévio para participar do Curso"
      ],
      "description": "O ChatGPT é uma das mais avançadas tecnologias de inteligência artificial, capaz de fornecer respostas precisas e personalizadas para diversas perguntas e tópicos. Este curso abrangente foi projetado para ajudá-lo a aproveitar ao máximo as capacidades do ChatGPT, aprendendo a usá-lo para obter respostas, soluções e insights em diferentes contextos.\nAo se inscrever no Curso Completo de ChatGPT, você irá:\nAprender a UTILIZAR o ChatGPT para vender mais, desenvolver estratégias de marketing e criar conteúdo com êxito\nAplicar o ChatGPT em diferentes contextos, como pesquisa, trabalho, educação e comunicação escrita\nDominar esses conceitos para ter mais liberdade e segurança para gerar riqueza!\nEste curso é projetado para ajudar profissionais de todas as áreas a aprender como usar o ChatGPT para obter informações e insights úteis, desde profissionais de marketing e vendas até pesquisadores, educadores e profissionais de tecnologia. Ele também é adequado para estudantes que desejam melhorar suas habilidades de pesquisa e comunicação escrita.\nAo longo do curso, você irá:\nAprender os fundamentos do ChatGPT, incluindo como ele funciona e como interagir com ele para fazer perguntas\nAprender como usar o ChatGPT para obter respostas sobre diversos tópicos e para ganhar dinheiro\nDescobrir como usar o ChatGPT para criar conteúdo na internet, incluindo em plataformas como YouTube, Instagram e TikTok\nAprender como usar o ChatGPT para aprimorar a escrita e comunicação interpessoal\nDescobrir como usar o ChatGPT para fins educacionais e de aprendizagem\nAprender como usar o ChatGPT para criar conteúdo para marketing e vendas\nExplorar futuras possibilidades de aplicação do ChatGPT em diferentes áreas e setores.\nE mais!\nAo se inscrever no Curso Completo de ChatGPT, você receberá:\nAcesso vitalício ao curso e todas as atualizações\nSuporte personalizado e respostas às suas perguntas\nCertificado de conclusão Udemy, que pode ser incluído em seu currículo\nGarantia de devolução do dinheiro de 30 dias, se não gostar do curso, podes pedir o reembolso de 100%\nEste curso é ideal para profissionais de todas as áreas que desejam aprender como usar o ChatGPT para obter informações e insights úteis, desde iniciantes até avançados. Com este curso, você estará preparado para enfrentar os desafios e oportunidades do mundo moderno, bem como para obter o máximo benefício do ChatGPT e da inteligência artificial.",
      "target_audience": [
        "Profissionais de Marketing que desejam ser mais produtivos",
        "Profissionais de Marketing",
        "Proprietários de Pequenas empresas que querem aperfeiçoar o conhecimento em Marketing",
        "Entusiastas de Inteligência Artificial",
        "Qualquer pessoa que deseje utilizar o ChatGPT para agregar no seu negócio",
        "Qualquer pessoa que queira aprender e colocar em prática a ferramenta do ChatGPT"
      ]
    },
    {
      "title": "【初心者向け】数理最適化を学び線形計画問題や整数計画問題など様々な最適化問題をPythonで解けるようになろう！",
      "url": "https://www.udemy.com/course/math-optimization/",
      "bio": "数理最適化（線形計画問題や整数計画問題など）の主要例題である生産計画最適化問題、輸送最適化問題、ナップサック問題、巡回セールスマン問題をPythonで解けるようになろう！",
      "objectives": [
        "数理最適化の概念について",
        "線形計画法とシンプルな解法",
        "生産計画最適化問題をPythonで解く方法",
        "輸送最適化問題をPythonで解く方法",
        "ナップザック問題をPythonで解く方法",
        "巡回セールスマン問題をPythonで解く方法"
      ],
      "course_content": {
        "紹介": [
          "紹介"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Searbornについて学ぼう！",
          "Python構文の復習"
        ],
        "数理最適化とは？": [
          "数理最適化とは？線形計画問題とは？"
        ],
        "生産最適化問題をPythonで解いてみよう！": [
          "目的関数や制約条件を定義していこう！",
          "線形計画問題を解いて答えを出力してみよう！",
          "変数を3つに増やした場合の線形計画問題を解いてみよう！",
          "Pulpを使って線形計画問題と整数計画問題を解いてみよう！"
        ],
        "輸送問題を解いてみよう！": [
          "問題の確認と変数の設定をしていこう！",
          "目的関数の設定をしていこう！",
          "供給能力の制約条件を設定していこう！",
          "需要の制約条件を設定して最適化問題を解いていこう！"
        ],
        "ナップサック問題を解いてみよう！": [
          "変数設定から目的関数の設定までやっていこう！",
          "制約条件の設定をして問題を解いていこう！"
        ],
        "巡回セールスマン問題を解いてみよう！": [
          "問題設定と最初の定義を確認しよう！",
          "変数と目的関数を設定しよう！",
          "各都市に1回だけ訪問し1回だけ出発する制約条件を作っていこう！",
          "部分巡回（サブツアー）を除去する制約条件を作っていこう！",
          "最適解を求めて結果を表示してみよう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学びますのでプログラミングの知識は特に必要ありません",
        "数式はほぼ登場しませんので数学の素養はそれほど必要ありません"
      ],
      "description": "このコースでは、数理最適化について学んでいきます。\n\n\n数理最適化問題には様々な種類があるのですが、その中から\n・生産計画最適化問題\n・輸送最適化問題\n・ナップサック問題\n・巡回セールスマン問題\nなど、いくつか有名なものをピックアップして取り上げていきます。\n\n\nまずは、よく登場する線形計画問題について取り上げつつ、他の最適化問題についても見ていきます。\n\n\nPythonを使って色んな数理最適化問題を解いていきましょう！\n\n\n実際にビジネスシーンでは最適化アプローチが必要になることが多いのでしっかり理解しておきましょう！",
      "target_audience": [
        "様々な問題を最適化するアプローチに興味のある方",
        "数理最適化問題をPythonを使って解くことに興味のある方"
      ]
    },
    {
      "title": "เรียน Python Data Wrangling Programming สำหรับ Data Science",
      "url": "https://www.udemy.com/course/pythondatawrangling/",
      "bio": "เรียนเขียนโปรแกรม Python Data Wrangling with Pandas สำหรับผู้เริ่มต้นสายงาน Data Science Zero to Hero",
      "objectives": [
        "ผู้เรียนจะเข้าใจกระบวนการทำงานของ Data Wrangling สำหรับงานด้าน Data Science",
        "ผู้เรียนจะได้รับความเข้าใจเกี่ยวกับเนื้อหาของการเขียนโปรแกรมภาษา Python เพื่อทำความสะอาดและวัดคุณภาพของข้อมูลได้ด้วยตนเอง",
        "ผู้เรียนสามารถเขียนโปรแกรมภาษา Python ตั้งแต่ขั้นเริ่มต้นดูข้อมูลไปจนถึงขั้นการสร้างภาพข้อมูล",
        "ผู้เรียนสามารถนำความรู้ที่ได้ไปประยุกต์ใช้ทำ Data Wrangling Projects ต่าง ๆ ในการเรียนและการทำงานจริงได้"
      ],
      "course_content": {
        "เรียนรู้กระบวนการวิเคราะห์ข้อมูลและลงมือทำความสะอาดข้อมูลด้วยตนเอง": [
          "เรียนรู้กระบวนการวิเคราะห์ข้อมูลและลงมือทำความสะอาดข้อมูลแบบเข้าใจง่าย"
        ],
        "เรียนเขียนโปรแกรม Python Data Wrangling with Pandas ระดับพื้นฐาน Basic Level": [
          "Workshop 1: เริ่มต้นดูข้อมูลของคุณก่อน",
          "Workshop 2: การเลือกและจัดระเบียบคอลัมน์",
          "Workshop 3: การเลือกแถว",
          "Workshop 4: สร้างค่าความถี่ให้กับข้อมูล",
          "Workshop 5: การสร้าง Summary Statistics สำหรับ Continuous Variables"
        ],
        "เรียนเขียนโปรแกรม Python Data Wrangling with Pandas ระดับกลาง Intermediate Level": [
          "Workshop 6: ตรวจหาค่าที่หายไป ใส่ค่าข้อมูล และลบแถวที่หายไป",
          "Workshop 7: การลบข้อมูลแถวที่ซ้ำกัน",
          "Workshop 8: ใช้ groupby จัดระเบียบข้อมูลตามกลุ่ม",
          "Workshop 9: ใช้ Aggregation Functions groupie จัดข้อมูลตามกลุ่ม"
        ],
        "เรียนเขียนโปรแกรม Python Data Wrangling with Pandas ระดับสูง Advanced Level": [
          "Workshop 10: สร้างฟังก์ชันใช้เองกับ groupby จัดข้อมูลตามกลุ่ม",
          "Workshop 11: สร้างฟังก์ชันสำหรับตรวจดูคุณภาพข้อมูล",
          "Workshop 12: สร้างฟังก์ชันแสดง Summary Statistics และ Frequencies",
          "Workshop 13: การสร้าง Class และเรียกใช้งาน Functions ทำความสะอาดข้อมูล",
          "Workshop 14: การสร้างภาพข้อมูลเพื่อตรวจสอบแนวโน้มในตัวแปรต่อเนื่อง"
        ]
      },
      "requirements": [
        "ผู้เรียนไม่จำเป็นต้องมีความรู้ด้านการเขียนโปรแกรมมาก่อน คุณจะได้เรียนรู้ทุกสิ่งที่คุณอยากเรียน"
      ],
      "description": "หลักสูตร เรียน Python Data Wrangling Programming สำหรับ Data Science\nสามารถเรียนได้ทุกคน ไม่จำเป็นต้องมีความรู้ด้านการเขียนโปรแกรมมาก่อน\nเนื้อหาการเรียน Python Data Wrangling Programming with Pandas\nแบ่งเป็น 4 ส่วน\nส่วนที่ 1: เรียนรู้กระบวนการวิเคราะห์ข้อมูลและลงมือทำความสะอาดข้อมูลด้วยตนเอง\nIntroduction เรียนรู้กระบวนการวิเคราะห์ข้อมูลและลงมือทำความสะอาดข้อมูลแบบเข้าใจง่าย\nส่วนที่ 2: เรียนเขียนโปรแกรม Python Data Wrangling with Pandas ระดับพื้นฐาน Basic Level\nWorkshop 1 เริ่มดูข้อมูลของคุณก่อน\nWorkshop 2 การเลือกและจัดระเบียบคอลัมน์\nWorkshop 3 การเลือกแถว\nWorkshop 4 สร้างค่าความถี่ให้กับข้อมูล\nWorkshop 5 การสร้าง Summary Statistics สำหรับ Continuous Variables\nส่วนที่ 3: เรียนเขียนโปรแกรม Python Data Wrangling with Pandas ระดับกลาง Intermediate Level\nWorkshop 6 ตรวจหาค่าที่หายไป ใส่ค่าข้อมูล และลบแถวที่หายไป\nWorkshop 7 การลบข้อมูลแถวที่ซ้ำกัน\nWorkshop 8 ใช้ groupby จัดระเบียบข้อมูลตามกลุ่ม\nWorkshop 9 ใช้ Aggregation Functions groupie จัดข้อมูลตามกลุ่ม\nส่วนที่ 4: เรียนเขียนโปรแกรม Python Data Wrangling with Pandas ระดับสูง Advanced Level\nWorkshop 10 สร้างฟังก์ชันใช้เองกับ groupby จัดข้อมูลตามกลุ่ม\nWorkshop 11 สร้างฟังก์ชันสำหรับตรวจดูคุณภาพข้อมูล\nWorkshop 12 สร้างฟังก์ชันแสดง Summary Statistics และ Frequencies\nWorkshop 13 การสร้าง Class และเรียกใช้งาน Functions ทำความสะอาดข้อมูล\nWorkshop 14 การสร้างภาพข้อมูลเพื่อตรวจสอบแนวโน้มในตัวแปรต่อเนื่อง",
      "target_audience": [
        "ผู้เริ่มต้นเรียนรู้การเขียนโปรแกรม นักพัฒนาโปรแกรม โปรแกรมเมอร์ ที่สนใจงานด้าน Data Science"
      ]
    },
    {
      "title": "Python と JavaScript による機械学習アプリケーション公開入門【ONNX・Render】",
      "url": "https://www.udemy.com/course/mnist-app/",
      "bio": "自分が作った機械学習モデルを他の人もさわれるアプリケーションとして公開する方法を学んで、機械学習に関わるデータサイエンティスト・PM・PdM としてステップアップしましょう！",
      "objectives": [
        "Git・GitHub の使用方法の基礎",
        "ブラウザにおける JavaScript の基礎",
        "Python と JavaScript を使った Web アプリケーションの実装方法",
        "ONNX 形式でのモデルの出力と ONNX Runtime を使った推論方法",
        "PaaS (Render) を使ったアプリケーションのデプロイ方法",
        "静的サイトホスティングサービスを使ったアプリケーションの公開方法"
      ],
      "course_content": {
        "はじめに": [
          "このコースについて",
          "受講ガイド",
          "(Windows の場合) WSL 2 のセットアップ"
        ],
        "最小限だけ学ぶ Git・GitHub 入門": [
          "Git とは・GitHub とは",
          "GitHub でリポジトリを作成",
          "リポジトリをローカルに clone する",
          "Git のコマンドを最小限学ぶ"
        ],
        "Python のセットアップ": [
          "Python のセットアップ方針について",
          "Python をインストールするために asdf をインストール",
          "（補足）asdf のセットアップについて",
          "asdf で Python をインストール",
          "asdf で poetry をインストール",
          "poetry で学習コード用のプロジェクトを初期化",
          "Python の Hello World"
        ],
        "MNIST を使った学習コードを実装してモデルを作成": [
          "このセクションの目標",
          "scikit-learn のインストール",
          "（追記）poetry add コマンドのエラーについて（'HTTPResponse' object has no attribute 'strict'）",
          "MNIST のデータを確認",
          "MNIST の学習",
          "ONNX とは",
          "モデルを ONNX 形式で保存",
          "画像データを入力形式に変換",
          "Python の ONNX Runtime で推論を試す"
        ],
        "ブラウザにおける JavaScript の超入門": [
          "なぜ JavaScript なのか",
          "JavaScript の Hello World",
          "変数・定数 (let・const)",
          "配列・for ループ・while ループ",
          "分岐と falsy",
          "3 種類の方法で関数を定義する",
          "JavaScript のコールバックを学ぶ",
          "DOM 操作の基本"
        ],
        "手書き数字推論アプリケーションの実装": [
          "このセクションで実装するアプリケーションの仕組み",
          "poetry で Web アプリケーションのプロジェクトを初期化",
          "FastAPI の Hello World",
          "FastAPI を使った HTML の Hello World",
          "手書き数字推論アプリケーションの HTML を実装",
          "StaticFiles の設定",
          "CSS を実装",
          "canvas への手書き機能を実装",
          "JavaScript と Python の疎通",
          "推論結果を画面に表示",
          "画像データの送信",
          "ONNX Runtime を使った推論処理を実装",
          "推論に使用した画像を画面に表示",
          "このセクションのまとめ"
        ],
        "PaaS (Render) を使った機械学習アプリケーションの公開": [
          "Web アプリケーションを動かすプラットフォームの基本",
          "Render を使って Web アプリケーションを公開",
          "Render の無料プランの制約"
        ],
        "静的ホスティングサービスを使った機械学習アプリケーションの公開": [
          "このセクションで実施する内容の説明",
          "静的サイト実装の準備",
          "JavaScript で画像の前処理を実装",
          "ONNX Runtime Web を使った推論処理を実装",
          "Render で静的サイトホスティング",
          "このセクションのまとめ"
        ],
        "おわりに": [
          "さらにステップアップするには",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "学習・推論・モデルといった単語が分かる程度の機械学習の基礎知識がある",
        "Python でのプログラミングの基礎知識がある",
        "絶対パス・相対パス程度のコンピュータの基礎知識がある",
        "ターミナルで ls、cd などの基本的なコマンドを実行したことがある",
        "プログラミングに使用可能な PC を所有している"
      ],
      "description": "近年、機械学習に入門するための情報源は非常に多くなっており、機械学習モデルの作成には気軽に取り組めるようになっています。\n個人でも、ちょっとしたモデルを作ってみて手元で推論してみたことがある方は少なくありません。\n\n\nしかし、個人が作ってみたモデルを、実際に推論を試せるアプリケーションとして「公開」している方は少ないです。\nまた、企業においても、データサイエンティストが R&D 的に作成したモデルを実際のアプリケーションに組み込む段階で苦戦している例は多いです。\nそんな状況に対応するため、近年「MLOps」というキーワードも登場しています。\n\n\nこのコースでは、機械学習を使ったアプリケーションの「公開」に興味があるデータサイエンティスト・PM・PdM といった方を主な対象者として、Python と JavaScript で機械学習を使った Web アプリケーションを実装し、実際にインターネット上に公開してみます。\n\n\n実装するのは MNIST で学習したモデルを使った「手書き数字推論アプリケーション」です。\nPython の scikit-learn で学習したモデルを ONNX 形式で出力して、他のプログラミング言語 (ここでは JavaScirpt) で推論を実行する例も学習します。\n\n\nキーワード\nGit/GitHub、Python、JavaScript、FastAPI、scikit-learn、MNIST、ONNX、Render\n\n\n更新履歴\n2023/05/12「（補足）asdf のセットアップについて」を追加\n2023/05/24「（追記）poetry add コマンドのエラーについて（'HTTPResponse' object has no attribute 'strict'）」を追加",
      "target_audience": [
        "自分が作ったモデルを使い、簡単なアプリケーションを実装して公開してみたいデータサイエンティストの方",
        "機械学習については知識があるが、アプリケーション開発についても学びたいと思っている PM・PdM といったポジションの方",
        "機械学習をアプリケーションに組み込む方法を学びたいアプリケーションエンジニアの方"
      ]
    },
    {
      "title": "Conception et optimisation de prompts pour l'IA",
      "url": "https://www.udemy.com/course/lessentieldupromptengineering/",
      "bio": "Intelligence artificielle, Sciences des données, Ingenierie des prompt",
      "objectives": [
        "Comprendre les enjeux et mécanismes de l’ingénierie des prompts pour les modèles de langage",
        "Concevoir et structurer des prompts efficaces selon différents formats (instruction, few-shot, CoT, etc.)",
        "Adapter les prompts à différents modèles de langage (OpenAI, Anthropic, Mistral, etc.)",
        "Intégrer des prompts dans des applications concrètes : agents conversationnels, assistants métier, RAG, etc."
      ],
      "course_content": {
        "Introduction et syllabus du cours": [
          "Introduction",
          "C'est quoi l'ingénierie des prompts ?",
          "Benefices et limites de l'ingénierie des prompt",
          "Écosystème des plateformes d’ingénierie des prompts",
          "Partie 1 Initiation à l'ingénierie des prompts: texte",
          "Partie 2 Initiation pratique à l'ingenierie des prompt: analyse d'image",
          "Partie 3 Initiation à l'ingenierie des prompts: audio et memoire",
          "Partie 4 creation d'interface utilisateur avec gradio",
          "Ressources de lecture",
          "Quizz"
        ],
        "Modele de conception en ingénierie des prompts": [
          "Comment écrire un prompt de qualité ?",
          "Element clés d'un prompt",
          "Qu'entend-on par modèle de prompt ?",
          "Modéle Persona et modele persona inversé",
          "TP Modele Persona",
          "TP Modèle Persona inversé",
          "TP Modéle d'interaction inversée",
          "Modéle de prompt avec N exemples",
          "Modéle de stimulation orientée",
          "Gabarit de prompt",
          "Modele de meta-langage",
          "Resume du catalogue de modele",
          "Modele de prompt"
        ],
        "Modeles avancés de conception en ingénierie des prompts": [
          "Modele de chaine de raisonnement",
          "TP Chaine de raisonnement",
          "Modele d'auto-coherence",
          "TP Modèle d'auto-coherence",
          "Modele du raisonnement du plus simple au plus complexe",
          "TP raisonnement du plus simple au plus complexe",
          "Modéle ReAct",
          "TP Modéle ReAct",
          "Tree of Thought",
          "Ressources à lire",
          "Modeles avancés de prompt"
        ],
        "Bonnes pratiques et recommandations en ingénierie des prompts": [
          "Bonnes pratiques en ingénierie des prompt",
          "Generer de meilleurs prompts automatiquement et rapidement",
          "Optimiser et améliorer les prompts automatiquement",
          "Compréhension des modèles de tarification des API des LLM",
          "Parametres de generation dans les LLM",
          "Critéres de choix d'un LLM",
          "Quelques ressources",
          "Questions sur les bonnes pratiques"
        ],
        "Ingenierie des prompts dans les plateformes commerciales d’API pour LLM": [
          "Principales plateformes commerciales d’API pour LLM",
          "Travaux pratiques: conception de prompts avec les LLMs d'OpenAI",
          "Travaux pratiques: conception de prompts avec Gemini",
          "Questions sur les LLMs commerciaux"
        ],
        "Ingenierie des prompts avec les LLMs opensource": [
          "Principales plateformes opensource d'API de LLMs",
          "Travaux pratiques: conception de prompts avec Meta-llama de HuggingFace",
          "Travaux pratiques: conception de prompts avec Meta-llama de Groq",
          "Avantages et inconvénients de l'ingénierie des prompts avec les LLMs opensources",
          "Questions sur les LLMs opensource ?"
        ],
        "Experimentation": [
          "Partie 1: Ingénierie des prompts sur des taches réelles avec GPT et llama",
          "Partie 2: Ingénierie des prompts sur des taches réelles, expérimentation avec GP",
          "Prompting dans un contexte multimodal avec Google Gemini: image et pdf",
          "Ingénierie des prompts dans un contexte multimodal avec Google Gemini: Audio",
          "Ingenierie des prompt avec gemini dans un contexte multimodal: video",
          "Ingénierie des prompts dans un contexte multimodal avec OpenAI chatGPT: base64",
          "Ingenierie des prompts dans un contexte multimodal: traitement par url",
          "Ingénierie des prompts dans un contexte multimodal avec OpenAI: Videos, audio",
          "Projet final"
        ]
      },
      "requirements": [
        "Experience intermédiaire necessaire en python mais pas fondamentale"
      ],
      "description": "Maîtrisez l’ingénierie des prompts, la compétence-clé pour exploiter le plein potentiel de l’IA générative\nDans un monde où les modèles de langage comme GPT-4, Claude, Gemini ou LLaMA redéfinissent nos façons de travailler, l'ingénierie des prompts devient une compétence incontournable. Ce cours vous plonge dans l'art de concevoir des instructions claires, efficaces et stratégiques pour guider l'intelligence artificielle avec précision.\nAu fil de modules structurés, vous apprendrez à formuler différents types de prompts (zero-shot, few-shot, chain-of-thought), à résoudre des tâches complexes par le raisonnement et à appliquer des modèles de conception comme ReAct pattern, ou tree of thought.\nVous explorerez des cas réels dans des domaines variés : rédaction, analyse de données, santé, juridique, service client, recherche scientifique… Grâce à des exercices interactifs, des outils no-code et code, ainsi que des retours personnalisés, vous serez à même de concevoir des prompts robustes, pertinents et adaptés à votre métier.\nLe cours aborde également les bonnes pratiques, les pièges à éviter, et les différences entre les modèles open source et commerciaux. Il vous vous également dans le choix du meilleur LLM adapté à votre projet.\nAccessible à tous niveaux, il offre un accompagnement pédagogique, des ressources téléchargeables et une certification.\nRejoignez-nous et transformez durablement votre manière d’interagir avec l’intelligence artificielle.",
      "target_audience": [
        "developpeurs, mathématiciens, informaticiens, étudiants, professionnels en informatique"
      ]
    },
    {
      "title": "Chat GPT: Guia Completo (2023) + Ebook: 500 Prompts",
      "url": "https://www.udemy.com/course/chat-gpt-guia-completo-2023-ebook-500-prompts/",
      "bio": "Domine Inteligência Artificial ChatGPT: Use Chat GPT e outras ferramentas para aumentar produtividade.",
      "objectives": [
        "O que é Chat GPT",
        "ChatGPT para criar SEO em E-commerce : estratégias de otimização de mecanismos de busca em plataformas como Amazon, Mercado Livre, Shopee e Dropshipping.",
        "Copywriting de Vendas com o ChatGPT: Aprenda a usar o ChatGPT para criar cópias persuasivas e eficazes para impulsionar suas vendas.",
        "Técnicas para Conteúdo Personalizado no YouTube: Descubra como o ChatGPT pode ajudar a criar conteúdo lucrativo e envolvente para o seu canal no YouTube.",
        "Ganhe Dinheiro com o ChatGPT: Aprenda maneiras de monetizar o seu uso do ChatGPT e transformá-lo em uma fonte de renda.",
        "Crie Prompts Eficientes: Domine a arte de criar prompts eficientes, incluindo prompts básicos, moderados e meta prompts, para obter respostas mais precisas e di",
        "Desenvolvimento de Diálogos Personalizados: Aprenda técnicas para desenvolver diálogos eficientes e personalizados usando o ChatGPT.",
        "Listas de Prompts: Acesse listas de prompts prontas para uso, projetadas para ajudar você a obter melhores resultados com o ChatGPT.",
        "Crie anúncios profissionais para Google ads, facebook e Instagram para qualquer tipo de plataforma",
        "Acelere seu Aprendizado: Saiba como utilizar o ChatGPT e o ChatGPT Plus para aprender de forma mais eficiente e rápida."
      ],
      "course_content": {
        "Introdução": [
          "Apresentação do curso",
          "Explorando a interface do ChatGPT",
          "Criando a conta no ChatGPT",
          "Entendendo o ChatGTP 4",
          "O Que são os Prompts",
          "Colocar Emojis nas respostas dos prompts"
        ],
        "O Poder do chatGPT - Prompts de Diversos Nichos": [
          "Introdução - O Poder do ChatGPT - Exemplos de Prompts (copywriter)",
          "Prompts ChatGPT com overleaf para Professor Parte 1 (LATEX)",
          "Prompts ChatGPT com overleaf para Professor Parte 2 (LATEX)",
          "Prompts para Especialistas em SEO Parte 1",
          "Prompts para Especialistas em SEO Parte 2",
          "Prompts Gestores de Redes Sociais Parte 1",
          "Prompts Gestores de Redes Sociais Parte 2",
          "Prompts para contratos",
          "Prompts para Landing page",
          "Prompts para especialista de negócios Parte 1",
          "Prompts para especialista de negócios Parte 1",
          "Prompt Moderado calendários",
          "Cronograma e é documento com 500 promtps"
        ]
      },
      "requirements": [
        "Qualquer pessoa interessada em Inteligência Artificial.",
        "Qualquer pessoa interessada em aprender só precisa de um computador ou celular com acesso a Internet.",
        "Qualquer pessoa que quer ganhar dinheiro com Chat GPT."
      ],
      "description": "\"Imersão Completa no Universo do Chat GPT: Descubra o ChatGPT 4 e Muito Mais\"\nApresentamos a você um curso abrangente de Chat GPT que mergulha profundamente no mundo da Inteligência Artificial (IA), com foco no sofisticado chatbot ChatGPT 4. Este curso de imersão proporcionará uma experiência prática e aplicada, equipando você com habilidades essenciais para extrair o máximo de produtividade do ChatGPT 4, ao mesmo tempo em que desenvolve habilidades avançadas de conversação.\nAo participar deste curso, você não apenas compreenderá o funcionamento do ChatGPT 4, mas também entenderá seu papel no contexto mais amplo da IA, juntamente com inovações como BingAI, DALL-E2 da OpenAI e Nvidia Maxine. Além disso, você aprenderá a integrar essas poderosas ferramentas em seus próprios projetos, capacitando-se para criar soluções personalizadas e eficazes.\nExploraremos também a intersecção entre IA e SEO (Search Engine Optimization), fornecendo técnicas para monetizar seu conhecimento em IA e utilizar essa compreensão para impulsionar o tráfego orgânico em seus projetos. Você descobrirá como a IA é aplicada para melhorar a transcrição e acessibilidade no Adobe Podcast, além de aprender como aplicar essas técnicas em seus próprios empreendimentos.\nA estrutura do curso é dividida em oito módulos detalhados:\n\n\n\n\n\n\nEste curso é ideal para qualquer pessoa que queira dominar a IA e maximizar seu potencial em seu trabalho, carreira ou projetos pessoais. Estamos ansiosos para vê-lo em breve!",
      "target_audience": [
        "Qualquer pessoa que quer aprender sobre o Chat GPT",
        "Quem deseja ganhar dinheiro com Chat GPT",
        "Criadores de Conteúdo",
        "Designers",
        "Programadores",
        "Profissionais de TI",
        "Professores e Alunos"
      ]
    },
    {
      "title": "【한글자막】 R 프로그래밍: Data Science 에서의 R 고급 분석",
      "url": "https://www.udemy.com/course/best-r-advanced/",
      "bio": "R에서 분석할 데이터를 준비하고, 중앙값 대체법을 실행, date-times 다루는 방법에 대해 학습하고 리스트, Apply 계열 함수 등 고급 분석까지 R과 R 스튜디오 사용 능력 업그레이드 | GGPlot2",
      "objectives": [
        "R에서 데이터 준비하기",
        "데이터 프레임에서 누락된 레코드 확인하기",
        "데이터 프레임에서 누락된 레코드 찾기",
        "누락된 레코드를 대체하기 위해 중앙값 대체법 적용하기",
        "누락된 레코드를 대체하기 위해 사실적 분석법 적용하기",
        "which() 함수 사용법 이해하기",
        "데이터 프레임 인덱스 재설정 하는 법 알기",
        "gsub() 및 sub() 함수를 사용하여 문자열 교체하기",
        "NA가 왜 논리 상수의 세 번째 유형인지 설명하기",
        "R에서 date-times 사용하기",
        "date-times를 POSIXct 시간 형식으로 변환하기",
        "R에서 리스트를 만들고, 사용하고, 수정하고, 이름 바꾸고, 접근하고, 서브셋하기",
        "리스트를 다룰 때 언제 [], [[]], $기호를 쓰는지 이해하기",
        "R에서 시계열 플롯 만들기",
        "Apply 계열 함수가 어떻게 작동하는지 이해하기",
        "for() 루프로 apply 문 다시 만들기",
        "행렬에서 apply() 사용하기",
        "리스트와 벡터에서 lapply()와 sapply() 사용하기",
        "apply문에 자신만의 함수 추가하기",
        "apply(), lapply(), sapply() 함수들 서로 감싸기"
      ],
      "course_content": {
        "코스에 오신 것을 환영합니다.": [
          "도전을 환영합니다!",
          "R 프로그래밍 고급 코스에 오신 것을 환영합니다!",
          "보너스: 학습 경로",
          "보너스: Hadley Wickham과 인터뷰",
          "자료 받기",
          "더 좋은 데이터 과학자가 되는 지름길!",
          "성공을 위한 학습 팁"
        ],
        "데이터 준비": [
          "이 섹션에 오신 것을 환영합니다. 여러분이 배울 내용을 소개합니다!",
          "프로젝트 개요: 재무 검토",
          "데이터를 R로 가져오기",
          "요인이란 무엇인가(복습)",
          "요인 변수 함정(FVT)",
          "FVT 예제",
          "gsub() 및 sub()",
          "누락된 데이터 처리",
          "NA는 무엇인가?",
          "누락된 데이터 우아하게 찾기",
          "데이터 필터: 누락되지 않은 데이터에 which() 사용하기",
          "데이터 필터: 누락된 데이터에 is.na() 사용하기",
          "누락된 데이터 레코드 삭제",
          "데이터 프레임 인덱스 재설정하기",
          "누락된 데이터 교체하기: 사실적 분석법",
          "누락된 데이터 교체하기: 중앙값 대체법(파트 1)",
          "누락된 데이터 교체하기: 중앙값 대체법(파트 2)",
          "누락된 데이터 교체하기: 중앙값 대체법(파트 3)",
          "누락된 데이터 교체하기: 가치 파생법",
          "결과 시각화하기",
          "섹션 복습",
          "데이터 준비"
        ],
        "R에서의 리스트": [
          "이 섹션에 오신 것을 환영합니다. 여러분이 배울 내용을 소개합니다!",
          "프로젝트 개요: 기계 활용률",
          "데이터를 R로 임포트하기",
          "R에서 Date-Times 사용하기",
          "R 프로그래밍: 리스트란 무엇인가?",
          "리스트의 구성 요소에 이름 붙이기",
          "리스트에서 구성 요소 추출하기: [] 대 [[]] 대 $",
          "구성 요소 추가 및 삭제하기",
          "리스트 서브셋하기",
          "시계열 플롯 만들기",
          "섹션 복습",
          "R에서의 리스트"
        ],
        "“Apply” 계열 함수": [
          "이 섹션에 오신 것을 환영합니다. 여러분이 배울 내용을 소개합니다!",
          "프로젝트 요약: 날씨 패턴",
          "데이터를 R로 임포트하기",
          "R 프로그래밍: Apply 계열은 무엇인가?",
          "apply() 사용하기",
          "루프로 apply 함수 재현하기(고급 주제)",
          "lapply() 사용하기",
          "lapply()와 [] 결합하기",
          "자신만의 함수 추가하기",
          "sapply() 사용하기",
          "apply() 함수들 감싸기",
          "which.max()와 which.min() (고급 주제)",
          "섹션 복습",
          "\"Apply\" 계열 함수",
          "감사 보너스 비디오"
        ],
        "축하합니다!! 상품을 잊지 마세요 :)": [
          "챌린지를 완료하신 것을 진심으로 축하드립니다!",
          "보너스: 최고 연봉을 잠금 해제하는 방법 (라이브 교육)",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "R 기본 지식",
        "GGPlot2 패키지에 대한 지식이 있는 것이 좋습니다",
        "데이터 프레임에 대한 지식",
        "벡터 및 벡터화 연산에 대한 지식"
      ],
      "description": "R 프로그래밍 능력 향상을 위한 데이터 분석 강의!\n실제 사례 연구 포함!\n*R 프로그래밍 경험이 없는 분들께는 적합하지 않습니다*\n\n\nR 프로그래밍: Data Science 에서의 R 고급 분석 강의를 선택해야 하는 이유\n기본적인 R 지식이 있으신 분들을 위해서 이 코스를 준비했습니다.\n\n\nR 프로그래밍 능력을 한 단계 업그레이드할 준비됐나요?\nR을 사용한 데이터 과학 및 분석을 정말로 잘하고 싶나요?\n\n\n그렇다면 이 코스는 당신을 위한 것입니다!\n\n\nR을 전문가 수준으로 배울 수 있는 영상 강의, 수십년의 업계 경험을 살려 만든 특별한 데이터셋, 현실 세계의 분석을 경험할 수 있는 재밌는 연습 문제를 제공합니다.\n\n\nR 프로그래밍: Data Science 에서의 R 고급 분석 강의는 아래와 같이 진행 됩니다\n이 코스에서는 다음을 배울 것입니다.\nR에서 분석할 데이터를 준비하는 방법\nR에서의 중앙값 대체법을 실행하는 방법\nR에서 date-times 다루는 방법\n리스트란 무엇이고 어떻게 사용하는지\nApply 계열 함수는 무엇인지\n루프 대신 apply(), lapply(), sapply()를 사용하는 방법\napply유형 함수들 안에 자신만의 함수를 넣는 방법\napply(), lapply(), sapply() 함수를 서로 감싸는 방법\n그리고 훨씬 더 많은 것들!\n\n\n이 코스에는 실생활 실제 사례 연구가 준비되어 있습니다.\n첫 번째 섹션에서는 금융 데이터를 정리하고 분석을 위해 준비하는 법을 배웁니다. 다양한 산업 분야의 수익, 비용 및 이익을 보여주는 차트들을 만들 것입니다.\n두 번째 섹션에서는 다양한 데이터를 분석하여 석탄 터미널에서 어떤 기계가 덜 활용되고 있는지 알 수 있도록 도울 것입니다.\n세 번째 섹션에서는 기상청으로 갑니다. 날씨 패턴을 더 잘 이해하도록 도울 것입니다.\n\n\n\n\nLigency Team의 한마디!\n한국 수강생 여러분, 안녕하세요?\n\n\n여러분은 더 배울수록 데이터 과학 분야에서 더욱 성장할 것입니다.\n코스를 마치면 데이터 과학 업계에서 일할 수 있는 강력한 기술 활용 능력을 갖게 될 것입니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n데이터 사이언스 업계에서 역량을 더욱 마음껏 발휘할 수 있도록 강력한 기술을 배워보세요!\n강의에서 만나요,\n\n\n- Ligency Team",
      "target_audience": [
        "기본적인 R 지식이 있고 자기 능력을 한 단계 업그레이드하고 싶은 분",
        "R 프로그래밍 A-Z 코스를 수료하신 분"
      ]
    },
    {
      "title": "완전 초보자, 코딩없이 매력적인 R 차트 쉽게 만들기",
      "url": "https://www.udemy.com/course/r-data-visualization-for-total-beginers/",
      "bio": "R을 설치도 해 본적 없는 완전 초보자들이 논문에 낼 차트를 쉽게 만들도록 해 드립니다.",
      "objectives": [
        "다양한 데이터 시각화 종류들을 선택할 수 있는 능력",
        "자신의 데이터의 성격에 맞는 차트를 만들 수 있는 능력",
        "R의 다양한 데이터 시각화 도구를 활용할 수 있는 능력",
        "데이터 시각화를 통해 데이터를 들여다 볼 수 있는 능력",
        "논문의 결론을 매력적으로 보여줄 차트를 만드는 능력",
        "코딩없이 데이터로 다양한 R 차트를 만들 수 있는 능력"
      ],
      "course_content": {
        "Introduction and Basics": [
          "dot plot, jitter plot, box plot, violin plot",
          "Densitogram and Histogram",
          "Plot with error bar (II)",
          "Plot with error bar (I)"
        ],
        "Advanced": [
          "Matrix Correlations(II)",
          "Grouped Correlation Plot",
          "Kaplan-Meier Plot & Table"
        ],
        "5개의 링크 소개": [
          "제 1 링크",
          "제 2 링크- 단순한 변수",
          "제 3 링크- 다양한 변수 / 지도",
          "제 4 링크- 시간과 관련된 차트 / 통계와 차트",
          "제 5 링크- 그외의 차트 / 반응형 차트",
          "제 6 링크"
        ]
      },
      "requirements": [
        "인터넷이 연결되는 컴퓨터",
        "프로그래밍이 필요하지 않습니다. R 스크립트를 몰라도 할 수 있습니다."
      ],
      "description": "숫자로만 표로만 데이터를 정리하면 이해하기 힙듭니다.\n논문에서도 발표에서도 독자들도 심사 위원도 이해하기 어렵습니다.\n자신의 결론을 확실하게 보여 준 매력적인 R 차트를 쉽게 만들어 보세요.\n\n\n데이터를 다루고 분석하는 일은 누구라도 필요합니다.\n데이터 과학자가 아니더라도, 학교 선생님, 공무원, 공무원, 경찰, 농부와 어부,\n주부와 학생도 모두 데이터를 적절히 쉽게 시각화 하는 일은 필수적입니다.\n\n\n목적\n1.  R을 설치조차 해 보지 않은 사람조차,\n컴퓨터는 엑셀에 숫자와 글자를 입력하고 저장할 줄만 아는 사람도\nR을 이용해서 데이터 시각화를 할 수 있도록 해 주는 것이 이번 강의의 첫번째 목적입니다.\n\n\n2.  세상에서 보게 되는 다양한 데이터 시각화의 종류들을 살펴 보고 선택할 수 있는 능력을  가져야 합니다.\n이미 데이터 시각화에 익숙하고 R에 익숙한 사람조차\n자신이 사용하는 것 외에 다른 것들에 대해서는 잘 모를 수있습니다.\n다양한 사람들이 다양한 데이터의 특성에 맞도록 개발한 것을 살펴 보고,\n그것을 만들 수 있다는 것은 자신을 표현할 수 있는 강력한 도구를 얻는 것입니다.\n\n\n3. 어떤 논문이 채택될까요? 어떤 논문이 읽힐까요?\n사람들은 차트를 봅니다. 차트가 가장 적은 시간으로 가장 효과적으로 결과를 보여 주기 때문입니다.\n그러므로 자신의 논문을 매력적인 R 차트로 표현해 보세요.\n이 강의는 이것을 가능하게 해 줍니다.\n\n\n아무쪼로 이 두 가지 목적을 충분히 이루시길 희망합니다.",
      "target_audience": [
        "데이터 과학자",
        "다양한 종류의 연구자, 대학원생, 박사과정 학생",
        "데이터 시각화에 관심있는 사람 모두",
        "논문을 쓰는 사람"
      ]
    },
    {
      "title": "R数据分析与可视化训练营： 数据分析篇",
      "url": "https://www.udemy.com/course/r-mpcvnj/",
      "bio": "30年资深讲师倾心讲授：描述性统计分析、相关性分析（皮尔逊相关系数和斯皮尔曼相关系数）和 统计模型与推断分析、时间序列建模、AR、MA、ARMA和ARIMA",
      "objectives": [
        "描述性统计：中心趋势、离散程度等测量及可视化",
        "数据分组与汇总：分组、汇总与数据透视表操作",
        "相关性分析：相关系数计算及可视化",
        "统计模型基础：概率分布与参数估计",
        "回归分析：线性与逻辑回归原理及应用",
        "时间序列：分解、AR、MA 等多种模型"
      ],
      "course_content": {
        "描述性统计分析": [
          "8.1.1 均值",
          "8.1.1 均值【动手实践】",
          "8.1.2 均值与数据可视化",
          "8.1.2 均值与数据可视化【动手实践】",
          "8.1.3 中位数",
          "8.1.3 中位数【动手实践】",
          "8.1.4 中位数与数据可视化",
          "8.1.4 中位数与数据可视化【动手实践】",
          "8.1.5 众数",
          "8.1.5 众数【动手实践】",
          "8.1.6 众数与数据可视化",
          "8.1.6 众数与数据可视化【动手实践】",
          "8.2.1 极差",
          "8.2.2 方差",
          "8.2.2 极差和方差【动手实践】",
          "8.2.3 方差与数据可视化",
          "8.2.3 方差与数据可视化【动手实践】",
          "8.2.4 标准差",
          "8.2.4 标准差【动手实践】",
          "8.2.5 标准差与数据可视化",
          "8.2.5 标准差与数据可视化【动手实践】",
          "8.3.1 四分位数",
          "8.3.2 异常值",
          "8.3.2 异常值【动手实践】",
          "8.3.3 箱线图与四分位数和异常值分析",
          "8.3.3 箱线图与四分位数和异常值分析【动手实践】",
          "8.4.1 数据分组操作",
          "8.4.1 数据分组操作【动手实践】",
          "8.4.2 数据汇总操作",
          "8.4.2 数据汇总操作【动手实践】",
          "8.4.3 使用数据透视表进行汇总",
          "8.4.3 使用数据透视表进行汇总【动手实践】"
        ],
        "相关性分析": [
          "9.1 相关性分析概述",
          "9.2.1 计算皮尔逊相关系数",
          "9.2.1 计算皮尔逊相关系数【动手实践】",
          "9.2.2 示例：计算小鸡生长天数与体重的皮尔逊相关系数",
          "9.2.2 示例：计算小鸡生长天数与体重的皮尔逊相关系数【动手实践】",
          "9.3.1 计算斯皮尔曼相关系数",
          "9.3.1 计算斯皮尔曼相关系数【动手实践】",
          "9.3.2 示例：计算小鸡生长天数与体重的斯皮尔曼相关系数",
          "9.3.2 示例：计算小鸡生长天数与体重的斯皮尔曼相关系数【动手实践】",
          "9.4.1 散点图与相关性分析",
          "9.4.1 散点图与相关性分析【动手实践】",
          "9.4.2 热力图与相关性分析",
          "9.4.2 热力图与相关性分析【动手实践】"
        ],
        "统计模型与推断分析": [
          "10.1.1 概率分布",
          "10.1.2 参数估计",
          "10.2.1 线性回归分析",
          "10.2.1 线性回归分析【动手实践】",
          "10.2.2 示例：线性回归分析预测马力与油耗的关系",
          "10.2.2 示例：线性回归分析预测马力与油耗的关系【动手实践】",
          "10.2.3 逻辑回归分析",
          "10.2.3 逻辑回归分析示例",
          "10.2.3 逻辑回归分析示例【动手实践】",
          "10.3 时间序列分析基础",
          "10.3.1 时间序列的分解",
          "10.3.1 时间序列的分解【动手实践】",
          "10.3.2 示例：AirPassengers数据集的时间序列分解与可视化分析",
          "10.3.2 示例：AirPassengers数据集的时间序列分解与可视化分析【动手实践】",
          "10.4 时间序列建模",
          "10.4.1 自回归模型 (AR)",
          "10.4.1 自回归模型 (AR)示例：采用AR模型预测AirPassengers数据集",
          "10.4.1 自回归模型 (AR)示例：采用AR模型预测AirPassengers数据集【动手实践】",
          "10.4.2 移动平均模型(MA)",
          "10.4.2 移动平均模型(MA)示例：采用MA模型预测AirPassengers数据集",
          "10.4.2 移动平均模型(MA)示例：采用MA模型预测AirPassengers数据集【动手实践】",
          "10.4.3 自回归滑动平均模型(ARMA)",
          "10.4.3 自回归滑动平均模型(ARMA)示例：采用ARMA模型预测AirPassengers数据集",
          "10.4.3 自回归滑动平均模型(ARMA)示例：采用ARMA模型预测AirPassengers数据集【动手实践】",
          "10.4.4 自回归积分滑动平均模型(ARIMA)",
          "10.4.4 自回归积分滑动平均模型(ARIMA)示例：采用ARIMA模型预测AirPassengers数据集",
          "10.4.4 自回归积分滑动平均模型(ARIMA)示例：采用ARIMA模型预测AirPassengers数据集【动手实践】",
          "**后记（本节可以下载使所有课件和代码）"
        ]
      },
      "requirements": [
        "参加《R数据分析与可视化训练营：R语言语法基础篇、数据可视化基础篇、 数据可视化高级篇课程",
        "熟练 R基本语法",
        "熟练R基本绘图工具Base R",
        "熟练R基本绘图工具ggplot2"
      ],
      "description": "本章节将深入探索相关性分析，这是数据分析中的一个关键领域。学生将通过理论学习和实践应用，理解并掌握多种相关性系数的计算方法，以及如何利用可视化工具来展示变量之间的关系。\n相关性分析概述\n开始部分将介绍相关性分析的基本概念，强调其在数据分析中的重要性。同时，将探讨不同类型的变量之间如何进行相关性分析，为后续的深入学习奠定基础。\n皮尔逊相关系数\n在本节中，将详细讲解皮尔逊相关系数的计算方法，它适用于评估两个连续变量之间的线性关系。通过一个实际的案例——小鸡生长天数与体重的关系，将演示如何计算皮尔逊相关系数并解释其实际意义。\n斯皮尔曼相关系数\n斯皮尔曼相关系数是另一种常用的相关性度量，它适用于评估两个变量之间的单调关系，不要求数据正态分布。本节将介绍斯皮尔曼相关系数的计算方法，并通过与皮尔逊相关系数相似的案例，展示其在不同场景下的应用。\n相关性分析数据可视化\n数据可视化是理解变量之间关系的重要工具。在本节中，将教授如何利用散点图直观地展示两个变量之间的关系，并通过散点图的形态判断相关性的强度和类型。此外，还将介绍热力图在展示多个变量间相关性矩阵中的应用，帮助学生快速识别变量间的复杂关系。",
      "target_audience": [
        "统计学专业学生",
        "其他理工科专业学生",
        "数据分析师",
        "市场调研人员",
        "金融从业者",
        "科研工作者"
      ]
    },
    {
      "title": "Analisis de Streaming de Datos | Portafolio Data Engineer",
      "url": "https://www.udemy.com/course/analisis-de-streaming-de-datos-portafolio-data-engineer/",
      "bio": "Data Streaming | Kafka Streams | AWS | Flink | AWS Kinesis | Druid | Grafana | Análisis Near Real Time",
      "objectives": [
        "Aprenderas a simular tu propia data desde CERO",
        "Aprenderas a enviar datos a Kinesis Data Stream",
        "Aprenderas a enviar datos a un topico de Apache Kafka",
        "Aprenderas a entregar Streaming de datos con Kinesis Firehose",
        "Aprenderas a analizar streaming de datos con Apache Flink",
        "Aprenderas a consultar datos con Apache Druid",
        "Aprenderas a consultar datos con Amazon Athena",
        "Monitorearas tus datos con la ayuda de Grafana",
        "Construiras notificaciones con la ayuda de las Step Functions y SNS"
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Valoraciones",
          "Metodologia"
        ],
        "Aprende a simular tu propio Streaming de Datos": [
          "Introducción casos a simular",
          "Descripción Caso de estudio #1 - Ecommerce de Tecnología Simulado",
          "Ecommerce simulado parte 1",
          "Ecommerce simulado parte 2",
          "Descripción Caso de estudio #2 - Eventos Megatienda en su App Mobil",
          "Eventos App Simulados- Parte 1",
          "Eventos App Simulados- Parte 2",
          "Challenge Sección #1"
        ],
        "Proyecto # 1 - Analiza Ventas de un Ecomerce de Tecnologia Simulado Con Druid": [
          "Introducción al Proyecto #1",
          "Recomendaciones Importantes Costos EC2",
          "Como Crear una Instancia Gratuita en EC2",
          "Deploy Apache Druid en una instancia EC2",
          "Configuración Cluster de Kafka desde Confluent Cloud",
          "Envio de compras simuladas a Confluent Cloud",
          "Integración Kafka con Apache Druid",
          "Querys a las ventas registradas con Apache Druid",
          "Challenge Proyecto #1"
        ],
        "Proyecto #2 - Analiza Eventos de tu App Mobil con Kinesis Data Stream y Athena": [
          "Introducción al Proyecto #2",
          "Recomendaciones Importantes Costos AWS Kinesis",
          "Envio a Kinesis Data Stream",
          "Conexión Kinesis Data Stream , Kinesis Firehose y S3",
          "Analiza tu data simulada en AWS Athena",
          "Challenge Proyecto #2"
        ],
        "Proyecto #3 - Monitorea tus Streaming de Datos con Grafana | Step Functions": [
          "Introducción al Proyecto #3",
          "Creación de Dasboards en Grafana",
          "Alertas Grafana Parte 1",
          "Alertas Grafana Parte 2",
          "Creando una Step Functions y notificaciones SNS - Parte 1",
          "Creando una Step Functions y notificaciones SNS - Parte 2",
          "Notificación Correo Parte 1",
          "Regla de automatización con EventBridge",
          "Notificación Correo Parte 2",
          "Challenge Proyecto #3"
        ],
        "BONUS : Apache Flink": [
          "Analizando Streaming con Apache Flink - Parte 1",
          "Analizando Streaming con Apache Flink - Parte 2",
          "Challenge BONUS"
        ],
        "NEWS !! - Curso Final Portafolio Data Engineer - Volumen 3": [
          "CONCLUSIONES",
          "¿Que deseas ver en el curso final - Volumen 3 del portafolio Data Engineer ?"
        ]
      },
      "requirements": [
        "Conocimientos básicos en la nube AWS",
        "Conocimientos básicos en Kafka",
        "Conocimientos básicos en Python"
      ],
      "description": "Si deseas continuar tu camino hacia convertirte en un Data Engineer Crack en el corto plazo , incrementar tus skills procesando Streaming de  datos para encontrar el trabajo de tus sueños estás en el curso correcto.\n\n\nEn esta segunda entrega tendrás la oportunidad  de crear  proyectos usando algunas herramientas para analisis cercano al tiempo real como  Kinesis Data Stream , Kinesis Firehose , Kafka (Confluent Cloud) , Apache Druid , Apache Flink , Amazon Athena  entre otras ,  las cuales son relevantes al momento de aspirar a un cargo como Data Engineer en LATAM  .\n\n\nTe enseñaré lo necesario al momento de querer montar un proyecto GANADOR para tu portafolio como Data Engineer y te garantizo que vas a enamorarte tanto como YO de lo que hacemos como Data Engineers.\n\n\nEn este curso utilizaremos Python , debido a que  es considerado  uno de los mejores lenguajes de programación para principiantes y uno de los favoritos a la hora de procesar datos , en cuanto a las herramientas que usaremos tenemos las siguientes :\n\n\nAWS  >> Como Cloud Provider\nAWS Kinesis Data Stream\nAWS Kinesis Data Firehose\nAWS Glue\nApache Kafka >> Confluent Cloud\nApache Druid\nAthena\nApache Flink\nS3 Buckets\nAWS Lambda\nAWS Step Functions\nSNS para notificaciones\n\n\nEste curso es una extraordinaria opción para ti si :\n\n\nDeseas aprender a analizar datos en  near real time\nDeseas crear Dashboards para visualizar metricas near real time\nDeseas encontrar esa oportunidad laboral de tus sueños en el corto plazo a bajo costo\nDeseas crear un portafolio ganador que hable por ti y sin recomendaciones",
      "target_audience": [
        "Data Engineers intermedios que deseen contruir un portafolio ganador para este 2023",
        "Data Engineers que deseen aprender a usar herramientas de analisis de Streaming de Datos",
        "Data Engineers intermedios que deseen incrementar sus skills en procesamiento de Streaming de Datos",
        "Cualquier persona que quiera aprender Ingeniería de datos de una manera sencilla",
        "Personas que les gusta aprender a través de la práctica"
      ]
    },
    {
      "title": "Data Science Kurs mit Excel",
      "url": "https://www.udemy.com/course/data-science-mit-excel/",
      "bio": "Lerne die Methoden der Datenanalyse und -auswertung in Excel kennen.",
      "objectives": [
        "Data Science in Excel",
        "Methoden der Datenanalyse in Excel",
        "Statistik"
      ],
      "course_content": {
        "Willkommen": [
          "Agenda"
        ],
        "Teil 1: Datenvorbereitung und -verständnis": [
          "Lageparameter 1/2",
          "Lageparameter 2/2",
          "Streumaße 1/2",
          "Streumaße 2/2",
          "Deskriptive Statistiken",
          "Standardfehler",
          "Konfidenzintervall",
          "Daten aus CSV Datei importieren",
          "Daten aus txt Datei importieren",
          "Daten aus CSV Datei mit US Format importieren"
        ],
        "Teil 2: Methoden der Datenanalyse": [
          "Überblick über die Methoden der Datenanalyse",
          "Aktivierung Datenanalyse-Tools in Excel"
        ],
        "Korrelationsanalyse": [
          "Korrelation manuell berechnen",
          "Korrelation mit Formel berrechnen",
          "Korrelationsmatrix in Excel manuell erstellen",
          "Korrelationsmatrix mittels Excel Tool erstellen"
        ],
        "Multiple Lineare Regression": [
          "Multiple Regression - Berechnung",
          "Multiple Regression - Interpretation",
          "Multiple Regression - Schätzung der Regressionsparameter",
          "Multiple Regression - Variablenselektion",
          "Multiple Regression - Residuenanalyse"
        ],
        "Varianzanalyse": [
          "einfaktorielle ANOVA - Einleitung",
          "einfaktorielle ANOVA - Berechnung",
          "einfaktorielle ANOVA - Intepretation",
          "mehrfaktorielle ANOVA - Berechnung",
          "mehrfaktorielle ANOVA - Intepretation"
        ],
        "Faktorenanalyse": [
          "Faktorenanalyse - Einleitung",
          "Faktorenanalyse - Korrelationsmatrix",
          "Faktorenanalyse - Eigenwerte der Matrix berechnen",
          "Faktorenanalyse - Die erklärte Varianz",
          "Faktorenanalyse - Das Kaiser-Kriterium",
          "Faktorenanalyse - Der Scree-Plot"
        ],
        "t-Test": [
          "t-Test bei abhängigen Stichproben",
          "t-Test bei unabhängigen Stichproben"
        ],
        "Teil 3: Visualisierung": [
          "Histogramm 1/2",
          "Histogramm 2/2",
          "Scatter-Plot 1/2",
          "Scatter-Plot 2/2",
          "Boxplot 1/3",
          "Boxplot 2/3",
          "Boxplot 3/3",
          "Säulendiagramm 1/2",
          "Säulendiagramm 2/2",
          "Kreisdiagramm",
          "Normalverteilungskurve"
        ]
      },
      "requirements": [
        "Statistik Grundkenntnisse",
        "Excel Basics"
      ],
      "description": "Ziel dieses Kurses ist es, statistische Methoden in Excel anzuwenden, um aus den erhobenen Daten weitere Informationen und Ergebnisse zu generieren. Korrelationsanalyse, Varianzanalyse, Multiple Lineare Regression, t-Test, etc. sind Verfahren, die in diesem Kurs behandelt werden.\n\n\nKursaufbau:\nTeil 1: Datenvorbereitung und -verständnis\nTeil 2: Methoden der Datenanalyse\nTeil 3: Visualisierung\n\n\nZielgruppe:\nPersonen, die sich für Statistik und Data Science interessieren und keine neue Programmiersprache lernen wollen.",
      "target_audience": [
        "Personen, die sich für Data Science, Datenenanalyse oder Statistik interessieren und keine Programmiersprache lernen wollen"
      ]
    },
    {
      "title": "Bayesian Statistics: Generalized Linear Models with R",
      "url": "https://www.udemy.com/course/bayesian-statistics-generalized-linear-models-with-r/",
      "bio": "Modelos Lineares Generalizados Bayesianos com Aplicações no R-programming e rstanarm",
      "objectives": [
        "Modelagem Estatística Bayesiana com R e rstanarm",
        "Estimar Modelos de Regressão Lineares para dados Binários e Binomial",
        "Estimar Modelos de Regressão Lineares para dados de Contagem",
        "Modelar Taxas e Proporções",
        "Estimar Modelos para Eventos Longitudinais",
        "Aprender quando utilizar Modelos Discretos ou Contínuos",
        "Utilizar a Família Exponencial de Distribuições em Estatística Bayesiana",
        "Aplicar Simulação Estocástica (Cadeias de Markov) em Modelagem Bayesiana"
      ],
      "course_content": {
        "Introdução": [
          "Introdução",
          "Referências",
          "Cronograma & Introdução",
          "Família Exponencial de Distribuições",
          "Definição de um Modelo Linear Generalizado (MLG)"
        ],
        "Binomial Bayesian GLM": [
          "MLG Binomial (Regressão Logística)",
          "rstanarm",
          "Lendo dataset no Github",
          "Modelo Binomial no R Programming",
          "Transformação da Função Logit",
          "Interpretação dos Coeficientes",
          "Atividade - MLG Binomial",
          "Errata",
          "sample( )",
          "Amostras: Treino & Teste",
          "Treinar Modelo",
          "Acurácia do Modelo",
          "Teste do Modelo",
          "Bayesiano vs Frequentista",
          "Resíduos do Modelo",
          "Seleção do Melhor Modelo",
          "Análise dos Resultados",
          "Interpretação do Intercepto",
          "Interpretação Coeficientes Parciais (β1 a β6)",
          "Predição para Novos Dados",
          "R Notebook",
          "Report",
          "R Chunk"
        ],
        "Poisson Bayesian GLM": [
          "Bayesian GLM Poisson(λ)",
          "Experimento sobre queda de folhas",
          "Regra de Sturges",
          "Bayes GLM - Poisson",
          "Interpretação Modelo Poisson",
          "Statistical Analysis of Natural Events in the US",
          "GLM Frequentista vs GLM Bayesiano",
          "Poisson vs Negative Binomial",
          "Comentários: Script Poisson & NB"
        ],
        "Normal Bayesian GLM": [
          "GLM para Variáveis Respostas Contínuas",
          "GLM Gaussian Model I - Simples",
          "GLM Gaussian Model II e III - Múltipla",
          "Modelo com Interação entre Variáveis Preditoras",
          "Interpretação Modelo com Interação"
        ],
        "Gamma Bayesian GLM": [
          "GLM Gamma",
          "Clotting Dataset",
          "GLM Gamma com e sem interação",
          "GLM Gamma - Coeficientes",
          "Outros Modelos Lineares Generalizados",
          "Considerações Finais"
        ]
      },
      "requirements": [
        "Ter conhecimento básico em Análise Bayesiana de Dados"
      ],
      "description": "Este curso foi desenvolvido pensando nos pesquisadores e profissionais que trabalham com Data Science, Análise de Negócios e precisam realizar análise preditiva.\nNeste curso iremos desenvolver habilidades estatísticas e computacionais para trabalhar com diferentes Modelos Lineares Generalizados Bayesianos (MLGB). Primeiro iremos entender a razão pela qual estes tipos de modelos estatísticos são tão robustos, fáceis de serem utilizados e preferidos para projetos em Ciência de Dados e pesquisa científica em geral.\nDepois iremos explorar suas aplicações para dados de contagem, binários, contínuos e a combinação destes. Na sequência iremos trabalhar com Modelos Lineares Generalizados Bayesianos específicos para dados contínuos e para eventos longitudinais.\nTodo o curso é desenvolvido com o auxílio da linguagem de programação científica R-programming e com o pacote rstanarm, um dos pacotes mais robustos para trabalhar com Estatística Bayesiana.\nAo final do curso os alunos estarão aptos a desenvolver modelos preditivos complexos utilizando Estatística Bayesiana e terão autonomia para avançar seus estudos em técnicas de modelagem que utilizem MLGB.\nAtenção: para melhor aproveitamento do conteúdo é importante ter conhecimento mínimo da linguagem de programação R. Ter conhecimento em modelos de regressão linear e que ter conhecimento básico em estatística bayesiana. Se tiver inseguro(a) recomendo fazer antes os outros cursos de estatística bayesiana que disponibilizei na plataforma: (1) Introdução à Análise Bayesiana com R; (2) Introdução à Análise Bayesiana: Simulação Estocástica com R; e (3) Modelos Lineares com Abordagem Bayesiana.\nQualquer dúvida, antes de adquirir o curso entre em contato comigo.\nEspero lhe ver em breve! :)",
      "target_audience": [
        "Cientistas de Dados",
        "Engenheiros de Dados",
        "Programadores",
        "Analistas de Inteligência de Negócios",
        "Matemáticos",
        "Físicos",
        "Pesquisadores",
        "Pessoas que queiram aprofundar conhecimento em Estatística Bayesiana"
      ]
    },
    {
      "title": "深度学习-入门课程(通俗易懂版)",
      "url": "https://www.udemy.com/course/dl-tangyudi/",
      "bio": "深度学习快速入门",
      "objectives": [
        "深度学习必备基础知识点",
        "神经网络算法原理",
        "神经网络整体架构",
        "神经网络应用领域",
        "卷积神经网络CNN原理",
        "CNN网络应用与整体架构",
        "递归神经网络RNN原理",
        "RNN网络模型应用与整体架构",
        "深度学习经典网络模型架构",
        "自然语言处理模型word2vec",
        "词向量模型应用实战",
        "物体检测框架-FaterRcnn实战",
        "机器翻译框架NMT实战"
      ],
      "course_content": {
        "深度学习必备基础知识点": [
          "深度学习与人工智能概述",
          "计算机视觉面临的挑战与常规套路",
          "用K近邻来进行图像分类",
          "超参数与交叉验证",
          "线性分类",
          "损失函数",
          "正则化惩罚项",
          "softmax分类器",
          "最优化形象解读",
          "最优化问题细节",
          "反向传播"
        ],
        "走进深度学习的世界-神经网络模型": [
          "整体架构",
          "实例演示",
          "过拟合解决方案"
        ],
        "神经网络案例实战": [
          "神经网络案例-cifar分类任务",
          "分模块构造神经网络",
          "训练神经网络完成分类任务",
          "感受神经网络的强大"
        ],
        "卷积神经网络": [
          "卷积神经网络的应用",
          "卷积层解释",
          "卷积计算过程",
          "pading与stride",
          "卷积参数共享",
          "池化层原理"
        ],
        "卷积神经网络案例实战": [
          "卷积池化反向传播",
          "卷积网络代码",
          "卷积网络代码2"
        ],
        "递归神经网络（RNN）": [
          "递归神经网络（RNN）概述",
          "RNN网络细节",
          "LSTM网络架构"
        ],
        "自然语言处理word2vec": [
          "自然语言处理与深度学习",
          "语言模型",
          "N-gram模型",
          "词向量",
          "神经网络模型",
          "Hierarchical Softmax",
          "CBOW模型实例",
          "CBOW求解目标",
          "锑度上升求解",
          "负采样模型"
        ],
        "Gemsim词向量模型": [
          "使用Gensim库构造词向量",
          "维基百科中文数据处理",
          "Gensim构造word2vec模型",
          "测试模型相似度结果"
        ],
        "使用word2vec进行分类任务": [
          "影评情感分类",
          "基于词袋模型训练分类器",
          "准备word2vec输入数据",
          "使用gensim构建word2vec词向量"
        ],
        "物体检测框架-FaterRcnn实战": [
          "三代算法-1-物体检测概述",
          "三代算法-2-深度学习经典检测方法",
          "三代算法-3-faster-rcnn概述",
          "论文解读",
          "RPN网络结构",
          "损失函数定义",
          "网络细节",
          "代码环境配置概述",
          "项目配置",
          "数据加载",
          "数据变换",
          "完成数据读取",
          "特征提取VGG",
          "RPN层",
          "提取网络细节",
          "网络训练迭代"
        ]
      },
      "requirements": [
        "零基础亦可入门，通俗易懂"
      ],
      "description": "深度学习入门视频课程从最基本的神经网络开始讲起，讲复杂的神经网络分成几个小模块，先对必备的知识点的细节进行详细讲解再拓展到整个神经网络，从神经网络的架构，细节进行全面分析，并使用python代码完成简易的神经网络，从效果上感受神经网络的强大。熟悉神经网络后再进军卷积神经网络与递归神经网络，详解CNN与RNN的原理与细节。实战部分通俗讲解当下最流行的物体检测与机器学习翻译框架，逐行代码解读。",
      "target_audience": [
        "深度学习方向的同学们",
        "人工智能方向的同学们"
      ]
    },
    {
      "title": "퀀트 투자를 위한 주식 자동매매 봇 만들기 Part 1",
      "url": "https://www.udemy.com/course/stock-trading-bot-part-1/",
      "bio": "이베스트투자증권 xingAPI를 이용해서 주식 자동매매 봇 만들기",
      "objectives": [
        "이베스트투자증권 xing API를 이용해서 주식 자동매매 봇을 만드는 법",
        "xing API의 다양한 TR, REAL 사용법",
        "래리 윌리엄스의 변동성 돌파 전략",
        "텔레그램 봇을 통한 알림 구현 방법"
      ],
      "course_content": {
        "주식 자동매매 봇 구현을 위한 사전 준비 과정 및 프로그램 설치": [
          "주식 자동매매 봇 구현을 위한 사전 준비 과정",
          "주식 자동매매 봇 구현을 위한 Python 32-bit 설치",
          "이베스트투자증권 xing API 설치하기",
          "eBEST Pro HTS 설치"
        ],
        "강의에서 사용하는 소스코드 다운로드": [
          "강의에서 사용하는 소스코드 다운로드"
        ],
        "이베스트투자증권 xing API 소개": [
          "이베스트투자증권 xing API 소개",
          "이베스트투자증권 xing API 패키지가이드 다운로드"
        ],
        "이베스트투자증권 xing API 기초 - 로그인하기, 계좌 가져오기": [
          "xing API - 로그인하기",
          "xing API - 로그인하기 - 코드 리뷰 및 실행",
          "xing API - 계좌 가져오기",
          "xing API - 계좌 가져오기 - 코드리뷰 및 실행"
        ],
        "TR 사용법을 학습해보자": [
          "DevCenter & Res 파일 다운로드",
          "TR - 단일 데이터 조회",
          "t1101 - 주식 현재가 호가 조회",
          "TR - 반복 데이터 조회",
          "t8430 - 주식종목조회",
          "t4201 - 주식차트(종합)"
        ],
        "매수 매도 주문을 구현해보자": [
          "CSPAT00600 - 현물 정상주문 & 매수 주문 - 지정가 매수",
          "지정가 매수 매도 & 시장가 매수 매도 주문 종합"
        ],
        "계좌 잔고조회 기능을 구현해보자": [
          "CSPAQ12300 - 현물계좌 잔고내역 조회(API)"
        ],
        "REAL 실시간 데이터 조회 사용법을 학습해보자": [
          "REAL - 실시간 데이터 조회",
          "S3_ - KOSPI 체결",
          "K3_ - KOSDAQ 체결"
        ],
        "호가 단위 보정": [
          "호가 단위 보정"
        ],
        "텔레그램 봇을 이용한 알림 기능 구현": [
          "텔레그램 소개 & 텔레그램봇을 이용한 알림 기능 구현",
          "텔레그램(Telegram) 알림 API 구현"
        ]
      },
      "requirements": [
        "Python의 Function과 Class를 이용해서 프로그램을 작성해본 경험",
        "Python을 이용해서 Class를 생성하고 사용해본 경험이 있다.",
        "Python Class의 생성자의 개념을 알고있다."
      ],
      "description": "이베스트투자증권 xing API를 이용해서 주식 자동매매 봇을 만드는 강의입니다. 1년 365일 자동으로 거래하는 나만의 주식 자동매매 봇을 만들어보세요.\n\n\n주식 거래를 자동화 할 수 있다면?\n1년 365일 자동으로 돌아가는 주식 자동매매 봇을 만들어 보세요.\n이베스트투자증권 xing API 기초 사용법 학습\n알림 기능 추가를 위한 텔레그램 봇 구현방법 학습\n래리 윌리엄스의 변동성 돌파전략 학습 및 변동성 돌파전략 자동매매 봇 구현\n\n\n이런 분들께 추천드려요!\n출근해서 일하는 동안에도 원하는 타점에 주식을 매매하고 싶은 직장인\n기능이 풍부한 이베스트투자증권 xing API로 주식 자동매매 봇을 구현하고 싶은 분\n주식 자동매매 봇을 통해 월급 외 부수입에 도전하고 싶은 분\n매수, 매도, 계좌 잔고 확인, 시세 수신 등 주식 자동매매 봇 개발에 필요한 전체 소스코드를 다운받고 싶은 분\n\n\n예상 질문 Q&A\nQ. 선수지식이 필요한가요?\nA. 본 [퀀트 투자를 위한 주식 자동매매 봇 만들기 Part 1] 강의는 이베스트투자증권 xing API를 이용한 주식 자동매매 봇 개발에 대한 설명에 초점을 맞추고 있습니다. xing API를 개발하기 위해서는 Python의 Class와 Fucntion 문법에 대한 배경지식이 필요합니다. 따라서 Python의 Class의 생성자, 인스턴스, 클래스 변수 등의 개념을 이해하고 있다는 가정하에 강의가 진행됩니다.\n\n\nQ. 실습 환경 구성을 위해 준비해야만 하는 사항이 있나요?\nA. 강의에서 진행하는 실습을 따라하기 위해서는 이베스트투자증권 계좌 개설과 Windows OS가 설치된 컴퓨터, Python 32-bit 설치, 이베스트투자증권 xing API 설치가 필요합니다. Python 32-bit 설치, xing API 설치 과정은 강의에서 안내드리지만 이베스트투자증권 계좌 개설은 직접 진행하셔야만 합니다.",
      "target_audience": [
        "나만의 자동화된 주식 자동매매 봇을 만들어 보고 싶은 분",
        "나만의 주식 투자 아이디어를 자동매매 봇으로 자동화하고 싶은 분",
        "주식 자동매매 봇 구현에 필요한 [증권사 API 기초 - 전략 구현 - 배포 및 모니터링] 전 과정을 학습하고 싶은 분"
      ]
    },
    {
      "title": "データエンジニアリングのためのPySpark入門",
      "url": "https://www.udemy.com/course/pyspark-data-engineering/",
      "bio": "スケーラブルデータサイエンスの入り口。ビッグデータ分析、ETLパイプライン実装に必須のPySparkを学ぼう",
      "objectives": [
        "分散処理の基礎知識(MapReduce / PySpark)を身に付ける",
        "PySparkの基礎を一通り学習する",
        "PySparkの実践を通して、実務におけるPySparkの使い方を身に付ける",
        "小売のReal Worldデータ(M5 dataset)を用いた実践的なビッグデータ分析"
      ],
      "course_content": {
        "はじめに": [
          "講座概要"
        ],
        "分散処理の基礎": [
          "分散処理とは",
          "MapReduce(Hadoop)",
          "MapReduceの実際",
          "PySparkとは",
          "PySparkの実際"
        ],
        "PySparkの基礎": [
          "使用するデータセット",
          "PySparkの基礎",
          "SparkSession CreateDataFrame",
          "select",
          "新しいColumnを作成する",
          "カラム名を変える",
          "カラムの削除",
          "データ型の変換",
          "データの並び替え",
          "ユニークな要素の抽出",
          "条件で抽出",
          "SparkDataFrameの結合",
          "条件分岐",
          "欠測値の取り扱い",
          "SparkSQL",
          "groupByによる集計",
          "Window関数による複雑な集計",
          "ユーザー定義の関数 UDF",
          "Pandas DataFrameへの変換"
        ],
        "実践PySpark": [
          "このセクションの流れ",
          "実践PySpark 演習1",
          "実践PySpark 演習2",
          "演習課題について",
          "演習課題の解説"
        ]
      },
      "requirements": [
        "Pythonでの分析（pandas/NumPy など）の基本操作",
        "基本的なSQLの知識があると学習がスムーズです",
        "Google Colabを使用するためGoogleアカウントが必要です"
      ],
      "description": "【本講座の概要】\n本講座は、データサイエンティストがAIシステムの前処理、ETLパイプラインを実装する上で必要不可欠となるPySparkの入門講座です。\n\n本講座を受講する事で、分散処理の基礎（MapReduce／Spark）を押さえたうえで、PySparkのスキルを実務レベルで習得します。実装パートでは、実データ（M5データセット）を取り扱う為、実践的な前処理、ETLパイプライン構築、ビッグデータ分析スキルを一気通貫で学べます。\n\n\nデータサイエンティストの中には統計分析や機械学習によるモデリングに長けた人は多いと思います。\n一方でこんな悩みはありませんか？\nPySparkを使ってみたいが、教材が少なくどう始めればよいのか分からない\nビッグデータの分析は全てSQLベースの手法に依存している\nパイプラインは全てデータエンジニア任せで自分でETLパイプラインを実装したことが無い\n\n\n本講座は、こうした課題を持つデータサイエンティストの「データエンジニアリング力」を短期間で底上げするために設計されています。\n\n\n【この講座で学べること】\nこの講座は分散処理の理論とHandsOn形式のPySparkの実装を通じて、理論と実践をバランスよく学習します。\nまた実践PySparkのパートではビッグデータ分析を想定した演習と課題を用意しています。\nこれらの演習・課題に取り組むことで座学で学んだ知識の定着が図れます。\n\n\n■ 分散処理とSparkの基礎\n分散処理の考え方／MapReduceの要点\nSparkの基本コンポーネントと実行の流れ（DataFrame/SQLの位置づけ）\n\n\n■ PySparkの基礎\nセッション：SparkSession\n列操作：select / withColumn / withColumnRenamed / drop / cast / when\n絞り込み・整列：filter / orderBy / unique（重複排除）\n結合：join（キー重複・列名衝突の扱い）\n欠測値処理：fillna / isnull / dropna\n集約：groupBy\n高度な集計：Window関数（順位付け、移動平均）\nユーザー定義関数：UDF\nSpark SQL\ntoPandas\n■ 実践PySpark\n講師と共にM5を用いたビッグデータ分析に挑戦\n（売上集計・Top Selling itemの分析など）\n課題：3つの課題に自身で取り組み、講座で学んだことを定着\n\n\n【対象者とゴール】\n対象者\nPython中級者でデータエンジニアリングについて学びたい方\n大規模データの集計・結合・欠測処理を学びたいデータ分析者\nETLパイプラインをPySparkを使って実装していきたいデータサイエンティスト\n前提スキル\nPythonでの分析（pandas/NumPy など）の基本操作\n基本的なSQLの知識があると学習がスムーズです\n受講環境：Google Colab\n本コースのゴール\n分散処理の基礎知識(MapReduce / PySpark)を身に付ける\nPySparkの基礎を一通り学習する\n実践PySparkを通して、実務におけるPySparkの使い方を身に付ける\n\n\n【人事・マネージャーの方へ】\nSparkを使う事でデータ量が増えてもスケールする堅牢なAIシステムを構築する事ができます。\n社内のDX推進部門やデータサイエンティスト、データエンジニアが受講する事で、実践的なETLパイプラインを実装し、AIソリューションのシステム全体がより効率的、堅牢になります。",
      "target_audience": [
        "Python中級者でデータエンジニアリングについて学びたい方",
        "大規模データの集計・結合・欠測処理を学びたいデータ分析者",
        "ETLパイプラインをPySparkを使って実装していきたいデータサイエンティスト"
      ]
    },
    {
      "title": "Deep Learning Profissional com PyTorch",
      "url": "https://www.udemy.com/course/deep-learning-profissional-com-pytorch/",
      "bio": "Aprenda a criar e treinar modelos de Deep Learning com PyTorch, dominando redes neurais e backpropagation.",
      "objectives": [
        "Compreender a fundo a manipulação de tensores no PyTorch, incluindo operações em vetores, matrizes e tensores, e como utiliza GPU e CPU",
        "Desenvolver uma compreensão sólida dos princípios do perceptron e como utilizar o backpropagation para treinar redes neurais de forma eficaz.",
        "Implementar modelos de Deep Learning, desde regressão linear até arquiteturas mais avançadas, funções de ativação e ajustes dos dos hiperparâmetros.",
        "Aplicar técnicas de aprendizado supervisionado para criar modelos robustos e resolver problemas complexos de classificação."
      ],
      "course_content": {
        "Introdução": [
          "Introdução (Obrigatório)",
          "Materiais de estudo"
        ],
        "Manipulação de Tensores": [
          "Origem do Pytorch",
          "Instalação e arquitetura do Pytorch",
          "Escalar, Vetor, Matriz e Tensores",
          "Escalar",
          "Vetor",
          "Matriz",
          "Tensores",
          "Executando operações na GPU e CPU",
          "Acessando os elementos do tensor via index",
          "Criação e Inicialização de Tensores",
          "torch.sum",
          "torch.mean",
          "torch.max",
          "torch.min",
          "torch.argmax e torch.argmin",
          "Várias formas de transposição em tensores",
          "Várias funções do produto escalar em tensores",
          "Broadcasting",
          "torch.reshape e torch.view",
          "torch.squeeze e torch.unsqueeze",
          "torch.cat e torch.stack",
          "torch.chunk",
          "torch.split",
          "torch.tril",
          "torch.save e torch.load"
        ],
        "Perceptron": [
          "Tipos de modelos e aprendizado supervisionado",
          "Introdução ao perceptron",
          "Equação do perceptron",
          "Propriedade linear do perceptron",
          "Introdução ao treinamento do perceptron",
          "Backpropagation com perceptron",
          "Visualização do treinamento"
        ],
        "Backpropagation": [
          "Funções",
          "Limites",
          "Derivadas",
          "Regras de derivação",
          "Regra da cadeia com uma variável",
          "Regra da cadeia com duas variáveis",
          "Regra da cadeia inversa (Backpropagation)",
          "Descida do gradiente"
        ],
        "Tipos de dados e aproximação de funções": [
          "Teorema da aproximação universal",
          "Dados não linearmente separáveis"
        ],
        "Deep Learning": [
          "Regressão linear (Criação do Modelo)",
          "Regressão linear (Treinamento do Modelo)",
          "Regressão linear (Resolvendo problemas do aprendizado)",
          "Funções de ativação",
          "Otimizadores",
          "Classificação binária"
        ]
      },
      "requirements": [
        "Conhecimento básico de Python e programação.",
        "Vontade de aprender e explorar o PyTorch para criar modelos de Deep Learning."
      ],
      "description": "Descubra o poder do PyTorch e domine o campo em expansão do Deep Learning com nosso curso intensivo e prático. Este curso foi projetado para equipar você com as habilidades necessárias para construir, treinar e implementar modelos avançados de redes neurais que podem solucionar problemas complexos em diversos domínios.\nAo longo do curso, você terá acesso a uma série de módulos detalhados que começam com fundamentos de manipulação de tensores e avançam até técnicas sofisticadas de otimização de modelos. Cada aula é acompanhada de exemplos práticos e projetos que ilustram como aplicar conceitos teóricos a problemas do mundo real. Além disso, discutiremos as últimas tendências e inovações em Deep Learning, preparando você para implementar soluções que não apenas acompanham mas definem o estado da arte na tecnologia.\nAo final deste curso, você não apenas entenderá como trabalhar com Deep Learning utilizando PyTorch, mas também terá desenvolvido um portfólio robusto de projetos que demonstram sua competência e habilidade em transformar teoria em prática efetiva.\nEste curso é ideal para uma ampla gama de entusiastas e profissionais que desejam dominar a arte do Deep Learning utilizando a biblioteca PyTorch, uma das ferramentas mais poderosas e flexíveis no campo da Inteligência Artificial.\nQuem deve se inscrever?\nDesenvolvedores de Software e Engenheiros de Machine Learning: Se você já possui alguma experiência em programação e quer aprofundar seus conhecimentos em técnicas avançadas de modelagem e treinamento de redes neurais, este curso oferecerá a expertise necessária para elevar sua carreira a um novo patamar.\nCientistas de Dados: Profissionais que buscam integrar modelos de Deep Learning em suas análises para gerar insights mais profundos e predições mais precisas encontrarão neste curso as técnicas e práticas recomendadas para implementação efetiva.\nAcadêmicos e Estudantes: Se você está no meio acadêmico e deseja adquirir uma compreensão sólida sobre redes neurais profundas para seus projetos de pesquisa ou dissertações, este curso cobrirá desde os fundamentos até as aplicações mais complexas.\nHobbyistas de AI e Tecnologia: Indivíduos com uma paixão por tecnologia e inovação que querem entender como as máquinas podem aprender a realizar tarefas complexas e melhorar continuamente.\nPor que se inscrever?\nEste curso não apenas ensina a teoria por trás do Deep Learning, mas também fornece uma experiência prática intensa, permitindo que você implemente e treine seus próprios modelos. Com um foco na aplicação prática, você aprenderá a resolver problemas reais, preparando-se para desafios em várias indústrias, desde saúde até tecnologia financeira. Além disso, o domínio do PyTorch abrirá portas para oportunidades de carreira em empresas que estão na vanguarda da tecnologia.\nInscreva-se hoje para começar sua jornada para se tornar um especialista em Deep Learning com PyTorch e transformar seu potencial em conquistas palpáveis.",
      "target_audience": [
        "Estudantes e profissionais que desejam aprofundar seus conhecimentos em Deep Learning.",
        "Desenvolvedores que querem aprender a usar PyTorch para criar modelos de IA.",
        "Cientistas de dados e engenheiros que trabalham com aprendizado de máquina.",
        "Qualquer pessoa interessada em aprender a implementar redes neurais do zero com PyTorch."
      ]
    },
    {
      "title": "Inteligencia Artificial: Aprendizaje por Refuerzo con Python",
      "url": "https://www.udemy.com/course/aprendizaje-por-refuerzo-con-python-y-gym/",
      "bio": "Domina Q-Learning y experimenta con simuladores de IA en Gymnasium con proyectos reales y prácticos.",
      "objectives": [
        "Comprender los Fundamentos del Aprendizaje por Refuerzo",
        "Implementar el Algoritmo Q-Learning desde cero",
        "Implementar algoritmos y simularlos en Gym y Python",
        "Resolver Problemas Prácticos"
      ],
      "course_content": {
        "Introducción al Aprendizaje por Refuerzo": [
          "¿Qué es aprendizaje por refuerzo?",
          "Q-learning: Introducción",
          "Fórmula de Q-Learning",
          "Pseudocódigo Q-Learning"
        ],
        "Entorno de Desarrollo Python y Gym (Gymnasium)": [
          "Instalación de Python y módulos (librerías)",
          "Instalación de gymnasium"
        ],
        "Programando el Algoritmo Q-Learning": [
          "Algoritmo Q-Learning Parte 1",
          "Algoritmo Q-Learning Parte 2",
          "Algoritmo Q-Learning Parte 3",
          "Algoritmo Q-Learning Parte 4",
          "Resumen del algoritmo"
        ],
        "Aplicación Práctica Lago Congelado (Videojuego)": [
          "Problema Frozen Lake (Lago congelado)"
        ],
        "Aplicación Práctica Coche de montaña (Mountain Car)": [
          "Introducción al problema Coche de Montaña",
          "Programación del algoritmo Parte 1",
          "Programación del algoritmo Parte 2",
          "Programación del algoritmo Parte 3",
          "Programación del algoritmo Parte Final"
        ]
      },
      "requirements": [
        "Conocimientos Básicos de Programación",
        "Interés en la Inteligencia Artificial"
      ],
      "description": "¿Sabías que el aprendizaje por refuerzo es la técnica que impulsa a los robots autónomos, a la inteligencia de los videojuegos y a sistemas avanzados de recomendación como los de Netflix o Amazon? Esta rama de la inteligencia artificial enseña a las máquinas a aprender de la experiencia y tomar decisiones cada vez más inteligentes.\nEn este curso aprenderás paso a paso cómo implementar el algoritmo Q-Learning con Python, aplicándolo en escenarios prácticos dentro de Gymnasium, el simulador más popular de IA desarrollado por OpenAI. Desde los conceptos básicos hasta proyectos finales, vivirás un recorrido completo para dominar esta tecnología.\nEsto es lo que te llevas al inscribirte:\nFundamentos del Aprendizaje por Refuerzo\nPrincipios esenciales explicados de forma sencilla.\nEjemplos claros para entender cómo un agente aprende.\nEntorno de Desarrollo Profesional\nInstalación y configuración de Python y Gymnasium.\nCreación de un espacio de pruebas realista para tus algoritmos.\nImplementación del Algoritmo Q-Learning\nDe la teoría a la práctica, paso a paso.\nCódigo comentado para que comprendas cada línea.\nAplicaciones en Simuladores Reales\nReto del Lago Congelado: toma de decisiones en entornos inciertos.\nDesafío del Robot Montaña: aprendizaje en entornos complejos.\nProyecto Final Integrador\nDiseñarás y optimizarás tu propia solución de IA con Q-Learning.\nAl finalizar, tendrás bases sólidas en inteligencia artificial aplicada, experiencia con simuladores de renombre y proyectos que te diferenciarán como profesional.",
      "target_audience": [
        "Profesionales con conocimientos de programación que buscan aprender e implementar algoritmos de inteligencia artificial.",
        "Aquellos que estudian carreras relacionadas con la informática, ingeniería, matemáticas o ciencias de datos y buscan complementar su formación con conocimientos prácticos en aprendizaje por refuerzo.",
        "Personas apasionadas por la tecnología y la inteligencia artificial que quieren comprender cómo las máquinas aprenden y resuelven problemas complejos mediante prueba y error."
      ]
    },
    {
      "title": "Machine Learning Automatizado com Pycaret",
      "url": "https://www.udemy.com/course/automl-pycaret/",
      "bio": "Diminua drasticamente o tempo de aprendizado e de desenvolvimento de projetos de Data Science",
      "objectives": [
        "Você irá aprender Machine Learning Automatizada com uma incrivél biblioteca",
        "Será capaz de criar seus proprios projetos de machine learning de forma fácil e com pouquíssimo código",
        "Comece analisar seus dados com de forma simples",
        "Use técnicas avançadas de forma simples"
      ],
      "course_content": {
        "Introdução": [
          "Introdução",
          "Programa do Curso",
          "Material",
          "Quiz"
        ],
        "Como obter melhores Resultados na plataforma": [
          "Como otimizar seus estudos"
        ],
        "Teoria do Machine Learning": [
          "Introdução ao Aprendizado de Maquina",
          "Fases do aprendizado de máquina",
          "Seleção de fontes de dados e extração",
          "Pre processamento de dados",
          "Seleção de modelo de aprendizagem",
          "Treinamento do Modelo",
          "Avaliação do Modelo",
          "Ajustes e Otimizaçao",
          "Teste"
        ],
        "Preparação do Ambiente": [
          "Apresentação do Google colab",
          "Configurações iniciais"
        ],
        "Machine Learning com Pycaret - Aprendizado Acelerado": [
          "QuickStart",
          "Functions do Pycaret",
          "Setup",
          "API Funcional",
          "OOP API",
          "Compare Models",
          "Analyze Model",
          "Predictions",
          "Save the model"
        ],
        "Machine Learning com Pycaret do básico ao Avançado": [
          "Instalação da biblioteca Pycaret",
          "Apresentação do Script de estudo",
          "Setup e carregamento dos dados",
          "Entendendo o Setup do Pycaret",
          "Comparando os modelos",
          "Analise grafica dos modelos",
          "Alterantiva ao método plot utilizando o Evaluate",
          "Realizando Predições",
          "Salvando Modelo",
          "Carregando modelo",
          "Opções Avançadas da função SETUP",
          "Utilizando parametro Normalize",
          "Customizando o grid de modelos da função Compare_models",
          "Configurando a ordenação de modelos de acordo com a métrica escolhida",
          "Treinando modelo usando Cross Validation",
          "Opções avançadas para criação de modelos",
          "Realizando Tunning no Modelo",
          "Customizando o processo de Tunning",
          "Utilizando método de Ensemble",
          "Outros Métodos",
          "Utilizando função de plotagem",
          "Utilizando a função Interpret_model",
          "Utilizando função leaderboard",
          "Utilização da função AutoML",
          "Criando Dashboard Automaticamente",
          "Realizando validação profunda com função deep_check",
          "Realizando Analise Exploratoria Automatica",
          "Criando aplicativo com pycaret",
          "Outras Funcionalidades do Pycaret"
        ],
        "Encerramento": [
          "Revisão do curso",
          "Agradecimentos"
        ]
      },
      "requirements": [
        "Interessante conhecimento básico em python"
      ],
      "description": "Aprenda Machine Learning automatizado com Pycaret\nNeste curso, você será introduzido ao mundo do Machine Learning automatizado usando a biblioteca Pycaret. O Pycaret é uma ferramenta poderosa que simplifica o processo de construção, treinamento e implantação de modelos de Machine Learning. Ao longo deste curso, você aprenderá os fundamentos teóricos do Machine Learning, bem como como aplicar esses conceitos usando o Pycaret. Desde a preparação dos dados até a avaliação do modelo, você desenvolverá uma compreensão completa de como usar o Pycaret para automatizar o processo de Machine Learning.\n\n\nEstrutura do Curso:\nIntrodução ao Machine Learning automatizado e Pycaret\nO que é Machine Learning automatizado\nBenefícios do uso do Pycaret\nConfiguração do ambiente de desenvolvimento\nInstalação e configuração do Pycaret\nVisão geral do conjunto de dados de exemplo\nPré-processamento de Dados\nImportação de dados com o Pycaret\nAnálise exploratória de dados\nLimpeza e transformação de dados\nLidando com valores ausentes\nTratamento de outliers\nNormalização e padronização de dados\nPreparação de Dados para Modelagem\nDivisão de dados em conjuntos de treinamento e teste\nCodificação de variáveis categóricas\nSeleção de características\nDimensionamento de características\nTreinamento de Modelos\nConfiguração do ambiente de treinamento\nTreinamento de modelos de classificação, regressão e agrupamento\nAjuste de hiperparâmetros\nValidação cruzada\nAvaliação de modelos\nComparação de Modelos\nMétricas de avaliação de desempenho\nVisualização de resultados\nSeleção do modelo final\nImplantação do Modelo\nExportação do modelo treinado\nMonitoramento de desempenho do modelo\nEstratégias Avançadas com Pycaret\nStacking de modelos\nEnsembling de modelos\nAjuste de hiperparâmetros avançado\nExploração automatizada de características\nDiagnóstico de modelo\nRecursos especiais\nConstrução de dashboards usando pycaret\nDeepcheck (análise avançada)\nContrução de aplicativo com pycaret\nFunções complementares do Pycaret\nPráticas recomendadas e considerações finais\nRecapitulação do curso",
      "target_audience": [
        "• Profissionais de análise de dados interessados em aprender técnicas avançadas de Machine Learning. • Desenvolvedores de software que desejam implementar modelos de Machine Learning automatizado em seus projetos. • Estudantes de ciência de dados e aprendizado de máquina que desejam aprofundar seus conhecimentos práticos."
      ]
    },
    {
      "title": "Computer Vision With Deep Learning",
      "url": "https://www.udemy.com/course/computer-vision-with-deep-learning-t/",
      "bio": "رؤية الكمبيوتر باستخدام التعلم العميق",
      "objectives": [
        "Computer Vision Basic Operations",
        "Deep Neural Network (DNN) -Pytorch",
        "Convolutional Neural Network (CNN)- TensorFlow",
        "Semantic Segmentation",
        "Object Detection",
        "Instance Segmentation",
        "Pose Estimation",
        "Generative AI",
        "Face Recognition"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Installing Anaconda",
          "Course Requirements",
          "Course Curriculum",
          "Computer Vision Applications"
        ],
        "Computer Vision Basic Operations": [
          "Red, Green, Blue",
          "Gray Scale",
          "HSV Color Based Masking",
          "Draw on Image",
          "Edge_detection",
          "thresholding",
          "image_scaling_crop",
          "rotation_translation",
          "filters",
          "Data Augmentation"
        ],
        "Deep Neural Network (DNN) -Pytorch": [
          "DNN Basics",
          "PyTorch Set up",
          "Tensors in PyTorch",
          "Tensors to NumPy arrays",
          "Backpropagation Theory",
          "Backpropagation using PyTorch",
          "Simple DNN using PyTorch"
        ],
        "Convolutional Neural Network (CNN)- TensorFlow": [
          "CNN Basics",
          "TensorFlow setup",
          "TensorFlow basics",
          "CNN Data preprocessing",
          "CNN model build up",
          "CNN Results Evaluation"
        ],
        "Semantic Segmentation": [
          "U-Net",
          "Input Data Formating",
          "Model build up",
          "Results Evaluation"
        ],
        "Object Detection": [
          "YOLO(You Look Only Onse)",
          "Input video processing",
          "Inference using pre-trained model",
          "output the images as video",
          "how to create YOUR data for training",
          "re-train the YOLO algorithm",
          "predict the results using Re-Trained YOLO"
        ],
        "Instance Segmentation": [
          "HOW Image Segmentation works (YOLACT)",
          "Predict one image using pre-trained data",
          "Results post-processing",
          "create YOUR training data",
          "training process"
        ],
        "Pose Estimation": [
          "How pose estimation works (YOLO-pose)",
          "process one Video using pre-trained model",
          "Deep Analysis of results of one image using pre-trained model",
          "Create YOUR data for pose",
          "Re-Train the model"
        ],
        "Generative AI": [
          "GAN (Generative Adversarial Network)",
          "Data View_ import Needed Libraries",
          "Data-Set Build Up",
          "GAN Model Build up",
          "Training Process and results evaluation",
          "How Stable Diffusion works",
          "Stable Diffusion, models Re-training Example"
        ],
        "Vision Transformer": [
          "Vision Transformer Introduction",
          "Import Data file set up",
          "Input Data (upload)",
          "Data Augmentation Transformation",
          "Model Build Up",
          "Model Training",
          "Results Evaaluation"
        ]
      },
      "requirements": [
        "High School Math",
        "Basic Python knowledge"
      ],
      "description": "Computer Vision With Deep Learning\nرؤية الكمبيوتر باستخدام التعلم العميق\n\n\nDescription\nThis is a complete course that will prepare you to work in Computer Vision Using Deep Learning. We will cover the fundamentals of Deep Learning/ computer Vision and its applications, this course is designed to reduce the time for the learner to Learn Computer Vision using Deep learning.\nهذه دورة كاملة ستعدك للعمل في رؤية الكمبيوتر باستخدام التعلم العميق. سنغطي أساسيات التعلم العميق/رؤية الكمبيوتر وتطبيقاتها، وقد تم تصميم هذه الدورة لتقليل الوقت الذي يستغرقه المتعلم لتعلم رؤية الكمبيوتر باستخدام التعلم العميق.\n\n\nWhat Skills will you Learn:\nIn this course, you will learn the following skills:\nUnderstand the Math behind Deep Learning Algorithms.\nUnderstand How computer vision Algorithms works.\nWrite and build computer vision Algorithms using Deep learning technologies.\nUse opensource libraries.\n\n\nWe will cover:\nFundamentals of Computer Vision.\nImage Preprocessing.\nDeep Neural Network (DNN) - Pytorch .\nConvolutional Neural Network (CNN)- TensorFlow.\nSemantic Segmentation.\nObject Detection.\nInstance Segmentation.\nPose Estimation.\nGenerative AI.\nFace Recognition.\nIf you do not have prior experience in Machine Learning OR Computer vision, that's NO PROBLEM!. This course is complete and concise, covering the fundamental Theory and needed coding knowledge. Let's work together to learn Computer Vision Using Deep Learning.\nإذا لم تكن لديك خبرة سابقة في التعلم الآلي أو رؤية الكمبيوتر، فلا مشكلة!. هذه الدورة كاملة وموجزة، وتغطي النظرية الأساسية ومعرفة البرمجة اللازمة. دعونا نعمل معًا لتعلم رؤية الكمبيوتر باستخدام التعلم العميق.",
      "target_audience": [
        "Anyone who wants to use Deep Learning for Computer Vision"
      ]
    },
    {
      "title": "ChatGPT ile etkili prompt kullanımı: Stratejiler&Uygulamalar",
      "url": "https://www.udemy.com/course/chatgpt-prompt/",
      "bio": "ChatGPT'den alacağınız yanıtların kalitesini artırmak için en iyi prompt tekniklerini uygulamalı öğrenin",
      "objectives": [
        "ChatGPT'nin ne olduğunu ve nasıl kullanıldığını öğreneceksiniz.",
        "ChatGPT ile çok daha iyi iletişim kuracak ve tam istediğiniz yanıtlar alacaksınız.",
        "Prompt yazma mantığını çözecek ve onlarca prompt örneği uygulaması ile öğrendiklerinizi pekiştireceksiniz.",
        "Öğrendiğiniz teknikler sayesinde çok daha iyi promptlar yazacak ve ChatGPT'yi profesyonel bir şekilde kullanacaksınız.",
        "Yüzlerce hazır prompt bulabileceğiniz kaynaklara erişeceksiniz.",
        "Yazacağınız promptları paraya çevirebileceğiniz platformları öğreneceksiniz."
      ],
      "course_content": {
        "Giriş": [
          "Giriş",
          "ChatGPT arayüzünü tanımak.",
          "Prompt nedir? Etkili prompt yazma teknikleri.",
          "Prompt yazma ipuçları",
          "Aynı bağlama ait etkili-etkisiz prompt karşılaştırmaları"
        ],
        "Prompt uygulamları": [
          "İstediğini herhangi bir konuyu derinlemesine araştırıp yazdırın.",
          "Siz gezi planınızdan bahsedin o sizin için kusursuz bir gezi planı yapsın",
          "İngilizce alıştırma yapmak",
          "Kan değerleri veya doktor raporu kontrolü",
          "Kıyafet kombini tasarlatmak ve DALL-E ile çizdirmek",
          "Web sayfası oluşturma",
          "Cv oluşturma ve en iyi özgeçmişi yazdırma",
          "İstediğiniz cümleyi emojiye çevirsin",
          "Röportaj soruları yazdırın",
          "Kitap özeti yazsın",
          "Sizin için bir kitap yazsın",
          "Kişiye özel öğrenci programı yazsın",
          "Trend topic (TT) olacak Tweetler yazsın",
          "İstediğiniz bir resmi çizsin (ASCİİ)",
          "Size her hangi bir konu ile alakalı çoktan seçmeli test soruları sorsun",
          "Rüyalarınızı yorumlatın",
          "Psikoloğunuz olsun, sizi dinlesin ve öneriler sunsun.",
          "Youtube içerik fikri ürettirmek ve konuşma metnini yazdırmak",
          "Çocuk doktoru olsun ve sizin sorularınızı yanıtlasın.",
          "Ruh halinize göre şarkı önerisi yapsın.",
          "Elinizdeki malzemeleri söyleyin size yapılabilecek en iyi yemeği tarif etsin.",
          "Emojiden film bilme yarışması yaptırın",
          "Siz karakter isimlerini, türünü belirtin sizin için benzersiz bir hikaye yazsın",
          "Bir toplu işlem dosyası yazdırarak windows'da istediğiniz değişikliği yaptırın",
          "İstediğiniz yazılım dilini size adım adım öğretsin. (python,java..)",
          "Avukatınız olsun istediğiniz her şeyi danışın. Ayrıntılı olarak anlatsın.",
          "Size sorular sorsun ve tam size göre olan oyunları listelesin"
        ],
        "Prompt kaynakları": [
          "Prompt generator",
          "Onlarca prompt örneği",
          "Kategorilere göre ayrılmış sayfalar dolusu prompt",
          "Yazdığınız promptları satın ve para kazanın"
        ]
      },
      "requirements": [
        "Temel bilgisayar bilgisi ve yapay zeka teknolojilerine merak yeterli."
      ],
      "description": "ChatGPT ile daha etkili bir iletişimin nasıl kurulacağını anlatmak için hazırladığım bu kursa hoş geldiniz!\nBu kurs, size ChatGPT'nin ne olduğunu ve ne işe yaradığını anlatarak başlıyor ve  prompt yazma tekniklerini etkili bir şekilde kullanarak daha akıcı ve anlamlı bir konuşma deneyimi sunmayı hedefliyor.\nKursun ilk bölümünde, kısa bir şekilde ChatGPT'yi  tanıyacaksınız. Ardından, prompt kavramını anlayacak ve en iyi prompt yazma tekniklerini öğreneceksiniz. Promptlar, ChatGPT ile iletişim kurarken kullanılan giriş ifadeleridir ve onları etkili bir şekilde kullanmak, daha akıcı ve anlamlı yanıtlar almanıza yardımcı olacaktır.\nKursun ilerleyen bölümlerinde, bir çok uygulama örneği izleyerek prompt yazma tekniklerini pekiştireceksiniz. Bu uygulamalar sayesinde, gerçek dünya senaryolarında ChatGPT'yi nasıl kullanabileceğinizi keşfedecek ve pratik yapma fırsatı bulacaksınız. Örnek videolar aracılığıyla, her bir uygulama senaryosunu adım adım açıklayacak ve size rehberlik edeceğim.\nSon bölümde ise prompt yazma örneklerini içeren pek çok internet sitesinin linkine erişerek daha geniş bir kaynak içeriğine sahip olacaksınız ve bu linkler devamlı güncellenecek. Paylaşılan kaynaklar, prompt yazma becerilerinizi geliştirmek ve daha karmaşık senaryolara uyum sağlamanız için mükemmel bir fırsat olacak.\nBu kurs, ChatGPT ile daha etkili konuşma becerileri geliştirmek isteyen herkes için uygundur. Öğrenciler, öğretmenler, mühendisler, ev hanımları yani kısaca bu konuya ilgisi olan herkes için faydalı olacaktır. Siz de bu kursa katılarak, ChatGPT ile aranızdaki dil becerinizi geliştirmek ve etkili bir iletişim kurmak için gereken bilgi ve becerileri edinebilirsiniz.",
      "target_audience": [
        "Hızla gelişen yapay zeka teknolojisini yakalamak ve hayatının her alanında kullanmak isteyen herkese"
      ]
    },
    {
      "title": "Data Scientist(데이터 사이언티스트) 전문가 과정 (2022) - 1편",
      "url": "https://www.udemy.com/course/data-scientist-2022-1/",
      "bio": "[강의 교안 제공] 현직 데이터사이언티스트 전문가 전하는 빅데이터 개발 및 분석 실무 노하우 시작편!",
      "objectives": [
        "데이터 사이언스의 정의, 사례, 도구, 라이프사이클",
        "수집 방식의 정의,수집 방식의 종류,수집 방식의 결정",
        "우분투 설치, 이클립스, 파일질라, putty 설치",
        "비정형 데이터 수집 방식(jupyter notebook을 이용한 스크레이핑 실습)"
      ],
      "course_content": {
        "Part.1 빅데이터 수집 1": [
          "데이터 사이언스의 정의, 사례, 도구, 라이프사이클",
          "수집 방식의 정의,수집 방식의 종류,수집 방식의 결정",
          "내 · 외부 데이터 수집을 위한 환경을 구축",
          "우분투 설치, 이클립스, 파일질라, putty 설치",
          "비정형 데이터 수집 방식(jupyter notebook을 이용한 스크레이핑 실습)",
          "html, css, javascript,구문 분석기,wget으로 이미지 가져오기,빅데이터 수집 방식 결정",
          "수집시 HTTPError, URLError 에러 처리",
          "스크레이핑 기초, 리눅스(우분투)에서 데이터 수집 관련 명령어",
          "리눅스(우분투)에서 데이터 수집 관련 명령어",
          "정규표현식을 이용한 도서 목록 가져오기1",
          "정규표현식을 이용한 도서 목록 가져오기2",
          "정규표현식을 이용한 도서 목록 가져오기3",
          "빅데이터 수집 모델 설계 및 검증 및 관계법령"
        ],
        "Part.1 빅데이터 수집 2 (시스템구성)": [
          "빅데이터 수집 모델 설계 및 검증하기",
          "빅데이터 수집 모듈 개발",
          "스크래파이 실습1",
          "스크래파이 실습2",
          "스크래파이 실습3",
          "스크래파이 실습4"
        ],
        "Part.2 빅데이터 적재": [
          "빅데이터 저장 모델 설계",
          "관계형 데이터베이스",
          "하둡 에코 시스템(hadoop eco-system)",
          "하둡환경설정파일",
          "하둡 클러스터 설정",
          "하둡 환경 설정1",
          "하둡 환경 설정2",
          "하둡 환경 설정3",
          "하둡 환경 설정4",
          "하둡 환경 설정5",
          "하둡 환경 설정6",
          "하둡 테스트1",
          "하둡 테스트2",
          "하둡 설치 확인1",
          "하둡 설치 확인2",
          "하둡 설치 확인3",
          "배치성 로그 데이터 적재",
          "실시간 데이터 적재"
        ],
        "Part.3 탐색 및 통계기반 데이터분석 1 (기술 통계학)": [
          "통계학의 분류",
          "변수 종류, 추정",
          "좋은 추정량",
          "표본추출방법",
          "R 자료구조",
          "기술통계",
          "질적자료와 연속자료",
          "R 데이터 가져오기",
          "중심위치 산포 경향",
          "산점도, 막대그래프, 히스토그램",
          "중심 경향도, 산포도",
          "평균, 중간값, 최빈값",
          "모분산, 표본분산",
          "분위수, 박스플롯",
          "이상치 판별",
          "변동계수",
          "확률변수",
          "베르누이 시행",
          "정규분포",
          "정규화 표준화",
          "표본분포",
          "프아송 분포",
          "표준오차"
        ],
        "Part.3 탐색 및 통계기반 데이터분석 2 (추론 통계학)": [
          "추정",
          "신뢰구간",
          "부트스트랩",
          "가설 검정",
          "t 검정",
          "모 비율의 가설검정",
          "통계 분석 개요",
          "모 집단이 두 개인 경우 가설 검정",
          "모집단 분산의 구간 추정",
          "모 집단이 세 개인 경우 가설 검정",
          "이원 분산 분석",
          "상관",
          "회귀"
        ]
      },
      "requirements": [
        "데이터 사이언스에 대한 기본 지식이 필요합니다"
      ],
      "description": "현직 데이터사이언티스트 전문가가 전하는 빅데이터 개발 및 분석 실무 노하우 및 체계적인 교육\n회사내에서 빅데이터 개발 및 분석 업무로 보직 변경을 하고자 하는 분을 위한 교육\n빅데이터 시스템 구축 및 분석의 A부터 Z까지 전체적인 흐름을 파악하고, 빅데이터 수집부터 적재, 처리 , 분석까지 프로젝트로 배우며 관련 노하우를 습득합니다.\n\n\n[HD]Data Scientist(데이터 사이언티스트) 전문가 과정 (2022) Part.1 빅데이터 수집 1\n\n\n데이터 사이언스의 정의, 사례, 도구, 라이프사이클\n수집 방식의 정의,수집 방식의 종류,수집 방식의 결정\n...\n[HD]Data Scientist(데이터 사이언티스트) 전문가 과정 (2022) Part.1 빅데이터 수집 2 (시스템구성)\n\n\n빅데이터 수집 모델 설계 및 검증하기\n빅데이터 수집 모듈 개발\n...\n[HD]Data Scientist(데이터 사이언티스트) 전문가 과정 (2022) Part.2 빅데이터 적재\n\n\n빅데이터 저장 모델 설계\n관계형 데이터베이스\n...\n[HD]Data Scientist(데이터 사이언티스트) 전문가 과정 (2022) Part.3 탐색 및 통계기반 데이터분석 1 (기술 통계학)\n\n\n통계학의 분류\n변수 종류, 추정\n...\n[HD]Data Scientist(데이터 사이언티스트) 전문가 과정 (2022) Part.3 탐색 및 통계기반 데이터분석 2 (추론 통계학)\n\n\n추정\n신뢰구간\n...",
      "target_audience": [
        "데이터분석 분야 및 관련 분야 취업 및 ADP 자격 취득을 하고자 하는 누구나",
        "빅데이터 분석 기사 취득을 하고자 하는 누구나"
      ]
    },
    {
      "title": "모두를 위한 ChatGPT Part 2 - ChatGPT를 이용한 데이터분석과 판다스 활용",
      "url": "https://www.udemy.com/course/data-analysis-using-chatgpt-part2/",
      "bio": "ChatGPT를 이용한 데이터 분석과 판다스(Pandas) 라이브러리 활용 방법",
      "objectives": [
        "ChatGPT를 이용한 데이터분석 방법",
        "넘파이(Numpy)와 판다스(Pandas) 라이브러리 활용법",
        "다양한 분야에 데이터 분석을 진행하는 법",
        "matplotlib과 seaborn을 이용한 데이터 시각화 방법"
      ],
      "course_content": {
        "ChatGPT를 이용한 데이터 분석과 판다스 활용 개요": [
          "ChatGPT를 이용한 데이터 분석과 판다스 활용 개요",
          "데이터 분석의 개념과 데이터 분석의 필요성"
        ],
        "행렬 형태의 데이터를 다뤄보자 - 넘파이(Numpy)": [
          "데이터 분석을 위한 공구세트 넘파이(Numpy)와 판다스(Pandas) 개요",
          "넘파이(Numpy) 기초 1 - 다차원 배열 만들기",
          "넘파이(Numpy) 기초 2 - 인덱싱(Indexing)과 슬라이싱(Slicing)",
          "넘파이(Numpy) 기초 3 - Broadcasting과 Aggregation",
          "Python 실습을 위한 구글 코랩 Colab 소개",
          "Colab 실습 - 넘파이(Numpy) 기초 1 - 다차원 배열 만들기",
          "Colab 실습 - 넘파이(Numpy) 기초 2 - Indexing과 Slicing",
          "Colab 실습 - 넘파이(Numpy) 기초 3 - Broadcasting과 Aggregation",
          "ChatGPT를 이용해서 넘파이(Numpy) 라이브러리 학습하고 사용하기"
        ],
        "데이터 분석의 꽃 - 판다스(Pandas)": [
          "판다스(Pandas) 소개 & 시리즈(Series) 기초 - 인덱싱(Indexing)과 슬라이싱(Slicing)",
          "데이터프레임(DataFrame) 기초 1 - 인덱싱(Indexing)과 슬라이싱(Slicing)",
          "데이터프레임(DataFrame) 기초 2 - Broadcasting과 Aggregation & 정렬",
          "데이터프레임(DataFrame) 기초 3 - 데이터프레임(DataFrame) 생성하기",
          "Colab 실습 - 시리즈(Series) 기초 - 인덱싱(Indexing)과 슬라이싱(Slicing), 시리즈 생성",
          "Colab 실습 - 데이터프레임(DataFrame) 기초 1 - 인덱싱(Indexing)과 슬라이싱(Slicing)",
          "Colab 실습 - 데이터프레임(DataFrame) 기초 2 - Broadcasting과 Aggregation",
          "Colab 실습 - 데이터프레임(DataFrame) 기초 3 - 정렬",
          "Colab 실습 - 데이터프레임(DataFrame) 기초 4 - 데이터프레임(DataFrame) 생성",
          "ChatGPT를 이용해서 판다스(Pandas) 라이브러리 학습하고 사용하기 - 시리즈(Series) 기초 - 인덱싱(Indexing)과 슬라이싱",
          "ChatGPT를 이용해서 판다스(Pandas) 라이브러리 학습하고 사용하기 - 데이터프레임(DataFrame) 기초"
        ],
        "데이터를 시각화 해보자 - 데이터 시각화를 위한 라이브러리 matplotlib과 seaborn": [
          "데이터 시각화 라이브러리 - matplotlib과 seaborn 개요",
          "Colab 실습 - matplotlib과 seaborn으로 데이터 시각화하기",
          "ChatGPT를 이용해서 seaborn 라이브러리 학습하고 사용하기"
        ],
        "데이터 분석 응용 1 - 주식 데이터 분석해보기": [
          "코드 10줄로 시작하는 손쉬운 금융 데이터 크롤링 라이브러리 - FinanceDataReader 소개",
          "Colab 실습 - FinanceDataReader로 주식 데이터를 데이터프레임 형태로 받아오자",
          "Colab 실습 - ChatGPT를 이용해서 FinanceDataReader와 판다스(Pandas) 활용하기",
          "Colab 실습 - ChatGPT를 이용해서 FinanceDataReader와 판다스(Pandas) 활용하기 - 코드 리뷰",
          "Colab 실습 - 코스피 코스닥 전종목을 섹터(Sector)를 기준으로 분석해보자"
        ],
        "ChatGPT 확장 기능을 학습해보자": [
          "ChatGPT Code Interpreter - 파이썬 코딩없이 데이터분석 수행하기 - 비트코인 일봉 데이터 분석"
        ]
      },
      "requirements": [
        "데이터분석을 학습하고자 하는 의지"
      ],
      "description": "ChatGPT를 이용한 데이터 분석과 판다스 활용방법을 학습할 수 있는 강의입니다. ChatGPT가 만들 변화된 미래를 미리 경험해보세요.\n\n\n코딩을 몰라도 데이터분석이 가능하다면?\nChatGPT가 만들 업무처리 방식의 미래를 경험해보세요.\nChatGPT를 이용한 데이터 분석 방법을 학습합니다.\n넘파이(Numpy)와 판다스(Pandas) 라이브러리 사용법\nChatGPT를 이용한 주식 데이터 분석\n\n\n이런 분들께 추천드려요!\n데이터 분석을 수행하고 싶은 직장인\nChatGPT를 효율적으로 사용하는 방법을 학습하고 싶은 분\nChatGPT가 만들 변화된 미래를 먼저 경험하고 싶은 분\n\n\n예상 질문 Q&A\nQ. 데이터 분석이 무엇인가요?\nA. 데이터 분석(Data Analysis)은 데이터에 기반한 분석을 통해서 인사이트를 도출하고, 이로 인해 효율적이고 과학적인 의사결정을 할 수 있도록 도와주는 방법론입니다. 따라서 데이터 분석을 이용하면 더 고차원적인 업무를 수행할 수 있게됩니다.\n\n\nQ. ChatGPT를 이용한 데이터 분석의 장점은 무엇인가요?\nA. 기존에 데이터 분석을 수행하기 위해서는 Python 코드 작성방법과 판다스(Pandas) 라이브러리 사용법을 학습해야만 했습니다. 하지만 ChatGPT를 이용하면 Python 코드를 직접 작성하지 않고도 한국어 문장으로 분석하고자하는 내용을 작성해서 ChatGPT에게 요청하면, ChatGPT가 판다스 라이브러리를 이용한 Python 코드를 작성해주기 때문에 판다스 라이브러리와 Python 학습에 대한 진입장벽이 사라졌습니다.\n\n\nQ. 그렇다면 이제 Python 코드 작성방법과 판다스 라이브러리를 학습할 필요가 없나요?\nA. ChatGPT가 자동으로 Python 코드를 작성해주긴 하지만 ChatGPT가 작성해준 Python 코드를 분석하고, ChatGPT에게 더 명확하게 작업을 요청하기 위해서, 기본적인 Python 코드 작성 방법과 판다스 라이브러리 기초를 학습하면 ChatGPT를 200% 활용할 수 있습니다.",
      "target_audience": [
        "데이터 분석을 수행하고 싶은 직장인",
        "ChatGPT를 효율적으로 사용하는 방법을 학습하고 싶은 분",
        "ChatGPT가 만들 변화된 미래를 먼저 경험하고 싶은 분"
      ]
    },
    {
      "title": "Initiation rapide à l'intelligence artificielle en Python",
      "url": "https://www.udemy.com/course/initiation-rapide-a-lintelligence-artificielle-en-python/",
      "bio": "Deep learning, machine learning avec Keras et Tensorflow en Python pour débutants niveau lycée",
      "objectives": [
        "Connaître les notions générales sur l'intelligence artificielle",
        "Construire et utiliser un réseau de neurones simple en Python afin de réaliser un projet de classification",
        "Construire et utiliser un réseau de neurones simple avec les librairies Tensorflow et Keras",
        "Construire et utiliser un réseau de neurones profond sous Tensorflow et Keras"
      ],
      "course_content": {},
      "requirements": [
        "Aucune expérience dans le domaine n'est nécessaire"
      ],
      "description": "Ce cours est une initiation rapide à l’intelligence artificielle. Vous allez apprendre à coder et à utiliser un réseau de neurones en Python à l’aide des librairies Tensorflow et Keras. Le projet sur lequel nous travaillerons consistera à résoudre un problème de classification.\n\n\nLes travaux sont accessibles et exploitables en ligne grâce à l'utilisation des carnets Jupyter avec Google Colab. Aucune installation de logiciel spécifique sur son ordinateur n'est requise car tout le travail se fait en ligne.\n\n\nCette initiation est structurée de façon à introduire progressivement les concepts clés nécessaires à la mise en œuvre d’une IA basée sur des neurones artificiels. Elle est organisée en 4 sections :\n\n\nIntroduction à l’intelligence artificielle\nPrésentation du projet d’étude et des ressources utilisées\nModélisation et mise en œuvre d’un réseau de neurones artificiels\nCoder et utiliser un réseau de neurones artificiels en Python avec Tensorflow et Keras\n\n\n=== Prérequis ===\nCe cours s’adresse à des débutants, niveau lycée. Vous n'avez pas besoin d'être un spécialiste du langage Python. En effet, au fur et à mesure de votre progression, vous manierez ce langage et découvrirez les subtilités liées à son utilisation.\n\n\nSi vous êtes complètement débutant en Deep Learning et que vous souhaitez acquérir rapidement les bases nécessaire pour utiliser une IA en Python, alors cette initiation est faite pour vous.\n\n\n== Aide en ligne ===\nQuelque soit votre niveau, je suis disponible pour vous aider dans votre progression. Dans ce sens, il ne faudra surtout pas hésiter à me poser vos questions et je m'engage à y répondre dans un délai raisonnable.\n\n\n=== Structure du cours ===\n\n\n#1. Introduction à l’intelligence artificielle\nL’intelligence artificielle est un domaine en plein essor et un des plus porteurs du moment et ses ramifications sont nombreuses.\nCette section a pour objectif d’introduire les concepts clés attachés à l’IA ainsi que le vocabulaire de base qui lui est associé.\n\n\n#2. Présentation du projet d’étude et des ressources utilisées\nCette section introduit le support de notre problématique, qui est un problème dit de classification.\nUn problème de classification consiste à prédire (deviner) la valeur d'une propriété d'un individu à partir des valeurs de ses autres propriétés.\n\n\n#3. Modélisation et mise en œuvre d’un réseau de neurones artificiels\nLes réseaux de neurones, communément appelés des réseaux de neurones artificiels sont des imitations simples des fonctions d’un neurone dans le cerveau humain pour résoudre des problématiques d’apprentissage de la machine (Machine Learning)\n\n\nLes domaines d’application des réseaux neuronaux sont souvent caractérisés par une relation entrée-sortie de la donnée d’information :\nLa reconnaissance d’image\nLes classifications de textes ou d’images\nIdentification d’objets\nPrédiction de données\nFiltrage d’un set de données\n\n\n#4. Coder et utiliser un réseau de neurones artificiels en Python avec Tensorflow et Keras\nKeras et Tensorflow sont des API de haut niveau permettant de créer et d'entraîner des modèles de deep learning. Elles sont utilisées dans le cadre du prototypage rapide, de la recherche de pointe et du passage en production. Elles présentent trois avantages majeurs :\nConvivialité\nKeras dispose d'une interface simple et cohérente, optimisée pour les cas d'utilisation courants. Elle fournit des informations claires et concrètes concernant les erreurs des utilisateurs.\nModularité et facilité de composition\nLes modèles Keras sont créés en connectant des composants configurables, avec quelques restrictions.\nFacilité d'extension\nComposez des éléments de base personnalisés pour exprimer de nouvelles idées de recherche. Créez des calques, des métriques et des fonctions de perte, et développez des modèles de pointe.",
      "target_audience": [
        "Débutants souhaitant s'initier rapidement à l'IA"
      ]
    },
    {
      "title": "Análise de Dados com ChatGPT",
      "url": "https://www.udemy.com/course/analise-de-dados-com-chatgpt/",
      "bio": "Potencialize sua produtividade em análise de dados com ChatGPT, GPTs Personalizados e GenAI.",
      "objectives": [
        "Fundamentos de Prompt Engineering",
        "Recursos Avançados do ChatGPT",
        "Fundamentos de Modelos de LLMS",
        "Limpeza e Processamento de dados com ChatGPT",
        "Análise exploratória de dados com ChatGPT",
        "Seleção de modelos de Machine Learning com ChatGPT",
        "Treinamento e Validação de modelos com ChatGPT",
        "Avaliação e Refinamento de Modelos com ChatGPT"
      ],
      "course_content": {},
      "requirements": [
        "Conhecimento de técnicas convencionais de Análise de Dados (R, Python, etc)",
        "Acesso ao ChatGPT",
        "Desejável ChatGPT Plus (Assinatura)"
      ],
      "description": "O curso \"Análise de Dados com ChatGPT\" foi desenvolvido para capacitar profissionais, estudantes e entusiastas de Inteligência Artificial na utilização do ChatGPT e tecnologias de inteligência artificial generativa (GenAI) na análise de dados.\nEste curso aborda desde os fundamentos de engenharia de prompt para modelos de LLM até a aplicação prática de técnicas de machine learning, oferecendo uma abordagem objetiva e orientada a resultados para maximizar a eficiência e a produtividade em projetos de análise de dados.\nOs participantes aprenderão a interagir com o ChatGPT de forma eficaz, utilizando técnicas avançadas de prompt engineering para extrair o máximo potencial da ferramenta. Além disso, o curso cobre métodos de limpeza e processamento de dados, explorando como automatizar tarefas repetitivas e complexas, e facilitando a preparação de dados para análises subsequentes.\nDurante o curso, serão exercitadas técnicas de análise exploratória de dados, ajudando os participantes a identificar padrões e insights valiosos de maneira rápida e eficiente. A seleção, treinamento e validação de modelos de machine learning serão abordados com foco na aplicação prática, utilizando o ChatGPT para otimizar cada etapa do processo. Por fim, o curso ensinará a avaliar e refinar modelos, garantindo resultados robustos e confiáveis em projetos de análise de dados.",
      "target_audience": [
        "Cientistas de Dados que buscam agregar GenAI em seu repertório de atuação",
        "Pessoas Estatísticas que queiram focar menos em código e mais na solução científica dos problemas",
        "Analistas de Business Inteligence",
        "Analistas de Dados",
        "Gestores",
        "Líderes",
        "Diretores",
        "Entusiastas de GenAI"
      ]
    },
    {
      "title": "Машинное зрение: локализация объектов на Python",
      "url": "https://www.udemy.com/course/ittensive-machine-vision-localization/",
      "bio": "Обработка изображений с помощью фильтров, градиентов, каскадов и нейросетей для выделения форм и областей",
      "objectives": [
        "Графические фильтры и операторы",
        "Детектор границ Канни",
        "Контуры и ориентация изображения",
        "Направляющие и эллипсы Хафа",
        "Примитивы и каскады Хаара",
        "Локальные бинарные шаблоны",
        "Направленные градиенты",
        "Дескрипторы ключевых точек",
        "SIFT и SURF",
        "ORB, FAST, BRIEF",
        "Панорамное изображение",
        "Моменты изображения",
        "Глубокие нейросети",
        "YOLO",
        "Mask R-CNN",
        "MobileNet-SSD",
        "Сегментационные нейросети"
      ],
      "course_content": {
        "Введение": [
          "Приветствие",
          "Задачи машинного зрения"
        ],
        "Выделение форм": [
          "Графические фильтры",
          "Восстановление резкости",
          "Выделение границ",
          "Контуры и ориентация",
          "Геометрические формы",
          "Чтение штрих-кодов"
        ],
        "Выделение объектов": [
          "Каскады Хаара",
          "Направленные градиенты (HOG)",
          "Глубокие нейросети (DNN)",
          "Бинарные шаблоны (LBPH)",
          "Обнаружение лиц",
          "* Распознавание лиц"
        ],
        "Выделение признаков": [
          "SIFT",
          "BRIEF и ORB",
          "Моменты изображения",
          "Трансформация и повороты",
          "Объединение изображений",
          "Склейка панорамы"
        ],
        "Сегментация изображений": [
          "YOLO",
          "Mask R-CNN",
          "MobileNet-SSD",
          "Сегментация изображения"
        ],
        "Курсовой проект": [
          "Локализация пальцев стопы"
        ]
      },
      "requirements": [
        "Уверенное владение Python",
        "Знакомство с методами машинного обучения"
      ],
      "description": "Внимание: для доступа к курсам ITtensive на Udemy напишите, пожалуйста, на support@ittensive.com с названием курса или группы курсов, которые хотите пройти.\n\n\nВторой курс из серии Машинное зрение посвящен локализации объекта на изображениях с помощью OpenCV на Python. Для работа по курсу необходимо установить модули numpy pandas sklearn keras tensorflow pillow opencv-python opencv-contrib-python scikit-image cmake face_recognition mrcnn.\nКурс состоит из 4 больших частей:\nВыделение форм\nРазберем базовые подходы к фильтрации изображений и освоим авто-поворот изображений:\nГрафические фильтры: четкость, размытие, наращивание и эрозия.\nВосстановление резкости: адаптивные гистограммы, Ричардсон-Люси, маска нечеткости и устранение шума.\nВыделение границ по Собелю, Щару и Канни.\nСбор контуров из границ, ограничивающие прямоугольники и поворот изображения.\nПреобразования Хафа и выделение окружностей.\nВ заключении соберем простой сканер штрих-кодов на изображении.\nВыделение объектов\nПрименим общие подходы к обнаружению различных форм на изображении на примере человеческих лиц.\nПримитивы Хаара и каскады Виолы-Джонса.\nГистограммы направленных градиентов.\nГлубокие нейросети.\nЛокальные бинарные шаблоны гистограмм.\nДля закрепления материала обнаружим лица на фотографиях и распознаем их.\nВыделение признаков\nИспользуем дескрипторы ключевых точек для масштабно-инвариантных преобразований.\nSIFT и SURF.\nORB, FAST и BRIEF.\nМоменты изображения.\nТрехмерная трансформация и повороты.\nОбъединение изображений в панораму.\nОбъединим несколько изображений в панораму, используя ключевые точки.\nСегментация изображений\nВ заключении разберем нейросетевые подходы для локализации классов объектов на изображении.\nYOLO: You Only Look Once.\nMask R-CNN: Regions CNN.\nMobileNet-SSD: Single Shot Detection.\nСегментационные нейросети.\nВ качестве курсового проекта обработаем набор реальных фотографий для подготовки их к задаче распознавания или классификации.",
      "target_audience": [
        "Разработчики систем машинного зрения",
        "Инженеры по работе с графическими данными",
        "Научные работники и исследователи данных"
      ]
    },
    {
      "title": "Data Science con Python - Elaborare e Visualizzare Dati",
      "url": "https://www.udemy.com/course/elaborazione-e-visualizzazione-dei-dati-con-python/",
      "bio": "Impara ad Elaborare e Visualizzare i Dati con Python, NumPy, Pandas, Matplotlib, Seaborn e Plotly con Esercizi e Codice",
      "objectives": [
        "Python",
        "NumPy",
        "Pandas",
        "Matplotlib",
        "Seaborn",
        "Plotly",
        "Elaborare i Dati",
        "Visualizzare i Dati"
      ],
      "course_content": {},
      "requirements": [
        "Nessun Prerequisito"
      ],
      "description": "In questo corso imparerai due parti fondamentali del lavoro del Data Scientist: l'elaborazione e la visualizzazione dei dati. Per imparare questo faremo uso di uno dei linguaggi più popolari e più usati negli ultimi anni: Python, di cui studieremo le basi nella prima parte del corso, ci sposteremo poi all'elaborazione dei dati, con due delle librerie più importanti e utilizzate: Numpy e Pandas.\nInfine, nell'ultima parte del corso studieremo la visualizzazione dei dati, tramite ben 3 librerie diverse, tutte molto complete e molto utilizzate: Matplotlib, Seaborn e Plotly, che ti permetteranno di visualizzare qualsiasi dato voi vogliate con praticamente qualsiasi tipologia di grafico.\nTutto il corso sarà accompagnato da due moduli, uno contenente degli esercizi per testare le vostre competenze, e l'altro contenente le soluzioni agli esercizi, inoltre ci saranno dei file che conteranno tutti i codici di ogni lezione.\nVediamo la scaletta di ciò che impareremo:\nPython\nVariabili\nInput e Output\nTipi di dato\nVari operatori ( matematici, di confronto, logici )\nStrutture decisionali e cicli\nTipi di dati complesso ( liste, dizionari, tuple e set )\nNumpy\ncos'è numpy e perché utilizzarlo\nArray\nIndicizzazione e Slicing degli array\nOperazioni sugli array\nMatrici\nGenerazione di numeri random\nPandas\nCos'è e perchè usarlo\nSeries\nDataframe\nOperazioni sui Dataframe\ninput e output\nlavorare con i dati che mancano\nMatplotlib\ncos'è e perché lo usiamo\ni grafici di base\npersonalizzare i grafici\nDataframe, grafici più complessi ed esportazione\nSeaborn\ncos'è e perché lo usiamo\ngrafici a distribuzione\ngrafici categorici\nregressione\nGrafici con Pandas\nPlotly\ngrafici a punti\ngrafici a righe\ngrafici a barre\nistogrammi\naltri grafici",
      "target_audience": [
        "Saper Elaborare e Visualizzare i Dati con le librerie di Python"
      ]
    },
    {
      "title": "통계 분석 마스터 클래스 : 회귀분석과 실전 프로젝트",
      "url": "https://www.udemy.com/course/maso-ds-excel-onc49-2/",
      "bio": "수학적 지식 No, 입문자도 따라올 수 있는 쉽고 재미있는 통계를 실무에!",
      "objectives": [
        "확률과 추론을 통해 미래의 데이터를 예측할 수 있는 역량",
        "회귀분석을 통해 고급 통계 분석을 수행하는 역량",
        "통계 지식을 현실 문제의 해결에 적용하는 역량",
        "현실의 비즈니스 문제(Business Question)를 해결하는 최적의 방법을 찾아내는 역량"
      ],
      "course_content": {
        "T-검정": [
          "PST2501 – T-검정의 이해",
          "PST2502 – 독립표본 T 검정(1)",
          "PST2503 – 독립표본 T 검정(2)",
          "PST2504 – 일표본 T 검정",
          "PST2505 – 대응표본 T 검정"
        ],
        "분산분석": [
          "PST2601 분산분석의 이해",
          "PST2602 – 일원배치 분산분석",
          "PST2603 – 반복 없는 이원배치 분산분석",
          "PST2604 – 반복 있는 이원배치 분산분석",
          "PST2605 – 이원 분산분석 – 주 효과와 교호 작용"
        ],
        "회귀분석의 이해": [
          "PST2701 – 회귀분석의 이해"
        ],
        "단순 선형 회귀 분석": [
          "PST2801 – 기온에 따른 아이스크림 판매량 추정",
          "PST2802 회귀분석의 결과 읽기 – 회귀식과 회귀 계수",
          "PST2803 회귀분석의 결과 읽기 – 결정계수와 잔차",
          "PST2804 다양한 회귀분석 실행 방법",
          "PST2805 – 잘못된 분석 사례"
        ],
        "다중 선형 회귀 분석": [
          "PST2901 – 다중 선형 회귀분석의 이해",
          "PST2902 – 다중 선형 회귀분석의 실행과 결과 읽기",
          "PST2903 – 다중 선형 회귀분석 – 회귀분석식을 활용한 추정"
        ],
        "로지스틱 회귀분석": [
          "PST3001 – 로지스틱 회귀분석의 이해",
          "PST3002 – 로지스틱 회귀분석의 실행",
          "PST3003 – 로지스틱 회귀분석의 결과 읽기"
        ],
        "신입사원 업무 성과 예측": [
          "PST3101 – 실전프로젝트_PPDAC 모형",
          "PST3102 – 실전프로젝트-데이터 요약 및 패턴 찾기(1)",
          "PST3103 – 실전프로젝트-데이터 요약 및 패턴 찾기(2)",
          "PST3104 – 실전프로젝트-데이터 요약 및 패턴 찾기(3)",
          "PST3105 – 실전프로젝트-결론 도출과 새로운 문제 발견"
        ],
        "어떻게 하면 매출을 올릴까": [
          "PST3201 – 실전프로젝트_매장 방문횟수가 늘수록 구매금액이 오르는가",
          "PST3202 – 실전프로젝트_어떤 요인이 매출에 영향을 미치는가",
          "PST3203 – 실전프로젝트_DM 발송이 정말 효과가 있는지 확인해보자",
          "PST3204 – 실전프로젝트_어느 매체를 사용할 것인가",
          "PST3205 – 실전프로젝트_구매 여부를 예측해보자"
        ]
      },
      "requirements": [
        "실습 위주의 강의이기 때문에 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기를 함께 준비해주시면 좋습니다.",
        "또한 Windows OS 기반으로 실습이 진행되므로, Windows 환경에서의 강의 수강을 추천해드립니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n통계, 왜 배워야 할까요?\n무엇이든지 기본기가 잡혀 있으면 두려움과 걱정은 없어지기 마련입니다.\n이제는 꼭 필요한 데이터 분석!\n바로 데이터 분석의 기본기는 ‘통계 지식’에서 시작합니다.\n통계를 배우면, 실생활에 유용합니다.\n우리의 일상이 통계에 묻혀 있다는 사실, 알고 계셨나요? 통계를 통해 우리 일상에서 발생하는 이슈에 답을 찾아볼 수 있을 겁니다!\n통계를 배우면, 합리적인 사고가 가능합니다.\n수치를 단순히 숫자로만 바라보는 것이 아닌, 그 이면의 의미에 집중하는 방법을 알게 됩니다.\n통계를 배우면, 진짜와 가짜를 구별할 수 있습니다.\n동일한 이슈를 다루는 기사인데도 왜 스탠스가 다를까요?\n이제 통계치를 스스로 직접! 해석하여 진짜 기사를 발견해낼 수 있습니다.\n통계를 배우면, 데이터 기반의 판단이 가능합니다.\nB회사의 한 달 매출이 3,000만 원이라고 합니다.\n과연, 3,000만 원이 좋은 성과일까요?\n여러분은 이 물음에 통계를 활용해 그 답을 내릴 수 있습니다.\n‘10% 담뱃값 인상이 청소년층의 흡연을 어느 정도 줄일 수 있을까?’\n‘직업 훈련은 재취업률을 얼마나 높이는가?’\n‘외국인 직접 투자가 늘면 경제 성장률이 제고되는가?’\n위 질문에 정확히 답하기 위해선 “통계”가 필요합니다!\n그러나,\n막상 시작해보려면 너무 막막한 통계! 고등학교만 졸업하면 통계와는 이별일 줄 알았는데…\n“통계분석 마스터 클래스”로 현실에 바로 적용하는 통계를 배워\n우리 삶 속에 숨겨진 통계적 원리를 발견해보세요!\n\n\n<통계분석 마스터 클래스 : 회귀분석과 실전 프로젝트> 강의를 듣고 나면, 여러분은 다음과 같은 역량을 확보할 수 있습니다.\n수집한 데이터를 읽고 요약하는 기술통계 및 시각화 역량\n회귀분석을 통해 고급 통계 분석을 수행하는 역량\n통계 지식을 현실 문제의 해결에 적용하는 역량\n현실의 비즈니스 문제(Business Question)를 해결하는 최적의 방법을 찾아내는 역량\n\n“통계분석 마스터 클래스: 회귀분석과 실전 프로젝트” 강의를 듣고, 여러분의 의사결정에 날개를 달아보세요!\n\n\n[ 강 사 소 개 ]\n김 진\n現 마소캠퍼스 대표\n서울대학교 MBA 졸업\n오라클, 네이버를 거쳐 중국 네이버 개발 아웃소싱 센터를 설립 및 지휘하였으며, 서울대 MBA 졸업 후 글로벌 모바일 기업인 Obigo로 옮겨 데이터 분석에 기반한 성과 관리 시스템 도입 등 국내외 다양한 사업 영역을 개척하였습니다. 2010년에는 게임웹진 플레이포럼 M&A 후 데이터 분석과 디지털 마케팅을 실무에 본격 도입해 코리안클릭 수치 기준으로 월 평균 활성유저(MAU) 238만, 월 평균 페이지뷰(PV)수 1,700만을 달성하였습니다. 개발자, 전문 경영인의 길을 걸어온 사업가로서 폭넓은 경험과 IT 기술을 융합해 현재는 기업의 ROI를 높여줄 실무 전문가 교육에 힘 쓰고 있습니다.\n\n\n최 정 아\n現 마소캠퍼스 콘텐츠랩 이사\n연세대학교 경영학 석사\nYSCEC의 웹마스터로서 연세-게이오(日)-릿쿄(日)-푸단(中) 대학의 YKLP 사업에 초기부터 합류해 성공적으로 론칭시킨 국제 원격교육 전문가입니다. 이후 플레이포럼 편집장으로 자리를 옮겨 MAU 238만 명의 커뮤니티를 7년간 운영하면서 최대 900만 뷰를 달성한 디지털 콘텐츠를 제작했습니다. 언어학, 정보학, 경영학 학위를 소지한 다재다능한 디지털마케팅 전문가로서 데이터를 활용해 디지털 플랫폼에서 최고의 퍼포먼스를 이뤄냈습니다. 효과적인 데이터 마케팅 방법을 다룬 도서를 다수 출간하여 모두 경제경영 분야 베스트셀러에 오른 검증된 지식을 공유하고 있습니다.",
      "target_audience": [
        "수학이 무서워 통계에 장벽을 느끼셨던 분",
        "데이터 분석 프로젝트 기획력을 함양하고 싶은 분",
        "실습으로 통계를 한 번에, 제대로 이해하고 싶은 비전공자",
        "실무에 통계 분석을 바로 적용하여 인사이트를 찾고 싶은 분",
        "비즈니스 애널리틱스 역량을 함양하여 데이터 사이언스와 경영 의사결정을 결합하고 싶은 분"
      ]
    },
    {
      "title": "Pelatihan Data Science dengan Deep Learning dan Python",
      "url": "https://www.udemy.com/course/pydeeplearning/",
      "bio": "Memahami dan Mengimplementasi Deep Learning dengan Python, Tensorflow, PyTorch and TensorBoard",
      "objectives": [
        "Memahami konsep dan cara kerja Deep Learning",
        "Implementasi dan membuat aplikasi Deep Learning dengan Python",
        "Eksplorasi Deep Learning dengan Tensorflow dan Keras",
        "Eksplorasi Deep Learning dengan PyTorch",
        "Hyperparameter Tuning Untuk Deep Learning",
        "Pemanfaatan TensorBoard Untuk Visualiasi pada TensorFlow dan PyTorch"
      ],
      "course_content": {
        "Pendahuluan": [
          "Introduction",
          "Persiapan Pelatihan"
        ],
        "Konsep dan Teori Deep Learning": [
          "Pendahuluan",
          "Apa Itu Deep Learning ?",
          "Pengantar Neural Network - Bagian 1",
          "Pengantar Neural Network - Bagian 2",
          "Training Neural Network - Bagian 1",
          "Training Neural Network - Bagian 2",
          "Generalisasi",
          "Regularisasi",
          "Hyper-Parameter Tuning",
          "Convolutional Neural Network (CNN)",
          "Recurrent Neural Network (RNN)"
        ],
        "Deep Learning Dengan Keras Dan Tensorflow": [
          "Pendahuluan",
          "Apa Itu Keras dan Tensorflow ?",
          "Instalasi dan Konfigurasi Untuk Keras dan Tensorflow",
          "Pengenalan Tensor : Deklarasi, Operasi Matematika dan Dimensi",
          "Pengenalan Tensor : Indexing",
          "Pengenalan Tensor : Manipulasi Dimensi",
          "Pengenalan Tensor : DTypes, Broadcasting, dan tf.convert_to_tensor",
          "Pengenalan Tensor : Ragged Tensor, String Tensor dan Penyebaran Tensor",
          "Variabel Pada Tensorflow",
          "Penggunaan CPU dan GPU Pada Tensorflow",
          "Penggunaan TPU Pada Tensorflow",
          "Model dan Layer",
          "Model dan Layer: Model Sequential",
          "Model dan Layer: Menampilkan Visual Grafik Bentuk Model",
          "Catatan: Menampilkan Visual Grafik Bentuk Model",
          "Model dan Layer: Model Functional API",
          "Eksplorasi Macam-Macam Layer Pada Keras",
          "Tensorflow Module",
          "Training dan Evaluasi - Bagian 1",
          "Training dan Evaluasi - Bagian 2",
          "Training dan Evaluasi - Bagian 3",
          "Kustomisasi Model",
          "Serialisasi dan Penyimpanan Model",
          "TensorBoard : Tool Visualisasi Tensorflow",
          "Tensorflow Hub - Repository Kumpulan Trained Model"
        ],
        "Deep Learning Dengan PyTorch": [
          "Pendahuluan",
          "Apa Itu PyTorch ?",
          "Instalasi dan Konfigurasi Untuk PyTorch",
          "Pengenalan PyTorch Tensor",
          "Penggunaan GPU dan CPU Pada PyTorch",
          "Penggunaan TPU Pada PyTorch",
          "Model dan Layer",
          "Datasets dan DataLoaders",
          "Training dan Evaluasi",
          "Menyimpan dan Memuat Model PyTorch",
          "Penggunaan TensorBoard Pada PyTorch"
        ],
        "Hyperparameter Tuning Untuk Model Deep Learning": [
          "Pendahuluan",
          "Hyperparameter Tuning Pada Tensorflow",
          "Hyperparameter Tuning Pada Tensorflow Menggunakan Tensorboard",
          "Hyperparameter Tuning Pada PyTorch",
          "Hyperparameter Tuning Pada PyTorch Menggunakan Tensorboard"
        ],
        "Kumpulan Proyek Deep Learning": [
          "Pengenalan Digit Tulisan Tangan Dengan Deep Learning dan Tensorflow",
          "Pengenalan Digit Tulisan Tangan Dengan Deep Learning dan PyTorch"
        ]
      },
      "requirements": [
        "Komputer dengan sistem operasi Windows, macOS atau Linux",
        "Sudah menguasai dasar pemrograman Python",
        "Akses Internet"
      ],
      "description": "Selamat datang di program Pelatihan Data Science dengan Deep Learning dan Python\nPelatihan ini diperuntukan untuk rekan - rekan ingin belajar data science dan machine learning dengan titik fokus pemanfaatan Deep Learning untuk model machine learning dan data science.\nPeserta diharapkan sudah menguasai pemrograman Python dasar implementasi machine learning dan data science dengan menggunakan Python. Kami juga menyediakan konten mengenai Pelatihan Data Science dan Machine Learning Dengan Python yang ada di Udemy ini.\nSeluruh konten didalam pelatihan ini dilaksanan secara step - by - step (langkah demi langkah) dan berurutan sehingga ini diharapkan semua peserta dapat dengan mudah mengikuti semua praktikum yang diberikan didalam pelatihan ini. Diharapkan semua peserta dapat mengikuti konten pelatihan ini secara berurutan ;).\nBerikut ini konten yang akan diberikan pada pelatihan ini.\nPersiapan pelatihan\nKonsep dan teori mengenai Deep Learning\nPengenalan TensorFlow dan Keras\nDasar Tensor TensorFlow\nPemanfaatan GPU dan TPU pada komputasi TensorFlow dan Keras\nPembuat Model dan Layer Untuk TensorFlow\nTraining dan evaluasi Deep Learning pada TensorFlow\nPengenalan dan instalasi PyTorch\nPemanfaatan GPU dan TPU pada komputasi PyTorch\nMembangun model Deep Learning dengan PyTorch\nTraining dan evaluasi Deep Learning pada PyTorch\nPenggunaan TensorBoard untuk visualisasi model pada TensorFlow dan PyTorch\nPenerapan Hyperparameter Tuning pada TensorFlow dan Keras\nPenerapan Hyperparameter Tuning pada PyTorch\nPenggunaan TensorBoard untuk implementasi Hyperparameter\nKumpulan Studi Kasus\n\n\nJika ada hal - hal yang ingin ditanyakan mengenai topik diatas, rekan - rekan dapat langsung ditulisnya di ruang diskusi pada web ini sehingga rekan-rekan lainnya dapat mengetahui dan ikut terlibat diskusinya.",
      "target_audience": [
        "Pelajar dan mahasiswa yang ingin mempelajari data science dengan menggunakan Deep Learning",
        "Professional yang ingin mempelajari Deep Learning",
        "Pengajar dan peneliti yang ingin mempelajari Deep Learning"
      ]
    },
    {
      "title": "معسكر الذكاء الإصطناعي | Artificial Intelligence Bootcamp",
      "url": "https://www.udemy.com/course/artificial-intelligence-bootcamp-ar/",
      "bio": "أفضل بداية من الصفر لأي حد عاوز يتعلم ويحترف مجال \"الذكاء الإصطناعي\" بكل تخصصاته ومواضيعه AI, ML, DL, GENAI, LLM, AGENTS",
      "objectives": [
        "مقدمة في الذكاء الإصطناعي | Introduction to Artificial Intelligence",
        "بايثون للذكاء الأصطناعي | Python for Artificial Intelligence",
        "أساسيات الذكاء اللإصطناعي التنبؤي | Predictive Artificial Intelligence Basics",
        "أساسيات تعلم الآلة | Machine Learning Basics",
        "أساسيات التعلم العميق | Deep Learning Basics",
        "أساسيات الذكاء الإصطناعي التوليدي | Generative Artificial Intelligence (GenAI) Basics",
        "أساسيات نماذج اللغة الكبيرة | Large Language Models (LLM) Basics",
        "أساسيات وكلاء الذكاء الإصطناعي | AI Agents Basics",
        "مشاريع الذكاء الإصطناعي | Artificial Intelligence Projects"
      ],
      "course_content": {
        "التعريف بالمعسكر التدريبي | AI Bootcamp Orientation": [
          "هيا بنا نلعب (عرض تقديمي لتوضيح أهمية الذكاء الإصطناعي) | AI DEMO (Why AI?)",
          "مواضيع الدورة التدريبية | Course Topics",
          "الجمهور المستهدف ومتطلبات المعسكر التدريبي | Bootcamp Audience & Prerequisites",
          "الأدوات المستخدمة في المعسكر التدريبي | AI Bootcamp Toolkit",
          "هل أنت مستعد؟ (ملخص المقدمة) | Are You Ready (Summary)"
        ],
        "=== PART(A): WELCOME TO ARTIFICIAL INTELLIGENCE WORLD ===": [
          "القسم الأول من المعسكر التدريبي | Bootcamp Part One"
        ],
        "مقدمة عامة عن الذكاء الإصطناعي | AI General Introduction": [
          "نظرة عامة General Overview",
          "يعني إيه ذكاء إصطناعي؟ What is Artificial Intelligence",
          "أنواع الذكاء الإصطناعي AI Types",
          "موضوعات وأفرع الذكاء الإصطناعي AI Branches & Topics",
          "أدوات الذكاء الإصطناعي AI Tech Stack",
          "يعني إيه نموذج ذكاء إصطناعي What is an AI Model?",
          "تطبيق عملي: وكيل ذكاء إصطناعي بسيط (لا يتطلب التطبيق) Simple AI Agent (Flowise)"
        ],
        "استخدام أدوات الذكاء الإصطناعي لبناء نموذج ذكاء إصطناعي | AI Tools for AI Models": [
          "مقدمة سريعة Quick Introduction",
          "استخدام شات جي بي تي في بناء نماذج ذكاء إصطناعي ChatGPT for AI Models",
          "استخدام جيميناي في بناء نماذج ذكاء إصطناعي Gemini for AI Models",
          "ماذا بعد، إيه الخطوة الجاية في الذكاء الإصطناعي What's Next?"
        ],
        "أساسيات البرمجة باستخدام بايثون | Python Programming Basics": [
          "تحميل الأدوات والتطبيقات الخاصة بالبرمجة Installing Programming Toolkit",
          "مقدمة عامة وسريعة عن البرمجة وحل المشكلات Intro to Programming & Problem Solving",
          "التعامل مع بيئة التطوير والعمل Jupyter IDE Basics",
          "التعامل مع بيئة التطوير والعمل Google Colaboratory Basics",
          "أساسيات بايثون: التعامل مع التعليقات Python Comments",
          "أساسيات بايثون: التعامل مع المسافات Python Whitespaces",
          "أساسيات بايثون: المتغيرات Python Variables",
          "أساسيات بايثون: المعاملات Python Operators",
          "أساسيات بايثون: أنواع البيانات الأساسية Python Basic Data Types",
          "أساسيات بايثون: التعامل مع سلاسل الحروف Python Strings",
          "المنطق والشروط Logic & Conditions (if,elif,else)",
          "الحلقات التكرارية Python Loops (for loops)",
          "الحلقات التكرارية Python Loops (while loops)",
          "هياكل البيانات: مقدمة Introduction to Python Data Structures",
          "هياكل البيانات: التعامل مع القوائم في بايثون Python Lists",
          "هياكل البيانات: التعامل مع المجموعات في بايثون Python Tuples",
          "هياكل البيانات: التعامل مع المجموعات في بايثون Python Sets",
          "هياكل البيانات: التعامل مع القواميس في بايثون Python Dictionaries",
          "التعامل مع الدوال والمكتبات في بايثون Python Functions & Packages",
          "التعامل مع الملفات في بايثون Python Files I/O"
        ],
        "تحليل البيانات باستخدام بايثون | Python Data Analysis": [
          "دورة سريعة في مكتبة التعامل مع البيانات العددية | NumPy Crash Course (Numerical)",
          "دورة سريعة في مكتبة تحليل البيانات | Pandas Crash Course (Data Analysis)",
          "دورة سريعة في مكتبة تصور البيانات | Matplotlib & Seaborn Crash Course (Data Viz)"
        ],
        "=== PART(B): PREDICTIVE ARTIFICIAL INTELLIGENCE BASICS ===": [
          "القسم الثاني من المعسكر التدريبي | Bootcamp Part Two"
        ],
        "أساسيات تعلم الآلة | Machine Learning Basics": [
          "مقدمة الدورة التدريبية Machine Learning Foundations Course Introduction",
          "يعني إيه ذكاء اصطناعي وإيه تطبيقاته؟ What is Artificial Intelligence",
          "تعريف وأهمية تعلم الآلة Machine Learning Definition",
          "أنواع وتطبيقات تعلم الآلة Machine Learning Types & Its Applications",
          "مراحل مشروع تعلم الآلة Machine Learning End-to-end Project",
          "نماذج تعلم الآلة ML Models (أخطر فيديو في تعلم الآلة والذكاء الاصطناعي)"
        ],
        "خوارزميات تعلم الآلة | Machine Learning Algorithms": [
          "تجهيز البيانات لنماذج تعلم الآلة Feature Engineering for Machine Learning",
          "تطبيق عملي: تجهيز البيانات تعلم الآلة Feature Engineering for Machine Learning",
          "التعلم الغير مراقب (العناقيد) Unsupervised Learning (Clustering)",
          "تطبيق عملي: التعلم الغير مراقب (العناقيد) Unsupervised Learning (Clustering)",
          "التعلم المراقب (التصنيف) Supervised Learning (Classification)",
          "تطبيق عملي: التعلم المراقب (التصنيف) Supervised Learning (Classification)",
          "التعلم المراقب (الانحدار) Supervised Learning (Regression)",
          "تطبيق عملي: التعلم المراقب (الانحدار) Supervised Learning (Regression)"
        ],
        "أساسيات التعلم العميق | Deep Learning Basics": [
          "مقدمة عامة عن التعلم العميق Deep Learning Introduction",
          "تعريف التعلم العميق What is Deep Learning",
          "أهمية التعلم العميق Why Deep Learning",
          "تطبيقات التعلم العميق Deep Learning Applications"
        ]
      },
      "requirements": [
        "لا توجد أي متطلبات لهذه الدورة"
      ],
      "description": "معسكر الذكاء الإصطناعي | Artificial Intelligence Bootcamp\nدورة الذكاء الإصطناعي الشاملة Full AI Diploma بنحاول من خلاله نقدم دورة \"شاملة ومتكاملة\" في الذكاء الإصطناعي بنحاول من خلالها نغطي كل المفاهيم والتقنيات والأدوات المهمة في المجال زي PYTHON, AI, ML, DL, GENAI, LLM, AGENTS .. ونعتبرها مبادرة نسعى من خلالها إلى إثراء المحتوى العربي في هذا المجال من خلال إعداد دورة تدريبية شاملة بشكل تفاعلي وتطبيقي لكل مواضيع وتخصصات هذا المجال .. وبنحاول إن التدريب يكون مناسب للمبتدئين ولأي شخص يرغب في بدء العمل كمهندس ذكاء إصطناعي AI Engineer واحتراف هذا المجال من الصفر.\n\n\nالدبلومة بتتميز بالآتي:\n\n\n- خطة واضحة ومنظمة للبدء في المجال من الصفر وحتى احترافه\n- 6 كورسات في كورس واحد\n- أكثر من 20 ساعة تدريبية\n- تطبيقات عملية ومشاريع Case-studies\n- تحميل ملفات التدريب والأكواد Course Materials\n- المحتوى متاح مدى الحياة\n- شهادة بنهاية التدريب\n\n\nبنشرح في الدبلومة التقنيات والأدوات الرئيسية لأي مهندس ذكاء إصطناعي:\n- مقدمة في الذكاء الإصطناعي | Introduction to Artificial Intelligence\n- بايثون للذكاء الأصطناعي | Python for Artificial Intelligence\n- أساسيات الذكاء اللإصطناعي التنبؤي | Predictive Artificial Intelligence Basics\nأساسيات تعلم الآلة | Machine Learning Basics\nأساسيات التعلم العميق | Deep Learning Basics\n- أساسيات الذكاء الإصطناعي التوليدي | Generative Artificial Intelligence (GenAI) Basics\nأساسيات نماذج اللغة الكبيرة | Large Language Models (LLM) Basics\nأساسيات وكلاء الذكاء الإصطناعي | AI Agents Basics\n- مشاريع الذكاء الإصطناعي | Artificial Intelligence Projects\n\n\n--\n= (*) تحذير هام: تم بذل مجهود كبير بفضل الله وتوفيقه من قبل م. مصطفى عثمان في إعداد هذا المحتوى الذي يقدم بصفة شخصية لك مقابل الاشتراك، رجاء عدم نسخه أو استخدامه بعيداً عن الموقع أو الإتجار به لإن ذلك يعرضك للمسائلة أمام الله عز وجل .. شكراً لتفهمك، وشكراً لاهتمامك بما نقدمه",
      "target_audience": [
        "أي حد لسة هيبدأ في مجال الذكاء الإصطناعي وعاوز يبدأ بداية موفقة"
      ]
    },
    {
      "title": "실전 | ChatGPT로 데이터 수집(시장조사) 웹스크레이핑(크롤링)",
      "url": "https://www.udemy.com/course/chatgpt_scraping/",
      "bio": "시행착오를 통해 고기 잡는 법을 배우는 강의 (네이버 블로그, 네이버 쇼핑, 인스타그램, 메타 광고 라이브러리, 개드립넷 커뮤니티 사이트)",
      "objectives": [
        "ChatGPT 활용하는 팁과 오류 대응방안",
        "네이버 블로그 데이터 가져오는 법",
        "네이버 쇼핑검색 데이터 가져오는 법",
        "인스타그램 데이터 가져오는 법",
        "메타 광고 라이브러리 데이터 가져오는 법",
        "커뮤니티 사이트(개드립넷) 데이터 가져오는 법"
      ],
      "course_content": {
        "소개": [
          "강의 소개"
        ],
        "네이버 블로그": [
          "목표 확인하기",
          "첫번째 과제 수행하기(블로그글)",
          "문제상황 해결하기 + 오류 대응방안",
          "기억해야할 내용",
          "두번째 과제 수행하기(검색결과)",
          "팁: 스크레이핑 단서 찾기 + 오류 대응방안",
          "첫번째 + 두번째 과제 합치기",
          "두개의 코드 똑똑하게 합치는 법 (Function)",
          "기억해야할 내용",
          "특정 키워드만 들어간 내용 가져오기"
        ],
        "네이버 쇼핑": [
          "목표 확인하기",
          "과제 도식화하기",
          "첫번째 과제 수행하기(상품명 가져오기)",
          "스크롤 내리는 법",
          "두번째 과제 수행하기(등장횟수)",
          "첫번째 + 두번째 과제 합치기"
        ],
        "인스타그램": [
          "Instaloader 활용하기"
        ],
        "메타 광고 라이브러리": [
          "목표 확인하기",
          "첫번째 과제 수행하기(영역 찾기)",
          "팁. 여러 레벨의 HTML코드 시도해보기",
          "두번째 과제 수행하기(텍스트 재구성)",
          "팁. 최종 결과물 예시 제공하며 물어보기"
        ],
        "커뮤니티 사이트(Dogdrip.net)": [
          "목표 확인하기",
          "첫번째 과제 수행하기(커뮤니티 인기 시간대 확인하기)",
          "인기 시간대 데이터 카운트하기",
          "두번째 과제 수행하기(커뮤니티 인기 요일 확인하기)"
        ],
        "마무리": [
          "맺는 말"
        ],
        "Quiz": [
          "배운 것 리뷰하기"
        ]
      },
      "requirements": [
        "직장인맞춤 | ChatGPT 로 배우는 초단기 파이썬 코딩 | 실전 문제 13개 | 판다스, 크롤링 포함"
      ],
      "description": "이 강의는 ChatGPT를 활용하여 마케팅에 필요한 다양한 웹사이트들을 스크레이핑하는 법을 실전적으로 배우는 강의입니다.\n정해진 정답을 알려주는 것이 아니라, 초보자들이 실제로 마주할 수 있는 시행착오와 어려움을 실전으로 경험하면서 학습합니다.\n이제는 배워야 합니다. AI를 잘 다루는 법!\n본 강의 수강 전 『직장인맞춤 | ChatGPT 로 배우는 초단기 파이썬 코딩 | 실전 문제 13개 | 판다스, 크롤링 포함』 강의 수강을 권장합니다.\n\n\n배우는 내용\n\n네이버 블로그 데이터 가져오기\n네이버 쇼핑 데이터 가져오기\n인스타그램 데이터 가져오기\n메타 광고 라이브러리 데이터 가져오기\n커뮤니티 사이트(개드립넷) 데이터 가져오기",
      "target_audience": [
        "ChatGPT 활용법을 배우고 싶으신 분들"
      ]
    },
    {
      "title": "Gráficos com Matplotlib e Python com Interface Gráfica",
      "url": "https://www.udemy.com/course/graficos-com-matplotlib-e-python-com-interface-grafica/",
      "bio": "Crie gráficos em Python com Matplotlib e dê vida aos seus dados!",
      "objectives": [
        "Criar gráficos em Python usando a biblioteca Matplotlib.",
        "Desenvolver uma interface gráfica para visualização de dados.",
        "Criar gráficos de colunas, linha, funil e muito mais.",
        "Melhore suas habilidades em Python.",
        "Utilizar recursos avançados do Matplotlib"
      ],
      "course_content": {
        "Introdução": [
          "O que vamos aprender?",
          "Dica!",
          "Baixando e Instalahndo o Anaconda",
          "Instalando Bibliotecas e Configurando a Tela Principal",
          "Criando Menu e Botões da Tela",
          "Configura a Figura para Criar um Gráfico em Branco na Tela",
          "Função Abrir Arquivo",
          "Criando Tela para Configurar o Gráfico de Colunas",
          "Gráfico de Colunas parte 1",
          "Salvando o Gráfico com uma Imagem no Computador",
          "Criando Grafico de Colunas exemplo 2",
          "Criando Gráfico de Pizza modelo 1",
          "Criando Gráfico de Pizza modelo 2",
          "Gráfico de Linhas Modelo 1",
          "Gráfico de Linhas Modelo 2",
          "Gráfico de Área exemplo 1",
          "Gráfco de Área exemplo 2",
          "Gráfico de Funil",
          "Tela Editar Dados - Parte 1",
          "Populando a Treeview",
          "Renomear Coluna da Treeview",
          "Atualizar Treeview",
          "Remover Colunas do DataFrame",
          "Remover Linhas Alternadas do DataFrame",
          "Ajustes Gráficos",
          "Remover Duplicados",
          "Remover Linhas em Branco",
          "Tela Exemplo Simulação Dashboard 1",
          "Tela Exemplo Simulação Dashboard 2 e 3"
        ],
        "Mensagem Final de Curso": [
          "Parabéns, você completou o curso"
        ]
      },
      "requirements": [
        "É recomendado ter conhecimentos básicos de programação em Python, como a sintaxe básica da linguagem, estruturas de controle de fluxo (if/else, for, while) e estruturas de dados (listas, dicionários, tuplas).",
        "Não é necessário ter conhecimentos prévios sobre a biblioteca Matplotlib"
      ],
      "description": "Você já quis aprender a criar gráficos em Python? Então este curso é para você!\n\n\nNosso curso de Gráficos com Matplotlib e Python com Interface Gráfica é perfeito para quem quer aprender a criar gráficos. Com a ajuda do Matplotlib, uma biblioteca poderosa para visualização de dados em Python, você aprenderá a criar gráficos de colunas, pizza, linha, área e funil.\n\n\nMas não é só isso! Você também aprenderá a criar uma interface gráfica para que seus gráficos possam ser criados e visualizados com facilidade e elegância. Com a interface gráfica, você poderá criar widgets personalizados e interativos para facilitar a manipulação de dados e de seus gráficos.\n\n\n\n\nPara quem é este curso?\nO curso é projetado para todos, desde iniciantes em programação até cientistas de dados experientes. Você terá a oportunidade de aplicar as habilidades recém-adquiridas em situações do mundo real.\n\n\nPreciso de conhecimento prévio de Python?\nSim. Você precisa conhecer o básico do Python, que são variáveis, tipos de dados, funções, condicionais e loops. Este curso não cobre isso porque você pode encontrar esse conteúdo facilmente no YouTube.\n\n\nEste curso cobre Python 2 ou Python 3?\nPython 3.\n\n\nPor que escolher nosso curso?\n\n\nAprendizado interativo: Nossa abordagem interativa de ensino permite que você aprenda de forma envolvente e prática.\nSuporte a dúvidas: Para ajudá-lo a atingir seus objetivos de aprendizado.\nFlexibilidade: Nossas aulas são oferecidas em formato online, para que você possa estudar quando quiser e sempre que quiser em qualquer lugar com um computador e acesso a internet.\n\n\nNo final do curso, você terá as habilidades necessárias para criar projetos visualmente atraentes e interativos usando Python e interface gráfica de usuário.\n\n\nInscreva-se agora e comece a aprender!",
      "target_audience": [
        "É destinado a estudantes e profissionais que desejam aprender como criar gráficos e visualizações de dados usando a biblioteca Matplotlib"
      ]
    },
    {
      "title": "LlamaIndex : Crie Agentes de IA e Apps com LLMs",
      "url": "https://www.udemy.com/course/llamaindex-crie-agentes-de-ia-e-apps-com-llms/",
      "bio": "Criação de Agentes de IA, Chatbots, Análise de Dados, Assistente de Banco de Dados com LlamaIndex na Prática",
      "objectives": [
        "Fundamentos do RAG (Retrieval-Augmented Generation) – Como melhorar a precisão e relevância das respostas geradas por LLMs.",
        "Criação de Chatbots com Gradio – Desenvolvimento e implementação de um chatbot interativo usando LlamaIndex.",
        "Análise de Dados com PandasQueryEngine – Consulta e extração de insights a partir de grandes volumes de dados.",
        "Desenvolvimento de Agentes Inteligentes – Construção de agentes autônomos para automação e tomada de decisões.",
        "Integração Avançada com LLMs – Uso do LlamaIndex para potencializar modelos de linguagem em aplicações reais."
      ],
      "course_content": {
        "Introdução": [
          "Apresentação do Curso"
        ],
        "Introdução a Agentes de IA": [
          "O que é um Agente de IA",
          "Exemplos práticos de agentes inteligentes",
          "Tipos de agentes inteligentes"
        ],
        "Introdução ao LlamaIndex": [
          "O que é o LlamaIndex",
          "Aplicabilidades do LlamaIndex",
          "Como Usar o LlamaIndex"
        ],
        "Primeiros Passos com Python": [
          "Instalação e Configuração do Python",
          "Ambiente Virtual de Desenvolvimento e Pip",
          "Introdução a Versionamento com Git"
        ],
        "LlamaIndex - Desenvolvendo Chatbot com RAG": [
          "Preparação do Ambiente",
          "Carregando os Documentos",
          "Documentos em Partes Menores",
          "Gerando Embeddings",
          "Salvando Embeddings no Banco de Dados",
          "Recuperação de Informações",
          "Conversa Interativa",
          "Desenvolvendo Interface com Gradio"
        ],
        "LlamaIndex - Analisando Dados do Banco de Dados": [
          "Configuração do Ambiente",
          "Importando os Dados",
          "Configuração do LlamaIndex",
          "Configurações do Banco de Dados ao Modelo",
          "Testando a Primeira Consulta",
          "Melhorando o Contexto com Prompt",
          "Testando Nova Consulta"
        ],
        "LlamaIndex - Analisando Dados com Pandas": [
          "Conhecendo o Groq",
          "Demonstração do Projeto e Configuração de Ambiente",
          "Importando os Dados",
          "Usando o PandasQueryEngine",
          "Gerando Gráficos",
          "Criando o Pipeline",
          "Estruturando o Pipeline da Consulta",
          "Criando a Interface com o Gradio"
        ],
        "LlamaIndex - Desenvolvimento de Agentes": [
          "Configuração do Ambiente",
          "Convertendo Função em Tool",
          "Desenvolvendo outra Tool para o Agent",
          "Usando o Tavily",
          "Gerando Embeddings e Engine de Busca",
          "Testando o Agente",
          "Usando Agente ReAct"
        ],
        "Interface Gráfica com Gradio": [
          "Conhecendo o Gradio",
          "Criando as Primeiras Aplicações",
          "Tipos de Entrada e Saída",
          "Customização da Interface I",
          "Customização da Interface II",
          "Usando Componentes Interativos",
          "Consolidando os Conhecimentos"
        ],
        "Dominando a Linguagem Python": [
          "Criando o Primeiro Programa",
          "Exercício 1 - Hello World",
          "Tipos de Dados",
          "Exercício 2 - Tipos de Dados",
          "Utilizando o Input",
          "Concatenando Valores",
          "Exercício 3 - Concatenando Valores",
          "Utilizando Operadores",
          "Exercício 4 - Operadores",
          "Utilização de Strings",
          "Operações e Métodos em Strings",
          "Exercício 5 - Operações em Strings",
          "Utilizando uma Lista",
          "Exercício 6 - Listas",
          "Utilizando uma Tupla",
          "Exercício 7 - Tupla",
          "Utilizando um Set",
          "Exercício 8 - Set",
          "Utilizando um Dicionário",
          "Exercício 9 - Dicionário",
          "Trabalhando com Condições",
          "Utilizando For",
          "Utilizando While",
          "Utilizando List Comprehension",
          "Utilizando Funções",
          "Argumentos em Funções",
          "Função Recursiva",
          "Parâmetros Args e Kwargs",
          "Função Lambda",
          "O Desenvolvedor Júnior e o Especialista em Automação"
        ]
      },
      "requirements": [
        "Noções de Modelos de Linguagem (LLMs) – Entendimento básico sobre como funcionam os modelos de IA como GPT.",
        "Conceitos básicos de APIs e Web Apps – Noção sobre como consumir APIs e criar interfaces simples, como no Gradio.",
        "Curiosidade e vontade de aprender IA – Interesse em desenvolver agentes inteligentes, chatbots e análise de dados."
      ],
      "description": "Por que aprender LlamaIndex?\nIntegração Poderosa com LLMs: Facilita o uso de modelos de linguagem grandes (LLMs) para criar soluções inteligentes e dinâmicas.\nCriação de Agentes Inteligentes: Permite o desenvolvimento de agentes autônomos capazes de interagir e tomar decisões com base em dados reais.\nAnálise Avançada de Dados: Utiliza ferramentas como o PandasQueryEngine para consultas eficientes e extração de insights a partir de grandes volumes de dados.\nDesenvolvimento de Chatbots: Facilitando a criação de chatbots interativos e personalizados com interfaces como Gradio.\nDescrição do Curso: LlamaIndex - Desenvolva Agentes IA e Apps com LLMs\nIntrodução ao RAG (Retrieval-Augmented Generation)\nConceitos e aplicação do RAG em modelos de linguagem.\nComo melhorar a precisão e a relevância das respostas geradas por LLMs.\nImplementação prática: criação de um sistema de recuperação de informações com LlamaIndex.\nDa Teoria à Prática: Criando um Chatbot com Gradio\nFundamentos para desenvolver um chatbot usando LlamaIndex.\nConstrução de interfaces interativas para o chatbot com Gradio.\nPasso a passo desde a configuração até a implementação de um chatbot funcional.\nAnalisando Dados com PandasQueryEngine no LlamaIndex\nComo usar o PandasQueryEngine para realizar consultas eficientes e precisas.\nIntegração de dados com LlamaIndex para análise e extração de insights.\nAplicação prática: análise de dados reais com LlamaIndex e Pandas.\nCriação de Agentes Inteligentes na Prática\nComo criar e treinar agentes autônomos com LlamaIndex.\nExemplos de agentes para automação, análise e interação.\nDesenvolvimento de soluções para tarefas específicas utilizando IA e LLMs.\nNeste curso, você aprenderá a construir agentes de IA avançados, desenvolver chatbots, realizar análises de dados e automatizar processos complexos utilizando LlamaIndex e LLMs.",
      "target_audience": [
        "Desenvolvedores e Engenheiros de Software – Que desejam integrar LLMs em aplicações e criar agentes inteligentes.",
        "Cientistas e Analistas de Dados – Interessados em explorar o LlamaIndex para consultas e extração de insights avançados.",
        "Pesquisadores e Estudantes de IA – Que querem aprender sobre RAG, automação e aplicações práticas de LLMs.",
        "Empreendedores e Profissionais de Negócios – Buscando automatizar processos e criar soluções baseadas em IA.",
        "Entusiastas de Inteligência Artificial – Que querem entender como desenvolver chatbots, agentes e análises inteligentes."
      ]
    },
    {
      "title": "SQL for Developers: Real-World Database Skills",
      "url": "https://www.udemy.com/course/sql-mssql-mysql-postgreesql-oracle-2023/",
      "bio": "Master relational databases, SQL queries, and DBMS essentials with real-world examples tailored for developers.",
      "objectives": [
        "Verilənlər bazalarına aid idarəetmə sistemləri",
        "MSSQL",
        "MySQL",
        "PostgreSQL",
        "Verilənlər bazalarının və baza obyektlərinin hazırlanması",
        "Verilənlər bazaları üzrə məlumat depolamaq və məlumatların işlədilməsi"
      ],
      "course_content": {
        "Giriş": [
          "Giriş"
        ],
        "Lazımlı məlumatlar": [
          "Visual Studio Code`un quraşdırılması",
          "Məlumatlandırma"
        ],
        "Verilənlər bazasının normallaşdırılması": [
          "Giriş",
          "Normalizasiyanın üstünlükləri",
          "1NF - Birinci normal forma",
          "2NF - İkinci normal forma",
          "3NF - Üçüncü normal forma"
        ],
        "MSSQL": [
          "MSSQL servisinin komputerə quraşdılılması",
          "SSMS-Sql Server Management Studio`nun kompüterə quraşdırılması"
        ],
        "MSSQL-DDL | with GUI": [
          "CREATE-Announces Table",
          "RENAME-Announces Table",
          "CREATE-Create AnnounceTypes Table",
          "ALTER-Announces Table",
          "CREATE-ObjectTypes Table",
          "CREATE-DocumentTypes Table",
          "CREATE-Images Table",
          "Cədvəl üçün əsas açar seçmək",
          "Cədvəli avtomatik artan sütunla təmin etmək"
        ],
        "MSSQL-DDL | with script": [
          "ALTER,DROP And CREATE New Database",
          "CREATE-Create AnnounceTypes Table",
          "CREATE-ObjectTypes Table",
          "CREATE-DocumentTypes Table",
          "CREATE and ALTER-Images Table",
          "CREATE-Announces Table",
          "DROP-Announces Table",
          "DELETE və TRUNCATE fərqi"
        ],
        "MSSQL-DML": [
          "AnounceTypes bir sətri cədvələ yazmaq",
          "AnounceTypes birdən çox sətri cədvələ yazmaq",
          "AnnounceTypes Insert from select results set",
          "Fill Tables with script",
          "Announces Table Update",
          "AnnounceTypes Table Delete Records"
        ],
        "MSSQL-DQL": [
          "SELECT",
          "WHERE",
          "AND - OR - NOT",
          "IN vs NOT IN",
          "IS NULL vs IS NOT NULL",
          "LIKE, NOT LIKE. Wildcards",
          "BETWEEN, NOT BETWEEN",
          "Məlumatların bir neçə sütununa görə göstərilməsi",
          "ALIAS",
          "ORDER BY (ASCENDING | DESCENDING)",
          "DISTINCT",
          "TOP",
          "COUNT, COUNT DISTINCT",
          "SUM, Column Alias",
          "AVG",
          "MIN,MAX",
          "GROUP BY",
          "HAVING",
          "JOINS",
          "INNER JOIN",
          "LEFT JOIN",
          "RIGHT JOIN",
          "Right və Left Join-ləin üstünlükləri",
          "FULL JOIN",
          "İkidən çox cədvəl arasında bağlantı qurmaq"
        ],
        "MSSQL | Views": [
          "View nədir?",
          "Yeni View yaratmaq",
          "Mövcud View`un adının dəyişdirilməsi və redaktə edilməsi",
          "Mövcud View`un silinməsi"
        ],
        "MSSQL | Backup & Restore": [
          "Bazanın Backup edilməsi",
          "Bazanın Restore edilməsi",
          "Schema only-modunu istifadə edərək bazanın generasiya script-ini yaratmaq",
          "Data only-modunu istifadə edərək bazanın generasiya script-ini yaratmaq"
        ]
      },
      "requirements": [
        "Səbrli,sahəyə kifayət qədər maraqlı və öyrənmə əzminə sahib olmaq"
      ],
      "description": "Programçılar üçün sql biliklərinin öyrənilməsi | 2023 dərslərimizə xoş gəldiniz!\n\n\nBu kursda\nVerilənlər bazaları, Verilənlər bazalarının idarəetmə sistemlərini\nBaza elementlərinin təşkili\nMəlumat bazalarının emalı və istifadə edilməsini öyrənəcəyik\n\n\nNiyə bu kursu almalıyam?\nVerilənlər bazaları və onların mənimsənilməsi böyük zaman tələb etsə də,buna baxmayaraq ixtisası əsas olaraq Verilənlər bazaları olmayan program tərtibatçılarının da bu sahə üzrə biliyə ehtiyyacı olur.Bu səbəbdən hazırlanmış bu kurs tam olaraq program tərtibatçıları üçün ideal vəsaitdir və bu sahədə biliklərinizlə seçilməyinizə kömək edəcək.İstər təlimçi təcrübəmdən,istərsə də illərlə bu sahədə qazandığım mühəndis təcrübəmə əsaslanaraq,illərdir qarşılaşdığım bütün tələbləri,qarşılaşa biləcəyiniz xətaları və həlli yollarına bütün kurslarımda olduğu kimi bu kursda da geniş yer vermişəm.Və siz bir necə saatlıq bu kursla illərin süzgəcindən keçmiş praktikanı mənimsəyə bilərsiniz.\nHəmçinin sizinlə eyni sahəyə maraqlı olan,fərqli təcrübələrə sahib  bu kursa maraqlı olan hərkəslə fikir mübadiləsi edə biləcək bir mühit əldə etmiş olacaqsınız.Kariyera inkişafınıza yetərincə təsir edəcək ətrafınızı da qurmağa yardım edəcəyik.\n\n\nKursa qeyd olun və:\nDaim yenilənən videolara baxmaq haqqı qazanın\nVerilənlər bazası mühəndisinin biliklərinin Program təribatçısına lazım olan həmçinin daha çox öyrənmə imkanı əldə edin\nTək bir kursda dörd verilənlər bazası idarəetmə sistemi haqqında praktiki biliklərə sahib olun\nHazırladığınız program məhsuluna aid verilənlər bazasının idarə edilməsi prinsiplərinə yiyələnin\nHazırladığınız program məhsuluna aid verilənlər bazasının test edilməsin prinsiplərinə yiyələnin\nHəmçinin kurs haqqında,həm də kariyeranızda irəliləmək haqqında hər növ suallara 24 saat ərzində cavab ala bilərsiniz.\n\n\nHazırsız ?\nKursu əldə edin və kariyeranızda uğurlu bir addım atın.\nKursda görüşənədək!",
      "target_audience": [
        "Verilənlər bazası ilə əlaqəli sistem hazırlayanlar",
        "Data Analiz üçün təməl bilik qazanmaq istəyənlər",
        "Hər hansı bir VBİS-biliyinə sahib və biliklərini təkmilləşdirmək istəyənlər"
      ]
    },
    {
      "title": "机器学习算法实战",
      "url": "https://www.udemy.com/course/ufehsrid/",
      "bio": "短平快掌握机器学习实战要点；摆脱理论束缚，迅速上手实战！",
      "objectives": [
        "掌握机器学习关键算法知识",
        "学会机器学习项目流程",
        "掌握机器学习环境搭建",
        "提升机器学习算法实战能力"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师简介",
          "课程大纲"
        ],
        "课程内容": [
          "机器学习的根本任务",
          "机器学习的黑盒模型",
          "机器学习的前提条件",
          "机器学习的任务类型",
          "机器学习的环境搭建",
          "机器学习的项目流程",
          "数据的采样原则",
          "数据的编码方式",
          "数学视角看数据",
          "数据集的划分",
          "数据量纲不统一问题",
          "数据中心化",
          "数据归一化",
          "数据规范化",
          "PCA降维算法",
          "线性回归算法",
          "逻辑回归算法",
          "KNN算法",
          "KMeans聚类算法",
          "朴素贝叶斯算法",
          "支持向量机算法",
          "决策树算法",
          "RandomForest算法",
          "AdaBoost算法",
          "GradientBoosting算法",
          "XGBoost算法",
          "LightGBM算法"
        ],
        "课程总结": [
          "课程结语"
        ]
      },
      "requirements": [
        "机器学习相关的从业人员"
      ],
      "description": "机器学习实战（速成版）课程，可以让学员用较短的时间、零起步迅速学会基于sklearn完成机器学习项目！先从基本概念开始；然后实战各类算法；全程弱化理论推导，强化动手实战！全流程一气呵成，短平快即学即用！\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为，课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权,任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "适合机器学习相关的工程师、科研人员以及学生",
        "适合企业中高级算法工程师",
        "机器学习相关的工程师、科研人员"
      ]
    },
    {
      "title": "Python Docx de Iniciante a Vencedor",
      "url": "https://www.udemy.com/course/python-docx-de-iniciante-a-vencedor/",
      "bio": "Aprenda a Gerar Arquivos do Microsoft Word",
      "objectives": [
        "Criar arquivos docx com Python",
        "Altere a cor e o tamanho da fonte",
        "Altere o nome da fonte, usar fontes TTF",
        "Inserir imagens e parágrafos",
        "Alinhar parágrafos e imagens",
        "Definir/Desativar negrito, itálico e sublinhado",
        "Defina diferentes estilos de sublinhado: único, traço duplo, ponto ponto traço",
        "Inserir tabelas",
        "Altere os dados XML internos",
        "Adicionar número de página"
      ],
      "course_content": {
        "Documento do Koala": [
          "Introdução + Pré Requisitos [Parte 0 de 35]",
          "Olá Mundo Python Docx [Parte 1 de 35]",
          "Definir Esqueleto de Criação de Documentos [Parte 2 de 35]",
          "Adicionar Heading ao Título [Parte 3 de 35]",
          "Alterar Nome da Fonte [Parte 4 de 35]",
          "Alterar Tamanho da Fonte [Parte 5 de 35]",
          "Adicionar/Remover Negrito [Parte 6 de 35]",
          "Alterar a Cor do Texto [Parte 7 de 35]",
          "Alinhar Texto ao Centro [Parte 8 de 35]",
          "Tamanho da Página [Parte 9 de 35]",
          "Margens da Página [Parte 10 de 35]",
          "Distância do Cabeçalho e Rodapé [Parte 11 de 35]",
          "Espaçamento entre Parágrafos - Antes/Depois [Parte 12 de 35]",
          "Estilos Padrão do Documento [Parte 13 de 35]",
          "Criar Estilos Personalizados [Parte 14 de 35]",
          "Espaçamento entre Linhas de Parágrafo [Parte 15 de 35]",
          "Paragraph Run [Parte 16 de 35]",
          "Estilos de Sublinhado [Parte 17 de 35]",
          "Adicionar Atributos a Elementos Docx [Parte 18 de 35]",
          "Adicionar Imagem [Parte 19 de 35]",
          "Adicionar Nova Página [Parte 20 de 35]",
          "Estilo de Parágrafo Obter Modelo XML [Parte 21 de 35]",
          "Estilo de Parágrafo Construir Modelo XML [Parte 22 de 35]",
          "Oxml Element Wrapper [Parte 23 de 35]"
        ]
      },
      "requirements": [
        "Conhecimentos básicos sobre Python",
        "Você precisa do Python 3.8.x ou posterior",
        "Visual Studio Code (recomendado)",
        "Extensões do Visual Studio Code \"Python from Microsoft\" e \"Pylance from Microsoft\"",
        "Extensão \"Ferramentas XML\" do Visual Studio Code",
        "7zip ou similar",
        "Vontade de aprender mais"
      ],
      "description": "Bem-vindo ao Python Docx de Iniciante a Vencedor!\n\n\nAqui vamos aprender juntos como usar o módulo python-docx para gerar arquivos docx dinamicamente! A automação de arquivos Docx com Python se tornará fácil para você!\n\n\nEm cada sessão iremos replicar um Microsoft docx previamente criado à mão.\nJuntos, exploraremos a API python-docx! Iremos examinar, depurar e melhorar o seu código!\nSerá divertido, será ousado, será memorável!\nTambém vamos dar uma olhada em seu código XML interno, vamos comparar com o original, vamos entender como funciona e vamos mudá-lo a nosso favor!\n\n\nDepois de fazer a primeira sessão, você já será capaz de:\nInserir parágrafos;\nInserir imagens;\nInserir tabelas;\nFormatar tabelas;\nAlinhar parágrafos e imagens;\nAltere o nome e o tamanho da fonte do parágrafo;\nUsar fontes TTF;\nAlterar a cor do parágrafo;\nAdicionar/remover negrito, itálico e sublinhado;\nAdicionar diferentes estilos de sublinhado: linha simples, dupla, onda, entre outras;\nCriar seus próprios estilos de parágrafo;\nLer seu código XML interno, entendendo-o e alterando-o a seu favor;\nAdicionar paginação.\n\n\nUma viagem e tanto né?\n\n\nJunte-se a mim nesse desafio de explorar o módulo python-docx, temos muito a aprender!\nTorne-se um vencedor e comece a automatizar seus arquivos Microsoft Docx agora!\n\n\nConceitos chave: Inserir parágrafos, inserir images, inserir tabelas, formatar tabelas, alinhar parágrafos, alinhar images, alterar a fonte de um parágrafo, alterar o tamanho da fonte de um parágrafo, usar fontes TTF (TrueType Font), alterar a cor de um parágrafo, adicionar negrito, remover negrito, adicionar itálico, remover itálico, adicionar sublinhado, remover sublinhado, adicionar sublinhado de linha única, adicionar sublinhado de linha dupla, adicionar sublinhado de onda, criar estilos, paginação.",
      "target_audience": [
        "Desenvolvedor Python Iniciante/Intermediário que deseja automatizar a criação e/ou processamento de documentos docx",
        "Qualquer pessoa interessada em automação docx",
        "Todos aqueles que queiram fazer mais com menos"
      ]
    },
    {
      "title": "Введение в машинное обучение",
      "url": "https://www.udemy.com/course/ittensive-machine-learning-introduction/",
      "bio": "Задачи и процесс машинного обучения, работа с моделью и данными, линейные метрики и простые модели",
      "objectives": [
        "Задачи и процесс машинного обучения",
        "Данные для машинного обучения",
        "Особенности обучение моделей",
        "Экспорт и импорт результатов машинного обучения",
        "Метод максимального правдоподобия",
        "Линейная регрессия и регуляризация",
        "Среднеквадратичная ошибка и другие метрики",
        "Полиномиальная и нелинейная регрессия",
        "Логистическая регрессия"
      ],
      "course_content": {
        "Процесс машинного обучения": [
          "Задачи машинного обучения",
          "Задачи машинного обучения",
          "Модель и процесс машинного обучения",
          "Процесс ETL",
          "Процесс машинного обучения"
        ],
        "Подготовка данных": [
          "EDA",
          "Подготовка данных",
          "Подготовка данных"
        ],
        "Модель машинного обучения": [
          "Разбиение выборки",
          "Оптимизация гиперпараметров",
          "Латинский квадрат (гиперкуб)",
          "Оптимизация гиперпараметров через Парзеновские деревья",
          "Недообучение и переобучение",
          "Смещение, разброс и ошибка данных",
          "Обучение модели",
          "Использование HDF",
          "\"Проклятье\" большой размерности"
        ],
        "Базовые методы и оценки": [
          "Метод максимального правдоподобия",
          "Метод наименьших квадратов",
          "Метод наименьших квадратов",
          "Аппроксимация пропусков в данных",
          "Аппроксимация данных",
          "Среднеквадратичная ошибка",
          "Метрики и расстояния",
          "Метрики и расстояния"
        ],
        "Линейные модели": [
          "Линейная регрессия и L1/L2-регуляризация",
          "Изотоническая регрессия",
          "Линейная регрессия",
          "BIC и AIC",
          "Полиномиальная регрессия",
          "Линеаризация регрессии",
          "Нелинейная регрессия",
          "Логистическая регрессия",
          "Линейные модели"
        ]
      },
      "requirements": [
        "Школьная математика",
        "Интерес к искусственному интеллекту и(ли) большим данным"
      ],
      "description": "Внимание: для доступа к курсам ITtensive на Udemy напишите, пожалуйста, на support@ittensive.com с названием курса или группы курсов, которые хотите пройти.\n\n\nРабота с большими данными и задачами искусственного интеллекта требует особого подхода - подхода машинного обучения. В этом курсе мы последовательно пройдем все этапы работы с данными: от видов задач и их постановки до работы с моделями машинного обучения для минимизации предсказательной ошибки.\nДополнительно рассмотрим фундаментальные основы построения моделей машинного обучения, базовые метрики и наиболее простые модели – линейную и логистическую регрессии.\nВ курсе изучается:\nКлассификация задач машинного обучения.\nПроцесс машинного обучения: ETL, EDA, подготовка данных, обучение модели.\nОсобенности обучения модели: выборки, переобучение и гиперпараметры.\nОптимизация гиперпараметров жадным поиском, через гиперкуб и парзеновские деревья.\nОтличия переобученной модели и недообученной, практики оптимального обучения.\nРабота с форматов хранения данных - HDF5.\n«Проклятье» большой размерности.\nПодходы к простым моделям машинного обучения: метод максимального правдоподобия и метод наименьших квадратов, среднеквадратичная ошибка.\nПодходы к заполнению пропусков в данных: интерполяция и экстраполяция.\nМетрики задач регрессии: эвклидово расстояние, расстояние городских квадратов, Чебышева и Минковского.\nЛинейная регрессия с регуляризацией и без.\nИзотоническая регрессия.\nКритерии выбора сложности модели: BIC и AIC.\nЛинеаризуемая и полиномиальная регрессия.\nЛогистическая регрессия.\nПосле завершения курса вы сможете организовывать процесс разработки моделей машинного обучения и перейти к более глубокому и прикладному изучению тему машинного обучения.\nКурс является вводным (базовым) и подойдет широкому кругу слушателей: от руководителей до разработчиков.\nОсновные задачи машинного обучения:\n1) Задача регрессии – прогноз на основе выборки объектов с различными признаками. На выходе должно получиться вещественное число (2, 35, 76.454 и др.), к примеру цена квартиры, стоимость ценной бумаги по прошествии полугода, ожидаемый доход магазина на следующий месяц, качество вина при слепом тестировании.\n2) Задача классификации – получение категориального ответа на основе набора признаков. Имеет конечное количество ответов (как правило, в формате «да» или «нет»): есть ли на фотографии кот, является ли изображение человеческим лицом, болен ли пациент раком.\n3) Задача кластеризации – распределение данных на группы: разделение всех клиентов мобильного оператора по уровню платёжеспособности, отнесение космических объектов к той или иной категории (планета, звёзда, чёрная дыра и т. п.).\n4) Задача уменьшения размерности – сведение большого числа признаков к меньшему (обычно 2–3) для удобства их последующей визуализации (например, сжатие данных).\n5) Задача выявления аномалий – отделение аномалий от стандартных случаев. На первый взгляд она совпадает с задачей классификации, но есть одно существенное отличие: аномалии – явление редкое, и обучающих примеров, на которых можно натаскать машинно обучающуюся модель на выявление таких объектов, либо исчезающе мало, либо просто нет, поэтому методы классификации здесь не работают. На практике такой задачей является, например, выявление мошеннических действий с банковскими картами.",
      "target_audience": [
        "Руководители и менеджеры",
        "Разработчики больших систем",
        "Научные работники",
        "Директора по маркетингу и продажам"
      ]
    },
    {
      "title": "ChatGPT로 배우는 SQL 입문",
      "url": "https://www.udemy.com/course/chatgptsql/",
      "bio": "36개의 ChatGPT 프롬프트와 9개의 데이터셋으로 배우는 SQL",
      "objectives": [
        "학습을 위한 ChatGPT Prompt 작성법",
        "ChatGPT 유용한 확장 프로그램",
        "SQL 기초 문법",
        "mySQL Workbench 사용법",
        "관계형 데이터베이스",
        "다양한 오픈 데이터 스스로 구하기"
      ],
      "course_content": {
        "Intro": [
          "소개",
          "수업 준비 (ChatGPT 맛보기 & mySQL Workbench 설치)"
        ],
        "DDL (Data Definition Language)": [
          "CREATE DATABASE - 데이터 베이스 생성하고 다루기",
          "CREATE TABLE - 테이블 생성하고 다루기",
          "ALTER TABLE - 테이블 수정 및 관리",
          "ChatGPT를 활용한 DATABASE 설계",
          "Mockaroo를 활용해 연습용데이터 생성하기"
        ],
        "Getting & import Data": [
          "오픈 데이터 플랫폼",
          "Data Import - kaggle에서 데이터 다운받고 사용하기"
        ],
        "SELECT": [
          "데이터를 조회하는 방법 - SELECT",
          "CASE WHEN 절",
          "숫자를 다루는 함수",
          "문자를 다루는 함수"
        ],
        "Group By and Partition By": [
          "GROUP BY / HAVING / ORDER BY",
          "window 함수 - OVER / PARTITION BY",
          "window 함수 - FRAME 절"
        ],
        "Join and Subquery": [
          "JOIN",
          "Subquery"
        ]
      },
      "requirements": [
        "IT에 대한 경험이 없어도 쉽고 자세한 설명으로 배우실 수 있습니다.",
        "IT에 대한 경험이 있다면 압축된 내용으로 실속있게 배우실 수 있습니다."
      ],
      "description": "과거에는 무언가를 배울 때 내용들이 정리된 책이 필요했고\n가르쳐줄 선생님이 필요했습니다.\n이후 인터넷의 등장으로 온라인 강의가 생겨났고\n검색을 통해 다양한 정보로 혼자서도\n배울 수 있게 되었습니다.\n\n\n얼마 지나지 않아 데이터들이 쌓이고 컴퓨터의 연산력이 높아지면서\n인공지능, AI에게 데이터를 연산시키며 인간에게 필요한 정보를\n질문을 통해 얻어내는 ChatGPT가 탄생했습니다.\n\n\n보통 학교나 학원에서만 했던 공부를\n최근에는 보통 컴퓨터나 스마트폰으로 하게 되었고\n앞으로는 보통 ChatGPT 처럼 빅데이터/AI 기술을 활용한 툴로 배우게 될 것입니다.\n\n\n이러한 배경으로 이 강의가 만들어 졌습니다.\n데이터를 다루는 SQL을 ChatGPT로 배우며\n새로운 보통, 뉴노멀을 준비합시다.\n\n\nLerning about Data, with AI",
      "target_audience": [
        "데이터/AI로 급변하는 시대를 준비하는 모든 사람",
        "업무에 SQL이 필요한 직장인",
        "아직 SQL을 모르는 대학생/취준생",
        "SQLD 자격증을 위한 기초를 쌓고 싶은 사람"
      ]
    },
    {
      "title": "[FR] DeepSeek R1 IA: 25 projets concrets en IA pour débutant",
      "url": "https://www.udemy.com/course/deepseek-french/",
      "bio": "Développement IA pratique avec DeepSeek : créez 25 projets NLP et automatisation de A à Z",
      "objectives": [
        "Créez des outils de traitement de texte IA comme des résumeurs.",
        "Appliquez des techniques de PNL à des cas réels.",
        "Installez et configurez DeepSeek AI en local.",
        "Développez des chatbots intelligents pour divers domaines.",
        "Automatisez des tâches avec les modèles DeepSeek AI.",
        "Générez des contenus et rapports assistés par IA.",
        "Créez des assistants et débogueurs de code IA.",
        "Optimisez les modèles DeepSeek AI pour la performance.",
        "Créez des systèmes de recommandation IA.",
        "Construisez des applications IA sans dépendre du cloud."
      ],
      "course_content": {
        "Introduction à DeepSeek AI Appliquée : 25 Projets Pratiques pour Développeurs IA": [
          "Bienvenue dans le cours – Aperçu, objectifs et prérequis",
          "Configuration de DeepSeek AI – Installation, paramétrage et premier test",
          "Cours accéléré : Apprendre Python depuis zéro"
        ],
        "Traitement de texte et NLP avec IA": [
          "Projet 1 : Résumeur de texte basé sur DeepSeek AI",
          "Projet 2 : Générateur de texte IA avec DeepSeek AI",
          "Projet 3 : Correcteur grammatical et orthographique avec DeepSeek AI",
          "Projet 4 : Outil de reconnaissance d’entités nommées (NER) avec DeepSeek AI",
          "Projet 5 : Analyseur de sentiments avec DeepSeek AI"
        ],
        "Chatbots et assistants virtuels": [
          "Projet 6 : Chatbot de support client avec DeepSeek AI",
          "Projet 7 : Assistant personnel intelligent avec DeepSeek AI",
          "Projet 8 : Assistant juridique IA avec DeepSeek AI",
          "Projet 9 : Vérificateur de symptômes médicaux avec DeepSeek AI",
          "Projet 10 : Bot de recommandation de produits e-commerce avec DeepSeek AI"
        ],
        "IA pour l’automatisation et la productivité": [
          "Projet 11 : Répondeur automatique aux e-mails avec DeepSeek AI",
          "Projet 12 : Générateur de CV avec DeepSeek AI",
          "Projet 13 : Générateur de comptes rendus de réunion avec DeepSeek AI",
          "Projet 14 : Extracteur automatique de texte PDF avec DeepSeek AI",
          "Projet 15 : Générateur de contenu IA avec DeepSeek AI"
        ],
        "IA pour développeurs et codage": [
          "Projet 16 : Autocompléteur de code et assistant IA avec DeepSeek AI",
          "Projet 17 : Générateur de requêtes SQL avec DeepSeek AI",
          "Projet 18 : Débogueur de code avec DeepSeek AI",
          "Projet 19 : Générateur de documentation avec DeepSeek AI",
          "Projet 20 : Testeur d’API alimenté par IA avec DeepSeek AI"
        ],
        "IA pour les affaires et l’analyse de données": [
          "Projet 21 : Analyseur de retours clients avec DeepSeek AI",
          "Projet 22 : Résumeur d’actualités en temps réel avec DeepSeek AI",
          "Projet 23 : Analyseur de rapports financiers avec DeepSeek AI",
          "Projet 24 : Sélecteur automatisé de candidatures avec DeepSeek AI",
          "Projet 25 : Résumeur d’articles de recherche avec DeepSeek AI"
        ]
      },
      "requirements": [
        "Familiarité avec les outils en ligne de commande (utilisation basique du terminal).",
        "Un ordinateur avec au moins 8 Go de RAM pour faire tourner les modèles DeepSeek AI.",
        "Un environnement Python installé (nous verrons comment le configurer).",
        "Une certaine expérience en apprentissage automatique ou NLP (facultatif mais utile).",
        "Intérêt pour l’automatisation et les chatbots basés sur l’IA.",
        "Aucun service cloud requis — tout fonctionne localement!",
        "Enthousiasme pour construire des applications IA concrètes.",
        "Volonté d’expérimenter et d’explorer les outils d’IA.",
        "Accès à un éditeur de code (VS Code, PyCharm ou Jupyter Notebook)."
      ],
      "description": "Libérez la puissance de DeepSeek AI avec 25 projets pratiques\nÊtes-vous prêt à créer des applications d’IA concrètes avec DeepSeek AI ? Ce cours est conçu pour vous faire passer du niveau débutant à développeur IA avancé, en mettant l’accent sur le traitement du langage naturel (NLP), les chatbots, l’automatisation et les applications intelligentes—le tout sans recourir aux services cloud !\nDeepSeek AI est un puissant modèle open-source qui permet aux développeurs de travailler localement avec l’automatisation avancée, la génération de texte et les tâches NLP. Dans ce cours, vous réaliserez 25 projets concrets, en acquérant une expérience pratique de l’IA appliquée aux domaines professionnels, à la productivité, à l’automatisation et au développement logiciel.\nCe que vous allez apprendre\nÀ la fin du cours, vous saurez :\nInstaller et configurer DeepSeek AI sur votre machine locale.\nConstruire des applications de traitement de texte avec IA : résumé, correction grammaticale, analyse de sentiments.\nDévelopper des chatbots intelligents et assistants virtuels pour le support client, l’e-commerce et la productivité personnelle.\nAutomatiser des tâches courantes : rédaction d’e-mails, génération de CV, résumé de documents.\nImplémenter des outils de codage IA : compléteurs automatiques, débogueurs, générateurs SQL.\nOptimiser les modèles DeepSeek AI pour une exécution locale performante.\nCréer des applications IA pour l’analyse financière, le tri de candidatures, l’analyse de feedback client.\nAcquérir une solide expérience pratique du NLP et de l’automatisation en Python.\nTravailler sur des projets IA sans dépendre d’API cloud.\nÀ qui s’adresse ce cours ?\nCe cours est idéal pour :\nDéveloppeurs Python souhaitant intégrer l’IA dans leurs applications.\nDébutants en IA et NLP cherchant une expérience concrète.\nData scientists explorant des modèles IA pour le traitement de texte.\nProfessionnels tech souhaitant créer des outils d’automatisation IA.\nEntrepreneurs et fondateurs de startups développant des produits IA.\nÉtudiants et chercheurs travaillant sans infrastructures cloud.\nAperçu des projets du cours\nCe cours comprend 25 projets concrets autour de :\nTraitement de texte avec IA – résumés, sentiment analysis, génération de texte.\nChatbots & assistants – création d’assistants intelligents pilotés par IA.\nAutomatisation – réponses d’e-mails, création de CV, automatisation de flux.\nIA pour développeurs – complétion de code, débogage, tests d’API.\nIA business – analyse financière, tri de CV, traitement de retours clients.\nPourquoi suivre ce cours ?\nDes projets concrets pour une expérience réelle.\nAucune dépendance au cloud – tout tourne en local !\nImplémentation pas à pas avec exemples de code.\nCouvre NLP, automatisation, IA pour développeurs, et plus.\nParfait pour développeurs, étudiants et passionnés d’IA.\nCommencez à créer des applications IA dès aujourd’hui !\nInscrivez-vous maintenant et exploitez tout le potentiel de DeepSeek AI avec 25 projets concrets et pratiques.",
      "target_audience": [
        "Développeurs Python souhaitant intégrer l’IA dans leurs applications.",
        "Débutants en IA et ML cherchant une expérience pratique en NLP et automatisation.",
        "Data scientists explorant DeepSeek AI pour le traitement de texte et les chatbots.",
        "Fondateurs de startups et entrepreneurs développant des produits basés sur l’IA.",
        "Passionnés d’automatisation cherchant à améliorer leurs flux de travail grâce à l’IA.",
        "Étudiants et chercheurs expérimentant avec des outils pilotés par l’IA.",
        "Professionnels de la tech souhaitant monter en compétence en automatisation par l’IA.",
        "Apprenants autonomes et amateurs d’IA désireux de découvrir de nouvelles applications."
      ]
    },
    {
      "title": "Curso de Ciência de Dados",
      "url": "https://www.udemy.com/course/ciencia-de-dados/",
      "bio": "Conheça as habilidades essenciais de um cientista de dados na prática com a execução de um projeto de machine learning!",
      "objectives": [
        "A ciência de dados e suas aplicações;",
        "Conhecendo a linguagem de programação python;",
        "Aplicação prática: prevendo preços de carros a partir de suas características utilizando árvores de decisão.",
        "Tratamento de dados utilizando a biblioteca pandas: upload dos dados, limpeza, tratamento de dados categóricos, visualizações e análises iniciais;",
        "Treinamento e aplicação de modelos de machine learning utilizando a biblioteca scikit-learn: treinamento, validação e aplicação de modelos de árvores de decisão."
      ],
      "course_content": {
        "Conteúdo": [
          "Introdução",
          "Sobre o Python",
          "Início do Projeto",
          "Projeto - parte 2",
          "Projeto - parte 3 - Aplicando ao Modelo",
          "Projeto - parte 4 - Final"
        ]
      },
      "requirements": [
        "Noções de informática e lógica de programação."
      ],
      "description": "As habilidades essenciais de um cientista de dados serão apresentadas na prática através da execução de um projeto de machine learning utilizando modelos de árvores de decisão.\nNeste curso, serão utilizados o programa Anaconda com a linguagem de programação Python.\n\n\nCONTEÚDO PROGRAMÁTICO:\n• Apresentando a ciência de dados e suas aplicações;\n• Conhecendo a linguagem de programação python;\n• Aplicação prática: prevendo preços de carros a partir de suas características utilizando árvores de decisão.\n• Tratamento de dados utilizando a biblioteca pandas: upload dos dados, limpeza, tratamento de dados categóricos, visualizações e análises iniciais;\n• Treinamento e aplicação de modelos de machine learning utilizando a biblioteca scikit-learn: treinamento, validação e aplicação de modelos de árvores de decisão;",
      "target_audience": [
        "O curso é destinado a todos aqueles que querem conhecer a ciência de dados."
      ]
    },
    {
      "title": "【初心者向け】PythonのDashとPlotlyでデータ可視化ダッシュボード（Webアプリ）を作る方法を学ぼう！",
      "url": "https://www.udemy.com/course/dash-plotly/",
      "bio": "グラフをキレイに描画できるPlotlyの使い方を学んだ後にDashを使ってそれらをデータ可視化ダッシュボード（Webアプリ）にしていこう！Pythonで誰でも簡単にキレイなダッシュボードを作成することが可能！",
      "objectives": [
        "Plotlyを使ったグラフ可視化の方法",
        "Dashを使った可視化Webアプリの作成方法",
        "Dashを使った株価ダッシュボードの作成方法",
        "Pythonの基礎"
      ],
      "course_content": {
        "はじめに": [
          "はじめに"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Searbornについて学ぼう！",
          "Python構文の復習"
        ],
        "Plotlyの使い方": [
          "Plotlyを使ってヒストグラムを描画してみよう！",
          "Plotlyを使った他の描画方法と棒グラフの描画方法",
          "Plotlyで円グラフと箱ひげ図と散布図を描画してみよう！",
          "Plotlyで折れ線グラフを描画してみよう！",
          "Plotlyで複数のグラフを描画してみよう！.mov",
          "Plotlyで3Dグラフを描画してみよう！"
        ],
        "Dashの使い方": [
          "VScodeの準備とPythonの準備",
          "Dashを使ってみよう！",
          "Dashを使ってテーブルとグラフを表示してみよう！",
          "インタラクティブに操作できるCallback処理について理解しよう！",
          "Callback処理を使ってデータを絞り込んでみよう！",
          "スタイルを修正してみよう！"
        ],
        "株価を可視化するようなダッシュボードをDash&Plotlyで作ってみよう！": [
          "【注意】次のレクチャーの株価取得のエラーに関して",
          "株価の取得をしていこう！",
          "ドロップダウンを作ってみよう！",
          "グラフとテーブルを作っていこう！",
          "コールバック部分を作成してダッシュボードを完成させよう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学びますのでプログラミングの知識は特に必要ありません"
      ],
      "description": "このコースでは、PythonのPlotlyとDashを使いながらデータ可視化ダッシュボード（Webアプリ）を作っていきます。\n\n\nDashはPlotly社が提供するライブラリで、PlotlyとDashを組み合わせて使うことでキレイなダッシュボードを誰でも簡単に作成することができるのです！\n\n\nまずPlotlyの使い方についてザッと学んだ後にDashの使い方について学んでいきます。\n最終的には株価データを可視化するようなダッシュボードを作成していきます。\n\n\nこのコースで学んだ内容を活かして自分だけのダッシュボードを作成していきましょう！",
      "target_audience": [
        "PlotlyとDashを使ってキレイな可視化ダッシュボードを作成してみたい方"
      ]
    },
    {
      "title": "오렌지(Orange)를 활용한 코딩 없는 AI 데이터 분석 - Lv.3 예측 머신러닝 분석",
      "url": "https://www.udemy.com/course/maso-ds-orange-onc45/",
      "bio": "복잡한 파이썬(python), 느린 엑셀(excel) 데이터 분석은 이제 그만! 노 코드 분석 도구 Orange로 쉽게 하는 예측 머신러닝(Machine Learning) 분석",
      "objectives": [
        "노코딩 인공지능 분석 도구 Orange를 활용한 예측 모델 구축",
        "머신 러닝의 모델 평가 및 최적화 기법 습득",
        "확률적 경사하강법 이해 및 적용",
        "고급 머신러닝 예측 분석 기법의 실습"
      ],
      "course_content": {
        "학습 내용 안내": [
          "AAC012 학습 내용 안내"
        ],
        "분류와 예측이란 무엇인가": [
          "AAC021 분류와 예측 모델의 이해"
        ],
        "회귀분석으로 이해하는 예측 모델 다루기": [
          "AAC022 가장 간단한 예측 – constant",
          "AAC023 단순 선형 회귀분석",
          "AAC024 지도학습 머신러닝 모델의 워크플로우",
          "AAC025 분석 모델의 저장과 다른 문제에도 활용하기"
        ],
        "예측 결과가 정확해야 좋은 모델이다": [
          "AAC031 분석 모델의 평가 – 편향(Bias)과 분산(Variance)",
          "AAC032 회귀 모델 결정계수 R^2와 설명력",
          "AAC033 회귀 모델 결정계수 R^2와 설명력-실습",
          "AAC034 회귀적 모델의 평가 지표 – RMSE, MSE, MAE"
        ],
        "두루두루 쓸 수 있어야 좋은 모델이다": [
          "AAC041 분석 모델의 일반화 가능성 평가 – 홀드아웃",
          "AAC042 LOOCV와 K-폴드 교차검증, 그리고 부트스트랩",
          "AAC043 모델 성능 교차 검증 비교와 무시할 수 있는 차이"
        ],
        "너무 복잡하지 않고 간결해야 좋은 모델이다": [
          "AAC051 분석 모델의 효율성 – Feature Selection"
        ],
        "꼭대기는 평평하다는 최적화 원리": [
          "AAC061 손실 함수와 경사하강법",
          "AAC062 확률적 경사하강법",
          "AAC063 확률적 경사하강법-실습"
        ],
        "인공지능의 본체 인공신경망": [
          "AAC071 퍼셉트론과 인공신경망",
          "AAC072 퍼셉트론의 AND와 OR, NAND 연산",
          "AAC073 XOR과 다층 퍼셉트론",
          "AAC074 복잡한 문제 해결을 위한 활성화 함수",
          "AAC075 인공신경망의 하이퍼 파라미터"
        ]
      },
      "requirements": [
        "본 강의는 인공지능에 관심이 생긴 누구나 바로 들어 실무에 활용할 수 있는 역량 제공을 목표로 설계된 강의이나, 오렌지(Orange)를 활용한 코딩 없는 AI 데이터 분석 - Lv.1 데이터 마이닝의 첫 걸음 강의를 먼저 수강하시는 것을 추천드립니다.",
        "실습 위주의 강의이기 때문에 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기를 함께 준비해주시면 좋습니다.",
        "오렌지는 무료로 배포되고 있는 소프트웨어이며, 다운로드부터 설치까지 하나하나 가르쳐 드리기 때문에 누구나 손쉽게 인공지능 데이터분석 환경을 구축 가능합니다. Portable 버전을 사용하면 외부 인터넷 연결 없이도 사용 가능하여, 보안 수준이 높은 근무 환경에서도 사용 가능합니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n분석 모델 구축부터 평가까지, AI와 함께하는 데이터 분석\n모든 데이터 분석도 같은 데이터 분석이 아닙니다.\n데이터 분석의 세계에서 분류와 예측은 기초이자 정점을 찍는 기술들입니다.\n이번 강의에서는 여러분이 머신 러닝 모델을 자유롭게 다루며, 실제 비즈니스 문제를 해결하는 방법까지 배울 수 있습니다.\n\n\n분류와 예측 모델이 어렵게만 느껴졌나요? 그럴 필요 없습니다.\n‘코딩 없는 AI 데이터 분석 Lv.3 예측 머신러닝 분석’에서는 복잡한 코딩 없이도, 누구나 쉽게 데이터 모델을 생성하고, 이를 통해 유의미한 인사이트를 얻을 수 있도록 도와드립니다.\n기본적인 예측부터 시작하여 다층 퍼셉트론까지, 단계별로 실습하며 깊이 있는 학습을 진행합니다.\n\n\n이 강의의 핵심은 ‘실용성’입니다.\n오렌지를 활용하여 실무에 필요한 분석 기법과 적절한 도구 사용법을 익히게 됩니다.\n이론적인 지식뿐만 아니라 실제로 데이터를 분석하고, 모델을 평가하는 방법까지 배우게 되므로, 교육 이후 바로 업무에 적용할 수 있는 역량을 갖추게 됩니다.\n\n\n데이터 사이언스 개발자들의 연봉이 부러우셨나요?\n개발 역량이 없어도 괜찮습니다.\n마소캠퍼스의 강의와 함께라면 누구나 높은 수준의 데이터 분석을 수행할 수 있습니다.\n특히 이번 강의에서는 분석 모델의 저장과 활용, 효율성 증대를 위한 피처 선택, 그리고 모델의 일반화 가능성을 평가하는 기법까지 다룹니다.\n\n\n마소캠퍼스의 “코딩 없는 AI 데이터 분석” 시리즈의 이번 강의를 통해 데이터의 숨겨진 가치를 발견하고, 그 가능성을 최대한 활용해보세요.\n여러분도 모르는 데이터의 잠재력을 마음껏 경험하실 수 있을 것입니다.\n\n\n\n\n강의 특징\n본 강의는 예측 모델을 깊이 있게 배우고, 코딩 없이 이를 실무에 적용할 수 있는 구조로 설계되었습니다. 복잡한 프로그래밍의 벽을 허물고, 데이터 분석을 누구나 자신 있게 수행할 수 있도록 도와드립니다.\n\n\n1. 입문자부터 전문가까지 활용 가능한 오렌지!\nOrange는 데이터 사이언스 및 머신 러닝을 처음 접하는 이들에게 이상적인 도구로, 복잡한 코딩 없이도 직관적으로 데이터 모델을 구축할 수 있습니다.\n\n\n\n\n2. 예측 모델과 인공신경망의 이해\n이 강의에서는 가장 기본적인 예측 모델부터 시작해, 단순 선형 회귀분석, 다층 퍼셉트론까지 다양한 모델을 Orange를 통해 직접 구현하고 학습합니다. 데이터에서 중요한 패턴을 인식하고 예측하는 방법을 마스터할 수 있습니다.\n\n\n\n\n3. 모델의 평가와 활용\n모델의 편향과 분산을 평가하는 방법, 회귀 모델의 결정계수 R²의 이해, 그리고 RMSE, MSE, MAE 같은 평가 지표들을 배우면서, 모델의 효과적인 평가 방법을 실습을 통해 마스터합니다.\n\n\n\n\n4. 실무에 적용 가능한 고급 분석 기법\n가장 간단한 예측부터 다양한 회귀 모델의 결정계수와 평가 지표 학습을 통해 데이터 과학의 다양한 문제를 해결하는 데이터 분석가로 거듭날 수 있습니다.\n\n\n\n\n코딩이 필요 없는 AI 활용 데이터 분석 강의를 듣고 나면\n마소캠퍼스의 코딩 없는 AI 데이터 분석 Lv.3 예측 머신러닝 분석 강의는\n데이터 사이언스의 더 깊은 단계로 나아가고자 하는 모든 분들에게 적합합니다.\n\n\n예측 모델의 기본적인 이해와 구현\n모델 평가와 최적화 기술 습득\n고급 분석 기법과 실습 경험\n실무 적용 능력 향상\n\n\n오렌지를 활용하여 데이터 사이언스의 다음 단계로 나아가세요!\n더 이상 복잡한 코딩 지식 없이도 데이터 분석 마스터할 수 있습니다.\n-\n\n\n[ 강 사 소 개 ]\n\n\n최 정 아\n現 마소캠퍼스 콘텐츠랩 이사\n연세대학교 경영학 석사\nYSCEC의 웹마스터로서 연세-게이오(日)-릿쿄(日)-푸단(中) 대학의 YKLP 사업에 초기부터 합류해 성공적으로 론칭시킨 국제 원격교육 전문가입니다. 이후 플레이포럼 편집장으로 자리를 옮겨 MAU 238만 명의 커뮤니티를 7년간 운영하면서 최대 900만 뷰를 달성한 디지털 콘텐츠를 제작했습니다. 언어학, 정보학, 경영학 학위를 소지한 다재다능한 디지털마케팅 전문가로서 데이터를 활용해 디지털 플랫폼에서 최고의 퍼포먼스를 이뤄냈습니다. 효과적인 데이터 마케팅 방법을 다룬 도서를 다수 출간하여 모두 경제경영 분야 베스트셀러에 오른 검증된 지식을 공유하고 있습니다.",
      "target_audience": [
        "실무적 데이터 분석 기술을 강화하고자 하는 분",
        "어려운 코딩 없이 데이터 분석 능력을 향상하고자 하는 분",
        "정확한 모델 구축과 평가를 쉽게 수행하고 싶은 분",
        "엑셀의 한계를 느끼고 더 간단한 고급 분석 도구를 원하는 분"
      ]
    },
    {
      "title": "Deep learning in Arabic",
      "url": "https://www.udemy.com/course/deep-learning-in-arabic/",
      "bio": "كن عالم بكل ما حولك",
      "objectives": [
        "learn what is deep learning",
        "learn what is different between deep learning & machine learning",
        "what neural network and how it works",
        "deep neural network equtions",
        "feedforward propagtion",
        "backward propagtion",
        "CNN",
        "RNN"
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Neural Network": [
          "what is neural network ?",
          "Neural Network part 1",
          "Neural Network part 2",
          "Feedforward Propgation in Neural Network",
          "Activiton Functions",
          "Backward Propgation in Neural Network",
          "Practical 1",
          "Practical 2",
          "Practical 3"
        ],
        "CNN": [
          "CNN 1",
          "CNN 2",
          "CNN 3",
          "CNN 4",
          "CNN 5",
          "Practical 1",
          "Practical 2 & Dropout"
        ]
      },
      "requirements": [
        "you need to know basics & some machine learning algorithm"
      ],
      "description": "السلام عليكم ورحمه الله وبركاته ،\nاهلا بكم في الكورس الاحترفي للتعلم العميق و هو احد اهم تخصصات مجال الذكاء الاصطناعي و هو فرع من تخصص تعلم الالةو هو التخصص الاكثر طلبا في سوق العمل و صاحب اكبر راتب في مجال البرمجيات و التكنولوجيا ،\nباذن الله في هذا الكورس سوف تتعلم ماهو التعلم العميق و ما الفرق بينه و بين تعلم الالة و سوف تتعلم ما هي الشبكات العصبية و كيف تعمل و مراحل العمل و معادلاتها ,\nلكي تبداء معنا في هذه الدورة تحتاج ان تكون علي معرفة بتخصص تعلم الالة يجب ان تكون علي معرفة باساسياته و علي معرفة ببعض خوارزمياته لان تخصص التعلم العميق هو فرع من تخصص تعلم الالة و هناك جوانب مشتركة بينهم\nكما قلت في البداية سوف نشرح الاساسيات للتعلم العميق سوف سوف نتطرق الي التطبيق العملي علي ما تعلمناه من خلال التطبيق بلغة بايثون باستخدام مكتبة تنسرفلو و كيرس المطورة من قبل شركة جوجل ثم سنتطرق الي شبكات عصبية متطورة و عميقة ومتخصصة في مهام معينة لكل شبكة منهم ك الشبكة العصبية الملتفة و الشبكة العصبية المتكررة\nاتمني منكم ان تستفادوا من هذا الكورس و ان تستمتعوا بهذه الرحلة كما استمتع انا بشرح هذا الكورس و اتمني لكم التوفيق الدائم\nو لا تنسونا في دعائكم و فقكم الله :)",
      "target_audience": [
        "for anyone need to study and learn deep learning"
      ]
    },
    {
      "title": "AlphaZeroの意外な構造　またはAlphaGoは如何にして棋譜データの利用をやめて自分の経験に頼るようになったか",
      "url": "https://www.udemy.com/course/alphazero/",
      "bio": "囲碁ＡＩの強化学習アルゴリズム：AlphaGoから人の知識なしでゼロから学習に成功した強化学習モデル のゲームＡＩ「AlphaZero」の学習モデルとモンテカルロ木探索を数式とイラストで解説していきます。将棋ＡＩとしても成果を出しています。",
      "objectives": [
        "AlphaGo ZeroとAlphaZero の仕組みを強化学習を通して説明できるようになります。",
        "AlphaZeroに至るまでの歴史的経緯をたどることができます。",
        "AlphaZeroを通して、ニューラルネットワークやディープラーニングの概要を理解します。",
        "Pythonコードに触れることができます。（初心者向け）"
      ],
      "course_content": {
        "はじめに": [
          "このコースについて",
          "コース概要",
          "受講対象者",
          "このコースの進め方"
        ],
        "ゲームＡＩ": [
          "ゲームＡＩ　概要",
          "人工知能について",
          "アラン・チューリング",
          "イミテーションゲーム",
          "第１次人工知能ブーム",
          "第２次人工知能ブーム",
          "第３次人工知能ブーム",
          "コンピュータチェス",
          "ベルと転置テーブル",
          "ディープ・ブルー",
          "36手目の衝撃",
          "AlphaGoの登場",
          "神の一手"
        ],
        "AlphaZeroの仕組み": [
          "AlphaZeroの仕組み　概要",
          "AlphaGoの構造",
          "AlphaGo_Zeroの構造",
          "ネットワークの単純化",
          "局面情報の単純化",
          "AlphaZero",
          "セルフプレイ",
          "Python言語 はじめの一歩（基本コマンドを実行してみましょう）",
          "Python言語 はじめの一歩（制御文を書いてみましょう。条件編）",
          "Python言語 はじめの一歩（制御文を書いてみましょう。ループ編）"
        ],
        "探索アルゴリスム": [
          "探索アルゴリスム　概要",
          "Mini Max アルゴリズム",
          "Alpha Beta 法",
          "AlphaBeta_処理フロー",
          "AlphaBeta_擬似コードを見てみよう",
          "プログラミング初心者向けの、Python言語の練習（足し算や掛け算のプログラムを作ってみましょう）",
          "AlphaBeta_動かしてみよう",
          "Mini Max を書いてみよう",
          "モンテカルロ法",
          "モンテカルロ木探索",
          "モンテカルロ木探索の動きを見てみよう"
        ],
        "モンテカルロ木探索": [
          "モンテカルロ木探索　概要",
          "まずは動かしてみよう",
          "ノードとエッジ",
          "木探索",
          "解説についての訂正",
          "MCTS基本構造",
          "JavaScriptでシミュレーション",
          "SELECT",
          "PUCTアルゴリズム Part1",
          "PUCTアルゴリズム Part2",
          "EXPAND",
          "BACKUP",
          "バックアップについての考察",
          "SIMULATION",
          "PLAY",
          "Dirichret_Noise",
          "Dirichret_Noise code Part1",
          "Dirichret_Noise code Part2"
        ],
        "AGZネットワークの構成": [
          "AGZネットワークの構成　概要",
          "局面の表し方",
          "ニューラルネットワーク",
          "畳み込み層",
          "ResNet",
          "Policyネットワーク",
          "Valueネットワーク",
          "損失関数について",
          "回帰",
          "平均二乗誤差",
          "分類",
          "クロスエントロピー誤差 Part1",
          "クロスエントロピー誤差 Part2",
          "クロスエントロピー誤差 Part3",
          "正則化Part1",
          "正則化Part2"
        ],
        "最適化": [
          "最適化　概要",
          "勾配降下法",
          "確率的勾配降下法",
          "確率的勾配降下法 Part1",
          "確率的勾配降下法 Part2",
          "確率的勾配降下法 Part3",
          "確率的勾配降下法 Part4",
          "モメンタムSGD",
          "モメンタム_教材の実行",
          "Adam"
        ],
        "五目並べでみてみよう": [
          "五目並べでみてみよう　概要",
          "学習用の教材について",
          "DriveのマウントPart1",
          "DriveのマウントPart2",
          "既定値_Part1",
          "規定値のレクチャーについて",
          "既定値_Part2",
          "既定値_Part3",
          "既定値(CFG) の設定_Part4_Model_HyperParameters",
          "既定値(CFG) の設定_Part5_Self play hyper parameters",
          "既定値(CFG) の設定_Part6_MCTS hyper parameters",
          "既定値(CFG) の設定_Part7_Train data info",
          "教材のインストール",
          "環境のインスタンス",
          "環境を確認してみよう",
          "モデルのインスタンス化",
          "SelfPlayのインスタンス化",
          "データセットの作成",
          "Trainのインスタンス化と、これまでのおさらい。",
          "Trainループ_Part1",
          "Trainループ_Part2",
          "学習の実行",
          "評価の教材について",
          "評価",
          "三目並べで評価"
        ],
        "囲碁／オセロのゲーム環境": [
          "囲碁で実行",
          "オセロゲームで実行",
          "最後に"
        ]
      },
      "requirements": [
        "Goolgeドライブを使うため、Goolge アカウントが必要です。Gmailが使える方なら大丈夫です。",
        "何より大前提として、世界最強となったゲームＡＩ「AlphaZero」 がどのような仕組みなのか具体的に知りたいという好奇心が必要です。"
      ],
      "description": "AlphaGoは大量のプロの棋譜データを集めて教師あり学習をさせていましたが、その後発表されたAlphaGoZeroは、プロの棋譜データなしで、まるで赤ちゃんのような状態から学習を始めてAlphaGoに勝つようになりました。さらに、AlphaGoZeroをより汎用的に改良したAlphaZero は大変シンプルな構造となっていて、強化学習初心者でも学びやすくなっています。モンテカルロ木探索 (Monte Carlo Tree Search) と、マルチヘッドのディープニューラルネットワークを中心に学んでいきます。\nAlphaZeroは、Googleの巨大なネットワークの中で学習されたゲームＡＩですので、１台のマシンでは学習できませんが、論文に基づくコードを動かしながら、人の知識なしでゼロから学習を始めるAlphaZeroの構造を、強化学習の観点から、豊富な図とPythonプログラミングで楽しく学んでいきましょう。\n前半には、チェス・マシン「Deep Blue」についての解説もあります。",
      "target_audience": [
        "人工知能（ＡＩ）に興味をもつ方",
        "ゲームＡＩの仕組みに興味のある方",
        "AlphaZeroの仕組みを詳しく理解したい方",
        "ディープラーニングを一通り受講された方、またはこれからディープラーニングを始めたい方"
      ]
    },
    {
      "title": "职场人的第一节人工智能课",
      "url": "https://www.udemy.com/course/jjxjxumf/",
      "bio": "职场新人快速上手文心一言",
      "objectives": [
        "了解AI级别：通过课程，学员将了解不同级别的AI应用，并在未来能够不断提升自己的AI使用能力，使自己在职场中保持竞争力。",
        "学习AI思维：学员将学习到AI的底层思维，不仅仅是了解AI如何工作（知其然），更要理解其工作原理（知其所以然），从而能够更深入地利用AI技术。",
        "掌握AI应用：课程将教授学员如何在不同的职场场景中灵活运用AI技术，提升他们的工作效率和解决问题的能力。",
        "加深AI理解"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲",
          "课程介绍"
        ],
        "第一章 让AI成为“机甲”，而非“拐杖”": [
          "第一章 让AI成为“机甲”，而非“拐杖”"
        ],
        "第二章 AI思维": [
          "2-1 掌握AI思维，而非简单AI应用",
          "2-2 领导AI，下达命令的三种方式"
        ],
        "第三章 AI应用": [
          "第三章 AI应用"
        ],
        "第四章 AI升级": [
          "第四章 AI升级"
        ],
        "课程回顾": [
          "课程总结"
        ]
      },
      "requirements": [
        "无需经验"
      ],
      "description": "在这个AI技术飞速发展的时代，掌握人工智能不仅是职场竞争力的关键，更是个人成长的重要途径。\n课程专为即将毕业或刚步入职场的你量身打造，旨在通过AI的力量，让你在职场上先人一步。让AI成为你的机甲，而不是拐棍。\n课程亮点：\nAI思维培养：我们不只教你使用AI工具，更重视培养你的AI思维，让你深刻理解AI的工作原理，提升你的创新能力和问题解决能力。\n实际应用指导：通过具体案例分析，我们将指导你如何在职业规划、人际沟通等职场场景中运用AI技术，让你的工作更加高效。\n课程特色：\n案例丰富：让你在实际操作中掌握AI应用，提升职场实战能力。\n专家互动：课程由工信部认证AI应用专家王长乐主讲。\n无论你是即将毕业的大学生，还是刚步入职场的新人，或是希望提升职场能力的拼搏者，这门课程都将是你职场升级的得力助手。让我们一起探索AI的无限可能，开启你的职场“AI机甲”之旅！",
      "target_audience": [
        "即将毕业的大学生，为未来职场做准备",
        "新入职场的年轻人",
        "想用AI快速成为职场的超级个体"
      ]
    },
    {
      "title": "파이썬(Python) 딥러닝(Deep Learning,DL) 프로젝트 - 기초 수학과 모델링 원리",
      "url": "https://www.udemy.com/course/maso-ds-python-onc72/",
      "bio": "딥러닝(Deep Learning)을 본격적으로 활용하기 위한 머신 러닝(Machine Learning) 개념, 인공지능의 학습 원리, 모델 구현을 위한 수학적 원리와 파이썬(Python) 모델링 알기!",
      "objectives": [
        "인공 지능, 머신 러닝, 딥러닝의 개념 파악",
        "딥러닝 알고리즘의 기초 수학적 이해",
        "딥러닝의 학습 원리 및 오차 수정 방식 이해",
        "파이썬 가상 환경 구축과 텐서플로우 CPU 활용 능력"
      ],
      "course_content": {
        "딥러닝 실습환경 구축": [
          "DLM001_딥러닝 실습 환경",
          "DLM002_아나콘다 환경 구성",
          "DLM003_가상 환경의 이해",
          "DLM004_가상 환경 구축",
          "DLM005_구글 코랩 환경 구축",
          "DLM006_딥러닝 추가 정보"
        ],
        "딥러닝 기초 개념": [
          "DLM101_강의 소개",
          "DLM102_인공지능, 머신 러닝, 딥러닝",
          "DLM103_전통적인 프로그래밍vs 머신 러닝",
          "DLM104_머신 러닝의 데이터 셋 나누기",
          "DLM105_머신 러닝 학습의 개념",
          "DLM106_머신 러닝의 종류",
          "DLM107_지도학습의 종류",
          "DLM108_머신 러닝과 딥러닝의 차이",
          "DLM109_딥러닝의 평가 지표"
        ],
        "딥러닝 기초 수학": [
          "DLM201_함수와 기울기",
          "DLM202_편미분",
          "DLM203_시그모이드 함수",
          "DLM204_지수와 지수함수",
          "DLM205_로그와 로그함수"
        ],
        "딥러닝 수학 실습": [
          "DLM301_딥러닝 수학 실습_용어정리",
          "DLM302_딥러닝 수학 실습_평균제곱근 오차",
          "DLM303_딥러닝 수학 실습_경사 하강법과 다중선형회귀"
        ],
        "딥러닝의 학습 원리 - 회귀": [
          "DLM401_딥러닝의 학습 원리",
          "DLM402_학습 원리_회귀",
          "DLM403_회귀의 학습 과정",
          "DLM404_회귀의 오차 수정"
        ],
        "딥러닝의 학습 원리 - 분류": [
          "DLM501_분류의 학습 과정",
          "DLM502_로지스틱 회귀의 손실 함수"
        ],
        "딥러닝 모델 구현 실습": [
          "DLM601_딥러닝 모델 구현_회귀",
          "DLM602_딥러닝 모델 구현_다중선형회귀와 로지스틱 회귀"
        ]
      },
      "requirements": [
        "본 강의는 기본적인 파이썬 활용 능력을 요구합니다.",
        "마소캠퍼스의 [파이썬(Python) 실무 데이터 분석 프로젝트] 강의들을 먼저 수강하시는걸 추천드립니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n\n\n딥러닝.. 모두가 하고있지만 내가 하기는 두려우신가요?\n최근 딥러닝, 머신러닝 등 인공지능 관련 기술이 각광받고 있습니다.\n4차 산업혁명 시대라고 불리는 지금, 꼭 알아야 할 핵심 기술이기 때문이지요.\n이제 막 IT 업계에 발을 들이신 분이라면 반드시 알고 있어야 할 지식이기도 합니다.\n그런데 대부분의 입문자분들은 이러한 배경지식 없이 무작정 코딩부터 배우려고 합니다.\n이렇게 되면 당연히 한계에 부딪힐 수밖에 없습니다.\n그래서 마소캠퍼스가 준비했습니다.\n기초 이론부터 차근차근 배워나가실 수 있도록 구성한\n[파이썬(Python) 딥러닝(Deep Learning,DL) 프로젝트 - 기초 수학과 모델링 원리]과 함께라면 누구나 쉽게 배울 수 있습니다.\n어려운 코딩이나 비싼 프로그램? NO!\n파이썬의 최대 장점 중 하나인 무료로 설치 가능한 모듈에는\n이미 딥러닝을 구현할 수 있는 모듈이 개발되었으며, 실제로 많은 사람들이 활용하고 있습니다.\n많은 사람들이 사용할 수 있다는 건, 당신도 충분히 활용 가능하다는 의미입니다.\n그래서 마소캠퍼스에서는 누구나 딥러닝에 쉽게 입문할 수 있도록\n[파이썬(Python) 딥러닝(Deep Learning,DL) 프로젝트 - 기초 수학과 모델링 원리] 강의를 제작하였습니다.\n그야말로 혁명적인 생산성 향상을 가져오기 위해, 당신도 딥러닝에 입문해보세요!\n\n\n<파이썬(Python) 딥러닝(Deep Learning,DL) 프로젝트 - 기초 수학과 모델링 원리> 강의를 듣고 나면,\n여러분께서는 다음과 같은 역량을 확보하실 수 있습니다.\n인공 지능, 머신 러닝, 딥러닝의 개념 파악\n딥러닝 알고리즘의 기초 수학적 이해\n딥러닝의 학습 원리 및 오차 수정 방식 이해\n파이썬 가상 환경 구축과 텐서플로우 CPU 활용 능력\n\n\n분야에 상관 없이 압도적인 생산성 향상을 가져다 주는 딥러닝!\n딥러닝을 “제대로” 활용하기 위해 개념부터 완벽하게 잡고 가는 과정!\n\n\n-\n\n\n[ 강 사  소 개 ]\n\n\n김 진 숙\n現 마소캠퍼스 수석 교수\n컴퓨터시스템 공학 석사\n김진숙 교수는 마소캠퍼스에서 빅데이터 부분 수석 교수로 빅데이터(R, 파이썬), HTML5/CSS3, JQueryMobile, 스크래치, 앱인벤터, IoT 등의 최신 IT 관련 기술 과정들까지 다양한 기업과 기관의 수강생들을 대상으로 열정 넘치는 강의를 이어가고 있습니다. 김진숙 교수는 스마트팜 IoT 프로젝트, 카 셰어링 앱 프로젝트 등 다수 프로젝트 지도 경력까지 겸비한 전문가입니다.\n-",
      "target_audience": [
        "인공지능으로 혁신적인 생산성을 확보하고 싶은 실무자",
        "IT업계로 창업/이직/입사 등 커리어를 쌓고 싶은 모든 사람",
        "이미 딥러닝을 활용하고 있지만, 작동 원리에 대해서는 모르는 실무자",
        "딥러닝 역량을 쌓기 위해 첫 단추부터 제대로 시작하고 싶은 모든 사람"
      ]
    },
    {
      "title": "ChatGPT e OpenAI API: O Poder da Inteligência Artificial",
      "url": "https://www.udemy.com/course/chatgpt-e-openai-api-o-poder-da-inteligencia-artificial/",
      "bio": "Explorando o Futuro: Domine ChatGPT, DALL-E e OpenAI API para Transformar Ideias em Realidade!",
      "objectives": [
        "Aprender diversas técnicas de inteligência artifical",
        "Aprender sobre ChatGPT e a API da OpenAI",
        "Configuração do ambiente de execução",
        "Geração de imagens com DALL-E",
        "Gerar áudios a partir de texto",
        "Transcrição de áudios",
        "Tradução de áudios",
        "Utilização de ferramentas de moderação de texto"
      ],
      "course_content": {
        "Introdução": [
          "Introdução",
          "Sobre a OpenAI",
          "Instruções"
        ],
        "ChatGPT": [
          "Introdução ao Módulo",
          "Criando conta e obtendo a key da API",
          "Interface",
          "Aplicação - Correção Ortográfica",
          "Aplicação - Resumo",
          "Aplicação - Codificação",
          "Aplicação - Guia Turístico",
          "Limitações"
        ],
        "Ambiente de Execução": [
          "Google Colab - Teoria",
          "Google Colab - Prática"
        ],
        "Chat Completion": [
          "Introdução ao Módulo",
          "Chat Completion",
          "Testando modelos",
          "Parâmetros Adicionais",
          "Streaming",
          "Aplicação - Análise de sentimentos",
          "Aplicação - Tradução"
        ],
        "DALL-E": [
          "Introdução ao Módulo",
          "DALL-E-2 - Criação de Imagens",
          "DALL-E-2 - Parâmetros Adicionais",
          "DALL-E-2 - Editando uma imagem",
          "DALL-E-2 - Gerando variações de uma imagem",
          "DALL-E-3 - Criação de Imagens",
          "DALL-E-3 - Parâmetros Adicionais",
          "Visualizando e baixando imagens"
        ],
        "Text to Speech": [
          "Introdução ao Módulo",
          "Gerando Áudios",
          "Testando as vozes",
          "Testando os modelos",
          "Parâmetros Adicionais",
          "Controlando emoções"
        ],
        "Speech to Text": [
          "Introdução ao Módulo",
          "Transcription",
          "Transcription - Parâmetros Adicionais",
          "Translation",
          "Correção ortográfica"
        ],
        "Moderation": [
          "Introdução ao Módulo",
          "Moderação",
          "Parâmetros Adicionais"
        ],
        "Considerações Finais": [
          "Considerações Finais"
        ]
      },
      "requirements": [
        "Vontade de aprender"
      ],
      "description": "Bem-vindo ao curso \"ChatGPT e OpenAI API: O Poder da Inteligência Artificial\". Este curso inovador proporciona uma imersão profunda no fascinante mundo da inteligência artificial (IA), com foco especial nas tecnologias desenvolvidas pela OpenAI. Ao longo do programa, os participantes terão a oportunidade de explorar e aplicar as capacidades revolucionárias do ChatGPT e da OpenAI API em diversos contextos.\nMódulos do Curso:\nChatGPT: Inicie sua jornada descobrindo o ChatGPT, um modelo de linguagem de última geração que utiliza a técnica de aprendizado profundo para gerar respostas contextualmente relevantes e realistas em linguagem natural.\nChat Completition: Aprofunde-se na geração de texto com o módulo de Chat Completition, explorando como a IA pode ser usada para complementar e aprimorar conversas de maneira dinâmica. Além da integração desse serviço com outras aplicações.\nDALL-E: Entre no universo visual com o módulo DALL-E, que utiliza técnicas avançadas de generação de imagens para criar arte e conceitos visuais inovadores. Além da geração de variações de uma imagem e também da edição.\nText to Speech (TTS): Descubra como transformar texto em uma experiência auditiva envolvente, explorando as capacidades de conversão de texto para fala.\nSpeech to Text (STT): Aprenda a extrair informações valiosas a partir de áudio, convertendo a fala em texto de maneira eficiente e precisa.\nModeração: Explore as aplicações práticas da IA na moderação de conteúdo, compreendendo como as tecnologias OpenAI podem ser empregadas para garantir ambientes online seguros e inclusivos.\nAmbiente de Execução - Google Colab: Familiarize-se com o ambiente de execução no Google Colab, uma plataforma colaborativa baseada em nuvem que permite a execução de códigos em Python de forma eficiente e acessível.\nObjetivos do Curso:\nCapacitar os participantes a compreender e aplicar as tecnologias da OpenAI em suas próprias áreas de interesse.\nDesenvolver habilidades práticas na utilização de ChatGPT, Chat Completition, DALL-E, Text to Speech, Speech to Text e moderação.\nDemonstrar como integrar essas tecnologias em projetos do mundo real.\nProporcionar uma experiência prática e interativa por meio do ambiente de execução no Google Colab.\nPrepare-se para desbravar as fronteiras da inteligência artificial e desbloquear o potencial criativo e inovador dessas poderosas ferramentas da OpenAI. Inscreva-se agora e mergulhe no futuro da IA!",
      "target_audience": [
        "Pessoas que querem dar seu primeiro passo em inteligência artificial",
        "Estudantes de graduação e pós-graduação que estejam cursando disciplinas sobre este assunto",
        "Qualquer pessoa interessada em inteligência artificial, ciência de dados e machine learning",
        "Pessoas que estão envolvidos na área de ciência de dados e almejam progredir em suas trajetórias profissionais, bem como expandir seu portfólio.",
        "Pessoas que desejam aplicar inteligência artificial em seus projetos, seja pessoal ou empresarial"
      ]
    },
    {
      "title": "Python ile Web Kazıma ( Web Scraping ) Eğitimi",
      "url": "https://www.udemy.com/course/python-ile-web-kazma-web-scraping-egitimi/",
      "bio": "Beautiful Soup, Selenium, Scrapy ve Scrapy-Playwright ile Egzersiz ve Proje Odaklı Web Kazıma - Web Scraping Eğitimi",
      "objectives": [
        "Python ile veri kazıma",
        "Python'un en popüler ve etkili web kazıma kütüphaneleri",
        "Scrapy-Playwright",
        "Selenium ile web otomasyon",
        "Scrapy",
        "Requests ve Beautiful Soup",
        "Web sitesine göre doğru web kazıma aracını seçme",
        "Html dosyalarını okuma ve analiz etme",
        "Kazınan verilerin kaydedilmesi",
        "Toplu resim indirme"
      ],
      "course_content": {
        "Giriş": [
          "Bölüme Giriş",
          "Kurs Kaynakları",
          "Web Sitesinin Statik mi Dinamik mi Olduğunun Kontrolü",
          "Kullanılacak Yönteme Nasıl Karar Vereceğiz?",
          "HTML Dosyalarını Okumak ve Analiz Etmek",
          "Python ve Pycharm Yüklemeleri (WINDOWS)",
          "Python ve Pycharm Yüklemeleri (LINUX)",
          "Python ve Pycharm Yüklemeleri (MACOS)",
          "Windows, Linux ve MacOS | Jupyter Notebook Yüklemeleri (Opsiyonel)",
          "Uygulama Projeleri Hakkında",
          "Kurs Planı"
        ],
        "BEAUTIFUL SOUP ve REQUESTS 1 - TEMELLER": [
          "Bölüme Giriş",
          "Kütüphaneler ve İlk Request",
          "Beautiful Soup Seçicileri (Selectors)",
          "Bir Kitabın Verisini Kazımak",
          "Dış Döngü - Sayfalar",
          "İç Döngü - Tüm Kitapların Verisini Kazımak",
          "Veriyi Kaydetmek",
          "Requests ile Resim İndirmek"
        ],
        "BEAUTIFUL SOUP ve REQUESTS 2 - EGZERSİZ 1 (QUOTES)": [
          "Bölüme Giriş",
          "Egzersiz 1",
          "Egzersiz 1 Çözümleri"
        ],
        "BEAUTIFUL SOUP ve REQUESTS 3 - UYGULAMA PROJESİ 1 (EBAY)": [
          "Bölüme Giriş",
          "Bir Laptop'ın Verisini Kazımak, Cookies ve Headers Kullanımı",
          "Sayfalar",
          "Veriyi Kaydetmek"
        ],
        "SELENIUM 1 - TEMELLER": [
          "Bölüme Giriş",
          "Selenium ve Chromedriver Yüklemeleri",
          "Driver Oluşturmak ve Tarayıcıyı Çalıştırmak",
          "CSS Seçicileri (Selectors)",
          "XPATH",
          "Selenium ile Siteye Giriş Yapmak - Login",
          "İlk Sayfayı Kazımak",
          "Bir Döngü ile Sayfaları Gezmek",
          "Sonsuz Scroll (Infinite Scroll)",
          "Beklemeler (Waits)",
          "Actions"
        ],
        "SELENIUM 2 - EGZERSIZ 2 (YAZARLAR)": [
          "Bölüme Giriş",
          "Egzersiz 2",
          "Egzersiz 2 Çözümleri"
        ],
        "SELENIUM 3 - UYGULAMA PROJESİ 2 (IMDB)": [
          "Bölüme Giriş",
          "Driver Oluşturmak ve Tarayıcıyı Çalıştırmak",
          "Otomasyon ile İstenilen Sayfaya Ulaşmak",
          "Tüm Elementleri Yüklemek İçin Aşağı Kaydırmak",
          "Verileri Kazımak"
        ],
        "SELENIUM 4 - EGZERSİZ 3 (IMDB YÖNETMENLER)": [
          "Bölüme Giriş",
          "Egzersiz 3",
          "Egzersiz 3 Çözümleri"
        ],
        "SCRAPY 1 - TEMELLER": [
          "Bölüme Giriş",
          "Scrapy Yüklemek, Scrapy Projesi ve Spider Oluşturmak",
          "Scrapy Shell ve Scrapy Seçicileri (Selectors)",
          "Parse Method",
          "Items",
          "Parse Books Method",
          "Pipelines",
          "Item Eleme (Dropper Pipeline)",
          "Excel Pipeline",
          "SQLite Pipeline",
          "Middlewares",
          "Crawler (Scrapy Crawl Spider)"
        ],
        "SCRAPY 2 - EGZERSİZ 4 (QUOTES)": [
          "Bölüme Giriş",
          "Egzersiz 4",
          "Egzersiz 4 Çözümleri"
        ]
      },
      "requirements": [
        "Temel Python bilgisi",
        "Internete bağlanabilen ve temel programları çalıştırabilen bir bilgisayar"
      ],
      "description": "Günümüz veri odaklı dünyasında, web kazıma çok güçlü bir araç ve önemli bir yetenek.\nBu kursu, Udemy'deki en kapsamlı web scraping kursu olacak şekilde tasarladım. Kurs, zengin kütüphane içeriğinin yanı sıra egzersizler ve gerçek web siteleri üzerinde uygulama projeleri de içeriyor.\nİlk olarak, kazınmak üzere tasarlanmış bookstoscrape ve quotestoscrape sitelerini kazıyacak ve temel oluşturacağız. Temel bilgileri öğrendikten sonra, gerçek web sitelerinden veri kazımaya başlayacağız.\n\n\nUygulamalarımız:\nRequests ve BeautifulSoup: EBAY üzerinde web kazıma\nSelenium: IMDB üzerinde otomasyon ve web kazıma\nScrapy: Flying Tiger ve Yelp üzerinde web kazıma ve web crawling\nScrapy-Playwright: Playwright özelliklerini Scrapy projesine entegre ederek dinamik web sitelerini Scrapy’nin gücü ile kazımayı öğrenme.\n\n\nBu Kurs Neden Alınmalı?\nZengin kütüphane içeriği: Python’un en popüler ve etkili web scraping kütüphaneleri; Requests, Beautiful Soup, Selenium, Scrapy ve Scrapy-Playwright\nProje boyutunda egzersizler: 4 adet (Beautiful Soup, Selenium, Selenium, Scrapy)\nUygulama projeleri: 4 adet (Ebay, Imdb, Flying Tiger, Yelp)\n\n\nWeb kazımayı kapsamlı ve etkili bir şekilde öğrenmek için bana katılın. Öğretici temel projeler, egzersizler ve uygulama projeleri ile hem gerekli konseptleri öğrenip hem de pratik kazanacaksınız. Bu kurs, hem yeni başlayanlar hem de mevcut bilgilerini geliştirmek isteyenler için çok iyi bir kaynak durumunda. Kazanacağınız yetenekler, veri bilimi, iş zekası ve daha birçok alanda faydalı olacak. Haydi başlayalım!",
      "target_audience": [
        "Web kazıma öğrenmek isteyen başlangıç seviyesi Python geliştiricileri",
        "Veri bilimi alanına en temel kısmından başlamak isteyen programcılar"
      ]
    },
    {
      "title": "Curso Python: Series Temporales con Pandas",
      "url": "https://www.udemy.com/course/curso-python-series-temporales-con-pandas/",
      "bio": "Jorge, con experiencia en programación, te guiará en el aprendizaje de Python desde cero.",
      "objectives": [
        "Crear y manipular series temporales utilizando la librería pandas en Python.",
        "Aplicar técnicas de resampling para modificar la frecuencia de los datos.",
        "Implementar window functions como medias móviles y ventanas personalizadas.",
        "Realizar un análisis exploratorio, incluyendo visualización y detección de anomalías.",
        "Descomponer una serie temporal en sus componentes principales para entender patrones y tendencias.",
        "Llevar a cabo un proyecto final de análisis de una serie temporal real utilizando todas las técnicas aprendidas."
      ],
      "course_content": {
        "Introducción a las Series Temporales y Preparación de Entorno": [
          "Bienvenido a DataBoosters",
          "Introducción",
          "Importancia de las Series Temporales",
          "Configuración de Entorno de Trabajo",
          "Archivos del curso"
        ],
        "Manipulación de Datos Temporales con pandas": [
          "Creación de Series Temporales en pandas",
          "Indexación y Selección de Datos Temporales",
          "Operaciones con Series Temporales en pandas"
        ],
        "Resampling en Series Temporales": [
          "Conceptos de Resampling",
          "Resampling de Alta Frecuencia a Baja Frecuencia",
          "Resampling de Baja Frecuencia a Alta Frecuencia"
        ],
        "Window Functions en Series Temporales": [
          "Introducción a Window Functions",
          "Cálculos de Media Móvil (Moving Averages)",
          "Ventanas de Tiempo Personalizadas"
        ],
        "Análisis Exploratorio de Series Temporales": [
          "Visualización de Series Temporales",
          "Descomposición de Series Temporales",
          "Detección de Anomalías en Series Temporales"
        ],
        "Conclusión del Curso": [
          "Resumen y Mejores Prácticas",
          "Proyecto Final: Análisis de una Serie Temporal Real",
          "Recursos Adicionales y Pasos Siguientes"
        ],
        "Terminaste": [
          "Clase extra"
        ]
      },
      "requirements": [
        "Conocimientos básicos de Python, incluyendo estructuras de datos y funciones.",
        "Familiaridad con librerías como pandas y matplotlib (aunque se repasarán conceptos clave).",
        "Tener instalado Python en tu equipo y un entorno de trabajo como Jupyter Notebook o VSCode."
      ],
      "description": "¿Quieres dominar el análisis de series temporales y llevar tus habilidades de Python al siguiente nivel? Este curso está diseñado para equiparte con las herramientas y técnicas necesarias para trabajar con datos temporales, uno de los desafíos más frecuentes y emocionantes en el análisis de datos.\nAprenderás desde lo básico hasta lo avanzado, explorando conceptos como la creación y manipulación de series temporales con pandas, técnicas de resampling, y el uso de window functions para análisis más profundos. Además, realizaremos un análisis exploratorio que incluye visualización, detección de anomalías y la descomposición de series para identificar patrones ocultos.\nCon ejercicios prácticos y un proyecto final basado en un caso real, este curso te ayudará a aplicar tus nuevos conocimientos en áreas como finanzas, ventas, logística, meteorología y mucho más. La combinación de teoría y práctica te permitirá abordar proyectos complejos con confianza y precisión.\nNo importa si eres un principiante o un profesional con experiencia, este curso está diseñado para que puedas aprender a tu propio ritmo. Al finalizar, tendrás las habilidades necesarias para trabajar con datos temporales de manera eficiente y estructurada, transformando tu conocimiento en un activo valioso.\n¡Inscríbete hoy y lleva tu análisis de datos al siguiente nivel con series temporales en Python!",
      "target_audience": [
        "Analistas de datos interesados en profundizar su conocimiento en análisis de series temporales.",
        "Científicos de datos que desean mejorar sus habilidades en manipulación de datos temporales.",
        "Profesionales en finanzas, marketing o logística que trabajan con datos dependientes del tiempo.",
        "Estudiantes o entusiastas de la programación en Python que buscan un desafío adicional."
      ]
    },
    {
      "title": "Alteryx TRIFACTA e Apache HOP: cargas e tratamento de dados",
      "url": "https://www.udemy.com/course/alteryx-trifacta-e-apache-hop-cargas-e-tratamento-de-dados/",
      "bio": "Construa pipelines de dados e faça tratamento, governança e ajustes nos dados",
      "objectives": [
        "Preparação de dados aberta que pode se conectar a diversas fontes de dados",
        "Integração em todas as principais plataformas de dados em nuvem",
        "Decida entre ETL ou ELT, ou uma combinação ideal dos dois com base no desempenho",
        "Suporte para todas as principais nuvens, Google, AWS, Azure e on-premise",
        "Interface intuitiva e simples utilização de objetos de dados",
        "Perfilização de dados, ajudando na identificação de outliers",
        "Tratamento de dados, criação de novos campos, dentre outras tarefas",
        "Eliminação de dados nulos, inconsistências, criação de novos campos",
        "Exploração e avaliação de conteúdo e de qualidade de qualquer conjunto de dados",
        "Engenharia de dados com low-code, visual, direto na nuvem",
        "Construção, implantação e automatização de pipelines de dados",
        "Criação de flow de dados, que permite ao analista encadear suas ações de tratamento",
        "Action com os dados: Columns, Rename, Sort, Calculate, Group By, Filter Rows, Replace",
        "Action com os dados: Split, Create formula, dentre outros",
        "Exportação dos resultados automatizados",
        "O que é  Hop Orchestration Platform",
        "Entendendo sobre fluxos de trabalho e pipelines",
        "Entendendo sobre projetos e ambientes",
        "Instalação do APACHE HOP",
        "Criando pipelines com arquivos texto",
        "Realizando tratamento de dados para entendimento do processo de engenharia de dados",
        "O que são transformações, links e ações dentro de um pipeline",
        "Construindo um workflow, orquestrador da sequência das operações",
        "Entendendo o HOP GUI e seus componentes",
        "Entendendo menu barras, principal e perspectivas",
        "Criando sua área de projetos",
        "Componentes pipelines: Sort, Select value, CSV file input, Value mapper, Filter rows, Dummy, Unique rows, Merge Join, Text File Output",
        "Entendendo o que é : View output, Preview output , Debug output",
        "Componentes pipelines: Number Range, Concat Field, String Operations, Replace in String, IF Field Value is Null, Split Fields, CSV File Input, Mail, File Exist",
        "Leitura de dados em uma API: Rest Client, JSON Input, JSON Output",
        "Construindo Workflow com execução de pipelines",
        "Entendo o uso de variáveis globais no APACHE HOP",
        "Automatização de pipeline ou workflow pelo HOP-RUN",
        "Construindo pipelines em banco de dados Postgresql: Table Input, Table Output, Configurando conexão",
        "Instalação de banco de dados Postgresql, usando PGAdmin"
      ],
      "course_content": {
        "Alteryx TRIFACTA - Preparação de dados - explore e qualidade": [
          "O que é o Alteryx TRIFACTA",
          "Apresentação da Ferramenta e arquitetura",
          "INFORMAÇÕES IMPORTANTES! - Leia antes de começar o curso",
          "Carregando os dados e fazendo Explorer dos dados",
          "Action Substituir - Tratamento de dados - parte 01",
          "Action Rename e Sort - Tratamento de dados - parte 02",
          "Action Move e Hide - Tratamento de dados - parte 03",
          "Action Format - Tratamento de dados - parte 04",
          "Action Calculate - Tratamento de dados - parte 05",
          "Action Create Columns From Examples - Tratamento de dados - parte 06",
          "Action Extract - Tratamento de dados - parte 07",
          "Action Split Column - Tratamento de dados - parte 08",
          "Action Merge - Tratamento de dados - parte 09",
          "Action Group By - Tratamento de dados - parte 10",
          "Action Filtro - Tratamento de dados - parte 11",
          "Aplicação de Funções de Controle",
          "Aplicação de Funções Especiais",
          "Executando o Fluxo de dados e gerando arquivo de saída",
          "Gerando o agendamento (Schedule) do Fluxo de Dados",
          "Aula Final - Atividade para entrega"
        ],
        "APACHE HOP - Integração e Ingestão de dados": [
          "Entendendo o funcionamento e componentes",
          "Instalação do JAVA",
          "Instalação do APACHE HOP",
          "Configuração extra e iniciando APACHE HOP",
          "Criando projeto e ambiente, primeiros passos",
          "Pipeline de Tratamento: arquivo vinhos",
          "Pipeline de tratamento: filtragem e seleção de atributos - arquivos vinho",
          "Pipeline de tratamento: sort e group by atributos - arquivos vinho",
          "Pipeline de tratamento: gerando arquivo de saída totalizador - arquivos vinho",
          "Pipeline Merge dos dados: Leitura arquivos de entrada",
          "Pipeline Merge dos dados: Sort arquivos de entrada",
          "Pipeline Merge dos dados: Merge arquivos venda e cliente",
          "Pipeline Merge dos dados: Merge arquivos venda com produto e marca",
          "Pipeline Merge dos dados: geração arquivo venda final tratado",
          "Pipeline Tratamento de dados: Arquivo cliente veículos e strings diversos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e ajustes campo hora",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e retirada valores nulos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e junção de atributos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e geração grupos de dados",
          "Pipeline Carga API: Leitura dados CEP e uso de REST GET",
          "Pipeline Carga API: Leitura e armazenamento arquivo JSON",
          "Pipeline Carga API: Tratamento dos dados escolha campos e gravação arquivo texto",
          "Workflow de execução: Parte01",
          "Workflow de execução: Parte02",
          "Banco de dados: Instalação do Postgresql",
          "Banco de dados: Pipeline de tratamento de dados no Postgresql",
          "HOP-RUN: Automatização de pipeline e workflow",
          "Aula Final - Entrega de atividades",
          "Responda a nossa pergunta"
        ]
      },
      "requirements": [
        "Importante ter conhecimento sobre banco de dados, arquivos de dados",
        "Importante que você conheça lógica de programação"
      ],
      "description": "Este treinamento foi construido como um dos mais práticos e principais da área de preparação de dados. Utilizaremos duas das mais importantes ferramentas de mercado que fazem o trabalho de preparação de dados, governaça de dados e ajustes nos dados, estamos falando Alteryx TRIFACTA e do APACHE HOP.\nO Alteryx TRIFACTA, é uma ferramenta 100% na nuvem, low-code, totalmente prática e com grande destaque no mercado. Ela é uma plataforma em nuvem aberta e interativa, que permite a capacitação de engenheiros de dados e analistas a interpretar, preparar e criar pipelines de dados para acelerar suas análises.\n\n\nAs principais características do Alteryx TRIFACTA são:\nExplore e avalie o conteúdo e a qualidade de qualquer conjunto de dados.\nAcelere e acompanhe transformações de dados de forma visual.\nConstrua, implante e automatize pipelines de dados.\nUtilize os fluxos de dados para definir TODAS as suas necessidades em tratamento de dados e governança de dados\n\n\nO APACHE HOP é a abreviação de Hop Orchestration Platform, é uma plataforma de orquestração de dados e engenharia de dados que visa facilitar todos os aspectos da orquestração de dados e metadados, por padrão o HOP vem com cerca de 400 plugins ou componentes.\nSão criados fluxos de trabalho (Workflow) e pipelines em um ambiente de desenvolvimento visual chamado Hop Gui.\nCom o APACHE HOP é possível combinar, enriquecer, limpar e de muitas outras maneiras manipular dados.\nA ideia é que você faça a leitura de dados, realize os ajustes e tratamentos no conteúdo (limpeza de inconsistências, criação de campos, composição de campos, dentre outros).\nPara você que pretende ou trabalha com engenharia de dados é a ferramenta perfeita.\nO curso cobre todo o ciclo desde o START da construção do pipeline ou workflow até a automatização deste.\n\n\nEntão venha para o nosso treinamento e promova a exploração sobre seus dados com alta performance.",
      "target_audience": [
        "Profissionais de TI",
        "Profissionais que querem trabalham na área de Engenharia de dados, Análise de dados, Ciência de Dados, Business Intelligence",
        "Pessoas interessadas em aprender os conceitos sobre ferramentas de ingestão de dados, ou que gostariam adentrar na área de engenharia de dados",
        "Profissionais que, de alguma forma, utilizam dados no seu dia a dia"
      ]
    },
    {
      "title": "GPT 논문 구현으로 배우는 딥러닝 논문 구현 with TensorFlow 2.0 Part 1",
      "url": "https://www.udemy.com/course/gpt-transformer-implementation-tensorflow-part1/",
      "bio": "GPT (Generative Pre-trained Transformer) 구현으로 배우는 딥러닝 논문 구현",
      "objectives": [
        "딥러닝 논문 읽는 법",
        "딥러닝 논문 구현하는 법",
        "GPT(Generative Pre-trained Transformer) 모델 구조에 대한 디테일한 이해",
        "GPT(Generative Pre-trained Transformer) 모델에 대한 배경지식",
        "TensorFlow 2.0을 이용한 코드 작성법"
      ],
      "course_content": {
        "강의 소개": [
          "강의 소개"
        ],
        "GPT Overview": [
          "GPT-1 모델의 핵심 Contribution",
          "GPT-1이 해결한 다양한 자연어처리 Task - Text Entailment, Semantic Similarity",
          "GPT-1 모델 리뷰 - Framework",
          "GPT-1 모델 리뷰 - Task-specific input transformations",
          "GPT-1 모델 리뷰 - Model specifications, Supervised fine-tuning",
          "GPT-1 모델 리뷰 - Analysis",
          "GPT-1 추가 참고자료"
        ],
        "딥러닝 논문 읽는 법": [
          "일반적인 딥러닝 논문 구성 및 논문 읽는 법"
        ],
        "GPT-1(Improving Language Understanding by Generative Pre-Training) 논문 리뷰": [
          "GPT-1(Improving Language Understanding by Generative Pre-Training) 논문 다운로드",
          "GPT-1 논문 리뷰 - Abstract",
          "GPT-1 논문 리뷰 - Introduction",
          "GPT-1 논문 리뷰 - Related Work",
          "GPT-1 논문 리뷰 - Framework",
          "GPT-1 논문 리뷰 - Experiments",
          "GPT-1 논문 리뷰 - Analysis",
          "GPT-1 논문 리뷰 - Conclusion"
        ],
        "Gaussian Error Linear Unit (GELU) & Byte Pair Encoding (BPE)": [
          "Gaussian Error Linear Unit (GELU)",
          "Byte Pair Encoding (BPE)"
        ],
        "강의에서 사용하는 소스코드 다운로드": [
          "강의에서 사용하는 소스코드 다운로드"
        ],
        "TensorFlow 2.0을 이용한 GPT-1 논문 구현": [
          "딥러닝 논문 구현방법 개요 & 프로젝트 설명",
          "train.py",
          "model.py",
          "evaluate.py",
          "utils.py",
          "train.py & evaluate.py 실행",
          "train_adder.py",
          "evaluate_adder.py",
          "train_adder.py & evaluate_adder.py 실행",
          "colab을 이용한 train.py & evaluate.py & train_adder.py & evaluate_adder.py 실행"
        ]
      },
      "requirements": [
        "Python 사용경험",
        "선수강의 [예제로 배우는 딥러닝 자연어 처리 입문 NLP with TensorFlow - RNN부터 BERT까지] 수강경험"
      ],
      "description": "GPT-1(Improving Language Understanding by Generative Pre-Training) 논문을 TensorFlow 2.0을 이용해서 밑바닥부터 구현해보며 딥러닝 논문 구현 능력을 배울 수 있는 강의입니다.\n\n\n딥러닝 연구자 필수 소양, 최신 논문 구현 능력!\nGPT 구현과 함께 익혀보세요\n\n\n최신 논문 구현, GPT로 함께!\n많은 기업들에서 딥러닝 연구자를 채용할때 최신 논문을 직접 구현해본 경험을 우대하고 있습니다. GPT-1(Improving Language Understanding by Generative Pre-Training) 논문을 직접 구현해보면서 최신 논문 구현 경험을 익혀보세요.\n\n\nGPT-1 논문으로 구조 파악 + TensorFlow 2.0으로 직접 구현까지!\nGPT-1 논문을 함께 읽으며 GPT-1 구조를 완벽하게 파악한 뒤,\nTensorFlow 2.0을 이용해서 GPT-1을 직접 구현해봅시다.\n\n\nGPT-1 논문(Improving Language Understanding by Generative Pre-Training)을 같이 읽고, GPT-1 모델을 TensorFlow 2.0을 이용해서 밑바닥부터 구현해봅니다.\n\n\n선수 강의\n본 강의는 TensorFlow 2.0과 자연어처리(NLP)에 대한 선수지식이 필요한 강의입니다. 반드시 아래 강의를 먼저 수강하시거나 그에 준하는 지식을 갖춘 뒤 본 강의를 수강하세요.\n\n\nAISchool [예제로 배우는 딥러닝 자연어 처리 입문 NLP with TensorFlow - RNN부터 BERT까지]\n\n\n딥러닝 자연어처리 기초부터 최신모델인 Transformer와 BERT까지 딥러닝 자연어 처리(Natural Language Processing[NLP])의 원리와 활용방법을 다양한 예제와 실습 코드 구현을 통해 학습합 수 있는 강의입니다.",
      "target_audience": [
        "딥러닝 논문을 읽고 구현하는 능력을 기르고 싶은 분",
        "딥러닝 연구 관련 직종으로 취업을 원하시는 분",
        "인공지능/딥러닝 관련 연구를 진행하고 싶은 분",
        "인공지능(AI) 대학원을 준비 중이신 분"
      ]
    },
    {
      "title": "Machine Learning: Classificação com Linguagem Python",
      "url": "https://www.udemy.com/course/machine-learning-previsao-de-churn-em-um-e-commerce/",
      "bio": "Aprenda sobre Random Forest com um PROJETO do zero de Churn em um E-commerce",
      "objectives": [
        "O que é Machine Learning",
        "O que é Classificação",
        "O que é Churn",
        "O que é e como funciona o Jupyter Notebook",
        "Conhecer os principais tipos de aprendizado (supervisionado, não supervisionado e por esforço)",
        "Executar códigos em Python, célula por célula",
        "Entender quando aplicar transformação nos dados",
        "Aprender um pouco mais sobre o pandas",
        "Aprender sobre Árvores de Decisão",
        "Aprender sobre Random Forests",
        "Aprender a realizar otimização de hiper-parâmetros",
        "Aprender o que é cross-validation",
        "Aprender o que é Data Leakage",
        "Entender quando normalizar ou padronizar seus dados",
        "Aprender a treinar e testar seus modelos",
        "Aprender sobre Confusion Matrix"
      ],
      "course_content": {
        "Apresentação": [
          "Apresentação do Instrutor",
          "Dinâmica do Curso",
          "Módulos",
          "Ferramentas, Dicas e Contato"
        ],
        "Machine Learning": [
          "Definição",
          "Tipos de Aprendizado",
          "Aprendizado Supervisionado",
          "Aprendizado Não Supervisionado",
          "Aprendizado por Reforço",
          "Exemplos de Pojetos"
        ],
        "Classificação": [
          "Definição",
          "Importância",
          "Algoritmos",
          "Árvore de Decisão",
          "Random Forest",
          "Pipeline"
        ],
        "Projeto": [
          "Jupyter Notebook: Definição",
          "Jupyter Notebook: Instalação",
          "Jupyter Notebook: Interface",
          "Jupyter Notebook: Executando Códigos",
          "Etapa I: Coleta",
          "Etapa II: Análise Exploratória e Limpeza dos Dados (PARTE I)",
          "Etapa II: Análise Exploratória e Limpeza dos Dados (PARTE II)",
          "Etapa II: Análise Exploratória e Limpeza dos Dados (PARTE III)",
          "Etapa II: Análise Exploratória e Limpeza dos Dados (PARTE IV)",
          "Etapa III: Treinamento do Modelo",
          "Etapa IV: Teste do Modelo",
          "Etapa V: Otimização de Hiper-Parâmetros"
        ]
      },
      "requirements": [
        "Conhecimento básico de Python",
        "Muita vontade de aprender e de se destacar no mercado",
        "Você não precisa ser da área de exatas para realizar esse curso"
      ],
      "description": "COM PROJETO\nTEORIA E PRÁTICA COMBINADAS\n\n\nSOBRE O CURSO\nEsse NÃO é mais um curso complicado, sem explicações claras ou exemplos práticos para o mercado de trabalho.\n\n\nEsse curso É um jeito simples de você aprender Machine Learning em projetos de Classificação (Aprendizado Supervisionado), dos primeiros conceitos até os mais avançados.\n\n\nVocê não precisa ter experiência na área de Dados ou exatas para acompanhar todo o curso, que foi pensado com didática simples e módulos progressivos para você avançar com segurança! E para auxiliá-lo na evolução ao longo do curso, temos um projeto do início ao fim! Porém, é interessante que você tenha já um conhecimento básico em Python.\n\n\nComece hoje a explorar a área de Ciência de Dados com tranquilidade. Mesmo que já esteja na área, essa é a oportunidade para você melhorar suas habilidades com um conhecimento novo. Machine Learning traz MUITO VALOR para o negócio com análises preditivas, que preparam a empresa para o que pode ocorrer no futuro, diferentemente do BI tradicional que trabalha com análises descritivas sobre o passado.\n\n\nCada vez mais o mercado de trabalho exige de vários profissionais o conhecimento sobre Machine Learning! Aprenda a prever churn antes mesmo que eles aconteçam, para trazer mais valor ao negócio e trabalhando junto com equipes de Marketing e CX.\n\n\nAbaixo a trilha ideal em direção ao sucesso na área de dados:\nLinguagem SQL para Análise de Dados.\nCriação com Dashboards com Looker Studio.\nPython: Manipulação de Dados com Pandas.\nMachine Learning: Clusterização com Linguagem Python.\nMachine Learning: Classificação com Linguagem Python (esse que você está vendo).\nMachine Learning: Regressão com Linguagem Python.\n\n\nSOBRE O INSTRUTOR\nMe chamo Caio Avelino, e o conhecimento que vou dividir com você nesse curso foi adquirido, principalmente, com minha experiência no mercado de trabalho. Atuo nas áreas de Business Intelligence, Ciência de Dados e Inteligência Artificial há anos e tive a oportunidade de desenvolver minhas habilidades em diversas startups.\n\n\nAté mais!",
      "target_audience": [
        "Iniciantes e Curiosos sobre Machine Learning",
        "Alunos de Ciência de Dados que gostariam de aprender Classificação e Aprendizado Supervisionado",
        "Analistas de BI com interesse em utilizar Python para Machine Learning para se destacarem no mercado",
        "Qualquer pessoa, de qualquer área que deseja entrar no Mundo de Dados"
      ]
    },
    {
      "title": "Credit Score - Módulo 2: Boosting em python",
      "url": "https://www.udemy.com/course/formacao-data-science-boosting-com-python/",
      "bio": "Aumente o seu poder preditivo com este algoritmo",
      "objectives": [
        "boosting",
        "python",
        "machine learning",
        "credit score"
      ],
      "course_content": {
        "Introdução": [
          "Motivação",
          "Parte 1 - Adaboosting",
          "Parte 1 - Adaboosting - Prática",
          "Parte 1 - Gradient Boosting",
          "Parte 1 - Gradient Boosting - Prática",
          "Parte 1 - XG Boosting",
          "Parte 2 - XG Boosting - Prática 1",
          "Parte 2 - XG Boosting - Prática 2",
          "Parte 2 - XG Boosting - Prática 3",
          "Parte 2 - XG Boosting - Prática 4",
          "Parte 2 - XG Boosting - Prática 5",
          "Parte 2 - XG Boosting - Prática 6",
          "Parte 3 - Desafio - Revisão da amostragem",
          "Parte 3 - Desafio - Amostragem da Logística",
          "Parte 3 - Desafio Final"
        ]
      },
      "requirements": [
        "Python básico"
      ],
      "description": "Neste curso é apresentado a técnica de boosting.\nSão exploradas diferentes tipos de implementações como Adaboosting, Gradiente Boosting e XGBoosting.\nÉ realizada a construção de um credit score e a comparação da performance com o modelo de regressão logística.\nO conteúdo é pensado para ser construído de forma incremental em que o aluno é convidado a pensar sobre os fundamentos dos algoritmos e depois é apresentado para a prática.\nA prática é realizada em python, com o uso do Google Colab. Você não precisará instalar nada!\n\n\nIn machine learning, boosting is an ensemble meta-algorithm for primarily reducing bias, and also variance in supervised learning, and a family of machine learning algorithms that convert weak learners to strong ones. Boosting is based on the question posed by Kearns and Valiant (1988, 1989): \"Can a set of weak learners create a single strong learner?\" A weak learner is defined to be a classifier that is only slightly correlated with the true classification (it can label examples better than random guessing). In contrast, a strong learner is a classifier that is arbitrarily well-correlated with the true classification.\nRobert Schapire's affirmative answer in a 1990 paper to the question of Kearns and Valiant has had significant ramifications in machine learning and statistics, most notably leading to the development of boosting.\nWhen first introduced, the hypothesis boosting problem simply referred to the process of turning a weak learner into a strong learner. \"Informally, [the hypothesis boosting] problem asks whether an efficient learning algorithm […] that outputs a hypothesis whose performance is only slightly better than random guessing [i.e. a weak learner] implies the existence of an efficient algorithm that outputs a hypothesis of arbitrary accuracy [i.e. a strong learner].\" Algorithms that achieve hypothesis boosting quickly became simply known as \"boosting\". Freund and Schapire's arcing (Adapt[at]ive Resampling and Combining), as a general technique, is more or less synonymous with boosting.",
      "target_audience": [
        "Quem quer ganhar muito dinheiro se tornando cientistas de dados em instituições financeiras (bancos e outros)"
      ]
    },
    {
      "title": "Prédiction des séries temporelles en deep learning - Partie2",
      "url": "https://www.udemy.com/course/modeles-avances-des-series-temporelles-avec-keras-partie-2/",
      "bio": "Modèles avancés tirés de la recherche scientifique sous Keras/Tensorflow, Random Forest, optimisation d'hyperparamètres",
      "objectives": [
        "Comprendre et coder des modèles de prédiction avancés de séries temporelles issus de la recherche scientifique de ces dernières années sous Keras / Tensorflow",
        "Comprendre et utiliser la méthode des forêts aléatoires (Random Forest) pour les prédictions et pour sélectionner les variables exogènes les plus importantes",
        "Optimiser les hyperparamètres des modèles avec la librairie Raytune, utiliser ses algorithmes de recherche Bayesiens ainsi que ses algorithmes de planification",
        "Utiliser l'algorithme VSURF afin d'extraire les variables les plus importantes d'une série exogène avec R",
        "Utiliser un serveur dédié sous Google Cloud pour mettre en place l'application R-Studio permettant d'exécuter des programmes R",
        "Utiliser un algorithme de compensation des erreurs à base de correcteur PID (Proportionnel Intégral Dérivé)"
      ],
      "course_content": {
        "Modèle multivarié multi-step à attention spatio-temporelle - DSTP-RNN": [
          "Le modèle DSTP-RNN",
          "Chargement des données et création des datasets",
          "Création de l'encodeur à deux phases",
          "Création du décodeur et du modèle global",
          "Prédictions single-step",
          "Comparaisons des modèles DA-RNN et DSTP",
          "Prédiction multi-step",
          "Le modèle DSTPII-RNN",
          "Prédictions avec le modèle DSTPII en single-step",
          "Prédictions avec le modèle DSTPII en multi-step"
        ],
        "Un autre modèle à Attention Spatio-temporelle amélioré - Modèle HRHN": [
          "Améliorer les réseaux récurrents avec les Recurrent Highway Networks (RHN)",
          "Structure des RHN",
          "Codage d'un réseau RHN",
          "Le dropout variationnel",
          "Codage du dropout variationnel dans la structure RHN",
          "Tests sur les RHN",
          "Le modèle HRHN",
          "Codage du réseau de convolution de l'encodeur",
          "Ajout de l'encodeur RHN",
          "Codage du décodeur HRHN",
          "Prédictions single-step avec le modèle HRHN",
          "Prédictions multi-step avec le modèle HRHN"
        ],
        "Compensation des erreurs résiduelles par régulation PID": [
          "Les correcteurs PID (Proportionnel Integral Dérivé)",
          "Structure du modèle à base de correcteur PID",
          "Mise en place du prédicteur autoregressif VAR avec le modèle HRHN Multistep",
          "Mise en place du correcteur PID avec le modèle HRHN Multistep",
          "Mise en place de la structure globale HRHN-VAR-PID",
          "Prédictions avec le modèle HRHN-VAR-PID",
          "Prédictions avec le modèle DSTPII-VAR-PID"
        ],
        "Optimisation Bayesienne des hyperparamètres avec RayTune": [
          "Petite introduction à Raytune",
          "Création du modèle DSTP et définition des hyperparamètres de Raytune",
          "Définition des callbacks de Keras",
          "Définition de la fonction d'entrainement de Raytune",
          "Synchronisation des enregistrements avec Google Drive",
          "Lancement de l'optimisation Bayesienne et suivi avec Tensorboard",
          "Optimisation du modèle HRHN sous Raytune",
          "Résultats d'optimisation du modèle DSTP",
          "Résultats d'optimisation du modèle HRHN"
        ],
        "Méthode des forêts aléatoires (Random Forest)": [
          "Introduction",
          "Arbres de décision - Classification",
          "Arbres de décision - Régression",
          "Construction automatique des arbres en régression",
          "Construction automatique des arbres en classification",
          "Bootsrap aggregating (bagging) en régression",
          "Bootsrap aggregating (bagging) en classification",
          "Retour sur les hypothèses du bagging",
          "Méthode des forets aléatoires",
          "Importance des variables"
        ],
        "Sélection des variables et prédictions avec l'algorithme Random Forest": [
          "Objectif",
          "Etude des corrélations entre les variables exogènes",
          "Choix du nombre d'arbres",
          "Sélection des variables par importance de Gini",
          "Sélection des variables par importance des permutations",
          "Sélection des variables avec la méthode RFE (Recursive Feature Elimination)",
          "Sélection des variables avec l'algorithme VSURF",
          "Analyse des résultats obtenus avec VSURF",
          "Utiliser VSURF sur un serveur dédié Google Cloud",
          "Prédictions avec le modèle DSTP en utilisant les résultats de prédiction de",
          "Prédictions avec le modèle DSTP en utilisant les résultats d'interprétation",
          "Prédictions avec l'algorithme de random forest",
          "Petite introduction à Raytune",
          "Création du modèle DSTP et définition des hyperparamètres de Raytune",
          "Définition des callbacks de Keras",
          "Définition de la fonction d'entrainement de Raytune",
          "Synchronisation des enregistrements avec Google Drive",
          "Lancement de l'optimisation Bayesienne et suivi avec Tensorboard",
          "Optimisation du modèle HRHN sous Raytune",
          "Résultats d'optimisation du modèle DSTP",
          "Résultats d'optimisation du modèle HRHN"
        ],
        "Un modèle causal multivarié de type Seq-2-Seq - Le modèle STAM": [
          "Modèle STAM",
          "Codage de la couche de création des motifs spatiaux",
          "Codage de la couche de création des motifs temporels",
          "Codage des encodeurs spatiaux et temporels",
          "Codage des décodeurs spatiaux et temporels",
          "Création de la couche STAM",
          "Prédictions en single step",
          "Prédictions en multi-step",
          "Extraction de l'importance des variables"
        ],
        "Utilisation du modèle Wavenet de Google pour la prédiction de séries temporels": [
          "Le modèle WaveNet",
          "Le modèle WaveNet pour la prédiction de séries temporelles",
          "Chargement des données de la série chaotique de l'attracteur de Lorenz",
          "Construction du modèle Wavenet univarié à prédiction simple pas",
          "Prédictions univariés simple pas",
          "Construction du modèle Wavenet univarié à prédiction multi pas",
          "Prédictions univariés multi pas",
          "Construction du modèle Wavenet multivarié à prédiction multi pas",
          "Prédictions multivariées simple pas",
          "Prédictions multivariées multi pas",
          "Prédictions multivariées simple pas de la série SML2010",
          "Prédictions multivariées multi pas de la série SML2010"
        ]
      },
      "requirements": [
        "Bonnes connaissances en Python",
        "Avoir accès aux TPU sous Google Colab",
        "Bonnes connaissances de Keras / Tensorflow"
      ],
      "description": "Pour aller encore plus loin que dans ma formation \"Prédiction des séries temporelles en deep learning - Partie1\" où vous avez travaillé sur le modèle DA-RNN, vous allez découvrir dans cette formation de nouveaux modèles plus complexes (DSTP-RNN, HRHN, STAM, Wavenet).\nIls sont issus de la recherche scientifique de ces dernières années et sont dédiés à la prédiction des séries temporelles avec le deep learning sous Python. Nous utiliserons les librairies telles que Tensorflow, Keras, Pandas, Numpy, Scikit learn pour les coder et nous les optimiserons avec la librairie Raytune.\nLes travaux sont accessibles et exploitables en ligne grâce à l'utilisation des carnets Jupyter avec Google Colab. Aucune installation de logiciel spécifique sur son ordinateur n'est requise car tout le travail se fait en ligne.\nA chaque étape d'apprentissage de ce cours, de nouveaux concepts sont introduits. Des explications claires permettent de bien les comprendre à travers 9 thèmes d'étude :\nLe modèle DSTP-RNN est un modèle de type Seq2Seq multivarié, évolution majeure du modèle DA-RNN\nLe modèle HRHN utilise des réseaux récurrents spécifiques de type RHN (Recurrent Highway Network) et des couches de convolutions 1D.\nLa méthode de compensation des erreurs à base de correcteur PID (Proportionnel Intégral Dérivé)\nLa librairie Raytune permet d'optimiser les hyperparamètres des modèles. Elle propose par exemple des algorithmes d'optimisation Bayesiens et différents planificateurs.\nLa méthode des forets aléatoires (Random Forest) est un algorithme puissant du deep learning pour faire de la régression et de la classification.\nL'algorithme Random Forest permet également de sélectionner les variables les plus importantes contenues dans une série multivariée.\nUtiliser la librairie VSURF sous R, spécifiquement conçu pour l'identification de l'importance des variables, sur un serveur dédié Google Cloud.\nLe modèle STAM a la particularité d'être causal et évolutif, ce qui permet un meilleur suivi de l'importance des variables des séries multivariées.\nLe modèle Wavenet de Google, qui est dédié à la génération de signaux audio, est également très utilisé dans la prédiction de séries temporelles.\nLes activités en Python expliquent clairement comment les exploiter. D'une durée totale de plus de 9h, ce cours vous permettra d'être à l'aise dans l'utilisation avancée de Keras et Tensorflow pour coder vos propres couches et modèles, à partir de classes héritées. Les thèmes d'étude s'appuient sur des documents issus de la recherche scientifique et proposent des concepts importants qui ont été développés ces dernières années.\n=== Prérequis ===\nCe cours fait suite à la première partie de ma formation sur l'utilisation de modèles avancés dédiés à la prédiction des séries temporelles (Prédiction des séries temporelles en deep learning - Partie1).\nSi vous avez déjà une expérience en Deep Learning, vous découvrirez certainement de nouveaux thèmes d'étude qui vous permettront d'élargir vos compétences.\n== Aide en ligne ===\nQuelque soit votre niveau, je suis disponible pour vous aider dans votre progression. Vous pourrez éventuellement rencontrer des difficultés en Mathématiques ou en programmation car il est bien évident que vous avez tous un bagage différent en fonction de votre parcours (études ou professionnel).\nDans ce sens, il ne faudra surtout pas hésiter à me poser vos questions et je m'engage à y répondre dans un délai raisonnable. Votre motivation est essentielle pour réussir cette formation.\n\n\n=== Thèmes étudiés dans la formation ===\n#1. Le modèle DSTP-RNN est un modèle de type Seq2Seq multivarié, évolution majeure du modèle DA-RNN\nL'inconvénient majeur du modèle DA-RNN est qu'il utilise des informations actuelles des séries exogènes pour réaliser ses prédictions. Le modèle DSTP-RNN est un modèle à attention spatio-temporelle qui améliore grandement l'architecture du modèle DA-RNN pour palier ce problème et augmenter ses performances.\n\n\n#2. Le modèle HRHN utilise des réseaux récurrents spécifiques de type RHN (Recurrent Highway Network) et des couches de convolutions 1D.\nPour augmenter les performances des réseaux neuronaux, on empile plusieurs couches afin de créer des réseaux profonds. Mais des problèmes de convergence lors de l'entrainement apparaissent. C'est la raison pour laquelle l'architecture Highway Network a été crée.\nLe réseau HRHN va plus loin en intégrant l'architecture Highway Network aux réseaux récurrents : ce sont les réseaux RHN (Recurrent Highway Networks).\nLe modèle HRHN est un modèle qui utilise ces nouveaux réseaux récurrents. De plus, il utilise des couches de convolutions CNN 1D pour l'attention spatiale.\n\n\n#3. La méthode de compensation des erreurs à base de correcteur PID (Proportionnel Intégral Dérivé)\nLe régulateur PID, appelé aussi correcteur PID (proportionnel, intégral, dérivé) est un système de contrôle permettant d’améliorer les performances d'un asservissement, c'est-à-dire un système ou procédé en boucle fermée. C’est le régulateur le plus utilisé dans l’industrie où ses qualités de correction s'appliquent à de multiples grandeurs physiques.\nAprès avoir étudié en quoi ce type de correcteur se démarque de ses versions plus allégées, nous le mettrons en place dans les modèles DSTP-RNN et HRHN. Nous verrons qu'il permet d'augmenter les performances de nos modèles.\n\n\n#4. La librairie Raytune permet d'optimiser les hyperparamètres des modèles.\nL'optimisation des hyperparamètres est une opération essentielle dans l'élaboration d'un modèle car elle permet d'augmenter la précision des prédictions. Malheureusement, c'est un travail qui devient impossible à réaliser manuellement lorsque la complexité des modèles augmente. L'optimisation par Grid Search, souvent considérée comme une première approche, n'est pas non plus applicable dans ces cas car trop chronophage.\nLa librairie Raytune propose des algorithmes d'optimisation beaucoup plus performants qu'un simple Grid Search, tels que Hyperband, ASHA, PBT. Elle permet également d'intégrer des algorithmes externes tels qu'HyperOpt et l'optimisation Bayesienne.\nNous mettrons en œuvre cet outil afin d'optimiser les hyperparamètres de nos modèles et nous utiliserons Tensorboard pour suivre leurs évolutions. Nous verrons également comment synchroniser les données avec Google Drive.\n\n\n#5. La méthode des forêts aléatoires (Random Forest).\nL’algorithme des « forêts aléatoires » a été proposé par Leo Breiman et Adèle Cutler en 2001. Dans sa formule la plus classique, il effectue un apprentissage en parallèle sur de multiples arbres de décision construits aléatoirement et entraînés sur des sous-ensembles de données différents.\nC’est un algorithme particulièrement performant pour les problématiques de prédiction. En particulier vous pouvez les utiliser quand vous avez un nombre de variables exogènes important.\nAprès avoir étudié le fonctionnement de cet algorithme, vous serez capable de le paramétrer en fonction de vos besoins.\n\n\n#6. L'algorithme Random Forest pour sélectionner les variables les plus importantes contenues dans une série multivariée.\nLorsque les données à traiter sont trop nombreuses (par exemple si on s'intéresse à la recherche de gènes impliqués dans certaines maladies), les temps de calculs sont beaucoup trop long et il est nécessaire de trier les variables à utiliser par ordre d'importance pour réduire leur nombre.\nDe par sa structure, l'algorithme Random Forest est souvent utilisé pour sélectionner les variables les plus importantes. Nous utiliserons plusieurs techniques pour réaliser cette opération, comme la méthode RFE (Recursive Feature Selection)\n\n\n#7. Utiliser l'algorithme VSURF sous R, spécifiquement conçu pour l'identification de l'importance des variables, sur un serveur dédié Google Cloud.\nVSURF est une librairie sous R dédiée à la sélection de variables à l'aide de forêts aléatoires. Cet algorithme fournit deux sous-ensembles de variables associé a deux objectifs de sélection de variables pour des problèmes de régression et de classification. Le premier est un sous-ensemble de variables importantes pour l'interprétation. Le second est un sous-ensemble parcimonieux a l'aide duquel on peut faire de bonnes prédictions.\nLa stratégie générale est basée sur un classement préliminaire des variables donné par l'indice d'importance des forêts aléatoires, puis utilise un algorithme d'introductions ascendantes de variables pas a pas. Les deux sous-ensembles peuvent être obtenus automatiquement en gardant le comportement par défaut du package, mais peuvent également être réglés en jouant sur plusieurs paramètres.\nNous verrons comment mettre en place un serveur dédié Google Cloud avec R-Studio afin d'utiliser cette librairie pour effectuer des calculs en parallèles sur des ordinateurs puissants.\n\n\n#8. Le modèle STAM : Un modèle causal et évolutif\nLe modèle STAM est un des derniers modèles à base d'attention spatio-temporelle qui date de 2020. Il a la particularité d'être causal et évolutif.\nNous coderons ce modèle et nous verrons que ses spécificités permettent d'obtenir des informations fiables afin de sélectionner les variables.\n\n\n#9. Le modèle Wavenet de Google.\nWaveNet est un réseau neuronal profond pour générer de l'audio brut. Il a été créé par des chercheurs de la société d'intelligence artificielle basée à Londres DeepMind.\nPlusieurs recherches scientifiques se sont intéressées à l'utilisation de ce modèle dans le domaine de la prédiction des séries temporelles avec des résultats très concluants.\nAprès avoir étudié le fonctionnement du modèle Wavenet dans sa version originale, nous verrons les adaptations qui sont proposées pour l'utiliser dans la prédiction des séries temporelles. Nous coderons ensuite son architecture afin de réaliser des prédictions sur nos séries.",
      "target_audience": [
        "Etudiants ou professionnels souhaitant approfondir leurs connaissances dans le domaine de la prédiction des séries temporelles à l'aide du deep learning."
      ]
    },
    {
      "title": "PENTAHO PDI e APACHE HOP: pipeline e tratamento em dados",
      "url": "https://www.udemy.com/course/pentaho-pdi-e-apache-hop-pipeline-e-tratamento-em-dados/",
      "bio": "Construa pipelines e cargas de dados mais avançadas com as duas principais ferramentas do mercado",
      "objectives": [
        "PENTAHO PDI: O que é o Pentaho PDI",
        "PENTAHO PDI: Entendendo sobre fluxos de trabalho e pipelines",
        "PENTAHO PDI: Entendendo sobre projetos e ambientes",
        "PENTAHO PDI: Instalando o Pentaho PDI",
        "PENTAHO PDI: Criando pipelines com arquivos texto",
        "PENTAHO PDI: Realizando tratamento de dados para entendimento do processo de engenharia de dados",
        "PENTAHO PDI: O que são transformações, Jobs e ações dentro de um pipeline",
        "PENTAHO PDI: Construindo um workflow com Jobs, orquestrador da sequência das operações",
        "PENTAHO PDI: Entendendo os menus principais e o seu GUI e seus componentes",
        "PENTAHO PDI: Comp. pipelines: Sort, Select value, CSV file input, Value mapper, Filter rows, Dummy, Unique rows, Merge Join, Text File Output, Row Normaliser",
        "PENTAHO PDI: Entendendo como podem ser depurados os dados via output, logs",
        "PENTAHO PDI: Number Range, Concat Field, String Operations, Replace in String, IF Field Value is Null, Split Fields, CSV File Input, Mail, File Exist",
        "PENTAHO PDI: Leitura de dados em uma API: Rest Client, JSON Input, JSON Output",
        "PENTAHO PDI: Construindo Workflow com execução de pipelines",
        "PENTAHO PDI: Entendo o uso de variáveis globais no PENTAHO PDI",
        "PENTAHO PDI: Automatização de pipeline ou workflow",
        "PENTAHO PDI: Construindo pipelines em banco de dados Postgresql: Table Input, Table Output, Configurando conexão",
        "PENTAHO PDI: Instalação de banco de dados Postgresql, uso do PGAdmin",
        "PENTAHO PDI: Automatização de JOBs e Transformações com o Kitchen e Pan",
        "PENTAHO PDI: Construção do projeto de dados a sua escolha e correção com o uso do Pentaho PDI",
        "APACHE HOP: O que é  Hop Orchestration Platform",
        "APACHE HOP: Entendendo sobre fluxos de trabalho e pipelines",
        "APACHE HOP: Entendendo sobre projetos e ambientes",
        "APACHE HOP: Instalação do APACHE HOP",
        "APACHE HOP: Criando pipelines com arquivos texto",
        "APACHE HOP: Realizando tratamento de dados para entendimento do processo de engenharia de dados",
        "APACHE HOP: O que são transformações, links e ações dentro de um pipeline",
        "APACHE HOP: APACHE HOP: Construindo um workflow, orquestrador da sequência das operações",
        "APACHE HOP: Entendendo o HOP GUI e seus componentes",
        "APACHE HOP: Entendendo menu barras, principal e perspectivas",
        "APACHE HOP: Criando sua área de projetos",
        "APACHE HOP: Componentes pipelines: Sort, Select value, CSV file input, Value mapper, Filter rows, Dummy, Unique rows, Merge Join, Text File Output",
        "APACHE HOP: Entendendo o que é : View output, Preview output , Debug output",
        "APACHE HOP: Number Range, Concat Field, String Operations, Replace in String, IF Field Value is Null, Split Fields, CSV File Input, Mail, File Exist",
        "APACHE HOP: Leitura de dados em uma API: Rest Client, JSON Input, JSON Output",
        "APACHE HOP: Construindo Workflow com execução de pipelines",
        "APACHE HOP: Entendo o uso de variáveis globais no APACHE HOP",
        "APACHE HOP: Automatização de pipeline ou workflow pelo HOP-RUN",
        "APACHE HOP: Construindo pipelines em banco de dados Postgresql: Table Input, Table Output, Configurando conexão",
        "APACHE HOP: Instalação de banco de dados Postgresql, usando PGAdmin"
      ],
      "course_content": {
        "PENTAHO PDI: ETL-Integração e Ingestão de dados": [
          "Apresentação sobre o Pentaho PDI",
          "INFORMAÇÕES IMPORTANTES - Leia antes de começar o curso",
          "Introdução ao Pentaho PDI",
          "Instalação do JAVA",
          "Site de instalação do PDI",
          "Instalação do Pentaho PDI",
          "Entendo como funciona a área de trabalho",
          "Pipeline de Tratamento: arquivo vinhos",
          "Pipeline de tratamento: filtragem e gravação de arquivo ajustado- arquivo vinhos",
          "Pipeline de tratamento: seleção de atributos - arquivos vinhos",
          "Pipeline de tratamento: ordenação, agrupamento - arquivos vinhos",
          "Aula extra - 01 - Leitura de arquivo sem cabeçalho e sem delimitador",
          "Pipeline Merge dos dados: leitura arquivos de entrada e sort dados - 4 arquivos",
          "Pipeline Merge dos dados: componente merge e sort dados - 4 arquivos",
          "Pipeline Merge dos dados: seleção de campos e gravação arquivo - 4 arquivos",
          "Aula extra - 02 - Tratamento e leitura de arquivo colunar",
          "Pipeline Tratamento de dados: arquivo cliente veículos e replace dados",
          "Pipeline Tratamento de dados: operação string, categorias e componente IF null",
          "Pipeline Tratamento de dados: componentes cut e split fields",
          "Pipeline Tratamento de dados: componente number range e concat fileds",
          "Utilizando Debug do PDI dentro de um pipeline",
          "Tratando dados em um Pipeline lendo WebService",
          "Construindo JOB - encadeamento de pipelines",
          "Instalação do Postgres",
          "Carregado dados tabela AUTOR e gerando novos dados tabela NOVO_TB_AUTOR",
          "Aula extra - 03 - Criando JOB para movimentação de arquivos e pastas",
          "Automatizando Jobs e Transformações - Kitchen e Pan",
          "Aula Final - Construa o seu projeto de dados",
          "Responda a pergunta"
        ],
        "APACHE HOP - Integração e Ingestão de dados": [
          "Entendendo o funcionamento e componentes",
          "Instalação do JAVA",
          "Instalação do APACHE HOP",
          "Configuração extra e iniciando APACHE HOP",
          "Criando projeto e ambiente, primeiros passos",
          "Pipeline de Tratamento: arquivo vinhos",
          "Pipeline de tratamento: filtragem e seleção de atributos - arquivos vinhos",
          "Pipeline de tratamento: sort e group by atributos - arquivos vinhos",
          "Pipeline de tratamento: gerando arquivo de saída totalizador - arquivos vinhos",
          "Pipeline Merge dos dados: Leitura arquivos de entrada",
          "Pipeline Merge dos dados: Sort arquivos de entrada",
          "Pipeline Merge dos dados: Merge arquivos venda e cliente",
          "Pipeline Merge dos dados: Merge arquivos venda com produto e marca",
          "Pipeline Merge dos dados: geração arquivo venda final tratado",
          "Pipeline Tratamento de dados: Arquivo cliente veículos e strings diversos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e ajustes campo hora",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e retirada valores nulos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e junção de atributos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e geração grupos de dados",
          "Pipeline Carga API: Leitura dados CEP e uso de REST GET",
          "Pipeline Carga API: Leitura e armazenamento arquivo JSON",
          "Pipeline Carga API: Tratamento dos dados escolha campos e gravação arquivo texto",
          "Workflow de execução: Parte01",
          "Workflow de execução: Parte02",
          "Banco de dados: Instalação do Postgresql",
          "Banco de dados: Pipeline de tratamento de dados no Postgresql",
          "HOP-RUN: Automatização de pipeline e workflow",
          "Aula Final - Entrega de atividades"
        ]
      },
      "requirements": [
        "Importante ter conhecimento sobre banco de dados, arquivos de dados",
        "Importante que você conheça lógica de programação"
      ],
      "description": "Chegou o momento de você estudar duas grandes ferramentas do mercado do mundo open source e que fazem diferença nas empresas. Posso afirmar que o Apache Hop e o Pentaho PDI são duas das ferramentas mais importantes que um profissional de dados deve dominar. Essas duas plataformas oferecem um conjunto completo de recursos para gerenciar, transformar e integrar dados de várias fontes, tornando-as cruciais para qualquer projeto de análise de dados.\nO Apache Hop é uma ferramenta de ETL (Extração, Transformação e Carga) de código aberto, que permite criar pipelines de dados complexos e escaláveis. Com o Hop, os engenheiros de dados podem automatizar o processo de coleta de dados, limpeza, transformação e carregamento em um sistema de armazenamento de dados. O Hop suporta diversas fontes de dados, incluindo bancos de dados, arquivos de texto, planilhas e muito mais, e permite que os usuários criem fluxos de trabalho de ETL com pouca ou nenhuma codificação.\nJá o Pentaho PDI é uma plataforma de integração de dados que oferece recursos de ETL, gerenciamento de metadados, geração de relatórios e análise de dados. Com o PDI, os usuários podem conectar-se a diversas fontes de dados, como bancos de dados, APIs, serviços da web e arquivos, e transformá-los em informações úteis. O PDI oferece recursos de análise de dados, como visualizações gráficas e dashboards interativos, tornando-se uma ferramenta valiosa para profissionais que precisam apresentar seus resultados de maneira clara e fácil de entender.\nAmbas as ferramentas oferecem vantagens únicas para projetos de dados. Ambas as plataformas oferecem uma interface amigável e recursos de automação, permitindo que os usuários criem fluxos de trabalho complexos com facilidade.\nDominar o Apache Hop e o Pentaho PDI é essencial para a carreira de um engenheiro de dados. As habilidades em ETL e integração de dados são cada vez mais importantes para profissionais de dados em todas as áreas, desde análise de dados até inteligência artificial e aprendizado de máquina.\nNo geral, a capacidade de criar fluxos de trabalho de ETL eficientes e integrar dados de várias fontes é fundamental para qualquer projeto de dados bem-sucedido. Com o nosso treinamento, agora é possível dominar essas ferramentas em seu próprio ritmo, e com a ajuda minha ajuda bem de perto.\nInscreva-se agora e prepare-se para levar sua carreira em dados para o próximo nível!",
      "target_audience": [
        "Estudantes e profissionais de computação, Informática, estatística, data science, analista de dados, engenheiro de dados",
        "Pessoas interessadas em aprender os conceitos sobre ferramentas de ingestão de dados, ou que gostariam adentrar na área de engenharia de dados",
        "Profissionais que, de alguma forma, utilizam dados no seu dia a dia"
      ]
    },
    {
      "title": "[TR] DeepSeek R1 AI: Yeni başlayanlar için 25 AI projesi",
      "url": "https://www.udemy.com/course/deepseek-turkish/",
      "bio": "DeepSeek ile Uygulamalı AI: Sıfırdan 25 gerçek NLP ve otomasyon projesi geliştir",
      "objectives": [
        "Özetleyici gibi yapay zekâ metin araçları geliştir.",
        "NLP tekniklerini gerçek uygulamalarda kullan.",
        "DeepSeek AI’yi yerel olarak kur ve yapılandır.",
        "Farklı alanlara yönelik akıllı sohbet botları geliştir.",
        "DeepSeek AI modelleriyle görevleri otomatikleştir.",
        "Yapay zekâ destekli içerik ve rapor üret.",
        "Yapay zekâ kod asistanları ve hata ayıklayıcılar oluştur.",
        "Performans için DeepSeek AI modellerini optimize et.",
        "Yapay zekâ ile öneri sistemleri geliştir.",
        "Bulut kullanmadan pratik yapay zekâ uygulamaları kur."
      ],
      "course_content": {
        "Uygulamalı DeepSeek AI’ye Giriş: AI Geliştiricileri için 25 Pratik Proje": [
          "Kursa Hoş Geldiniz – Genel Bakış, Hedefler ve Ön Koşullar",
          "DeepSeek AI Kurulumu – Yükleme, yapılandırma ve ilk test çalıştırması",
          "Hızlı Python Eğitimi: Sıfırdan Python Öğrenin"
        ],
        "AI ile Metin İşleme ve Doğal Dil İşleme (NLP)": [
          "Proje 1: DeepSeek AI ile Metin Özetleyici",
          "Proje 2: DeepSeek AI ile Metin Üretimi",
          "Proje 3: DeepSeek AI ile Dil Bilgisi ve Yazım Denetleyici",
          "Proje 4: DeepSeek AI ile Varlık Tanıma (NER) Aracı",
          "Proje 5: DeepSeek AI ile Duygu Analizi"
        ],
        "Sohbet Botları ve Sanal Asistanlar": [
          "Proje 6: DeepSeek AI ile Müşteri Destek Chatbot'u",
          "Proje 7: DeepSeek AI ile Kişisel AI Asistanı",
          "Proje 8: DeepSeek AI ile Hukuki Asistan",
          "Proje 9: DeepSeek AI ile Tıbbi Belirti Kontrol Aracı",
          "Proje 10: DeepSeek AI ile E-ticaret Ürün Öneri Botu"
        ],
        "Otomasyon ve Verimlilik için Yapay Zekâ": [
          "Proje 11: DeepSeek AI ile Otomatik E-posta Yanıtlayıcı",
          "Proje 12: DeepSeek AI ile Özgeçmiş (CV) Oluşturucu",
          "Proje 13: DeepSeek AI ile Toplantı Notu Oluşturucu",
          "Proje 14: DeepSeek AI ile Otomatik PDF Metin Ayıklayıcı",
          "Proje 15: DeepSeek AI ile İçerik Yazarı AI"
        ],
        "Geliştiriciler ve Kodlama için AI": [
          "Proje 16: DeepSeek AI ile Kod Otomatik Tamamlayıcı ve Asistan",
          "Proje 17: DeepSeek AI ile SQL Sorgu Üreticisi",
          "Proje 18: DeepSeek AI ile Kod Hata Ayıklayıcı",
          "Proje 19: DeepSeek AI ile Belgeler Oluşturucu",
          "Proje 20: DeepSeek AI ile API Test Aracı"
        ],
        "İş Dünyası ve Veri Analizi için AI": [
          "Proje 21: DeepSeek AI ile Müşteri Geri Bildirimi Analizi",
          "Proje 22: DeepSeek AI ile Gerçek Zamanlı Haber Özetleyici",
          "Proje 23: DeepSeek AI ile Finansal Rapor Analiz Aracı",
          "Proje 24: DeepSeek AI ile İş Başvurusu Eleme Aracı",
          "Proje 25: DeepSeek AI ile Akademik Makale Özetleyici"
        ]
      },
      "requirements": [
        "Komut satırı araçlarına aşinalık (temel terminal kullanımı).",
        "DeepSeek AI modellerini çalıştırmak için en az 8GB RAM’e sahip bir bilgisayar.",
        "Kurulmuş bir Python ortamı (kurulumu birlikte yapacağız).",
        "Makine öğrenmesi veya NLP deneyimi (zorunlu değil ama faydalı).",
        "Yapay zekâ destekli otomasyon ve sohbet botlarına ilgi.",
        "Bulut hizmetlerine gerek yok—her şey yerel olarak çalışıyor!",
        "Gerçek dünya AI uygulamaları oluşturma isteği.",
        "AI araçlarını denemeye ve keşfetmeye istekli olma.",
        "Bir kod düzenleyicisine erişim (VS Code, PyCharm veya Jupyter Notebook)."
      ],
      "description": "Bu kurs, yapay zeka tarafından İngilizceden Türkçeye çevrilmiştir, böylece son teknolojileri kendi ana dilinizde öğrenebilirsiniz.\n\nDeepSeek AI'nin Gücünü Keşfedin: 25 Uygulamalı Proje ile Yapay Zeka Geliştirme\nDeepSeek AI kullanarak gerçek dünya yapay zeka uygulamaları geliştirmeye hazır mısınız? Bu kurs, sizi başlangıç seviyesinden ileri düzeye taşıyacak şekilde tasarlanmıştır. Doğal Dil İşleme (NLP), sohbet botları, otomasyon ve yapay zeka destekli uygulamalara odaklanır—üstelik bulut servislerine ihtiyaç duymadan!\nDeepSeek AI, açık kaynaklı ve güçlü bir yapay zeka modelidir. Geliştiricilere, ileri düzey otomasyon, metin üretimi ve NLP görevlerini yerel olarak gerçekleştirme olanağı sunar. Bu kursta, 25 gerçek dünya projesi geliştirerek iş, verimlilik, otomasyon ve yazılım geliştirme alanlarında uygulamalı deneyim kazanacaksınız.\nBu Kursta Neler Öğreneceksiniz?\nKurs sonunda şunları yapabileceksiniz:\nDeepSeek AI'yi yerel bilgisayarınıza kurmak ve yapılandırmak.\nÖzetleme, dil bilgisi düzeltme, duygu analizi gibi metin işleme uygulamaları geliştirmek.\nMüşteri hizmetleri, e-ticaret ve kişisel verimlilik için akıllı sohbet botları ve sanal asistanlar oluşturmak.\nE-posta yazma, özgeçmiş oluşturma, belge özetleme gibi günlük görevleri yapay zekayla otomatikleştirmek.\nKod tamamlama, hata ayıklama, SQL üretimi gibi yapay zekâ tabanlı yazılım araçlarını uygulamak.\nModelleri yerel çalışma için optimize ederek performans artırmak.\nFinansal analiz, iş başvurusu eleme ve müşteri geri bildirimi gibi iş senaryoları için uygulamalar geliştirmek.\nPython ile NLP ve yapay zekâ destekli otomasyon konusunda uygulamalı deneyim kazanmak.\nBulut tabanlı API’lere ihtiyaç duymadan gerçek projeler üzerinde çalışmak.\nBu Kurs Kimler İçin Uygun?\nKurs şu kişiler için idealdir:\nUygulamalarına yapay zeka eklemek isteyen Python geliştiricileri.\nNLP ve yapay zekâya yeni başlayanlar ve uygulamalı deneyim kazanmak isteyenler.\nMetin işleme üzerine yapay zekâ modellerini araştıran veri bilimcileri.\nYapay zeka destekli otomasyon araçları geliştirmek isteyen teknoloji profesyonelleri.\nYapay zeka odaklı ürünler geliştiren girişimciler ve startup kurucuları.\nBulut hizmetlerine bağlı kalmadan projeler geliştiren öğrenciler ve araştırmacılar.\nKurs Proje Özeti\nBu kurs aşağıdaki alanlarda 25 uygulamalı proje içerir:\nYapay Zekâ ile Metin İşleme – Özetleme, duygu analizi ve metin üretimi.\nSohbet Botları ve Sanal Asistanlar – Akıllı asistanlar geliştirme.\nOtomasyon – E-posta yanıtlayıcıları, CV oluşturucular, iş akışı otomasyonu.\nGeliştiriciler için AI – Kod tamamlama, hata ayıklama, API test araçları.\nİş ve Verimlilik için AI – Finansal analiz, aday eleme, müşteri geri bildirimleri.\nBu Kurs Neden Alınmalı?\nGerçek projelerle uygulamalı yapay zeka deneyimi kazanırsınız.\nBulut bağımlılığı yok – her şey yerel çalışır!\nAdım adım anlatım ve tam kod örnekleriyle ilerlenir.\nNLP, otomasyon, sohbet botları ve daha fazlasını kapsar.\nGeliştiriciler, öğrenciler ve yapay zeka meraklıları için mükemmel.\nYapay Zeka Destekli Uygulamalar Geliştirmeye Bugün Başlayın!\nHemen katılın ve DeepSeek AI’nin gücünü 25 pratik, gerçek dünya projesiyle açığa çıkarın!",
      "target_audience": [
        "Uygulamalarına yapay zekâ entegre etmek isteyen Python geliştiricileri.",
        "NLP ve otomasyonla pratik deneyim kazanmak isteyen AI ve ML yeni başlayanları.",
        "Metin işleme ve sohbet botları için DeepSeek AI’yi keşfeden veri bilimcileri.",
        "Yapay zekâ destekli ürünler geliştiren girişimciler ve startup kurucuları.",
        "AI ile iş akışlarını kolaylaştırmak isteyen otomasyon meraklıları.",
        "AI tabanlı araçlarla denemeler yapan öğrenciler ve araştırmacılar.",
        "AI tabanlı otomasyonda yeteneklerini geliştirmek isteyen teknoloji uzmanları.",
        "Yeni AI uygulamalarını keşfetmeye istekli bireysel öğreniciler ve meraklılar."
      ]
    },
    {
      "title": "【한글자막】 스파크 스트리밍과 Scala 로 빅 데이터 스트리밍하기 (실전편)",
      "url": "https://www.udemy.com/course/best-scala/",
      "bio": "실시간으로 구조화된 스파크 스트리밍, 카프카 통합 및 실시간 스트리밍 빅 데이터를 다루는 스파크 스트리밍 튜토리얼",
      "objectives": [
        "스파크스트리밍을 사용하여 실시간 대용량 데이터를 스트림 처리합니다",
        "카프카, 플룸, 키네시스와 같은 데이터 소스를 스파크스트리밍을 이용하여 통합합니다",
        "구조화된 스파크 2의 스트리밍 응용 프로그램 인터페이스를 사용합니다",
        "스칼라 프로그래밍 언어를 사용하여 스파크 응용 프로그램을 만듭니다",
        "출력된 결과는 실시간 데이터를 카산드라 또는 파일 시스템으로 변환시킨 것을 배웁니다",
        "스파크 스트리밍을 스파크 구조화 질의어와 통합하여 실시간으로 스트리밍 데이터를 질문합니다",
        "스트리밍 데이터를 사용하여 실시간 교육에 사용하고 머신러닝 모델을 가르쳐서 실시간 예측에 이용합니다",
        "아파치 로그 액세스 데이터를 수집하고 스트림을 변환합니다",
        "실시간 트위터 피드 스트림을 수용합니다",
        "연속적인 입력 데이터 스트림을 거쳐 네트워크 연결 상태를 추적할 수 있는 데이터를 유지합니다",
        "윈도우 시간 경과에 따른 스트리밍 데이터를 질문합니다"
      ],
      "course_content": {
        "시작하기": [
          "팁: 지금 바로 트위터 개발자 계정을 신청하세요!",
          "소개 및 설정하기",
          "[활동] 스파크 스트리밍으로 라이브 트윗을 스트리밍 하세요!",
          "유데미 101: 이 코스를 최대한 활용하는 방법"
        ],
        "스칼라 집중 코스": [
          "[활동] 스칼라 기본사항: 파트 1",
          "[문제] 스칼라의 흐름 제어",
          "[문제] 스칼라의 기능",
          "[문제] 스칼라의 데이터 구조"
        ],
        "스파크 스트리밍에 대한 개념": [
          "스파크 소개",
          "탄력적인 분산 데이터 세트 (RDD)",
          "[활동] RDD 작동 : 간단한 단어 수 응용 프로그램",
          "스파크 스트리밍 소개",
          "[활동] 프린트윗츠 응용 프로그램 다시 보기",
          "윈도우 설정: 장기간에 걸친 데이터 집계",
          "스파크 스트리밍의 고장 허용 범위"
        ],
        "트위터를 이용한 스파크 스트리밍 예제": [
          "[문제] 트윗을 디스크에 저장하기",
          "[문제] 평균 트윗 길이 추적하기",
          "[문제] 가장 인기있는 해시태그 추적하기"
        ],
        "클릭스트림 / 아파치 액세스 로그 데이터를 사용한 스파크 스트리밍 예제": [
          "[문제] 요청한 상위 URL 추적하기",
          "[문제] 로그 오류에 대해 경고하기",
          "[문제] 스파크 스트리밍과 구조화 질의어 통합하기",
          "구조화된 스트리밍 소개",
          "[활동] 구조화된 스트리밍으로 아파치 로그 파일 분석"
        ],
        "다른 시스템과 통합하기": [
          "아파치 카프카와 통합하기",
          "아파치 플룸과 통합하기",
          "아마존 키네시스와 통합하기",
          "[활동] 사용자 정의 데이터 수신기 작성하기",
          "카산드라와 통합하기"
        ],
        "스파크 스트리밍 예제 (고급)": [
          "[문제] 스파크 스트림의 추적 가능한 정보",
          "[활동] K-방식을 통한 클러스터링 스트리밍하기",
          "[활동] 직선회귀 스트리밍하기"
        ],
        "스파크 스트리밍의 운영": [
          "[활동] 실행중인 스파크 코드 패키징 및 운영",
          "[활동] SBT로 코드 패키징하기",
          "하둡 클러스터에서 EMR을 사용하여 실제로 실행해보기",
          "스파크 작업 문제를 해결하고 조정하기"
        ],
        "여러분이 해냈습니다!": [
          "더 배우기",
          "보너스 강의: 더 많은 강의 탐구하기!",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "개인용 컴퓨터가 필요합니다(설치 과정 등은 windows OS를 사용하였으며, 리눅스나 MAC OS에서도 설치가 가능합니다)",
        "스파크에 대해 소개하고 있으나, 사전 지식이 필요하지 않습니다",
        "스칼라 프로그래밍 경험은 수강에 도움이 됩니다 (사전 지식이 없어도 관련 강의가 포함되어 있어 수강이 가능합니다)"
      ],
      "description": "스파크 스트리밍과 스칼라로 빅데이터 스트리밍!\n대량의 데이터 세트를 해결하세요!\n실무에 바로 적용할 수 있습니다!\n\n\n스파크 스트리밍과 스칼라로 빅 데이터 스트리밍하기 (실전편) 강의를 선택해야 하는 이유\n현재 IntelliJ 통합개발환경에 맞춰 업데이트 됐습니다!\n“빅 데이터” 분석은 인기있고 대단히 가치있는 능력입니다. 중요한 건 “빅 데이터”의 흐름이 멈추지 않는다는 것입니다! 스파크 스트리밍은 대량의 데이터 세트를 생성할 때 처리하기 위한 새롭고 신속하게 개발되는 기술입니다 - 항상 실시간으로 분석 업데이트를 할 수 있는데 밤마다 분석을 해야할까요? 대형 웹사이트의 방문 사이트 동향 데이터, 대규모 “사물 인터넷” 배포의 센서 데이터, 재무 데이터 등 그 어떤 것이든 스파크 스트리밍은 데이터가 생성될 때 항상 데이터를 변환하고 분석할 수 있는 강력한 기술입니다.\n\n\n여러분은 아마존과 IMDb 선임 매니저와 전 엔지니어분으로부터 해당 내용을 배우게 될 것입니다.\n이 코스 과정에서는 실제 라이브 트위터 데이터, 아파치 액세스 로그의 시뮬레이션 동향, 그리고 심지어 머신러닝 모델을 훈련하는 곳에 사용되는 데이터까지 접해볼 수 있습니다! 직접 집에서 컴퓨터로 스파크 스트리밍 작업을 작성하고 실행해 볼 수 있습니다. 그리고 과정이 끝날 때쯤 여러분에게 실제 하둡 클러스터로 이러한 작업을 가져와서 생산 환경에서도 실행하는 방법을 보여줄 것입니다.\n\n\n이 교육과정은 매우 실용적이고 바로 수행 가능한 활동으로 구성되어 여러분의 교육을 강화하는 데 도움이 됩니다. 강의가 끝날 무렵, 여러분은 스파크 스트리밍 스크립트를 스칼라를 활용하여 자신있게 작성할 줄 알게되며, 완전히 새로운 방식으로 거대한 양의 데이터를 해결하는데 준비가 되어있을 것입니다. 스파크 스트리밍이 이 모든 걸 가능하게 했다는 사실에 매우 놀랄 것입니다!\n\n\n스파크 스트리밍과 스칼라로 빅 데이터 스트리밍하기 (실전편) 강의에서는 아래의 내용을 배울 수 있습니다:\n\n\n스칼라 프로그래밍 언어로 된 집중 훈련을 수강하세요\n아파치 스파크가 클러스터에서 어떻게 운영되는지 알아보세요\n스파크 스트리밍으로 불연속의 스트림을 설정하고 데이터가 수신되면 변환할 수 있습니다\n실시간으로 구조화된 스트리밍을 이용하여 데이터 프레임으로 스트리밍합니다\n슬라이딩 윈도우에서 시간 경과에 따른 스트리밍 데이터 분석\n여러 데이터 스트림 전반에 걸쳐 상태 정보 유지하게 됩니다\n카프카, 플룸, 및 키네시스와 같은 확장성이 뛰어난 데이터 소스와 스파크 스트리밍을 연결하는 방법을 습득합니다\n카산드라와 같은 구조화 질의어만을 사용하지 않는 데이터베이스에 실시간으로 데이터 스트림을 폐기하는 방법\n스트리밍 된 데이터에 실시간으로 구조화 질의어 쿼리를 실행합니다\n스트리밍 데이터로 머신러닝 모델을 실시간으로 훈련하고, 이 모델을 사용하여 시간이 지남에 따라 계속 향상되는 예측을 할 수 있습니다\n아마존의 빅데이터 프레임워크 실행을 간소화하는 관리형 클러스터 플랫폼을 사용하여 자체적으로 내장된 스파크 스트리밍 코드를 실제 하둡 클러스터에 패키징, 배포 및 실행하는 방법을 배웁니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n강의에서 만나요!",
      "target_audience": [
        "프로그래밍 사전 지식이나 스크립팅 능력이 있는 학생",
        "“빅 데이터”가 지속적으로 생성되는 회사에서 근무하고 있거나 해당 기업에서 근무하고 싶은 관련 종사자",
        "이전 소프트웨어 공학이나 프로그래밍 경험이 없는 학생들은 먼저 프로그래밍 입문 과정을 수강해야 합니다"
      ]
    },
    {
      "title": "빅데이터분석기사 완전정복 필기편 : Part.4. 빅데이터 결과해석",
      "url": "https://www.udemy.com/course/part4-qi/",
      "bio": "빅데이터 결과 해석하기! 분석 모형 평가 및 개선부터 분석 결과 시각화, 활용까지 함께 배워봅시다.",
      "objectives": [
        "빅데이터 결과해석",
        "분석 모형 평가",
        "분석 모형 개선",
        "분석결과 해석",
        "분석결과 시각화",
        "예상 문제 풀이",
        "빅데이터 결과 해석 과목 마무리 문제 풀이"
      ],
      "course_content": {
        "빅데이터분석기사 완전정복 (필기) Part.4. 빅데이터 결과해석 - 1.분석 모형 평가 및 개선": [
          "분석 모형 펑가(평가지표, 분석 모형 설정, 편향, 분산, 평가 방법, 회귀모형 평가 지표 4가지, MAE, MSE, RMSE, MAPE)",
          "분석 모형 펑가(결정계수 개념, 특징, 수식, SST, SSR, SSE, 분류모형 평가 지표, 혼동행렬 개념, 분류모형 평가 지표 7가지)",
          "분석 모형 펑가(ROC 곡선의 개념, 특징, AUC의 개념, 특징)",
          "분석 모형 펑가(분석 모형 진단의 개념, 일반화 오류-과대적합, 학습 오류-과소적합, 교차검증 개념, 목적)",
          "분석 모형 펑가(K-fold, 홀드 아웃, LOOCV, LpOCV, 부트스트랩 교차검증, 모집단, 모수, 표본, 모집단 유의성 검정 방법 6가지",
          "분석 모형 펑가(교차검증, 모집단, 모수, 표본, 모집단 유의성 검정 방법 개념 체크 문제 풀이)",
          "분석 모형 펑가(적합도 검정 개념, 가정된 확률 검정-카이제곱 검정, 정규성 검정-샤피로-윌크, K-S검정, Q-Q plot)",
          "분석 모형 개선(과대적합 방지, 데이터 증강, 모델의 복잡도 감소, 가중치 규제-라쏘, 릿지, 엘라스틱 넷, 드롭 아웃)",
          "분석 모형 개선(매개변수 최적화의 개념, 손실함수, 경사하강법 개념, 종류-배치, 확률적, 미니배치 경사하강법)",
          "분석 모형 개선(모멘텀 개념, 특징, 오버슈팅, 네스테로프 모멘텀, AdaGrad. RMSProp, Adam, 초매개변수 최적화 개념, 방법 4",
          "분석 모형 개선(분석 모형 융합의 개념, 특징, 방법, 최종 모형 선정 개념, 순서, 예상문제 풀이-1)",
          "분석 모형 개선(예상문제 풀이-2)"
        ],
        "빅데이터분석기사 완전정복 (필기) Part.4. 빅데이터 결과해석 - 2.분석결과 해석, 분석결과 시각화, 분석결과 활용": [
          "분석결과 해석(데이터 시각화 개념, 목적, 시각화 도구 종류, 시각화 분류, 시각화 절차)",
          "분석결과 해석(비즈니스 기여도 개념, TCO, ROI, NPV, IRR, PP 용어의 개념, 특징)",
          "분석결과 시각화(시간 시각화 개념, 특징, 유형 7가지, 공간 시각화 개념, 특징, 유형 5가지)",
          "분석결과 시각화(분포 시각화 개념, 특징, 유형 4가지)",
          "분석결과 시각화(관계 시각화 개념, 특징, 유형 5가지, 비교 시각화 개념, 특징, 유형 5가지)",
          "분석결과 시각화(인포그래픽(Inforgraphics) 개념, 특징, 종류 6가지, 예시)",
          "분석결과 활용(분석 결과 활용 단계 4가지와 순서, 각각의 개념과 특징)",
          "예상 문제 풀이-1",
          "예상 문제 풀이-2",
          "빅데이터 결과 해석 과목 마무리 문제 풀이-1",
          "빅데이터 결과 해석 과목 마무리 문제 풀이-2",
          "빅데이터 결과 해석 과목 마무리 문제 풀이-3"
        ]
      },
      "requirements": [
        "\"한번에 합격하겠다는 의지! 데이터 통계와 데이터 보안 관련 분야 지식이 있으면 좋습니다.\""
      ],
      "description": "안녕하세요, ITGO 입니다.\n\n\n본 강의는 빅데이터분석기사 완전정복 필기편 : Part.4. 빅데이터 결과해석 강의입니다.\n\n\n빅데이터 분석 기사는 국가 기술 자격증으로 필기와 실기 시험이 있습니다.\n\n\n본 강의는 빅데이터 분석 기사 자격증 취득을 위한 필기 시험 대비 강의입니다.\n\n\n빅데이터 분석 기사 필기 시험 핵심 개념부터 예상 문제 풀이까지 제대로 배워 한번에 합격합시다!\n\n\n\n\n누구를 위한 강의인가요?\n\n\n빅데이터 분석기사(필기) 자격증 취득을 원하시는 분들\n\n\n데이터 분석 직무로의 취업 및 이직을 준비하시는 분들\n\n\n데이터 분석에 대해 공부하고자 하시는 분들\n\n\n\n\n무엇을 배우나요?\n\n\n빅데이터 결과해석\n\n\n분석 모형 평가\n\n\n분석 모형 개선\n\n\n분석결과 해석\n\n\n분석결과 시각화\n\n\n예상 문제 풀이\n\n\n빅데이터 결과 해석 과목 마무리 문제 풀이\n\n\n\n\n빅데이터분석기사 완전정복 필기편 : Part.4. 빅데이터 결과해석 강의에 입문해봅시다~!\n\n\n\n\n그럼 강의에서 만나요 :)",
      "target_audience": [
        "빅데이터 분석기사(필기) 자격증 취득을 원하시는 분들",
        "데이터 분석 직무로의 취업 및 이직을 준비하시는 분들",
        "데이터 분석에 대해 공부하고자 하시는 분들"
      ]
    },
    {
      "title": "详解数据分析报表，教你制作可视化报告",
      "url": "https://www.udemy.com/course/nthngovk/",
      "bio": "详解报表和报告的分析思路和制作流程，综合使用Excel和Power BI灵活展现业绩数据",
      "objectives": [
        "了解报表和报告的作用和分类，明确如何根据需求选择报表和报告",
        "了解不同类型报表和报告的基本框架",
        "在To C型销售场景中，能应用销售报表分析数据",
        "掌握销售模块的分析方法论",
        "掌握如何通过工具高效的实现报表，了解如何通过报表解读业务现状"
      ],
      "course_content": {},
      "requirements": [
        "掌握可视化工具（Power BI）基本操作技能"
      ],
      "description": "说起报表，企业林林总总的报表数不胜数，比如从业务模块维度看，有财务相关的报表、销售相关的报表等；从目标用户的维度看，又可分为向上汇报的报表和给业务部门的报表……\n报表种类繁杂、功能迥异，若是掌握了报表制作技巧，不仅能在领导面前产生高光时刻，还能让自己的工作快捷又高效。那么，报表制作的底层逻辑是什么？报表究竟要怎么做？什么样的报表才能让数据清晰直观？\n为此，我们邀请上海志登科技创始人张志绮（登登）老师，为你带来这门课程。张志绮（登登）老师作为国内头部投资公司+C轮及以上项目投资尽调分析师，在数据分析领域拥有丰富经验。\n本节课老师首先通过实际工作案例引入报表的作用和意义，分别介绍了报表、报告和商业智能报表的使用场景，帮助学员根据业务场景选择合适的展现形式。接着，介绍了制作不同报表的工具选择，丰富学员的工具库，通过六个步骤总结了常见报表的制作流程，介绍了两种报表制作的常见套路。最后通过一个实际案例将方法串联起来，帮你消化理解。\n然后介绍了To C型销售报表的分类及分析方法论，结合树状结构分析应用对方法论进行解释。与此同时，引入BAT大厂销售日报分析案例，对设计报表、实现报表、报表解读内容逐一进行讲述，为使你对销售报表内容拥有全面掌握，课程中运用了丰富的实操案例，帮助你从多个角度了解报表。\n课程以“实战”为特色，通过对多个案例的解析，使原本枯燥的知识点内容变得生动有趣，帮助你理解和操作，期待你在学习后能够将具体的理论方法运用于实践。",
      "target_audience": [
        "需要解读数据的业务人员：运营、销售、市场等",
        "1-3年数据分析人员：希望运用工具有逻辑的阐述业务发现",
        "希望利用数据辅助业务决策，却面对数据无从下手的其他岗位人员"
      ]
    },
    {
      "title": "Python Data Science Campus: Komplettkurs inkl. Praxisprojekt",
      "url": "https://www.udemy.com/course/python-data-science-campus/",
      "bio": "Python Data Science von A-Z: Statistik, Pandas, NumPy, Machine Learning mit Scikit-Learn & Deep Learning mit TensorFlow!",
      "objectives": [
        "Statistik: Lerne deskriptive Statistik, Wahrscheinlichkeitsverteilungen und Hypothesentests zur effektiven Datenanalyse und Interpretation",
        "Datenstrukturen in Python: Verstehe und nutze Python-Listen, Sets und Dictionaries für effiziente Data-Science-Projekte",
        "Datenmanipulation mit Pandas: Bearbeite und bereinige Datensätze, nutze Gruppierungen und Pivot-Tabellen für tiefere Einblicke",
        "NumPy: Arbeite mit NumPy-Arrays und führe mathematische Berechnungen zur Optimierung der Performance durch",
        "Datenvisualisierung mit Matplotlib: Erstelle prägnante Diagramme und Visualisierungen, um Datenmuster zu erkennen und zu präsentieren",
        "Seaborn: Nutze Seaborn für fortgeschrittene Visualisierungen wie Boxplots, Violinplots und Heatmaps zur Datenanalyse",
        "Machine Learning Grundlagen: Lerne die Grundprinzipien von Machine Learning und setze sie auf verschiedene Datensätze an",
        "Überwachtes Lernen mit Scikit-Learn: Baue und evaluiere Modelle wie lineare Regression und Random Forest mit Scikit-Learn",
        "Unüberwachtes Lernen: Entdecke unstrukturierte Datenmuster mit K-Means Clustering und hierarchischem Clustering",
        "Deep Learning: Baue neuronale Netze mit TensorFlow und Keras und lerne fortgeschrittene Deep-Learning-Techniken kennen"
      ],
      "course_content": {
        "Einführung": [
          "Einführung"
        ],
        "Statistische Grundlagen für Data Science": [
          "Deskriptive Statistik",
          "Wahrscheinlichkeitsverteilungen",
          "Korrelation und Kausalität",
          "Hypothesentests",
          "A/B-Testing"
        ],
        "Datenstrukturen in Python": [
          "Grundlegende Datentypen",
          "Listen, Sets und Dictionaries",
          "Listen, Sets und Dictionary Comprehensions"
        ],
        "Datenmanipulation mit Pandas": [
          "Einführung in Pandas und DataFrames",
          "Einlesen und Speichern von Daten",
          "Daten explorieren & analysieren",
          "Datenbereinigung und Vorverarbeitung",
          "Sortieren, Filtern und Gruppieren von Daten",
          "Aggregationsfunktionen",
          "Pivot-Tabellen",
          "Daten zusammenführen & kombinieren",
          "Arbeiten mit Zeitserien"
        ],
        "Numerische Berechnungen mit NumPy": [
          "Einführung in NumPy",
          "Erstellen von NumPy Arrays",
          "Indexieren und Slicing von Arrays",
          "Mathematische Operationen mit NumPy",
          "Broadcasting und Effizeinzvergleich"
        ],
        "Datenvisualisierung mit Matplotlib": [
          "Einführung in Matplotlib",
          "Liniendiagramm",
          "Balkendiagramm",
          "Punktdiagramme",
          "Histogramme",
          "Boxplots",
          "Subplots",
          "Besondere Visualisierungen",
          "Erweiterte Anpassungsmöglichkeiten von Graphen"
        ],
        "Datenvisualisierung mit Seaborn": [
          "Einstieg",
          "Pandas Integration",
          "Box und Violinplots",
          "Pairplot und Facetgrid",
          "Scatter- und Lineplot",
          "Histogramme und Dichte",
          "Regressionsplot und Heatmap"
        ],
        "Einführung in Machine Learning": [
          "Was ist Machine Learning?",
          "Überblick über ML-Typen",
          "Algorithmen im Machine Learning",
          "Der Machine-Learning-Workflow",
          "Auswahl von Features und Datenvorbereitung",
          "Overfitting und Underfitting"
        ],
        "Überwachtes Lernen mit Scikit-Learn": [
          "Einführung Scikit-Learn",
          "Lineare Regression und Multiple Regression",
          "Feature Selection",
          "Dimensionenreduktion",
          "Entscheidungsbäume und Random Forest",
          "Support Vector Machines (SVM)",
          "Künstliche Neuronale Netze in Scikit-Learn",
          "Unbalanced Data",
          "Modellvergleich und Ensemble-Methoden",
          "Hyperparameter-Tuning und Kreuzvalidierung",
          "Evaluierung von Modellen mit Metriken"
        ],
        "Unüberwachtes Lernen mit Scikit-Learn": [
          "Einführung in unüberwachtes Lernen",
          "K-Means Clustering",
          "Hierarchisches Clustering",
          "Dimensionalitätsreduktion",
          "Assoziationsanalyse",
          "Anomalieerkennung",
          "Kombination mit überwachtem Lernen"
        ]
      },
      "requirements": [
        "Du brauchst keine Vorkenntnisse! Alles was du wissen musst, lernst du im Kurs!"
      ],
      "description": "Bist du ein Einsteiger in Data Science, ein angehender Data Scientist oder ein erfahrener Programmierer, der seine Kenntnisse auf das nächste Level bringen möchte?\n\n\nDann führt kein Weg an diesem Python Data Science Campus vorbei! Dieser Kurs bietet dir alles, was du benötigst, um von den Grundlagen bis hin zu fortgeschrittenen Techniken in Data Science und Machine Learning durchzustarten – und das alles mit Python als Hauptwerkzeug!\n\n\nHast du dich schon einmal gefragt, wie es wäre …\nMit Python als Schlüssel zu einer der gefragtesten Kompetenzen in der Tech-Welt zu arbeiten?\nAlle wichtigen Data-Science-Tools wie Pandas, NumPy und Matplotlib zu meistern, um Daten zu analysieren und zu visualisieren?\nDein Wissen auf Machine Learning und Deep Learning auszudehnen und mit Algorithmen wie Künstlichen Neuronalen Netzen und Random Forests zu arbeiten?\nProjekte Schritt für Schritt zu entwickeln und dabei die gesamte Data-Science-Pipeline zu durchlaufen – von der Datenvorbereitung bis zur Modellbewertung?\nMit praxisnahen Beispielen und Projekten zu lernen, die dir helfen, dein Wissen sofort anzuwenden und umzusetzen?\nZeit, Geld und Nerven zu sparen, indem du auf eine strukturierte Lernreise gehst, die dich effizient und direkt zum Ziel führt?\n\n\nAll das ist durch den Python Data Science Campus möglich!\nMit klar strukturierten Lektionen und einem tiefen Einblick in die Welt der Data Science und Machine Learning wirst du Schritt für Schritt die nötigen Fähigkeiten erwerben, um deine eigenen Datenanalysen und Modelle zu entwickeln – ideal für Anfänger bis hin zu fortgeschrittenen Lernenden.\n\n\nAbschnitt 1: Einführung\nIn diesem Abschnitt wirst du mit den Grundlagen des Kurses vertraut gemacht und erhältst einen klaren Überblick darüber, was dich erwartet. Du wirst verstehen, wie der Kurs aufgebaut ist und welche Lernziele du erreichen wirst. Der perfekte Startpunkt, um dich auf die Reise in die Welt der Data Science zu begeben!\n\n\nAbschnitt 2: Statistische Grundlagen für Data Science\nHier tauchst du in die Welt der Statistik ein, die das Fundament für jede Data-Science-Analyse bildet. Du lernst wichtige Konzepte wie deskriptive Statistik, Wahrscheinlichkeitsverteilungen, Korrelation und Kausalität sowie Hypothesentests kennen. Diese Grundlagen helfen dir, Daten zu verstehen und fundierte Entscheidungen zu treffen.\n\n\nAbschnitt 3: Datenstrukturen in Python\nIn diesem Abschnitt wirst du die wichtigsten Datenstrukturen in Python kennenlernen, die du für Data Science benötigst. Du wirst verstehen, wie Listen, Sets und Dictionaries funktionieren und wie du diese effizient in deinen Projekten einsetzen kannst. Außerdem tauchst du in Python-typische Datenstrukturen und deren Anwendung ein.\n\n\nAbschnitt 4: Datenmanipulation mit Pandas\nPandas ist das unverzichtbare Tool, um mit Daten zu arbeiten. In diesem Abschnitt lernst du, wie du mit Pandas DataFrames erstellst, Daten einliest und speicherst, sie bereinigst und analysierst. Du wirst auch lernen, wie du Daten sortierst, filterst, gruppierst und mit fortgeschrittenen Funktionen wie Pivot-Tabellen arbeitest.\n\n\nAbschnitt 5: Numerische Berechnungen mit NumPy\nNumPy ist das perfekte Werkzeug für numerische Berechnungen und effizientes Arbeiten mit großen Datenmengen. Du lernst, wie du NumPy Arrays erstellst, manipuliert und mathematische Operationen durchführst. Außerdem erfährst du, wie du mit NumPy die Leistung deines Codes maximierst.\n\n\nAbschnitt 6: Datenvisualisierung mit Matplotlib\nDaten müssen nicht nur analysiert, sondern auch visualisiert werden, um sie verständlich und aussagekräftig zu präsentieren. In diesem Abschnitt wirst du lernen, wie du mit Matplotlib beeindruckende und informative Diagramme und Grafiken erstellst – von einfachen Liniendiagrammen bis hin zu komplexeren Visualisierungen.\n\n\nAbschnitt 7: Datenvisualisierung mit Seaborn\nSeaborn baut auf Matplotlib auf und bietet eine benutzerfreundlichere Möglichkeit, Daten zu visualisieren. Du wirst lernen, wie du mit Seaborn ansprechende Visualisierungen wie Boxplots, Violinplots und Heatmaps erstellst. Seaborn erleichtert dir das Arbeiten mit komplexen Datensätzen und hilft, Muster in deinen Daten schneller zu erkennen.\n\n\nAbschnitt 8: Einführung in Machine Learning\nMachine Learning ist das Herzstück moderner Data Science. In diesem Abschnitt wirst du die Grundlagen von Machine Learning kennenlernen, verschiedene Lernarten verstehen und einen Überblick über gängige Algorithmen und deren Anwendung erhalten. Du lernst, wie du den Machine-Learning-Workflow beginnst und warum die Auswahl der richtigen Features so wichtig ist.\n\n\nAbschnitt 9: Überwachtes Lernen mit Scikit-Learn\nHier wirst du tiefer in die Welt des überwachten Lernens eintauchen und lernen, wie du mit Scikit-Learn Algorithmen wie lineare Regression, Entscheidungsbäume und Random Forests anwendest. Du erfährst, wie du Modelle erstellst, sie evaluierst und optimierst, um präzise Vorhersagen und Klassifikationen zu treffen.\n\n\nAbschnitt 10: Unüberwachtes Lernen mit Scikit-Learn\nUnüberwachtes Lernen hilft dir, Muster in unbeschrifteten Daten zu erkennen. In diesem Abschnitt wirst du lernen, wie du mit Clustering-Techniken wie K-Means und Hierarchical Clustering arbeitest und wie du Anomalien und interessante Zusammenhänge in deinen Daten entdeckst. Ein faszinierender Abschnitt für das Finden von verborgenen Mustern!\n\n\nAbschnitt 11: Deep Learning mit TensorFlow und Keras\nDeep Learning hat die Welt der künstlichen Intelligenz revolutioniert. In diesem Abschnitt wirst du neuronale Netze mit TensorFlow und Keras aufbauen. Du lernst alles von der Grundstruktur bis hin zu komplexen Deep-Learning-Modellen wie Convolutional Neural Networks (CNNs) und Generative Adversarial Networks (GANs), die in der Bild- und Videoverarbeitung verwendet werden.\n\n\nAbschnitt 12: Praxisprojekt\nIm letzten Abschnitt des Kurses wirst du dein gesamtes Wissen in einem realen Data-Science-Projekt anwenden. Du wirst ein vollständiges Data-Science-Projekt durchführen, das alle Schritte von der Datenbereinigung bis hin zum Training und der Evaluierung von Modellen umfasst. Dies ist der perfekte Abschluss, um deine Fähigkeiten zu testen und dein Wissen praktisch umzusetzen.\n\n\nDu bekommst sofortigen Zugriff auf:\n9,5 Stunden Python Data Science Campus\n40 Kursmaterialien zum Download\nPraktische Beispiele zum sofortigen umsetzen\nSupport von Mika dem Python & Data Science Experte\nLebenslanger Zugriff auf den Kurs\n\n\nUdemy Zufriedenheitsgarantie\nUdemy hat eine 30 Tage 100% Geld zurück Garantie. Wenn Du also doch nicht zufrieden mit dem Kauf bist, bekommst du das gesamte Geld sofort zurück!\n\n\nIch freue mich schon, dich in der ersten Lektion des Python Data Science Campus begrüßen zu dürfen!\nDein Mika, Marius & Michael",
      "target_audience": [
        "Neueinsteiger in Data Science und Python: Personen ohne oder mit wenig Programmiererfahrung, die die Grundlagen von Python und Data Science erlernen möchten",
        "Berufseinsteiger im Bereich Data Science: Personen, die eine Karriere in Data Science anstreben und eine fundierte Ausbildung in Python, Statistik und Machine Learning wünschen",
        "Hobby-Programmierer und Technikbegeisterte: Personen, die ihre Kenntnisse in Python und Data Science erweitern möchten, um eigene Projekte umzusetzen",
        "Berufserfahrene Entwickler, die Data Science lernen möchten: Entwickler, die ihre Python-Kenntnisse auf Data Science und Machine Learning ausweiten wollen, um neue berufliche Möglichkeiten zu erschließen",
        "Datenanalysten und Business-Intelligence-Spezialisten: Personen mit Erfahrung in Datenanalyse, die ihr Wissen auf Python und Machine Learning erweitern möchten, um tiefere Einblicke aus Daten zu gewinnen",
        "Karrierewechsler in Data Science: Personen aus anderen Berufsfeldern, die eine Karriere in Data Science anstreben und sich die nötigen Python- und Data-Science-Kenntnisse aneignen wollen",
        "Freelancer und Unternehmer im Bereich Data Science: Selbstständige oder Unternehmer, die Python und Data Science nutzen möchten, um datengetrieben bessere Geschäftsentscheidungen zu treffen"
      ]
    },
    {
      "title": "Master Python: From Basics to Advanced Applications",
      "url": "https://www.udemy.com/course/python-diploma-in-data-science/",
      "bio": "تعلم بايثون بالتفصيل وأبدأ رحلتك في مجال تحليل البيانات وعلم البيانات",
      "objectives": [
        "Python Basics",
        "Control Flow and Logic",
        "Functions and Error Handling",
        "Advanced Python Topics"
      ],
      "course_content": {
        "Foundations of Programming and Computer Science": [
          "Number System",
          "Units",
          "Binary & Decimal System",
          "Understanding CPU and Memory",
          "Different Language (High level - Low level)",
          "Compiler and Interpreter",
          "Print Statement",
          "Comment and Escape Character",
          "Variable - part-1",
          "Variable - part2",
          "Data type",
          "Operations",
          "String",
          "String concatenation",
          "Indexing & Slicing",
          "String Operation1",
          "String Methods",
          "input function and string format"
        ],
        "Core Data Structures and Control Flow in Programming": [
          "Boolean Data Type",
          "Operations with Boolean Values",
          "Comparision",
          "List",
          "List 1",
          "Indexing with List",
          "List Methods (Part 1)",
          "List Methods(Part 2)",
          "List Operation",
          "Unpacking",
          "Challenges with LIst - Advantages of tuple and set",
          "Sets",
          "Dictionary",
          "IF- Else –Elif",
          "Nested if",
          "Assignment - Expression Modification",
          "Assignment - sentence variable",
          "Assignment-Name Error"
        ],
        "Mastering Loops and Control Flow in Programming": [
          "Flow Chart",
          "flow chart example",
          "Why for loop !",
          "For loop",
          "For Loop Example",
          "Enumerate",
          "Nested Loop",
          "For loop with if statement",
          "Continue",
          "Break",
          "Pass",
          "While Loop",
          "ternary operator(if condition)",
          "zip function",
          "Assignment - Simple calclator (part 1)",
          "Assignment - Simple calclator (part 2)",
          "Assignment - Simple calclator (part 3)"
        ],
        "Understanding Functions, File Handling, and Error Management in Programming": [
          "types of error",
          "Handling error",
          "Generating Random Number",
          "How to open file (Determine Path) part-1",
          "How to open file (Determine Path) part-2",
          "Read file",
          "Write file vs Append file",
          "Readlines",
          "create file and remove file",
          "Built-in function vs defined function",
          "what is function",
          "Understanding parameters and arguments",
          "default values",
          "Return",
          "Arbitrary Arguments(args)",
          "keyword arguments",
          "Arbitary keyword arguments",
          "positional-only arguments",
          "keyword only argument",
          "Combine positional only and keyword only",
          "Assignment - Counting products and extracting items",
          "Assignment - Determine List Size",
          "Assignment - Pseudo code"
        ],
        "OOP": [
          "global variable vs local variable",
          "global variable",
          "multiple variable in function",
          "Lambda function",
          "Map function",
          "Filter function",
          "Authontication syatem",
          "object vs function",
          "Class",
          "instance attribute vs class attribute",
          "class method vs instaance method",
          "Encapsulation",
          "Access Modifier (public and protected modifier)",
          "private access modifier",
          "getter vs setter",
          "Inheritance"
        ],
        "Project 1 (stock Management)": [
          "Stock Managment Idea - start from this video",
          "stock managment code (part 1).mp4",
          "stock managment code (part 2)",
          "stock managment code(part 3) - load function",
          "stock managment code(part 4) - create class and constructor",
          "stock managment code(part 5) - display function",
          "stock managment code(part 6) - shop product function",
          "stock managment code(part 7) - add product function",
          "stock managment code(part 8) - remove product function",
          "stock managment code(part 9)-save function",
          "stock managment code (part 10)- Shopping Menu",
          "stock managment code(part 11) - check project output"
        ],
        "Project 2 (course platform project)": [
          "course platform project (descripe idea)",
          "Part-1",
          "Part-2",
          "Part-3",
          "part 4 - check output"
        ],
        "Understanding Numpy": [
          "What is Numpy",
          "Create Array from Scratch",
          "Numpy Array shape",
          "Numpy Array Dimensions",
          "Numpy Array Transpose",
          "Array Operation - part 1",
          "Array Operation - part 2",
          "View vs Copy",
          "Reshape",
          "Flatten multidimensional and mathematical formulas",
          "Numpy Tautorial (part 1)",
          "Numpy Tautorial (part 2)",
          "Higher Dimension Array",
          "Numpy Slicing",
          "Numpy Data Type",
          "Numpy Data Type – part 2",
          "Difference betwen copy and view (part 2)",
          "Numpy Array Indexing",
          "Accessing Element in Array",
          "Numpy Iteration",
          "Iteration using nditer() and ndenumerate()",
          "Iteration with Data type and step size",
          "Concatination",
          "Stacking",
          "Numpy Splitting",
          "Numpy Searching",
          "Numpy Sorting",
          "Numpy Filtering",
          "Vectorization",
          "Convert from dimension to another dimension"
        ]
      },
      "requirements": [
        "Some programming experience",
        "Be able to use a computer with internet access",
        "Passion to learn, discuss and explore"
      ],
      "description": "Course: “Master Python: From Basics to Advanced Applications”\nWelcome to your comprehensive guide to Python programming! Whether you're a complete beginner or\nsomeone looking to strengthen your coding skills, this course is designed to take you step-by-step\nthrough Python, from the basics to advanced concepts.\nWith over 40 detailed Jupiter notebooks, interactive explanation videos, and hands-on projects, you'll not\nonly learn the \"how\" of Python but also the \"why\" behind it. This course is your one-stop shop to master\nPython for real-world applications.\n\n\nBy the end of this course, you'll gain a deep understanding of:\n\n\n1. Python Basics\n-Setting up Python and writing your first code.\n-Mastering variables, data types, and operations.\n-Understanding and using strings, lists, tuples, sets, and dictionaries e ectively.\n-Performing basic to advanced calculations using Python.\n\n\n2. Control Flow and Logic\n-Implementing decision-making using if, else, and elif statements.\n-Creating loops (for and while) and managing nested loops.\n-Tackling real-world challenges with control flow through projects like:\n-A Simple Calculator.\n-Rock-Paper-Scissors game with user interaction.\n\n\n3. Functions and Error Handling\n-Defining and using functions e ectively.\n-Mastering functional programming concepts.\n-Handling errors gracefully using Python's built-in exception handling.\n\n\n4. Advanced Python Topics\n-Working with files to read, write, and manipulate data.\n-Introduction to object-oriented programming (OOP) and its pillars: encapsulation, inheritance,\nand polymorphism.\n\n\n5. Data Analysis and Visualization\n-Using NumPy for numerical computations, array manipulation, and mathematical operations.\n-Leveraging Pandas for data indexing, selection, cleaning, and aggregation.\n-Combining, merging, and grouping data for analysis.\n\n\nGoals of the Course\n1. Solid Foundation: Gain confidence in programming using Python with structured lessons and\nexamples.\n2. Problem-Solving: Apply Python to solve real-world challenges and build useful projects.\n3. Advanced Skills: Transition from basic scripting to understanding and using advanced Python\nconcepts for data science, software development, or automation.\n4. Hands-on Practice: Work through exercises, solutions, and projects to reinforce your learning.\n\n\nWhy This Course?\nThis course is perfect for students and hobbyists who:\n-want a practical approach to learning Python programming.\n-Need structured guidance to master Python step-by-step.\n-Are aiming for careers in data science, software development, or IT automation.",
      "target_audience": [
        "Beginner Python developers curious about data science",
        "Working professionals with no prior experience in data sci",
        "College graduates pursuing Master's or Ph.d in Machine Learning /Data Science",
        "Developers looking forward to build a career in data science"
      ]
    },
    {
      "title": "Introdução ao Processamento de Sinais Biomédicos em Python",
      "url": "https://www.udemy.com/course/introducao-ao-processamento-de-sinais-biomedicos-em-python/",
      "bio": "Aprenda na prática a trabalhar com sinais biomédicos utilizando a famosa linguagem Python.",
      "objectives": [
        "Conhecer e instalar bibliotecas Python",
        "Utilizar estruturas de dados",
        "Compreensão de séries temporais",
        "Interpretar métricas de desempenho",
        "Principais técnicas de aprendizagem de máquina",
        "Principais técnicas de aprendizagem profunda",
        "Analisar e processar sinais biomédicos do tipo 1D e 2D",
        "Exames: Ultrassonografia, Radiografia, EEG, ECG, EMG"
      ],
      "course_content": {
        "Boas vindas": [
          "Apresentação das bibliotecas",
          "Ambiente de programação",
          "Instalação de bibliotecas"
        ],
        "Conceitos importantes": [
          "Estrutura de dados: Série",
          "Estrutura de dados: Dataframe",
          "Séries temporais",
          "Metodologia de avaliação",
          "Aprendizagem de máquina",
          "Aprendizagem profunda"
        ],
        "Aplicações com Sinais Biomédicos": [
          "Introdução da Unidade",
          "Prática 1: Ultrassonografia",
          "Prática 2: Radiografia",
          "Prática 3: Eletroencefalograma",
          "Prática 4: Eletrocardiograma",
          "Prática 5: Eletromiografia",
          "Lista de atividades",
          "Agradecimentos"
        ],
        "Aula Bônus": [
          "Aula bônus"
        ]
      },
      "requirements": [
        "Familiaridade com informática.",
        "Noções de programação em Python, C++ ou outras linguagens."
      ],
      "description": "O processamento digital de sinais biomédicos teve início quando os computadores tornaram-se mais disponíveis para a comunidade científica após a Segunda Guerra Mundial. No final dos anos 50 pesquisadores da George Washington University e do Massachusetts Institute of Technology (MIT) publicaram os primeiros algoritmos para análise de eletrocardiogramas e eletroencefalogramas, respectivamente.\nTambém naquela época imagens médicas começaram a ser digitalizadas e processadas por computador para análise morfológica celular e para contagem automática de culturas bacterianas. Em linhas gerais, o processamento de sinais e imagens biomédicos consiste na aplicação de algoritmos, principalmente para execução de operações matemáticas, a dados biológicos e médicos, em geral coletados de um paciente por meio de sensores.\nTipicamente, os dados são primeiro submetidos a operações de pré-processamento, tais como a filtragem digital para redução do nível de ruído, e em seguida, são aplicados algoritmos para extração de parâmetros relevantes para o diagnóstico médico.\nNo caso de eletrocardiogramas, por exemplo, os parâmetros podem ser os intervalos temporais entre determinados pontos da forma de onda, a dimensão fractal do sinal ou a energia dos coeficientes de wavelets em uma determinada escala. O último passo é a identificação de padrões e/ou a classificação das medições dos parâmetros em classes que correspondem a condições consideradas normais e anormais.\nNeste curso, veremos uma abordagem prática e bem interessante sobre visualização e classificação de padrões de sinais biomédicos utilizando as bibliotecas e métodos mais sofisticados que existem na atualidade.\nGaranta já a sua participação e invista na sua carreira profissional!",
      "target_audience": [
        "Desenvolvedores iniciantes de Python, Iniciantes em Ciência de Dados, Profissionais da Saúde, Estudantes e Hobbystas que tem interesse por esta área de estudo.."
      ]
    },
    {
      "title": "AI 개발자로 성장하기: 취업과 이직을 위한 실전 완벽 가이드",
      "url": "https://www.udemy.com/course/be-ai-engineer/",
      "bio": "AI 직무 분석, 채용 전략, 실무 기술 로드맵, 포트폴리오 기획까지 커버하는 취업·이직 대비 완성형 강의",
      "objectives": [
        "AI 개발자의 실제 직무와 채용 시장의 흐름을 분석하고 이해할 수 있습니다.",
        "기업이 원하는 AI 인재상과 그에 맞는 실무형 기술 역량을 습득할 수 있습니다.",
        "FastAPI, Huggingface 실무에 필요한 기술 스택을 프로젝트 중심으로 익힙니다.",
        "문제 해결 중심 포트폴리오를 설계하고, 기술이 아닌 ‘비즈니스 가치를 전달하는 방법’을 배웁니다.",
        "신입, 비전공자, 이직자별 커리어 전략과 단계별 성장 로드맵을 세울 수 있습니다."
      ],
      "course_content": {
        "인트로": [
          "소개"
        ],
        "강의 및 강사 소개": [
          "강의 목표",
          "강의 소개",
          "강사 소개"
        ],
        "직무 이해 및 시장 파악": [
          "AI 직무의 이해",
          "AI 개발자 시장의 불확실성 요인 분석",
          "AI 채용 시장의 이해"
        ],
        "인재상 분석 및 성장 전략": [
          "AI 채용 시장의 양극화",
          "AI 개발자 역량 쌓기 전략",
          "성장시기 및 역량별 학습 전략"
        ],
        "실전 포트폴리오 준비 및 차별화": [
          "진로 전략 및 케이스 분석",
          "성장시기 및 역량별 학습 전략",
          "면접관의 까다로운 질문에 답하라: 포트폴리오 차별화 실전연습"
        ],
        "정리 및 마무리": [
          "정리 및 마무리"
        ]
      },
      "requirements": [
        "프로그래밍 경험이 많지 않아도 괜찮습니다. 실전 중심 예제와 함께 학습합니다.",
        "Python 기초 문법 또는 머신러닝 입문 수준 이해가 있다면 더욱 효과적입니다.",
        "강의에서는 Jupyter Notebook, GitHub, FastAPI 등 무료 오픈소스를 활용합니다.",
        "Google Colab 또는 개인 노트북 환경에서 실습이 가능합니다."
      ],
      "description": "AI 개발자라는 직무는 빠르게 성장 중이지만, 실제로 무엇을 준비하고 어떤 방향으로 역량을 키워야 하는지 막막한 분들이 많습니다. 이 강의는 그런 분들을 위한 실전형 성장 전략 가이드입니다.\n강의는 크게 세 가지 흐름으로 구성되어 있습니다.\n첫째, AI 개발자라는 직무에 대한 정확한 이해입니다.\n데이터 사이언티스트, ML 엔지니어, 리서처와 어떤 차이가 있는지, 채용 시장에서는 어떤 스킬셋을 요구하는지 분석합니다.\n둘째, 기업이 실제로 원하는 인재상을 파악합니다.\n단순히 GPT를 써봤다고 말하는 포트폴리오가 아니라, 문제를 정의하고 해결 방법을 설계할 수 있는 실전형 AI 엔지니어로 포지셔닝하는 전략을 소개합니다.\n셋째, 실무 기술과 포트폴리오 작성 전략을 제시합니다.\nPyTorch, FastAPI, Huggingface 등을 활용해 실제 제품처럼 문제를 해결하는 경험을 쌓고, 그것을 어떻게 정리해 채용 시장에 어필할 수 있는지 배웁니다.\n이 강의는 기초를 익힌 분이 실전 준비를 하고자 할 때 최적화된 강의입니다.\n\n이론보다는 실전 위주로, 실습보다는 전략과 방향성 위주로 구성되어 있습니다.\nAI를 배우는 단계를 넘어, AI로 문제를 해결할 줄 아는 사람이 되고 싶은 분들을 위한 강의입니다.",
      "target_audience": [
        "AI 개발자로 커리어를 시작하거나 이직을 준비하는 분",
        "기술은 익혔지만 포트폴리오 설계와 취업 전략이 막막한 분",
        "AI 기술을 활용해 실무 문제를 해결하는 역량을 기르고 싶은 실무자",
        "서비스 개발자에서 AI 개발자로 방향을 바꾸고 싶은 백엔드/풀스택 개발자"
      ]
    },
    {
      "title": "파이썬(Python) 실무 데이터 분석 프로젝트 - 머신러닝 with 사이킷런(scikit-learn)",
      "url": "https://www.udemy.com/course/maso-ds-python-onc33/",
      "bio": "어렵고 복잡할 것만 같았던 머신러닝도 마소캠퍼스와 파이썬 사이킷런(Python scikit-learn)과 함께 쉽고 재미있게 배우는 과정!",
      "objectives": [
        "파이썬 핵심 패키지 정리를 통한 데이터 분석과 데이터 시각화 진행",
        "머신러닝의 지도학습과 비지도학습, 강화학습의 개념과 차이 이해",
        "파이썬 머신러닝 패키지 사이킷런에 대한 이해와 프레임워크 정리",
        "실전 사례와 사이킷런 실습을 통한 알고리즘의 핵심 이해"
      ],
      "course_content": {
        "1. 데이터분석을 위한 파이썬 핵심정리": [
          "pym100 – 머신러닝 실무 과정 설명",
          "pym101 – 파이썬 개발환경과 주요 패키지 소개",
          "pym102 – 파이썬 기본 개발환경 구축 및 환경테스트",
          "pym103 – 주피터 노트북 개발환경 구축",
          "pym104 – 주피터 노트북을 활용하여 파이썬 코딩하기",
          "pym105 – 파이썬 프로그래밍 Overview",
          "pym111 – 파이썬 기본 지식 정리1",
          "pym112 – 파이썬 기본 지식 정리2",
          "pym113 – 파이썬 자료구조 핵심정리_설명",
          "pym114 – 파이썬 자료구조 핵심정리_실습1",
          "pym115 – 파이썬 자료구조 핵심정리_실습2",
          "pym116 – 파이썬 함수와 모듈 핵심정리"
        ],
        "2. 데이터분석 핵심 패키지 활용 실무": [
          "pym201 – 파이썬 데이터분석 핵심 패키지 정리",
          "pym202 – 파이썬 고성능 수치 계산 패키지_Numpy 핵심정리",
          "pym203 – 파이썬 고성능 수치 계산 패키지_Numpy 활용_핵심실습1",
          "pym204 – 파이썬 고성능 수치 계산 패키지_Numpy 활용_핵심실습2",
          "pym205 – 파이썬 고성능 수치 계산 패키지_Numpy 활용_핵심실습3",
          "pym206 – 파이썬 데이터 핸들링 패키지_Pandas 핵심정리",
          "pym207 – 파이썬 데이터 핸들링 패키지_Pandas 활용_핵심실습1",
          "pym208 – 파이썬 데이터 핸들링 패키지_Pandas 활용_핵심실습2",
          "pym209 – 파이썬 데이터 핸들링 패키지_Pandas 활용_핵심실습3",
          "pym210 – 파이썬 데이터 핸들링 패키지_Pandas 활용_핵심실습4",
          "pym211 – 파이썬 데이터 핸들링 패키지_Pandas 활용_핵심실습5",
          "pym212 – 파이썬 데이터 핸들링 패키지_Pandas 활용_핵심실습6",
          "pym213 – 파이썬 데이터 핸들링 패키지_Pandas 활용_핵심실습7"
        ],
        "3. 데이터 시각화 기법 핵심정리": [
          "pym214 – 파이썬 데이터 시각화 패키지_Matplotlib Seaborn 핵심정리",
          "pym215 – 파이썬 데이터 시각화 패키지_Matplotlib 활용_핵심실습",
          "pym216 – 파이썬 데이터 시각화 패키지_Seaborn 활용_핵심실습1",
          "pym217 – 파이썬 데이터 시각화 패키지_Seaborn 활용_핵심실습2"
        ],
        "4. 실전 머신러닝 입문 지도학습 및 비지도학습": [
          "pym301 – 파이썬 머신러닝을 활용한 문제해결_핵심정리",
          "pym302 – 파이썬 머신러닝_지도학습 비지도학습 강화학습_핵심정리",
          "pym303 – 파이썬 머신러닝_분류 추정 차원축소 군집화 연관성 규칙_핵심정리",
          "pym304 – 파이썬 머신러닝_지도학습 모델타입_핵심정리",
          "pym305 – 파이썬 머신러닝_지도학습_예시",
          "pym306 – 파이썬 머신러닝_비지도학습_예시",
          "pym307 – 파이썬 머신러닝_핵심 용어 정리",
          "pym308 – 파이썬 머신러닝_지도학습_핵심 프로세스 정리",
          "pym309 – 파이썬 머신러닝_사이킷런의 지도 학습_실행 모델 정리",
          "pym310 – 파이썬 머신러닝_사이킷런의 비지도 학습_실행 모델 정리",
          "pym311 – 파이썬 머신러닝 패키지_사이킷런_소개와 특징",
          "pym312 – 파이썬_머신러닝 패키지_사이킷런_프레임워크 정리",
          "pym313 – 파이썬_머신러닝 패키지_사이킷런_Estimator 클래스_지도학습 정리",
          "pym314 – 파이썬_머신러닝 패키지_사이킷런_Estimator 클래스_비지도학습 정리",
          "pym315 – 파이썬_머신러닝 패키지_사이킷런_주요 모듈 정리",
          "pym316 – 파이썬 머신러닝 패키지_사이킷런_예제 데이터 셋 구조 정리"
        ],
        "5. 실전 머신러닝 시작하기": [
          "pym401 – 파이썬 머신러닝_Model Selection 모듈_핵심정리",
          "pym402 – 파이썬 머신러닝_Model Selection 모듈_핵심실습",
          "pym403 – 파이썬 머신러닝_Model Selection 모듈_교차검증 핵심정리",
          "pym404 – 파이썬 머신러닝_Model Selection 모듈_교차검증 핵심실습",
          "pym405 – 파이썬 머신러닝_Model Selection 모듈_iris 데이터셋 교차검증_사례실습",
          "pym501 – 파이썬 머신러닝_일반화의 오류_UnderFitting 및 OverFitting 핵심정리",
          "pym601 – 파이썬 머신러닝_데이터 전처리_핵심정리",
          "pym602 – 파이썬 머신러닝_데이터 전처리_결측치 처리 핵심정리",
          "pym603 – 파이썬 머신러닝_데이터 전처리_결측치 처리 핵심실습",
          "pym604 – 파이썬 머신러닝_데이터 전처리_피처 스케일링과 정규화 핵심정리",
          "pym605 – 파이썬 머신러닝_데이터 전처리_피처 스케일링과 정규화 핵심실습",
          "pym606 – 파이썬 머신러닝_데이터 전처리_레이블 인코딩 핵심정리",
          "pym607 – 파이썬 머신러닝_데이터 전처리_레이블 인코딩 핵심실습",
          "pym608 – 파이썬 머신러닝_데이터 전처리_원핫인코딩 핵심정리",
          "pym609 – 파이썬 머신러닝_데이터 전처리_원핫인코딩 핵심실습",
          "pym610 – 파이썬 머신러닝_데이터 전처리_건강진단 데이터 실전사례",
          "pym701 – 파이썬 머신러닝_주요 알고리즘_Regression 핵심정리1",
          "pym702 – 파이썬 머신러닝_주요 알고리즘_Regression 핵심정리2",
          "pym703 – 파이썬 머신러닝_주요 알고리즘_단순선형회귀와 다중선형회귀 핵심정리",
          "pym704 – 파이썬 머신러닝_주요 알고리즘_회귀 모델 평가 지표 핵심정리",
          "pym705 – 파이썬 머신러닝_주요 알고리즘_주택가격예측 회귀모델 실전사례",
          "pym706 – 파이썬 머신러닝_주요 알고리즘_statsmodels 라이브러리 활용 회귀모델 핵심실습",
          "pym707 – 파이썬 머신러닝_주요 알고리즘_Classification 핵심정리",
          "pym708 – 파이썬 머신러닝_주요 알고리즘_최근접이웃 Knn 핵심정리",
          "pym709 – 파이썬 머신러닝_주요 알고리즘_최근접이웃 Knn 핵심실습",
          "pym710 – 파이썬 머신러닝_주요 알고리즘_Decision Tree 핵심정리",
          "pym711 – 파이썬 머신러닝_주요 알고리즘_Decision Tree 핵심실습",
          "pym712 – 파이썬 머신러닝_주요 알고리즘_분류 앙상블 모형 핵심정리",
          "pym713 – 파이썬 머신러닝_주요 알고리즘_분류 앙상블 모형 핵심실습",
          "pym714 – 파이썬 머신러닝_주요 알고리즘_분류 모델 평가지표 핵심정리",
          "pym715 – 파이썬 머신러닝_주요 알고리즘_분류 모델 평가지표 핵심실습",
          "pym716 – 파이썬 머신러닝_주요 알고리즘_K Means Clustering 핵심정리",
          "pym717 – 파이썬 머신러닝_주요 알고리즘_K Means Clustering_와인데이터세트 실전사례"
        ],
        "99. 최종 테스트": [
          "파이썬 머신러닝 최종 평가"
        ]
      },
      "requirements": [
        "실습 위주의 강의로, 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기 활용을 권장드립니다.",
        "Windows OS 기반의 실습 환경을 구성하여 진행되는 강의이므로 참고 부탁드립니다.",
        "파이썬 데이터 분석 관련 강의를 수강했거나 파이썬을 이용하여 데이터 분석 패키지를 이용해 본 경험이 있는 분들께 추천드립니다.",
        "마소캠퍼스의 파이썬 데이터 분석 입문, 실무 강의를 수강하신 후 본 강의를 학습하시면 더 쉬운 이해가 가능합니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n\n\n머신러닝은 무엇인가요?\n인터넷 쇼핑 웹사이트에서 내가 좋아할만한 상품을 추천받으신 적이 있으신가요?\n이는 바로 머신러닝을 활용한 마케팅의 예입니다!\n머신러닝이란, 사람이 명시적으로 프로그램을 만들지 않더라도\n컴퓨터 스스로 예측 결과를 만들어 내는 것을 의미합니다.\n\n\n우리의 삶을 획기적으로 변화시킬 머신러닝을 배우면, 다음과 같은 장점이 있습니다.\n1. 감에 의존하는 불안한 의사결정이 아닌, 데이터 기반의 미래 예측 모델을\n획기적으로 높은 퍼포먼스로 만들 수 있습니다.\n2. 기존 본인의 업무 영역에 머물러 있던 한계를 벗어나\nSuperjobs로 전환할 수 있는 역량을 확보할 수 있습니다.\n3. 주가 예측, 부동산 예측, 매출 예측, 고객 분류 등\n복잡한 분석과 예측을 머신러닝의 도움을 받아 해결할 수 있습니다.\n4. 빠르게 성장하고 있는 시장으로 지금 머신러닝을 익히면 남다른 경쟁력을 가질 수 있습니다.\n파이썬 머신러닝을 수강하며 세계 모든 기업들이 찾는 인재로 거듭나보세요!\n\n\n\n\n간혹, 머신러닝은 전문가들만이 다루는 분야라고 생각하고 학습을 망설이는 분들이 있습니다.\n하지만, 마소캠퍼스의 <파이썬 머신러닝> 강의와 함께라면 전혀 어렵지 않습니다!\n머신러닝의 개념부터 다양한 사례 학습, 실습까지 따라 하다 보면\n문과생도, 머신러닝 입문자도 바로바로 쉽게 익히실 수 있습니다.\n\n\n1. 파이썬 핵심 패키지를 통한 데이터 분석 및 시각화 마스터!\n머신러닝에 입문하기 전, 파이썬의 주요 데이터 분석 패키지인 Numpy와 Pandas를 복습하여,\n데이터 분석을 진행하도록 합니다. 또한, Matplotlib와 Seaborn을 활용하여\n데이터 특성과 분석 목표에 따라 데이터를 시각화할 수 있도록 합니다.\n\n\n2. 개념부터 차근차근! 머신러닝 기초 다지기\n지도학습, 비지도학습, 강화학습의 핵심을 정리하고 예시를 통해 완벽히 이해할 수 있도록 돕습니다.\n머신러닝의 종류와 개념을 완벽하게 익힘으로써 본격적인 시작에 앞서 머신러닝과 친해질 수 있도록 합니다.\n\n\n3. 실전 사례와 사이킷런 실습으로 실무 활용력 업그레이드!\n실전 사례와 사이킷런 실습으로 실무에서 주요하게 쓰이는 알고리즘의 핵심을 이해하고\n건강 진단 데이터 전처리, 주택가격 예측, 와인 데이터셋 분류 등의 실습을 해낼 수 있습니다.\n단순한 주입식 교육이 아닌 직접 시도해보는 실습을 통해 실무 활용도를 향상시킬 수 있습니다.\n\n\n4. 어려울 거란 편견은 NO! 단계별 학습으로 어려워 보이던 머신러닝도 OK!\n이 강의를 수강하면, 머신러닝은 어렵고 복잡하다는 편견이 사라집니다.\n머신러닝의 개념부터 실전 프로젝트까지 단계별로 머신러닝의 핵심을 깨우쳐가며\n누구나 데스크탑 PC만으로 머신러닝 도구를 사용할 수 있습니다!\n\n\n마소캠퍼스의 <파이썬 머신러닝>은 어렵고 쓸데없는 강의가 아닙니다!\nAI와 함께 살아가는 시대 속에서, 복잡한 분석과 예측은 머신러닝에 맡기고 업무 효율을 높여보세요!\n\n\n\n\n*본 과정은 MSIQ 데이터사이언스마스터/디지털마케팅마스터 자격을 보유한 마소캠퍼스 콘텐츠랩의 자체 개발 평가 문항이 포함되어 있습니다.[민간자격 등록번호 : 2020-005943(데이터사이언스)/2020-005944(디지털마케팅)]\n\n\n\n\n-\n\n\n[ 강 사  소 개 ]\n\n\n김 진 숙\n現 마소캠퍼스 수석 교수\n컴퓨터시스템 공학 석사\n김진숙 교수는 마소캠퍼스에서 빅데이터 부분 수석 교수로 빅데이터(R, 파이썬), HTML5/CSS3, JQueryMobile, 스크래치, 앱인벤터, IoT 등의 최신 IT 관련 기술 과정들까지 다양한 기업과 기관의 수강생들을 대상으로 열정 넘치는 강의를 이어가고 있습니다. 김진숙 교수는 스마트팜 IoT 프로젝트, 카 셰어링 앱 프로젝트 등 다수 프로젝트 지도 경력까지 겸비한 전문가입니다.\n-",
      "target_audience": [
        "파이썬을 활용한 머신러닝에 관심이 있으신 분",
        "데이터를 기반으로 다양하게 분석하고 이를 기반으로 미래를 예측하고 싶은 분",
        "복잡한 분석과 예측을 빠르고 쉽게 해결하고 싶은 분",
        "빠르고 정확하게 분석된 예측과 결과로 의사결정을 효율적으로 진행하고 싶은 분",
        "“창업/입사/직무전환/리스킬/탤런트 트랜스포메이션\"을 꿈꾸는 분들"
      ]
    },
    {
      "title": "政府統計 e-Stat API 入門",
      "url": "https://www.udemy.com/course/e-stat-api/",
      "bio": "公共データをAPIを使って効率的にダウンロードする方法",
      "objectives": [
        "政府統計 e-Stat がサービス提供している API の仕組みと使い方を学べます",
        "APIを利用するのに必要十分なPython技術を学べます",
        "e-Stat 以外のAPIサービスを使えるようになります",
        "日本政府が提供している公共データ・政府統計について学ぶことができます"
      ],
      "course_content": {
        "eStat とは何か？": [
          "政府統計 e-Statとはなんでしょうか"
        ],
        "政府統計 e-Stat をポータルサイトで操作する方法を学びます": [
          "政府統計e-Statポータルを使ってみる"
        ],
        "e-Stat の API について紹介します": [
          "e-Statポータル上のデータベースを操作してみる",
          "e-Statポータル上のデータベースからデータを取得します"
        ],
        "e-Stat API を使って、政府データの内容（メタ情報）を調査する方法を学びます": [
          "e-Stat APIを利用するための準備",
          "e-Stat API を使ってみる",
          "e-Stat API を使ってデータを調べる"
        ],
        "e-Stat API を使って「家計調査」から、過去20年間の二人以上世帯の電気代平均額の推移を確認するためのデータを取り出します": [
          "e-Stat APIで取得したデータの構造",
          "e-Stat API で取得したデータの構造"
        ],
        "e-Stat API を使って、政府統計ポータルに同録されているデータを調べる方法を知ります": [
          "e-Stat API で公共データの情報を探す"
        ],
        "E-Stat API を操作するのに必要十分なPython言語について学びます": [
          "Python超入門",
          "Python超入門「リスト」と「インデックス」",
          "Python超入門「辞書」"
        ],
        "APIの仕組みについて基本から応用まで学びます": [
          "API入門"
        ]
      },
      "requirements": [
        "コンピューター操作を苦手としていない方がよいです"
      ],
      "description": "政府統計e-Statには、日本政府が保有するあるいは、各種機関から提供された公開可能データが多く登録されています。これらの高校データは、e-Stat ポータルでも確認することもできますが、一般にデータサイズが大きくなるため、e-Statポータルで可能な操作は限られます。\nそこで、いったんデータを自分のパソコンなどにダウンロードし、てもとのソフトウェアあるいはプログラミング言語でデータを確認また操作する必要が生じます。そのためには、e-Statから、自分が必要とするデータを効率的かつ正確に取得することが必要です。\nこうした需要にこたえるため e-Stat には、データを機械的に取得できるAPI(Application Programming Interface) という仕組みが用意されています。\n本講座では、e-Stat API の概要、準備、そして実際の使い方を1から解説しています。また、APIを利用するにはプログラミング言語を使うのが効率的です。本講座ではPythonという言語を使います。ただし、Python言語を使ったことがないというユーザーのため、本講座ではAPIを利用するのに必要十分な内容についても、取り上げています。このほか、APIの仕組みについても解説動画を用意しています。",
      "target_audience": [
        "公共データの分析に興味を抱いている実務家",
        "業務や研究で日常的に公共データを利用しており、作業を効率化したいと考えている方"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第12部 視覺之煉金術師",
      "url": "https://www.udemy.com/course/generative_ai_12/",
      "bio": "關於ComfyUI，LoRA，AI換臉，AI視頻，AI動畫， Stable diffusion，Prompt，KSampler，UpScaling，ControlNet，rgthree，SDXL",
      "objectives": [
        "了解ComfyUI的定義、用途及其背後的技術原理",
        "掌握如何創建和管理工作流程",
        "學會如何靈活地連接和配置節點，實現複雜的圖像生成任務",
        "學習如何撰寫提示詞，提升創作質量",
        "學會如何選擇最合適的種模型和采樣器來提升圖像質量"
      ],
      "course_content": {
        "ComfyUI配置": [
          "什麼是Image Generation圖片生成",
          "如何使用ComfyUI",
          "如何在iMac電腦上安裝ComfyUI",
          "如何創建第一個ComfyUI工作流"
        ],
        "如何改善生成的圖片質量": [
          "如何創建好的Promp提示詞",
          "如何使用雙KSampler優化圖片輸出",
          "如何使用UpScaling細節增強"
        ],
        "如何使用ControlNet控制網絡": [
          "如何安裝ControlNet模型",
          "如何添加ControlNet控制網絡到ComfyUI當中",
          "如何安裝與使用rgthree整理和控制工作流",
          "如何同時使用多個ControlNet"
        ],
        "如何用圖生成新圖": [
          "如何用Image生成圖片",
          "如何用Image生成Prompt",
          "如何用將動畫轉換成動畫以及如何使用Mask",
          "如何使用LoRA模型"
        ],
        "如何使用ComfuUI生成動畫": [
          "如何使用ComfyUI生成動畫",
          "如何使用Video生成動畫"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "在當今的數字藝術和人工智能領域，ComfyUI作為一款基於Stable Diffusion的強大工具，正迅速成為創作者和開發者的首選。無論你是想要創建驚人的AI藝術作品，還是希望深入了解圖像生成的技術，這個課程將為你提供系統化的學習體驗，幫助你從基礎到高級逐步掌握ComfyUI的所有功能。\n為什麼選擇ComfyUI？\nComfyUI不僅是一個用於生成圖像的工具，它還提供了一個直觀的界面，讓用戶能夠輕鬆地創建和管理工作流程。這意味著即使是初學者也能快速上手，並在短時間內創造出令人驚嘆的作品。這個課程將帶你深入了解ComfyUI的每一個方面，讓你能夠靈活運用所學知識進行創作。\n課程內容概覽\n1. ComfyUI概述\n內容：了解ComfyUI的定義、用途及其基於Stable Diffusion的工作原理。\n學習線索：探索AI圖像生成的基本概念，了解ComfyUI的歷史和發展。\n2. 工作流程（Workflows）\n內容：學習工作流程的基本結構，如何創建和管理工作流程。\n學習線索：參考官方文檔中的“Workflows”部分，查閱社區教程和示例。\n3. 節點（Nodes）\n內容：深入了解節點的類型及其功能，學習如何連接和互動。\n學習線索：研究不同節點的特性，探索社區分享的節點庫。\n4. 提示詞（Prompts）\n內容：掌握撰寫有效提示詞的技巧，了解提示詞對生成結果的影響。\n學習線索：查閱在線資源和教程，專注於提示詞設計。\n5. 采樣器（Samplers）\n內容：比較不同采樣器的特性，學習如何選擇合適的采樣器以提升圖像質量。\n學習線索：參考官方文檔中“Samplers”部分，閱讀社區評測和使用經驗分享。\n6. 模型（Models）\n內容：了解各種模型的功能和用途，學習如何選擇和組合模型以獲得最佳效果。\n學習線索：訪問Civitai、Hugging Face等模型分享網站。\n7. ControlNet技術\n內容：了解ControlNet如何提升圖像生成精確性，學習使用邊緣檢測等技術。\n學習線索：參考官方文檔中的“ControlNet”部分及應用示例。\n無論你是藝術創作者、開發者還是對AI技術感興趣的學習者，這個ComfyUI課程都將為你打開一扇新的大門。立即報名，開始你的學習之旅，掌握這一前沿技術，創造出屬於你的獨特作品！～",
      "target_audience": [
        "數字藝術創作者",
        "開發者和程序員",
        "AI愛好者和學習者"
      ]
    },
    {
      "title": "파이썬(Python) 딥러닝(Deep Learning,DL) 프로젝트 - DNN, CNN, RNN 모델 실무",
      "url": "https://www.udemy.com/course/maso-ds-python-onc74/",
      "bio": "이제부터가 진짜 딥러닝이다! 심층신경망(DNN), 합성곱신경망(CNN), 순환신경망(RNN)을 활용해 실제 딥러닝 활용 역량을 길러보자.",
      "objectives": [
        "딥러닝 개발 과정 프로세스의 이해",
        "DNN, CNN, RNN의 구성 요소와 모델링 원리 이해",
        "Tensorflow Keras의 다양한 Framework에 대한 이해",
        "다양한 딥러닝 실습을 통한 딥러닝 알고리즘 활용 능력"
      ],
      "course_content": {
        "딥러닝 실무 개요": [
          "DLW001 딥러닝 개발 과정",
          "DLW002 코드로 알아보는 딥러닝 개발 과정",
          "DLW003 딥러닝 알고리즘의 종류",
          "DLW004 데이터 준비를 위한 데이터 전처리"
        ],
        "다중 분류 예측": [
          "DLW101 다중 분류를 위한 데이터셋 살펴보기",
          "DLW102 다중 분류 예측을 위한 데이터 탐색",
          "DLW103 다중 분류 예측 모델 설계와 실행"
        ],
        "다중선형회귀 모델": [
          "DLW201 다중선형회귀의 개념과 데이터 표준화",
          "DLW202 다중선형회귀 모델 설계와 예측",
          "DLW203 K-Fold를 이용한 교차 검증"
        ],
        "MNIST 손글씨 인식": [
          "DLW301 예측을 위한 MNIST 손글씨 데이터 살펴보기",
          "DLW302 MNIST 손글씨 데이터 전처리와 모델 정의",
          "DLW303 혼동 행렬과 학습 과정 시각화"
        ],
        "합성곱신경망(CNN)": [
          "DLW401 합성곱신경망(CNN)의 개요"
        ],
        "합성곱신경망(CNN)의 구성요소와 연산": [
          "DLW501 스트라이드, 필터와 CNN의 연산 과정",
          "DLW502 연산을 위한 풀링과 드롭아웃"
        ],
        "합성곱신경망(CNN)을 이용한 MNIST 손글씨 인식": [
          "DLW601 EarlyStopping 콜백",
          "DLW602 CNN을 이용한 MNIST 손글씨 인식",
          "DLW603 MNIST 손글씨 모델 평가와 시각화",
          "DLW604 내가 만든 모델 저장하기"
        ],
        "순환신경망(RNN)": [
          "DLW701 순환신경망(RNN)의 특징",
          "DLW702 IMDB 데이터셋을 활용한 RNN 실습"
        ],
        "LSTM": [
          "DLW801 LSTM의 원리와 특징",
          "DLW802 LSTM을 이용한 뉴스 카테고리 분류"
        ]
      },
      "requirements": [
        "본 강의는 기본적인 파이썬 활용 능력을 요구합니다.",
        "마소캠퍼스의 [파이썬(Python) 실무 데이터 분석 프로젝트] 강의들을 먼저 수강하시는걸 추천드립니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n딥러닝 본격적으로 활용해보고 싶어요!\n4차 산업혁명 시대에서는 인공지능 기술이 무엇보다 중요해지고 있습니다.\n그래서 많은 기업들 역시 AI 전문가 채용에 적극 나서고 있으며, 앞으로는 많은 직업들이 사라질 거라는 전망도 나오고 있습니다.\n물론 인간 고유의 영역이라고 여겨졌던 예술이나 창작 등에서는 AI가 아직까지 두각을 드러내지 못하고 있지만, 점차 대체되는 건 시간 문제일 겁니다.\n딥러닝 기술은 IT업계 종사자라면 누구나 해보고 싶은 기술이지만 그만큼 진입장벽이 높아 쉽게 도전하지 못하는게 현실입니다.\n때문에 딥러닝 관련 지식을 쌓아두실 수 있도록 저희 마소캠퍼스에서 본 딥러닝 강좌를 누구나 따라오실 수 있도록 설계하였습니다.\n이를 위해서는 딥러닝의 새로운 알고리즘들에 대해 배우고 익혀야합니다.\n이번 <파이썬(Python) 딥러닝(Deep Learning,DL) 프로젝트 - DNN, CNN, RNN 모델 실무> 과정은\n파이썬(Python) 언어와 텐서플로우 케라스(Tensorflow Keras) 프레임워크를 기반으로 하는 딥러닝 알고리즘 모델 개발 과정입니다.\n앞으로는 더 많은 데이터들로부터 유용한 정보를 추출할 수 있는 기술력 확보가 중요해질 것입니다.\n이러한 문제를 해결하기 위해 인공지능(AI) 기반 머신러닝/딥러닝 기술이 등장했으며, 이를 구현하는데 사용되는 주요 모델로는 지도학습 방식의 DNN, 비지도학습 방식의 CNN, 그리고 강화학습 방식의 RNN이 있습니다.\n딥러닝의 전반적인 개발 과정을 살펴보고 다양한 알고리즘으로 딥러닝 모델을 개발해보는 학습 과정을 자세히 다루며, 각 모델별 장단점 및 적용 사례 실습을 알아보고, 실제 코드를 입력하며 각 모델간 차이를 확인하고 딥러닝 알고리즘을 활용해보세요!\n\n<파이썬(Python) 딥러닝(Deep Learning,DL) 프로젝트 - DNN, CNN, RNN 모델 실무> 강의를 듣고 나면,\n여러분께서는 다음과 같은 역량을 확보하실 수 있습니다.\n딥러닝 개발 과정 프로세스의 이해\nDNN, CNN, RNN의 구성 요소와 모델의 원리 이해\nTensorflow Keras의 다양한 Framework에 대한 이해\n다양한 딥러닝 실습을 통한 딥러닝 활용 능력\n\n\n분야에 상관 없이 압도적인 생산성 향상을 가져다 주는 딥러닝!\n딥러닝의 핵심 알고리즘에 대한 상세한 설명을 통해 깊이 있는 이론과 실습을 동시에 학습하는 과정!\n\n\n-\n\n\n[ 강 사  소 개 ]\n\n\n김 진 숙\n現 마소캠퍼스 수석 교수\n컴퓨터시스템 공학 석사\n김진숙 교수는 마소캠퍼스에서 빅데이터 부분 수석 교수로 빅데이터(R, 파이썬), HTML5/CSS3, JQueryMobile, 스크래치, 앱인벤터, IoT 등의 최신 IT 관련 기술 과정들까지 다양한 기업과 기관의 수강생들을 대상으로 열정 넘치는 강의를 이어가고 있습니다. 김진숙 교수는 스마트팜 IoT 프로젝트, 카 셰어링 앱 프로젝트 등 다수 프로젝트 지도 경력까지 겸비한 전문가입니다.\n-",
      "target_audience": [
        "인공지능의 업무 활용을 시도하고 싶은 실무자",
        "IT업계로 창업/이직/입사 등 커리어를 쌓고 싶은 모든 사람",
        "사업에 인공지능을 도입하고 싶은 경영자, 실무자",
        "딥러닝 역량을 쌓기 위해 첫 단추부터 제대로 시작하고 싶은 모든 사람"
      ]
    },
    {
      "title": "(2024)-Finansal Özgürlük Anahtarı:Python ile Yatırım Analizi",
      "url": "https://www.udemy.com/course/2024-sfrdan-python-ile-finansal-yatrm-analizi-kursu/",
      "bio": "Sıfırdan Python Programlama Dili öğrenerek, öğrendiklerimizi Finansal Yatırımlarımızı optimize etmek için kullanacağız.",
      "objectives": [
        "Sifirdan Ileri Seviyeye Python Yazilim dili hakkinda bilgi sahibi olabilecekler.",
        "Ogrenilen yazilim dilini finansal verileri anlayarak en getiri orani yuksek yatirim aracina yatirim yapabilecekler.",
        "Farkli finansal yontemleri saptayip ona yatirim yapabilecekler.",
        "Kursta sadece hisse senetleri ve borsadan degil ayni zamanda farkli portfolyolerin nasil olusturulacagindan bahsediliyor."
      ],
      "course_content": {
        "Hoşgeldiniz! Kurs Hakkında": [
          "Giriş"
        ],
        "Python Programlara Dili Hakkında Tanıtım ve Bilgilendirme": [
          "Programlama ve Yazılım Dilleri Hakkında",
          "Neden Python?",
          "Neden Jupyter Notebook?",
          "Python ve Jupyter's Notebook Yükleme Rehberi",
          "Jupyter's Notebook Arayüz Tanıtımı"
        ],
        "Python'da Değişkenler ve Veri Tipleri": [
          "Değişkenler",
          "Sayılar ve Veri Tipleri",
          "String Yapıları"
        ],
        "Basit Python Syntax Yapıları": [
          "Aritmetik Operatorler",
          "Çift Eşittir İşareti ve İşlevi",
          "Yeniden Değer Atama",
          "Yorum Ekleme",
          "Satır Atlama ve Indexing"
        ],
        "Operatorler": [
          "Karsılastırmalı Operatorler",
          "Mantıksal Sınamalar"
        ],
        "Kosullu Ifadeler": [
          "IF Kosulu",
          "ELIF Kosulu",
          "ELSE Kosulu"
        ],
        "Python'da Fonksiyonlar": [
          "Python'da Fonksiyonun Tanımı",
          "Python'da Fonksiyon Oluşturma",
          "Fonksiyon Tanımlamanın Başka Bir Yolu",
          "Bir Fonksiyonu Başka Bir Fonksiyonda Kullanma",
          "Koşullu İfadeler ve Fonksiyonlar ile Birleştirme",
          "Python'da Önemli Fonksiyonlar"
        ],
        "Python'da Dizi Yapilari": [
          "Listeler",
          "Listeler - II",
          "Python Liste Dilimleme Yöntemi",
          "Demetler (Tuples)",
          "Sözlükler"
        ],
        "Python'da Dongu Yapilari": [
          "For Döngüsü",
          "While Dongusu",
          "range() Fonksiyonu ile Listeler Oluşturma",
          "Hepsi-Bir-Arada - Koşullu İfadeler, Fonksiyonlar ve Döngüler",
          "Sözlükler Üzerinden Döngü Yapısı"
        ],
        "Ileri Seviye Python Araclari ve Dersleri": [
          "Nesne Tabanlı Programlama",
          "Moduller ve Paketler",
          "Modülleri Dahil Etmek ve Standart Kütüphaneler",
          "Veri Bilimi ve Finans Modülleri",
          "Array Yapıları",
          "Rastgele Modulu",
          "Verileri Import Edip Organize Etme - I",
          "Verileri Import Edip Organize Etme - II",
          "Zaman Serilerini Değiştirme"
        ]
      },
      "requirements": [
        "Programlama ve Finans alanina merakli olmak bu kurs icin yeterlidir. Kalan herseyi kurs icinde ogreneceksiniz."
      ],
      "description": "Finansal piyasalarda başarılı olmak için doğru yatırımları yapmak gerekir. Bu da finansal verileri doğru analiz etmeyi gerektirir. Python, finansal veri analizi için oldukça güçlü bir araçtır.\nPython ile Finansal Yatırım Analizi Kursu, Python'u kullanarak finansal veri analizi yapmayı öğrenmek isteyenler için tasarlanmıştır. Kurs, temel Python programlama bilgisinden başlayarak, finansal analiz için önemli olan kavramları ve teknikleri öğretir.\nKurs, aşağıdaki konuları kapsar:\nTemel Python programlama\nFinansal veri analizi için temel kavramlar\nTeknik analiz\nTemel istatistik\nMakine öğrenimi\nKurs, video dersler ve projeler şeklinde sunulur. Video dersler, konuların teorik ve pratik yönlerini kapsar.\nKursu tamamlayarak, aşağıdaki becerileri kazanacaksınız:\nPython'u kullanarak finansal veri analizi yapmayı öğreneceksiniz.\nTeknik analiz ve temel istatistik tekniklerini kullanabileceksiniz.\nYaygın finansal tekniklerini kullanarak finansal verilerden anlamlı bilgiler çıkarabileceksiniz.\nİstatistiksel teorileri öğrenip Python'da da kullanabileceksiniz.\nDünyadaki tüm endekslerin getirilerini hesaplayabileceksiniz.\nBETA Kavramını ve önemini anlayabileceksiniz.\nPython ile Finansal Yatırım Analizi Kursu, finansal piyasalarda başarılı olmak isteyenler için oldukça değerli bir kurstur. Kurs, finansal veri analizi konusundaki bilginizi ve becerilerinizi geliştirmenize yardımcı olacaktır.\nVeri Bilimi ile İlişki\nVeri bilimi, veri toplama, temizleme, analiz etme ve yorumlama ile ilgilenen bir disiplindir. Finansal veri analizi, veri biliminin bir alt dalıdır.\nPython, veri bilimi için oldukça popüler bir araçtır. Python'un güçlü veri analizi özellikleri, finansal veri analizi için de idealdir.\nPython ile Finansal Yatırım Analizi Kursu, veri bilimi ile de yakından ilişkilidir. Kurs, veri biliminin temel kavramlarını ve tekniklerini de kapsar.\nKurs, finansal veri analizi konusunda bilgi ve beceri kazanmak isteyenler için olduğu kadar, veri bilimine ilgi duyanlar için de faydalı olacaktır.",
      "target_audience": [
        "Programlamaya merakli ve bu merak duygusunu finansal bilgiyle kullanmak isteyen kisiler icin yeterli bir kurstur."
      ]
    },
    {
      "title": "Midjourney × GEN2で革新的なAI動画を生成しよう【初心者向け生成AI入門コース】",
      "url": "https://www.udemy.com/course/midjourney-gen2/",
      "bio": "MidjourneyとRunwayのGEN2を使った静止画からAI動画を生成する方法について学びます。静止画やテキストから動画を生成する技術(img2mov・tex2mov)を身につけ、自分だけのオリジナルAI動画が作るれるようになります。",
      "objectives": [
        "MidjourneyとRunwayのGEN2についての基本的な知識を学びます。",
        "テキストから動画を生成する技術、img2movやtex2movを学びます。",
        "MidjourneyとRunwayのGEN2を使って自分だけのオリジナルAI動画を生成する方法を学びます。",
        "AI動画生成の際のコツや、より高品質な動画を生成するためのテクニックを学びます。",
        "AI動画生成におけるトラブルシューティングや法的考慮事項について学びます。",
        "AI動画生成技術の未来やその可能性について考察します。"
      ],
      "course_content": {
        "紹介": [
          "はじめに",
          "MidjourneyとRunwayについて",
          "Midjourneyの登録、Discordの設定について",
          "Runwayの登録",
          "Midjourneyで動画向け画像を生成",
          "Runwayで静止画を動画にする",
          "Midjourneyの応用",
          "AI動画のサンプル例",
          "AI動画のトラブルシューティング",
          "AI動画の法的考慮事項",
          "AI動画の未来",
          "さいごに"
        ]
      },
      "requirements": [
        "プログラミング知識や経験は必要ありません。",
        "初心者向けにわかりやすく説明していますので、AIや動画生成についての知識は必要ありません。",
        "ネットにつながるパソコンがあれば大丈夫です。",
        "AI動画生成に興味がある方向けのコースです。"
      ],
      "description": "このコースでは、MidjourneyとRunwayのGEN2を使ったAI動画生成について学びます。テキストや静止画から動画を生成するimg2mov(image2video)やtex2mov(text2video)などの技術を使い、自分だけのオリジナルなAI動画を作成するスキルを身につけることができます。初心者向けにわかりやすく解説しています。各種登録から生成手順、生成AIにおけるポイントや注意点など細かく説明していきます。このコースを通じて、自分だけのAI動画を生成する楽しさとAI技術の可能性を体験できます。",
      "target_audience": [
        "AI動画生成に興味がある方",
        "MidjourneyとRunwayのGEN2を使った生成AIに興味がある方",
        "自分だけのオリジナルAI動画を作りたい方",
        "テキストから動画を生成する技術、img2movやtex2movに興味がある方",
        "AI動画生成を応用して自分好みの動画を作りたい方",
        "AIや機械学習を用いた新しい生成技術を体験したい初心者の方",
        "AI動画の作成方法を学びたい方"
      ]
    },
    {
      "title": "【한글자막】 기초부터 배우는 Python 인공 신경망 : 완벽가이드",
      "url": "https://www.udemy.com/course/best-python-neural-networks/",
      "bio": "Python 에서 Deep Learning을 활용하여 인공 신경망을 구현하기 위한 기초지식을 이론부터 실습까지 모두 배워봅시다!",
      "objectives": [
        "인공 신경망과 관련된 모든 수학 연산을 차근차근 학습",
        "사전 기반 없이 파이썬과 넘파이를 이용해 인공 신경망을 구현하는 법",
        "퍼셉트론, 활성화 함수, 역전파, 경사 하강법, 학습률과 같은 기본 개념",
        "분류와 회귀분석을 수행할 수 있는 인공 신경망을 구현하는 법",
        "Pybrain, sklearn, TensorFlow, Pytorch와 같은 주요 라이브러리를 사용해 인공 신경망 구현하는 법"
      ],
      "course_content": {
        "소개": [
          "소개와 강의 구성",
          "준비물 가져오기"
        ],
        "단층 퍼셉트론": [
          "공격 계획",
          "인공 신경망 애플리케이션",
          "생물학적 기초",
          "인공 신경",
          "퍼셉트론",
          "퍼셉트론 구현 1",
          "퍼셉트론 구현 2",
          "가중치 갱신 1",
          "가중치 갱신 2",
          "퍼셉트론 구현 3",
          "퍼셉트론 구현 4",
          "퍼셉트론 구현 5",
          "추가 읽기",
          "Single layer perceptron",
          "숙제 설명",
          "숙제 해설"
        ],
        "다층 퍼셉트론": [
          "공격 계획",
          "다층 신경망 소개",
          "활성화 함수",
          "시그모이드 함수 구현",
          "은닉층 활성화 1",
          "은닉층 활성화 2",
          "다층 퍼셉트론 구현 1",
          "다층 퍼셉트론 구현 2",
          "출력층 활성화",
          "다층 퍼셉트론 구현 3",
          "오류 계산 (손실함수)",
          "다층 퍼셉트론 구현 4",
          "기본 알고리즘",
          "기울기 하강과 도함수",
          "다층 퍼셉트론 구현 5",
          "출력층 델타",
          "다층 퍼셉트론 구현 6",
          "은닉층 델타",
          "다층 퍼셉트론 구현 7",
          "오차역전파와 학습률",
          "가중치 업데이트 및 오차역 전파 1",
          "다층 퍼셉트론 구현 8",
          "가중치 업데이트 및 오차역 전파 2",
          "다층 퍼셉트론 구현 9",
          "다층 퍼셉트론 구현 10",
          "아이리스 데이터 집합",
          "바이어스와 오류, 다중 출력",
          "은닉층",
          "범주형 데이터가 포함된 출력층",
          "확률적 경사하강법",
          "딥러닝",
          "추가 읽기",
          "숙제 설명",
          "Multi-layer perceptron",
          "숙제 해설"
        ],
        "신경망 라이브러리": [
          "공격 계획",
          "파이브레인 1",
          "파이브레인2",
          "숙제 설명: 아이리스 데이터 집합",
          "숙제 해설",
          "분류를 위한 사이킷런 1",
          "분류를 위한 사이킷런 2",
          "분류를 위한 사이킷런 3",
          "회귀를 위한 사이킷런",
          "숙제 설명: 와인 분류",
          "숙제 해설",
          "이미지 분류를 위한 텐서플로우 1",
          "이미지 분류를 위한 텐서플로우 2",
          "이미지 분류를 위한 텐서플로우 3",
          "숙제 설명: 패션 MNIST 분류",
          "숙제 해설",
          "분류를 위한 파이토치 1",
          "분류를 위한 파이토치 2",
          "분류를 위한 파이토치 3",
          "숙제 설명: 당뇨병 분류",
          "숙제 해설",
          "마지막 말"
        ],
        "축하합니다!! 상품을 잊지 마세요 :)": [
          "보너스: 최고 연봉을 잠금 해제하는 방법(실시간 교육)",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "프로그래밍 지식 (if, while과 for문)",
        "파이썬 기초 프로그래밍 지식",
        "인공 신경망이나 인공지능과 관련된 사전 지식은 전혀 필요 없음"
      ],
      "description": "초보자도 이해하는 인공 신경망 완벽 가이드!\n퍼셉트론, 활성화 함수, 다층 신경망, 역전파, 경사 하강법 알고리즘 등 포함!\n파이썬으로 배우는 인공 신경망!\n\n\n기초부터 배우는 Python 인공 신경망 : 완벽가이드 를 선택해야 하는 이유\n인공 신경망 기술은 현재 가장 효율적인 머신 러닝 기술로 여겨집니다. 구글, IBM, 마이크로소프트와 같은 회사에서 인공 신경망을 기상천외한 방법으로 응용하고 있죠. 여러분도 아마 자율주행 자동차나 자동으로 노래, 시, 이미지에 영화 시나리오까지 제작하는 앱에 대해서 들어 보셨을 겁니다. 한 가지 흥미로운 사실은 이 모든 것은 대부분 인공 신경망 기술을 써서 개발되었다는 건데요. 인공 신경망 기술은 기존에 사용되고 있긴 했으나, 딥러닝의 등장과 함께 더욱 강력해졌고, 이제 데이터 분석에 있어서 가장 뛰어난 기술로 평가받고 있습니다.\n\n\n이제 막 인공 신경망을 공부하는 학생들이 맞이하는 가장 큰 문제점은 쉽게 이해할 수 있는 강의가 적다는 건데요, 이는 시중에서 구할 수 있는 교재가 대부분 매우 학술적으로 작성되었고 수학 공식을 많이 사용해서 해당 분야를 공부하고 싶은 초심자에게 매우 어렵기 때문입니다. 이를 염두에 두고 해당 강의는 여러분이 인공 신경망에 대해 아무것도 몰라도 전 과정을 이해할 수 있게 인공 신경망과 관련된 이론적이고 수학적인 개념을 이해하기 쉬우며 동시에 철저하게 가르치고자 합니다.\n우리는 퍼셉트론, 활성화 함수, 다층 신경망, 역전파, 경사 하강법 알고리즘과 같은 개념을 배울 건데, 이를 통해 여러분은 인공 신경망이 구현되는 과정을 이해하기 위한 기반을 구축하게 됩니다. 또 인공 신경망을 단계별로 구현하는 과정에서 현재 데이터 과학계에서 가장 인기 있는 프로그래밍 언어인 파이썬을 이용할 것입니다. 여기서 중요한 점은 단계별 구현에 있어 머신 러닝에 전문화된 파이썬 라이브러리를 사용하지 않는다는 것인데, 왜냐하면 이 강의의 목표는 여러분이 기초부터 인공 신경망을 구현하는데 필요한 모든 연산을 이해하는 것이기 때문입니다.\n\n\n한마디로 이 강의는 여러분께서 딥러닝을 배우는 데 첫걸음을 내디딜 때 필요한 모든 걸 제공해드립니다. 또 하나 유의할 점은 이 강의는 인공 신경망에 대해 이제 막 알아가는 분들을 대상으로 하고 있다는 겁니다. 모든 설명은 의도적으로 느리게 이루어지며, 모든 단계를 철저히 다뤄서 여러분께서 해당 내용을 최대한 많이 이해하도록 교육해드릴 것입니다. 만약 인공 신경망에 대해 이미 잘 알고 계신다면, 이 강의를 통해 몇몇 중요한 개념을 복기하고 복습하는데 있어 도움이 될 것입니다.\n\n\n기초부터 배우는 Python 인공 신경망 : 완벽가이드 세부 커리큘럼\n인공 신경망과 관련된 모든 수학 연산을 차근차근 학습\n사전 기반 없이 파이썬과 넘파이를 이용해 인공 신경망을 구현하는 법\n퍼셉트론, 활성화 함수, 역전파, 경사 하강법, 학습률과 같은 기본 개념\n분류와 회귀분석을 수행할 수 있는 인공 신경망을 구현하는 법\nPybrain, sklearn, TensorFlow, Pytorch와 같은 주요 라이브러리를 사용해 인공 신경망 구현하는 법\n\n\nLigency Team의 한마디!\n한국 수강생 여러분들, 안녕하세요?\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n새로운 경력을 향해 첫 발걸음을 내디딜 준비가 되었나요?\n모두 강의에서 만나요!\n\n\n- Ligency Team",
      "target_audience": [
        "인공 신경망이나 딥러닝에 대해 처음 공부하는 초심자",
        "인공지능과 관련된 분야에서 공부하는 대학생",
        "인공지능이나 인공 신경망에 관심을 가진 사람이면 누구나"
      ]
    },
    {
      "title": "Transformer Modelle und Deep Learning",
      "url": "https://www.udemy.com/course/transformer-modelle-und-deep-learning/",
      "bio": "Integration von Encoder-Decoder Modellen mithilfe von Hugging Face und Fastai für Natural Language Understanding",
      "objectives": [
        "Du lernst, wie du Transformer Modelle wie BERT oder GPT2 für NLP Aufgaben verwendest.",
        "Transfer Learning mithilfe von vortrainierten Modell im Deep Learning umsetzen",
        "Wie kann künstliche Intelligenz mithilfe von Encoder / Decoder Modellen Texte generieren?",
        "Was sind Transfomer Modell Architekturen?",
        "Wie können wir die fastai Bibliothek einsetzen, um Transformer Modell Architekturen zu integrieren?",
        "Der Hugging Face Modell Zoo",
        "Eigene vortrainierten Modelle via Hugging Face Hub zu Verfügung stellen."
      ],
      "course_content": {
        "Einführung": [
          "Einführung"
        ],
        "Basiswissen Transformer Modelle für Deep Learning": [
          "Wie funktionieren Transformer Modelle?",
          "Modellarchitekturen von Transformer Modellen im Deep Learning",
          "Transformer Modelle Code Walk-Through"
        ],
        "Die Pipeline Bibliothek zur Anbindung von Transformer Modellen": [
          "Einführung in die Pipeline Bibliothek",
          "Pipeline API",
          "Pipeline API Code Walkthrough"
        ],
        "Integration von Hugging Face Modellen mithilfe von Blurr": [
          "Hugging Face Modelle mithilfe von blurr anbinden",
          "Hugging Face Modelle und Blurr - Code Walkthrough"
        ],
        "Fast Hugs": [
          "Fast Hugs Intro",
          "Fast Hugs Code Walkthrough 1",
          "Fast Hugs Code Walkthrough 2"
        ],
        "Hugging Face Model Zoo": [
          "Hugging Face Model Hub"
        ],
        "Outro": [
          "Transformer Modelle für fastai - Outro"
        ]
      },
      "requirements": [
        "Grundlegendes Verständnis für Deep Learning Architekturen",
        "Basisprogrammierkenntnisse in Python",
        "Basiskenntnisse aus PyTorch / fastai"
      ],
      "description": "Dieser Kurs beschäftigt sich mit dem Thema Encoder-Decoder-Modellarchitekturen im Deep Learning und darauf basierenden Anwendungsfällen im Bereich Natural Language Understanding.\nWir besprechen, wie Encoder-Decoder Modelle (insbesondere Transformer Modelle wie GPT2 oder BERT-Architekturen) aufgebaut sind und welche Schritte während des Trainings eines solchen Modells ablaufen.\nDer große Nutzen dieser vortrainierten Modellarchitekturen besteht in der Anwendung des Transfer-Learning Konzepts. Das bedeutet, wir können uns riesige, vortrainierte Modellarchitekturen zu Nutze machen und mit relativ wenig Aufwand für unseren konkreten Anwendungsfall trainieren.\nWie können wir mittel one-shot-classification Texte einer bestimmten Kategorie zuordnen?\nWie integrieren wir Modelle aus dem Hugging Face Projekt in unsere eigenen Deep Learning Projekt auf Basis der fastai Bibliothek?\nNeben dem theoretischen Input entwickeln wir anhand von Jupyther Notebooks Anwendungsbeispiele und gehen den implementierten Code unserer KI-Anwendungen Schritt für Schritt gemeinsam durch.\nLernziele Transformer Modelle, Deep Learning und fastai\nFolgende Lernziele verfolgen wir mit dem Kurs Transformer Modelle (Encoder/Decoder Architekturen) und Deep Learning:\n- Du lernst das erforderliche theoretische Basiswissen, um Transformer Modellarchitekturen im Deep Learning zu verstehen.\n- Du kannst das Funktionsprinzip von Transformer Modellen wie BERT oder GPT2 verstehen.\n- Du lernst, wie du Transformer Modelle in fastai Projekt integrieren kannst\n- Du lernst verschiedene Bibliotheken wie `Blurr` oder `FastHugs` kennen.\n- Mithilfe von Bibliotheken integrieren wir vortrainierte Transformermodelle mittels Hugging-Face und fastai Framework.\n\n\n\"Transformers (früher bekannt als pytorch-transformers und pytorch-pretrained-bert) bietet Allzweckarchitekturen (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet…) für Natural Language Understanding (NLU) und Natural Language Generation (NLG) mit über 32+ vortrainierten Modellen in über 100 Sprachen und umfassender Interoperabilität zwischen Jax, PyTorch und TensorFlow.\" (Quelle: huggingface)\nWir zeigen in diesem Kurs, wie wir Transformer (Encoder / Decoder) Modelle aus dem Hugging Face Model Zoo mithilfe von verschiedenen Bibliotheken in das fastai Framework integrieren können.\nInsbesondere die Erfolge von künstlicher Intelligenz und Deep Learning im Bereich der Textanalyse und Textgenerierung ist den Transformer Modellarchitekturen zu verdanken. Modellnamen wie BERT oder GPT2 sind wohl allen ein Begriff.\nIn diesem Kurs präsentieren wir verschiedene Bibliotheken und Projekte, die es uns ermöglichen, vortrainierte Modelle via Hugging Face Model Hub gemeinsam mit der fastai Bibliothek einsetzen können.\nDas Transformer Modell stellt im Wesentlichen eine Serie von hintereinander verknüpften Encodern dar. Ein Embedding Layer ist für die Tranformation der Eingabedaten in eine Vektorrepräsentation verantwortlich. Die Weights dieser Schicht werden während des Trainings angepasst.\nNachdem die Eingabedaten durch den Embedding Layer in eine Vektorrepräsentation übergeführt worden sind, erstellt das Modell eine interne Repräsentation. Der Decoding Layer ist dann wiederum für die Überführung der internen Repräsentation im Modell in die Ergebnisschicht verantwortlich.\nUnterschiedliche Längen der Eingabesequenzen werden durch Padding-Mechanismen angepasst.\nZusätzlich wurden in den Encoder / Decoder Modellen Attention Layer eingeführt.",
      "target_audience": [
        "Du lernst in diesem Kurs, wie du vortrainierte Modelle von HuggingFace nun auch mit dem fastai Deep Learning Framework einsetzen kannst."
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第14部 ComfyUI 進階版 - 製作商業產品廣告海報",
      "url": "https://www.udemy.com/course/generative_ai_14/",
      "bio": "關於Advertise，ComfyUI，IPAdapter，IC-Light，Ollama，Concatenate Prompt，",
      "objectives": [
        "學會如何使用ComfyUI結合商業產品流程",
        "將學會如何添加細節，讓圖片更加專業和吸引眼球",
        "學習如何分離Image & Mask，讓工作流程更加流暢",
        "提升廣告設計質感，滿足高端需求"
      ],
      "course_content": {
        "課程準備": [
          "什麼是Image Generation圖片生成",
          "如何使用ComfyUI",
          "如何在iMac電腦上安裝ComfyUI",
          "如何創建第一個ComfyUI工作流"
        ],
        "如何在ComfyUI中實現產品摳圖調色與調整位置": [
          "如何在ComfyUI中摳圖或去除圖片背景",
          "如何更靈活地控制物件在廣告圖片中的位置",
          "如何設定背景分辨率及分離Image&Mask"
        ],
        "如何使用Ollama, IC-Lighting, IP-Adapter": [
          "如何使用IPAdapter以及Atten Mask",
          "如何連結多個IPAdapter使用",
          "如何使用Ollama設定Concatenate Prompt",
          "如何為廣告海報添加細節"
        ],
        "如何使用Mask控制光源": [
          "如何控制產品海報光源"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "掌握ComfyUI，成為創意設計大師！\n您是否想製作高品質、吸睛的產品廣告海報，但又不知道從哪裡開始？這門課程將帶您從零到專業，全面掌握 ComfyUI 的強大功能，快速提升您的創意設計技能！\n課程亮點\n學會如何使用IPAdapter及Atten Mask\n精確控制圖片細節，實現高水準廣告設計。\n圖片摳圖與背景去除\n解鎖去背技巧，輕鬆製作清晰專業的產品圖片。\n靈活控制物件位置與光源\n完美配置圖像元素，讓您的產品成為視覺焦點。\n創建專屬ComfyUI工作流\n從安裝到實踐，系統學習，適合初學者和進階用戶。\n如何使用Ollama設定Concatenate Prompt\n發揮更精細的創意控制，實現多樣化的圖片生成。\n學習成果\n創作細節豐富的廣告海報：您將學會如何添加細節，讓圖片更加專業和吸引眼球。\n高效處理圖片與背景：學習如何分離Image & Mask，讓工作流程更加流暢。\n打造高分辨率廣告背景：提升廣告設計質感，滿足高端需求。",
      "target_audience": [
        "對AI生成圖像技術感興趣的創作者",
        "想提升廣告設計技能的市場營銷人員",
        "需要快速製作產品海報的自由職業者",
        "希望學習如何在iMac上使用ComfyUI的設計師"
      ]
    },
    {
      "title": "Reinforcement Learning Avanzado: de DQN a SAC",
      "url": "https://www.udemy.com/course/reinforcement-learning-dqn-a-sac/",
      "bio": "Crea agentes inteligentes con Deep Reinforcement Learning y PyTorch: DDPG, TD3, SAC, NAF, HER.",
      "objectives": [
        "Dominar algunos de los algoritmos más avanzados del Reinforcement Learning",
        "Aprende a crear inteligencias artificiales que puedan actuar en un entorno complejo para alcanzar sus objetivos.",
        "Crea desde cero agentes avanzados de Aprendizaje por Reforzamiento utilizando las herramientas más populares de Python (PyTorch Lightning, Gym, Brax, Optuna)",
        "Aprende a realizar ajuste de hiperparámetros (selección de las mejores condiciones experimentales para que nuestra inteligencia artificial aprenda).",
        "Comprende fundamentalmente el proceso de aprendizaje de cada algoritmo.",
        "Depurar y extender los algoritmos presentados.",
        "Comprende e implementa nuevos algoritmos a partir de artículos de investigación."
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Serie de Reinforcement Learning",
          "Google Colab",
          "Dónde empezar",
          "Código completo",
          "Conecta conmigo en redes sociales"
        ],
        "Repaso: El proceso de decisión de Markov (MDP)": [
          "Visión general del módulo",
          "Elementos comunes a todas las tareas de control",
          "El proceso de decisión de Markov (PDM)",
          "Tipos de proceso de decisión de Markov",
          "Trayectoria y episodio",
          "Recompensa vs retorno",
          "Factor de descuento",
          "Política",
          "Valor de un estado v(s) y valor de un estado-acción q(s,a)",
          "Ecuaciones de Bellman",
          "Resolver un proceso de decisión de Markov"
        ],
        "Repaso: Q-Learning": [
          "Visión general del módulo",
          "Métodos de diferencias temporales (TD)",
          "Resolver tareas de control con métodos de diferencias temporales",
          "Q-Learning",
          "Ventajas de los métodos de diferencias temporales"
        ],
        "Repaso: Breve introducción a las redes neuronales": [
          "Visión general del módulo",
          "Aproximadores de funciones",
          "Redes neuronales artificiales",
          "Neuronas artificiales",
          "Cómo representar una red neuronal",
          "Descenso gradiente estocástico (SGD)",
          "Optimización de redes neuronales"
        ],
        "Repaso: Deep Q-Learning": [
          "Visión general del módulo",
          "Deep Q-Learning",
          "Repetición de experiencia (experience replay)",
          "Red target (target network)"
        ],
        "PyTorch Lightning": [
          "PyTorch Lightning",
          "Enlace a la libreta de código",
          "Introducción a PyTorch Lightning",
          "Crear la Deep Q-Network",
          "Crear la política",
          "Crear la memoria de repetición",
          "Crear el entorno",
          "Definir la clase para el algoritmo Deep Q-Learning",
          "Definir la función 'play_episode'",
          "Preparación del 'data loader' y el optimizador",
          "Definir la función 'train_step'",
          "Definir la función 'train_epoch_end'",
          "[Importante] Corrección de la lección",
          "Entrenar el algoritmo Deep Q-Learning",
          "Explorar el agente resultante"
        ],
        "Ajuste de hiperparámetros con Optuna": [
          "Ajuste de hiperparámetros con Optuna",
          "Link a la libreta de código",
          "Registro del retorno promedio",
          "Definición de la función objetivo",
          "Creación y lanzamiento del ajuste de hiperparámetros",
          "Exploración del mejor ensayo"
        ],
        "Deep Q-Learning para espacios de acción continuos (NAF)": [
          "Espacios de acciones contínuos",
          "La función ventaja",
          "Función de ventaja normalizada (NAF)",
          "Pseudocódigo de NAF",
          "Link a la libreta de código",
          "Tangente hiperbólica",
          "Creación de la red NAF - Parte 1",
          "Creación de la red NAF - Parte 2",
          "Creación de la red NAF - Parte 3",
          "Creación de la red NAF - Parte 4",
          "Creación de la política",
          "Creación del entorno",
          "Media de Polyak",
          "Implementación de la media de Polyak",
          "Creación del algoritmo Deep Q-Learning con NAF",
          "Implementación de la función 'training_step'",
          "Implementación de la lógica de final de época",
          "Depurado y lanzamiento del algoritmo",
          "Testeando el agente resultante"
        ],
        "Repaso: métodos de política gradiente (o gradiente de políticas)": [
          "Métodos de política gradiente",
          "Rendimiento de la política",
          "Representación de políticas con redes neuronales",
          "Teorema del gradiente de políticas",
          "Regularización mediante entropía"
        ],
        "Deep Deterministic Policy Gradient (DDPG)": [
          "El motor de física Brax",
          "Introducción a Deep Deterministic Policy Gradient (DDPG)",
          "Pseudocódigo de DDPG",
          "Link a la libreta de código",
          "Importante - Actualización del código",
          "Deep Deterministic Policy Gradient (DDPG)",
          "Creación de la política",
          "Creación de la política - Corrección",
          "Creación de la Deep Q-Network",
          "Creación de la clase DDPG",
          "Definición del método 'play'",
          "Definición del método 'play' - Corrección",
          "Preparación de los optimizadores y 'dataloaders'",
          "Definición del método 'training_step'",
          "Definición del método 'training_step' - Corrección",
          "Lanzamiento del proceso de entrenamiento",
          "Testeando el agente resultante"
        ]
      },
      "requirements": [
        "Conocer las bases de la programación en Python",
        "Completar nuestro curso \"Reinforcement Learning de principiante a maestro\" o estar familiarizado con los conceptos básicos del Aprendizaje por Reforzamiento (o ver las secciones introductorias incluidas en este curso).",
        "Conocer estadísticas básicas (media, varianza, distribución normal)."
      ],
      "description": "Este es el curso más completo de Aprendizaje por Reforzamiento Avanzado en Udemy. En él, aprenderás a implementar algunos de los algoritmos de Deep Reinforcement Learning más potentes en Python utilizando PyTorch y PyTorch Lightning. Implementarás desde cero algoritmos adaptativos que resuelven tareas de control basadas en la experiencia. Aprenderás a combinar estas técnicas con Redes Neuronales y métodos de Aprendizaje Profundo para crear agentes de Inteligencia Artificial adaptativos capaces de resolver tareas de toma de decisiones.\n\n\nEste curso te introducirá al estado del arte en técnicas de Reinforcement Learning. También te preparará para los próximos cursos de esta serie, donde exploraremos otros métodos avanzados que sobresalen en otros tipos de tareas.\n\n\nEl curso se centra en el desarrollo de habilidades prácticas. Por lo tanto, después de aprender los conceptos más importantes de cada familia de métodos, implementaremos uno o más de sus algoritmos en cuadernos Jupyter, desde cero.\n\n\nMódulos de nivelación:\n\n\n- Repaso: El proceso de decisión de Markov (MDP).\n- Repaso: Q-Learning.\n- Repaso: Breve introducción a las Redes Neuronales.\n- Repaso: Deep Q-Learning.\n- Repaso: Métodos de gradiente de políticas.\n\n\n\n\nDeep Reinforcement Learning:\n\n\n- PyTorch Lightning.\n- Ajuste de hiperparámetros con Optuna.\n- Deep Q-Learning para espacios de acción continuos (Función de ventaja normalizada - NAF).\n- Deep Deterministic Policy Gradient (DDPG).\n- Twin Delayed DDPG (TD3).\n- Soft Actor-Critic (SAC).\n- Repetición de Experiencia con Perspectiva (HER).",
      "target_audience": [
        "Desarrolladores que deseen conseguir un empleo en el campo del Machine Learning.",
        "Científicos/analistas de datos y profesionales del Machine Learning que buscan ampliar sus conocimiento.",
        "Estudiantes e investigadores de robótica.",
        "Estudiantes e investigadores de ingeniería."
      ]
    },
    {
      "title": "Python & Deep Learning & IA : reconnaissance d'images",
      "url": "https://www.udemy.com/course/deeplearning-classification-dimages-avec-tensorflow/",
      "bio": "Deep learning + projets de classification d'image(chien vs chat,...) en utilisant les réseaux de neurones convolutifs",
      "objectives": [
        "apprendre la classification d'image binaire et multi classes avec les réseaux de neurones",
        "créer des réseaux de neurones profonds(DNN)",
        "découvrir et comprendre la convolution",
        "découvrir et maitrisez les réseaux de neurone convolutifs (CNN)",
        "comprendre et appliquer l'apprentissage par transfert",
        "utiliser l'environnement de programmation google colab",
        "apprendre à utiliser tensorflow et keras pour le deeplearning",
        "comprendre c'est quoi la vision par ordinateur et ses applications",
        "maitrisez numpy et matplotlib pour l'analyse de donnée",
        "comprendre l'algorithme du gradient descendant pour l'optimisation"
      ],
      "course_content": {
        "librairies de bases": [
          "créer des tableaux en numpy",
          "opérations sur les tableaux en numpy",
          "indexation et slicing des tableaux en numpy",
          "tracer des courbes avec matplotlib",
          "les sous-courbes en matplotlib",
          "manipulez les images avec numpy et matplotlib"
        ],
        "introduction au deep learning": [
          "introduction a l'ia / machine learning / deep learning",
          "le perceptron ( théorie)",
          "exemple théorique sur le perceptron",
          "l'algorithme du gradient descendant"
        ],
        "###PROJET 1 : le perceptron par la pratique": [
          "perceptron en pratique part 1",
          "perceptron en pratique part 2",
          "perceptron en pratique part 3"
        ],
        "###PROJET 2 : fashion mnist avec un réseau de neurone profond": [
          "découverte de la base de donnée fashion-mnist et création du modèle",
          "entrainement du modèle et prédiction"
        ],
        "réseau de neurone convolutif (CNN)": [
          "introduction au réseau de neurone convolutif (CNN,CONVNET)",
          "filtre de convolution",
          "la couche de pooling",
          "application du cnn à la fashion-mnist"
        ],
        "###PROJET 3 : chien vs chat": [
          "exploration de la base de donnée chien vs chat",
          "traitement des images de la bd (image data generator)",
          "simple CNN sur la bd chien vs chat",
          "augmentation d'image part 1",
          "augmentation d'image part 2",
          "chien vs chat avec un cnn et l'augmentation d'image",
          "prédiction avec des nouvelles images",
          "comment enregistrer notre modèle pour le deployer",
          "apprentissage par transfert"
        ]
      },
      "requirements": [
        "avoir des bases en python"
      ],
      "description": "Cette formation vous permettra de comprendre la vision par ordinateur en classifiant des images.\nDonc nous allons découvrir les concepts théoriques et pratiques sur le deep learning, les réseaux de neurones, les réseaux de neurones convolutifs et nous allons réaliser 3 principaux projets :\n1 - coder un perceptron de zéro: qui vous permettra de comprendre comment un modèle de deep learning marche, car nous allons coder un perceptron (réseau de neurone à une seule couche) sans utiliser tensorflow\n2 - classification d'images multi classes : nous allons classifier des images d'articles de modes(sac, sandale, sneaker, tee-shirt etc..) en 10 classes différentes avec la base de donnée fashion-mnist et cette fois si avec tensorflow et keras et les réseaux de neurones convolutifs(nous obtiendrons une précision de 96%)\n3 - classification d'images binaire : nous allons classifier des images de chats et de chien avec une base de données de 3000 photos de chien et de chat. dans ce dernier projet nous allons apprendre plusieurs techniques comme l'augmentation d'image, et l'apprentissage par transfert.\nAvec les connaissances acquises dans ce cours vous allez pouvoir classifier n'importe qu'elle catégorie d'image et vous allez pouvoir vous lancez dans d'autres applications de la vision par ordinateur tels que la reconnaissance faciale, la détection d'émotion etc...",
      "target_audience": [
        "développeurs python débutant qui veulent découvrir le deep learning",
        "passionnez de la vision par ordinateur(reconnaissance faciale, classification d'image…)",
        "des personnes voulant comprendre les réseaux de neurones convolutifs (CNN)",
        "personnes voulant devenir data scientist"
      ]
    },
    {
      "title": "『Rの基礎から機械学習まで一気に学ぼう！』 | R言語 Rstudio講座",
      "url": "https://www.udemy.com/course/r-r-rstudio/",
      "bio": "基本から回帰分析、母平均検定、k近傍法による機械学習まで",
      "objectives": [
        "R言語の基礎",
        "Rでデータ分析する方法",
        "Rで機械学習を行う方法",
        "Rstudioの基本的な操作方法"
      ],
      "course_content": {
        "必要なソフトのインストール": [
          "Rのインストール",
          "R言語のインストール",
          "Rstudioのインストール"
        ],
        "シンボル、オブジェクトの利用": [
          "シンボルとは",
          "シンボルの使い方",
          "ベクトルとは",
          "ベクトルの利用"
        ],
        "基本構文": [
          "基本構文",
          "条件分岐の実演",
          "おまけ",
          "演算子の利用",
          "繰り返し分",
          "繰り返し分の記述法"
        ],
        "関数": [
          "関数の紹介",
          "関数の実演"
        ],
        "データ分析、検定": [
          "CSVデータの読み込み",
          "回帰分析とは",
          "データのダウンロード",
          "データの前処理",
          "ダウンロードしたデータの読み込み",
          "回帰分析の実行",
          "実行結果の見方",
          "母平均検定の紹介"
        ],
        "機械学習": [
          "機械学習の概要",
          "データセットの利用",
          "品種の数値変換",
          "データ分割",
          "分類を行う"
        ]
      },
      "requirements": [
        "Windows"
      ],
      "description": "Windows推奨(Macでも問題なく受講できます)\n\n\n初めてRを学ぶ方に最適です！\n\n\nRとRstudioを使用してデータ分析を行うための基礎を紹介しています。\n本講座を受講して頂けるとデータサイエンティストが普段Rを使ってどのようにデータ分析を行っているかを知ることが出来ます。\n\n\nまた、「今後Rをより深く学ぶ際にどのように学べば良いか」など全体感を知りたい方に非常におすすめの講座となっております。\n\n\nカリキュラム\nインストール\nシンボルの利用\n基本構文\n関数の利用\nデータ分析\n機械学習",
      "target_audience": [
        "Rの基礎から応用方法まで学びたい方",
        "Rstudioを使って簡単にデータ分析したい方",
        "Rを使って機械学習を行いたい方",
        "データサイエンティストになりたい方"
      ]
    },
    {
      "title": "Fundamentos de Data Science e Machine Learning",
      "url": "https://www.udemy.com/course/fundamentos-de-data-science-e-machine-learning/",
      "bio": "A base teórica e matemática de modelos, e como eles são usados nas empresas!",
      "objectives": [
        "Compreender a fundação lógica e matemática por trás dos principais modelos de Machine Learning",
        "Entender como Data Science e Machine Learning de fato funciona no mundo empresarial",
        "Aprender todas as etapas do ciclo de vida de um modelo de Machine Learning",
        "Técnicas fundamentais para um cientista de dados, como: Regressão, Classificação, Clusterização, Deep Learning, NLP, Algoritmos Genéticos e muito mais!",
        "Aprender/Solidificar os conhecimentos na programação em Python",
        "Aplicar os conhecimentos teóricos em projetos da vida real"
      ],
      "course_content": {
        "Introdução": [
          "Ementa",
          "O que NÃO é coberto no curso"
        ],
        "Python Básico": [
          "Python: Primeiro Contato",
          "Operadores",
          "Data Types",
          "Controle de Fluxo: If-Else",
          "Controle de Fluxo: For",
          "Controle de Fluxo: While",
          "Funções pt. 1",
          "Funções pt. 2",
          "Escopo",
          "Tratamento de Exceções",
          "Projetinho: Explicação",
          "Projetinho: Solução"
        ],
        "Python Intermediário": [
          "Classes",
          "Herança",
          "Encapsulamento",
          "Polimorfismo",
          "Operator Overloading",
          "Decoradores",
          "@classmethod e @staticmethod",
          "Iteradores",
          "Geradores",
          "Built-in Functions",
          "Built-in Libs"
        ],
        "Algoritmos Genéticos": [
          "Algoritmos Genéticos: Introdução",
          "Principais Termos",
          "Fitness",
          "Seleção de Parentes",
          "Crossover",
          "Mutação",
          "Seleção de Sobreviventes",
          "Critério de Parada",
          "Implementação Completa"
        ],
        "Algoritmo Genético implementado em Python": [
          "Qual problema vamos atacar? NFL Team Building",
          "Fontes de Dados Utilizadas",
          "Restrições",
          "Fitness e Estratégias",
          "Implementação do Algoritmo",
          "Simulações",
          "Resultados",
          "Algoritmo Genético em código pt. 1",
          "Algoritmo Genético em código pt. 2",
          "Algoritmo Genético em código pt. 3",
          "Algoritmo Genético em código pt. 4",
          "Algoritmo Genético em código pt. 5",
          "Algoritmo Genético em código pt. 6"
        ],
        "Essência de Data Science": [
          "O que é Ciência de Dados?",
          "Salário",
          "Carreiras em Dados",
          "Entendendo termos: AI, DS, ML, DL",
          "Aprendizagem Supervisionada vs. Não-Supervisionada",
          "Classificação",
          "Regressão",
          "Clusterização",
          "Aprendizagem por Reforço",
          "Treino/Teste",
          "Validação Cruzada",
          "Data Leakage",
          "Bias-Variance Tradeoff",
          "Ciclo de vida de um modelo de ML",
          "Definindo um projeto de ML",
          "Montando a base de treino",
          "Consumo do modelo",
          "Como é ser um Cientista de Dados: Estagiário",
          "Como é ser um Cientista de Dados: Júnior",
          "Como é ser um Cientista de Dados: Pleno",
          "Como é ser um Cientista de Dados: Sênior"
        ],
        "Pré-processamento": [
          "Missing Values",
          "Encoding",
          "Outliers",
          "Feature Scaling",
          "Feature Engineering",
          "PCA",
          "Kernel PCA",
          "SVD",
          "LDA",
          "t-SNE",
          "Dados Desbalanceados"
        ],
        "Modelo em Produção": [
          "Avaliação e Seleção de Modelos",
          "Interpretabilidade",
          "Deploy",
          "Monitoramento",
          "Retreino",
          "Estratégias de Deploy"
        ],
        "Regressão": [
          "Regressão Linear: Intuição",
          "Regressão Linear: Suposições",
          "OLS (Método dos Mínimos Quadrados)",
          "Regressão Linear Múltipla",
          "Regressão Polinomial",
          "Lasso/Ridge/ElasticNet",
          "Métricas de Performance"
        ],
        "Classificação": [
          "Matriz de Confusão",
          "Métricas de Performance",
          "AUC",
          "KS",
          "LogLoss",
          "Classificação Multiclasse",
          "KNN",
          "Naïve Bayes",
          "Regressão Logística",
          "SVM",
          "Árvore de Decisão",
          "Métodos de Ensemble",
          "Random Forest",
          "XGBoost",
          "LightGBM"
        ]
      },
      "requirements": [
        "Ter uma noção razoável de conceitos matemáticos/estatísticos ajuda, mas não é fundamental",
        "Ter uma noção razoável de conceitos de computação/programação ajuda, mas não é fundamental",
        "Não é necessário saber nada de Ciência de Dados e/ou Machine Learning de antemão!"
      ],
      "description": "Neste curso, exploramos o vasto mundo de Data Science e Machine Learning, focando na base lógica e matemática por trás dos principais algoritmos utilizados na área. Veremos como funcionam os principais algoritmos de Regressão, Classificação, Clusterização, NLP, Deep Learning, Regras de Associação, Algoritmos Genéticos, Séries Temporais e muito mais - sem exagerar no \"matematiquês\".\nO curso foi pensado de forma a ser o mais democrático possível, servindo como porta de entrada para pessoas que queiram aprender de verdade os principais conceitos antes de entrar no mercado, pessoas que já estejam trabalhando com ciência de dados mas se veem com dificuldades de entender como funcionam os modelos, ou pessoas que simplesmente se interessam pela área e gostariam de aprender como funciona - não necessariamente visando adentrar o mercado. Até por isso, o curso não é tão orientado a código; ao invés de criar código para cada modelo e cada técnica mostrada, ao final do curso há uma seção com alguns projetos da vida real, em que podemos ver tanto como o código é feito, mas, principalmente, como é o raciocínio e as decisões tomadas para resolver problemas de dados.\nTambém trago uma seção bastante rica e dedicada a explicar como se \"produtizam\" modelos em empresas, falando sobre coisas como deploy, monitoramento, construção de features, pré-processamento, definição de um projeto de ML, expectativa e visão do mercado, progressão de carreira e muito mais!\nO curso ainda tem um \"crash course\" de Python, opcional para quem já programa na linguagem, mas valiosa para aqueles que precisam de uma base mais sólida.",
      "target_audience": [
        "Pessoas de qualquer área interessadas em entender a fundo como Ciência de Dados/Machine Learning funciona (tanto a parte matemática quanto o uso nas empresas)",
        "Pessoas querendo entrar no mercado na área de Ciência de Dados, independente da experiência prévia",
        "Pessoas que já estejam trabalhando com Ciência de Dados, mas que gostariam de revisar/aprofundar alguns conceitos",
        "Pessoas interessadas em aprender a programar em Python, com exemplos da vida real"
      ]
    },
    {
      "title": "Gender Classification Model Using Deep Learning",
      "url": "https://www.udemy.com/course/gender-classification-model-using-deep-learning/",
      "bio": "Practical Deep Learning for Gender Classification: A Step-by-Step Approach",
      "objectives": [
        "Image Data Preprocessing",
        "Convolutional Neural Networks (CNNs)",
        "Transfer Learning",
        "Model Evaluation and Performance Metrics",
        "Model Fine-tuning and Customization",
        "Real-time Gender Prediction"
      ],
      "course_content": {
        "Loading the Dataset": [
          "Knowing your Dataset",
          "Normalizing Data and turning into batches"
        ],
        "Creating CNN Model": [
          "Building a CNN Model",
          "Compiling the Model",
          "Fit the Model",
          "Evaluating the Model"
        ],
        "Predicting the Model": [
          "Predicting using custom Image",
          "Creating Functions for custom input image",
          "Colab GPU time limit issue (Optional)",
          "Fixing the issue",
          "Visualize our Custom Image"
        ]
      },
      "requirements": [
        "Basic understanding of Python and machine learning",
        "Familiarity with TensorFlow/Keras is a plus but not required"
      ],
      "description": "This course provides a comprehensive guide to building a gender classification model using deep learning techniques. Starting from the fundamentals of image processing to advanced concepts in neural networks, the course equips students with the knowledge to develop a model that classifies gender based on facial images. Students will learn how to preprocess data, design a neural network architecture, and train a model using TensorFlow/Keras.\nThroughout the course, students will work on:\nData Collection and Preprocessing: Learn how to handle large datasets of images, including techniques for face cropping, resizing, and augmentation to improve model accuracy.\nConvolutional Neural Networks (CNNs): Dive into CNNs, which are ideal for image-related tasks, and understand how layers such as convolution, pooling, and fully connected layers contribute to image classification.\nModel Training and Evaluation: Implement model training using TensorFlow/Keras, tune hyperparameters, and assess performance using accuracy, precision, recall, and F1 score.\nCustom Image Prediction: Work with real-time prediction by uploading custom images to the model and fine-tuning it for specific datasets.\nError Handling and Model Adaptation: Explore how to create a self-learning model that adapts to incorrect predictions and improves over time by leveraging user feedback.\nThis course is designed for students and professionals with basic knowledge of deep learning, eager to apply these concepts in the exciting domain of gender classification. By the end of the course, learners will have a fully functional gender classification model and the skills to deploy it in real-world applications.",
      "target_audience": [
        "Beginner"
      ]
    },
    {
      "title": "Estructuras de Datos: Domine Listas Dinámicas en Java",
      "url": "https://www.udemy.com/course/listas-dinamicas-java/",
      "bio": "Domine la creación de estructuras de datos lineales en Java mientras desarrolla un juego de dominó desde cero",
      "objectives": [
        "Comprender qué son estructuras de datos dinámicas",
        "Desarrollará Listas Simplemente enlazadas (LSE)",
        "Desarrollará Listas Doblemente enlazadas (LDE)",
        "Descubrirá cómo crear listas emplantilladas con tipos de datos genéricos, permitiendo la creación de listas de cualquier tipo de dato.",
        "Desarrollará habilidades para minimizar duplicados en listas y maximizar la eficiencia en el uso de memoria dentro de sus programas.",
        "Aprender cómo funcionan los punteros en memoria",
        "Diseñar e implementar un juego de Dominó",
        "Aprenderá a aplicar los conceptos vistos en un juego de dominó",
        "Profundizará en la aplicación de POO en Java para crear estructuras de datos robustas y reutilizables.",
        "Aplicará los conceptos aprendidos creando un juego de dominó en Java, utilizando interfaces gráficas con JOptionPane."
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Requisitos del curso",
          "Distribución de las secciones"
        ],
        "Instalación de herramientas": [
          "Instalación y configuración del JDK",
          "Instalación y prueba del IDE a utilizar",
          "Instalación de Java y Sublime (en MacOS)"
        ],
        "Listas Simplemente Enlazadas": [
          "Teoría Listas Simplemente Enlazadas",
          "Inserción al inicio e impresión LSE",
          "Generalización: inserción en cualquier posición",
          "Borrado de un elemento",
          "Modificación de un elemento",
          "Obtener el tamaño de la lista (length)",
          "Listas con clases genéricas"
        ],
        "Listas Doblemente Enlazadas": [
          "Teoría Listas Doblemente Enlazadas (LDE)",
          "Inserción al inicio e impresión LDE",
          "Generalización: inserción al final y en cualquier posición",
          "Borrado de un elemento",
          "Obtener el tamaño de la lista (length)",
          "Imprimir la lista de forma inversa",
          "Modificar y buscar nodos",
          "Borrado de todos los elementos con el mismo valor"
        ],
        "Proyecto utilizando listas: un juego de Dominó": [
          "Diseño de nuestro juego",
          "Objeto Ficha",
          "Objeto Pila De Fichas",
          "Objeto Tablero",
          "Objeto Jugador Parte 1",
          "Objeto Jugador Parte 2",
          "Objeto Juego Parte 1",
          "Objeto Juego Parte 2",
          "Finalización y prueba del juego",
          "Proyecto Dominó"
        ]
      },
      "requirements": [
        "Conocimiento básico del lenguaje de programación Java y su sintaxis",
        "Conocimiento de conceptos básicos de Programación Orientada a Objetos",
        "Conocimiento de métodos, ciclos, atributos, estructuras de selección como if/else"
      ],
      "description": "Domine las Estructuras de Datos con Java: Listas Dinámicas y POO\nEn este curso aprenderá los fundamentos de las estructuras de datos en Java, con un enfoque en el desarrollo y manipulación de listas dinámicas de una dimensión. A lo largo del curso, profundizará en los principios básicos de la Programación Orientada a Objetos (POO) y cómo aplicarlos para crear y gestionar listas eficientes y adaptables.\n\n\n¿Qué aprenderá?\n\n\nFundamentos de las Listas Dinámicas: Explore cómo funcionan las listas basadas en punteros y comprenda la importancia de las Listas Simplemente Enlazadas (LSE) y las Listas Doblemente Enlazadas (LDE).\nOperaciones Esenciales en Listas: Aprenderá a realizar operaciones clave como insertar, eliminar, modificar, obtener elementos en posiciones específicas, imprimir elementos, y calcular el tamaño de una lista.\nGeneralización de Estructuras: Descubra cómo generalizar estructuras de datos para crear listas emplantilladas con tipos de datos genéricos, permitiendo instanciar listas de cualquier tipo de dato u objeto.\nProyecto Práctico: Juego de Dominó: Aplique lo aprendido desarrollando un juego de dominó en modo hot-seat (jugador contra jugador) con una interfaz gráfica creada con JOptionPane. Este proyecto le permitirá implementar diferentes tipos de listas mientras optimiza el uso de memoria y minimiza los elementos duplicados.\n\n\nEste curso está diseñado para quienes desean comprender y dominar las estructuras de datos dinámicas en Java, utilizando un enfoque práctico que refuerza la teoría con un proyecto real y desafiante.",
      "target_audience": [
        "Desarolladores de Java con interés en aprender sobre estructuras de datos",
        "Desarrolladores de software que quieran aprender acerca de punteros",
        "Programadores que deseen reforzar la Programación Orientada a Objetos (POO)"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第16部 ComfyUI 進階版 - 360度無縫全景圖",
      "url": "https://www.udemy.com/course/generative_ai_16/",
      "bio": "使用Flux，Redux, ControlNet，LoRA，Flux fill， Redux，Panorama，Seamless",
      "objectives": [
        "學會從零開始生成 360 度全景圖的完整流程",
        "獲得首尾無縫銜接的專業技巧，解決全景創作的痛點",
        "學會如何使用Flux的工具",
        "熟悉 ComfyUI 的高階功能，提升 AI 創作效率"
      ],
      "course_content": {
        "介紹": [
          "如何在iMac電腦上安裝ComfyUI",
          "如何在Mac上運行第一個Flux工作流"
        ],
        "Flux加速": [
          "如何加快Flux Workflow的速度"
        ],
        "如何處理ComfyUI的T5XXL和CLIP-L Prompt": [
          "如何生成合適的T5XXL和CLIP-L Prompt提示詞",
          "如何減少運行Ollama LLM節約時間成本"
        ],
        "如何接入ControlNet到Flux工作流當中": [
          "如何將ControlNet接入到Flux WorkFlow當中",
          "如何測試和選擇Max Shift和Base Shift的值"
        ],
        "如何使用Flux做風格轉移": [
          "如何使用Flux做風格轉移",
          "如何修復Flux圖片模糊問題"
        ],
        "如何修復360全景圖無縫問題": [
          "如何為圖片添加細節",
          "如何重組圖片",
          "如何實現無縫連結"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "打造無縫全景的未來｜用 ComfyUI 解鎖 360 度全景圖創作的秘密！\n想像一下，你站在一個虛擬世界的中心，周圍的每個細節都真實而連貫，無論是山巒、建築，還是星空，都毫無違和感地在你的視野中無縫連接。這不僅是一個令人驚嘆的技術奇蹟，更是創作者們打造沉浸式體驗的黃金機會！現在，我們的課程將教您如何使用 ComfyUI，掌握創作 360 度無縫全景圖的核心技能！\n課程亮點\n掌握 360 度全景生成技術：\n從零開始，深入探索如何使用 ComfyUI 的強大功能，設計能用於 VR 的高品質全景圖，帶領觀眾進入身臨其境的虛擬世界。\n破解無縫銜接難題：\n您是否遇到過生成的圖像首尾無法對接的問題？我們的課程將逐步拆解關鍵技術，教授如何生成 首尾相接 的全景圖，確保圖像在 360 度環繞中實現完美銜接。\n實戰應用與專業指導：\n通過實際案例演練，您將學會處理圖像邊緣對齊、調整光影銜接，以及如何優化輸出，將創作水平提升到專業級。\n別讓技術瓶頸限制您的創意！報名我們的課程，解鎖 ComfyUI 在 360 度全景圖創作中的無限可能，讓您的作品征服 VR 世界！\n早鳥優惠現正開放，立即行動，搶占全景創作的先機！",
      "target_audience": [
        "VR 開發者： 想為自己的 VR 項目注入更高沉浸感的開發者",
        "數字藝術家： 渴望突破平面創作，進入全景藝術的新世界",
        "AI 創作者： 想充分發揮 ComfyUI 潛力，探索生成式藝術的新可能"
      ]
    },
    {
      "title": "Yapay Zeka : Makine Öğrenmesine Giriş",
      "url": "https://www.udemy.com/course/yapay-zeka-makine-ogrenmesine-giris/",
      "bio": "Makine Öğrenmesini ve günlük hayat problemlerine nasıl çözüm üretilebileceğini kod pratikleriyle derinlemesine öğrenin.",
      "objectives": [
        "Makine Öğrenmesi algoritma temellerini derinlemesine kavrayacaksınız.",
        "Algoritmaları görselleştirerek görselleri yorumlayabileceksiniz",
        "Günlük hayat problemlerine çözüm üretebilecek bilgileri uygulayarak öğreneceksiniz",
        "CV'lerinizde sizi ön plana çıkaracak bilgileri ve uygulamaları rahatlıkla ekleyebileceksiniz."
      ],
      "course_content": {
        "Makine Öğrenmesi İçin Veriyi Anlamak": [
          "Veriyi Anlamak"
        ],
        "Denetimli Öğrenme": [
          "Denetimli Öğrenme Nedir ?",
          "Denetimli Öğrenmenin Çalışma Mekanizması Kod Pratiği",
          "Denetimli Öğrenmenin Çalışma Mekanizması Kod Pratiği-2",
          "Denetimli Öğrenmede Sınıflandırma",
          "Sınıflandırma ve Regression Farkları",
          "Linear Regression Nedir ?",
          "Linear Regression İle Kanser Tahmin Uygulaması"
        ],
        "Algoritma Değerlendirme Metrikleri": [
          "Algoritma Değerlendirme Metrikleri ( Confusion Matrix )",
          "Algoritma Değerlendirme Metrikleri ( Accuracy Score )",
          "Algoritma Değerlendirme Metrikleri ( Precision Score )",
          "Algoritma Değerlendirme Metrikleri ( Recall )",
          "Algoritma Değerlendirme Metrikleri ( F1 Score )"
        ],
        "Denetimli Öğrenme-II": [
          "Logistic Regression Nedir ?",
          "Logistic Regression Uygulama",
          "Logistic Regression İle Kalp Hastalığı Tespit Uygulaması",
          "Support Vector Machine ( SVM ) Nedir ?",
          "SVM Nasıl Çalışır ?",
          "SVM Uygulama Alanları",
          "SVM için Karar Sınırı Nedir ?",
          "SVM Kod Uygulaması"
        ],
        "Denetimli Öğrenmede Karar Ağaçları ( Decision Tree )": [
          "Decision Tree Nedir ?",
          "Decision Tree Terminolojisi",
          "Decision Tree Matematiksel İfadeleri",
          "Decision Tree Restoran Tavsiye Sistemi Uygulaması",
          "Restoran Tavsiye Sistemi Veri Seti İncelemesi",
          "Restoran Tavsiye Sistemi Veri Analiz İşlemleri",
          "Restoran Tavsiye Sistemi Veri Hazırlama Adımları",
          "Restoran Tavsiye Sistemi Veri Görselleştirme-1",
          "Restoran Tavsiye Sistemi Veri Görselleştirme-2",
          "Restoran Tavsiye Sistemi Veriyi ve Grafikleri Yorumlama",
          "Restoran Tavsiye Sistemi İçin Model Oluşturma ve Modeli Uygulama"
        ],
        "Denetimli Öğrenme-III ( Random Forest )": [
          "Random Forest Nedir ?",
          "Random Forest Uygulama",
          "Random Forest Ağaç Yapısı Yorumlama"
        ],
        "Denetimsiz Öğrenme": [
          "Denetimsiz Öğrenme Nedir ?",
          "Principal Component Analysis ( PCA ) Nedir ?",
          "Clustering ( Kümeleme ) Nedir ?",
          "K-Means Algoritması",
          "K-Means Algoritması Uygulama",
          "K-Means Algoritmasında Optimum K Değeri İçin Dirsek Metodu Uygulaması",
          "DBSCAN Nedir ?",
          "DBSCAN Uygulama",
          "DBSCAN-KMeans Algoritmalarının Farkları",
          "Spectral Kümeleme Nedir ?",
          "Spectral Kümeleme Uygulama",
          "PCA Detaylı Öğrenelim"
        ],
        "Kapanış Ve Ek Kaynaklar": [
          "Kapanış ve Ek Kaynaklar"
        ]
      },
      "requirements": [
        "Temel Python bilgisi",
        "Eğitim kapsamında hem teorik bilgiler hem de kod uygulamaları detaylıca açıklanarak anlatılmıştır"
      ],
      "description": "Makine öğrenmesini öğrenmek, yazılım geliştirme süreçlerine hakim olmak ve yazılımcı kariyerinize güzel bir başlangıç için doğru yerdesiniz!\nBu eğitim tam size göre! Eğitimi tamamladığınızda anlamadığınız hiç bir yerin kalmamasına, kendi ürünlerinizi geliştirebilir hale gelmenize, makine öğrenmesi alanında temel becerilerinizi hem teorik hem de pratik olarak öğrenmiş olacak ve kariyerinizde sağlam bir adım atmış olacaksınız\nKurs Yapay Zeka alanında 200+ bin kişiye eğitim veren ve Microsoft' ta teknik mülakatları uygulayan ve yönetici mühendis olarak çalışan Caner ŞEKERCİ tarafından verilmektedir! Siz de Yapay Zeka dünyasına sağlam adımlar atmak istiyorsanız aşağıdaki detaylı açıklamayı inceleyip kursa hemen kayıt olabilirsiniz.\nBu kursta Makine Öğrenmesi alanında Python programlama dili ile bilgiler elde edeceksiniz. Eğitimin içindeki bölümlerde değineceğimiz konulardan bazıları şunlar:\nDenetimli Öğrenme\nDenetimsiz Öğrenme\nNumpy, Pandas, Matplotlib\nMatematiksel İfadeler\nSVM\nRandom Forest\nDecision Tree\nKümeleme Algoritmaları\nKMeans\nAlgoritma Değerlendirme Metrikleri\nVeri Görselleştirme\nGörsel Yorumlama\nİçerik & Genel Görünüş\nBu kurs Python dili ile makine öğrenmesini öğrenmek isteyenler için mükemmel bir seçim. Öncesinde herhangi bir yazılım deneyiminiz yoksa hiç dert etmeyin. En başından, temellerden öğrenmeye başlayarak ileri seviyeye kadar gideceğiz. Dersleri bitirdiğinizde kendi uygulamalarınızı yazacak seviyeye geleceksiniz.\nİlgili konuları \"Hastalık Teşhisleri\", \"Restoran Tavsiye Sistemi\", \"Tahminleme Problemleri\"  gibi yenilikçi ve dolu dolu uygulamalar geliştirerek öğreneceğiz. Eğitim pratik odaklı olsa da kesinlikle teorik boyutu aksatılmadan en ince detayları işlemeyi ihmal etmeyeceğiz.\nEğitim içerisinde yazılan tüm uygulamaların kaynak kodları indirilebilir kaynaklar bölümünde bulabileceksiniz. Bu şekilde kendi uygulamalarınızı geliştirirken ilgili kaynak kodlarını referans alabilir, istediğiniz şekilde kullanabilirsiniz!",
      "target_audience": [
        "Makine Öğrenmesi ile günlük hayat problemleri çözmek isteyenler",
        "Yapay zeka dünyasına adım atmak isteyenler",
        "Makine Öğrenmesinde uzmanlaşmak isteyenler",
        "CV'lerini yapay zeka algoritma becerileri ile güçlendirmek isteyenler"
      ]
    },
    {
      "title": "解剖深度学习原理",
      "url": "https://www.udemy.com/course/dl_hwdong/",
      "bio": "从0编写深度学习库",
      "objectives": [
        "深度学习原理及如何从0 实现一个深度学习库"
      ],
      "course_content": {
        "课程介绍": [
          "什么是机器学习",
          "课程介绍"
        ],
        "Python编程基础": [
          "1.1 Python1-对象与变量、IO、计算",
          "1.1 Python2-控制语句",
          "1.1 Python3-函数",
          "1.1 Python4-类和对象",
          "1.1 Python5-Matplotlib入门",
          "什么是张量",
          "1.2-numpy-创建numpy张量",
          "1.2-numpy-numpy张量的索引于切片",
          "1.2-numpy-numpy张量的运算"
        ],
        "微积分和概率基础": [
          "函数、极限、连续性",
          "导数",
          "多变量函数、向量值函数、积分",
          "概率",
          "随机变量",
          "期望、方差、协方差、协变矩阵"
        ],
        "梯度下降法": [
          "单调性、极值、极值的必要条件",
          "梯度下降法",
          "参数优化器",
          "梯度验证",
          "分离梯度下降算法与参数优化器"
        ],
        "线性回归、逻辑回归和softmax回归": [
          "线性回归",
          "多特征线性回归",
          "数据规范化",
          "模型的评估",
          "正则化",
          "逻辑回归",
          "softmax回归",
          "softmax回归的多分类交叉熵损失梯度"
        ],
        "神经网络": [
          "感知机、神经元、激活函数",
          "神经网络",
          "基于数值梯度训练神经网络",
          "反向求导、2层神经网络的实现",
          "任意层反向求导（列向量形式）",
          "实现一个神经网络框架",
          "通用神经网络框架"
        ],
        "改进神经⽹络性能的基本技巧": [
          "数据处理",
          "参数调试",
          "批规范化",
          "正则化和Dropout"
        ],
        "卷积神经网络": [
          "卷积",
          "卷积神经网络",
          "卷积的矩阵乘法",
          "基于下标索引的快速卷积",
          "典型的卷积神经网络结构"
        ],
        "循环神经网络": [
          "序列问题和模型",
          "循环神经网络",
          "传过时间的反向求导",
          "序列数据的采样和RNN模型的训练与预测",
          "RNN语言模型和文本生成",
          "长短期记忆网络LSTM",
          "门控循环单元GRU",
          "循环神经网络的类实现",
          "多层循环神经网络",
          "双向循环神经网络",
          "序列到序列模型、字符级机器翻译",
          "字符级Seq2Seq机器翻译",
          "基于Word2Vec词量化的Seq2Seq机器翻译",
          "基于词嵌入层的Seq2Seq机器翻译",
          "注意力机制的解码器"
        ],
        "生成模型": [
          "生成模型",
          "自编码器",
          "变分自编码器",
          "生成对抗网络",
          "生成对抗网络的实例",
          "GAN损失函数和概率分布散度的关系",
          "改进的损失函数：Wasserstein GAN（WGAN）",
          "深度卷积对抗网络 DCGAN"
        ]
      },
      "requirements": [
        "具有高中数学知识即可，最好懂点导数、概率、线性代数"
      ],
      "description": "从底层由浅入深地介绍深度学习原理并结合实现说明原理是如何实现的。不仅包含全连接神经网络，还包含了卷积神经网络、循环神经网络、对抗生成网络等的原理与实现。通俗易懂的原理讲解、从底层打造深度学习库、完整的深度学习基础内容构成了课程的特色。\n教学内容主要有\n第一章： 编程和数学基础。包括Python快速入门、张量（包括向量、矩阵）和numpy、微积分基础（函数、极限、连续性、导数、多变量函数和向量值函数、积分）、概率（样本空间、概率、随机变量、期望、方差等）。\n第二章： 梯度下降法。包括：函数单调性、极值的必要条件、梯度下降法、梯度下降法的参数优化策略、数值梯度和梯度验证、分离梯度下降和参数优化策略等。\n第三章：线性回归、逻辑回归、softmax回归。包括：线性回归、逻辑回归、softmax回归、模型评估、数据规范化、过拟合和欠拟合、学习曲线、偏差与方差、正则化、交叉熵损失、批梯度下降和随机梯度下降等。\n第四章：神经网络。包括：神经元、神经网络、损失函数（均方差、二分类和多分类交叉熵）、正向计算与反向求导、基于数值梯度的神经网络实现、基于反向求导的神经网络实现、面向全连接神经网络的深度学习框架。\n第五章：改进神经⽹络性能的基本技巧。包括数据处理（数据增强、数据的规范化、特征工程）、参数调式（权重初始化、优化参数）、批规范化、正则化。\n第六章：卷积神经网络CNN。包括卷积（池化）、卷积神经网络、卷积层的反向求导、快速卷积、典型的卷积神经网络架构。\n第七章：循环神经网络。包括序列问题和模型、序列数据的顺序和随机采样、单层循环神经网络的原理与实现、RNN语言模型和文本生成、长短记忆网络LSTM 、门控循环单元GRU、多层和双向循环神经网络原理与实现、序列到序列模型、机器翻译、单词向量化、词嵌入、注意力机制等。\n第八章：对抗生成网络。包括生成模型、自动编码器、变分自动编码器、生成对抗网络的原理与实现、生成对抗网络的例子、GAN损失函数和概率分布散度的关系、：Wasserstein GAN（WGAN）、深度卷积对抗网络的原理与实现、转置卷积等。",
      "target_audience": [
        "对机器学习、深度学习、人工智能大的原理及实现感兴趣的大学生、研究生、研究和工程技术人员"
      ]
    },
    {
      "title": "Sıfırdan Google Cloud Platformu BigQuery SQL Eğitimi",
      "url": "https://www.udemy.com/course/sfrdan-bigquery-egitimi/",
      "bio": "BigQuery ile Hızlı ve Verimli Büyük Veri Analizi: Temelden İleri Seviyeye Kapsamlı Bir Rehber!",
      "objectives": [
        "Google Cloud Platformunu kullanmaya başlayacaksınız.",
        "BigQuery ve inceliklilerini kullanmayı öğreneceksiniz.",
        "BigQuery kullanarak hızlı bir şekilde cloud üzerinde çalışabileceksiniz.",
        "BigQuery StandardSQL ile veri analizine başlayabileceksiniz."
      ],
      "course_content": {
        "Kurs Tanıtımı ve Kavramlar": [
          "Cloud Nedir?",
          "Google Cloud Platformu (GCP) Nedir?",
          "Bigquery Nedir?"
        ],
        "BigQuery Kurulumu ve Kavramları": [
          "Google Cloud Platformuna nasıl girilir? - 1",
          "Google Cloud Platformuna nasıl girilir? - 2",
          "BigQuery'e nasıl giriş yapılır?",
          "BigQuery Arayüzünü Tanıyalım - 1",
          "BigQuery Arayüzünü Tanıyalım - 2",
          "BigQuery Arayüzünü Tanıyalım - 3",
          "Proje nedir?",
          "Proje nasıl oluşturulur ve silinir?",
          "Dataset nedir ve nasıl oluşturulur?",
          "Public Datasetlere nasıl ulaşılır?"
        ],
        "BigQuery'de SQL": [
          "Google Sheets ile Tablo Nasıl oluşturulur?",
          "CSV ile Tablo Nasıl oluşturulur?",
          "CREATE Komutu ile Tablo Nasıl Oluşturulur?",
          "DROP Komutu ile BigQueryde Tablo Nasıl Silinir?",
          "INSERT INTO Komutu ile Veriler Tabloya Nasıl Eklenir?",
          "UPDATE Komutu ile Veriler Nasıl Değiştirilir?",
          "DELETE nasıl kullanılır?",
          "SELECT * ve LIMIT Nasıl Kullanılır?",
          "ALIAS Nasıl Kullanılır?",
          "WHERE Nasıl Kullanılır?",
          "COUNT (*) Nasıl Kullanılır? - 1",
          "COUNT (*) Nasıl Kullanılır? - 2",
          "GROUP BY Nasıl Kullanılır?",
          "HAVING Nasıl Kullanılır?",
          "CASE Nasıl Kullanılır? - 1",
          "CASE Nasıl Kullanılır? - 2",
          "En Pahalı İlk 2 Ürünü Nasıl Bulunur?",
          "MAX Fonksiyonu Nasıl Kullanılır?",
          "MIN Fonksiyonu Nasıl Kullanılır?",
          "AVG Fonksiyonu Nasıl Kullanılır?",
          "SUM Fonksiyonu Nasıl Kullanılır?",
          "INNER JOIN Nasıl Kullanılır?",
          "LEFT JOIN Nasıl Kullanılır?",
          "RIGHT JOIN Nasıl Kullanılır?"
        ],
        "Kapanış ve Son Söz": [
          "Son Söz"
        ]
      },
      "requirements": [
        "Herhangi bir deneyim gerektirmeden, sıfırdan ileri seviyeye geleceksiniz. Tek ihtiyacınız olan şey bir bilgisayar ve bir de internet bağlantısı."
      ],
      "description": "Neden BigQuery SQL öğrenmek istiyorsun? Eğer aşağıdaki sebeplerden en az birisi buradaki motivasyonunu oluşturuyorsa, bu kurs tam sana göre!\nVeri analizi projelerinde zaman ve kaynak tasarrufu yapmak ister misin?\nBigQuery SQL ile gerçek dünyadan örneklerle bu kurs sayesinde pratik yaparak hızlı ve etkili bir şekilde veri analizleri yapabileceksin. Büyük veri setlerini kolayca yönetmeyi ve iş zekası çözümleri geliştirmeyi öğren.\nBu kurs, özellikle veriye dayalı kararlar almak isteyen işletme sahipleri, pazarlama yöneticileri ve veri analistleri için idealdir. İster bir veri bilimcisi, ister bir iş analisti veya isterse bir pazarlama uzmanısın, bu kurs sana veri odaklı bir yaklaşımla iş sorunlarına çözüm bulma becerisi kazandıracak.\nBigQuery'in sunduğu kullanıcı dostu arayüzü sayesinde kodlama bilgisine sahip olmadan da etkili analizler yapabilirsin. Sektörden bağımsız olarak, e-ticaretten finansal analizlere kadar geniş bir yelpazede veriye dayalı kararlar almak için gerekli olan tüm becerileri kazanacaksın.\nMüşteri davranışlarını analiz etmek, satış tahminleri oluşturmak ve pazarlama kampanyalarının etkinliğini ölçmek gibi konularda uzmanlaşacaksın. BigQuery'in sunduğu güçlü sorgulama dili ve ölçeklenebilirliği sayesinde karmaşık veri setlerini saniyeler içinde tarayabilir ve anlamlı sonuçlar elde edebilirsin.\nÖrneğin, bir e-ticaret şirketinin ürün satışlarını analiz etmek için BigQuery SQL ile karmaşık sorgular yazabilir, müşteri segmentasyonu yapabilir ve satış trendlerini belirleyebilirsin.\nTüm kurs boyunca en çekirdek bilgiyi, en yalın haliyle aktarmaya çalıştım. Bu doğrultuda taleplerinle uyuşan bir eğitim olacaktır.",
      "target_audience": [
        "Bilişim sektöründeki pek çok kullanıcıya yönelik olan bu kurs, özellikle veri ile çalışmak isteyen herkese çok fayda sağlayacaktır."
      ]
    },
    {
      "title": "互联网行业的数据采集",
      "url": "https://www.udemy.com/course/yujpvwlg/",
      "bio": "大数据分析入门",
      "objectives": [
        "1.了解大数据架构及大数据分析的Pipeline",
        "2.了解互联网行业常见的四种数据采集方式",
        "3.了解爬虫的常见框架-Scrapy",
        "4.了解分布式爬虫以及反爬虫策略",
        "5.了解前后端埋点原理",
        "6.了解离线数据分析的分析场景及框架",
        "7.了解实时数据分析的分析场景及框架"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "一、课程导论": [
          "课程导论"
        ],
        "二、大数据分析简介": [
          "大数据分析的历史",
          "Hadoop生态圈",
          "经典大数据分析Pipeline"
        ],
        "三、数据采集": [
          "「案例」为什么要采集数据",
          "互联网爬虫采集数据",
          "前、后端埋点采集数据",
          "日志上报方式采集数据",
          "已有数据库数据同步",
          "小结"
        ],
        "四、大数据离线分析": [
          "常见离线分析架构及应用场景"
        ],
        "五、大数据实时分析": [
          "常见实时分析架构及应用场景"
        ],
        "六、课程总结": [
          "总结"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "面向0基础学员"
      ],
      "description": "很多同学都有过数据采集的经历，不知道在数据采集实操过程中，你是否也会以下疑问呢：\n\n大数据架构具有怎样的作用呢？什么是Hadoop生态圈和经典大数据分析Pipeline？\n常见的数据来源有哪些？\n在进行互联网爬虫采集数据时，有哪些反反爬虫策略？\n在埋点采集数据时，如何确定是前端埋点还是后端埋点？\n如何通过日志上报的方式进行数据采集呢？\n在对已有数据库进行同步时，离线同步和实时同步流程是怎样的呢？它们具体有哪些应用场景呢？\n......\n本节课，拥有丰富大数据分析经验的刘恒老师将结合实例按照业务流程来解答同学们的疑问。\n\n\n本节课程是由授课老师与三节课合作制作的。在此，要特别感谢老师的辛苦付出！经历了课程立项、设计、开发中的众多环节，我们才能最终为你呈现现在的这门课程。无论是授课老师还是三节课团队，都希望这门课程能够让你有所收获，希望同学们结合个人工作情况，学以致用。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "1.0-1岁数据分析方向从业者",
        "2.想要提升数据分析能力的互联网从业者",
        "3.对大数据分析感兴趣的学习者"
      ]
    },
    {
      "title": "Machine Learning/Künstliche Intelligenz",
      "url": "https://www.udemy.com/course/machine-learningkunstliche-intelligenz/",
      "bio": "künstliche Intelligenz Tensorflow Machine Lerning Modell",
      "objectives": [
        "Machine Learning und Deep Learning",
        "Tensorflow",
        "künstliche intelligenz",
        "python",
        "Künstliche Intelligenz in der Praxis",
        "Künstliche Intelligenz für Anfänger und Fortgeschrittene"
      ],
      "course_content": {},
      "requirements": [
        "Anfänger der etwas programmieren kann",
        "Künstliche Intelligenz für Anfänger und Fortgeschrittene"
      ],
      "description": "Hier baust du dein erstes Modell das Bilder erkennen kann, mit wenig Zeilen Code ist das Modell fertig, in nicht mehr als 15 min ?\nWir werden den Berühmten Machine Learning Modell VGG 19 von dem Hause Google  Keras/Tensorflow ausprobieren.\nIch zeige dir welche Library du importieren musst, und wie man Sie anwendet.\nWie man die Library/Module importiert\nWie man Bilder lädt\nDu wirst lernen wie man Bilder in Arrays umwandelt.\nwie man die Arrays in einem 3 Dimensonales Netz umwandelt\nWie man die Daten Reinigt durch den sogenannten Preprocessing\nWie man das Modell deine Vorhersage/Bild erkennt und das ergebnis anzeigt\nsomit hast du ein Einblick über das die Künstliche Intelligenz gewonnen und kannst evtl. das erlernte auch anweden, natürlich bist danach kein Experte,somit hast du schon mal rein geschnuppert in das Thema ob das Thema was für dich ist oder nicht.Und danach kannst du dich entscheiden ob du dich für weitere Kurse einschreibst oder nicht.\n\n\nBitte verzeiht falls dieser Kurs keine gute Qualität bietet, es ist auch mein erster Kurs den ich hier auf Udemy halte, deshalb biete diesen Kurs auch Kostenlos an.\nViel Spaß mit dem kurz Kurs und würde mich über ein Feedback was ich besser machen kann, wie und was hat dir an diesem Kurs gefallen freuen.\n\n\nIn diesem Sinne bis Bald\n\n\nEuer Mohamed (Mo)",
      "target_audience": [
        "Alle die Intresse haben an künstlicher intelligenz"
      ]
    },
    {
      "title": "NLP con Python: Procesamiento de Lenguaje Natural con Python",
      "url": "https://www.udemy.com/course/nlp-con-python/",
      "bio": "Aprende los fundamentos del NLP con Python",
      "objectives": [
        "Entenderás los fundamentos del Procesamiento Natural del Lenguaje, y del Machine Learning",
        "Tendrás una clara imagen de qué librerias estan disponibles en Python para tareas de NLP",
        "Verás diversos ejemplos prácticos, donde en cada uno se explicará el modelo y como preprocesar los datos",
        "Cerraremos el curso introduciendo redes neuronales, en especial aquelas más comunmente utilizadas para NLP",
        "Serás capaz de comprender como funciona Pytorch, y los modelos basados en la arquitectura Transformers"
      ],
      "course_content": {
        "Introducción al curso": [
          "Presentación del curso",
          "Plataforma y recursos",
          "Archivos del curso",
          "¿Qué es Python? (repaso)",
          "Conocimientos necesarios",
          "¿Qué es NLP? - Video de YouTube"
        ],
        "Conceptos básicos del Machine Learning": [
          "AI vs ML vs DL",
          "Tipos de aprendizajes",
          "Aplicaciones del Machine Learning",
          "Tipos de atributos en un set de datos",
          "Función de costo",
          "Underfitting vs Overfitting",
          "Sets de entrenamiento, validación, y evaluación",
          "Validación cruzada",
          "Conceptos",
          "Matriz de confusión",
          "Ejemplo con set de datos imbalanceado",
          "Curva ROC y AUC",
          "Métricas para la regresión"
        ],
        "Conceptos básicos del Procesamiento Natural del Lenguage": [
          "Qué es el NLP",
          "Vectorización",
          "One hot encoding",
          "Matriz término-termino y término-documento (BoW)",
          "TF-IDF",
          "Word Embeddings",
          "Word2Vec",
          "Ejemplo práctico con Skip-gram",
          "Pipeline de NLP",
          "Línea de tiempo",
          "Límites de los modelos lingüísticos",
          "Knowledge Graph",
          "Neural Entity Linking"
        ],
        "Preprocesamiento del texto con NLTK": [
          "Qué es y cómo utilizar NLTK",
          "Pasos previos",
          "NLTK Downloader y Corpora",
          "Tokenización",
          "Stopwords",
          "Ejemplo utilizando tokenización y removiendo stopwords",
          "Stemming",
          "Part of speech (POS)",
          "Lematización",
          "Chunking",
          "Chinking",
          "Named Entity Recognition (NER)",
          "Concordance",
          "Dispersion plot",
          "Frequency distribution",
          "WordCloud",
          "Collocations",
          "Ejemplo 1: Identificación del género",
          "Ejemplo 2: Identificación de la categoría de una noticia",
          "Ejemplo 3: Sentiment Analysis"
        ],
        "Preprocesamiento del texto con spaCy": [
          "Pasos previos",
          "Pipeline de spaCy",
          "Tokenización y selección de componentes",
          "Etiquetas de POS, dependencias, y NER",
          "Word Embeddings y similaridad",
          "DisplaCy"
        ],
        "Herramientas adicionales para preprocesar texto": [
          "Introducción",
          "Hipervínculos y menciones",
          "Hashtags y retweets",
          "Normalización de caracteres repetidos",
          "Emojis y smileys",
          "Puntuación, dígitos, abreviaciones, y tokenización",
          "Normalización con spaCy",
          "Corrección de la ortografía",
          "Data Augmentation con eda_nlp",
          "Data Augmentation con nlpaug"
        ],
        "Machine Learning con Scikit-learn": [
          "Presentación de la unidad",
          "Carga del set de datos a utilizar",
          "CountVectorizer",
          "Regresión Lineal (Linear Regression)",
          "Regresión Logística (Logistic Regression)",
          "Ejemplo de regresión logística",
          "Vectorizador TF-IDF",
          "Support Vector Machine",
          "SVM - Truco del núcleo (Kernel Trick)",
          "Ejemplo de SVM con SGD",
          "Metodos fit, transform y fit-transform",
          "Naïve Bayes",
          "Ejemplo de Naïve Bayes",
          "Árboles de decisión y bosques aleatorios",
          "Ejemplo de árboles de decisión y bosques aleatorios",
          "K-Vecinos próximos (K-Nearest Neighbors)",
          "Ejemplo de K-NN",
          "Función train-test-split",
          "Búsqueda de grilla con validación cruzada (Grid Search CV)"
        ],
        "Introducción a las Redes Neuronales y Pytorch": [
          "Presentación de la unidad",
          "¿Qué es el Deep Learning? - Video de YouTube",
          "Modelo Perceptrón",
          "Redes Neuronales",
          "Multilayer Perceptron (MLP) con Scikit-learn",
          "Funciones de Activación",
          "Funciones de Activación de Clases Múltiples",
          "Funciones de Coste y Gradiente Descendiente",
          "Retropropagación",
          "Instalación de Pytorch",
          "Introducción a Pytorch: Tensores",
          "Operaciones entre tensores y selección",
          "Dispositivo de cómputo",
          "Autogradiente",
          "Bucle de entrenamiento, función de perdida, y optimizador",
          "Regresión Lineal",
          "Preparación de los datos para la regresión logística",
          "Regresión Logística",
          "Red Neuronal Recurrente (RNN)",
          "Ejemplo de RNN: carga de los datos y GloVe Word Embeddings",
          "Ejemplo de RNN: creación de la matriz de word embeddings",
          "Ejemplo de RNN: creación del modelo",
          "Ejemplo de RNN: funciones de ayuda",
          "Ejemplo de RNN: bucle de entrenamiento",
          "Long Short-Term Memory (LSTM)"
        ],
        "BERT, GPT-2 y Hugging Face": [
          "Presentación de la unidad",
          "Arquitectura Transformers",
          "Transformers: Input Embedding + Positional Encoding",
          "Transformers: Atención",
          "Ejemplo de atención",
          "Transformers: Últimos comentarios",
          "BERT",
          "BERT: Representación de la entrada y aplicaciones",
          "Comparación entre GPT y BERT",
          "Clasificación de reseñas de yelp (Huggingface, BERT)",
          "Clasificación de tweets (Pytorch, BERT)",
          "Pre-procesamiento de los datos",
          "Creación del modelo",
          "Loop de entrenamiento",
          "Generación de texto con GPT-2"
        ],
        "¡Ya has terminado!": [
          "¡Ya has terminado!"
        ]
      },
      "requirements": [
        "Conocimientos básicos de Python son útiles, pero no excluyentes. El curso se puede seguir perfectamente aún con conocimientos básicos de programación"
      ],
      "description": "Hola y bienvenido a este curso de Procesamiento del lenguaje Natural o NLP con Python.\nEn este curso aprenderás todos los conceptos teóricos y prácticos para empezar a trabajar en proyectos enfocados al procesamiento natural del lenguaje, aplicando diversas técnicas y modelos predictivos.\nEl curso es mayoritariamente práctico, donde comprenderás el funcionamiento y uso de diferentes modelos de machine learning, cómo procesar los datos para cada uno de ellos, y cuál es su capacidad predictiva o limitaciones.\nEl curso empezará con dos unidades teóricas, para que te familiarices con conceptos importantes que debes conocer para el procesamiento del lenguaje natural. En la primera explicaremos los conceptos básicos del machine learning y en la segunda, los conceptos básicos del NLP necesarios para un mejor seguimiento de la parte práctica del curso.\nLuego, exploraremos diversas técnicas para pre procesar texto. Desde la limpieza, a la augmentacion, y la vectorización. En este curso utilizaremos Spacy y NLTK: dos librerías muy utilizadas en el mundo del NLP.\nA lo largo del curso, veremos varios casos prácticos utilizando diferentes algoritmos o modelos, para diferentes tareas como por ejemplo la clasificación de tweets. En particular utilizaremos la librería Scikit-learn para los algoritmos más clásicos, y Pytorch y Huggingface para los modelos del lenguaje basados en la arquitectura de transformers, los cuales son redes neuronales.\nEste curso será impartido por Lisandro Cesaratto, un ingeniero electrónico especializado en el área de la ciencia de datos, y específicamente en tareas relacionadas al NLP. Lisandro tiene mucha experiencia profesional en el campo de la ciencia de datos y ha trabajado en empresas conocidas como PwC, y BASF.\nEn Datademia trabajamos para crear el mejor contenido de datos en español, incluyendo ciencia de datos, inteligencia de negocios y programación. Nuestro objetivo es transformarte en un experto en datos, aprendiendo desde cualquier parte del mundo y a tu ritmo.\nTe invitamos a que veas la presentación del curso y algunas de las clases gratuitas. Cualquier duda que tengas nos puedes contactar a través de nuestras redes sociales o a través de la plataforma\n¡Nos vemos en el curso!",
      "target_audience": [
        "Personas que busquen aprender los conocimientos básicos del Procesamiento Natural del Lenguage y de Machine Learning",
        "Quienes busquen un curso orientado a la práctica, pero sin descuidar conceptos fundamentales",
        "Profesionales que ya tienen una primera experiencia con NLP o ML y busquen expandir sus conocimientos",
        "Aficionados de Python que busquen nuevos desafíos en una temática con mucho potencial",
        "Analistas o científicos de datos que busquen un cambio en su carrera orientado al NLP",
        "Personas que deseen dar su primer paso en el área de Machine Learning. El curso comienza con ejemplos sencillos"
      ]
    },
    {
      "title": "PythonではじめるSQL入門〜ゼロからはじめてウィンドウ関数まで〜",
      "url": "https://www.udemy.com/course/pythonsql/",
      "bio": "データベースのインストール不要！PythonがあればすぐにSQLを実行/学習できます。Pythonからのデータベース操作を身につけながら、SQLの超基本から分析SQLの主役\"ウィンドウ関数\"まで修得しよう。",
      "objectives": [
        "SQLを使ってデータベースからデータを取得することができる",
        "Pythonプログラムの中からデータベースへアクセスできる",
        "ウィンドウ関数を使ったデータ分析ができる",
        "WITH句で、長くても見通しがよいSQLが書ける",
        "SQLで取得したデータをグラフで表示できる"
      ],
      "course_content": {
        "はじめに": [
          "コースのご紹介",
          "コースの各セクションの紹介",
          "データベースとSQL",
          "添付資料（教材）の使い方",
          "【準備】Mac",
          "【準備】Windows（音声なし）",
          "PythonからSQLを実行してデータベースを作成する",
          "データベースにテーブルを作成する",
          "PythonからSQLファイルをとりこんで実行する"
        ],
        "はじめてのSQL：SELECT文の基本": [
          "SELECT文の基本形",
          "SELECT/FROMの実行",
          "WHERE",
          "ORDER BY",
          "LIMIT"
        ],
        "JOINで複数のテーブルを結合する": [
          "JOINとは",
          "テーブルとデータの準備",
          "JOIN",
          "LEFT JOIN"
        ],
        "GROUP BYでグループ化して比べる": [
          "GROUP BYと集約関数",
          "GROUP BYでグループ化",
          "いろいろな関数"
        ],
        "サブクエリ": [
          "サブクエリとは",
          "スカラサブクエリ",
          "テーブルを返すサブクエリ",
          "WITH句"
        ],
        "ウィンドウ関数": [
          "ウィンドウ関数とは",
          "ウィンドウ関数でランキング",
          "ウィンドウ関数に返信する関数",
          "ウィンドウ関数で移動平均を求める",
          "ウィンドウ関数で累計を求める",
          "結果をグラフ表示(移動平均)",
          "結果をグラフ表示(累計)"
        ],
        "データの作成と削除": [
          "テーブルを作成する",
          "データを作成する",
          "データを削除する",
          "テーブルを削除する"
        ],
        "まとめ": [
          "修了おめでとう！今後の学び方",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonを使ったことがある（importやprintを使ったことがあるレベルでOK）"
      ],
      "description": "データベースからデータを取得したり格納したする際は、SQLという言語を必ず利用する必要があります。SQLはデータ分析/活用における重要スキルといえます。\nしかしSQLを学習するためには、データベースをインストールしたりユーザー権限を設定したり、といった操作が必要ですぐにははじめることができません。ただPythonが動く環境をお持ちの方は違います。Pythonにインストール済のSQLiteを使って、すぐにSQLを実行することができます。\n本講座ではPythonからのデータベース操作を身につけながら、ステップバイステップでSQLを学びます。\nSQLとして非常によく使われる構文やキーワード の超基本をおさえています。\nまた、読みやすいSQLを書く事ができるWITH句やデータ分析で役立つウィンドウ関数など応用が効くSQLまで、短時間で学べるのが本講座の特徴です。\n講師はウェブのアクセス解析やビッグデータのデータ基盤構築などを通じSQLの重要性を身に見て感じました。\nデータ・AI時代の基礎スキルとして、本講座で一緒にSQLを身につけましょう。",
      "target_audience": [
        "SQLに関心があるが使ったことがない方",
        "データベース操作を学びたいPythonユーザー",
        "データ分析やデータ活用に興味がある方"
      ]
    },
    {
      "title": "데이터와 SQL 입문반(Learning Data & SQL for Beginners)",
      "url": "https://www.udemy.com/course/learning-data-sql-for-beginners/",
      "bio": "MySQL Workbench 8.0 프로그램 설치 및 기초예제 활용 실습반",
      "objectives": [
        "MySQL 기본 문법 Keyword, Syntax를 빠르게 1회독 할 수 있습니다.",
        "MySQL Workbench 필수 기능을 배울 수 있습니다.",
        "초급 데이터 엔지니어링 능력을 획득하고 향후 심화 분석과정에 필요한 기초 실력을 다질 수 있습니다.",
        "Database에 접속하여 필요한 데이터를 추출하고 실전 활용에 가능한 준비를 할 수 있습니다.",
        "프로그래밍에 입문하여 어떻게 기술 개발을 할 수 있을지 이해할 수 있습니다.",
        "컴퓨터와 소통하기 위해 영어로 명령하고 정보를 얻는 것에 익숙해집니다."
      ],
      "course_content": {
        "SQL 시작": [
          "SQL과 데이터베이스(DB) 개념 이해하기",
          "SQL Syntax 개념 이해하기",
          "Workbench 설치",
          "Workbench 설치 파일 다운로드 이후부터 따라하기",
          "실습용 DB와 Table 만들고 데이터 조회하기: CREATE, INSERT, SELECT, FROM"
        ],
        "SQL 활용": [
          "생성한 DB와 Table 수정하기: UPDATE, ALTER, DELETE, DROP",
          "조건을 더해 데이터 조회하기: WHERE, ORDER BY, GROUP BY, HAVING",
          "논리 연산자 사용하기: BETWEEN, LIKE, IN, IS",
          "집합 함수 사용하기: COUNT, MAX, MIN, SUM, AVG"
        ],
        "관계 구성": [
          "SQL제약조건(Constraint) 활용하기: Primary Key, Foreign Key",
          "DB 디자인 설계하고 시각화하기: Entity Relationship Diagram(ERD)",
          "데이터 관계를 이해하고 결합하기: JOIN, SUBQUERY",
          "가상 테이블 생성하기: View"
        ]
      },
      "requirements": [
        "강의 페이지에 접속하여 수업 동영상을 실행할 수 있어야 합니다.",
        "적절한 설명서가 동영상, 스크린샷 등으로 제공될 경우 이를 보고 안내된 페이지에 접속, 프로그램 및 교안 다운로드 후 실행(설치), 순서대로 따라 할 수 있어야 합니다.",
        "자신의 화면을 캡쳐하여 공유해 본 경험이 있어야 합니다. Q&A 이용을 위해 사진 첨부 등록이 필요할 수도 있습니다."
      ],
      "description": "본 강의는 수강생이 Windows 10 운영체제 컴퓨터에 MySQL Workbench 8.0 (무료 커뮤니티 버전)을 설치할 수 있다고 전제하여 진행합니다. 다른 많은 SQL 강의가 인터넷 브라우저(웹) 기반 콘솔에서 진행되는 것에 비교해 본인의 컴퓨터에 실제 설치한 프로그램을 통해 공부하고 연습, 활용할 수 있다는 장점이 있습니다. 프로그램 설치가 어려운 경우를 대비해 SQL 이론 및 쿼리 설명과정은 웹 기반 콘솔로 병행하여 1차 설명합니다. 이후 동일한 예제 내용을 MySQL Workbench 8.0에서 2차 설명, 활용 가이드를 안내하는 방식으로 반복하여 설명합니다. 강의에 활용된 모든 슬라이드와 실습 쿼리문은 별도 첨부 파일로 제공합니다.",
      "target_audience": [
        "취업 또는 커리어 전환을 위해 SQL 인터뷰를 준비중인 분",
        "데이터사이언티스트, 디지털분석가 등이 활용하는 SQL이 궁금하신 분",
        "데이터 분야에 근무하며 동료 팀원/부서가 하는 일을 이해하고 싶은 분",
        "Python, R 프로그래밍 등의 경험이 있지만 MySQL은 처음인 분",
        "코딩(coding)이 처음인 분"
      ]
    },
    {
      "title": "用Kedro构建完整数据科学管道",
      "url": "https://www.udemy.com/course/kedro-kb/",
      "bio": "Introduction to kedro and MLOps",
      "objectives": [
        "学习数据科学管道的相关概念",
        "学习怎么用软件开发的最佳实践开发数据科学管道",
        "学习kedro，mlflow，great-expectation这些工具",
        "学习如何独立完成一条完整的数据科学管道",
        "了解在大型数据科学项目中的开发合作模式"
      ],
      "course_content": {
        "Course Introduction": [
          "Introduction",
          "Development Env Setup",
          "What is Data pipeline，what is Kedro"
        ],
        "Kedro基础概念：Node，Catalog，Parameter，Pipeline": [
          "Kedro Overview",
          "Create Kedro project",
          "Run Kedro pipeline， kedro requirements， Kedro-viz",
          "Kedro Data Catalog",
          "Kedro Node",
          "Kedro Pipeline",
          "Kedro Parameters",
          "Jupyter notebook in Kedro"
        ],
        "Kedro MLOps": [
          "MLOps with Kedro",
          "Kedro Hooks（Advanced Kedro）",
          "Great-expectations in kedro",
          "Mlflow with kedro"
        ],
        "Complete a data science pipeline from scratch": [
          "Kedro workflow",
          "Project description",
          "Create new project",
          "Create whole pipeline with jupyter lab",
          "Create whole pipeline with kedro",
          "Integration with great-expectations and mlflow",
          "Package project with kedro"
        ]
      },
      "requirements": [
        "python, pandas, numpy, scikit-learn"
      ],
      "description": "这门课程会带大家一步一步了解到什么是数据科学管道，如何用kedro来构建数据科学管道\n如果对以下内容感兴趣，欢迎报名这个课程\n1、 在企业中数据科学管道是如何构建的\n2、如何构建产品级的数据科学管道\n3、什么是MLOps，如何实现MLOps\n4、如何运用kedro， great-expectations，mlflow来实现MLOps\n5、如何利用kedro开发大型数据科学项目，团队内部怎么合作\n\n\n欢迎对数据科学感兴趣，想要在工作学习中构建可维护，模块化的数据科学代码的同学来学习。",
      "target_audience": [
        "对数据科学感兴趣的学生，开发人员",
        "对MLOps感兴趣的学生，开发人员",
        "对kedro，mlflow，great-expectation等工具感兴趣的学生，开发人员"
      ]
    },
    {
      "title": "【初心者向け】統計的因果推論を学びPythonで実装していこう！RCT・層別解析・マッチング法・傾向スコアを学ぼう！",
      "url": "https://www.udemy.com/course/causal-inference/",
      "bio": "因果関係を統計的に見つける統計的因果推論の世界に足を踏み入れていこう！具体的な問題設定をベースにランダム化比較実験(RCT)・層別解析・マッチング法・傾向スコア・逆確率重み付け法などについて学びPythonで実行していこう！",
      "objectives": [
        "統計的因果推論の概要",
        "ランダム化比較実験（RCT）の概念とPythonでの実装方法",
        "層別解析の概念とPythonでの実装方法",
        "マッチング法の概念とPythonでの実装方法",
        "傾向スコアを用いたマッチング法と逆確率重み付け法の概念とPythonでの実装方法",
        "オンラインショップのクーポン付与の因果関係を紐解く実践課題"
      ],
      "course_content": {
        "紹介": [
          "紹介"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyの使い方を学ぼう！",
          "Matplotlibについて学ぼう！",
          "Searbornについて学ぼう！",
          "Python構文の復習"
        ],
        "統計的因果推論の問題設定とランダム化比較実験": [
          "問題設定の説明とデータ生成",
          "問題設定そのままで単純比較をするとどうなるか見ていこう！",
          "ランダム化比較実験を実行して差を見てみよう！"
        ],
        "層別解析で因果推論してみよう！": [
          "層別解析の概要とグループ分け",
          "各層の重み付け平均を取って最終的な差を見ていこう！"
        ],
        "マッチング法で因果推論してみよう！": [
          "マッチング法とは？",
          "k近傍法とは？",
          "k近傍法を実施して一番近いマッチングするサンプルを取得しよう！",
          "マッチングしたサンプル同士を比較して因果効果を推定していこう！"
        ],
        "回帰モデルを使って因果推論してみよう！": [
          "回帰モデルの概要説明",
          "回帰モデルを使った因果推論"
        ],
        "傾向スコアを用いたマッチング法で因果推論してみよう！": [
          "傾向スコアの概要説明",
          "複数交絡因子におけるデータ生成と単純比較",
          "【注意】次のレクチャーのエラーについて",
          "傾向スコアを算出してみよう！",
          "傾向スコアを用いたマッチング法で因果推論！",
          "年齢が高くてBMIが高い人の確率値が高くなるように修正"
        ],
        "傾向スコアを用いた逆確率重み付け法で因果推論してみよう！": [
          "逆確率重み付け法の概要",
          "重みを計算していこう！",
          "逆確率重み付けを計算して因果効果を推定していこう！"
        ],
        "応用：オンラインショップでクーポンの効果があるか因果推論するケース": [
          "問題設定とデータについて確認していこう！",
          "単純比較で差を見ていこう！",
          "統計的検定で差を見ていこう！",
          "統計的検定とは？",
          "傾向スコアを用いたマッチング法でクーポンの効果を見ていこう！",
          "統計的検定で差を見ていこう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学びますのでプログラミングの知識は特に必要ありません"
      ],
      "description": "このコースでは統計的因果推論について学んでいきます！\n\n\n因果関係がありそうでも、実際には隠れた因子が存在していて因果関係がないことなどが起こり得ます。\nそんな複雑な因子が絡まった状況で本当の効果を検証していくのが、統計的因果推論の世界。\n\n\n具体的な問題設定をベースに\n・ランダム化比較実験（RCT）\n・層別解析\n・マッチング法\n・傾向スコアを用いたマッチング法\n・傾向スコアを用いた逆確率重み付け法\nなど様々なアプローチを学びPythonで実装していきます。\n\n\n最終的には、オンラインショップのクーポン付与の例を取り上げて因果関係を見ていきます。\n統計的因果推論をしっかり学んでビジネスに活かせるようになりましょう！",
      "target_audience": [
        "統計的因果推論に興味のある方",
        "実際に様々な因果関係を突き止めたい方"
      ]
    },
    {
      "title": "Stable Diffusion Fine-Tuning: 실전 튜토리얼",
      "url": "https://www.udemy.com/course/stable-diffusion-fine-tuning/",
      "bio": "생성형 AI의 원리부터 DreamBooth, Textual Inversion, LoRA 까지 — 직접 구현하며 배우는 Stable Diffusion 파인튜닝 실전 가이드",
      "objectives": [
        "Stable Diffusion의 기본 개념과 모델 아키텍처를 이해합니다.",
        "실제 데이터셋을 사용하여 Fine-Tuning 진행합니다.",
        "DreamBooth, LoRA, Textual Inversion 등 다양한 튜닝 기법을 이해하고 적용해봅니다.",
        "실전 프로젝트를 통해 AI 기반 이미지 생성 모델 활용 능력을 강화합니다."
      ],
      "course_content": {
        "생성형 AI와 Stable Diffusion 이해하기": [
          "강의 오리엔테이션",
          "생성형 AI 개요 및 Diffusion 모델 구조 이해",
          "Stable Diffusion의 원리와 Fine-Tuning 개요"
        ],
        "Stable Diffusion Fine-Tuning 실습": [
          "Stable Diffusion 기반 Text-to-Image 생성 실습",
          "DreamBooth를 활용한 개인화 Fine-Tuning 실습",
          "Textual Inversion을 활용한 커스텀 이미지 학습 실습"
        ],
        "모델 평가 및 실무 적용 전략": [
          "Fine-Tuning 기법 비교 및 성능 평가",
          "경영진을 설득하라: 어떤 Fine-Tuning 방식이 우리에게 최적일까?"
        ]
      },
      "requirements": [
        "Python 기본 문법"
      ],
      "description": "생성형 AI 모델을 직접 다뤄보고 싶지만, 어디서부터 시작해야 할지 막막하셨나요?\n이 강의는 Stable Diffusion을 중심으로 생성형 AI의 전반적인 개념부터 실습까지 한 번에 배우는 실전 중심 튜토리얼입니다.\n기초 개념은 물론, Hugging Face의 diffusers 라이브러리를 활용한 실제 코드 기반 실습을 통해\nDreamBooth, Textual Inversion, LoRA과 같은 대표적인 파인튜닝 기법들을 직접 구현해봅니다.\n\n\n이 강의에서는 다음을 배우게 됩니다:\n생성형 AI(GAN, Diffusion)의 개요와 Stable Diffusion의 작동 원리\nHugging Face Diffusers 기반 프로젝트 환경 구성\nLoRA / DreamBooth / Textual Inversion 실습\n나만의 데이터셋을 활용한 이미지 생성 모델 커스터마이징\n모델 학습 결과 비교 및 튜닝 전략\n학습된 모델의 저장, 공유, 실무 활용\n이런 분께 추천합니다:\n생성형 AI 모델의 개념과 구조를 알고 싶은 입문자 및 개발자\n단순한 모델 사용을 넘어 직접 튜닝하고 커스터마이징하고 싶은 분\n논문은 어렵고 실습 위주로 익히고 싶은 분\n연구, 서비스, 포트폴리오 프로젝트 등에 AI 모델을 활용하고 싶은 분\n사전 준비 사항:\nPython 기초\nGoogle Colab 또는 로컬 Python 환경 사용 경험\n(비전공자도 충분히 따라올 수 있도록 구성되어 있습니다)",
      "target_audience": [
        "AI 기반 이미지 생성 및 Fine-Tuning에 관심 있는 연구자, 개발자",
        "Python 프로그래밍에 기초 지식이 있는 초급~중급자"
      ]
    },
    {
      "title": "Aprenda Machine Learning com Python na Prática",
      "url": "https://www.udemy.com/course/aprenda-machine-learning-com-python-scikit-learn-matplotlib-pandas/",
      "bio": "Aprenda usar Jupyter Notebooks, Numpy, Matplotlib, Pandas e Scikit-Learn para Aplicar Algoritmos de Machine Learning",
      "objectives": [
        "Trabalhar com Jupyter Notebooks no Anaconda ou Google Colab",
        "Explorar a Biblioteca Python Numpy",
        "Explorar a Biblioteca Python Pandas",
        "Explorar a Biblioteca Python Matplotlib",
        "Explorar a Biblioteca Python Scikit-Learn",
        "Algoritmos de Regressão",
        "Algoritmos de Classificação",
        "Clustering"
      ],
      "course_content": {
        "Dia 01": [
          "Como será Estruturado o Curso?",
          "Introduction",
          "Seus resultados vem também da sua atitude diante das oportunidades.",
          "Usando o Jupyter Notebook com Google Colab",
          "Usando Jupyter Notebook com o Anaconda no seu Desktop ou Notebook",
          "Introdução ao Machine Learning",
          "Abordagens de Machine Learning",
          "Ciclo de Vida de um Projeto de Machine Learning"
        ],
        "Dia 02": [
          "Machine Learning com NumPy",
          "02-02-Verificando se o NumPy está Instalado no Jupyter Notebooks com Anaconda",
          "Verificando NumPy com Google Colab",
          "Criando ndarrays com NumPy",
          "Selecionando Elementos em Arrays de 2 Dimensões",
          "Slice com Intervalo em Arrays de 2 Dimensões. Slice & Step Numpy",
          "Slice & Steps com um pouco mais de Detalhes",
          "Métodos python ndarray: sum() e mean()",
          "Métodos Python ndarray: reshape()",
          "Funções Numpy: concatenate() python function",
          "Funcoes vs Metodos ndarray. Qual a diferença?",
          "Pandas: Introducao",
          "Criando Series com Pandas no Python",
          "Criando Series com Pandas com diferentes tipos de dados",
          "Criando Series com Pandas usando Dicionarios de Dados Python",
          "Operações Matemáticas e Estatísticas com Pandas",
          "Trabalhando com Valores Nulos ou Vazios",
          "Criando Dataframes a Partir de Lista de Listas",
          "Criando Dataframes a Partir de Dicionario de Listas",
          "Adicionando Colunas ao Dataframe",
          "Criando Dataframes Complexos",
          "A importância de Dominar Dataframes para Mahine Learning",
          "Importando e Carregando Arquivos no Google Colab",
          "Explorando Dados do Dataframe",
          "Renomeando Linhas e Colunas",
          "Selecionando Linhas e Colunas nos Dataframes",
          "Atualizando Dados no Dataframe: Update, Remoção, Colunas Calculadas etc"
        ],
        "Dia 03": [
          "Introdução",
          "Criando Gráficos de Dispersão para Encontrar Correlação de Variáveis",
          "Usando Gráfico de Barras para Econtrar Diferenças entre Categorias de Dados",
          "Usando Histogramas para Encontrar Frequencias",
          "Graficos de Linha no matplotlib",
          "Integração Pandas x Matplotlib",
          "Usando Orientação a Objetos no Matplotlib para Criar Apresentações de Gráficos",
          "Introducao ao Python Scikit-Learn",
          "Regressão Linear com Scikit-Learn: Classes, Métodos e Atributos",
          "Estimators com Scikit-Learn: Encontrando Semelhanças entre 4 Restaurantes",
          "Predictors com Scikit-Learn: Previsão de Resultados",
          "Pre-processamento de dados : Tratando valores ausentes com Scikit-Learn",
          "Transformando Variáveis Categóricas com Scikit-Learn",
          "Escalonamento de Variáveis com Scikit-Learn",
          "03 - 16 - Pipelines com Scikit-Learn",
          "Scikit-Learn ColumnTransformer",
          "Acurácia do Modelo",
          "Precision, Recall e F1-Score: Avaliando a Precisão do Modelo",
          "Métricas de Regressão - RMSE e Erro Médio Quadrático",
          "Métricas de Regressão : Coeficiente de Determinação",
          "Modelos de Seleção: Split Train Test",
          "Modelos de Seleção: k-Fold (Validação Cruzada)"
        ],
        "Dia 04": [
          "Introdução á Regressão",
          "Fundamentos da Regressão Linear",
          "Regressão Linear com Scikit-Learn",
          "Fundamentos de Regressão Polinomial",
          "Regressão Polinomial com Scikit-Learn",
          "Pipelines com Scikit-Learn",
          "Validação Cruzada com Pipelines",
          "Introdução a Algoritmos de Classificação",
          "Implementação de Algoritmo de Classificação com Decision Tree e Google Colab",
          "Implementação do Random Forest",
          "Introdução ás Maquinas de Vetores de Suporte",
          "Machine Learning : Aprendizagem Não Supervisionada com Clustering",
          "Topico Avançado: Redução de Dimensionalidade",
          "Topico Avançado Overfitting",
          "Topico Avançado: Underfitting com Python & Scikit-Learn",
          "Topico Avançado: Ajuste de Hiperparâmetros com Python e Scikit-Learn"
        ],
        "Projeto": [
          "Introdução",
          "Tarefa 1: Carregar e Observar os Dados",
          "Tarefa 2: Exploração dos Dados",
          "Tarefa 3: Check de Valores Inválidos",
          "Tarefa 4: Remover Linhas Inválidas",
          "Tarefa 5: Split dos Dados em Subconjuntos de Treinamento e Teste",
          "Tarefa 6 - Verifique se há Correlação forte entre as variáveis independentes",
          "Tarefa 7: Crie Gráficos de Dispersão",
          "Tarefa 8 - Pré-processamento de Dados",
          "Tarefa 9 - Treinar o Modelo",
          "Tarefa 10 - Avaliar o Modelo",
          "Tarefa 11 - Usar ColumnTransformer e Pipeline",
          "Tarefa 12 - Usar Pipeline para Treinar o Modelo",
          "Tarefa 13 - Avaliar o Modelo com Pipeline",
          "Tarefa 14 - Fazer Validação cruzada usando Pipeline"
        ],
        "Python para Iniciantes - Dia 01": [
          "Esclarecimentos sobre as ferramentas",
          "Introducao",
          "01-02-Instalando Interpretador Python",
          "01-04 - Por que usar o VSCODE",
          "Instalando o VSCODE",
          "Usando VSCode para rodar seu programa Python",
          "Comentarios em Python: Single Line & Multiple Lines",
          "Variaveis em Python",
          "Operadores em Python"
        ],
        "Python para Iniciantes - Dia 02": [
          "Inteiros em Python",
          "Python Float Data Type",
          "Python String Data Type e Formatação de Strings",
          "Type Casting em Python: Convertendo Tipos de Dados em Python",
          "Listas em Python como Criar e Como acessar",
          "Operações de Adição, Concatenação e Tamanho de Lista em Python",
          "Modificando Elementos em uma Lista",
          "Outras Operações Importantes com Lista",
          "Tuplas em Python",
          "Dicionários em Python",
          "Fazendo seu Programa Interagir com Usuário: print(), input() e escape characters",
          "Caracteres de Escape: Imprimindo Citações e Criando um Programa De Entrevista"
        ],
        "Python para Iniciantes - Dia 03": [
          "Introdução",
          "IF - IF ELSE - e IF INLINE no PYTHON",
          "For Loop em Python - Sintaxe e Exemplos Básicos",
          "Acessando Indices de Elementos no For Loop em Python",
          "Acessando e Imprimindo Indices de Elementos (sintaxe old school)",
          "Acessando Elementos de Dicionarios com For Loops em Python",
          "Iteração de Loops com o metodo range() em python",
          "Python Loops com range() Reverso Explicados",
          "Python Loops While",
          "Break em Loops Python",
          "Break Statements em Loops Aninhados. Python Nested Loops",
          "Continue Statment em Python: Estrutura Basica",
          "Continue Statement em Loops Aninhados: Nested Loops",
          "Try & Except Statement. Como tratar exceções no Python",
          "Funções em Python o Que são e Como definir Python Functions",
          "Definindo suas Próprias Funções 6min",
          "Documentando suas Funções com docstring",
          "Variáveis Globais vs Variáveis Locais",
          "Modificando Variáveis Globais",
          "Cuidados com Parâmetros default quando usamos tipos mutáveis, listas, dicionario",
          "Lista de Parâmetros de Comprimento Variável",
          "Importando Modulos em Python",
          "Criando seu Proprio Modulo",
          "Como Garantir Acesso aos Modulos em Subdiretorios",
          "Como acessar Modulos em Subdiretorios - Pratica",
          "Importando Modulos em Diretórios Acima do seu Projeto ou Outros Drives",
          "Importante: Encerramento"
        ]
      },
      "requirements": [
        "Não precisa experiência prévia em Python."
      ],
      "description": "Bem-vindo ao curso \"Aprenda Machine Learning com Python na Prática\"! Se você está procurando uma maneira eficiente e prática de dominar o Machine Learning, este é o curso perfeito para você. Este treinamento foi cuidadosamente elaborado para oferecer um aprendizado profundo, prático e altamente aplicável, utilizando a linguagem Python.\nO que você aprenderá\nNeste curso, você explorará desde os conceitos básicos até as técnicas mais avançadas de Machine Learning. A seguir, confira alguns dos tópicos que você irá abordar:\nIntrodução ao Machine Learning\nFundamentos do Machine Learning: Definição, tipos de aprendizado (supervisionado, não supervisionado)\nAmbiente de Desenvolvimento: Configuração do ambiente de trabalho com Python no Anaconda ou Google Colab, instalação de bibliotecas essenciais como NumPy, Pandas, Scikit-learn e Matplotlib.\nPreparação dos Dados\nColeta e Limpeza de Dados: Técnicas de manipulação de dados, tratamento de valores nulos, duplicados e categóricos usando Pandas.\nAnálise Exploratória de Dados (EDA): Uso de visualizações gráficas para compreender padrões e correlações nos dados.\nModelos de Machine Learning\nRegressão Linear: Fundamentos, implementação e avaliação de modelos de regressão.\nÁrvores de Decisão e Florestas Aleatórias: Construção, interpretação e aplicação de árvores de decisão e florestas aleatórias para classificação.\nSuporte Vetorial (SVM): Introdução, teoria e implementação prática dos modelos de Máquinas de Vetores de Suporte.\nEstratégias de Classificação Multiclasse\nOne-vs-Rest (OvR): Definição, implementação e quando usar essa estratégia. Aprenda como essa técnica simplifica problemas multiclasse tratando cada classe contra todas as outras.\nOne-vs-One (OvO): Entendimento profundo de como funciona esta estratégia e sua aplicação prática. Ideal para situações em que a diferenciação entre classes precisa ser mais detalhada.\nAnálise de Métricas e Modelos\nMétricas de Avaliação: Compreensão de métricas como acurácia, precisão, recall, F1-score e matriz de confusão.\nValidação Cruzada e Otimização de Modelos: Técnicas para validação cruzada, ajuste fino de hiperparâmetros e avaliação de desempenho de modelos para garantir a robustez e eficácia.\nImplementação Avançada\nUsando Bibliotecas Nativas do Python: Scikit-Learn, Matplotlib, Numpy e Pandas.\nProjeto Final Prático: Desenvolvimento de um projeto de machine learning do início ao fim, envolvendo coleta, limpeza, análise, modelagem e avaliação de dados reais.\nPor que este curso é para você?\nPrática Intensa: Todas as aulas incluem exemplos práticos e projetos reais para garantir que você não apenas aprenda a teoria, mas também saiba como aplicá-la.\nCompreensão Completa: O curso aborda desde os fundamentos até as técnicas avançadas, garantindo que você tenha uma compreensão completa do Machine Learning.\nFerramentas Essenciais: Aprenda a usar as ferramentas e bibliotecas mais populares do Python, preparando-o para enfrentar desafios reais no mercado de trabalho.\n\n\nConclusão\nEste curso foi projetado para transformar iniciantes em especialistas em Machine Learning com Python. Ao final do treinamento, você estará habilitado a criar, avaliar e implementar modelos de Machine Learning de maneira eficiente e prática. Inscreva-se agora e leve suas habilidades em Python e Machine Learning para o próximo nível com \"Aprenda Machine Learning com Python na Prática\"!",
      "target_audience": [
        "Desenvolvedores Python que não conhecem machine learning",
        "Iniciantes em Machine Learning",
        "Cientistas de Dados Iniciantes que querem aprender Machine Learning com Python"
      ]
    },
    {
      "title": "六小時學會資料科學",
      "url": "https://www.udemy.com/course/ywfszkyr/",
      "bio": "Python、爬蟲、資料分析、機器學習和深度學習",
      "objectives": [
        "學習利用Python寫網路爬蟲、數據分析、資料預測走向、資料視覺化等程式與功能",
        "學習利用課堂中學習的Python程式解決經典問題，例如影像分析、分類與生存預測等",
        "學習利用資料科學解決現實問題"
      ],
      "course_content": {
        "寫在前頭 (Before we start)": [
          "推廣 (中文版)",
          "Promote (English version)"
        ],
        "課程與開發環境介紹": [
          "課程簡介",
          "課程單元說明",
          "Python介紹",
          "Colab 介紹"
        ],
        "Python資料擷取與網頁爬蟲": [
          "BeautifulSoup套件介紹",
          "網頁結構巡覽",
          "PTT八卦版網頁實戰",
          "Yahoo電影資訊實戰"
        ],
        "數據分析與資料視覺化": [
          "數據分析框架與方法介紹",
          "資料視覺化與工具介紹",
          "視覺化案例實戰一",
          "視覺化案例實戰二"
        ],
        "機器學習與Kaggle經典資料集": [
          "線性邏輯與迴歸介紹",
          "決策樹與隨機森林",
          "鐵達尼號乘客生存預測實戰",
          "共享單車需求實戰"
        ],
        "深度學習(類神經網路)與經典案例": [
          "類神經網路概念介紹",
          "CNN, RNN, LSTM介紹",
          "狗貓影像分類實戰",
          "飛機航班載客量預測實戰"
        ],
        "AIdea平台與資料集實作": [
          "AIdea平台介紹",
          "Aidea專題使用",
          "AOI影像預測專題實戰",
          "設備汰換預測專題實戰"
        ]
      },
      "requirements": [
        "曾使用任一程式語言寫過程式者 或 具備程式概念和基礎"
      ],
      "description": "課程目標/學習目標：\n1. 學習利用Python寫網路爬蟲、數據分析、資料預測走向、資料視覺化等程式與功能\n2. 學習利用課堂中學習的Python程式解決經典問題，例如影像分析、分類與生存預測等\n3. 學習利用資料科學解決現實問題\n\n\n課程特色：\n1. 使用線上Colab程式撰寫與資料分析平台\n2. 以實際資料為案例說明與練習\n3. 以口頭敘述情境和問題為導向之教學\n\n\n教材影音時數：\n至少6小時\n\n\n適用對象：\n1. 對資料科學感興趣的人\n2. 對Python、爬蟲、資料分析、機器學習和深度學習感興趣的學習者\n3. 對資料科學有興趣的自主學習者\n\n\n先備知識：\n曾使用任一程式語言寫過程式者 或 具備程式概念和基礎\n\n\n教學設計：\n使用專題導向學習方式設計\n\n\n維基百科認為的資料科學：\n資料科學（英語：data science）是一門利用資料學習知識的學科，其目標是通過從資料中提取出有價值的部分來生產資料產品。它結合了諸多領域中的理論和技術，包括應用數學、統計、圖型識別、機器學習、資料視覺化、資料倉儲以及高效能計算。資料科學通過運用各種相關的資料來幫助非專業人士理解問題。 資料科學技術可以幫助我們如何正確的處理資料並協助我們在生物學、社會科學、人類學等領域進行研究調研。此外，資料科學也對商業競爭有極大的幫助。",
      "target_audience": [
        "對資料科學感興趣的人",
        "對Python、爬蟲、資料分析、機器學習和深度學習感興趣的學習者",
        "對資料科學有興趣的自主學習者"
      ]
    },
    {
      "title": "Machine Learning: Natural Language Processing mit Python",
      "url": "https://www.udemy.com/course/machine-learning-natural-language-processing/",
      "bio": "NLP mit Python: Deep Learning, Markov, Naive Bayes, Word2Vec, ChatGPT, Neuronale Netze, KI, LSTM, Seq2Seq, LLM, PyTorch",
      "objectives": [
        "Die Grundlagen des Natural Language Processing (NLP) verstehen.",
        "Python und relevante Bibliotheken für NLP einrichten und nutzen.",
        "N-gram Sprachmodelle verstehen und implementieren.",
        "Textklassifikation mit Naive Bayes und Python durchführen.",
        "Die Bedeutung von Word Embeddings in NLP verstehen.",
        "Word2Vec und seine Implementierung in Python kennenlernen.",
        "Hidden Markov Models für Sequenzmodellierung anwenden.",
        "Neuronale Netze für NLP trainieren und implementieren.",
        "Rekurrente Neuronale Netze (RNNs) für Textverarbeitung einsetzen.",
        "Long short term memory (LSTM) verstehen und implementieren.",
        "Seq2Seq-Modelle für maschinelle Übersetzung bauen und trainieren.",
        "Attention Mechanismen in NLP verstehen und implementieren.",
        "Transformer-Modelle und ihre Architektur kennenlernen.",
        "Die Implementierung von Transformern mit PyTorch erlernen.",
        "Fortgeschrittene NLP-Modelle wie GPT-3 verstehen.",
        "Mathematische Konzepte hinter NLP-Algorithmen verstehen.",
        "Mit numpy und PyTorch Daten für NLP-Projekte verarbeiten.",
        "Python-Grundlagen für Datenverarbeitung und Visualisierung.",
        "Daten laden, aufbereiten und visualisieren für NLP-Anwendungen.",
        "Die Fähigkeit, eigene NLP-Modelle zu entwerfen und zu implementieren."
      ],
      "course_content": {
        "Introduction": [
          "Dein Dozent: Philipp",
          "Was du in diesem Kurs lernen wirst",
          "Willkommen im Kurs!"
        ],
        "Download der Kursmaterialien": [
          "INTRO: Download der Kursmaterialien",
          "Download von Anaconda pt.1",
          "Download von Anaconda pt.2",
          "Einrichtung der Programmierumgebung"
        ],
        "Einleitung In Natural Language Processing (NLP)": [
          "INTRO: Einleitung NLP",
          "Definition: Natural Language Processing (NLP)",
          "Stastisches Lernen",
          "Zeitalter des Deep Learnings",
          "Warum ist Sprache schwer zu verstehen?"
        ],
        "N-gram Sprachmodelle": [
          "INTRO: N-gram Sprachmodelle",
          "Definition N-gram Sprachmodelle",
          "Markov Annahme",
          "Generierungs Methoden",
          "Evaluierung",
          "Smoothing",
          "Python Projekt N-Gram pt.1",
          "Python Projekt N-Gram pt.2",
          "Python Projekt N-Gram pt.3"
        ],
        "Textklassifikation": [
          "INTRO: Textklassifikation",
          "Warum Textklassifikation?",
          "Verfahren",
          "Naive Bayes pt.1",
          "Naive Bayes pt.2",
          "Naive Bayes Beispiel",
          "Naive Bayes Implementierung pt.1",
          "Naive Bayes Implementierung pt.2",
          "Naive Bayes Implementierung pt.3"
        ],
        "Worteinbettungen": [
          "INTRO: Worteinbettungen",
          "Wie werden Wörter in NLP Modellen dargestellt?",
          "Warum Wordembeddings?",
          "Wörter und Vektoren",
          "Cosinus-Ähnlichkeit",
          "Word Embedding Implementierung pt.1",
          "Word Embedding Implementierung pt.2",
          "Word Embedding Implementierung pt.3"
        ],
        "Word2Vec": [
          "INTRO: Word2Vec",
          "Skip-Gram",
          "Skip-Gram Objective function",
          "Training",
          "Word2Vec Python Implementierung pt.1",
          "Word2Vec Python Implementierung pt.2",
          "Word2Vec Python Implementierung pt.3"
        ],
        "Hidden Markov Models": [
          "INTRO: Hidden Markov Models",
          "Warum Sequenzmodellierung?",
          "Wortartbestimmung",
          "Hidden Markov Modelle",
          "Viterbi Algorithmus",
          "Viterbi Beispiel pt.1",
          "Viterbi Beispiel pt.2",
          "Viterbi Python Implementierung"
        ],
        "Neuronale Netze für NLP": [
          "INTRO: Neuronale Netze für NLP",
          "Einführung Neuronale Netze pt.1",
          "Einführung Neuronale Netze pt.2",
          "Feedforward-Process",
          "Aktivierungsfunktionen",
          "weights und biases",
          "Matrix Notationen im Neuronalen Netz",
          "Backpropagation",
          "Pooling",
          "Neuronales Netz Python Implementierung pt.1",
          "Neuronales Netz Python Implementierung pt.2",
          "Neuronales Netz Python Implementierung pt.3",
          "Neuronales Netz Python Implementierung pt.4",
          "Neuronales Netz Python Implementierung pt.5",
          "Neuronales Netz Python Implementierung pt.6",
          "Neuronales Netz Python Implementierung pt.7",
          "Neuronales Netz Python Implementierung pt.8"
        ],
        "Rekurrente Neuronale Netze": [
          "INTRO: Rekurrente Neuronale Netze",
          "Einführung RNN",
          "Architektur RNN",
          "RNN vs. Feedforward NN",
          "Anwendungen",
          "Training von RNNs",
          "Text Generierung mit RNNs",
          "Nachteile bisheriger Sprachmodelle",
          "Multi layer RNNs",
          "Bidirectional RNNs",
          "RNN Python Implementierung pt.1",
          "RNN Python Implementierung pt.2",
          "RNN Python Implementierung pt.3",
          "RNN Python Implementierung pt.4",
          "RNN Python Implementierung pt.5"
        ]
      },
      "requirements": [
        "Du brauchst keine Vorkenntnisse und lernst alles was du brauchst im Kurs. (Grundsätzliches Interesse für Mathe ist erwünscht!)"
      ],
      "description": "Möchtest du die Themen Machine Learning, Deep Learning und speziell Natural Language Processing endlich verstehen und deiner Neugier nachgehen?\nDann ist dieser Kurs genau das Richtige für Dich!\n\n\nNLP mit Python: Deep Learning, Marchine Learning, N-Gram, Word Embedding, Viterbi, Rekurrente Neuronale Netze (RNN), Markov, Naive Bayes, Word2Vec, ChatGPT, Neuronale Netze, KI, Long short term memory (LSTM), Seq2Seq, Transformer / Large Language Models (LLMs), PyTorch, Numpy...\n\n\nHast du dich schonmal gefragt wie es wäre...\neine der nachgefragtesten Fähigkeiten in 2024 zu lernen?\nendlich das komplexe Thema NLP zu verstehen?\ndahinter zu blicken wie ChatGPT funktioniert?\n\n\nMit diesem Kurs bekommst du dein Komplettpaket für das Thema Natural Language Processing und allem was dazu gehört:\nAbschnitt 1: Introduction\nIn diesem Auftakt des Kurses begrüßt dich Philipp, dein Dozent, und gibt dir einen Vorgeschmack darauf, was dich erwartet. Er skizziert die faszinierende Welt des Natural Language Processing mit Python und zeigt dir, welche spannenden Einblicke und Fähigkeiten du in den kommenden Abschnitten erlangen wirst.\nAbschnitt 2: Download der Kursmaterialien\nBevor es richtig losgeht, ist es wichtig, die richtigen Werkzeuge zu haben. Hier lernst du, wie du Anaconda herunterlädst und einrichtest, um eine effiziente Programmierumgebung für den Kurs zu schaffen.\nAbschnitt 3: Einleitung NLP\nNun tauchst du ein in die Grundlagen des Natural Language Processing. Von den grundlegenden Definitionen über die Entwicklung von statistischen Ansätzen bis hin zum aktuellen Zeitalter des Deep Learnings erforschst du, warum Sprachverarbeitung so herausfordernd und gleichzeitig faszinierend ist.\nAbschnitt 4: N-gram Sprachmodelle\nHier wird es praktisch! Du lernst, wie N-gram Sprachmodelle funktionieren, von der Markov-Annahme bis hin zur Evaluierung und Glättungstechniken. Mit Python-Projekten in mehreren Teilen wirst du diese Konzepte direkt umsetzen und ein Verständnis für ihre Anwendung entwickeln.\nAbschnitt 5: Textklassifikation\nWarum ist Textklassifikation wichtig und welche Verfahren stehen zur Verfügung? Du entdeckst die Grundlagen, insbesondere den Naive-Bayes-Algorithmus, und siehst, wie er in der Praxis angewendet wird. Durch eine umfassende Implementierung in Python wirst du in der Lage sein, Texte automatisch zu klassifizieren.\nAbschnitt 6: Worteinbettungen\nWie werden Wörter in NLP-Modellen repräsentiert? Diese Frage wird in diesem Abschnitt beantwortet, wenn du die Bedeutung von Word Embeddings erkundest. Du wirst sehen, warum sie so wichtig sind und wie sie die Grundlage für viele fortschrittliche NLP-Anwendungen bilden.\nAbschnitt 7: Word2Vec\nHier steigst du tiefer in die Welt der Wortvektoren ein, insbesondere mit dem beliebten Skip-Gram-Modell. Du wirst verstehen, wie das Training funktioniert und wie du es in Python implementierst, um die semantischen Beziehungen zwischen Wörtern zu erfassen.\nAbschnitt 8: Hidden Markov Models\nDie Sequenzmodellierung ist ein entscheidender Schritt für fortgeschrittene NLP-Anwendungen. Mit Hidden Markov Models und dem Viterbi-Algorithmus lernst du, wie man beispielsweise Wortarten bestimmt und die Wahrscheinlichkeit von Sequenzen berechnet.\nAbschnitt 9: Neuronale Netze für NLP\nNeuronale Netze sind das Herzstück vieler moderner NLP-Modelle. Von Feedforward-Netzwerken bis hin zu komplexen RNNs lernst du, wie sie funktionieren und wie du sie effektiv implementierst, um Sprachmuster zu erkennen und Sprachgenerierung durchzuführen.\nAbschnitt 10: Rekurrente Neuronale Netze\nHier wird es rekursiv! RNNs bieten die Möglichkeit, Sequenzdaten zu verarbeiten, was sie ideal für NLP-Anwendungen macht. Du lernst ihre Architektur kennen, trainierst sie und siehst, wie sie zur Textgenerierung eingesetzt werden können.\nAbschnitt 11: Long short term memory\nLSTM-Netzwerke sind eine Weiterentwicklung von RNNs, die das Problem des Verschwindens oder Explodierens von Gradienten angehen. Du wirst verstehen, wie sie funktionieren und wie sie klassischen RNNs überlegen sind.\nAbschnitt 12: Seq2Seq\nDie nächste Stufe der NLP-Modellierung: Seq2Seq. Hier erfährst du, wie man maschinelle Übersetzer und andere auf Encoder-Decoder-Architekturen basierende Modelle baut. Du wirst sehen, wie sie trainiert werden und wie sie effektiv für Aufgaben wie Übersetzung eingesetzt werden können.\nAbschnitt 13: Attention\nDas Schlüsselkonzept, das viele moderne NLP-Modelle antreibt: Attention. Du wirst verstehen, wie Attention funktioniert, wie es sequenzielle Modelle verbessert und wie du es selbst implementieren kannst.\nAbschnitt 14: Transformer / Large Language Models (LLMs)\nDie Evolution der NLP-Modelle: Transformer und Large Language Models. Du wirst sehen, warum sie so leistungsstark sind, wie sie funktionieren und wie du sie selbst implementieren kannst, um fortgeschrittene NLP-Aufgaben zu lösen.\nAbschnitt 15: Transformer Implementierung mit PyTorch\nJetzt wird es praktisch! Mit PyTorch lernst du, wie du Transformer-Modelle von Grund auf baust, trainierst und verwendest, um NLP-Aufgaben zu lösen. Durch praktische Übungen wirst du mit den Werkzeugen und Techniken vertraut gemacht, die du für eigene Projekte benötigst.\nAbschnitt 16: GPT-3\nHier erkundest du die Architektur und Funktionsweise von GPT-3, einem der fortschrittlichsten Large Language Models. Du wirst sehen, wie es trainiert wird und welche Anwendungen es bietet.#\nAbschnitt 17: Mathe, numpy, PyTorch\nUm die NLP-Modelle wirklich zu verstehen und zu implementieren, musst du die Mathematik dahinter beherrschen. Hier lernst du die grundlegenden Konzepte und Werkzeuge wie numpy und PyTorch kennen, die dir dabei helfen.\nAbschnitt 18-22: Python Intro\nBevor es losgeht, ist es wichtig, eine solide Grundlage in Python zu haben. Diese Abschnitte bieten eine umfassende Einführung in die Python-Grundlagen, von den Datentypen über Datenstrukturen bis hin zu Schleifen und Funktionen.\nAbschnitt 23-24: Python für Datenverarbeitung und Visualisierung\nSchließlich lernst du, wie du Daten mit Python laden, aufbereiten und visualisieren kannst, um sie für deine NLP-Projekte zu verwenden. Von pandas für Datenverarbeitung bis hin zu matplotlib für Visualisierungen wirst du alle wichtigen Werkzeuge kennenlernen. Die Python Abschnitte sind für die Teilnehmer gedacht, die noch keine Vorkenntnisse mit Python haben.\n\n\nDu bekommst sofortigen Zugriff auf:\n10 Stunden NLP Komplettpaket\nZugang zur Community. Austausch mit allen Kursmitgliedern\nSupport von Experte Philipp\nLebenslanger Zugriff auf den Kurs und alle zukünftigen Updates\n\n\nUdemy Zufriedenheitsgarantie\nUdemy hat eine 30 Tage 100% Geld zurück Garantie. Wenn Du also doch nicht zufrieden mit dem Kauf bist, bekommst du das gesamte Geld sofort zurück!\n\n\nSchreibe dich jetzt in den Kurs ein starte noch heute das Lernen!\n\n\nWir freuen uns schon Dich in der ersten Lektion begrüßen zu dürfen!\nPhilipp & Marius",
      "target_audience": [
        "Personen, die lernen wollen, was wirklich hinter den neuesten Sprachmodellen wie ChatGPT steckt und wie man anfängt Modelle selber zu implementieren",
        "Alle Personen, die sich in dem Thema Natural Language Processing l"
      ]
    },
    {
      "title": "如何用Python做数据可视化",
      "url": "https://www.udemy.com/course/python-tx/",
      "bio": "Python数据可视化工具实战",
      "objectives": [
        "1.了解Python语言及常用的数据挖掘工作平台：Jupyter Notebook",
        "2.了解Numpy和Pandas中常用数据结构",
        "3.初步掌握使用Python进行数据整理",
        "3.掌握使用Python进行数据可视化"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "1.Python语言介绍",
          "2.Python数据挖掘工作平台",
          "3.Numpy和Pandas中常用的数据结构",
          "4.数据整理（上）",
          "5.数据整理（下）",
          "6.数据可视化（上）",
          "7.数据可视化（下）"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "面向0基础学员"
      ],
      "description": "数据整理是数据挖掘工作的基础。我们在一开始先介绍了Python语言以及常用的数据挖掘工作平台：Jupyter Notebook。接着我们引入了Python中常用的数据结构（Ndarray, Series, DataFrame）。在数据整理技术方面，我们使用了一个接近实际情况的完整案例一步步进行讲解。目的是通过这个数据整理工作案例讲解，使同学了解常用的Python数据处理功能语句。\n数据可视化目标一是让同学了解使用Python进行数据可视化的常用方法（Matplotlib & Seaborn这两个库，pyplot方法，以及DataFrame的plot方法）；目标二是让同学可以完成一个典型的数据可视化任务（pyplot基本作图、seaborn基本作图、pyplot图形个性化方法、plt.subplot多子图方法、plt.figure全图调参方法等）。另外我们也会授之以渔，教同学如何使用Matplotlib & Seaborn的官方文档去处理更多样、更复杂的数据可视化任务。\n本节课程是由授课老师与三节课合作制作的。在此，要特别感谢老师的辛苦付出！经历了课程立项、设计、开发中的众多环节，我们才能最终为你呈现现在的这门课程。无论是授课老师还是三节课团队，都希望这门课程能够让你有所收获，希望同学们结合个人工作情况，学以致用。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "1.0-1岁数据分析方向从业者",
        "2.想要提升数据分析能力的职场人",
        "3.对Python感兴趣的学习者"
      ]
    },
    {
      "title": "【実践】dbt完全入門！dbt × SQL × DuckDB超速習コースで最先端ETLとデータモデリングを学ぼう！",
      "url": "https://www.udemy.com/course/dbt-sql-duckdb/",
      "bio": "dbt × SQL × DuckDBで実践！データ変換の自動化・テスト駆動開発・ドキュメント生成まで、モダンデータスタックの基礎から応用まで完全マスター",
      "objectives": [
        "dbtの基礎知識と開発環境構築、プロジェクト初期化からモデル実行までの一連の流れ",
        "ステージング→マートの階層型データモデル開発と、各種マテリアライゼーション戦略の使い分け",
        "ジェネリックテストとカスタムテストによるデータ品質保証、schema.ymlを使った包括的なテスト設計",
        "Jinjaマクロを活用した動的SQL生成とコード再利用、dbt Utilsパッケージの活用方法",
        "インクリメンタルモデルによる大規模データの効率的な処理と、スナップショットによる履歴データ管理",
        "SQLの基本構文"
      ],
      "course_content": {
        "はじめに": [
          "紹介"
        ],
        "SQL の使い方": [
          "SQL概要",
          "DB-FIDDLE",
          "DB-FIDDLE使い方",
          "テーブル作成とSELECT文",
          "WHERE句",
          "集計関数",
          "GROUP BY句",
          "ORDER BY句",
          "条件分岐のCASE WHEN",
          "JOIN句",
          "JOIN句の種類とWITH句",
          "LEFT JOIN",
          "続いてはdbtへ！"
        ],
        "dbt の開発環境を構築しよう！": [
          "【座学】dbtの概要について",
          "以降のレクチャーの準備",
          "dbt コマンドが実行できる環境を構築",
          "dbt 学習用プロジェクトの作成と seed データ読み込み",
          "dbt の最初のモデルを作成してみる"
        ],
        "dbt のモデル開発と品質管理に挑戦しよう！": [
          "複数の Staging モデルを作成し、中核となる Marts モデルを作成する",
          "schema.yml にデータテストを定義してデータの品質保証について学ぶ",
          "dbt docs を実行してデータのドキュメンテーションとリネージュについて学ぶ",
          "【応用】データソースを定義して seeds から DuckDB のソース参照へ移行する",
          "【応用】incremental マテリアライゼーションを使ったインクリメンタルモデルの構築を学ぶ"
        ],
        "dbt 応用編: マクロを書けるようになろう + スナップショットで履歴を管理してみよう": [
          "dbt の基礎を支える「マクロ」について学ぶ",
          "スナップショットを通してマスタデータの履歴管理について学ぶ",
          "まとめと終わりの挨拶",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Python がインストールされた環境で簡単なターミナル操作ができれば、SQL から dbt での活用まで一通りを学ぶことができます。",
        "Mac前提での講座を進めていきますが、Windows環境でも基本的には問題ございません。"
      ],
      "description": "データエンジニアリングの世界で急速に普及している dbt（data build tool）を、初心者でも理解できるように基礎から丁寧に解説します。本コースでは、サンプルとなる飲食店の経営データを題材に、SQL と dbt を組み合わせたデータ変換パイプラインの構築方法を実践的に学習します。\n\n\nまず、SQLの基本、そしてdbt の基本概念と DuckDB を使った開発環境の構築から始め、段階的にスキルを積み上げていきます。ステージング層・中間層・マート層という3層アーキテクチャを実装しながら、データモデリングのベストプラクティスを身につけます。\n\n\nコースの中盤では、ジェネリックテストとカスタムテストを活用したデータ品質保証の手法を詳しく解説。schema.yml ファイルを使った包括的なテスト設計により、信頼性の高いデータパイプラインを構築できるようになります。\n\n\n後半では、Jinja テンプレートとマクロを使った高度な技法を習得。動的 SQL の生成、コードの再利用、dbt Utils パッケージの活用など、実務で役立つテクニックを豊富に紹介します。さらに、インクリメンタルモデルによる大規模データの効率的な処理方法や、スナップショット機能を使った履歴データ管理まで、実践的なスキルを幅広くカバーします。\n\n\n各章では実際にコードを書きながら学習を進めるため、理論と実践のバランスが取れた内容となっています。VSCode の拡張機能を活用した効率的な開発方法も紹介し、すぐに実務で活用できるスキルが身につきます。",
      "target_audience": [
        "データエンジニア・アナリティクスエンジニアになりたい方",
        "データを使ってファクトベース・技術ベースのアプローチでビジネスに貢献したい意欲のある方",
        "データアナリストやデータサイエンティストでデータエンジニアリングに興味のある方"
      ]
    },
    {
      "title": "Microsoft Power BI for beginners in Urdu/Hindi",
      "url": "https://www.udemy.com/course/microsoft-power-bi-for-beginners-in-urduhindi/",
      "bio": "Understanding of Microsoft Power BI basics and dashboard development from scratch in Urdu/Hindi language.",
      "objectives": [
        "Learn to create attractive dashboards using the easiest Business Intelligence tool.",
        "Learn basic techniques of data visualization.",
        "Learn to import data from Excel, CSV and folders.",
        "Learn how to create calculations and comparisons with the power of basic DAX, across multiple tables of data.",
        "Learn to create DAX measures and calculated columns for calculations.",
        "Learn how to add bookmarks and page navigation.",
        "Learn dashboard designing and importing images and icons.",
        "Learn how to turn data into insight and data into interactive visualizations to tell a story.",
        "Learn data modeling in power BI.",
        "Learn to collaborate and share content on Microsoft's Powerful platform.",
        "Learn Dashboard-in-a-day at your own pace at home or at your office."
      ],
      "course_content": {},
      "requirements": [
        "Absolutely no experience is required.",
        "A work or school email address to sign up in Power BI is required. Email addresses provided by consumer email services or telecommunication providers cannot be used to signup. This includes outlook, hotmail, gmail, yahoo and others."
      ],
      "description": "Does your data speak? Do you want to transform the bulk of characters into meaningful insights? Do you want to learn to forecast your business need? Do you want to transform the raw bulk of data into eye-catching Interactive Dashboards?\nIf yes, then Microsoft Power BI is the accurate tool and this beginners course will teach you everything you need to know about it.\nThis hands-on course will support you to utilize this tool for your business growth and will also prepare you to start your career in data analysis.\nThe course contains 2+ hours of video of downloading Power BI, understanding its features & functions, Data transformation, Modeling Relationship, basics of DAX aggregate function, data visualization, and dashboard development along with data sets for practice.\nBy the time you complete this course, You'll be able to develop an attractive dashboard using Power BI and find out interesting insights from that. You'll be fully prepared to collect, clean, model, and present data for any purpose.\nLearn to create Dashboards using Microsoft's free tool Power BI for data analysis.",
      "target_audience": [
        "Individuals interested in data science and data visualization.",
        "Anyone looking to start data analytics career.",
        "Passionate professionals who are new to the Business Analysis and keen to learn Power BI for their work. Students learning in the field of Data.",
        "Anyone who is looking to enhance his/her skill sets in the field of Business Analysis."
      ]
    },
    {
      "title": "파이썬으로 시작하는 데이터 사이언스, Colab으로 배우는 핵심 강의",
      "url": "https://www.udemy.com/course/python-datascience-colab/",
      "bio": "딥러닝, 사물인터넷 등 실전 프로젝트를 수행하기 위해 파이썬 프로그래밍 실전 능력을 키우고 데이터 사이언스 전문가가 되기 위한 역량을 키우는 강의입니다. 핵심 내용을 익히도록 하나의 강의에 모든",
      "objectives": [
        "파이썬 프로그래밍",
        "파이썬을 이용한 데이터 분석",
        "사무자동화",
        "개발 환경 설치 없이 Colab으로 프로그래밍하기",
        "머신러닝, 딥러닝을 위한 데이터 가공",
        "파이썬 판다스로 데이터 가공 분석",
        "차트를 사용하는 핵심용도 5가지 습득",
        "핵심 차트 10가지에 대한 이해와 개발",
        "데이터 시각화 분석 기법 설계",
        "다양한 분석에 적절한 차트와 시각화 기법 활용",
        "데이터 시각화와 차트에 대한 이해"
      ],
      "course_content": {
        "강의소개": [
          "강의 소개",
          "코드 소개"
        ],
        "파이썬 기초": [
          "파이썬 강의소개",
          "나의 첫 파이썬 프로그램",
          "변수와 자료형",
          "군집 데이터형"
        ],
        "파이썬 기본": [
          "흐름제어",
          "함수",
          "화면구성 GUI",
          "파일관리"
        ],
        "파이썬 응용": [
          "객체지향-클래스",
          "객체지향-상속",
          "데이터 시각화",
          "웹 스크래핑",
          "Open API"
        ],
        "데이터 조작하기": [
          "Pandas 소개",
          "데이터 가져오기, 저장",
          "데이터 정제",
          "데이터 선택",
          "데이터 추가",
          "데이터 변환",
          "데이터 정렬, 그룹",
          "마라톤 데이터 가공 1",
          "마라톤 데이터 가공 2"
        ],
        "데이터 시각화 분석 - 핵심차트 10": [
          "데이터 시각화란 무엇인가?",
          "Column, Bar 차트 이해",
          "Column, Bar 차트 제작",
          "Dual Axis, 파레토 차트 이해",
          "Dual Axis, 파레토 차트 제작",
          "Pie 차트 이해",
          "Pie 차트 제작",
          "Line 차트 이해",
          "Line 차트 제작",
          "Scatter 차트 이해",
          "Scatter 차트 제작",
          "Bubble 차트 이해",
          "Bubble 차트 제작",
          "Heat Map 이해",
          "Heat Map 제작",
          "Histogram 이해",
          "Histogram 제작",
          "Box Plot 이해",
          "Box plot 제작",
          "Geo 차트 이해",
          "Geo 차트 제작"
        ]
      },
      "requirements": [
        "열심히 하고자 하는 열정"
      ],
      "description": "혹시 비슷하게 생각하고 계시나요?\n\n\n아, 어떻게 하지? 다음 주부터 파이썬 개발 프로젝트인데.\n파이썬은 처음이라 자신이 없는데...\n주말 동안 짧게 집중해서 배울 수는 없을까? 큰일 났네...\n•••\n\n\n장황한 이론보다도 실전에서 할 수 있는 프로젝트 경험이 필요한 때입니다!\n파이썬 기본기,  단시간에 빠르게\n파이썬의 Pandas, Matplotlib, Seaborn 을 이용하여 머신러닝, 딥러닝 등 다양한 프로젝트에서 활용할 수 있는\n데이터 시각화와 분석 기술을 한번에 배워 보세요.\n\n\n보스톤 마라톤 빅 데이터를 파이썬을 이용하여\n원하는 형태로 가공하여 다양한 차트와 기술을 이용하여\n가치있는 정보로 만드는 머신러닝, 딥러닝 프로젝트 준비 과정입니다.\n\n\n훌륭한 축구선수가 되기 위해서는 시작하는 단계에서 기본기를 탄탄하게 다져야 합니다. 유명 골프선수조차도 매년 초가 되면 퍼팅부터 다시 기초를 다집니다. 프로그래밍도 마찬가지입니다. 아무리 인공지능 전문가더라도 프로젝트를 수차례 하다 보면 주기적으로 파이썬 기초를 다시 익힐 필요가 있습니다.\n실제로 그동안 많은 인공지능 프로젝트를 수행하다 보면 파이썬 프로그램에 대한 기초가 튼튼한 사람이 두각을 나타내는 모습을 자주 볼 수 있었습니다. 그래서 함께할 프로젝트 인원을 교육한다는 마음으로, 실전에서 사용하는 핵심적인 내용만 모아 파이썬 과정을 만들었습니다.\n\n\n제가 다시 본다는 마음으로 만들었습니다.\n지난 2019년에 출시되어 많은 수강생 분들에게 사랑받고 있는 파이썬 100분 핵심강의를 기반으로, 그동안의 프로젝트 경험과 수강생 여러분의 의견을 모아 새로운 버전 및 기술을 적용한 핵심 내용 중심의 강의를 새롭게 재구성하였습니다. 프로그래밍 경험이 있지만 파이썬에 익숙하지 않은 분은 물론, 프로그래밍 경험이 전혀 없이 개발의 세계에 뛰어든 분들까지 모두 환영합니다. 실제 파이썬 프로젝트에 투입되기 전 자신감을 얻기 위해 거쳐야 하는 커리큘럼으로 구성했습니다.\n특히, 초보자가 자신의 PC에 개발 환경을 설치하는 과정에서 많은 오류를 경험하게 된다는 불편을 해소하기 위해 로컬 파일을 제외한 나머지 모든 과정의 실습을 설치 없이 언제 어디서나 실행할 수 있는 Google Colab(구글 코랩) 기반으로 진행했습니다. 복잡하게 설치할 필요 없이, 언제 어디서나 쉽게 파이썬 프로그래밍에만 집중하세요!\n\n\n시작하는 부담을 덜어드려요\n가장 먼저 Colab 환경에서 파이썬 프로그래밍을 처음 하는 방법을 배웁니다. 그동안 많은 분들이 프로그램 설치 단계부터 가로막혀 좌절하고 그만두시는 모습을 보았어요. 복잡하게 설치할 필요 없이 구글이 제공하는 클라우드 개발 환경인 Colab에서 온전히 프로그래밍만 집중하실 수 있게 도와드릴게요!\n\n\n알기 쉽게, 빠르게, 핵심만\n프로그래밍은 기초가 중요합니다. 파이썬뿐 아니라 다른 프로그래밍 언어를 배울 때도 기반이 되는 변수, 자료형, 흐름 제어, 함수, 객체지향 등의 개념을 쉬운 예제와 삽화를 통해 알기 쉽게 설명합니다. 다른 언어에도 공통으로 적용되는 프로그램 로직을 익혀보세요.\n\n\n실제 업무도 생각했어요\n강의는 대부분 구글 Colab 환경에서 실습이 이루어지지만, 공장 자동화 등에서 사용하는 GUI(Graphic User Interface), CSV 파일 처리 등 로컬 컴퓨터에서 수행하는 게 더 좋은 영역도 있습니다. 이를 위해 로컬 환경에 개발 도구(Visual Studio Code)를 사용해 파이썬 프로그래밍을 하는 방법도 배웁니다.\n\n\n데이터 사이언스를 위한 파이썬\n데이터 과학 분야에 파이썬이 활발하게 사용되고 있습니다. 인공지능 및 데이터 과학 분야에 진입한다면 꼭 사용해야 하는 데이터 시각화, 웹 스크래핑, Open API 활용 기술들을 쉽지만 곧바로 사용할 수 있는 예제와 함께 알려드립니다. 이밖에도 많은 내용이 강의에 들어있습니다. 함께 도전해보세요!\n\n\n데이터 조작하기\n파이썬 Pandas를 이용하여 데이터를 원하는 데로 조작합니다.\n파이썬 Pandas를 이용하여 CSV데이터를 가져오고, 정제하고, 가공하고, 변환하여 원하는 데이터로 만듭니다.\n보스톤 마라톤 빅데이터를 우리가 원하는 형식으로 가공하여 데이터 시각화와 머신러닝, 딥러닝에 활용할 자료로 만듭니다.\n\n\n데이터 시각화 분석\n파이썬의 다양한 라이브러리를 이용하여 차트 10가지를 만들어 봅니다.\n파이썬 Matplotlib, Seaborn 라이브러리를 활용하여 데이터 시각화의 기본 핵심차트 10가지를 만듭니다.\n핵심차트 10가지를 활용하여 보스턴 마라톤 빅데이터를 분석하는 실전 프로젝트를 통해 데이터 시각화의 개념과 개발능력을 함께 배웁니다.",
      "target_audience": [
        "파이썬을 처음으로 배우시는 분",
        "프로그래밍을 배우고 싶은 분",
        "실전 프로젝트를 통해 실력을 키우고 싶은 분",
        "긴 강의에 지쳐 단기간에 핵심을 이해하고 싶은 분",
        "프로그램 설치와 설정에 지치신 분들",
        "머신러닝 딥러닝 프로젝트를 준비하시는 분",
        "데이터 분석 프로젝트를 진행하시는 분",
        "데이터 시각화에 대해 관심있는 분",
        "엑셀분석의 한계를 느끼신 분",
        "적절한 차트를 이용하여 분석하고자 하시는 분"
      ]
    },
    {
      "title": "Machine Learning : Débutant à Expert en seulement 5h30",
      "url": "https://www.udemy.com/course/machine-learning-debutant-a-expert-en-seulement-5h30/",
      "bio": "La formation idéale pour obtenir des connaissances solides et avancées en Machine Learning. (+ de 20 modèles vus)",
      "objectives": [
        "Machine Learning : Notions essentielles",
        "Apprentissage supervisé : 17 modèles",
        "Apprentissage non-supervisé : 4 modèles",
        "Reinforcement learning : Introduction",
        "Deep Learning : 6 modèles",
        "Bonnes pratiques (éviter overfitting, encoder features catégoriques, etc.)"
      ],
      "course_content": {},
      "requirements": [
        "Un peu de volonté et quelques connaissances basiques en mathématiques suffiront !",
        "(Ne vous inquiétez pas pour les maths, il y a un petit rappel des notions essentielles)"
      ],
      "description": "Si vous pensiez pouvoir vous passer de théorie et commencer directement la pratique, détrompez-vous !\nLe machine learning est un domaine extrêmement complexe et il est tellement facile de s'embrouiller et de confondre des concepts.\nJe suis moi même passé par cette étape là.\nOn peut dire que c'est exactement l'inverse du développement web, par exemple, où il est possible de résumer la théorie en 5 minutes, et où il suffit de pratiquer un peu pour devenir bon.\nIl est essentiel d'avoir de solides connaissances théorique en Machine Learning avant de commencer quoi que ce soit en pratique !\nSinon on ne prend pas de plaisir, on a des doutes sur tout, on passe son temps sur des forums à chercher des solutions à des problèmes qu'on ne comprend même pas, etc.\nMon but est justement que vous évitiez cette phase là !\nLa formation qui aborde LE PLUS GRAND NOMBRE DE MODÈLES (+ de 20 types de modèles vus)\nPlus besoin de chercher de l'information à droite à gauche, ici tout est au même endroit et clairement expliqué !\nRéférez-vous au contenu du cours ci-dessous pour constater le quantité de types modèles expliqués lors de cette formation.\nUne formation axée sur la théorie, certes, mais illustrée d'exemples concrets !\nCe n'est pas parce que cette formation vise à expliquer la théorie du Machine Learning qu'elle est forcément difficile à comprendre ou abstraite.\nTout ce qui est vu dans cette formation vous sera utile lors de la pratique, et chaque étape est clairement expliquée et contient des exemples.\nVous êtes un débutant complet en Machine Learning et souhaitez commencer sur des bases solides...\nCette formation est faite pour vous ! Prenez dès le départ les bonnes habitudes et ayez une vision claire de ce qu'est le Machine Learning.\nVous avez déjà commencé à programmer quelques modèles prédictifs, mais vous passez votre temps sur des forums, tout est flou...\nVous êtes au bon endroit ! Ici, notre but sera de clarifier toute la théorie du Machine Learning, des modèles les plus utilisés, pour que vous n'ayez plus aucun doute lorsque vous passez à la partie programmation !\nUn complément essentiel aux autres formations\nQue vous ayez déjà acheté ou souhaitiez acheter une autre formation sur le sujet, celle-ci constitue un complément idéal !\n11 Quiz\nProfitez de tous les quiz pour vous assurer d'avoir bien compris toutes les notions vues au fur et à mesure que vous progressez dans la formation !",
      "target_audience": [
        "Débutants complets en Machine Learning qui souhaitent se construire des fondations théoriques solides.",
        "Intermédiaires en Machine Learning qui souhaitent clarifier, préciser leurs connaissances, et ne laisser aucune zone de flou."
      ]
    },
    {
      "title": "Data Science - Datenvorbereitung & Qualitätssicherung Excel",
      "url": "https://www.udemy.com/course/maschinelles-lernen-datenvorbereitung-qualitatssicherung/",
      "bio": "Entdecken Sie die Welt des Maschinellen Lernens (ML) in Excel und bauen Sie Ihre Fähigkeiten für ML & Data Science aus",
      "objectives": [
        "Grundlegende Fähigkeiten im Bereich maschinelles Lernen in Excel und Data Science aufbauen, ohne komplexen Code zu schreiben",
        "Data Science: Vorbereiten von Rohdaten (in Excel) für die Analyse mit QA-Tools wie Variablentypen, Bereichsberechnungen und Tabellenstrukturen",
        "Beschreibung und Visualisierung von Verteilungen mit Histogrammen, Kerndichten, Heatmaps und Violin-Plots (in Excel)",
        "Verwendung intuitiver, benutzerfreundlicher Tools wie Microsoft Excel zur Einführung und Enthüllung von Tools und Techniken des maschinellen Lernens",
        "Data Science: Analysieren von Datensätzen unter Verwendung gängiger univariater und multivariater Profiling-Metriken (in Excel)",
        "Data Science: Untersuchen Sie multivariate Beziehungen mit Streudiagrammen und Korrelationen (in Excel)"
      ],
      "course_content": {
        "Einführung": [
          "Ziele und Kursgliederung",
          "Erwartungsmanagement"
        ],
        "Einführung zu ML & Landschaft": [
          "Was ist Maschinelles Lernen (ML)",
          "ML Prozess",
          "ML Landschaft"
        ],
        "Vorläufige Data Qualitätssicherung": [
          "Einführung",
          "Wofür brauchen wir die Qualitätssicherung?",
          "Variablentypen",
          "Leerwerte",
          "Rechweitenberechnung und Zahlberechnung",
          "Zensierte Daten und Tabellenstruktur",
          "FALLSTUDIE: Qualitätssicherung",
          "Beste Praktiken bei der Qualitätssicherung",
          "Vorläufige Data Qualitätssicherung"
        ],
        "Univariate Profilierung": [
          "Einführung",
          "Kategorische Daten",
          "Diskretisierung",
          "Kategorische Verteilungen",
          "Numerische Variablen, Histograme & Kerndichten",
          "FALLSTUDIE: Histogramme",
          "Normalverteilung",
          "FALLSTUDIE: Normalverteilung",
          "Data Profilierung / Profiling",
          "Modus",
          "Mittelwert",
          "Median",
          "Perzentile",
          "Varianz",
          "Standardabweichung",
          "Schiefe",
          "Beste Praktiken Univariate Profilierung",
          "Univariate Profilierung"
        ],
        "Multivariate Profilierung": [
          "Einführung",
          "Kategorisch-kategorische Verteilung",
          "FALLSTUDIE: Heatmaps",
          "Kategorisch-numerische Verteilung",
          "Multivariate Kerndichte",
          "Violin Plots",
          "Box Plots",
          "Einschränkungen der kategorischen Verteilung",
          "Numerisch-numerische Verteilung",
          "Korrelation",
          "Korrelation versus Kausalität",
          "Streudiagramme",
          "FALLSTUDIE: Korrelation",
          "Beste Praktiken Multivariate Profilierung",
          "Multivariate Profilierung"
        ]
      },
      "requirements": [
        "Dies ist ein einsteigerfreundlicher Kurs (keine Vorkenntnisse oder Mathe-/Statistikkenntnisse erforderlich)",
        "Wir werden Microsoft Excel (Office 365) für einige Kursdemos verwenden, die Teilnahme ist jedoch optional"
      ],
      "description": "Tauchen Sie ein in die Welt des maschinellen Lernens – direkt in Excel!\nErlernen Sie grundlegende Data-Science- und Predictive-Analytics-Kenntnisse, ohne eine Zeile Code zu schreiben. Unser Kurs macht Data Science in Excel mühelos zugänglich und bietet leistungsstarke Machine-Learning-Tools und -Techniken, ganz ohne Programmierkenntnisse.\nWarum dieser Kurs?\nIm Gegensatz zu herkömmlichen Data-Science- und Machine-Learning-Kursen, schreiben Sie hier keine einzige Zeile Code. Mit vertrauten und benutzerfreundlichen Tools wie Microsoft Excel lernen Sie komplexe Konzepte auf einfache Weise. Bevor Sie in Programmiersprachen wie Python oder R eintauchen, werden Sie verstehen, wie und warum maschinelles Lernen funktioniert – ganz ohne Vorwissen in der Programmierung.\nKursüberblick:\nIn diesem Kurs behandeln wir folgende Themen:\nEinführung in maschinelles Lernen mit Excel\nGrundlegendes Verständnis für Prozesse, Definitionen und die Welt des maschinellen Lernens.\nDatenqualitätssicherung\nArbeiten Sie mit Variablentypen, Leerwerten, Bereichs- und Zählberechnungen und sichern Sie die Datenqualität – alles direkt in Excel.\nUnivariate Profilierung\nErstellen Sie Histogramme, Häufigkeitstabellen und berechnen Sie Mittelwert, Median, Modus, Varianz und mehr – ganz ohne komplexe Software.\nMultivariate Profilierung\nErforschen Sie Violin- und Boxplots, Kernel-Dichten, Heatmaps, Korrelationen und mehr – weiterhin in Excel.\nMit realen Szenarien und praxisnahen Fallstudien wie der Bereinigung von Produktdaten für ein Lebensmittelgeschäft, der Analyse von Olympia-Athlet-Daten und der Visualisierung von Verkehrsunfällen festigen Sie die Schlüsselkonzepte.\nDieser Kurs ist ideal für Sie, wenn Sie eine solide Basis für eine Karriere in der Datenwissenschaft aufbauen möchten.\nWas Sie erhalten:\nMelden Sie sich heute an und profitieren Sie von:\nHochwertigen On-Demand-Videos\nPraxisnahen Fallstudien in Excel\nQuizfragen zu jedem Thema\nDownloadbaren Excel-Projektdateien\n30-Tage-Geld-zurück-Garantie\nBeginnen Sie noch heute Ihre Reise in die Welt des maschinellen Lernens und der Datenanalyse – viel Erfolg und Freude beim Lernen!",
      "target_audience": [
        "Alle, die die Grundlagen des maschinellen Lernens anhand von Demos aus der Praxis und intuitiven, kristallklaren Erklärungen erlernen möchten - Datenanalysten oder BI-Experten, die in die Datenwissenschaft einsteigen oder ein grundlegendes Verständnis für maschinelles Lernen aufbauen möchten - R- oder Python-Anwender, die ein tieferes Verständnis für die Modelle und Algorithmen hinter ihrem Code suchen",
        "Datenanalysten oder BI-Experten, die in die Datenwissenschaft einsteigen oder ein grundlegendes Verständnis für maschinelles Lernen aufbauen möchten",
        "R- oder Python-Anwender, die ein tieferes Verständnis für die Modelle und Algorithmen hinter ihrem Code suchen"
      ]
    },
    {
      "title": "【初心者向け】PythonのPolarsを使ってデータ加工集計・データ分析を高速化！Pandasと比較してみよう！",
      "url": "https://www.udemy.com/course/python-polars/",
      "bio": "Pythonのデータ加工集計ライブラリであるPolarsを使って高速化！定番ライブラリであるPandasとPolarsの処理時間を比較し、Polarsを使った様々なデータ加工処理の問題に挑戦していこう！",
      "objectives": [
        "Pythonの基礎",
        "Pandasの使い方",
        "PolarsとPandasの書き方・処理時間の違い",
        "Polarsを使った様々なデータ加工処理問題に挑戦"
      ],
      "course_content": {
        "はじめに": [
          "はじめに"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Searbornについて学ぼう！",
          "Python構文の復習"
        ],
        "PolarsとPandasを比べてみよう！": [
          "PandasとPolarsで大規模データを作成しよう！",
          "PandasとPolarsで統計量表示と行のスライスを実行！",
          "PandasとPolarsでフィルタリングの処理を実行！",
          "PandasとPolarsでグループ集計と列の追加を実行！",
          "PandasとPolarsでカラムの抽出とソートと条件分岐を実行！",
          "PandasとPolarsで欠損値補完を実行！",
          "PandasとPolarsでデータ結合を実行！"
        ],
        "Polarsを使った様々な加工集計処理問題25問に挑戦しよう！": [
          "Polarsでデータインポートとデータ確認！",
          "Polarsで型変換と統計量確認！",
          "Polarsで様々な条件でデータを抽出してみよう！",
          "Polarsで日付を丸めて集計してみよう！",
          "Polarsでgroup_byとfilterを組みあわせた処理を実行してみよう！",
          "Polarsで結合処理や様々な処理を実行してみよう！",
          "Polarsで正規表現やランク付けをしてみよう！",
          "Polarsでピボットテーブルやダミー変数化をしてみよう！",
          "Polarsでサンプリングやフラグ追加やCSV出力をしてみよう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学びますのでプログラミングの知識は特に必要ありません"
      ],
      "description": "このコースでは、PythonのPolarsを使ったデータ加工集計について学んでいきます。\n\n\nデータ加工集計と言えばPandasが有名ですが、実は速度の面ではPolarsの方が優れていることの方が多いのです。\n\n\n特に大規模データに対してはPolarsが優れています。\n大規模データを使ってデータ加工集計する際に速度の面で課題を持っているのであればぜひPolarsを理解して使えるようになりましょう！\n\n\nこのコースでは、まず同じ処理に対してPolarsとPandasでコードを書き処理時間を比較していきます。\nその後に、Polarsを使った様々なデータ加工集計の問題に挑戦いただきます。\n\n\nそれではここからPolarsとPandasを比較しながらPolarsを使ったデータ加工集計処理を学んでいきましょう！",
      "target_audience": [
        "Pythonのデータ加工処理を高速化したい方",
        "Pandasの代替ライブラリであるPolarsに興味のある方"
      ]
    },
    {
      "title": "Pengenalan Machine Learning dengan Python",
      "url": "https://www.udemy.com/course/pengenalan-machine-learning-dengan-python/",
      "bio": "Materi yang akan dipelajari Pemahaman tentang konsep dasar machine learning dan penerapannya",
      "objectives": [
        "Pemahaman tentang konsep dasar machine learning dan penerapannya",
        "Pemahaman proses preprocessing data",
        "Pemahaman algoritma supervised learning pada Machine Learning",
        "Pemahaman algoritma unsupervised learning pada Machine Learning",
        "Pemahaman melakukan evaluasi model dan melakukan improvement pada model",
        "Pemahaman tentang Natural Language Processing",
        "Pemahaman tentang Neural Network dan Deep Learning",
        "Menyelesaikan project Machine Learning terkait materi yang sudah dipelajari"
      ],
      "course_content": {
        "Pengenalan": [
          "Mengapa Machine Learning?",
          "Jenis - Jenis Pada Machine Learning",
          "Mengapa Python?",
          "Ekosistem Python untuk Machine Learning",
          "Instalasi Ekosistem Python untuk Machine Learning",
          "Kelas Singkat Phython",
          "Kelas Singkat Numpy",
          "Kelas Singkat Matplotlib",
          "Kelas Singkat Pandas",
          "Quiz"
        ],
        "Preprocessing Data": [
          "Mendapatkan Dataset",
          "Memahami Data dengan Statistik",
          "Memahami Data dengan Visualisasi",
          "Melakukan Transformasi Data",
          "Mengatasi Missing Data",
          "Mengatasi Data Categorical",
          "Pembagian Dataset",
          "Quiz Data Processing"
        ],
        "Supervised Learning": [
          "Classification dan Regression",
          "Generalization, Overfitting, dan Underfitting",
          "K-Nearest Neighbor Classifier",
          "K-Nearest Neighbor Regressor",
          "Logistic Regression",
          "Naïve Bayes",
          "Decision Tree",
          "Quiz Supervised Learning"
        ],
        "Unsupervised Learning": [
          "Pengenalan Unsupervised Learning",
          "Principal Component Analysis",
          "Non-Negative Matrix Factorization",
          "Manifold Learning dengan t-SNE",
          "K-Means Clustering",
          "Agglomerative Clustering",
          "DBSCAN",
          "Quiz Unsupervised Learning"
        ],
        "Evaluasi Model dan Improvement": [
          "Pengenalan",
          "Cross Validation",
          "Grid Search",
          "Evaluation Metrics dan Scoring",
          "Pipeline",
          "Quiz Evaluasi Model dan Improvement"
        ],
        "Natural Language Processing (NLP)": [
          "Pengenalan",
          "Sentiment Analysis Explore Data",
          "Preprocessing dan Bag of Words",
          "Stopwords",
          "Rescaling Data dengan Tf-idf",
          "Final Sentiment Analysis",
          "Stemming dan Lemmatization",
          "Tokenization",
          "Topic Modelling",
          "Quiz Natural Language Processing (NLP)"
        ],
        "Neural Network dan Deep Learning": [
          "Pengenalan",
          "Deep Neural Network",
          "Convolutional Layer",
          "Max Pooling Layer",
          "CNN dengan MNIST",
          "RNN dengan Pytorch"
        ]
      },
      "requirements": [
        "Basic programming"
      ],
      "description": "Kursus ini adalah materi pengenalan dasar-dasar machine learning. Materi yang akan dipelajari Pemahaman tentang konsep dasar machine learning dan penerapannya, Pemahaman proses preprocessing data, Pemahaman algoritma supervised learning pada Machine Learning, Pemahaman algoritma unsupervised learning pada Machine Learning, Pemahaman melakukan evaluasi model dan melakukan improvement pada model, Pemahaman tentang Natural Language Processing, Pemahaman tentang Neural Network dan Deep Learning, Menyelesaikan project Machine Learning terkait materi yang sudah dipelajari",
      "target_audience": [
        "Menguasai konsep dasar machine learning dan penerapannya",
        "Melakukan preprocessing pada data",
        "Menerapkan algoritma supervised learning",
        "Menerapkan algoritma unsupervised learning",
        "Melakukan evaluasi pada model dan melakukan peningkatan performa model",
        "Menerapkan algoritma pada Natural Language Processing",
        "Menerapkan algoritma Neural Network dan Deep Learning",
        "Dapat menyelesaikan project Machine Learning dari materi yang telah dipelajari",
        "Mengetahui model Machine Learning yang dipilih dari masalah yang ada",
        "Dapat membuat model machine learning yang robust"
      ]
    },
    {
      "title": "数式なしでわかる人工知能（AI）入門講座",
      "url": "https://www.udemy.com/course/ai-finger-character/",
      "bio": "数式なしでPython/OpenCV/Tensorflow/Kerasによる機械学習入門 手話指文字画像認識ディープラーニング実践学習（ソース付）",
      "objectives": [
        "シンギュラリティ・人工知能の歴史と現状が分かります",
        "開発・実行環境準備できます",
        "Python/OpenCV/SVM/Tensorflow/Keras/CNN等の基本知識が分かります",
        "SVMによる日本手話指文字認識の実装ができます",
        "CNNによる日本手話指文字認識の実装ができます",
        "機械学習ライブラリ及びクラウドサービスが分かります"
      ],
      "course_content": {
        "概要": [
          "概要"
        ],
        "01 人工知能の歴史と現状": [
          "01 人工知能の歴史と現状"
        ],
        "02 環境準備": [
          "02 環境準備"
        ],
        "03 基本知識": [
          "03 基本知識"
        ],
        "04 SVMによる指文字認識実践": [
          "04 SVMによる指文字認識実践"
        ],
        "05 CNNによる指文字認識実践": [
          "05 CNNによる指文字認識実践"
        ],
        "06 機械学習ライブラリ": [
          "06 機械学習ライブラリ"
        ]
      },
      "requirements": [
        "カメラ付きのPCが必要です",
        "プログラミング知識が必要です"
      ],
      "description": "1.人工知能（AI）の歴史と現状\n2.環境準備\n3.基本知識（Python・OpenCV・Tensorflow・Keras）\n4.SVMによる指文字認識実践\n5.CNNによる指文字認識実践\n6.機械学習ライブラリ\n添付：指文字認識機械学習及びリアル認識ソースコード",
      "target_audience": [
        "機械学習、ディープランニングを学びたい初心者"
      ]
    },
    {
      "title": "PYTHON, Makine Öğrenmesi Yolculuğu",
      "url": "https://www.udemy.com/course/makine-ogrenmesi-yolculugu/",
      "bio": "MAKİNE ÖĞRENMESİ & VERİ BİLİMİ PROJELERİ | Veri bilimi Projeleri ve Makine Öğrenmesi Modelleri",
      "objectives": [
        "Sıfırdan başlayarak bir veri bilimi projesi nasıl yapılır",
        "Veri biliminde kullanılacak makine öğrennmesi metotları",
        "Kullanılacak metotların pratik açıklamaları",
        "Gerçek dünya verileri ile gerçekçi modellemeler ve analizler",
        "SCIKIT-LEARN, Numpy, Pandas, Matplotlib, Seaborn",
        "Regresyon analizi ile tahmin algoritmaları",
        "Sınıflandırma metotları ile gerçek dünya problemlerinin çözümü",
        "Kümeleme metotları ile verilerin ideal gruplara ayrıştırılması"
      ],
      "course_content": {
        "Giriş": [
          "Giriş",
          "Kurulum İçin Gerekenler"
        ],
        "Dünya Ülkelerinin Veri Analizi (Biz tek siz hepiniz)": [
          "GÜNCELEME GELDİ Vol 1",
          "Giriş ve Verilerin Düzenlenmesi",
          "Verileri Görselleştirme",
          "İnteraktif ve Alengirli Plotlar"
        ],
        "Kira Zammı Gibi Proje! Ev Fiyatı Tahmini": [
          "Veriyi yorumlama ve eksik verilerin düzenlenmesi",
          "Makine öğrenmesine uygun veri oluşturma ve ilk model",
          "Model sonuçlarınn karşılaştırılması ve yorumlanması"
        ],
        "Köpek Sınıflandırma (Shih-tzu / Rhodesian Ridgeback / Eskimo Dog)": [
          "Kaynaklar",
          "Giriş",
          "Kod ve Web Uygulaması"
        ],
        "Kuş Sınıflandırma (Flamingo, penguen, baykuş ve diğerleri)": [
          "Model Oluşturma ve Test",
          "Overfitting Sorununa Kalıcı Çözüm"
        ],
        "Şeker Gibi Proje (Yapay zeka web uygulaması oluşturmalı)": [
          "Kaynak Kodlar ve Veri Seti",
          "Diyabet ve ML Web Uygulaması"
        ],
        "Trafik İşaretleri Görsel İşleme": [
          "Yapay Sinir Ağları Hakkında",
          "Trafik İşaretleri Bölüm 1",
          "Trafik İşaretleri Bölüm 2"
        ],
        "Efsanevi Pokemon Bulma (Mewtwo efsanevi pokemon mudur?)": [
          "Veri Analizi ve Verilerin Model İçin Hazırlanması",
          "Decision Tree",
          "Random Forest"
        ],
        "Penguen Türü Belirleme": [
          "ML Model"
        ],
        "Opsiyonel Bölümler": [
          "Kaynaklar",
          "Python - Giriş ve Değişken Atama",
          "Python - Veri Türleri",
          "Python - if Komutu ve Karşılaştırma İfadeleri",
          "Python - Döngüler ve Fonksiyonlar",
          "Python - String İşlemleri",
          "Numpy - Bölüm 1",
          "Numpy - Bölüm 2",
          "Pandas - DataFrame Operasyonları 1",
          "Pandas - DataFrame Operasyonları 2",
          "Pandas - DataFrame Operasyonları 3",
          "Matplotlib - Bölüm 1",
          "Matplotlib - Bölüm 2",
          "Seaborn - Bölüm 1",
          "Seaborn - Bölüm 2",
          "Tensor Operasyonları"
        ]
      },
      "requirements": [
        "Bilgisayar dışında bir gereksinim yok. İhtiyacınız olan her şey burada öğretilecek."
      ],
      "description": "Bu tür eğitimlerin bana göre 2 problemi var\nİzlediğiniz videonun tamamının ekranı kaplaması ve ekranlar arası sürekli geçiş yapmak\nEğitmenlerin alanlarında uzman olmaları dolayısıyla başlangıç seviyesindeki bir öğrencinin ihtiyaçlarını ve sorunlarını tam olarak anlayamıyor olmaları\nBenim de bu eğitimdeki amacım temelde bu iki problemi çözerken size bir veri bilimi projesi nasıl yapılır, hangi adımlar işlenir ve bu adımlar neden kullanılır bunu anlatmak.\nKurs boyunca sizler gibi sıfırdan başlayan bir konuğum olacak ve dersleri sizinle beraber ona da anlatıyormuşum gibi dinleyeceksiniz. Böylece konuyu hiç bilmeyen birinin izlerken karşılaşabileceği soruları sizin yerinize o bana sormuş olacak.\n\n\nEğitim sonunda sizi klavyeye basan robotlar yapmaktan ziyade neyi, ne için, nerede ve nasıl kullandığını bilen birisi yapmak için mümkün olduğu kadar bütün algoritmaları, kodları, parametreleri ve kodların içinde gördüğünüz diğer şeyi açıklamaya çalıştım. Fakat yine de aklınızda kalan soruları sormaktan çekinmeyin. Derslerin sürekli güncel tutulacağından ve sorularınızla şekilleneceğinden emin olabilirsiniz.\n\n\nPeki biz bu eğitimde ne işleyeceğiz\nÇeşitli makine öğrenmesi modelleri kurmak için SCIKIT-LEARN\nYapay sinir ağları kurmak için TENSORFLOW & KERAS\nGörüntü işleme için OPENCV\nOPSİYONEL (Konu hakkında hiç bilgisi olmayanlar için)\nVeri biliminde kullanılacak temel seviyede PYTHON\nSayısal operasyonları gerçekleştirmek için NUMPY\nVerilerin düzenlenmesi ve analiz için PANDAS\nVerileri görselleştirmek ve görselleri düzenlemek için MATPLOTLIB ve SEABORN",
      "target_audience": [
        "Makine öğrenmesi, veri bilimi ve veri analizi ile ilgilenen, bu alanda profesyonel olarak veya hobi amaçlı ilerlemek isteyen herkes"
      ]
    },
    {
      "title": "ChatGPT und Midjourney im Vertrieb & Marketing nutzen.",
      "url": "https://www.udemy.com/course/chatgpt-midjourney-ai-im-berufprivat-leicht-beherrschen/",
      "bio": "ChatGPT mit Midjourney und weiterer KI / AI verwenden, 1000+ Prompts. Künstliche Intelligenz für Text Bild - Bilder.",
      "objectives": [
        "Wesentlich bessere Antworten von ChatGPT für Beruf und Privates erhalten, durch das Erlernen der richtigen Fragetechniken.",
        "Professionelle Ergebnisse mit echtem Mehrwert, sowohl für dich als auch für deine Kunden erhalten, durch die optimale Anwendung von Experten Ki´s.",
        "Komplexe Aufgaben von ChatGPT und Hilfs-Programmen, KINDERLEICHT erledigen lassen.",
        "Perfekte Bilder, nach genau deinen Vorstellungen von Midjourney und ChatGPT erstellen lassen. Die richtige Anwendung von Midjourney und ChatGPT uns unschlagbar.",
        "1000+ Anweisungen (Prompts) für ChatGPT und Midjourney zum Download, um gerade am Anfang, ein besseres Verständnis für die Arbeitsweise von Ki´s zu erlernen.",
        "Vorstellung meiner persönlichen KI Liste, Ki´s die ich täglich nutze, um Arbeiten für Kunden zu erledigen."
      ],
      "course_content": {
        "Einführung, Lernziel und Kursaufbau.": [
          "Kursziele und Kursaufbau"
        ],
        "Einführung von Anfang an in ChatGPT": [
          "Anmeldung in ChatGPT",
          "Die Basics zu Chat GPT",
          "Der Unterschied zwischen Google und ChatGPT 1. Teil",
          "Der Unterschied zwischen Google und ChatGPT 2. Teil"
        ],
        "Nutze das volle Potenzial ChatGPT (und Wie du bessere Antworten bekommst).": [
          "Sage ChatGPT genau was du willst.",
          "Lasse ChatGPT als Kunde in einem (Bio) Laden agieren.",
          "Das kann ChatGPT für uns beim FBA Business übernehmen.",
          "Erste Amazon FBA Produktideen mit ChatGPT finden.",
          "Hilfe bei der Erstellung von Flyern durch ChatGPT.",
          "ChatGPT Autoverkäufer Beispiel.",
          "Lasse Skripte für Videos erstellen.",
          "Stelle ChatGPT Fragen zur Berufsfindung.",
          "Stelle ChatGPT Fragen - Abnehm Beispiel",
          "KFZ Kaufvertrag von ChatGPT erstellen lassen.",
          "Einwandbehandlung beim Verkauf mit ChatGPT Hilfe.",
          "1000+ Eingaben für ChatGPT und Midjourney",
          "Titel: Künstliche Intelligenz im Berufsleben: Warum sie immer wichtiger wird."
        ],
        "Zünde den KI Turbo: Die Zusammenarbeit von ChatGPT und AIPRM": [
          "Wir lassen von ChatGPT und AIPRM ein Youtube Script erstellen.",
          "Facebook Werbeanzeigen erstellen mit ChatGPT und AIPRM.",
          "Mit ChatGPT und AIPRM eine Online-Kurs Struktur erstellen Lassen.",
          "Mit ChatGPT und AIPRM Dropshipping Produkte finden.",
          "Mit ChatGPT und AIPRM die nächsten 5 Feiertage erklären lassen.",
          "Die weiteren Möglichkeiten mit AIPRM"
        ],
        "Wir lassen uns von ChatGPT eine Komplette E-Mail Marketing Strategie erstellen.": [
          "Die komplette E-Mail Strategie."
        ],
        "Wir lassen uns von ChatGPT eine komplette Zielgruppen Analyse erstellen.": [
          "Die komplette Zielgruppen Analyse."
        ],
        "Einführung in Midjourney": [
          "Vorstellung von Midjourney",
          "Anmeldung bei Midjourney und Discord"
        ],
        "Midjourney: Kinderleicht anhand von Beispielen erklärt.": [
          "1. Teil: Midjourney Bild mit Noonshot erstellen lassen.",
          "2. Teil: Midjourney Bild mit Noonshot erstellen lassen.",
          "Promptherro - Promptideen an Beispielbildern für Midjourney.",
          "Mit AIPRM und Noonshot, Bild in Midjourney erstellen.",
          "2. Teil ChatGPT agiert als Prompt Engineer für Midjourney.",
          "Parameterliste für Midjourney."
        ],
        "Komplettes Buch und Buch-Cover mit ChatGPT und Midjourney erstellen lassen.": [
          "ChatGPT / AIPRM erstellt uns auf Knopfdruck ein komplettes Buch.",
          "Midjourney erstellt uns das Cover für unser Buch."
        ],
        "Canva: Einfach tolle Ergebnisse, Vorstellung und die neuen Möglichkeiten der KI.": [
          "Canva Vorstellung",
          "Präsentationen und Kalender in Canva erstellen.",
          "Bilder - Vordergrund und Hintergrund getrennt bearbeiten.",
          "Personen / Dinge freistellen.",
          "Magic Edit, Bildteile austauschen.",
          "Animierte Dinge durchs Bild fliegen lassen.",
          "Magic Eraser, Dinge ganz einfach aus Bildern entfernen.",
          "Präsentationen erstellen lassen, inkl. ChatGPT-ähnlicher Funktion.",
          "Mit Text to Image Bilder erstellen lassen."
        ]
      },
      "requirements": [
        "PC oder Laptop mit Internetverbindung.",
        "Keine Vorkenntnisse nötig, du lernst hier alles von Anfang an."
      ],
      "description": "Entdecke die Geheimnisse hinter künstlicher Intelligenz und maximiere Deine Ergebnisse mit meinem neuen Onlinekurs! Egal, ob Du ein Unternehmer, ein Freelancer oder einfach nur jemand bist, der seine Effizienz steigern möchte- oder tolle Designs erstellen möchte, um Freunden und Bekannten eine Freude zu machen, dieser Kurs hilft Dir dabei, die besten Ergebnisse mit ChatGPT, Midjourney und weiteren Ki's zu erzielen.\nIn diesem Kurs lernst Du, wie Du die richtigen Fragetechniken anwendest, um bessere Antworten von ChatGPT für Deine beruflichen und privaten Anliegen zu erhalten. Du wirst in der Lage sein, Deine Kommunikation mit KI-Systemen zu optimieren und dadurch schneller und effizienter zu arbeiten.\nIch zeige Dir, wie Du Experten-KI-Tools optimal einsetzt, um professionelle Ergebnisse mit echtem Mehrwert für Dich und Deine Kunden zu erzielen. So kannst Du Deinen Wettbewerbsvorteil ausbauen und Dein Geschäft weiterentwickeln.\nErlange die Fähigkeiten, um komplexe Aufgaben mühelos von ChatGPT und unterstützenden Programmen erledigen zu lassen. Dies ermöglicht es Dir, Deine Produktivität zu steigern und mehr Zeit für wichtigere Aufgaben zu haben.\nLerne, wie Du beeindruckende Bilder nach Deinen Vorstellungen erstellen lassen kannst, indem Du Midjourney und ChatGPT richtig anwendest. So kannst Du Deine kreativen Ideen verwirklichen und Deine Projekte visuell ansprechend gestalten.\nErhalte Zugriff auf über 1000 herunterladbare Anweisungen (Prompts) für ChatGPT und Midjourney, die Dir helfen, ein besseres Verständnis für die Arbeitsweise von KI-Systemen zu erlangen und Deine KI-Fähigkeiten kontinuierlich zu verbessern.\nEntdecke die KI-Tools, die ich täglich nutze, um Arbeiten für Kunden effizient und erfolgreich zu erledigen. So kannst Du von meiner Erfahrung profitieren und Deine eigene KI-Toolbox aufbauen.\n\n\nDarum ist die Kombination aus ChatGPT und Midjourney so genial und darum gehe ich auch ins Detail hier im Kurs:\n\nZeiteffizienz: ChatGPT kann dabei helfen, schnell Antworten auf ihre Fragen zu finden oder Informationen zu recherchieren, was Zeit spart und die Produktivität erhöht.\nKostenreduktion: Midjourney kann teure Grafikdesigner und Illustratoren ersetzen. So sparst du Geld bei der Erstellung von Bildmaterial für deine Projekte.\nSkalierbarkeit: Mit Midjourney kannst du problemlos große Mengen an Bildmaterial generieren. Dies ist besonders nützlich, wenn du Inhalte für mehrere Kunden gleichzeitig oder für eine große Anzahl von Produkten erstellen musst.\nZeitersparnis: Eine der größten Vorteile von Text zu Bild KIs ist die enorme Zeitersparnis. Du musst keine komplizierten Grafikdesign-Tools erlernen oder Stunden damit verbringen, das perfekte Bild zu erstellen. Gib einfach eine Beschreibung ein, und die KI wird in kürzester Zeit ein passendes Bild generieren.\n\n\nMelde Dich noch heute für diesen Kurs an und entfessele das volle Potenzial von ChatGPT, Midjourney und im Allgemeinen von künstliche Intelligenzen für Deine beruflichen und privaten Anliegen. Verpasse nicht die Gelegenheit, Dein Wissen über künstliche Intelligenz zu erweitern.",
      "target_audience": [
        "Personen die durch den Einsatz von Künstlicher Intelligenz Geld verdienen, Zeit sparen- oder einfach tolle Dinge erstellen möchten.",
        "Auch für Anfänger geeignet."
      ]
    },
    {
      "title": "YOLOv8實例分割實戰：訓練自己的資料集",
      "url": "https://www.udemy.com/course/yolov8-seg/",
      "bio": "YOLOv8 Instance Segmentation : Train Custom Dataset",
      "objectives": [
        "掌握YOLOv8實例分割訓練自己的資料集方法",
        "掌握本機安裝軟體環境",
        "掌握圖像分割標注方法",
        "掌握實例分割原理"
      ],
      "course_content": {
        "課程介紹": [
          "課程介紹"
        ],
        "圖像分割基礎篇": [
          "圖像分割-任務說明及常用資料集",
          "圖像分割-性能指標"
        ],
        "YOLOv8網路原理篇": [
          "YOLO目標檢測系列技術發展史",
          "YOLOv8網路架構",
          "YOLACT實例分割原理",
          "YOLOv8實例分割網路輸出"
        ],
        "YOLOv8實例分割專案實戰（Windows）": [
          "安裝軟體環境(Nvidia驅動，CUDA和cuDNN)",
          "安裝PyTorch",
          "安裝YOLOv8",
          "使用labelme標注自己的資料集",
          "資料集格式轉換",
          "準備自己的資料集",
          "修改設定檔",
          "訓練自己的資料集",
          "測試訓練出的網路模型和性能統計",
          "修改設定檔更新"
        ],
        "YOLOv8實例分割專案實戰（Ubuntu）": [
          "安裝軟體環境(Nvidia驅動，CUDA和cuDNN)",
          "安裝PyTorch",
          "安裝YOLOv8",
          "使用labelme標注自己的資料集",
          "資料集格式轉換",
          "準備自己的資料集",
          "修改設定檔",
          "訓練自己的資料集",
          "測試訓練出的網路模型和性能統計",
          "修改設定檔更新"
        ]
      },
      "requirements": [
        "熟悉Python和PyTorch"
      ],
      "description": "Ultralytics YOLOv8 基於先前 YOLO 版本的成功，引入了新功能和改進，進一步提升性能和靈活性。YOLOv8 支援目標檢測與跟蹤、實例分割、圖像分類和姿態估計任務。\n本課程將手把手地教大家使用labelme標注和使用YOLOv8訓練自己的資料集，完成一個多目標實例分割實戰專案。本課程以汽車駕駛場景圖片和視頻開展專案實戰：對汽車行駛場景中的路坑、車、車道線進行物體標注和實例分割。\n本課程分別在Windows和Ubuntu系統上做專案演示。包括：安裝軟體環境（Nvidia顯卡驅動、cuda和cudnn）、安裝PyTorch、安裝YOLOv8、使用labelme標注自己的資料集、資料集格式轉換、準備自己的資料集、修改設定檔、訓練自己的資料集、測試訓練出的網路模型和性能統計。",
      "target_audience": [
        "希望學習YOLOv8實例分割技術的學員和從業者"
      ]
    },
    {
      "title": "R Programming - 데이터분석과 머신러닝 기초",
      "url": "https://www.udemy.com/course/r-programming-y/",
      "bio": "[강의교안&소스파일 제공] 머신러닝 기초! 실습하며 배우는 데이터분류-분석, 텍스트마이닝",
      "objectives": [
        "OT & 머신러닝 개요",
        "데이터 분류, 데이터 분포 분석과 시각화",
        "빈도분석 실습작업",
        "지역별 교통사고사상자 분석 코딩 및 시각화",
        "dyplr 패키지, 함수",
        "데이터 수집과 전처리",
        "텍스트마이닝(tm, KoNLP 패키지)",
        "연관성 규칙"
      ],
      "course_content": {
        "OT & 머신러닝 개요": [
          "1. 강의 안내 및 머신러닝 개요"
        ],
        "데이터 분류, 데이터 분포 분석과 시각화": [
          "2. 명목형 데이터와 수치형 데이터 분류 및 특징 설명",
          "3. 데이터 중심경향: 평균,중앙값,최빈수 계산",
          "4. 데이터 분포분석: 범위,사분위수,분산,표준편차 계산",
          "5. 데이터 분포 시각화: 히스토그램과 상자도표 구현"
        ],
        "중간 실습": [
          "6. 빈도분석 실습작업",
          "7. 지역별 교통사고사상자 분석 코딩 및 시각화"
        ],
        "dyplr 패키지, 함수": [
          "8. dplyr패키지 - aasample.csv",
          "9. Dplyr 패키지 주요함수 설명",
          "10. Summarise()함수와 aggreagate()함수 설명"
        ],
        "데이터 수집과 전처리, 트위터 연결": [
          "11. 데이터 수집- 트위터 연결하기",
          "12. 데이터 전처리",
          "13. 불필요한 트윗내용 제거하기",
          "14. 트윗에서 분석에 불필요한 트윗태그,특수문자,url제거방법",
          "15. 워드클라우드 시각화 작업까지 활용"
        ],
        "텍스트마이닝": [
          "16. tm패키지를 이용한 텍스트마이닝",
          "17. tm패키지에서 텍스트 분석과정 및 해당 관련 함수 설명 및 실습",
          "18. KoNLP 패키지를 통한 형태소 분석"
        ],
        "실습, 연관성 규칙": [
          "19. 보통명사를 추출 프로그램 실습",
          "20. 연관성 규칙 및 apriori 알고리즘 개략적 설명",
          "21. 문서에서 단어간의 연관성 규칙 생성하여 문서요약하기"
        ]
      },
      "requirements": [
        "데이터에 대한 관심과 약간의 이해도와 함께 흥미롭게 배울 의지가 있는 수강생"
      ],
      "description": "안녕하세요, 웅진씽크빅 IT 입니다.\n본 강의는 R Programming - 데이터분석과 머신러닝 기초입니다.\n\n\n누구를 위한 강의인가요?\n\n\nR 프로그래밍을 배우고 싶은 누구나\n머신러닝과 데이터분석에 관심있는 모든 분\n예비 데이터사이언스, 비전공자\n\n\n무엇을 배우나요?\n\n\nOT & 머신러닝 개요\n데이터 분류, 데이터 분포 분석과 시각화\n빈도분석 실습작업\n지역별 교통사고사상자 분석 코딩 및 시각화\ndyplr 패키지, 함수\n데이터 수집과 전처리\n텍스트마이닝(tm, KoNLP 패키지)\n연관성 규칙\n\n\n머신러닝 기초! 실습하며 배우는 데이터분류-분석, 텍스트마이닝 등을 함께 배워보아요!\n\n\n그럼 강의에서 만나요 :)",
      "target_audience": [
        "R 프로그래밍을 배우고 싶은 누구나",
        "머신러닝과 데이터분석에 관심있는 모든 분",
        "예비 데이터사이언스, 비전공자"
      ]
    },
    {
      "title": "【なるほどね！が止まらない】一度挫折した人のための数理最適化講座",
      "url": "https://www.udemy.com/course/math-opt/",
      "bio": "数理最適化を勉強してみたけど「数式が多くて難しい...」ってなった経験ありませんか？この講座はここまで丁寧に！？ってほど数理最適化に登場する数式を解説します。",
      "objectives": [
        "数理最適化で使われる文字・文字の意味が分かる",
        "最適化って数式が多くて難しいなと思う気持ちを払拭する",
        "ナップサック問題の定式化ができる",
        "割当問題の定式化ができる",
        "配送計画問題の定式化ができる"
      ],
      "course_content": {
        "はじめに": [
          "この講座の紹介",
          "数理最適化ってなに？",
          "数理最適化の典型問題を紹介する",
          "最適化問題を解く手順"
        ],
        "ナップサック問題の数式を理解しよう！": [
          "ナップサック問題ってどんな問題？",
          "パラメータを設定しよう！",
          "変数を設定しよう！",
          "目的関数を設定しよう！",
          "制約条件を設定しよう！"
        ],
        "割当問題の数式を理解しよう！": [
          "割当問題ってどんな問題？",
          "パラメータを設定しよう！",
          "変数を設定しよう！",
          "目的関数を設定しよう！",
          "制約条件を設定しよう！"
        ],
        "配送計画問題の数式を理解しよう！": [
          "配送計画問題ってどんな問題？",
          "定式化に必要な情報を言語化しよう！",
          "パラメータを設定しよう！",
          "変数を設定しよう！",
          "目的関数を設定しよう！",
          "1つ目の制約条件を設定しよう！",
          "2つ目の制約条件を設定しよう！",
          "3つ目の制約条件を設定しよう！",
          "4つ目の制約条件を設定しよう！",
          "5つ目の制約条件を設定しよう！"
        ]
      },
      "requirements": [
        "特になし。数理最適化に興味があること。"
      ],
      "description": "数理最適化に興味はあるものの「難しそう...」と感じて一歩踏み出せない方、あるいは勉強してみたけれど途中でつまずいてしまった方、数式が苦手で敬遠していた方──そんな方々に向けたコースです。\n数理最適化は実務でも非常に強力な手法ですが、数式が登場するため、初めは戸惑いや苦手意識を持ってしまいがちです。この講座では、典型的な最適化問題を実例として挙げながら、どうやって問題を定式化していくのかをやさしく丁寧に解説を行います。数式が苦手な方でも理解しやすいよう、基礎を大切にしつつステップを踏んで学習できるよう設計しています。\n「実務で使える数理最適化スキルを、わかりやすく身につけたい」そんなあなたの一歩を、私がしっかりサポートします。ぜひ一緒に、数理最適化の世界に踏み出してみましょう。",
      "target_audience": [
        "数理最適化に興味がある人",
        "一度数理最適化を勉強したけど挫折してしまった人",
        "数理最適化を実務で使ってみたい人"
      ]
    },
    {
      "title": "Alteryx Designer 初級トレーニング",
      "url": "https://www.udemy.com/course/cm-alteryx-designer-core-training/",
      "bio": "Alteryx Designerを座学と演習をまじえて基礎から学びます。",
      "objectives": [
        "Alteryx Designerの操作方法やワークフローの作成方法について学びます。",
        "Alteryx Designerを使ったデータの加工について学びます。",
        "Alteryx Designerを使ったデータの前処理について学びます。",
        "Alteryx Designerを使ったデータの集計や分析について学びます。"
      ],
      "course_content": {},
      "requirements": [
        "本講座にはAlteryx Designerを使った演習が含まれます。Alteryx DesignerがインストールされたWindows PCを用意して受講することを推奨します。",
        "本動画は、Alteryx Designer 2022.3にて作成しています。異なるバージョンをご利用の場合、画面構成や動作などが異なる場合がございますので予めご了承ください。"
      ],
      "description": "本講座は、Alteryx Designerを基礎から学びます。Alteryx社による公式のコアトレーニングをベースに、動画でのトレーニング用に内容を調整したものになっています。\n本講座では、機能を解説する座学パートと、Alteryxを操作する演習パートが含まれます。演習パートでは実際にAlteryxを操作していただく内容になっていますので、本講座の受講には、Alteryx Designerがインストールされた環境をご用意いただくことを推奨しております。\n本講座は、Alteryx Designerバージョン2022.3にて作成しています。\n本講座は、Alteryx Designer Desktopについての講座となっております。Alteryx Designer Cloudについては取り扱っておりませんのでご注意ください。\n\n\n本講座で解説するツールは以下の通りです。\n\n\nデータ入力\n動的入力\nソート\nサンプリング\nオートフィールド\nセレクト\nフィルター\n結合\nユニオン\nフィールド付加\nテキスト入力\nフォーミュラ\n複数フィールドフォーミュラ\nデータクレンジング\n集計\n列分割\nユニーク\n日時\n動的リネーム\n複数行フォーミュラ\nクロスタブ\n転置\nデータ出力",
      "target_audience": [
        "Alteryx Designerの基礎的な使い方を学びたい方"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第15部 ComfyUI 進階版 - 自動化FLUX流程攻略",
      "url": "https://www.udemy.com/course/generative_ai_15/",
      "bio": "關於ComfyUI，FLUX， Clip-L，T5XXL，Ollama, Prompt，InPainting，SAM2 Segmentation",
      "objectives": [
        "如何在 Apple Silicon（如 M1 和 M2）上運行 Flux",
        "從 GGUF 量化模型到完整模型選擇",
        "結合自定義節點與 LLM 提示優化",
        "如何製作自動化 Flux 工作流"
      ],
      "course_content": {
        "如何在本地電腦安裝ComfyUI": [
          "如何在iMac電腦上安裝ComfyUI"
        ],
        "如何在Mac上運行第一個Flux工作流": [
          "如何在Mac上運行第一個Flux工作流"
        ],
        "Flux自動分辨率，Flux圖生圖輸入，Flux文字生圖輸入": [
          "如何自動計算Flux分辨率和圖片寬度高度",
          "如何控制Image Input & Text Input的邏輯選擇",
          "如何控制Text LLM Conditioning製作Prompt描述"
        ],
        "圖生圖自動化Prompt定義": [
          "如何實現Image LLM與Modify Image LLM的邏輯處理"
        ],
        "T5XXL和Clip_L的定義和邏輯選擇": [
          "如何製作T5XXL和CLIP-L的切換邏輯",
          "如何製作可切換圖生圖設定FLux loRA工作流",
          "如何使用Max Shift與Modify Image"
        ],
        "如何使用SAM2和自定義Mask做InPainting": [
          "如何用SAM2實現InPainting",
          "如何使用MaskEditor處理自定義Mask結合SAM2Segmentation"
        ],
        "如何為實現Upscaling": [
          "如何為圖片增加細節",
          "如何實現2倍UpScaling"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "學習如何掌握 Flux 工作流和 AI 圖像生成技巧的完整指南！\n你是否夢想過能夠使用 Mac 創建出令人驚豔的 AI 圖像，並靈活地操控工作流邏輯？這門課程專為追求創新與效率的技術愛好者而設，帶你從零開始，深入了解 Flux 工作流的運作邏輯，以及如何結合 ComfyUI 和先進 AI 模型進行高效圖像生成。現在就加入我們，為你的創意插上 AI 的翅膀！\n課程亮點\n1. 在 Mac 上運行第一個 Flux 工作流\n從安裝到運行，手把手帶你在 iMac 上快速搭建 Flux 工作流環境，零基礎也能輕鬆上手！\n2. 深入控制 Text LLM Conditioning\n學習如何定製 Prompt 描述，打造更精準的文字生成結果，讓 AI 真正為你的需求服務！\n3. 靈活切換 T5XXL 和 CLIP-L 模型\n掌握模型切換邏輯，根據任務需求選擇最優 AI 模型，提升生成效率與效果！\n4. 自動計算 Flux 圖片分辨率與尺寸\n再也不用為圖片尺寸煩惱，課程教你自動化分辨率與寬高計算，優化工作流細節處理。\n5. 使用 MaskEditor 與 SAM2 實現自定義遮罩處理\n輕鬆創建高精度遮罩，結合 Segmentation 技術進行更靈活的圖像處理。\n6. 圖像 2 倍放大（UpScaling）技術\n讓小圖像瞬間變得高清，捕捉每一處細節，滿足各種精美輸出的需求！\n7. Flux LoRA 工作流的可切換圖生圖設置\n製作適合不同風格與用途的工作流，提升創作靈活性，實現真正的自由創作。\n8. 圖像 LLM 與 Modify Image LLM 的邏輯處理\n學習如何實現高效的圖像生成與修改邏輯，解決複雜的場景需求。\n9. 在 iMac 上安裝 ComfyUI 的完整指南\n深入指導如何快速安裝和配置 ComfyUI，讓你的 Mac 成為 AI 圖像生成的專業平台。\n10. 使用 SAM2 技術實現 InPainting\n修復與補全圖像的高級技術，打造無痕跡的高品質 AI 作品。\n11. 為圖片添加細節的專業技巧\n提升圖像質感，讓你的作品更具吸引力和專業水準。\n12. Max Shift 與 Modify Image 的實戰運用\n掌握這兩大核心技術，讓你對圖像修改得心應手，應對多樣場景需求。\n13. Image Input 與 Text Input 的邏輯選擇\n深入理解並靈活控制圖像與文字輸入邏輯，實現高效生成流程的設計。\n\n\n現在就加入我們，搶占 AI 圖像生成的先機！快來體驗 Flux 工作流的無限可能，輕鬆解鎖未來創作的無窮潛力！",
      "target_audience": [
        "進行FLUX圖像生成和編輯的設計師",
        "對自動化圖像生成工作流感興趣的創作者。",
        "希望提升工作效率的數字設計愛好者和專業人士"
      ]
    },
    {
      "title": "Курс по ChatGPT от магистра University of Cambridge.",
      "url": "https://www.udemy.com/course/chatgpt-all/",
      "bio": "ChatGPT: Курс для продуктологов, предпринимателей, менеджеров, маркетологов.",
      "objectives": [
        "Узнаете как работать с ChatGPT.",
        "Снизите расходы на маркетинг и исследование рынка.",
        "Научитесь создавать ChatBot для Telegram.",
        "Узнаете как использовать ChatGPT в Product Management.",
        "Научитесь создавать программы для аналитики документов Excel, Word, PDF.",
        "Сделаете свою программу для парсинга сайтов и научитьесь азам SEO оптимизации."
      ],
      "course_content": {
        "Введение в Chat GPT": [
          "Chat GPT и его преимущества для бизнеса",
          "Лекция 2: Два типа компаний: те, что внедряют ChatGPT и которые закрываются",
          "Лекция 3: Почему OpenAI (ChatGPT) — самая заметная компания в 2023 году",
          "Лекция 4: Почему ChatGPT — это не новый Google",
          "Лекция 5: Начало работы с ChatGPT"
        ],
        "Создаем запросы в ChatGPT правильно или что такое Prompt Engeenering": [
          "Лекция 1: Частые ошибки при создании запросов",
          "Лекция 2: Создаем запрос правильно"
        ],
        "ChatGPT для оптимизации бизнес-процессов": [
          "Лекция 1: ChatGPT и его глюки",
          "Лекция 2: Используем доп AI инструменты вместе с Google / Word",
          "Лекция 3: Ответы на письма клиентов и сотрудников с помощью ChatGPT",
          "Лекция 4: Chat GPT 4.0! Перевернет мир. Рассказываю как.",
          "Лекция 5: Как применить ChatGPT в бизнесе и работе? Примеры.",
          "Лекция 6: Создание презентаций с помощью ChatGPT"
        ],
        "Запускаем новый бизннес": [
          "Исследуем рынок",
          "Создаем Бизнес-План"
        ],
        "Совершенствуем бизнес решения и оптимизируем рабочие процессы": [
          "Совершенствуем бизнес-решения",
          "Снижаем затраты на «операционку» на 40%",
          "Сокращаем время на написание деловых писем на 70%"
        ]
      },
      "requirements": [
        "Нужен только доступ к ChatGPT (на курсе расскажу как его получить)"
      ],
      "description": "Этот уникальный курс разработан магистром предпринимательства University of Cambridge, выпускником MBA Skolkovo, международным предпринимателем и опытным топ-менеджером.\n\nОсвойте мощь искусственного интеллекта с курсом ChatGPT: преобразуйте бизнес, улучшите свою жизнь, освободите время!\nЭтот курс на Udemy создан специально для предпринимателей, менеджеров и маркетологов, желающих использовать AI для улучшения коммуникации, оптимизации рабочих процессов и увеличения продаж.\nВ современном бизнес-мире, где все процессы становятся все более сложными и многогранными, использование AI может дать вам преимущество перед конкурентами. Овладев технологией ChatGPT, вы сможете ускорить решение задач, анализировать большие объемы данных и создавать инновационные продукты. Приобретите навыки, которые помогут вам оставаться на гребне волны цифровых инноваций и выделяться среди конкурентов.\nНа курсе мы разберем базовые принципы работы ChatGPT, научимся его настраивать и интегрировать с различными платформами и инструментами. Вы познакомитесь с применением ChatGPT в различных отраслях, таких как маркетинг, продажи, управление проектами и аналитика, что позволит вам применять знания на практике и увидеть реальные результаты.\nКурс состоит из уроков, в которых мы будем изучать теорию, практику, а также решать задачи и примеры из реальной жизни. Благодаря этому вы сможете лучше понять возможности и ограничения технологии, научитесь ей эффективно пользоваться и применять в своем бизнесе.\nВам не нужно быть специалистом в области искусственного интеллекта или программирования, чтобы начать изучать курс. Мы разработали его таким образом, чтобы он был доступным для всех, независимо от опыта и образования. Наша цель - сделать мир AI понятным и доступным для каждого, кто хочет улучшить свой бизнес и карьеру, расширить свои горизонты и открыть новые возможности для развития.\nПрисоединяйтесь к нашему курсу и откройте для себя мир возможностей, который предлагает ChatGPT! Вместе мы изучим, как использовать эту технологию для автоматизации рутинных задач, улучшения взаимодействия с клиентами и партнерами, а также создания уникальных маркетинговых стратегий, которые позволят вам выходить на новый уровень.",
      "target_audience": [
        "менеджеры, предприниматели, управленцы, студенты"
      ]
    },
    {
      "title": "TPOTによる回帰モデル作成講座 : 【AutoML/Python/Kaggle/SIGNATE】②",
      "url": "https://www.udemy.com/course/automated-machine-learning-tpot-pythonkagglesignate2/",
      "bio": "Learn how to create Supervised Regression model with TPOTRegressor(AutoML) & Participate in Kaggle/SIGNATE",
      "objectives": [
        "TPOTRegressor (AutoML)を使用した回帰モデルの作成",
        "TPOTRegressorのパラメータチューニング方法",
        "TPOTRegressorのAttributesやFunctionsを学習",
        "Kaggle・Signateに向けたモデルの作成"
      ],
      "course_content": {
        "はじめに": [
          "講座開始前のご連絡",
          "講座の概要",
          "TPOTとは",
          "TPOTのインストール"
        ],
        "回帰【Tips】": [
          "データセットの取得",
          "Parametersの学習①",
          "Parametersの学習②",
          "Drill",
          "Functionsの学習",
          "Attributesの学習"
        ],
        "回帰【Diamonds】": [
          "Test",
          "Answer"
        ],
        "回帰【Boston Housing】": [
          "Test",
          "Answer"
        ],
        "回帰【Diabetes】": [
          "Test",
          "Answer"
        ],
        "Challenge for SIGNATE 【山火事の消失面積予測】": [
          "コンペの参加",
          "データの取得",
          "モデルの作成"
        ],
        "Practice in Kaggle 【健康保険料予測】": [
          "データセットの調査",
          "モデルの作成",
          "TPOTRegressorの関数化"
        ]
      },
      "requirements": [
        "Jupyter NotebookによるPythonの基本操作",
        "データセットの読込、データ前処理、モデル作成、モデルの評価の経験",
        "TPOTRegressorの使用が未経験な方、又は経験が浅い方"
      ],
      "description": "本講座はAutomated Machine Learning Tool（自動機械学習モデル）であるTPOTライブラリを使用し、公式ドキュメントを参考にしながら TPOTRegressorのParametersやAttributes・Functions、そして回帰モデルの作成を学習していくコースとなっています。\nまた、講義の中では分析コンペティション（SIGANTE）にも参加し、機械学習モデル自動化ツールがどれほどの予測精度を出すか確認できます。\n手軽で実用的なツールなため、機械学習に苦手意識を持っていた方でもお勧めです。\n\n\nコース内容は以下の通りです。\nSection1:はじめに\nSection2:回帰【Tips】\nSection3:回帰【Diamonds】\nSection4:回帰【Boston Housing】\nSection5:回帰【Diabetes】\nSection6:Challenge for SIGNATE 【山火事の消失面積予測】\nSection7:Practice in Kaggle 【健康保険料予測】",
      "target_audience": [
        "TPOTライブラリの使用に関心を持つ方",
        "TPOTRegressorを使用し回帰モデルの作成を行いたい方",
        "機械学習をツールとして使いこなしたい方",
        "TPOTに興味があるけど、始め方が分からない方",
        "AutoMLで何らかの問題を解決したい方",
        "AIコンペの参加に関心がある方"
      ]
    },
    {
      "title": "Üretken Yapay Zeka (GenAI) : Görsel",
      "url": "https://www.udemy.com/course/genai-gorsel/",
      "bio": "Sıfırdan Kendi Üretken Yapay Zeka Modellerinizi Oluşturun!",
      "objectives": [
        "Kendi Üretken Yapay Zekanızı Yapabileceksiniz!",
        "GAN modellerini anlama ve sıfırdan geliştirme.",
        "Görsel üretim ve dönüştürme projeleri oluşturma.",
        "Görüntü iyileştirme ve süper çözünürlük tekniklerini uygulama.",
        "Yenilikçi GAN tabanlı projeler geliştirme."
      ],
      "course_content": {
        "Giriş": [
          "Giriş",
          "Üretken Yapay Zeka Nedir?",
          "GenAI'nin Tarihçesi ve Gelişimi"
        ],
        "Üretken Çekişmeli Ağ - GAN": [
          "Nedir?",
          "GANLab",
          "Veriseti Hazırlığı",
          "Generator Model",
          "Discriminator Model",
          "GANs Model",
          "Eğitim Modeli",
          "Gerçek Zamanlı Görsel Oluşturulması",
          "Derste Kullanılan Kod"
        ],
        "Derin Evrişimli Üretken Çekişmeli Ağ - DCGAN": [
          "Nedir?",
          "Veriseti Hazırlığı",
          "Generator Model",
          "Discriminator Model",
          "Kayıp Fonksiyonu",
          "GANs Model",
          "Eğitim Modeli",
          "Derste Kullanılan Kod"
        ],
        "Koşullu Üretken Çekişmeli Ağ - cGAN": [
          "Nedir?",
          "Veriseti Hazırlığı",
          "Conv Katman",
          "Generator",
          "Discriminator",
          "Optimizasyon",
          "Görsel Fonksiyonu",
          "Eğitim Modeli",
          "Derste Kullanılan Kod"
        ],
        "Wasserstein Üretken Çekişmeli Ağ - WGAN": [
          "Kullback-Leibler Divergence",
          "Jensens-Shannon Divergence",
          "Wasserstein Distance",
          "Loss Function",
          "Eğitim",
          "Derste Kullanılan Kod"
        ],
        "Pikselden Piksele - Pix2Pix cGAN": [
          "Nedir?",
          "Veriseti Hazırlığı",
          "Generator",
          "Discriminator",
          "Loss Function",
          "Eğitim",
          "Derste Kullanılan Kod"
        ],
        "Döngü-Tutarlı Üretken Çekişmeli Ağ - CycleGAN": [
          "Nedir?",
          "Veriseti Hazırlığı",
          "Model",
          "Loss Function",
          "Eğitim",
          "Derste Kullanılan Kod"
        ],
        "Geliştirilmiş Süper Çözünürlük Üretken Çekişmeli Ağ - ESRGAN": [
          "Nedir?",
          "Veriseti Hazırlığı",
          "Generator",
          "Discriminator",
          "Loss Function",
          "Eğitim",
          "Real-ESRGAN",
          "Derste Kullanılan Kod"
        ]
      },
      "requirements": [
        "Temel ve Orta Seviye Yapay Zeka Eğitimi Almış Olmak"
      ],
      "description": "Üretken Yapay Zeka (GenAI): Görsel kursuna hoş geldiniz! Bu kurs, görsel içerik üretiminde ve dönüştürülmesinde devrim yaratan Üretken Yapay Zeka tekniklerine dair kapsamlı bir eğitim sunmaktadır. Üretken Yapay Zeka, özellikle Generative Adversarial Networks (GAN) olarak bilinen derin öğrenme tabanlı modeller aracılığıyla, hem akademik hem de endüstriyel alanlarda büyük ilgi görmektedir. Bu kurs, GAN'ların temel prensiplerinden başlayarak, gelişmiş uygulamalarına kadar geniş bir yelpazeyi kapsar.\nKursumuzun başlangıcında, GAN'ların temel işleyiş mantığını ve arkasındaki teorik altyapıyı öğreneceksiniz. GAN modelleri, iki yapay sinir ağının - bir üreteç (generator) ve bir ayrımcı (discriminator) - birbiriyle rekabet ettiği ve sonuç olarak son derece gerçekçi görüntüler üretebildiği bir yapıya sahiptir. Bu dinamik, birçok yaratıcı ve teknik uygulamanın temelini oluşturur. Ardından, DCGAN (Deep Convolutional GAN) ile başlayarak, derin öğrenme ve konvolüsyonel sinir ağlarının GAN'lara nasıl entegre edildiğini keşfedeceksiniz. DCGAN, yüksek çözünürlüklü ve detaylı görseller üretme yeteneği ile bilinir ve bu modelin mimarisi, daha karmaşık uygulamalara giriş için sağlam bir temel sunar.\nKurs ilerledikçe, cGAN (Conditional GAN) ve WGAN (Wasserstein GAN) gibi daha gelişmiş GAN türlerine odaklanacağız. cGAN, belirli koşullara dayalı görseller üretme yeteneği ile, örneğin belirli bir stil veya içerik ile eşleştirilebilecek görseller oluşturma konusunda devrim niteliğindedir. WGAN ise, eğitim sürecini stabilize ederek, daha yüksek kaliteli sonuçlar elde etmenizi sağlar. Bu model, özellikle GAN'ların eğitimi sırasında yaşanan zorlukları aşmak için geliştirilmiştir ve pratik projelerde büyük avantajlar sunar.\nKursun en heyecan verici bölümlerinden biri, Pix2Pix cGAN ve CycleGAN gibi görüntü çevirme (image-to-image translation) tekniklerine odaklanacaktır. Bu modeller, bir görüntüyü başka bir tarza, formata veya içerik yapısına dönüştürmek için kullanılır. Örneğin, bir karakalem çizimi renklendirmek, bir gündüz sahnesini geceye çevirmek veya farklı sanat stilleri arasında dönüşüm yapmak gibi uygulamalarla bu tekniklerin gücünü yakından göreceksiniz.\nSon olarak, ESRGAN (Enhanced Super-Resolution GAN) ile, düşük çözünürlüklü görüntülerin nasıl inanılmaz detaylarla yüksek çözünürlüklü hale getirilebileceğini öğreneceksiniz. ESRGAN, görüntü iyileştirme ve fotoğraf kalitesini artırma konusunda en son teknolojiye sahip bir modeldir ve bu alandaki yeteneklerinizi bir üst seviyeye taşıyacaktır.\nBu kurs, yapay zeka ve derin öğrenme alanında kariyer yapmak isteyen, yenilikçi projeler geliştirmek isteyen veya sadece bu alandaki bilgisini derinleştirmek isteyen herkes için idealdir. Python programlama diline ve TensorFlow kütüphanesine aşina olan katılımcılar, kurs içeriğini daha kolay takip edebilir. Kurs sonunda, kendi GAN tabanlı projelerinizi hayata geçirebilecek ve görsel üretkenlik alanında fark yaratacak bilgi ve becerilere sahip olacaksınız.\nKapsamlı dersler, uygulamalı projeler ve örneklerle desteklenen bu kurs, sizi yapay zekanın görsel dünyasındaki en heyecan verici gelişmelerle tanıştıracak. Şimdi kaydolun ve görsel üretken yapay zeka dünyasında adım atmaya başlayın!",
      "target_audience": [
        "Yapay Zeka ve Makine Öğrenimi Öğrencileri",
        "Veri Bilimciler ve Mühendisler",
        "Araştırmacılar ve Akademisyenler",
        "Girişimciler ve Uygulama Geliştiricileri",
        "Görsel Sanatçılar ve Tasarımcılar"
      ]
    },
    {
      "title": "Makine Ögrenmesi Konut Fiyat Tahminlemesi Projesi",
      "url": "https://www.udemy.com/course/makine-ogrenmesi-konut-fiyat-tahminlemesi-projesi-i/",
      "bio": "Python ile Konut Fiyat Tahminlemesi Projesi",
      "objectives": [
        "Makine öğrenmesi nedir?",
        "Python ile makine öğrenmesi projesi",
        "Yapay Zeka",
        "Python ile Lineer Regresyon",
        "yapay zeka ile tahminleme"
      ],
      "course_content": {
        "Giriş": [
          "Giriş",
          "Veri Temizleme",
          "Feature Engineering",
          "Outlier Temizleme",
          "Model Oluşturma",
          "Frontend ve Backend"
        ]
      },
      "requirements": [
        "Herhangi bir gereksinim yok."
      ],
      "description": "Öğrenecekleriniz:\n\"Makine Öğrenmesi\" (Machine Learning) kavramını anlayın ve gerçek dünya uygulamalarını keşfedin.\nPython kullanarak konut fiyat tahmini odaklı bir makine öğrenmesi projesi geliştirin.\nYapay Zeka (Artificial Intelligence) alanını keşfedin ve projelerdeki rolünü anlayın.\nPython ile Lineer Regresyon (Linear Regression) uygulayarak tahmin modellemesini gerçekleştirin.\nMakine öğrenmesi teknikleri kullanarak tahmin yapma konusundaki yetenekleri öğrenin.\n1 bölüm, 6 ders ve toplam 2 saat 9 dakika süren bir içerikle kursa dalın.\nFeature Engineering gibi konuları içeren kurs içeriğini keşfedin ve makine öğrenmesindeki önemini anlayın.\nVeri analizi için veriyi hazırlamanın kritik bir adımı olarak Outlier Temizleme'yi ele alın.\nKonut fiyat tahmini için modeller oluşturun ve Python ile makine öğrenmesini uygulayın.\nProjeyi uygulamanın Frontend ve Backend yönlerini keşfedin.\nKursa kaydolmak için özel gereksinimlere ihtiyaç duyulmamaktadır (Herhangi bir gereksinim yok).\n\"Makine Öğrenmesi | Konut Fiyat Tahminleme Projesi\" serisi aracılığıyla gerçek dünya uygulamalarında deneyim kazanın.\nMakine öğrenmesi konularına ilgi duyanlar ve pratik beceriler kazanmak isteyenler için idealdir.\nGerçek dünya uygulamalarında deneyim kazanmak isteyen bireyler için uygundur.\nKonut fiyat tahminleme sorunlarını çözmek isteyen veri bilimciler ve geliştiriciler için tasarlanmıştır.\nVeri Keşfi ve Temizleme aşamasının bir parçası olarak veri setlerini keşfedin ve analiz edin.\nAnaliz sürecinde eksik verileri etkili bir şekilde yönetin (Eksik veri yönetimi).\nAykırı Değer Tespiti ile aykırı değerleri tanımlayın ve yönetin.\nMakine öğrenmesi projelerinde Özellik Mühendisliğinin önemini anlayın.\nÖzellik seçimi ve önceliklendirme, yeni özellikler oluşturma ve veri dönüşümleri gerçekleştirin.\nRegresyon modellerini keşfedin ve nuanslarını anlayın (Regresyon Modelleri İncelemesi).\nMakine öğrenmesi modellerini eğitin ve değerlendirin, Model Seçimi ve Eğitimi aşamasını kapsayın.\nModel optimizasyonu için hiperparametre ayarlama tekniklerini öğrenin (Hiperparametre Ayarlaması).\nKonut fiyat tahmini projesinin adım adım uygulanması (Proje Uygulaması).\nGerçek dünya veri setleri üzerinde çalışın ve geliştirilen modeli iteratif bir şekilde iyileştirin.\nKonut fiyat tahmini projelerinde pratik beceriler kazanın.\nModel seçimi ve hiperparametre ayarlama gibi ileri seviye makine öğrenmesi kavramlarını deneyimleyin.\nEtkileşimli derslerle öğretim yapan deneyimli eğitmenlerin uzmanlığından faydalanın.\nÖğrenen bir toplulukla etkileşimde bulunma ve deneyim paylaşma fırsatları sağlayın.\nBaşlangıç ve orta seviye Python geliştiricileri ve veri bilimcileri için özel olarak tasarlanmıştır.\n\n\n\n\nAçıklama:\nEğitim Serisi Adı: Makine Öğrenmesi | Konut Fiyat Tahminleme Projesi\nMakine öğrenmesinin gerçek dünya uygulamalarını keşfetmeye hazır mısınız? \"Makine Öğrenmesi | Konut Fiyat Tahminleme Projesi\" eğitim serisi, adım adım bir konut fiyat tahminleme projesi geliştirerek makine öğrenmesi becerilerinizi mükemmelleştirmenize olanak tanıyor. Bu seri, hem yeni başlayanlar hem de daha deneyimli katılımcılar için özel olarak tasarlanmış olup konut fiyat tahminleme problemine çözüm getirirken makine öğrenmesi konularını kapsamlı bir şekilde ele almaktadır.\nKimler İçin:\nMakine öğrenmesi konularına ilgi duyanlar\nGerçek dünya uygulamalarında deneyim kazanmak isteyenler\nKonut fiyat tahminleme problemlerini çözmek isteyen veri bilimciler ve geliştiriciler\nEğitim İçeriği:\nBu eğitim serisi, bir konut fiyat tahminleme projesi oluşturmak için gerekli temel makine öğrenmesi konularını kapsar. İşte eğitim serisinin ana konuları:\nVeri Keşfi ve Temizleme\nVeri seti analizi\nEksik veri yönetimi\nAykırı değer tespiti\nÖzellik Mühendisliği\nÖzellik seçimi ve önem sıralaması\nYeni özellikler oluşturma\nVeri dönüşümleri\nModel Seçimi ve Eğitimi\nRegresyon modelleri incelemesi\nModel eğitimi ve değerlendirme\nHiperparametre ayarlaması\nProje Uygulaması\nKonut fiyat tahminleme projesinin adım adım uygulanması\nGerçek dünya veri setleri üzerinde çalışma\nModelinizi geliştirme ve optimize etme\nEğitim Avantajları:\nPratik Projeler: Gerçek dünya konut fiyat tahminleme projesi ile pratik beceriler kazanma\nİleri Seviye Makine Öğrenmesi: Model seçimi, özellik mühendisliği ve hiperparametre ayarlaması gibi ileri seviye konuları anlama fırsatı\nDeneyimli Eğitmenler: Konunun uzmanları tarafından verilen etkileşimli derslerle etkili bir öğrenme deneyimi\nTopluluk Katılımı: Diğer öğrencilerle etkileşimde bulunma ve deneyim paylaşma fırsatı\nBu eğitim serisi, makine öğrenmesi konularına hakim olanlar için gerçek dünya uygulamalarında deneyim kazanma ve konut fiyat tahminleme projelerini geliştirme fırsatı sunuyor. Hemen kaydolun ve aktif olarak makine öğrenmesi prensiplerini uygulayarak yeni becerilere sahip olun!",
      "target_audience": [
        "Başlangıç ve Orta seviye python geliştiricileri ve veri bilimciler içindir"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第20部 AutoGen + MCP 打造 Manus 智能體",
      "url": "https://www.udemy.com/course/generative_ai_20/",
      "bio": "關於AutoGen， MCP server， RoundRobinGroupChat，SWARM，SelectorGroupChat，Web Surfer，Chat Message",
      "objectives": [
        "如何在Mac上配置Java環境",
        "如何使用Maven以及如何接入LangChain4J到項目當中",
        "如何為LLM添加記憶功能",
        "如何使用Chains為LLM添加記憶功能"
      ],
      "course_content": {
        "介紹": [
          "課程工具準備",
          "如何安裝和使用包管理器",
          "Windows安裝使用Poetry的方法"
        ],
        "如何使用 AutoGen - AgentChat & Core & Extentions": [
          "如何創建一個 AutoGen Agent 回復",
          "如何使用 AutoGen Agent 輸出ChatMessage & ToolCall 使用",
          "如何使用 AutoGen RoundRobinGroupChat",
          "如何使用 AutoGen 选择性群聊",
          "如何使用 AutoGen Swarm集群智能體",
          "SWARM如何使用工具"
        ],
        "如何結合 AutoGen 和 MCP": [
          "如何使用 MCP",
          "如何在 Python 中使用 MCP server",
          "如何實現 AutoGen 上網自動搜索並介入人工干預"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "【引爆AI智能體革命】Ken Cen重磅推出《Generative AI第20部：AutoGen+MCP打造Manus級智能體》\n隨著生成式 AI 技術日新月異，如何打造一個既智能又高效的 AI 智能體成為業界熱點。現在，我們隆重推出由 Ken Cen 精心打造的新課程——“Generative AI第20部 AutoGen + MCP 打造 Manus 智能體”，帶您深入探索利用 AutoGen 框架與 MCP 模型上下文協議，從零開始構建屬於您的智能體！\n課程亮點\nAutoGen 框架應用\n掌握 AutoGen 框架學習如何快速設計、調試與部署智能代理，實現消息協同與工具調用，打破傳統開發的繁瑣限制。\nMCP 模型上下文協議\n了解 MCP 的開放標準，學會如何通過 JSON-RPC 協議連接外部數據源與工具。讓您的智能體在面對複雜任務時，能夠靈活調用各類資源，實現動態上下文信息交換，從而大幅提升應用效果。\n打造 智能體\n深入實戰案例，演示如何結合 AutoGen 與 MCP，構建出高效智能體。從環境搭建、依賴安裝、到智能代理的定制與協同工作，每一步均精心講解，讓您從入門到精通。\n多智能體協同工作\n探索如何利用 AutoGen 的多智能體協作機制，構建功能完備的系統。學習 RoundRobin 分工、工具調用反思、結果整合等多項關鍵技術，實現智能體間的高效協同與自動優化。\n立即報名，加入我們的課程，一起探索 AutoGen 與 MCP 的無限可能，打造屬於您的 Manus 智能體！\n走在技術前沿，讓 AI 為您開創全新的智慧未來！",
      "target_audience": [
        "對AI感興趣的設計者"
      ]
    },
    {
      "title": "เรียนเทคนิคเขียน Prompt สั่งงาน AI สู่ความเป็นมืออาชีพ",
      "url": "https://www.udemy.com/course/aipromptworkshop/",
      "bio": "เรียนเทคนิคเขียน Prompt สั่งงาน AI สู่ความเป็นมืออาชีพ เปลี่ยนคนธรรมดาให้เป็นคนเก่ง Zero to Hero",
      "objectives": [
        "ผู้เรียนสามารถใช้งาน Generative AI เพื่อ Productivity X10 ในการทำงานได้อย่างมีประสิทธิภาพ",
        "ผู้เรียนจะได้เรียนรู้การใช้งานเครื่องมือ AI เช่น ChatGPT, Claude AI, Perplexity, Adobe Firefly และเครื่องมืออื่น ๆ",
        "ผู้เรียนสามารถใช้เทคนิคการเขียน Prompt สั่งงาน AI เพื่อให้ได้ผลลัพธ์ที่ตรงกับความต้องการมากที่สุด",
        "ผู้เรียนสามารถใช้เทคนิคการเขียน Prompt สั่งงาน AI สร้างสรรค์งานเขียนต่าง ๆ ได้อย่างมีประสิทธิภาพ",
        "ผู้เรียนสามารถใช้เทคนิคการเขียน Prompt สั่งงาน AI สร้างสรรค์งานศิลปะ รูปภาพ และวิดีโอ ให้ตรงตามความต้องการได้",
        "ผู้เรียนสามารถนำความรู้ที่ได้ไปประยุกต์ใช้ในการทำงานและ Projects ต่าง ๆ ได้จริง"
      ],
      "course_content": {
        "ทำความรู้จักกับเครื่องมือ AI": [
          "แนะนำคอร์สเรียนเทคนิคเขียน Prompt สั่งงาน AI สู่ความเป็นมืออาชีพ",
          "ทำไมต้องใช้ AI ให้เป็น",
          "Pain Point ของ Google นำไปสู่การเกิดขึ้นของ ChatGPT",
          "ประเภทของเครื่องมือ Generative AI"
        ],
        "เริ่มต้นเขียน Prompt  สั่งงาน AI ขั้นพื้นฐาน": [
          "วิธีเขียน Prompt สั่งงาน AI ให้เหมือนคุยกับมนุษย์",
          "จะเกิดอะไรขึ้นถ้าเขียน Prompt สั่งงาน AI ให้แนะนำสิ่งที่ไม่ดี",
          "สมัครใช้งาน ChatGPT, Claude และ Perplexity"
        ],
        "Workshop 1 เทคนิคเขียน Prompt แบบ Zero-Shot Prompting": [
          "Example 1.1 เขียน Prompt แบบ Zero-Shot Prompting ขั้นพื้นฐาน",
          "Example 1.2 เขียน Prompt แบบ Zero-Shot Prompting ขั้นกลาง",
          "Example 1.3 เขียน Prompt แบบ Zero-Shot Prompting ขั้นสูง"
        ],
        "Workshop 2 เทคนิคเขียน Prompt แบบ One-Shot Prompting": [
          "Example 2.1 เขียน Prompt แบบ One-Shot Prompting ขั้นพื้นฐาน",
          "Example 2.2 เขียน Prompt แบบ One-Shot Prompting ขั้นกลาง",
          "Example 2.3 เขียน Prompt แบบ One-Shot Prompting ขั้นสูง"
        ],
        "Workshop 3 เทคนิคเขียน Prompt แบบ Few-Shot Prompting": [
          "Example 3.1 เขียน Prompt แบบ Few-Shot Prompting ขั้นพื้นฐาน",
          "Example 3.2 เขียน Prompt แบบ Few-Shot Prompting ขั้นกลาง",
          "Example 3.3 เขียน Prompt แบบ Few-Shot Prompting ขั้นสูง"
        ],
        "Workshop 4 เทคนิคเขียน Prompt แบบ Chain-of-Thought Prompting": [
          "Example 4.1 เขียน Prompt แบบ Chain-of-Thought Prompting ขั้นพื้นฐาน",
          "Example 4.2 เขียน Prompt แบบ Chain-of-Thought Prompting ขั้นกลาง",
          "Example 4.3 เขียน Prompt แบบ Chain-of-Thought Prompting ขั้นสูง"
        ],
        "Workshop 5 เทคนิคเขียน Prompt แบบ Counterfactual Prompting": [
          "Example 5.1 เขียน Prompt แบบ Counterfactual Prompting ขั้นพื้นฐาน",
          "Example 5.2 เขียน Prompt แบบ Counterfactual Prompting ขั้นกลาง",
          "Example 5.3 เขียน Prompt แบบ Counterfactual Prompting ขั้นสูง"
        ],
        "Workshop 6 เทคนิคเขียน Prompt แบบ Role-Play Prompting": [
          "Example 6.1 เขียน Prompt แบบ Role-Play Prompting ขั้นพื้นฐาน",
          "Example 6.2 เขียน Prompt แบบ Role-Play Prompting ขั้นกลาง",
          "Example 6.3 เขียน Prompt แบบ Role-Play Prompting ขั้นสูง"
        ],
        "Workshop 7 เทคนิคเขียน Prompt แบบ Constitutional AI Prompting": [
          "Example 7.1 เขียน Prompt แบบ Constitutional AI Prompting ขั้นพื้นฐาน",
          "Example 7.2 เขียน Prompt แบบ Constitutional AI Prompting ขั้นกลาง",
          "Example 7.3 เขียน Prompt แบบ Constitutional AI Prompting ขั้นสูง"
        ],
        "Workshop 8 เทคนิคเขียน Prompt แบบ Meta-Prompting": [
          "Example 8.1 เขียน Prompt แบบ Meta-Prompting ขั้นพื้นฐาน",
          "Example 8.2 เขียน Prompt แบบ Meta-Prompting ขั้นกลาง",
          "Example 8.3 เขียน Prompt แบบ Meta-Prompting ขั้นสูง"
        ]
      },
      "requirements": [
        "ผู้เรียนต้องมีความรู้พื้นฐานด้านการใช้ภาษาในการสื่อสารกับ AI ได้"
      ],
      "description": "หลักสูตร เรียนเทคนิคเขียน Prompt สั่งงาน AI สู่ความเป็นมืออาชีพ\nสามารถเรียนได้ทุกคน ไม่จำเป็นต้องมีความรู้มาก่อน\nเนื้อหาการเรียนเทคนิคเขียน Prompt สั่งงาน AI สู่ความเป็นมืออาชีพ เปลี่ยนคนธรรมดาให้เป็นคนเก่ง Zero to Hero\nเป็นการเรียนแบบทำ Workshops ไปพร้อมกัน\nเรียนเทคนิคเขียน Prompt สั่งงาน AI สู่ความเป็นมืออาชีพ\nส่วนที่ 1: ทำความรู้จักกับเครื่องมือ AI\n1. แนะนำคอร์สเรียนเทคนิคเขียน Prompt สั่งงาน AI สู่ความเป็นมืออาชีพ\n2. ทำไมต้องใช้ AI ให้เป็น\n3. Pain Point ของ Google นำไปสู่การเกิดขึ้นของ ChatGPT\n4. ประเภทของเครื่องมือ Generative AI\nส่วนที่ 2: เริ่มต้นเขียน Prompt  สั่งงาน AI ขั้นพื้นฐาน\n5. วิธีเขียน Prompt สั่งงาน AI ให้เหมือนคุยกับมนุษย์\n6. จะเกิดอะไรขึ้นถ้าเขียน Prompt สั่งงาน AI ให้แนะนำสิ่งที่ไม่ดี\n7. สมัครใช้งาน ChatGPT, Claude และ Perplexity\nส่วนที่ 3: Workshop 1 เทคนิคเขียน Prompt แบบ Zero-Shot Prompting\n8. Example 1.1 เขียน Prompt แบบ Zero-Shot Prompting ขั้นพื้นฐาน\n9. Example 1.2 เขียน Prompt แบบ Zero-Shot Prompting ขั้นกลาง\n10. Example 1.3 เขียน Prompt แบบ Zero-Shot Prompting ขั้นสูง\nส่วนที่ 4: Workshop 2 เทคนิคเขียน Prompt แบบ One-Shot Prompting\n11. Example 2.1 เขียน Prompt แบบ One-Shot Prompting ขั้นพื้นฐาน\n12. Example 2.2 เขียน Prompt แบบ One-Shot Prompting ขั้นกลาง\n13. Example 2.3 เขียน Prompt แบบ One-Shot Prompting ขั้นสูง\nส่วนที่ 5: Workshop 3 เทคนิคเขียน Prompt แบบ Few-Shot Prompting\n14. Example 3.1 เขียน Prompt แบบ Few-Shot Prompting ขั้นพื้นฐาน\n15. Example 3.2 เขียน Prompt แบบ Few-Shot Prompting ขั้นกลาง\n16. Example 3.3 เขียน Prompt แบบ Few-Shot Prompting ขั้นสูง\nส่วนที่ 6: Workshop 4 เทคนิคเขียน Prompt แบบ Chain-of-Thought Prompting\n17. Example 4.1 เขียน Prompt แบบ Chain-of-Thought Prompting ขั้นพื้นฐาน\n18. Example 4.2 เขียน Prompt แบบ Chain-of-Thought Prompting ขั้นกลาง\n19. Example 4.3 เขียน Prompt แบบ Chain-of-Thought Prompting ขั้นสูง\nส่วนที่ 7: Workshop 5 เทคนิคเขียน Prompt แบบ Counterfactual Prompting\n20. Example 5.1 เขียน Prompt แบบ Counterfactual Prompting ขั้นพื้นฐาน\n21. Example 5.2 เขียน Prompt แบบ Counterfactual Prompting ขั้นกลาง\n22. Example 5.3 เขียน Prompt แบบ Counterfactual Prompting ขั้นสูง\nส่วนที่ 8: Workshop 6 เทคนิคเขียน Prompt แบบ Role-Play Prompting\n23. Example 6.1 เขียน Prompt แบบ Role-Play Prompting ขั้นพื้นฐาน\n24. Example 6.2 เขียน Prompt แบบ Role-Play Prompting ขั้นกลาง\n25. Example 6.3 เขียน Prompt แบบ Role-Play Prompting ขั้นสูง\nส่วนที่ 9: Workshop 7 เทคนิคเขียน Prompt แบบ Constitutional AI Prompting\n26. Example 7.1 เขียน Prompt แบบ Constitutional AI Prompting ขั้นพื้นฐาน\n27. Example 7.2 เขียน Prompt แบบ Constitutional AI Prompting ขั้นกลาง\n28. Example 7.3 เขียน Prompt แบบ Constitutional AI Prompting ขั้นสูง\nส่วนที่ 10: Workshop 8 เทคนิคเขียน Prompt แบบ Meta-Prompting\n29. Example 8.1 เขียน Prompt แบบ Meta-Prompting ขั้นพื้นฐาน\n30. Example 8.2 เขียน Prompt แบบ Meta-Prompting ขั้นกลาง\n31. Example 8.3 เขียน Prompt แบบ Meta-Prompting ขั้นสูง\nส่วนที่ 11: Workshop 9 เทคนิคเขียน Prompt แบบ Prompt Chaining\n32. Example 9.1 เขียน Prompt แบบ Prompt Chaining ขั้นพื้นฐาน\n33. Example 9.2 เขียน Prompt แบบ Prompt Chaining ขั้นกลาง\n34. Example 9.3 เขียน Prompt แบบ Prompt Chaining ขั้นสูง\nส่วนที่ 12: Workshop 10 เทคนิคเขียน Prompt แบบ Prompt Framework\n35. Example 10.1 เขียน Prompt แบบ Prompt Framework สร้างงานเขียน Text-to-Text\n36. Example 10.2 เขียน Prompt แบบ Prompt Framework สร้างรูปภาพ Text-to-Image\n37. Example 10.3 เขียน Prompt แบบ Prompt Framework สร้างวิดีโอ Text-to-Video",
      "target_audience": [
        "ผู้เริ่มต้นเรียนรู้การใช้งาน AI เพื่อการเรียนและการทำงาน พนักงานบริษัท มนุษย์เงินเดือน โปรแกรมเมอร์ นักออกแบบงานศิลปะ Creative นักการตลาด นักวิเคราะห์ข้อมูล ผู้บริหาร นักเรียน นักศึกษา อาจารย์ และผู้ที่สนใจในการใช้ AI เพิ่มความเร็วและประสิทธิภาพในการทำงานอย่างมืออาชีพ"
      ]
    },
    {
      "title": "[TR] Tariften Şefe: 100+ Projeyle LLM Mühendisi Olun",
      "url": "https://www.udemy.com/course/tariften-sefe-100-projeyle-llm-muhendisi-olun/",
      "bio": "Kod yazmadan LLM ustası olun! Yapay zekayı eğlenceli yemek benzetmeleriyle öğrenin. (AI)",
      "objectives": [
        "Büyük dil modellerinin (LLM) ne olduğunu ve nasıl çalıştığını gerçek dünya benzetmeleriyle anlayın",
        "LLM’leri güçlendiren temel bileşenleri belirleyin: eğitim verileri, tokenizasyon ve veri kalitesi gibi.",
        "LLM'lerin nasıl eğitildiğini, partiler (batch), dönemler (epoch) ve kayıp fonksiyonları (loss functions) gibi kavramlarla açıklayın.",
        "Zero-shot, few-shot ve chain-of-thought gibi teknikleri kullanarak daha iyi istemler yazın.",
        "Hugging Face ve LoRA gibi araçları kullanarak modelleri fine-tuning ile özelleştirin.",
        "Model performansını hem nicel hem de nitel ölçütler kullanarak değerlendirin.",
        "LLM’leri API’ler, FastAPI/Flask kullanarak dağıtın ve Hugging Face Spaces gibi platformlarda barındırın.",
        "Kod yazmadan kullanılan araçlar ve LangChain ile LLM destekli tam uygulamalar oluşturun.",
        "Günlükler, geri bildirim döngüleri ve A/B testleri kullanarak yapay zeka modellerinizi izleyin ve iyileştirin.",
        "Günlükler, geri bildirim döngüleri ve A/B testleri kullanarak yapay zeka modellerinizi izleyin ve geliştirin."
      ],
      "course_content": {
        "Ne Pişiyor? LLM’lere Giriş": [
          "“Ne Pişiyor? LLM’lere Giriş”e Giriş",
          "Dil modeli nedir?",
          "LLM’lerin Evrimi – Daktilolardan Gurme Robotlara",
          "LLM’ler “sonraki kelimeyi” nasıl tahmin eder? (Sandviç Tamamlama Otomasyonu)",
          "LLM’ler ile Geleneksel Yapay Zeka Arasındaki Farklar (Mikrodalga vs Şef Yemeği)",
          "Popüler LLM’lere Genel Bakış: GPT, Claude, Gemini, LLaMA (Restoran Turu)"
        ],
        "Malzemeler Önemlidir – Veriyi Anlamak": [
          "“Malzemeler Önemlidir – Veriyi Anlamak”a Giriş",
          "Eğitim verisi nedir? (Kiler stoklamak)",
          "Tokenizasyon – Metni küçük lokmalara ayırmak",
          "LLM veri setleri: Vikipedi, Kitaplar, WebMetinleri(Süpermarket alışveriş listesi",
          "Çöp veri girerse = çöp sonuç çıkar: Veri kalitesi önemlidir",
          "Verideki önyargı = Biri için acı, diğeri için tatsız olabilir"
        ],
        "Büyük Ölçekte Pişirme – Model Eğitiminin Temelleri": [
          "“Büyük Ölçekte Pişirme – Model Eğitiminin Temelleri”ne Giriş",
          "Model eğitimi sırasında ne olur? (Karıştırmak, pişirmek, ayarlamak)",
          "Epoklar, partiler ve kayıp – Pişirme turları",
          "GPU ve TPU’lar – Eğitim için endüstriyel fırınlar",
          "Eğitim maliyeti – LLM market faturası",
          "Ön eğitim vs İnce ayar – Ana tarif vs Bölgesel dokunuş"
        ],
        "Prompt Mühendisliği – Mükemmel Sonuç İçin Baharat Ayarı": [
          "“Prompt Mühendisliği – Mükemmel Sonuç İçin Baharat Ayarı”na Giriş",
          "Bir prompt’un anatomisi – Gizli baharat karışımı",
          "Prompt stilleri: Zero-shot, Few-shot, Chain-of-Thought(Tuz, acıbiber, otlar gibi",
          "Rol yapma prompt’ları – “Kendini bir barista gibi düşün”",
          "Prompt optimizasyonu – Çiğden pişmişe",
          "Prompt değerlendirmesi – Prompt’lar için tat testi"
        ],
        "İnce Ayar – Tarifi Kişiselleştirme": [
          "“İnce Ayar – Tarifi Kişiselleştirme”ye Giriş",
          "İnce ayar nedir? – Klasik tarife babaannenin dokunuşu",
          "Transfer öğrenimi – Kek tabanını ödünç al, süslemeyi sen ekle",
          "Teknikler: Tam İnce Ayar vs LoRA (Düşük Sıralı Uyumlama)",
          "Kendi verinle ince ayar yapma (Senin mutfağın, senin kuralların)",
          "İnce Ayar Araçları: Hugging Face, Google Colab, PEFT"
        ],
        "LLM’leri Değerlendirme – Tat Testi": [
          "“LLM’leri Değerlendirme – Tat Testi”ne Giriş",
          "Değerlendirme neden önemlidir? – Şefin son kontrolü",
          "Nicel Ölçütler: Perpleksite, BLEU, ROUGE",
          "Nitel Ölçütler: İnsan geri bildirimi, fayda, alaka düzeyi",
          "Halüsinasyonlar ve model hataları – Beklenmedik tatlar",
          "Önyargı Tespiti – Farklı diyet tercihlerine hitap etmek"
        ],
        "Yemeği Servis Etmek – LLM’leri Yayına Alma": [
          "“Yemeği Servis Etmek – LLM’leri Yayına Alma”ya Giriş",
          "Yayına alma nedir? – Geçici bir restoran açmak",
          "FastAPI veya Flask ile API oluşturma",
          "Gradio/Streamlit ile demo arayüzleri oluşturma (Yemek kamyonu sunumu)",
          "Barındırma seçenekleri: Hugging Face Spaces, AWS, GCP",
          "Ölçekleme ve izleme – Açık büfeyi sorunsuz yürütmek"
        ],
        "LLM Destekli Uygulamalar – Kendi Yemek Kamyonun": [
          "“LLM Destekli Uygulamalar – Kendi Yemek Kamyonun”a Giriş",
          "Uygulama Kullanım Alanları: Sohbet botları, özetleyiciler, önericiler",
          "Kodsuz Araçlar: LangChain Şablonları, GPT Builder, Voiceflow",
          "LLM + Veritabanı: Akıllı Menü",
          "LangChain ile zincirleme – Yapay zekâ montaj hattı",
          "Proje: Özel arayüze sahip tam işlevli bir LLM uygulaması oluşturun"
        ],
        "Tazeliğini Koruma – İzleme ve Geliştirme": [
          "“Tazeliğini Koruma – İzleme ve Geliştirme”ye Giriş",
          "Geri bildirim döngüleri – Yapay zekâ için Yelp yorumları gibi",
          "Kayıt alma ve izleme – Akıllı mutfak kameraları",
          "A/B Testi – Hangi tatlı kazandı?",
          "Model kayması – Zamanla damak tadı değiştiğinde",
          "Prompt’ların, veri setlerinin ve dağıtımların güncellenmesi"
        ],
        "Usta Şef Olmak – LLM Mühendisliğinde Kariyer": [
          "“Usta Şef Olmak – LLM Mühendisliğinde Kariyer”e Giriş",
          "LLM Kariyer Yolları: Mühendis, Mimar, Prompt Uzmanı",
          "Portföyünü Oluşturmak – Kendi Yapay Zeka Tarif Kitabın",
          "Açık Kaynağa Katkı: Veri setleri, Modeller, Araçlar",
          "Özgeçmiş İpuçları, Mülakatlar ve Teknik Sorular",
          "Final Projesi: Kendi LLM uygulamanı oluştur ve dağıt"
        ]
      },
      "requirements": [
        "Programlama deneyimi gerekmez – bu kurs tamamen yeni başlayanlar için tasarlanmıştır.",
        "Yapay zekaya ve dil modellerinin nasıl çalıştığına duyulan merak, başlamak için fazlasıyla yeterlidir.",
        "Tarayıcı kullanma, dosya yükleme ve yazı yazma gibi temel bilgisayar becerileri faydalıdır.",
        "İnternete erişimi olan bir dizüstü veya masaüstü bilgisayar – gelişmiş donanım gerekmez.",
        "Opsiyonel: GPT ile uygulamalı projeler için ücretsiz bir OpenAI API anahtarı.",
        "Opsiyonel: sohbet botları oluşturma, istemler yazma veya yapay zeka kariyerlerini keşfetme ilgisi.",
        "Kullanılan tüm araçlar (Gradio, Google Colab veya LangChain şablonları gibi) ücretsizdir ve yeni başlayanlar için uygundur."
      ],
      "description": "Bu kurs, yapay zeka tarafından İngilizceden Türkçeye çevrilmiştir, böylece son teknolojileri kendi ana dilinizde öğrenebilirsiniz.\nTariften Şefe: LLM Mühendisi Ol (Yemek Benzetmeleriyle), hiç kod yazmadan Büyük Dil Modellerini (LLM'ler) öğrenebileceğiniz eğlenceli ve başlangıç dostu bir kurstur. Yapay zekaya ilgi duyuyorsanız, dil modellerinin dünyasına adım atmak istiyorsanız ya da bir LLM mühendisi olmak hedefindeyseniz, bu kurs sizi ChatGPT, Claude, Gemini ve LLaMA gibi güçlü araçları anlamaya ve kullanmaya hazırlayacak. Teknik kavramları mutfak metaforlarıyla basitleştiriyoruz—böylece sıfırdan bir yapay zeka şefine dönüşmeniz hiç zaman almayacak.\nLLM’lerin nasıl inşa edildiğini, eğitildiğini, dağıtıldığını ve değerlendirildiğini kolay anlaşılır benzetmelerle keşfedeceksiniz. Tokenizasyonu sebze doğramaya, eğitimi büyük ölçekli fırınlamaya, prompt mühendisliğini ise yemeği doğru şekilde tatlandırmaya benzetiyoruz. Her modül veri hazırlama ve ince ayardan değerlendirme ve dağıtıma kadar yeni bir beceri kazandırmak için tasarlandı. Kurs sonunda, model mimarisi, ön eğitim, transfer öğrenimi, prompt optimizasyonu, perplexity ve BLEU gibi metriklerle model değerlendirme ve FastAPI, Gradio, Hugging Face Spaces ve LangChain gibi araçlarla kendi LLM tabanlı uygulamalarınızı dağıtma konularında yetkinlik kazanacaksınız.\nBu kurs, teknik altyapısı olmayan öğrenciler, eğitmenler, içerik üreticileri, girişimciler ve profesyoneller için idealdir. Yapay zeka yaşam döngüsünü adım adım keşfedeceksiniz—“Dil modeli nedir?” sorusundan başlayarak kendi chatbot’unuzu, özetleyicinizi veya öneri uygulamanızı dağıtmaya kadar. Kod yazmadan çalışan araçları nasıl kullanacağınızı, gerçek prompt’larla nasıl denemeler yapacağınızı, var olan modelleri nasıl iyileştireceğinizi, çıktıları nasıl değerlendireceğinizi ve prompt mühendisi, yapay zeka ürün yöneticisi veya LLM mimarı gibi kariyer yollarını nasıl keşfedeceğinizi öğreneceksiniz.\nKodlama deneyimi gerekmez. LLM’lerle doğal dil kullanarak nasıl iletişim kuracağınızı, akıllı ve etkili prompt’lar nasıl tasarlanacağını, veri toplama ve tokenizasyondan modelin tahmin sürecine ve GPU/TPU gibi donanım ihtiyaçlarına kadar perde arkasında neler olduğunu öğreneceksiniz. Ayrıca, önyargı tespiti, halüsinasyonlar, geri bildirim döngüleri ve zaman içinde yapay zeka sistemlerinizi izleme ve geliştirme stratejilerini de ele alacağız.\nKursun sonunda LLM teorisinde sağlam bir temele, uygulamalı AI projelerinden oluşan bir portföye ve üretken yapay zekanın büyüyen dünyasında yer almak için gerekli özgüvene sahip olacaksınız. Kendi AI ürününüzü oluşturmak, bir startup'a katılmak, açık kaynak projelere katkı sağlamak veya sadece arkadaşlarınıza makine öğrenimini açıklayabilmek istiyorsanız, bu kurs sizi oraya taşıyacak—bilgiyle dolu bir tabak ve yanında eğlenceli bir sunumla.\nEğer tarif okuyucusundan LLM şefine dönüşmeye hazırsanız, mutfak benzetmeleri ve pratik örneklerle dolu bu lezzetli yapay zeka yolculuğuna katılın!",
      "target_audience": [
        "Teknik terimlere boğulmadan yapay zeka dünyasına adım atmak isteyen yeni başlayanlar.",
        "Yapay zeka destekli araçları keşfeden ürün yöneticileri ve iş liderleri.",
        "LLM’lerden yararlanmak isteyen eğitimciler, içerik üreticileri ve hikaye anlatıcıları.",
        "LLM mühendisi, istem tasarımcısı veya yapay zeka uzmanı olmayı hedefleyen kariyer değiştiriciler.",
        "Gerçek hayattan alınan benzetmelerle (örneğin yemek!), etkileşimli projelerle ve uygulamalı yaratıcılıkla öğrenmeyi seviyorsanız, bu kursu lezzetli derecede değerli bulacaksınız."
      ]
    },
    {
      "title": "Python w Data Science - NumPy, Pandas & Scikit-Learn",
      "url": "https://www.udemy.com/course/python-data-science-numpy-pandas-scikit-learn/",
      "bio": "Podnieś poziom swoich umiejętności programowania w języku Python oraz data science i rozwiąż 350 ćwiczeń!",
      "objectives": [
        "rozwiąż ponad 350 ćwiczeń z data science przy pomocy języka Python",
        "postaw się przed rzeczywistymi problemami występującymi w data science",
        "pracuj z bibliotekami NumPy, Pandas, Scikit-Learn",
        "pracuj z dokumentacją",
        "zagwarantowane wsparcie instruktora"
      ],
      "course_content": {
        "Wskazówki": [
          "Kilka słów od autora"
        ],
        "Starter": [
          "Ćwiczenie 0",
          "Rozwiązanie 0"
        ],
        "----- NUMPY -----": [
          "Intro"
        ],
        "Ćwiczenia 1-10": [
          "Ćwiczenie 1",
          "Rozwiązanie 1",
          "Ćwiczenie 2",
          "Rozwiązanie 2",
          "Ćwiczenie 3",
          "Rozwiązanie 3",
          "Ćwiczenie 4",
          "Rozwiązanie 4",
          "Ćwiczenie 5",
          "Rozwiązanie 5",
          "Ćwiczenie 6",
          "Rozwiązanie 6",
          "Ćwiczenie 7",
          "Rozwiązanie 7",
          "Ćwiczenie 8",
          "Rozwiązanie 8",
          "Ćwiczenie 9",
          "Rozwiązanie 9",
          "Ćwiczenie 10",
          "Rozwiązanie 10"
        ],
        "Ćwiczenia 11-20": [
          "Ćwiczenie 11",
          "Rozwiązanie 11",
          "Ćwiczenie 12",
          "Rozwiązanie 12",
          "Ćwiczenie 13",
          "Rozwiązanie 13",
          "Ćwiczenie 14",
          "Rozwiązanie 14",
          "Ćwiczenie 15",
          "Rozwiązanie 15",
          "Ćwiczenie 16",
          "Rozwiązanie 16",
          "Ćwiczenie 17",
          "Rozwiązanie 17",
          "Ćwiczenie 18",
          "Rozwiązanie 18",
          "Ćwiczenie 19",
          "Rozwiązanie 19",
          "Ćwiczenie 20",
          "Rozwiązanie 20"
        ],
        "Ćwiczenia 21-30": [
          "Ćwiczenie 21",
          "Rozwiązanie 21",
          "Ćwiczenie 22",
          "Rozwiązanie 22",
          "Ćwiczenie 23",
          "Rozwiązanie 23",
          "Ćwiczenie 24",
          "Rozwiązanie 24",
          "Ćwiczenie 25",
          "Rozwiązanie 25",
          "Ćwiczenie 26",
          "Rozwiązanie 26",
          "Ćwiczenie 27",
          "Rozwiązanie 27",
          "Ćwiczenie 28",
          "Rozwiązanie 28",
          "Ćwiczenie 29",
          "Rozwiązanie 29",
          "Ćwiczenie 30",
          "Rozwiązanie 30"
        ],
        "Ćwiczenia 31-40": [
          "Ćwiczenie 31",
          "Rozwiązanie 31",
          "Ćwiczenie 32",
          "Rozwiązanie 32",
          "Ćwiczenie 33",
          "Rozwiązanie 33",
          "Ćwiczenie 34",
          "Rozwiązanie 34",
          "Ćwiczenie 35",
          "Rozwiązanie 35",
          "Ćwiczenie 36",
          "Rozwiązanie 36",
          "Ćwiczenie 37",
          "Rozwiązanie 37",
          "Ćwiczenie 38",
          "Rozwiązanie 38",
          "Ćwiczenie 39",
          "Rozwiązanie 39",
          "Ćwiczenie 40",
          "Rozwiązanie 40"
        ],
        "Ćwiczenia 41-50": [
          "Ćwiczenie 41",
          "Rozwiązanie 41",
          "Ćwiczenie 42",
          "Rozwiązanie 42",
          "Ćwiczenie 43",
          "Rozwiązanie 43",
          "Ćwiczenie 44",
          "Rozwiązanie 44",
          "Ćwiczenie 45",
          "Rozwiązanie 45",
          "Ćwiczenie 46",
          "Rozwiązanie 46",
          "Ćwiczenie 47",
          "Rozwiązanie 47",
          "Ćwiczenie 48",
          "Rozwiązanie 48",
          "Ćwiczenie 49",
          "Rozwiązanie 49",
          "Ćwiczenie 50",
          "Rozwiązanie 50"
        ],
        "Ćwiczenia 51-60": [
          "Ćwiczenie 51",
          "Rozwiązanie 51",
          "Ćwiczenie 52",
          "Rozwiązanie 52",
          "Ćwiczenie 53",
          "Rozwiązanie 53",
          "Ćwiczenie 54",
          "Rozwiązanie 54",
          "Ćwiczenie 55",
          "Rozwiązanie 55",
          "Ćwiczenie 56",
          "Rozwiązanie 56",
          "Ćwiczenie 57",
          "Rozwiązanie 57",
          "Ćwiczenie 58",
          "Rozwiązanie 58",
          "Ćwiczenie 59",
          "Rozwiązanie 59",
          "Ćwiczenie 60",
          "Rozwiązanie 60"
        ],
        "Ćwiczenia 61-70": [
          "Ćwiczenie 61",
          "Rozwiązanie 61",
          "Ćwiczenie 62",
          "Rozwiązanie 62",
          "Ćwiczenie 63",
          "Rozwiązanie 63",
          "Ćwiczenie 64",
          "Rozwiązanie 64",
          "Ćwiczenie 65",
          "Rozwiązanie 65",
          "Ćwiczenie 66",
          "Rozwiązanie 66",
          "Ćwiczenie 67",
          "Rozwiązanie 67",
          "Ćwiczenie 68",
          "Rozwiązanie 68",
          "Ćwiczenie 69",
          "Rozwiązanie 69",
          "Ćwiczenie 70",
          "Rozwiązanie 70"
        ]
      },
      "requirements": [
        "Ukończone kursy ze ścieżki Python Developer na tym koncie instruktorskim",
        "Ukończone kursy ze ścieżki Data Scientist na tym koncie instruktorskim"
      ],
      "description": "Kurs składa się z 350 ćwiczeń (zadania + rozwiązania) z języka Python w obszarze data science. Wykorzystane są takie biblioteki jak NumPy, Pandas oraz Scikit-Learn. Kurs przeznaczony jest dla osób posiadających podstawową wiedzę z zakresu języka Python oraz data science. Jest to świetny sprawdzian dla osób, które chcą wejść w świat data science i szukają nowych wyzwań. Ćwiczenia są również dobrym sprawdzianem przed rozmową kwalifikacyjną. Wiele popularnych pytań zostało omówionych na kursie.\nJeśli zastanawiasz się, czy warto zrobić krok w kierunku języka Python oraz data science nie zwlekaj i już dziś podejmij wyzwanie!\n\n\nData Scientist - zawód przyszłości!\nDynamiczny rozwój technologii, a także nieustannie zwiększająca się ilość danych, które są generowane powoduje, że w skali globalnej drastycznie wzrasta zapotrzebowanie na osoby zajmujące się data science. Jest to już trend globalny od którego żaden wysoko rozwinięty kraj nie może przejść obojętnie.\nPrzez ostatni rok sporo firm działających na terenie Polski zaczęło budować zespoły data science. Pojawiło się także bardzo dużo ofert pracy związanych z przeróżnymi branżami, np. finanse, ubezpieczenia, telco, sprzedaż, marketing internetowy czy nawet gaming, To tylko początkowy sygnał trendu, który jak przewiduje wiele źródeł nie pojawił się tylko na chwilę.\n\n\nKim jest data scientist?\nJest to osoba, która łączy w sobie rolę programisty (tutaj preferowanym językiem jest Python) oraz analityka danych poruszająca się zwinnie w obszarze statystyki oraz uczenia maszynowego. Poza cechami technicznymi cenne są także umiejętności miękkie, takie jak umiejętność prezentacji, ciekawość, umiejętność wyjaśniania skomplikowanych zagadnień w prosty sposób czy myślenie krytyczne.\nJeśli zastanawiasz się nad karierą w data science właściwy moment jest właśnie teraz!\n\n\nBoom na rozwiązania AI\nZastosowania sztucznej inteligencji (Artificial Intelligence) rosną w tempie wykładniczym. Od prostych modeli klasyfikujących pocztę mailową, wybierającą najbardziej optymalną trasę dojazdu, rozpoznającą nas w czasie rzeczywistym (wideoweryfikacja) po auta a nawet samoloty autonomiczne. A przed nami przecież tyle nieodkrytych obszarów w których można zastosować AI.\n\n\nStack Overflow Developer Survey\nWedług Stack Overflow Developer Survey 2021 język Python jest najchętniej wybieranym językiem do nauki programowania.",
      "target_audience": [
        "Początkujący analitycy danych",
        "Programiści i developerzy",
        "Osoby przygotowujące się do pracy jako Data Scientist / Data Analyst",
        "Specjaliści Business Intelligence i analitycy biznesowi",
        "Entuzjaści sztucznej inteligencji i uczenia maszynowego",
        "Naukowcy i badacze",
        "Studenci kierunków technicznych i ścisłych"
      ]
    },
    {
      "title": "Bootcamp Lengkap Data Science 2022",
      "url": "https://www.udemy.com/course/bootcamp-lengkap-data-science-2022/",
      "bio": "Dalam upaya menciptakan pelatihan data scientist yang efektif, efisien, dan terstruktur, kami menyediakan secara online",
      "objectives": [
        "Bidang Data Science dan Berbagai Disiplin Data Science",
        "Teknik Populer Data Science",
        "Tools Populer Data Science",
        "Karir di Ilmu Data",
        "Probabilitas, Kombinatorika, Permutasi, Faktorial, Himpunan",
        "Simetri Kombinasi",
        "Aturan Aditif",
        "Statistik, Variabel, Histogram, Kovarians, Koefisien Korelasi",
        "Distribusi, Estimasi, Interval Keyakinan",
        "Python",
        "Metode Statistik TIngkat Lanjut"
      ],
      "course_content": {
        "1. Pendahuluan": [
          "1.1 Apa yang Akan Anda Pelajari dalam Kursus Ini",
          "1.2 Apa yang Dicakup pada Kursus Ini?"
        ],
        "2. Bidang Data Science dan Berbagai Disiplin Data Science": [
          "2.1 Data Science dan Kata Kunci Bisnis: Mengapa ada begitu banyak? (Part 1)",
          "2.2 Apa Perbedaan antara analisis dan analitik?",
          "2.3 Business Analytics, Data Analytics, dan Pendahuluan Data Science",
          "2.4 Melanjutkan dengan BI, ML, dan AI",
          "2.5 Rincian Infografis Data Science"
        ],
        "3. Bidang Data Science - Menghubungkan Disiplin Data Science": [
          "3.1 Menerapkan Data Tradisional, Data Besar, BI, Ilmu Data Tradisional, dan ML"
        ],
        "4. Bidang Data Science - Manfaat Setiap Disiplin Data Science": [
          "4.1 Alasan Dibalik Disiplin Data Science"
        ],
        "5. Bidang Ilmu Data - Teknik Populer Data Science": [
          "5.1 Teknik untuk Bekerja dengan Data Tradisional (Part 1)",
          "5.1 Teknik untuk Bekerja dengan Data Tradisional (Part 2)",
          "5.2 Contoh Kehidupan Nyata Data Tradisional",
          "5.3 Teknik untuk Bekerja dengan Big data (Part 1)",
          "5.3 Teknik untuk Bekerja dengan Big Data (Part 2)",
          "5.4 Contoh Kehidupan Nyata dari Big Data",
          "5.5 Teknik Business Intelligence (BI)",
          "5.6 Contoh Kehidupan Nyata Business Intelligence (BI)",
          "5.7 Teknik Bekerja dengan Metode Tradisional (Part 1)",
          "5.7 Teknik Bekerja dengan Metode Tradisional (Part 2)",
          "5.7 Teknik Bekerja dengan Metode Tradisional (Part 3)",
          "5.8 Contoh Kehidupan Nyata dari Metode Tradisional",
          "5.9 Teknik Pembelajaran Mesin (ML)",
          "5.10 Jenis Pembelajaran Mesin",
          "5.11 Contoh Pembelajaran Mesin (ML) di Kehidupan Nyata"
        ],
        "6. Tools Populer Data Science": [
          "6.1 Bahasa Pemrograman dan Perangkat Lunak yang Digunakan (Part 1)",
          "6.1 Bahasa Pemrograman dan Perangkat Lunak yang Digunakan (Part 2)",
          "6.1 Bahasa Pemrograman dan Perangkat Lunak yang Digunakan (Part 3)"
        ],
        "7. Bidang Ilmu Data - Karir di Ilmu Data": [
          "7.1 Menemukan Pekerjaan - Apa yang Diharapkan dan Apa yang Harus Dicari"
        ],
        "8. Bidang Data Science - Membongkar Kesalahpahaman Umum": [
          "8.1 Membongkar Kesalahpahaman Umum"
        ],
        "9. Probabilitas": [
          "9.1 Rumus Probabilitas Dasar",
          "9.2 Menghitung Nilai yang Diharapkan",
          "9.3 Frekuensi",
          "9.4 Acara dan Pelengkapnya"
        ],
        "10. Probabilitas - Kombinatorika": [
          "10.1 Dasar-dasar Kombinatorika",
          "10.2 Permutasi dan Cara Menggunakannya",
          "10.3 Operasi Sederhana dengan Faktorial",
          "10.4 Menyelesaikan Variasi dengan Pengulangan",
          "10.5 Menyelesaikan Variasi tanpa Pengulangan",
          "10.6 Menyelesaikan Kombinasi",
          "10.7 Simetri Kombinasi",
          "10.8 Menyelesaikan Kombinasi dengan Ruang Sampel Terpisah",
          "10.9 Kombinatorik dalam Kehidupan Nyata: Lotere",
          "10.10 Rekap Kombinatorika",
          "10.11 Contoh Praktis Kombinatorika (Part 1)",
          "10.11 Contoh Praktis Kombinatorika (Part 2)"
        ]
      },
      "requirements": [
        "Tidak perlu pengalaman pemrograman, karena kursus ini dimudahkan untuk para pemula"
      ],
      "description": "Data Sciencetist adalah salah satu profesi yang paling cocok untuk berkembang di era digital ini. Di Universitas program Data Science dibagi menjadi beberapa mata kuliah terpisah dan sebagian besar kursus online berfokus pada topik tertentu. Tetapi pada kursus ini, data science sudah di bagi menjadi beberapa topik:\n\n\n• Pemahaman bidang ilmu data dan jenis analisis yang dilakukan\n• Matematika\n• Statistik\n• Python\n• Menerapkan teknik statistik tingkat lanjut dengan Python\n• Visualisasi data\n• Pembelajaran mesin\n• Pembelajaran Mendalam\nDalam upaya menciptakan pelatihan data scientist yang paling efektif, efisien waktu, dan terstruktur yang tersedia secara online, kami membuat Kursus Data Science ini.\nApa yang akan Anda pelajari:\n• Kursus ini menyediakan seluruh kotak peralatan yang Anda butuhkan untuk menjadi ilmuwan data\n• Isi resume Anda dengan keterampilan ilmu data yang dibutuhkan: Analisis statistik, pemrograman Python dengan NumPy, panda, matplotlib, dan Seaborn, Analisis statistik lanjutan, Tableau, Pembelajaran Mesin dengan model statistik dan scikit-learn, Pembelajaran mendalam dengan TensorFlow\n• Buat pewawancara terkesan dengan menunjukkan pemahaman tentang bidang ilmu data\n• Pelajari cara memproses data sebelumnya\n• Pahami matematika di balik Pembelajaran Mesin (suatu keharusan mutlak yang tidak diajarkan oleh kursus lain!)\n• Mulai coding dengan Python dan pelajari cara menggunakannya untuk analisis statistik\n• Lakukan regresi linier dan logistik dengan Python\n• Lakukan analisis klaster dan faktor\n• Mampu membuat algoritma Machine Learning dengan Python, menggunakan NumPy, statsmodels dan scikit-learn\n• Terapkan keahlian Anda ke kasus bisnis kehidupan nyata\n• Gunakan kerangka kerja Deep Learning yang canggih seperti Google's TensorFlowMengembangkan intuisi bisnis sambil membuat kode dan menyelesaikan tugas dengan data besar\n• Terungkap kekuatan jaringan saraf yang dalam\n• Tingkatkan algoritme Pembelajaran Mesin dengan mempelajari underfitting, overfitting, pelatihan, validasi, validasi silang n-fold, pengujian, dan bagaimana hyperparameter dapat meningkatkan kinerja\n• Hangatkan jari Anda karena Anda akan bersemangat untuk menerapkan semua yang telah Anda pelajari di sini ke lebih banyak situasi kehidupan nyata\nApakah ada persyaratan atau prasyarat kursus:\n• Tidak diperlukan pengalaman sebelumnya. Kita akan mulai dari yang paling dasar\n• Anda harus menginstal Anaconda. Kami akan menunjukkan cara melakukannya langkah demi langkah\n• Microsoft Excel 2003, 2010, 2013, 2016, atau 365\nUntuk siapa kursus ini:\n• Anda harus mengikuti kursus ini jika Anda ingin menjadi Data Science atau jika Anda ingin mempelajari bidang ini\n• Kursus ini cocok untuk Anda jika Anda menginginkan karier yang hebat\n• Kursus ini juga ideal untuk pemula, karena dimulai dari dasar dan secara bertahap meningkatkan keterampilan Anda",
      "target_audience": [
        "Kursus ini sangat cocok bagi Anda yang ingin mengetahui lebih dalam mengenai Data Science"
      ]
    },
    {
      "title": "ChatGPT - Le guide pour débuter",
      "url": "https://www.udemy.com/course/chatgpt-guide-debutants/",
      "bio": "Commencez à utiliser ChatGPT aujourd'hui - Apprenez à maîtriser chat GPT maintenant, avant qu'il ne contrôle le monde",
      "objectives": [
        "Comment utiliser ChatGPT pour créer des contenus SEO, des sites e-commerce, des traductions, pour la rédaction de textes de vente ou améliorer votre entreprise!",
        "Découvrez les méthodes pour utiliser ChatGPT pour créer des contenus YouTube personnalisés et captivants !",
        "Apprenez les techniques pour évaluer et améliorer la qualité du texte généré par ChatGPT .",
        "Découvrez comment créer un podcast en quelques minutes en utilisant les fonctionnalités d'écriture de scénario de ChatGPT.",
        "Apprenez à créer des images en utilisant Dalle et à créer des codes et des applications en utilisant l'API ouverte d'OpenAI .",
        "Comment utiliser ChatGPT pour automatiser votre charge de travail et vos tâches quotidiennes .",
        "Comment construire un site web et créer du contenu de page web pour ChatGPT ."
      ],
      "course_content": {
        "Comment Utiliser ChatGPT": [
          "Pourquoi vous avez besoin d'apprendre à utiliser ChatGPT",
          "Comment démarrer rapidement avec ChatGPT",
          "Problèmes et informations erronées à connaître lors de l'utilisation de ChatGPT",
          "La version payante de ChatGPT se déploie plus largement…"
        ],
        "ChatGPT une aide pour chaque domaine": [
          "Glycémie et diabète avec chatGPT",
          "Stress, méditation et pleine conscience avec ChatGPT",
          "Automatisation dans les soins de santé",
          "Débogage de code avec ChatGPT"
        ],
        "Méthodes d'utilisation avancées de ChatGPT": [
          "Générer des réponses aux e-mails à l'aide de ChatGPT",
          "Créer des extensions Google Chrome sans codage"
        ],
        "Utilisation de ChatGPT pour les étudiants et autres": [
          "Traduction avec ChatGPT",
          "Résumer un roman en 500 mots avec ChatGPT",
          "Recherche historique avec ChatGPT",
          "Rédigez une lettre de motivation pour un emploi avec ChatGPT",
          "Entretien d'embauche avec l'aide de ChatGPT",
          "Idées de carrière et d'emploi avec ChatGPT"
        ],
        "Conclusion": [
          "L'avenir de ChatGPT",
          "Félicitations, vous avez terminé ce cours ChatGPT pour débutant"
        ]
      },
      "requirements": [
        "Aucune compétence requise ! Il vous suffit d'avoir la volonté d'apprendre et le désir de profiter de la technologie incroyable de l'intelligence artificielle",
        "Une connexion à internet mais vous l'avez déjà si vous lisez ceci !"
      ],
      "description": "Ce cours est destiné aux débutants, si vous êtes développeur ou ingénieur logiciel, il pourrait être trop basique pour vous.\nÊtes-vous intéressé(e) à apprendre à utiliser ChatGPT, le puissant modèle de langage développé par OpenAI ? Notre cours en ligne est l'endroit idéal pour commencer !\n\n\nDans ce cours, vous apprendrez à mettre en pratique ChatGPT à travers des exemples concrets, en acquérant une expérience pratique avec cet outil AI polyvalent. Avec ChatGPT, vous pouvez en apprendre sur une grande variété de sujets, tels que la science, l'histoire, la littérature, et plus encore. Vous pouvez également améliorer votre vocabulaire et vos compétences en langue, obtenir des explications et des définitions de concepts complexes, rester informé(e) des événements actuels et de l'actualité, et même recevoir des conseils et des orientations sur le développement personnel et professionnel.\n\n\nChatGPT est une variante de GPT-3, et il est connu pour sa capacité à engager des conversations en langage naturel avec les humains. Cela le rend idéal pour les applications de chatbot, où il peut générer des réponses qui ont l'air naturelles et humaines. Il est également capable de gérer une grande variété de sujets, grâce à sa formation sur un jeu de données diversifié, ce qui le rend utile pour des tâches telles que la génération de contenu.\n\n\nN'oubliez pas de saisir cette opportunité d'en apprendre davantage sur ChatGPT et son potentiel pour révolutionner le traitement et la génération de la langue naturelle. Inscrivez-vous à notre cours dès maintenant !\n\n\nCe cours vous permettra d'acquérir des connaissances générales et des faits sur une grande variété de sujets, y compris la science, l'histoire, la littérature, et plus encore.\nVous apprendrez également l'utilisation du vocabulaire et de la langue, y compris les définitions des mots et des phrases, et des conseils pour une communication efficace.\nDes explications et des définitions de concepts et d'idées complexes vous seront données.\nVous serez informé(e) des événements actuels et de l'actualité.\nDes conseils et des orientations sur divers sujets, y compris le développement personnel et professionnel vous seront fournis.\nEn résumé, mon objectif est d'être une source d'informations et de soutien fiable et utile pour les personnes qui cherchent à apprendre et à élargir leurs connaissances.\nChatGPT est une variante du modèle de langage GPT-3 (Generative Pretrained Transformer 3) développé par OpenAI. Comme d'autres versions de GPT, ChatGPT est conçu pour générer un texte similaire à celui des humains en fonction d'un prompt ou d'un contexte donné.\nL'une des principales caractéristiques de ChatGPT est sa capacité à engager des conversations en langage naturel avec les humains. Cela le rend particulièrement utile pour des tâches comme les chatbots, où le modèle peut générer des réponses aux demandes des utilisateurs de manière naturelle et semblable à celle des humains.\nUn autre avantage de ChatGPT est sa capacité à gérer une grande variété de sujets et de domaines. Comme il a été entraîné sur un grand jeu de données diversifié, ChatGPT peut générer du texte sur une variété de sujets avec une qualité relativement élevée. Cela le rend utile pour des applications comme la génération de contenu, où le modèle peut être utilisé pour générer des articles ou d'autres contenus écrits sur un sujet donné.\nEn somme, ChatGPT est un outil important pour les tâches de traitement et de génération de la langue naturelle, et il a le potentiel de révolutionner la façon dont nous interagissons avec les chatbots et les autres systèmes alimentés par l'IA qui reposent sur la communication en langage naturel. -Créé et fourni par ChatGPT\nAvertissement : Nous ne possédons pas ChatGPT.",
      "target_audience": [
        "Toute personne souhaitant apprendre",
        "Toute personne intéressé par les nouvelles technologies",
        "Managers",
        "Experts en la matière et non développeurs ou ingénieur logiciel"
      ]
    },
    {
      "title": "통계 분석 마스터 클래스 : 확률과 추론",
      "url": "https://www.udemy.com/course/maso-ds-excel-onc49-1/",
      "bio": "데이터 분석의 가장 기초가 되는 통계분석 마스터 과정!",
      "objectives": [
        "확률과 추론을 통해 미래의 데이터를 예측할 수 있는 역량",
        "수집한 데이터를 읽고 요약하는 기술통계 및 시각화 역량",
        "가설 검정과 유의성 검정을 통해 올바른 의사결정을 돕는 역량",
        "현실의 비즈니스 문제(Business Question)를 해결하는 최적의 방법을 찾아내는 역량"
      ],
      "course_content": {
        "00 학습 목표 및 수강 안내": [
          "PST1001 – 통계분석 마스터 클래스 배울 내용 소개",
          "PST1002 – 수업 수강 환경 안내"
        ],
        "01 직관적 의사결정 vs 데이터 기반 의사결정": [
          "PST1101 – 직관적 의사결정과 데이터 기반 의사결정",
          "PST1102 – 데이터 사이언티스트 필요 역량",
          "PST1103 – 통계적 의사결정 모형"
        ],
        "02 데이터와 척도의 종류": [
          "PST1201 – 데이터의 유형과 측정 기준",
          "PST1202 – 정형 데이터",
          "PST1203 – DIKW 피라미드 데이터 기반 비즈니스 전략 수립"
        ],
        "03 데이터 확보": [
          "PST1301 – 1차 자료와 2차 자료",
          "PST1302 – 2차 자료 확보"
        ],
        "04 데이터 요약의 의미": [
          "PST1401 – 기술 통계의 필요성",
          "PST1402 – 통계량 – 데이터를 값으로 요약하기",
          "PST1403 – 차트 – 데이터를 그림으로 요약하기"
        ],
        "05 연속형(양적) 데이터 요약": [
          "PST1501 – 히스토그램",
          "PST1502 – 중심 경향치",
          "PST1503 – 산포도",
          "PST1504 – 평균과 표준편차의 해석",
          "PST1505 – 산점도",
          "PST1506 – 상관관계와 상관계수",
          "PST1507 – 상자수염 그림",
          "PST1508 – 히트맵"
        ],
        "06 범주형(질적) 데이터 요약": [
          "PST1601 – 도수분포표",
          "PST1602 – 파이 차트",
          "PST1603 – 트리맵"
        ],
        "07 모집단 추정": [
          "PST1701 – 모집단 추정",
          "PST1702 – 모수와 추정량",
          "PST1703 – 점 추정과 구간 추정",
          "PST1704 – 구간 추정 핵심 개념",
          "PST1705 – 신뢰수준과 신뢰구간"
        ],
        "08 확률": [
          "PST1801 – 확률의 정의"
        ],
        "09 확률 변수와 확률 분포": [
          "PST1901 – 동전 던지기 확률 나무",
          "PST1902 – 확률 변수",
          "PST1903 – 확률 분포",
          "PST1904 – 확률 법칙",
          "PST1905 – 데이터 부트스트랩",
          "PST1906 – 대수의 법칙"
        ]
      },
      "requirements": [
        "실습 위주의 강의이기 때문에 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기를 함께 준비해주시면 좋습니다.",
        "또한 Windows OS 기반으로 실습이 진행되므로, Windows 환경에서의 강의 수강을 추천해드립니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n통계, 왜 배워야 할까요?\n무엇이든지 기본기가 잡혀 있으면 두려움과 걱정은 없어지기 마련입니다.\n이제는 꼭 필요한 데이터 분석!\n바로 데이터 분석의 기본기는 ‘통계 지식’에서 시작합니다.\n통계를 배우면, 실생활에 유용합니다.\n우리의 일상이 통계에 묻혀 있다는 사실, 알고 계셨나요? 통계를 통해 우리 일상에서 발생하는 이슈에 답을 찾아볼 수 있을 겁니다!\n통계를 배우면, 합리적인 사고가 가능합니다.\n수치를 단순히 숫자로만 바라보는 것이 아닌, 그 이면의 의미에 집중하는 방법을 알게 됩니다.\n통계를 배우면, 진짜와 가짜를 구별할 수 있습니다.\n동일한 이슈를 다루는 기사인데도 왜 스탠스가 다를까요?\n이제 통계치를 스스로 직접! 해석하여 진짜 기사를 발견해낼 수 있습니다.\n통계를 배우면, 데이터 기반의 판단이 가능합니다.\nB회사의 한 달 매출이 3,000만 원이라고 합니다.\n과연, 3,000만 원이 좋은 성과일까요?\n여러분은 이 물음에 통계를 활용해 그 답을 내릴 수 있습니다.\n‘10% 담뱃값 인상이 청소년층의 흡연을 어느 정도 줄일 수 있을까?’\n‘직업 훈련은 재취업률을 얼마나 높이는가?’\n‘외국인 직접 투자가 늘면 경제 성장률이 제고되는가?’\n위 질문에 정확히 답하기 위해선 “통계”가 필요합니다!\n그러나,\n막상 시작해보려면 너무 막막한 통계! 고등학교만 졸업하면 통계와는 이별일 줄 알았는데…\n“통계분석 마스터 클래스”로 현실에 바로 적용하는 통계를 배워\n우리 삶 속에 숨겨진 통계적 원리를 발견해보세요!\n\n\n<통계분석 마스터 클래스 : 확률과 추론> 강의를 듣고 나면, 여러분은 다음과 같은 역량을 확보할 수 있습니다.\n수집한 데이터를 읽고 요약하는 기술통계 및 시각화 역량\n확률과 추론을 통해 미래의 데이터를 예측할 수 있는 역량\n가설 검정과 유의성 검정을 통해 올바른 의사결정을 돕는 역량\n현실의 비즈니스 문제(Business Question)를 해결하는 최적의 방법을 찾아내는 역량\n\n“통계분석 마스터 클래스: 확률과 추론” 강의를 듣고, 여러분의 의사결정에 날개를 달아보세요!\n\n\n[ 강 사 소 개 ]\n김 진\n現 마소캠퍼스 대표\n서울대학교 MBA 졸업\n오라클, 네이버를 거쳐 중국 네이버 개발 아웃소싱 센터를 설립 및 지휘하였으며, 서울대 MBA 졸업 후 글로벌 모바일 기업인 Obigo로 옮겨 데이터 분석에 기반한 성과 관리 시스템 도입 등 국내외 다양한 사업 영역을 개척하였습니다. 2010년에는 게임웹진 플레이포럼 M&A 후 데이터 분석과 디지털 마케팅을 실무에 본격 도입해 코리안클릭 수치 기준으로 월 평균 활성유저(MAU) 238만, 월 평균 페이지뷰(PV)수 1,700만을 달성하였습니다. 개발자, 전문 경영인의 길을 걸어온 사업가로서 폭넓은 경험과 IT 기술을 융합해 현재는 기업의 ROI를 높여줄 실무 전문가 교육에 힘 쓰고 있습니다.\n\n\n최 정 아\n現 마소캠퍼스 콘텐츠랩 이사\n연세대학교 경영학 석사\nYSCEC의 웹마스터로서 연세-게이오(日)-릿쿄(日)-푸단(中) 대학의 YKLP 사업에 초기부터 합류해 성공적으로 론칭시킨 국제 원격교육 전문가입니다. 이후 플레이포럼 편집장으로 자리를 옮겨 MAU 238만 명의 커뮤니티를 7년간 운영하면서 최대 900만 뷰를 달성한 디지털 콘텐츠를 제작했습니다. 언어학, 정보학, 경영학 학위를 소지한 다재다능한 디지털마케팅 전문가로서 데이터를 활용해 디지털 플랫폼에서 최고의 퍼포먼스를 이뤄냈습니다. 효과적인 데이터 마케팅 방법을 다룬 도서를 다수 출간하여 모두 경제경영 분야 베스트셀러에 오른 검증된 지식을 공유하고 있습니다.",
      "target_audience": [
        "수학이 무서워 통계에 장벽을 느끼셨던 분",
        "데이터 분석 프로젝트 기획력을 함양하고 싶은 분",
        "실습으로 통계를 한 번에, 제대로 이해하고 싶은 비전공자",
        "실무에 통계 분석을 바로 적용하여 인사이트를 찾고 싶은 분",
        "비즈니스 애널리틱스 역량을 함양하여 데이터 사이언스와 경영 의사결정을 결합하고 싶은 분"
      ]
    },
    {
      "title": "R로 배우는 데이터 분석 첫 걸음",
      "url": "https://www.udemy.com/course/maso-ds-r-onc2006/",
      "bio": "기초 문법부터 데이터 마이닝 실습까지",
      "objectives": [
        "R의 기초부터 데이터에서 인사이트를 얻을 수 있는 통계 기법까지 학습",
        "비전공자도 이해할 수 있도록 쉽게 설명",
        "다양한 예제와 실습을 기반으로 다양한 데이터셋을 분석하고 결과 해석",
        "모든 예제에 제공되는 코드로 반복 연습이 가능"
      ],
      "course_content": {},
      "requirements": [
        "실습 위주의 강의이기 때문에, 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 사용 또는 여분 기기 활용을 권장 드립니다.",
        "강의는 Windows OS 기반으로 실습이 진행되므로 실습 환경 체크시 참고 부탁드립니다.",
        "R에 대한 지식이 있으면 도움이 되나, 필수 사항은 아닙니다.",
        "데이터 분석에 대한 사전 지식은 필요 없습니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n\n\nMLB나 KBO 프로야구 타자들의 데이터와 같이 디테일하고 엄청난 양의 데이터셋을 다양한 목적과 의사결정을 위해 분석하고자 할 때,\n과연 엑셀만으로 충분할까요?\n엑셀은 빠르고 간편하게 데이터를 분석할 수 있는 훌륭한 장점이 있지만,\n데이터 처리 용량과 타 시스템과의 연계성 관점에서는 살짝 아쉬운 점이 있습니다.\n\n\n하지만 R을 활용한다면 어떨까요? R은 다음과 같은 특징을 가지고 있습니다.\n오픈소스 언어로 누구나 무료로 활용\n다양한 운영체제에서 구현 가능\n많은 프로그램과 연계가 가능\n다양한 패키지 다운 및 활용 가능\n데이터 시각화 가능\n따라서, R을 활용한다면 엑셀의 한계를 극복하고, 통계 함수 이용과 데이터 시각화를 보다 손쉽게 할 수 있습니다.\n\n\nR은 통계적인 계산, 데이터 분석, 데이터를 그래프로 시각화하는데 사용되는 프로그래밍 언어로, 다양한 패키지(함수들의 집합)를 제공하여\n간단하지만 자세한 데이터 분석을 가능케 합니다.\nR은 통계 분석을 시작으로, 현재는 머신러닝과 데이터 시각화 분야까지 다루는 기본 분석 도구로 자리잡았습니다.\n\n\n또한, R은 가장 쉬운 프로그래밍 언어이지만, 프로그래밍 언어를 처음 시작하는 분이라면 '내가 코드를 작성할 수 있을까?'하는 걱정이 앞서실겁니다.\n하지만 R의 기본적인  몇 가지 문법을 잘 활용할 수 있다면, 코딩을 처음 배우는 수강생도 복잡한 코드 작성 없이 쉽게 데이터 분석을 할 수 있습니다.\n\n\n본 과정에서는 프로그래밍을 처음 배우시는 분들도 데이터 분석이 필요한 현업에서 필요한 R 활용 역량을 확보하실 수 있습니다.\n기초적이지만 놓치기 쉬운 R의 기초문법과 데이터 구조 개념을 이해하고\n기초 통계 지식을 습득하여 평소 통계가 낯설거나 통계에 자신 없던 분들도 통계 지식의 이론적 기반을 다질 수 있습니다.\n또한, 다양한 예제와 실습을 기반으로 직접 코드를 작성하여 다양한 데이터셋을 분석하고 결과를 해석하며\n현업에서 바로 적용 가능한 데이터 분석 역량을 기를 수 있습니다.\n\n\n-\n\n\n[ 강 사  소 개 ]\n\n\n김 진 숙\n現 마소캠퍼스 수석 교수\n롯데인재개발원, 하나은행, 현대커머셜 등 다수 기업 및 기관 강의\n홍익대, 아주대, 가천대, 성결대 등 다수 대학 강의\n김진숙 교수는 마소캠퍼스에서 빅데이터 부분 수석 교수로 빅데이터(R, 파이썬), HTML5/CSS3, JQueryMobile, 스크래치, 앱인벤터, IoT 등의 최신 IT 관련 기술 과정들까지 다양한 기업과 기관의 수강생들을 대상으로 열정 넘치는 강의를 이어가고 있습니다. 김진숙 교수는 스마트팜 IoT 프로젝트, 카 셰어링 앱 프로젝트 등 다수 프로젝트 지도 경력까지 겸비한 전문가입니다.",
      "target_audience": [
        "데이터 분석에 관심은 있지만 어떻게 시작해야 할 지 모르는 분들",
        "기초 통계 지식을 단기간에 쉽게 습득하고 싶은 분들",
        "방대한 양의 데이터를 빠르게 처리하고 시각화하고 싶은 분들",
        "정보를 보기 좋게 전달할 수 있는 보고서를 작성하고 프레젠테이션에 사용하고 싶은 분들"
      ]
    },
    {
      "title": "Statistica per Data Analyst e sviluppatori",
      "url": "https://www.udemy.com/course/corso-statistica-per-data-analyst-e-sviluppatori/",
      "bio": "Acquisisci competenze statistiche essenziali per l'analisi dei dati e la programmazione con Excel, SQL e Python",
      "objectives": [
        "Comprendere l'importanza di classificare correttamente le variabili statistiche",
        "Conoscere e capire quando utilizzare i principali indici di statistica univariata",
        "Analizzare il grado di associazione tra più variabili",
        "Utilizzare Excel, SQL e Python per calcolare i più importanti indici statistici",
        "Rappresentare efficacemente i dati e condurre un'analisi esplorativa con le librerie di Python Pandas e Seaborn",
        "Comprendere i concetti principali della statistica inferenziale",
        "Utilizzare Python per calcolare intervalli di fiducia",
        "Eseguire i principali test statistici"
      ],
      "course_content": {
        "Introduzione": [
          "Introduzione",
          "Classificazione variabili"
        ],
        "Statistica descrittiva univariata (univariate statistics)": [
          "Indici di posizione centrale",
          "Indici di variabilità",
          "Outlier e coefficiente di variazione",
          "Altra formulazione per il calcolo della varianza",
          "Grafici per la statistica monovariata",
          "Calcolo degli indici con Excel",
          "Grafici con Excel",
          "Installazione SQL Server Express",
          "Calcolo degli indici con SQL",
          "Installazione Python e librerie",
          "Calcolo degli indici con Python",
          "Scaling di una variabile",
          "Indici di forma per una variabile",
          "Scaling e indici di forma con SQL",
          "Scaling e indici di forma con Python",
          "Variabilità per variabili qualitative: indice di eterogeneità di Gini",
          "Indice di eterogeneità di Gini con SQL e Python"
        ],
        "Statistica descrittiva bivariata (bivariate statistics)": [
          "Relazione tra due variabili qualitative: indici Chi quadrato e V di Cramer",
          "Indici Chi quadrato e V di Cramer con SQL",
          "Indici Chi quadrato e V di Cramer con Python",
          "Relazione tra una variabili qualitativa e una quantitativa: indice Eta quadro",
          "Indice Eta quadro con SQL",
          "Indice Eta quadro con Python",
          "Relazione tra due variabili quantitative: covarianza",
          "Regressione e coefficiente di Pearson",
          "Grafici per statistica bivariata: diagramma di dispersione",
          "Coefficiente di Spearman",
          "Covarianza, coefficiente di Pearson e regressione con SQL",
          "Covarianza, coefficiente di Pearson e regressione con Python"
        ],
        "Analisi esplorativa con Python": [
          "Analisi esplorativa dei dati - calcolo dei principali indici statistici",
          "Analisi esplorativa - rappresentazioni grafiche con Seaborn"
        ],
        "Previsione di serie storiche": [
          "Introduzione alle serie storiche",
          "Funzionalità foglio previsione di Excel",
          "Modello matematica per la previsione di una serie storica - parte 1",
          "Modello matematico per la previsione di una serie storica - parte 2"
        ],
        "Statistica inferenziale (inferential statistics)": [
          "Introduzione alla statistica inferenziale",
          "Stime puntuali",
          "Distribuzione normale e test di Shapiro",
          "Intervallo di fiducia per la media di una popolazione normale con Python",
          "Approfondimento sugli intervalli di fiducia e confronto tra distribuzioni t e z",
          "Intervallo di fiducia per varianza e deviazione standard",
          "Test sulla media di una popolazione normale con Python",
          "T test per la media di due campioni indipendenti",
          "T test per la media di due campioni dipendenti",
          "Congratulazioni finali e anteprima gratuita della Scuola dei Dati"
        ]
      },
      "requirements": [
        "Per la parte di statistica non serve nessun prerequisito particolare in quanto tutti i concetti saranno spiegati assolutamente da zero. Per seguire anche gli esempi su Excel, SQL Server e Python serve avere già un po' di dimestichezza con questi strumenti/linguaggi"
      ],
      "description": "Conoscere la statistica è un upgrade fondamentale per chiunque lavori nell'ambito dell'analisi dei dati e più in generale nella programmazione. Il corso nasce per darti una formazione pratica e diretta sui temi principali della statistica, a partire dalla mia esperienza prima come studente di matematica all'università, e poi come programmatore in SQL e Python.\n\n\nPartiremo assolutamente da zero, imparando a classificare le variabili, calcolare i principali indici di statistica univariata e bivariata, fino a studiare i temi principali della statistica inferenziale come le stime puntuali, intervallari e i test statistici.\n\n\nIl corso è ricco di implementazioni statistiche in Excel, SQL (nella versione T-SQL del database SQL Server) e Python. Ho scelto questi tre strumenti/linguaggi perché sono i più utilizzati in ambito aziendale, essendo il corso pensato soprattutto per chi proviene da un background informatico, per quanto penso che possa essere apprezzato da chiunque sia interessato alla statistica.\n\n\nII corso non è pensato per insegnarti da zero SQL e Python, ma per farti vedere come è possibile utilizzarli praticamente per automatizzare e applicare a grandi moli di dati i calcoli statistici che impareremo a fare prima manualmente e su Excel. D'altra parte non è indispensabile avere conoscenza di SQL e Python per seguire il corso, per quanto una loro conoscenza permetterebbe di apprezzare meglio le parti relative a questi linguaggi. Ho riportato comunque per completezza anche delle videolezioni per procedere con l'installazione di SQL Server e Python su un proprio PC personale con sistema operativo Windows.\n\n\nAggiornamento: ho aggiunto una nuova sezione dedicata alla previsione di serie storiche con Excel, sia con la nuova funzionalità Foglio Previsioni di Excel 365 e sia tramite l'implementazione step by step di un modello matematico previsionale.\n\n\nTutte le videolezioni sono corredate anche dai file contenenti gli esercizi visti durante le spiegazioni. Nel complesso, si tratta a tutti gli effetti di un manuale riepilogativo degli argomenti di statistica visti. Inoltre sarò sempre disponibile a rispondere a dubbi e domande sul materiale del corso, che potrai porre tramite i messaggi di Udemy o l'apposita sezione di Domande & Risposte.",
      "target_audience": [
        "Programmatori e sviluppatori che desiderano potenziare le proprie competenze in statistica per migliorare le capacità di analisi dei dati",
        "Data analyst che vogliono acquisire una solida base di conoscenze statistiche per supportare le loro attività di analisi e interpretazione dei dati",
        "Studenti interessati a integrare le loro competenze con la statistica per ampliare le opportunità professionali",
        "Professionisti che lavorano nell'ambito dell'analisi dei dati e desiderano consolidare e approfondire le loro conoscenze statistiche per migliorare la precisione e la qualità delle loro analisi"
      ]
    },
    {
      "title": "Deploy de Aplicativos Python na Google Cloud Platform",
      "url": "https://www.udemy.com/course/deploy-de-aplicativos-python-na-google-cloud-platform/",
      "bio": "Do Treinamento à Nuvem: Deploy de Modelos de Machine Learning na GCP com Python",
      "objectives": [
        "Conhecer os principais serviços da plataforma, como Google Compute Engine (GCE), App Engine (GAE), Kubernetes Engine (GKE), Cloud Run e Cloud Functions",
        "Descobrir qual é o serviço mais adequado para cada tipo de aplicação",
        "Treinar e avaliar um modelo de CNN, passando pela criação de um projeto Python local pronto para deploy",
        "Implementar seu aplicativo de machine learning em múltiplos serviços da GCP, aprendendo a configurar ambientes e gerenciar recursos",
        "Evitar custos indesejados com a limpeza adequada de recursos após o deploy"
      ],
      "course_content": {},
      "requirements": [
        "Conhecimento básico em Python e machine learning (experiência prévia com redes neurais é um diferencial)",
        "Familiaridade com conceitos de desenvolvimento web (opcional, mas recomendado)"
      ],
      "description": "Aprender a implementar modelos de machine learning em produção é uma habilidade crítica para cientistas de dados que desejam ir além da análise teórica e impactar negócios de forma prática. Enquanto a criação de modelos é essencial, é no deploy que essas soluções ganham vida, tornando-se acessíveis a usuários finais e integrando-se a sistemas reais. Dominar essa etapa permite que cientistas de dados garantam a escalabilidade de suas soluções, monitorem desempenho em ambientes dinâmicos e colaborem de forma eficiente com equipes de desenvolvimento e operações. Além disso, compreender o ciclo completo — do treinamento à disponibilização na nuvem — amplia a relevância profissional, posicionando o cientista de dados como um agente estratégico capaz de entregar valor tangível desde a concepção até a operação.\nEste curso introdutório é destinado a desenvolvedores, entusiastas de machine learning e profissionais de dados que desejam aprender a publicar suas primeiras aplicações de inteligência artificial na web utilizando a Google Cloud Platform (GCP). Com abordagem prática, você será guiado desde o treinamento de uma rede neural convolucional (CNN) para classificação de imagens até a implementação do modelo em serviços de nuvem escaláveis. O curso inclui uma introdução aos principais serviços da GCP, como Google Compute Engine (GCE), App Engine (GAE), Kubernetes Engine (GKE), Cloud Run e Cloud Functions, permitindo que você compare e escolha a melhor opção para seu projeto.\nNa primeira etapa, você preparará o ambiente localmente: importará bibliotecas (como TensorFlow/Keras), treinará e avaliará seu modelo de CNN, além de criar um aplicativo Python simples para integração com o modelo treinado. Em seguida, aprenderá a configurar a GCP e fazer deploy em diferentes serviços.\nIdeal para iniciantes em cloud computing e profissionais que desejam colocar modelos de machine learning em produção. Ao final, você terá publicado uma aplicação web funcional de classificação de imagens na nuvem, dominando o ciclo completo de desenvolvimento, desde o treinamento do modelo até a disponibilização em serviços profissionais da Google.",
      "target_audience": [
        "Iniciantes em cloud computing que querem dar os primeiros passos na GCP",
        "Cientistas de dados e desenvolvedores Python que desejam colocar modelos de machine learning em produção"
      ]
    },
    {
      "title": "Machine Learning-Ready +",
      "url": "https://www.udemy.com/course/machine-learning-ready/",
      "bio": "Dein Einstieg für eine Karriere im Bereich Data Science",
      "objectives": [
        "Du lernst alle wichtige Grundlagen des Machine Learning",
        "Du lernst alle wichtigen Grundlagen der Programmiersprache Python",
        "Du lernst, wie Du als \"Data Scientist\" Machine Learning-Modelle mit Python entwickelst",
        "Du lernst, wie Du als \"ML Engineer\" Machine Learning-Modelle mit Python für die produktive Nutzung bereitstellt und ihren Betrieb sicherstellst",
        "Du arbeitest mit einem plattformunabhängigen Tech Stack für Machine Learning",
        "Du erhältst unbegrenzten Zugriff auf alle meine Online-Kurse zum Thema Machine Learning"
      ],
      "course_content": {
        "MACHINE LEARNING 1x1": [
          "Machine Learning",
          "Lineare Regression",
          "Logistische Regression",
          "Kostenfunktion und Gradient Descent",
          "Overfitting und Regularization",
          "Multiple Choice",
          "Code Challenge: Breast Cancer Classifier I"
        ],
        "MACHINE LEARNING-ALGORITHMEN": [
          "Linear SVM",
          "Kernelized SVM",
          "Decision Tree",
          "Random Forest und Gradient Boosting",
          "k-Nearest Neighbors",
          "Multiple Choice",
          "Code Challenge: Breast Cancer Classifier II"
        ],
        "PYTHON 1x1": [
          "Jupyter Lab, Notebooks & Markdown",
          "Python Variables",
          "Python Data Types",
          "Code Challenge: Python Variables und Data Types",
          "Python Operators",
          "Code Challenge: Python Operators",
          "Python Conditional Statements",
          "Code Challenge: Python Conditional Statements",
          "Python Loops",
          "Code Challenge: Python Loops",
          "Python Functions",
          "Code Challenge: Python Functions",
          "Python Errors und Exceptions",
          "Code Challenge: Python Errors und Exceptions"
        ]
      },
      "requirements": [
        "Keine Vorkenntnisse notwendig.",
        "Gute Mathematikkenntnisse und erste Programmiererfahrung von Vorteil."
      ],
      "description": "Herzlich willkommen in meinem Kurs:\nMACHINE LEARNING-READY +\n\n\nMit diesem Kurs erhältst Du unbegrenzten Zugriff auf alle meine Online-Kurse zum Thema Machine Learning - sowohl auf die bereits veröffentlichten als auch auf alle Kurse, die ich zukünftig noch veröffentlichen werde.\n\n\nIn meinen Kursen lernst Du alles über Machine Learning, was Du für eine erfolgreiche Karriere als Data Scientist brauchst - von den theoretischen Grundlagen des Machine Learning und den wichtigsten Machine Learning-Algorithmen aus der Data Science-Praxis bis zur praktischen Implementierung produktionsreifer Machine Learning-Anwendungen sowie deren Betrieb und Weiterentwicklung im Rahmen von MLOps.\n\n\nDas Tech Stack, mit dem Du in diesem Kurs arbeiten wirst, umfasst zahlreiche Tools aus der Data Science-Praxis wie z.B. (Jupyter) Notebooks, VS Code und GitHub. Alle Code-Beispiele und Programmierübungen sind in Python programmiert. Wir arbeiten mit einschlägigen Python Libraries wie z.B. Pandas, NumPy, Matplotlib, Scikit-learn und XGBoost.\n\n\nAlle Materialien, die wir im Kurs verwenden (Power Point Slides, Python Notebooks, usw.), stehen Dir zeitlich unbegrenzt auch zum Download zur Verfügung. Wenn Du Inhalte aus diesem Kurs für eigene Präsentationen / Veröffentlichungen verwenden möchtest, freue ich mich darüber - bitte Dich aber gleichzeitig darum, auf mich als Urheber zu referenzieren.\n\n\nFalls Du während des Kurses Fragen oder Anmerkungen hast, kannst Du mich jederzeit gerne kontaktieren - ich freue mich über Deine Nachricht und Dein Feedback.\n\n\nSollte Dir dieser Kurs gefallen, freue ich mich über eine Bewertung von Dir auf Udemy und Deine Weiterempfehlung im Bekanntenkreis und auf Social Media. Damit würdest Du mir bei meiner Mission, möglichst vielen Menschen im deutschsprachigen Raum den Berufseinstieg im Bereich Machine Learning zu ermöglichen, sehr helfen.\n\n\nFolge mir auch gerne auf LinkedIn und YouTube oder besuche mich auf meiner Website (machine-learning-ready). Dort hast Du auch die Möglichkeit, Dich für meinen kostenlosen Newsletter anzumelden und von besonderen Angeboten zu profitieren.\n\n\nViel Spaß beim Lernen!",
      "target_audience": [
        "Alle, die eine Karriere im Bereich im Bereich Data Science anstreben.",
        "z.B. als Data Scientist, ML Engineer oder Data Science Manager"
      ]
    },
    {
      "title": "IIBA® ECBA® Exam Prep 2025: Complete Certification Course",
      "url": "https://www.udemy.com/course/iiba-ecba-exam-prep-2025-complete-certification-course/",
      "bio": "دورة التحضير لشهادة ECBA لعام 2025: برنامج شامل\"",
      "objectives": [
        "Define and describe core business analysis concepts and domains",
        "Apply foundational techniques in elicitation, requirements management, and stakeholder engagement",
        "Understand the strategic importance of value, context, and stakeholders in business analysis",
        "Interpret and respond to situational multiple-choice exam questions",
        "Confidently sit for the ECBA exam and join the IIBA professional community"
      ],
      "course_content": {
        "Course Introduction2025": [
          "Course Introduction",
          "ECBA Study Plan New 2025",
          "0-Business Analysis introduction",
          "BA Introduction"
        ],
        "Domain 1. Understanding Business Analysis (20%)": [
          "Domain 1 Part One",
          "Domain 1 - Part two",
          "Domain 1-Part Three",
          "Understanding Business Analysis"
        ],
        "Domain 2. Mindset for Effective Business Analysis (14%)": [
          "Domain 2 Part one",
          "Domain 2 Part 2",
          "Mindset for Effective Business Analysis"
        ],
        "Domain 3. Implementing Business Analysis (6%)": [
          "Domain 3 Part one",
          "Domain 3 Part two",
          "Domain 3 Part 3 foundation techniques",
          "Domain 3 Part 4 Requirements and design",
          "Implementing Business Analysis"
        ],
        "Domain 4-Change (10%)": [
          "1-Business analysis overview",
          "2-Analyze Current State",
          "3-Assess Enterprise Limitations",
          "4-Plan Business Analysis Governance",
          "5-Plan Business Analysis Information Management",
          "6-Assess Requirements Changes",
          "7-Prepare for Elicitation",
          "8-Trace Requirements",
          "9-Define Future State",
          "Change"
        ],
        "Domain 5- Need 10%": [
          "1 - Confirm Elicitation Results.",
          "2- Specify and Model Requirements.",
          "3- Prioritize Requirements.",
          "5. Need"
        ],
        "Domain 6 - Solution (10%)": [
          "1- Verify Requirements",
          "2- Validate Requirements",
          "3-Conduct Elicitation",
          "4-Assess Risks",
          "5- Define Requirements Architecture",
          "6-Measure solution performance",
          "7- Assess Solution Limitations.",
          "Solution"
        ],
        "Domain 7. Stakeholder (10%)": [
          "1- Plan Stakeholder Engagement.",
          "3-Domain 7 Part 2",
          "3- Manage Stakeholder Collaboration.",
          "Stakeholders"
        ],
        "Domain 8 - Value (10%)": [
          "1- Define Change Strategy.",
          "2- Analyze Performance Measures.",
          "3- Approve Requirements.",
          "4-Identify BA Performance improvement 1",
          "4- Identify Business Analysis Performance Improvements2",
          "Value"
        ],
        "Domain 9. Context (10%)": [
          "1- Maintain Requirements",
          "2- Communicate BA Information.",
          "Context"
        ]
      },
      "requirements": [
        "No requirements or prerequisites for taking your course"
      ],
      "description": "ملخص عام على الدورة :\n1- دورة متكاملة تغطي جميع المجالات التسعة (Domains) وفقًا للتحديث الجديد لاختبار ECBA 2025.\n2- شرح تفصيلي لأهم التقنيات (Techniques) المستخدمة في تحليل الأعمال.\n3- تغطية شاملة لمهارات الكفاءات (Competencies) الضرورية للمحلل.\n4-أمثلة واقعية لتعزيز الفهم.\n5-ما يصل إلى 30 سؤالًا تدريبياً لكل دومين مع اختبارات تقييمية.\n6-امتحان تجريبي كامل في نهاية الدورة لقياس الاستعداد.\n7-الحصول على شهادة إتمام الدورة من منصة Udemy يمكنكم إضافتها إلى السيرة الذاتية.\n8-الوصول مدى الحياة إلى المحاضرات والمحتوى التدريبي.\n9-متابعة لمدة 6 شهور بعد الاشتراك عبر التواصل المباشر معنا على الواتساب.\n10الحصول على خصم مميز عند التسجيل في الدورة.\n7-يتوفر كذلك كورس آخر متخصص على منصة Udemy للتدريب المكثف على نمط أسئلة الاختبار الدولي.2025 ECBA Simualtion Exams\n\n\n1. Course Introduction\nThe ECBA Certification Preparation Program is designed to equip aspiring business analysis professionals with essential, job-ready competencies. This course introduces foundational concepts, practices, and tools of business analysis aligned with the IIBA’s latest global standards. Learners will explore both theoretical frameworks and practical scenarios, preparing them to pass the updated ECBA certification exam and confidently enter the field.\n2. Course Objectives\nBy the end of this course, participants will be able to:\n· Understand and apply the Business Analysis Core Concept Model (BACCM)\n·  Recognize and demonstrate the mindset for effective business analysis\n·  Identify business needs, define solutions, and evaluate value\n· Apply techniques across the business analysis lifecycle\n·  Prepare thoroughly for the updated ECBA exam\n3. Course Learning Outcomes\nUpon successful completion, participants will be able to:\n· Define and describe core business analysis concepts and domains\n· Apply foundational techniques in elicitation, requirements management, and stakeholder engagement\n· Understand the strategic importance of value, context, and stakeholders in business analysis\n· Interpret and respond to situational multiple-choice exam questions\n·  Confidently sit for the ECBA exam and join the IIBA professional community\n4. Course Elements and Structure\nThe course is structured around the nine domains of the ECBA 2025 Exam Blueprint:\n1. Understanding Business Analysis (20%)\nCovers the purpose, value, and application of business analysis, including definitions, key activities, and the Business Analysis Core Concept Model (BACCM). This domain establishes foundational knowledge essential for all other topics.\n2. Mindset for Effective Business Analysis (14%)\nFocuses on behaviors, attitudes, and principles that support effective analysis. Includes collaborative mindset, ethics, adaptability, and continuous improvement.\n3. Implementing Business Analysis (6%)\nProvides an overview of how to conduct business analysis using various approaches (predictive, adaptive, hybrid), including planning, selecting techniques, and aligning practices with organizational needs.\n4. Change (10%)\nExplores how business analysis facilitates change, with emphasis on understanding impacts, transition strategies, and aligning solutions with enterprise objectives.\n5. Need (10%)\nCovers the identification and analysis of needs that justify business change, including problem definition, root cause analysis, and prioritizing opportunities.\n6. Solution (10%)\nFocuses on defining and evaluating solution options that address business needs. Includes feasibility analysis, solution scope, and validating value delivery.\n7. Stakeholder (10%)\nCovers identifying, engaging, and collaborating with stakeholders. Emphasizes communication, expectation management, and facilitating agreement.\n8. Value (10%)\nExplains how to assess and measure value throughout the initiative lifecycle. Includes value definition, metrics, KPIs, and continuous validation.\n9. Context (10%)\nAnalyzes external and internal factors influencing change and solution success. Includes environmental, organizational, and strategic considerations.\n5. Main References and Study Materials\n· The Business Analysis Standard (2022–2025) – Emphasizes practical application of business analysis and BACCM.\n·  A Guide to the Business Analysis Body of Knowledge (BABOK Guide v3) – Detailed tasks and techniques across six knowledge areas.\n·  IIBA ECBA Exam Blueprint (2025) – Exam structure, question distribution, and domain focus.\n·  ECBA Learning Outcomes and Syllabus Map – Aligns learning objectives with job-readiness competencies.\n· ECBA Sample Exam Questions – Practice materials in both standard and situation-based formats.\n6. Target Audience\nThis course is ideal for:\n· New professionals entering business analysis\n· Career changers transitioning into a BA role\n· Project coordinators or analysts without formal BA training\n· Students or graduates in business, IT, or related fields",
      "target_audience": [
        "New professionals entering business analysis",
        "Career changers transitioning into a BA role",
        "Project coordinators or analysts without formal BA training",
        "Students or graduates in business, IT, or related fields"
      ]
    },
    {
      "title": "Aprenda Python do zero para Engenheiro de Dados",
      "url": "https://www.udemy.com/course/aprenda-python-do-zero-para-engenheiro-de-dados/",
      "bio": "Curso de Python para iniciantes na area de Engenharia de Dados",
      "objectives": [
        "Aprender a usar o Python no dia a dia",
        "Aprender a trabalhar com Python em projetos de Engenharia de Dados",
        "Identificar formas de melhorar e evoluir o código",
        "Ser capaz de construir processos e regras de negócio em Python"
      ],
      "course_content": {
        "Introdução": [
          "História",
          "Sudoers - Um pouco de história",
          "Características",
          "Aplicações",
          "Introdução",
          "Um pouco mais de Introdução",
          "Instalação Jupyter Windows",
          "Instalação Jupyter Linux",
          "IDE Jupyter - Como usar",
          "Comandos e funções importantes",
          "Tipos de Dados",
          "Operadores",
          "Listas, Tuplas, Sets e Dicionários",
          "Funções",
          "Manipulações de Strings",
          "Manipulações de Strings - Parte 2",
          "Classes e Objetos",
          "Instruções Condicionais",
          "Laços de Repetição",
          "Manipulação de Arquivos",
          "Como usar as Exceções",
          "Módulos e Pacotes",
          "Introdução, manipulação e visualização de Dados no Pandas",
          "Introdução, manipulação e visualização de Dados no Pandas - Parte 2",
          "Introdução, manipulação e visualização de Dados no Pandas - Parte 3"
        ]
      },
      "requirements": [
        "Nâo é necessário nenhuma experiência, basta ter vontade de aprender."
      ],
      "description": "Transforme-se em um Mestre do Python e Engenheiro de Dados ROOT!\n\n\nNeste curso, você não só aprenderá a criar e manter código Python, mas também dominará a arte de escrever código claro e eficaz para o seu dia a dia. Projetado para iniciantes e para quem busca atualização, este curso aborda os detalhes da linguagem Python de forma rápida e acessível. Ele inclui um extenso material de apoio que expande seu conhecimento para áreas correlatas como a engenharia de dados. Todo o conteúdo é enriquecido com referências ao material original, dicas práticas e informações adicionais que farão de você um especialista em Python.\n\n\nAlém disso, você estará apto a construir pipelines de dados, garantindo que você possa suportar todas as necessidades diárias de seu trabalho. Iremos além, preparando você para corrigir, evoluir e modificar códigos já existentes, aprimorando suas habilidades de manutenção e inovação.\n\n\nPara os engenheiros de dados que estão começando a explorar o vasto universo do Big Data, este curso é o ponto de partida ideal. Ele oferece uma base sólida e conhecimentos técnicos profundos, todos alinhados com o material oficial e complementados por aulas práticas no Jupyter Notebook. Nosso foco é no aprendizado ROOT, onde você aprenderá com as ferramentas mais básicas, mas também as mais poderosas da programação.\n\n\nVenha ser ROOT na sua carreira. Venha ser SUDOERS e eleve suas habilidades a um novo nível!",
      "target_audience": [
        "Desenvolvedores Iniciantes",
        "Profisionais em início de carreira"
      ]
    },
    {
      "title": "Альтернатива Excel: работа с данными в KNIME",
      "url": "https://www.udemy.com/course/knime-instead-of-excel/",
      "bio": "Автоматизация рутинных процессов по работе с данными (например, создание отчетов) с помощью платформы KNIME.",
      "objectives": [
        "работа с данными",
        "автоматизация рутинных задач по работе с данными с помощью KNIME"
      ],
      "course_content": {
        "Введение": [
          "Введение",
          "Установка и настройка KNIME",
          "Обзор интерфейса и базовые понятия KNIME",
          "Базовые понятия KNIME"
        ],
        "Основные операции с данными": [
          "Считывание данных из файлов. Использование фильтров.",
          "Считывание данных из файлов, фильтрация данных",
          "Изменение типов данных. Работа с недостающими значениями.",
          "Изменение типов данных, работа с недостающими значениями",
          "Группировка данных",
          "Группировка данных",
          "Сохранение результатов в файл",
          "Работа с данными из нескольких источников",
          "Работа с данными из нескольких источников",
          "Работа с числами и текстом",
          "Работа с числами и текстом",
          "Узел Rule Engine для нестандартных задач. Переменные (параметры).",
          "Использование узла Rule Engine",
          "Использование циклов для автоматизации повторяющихся операций",
          "Использование метаузлов для структурирования workflow"
        ],
        "Презентуем результаты. Делимся настроенным workflow с коллегами.": [
          "Визуализация данных",
          "Визуализация данных",
          "Создание отчета для презентации Ваших результатов",
          "Создание отчета",
          "Экспорт/импорт workflow",
          "Экспорт / импорт workflow"
        ],
        "Заключительная часть": [
          "Заключение"
        ]
      },
      "requirements": [
        "любой опыт работы с данными (с помощью любого программного обеспечения) приветствуется, но не является обязательным"
      ],
      "description": "В любом современном бизнесе обработка данных занимает много времени и ресурсов. В большинстве компаний, особенно малых и средних, которые не могут себе позволить большие инвестиции в сложные ИТ решения, вроде хранилища данных и системы бизнес-аналитики, Microsoft Excel занимает доминирующую позицию в качестве инструмента для работы с данными. Будучи прекрасным инструментом для быстрого анализа не очень большого массива данных, Microsoft Excel тем не менее имеет ряд узких мест и плохо подходит для работы с большими массивами данных, а также не позволяет автоматизировать рутинные (повторяющиеся) задачи без знания VBA макросов. По моим многолетним практическим наблюдениям, многие люди тратят значительную часть своего рабочего дня на обработку данных и подготовку неких сводных отчетов в Excel, причем это одни и те же отчеты, которые нужно готовить периодически. Я считаю, что работа должна быть интересной и приносить удовольствие, а рутинные задачи этому не способствуют. Именно поэтому я решил создать курс по работе с KNIME, прекрасной (и, к тому же, бесплатной) платформой для работы с данными, которая будет делать рутинные задачи за Вас, высвободит время и позволив Вам заниматься действительно интересными и захватывающими задачами. Навыки программирования для использования KNIME не требуются! Итак, если Вам надоело каждый месяц тратить по три-четыре дня на подготовку одного и того же отчета, этот курс для Вас! После освоения KNIME Ваш опыт по работе с данными разделится на \"до\" и \"после\".",
      "target_audience": [
        "люди, тратящие много времени на работу с данными в Excel, желающие упростить свою работу, сократить время на обработку данных"
      ]
    },
    {
      "title": "HERKES İÇİN YAPAY ZEKA: GPT, GEMINI, CLAUDE ve MCP Eğitimi",
      "url": "https://www.udemy.com/course/herkes-icin-yapay-zeka-gpt-gemini-claude-ve-mcp-egitimi/",
      "bio": "Temel Yapay Zeka Eğitimi ve GPT, GEMINI, CLAUDE, MCP Araçlarının Pratik Kullanımı - 2025",
      "objectives": [
        "Yapay zekanın temellerini anlayacak ve teknik bilgi gerektirmeden günlük hayatta nasıl kullanabileceğinizi öğreneceksiniz.",
        "Makine öğrenmesi, derin öğrenme ve üretken yapay zeka kavramlarını anlayacaksınız.",
        "ANI, AGI ve ASI gibi yapay zeka türlerini ayırt etmeyi öğreneceksiniz.",
        "Büyük dil modellerinin (LLM) nasıl çalıştığını ve hangi alanlarda kullanıldığını öğreneceksiniz.",
        "ChatGPT, Claude ve Gemini gibi yapay zeka araçlarını kullanmayı öğreneceksiniz.",
        "Bu araçların sürümlerini ve farklarını karşılaştırarak bilinçli seçim yapmayı öğreneceksiniz.",
        "Yapay zeka araçlarının sınırlamalarını ve dikkat edilmesi gereken noktaları öğreneceksiniz.",
        "Etkili prompt yazmayı ve doğru komutlarla yapay zeka çıktıları almayı öğreneceksiniz.",
        "Zero-shot, few-shot, CoT gibi ileri düzey prompt tekniklerini uygulamayı öğreneceksiniz.",
        "MCP ile teknik bilgi gerekmeden yapay zeka araçlarını diğer uygulamalara bağlamayı öğreneceksiniz."
      ],
      "course_content": {
        "Giriş": [
          "Ben Kimim?",
          "Bu Kurs Kimler İçin?",
          "Kursun İçeriği",
          "Kurs Sonunda Neleri Yapabileceksiniz?"
        ],
        "YAPAY ZEKA": [
          "Yapay Zeka Nedir?",
          "Yapay Zekanın Kısa Tarihi",
          "Makine Öğrenmesi, Derin Öğrenme ve Üretken Yapay Zeka (GenAI) Kavramları",
          "Yapay Zeka Türleri: ANI, AGI, ASI Nedir?"
        ],
        "BÜYÜK DİL MODELLERİ (LLM)": [
          "LLM Nedir?",
          "LLM Nasıl Çalışır?",
          "LLM Ne Yapabilir, Ne Yapamaz?",
          "Chatbot Arena LLM Liderlik Tablosu"
        ],
        "CHATBOTLAR: Dijital Asistanlar": [
          "Chatbot Nedir?",
          "Kurs Kapsamında Kullanılacak ChatBotlara Giriş (ChatGPT, Claude, Gemini)",
          "GPT Modelleri",
          "ChatGPT Arayüzü",
          "ChatGPT Özellikleri",
          "Gemini Modelleri",
          "Gemini & Studio Arayüzü",
          "Gemini Özellikleri",
          "Claude Modelleri",
          "Claude Arayüzü",
          "Claude Özellikleri",
          "Sınırlamalar: Gerçeklik algısı, halüsinasyon, kaynak verememe vb.",
          "API Ücretlendirmesi ve Tokenler"
        ],
        "PROMPT MÜHENDİSLİĞİ": [
          "Prompt Nedir?",
          "Prompt Mühendisliği Nedir?",
          "Prompt Yazarken Dikkat Edilmesi Gerekenler Giriş",
          "Basit & Açık ve Net Olmak",
          "Konuya Özgün Talimat Vermek",
          "Belirsizlikten Kaçınmak",
          "Olumsuzluklardan Kaçınmak",
          "Bağlam Sağlamak",
          "Format Belirlemek",
          "Rol Tabanlı Prompt Örnekleri",
          "Yaratıcı Prompt Örnekleri",
          "Görsel Prompt Örnekleri",
          "Parametre Kullanımı ve Örnekleri"
        ],
        "İLERİ PROMPT TEKNİKLERİ": [
          "Zero Shot Tekniği",
          "Few Shot Tekniği",
          "Chain of Thought (Adım Adım Düşünme) Tekniği",
          "Tree of Thought (Düşünce Ağacı) Tekniği",
          "Self-Ask (Modelin kendi sorularını sorması) Tekniği",
          "Özet ve Genel Değerlendirme"
        ],
        "MCP İLE UYGULAMALARI YAPAY ZEKA ARAÇLARINA BAĞLAMA": [
          "MCP Nedir?",
          "Kullanılabilecek Sunucular",
          "Claude ile Blender Uygulamasını Bağlamak"
        ]
      },
      "requirements": [
        "Bu kurs için herhangi bir teknik bilgiye veya deneyime sahip olmanız gerekmiyor."
      ],
      "description": "HERKES İÇİN YAPAY ZEKA: GPT, GEMINI, CLAUDE ve MCP Eğitimi, herkesin yapay zeka araçlarını anlayıp etkin bir şekilde kullanabilmesini sağlayan kapsamlı ve uygulamalı bir kurstur. İçerikler, teknik bilgisi olsun ya da olmasın herkesin anlayabileceği ve kendini geliştirebileceği şekilde tasarlanmıştır.\nBu kurs, yapay zekaya ilgi duyan ancak nereden başlayacağını bilemeyen bireyler için olduğu kadar, yazılımcılar, öğretmenler, içerik üreticileri, finans çalışanları, pazarlamacılar, girişimciler ve veriyle çalışan herkes için ideal bir kaynaktır. Temel kavramlardan başlayarak, adım adım gelişmiş konulara geçilecek şekilde yapılandırılmıştır.\nKurs süresince, yapay zekanın temel kavramlarını, Üretken Yapay Zeka (Generative Artificial Intelligence - GenAI) modellerinin nasıl çalıştığını ve hayatımızda nasıl yer bulduğunu adım adım keşfedeceksiniz. ChatGPT, Gemini ve Claude gibi önde gelen Büyük Dil Modellerini (Large Language Model - LLM) tüm özellikleri ile kullanmayı öğreneceksiniz. LLM modellerinin sınırlamalarını, güçlü ve zayıf yönlerini öğreneceksiniz. Kurs boyunca interaktif egzersizler ve pratik örneklerle öğrendiklerinizi pekiştirecek, özellikle prompt mühendisliği konusunda ileri teknikleri uygulayabileceksiniz. Öğrendiğiniz prompt tekniklerini diğer LLM araçları üzerinde de uygulayabilecek ve verimli sonuçlar alabileceksiniz. Ayrıca, Model Bağlam Protokolü (Model Context Protocol - MCP) ile tanışarak bu LLM modellerini nasıl kişiselleştireceğinizi ve yapay zeka özelliği olmayan diğer uygulamalara nasıl entegre edebileceğinizi öğreneceksiniz.\nKursun sonunda, üretken yapay zeka araçlarını bilinçli, yaratıcı ve verimli bir şekilde kullanabilecek; iş, eğitim, içerik üretimi, yazılım geliştirme gibi birçok alanda fark yaratabileceksiniz.",
      "target_audience": [
        "Bu kurs, yapay zeka ile ilk kez tanışacak olanlar ve ileri düzeye taşımak isteyen herkes için uygundur.",
        "Günlük hayatında ya da işinde yapay zekayı verimli kullanmak isteyen herkes kursa katılabilir."
      ]
    },
    {
      "title": "Machine Learning Campus: Data Science mit Python",
      "url": "https://www.udemy.com/course/machinelearningmitpython/",
      "bio": "Dein Machine Learning Komplettpaket mit Python, KI, Data Science, Deep Learning, Reinforcement Learning, NLP",
      "objectives": [
        "Python und PyCharm einzurichten und zu nutzen",
        "Grundlagen und fortgeschrittene Konzepte in Python",
        "Datenanalyse mit Numpy und Pandas",
        "Datenvisualisierung mit Matplotlib",
        "Nutzung von scikit-learn für Machine Learning",
        "Unterschied zwischen Statistik und Machine Learning",
        "Wichtige ML-Terminologien und -Konzepte",
        "Evaluierung von Modellen und Fehleranalyse",
        "Implementierung von Supervised Learning-Algorithmen",
        "Grundlagen des Deep Learning und PyTorch-Anwendungen"
      ],
      "course_content": {
        "Introduction": [
          "Willkommen und Übersicht",
          "Dein Dozent Tim",
          "Wichtige Information bevor du startest."
        ],
        "Vorarbeit": [
          "Python und PyCharm einrichten",
          "Python Grundlagen",
          "Python Grundlagen 2",
          "Python Grundlagen 3",
          "Python Grundlagen 4",
          "Python Grundlagen 5",
          "Optional: VS Code und Jupyter Notebooks einrichten",
          "Numpy 1",
          "Numpy 2",
          "Pandas",
          "Matplotlib",
          "scikit-learn"
        ],
        "Machine Learning Einführung": [
          "Unterschiede Statistik und Machine Learning"
        ],
        "Terminologie": [
          "Merkmale u. Merkmalsextraktion",
          "Regression u. Klassifikation"
        ],
        "Evaluation von Modellen": [
          "Fehlerfunktionen - Teil 1",
          "Fehlerfunktionen - Teil 2",
          "Fehlerfunktionen - Teil 3",
          "Over- & Underfitting",
          "Train-Test-Validierung",
          "k-Fold-Cross-Validation"
        ],
        "Supervised Learning": [
          "Lineare Regression",
          "k-Nearest-Neighbours",
          "Decision Tree - Erklärung",
          "Decision Tree - Code",
          "Ensemble Methoden",
          "Ensemble: Bagging",
          "Ensemble: Random Forest",
          "Feature Importance mit Random Forest",
          "Ensemble: Gradient Boosted Trees"
        ],
        "Clustering": [
          "K-Means",
          "Hierachisches Clustering",
          "DBSCAN"
        ],
        "Feature Engineering": [
          "Distanzmaße",
          "Feature Importance - Mean Decrease Impurity",
          "Feature Importance - Permutation-based & Shap",
          "Auswahl von Features",
          "Normalisieren von Features",
          "Normalisieren vs. nicht Normalisieren",
          "Dimensionsreduzierung"
        ],
        "Deep Learning": [
          "Einführung neuronale Netze",
          "Aktivierungsfunktionen",
          "Convolutional Layers",
          "Pooling Layers",
          "PyTorch - Tensors & Linear Layers",
          "PyTorch - nn.Module",
          "PyTorch - nn.Sequential",
          "Einfluss von Stride, Padding, Filtergröße u. Dilation",
          "Beispiel Projekt - Datensatz & Data Loader",
          "Beispiel Projekt - Model & Optimizer",
          "Beispiel Projekt - GPU & Training",
          "Beispiel Projekt - Evaluation"
        ],
        "Reinforcement Learning": [
          "Begrifflichkeiten",
          "Q-Learning - Einführung",
          "Q-Learning - Beispiel Taxi",
          "Policy Gradient - Teil 1",
          "Policy Gradient - Teil 2",
          "Erklärung Policy Gradient"
        ]
      },
      "requirements": [
        "Keine Vorkenntnisse nötig. Du lernst alles im Kurs, solltest aber natürlich Interesse mitbringen"
      ],
      "description": "Du möchtest Machine Learning verstehen und dich zum Data Scientist ausbilden lassen?\nDann ist dieser Kurs genau das Richtige für Dich!\n\n\nKomplettpaket Machine Learning: Alle Grundlagen in Python und Machine Learning Algorithmen mitsamt Evaluation und Feature Engineering. Dabei werden Modelle aus dem Supervised Learning und Clustering betrachtet, sowie das Deep Learning und der KI. Der Fokus liegt auf den aktuellen Themen Reinforcement Learning und Natural Language Processing.\n\n\nHast du dich schonmal gefragt wie es wäre den aktuell relevantesten Skill zu lernen und...\nvon KI Trends zu profitieren?\nMöglichkeit auf richtig gut bezahlte Jobs zu haben?\nmit Python komplexe Probleme spielerisch zu lösen?\nin der Welt der Künstlichen Intelligenz und Deep Learning mitzuwirken?\n\n\nAll das ist möglich im Leben eines Data Scientist. Und mit diesem Kurs bekommst du die vollständige Ausbildung dazu.\nAbschnitt 1: Introduction\nIm ersten Abschnitt des Kurses \"Machine Learning Campus: Data Science mit Python\" erhältst du eine Einführung in den Kurs. Die erste Lektion bietet einen Überblick über den gesamten Kurs, damit du die Struktur und die wichtigsten Themenbereiche kennenlernen kannst. In der zweiten Lektion stellt sich der Dozent vor und teilt seine Motivation sowie seine Ziele für den Kurs mit, um dir einen persönlichen Einblick zu geben.\nAbschnitt 2: Vorarbeit\nIn diesem Abschnitt legst du das Fundament für die Arbeit mit Python und den notwendigen Tools. Zunächst lernst du, wie du Python und PyCharm einrichtest. Die darauf folgenden Lektionen vertiefen deine grundlegenden Kenntnisse in Python und führen dich schrittweise in die Welt der Datenwissenschaft ein. Der Abschnitt schließt mit der Einführung in wichtige Bibliotheken wie Numpy, Pandas, Matplotlib und scikit-learn ab, die essenziell für die Datenanalyse und Machine Learning sind.\nAbschnitt 3: Machine Learning Einführung\nHier wird dir der Unterschied zwischen Statistik und Machine Learning erläutert. Es wird die Basis für ein tieferes Verständnis der Konzepte geschaffen, die im Machine Learning eine Rolle spielen. Du erfährst, wie Machine Learning sich von traditioneller Statistik unterscheidet und welche Anwendungen daraus resultieren.\nAbschnitt 4: Terminologie\nDie Lektionen in diesem Abschnitt erklären dir die grundlegenden Begriffe und Techniken im Machine Learning. Du lernst, was Merkmale sind und wie sie extrahiert werden können. Außerdem wird dir der Unterschied zwischen Regression und Klassifikation verdeutlicht. Diese Kenntnisse sind entscheidend, um die verschiedenen Algorithmen und Modelle richtig anwenden zu können.\nAbschnitt 5: Evaluation von Modellen\nDie Evaluation von Modellen ist ein kritischer Schritt im Machine Learning. Dieser Abschnitt behandelt verschiedene Fehlerfunktionen und wie sie zur Bewertung von Modellen verwendet werden. Themen wie Over- und Underfitting sowie Train-Test-Validierung und k-Fold-Cross-Validation werden ausführlich erläutert, um dir ein fundiertes Verständnis der Modellbewertung zu vermitteln.\nAbschnitt 6: Supervised Learning\nDieser Abschnitt führt dich in die Welt des überwachten Lernens ein. Du lernst verschiedene Algorithmen kennen, darunter lineare Regression, k-Nearest-Neighbours und Entscheidungsbäume. Darüber hinaus werden Ensemble-Methoden wie Bagging, Random Forest und Gradient Boosted Trees erklärt, inklusive der Bedeutung der Feature-Importance in diesen Modellen.\nAbschnitt 7: Clustering\nIm Abschnitt Clustering werden unüberwachte Lernmethoden vorgestellt. Du lernst die Prinzipien von K-Means, hierarchischem Clustering und DBSCAN kennen. Diese Methoden sind wichtig, um Muster und Strukturen in unbeschrifteten Daten zu erkennen und zu analysieren.\nAbschnitt 8: Feature Engineering\nFeature Engineering ist ein entscheidender Prozess zur Verbesserung der Modellleistung. Die Lektionen in diesem Abschnitt behandeln verschiedene Methoden zur Auswahl und Transformation von Features, darunter Distanzmaße, Normalisierungstechniken und Dimensionsreduzierung. Dies ermöglicht es dir, deine Daten optimal für das Training von Modellen vorzubereiten.\nAbschnitt 9: Deep Learning\nDeep Learning ist ein spannendes und komplexes Thema. In diesem Abschnitt lernst du die Grundlagen neuronaler Netze, einschließlich Aktivierungsfunktionen, Convolutional und Pooling Layers. PyTorch wird als Framework eingeführt, und du wirst durch praktische Beispiele geführt, um ein tiefes Verständnis für die Implementierung und das Training von neuronalen Netzen zu entwickeln.\nAbschnitt 10: Reinforcement Learning\nReinforcement Learning ist ein fortgeschrittenes Thema, das in diesem Abschnitt behandelt wird. Du lernst die grundlegenden Begrifflichkeiten und Konzepte kennen, einschließlich Q-Learning und Policy Gradients. Praktische Beispiele, wie das Taxi-Problem, helfen dir, die Theorie in die Praxis umzusetzen und ein tiefes Verständnis für diese Lernmethode zu entwickeln.\nAbschnitt 11: Natural Language Processing\nDer letzte Abschnitt des Kurses widmet sich der Verarbeitung natürlicher Sprache. Du lernst Techniken wie Bigram, Tokenization und Embeddings kennen. Der Abschnitt endet mit einer Einführung in Transformer-Modelle, die eine zentrale Rolle im modernen NLP spielen. Diese Kenntnisse sind entscheidend, um Texte und sprachliche Daten effektiv zu analysieren und zu modellieren.\n\n\nDu bekommst sofortigen Zugriff auf:\n14 Stunden Machine Learning Campus\nZugang zur Community. Austausch mit allen Kursmitgliedern\nSupport von Data Scientist Tim\nLebenslanger Zugriff auf den Kurs und alle zukünftigen Updates\n\n\nUdemy Zufriedenheitsgarantie\nUdemy hat eine 30 Tage 100% Geld zurück Garantie. Wenn Du also doch nicht zufrieden mit dem Kauf bist, bekommst du das gesamte Geld sofort zurück!\n\n\nSchreibe dich jetzt in den Kurs ein und werde innerhalb kürzester Zeit zum Data Scientist!\n\n\nWir freuen uns schon Dich in der ersten Lektion des Machine Learning Campus begrüßen zu dürfen!\nTim & Marius",
      "target_audience": [
        "Anfänger ohne Vorkenntnisse in Datenwissenschaft.",
        "Programmierer, die Python für Data Science lernen möchten.",
        "Berufstätige, die Machine Learning in ihre Arbeit integrieren wollen.",
        "Studierende, die praktische Kenntnisse in Datenanalyse und ML suchen.",
        "Technikbegeisterte, die moderne KI-Techniken verstehen und anwenden möchten."
      ]
    },
    {
      "title": "ChatGPT+百度AI实现小红书高效运营",
      "url": "https://www.udemy.com/course/chatgptai-v/",
      "bio": "把小红书起号交给人工智能",
      "objectives": [
        "学会用ChatGPT辅助高效建立小红书矩阵",
        "学会用百度AI辅助高效建立小红书矩阵",
        "学会小红书的基本算法框架",
        "理解小红书快速起号的基本原理"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲",
          "引入讲解"
        ],
        "课程内容": [
          "小红书的实操案例：0基础5天拿下1000w阅读",
          "小红书营销生态新认知：AI+私域引流+公域变现",
          "有哪些AI适合辅助大家小红书高效建立矩阵",
          "如何利用ChatGPT生成小红书“种草体笔记”",
          "如何利用百度AI生成小红书“种草体笔记 ”",
          "AI起号的内容方向"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "有运营经验"
      ],
      "description": "大数据时代，小红书成为营销变现的新引擎，但经营小红书要花费大量时间，人工智能却能够帮助我们大大减轻运营压力。\n为此，三节课邀请了操盘多个亿级私域互联网项目的私域和直播运营专家田子曾老师带来这门课程，教我们如何把小红书起号交给人工智能。\n通过课程的学习，你将学会如何巧妙运用ChatGPT和百度AI实现小红书的高效运营，让人工智能成为你的得力助手，辅助你轻松掌握流量密码。本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权,任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "小红书运营专员",
        "新媒体运营主管、经理、总监",
        "0基础小白运营负责人",
        "想要学习新媒体运营逻辑的学员"
      ]
    },
    {
      "title": "Pythonによるレコメンド入門 ~協調フィルタリングによる推薦~",
      "url": "https://www.udemy.com/course/python-recommend1/",
      "bio": "レコメンドシステムの基本である協調フィルタリングについて学び、簡単なレコメンドPythonで実装できるようになりましょう！また、レコメンドの手法や評価方法やについても学んでいきましょう。",
      "objectives": [
        "レコメンドシステムの概要",
        "協調フィルタリングによる推薦",
        "レコメンドの評価手法",
        "類似度を用いた推薦",
        "特異値分解による推薦",
        "Matrix Factorizationによる推薦"
      ],
      "course_content": {
        "コース紹介": [
          "紹介",
          "ソースコードのダウンロード",
          "コース準備レクチャー"
        ],
        "レコメンドの基礎": [
          "レコメンドと言えば",
          "レコメンド手法の種類",
          "ルールベースのレコメンド",
          "アソシエーション分析",
          "コンテンツベースフィルタリング"
        ],
        "協調フィルタリング": [
          "協調フィルタリング",
          "協調フィルタリングの手法",
          "レコメンドで使うデータの種類",
          "評価値行列とその特徴"
        ],
        "レコメンドの評価（前編）": [
          "レコメンドの評価手法",
          "オフライン評価とは",
          "レコメンドの評価の難しいところ",
          "評価のためのデータの分け方とCross Validation",
          "評価指標",
          "ROC曲線とAUC",
          "PR曲線とAUC"
        ],
        "Pythonによるレコメンド実践演習": [
          "問題の説明とデータの取得",
          "MovieLensデータの確認①",
          "MovieLensデータの確認②",
          "類似度による手法の説明",
          "Pythonによる実践（類似度による手法）①",
          "Pythonによる実践（類似度による手法）②",
          "Pythonによる実践（類似度による手法）③",
          "Pythonによる実践（類似度による手法）④",
          "Pythonによる実践（類似度による手法）⑤",
          "Pythonによる実践の補足（Cross Validation）",
          "特異値分解（SVD）による手法の説明",
          "Pythonによる実践（特異値分解（SVD）による手法）①",
          "Pythonによる実践（特異値分解（SVD）による手法）②",
          "Matrix Factorization（MF）による手法の説明",
          "Pythonによる実践（MFによる手法）①",
          "Pythonによる実践（MFによる手法）②",
          "Pythonによる実践（MFによる手法）③",
          "（参考）勾配降下法",
          "（参考）確率的勾配降下法（SGD）"
        ],
        "レコメンドの評価（後編）": [
          "オンライン評価（A／Bテスト、インターリービング）",
          "ユーザ調査"
        ],
        "終わりに": [
          "ビジネス要件の明確化",
          "コールドスタート問題",
          "さまざまなバイアス",
          "参考資料"
        ],
        "ボーナスレクチャー": [
          "ボーナス"
        ]
      },
      "requirements": [
        "基礎的なPythonプログラミングができる",
        "Pythonの環境構築ができる"
      ],
      "description": "情報や商品を的確に提供するために、レコメンドシステムは現代のビジネスやサービスに非常に重要になってきました。\n本コースでは、レコメンドシステムの基本の理解から実装まで、手を動かしながら理解していくことを目指します。\n2時間半程度で完結するコースなので、ぜひ手を動かしながら実践してみてください！\n\n\n内容\nレコメンドシステムの概要\n協調フィルタリング\nレコメンドの評価手法\n類似度ベースの推薦\nSVDによる推薦\nMatrix Factorization（MF）による推薦\nPythonによる実装\n\n本講座の特徴\n基礎からのステップバイステップ学習\n本講座では、レコメンドシステムの基本的な概念から始め、協調フィルタリング、類似度ベースのアプローチ、SVD、Matrix Factorizationまで段階的に学習していきます。\n実践的なプロジェクト\n各セクションで理論だけでなく、Pythonを使用した実際のコーディング演習も行います。実際のデータセットを用いてレコメンドシステムを構築し、動作を確認します。\n評価手法\nレコメンドシステムの効果を測定するための評価手法についても解説します。あなたが構築したシステムのパフォーマンスを客観的に評価する方法を学びましょう。\n誰に向いているか\nレコメンドに初めてチャレンジしてみたい人\n業務でレコメンドを実装する必要がある方\nデータサイエンティストやエンジニア志望の方\nレコメンドシステム開発をリードするビジネスオーナーやマーケターなど\nこの講座を修了することで、レコメンドシステムの設計や実装に関する基本的な知識を得ることができるはずです。ユーザーに価値ある体験を提供するレコメンドスキルを身につけましょう！\n\n必要な前提知識\nPythonの基本的な知識があると良いです。\n\n\n※ サンプルコードはnumpy 1.0系でないと動かない可能性があります。エラーが出た場合、numpy 2.0系をお使いの方は1.0系の環境でお試しください。",
      "target_audience": [
        "レコメンドシステムを学んでみたい方",
        "業務でレコメンドシステムを構築しなければならなくなった方",
        "レコメンドプロジェクトのマネジメントをする方",
        "Python初学者で次のテーマを見つけたい方"
      ]
    },
    {
      "title": "从零开始学 SQL 实战数据分析",
      "url": "https://www.udemy.com/course/sql4dataanalysis/",
      "bio": "本地安装，上手练习，也可以只看视频，学习 SQL",
      "objectives": [
        "学习如何写 SQL 程序",
        "学习用SQL进行数据分析",
        "用SQL 进行多表查询 Join",
        "用 SQL 进行高阶计算 （窗口函数) 排序"
      ],
      "course_content": {},
      "requirements": [
        "无需编程经验"
      ],
      "description": "为什么要学习 SQL？很多人学不会的原因是从一开始就没明白学某个东西能干什么。学会了有什么用。\n以至于一开始兴致勃勃，但是学到一半就放弃了。\n所以坚持学习的根本原因不在于这个知识有多难，而在于它能带给你的意义有多大。\n如果做事情没有意义，那么你就会没有学习的动力。\n那么学习 SQL 的意思是什么呢？\n如果你打开招聘网站，不管数据分析，机器学习，运营，产品经理，开发等各个职位，都要求 会SQL\n所以学习SQL的意义就在于，这是技能不仅可以提升你的工作效率，还能帮助你招到一份好的工作，或者让你的本职工作更上一层楼.\n\n\nSQL 的知识点很多，为了帮助同学们快速学习，我把 SQL 的知识点分为基础部分和进阶部分。\n\n\n基础部分主要包括\n入门：学习什么是数据库，什么是 SQL, 并在个人电脑安装数据库\n简单查询，学习 SQL 查询基本语法\n汇总分析 — 学习如何对数据进行汇总和分组，如何用SQL来做分析\n复杂查询 — 学习函数，学完这部分，你可以写出复杂的sql语句，处理复杂的业务问题了。\n多表查询 — 学习多张表之间如何查找和分析数据\n实战：挖掘最受客户喜爱电影类型\n\n\n进阶部分:\n会讲经典业务问题，也是面试会经常问到的问题\n\n\n学完本课程，你可以在本地电脑安装 MySQL 服务器 (Windows or Mac)，熟悉 MySQL 官方客户端 Workbench.\n并且了解如何用 SQL 从数据库抓取数据，进行数据分析。\n除了基础的 Select 语句，你还可以掌握告诫 SQL 的用法，比如 Join 多表查询，比如窗口函数等经典业务问题（SQL 面试常用测试题）",
      "target_audience": [
        "任何对数据分析感兴趣的人",
        "任何对 SQL 数据分析感兴趣的人",
        "数据分析师 Data Analyst",
        "产品经理 Product Manager",
        "数据开发 Data Engineer",
        "AI 算法工程师 Data Scientist"
      ]
    },
    {
      "title": "Импорт, парсинг и скрепинг данных на Python",
      "url": "https://www.udemy.com/course/ittensive-python-api/",
      "bio": "Работа с API, JSON, XML, HTML и SQL, парсинг сайтов",
      "objectives": [
        "Отправлять HTTP запросы",
        "Отправлять GET и POST запросы к API",
        "Разбирать JSON, XML, HTML ответы, включая SOAP",
        "Использовать BeautifulSoup для парсинга страниц",
        "Создавать робота-паука для обхода сайта",
        "Импортировать данные в SQL"
      ],
      "course_content": {
        "Импорт данных": [
          "HTTP запросы: JSON и API",
          "HTTP запросы с параметрами",
          "Работа с SOAP",
          "Получение данных по API"
        ],
        "Парсинг данных": [
          "Получение данных из HTML",
          "Получение табличных данных",
          "Парсинг данных",
          "Получение котировок акций"
        ],
        "Веб-скрепинг": [
          "Обход сайта по страницам",
          "Мультипроцессность",
          "Этика парсинга",
          "Парсинг интернет-магазина"
        ],
        "Работа с SQL": [
          "Установка SQLite и создание базы",
          "Создание таблиц и загрузка данных",
          "Сохранение результатов",
          "Загрузка результатов в БД"
        ]
      },
      "requirements": [
        "Базовое знание Python",
        "Базовое знание SQL"
      ],
      "description": "Центр digital-профессий ITtensive предлагает персонализированные программы с индивидуальными наставниками для освоения актуальных профессий будущего: аналитик данных на Python и программист больших данных.\nВ этом курсе вы изучите получение данных в Python, используя библиотеку requests API и форматы JSON и XML (включая SOAP).\nНаучитесь работать с неструктурированными данными в HTML, собирать их и преобразовывать в фреймы данных.\nНаучитесь собирать данные целиком с сайта в несколько потоков: создадим мультипроцессного робота-паука.\nВ завершении установите SQLite и загрузите все собранные данные в базу, а также научитесь выбирать из базы данных непосредственно в фреймы данных.\nПолностью текстовый конспект к урокам, исходный код, тесты для проверки, дополнительные материалы и обратная связь от методистов доступна на платформе Learme. Напишите нам, чтобы получить доступ к полным материалам курса.\n(C) Course Icon by Flat Icons",
      "target_audience": [
        "Начинающие разработчики Python с интересом к анализу данных",
        "Аналитики, которые используют Python для автоматизации и получения данных"
      ]
    },
    {
      "title": "Introdução a Machine Learning, Data Analytics e Data Science",
      "url": "https://www.udemy.com/course/introducao-a-machine-learning-data-analytics-e-data-science/",
      "bio": "Introdução a Machine Learning, Data Analytics e Data Science",
      "objectives": [
        "Aprenderá sobre Machine Learning;",
        "Aprenderá sobre a Indústria 4.0 e a Transformação Digital;",
        "Aprenderá sobre Data Analytics;",
        "Aprenderá sobre Data Science;",
        "Aprenderá sobre Inteligência Empresarial;",
        "Aprenderá sobre Business Intelligence;"
      ],
      "course_content": {
        "Apresentação da Instrutora": [
          "Apresentação da Instrutora"
        ],
        "Indústria 4.0 e Transformação Digital": [
          "Indústria 4.0",
          "Planejamento, Gestão e Definição",
          "Business Analytics x Transformação Digital"
        ],
        "Machine Learning": [
          "Machine Learning",
          "Machine Learning em Práticas de Serviços de Streaming",
          "Machine Learning em Mecanismos de Busca"
        ],
        "Data Analytics e Data Science": [
          "Banco de Dados",
          "Privacidade de Dados",
          "Extra: Pilares da Qualidade de Software",
          "Modelagem de Dados",
          "Relação e Funcionalidades",
          "Melhores Práticas",
          "DevOps e DevSecOps",
          "Processos de Limpeza e Padronização de Dados"
        ]
      },
      "requirements": [
        "Vontade de aprender e disposição para descobrir novos conhecimentos."
      ],
      "description": "Machine Learning é uma disciplina da área da Inteligência Artificial que, por meio de algoritmos, dá aos computadores a capacidade de identificar padrões em dados massivos e fazer previsões (análise preditiva).\nData Science é o estudo disciplinado dos dados e informações inerentes ao negócio e todas as visões que podem cercar um determinado assunto. É uma ciência que estuda as informações, seu processo de captura, transformação, geração e, posteriormente, análise de dados para converter em evidência.\nA Análise de Dados é um processo de inspeção, limpeza, transformação e modelagem de dados com o objetivo de descobrir informações úteis, informar conclusões e apoiar a tomada de decisões. A análise de dados tem múltiplas facetas e abordagens, abrangendo diversas técnicas sob uma variedade de nomes, e é usada em diferentes domínios dos negócios, ciências e ciências sociais. No mundo dos negócios de hoje, a análise de dados desempenha um papel tornando a tomada de decisões mais científicas e ajudando as empresas a operar com mais eficácia\nNeste curso você vai entender que juntos a Data Science, Machine Learning e Data Analytics além de inovações tecnológicas são aliados para o bom funcionamento das ações organizacionais, e tem poder de influência em toda cadeia produtiva.\nBons estudos!",
      "target_audience": [
        "Estudantes, Analistas de Negócios, Analistas Junior em TI e todos com vontade de aprender."
      ]
    },
    {
      "title": "ChatGPT for Beginners in Hindi with Prompt Engineering",
      "url": "https://www.udemy.com/course/chatgpt-for-beginners-in-hindi-with-prompt-engineering/",
      "bio": "Transforming Conversations with AI: ChatGPT's Beginner's Guide to Creating Future, with Generative AI and AI Tools",
      "objectives": [
        "What is an AI in this world?",
        "They will learn how to use ChatGPT to assist with coding and programming tasks, even without prior expertise.",
        "Students will gain essential knowledge about ChatGPT's discovery and learn how to use it and why it's essential.",
        "They will acquire skills to produce high-quality written articles and practical plans in various subjects.",
        "ChatGPT के आविष्कार से जुड़े आवश्यक ज्ञान के साथ, वे यह सीखेंगे कि कैसे इसका उपयोग करते हैं और क्यों।",
        "ChatGPT को साहित्यिक और प्रोग्रामिंग जगत में एक सशक्त साथी के रूप में उपयोग करने की योग्यता.",
        "उच्च गुणवत्ता वाले व्यवसायिक योजनाओं और प्रस्तावनाओं का निर्माण करने की कौशल."
      ],
      "course_content": {
        "AI kya hai?": [
          "Let's start",
          "AI kya hai"
        ],
        "AI aur kya?": [
          "AI ke types",
          "AGI",
          "ANI",
          "ASI"
        ],
        "ChatGPT ka gyan": [
          "ChatGPT kya hai?",
          "ChatGPT use kaise kare?"
        ],
        "ChatGPT use kare": [
          "ChatGPT se likhe?"
        ],
        "ChatGPT code ke liye": [
          "ChatGPT aur code"
        ],
        "ChatGPT business ke liye": [
          "Business me ChatGPT"
        ],
        "Conclusion par ChatGPT": [
          "Chaliye milte hain..."
        ]
      },
      "requirements": [
        "No prior experience is needed, just your attention will be appreciated"
      ],
      "description": "चैटजीपीटी कोर्स बेगिनर्स के लिए\nक्या आप जानते हैं कि आप ChatGPT क्या है और इसका उपयोग क्यों करना चाहिए? क्या आप तैयार हैं इस उपकरण की माहिती और उपयोग सीखने के लिए? अगर हां, तो यह कोर्स आपके लिए है!\nकौन कौन से छात्र इस कोर्स के लिए हैं:\nतकनीकी ज्ञान के बिना भी, यह शुरुआती स्तर का कोर्स है, तो यह किसी भी प्रारंभिक सीखने वाले के लिए उपयुक्त है.\nव्यावासिक योजनाओं और प्रस्तावनाओं को तैयार करने वाले व्यक्तियों के लिए, जो उच्च गुणवत्ता वाले प्रतिपूर्ण आलेख और योजनाएँ बनाना चाहते हैं.\nकोडिंग और प्रोग्रामिंग के बिना भी, डेवलपर्स और टेक्निकल पेशेवर्स के लिए, जो टेक्स्ट और लिखित सामग्री को और भी सुधारना चाहते हैं.\nइस कोर्स से छात्र क्या सीखेंगे:\nChatGPT के आविष्कार से जुड़े आवश्यक ज्ञान के साथ, वे यह सीखेंगे कि कैसे इसका उपयोग करते हैं और क्यों।\nउन्हें विभिन्न विषयों पर उच्च गुणवत्ता वाले लिखित आलेख और व्यावासिक योजनाएँ बनाने के लिए उपयुक्त तरीकों की समझ होगी.\nवे कैसे ChatGPT का उपयोग करके कोडिंग और प्रोग्रामिंग के काम में मदद कर सकते हैं.\nइस कोर्स से आपको क्या लाभ होगा:\nक्वालिटी और सुंदर लिखित सामग्री की तैयारी करने के लिए एक शक्तिशाली उपकरण का उपयोग करने की क्षमता.\nउच्च गुणवत्ता वाले व्यवसायिक योजनाओं और प्रस्तावनाओं का निर्माण करने की कौशल.\nChatGPT को साहित्यिक और प्रोग्रामिंग जगत में एक सशक्त साथी के रूप में उपयोग करने की योग्यता.\nइस कोर्स के माध्यम से, आप आपके व्यवसाय को नई ऊँचाइयों तक पहुँचाने के लिए ChatGPT का उपयोग करने के सारे रहस्य जानेंगे, और विभिन्न क्षेत्रों में आपकी सामग्री की मानकता बढ़ाएंगे। अब इस दुनिया में अपने स्वप्नों को पूरा करने के लिए तैयार हों!\nCall to Action: अगर आप अपने लेखन और व्यवसाय को नई ऊँचाइयों तक पहुँचाना चाहते हैं, तो अब ही इस कोर्स में शामिल हों! सीखिए ChatGPT का उपयोग करने के रोचक और उपयोगी तरीकों को, और अपने करियर को नई ऊँचाइयों तक ले जाएं।\n\n\n\n\nChatGPT Course for Beginners\nDo you know what ChatGPT is and why you should use it? Are you ready to dive into learning about this powerful tool and how to harness its capabilities? If yes, this course is designed just for you!\nWho is this course for:\nBeginners with or without technical knowledge, making it suitable for anyone looking to get started.\nEntrepreneurs and professionals aiming to create high-quality written content, business plans, and proposals.\nDevelopers and technical professionals interested in leveraging ChatGPT for coding and programming tasks.\nWhat will students learn from this course:\nStudents will gain essential knowledge about ChatGPT's discovery and learn how to use it and why it's essential.\nThey will acquire skills to produce high-quality written articles and practical plans in various subjects.\nThey will learn how to use ChatGPT to assist with coding and programming tasks, even without prior expertise.\nWhat benefits can you expect from this course:\nThe ability to create quality and engaging written content using a powerful tool.\nProficiency in crafting high-quality business plans and proposals.\nThe capacity to use ChatGPT as a robust ally in the literary and programming domains.\nCall to Action: If you want to take your writing and business to new heights, join this course now! Learn the fascinating and practical ways of using ChatGPT and elevate your career to new heights.\nMake sure to explore the endless possibilities of ChatGPT and start your journey towards achieving your dreams!",
      "target_audience": [
        "Students: who are interested in learning about AI and how it can be used in their studies and future careers.",
        "Educators and Trainers: Teachers and trainers interested in using AI tools for online education and course creation.",
        "Content Creators: Video creators, bloggers, and social media influencers who want to automate content creation and enhance their online presence.",
        "Digital Marketers: Individuals seeking to leverage AI for personalized marketing campaigns, chatbots for customer engagement, and video ads.",
        "Beginners with or without technical knowledge, making it suitable for anyone looking to get started.",
        "तकनीकी ज्ञान के बिना भी, यह शुरुआती स्तर का कोर्स है, तो यह किसी भी प्रारंभिक सीखने वाले के लिए उपयुक्त है.",
        "व्यावासिक योजनाओं और प्रस्तावनाओं को तैयार करने वाले व्यक्तियों के लिए, जो उच्च गुणवत्ता वाले प्रतिपूर्ण आलेख और योजनाएँ बनाना चाहते हैं.",
        "व्यावासिक योजनाओं और प्रस्तावनाओं को तैयार करने वाले व्यक्तियों के लिए, जो उच्च गुणवत्ता वाले प्रतिपूर्ण आलेख और योजनाएँ बनाना चाहते हैं.",
        "क्वालिटी और सुंदर लिखित सामग्री की तैयारी करने के लिए एक शक्तिशाली उपकरण का उपयोग करने की क्षमता."
      ]
    },
    {
      "title": "APACHE Superset e METABASE - visualizações de dados",
      "url": "https://www.udemy.com/course/apache-superset-e-metabase-visualizacoes-de-dados/",
      "bio": "Uso de visualização de dados e dashboards com tecnologias avançadas",
      "objectives": [
        "Plataforma de exploração e visualização de dados criada com base no Apache Superset de código aberto",
        "Superset: Permite a criação de gráficos e dashboards, permitindo a construção de visualização sem código",
        "Superset: é possível executar uma análise mais profunda usando o editor SQL nativo",
        "Superset: permite a conexão com diversas fontes de dados como Data Warehouse, Data Lake, planilhas, tudo 100% na nuvem",
        "Superset: possui um ambiente fácil de usar, onde você cria uma workspace de trabalho e constrói seus projetos",
        "Superset: permite carregar seus dados de diversos bancos de dados e origens diferentes, acessando os dados de forma transparente",
        "Superset: permite a criação de gráficos (CHART) dos mais variados e com requisitos de filtros e ajustes de campos, podendo gerar novos atributos.",
        "Superset: permite que você utilize o SQL LAB para explorar seus dados via SQL",
        "Superset: possui um fluxo de trabalho que organiza a construção das análises de dados",
        "Superset: com o Preset - APACHE Superset é possível conectar seus dados, criar um conjunto de dados, criar gráficos, construir um painel e compartilhar seus ins",
        "Superset: possui um espaço de trabalho para armazenamento das informações a serem desenvolvidas",
        "Superset: permite a construção de gráficos diversos: tabela, setores, heatmap, treemap, box plot, linha, sunburst, dentre outros",
        "Superset: permite a construção de previsões utilizando técnicas como FORECAST",
        "Superset: permite a colaboração e compartilhamento de gráficos e dashboard",
        "Metabase: é uma ferramenta simples para construção de suas análises",
        "Metabase: permite a leitura de tabelas de banco de dados",
        "Metabase: uso de SQL nativo",
        "Metabase: permite que você construa painéis com gráficos e sua storytelling",
        "Metabase: possui uma interface intuitiva e simples utilizando objetos em menus",
        "Metabase: é uma ferramenta que utiliza os dados para responder as suas principais perguntas",
        "Metabase: utiliza tratamento em dados e ajustes como seleção de conteúdo e preparação de consultas personalizadas",
        "Metabase: possui componentes gráficos diversos que facilitam a construção visual de suas respostas: gráfico de barras, gráfico de linha, gráfico de área, KPI, e",
        "Metabase: uma ferramenta de inteligência de negócios (BI) que permite a você a busca por respostas em suas mais diversas perguntas",
        "Metabase: permite a construções de coleções de dados, armazenando todas as suas análises",
        "Metabase: poderosa função RAIO-X que permite obter insights automáticos e explorações de seus dados",
        "Metabase: construção de conexões externas, bancos externos",
        "Metabase: apostila e material de apoio próprio passo a passo",
        "Metabase: construção de filtros, colunas customizadas, mapas",
        "Metabase: trabalhando e explicando o METABASE ADMIN"
      ],
      "course_content": {
        "Preset - APACHE Superset: Dashboard e Visualização de Dados": [
          "Apresentação - O que é o APACHE Superset",
          "INFORMAÇÕES IMPORTANTES - leia antes de iniciar o curso",
          "Entendendo sobre Preset - APACHE Superset",
          "Criação da conta no ambiente da nuvem do Preset",
          "Realizando a carga dos dados para o treinamento",
          "Criação do Chart - Tabela",
          "Criação do Chart - Treemap",
          "Criação do Chart - Série Temporal e Previsão com FORECAST",
          "Criação de uma nova coluna customizada",
          "Criação do Chart - KPI",
          "Criação do Chart - Sunburst",
          "Criação do Chart - Graph Chart - Gráfico de rede",
          "Criação do Chart - Box Plot",
          "Criação de dashboard - gerando insights e entendo as análises",
          "Criação de filtros nos dashboards",
          "Criação de query pelo SQL LAB",
          "Aula Final - entrega de atividade",
          "Responda a pergunta"
        ],
        "METABASE - Análise e conexão com os seus dados": [
          "Apresentação do treinamento de METABASE",
          "Introdução ao METABASE e sua arquitetura pra instalação",
          "Instalação do METABASE",
          "Instalação do JAVA",
          "Entendendo sobre Collection, apostila e primeiros gráficos",
          "Construindo uma coleção",
          "Trabalhando com consulta SQL, escala semafórica e tabelas",
          "Inclusão de insights no METABASE",
          "Construção automática de insights - RAIO-X",
          "Construindo filtros",
          "Construindo filtros inteligentes - uso de SQL",
          "Criando colunas customizadas",
          "Entendo a administração do METABASE",
          "Construção de mapas temáticos",
          "Entendo como conectar banco de dados externos",
          "Instalação do Postgres para análises",
          "Linkando dados do Postgres e trabalhando no METABASE",
          "Export dos dados do METABASE",
          "Administração de usuários - criando novos acessos",
          "Avaliação final"
        ]
      },
      "requirements": [
        "Conhecimento elementar de SQL"
      ],
      "description": "Se você está procurando uma forma de aprimorar suas habilidades em visualização de dados e análise de negócios, temos dois cursos incríveis que podem te ajudar a alcançar esse objetivo: APACHE Superset e METABASE.\nNo curso APACHE Superset, você aprenderá a usar uma das ferramentas de visualização de dados mais populares do mercado. Durante o curso, você será guiado por uma série de módulos que partindo da criação de visualizações avançadas, como gráficos de linhas, barras, e muito outros super avançados. Você também terá a oportunidade de trabalhar com dados reais, aplicando as técnicas que aprenderá ao longo do curso.\nJá no curso METABASE, você aprenderá a usar outra ferramenta de visualização de dados poderosa e fácil de usar. Ao longo do curso, você aprenderá a instalar e configurar o Metabase, conectar-se a diferentes fontes de dados, criar painéis personalizados e gerenciar usuários e permissões. Você contará com um material de apoio super fácil para interagir .\nAmbos os cursos são projetados para profissionais de negócios e de tecnologia que desejam aprender a usar ferramentas de visualização de dados avançadas para melhorar sua tomada de decisão e análise de negócios. Independentemente do seu nível de experiência, nossos cursos oferecem uma abordagem prática e fácil de seguir para ajudá-lo a desenvolver suas habilidades e se destacar em sua carreira.\nInscreva-se agora em nossos cursos APACHE Superset e METABASE e comece sua jornada para se tornar um especialista em visualização de dados. Aprenda a criar visualizações atraentes e informativas para ajudá-lo a entender melhor seus dados e tomar decisões mais informadas e estratégicas. Não perca essa oportunidade de aprimorar suas habilidades e se destacar em sua carreira!\nVenha e participe.",
      "target_audience": [
        "Profissionais da área de dados, estudantes, administradores, estatísticos",
        "Profissionais que desejam construir dashboards e gráficos"
      ]
    },
    {
      "title": "เรียน Python เพิ่มทักษะการทำงานสายอาชีพ Data Scientist",
      "url": "https://www.udemy.com/course/pythondatascientist/",
      "bio": "เรียนเขียนโปรแกรมภาษา Python เพิ่มทักษะการทำงานสายอาชีพ Data Scientist ฉบับเสริมทักษะ Zero to Hero",
      "objectives": [
        "ผู้เรียนจะเข้าใจการเขียนโปรแกรมภาษา Python สำหรับเพิ่มทักษะการทำงานสายอาชีพ Data Scientist",
        "ผู้เรียนจะได้เพิ่มทักษะการเขียนโปรแกรมภาษา Python สำหรับงาน Data Science อย่างเข้มข้น",
        "ผู้เรียนสามารถเขียนโปรแกรมภาษา Python เพิ่มทักษะสายอาชีพ Data Engineer Data Scientist และ Data Analyst ตั้งแต่ระดับพื้นฐานไปจนถึงสามารถต่อยอดประยุกต์ใช้งานจริง",
        "ผู้เรียนสามารถนำความรู้ที่ได้ไปประยุกต์ใช้ทำ Project ต่าง ๆ ในการเรียนและการทำงานจริงได้"
      ],
      "course_content": {
        "Python Programming Tutorials": [
          "Introduction to Python Data Science",
          "Python Syntax Exercise 1.1",
          "Python Variables Exercise 1.2",
          "Python Variables Exercise 1.3",
          "Python Variables Exercise 1.4",
          "Python Variables Exercise 1.5",
          "Python Variables Exercise 1.6",
          "Python Variables Exercise 1.7",
          "Python Variables Exercise 1.8",
          "Python Conditional Statements Exercise 1.9",
          "Python Conditional Statements Exercise 1.10",
          "Python Conditional Statements Exercise 1.11",
          "Python Loops Exercise 1.12",
          "Python Loops Exercise 1.13",
          "Python Loops Exercise 1.14",
          "Python Data Structures Exercise 1.15 Lists",
          "Python Data Structures Exercise 1.16 Tuples",
          "Python Data Structures Exercise 1.17 Sets",
          "Python Data Structures Exercise 1.18 Dictionaries",
          "Python Data Structures Exercise 1.19",
          "Python Functions Exercise 1.20",
          "Homework for Python Programming Tutorials"
        ],
        "Python for Data Science Tutorials": [
          "Introduction to Data Science Tutorials",
          "Reading & Writing Files Exercise 2.1",
          "Working CSV Files Exercise 2.2",
          "Python NumPy Exercise 2.3",
          "Python Pandas Exercise 2.4",
          "Python Data Cleaning & Organizing Exercise 2.5",
          "Python Data Analysis & Visualization Exercise 2.6",
          "Homework for Python Data Science"
        ],
        "Python Data Cleaning": [
          "Introduction to Python Data Cleaning",
          "Python Data Cleaning Exercise 3.1",
          "Python Data Cleaning Exercise 3.2",
          "Python Data Cleaning Exercise 3.3",
          "Python Data Cleaning Exercise 3.4",
          "Python Data Cleaning Exercise 3.5",
          "Homework for Python Data Cleaning"
        ],
        "Python for Machine Learning": [
          "Introduction to Python Machine Learning",
          "Mathematics & Statistics Exercise 4.1 Part 1",
          "Mathematics & Statistics Exercise 4.1 Part 2",
          "Mathematics & Statistics Exercise 4.1 Part 3",
          "Mathematics & Statistics Exercise 4.1 Part 4",
          "Supervised Learning Exercise 4.2 Linear Regression Part 1",
          "Supervised Learning Exercise 4.2 Linear Regression Part 2",
          "Supervised Learning Exercise 4.2 Linear Regression Part 3",
          "Supervised Learning Exercise 4.2 Linear Regression Part 4",
          "Supervised Learning Exercise 4.3 Decision Tree Part 1",
          "Supervised Learning Exercise 4.3 Decision Tree Part 2",
          "Supervised Learning Exercise 4.3 Decision Tree Part 3",
          "Unsupervised Learning Exercise 4.4 Clustering Part 1",
          "Unsupervised Learning Exercise 4.4 Clustering Part 2",
          "Unsupervised Learning Exercise 4.4 Clustering Part 3",
          "Supervised and Unsupervised Learning Decision Tree & Clustering"
        ],
        "Python for Data Visualization": [
          "Introduction to Python Data Visualization",
          "Line Charts Exercise 5.1 Single Line Number",
          "Line Charts Exercise 5.2 Single Line String",
          "Line Charts Exercise 5.3 Multiple Line add Colors",
          "Line Charts Exercise 5.4 Import Local File",
          "Bar Charts Exercise 5.5 Single Bar Vertical",
          "Bar Charts Exercise 5.6 Single Bar Horizontal",
          "Bar Charts Exercise 5.7 Multiple Bar Vertical",
          "Bar Charts Exercise 5.8 Multiple Bar Horizontal",
          "Bar Charts Exercise 5.9 Add Label Top",
          "Bar Charts Exercise 5.10 Add Label Alignment",
          "Bar Charts Exercise 5.11 Add Label Center",
          "Stacked Bar Charts Exercise 5.12 Multiple Stacked Bar Vertical",
          "Stacked Bar Charts Exercise 5.13 Multiple Stacked Bar Horizontal",
          "Stacked Area Charts Exercise 5.14 Stacked Area and Line Charts",
          "Scatter Plot Exercise 5.15 Scatter Plot",
          "Pie Charts Exercise 5.16 Pie Charts",
          "Histogram Exercise 5.17 Histogram Bins",
          "Histogram Exercise 5.18 Histogram Segment Bins",
          "Histogram Exercise 5.19 Histogram Fixed Bins",
          "Combo Charts Exercise 5.20 Combo Charts",
          "Homework Python for Data Visualization"
        ]
      },
      "requirements": [
        "ผู้เรียนต้องมีความรู้และความเข้าใจพื้นฐานการเขียนโปรแกรมภาษา Python",
        "ผู้เรียนต้องมีความรู้และความเข้าใจพื้นฐานทางด้าน Data Science",
        "ผู้เรียนต้องมีความรู้และความเข้าใจพื้นฐานทางด้าน Mathematics"
      ],
      "description": "หลักสูตร เรียน Python เพิ่มทักษะการทำงานสายอาชีพ Data Scientist\nสามารถเรียนได้ทุกคน จำเป็นต้องมีความรู้ด้านการเขียนโปรแกรมภาษา Python มาก่อน\nเนื้อหาการเรียนเขียนโปรแกรมภาษา Python เพิ่มทักษะการทำงานสายอาชีพ Data Scientist ฉบับเสริมทักษะ Zero to Hero\nแบ่งเป็น 5 ส่วน\nส่วนที่ 1: Python Programming Tutorials\n1. Introduction to Python Data Science\n2. Python Syntax Exercise 1.1\n3. Python Variables Exercise 1.2\n4. Python Variables Exercise 1.3\n5. Python Variables Exercise 1.4\n6. Python Variables Exercise 1.5\n7. Python Variables Exercise 1.6\n8. Python Variables Exercise 1.7\n9. Python Operators Exercise 1.8\n10. Python Conditional Statements Exercise 1.9\n11. Python Conditional Statements Exercise 1.10\n12. Python Conditional Statements Exercise 1.11\n13. Python Loops Exercise 1.12\n14. Python Loops Exercise 1.13\n15. Python Loops Exercise 1.14\n16. Python Data Structures Exercise 1.15 Lists\n17. Python Data Structures Exercise 1.16 Tuples\n18. Python Data Structures Exercise 1.17 Sets\n19. Python Data Structures Exercise 1.18 Dictionaries\n20. Python Data Structures Exercise 1.19\n21. Python Functions Exercise 1.20\n22. Homework for Python Programming Tutorials\nส่วนที่ 2: Python for Data Science Tutorials\n23. Introduction to Data Science Tutorials\n24. Reading & Writing Files Exercise 2.1\n25. Working CSV Files Exercise 2.2\n26. Python NumPy Exercise 2.3\n27. Python Pandas Exercise 2.4\n28. Python Data Cleaning & Organizing Exercise 2.5\n29. Python Data Analysis & Visualization Exercise 2.6\n30. Homework for Python Data Science\nส่วนที่ 3: Python Data Cleaning\n31. Introduction to Python Data Cleaning\n32. Python Data Cleaning Exercise 3.1\n33. Python Data Cleaning Exercise 3.2\n34. Python Data Cleaning Exercise 3.3\n35. Python Data Cleaning Exercise 3.4\n36. Python Data Cleaning Exercise 3.5\n37. Homework for Python Data Cleaning\nส่วนที่ 4: Python for Machine Learning\n38. Introduction to Python Machine Learning\n39. Mathematics & Statistics Exercise 4.1 Part 1\n40. Mathematics & Statistics Exercise 4.1 Part 2\n41. Mathematics & Statistics Exercise 4.1 Part 3\n42. Mathematics & Statistics Exercise 4.1 Part 4\n43. Supervised Learning Exercise 4.2 Linear Regression Part 1\n44. Supervised Learning Exercise 4.2 Linear Regression Part 2\n45. Supervised Learning Exercise 4.2 Linear Regression Part 3\n46. Supervised Learning Exercise 4.2 Linear Regression Part 4\n47. Supervised Learning Exercise 4.3 Decision Tree Part 1\n48. Supervised Learning Exercise 4.3 Decision Tree Part 2\n49. Supervised Learning Exercise 4.3 Decision Tree Part 3\n50. Unsupervised Learning Exercise 4.4 Clustering Part 1\n51. Unsupervised Learning Exercise 4.4 Clustering Part 2\n52. Unsupervised Learning Exercise 4.4 Clustering Part 3\n53. Supervised and Unsupervised Learning Decision Tree & Clustering\nส่วนที่ 5: Python for Data Visualization\n54. Introduction to Python Data Visualization\n55. Line Charts Exercise 5.1 Single Line Number\n56. Line Charts Exercise 5.2 Single Line String\n57. Line Charts Exercise 5.3 Multiple Line add Colors\n58. Line Charts Exercise 5.4 Import Local File\n59. Bar Charts Exercise 5.5 Single Bar Vertical\n60. Bar Charts Exercise 5.6 Single Bar Horizontal\n61. Bar Charts Exercise 5.7 Multiple Bar Vertical\n62. Bar Charts Exercise 5.8 Multiple Bar Horizontal\n63. Bar Charts Exercise 5.9 Add Label Top\n64. Bar Charts Exercise 5.10 Add Label Alignment\n65. Bar Charts Exercise 5.11 Add Label Center\n66. Stacked Bar Charts Exercise 5.12 Multiple Stacked Bar Vertical\n67. Stacked Bar Charts Exercise 5.13 Multiple Stacked Bar Horizontal\n68. Stacked Area Charts Exercise 5.14 Stacked Area and Line Charts\n69. Scatter Plot Exercise 5.15 Scatter Plot\n70. Pie Charts Exercise 5.16 Pie Charts\n71. Histogram Exercise 5.17 Histogram Bins\n72. Histogram Exercise 5.18 Histogram Segment Bins\n73. Histogram Exercise 5.19 Histogram Fixed Bins\n74. Combo Charts Exercise 5.20 Combo Charts\n75. Homework Python for Data Visualization",
      "target_audience": [
        "ผู้ที่ต้องการเพิ่มทักษะความรู้การเขียนโปรแกรม นักวิทยาศาสตร์ข้อมูล วิศวกรข้อมูล นักวิเคราะห์ข้อมูล นักพัฒนาโปรแกรม โปรแกรมเมอร์ ที่สนใจงานด้าน Data Science"
      ]
    },
    {
      "title": "Reinforcement Learning Avanzado: Política Gradiente",
      "url": "https://www.udemy.com/course/reinforcement-learning-politica-gradiente/",
      "bio": "Crea agentes inteligentes con Deep Reinforcement Learning y PyTorch: PPO, TRPO, A2C, REINFORCE",
      "objectives": [
        "Dominar algunos de los algoritmos más avanzados del Reinforcement Learning",
        "Aprende a crear inteligencias artificiales que puedan actuar en un entorno complejo para alcanzar sus objetivos.",
        "Crea desde cero agentes avanzados de Aprendizaje por Reforzamiento utilizando las herramientas más populares de Python (PyTorch Lightning, Gym, Brax, Optuna)",
        "Aprende a realizar ajuste de hiperparámetros (selección de las mejores condiciones experimentales para que nuestra inteligencia artificial aprenda).",
        "Comprende fundamentalmente el proceso de aprendizaje de cada algoritmo.",
        "Depurar y extender los algoritmos presentados.",
        "Comprende e implementa nuevos algoritmos a partir de artículos de investigación."
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Serie de Reinforcement Learning",
          "Google Colab",
          "Dónde empezar",
          "Código completo",
          "Conecta conmigo en redes sociales"
        ],
        "Repaso: El proceso de decisión de Markov (MDP)": [
          "Visión general del módulo",
          "Elementos comunes a todas las tareas de control",
          "El proceso de decisión de Markov (PDM)",
          "Tipos de proceso de decisión de Markov",
          "Trayectoria y episodio",
          "Recompensa vs retorno",
          "Factor de descuento",
          "Política",
          "Valor de un estado v(s) y valor de un estado-acción q(s,a)",
          "Ecuaciones de Bellman",
          "Resolver un proceso de decisión de Markov"
        ],
        "Repaso: Métodos Monte-Carlo": [
          "Métodos Monte-Carlo",
          "Resolver tareas de control con métodos Monte-Carlo",
          "Algoritmo de control Monte-Carlo"
        ],
        "Repaso: Métodos de diferencias temporales": [
          "Métodos de diferencias temporales",
          "Resolver tareas de control con métodos de diferencias temporales",
          "Métodos Monte-Carlo vs diferencias temporales",
          "SARSA",
          "Q-Learning",
          "Ventajas de los métodos de diferencias temporales"
        ],
        "Repaso: Bootstrap de 'n' pasos": [
          "Métodos de diferencias temporales de 'n' pasos",
          "¿Dónde encajan los métodos de 'n' pasos?",
          "Efecto de variar el valor de 'n'"
        ],
        "Repaso: Breve introducción a las redes neuronales": [
          "Visión general del módulo",
          "Aproximadores de funciones",
          "Redes neuronales artificiales",
          "Neuronas artificiales",
          "Cómo representar una red neuronal",
          "Descenso gradiente estocástico (SGD)",
          "Optimización de redes neuronales"
        ],
        "Repaso: REINFORCE": [
          "Métodos de política gradiente",
          "Representando políticas con redes neuronales",
          "Rendimiento de una política",
          "El teorema del gradiente de la política",
          "REINFORCE - Parte 1",
          "Aprendizaje en paralelo",
          "Regularización mediante entropía",
          "REINFORCE - Parte 2"
        ],
        "PyTorch Lightning": [
          "PyTorch Lightning",
          "Enlace a la libreta de código",
          "Creación de la política",
          "Creación del entorno",
          "Creación del dataset",
          "Creación del algoritmo REINFORCE - Part 1",
          "Creación del algoritmo REINFORCE - Part 2",
          "Exploración del agente resultante"
        ],
        "REINFORCE para espacios de acciones contínuos": [
          "REINFORCE para espacios de acciones contínuos",
          "Enlace a la libreta de código",
          "Creación de la política",
          "Creación del entorno",
          "Creación del dataset",
          "Creación del algoritmo - Parte 1",
          "Creación del algoritmo - Parte 2",
          "Exploración del agente resultante"
        ],
        "Advantage Actor-Critic (A2C)": [
          "Advantage Actor-Critic (A2C)",
          "Enlace a la libreta de código",
          "Creación de la política y la value network",
          "Creación del entorno",
          "Creación del dataset",
          "Implementación de A2C - Parte 1",
          "Implementación de A2C - Parte 2",
          "Exploración del agente resultante"
        ]
      },
      "requirements": [
        "Conocer las bases de la programación en Python",
        "Completar nuestro curso \"Reinforcement Learning de principiante a maestro\" o estar familiarizado con los conceptos básicos del Aprendizaje por Reforzamiento (o ver las secciones introductorias incluidas en este curso).",
        "Conocer estadísticas básicas (media, varianza, distribución normal)."
      ],
      "description": "Esta es la serie de cursos más completa sobre Reinforcement Learning en Udemy. En ella, aprenderás a implementar algunos de los algoritmos de Deep Reinforcement Learning más poderosos en Python utilizando PyTorch y PyTorch Lightning. Implementarás desde cero algoritmos adaptativos que resuelven tareas de control basadas en la experiencia. Aprenderás a combinar estas técnicas con Redes Neuronales y métodos de Aprendizaje Profundo para crear agentes de Inteligencia Artificial adaptativos capaces de resolver tareas de toma de decisiones.\nEste curso te introducirá al estado del arte en técnicas de Reinforcement Learning. También te preparará para los cursos siguientes en esta serie, donde exploraremos otros métodos avanzados que destacan en otros tipos de tareas.\n\n\nEl enfoque del curso está en desarrollar habilidades prácticas. Por lo tanto, después de aprender los conceptos más importantes de cada familia de métodos, implementaremos uno o más de sus algoritmos en cuadernos de Jupyter, desde cero.\n\n\n\n\nMódulos de nivelación:\n\n\n- Actualización: El proceso de decisión de Markov (MDP).\n- Actualización: Métodos de Monte Carlo.\n- Actualización: Métodos de diferencia temporal.\n- Actualización: Bootstrap de N pasos.\n- Actualización: Breve introducción a las Redes Neuronales.\n- Actualización: Métodos de política gradiente.\n\n\n\n\nAprendizaje por Reforzamiento Avanzado:\n\n\n- REINFORCE\n- REINFORCE para espacios de acción continuos\n- Actor-crítico de ventaja (A2C)\n- Métodos de región de confianza\n- Optimización de política de proximal (PPO)\n- Estimación de ventaja generalizada (GAE)\n- Optimización de política de región de confianza (TRPO)",
      "target_audience": [
        "Desarrolladores que deseen conseguir un empleo en el campo del Machine Learning.",
        "Científicos/analistas de datos y profesionales del Machine Learning que buscan ampliar sus conocimiento.",
        "Estudiantes e investigadores de robótica.",
        "Estudiantes e investigadores de ingeniería."
      ]
    },
    {
      "title": "Probabilidad y Estadística",
      "url": "https://www.udemy.com/course/probabilidad-y-estadistica/",
      "bio": "Curso fundamental",
      "objectives": [
        "Definir cantidades y conceptos fundamentales de probabilidad y estadística",
        "Definir clases y frecuencias de datos",
        "Representar gráficamente una frecuencia estadística",
        "Trabajar con medidas de tendencia central",
        "Trabajar con medidas de dispersión",
        "Definir y utilizar conceptos como coeficientes, puntuaciones y permutaciones",
        "Dstudiar la probabilidad clásica y la probabilidad bayesiana",
        "Trabajar con diferentes distribuciones de probabilidad continuas y discretas"
      ],
      "course_content": {
        "Fundamentos matemáticos": [
          "Introducción",
          "Porcentaje",
          "Proporción y razón",
          "Potencias y raíces",
          "Función factorial",
          "Función suma",
          "Variables y escalas de medición",
          "Operaciones entre conjuntos",
          "Población, muestra y muestreo",
          "Estimación, hipótesis, y tendencias",
          "Unidad 1"
        ],
        "Distribuciones de frecuencias": [
          "Intervalos y clases",
          "Determinación de clases y frecuencias",
          "Ejemplo de determinación de clases y frecuencias",
          "Límite exacto y marca de clase",
          "Frecuencia absoluta, relativa y acumulada",
          "Histograma, polígono y curva de frecuencias",
          "Representaciones gráficas en barras y circulares",
          "Gráfica de frecuencias acumuladas y complementarias: ojivas",
          "Clases y frecuencias unitarias",
          "Unidad 2"
        ],
        "Medidas de tendencia central": [
          "Factores unitarios",
          "La media aritmética",
          "La mediana y la moda",
          "Promedio ponderado",
          "Promedio móvil",
          "La media geométrica y armónica",
          "Cuantiles: deciles, cuartiles y porcentiles",
          "Aplicación de cuantiles",
          "Media aritmética para datos agrupados",
          "Mediana para datos agrupados",
          "Moda para datos agrupados",
          "Cuantiles para datos agrupados",
          "Unidad 3"
        ],
        "Medidas de dispersión": [
          "Rango, desviación media y varianza",
          "Aplicación de: rango, desviación media y varianza",
          "Desviación estándar",
          "Aplicación de la desviación estándar",
          "Coeficientes de variación",
          "Coeficientes de asimetría de Pearson",
          "Momentos y curtosis",
          "Aplicación de momentos y curtosis",
          "Puntuaciones estándar: Z y t de Student",
          "Rango, varianza, y desviación estándar para datos agrupados",
          "Unidad 4"
        ],
        "Análisis combinatorio": [
          "Permutaciones: algunos objetos, todos diferentes",
          "Permutaciones: todos los objetos, todos diferentes",
          "Permutaciones: todos los objetos, algunos repetidos",
          "Permutaciones: algunos objetos, algunos repetidos",
          "Permutaciones con reemplazo",
          "Combinaciones",
          "Multiplicación de combinaciones",
          "Unidad 5"
        ],
        "Introducción a la probabilidad": [
          "Estudio básico de probabilidades",
          "Tipos de eventos",
          "Suma y multiplicación de probabilidades",
          "Espacio muestral",
          "Aplicación del espacio muestral",
          "Árbol de probabilidad",
          "Esperanza matemática",
          "Probabilidad conjunta I",
          "Probabilidad conjunta II",
          "Probabilidad conjunta III",
          "Diagramas de Venn",
          "Análisis de probabilidades condicionales",
          "Tabla de contingencias",
          "La fórmula de Bayes",
          "Unidad 6"
        ],
        "Distribuciones discretas de probabilidad": [
          "Distribución uniforme",
          "Distribución simétrica",
          "Distribución binomial o de Bernoulli",
          "Aplicación de la distribución binomial o de Bernoulli",
          "Media y desviación estándar de la distribución binomial (población infinita)",
          "Media y desviación estándar de la distribución binomial (población finita)",
          "Sesgo y curtosis de la distribución binomial",
          "El triángulo de Pascal",
          "Muestro para aceptación por lotes",
          "Distribución hipergeométrica",
          "Media y desviación estándar de la distribución hipergeométrica",
          "Distribución de Poisson",
          "Distribución de Poisson como aproximación a la binomial y a la hipergeométrica",
          "Media y desviación estándar de la distribución de Poisson (variables discretas)",
          "Unidad 7"
        ],
        "Distribuciones continuas de probabilidad": [
          "Distribución normal I",
          "Distribución normal II",
          "Distribución normal III",
          "Aplicación de la distribución normal I",
          "Aplicación de la distribución normal II",
          "Distribución normal como aproximación a la binomial",
          "Aplicación de la distribución normal como aproximación a la binomial",
          "Distribución normal como aproximación a la de Poisson",
          "Distribución exponencial",
          "Unidad 8"
        ],
        "Análisis de tendencias": [
          "Introducción al análisis de tendencias",
          "Análisis de regresión",
          "Método de mínimos cuadrados I",
          "Método de mínimos cuadrados II",
          "Análisis de correlación",
          "Aplicación del análisis de correlación",
          "Error estándar del ajuste",
          "Unidad 9"
        ],
        "Banco de Fórmulas": [
          "Formulario Estadística",
          "Formulario Probabilidad"
        ]
      },
      "requirements": [
        "Conocimiento básico de álgebra"
      ],
      "description": "Entre razones, proporciones, tendencias y dispersiones, este curso de probabilidad y estadística está hecho para comprender cada aspecto de las matemáticas que estudian los eventos y buscan patrones en los datos. A través de la probabilidad y la estadística es posible analizar datos de un conjunto de elementos para establecer sus tendencias y tomar decisiones apoyadas en hechos.",
      "target_audience": [
        "Profesionales que quieran reforzar los conceptos.",
        "Universitarios que desean refrescar sus conocimientos del tema"
      ]
    },
    {
      "title": "Déploiement de Modèles ML en Production avec FastAPI &Docker",
      "url": "https://www.udemy.com/course/deploiement-de-modeles-ml-en-production-avec-fastapi-docker/",
      "bio": "Maîtrisez le cycle complet du déploiement ML: de la création de modèles à leur mise en production via FastAPI, Docker",
      "objectives": [
        "Créer et déployer des modèles de machine learning en environnement de production • Développer des APIs robustes avec FastAPI pour servir des modèles ML",
        "Conteneuriser vos applications ML avec Docker pour assurer portabilité et mise à l'échelle",
        "Implémenter des interfaces utilisateur simples pour interagir avec vos modèles ML",
        "Maîtriser le déploiement cloud sur Heroku et Microsoft Azure",
        "Mettre en place des pipelines CI/CD avec GitHub Actions",
        "Gérer les bonnes pratiques de test, monitoring et logging pour applications ML",
        "Réaliser 3 projets complets de déploiement ML de bout en bout"
      ],
      "course_content": {
        "Concepts d'Apprentissage Automatique": [
          "Les bases de l'Apprentissage Automatique",
          "Déploiement de Modèle d'Apprentissage Automatique (ML)",
          "Configuration de l'environnement de développement"
        ],
        "Modèle ML de prédiction de score avec Régression Linéaire": [
          "Chargement des données pour le modèle ML",
          "Entraînement du modèle ML",
          "Évaluation et sauvegarde du modèle ML",
          "Support de Cours"
        ],
        "Déploiement de Modèle ML avec Serveur Streamlit": [
          "Introduction à Streamlit",
          "Écriture de votre première application Streamlit",
          "Déploiement de Modèle ML avec Streamlit"
        ],
        "Introduction à FastAPI": [
          "Aperçu de FastAPI",
          "Création d'une API simple",
          "Définition des routes et des points d'extrémité"
        ],
        "Création d'une Application FastAPI pour la Distribution de Modèle": [
          "Configuration de FastAPI pour le projet ML",
          "Définition des routes et des points d'extrémité pour la prédiction de modèle",
          "Test local des points d'extrémité FastAPI"
        ],
        "Mini Projet 1: Classification de Valeur de Vin avec FastAPI": [
          "Prétraitement et préparation des données de qualité du vin",
          "Entraînement et sauvegarde du modèle de classification de Valeur de Vin",
          "Construction de FastAPI"
        ],
        "Préparation de l'Application pour la Production": [
          "Préchargement du Modèle pour la Réduction de Latence",
          "Mise en œuvre de la gestion des requêtes, gestion des erreurs et journalisation",
          "Configuration des variables d'environnement",
          "Écriture d'une interface simple pour la distribution de modèle"
        ],
        "Introduction à Docker": [
          "Aperçu de Docker",
          "Écriture d'un Dockerfile",
          "Construction et exécution d'une image docker"
        ],
        "Prédiction de Score ML avec FastAPI et Docker": [
          "Écriture d'un Dockerfile pour conteneuriser l'application FastAPI",
          "Construction et exécution locale d'images Docker pour les tests",
          "Mise en œuvre de tests unitaires et d'intégration"
        ],
        "Mini Projet 2: Classification de Fleur d'Iris avec FastAPI et Docker": [
          "Mise en œuvre de tests unitaires et d'intégration",
          "Construction de FastAPI",
          "Test local des points d'extrémité",
          "Développement d'un html simple pour l'interface de distribution de modèle",
          "Configuration de FastAPI pour communiquer avec l'interface",
          "Préparation de l'Application pour la Production",
          "Dockerisation de la production FastAPI",
          "Mise en œuvre de tests unitaires & d'intégration pour les points d'extrémité AP"
        ]
      },
      "requirements": [
        "Connaissances de base en Python (structures de données, fonctions)",
        "Compréhension fondamentale des concepts de machine learning",
        "Familiarité avec les bibliothèques comme NumPy, pandas, scikit-learn (recommandé)",
        "Aucune expérience préalable avec FastAPI ou Docker n'est requise",
        "Aucune expérience préalable avec FastAPI ou Docker n'est requise",
        "Un ordinateur avec accès Internet pour installer les outils nécessaires"
      ],
      "description": "Vous êtes data scientist ou développeur et vous savez créer des modèles d'apprentissage automatique, mais vous vous demandez comment les mettre en production efficacement? Ce cours complet est fait pour vous!\n\"Déploiement de Modèles ML en Production avec FastAPI et Docker\" vous guide pas à pas dans l'art de transformer vos modèles ML en applications web robustes et évolutives prêtes pour un environnement de production.\nContrairement à d'autres formations qui se concentrent uniquement sur la création de modèles ou sur les aspects techniques isolés, notre approche pratique couvre l'ensemble du cycle de déploiement ML, en combinant théorie et projets concrets.\nAu fil des sections, vous allez: • Maîtriser les fondamentaux de l'apprentissage automatique orienté production • Créer et entraîner plusieurs modèles ML (prédiction de scores, classification de qualité de vin et d'espèces de fleurs) • Découvrir et implémenter des API REST avec FastAPI, l'un des frameworks Python les plus rapides et modernes • Conteneuriser vos applications avec Docker pour garantir portabilité et scalabilité • Déployer vos modèles sur des plateformes cloud (Heroku et Microsoft Azure) • Mettre en place des pipelines CI/CD professionnels avec GitHub Actions\nChaque section théorique est suivie d'un mini-projet pratique, culminant dans un projet final intégrant toutes les compétences acquises. Vous construirez une application ML de bout en bout, de la préparation des données jusqu'au déploiement en production avec monitoring.\nCe cours est à jour avec les dernières pratiques de l'industrie et vous prépare directement aux défis réels rencontrés par les équipes ML en entreprise. Rejoignez-nous pour faire passer vos compétences en déploiement ML au niveau professionnel!",
      "target_audience": [
        "Data scientists qui souhaitent déployer leurs modèles ML en production",
        "Ingénieurs ML cherchant à améliorer leurs compétences en déploiement",
        "Développeurs Python voulant se spécialiser dans les applications de machine learning",
        "Professionnels IT intéressés par l'intégration de solutions ML dans leur infrastructure",
        "Étudiants en data science désireux d'acquérir des compétences pratiques en MLOps",
        "Toute personne souhaitant passer du prototype à la production dans les projets ML"
      ]
    },
    {
      "title": "YOLOv8+DeepSORT多目標跟蹤(行人車輛計數與越界識別)",
      "url": "https://www.udemy.com/course/yolov8deepsort/",
      "bio": "YOLOv8+DeepSORT Multiple Object Tracking",
      "objectives": [
        "掌握YOLOv8結合DeepSORT多目標跟蹤的方法",
        "掌握YOLOv8結合DeepSORT的應用（行人車輛計數與越界識別）",
        "學習DeepSORT多目標跟蹤原理",
        "解讀DeepSORT多目標跟蹤代碼"
      ],
      "course_content": {
        "课程介紹": [
          "课程介紹"
        ],
        "基礎篇": [
          "多目標跟蹤任務介紹",
          "多目標跟蹤常用資料集",
          "多目標跟蹤評估指標"
        ],
        "實踐篇(Windows)": [
          "安裝軟體環境(Nvidia驅動，CUDA和cuDNN)",
          "安裝PyTorch",
          "克隆和安裝YOLOv8",
          "項目代碼下載及安裝",
          "行人多目標跟蹤與計數演示",
          "訓練行人RelD資料集",
          "訓練車輛ReID資料集",
          "車輛多目標跟蹤與計數演示",
          "越界識別演示"
        ],
        "實踐篇（Ubuntu）": [
          "安裝軟體環境(Nvidia驅動，CUDA和cuDNN)",
          "安裝PyTorch",
          "克隆和安裝YOLOv8",
          "項目代碼下載及安裝",
          "行人多目標跟蹤與計數演示",
          "訓練行人RelD資料集",
          "訓練車輛ReID資料集",
          "車輛多目標跟蹤與計數演示",
          "越界識別演示"
        ],
        "原理篇": [
          "馬氏距離",
          "匈牙利算法",
          "卡爾曼濾波器",
          "SORT多目標跟蹤論文解讀（上）",
          "SORT多目標跟蹤論文解讀（下）",
          "DeepSORT多目標跟蹤論文解讀（上）",
          "DeepSORT多目標跟蹤論文解讀（下）"
        ],
        "代碼解析篇": [
          "項目代碼概覽",
          "程式流程圖",
          "PyCharm中斷點跟蹤方法",
          "demo.py代碼解析",
          "count.py代碼解析",
          "zone.py代碼解析",
          "objdetector.py代碼解析",
          "objtracker.py代碼解析",
          "reid網路相關代碼解析",
          "detection.py代碼解析",
          "nn_matching.py代碼解析",
          "iou_matching.py代碼解析",
          "linear_assignment.py代碼解析",
          "preprocessing.py代碼解析",
          "kalman_filter.py代碼解析",
          "track.py代码解析",
          "tracker.py代碼解析",
          "deep_sort.py代碼解析"
        ]
      },
      "requirements": [
        "熟悉Python和PyTorch"
      ],
      "description": "本課程使用YOLOv8和DeepSORT對視頻中的行人、車輛做多目標跟蹤計數與越界識別，開展YOLOv8目標檢測和DeepSORT多目標跟蹤強強聯手的應用。\n課程分別在Windows和Ubuntu系統上做專案演示，並對DeepSORT原理和代碼做詳細解讀（使用PyCharm單步調試講解）。\n課程包括：基礎篇、實踐篇、原理篇和代碼解析篇。\n基礎篇包括多目標跟蹤任務介紹、常用資料集和評估指標；\n實踐篇包括Win10和Ubuntu系統上的YOLOv8+DeepSORT的多目標跟蹤計數與越界識別具體的實踐操作步驟演示，特別是對行人、車輛的ReID資料集講解了訓練方法；\n原理篇中講解了馬氏距離、匈牙利演算法、卡爾曼濾波器的原理，並解讀了SORT和DeepSORT論文；\n代碼解析篇中使用PyCharm單步調試對DeepSORT的代碼逐個檔進行講解。課程提供注釋後的代碼和代碼解析文檔。",
      "target_audience": [
        "希望學習多目標跟蹤技術的學員和從業者"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第19部 DeepSeek如何 Fine-tune (微調)大語言模型",
      "url": "https://www.udemy.com/course/generative_ai_19/",
      "bio": "關於DeepSeek，Tokenizer，Chain of Thought，Reinforcement Learning，LoRA，量化，GRPO，PEFT ，CoT，SFT，HuggingFace，Fine-tuning",
      "objectives": [
        "掌握DeepSeek大模型微调实战",
        "掌握LoRA和量化技术",
        "理解Chain of Thought (CoT)推理",
        "掌握 GRPO 框架",
        "Hugging Face生态实操"
      ],
      "course_content": {
        "課程準備": [
          "課程工具準備",
          "如何安裝和使用包管理器",
          "Windows安裝使用Poetry的方法"
        ],
        "如何使用Huggingface 的Transformers 微調fine-tune 模型": [
          "DeepSeek的發展與技術特點",
          "如何使用Hugging hub & Tokenizer",
          "如何用 Tokenizer 分詞器預處理數據",
          "如設定超參數 & labels & dtype 實現模型fine-tune&評估",
          "如何微調 fine-tune 模型"
        ],
        "如何降低微调 fine-tune门槛": [
          "如何實現量化 Quantization 模型",
          "如何實現 Low-Rank Adaptation"
        ],
        "如何微调 DeepSeek": [
          "如何實現Supervised Fine-Tuning",
          "如何實現Chain of Thought (CoT) - 連鎖思維推理",
          "第 12 講座的數據集",
          "如何轉換dataset 推理邏輯語句",
          "如何實現 GRPO"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "DeepSeek如何Fine-tune大語言模型\n在這個數位轉型的時代，大語言模型正以前所未有的速度重塑各行各業，而DeepSeek作為新一代大語言模型的代表，憑藉其獨特技術特點和靈活的微調方案，為業界提供了極具前瞻性的解決方案。今天，我們誠摯推薦由Ken Cen出品的新課程——“Generative AI第19部 DeepSeek如何 Fine-tune (微調)大語言模型”，帶您從零開始，全面掌握DeepSeek的微調技術。\n1. DeepSeek的發展與技術特點\n發展歷程：從最早期的語言生成模型到如今的DeepSeek，技術日益成熟，實現了更高效、更準確的語言生成。\n技術亮點：具備高效的運算性能、靈活的調參機制和出色的量化能力，適合各類應用場景。\n2. 如何使用Hugging Hub & Tokenizer\nHugging Hub：利用Hugging Face Hub快速下載並部署最新預訓練模型，與DeepSeek無縫銜接。\nTokenizer應用：掌握如何使用Tokenizer進行文本分詞，將自然語言轉換成模型可處理的數字化序列，為後續微調奠定基礎。\n3. 使用Tokenizer分詞器預處理數據\n數據清洗與標準化：學習如何利用Tokenizer進行數據預處理，確保數據輸入的一致性和高效性。\n文本編碼：實際演示如何將文本轉化為token id，設定最大序列長度，並利用padding和truncation處理超長文本。\n4. 超參數、labels與dtype設定及Fine-tune&評估\n超參數調整：探討學習率、批次大小、梯度累積步數等超參數的設置，如何平衡精度和計算資源。\n標籤與數據類型：詳細介紹如何配置labels與dtype，確保模型在微調過程中能夠正確反向傳播和穩定收斂。\n評估指標：講解如何使用標準指標評估模型性能，確保微調效果達到預期目標。\n5. 如何微調Fine-tune模型\n微調策略：深入解析模型微調流程，從數據加載、預處理到模型訓練，每一步都精心設計，實戰演練細節豐富。\n訓練技巧：分享多種微調技巧，包括混合精度訓練等，助您實現高效穩定的模型微調。\n6. 實現量化Quantization模型\n量化技術原理：介紹8-bit、4-bit量化技術，如何在降低內存占用的同時保持模型性能。\n實作步驟：逐步講解如何利用現有工具對DeepSeek進行量化處理，實現高性能輕量級部署。\n7. 實現Low-Rank Adaptation (LoRA)\nLoRA原理：解析低秩分解如何在保持原模型表現的前提下，降低微調參數量，提高計算效率。\n應用實例：通過實戰案例演示LoRA在DeepSeek微調中的應用，並比較不同配置參數對模型效果的影響。\n8. 實現Supervised Fine-Tuning\n監督式微調：探討如何使用標註數據進行監督式微調，進一步提升模型回答的準確性與一致性。\n模型評估：介紹如何構建評估流程，檢測模型在各類測試場景下的表現。\n9. 實現Chain of Thought (CoT)連鎖思維推理\nCoT概念：講解連鎖思維推理的重要性，如何引導模型生成具備清晰推理流程的答案。\n實戰應用：展示如何構建CoT格式的輸入，並引導模型在回答時同時展現推理過程與最終結論。\n10. 轉換Dataset推理邏輯語句\n數據集格式轉換：深入解析如何從原始數據集中提取並轉換出推理邏輯語句，使模型能夠理解並生成合理的邏輯推理。\n模板設計：提供模板設計範例，確保轉換後的數據符合模型訓練要求。\n11. 實現GRPO\nGRPO框架：介紹GRPO（Gradient Reward Policy Optimization）在強化學習中的應用，如何用於模型微調過程中的策略優化。\n實施步驟：詳細講解GRPO的參數配置、獎勵函數設計與訓練流程，幫助您實現更加精細化的模型優化。\n這門課程由業界專家Ken Cen精心打造，從DeepSeek大語言模型的技術特點到全流程的微調、量化、LoRA、監督微調、連鎖思維推理及GRPO應用，內容全面、實戰性強。無論您是AI技術的入門者還是進階工程師，都能在這裡學到最前沿、最實用的技術知識，助力您在Generative AI領域取得突破性進展。\n立即報名，與我們一起迎接AI技術的新時代，掌握DeepSeek微調的無限可能！",
      "target_audience": [
        "AI工程师",
        "對 Deepseek 感興趣的學員",
        "研究人员 & 學者"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第9部 掌握 Llama-Index 開啟數據檢索新篇章",
      "url": "https://www.udemy.com/course/generative_ai_09/",
      "bio": "關於Query Pipeline, Chroma,VectorStore Index,Document Chunks, Streaming, Retriever, Ollama, Embedding,",
      "objectives": [
        "掌握如何與 LLM 結合使用數據索引技術",
        "掌握如何將不同格式的數據進行索引",
        "掌握如何從文本、API 到 SQL 資料庫，課程將教你如何靈活處理各種數據源",
        "掌握如何用LlamaIndex在Chroma 與 VectorStore Index的數據實現RAG",
        "掌握如何使用Query Pipeline並結合Agent實現RAG"
      ],
      "course_content": {
        "課程準備": [
          "課程工具準備",
          "如何使用Poetry"
        ],
        "LlamaIndex與LLM大語言模型聯合的使用": [
          "如何創建第一個LlamaIndex程序",
          "LlamaIndex如何處理LLM處理用戶提問"
        ],
        "LlamaIndex實現Embedding到VectorStrore應對用戶提問": [
          "如何使用LlamaIndex實現Embedding到VectorStrore應對用戶提問",
          "如何保存VectorStore Index到根目錄當中",
          "如何更好處理中文PDF的內容",
          "如何用Nodes去分割Document Chunks",
          "如何使用ChromaVectorStore創建Index和回覆用戶提問"
        ],
        "如何使用Pipeline": [
          "如何使用QueryPipeline連結LLM與Prompts",
          "如何使用QueryPipeline實現Streaming和Retriever",
          "如何透過Pandas的Dataframe創建查詢管道"
        ],
        "如何使用Agent智能體幫助實現QueryPipeline查詢": [
          "如何導入SQL查詢到QueryPipeline當中",
          "如何製作Agent的Input Component和Prompt Component.",
          "如何定義Agent Prompt和運行Agent工具",
          "如何連結modules和創建判斷條件Link",
          "如何製作自我修復的Query Pipeline Agent"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "在這個數據驅動的時代，如何快速檢索和處理大量數據成為了每個開發者和數據科學家的核心挑戰。你是否希望大幅提升大型語言模型（LLM）的效能？是否想要讓人工智慧更聰明、更高效地回答問題？Llama-Index 是你的最佳解決方案！\nLlama-Index（原 GPT Index）不僅僅是與大型語言模型結合的數據庫索引工具，它還能顯著增強你的數據處理能力，打開你進軍人工智慧領域的新大門。本課程將帶你深入學習並實作 Llama-Index，幫助你輕鬆掌握這項前沿技術，實現從基礎到進階的全面突破。\n課程亮點：\nQuery Pipeline：從基本概念到高階應用，教你如何優化查詢管線以獲得更準確、更快速的結果。\nChroma 與 VectorStore Index：掌握最熱門的向量儲存技術，實現高效的大規模數據檢索。\nDocument Chunks：了解如何將大文檔分割為可檢索的小單元，提升數據查找效率。\nStreaming 技術：即時數據流處理，打造流暢的使用者體驗。\nRetriever 技術：探索最新的檢索技術，快速精準提取關鍵數據。\nOllama 集成與 Embedding 技術：學習如何運用嵌入式技術提升數據檢索性能，並與 Ollama 進行無縫整合。\n課程知識點：\n數據索引的本質：透過這門課程，你將深入理解如何將不同格式的數據進行索引，並有效地結合 LLM 進行查詢。\n查詢增強技術：學會如何使用查詢增強技術，大幅提升語言模型的回答準確度。\n多樣化數據支持：從文本、API 到 SQL 資料庫，課程將教你如何靈活處理各種數據源。\n實戰項目：通過實戰案例（如智能客服系統），幫助你快速掌握 Llama-Index 的應用。\n性能調優：學習如何處理大規模數據，並通過各種優化技巧讓系統更高效\n立即報名，搶先學習 Llama-Index 如何引領數據檢索的未來！讓我們一起掌握這場技術革命的核心，站在數據檢索的最前沿！",
      "target_audience": [
        "對大規模數據檢索有興趣的開發者",
        "想要提升查詢效能與數據管理的資料科學家",
        "探索 AI 驅動檢索技術的新手與專家"
      ]
    },
    {
      "title": "Pythonで体系的に学ぶデータサイエンスとAIの初歩 Vol.3 線形代数・主成分分析(PCA)・自然言語処理",
      "url": "https://www.udemy.com/course/pythonai-vol3/",
      "bio": "線形代数の初歩（ベクトル、行列、線形変換、固有ベクトルと固有値）、主成分分析（分散、共分散、基底変換、座標変換、アイリスのデータセット、乳がんのデータセット）、自然言語処理の初歩（文字列操作、正規表現、形態素解析、BoW、word2vec）",
      "objectives": [
        "Pythonの基礎知識を得て、簡単なプログラムを作成できるようになります。",
        "データサイエンスやAIの学習に必要な数学・統計などの初歩的基礎知識を体系的に得ることができます。",
        "データサイエンスとAIを本格的に学ぶにあたって必要な初歩的事項を身に付けることができます。",
        "本Vol.3では特に「線形代数の初歩」、「主成分分析」、「自然言語処理の初歩」についての基礎知識を得ることができます。"
      ],
      "course_content": {
        "コースの紹介": [
          "コースの紹介"
        ],
        "Anacondaのインストール方法": [
          "Anacondaのインストール方法 Windows向け",
          "Anacondaのインストール方法 Mac向け"
        ],
        "テキスト": [
          "テキスト"
        ],
        "線形代数の初歩": [
          "テンプレートプログラム",
          "テンプレートプログラムの使い方 Windows向け",
          "テンプレートプログラムの使い方 Mac向け"
        ],
        "線形代数とは": [
          "線形代数とは"
        ],
        "ベクトル": [
          "ベクトルの作成1",
          "ベクトルの作成2",
          "ベクトルの作成3",
          "ベクトルの表示1",
          "ベクトルの表示2",
          "ベクトルの表示3"
        ],
        "内積": [
          "内積の計算1",
          "内積の計算2",
          "内積の計算3"
        ],
        "行列": [
          "行列の作成"
        ],
        "単位行列": [
          "単位行列の作成"
        ],
        "行列の演算": [
          "実数倍、和と差",
          "行列の積",
          "アダマール積"
        ]
      },
      "requirements": [
        "簡単なプログラミングの経験があった方が望ましいです。",
        "中学生レベル、できれば高校生レベルの数学的素養があると理解が早いです。"
      ],
      "description": "■「Pythonで体系的に学ぶデータサイエンスとAIの初歩」シリーズ全4巻ではデータサイエンスとAIの初歩を学ぶのに必要な数学、統計学などの初歩的基礎知識を体系的に学んでいきます。高校の新学習指導要領の「情報I」および「情報II」の内容も多く含んでいます。\n■高校生程度の数学の知識があれば理解できるように説明しているので、いきなりデータサイエンスやAIのコースは荷が重いという方にお勧めです。実際に中高生向けのプログラミング教室での実績があります。\n■Anacondaをインストールして、Jupyter Notebookでプログラミングを行なっていきます。\n■学習内容\nVol.1ではPythonの基礎、数と暗号、関数と微分\nVol.2では確率と統計、ベイズ統計、データサイエンスとAIの初歩\nVol.3では線形代数、主成分分析、自然言語処理\nVol.4ではネットワークの基礎知識、ブロックチェーン\nについて学んでいきます。\n■4コースともPDF形式のテキスト（約100ページ）が付属しています。\nまた、タイピングが大変だったり時間がないという方のためにある程度コードを記載したテンプレートプログラムをつけてあります。完成したサンプルプログラムもついています。\n■Vol.3の内容は以下の通りです。\n線形代数の初歩\n主成分分析\n自然言語処理の初歩",
      "target_audience": [
        "データサイエンスやAIに関心を持つが、いきなり本格的なAIプログラミングは困難なPythonプログラミング初心者。",
        "高校の新学習指導要領「情報I」、「情報II」レベルのプログラミングを学びたい方。",
        "高校の新学習指導要領「情報I」、「情報II」レベルのプログラミングを教えたい教師。"
      ]
    },
    {
      "title": "Python ile Makine Öğrenmesine Giriş",
      "url": "https://www.udemy.com/course/python-ile-makine-ogrenmesine-giris-2023-guncel/",
      "bio": "Makine Öğrenmesi Metotlarını Öğrenin ve Kendi Modelinizi Oluşturun",
      "objectives": [
        "Veri biliminde kullanılan Python kütüphanelerini öğrenin",
        "Veri biliminin inceliklerini anlayın",
        "Makine öğrenmesi ve derin öğrenme gibi kavramları anlayın",
        "Yapay zeka çağına kendinizi hazırlayın"
      ],
      "course_content": {
        "Nesne Tabanlı Programlama(OOP)": [
          "OOP Nedir?",
          "Sınıf Yapısı ve Method Kullanımı",
          "Init ve Str Methodları",
          "Global & Private Değişkenler",
          "Encapsulation",
          "Polymorphism",
          "Inheritance",
          "Abstract Methods",
          "Overriding",
          "Property",
          "Örnek Proje"
        ],
        "Numpy Kullanımı": [
          "Numpy Nedir?",
          "Array Yaratılması",
          "Adding, Removing ve Sorting İşlemleri",
          "Dimension, Size ve Shape İşlemleri",
          "Reshape İşlemleri",
          "Indexing ve Slicing İşlemleri",
          "Toplama,Çıkarma,Çarpma ve Bölme İşlemleri",
          "Minimum, Maksimum ve Toplam Bulma İşlemleri"
        ],
        "Pandas Kullanımı": [
          "Pandas Nedir?",
          "Seri Yaratılması",
          "Dictionary Yaratılması",
          "Dataframe Yaratılması",
          "Dataframe'in Analizi",
          "Dataframe'de Değişiklikler Yapmak",
          "Birleştirme İşlemi",
          "Null Değerler",
          "Aggretion İşlemleri",
          "Pivot İşlemi",
          "Mito Kullanımı",
          "Parquet Kullanımı",
          "Kaggle Nedir?",
          "GDP Analizi",
          "Excel'e Kaydetme"
        ],
        "Matplotlib Kullanımı": [
          "Matplotlib Nedir ?",
          "Temel Plotting İşlemleri",
          "Historgram Oluşturulması",
          "Seaborn Kullanımı",
          "Örnek Proje"
        ],
        "SQL Lite Kullanımı": [
          "SQL Lite Nedir?",
          "SQL Lite Üzerinde Veri Tabanı Yaratmak",
          "Python - SQL Lite Bağlantısı",
          "Python Üzerinde Basit Query Sorguları",
          "Örnek Proje"
        ],
        "Makine Öğrenmesi": [
          "Makine Öğrenmesi Nedir?",
          "Sckilt-Learn'e Giriş",
          "Supervised Learning - Linear Regression",
          "Supervised Learning - Classification",
          "Unsupervised Learning- Clustering",
          "Model Doğrulaması Yapmak",
          "Overfitting ve Underfitting Örnekleri",
          "Polynomial Regression Kullanımı",
          "Validation Curve Kullanarak Modeli Bulma",
          "GridSearch Kullanarak Modeli Bulma",
          "Model Kaydetme ve Okuma"
        ],
        "İleri Seviye Algoritmalar": [
          "Naive Bayes Classification",
          "Support Vector Machine",
          "Random Forest",
          "Manifold Learning",
          "K-Means",
          "Gaussian Mixture Models",
          "Kernel Density"
        ],
        "BONUS BÖLÜMLER": [
          "Binance API ile Veri Çekmek"
        ]
      },
      "requirements": [
        "Python 101 kursumu almanız gerekiyor"
      ],
      "description": "\"Python ile Makine Öğrenmesi\" kursu, makine öğrenmesi konusunda temel becerileri edinmek veya mevcut bilgilerinizi derinleştirmek isteyen herkes için tasarlanmış kapsamlı bir kursudur. Bu kurs, Python programlama dilini kullanarak makine öğrenmesi modelleri oluşturmayı ve verileri analiz etmeyi öğretmek amacıyla hazırlanmıştır.\nKursa başlarken, Python programlama dilinin temel kavramlarını öğreniyoruz ve ardından makine öğrenmesine yönelik temel prensipleri ele alıyoruz. Kurs, popüler Python kütüphaneleri olan Numpy, Pandas ve Matplotlib'i kullanarak veri manipülasyonu, veri görselleştirme ve model eğitimi konularını kapsamlı bir şekilde ele alıyor.\nBu kurs, sınıflandırma, regresyon ve kümeleme gibi temel makine öğrenmesi algoritmalarını öğrenmenizi sağlayarak, verileri analiz etme ve tahminleme becerilerinizi geliştirir. Ayrıca, verileri depolamak ve sorgulamak için SQLite veritabanını kullanarak gerçek dünya projeleri üzerinde uygulamalar yapmayı öğreniyoruz.\nKurs ayrıca Nesne Tabanlı Programlama (OOP) prensiplerini vurgulayarak, kodunuzun düzenli ve yeniden kullanılabilir olmasını sağlar. Bu sayede, makine öğrenmesi modelleri üzerinde daha etkili bir şekilde çalışabilirsiniz.\n\"Python ile Makine Öğrenmesi\" kursu, makine öğrenmesi modelleri, Matplotlib, Numpy, OOP, Pandas ve SQLite gibi temel konulara odaklanan kapsamlı bir kurs. Kurs, Python programlama dilini kullanarak veri analizi, model oluşturma ve veri görselleştirme becerilerinizi geliştirmenizi sağlar. Matplotlib ile grafikler çizmeyi, Numpy ile verileri işlemeyi, Pandas ile veri manipülasyonunu, OOP ile kod düzenini ve veritabanlarına erişimi öğrenirsiniz. SQLite kullanarak gerçek projeler üzerinde çalışarak pratik deneyim kazanacaksınız. Kurs, Python programlama bilgisine sahip herkes için uygun olup, makine öğrenmesine temel bir giriş sunar. \"Python ile Makine Öğrenmesi\" kursu, öğrencilere güçlü bir temel sağlayarak, makine öğrenmesi alanında kendi projelerini başlatmalarına olanak tanır.",
      "target_audience": [
        "Veri bilimine meraklı ve yeni bilgiler edinmek isteyen Python yazılımcıları"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第五部（前端） - Generative UI 生成式UI",
      "url": "https://www.udemy.com/course/generative-ui-client/",
      "bio": "使用AI SDK，NextJS，Langchain.js編寫前端連結後端LangGraph",
      "objectives": [
        "如何配置NextJS編寫環境",
        "了解NextJS的程序結構",
        "如何創建NextJS程序",
        "如何使用NextJS建立路由"
      ],
      "course_content": {
        "用NextJS創建第一個程序": [
          "如何配置環境及創建第一個Next.JS項目"
        ],
        "Next JS基礎": [
          "如何在NextJS中使用Routing",
          "如何使用Server Component & Client Component",
          "如何使用Server-only和Client-only",
          "如何使用Layout文檔改變頁面佈局",
          "如何接入及使用Shadcn-UI",
          "如何自訂義Shadcn-UI component組件"
        ],
        "Next JS進階": [
          "如何使用useContext與createContext",
          "如何Generic泛型修復undefined問題",
          "如何用useContext去創建Weather UI"
        ],
        "AI SDK 與 LangChain.js": [
          "如何在Next JS中接入AI SDK",
          "如何在伺服器和客戶端生成串流Stream",
          "如何在使用AI SDK 創建串流UI"
        ],
        "Generative UI Frontend": [
          "創建項目Page tsx文檔",
          "如何創建Remote Runnable Object",
          "如何創建Loading與Final UI",
          "如何創建Search Tool的Loading與Final UI",
          "如何使用Promise Resolve",
          "如何在Server文檔中獲得InvokeModel與InvokeTool的返回結果",
          "如何在將後端獲得的數據分享給其他Components",
          "如何在完成HumanMessage&AIMessage的內容",
          "如何在完成Chat頁面的顯示",
          "如何編寫Chat聊天部分"
        ]
      },
      "requirements": [
        "一台電腦",
        "需要一定JS基礎",
        "學習過Generative AI第一到第四部內容"
      ],
      "description": "發現下一代UI開發的無限可能——加入我們的Generative UI生成式UI課程！\n在這個充滿挑戰和機遇的時代，AI與UI的結合不僅僅是一種趨勢，更是未來開發的重要方向。你是否準備好迎接這一變革，成為下一代技術專家的其中一員？\n我們將深入探討如何將AI與UI無縫結合，創建出能夠根據不同用戶需求自動生成的用戶界面。\n在前一部課程中，我們已經介紹了如何使用lang serve和langGraph製作Fast API endpoint和後端部分。這一次，我們將帶你進一步，專注於前端的開發。我們將使用Next.js、TypeScript、shadcn-ui、langchain.js和AI SDK來構建這些前端部分，展示如何接收和處理後端傳遞過來的數據，並在網頁中生成動態的用戶界面。\n這門課程涵蓋：\nStreaming和Next.js的數據處理：學習如何在伺服器和客戶端之間進行高效的數據處理。\nLangchain.js的使用：深入了解如何在JavaScript中應用人工智能技術，連結LLM大語言模型與langGraph的各個節點。\nShadcn-ui的UI生成：探索如何利用shadcn-ui來生成動態且適應性強的用戶界面。\nAI與UI的協同工作：詳細講解各個技術如何協同工作，創建出智能且高效的用戶界面。\n這門課程適合那些希望掌握最新AI技術並應用於實際UI開發中的開發者，不論你是初學者還是有經驗的開發者，都能從中獲得實用的知識和技能。\n不要錯過這個機會，讓我們一起探索AI與UI的無限可能，創造出令人驚嘆的用戶體驗！\n立即報名，成為下一代UI開發的領軍人物！",
      "target_audience": [
        "開發人員和技術愛好者",
        "希望了解Next JS的學生",
        "希望用NextJS編寫代碼的學生"
      ]
    },
    {
      "title": "Pemrograman Data dengan MS Excel dan Python",
      "url": "https://www.udemy.com/course/pemrograman-data-dengan-ms-excel-dan-python/",
      "bio": "Pelajari Langkah Demi Langkah Menggunakan Python untuk Memproses, Menganalisis, dan Memvisualisasikan Data di MS Excel",
      "objectives": [
        "Instalasi Python dan Visual Studio Code",
        "Konsep Dasar Pemrograman Python",
        "Pembuatan Function, Contoh Kasus Fungsi Menghitung Jumlah Tabungan di Bank",
        "Mengenal Libraries/Package, Menginstall OpenpyXL",
        "Python untuk MS Excel, Mengakses dan Mengubah Data di dalam Sheet",
        "Menggunakan VLOOKUP, Clean dan Remove Duplicate",
        "Python dan Visualisasi Data MS Excel"
      ],
      "course_content": {
        "Setup": [
          "Instalasi Python dan Visual Studio Code",
          "Pembuatan Project Baru"
        ],
        "Konsep Dasar Pemrograman Python": [
          "Variabel",
          "Fungsi print()",
          "List",
          "Dictionary",
          "Logika If",
          "Perulangan"
        ],
        "Function": [
          "Membuat Fungsi",
          "Parameter dan Argumen",
          "Fungsi Matematika",
          "Contoh Fungsi Matematika Terapan",
          "Contoh Kasus: Menghitung Bunga Bank",
          "Contoh Kasus; Menghitung Jumlah Genteng"
        ],
        "Libraries": [
          "Mengenal Libraries/Packages",
          "Menginstall OpenpyXL"
        ],
        "Python untuk MS Excel": [
          "Load Workbook",
          "Mengakses dan Mengubah Data di dalam Sheet",
          "Membuat dan Memilih Sheet",
          "Membuat Workbook Baru",
          "Update Data"
        ],
        "Python dan Data MS Excel": [
          "Fungsi dan Formula",
          "Vlookup",
          "Range dan Analisis Data",
          "Clean dan Remove Data"
        ],
        "Python dan Visualisasi Data": [
          "Membuat Chart",
          "Membuat Bar Chart"
        ]
      },
      "requirements": [
        "MS Excel"
      ],
      "description": "Apakah Anda ingin menguasai cara memanipulasi dan menganalisis data di MS Excel menggunakan Python? Kursus ini dirancang untuk membantu Anda meningkatkan efisiensi kerja dengan menggabungkan kekuatan Python dan MS Excel. Dari dasar hingga mahir, Anda akan mempelajari teknik pemrograman yang dapat langsung diterapkan dalam pekerjaan atau studi Anda.\nDengan pendekatan praktis, kursus ini memungkinkan Anda memahami konsep fundamental Python dan menerapkannya pada berbagai kasus pengolahan data nyata.\n\n\nApa yang Akan Anda Pelajari?\nCara menginstal Python dan mempersiapkan komputer untuk analisis data.\nKonsep dasar pemrograman Python, mulai dari variabel hingga logika perulangan.\nTeknik pembuatan fungsi yang dapat digunakan untuk memecahkan masalah sehari-hari, seperti menghitung tabungan atau kebutuhan material.\nIntegrasi Python dengan MS Excel untuk manipulasi data, seperti membuat workbook, memperbarui data, dan membersihkan data.\nAnalisis dan visualisasi data menggunakan grafik yang menarik dan informatif.\n\n\nMengapa Harus Mengambil Kursus Ini?\nLangsung ke Inti: Materi difokuskan pada kasus-kasus praktis yang relevan dengan kebutuhan dunia kerja dan studi.\nBersifat Modular: Anda dapat belajar sesuai waktu yang tersedia tanpa merasa terbebani.\nDukungan Lengkap: Selain penjelasan video, Anda juga akan mendapatkan latihan, dokumen, dan materi pendukung lainnya untuk memperkuat pemahaman.\nPenghematan Waktu: Pelajari cara otomatisasi tugas-tugas data di MS Excel yang sebelumnya dilakukan secara manual.\n\n\nManfaat Kursus untuk Anda\nOtomasi Pekerjaan: Kurangi pekerjaan manual dengan membuat skrip Python untuk MS Excel.\nPeningkatan Karier: Keterampilan Python dan MS Excel adalah kombinasi yang sangat dicari di dunia kerja.\nPendekatan Hands-On: Setiap topik disertai dengan contoh nyata yang dapat Anda praktikkan langsung.\nEfisiensi dalam Analisis Data: Temukan cara membersihkan, mengelompokkan, dan menganalisis data secara cepat.\n\n\nUntuk Siapa Course Ini?\nPemula yang belum pernah belajar Python tetapi ingin menggunakannya untuk pengolahan data.\nProfesional yang ingin meningkatkan efisiensi kerja dengan mengintegrasikan Python dan MS Excel.\nMahasiswa yang ingin menguasai alat bantu analisis data untuk proyek penelitian.\nSiapa saja yang ingin mempelajari Python dengan pendekatan praktis dan aplikatif.\n\n\nApa yang Anda Dapatkan?\nAkses penuh ke semua video dan materi.\nSertifikat penyelesaian resmi dari Udemy.\nForum T&J melalui Platform Udemy.\nUpdate konten gratis seumur hidup.\n\n\nJaminan Kepuasan 100%\nKami percaya kursus ini akan membantu Anda mencapai tujuan Anda. Namun, jika Anda merasa kursus ini tidak sesuai dengan kebutuhan Anda, Udemy memberikan jaminan 30 hari uang kembali. Jadi, Anda tidak perlu ragu untuk bergabung.\n\n\nAyo Mulai Sekarang!\nMulailah perjalanan Anda menguasai Python dan MS Excel untuk pengolahan data. Jangan lewatkan kesempatan untuk meningkatkan keterampilan Anda dan membuka peluang baru dalam karier atau studi Anda!",
      "target_audience": [
        "Pemula yang belum pernah belajar Python tetapi ingin menggunakannya untuk pengolahan data.",
        "Profesional yang ingin meningkatkan efisiensi kerja dengan mengintegrasikan Python dan MS Excel.",
        "Mahasiswa yang ingin menguasai alat bantu analisis data untuk proyek penelitian.",
        "Mahasiswa yang ingin menguasai alat bantu analisis data untuk proyek penelitian."
      ]
    },
    {
      "title": "R-Analyst - Lerne die statistische Programmiersprache R",
      "url": "https://www.udemy.com/course/r-analyst/",
      "bio": "Lerne die statistische Programmiersprache R",
      "objectives": [
        "In diesem Kurs lernst du mit R umzugehen.",
        "Nach einer Einführung in die Programmiersprache, wirst du lernen, Daten einzuladen, einfach mit unseren Daten umzugehen und diese ansprechend zu visualisieren.",
        "Anschließend lernst du, mit räumlichen Daten umzugehen und dynamische Visualisierungen zu erzeugen, die du bspw. auch in einer Internetseite einbinden kannst..",
        "Zum Schluss lernst du das Programmieren mit R kennen, was es dir erlauben wird, Prozesse zu automatisieren."
      ],
      "course_content": {
        "Kursübersicht, Schulungsdaten & R-Skripte": [
          "Kursübersicht",
          "Schulungsdaten & R-Skripte",
          "Nutzungsbedingungen"
        ],
        "Einführung in die Programmiersprache R": [
          "Kurzvorstellung, Installation und erste Schritte",
          "R-Tipp: RStudio und R-Versionen",
          "Datentypen",
          "R-Tipp: RStudio Themes",
          "R-Tipp: Encodierung",
          "Indizierung",
          "Übung",
          "Musterlösung zur Übung",
          "Daten Import/Export",
          "R-Tipp: Skript-Abschnitte"
        ],
        "Daten-Handling mit dplyr": [
          "Fortgeschrittenes Daten-Handling mit dplyr",
          "dplyr-Übung",
          "Musterlösung zur dplyr-Übung"
        ],
        "Visualisierungen": [
          "Datenvisualisierung mit base-R",
          "Datenvisualisierung mit base-R - Übung",
          "Datenvisualisierung mit base-R - Musterlösung zur Übung",
          "R-Tipp: Daten in graphischer Tabellenform",
          "R-Tipp: Plot-Koordinaten abrufen",
          "Fortgeschrittene Datenvisualisierung mit ggplot2",
          "Fortgeschrittene Datenvisualisierung mit ggplot2 - Übung",
          "Fortgeschrittene Datenvisualisierung mit ggplot2 - Musterlösung zur Übung"
        ],
        "Räumliche Daten": [
          "Räumliche Daten in R",
          "Räumliche Daten - Übung",
          "Räumliche Daten - Musterlösung zur Übung"
        ],
        "Programmieren mit R": [
          "Programmieren mit R",
          "Programmieren mit R - Übung",
          "Programmieren mit R - Musterlösung"
        ],
        "Abschluss": [
          "Abschluss"
        ]
      },
      "requirements": [
        "Es bestehen keine Anforderungen oder Voraussetzungen für diesen Kurs. Es werden alle mitgenommen und schnell und verständlich an die Arbeiten mit R herangeführt. Ein hoher Lernerfolg ist in der Regel der Lohn unserer Neugierde."
      ],
      "description": "Hallo und herzlich willkommen zu R,\nIn diesem Kurs werden wir lernen mit R umzugehen. Nach einer Einführung in die Programmiersprache, werden wir lernen, Daten einzuladen, einfach mit unseren Daten umzugehen und diese ansprechend zu visualisieren. Anschließend lernen wir, mit räumlichen Daten umzugehen und dynamische Visualisierungen zu erzeugen, die wir bspw. auch in unsere Internetseite einbinden können. Zum Schluss lernen wir das Programmieren mit R kennen, was es uns erlauben wird, unsere Prozesse zu automatisieren.\nEs bestehen keine Anforderungen oder Voraussetzungen für diesen Kurs. Es werden alle mitgenommen und schnell und verständlich an die Arbeiten mit R herangeführt. Ein hoher Lernerfolg ist in der Regel der Lohn deiner Neugierde. Du wirst schnell feststellen, dass es sich lohnt in diese einfach zu erlernende Programmiersprache einzusteigen. Prozese lassen sich automatisieren, Analyse lassen sich vereinheitlichen, Visualisierungen wirken professioneller und besser für den jeweiligen Kontext geeignet und Berichte aktuallisieren sich auf Knopfdruck für das aktuelle Jahr. Das macht unsere Arbeiten nicht nur reproduzierbarer und transparenter, wir schaffen auch Zeit, um uns über wichtigere Dinge Gedanken zu machen, als stumpfe, wiederkehrende Arbeiten.\nDieser Kurs richtet sich an alle, die mit Daten arbeiten. R erleichtert und professionalisiert alle Prozesse im Umgang mit Daten inkl. deren Visualisierung.\nFolgende Inhalte wirst du in diesem Kurs zu beherrschen lernen:\nTeil 1: Einführung in die Programmiersprache R\nKurzvorstellung der Programmiersprache R\nDatentypen, Datenmodi\nIndizierung\nTabellarische Daten einladen\nDatenexport\nHilfe holen\nÜbungen\nTeil 2: Daten-Handling mit dplyr\nTeil 3: Visualisierungen\nDatenvisualisierung mit base-r\nDatenvisualisierung mit ggplot2\nTeil 4 – Räumliche Daten\nRäumliche Daten einladen\nAuf Attribute zugreifen & visualisieren\nEinfache Geoprozessierung\nRaster in R\nTeil 5 – Programmieren mit R\nFunktionen selber definieren\nLogische Abfragen\nSchleifen\nViel Spaß mit R!",
      "target_audience": [
        "Alle, die mit Daten arbeiten. R erleichtert und professionalisiert alle Prozesse im Umgang mit Daten inkl. deren Visualisierung."
      ]
    },
    {
      "title": "[ES] Curso de Certificación de Ingeniero Asociado en IA",
      "url": "https://www.udemy.com/course/es-curso-de-certificacion-de-ingeniero-asociado-en-ia/",
      "bio": "Domina el Aprendizaje Automático, el Aprendizaje Profundo y los Fundamentos de Agentes de IA con TensorFlow y PyTorch",
      "objectives": [
        "Realizar ingeniería avanzada de características para modelos de aprendizaje automático",
        "Evaluar el rendimiento del modelo utilizando precisión, recall, F1 y AUC",
        "Aplicar algoritmos como árboles de decisión, bosques aleatorios y gradient boosting",
        "Comprender conceptos de deep learning como activación y retropropagación",
        "Construir redes neuronales desde cero utilizando Python",
        "Entrenar y desplegar modelos usando TensorFlow y Keras",
        "Usar PyTorch para construir, optimizar y evaluar modelos de deep learning",
        "Comprender los fundamentos de los agentes de IA y sus aplicaciones en el mundo real"
      ],
      "course_content": {
        "Introducción al curso y al instructor": [
          "Qué aprenderás en el Curso de Certificación de Ingeniero Asociado en IA"
        ],
        "Ingeniería de características y evaluación de modelos": [
          "Día 1: Introducción a la ingeniería de características",
          "Día 2: Escalado y normalización de datos",
          "Día 3: Codificación de variables categóricas",
          "Día 4: Técnicas de selección de características",
          "Día 5: Creación y transformación de características",
          "Día 6: Técnicas de evaluación de modelos",
          "Día 7: Validación cruzada y ajuste de hiperparámetros",
          "Recursos para proyectos en formación"
        ],
        "Algoritmos avanzados de aprendizaje automático": [
          "Día 1: Introducción al aprendizaje por conjuntos (ensemble)",
          "Día 2: Bagging y bosques aleatorios",
          "Día 3: Boosting y gradient boosting",
          "Día 4: Introducción a XGBoost",
          "Día 5: LightGBM y CatBoost",
          "Día 6: Manejo de datos desbalanceados",
          "Día 7: Proyecto conjunto – Comparación de modelos con datos reales",
          "Recursos para proyectos en formación"
        ],
        "Redes neuronales y fundamentos del aprendizaje profundo": [
          "Día 1: Introducción al aprendizaje profundo y redes neuronales",
          "Día 2: Propagación hacia adelante y funciones de activación",
          "Día 3: Funciones de pérdida y retropropagación",
          "Día 4: Descenso de gradiente y técnicas de optimización",
          "Día 5: Construcción de redes neuronales con TensorFlow y Keras",
          "Día 6: Construcción de redes neuronales con PyTorch",
          "Día 7: Proyecto de red neuronal – Clasificación de imágenes con CIFAR-10",
          "Recursos para proyectos en formación"
        ],
        "Algoritmos e implementaciones de aprendizaje automático": [
          "Introducción a los algoritmos de aprendizaje automático",
          "Implementación de regresión lineal en Python",
          "Implementación de regresión Ridge y Lasso en Python",
          "Implementación de regresión polinómica en Python",
          "Implementación de regresión logística en Python",
          "Implementación de K-Vecinos más Cercanos (KNN) en Python",
          "Implementación de Máquinas de Vectores de Soporte (SVM) en Python",
          "Implementación de árboles de decisión en Python",
          "Implementación de bosques aleatorios en Python",
          "Implementación de gradient boosting en Python",
          "Implementación de Naive Bayes en Python",
          "Implementación de clustering K-Means en Python",
          "Implementación de clustering jerárquico en Python",
          "Implementación de DBSCAN (Agrupamiento Basado en Densidad) en Python",
          "Implementación de Modelos de Mezcla Gaussiana (GMM) en Python",
          "Implementación de Análisis de Componentes Principales (PCA) en Python",
          "Implementación de t-SNE (t-Distributed Stochastic Neighbor Embedding) en Python",
          "Implementación de autoencoders en Python",
          "Implementación de autoentrenamiento (self-training) en Python",
          "Implementación de Q-Learning en Python",
          "Implementación de Redes Q Profundas (DQN) en Python",
          "Implementación de métodos de política por gradiente en Python",
          "Implementación de SVM de una sola clase en Python",
          "Implementación de bosques de aislamiento en Python",
          "Implementación de redes neuronales convolucionales (CNNs) en Python",
          "Implementación de redes neuronales recurrentes (RNNs) en Python",
          "Implementación de LSTM (memoria a largo y corto plazo) en Python",
          "Implementación de transformadores en Python"
        ],
        "Introducción al aprendizaje automático y TensorFlow": [
          "¿Qué es el aprendizaje automático?",
          "Introducción a TensorFlow",
          "TensorFlow vs. otros frameworks de aprendizaje automático",
          "Instalación de TensorFlow",
          "Configuración del entorno de desarrollo",
          "Verificación de la instalación",
          "Introducción a los tensores",
          "Operaciones con tensores",
          "Constantes, variables y placeholders",
          "Grafo computacional de TensorFlow",
          "Creación y ejecución de una sesión de TensorFlow",
          "Gestión de grafos y sesiones",
          "Construcción de una red neuronal feedforward simple",
          "Funciones de activación",
          "Funciones de pérdida y optimizadores",
          "Introducción a la API de Keras",
          "Construcción de modelos complejos con Keras",
          "Entrenamiento y evaluación de modelos",
          "Introducción a las CNNs",
          "Construcción y entrenamiento de CNNs con TensorFlow",
          "Aprendizaje por transferencia con CNNs preentrenadas",
          "Introducción a las RNNs",
          "Construcción y entrenamiento de RNNs con TensorFlow",
          "Aplicaciones de RNNs: modelado de lenguaje, predicción de series temporales",
          "Guardado y carga de modelos",
          "TensorFlow Serving para despliegue de modelos",
          "TensorFlow Lite para dispositivos móviles y embebidos",
          "Introducción a la computación distribuida con TensorFlow",
          "Framework de ejecución distribuida de TensorFlow",
          "Escalado de TensorFlow con Serving y Kubernetes",
          "Introducción a TFX",
          "Construcción de pipelines de ML de extremo a extremo con TFX",
          "Validación, transformación y despliegue de modelos con TFX",
          "Clasificación de imágenes",
          "Procesamiento de lenguaje natural",
          "Sistemas de recomendación",
          "Detección de objetos",
          "Creación de un modelo de análisis de sentimientos",
          "Creación de un sistema de reconocimiento de imágenes",
          "Desarrollo de un modelo de predicción de series temporales",
          "Implementación de un chatbot",
          "Redes generativas adversarias (GANs)",
          "Aprendizaje por refuerzo con TensorFlow",
          "Aprendizaje automático cuántico con TensorFlow Quantum",
          "Documentación y tutoriales de TensorFlow",
          "Cursos en línea y libros",
          "Comunidad y foros de TensorFlow",
          "Resumen de conceptos clave",
          "Próximos pasos en tu camino con TensorFlow"
        ],
        "Introducción al aprendizaje con PyTorch": [
          "Introducción a PyTorch",
          "Primeros pasos con PyTorch",
          "Trabajo con tensores",
          "Autograd y grafos computacionales dinámicos",
          "Construcción de redes neuronales simples",
          "Carga y preprocesamiento de datos",
          "Evaluación y validación de modelos",
          "Arquitecturas avanzadas de redes neuronales",
          "Aprendizaje por transferencia y ajuste fino",
          "Manejo de datos complejos",
          "Despliegue y producción de modelos",
          "Depuración y resolución de problemas",
          "Entrenamiento distribuido y optimización del rendimiento",
          "Capas personalizadas y funciones de pérdida",
          "Técnicas orientadas a investigación",
          "Integración con otras bibliotecas",
          "Contribución a PyTorch y participación en la comunidad"
        ],
        "Agentes de IA para principiantes": [
          "1.1: Comprendiendo los agentes de IA - Cómo funcionan",
          "1.2: Introducción a los agentes de IA",
          "1.3: Tipos de agentes de IA",
          "2.1: Tecnologías detrás de los agentes de IA - Aprendizaje automático y agentes",
          "2.2: Procesamiento de lenguaje natural en agentes de IA",
          "2.3: Agentes de IA en robótica",
          "3.1: Frameworks y arquitecturas para agentes de IA",
          "3.2: Descripción general de AutoGPT para agentes de IA",
          "3.3: Framework IBM Bee para agentes de IA",
          "3.4: LangGraph para agentes de IA con estado",
          "3.5: CrewAI para agentes de IA colaborativos",
          "4.1: Aplicaciones de los agentes de IA - Operaciones empresariales",
          "4.2: Agentes de IA en el sector salud",
          "4.3: Agentes de IA en sistemas financieros",
          "4.4: Agentes de IA en entretenimiento",
          "4.5: Agentes de IA en hogares inteligentes e IoT",
          "5.1: Tendencias futuras e implicaciones éticas - El futuro de los agentes de IA",
          "5.2: Ética en el desarrollo de agentes de IA",
          "5.3: Desafíos legales y regulatorios de los agentes de IA",
          "6.1: Impacto más amplio de los agentes de IA - Impactos sociales y económicos",
          "6.2: Colaboración entre humanos y agentes de IA",
          "6.3: El papel de los agentes de IA en la investigación científica",
          "6.4: Agentes de IA en seguridad pública y defensa nacional"
        ],
        "Felicitaciones": [
          "Examen final de opción múltiple",
          "¡Felicidades y mucha suerte!"
        ]
      },
      "requirements": [
        "Conocimientos básicos de programación en Python, incluyendo funciones, bucles y estructuras de datos",
        "Haber cursado una introducción a la ciencia de datos o completado un curso de IA para principiantes",
        "Familiaridad con conceptos básicos de matemáticas como álgebra, funciones y vectores",
        "Tener alguna comprensión de probabilidad y estadística es útil, pero no obligatorio",
        "Una computadora (Windows, macOS o Linux) con acceso estable a internet",
        "Capacidad para instalar y trabajar con herramientas como Jupyter Notebook, TensorFlow y PyTorch (se proporcionan instrucciones de instalación)",
        "Curiosidad y motivación para explorar conceptos de IA de nivel intermedio a avanzado",
        "Disposición para participar en codificación práctica y aprendizaje basado en proyectos"
      ],
      "description": "Lleva tus habilidades en IA al siguiente nivel con el Curso de Certificación de Ingeniero Asociado en IA: un programa práctico de nivel intermedio diseñado para ayudarte a desarrollar experiencia en el mundo real en aprendizaje automático, aprendizaje profundo y desarrollo de agentes de IA. Ya seas un aspirante a ingeniero de IA, un profesional de la ciencia de datos o un desarrollador que busca mejorar sus habilidades, este curso te brinda una base sólida en técnicas avanzadas de IA y en herramientas altamente demandadas como TensorFlow y PyTorch.\nComenzamos con Ingeniería de Características y Evaluación de Modelos, donde aprenderás a preparar datos para el aprendizaje automático, extraer características significativas y evaluar el rendimiento del modelo utilizando métricas como precisión, recall, F1 score y ROC-AUC. Estas habilidades son esenciales para construir modelos precisos, confiables y listos para producción.\nLuego abordamos Algoritmos Avanzados de Machine Learning, donde explorarás implementaciones reales de árboles de decisión, bosques aleatorios, gradient boosting, XGBoost y aprendizaje por conjuntos. Comprenderás cuándo y cómo aplicar cada algoritmo según el tipo de datos y el problema a resolver.\nDespués nos sumergimos en Redes Neuronales y Fundamentos del Deep Learning, brindándote una comprensión clara de perceptrones, funciones de activación, retropropagación y arquitecturas de red. Esta sección sienta las bases para que puedas construir tus propios modelos de aprendizaje profundo desde cero.\nEn la sección de Algoritmos de ML e Implementaciones, obtendrás experiencia práctica programando una variedad de algoritmos desde cero. Reforzarás tu comprensión tanto teórica como práctica de los modelos más populares, al mismo tiempo que fortaleces tu dominio de Python y tu razonamiento matemático.\nLuego exploramos el Aprendizaje Automático con TensorFlow, donde construirás, entrenarás y evaluarás modelos utilizando uno de los marcos de deep learning más adoptados en la industria. Aprenderás a crear modelos con Keras, trabajar con operaciones tensoriales y utilizar ciclos de entrenamiento personalizados, esenciales para soluciones de IA escalables.\nA continuación, viene el Aprendizaje con PyTorch, donde experimentarás cómo usar este marco de aprendizaje profundo flexible y poderoso para implementar desde regresión logística hasta redes neuronales convolucionales (CNNs). Comprenderás autograd, optimizadores y cómo entrenar modelos en un entorno modular y amigable para la investigación.\nFinalmente, presentamos Agentes de IA para Principiantes, una sección accesible pero poderosa sobre agentes autónomos y arquitecturas basadas en agentes. Comprenderás el papel de los agentes de IA en la toma de decisiones, la planificación y la automatización de tareas, con ejemplos actuales como chatbots, sistemas de recomendación y coordinación multi-agente.\nAl finalizar el curso, podrás:\nConstruir y desplegar modelos avanzados de ML\nComprender las matemáticas y el código detrás de las redes neuronales\nUsar TensorFlow y PyTorch con confianza\nTrabajar con conceptos y aplicaciones prácticas de agentes de IA\nPrepararte para roles de IA más especializados o certificaciones\nYa sea que quieras conseguir un trabajo como Ingeniero de Machine Learning, Desarrollador de IA o simplemente profundizar tu comprensión de la inteligencia artificial, este curso te brinda todo lo que necesitas para tener éxito.\n¡Únete a miles de estudiantes y obtén hoy tu Certificado de Ingeniero Asociado en IA—el siguiente paso para convertirte en un ingeniero de IA full-stack!",
      "target_audience": [
        "Ingenieros de IA aspirantes que están listos para ir más allá de los conceptos básicos",
        "Desarrolladores de software que desean hacer la transición hacia la IA o mejorar sus habilidades en aprendizaje automático",
        "Analistas de datos o científicos de datos junior que buscan especializarse en soluciones impulsadas por IA",
        "Estudiantes de informática o campos relacionados que quieren experiencia práctica con marcos de aprendizaje automático del mundo real",
        "Profesionales tecnológicos que desean construir un portafolio de proyectos de IA de nivel intermedio",
        "Gerentes de producto y líderes técnicos que necesitan una comprensión más profunda de cómo se entrenan, evalúan y despliegan los modelos de IA"
      ]
    },
    {
      "title": "빅데이터분석기사 완전정복 필기편 : Part.3. 빅데이터 모델링(1)",
      "url": "https://www.udemy.com/course/part3-1-x/",
      "bio": "빅데이터 모델링 배우기! 분석 모형 설계부터 분석 기법 적용까지 함께 학습합시다.",
      "objectives": [
        "빅데이터 모델링",
        "분석 절차 수립, 분석 환경 구축",
        "고급 분석기법",
        "분석 모형 설계 예상문제 풀이",
        "분석기법 적용 과목 마무리 문제 풀이"
      ],
      "course_content": {
        "빅데이터 모델링 : 분석 모형 설계(분석 절차 수립, 분석 환경 구축)": [
          "분석 절차 수립(분석 모형 선정 개념, 방법, 통계기반 분석 모형 선정 개념, 종류 7가지, 데이터 마이닝 개념, 분류, 예측 모델)",
          "분석 절차 수립(군집화, 연관규칙 모델 개념 및 예시, 머신러닝 기반 분석 모형 선정 개념, 순서 지도학습, 비지도학습, 강화학습)",
          "분석 절차 수립(준지도, 전이학습 개념 및 예시, 학습방법에 따른 분석 모형, 독립변수와 종속변수에 따른 분석기법)",
          "분석 절차 수립(분석 모형 정의 개념, 매개변수와 초매개변수 차이, 특징, 예시, 분석 모형 구축 절차)",
          "분석 환경 구축(분석 도구 선정, R과 Python의 특징과 차이점, Data Split 개념, 목적, 데이터 종류 3가지)",
          "분석 모형 설계 예상문제 풀이-1",
          "분석 모형 설계 예상문제 풀이-2",
          "분석 모형 설계 예상문제 풀이-3"
        ],
        "빅데이터 모델링 : 분석기법 적용(고급 분석기법1)": [
          "고급 분석기법(범주형 자료 분석, 분할표 분석, 상대위험도, 승산비 각각 개념, 공식, 예시)",
          "고급 분석기법(카이제곱 검정 개념, 종류, 모수, 비모수적 통계방법, T-검정 개념, 종류, 피셔의 정확 검정)",
          "고급 분석기법(다변량 분석, 상관관계 분석, 다차원척도법, 다변량 분산 분석, 주성분 분석 각각 개념, 특징)",
          "고급 분석기법(시계열 분석 개념, 정상성, 비정상성, 시계열 데이터 예측 방법 종류)",
          "고급 분석기법(시계열 데이터 공분산 기법, 시계열 모형, ARIMA 모형, 시계열 분해 구성요소 4가지)",
          "고급 분석기법(베이지안 기법, 조건부 확률, 베이지 정리 개념, 공식, 나이브 베이즈 분류 개념, 특징)",
          "고급 분석기법(딥러닝 개념, DNN(심층신경망), CNN(합성곱 신경망) 알고리즘 개념, 특징, 구조, CNN Feature Map공식, 풀링)",
          "고급 분석기법(RNN의 개념 문제점, 구조, LSTM의 개념, 구성 게이트, GRU 개념, 특징, GAN(생성적 적대 신경망)알고리즘, 딥 페이",
          "고급 분석기법(비정형 데이터 분석 개념, 종류, 텍스트 마이닝 개념, 절차, 텍스트 전처리 기법 5가지)",
          "고급 분석기법(텍스트 전처리 기법 5가지 개념, 예시, 벡터화 개념, 벡터화 방법 4가지의 개념, 특징)"
        ],
        "빅데이터 모델링 : 분석기법 적용(고급 분석기법2)": [
          "고급 분석기법(오피니언 마이닝, 웹 마이닝, 사회 연결망 분석 각각의 개념, 특징, 절차)",
          "고급 분석기법(앙상블 분석 개념, 특징, 종류 5가지, 배깅(Bagging)기법의 개념, 특징)",
          "고급 분석기법(랜덤 포레스트, 보팅, 부스팅, 부스팅 알고리즘, 스태킹 각각의 개념, 특징)",
          "고급 분석기법(비모수 통계 분석 개념, 특징, 종류 6가지 설명)",
          "고급 분석기법 예상문제 풀이-1",
          "고급 분석기법 예상문제 풀이-2",
          "분석기법 적용 과목 마무리 문제 풀이-1",
          "분석기법 적용 과목 마무리 문제 풀이-1"
        ]
      },
      "requirements": [
        "\"한번에 합격하겠다는 의지! 데이터 통계와 데이터 보안 관련 분야 지식이 있으면 좋습니다.\""
      ],
      "description": "안녕하세요, ITGO 입니다.\n\n\n본 강의는 빅데이터분석기사 완전정복 필기편 : Part.3. 빅데이터 모델링(1) 강의입니다.\n\n\n빅데이터 분석 기사는 국가 기술 자격증으로 필기와 실기 시험이 있습니다.\n\n\n본 강의는 빅데이터 분석 기사 자격증 취득을 위한 필기 시험 대비 강의입니다.\n\n\n빅데이터 분석 기사 필기 시험 핵심 개념부터 예상 문제 풀이까지 제대로 배워 한번에 합격합시다!\n\n\n\n\n누구를 위한 강의인가요?\n\n\n빅데이터 분석기사(필기) 자격증 취득을 원하시는 분들\n\n\n데이터 분석 직무로의 취업 및 이직을 준비하시는 분들\n\n\n데이터 분석에 대해 공부하고자 하시는 분들\n\n\n\n\n무엇을 배우나요?\n\n\n빅데이터 모델링\n\n\n분석 모형 설계\n\n\n분석 절차 수립, 분석 환경 구축\n\n\n고급 분석기법\n\n\n분석 모형 설계 예상문제 풀이\n\n\n분석기법 적용 과목 마무리 문제 풀이\n\n\n\n\n빅데이터분석기사 완전정복 필기편 : Part.3. 빅데이터 모델링(1) 강의에 입문해봅시다~!\n\n\n\n\n그럼 강의에서 만나요 :)",
      "target_audience": [
        "빅데이터 분석기사(필기) 자격증 취득을 원하시는 분들",
        "데이터 분석 직무로의 취업 및 이직을 준비하시는 분들",
        "데이터 분석에 대해 공부하고자 하시는 분들"
      ]
    },
    {
      "title": "Automatyzacja zadań w Pythonie",
      "url": "https://www.udemy.com/course/automatyzacja-zadan-w-pythonie/",
      "bio": "Wykorzystaj Pythona do automatyzacji pracy!",
      "objectives": [
        "Nauczysz się obsługiwać ścieżki, pliki i katalogi w Pythonie.",
        "Poznasz służące do ich obsługi biblioteki, takie jak os, pathlib.",
        "Nauczysz się operować na dokumentach tekstowych z poziomu języka programowania.",
        "Zdobędziesz umiejętność przeszukiwania plików z wykorzystaniem wyrażeń regularnych.",
        "Dowiesz się, jak tworzyć, modyfikować i zapisywać pliki PDF.",
        "Nauczysz się wstawiać znaki wodne do PDF.",
        "Poznasz bibliotekę Pillow do obsługi obrazów w Pythonie.",
        "Dowiesz się, jak zmniejszać, zwiększać i obracać serię obrazów.",
        "Będziesz wyszukiwać duplikaty obrazów oraz zdjęcia podobne.",
        "Nauczysz się operować na dokumentach Worda w Pythonie.",
        "Lepiej zrozumiesz strukturę pliku Worda.",
        "Będziesz zmieniać atrybuty poszczególnych części pliku Worda.",
        "Nauczysz się łatwo wyciągać z dokumentu wszystkie znajdujące się w nim obrazy.",
        "Nauczysz się operować na dokumentach Excela w Pythonie.",
        "oznasz bibliotekę pandas i jej obiekt DataFrame będący obiektem danych stabelaryzowanych.",
        "Poznasz metodę kompresowania plików w Pythonie przy użyciu dwóch bibliotek.",
        "Nauczysz się, jak przy użyciu Pythona szyfrować dane i rozpakowywać pliki."
      ],
      "course_content": {
        "Obsługa ścieżek i plików": [
          "Wstęp do automatyzacji zadań",
          "Obsługa ścieżek, plików i katalogów w Pythonie",
          "Otwieranie/zapisywanie kilku przykładowych plików w Pythonie",
          "Użycie modułu os do: getcwd, os.system(), listdir, chdir, os.path.join, os.maked",
          "Kopiowanie i przenoszenie plików przy użyciu shutil",
          "Wyszukiwanie plików spełniających pewien wzorzec przy użyciu glob",
          "pathlib jako alternatywa do os.path",
          "Zmiana nazw wielu plików w Pythonie",
          "Operowanie na dokumentach tekstowych w Pythonie",
          "Proste wyrażenia regularne w dokumentach tekstowych"
        ],
        "Obsługa plików PDF": [
          "Wczytywanie pliku PDF",
          "Konwertowanie PDF na JPG przy użyciu pdfplumber",
          "Importowanie tabeli z PDF",
          "Dodawanie znaku wodnego do PDF-a",
          "Wstawianie miejsca na podpis do istniejącego PDF-a",
          "Zamazywanie części PDF-a",
          "Przeszukiwanie PDF-a",
          "Wyodrębnianie i łączenie PDF-ów"
        ],
        "Przetwarzanie wielu plików graficznych": [
          "Wczytywanie obrazu do Pythona",
          "Zmiana rozdzielczości serii obrazów",
          "Desaturacja serii obrazów",
          "Popularne modyfikacje obrazów",
          "Wyszukiwanie duplikatów zdjęć w folderze",
          "Wyszukiwanie podobnych zdjęć - część I",
          "Wyszukiwanie podobnych zdjęć - część II"
        ],
        "Obsługa Worda w Pythonie": [
          "Otwieranie i przeszukiwanie pliku Worda (docx)",
          "Zamiana określonych wartości w Wordzie",
          "Zmiana atrybutów akapitu Worda",
          "Zmiana tekstu w Wordzie bez zmiany atrybutów",
          "Tworzymy konwerter Word -> PDF w Pythonie - część I",
          "Tworzymy konwerter Word -> PDF w Pythonie - część II",
          "Wyciągamy wszystkie obrazki z Worda i zapisujemy do plików",
          "Dodajemy tabele i obrazy do Worda"
        ],
        "Obsługa Excela i wstęp do analizy danych w Pythonie": [
          "Wczytywanie pliku Excela",
          "Przeszukiwanie wielu arkuszy i wielu dokumentów Excela",
          "Tworzenie pliku Excela",
          "Wstęp do DataFrame w bibliotece pandas",
          "Analiza danych przy użyciu pandas",
          "Sortowanie i filtrowanie danych",
          "Bardziej zaawansowane filtrowanie w pandas"
        ],
        "Kompresja i szyfrowanie danych w Pythonie": [
          "Kompresujemy dane do formatu ZIP/RAR/TAR przy użyciu Pythona",
          "Rozpakowujemy dane zapisane w formatach ZIP/RAR/TAR",
          "Szyfrujemy dane przy użyciu Pythona"
        ]
      },
      "requirements": [
        "Podstawowa wiedza o programowaniu."
      ],
      "description": "Obierz kurs na... automatyzację pracy w Pythonie!\nNic skuteczniej niż rutyna nie zabija kreatywności. Konieczność monotonnego powtarzania tych samych mechanicznych czynności i zadań może źle wpłynąć na jakość naszej codziennej pracy - niezależnie od tego, czym się zajmujemy. Ale uwaga: nie musi tak być. W każdym razie nie wtedy, kiedy swoją pracę wykonujemy przy komputerze, znamy w stopniu przynajmniej podstawowym jeden z języków programowania i potrafimy zainstalować Pythona. Jeżeli tak, mamy dobrą informację: wiele codziennych operacji wykonywanych na różnych plikach można zautomatyzować, pozwalając, by napisany przez nas program sam rozwiązywał sprawy wymagające dotychczas naszego zaangażowania.\n\nCo Cię czeka podczas naszego profesjonalnego szkolenia?\nNauczysz się obsługiwać ścieżki, pliki i katalogi w Pythonie.\nPoznasz służące do ich obsługi biblioteki, takie jak os, pathlib.\nNauczysz się operować na dokumentach tekstowych z poziomu języka programowania.\nZdobędziesz umiejętność przeszukiwania plików z wykorzystaniem wyrażeń regularnych.\nDowiesz się, jak tworzyć, modyfikować i zapisywać pliki PDF.\nNauczysz się wstawiać znaki wodne do PDF.\nDowiesz się, jak zamazywać część pliku PDF.\nPoznasz bibliotekę Pillow do obsługi obrazów w Pythonie.\nDowiesz się, jak zmniejszać, zwiększać i obracać serię obrazów.\nBędziesz wyszukiwać duplikaty obrazów oraz zdjęcia podobne.\nNauczysz się operować na dokumentach Worda w Pythonie.\nLepiej zrozumiesz strukturę pliku Worda.\nBędziesz zmieniać atrybuty poszczególnych części pliku Worda.\nNauczysz się łatwo wyciągać z dokumentu wszystkie znajdujące się w nim obrazy.\nDodasz tabele i obrazy do pliku Worda.\nNauczysz się operować na dokumentach Excela w Pythonie.\nPoznasz bibliotekę pandas i jej obiekt DataFrame będący obiektem danych stabelaryzowanych.\nDowiesz się, jak filtrować wyniki Excela.\nZ łatwością przeszukasz wiele arkuszy wielu plików Excela.\nPoznasz metodę kompresowania plików w Pythonie przy użyciu dwóch bibliotek.\nNauczysz się, jak przy użyciu Pythona szyfrować dane i rozpakowywać pliki.\n\nA po zakończeniu szkolenia...\nPo zakończeniu obejmującego 41 lekcji i trwającego łącznie ponad 6 godzin kursu będziesz umiał napisać program wykonujący za ciebie każde rutynowe zadanie. Może to być dodawanie podpisu do istniejącego pliku PDF z fakturą, spisywanie kosztów z pliku Worda, comiesięczna zmiana dat w dokumentach Worda, przeszukiwanie wielu plików Excela w celu znalezienia odpowiedniego fragmentu dokumentacji. Dla osoby tworzącej grafikę będzie to stworzenie programu dodającego znak wodny do jej prac, fotografa zainteresuje seryjna zmiana rozdzielczości, pracujący z Wordem docenią możliwość generowania dokumentów (na przykład wniosku o urlop) na żądanie - możliwości zastosowania wiedzy wyniesionej z tego szkolenia są bardzo szerokie. Pamiętajmy, że każdy program powinien działać przy minimalnym udziale programisty, a najlepiej bez niego.\n\nDo kogo skierowany jest kurs?\nAutomatyzacja pracy w Pythonie. Wykorzystaj Pythona do automatyzacji pracy! przeznaczony jest głównie dla programistów, ale zawarta w nim wiedza może się przydać niemal każdemu użytkownikowi komputera dysponującemu podstawową wiedzą o programowaniu. Praktycznie nie ma takiego obszaru aktywności związanej z pracą przy komputerze, w którym nie przydałaby się wiedza na temat wykorzystania Pythona do automatyzacji pracy.\n\nTylko dla wtajemniczonych\nWielogodzinne poszukiwania interesujących nas informacji w internecie są tyleż żmudne, co niejednokrotnie bezcelowe. Wiele rozwiązań polecanych w sieci jest zwyczajnie bezużytecznych, ponieważ źle działają - albo wcale nie działają - na przykład wtedy, gdy posługujemy się polskimi znakami, czyli w praktyce niemal zawsze. Z kolei część wiedzy zdobytej w czasie naszego kursu pozwoli Ci na samodzielne wykonanie zadań, do których obsługi trzeba kupić specjalistyczne, nierzadko kosztowne programy. Będziesz pracować sprawniej, szybciej i po prostu przyjemniej, a do tego posiądziesz umiejętności wysoko cenione na rynku pracy, takie jak chociażby znajomość biblioteki pandas.\nPamiętaj: monotonia zabija kreatywność, a rutyna w pracy z komputerem szybciej doprowadzi Cię do nerwicy natręctw, niż przyczyni się do rozwoju umiejętności!\n\n\nKarol Kurek ma siedmioletnie doświadczenie w programowaniu — programuje w Pythonie. Pracował jako twórca aplikacji mobilnych, serwisant sprzętu komputerowego oraz nauczyciel matematyki. Aktualnie współtworzy w Pythonie projekt z dziedziny big data i data science. W wolnym czasie grywa w szachy, uczy się języka rosyjskiego i rozwiązuje zadania na forum matematycznym.",
      "target_audience": [
        "Kurs przeznaczony jest głównie dla programistów, ale zawarta w nim wiedza może się przydać niemal każdemu użytkownikowi komputera dysponującemu podstawową wiedzą o programowaniu."
      ]
    },
    {
      "title": "Ciencia de datos con python",
      "url": "https://www.udemy.com/course/ciencia-de-datos-con-python-r/",
      "bio": "De Cero a Cientifico de Datos con Python",
      "objectives": [
        "Comprender el funcionamiento basico de python a traves del taller intensivo",
        "Dominio de las librerias pandas, numpy, matplotlib y sklearn a traves de multiples ejercicios.",
        "Capacidad de analizar datos y encontrar patrones utiles para tomar desiciones informadas",
        "Resolucion de problemas de machine learning a traves de ejemplos y practicas."
      ],
      "course_content": {
        "Introduccion al curso": [
          "¿Qué es la ciencia de datos?"
        ],
        "Taller intensivo de python": [
          "Python y Ambientes Virtuales",
          "Manejo de ambientes virtuales",
          "Variables",
          "Operadores y Expresiones",
          "Colecciones",
          "Flujo de control",
          "Funciones",
          "Modulos y paquetes",
          "Programacion Orientada a Objetos"
        ],
        "Analisis de Datos": [
          "Introduccion al Analisis de datos",
          "Numpy: Arrays",
          "Numpy: Indexacion y Slicing",
          "Numpy: Manipulacion de datos",
          "Numpy: Operaciones Aritmeticas",
          "Numpy: Funciones Matematicas",
          "Numpy: Algebra Lineal",
          "Pandas: Series y DataFrames",
          "Pandas: Manipulacion de datos",
          "Pandas: Tratamiento de datos",
          "Pandas: Agrupacion y Agregacion multinivel de datos",
          "Pandas: Combinando DataFrames",
          "Pandas: Proceso ETL ¿Qué es?",
          "Pandas: Proceso ETL práctica",
          "Pandas: EDA ¿Qué es?",
          "Pandas: EDA práctica",
          "Matplotlib: Introduccion",
          "Matplotlib: Tipos de Graficos",
          "Matplotlib: Personalizando Graficos",
          "Matplotlib: Múltiples Figuras y Ejes"
        ],
        "Machine Learning": [
          "¿Que es el aprendizaje maquina?",
          "Metricas para clasificación y regresión",
          "Aprendizaje Supervisado: Regresion Lineal",
          "Aprendizaje Supervisado: Clasificador de minima distancia",
          "Aprendizaje Supervisado: Vecinos mas cercanos (KNN)",
          "Aprendizaje Supervisado: Clasificador Bayesiano Ingenuo",
          "Aprendizaje Supervisado: Support Vector Machine",
          "Aprendizaje Supervisado: Multi Layer Perceptron",
          "Comparacion entre clasificadores",
          "Aprendizaje Supervisado: Arboles de Decision",
          "Aprendizaje No Supervisado: PCA",
          "Aprendizaje No Supervisado: Kmeans",
          "Aprendizaje No Supervisado: Jerarquico Aglomerativo",
          "Aprendizaje No Supervisado: DBSCAN",
          "Aprendizaje No Supervisado: Gaussian Mixture Model",
          "Comparacion entre clusters"
        ],
        "¡Resolvamos Problemas!": [
          "Cuantizacion de Imagenes con Kmeans",
          "Reconocimiento de Patrones con Redes Neuronales"
        ]
      },
      "requirements": [
        "No necesitas tener ningun conocimiento previo, todo lo aprenderás aqui."
      ],
      "description": "¡Conviértete en un experto en Ciencia de Datos con nuestro curso intensivo de Python! Aprovecha esta oportunidad única para dominar desde la programación básica hasta las técnicas más avanzadas. Aquí te dejamos las razones por las cuales no debes dejar pasar este curso:\n\n\nAprende Python desde Cero: Comienza tu viaje en la programación con nuestro taller intensivo, diseñado para llevarte de los fundamentos hasta la programación orientada a objetos sin necesidad de experiencia previa.\n\n\nDomina las Librerías Esenciales: Te enseñaremos a manejar herramientas clave como Pandas, Numpy, Sklearn y Matplotlib. Estas librerías son indispensables para el análisis de datos, la visualización de información y la construcción de modelos predictivos.\n\n\nPractica Procesos ETL: Aprende técnicas para llevar a cabo procesos ETL (Extract, Transform, Load) eficientemente, permitiéndote preparar y manipular grandes volúmenes de datos para tus análisis.\n\n\nAprende Aprendiendo: A lo largo del curso, resolveremos problemas reales de machine learning, lo que te permitirá comprender cómo aplicar lo aprendido en situaciones prácticas y reales. Esta experiencia directa es invaluable para solidificar tu conocimiento y habilidades.\n\n\nConviértete en un Científico de Datos: Este curso está diseñado para equiparte con todo lo necesario para convertirte en un profesional de la ciencia de datos. Desde las bases de la programación hasta las habilidades técnicas avanzadas, te preparamos para enfrentar los desafíos del mundo real.\n\n\nEncuentra el Trabajo de Tus Sueños: La demanda de científicos de datos sigue creciendo. Al finalizar este curso, tendrás las habilidades y el conocimiento necesarios para destacarte en el mercado laboral y acceder a las oportunidades de trabajo más codiciadas.\n\n\nNo dejes pasar la oportunidad de transformar tu carrera y adentrarte en el mundo de la ciencia de datos con confianza. ¡Inscríbete ahora y da el primer paso hacia el trabajo de tus sueños!",
      "target_audience": [
        "Desarrolladores de python con interés en la ciencia de datos."
      ]
    },
    {
      "title": "Master Deep Learning and Generative AI with PyTorch in Hindi",
      "url": "https://www.udemy.com/course/master-deep-learning-and-ai-with-pytorch-basics-to-advanced/",
      "bio": "Build and Deploy AI Models: Learn Neural Networks, Computer Vision, NLP, and More with PyTorch",
      "objectives": [
        "Understand and implement core deep learning concepts, including backpropagation, activation functions, and optimization techniques etc.",
        "Build, train, and deploy neural networks for NLP, Computer Vision, and Generative AI using PyTorch.",
        "Master advanced topics like Transformers, GANs, to tackle real-world AI challenges.",
        "Utilize tools like TensorBoard, and PyTorch for effective model development and deployment."
      ],
      "course_content": {
        "Most Important Concepts of Deep Learning": [
          "Perceptron",
          "Perceptron 2",
          "MLP(Ann) and its Notation",
          "Forward Propagation",
          "Forward Propagation 2",
          "Backpropagation"
        ],
        "Section 2 : Pytorch": [
          "Starting With Pytorch",
          "Introduction To Tensors",
          "Random Tensors",
          "Zeros and Ones",
          "creating arange and tensors_like",
          "torch.eye",
          "torch.full",
          "Torch.linspace",
          "Tensor Data types",
          "Getting Information from tensors",
          "Manipulating Tensors (Tensor operations)",
          "Aggregations: Min, Max, and Everything In Between",
          "Reshaping,stacking,squeezing , unsqueezing and permute",
          "Indexing(selecting data from tensors)",
          "Pytorch tensors and Numpy",
          "Reproducibility (trying to take the random out of random )",
          "Running tensors on GPUs"
        ],
        "Linear Regression": [
          "Linear Regression Part 1",
          "Linear Regression Part 2",
          "Linear Regression Part 3",
          "Linear Regression Part 4"
        ],
        "All Activation Functions Explained": [
          "Linear Activation Function",
          "Coding Linear Activation Function",
          "threshold Function",
          "Coding Threshold Function",
          "Sigmoid function",
          "Sigmoid function part 2",
          "Coding Sigmoid function",
          "Tanh function",
          "Coding Tanh function",
          "Softmax function",
          "Coding Softmax function",
          "ReLU (Rectified Linear Unit)",
          "Coding ReLU (Rectified Linear Unit)",
          "LeakyRelu(LReLU)",
          "Coding LeakyRelu(LReLU)",
          "Parametric ReLU (PReLU)",
          "Coding Parametric ReLU (PReLU)",
          "Exponential Linear Unit (ELU)",
          "Coding Exponential Linear Unit (ELU)",
          "Scaled Exponential Linear Unit (SELU)",
          "Coding Scaled Exponential Linear Unit (SELU)",
          "Swish function",
          "Coding Swish function",
          "Softplus",
          "Coding Softplus",
          "Mish",
          "Coding Mish"
        ],
        "All Loss(Cost) Functions Explained": [
          "(Cost) Functions",
          "Mean Squared Error (MSE)(L2 LOSS)",
          "Coding Mean Squared Error (MSE)(L2 LOSS)",
          "Mean Absolute Error (MAE)(L1 Loss)",
          "Coding Mean Absolute Error (MAE)(L1 Loss)",
          "Mean Bias Error (MBE)",
          "Coding Mean Bias Error (MBE)",
          "Root Mean Squared Error (RMSE)",
          "Coding Root Mean Squared Error (RMSE)",
          "Root Mean Squared Logarithmic Error (RMSLE)",
          "Coding Root Mean Squared Logarithmic Error (RMSLE)",
          "Huber Loss(Smooth L1 Loss)",
          "Coding Huber Loss(Smooth L1 Loss)",
          "Log-Cosh Loss",
          "Coding Log-Cosh Loss",
          "Binary Cross-Entropy Loss (BCE)(logloss)",
          "Coding Binary Cross-Entropy Loss (BCE)(logloss)",
          "Categorical Cross-Entropy Loss",
          "Coding Categorical Cross-Entropy Loss",
          "Remaining Cost Functions"
        ],
        "All Optimizers Explained": [
          "Gradient Descent,Batch ,Stochastic,Mini-batch",
          "Coding Gradient Descent,Batch ,Stochastic,Mini-batch",
          "Exponentially Weighted Moving Average (EWMA)",
          "SGD with Momentum",
          "Coding SGD with Momentum",
          "Nesterov Accelerated Gradient (NAG)",
          "Coding Nesterov Accelerated Gradient (NAG)",
          "AdaGrad and RMSProp",
          "Coding AdaGrad and RMSProp",
          "Adam (Adaptive Moment Estimation)",
          "Coding Adam (Adaptive Moment Estimation)"
        ],
        "Must Do Projects": [
          "Logistic",
          "Logistic part 2",
          "Logistic part 3",
          "Logistic part 4",
          "Classification part 1",
          "Classification part 2"
        ],
        "Improving Performance Of Neural Network": [
          "Vanishing Gradient AND Exploding Gradient",
          "Overfitting AND Underfitting",
          "Regularizations,L1 Regularization,L2 Regularization ,Elastic Net Regularization",
          "Coding Regularizations,L1 ,L2 Regularization ,Elastic Net Regularization",
          "Dropout",
          "All Normalizations Explained",
          "Batch Normalization",
          "Layer Normalization",
          "Group Normalization",
          "Normalizations on Images",
          "Instance Normalization",
          "RMSNormalization",
          "Normalizing Inputs",
          "Coding All Normalizations"
        ],
        "Natural language processing (NLP)": [
          "Sentiment Analysis (Word Embedding) with Neural Bag Of Words part 1",
          "Sentiment Analysis (Word Embedding) with Neural Bag Of Words part 2",
          "LSTM(RNNS)",
          "Seq2Seq ModelS Part 1",
          "Seq2Seq ModelS Part 2",
          "Seq2Seq ModelS Part 3"
        ],
        "Generative models": [
          "Generative adversarial networks Part 1",
          "Generative adversarial networks Part 2",
          "DCGAN, or Deep Convolutional GAN"
        ]
      },
      "requirements": [
        "Basic programming knowledge, preferably in Python.",
        "Familiarity with high school-level mathematics, including linear algebra and calculus.",
        "No prior experience in AI or machine learning is required — all concepts will be taught from the ground up.",
        "Access to a computer with internet connectivity for coding and practicing."
      ],
      "description": "you will learn all these Topics and lot more\n\n1. Core Concepts\n1. Perceptron\n2. MLP and its Notation\n3. Forward Propagation\n4. Backpropagation\n5. Chain Rule of Derivative in Backpropagation\n6. Vanishing Gradient Problem\n7. Exploding Gradient\n\n\n\n\nActivation Functions\n\n\nList of Activation Functions\n1. Linear Function\n2. Binary Step Function\n3. Sigmoid Function (Logistic Function)\n4. Tanh (Hyperbolic Tangent Function)\n5. ReLU (Rectified Linear Unit)\n6. Leaky ReLU\n7. Parametric ReLU (PReLU)\n8. Exponential Linear Unit (ELU)\n9. Scaled Exponential Linear Unit (SELU)\n10. Softmax\n11. Swish.\n12. SoftPlus\n13. Mish\n14. Maxout\n15. GELU (Gaussian Error Linear Unit)\n\n\n16. SiLU (Sigmoid Linear Unit)\n17. Gated Linear Unit (GLU)\n18. SwiGLU\n19. Mish Activation Function\n\n\nDerivative of Activation Functions\n\n\nProperties of Activation Functions\n1. Saturating vs Non-Saturating\n2. Smooth vs Non-Smooth\n3. Generalized vs Specialized\n4. Underflow and Overflow\n5. Undefined and Defined\n6. Computationally Expensive vs Inexpensive.\n7. 0-Centered and Non-0-Centered\n8. Differentiable vs Non-Differentiable\n9. Bounded and Unbounded\n10. Monotonicity\n11. Linear Vs Non Linear\n\n\n\n\nIdeal Activation Function Characteristics\n1. Non-Linearity\n2. Differentiability\n3. Computational Efficiency\n4. Avoids Saturation\n5. Non-Sparse (Dense) Gradients\n6. Centered Output (0-Centered)\n7. Prevents Exploding Gradients\n8. Monotonicity (Optional)\n9. Sparse Activations (Optional)\n10. Resilience to Outliers\n11. Noise Robustness\n12. Stable Training Dynamics\n13. Minimal Parameter Dependency\n14. Compatibility with Modern Techniques\n15. Efficient in Hardware\n16. The Function Must Be Continuous and Infinite in Domain\n17. Vanishing Gradient Problem\n18. Dynamic Range Adaptation\n19. Scalability to Deeper Networks\n20. Biological Plausibility (Optional)\n21. Simplicity in Implementation\n\n\n22. Gradient Smoothness\n23. Compatibility with Unsupervised Objectives\n\n\n\n\nLoss Functions\n\n\n1. Mean Squared Error (MSE)\n2. Mean Absolute Error (MAE)\n3. Root Mean Squared Error (RMSE)\n4. Root Mean Squared Log Error (RMSLE)\n5. Huber Loss\n6. Hinge Loss\n7. Binary Cross-Entropy (BCE)\n8. Categorical Cross-Entropy\n9. Focal Loss\n10. Contrastive Loss\n11. KL Divergence (Kullback-Leibler Divergence)\n12. Triplet Loss\n13. Smooth L1 Loss:\n14. Dice Loss:\n\n\nOptimizers\n\n\n1. Gradient Descent\n2. Stochastic Gradient Descent (SGD)\n3. Mini-Batch Gradient Descent\n4. Exponentially Weighted Moving Average (EWMA)\n5. Gradient Descent with Momentum\n6. Nesterov Accelerated Gradient\n7. AdaGrad (Adaptive Gradient)\n8. RMSProp (Root Mean Squared Propagation)\n9. AdaDelta\n10. Adam (Adaptive Moment Estimation)\n11. Nadam (Nesterov-accelerated Adaptive Moment Estimation)\n12. LAMB (Layer-wise Adaptive Moments):\n13. SGDW/AdamW\n\n\nImproving Performance of Neural Networks\n\n\n· Effect of Batch Size on Training\n· Memoization\n\n\nWeight Initialization\n1. Zero Initialization\n\n\n2. Non-Zero Constant Value Initialization\n3. Random Initialization (with small values, large values)\n4. Xavier (Glorot) Initialization\n5. He Initialization\n6. LeCun Initialization\n7. Uniform Initialization\n8. Normal (Gaussian) Initialization\n9. Bilinear Initialization\n10. Orthogonal Initialization\n\n\n\n\n\n\nRegularization\n1. L1 Regularization (Lasso)\n2. L2 Regularization (Ridge) (weight decay)\n3. Elastic Net Regularization\n4. Dropout\n5. Early Stopping\n6. Data Augmentation\n7. Batch Normalization\n8. Residual Connections\n9. Label Smoothing\n10. Parameter Sharing\n11. Weight Constraint\n12. Adversarial Training\n\n\nNormalization\n1. Normalizing Inputs\n2. Batch Normalization (BatchNorm)\n3. Layer Normalization (LayerNorm)\n4. Instance Normalization (InstanceNorm)\n5. Group Normalization (GroupNorm)\n6. RMSNorm\n7. Filter Response Normalization\n8. Weight Normalization\n\n\nOther Techniques\n\n\nGradient Clipping and Gradient Checking Hyperparameter Tuning\nLearning Rate Scheduling\n\n\n1. Step Decay\n2. Exponential Decay\n3. Cosine Annealing\n4. Cyclical learning rate\n5. OneCycleLR\n6. Warmup\n\n\n\n\nRecurrent Neural Networks (RNNs)\n1. RNN\n2. LSTM\n3. GRU\n4. Deep Stacked RNN, Bidirectional\n\n\nSequence-to-Sequence Models\n1. Encoder-Decoder Architecture\n2. Attention Mechanism\n\n\nNatural Language Processing (NLP)\n· Tokenization: Sentence tokenization, word tokenization, and subword tokenization (BPE, WordPiece).\nText Preprocessing: Lowercasing, stemming, lemmatization, stopword removal etc...\nText Vectorization:\n\n\n1. One-Hot Encoding\n2. Bag of Words (BoW)\n3. TF-IDF\n4. Word Embeddings (Word2Vec, GloVe, FastText)\n5. Contextual Embeddings (ELMo, BERT, GPT, etc.) Complete NLP Basics\nTransformers\n1. Vanilla Transformer\n\n\n2. Vision Transformer\n3. Swin Transformer\nand lot more",
      "target_audience": [
        "Beginners interested in starting their journey in AI and deep learning.",
        "Software developers aiming to transition into the field of AI and machine learning.",
        "Data scientists and analysts looking to enhance their expertise with PyTorch and advanced deep learning techniques."
      ]
    },
    {
      "title": "Aplicaciones de Data Science: Text Mining-NLP & Data Mining",
      "url": "https://www.udemy.com/course/aplicaciones-de-data-science-text-mining-pln-data-mining/",
      "bio": "Procesa datos para encontrar patrones de compras y analiza textos para encontrar mensajes ocultos en el corpus textual.",
      "objectives": [
        "Aplicaciones de Minería de Datos con el algoritmo Apriori.",
        "Aplicaciones de Minería de Texto para analizar contenidos y sentimientos.",
        "Uso de RStudio para crear informes Makdown html profesionales.",
        "Ciencia de Datos aplicada.",
        "Analizar la cesta de compra de clientes.",
        "Interpretación lingüística cuantitativa."
      ],
      "course_content": {
        "Introducción": [
          "Presentación del contenido del curso",
          "Filosofía del curso",
          "Los cursos online"
        ],
        "Reglas de Asociación: Algoritmo Apriori": [
          "Setup RMarkdown Arules",
          "Extraer los Datos del Online Retail",
          "Creación del objeto R \"Basket\"",
          "Función Apriori sobre las transacciones",
          "Top Reglas de Asociación",
          "Informe HTML Reglas de Asociación Apriori"
        ],
        "Análisis del Discurso": [
          "Paquete de R \"Quanteda\"",
          "Creación del Corpus con los discursos",
          "Comparación de la Extensión de los discursos",
          "Nube de frecuencia de palabras",
          "Dispersión Léxica",
          "Cálculo de similitudes y distancias entre discursos",
          "Red de binomios y trinomios de palabras",
          "Análisis de sentimientos de tokens del corpus",
          "Informe HTML de Análisis del Discurso"
        ],
        "Despedida": [
          "Despedida del curso"
        ]
      },
      "requirements": [
        "Conocimientos previos de R y RStudio"
      ],
      "description": "La Minería de Datos se utiliza en las organizaciones en diversas aplicaciones, como la comprensión del marketing de los consumidores, el análisis de productos, la demanda y el suministro, el comercio electrónico, la tendencia de inversión en acciones y bienes raíces, las telecomunicaciones, etc. Esta se basa en algoritmos matemáticos y habilidades analíticas para encontrar patrones dentro de la enorme colección de bases de datos.\nUna de las múltiples aplicaciones que tiene la Minería de Datos es la de los algoritmos de reglas de asociación, los cuales tienen como objetivo encontrar relaciones dentro un conjunto de transacciones, en concreto, ítems o atributos que tienden a ocurrir de forma conjunta, en este curso aplicaremos el Apriori uno de los más utilizados.\nAsimismo, la Minería de Textos es un campo de investigación de gran crecimiento en la actualidad por las capacidades que brindan para analizar expresiones textuales ya sean de documentos, artículos web, comentarios en redes sociales, tesis, literatura, etc. con potencia computacional para el procesamiento del lenguaje Natural (PLN), para análisis basados en la lingüística para encontrar patrones y mensajes ocultos dentro de los contenidos.\nLas habilidades en minería de datos y minería de textos son de gran valor para cualquier analista de datos, de business intelligence y científico de datos en general porque sin duda alguna, llevan al análisis mucho más allá, abriendo un sinfín de oportunidades de aplicación en los negocios y todo tipo de organizaciones.\nEn este curso usaremos el paquete de R \"Quanteda\" para realizar análisis de contenido y análisis de sentimientos sobre un corpus textual referidos a discursos.",
      "target_audience": [
        "Analistas de Datos.",
        "Analistas de Business Intelligence.",
        "Interesados en la Ciencia de Datos.",
        "Especialistas de Marketing."
      ]
    },
    {
      "title": "数据分析进阶课",
      "url": "https://www.udemy.com/course/hvdgwonn/",
      "bio": "用数据指导业务，高效提升运营人职场竞争力",
      "objectives": [
        "全面了解数据科学",
        "运用数据分析工具Python",
        "机器学习初步建模、调试与预估",
        "A/B测试分析方法"
      ],
      "course_content": {
        "「零」课程导论": [
          "讲师介绍",
          "课程介绍"
        ],
        "「第一周」数据科学是什么": [
          "什么是数据科学（一）",
          "什么是数据科学（二）",
          "数据科学职位介绍（一）",
          "数据科学职位介绍（二）",
          "数据科学职位介绍（三）",
          "数据科学职位介绍（四）",
          "CRISP-DM简介（一）",
          "CRISP-DM简介（二）"
        ],
        "「第二周」数据分析工具Python（上）": [
          "安装Python",
          "「案例」用Python分析员工离职原因（上）",
          "「案例」用Python分析员工离职原因（下）",
          "Python语言简介",
          "Python中的报错和异常",
          "Python基本语法知识",
          "基本数据类型和数据结构（上）",
          "基本数据类型和数据结构（下）",
          "基本运算符",
          "控制流（上）",
          "控制流（下）",
          "自定义函数和Python脚本",
          "类的概念（上）",
          "类的概念（下）",
          "手把手教你为HR建立一个智能信息表",
          "Python自学资源"
        ],
        "「第三周」数据分析工具Python（下）": [
          "课前导读",
          "开始安装Jupyter Notebook！（上）",
          "开始安装Jupyter Notebook！（中）",
          "开始安装Jupyter Notebook！（下）",
          "完成数据整理任务",
          "数据整理常用库：Numpy &amp; Pandas",
          "Numpy &amp; Pandas中的数据结构（上）",
          "Numpy &amp; Pandas中的数据结构（下）",
          "手把手带你完成数据整理任务（上）",
          "手把手带你完成数据整理任务（中）",
          "手把手带你完成数据整理任务（下）",
          "数据整理思路&amp;基本操作",
          "完成数据可视化任务",
          "数据可视化库：Matplotlib &amp; Seaborn（上）",
          "数据可视化库：Matplotlib &amp; Seaborn（中）",
          "数据可视化库：Matplotlib &amp; Seaborn（下）",
          "手把手带你完成数据可视化任务（上）",
          "手把手带你完成数据可视化任务（下）",
          "用Python分析离职原因完整代码（上）",
          "用Python分析离职原因完整代码（下）"
        ],
        "「第四周」数据理解与准备": [
          "相关性系数（上）",
          "相关性系数（下）",
          "卡方检验（上）",
          "卡方检验（下）",
          "方差分析（上）",
          "方差分析（下）",
          "特征选取引入（上）",
          "特征选取引入（下）",
          "过滤法（上）",
          "过滤法（下）",
          "包装法（上）",
          "包装法（下）",
          "嵌入法（上）",
          "嵌入法（下）",
          "特征选取总结（上）",
          "特征选取总结（下）"
        ],
        "「第五周」机器学习初步建模": [
          "为什么需要机器学习",
          "机器学习是什么（上）",
          "机器学习是什么（下）",
          "三种主要的机器学习算法",
          "Scikit-learn算法库介绍",
          "机器学习模型的评估和选择（上）",
          "机器学习模型的评估和选择（下）",
          "机器学习模型三个组成部分",
          "逻辑回归直观理解",
          "逻辑回归三个组成部分（一）",
          "逻辑回归三个组成部分（二）",
          "逻辑回归应用（上）",
          "逻辑回归应用（下）",
          "SVM直观理解（一）",
          "SVM直观理解（二）",
          "SVM三个组成部分（一）",
          "SVM三个组成部分（二）",
          "SVM三个组成部分（四）",
          "SVM三个组成部分（五）",
          "SVM核方法（一）",
          "SVM核方法（二）",
          "SVM核方法（三）",
          "SVM和逻辑回归的比较"
        ],
        "「第六周」模型调试与评估": [
          "模型调试与评估（上）",
          "模型调试与评估（下）",
          "交叉验证机制（一）",
          "交叉验证机制（二）",
          "交叉验证机制（三）",
          "交叉验证机制（四）",
          "交叉验证机制（五）",
          "模型的过拟合和欠拟合（一）",
          "模型的过拟合和欠拟合（二）",
          "模型的过拟合和欠拟合（三）",
          "正则化方法提升模型表现（一）",
          "正则化方法提升模型表现（二）",
          "模型效果评估指标（一）",
          "模型效果评估指标（二）",
          "模型效果评估指标（三）"
        ],
        "「第七周」机器学习建模进阶I": [
          "课程导言",
          "集成方法（一）",
          "集成方法（二）",
          "随机森林",
          "自适应提升",
          "梯度提升",
          "神经网络（一）",
          "神经网络（二）",
          "神经网络（三）",
          "反向传播",
          "时间序列（一）",
          "时间序列（二）",
          "ARIMA（一）",
          "ARIMA（二）"
        ],
        "「第八周」机器学习建模进阶II": [
          "课程导言",
          "层次聚类（一）",
          "层次聚类（二）",
          "层次聚类（三）",
          "密度聚类（一）",
          "密度聚类（二）",
          "主成分分析（一）",
          "主成分分析（二）",
          "主成分分析（三）",
          "主成分分析（四）"
        ],
        "「第九周」A/B测试": [
          "A/B测试能解决的问题",
          "严谨的A/B测试流程",
          "A/B测试：确立目标",
          "A/B测试：实验设计（一）",
          "A/B测试：实验设计（二）",
          "A/B测试：实验设计（三）",
          "A/B测试：实验设计（四）",
          "A/B测试：运行实验到结论（上）",
          "A/B测试：运行实验到结论（下）",
          "A/B测试实验设计案例（上）",
          "A/B测试实验设计案例（下）",
          "A/B测试之数据分析",
          "A/B测试失效时的分析方法",
          "A/B测试分析方法"
        ]
      },
      "requirements": [
        "有一定工作年限的数据分析师/BI工程师"
      ],
      "description": "随着大数据和人工智能发展，数据科学作为一个新兴学科发展迅猛。数据科学也可以赋能业务，通过深入挖掘数据价值，一方面可以提高运营效率，降低成本，另一方面也可以发现商机，开拓业务，带来更多利润。但是数据科学门槛高，体系庞杂，让初学者望而却步。\n为此，我们特别开发了本门系统课程，覆盖基于数据挖掘流程展开的核心能力要求，包括商业理解、数据理解、数据准备、建模、评估和发布的全流程。\n张宇晖，三节课数据分析课程主讲老师，美国国家强磁场实验室理论物理博士。曾就职于文思海辉（美国）、微软（美国）、滴滴（中国），历任数据科学家、高级数据与应用科学家、策略运营专家；在滴滴快捷出行事业群平台车主团队，负责各类数据运营项目的对接与具体执行，构建全面的司机标签体系，制定司机衰退干预策略，策略效果 ROI 约 3.5，提升大盘 GMV 约 1%；作为微软负责中小企业预售&留存的约 500 人团队的主要数据科学家，从事各种数据科学分析任务和相关项目管理工作，参与建立并优化相关业务的数据仓库和数据看板；\n这门课程适合成为高薪数据分析人才适用于2-5年数据分析师：希望通过此次培训可以系统夯实技术知识，掌握系统化项目方法论的学员；适用于2-5年BI工程师：适用于有意学习数据分析知识，系统夯实技术知识，掌握系统化项目方法论的学员。",
      "target_audience": [
        "适用于有意学习数据分析知识，系统夯实技术知识，掌握系统化项目方法论的2-5年BI工程师",
        "希望通过此次培训可以系统夯实技术知识，掌握系统化项目方法论的2-5年数据分析师"
      ]
    },
    {
      "title": "Derinlemesine Python 3 : AI Machine Learning",
      "url": "https://www.udemy.com/course/derinlemesine-python-ai-machine-learning/",
      "bio": "Yapay Zeka, Makine Öğrenmesi, Sklearn, Tensorflow, Keras, PyTorch",
      "objectives": [
        "Python ile Yapay Zeka Makine Öğrenmesi"
      ],
      "course_content": {
        "Sklearn - Veri (Data)": [
          "Ölçeklendirme (Rescaling)",
          "Etiket Düzgülendirme (Label Encoding)",
          "Veritakımları (Datasets)",
          "Çalıştırma-Sınama Yarması (Train-Test Split)",
          "Veri Yükleme (Data Loading)"
        ],
        "Çizdirim (Plot)": [
          "Saçılım (Scatter)",
          "Eşyükselti (Contour)",
          "Kökleşileyici Çizdirimi (Classifier Plot)"
        ],
        "Kökleşileme (Classification)": [
          "Kuram (Theory)",
          "Toy Bayesçi Kökleşileme (Naive Bayesian Classification)",
          "Destek Yöneyi Kökleşileme (Support Vector Classification)",
          "Lojistik Gerileme Kökleşileme (Logistic Regression Classification)",
          "Karar Ağacı Kökleşileme (Decision Tree Classification)",
          "K En Yakın Komşu Kökleşileme (K-Nearest Neigbours Classification)",
          "Yapay Sinir Ağı Kökleşileme (Artificial Neural Network Classification)"
        ],
        "Gerileme (Regression)": [
          "Çizgili Gerileme - Tek Değişkinli (Linear Regression - Univariate)",
          "Çizgili Gerileme - Çok Değişkinli (Linear Regression - Multivariate)",
          "Sinir Ağı Gerileme (Neural Network Regression)",
          "Gerçek Verilerle Gerileme - Trafik İndeksi"
        ],
        "Salkımlama (Clustering)": [
          "Kuram (Theory)",
          "K Bayağılar Salkımlama (K-Means Clustering)",
          "Bayağı Kaydırma Salkımlama (Mean-Shift Clustering)"
        ],
        "Tensorflow & Keras - Gereyler (Tensors)": [
          "Kurulum (Installation) : Tensorflow & CUDA",
          "Nesne (Object)",
          "İşlemler (Operations)",
          "Çizgili İşlemler (Linear Operations)",
          "Tensorflow & Numpy"
        ],
        "Tensorflow & Keras - Veritakımları (Datasets)": [
          "Veritakımı Yaratma (Create Dataset)",
          "Veritakımı İşlemleri (Dataset Operations)",
          "Eşlemle, Süz, İndirge (Map, Reduce, Filter) - Lambda",
          "Veritakımı Yükleme (Dataset Load)",
          "Veritakımı & Pandas (Dataset & Pandas)"
        ],
        "Tensorflow & Keras - Yapay Sinir Ağları (Artificial Neural Networks)": [
          "Sinir Ağı Temelleri (Neural Network Fundamentals)",
          "Pandas İle Kullanım - Kalp Örneği (Heart Example)",
          "Dikeçler (Columns) - Titanik Örneği (Titanic Example)",
          "Gerileme (Regression) - Araba MPG Örneği (Auto MPG Example)"
        ],
        "PyTorch - Gerey (Tensor)": [
          "Kurulum (Installation) : PyTorch & CUDA",
          "Gerey (Tensor)",
          "Gerileme (Regression)"
        ],
        "PyTorch - Yapay Sinir Ağı (Artificial Neural Network)": [
          "Veritakımı (Dataset)",
          "Sinir Ağı (Nerual Network) & Taslam (Model)",
          "Çalıştırma (Train)",
          "Değerlendirme (Evaluation) / Sınama (Test) & Öngörü (Prediction)"
        ]
      },
      "requirements": [
        "Temel Python bilgisi ve temel Veri Bilim (Data Science) araçlarının kullanımı"
      ],
      "description": "Bu eğitimde Python ile Yapay Us (Artificial Ingelligence) & Düzenek Öğrenmesi (Machine Learning) anlatılmaktadır. Salkımlama (Clustering), Sınıflandırma/Kökleşileme (Classification) & Gerileme  (Regression) gibi konular işlenmektedir. Yapay Sinir Ağları (Artificial Neural Networks), Destek Yöneyleri (Support Vectors), Karar Ağacı (DecisionTree), K En Yakın Komşu (K-Nearest Neighbours), K Bayağılar (K-Means ) yöntemleriyle uygulama geliştirme açıklanmaktadır.  Skit-Learn / Sklearn ile konular işlenip TensorFlow & Keras ile PyTorch kütüphaneleri de anlatılmaktadır.\nEğitim tümüyle uygulamaları olarak yapılmaktadır. Kuramsal/Teorik konular yeri geldikçe, özet olarak verilmektedir. Python dilindeki betikliklerle yapay zeka uygulamalarının nasıl geliştirildiği anlatılmakta; kullanılan algoritmaların nasıl geliştirildiği ve nasıl çalıştığı konusu, yalnızca onları kullanabilmek için gerektiği ölçüde anlatılmaktadır. Her yöntemin ya da algoritmanın çalışması kendi başına, bilgisayar bilimi ve matematiğin konusu olduğu için burada çok ayrıntılı olarak gösterilmemektedir.\nEğitimde, Bilgisayar Görümü (Computer Vision) ve İmge Özellikleri (Image Features) konusu ile Doğal Dil İşleme (Natural Language Processing) ve Yazı Özellikleri (Text Features), ayrı bir eğitim konusu olduğu için dışarda tutulmuştur. Öte yandan söz konusu alanlar için gerekli, çoğu kez ön koşul olan temel makine öğrenmesi özellikleri burada anlatılmaktadır.\nEğitimde Python dili ve Veri Bilimi (Data Science) en başından anlatılmamakta, temel düzeyde bilindiği var sayılmaktadır. Öte yandan bu konular yeri geldikçe uygulama olarak gösterildiği için, bu eğitimle Python ve Veri Bilimi bilgilerinin ilerletilmesi sağlanmaktadır. Bu nedenle, yapay zekayla ilgilenmeyenleri de Python dilini geliştirmek için bu eğitimi almalarını öneriyoruz.\nEğitimdeki örnekleri GitHub sitesinde godoro-education kullanıcısı altında python-machine-learning adlı depoya katıldıktan sonra görebilirsiniz.",
      "target_audience": [
        "Yazılım Geliştiriciler, Bilgisayar Programcıları, Bilim İnsanları, Akademisyenler"
      ]
    },
    {
      "title": "UNet（PyTorch）图像语义分割实战：训练自己的数据集",
      "url": "https://www.udemy.com/course/unetpytorch/",
      "bio": "计算机视觉图像语义分割实战",
      "objectives": [
        "学习PyTorch版UNet图像语义分割技术来训练自己的数据集",
        "学习labelme图像分割标注工具",
        "掌握多类物体的图像分割方法",
        "学习UNet语义分割原理"
      ],
      "course_content": {
        "课程介绍": [
          "介绍"
        ],
        "图像语义分割介绍": [
          "图像分割任务及数据集",
          "图像分割性能指标"
        ],
        "UNet图像语义分割原理": [
          "UNet图像语义分割原理"
        ],
        "Kaggle盐体识别竞赛UNet实战": [
          "安装PyTorch (ubuntu)",
          "安装PyTorch (Windows)",
          "Kaggle盐体识别：比赛介绍",
          "Kaggle盐体识别：U-Net实战"
        ],
        "Pothole语义分割UNet实战": [
          "labelme图像标注及mask制作",
          "Pothole分割UNet实战"
        ]
      },
      "requirements": [
        "熟悉Python和PyTorch"
      ],
      "description": "UNet是一种基于深度学习的图像语义分割方法，尤其在医学图像分割中表现优异。\n本课程将手把手地教大家使用labelme图像标注工具制作自己的数据集，生成Mask图像，并使用PyTorch版UNet训练自己的数据集，从而能开展自己的图像分割应用。\n本课程首先讲述图像分割的任务说明、常用数据集，然后介绍UNet网络的原理\n本课程有两个项目实践：\n(1) Kaggle盐体识别比赛 ：利用PyTorch版UNet进行Kaggle盐体识别\n(2) Pothole语义分割：对汽车行驶场景中的路坑进行标注和PyTorch版UNet语义分割\n本课程使用PyTorch版本的UNet，在Ubuntu系统上用Jupyter Notebook做项目演示。 包括：数据集标注、数据集格式转换和Mask图像生成、编写UNet程序文件、训练自己的数据集、测试训练出的网络模型、性能评估。项目代码也可在Windows上运行，课程提供Windows环境搭建方法。\n本课程提供项目的数据集和Python程序代码。",
      "target_audience": [
        "希望掌握PyTorch版UNet图像语义分割实战技术的同学们"
      ]
    },
    {
      "title": "【事前知識不要】Pythonで始める画像認識入門：深層学習の基礎から実践まで",
      "url": "https://www.udemy.com/course/python-recognition/",
      "bio": "プログラミング初心者でも安心して学べる内容で、PythonとTensorFlow/Kerasを使い、画像認識モデルをゼロから構築します。Google Colaboratoryを使って実践的に深層学習を体験し、AIモデル作成の基礎を学べます。",
      "objectives": [
        "ニューラルネットワークの基礎理解",
        "TensorFlow/Kerasを使ったディープラーニングモデルの構築スキル",
        "Python基礎とGoogle Colaboratoryの活用スキル",
        "画像認識モデルの構築と改善",
        "ディープラーニングの実践プロジェクト経験",
        "評価指標とモデルの性能評価の習得",
        "データ前処理と過学習/未学習の回避方法の理解"
      ],
      "course_content": {
        "はじめに": [
          "講座の説明"
        ],
        "Python入門": [
          "PythonとGoogle Colaboratoryの紹介",
          "GoogleColabインストール",
          "はじめに、基本関数",
          "変数について",
          "キャスト、コメント",
          "データ型",
          "演算子",
          "関数について",
          "制御構文",
          "クラス",
          "NumPy,Matplotlib",
          "確認問題"
        ],
        "機械学習入門": [
          "機械学習入門",
          "未学習、過学習",
          "評価指標",
          "混合行列"
        ],
        "ディープラーニングとは": [
          "ディープラーニングとは"
        ],
        "ニューラルネットワーク基礎": [
          "ニューラルネットワーク基礎",
          "CNNについて",
          "活性化関数",
          "パーセプトロン、多層パーセプトロン",
          "誤差逆伝播法",
          "最適化アルゴリズム"
        ],
        "TensorFlow/Keras入門": [
          "TensorFlow/Keras入門",
          "TensorFlow/Kerasのインストールと基本的な使い方",
          "Sequentialモデル",
          "モデルのコンパイル、学習、評価"
        ],
        "画像認識入門": [
          "画像認識入門",
          "MNISTデータセットを使った手書き数字認識",
          "画像分類、物体検出"
        ],
        "実践プロジェクト": [
          "実践プロジェクト",
          "プロジェクト概要、画像データセットの準備",
          "モデルの構築",
          "モデルの訓練と評価",
          "モデルの改善"
        ]
      },
      "requirements": [
        "プログラミングの経験は不要です。必要なことはすべてコース内で学べます。",
        "数学の基本的な知識があると理解がスムーズになりますが、コース内で必要な部分は丁寧に解説します。",
        "必要なツールはすべて無料で利用可能です。Google Colabを使用して、ローカル環境を整える必要はありません。"
      ],
      "description": "この講座は、プログラミング初心者でも、数学が苦手でも、AIの第一歩を踏み出したいあなたのための講座です。\nPythonとGoogle Colaboratoryを使って、手を動かしながらニューラルネットワークを学び、画像認識モデルをゼロから作成できます。\n難しい数学は不要！ 図やアニメーションを多用し、直感的に深層学習の仕組みを理解できます。りんごの画像を自動で判別するモデルを作ったり、自分の好きな画像でオリジナルのAIを作ってみませんか？\n\n\nこの講座で学べること\nニューラルネットワークの基礎\nPythonとGoogle Colaboratoryを使ったプログラミング\n画像認識モデルの作り方\n\n\nなぜこの講座がおすすめか\n分かりやすい: 図やアニメーションを多用し、難しい概念も簡単に理解できる\n実践的: 実際に手を動かしながら学べる\n初心者向け: 前提知識、プログラミング経験がなくてもOK\n\n\n各章の詳細\nはじめに\nPython入門\nPythonのインストールと基本的な使い方\nGoogle colabの使い方\nPython基本構文\nNumPy、Matplotlib\n機械学習入門\n機械学習入門\n過学習と未学習\n評価指標\n混合行列\nディープラーニングとは\nディープラーニングとは\nニューラルネットワークの基礎\nニューラルネットワーク基礎\nCNNについて\n活性化関数\nパーセプトロン、多層パーセプトロン\n誤差逆伝播法\n最適化アルゴリズム\nTensorFlow/Keras入門\nTensorFlow/Keras入門\nTensorFlow/Kerasのインストールと基本的な使い方\nSequentialモデル\nモデルのコンパイル、学習、評価\n画像認識入門\n画像認証入門\nMNISTデータセットを使った手書き数字認識\n画像分類、物体検出\n実践プロジェクト\n実践プロジェクト\nプロジェクト概要、画像データセットの準備\nモデルの構築\nモデルの訓練と改善\nモデルの改善\n\n\n深層学習の楽しさを体験したい方は、ぜひこの講座をご受講ください。",
      "target_audience": [
        "画像認識に関心があり、実践的なスキルを身につけたいと考えている方。",
        "深層学習やAIに興味がある初心者のプログラマー。",
        "機械学習の基礎を学び、キャリアをスタートさせたい学生や職業転換を考えている社会人。",
        "深層学習を学ぼうとしたけれど、途中で挫折した経験がある方。"
      ]
    },
    {
      "title": "겁나 쉬운 지도 데이터 시각화",
      "url": "https://www.udemy.com/course/ezmapdata/",
      "bio": "코딩 한줄 없이 지도에 자신의 데이터를 표현하는 편리한 여러 가지 방법",
      "objectives": [
        "지도에 데이터를 표현하려는 연구자, 학생, 기업인 모두",
        "지역 기반 데이터의 경향을 파악하려는 사람",
        "지역 기반 데이터의 경향을 지도로 표현하여 발표하려는 분",
        "파이썬, R 등 다루지 못하는 분"
      ],
      "course_content": {
        "겁나 쉬운 지도 데이터 시각화": [
          "1과. 경도 위도 점찍기",
          "2과. 위도 경도 추출하기",
          "3과. 엑셀 맵 투어",
          "4과. 지도같은 차트",
          "5과. 한국 지도 SGIS 이용"
        ],
        "보충 및 자세한 강의": [
          "6과. 파워포인트 도형의 장점",
          "7과. 엑셀 맵 투어의 자세한 강의",
          "5과. 한국 지도 SGIS 이용의 자세한 강의"
        ]
      },
      "requirements": [
        "인터넷 연결되는 컴퓨터와 표현하려는 데이터"
      ],
      "description": "지역과 관련된 데이터는 지도상에 표현할 때 비로소 파악되는 경향이 있습니다.\n또 자신의 데이터를 지도상에 표현할 때 보다 명확하게 청중들이 이해할 수 있습니다.\n한편 R이나 파이썬이나, 구글, 엑셀의 지도들이 훌륭하지만,\n만들기 어렵거나, 한국의 지도에 맞지 않는 경우가 있습니다.\n특히 세종시가 잘 표현되지 않는 것은 아주 오래 전부터 고질적인 문제입니다.\n이에 한국 지도에 특화된 표현 방법도 이 강의에서 다룹니다.\n코딩없이 누구라도 쉽게 만들 수 있습니다.",
      "target_audience": [
        "R이나 파이썬 등 다루지 못하면서도 자신의 데이터를 지도에 표현하려는 분"
      ]
    },
    {
      "title": "Aprenda CNNs de forma Fácil e Rápida!",
      "url": "https://www.udemy.com/course/classificacao-de-imagens/",
      "bio": "Aprenda a criar e editar uma rede neural convolucional, utilizando suas próprias imagens",
      "objectives": [
        "Definir e processar imagens para treinamento",
        "Treinamento de modo congelado (utilizando pesos pré treinados)",
        "Uso de parâmetros para melhorar o aprendizado da rede",
        "Entender a estrutura de uma rede neural convolucional"
      ],
      "course_content": {
        "Introdução": [
          "O que você aprenderá neste curso"
        ],
        "Configurações iniciais": [
          "Apresentando plataformas e ferramentas",
          "Configurando ambiente",
          "Selecionando banco de dados I",
          "Selecionando banco de dados II",
          "Selecionando banco de dados III",
          "Fazendo Acesso pelo Google Drive",
          "Primeiras importações"
        ],
        "Definindo Estrutura do dataset": [
          "Ajustando Dataset",
          "Separando os dados do Dataset",
          "Importando bibliotecas"
        ],
        "Treinamento da Rede": [
          "Um pouco sobre redes pré-treinadas",
          "Primeiros passos com o modelo",
          "Entendendo o modelo convolucional",
          "Compilando o modelo",
          "Primeiro treinamento",
          "Salvando o modelo treinado"
        ],
        "Modificação de parâmetros": [
          "Modelo com MobileNet V2",
          "Treinando Modelo MobileNet V2",
          "Validação do modelo",
          "Learning Rate - Taxa de aprendizado variável",
          "Configurando Early Stoping",
          "Imagens Menores",
          "Imagens Maiores",
          "Data Augmentation - Aumento dos dados I",
          "Data Augmentation - Aumento dos dados II",
          "Data Augmentation - Aumento dos dados III"
        ],
        "Final do Curso": [
          "Discussão útil sobre imagens e dataset",
          "Teste Final com imagens do Google"
        ]
      },
      "requirements": [
        "Não há requisitos"
      ],
      "description": "Neste curso você aprenderá a criar uma rede neural convolucional e editar uma enorme quantidade de parâmetros envolvidos.\n\nDesta maneira será possível ensinar sua rede neural com suas próprias imagens, e treiná-la até atingir os resultados que você procura, para aplicar em diversos projetos e ocasiões diferentes. Como:\n\nIdentificação de objetos (onde pode ser utilizado para identificar objetos de maneira geral, sem muitas otimizações)\nIdentificação de objetos específicos (aqui a rede pode ser treinada para atingir um alto nível de confiança para determinado objeto)\nIdentificação de grupos de objetos\nReconhecimento Facial (com determinados parâmetros definidos, é possível reconhecer seu próprio rosto e de seus amigos)\nReconhecimento de objetos em vídeos tempo real (muito ambicioso, porém possível, também é possível ensinar a rede a reconhecer objetos em tempo real, onde a mesma realiza uma varredura em um determinado intervalo de tempo para o reconhecimento de todo o vídeo e assim detectar ou não detectar tal objeto)\nReconhecimento do estado de um objeto (você pode desenvolver um projeto para identificar o estado de objetos, como carros, motos, onibus, etc)\nReconhecimento através de uma webcam como está o clima.\nEntre uma infinidade de ideias criativas prontas para serem feitas após a conclusão deste curso\n\nAproveite para embarcar nesta oportunidade com este curso super didático e prático.",
      "target_audience": [
        "Para quem quer aprender a desenvolver sua primeira rede neural artificial"
      ]
    },
    {
      "title": "[2024년 개정] 데이터분석 전문가(ADP) 자격증 핵심정리 - 필기편",
      "url": "https://www.udemy.com/course/2024-adp/",
      "bio": "[강의 교안 제공] 데이터분석 전문가(ADP) 자격증 필기 시험 핵심 총정리 코스",
      "objectives": [
        "데이터분석전문가 자격증 개요",
        "데이터의 이해",
        "데이터 처리 기술",
        "데이터 분석 기획",
        "데이터 시각화",
        "데이터 분석",
        "기출문제풀이"
      ],
      "course_content": {
        "데이터분석 전문가(ADP) 자격증 따기 - 필기 Part.1": [
          "1 데이터분석전문가 자격증 개요 및 데이터의 이해1",
          "2 데이터의 이해2 - 데이터베이스 특징과 활용",
          "3 데이터의 이해3 - 데이터의 가치와 이해",
          "4 데이터의 이해4 - 가치 창조를 위한 데이터 사이언스",
          "5 데이터의 이해 - 문제풀이(1)",
          "6 데이터의 이해 - 문제풀이(2)",
          "7 데이터의 처리 기술1 - 데이터 웨어하우스",
          "8 데이터의 처리 기술2 - 대용량 비정형 데이터 처리",
          "9 데이터의 처리 기술3 - 분산 데이터 처리",
          "10 데이터의 처리 기술4 - 분산 컴퓨팅",
          "11 데이터의 처리 기술 - 문제풀이(1)",
          "12 데이터의 처리 기술 - 문제풀이(2)",
          "13 데이터 분석 기획1 - 분석 기획의 이해",
          "14 데이터 분석 기획2 - 분석 마스터 플랜",
          "15 데이터 분석 기획 - 문제풀이(1)"
        ],
        "데이터분석 전문가(ADP) 자격증 따기 - 필기 Part.2": [
          "1 데이터 분석 기획 - 문제풀이(2)",
          "2 데이터 분석1 - R 언어 기초",
          "3 데이터 분석2 - 통계 분석 기초",
          "4 데이터 분석3 - 회귀분석",
          "5 데이터 분석4 - 시계열분석",
          "6 데이터 분석5 - 다차원 데이터",
          "7 데이터 분석6 - 데이터 마이닝",
          "8 데이터 분석7 - 분류분석",
          "9 데이터 분석8 - 앙상블/인공신경망 분석",
          "10 데이터 분석9 - 군집분석/연관분석",
          "11 데이터 분석10 - 비정형 데이터 마이닝",
          "12 데이터 분석 - 문제풀이",
          "13 데이터 시각화1 - 시각화 프로세스와 디자인",
          "14 데이터 시각화2 - 시각화 구현",
          "15 데이터 시각화 - 문제풀이"
        ]
      },
      "requirements": [
        "누구나 수강할 수 있습니다."
      ],
      "description": "안녕하세요, ITGO 입니다.\n\n\n본 강의는 [2024년 개정] 데이터분석 전문가(ADP) 자격증 핵심정리 - 필기편입니다.\n\n\n본 과정을 통해 수강생은 데이터분석 전문가(ADP) 자격증 필기 시험에 합격하기 위한 이론을 습득할 수 있습니다.\n\n\n데이터 분석에 필요한 데이터 분석 및 처리기술, 시각화 등 분석을 위한 기초 및 응용 지식을 습득할 수 있습니다.\n\n\n본 강의는 필기 시험 대비 중심으로 진행됩니다.\n\n\n\n\n누구를 위한 강의인가요?\n\n\n데이터분석전문가(ADP) 자격증을 취득하고자 하는 분\n\n\n실무 데이터 분석에 필요한 이론 및 지식을 이해하고 싶은 분\n\n\n데이터분석 관련 분야 취업을 준비하시는 분\n\n\n\n\n무엇을 배우나요?\n\n\n데이터분석전문가 자격증 개요\n\n\n데이터의 이해\n\n\n데이터 처리 기술\n\n\n데이터 분석 기획\n\n\n데이터 시각화\n\n\n데이터 분석\n\n\n기출문제풀이\n\n\n\n\n[2024년 개정] 데이터분석 전문가(ADP) 자격증 핵심정리 - 필기편 강의에 입문해봅시다~!\n\n\n그럼 강의에서 만나요 :)",
      "target_audience": [
        "데이터분석전문가(ADP) 자격증을 취득하고자 하는 분",
        "실무 데이터 분석에 필요한 이론 및 지식을 이해하고 싶은 분",
        "데이터분석 관련 분야 취업을 준비하시는 분"
      ]
    },
    {
      "title": "【初心者向け】パラメータチューニング入門！Pythonで機械学習モデルを構築しパラメータチューニングで精度向上させよう！",
      "url": "https://www.udemy.com/course/parameter-tuning/",
      "bio": "様々なパラメータチューニング手法であるグリッドサーチ・ランダムサーチ・ベイズ最適化（Optunaを使用）の違いを学び、それぞれをPythonで実装しながら身につけていこう！様々なデータセットを使って実際にモデルの精度向上ができるようになろう",
      "objectives": [
        "ハイパーパラメータ・そしてパラメータチューニングとは何か？ なぜ重要なのか？",
        "グリッドサーチによる全探索の方法と利点・限界",
        "ランダムサーチによる高速なチューニング",
        "Optunaによるベイズ最適化の実装とメリット",
        "複数のデータセットを用いたパラメータチューニングの実装"
      ],
      "course_content": {
        "紹介": [
          "紹介"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Searbornについて学ぼう！",
          "Python構文の復習"
        ],
        "パラメータチューニングの基本とグリッドサーチ": [
          "パラメータチューニングを始めよう！",
          "パラメータチューニングの概要をアニメーションで学ぼう！",
          "データセットをインポートしていこう！",
          "使用するデータセットの説明",
          "決定木モデルを構築していこう！",
          "決定木の基礎をアニメーションで学ぼう！",
          "グリッドサーチを実行していこう！",
          "グリッドサーチの探索範囲を細かくして実装してみよう！"
        ],
        "ランダムサーチを実装してみよう！": [
          "ランダムサーチを実行してみよう！"
        ],
        "ベイズ最適化を実装してみよう！": [
          "Optunaで最適なパラメータを見つけてみよう！",
          "Optunaのパラメータ重要度や学習過程を可視化してみよう！",
          "Optunaのパラメータ遷移とランダムサーチのパラメータ遷移を比較してみよう！",
          "パラメータの数を増やすとどうなるか見ていこう！"
        ],
        "年収のデータセットに対して決定木モデルを構築しパラメータチューニングをしていこう！": [
          "データの確認とシンプルな決定木モデルでの実装をしていこう！",
          "パラメータチューニングをしていこう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学びますのでプログラミングの知識は特に必要ありません"
      ],
      "description": "このコースでは、機械学習モデルの精度を向上させる上で非常に重要なパラメータチューニングについて、初心者でも理解できるよう丁寧に解説していきます。\nパラメータチューニングは精度向上における最後のステップとして非常に重要。\n\n\nそんなパラメータチューニングのアプローチである\n・グリッドサーチ\n・ランダムサーチ\n・ベイズ最適化（Optunaを利用）\nについて学び、実際に手を動かしてPythonで実装していきます。\n\n\n具体的には、決定木を乳がんのデータや年収のデータなどに適用させて、分類モデルの精度向上を図っていきます。\nその過程で、それぞれのアプローチの違いを理解し、メリット・デメリットを学んでいきましょう。\n\n\nぜひこのコースでパラメータチューニングをマスターし、機械学習モデルの精度を向上させられるようになりましょう！",
      "target_audience": [
        "パラメータチューニングで少しでも機械学習モデルの精度を向上させたい方",
        "データ分析コンペに挑戦しはじめた初心者",
        "様々なパラメータチューニングのアプローチについて知りたい方"
      ]
    },
    {
      "title": "Derinlemesine Python 2 : Data Science",
      "url": "https://www.udemy.com/course/derinlemesine-python-data-science/",
      "bio": "Veri Bilimi kütüphaneleri",
      "objectives": [
        "Python ile Veri Bilimi yapma; Yapay Zeka ve Makine Öğrenmesi için gerekli bilgiler"
      ],
      "course_content": {
        "Numpy - Diziler (Arrays)": [
          "Dizi Yaratma (Array Creation)",
          "Dizi Öğeleri (Array Elements)",
          "Öğe Türü (Element Type)",
          "Dizi Aritmetiği (Array Arithmetics)",
          "Dizi Doldurma (Array Fill)",
          "Dizilerde Rasgele (Random in Arrays)",
          "2 Boyutlu Dizi (2-Dimensional Array) / Dizey (Matrix)"
        ],
        "Numpy - İleri İşlemler": [
          "Dizinleme (Indexing)",
          "Yayınlama (Broadcasting)",
          "Betilendirme (Reshape)",
          "Düzleştirme (Flatten)",
          "Kuşama (Generate)",
          "Uzay (Space)",
          "Altçizgililer (Underscores)",
          "Dizi Yükleme (Array Loading)"
        ],
        "Numpy - Bilim (Science)": [
          "Sayımbilim (Statistics)",
          "Linear Algebra (Çizgili Cebir)",
          "Sıralama (Sorting)",
          "Arama (Search)"
        ],
        "Matplotlib - Tabanlılar (Basics)": [
          "Temeller (Fundamentals)",
          "İşlev (Function)",
          "Renk / Tüs (Color)",
          "Ulamlı (Categorical)",
          "Eşyükselti (Contour)",
          "Yığıt (Stack)"
        ],
        "Matplotlib- Özelleşik (Custom)": [
          "Alt Çizdirim (Subplot)",
          "Eksenler (Axes)",
          "Biçimletim (Formatting)",
          "Özellikler (Properties)",
          "Yazı (Text)",
          "Ölçek (Scale)"
        ],
        "Matplotlib 3-Boyutlu (3-Dimensional)": [
          "3B Eksenler (3D Axes)",
          "3B Yüzey (3D Surface)",
          "3B Saçılım (3D Scatter)",
          "3B Çubuk (3D Bar)"
        ],
        "Pandas - Tabanlılar (Bascis)": [
          "Derney (Series)",
          "Veri Çatımı (Data Frame)",
          "Türler Sözlüğü (Types Dictionary)",
          "Görünüm (View)"
        ],
        "Pandas - Veri Eyletme (Data Manipulation)": [
          "Sıralama (Sorting)",
          "Dilimleme (Slicing)",
          "Süzme (Filter)",
          "İşlemler (Operations)",
          "Yitik (Missing)"
        ],
        "Pandas - İşlemler (Operations)": [
          "Sayıbilim (Arithmetics)",
          "İliştirme (Append)",
          "Bitiştirime (Concatenate)",
          "Kaynaştırma (Merge)",
          "Uygulamak (Apply)",
          "İşlevsizler (Dummies)"
        ],
        "Pandas - Çözümleme (Analytics)": [
          "Öbekleme (Grouping)",
          "Yığıtlama (Stacking)",
          "Dayanak Çizelgesi (Pivot Table)",
          "Ulamlı (Categorical)",
          "Örneklendirme (Resample)",
          "Çizdirim (Plot)"
        ]
      },
      "requirements": [
        "Temel Python bilgisi"
      ],
      "description": "Bu eğitimde Python ile Data Science (Veri Bilimi) araçları anlatılmaktadır. Numpy, Matplotlib, Pandas, Scipy gibi veri bilimi kütüphanelerinin kullanımı ayrıntısıyla gösterilmektedir. Data Science dışında da Python dili ile geliştirme yapanların kullanacağı kütüphaneler açıklanmaktadır. Artificial Intelligence, Machine Learning, Natural Language Processing, Computer Vision gibi alanlarda kullanılan veri bilimi ve görselleştirme işlemleri içerilmektedir.\nNumpy, sayılarla işlem yapmak için kullanılan, gerektiğinde ve olanaklı olduğundan GPU gibi bilgisayar donanımlarını da kullanarak işlem yapan bir kütüphanedir. Bu araç kendi başına bir çok özellik içerdiği gibi; gerek Veri Bilimi, gerekse Yapay Zeka (Artificial Intelligence) / Makine Öğrenmesi (Machine Learning) konularında yoğun olarak kullanılmaktadır.\nMatplotlib ile grafik işlemleri gösterilmektedir. Bunlardan en önemlileri matematiksel işlevler için bir çok çizdirim (plot) öğeleridir. Grafikler yalnızca görselleştirme (visualization) sağlamak için değil, kullanılan yöntemlerin ne düzeyde doğru çalıştığını izlemek için de kullanılır. Sayılara bakılarak görülemeyen özelliklerin şekillerle anlaşılmasını sağlar.\nPandas betikliği verilerin yüklenmesi ve saklanması, üzerinde değişiklikler yapılması, belli özet bilgilerin elde edilmesi gibi işlevleri içeren yüksek düzeyli bir betikliktir. Numpy gibi düşük düzeyli kütüphanelerdeki özelliklerin Python içindeki bir takım kütüphanelerle birlikte kullanılmasını daha kolay ve düzenli biçimde sağlar.\n\nPandas bölümünün sonunda gerçek veriyle indirme (download), temizleme (clean), çözümleme (analysis) ve çizdirim (plot) işlemleri içeren bir örnek eklenmiştir.\nScipy ise bilim (science) konularında bir çok özellik içermektedir. Bunlardan bir kesimi; matematikçi, finansçı, bilimci ve mühendisler için olduğu kadar veri bilimcileri için de gerekli araçlar da içerir. Başka bir deyişle bir geliştiricinin bilimi kullanmasını sağlar.\nEğitim, daha geniş anlamda kullanıldığında Veri Bilimi kapsamında sayılan Yapay Zeka / Makine Öğrenmesi konularını içermemekte, ancak onlarda kullanılan özelliklerin öğrenilmesini sağlamaktadır. Başka bir deyişle anlatılanlar Yapay Zeka / Makine Öğrenmesi için bir önkoşuldur.\nEğitimde Python dili anlatılmamaktadır. Temel düzeyde bilindiği varsayılmaktadır. Çok ileri Python özelliklerine girilmeden anlatım yapılmaktadır. Öte yandan, Python dilini öğrenenlerin, Veri Bilimi yapmasalar da (örneğin Web Programlama yapsalar da) kendilerini geliştirmek, Python'u iyi öğrenebilmek için ve gerektiğinde kullanabilmeleri için Veri Bilimi öğrenmelerini öneriyoruz. Yapay Zeka konularına girmeleri gerekmese de Veri Bilimi her geliştirici için gereklidir. Python eğitimlerinde dilin kendisi anlatılmaktadır. Ancak gerçek yaşamda nasıl kullanıldığını görmek için belli bir kütüphanenin kullanılması gerekmektedir. Bunun için de veri bilimi uygun bir seçenektir.\n\n\nEğitimdeki örnekleri GitHub sitesinde godoro-education kullanıcısı altında python-data-science adlı depoya katıldıktan sonra görebilirsiniz.",
      "target_audience": [
        "Veri Bilimi ile ilgili çalışma yapmak istenler, Yapay Zeka ve Makine Öğrenmesi alanı için gerekli donanımı kazanmak isteyenler, Python bilgilerini geliştirmek isteyenler."
      ]
    },
    {
      "title": "Fundamentos de geoestatíca em R",
      "url": "https://www.udemy.com/course/fundamentos-geoestatica-r/",
      "bio": "Extraia e gere informações valiosas a partir de dados georreferenciados",
      "objectives": [
        "Fundamentação teórica: princípios matemáticos, estatística espacial e interpoladores",
        "Como interpolar dados espaciais",
        "Tratamento e análises exploratórias de dados geoestatísticos",
        "Estrair previsões a partir de diferentes modelos"
      ],
      "course_content": {
        "Instruções e materiais do curso": [
          "Instruções de acesso e uso do curso",
          "Materiais do curso"
        ],
        "Fundamentos teóricos": [
          "Introdução ao curso",
          "Estatística Espacial, Interpoladores Determinísticos e Krigagem",
          "Fundamentação Matemática",
          "Tipos de Krigagem"
        ],
        "Tratamento de dados": [
          "Amostragem de dados geoprocessados",
          "Análises exploratórias e diagnósticos de dados geoprocessados"
        ],
        "Predição com Krigagem": [
          "Variografia e Estimação",
          "Predição e interpretação",
          "Validação e performance dos Modelos"
        ],
        "Casos Especiais de Modelos Geoestatísticos": [
          "Anisotropia, Simulações Condicionais e Krigagem Bayesiana",
          "Interpolação Espaço-temporal e tridimensional",
          "Considerações Finais e Recomendações"
        ],
        "Conteúdo Bônus": [
          "Modelagem para Radiação e Controle Epidêmico"
        ]
      },
      "requirements": [
        "É desejável conhecimento básico de R (ex: instalação, uso de pacotes). Porém, o conteúdo é acessível a todos os públicos."
      ],
      "description": "A análise estatística de dados em contexto geográfico é um dos tópicos mais importantes atualmente em ciência de dados. Em grande parte isso se deve a crescente necessidade de extrapolar padrões de fenômenos, processos e eventos para grandes áreas no espaco físico. Seja para avaliar e prever um evento meteorológico, áreas de foco de uma doença, potenciais ilhas de calor com as mudanças climáticas, potencial produtivo de culturas agrícolas, áreas foco de crescimento imobiliário ou até mesmo regiões subjeitas a reter ou perder biodiversidade. Isso somente para citar algumas aplicações. Que tal aprender a usar a robustez da geoestatística para interpolar dados espaciais e prever padrões como os exemplificados e muito mais?\n\n\nNesse curso você aprenderá as bases fundamentais e sólidas para aplicações diversas da geoestatística usando a interface amistosa do RStudio e a eficiência da programção R. Esse curso te fornecerá o conhecimento crítico e essencial para aplicá-lo  utilizando exemplos práticos e detalhados para demonstração dos mais usados métodos geoestatísticos. Com esse conhecimento você aumentará o seu valor como profissional no mercado de trabalho, seja nos meios corportativos ou acadêmicos.\n\n\nSe você quer se atualizar para adentrar no ramo do crescente mercado de análises geoestatísticas este curso é para você.",
      "target_audience": [
        "Pesquisadores, professores, pós-graduandos, analistas de dados, estatísticos. Empreendedores e profissionais em geral que desejam enriquecer o currículo."
      ]
    },
    {
      "title": "ChatGPT y DialogFlow: Crea ChatBots y aumenta tus ventas",
      "url": "https://www.udemy.com/course/chat-gpt-y-dialogflow-crea-chatbots-y-aumenta-tus-ventas/",
      "bio": "Maximiza tu potencial de ventas creando ChatBots. De 0 a Experto. Chat-GPT, DialogFlow, Prompt, Marketing y mucho más!",
      "objectives": [
        "Utilizar las herramientas necesarias para crear chatbots personalizados utilizando la tecnología GPT",
        "Integrar los chatbots en diferentes plataformas de mensajería, como Facebook Messenger y WhatsApp, para aumentar la interacción con los clientes.",
        "Recopilar y analizar datos de los chatbots para comprender mejor las necesidades y preferencias de los clientes y mejorar las estrategias de marketing.",
        "Optimizar los chatbots maximizando las conversiones y ventas, a través de la implementación de técnicas de venta efectivas en la interacción con los clientes",
        "Aprender Prompt Básico",
        "Crear ChatBots desde 0 y paso a paso",
        "DialogFlow",
        "Chat-GPT",
        "IA aplicada a Marketing",
        "Aumentar las Ventas de tu Negocio",
        "Proyecto Final de Curso",
        "Archivos Descargables para Ayudarte durante el Curso",
        "Cuestionarios y Preguntas para cimentar los Conocimientos",
        "Introducción a la Inteligencia Artificial",
        "Lenguaje Natural aplicado a Inteligencia Artificial",
        "Casos de Éxitos usando ChatBots"
      ],
      "course_content": {
        "Introducción": [
          "Presentación del curso y el instructor",
          "¿Qué es Chat-GPT y cómo puede ayudar en el marketing?",
          "Cuestionario de la sección 1"
        ],
        "Sección 2: Conceptos básicos de Chat-GPT y preparación del entorno de trabajo": [
          "Introducción a Chat-GPT",
          "Preparación del entorno de trabajo",
          "Buscar información extra sobre DialogFlow"
        ],
        "Creación de ChatBots personalizados": [
          "Introducción a la creación de ChatBots personalizados con Dialog Flow",
          "Entrando en DialogFlow",
          "Creando nuestro primer agente en DialogFlow",
          "Integracion con plataformas de mensajería",
          "Pruebas y optimización del Chat-Bot",
          "ChatBots en DialogFlow"
        ],
        "Sección 4: Optimización del ChatBot para aumentar las ventas": [
          "Profundicemos",
          "Chat-GPT 3.5"
        ],
        "Sección 5: Ejemplos prácticos": [
          "Casos de éxito de ChatBots personalizados en marketing",
          "Práctica guiada: Creación de un ChatBot personalizado para marketing"
        ],
        "Sección 6: Conclusiones": [
          "Resumen del curso",
          "Siguientes pasos en el aprendizaje de creación de ChatBots para marketing",
          "Cierre y agradecimientos"
        ]
      },
      "requirements": [
        "Una computadora con acceso a internet.",
        "Ganas de Aprender"
      ],
      "description": "¡Bienvenido al curso de Chatbots con DialogFlow y Chat-GPT! Este curso es una oportunidad única para aprender cómo crear chatbots personalizados para tu empresa y aumentar tus ventas. En este curso, descubrirás cómo combinar la inteligencia artificial y el aprendizaje automático para diseñar chatbots eficientes capaces de interactuar con tus clientes y brindar una atención al cliente óptima.\nA lo largo de este curso, explorarás las funciones y características de DialogFlow y Chat-GPT 3.5, y aprenderás cómo definir las intenciones, entidades y respuestas del chatbot. Aprenderás cómo integrar el chatbot en tu página web o plataforma de ventas para mejorar la experiencia del usuario y aumentar la eficiencia del servicio al cliente.\nEste curso práctico e innovador te permitirá convertirte en un experto en Chatbots, adquiriendo conocimientos y habilidades para crear chatbots personalizados y mejorar tu negocio. Nuestro equipo de expertos te guiará a través de las últimas técnicas y mejores prácticas en la creación de chatbots, para que puedas llevar tu negocio al siguiente nivel.\n¡No te pierdas esta oportunidad de aprendizaje! Este curso te proporcionará todo lo que necesitas para desarrollar y personalizar un chatbot eficiente para tu negocio. Aprenderás a cómo crear diálogos naturales y automatizar tareas repetitivas de atención al cliente, mejorando la satisfacción de los usuarios y la eficiencia en tu empresa. ¡Inscríbete ahora y comienza a crear chatbots personalizados y eficientes para tu empresa!",
      "target_audience": [
        "A cualquier persona interesada en aprender sobre la tecnología Chat-GPT y cómo se puede aplicar en el campo del marketing. Esto puede incluir a profesionales del marketing digital, propietarios de negocios en línea, emprendedores, desarrolladores de software y estudiantes de tecnología."
      ]
    },
    {
      "title": "【ノーコードGISデータ処理】初めて学ぶQGISによる地理情報データ分析入門",
      "url": "https://www.udemy.com/course/gis-qgis/",
      "bio": "ノーコードでGISデータを分析できるツールQGISを使って、シェープファイルやgeojsonなどのファイルの扱いや可視化をできるようになりましょう",
      "objectives": [
        "GISデータ（地理情報データ）とは何か",
        "QGISのインストール",
        "QGISによるGISデータの可視化",
        "オープンデータのダウンロードとQGISによる可視化"
      ],
      "course_content": {
        "コースの説明": [
          "コース紹介",
          "コース準備レクチャー"
        ],
        "イントロダクション": [
          "GISデータとは",
          "ベクターデータ・ラスターデータ",
          "シェープファイル・geojsonファイル",
          "GISの応用分野",
          "GISデータの分析ソフト",
          "GISデータの座標系：CRS, EPSGコード",
          "地域メッシュ"
        ],
        "QGISインストールと画面の説明": [
          "QGISのインストール方法",
          "QGISのインストール",
          "QGISのUIの説明"
        ],
        "QGIS演習①：基本操作": [
          "地図の表示と地図の追加",
          "演習用オープンデータのダウンロード①",
          "QGISへのCSVファイル読み込み",
          "QGISへのgeojsonファイル読み込み",
          "QGISへのシェープファイル読み込み",
          "一時スクラッチレイヤ",
          "属性データの確認と編集",
          "結果のフィルタリング",
          "点のいろいろな表示方法",
          "ラベリング",
          "ヒートマップ"
        ],
        "QGIS演習②": [
          "演習用オープンデータのダウンロード②",
          "データの可視化演習"
        ],
        "おわりに": [
          "GISデータをダウンロードできるサイト",
          "終わりに"
        ]
      },
      "requirements": [
        "プログラミング経験不問です"
      ],
      "description": "本コースは、プログラミング不要（ノーコード）で地理情報データを扱いたいすべての人のためのオンライン講座です。\nオープンソース のGIS ソフトウェア QGIS を使い、シェープファイル・GeoJSON・CSV など多様なデータ形式の読み込みから、基本的な使い方、可視化までをハンズオン形式で学習します。\n\n\nコースの内容\nGISデータについての基本\nQGIS のインストールと初期設定\n地図やレイヤーの追加\n属性テーブルの操作\nいろいろな可視化手法\nオープンデータの取得と可視化\n\n\n受講条件\n特にありませんが、ストレージが10GB以上は余裕のあるPCがあるとよいです。\nプログラミング経験は必要ありません。\n\n\nGISデータは防災や商圏分析、土地利用、モビリティなど、意外と多くの分野で使用するデータになります。\nプログラミング経験はなくとも、データを読み解くことができると、それは非常に有用な情報となります。\nぜひ本コースを通じて、QGISの基本操作方法を学び、ビジネスなどに活かしていきましょう！",
      "target_audience": [
        "プログラミングはできないがGISデータ（地理情報データ）を扱う必要がある方",
        "QGISを使ってデータの可視化をしたい方"
      ]
    },
    {
      "title": "以 DeepSeek 为翼，助力超级个体腾飞的 5 大商业能力解析",
      "url": "https://www.udemy.com/course/deepseek-5/",
      "bio": "工信部认证讲师带你成为 AIGC超级个体",
      "objectives": [
        "掌握 AI 驱动的商业能力 ：你将深入学习并掌握借助 DeepSeek 等 AI 工具打造的 5 大商业能力，包括营销能力、商业嗅觉、分析能力、管理能力以及学习能力，全面提升自己在商业领域的专业素养和竞争力，为未来的职业发展或创业之路奠定坚实基础。",
        "提升职场竞争力与工作效率 ：通过课程学习，你能够熟练运用 AIGC 技术，将 AI 工具应用到实际工作场景中，无论是产品管理、项目管理还是个人品牌建设等方面，都能实现效率的大幅提升和工作质量的显著优化，让你在职场中脱颖而出，成为备受瞩目的超级个体。",
        "培养敏锐的商业洞察力与创新思维 ：本课程将帮助你培养敏锐的商业嗅觉，学会运用 AI 进行市场洞察、用户研究和行业趋势分析，提前发现商业机会和潜在风险。同时，通过学习 AI 赋能的分析方法和结构化思维，激发你的创新思维，为你在商业决策和问题解决过程中提供全新的视角和思路，助力你在复杂多变的商业环境中保持领先地位。",
        "拓展商业人脉：与志同道合的学员交流互动，拓展商业人脉，共同探索超级个体的发展机遇。"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "第一章 超级个体的5个能力",
          "第二章 超级个体的营销能力",
          "第三章 超级个体的商业嗅觉",
          "第四章 超级个体的分析能力",
          "第五章 超级个体的管理能力",
          "第六章 超级个体的学习能力培养"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "基础认知：对AI技术有一定的了解，但不要求具备深入的技术背景。",
        "学习态度：具有积极主动的学习态度，愿意探索新的商业模式和思维方式。",
        "时间投入：能够合理安排时间，保证课程学习的连贯性和完整性。",
        "实践意愿：有意愿将所学知识应用到实际的商业实践中，勇于尝试和创新。"
      ],
      "description": "DeepSeek 等先进的 AIGC 工具，已经成为了推动企业和个人不断向前发展的有力助手。\n当下，AI 在商业方面的应用正处于高速扩张阶段，越来越多的企业都开始利用 AI 来对业务进行升级和转型。对于未来职场中的员工来说，掌握 AI 驱动的商业能力，会成为大家在职场竞争中的关键优势。\n这门课程是由有着丰富经验和专业背景的莫敏老师打造的。莫老师曾经是腾讯 “欢乐斗地主” 的高级产品经理，还拥有工信部人工智能授权认证讲师、工信部课程研发组成员以及微软认证 AI 工程师等多重身份。凭借在腾讯等知名企业积累的实战经验，以及在 AI 领域的专业知识，莫老师会在课程中为大家讲解如何借助 DeepSeek 等 AI 工具，培养超级个体的 5 大商业能力，帮助大家在职场中崭露头角，实现个人价值的最大化。\n参加这门课程，对你会有很大的收获：\n能够掌握 AI 驱动的商业能力。深入了解营销能力、商业嗅觉、分析能力、管理能力以及学习能力这 5 大商业能力的核心内容，学会运用 DeepSeek 等 AI 工具，让这些能力得到进一步提升，从而在未来商业竞争中占据优势。\n可以提升职场竞争力与工作效率。学会把 AI 技术应用到实际工作场景中，不管是在产品管理、项目管理还是个人品牌建设等方面，都能够大幅提高工作效率，显著优化工作质量，让自己在职场中成为备受关注的超级个体。\n有助于培养敏锐的商业洞察力与创新思维。通过学习如何运用 AI 进行市场洞察、用户研究和行业趋势分析，培养自己敏锐的商业嗅觉，提前发现商业机会和潜在风险。同时，激发自己的创新思维，在商业决策和问题解决过程中拥有全新的视角和思路。\n对于企业员工来说，学习这门课程有着非常重要的意义。企业现在面临着激烈的市场竞争和不断变化的商业环境，只有不断提升员工的商业能力，才能保持企业的竞争力和创新能力。这门课程能够帮助员工掌握 AI 驱动的商业能力，更好地适应企业的发展需求，为企业的数字化转型和业务增长贡献更多的力量。\n快来加入这门课程，开启提升 AI 商业能力的旅程，让我们携手在 AI 时代中勇往直前，创造更加美好的未来！",
      "target_audience": [
        "职场新人与初级从业者 ：如果你刚步入职场，渴望快速提升个人能力，在竞争激烈的职场中脱颖而出，那么这门课程就是为你量身打造。你可以通过学习本课程，借助 DeepSeek 等 AI 工具，掌握先进的商业能力，为自己的职业发展打下坚实基础，无论是面对日常工作任务还是未来的职业晋升，都能凭借所学的 5 大商业能力获得优势。",
        "职场进阶者与中级从业者 ：如果你在职场中已积累了一定经验，但希望进一步突破瓶颈，提升自己在商业领域的专业性和竞争力，这门课程将对你大有裨益。你将深入学习如何运用 AIGC 技术，结合自身工作经验，将 5 大商业能力提升到新的高度，以便更好地应对复杂多变的商业环境，承担更重要的工作职责，实现职场的进阶发展。",
        "创业者与自由职业者 ：如果你是创业者或自由职业者，需要独立应对各种商业挑战，从项目策划、市场推广到运营管理等全方位的工作，本课程能为你提供有力支持。你可以利用 DeepSeek 等 AI 工具，高效地掌握 5 大商业能力，从而在创业或自由职业的道路上，更好地把握市场机遇，提升工作效率，优化业务模式，增强自身的商业竞争力，实现事业的快速发展和成功。"
      ]
    },
    {
      "title": "Dataiku DSS | Formation Complète pour Designers",
      "url": "https://www.udemy.com/course/dataiku-dss-formation-complete-pour-debutants/",
      "bio": "Un apprentissage 100% pratique de Dataiku DSS : construisez vos premiers projets et maîtrisez les fondamentaux",
      "objectives": [
        "Accéder à l'environnement gratuit de Dataiku DSS local",
        "Importer ou se connecter à une source de données",
        "Créer des recettes visuelles pertinentes en fonction du besoin",
        "Répondre à des besoins spécifiques avec des recettes de code",
        "Construire et manager un Flow de bout en bout",
        "Collaborer avec d'autres développeurs sur un ou plusieurs projets Dataiku",
        "Créer des visuels pertinents et les consolider dans des dashboards publiables ou exportables",
        "Orchestrer et automatiser avec les scénarios"
      ],
      "course_content": {},
      "requirements": [
        "Aucune expérience sur Dataiku n'est nécessaire",
        "Des connaissances basiques dans n'importe quel langage de programmation (Python de préférence) sont un plus"
      ],
      "description": "Vous souhaitez apprendre à utiliser Dataiku DSS, la plateforme collaborative incontournable pour la préparation et l’analyse de données ?\nCette Formation Complète et Pratique vous guide pas à pas dans l’utilisation des fonctionnalités essentielles de Dataiku.\nL’objectif : apprendre en faisant. Chaque chapitre est orienté projet, avec des manipulations concrètes qui vous permettront de développer de vraies compétences opérationnelles.\nÀ travers des exercices pratiques, vous apprendrez à :\nImporter, explorer et nettoyer des jeux de données.\nCréer des pipelines de traitement visuels avec les Recipes.\nConstruire et organiser vos projets autour du Flow.\nExplorer les possibilités de Dataiku avec Python.\nRéaliser des visualisations pour analyser vos données avec les Dashboards.\nAutomatiser vos tâches avec les Scénarios.\nGagner en autonomie dans la gestion d’un projet Dataiku de bout en bout.\nAucun prérequis technique avancé n’est nécessaire pour suivre ce cours : une simple curiosité pour la data et des notions basiques en Python suffisent pour démarrer.\nCette Formation Complète s’adresse aux Professionnels et Etudiants en Data Science, Data Engineering, ou encore aux Data Analysts souhaitant enrichir leurs compétences.\nQue vous soyez en reconversion professionnelle, en formation académique ou déjà en poste, ce cours vous permettra d’acquérir des bases solides pour travailler efficacement avec Dataiku DSS et préparer vos futurs projets data.",
      "target_audience": [
        "Data Analysts, Data Scientists, Data Engineers, ou autres professionnels de la Data devant travailler sur Dataiku DSS"
      ]
    },
    {
      "title": "데이터사이언스 훈련소 - 입소하기",
      "url": "https://www.udemy.com/course/datasciencefirst/",
      "bio": "데이터로부터 의미있는 정보를 추출해내기 위한 데이터 사이언스!",
      "objectives": [
        "데이터 사이언스의 기초 개념 및 데이터의 중요성을 알 수 있다.",
        "데이터 분석의 기반이 되는 기초 통계 용어를 이해하고 이를 직접 설명할 수 있다.",
        "산업별 데이터 분석 사례를 통하여 데이터 사이언스의 활용에 대해서 알 수 있다.",
        "통계 기법 유형에 대해서 학습하고 이를 활용할 수 있다."
      ],
      "course_content": {
        "데이터 사이언스 기초": [
          "01. 데이터 사이언스란",
          "02. 왜 배워야할까",
          "03. 데이터 사이언스의 개념",
          "04. 데이터 사이언스 로드맵",
          "05. 데이터 사이언스의 절차",
          "06. 데이터 사이언티스트란",
          "07. 데이터 사이언스의 활용"
        ],
        "통계 주요 용어 및 상식": [
          "08. 데이터 사이언스 통계 주요 용어 및 상식",
          "09. 통계 주요 용어",
          "10. 통계 주요 상식",
          "11. 통계 기법 유형",
          "12. 베이즈 정리",
          "13. Monte Carlo Method",
          "14. 정규분포",
          "15. 추정이론",
          "16. 가설검정",
          "17. 주성분 분석"
        ]
      },
      "requirements": [
        "데이터 분석의 기반이 되는 기초 통계를 설명하기 때문에 선수지식은 없어도 됩니다."
      ],
      "description": "데이터 분석을 이해하기 위해서는 통계 관련 지식을 필수로 이해하여야 합니다.\n머신러닝 및 딥러닝 과정을 수강하기 전에 이 강의를 먼저 수강하시면 좋습니다.\n데이터 사이언스에 대해 생소한 분들도 데이터 분석 기초가 되는 통계 지식을 한 번에 이해할 수 있도록 정리해드립니다!\n\n\n\n\n■ 데이터 사이언스의 개념, 로드맵, 활용 방법 등에 대해서 알려드립니다.\n\n\n데이터 분석이 중요한 이유부터 데이터 분석의 학문적인 접근까지 정리할 수 있다.\n데이터 사이언스 로드맵에 대해서 알 수 있다.\n데이터 전문 분석의 절차에 대해 학습할 수 있다.\n데이터 사이언티스트의 역할에 대해 학습함으로써 그들의 직무에 대한 이해도를 높일 수 있다.\n\n\n■ 데이터 분석을 위한 통계 주요 용어 및 상식에 대해서 정리해드립니다.\n\n\n통계의 기본이 되는 주요 용어에 대해 학습할 수 있다.\n통계를 이해하기 위한 기본 상식을 알 수 있다.\n통계 기법 유형에 대해서 학습할 수 있다.\n베이즈 정리, Monte Carlo Method, 정규분포, 추정이론, 가설검정, 주성분 분석 각 특징을 알아보며 이를 정리할 수 있다.",
      "target_audience": [
        "데이터 사이언스의 개념을 처음 접하는 분",
        "데이터 사이언티스트와 협업하는 비전공자",
        "예비 데이터 사이언티스트"
      ]
    },
    {
      "title": "OpenAI gpt-oss 20B / Goole Gemma 3n 4Bファインチューニング完全攻略講座",
      "url": "https://www.udemy.com/course/gpt-oss-20b/",
      "bio": "〜Google Colaboratory無料環境から本格運用まで、次世代AIファインチューニング実践〜",
      "objectives": [
        "gpt-oss 20BモデルをGoogle Colabでファインチューニング",
        "gemma-3n 4bモデルをGoogle Colabでファインチューニング",
        "Unslothフレームワークを使用した効率的なメモリ管理手法を実装",
        "MXFP4量子化とLoRA技術により、通常65GB必要な処理を14GBで実現する方法をマスターします",
        "32個のエキスパートから最適な4つを動的に選択するMoE（Mixture of Experts）の仕組みを理解し活用できます",
        "Reasoning Effort（Low/Medium/High）を適切に調整し、用途に応じた推論精度と速度のバランスを最適化できます",
        "複雑な数学問題や科学的分析に対応する高精度AIシステムを構築できます",
        "Multilingual-Thinkingデータセットを活用した多言語対応推論モデルを構築できます",
        "医療、金融、教育など特定ドメインに特化したAIアシスタントを開発できます",
        "ShareGPT形式やHarmonyテンプレートへのデータ変換と前処理を実装できます",
        "gemma 3n 4bモデルを使用した音声認識システムを構築できます",
        "画像認識とテキスト処理を統合したマルチモーダル推論を実装できます",
        "音声・画像・テキストを自在に行き来する統合AIアプリケーションを開発できます",
        "VRAM不足エラーの対処法（勾配累積、バッチサイズ調整など）を習得します",
        "学習が収束しない問題の診断と解決方法を実践できます",
        "ファインチューニング後の精度低下を防ぐ最適化手法を適用できます"
      ],
      "course_content": {
        "紹介": [
          "紹介"
        ],
        "GPT-OSS概要": [
          "01_gpt-ossの特徴と利点",
          "MoEとは",
          "量子化(MXFP4)の解説",
          "Reasoning Effortとは？"
        ],
        "環境要件＆セットアップ": [
          "環境要件",
          "Google Colaboratoryの始め方"
        ],
        "Colab無償版(T4 GPU)でのgpt-oss 20bファインチューニング実装ハンズオン": [
          "gpt-oss 20bのVRAMへのロード",
          "LoRAファインチューニングとは",
          "LoRAファインチューニングをする",
          "データセットの説明",
          "データセットの準備",
          "再学習をする。"
        ],
        "Colab無償版(T4 GPU)でのgemma-3n 4bファインチューニング実装ハンズオン": [
          "gemma-3n 4bならT4 GPUでも動く"
        ],
        "Colab Pro/Unit購入方法": [
          "Colab Proから100ユニット買う"
        ],
        "Colab有償版(L4 GPU)でのgpt-oss 20bファインチューニング実装ハンズオン": [
          "gpt-oss 20bファインチューニング"
        ],
        "よくある質問": [
          "よくある質問"
        ],
        "さいごに": [
          "まとめと次のステップ"
        ],
        "資料ダウンロード置き場": [
          "資料置き場"
        ]
      },
      "requirements": [
        "Googleアカウント",
        "無料版のT4 GPU (16GB)でGemma 3nのファインチューニングは可",
        "有償版のL4 GPU(24GB)以上であればgpt-oss 20bのファインチューニングも可（見るだけであれば契約の必要なし）",
        "Python基礎文法の理解（変数、関数、リストなど）（推奨）"
      ],
      "description": "OpenAIが贈る革命的オープンソースAI「gpt-oss 20B」を完全マスター！\nついにOpenAIが完全オープンソース化した大規模言語モデル「gpt-oss 20B」。本講座では、無料のGoogle Colab環境から始まり、本格運用レベルまで、この最先端AIモデルのファインチューニングから実践活用まで、段階的にすべてを体験できます。\n◆ 講座の特徴\n無料環境で基礎習得: Google Colab T4 GPUで推論・軽量ファインチューニング体験\n有償環境で本格実践: Colab Pro L4 GPUで大規模ファインチューニングまで完全網羅\n驚異的メモリ効率: Unsloth最適化により、わずか14GBでファインチューニング実現\n可変推論レベル: Low/Medium/Highで精度と速度を自在に調整\n多言語対応: 日本語を含む複数言語での高精度推論\n実践重視: 数学問題解決、専門ドメイン対応など実用例が豊富\n◆ 豊富な実習コンテンツ\n動作検証済みJupyter Notebookを全受講生に配布\n段階別学習パス: 無料環境→有償環境→本格運用の流れで確実にスキルアップ\nMoEアーキテクチャとMXFP4量子化の仕組み解説\nLoRAによる効率的パラメータチューニング実践\nカスタムデータセットでの専門モデル構築\nマルチモーダル拡張: Gemma 3n 4Bとの連携で音声・画像認識も体験\n◆ 学習ステップ\n◎ 基礎編（無料Colab T4）: モデル理解・推論実行・軽量チューニング ◎ 実践編（Colab Pro L4）: 本格ファインチューニング・専門モデル構築 ◎ 応用編: 商用デプロイ・スケーリング・運用ノウハウ\n◆ こんな方におすすめ\nAI研究者・エンジニアで最新モデルをいち早く活用したい方\nまずは無料で試してから本格導入を検討したい企業担当者\n限られた計算資源で効率的にAIをカスタマイズしたい方\nオープンソースAIの可能性を最大限引き出したい方\n◆ 受講後に身につくスキル\n○ Apache 2.0ライセンスモデルの商用活用ノウハウ ○ コスト効率を考慮した環境選択と段階的スケーリング手法 ○ メモリ効率的ファインチューニング技術（80%メモリ削減） ○ 推論レベル最適化による用途別パフォーマンス調整 ○ 多言語・マルチモーダルAIアプリケーション開発基盤\n◆ 特典\n無料環境で始めて、必要に応じて本格環境へステップアップ！ 初心者から上級者まで、予算と目的に合わせて最適な学習パスを選択できます。\nOpenAI最新技術を、今すぐあなたの手で！",
      "target_audience": [
        "AIエンジニアを目指す初心者・学生",
        "就職・転職活動中で、ポートフォリオに最先端のLLM開発経験を追加したい方",
        "独学でAIを学習中だが、理論だけでなく実際に動くものを作りたい方",
        "プログラミング初心者でも、AIの世界に飛び込んでみたい意欲的な方",
        "Webエンジニア・アプリ開発者で、自社サービスにAI機能を組み込みたい方",
        "バックエンドエンジニアで、LLMのファインチューニング技術を習得したい方",
        "データサイエンティストで、最新のオープンソースLLMを業務に活用したい方",
        "既にChatGPT APIを使用中だが、コスト削減のため自前モデルを構築したい方",
        "DX推進担当者で、社内にAIソリューションを導入検討している方",
        "プロダクトマネージャーで、AI機能の実装可能性を技術的に理解したい方",
        "経営者・起業家で、AIビジネスの技術的な基盤を理解したい方",
        "マーケター・企画職で、AIを活用した新サービスを企画している方",
        "大学院生・研究者で、最新のMoEアーキテクチャを研究に活用したい方",
        "教育関係者で、学生にAI技術を実践的に教えたい方",
        "技術ライター・ブロガーで、最新AI技術を正確に理解し発信したい方"
      ]
    },
    {
      "title": "KNIME NODE'S (Temel Kullanıcı Eğitimi)",
      "url": "https://www.udemy.com/course/knime-nodes-temel-kullanc-egitimi/",
      "bio": "Eğitim amacı knime programına giriş ve node (düğüm)’ ların çalışma presibini anlamak üzerine kurgulanmıştır.",
      "objectives": [
        "Knime programını kullanmayı,",
        "Node'ların çalışma presibini,",
        "Node'lar arasında ilişki kurmayı,",
        "Knime programı ile temel analizlerini yapabilmeyi,",
        "Knime programı ile verileri işlemeyi,"
      ],
      "course_content": {
        "Tanışma ve Knime Programına Giriş": [
          "Tanışma",
          "Knime Download",
          "Knime Arayüz'ü Tanıyalım",
          "Workflow Oluşturma",
          "Workflow'a Not Eklemek",
          "Workflow Çalışma Alanının Özelleştirilmesi",
          "Node Yapıları",
          "Node Özelleştirme",
          "Kullanılan DataSet'ler"
        ],
        "Knime Node's": [
          "Excel Reader",
          "CSV Reader",
          "Column Filter",
          "Row Filter",
          "Rule Based Row Filter",
          "Duplicate Row Filter",
          "Column Rename",
          "Column Combiner",
          "Cell Replacer",
          "Concanate",
          "Node Port ekleme",
          "Missing Value",
          "Row Splitter",
          "Math Formula",
          "String Manipulation",
          "String Manipulation (Multi Column)",
          "Excel Writer",
          "Rule Engine",
          "Group By",
          "Pivotting",
          "Rank (Derecelendirme)",
          "Meta Node",
          "Join Teori",
          "Joiner Uygulama",
          "Statistic",
          "Table Creator",
          "Varaible Creator",
          "Partitioning"
        ]
      },
      "requirements": [
        "Temel bilgisayar kullanma yeteneği"
      ],
      "description": "KNIME ismi Konstanz Information Miner yani Konstanz Bilgi Madencisinin kısaltmasından oluşmuştur. KNIME açık kaynak ve çapraz platform veri analizi, raporlama, entegrasyon platformudur. KNIME, modüler veri hattı konsepti aracılığıyla makine öğrenimi ve veri madenciliği için çeşitli bileşenleri içerir ve bu araçlara \"node\" denir. Görselleştirme, modelleme ve veri analizi için (ETL) temel veri ön işleme nodelarını bir kullanıcı grafik arabiriminde herhangi bir kod yazmadan kullanılmasını sağlar.\n\n\nNeden Knime ?\no Açık kaynak olması.\no Bütünleşik bir veri analiz aracıdır.\no Knime’ın node (düğüm) adı verilen bileşenleri sürükle bırak yöntemi ile çalışır.\no Node yapıları ile kod yazmadan görselleştirme, modelleme ve veri analizi için temel veri işleme işlemlerini gerçekleştirebilirsiniz.\n\n\nBu eğitim,\no Knime programını öğrenmek isteyen,\no Analitiğe, veri bilimine ilgisi olan,\no Kod veya formül yazmadan veriyi işleyerek anlamlı sonuçlar çıkarmak isteyen,\no Veri analizi sürecini keyifli bir hale getirmek isteyen herkes için uygundur.\n\n\nEğitim amacı knime programına giriş ve node (düğüm)’ ların çalışma presibini anlamak üzerine kurgulanmıştır.\n\n\nNOT: Bu eğitime istekler doğrultusunda yeni node'lar ekleyerek güncel tutacağım.\n\n\nKNIME, Gartner tarafından 2014, 2015 ve 2016 yılında yayınlanan İleri Veri Analitiği Quadrantında sürekli olarak Liderler grubunda yer almakta ve yükselişini sürdürmektedir.\nKNIME’ın Veri Analitiği ile ilgili akademik araştırmalarda kullanımı R ve Pyhton’dan sonra en fazla artışa sahiptir. Güçlü fonksiyonları, kolay kullanılan görsel programlama ve açık sistem yapısı ile gittikçe yaygınlaşmaktadır.\nKNIME, GARTNER tarafından da artan bir trend olan tarif edilen Citizen Data Scientist kavramını destekleyecek şekilde güçlü fonksiyonların programlama bilmeyen kullanıcılar tarafından görsel arayüzden kolaylıkla kullanabilmesi sağlanmakta, iş analistlerinin de süreç içinde daha etkin görev almasını sağlamaktadır.",
      "target_audience": [
        "Veri ile işi olan, veriyi işleyerek değer üretmek isteyenler,",
        "Kod yazmadan görselleştirme, modelleme ve veri analizi için temel veri işleme işlemlerini gerçekleştirmek isteyenler",
        "Veri bilimine meraklı başlangıç yapmak isteyen kişiler,",
        "Analitik alanda ilerlemek isteyip başlangıç yapmak isteyenler,"
      ]
    },
    {
      "title": "Introdução prática à Análise de Sentimentos em Python",
      "url": "https://www.udemy.com/course/introducao-pratica-a-analise-de-sentimentos-em-python/",
      "bio": "Conheça relevantes conceitos de Machine Learning e Análise de Sentimentos com este curso para iniciantes",
      "objectives": [
        "Conceitos relevantes de Data Science, Machine Learning e Análise de Sentimentos",
        "Configurar ambiente de desenvolvimento virtual",
        "Instalar bibliotecas de Python com PIP",
        "Extrair dados de bases em arquivos .csv",
        "Processar textos com NLTK e RE",
        "Salvar e carregar dados com Pickle",
        "Vetorizar textos com Scikit-Learn",
        "Classificar textos usando os algoritmos Naive Bayes e Support Vector Machine com Scikit-Learn",
        "Analisar sentimentos em textos"
      ],
      "course_content": {
        "Apresentação do curso": [
          "Apresentação"
        ],
        "Conceitos de Ciência dos Dados, Aprendizado de Máquina e Análise de Sentimentos": [
          "Conceitos de Ciência dos Dados, Aprendizado de Máquina e Análise de Sentimentos"
        ],
        "Requisitos de infraestrutura e configuração do ambiente de trabalho": [
          "Requisitos de infraestrutura e configuração do ambiente de trabalho"
        ],
        "Base de dados": [
          "Base de dados"
        ],
        "Extração e processamento de dados": [
          "Extração e processamento de dados"
        ],
        "Vetorização de texto": [
          "Vetorização de texto"
        ],
        "Classificação de texto": [
          "Classificação de texto"
        ],
        "Avaliação de classificação": [
          "Avaliação de classificação"
        ],
        "Análise de sentimentos em textos avulsos": [
          "Análise de sentimentos em textos avulsos"
        ],
        "Avaliação do curso": [
          "Compartilhe o repositório público criado com arquivos do projeto em seu GitHub"
        ]
      },
      "requirements": [
        "Noções de lógica de programação",
        "Noções de orientação a objetos",
        "Noções de Python 3.x",
        "Computador com acesso à internet",
        "Python 3.8.2",
        "Visual Studio 1.44.2 ou superior"
      ],
      "description": "Este curso foi criado para integrar a Semana de Sistemas de Informação da Universidade Federal Rural de Pernambuco. Porém, qualquer pessoa pode fazê-lo se ignorar os momentos em que eu falo sobre a SEMSIS ou sobre avaliação que condiciona o certificado da SEMSIS. O certiticado padrão da Udemy é disponibilizado a todos que concluírem. Este curso trata de relevantes tópicos de Machine Learning e Análise de Sentimentos através de uma abordagem realmente prática. Os participantes serão instruídos para que compreendam a breve teoria apresentada e, em suas próprias máquinas, desenvolvam aplicações em Python capazes de analisar sentimentos em textos por meio do emprego de tecnologias e paradigmas atuais, realizando operações diversas sobre dados variados e implementando classificadores baseados em Naive Bayes e Support Vector Machine treinados para, enfim, visualizar, entender e comparar resultados. Não é necessário ter conhecimentos prévios de Data Science.",
      "target_audience": [
        "Estudantes e entusiastas da linguagem de programação Python que queiram aprender sobre Machine Learning e Análise de Sentimentos através de uma abordagem prática"
      ]
    },
    {
      "title": "รู้จัก AI ทุกแง่มุมในคอร์สเดียว",
      "url": "https://www.udemy.com/course/technical-introduction-to-ai/",
      "bio": "Technical Introduction to AI",
      "objectives": [
        "ปูพื้นสร้างความเข้าใจให้เห็นภาพรวมว่าสถานการณ์ AI บนโลกกำลังอยู่จุดไหน ทำความเข้าใจว่า AI คืออะไร, จำเป็นต้องมี AI ด้วยหรือและย้อนดูประวัติความเป็นมา",
        "ทำความเข้าใจว่าอะไรเป็นตัวเร่งที่ทำให้เกิดการพัฒนาก้าวหน้าของ AI, ตัวอย่างการพัฒนาที่ได้ประโยชน์จากตัวเร่ง เช่น Cyber Physical System (CPS) และ Ameca Robot",
        "ทำความรู้จักประเภทของ AI (Narrow AI, AGI, และ Superintelligence)",
        "เข้าใจแนวคิดโดยรวมเกี่ยวกับการแตกสายการทำงานย่อยทั้ง 7 ที่สำคัญของ AI (Subfields of AI) ประกอบไปด้วย Natural Language Processing (NLP), Machine Learning (ML)",
        "ตามด้วย Subfields: Speech Recognition, Robotics, Computer Vision (CV), Expert System, และ Planning and Scheduling คืออะไร เป็นอย่างไร",
        "๊ืสามยูนิตสุดท้ายเราจะไปพูดคุยกันในรายละเอียดเกี่ยวกับ ส่วนการทำงานย่อยของ AI (Subsets of AI) คือ Artificial Neural Networks, Deep Learning และ Generative AI",
        "เรียนรู้ Perceptron หน่วยการทำงานพื้นฐานของ Neural Networks และเรียนรู้โมเดลการทำงานของ Generative AI"
      ],
      "course_content": {
        "Introduction to AI": [
          "AI คืออะไร",
          "ย้อนประวัติความเป็นมาของ AI, จำเป็นต้องมี AI ด้วยหรือ?",
          "ตัวเร่งการพัฒนา AI",
          "ตัวอย่าง AI ที่ได้ประโยชน์จากตัวเร่งการพัฒนา (ระบบ CPS และ Ameca Robot)",
          "ประเภทของ AI (Different Types of AI)",
          "เจ็ดสายงานที่สำคัญของ AI (Subfields of AI)"
        ],
        "ส่วนการทำงานย่อยของ AI (Subsets of AI)": [
          "ส่วนการทำงานย่อยของ AI (Subsets of AI) : 1. Artificial Neural Networks (ANN)",
          "ส่วนการทำงานย่อยของ AI (Subsets of AI) : 2. Deep Learning",
          "ส่วนการทำงานย่อยของ AI (Subsets of AI) : 3. Generative AI"
        ]
      },
      "requirements": [
        "คอร์สนี้มีไว้สำหรับบุคคลทั่วไป บางหัวข้ออาจจะมีการอธิบายเฉพาะลงไปในสาระสำคัญของหลักการทำงานของคอมพิวเตอร์ โดยไม่มีรายละเอียดทางคณิตศาสตร์หรือการเขียนโปรแกรมใดๆ เนื้อหาในคอร์สนี้ไม่ได้อ้างอิงรายละเอียดของแอปพลิเคชัน AI ใดๆ เป็นพิเศษ มีการกล่าวถึงตัวอย่างบางส่วนแค่เพียงพอที่จะสร้างความเข้าใจให้ผู้เรียนมากขึ้นโดยไม่ต้องลงรายละเอียด และแน่นอนความรู้ทั้งหมดที่รวบรวมมาเป็นคอร์สนี้ ผู้บรรยายต้องขอขอบคุณแหล่งข้อมูลต่างๆ หนังสือหลายเล่ม เอกสารงานวิจัย งานการศึกษาที่เปิดเผยให้ความรู้แก่บุคคลทั่วไป ทุกชิ้นสามารถอ้างอิงได้และมีรวมรายการไว้ในส่วนของ References ท้ายคอร์ส"
      ],
      "description": "คอร์สนี้จัดทำขึ้นเพื่อการแนะนำอย่างรวดเร็ว แต่พยายามที่จะครอบคลุมให้ได้ทุกมิติของรายละเอียดวิทยาการด้าน AI เพื่อสามารถพิจารณาว่าควรจะวางใจกับสิ่งนี้อย่างไร ใช้เป็นความรู้พื้นฐานเพื่อต่อยอดในการทำงานและให้สามารถมองเรื่องต่างๆ ได้กว้างไกลขึ้น มองออกว่าในอนาคตอันใกล้ควรวางแนวทางการปรับตัวให้กับตัวเองหรือสมาชิกในครอบครัวอย่างไร เพราะโลกของซอฟแวร์ AI ที่มีความชาญฉลาดระดับเบื้องต้นในวันนี้ ก้าวขาข้างหนึ่งเข้ามาในบ้านเราแล้ว ระบบ AI กำลังคืบคลานเข้ามาเปลี่ยนแปลงวิถีชีวิตและการทำงานของเรา AI จะมีผลกระทบต่อตลาดแรงงานทั่วโลก ไม่มีใครบอกได้ว่าการเตรียมตัวรับมือกับมันให้ทันนั้นต้องทำอย่างไร เอาเป็นว่าควรมาทำความรู้ความเข้าใจเกี่ยวกับมันให้ได้มากที่สุดไว้ก่อน\nคอร์สนี้เป็นการปูพื้นความรู้แนวกว้างในยูนิตแรกเพื่อสร้างความเข้าใจและเห็นภาพรวมว่าสถานการณ์ AI บนโลกกำลังอยู่จุดไหน ทำความเข้าใจว่า AI คืออะไร, ทำไมต้องมี AI, ย้อนดูประวัติของ AI, อะไรเป็นตัวเร่งที่ทำให้เกิดการพัฒนาก้าวหน้าของเอไอ, ตัวอย่าง AI ที่ก้าวหน้าได้เร็วด้วยตัวเร่งการพัฒนา เช่น ระบบ CPS และ Ameca Robot, ทำความรู้จักประเภทของ AI\nก่อนที่จะพาไปสู่ยูนิตที่สอง เป็นการทำความเข้าใจแนวคิดและหลักการทำงานโดยรวมว่า เจ็ดสายงานที่สำคัญของ AI (Subfields of AI) ซึ่งประกอบไปด้วย Natural Language Processing (NLP), Machine Learning (ML), Speech Recognition, Robotics, Computer Vision (CV), Expert System,  และ Planning and Scheduling เป็นอย่างไร\nและสามยูนิตสุดท้ายเราจะไปพูดคุยกันในรายละเอียดเกี่ยวกับ ส่วนการทำงานย่อยของ AI (Subsets of AI) ที่สำคัญ ประกอบไปด้วย แนวคิดการทำงานของ Artificial Neural Networks (ANN), หลักการของ Deep Learning, และ โมเดลการทำงานของ Generative AI",
      "target_audience": [
        "คอร์สนี้มีไว้สำหรับผู้เรียนที่เป็นบุคคลทั่วไปที่สนใจเรื่องราวของ AI, รวมถึงยังเหมาะสำหรับพนักงานในองค์กรต่างๆ ข้าราชการ และนักเรียนนักศึกษาด้วย"
      ]
    },
    {
      "title": "Google AI Studio入門 -コスパ最強の生成AIプラットフォームを学ぼう！-",
      "url": "https://www.udemy.com/course/google-ai-studio-ai/",
      "bio": "プログラミング不要で直感的に操作できる生成AIプラットフォーム「Google AI Studio」を使いこなす技術を学びます。最新の生成AIを手軽に試したい方、AIアプリのプロトタイプを作りたい方、業務や創作活動で使いたい方におすすめです。",
      "objectives": [
        "Google AI Studioの基礎と、使いこなす技術を学びます。",
        "最新の生成AI技術を手軽に包括的に習得します。",
        "Google AI Studio上で、最新のAIモデルを利用したテキスト生成、画像生成、動画生成、音声生成、コード生成などについて学びます。",
        "生成AIのパラメータ調整、そして様々なデータを生成する実験のやり方を学びます。",
        "Gemini APIを活用し、外部サービスに生成AI機能を取り入れる方法を学びます。"
      ],
      "course_content": {},
      "requirements": [
        "プログラミングの知識、経験は不要です。ただ、有る方が理解は進みます。",
        "最新の情報をカバーしていない可能性があります。2025年9月までの情報を元にした講座です。",
        "APIの利用は一部有料ですが、無料の範囲で講義は十分受講可能です。画像生成APIを使う際は支払い方法の登録が必要ですが、受講に必須ではありません。",
        "コードの読み方、書き方に関する解説はありません。",
        "環境はWindowsでもMacでもLinuxでも大丈夫です。",
        "Goolgleアカウントが必要です。"
      ],
      "description": "「Google AI Studio入門」は、生成AI技術を手軽に包括的に習得し、アイデアを形にしたいエンジニア、クリエイター、そしてAI活用の第一歩を踏み出したいすべての方のための講座です。\n\n\n本講座では、Googleが提供する最先端の生成AIモデル「Gemini」、そしてプログラミング不要で直感的に操作できるプラットフォーム「Google AI Studio」を使いこなす技術を学びます。Google AI Studioとは、テキストの生成・要約・翻訳はもちろん、画像や音声、動画ファイルまで扱える、ウェブブラウザ上で簡単にAIを試せる生成AIプラットフォームです。このツールにより、あなたは単なるAIとの対話者から、AIを自在に操り、具体的な成果物を生み出すクリエイターへと進化します。\n\n\n最新の生成AIを手軽に試してみたい方、プログラミングなしでAIアプリケーションのプロトタイプを作りたい方、業務や創作活動にAIを取り入れて効率化したい方に最適です。\n\n\n講座の内容は以下の通りです。\nSection1. Google AI Studioの基礎\n→ Google AI Studioの概要、基本的な画面構成、プロンプトの基本的な書き方まで、Google AI Studioを始めるための第一歩を解説します。\nSection2. Google AI Studioの様々な機能\n→ テキストや画像の生成、音声ファイルの文字起こしと要約、さらにはYouTube動画のURLを入力するだけで内容を分析するなど、多岐にわたる機能を実践的に学びます。\nSection3. Google AI Studioの応用\n→  作成したAI機能を外部のアプリケーションで利用するための「APIキー」の取得方法と、その基本的な考え方についても解説し、開発プロジェクトや業務へのAI統合をサポートします。",
      "target_audience": [
        "アイデアを形にしたいエンジニア、クリエイター、そしてAI活用の第一歩を踏み出したいすべての方。",
        "最新の生成AIができることを一通り検証したい方。",
        "業務や創作活動にAIを取り入れて効率化したい方。",
        "コスパ良く最新のAIのトレンドに追従したい方。",
        "アプリのプロトタイプやインタラクティブなデモを素早く作成したい方。"
      ]
    },
    {
      "title": "Derin Öğrenme & Makine Öğrenmesi & Görüntü İşleme",
      "url": "https://www.udemy.com/course/derin-ogrenme-makine-ogrenmesi-goruntu-isleme/",
      "bio": "Derin Öğrenme, Makine Öğrenmesi, Görüntü İşleme ve Bilgisayarlı Görüde Ustalaşın",
      "objectives": [
        "Makine Öğrenmesi",
        "Derin Öğrenme",
        "Bilgisayarlı Görü",
        "Görüntü İşleme",
        "Yapay Zeka Modellerine Arayüze Entegre Etme",
        "GAN",
        "Depth Estimation",
        "Reinforcement Learning"
      ],
      "course_content": {
        "Görüntü İşleme & Bilgisayarlı Görü": [
          "Terminoloji",
          "OpenCV Resim Okuma",
          "OpenCV ROI",
          "OpenCV Video Okuma",
          "OpenCV ve Numpy ile Basit Şekiller",
          "OpenCV Line",
          "OpenCV Rectangle",
          "OpenCV PutText",
          "OpenCV Circle",
          "OpenCV Ellipse",
          "OpenCV Threshold",
          "OpenCV Renk Uzayları",
          "OpenCV Canny",
          "OpenCV Dilate",
          "OpenCV Blur",
          "OpenCV Contours",
          "OpenCV Find Perimeter",
          "OpenCV Find Area",
          "OpenCV Erode",
          "OpenCV Morfolojik İşlemler",
          "OpenCV ile Takip Algoritmaları -1",
          "OpenCV ile Takip Algoritmaları -2",
          "Yolov8 Nesne Takibi Uygulaması",
          "Kendi Takip Algoritmamızı Yazalım Uygulama",
          "OpenCV ile Şerit Takibi",
          "CAM Shift Takip Algoritması",
          "Plate Recognition (Plaka Tanıma)",
          "Easyocr ile Yazı Okuma",
          "Yolov8 ile Pose Estimation Uygulaması",
          "Yolov8 Resim Nesne Tespiti PyQt5 Arayüzene Entegre Uygulaması",
          "OpenCV ile Araç Sayımı Uygulaması",
          "Mediapipe ile Otonom Araç Kontrolu Detaylı Uygulaması",
          "Maskeleme ile Renk Tespiti Uygulaması",
          "OpenCV Trackbar Giriş",
          "Trackbar Uygulaması",
          "Cascade Uygulaması",
          "Mediapipe ile Hand Estimation",
          "Mediapipe ile Pose Estimation",
          "Mediapipe ile Açı Tespiti",
          "Mediapipe ile Fitness Projesi",
          "Mediapipe ile Şınav Sayımı",
          "Mediapipe ile Rakam Sayımı",
          "YOLO Nedir?",
          "Yolov8 Object Detection Model Eğitimi",
          "Yolov8 Object Detection Test",
          "Yolov8 Classification Model Eğitimi",
          "Yolov8 Classification Test",
          "Yolov8 Segmentation Model Eğitimi",
          "Yolov8 Segmentation Test",
          "Yolov8 Pose Estimation Model Eğitimi",
          "Yolov8 Pose Estimation Test"
        ],
        "Makine Öğrenmesi": [
          "Makine Öğrenmesi",
          "K-Fold Cross Validation",
          "Gradient Descent - Learning Rate",
          "Confusion Matrix - Değerlendirme Metrikleri - Hata Türleri",
          "Outlier (Aykırı Değer) Tespiti",
          "Overfit - Underfit - Optimal Fit",
          "KNN -1",
          "KNN -2",
          "Decision Tree -1",
          "Decision Tree -2",
          "Random Forest -1",
          "Random Forest -2",
          "SVM -1",
          "SVM -2",
          "Naive Bayes -1",
          "Naive Bayes -2",
          "Linear Regression -1",
          "Linear Regression -2",
          "Multiple Linear Regression",
          "Polynomial Regression -1",
          "Polynomial Regression -2",
          "Ensemble Learning -1",
          "Ensemble Learning -2",
          "Clustering -1",
          "Clustering -2",
          "Grid Search -1",
          "Grid Search -2",
          "XGBoost -1",
          "XGBoost -2",
          "Makine Öğrenmesi Final Projesi -1",
          "Makine Öğrenmesi Final Projesi -2"
        ],
        "PyQt5 ile Bilgisayarlı Görü ve Makine Öğrenim Projelerine Arayüz Desteği": [
          "PyQt5 Giriş",
          "PyQt5 Resim Ekleme",
          "PyQt5 Video Ekleme",
          "Haar Cascade Arayüz Uygulaması",
          "Mediapipe Arayüz Uygulaması",
          "Nesne Takip Arayüz Uygulaması",
          "Yolov8 ile Nesne Tespiti Arayüz Uygulaması",
          "Yolov8 ile Nesne Takip Arayüz Uygulaması",
          "Yolov8 ile Araç Hız Tespiti Arayüz Uygulaması",
          "Yolov8 ile Araç Sayımı Arayüz Uygulaması",
          "Facial Emotion Recognition Arayüz Uygulaması"
        ],
        "Derin Öğrenme": [
          "Logistic Regression & Yapay Sinir Ağları",
          "Aktivasyon Fonksiyonları",
          "CallBacks",
          "CNN",
          "Ünlü Mimariler (AlexNet VGG İnception Resnet)",
          "Transfer Learning",
          "Classification & Object Detection & Segmentasyon Farkları",
          "Digit Classification with CNN",
          "Object Detection with vgg16",
          "Semantic Segmentation (Anlamsal Bölütleme) with UNet",
          "Tensofrlow Kullanmadan Numpy ile Rakam Sınıflandırma Uygulaması",
          "İnstance Segmentation",
          "Panothic Segmentation"
        ],
        "GANs": [
          "GANs Nedir ?",
          "DCGAN Uygulama -1",
          "DCGAN Uygulama -2",
          "DCGAN Uygulama -3",
          "DCGAN Uygulama -4",
          "DCGAN Uygulama -5",
          "WGAN Uygulama -1",
          "WGAN Uygulama -2"
        ],
        "Depth Estimation (Derinlik Algısı)": [
          "Depth Estimation (Derinlik Algısı)",
          "Depth Estimation with MİDAS",
          "Monocular Depth Estimation Custom Model Eğitimi -1",
          "Monocular Depth Estimation Custom Model Eğitimi -2",
          "Monocular Depth Estimation with Pix2Pix",
          "Monocular Depth Estimation with CycleGAN",
          "Monocular Depth Estimation - GLPN Model"
        ],
        "Reinforcement Learning": [
          "Reinforcement Learning"
        ]
      },
      "requirements": [
        "Python Programlama Dili"
      ],
      "description": "Görüntü işleme ve bilgisayarlı görü, modern teknolojinin en dinamik ve geleceğe yön veren alanlarından biridir. Bu alanlar, dijital verilerin analizinden, görsel bilgiye dayalı karar süreçlerine kadar birçok kritik uygulama sunar. Hem araştırmacılar hem de uygulayıcılar için bu konularda sahip olunacak bilgi ve beceriler, sağlık, otomotiv, güvenlik, eğlence, tarım ve daha birçok sektörde devrim yaratma potansiyeline sahiptir.\nBu kapsamlı Udemy kursu, görüntü işleme ve bilgisayarlı görü alanında kapsamlı bir eğitim sunarak, teknolojinin tüm inceliklerini anlamanızı sağlayacaktır. Kursumuz, makine öğrenimi (ML), derin öğrenme (DL), Generative Adversarial Networks (GAN), derin tahmin (deep estimation), pekiştirmeli öğrenme (reinforcement learning) ve daha fazlasını kapsayarak, bu teknolojilerin nasıl çalıştığını ve gerçek dünya problemlerini nasıl çözebileceğinizi öğretmeyi amaçlar.\nMakine öğrenimi (ML) ile başlayarak, veri analizi ve modelleme konularında sağlam bir temel oluşturacaksınız. ML'in temel prensipleri ve uygulama alanları hakkında derinlemesine bilgi sahibi olacaksınız. Bu temel üzerine, derin öğrenme (DL) ve sinir ağlarıyla daha karmaşık ve güçlü modeller oluşturmayı öğreneceksiniz. Derin öğrenme ile, görüntüleri daha iyi analiz edebilir, nesne tespiti ve sınıflandırma gibi görevleri daha yüksek doğrulukla gerçekleştirebilirsiniz.\nGenerative Adversarial Networks (GAN) ile tanışarak, veri üretme ve modelleme konusunda çığır açan yöntemleri keşfedeceksiniz. GAN'lar, yapay verilerin oluşturulmasında ve çeşitli uygulama senaryolarında nasıl kullanıldığını anlamanıza yardımcı olacaktır. Derin tahmin (deep estimation) teknikleriyle, karmaşık tahmin problemlerine çözümler üretmeyi öğreneceksiniz. Bu teknikler, verilerinizi daha iyi analiz etmenize ve daha doğru sonuçlar elde etmenize olanak tanıyacaktır.\nPekiştirmeli öğrenme (reinforcement learning) ile, karar verme süreçlerini optimize eden ve dinamik ortamlarda öğrenme yeteneğinizi geliştiren stratejileri keşfedeceksiniz. Bu teknoloji, robotik, oyun tasarımı ve daha birçok alanda geniş bir uygulama yelpazesi sunar.\nKursumuz, temel bilgi ve becerilerden başlayarak ileri düzey konulara kadar kapsamlı bir eğitim sunar. Her bölümde, teorik bilgilerin yanı sıra pratik uygulamalar ve projelerle desteklenen bir öğrenme deneyimi elde edeceksiniz. Güncel teknolojiye dair bilgileri edinerek, profesyonel kariyerinizi ileriye taşıyacak bilgi ve becerilere sahip olacaksınız.\nBu kurs, yapay zeka ve bilgisayarlı görü alanında uzmanlaşmak isteyen herkes için idealdir. Teknolojinin tüm yönlerini öğrenerek, teknoloji dünyasında fark yaratma yolunda önemli adımlar atabilirsiniz. Görüntü işleme ve bilgisayarlı görü alanında kariyerinizi ileriye taşıyacak bilgi ve becerilerle donanmak için bu kursa katılın ve geleceğin teknolojilerini şekillendirin!",
      "target_audience": [
        "Yapay Zekaya meraklı herkes"
      ]
    },
    {
      "title": "Python : 7 Travaux pratiques (TP)",
      "url": "https://www.udemy.com/course/python-7-travaux-pratiques-tp/",
      "bio": "Apprennez la programmation en python grace à 7 travaux pratiques qui couvrent les fondamentaux du langage et plus encore",
      "objectives": [
        "La syntaxe et les operateurs en python",
        "Les fonctions",
        "Les conditions",
        "Les boucles",
        "Les listes",
        "Les dictionnaires",
        "Programmation orienté objet : Les classes"
      ],
      "course_content": {},
      "requirements": [
        "Avoir des notions de base en python",
        "Avoir installé jupyter notebook"
      ],
      "description": "Bienvenue dans ce cours sur python. A La fin de celui ci vous serez capable de réaliser des scripts en python et aurez le bagage nécessaire  pour aborder une carrière dans la data science ou dans le développement web. Practice make perfect dit on. Eh bien cette pensée est le fil conducteur de ce cours ou vous serez confronté à plus d' une soixantaine de taches en python  afin de tester vos connaissances et de découvrir de nouveaux concept.\nNous avons décomposé chaque Exercice de ce contenu en tache pour qu'il soit concis et simple . De plus Chaque Tp s'appuie sur le précèdent et réutilise les concepts passé ce qui fait que par effet boule de neige en traitant un exercice vous révisez aussi les autres notions abordées.\nDans ce cours nous couvrirons  les sujets suivants :\nLa syntaxe de bases en python\nLes fonctions\nLes boucles\nLes conditions\nLes Listes\nLes dictionnaires\nLa programmation orienté objet : Les classes\net bien d'autres....\n\n\nPourquoi choisir ce cours ?\nExplication détaillée de chaque Exercice en vidéo\nJe vous fournis le code source pour chaque tp pour vos propres expérimentations\nDes conseils sur les bonnes pratiques de programmation\n\n\nA qui s'adresse ce cour ?\nLes débutants en programmation .\nLes programmeurs ayant de l'expérience dans d'autres langages qui souhaitent démarrer leur programmation Python.\nLes programmeurs qui connaissent un peu Python mais qui veulent compléter leurs acquis et devenir vraiment compétents.",
      "target_audience": [
        "Débutants en python",
        "Personnes souhaitant pratiquer le langage python",
        "Les programmeurs désirant s'initier à la syntaxe python avec des exercices pratiques"
      ]
    },
    {
      "title": "Data Visualization con Power BI",
      "url": "https://www.udemy.com/course/data-visualization-con-power-bi/",
      "bio": "Aprende y consolida las habilidades esenciales de Power BI",
      "objectives": [
        "Aprenderás las habilidades esenciales en Power BI"
      ],
      "course_content": {
        "Introducción": [
          "¿Qué aprenderemos?",
          "Introducción a Power BI",
          "Instalación y conociendo Power BI"
        ],
        "Conexión a orígenes de datos": [
          "Conexión a Excel",
          "Conexión a CSV",
          "Conexión a TXT",
          "Conexión a XML",
          "Conexión a Carpetas - TXT",
          "Conexión a Carpetas - Excel",
          "Conexión a Word",
          "Scraping Web",
          "Conexión a JSON",
          "Importación de un modelo de datos",
          "Conexión desde Power BI a Azure SQL",
          "Configuración de Parámetros"
        ],
        "Power Query": [
          "Combinar y dividir columnas",
          "Combinar consultas en la Fact Table",
          "Integrar datos anexando consultas en Power Query",
          "Duplicar vs Referenciar",
          "Agrupar filas para crear campos agregados",
          "Limpiar y quitar duplicados"
        ],
        "Introducción a DAX": [
          "Introducción a DAX",
          "Ejercicios de aplicación de funciones DAX",
          "Calendario de tiempo"
        ],
        "Dashboards y publicación": [
          "Creación de un dashboard desde cero",
          "Creación de un dashboard desde cero - Ejercicio 2",
          "Creación de un dashboard desde cero - Ejercicio 3",
          "Creación de una cuenta en el servicio",
          "Publicación en el servicio"
        ],
        "Fin del curso": [
          "Resumen final"
        ],
        "Bonus Lecture": [
          "Bonus Lecture: DataHack"
        ]
      },
      "requirements": [
        "No, solo muchas ganas de aprender =)"
      ],
      "description": "Este curso está dirigido para todos los que quieran aprender o consolidar conocimientos esenciales sobre Power BI. Empezaremos con una introducción al software y su entorno, veremos cómo vincular esta herramienta con diferentes orígenes de datos, y realizar transformaciones de estos mismos aprovechando las funciones de Power BI. Finalmente, aprenderás a elaborar tus propios dashboards desde cero y realizar publicaciones.\nEn la actualidad, Power BI de Microsoft es una de las herramientas más importantes y más usadas en el campo de Business Intelligence. Este curso ha sido diseñado con el objetivo de ayudar a las personas a entender de forma rápida y efectiva el software. El curso adquiere un enfoque práctico que permitirá a los participantes interiorizar de mejor forma los conocimientos.\n¿Qué cosas vas a aprender?\nEntorno de Power BI\nConectarte a orígenes de datos\nTransformación de datos\nElaborar dashboards\nRealizar publicaciones\nContenido de curso\n1. Introducción a Power BI\n2. Conexión a orígenes de datos\n3. Power Query\n4. Introducción a DAX\n5. Dashboards y publicaciones\nNuestro curso te permite aprender a tu ritmo. Si quieres empezar en el mundo de Power BI, este curso te brindará las herramientas necesarias para lograrlo.\nÚnete a la comunidad de DataHackers, ya somos más de 30 mil alumnos aprendiendo temas de Data, Analytics y Cloud.\nAprende, Aplica y Crece con DataHack.",
      "target_audience": [
        "Este curso está dirigido para todas las personas que desean aprender Power BI o consolidar sus conocimientos sobre esta herramienta."
      ]
    },
    {
      "title": "从零构建大数据平台",
      "url": "https://www.udemy.com/course/nnilbwev/",
      "bio": "大数据体系搭建入门",
      "objectives": [
        "1.了解大数据平台是如何形成的",
        "2.了解大数据组件如何应用",
        "3.了解常见大数据开源架构",
        "4.了解如何通过开源生态快速构建大数据平台"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "大数据平台是如何形成的",
          "如何构建大数据平台"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "面向0基础学员"
      ],
      "description": "大数据短短数年之间，就从概念的萌芽，到现在的蓬勃发展，仅仅花费了数年的时间。大数据既是一个被滥用的流行语，也是一个当今社会的真实趋势。“大数据”指代总量与日俱增的数据，这些数据每天都在被捕获、处理、汇集、储存、分析。那大数据到底有何魔力？又能改变什么？\n本门课程内容，是10年以上从事大数据基础设施研发的杨卓荦老师在大数据行业长年摸爬滚打出来的最佳实践的总结，让你对大数据体系有初步认知\n\n\n本节课程是由授课老师与三节课合作制作的。在此，要特别感谢老师的辛苦付出！经历了课程立项、设计、开发中的众多环节，我们才能最终为你呈现现在的这门课程。无论是授课老师还是三节课团队，都希望这门课程能够让你有所收获，希望同学们结合个人工作情况，学以致用。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "1.0-1岁数据分析新人",
        "2.想要进入大数据领域的互联网从业者",
        "3.对大数据工具感兴趣的学习者"
      ]
    },
    {
      "title": "빅데이터분석기사 완전정복 필기편 : Part.1 빅데이터 분석 기획(2)",
      "url": "https://www.udemy.com/course/part1-2-w/",
      "bio": "빅데이터 분석 기획하기! 데이터 분석 계획부터 수집 및 저장 계획까지 함께 배워봅시다.",
      "objectives": [
        "빅데이터 분석 기획",
        "데이터 분석 계획",
        "분석 방안 수립",
        "데이터 수집 및 전환",
        "데이터 적재 및 저장",
        "예상문제 풀이",
        "1과목 빅데이터 분석 기획 마무리 문제 풀이"
      ],
      "course_content": {
        "빅데이터 분석 기획 : 데이터 분석 계획(분석 방안 수립)": [
          "분석 방안 수립(데이터 분석 개념, 데이터 분석 현황, 데이터 분석의 지향점)",
          "분석 방안 수립(데이터 분석 고려사항, 데이터 분석 기획 개념, 특징, 주제 유형, 분류, 필요 역량)",
          "분석 방안 수립(분석 기획 시 고려사항, 데이터 분석 유형 4가지, 분석 마스터 플랜 개념, 수립절차, ISP)",
          "분석 방안 수립(분석 과제 우선순위 평가기준 3가지 단계)",
          "분석 방안 수립(분석 과제 우선순위 선정 및 조정, 사분면 분석 기법 활용, 과제 우선순위 선정, 분석 로드맵 설정)",
          "분석 방안 수립(분석 문제 정의, 하향식, 상향식 접근 방식, 대상별 분석 기획 유형, 빅데이터 분석 방법론 개념, 분석 절차)",
          "분석 방안 수립(빅데이터 분석 방법 유형, KDD 분석 방법론, CRISP-DM 분석 방법론, SEMMA 분석 방법론)",
          "분석 방안 수립(데이터 분석 거버넌스의 개념, 필요성, 구성요소, 관리 대상, 특징, 체계)",
          "분석 방안 수립(데이터 분석 수준진단, 필요성, 목표, 분석 준비도, 분석 성숙도 모델, 분석 수준진단 결과)",
          "분석 방안 수립 예상문제 풀이"
        ],
        "빅데이터 분석 기획 : 데이터 수집 및 저장 계획": [
          "데이터 수집 및 전환(데이터 수집 과정, 데이터 수집 기술 10가지의 종류와 개념)",
          "데이터 수집 및 전환(구조 관점, 시간 관점, 저장 형태 관점에서의 데이터 유형의 종류와 설명)",
          "데이터 수집 및 전환(데이터 변환 5가지 기술, 개인정보 비식별 조치 가이드 라인, 비식별 조치 5가지 방법)",
          "데이터 수집 및 전환(적정성 평가, 사후관리, 재현 데이터 정의, 특징, 종류, 개인정보 익명처리 4가지 기법)",
          "데이터 수집 및 전환(재현 데이터 개념, 특징, 종류, 개인정보 익명처리 4가지, 데이터 품질 특성, 정형, 비정형 품질 기준)",
          "데이터 수집 및 전환(데이터 변환 후 품질 검증 3가지 방법, 데이터 품질 진단 절차)",
          "데이터 적재 및 저장(데이터 적재 개념, 적재 도구 4가지, 데이터 저장 개념, 종류 3가지, NoSQL 유형 4가지, 저장 기술 4가지)",
          "데이터 수집 및 저장 계획 예상 문제 풀이",
          "1과목 빅데이터 분석 기획 마무리 문제 풀이-1",
          "1과목 빅데이터 분석 기획 마무리 문제 풀이-2"
        ]
      },
      "requirements": [
        "한번에 합격하겠다는 의지! 데이터 통계와 데이터 보안 관련 분야 지식이 있으면 좋습니다."
      ],
      "description": "안녕하세요, ITGO 입니다.\n\n\n본 강의는 빅데이터분석기사 완전정복 필기편 : Part.1 빅데이터 분석 기획(2) 강의입니다.\n\n\n빅데이터 분석 기사는 국가 기술 자격증으로 필기와 실기 시험이 있습니다.\n\n\n본 강의는 빅데이터 분석 기사 자격증 취득을 위한 필기 시험 대비 강의입니다.\n\n\n빅데이터 분석 기사 필기 시험 핵심 개념부터 예상 문제 풀이까지 제대로 배워 한번에 합격합시다!\n\n\n\n\n누구를 위한 강의인가요?\n\n\n빅데이터 분석기사(필기) 자격증 취득을 원하시는 분들\n\n\n데이터 분석 직무로의 취업 및 이직을 준비하시는 분들\n\n\n데이터 분석에 대해 공부하고자 하시는 분들\n\n\n\n\n무엇을 배우나요?\n\n\n빅데이터 분석 기획\n\n\n데이터 분석 계획\n\n\n분석 방안 수립\n\n\n데이터 수집 및 전환\n\n\n데이터 적재 및 저장\n\n\n예상문제 풀이\n\n\n1과목 빅데이터 분석 기획 마무리 문제 풀이\n\n\n\n\n빅데이터분석기사 완전정복 필기편 : Part.1 빅데이터 분석 기획(2) 강의에 입문해봅시다~!\n\n\n\n\n그럼 강의에서 만나요 :)",
      "target_audience": [
        "빅데이터 분석기사(필기) 자격증 취득을 원하시는 분들",
        "데이터 분석 직무로의 취업 및 이직을 준비하시는 분들",
        "데이터 분석에 대해 공부하고자 하시는 분들"
      ]
    },
    {
      "title": "Inteligência Artificial com Python NATIVO",
      "url": "https://www.udemy.com/course/inteligencia-artificial-com-python-nativo/",
      "bio": "Aprenda a codificar algoritmos de IA utilizando apenas código nativo",
      "objectives": [
        "Inteligência Artificial, Machine Learning e Deep Learning com Python em código nativo"
      ],
      "course_content": {
        "Introdução ao Curso": [
          "01-Apresentação do Curso de Inteligência Artificial com Python Nativo"
        ],
        "Classificação com K-Nearest Neighbors": [
          "01-Introdução aos Algoritmos de Inteligência Artificial",
          "02-Entendendo a Fase de Treinamento e Execução",
          "03-Entendendo o Posicionamento dos Dados no Plano Cartesiano",
          "04-Cálculo do Algoritmo K-Nearest Neighbors",
          "05-Codificando o Algoritmo KNN em Python",
          "06-Executando o Algoritmo de Machine Learning KNN",
          "07-Executando Outros Exemplos com o KNN",
          "08-Entendendo a Base de Dados do Iris Dataset",
          "09-Classificando Dados de uma Base Real do Iris Dataset",
          "10-Codificação do Arquivo de Conversão - Parte 1",
          "11-Codificação do Arquivo de Conversão - Parte 2",
          "12-Execução do KNN com o Iris e a Classe de Conversão"
        ],
        "Naive Bayes Probabilístico": [
          "01-Fórmula Probabilística do Teorema de Bayes",
          "02-Explicação dos Dados de Treinamento",
          "03-Entendendo os Cálculos de Frequência",
          "04-Explicação dos Cálculos dos Pesos",
          "05-Percentuais Probabilísticos das Entradas para as Classes",
          "06-Aplicando o Teorema de Bayes",
          "07-Codificando o Naive Bayes em Python - Parte 1",
          "08-Codificando o Naive Bayes em Python - Parte 2",
          "09-Executando o Naive Bayes e Corrigindo Erros",
          "10-Outros Testes de Probabilidade com Naive Bayes",
          "11-Último Teste com o Naive Bayes Classificativo"
        ],
        "Naive Bayes Classificativo": [
          "01-Adaptando o Naive Bayes Probabilístico para Classificação",
          "02-Testando o Naive Bayes Classificativo",
          "03-Alterando o Arquivo de Manipulação CSV",
          "04-Classificação com Dados Reais do Titanic"
        ],
        "Árvore de Decisão": [
          "01-Entendendo os Dados de Treinamento",
          "02-Cálculo da Entropia Geral",
          "03-Isolamento dos Valores de Entrada",
          "04-Cálculo da Entropia Local",
          "05-Cálculo do Ganho de Informação para as Entradas",
          "06-Encontrando a Raiz da Árvore de Decisão",
          "07-Raiz, Ramos, Nós e Folhas da Árvore de Decisão",
          "08-Treinamento e Cálculo da Entropia em Python - Parte 1",
          "09-Treinamento e Cálculo da Entropia em Python - Parte 2",
          "10-Cálculo dos Totais das Proporções e Retorno das Entradas",
          "11-Ganho de Informação, Índice da Raiz e Nós da Árvore - Parte 1",
          "12-Ganho de Informação, Índice da Raiz e Nós da Árvore - Parte 2",
          "13-Predominância e Fase de Execução da Árvore",
          "14-Execução do Algoritmo da Árvore de Decisão",
          "15-Correção e Encerramento do Algoritmo Decision Tree"
        ],
        "Regressão Linear Simples": [
          "01-Entendendo o Treinamento da Regressão Linear",
          "02-Fórmulas da Tabela de Resultados",
          "03-Cálculo da Fase de Execução do Algoritmo",
          "04-Entendendo o Plano Cartesiano da Regressão",
          "05-Tipos de Correlação na Distribuição dos Dados",
          "06-Algoritmo da Regressão Linear em Python",
          "07-Executando um Teste de Regressão Linear",
          "08-Utilizando Outros Valores na Fase de Execução",
          "09-Entendendo a API de Cotação do Dólar Comercial",
          "10-Iniciando a Codificação da Previsão do Dólar",
          "11-Finalizando a Codificação e Executando a Predição do Dólar"
        ],
        "Regressão Linear Multivariada": [
          "01-Adaptação do Algoritmo de Regressão Linear Simples",
          "02-Reconhecimento de Padrões com a Regressão Linear Multivariada",
          "03-Melhorando a Estrutura da Fase de Execução",
          "04-Utilizando a Regressão Linear Multivariada em Dados Reais - Parte 1",
          "05-Utilizando a Regressão Linear Multivariada em Dados Reais - Parte 2",
          "06-Executando a Análise Preditiva da Cotação do Dólar"
        ],
        "Regressão Linear Multivariável": [
          "01-Construindo e Executando o Algoritmo de Regressão Linear Multivariável",
          "02-Previsão da Cotação do Dólar com Regressão Multivariável",
          "03-Análise Preditiva do Dólar com Dias Futuros Alternativos"
        ],
        "Clusterização com k-Means": [
          "01-Entendendo o Agrupamento ou Clusterização",
          "02-Aprendizado Autônomo ou Não Supervisionado e Aprendizado Supervisionado",
          "03-Entendendo os Valores de Entrada do Agrupamento",
          "04-Tabela de Grupos Aleatórios e Centróides",
          "05-Calculando a Distância dos Elementos entre os Grupos",
          "06-Próximas Etapas do Cálculo e Atualização dos Centróides",
          "07-Agrupamento Final com o Algoritmo K-Means",
          "08-Codificação do Algoritmo KMeans no Python - Parte 1",
          "09-Codificação do Algoritmo KMeans no Python - Parte 2",
          "10-Codificação do Algoritmo KMeans no Python - Parte 3",
          "11-Clusterização no KMeans com Mais de Dois Grupos",
          "12-Parâmetro de Configuração dos Centroides"
        ],
        "Rede Neural Feedforward": [
          "01-Arquitetura do Neurônio Natural Biológico",
          "02-Estrutura Matemática do Neurônio Artificial",
          "03-Estrutura Matemática da Rede Neural Artifical",
          "04-Treinamento e Execução de uma Rede Neural",
          "05-Entendendo as Configurações da Rede Neural Artificial",
          "06-Codificando o Treinamento e o Gradiente Descendente",
          "07-Codificanto a Fase de Execução com as Épocas e o Backpropagation",
          "08-Executando a Rede Neural Artificial FeedForward",
          "09-Executando a Rede Neural com Múltiplos Elementos de Entrada"
        ]
      },
      "requirements": [
        "Conhecimentos básicos em Programação Python"
      ],
      "description": "Neste curso você aprenderá a desenvolver códigos de Inteligência Artificial utilizando apenas a linguagem Python nativamente sem algoritmos prontos ou bibliotecas de terceiros com exemplos de classificação, regressão e agrupamento/clusterização. Ao codificar tudo do zero isso te possibilitará ter uma visão mais abrangente da teoria matemática e algorítmica por trás dos principais algoritmos de Aprendizado de Máquina, facilitando a sua posterior codificação através de frameworks e bibliotecas prontas. Com isso você terá uma base sólida para a aplicação destes algoritmos que poucos profissionais da área têm.",
      "target_audience": [
        "Programadores Python e Estudantes ou Profissionais da área de Inteligência Artificial"
      ]
    },
    {
      "title": "Aprender Python para Brasileiros: Mechanismo de Busca",
      "url": "https://www.udemy.com/course/aprender-python-para-brasileiros-mechanismo-de-busca/",
      "bio": "Nesse curso voce vai aprender python para ciencia de dados e criar uma sistema de busca.",
      "objectives": [
        "linguagem python básica",
        "estruturas de dados básicas do Python",
        "crie um mecanismo de pesquisa simples do zero",
        "ser capaz de responder a perguntas sobre mecanismos de pesquisa em uma entrevista de emprego básica em ciência de dados"
      ],
      "course_content": {},
      "requirements": [
        "Computador Linux ou Windows"
      ],
      "description": "Nesse curso voce vai aprender Python para ciencia de dados e criar uma sistema de busca. Meu nome é Jasper e tenho 13 anos. Gosto de programar em python e faço isso há 3 anos. Comecei com programação de jogos e mudei para ciência de dados. Morei nos Estados Unidos por 10 anos antes de me mudar para o Brasil. Outras coisas que gosto de fazer incluem basquete e também jogar videogame.\n\n\nA ciência de dados é importante porque combina ferramentas, métodos e tecnologia para gerar significado com base em dados. As organizações modernas são inundadas com dados; há uma proliferação de dispositivos que podem coletar e armazenar informações automaticamente.\nA sua principal função é extrair informações valiosas de dados armazenados de uma empresa que serão importantes para avaliar a situação atual e traçar estratégias mais assertivas para o futuro.\nCom conhecimento em Data Science, o profissional poderá trabalhar em empresas de diferentes portes e setores, podendo ocupar cargos de desenvolvimento de produtos ou inteligência de negócios, além de conquistar cargos de liderança na área de tecnologia e marketing.\nCiencia de dados trabalha com inteligencia artificial. A inteligência artificial (IA) é a capacidade que uma máquina para reproduzir competências semelhantes às humanas como é o caso do raciocínio, a aprendizagem, o planeamento e a criatividade.",
      "target_audience": [
        "brasileiros interessados em uma carreira em ciência de dados"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第11部 企業級的AI解決方案 - Cohere",
      "url": "https://www.udemy.com/course/generative_ai_11/",
      "bio": "關於Command R Plus，Embed，Rerank，Stream，Tool calls，Connector，Text Classification，Agent，FAISS",
      "objectives": [
        "如何使用 Cohere 進行高效的文本生成與語義理解",
        "如何利用 NLP 提高數據分析效率，從海量文本中提取有價值的資訊",
        "從零開始構建智能對話系統、客戶服務自動化解決方案",
        "實現高效的查詢系統與推薦系統，提升企業業務增長潛力"
      ],
      "course_content": {
        "介紹": [
          "課程工具準備",
          "如何使用Poetry"
        ],
        "如何創建Cohere程序": [
          "如何創建我們第一個Cohere AI程序",
          "如何使用Cohere裡面的Stream和RAG功能",
          "如何使用Cohere AI模型調用Tools搜索網絡",
          "如何使用Cohere Agent運行Tool calls獲得運行結果"
        ],
        "如何使用Cohere API各種Endpoints的功能": [
          "如何使用Cohere實現Rerank重新排序",
          "如何使用Cohere實現Embedding嵌入向量",
          "如何使用Cohere做文本分類",
          "如何讓Cohere結構化輸出和使用Connector"
        ],
        "如何使用Cohere結合Tool Calls": [
          "如何在Langchain中定義Agent工具",
          "如何創建Cohere ReAct Agent以及如何修復無法安裝FAISS數據庫問題",
          "如何將VectorStore向量數據庫檢索添加到Agent工具當中",
          "如何用Cohere實現總結"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "如果你正考慮進入生成式 AI 的世界，那麼 Cohere 將是你不可錯過的一大助力。本課程將從零基礎開始，深入剖析 Cohere 的功能和其對當今生成式 AI 應用開發的重要性。我們將帶你探索 Cohere 如何在文本生成、語義搜尋以及重排結果等應用領域脫穎而出，讓你快速上手開發 AI 驅動的應用。\n\n\nCohere 模型應用：學會使用 Cohere 的 Command R+ 來實現文本生成、摘要撰寫、內容重寫及關鍵信息提取等功能。\n語義搜尋：了解如何使用 Cohere Embed 構建語義搜尋應用，讓你能夠更精確地查找和理解文本內容。\n提升搜尋準確性：通過 Cohere Rerank 優化搜尋結果排序，提升用戶體驗。\n\n\n此課程不僅提供理論知識，還會帶領你實踐，讓你能夠將 Cohere 及生成式 AI 模型技術應用到實際項目中。無論你是生成式 AI 領域的新手，還是已有經驗的開發者，這門課程都將成為你實現技術突破的重要一步。\n現在就加入我們，掌握 Cohere 和生成式 AI 開發的無限潛力！",
      "target_audience": [
        "對人工智慧、機器學習和 NLP 感興趣的初學者",
        "尋求提升職場競爭力的開發者、數據科學家及分析師",
        "想利用 AI 創新業務流程的企業領導人與技術專家"
      ]
    },
    {
      "title": "Ciencia de los Datos - Python, Plotly y Leaflet - AulaGEO",
      "url": "https://www.udemy.com/course/aprende-ciencia-de-los-datos/",
      "bio": "Aprenda ciencia de datos con proyectos de pandemia: Cólera y covid",
      "objectives": [
        "Introducción a la visualización de datos",
        "Tipos de datos y tipos de gráficos",
        "Visualización de datos en Plotly",
        "Visualización COVID en Plotly",
        "Trazar datos geográficos en trazado",
        "Gráfico de cólera de John",
        "Gráficos y animación científica y estadística",
        "Mapas interactivos con folleto"
      ],
      "course_content": {
        "Modulo 1. Introducción a visualización de datos": [
          "Introducción a visualización de datos",
          "¿Por qué debemos preocuparnos?",
          "Objetivos de la visualización de datos",
          "Teoría de la Visualización de Datos",
          "Practica"
        ],
        "Módulo 2. Tipos de Datos y Tipos de Gráficos": [
          "Variables continuas e Histograma",
          "Series de tiempo y Gráfico de líneas",
          "Datos categóricos y Gráfico de barras",
          "Tipo de Datos Categóricos y Gráfico Circular",
          "Par de Variables Continuas",
          "Uno Continuo y Uno Categórico",
          "Par de Variable categórica",
          "Práctica"
        ],
        "Module 3. Visualización de datos en Plotly": [
          "Fundamentos de Plotly",
          "Submódulo Plotly y Express",
          "Actualización y personalización de diseños",
          "Práctica"
        ],
        "Módulo 4. Proyecto final": [
          "Proyecto 1"
        ],
        "Módulo 5. Trazar datos geográficos en Plotly": [
          "Mapas de coropletas",
          "Línea en mapas",
          "Áreas rellenas y puntuales",
          "Mapas con burbujas",
          "Mapas con mapa de calor (vista previa habilitada)",
          "Miniproyecto"
        ],
        "Módulo 6. Algunos temas avanzados en Plotly": [
          "Cuadros financieros",
          "Tres diagramas D en Plotly",
          "Subparcelas en Plotly",
          "Práctica"
        ],
        "Módulo 7. Proyecto final 2 (Gráfico de cólera de John)": [
          "Proyecto Mapa Fantasma del Cólera"
        ],
        "Módulo 8. Gráficos científicos y estadísticos": [
          "Gráficos de contorno",
          "Imagen en Ploty",
          "Mapa de calor",
          "Parcelas ternarias",
          "Log Plots",
          "Gráficos estadísticos"
        ],
        "Módulo 9. Animación en Plotly": [
          "Animación usando Plotly Express",
          "Marcos y objetos gráficos",
          "Proyecto de carrera de gráficos de líneas"
        ],
        "Módulo 10. Proyecto final 3 (Exploración de mapas interactivos mediante el folle": [
          "Proyecto final sobre Chipotle"
        ]
      },
      "requirements": [
        "Destrezas matemáticas básicas",
        "Habilidades de Python básicas a intermedias"
      ],
      "description": "Actualmente vivimos en un mundo en el que diariamente estamos procesando datos sobre el entorno en el que desarrollamos nuestras actividades para luego tomar las decisiones que más nos favorezcan.\nEl consumo de información se ha multiplicado exponencialmente debido a la gran cantidad de información que se produce y, aunado a ello, la capacidad de acceso a dicha información a través de Internet es cada vez mayor y es necesario que todos esos datos que estamos consumiendo adquieran significado.\nCuando se le da el tratamiento adecuado a esos datos que surgen diariamente, se analizan, se interpretan y se comunican, se transforman en conocimiento.  La Visualización de datos puede definirse como una técnica para crear animaciones, esquemas o imágenes con la finalidad de comunicar un mensaje.\nEste es un curso para amantes de la visualización de datos.\nSe ha elaborado con ejercicios prácticos del contexto actual para su mejor comprensión y aplicación en 10 horas intensivas.\n#AulaGEO\nEn la primera sección, se explican los principios metodológicos sobre visualización de datos y técnicas de visualización gráfica. Como ejercicio, se desarrolla la extracción e implementación de datos COVID-19 usando python, Plotly y el submódulo express.\nAdicionalmente, el curso incluye la aplicación geoespacial para la representación de datos geográficos utilizando los métodos de Plotly, y como ejercicio se reconstruyen los datos de la investigación de John Snow sobre el cólera.\nFinalmente, se exploran los gráficos científicos y estadísticos y su visualización mediante código de animación. Como proyecto final, el código del folleto se utiliza para explorar mapas interactivos.\n\n\nSection 1: Modulo 1. Introducción a visualización de datos\n1. Introducción a visualización de datos\n\n\n2. ¿Por qué debemos preocuparnos?\n\n\n3. Objetivos de la visualización de datos\n\n\n4. Teoría de la Visualización de Datos\n\n\n5. Practica\n\n\nSection 2: Módulo 2. Tipos de Datos y Tipos de Gráficos\n6. Variables continuas e Histograma\n\n\n7. Series de tiempo y Gráfico de líneas\n\n\n8. Datos categóricos y Gráfico de barras\n\n\n9. Tipo de Datos Categóricos y Gráfico Circular\n\n\n10. Par de Variables Continuas\n\n\n11. Uno Continuo y Uno Categórico\n\n\n12. Par de Variable categórica\n\n\n13. Práctica\n\n\nSection 3: Module 3. Visualización de datos en Plotly\n14. Fundamentos de Plotly\n\n\n15. Submódulo Plotly y Express\n\n\n16. Actualización y personalización de diseños\n\n\n17. Práctica\n\n\nSection 4: Módulo 4. Proyecto final\n18. Proyecto 1\n\n\nSection 5: Módulo 5. Trazar datos geográficos en Plotly\n19. Mapas de coropletas\n\n\n20. Línea en mapas\n\n\n21. Áreas rellenas y puntuales\n\n\n22. Mapas con burbujas\n\n\n23. Mapas con mapa de calor (vista previa habilitada)\n\n\n24. Miniproyecto\n\n\nSection 6: Módulo 6. Algunos temas avanzados en Plotly\n25. Cuadros financieros\n\n\n26. Tres diagramas D en Plotly\n\n\n27. Subparcelas en Plotly\n\n\n28. Práctica\n\n\nSection 7: Módulo 7. Proyecto final 2 (Gráfico de cólera de John)\n29. Proyecto Mapa Fantasma del Cólera\n\n\nSection 8: Módulo 8. Gráficos científicos y estadísticos\n30. Gráficos de contorno\n\n\n31. Imagen en Ploty\n\n\n32. Mapa de calor\n\n\n33. Parcelas ternarias\n\n\n34. Log Plots\n\n\n35. Gráficos estadísticos\n\n\nSection 9: Módulo 9. Animación en Plotly\n\n\n36. Animación usando Plotly Express\n\n\n37. Marcos y objetos gráficos\n\n\n38. Proyecto de carrera de gráficos de líneas\n\n\nSection 10: Módulo 10. Proyecto final 3 (Exploración de mapas interactivos mediante el folle\n\n\n39. Proyecto final sobre Chipotle",
      "target_audience": [
        "Desarrolladores",
        "Usuarios de GIS y Geoespaciales",
        "Investigadores de datos",
        "Cualquier persona interesada en aprender más sobre Python, ciencia de datos o visualizaciones de datos.",
        "Cualquiera interesado en el mundo de la ciencia de datos en rápida expansión"
      ]
    },
    {
      "title": "Cara menggunakan subfinder dan Domainscraper buatan saya",
      "url": "https://www.udemy.com/course/cara-menggunakan-subfinder-dan-domainscraper-buatan-saya/",
      "bio": "How to use my own subfinder and Domainscraper",
      "objectives": [
        "install python",
        "install chocolately",
        "pencarian tools dan AI",
        "Pemasangan server premium buat jualan VPN"
      ],
      "course_content": {
        "Pengenalan": [
          "Instalasi"
        ],
        "Materi Domain": [
          "2. Mencari AI dengan Domain scraper",
          "3. Cara mencari gratisan dengan domainscraper",
          "4. Cara Mencari Online Tools dengan DomainScaper",
          "5. Mencari Tools Rahasia Dengan DomainScraper"
        ],
        "Materi Freenet": [
          "2. Scanning Bug",
          "3. Cara Membuat SSH",
          "4. Cara Mengkoneksikan SSH",
          "5. Membuat Server Premium"
        ]
      },
      "requirements": [
        "harus paham bahasa indoenesai"
      ],
      "description": "Kursus Cara Menggunakan Subfinder dan Domainscraper Saya Sendiri\n\n\nBanyak orang telah menyadari pentingnya dan keuntungan alat subfinder dan domainscraper dalam melakukan aktivitas online yang sukses. Alat-alat ini memungkinkan pengguna menemukan dan mengekstrak informasi berharga terkait domain dan subdomain situs web. Jika Anda tertarik mempelajari cara menggunakan kursus subfinder dan domainscraper Anda sendiri, esai ini akan memberi Anda panduan komprehensif.\n\n\nSebelum mendalami aspek teknis, penting untuk memahami konsep dasar. Subdomain mengacu pada subdivisi domain, yang memungkinkan pengorganisasian berbagai bagian situs web. Di sisi lain, domain adalah alamat internet unik yang ditetapkan ke sebuah situs web. Oleh karena itu, subfinder adalah alat yang berfokus pada mengekstraksi subdomain dari domain tertentu. Sebaliknya, domainscraper dirancang untuk mengikis nama domain menggunakan berbagai sumber dan teknik ekstraksi.\n\n\nUntuk menggunakan kursus subfinder dan domainscraper Anda secara efektif, pertama-tama Anda harus memastikan bahwa kedua alat telah diinstal dan dikonfigurasi dengan benar. Sangat penting untuk mengikuti dokumentasi yang disediakan oleh pengembang atau instruktur kursus. Memiliki dependensi yang diperlukan dan memastikan bahwa dependensi berfungsi dengan lancar adalah penting untuk keberhasilan pengoperasian.\n\n\nSetelah alat diinstal, Anda harus mempelajari cara menggunakannya satu per satu. Biasakan diri Anda dengan berbagai perintah dan opsi yang tersedia untuk menyempurnakan pencarian. Subfinder, misalnya, memungkinkan Anda menentukan jumlah pemindaian bersamaan, kedalaman pencarian, dan parameter lainnya. Demikian pula, domainscraper menawarkan berbagai opsi untuk mengontrol sumber nama domain dan teknik pengikisan.\n\n\nUntuk memaksimalkan manfaat alat-alat ini, disarankan untuk menggabungkan fungsinya. Dengan menggunakan subfinder untuk mengekstrak subdomain dan meneruskannya sebagai masukan ke domainscraper, Anda dapat mengungkap berbagai nama domain yang terkait dengan situs web tertentu. Pendekatan ini memungkinkan Anda melakukan penelitian komprehensif dan mengumpulkan wawasan berharga tentang kehadiran online suatu entitas tertentu.\n\n\nSalah satu aspek penting yang perlu diingat saat menggunakan alat ini adalah penggunaan yang etis. Penting untuk memastikan bahwa Anda tidak melanggar undang-undang atau peraturan apa pun saat menghapus domain atau menjelajahi subdomain. Selalu hormati ketentuan penggunaan dan kebijakan privasi pemilik situs web. Mempraktikkan pengikisan etis tidak hanya menjaga kredibilitas Anda tetapi juga mendorong perilaku yang sah dalam komunitas online.\n\n\nTip berguna lainnya adalah mengotomatiskan proses subfinder dan domainscraper. Melalui otomatisasi, Anda dapat menghemat waktu dan energi, memastikan pengoperasian yang lebih cepat dan efisien. Beberapa bahasa skrip dan pemrograman, seperti Python, menawarkan perpustakaan dan kerangka kerja untuk memfasilitasi otomatisasi. Dengan menggabungkan alat Anda ke dalam kerangka otomatisasi ini, Anda dapat menyederhanakan alur kerja dan mengekstrak informasi berharga dengan lebih mudah.\n\n\nTerakhir, pembelajaran berkelanjutan dan mengikuti perkembangan terkini sangat penting untuk memanfaatkan kursus subfinder dan domainscraper Anda secara efektif. Baik komunitas online maupun pengembang alat ini terus memperkenalkan fitur baru, perbaikan bug, dan peningkatan. Terlibat dalam forum, blog, dan komunitas yang berfokus pada penelitian subdomain dan domain akan membantu Anda mendapatkan wawasan dan memaksimalkan kemampuan Anda.",
      "target_audience": [
        "pemula"
      ]
    },
    {
      "title": "Master the Basics of R Programming from Scratch",
      "url": "https://www.udemy.com/course/master-the-basics-of-r-programming-from-scratch/",
      "bio": "Unlock the Power of R: A Step-by-Step Tutorial for Beginners",
      "objectives": [
        "R Data Types, R Numbers, R Math, R Strings, R Escape Characters, R Booleans / Logical Values, R Operators,",
        "R If ... Else, R Nested If, R - AND OR Operators, R While Loop, R For Loop, R Nested Loops, R Functions",
        "R Nested Functions, R Function Recursion, R Global Variables, R Vectors, R Lists, R Matrices, R Arrays",
        "R Syntax, R Print Output, R Data Frames, R Factors"
      ],
      "course_content": {
        "Introduction": [
          "What is R - How to Install R Studio",
          "How to Print Strings & Variable Contents in R",
          "How To Insert Single & MultiLine Comments in R",
          "Creating Variables in R || Concatenate Variables",
          "Basic Data Type in R language",
          "Number Types in R || Number Type Conversion",
          "Built-in Math Functions in R || Math function in R",
          "Strings in R || String manipulation in R",
          "Boolean / Logical Values in R",
          "Operators in R || Arithmetic Assignment Comparison Logical",
          "Conditional Statements in R || If, Else If and Else in R",
          "While Loop in R Language",
          "For Loop in R Language",
          "Functions in R Language",
          "Global and local variables in R",
          "Vectors in R Programming",
          "Lists in R Programming || How to Create and Access List",
          "How to Create Matrix in R Programming",
          "Array In R Programming || How to Create an Array in R",
          "Data Frames in R Programming || How to Create a Data Frame in R",
          "Factors in R Programming || Using Factors in R"
        ],
        "Practise Test": [
          "R Programming Quizes to Test your Skills"
        ]
      },
      "requirements": [
        "This tutorial will teach you the basics of R. It is not necessary to have any prior programming experience."
      ],
      "description": "Course Description:\nThe Comprehensive R Programming Fundamentals course is designed to provide a solid foundation in using the R programming language. Whether you are new to programming or looking to expand your knowledge, this course covers essential topics to equip you with the necessary skills to manipulate data, perform mathematical operations, work with strings, and control flow in R.\n\n\nModule 1: Introduction to R\n- R Data Types: Learn about the different data types in R, including numeric, character, logical, and factors, and how to work with them effectively.\n- R Numbers and Math: Explore numeric operations, mathematical functions, and handling mathematical expressions in R.\n\n\nModule 2: Strings and Escape Characters\n- R Strings: Master the manipulation and concatenation of strings, string functions, and regular expressions in R.\n- R Escape Characters: Understand how to use escape characters to include special characters in strings.\n\n\nModule 3: Booleans and Logical Values\n- R Booleans / Logical Values: Discover how to work with logical operators and logical expressions to make decisions and control program flow in R.\n- R Operators: Explore arithmetic, relational, logical, and assignment operators in R.\n\n\nModule 4: Conditional Statements and Loops\n- R If ... Else: Learn how to use conditional statements to execute code blocks based on specific conditions.\n- R Nested If: Understand the concept of nesting conditional statements for more complex decision-making.\n- R - AND/OR Operators: Explore the logical operators \"AND\" and \"OR\" to combine multiple conditions.\n\n\nModule 5: Loops in R\n- R While Loop: Master the use of while loops for iterative tasks and condition-controlled repetitions.\n- R For Loop: Learn how to work with for loops to iterate over sequences and perform repetitive operations.\n- R Nested Loops: Understand the implementation of nested loops for more intricate looping tasks.\n\n\nModule 6: Functions and Recursion\n- R Functions: Discover how to create and call functions to modularize code and improve reusability.\n- R Nested Functions: Learn about nesting functions within functions for improved code organization.\n- R Function Recursion: Explore recursive functions and their role in solving complex problems.\n\n\nModule 7: Scope and Data Structures in R\n- R Global Variables: Understand the concept of scope and manage global and local variables in R.\n- R Vectors: Learn about vectors and vectorized operations for efficient data manipulation.\n- R Lists: Discover the power of lists to handle heterogeneous data structures and perform complex data operations.\n- R Matrices: Understand how to work with matrices for advanced mathematical operations.\n- R Arrays: Explore the concept of arrays and their role in multi-dimensional data storage and manipulation.\n\n\nModule 8: Working with Data in R\n- R Data Frames: Learn how to create, manipulate, and analyze data frames for structured data handling.\n- R Factors: Understand factors and their significance in categorical data representation and analysis.\n\n\nBy the end of this comprehensive R programming course, you will have gained a thorough understanding of R's core concepts and be proficient in utilizing its diverse functionalities to solve real-world data analysis and manipulation challenges. Whether you aspire to pursue a career in data science, research, or programming, this course is an excellent starting point to enhance your R programming skills and open doors to new opportunities.",
      "target_audience": [
        "It is a great resource for data analysis, data visualization, data science and machine learning. so anyone can learn the R Programming."
      ]
    },
    {
      "title": "Fortgeschrittener R-Analyst - next Level R Programmierung",
      "url": "https://www.udemy.com/course/fortgeschrittener-r-analyst-next-level-r-programmierung/",
      "bio": "Hebe deine R-Kenntnisse mit R Markdown, Shiny, Datenimputation und Git auf das nächste Level",
      "objectives": [
        "Am Ende dieser Schulung wirst du in der Lage sein, reproduzierbare Berichte auf Knopfdruck zu erzeugen.",
        "Du wirst den Stil des Berichtes auf einfache Weise und zielgerichtet anpassen können.",
        "Du wirst Berichte wiederholt für unterschiedliche Parameter, bspw. neue Datensätze, erzeugen können.",
        "Du wirst in der Lage sein, zu erklären, wie das Grundgerüst von Shiny aufgebaut ist und wie es funktioniert.",
        "Du wirst dynamische, interaktive Shiny-Anwendungen mit Inputs und Outputs erstellen können.",
        "Du die Reaktivität und das Layout deiner Shiny-Anwendungen anpassen können.",
        "Du wirst das generelle Erscheinungsbild deiner Anwendungen via Themes steuern können.",
        "Du wirst in der Lage sein, deine Kreationen ins Web zu deployen",
        "Du wirst effizient und professionell mit einem lückenhaften Datensatz umgehen können.",
        "Du wirst die wichtigsten Methoden kennen, um solche Datensätze für deine Analysen aufzubereiten.",
        "Du wirst die wichtigsten einfachen und fortgeschrittene Methoden zur singulären und multiplen Datenimputation kennen und anwenden können.",
        "Schließlich wirst du in der Lage sein, die Versionierungsoftware Git in Kombination mit RStudio zu nutzen, um kollaborativ an größeren R-Projekten zu arbeiten."
      ],
      "course_content": {
        "Los geht's": [
          "Einführung und Überblick",
          "Schulungsdaten"
        ],
        "R Markdown - Berichte auf Knopfdruck": [
          "Einführung in R Markdown",
          "R Markdown Syntax",
          "Code-Blocks und Inline-Code",
          "Dokument-Header und CSS",
          "Knit with Parameters",
          "Caching",
          "Tipps und mehr…"
        ],
        "Shiny - Interaktive Oberflächen mit R": [
          "Einführung in Shiny - Das Grundgerüst",
          "Inputs",
          "Outputs",
          "Reaktivität",
          "Layout",
          "HTML",
          "CSS",
          "Themes",
          "Deployment",
          "Ausblick"
        ],
        "Datenimputation - Umgang mit fehlenden Werten": [
          "Einführung in Datenimputation - Einfache Methoden",
          "Räumliche Nächste-Nachbarn-Imputation",
          "MICE"
        ],
        "Git & R - Versionskontrolle mit Git und RStudio": [
          "Git - R: Versionskontrolle mit Git und RStudio",
          "Praxis: Installation von Git",
          "Praxis: GitHub mit RStudio einrichten",
          "Praxis: GitHub mit RStudio nutzen",
          "Praxis: Azure DevOps und RStudio",
          "Praxis: Azure DevOps und RStudio über HTTPS"
        ]
      },
      "requirements": [
        "Du solltest sicher mit der Programmiersprache R umgehen können. Es empfiehlt sich den Kurs R-Analyst zu besuchen, auf den dieser Kurs aufbaut."
      ],
      "description": "Hallo und herzlich willkommen zum Fortgeschrittenen R-Analyst!\nIn diesem Kurs steigen wir tiefer in die mächtigen Methoden ein, die R für uns bereithält.\nDabei werden wir lernen, mit Hilfe von R Markdown automatisiert Berichte auf Knopfdruck zu erzeugen. Dabei eigenen wir uns die Fähigkeit an, bspw. PDFs oder auch HTMLs aus R heraus zu generieren, wobei wir dynamisch auf eine veränderte Datengrundlage reagieren können. Sollten sich die Daten von einem auf das nächste Jahr geändert haben, drücken wir nur auf das Knöpfchen und bringen unseren Bericht auf den neusten Stand.\nAnschließend befassen wir uns umfassend mit Shiny. Diese Technologie wird es uns erlauben dynamische, interaktive Anwendungen aus R heraus zu erzeugen. Wir lernen, wie wir unsere Analysen und Ergebnisse in Form von modernen interaktiven Apps zur Verfügung stellen können. Diese Anwendungen werden dann auch noch richtig gut aussehen, „shiny“ eben.\nUnsere Fähigkeiten in der Datenanalyse bauen wir aus, indem wir lernen, wie wir mit fehlenden Werten in unserer Datengrundlage umgehen können. Wir werden sehen, dass es sparsamere Wege gibt mit diesen Datenlücken umzugehen als sie einfach von unseren Analysen auszuschließen. Dadurch werden wir die Qualität aller unserer Analysen erheblich verbessern.\nIm letzten Teil lernen wir, die Versionierungs- und Kollaborationssoftware Git im Zusammenspiel mit R bzw. R Studio zu nutzten. Dadurch werden wir uns die Lage versetzten auch größere R-Projekte in einem Team umzusetzen. Wir heben unsere Arbeit mit R auf ein ganz neues Level, indem wir Git einsetzten, um gemeinsam mit anderen an einem R-Code zu arbeiten. Dabei nutzen wir die Versionskontrolle, um im Notfall \"in der Zeit zurückspulen\" zu können.\nFolgende Inhalte wirst du in diesem Kurs zu beherrschen lernen:\nAutomatisierte Berichte auf Knopfdruck mit R Markdown\nDynamische und interaktive Applikationen mit R und Shiny\nEffizienter Umgang mit fehlenden Werten mit Hilfe von Datenimputation\nVersionskontrollierte und kollaborative Projektarbeit mit R und Git\nHebe deine R-Fertigkeiten auf ein neues Level! Viel Spaß dabei!",
      "target_audience": [
        "Wenn du mit Daten zu tun hast, und diese Daten oder die darauf aufbauenden Analysen (wiederholt) in Berichten präsentieren möchtest, ist dieser Kurs sicherlich das Richtige für dich.",
        "Der Fortgeschrittene R-Analyst Kurs ist auch genau das Richtige für dich, wenn du aus R heraus schicke dynamische, interaktive Apps erzeugen möchtest.",
        "Wenn deine Analysen darunter leiden, dass die Daten, die du nutzt, fehlende Werte beinhalten, solltest du dir diesen Kurs ansehen.",
        "Wenn du in einem mittleren bis großen Projekt R einsetzten möchtest, lernst du in diesem Kurs Git zu nutzen, um versionskontrolliert und kollaborativ zu arbeiten."
      ]
    },
    {
      "title": "データサイエンス実戦講座［第７回］機械学習『予測』線形回帰から一般化線形モデルへ　演習：タイタニック号の事故データ分析",
      "url": "https://www.udemy.com/course/7-sawggf/",
      "bio": "機械学習の「予測・回帰」手法の詳細解説　－多くの変数が相互に影響を及ぼし合う現象を観測データに基づいた統計数理モデルで予測する－",
      "objectives": [
        "自然現象や社会現象のメカニズムを分析するデータサイエンスの様々な手法について、シリーズのコースに分けて1つずつ習得していきます。古典的な頻度論の統計学やベイズ統計学の基礎から、機械学習や多変量解析、そして最新のディープラーニングまで、原理の理解と実務への応用を目指します。",
        "機械学習のなかで予測や回帰と呼ばれる手法について解説します。相関関係と因果関係、統計数理モデルの全体像を把握し、目的変数と説明変数の間に線形（直線）関係があるときに使用する線形回帰モデルと、非線形のときに使用する一般化線形モデルがあることを理解します。",
        "現実の社会現象や物理現象のデータに統計数理モデルをあてはめるときには、相関関係だけでなく因果関係が必要です。因果関係は科学的な根拠や妥当な推論によって導かれるものであり、モデルの意味を正しく解釈して利用するうで不可欠な要素です。",
        "線形回帰モデルのなかで最も基本となる単回帰分析について理解し、複数の説明変数に拡張した重回帰モデルの適用と評価方法を習得します。演習では、賃貸住宅のを部屋の広さから予測する単回帰分析と、さらに駅からの距離、築年数、コンビニまでの距離を加えた重回帰分析の問題に取り組みます。",
        "説明変数が質的データを扱う数量化Ⅰ類について学びます。質的データをダミーデータと呼ばれる数値データに変換することで重回帰分析に拡張します。賃貸住宅の家賃の演習問題で部屋の広さを狭い／普通／広い、などという質的変数のときの分析方法を習得します。",
        "一般化線形モデルについて学びます。データ間に線形関係がないときはリンク関数でデータ変換して線形化したうえで回帰モデルを適用します。代表例として、ポアソン回帰ではコンビニの平均来客数の予測、ロジスティック回帰ではタイタニック号の生存確率の予測の演習問題を通して、手法の適用と評価方法を習得します。"
      ],
      "course_content": {
        "はじめに": [
          "予測・回帰の３つのポイント"
        ],
        "1. 線形回帰モデルの基礎": [
          "1-1 多変量解析と共変量",
          "1-2 予測モデルの体系",
          "1-3 共変動と相関"
        ],
        "2. 単回帰分析": [
          "2-1 単回帰分析の原理",
          "2-2 単回帰モデルの構造",
          "2-3 単回帰モデルの適用と評価"
        ],
        "3. 重回帰分析": [
          "3-1 重回帰分析への拡張",
          "03-2 重回帰モデルの適用と評価"
        ],
        "４. 数量化Ⅰ類": [
          "4-1 数量化理論",
          "4-2 数量化Ⅰ類の原理",
          "4-3 数量化Ⅰ類モデルの適用と評価"
        ],
        "5. 一般化線形モデル": [
          "5-1 一般化線形モデルの概要",
          "5-2 ポアソン回帰分析の適用と評価",
          "5-3 ロジスティック回帰分析の適用と評価"
        ],
        "6. まとめ": [
          "6. まとめ（6 -1 機械学習『予測』手法の体系, 6-2 線形回帰モデル, 6-3 一般化線形モデル）"
        ],
        "ボーナスレクチャ": [
          "ボーナスレクチャ"
        ]
      },
      "requirements": [
        "高校レベルの数学力があれば十分です。なくても丁寧に説明しますので心配ありません。",
        "正確を期すために数理モデルは示しますが、直感的な理解と解釈を重視してグラフや図による説明を主体にします。"
      ],
      "description": "機械学習の予測・回帰の手法について原理から応用まで完全マスターしましょう。ポイントは3つです。\n１.　予測の目的と手段：多くの変数が互いに影響を及ぼし合う社会現象や自然現象において、観測データの挙動に統計数理モデルを当て嵌める回帰分析の手段を用いることによって現象の進展を予測することを目的としています。\n２．数理モデルの体系：正規分布のデータに適用する線形回帰モデル、質的データを扱う数量化Ⅰ類のモデル、非正規分布のデータに適用する一般化線形モデルについて、モデルの構造とデータ挙動に当て嵌めるためのパラメータ推定のアルゴリズムを理解します。\n3. 主要な分析手法：単回帰分析、重回帰分析、数量化Ⅰ類、ポアソン回帰、ロジスティック回帰の５つの手法について、賃貸住宅の家賃の予測、コンビニの１日の平均来客数の予測、タイタニック号の乗客の生存確率の予測などの演習問題を通じて、予測手法の適用方法やモデルの解釈と評価方法を習得します。",
      "target_audience": [
        "学業や業務でデータ分析を必要としている方、将来データアナリストを目指す方、データサイエンスに興味のある方であればどなたでも。",
        "データ分析の初心者から学び直しの中級者。"
      ]
    },
    {
      "title": "Python数据分析科学库经典教程",
      "url": "https://www.udemy.com/course/python-jo/",
      "bio": "实战解析以Python语言为基础的数据分析常用库",
      "objectives": [
        "掌握科学计算库-Numpy",
        "掌握可视化库Matplotlib",
        "掌握可视化库Seaborn",
        "解读常用可视化图形绘制细节"
      ],
      "course_content": {
        "一、科学计算库——Numpy": [
          "1.Numpy概述",
          "2.Array数组",
          "3.数组结构",
          "4.数组类型",
          "5.数值运算",
          "6.排序操作",
          "7.数组形状操作",
          "8.数组生成函数",
          "9.常用生成函数",
          "10.四则运算",
          "11.随机模块",
          "12.文件读写",
          "13.数组保存",
          "14.练习题1",
          "15.练习题2",
          "16.练习题3"
        ],
        "二、数据分析处理库——Pandas": [
          "1.Pandas概述",
          "2.Pandas基本操作",
          "3.Pandas索引",
          "4.Groupby操作",
          "5.数值运算",
          "6.对象操作",
          "7.Merge操作",
          "8.显示设置",
          "9.数据透视表",
          "10.时间操作",
          "11.Pandas常用操作",
          "12.Groupby操作延伸",
          "13.字符串操作",
          "14.索引进阶",
          "15.Pandas绘图操作",
          "16.大数据处理技巧"
        ],
        "三、可视化库——Matplotlib": [
          "1.Matplotlib概述",
          "2.子图与标注",
          "3.风格设置",
          "4.条形图",
          "5.条形图细节",
          "6.条形图外观",
          "7.盒图绘制",
          "8.盒图细节",
          "9.绘图细节设置",
          "10.直方图与散点图",
          "11.3D图绘制",
          "12.Pie图",
          "13.子图布局",
          "14.结合pandas与sklearn"
        ],
        "四、可视化库——Seaborn": [
          "1.整体布局风格设置",
          "2.风格细节设置",
          "3.调色板",
          "4.调色板颜色设置",
          "5.单变量分析绘图",
          "6.回归分析绘图",
          "7.多变量分析绘图",
          "8.分类属性绘图",
          "9.Facetgrid使用方法",
          "10.Facetgrid绘制多变量",
          "11.热度图绘制"
        ]
      },
      "requirements": [
        "具备Python基础知识"
      ],
      "description": "Numpy科学计算库使用范围广泛，通常应用于Python中数据相关的部分，Numpy效率高，可以在短期内完成复杂任务。本节课以Python为基础，全程代码实战，详细讲解了Python数据分析需要掌握的科学计算库和可视化库，为后续机器学习与数据分析奠定基础。\n课程主要分为四部分：科学计算库-Numpy，包括数组常见操作和函数应用，章节末尾附有经典练习题讲解，可以帮助学员更好的掌握Numpy实战操作；第二部分是科学计算库-Pandas，系统介绍Pandas在数据处理以及数据分析中的应用，第三部分是可视化库Matplotlib，包括条形图、盒图、直方图、散点图、3D图、pie图等图形绘制细节；第四部分是可视化库Seaborn，包括整体布局风格设置、调色板设置、单变量分析绘图、多变量分析绘图、回归分析绘图、热度图、Facetgrid绘图等内容。",
      "target_audience": [
        "Python工程师、AI工程师",
        "数据分析方向的技术人员",
        "对数据分析与人工智能感兴趣的技术人员"
      ]
    },
    {
      "title": "AUTOML + ORANGE completo: analisando dados e modelos",
      "url": "https://www.udemy.com/course/automl-orange-completo-analisando-dados-e-modelos/",
      "bio": "Criação de modelos Machine Learning automatizados e aprendizado aplicado",
      "objectives": [
        "Exploração de Dados",
        "Visualização de Dados",
        "Machine Learning",
        "Agrupamento, descoberta de grupos em dados",
        "Classificação e modelagem preditiva",
        "Algoritmos de Mineração",
        "Análise Estatística",
        "Trabalhando Widget: Color, Distributions, Pivot Table",
        "Trabalhando Widget: Feature Statistics, Data Sample",
        "Trabalhando com Widget: Paint Data",
        "Trabalhando com Widget: Outliers ,Scatter Plot",
        "Trabalhando com: Create Class",
        "Trabalhando com: Select By data index",
        "Trabalhando com: Edit Domain",
        "Trabalhando com: Freeviz",
        "Trabalhando com: Árvore de Decisão",
        "Trabalhando com: Cluster - Imagens",
        "Trabalhando com: Correlação",
        "Trabalhando com: Cluster – K-means",
        "Trabalhando com: Cluster - Imagens",
        "Trabalhando com Widget Predictions (realizando previsões)",
        "Trabalhando com Widget Confusion Matrix (analisando matriz de score)",
        "Trabalhando com Widget Test and Score (avaliando modelos)",
        "Criando um modelo estatístico",
        "Estimando pelo modelo estatístico",
        "Salvando modelos estatísticos em python e executando em bases de teste para previsões",
        "Trabalhando com o algoritmo de associação APRIORI",
        "Trabalhando com Widget MDS",
        "Trabalhando com Widget Mosaic Display",
        "Trabalhando Widget CN2 Rules",
        "Trabalhando Widget Box Plot",
        "Criando modelos por Redes Neurais"
      ],
      "course_content": {
        "AUTOML": [
          "Instruções",
          "Apresentação",
          "Download Material AutoML",
          "Aplicações",
          "O que é AutoML",
          "O Processo de Machine Learning",
          "Hiper Parâmetros",
          "Como AutoML funciona",
          "Multi-fidelity",
          "Meta Learning",
          "Projetos Práticos",
          "Prática com Python",
          "Python H20 Parte I",
          "Python H20 Parte II",
          "Python com Autokeras",
          "Python com MLBox Parte I",
          "Python com MLBox Parte II",
          "Prática em R parte I",
          "Prática em R parte II",
          "Prática em R parte III",
          "Prática em R com Shiny parte I",
          "Prática em R com Shiny parte II",
          "Prática em R com Shiny parte III",
          "Auto-Weka parte I",
          "Auto-Weka parte II",
          "Auto-Weka parte III"
        ],
        "ORANGE DATA SCIENCE - 100% VISUAL - ROADMAP ONE": [
          "Entendendo o funcionamento da IDE do ORANGE",
          "Instalação do ORANGE",
          "Trabalhando com arquivos e utilizando: DATA TABLE, SELECT ROWS, SELECT COLUMNS",
          "Trabalhando Widget: Color, Distributions, Pivot Table, Feature Statistics, Data",
          "Trabalhando com Widget::Paint Data , Outliers ,Scatter Plot",
          "Trabalhando com: Create Class,Select By data index,Edit Domain",
          "Trabalhando com: Freeviz",
          "Trabalhando com Árvore de Decisão",
          "Trabalhando com: Cluster - Imagens",
          "Trabalhando com: Correlação",
          "Trabalhando com: Cluster – K-means",
          "Trabalhando com: Cluster - K-mens - Parte 02",
          "Responda a nossa pergunta"
        ],
        "ORANGE DATA SCIENCE - 100% VISUAL - ROADMAP TWO": [
          "Trabalhando com Widget Predictions (realizando previsões)",
          "Trabalhando com Widget Predictions (realizando previsões)",
          "Criando um modelo estatístico, estimando dados e salvando modelo",
          "Trabalhando com o algoritmo de associação APRIORI",
          "Trabalhando com Widget MDS",
          "Trabalhando com Widget Mosaic Display",
          "Trabalhando Widget CN2 Rules",
          "Trabalhando Widget Box Plot",
          "Trabalhando Widget Rede Neural",
          "Trabalhando Análise de Componentes Principais",
          "Mineração de Texto",
          "Análise Curva ROC",
          "Fim do curso ORANGE Data Science - 100% VISUAL - Roadmap Two"
        ],
        "Aula Bônus": [
          "Aula Bônus"
        ]
      },
      "requirements": [
        "Não há pré-requisitos, apenas conhecimento básico matemática, estatística"
      ],
      "description": "Unimos duas grandes forças no aprendizado de modelos de Machine Learning para você que deseja adentrar na área de Data Science, conhecimento de base e práticas com profundidade.\nFalando em AUTOML se você já implementou modelos de Machine Learning, não há nada igual com o uso de AUTOML, você será possível, testar cada configuração, eliminando em termos de tempo e de custo computacional. Você verá como:\n\n\nCriar Modelos Melhores!\nParticipar de Competições de Machine Learning!\nCriar Produtos Orientados a Dados!\nEste curso mostra como podemos usar  e criar modelos melhores do que aqueles que humanos, mesmo experientes, poderiam conseguir. Neste curso você estudar:\n\n\nO que é Auto Machine Learning e qual sua importância para a Inteligência Artificial\nComo Auto Machine Learning funciona\nComo é o processo de otimização de hiper parâmetros\nImplementação práticas com Python usando H2O, AutoKeras e MLBOX\nConstrução de uma aplicação web com R\n\n\nJá trabalhando com ORANGE você ficará surpreso ao criar modelos estatísticos e de Machine Learning, totalmente visuais, isso mesmo, sem criar uma única linha de código, é o LOW CODE em ação para projetos de Ciência de Dados.\nVocê explorará:\n\n\nASPECTOS PRESENTES:\nAprendizado de máquina de código aberto e visualização de dados para iniciantes e especialistas. Fluxos de trabalho de análise de dados interativos com uma grande caixa de ferramentas\nexecute análise de dados simples com visualização inteligente de dados. Explore distribuições estatísticas, gráficos de dispersão ou mergulhe mais fundo com árvores de decisão, agrupamentos hierárquicos. Até seus dados multidimensionais podem se tornar sensíveis em 2D, especialmente com classificações e seleções inteligentes de atributos.\nExploração interativa de dados para análise qualitativa rápida com visualizações limpas. A interface gráfica do usuário permite que você se concentre na análise exploratória de dados em vez codificação, enquanto padrões inteligentes tornam extremamente fácil a criação rápida de protótipos de um fluxo de trabalho de análise de dados. Coloque widgets na tela, conecte-os, carregue seus conjuntos de dados e colete os insights!\nUse vários complementos disponíveis no Orange para extrair dados de fontes de dados externas.\n\nDividindo o treinamento de ORANGE em duas partes, para assimilação mais fácil.\nEntão, venha aprender com conceitos modernos e aplicáveis no seu dia a dia.",
      "target_audience": [
        "tudantes de BI, Estatística, Computação, Informática, Gestores de Empresas (RH, Administração, Economia, dentre outros)"
      ]
    },
    {
      "title": "从自动化到智能化：技术与理论发展的逻辑",
      "url": "https://www.udemy.com/course/fltyrklk/",
      "bio": "学习智能化技术的理论发展实践",
      "objectives": [
        "学习弱电、计算机、互联网等为代表的基础技术的发展线索",
        "了解以控制论思想为实践过程的技术发展线索，学习从单一设备逐渐全面、深度地拓展到工厂和车间",
        "学习技术发展鲜果的相关理论生产和应用技术的发展",
        "深入了解企业对具体应用技术的需求"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "自动化思想：从机器代人谈起",
          "机器到工厂：管理与控制的分离",
          "智能化时代：管理与控制的融合",
          "智能化基础：知识与平台",
          "总结与展望：走向未来"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "自动化或者管理经验"
      ],
      "description": "本课程以控制论的基本思想为依据，讲述了从设备级自动化到工厂级智能化的发展过程。在这个过程的背后有两条线索：一条是以弱电、计算机、互联网等为代表的基础技术的发展线索；这条线索支撑了相关理论的产生和应用技术的发展。另一条以控制论思想的实践过程为线索，从单一设备逐渐全面、深度地拓展到工厂和车间；这条线索解释了企业对具体应用技术的需求。基础技术和需求，共同促进了相关技术和理论的发展。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。\n课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利\n人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课\n公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位\n提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，\n您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "适合企业中高层技术管理者 适合企业技术专家讲师 适合对自动化及智能化技术感兴趣的相关学员"
      ]
    },
    {
      "title": "ChatGPT自媒体全能写手",
      "url": "https://www.udemy.com/course/chatgpt-ty/",
      "bio": "打造专属的ChatGPT文案机器人",
      "objectives": [
        "学会编辑精准指令让ChatGPT生成你想要的文案",
        "清楚引导ChatGPT提出生成文本需求的方法",
        "把握文案结构，应用ChatGPT产出优质内容",
        "掌握根据输出内容优化调试方法"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "ChatGPT写朋友圈文案，打造有趣朋友圈",
          "ChatGPT写产品海报文案，戳用户痛点，忍不住下单",
          "ChatGPT写公众号/知乎长文，兼职赚点稿费太香了！",
          "如何用ChatGPT生产短视频卖货文案，质量与效率齐飞",
          "如何用ChatGPT生产直播文案，借势打造爆款"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "有运营经验"
      ],
      "description": "随着AI在各领域应用发展，AI生成内容（AIGC）成为新兴的内容生产模式，其中ChatGPT在文本编辑方面展现出惊人的潜力。在互联网时代如何把握新技术、利用智能工具，在自媒体创作与运营的道路上事半功倍？\n为此，三节课邀请互联网内容运营实战专家菜菜老师带来本次课程。\n本门课程从自媒体视角入手，清晰呈现了ChatGPT生成内容的过程，讲解了与之对话的逻辑与技巧。通过本门课的学习，你将学会高效产出高质量文案，创作出引人入胜的内容，成为私域运营高手。",
      "target_audience": [
        "想从事文案、内容运营的新人",
        "想借助ChatGPT提升效率的运营工作者",
        "想了解ChatGPT内容生成的小白"
      ]
    },
    {
      "title": "Python数据分析行业案例课程--信用评分方法",
      "url": "https://www.udemy.com/course/python-lr/",
      "bio": "全面掌握金融领域的典型信用评分方法，全代码讲解，真实场景应用",
      "objectives": [
        "掌握评分卡模型的使用",
        "学会专业的数据准备流程",
        "掌握针对互联网金融案例的建模分析",
        "学会Logistic回顾模型的应用"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "信用卡评分模型概述": [
          "信用卡评分课程介绍",
          "银行业务概述",
          "信用体系与信用风险",
          "从信用评分到评分卡",
          "A、B、C评分卡",
          "信用评分中考虑的因素"
        ],
        "传统银行案例之商业理解": [
          "如何定义坏样本",
          "如何建立评分卡模型"
        ],
        "数据理解与数据准备": [
          "数据理解与准备",
          "数据不平衡问题"
        ],
        "数据分箱": [
          "分箱1概述",
          "分箱2注意事项",
          "分箱3无监督分箱的代码实现",
          "分箱4Best KS法与卡方分箱法",
          "分箱5卡方分箱法的代码实现",
          "分箱6WOE与IV",
          "分箱7WOE与IV的代码实现",
          "分箱8案例的具体实现"
        ],
        "应用Logistic回归楑型": [
          "logistic回归模型的基本概念",
          "logistic回归模型的适用条件",
          "两分类logistic的代码实现",
          "银行案例具体的建模操作"
        ],
        "从模型结果到评分卡": [
          "如何将概率转换为分值",
          "评分卡分值的具体计算",
          "如何对评分卡分值进行分段",
          "计算预期违约率"
        ],
        "评分卡的使用与效果监控": [
          "模型验证与模型监控",
          "模型区分度的衡量指标",
          "模型准确度的衡量指标",
          "模型稳定性的衡量指标",
          "评分卡模型的部署",
          "评分卡的使用：准入与拒绝",
          "授信额度与利率定价",
          "拒绝推断问题"
        ],
        "互联网金融案例": [
          "什么是互联网金融",
          "内部与外部数据源",
          "互联网金融案例的原始数据",
          "数据字典",
          "本案例的特殊性"
        ],
        "互联网金融案例的数据预处理": [
          "特征工程概述",
          "数据的探索性分析：概述",
          "数据的探索性分析：代码实现",
          "数据衍生的基本思路",
          "变量衍生函数",
          "具体的变量衍生操作",
          "缺失值处理的基本概念",
          "具体的缺失值处理的代码实现",
          "分类变量的数值化"
        ]
      },
      "requirements": [
        "具备Python基础知识"
      ],
      "description": "玩转数据分析，在信用评分的案例分析中，我们会用到各种各样的模型，评分卡模型、数据分箱、Logistic回归模型等等，后面还会涉及到互联网金融案例的建模分析。信用评分是非常特殊且重要的领域，除银行业外，近年来在网络征信等新兴领域中也颇受重视。\n本课程使用银行征信和互联网金融征信两个真实案例数据，完整介绍了信用评分卡模型在相关业务领域中的构建和实施流程。\n课程的基本目标，就是做成一个行业的模板，相应的代码，相应的分析思路，整个案例可作为分析模板供学员在信用评分相关的分析项目中直接套用。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。\n未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "适合金融领域、风险管理、电信领域、从事评分卡及数据挖掘建模的人员",
        "适合企业数据领域的专家及工程师掌握实战案例",
        "适合对数据分析、数据挖掘感兴趣的小伙伴",
        "适合金融科技领域的在校生和相关科研人员"
      ]
    },
    {
      "title": "Bazy danych MongoDB - kurs dla każdego!",
      "url": "https://www.udemy.com/course/bazy-danych-mongodb-kurs-dla-kazdego/",
      "bio": "Kurs od podstaw",
      "objectives": [
        "Pracować z bazami danych MongoDB",
        "Pisać zaawansowane zapytania do bazy danych MongoDB",
        "Dodwać, usuwać oraz aktualizować dokumenty w bazie danych MongoDB",
        "Obsługiwać aplikację MongoDB Compass",
        "Instalować bazę danych MongoDB"
      ],
      "course_content": {
        "Wstęp": [
          "Wstęp",
          "Instalcja bazy danych MongoDB"
        ],
        "MongoDB": [
          "Dodawanie dokumentów do bazy danych",
          "Wyszukiwanie dokumentów - jeden warunek",
          "Wyszukiwanie dokumentów - wiele warunków",
          "Wyszykiwanie dokumentów - zaawansowane metody część 1",
          "Wyszykiwanie dokumentów - zaawansowane metody część 2",
          "Aktualizacja dokumentów",
          "Usuwanie dokumentów",
          "Zadanie"
        ],
        "MongoDB Compass": [
          "MongoDB Compass"
        ],
        "Podziękowanie": [
          "Podziękowanie"
        ]
      },
      "requirements": [
        "Komputer z dostępem do internetu",
        "Czas i chęci na poznanie nowych rzeczy"
      ],
      "description": "Zapraszam do kursu \"Bazy danych MongoDB dla każdego\".\nMongoDB to jedna z najbardziej popularnych i wszechstronnych baz danych, idealna dla każdego, kto chce zgłębić tajniki nowoczesnego zarządzania danymi. Nasze szkolenie zostało stworzone z myślą o osobach bez względu na poziom zaawansowania czy specjalizację. Wystarczy jedynie komputer, chęci oraz trochę czasu, aby otworzyć się na świat MongoDB.\nPodczas kursu skupiamy się na praktycznych aspektach, dzięki czemu każdy uczestnik może szybko przyswoić wiedzę. Każdy temat jest starannie rozłożony na lekcje, co ułatwia zrozumienie nawet najbardziej złożonych kwestii. Oto kilka głównych punktów, które poruszymy:\nNauczysz się niezbędnej teorii dotyczącej MongoDB.\nDowiesz się, jak instalować bazę MongoDB, krok po kroku.\nOpanujesz umiejętność dodawania, edytowania i usuwania dokumentów w bazie danych.\nPoznasz techniki pisania zaawansowanych zapytań do bazy danych.\nZdobędziesz umiejętności korzystania z aplikacji MongoDB Compass, aby jeszcze sprawniej zarządzać danymi.\nNasze szkolenie to intensywny kurs, który łączy teorię z praktyką, dając Ci niezbędne narzędzia do efektywnego pracy z MongoDB. Podczas zajęć masz możliwość zadawania pytań, na które odpowiemy z przyjemnością, zapewniając pełne zrozumienie omawianych tematów. Każda lekcja jest praktyczna i treściwa.\nNie czekaj dłużej! Naucz się MongoDB i otwórz nowe możliwości w zarządzaniu bazami danych. Serdecznie zapraszamy do udziału!\nW razie jakichkolwiek problemów / pytań chętnie pomogę!",
      "target_audience": [
        "Dla każego"
      ]
    },
    {
      "title": "Curso Completo: LangChain, LangGraph y Agentes IA con Python",
      "url": "https://www.udemy.com/course/curso-completo-langchain-langgraph-y-agentes-ia-con-python/",
      "bio": "Crea apps profesionales con LLMs, Inteligencia Artificial Generativa y Agentes de IA con LangChain, LangGraph y Python",
      "objectives": [
        "Crear agentes de IA profesionales desde cero usando LangChain, LangGraph y Python para automatizar procesos empresariales complejos.",
        "Construir sistemas de IA con RAG avanzado que integran documentos PDF, bases de datos y fuentes externas para crear asistentes expertos en cualquier dominio.",
        "Construir sistemas multi-agente coordinados con agentes especializados que colaboran para resolver problemas complejos.",
        "Desarrollar chatbots con memoria inteligente que recuerdan conversaciones pasadas, aprenden de interacciones y mantienen contexto en múltiples sesiones.",
        "Implementar agentes multi-herramienta que buscan en internet, procesan documentos y toman decisiones autónomas usando APIs externas.",
        "Diseñar workflows inteligentes con LangGraph que incluyen escalado humano, checkpoints, pausas/reanudación y control de flujo avanzado.",
        "Integrar múltiples LLMs y herramientas: OpenAI, Google Gemini, Tavily Search y herramientas personalizadas en un solo sistema cohesivo.",
        "Implementar bases de datos vectoriales (ChromaDB, FAISS) con estrategias de recuperación híbrida para búsquedas semánticas ultra-precisas.",
        "Aplicar técnicas de Prompt Engineering avanzado con plantillas dinámicas, few-shot learning, roles específicos y estructuración de respuestas con Pydantic.",
        "Desarrollar sistemas empresariales reales: helpdesks inteligentes, asistentes legales, procesadores de reuniones y evaluadores automáticos de candidatos."
      ],
      "course_content": {
        "Presentación del curso": [
          "Presentación del curso"
        ],
        "Descarga el cuaderno de trabajo del curso": [
          "Descarga el cuaderno de trabajo del curso"
        ],
        "Introducción a LangChain: Tu primera aplicación con IA y LLMs": [
          "Introducción a la sección",
          "Instalación de LangChain",
          "Instalación y configuración de VS Code",
          "API Key y Configuración de OpenAI",
          "API Key y Configuración de Google GenAI",
          "Tu primer \"Hello World\" con LangChain y OpenAI",
          "Tu primer \"Hello World\" con LangChain y Google GenAI",
          "Tu primera plantilla de prompt (Prompt Template) con LangChain",
          "Tu primera cadena (Chain) con LangChain",
          "LangChain Expression Language (LCEL)",
          "Lectura: Arquitectura de Paquetes en LangChain",
          "Tu primer Proyecto: Chatbot Básico con LangChain y Streamlit",
          "Proyecto: Descarga de los archivos del proyecto",
          "Proyecto: Importar LangChain y Streamlit",
          "Lectura: ¿Qué es Streamlit?",
          "Proyecto: Configuración inicial del proyecto",
          "Proyecto: Crear el historial de mensajes",
          "Proyecto: Tipos de mensajes en LangChain: AI, Human, System Message",
          "Proyecto: Campo de entrada de usuario",
          "Proyecto: Generar respuesta del asistente",
          "Tarea: Mejoras adicionales: LCEL, Prompt Templates, Streaming...",
          "Resolución Tarea: Mejoras adicionales: LCEL, Prompt Templates, Streaming..."
        ],
        "Fundamentos de LangChain: Componentes Core": [
          "Introducción a la sección",
          "Runnables: El poder de LCEL (LangChain Expression Language)",
          "Tarea: Mini-Proyecto: Análisis de sentimientos con LangChain",
          "RunnableParallel: Procesamiento en paralelo con LangChain",
          "Batch: Procesamiento por lotes con LangChain",
          "Prompt Templates y Prompt Engineering con LangChain",
          "ChatPromptTemplate: Plantillas de prompts para chats",
          "Tarea: Mejora tu Chatbot con ChatPromptTemplate, GPT y OpenAI",
          "MessagePlaceholders: Plantillas dinámicas de mensajes",
          "Lectura: MessagesPlaceholder y Few-Shot Examples",
          "Plantillas de mensajes con roles específicos",
          "Output Parsers: Estructurando Respuestas",
          "Pydantic: Validar y procesar datos con Python y LangChain",
          "Estructurando respuestas con LangChain y Pydantic",
          "Lectura: PydanticOutputParser: El Método Clásico para salidas estructuradas",
          "Proyecto: Sistema de Evaluación de CVs y candidatos con IA",
          "Proyecto: Descarga los archivos del proyecto",
          "Proyecto: Estructura de ficheros y directorios",
          "Proyecto: Modelo de datos con Pydantic",
          "Proyecto: Procesamiento de los CVs en formato PDF",
          "Proyecto: Prompts del sistema",
          "Proyecto: Análisis y evaluación de CVs con LangChain e IA Generativa",
          "Proyecto: Creación de la aplicación web",
          "Proyecto: Ejecución y pruebas de la aplicación final"
        ],
        "RAG y LangChain: Cargando y recuperando datos del mundo real": [
          "Introducción a la sección",
          "LangChain Community",
          "Document Loaders: Cargando datos del mundo real",
          "Mini-Proyecto: Cargando datos de Google Drive con GoogleDriveLoader",
          "Lectura: Document Loaders interesantes en LangChain",
          "Text Splitters: Limitaciones de contexto en los LLMs",
          "División inteligente de datos con LangChain y RecursiveCharacterTextSplitter",
          "¿Qué son los Embeddings?",
          "Embeddings con LangChain",
          "¿Qué son las bases de datos vectoriales?",
          "Bases de datos vectoriales con LangChain",
          "Retrievers en LangChain: Estrategias de recuperación",
          "MultiQueryRetriever: Recuperación de información con LLMs e IA",
          "Lectura: Retrievers interesantes en LangChain",
          "RAG (Retrieval Augmented Generation)",
          "Proyecto: Sistema de asistencia legal y evaluación de contratos",
          "Proyecto: Descarga los archivos del proyecto",
          "Proyecto: Identificación y construcción de la fuente de información externa",
          "Proyecto: Arquitectura del sistema RAG",
          "Proyecto: Prompts del sistema RAG",
          "Proyecto: Cadena LCEL del sistema RAG",
          "Proyecto: Formato de los documentos recuperados",
          "Proyecto: Consultas al sistema RAG",
          "Proyecto: Aplicación web con Streamlit",
          "[Bonus] Proyecto: Recuperación híbrida de documentos son LangChain"
        ],
        "LangGraph": [
          "Introducción a la sección",
          "¿Qué es LangGraph?",
          "Lectura: Componentes fundamentales de LangGraph",
          "Tu primer programa con LangGraph",
          "Proyecto: Sistema de Procesamiento de Reuniones con IA y LangGraph",
          "Resolución del Proyecto: Sistema de Procesamiento Reuniones con IA y LangGraph",
          "Estado avanzado y anotaciones",
          "Control de Flujo y Decisiones con LangGraph",
          "Proyecto: Helpdesk 2.0 con IA, LangGraph y RAG",
          "Proyecto: Descarga los archivos del proyecto",
          "Proyecto: Procesador de documentos para el sistema RAG",
          "Proyecto: Implementación del sistema RAG",
          "Proyecto: Definición del estado",
          "Proyecto: Creación de los nodos del grafo con LangGraph",
          "Proyecto: Human-in-the-Loop - Escalado a un humano",
          "Proyecto: Funciones de enrutamiento con LangGraph",
          "Proyecto: Conexión y creación del grafo final con LangGraph",
          "Proyecto: CheckPoints y persistencia del estado con LangGraph",
          "Proyecto: Streaming y Observabilidad con LangGraph",
          "Proyecto: Detención y reanudación de un grafo de LangGraph"
        ],
        "Memoria y Gestión de Contexto con LangChain y LangGraph": [
          "Introducción a la sección",
          "Fundamentos de Memoria en LangChain y LangGraph",
          "Memoria en LangChain: RunnableWithMessageHistory",
          "Memoria en LangGraph: MemorySaver",
          "Memoria con ventana deslizante en LangGraph",
          "Tipos de memoria principales con LangGraph",
          "Memoria persistente con LangGraph",
          "Memoria Vectorial con LangGraph",
          "Caso practico: Memoria Vectorial con LangGraph",
          "Proyecto: Chat Multi-Usuario con Memoria Avanzada",
          "Proyecto: Descarga los archivos del proyecto",
          "Proyecto: Configuración de la aplicación",
          "Proyecto: Definición del estado extendido y un modelo de Pydantic",
          "Proyecto: Definicion de la clase de gestion de memoria",
          "Proyecto: Inicializar la base de datos vectorial",
          "Proyecto: Sistema de extracción inteligente",
          "Proyecto: Gestión de múltiples Chats - Parte 1",
          "Proyecto: Gestión de múltiples Chats - Parte 2",
          "Proyecto: Implementación de la memoria vectorial",
          "Proyecto: Implementación de la extracción inteligente",
          "Proyecto: Gestión de los usuarios de la aplicación",
          "Proyecto: Inicializar el Chatbot avanzado",
          "Proyecto: Implementación del Chatbot y grafo de LangGraph",
          "Proyecto: Implementación del chat de la aplicación",
          "Proyecto: Obtener el historial de una conversación",
          "Proyecto: Gestión de Chatbots",
          "Proyecto: Interfaz y ejecución de la aplicación"
        ],
        "Agentes de IA y herramientas externas con LangChain y LangGraph": [
          "Introducción a la sección",
          "Herramientas (Tools) en LangChain",
          "Tu primera herramienta con LangChain",
          "Herramientas personalizadas con LangChain",
          "Herramientas personalizadas con StructuredTool",
          "Utilizando Herramientas con LLMs en LangChain",
          "Retornando un artefacto para uso interno con LangChain",
          "Herramientas predefinidas e integraciones en LangChain",
          "Fundamentos de los Agentes de IA",
          "Creando nuestro primer Agente de IA con LangChain",
          "Herramientas personalizadas y Agentes de IA con LangChain",
          "Creando nuestro primer Agente de IA con LangGraph",
          "Sistemas Multi-Agente con LangGraph",
          "Lectura: Agentes preconfigurados recomendados en LangChain y LangGraph",
          "Proyecto: Centro de Operaciones de Seguridad Multi-Agente",
          "Proyecto: Descarga los archivos del proyecto",
          "Proyecto: Configuración del entorno",
          "Proyecto: Búsqueda en Internet con LLMs y Tavily Search",
          "Proyecto: Análisis de Ciberseguridad con LLMs y VirusTotal",
          "Proyecto: Configuración de la aplicación",
          "Proyecto: Definición de las herramientas pre-construidas",
          "Proyecto: Implementación de las herramientas personalizadas",
          "[Opcional] Tarea Avanzada: Implementación de Herramientas de Threat Intelligence",
          "Proyecto: Creación de los agentes de IA del sistema",
          "Proyecto: Creación del supervisor que coordina los agentes",
          "Proyecto: Creación de una API Rest con FastAPI",
          "Proyecto: Creación de un dashboard web con Streamlit"
        ],
        "Despedida del curso": [
          "Despedida del curso"
        ]
      },
      "requirements": [
        "Conocimientos básicos de Python: No necesitas ser un experto, pero sí tener unas nociones básicas de este lenguaje de programación.",
        "Una computadora, conexión a Internet y muchas ganas de aprender y experimentar con las tecnologías más avanzadas de IA de la actualidad."
      ],
      "description": "En este curso 100% práctico y desde cero, dominarás las tecnologías más avanzadas para crear agentes de Inteligencia Artificial profesionales usando Python, LangChain y LangGraph. Aprenderás a construir sistemas de IA que procesan información, toman decisiones autónomas y resuelven problemas complejos del mundo real.\n\n\n¿Qué lograrás con este curso?\nAl finalizar, serás capaz de desarrollar sistemas completos de Inteligencia Artificial que integran múltiples fuentes de datos, mantienen memoria persistente y ejecutan tareas complejas de forma autónoma. Podrás crear desde chatbots avanzados hasta sistemas multi-agente especializados para casos de uso empresariales.\nImagina construir un asistente legal que analiza contratos automáticamente, un sistema de atención al cliente que escala a humanos cuando es necesario, o un centro de operaciones de seguridad con múltiples agentes especializados, todo esto lo desarrollarás durante el curso.\n\n\nLo que aprenderás:\nFundamentos sólidos de LangChain: Comenzarás desde cero con los conceptos esenciales. Dominarás la arquitectura de LangChain, incluyendo Runnables, LCEL (LangChain Expression Language), Prompt Templates y Output Parsers. Aprenderás a estructurar respuestas con Pydantic y crear cadenas de procesamiento robustas.\nSistemas RAG (Retrieval Augmented Generation): Construirás sistemas que conectan IA generativa con datos del mundo real. Aprenderás Document Loaders, Text Splitters, Embeddings, bases de datos vectoriales y estrategias avanzadas de recuperación. Crearás sistemas que pueden procesar documentos, PDFs y fuentes externas de información.\nDominio completo de LangGraph: Utilizarás la tecnología más avanzada para crear flujos de trabajo inteligentes. Aprenderás control de flujo, toma de decisiones, estados avanzados, checkpoints y persistencia. Implementarás sistemas que pueden pausarse, reanudarse y mantener contexto a largo plazo.\nGestión avanzada de memoria: Implementarás diferentes tipos de memoria en tus agentes: memoria de conversación, memoria vectorial, ventanas deslizantes y memoria persistente. Crearás sistemas que recuerdan interacciones pasadas y aprenden de ellas, incluyendo chat multi-usuario con memoria independiente.\nHerramientas y Agentes de IA especializados: Integrarás APIs externas, herramientas personalizadas y servicios web. Construirás agentes que pueden buscar en internet, analizar ciberseguridad, procesar reuniones y coordinar tareas complejas. Aprenderás tanto agentes de IA individuales como sistemas multi-agente coordinados.\nAplicaciones web completas: Desarrollarás interfaces profesionales con Streamlit y APIs con FastAPI. Crearás dashboards interactivos, sistemas de evaluación de CVs, asistentes legales y centros de operaciones completos con interfaces web funcionales.\nCasos de uso empresariales reales: Cada módulo incluye proyectos prácticos basados en necesidades reales del mercado: sistemas de evaluación de candidatos, asistentes legales para análisis de contratos, helpdesks inteligentes con escalado humano, y centros de operaciones de seguridad multi-agente.\n\n\nPor qué este curso es para ti:\nSi eres desarrollador, científico de datos, o profesional técnico que quiere dominar la Inteligencia Artificial aplicada, este curso te dará las habilidades más demandadas del mercado. No necesitas experiencia previa en IA, pero sí conocimientos básicos de Python.\nCada lección combina teoría esencial con implementación práctica inmediata. Terminarás cada sección con proyectos funcionales que podrás usar en tu portafolio profesional. El curso está diseñado para llevarte desde los conceptos básicos hasta implementaciones empresariales avanzadas.\n\n\nTecnologías que dominarás:\nLangChain y LangGraph (último stack de IA)\nOpenAI, Google Gemini, y modelos open source\nBases de datos vectoriales (ChromaDB, FAISS)\nAPIs modernas (FastAPI, REST)\nStreamlit para interfaces web\nHerramientas especializadas (Tavily Search, GmailToolkit)\n\n\nTransformación garantizada:\nAl completar este curso, tendrás las habilidades para desarrollar cualquier sistema de IA empresarial. Podrás identificar oportunidades de automatización inteligente, diseñar arquitecturas robustas y implementar soluciones escalables que generen valor real en organizaciones.\nSaldrás con conocimientos profundos en las tecnologías más avanzadas de IA, un portafolio de proyectos profesionales y la confianza para liderar iniciativas de Inteligencia Artificial en tu empresa o como freelancer.\n\n\n¡No te quedes atrás en la revolución de la IA generativa! Únete ahora y conviértete en un experto en las tecnologías que están definiendo el futuro de la automatización inteligente.\n¡Te esperamos dentro del curso para construir juntos el futuro de la Inteligencia Artificial!",
      "target_audience": [
        "Para profesionales técnicos que buscan dominar LangChain y LangGraph para crear soluciones empresariales de Inteligencia Artificial.",
        "Para científicos de datos y analistas que quieren expandir sus habilidades hacia la IA generativa y sistemas de agentes inteligentes.",
        "Para desarrolladores Python que quieren especializarse en las tecnologías de IA más demandadas del mercado actual.",
        "Para estudiantes de ingeniería, informática o carreras técnicas que desean destacar con las competencias más valiosas del futuro tecnológico.",
        "Para freelancers y consultores que quieren ofrecer servicios de desarrollo de agentes de IA y sistemas RAG a empresas y startups.",
        "Para emprendedores con perfil técnico que buscan construir productos innovadores basados en IA sin depender completamente de equipos externos.",
        "Para profesionales de TI y arquitectos de software que necesitan implementar soluciones de IA escalables en entornos empresariales.",
        "Para entusiastas de la programación que quieren entender a profundidad cómo funcionan los sistemas de IA más avanzados y crear sus propias implementaciones.",
        "Para equipos de desarrollo, DevOps y ingeniería que buscan automatizar procesos complejos con agentes inteligentes y sistemas de toma de decisiones."
      ]
    },
    {
      "title": "AI量化之道：DeepSeek+Python让量化交易插上翅膀",
      "url": "https://www.udemy.com/course/aideepseekpython/",
      "bio": "从零掌握Python+DeepSeek量化：掌握趋势跟踪策略、海龟策略、动量策略、高频交易策略、套利交易策略和机器学习策略",
      "objectives": [
        "理解量化交易的基本概念和流程",
        "熟练使用Python进行量化交易分析",
        "设计并实现多种量化交易策略",
        "进行策略回测和风险管理"
      ],
      "course_content": {},
      "requirements": [
        "基本的数学和统计知识",
        "对金融市场有一定的了解",
        "具备一定的编程基础（优先）"
      ],
      "description": "本课程是一门结合人工智能与量化交易的高级课程。本课程将带领您深入了解如何利用DeepSeek人工智能平台和Python编程语言，构建和优化量化交易策略。从基础概念到复杂策略，本课程旨在为学员提供一个全面的学习路径，使其能够在量化交易领域中实现稳健的收益。\n课程内容：\n第1章：DeepSeek、Python与量化交易概述\nDeepSeek模型家族及其优势\nPython编程在量化交易中的重要性和优势\nDeepSeek+Python赋能量化交易\n第2章：量化交易Python语言基础\nPython解释器和IDE工具\n第一个Python程序\nPython语法基础，包括标识符、关键字、变量、语句、代码块、模块\n运算符、数据类型、字符串类型、控制语句、函数\n第3章：Python量化基础工具库\nNumPy库和数组操作\nPandas库和数据结构（Series、DataFrame）\n数据读取（CSV、Excel、数据库）\n第4章：量化交易可视化库\n使用Matplotlib和Seaborn绘制图表\n时间序列可视化和K线图绘制\n第5章：数据采集与分析\n数据采集概述和API调用采集数据（Tushare案例）\n数据清洗与预处理\n统计分析（相关性分析、统计描述）\n第6章：量化交易基础\n量化交易概述和分析方法（技术分析、基本面分析）\n量化交易策略概述\n第7章：DeepSeek与量化交易结合\nDeepSeek辅助技术分析和基本面分析\n案例：新闻事件分析、企业公告分析、市场预测\n第8-12章：交易策略实战\n趋势跟踪策略、动量策略、海龟交易策略、高频交易策略、套利交易策略\n使用DeepSeek辅助决策和策略优化\n第13章：机器学习策略\n机器学习基础和策略分类\n实施过程和案例：分类策略预测、回归策略预测、LSTM预测比特币价格\n第14章：回测框架\n回测基础和Backtrader框架（案例：回测与优化）\n第15章：风险管理\n止损与止盈策略、头寸管理与分散投资、对冲策略\nDeepSeek辅助风控（智能监控、风险评估）",
      "target_audience": [
        "对量化交易感兴趣的初学者",
        "希望提升Python编程技能的金融从业者",
        "寻求优化交易策略的交易员"
      ]
    },
    {
      "title": "Machine Learning Básico Aplicado a Hidrocarburos",
      "url": "https://www.udemy.com/course/machine-learning-basico-aplicado-a-hidrocarburos/",
      "bio": "ML básico para Geocientíficos",
      "objectives": [
        "Aspectos de Algebra lineal",
        "Algoritmo Gradiente descendiente para regresión lineal y Logistica",
        "Algoritmo de Clustering (K-Means)",
        "Redes neuronales"
      ],
      "course_content": {
        "Tópicos de Algebra Lineal": [
          "Algebra lineal. Clase 1_4",
          "Algebra Lineal. Clase 2_4",
          "Algebra Lineal. Clase 3_4",
          "Algebra Lineal. Clase 4_4",
          "Tarea para algebra lineal"
        ],
        "Algoritmo gradiente descendiente en Regresión lineal": [
          "Gradiente descendiente en regresión lineal y logistica",
          "Tarea para algoritmo del gradiente descendiente",
          "tarea sobre el gradiente descendiente para regresión logística"
        ],
        "Redes Neuronales": [
          "Redes neuronales. Clase 1_3",
          "Redes neuronales. Clase_2_3",
          "Redes neuronales. Clase_3_3",
          "Tarea sobre Redes Neuronales"
        ],
        "Algoritmos de Clustering K-means": [
          "K-means. Clase 1_2",
          "K-means. Clase 2_2",
          "Tarea sobre algoritmo de K-means"
        ],
        "Lectura recomendada": [
          "Lectura sobre redes convolucionales"
        ]
      },
      "requirements": [
        "Conocimientos básicos de Algebra y algoritmos matemáticos",
        "Conocimientos básicos de programación"
      ],
      "description": "RESUMEN EJECUTIVO\n\n\nObjetivo\nImpartir los conocimientos teóricos y prácticos básicos en lo que respecta al tema sobre el campo que estudia los algoritmos que permiten a las computadoras tomar decisiones sin haber sido programadas explícitamente para ello, que es lo que llamamos hoy día MACHINE LEARNING, enfocado al área de las Geociencias, como la Petrofísica, Geología y Geofísica.\nDirigido a\nEste taller esta dirigido a todo profesional de las Geociencias, ya que en todas las áreas de estas, los algoritmos de redes neuronales, regresión lineal, regresión logística, regresión con múltiples variables, algoritmos de clasificación y otros, son utilizados en las actividades diarias de los Geocientíficos. Por ejemplo, las redes neuronales son muy útiles en el área de Petrofísica para generar curvas que por alguna razón no existen en ciertos pozos y el algoritmo permite entrenar la red con los pozos que si la tienen y en función de eso generarlo en los pozos faltantes. En estos casos muchas veces se realiza el procedimiento sin tener claro lo que realiza el algoritmo internamente, y para obtener la comprensión de esto es necesario ir a la raíz del algoritmo que no es mas que trabajar con el código fuente. En este taller veremos que las redes neuronales no son una caja negra, es un algoritmo que no es sencillo de entender, pero, con ejercicios es posible comprenderlo y adaptarlo a nuestras necesidades.\nLos ejercicios del curso no fueron colocados en este sitio por razones de que la plataforma no me permitía adecuarlo a la forma en que tenia los ejercicios ya organizados.",
      "target_audience": [
        "Personal de Geociencias."
      ]
    },
    {
      "title": "Lógica de Programação para Data Science",
      "url": "https://www.udemy.com/course/logica-de-programacao-data-science/",
      "bio": "Aprenda ou aprimore sua lógica de programação e tenha uma visão introdutória do mundo de Data Science",
      "objectives": [
        "Aprenda ou aprimore a sua lógica de programação e tenha uma introdução ao mundo de Data Science.",
        "Aprenda a estruturar seus pensamentos de forma mais adequada, permitindo que você possa criar sistemas mais robustos e que estejam de acordo com os requisitos.",
        "Entenda as bases de uma das áreas mais quentes do mercado de trabalho, com uma lógica de programação aprimorada você estará apto a criar soluções robustas.",
        "Após as aulas de Lógica de Programação, obtenha uma visão introdutória ao mundo de Data Sciente, uma das áreas mais desafiadoras do mundo da programação.",
        "Desenvolva a sua base de conhecimento para que possa se tornar futuramente um excelente desenvolvedor, engenheiro de software ou arquiteto de soluções."
      ],
      "course_content": {
        "Introdução a Lógica de Programação": [
          "Primeiros Passos",
          "O que são Fluxogramas?",
          "Fluxograma - Problema 1",
          "Fluxograma - Problema 2",
          "Exercício de Fluxograma",
          "O que é Lógica de Programação?",
          "Ambiente de desenvolvimento"
        ],
        "Variáveis e Constantes": [
          "O que são variáveis?",
          "Perguntas sobre variáveis",
          "Como usar constantes?",
          "Perguntas sobre constantes",
          "Exercícios de Variáveis e Constantes"
        ],
        "Estruturas condicionais": [
          "Se senão",
          "Condicional Escolha (Switch)",
          "Exercícios de Estruturas condicionais"
        ],
        "Estruturas de repetição": [
          "Enquanto",
          "Faça Enquanto",
          "Para",
          "Exercícios de Estrutura de repetição"
        ],
        "Vetores e Matrizes": [
          "Introdução a vetores - Conceito",
          "Introdução a vetores - Hands-on",
          "Exercícios sobre Vetores",
          "Introdução a matrizes - Conceito",
          "Introdução a matrizes - Hands-on",
          "Exercícios sobre Matrizes"
        ],
        "Funções": [
          "Introdução a funções",
          "Reutilizando seu código",
          "Recursividade"
        ],
        "Introdução ao Python": [
          "Principais características do Python",
          "Ferramentas necessárias",
          "Ferramentas necessárias - PDF",
          "Estruturas condicionais - If",
          "Estruturas condicionais - Match Case",
          "Exercícios de Estruturas Condicionais",
          "Estruturas de repetição - While",
          "Estruturas de repetição - For",
          "Exercícios de Estruturas de Repetição",
          "Funções"
        ],
        "Introdução ao Data Science": [
          "O que é Data Science?",
          "Bibliotecas mais utilizadas",
          "O que são Datasets e onde encontrá-los?",
          "Limpeza e tratamento de dados"
        ],
        "Introdução a Inteligência Artificial": [
          "O que é IA?",
          "Modelos de Visão Computacional",
          "Modelos de Classificação"
        ],
        "Próximos Passos": [
          "Linguagens de Programação",
          "O que faço agora?"
        ]
      },
      "requirements": [
        "Ter conhecimento em leitura em inglês é recomendável",
        "Não é necessário ter conhecimento em programação"
      ],
      "description": "A tecnologia está no nosso dia a dia, em todo momento estamos em contato com aplicativos, softwares e páginas web, toda essa tecnologia precisa de profissionais que construam de forma qualificada as bases de um bom sistema. O curso permitirá que você crie sua base e obtenha os requisitos iniciais para se tornar um excelente desenvolvedor, tenha a visão das estruturas de dados, estruturas de repetição e outros aspectos que permeia o desenvolvimento de software.\n\n\nEste curso foca em alunos que não possuam conhecimento em programação, ensinando-os do zero como desenvolver um sistema, fornecemos também uma introdução a linguagem Python, uma das mais utilizadas nos dias atuais e uma das linguagens mais indicadas para se trabalhar como cientista de dados, neste curso você também terá acesso a uma visão introdutória sobre Data Science, permitindo que você consiga visualizar o conteúdo aprendido em lógica ser aplicado em ciência de dados.\n\n\nNeste curso você aprenderá:\nA criar e manipular variáveis e constantes;\nEntender a estrutura de laços de repetição;\nEntender como funciona as estruturas de repetição;\nUtilização de funções;\nIntrodução a linguagem de programação Python;\nVisão introdutória da área de Data Science.\n\n\nCom estes conhecimentos você estará apto a:\nEntender o funcionamento da lógica de programação;\nManipular as estruturas básicas de programação;\nTer o conhecimento necessário para começar a aprender uma linguagem de programação;\nConhecer boas práticas de desenvolvimento de sistemas.\n\n\nEm uma área na qual sobram vagas, obter esses conhecimentos pode ser um grande divisor de águas para que você comece a estar apto a atuar nas profissões mais requisitadas no mercado atualmente, levando sua carreira a outro patamar.",
      "target_audience": [
        "Este curso é para todos aqueles que desejam aprender ou aprimorar a sua Lógica de Programação, nos módulos finais fornecemos uma pequena introdução para as pessoas que desejam trabalhar em projetos de Data Science"
      ]
    },
    {
      "title": "Statistics for machine learning in Arabic",
      "url": "https://www.udemy.com/course/statistics-for-machine-learning-in-arabic/",
      "bio": "مفاهيم إحصائية أساسية لتحليل البيانات وفهم الذكاء الاصطناعي",
      "objectives": [
        "معرفة كيفية تمثيل البيانات",
        "معرفة كيفية استخدام الإحصاء في اختصار البيانات",
        "معرفة المفاهيم الإحصائية الأساسية لفهم الذكاء الاصطناعي",
        "استخدام أدوات الإحصاء في علاج بعض المشاكل في البيانات"
      ],
      "course_content": {
        "المنهج": [
          "مقدمة",
          "إيه هو ال Weighted Mean و Trimmed Mean ؟ و إيه تأثير ال Outliers؟",
          "ال Median و اكتشاف ال Outliers",
          "يعني إيه Standard Deviation و Variance ؟ وإزاي بنستخدمهم في الإحصاء؟",
          "يعني إيه Frequency Table و Histogram ؟ وازاي نمثل البيانات؟",
          "يعني إيه Box Plot ؟ وإزاي بنستخدمه لاكتشاف ال Outliers ؟",
          "يعني إيه Parametric و Non-Parametric Fitting ؟ وفرقهم في تحليل البيانات؟",
          "ايه هي ال Central Limit Theorem ؟ وازاي بتظهر من ال data بتاعتنا؟ (الجزء 1)",
          "الجزء 2 من Central Limit Theorem إزاي ال samples بتقربنا من التوزيع الطبيعي؟",
          "كل ما تريد معرفته عن الـ t test",
          "Wilcoxon Signed Rank Test بمثال خطوة بخطوة",
          "Bonferroni Correction بمثال خطوة بخطوة",
          "False Discovery Rate FDR correction بمثال خطوة بخطوة",
          "خاتمة"
        ]
      },
      "requirements": [
        "لا تحتاج إلى خبرة مسبقة فنحن نبدأ من البداية"
      ],
      "description": "الدورة دي مصممة لبناء فهم واضح لأساسيات الإحصاء و تحليل البيانات، بشكل مبسط بأمثلة عشان يخليك تفهم إمتى وليه تختار كل أداة. بنبدأ من الأساسيات زي الفرق بين العينة (Sample) والمجتمع الإحصائي (Population) وتأثير ده على الاستنتاجات، وبعدها بندخل في مقاييس زي المتوسط (Mean)، وإزاي نستخدم ال (Weighted Mean) وإمتى نستعين بـ ال (Trimmed Mean) لتقليل تأثير القيم الشاذة (Outliers) اللي ممكن تشوه النتائج.\nهنتعرف كمان على الوسيط (Median) وأهميته لما البيانات يكون فيها قيم شاذة، والرباعيات (Quartiles) واستخدامها لتقسيم البيانات، مع طرق اكتشاف القيم الشاذة وتحديد إذا كانت مؤثرة على التحليل أو لأ. بعد كده هنغطي مقاييس التشتّت زي التباين (Variance) والانحراف المعياري (Standard Deviation)، ونقارنهم بالمتوسط عشان نفهم ليه قياس التشتّت مهم جدًا، خصوصًا في تطبيقات الذكاء الاصطناعي.\nتمثيل البيانات بشكل بصري مهم، عشان كده هنشتغل على جداول التكرار (Frequency Tables) وال (Histogram)، وهنفهم ال(Box Plot) من الداخل: فين الmedian والQuartiles، وإزاي نستعمله بسرعة لاكتشاف القيم الشاذة وفهم شكل البيانات.\nبعد الأساسيات، هنتكلم عن ال (Parametric & Non-Parametric Fitting)، الفرق بينهم، وإزاي تختار النوع المناسب حسب شكل بياناتك وأثر الاختيار ده على دقة التوقعات. هنشرح كمان نظرية الحد المركزي (Central Limit Theorem) وتوزيع العينة (Sampling Distribution)، وليه توزيع الإحصاء الناتج عن العينة بيختلف عن توزيع البيانات الأصلي، مع تجربة بسيطة توضح الفرق.\nفي أمثلة تطبيقية هنتعلم ال t-test بمثال عملي عشان نقارن نتائج اختبارين، واختبار Wilcoxon لما ماينفعش نفترض إن البيانات بتتبع ال Normal distribution، وهنغطي تصحيح بونفيروني (Bonferroni Correction) خطوة بخطوة، بالإضافة لطريقة بنجميني–هوخشبرج (Benjamini–Hochberg) للتحكم في معدل الاكتشافات الخاطئة (False Discovery Rate) مع أمثلة عملية واضحة.\nبنهاية الدورة هتكون قادر على:\nتلخيص وتمثيل بياناتك.\nاختيار الاختبار الإحصائي المناسب.\nالتعامل مع القيم الشاذة بطريقة علمية.\nتطبيق  ال t-test و Wilcoxon عشان تقارن نتائج اختبارين\nتطبيق تصحيحات المقارنات المتعددة لتقليل الأخطاء.",
      "target_audience": [
        "طلاب علوم الحاسب وأي شخص يريد البدء في تعلم الجانب الإحصائي اللازم لفهم الذكاء الاصطناعي وتعلم الآلة"
      ]
    },
    {
      "title": "APACHE Superset e Alteryx TRIFACTA - Dados e Visualizações",
      "url": "https://www.udemy.com/course/apache-superset-e-alteryx-trifacta-dados-e-visualizacoes/",
      "bio": "construção de visualizações de dados e preparação de dados com facilidade e desempenho",
      "objectives": [
        "Superset: plataforma de exploração e visualização de dados criada com base no Apache Superset de código aberto",
        "Superset: Permite a criação de gráficos e dashboards, permitindo a construção de visualização sem código",
        "Superset: é possível executar uma análise mais profunda usando o editor SQL nativo",
        "Superset: permite a conexão com diversas fontes de dados como Data Warehouse, Data Lake, planilhas, tudo 100% na nuvem",
        "Superset: possui um ambiente fácil de usar, onde você cria uma workspace de trabalho e constrói seus projetos",
        "Superset: permite carregar seus dados de diversos bancos de dados e origens diferentes, acessando os dados de forma transparente",
        "Superset: permite a criação de gráficos (CHART) dos mais variados e com requisitos de filtros e ajustes de campos, podendo gerar novos atributos.",
        "Superset: permite que você utilize o SQL LAB para explorar seus dados via SQL",
        "Superset: possui um fluxo de trabalho que organiza a construção das análises de dados",
        "Superset: com o Preset - APACHE Superset é possível conectar seus dados, criar um conjunto de dados, criar gráficos, construir um painel e compartilhar seus ins",
        "Superset: possui um espaço de trabalho para armazenamento das informações a serem desenvolvidas",
        "Superset: permite a construção de gráficos diversos: tabela, setores, heatmap, treemap, box plot, linha, sunburst, dentre outros",
        "Superset: permite a construção de previsões utilizando técnicas como FORECAST",
        "Superset: permite a colaboração e compartilhamento de gráficos e dashboard",
        "TRIFACTA: preparação de dados aberta que pode se conectar a diversas fontes de dados",
        "TRIFACTA: integração em todas as principais plataformas de dados em nuvem",
        "TRIFACTA: decida entre ETL ou ELT, ou uma combinação ideal dos dois com base no desempenho",
        "TRIFACTA: suporte para todas as principais nuvens, Google, AWS, Azure e on-premise",
        "TRIFACTA: interface intuitiva e simples utilização de objetos de dados",
        "TRIFACTA: Perfilização de dados, ajudando na identificação de outliers",
        "TRIFACTA: tratamento de dados, criação de novos campos, dentre outras tarefas",
        "TRIFACTA: eliminação de dados nulos, inconsistências, criação de novos campos",
        "TRIFACTA: exploração e avaliação de conteúdo e de qualidade de qualquer conjunto de dados",
        "TRIFACTA: engenharia de dados com low-code, visual, direto na nuvem",
        "TRIFACTA: construção, implantação e automatização de pipelines de dados",
        "TRIFACTA: criação de flow de dados, que permite ao analista encadear suas ações de tratamento",
        "TRIFACTA: action com os dados: Columns, Rename, Sort, Calculate, Group By, Filter Rows, Replace",
        "TRIFACTA: action com os dados: Split, Create formula, dentre outros",
        "TRIFACTA: exportação dos resultados automatizados"
      ],
      "course_content": {
        "Preset - APACHE Superset: Dashboard e Visualização de Dados": [
          "Apresentação - O que é o APACHE Superset",
          "INFORMAÇÕES IMPORTANTES! - Leia antes de começar o curso",
          "Entendendo sobre Preset - APACHE Superset",
          "Criação da conta no ambiente da nuvem do Preset",
          "Realizando a carga dos dados para o treinamento",
          "Criação do Chart - Tabela",
          "Criação do Chart - Treemap",
          "Criação do Chart - Série Temporal e Previsão com FORECAST",
          "Criação de uma nova coluna customizada",
          "Criação do Chart - KPI",
          "Criação do Chart - Sunburst",
          "Criação do Chart - Graph Chart - Gráfico de rede",
          "Criação do Chart - Box Plot",
          "Criação de dashoboard - gerando insights e entendo as análises",
          "Criação de filtros nos dashboards",
          "Criação de query pelo SQL LAB",
          "Aula Final - entrega de atividade",
          "Responda a nossa pergunta"
        ],
        "Alteryx TRIFACTA - Preparação de dados - explore e qualidade": [
          "O que é o Alteryx TRIFACTA",
          "Apresentação da Ferramenta e arquitetura",
          "Carregando os dados e fazendo Explorer dos dados",
          "Action Substituir - Tratamento de dados - parte 01",
          "Action Rename e Sort - Tratamento de dados - parte 02",
          "Action Move e Hide - Tratamento de dados - parte 03",
          "Action Format - Tratamento de dados - parte 04",
          "Action Calculate - Tratamento de dados - parte 05",
          "Action Create Columns From Examples - Tratamento de dados - parte 06",
          "Action Extract - Tratamento de dados - parte 07",
          "Action Split Column - Tratamento de dados - parte 08",
          "Action Merge - Tratamento de dados - parte 09",
          "Action Group By - Tratamento de dados - parte 10",
          "Action Filtro - Tratamento de dados - parte 11",
          "Aplicação de Funções de Controle",
          "Aplicação de Funções Especiais",
          "Executando o Fluxo de dados e gerando arquivo de saída",
          "Gerando o agendamento (Schedule) do Fluxo de Dados",
          "Aula Final - Atividade para entrega"
        ]
      },
      "requirements": [
        "Conhecimento elementar de SQL"
      ],
      "description": "Se você está procurando uma forma de aprimorar suas habilidades em análise de dados e visualização, temos dois cursos incríveis que podem te ajudar a alcançar esse objetivo: APACHE Superset e Alteryx TRIFACTA.\nNo curso APACHE Superset, você aprenderá a usar uma das ferramentas mais poderosas e populares de visualização de dados disponíveis. Durante o curso, você será guiado por uma série de módulos que abrangem desde o entendimento do Superset até a criação de visualizações avançadas, como gráficos de linhas, barras, e muito mais. Você também terá a oportunidade de trabalhar com dados reais, aplicando as técnicas que aprenderá ao longo do curso.\nJá no curso Alteryx TRIFACTA, você aprenderá a usar uma ferramenta poderosa e inovadora de preparação de dados, que permite limpar, transformar e enriquecer seus dados com facilidade. Ao longo do curso, você aprenderá a usar as poderosas funcionalidades do TRIFACTA para manipular dados de diversas fontes e formatos, automatizar tarefas de preparação de dados e melhorar a qualidade e consistência dos seus dados.\nAmbos os cursos são projetados para profissionais de negócios e de tecnologia que desejam aprender a usar ferramentas avançadas de análise e visualização de dados para melhorar sua tomada de decisão e análise de negócios. Independentemente do seu nível de experiência, nossos cursos oferecem uma abordagem prática e fácil de seguir para ajudá-lo a desenvolver suas habilidades e se destacar em sua carreira.\nInscreva-se agora em nossos cursos APACHE Superset e AlteryxTRIFACTA e comece sua jornada para se tornar um especialista em análise e visualização de dados. Aprenda a criar visualizações atraentes e informativas para ajudá-lo a entender melhor seus dados e tomar decisões mais informadas e estratégicas, e aprenda a manipular e preparar seus dados de forma mais eficiente com o Alteryx TRIFACTA. Não perca essa oportunidade de aprimorar suas habilidades e se destacar em sua carreira!\nComece hoje mesmo.",
      "target_audience": [
        "Profissionais da área de dados, estudantes, administradores, estatísticos",
        "Profissionais que desejam construir dashboards e gráficos",
        "Profissionais que querem trabalham na área de Engenharia de dados, Análise de dados, Ciência de Dados, Business Intelligence"
      ]
    },
    {
      "title": "AI绘画大师课：Midjourney入门到精通",
      "url": "https://www.udemy.com/course/aimidjourney-w/",
      "bio": "AIGC应用技巧与创作实践",
      "objectives": [
        "快速掌握Midjourney使用方法和技巧",
        "熟悉提示次撰写逻辑与高级应用",
        "了解绘画背景，充分结合艺术与创作",
        "清楚AI绘画商业变现思维与法律法规"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "第一章 AI绘画入门门": [
          "1.1 AIGC商业应用",
          "1.2 AI绘画工具4大主流平台",
          "1.3 Midjourney注册与使用入门",
          "1.4 提示词设计规则",
          "1.5 提升图片质量"
        ],
        "第二章 Midjourney工具进阶": [
          "2.1 工具命令详解",
          "2.2 Midjourney高级参数",
          "2.3 提示词高级应用 - 图片融合",
          "2.4 图片权重分配",
          "2.5 提示词排列组合、多线程任务",
          "2.6 如何保持图片风格一致性",
          "2.7 如何用chatGPT训练AI绘画模型",
          "2.8 Midjourney提示词生成器"
        ],
        "第三章 高阶创作必备": [
          "3.1如何欣赏一幅画",
          "3.2 绘画背景的选择",
          "3.3 绘画的笔触、形状和构图",
          "3.4 人物的情绪"
        ],
        "第四章 艺术风格": [
          "4.1 石器时代到洛可可艺术",
          "4.2 新古典主义到印象派",
          "4.3 现代主义"
        ],
        "第五章摄影作品": [
          "5.1 摄影作品提示词结构和构图",
          "5.2 相机参数设置",
          "5.3 光影参数"
        ],
        "第六章 插画创作": [
          "6.1黑白插画与彩色插画",
          "6.2 不同材质与不同风格",
          "6.3动漫作品"
        ],
        "第七章 3D艺术作品": [
          "7.1 雕塑设计",
          "7.2 工艺艺术品",
          "7.3 空间设计"
        ],
        "第八章 AI绘画商业变现": [
          "第八章 AI绘画商业变现"
        ],
        "第九章 变现场景": [
          "9.1 珠宝设计",
          "9.2 室内设计",
          "9.3 服装设计",
          "9.4 美食设计",
          "9.5 游戏建模",
          "9.6 平面设计",
          "9.7 商标设计",
          "9.8 产品模型设计",
          "9.9 绘本设计"
        ]
      },
      "requirements": [
        "有ai绘画意向或基础的人员"
      ],
      "description": "《太空歌剧院》画作的诞生揭开了AI绘画行业的序幕，AI逐渐走入人们的视野，产生新的认知，加上ChatGPT的出现更进一步引起世界对AIGC的关注。其中，AI绘画作为新兴的内容生产方式备受瞩目。\n为此，三节课邀请了《ChatGPT大师班》和《AI绘画大师班》的作者黄豆奶爸带来本次课程。\n本课程分为五大模块，从AI绘画基础工具与设计规则、Midjourney的进阶玩法、AI创作的底层逻辑与艺术背景、主流的艺术创作形态到AI绘画的商业变现。学习了本门课程，你将收获根据内容提炼出关键词和风格元素的能力，并将所学运用到实际工作中，把握行业变革与机遇。",
      "target_audience": [
        "AI技术爱好者",
        "对AI绘画感兴趣或想转型的学员",
        "设计师、原画师、商业插画师"
      ]
    },
    {
      "title": "데이터분석 패키지 : Numpy(넘파이) 제대로 배우기 Part.1",
      "url": "https://www.udemy.com/course/numpy-part1/",
      "bio": "Numpy(넘파이) 라이브러리로 데이터를 처리하기 위해 필요한 모든 학습 내용",
      "objectives": [
        "파이썬을 이용한 데이터분석 기초",
        "Numpy(넘파이) 소개 및 기본 사용법",
        "배열 조작과 변환",
        "행렬 및 행렬 연산",
        "자료형과 인덱싱",
        "배열 조작 및 Broadcasting",
        "다차원 배열 및 삼중 for문"
      ],
      "course_content": {
        "[HD]행렬 및 다차원배열, 고속의 수치계산용 라이브러리 Numpy(넘파이) 제대로 배우기 Part.1": [
          "과정개요 및 넘파이 설치",
          "넘파이 - import, version, array, shape",
          "넘파이 - type, size, ndim",
          "실습1",
          "넘파이 - size vs len 차이점",
          "넘파이 - 1차원 shape 값은 왜 (5,) 인가요",
          "넘파이 - identical type(부제 - 넘파이는 왜 빠른가)",
          "실습2",
          "넘파이 - 중첩배열, shape 인덱스, reshape, zeros, ones",
          "실습3",
          "넘파이 - 단위행렬(identity matrix) 및 실습",
          "넘파이 - 행렬 곱셈 및 실습",
          "넘파이 - arange",
          "실습4",
          "넘파이 - 마이너스(-1) shape 열 기준",
          "넘파이 - 마이너스(-1) shape 행 기준",
          "실습5",
          "넘파이 - 자료형(DataType)",
          "넘파이 - 자료형(DataType) int float dtype astype bool",
          "실습6",
          "넘파이 - int_ float_ str",
          "넘파이 - 빅 엔디언 vs 리틀 엔디언 방식",
          "넘파이 - 자료형 확인 issubdtype",
          "실습7"
        ],
        "[HD]행렬 및 다차원배열, 고속의 수치계산용 라이브러리 Numpy(넘파이) 제대로 배우기 Part.2": [
          "넘파이 - 인덱싱(1)",
          "넘파이 - 인덱싱(2)",
          "넘파이 - 인덱싱(3)",
          "실습8",
          "넘파이 - 인덱싱 열(Column) 기준 색인(1)",
          "넘파이 - 인덱싱 열(Column) 기준 색인(2)",
          "실습9",
          "넘파이 - 뷰(View)",
          "넘파이 - 고유 인덱싱 방식",
          "실습10",
          "넘파이 - 짝수(홀수)행 출력",
          "넘파이 - 고유 방식으로 짝수(홀수)행 출력",
          "실습11",
          "넘파이 - Broadcasting(1)",
          "넘파이 - Broadcasting(2)",
          "넘파이 - Broadcasting(3)",
          "넘파이 - Broadcasting Rule",
          "실습12",
          "넘파이 - Broadcasting 연습문제",
          "넘파이 - Broadcasting 비교연산",
          "넘파이 - indexing, slicing 연습문제(1)",
          "넘파이 - indexing, slicing 연습문제(2)",
          "넘파이 - view vs copy",
          "넘파이 - 3D array",
          "넘파이 - 3D array indexing slicing",
          "넘파이 - 2차원 및 3차원 배열 이중 삼중 for문으로 접근하기",
          "넘파이 - append 메서드를 사용하여 생성한 배열에 행과 열 추가하기"
        ]
      },
      "requirements": [
        "파이썬 기초 문법 및 활용이 가능하신 분들이 수강하실 수 있습니다"
      ],
      "description": "안녕하세요, ITGO 입니다.\n\n\n본 강의 시리즈는 '데이터분석 패키지 : Numpy(넘파이) 제대로 배우기 Part.1'입니다.\n\n\n'데이터분석 패키지' 강의 시리즈는 총 2편으로 나뉘어 있으며, 본 강의는 Numpy(넘파이) 제대로 배우기 Part.1편에 해당합니다.\n\n\n\n\n'데이터분석 패키지' 강의 시리즈는 파이썬을 이용한 데이터분석 과정에 입문해보고자 하는 분들을 위한 핵심 코스입니다. 파이썬 데이터분석에서 필수적으로 사용되는 Numpy(넘파이)와 Pandas(판다스) 라이브러리 활용에 대한 내용들을 담고있습니다\n\n\n본 강의는 Numpy(넘파이) 라이브러리로 데이터를 처리하기 위해 필요한 모든 학습 내용을 다루고 있습니다.\n\n\n\n\n[누구를 위한 강의인가요?]\n\n\nNumpy(넘파이)에 대한 학습이 필요한 사람\n\n\n내 손으로 직접 데이터를 처리하고 분석해보고 싶은 사람\n\n\n\n\n[무엇을 배우나요?]\n\n\n파이썬을 이용한 데이터분석 기초\n\n\nNumpy(넘파이) 소개 및 기본 사용법\n\n\n배열 조작과 변환\n\n\n행렬 및 행렬 연산\n\n\n자료형과 인덱싱\n\n\n배열 조작 및 Broadcasting\n\n\n다차원 배열 및 삼중 for문\n\n\n\n\n\n\n그럼 강의에서 만나요 :)",
      "target_audience": [
        "Numpy(넘파이)에 대한 학습이 필요한 사람",
        "내 손으로 직접 데이터를 처리하고 분석해보고 싶은 사람"
      ]
    },
    {
      "title": "金融风控实战入门",
      "url": "https://www.udemy.com/course/fzondrom/",
      "bio": "完整公开金融风控背后的技术",
      "objectives": [
        "全面了解信贷风控领域的算法与业务，能完整、规范地搭建金融风控模型",
        "掌握百万量级变量衍生变量筛选方法",
        "开启为业务定制模型的思路，踏入算法工程师的高精领域",
        "帮助学员积累大量一线业务经验，成为瑞士军刀般的风控人才"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "金融风控与反欺诈业务详解",
          "风控数据挖掘方法",
          "特征工程（上）",
          "特征工程（下）",
          "逻辑回归评分卡",
          "集成算法",
          "不均衡学习",
          "模型融合",
          "迁移学习",
          "深度学习与金融风控",
          "异常检测实战",
          "社交网络分析与金融反欺诈"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "有金融相关经验"
      ],
      "description": "本次课程将首次全面公开一线平台金融风控核心技术，覆盖风控全流程，从一线公司的业务出发。主要包括以下内容:\n五大思路:特征构造、特征选择、算法选择、损失函数构造、业务分析。四大风控算法:监督学习、无监督学习、弱监督学习、复杂网络算法。一套完整的风控流程:数据抓取、反欺诈、风控策略、风控模型、催收。\n通过这门课程，不仅可以一窥神秘的金融风控领域的全貌、接触来自Exprian、Dis-cover、蚂蚁金服等巨头公司的顶级风控技术，更可以从最新颖、最前沿的项目中，学习如何针对实际业务定制算法、选择模型。",
      "target_audience": [
        "适合想找金融风控相关工作、以及对金融风控感兴趣的同学",
        "适合企业风控算法工程师",
        "适合企业反作弊系统工程师"
      ]
    },
    {
      "title": "大模型的实战应用：有监督学习之机器学习",
      "url": "https://www.udemy.com/course/yfkvhhhc/",
      "bio": "掌握K近邻算法，探索机器学习实战之路",
      "objectives": [
        "深入理解K近邻算法：你将全面掌握K近邻算法的原理、推导过程和应用技巧。通过ChatGPT的生动讲解，你将轻松理解算法的核心思想，并能够灵活运用到实际场景中。",
        "实战能力提升：课程提供了丰富的实战案例，包括使用sklearn和R语言进行K近邻分类等。通过亲手实践，你将能够熟练运用K近邻算法解决实际问题，提升自己在数据分析和机器学习领域的实战能力。",
        "拓展职业视野：课程将介绍机器学习在不同行业的应用情况和前景，让你对行业的趋势和发展有更深入的了解。这将有助于你拓展职业视野，为未来的职业发展做好准备。",
        "培养创新思维：通过对大模型的深入学习和实战应用，学员将能够培养创新思维，学会如何将机器学习技术创造性地应用于各种实际场景中。"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲",
          "引入讲解"
        ],
        "课程内容": [
          "1、通过ChatGPT介绍什么是K近邻算法.",
          "2、通过ChatGPT介绍K近邻算法推导过程.",
          "3、通过ChatGPT解释为什么k近邻是一种“懒惰学习\"算法.",
          "4、通过ChatGPT介绍sklearn中的KNeighborsClassifier类.",
          "5、通过案例:利用ChatGPT利用sklearn对iris数据集进行K近邻分类.",
          "6、通过ChatGPT介绍R语言中的knn函数.",
          "7、案例:通过ChatGPT利用R语言的knn函数对iris数据集进行K近邻分类.",
          "8、通过ChatGPT介绍什么是决策树算法.",
          "9、通过ChatGPT介绍决策树常用算法.",
          "10、通过ChatGPT介绍嫡、信息增益、信息增益率.",
          "11、通过ChatGPT介绍决策树的预剪枝及后剪枝.",
          "12、通过ChatGPT介绍sklearn中的DecisionTreeClassifier类.",
          "13、案例:通过ChatGPT利用sklearn对iris数据集进行决策树分类.",
          "14、通过ChatGPT介绍R语言的rpart包的rpart函数",
          "15、案例： 通过ChatGPT利用R语言对iris数据集进行决策树分类",
          "16、通过ChatGPT学习集成学习",
          "17、案例1： python利用sklearn对iris数据集进行随机森林分类",
          "18、案例2： R语言对iris数据集进行随机森林分类"
        ],
        "课程回顾": [
          "课程寄语"
        ]
      },
      "requirements": [
        "有一定数据基础的学员"
      ],
      "description": "在数字化时代，数据驱动决策成为行业标配。然而，面对海量数据，如何有效提取信息并转化为实际应用成为了一大挑战。本课程《大模型的实战应用：有监督学习之机器学习》应运而生，聚焦K近邻算法，深入剖析其原理与实践。通过结合ChatGPT的生动讲解，你将掌握从理论到实践的完整流程，包括算法推导、懒惰学习原理、sklearn应用以及R语言实现等。本课程旨在帮助学习者构建完整的数据分析框架，提升在数据处理与机器学习领域的实战能力，为职业发展注入新动力。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "数据科学家和数据分析师：对于数据科学家和数据分析师来说，掌握各种机器学习算法是非常重要的。本课程将帮助他们深入理解K近邻算法的原理和应用，提升他们在数据分析和建模方面的能力。",
        "软件开发工程师：软件开发工程师通常需要处理大量的数据，并能够从中提取有用的信息。通过学习这门课程，他们可以更好地应用机器学习技术来解决实际问题，提高软件的质量和效率。",
        "机器学习初学者：对于刚开始接触机器学习的初学者来说，这门课程将提供坚实的理论基础和实战案例，帮助他们快速入门并掌握K近邻算法的核心内容。"
      ]
    },
    {
      "title": "Python数据可视化：Pyecharts可视化实战",
      "url": "https://www.udemy.com/course/pythonpyecharts/",
      "bio": "对Python的Pyecharts绘图有深刻的认识，轻松掌握Pyecharts数据可视化。",
      "objectives": [
        "掌握绘制交互柱状图、部分叠加柱状图、默认部分柱子选中的柱状图",
        "掌握利用Pyecharts绘制折线图、增加标注线的曲线图、增加标注区域的曲线图",
        "实战学会利用Pyecharts进行可视化的数据分析",
        "提升可视化数据分析能力及利用Python的数据处理能力"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "动态数据可视化常用库介绍",
          "Pyecharts绘制单属性柱状图",
          "Pyecharts绘制多属性柱状图-分组、堆叠、部分堆叠数据",
          "Pyecharts交互可视化-设置标题及图例",
          "Pyecharts交互数据可视化-瀑布图",
          "Pyecharts交互可视化-增加DataZoomOPts选项",
          "Pyecharts交互可视化-增加标记点",
          "Pyecharts交互可视化-直方图",
          "Pyecharts交互可视化-绘制线图、增加标注线曲线图",
          "Pyecharts交互可视化-绘制箱线图",
          "Pyecharts交互可视化-散点图和带涟漪效果散点图",
          "Pyecharts交互可视化-绘制仪表盘和水滴图",
          "Pyecharts交互可视化-绘制雷达图",
          "Pyecharts交互可视化-旭日图",
          "Pyecharts交互可视化-绘制树图和矩阵树图",
          "Pyecharts交互可视化-增加Timeline-时间轴",
          "Pyecharts交互可视化-增加Tab-选项卡",
          "Pyecharts交互可视化-多图"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "数据分析基础"
      ],
      "description": "本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。\n课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利\n人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课\n公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位\n提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，\n您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "适合想从事数据分析和数据可视化的人员 适合企业初中级数据分析师学习使用 适合高校师生以及企业运营/营销从业人员"
      ]
    },
    {
      "title": "Metabase: Análise e visualização de Dados para iniciantes",
      "url": "https://www.udemy.com/course/metabase-analise-e-visualizacao-de-dados-para-iniciantes/",
      "bio": "Curso METABASE, Tome decisões melhores e mais rápido orientado a dados",
      "objectives": [
        "Instalar e configurar o Metabase para análise de dados",
        "Criar visualizações e dashboards personalizáveis",
        "Conectar o Metabase a diferentes fontes de dados",
        "Gerenciar usuários, grupos de acesso e permissões no Metabase",
        "Disparo de Alertas com os dashboards",
        "Analisar e visualizar os dados",
        "Comparilhar e colaborar os dashboards com outros usuarios"
      ],
      "course_content": {
        "Introdução": [
          "Apresentação",
          "O que é o Metabase"
        ],
        "Conhecendo o ambiente do Metabase": [
          "Conhecendo o ambiente do Metabase"
        ],
        "Configuração do ambiente de desenvolvimento": [
          "Introdução",
          "Instalação do Metabase no Windows",
          "Instalação do Metabase no Linux (Ubuntu)"
        ],
        "Conexão do Metabase a um Banco de Dados": [
          "Introdução",
          "Instalação do Postgres como Banco de Dados de armazenamento",
          "Conhecendo os dados que serão utilizados no curso",
          "Conectando um Banco de Dados no Metabase",
          "Carregando os dados para dentro do Metabase",
          "Convertendo arquivos XLSX para CSV"
        ],
        "Criando Perguntas, Dashboards e Filtros": [
          "Iniciando sobre criação de Perguntas & Dashboards",
          "Perguntas & Dashboards; Quantidade de vendas por Ano e Mês",
          "Perguntas & Dashboards; Valor total de vendas e Vendas por Ano",
          "Perguntas & Dashboards; Quantidade total de itens vendidos e por Ano",
          "Perguntas & Dashboards; Quantidade de itens vendidos por categoria e Top Rank",
          "Perguntas & Dashboards; Valor de Vendas por Status da Entrega e Devoluções",
          "Criação de filtros no Dashboard 1",
          "Criação de filtros no Dashboard 2",
          "Apresentação Dashboard versão Final"
        ],
        "Criação de Dashboard de RH & Desafio complementar": [
          "Introdução",
          "Conhecendo os nossos dados utilizando o Postgres",
          "Criando querys e e analisando aos dados de RH",
          "Criando relacionamento entre as tabelas usando SQL",
          "Conectando um Banco de Dados no Metabase e mais sobre SQL & Relacionamentos",
          "Implementando uma melhoria na query & select",
          "Iniciando o desenvolvimento do Dashboard de RH",
          "Continuação com o desenvolvimento do Dashboard de RH",
          "Desafio"
        ],
        "Criação de Usuários, Grupos de Acesso e Configuração de Acessos e Permissões": [
          "Criação de usuários, grupos de acesso e configuração de acessos e permissões",
          "Reset de senha"
        ]
      },
      "requirements": [
        "Não há necessídade prévia em análise ou visualização de dados para fazer o curso"
      ],
      "description": "Curso Completo de METABASE: Análise e visualização de dados para iniciantes\nSeja bem-vindo ao curso mais completo de METABASE!\nVocê está buscando dominar uma das ferramentas mais poderosas e gratuita de BI (Business Intelligence) e análise de dados do mercado? Então este curso é para você! Nele, você aprenderá desde os conceitos básicos até as funcionalidades avançadas da plataforma, capacitando-se para criar dashboards, relatórios e análises detalhadas de dados que podem transformar a tomada de decisões em sua empresa.\nO que você vai aprender:\nInstalar e configurar o Metabase para análise de dados\nCriar visualizações e dashboards personalizáveis\nComo conectar o METABASE a diversas fontes de dados.\nGerenciar usuários, grupos de acesso e permissões no Metabase\nAnalisar e visualizar os dados\nComparilhar e colaborar os dashboards com outros usuarios\nCriação de relatórios personalizados e dinâmicos.\nDesenvolvimento de dashboards interativos e visualmente atraentes.\nAplicação de funções analíticas avançadas para extração de insights valiosos.\nPor que fazer este curso? Este curso é ideal para analistas de dados, profissionais de TI, gestores e todos aqueles que desejam elevar suas habilidades em Business Intelligence e dominar uma plataforma robusta e amplamente utilizada no mercado. Não importa se você é iniciante ou já tem experiência em BI, o curso foi desenhado para atender a diferentes níveis de conhecimento, oferecendo exercícios práticos e estudos de caso reais.\nComece hoje mesmo a sua jornada no mundo da análise de dados com o METABASE e destaque-se no mercado de trabalho!",
      "target_audience": [
        "Profissionais de TI e Analistas de Dados",
        "Equipes de vendas e marketing que desejam melhorar o monitoramento de KPIs",
        "Estudantes e iniciantes em análise de dados",
        "Profissionais que precisam tomar decisões baseadas em dados",
        "Empreendedores e gestores de pequenas empresas",
        "Profissionais que precisam implementar soluções de visualização de dados sem custos"
      ]
    },
    {
      "title": "쉽게 배우는 텍스트 마이닝(Text Mining) Part.3 한국어를 위한 KoNLPy",
      "url": "https://www.udemy.com/course/text-mining-part3-konlpy/",
      "bio": "한국어의 텍스트 마이닝에 필요한 기술을 체계적으로 학습할 수 있습니다",
      "objectives": [
        "KoNLTK 소개 및 기초 학습",
        "KoNLPy의 기본 말뭉치 분석",
        "KoNLPy를 활용한 실제 데이터 분석",
        "단어 빈도 분석과 시각화",
        "KoNLPy corpus를 NLTK로 분석"
      ],
      "course_content": {
        "[HD]쉽게 배우는 텍스트 마이닝(Text Mining) Part.3 한국어를 위한 KoNLPy 1": [
          "강의개요 및 권장 학습순서와 한국어 분석 KoNLPY",
          "품사 분석을 통한 텍스트분석의 의미와 다양한 KoNLPY 형태소 분석기들",
          "NLTK 패키지내 품사 분류표 - 암기하자",
          "KoNLPY 설치시 필요한 것과 내pc에 설치하기",
          "konlpy 형태소 분석기를 활용한 한국어 형태소 분석하기(1)",
          "konlpy 형태소 분석기를 활용한 한국어 형태소 분석하기(2)",
          "한국어 형태소 분석의 어려움 및 자립형태소와 의존형태소 구분하기",
          "KoNLPy에서 기본적으로 제공하는 말뭉치들 - kolaw, kobill",
          "KoNLPy 말뭉치(corpus) 순회하면서 단어 수 및 중복제거한 명사 개수 구하기(1)",
          "KoNLPy 말뭉치(corpus) 순회하면서 단어 수 및 중복제거한 명사 개수 구하기(2)",
          "KoNLPy내 kobill 말뭉치 10개 텍스트파일별 품사 부착하기 - pos 태깅(1)",
          "KoNLPy내 kobill 말뭉치 10개 텍스트파일별 품사 부착하기 - pos 태깅(2)",
          "한국어 동사 원형을 복원시켜서 출력하기 - stem",
          "[하늘을 나는 종이비행기] 를 각 한국어 형태소 분석기는 어떻게 분석할까",
          "문재인 대통령 취임사 연설문 분석하기(1)",
          "문재인 대통령 취임사 연설문 분석하기(2)",
          "문재인 대통령 취임사 연설문 분석하기(3)",
          "Counter() 함수를 이용하여 단어 빈도 수 계산하기",
          "단어구름(wordcloud)으로 출력 및 저장하기",
          "KoNLPy corpus(말뭉치)를 NLTK 패키지로 분석해보기(1)"
        ],
        "[HD]쉽게 배우는 텍스트 마이닝(Text Mining) Part.3 한국어를 위한 KoNLPy 2": [
          "021_KoNLPy corpus(말뭉치)를 NLTK 패키지로 분석해보기(2)",
          "022_KoNLPy corpus(말뭉치)를 NLTK 패키지로 분석해보기(3)",
          "023_KoNLPy 형태소 분석기별 품사 분류표 데이터프레임으로 변환 출력(1)",
          "024_KoNLPy 형태소 분석기별 품사 분류표 데이터프레임으로 변환 출력(2)",
          "025_KoNLPy 형태소 분석기별 품사 분류표 데이터프레임으로 변환 출력(3)",
          "026_단어주머니란 무엇인가 - Bag of words",
          "027_빈도 수 기반의 핵심어 추출",
          "028_TF-IDF 어휘 빈도 문서 역빈도",
          "029_자연어 처리를 위한 텍스트 수치화 작업 - BoW 구현하기(1) - 토큰화 처리",
          "030_자연어 처리를 위한 텍스트 수치화 작업 - BoW 구현하기(2) - WordPunctTokenizer, TreebankWordTokeni",
          "031_Bag of words 구현하기(3) - BoW 실습을 위한 텍스트 전처리",
          "032_Bag of words 구현하기(4) - stopwords, punctuation 제거",
          "033_사이킷런 BoW 구현1",
          "034_사이킷런 BoW 구현2 - Count Vector 수치화",
          "035_사이킷런 BoW 구현3 - 단어 사전화 처리된 vocabulary_(딕셔너리) 출력해보기",
          "036_CountVectorizer 파라미터 옵션(1) - max_df, min_df",
          "037_CountVectorizer 파라미터 옵션(2) - max_features, stop_words",
          "038_CountVectorizer 파라미터 옵션(3) - ngram_range",
          "039_TfidfVectorizer 기반의 자연어 텍스트 수치화 작업(1)",
          "040_TfidfVectorizer 기반의 자연어 텍스트 수치화 작업(2)"
        ]
      },
      "requirements": [
        "파이썬 및 데이터 분석에 대한 기초적인 지식이 있는 분들이 수강하실 수 있습니다"
      ],
      "description": "안녕하세요, ITGO 입니다.\n\n\n본 강의 시리즈는 '쉽게 배우는 텍스트 마이닝(Text Mining) Part.3 한국어를 위한 KoNLPy'입니다.\n\n\n'쉽게 배우는 텍스트 마이닝(Text Mining)' 강의 시리즈는 총 4편으로 나뉘어 있으며, 본 강의는 ‘Part.3 한국어를 위한 KoNLPy’편에 해당합니다.\n\n\n\n\n본 강의는 영어의 텍스트 마이닝에 필요한 기술을 체계적으로 학습할 수 있습니다.\n\n\n\n\n[누구를 위한 강의인가요?]\n\n\n빠른 시간에 데이터수집 및 관련 라이브러리를 배우고자 하는 자\n\n\n빠른 시간에 KoNLPy 패키지 및 관련 라이브러리를 배우고자 하는 자\n\n\n\n\n\n\n[무엇을 배우나요?]\n\n\nKoNLTK 소개 및 기초 학습\n\n\nKoNLPy의 기본 말뭉치 분석\n\n\nKoNLPy를 활용한 실제 데이터 분석\n\n\n단어 빈도 분석과 시각화\n\n\nKoNLPy corpus를 NLTK로 분석\n\n\n\n\n그럼 강의에서 만나요 :)",
      "target_audience": [
        "빠른 시간에 데이터수집 및 관련 라이브러리를 배우고자 하는 자",
        "빠른 시간에 KoNLPy 패키지 및 관련 라이브러리를 배우고자 하는 자"
      ]
    },
    {
      "title": "Python零基础入门全攻略",
      "url": "https://www.udemy.com/course/python-mm/",
      "bio": "掌握一技之长，Python精通之路，面试攻略+AI大模型实战",
      "objectives": [
        "Python宝典 - 从基本变量定义出发，到面向对象编程，并延伸至多线程开发，实现知识点的全方位深度覆盖。",
        "面试攻略 - 精细分析并梳理了针对Python基础知识的面试中常出现的问题类型及其关键考核点。",
        "项目实战 - 融入当前热门的大语言模型平台。最终项目将引导你开发个人软件包，并发布至Pypi，与全球Python开发者共襄盛举。",
        "课件内容丰富 - 凭借逾20年的研发经验，精心挑选了典型案例，并以独特的教学方法为学习者生动形象地阐述。"
      ],
      "course_content": {
        "介绍": [
          "Python 介绍",
          "安装Python开发环境"
        ],
        "Python 基础": [
          "数据类型和操作符",
          "项目实战 - 使用 Python 接入大语言模型",
          "模拟面试： Python 数据类型",
          "面试攻略1 - 数据类型核心考点精析",
          "模拟面试：Python 操作符",
          "面试攻略2 - 操作符核心考点精析",
          "数据结构 - 列表 List",
          "项目实战 - AI客服助理",
          "模拟面试：列表",
          "面试攻略3 - 列表核心考点精析",
          "数据结构 - 元组和集合 Tuple and Set",
          "数据结构 - 字典 Dict",
          "迭代器和生成器",
          "项目实战-写作精灵",
          "模拟面试：字典",
          "面试攻略4 - 字典核心考点精析",
          "逻辑控制",
          "函数 Function"
        ],
        "Python 进阶": [
          "错误处理",
          "导入模块 import",
          "闭包函数 Closures",
          "函数与装饰器 Decorator",
          "模拟面试：函数",
          "面试攻略5 - 函数核心考点精析",
          "面向对象编程 - 类 Class",
          "魔术方法 Magic methods",
          "面向对象编程 - 继承 Inheritance",
          "Public、Private 和 Protected 属性",
          "类与装饰器 @property @classmethod @staticmethod",
          "模块化",
          "项目实战 - 手把手教你将代码封装为Python库，轻松实现pip安装与分享",
          "并发及并行",
          "C语言扩展"
        ]
      },
      "requirements": [
        "零编程基础也可轻松掌握，您将学习到所需的全部知识。"
      ],
      "description": "我是一名数据科学家，拥有20年芬兰诺基亚、LG研发中心工作经验，专攻人工智能与深度强化学习。以丰富的实战经验，带你深入探索数据科学前沿。\n本课程专为零基础，并对Python编程充满热情，期望未来能投身于相关领域工作的学习者精心设计。\n本课程不会涉及 Python 爬虫等传统实战项目，因为在实际工作中根本不依赖爬虫技术来获取数据。课程特别结合了当前最受欢迎的“AI 大语言模型”，设计了一系列项目实战案例。\n本课程全面涵盖Python知识点，并特别融入模拟面试环节，让学习者亲身体验实际工作场景中的Python应用，不仅限于理论知识，更注重实践能力的培养。",
      "target_audience": [
        "对于数据科学怀抱热情，渴望掌握Python技能的开发者。"
      ]
    },
    {
      "title": "ViT（Vision Transformer）原理与代码精讲",
      "url": "https://www.udemy.com/course/vit-transformer/",
      "bio": "深度学习新范式",
      "objectives": [
        "掌握ViT原理",
        "掌握ViT的Pytorch实现代码",
        "学习Transformer的原理",
        "学习einops和einsum的使用方法"
      ],
      "course_content": {
        "课程介绍": [
          "课程介绍"
        ],
        "ViT原理精讲": [
          "Transformer架构概述",
          "Transformer的Encoder",
          "Transformer的Decoder",
          "ViT架构概述",
          "ViT模型详解",
          "ViT性能及分析"
        ],
        "ViT代码精讲（PyTorch）": [
          "安装PyTorch",
          "ViT的timm库实现代码精讲",
          "einops和einsum",
          "ViT的einops/einsum代码实现精讲"
        ]
      },
      "requirements": [
        "熟悉python和pytorch"
      ],
      "description": "Transformer在许多NLP(自然语言处理)任务中取得了最先进的成果。 ViT (Vision Transformer)是Transformer应用于CV（计算机视觉）领域里程碑式的工作，后面发展出更多的变体，如Swin Transformer。\nViT (Vision Transformer)模型发表于论文An Image is Worth 16X16 Words: Transformer For Image Recognition At Scale，使用纯Transformer进行图像分类。ViT在JFT-300M数据集上预训练后，可超过卷积神经网络ResNet的性能，并且所用的训练计算资源可更少。\n本课程对ViT的原理与PyTorch实现代码进行精讲，来帮助大家掌握其详细原理和具体实现。其中代码实现包含两种代码实现方式，一种是采用timm库，另一种是采用einops/einsum。\n原理精讲部分包括：Transformer的架构概述、Transformer的Encoder 、Transformer的Decoder、ViT架构概述、ViT模型详解、ViT性能及分析。\n代码精讲部分使用Jupyter Notebook对ViT的PyTorch代码进行逐行解读，包括：安装PyTorch、ViT的timm库实现代码解读、 einops/einsum 、ViT的einops/einsum实现代码解读。",
      "target_audience": [
        "希望学习ViT（Vision Transformer）原理与PyTorch实现代码的学员"
      ]
    },
    {
      "title": "Analistler için Veri Görselleştirme - 2025",
      "url": "https://www.udemy.com/course/analistler-icin-veri-gorsellestirme/",
      "bio": "Doğru grafik seçimi, güçlü hikâyeleştirme, interaktif araçlar ve profesyonel raporlama teknikleri",
      "objectives": [
        "Ham veriyi anlaşılır, ilgi çekici ve görsel olarak güçlü grafiklere dönüştürmek.",
        "Farklı veri setleri ve iş senaryoları için en uygun grafik türünü seçebilmek.",
        "Veriyle hikaye anlatımı tekniklerini kullanarak içgörüleri etkili şekilde aktarmak.",
        "Gelişmiş görselleştirme yöntemleriyle profesyonel slaytlar ve raporlar tasarlamak.",
        "Yanıltıcı grafik kullanımında yapılan yaygın hataları tanıyıp bunlardan kaçınmak.",
        "Alıştırmalar, quizler ve vaka çalışmalarıyla öğrenilen bilgileri pekiştirmek."
      ],
      "course_content": {
        "Giriş": [
          "Veri görselleştirmeye giriş"
        ],
        "Doğru Grafik Seçmek": [
          "Çubuk Grafikler (Bar Charts)",
          "Sütun Grafikler (Column Charts)",
          "Pasta Grafikler (Pie Charts)",
          "Quiz #1",
          "Çizgi Grafikler (Line Charts)",
          "Dağılım Grafikleri (Scatter Plots)",
          "Vaka Analizi - AeroLine",
          "Vaka Çalışması - AeroLine",
          "Quiz #2"
        ],
        "Verilerle Hikaye Anlatımı": [
          "Verilerle Hikaye Anlatımı - Giriş",
          "Sadelik",
          "Odak Noktası",
          "Biçimlendirme",
          "Vaka Analizi - Ayakkabıcım",
          "Vaka Analizi - Ayakkabıcım",
          "Quiz #3"
        ],
        "Ek Grafik Türleri": [
          "Ek Grafik Türleri - Giriş",
          "Mekko Grafikleri",
          "Şelale Grafikleri (Waterfall Charts)",
          "Radar Grafikleri"
        ],
        "Profesyonel Slayt Hazırlamak": [
          "Profesyonel Slayt Hazırlamak",
          "Profesyonel Slayt Türleri"
        ],
        "Kapanış": [
          "Kapanış"
        ]
      },
      "requirements": [
        "Bilgisayarda temel düzeyde çalışma (Excel, PowerPoint veya benzeri araçlar) faydalı olabilir ama zorunlu değildir.",
        "Veriyi daha etkili ve anlaşılır sunmaya ilgi duymak yeterlidir."
      ],
      "description": "Bu kurs, analistlerin, iş zekâsı uzmanlarının, danışmanların ve veriyle çalışan tüm profesyonellerin görselleştirme becerilerini üst seviyeye taşımaları için tasarlanmıştır. Günümüzde veriyi doğru analiz etmek kadar, onu etkili ve anlaşılır bir şekilde sunmak da kritik önem taşımaktadır. Yanlış grafik türü seçimi, mesajın izleyiciye ulaşmasını zorlaştırabilir veya karar vericilerin yanlış yönlendirilmesine yol açabilir. Bu eğitim, bu tür hataların önüne geçmeyi ve verilerinizin gerçek potansiyelini açığa çıkarmanızı hedefler.\nKurs boyunca;\nFarklı grafik türlerini tanıyacak ve hangi durumda hangisinin kullanılması gerektiğini net bir şekilde kavrayacaksınız.\nVerilerle hikâye anlatma (data storytelling) tekniklerini öğrenerek bulgularınızı yalnızca göstermekle kalmayacak, aynı zamanda ikna edici bir hikâyeye dönüştürmeyi deneyimleyeceksiniz.\nProfesyonel grafik tasarım ipuçları ve McKinsey tarzı sade, net ve güçlü sunum yöntemleri ile verilerinizi üst düzeyde aktarabileceksiniz.\nSadece teorik bilgi değil, uygulamalı egzersizler, quiz’ler, vaka çalışmaları ve gerçek hayattan örneklerle öğreniminizi pekiştireceksiniz.\nEğitimin sonunda, bir analist olarak yalnızca doğru analizler yapmakla kalmayacak, aynı zamanda:\nVerilerinizi akılda kalıcı, net ve etkili bir şekilde sunmayı,\nKarar vericilerin dikkatini kritik noktalara çekebilmeyi,\nSunumlarınızla güvenilirliğinizi ve profesyonelliğinizi artırmayı öğreneceksiniz.\nBu beceriler sayesinde hazırlayacağınız raporlar, dashboard’lar ve sunumlar iş hayatınız boyunca daha güçlü, daha anlaşılır ve daha ikna edici olacak. Kısacası, sizi diğer profesyonellerden ayıran stratejik bir veri hikâyeleştirme uzmanı olma yolunda önemli bir adım atacaksınız.",
      "target_audience": [
        "Veri analistleri, iş analistleri ve veriyle çalışan profesyoneller.",
        "Analitik ve sunum becerilerini geliştirmek isteyen öğrenciler veya yeni mezunlar.",
        "Yöneticilere, müşterilere veya paydaşlara veri sunmak durumunda olan iş dünyası çalışanları.",
        "Teknik geçmişi olmasa bile verilerle hikâye anlatmayı öğrenmek isteyen herkes."
      ]
    },
    {
      "title": "Ciência de Dados , Machine Learning com Python e Power BI",
      "url": "https://www.udemy.com/course/ciencia-dados-aplicada-python-powerbi/",
      "bio": "Domine a Análise de Dados com Python, Machine Learning e Power BI em um projeto real de Ciência de Dados",
      "objectives": [
        "Desenvolver, na prática, um projeto completo de Ciência de Dados, unindo Python, Machine Learning (XGBoost e Prophet) e visualização interativa com Power BI",
        "Integrar dados de fontes públicas gratuitas via APIs, possibilitando a reprodução do projeto sem custo adicional",
        "Aplicar Análise de Dados estruturados com técnicas de identificação de padrões, análise de tendências e previsão com modelos preditivos",
        "Construir seus próprios modelos de Machine Learning com base em exemplos reais e scripts prontos em Python",
        "Unir aprendizado estatístico e inteligência visual com Power BI, gerando dashboards inteligentes e insights acionáveis"
      ],
      "course_content": {
        "1. Ciência de dados e Machine Learning": [
          "Apresentação do Curso",
          "Introdução à Ciência de Dados",
          "Introdução ao Machine Learning",
          "Aula 4: Problemas e soluções em ML"
        ],
        "Renda Variável, Fundamentos e Análise Técnica": [
          "Introdução à Renda Variável e Ações",
          "Indicadores Fundamentais e Múltiplos",
          "Análise Técnica e Médias Móveis"
        ],
        "Instalação do Power BI": [
          "Instalação do Power BI",
          "Instalação do Conda e Ambiente Python",
          "Como e Onde Usar Scripts Python no Power BI",
          "Ferramentas para Desenvolver seus Scripts"
        ],
        "Projeto Aplicado: ETL, Modelos ML (XGBoost e Prophet) e Integração com BI": [
          "Revisão e Noções básicas de programação - linguagem python (iniciantes!!)",
          "ETL e Pré-processamento de Dados",
          "Machine Learning com XGBoost",
          "Séries Temporais com Prophet",
          "Visualização e Avaliação dos Resultados",
          "Compartilhamento do Projeto",
          "Compartilhamento do Projeto - II"
        ]
      },
      "requirements": [
        "Conhecimentos básicos sobre Análise de Dados, Python e modelagem preditiva são recomendáveis, mas não obrigatórios",
        "Não é necessário ter formação prévia em programação ou Ciência de Dados — o curso apresenta conceitos passo a passo",
        "Será necessário instalar ferramentas como Conda ou Miniconda, Jupyter Notebook , Google Colab e Power BI Desktop (orientações detalhadas são fornecidas no curso)",
        "Ter interesse em aprender Python aplicado à Análise de Dados, Machine Learning e visualização com Power BI de forma prática"
      ],
      "description": "Descrição Resumida do Curso\nEste é um curso completo e prático de Ciência de Dados e Machine Learning que ensina como aplicar Python e Power BI em um projeto real de Análise de Dados. Você vai aprender a construir modelos preditivos com XGBoost e Prophet, integrar scripts Python ao Power BI, realizar análise de dados financeiros e apresentar resultados visuais e preditivos com dashboards interativos.\nO que você vai aprender na prática:\nAplicar técnicas de Machine Learning como XGBoost e Prophet;\nIntegrar Python com Power BI para análises automatizadas;\nColetar, transformar e visualizar dados de diferentes fontes\nAnalisar dados financeiros, detectar padrões e prever tendências\nConstruir um projeto completo com validação e métricas reais (R², MAE, SMAE).\nConteúdo do Curso:\nFundamentos de Ciência de Dados e Machine Learning\nConceitos, métodos, algoritmos e aplicações com foco em finanças e negócios;\nIntrodução à Análise de Dados e à Renda Variável\nAprenda como funcionam ações, múltiplos (P/L, P/VPA, Dividend Yield), e análises de tendências;\nAmbiente de Trabalho para Python e Power BI\nInstalação e configuração do Conda, Jupyter Notebook, bibliotecas como Prophet e XGBoost, e integração com Power BI.\nProjeto Prático: Power BI + Python + Machine Learning\nCriação de um pipeline de dados real, desde a ingestão e transformação no Power BI, até a aplicação de modelos de Machine Learning no Python com avaliação e apresentação dos resultados.",
      "target_audience": [
        "Estudantes e profissionais interessados em Ciência de Dados e Machine Learning",
        "Analistas financeiros, economistas e econometristas que querem aprimorar suas habilidades em modelagem preditiva",
        "Investidores e analistas que atuam com renda variável e desejam aplicar análise preditiva",
        "Profissionais de análise de dados que buscam integrar modelos de previsão avançados com Power BI",
        "Qualquer pessoa que queira aprender a aplicar Python, Machine Learning e visualização de dados em projetos reais de análise financeira e estratégica"
      ]
    },
    {
      "title": "Pandas One - Análise de Dados com Pandas",
      "url": "https://www.udemy.com/course/pandas-one-analise-de-dados-com-pandas/",
      "bio": "Análise e tratamento de dados com a linguagem python e a biblioteca pandas",
      "objectives": [
        "Compreender assertivamente como realizar análise e tratamento de dados",
        "Realizar a criação de suas próprias bases de dados, ou acessá-las tanto na web como em bibliotecas do python",
        "Desenvolver uma sequência lógica de tratamentos de dados via funções, métodos e classes",
        "Criação de funções próprias para possibilitar a geração de insights pela equipe de trabalho"
      ],
      "course_content": {
        "Introdução": [
          "Introdução",
          "Nivelamento do Google Colab",
          "Links"
        ],
        "Tratamentos dos dados": [
          "Bases de dados - notebook 1",
          "EDA - Análise Exploratória de Dados - notebook 2",
          "Valores NaN - notebook 3",
          "Buscas e tratamentos numéricos - notebook 4",
          "Tratamento de textos"
        ],
        "Encerramento": [
          "Encerramento do curso",
          "Notebooks"
        ]
      },
      "requirements": [
        "Nenhuma experiência prévia com linguagem de programação será necessária para a realização do curso, uma vez que os notebooks já estão com os códigos comentados, bastando apenas que o aluno tenha um gmail para realizar as mesmas experiências propostas no curso"
      ],
      "description": "Este curso se destina a aperfeiçoar o tratamento e a análise de dados com a biblioteca pandas da linguagem python, hoje provavelmente o módulo mais importante e o mais utilizado na área de análise e ciência de dados. Durante o curso o aluno será exposto às melhores práticas de tratamentos de dados frente ao coditiano profissional de um analista de dados. Serão abordadas mais de 50 funções, métodos e classes em um curso totalmente atualizado com a versão mais recente da biblioteca, preparando o aluno para implementar as melhores soluções para os desafios dos dados na sua empresa.\nO curso foi estruturado pensando em diversos níveis de alunos, de completamente iniciantes aos já avançados na área. Portanto, não é necessária nenhuma experiência prévia em programação para completar o curso, já que os notebooks desenvolvidos estão com seus códigos comentados, ou seja, basta apenas que o aluno replique o código de cada notebook para sua compreensão e assertividade quanto ao curso.\nA progressão de conhecimento foi organizada de modo a fazer com o que o aluno consiga enxergar a sequência analítica dos tratamentos de dados, propondo com isso assertividade na sua rotina de trabalho e entrega de valor para sua empresa, além de gerar insights para sua equipe de trabalho e seu negócio. Ao final do curso, a título de nivelamento de conhecimento, o aluno poderá se considerar um profissional de júnior a pleno na área de análise de dados, visto a quantidade de funções, métodos e classes utilizadas nos tratamentos dos dados.",
      "target_audience": [
        "Iniciantes em linguagem de programação e na área de dados, profissionais que desejam migrar para a área de análise de dados, e profissionais que já tenham experiência com análise de dados mas que ainda não dominam a ferramenta pandas em suas análises de dados"
      ]
    },
    {
      "title": "Inteligencia Artificial Generativa en Snowflake",
      "url": "https://www.udemy.com/course/inteligencia-artificial-generativa-en-snowflake/",
      "bio": "IA Generativa en Snowflake: Cortex Functions, Analyst, Search y Document AI - Curso completo y práctico.",
      "objectives": [
        "Dominar las funciones SQL de Cortex AI para completar, clasificar, extraer y analizar datos usando inteligencia artificial directamente en Snowflake.",
        "Crear modelos semánticos y implementar Cortex Analyst para generar análisis automatizados y responder preguntas de negocio en lenguaje natural.",
        "Desarrollar servicios de búsqueda inteligente con Cortex Search y construir aplicaciones de chat interactivas para consultar documentos y datos.",
        "Implementar pipelines de Document AI para procesar documentos automáticamente y aplicar técnicas de observabilidad para monitorear modelos de IA."
      ],
      "course_content": {
        "Introducción al curso": [
          "Introducción a Snowflake IA",
          "Crear una cuenta de prueba de Snowflake",
          "Repositorio de GitHub del curso"
        ],
        "Funciones de Cortex AISQL": [
          "Funciones SQL de Cortex AISQL",
          "Privilegios requeridos para usar las funciones de Cortex AISQL",
          "Controlar el acceso a los modelos",
          "Función AI_COMPLETE",
          "Función AI_COMPLETE multimodal",
          "Función AI_COMPLETE con Python",
          "Función AI_CLASSIFY",
          "Función AI_CLASSIFY con Python",
          "Función EXTRACT_ANSWER",
          "Función PARSE_DOCUMENT",
          "Funciones ENTITY_SENTIMENT y SENTIMENT",
          "Funciones SUMMARIZE y TRANSLATE",
          "Función AI_FILTER",
          "Función AI_AGG y AI_SUMMARIZE_AGG",
          "Función AI_SIMILARITY",
          "Funciones auxiliares",
          "Cortex LLM Playground",
          "Verifica tus conocimientos",
          "Ejercicios",
          "Resolución de los ejercicios"
        ],
        "Cortex Analyst": [
          "Características principales de Cortex Analyst",
          "Modelo semántico",
          "Ingesta de datos",
          "Crear un modelo semántico",
          "Consejos para crear un modelo semántico",
          "Streamlit + Cortex Analyst en Snowflake",
          "Streamlit + Cortex Analyst en local",
          "Monitoreo",
          "Verifica tus conocimientos"
        ],
        "Cortex Search": [
          "Introducción a Cortex Search",
          "Crear un servicio Cortex Search mediante SQL",
          "Crear un servicio Cortex Search mediante Snowsight",
          "Consultar un servicio Cortex Search",
          "Construir una aplicación simple de chat con Cortex Search",
          "Construir un chatbot de PDFs con Cortex Search",
          "Verifica tus conocimientos"
        ],
        "Document AI": [
          "Introducción a Document AI",
          "Preparar los documentos para Document AI",
          "Pipeline de procesamiento de documentos con Document AI parte 1",
          "Pipeline de procesamiento de documentos con Document AI parte 2",
          "Verifica tus conocimientos"
        ],
        "Observabilidad": [
          "Observabilidad en Snowflake Cortex",
          "Conceptos clave",
          "Ejemplo práctico",
          "Verifica tus conocimientos"
        ]
      },
      "requirements": [
        "Este curso está diseñado para ser accesible a todos los niveles. No necesitas ser un experto para comenzar. Aquí te indicamos lo que sería útil, pero no indispensable.",
        "SQL básico: Familiaridad con consultas SELECT, WHERE y JOIN. Si nunca has usado SQL, ¡no te preocupes! El curso incluye explicaciones paso a paso.",
        "Conceptos básicos de bases de datos: Entender qué son tablas, columnas y relaciones te ayudará, pero aprenderás sobre la marcha.",
        "Python básico: Aunque es útil, proporcionamos todos los scripts necesarios y explicamos cómo ejecutarlos. No necesitas ser programador.",
        "Recomendamos un editor de código como Visual Studio Code (gratuito) o cualquier IDE que prefieras."
      ],
      "description": "¿Quieres llevar tus habilidades de análisis de datos al siguiente nivel integrando inteligencia artificial directamente en Snowflake? Este curso completo te enseñará a dominar Snowflake IA, la suite de herramientas de IA más poderosa para profesionales de datos.\n¿Qué aprenderás?\nComenzarás dominando las Funciones SQL de Cortex AI, incluyendo AI_COMPLETE para generar texto, AI_CLASSIFY para categorizar datos, EXTRACT_ANSWER para extraer información específica, y funciones de análisis de sentimientos. Aprenderás a implementar estas funciones tanto en SQL como en Python, con ejemplos prácticos que podrás aplicar inmediatamente.\nDescubrirás Cortex Analyst, la herramienta que revoluciona el análisis de datos permitiendo consultas en lenguaje natural. Crearás modelos semánticos robustos y desarrollarás aplicaciones que responden preguntas de negocio automáticamente, eliminando la barrera técnica entre los datos y los usuarios finales.\nConstruirás servicios de Cortex Search para crear sistemas de búsqueda inteligente y chatbots interactivos que consultan documentos y bases de datos. Desarrollarás aplicaciones completas de chat que transforman la manera en que tu organización accede a la información.\nImplementarás Document AI para automatizar el procesamiento de documentos, desde facturas hasta contratos, extrayendo información estructurada sin intervención manual.\nFinalmente, aplicarás técnicas de observabilidad para monitorear y optimizar el rendimiento de tus modelos de IA en producción.\n¿Por qué este curso es diferente?\nEste no es un curso teórico. Cada lección incluye ejercicios prácticos y casos de uso adaptables a tus necesidades. Aprenderás creando aplicaciones funcionales que podrás implementar en tu trabajo inmediatamente.\nComenzaremos desde cero creando tu cuenta gratuita de Snowflake, por lo que no necesitas experiencia previa con la plataforma. El curso está diseñado para ser progresivo: cada sección construye sobre la anterior, garantizando que domines completamente cada herramienta antes de avanzar.\n¿Qué incluye el curso?\nLecciones estructuradas con videos demostrativos donde verás la implementación en tiempo real de cada funcionalidad\nNotebooks de Jupyter con todos los códigos y ejemplos\nEjercicios prácticos con sus soluciones detalladas\nProyectos reales: chatbots, sistemas de búsqueda, análisis automatizado\nAcceso al repositorio de GitHub con todos los Notebooks\nVerificaciones de conocimiento en cada sección\nTu futuro profesional\nAl completar este curso, serás capaz de implementar soluciones de IA que automatizan tareas repetitivas, crean experiencias de usuario inteligentes y generan insights valiosos para tu organización. Estas habilidades están en alta demanda y te posicionarán como un profesional de datos de vanguardia.\nLa inteligencia artificial ya no es el futuro, es el presente. ¡Únete ahora y transforma tu carrera con las herramientas más avanzadas de Snowflake!",
      "target_audience": [
        "Analistas de datos y BI que buscan automatizar análisis, clasificaciones y resúmenes usando IA sin depender de equipos técnicos especializados.",
        "Desarrolladores e ingenieros de datos interesados en integrar capacidades de inteligencia artificial directamente en Snowflake sin APIs externas complicadas.",
        "Profesionales de negocio que trabajan con datos y quieren crear chatbots internos, búsquedas inteligentes y análisis automatizados para su organización.",
        "Estudiantes de tecnología o ciencia de datos que buscan experiencia práctica con herramientas empresariales de IA y quieren destacar en el mercado laboral.",
        "Consultores y freelancers que desean expandir su portafolio de servicios agregando soluciones de IA usando una plataforma robusta y escalable."
      ]
    },
    {
      "title": "所有人都能玩转的ChatGPT",
      "url": "https://www.udemy.com/course/chatgpt-m/",
      "bio": "解锁ChatGPT的十八般武艺",
      "objectives": [
        "众人热议的ChatGPT是什么",
        "普通人的职场/生活能否吃上ChatGPT的红利",
        "解锁ChatGPT的十八般武艺",
        "ChatGPT的基本原理、应用场景和实用技巧"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "告别搜索，与ChatGPT聊天就能获得答案",
          "让ChatGPT救赎你憋不出的文案",
          "叮！你的专属阅读助手已上线",
          "全能老师来了，除了算数都能教",
          "秒变“诗圣”，从古文研读到诗词创作",
          "综合实践，解锁智慧生活"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "会运用gpt的人员"
      ],
      "description": "在AI智能化时代，职场需求日新月异，掌握新兴技术成为职场人士不可或缺的必备技能。为此，三节课与Aether、百姓AI携手共同打造相关课程，特别推出《所有人都能玩转的ChatGPT》课程，帮助大家轻松驾驭ChatGPT，提升职场竞争力。 本课程以通俗易懂的方式讲解ChatGPT的基本原理、应用场景和实用技巧。涵盖了ChatGPT与大数据、人工智能等领域的结合，拓展大家的视野。将助您轻松应对大数据时代的职场挑战，实现职业生涯的华丽转身。赶快加入我们，开启您的ChatGPT之旅吧！",
      "target_audience": [
        "对用AI聊天技术应用感兴趣，向往AI智能生活的普通人 想要提高工作效率的职场人、创业者 0基础，非技术圈从业人群"
      ]
    },
    {
      "title": "巧用ChatGPT，Offer拿到手软",
      "url": "https://www.udemy.com/course/chatgptoffer/",
      "bio": "AI求职助手全程陪伴",
      "objectives": [
        "提高求职成功率",
        "职业生涯规划",
        "突破求职盲区",
        "提升面试技巧"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "简历做的好，求职没烦恼",
          "人工智能更懂你",
          "分析行业岗位，打通匹配缺口",
          "准备更充分，面试更自信",
          "模拟面试官，严厉又刁钻",
          "是人工智能也是职业规划导师"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "有ai使用基础"
      ],
      "description": "在大数据时代，职场需求瞬息万变，技术更新日新月异。为了帮助你在这竞争激烈的环境中脱颖而出，三节课与张墨菡老师、百姓AI携手共同带来本门课程。 通过课程的学习，让你轻松掌握人工智能时代的职场利器——ChatGPT，让你的简历在众多求职者中一眼被发现，轻松斩获心仪的offer。本课程将带你深入了解ChatGPT的原理和应用，通过实操掌握其使用技巧。提升你在求职中的应用技巧，如何撰写简历、面试技巧等； 使用ChatGPT进行求职信息搜集与分析，让你轻松掌握求职市场动态，将求职过程变得简单而高效。",
      "target_audience": [
        "专为职场人打造 了解AI在求职中的应用场景 掌握如何使用AI工具进行简历优化和职位匹配"
      ]
    },
    {
      "title": "AIGC在游戏⽣态中的应⽤探究：如何提升效率与创意",
      "url": "https://www.udemy.com/course/aigc-ckc/",
      "bio": "深度探索AIGC技术如何重塑游戏开发流程",
      "objectives": [
        "掌握AIGC的基本原理和在游戏开发中的应用场景。",
        "学习如何运用AIGC技术提升游戏开发的效率与创意。",
        "了解AIGC技术对游戏生态的影响和未来发展趋势。",
        "通过实际案例分析，掌握AIGC技术的最佳实践和应用技巧。",
        "建立与行业专家Joyce讲师的连接，拓展人脉和交流机会。"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "第一章 AIGC、OpenAI和ChatGPT是什么",
          "第二章 AIGC在游戏、电商、直播、社交行业的应用",
          "第三章 AIGC对互联网生态的改进",
          "第四章 AIGC的发展和前景"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "无需经验"
      ],
      "description": "在游戏开发过程中，效率和创意是两个核心要素。然而，很多团队在追求效率与创意之间常常面临诸多挑战。\n为此，三节课邀请了拥有丰富经验的Joyce讲师，带来了这门课程。在这门课程中，Joyce讲师将结合实际案例，深入讲解如何运用AIGC技术提升游戏开发的效率和创意。\n通过本课程的学习，学员将掌握如何利用AIGC技术优化游戏开发的全流程、了解AIGC的基本原理、应用场景和最佳实践，提升游戏的质量和用户体验，从而在竞争激烈的游戏市场中脱颖而出。",
      "target_audience": [
        "游戏开发者，掌握AIGC技术，提升游戏开发效率与创意。",
        "游戏策划师，了解AIGC应用场景，优化游戏设计。",
        "游戏美术师，运用AIGC技术，提升游戏视觉效果。",
        "游戏运营与推广人员，利用AIGC技术，提高游戏用户留存率。",
        "对游戏行业和AIGC技术感兴趣的所有人员，了解游戏行业发展趋势，拓展个人技能。"
      ]
    },
    {
      "title": "Stable Diffusion 实战课",
      "url": "https://www.udemy.com/course/stable-diffusion-z/",
      "bio": "从理论到应用探索生成艺术前沿",
      "objectives": [
        "更深入理解 Stable Diffusion，获得更多基于原理的使用技巧",
        "实现短时高效完成图片的生成与编辑，提升工作效率",
        "体验大模型的创造力，开启创意工作与数字艺术",
        "轻松跨界，用 Stable Diffusion 解决具体行业难题"
      ],
      "course_content": {
        "课程导入": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "Stable Diffusion 基础原理": [
          "01 课程简介及生成式 AI 常见应用",
          "02 扩散模型原理",
          "04 Stable Diffusion 详解"
        ],
        "Stable Diffusion 微调原理": [
          "01 导学：为什么需要微调?",
          "02 SD 常用微调方法：LoRA、DreamBooth",
          "03 SD 常用微调方法：Textural Inversion",
          "04 可控生成 ControINet"
        ],
        "Stable Diffusion 编辑原理": [
          "01 基于 SD Attention 机制的图片编辑",
          "02 真实图片的反推与编辑",
          "03 SD 的扩展应用：3D 生成与编辑",
          "04 SD 的扩展应用：视频生成（Sora 原理讲解）"
        ],
        "Stable Diffusion webui 基本使用": [
          "01 课程介绍",
          "02 Stable Diffusion webui 安装与配置",
          "03 第三方模型获取与使用",
          "04 webui 基本页面介绍与功能说明",
          "05 获取第三方 Checkpoint 和 LoRA",
          "06 图生图体验",
          "07 如何安装第三方插件",
          "08 如何使用 ControlNet 插件",
          "09 如何使用 roop 换脸插件"
        ],
        "ComfyUI 的基本使用与工作流使用教程": [
          "01 课程介绍",
          "02 ComfyUI 的安装与配置",
          "03 ComfyUI 基本操作与工作流",
          "04 ComfyUI 管理器",
          "05 安装 InstantID 节点"
        ],
        "训练 LoRA 模型与应用实践": [
          "01 课程介绍：LoRA 的原理与优势介绍",
          "02 使用 lora-scripts 训练 LoRA（1）",
          "03 使用 lora-scripts 训练 LoRA（2）",
          "04 使用训练好的 LoRA 生成图片"
        ],
        "制作个性化 \"妙鸭相机\"": [
          "01 课程介绍",
          "02 训练个人数据 LoRA 并实践生成数字写真",
          "03 使用换脸插件实现风格化数字写真"
        ],
        "课程回顾": [
          "回顾总结"
        ]
      },
      "requirements": [
        "无需经验"
      ],
      "description": "本门课程由机器之心和 Datawhale 开源学习组织共同打造，内容设计由浅及深，理论与实践相结合，带你逐步理解并最终熟练使用 Stable Diffusion 进行图片的生成和编辑，甚至根据具体场景需要训练微调 Stable Diffusion。\n\n\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。\n课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利\n人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课\n公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位\n提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，\n您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "对大模型及文生图、图生图感兴趣的非技术从业者",
        "想要系统学习文生图技术与实践的学习者",
        "想要低代码打造个性化图片生成模型的开发者",
        "想要通过 Stable Diffusion 入门大模型技术和应用的爱好者"
      ]
    },
    {
      "title": "邏輯思考應用：3.程式應用與實務",
      "url": "https://www.udemy.com/course/3-kwuhav/",
      "bio": "無",
      "objectives": [
        "Open data取得/靜態與動態網頁資料擷取方式",
        "Python串列/數組",
        "Python集合/字典",
        "urllib&requests模組",
        "Python csv檔案輸出入",
        "Python json檔案輸出入"
      ],
      "course_content": {
        "第一單元 Open data": [
          "1-1為何要開放?",
          "1-2政府開放資料平台",
          "1-3什麼是延伸應用?",
          "1-4 常見開放資料格式",
          "1-5抓取開放資料方式",
          "1-6 靜態網頁擷取",
          "1-7 靜態網頁擷取範例1-抓取臺灣銀行匯率資料",
          "1-8 靜態網頁擷取範例2-查詢證券辨識號碼一覽表",
          "1-9 動態網頁擷取",
          "第一單元 Open data"
        ],
        "第二單元 Python容器一(資料型態)": [
          "2-1 容器是什麼?",
          "2-2 資料型態─串列(上)",
          "2-3 資料型態─串列(下)",
          "2-4 串列案例演練(一)",
          "2-5 串列案例演練(二)",
          "2-6 串列案例演練(三)",
          "2-7 資料型態─數組",
          "2-8 數組型態案例演練",
          "第二單元 Python容器一(資料型態)"
        ],
        "第三單元 Python容器二(資料型態)": [
          "3-1 資料型態─集合(上)",
          "3-2 資料型態─集合(下)",
          "3-3 集合型態案例演練",
          "3-4 資料型態─字典(上)",
          "3-5 資料型態─字典(下)",
          "3-6 字典型態案例演練",
          "第三單元 Python容器二(資料型態)"
        ],
        "第四單元 運用Urllib、Requests": [
          "4-1 Urllib套件和常用的方法",
          "4-2 Urllib抓台北市交通即時資訊網頁",
          "4-3 Urllib靜態爬蟲",
          "4-4 用Urllib抓統一發票開獎號碼",
          "4-5 Requests套件和常用的方法",
          "4-6 Requests靜態爬蟲",
          "4-7 用Requests抓取環保署AQI資料",
          "4-8 BeautifulSoup靜態爬蟲",
          "4-9 利用BeautifulSoup抓取新北市房仲公會會員名冊",
          "第四單元 運用Urllib、Requests"
        ],
        "第五單元 CSV檔案讀取與寫入": [
          "5-1 CSV套件常用方法",
          "5-2 CSV讀取讀取新北市公共自行車即時資訊",
          "5-3 CSV讀取全國環境輻射偵測即時資訊",
          "5-4 CSV寫入",
          "5-5 新北市公共自行車即時資訊寫入CSV",
          "5-6 網路抓取農產品交易行情寫入",
          "5-7 文化部展覽資訊寫入",
          "第五單元 CSV檔案讀取與寫入"
        ],
        "第六單元 JSON檔案讀取與寫入": [
          "6-1 JSON開放資料格式",
          "6-2 JSON套件常用方法",
          "6-3 JSON讀取",
          "6-4 讀取台北市公共自行車即時資訊",
          "6-5 上網路抓取紫外線即時監測資料",
          "6-6 JSON寫入",
          "6-7 寫入人員資料到JSON",
          "6-8 XML讀取與寫入",
          "第六單元 JSON檔案讀取與寫入"
        ]
      },
      "requirements": [
        "有基本python基礎"
      ],
      "description": "這門課程介紹Python程式的進階語法與應用，讓學生可以利用Python來實作取得Open data、進行網頁資料擷取、運用Python各種容器型態、\n常用的csv/json等檔案格式的轉換。\n主要教授內容為Python進階程式設計與應用。\n【結業標準】閱讀線上影音教材及參加課程測驗，全部完成者可取得完課證明。",
      "target_audience": [
        "對資料科學感興趣的初級python開發人員",
        "有興趣學寫程式",
        "想多學一種程式語言的人"
      ]
    },
    {
      "title": "Data science & IA : le volet data analyst",
      "url": "https://www.udemy.com/course/data-science-ia-le-volet-data-analyst/",
      "bio": "Analyse de données",
      "objectives": [
        "Les bases de la data : types de données, structures tabulaires, distributions",
        "Utilisation professionnelle de Pandas : séries, dataframes, jointures, groupements",
        "Traitement et nettoyage des données : suppression, imputation, normalisation",
        "Analyse statistique descriptive",
        "Analyse statistique inférentiel",
        "Visualisations interactives et professionnelles",
        "Études de cas concrets et interprétation des résultats",
        "Création de visualisations dynamiques : histogrammes, boîtes à moustaches, courbes"
      ],
      "course_content": {},
      "requirements": [
        "Avoir les base en programmation python",
        "Maitriser la data engineering"
      ],
      "description": "Plongez dans le monde fascinant de l’analyse de données et développez des compétences recherchées par les entreprises actuelles. Que vous soyez débutant, étudiant, développeur, ou professionnel souhaitant élargir vos compétences, ce cours vous guidera pas à pas à travers les fondements de l’analyse de données jusqu’à la réalisation de projets concrets en Python.\nGrâce à des explications claires, des exemples concrets, et des exercices pratiques, vous apprendrez à extraire les informations pertinentes, analyser et visualiser des données comme un analyste professionnel.\n\n\nÀ la fin de ce cours, vous serez capable de :\nComprendre les concepts fondamentaux de l’analyse de données;\nManipuler efficacement des jeux de données avec Python, Pandas et NumPy;\nNettoyer et préparer les données pour l’analyse (gestion des valeurs manquantes, filtrage, transformation);\nEffectuer des analyses statistiques descriptives;\nCréer des visualisations percutantes avec Matplotlib et Seaborn;\nInterpréter des résultats pour en extraire des insights pertinents;\nRéaliser un mini-projet d’analyse de données de bout en bout;\nPoser les bases pour aller plus loin vers la data science, le machine learning ou la business intelligence;\nManier l'insertitude de la données;\n\n\n\n\n\n\nCe que vous allez apprendre :\nRôles, missions, compétences, place et champ d'action d'un data analyste;\nUtilisation professionnelle de Pandas : séries, dataframes, jointures, groupements;\nTraitement et nettoyage des données : suppression, imputation, normalisation;\nAnalyse statistique de base : moyennes, médianes, corrélations, agrégats;\nCréation de visualisations dynamiques : histogrammes, boîtes à moustaches, courbes, heatmaps;\nÉtudes de cas concrets et interprétation des résultats;\nBonnes pratiques de l’analyse exploratoire (EDA);\nProjet final : analyse d’un jeu de données réel, de la collecte à l’interprétation.",
      "target_audience": [
        "Débutant(e)s en data science ou analyse de données",
        "Développeur(eu)s Python souhaitant se spécialiser",
        "Entrepreneurs et professionnels désirant exploiter leurs données",
        "Toute personne curieuse d'explorer les données et de prendre des décisions."
      ]
    },
    {
      "title": "深度喚醒：DeepSeek的高效提示詞技巧與實戰應用",
      "url": "https://www.udemy.com/course/deepseek-r/",
      "bio": "掌握DeepSeek提示詞優化技巧，提升AI內容生成效率與品質",
      "objectives": [
        "掌握DeepSeek提示詞優化的核心技巧，提高AI生成內容的質量與效率。",
        "學會應用4C法則、角色設定法等提示詞設計技巧，解決工作中常見的AI生成問題。",
        "學會應用4C法則、角色設定法等提示詞設計技巧，解決工作中常見的AI生成問題。",
        "通過實戰案例，快速掌握AI創意生成、數據報告等自動化生成技巧，提升工作生產力。"
      ],
      "course_content": {
        "介紹": [
          "DeepSeek是什麼？",
          "DeepSeek是什麼？",
          "高效提示詞設計技巧-提示詞設計的4C法則",
          "提示詞優化技巧與實操演練-角色設定法",
          "CoT思維鏈法",
          "Few-Shot Learning（少樣本學習）",
          "限制條件法",
          "職場效率提升案例1：郵件撰寫",
          "職場效率提升案例2：會議紀要自動生成",
          "職場效率提升案例3：PPT大綱快速生成",
          "產品與用戶研究案例1：用戶畫像分析",
          "產品與用戶研究案例2：競品分析報告生成",
          "產品與用戶研究案例3：AB測試文案優化",
          "數據分析與技術開發案例1：自動代碼生成",
          "數據分析與技術開發案例2：數據可視化報告",
          "數據分析與技術開發案例3：API文檔生成",
          "AI創意生成案例1：小說續寫",
          "AI創意生成案例2：廣告腳本創作",
          "AI創意生成案例3：社交媒體內容規劃",
          "流程圖等專業畫圖能力案例1：業務流程圖快速生成",
          "流程圖等專業畫圖能力案例2：IT系統架構圖設計",
          "流程圖等專業畫圖能力案例3：產品需求分析思維導圖生成"
        ]
      },
      "requirements": [
        "1. 具備基本的AI或機器學習知識，了解AI運作的基本概念。",
        "2. 熟悉日常工作中的文檔撰寫、數據分析或創意生成等需求。",
        "3. 具備基本的電腦操作技能，能夠使用AI工具和平台進行操作。",
        "若沒有相關經驗，課程內容設計將有助於您逐步學習和掌握提示詞優化技巧。"
      ],
      "description": "在這門課程中，您將學習如何利用DeepSeek平台的高效提示詞設計技巧，優化AI生成內容的質量與效率。課程內容涵蓋了從基礎概念到實際應用的全方位知識，幫助學員在不同的工作場景中快速提升生產力。您將深入了解為何提示詞如此關鍵，以及如何根據具體需求進行有效的提示詞設計。\n\n\n課程的核心部分包括學習多種提示詞設計方法，如4C法則、角色設定法、CoT思維鏈法、少樣本學習等，這些方法能幫助您在AI生成內容的過程中達到更高的準確度與效率。學員將通過多個實戰案例，學會如何將這些技術應用於日常工作中，包括電子郵件撰寫、產品分析報告生成、數據可視化等，讓AI工具真正成為您工作中的得力助手。\n\n\n不論您是職場人士、產品經理、數據分析師，還是AI開發者，這門課程都將幫助您提升AI應用的能力，解決實際工作中的問題，提高決策效率，讓您的工作更加高效、智能。加入我們，學會如何利用AI技術提升您的創造力與生產力，實現工作突破！",
      "target_audience": [
        "1. 職場人士，希望提升工作效率並學會使用AI工具優化日常任務。",
        "2. 產品經理和數據分析師，尋求提升AI應用能力以加速產品開發和市場分析。",
        "3. 內容創作者，想要運用AI提升文案創作和社交媒體內容生成的效率。",
        "4. AI開發者，希望深入了解提示詞優化技術並應用於各種實際場景。"
      ]
    },
    {
      "title": "Excel - Fórmulas & Macros & VBA & Power BI",
      "url": "https://www.udemy.com/course/excel-formulas-o/",
      "bio": "Apreendo utilizar Fórmulas no Excel.",
      "objectives": [
        "Fórmulas básicas e avançadas."
      ],
      "course_content": {
        "Introdução": [
          "1-Introdução ao Microsoft excel",
          "2-Introdução Microsoft excel- salvar arquivo",
          "3-Introdução aos conceitos de Fórmulas excel",
          "4-Trabalhando com Formulas aritimetricas excel",
          "5-Função-SE 2 Condições excel",
          "6-Função-SE 3 Condições excel",
          "7-Função cont.se 1 condição excel",
          "8-Função cont.ses 2 condição excel",
          "9-Função procv excel",
          "10-Função proch excel",
          "11-Função proc excel",
          "12-Função =hoje 1,2,3 condições",
          "13-Função concatenar unir dois textos excel",
          "14-Função concatenar três textos excel",
          "15-Função Agora e Função Combin excel",
          "16-Função MED,MAX,MIN, DIA UTEIS TRABALHO excel",
          "17-Função E Vinculada a Função SE excel",
          "18-Função ou Vinculada a Função SE excel",
          "19-Função ou isolada excel",
          "20-Função somar produtos excel",
          "21-Função somase excel",
          "22-Função DATAM excel",
          "23-Função SE ERRO excel",
          "24-Função aleatório e aleatório entre excel",
          "25-Função Arrumar texto excel",
          "26-Função dia trabalho total excel",
          "27-Função Subistituir l 1 condição excel",
          "28-Função Subistituir infinitas condições excel",
          "29-Função mudar texto excel",
          "30-Função Extrair texto excel",
          "30-Função taxa A.M -A.A E VF excel",
          "31-Função PGTO A.M -A.A E VF excel",
          "32-Função NPER A.M -A.A E VF excel",
          "33-Função VP -Quitação empréstimos excel",
          "34-Função VP -Resgate de aplicação excel",
          "35-Função Cont valores 1 e 2 condição excel",
          "36-Funçao Cont Valores 1 e 2 Condição excel",
          "37-Função DATADIF dia, mes, ano excel",
          "38- Colocando Filtro tabela excel",
          "39-Criando tabela e graficos - Parte 1",
          "40-Criando tabelas e formatando graficos parte 2",
          "41-Criando tabelas e formatando graficos parte 3",
          "42-Validação de dados, impedindo erros excel",
          "43- Colocando senhas na planilha excel",
          "44 -Usando hiperlink na planilha",
          "45- Trabalhando com Macros",
          "46 -Criando Tabela Dinamica Excel",
          "47 - Criando os Filtros da Tabela Dinamica",
          "48 - Criando Macro de impressão",
          "49 - Formatação condicional avançada - Parte 1",
          "50 - Formatação condicional avançada - Parte 2",
          "51 -Formulário Macros - Parte 1",
          "52- Formulário Macros - Parte 2",
          "53 - Formulário Macros e VBA - Parte 3",
          "54 -Formulário Macros VBA -Parte 4",
          "55 - Formulario VBA - Fórmulas - Parte 5",
          "56 - Formulario Macro VBA - Graficos - Parte 6"
        ],
        "VBA - Excel": [
          "1- O QUE É VBA EXCEL 2019",
          "1.1 - CONHECENDO CONTROLES DE FORMULARIOS VBA Excel 2019",
          "2 - CRIANDO SEU PRIMEIRO CÓDIGO VBA - DATA VIA BOTÃO Excel 2019",
          "3 - LIMPAR CELULA VBA Excel 2019",
          "4 - SELECIONANDO CÉLULAS VBA Excel 2019",
          "5 - MULTIPLICANDO CÉLULAS VBA Excel 2019",
          "6 -COPIAR E COLAR CELULAS VBA Excel 2019",
          "6.1 - SELECIONANDO CELULAR VIA VBA Excel 2019",
          "6.2 -SELECIONADO REGIÃO A PARTIR DE UMA CELULAR VBA - Excel 2019",
          "6.3 - ENCONTRANDO A CELULA ATIVA VIA VBA - Excel 2019",
          "6.4 - SELECIONANDO GRANDE INTERVALOS E COLANDO VALORES RELATIVOS VBA - Excel 201",
          "6.5 - FORMATANDO SELEÇAO COLOR VBA - Excel 2019",
          "6.6 - OCULTANDO LINHAS VBA - Excel 2019",
          "6.7 -CALCULO AUTOMATICO VIA VBA - Excel 2019",
          "6.8 - CALCULO AUTOMATICO VIA VBA - Excel 2019",
          "7 - COPIANDO PLANILHA INTEIRA PARA OUTRA VBA Excel 2019",
          "8 - DESCONTRAINDO UM POUCO VBA Excel 2019",
          "9 - CRIANDO ALERTA DE EDIÇÃO VBA - Excel 2019"
        ],
        "Mini Curso de Power BI Iniciantes": [
          "1 - Baixando o Power BI Desktop",
          "2-Conhecendo o Ambiente do Power BI",
          "3 - Criando os Cartões no Power BI",
          "4 - Formatando cartões no Power BI",
          "5 - Aplicando gráfico Scroller no Power BI",
          "6 -Criação de Filtros e Segmentação de dados",
          "7 - Criando Gráfico de Pizza",
          "8 - Criando gráficos de Rosca",
          "9 - Criando matriz de layout de dados",
          "10 - criando gráfico de barras",
          "11 - Publicando e extraindo os relatórios"
        ]
      },
      "requirements": [
        "Usuário de computador e plataforma Excel"
      ],
      "description": "1-Introdução ao Microsoft Excel\n\n\n2-Introdução Microsoft Excel- salvar arquivo\n\n\n3-Introdução aos conceitos de Fórmulas Excel\n\n\n4-Trabalhando com Formulas aritméticas Excel\n\n\n5-Função-SE 2 Condições Excel\n\n\n6-Função-SE 3 Condições Excel\n\n\n9-Função procv Excel\n\n\n10-Função proch Excel\n\n\n11-Função proc Excel\n\n\n12-Função =hoje 1,2,3 condições\n\n\n13-Função concatenar unir dois textos Excel\n\n\n14-Função concatenar três textos Excel\n\n\n15-Função Agora e Função Combin Excel\n\n\n16-Função MED,MAX,MIN, DIA UTEIS TRABALHO Excel\n\n\n17-Função E Vinculada a Função SE Excel\n\n\n18-Função ou Vinculada a Função SE Excel\n\n\n19-Função ou isolada Excel\n\n\n20-Função somar produtos Excel\n\n\n21-Função soma-se Excel\n\n\n22-Função DATAM Excel\n\n\n23-Função SE ERRO Excel\n\n\n24-Função aleatório e aleatório entre Excel\n\n\n25-Função Arrumar texto Excel\n\n\n26-Função dia trabalho total Excel\n\n\n27-Função Substituir l 1 condição Excel\n\n\n28-Função Substituir infinitas condições Excel\n\n\n29-Função mudar texto Excel\n\n\n30-Função Extrair texto Excel\n\n\n30-Função taxa A.M -A.A E VF Excel\n\n\n31-Função PGTO A.M -A.A E VF Excel\n\n\n32-Função NPER A.M -A.A E VF Excel\n\n\n33-Função VP -Quitação empréstimos Excel\n\n\n34-Função VP -Resgate de aplicação Excel\n\n\n35-Função Cont valores 1 e 2 condição Excel\n\n\n36-Funçao Cont Valores 1 e 2 Condição Excel\n\n\n37-Função DATADIF dia, mês, ano Excel\n\n\n38- Colocando Filtro tabela Excel\n\n\n39-Criando tabela e gráficos - Parte 1\n\n\n40-Criando tabelas e formatando gráficos parte 2\n\n\n41-Criando tabelas e formatando gráficos parte 3\n\n\n42-Validação de dados, impedindo erros Excel\n\n\n43- Colocando senhas na planilha Excel\n\n\nAula 144:1-FUNÇÃO ÍNDICE + CORRESP - Excel 2019\nAula 145:2-FUNÇÃO ÍNDICE + CORRESP, ESQUERDA - Excel 2019\nAula 146:3 - FUNÇÃO INDICE + CORRESP BIDIRECIONAL Excel 2019\nAula 147:4 - FUNÇÃ SOMA + INDICE + CORRESP Excel 2019\nAula 148:5 - FUNÇÃO INDICE +CORRESP+MIN+ABS Excel 2019\nAula 149:6 - FUNÇÃO SE + E - Excel 2019\nAula 150:7 - FUNÇÃO SOMA + DESLOCAMENTO - Excel 2019\nAula 152:9 - FUNÇÃO SE + OU - Excel 2019\nAula 153:10 - FUNÇÃO SOMASE AVANÇADA - Excel 2019\nAula 154:11 - FUNÇÃO SOMA+DESLOCAMENTO AVANÇADOS - Excel 2019\nAula 155:12 - FUNÇÃO SOMA+DESLOCAMENTO AVANÇADOS - Excel 2019\nAula 156:13 - FUNÇÃO SE + MÉDIA + SOMA - Excel 2019\nAula 157:14 - FUNÇÃO SE + E + OU - Excel 2019\nAula 158:15 - FUNÇÃO MÉDIA + SE + ÉNUM+CORRESP - Excel 2019\nAula 159:16 - FUNÇÃO SE + ÉTEXTO - Excel 2019\nAula 160:17 - FUNÇÃO SE + SE + ÉTEXTO - Excel 2019\nAula 161:18 - FUNÇÃO SOMAPRODUTO + ÉTEXTO - Excel 2019\nAula 162:19 -FUNÇÃO SE +SOMAPRODUTO+ÉTEXTO - Excel 2019\nAula 163:20 - FUNÇÃO SE + ÉNUMERO+PROCURAR - Excel 2019\nAula 164:21 - FUNÇÃO ÉNÚM + VALIDAÇÃO DADOS - Excel 2019\nAula 165:22 - FUNÇÃO SEERRO +PROCV+PROCV - Excel 2019\nAula 166:23 -FUNÇÃO SEERRO 3X +PROCV 3X - Excel 2019\nAula 167:24 - FUNÇÃO SE + PROCV - Excel 2019\nAula 168:25 - FUNÇAO SE + PROCV +CELULA REFERENCIA - Excel 2019\nAula 169:26 - FUNÇÃO SE +ÉNAODISP +PROCV - Excel 2019\nAula 170:27 - FUNÇÃO SE +PROCV +PROCV +PROCV - Excel 2019\nAula 171:28 - FUNÇÃO SE + ÉNÃO DISP +PROCV = Excel 2019\nAula 172:29 -FUNÇÃO MÁX + PROCV - Excel 2019\nAula 173:30 - FUNÇÃO PROCV + SOMA + % - Excel 2019",
      "target_audience": [
        "Desenhistas, estudantes, todos que utilizam Excel baseado em fórmulas."
      ]
    },
    {
      "title": "AI 第一课：揭秘人工智能背后的工作原理",
      "url": "https://www.udemy.com/course/ai-wnhvq/",
      "bio": "本课程采用通俗易懂的讲解方式，深入剖析AIGC大模型的原理和应用，从基础知识开始，让你了解大模型的基本结构和算法原理、图像识别和语言识别模型原理、数据预测和应用分析等应用方法。其中还将分享一些最前沿的AIGC大模型研究成果。",
      "objectives": [
        "掌握人工智能基础概念与原理",
        "将学习到如何从原始数据中提取出有用的信息，为后续的模型训练和应用提供支持。",
        "将了解到AI如何从数据中提取规律和模式，逐步改进自己的算法和模型，以及如何通过推理机制对新的数据进行推断和预测",
        "通过实际应用案例分析，了解AI在各个领域中的具体应用和效果"
      ],
      "course_content": {
        "ChatGPT模型解析": [
          "课程简介",
          "GPT 如何识别你提问的文本信息？"
        ],
        "推荐系统": [
          "为什么你能一直刷到你喜欢的内容？"
        ],
        "图像识别模型解析": [
          "计算机“大脑”如何识别图片和物体？"
        ],
        "语音识别与合成技术": [
          "机器如何听懂人类说话？"
        ]
      },
      "requirements": [
        "无需经验"
      ],
      "description": "本课程旨在以简明扼要的方式，全面解读AIGC大模型的内在逻辑与实际应用。课程从基础概念入手，逐步深入剖析大模型的核心结构与算法原理，使学员能够清晰理解其工作原理。同时，课程将重点介绍图像识别和语言识别两大领域的模型原理，帮助学员掌握这些技术在实际问题中的应用方法。此外，课程还将关注数据预测和应用分析等前沿领域，引导学员运用AIGC大模型解决复杂问题。最重要的是，课程将分享AIGC领域的最新研究成果，让学员站在行业前沿，把握技术发展趋势。",
      "target_audience": [
        "计算机科学、数据科学、机器学习、人工智能等相关专业人员"
      ]
    },
    {
      "title": "copilot과 함께 파이썬 찍어먹기 (크롤링 , 데이터시각화 )",
      "url": "https://www.udemy.com/course/copilotwithcrol/",
      "bio": "파이썬 크롤링 데이터시각화 입문",
      "objectives": [
        "python의 기초적인 활용",
        "웹 크롤링",
        "간단한 데이터 분석 및 시각화",
        "프로젝트 디버깅 및 코파일럿 활용"
      ],
      "course_content": {
        "Introduction": [
          "강의 준비하기",
          "프로그래밍에서 중요한것을 말해보자면..",
          "python 자주 사용하는 것"
        ],
        "몸풀기 course - make a Lotto Program (feat: MachineLaearning)": [
          "무작위 숫자를 통한 로또 프로그램",
          "역대 로또 1등 데이터 준비",
          "로또번호 머신러닝 학습하기",
          "GUI 만들어보기"
        ],
        "Crolling": [
          "웹 크롤링이란?",
          "크롤링전 준비하기",
          "Get Naver.com",
          "Install JupyterLab",
          "크롤러 시나리오",
          "네이버 증권 크롤러 개발",
          "네이버 증권 크롤러 개발 (페이지 데이터 스크래핑)",
          "네이버 증권 크롤러 개발 (반복)",
          "네이버 증권 크롤러 마무리"
        ],
        "데이터 시각화": [
          "pandas install",
          "크롤러 수정",
          "데이터 전처리",
          "데이터 시각화",
          "데이터 시각화 2",
          "디버깅 및 excel export"
        ],
        "마치며": [
          "마치며"
        ]
      },
      "requirements": [
        "github copilot이 결제되어 있으면 좋습니다."
      ],
      "description": "초등학생도 따라할 수 있게 강사도 초심으로 돌아갑니다.\n요즘 윈도우와 노트북 등에는 Microsoft Copilot이 기본으로 들어가죠. 근데 이거 잘 사용하려면 어떻게하죠?\n프로그래밍을 처음 접하면 어디서부터 무얼 해야할지,\n용어들부터 시작하여서 어떤 개발을 해야 되고 무언가 만들 때 어떤 것이 필요한지 등등\n어떠한 정보도 없이 무작정 시작하게 되는 경우가 다반사입니다.\n파이썬이 좋다더라 하는데 정작 왜 좋은지, 어디에서 사용하는지는 애매하죠.\n하지만 AI 어시스턴트라고 불리는 ChatGPT , Copilot, CursorAI 등등\n이제 완전 왕초보도 입문하기 너무 쉬운 세상이 왔습니다.\n함께 프로그래밍에 입문해볼까요?",
      "target_audience": [
        "데이터과학에 관심있는 초보 Python 개발자 혹은 입문하고 싶은사람"
      ]
    },
    {
      "title": "IA & Machine Learning : Prédire des scores de football",
      "url": "https://www.udemy.com/course/ia-pour-predire-les-scores-de-football-formation-complete/",
      "bio": "Apprenez à créer un prédicteur intelligent de scores de football avec Python, le machine learning, des données réelles e",
      "objectives": [
        "Construisez un modèle d'IA complet pour prédire les résultats de football et enrichir votre portfolio en science des données.",
        "Maîtrisez les technologies les plus demandées : Python, Pandas, Scikit-learn, Flask, et bien plus encore.",
        "À l'issue de cette formation, vous serez capable d'appliquer des techniques prédictives à n'importe quel sport ou secteur d'activité.",
        "Développez une application web Flask entièrement interactive, prête à être déployée ou à être présentée dans vos projets.",
        "Améliorez vos compétences en science des données et en apprentissage automatique pour devenir freelance ou trouver un emploi.",
        "Apprenez et appliquez les meilleures pratiques utilisées par les scientifiques et développeurs de données professionnels."
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Construisez votre IA prédictive étape par étape en 18 étapes claires": [
          "Premiers pas avec Google Colab",
          "Étape 1 : Importation des bibliothèques nécessaires",
          "Décryptage complet des lignes de code - Étape 1",
          "Étape 2 : Téléchargement, décompression et préparation des données ESPN Soccer",
          "Décryptage complet des lignes de code - Étape 2",
          "Étape 3 : Affichage du schéma de la base de données ESPN",
          "Décryptage complet des lignes de code - Étap 3",
          "Étape 4 : Chargement des fichiers fixtures.csv, teamStats.csv, standings.csv...",
          "Décryptage complet des lignes de code - Étape 4",
          "Étape 5 : Analyse exploratoire",
          "Décryptage complet des lignes de code - Étape 5",
          "5.1. Analyse globale des résultats des rencontres",
          "5.2. Analyse globale des résultats de teamStats",
          "5.3. Analyse globale du classement",
          "5.4. Analyse de la répartition pour les ligues",
          "Étape 6 : Vérification des incohérences dans Standings.csv",
          "Décryptage complet des lignes de code - Étape 6",
          "Étape 7 : Vérification des incohérences dans teamStats.csv",
          "Décryptage complet des lignes de code - Étape 7",
          "Étape 8 : Vérification des incohérences dans leagues.csv",
          "Décryptage complet des lignes de code - Étape 8",
          "Étape 9 : Vérification des incohérences dans le fichier fixtures.csv",
          "Décryptage complet des lignes de code - Étape 9",
          "Étape 10 : Fusion et jointure - Consolidation des données pour la modélisation",
          "Décryptage complet des lignes de code - Étape 10",
          "Étape 11 : Traitement des valeurs manquantes (NaN) et optimisation de la qualité",
          "Décryptage complet des lignes de code - Étape 11",
          "11.1. Imputation à l'aide de la régression linéaire bayésienne",
          "Décryptage complet des lignes de code - Étape 11.1",
          "11.2. Validation et nettoyage des données relatives au classement des équipes",
          "Décryptage complet des lignes de code - Étape 11.2",
          "11.3. Suppression des colonnes relatives aux matchs futurs",
          "Décryptage complet des lignes de code - Étape 11.3",
          "11.4. Suppression des colonnes non pertinentes au contexte de compétition",
          "Décryptage complet des lignes de code - Étape 11.4",
          "11.5. Suppression des colonnes non pertinentes relatives aux mises à jour",
          "Décryptage complet des lignes de code - Étape 11.5",
          "11.6. Vérification finale de l'intégrité des données",
          "Décryptage complet des lignes de code - Étape 11.6",
          "Étape 12 : Enrichissement des données avec des variables dérivées et des indicat",
          "Décryptage complet des lignes de code - Étape 12",
          "Étape 13 : Transformation des variables catégorielles",
          "Décryptage complet des lignes de code - Étape 13",
          "Étape 14 – Normalisation des données numériques",
          "Décryptage complet des lignes de code - Étape 14",
          "Étape 15 : Analyse de l'importance des variables et sélection des features",
          "Décryptage complet des lignes de code - Étape 15",
          "Étape 16 : Entraînement et validation du modèle de prédiction des scores",
          "Décryptage complet des lignes de code - Étape 16",
          "Qu'est-ce que XGB Regressor ?",
          "16.1. Évaluation des performances du modèle de prédiction",
          "Décryptage complet des lignes de code - Étape 16.1",
          "Étape 17 – Adaptation et réentraînement du modèle à partir des données de l'API",
          "Décryptage complet des lignes de code - Étape 17",
          "Étape 18 : Stockage sur Drive",
          "Décryptage complet des lignes de code - Étape 18",
          "Téléchargement du Notebook – Projet Final"
        ],
        "Intégration d'API et développement web avec Flask": [
          "Installation de PyCharm",
          "Structure de l'application Web",
          "Configuration des dépendances : création d'un environnement virtuel adapté",
          "Fichier requirements.txt",
          "API.football.com",
          "Intégration back-end",
          "Décryptage complet des lignes de code - Intégration back-end",
          "Intégration front-end",
          "Décryptage complet des lignes de code - Intégration front-end",
          "Lancement de l'application"
        ]
      },
      "requirements": [
        "Connaissances de base en Python (variables, boucles, fonctions).",
        "Un ordinateur connecté à Internet (Windows, Mac ou Linux).",
        "Motivation à apprendre en travaillant sur des projets pratiques et concrets."
      ],
      "description": "Créez votre propre application IA de prédiction de scores de football\nBienvenue dans le cours Prédiction de scores de football avec Python et le Machine Learning — une expérience 100 % pratique et orientée projet, où vous apprendrez à combiner Python, l’intelligence artificielle (IA), le machine learning et le développement web avec Flask pour créer une véritable application capable de prédire les résultats de matchs de football.\nPrêt à créer votre première IA sportive et prédire les scores de vrais matchs ? C’est parti !\n\n\nCe que vous allez construire\nÀ la fin du cours, vous aurez développé une application web fonctionnelle qui prédit les scores de matchs des 5 plus grandes ligues européennes : Premier League, La Liga, Serie A, Bundesliga et Ligue 1.\nC’est un projet concret, idéal pour enrichir votre portfolio, postuler à des postes tech ou aller plus loin dans l’analyse sportive.\n\n\nCe que vous allez apprendre\nImporter et nettoyer des données complexes issues de Kaggle\nCréer des indicateurs de performance personnalisés (précision des tirs, possession, efficacité, etc.)\nEntraîner un modèle supervisé avec Scikit-learn\nÉvaluer les résultats avec des métriques du monde réel (MAE, RMSE, R²…)\nSe connecter à une API de football en temps réel\nCréer une application Flask interactive pour afficher dynamiquement vos prédictions\nPourquoi ce cours est différent ?\nVous codez un vrai projet du début à la fin, pas juste de la théorie.\nVous suivez un parcours progressif, divisé en 18 leçons pratiques.\nChaque notion est clairement expliquée, même pour les débutants en IA.\nAucun besoin d’être expert : des bases en Python et de la motivation suffisent.\nC’est une formation unique qui mêle football, données et intelligence artificielle.\n\n\nCe cours est fait pour vous si :\nVous voulez apprendre le machine learning en réalisant un projet concret\nVous cherchez un projet de portfolio solide pour booster votre profil\nVous êtes passionné par le football ou les données sportives\nVous aimez transformer des données brutes en applications interactives avec Python\n\n\nGarantie Udemy\nProfitez de la garantie satisfait ou remboursé pendant 30 jours.\nTestez les premières leçons sans risque. Si le cours ne vous convient pas, vous serez intégralement remboursé.\n\n\nRejoignez-nous dès maintenant\nInscrivez-vous dès aujourd’hui pour maîtriser Python et le machine learning, créer une IA de prédiction de scores de football, et construire une application web déployable, le tout dans un projet passionnant et complet.",
      "target_audience": [
        "Développeurs débutants à intermédiaires souhaitant créer un projet pratique d'IA axé sur le sport.",
        "Étudiants en science des données ou en intelligence artificielle à la recherche de projets concrets pour enrichir leur portfolio.",
        "Les passionnés de football intéressés par l'analyse sportive et désireux de développer leurs compétences en modélisation prédictive.",
        "Toute personne motivée par des projets concrets combinant apprentissage automatique, programmation Python et développement web (Flask)."
      ]
    },
    {
      "title": "Excel na wakacjach: Automatyzacja z xlwings i Python",
      "url": "https://www.udemy.com/course/excel-na-wakacjach-automatyzacja-z-xlwings/",
      "bio": "Praca z Excelem na poważnych sterydach",
      "objectives": [
        "Nauczysz się obsługi modułu xlwings",
        "Przyśpieszysz swoją pracę z Excelem",
        "Nauczysz się zastępować w wielu przypadkach VBA",
        "Zobaczysz, że Python to język prosty i przystępny"
      ],
      "course_content": {
        "Wstęp": [
          "Wstęp"
        ],
        "Wprowadzenie do xlwings": [
          "Dlaczego warto używać xlwings?",
          "Instalacja xlwings",
          "Różnica między xlwings a OpenPyXL"
        ],
        "Pierwsze kroki z xlwings": [
          "Tworzenie nowego pliku",
          "Otwieranie istniejącego pliku",
          "Manipulowanie arkuszami",
          "Zapisywanie i zamykanie pliku"
        ],
        "Manipulowanie danymi": [
          "Wprowadzanie, odczytywanie i zaznaczanie danych",
          "Kopiowanie danych między komórkami, arkuszami i plikami",
          "Formuły Excela",
          "Tabele",
          "Tabele przestawne"
        ],
        "Manipulowanie komórkami": [
          "Formatowanie komórek",
          "Formatowanie warunkowe",
          "Scalanie komórek",
          "Filtrowanie i sortowanie",
          "Blokowanie widoku",
          "Wyrównywanie wartości",
          "Format wartości"
        ],
        "Wizualizacje": [
          "Wykresy z xlwings - część 1, podstawy",
          "Wykresy z xlwings - część 2, szczegółowe funkcje"
        ],
        "UDFs (User Definied Functions)": [
          "Tworzenie UDFów"
        ],
        "Zakończenie": [
          "Zakończenie"
        ]
      },
      "requirements": [
        "Nie musisz mieć wielkiego doświadczenia w programowaniu, ale powinieneś znać podstawy Pythona i śmigać w Excelu."
      ],
      "description": "Zapraszamy na kurs \"Excel na Wakacjach: Automatyzacja z xlwings\", który przeniesie Twoje umiejętności pracy z Excelem na zupełnie nowy poziom! Jeśli chcesz zautomatyzować monotonne zadania, zaoszczędzić czas i wykorzystać potencjał języka Python do zarządzania arkuszami kalkulacyjnymi, ten kurs jest dla Ciebie.\nW trakcie kursu poznasz podstawy pracy z biblioteką xlwings – od instalacji, przez tworzenie i edycję plików, po zaawansowane operacje, takie jak formatowanie komórek, manipulowanie danymi czy tworzenie wykresów. Nauczysz się także tworzyć dynamiczne raporty i optymalizować codzienną pracę z dużymi zestawami danych, co przyspieszy realizację kluczowych zadań w Twojej firmie.\nKurs koncentruje się na praktycznym wykorzystaniu xlwings bez konieczności znajomości innych bibliotek czy zaawansowanego kodowania. Każdy temat omawiany jest w prosty sposób, krok po kroku, aby nawet początkujący użytkownicy Pythona mogli wdrożyć go w swojej pracy. Poruszamy także różnice między xlwings a innymi popularnymi narzędziami, takimi jak OpenPyXL, abyś mógł świadomie wybrać najlepsze rozwiązanie.\nDodatkowo, w trakcie kursu poznasz sprawdzone praktyki automatyzacji pracy, dzięki którym zaoszczędzisz godziny, a nawet dni żmudnego wysiłku. Odkryjesz, jak skutecznie wykorzystać xlwings do tworzenia wizualizacji, zarządzania danymi i wykonywania zadań, które wcześniej wydawały się niemożliwe.\nPo ukończeniu kursu będziesz mógł usprawnić procesy w Excelu, eliminując ręczne działania i skupiając się na tym, co naprawdę ważne. Dołącz już teraz i odkryj moc xlwings!",
      "target_audience": [
        "Dla miłośników Excela znudzonych powtarzalnością zadań lub zawiłością VBA."
      ]
    },
    {
      "title": "초보자도 쉽게! 따라하며 배우는 Python 데이터분석 Part.1 - 주요 문법 및 함수",
      "url": "https://www.udemy.com/course/python-part1/",
      "bio": "데이터 분석을 하기 위한 파이썬의 주요 문법 및 함수 사용법",
      "objectives": [
        "파이썬 기초 문법",
        "데이터 분석에 자주 사용되는 내장 함수",
        "데이터 분석을 하기 위한 기초 알고리즘",
        "파이썬 기초 알고리즘"
      ],
      "course_content": {
        "Part.1 - 주요 문법 및 함수 1": [
          "과정개요",
          "파이썬 함수 - 기본 실습",
          "파이썬 함수 - 리턴값 실습",
          "파이썬 함수 - 구구단",
          "실습 - 이중 for문",
          "데이터분석을 위한 주요함수 사용법1 - all, any, ord, chr, dir, enumerate",
          "데이터분석을 위한 주요함수 사용법2 - eval, hex, id, filter",
          "데이터분석을 위한 주요함수 사용법3 - input, isinstance, sum, zip, pow",
          "실습1",
          "실습2",
          "실습3",
          "데이터분석시 많이 사용되는 - filter() 함수와 람다식",
          "파이썬 출력 실습1",
          "파이썬 출력 실습2",
          "튜플 문자열 연결하기",
          "튜플 문자열 연결하기 - 실습",
          "f 문자열 - 문자 숫자",
          "f 문자열 - 리스트 자료형",
          "f 문자열 - 옵션 사용법 및 실습"
        ],
        "Part.1 - 주요 문법 및 함수 2": [
          "주요 자료구조 배열(1)",
          "주요 자료구조 배열(2)",
          "주요 자료구조 배열(3)",
          "주요 자료구조 배열(4)",
          "실습.",
          "다양한 배열 요소 및 이중 배열",
          "다양한 배열 요소 및 이중 배열 - 실습",
          "데이터분석을 위한 리스트 문자열 다루기 - List Comprehension",
          "실습.",
          "배열 메서드",
          "실습(1)",
          "실습(2) - 정렬",
          "실습(3) - 단어 빈도수",
          "실습(4) - 딕셔너리 타입과 반복문",
          "주요 함수 사용법 - 새 사람으로 태어나고 싶어요 map",
          "실습.",
          "map 함수와 tuple 사용시 주의점",
          "map 함수와 매개변수가 2 이상인 pow 사용시 주의점",
          "주요 자료구조 배열(1)",
          "사용자가 입력한 6개의 로또 번호 중복없이 출력하기(2)"
        ],
        "Part.1 - 주요 문법 및 함수 3": [
          "기초 알고리즘 - 거스름돈 계산 알고리즘(1)",
          "기초 알고리즘 - 거스름돈 계산 알고리즘(2)",
          "기초 알고리즘 - 거스름돈 계산 알고리즘(3)",
          "데이터 분석을 위한 문자열 처리(1)",
          "데이터 분석을 위한 문자열 처리(2)",
          "데이터 분석을 위한 문자열 처리(3)",
          "파이썬 문자열의 immutable 특징",
          "데이터 분석을 위한 문자열 처리(4)",
          "기초 알고리즘 - 뒤집어도 같은 문자열인지 판별하시오",
          "기초 알고리즘 - 뒤집어도 같은 문자열인지 판별하시오(코드 구현 고찰)",
          "Lorem 텍스트 분석 연습",
          "정렬 두번째 이야기 - sort sorted",
          "딕셔너리 Kyes 기준으로 정렬하기",
          "람다식을 사용한 Dict 정렬"
        ]
      },
      "requirements": [
        "누구나 수강 가능합니다"
      ],
      "description": "안녕하세요, ITGO 입니다.\n\n\n본 강의 시리즈는 '초보자도 쉽게! 따라하며 배우는 Python 데이터분석 Part.1 - 주요 문법 및 함수'입니다.\n\n\n'초보자도 쉽게! 따라하며 배우는 Python 데이터분석' 강의 시리즈는 총 3편으로 나뉘어 있으며, 본 강의는 ‘Part.1 - 주요 문법 및 함수’ 편에 해당합니다.\n\n\n\n\n본 강의의 시리즈는 파이썬으로 데이터 분석을 하기 위한 기초 사용 문법과 데이터분석 관련 라이브러이인 NumPy, Pandas 라이브러리의 사용법 및 실습을 다루고 있습니다.\n\n\n\n\n그 중 본 강의는 파이썬으로 데이터 분석을 하기 위한 기초 사용 문법에 관한 모든 내용을 다루고 있습니다.\n\n\n[누구를 위한 강의인가요?]\n\n\n파이썬을 활용한 데이터 분석의 기초를 학습해보고 싶은 사람\n\n\n빠른 시간에 데이터분석 핵심 라이브러리(Numpy, Pandas)를 학습해보고 싶은 사람\n\n\n실제 현업에서 데이터 분석을 통해 업무를 진행해보고 싶은 사람\n\n\n데이터 과학에 입문해보고 싶은 취업준비생\n\n\n\n\n\n\n\n\n[무엇을 배우나요?]\n\n\n\n\n\n\n파이썬 기초 문법\n\n\n데이터 분석에 자주 사용되는 내장 함수\n\n\n파이썬 기초 알고리즘\n\n\n데이터 분석을 하기 위한 기초 알고리즘\n\n\n\n\n\n\n\n\n\n\n그럼 강의에서 만나요 :)",
      "target_audience": [
        "파이썬을 활용한 데이터 분석의 기초를 학습해보고 싶은 사람",
        "빠른 시간에 데이터분석 핵심 라이브러리(Numpy, Pandas)를 학습해보고 싶은 사람",
        "실제 현업에서 데이터 분석을 통해 업무를 진행해보고 싶은 사람",
        "데이터 과학에 입문해보고 싶은 취업준비생"
      ]
    },
    {
      "title": "科大讯飞-星火内容运营大师实战教程",
      "url": "https://www.udemy.com/course/qphmrnlq/",
      "bio": "案例分享，指令优化，在实践中带你掌握AI大模型产品的应用技能",
      "objectives": [
        "掌握星火内容运营大师产品的的基本操作和应用场景",
        "深入了解AI大模型的优化策略，强化提示词的写法和使用技巧",
        "掌握高效工作方法，提升工作效率和质量。增加职场竟争力",
        "培养学员的创新能力，为企业带来更多创新解决方案"
      ],
      "course_content": {},
      "requirements": [
        "无需经验"
      ],
      "description": "随着人工智能技术的飞速发展，AI大模型产品已成为企业提升工作效率、实现智能化转型的重要工具。然而，许多人在面对这些复杂的AI产品时，往往感到无从下手，无法充分发挥其潜力。为此，我们特别推出了“科大讯飞出品的星火内容运营大师课程，旨在帮助学员掌握AI大模型产品的核心技能，提高工作效率，为企业创造更多价值。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "内容创作者",
        "自媒体运营者",
        "品牌管理者",
        "对内容运营感兴趣的学生",
        "自由职业者"
      ]
    },
    {
      "title": "Python数据可视化基础实践课程",
      "url": "https://www.udemy.com/course/python-da/",
      "bio": "学习Python可视化科学库，帮助学员快速解决数据处理难题",
      "objectives": [
        "快速学习Python数据可视化的关键科学库，包括Pandas，Numpy",
        "提升Python数据处理能力",
        "提升Python代码编程能力",
        "提升数据操作处理效率，赋能工作及业务发展"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲",
          "引入讲解"
        ],
        "课程内容": [
          "Anaconda介绍及安装",
          "Jupyter Notebook工具介绍及操作演示",
          "Spyder工具介绍及打开",
          "Spyder工具介绍及打开",
          "模块的安装与使用",
          "Python基础操作 (注释、对象、缩进详解)",
          "Python基本数据类型讲解",
          "Python基本数据结构介绍",
          "列表索引四种方式介绍及案例详解",
          "列表常用方法的介绍及案例演示",
          "字典常用方法及案例详解",
          "Python控制流讲解 (if、for、while语句)",
          "函数编写概述",
          "Numpy模块之创建数组array函数讲解",
          "Numpy模块之其他创建数组的方法介绍",
          "Numpy模块数组元素索引讲解",
          "Numpy: 数组常用方法及案例",
          "Pandas:创建序列的方法和案例详解",
          "Pandas: 访问序列数据",
          "Pandas:创建数据框函数及案例详解",
          "Pandas:序列及数据框基本功能介绍及案例演示",
          "Pandas:数据子集筛选iloc和loc方法详解",
          "Pandas: 数据处理概述",
          "Pandas: 缺失值处理",
          "Pandas:缺失值处理案例讲解",
          "重置索引和还原索引操作讲解",
          "数据合并介绍",
          "数据合并merge函数介绍",
          "数据分箱cut方法介绍",
          "描述统计分析和分组统计",
          "透视表pivot table介绍"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "从事数据分析工作的人"
      ],
      "description": "本课程是《Python数据可视化：入门、实践、进阶》系列课程的入门篇-Python新手上路：基础入门、Numpy、Pandas。本课程适合零基础学员学习，从Python的安装、常用工具的介绍开始，让学员能掌握如何在自己电脑上部署学习环境；通过快速入门掌握python基础语法；通过对数据对象的学习，掌握列表和字典的创建及常用方法；并深入学习了Numpy和Pandas数据分析的三方库，对Numpy数组、Pandas的序列和数据框的常见和处理有深刻的认知。为后续利用Python进行数据分析和处理打下坚实的基石。",
      "target_audience": [
        "适合企业初中级数据分析师提升数据可视化能力 适合企业有较大数据处理工作的业务人员 适合对数据有深入研究的数据工作者"
      ]
    },
    {
      "title": "ChatGPT高效工作伙伴",
      "url": "https://www.udemy.com/course/chatgpt-sl/",
      "bio": "深度学习利用ChatGPT提升工作效率",
      "objectives": [
        "加深对ChatGPT的认知",
        "帮助不同员工在各自的业务场景中学会利用ChatGPT提升工作效能",
        "帮助员工高效完成本职工作",
        "帮助学员提升新技术领域的应用能力"
      ],
      "course_content": {},
      "requirements": [
        "有chatgpt基础"
      ],
      "description": "本课程从ChatGPT的介绍与使用入手，深度解析不同场景下的ChatGPT的应用方法与使用技巧，帮助企业不同层级，不同岗位，不同业务的员工，从自身工作出发，学习如何利用ChatGPT提升自身的工作效率，提升效能。\n同时课程中深度解读了ChatGPT上线的新功能，帮助学员快速掌握新技术的发展动态，学会利用新功能赋能高效工作，赋能业务发展。本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。\n课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利\n人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课\n公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位\n提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，\n您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "适合企业各个部门的业务人员 适合对ChatGPT感兴趣的研究者和从业者 适合在校师生和相关学者"
      ]
    },
    {
      "title": "Curso Completo de SQL com MySQL",
      "url": "https://www.udemy.com/course/curso-completo-de-sql-com-mysql/",
      "bio": "Aprenda a Manipular Bancos de Dados em Poucos Passos",
      "objectives": [
        "Criar, consultar e manipular bancos de dados relacionais usando SQL com MySQL.",
        "Dominar comandos essenciais como SELECT, INSERT, UPDATE, DELETE e JOIN.",
        "Aplicar filtros, ordenações, agrupamentos e funções agregadas para análises completas.",
        "Criar relacionamentos entre tabelas e realizar consultas avançadas com subconsultas e joins múltiplos.",
        "Construir um projeto prático com banco de dados MySQL para consolidar o aprendizado."
      ],
      "course_content": {},
      "requirements": [
        "Não é necessário ter experiência prévia com SQL ou bancos de dados.",
        "Conhecimentos básicos de informática e uso de computadores.",
        "Vontade de aprender e praticar!"
      ],
      "description": "Neste curso, você aprenderá a linguagem SQL de forma prática, clara e focada em aplicações do mundo real. Vamos explorar desde os comandos mais básicos de consulta e filtragem de dados, até técnicas avançadas como junções entre tabelas, agregações, subconsultas, procedures, views e triggers.\nVocê começará entendendo como instalar e configurar o MySQL e o DBeaver, duas ferramentas poderosas para desenvolvimento e análise de dados. A partir daí, criará um banco de dados completo baseado em um sistema de vendas real, com clientes, produtos, vendas e itens de venda.\n\n\nAo longo das aulas, você vai aprender a:\n\n\nCriar e estruturar tabelas com integridade relacional\nUtilizar filtros, condições e operadores para consultas precisas\nRealizar junções entre tabelas (INNER JOIN, LEFT JOIN, RIGHT JOIN)\nUsar funções agregadoras como SUM, AVG, COUNT para gerar análises\nCriar relatórios com GROUP BY e HAVING\nCriar procedures reutilizáveis para relatórios e operações de vendas\nAutomatizar processos com triggers inteligentes (como controle de estoque)\nCriar views para facilitar a visualização de dados\nObjetivo do curso\nCapacitar você a dominar SQL de forma aplicada, para usar em qualquer sistema de banco de dados relacional, seja para desenvolvimento de sistemas, análise de dados ou BI.\n\n\nEntão não perde tempo!\nComece agora mesmo e acesse o conteúdo completo.\nTe vejo nas aulas!",
      "target_audience": [
        "Pessoas iniciantes que querem aprender SQL do zero com MySQL.",
        "Desenvolvedores iniciantes que querem integrar SQL em seus projetos.",
        "Profissionais que desejam aprimorar habilidades em banco de dados para o mercado de trabalho.",
        "Quem está se preparando para entrevistas técnicas que exigem conhecimentos em SQL.",
        "Qualquer pessoa curiosa para entender como os dados funcionam nos bastidores dos sistemas."
      ]
    },
    {
      "title": "Oracle SQL 0-dan irəli səviyyəyə | 2025",
      "url": "https://www.udemy.com/course/elmircoursesql/",
      "bio": "Oracle SQL",
      "objectives": [
        "Oracle SQL",
        "Select ifadəsi ilə başlayıb, view, constraint, DML, DDL, TCL və s. əmrlərinə kimi hər şey izah ediləcək.",
        "Subquery, Join, Set operators",
        "Praktik tapşırıqların həlli"
      ],
      "course_content": {
        "Giriş": [
          "Ümumi anlayışlar",
          "SQL developer-in yüklənməsi və quraşdırılması",
          "Select",
          "Where və müqayisə operatorları",
          "As (alias)",
          "Describe və Distinct",
          "Is null, is not null",
          "AND məntiqi operatoru",
          "OR və NOT məntiqi operatoru",
          "BETWEEN operatoru",
          "IN operatoru",
          "Order By",
          "Fetch, Offset",
          "Like (not like)"
        ],
        "SINGLE ROW FUNCTIONS": [
          "Giriş",
          "Length(), Upper(), Lower(), Initcap()",
          "Substr() və Instr()",
          "Reverse() və Replace()",
          "Lpad() və Rpad()",
          "Concat()",
          "Translate()",
          "Trim(), Ltrim(), Rtrim()",
          "Numeric Functions-Round(), Trunc()",
          "Numeric Functions-Mod(), Power() Ceil() və s.",
          "DateTime Functions",
          "Null Functions-NVL, NVL2, COALESCE, NULLIF",
          "To_char(date)",
          "To_char(number)",
          "To_date()",
          "To_number()",
          "Numtodsinterval(), Numtoyminterval()",
          "To_dsinterval(), To_yminterval()",
          "Extract()",
          "Case, Decode"
        ],
        "AGGREGATE FUNCTIONS": [
          "Count(), Sum(), Avg(), Min(), Max()",
          "Group By, Having"
        ],
        "JOIN": [
          "Inner JOIN",
          "Left, Right, Full JOIN",
          "Cross JOIN, Natural JOIN",
          "Self JOIN"
        ],
        "SUBQUERY": [
          "Single Row Subquery(WHERE)",
          "Single Row Subquery(COLUMN)",
          "Single Row Subquery(HAVİNG)",
          "Multiple Row Subquery(IN)",
          "Multiple Row Subquery(ANY)",
          "Multiple Row Subquery(ALL)",
          "From Subquery",
          "CTE",
          "Exists"
        ],
        "SET OPERATORS": [
          "Union, Union ALL",
          "Intersect, Minus"
        ],
        "ANALYTIC FUNCTIONS": [
          "Row_number(), Rank(), Dense_rank()",
          "Lag(), Lead()",
          "Partition By",
          "Rows Between",
          "First Value, Last Value"
        ],
        "SQL COMMAND TYPES": [
          "Giriş",
          "Data tipləri"
        ],
        "DDL": [
          "Create və Drop",
          "Alter, Rename, Comment",
          "Truncate"
        ],
        "DML": [
          "Insert",
          "Update və Delete"
        ]
      },
      "requirements": [
        "Bu kurs boyunca Oracle SQL başlanğıc səviyyədən öyrədilir. Bir kompüterinizin olması kifayətdir."
      ],
      "description": "Salam. Bu kurs, Oracle SQL-i tamamilə sıfırdan öyrənmək və onu irəli səviyyəyə qədər mənimsəmək istəyənlər üçün nəzərdə tutulmuşdur. Oracle SQL Developer proqramını nın kompüterə yüklənməsi və quraşdırılması görəcəksiniz. Kurs boyunca SQL (Structured Query Language) sorğu dilinin əsas anlayışları ilə tanış olub, sintaksisindən başlayaraq mürəkkəb sorğuların yazılması,\n\n\nsingle row functions,\n\n\ngroup (aggregate) functions,\n\n\nanalytic (window) functions,\n\n\nalt sorğular (subqueries),\n\n\nSet Operators,\n\n\nCTE (Common Table Expressions) ,\n\n\nJOINS,\n\n\nDML (Data Manipulation Language),\n\n\nDDL (Data Definition Language), TCL (Transaction Control Language),\n\n\nVIEW,\n\n\nConstraint,\n\n\nSequence,\n\n\nPivot, Unpivot mövzularına qədər hər şey detallı şəkildə izah ediləcəkdir.\n\n\nBu kursda həmçinin SQL sorğuları vasitəsilə verilənlər bazasında cədvəllərinin yaradılması və idarə olunması, cədvəllər arasında əlaqələrin qurulması kimi mövzular da ətraflı şəkildə izah ediləcəkdir. İstifadəçilər müxtəlif verilənlər bazası obyektləri ilə işləməyi öyrənəcəksiniz. Kursun sonunda, əldə etdiyiniz bilikləri praktiki layihələr üzərində tətbiq edərək möhkəmləndirəcəksiniz.\n\n\nTamamilə Azərbaycan dilində olan həm yeni başlayanlar, həm də SQL biliklərini daha da dərinləşdirmək istəyənlər üçün nəzərdə tutulmuş bu kurs, sizi Oracle SQL-də peşəkar səviyyəyə çatdırmağı hədəfləyir. İstənilən sahədə verilənlər bazaları ilə işləyənlər üçün uyğun olan bu kurs, praktiki tapşırıqlar vasitəsilə biliklərinizi gücləndirəcək.\n\n\nOracle SQL ilə verilənlərin idarə edilməsi, müxtəlif sorğuların yazılması və bacarıqları əldə etməklə yanaşı, verilənlər bazası dizaynı və strukturlaşdırılması haqqında da dərin biliklərə sahib olacaqsınız. Kursun məzmunu ardıcıl və aydın şəkildə təqdim olunur, beləliklə, mürəkkəb mövzuların öyrənilməsi asanlaşır.\n\n\nKursu bitirdikdən sonra Oracle SQL Developer proqramı vasitəsilə fərqli layihələr üzərində sərbəst işləməyi bacaracaq və verilənlər bazası üzrə öz bacarıqlarınızı peşəkar səviyyədə nümayiş etdirə biləcəksiniz.",
      "target_audience": [
        "Bu kurs SQL dilini öyrənmək və data analitika sahəsinə başlamaq istəyənlər üçün uyğundur."
      ]
    },
    {
      "title": "(Ken Cen 出品) Generative AI 第 34 部：用英偉達CUDA C 進階打造神經網絡的底層核心",
      "url": "https://www.udemy.com/course/generative_ai_34/",
      "bio": "CUDA C/C++，GPU Programming，Parallel Computing，Neural Networks from Scratch",
      "objectives": [
        "學員將掌握如何自動化處理 CUDA 錯誤",
        "學員將掌握如何在 CPU 和 GPU 上申請記憶體空間",
        "學員將掌握如何使用Kaiming 初始化 & 如何讀取二進制文檔到記憶體地址",
        "學員將掌握如何在 CUDA Kernel 上並行重置梯度 & 如何計算交叉熵誤差"
      ],
      "course_content": {
        "為編譯環境做準備": [
          "課程工具準備",
          "如何使用uv 作為包管理器和項目管理工具",
          "如何在Mac 上設定 C 語言編譯環境 & 編寫第一個C 語言代碼"
        ],
        "如何使用 CUDA C 打造神經網絡的底層核心": [
          "MNISTDataset 下載&預處理",
          "如何自動化處理 CUDA 錯誤 & 如何在 CPU 和 GPU 上申請記憶體空間",
          "如何使用Kaiming 初始化 & 如何讀取二進制文檔到記憶體地址",
          "如何在CUDA C 驗證輸入數據是否正常讀取",
          "如何在 CUDA Kernel 上並行重置梯度 & 如何計算交叉熵誤差",
          "如何用CUDA 計算矩陣相乘 & 添加Bias & 使用 ReLU 激活 & 處理 Softmax",
          "如何計算輸出層梯度 & 計算 weights 和 bias 的梯度 & 計算激活函數的梯度",
          "如何在 CUDA C 評估訓練效果"
        ]
      },
      "requirements": [
        "一臺電腦"
      ],
      "description": "本課程將手把手帶您從第 33 部課程的基礎上開始，利用 CUDA C 語言在 GPU 上建構一個能真正運作的兩層神經網路。\n從最底層的 C 語言環境配置，到 CUDA 核心程式設計、資料預處理、神經網路架構實現、反向傳播以及梯度更新，將所有環節無縫接軌，讓您真正理解深度學習模型是如何在 GPU 上高效運行的。\n獨特的 CUDA 知識點： 您將學到許多獨特且實用的 CUDA 技巧，這些內容在其他入門課程中極為罕見：\n高效的記憶體管理： 不僅教您如何在 CPU 和 GPU 之間傳輸數據，更深入講解如何自動化處理 CUDA 錯誤，確保您的程式碼強健且穩定。\n底層梯度計算： 我們會親手實作神經網路的梯度計算，包括輸出層、權重（weights）、偏差（bias）和激活函數（ReLU），讓您徹底擺脫對高階框架的黑盒依賴，從根本上掌握神經網路的運作原理。\nGPU 優化核心： 課程會展示如何利用 CUDA Kernel 來並行重置梯度、高效計算矩陣乘法（matmul）以及實現 ReLU 和 Softmax 激活，讓您親眼見證 GPU 強大的並行計算能力如何加速運算。\n\n\n課程使用業界標準的 MNIST 手寫數字資料集，並教您如何下載、預處理以及讀取二進制檔案，這些都是在實際專案中不可或缺的技能。您還會學到如何驗證數據是否正確讀取，養成嚴謹的程式設計習慣",
      "target_audience": [
        "對底層運作原理充滿好奇的學生或工程師",
        "希望轉職或專精於高效能計算的開發者",
        "正在學習計算機科學的學生",
        "對 C/C++ 語言有基本認識，想學習 CUDA 的工程師"
      ]
    },
    {
      "title": "【AI 자막】 머신러닝 마스터 클래스, AI 인공지능 쉽게 이해하기 (초보에서 숙련된 실무자로!)",
      "url": "https://www.udemy.com/course/machine-learning-masterclass-ai-made-easy-korean/",
      "bio": "머신러닝 에 대한 심층적인 접근 방식을 통해 머신러닝 의 기초를 쉽게 익히고 단시간에 전문가가 될 수 있습니다. 지금 바로 수강신청하세요!",
      "objectives": [
        "머신러닝과 관련된 이슈를 처리하고 실행할 수 있는 가장 효과적인 방법",
        "머신 러닝이 해결할 수 있는 문제와, 머신 러닝 프로세스가 어떻게 작동하는지를 이해하기",
        "머신 러닝에 파이썬 사용하기",
        "백분위수, 모멘트 및 분위수",
        "파이썬 플로팅을 위해 Matplotlib를 활용하는 방법 배우기",
        "Seaborn을 활용한 통계적 플롯 사용법 배우기",
        "행렬 곱셈, 행렬 연산 및 스칼라 연산 이해하기",
        "페어 플롯 사용법과 한계에 대해 이해하기",
        "항등행렬(identity matrix), 역행렬 속성, 전치 행렬, 벡터 곱셈",
        "선형 회귀, 다중 선형 회귀, 다항 회귀, 의사 결정 트리 회귀, 랜덤 포레스트 회귀 구현하기",
        "AdaBoost 및 XGBoost 회귀 분석, SVM(회귀) 배경, Python 에서의 SVR",
        "머신러닝 개념-k-폴드 검증 및 그리드서치(GridSearch)",
        "분류- K-최근접 이웃 알고리즘(KNN)",
        "Python 에서의 가우시안 나이브 베이즈 및 모델 시각화",
        "곡선(ROC, AUC, PR, CAP)을 사용한 평가 기술 학습",
        "머신 러닝 알고리즘 구현",
        "그 외에도 더 많은 주제가 추가제공될 예정입니다"
      ],
      "course_content": {
        "강의 소개": [
          "강사 소개",
          "머신러닝의 역사 소개",
          "강의수강의 선수조건",
          "리뷰 및 평점 안내"
        ],
        "셋업하기": [
          "파이썬의 역사",
          "파이썬 버전 2와 3 비교",
          "파이썬 IDE's 통합 개발 환경 옵션",
          "아나콘다 네비게이터 및 IDE's 통합 개발 환경",
          "주피터 노트북과 구글 코랩",
          "PyCharm 과 VS Code",
          "가상 환경"
        ],
        "몇 가지 추가 공지": [
          "링크드인 및 인스타그램 링크"
        ],
        "Python: 기초": [
          "데이터 유형",
          "파이썬 넘버",
          "변수 및 할당",
          "문자열 기초",
          "문자열: Start, Stop, Step",
          "문자열 슬라이싱",
          "문자열 포맷팅",
          "파이썬의 리스트",
          "리스트 정렬, 반전, 제거, 초기화, 리스트의 리스트",
          "집합(Sets)",
          "튜플(Tuples)",
          "파이썬 딕셔너리",
          "None 과 Bool",
          "비교 연산자",
          "논리 연산자",
          "LinkedIn에서 활발하게 활동하세요",
          "섹션의 프로젝트 파일/노트북"
        ],
        "Python: 명령문": [
          "If, elif, else",
          "While 루프",
          "For 루프",
          "튜플 언패킹",
          "Break, continue, pass",
          "Range, enumerate, zip",
          "In",
          "인풋 & 임포트",
          "토론 포럼",
          "섹션의 프로젝트 파일/노트북"
        ],
        "Python: 메서드 및 함수": [
          "사용자 정의 함수",
          "도움말 함수",
          "스코프",
          "args & kwargs",
          "Maps, Filters, Lambdas",
          "Lambda 심화학습",
          "프로젝트 파일 공지",
          "섹션의 프로젝트 파일/노트북"
        ],
        "Python: 모듈 및 패키지": [
          "파이썬 패키지",
          "사용자 정의 패키지",
          "사용자 정의 패키지 심화학습",
          "섹션의 프로젝트 파일/노트북"
        ],
        "Python: Python 에서의 객체 지향 프로그래밍 (OOPS)": [
          "네이밍 규칙 및 소개",
          "클래스 속성 및 메서드",
          "상속 (Inheritance)",
          "다중, 다단계 상속 및 MRO",
          "다형성 (Polymorphism)",
          "특수 클래스 메서드",
          "섹션의 프로젝트 파일/노트북"
        ],
        "Python: 오류 처리": [
          "Try, except, finally",
          "오류 유형, else 및 finally",
          "섹션의 프로젝트 파일/노트북"
        ],
        "Python 데코레이터 및 제너레이터": [
          "파이썬 데코레이터",
          "클래스 메서드 데코레이터",
          "파이썬 제너레이터",
          "섹션의 프로젝트 파일/노트북"
        ]
      },
      "requirements": [
        "고등학교 수준의 수학에 대한 기본적인 이해",
        "코딩 또는 스크립팅에 대한 사전 경험이 필요합니다",
        "머신 러닝 분야에 대한 탐구을 시작하려면 Python에 대한 기본 지식이 필요합니다(선택 사항)",
        "주피터 노트북 (Jupyter Notebook)"
      ],
      "description": "[꼭 읽어주세요] 한글 AI 자막 강의란?\n유데미의 한국어 [자동] AI 자막 서비스로 제공되는 강의입니다.\n퀴즈와 실전테스트에 대해서는 한글 번역이 제공되지 않습니다.\n강의에 대한 질문사항은 Chand 강사님이 확인하실 수 있도록 Q&A 게시판에 영어로 남겨주시기 바랍니다.\n\n\n【AI 자막】 머신러닝 마스터 클래스, AI 인공지능 쉽게 이해하기 (초보에서 숙련된 실무자로!) 강의에 오신 것을 환영합니다!\n이 강의에서는 흥미진진한 머신러닝 분야의 왕초보에서 전문가 및 숙련된 실무자가 될 수 있도록 여러분을 안내합니다. 이 과정은 초보자이든 프로그래밍 경험이 있든 없든 상관없이 머신 러닝 과 데이터 사이언스 분야에서 성공하기 위해 필요한 지식과 기술을 갖출 수 있도록 설계되었습니다. 데이터 사이언스나 통계에 관심이 있거나 단순히 머신 러닝 을 배워보려는 경우, 학습에 필요한 모든 핵심 이론과 실용적인 기술을 다룹니다. 단계별 튜토리얼과 실전 예제를 통해 여러분은 지식 뿐만 아니라 직접 모델을 구축해보는 실습 경험도 쌓을 수 있습니다.\n\n\n각 섹션에서 배우게 될 내용을 살펴보겠습니다:\n\n\n강의 개요:\n섹션 1 - 파이썬 기초 및 고급 개념:\n데코레이터와 제너레이터를 포함한 파이썬 프로그래밍의 기초를 배웁니다.\n효율적인 데이터 조작과 분석을 위한 NumPy, Pandas와 같은 필수 라이브러리를 살펴봅니다.\n섹션 2 - 머신러닝 개념:\n지도 (Supervised) 및 비지도 (Unsupervised) 학습의 핵심 개념을 이해합니다.\n표준 편차, 백분위수, 분위수 와 같은 통계적 측정에 대해 자세히 알아봅니다.\n평균, 최빈값, 중앙값과 같은 기술 통계를 마스터합니다.\n섹션 3 - 데이터 전처리:\n모델 평가를 위해 데이터를 테스트 세트와 훈련 세트로 분할하는 방법을 알아봅니다.\n누락된 데이터를 처리하고 언더샘플링 및 오버샘플링과 같은 기법을 살펴봅니다.\n섹션 4 - 회귀:\n단순 선형 회귀, 다중 선형 회귀, SVR, 의사 결정 트리 회귀, 랜덤 포레스트 회귀, 다항 회귀 등 회귀 분석의 개념을 견고히 다집니다.\n섹션 5 - 분류:\n로지스틱 회귀, K-최근접 이웃 (K-NN), 서포트 벡터 머신 (SVM), 나이브 베이즈, 의사 결정 트리 분류, 랜덤 포레스트 분류 등 분류 알고리즘에 대한 전문 지식을 쌓습니다.\n섹션 6 - 클러스터링:\nK-평균 클러스터링으로 클러스터링 기술을 숙달하고, 최적 클러스터 수를 결정하는 방법을 배웁니다.\n섹션 7 - 강화 학습:\n상위 신뢰 구간(UCB) 접근 방식을 중심으로 강화 학습 알고리즘을 살펴봅니다.\n섹션 8 - 자연어 처리 (NLP):\n머신 러닝을 이용한 텍스트 분류에서 NLP의 개념 및 응용에 대해 알아봅니다.\n배운 기술을 사용하여 직접 텍스트 분류기를 구축합니다.\n섹션 9 - 딥러닝:\n신경망, 역전파, 숫자를 사용한 데이터 표현, 활성화 함수 등을 포함한 딥러닝의 매력적인 세계를 탐구합니다.\n섹션 10 - 모델 선택 및 부스팅:\nK-겹 교차 검증, 매개변수 튜닝, 그리드서치와 같은 모델 선택 및 최적화 기법에 대해 알아봅니다.\n성능 향상을 위한 강력한 XGBoost 알고리즘에 대해 알아보세요.\n섹션 11 - Flask 및 모델 배포를 활용한 웹 애플리케이션:\nFlask를 사용하여 기본적인 웹 애플리케이션을 구축하는 실습 경험을 쌓습니다.\n머신 러닝 모델을  웹 애플리케이션에서 배포하는 방법을 알아봅니다.\n\n\n그 외에도 특성 선택, 시각화, 평가 기술 등과 같은 핵심 주제도 다루게 될 것입니다.\n또한 이 과정은 실제 예제를 기반으로 한 실습을 통해 학습을 강화하고 자신있게 모델을 구축할 수 있도록 하기 위해 실제 연습문제가 가득한 과정입니다. 따라서 이론뿐만 아니라 직접 모델을 구축하는 실습 경험도 얻게 될 것입니다.\n현재 데이터 사이언스 및 머신 러닝 기술의 높은 수요에 대해 인지하고 계신가요? 이 분야는 의심할 여지없이 마스터하기 어려운 분야입니다. 머신러닝을 위한 수학, 데이터 처리, 머신러닝 A-Z, 딥러닝 등 데이터 사이언스 및 머신러닝의 모든 측면을 다루는 포괄적인 강의를 원하신 적이 있나요? 그렇다면 제대로 찾아오셨습니다.\n\n\n왜 이 강의를 선택해야 하나요?\n포괄적인 커리큘럼: 이 강의는 Python 기초부터 고급 머신 러닝 기술까지 모든 것을 다루므로, 해당 주제에 대한 탄탄한 기초를 다질 수 있습니다.\n실용적인 접근 방식: 학습한 개념을 적용할 수 있도록 실습과 실전 예제를 제공합니다.\n강사의 경력: 8년 동안 14만 명 이상의 학생들을 가르치며 쌓은 산업 전문 지식을 바탕으로, 명확하고 간단하게 핵심 개념들을 가르쳐드립니다.\n명확한 궁금증 해결: 강의 내용이 헷갈리는 경우 질문을 남기면, 강사가 언제든지 질문에 답하고 의문을 해소해 드립니다.\n고품질 교육: 간결함과 단계별 학습에 중점을 둔 독특한 교수법으로 복잡한 개념도 이해하기 쉽게 만듭니다.\n가치 있는 스킬셋 학습: 머신러닝은 다양한 산업에서 수요가 높으며, 머신러닝을 마스터하면 데이터 사이언티스트, 머신러닝 엔지니어 또는 컴퓨터 비전 전문가로서의 커리어 전망을 높일 수 있습니다.\n\n\n이 강의는 복잡한 주제를 알기 쉽게 설명하고 단계별 접근 방식을 따르는 독특한 강의 스타일이 매우 뛰어납니다. 내용이 헷갈리거나 설명이 필요한 경우 질문을 남겨주시면 숙련된 강사가 즉시 의문을 해결해 드립니다.\n\n\n배우게 될 주제:\n효과적이고 문제 없이 실행되는 머신 러닝 방법들\n머신러닝을 통해 해결할 수 있는 문제들\n머신 러닝을 사용하여 함수를 처리하는 방법\n머신 러닝에 파이썬 사용하기\n백분위수, 모멘트 및 분위수\nPython 플로팅을 위한 Matplotlib 활용법 배우기\nSeaborn을 활용한 측정 그래픽 사용법 배우기\n머신 러닝을 위한 고급 수학 배우기\n행렬 곱셈, 행렬 연산 및 스칼라 연산 이해하기\n페어 플롯 사용법과 한계에 대해 이해하기\n항등 행렬, 역행렬 속성, 전치행렬 및 벡터 곱셈\n선형 회귀, 다중 선형 회귀, 다항 회귀, 의사 결정 트리 회귀, 랜덤 포레스트 회귀 구현하기\nAdaBoost 및 XGBoost 회귀 분석, SVM(회귀) 백그라운드, Python에서 SVR\n머신러닝 개념-k-겹 교차검증과 그리드서치(GridSearch)\n분류-K-최근접 이웃 알고리즘(KNN)\nPython의 가우시안 나이브 베이즈 및 모델 시각화\n곡선(ROC, AUC, PR, CAP)을 사용한 평가 기술 배우기\n머신 러닝 알고리즘 구현하기\nFlask 웹 애플리케이션에 모델 배포하기\n자연어 처리(NLP)\n딥러닝\n그 외에도 더 많은 흥미로운 주제들이 있습니다.\n\n\n머신러닝은 왜 중요한가요?\n머신러닝은 오늘날의 데이터 중심 세계에서 매우 중요해졌습니다. 방대한 양의 데이터를 사용할 수 있고 계산능력의 발전 및 저렴한 저장 공간과 결합되어, 머신러닝은 가치 있는 인사이트를 추출하고 데이터 기반의 의사결정을 내리는 데 중요한 역할을 합니다. 머신러닝을 통해 기업은 기회와 위험을 신속하게 파악하고, 경쟁 우위를 확보하며, 소매업, 의료, 운송 등 다양한 산업에서 혁신을 주도할 수 있습니다.\n\n\n접근성이 향상된 학습:\n이 강의는 집에서 편안하게 머신러닝을 배울 수 있는 특별한 기회를 제공합니다. 머신러닝을 마스터하려면 실제 응용이 필수적이라는 것을 잘 알고 있기 때문에, 실습 과제와 실전 예제를 제공하여 여러분의 학습을 돕습니다. 이 강의를 수료하면 여러분은 가치 있는 경험을 쌓고 머신러닝 분야에서 어디서든 러브콜을 받는 전문가가 될 수 있습니다.\n\n\n머신 러닝 기술을 습득함으로써 얻을 수 있는 이점을 원하신다면 이 강의를 꼭 수강하세요!\n\n\n묻지도 따지지도 않는 환불 보장 정책!\n어렵고 까다로운 기술을 배우기 위해 수강료를 지불하는 사람들에게 가장 큰 장벽은 해당 강좌가 자신에게 적합한지, 이 강좌를 통해 얻을 수 있는 혜택이 있는지 알아보는 것입니다. 이 머신 러닝 강의는 30일 이내에 언제든지 아무것도 묻지도 따지지도 않고 수강을 취소할 수 있으므로 안심하셔도 됩니다. 기본적으로 30일 환불 보장이 제공되므로 이 강좌를 구매할 때 발생하는 위험은 0에 가깝습니다. 강의를 구매한 후 어떤 이유로든 강좌가 만족스럽지 않다면 아.묻.따 전액 환불해드립니다.\n30일 환불 보장 정책도 마련되어 있으니 망설이지 말고 수강신청해보세요! 지금 바로 구매하셔서 머신 러닝에 대한 단계별 학습 방식을 제공하는 【AI 자막】 머신러닝 마스터 클래스, AI 인공지능 쉽게 이해하기 (초보에서 숙련된 실무자로!) 에 수강신청해보세요!\n\n\n오늘 바로 시작해보세요:\n수요가 많은 강력한 머신 러닝 기술을 습득할 수 있는 기회를 놓치지 마세요. 지금 수강신청하시고 머신 러닝 전문가가 되기 위한 여정을 시작하세요. 초보자이든 경험이 풍부한 프로그래머이든, 이 강좌는 여러분이 기계 학습 분야에서 뛰어날 수 있도록 필요한 지식과 실용적인 기술을 제공할 것입니다. 이 과정을 마치면 높은 연봉과 수요가 보장된 데이터 과학 분야에 진출하는 데 필요한 머신 러닝 기술을 손쉽게 다룰 수 있게 될 것입니다.\n학습 열정가들에게는 이 강의가 매력적으로 느껴질 것이며, 이를 통해 스킬셋을 향상시키고 자신의 이력서에 가치를 더할 수 있을 것입니다.\n\n\n지금 수강신청하시고 집에서 편안하게 머신 러닝의 힘을 학습해보세요!\n\n\n오늘 이 모험에 동참하세요! 강의에서 만나요. - Chand 드림",
      "target_audience": [
        "머신러닝과 AI 인공지능 분야를 탐구하고 싶어하는 호기심 많은 분",
        "수학적 이해가 미미한 사람들도 머신 러닝을 배우고 싶어하는 경우, 이 과정을 통해 견고한 기반을 쌓을 수 있습니다",
        "코딩 기술이 부족한 사람들도 접근할 수 있도록 이 과정은 프로그래밍 개념에 어려움을 겪는 사람들을 위해 접근 가능한 방식으로 자료를 제공합니다",
        "데이터 사이언티스트 직업을 희망하는 대학생은 이 과정을 통해 필요한 기술과 지식을 습득하기 위한 발판으로 활용할 수 있습니다",
        "데이터 분석가들은 머신 러닝 기술을 활용하여 본인의 스킬셋을 향상시키고, 데이터 분석 작업에 유용한 통찰과 실용적인 기술을 얻을 수 있습니다",
        "소프트웨어 개발자나 프로그래머들은 기존의 프로그래밍 기술을 활용하여 머신 러닝으로의 원활한 직무 전환을 이뤄내고, 이 흥미로운 머신러닝 분야에서 지식을 확장할 수 있습니다"
      ]
    },
    {
      "title": "Pemanfaatan AI BOT di dunia akademisi (free ai bot password)",
      "url": "https://www.udemy.com/course/pemanfaatan-ai-bot-di-dunia-akademisi/",
      "bio": "Usefull of AI BOT for education purpose (free ai bot password)",
      "objectives": [
        "membuat cerita dengan ai bot",
        "membuat makalah dengan ai bot",
        "pengenalan fitur ai bot",
        "password ai bot buatan saya"
      ],
      "course_content": {
        "Pengantar": [
          "Pengenalan",
          "2. Membuat cerita dengan AI",
          "Membuat makalah dengan AI part 1",
          "Membuat makalah dengan AI part 2",
          "Membuat makalah dengan AI part 3",
          "Sekedar kesimpulan dan saran"
        ]
      },
      "requirements": [
        "harus pandai berbahasa indonesia"
      ],
      "description": "Dalam lanskap digital yang berkembang pesat, kecerdasan buatan (AI) telah menjadi topik hangat di berbagai bidang, termasuk dunia akademis. Seiring dengan upaya sekolah dan universitas untuk menjadi yang terdepan dan memberikan pendidikan mutakhir kepada siswanya, pemanfaatan bot AI di dunia akademis semakin mendapat perhatian. Untuk memenuhi permintaan yang terus meningkat ini, semakin banyak institusi yang menawarkan kursus tentang pemanfaatan bot AI di dunia akademis.\n\n\nSalah satu mata kuliah yang mendapatkan popularitas adalah “Kursus Pemanfaatan AI BOT di dunia akademisi” atau Mata Kuliah Pemanfaatan AI Bot di Dunia Akademik. Kursus ini dirancang untuk membekali pendidik dan administrator dengan pengetahuan dan keterampilan untuk memanfaatkan teknologi AI secara efektif dalam tugas pengajaran dan administratif mereka. Dengan mempelajari cara menggunakan bot AI, peserta dapat menyederhanakan berbagai proses, meningkatkan efisiensi, dan meningkatkan pengalaman akademik secara keseluruhan baik bagi mahasiswa maupun dosen.\n\n\nKurikulum kursus mencakup berbagai topik, termasuk dasar-dasar teknologi AI, berbagai jenis bot AI, aplikasi praktis di dunia akademis, dan praktik terbaik untuk penerapannya. Peserta juga akan belajar bagaimana mengembangkan dan menyesuaikan bot AI agar sesuai dengan kebutuhan dan kebutuhan spesifik mereka. Melalui kombinasi ceramah, latihan langsung, dan studi kasus dunia nyata, peserta akan memperoleh pemahaman komprehensif tentang bagaimana bot AI dapat merevolusi dunia akademis.\n\n\nSalah satu manfaat utama mengikuti kursus ini adalah kesempatan untuk tetap menjadi yang terdepan dan beradaptasi dengan lanskap digital yang berubah dengan cepat. Dengan menguasai keterampilan yang diperlukan untuk memanfaatkan bot AI secara efektif, pendidik dan administrator dapat memperoleh keunggulan kompetitif dan meningkatkan pengembangan profesional mereka. Selain itu, penggunaan bot AI dapat membantu institusi menghemat waktu dan sumber daya, meningkatkan produktivitas, dan memberikan pengalaman belajar yang lebih personal dan menarik bagi siswa.\n\n\nSelain itu, dengan menggabungkan bot AI ke dalam tugas pengajaran dan administratif, pendidik dapat meningkatkan kemampuan mereka dalam memberikan dukungan dan masukan yang dipersonalisasi kepada siswa. Bot AI dapat menganalisis data, mengidentifikasi pola, dan memberikan wawasan yang dapat membantu pendidik menyesuaikan strategi pengajaran mereka untuk memenuhi kebutuhan individu setiap siswa. Pendekatan yang dipersonalisasi ini dapat menghasilkan hasil akademik yang lebih baik dan meningkatkan kepuasan siswa.\n\n\nKesimpulannya, \"Kursus Pemanfaatan AI BOT di dunia akademisi\" menawarkan kesempatan unik bagi para pendidik dan administrator untuk memanfaatkan kekuatan teknologi AI di dunia akademik. Dengan menguasai keterampilan yang diperlukan untuk memanfaatkan bot AI secara efektif, peserta dapat menyederhanakan proses, meningkatkan efisiensi, dan meningkatkan pengalaman akademik secara keseluruhan baik bagi mahasiswa maupun dosen. Seiring dengan kemajuan teknologi yang pesat, kursus seperti ini penting untuk tetap menjadi yang terdepan dan memberikan pendidikan mutakhir di era digital.",
      "target_audience": [
        "pemula yang memiliki dasar software"
      ]
    },
    {
      "title": "Artificial intelligence (AI) الذكاء الاصطناعي بالعربي",
      "url": "https://www.udemy.com/course/artificial-intelligence-ai-x/",
      "bio": "الذكاء الاصطناعي",
      "objectives": [
        "AI Concepts",
        "AI With python",
        "Dealing with Data Sets",
        "Ai Algorithms with python Examples",
        "Statistics concepts"
      ],
      "course_content": {
        "Artificial inteligence": [
          "2-Defination-Types",
          "3-tools",
          "4-var-datatype",
          "5-input",
          "6-condition",
          "7-for loop",
          "8-while",
          "9-Function",
          "10-list",
          "11-Dictionary",
          "12-tuple-set",
          "13-numpy",
          "14-matplotlib",
          "15-pandas",
          "16-Statistics1",
          "17-Variance-Standered",
          "18-Simple Line Regression",
          "19-Linear Regression Example",
          "20-ploy",
          "21-KNN",
          "22-preprocessing",
          "23-classification",
          "24-KNNExample",
          "25-SVExample",
          "26-clustering",
          "27-ClusteringExample"
        ]
      },
      "requirements": [
        "PC or Laptop"
      ],
      "description": "الذكاء الاصطناعي هو مجال علوم الكمبيوتر المخصص لحل المشكلات المعرفية المرتبطة عادةً بالذكاء البشري، مثل التعلم والإبداع والتعرف على الصور. تجمع المؤسسات الحديثة كمياتٍ كبيرةً من البيانات من مصادر متنوعة مثل أجهزة الاستشعار الذكية والمحتوى الذي ينشئه الإنسان وأدوات المراقبة وسجلات النظام. الهدف من الذكاء الاصطناعي هو إنشاء أنظمة ذاتية التعلم تستخلص المعاني من البيانات. بعد ذلك، يُمكن للذكاء الاصطناعي تطبيق تلك المعرفة لحل المشكلات الجديدة بطرق تشبه الإنسان. على سبيل المثال، يُمكن لتقنية الذكاء الاصطناعي الاستجابة بشكل هادف للمحادثات البشرية، وإنشاء صور ونصوص أصلية، واتخاذ القرارات بناءً على مُدخلات البيانات في الوقت الفعلي. يمكن لمؤسستك دمج إمكانات الذكاء الاصطناعي في تطبيقاتك لتحسين عمليات الأعمال لديك وتحسين تجارب العملاء وتسريع الابتكار\nيتمتع الذكاء الاصطناعي بالقدرة على تقديم مجموعة من المزايا لمختلف القطاعات\nيمكن لتقنية الذكاء الاصطناعي استخدام تعلّم الآلة وشبكات التعليم العميق في حل المشكلات المعقدة بذكاء يشبه ذكاء العنصر البشري. يمكن للذكاء الاصطناعي معالجة المعلومات على نطاق واسع، عن طريق مواجهة الأنماط وتحديد المعلومات وتقديم الإجابات. يُمكنك استخدام الذكاء الاصطناعي في حل المشكلات التي تواجه مجموعةً من المجالات مثل اكتشاف الاحتيال والتشخيص الطبي وتحليلات الأعمال\nعلى عكس العناصر البشرية، يُمكن لتقنية الذكاء الاصطناعي العمل على مدار الساعة طوال أيام الأسبوع بدون أن تنخفض معدلات الأداء. بعبارة أخرى، يمكن للذكاء الاصطناعي أداء المهام اليدوية بلا أخطاء. يُمكنك السماح للذكاء الاصطناعي بالتركيز على المهام المتكررة والمملة، حتى تتمكن من استخدام الموارد البشرية في مجالات أخرى من الأعمال. يمكن للذكاء الاصطناعي تقليل أعباء عمل الموظفين وفي الوقت نفسه تيسير جميع المهام المتعلقة بالأعمال",
      "target_audience": [
        "Everyone need to learn AI"
      ]
    },
    {
      "title": "CopyGPT: Cómo potenciar tu copywriting usando AI",
      "url": "https://www.udemy.com/course/copygpt-copywriting/",
      "bio": "copywriting, chatgpt",
      "objectives": [
        "Cómo utilizar la tecnología de chat GPT para potenciar tus habilidades de copywriting y escalar tu negocio.",
        "Descubrir cómo puedes mejorar tus habilidades de escritura y aumentar tu tasa de conversión.",
        "Cómo utilizar prompts para pedir lo que necesites",
        "Ejemplos, optimizaciones y casos de éxito"
      ],
      "course_content": {
        "Introducción": [
          "Introducción"
        ],
        "CopyGPT": [
          "Masterclass ChatGPT"
        ],
        "Otros usos": [
          "Otros Usos del ChatGPT"
        ],
        "El futuro y la diferencia humana": [
          "El futuro del Copywriting",
          "La Diferencia que hace la diferencia"
        ],
        "Invitación Final": [
          "Reflexiones y Cierre"
        ]
      },
      "requirements": [
        "basico copywriting"
      ],
      "description": "¿Eres redactor, copywriter o escribes para tu marca o servicio? En esta masterclass te cuento qué hacer y cómo usar el CHATGPT a tu favor para impulsar tu copy y expandir tu mensaje.\n\n\n\n\nEste video curso  consta de tres partes:\n\n\nPARTE 1. Introducción al tema: Presentación de lo que vas a ver\n\n\nPARTE 2. Masterclass Contenido CopyGPT\n\n\nAllí  descubrirás:\n\n\n1. Por qué el CHATGPT es algo que nunca has visto antes (y por qué sí está bien tenerle algo de miedo)\n\n\n1. Cómo superar el miedo al CHATGPT y convertirlo en tu herramienta más poderosa a la hora de escribir textos que enganchen y conviertan.\n\n\n2. Qué podés hacer con AI y qué necesitás saber para escribir prompts que funcionen. Veremos diferentes funciones del CHAT con ejemplos paso a paso para que entiendas cómo usarlo.\n\n\n3. Ejemplos de diferentes situaciones/requerimientos de copy para tu negocio o marca digital (cómo usarlo para investigación, reescritura, lluvia de ideas y otras aplicaciones de contenido)\n\n\n4. El futuro y qué podemos esperar del chat gpt en copywriting (mi opinión y la tendencia que noto, además de lo que creo que NUNCA podrá hacer el chatGPT y que vos sí.)\n\n\nPARTE 3. Cierre con conclusiones finales\n\n\nAdemás incluye PDF descargable de toda la presentación.\n\n\n¡Te espero!",
      "target_audience": [
        "redactores, copywriters, dueño de tu propia marca,"
      ]
    },
    {
      "title": "Pelatihan Inovasi AI Vision dan OCR Menggunakan Python",
      "url": "https://www.udemy.com/course/pelatihancvocr/",
      "bio": "Menguasai Masa Depan Digital: Inovasi AI Vision dan OCR dengan Python. Disertai dengan beberapa studi kasus yang nyata",
      "objectives": [
        "Kuasai Teknik Vision AI Modern: Pelajari prinsip dasar dan teknik canggih computer vision dengan Python dan OpenCV",
        "OCR Tingkat Lanjut: Dominasi OCR dari dasar hingga ekstraksi teks cerdas, termasuk tulisan tangan dan dokumen kompleks",
        "Deep Learning untuk Vision dan OCR: Penerapan praktis CNN dalam proyek OCR dan vision komputer, dari teori hingga implementasi",
        "Inovasi Model AI: Desain, latih, dan evaluasi model AI untuk tugas vision spesifik, dengan fokus pada hasil yang akurat dan efisien",
        "OCR dalam Aplikasi Nyata: Integrasi sistem OCR ke dalam aplikasi Python, termasuk pengolahan data dan visualisasi hasil",
        "Studi kasus berbasis skenario nyata: Terapkan pengetahuan dalam proyek nyata - dari pengenalan wajah hingga analisis video real-time"
      ],
      "course_content": {
        "Pendahuluan dan Persiapan": [
          "Pengantar Pelatihan",
          "Belum Mengenal Pemrograman Python ?",
          "Persiapan",
          "Kode Program Pelatihan"
        ],
        "Dasar-dasar Computer Vision dan AI Vision dengan Python": [
          "Pendahuluan",
          "Konsep Computer Vision dan AI Vision",
          "Pengenalan dan Eksplorasi OpenCV",
          "Manipulasi Gambar dengan OpenCV",
          "Deteksi Warna dan Bentuk",
          "Membaca dan Menulis Gambar dari Media File",
          "Menggambar Bentuk Dasar (Gambar Geometrik)",
          "Bekerja dengan Text dan Font Text",
          "Pengolahan Gambar Secara Real-Time",
          "Deteksi Wajah Dasar",
          "Eksplorasi Pre-trained Haar Cascade",
          "Deteksi Wajah dengan Library dlib",
          "Deteksi Wajah Secara Real-Time",
          "Ekstraksi Fitur Gambar",
          "Pengenalan Histogram Gambar",
          "Dasar-dasar Segmentasi Gambar",
          "Integrasi AI dengan Computer Vision (Studi Kasus: Deepface)",
          "Convolutional Neural Networks (CNNs)",
          "Deep Learning dalam Computer Vision",
          "Studi Kasus: Deteksi Wajah yang Memakai Masker atau Tidak",
          "Image Classification dengan Transfer Learning"
        ],
        "OCR (Optical Character Recognition) dengan Python": [
          "Pendahuluan",
          "Konsep Dasar OCR",
          "Library OCR dalam Python",
          "Tesseract OCR",
          "Ekstraksi Teks dari Gambar dan PDF",
          "Dukungan Bahasa Pada Tesseract OCR",
          "Preprocessing untuk OCR",
          "Ekstraksi dan Segmentasi Text",
          "Studi kasus: Ekstraksi Text dari Tulisan Tangan",
          "Studi Kasus Ekstraksi Text dari KTP",
          "Studi kasus: Ekstraksi Text dari Struk Belanja",
          "Studi kasus: Ekstraksi Text dari Plat Kendaraan",
          "Studi kasus: Ekstraksi Text dari Struk Parkir Kendaraan",
          "Studi kasus: Ekstraksi Text dari Struk Tol",
          "Studi kasus: Ekstraksi Text dari Surat Penagihan atau Invoice"
        ]
      },
      "requirements": [
        "Menguasai dasar bahasa pemrograman Python",
        "Akses Internet",
        "Menguasai dasar machine learning (lebih direkomendasikan)"
      ],
      "description": "Pelatihan Inovasi AI Vision dan OCR Menggunakan Python ini bukan hanya sebuah kursus biasa; ini adalah peluang untuk Anda untuk terjun langsung ke dalam revolusi teknologi terkini. Mengapa ini penting? Karena keahlian di bidang AI Vision dan OCR kini menjadi aset berharga di banyak industri, dari pengembangan aplikasi, analisis data, hingga otomatisasi proses bisnis. Melalui pelatihan ini, Anda akan mendapatkan pemahaman yang kuat serta keterampilan praktis yang dibutuhkan untuk menguasai teknologi ini.\n\n\nDalam pelatihan ini, topik penting yang menjadi fokus termasuk:\nEksplorasi OpenCV dan Manipulasi Gambar: Menyelami dunia OpenCV, Anda akan mempelajari cara-cara canggih dalam manipulasi gambar, yang merupakan keterampilan dasar dalam AI Vision.\nDeteksi Wajah dan Real-Time Image Processing: Topik ini mengajarkan tentang teknik deteksi wajah, termasuk penggunaan Haar Cascade dan library dlib, serta pengolahan gambar secara real-time, menyiapkan Anda untuk proyek-proyek AI Vision yang lebih kompleks.\nPenerapan Deep Learning dalam Computer Vision: Anda akan belajar tentang Convolutional Neural Networks (CNNs) dan bagaimana deep learning diterapkan dalam computer vision, termasuk studi kasus seperti deteksi wajah pemakai masker.\n\n\nBagian OCR dari pelatihan ini adalah sama pentingnya, dengan fokus pada:\nPengenalan Komprehensif tentang Tesseract OCR: Anda akan mendalami penggunaan Tesseract, salah satu library OCR paling populer, untuk ekstraksi teks dari berbagai media.\nStudi Kasus yang Relevan: Anda akan mengaplikasikan pengetahuan OCR pada studi kasus nyata, seperti ekstraksi teks dari KTP, struk belanja, dan lainnya, yang menunjukkan relevansi keterampilan ini di dunia nyata.\nDengan mengikuti pelatihan ini, Anda tidak hanya memperoleh pengetahuan yang mendalam, tetapi juga keterampilan praktis yang siap diterapkan dalam karir Anda. Jadilah pionir dalam dunia AI Vision dan OCR – daftarkan diri Anda sekarang untuk memulai transformasi karir Anda dengan Pelatihan Inovasi AI Vision dan OCR Menggunakan Python!",
      "target_audience": [
        "Data Science, Data Engineer",
        "Programmer / Developer",
        "Pelajar, Mahasiswa",
        "Pengajar, Dosen dan Peneliti"
      ]
    },
    {
      "title": "数据之纲：建模与架构探秘",
      "url": "https://www.udemy.com/course/azpezeln/",
      "bio": "深入学习如何设计和构建有效的数据模型以及相应的架构",
      "objectives": [
        "帮助学员理解数据建模的概念和作用、理解实体、关系等数据模型组件",
        "帮助学员学习不同层次的数据建模，包括概念、逻辑和物理模型",
        "掌握数据建模的原则、技术，了解数据架构的关键概念和企业数据架构模型，并应用数据架构技能来解决实际业务问题",
        "提升数据建模及数据架构设计能力"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲",
          "引入讲解"
        ],
        "课程内容": [
          "数据建模概念与组件",
          "数据建模方法",
          "数据建模活动与实践",
          "企业数据架构意义",
          "数据架构治理",
          "数据仓库与数据湖",
          "企业数据架构案例"
        ],
        "课程回顾": [
          "课程总结",
          "课后寄语"
        ]
      },
      "requirements": [
        "数据管理基础的人"
      ],
      "description": "本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。\n课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利\n人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课\n公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位\n提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，\n您将承担由此给三节课公司或其他权利人造成的一切损失",
      "target_audience": [
        "适合企业中高级数据治理工程师 适合企业对数据资产管理，数据治理有相关工作的业务人员 适合对数据治理，数据建模，数据架构感兴趣的相关科研人员"
      ]
    },
    {
      "title": "NLP算法——贝叶斯算法入门必备宝典",
      "url": "https://www.udemy.com/course/nlp-wvqi/",
      "bio": "掌握贝叶斯算法操作原理，实现新闻分类任务",
      "objectives": [
        "了解并掌握贝叶斯算法的基本概念与原理",
        "掌握贝叶斯算法的简单应用场景",
        "掌握贝叶斯实现拼写检查器项目的具体操作",
        "结合案例，掌握新闻分类任务的实际应用与操作"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "贝叶斯算法": [
          "贝叶斯算法概述",
          "贝叶斯推导实例",
          "拼写纠错实例",
          "模型比较理论",
          "垃圾邮件过滤",
          "贝叶斯实现拼写检查器"
        ],
        "新闻分类任务实战": [
          "文本分析",
          "关键词提取",
          "相似度计算",
          "新闻数据与任务简介",
          "TF-IDE关键词提取",
          "LDA建模",
          "基于贝叶斯算法进行新闻分类"
        ]
      },
      "requirements": [
        "有一定Python语言基础"
      ],
      "description": "贝叶斯模型发源于古典数学理论、具有稳定的分类效率，与其他分类方法相比，其算法更为简单、误差率更低，可以直接衡量标签和特征之间的概率关系，所以在数据处理分析板块运用十分广泛。\n本门课我们将进行系统的贝叶斯算法学习，课程从贝叶斯算法概述入手，涉及算法推导实例、拼写纠错、垃圾邮件过滤实例、拼写检查器实现等四个部分。\n学员通过完成课程学习，将对贝叶斯算法有更全面的认识与理解，除此之外，课程还穿插了新闻分类任务实战，我们将带领学员串联所学理论知识，实现项目的完整输出，完成贝叶斯算法的学习与应用。",
      "target_audience": [
        "对人工智能-NLP自然语言处理感兴趣的学员",
        "具备一定Python语言基础的学员",
        "计算机相关专业大学生"
      ]
    },
    {
      "title": "Sztuczna Inteligencja w Biznesie - Rozmowa Kwalifikacyjna AI",
      "url": "https://www.udemy.com/course/sztuczna-inteligencja-w-biznesie-rozmowa-kwalifikacyjna-ai/",
      "bio": "Przygotuj się do rozmowy kwalifikacyjnej z wykorzystaniem sztucznej inteligencji (AI) w biznesie!",
      "objectives": [],
      "course_content": {
        "Practice Tests": []
      },
      "requirements": [],
      "description": "Kurs jest specjalnie zaprojektowany dla profesjonalistów, którzy aspirują do roli specjalisty ds. sztucznej inteligencji (AI) w biznesie. Ten innowacyjny kurs skupia się na przygotowaniu kandydatów do skutecznego radzenia sobie z wyzwaniami rekrutacyjnymi, szczególnie podczas rozmów kwalifikacyjnych w dziedzinie sztucznej inteligencji.\nKurs zawiera sześć szczegółowo opracowanych testów praktycznych, które symulują rzeczywiste scenariusze rozmów kwalifikacyjnych. Każdy test składa się z serii pytań, które są często zadawane przez rekruterów w branży AI, zapewniając uczestnikom realistyczne doświadczenie rozmowy kwalifikacyjnej.\nPytania testowe obejmują różnorodne tematy, od podstawowych koncepcji AI, przez jej zastosowania w biznesie, aż po zaawansowane techniki i algorytmy. Uczestnicy kursu nauczą się, jak efektywnie odpowiadać na pytania techniczne, demonstrując przy tym głębokie zrozumienie tematu. Kurs kładzie również nacisk na rozwijanie umiejętności prezentacji projektów AI, dyskusję na temat etycznych wyzwań związanych z AI, oraz wyjaśnianie, w jaki sposób sztuczna inteligencja może przynieść korzyści biznesowi.\nKażde pytanie w testach praktycznych zawiera szczegółowe wyjaśnienia, które nie tylko pomagają zrozumieć prawidłowe odpowiedzi, ale także uczą, jak efektywnie komunikować swoje myśli. Te wyjaśnienia są nieocenionym zasobem wiedzy, dostarczającym kontekstu i głębszego zrozumienia wymaganych kompetencji.\nUkończenie kursu nie tylko przygotowuje uczestników do rozmów kwalifikacyjnych, ale także wzmacnia ich ogólną wiedzę o sztucznej inteligencji i jej zastosowaniach w biznesie. Jest to idealne rozwiązanie dla tych, którzy chcą wyróżnić się na rynku pracy i rozpocząć lub rozwijać swoją karierę w fascynującym świecie AI.\n\n\nCzy mogę przystąpić do testu praktycznego więcej niż raz?\nDo każdego testu praktycznego można przystąpić wielokrotnie. Po ukończeniu testu praktycznego zostanie opublikowany twój ostateczny wynik. Ponadto zostanie wyświetlony stosunek poprawnych odpowiedzi do wprowadzonych nieprawidłowych odpowiedzi, w oparciu o testowany obszar wiedzy. Z każdym przystąpieniem do testu kolejność pytań oraz odpowiedzi jest losowa.\n\n\nCzy mam jakiś limit czasowy na testy praktyczne?\nKażdy test ma wyznaczony limit czasowy.\n\n\nJaki wynik zalicza test praktyczny?\nPoziom zaliczenia każdego testu praktycznego to 70%.\n\n\nCzy pytania są jednokrotnego wyboru?\nAby jak najbardziej odzwierciedlić postać rozmowy kwalifikacyjnej i podnieść poziom trudności pytania są jednokrotnego oraz wielokrotnego wyboru.\n\n\nCzy mogę przejrzeć moje odpowiedzi?\nMożesz przejrzeć wszystkie przesłane odpowiedzi i zobaczyć, które są prawidłowe, a które nie.\n\n\nNie zwlekaj i już dziś podejmij wyzwanie!",
      "target_audience": [
        "Menedżerowie i Liderzy Projektów: Osoby na stanowiskach kierowniczych, które potrzebują lepszego zrozumienia potencjału AI w biznesie, aby efektywnie zarządzać zespołami technicznymi lub prowadzić projekty związane z sztuczną inteligencją.",
        "Specjaliści ds. Sztucznej Inteligencji: Pracownicy, którzy już posiadają podstawową wiedzę o AI i chcą poszerzyć swoje umiejętności, szczególnie w kontekście aplikacji biznesowych i rozmów kwalifikacyjnych, aby awansować na bardziej zaawansowane stanowiska w tej dziedzinie.",
        "Młodzi Profesjonaliści: Osoby, które już pracują w sektorze technologicznym, szczególnie w obszarach takich jak analiza danych, rozwój oprogramowania, inżynieria systemów czy zarządzanie projektami technologicznymi i chcą przebranżowić się lub rozszerzyć swoje kompetencje o specjalizację w AI.",
        "Absolwenci i Studenci Wyższych Uczelni: Osoby, które niedawno ukończyły studia lub są na etapie edukacji wyższej w dziedzinach związanych z informatyką, inżynierią danych, statystyką, matematyką lub pokrewnymi, i które chcą skierować swoją karierę w stronę sztucznej inteligencji w biznesie.",
        "Przedsiębiorcy i Startupowcy: Osoby prowadzące własny biznes lub planujące założenie startupu technologicznego, które chcą wykorzystać AI do innowacji i zyskania przewagi konkurencyjnej na rynku.",
        "Konsultanci i Analitycy Biznesowi: Specjaliści zajmujący się analizą biznesową, którzy chcą zrozumieć, jak sztuczna inteligencja może wpływać na strategie biznesowe i podejmowanie decyzji."
      ]
    },
    {
      "title": "机器学习：经典算法与模型实例",
      "url": "https://www.udemy.com/course/utxzopnu/",
      "bio": "经典算法模型面面俱到",
      "objectives": [
        "掌握机器学习的经典算法模型",
        "熟悉机器学习进阶算法建模流程",
        "了解机器学习经典算法的多种应用场景",
        "可基于经典算法模型对实际数据集进行应用"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "一、决策树算法": [
          "1.决策树算法概述",
          "2.熵的作用",
          "3.决策树构造实例",
          "4.决策树算法",
          "5.决策树剪枝策略",
          "6.回归问题解决"
        ],
        "二、案例实战：决策树构造实例分析": [
          "1.树模型可视化展示",
          "2.决策边界展示分析",
          "3.树模型预剪枝参数作用",
          "4.回归树模型"
        ],
        "三、随机森林与集成算法": [
          "1.随机森林算法原理",
          "2.随机森林优势",
          "3.提升算法概述"
        ],
        "四、基于随机森林的气温预测实战": [
          "1.任务概述",
          "2.基本随机森林模型建立",
          "3.可视化展示与特征重要性",
          "4.加入新的数据与特征",
          "5.数据与特征对结果的影响",
          "6.效率对比分析",
          "7.网格与随机参数选择",
          "8.随机参数选择方法实践",
          "9.调参优化细节"
        ],
        "回顾总结": [
          "课后寄语"
        ]
      },
      "requirements": [
        "熟悉机器学习基本概念"
      ],
      "description": "我们知道，机器学习算法有很多种，每种算法模型的应用场景也有所不同，尽管当前经典算法被广泛使用，但其原理却十分简单。\n本门课程将对机器学习经典算法进行全方位讲解，通过真实案例对决策树算法、随机森林与集成算法以及贝叶斯算法进行深度解读，并将结合数学模型与实际数据集进行实战演练。\n通过本门课程，我们将帮助学员把算法模型融于应用实践，让学员对机器学习经典算法有更加深入的认知，切身体验不同算法的使用场景，最终掌握机器学习的核心技能。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "对人工智能感兴趣的学员",
        "具备一定Python语言基础的学员",
        "计算机相关专业大学生"
      ]
    },
    {
      "title": "Google Document AI e OCR: Lendo imagens utilizando IA v2025",
      "url": "https://www.udemy.com/course/google-document-ai/",
      "bio": "Automatize a extração de dados com Google Document AI e OCR. Aprenda IA para processar documentos de forma inteligente!",
      "objectives": [
        "Dominar o uso do Google Document AI para extração de dados",
        "Implementar OCR inteligente em projetos reais",
        "Automatizar o processamento de documentos com IA",
        "Integrar o Google Document AI com outras aplicações"
      ],
      "course_content": {
        "Introdução": [
          "Apresentação do Curso",
          "Para não perder nenhuma novidade",
          "Artigo Complementar - Referências do projeto",
          "Introdução",
          "Aula 2 - Iniciando a Criação de um processador",
          "Aula 3 - Criando um bucket",
          "Aula 4 - Subindo para o bucket",
          "Aula 5 - Criando um Schema",
          "Criando a estrutura do Bucket",
          "Aula 6 - Rotulando documentos",
          "Aula 7 - Carregando documentos para base de teste",
          "Aula 8 - Exemplo de escala de cinza",
          "Aula 9 - Iniciando treinamento do modelo",
          "Aula 10 - Conceito de Métricas",
          "Aula 11 - Implantando um modelo",
          "Aula 12 - Testando modelo e criando novo campo",
          "Informe os dados do seu modelo treinado"
        ]
      },
      "requirements": [
        "Noções básicas de programação (Python)",
        "Conta no Google Cloud para acessar o Document AI",
        "Conhecimento básico em APIs e requisições HTTP"
      ],
      "description": "Neste curso  , você aprenderá a utilizar o Google Document AI para automação de extração de dados com OCR. A partir da configuração inicial da ferramenta, você será guiado passo a passo na criação e personalização de modelos que permitem a extração de dados de documentos complexos como faturas, contratos, notas fiscais, CNH e muito mais. O treinamento do modelo será abordado de forma clara, ensinando como ajustar e treinar seus modelos para reconhecer informações de diferentes tipos de documentos e em variados formatos.\nCom a integração de inteligência artificial (IA), você será capaz de processar documentos de forma extremamente precisa e eficiente. Ao dominar o uso de OCR e IA, seu fluxo de trabalho será automatizado, reduzindo o tempo necessário para a extração de dados e aumentando a produtividade.\nEste curso é ideal para desenvolvedores, analistas de dados e profissionais que buscam implementar OCR inteligente em seus projetos, além de otimizar processos empresariais. Ao final do curso, você estará preparado para integrar o Google Document AI em soluções personalizadas, elevando a extração de dados a um novo nível de automação e eficiência.\nSe você deseja aprimorar suas habilidades em data science, automação de documentos e inteligência artificial, este curso é para você. Prepare-se para dominar a tecnologia OCR e transformar a maneira como você lida com dados não estruturados.",
      "target_audience": [
        "Desenvolvedores que desejam aprender a usar o Google Document AI para OCR.",
        "Analistas de dados que precisam automatizar a extração de informações.",
        "Profissionais que querem integrar OCR com IA em seus projetos.",
        "Pessoas interessadas em processamento inteligente de documentos."
      ]
    },
    {
      "title": "2021 JSON ve Python ile JSON İşleme + Proje +PDF",
      "url": "https://www.udemy.com/course/json-python-api-entegrasyon-egitimi/",
      "bio": "JSON kodlama eğitimi ve Python - JSON Entegrasyonu , Anlık Verilerle Kriptopara Heaplama Projesi",
      "objectives": [
        "JSON dili",
        "Python JSON kütüphanesi",
        "Python ile JSON dosyaları üzerinde çalışma",
        "JSON dosyası oluşturma"
      ],
      "course_content": {
        "JSON": [
          "JSON Nedir ? Ne İşe Yarar ? Nerelerde Kullanılır ?",
          "JSON ile XML Karşılaştırması",
          "JSON Veri Tipleri",
          "İlk JSON Kodlarım",
          "Online JSON XML Çevirisi ile Sağlama"
        ],
        "Python ile JSON": [
          "JSON Kodlarını Python Değişkeni Haline Getirme",
          "JSON Kütüphanesi ve Loads() Metodu",
          "Dumps() Metodu",
          "JSON Uzantılı Dosyaları Çağırma with open ve Load() Metodu",
          "JSON Kodlarına Ulaşma ve Döngülere Sokma",
          "Veri Ekleme Çıkarma Düzenleme",
          "Ders 12: URL Üzerinden Veri Çekme"
        ],
        "Python ve JSON ile Kripto Para Projesi (Nesne Tabanlı)": [
          "Kriptopara Sınıfını Oluşturalım",
          "__init__ metodu ve self parametresi",
          "URL Getir ve DeğerGetir Metotlarını Oluşturma",
          "BTC cinsinden değer getirme",
          "Metot Parametreleri ve Default Değerler"
        ]
      },
      "requirements": [
        "Temel Python Bilgisi"
      ],
      "description": "JSON yani (JavaScript Object Notation – JavaScript Nesne Notasyonu) data saklama ve data transferi amaçlı kullanılan bir dildir. Yeni nesil web siteleri ve mobil uygulamalar olmak üzere bir çok yazılım bu sistemi kullanmaktadırlar. JSON özellikle API sistemlerinin içerisinde sık sık kullanılmaktadır. Yazılımlar arası entegrasyonlarda ve veri transferlerinde çalışmak isteyen herkesin bilmesi gereken sistemlerden biri olan JSON'u son zamanların en popüler nesne tabalı programlama dillerinden biri olan PYTHON ile birlikte kullanmayı gösteriyorum.\nDersimin ilk bölümü oldukça basit olan JSON dilini sizlere daha basit ancak tüm detaylarıyla amaçlamak üzerine kurdum. Burada da çeşitli örnekler yaparak bilgilerinizi kalıcı bir hale getirmeyi ve gerçek hayatta karşınıza çıkacak durumları ve sorunları çözmeyi amaçladım.\nDersin ikinci bölümünde JSON kodlarını karşımıza çıkabilcek her türlü şekilde python üzerinde kullanabilmeyi ve işleyebilmeyi gösterdim. Burada python kodları ile işlemler yaptığımız için ileri seviyede olmasa bile temel bir python eğitimi ile bu eğitime başlamanızı tavsiye ederim.\nDersin üçüncü bölümünde gerçek hayat problemlerinden biri olan API entegrasyonuyla alakalı olarak JSON kodlarını online bir kaynak üzerinden çekebilmeyi ve çektiğimiz bu dosyaları Python sınıf yapılarını kullanarak nesneler haline getirebilmeyi öğretmeyi amaçlayan bir proje hazırladım.\nDersin dördüncü bölümünde ise eğitim süresince veya eğitim sonrasında karşınıza çıkan JSON ve Python-Json kullanımı ile alakalı çözemediğiniz problemleri video şeklinde sizlere açıklamayı amaçladım.\n\n\nEğitimlerin özellikle de dijital eğitimlerin sürekli gelişmesi ve güncellenmesi gerektiğini düşünüyorum. Bu amaçla diğer eğitimlerimde olduğu gibi bu eğitimi de sürekli güncel tutmak niyetindeyim. Derste görüşmek üzere kendinize iyi bakın.",
      "target_audience": [
        "Orta ve üzeri seviyede python kullanıcıları"
      ]
    },
    {
      "title": "R ilə proqramlaşdırma, Data və Statistiksəl analizlər",
      "url": "https://www.udemy.com/course/r-il-proqramlasdrma-data-v-statistiksl-analizlr/",
      "bio": "Proqramlaşdırmayı R və R studio ilə öyrən. Data Analizi, Data Elmi, Statistiksəl Analizlər, Funksiyalar, Paketlər",
      "objectives": [
        "R proqramlaşdırma dilini anlamaq",
        "R dakı paketlər vasitəsilə sahənizdə daha çox professionallaşmaq",
        "Statistiksəl analiz metodları",
        "R interfeysi",
        "R ın təməl işləyişi və funksiyaları haqqında bilgi sahibi olmaq",
        "Data Çərçivələri",
        "İf else şərti funksiyaları",
        "Data vizuallaşdırılması üçün qrafik və sxemlər",
        "Data manipulyasiyası",
        "Reqresiya testləri",
        "Matrikslər",
        "R da təməl riyazi/ statistiksəl funksiyalar",
        "Funksiyalar",
        "Qərar Ağacları"
      ],
      "course_content": {
        "R ilə ümumi Tanışlıq": [
          "R ilə ümumi Tanışlıq"
        ],
        "R konsol və R studio yüklənməsi, qurulumu": [
          "R- ın qurulması"
        ],
        "Təməl kod yazma qaydaları": [
          "Dəyişkənlərə dəyər vermək, riyazi işləmlər",
          "Dəyişkənlər",
          "Vektorlar",
          "Dəyişkənlər / Vektorlar"
        ],
        "Data tipləri və Datanın yönləndirilməsi": [
          "Listlər",
          "Matrikslər",
          "Sıralar",
          "Faktorlar",
          "Data Çərçivələri",
          "Operatorlar",
          "If/else şərti döngülər",
          "Döngülər",
          "Funksiyalar",
          "R paketləri",
          "Datanın Oxudulması",
          "Data Manipulyasiyası",
          "3. Hissə üçün quiz"
        ],
        "Qrafiklər və Sxemlər": [
          "Qrafiklər və Sxemlər 1",
          "Qrafiklər və Sxemlər 2",
          "Qrafiklər və Sxemlər 3"
        ],
        "Statistiksəl Metodlar": [
          "Statistikaya əsaslanan funksiyalar",
          "Normal ehtimal paylanması",
          "Korrelyasiya",
          "T-test",
          "Xətti Reqresiya",
          "Çoxlu Xətti Reqresiya",
          "Qərar Ağacları",
          "Ki-Kare (Ki-kvadrat) testləri"
        ]
      },
      "requirements": [
        "Kompyuteriniz ( hansı model olması heç fərq etmir) və internetiniz olmalıdır",
        "Çalışma və araşdırma əzminiz olması kifayətdir",
        "Dərsləri dinləyərkən paralel olaraq kodlamanız sizə avantajdır"
      ],
      "description": "Salam hamıya,\nR ilə proqramlaşdırma, Data və Statistiksəl analizlər kursuna xoş gəlmisiniz.\nR Proqramlama kursu, data analizi sahəsində ixtisaslaşmaq istəyənlərin ilk başlanğıc nöqtəsi ola biləcək bir kursdur.\nR proqramını digər yazılım proqramlarından fərqli edən ən önəmli xüsusiyyət, R proqramının həm yazılım, həm data bazası, həm  statistika, həm də data mining və sosial şəbəkə analizi sahələrində eyni anda çox güclü analiz texnikaları və görsəlləşdirmə imkanları təqdim etməsidir.\nKurs kimlərə üstünlük verir?\nProqramlaşdırmada və ya R-da yeni olsanız da  kursumuz, çox qısa müddətdə hər kəsi R-da effektiv hala gətirməyi planlayır.\nƏn əsas səvviyədən başlayaraq addım-addım irəlilədiyimiz kurs ilə;\n-R proqramlama dilini anlayacaq,\n-R'ın əsas funksiyaları haqqında məlumat sahibi olacaq,\n-R'daki paketlər vasitəsilə öz sahənizdə daha çox ixtisaslaşma imkanına sahib olacaqsınız.\nBu təlimlə yalnızca R proqramlama dilinin necə işlədiyi haqqında ətraflı bir fikir sahibi olmaqla qalmayacaq, həmçinin R proqramlama dilində ən çox üzləşdiyiniz əsas suallarınıza da cavablar tapacaqsınız.\nTəlimimiz həm R proqramlama dilinə yeni giriş edəcəklər, həm də aktiv iş həyatında R proqramından istifadə edən və biliklərini təzələmək istəyən, yəni bütün R maraqlıları üçün böyük bir mənbədir.\nBu təlimə;\nData analizinə maraqlı tələbələr,\nNəqliyyatçılar,\nBöyük data yəni big data ilə məşğul olan analistlər,\nŞirkətlərindəki xalisliyi artırmaq istəyən xüsusi şirkət menecərləri\nR proqramlama dilini öyrənmək istəyən proqramçılar və R-a marağı olan hər kəs qoşula bilər.",
      "target_audience": [
        "Tələbələr",
        "Kompyuter, data sahəsində irəliləmək istəyən bütün şəxslər",
        "0 dan kodlamaya başlayanlar üçün",
        "Data dünyasına, elminə giriş etmək istəyənlər",
        "Kodlama və data ilə bir az bilgisi olub daha çox professionallaşmaq istəyənlər"
      ]
    },
    {
      "title": "Derin Öğrenme ile Arazi Sınıflandırması (Arcgis Pro 3.4)",
      "url": "https://www.udemy.com/course/derin-ogrenme-ile-arazi-snflandrmas-arcgis-pro-34/",
      "bio": "Arcgis Pro'da Derin Öğrenme (Yapay Zeka ) Modülü kullanılarak Arazi Sınıflandırması Nasıl Yapılır",
      "objectives": [
        "Uydu Görüntüsü ve Hava Fotografı İndirme",
        "Derin Öğrenme Metodu (Yapay zeka)",
        "Arcgıs Proda Derin Öğrenmeyi Kullanma",
        "Arazi Sınıflandırması, Analiz ve Profesyonel Harita Üretme"
      ],
      "course_content": {
        "Giriş": [
          "Derin Öğrenme modülü Nedir",
          "Arcgis Proya Derin öğrenme Modülü Yükleme ve Çalıştırma",
          "Veri Temin etme ( download)"
        ],
        "Arcgis Pro da Derin Öğrenme ile Arazi Sınıflandırması": [
          "Eğitim Örnekleri Yöneticisi Kullanma (Eğitim verisi hazırlama)",
          "Eğitim Örneklerini Export etmek",
          "Derin Öğrenme ile Eğitme",
          "Derin Öğrenmeyi Kullanarak Arazi Örtüsü Sınıflandırma"
        ],
        "Analiz ve Haritalama": [
          "Arcgıs Pro da Harita Üretimi-1",
          "Arcgıs Pro da Harita Üretimi-2"
        ]
      },
      "requirements": [
        "Arcgis Pro yu temel düzeyde kullanıyor olmak",
        "Derin öğrenme hakkında bilgiye sahip olmak"
      ],
      "description": "Bu Kurs Kapsamında Arcgis Pro kullanarak  Derin öğrenme  ile Arazi Sınıflandırması Nasıl yapılır bunu öğreneceksiniz. İlk olarak  Derin Öğrenme hakkında teorik bilgiler verilecek ve  Derin öğrenme Modülü indirilerek  Arcgis proya entegre edilecektir.  Bu modül kullanılarak  uydu görüntülerinden  eğittiğiniz piksel verilerle bilinmeyen  arazi sınıflarını  tanımlayacaksınız kendi oluşturduğunuz model ile   farklı  uydu  görüntülerini otomatik analiz etmeyi  öğreneceksiniz   ve  aynı zamanda  Sıfırdan başlayarak   Yapay Zekanın  Coğrafi Bilgi Sisteminde   nasıl kullanıldığı  ve avantajlarını  bu örnek ile  kavramış olacaksınız  bu çalışmamızdan hareketle,  farklı  kendi belirlediğiniz  konularda ArcGis Pro ortamında  derin öğrenme  yöntemi kullanarak   analizler ve haritalamalar yapabileceksiniz . Coğrafi Bilgi Sistemlerinin   Haritanın ötesinde bir sistem olduğunu  yaparak yaşayarak  öğreneceksiniz.   Yüksek Lisans ve Doktora Tezleriniz de proje ve makalelerinizde  Derin öğrenme ile  çalışmak isteyen   bütün  arkadaşlarımızı  kursumuza davet ediyoruz.   Kurs Basitten karmaşığa gidecek şekilde   hiyerarşik bir  planla hazırlanmıştır.   en ince ayrıntısına kadar  modül üzerinde  durulmuştur.\nİŞ akışı : Uydu Görüntüsü   İndirme, Görüntüyü kesme,  Görüntü üzerinde eğitim verilerini   hazırlama , Verileri Eğitme\nEğitilmiş verilerle raster görüntüde  arazi sınıflandırması yapma , arazi sınıflarını alan ve oransal olarak analiz etme\nKursta kullanılan örnek veriler ilgili dersin kaynak kısmına yüklenmiştir. Alıştırma yapmak isteyenler buradan indirerek çalışabilirler. Kurs ile ilgili olumlu ve olumsuz geri dönüşlerinizi yorum olarak belirtebilir ayrıca sormak istediğiniz soruları soru-cevap kısmından ya da mesaj yoluyla bana iletebilirsiniz\nEğitmen : Mehmet ÇAVUŞ\nCoğrafya Öğretmeni",
      "target_audience": [
        "veri bilimcileri, jeologlar, peyzaj mimarları, Şehir planlamacıları , coğrafyacılar",
        "Haritacılar"
      ]
    },
    {
      "title": "تعلم خوارزميات الذكاء الاصطناعى وتنبؤ البيانات بالويكا",
      "url": "https://www.udemy.com/course/data-mining-and-machine-learning-with-weka-gui-interface/",
      "bio": "Weka لإنشاء نماذج الخوارزميات التنبؤية انطلق بدورة التعلم الآلي الخاصة بك مع",
      "objectives": [
        "التنقيب عن البيانات ومفهوم التعلم الآلي",
        "كيفية تثبيت أداة Weka لاستخراج البيانات",
        "مصادر البيانات وتنسيق الملف المألوف في Weka",
        "كيف تضيف ملحقات لأداة Weka لضبط أداء وحدات التنبؤ",
        "كيف يمكننا إجراء معالجة مسبقة على مجموعة البيانات باستخدام Weka واستراتيجياتها",
        "كيف يمكن استخدام استخراج الميزات مع weka واستخدام طرق متعددة لذلك على مجموعة البيانات الرقمية والصور",
        "كيف يمكن عمل وحدة خاضعة للإشراف وغير خاضعة للإشراف مع التصنيف والعناقيد في Weka",
        "كيف يمكن ملاءمة وحدة التنبؤ الخاصة بنا واستخراج نموذج التصور Weka",
        "قم بالتجربة ومقارنة الخوارزميات في Weka"
      ],
      "course_content": {
        "Introduction": [
          "welcome to machine learning course | اهلا بك فى كورس تعلم الالة"
        ],
        "Concept of Machine Learning": [
          "Understanding component of machine learning |اساسيات تعلم الالةوالخوارزميات",
          "types of machine learning | انواع خورازميات تعلم الالة"
        ],
        "practice with weka": [
          "what's weka ? | ماهو برنامج الويكا ؟",
          "how to download and install weka ? | كيفية تحميل برنامج الويكا وتشغيله على جهازك",
          "Weka's data sources and file formats| كيفيةالتعامل مع ملف امتداد الويكا",
          "Weka's Package Manager | كيفية التعامل مع اضافات خارجيه للويكا",
          "Weka's Preprocessing of data | كيفية تجهيز بياناتك للتصنيف داخل الويكا",
          "How use filters in remove duplicate data in weka ? |تنقيه البيانات من التكرار",
          "weka classification | تصنيف البيانات",
          "weka associate rule algorithms",
          "weka clusters",
          "weka visualization"
        ],
        "Experiment # / Image classification": [
          "Image analysis & classification & prediction"
        ]
      },
      "requirements": [
        "اتصال الكمبيوتر والانترنت"
      ],
      "description": "- اهلا بكم فى اول كورس عربى نقوم من خلاله بشرح مبادئ لغه تعلم الاله وجميع الخوارزميات الخاصه به لكى نستطيع ان نوفر ماده عربيه بشرح مبسط وسهل لجميع الطلاب العرب من جميع المستويات الدراسيه وايضا الباحثين العرب الذين يقومون باستخدام خوارزميات تعلم الالة فى ابحاثهم .\n- سوف نيسر عليك فى هذا الكورس كيفيه استخدام خوارزميات تعلم الالة وتطبيقها عن طريق برنامج ويكا ولاتقلق عزيزى الطالب/ الباحث فانك لن تتورط فى كتابه كود برمجى واحد لتصل الى هدفك فى تطبيق هذه الخوارزميات .\n- سوف اشرح لك مبادئ تعلم الالة وتنفيذها على برنامج مفتوح المصدر (ويكا) وامكنك بالتدريب العملى من تجميع مصادر معلومات ووضعها داخل البرنامج وكيفيه عمل تنقيح لبياناتك وايضا كيفيه تجهيز بياناتك لاستخراج افضل العناصر المؤثرة والتى يتم عليها اتخاذ قرار التصنيف فى عمليه classification\n- سوف نتعلم تطبيق خوارزميات التصنيف المتعدده مثل c4.5-knn-cnn-MLP-NB\n- كيفية استخلاص نتائج الخوارزميات المطبقة على البيانات وال charts الخاصه بها وكيفيه تقييم المصنف والتعديل عليه لتصل الى افضل النتائج التصنيفية فى دراساتك .\nستساعد هذه الدورة التمهيدية في جعل تجربة مفهوم علم البيانات والتعلم الآلي بسيطة ومثيرة. سوف تتعلم من خلال\n\n\nباستخدام برنامج التعلم الآلي الشهير Weka مفتوح المصدر الذي طورته جامعة وايكاتو في نيوزيلندا. أداة weka مبنية على أساس مكتبة جافا ولكن لا تقلق فلا داعي لأن تكون مبرمج جافا للتعامل مع ويكا ، بسبب واجهة المستخدم الرسومية البسيطة.\n\n\nبطريقة بسيطة وغير معقدة ، يمكنك تعلم عادات الخوارزمية المعقدة. استخدام مرافق Weka المتخصصة لإجراء تجارب التعلم الآلي من أجل فهم الخوارزميات والمصنفات ، مثل\n\n\n(Naive Bayes ، Neural Network ، J48 ، KNN ، الانحدار الخطي).\n\n\nسوف تتدرب على تصنيف الصورة ، نص مجموعة البيانات الحقيقية\n\n\nوسوف تتعلم كيفية تحويل ملفات مصدر البيانات إلى ملف ARFF واحد (تنسيق ضعيف)\n\n\nفيما يتعلق بمفهوم مناهج التعلم الآلي supervised-unsupervised",
      "target_audience": [
        "أي شخص لديه فضول حول أداة خوارزميات التعلم الآلي بدون برمجة.",
        "أي شخص يريد تعلم مفهوم هندسة البيانات وعلوم البيانات باستخدام أداة واجهة المستخدم الرسومية"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第25部 使用Pytorch編寫 Stable Diffusion 下部",
      "url": "https://www.udemy.com/course/generative_ai_25/",
      "bio": "關於 Stable Diffusion，U-NET，DDPM，TimeSteps，CLIP，VAE，Classifier Free Guidance，Pytorch",
      "objectives": [
        "如何在僅用 Pytorch 編寫 Stable Diffusion 架構和組件",
        "如何用 Pytorch 編寫 DDPM 實現模型學習 Latent Space 數據分佈",
        "如何用 Pytorch 編寫 Diffusion 實現 U-NET 功能",
        "如何用 Stable Diffusion 在 VSCode 按照 Prompt 生成圖片"
      ],
      "course_content": {
        "介紹": [
          "課程工具準備",
          "如何使用uv 作為包管理器和項目管理工具"
        ],
        "UNET 的原理 & 如何用 Pytorch 實現 U-NET": [
          "UNET 是什麼 & 如何用 Pytorch 融合時間步 Time Steps 融合到輸入特徵 Features 當中",
          "如何將 CLIP 處理的 Prompt 和圖片像素加入到 Attention 注意力機制中",
          "如何處理 U-NET 中的 Encoder & Bottle Neck & Decoder 之間的邏輯關係"
        ],
        "如何組織 CLIP，UNET，VAE 等模型生成/推理圖片": [
          "UNET 的OutputLayer 做的是什麼 & 如何處理 Classifier free guidance 的邏輯",
          "如何實現前向擴散 & 逆擴散的核心步驟",
          "如何組織所有CLIP & VAE & UNET & Pretrain models 生成圖片"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "繼續在(Ken Cen出品)Generative AI第24部 使用Pytorch編寫 Stable Diffusion 上部的基礎上，實現整個 Diffusion，擴散過程和 DDPM 實現模型學習 Latent Space 數據分佈過程，這是 Stable Diffusion 中的核心關鍵。\n\n\n課程不使用其他外部 library，以 Pytorch 作為底層構建 Stable Diffusion 所需一切組件，最終將根據用戶的 prompt 在 VSCode 中生成圖片。\n\n\n從 U-NET 開始構建，創建 U-NET 內部的Encoder，Bottle Neck， Decoder，了解內容結構\n如何讓 U-NET 以用不同參數餵養Encoder，Bottle Neck， Decoder，以及每個組件中，如何搭配 Self-Attention & Cross-Attention 和 Residual\n用 Pipeline 組織 CLIP，VAE，U-NET，根據不同的Classifier Free Guidance 輸出不同的雜訊預測，結合 Context 輸入得到 U-NET 的輸出\n最終輸入 Stable Diffusion 預訓練模型的權重，按Prompt 生成圖片。",
      "target_audience": [
        "AI/ML 研究者與工程師",
        "產品經理與創意設計師",
        "數據科學家與視覺工程師",
        "所有對 AI 藝術與創新應用有興趣者"
      ]
    },
    {
      "title": "Les bases de Python",
      "url": "https://www.udemy.com/course/les-bases-de-python-n/",
      "bio": "Testez votre maîtrise du langage !",
      "objectives": [],
      "course_content": {
        "Practice Tests": []
      },
      "requirements": [],
      "description": "Cet exercice est composé de questions à choix multiples qui couvrent les concepts fondamentaux du langage Python. En répondant à ces questions, vous pourrez évaluer votre maîtrise des sujets suivants :\nVariables et types de données : Comprendre comment stocker des informations (nombres, texte, listes, dictionnaires) et manipuler leurs types.\nOpérateurs : Reconnaître les différents symboles utilisés pour les opérations mathématiques, les comparaisons et les manipulations de données.\nFonctions : Savoir comment créer et utiliser des fonctions pour rendre votre code plus propre et réutilisable.\nBoucles et Conditions : Apprendre à contrôler le flux de votre programme, que ce soit pour répéter des tâches ou exécuter du code selon des conditions spécifiques.\nProgrammation Orientée Objet (POO) : Découvrir comment structurer votre code en utilisant des classes et des objets pour une organisation plus logique et modulaire.\nConcepts Avancés et Utilitaires : Explorer des techniques comme la manipulation de chaînes de caractères, les opérateurs logiques (and, or, not), l'utilisation de la fonction range() et les compréhensions de listes.\nCet exercice est idéal pour vous si vous êtes :\nDébutant·e en Python et souhaitez consolider vos acquis.\nEn train d'apprendre les bases et cherchez un moyen de vérifier votre compréhension.\nCurieux·se de découvrir le langage et voulez un aperçu des concepts de base.\nL'objectif n'est pas de vous piéger, mais de vous aider à identifier les domaines que vous maîtrisez déjà et ceux qui nécessitent un peu plus de travail. Chaque question inclut une explication détaillée pour vous aider à comprendre la bonne réponse.\nBonne chance !",
      "target_audience": [
        "Tout personne voulais tester sa maîtrise des bases du Python"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第27部 強化學習模型RLHF 與 策略梯度優化",
      "url": "https://www.udemy.com/course/generative_ai_27/",
      "bio": "關於 Reward Model 獎勵模型，Trajectory 軌跡，Q function Q 函數， Value function 價值函數， Advantage function 優勢函數， Offline Policy 離線策略",
      "objectives": [
        "深入解析強化學習（Reinforcement Learning, RL）算法",
        "深入解析如何構建獎勵模型",
        "深入解析計算軌跡（Trajectories）及其在RL中的作用",
        "深入解析Off-Policy Learning 離線策略學習 和 Importance Sampling 重要性採樣"
      ],
      "course_content": {
        "課程準備": [
          "課程工具準備",
          "如何使用uv 作為包管理器和項目管理工具"
        ],
        "如何構建獎勵模型": [
          "如何構建Reward Model 獎勵模型"
        ],
        "如何計算軌跡（Trajectories）及其在RL中的作用": [
          "如何計算軌跡（Trajectories）及其在RL中的作用"
        ],
        "什麼是強化學習（Reinforcement Learning, RL）演算法 & 什麼是策略梯度優化": [
          "什麼是強化學習（Reinforcement Learning, RL）演算法 & 什麼是策略梯度優化"
        ],
        "什麼是 Advantage function 優勢函數& Q function Q 函數 & Value function 價值函數": [
          "什麼是 Advantage function 優勢函數& Q function Q 函數 & Value function 價值函數"
        ],
        "什麼是 Off-Policy Learning 離線策略學習 和 Importance Sampling 重要性採樣": [
          "什麼是 Off-Policy Learning 離線策略學習 和 Importance Sampling 重要性採樣"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "在本課程中，我們將深入學習一系列強化學習（Reinforcement Learning, RL）中至關重要的核心概念與技術。理解以下主題的原因不僅是為了能夠實作一個完整的 RLHF（Reinforcement Learning with Human Feedback）系統，更是為了從根本上理解語言模型在實際應用中如何被微調與優化，以符合人類偏好。\n課程內容：\n如何構建 Reward Model（獎勵模型）\n在傳統監督式學習中，我們依賴標註資料來告訴模型什麼是對的；但在 RLHF 中，我們使用獎勵模型來評估模型行為的好壞\n\n\n如何計算 Trajectories（軌跡）及其在 RL 中的作用\n在 RL 中，模型與環境互動後會產生一連串狀態、動作、獎勵的序列，這稱為一條軌跡（trajectory）\n這些軌跡是我們計算期望報酬、策略更新、模型訓練的依據\n\n\n什麼是強化學習（RL）演算法 & 策略梯度優化\n強化學習讓模型可以透過與環境互動逐步學習「好的策略」\n策略梯度（Policy Gradient）是一種重要方法，能夠直接對模型輸出機率進行優化，使其更可能產生高獎勵的行為\n\n\n什麼是 Advantage Function、Q Function 和 Value Function\nValue function 評估某個狀態的「長期價值」。\nQ function 評估某個狀態下，採取某個動作的價值\nAdvantage function 則比較某動作相對於平均策略的好壞，是降低估計方差的關鍵\n\n\n什麼是 Off-Policy Learning & Importance Sampling\nOff-policy learning 讓我們可以使用「非當前策略」產生的軌跡來訓練模型，提高數據利用率\nImportance sampling 則是數學工具，讓我們能夠糾正這種策略不一致所產生的偏差",
      "target_audience": [
        "自然語言處理工程師與研究員",
        "強化學習愛好者與開發者",
        "AI安全與對齊研究者",
        "具備基礎機器學習知識，想深入強化學習理論與實踐者"
      ]
    },
    {
      "title": "(Ken Cen 出品) Generative AI 第 33 部：用英偉達CUDA C加速 AI - GPU底層核心",
      "url": "https://www.udemy.com/course/generative_ai_33/",
      "bio": "關於 英偉達 Nvida CUDA C，GPU acceleration，C 語言，AI acceleration，GPU programming，Deep learning GPU，Parallel computing",
      "objectives": [
        "瞭解如何嵌套 Pointer & 如何使用 Void & 如何避免無效地址",
        "瞭解 什麼是 CUDA ？CPU 和 GPU 架構的差異和設計意義",
        "瞭解如何處理 CUDA 錯誤 & 如何在 GPU 上實現 CUDA Kernel 核心代碼編寫",
        "瞭解如何在 Google Colab 上運行CUDA C 代碼"
      ],
      "course_content": {
        "課程編譯環境設定": [
          "課程需要軟體的安裝",
          "如何在Mac 上設定 C 語言編譯環境 & 編寫第一個C 語言代碼",
          "如何在 Windows 設定 C/C++ 環境"
        ],
        "掌握 C / C++ 的基礎": [
          "如何嵌套 Pointer & 如何使用 Void & 如何避免無效地址",
          "如何使用 Matrix陣列 & Struct 結構體 & Marcos 宏參數"
        ],
        "什麼是 CUDA？CPU 與 GPU 的差異 & 如何編寫 CUDA C": [
          "什麼是 CUDA ？CPU 和 GPU 架構的差異和設計意義",
          "如何處理 CUDA 錯誤 & 如何在 GPU 上實現 CUDA Kernel 核心代碼編寫",
          "如何在 Google Colab 上運行CUDA C 代碼"
        ]
      },
      "requirements": [
        "一臺電腦"
      ],
      "description": "在 Ken Cen 的 Generative AI 系統課程中，我們從瞭解 AI 鏈接工具 -> AI 模型架構，現在，我們將更進入一步，看看如何使用 GPU 底層核心強大的平行運算優勢來實現 AI 的功能。\n由於有別與之前課程，本課程我們需要學習 C/C++ 語言。在掌握基本的功能和使用後，我們開始對比 CPU 和 GPU 的設計差異，以及這樣設計各有什麼好處。這對我們深入瞭解 CUDA 核心編程很有好處。\n接著，我們會直接從實作入手，看看 CUDA 編程的各個組成部分，以及實現方式。\n想在 AI 領域更進一步的學員，切勿錯過！～",
      "target_audience": [
        "對人工智能感興趣的學員",
        "對英偉達 CUDA 底層核心編程感興趣的學員",
        "想進一步深入瞭解 如何使用 CUDA 開發人工智能架構的學員"
      ]
    },
    {
      "title": "[DE] KI-Masterclass: Vom Anfänger zum KI-Helden",
      "url": "https://www.udemy.com/course/ki-ingenieurwesen-masterclass-vom-anfanger-zum-ki-helden/",
      "bio": "Meistere KI-Engineering: Entwickle skalierbare KI-Lösungen mit echten Projekten und praktischem Lernen (AI)",
      "objectives": [
        "Erstelle KI-Modelle mit Python, TensorFlow und PyTorch, um intelligente Systeme zu entwickeln, die reale Probleme lösen können",
        "Vorverarbeite, bereinige und analysiere komplexe Datensätze, um hochwertige Eingabedaten für das Training von KI- und Machine-Learning-Modellen sicherzustellen",
        "Trainiere, evaluiere und optimiere Machine-Learning-Modelle für Aufgaben wie Regression, Klassifikation und Clustering",
        "Entwerfe, implementiere und feintune neuronale Netzwerke, einschließlich CNNs und RNNs, für fortgeschrittene KI-Anwendungen",
        "Wende Techniken der natürlichen Sprachverarbeitung (NLP) an, um menschenähnliche Texte zu analysieren, interpretieren und generieren",
        "Nutze Transfer Learning, um vortrainierte KI-Modelle für neue Aufgaben anzupassen und Entwicklungszeit sowie Ressourcen zu sparen",
        "Setze KI-Modelle mit skalierbaren APIs und Container-Tools wie Docker ein, um eine nahtlose Integration in Anwendungen zu ermöglichen",
        "Überwache die Leistung von KI-Modellen, erkenne Datenabweichungen und etabliere Workflows zum erneuten Training für zuverlässige Ergebnisse",
        "Löse reale geschäftliche und technische Herausforderungen mit KI-gestützten Ansätzen und intelligenten Systemen",
        "Entwickle durchgängige KI-Projekte – von der Ideenfindung und dem Prototyping bis hin zur Bereitstellung und langfristigen Wartung"
      ],
      "course_content": {
        "Einführung in den Kurs": [
          "Einführung in die Masterclass für KI-Engineering: Von Null zum KI-Held",
          "Kursressourcen – Folien und Code-Dateien"
        ],
        "Woche 1: Python-Grundlagen für Künstliche Intelligenz": [
          "Einführung in Woche 1 – Python-Grundlagen",
          "Tag 1: Einführung in Python und Einrichtung der Entwicklungsumgebung",
          "Tag 2: Kontrollstrukturen in Python",
          "Tag 3: Funktionen und Module",
          "Tag 4: Datenstrukturen (Listen, Tupel, Dictionaries, Sets)",
          "Tag 5: Arbeiten mit Strings",
          "Tag 6: Dateiverwaltung",
          "Tag 7: Pythonischer Code und Projektarbeit"
        ],
        "Woche 2: Data-Science-Grundlagen für Künstliche Intelligenz": [
          "Einführung in Woche 2 – Data Science Essentials",
          "Tag 1: Einführung in NumPy für numerische Berechnungen",
          "Tag 2: Erweiterte NumPy-Operationen",
          "Tag 3: Einführung in Pandas für Datenmanipulation",
          "Tag 4: Datenbereinigung und -vorbereitung mit Pandas",
          "Tag 5: Datenaggregation und Gruppierung mit Pandas",
          "Tag 6: Datenvisualisierung mit Matplotlib und Seaborn",
          "Tag 7: Exploratives Datenanalyseprojekt (EDA)"
        ],
        "Woche 3: Mathematik für Machine Learning und KI": [
          "Einführung in Woche 3 – Mathematik für ML",
          "Tag 1: Grundlagen der linearen Algebra",
          "Tag 2: Erweiterte lineare Algebra",
          "Tag 3: Analysis für ML – Ableitungen",
          "Tag 4: Analysis – Integrale und Optimierung",
          "Tag 5: Wahrscheinlichkeitstheorie und Verteilungen",
          "Tag 6: Statistik-Grundlagen",
          "Tag 7: Mathematisches Mini-Projekt – Lineare Regression von Grund auf"
        ],
        "Woche 4: Wahrscheinlichkeit und Statistik für ML & KI": [
          "Einführung in Woche 4 – Wahrscheinlichkeit & Statistik",
          "Tag 1: Zufallsvariablen und Wahrscheinlichkeitstheorie",
          "Tag 2: Wahrscheinlichkeitsverteilungen im ML",
          "Tag 3: Statistische Inferenz – Schätzung & Konfidenzintervalle",
          "Tag 4: Hypothesentests und p-Werte",
          "Tag 5: Arten von Hypothesentests",
          "Tag 6: Korrelations- und Regressionsanalyse",
          "Tag 7: Statistikprojekt – Analyse realer Datensätze"
        ],
        "Woche 5: Einführung in Machine Learning": [
          "Einführung in Woche 5 – ML",
          "Tag 1: Grundlagen und Begriffe im Machine Learning",
          "Tag 2: Überwachtes Lernen & Regressionsmodelle",
          "Tag 3: Erweiterte Regression – Polynom & Regularisierung",
          "Tag 4: Klassifikation & Logistische Regression",
          "Tag 5: Modellbewertung & Cross-Validation",
          "Tag 6: k-Nearest-Neighbors (k-NN) Algorithmus",
          "Tag 7: Mini-Projekt: Überwachtes Lernen"
        ],
        "Woche 6: Feature Engineering & Modellbewertung": [
          "Einführung in Woche 6 – Feature Engineering & Bewertung",
          "Tag 1: Einführung in Feature Engineering",
          "Tag 2: Skalierung und Normalisierung von Daten",
          "Tag 3: Kodierung kategorialer Variablen",
          "Tag 4: Techniken zur Merkmalsauswahl",
          "Tag 5: Erstellung & Transformation von Merkmalen",
          "Tag 6: Bewertungsverfahren für Modelle",
          "Tag 7: Cross-Validation & Hyperparameter-Tuning"
        ],
        "Woche 7: Fortgeschrittene ML-Algorithmen": [
          "Einführung in Woche 7 – Fortgeschrittene Algorithmen",
          "Tag 1: Einführung in Ensemble Learning",
          "Tag 2: Bagging & Random Forests",
          "Tag 3: Boosting & Gradient Boosting",
          "Tag 4: Einführung in XGBoost",
          "Tag 5: LightGBM & CatBoost",
          "Tag 6: Umgang mit unausgeglichenen Daten",
          "Tag 7: Ensemble-Projekt – Modellvergleich auf echtem Datensatz"
        ],
        "Woche 8: Modelloptimierung & Feintuning": [
          "Einführung in Woche 8 – Modelloptimierung",
          "Tag 1: Einführung in Hyperparameter-Tuning",
          "Tag 2: Grid Search & Random Search",
          "Tag 3: Bayessches Tuning fortgeschritten",
          "Tag 4: Regularisierungstechniken",
          "Tag 5: Cross-Validation & Bewertung",
          "Tag 6: Automatisches Tuning mit GridSearchCV & RandomizedSearchCV",
          "Tag 7: Optimierungsprojekt – Finale Modellanpassung"
        ],
        "Woche 9: Neuronale Netze & Deep Learning Grundlagen": [
          "Einführung in Woche 9 – Neuronale Netze",
          "Tag 1: Einführung in Deep Learning & Netzwerke",
          "Tag 2: Forward Propagation & Aktivierungsfunktionen",
          "Tag 3: Verlustfunktionen & Backpropagation",
          "Tag 4: Gradientenabstieg & Optimierung",
          "Tag 5: Netzwerke mit TensorFlow & Keras",
          "Tag 6: Netzwerke mit PyTorch",
          "Tag 7: Projekt – Bildklassifikation mit CIFAR-10"
        ]
      },
      "requirements": [
        "Grundkenntnisse in Programmierung: Grundkenntnisse in Python sind empfehlenswert, aber nicht zwingend erforderlich.",
        "Neugier und Begeisterung: Eine Leidenschaft für KI und die Bereitschaft zu lernen sind entscheidend.",
        "Zugang zu einem Computer: Ein Computer mit Internetzugang und ausreichender Rechenleistung für KI-Aufgaben.",
        "Keine Vorkenntnisse in KI erforderlich: Der Kurs beginnt mit grundlegenden Konzepten und baut schrittweise auf.",
        "Grundlegende Mathematikkenntnisse: Verständnis von Mathematik auf Schulniveau (z. B. Algebra, einfache Statistik).",
        "Stabile Internetverbindung: Für den Zugriff auf Kursmaterialien, Tools und praktische Projekte.",
        "Optionale Tools: Installation von Python, Jupyter Notebook und relevanten KI-Bibliotheken (Anleitung im Kurs enthalten).",
        "Offene Denkweise: Sei bereit, zu erkunden, zu experimentieren und reale KI-Anwendungen zu entwickeln."
      ],
      "description": "Dieser Kurs wird mithilfe einer KI vom Englischen ins Spanische übersetzt, sodass Sie modernste Technologien in Ihrer Muttersprache erlernen können.\nWillkommen zur Masterclass in KI-Engineering: Von Null zum KI-Held!\nDieser umfassende Kurs nimmt dich mit auf eine spannende Reise – vom absoluten Anfänger bis zum selbstbewussten KI-Ingenieur. Du wirst lernen, wie man KI-Lösungen entwickelt, trainiert und skaliert, um reale Herausforderungen zu meistern. Ob du gerade erst anfängst oder deine Fähigkeiten vertiefen willst – diese Masterclass bietet dir eine klare, strukturierte Lernreise zum Erfolg.\nIn dieser Masterclass beginnst du mit den Grundlagen der KI – Python-Programmierung, Datenvorverarbeitung und den Basics des maschinellen Lernens. Schritt für Schritt steigst du in fortgeschrittene Themen ein wie neuronale Netze, Deep Learning, natürliche Sprachverarbeitung (NLP) und Computer Vision. Du sammelst praktische Erfahrung mit Top-Frameworks wie TensorFlow, PyTorch und Hugging Face und entwickelst produktionsreife KI-Lösungen.\nDer Fokus liegt auf praktischen Fähigkeiten: In jedem Modul arbeitest du an realen Projekten, löst konkrete Geschäftsprobleme, optimierst Modelle und setzt skalierbare Lösungen ein.\nWarum diese KI-Masterclass wählen?\nEinsteigerfreundlich: Starte ohne Vorkenntnisse und werde zum Experten\nPraxisprojekte: Entwickle echte KI-Anwendungen für reale Herausforderungen\nFrameworks meistern: Lerne TensorFlow, PyTorch und Hugging Face\nKomplette Ausbildung: Python, Machine Learning, Deep Learning, NLP & Deployment\nVon Null zum Held: Strukturierter Lernpfad zur vollen KI-Kompetenz\nAm Ende dieser Masterclass beherrschst du nicht nur die wichtigsten Fähigkeiten im KI-Engineering, sondern bist auch bereit, Innovation voranzutreiben, Projekte zu leiten und mit KI echte Transformationen in Unternehmen oder Startups zu bewirken.\nOb du angehender KI-Ingenieur, leidenschaftlicher KI-Fan oder Berufseinsteiger in die KI-Branche bist – diese Masterclass ist dein ultimatives Sprungbrett von Null zum KI-Held.\nMach heute den ersten Schritt – melde dich zur KI-Engineering Masterclass an und werde Teil der KI-Revolution!",
      "target_audience": [
        "Künftige KI-Ingenieure: Personen, die eine Karriere im Bereich KI mit praktischen Fähigkeiten und realen Projekten starten möchten.",
        "Datenwissenschaftler & Analysten: Fachleute, die ihre Kenntnisse im Aufbau und in der Bereitstellung von KI-Modellen erweitern möchten.",
        "Softwareentwickler: Programmierer, die KI-Funktionen in ihre Anwendungen und Systeme integrieren wollen.",
        "Quereinsteiger: Personen ohne technischen Hintergrund, die in die KI-Branche wechseln möchten.",
        "Studierende im Master: Studierende in Datenwissenschaft, Informatik oder verwandten Bereichen, die praktische KI-Kenntnisse suchen.",
        "Tech-Unternehmer: Gründer und CTOs, die KI zur Produktinnovation und Unternehmensentwicklung erforschen.",
        "KI-Enthusiasten: Jeder, der sich für KI begeistert und intelligente Systeme von Grund auf entwickeln möchte.",
        "Geschäftsleute: Führungskräfte, die KI verstehen möchten, um strategische Entscheidungen zu treffen und ihr Unternehmen voranzubringen."
      ]
    },
    {
      "title": "Apache Flink 1.17.x DataStream API Streaming即時計算完全教程",
      "url": "https://www.udemy.com/course/apache-flink-117x-datastream-api-streaming/",
      "bio": "Build powerful stream and batch processing application, real-time data warehouse, data lake by Apache Flink (Java,Kafka)",
      "objectives": [
        "清楚知道什麼是 Apache Flink",
        "Apache Flink Stream API",
        "Apache Flink Resource Provider and Deployment Mode",
        "Apache Flink 內部架構",
        "Apache Flink Windows and Window Operator",
        "Apache Flink Watermarks and Strategies",
        "Apache Flink distributed state and backend stores",
        "Apache Flink Job Fault Tolerance"
      ],
      "course_content": {
        "Apache Flink 1.17.2 課程介紹": [
          "Prerequisites",
          "Course Objective",
          "課程介紹"
        ],
        "Apache Flink 1.17.2 快速開始": [
          "第一部分(Flink QuickStart)内容概要",
          "Apache Flink的基本介紹",
          "Apache Flink的特色介紹",
          "Apache Flink的使用場景",
          "Apache Flink的架构预览",
          "Flink獨立叢集安裝",
          "Flink叢集的啟動及停止",
          "Flink DataSet API處理離線檔",
          "Flink DataStream API處理離線文件",
          "Flink Runtime Execution Mode",
          "Flink DataStream處理流數據",
          "Flink DataStream API and Java Lambda表达式",
          "使用Job Manager的WebUI提交Flink Job",
          "使用Flink命令行提交Flink Job"
        ],
        "詳細講解Apache Flink 1.17.2 Job Deployment Mode": [
          "第二部分(Flink Job Deployment Mode)內容摘要",
          "Session Mode,Per-Job Mode和Application Mode概述",
          "Flink job Session deploy Mode的優缺點",
          "Flink job Per-Job Deploy Mode的優缺點",
          "Flink job Application Deploy Mode的優缺點",
          "Session Mode Under Standalone Cluster",
          "Application Mode Under Standalone Cluster",
          "Hadoop叢集的安裝與準備",
          "Session Mode Under Yarn Resource Provider",
          "Per-Job Mode Under Yarn Resource Provider",
          "Application Mode Under Yarn Resource Provider",
          "進一步優化Application Mode的作業提交",
          "Flink Job History Server配置以及啟動"
        ],
        "詳細講解Apache Flink 1.17.2 運行時架構": [
          "第三部分(Apache Flink Runtime Architecture)內容概要",
          "Apache Flink運行時架構與內部組件詳解",
          "Apache Flink Slots,Tasks,SubTasks概念的介紹",
          "Apache Flink Local Environment For Develop",
          "Apache Flink job operator parallelism",
          "Apache Flink operator並行度優先權詳解",
          "Apache Flink operator chaining介紹",
          "什麼情況下會發生Operator chaining",
          "Apache Flink Operator Chaining API and Programming",
          "Apache Flink Shard Slots Group",
          "Apache Flink Job提交執行的流程-Standalone叢集下的Session Deploy Mode",
          "Apache Flink Job提交執行的流程-Yarn叢集下的Per-Job Deploy Mode",
          "Apache Flink Job提交執行的流程-Yarn叢集下的Session Deploy Mode",
          "深入學習 Apache Flink's data flow graphs"
        ],
        "詳細講解Apache Flink 1.17.2 DataStream API及即時應用開發": [
          "第四部分(Apache Flink 1.17.2 DataStream API)內容概要",
          "Source Collector-Java Collections",
          "Source Collector-DataGen",
          "Source Collector-TCP Socket",
          "Source Collector-FileSystem以StreamFormat讀取處理本機文件",
          "Source Collector-FileSystem以BulkFormat讀取處理本機文件",
          "Source Collector-Hdfs File source connector",
          "Source Collector-Mongodb source connector",
          "Source Collector-Kafka source connector consume text data",
          "Source Collector-Kafka source connector consume JSON data",
          "Source Collector-Kafka source connector consume K,V data",
          "Source Collector-Custom RichSourceFunction",
          "Source Collector-Custom RichParallelSourceFunction",
          "Flink Data Types and TypeInformation",
          "Stream Data Transformations",
          "MAP,FILTER,FLATMAP Transformation",
          "KeyBy and KeyedStream",
          "KeyedStream Rolling Aggregation",
          "KeyedStream ReduceFunction",
          "Multistream Merge Operator - UNION",
          "Multistream Merge Operator-CONNECT(fire alarm application-I)",
          "Multistream Merge Operator-CONNECT(fire alarm application-II)",
          "Multistream Connect Operator-DataStreams Inner Join",
          "Split Data Stream-Side Output Stream",
          "RichFunction and Handling Application Parameters",
          "Data Exchange Strategies and Algorithms",
          "Forward Partitioner Algorithm",
          "Shuffle Partitioner Algorithm",
          "Rebalance Partitioner Algorithm",
          "Broadcast Partitioner Algorithm",
          "Global Partitioner Algorithm",
          "KeyGroupStream Partitioner Algorithm",
          "Rescale Partitioner Algorithm",
          "Custom Partitioner Algorithm",
          "How to apply Accumulators & Counters",
          "Sink Collector-Socket Sink Connector",
          "Sink Collector-LocalFileSystem Sink Connector(TXT)",
          "Sink Collector-LocalFileSystem Sink Connector(AVRO)",
          "Sink Collector-LocalFileSystem Sink Connector(Parquet)",
          "Sink Collector-Hdfs FileSystem Sink Connector(Avro)",
          "Sink Collector-JDBC Sink Connector",
          "Sink Collector-Kafka Sink Connector(Value Only)",
          "Sink Collector-Kafka Sink Connector(Key and Value)",
          "Sink Collector-Kafka Sink Connector(JSON)",
          "Sink Collector-Mongodb Sink Connector",
          "自定义sink collector(old API)",
          "自定义sink collector(new API)"
        ],
        "詳細講解Apache Flink 1.17.2 Window API及即時應用開發": [
          "第五部分(Apache Flink 1.17.2 Window API)內容概要",
          "Keyed Window和No-Keyed Window之間的差異",
          "深入解析No-Keyed Window實作原理",
          "深入解析Flink Keyed Window的定義以及源碼分析",
          "Flink 支援的幾種Window類別",
          "Flink Window的生命週期",
          "如何建立Tumbling Process TimeWindow並建置Streaming Application-I",
          "如何建立Tumbling Process TimeWindow並建置Streaming Application-II",
          "深入Flink原始碼進一步分析Window的運算與輸出邏輯",
          "Sliding Process TimeWindow詳解",
          "Session Process TimeWindow詳解",
          "Global TimeWindow詳解",
          "Count Window詳解",
          "WindowedStream Rolling Aggregation Function詳解",
          "WindowedStream reduce operator and ReduceFunction詳解",
          "WindowedStream aggregate operator and AggregateFunction詳解",
          "WindowedStream process operator and ProcessWindowFunction詳解",
          "WindowedStream Side Output詳解",
          "WindowedStream window function結合incrementally function(最佳實務)",
          "WindowedStream apply operator and WindowFunction(Legacy)詳解",
          "WindowedStream Trigger& Trigger API & TriggerResult 詳細講解",
          "WindowedStream 深入Trigger源碼剖析工作原理-I",
          "WindowedStream 深入Trigger源碼剖析工作原理-II",
          "WindowedStream 深入Trigger源碼剖析工作原理-III",
          "WindowedStream如何自定义以及應用Window Trigger-I",
          "WindowedStream如何自定义以及應用Window Trigger-II",
          "WindowedStream Evictor 詳解以及自定义Evictor",
          "Timer and TimerService介紹",
          "深入Timer和TimerService的工作內幕"
        ],
        "深入解讀Apache Flink 1.17.2 Watermark-處理遲到和亂序數據": [
          "第六部分(Apache Flink 1.17.2 Watermark)內容概要",
          "Time Semantics Introduce",
          "Process Time and Event Time Introduce",
          "什麼是Flink Watermark(Watermark需要解決哪些問題)",
          "Watermark的生成演算法演進講解",
          "透過程式再現亂序數據和遲到數據",
          "在視窗計算中如何處理亂序數據和遲到數據",
          "Flink Watermark Strategy詳細解說",
          "深入分析Flink Watermark Strategy源碼",
          "自定义Flink Watermark Generator",
          "多並行度下的watermark傳遞詳細講解",
          "透過閱讀原始碼進一步深入分析Flink中Watermark傳遞機制與原理",
          "如何處理空閒source的watermark傳遞",
          "WindowedStream Allowed Lateness詳細解說",
          "WindowedStream透過測輸出流獲取遲到資料避免遺失",
          "JoinedStreams window join詳細講解",
          "KeyedStream interval join詳細講解"
        ],
        "詳細講解Apache Flink 1.17.2 Stateful operators and Application": [
          "第七部分(Apache Flink 1.17.2 Stateful operators and Application)內容概要",
          "Stateful Operator and Stateful Application",
          "Flink中关于State的分类",
          "Flink Keyed State之ValueState使用詳細講解",
          "Flink Keyed State之ReducingState使用詳細講解",
          "Flink Keyed State之AggregatingState使用詳細講解",
          "Flink Keyed State之ListState使用詳細講解(TopN Example)",
          "Flink Keyed State之MapState使用詳細講解",
          "Flink State Time to Live(TTL) 配置及應用",
          "Flink Operator State詳細講解",
          "Flink Stateful Source Collector(CheckpointedFunction)",
          "Flink Stateful Source Operator State Application開發及測試",
          "Flink Broadcast State詳細講解",
          "Flink State Backend之HashMapStateBackend詳細講解",
          "Flink State Backend之EmbeddedRocksDBStateBackend詳細講解",
          "Flink State Questions And Answers"
        ],
        "詳細講解Apache Flink 1.17.2 Checkpoints & SavePoints & Exactly Once Semantic": [
          "第八部分(Apache Flink 1.17.2 Checkpoints & SavePoints & Exactly Once Semantic)内容概要",
          "Flink Consistent Checkpoints",
          "Flink Consistent Checkpoints算法-Instant Checkpoints",
          "Flink Consistent Checkpoints算法-Periodically Checkpoints",
          "Flink Consistent Checkpoints算法-Chandy-Lamport",
          "Flink Checkpoints and JobManager Checkpoints Coordinator",
          "Flink Checkpoints的基本配置與啟用",
          "Flink Checkpoints Barrier Alignment and Exactly Once配置",
          "Checkpoints Barrier Alignment and At Least Once配置",
          "Flink Checkpoints Barrier Unalignment and Exactly Once配置",
          "Flink savepoints introduction and restoring application state from savepoints",
          "How to apply savepoints when you resume Flink Application",
          "Trigger Savepoints when stop the Flink Job",
          "Flink Checkpoints vs Savepoints",
          "Flink Application End to End Exactly Once Semantics",
          "Flink EOS Application - Idempotent writes",
          "Flink EOS Application - Generic write-ahead-log (WAL) sink",
          "Flink EOS Application - TwoPhaseCommit Sink",
          "Flink work with Apache Kafka implement the End to End Exactly Once Semantics-I",
          "Flink work with Apache Kafka implement the End to End Exactly Once Semantics-II",
          "Flink work with Apache Kafka implement the End to End Exactly Once Semantics-III",
          "Flink New Data Source Collector Specification",
          "Flink New Data Source Collector自定义-I",
          "Flink New Data Source Collector自定义-II",
          "Flink New Data Source Collector自定义-III"
        ],
        "Materials & Source Code Download": [
          "Feel Free To Download"
        ]
      },
      "requirements": [
        "Apache Hadoop (Mandatory)",
        "Java 1.8+ (Mandatory)",
        "Linux basic commands (Mandatory)",
        "Apache Kafka (Optional)",
        "Apache Kafka Streams Framework(Optional)",
        "Apache Maven(Optional)"
      ],
      "description": "非常感謝您能夠購買我的課程，這是一門關於Apache Flink 1.17.x的完全教學視頻，在該視頻中我會非常詳細由淺入深的介紹並且練習每一個Apache Flink框架的使用細節.\nApache Flink 是一個框架和分散式處理引擎，用於對無界和有界資料流進行狀態計算。 Flink 被設計為在所有常見的叢集環境中運行，以記憶體速度和任何規模執行計算。\n\n\n【課程特色】\n代碼驅動\n大量的案例\n由淺入深\n課程內容緊湊\n涵蓋絕大多數Apache Flink框架的內容\n豐富的綜合案例\n\n\n[課程大綱]\nApache Flink 1.17.2 快速開始\n詳細講解Apache Flink 1.17.2 Job Deployment Mode\n詳細講解Apache Flink 1.17.2 運行時架構\n詳細講解Apache Flink 1.17.2 DataStream API及即時應用開發\n詳細講解Apache Flink 1.17.2 Window API及即時應用開發\n深入解讀Apache Flink 1.17.2 Watermark-處理遲到和亂序數據\n詳細講解Apache Flink 1.17.2 Stateful operators and Application\n詳細講解Apache Flink 1.17.2 Checkpoints & SavePoints & Exactly Once Semantic\n\n\n希望你能夠喜歡這門課程，經過這門課程的學習，您將成為Apache Flink的專家，並且能夠基於Apache Flink構建複雜即時事件處理應用程式",
      "target_audience": [
        "Big Data Engineer",
        "Big Data Developer",
        "Big Data Architecture"
      ]
    },
    {
      "title": "知识图谱快速入门（基于Python）",
      "url": "https://www.udemy.com/course/python-wq/",
      "bio": "构建知识图谱，探索信息关联，提升智能化分析能力",
      "objectives": [
        "学员将学会构建知识图谱的基本原理和方法，了解知识图谱的概念和应用领域。",
        "学员将学习如何收集、整理和标注数据，以构建有结构的知识图谱。",
        "学员将能够使用知识图谱的工具和技术，探索信息之间的关联和语义关系。",
        "学员将能够应用知识图谱进行智能化分析，发现隐藏的知识和洞察，提升决策和分析能力。"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "java的安装与环境变量的配置",
          "neo4的安装与环境变量的配置",
          "neo4i简单操作",
          "案例一: Python搭建员工智能关系图谱",
          "案例二: Pvthon搭建上市公司关联关系知识图谱",
          "补充知识点: echarts构建党建知识图谱-前端",
          "补充知识点: echarts构建党建知识图谱-后端"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "工作内容与分析相关的人"
      ],
      "description": "本课程旨在帮助学员学习知识图谱的构建和应用，提升智能化分析能力。课程内容涵盖了知识图谱的基本原理和概念，以及构建知识图谱的方法和工具。\n在课程中，学员将学习如何收集、整理和标注数据，以构建有结构的知识图谱。学员将了解知识图谱的存储和查询技术，以及常用的知识图谱表示方法，如RDF和OWL。\n此外，课程还将介绍知识图谱的应用领域，包括信息检索、推荐系统、智能问答等。学员将学习如何使用知识图谱的工具和技术，探索信息之间的关联和语义关系，从而提升智能化分析能力。\n通过本课程，学员将能够掌握知识图谱的构建和应用，应用于智能化分析和决策支持，为企业和组织提供有力的知识管理和智能化解决方案。",
      "target_audience": [
        "对知识图谱和信息关联感兴趣的人员，包括数据分析师、研究人员、信息科学专业学生等。 希望提升自己在知识图谱领域的技能和竞争力的人员。 对智能化分析和决策支持感兴趣的人员。 终身学习者，渴望学习新知识和技能的人员。"
      ]
    },
    {
      "title": "Python人工智能AI零基础编程开发：从零开始掌握Python编程，探索人工智能和数据爬虫，轻松构建智能应用",
      "url": "https://www.udemy.com/course/pythonaipython/",
      "bio": "从零开始掌握Python编程，探索人工智能和数据爬虫，轻松构建智能应用",
      "objectives": [
        "掌握Python编程基础，包括数据类型、条件判断、循环、函数等核心知识",
        "使用Pygame、海龟绘图等工具开发简单的游戏和动画效果",
        "学习网络爬虫技术，抓取网页数据，进行信息处理",
        "通过GUI图形化界面，开发用户友好的应用程序",
        "了解人工智能与数据挖掘的基础，开启AI编程的第一步"
      ],
      "course_content": {},
      "requirements": [
        "无需编程基础，适合所有对Python编程感兴趣的人 学员需要具备基本的电脑操作技能，课程适用于Windows与MacOS系统"
      ],
      "description": "本课程为零基础学员设计，帮助你从零开始学习Python编程，并逐步迈向人工智能开发。通过实战项目，你将掌握Python的核心编程知识、图形界面开发、爬虫技术以及人工智能入门技术。无论你是想开发游戏、处理数据，还是进行网络爬虫，本课程都能为你提供全面的指导与实操。\n课程亮点：\n零基础友好：课程内容循序渐进，涵盖基础编程、GUI图形界面设计、数据处理、爬虫技术等。\n实战项目驱动：通过海龟绘图、Pygame图形编程、网络爬虫等实战项目，让你在实操中掌握核心技能。\n人工智能AI入门：课程包含基础的AI知识，带领你进入人工智能开发的世界。\n适用多平台：无论你是Windows用户还是Mac用户，课程都提供详细的操作步骤，轻松上手。\n你将学到什么：\n掌握Python编程基础，包括数据类型、条件判断、循环、函数等核心知识\n使用Pygame、海龟绘图等工具开发简单的游戏和动画效果\n通过GUI图形化界面，开发用户友好的应用程序\n学习网络爬虫技术，抓取网页数据，进行信息处理\n了解人工智能与数据挖掘的基础，开启AI编程的第一步\n适合人群：\n对编程感兴趣的零基础学习者\n想要开发图形界面和游戏的编程爱好者\n希望通过Python进行数据处理、网络爬虫的职场人士\n对人工智能有兴趣，想要入门AI开发的初学者",
      "target_audience": [
        "对编程感兴趣的零基础学习者 想要开发图形界面和游戏的编程爱好者 希望通过Python进行数据处理、网络爬虫的职场人士 对人工智能有兴趣，想要入门AI开发的初学者"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第26部 Mistral 語言模型的架構秘密",
      "url": "https://www.udemy.com/course/generative_ai_26/",
      "bio": "關於Sliding Window Attention，Rolling Buffer Cache，MoE，Key-Value Cache，Experts",
      "objectives": [
        "瞭解Mistral 語言模型的Sliding Window Attention 技術",
        "瞭解Mistral 語言模型的Rolling Buffer Cache 技術",
        "瞭解Mistral 語言模型的Sparse Mixture of Experts (MoE) 技術",
        "瞭解Mistral 語言模型的Model Sharding技術"
      ],
      "course_content": {},
      "requirements": [
        "一臺電腦"
      ],
      "description": "本課程延續Generative AI 第 18～25 部，繼續講解大語言模型架構技術的原理，圍繞Mistral 大語言模型與原始 Transformer 之間的架構差異展開。\n其中包括如下技術：\nSliding Window Attention - 滑動窗口注意力：\n限制注意力計算在固定大小窗口內，減少計算量\n\n\nRolling Buffer Cache - 滾動緩衝區緩存：\n一種用於推理時保存中間計算結果的緩存技術\n\n\nSparse Mixture of Experts (MoE) - 稀疏混合專家模型：\n利用多個專家子網絡並行處理，提升模型容量與效率\n\n\nKV 緩存 - Key-Value Cache：\n儲存注意力機制中Key和Value的緩存，加速推理\n\n\nFeedforward Networks (Experts) - 前饋網絡（專家）：\nMoE中多個獨立的前饋子網絡，負責不同輸入的處理\n\n\nModel Sharding - 模型分片：\n將模型參數分散到多個設備上以減少單設備負擔",
      "target_audience": [
        "AI/ML 研究者與工程師",
        "數據科學家與視覺工程師",
        "所有對 AI 藝術與創新應用有興趣者"
      ]
    },
    {
      "title": "The Guide to be: a storyteller with data",
      "url": "https://www.udemy.com/course/be-astoryteller/",
      "bio": "Being a creative using Data",
      "objectives": [
        "being a creative person using data",
        "be a storyteller in easy learning",
        "it's a good communication skill",
        "have fun with visualization"
      ],
      "course_content": {},
      "requirements": [
        "No need anything",
        "لا يحتاج لاي مهارة.. يحتاج منك البدء وفقط"
      ],
      "description": "كل ما يدور حوله الكورس وهو: لي احنا مش متمكنين من اننا نقدر نعمل قصة باستخدام الداتا .. السبب وراءه هو اننا في المدرسة اتعلمنا لغة وهو ازاي نكتب كلمة ونعمل من خلالها جمل و نعمل قصة .. واتعلمنا كمان ماث ازاي نقدر نستخدم الارقام ونعمل حسابات ومعادلات .. طب انت عايز تقول اي ي عمر ! نا هقولك بقول الكلام ده لي .. دلوقتي متعلمين لغة و ماث بس اتعلمناهم كل حاجة لوحدها .. والاجابه ان مفيش حد اتعلم ازاي نعمل قصة بالارقام\n\n\nهمشي معاك خطوة خطوة عشان تبدء تضع قدمك علي الطريق لتكون محترف سرد قصة باستخدام جرافس\n\n\nهتكلم معاك علي اشهر الجرافس المستخدمة ثم هكلمك علي بعض الجرافس التي يجب عليك تجنبها\n\n\nازاي يكون الجراف بسيط ومش معقد\n\n\nازاي تجذب انتباه اي شخص ينظر الي الجراف تبعك\n\n\nازاي تفكر زي المصمم\n\n\nشرح علي امثلة عملية وكيفية الاستفادة منها في شغلك\n\n\nبعض التفاصيل النظرية عن سرد القصص\n\n\nتطبيق عملي كامل من الصفر الي الاحتراف\n\n\n5 دراسات تاخد بالك منها وانت بتصمم اي جراف\n\n\nكيف اكون محترف بعد هذا الكورس\n\n\nملحوظة: هذا الكورس سهل الفهم لسبب وهو ان الشرح كاملا بصور وامشي معك خطوة خطوة من بداية الي النهاية\n\n\nمستني اي ! منتطرك في هذا الكورس العظيم | ربنا يوفق الجميع\n\n\nواتمني اكون وفقت في شرح الكورس",
      "target_audience": [
        "for anyone his job related to data",
        "Data Scientist, data engineering & data analyst"
      ]
    },
    {
      "title": "AI大模型应用从入门到实战 2025（DeepSeek）",
      "url": "https://www.udemy.com/course/ai-llm-study/",
      "bio": "AI大模型发展历程，排名，开发框架，Python环境安装，讲解文心一言，通义千问，ChatGPT的API调用和框架应用，快速搭建简易AI大模型应用：DeepSeek V3和R1，文心一言",
      "objectives": [
        "对AI大模型感兴趣的用户",
        "对AI感兴趣的用户",
        "转型开发AI的用户",
        "AI爱好者",
        "想学习文心一言",
        "想学习通义千问",
        "在线调用AI大模型",
        "本地搭建AI大模型",
        "DeepSeek V3和R1的特点和区别",
        "实战项目1：快速搭建DeepSeek V3和R1的简易AI大模型应用",
        "实战项目2：简易AI聊天机器人（文心一言）",
        "快速了解RAG技术"
      ],
      "course_content": {},
      "requirements": [
        "对Python有一些基础"
      ],
      "description": "本课程是AI大模型应用基础，为学习开发AI大模型技术，做好快速入门的学习。用快速掌握见效快的大模型调用技术，这也是实际生产中，快速实现成果，以及快速解决AI大模型线上高并发的方式。\n\n\n课程中使用的文心一言 大模型API，目前刚免费开放，是最佳抢占先机的AI机会\n\n\nAI大模型认识和准备\nAI大模型如何从入门，到快速搭建AI应用\nAI大模型发展历程\nAI大模型排名\nCreativeAI框架讲解\nPython环境准备\nNode.js环境准备\n调用AI大模型API\n文心一言\n在线调用文心一言API\n在线调用文心一言API - 补充\n文心一言API在框架的应用\n通义千问\n在线调用通义千问API\n通义千问API在框架的应用\nChatGPT\n在线调用ChatGPT API\nChatGPT API在框架的应用\nDeepSeek V3和R1入门到实战：简易AI聊天机器人\nDeepSeek V3和R1的特点和区别\nDeepSeek V3和R1调用接口\nDeepSeek V3和R1调用接口\n实战项目2：简易AI聊天机器人（文心一言）\nAI大模型应用前端\nAI大模型应用后端\nWindows部署AI大模型\nWindows部署通义千问2\nWindows部署Llama 3\nWindows部署Stable Diffusion\nRAG快速了解\nRAG是什么\nRAG的设计思路\n部署Embedding向量模型",
      "target_audience": [
        "AI爱好者"
      ]
    },
    {
      "title": "L’IA POUR OPTIMISER SON TRAVAIL: outils et logiciels",
      "url": "https://www.udemy.com/course/ia-optimiser-le-travail-en-entreprise-avec-lia-et-chatgpt/",
      "bio": "Maitriser l’IA, IA de A à Z, IA ChatGPT, optimisation travail",
      "objectives": [
        "Introduction à ChatGPT et ses Capacités",
        "Utilisation de ChatGPT pour la Création de Contenu",
        "Utiliser ChatGPT pour augmenter sa productivité personnelle, gérer son emploi du temps et automatiser des tâches",
        "Utiliser ChatGPT comme assistant en programmation, dépannage et résolution de problèmes techniques.",
        "Apprendre à utiliser ChatGPT de manière avancée tout en respectant les considérations éthiques et les bonnes pratiques."
      ],
      "course_content": {
        "ChatGPT pour optimiser son travail": [
          "Introduction à ChatGPT et ses Capacités",
          "Automatiser et Accélérer ses Tâches",
          "Gagner en Productivité et Organisation",
          "ChatGPT pour les Créateurs de Contenu et Entrepreneurs",
          "Études de Cas et Applications Avancées"
        ]
      },
      "requirements": [
        "Aucun"
      ],
      "description": "Chapitre 1 : Comprendre et Maîtriser ChatGPT\nObjectif : Apprendre à dialoguer efficacement avec ChatGPT et maximiser la qualité des réponses\n1.1. Fonctionnement de ChatGPT\nExplication simplifiée des modèles GPT (animation graphique)\nDifférences entre GPT-3.5, GPT-4 et versions futures\nOù et comment utiliser ChatGPT efficacement (site web, extensions, API)\n1.2. Rédiger des invites efficaces\nLes éléments clés d'un bon prompt (clair, précis, structuré)\nTechniques d'optimisation : contextuel, rôles, contraintes et format de sortie\nExemples de prompts : basique vs optimisé\n1.3. Affiner et améliorer les réponses\nComment reformuler ses demandes pour obtenir de meilleures réponses\nItérations et ajustements progressifs d'un prompt\nExercice démonstratif : analyser d'un prompt et en direct\n\n\nChapitre 2 : Automatiser et Accélérer ses Tâches\nObjectif : Exploiter ChatGPT pour gagner du temps sur les tâches quotidiennes\n2.1. Rédaction et correction de texte\nÉcrire un email professionnel en quelques secondes\nCorrection automatique et reformulation (exemple concret)\nGénération de contenu structuré (ex : plan d'article, rapport, résumé)\n2.2. Synthèse et CV automatique\nComment résumer rapidement un document (PDF, article, réunion)\nGénération de bullet points et synthèse détaillée\nExemples d'applications : gestion de l'information, veille stratégique\n2.3. ChatGPT pour la gestion de la connaissance\nOrganiser ses idées et créer des fiches de synthèse\nGénérer des scripts et des modèles réutilisables\n\n\nChapitre 3 : Gagner en Productivité et Organisation\nObjectif : Intégrer ChatGPT dans son organisation quotidienne pour être plus efficace\n3.1. Gérer ses tâches et son temps\nGénération automatique de listes de tâches et plannings personnalisés\nUtilisation de ChatGPT pour prioriser les tâches selon l'urgence et l'importance\nPlanification d'une journée de travail optimisée\n3.2. ChatGPT comme assistant personnel\nGénérer des scripts d'organisation et de suivi\nSimulation d'un échange avec un \"assistant IA\" pour gérer une semaine de travail\n3.3. Automatisation avancée avec des outils tiers\nConnecter ChatGPT à Notion, Trello, Zapier, Google Docs\nExemples concrets d'automatisation de tâches répétitives\n\n\nChapitre 4 : ChatGPT pour les Créateurs de Contenu et Entrepreneurs\nObjectif : Générer du contenu de manière efficace et booster son activité\n4.1. Génération de contenu rapide et efficace\nRédaction d'articles et de posts LinkedIn optimisés\nGénération d'idées de contenu et de titres accrocheurs\nOptimisation SEO avec ChatGPT\n4.2. Rédaction persuasive et copywriting\nCréation de pages de vente et de descriptions de produits\nAméliorer ses textes marketing et publicitaires\nExemples d'emailing efficace généré avec ChatGPT\n4.3. ChatGPT pour la création d'entreprise en ligne\nIdées de business exploitables avec ChatGPT\nGénérer un plan d'action et des stratégies de monétisation\nChapitre 5 : Études de Cas et Applications Avancées\nObjectif : Voir comment ChatGPT est utilisé dans différents secteurs et optimiser son workflow\n5.1. ChatGPT pour le support client et la relation client\nSimulation d'une conversation chatbot\nGénérer des réponses automatiques aux questions clients\nRédaction de FAQ dynamique\n5.2. Utilisation avancée pour la programmation et l'automatisation\nGénérer du code et des scripts automatisés\nExplication et correction de code avec ChatGPT\nGénération de bases de données et structures complètes\n5.3. Études de cas réels : Entrepreneurs et professionnels\nComment des freelancers et entreprises utilisent ChatGPT au quotidien\nAnalysez les stratégies gagnantes avec ChatGPT",
      "target_audience": [
        "Tout le monde"
      ]
    },
    {
      "title": "强化Q学习构建Turtle控制的人工智能代理【中字】",
      "url": "https://www.udemy.com/course/qturtle-k/",
      "bio": "通过Q-Learning，Turtles学习强化学习：Q-Learning实践之旅",
      "objectives": [
        "掌握强化学习基础",
        "实施Q-Learning算法",
        "设计智能代理行为",
        "导航复杂环境",
        "优化决策策略",
        "可视化并解释Q-Learning输出",
        "将强化学习应用于现实问题",
        "Q-Learning模型的故障排除和优化"
      ],
      "course_content": {
        "强化Q学习构建Turtle控制的人工智能代理": [
          "课程介绍",
          "1 用Turtle创建方块",
          "2 创建Q-Learning算法",
          "添加障碍",
          "4 学习策略的可视化呈现",
          "5 学习进度可视化",
          "6 优化形状与训练周期",
          "7 将Q表保存在yaml文件中",
          "8 训练AI实现每个目标",
          "9 优化并完成项目"
        ]
      },
      "requirements": [
        "Python编程基础"
      ],
      "description": "深入迷人的强化学习世界，掌握Q学习艺术。在这个综合课程中，你将开始一段引人入胜的旅程，建立自己的人工智能控制的海龟代理，该代理将在动态迷宫中导航，学习做出最佳决策并实现目标。\n强化学习是一种强大的技术，它允许代理（如我们的海龟）通过试错与其环境进行交互来学习和改进其行为。通过实施Q学习算法，你将亲眼目睹代理如何学习做出最佳决策，以最大化其奖励并成功达到其目标。\n在整个课程中，你将：\n了解强化学习和Q学习算法的基本原理\n使用Python和Turtle图形库从头开始实现Q学习算法\n设计一个带有障碍物、目标位置和海龟代理的动态迷宫环境\n使用Q学习技术训练你的海龟代理在迷宫中导航并达到目标\n可视化学习过程并分析代理随时间推移的表现\n探索优化Q学习过程的技巧，例如调整学习率和探索与利用之间的权衡\n深入了解强化学习在实际应用中的实践应用\n在本课程结束时，你将深入了解强化学习和Q学习算法，以及将这些概念应用于解决复杂问题的技能。无论你是初学者还是经验丰富的程序员，本课程都将为你提供知识和实践经验，使你成为一名熟练的强化学习从业者。",
      "target_audience": [
        "有志于机器学习工程的工程师",
        "人工智能爱好者"
      ]
    },
    {
      "title": "เรียน Canva Sheets วิเคราะห์ข้อมูลและสร้างงานดีไซน์อย่างโปร",
      "url": "https://www.udemy.com/course/canvasheets/",
      "bio": "เรียน Canva Sheets วิเคราะห์ข้อมูลและสร้างงานดีไซน์อย่างโปร Zero to Hero",
      "objectives": [
        "ผู้เรียนเข้าใจพื้นฐาน Canva Sheets กับ AI เช่น การสร้างตาราง การจัดการข้อมูล และการใช้ Magic Formulas ในการคำนวณและประมวลผล",
        "ผู้เรียนสามารถสร้าง Data Visualization ด้วย Magic Charts แปลงข้อมูลให้เป็นแผนภูมิและกราฟที่สวยงามและเข้าใจง่าย",
        "ผู้เรียนสามารถดึงข้อมูลเชิงลึกด้วย Magic Insights เพื่อวิเคราะห์และค้นพบข้อมูลสำคัญที่ซ่อนอยู่ในชุดข้อมูล เพื่อช่วยในการตัดสินใจ",
        "ผู้เรียนสามารถจัดการข้อมูลขั้นสูงและสร้างเทมเพลต โดยใช้ AI ในการสรุปข้อมูล นำเข้าข้อมูล และสร้างเทมเพลตเฉพาะทางได้",
        "ผู้เรียนสามารถสร้างงานดีไซน์จากข้อมูลใน Canva Sheets ได้หลายร้อยชิ้นอย่างอัตโนมัติด้วย Bulk Create",
        "ผู้เรียนสามารถนำความรู้ที่ได้ไปประยุกต์ใช้ในการทำงานและ Projects ต่าง ๆ ได้จริง"
      ],
      "course_content": {
        "พื้นฐาน Canva Sheets AI และการวิเคราะห์ข้อมูล": [
          "Canva Sheets Basics สร้างตารางและเติมข้อมูลด้วย Fill Empty Cell",
          "Canva Sheets Basics สร้างตารางและใช้ Magic Formulas สร้างสูตร",
          "AI Data Visualization ใช้ Magic Charts สร้าง Pie Chart",
          "AI Data Visualization ใช้ Magic Chart สร้าง Racing Bar Chart Animation",
          "AI Data Insights วิเคราะห์ข้อมูลด้วย Magic Insights 1",
          "AI Data Insights วิเคราะห์ข้อมูลด้วย Magic Insights 2"
        ],
        "การจัดการข้อมูลขั้นสูงด้วย Canva Sheets AI": [
          "AI Data Management Advanced Magic Write สำหรับข้อมูล Part 1",
          "AI Data Management Advanced Magic Write สำหรับข้อมูล Part 2",
          "AI Data Management Advanced สรุปฟังก์ชัน AI และการนำเสนอ",
          "AI Data Management Advanced นำเข้าข้อมูล Import Data และใช้ Magic Charts",
          "AI Data Management Advanced นำเข้าข้อมูล Import Data และใช้ Magic Insights",
          "AI Data Management Advanced นำเข้าข้อมูล Import Data และใช้ Magic Formulas",
          "AI Data Management Advanced นำเข้าข้อมูล Import Data และสรุปด้วย Magic Write"
        ],
        "การประยุกต์และปรับแต่งการใช้งาน Canva Sheets Templates": [
          "AI Data Management Advanced สร้าง Social Media Calendar Template",
          "AI Data Management Advanced สร้าง Inventory Template และลบ BG Image",
          "AI Data Management Advanced สร้าง Templates อื่นๆ"
        ],
        "สร้างงานดีไซน์หลายชิ้นด้วย Canva Sheet AI และ Bulk Create": [
          "AI Bulk Create เตรียมข้อมูลตารางเพื่อสร้างงาน Design ด้วย Canva Sheets AI",
          "AI Bulk Create สร้างรูปภาพด้วย AI เพื่อเชื่อมงาน Design",
          "AI Bulk Create จัดการภาพ สร้างไอคอนและลบพื้นหลังด้วย AI",
          "AI Bulk Create ออกแบบ Template สำหรับงาน Design",
          "AI Bulk Create เชื่อมโยงข้อมูลระหว่าง Sheets กับ Design Template",
          "AI Bulk Create ประยุกต์ใช้และปรับแต่งดีไซน์เพื่อสร้างผลงานหลายชิ้นในพริบตา",
          "AI Bulk Create แสดงผลลัพธ์งาน Design สร้างสรรค์จากข้อมูล Sheets",
          "สรุปและก้าวต่อไป เคล็ดลับสู่การเป็นผู้เชี่ยวชาญ Canva Sheet AI"
        ]
      },
      "requirements": [
        "ผู้เรียนต้องมีความรู้การใช้งาน Canva พื้นฐานมาก่อน จะทำให้เรียนรู้ได้เร็วขึ้น"
      ],
      "description": "หมดปัญหางานข้อมูลที่ซับซ้อน และการสร้างดีไซน์จากตัวเลขที่น่าเบื่อไปได้เลย คอร์ส \"Canva Sheets AI วิเคราะห์ข้อมูลและสร้างงานดีไซน์หลายชิ้นในคลิกเดียวด้วย AI\" คือคอร์สที่จะปฏิวัติการทำงานของคุณให้ง่ายขึ้นถึงขีดสุด ด้วยพลังของปัญญาประดิษฐ์ใน Canva Sheets\nคุณจะได้เรียนรู้วิธีเปลี่ยนข้อมูลธรรมดาให้กลายเป็นภาพกราฟิกที่ทรงพลัง สร้างรายงานที่น่าสนใจ และออกแบบงานดีไซน์หลายร้อยชิ้นได้อย่างอัตโนมัติ เพียงแค่คลิกไม่กี่ครั้ง ก็พร้อมนำเสนอได้อย่างมืออาชีพ ไม่ต้องเสียเวลานั่งดีไซน์ทีละชิ้นอีกต่อไป\nแบ่งเป็น 4 บทเรียน เน้นการฝึกปฏิบัติการทำ Workshop ไปพร้อม ๆ กันแบบ Step by Step\nส่วนที่ 1: พื้นฐาน Canva Sheets AI และการวิเคราะห์ข้อมูลเชิงลึก\n1. Workshop 1: สร้างตารางและเติมข้อมูลด้วย Fill Empty Cell\n2. Workshop 2: สร้างตารางและใช้ Magic Formulas สร้างสูตร\n3. Workshop 3: ใช้ Magic Charts สร้าง Pie Chart\n4. Workshop 4: ใช้ Magic Chart สร้าง Racing Bar Chart Animation\n5. Workshop 5-1: วิเคราะห์ข้อมูลด้วย Magic Insights 1\n6. Workshop 5-2: วิเคราะห์ข้อมูลด้วย Magic Insights 2\n7. Workshop 6-1: ใช้ Magic Write เขียนสรุปผลการวิเคราะห์ข้อมูล Part 1\n8. Workshop 6-2: ใช้ Magic Write เขียนสรุปผลการวิเคราะห์ข้อมูล Part 2\n9. สรุปฟังก์ชันพื้นฐานของ Canva Sheets AI และการนำเสนอ\nส่วนที่ 2: การจัดการข้อมูลขั้นสูงด้วย Canva Sheets AI\n10. Workshop 7-1: จัดการนำเข้าข้อมูล Import Data และใช้ Magic Charts สร้างกราฟ\n11. Workshop 7-2: จัดการนำเข้าข้อมูล Import Data และใช้ Magic Insights หาข้อมูลเชิงลึก\n12. Workshop 7-3: จัดการนำเข้าข้อมูล Import Data และใช้ Magic Formulas สร้างสูตรการคำนวณ\n13. Workshop 7-4:  จัดการนำเข้าข้อมูล Import Data และสรุปผลการวิเคราะห์ข้อมูลด้วย Magic Write\nส่วนที่ 3: การประยุกต์และปรับแต่งการใช้งาน Canva Sheets Templates\n14. Workshop 8: สร้าง Social Media Calendar Template\n15. Workshop 9: สร้าง Inventory Template และลบ BG Image\n16. Workshop 10: สร้าง Canva Sheets Templates รูปแบบต่าง ๆ\nส่วนที่ 4: สร้างงาน Design หลายชิ้นด้วย Canva Sheets AI และ Bulk Create\n17. Workshop 11-1: เตรียมข้อมูลตารางเพื่อสร้างงาน Design ด้วย Canva Sheets AI\n18. Workshop 11-2: สร้างรูปภาพด้วย AI เพื่อเชื่อมงาน Design\n19. Workshop 11-3: สร้างรูปภาพไอคอนและลบพื้นหลังด้วย AI\n20. Workshop 11-4: ออกแบบ Template สำหรับงาน Design\n21. Workshop 11-5: เชื่อมโยงข้อมูลระหว่าง Sheets กับ Design Template ด้วย AI Bulk Create\n22. Workshop 11-6: ประยุกต์ใช้และปรับแต่งงาน Design เพื่อสร้างผลงานหลายชิ้นในพริบตา\n23. Workshop 11-7: แสดงผลลัพธ์งาน Design สร้างสรรค์จากข้อมูล Canva Sheets\n24. สรุปและก้าวต่อไป เคล็ดลับสู่การเป็นผู้เชี่ยวชาญ Canva Sheets AI",
      "target_audience": [
        "นักวิเคราะห์ข้อมูล, คอนเทนต์ครีเอเตอร์, นักการตลาด, นักออกแบบกราฟิก, จ้าของธุรกิจ, ผู้ประกอบการ, ผู้จัดการ, พนักงานธุรการ, และทุกคนที่ต้องการเพิ่มประสิทธิภาพในการสร้างงานออกแบบจากข้อมูล"
      ]
    },
    {
      "title": "오렌지(Orange)를 활용한 코딩 없는 AI 데이터 분석 - Lv.6 텍스트와 이미지 분석",
      "url": "https://www.udemy.com/course/maso-ds-orange-onc50/",
      "bio": "복잡한 파이썬(python), 느린 엑셀(excel) 데이터 분석은 이제 그만! 노 코드 분석 도구 Orange로 쉽게 하는 비정형 데이터 분석",
      "objectives": [
        "비정형 데이터 분석의 기본 개념 및 데이터의 유형과 구조 이해",
        "텍스트 마이닝 기법의 기본부터 텍스트 전처리의 실습까지 학습",
        "텍스트 기반의 데이터로 실제 비즈니스 예측 및 분류 분석",
        "이미지 데이터의 핵심 특징 추출 및 분석"
      ],
      "course_content": {
        "학습 내용 안내": [
          "AAE011 학습 내용 안내"
        ],
        "비정형 데이터 분석의 이해": [
          "AAE021 비정형 데이터 분석의 이해"
        ],
        "텍스트 마이닝의 첫 걸음": [
          "AAE031 코퍼스와 워드 클라우드",
          "AAE032 텍스트 전처리와 불용어 사전, 그리고 정규표현식",
          "AAE033 토큰과 N-그램"
        ],
        "텍스트 데이터를 활용한 예측과 분류": [
          "AAE041 텍스트 군집 분석과 Bag of Words",
          "AAE042 텍스트 문서 분류 모델과 평가"
        ],
        "비즈니스를 위한 텍스트 분석": [
          "AAE051 고객의 구매 후기 감성 분석",
          "AAE052 텍스트 데이터의 네트워크 분석"
        ],
        "이미지 데이터를 활용한 예측과 분류": [
          "AAE061 이미지 데이터 다루기",
          "AAE062 이미지 임베딩과 합성곱 신경망(CNN)",
          "AAE063 이미지 데이터 분류 모델"
        ]
      },
      "requirements": [
        "본 강의는 인공지능, 코딩, 또는 엑셀 실력과 같은 선수지식을 요구하지 않습니다. 누구나 쉽게 따라올 수 있도록 기초부터 설명 드립니다. 다만, 이전 단계인 오렌지 강의 Lv.1 또는 Lv.2까지 수강하시면 강의 내용을 더욱 원활하게 이해하실 수 있습니다.",
        "오렌지를 일절 사용해보신 적이 없다면, 강의를 더욱 원활하게 진행하기 위해 기본적인 사용 방법이나 설치 방법을 미리 알아보시는 것을 추천 드립니다.",
        "실습 위주의 강의이기 때문에 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기를 함께 준비해주시면 좋습니다.",
        "또한 Windows OS 기반으로 실습이 진행되므로, Windows 환경에서의 강의 수강을 추천해드립니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n\n\n흔한 강의가 아닙니다\n- 정형 / 비정형 데이터의 주요 차이점, 다양한 형태와 구조 설명\n-기본적인 텍스트 전처리의 원리 설명\n-코퍼스, 토큰화, 품사 태깅과 같은 텍스트 마이닝 기법\n- 텍스트 클러스터링 및 TF-IDF 기법을 실제 비즈니스 데이터 예측과 분류에 활용\n- 이미지 데이터 추출의 기초 개념부터 비전 모델, 이미지 분류 및 클러스터링 기법\n\n\n강의 교재 파일 + 개념 설명\n+ 실제 비즈니스 분석에 활용 가능한 풍부한 텍스트 및 이미지 실습 자료\n+ Orange를 활용한 비정형 데이터 분석을 통해 비즈니스 예측과 분류 분석\n\n\n비정형 데이터 분석은 오늘날 많은 기업들이 직면한 중요한 도전 과제입니다.\nOrange를 활용해 비정형 데이터를 손쉽게 분석하고 새로운 통찰력을 발견하세요\n빠르게 변하는 직무 역량과 인재 트렌드 속에서, 데이터 분석 능력은 필수 역량입니다\n\n\n성과로 이어지는 Orange 데이터 분석 강의\n\n\n데이터 분석? 더 이상 전문가들만의 영역이 아닙니다\n비정형 데이터의 개념과 예시, 그리고 관련된 기법들을 이해하기 쉽게 배울 수 있습니다!\n\n\n-복잡한 코딩 기술 없이 누구나 Orange를 통해 비정형 데이터에서 유의미한 결론 이끌어내기\n-텍스트 & 이미지 분석의 기본적인 프로세스부터 결과물까지 한 눈에\n-텍스트와 이미지 데이터를 실무에서 어떻게 다루고 분석하는지에 대한 직관적인 설명\n\n\n비정형 데이터를 활용한 비즈니스 분석은 더 이상 먼 미래의 일이 아닙니다.\n이 강의로, 실질적인 문제 해결을 위해 비정형 데이터를 활용할 수 있는 첫 걸음을 내딛으세요!\n\n\nSTEP 1. 입문자도 접근하기 쉽게, 비정형 데이터의 기초 개념 및 분석 방법 학습\n비정형 데이터의 기본적인 유형, 구조, 형태를 기점으로 이러한 데이터를 분석할 때 발생하는 고유한 도전 과제 이해\n\n\nSTEP 2. 텍스트 마이닝의 기초부터 시작하는 실습\n텍스트 데이터를 전처리하는 과정에서 필요한 핵심 기법들을 배우고, 텍스트 데이터를 컴퓨터가 이해할 수 있는 형태로 변환하는 방법 실습\n\n\nSTEP 3. 텍스트 분류 및 예측을 위한 다양한 기법 학습\n텍스트 데이터의 군집 분석과 분류 기법을 활용해 비즈니스 문제 해결에 적용할 수 있는 실습 진행\n\n\nSTEP 4. 이미지 데이터 분석의 기초부터 응용까지 실습\n이미지 데이터를 다루는 기본 원리를 이해하고 이를 활용해 이미지 분류 및 예측을 실무에 활용하는 방법 습득\n\n\n강의 수강 이후 당신은,\n\n\n+ 비정형 데이터 분석 기법을 통한 분석 역량 강화\n비정형 데이터 분석을 통해 텍스트 및 이미지 데이터의 핵심 패턴을 찾아내는 능력\n+ 텍스트 마이닝 기법을 활용 전처리 및 데이터 활용\n코퍼스 생성, 워드 임베딩 벡터, 중요 키워드 추출, 감성 분석 등 텍스트 데이터 활용\n+ 이미지 데이터를 활용한 예측과 분류 능력 향상\n이미지 임베딩 알고리즘 이해, 이미지 클러스터링과 등 이미지 데이터 분석 기초 능력\n+ 다양한 비정형 데이터 실무 활용 기초 역량 강화\n고객 피드백 이해, 분류와 제품 품질 관리와 같이 실제 비즈니스 분석에 활용 가능\n\n\n\n\n\n\n[ 강 사 소 개 ]\n\n\n최 정 아\n現 마소캠퍼스 콘텐츠랩 이사\n연세대학교 경영학 석사\nYSCEC의 웹마스터로서 연세-게이오(日)-릿쿄(日)-푸단(中) 대학의 YKLP 사업에 초기부터 합류해 성공적으로 론칭시킨 국제 원격교육 전문가입니다. 이후 플레이포럼 편집장으로 자리를 옮겨 MAU 238만 명의 커뮤니티를 7년간 운영하면서 최대 900만 뷰를 달성한 디지털 콘텐츠를 제작했습니다. 언어학, 정보학, 경영학 학위를 소지한 다재다능한 디지털마케팅 전문가로서 데이터를 활용해 디지털 플랫폼에서 최고의 퍼포먼스를 이뤄냈습니다. 효과적인 데이터 마케팅 방법을 다룬 도서를 다수 출간하여 모두 경제경영 분야 베스트셀러에 오른 검증된 지식을 공유하고 있습니다.",
      "target_audience": [
        "실무적 데이터 분석 기술을 강화하고자 하는 분",
        "어려운 코딩 없이 데이터 분석 능력을 향상하고자 하는 분",
        "텍스트 / 이미지와 같은 비정형 데이터 분석을 통해 성과를 내고자 하는 분",
        "엑셀의 한계를 느끼고 더 간단한 고급 분석 도구를 원하는 분"
      ]
    },
    {
      "title": "의약학,바이오 분야 논문그래프 시리즈-2 : 시간 경과에 따른 변화의 그래프",
      "url": "https://www.udemy.com/course/repeated_means/",
      "bio": "시간에 따른 변화를 연결된 오차막대, 연결된 boxplot이나 violin plot으로 표현해 보세요. 논문과 발표가 훨씬 좋아집니다.",
      "objectives": [
        "데이터의 종류에 어울리는 그래프를 선택하기",
        "의약학,바이오 분야 그래프 중 가장 흔히 사용되는 것을 잘 만들기",
        "오차막대가 있는 선차트, 막대차트를 시간 순서에 따라 배치하기",
        "boxplot, violin plot을 시간 순서에 따라 배치하기",
        "수준 높은 그래프를 만든 뒤에 논문에 제출하기 좋도록 편집하기"
      ],
      "course_content": {
        "소개": [
          "기본 : 오차가 있는 선차트 막대차트",
          "Aggregate Plot",
          "Repeated Means Plot",
          "Repeated Means Plot for Many Outcomes",
          "자료 준비하기 그림 편집하기",
          "연습용 데이터 다운로드 받기"
        ]
      },
      "requirements": [
        "프로그래밍이 필요하지 않습니다. 자신의 데이터와 웹브라우저만 있으면 됩니다."
      ],
      "description": "시간에 따라 변하는 결과값(연속변수)를 효과적으로 표현하기 위해 흔히 사용되는 몇 가지 그래프들을 효과적으로, 쉽고 빠르게, 그리고 예쁘고 매력적으로 만드는 법을 배우게 될 것입니다.\n이것을 만들기 위해 코딩을 배우거나 특별한 프로그램을 구입할 필요가 없습니다.\n자신의 데이터만 잘 정리해서 업로드하면 바로 만들어 집니다.\n추가적인 몇 가지 편집도 클릭 몇 번으로 끝나게 됩니다.",
      "target_audience": [
        "의약학,바이오 분야의 학생, 대학원생, 연구자"
      ]
    },
    {
      "title": "科大讯飞-星火AI大模型教程",
      "url": "https://www.udemy.com/course/ai-yhcfz/",
      "bio": "深入研究科大讯飞星火AI大模型的训练技巧与调优方法",
      "objectives": [
        "提升职场效率",
        "开拓创意思维",
        "提高技能竞争力",
        "增强科技感知力",
        "掌握高级文本编辑技巧"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "1、科大讯飞人工智能Al讯飞星火大模型产品介绍和实用教程概述",
          "2、用Al的一定要看！科大讯飞星火Al大模型提示词交互技巧分享",
          "3、三分钟带你明白，如何用科大讯飞星火Al大模型进行日常生活类对话！",
          "4、如何用科大讯飞星火Al大模型进行各种情感类对话？这个视频有答案！",
          "5、创意思维不够？来看看用科大讯飞星火Al大模型获取灵感的快捷方法！",
          "6、用科大讯飞星火Al大模型生成公文类内容的实战讲解，让Al帮你干活",
          "7、科大讯飞星火Al大模型生成新媒体文案内容的指令详解，千万别错过！",
          "8、专家带你解读：如何用科大讯飞星火Al大模型生成各类型的营销文案？",
          "9、文案写作神器来袭!星火Al大模型生成的文案写作类内容，太优秀了！",
          "10、职场人福音!科大讯飞星火Al大模型生成职场类文件，Al打工你休息",
          "11、科大讯飞星火Al大模型可以生成的学习类内容，覆盖行业原来这么广",
          "12、专家教你如何使用星火Al大模型生成小红书种草文案，轻松吸粉！",
          "13、惊呆了!用讯飞星火Al大模型创作短视频脚本如此轻松，网红都在用",
          "14、用星火Al大模型生成法学专业开题报告的方法，这里一次性讲清楚了",
          "15、毕业季必备!如何用星火AI大模型生成平面设计毕业答辩自述稿",
          "16、学霸秘籍大公开!如何使用星火Al大模型生成地理知识思维导图",
          "17、用星火Al大模型生成初中生物说课稿的保姆级教程，其他科目也能用",
          "18、想告诉所有人，这些用星火Al大模型生成历史事件思维导图的好方法！",
          "19、思维导图不会写？用星火AI大模型就可以生成书籍思维导图，快来看",
          "20、 用星火Al大模型竟可以一键生成五四青年节发言稿!内容质量也很赞",
          "21、借助讯飞星火Al大模型生成大学生运动会领导发言稿，就这么简单！",
          "22、教师必备!用星火AI大模型带你写出惊艳全场的班主任发言",
          "23、Al备课太爽了!用星火AI大模型生成高中物理说课稿，再也不用熬夜",
          "24、用星火Al大模型生成小学语文说课稿的指示词分享，换换科目也通用",
          "25、用星火Al大模型要怎样写英语专业开题报告才更好？专业讲师有话说",
          "26、如何用星火Al大模型生成机电专业开题报告？这里有详细步骤讲解！",
          "27、别再熬夜出题了!用星火AI大模型生成小学语文试卷，省时又高效！",
          "28、用星火AI大模型生成初中数学试卷，老师们的工作效率提升百分百！",
          "29、出题也内卷？写好提示词，一分钟星火Al大模型生成了一套生物试卷",
          "30、超强答辩干货！用星火Al大模型生成动物医学类毕业答辩的全解教程",
          "31、如何用星火Al大模型轻松准备土木工程毕业答辩？这里有专家技巧！",
          "32、Al备课究竟有多简单？来看这个用星火Al大模型生成的小学语文教案",
          "33、解密！如何巧用星火Al大模型生成精彩的小学科学教案，别再错过了",
          "34、专业讲师讲解如何用星火Al大模型生成初中地理教案，附带提示词！",
          "35、手把手带你从零开始用星火Al大模型生成新闻传播类论文全是干货",
          "36、如何使用星火Al大模型生成农学类论文？这里有提问技巧和方法！",
          "37、专业老师一步步教你，如何用星火Al大模型写出高质量特殊教育论文",
          "38、高考填志愿一定不能草率!报之前看看讯飞星火给的智能分析吧",
          "39、用讯下星火Al辅助填报高考志愿教程分享，不知道怎么报志愿就看这"
        ],
        "课程回顾": [
          "回顾总结"
        ]
      },
      "requirements": [
        "无需经验"
      ],
      "description": "星火AI大模型是科大讯飞旗下的产品之一，是一个基于人工智能技术的大型语言模型，本课程将带您全面了解并掌握星火AI大模型的使用方法。它作为一款功能强大的智能工具，为我们的日常生活和工作带来了极大的便利。在本教程中，我们将从日常九大场景入手，逐步解锁不同场景下的使用方法，帮助您充分利用星火AI大模型，提升工作效率。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "职场人士",
        "学生群体",
        "自由职业者与创作者",
        "对新技术感兴趣的人士"
      ]
    },
    {
      "title": "LangChain开发实战",
      "url": "https://www.udemy.com/course/langchain-a/",
      "bio": "从基础到进阶的开发实战",
      "objectives": [
        "掌握LangChain从基础到进阶的应用开发",
        "掌握任务链的构建、优化提示模板",
        "掌握AI大模型的自动知识更新技术",
        "增强科技感知力"
      ],
      "course_content": {},
      "requirements": [
        "有一定的编程经验"
      ],
      "description": "掌握未来，从LangChain开始\n个人收获： 加入我们的LangChain开发实战课程，您将开启一段技术革新之旅。无论是AI爱好者、软件开发者还是学术研究者，这门课程都将为您带来前所未有的个人成长体验。\n技能提升：从基础到高级，系统性地掌握LangChain框架，让您在AI应用开发领域游刃有余。\n知识更新：通过学习大模型的自动知识更新技术，保持您的知识库始终处于行业前沿。\n解决复杂问题：课程中的实战案例将教会您如何使用LangChain解决实际问题，提升您的技术应变能力。\n企业价值： 对于企业而言，员工的技术能力直接关系到企业的创新力和市场竞争力。我们的课程为企业带来的价值包括：\n技术升级：员工通过学习LangChain，能够为企业引入最新的AI技术，推动产品和服务的技术升级。\n效率优化：掌握LangChain的员工能够更高效地开发和优化AI应用，提升企业运营效率。\n创新驱动：课程培养的创新思维和实战技能，将激发员工的创造力，为企业带来新的增长点。\n为什么选择我们的课程？\n专业讲师团队：由经验丰富的高级工程师韦玮领衔，确保课程内容的专业性和实用性。\n实战导向：课程设计以实战为核心，通过大量案例分析和项目实战，确保学习效果。\n灵活学习：线上课程设计，打破时间和空间的限制，让学习更加灵活便捷。\n加入课程，让LangChain开发实战课程成为您个人技术飞跃的跳板，企业创新发展的加速器。",
      "target_audience": [
        "AI爱好者与从业者：对人工智能领域有浓厚兴趣的个人，以及正在从事相关工作的专业人士。",
        "开发者与工程师：具备编程能力和技术背景，希望在人工智能领域进一步发展技能的软件开发者和工程师。",
        "AI领域学生与研究者：在学术界进行人工智能相关研究的学生和研究人员，他们可能正在寻找深入学习和研究AI技术的机会。"
      ]
    },
    {
      "title": "ChatGPT应用指南：职场技能通关",
      "url": "https://www.udemy.com/course/chatgpt-ra/",
      "bio": "ChatGPT助力职场技能通关",
      "objectives": [
        "1.全面了解ChatGPT高效办公的流程和策略，快速掌握生成PPT、光速处理Excel的关键技巧",
        "2.增强寻找创业机会，做商业计划书的效率",
        "3.通过学习ChatGPT做市场调研和营销方案，提升竞争力",
        "4.学习实战案例，学习如何用ChatGPT提升自身职场技能"
      ],
      "course_content": {
        "课程内容": [
          "如何用ChatGPT一键生成PPT",
          "如何用ChatGPT光速处理Excel",
          "如何用ChatGPT找创业机会，做商业计划书",
          "如何用ChatGPT做市场调研和营销方案",
          "如何用ChatGPT写周报",
          "如何用ChatGPT写邮件",
          "如何用ChatGPT职业规划、改简历、 模拟面试"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "1.对ChatGPT有兴趣",
        "2.想要通过ChatGPT进行技能提升"
      ],
      "description": "当前，AI正在深刻影响我们的世界，ChatGPT走进职场。高效办公流程和策略的全面把握成为打工人的必备技能。\n\n为此，三节课邀请了长期玩转AI职场技能的陈榕榕老师带来这门课程。\n\n通过学习本课程，你将准确掌握一套高效办公技能，包括快速生成PPT、光速处理Excel等关键技巧。职场新人增强寻找创业机会，做商业计划书的效率，拥有最简单有效的自我培训手册。企业工作者加快做市场调研和营销方案的速度，提升竞争力，拥有最快速便捷的商业策划技能指南。职场打工人丰富内容产出、经验梳理和自我复盘的路径，拥有最全面系统的自我迭代工具。",
      "target_audience": [
        "1.有兴趣学习AI软件办公的职场新人",
        "2.期望提升办公效率的学员",
        "3.有志于掌握前沿办公技术的企业工作者"
      ]
    },
    {
      "title": "تعلم الذكاء الاصطناعي بإنجاز 5 مشاريع عملية – بلا حشو ممل",
      "url": "https://www.udemy.com/course/5-oxvuoz/",
      "bio": "استخدام المكتبات والأدوات الشهيرة مثل Pandas و Scikit-learn إنشاء 5 مشاريع عملية",
      "objectives": [
        "بناء 5 مشاريع عملية في الذكاء الاصطناعي وتعلّم الآلة من الصفر حتى الإتقان",
        "تعللم الذكاء الاصطناعي وتعللم الآلة بدون الحاجة لأي خبرة برمجية مسبقة",
        "القدرة على إنشاء مشاريعك الخاصة في الذكاء الاصطناعي بعد انتهاء الدورة",
        "فهم المفاهيم الأساسية مثل التصنيف، التنبؤ، ومعالجة البيانات بشكل عملي",
        "التعرف على أهم الأدوات والمكتبات المستخدمة في الذكاء الاصطناعي مثل Pandas و Scikit-learn",
        "بناء أساس قوي يمكّنك من التقدم إلى مشاريع أكثر احترافية في الذكاء الاصطناعي",
        "تعلّم أساسيات الذكاء الاصطناعي وتعلّم الآلة بدون الحاجة لأي خبرة برمجية مسبقة"
      ],
      "course_content": {
        "Introduction": [
          "ما هو الذكاء الاصطناعي"
        ],
        "اساسيات": [
          "شرح رئيسي لموقع colab",
          "شرح موقع kaggle",
          "خطوات انشاء اي مشروع ذكاء اصطناعي"
        ],
        "المشاريع": [
          "المشروع الاول",
          "المشروع الثاني",
          "المشروع الثالث",
          "المشروع الرابع",
          "المشروع الخامس"
        ]
      },
      "requirements": [
        "لا تحتاج أي خبرة برمجية مسبقة – الكورس مناسب للمبتدئين تمامًا"
      ],
      "description": "هل تريد دخول عالم الذكاء الاصطناعي وتعلّم الآلة بطريقة ممتعة وسهلة؟ هذا الكورس مُصمّم خصيصًا لأي شخص حتى لو لم يكتب سطر برمجي واحد في حياته.\nبدلاً من الشرح النظري الممل، ستتعلم من خلال تنفيذ 5 مشاريع عملية قوية تغطي أهم المفاهيم والخوارزميات في الذكاء الاصطناعي.\nخلال هذه الدورة ستتعلم:\nكيفية التعامل مع البيانات وتحضيرها للنماذج.\nأهم خوارزميات تعلّم الآلة مثل التصنيف والتنبؤ.\nاستخدام المكتبات الشهيرة مثل Pandas و Scikit-learn لبناء حلول ذكية.\nإنشاء مشاريعك الخاصة بعد الانتهاء من الدورة بثقة.\nهذا الكورس مثالي إذا كنت:\nمبتدئ وتريد دخول مجال الذكاء الاصطناعي بدون تعقيد.\nلا تحب النظريات الطويلة وتفضل التطبيق العملي.\nتبحث عن طريقة مختصرة لإتقان المفاهيم الأساسية بسرعة.\nبنهاية الدورة ستكون قادرًا على:\nفهم أساسيات الذكاء الاصطناعي وتعلّم الآلة.\nبناء مشاريع حقيقية من الصفر.\nاكتساب خبرة عملية تجعلك مستعدًا لمستوى أعلى أو للعمل على مشاريعك الخاصة.\nابدأ رحلتك الآن، وتعلم الذكاء الاصطناعي عمليًا خطوة بخطوة\nايضا سيكون لديك المان كافي بما يلي\n\n\nأساسيات الذكاء الاصطناعي وكيفية التعامل مع البيانات.\n\n\nخوارزميات تعلّم الآلة مثل التصنيف والتنبؤ والتحليل.\n\n\nاستخدام المكتبات والأدوات الشهيرة مثل Pandas و Scikit-learn.\n\n\nإنشاء 5 مشاريع عملية تمنحك الخبرة لبناء مشاريعك الخاصة\nفهم المفاهيم الأساسية مثل التصنيف، التنبؤ، ومعالجة البيانات بشكل عملي.\nالتعرف على أهم الأدوات والمكتبات المستخدمة في الذكاء الاصطناعي مثل Pandas و Scikit-learn.\nبناء أساس قوي يمكّنك من التقدم إلى مشاريع أكثر احترافية في الذكاء الاصطناعي.\nتطبيق ما تعلمته في سيناريوهات حقيقية لتقوية مهاراتك للسوق والعمل الحر",
      "target_audience": [
        "أي شخص يرغب في دخول عالم الذكاء الاصطناعي وتعلّم الآلة بطريقة عملية وممتعة.",
        "المبتدئون الذين ليس لديهم أي خبرة برمجية ويريدون البدء من الصفر.",
        "الطلاب والمهتمون بالتقنية الذين يريدون إضافة مهارات قوية لسيرتهم الذاتية.",
        "الأشخاص الذين يكرهون الشرح النظري الطويل ويفضلون التعلم بالتطبيق المباشر.",
        "المطورون أو العاملون في مجالات أخرى ويرغبون في تعلم الذكاء الاصطناعي بسرعة عبر مشاريع عملية."
      ]
    },
    {
      "title": "Blockchain : Découvrir les fondamentaux",
      "url": "https://www.udemy.com/course/blockchain-decouvrir-les-fondamentaux/",
      "bio": "Naviguer dans le Monde Blockchain : Un Cours Complet sur ses Principes Essentiels",
      "objectives": [
        "Identifier les principaux composants d'une blockchain.",
        "Expliquer le processus de consensus.",
        "Distinction entre les blockchains publiques, privées et consortium.",
        "Examiner les principales cryptomonnaies comme Bitcoin et Ethereum.",
        "Expliquer comment la sécurité est assurée dans une blockchain",
        "Analyser comment la blockchain résout certains problèmes spécifiques.",
        "Découvrir les différents consensus utilisés dans la blockchain"
      ],
      "course_content": {
        "Présentation de la formation": [
          "Présentation de la formation"
        ],
        "Découvrir la technologie blockchain": [
          "Introduire la notion de la blockchain",
          "Explorer les objectifs de la blockchain",
          "Connaitre l'historique de la blockchain",
          "Déterminer les challenges de la blockchain"
        ],
        "Connaitre l'état d'art de la blockchain": [
          "Explorer les différentes applications de la blockchain",
          "Etudier le cas du Bitcoin",
          "Etudier le cas de l'Ethereum"
        ],
        "Identifier les différents types de la blockchain": [
          "Comprendre la blockchain publique",
          "Comprendre la blockchain privée",
          "Comprendre la blockchain hybride"
        ],
        "Découvrir la cryptographie utilisée dans la blockchain": [
          "Explorer la notion du chiffrement",
          "Découvrir les signatures numériques",
          "Comprendre le hachage et son utilisation dans la blockchain"
        ],
        "Décortiquer les clés de la blockchain": [
          "Comprendre le Ledger",
          "Comprendre la notion des blocs",
          "Explorer le processus du minage",
          "Comprendre la notion du Wallet",
          "Comprendre les transactions dans la blockchain",
          "Comprendre la notion de l'incentive",
          "Savoir le concept de l'immutabilité",
          "Savoir le concept de la transparence"
        ],
        "Découvrir les systèmes distribués": [
          "Introduire la notion d'un système distribué",
          "Explorer les différents caractéristiques d'un système distribué",
          "Explorer les différents modèles d'un système distribué",
          "Découvrir le théorème du CAP",
          "Résoudre le problème des généraux byzantins"
        ],
        "Décortiquer les composantes essentielles de la blockchain": [
          "Comprendre la notion du consensus et explorer des exemples de consensus",
          "Explorer l'authentification dans la blockchain",
          "Découvrir le chiffrement dans la blockchain",
          "Différencier entre le On-Chain et le Off-Chain"
        ],
        "Découvrir les technologies du registre distribués - DLT": [
          "Comprendre la relation entre la blockchain et le DLT"
        ],
        "Connaitre les SidesChains": [
          "Introduire la notion de la sideChain",
          "Découvrir le concept du Two-way Peg",
          "Explorer les applications des sideChains"
        ]
      },
      "requirements": [
        "Curiosité et intérêt pour la technologie",
        "Accès à un ordinateur et à Internet",
        "Notions de base en programmation",
        "Familiarité avec les concepts financiers",
        "Compréhension des bases de données"
      ],
      "description": "Dans cette formation Blockchain , vous allez vous familiariser avec les notions fondamentales de fonctionnement de la technologie blockchain.\n#Qu'est-ce que la blockchain\nLa blockchain est une technologie de stockage et de transmission d'informations, transparente, sécurisée et fonctionnant sans organe central de contrôle.\nLa blockchain est la technologie au cœur du Web décentralisé.\nLe concept de base de la blockchain est assez simple, une blockchain est un type de base de données et pour pouvoir comprendre ce que c'est la blockchain, il est utile de comprendre d'abord ce qu'est réellement une base de données.\nUne base de données est un ensemble d'informations stockées électroniquement sur un système informatique.\nLes informations, ou données, dans les bases de données sont généralement structurées sous forme de tableau pour permettre une recherche et un filtrage plus faciles d'informations spécifiques.\nLa différence clé entre une base de données typique et une blockchain est la façon dont les données sont structurées.\nUne blockchain collecte des informations en groupes, également appelées blocs, qui contiennent des ensembles d'informations.\nLes blocs ont certaines capacités de stockage et, lorsqu'ils sont remplis, sont enchaînés sur le bloc précédemment rempli, formant une chaîne de données connue sous le nom de blockchain.\nToutes les nouvelles informations qui suivent ce bloc fraîchement ajouté sont compilées dans un bloc nouvellement formé qui sera ensuite également ajoutées à la chaîne une fois remplie.\nUne base de données structure ses données en tables alors qu'une blockchain, comme son nom l'indique, structure ses données en morceaux (blocs) qui sont enchaînés.\nCela fait en sorte que toutes les blockchains sont des bases de données mais que toutes les bases de données ne sont pas des blockchains.\nCe système crée également une chronologie irréversible des données lorsqu'il est mis en œuvre de manière décentralisée.\nLorsqu'un bloc est rempli, il est gravé dans la pierre et fait partie de cette chronologie.\nChaque bloc de la chaîne reçoit un horodatage exact lorsqu'il est ajouté à la chaîne.\n# Dans cette formation Blockchain sur les fondamentaux de la blockchain\nDans cette formation Blockchain, vous allez découvrir la technologie, son objectif, ses limitations et ses types.\nEnsuite vous allez voir en détail comment les transactions et les protocoles agissent dans le Bitcoin et l'Ethereum .\nEt enfin vous allez explorer les composantes essentielles de la blockchain, à savoir le Wallet , le mining , les consensus et autres.\nSi vous recherchez un cours sur les fondamentaux de la blockchain, je vous suggère de visiter Alphorm un site web de formation et de rechercher le cours spécifique. Vous devriez pouvoir trouver des informations détaillées sur le contenu du cours, les instructeurs et les avis d'autres étudiants. N'hésitez pas à contacter le support d'Alphorm si vous avez des questions spécifiques concernant le cours en question.",
      "target_audience": [
        "Professionnels de l'informatique",
        "Professionnels de la finance",
        "Responsables des systèmes d'information",
        "Étudiants en informatique et en génie logiciel",
        "Entrepreneurs et chefs d'entreprise",
        "Passionnés de technologie"
      ]
    },
    {
      "title": "AI数学①文系・中高年の方でも分かる！AIのための数学入門(線形代数ー行列編)ー国立大学を首席で卒業したプロの講師直伝！",
      "url": "https://www.udemy.com/course/ai1ai-yq/",
      "bio": "40代・50代・60代でも大丈夫！転職・リストラ後にAI時代の基礎力を身につける",
      "objectives": [
        "線形代数における「行列」の基本概念とその構造",
        "行列の四則演算（加法・減法・スカラー倍・積）とその意味",
        "逆行列や単位行列の性質と活用法",
        "1次変換の意味と行列との関連性",
        "行列による平面変換とその視覚的理解（像、直線の変化など）",
        "ケーリー・ハミルトンの定理を用いた行列の記号的操作（上級応用）"
      ],
      "course_content": {
        "AI数学の第一歩：行列の定義と基本演算をマスターしよう」": [
          "行列の相等(A=B)の求め方",
          "行列の演算(実数倍と和・差)の求め方",
          "逆行列と単位行列の仕組み",
          "行列の積(掛け算)の求め方",
          "乗法の結合法則・分配法則の求め方"
        ],
        "1次変換とは何か？行列による変換のしくみを学ぶ": [
          "一次変換の定義",
          "一次変換の行列表現",
          "像と平面全体",
          "像の縮小",
          "直線の像"
        ],
        "行列を使った高度な計算へ：抽象操作とケーリー・ハミルトン定理": [
          "成分計算の仕組み",
          "記号計算(ケーリー・ハミルトン定理を利用)"
        ]
      },
      "requirements": [
        "中学・高校数学の基礎（式の展開・因数分解・関数）を理解していること",
        "ベクトルの基本的な概念（加法・スカラー倍）を理解していること",
        "文系・理系問わず、数学への興味と学び直しへの意欲",
        "AIやデータ分析に関心があり、将来的に活用したいと考えていること",
        "紙とペンを用いた手計算に抵抗がないこと"
      ],
      "description": "国立大学を首席で卒業した講師が、やさしく丁寧に解説！\nこのコースは、AIの基盤である数学的知識、特に「行列」の理解を深めることを目的としています。AIや機械学習に関心はあるけれど、数学が苦手…。そんな不安を抱える方のために、文系や中高年世代でも安心して学べるやさしい講座を用意しました。\n\n\nAIと数学（行列）のつながりとは？\nAIの進化、特に「機械学習」や「ニューラルネットワーク」は、行列計算なしには成立しません。\n画像認識では、画像がピクセルの行列として表現され、それが「重み行列」と乗算されて特徴が抽出されます。音声認識でも、文章の生成でも、自然言語処理でも、背後ではすべて行列の演算が行われています。\nつまり、AIにおいて「行列を理解していない＝仕組みを理解していない」と言っても過言ではありません。\n\n\n高校では教えてくれない「行列」\n日本の高校教育では、2000年代以降「行列」がカリキュラムから除外されました。かつては「数学C」という科目で扱っていたものの、今では大学に入ってから「線形代数」として初めて学ぶ内容になっています。\nそのため、現在の学生や社会人の多くは、行列に触れる機会がほとんどないのが現実です。\nこの講座では、その空白を埋めるべく、高校数学の延長線上で理解できる構成になっています。\n\n\nコースの構成：初級～中級～上級へ\n本コースでは、行列を「初級」「中級」「上級」の3つの段階に分けて丁寧に解説しています。\n【初級編】行列の基本操作\n行列の定義と相等\n加減・スカラー倍・積\n単位行列と逆行列\n分配法則・結合法則などの性質\n【中級編】1次変換とは何か？行列による変換のしくみを学ぶ\n1次変換とは何か？\n行列による平面上の変換の可視化\n像、拡大・縮小、直線の変化\n行列が何をしているかを「図」で理解\n【上級編】記号的計算への応用\n行列の成分による抽象的な操作\nケーリー・ハミルトンの定理の解説\n高度な演算とその意味\nそれぞれのステップで「AIとのつながり」を毎回補足しているため、「なぜこの数学が必要なのか？」が納得できます。\n\n\n講師紹介：国立大学を首席卒業、教えるプロ\n講師は、国立大学を首席で卒業した教育のプロフェッショナルです。長年の教育経験を活かし、わかりにくい概念も図や例を交えて丁寧に解説します。高校～大学初級レベルの内容をベースに、AI時代に必須の知識へとつなげていきます。\n\n\nこのコースはこんな方におすすめ\n数学が苦手だけどAIに興味がある文系の方\n学び直しをしたい40代～60代の方\n転職・リスキリングを考えている方\nAI・Python・データ分析をこれから学びたい方\n理論を理解して強くなりたいプログラマ志望者\n数式だけでなく「意味」や「つながり」を理解したい方\n受講後のメリット\nAIの本質的な理解ができるようになる\n「ブラックボックス」だったニューラルネットの挙動が見える化\n数学への抵抗感がなくなり、今後の学習が楽になる\n中高年世代でも「学び直しができる」と自信がつく\n\n\nAI時代の「基礎力」は、今からでも遅くない！\nAI・機械学習の専門書や実践講座は多数ありますが、その“前段階”としての数学講座は非常に貴重です。特に、「行列」を基礎からわかりやすく解説している教材は、限られています。\nAIの仕組みを“本当に”理解したい方は、まずはここから始めてみませんか。",
      "target_audience": [
        "AIや機械学習をこれから学びたいが、数学に不安がある初学者",
        "文系出身で、数式や行列に苦手意識を持っている社会人",
        "40代〜60代の方で、リストラ・早期退職などを機に新たなスキルを身につけたい方",
        "AIやデータサイエンスの学習を始めるための基礎固めをしたい方",
        "大学生や専門学生で、線形代数をわかりやすく復習したい方",
        "高校数学では行列を習わなかった世代で、大学以降の内容を学びたい方"
      ]
    },
    {
      "title": "【AI 자막】 데이터 구조, 알고리즘, 코딩 인터뷰를 위한 파이썬 클래스!",
      "url": "https://www.udemy.com/course/python-for-data-structures-algorithms-interviews-korean/",
      "bio": "이 파이썬 클래스와 함께 커리어를 부스트하고, 코딩 인터뷰에서 합격하세요!",
      "objectives": [
        "멋진 이력서 작성하기",
        "채용 담당자가 찾을 수 있도록 LinkedIn 및 GitHub 프로필 만드는 법",
        "모든 주요 데이터 구조 및 알고리즘 이해",
        "강의의 모의 면접을 통해 코딩 인터뷰 완벽하게 준비하기"
      ],
      "course_content": {
        "강의 셋업하기": [
          "강의 소개",
          "전체 교육 과정 개요",
          "강의에 대한 도움을 받는 방법!",
          "강의 자주 묻는 질문 (FAQ)"
        ],
        "회사 및 직무 유형": [
          "회사 유형 개요",
          "직무 유형 개요"
        ],
        "이력서 준비": [
          "이력서 준비",
          "이력서 작성 툴",
          "이력서 작성 웹사이트 목록",
          "이력서 체크리스트 검토"
        ],
        "온라인 존재감 만들기": [
          "LinkedIn",
          "GitHub",
          "개인 웹사이트 및 포트폴리오"
        ],
        "네트워킹": [
          "네트워크 구축하기",
          "네트워킹 행사"
        ],
        "채용 정보 검색": [
          "채용 정보 검색하는 법",
          "채용 정보 검색 사이트",
          "구인 게시판 및 사이트 목록",
          "기업 매칭 사이트",
          "기업 매칭 사이트 목록"
        ],
        "인터뷰를 위해 알아야 할 것 (비기술적 측면)": [
          "인터뷰 섹션 개요",
          "인터뷰의 5단계",
          "까다로운 면접 질문",
          "학생용 질문",
          "특별 케이스 인터뷰 질문"
        ],
        "인터뷰 후단계를 위해 알아야 할 것": [
          "연봉 협상",
          "연봉 관련 질문과 답변",
          "레퍼런스 준비"
        ],
        "기술 섹션": [
          "기술 개요",
          "기술 섹션에 대한 도움 받기",
          "강의 질문 시 유의사항"
        ],
        "주피터 노트북 소개": [
          "강의 자료 설치 가이드",
          "Windows - 강의 자료 설치",
          "Mac OSX - 강의 자료 설치",
          "주피터 노트북 개요",
          "강의용 노트북",
          "인터뷰 노트북"
        ]
      },
      "requirements": [
        "파이썬 기초~중급 수준의 지식"
      ],
      "description": "[꼭 읽어주세요] 한글 AI 자막 강의란?\n유데미의 한국어 [자동] AI 자막 서비스로 제공되는 강의입니다.\n강의에 대한 질문사항은 Jose 강사님이 확인하실 수 있도록 Q&A 게시판에 영어로 남겨주시기 바랍니다.\n\n\n안내사항: 파이썬을 완전히 처음 접하는 분이라면 저의 다른 강의인 【한글자막】 Python 완벽 부트캠프 : 파이썬 초보자에서 전문가로! 를 통해 파이썬을 먼저 학습 후 수강해주세요.\n\n\n【AI 자막】 데이터 구조, 알고리즘, 코딩 인터뷰를 위한 파이썬 클래스! 강의에 오신 것을 환영합니다!\n코딩 인터뷰 에서 합격하고 데이터 구조와 알고리즘에 대해 배울 수 있는 가장 포괄적인 파이썬 온라인 클래스 입니다! 이 강의는 여러분의  꿈의 직장에 취직하기 위해 알아야 할 모든 것들을 읽기 쉬운 파이썬 프로그래밍 언어를 활용하여 효율적으로 가르칩니다!\n\n\n이 강의는 소프트웨어 기술 분야에서 훌륭한 직업을 얻기 위해 알아야 할 모든 것을 알려줍니다:\n멋진 이력서 작성하는 법\n채용 담당자가 찾을 수 있도록 LinkedIn 및 GitHub 프로필 만드는 법\n더 많은 취업 기회를 얻기 위한 네트워크 구축 및 활용하는 법\n온라인에서 활용할 수 있는 최신의 잡서칭 툴\n비기술적인 인터뷰 질문에 대한 답변 준비하는 법\n인터뷰 이후 단계 준비하는 법 (연봉 협상 및 레퍼런스 준비)\n주피터 노트북 개요\n알고리즘 분석 및 Big-O 표기법\n배열 시퀀스\n스택, 큐, 덱\n연결 리스트\n재귀 (Recursion)\n트리\n탐색 및 정렬 알고리즘\n그래프 알고리즘\n수수께끼와 퀴즈\n4개의 모의 인터뷰!\n\n\n이 강의에 등록하시고 커리어 목표를 달성하고 IT 분야에서 원하시는 최고의 직업을 얻으세요!",
      "target_audience": [
        "IT 업계에서 커리어를 시작하고자 하는 분!",
        "파이썬 프로그래밍에 익숙한 분!"
      ]
    },
    {
      "title": "达梦（DM）数据库从零开始",
      "url": "https://www.udemy.com/course/dm-collenzhao/",
      "bio": "全面介绍达梦数据库相关知识",
      "objectives": [
        "达梦数据库从业者",
        "专业数据库DBA",
        "数据库爱好者",
        "IT从业者"
      ],
      "course_content": {
        "第01章--达梦数据库基础": [
          "《达梦数据库从零开始》课程概述",
          "01-01-达梦数据库基础概述",
          "01-02-什么是达梦数据库",
          "01-03-达梦数据库产品系列",
          "01-04-安装麒麟Linux",
          "01-05-安装达梦数据库软件",
          "01-06-使用DBCA创建数据库",
          "01-07-数据库的目录结构",
          "01-08-使用disql命令行工具",
          "01-09-使用达梦的图形化工具",
          "01-10-在Docker中部署达梦数据库"
        ],
        "第02章--达梦数据库的体系架构": [
          "02-01-达梦数据库的体系架构概述",
          "02-02-数据库和数据库实例",
          "02-03-什么是表空间",
          "02-04-管理达梦的表空间",
          "02-05-段、簇和数据页",
          "02-06-数据文件",
          "02-07-重做日志文件",
          "02-08-达梦数据库写入数据的过程",
          "02-09-控制文件",
          "02-10-参数配置文件",
          "02-11-其他物理文件",
          "02-12-DM的线程结构",
          "02-13-内存池",
          "02-14-缓冲区",
          "02-15-排序区和哈希区",
          "02-16-达梦数据库实例的启动与关闭",
          "02-17-数据库实例状态和模式",
          "02-18-数据字典",
          "02-19-什么是回滚数据",
          "02-20-回滚数据的工作机制",
          "02-21-回滚数据与重做数据",
          "02-22-管理回滚数据",
          "02-23-闪回的参数设置",
          "02-24-闪回查询",
          "02-25-闪回版本查询"
        ],
        "第03章-安全管理与访问控制": [
          "03-01-安全管理与访问控制概述",
          "03-02-DM的预定义用户",
          "03-03-DM的自定义用户",
          "03-04-DM数据库用户的认证",
          "03-05-基于操作系统的用户认证",
          "03-06-使用概要文件限定用户",
          "03-07-系统权限与对象权限",
          "03-08-使用grant和revoke语句",
          "03-09-撤销具有admin option的系统权限",
          "03-10-撤销具有grant option的对象权限",
          "03-11-DM数据库的角色",
          "03-12-创建自定义角色",
          "03-13-角色的启用与禁用",
          "03-14-DM数据库的审计",
          "03-15-数据库审计的级别",
          "03-16-语句审计",
          "03-17-对象级审计",
          "03-18-审计文件的管理",
          "03-19-审计分析工具dmaudtool"
        ],
        "第04章-管理数据库对象": [
          "04-01-管理数据库对象概述",
          "04-02-表的基本知识和数据类型",
          "04-03-表的基本操作",
          "04-04-主键约束和唯一约束",
          "04-05-检查约束-非空约束-外键约束",
          "04-06-分区表",
          "04-07-临时表",
          "04-08-什么是索引",
          "04-09-创建数据库的索引",
          "04-10-其他类型的索引",
          "04-11-手动收集统计信息",
          "04-12-自动收集统计信息",
          "04-13-视图",
          "04-14-序列",
          "04-15-同义词",
          "04-16-模式Schema"
        ],
        "第05章-应用程序开发": [
          "05-01-应用程序开发概述",
          "05-02-开发第一个DMSQL程序",
          "05-03-DMSQL中的变量",
          "05-04-引用型变量和记录型变量",
          "05-05-条件判断和循环语句",
          "05-06-在DMSQL中使用游标",
          "05-07-如何使用带参数的游标",
          "05-08-系统预定义例外",
          "05-09-用户自定义例外",
          "05-10-DMSQL综合案例",
          "05-11-开发第一个存储过程",
          "05-12-带参数的存储过程",
          "05-13-开发和调用存储函数",
          "05-14-在存储过程中使用out参数",
          "05-15-在out参数中使用游标",
          "05-16-什么是触发器",
          "05-17-利用触发器实现安全性检查",
          "05-18-利用触发器进行数据确认",
          "05-19-利用触发器实现审计"
        ],
        "第06章-事务与锁": [
          "06-01-事务与锁课程简介",
          "06-02-什么是事务",
          "06-03-控制事务",
          "06-04-事务的并发简介",
          "06-05-脏读问题",
          "06-06-不可重复读问题",
          "06-07-设置事务的只读",
          "06-08-事务的可序列化读",
          "06-09-DM锁的模式",
          "06-10-DM锁的粒度",
          "06-11-v$lock的结构",
          "06-12-监控DM数据库的锁",
          "06-13-死锁",
          "06-14-lock table手动加锁",
          "06-15-使用dbms_lock手动加锁",
          "06-16-开发客户端测试程序"
        ],
        "第07章-备份与恢复": [
          "07-01-备份和恢复的基本概念",
          "07-02-数据库的故障类型",
          "07-03-备份的基本术语",
          "07-04-数据库的归档",
          "07-05-备份集",
          "07-06-联机执行SQL备份数据库",
          "07-07-联机执行SQL备份表空间",
          "07-08-联机执行SQL备份表和归档日志",
          "07-09-联机执行SQL备份的管理概述",
          "07-10-联机执行SQL管理备份目录",
          "07-11-联机执行SQL备份集的校验与删除",
          "07-12-联机执行SQL备份信息的查看与监控",
          "07-13-联机执行SQL还原与恢复表",
          "07-14-脱机备份工具dmran基础",
          "07-15-使用dmrman进行备份",
          "07-16-使用dmrman管理备份",
          "07-17-使用dmrman执行数据库的还原恢复",
          "07-18-使用dmrman执行表空间的还原恢复",
          "07-19-查看备份还原的日志",
          "07-20-数据库的逻辑导出与逻辑导入",
          "07-21-使用图形化客户端工具进行备份还原"
        ],
        "第08章-监控与优化": [
          "08-01-监控与优化概述",
          "08-02-数据库实例状态监控",
          "08-03-使用性能监控工具监控性能",
          "08-04- 管理与监控作业的运行",
          "08-05-搭建DEM环境",
          "08-06-使用DEM监控数据库",
          "08-07-性能诊断与优化简介",
          "08-08-收集数据库的诊断信息",
          "08-09-查询优化器简介",
          "08-10-INI参数提示",
          "08-11-索引提示",
          "08-12-优化表的连接方式",
          "08-13-优化表的连接顺序",
          "08-14-统计信息提示",
          "08-15-AWR性能报告",
          "08-16-AWR性能报告分析案例"
        ],
        "第09章-达梦大规模并行处理MPP": [
          "09-01-达梦MPP概述",
          "09-02-MPP中的基本概念",
          "09-03-并行执行计划与MPP的配置文件",
          "09-04-全局连接与本地连接",
          "09-05-搭建DM MPP集群",
          "09-06-DM MPP的系统视图",
          "09-07-建立MPP分布表",
          "09-08-使用dmfldr工具快速装载数据",
          "09-09-MPP系统节点的扩容",
          "09-10-使用DEM监控MPP集群"
        ],
        "第10章-达梦共享存储集群DMDSC": [
          "10-01-DMDSC简介",
          "10-02-DMDSC的组件和体系架构",
          "10-03-DMDSC集群中的核心概念",
          "10-04-DMCSS和DMASM",
          "10-05-配置DMDSC共享磁盘",
          "10-06-配置DMDSC集群",
          "10-07-启动DMDSC集群",
          "10-08-验证集群状态",
          "10-09-DSC的重做日志管理",
          "10-10-DMDSC的实现原理",
          "10-11-深入DMDSC的运行机制",
          "10-12-DMDSC的动态视图"
        ]
      },
      "requirements": [
        "掌握基本的SQL与Linux操作"
      ],
      "description": "本课程对数据库的研发人员、数据库构师、数据库运维人员而设置，将重点覆盖达梦数据库。具体内容包括：数据库的体系架构与安装配置、数据库的用户管理、数据库的并发与锁、备份与恢复技术、数据库的监控优化等知识。通过课程学习让学员全面系统的掌握关系型数据库达梦。\nDM8是达梦公司在总结DM系列产品研发与应用经验的基础上，坚持开放创新、简洁实用的理念，推出的新一代自研的关系型数据库。DM8吸收借鉴当前先进新技术思想与主流数据库产品的优点，融合了分布式、弹性计算与云计算的优势，对灵活性、易用性、可靠性、高安全性等方面进行了大规模改进，多样化架构充分满足不同场景需求，支持超大规模并发事务处理和事务-分析混合型业务处理，动态分配计算资源，实现更精细化的资源利用、更低成本的投入。一个数据库，满足用户多种需求，让用户能更加专注于业务发展。",
      "target_audience": [
        "对达梦数据库感兴趣的IT从业人员"
      ]
    },
    {
      "title": "MySQL数据库进阶实战",
      "url": "https://www.udemy.com/course/collenzhao-mysql/",
      "bio": "全面介绍MySQL数据库相关知识",
      "objectives": [
        "MySQL数据库从业者",
        "计算机IT从业者",
        "数据库爱好者",
        "专业数据库DBA"
      ],
      "course_content": {
        "第01章 MySQL数据库基础": [
          "01-00-本门课程简介",
          "01-01-MySQL数据库简介与分支版本",
          "01-02-MySQL的体系架构",
          "01-03-安装Linux操作系统",
          "01-04-配置Linux环境",
          "01-05-安装MySQL数据库",
          "01-06-启动与关闭MySQL数据库实例",
          "01-07-本地连接和远程连接",
          "01-08-安全连接",
          "01-09-MySQL的存储引擎示例",
          "01-10-数据库和数据库实例",
          "01-11-配置MySQL的多实例环境"
        ],
        "第02章 深入InnoDB存储引擎": [
          "02-00-本章概述",
          "02-01-表空间",
          "02-02-段、区和页",
          "02-03-数据文件",
          "02-04-重做日志文件",
          "02-05-撤销日志文件",
          "02-06-参数文件",
          "02-07-错误日志",
          "02-08-二进制日志文件",
          "02-09-慢查询日志",
          "02-10-全量日志",
          "02-11-其他数据库文件",
          "02-12-内存结构的SGA和PGA",
          "02-13-Buffer缓冲区的状态与链表",
          "02-14-内存的刷新机制",
          "02-15-InnoDB的线程结构"
        ],
        "第03章 用户管理与访问控制": [
          "03-01-用户权限管理基础",
          "03-02-管理MySQL的用户",
          "03-03-丢失了root用户密码",
          "03-04-密码加密插件",
          "03-05-用户密码的复杂度设置",
          "03-06-用户密码的过期设置与用户的锁定",
          "03-07-MySQL的权限管理系统",
          "03-08-权限的授予与撤销",
          "03-09-用户权限的验证过程",
          "03-10-MySQL权限的生效机制",
          "03-11-MySQL访问控制的实现"
        ],
        "第04章 管理的数据库对象": [
          "04-00-本章概述",
          "04-01-MySQL的数据类型",
          "04-02-表的基本操作",
          "04-03-数据的约束条件",
          "04-04-使用主键约束",
          "04-05-使用唯一约束",
          "04-06-使用检查约束和非空约束",
          "04-07-使用外键约束",
          "04-08-表中的碎片",
          "04-09-表的统计信息",
          "04-10-收集统计信息",
          "04-11-使用MySQL的临时表",
          "04-12-什么是索引",
          "04-13-使用explain查看索引信息",
          "04-14-创建普通索引",
          "04-15-创建唯一索引和主键索引",
          "04-16-创建组合索引",
          "04-17-创建全文索引",
          "04-18-创建哈希索引",
          "04-19-使用ICP优化索引",
          "04-20-使用MRR和BKA优化索引",
          "04-21-使用视图简化查询语句",
          "04-22-MySQL的事件"
        ],
        "第05章 应用程序开发": [
          "05-00-本章概述",
          "05-01-定义变量",
          "05-02-运算符与表达式",
          "05-03-begin-end语句块",
          "05-04-IF语句",
          "05-05-CASE语句",
          "05-06-循环控制语句",
          "05-07-异常处理机制",
          "05-08-存储过程与存储函数的基本概念",
          "05-09-开发第一个存储过程",
          "05-10-带输入参数的存储过程",
          "05-11-带多个输入参数的存储过程",
          "05-12-创建和使用存储函数",
          "05-13-存储过程中的out和inout参数",
          "05-14-触发器的基本概念",
          "05-15-利用触发器实现安全性的检查",
          "05-16-利用触发器进行数据的确认",
          "05-17-利用触发器实现审计"
        ],
        "第06章 事务与锁": [
          "06-00-本章概述",
          "06-01-什么是事务",
          "06-02-操作控制事务",
          "06-03-事务的并发和隔离级别",
          "06-04-脏读",
          "06-05-不可重复读",
          "06-06-InnoDB的锁机制",
          "06-07-验证InnoDB的锁机制",
          "06-08-死锁",
          "06-09-监控MySQL的阻塞"
        ],
        "第07章 备份与恢复": [
          "07-00-本章概述",
          "07-01-备份与恢复的方式",
          "07-02-执行第一个冷备份和冷恢复",
          "07-03-使用mysqldump进行热备份与恢复",
          "07-04-使用select...into outfile进行热备份",
          "07-05-使用mydumper进行热备份与恢复",
          "07-06-XtraBackup简介和安装",
          "07-07-使用xtrabackup执行第一个备份与恢复",
          "07-08-XtraBackup执行部分备份和恢复",
          "07-09-XtraBackup执行增量备份和恢复",
          "07-10-使用XtraBackup流式备份",
          "07-11-使用可传输的表空间实现数据的迁移",
          "07-12-MySQL的闪回技术",
          "07-13-使用MySQL的binlog Server备份二进制日志"
        ],
        "第08章 主从复制与主主复制": [
          "08-00-本章概述",
          "08-01-MySQL主从复制基础",
          "08-02-主从复制集群的优点",
          "08-03-搭建MySQL的主从复制",
          "08-04-MySQL主从复制的管理",
          "08-05-MySQL的主主复制"
        ],
        "第09章 MySQL的高可用架构": [
          "09-00-本章概述",
          "09-01-主从架构的单点故障问题与高可用解决方案",
          "09-02-基于MHA的MySQL高可用架构",
          "09-03-配置免密码登录",
          "09-04-基于MHA搭建MySQL高可用架构",
          "09-05-基于KeepAlived的MySQL高可用架构",
          "09-06-其他MySQL高可用解决方案"
        ],
        "第10章 性能优化与运维管理": [
          "10-00-本章概述",
          "10-01-MySQL优化概述与优化方案",
          "10-02-MySQL的基准测试",
          "10-03-安装和使用sysbench",
          "10-04-使用sysbench测试MySQL",
          "10-05-使用Explain查看SQL的执行计划",
          "10-06-SQL执行计划示例",
          "10-07-使用Profile查看SQL的资源消费",
          "10-08-使用SQLAdvisor的建议指导",
          "10-09-使用MySQL Utilities工具箱",
          "10-10-使用Percona Toolkit工具箱",
          "10-11-表的维护与修复工具"
        ]
      },
      "requirements": [
        "基本的Linux操作和SQL操作"
      ],
      "description": "本课程对数据库的研发人员、数据库构师、数据库运维人员而设置，将重点覆盖MySQL数据库。具体内容包括：数据库的体系架构与安装配置、数据库的用户管理与审计、数据库的并发与锁、备份与恢复技术、数据库的主从复制与高可用，以及数据库优化等知识。通过课程学习让学员全面系统的掌握关系型数据库MySQL，尤其具备以下的能力：\n（*）具备常见关系型数据库的技术选型能力，尤其是MySQL。\n（*）具备在企业生产环境中实施安装部署MySQL的能力。\n（*）掌握数据库MySQL的数据库设计能力。\n（*）能够实现数据库的备份恢复与日常运维的管理。\n（*）能够在生产环境中搭建数据库的主从复制架构。\n（*）能够利用不同方式实现数据库的高可用。\n（*）能够合理规划数据库的存储。",
      "target_audience": [
        "对MySQL数据库感兴趣的从业人员"
      ]
    },
    {
      "title": "Python数据分析系列课程：学习文本挖掘",
      "url": "https://www.udemy.com/course/python-ayy/",
      "bio": "从基本的分词、词袋模型、分布式表示等概念开始，多面深入学习文本挖掘技术的各个方面",
      "objectives": [
        "学习文本挖掘的基本技术：分词、词袋模型、分布式表示等",
        "多面深入掌握文本挖掘的关键技术",
        "实战掌握经典案例中的文本挖掘应用方法和技术",
        "帮助学员独立使用Python环境完成各类文本挖掘工作"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "文本挖掘概述": [
          "什么是文本挖掘",
          "文本挖掘的基本流程和任务",
          "文本挖掘的基本思路",
          "语料数据化时需要考虑的工作",
          "TM常用工具介绍1",
          "TM常用工具介绍2"
        ],
        "磨刀不误砍柴工": [
          "IDE简介",
          "安装202004",
          "Notebook演示",
          "NLTK安装",
          "什么是语料库",
          "射雕准备"
        ],
        "分词.": [
          "分词原理简介",
          "结巴分词的基本用法",
          "自定义词典",
          "去除停用词",
          "词性标注及其他"
        ],
        "词云展示": [
          "词频统计",
          "词云概述",
          "Wordcloud安装",
          "绘制词云",
          "设置词云背景",
          "修改词云颜色"
        ],
        "文本信息的向量化": [
          "词袋模型",
          "词袋模型的gensim实现",
          "用Pandas生成文档-词条矩阵",
          "用sklearn库生成文档-词条矩阵",
          "N-gram",
          "分布式表示",
          "共现矩阵",
          "NNLM",
          "word2vec"
        ],
        "关键词提取": [
          "关键词提取的基本思路",
          "TF-IDF算法",
          "TF- IDF算法的jieba实现",
          "TF- IDF算法的sklearn实现",
          "TF-IDF算法的gensim实现",
          "Textrank算法"
        ],
        "抽取文档主题": [
          "主题模型概述",
          "主题模型的sklearn实现",
          "主题模型的gensim实现",
          "主题模型的LDA可视化"
        ],
        "文档相似度": [
          "基本概念",
          "词条相似度：Word2vec训练",
          "词条相似度：Word2vec应用",
          "文档相似度的词袋模型实现",
          "doc2vec",
          "文档聚类"
        ],
        "文本分类": [
          "文本分类概述",
          "朴素贝叶斯算法",
          "算法的sklearn实现",
          "算法的NLTK实现"
        ]
      },
      "requirements": [
        "具备Python基础知识"
      ],
      "description": "文本挖掘（TM），又称自然语言处理（NLP），是AI时代炙手可热的数据分析挖掘前沿领域，其所涉及的人机对话系统，推荐算法，文本分类等技术在BAT等企业中都得到广泛应用。\n本课程将使用经典武侠小说、大众点评抓取结果、微博语料数据等多个实际案例进行教学。\n课程将会从基本的分词、词袋模型、分布式表示等概念开始，多面介绍文本挖掘技术的各个方面，特别会针对目前最热的word2vec，gensim 等结合实际案例进行学习，帮助学员直接升级至业界技术前沿。学习完本课程后，学员将能够独立使用Python环境完成中文文本挖掘的各种工作。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。\n未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "企业内对文本挖掘和数据分析感兴趣的Python工程师、软件研发工程师等",
        "适合企业中的中高级数据分析师、Python数据分析师等提升数据挖掘硬性技术能力",
        "适合目前正在数据挖掘、推荐算法、NLP等领域从事科研工作的在校生和工程师等"
      ]
    },
    {
      "title": "AI数学② 文系でもわかる！AIのための数学入門（積分ー不定積分編）― 国立大学首席卒講師が“足し算の本質”をゼロから",
      "url": "https://www.udemy.com/course/ai2-ai-n/",
      "bio": "40代・50代・60代からの学び直しに最適！数学が苦手でも“AIの仕組み”が見えてくる積分講座",
      "objectives": [
        "不定積分の基本的な意味と役割 　→「積分＝足し算の本質」であることをやさしく理解。",
        "微分と積分の関係性（基本定理）→ 　“逆の操作”としての直感的な理解。",
        "基本的な積分公式の使い方 　→「xⁿ型」など、代表的なパターンを習得。",
        "実践的な積分計算のステップ 　→　公式に当てはめる力、応用的な簡単な問題への対応力。",
        "数式アレルギーを克服する思考のコツ 　→　式の「意味」から理解し、苦手意識を克服する方法を身につける。"
      ],
      "course_content": {
        "不定積分の基本と考え方：微分の逆から積分定数・不定積分の求め方までー国立大学首席で卒業した講師直伝！": [
          "原始関数(不定積分)　(ア)微分することの逆演算",
          "原始関数(不定積分) 　(イ）積分定数の考え方",
          "G(x) = F(x) + C の概念",
          "不定積分の求め方　パターン①",
          "不定積分の求め方　パターン②",
          "「積分する」という概念",
          "( X ー A )^ n の不定積分の求め方",
          "不定積分を求めたら、微分して確認する仕組み"
        ]
      },
      "requirements": [
        "高校数学を忘れてしまった方でもOK 　→　前提知識は一切不要。足し算・引き算レベルからスタートします。",
        "文系出身者・中高年層を想定 　→　数学の専門用語は極力使わず、身近なたとえで説明します。",
        "AIやデータサイエンスに興味がある方 　→　背景知識は不要。関心があればOK！",
        "AI数学①（行列編）を受講していなくても可 　→　この講座単体でも理解できる構成になっています。",
        "パソコンやスマホで動画視聴ができること 　→　特別なソフトやプログラミング環境は不要です。",
        "ノートと筆記用具があればOK 　→　書きながら学ぶことで理解が深まります。"
      ],
      "description": "「AIの計算って、なんで“積分”が必要なの？」\nそんな疑問に、数学が苦手な方でも納得できるようにやさしく答える講座、それが本講座です。\n本シリーズ「AI数学」の第2弾として、今回は“積分”、特に「不定積分」にフォーカスを当てます。\n積分とはいったい何をしているのか？ なぜ“足し算”と呼ばれるのか？\nそしてそれが、なぜAIの仕組みと深くつながっているのか？\n文系・中高年でも“意味”から理解できるよう、1つずつ丁寧に解説します。\n\n\nこの講座の目的\n数式暗記ではなく、「意味」や「考え方」から積分を理解する\nAIや機械学習の計算の裏にある“積分の直感”を身につける\n数学にブランクのある方が、ゼロから安心して学べる場をつくる\n\n\n本講座で学べること\n積分って何？ 「面積」と「足し算」の不思議な関係\n微分と積分の関係：なぜ“逆”といわれるのか\n不定積分の意味と「＋C」がつく理由\n基本的な積分公式の成り立ちと考え方\n関数のグラフと面積イメージを結びつける練習\nAIやデータ処理における積分の役割（確率・重みづけなど）\n講師紹介\n講師は、国立大学を首席で卒業した教育のプロフェッショナル。\n長年にわたり中高年層への指導経験を積み、わかりにくい抽象概念を噛み砕いて説明します。\n「積分は初めて」「学生時代につまずいた」という方も安心して受講できます。\nこのコースはこんな人におすすめ！\n文系出身で数学が苦手だけど、AIや機械学習に興味がある方\n数学を忘れてしまった40代・50代・60代の学び直し層\n転職・リスキリングを考えていて、基礎力をつけたい方\nPythonやAIツールを使う前に、数学を感覚的に理解したい方\n「仕組みから理解したい」と考える、プログラミング学習者や教養層の方\n\n\n受講後に得られるメリット\n積分の本質が「イメージ」でわかるようになる\nAIの背後にある計算の意味が見えるようになる\n数式を暗記するのではなく、「なぜそうなるのか」がわかる\n数学への苦手意識が減り、学び続ける自信がつく\n行列編と合わせて、AI数学の“地盤”が整う\n今からでも遅くない。AI時代に必要な「数学の思考力」\nAIや機械学習の講座はたくさんありますが、その土台となる数学を「わかりやすく、やさしく」教えてくれる教材は多くありません。\nこの積分講座は、そんな“空白”を埋めることを目指しています。\n\n\nあなたも、数式ではなく「意味」から学ぶことで、AIを理解する力を手に入れてみませんか？\n\n前作「行列編」に続くステップとして、ぜひご活用ください。",
      "target_audience": [
        "AIの中身を本質から理解したい文系出身者の方",
        "40代・50代・60代からの“リスキリング”を考えている方",
        "かつて数学が苦手だったけれど、もう一度挑戦したい方",
        "生成AIや機械学習を理解するための数学基礎を学びたい方",
        "難しい数式を避けながらも、AIの仕組みを理論的に理解したい社会人",
        "子どもや学生に教えるために、数学の考え方を学び直したい保護者や教育関係者"
      ]
    },
    {
      "title": "生成式AI大模型应用实战",
      "url": "https://www.udemy.com/course/ai-onpgu/",
      "bio": "深入探索生成式AI大模型的创新应用和挑战应对",
      "objectives": [
        "理解生成式AI大模型的基本原理和方法，掌握其在实际应用中的技术要点",
        "学会使用生成式AI大模型解决实际问题，如文本生成、对话系统、机器翻译等",
        "掌握数据准备和模型训练的关键技巧，以提高生成式AI大模型的性能和效果",
        "能够评估和优化生成式AI大模型的质量和效率，以满足实际应用需求"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "第1章 GAI（生成式AI）对个人和企业的最大价值": [
          "01-0 先导课",
          "01-1 AIGC是影响未来5年的天花板科技",
          "01-2 认真系统学习（AIGC）的应用和场景范围",
          "01-3 AIGC在当今世界的重要性和应用范围",
          "01-4 AIGC基本工作原理和技术",
          "01-5 最新AIGC领域动态和趋势",
          "01-6 GPT大浪潮-个体决策参考"
        ],
        "第2章 基础学懂大模型和AIGC工具的底层逻辑": [
          "02-0 章节导读",
          "02-1学懂科技树掌握科技发展底层逻辑",
          "02-2 AIGC领域常用算法编程语言和工具",
          "02-3 安装和配置AIGC开发环境",
          "02-4 基本的文本生成示例和代码解析",
          "02-4.2 基本的文本生成示例和代码解析",
          "02-4.3 基本的文本生成示例和代码解析",
          "02-5 最新AIGC工具框架介绍"
        ],
        "第3章 未来是深度全面数字化且Data for AI": [
          "03-0 章节导读",
          "03-1 世界500强和创业团队分别落地应用案例",
          "03-1.2世界500强和创业团队分别落地应用案例",
          "03-2 大模型分层未来实战趋势",
          "03-3 企业案例实战研究"
        ],
        "第4章 汇总获取AI红利": [
          "04-0 章节导读",
          "04-1 获得AIGC大模型红利以及Transformer技术核心",
          "04-2 AI领域的5个重大转变和大模型训练",
          "04-3 改进大模型有监督的微调",
          "04-4 大语言模型必懂算力篇",
          "04-5 大语言模型应用和商业赋能",
          "04-6 大语言模型应用实战",
          "04-7 大模型在国外的应用实战",
          "04-8 大语言模型在国内应用实战"
        ],
        "课程回顾": [
          "课程寄语"
        ]
      },
      "requirements": [
        "有一定AI大模型经验的学员"
      ],
      "description": "本课程旨在帮助学员掌握生成式AI大模型的实际应用技能。生成式AI大模型是指基于深度学习的大规模神经网络模型，能够生成高质量的文本、图像和音频等内容。课程将介绍生成式AI大模型的基本原理和方法，并通过实际案例进行实战演练，让学员能够在实际应用中灵活运用这些模型。\n课程内容包括：\n生成式AI大模型概述：介绍生成式AI大模型的定义、发展历程和应用领域。\n数据准备与清洗：讲解如何准备和清洗用于生成式AI大模型训练的数据，以提高模型的质量和效果。\n生成式AI大模型架构：介绍常用的生成式AI大模型架构，如GPT、BERT等，并详细解释其原理和特点。\n模型训练与调优：讲解生成式AI大模型的训练过程和关键技巧，如模型调参、迁移学习等。\n实战案例分析：通过实际应用案例，展示生成式AI大模型在文本生成、对话系统、机器翻译等领域的应用效果。\n模型评估与优化：介绍生成式AI大模型的评估指标和方法，以及如何优化模型的质量和效率。\n案例分享和讨论：与其他学员分享生成式AI大模型应用的经验，进行案例讨论和解答疑惑。\n通过学习本课程，学员将能够掌握生成式AI大模型的实际应用技能，能够使用这些模型解决实际问题，如文本生成、对话系统的构建、机器翻译等。无论您是数据科学家、机器学习工程师还是自然语言处理研究人员，本课程都将为您提供实用的工具和方法，帮助您在生成式AI大模型应用领域取得突破和创新。",
      "target_audience": [
        "数据科学家",
        "机器学习工程师",
        "自然语言处理研究人员"
      ]
    },
    {
      "title": "深度学习——神经网络实战精讲",
      "url": "https://www.udemy.com/course/vxxlzhfs/",
      "bio": "全面解读神经网络应用场景",
      "objectives": [
        "了解卷积神经网络的基本概念",
        "了解图像识别基本概念",
        "掌握图像识别的工作流程",
        "提升深度学习综合应用能力"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "卷积神经网络原理与参数解读 共7节 | 1小时15分钟": [
          "卷积神经网络应用领域",
          "卷积的作用",
          "卷积特征值计算方法",
          "步长与卷积核大小对结果的影响",
          "特征图尺寸与池化层",
          "网络架构与残差网络",
          "残差网络Resnt与感受野"
        ],
        "图像识别核心模块实战解读": [
          "卷积网络参数定义",
          "网络流程解读",
          "Vision模块与分类任务数据集定义与配置",
          "数据预处理与数据增强模块",
          "Batch数据制作"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "有一定Python语言基础"
      ],
      "description": "卷积神经网络（CNN）在计算机视觉领域已经取得了巨大成功，当前众多传统计算机视觉算法已经被深度学习所替代，这也导致深度学习以及卷积神经网络成为研究的热点。图像识别是计算机视觉领域最基本、最核心的问题，其常用算法也正是卷积神经网络。\n本门课程我们将对卷积神经网络进行深入探究，课程从卷积神经网络原理与图像识别核心模块两个部分展开，全面讲解卷积神经网络的基本概念与典型应用。\n与此同时，我们还将引导学员运用CNN训练图像分类模型，从数据预处理到网络模块设置再到网络模型的保存与测试，带领学员从理论到应用，一步步掌握卷积神经网络。",
      "target_audience": [
        "对人工智能感兴趣的学员",
        "具备一定Python语言基础的学员",
        "计算机相关专业大学生"
      ]
    },
    {
      "title": "AI辅助英文原版书“悦读”",
      "url": "https://www.udemy.com/course/ai-nlnmn/",
      "bio": "巧用AI如母语者般阅读",
      "objectives": [
        "掌握阅读方法与AI技能，一次学习终生受用",
        "巧用AI如母语者般阅读",
        "3本好书, 享受人气讲师高水准伴读",
        "从阅读到AI应用,，双轨学习能力倍增"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲",
          "引入讲解"
        ],
        "课程内容": [
          "如母语者般品读《马斯克传》",
          "从读到学，延伸阅读《马斯克传》",
          "AI变身文学导师带你精读《了不起的盖茨比》",
          "AI让你如临其境深度对话主人公“盖茨比”",
          "读懂《未来简史》中的“争议”与自我立场",
          "Al支撑阅读背景知识扩充提升阅读体验"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "会使用gpt端人员"
      ],
      "description": "在AI智能办公时代，职场竞争日益激烈，掌握英语阅读和沟通能力成为了不可或缺的重要技能。然而，对于很多职场人士来说，阅读英文原版书籍却是一项极具挑战的任务。为了帮助大家解决这一难题，三节课与黄河清老师、百姓AI携手特别推出了《AI辅助英文原版书“悦读”》课程。 本课程通过智能识别、机器学习和自然语言处理等技术，实现英文原版书籍的智能推荐、词汇解析、句子翻译等功能。通过先进的AI技术，实现英文原版书籍的智能推荐和解析，帮助大家更加轻松地阅读和理解。结合在线阅读、视频讲解、互动讨论等多种学习模式，让大家能够更加灵活地学习英语阅读技能。总之，课程将帮助大家克服英语阅读的障碍，提高英语阅读和沟通能力，为职场竞争增加重要的砝码。",
      "target_audience": [
        "想要提升英语阅读能力 原文书爱好者 拓宽AI边界，增长使用能力"
      ]
    },
    {
      "title": "AIGC在游戏⽣态中的应⽤探究：如何提升效率与创意",
      "url": "https://www.udemy.com/course/aigc-qlz/",
      "bio": "深度探索AIGC技术如何重塑游戏开发流程",
      "objectives": [
        "掌握AIGC的基本原理和在游戏开发中的应用场景。",
        "学习如何运用AIGC技术提升游戏开发的效率与创意。",
        "了解AIGC技术对游戏生态的影响和未来发展趋势。",
        "通过实际案例分析，掌握AIGC技术的最佳实践和应用技巧。",
        "建立与行业专家Joyce讲师的连接，拓展人脉和交流机会。"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "第一章 AIGC、OpenAI和ChatGPT是什么",
          "第二章 AIGC在游戏、电商、直播、社交行业的应用",
          "第三章 AIGC对互联网生态的改进",
          "第四章 AIGC的发展和前景"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "无需课程基础。您会学到您想学到的所有内容"
      ],
      "description": "在游戏开发过程中，效率和创意是两个核心要素。然而，很多团队在追求效率与创意之间常常面临诸多挑战。\n为此，三节课邀请了拥有丰富经验的Joyce讲师，带来了这门课程。在这门课程中，Joyce讲师将结合实际案例，深入讲解如何运用AIGC技术提升游戏开发的效率和创意。\n通过本课程的学习，学员将掌握如何利用AIGC技术优化游戏开发的全流程、了解AIGC的基本原理、应用场景和最佳实践，提升游戏的质量和用户体验，从而在竞争激烈的游戏市场中脱颖而出。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "游戏开发者，掌握AIGC技术，提升游戏开发效率与创意。",
        "游戏策划师，了解AIGC应用场景，优化游戏设计。",
        "游戏美术师，运用AIGC技术，提升游戏视觉效果。",
        "游戏运营与推广人员，利用AIGC技术，提高游戏用户留存率。",
        "对游戏行业和AIGC技术感兴趣的所有人员，了解游戏行业发展趋势，拓展个人技能。"
      ]
    },
    {
      "title": "Pythonで学ぶ実践強化学習：Q学習で迷路AIを作ろう",
      "url": "https://www.udemy.com/course/learn-rl/",
      "bio": "手を動かして学ぶ！強化学習の基礎から迷路AIの実装まで",
      "objectives": [
        "強化学習の基礎を理解し、Q学習・DQNを説明できる",
        "Q学習とDQNをPythonとGoogle Colab上で実装できる",
        "OpenAI Gymの環境を活用し、強化学習アルゴリズムを適用できる",
        "自作の迷路環境を作成し、強化学習エージェントを訓練できる"
      ],
      "course_content": {
        "はじめに": [
          "講座紹介",
          "Google Colabの使い方"
        ],
        "強化学習の基本概念": [
          "強化学習とは？",
          "エージェントと環境の関係",
          "マルコフ決定過程 (MDP) とは？",
          "価値関数とQ値"
        ],
        "Q学習を実装しよう": [
          "Q学習とは？",
          "Q学習を実装しよう"
        ],
        "深層強化学習 (Deep Q-Network, DQN)": [
          "Q学習の限界とDQNの登場",
          "PyTorchでDQNを実装"
        ],
        "実践プロジェクト: 自作迷路で強化学習エージェントを作ろう": [
          "実践プロジェクト: 自作迷路で強化学習エージェントを作ろう"
        ]
      },
      "requirements": [
        "Pythonの基礎知識があること",
        "Google Colabの基本的な使い方を知っていること",
        "高校レベルの数学知識",
        "機械学習やニューラルネットワークの基礎知識は不要"
      ],
      "description": "この講座は、プログラミング初心者でも、数学が苦手でも、強化学習を実践的に学びたい方のための講座です。\nPythonとGoogle Colaboratoryを使いながら、Q学習やDQN（Deep Q-Network）を基礎から学び、迷路を解くAIをゼロから実装できるようになります。\n強化学習と聞くと難しそうに感じるかもしれませんが、心配はいりません。\nこの講座では、直感的に理解できるように図や具体例を交えて解説し、Pythonのコードを書きながら学べるため、着実にスキルを身につけられます。\n「AIが試行錯誤しながら学習する仕組みを知りたい」「自分の手で強化学習モデルを動かしてみたい」という方にぴったりの内容です。\nこの講座で学べること\n強化学習の基本概念（エージェント、環境、マルコフ決定過程など）\nPythonとGoogle Colaboratoryを使ったプログラミング\nQ学習を活用した迷路AIの実装\nDQN（深層強化学習）の仕組みと実装方法\nOpenAI Gymを使った強化学習の応用\nこの講座がおすすめな理由\nわかりやすい：難しい数式を極力使わず、直感的な説明を重視\n実践的：実際に手を動かしながら学ぶことで、知識が定着しやすい\n初心者向け：Pythonの基礎があればOK。強化学習の前提知識は不要\n講座の内容\n1. はじめに\n講座の目的と学べること\n強化学習とは？（機械学習との違い、実世界での応用例）\nGoogle Colabの基本的な使い方\n2. 強化学習の基本概念\nエージェントと環境の関係\nマルコフ決定過程（MDP）とは？\n価値関数とQ値の考え方\n3. Q学習を実装しよう\nQ学習の理論とアルゴリズム\nグリッドワールドを使ったQ学習の実装\n4. 深層強化学習（DQN）\nQ学習の限界とDQNの登場\nPyTorchを使ったDQNの実装（CartPole環境）\n5. 実践プロジェクト：迷路AIを作ろう\n迷路環境の作成\nQ学習を使った迷路解決AIの実装\nこんな方におすすめ\n強化学習を基礎から学びたい初心者\n理論だけでなく、実際にコードを書きながら学びたい方\nAIが試行錯誤しながら学習する仕組みに興味がある方\n強化学習の面白さを実感しながら学べるこの講座、ぜひ一緒に挑戦してみましょう！",
      "target_audience": [
        "Pythonの基礎を学んだ後、実践的な応用を探している人",
        "強化学習に興味があるが、初心者向けの実践的な学習教材を探している人",
        "ゲームAIや自律エージェントの作成に興味がある人",
        "AIや機械学習を学びたいエンジニア・データサイエンス入門者"
      ]
    },
    {
      "title": "De Excel y SQL a Python: Series de Tiempo Financieras",
      "url": "https://www.udemy.com/course/python_series_tiempo/",
      "bio": "Aprende a analizar y predecir tendencias financieras con Python, desde la extracción de datos hasta dashboards",
      "objectives": [
        "Extraer y limpiar datos de series de tiempo desde Excel y SQL para su análisis en Python.",
        "Realizar análisis exploratorio de datos (EDA) para identificar patrones, tendencias y valores atípicos en series de tiempo.",
        "Aplicar modelos de pronósticos como Holt-Winters, SARIMA y Prophet para predecir ventas futuras.",
        "Crear visualizaciones interactivas y paneles de control con Plotly para comunicar resultados a partes interesadas."
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "¿Qué son las series de tiempo?",
          "¿Qué son las series de tiempo?",
          "Configuración del entorno",
          "Instalación de paquetes en Python"
        ],
        "Extracción y Limpieza de Datos": [
          "Importar datos desde Excel y SQL",
          "Limpieza de datos: Valores nulos y formatos",
          "Importación y Limpieza de Datos"
        ],
        "Análisis Exploratorio de Datos (EDA)": [
          "Estadísticas básicas de series de tiempo",
          "Detección de valores atípicos",
          "Exploración de tendencias y estacionalidad",
          "Análisis Exploratorio de Datos (EDA)"
        ],
        "Modelado de Series de Tiempo": [
          "Modelado de series de tiempo",
          "Implementación de Holt-Winters",
          "Implementación de SARIMA y Prophet",
          "Comparación de Modelos y Pronósticos"
        ],
        "Visualización y Comunicación de Resultados": [
          "Visualización y Comunicación de Resultados",
          "Cierre del curso"
        ]
      },
      "requirements": [
        "Intermedio en análisis de datos (saben usar Excel para cálculos básicos o SQL para consultas), pero principiantes o intermedios en Python."
      ],
      "description": "¿Usas Excel o SQL para analizar datos financieros, pero quieres dar el salto a Python para automatizar y potenciar tus análisis? De Excel y SQL a Python: Series de Tiempo Financieras es tu curso ideal. Diseñado por los expertos de Soitra Digital, líderes en transformación digital con experiencia en banca, comercio y tecnología, este curso práctico te guía paso a paso para dominar el análisis de series de tiempo con Python, sin necesidad de ser experto en programación.\nA través de un caso real de ventas de vehículos, aprenderás a:\nExtraer y limpiar datos desde Excel y SQL usando pandas y SQLAlchemy.\nRealizar análisis exploratorios para identificar tendencias, estacionalidad y valores atípicos.\nAplicar modelos de pronósticos como Holt-Winters, SARIMA y Prophet para predecir ventas futuras.\nCrear visualizaciones interactivas y dashboards impactantes con Plotly para comunicar resultados a stakeholders.\nCon ejercicios interactivos, cuestionarios y un notebook completo en Jupyter, este curso te prepara para aplicar técnicas avanzadas en tu trabajo desde el primer día. Perfecto para analistas de datos, financieros o profesionales de negocio con experiencia en Excel o SQL, pero principiantes o intermedios en Python. ¡Transforma tus datos en decisiones estratégicas, optimiza procesos y lleva tu carrera al siguiente nivel con habilidades demandadas en el mercado actual!",
      "target_audience": [
        "Profesionales que trabajan con datos en entornos laborales o de negocio, familiarizados con Excel y/o SQL, pero con poca o ninguna experiencia en Python para series de tiempo."
      ]
    },
    {
      "title": "AI In Project Management & Manage AI Projects",
      "url": "https://www.udemy.com/course/ai-in-project-management/",
      "bio": "استخدام الذكاء الاصطناعى فى ادارة المشاريع",
      "objectives": [
        "Demonstrate a comprehensive understanding of project management principles as they relate to AI.",
        "Apply AI tools and techniques to improve project efficiency and effectiveness.",
        "Communicate effectively with stakeholders about AI project goals and outcomes.",
        "Evaluate the impact of AI on project success and make data-driven decisions."
      ],
      "course_content": {
        "Course Introduction": [
          "Course Introduction.V2"
        ],
        "Part 1- 1 Introduction to AI in Project Management": [
          "1-Introduction Part one",
          "1-Introduction Part two"
        ],
        "Part 1- 2- AI tools In Project Management": [
          "AI tools overview",
          "2-Chat GPT settings",
          "3-Claude Tool",
          "4-PMI infinity",
          "5-Gemini",
          "6-AI Google studio Part one",
          "6-AI Google studio Part two",
          "7-Deep Seek",
          "8-Gamma",
          "9-Copilot",
          "10-Napkin"
        ],
        "Part Two :Managing AI Projects.": [
          "Manage AI Projects Part one",
          "Managing AI Projects Part two"
        ]
      },
      "requirements": [
        "No prior AI or programming experience is required. This course is designed to be accessible to learners from diverse backgrounds, including those new to artificial intelligence or project management. A basic understanding of project management concepts is helpful but not mandatory. All necessary concepts, tools, and applications will be introduced progressively, starting from AI fundamentals and evolving toward practical project management use cases."
      ],
      "description": "Course Introduction\nThis Artificial Intelligence (AI) in Project Management training course is tailored to equip project managers and their teams with state-of-the-art AI tools, specifically designed to enhance project management processes. Participants will learn how to effectively implement AI solutions to streamline operations, predict risks, and improve decision-making.\nBy the end of this Artificial Intelligence (AI) in Project Management training course, attendees will have a solid understanding of practical AI applications that can be smoothly integrated into their project workflows, focusing on real-world examples to demonstrate the transformative impact of AI on managing complex projects successfully.\nThis Artificial Intelligence (AI) in Project Management training course will highlight:\n· Integration of AI technologies in project scheduling and resource management.\n· Advanced techniques in AI for predicting and managing project risks.\n· Demonstrations of AI effectiveness in project management through real-world scenarios.\n· Hands-on sessions with AI software tools designed for project management.\n· Strategies for adopting AI within existing project management frameworks.\nObjectives\nBy the end of this Artificial Intelligence (AI) in Project Management training course, participants will be able to:\n· Grasp the fundamental concepts of AI as they apply to project management.\n· Apply AI tools to optimize project scheduling and resource allocation.\n· Utilize AI techniques for effective risk prediction and mitigation strategies.\n· Seamlessly integrate AI solutions into their project management practices.\n· Evaluate the benefits and potential challenges of AI in project settings.\n· Develop a strategic approach to implement AI-driven innovations in their projects.\nTraining Methodology\nThe training course will feature interactive lectures, practical exercises with AI tools, in-depth discussions, individual feedback sessions, and live demonstrations to ensure a thorough understanding and application of the concepts taught.\nOrganisational Impact\nOrganisations will benefit through:\n· Enhanced efficiency and productivity in project management tasks.\n· Improved risk management capabilities.\n· Reduction in project delivery times and cost overruns.\n· Increased competitive edge by adopting advanced AI technologies.\n· Better alignment of project outcomes with organizational goals.\nPersonal Impact\nParticipants will gain:\n· Advanced skills in using AI tools for project management.\n· Enhanced ability to anticipate and mitigate risks using AI.\n· Greater confidence in managing complex projects.\n· Improved problem-solving and decision-making capabilities.\n· Up-to-date knowledge of the latest AI technologies in project management.\nWho Should Attend?\n· Project Managers and Team Leaders\n· IT Professionals in Project Teams\n· Risk Managers\n· Business Analysts\n· Innovation Managers\n· Anyone interested in integrating AI technology into project management processes\nCourse Outline\nPart One : Introduction\n1.What is AI?\n2.Key Terminologies and Concepts in AI .\n3.Prompts Engineering\n4.Steps for Integrating AI into Project Workflows.\n\n\n\n\nPart Two :Managing AI Projects.\n1.Examples for AI Projects\n2.The Need for an Approach to Successfully Run and Manage AI Projects\n3.Addressing AI Project Failures\n4.The Seven Patterns of AI\n5.The Six Phases of AI Projects\n6.Making AI Projects Not Only Successful but Also Trustworthy\n7. Key Roles in AI Projects\nDay two :\n3- AI Tools in Project Management.\n•AI in Contract review\n•AI For review and create B. Case.\n•AI For Check and create Project compliance and governance.\n•AI in Project Initiating.\n•AI In Project Planning.\n•AI in Project execution\n•AI in Project mentoring and controlling.\n•AI in Project closing",
      "target_audience": [
        "Project managers looking to enhance their skills in AI project management.",
        "Professionals in technology and business sectors who wish to understand the implications of AI on project outcomes.",
        "Students and recent graduates interested in pursuing a career in project management with a focus on AI."
      ]
    },
    {
      "title": "Machine Learning e Modelos de IA em Python para dados",
      "url": "https://www.udemy.com/course/machine-learning-fundamentos-algoritmos-e-aplicacoes/",
      "bio": "Aprenda Machine Learning, Python e Data Science com algoritmos aplicados a problemas reais de análise de dados",
      "objectives": [
        "Tarefas de aprendizado de máquina",
        "Algorithmos e técnicas de amostragem, treinamento e teste de dados",
        "Técnicas de avaliação e desempenho de modelos de aprendizado de máquina",
        "Domínio e prática de modelos de regressão, classificação, agrupamento, árvores de decisão, redes neurais e suport vector machine (SVM)."
      ],
      "course_content": {
        "Introdução": [
          "Apresentar aos alunos objetivo geral de aprendizagem e estrutura do curso"
        ],
        "Módulo 1: Contexto e definições - Parte 2": [
          "Histórico e Contexto de AI, Machine Learning",
          "Contexto e Definições"
        ],
        "Módulo 2 – Tarefas de Aprendizado": [
          "Tarefas de Aprendizado"
        ],
        "Módulo 3: Viés Indutivo": [
          "Viés, Variância, Divisão de dados, Validação",
          "Prática - Introdução ao Google Colab",
          "Prática - Regressão Linear, Viés, Erro",
          "Prática - Regressão Logística"
        ],
        "Módulo 4: Avaliação de Desempenho": [
          "Módulo 4: Avaliação de Desempenho"
        ],
        "Módulo 5: Modelos KNN": [
          "Algorithms_proximidade_KNN"
        ],
        "Algorithms_proximidade_KNN_Prática": [
          "Aula Prática _ Modelos KNN"
        ],
        "Módulo 6: Algorithms_Árvores de Decisão": [
          "Árvore de Decisão"
        ],
        "Módulo 7 - Redes Neurais (Parte I)": [
          "Módulo 7 - Redes Neurais I",
          "Aula Prática MPL"
        ],
        "Módulo 7 - Redes Neurais (Parte II)": [
          "Redes Neurais (Parte II)"
        ]
      },
      "requirements": [
        "Não é necessário ter formação prévia em programação ou Ciência de Dados — o curso apresenta conceitos passo a passo",
        "Ter interesse em aprender Machine Learning, Algorithms e Modelos de aprendizado de máquina",
        "Será necessário ter login na Google e utilizar o Google Colab"
      ],
      "description": "Este curso contém uso de Inteligência Artificial, incluindo a criação de vídeos e áudio do instrutor, proporcionando uma experiência de aprendizado mais dinâmica e envolvente.\nEste curso foi desenvolvido para guiar você passo a passo pelo universo do Machine Learning (Aprendizado de Máquina) e da Inteligência Artificial, desde a compreensão conceitual até a aplicação prática em Python.\nAo longo de 7 módulos, você aprenderá a utilizar algoritmos clássicos e modernos para resolver problemas reais de Data Science, estatística aplicada e análise de dados.\nO que você vai aprender:\nFundamentos de Machine Learning e Inteligência Artificial\nDiferença entre aprendizado supervisionado, não supervisionado e por reforço\nComo aplicar regressão, classificação e clusterização em Python\nConceitos de viés, variância, overfitting e técnicas de reamostragem\nAlgoritmos como KNN, Árvores de Decisão, SVM e Redes Neurais\nComo comparar modelos usando métricas estatísticas e validação cruzada\nPúblico-alvo:\nEstudantes e profissionais que desejam iniciar em Data Science e Machine Learning\nInteressados em aplicar Python para Inteligência Artificial\nProfissionais de áreas como Administração, Economia, Finanças, Negócios e Tecnologia\nQualquer pessoa que deseja aprender algoritmos de Machine Learning aplicados a problemas reais\nAo final, você será capaz de construir, aplicar e avaliar modelos de Machine Learning em Python, dominando as bases para avançar em projetos mais complexos de IA e Data Science.",
      "target_audience": [
        "Estudantes e profissionais interessados em Machine Learning e algorithms de aprendizado de máquina",
        "Profissionais de diversas áreas que desejam aprimorar suas habilidades em modelagem preditiva através de machine learning",
        "Profissionais de análise de dados ou modelagem que buscam integrar algoritmos ou modelos de machine learning para extração de insights e realização de tarefas",
        "Qualquer pessoa que queira aprender a aplicar AI, Machine Learning em projetos reais"
      ]
    },
    {
      "title": "【2025年版】DVCで実現するMLOps実践ガイド【python, DVC】",
      "url": "https://www.udemy.com/course/dvc-mlops-reproduce/",
      "bio": "データバージョン管理と再現可能な実験パイプラインの構築",
      "objectives": [
        "データセットの効率的なバージョン管理ができるようになる",
        "チーム内でデータセットを共有・同期する方法を理解し実践できる",
        "MLOpsのベストプラクティスに基づいた開発ができるようになる",
        "データ、コード、モデルの依存関係を適切に管理できる",
        "機械学習実験の自動化と再現性の確保が可能になる"
      ],
      "course_content": {
        "00-ソフトウェアのインストール": [
          "gitのインストール",
          "(オプション)tortoise gitのインストール",
          "(オプション)git krakenのインストール",
          "python環境、minicondaのインストール",
          "本セクションで使用するコード"
        ],
        "01-dvcの紹介とインストール": [
          "DATAopsやMLopsについて",
          "dvcを利用するメリット",
          "dvcのインストール",
          "本セクションで使用するコード"
        ],
        "02-dvcの操作方法": [
          "dvc init, add, commit, status",
          "バージョンの移動, checkout",
          "git branchをつかった実験の管理, dvc remove, checkout",
          "dvc remote addとstrage設定",
          "dvc push, pull, fetch",
          "本セクションで使用するコード"
        ],
        "03-dvcによる再現可能な機械学習プロジェクトの作成": [
          "pipline stageとは",
          "dvc stage add, gitの監視対象の切り替え",
          "高度なstage設定と再現コマンドrepro",
          "dvc metrics, show, diff",
          "dvc plots, show, diff",
          "dvc prams diff",
          "dvc exp run, show, queue",
          "stageのグラフによる可視化、関係図",
          "高度な実験の設定、dvc exp metric all-branch",
          "本セクションで使用するコード",
          "ブランチ別のデータセットの作成コード"
        ],
        "04-その他、周辺知識": [
          "dvc gc",
          "dvc install",
          "最後に"
        ],
        "05-付録、パラメーター探索、AWS S3のストレージ設定": [
          "foreachとmatrixによるstage設定",
          "AWS S3のストレージ設定",
          "本セクションで使用するコード"
        ]
      },
      "requirements": [
        "Pythonによるプログラミングの基礎的な理解",
        "機械学習の基本概念の理解（学習、評価、モデル選択など）",
        "Git による基本的なバージョン管理の経験",
        "コマンドライン操作の基本的な知識"
      ],
      "description": "機械学習プロジェクトにおいて、データやモデルのバージョン管理、実験の再現性確保は重要な課題です。\n本コースでは、Data Version Control（DVC）を活用して、これらの課題を効率的に解決する実践的なアプローチを学びます。\nDVCを用いたデータバージョン管理の基礎から、再現可能な実験パイプラインの構築、チーム開発におけるベストプラクティスまで、実際のプロジェクトで直面する具体的な課題に焦点を当てて解説します。\nすでに機械学習プロジェクトに携わっているデータサイエンティストやMLエンジニアの方々に最適な内容となっています。Pythonによるプログラミングと機械学習の基礎知識があれば、スムーズに学習を進めることができます。\n本コースはwindows機を使用します。\n\n\nハンズオン形式の演習を通じて、以下のスキルを習得できます\n大規模データセットのバージョン管理と共有方法\n実験結果の追跡と再現性の確保\n効率的な機械学習パイプラインの構築",
      "target_audience": [
        "データサイエンティストやML エンジニアとして、より体系的な実験管理を目指している方",
        "ML プロジェクトのワークフローを改善したい方",
        "個人やチームの機械学習プロジェクトで再現性の課題に直面している実務者",
        "MLOpsの実践的なスキルを身につけたいデータサイエンス実践者"
      ]
    },
    {
      "title": "Introducción a la visualización de datos en R con ggplot2",
      "url": "https://www.udemy.com/course/introggplot2/",
      "bio": "Aprende a hacer gráficos con ggplot2",
      "objectives": [
        "Entender cuáles son los elementos esenciales de un gráfico en ggplot2.",
        "Crear histogramas, gráficos de dispersión, gráficos de barra y columna, boxplots y gráficos de línea.",
        "Identificar cuando utilizar los componentes estéticos vs atributos para cambiar color, forma, tamaño y elementos del gráfico.",
        "Modificar los títulos y ejes de los gráficos.",
        "Exportar los gráficos en diferentes formatos."
      ],
      "course_content": {
        "Introducción del curso": [
          "Introducción",
          "Componentes básicos de los gráficos en ggplot2"
        ],
        "Creación de gráficos en ggplot2": [
          "Histograma Parte 1",
          "Histograma Parte 2",
          "Gráficos de dispersión Parte 1",
          "Gráficos de dispersión Parte 2",
          "Gráficos de barra y columna Parte 1",
          "Gráficos de barra y columna Parte 2",
          "Boxplot Parte 1",
          "Boxplot Parte 2",
          "Gráficos de línea Parte 1",
          "Gráficos de línea Parte 2"
        ],
        "Exportar los gráficos": [
          "Exportar los gráficos"
        ],
        "Ejercicios de practica": [
          "Ejercicios de practica"
        ]
      },
      "requirements": [
        "Se recomienda conocimiento básico de R."
      ],
      "description": "En este curso en español, que tomas a tu propio ritmo, te enseñaremos a crear gráficos en R utilizando el paquete ggplot2 junto a la interfaz de RStudio. Ggplot2 es uno de los paquetes más poderosos y populares en R. El enfoque de este curso es que aprendas a utilizar ggplot2 para hacer una variedad de visualizaciones que te ayuden a comprender y explicar mejor tus datos a tus compañeros de trabajo o a tu audiencia. Vas a aprender a crear los principales tipos de gráficos para el análisis exploratorio de los datos, entre los que se encuentras los histogramas, gráficos de dispersión (scatterplots), gráficos de barra y columna, boxplots y gráficos de línea. También te mostraremos las opciones más comunes para personalizar los gráficos. Esto incluye modificar los colores, la forma y tamaño de los elementos del gráfico, así como hacer cambios a las etiquetas y los ejes. Finalmente te explicaremos como exportar los gráficos en diferentes formatos, ya sea utilizando programación o la interfaz de RStudio. Los gráficos generados en ggplot2 pueden ser integrados en documentos, presentaciones y otros productos.\nEl curso incluye los conjuntos de datos, el código utilizado, ejercicios de practica y las contestaciones a los ejercicios de practica.",
      "target_audience": [
        "Principiantes que quieran aprender a crear gráficos en R para entender mejor sus datos y comunicar resultados.",
        "Personas curiosas sobre como la visualización de datos en programados como R."
      ]
    },
    {
      "title": "【AI 자막】 파이썬 부트캠프 와 함께 하는 랭체인 클래스! (LangChain)",
      "url": "https://www.udemy.com/course/langchain-with-python-bootcamp-korean/",
      "bio": "대규모 언어 모델 (LLM) 과 LangChain으로 실제 애플리케이션을 구축하세요!",
      "objectives": [
        "모델 입력 및 출력에 LangChain을 사용해 LLM을 쉽게 전환하는 방법을 알아보세요.",
        "ChromaDB와 같은 벡터 데이터베이스와 LLM 및 LangChain으로 데이터 연결을 수행하는 방법을 알아보세요.",
        "LangChain 메모리를 활용하여 사용자와 AI의 대화를 추적하는 방법을 알아보세요.",
        "LangChain을 사용해 사용자 정의 에이전트를 구축하여 LLM으로 작업을 수행하는 방법을 알아보세요."
      ],
      "course_content": {
        "강의 소개": [
          "강의 소개 및 강의노트 다운로드",
          "강의 개요"
        ],
        "모델 - 입력 및 출력": [
          "모델 소개 - 입력 및 출력",
          "선택 사항 - 오픈AI 계정 설정",
          "LangChain으로 LLM 사용하기",
          "LangChain을 사용한 채팅 모델",
          "프롬프트 템플릿",
          "프롬프트 및 모델 - 연습",
          "프롬프트 및 모델 - 연습 솔루션",
          "샷 프롬프트 템플릿",
          "출력 구문 분석 - 1부",
          "출력 구문 분석 - 2부",
          "출력 구문 분석 - 3부",
          "직렬화 (Serialization) - 프롬프트 저장하고 불러오기",
          "모델 - 입력 및 출력 - 프로젝트 실습",
          "모델 - 입력 및 출력 - 프로젝트 실습 솔루션"
        ],
        "데이터 연결": [
          "데이터 연결 소개",
          "문서 로더 - 1부",
          "문서 로더 - 통합",
          "문서 로더 - 연습",
          "문서 로더 - 연습 솔루션",
          "문서 트랜스포머",
          "텍스트 임베딩",
          "벡터 스토어",
          "벡터 저장소 - 검색기 (Retrievers)",
          "다중 쿼리 검색 (MultiQuery Retrieval)",
          "컨텍스트 압축",
          "데이터 연결 - 연습",
          "데이터 연결 - 연습 솔루션"
        ],
        "체인 (Chains)": [
          "LangChain 체인 소개",
          "LLMChain 객체",
          "SimpleSequentialChain",
          "SequentialChain",
          "LLMRouterChain",
          "TransformChain",
          "LangChain으로 OpenAI 함수 호출",
          "MathChain",
          "추가적인 체인 - QA 문서",
          "체인 - 연습",
          "체인 - 연습 솔루션"
        ],
        "메모리": [
          "메모리 소개",
          "ChatMessageHistory 객체",
          "ConversationBufferMemory 소개",
          "ConversationBufferWindowMemory 소개",
          "ConversationSummaryMemory 소개"
        ],
        "에이전트": [
          "에이전트 소개",
          "에이전트 기본사항",
          "에이전트 툴",
          "커스텀 툴",
          "대화 에이전트"
        ]
      },
      "requirements": [
        "Python 프로그래밍 경험 필수",
        "OpenAI에 대한 어느 정도의 익숙함이 권장됩니다."
      ],
      "description": "[꼭 읽어주세요] 한글 AI 자막 강의란?\n유데미의 한국어 [자동] AI 자막 서비스로 제공되는 강의입니다.\n강의에 대한 질문사항은 Jose 강사님이 확인하실 수 있도록 Q&A 게시판에 영어로 남겨주시기 바랍니다.\n\n\n저의 랭체인 유데미 강의에 오신 것을 환영합니다. 【AI 자막】 파이썬 부트캠프 와 함께 하는 랭체인 클래스! (LangChain)\n파이썬으로 언어 모델의 강력한 기능을 활용하세요!\n언어 모델로 구동되는 최첨단 애플리케이션을 개발할 준비가 되셨나요? LangChain은 여러분에게 필요한 프레임워크입니다. 언어 모델을 다른 데이터 소스와 연결하고 환경과의 상호 작용을 가능하게 하는 데이터를 인식하는 에이전트형 애플리케이션을 LangChain으로 만들어 보세요.\n\n\n왜 LangChain을 선택해야 할까요?\nLangChain은 언어 모델 개발에 필요한 다양한 이점을 제공합니다:\n구성 요소: LangChain은 다양한 구현과 함께 언어 모델 작업을 위한 모듈식 사용자 친화적인 추상화를 제공합니다.\n사전 구축된 체인: 특정 작업을 위해 설계된 사전 구축된 체인으로 애플리케이션을 빠르게 구축하세요. 더 복잡하거나 맞춤화된 사용을 위해 기존 체인을 수정하거나 새로운 체인을 생성하세요.\n\n\nLangChain 코스 모듈:\nLangChain은 다양한 모듈을 위한 표준 인터페이스와 외부 통합을 제공합니다:\n모델 I/O: 언어 모델과 쉽게 인터페이스할 수 있습니다.\n데이터 연결: 애플리케이션별 데이터 소스와 연결하세요.\n체인: 특정 작업을 수행하기 위한 호출 시퀀스를 구성합니다.\n에이전트: 체인이 상위 수준 지시문 (high-level directives) 을 기반으로 도구를 선택할 수 있도록 합니다.\n메모리: 체인 실행 사이에 애플리케이션 상태를 유지합니다.\nLangChain을 사용하면 OpenAI의 GPT-4 API와 같은 대규모 언어 모델과 직접 동기화되는 실제 애플리케이션을 빠르게 구축할 수 있습니다!\n언어 모델의 강력한 힘을 활용하여 여러분의 애플리케이션을 혁신하세요. 지금 이 LangChain Udemy 강의에 등록하고 무한한 가능성을 열어보세요!",
      "target_audience": [
        "LangChain을 사용하여 LLM 애플리케이션을 개발하는 데 관심이 있는 Python 개발자분들"
      ]
    },
    {
      "title": "人工智能技术之旅",
      "url": "https://www.udemy.com/course/wixoxggr/",
      "bio": "带你进入人工智能的世界",
      "objectives": [
        "了解机器学习的基础概念和流程",
        "了解常见的机器学习算法，如线性回归、逻辑回归、支持向量机、卷积神经网络、递归神经网络和增强学习等",
        "理解机器学习算法的原理和实现方法",
        "掌握数据预处理和特征工程的基本技巧",
        "能够运用机器学习算法来解决实际问题"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "课程绪论",
          "拟合与优化",
          "Logistic与SVM",
          "神经网络",
          "正则化方法",
          "卷积神经网络",
          "递归神经网络",
          "增强学习"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "有一定的机器学习基础"
      ],
      "description": "这门课程主要讲解了机器学习中的基础知识和常用算法，包括拟合与优化、Logistic与SVM、神经网络、正则化方法、卷积神经网络、递归神经网络和增强学习等内容。\n通过这门课程的学习，可以了解到机器学习的基本概念、常用算法和应用场景，掌握各种算法的原理和实现方法，并能够运用机器学习算法来解决实际问题。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "适合对机器学习感兴趣的学生、工程师和研究人员",
        "对于刚刚入门的学生，这门课程可以帮助他们了解机器学习的基础知识和常用算法",
        "对于已经有一定机器学习基础的人员，可以帮助他们深入了解各种算法的原理和实现方法，提高他们机器学习技能"
      ]
    },
    {
      "title": "【デジタル社会の「読み・書き・そろばん」】AI・データサイエンストレンド2022",
      "url": "https://www.udemy.com/course/ai2022-trend/",
      "bio": "2020年から2022年における、AI・データサイエンスをキーワードとした社会の話題について理解を深めよう",
      "objectives": [
        "実社会における「AI・データ活用事例」を学び、AI・データを活用できる実践的なリテラシーを身につけることができます。",
        "2020年～2022年1月にかけての、AI・データサイエンスをキーワードとした、社会のトピックスについて理解を深めることができます。",
        "社会の課題に対して、AI・データサイエンスがどのように関わっているかを最新の事例から理解できます。",
        "2021年制作講座「【デジタル社会の「読み・書き・そろばん」】AI・データサイエンス基礎講座～リテラシーレベル～」と併せて受講することで双方の講義内容をより深く理解することができます。"
      ],
      "course_content": {
        "AI・データサイエンストレンド2022": [
          "(1) 新型コロナ感染予測の公開",
          "(2) AI創薬による新型コロナ治療薬候補の特定",
          "(3) 「デジタル庁」の発足",
          "(4) コロナ禍における情報セキュリティに関する脅威",
          "(5) B to C - EC市場の変容",
          "(6) 東京オリンピック・パラリンピックにおける自動走行車の運行",
          "(7) AI研究のためのデータセットの公開",
          "(8) EUのデジタルプラットフォーム規制",
          "(9) EUにおける初のAI規則案の公表",
          "(10) 改正個人情報保護法の施行"
        ]
      },
      "requirements": [
        "特にありません。"
      ],
      "description": "この講座は、2021年に公開した「【デジタル社会の「読み・書き・そろばん」】AI・データサイエンス基礎講座～リテラシーレベル～」の番外編です。\n2020年から2022年1月までの間に、AI・データサイエンスをキーワードとした社会の話題について、10のトピックスを取り上げて講師が解説します。\n\n\n本講座では、既出の「【デジタル社会の「読み・書き・そろばん」】AI・データサイエンス基礎講座～リテラシーレベル～」の講義内容とも関連するトピックスを取り上げていますので、併せて受講いただくことで、より理解を深めていただくことができます。\n\n\n【デジタル社会の「読み・書き・そろばん」】AI・データサイエンス基礎講座～リテラシーレベル～は、\n①導入編（社会におけるデータ・AI利活用）\n②基礎編（データリテラシー）\n③心得編（データ・AI利活用における留意事項）\nの3シリーズで構成されています。\n\n\n①導入編では、社会や日常生活におけるAI・データの活用事例や、AIやデータの活用によって、新しいビジネス／サービスが創出されていることを学びます。\n②基礎編では、データを取り扱ううえでの正しい読み取り方や、適切な可視化の手法を学びます。また、Excelを使った総合演習も行います。\n③心得編では、データ・AIを利活用する際に求められるモラルや倫理について学びます。個人情報保護法やEU一般データ保護規則(GDPR)など、データを取り巻く国際的な動きも学びます。",
      "target_audience": [
        "AI・データサイエンスについてこれから学びたい方"
      ]
    },
    {
      "title": "ECBA 商业/业务分析师 (初级)认证培训课程：单元4发掘与协作、需求分析与设计定义、需求生命周期管理",
      "url": "https://www.udemy.com/course/ecba-4-l/",
      "bio": "ECBA认证精进：解锁发掘协作艺术，驾驭需求分析与设计，贯通需求生命周期管理之道",
      "objectives": [
        "让你全面了解商业分析职业，开始您的 BA 职业所需的基础知识和核心技能",
        "能够使用行业标准的BA方法，提供更安全、更高质量的输出，同时也提高了效率和一致性",
        "能够协助团队通过数据分析增加市场潜力，企业/组织可以根据BA专业团队的建议使其业务多样化，进入有利可图的细分市场",
        "考取ECBA证书，获得行业认可的专业资格，提升职业竞争力"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "第一章 单元4发掘与协作": [
          "第1节 发掘与协作（A）",
          "第2节 发掘与协作（B）",
          "第3节 发掘与协作（C）",
          "第4节 发掘与协作（D1）",
          "第5节 发掘与协作（D2）"
        ],
        "第二章 需求分析与设计定义": [
          "第1节 需求分析与设计定义（A1）",
          "第2节 需求分析与设计定义（A2）",
          "第3节 需求分析与设计定义（B）",
          "第4节 需求分析与设计定义（C1）",
          "第5节 需求分析与设计定义（C2）",
          "第6节 需求分析与设计定义（D1）",
          "第7节 需求分析与设计定义（D2）",
          "第8节 需求分析与设计定义（E）",
          "第9节 需求分析与设计定义（F1）",
          "第10节 需求分析与设计定义（F2）"
        ],
        "第三章 需求生命周期管理": [
          "第1节 需求生命周期管理（A1）",
          "第2节 需求生命周期管理（A2）",
          "第3节 需求生命周期管理（B1）",
          "第4节 需求生命周期管理（B2）",
          "第5节 需求生命周期管理（C）"
        ],
        "第四章 基础能力": [
          "第一节 基础能力"
        ],
        "回顾总结": [
          "课后寄语"
        ]
      },
      "requirements": [
        "虽然ECBA认证考试无门槛，但学员最好对商业分析有一定的了解或兴趣，以便更好地吸收课程内容。 学员应具备基本的分析能力和逻辑思维，以便更好地理解和应用商业分析的方法和工具。"
      ],
      "description": "在快速变化的商业环境中，精准把握业务需求并有效转化为可执行方案，是企业成功的关键。为此，《ECBA商业/业务分析师（初级）认证培训课程》旨在培养学员在业务分析领域的核心技能，助力其成为企业不可或缺的价值创造者。\n完成本单元的学习后，学员将能够：\n熟练运用多种方法与技术进行业务需求发掘与协作；\n系统地进行需求分析与设计定义，确保解决方案的可行性与有效性；\n掌握需求生命周期管理的最佳实践，提高项目管理的效率与质量；\n为进一步参加ECBA（Entry Certificate in Business Analysis）认证考试做好充分准备。\n无论您是刚刚踏入商业分析领域的新手，还是希望提升现有技能的从业者，《ECBA商业/业务分析师（初级）认证培训课程：单元4——发掘与协作、需求分析与设计定义、需求生命周期管理》都将是您不可多得的学习资源。加入我们，开启您的商业分析之旅，共创辉煌职业未来！",
      "target_audience": [
        "ECBA非常适合刚进入职场的大学生、职场新人、或者希望转岗/过渡到 BA职业的专业人士",
        "在我国,目前绝大多数的项目经理/产品经理/管理层，也都在扮演BA的角色，也同样适合学",
        "ECBA认证考试无门槛,所有人都可以学,都可以考，ECBA已有中文版考试。ECBA的进阶考试是CCBA(中级)以及CBAP(专家级)"
      ]
    },
    {
      "title": "Python数据分析系列课程：学习Pandas",
      "url": "https://www.udemy.com/course/pythonpandas-q/",
      "bio": "从实际案例数据的可视化需求出发，在实战中学习pandas的使用方法",
      "objectives": [
        "可以在实战中学习Pandas包的使用",
        "学员将学习独立使用Pandas包完成数据读入、数据清理、数据准备、图表呈现等工作",
        "为继续学习数据建模和数据挖掘打下坚实基础",
        "学习使用统计图表工具进行数据信息呈现"
      ],
      "course_content": {},
      "requirements": [
        "掌握python的基础使用"
      ],
      "description": "Pandas包是基于Python平台的数据管理利器，已经成为了Python进行数据分析和挖掘时的数据基础平台和事实上的工业标准，学习其使用方法，是使用Python进行数据分析和数据挖掘的必备条件。\n\n本课程将从中国高校综合排名和北京PM2.5实测数据两个实际案例出发，在实战中学习Pandas包的使用方法。\n\n学习完本课程后，学员将能够独立使用Pandas包完成数据读入、数据清理、数据准备方面的工作，学习如何使用统计图表工具进行数据信息呈现，为后续进一步进行数据分析建模和数据挖掘打下坚实基础。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。\n未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "有一定编程基础的同学",
        "对数据分析及可视化感兴趣的同学",
        "希望成为Python工程师和数据分析师的跨界人才"
      ]
    },
    {
      "title": "使用ChatGPT学习数据静态可视化操作",
      "url": "https://www.udemy.com/course/chatgpt-uf/",
      "bio": "数据可视化实操指南：借助ChatGPT掌握静态图表制作技巧",
      "objectives": [
        "学习如何利用ChatGPT辅助数据可视化学习，快速解决在数据可视化过程中遇到的技术难题",
        "使用Python中的matplotlib、pandas、创建各种静态数据可视化图表seaborn和plotnine库来",
        "掌握绘制线图、散点图、箱线图、热力分布图等可视化图表",
        "将理论知识应用于实际工作中，解决数据可视化的具体问题"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "1 使用ChatGPT学习python常用数据可视化工具": [
          "1 使用ChatGPT学习python常用数据可视化工具"
        ],
        "2 使用ChatGPT学习Matplotlib可视化": [
          "2.1 介绍Matplotlib工具",
          "2.2 学习颜色设置及案例讲解",
          "2.3 学习图形线类型的形状和大小",
          "2.4 学习图形点形状",
          "2.5 学习Matplotlib默认设置的修改",
          "2.6 学习绘制子图",
          "2.7.1 学习常用绘图函数",
          "2.7.2 学习绘制线图",
          "2.7.3 学习绘制散点图",
          "2.7.4 学习绘制单个条形图及在条形图上添加数值",
          "2.7.5 学习绘制分组条形图",
          "2.7.6 学习绘制箱线图",
          "2.7.7 学习绘制饼图"
        ],
        "3 使用ChatGPT学习Pandas可视化": [
          "3.1 学习Pandas数据可视化的绘图方法",
          "3.2 学习绘制线图",
          "3.3 学习绘制散点图",
          "3.4 学习绘制分组柱状图",
          "3.5 学习绘制箱线图"
        ],
        "4 使用ChatGPT学习seaborn可视化": [
          "4.1 学习Seaborn数据可视化的绘图方法",
          "4.2 学习绘制线图、散点图、分组柱状图、箱线图",
          "4.3 学习绘制小提琴图",
          "4.4 学习绘制线性相关图",
          "4.5 学习绘制散点图矩阵",
          "4.6 学习绘制热力图"
        ],
        "5 使用ChatGPT学习Plotnine绘制方法": [
          "5.1使用ChatGPT学习Plotnine绘制方法"
        ]
      },
      "requirements": [
        "无需经验"
      ],
      "description": "在数据驱动的商业环境中，数据可视化已成为传达复杂数据信息的关键工具。无论是在市场分析、产品开发还是决策支持中，能够清晰、有效地展示数据的能力至关重要。\n《使用ChatGPT学习数据静态可视化操作》课程正是为了满足这一需求而设计。本课程由资深数据分析师谢佳标老师主讲，旨在教授学员如何高效地利用ChatGPT这一强大的人工智能工具，学习matplotlib、pandas、seaborn和plotnine等Python库，来创建直观、专业的数据可视化图表。\n学员将掌握如何制作专业、吸引人的数据可视化报告，提高工作效率，同时通过实践操作，解决实际工作中的数据可视化问题。无论是数据分析师、商业分析师，还是学生与研究人员，都能够通过本课程提升自己的数据可视化能力。",
      "target_audience": [
        "数据分析师: 对于需要将数据分析结果以图形化方式呈现的专业人士",
        "商业分析师: 商业决策过程中需要数据支持的分析人员，以更直观的方式展示数据洞察",
        "学生与研究人员: 正在学习数据科学或进行学术研究，需要数据可视化技能来增强研究表现的群体"
      ]
    },
    {
      "title": "Python ile Veri Analisti Olun: Temelden İleri Seviyeye",
      "url": "https://www.udemy.com/course/python-ile-veri-analisti-olun-temelden-ileri-seviyeye/",
      "bio": "Python ile Veri Analizi: Temelden İleri Seviyeye - Pratik Becerilerle Uygulamalı Kurs",
      "objectives": [
        "Veri analitiği konseptlerini anlayıp uygulayacaksınız.",
        "Gerçek dünya projeleri üzerinde deneyim kazanacaksınız.",
        "Pandas, NumPy gibi kütüphaneleri etkili bir şekilde kullanmayı öğreneceksiniz.",
        "Veri görselleştirmesi yaparak analizlerinizi güçlendireceksiniz.",
        "Makine öğrenimi ve veri madenciliği temellerini öğrenip uygulayacaksınız.",
        "İleri düzey konularla kendi projelerinizi geliştireceksiniz."
      ],
      "course_content": {},
      "requirements": [
        "Temel Python Bilgisi",
        "Temel Matematik",
        "Temel İstatistik",
        "Orta Seviye Bilgisayar Becerisi"
      ],
      "description": "Bu detaylı ve kapsamlı kurs, Python programlama dilini kullanarak veri analizi konusunda geniş bir anlayış ve beceri kazanmak isteyen öğrencilere hitap ediyor. Kurs, katılımcılarına Python dilindeki temel yapı taşlarından başlayarak ileri düzey veri analizi konularına kadar olan bir yelpazede bilgi sunmaktadır.\nKursun başlangıç aşamasında, Python dilinin temel öğeleri ayrıntılı bir şekilde ele alınarak katılımcılara dilin temel syntax'ı, veri tipleri, döngüler ve koşullu ifadeler konusunda sağlam bir temel oluşturulmaktadır. Ardından, veri analizi için güçlü kütüphaneler olan Pandas ve NumPy'nin kullanımı incelenerek, katılımcılar bu kütüphaneleri etkili bir şekilde kullanma becerisi kazanmaktadır.\nKursun en dikkat çekici özelliklerinden biri, teorik bilgilerin hemen pratiğe dökülebileceği gerçek dünya projeleri üzerinde uygulama fırsatı sunmasıdır. Bu sayede öğrenciler, edindikleri bilgileri doğrudan işlevsel becerilere dönüştürme şansına sahip olacaklardır.\nPratik beceriler kazanma odaklı bir yapıya sahip olan kurs, veri görselleştirmesi yapma yeteneklerini geliştirirken aynı zamanda makine öğrenimi ve veri madenciliği konularında da uzmanlaşma imkanı tanımaktadır. Bu, öğrencilere sadece veri analizi yapma değil, aynı zamanda bu analizleri anlama ve kullanma yeteneği kazandıracak bir eğitim sunmaktadır.\nPython ile Veri Analizi: Temelden İleri Seviyeye - Pratik Becerilerle Uygulamalı Kurs, katılımcılarına veri analitiği alanında güçlü bir temel oluşturmanın yanı sıra, Python dilindeki pratik kullanımıyla da öne çıkan kapsamlı bir eğitim sunmaktadır. Bu kurs, veri analitiği dünyasına adım atmak veya mevcut bilgilerinizi güçlendirmek isteyen her seviyeden öğrenci için ideal bir öğrenme deneyimi sunmaktadır. Kısacası veri bilimi için aradığınız her konu burada mevcut. Hadi sende gel ve öğrenmeye başla",
      "target_audience": [
        "Hem yeni başlayanlar hem de deneyimli programcılar için, temel konulardan başlayarak ileri düzey veri analitiği konularına kadar geniş bir kapsam sunar.",
        "Gerçek dünya projeleri üzerinde çalışarak, teorik bilgileri pratiğe dökmek isteyenler için uygundur.",
        "Veri analitiği alanında uzmanlaşarak kariyerlerine yeni bir yön vermek isteyen profesyoneller için ideal bir seçenektir.",
        "Veri analitiği konusunda temel bilgiler edinmek veya mevcut bilgilerini geliştirmek isteyenler için tasarlanmıştır.",
        "Temel Python bilgisi olanlar ve programlamaya ilgi duyan herkes için uygundur."
      ]
    },
    {
      "title": "Data Science Mudah Menggunakan Phyton",
      "url": "https://www.udemy.com/course/data-science-mudah-menggunakan-phyton/",
      "bio": "Mulai karirmu menjadi Data Science, Karir yang paling banyak dibutuhkan saat ini!",
      "objectives": [
        "Memahami konsep dasar Data Sains dan bagaimana bidang ini diterapkan di berbagai industri.",
        "Mengetahui tahapan dalam proyek Data Sains, mulai dari pengumpulan hingga penyajian data.",
        "Menguasai sintaks dasar Python, seperti variabel, tipe data, operasi matematika, dan struktur kontrol.",
        "Menulis fungsi sederhana dan memahami konsep pemrograman berbasis objek (OOP).",
        "Memahami berbagai format data (CSV, JSON, Excel, SQL) dan cara membacanya menggunakan Python.",
        "Menganalisis data menggunakan teknik statistik dasar seperti mean, median, modus, distribusi, dan korelasi."
      ],
      "course_content": {
        "Introduction": [
          "Introduction to Data Science",
          "Getting Started with Google Colab"
        ],
        "Learning": [
          "Variables and Data Types in Python",
          "Operators in Python",
          "Control Structures in Python",
          "Functions in Python",
          "Arrays and Array Operation in Numpy",
          "Pandas",
          "Data Visualization",
          "Introduction Machine Learning",
          "Linear Regression Part 1",
          "Linear Regression Part 2",
          "Logistic Regression",
          "Decision Tree",
          "Random Forest",
          "Support Vector Machines Part 1",
          "Support Vector Machines Part 2",
          "K Nearest Neighbors",
          "Clustering",
          "Introduction to Deep Learning",
          "Keras Part 1",
          "Keras Part 2",
          "Data Science Project",
          "Wrap Up and Conclusion"
        ],
        "Extra": [
          "Kelas Data Science dengan Python → Numpy Basics"
        ]
      },
      "requirements": [
        "Bisa dipelajari tanpa pengalaman",
        "Gunakan fasilitas belajar seperti laptop dan internet"
      ],
      "description": "Tujuan dan Hasil Pembelajaran Data Sains untuk Pemula dengan Python\nKursus ini bertujuan untuk membekali peserta dengan dasar-dasar Data Sains menggunakan Python, mulai dari pemrograman dasar, manipulasi data, hingga analisis dan visualisasi data.\nTujuan Pembelajaran\n1. Pengenalan Data Sains\nMemahami konsep dasar Data Sains dan bagaimana bidang ini diterapkan di berbagai industri.\nMengetahui tahapan dalam proyek Data Sains, mulai dari pengumpulan hingga penyajian data.\nMengenali berbagai peran dalam Data Sains, seperti Data Analyst, Data Engineer, dan Data Scientist.\n2. Dasar-Dasar Pemrograman Python\nMenguasai sintaks dasar Python, seperti variabel, tipe data, operasi matematika, dan struktur kontrol.\nMenulis fungsi sederhana dan memahami konsep pemrograman berbasis objek (OOP).\nMenggunakan modul dan pustaka penting dalam Python untuk Data Sains.\n3. Pengolahan dan Manipulasi Data\nMemahami berbagai format data (CSV, JSON, Excel, SQL) dan cara membacanya menggunakan Python.\nMenggunakan pustaka Pandas dan NumPy untuk membersihkan, mengolah, dan menganalisis data.\nMelakukan operasi dasar seperti filtering, grouping, merging, dan reshaping data.\n4. Eksplorasi dan Analisis Data\nMenganalisis data menggunakan teknik statistik dasar seperti mean, median, modus, distribusi, dan korelasi.\nMengidentifikasi pola dalam data dan membuat hipotesis berdasarkan analisis eksploratif.\nMenggunakan Python untuk menghitung dan menyajikan berbagai metrik analisis.\n5. Visualisasi Data\nMemahami pentingnya visualisasi dalam komunikasi data.\nMenggunakan Matplotlib dan Seaborn untuk membuat grafik, diagram batang, scatter plot, histogram, dan heatmap.\nMenginterpretasikan hasil visualisasi untuk mendukung pengambilan keputusan.\n6. Pengenalan Machine Learning (Pembelajaran Mesin)\nMemahami konsep dasar machine learning dan perbedaannya dengan pemrograman tradisional.\nMengenal berbagai jenis algoritma machine learning, seperti supervised dan unsupervised learning.\nMenerapkan model machine learning sederhana dengan Scikit-learn untuk klasifikasi dan regresi.\n7. Studi Kasus dan Proyek Praktik\nMengerjakan studi kasus dengan dataset nyata untuk mengasah keterampilan analisis data.\nMengembangkan proyek akhir berupa eksplorasi data dan insight yang dapat disajikan dalam laporan atau dashboard.\nMempersiapkan peserta untuk mengaplikasikan ilmu yang diperoleh dalam dunia kerja atau proyek pribadi.\nHasil Pembelajaran yang Diharapkan\nMemahami konsep dasar Data Sains dan tahapan dalam proses analisis data.\nMenguasai dasar-dasar pemrograman Python dan penerapannya dalam Data Sains.\nMampu membersihkan dan mengolah data dengan Pandas dan NumPy.\nDapat melakukan analisis statistik dasar untuk memahami pola dalam data.\nMampu membuat visualisasi data yang informatif dan menarik menggunakan Matplotlib dan Seaborn.\nMemahami dasar-dasar machine learning dan mencoba model sederhana.\nMengembangkan proyek analisis data dari dataset nyata dan mempresentasikan hasilnya.\nMempunyai dasar yang kuat untuk melanjutkan ke tingkat Data Sains yang lebih lanjut atau menerapkannya dalam dunia kerja.",
      "target_audience": [
        "Data Sains menggunakan Phyton khusus pemula"
      ]
    },
    {
      "title": "Power BI-stwórz, opublikuj profesjonalny raport do portfolio",
      "url": "https://www.udemy.com/course/powerbi-stworz-i-opublikuj-profesjonalny-raport-do-portfolio/",
      "bio": "Profesjonalny interaktywny raport sprzedaży. Od planowania do storytellingu. Pokaż szefowi lub rekruterowi co potrafisz!",
      "objectives": [
        "Przygotujesz własne portfolio raportowe i opublikujesz je w sieci. Raport będzie gotowy do pokazania pracodawcy lub do umieszczenia w CV.",
        "Zrozumiesz cały proces tworzenia raportu w Power BI - od planowania raportu, planowania KPI do czytelnego, przyjaznego layoutu.",
        "Nauczysz się przekształcać dane w czytelne i użyteczne wizualizacje, które doprowadzą użytkownika do podejmowania właściwych decyzji.",
        "Zbudujesz profesjonalny raport sprzedażowy krok po kroku - w krótkim czasie nauczysz się wszystkiego co niezbędne do tworzenia profesjonalnego raportu.",
        "Opanujesz podstawy języka DAX, wykorzystasz ChatGPT do tworzenia miar.",
        "Zaczniesz myśleć jak analityk danych, zaczniesz zadawać właściwe pytania i kierować uwagą użytkownika do znalezienia właściwych odpowiedzi.",
        "Nauczysz się dodawać elementy storytellingu, żeby raport sam opowiadał o danych.",
        "Dostaniesz argumenty w postaci swoich umiejętności do awansu lub rozwoju swojej kariery analityka danych."
      ],
      "course_content": {
        "Wstęp": [
          "Wstęp",
          "Cele kursu"
        ],
        "Planowanie raportu i przygotowanie danych": [
          "Planowanie raportu",
          "Pobranie Power BI",
          "Pobranie i naprawa danych Power Query",
          "Model danych - fundament raportu",
          "Planowanie layoutu raportu"
        ],
        "Tworzenie profesjonalnego raportu - strona główna": [
          "KPI i karty wyników cz1.",
          "KPI i karty wyników cz2.",
          "Wykresy trendów sprzedaży i marży w czasie",
          "Wykresy słupkowe sprzedaży i marży wg danych kategorialnych"
        ],
        "Elementy interaktywne i storytelling - niech nasze dane przemówią!": [
          "Formatowanie warunkowe - siła kolorów w raporcie",
          "Tooltipy - dodatkowe dane bez zajmowania miejsca.",
          "Drąż wskroś - Drill Down - dowiedz się więcej szczegółów w interesujących danych",
          "Filtrowanie danych - patrz na to, co ważne",
          "Nawigacja - sprawnie poruszaj się między stronami raportu.",
          "Storytelling - opowiadaj historię i prowadź do podejmowania decyzji"
        ],
        "Kolejne strony raportu - patrz na dane z różnych perspektyw": [
          "Raport wg regionów - geografia ma znaczenie",
          "Raport wg produktów - czy nasze portfolio jest ok?",
          "Raport wg klientów",
          "Końcowe szlify"
        ],
        "Publikacja raportu -jak pokazać nasz raport światu bez płatnej licencji Power BI": [
          "Publikacja raportu"
        ],
        "DAX - podstawy i motywacja do dalszej nauki": [
          "DAX podstawy podstaw"
        ],
        "Zakończenie": [
          "Zakończenie"
        ]
      },
      "requirements": [
        "Wystarczy komputer i chęć do działania!"
      ],
      "description": "Dodatki do kursu:\n1. E-book - 10 najczęstszych błędów w danych\n2. E-book - Funkcje DAX do raportu sprzedaży\n3. Mapa raportu - narzędzie Excel do planowania raportu\n4. Planowanie layuotu raportu - narzędzie Excel do planowania layoutu\n5. E-book - Prompty DAX ChatGPT do kursu Power BI raport sprzedaży\n6. E-book - UI Design przydatne linki\n7. Przykładowy layout w *pptx i *svg\n8. E-book - RoadMap Analityka Danych\n\n\nDane są dziś jednym z najważniejszych zasobów w biznesie – pomagają podejmować trafne decyzje, optymalizować procesy i odkrywać nowe możliwości. Umiejętność ich analizy i prezentowania w formie przejrzystych raportów to kompetencja przyszłości. Ten kurs pokaże Ci, jak tworzyć profesjonalne raporty w Power BI – krok po kroku, od pobrania danych aż po finalną prezentację.\nW trakcie kursu zbudujesz kompletny raport sprzedażowy – od zera, aż do gotowego dashboardu. Przejdziesz przez wszystkie etapy pracy analityka danych: pobieranie i przekształcanie danych w Power Query, tworzenie modelu danych i relacji, obliczanie kluczowych wskaźników (KPI) w języku DAX, budowanie atrakcyjnych i interaktywnych wizualizacji oraz publikacja raportu w chmurze (Power BI Service).\nEfekt końcowy? Gotowy, interaktywny raport online, który otrzyma unikalny link – możesz dodać go do swojego CV, załączyć w portfolio lub przesłać przełożonemu jako dowód Twoich umiejętności. To nie tylko nauka narzędzia – to pierwszy krok do zmiany kariery i wejścia w świat analizy danych.\nPodczas kursu nauczysz się myśleć jak analityk: zadawać właściwe pytania, łączyć dane z kontekstem biznesowym i opowiadać historię na podstawie liczb. To kompetencja, która wyróżnia najlepszych specjalistów.\nKurs jest idealny dla osób, które chcą wejść do świata danych, przebranżowić się, awansować w obecnej pracy lub po prostu zdobyć umiejętność, która jest dziś jedną z najbardziej poszukiwanych na rynku.",
      "target_audience": [
        "Osoby, które chcą zwiększyć swoje zarobki przez awans lub znalezienie pracy jako analitycy danych",
        "Osoby, które chcą szybko nauczyć się, jak krok po kroku zbudować profesjonalny, interaktywny raport w Power BI",
        "Osoby, które potrzebują praktycznej wiedzy, jak przekształcać dane w czytelne i atrakcyjne raporty",
        "Osoby, które chcą poprawić umiejętności analizy i wizualizacji danych",
        "Osoby, które potrzebują wiedzy praktycznej bez zbędnej teorii",
        "Analitycy biznesowi, którzy chcą tworzyć raporty i dashboardy dostosowane do potrzeb biznesu",
        "Menedżerowie i właściciele firm, którzy potrzebują skutecznych narzędzi do monitorowania KPI",
        "Menedżerowie i właściciele firm, którzy chcą lepiej rozumieć dane i podejmować decyzje na ich podstawie",
        "Osoby pracujące w Excelu, które chcą przejść na Power BI"
      ]
    },
    {
      "title": "AIでコンテンツを量産して収益化を加速！初心者でもできるAI×オンラインビジネス活用法",
      "url": "https://www.udemy.com/course/ai-uzyek/",
      "bio": "ゼロから始めるAI活用法。コンテンツ制作の効率化と収益化を目指す",
      "objectives": [
        "Chat GPTとは何か、その機能や仕組みについての基本的な理解が深まります。",
        "AIを使いこなすための第一歩として、基礎知識を確実に習得できます。",
        "プロンプトの作成方法や、プロンプトを効果的に使うための戦略を学べます。",
        "日常業務やコンテンツ作成の現場で即座に活用できる知識とスキルを身につけられます。",
        "Chat GPTをどのようにコンテンツビジネスに応用できるか、具体的な事例やケーススタディを通じて理解できます。",
        "長期的な戦略を立てるための視野が広がります。"
      ],
      "course_content": {
        "Chat GPTのプロンプトについて": [
          "１−１：Chat GPTとは",
          "１−２：Chat GPTで何ができるか",
          "１−３：Chat GPTのプロンプトとは何か",
          "１−４：プロンプトを効果的に書くための戦略",
          "１−５：プロンプトの必殺技",
          "１−６：このセクションのまとめ"
        ],
        "プロンプトで使われる記号について": [
          "２−１：プロンプトで使われる記号について",
          "２−２：プロンプトエンジニアリングとは",
          "２−３：このセクションのまとめ"
        ],
        "より効果的なプロンプトを書く技術": [
          "３−１：より効果的なプロンプトを書くために",
          "３−２：七里式テンプレート",
          "３−３：前提条件を作るカスタムプロンプト",
          "３−４：このセクションのまとめ"
        ],
        "深津式テンプレート": [
          "４−１：深津式プロンプト・システムについて",
          "４−２：深津式プロンプト・システム１",
          "４−３：深津式プロンプト・システム２",
          "４−４：深津式汎用プロンプトとは",
          "４−５：深津式プロンプト例題",
          "４−６：深津式プロンプトの仕組み",
          "４−７：深津式プロンプトの留意点",
          "４−８：深津式プロンプトに関するQ&A",
          "４−９：このセクションのまとめ"
        ],
        "プロンプトの未来": [
          "５−１：AGIのコンセプト",
          "５−２：プロンプトの達人になる７つのポイント",
          "５−３：ブレインストーミングのプロンプト例",
          "５−４：プロンプトの未来"
        ],
        "AIを使った実演講座": [
          "Vrewで簡単にショート動画を作成する方法【実演デモ】",
          "Geminiで画像生成する方法【実演デモ】",
          "Google AI Stadioでカウンセリングを受ける方法【実演デモ】",
          "Perplexityで見込み客をリサーチする方法【実演デモ】",
          "NootbookLMで商品を作成する方法【実演デモ】",
          "Canva AIでAIプレゼンターを作る方法【実演デモ】",
          "AIでセールスやコンサル、コーチングなどのロールプレーニングをやる方法",
          "Chat GPTでYouTube動画のSEOに強いタイトルを作成する方法",
          "ChatGPT×Vrewで簡単！ブログ記事をショート動画にする方法【初心者向け】",
          "ChatGPTで簡単！SEOに強いタイトルを作る方法とコツ",
          "ChatGPTで目標設定と行動計画を効率化！具体的な活用方法を解説",
          "ChatGPTでマインドマップを簡単作成！効率的な使い方と具体例を解説",
          "AIで目標設定と行動計画を作る方法",
          "AIで売れる本のタイトル案を考えてもらう方法",
          "AIでキーワードリサーチをする方法",
          "AIでターゲットのキーワードリサーチをする方法",
          "GeminiでDeep Researchする方法",
          "GeminiのCanvas機能を使ってブログ記事を作成する方法",
          "Geminiでインフォグラフィックを作成する方法",
          "Geminiで役立つYouTube動画を探す方法",
          "NotebookLMで日本語のポッドキャストを出力する方法",
          "NotebookLMでブログやnoteの記事のSEO対策をする方法",
          "NotebookLMでキャプションとハッシュタグを生成する方法",
          "NotebookLMでYouTubeの日本語・英語字幕を作る方法",
          "AIでYouTubeのタイムスタンプを作る方法",
          "AIで心理テストを作る方法",
          "AIにいろんなキャラになってもらう方法",
          "GPTsを作る手順（自分の文体やテイストでメルマガの記事作成）",
          "CanvaAIで診断ツールを作る方法",
          "Napkin AIで文字から図を作成する方法",
          "GeminiのGemの使い方＆活用事例",
          "AIでブログ記事の添削とリライトをする方法",
          "Canva AIでオーディオを作る方法",
          "AIを使って教材を作る方法"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "ChatGPT"
      ],
      "description": "この度は本コースを手に取ってくださりありがとうございます。\n\n\n■このコースの概要説明\n生成AIを活用して、コンテンツ作成のスピードと質を向上させたいと思いませんか？\nこんな悩みを抱えている方におすすめです。\nChatGPTを使ってみたいが、プロンプトの書き方が分からない。\nAIを活用してコンテンツを作成したいが、どこから始めればいいか分からない。\n効果的なプロンプトを作成し、より良いアウトプットを得たい。\nChatGPT以外の生成AIも活用して、収益化につなげたい。\nブログやYouTube、SNSなどで効率的にコンテンツを量産したい。\nこれはそんなあなたのためのコースです。\nこのコースでは、ChatGPTを中心とした生成AIの活用方法を学び、コンテンツ制作の効率化と収益化を目指します。\nコース本編の内容は以下の通りです。\nChatGPTのプロンプトについて\nプロンプトで使われる記号について\nより効果的なプロンプトを書く技術\n深津式テンプレート\nプロンプトの未来\n実技講座（動画制作・画像生成・リサーチなど）\n■コースを受講するとできること\nこのコースを受講すると、以下のことができるようになります。\nChatGPTを活用したコンテンツ作成の基本を理解する。\n効果的なプロンプトを書く技術を習得し、より質の高いアウトプットを得る。\n深津式テンプレートを活用し、汎用性の高いプロンプトを作成できる。\n生成AIを使って、動画・画像・リサーチなどの実践的なスキルを身につける。\n生成AIを活用して、効率的にコンテンツを量産し、収益化につなげる。\n■こんな方が受講に向いています\nブログ、YouTube、ポッドキャストなど、さまざまなメディアでコンテンツを制作している方。\nAI技術を使って制作プロセスを効率化し、より質の高いコンテンツを生み出したいと考えている方。\n広告コピーやSNS投稿、メールマーケティングなど、日々の業務で大量のコンテンツを作成しているマーケッター。\nChatGPTを活用して、クリエイティブなアイデアを瞬時に得たいと考えている方。\nChatGPT以外の生成AIを活用し、コンテンツ制作の幅を広げたい方。\n■必要なツールや要件\nこのコースを受講するには、以下のツールや要件が必要です。\nChatGPTを利用するためのOpenAIアカウント。\nGemini、Google AI Studio、Perplexity、NootbookLMなどの生成AIツールのアカウント。\nインターネットに接続できるPCまたはタブレット。\n■締めくくりの挨拶\nこのコースでは、初心者の方でも簡単に実践できる生成AIの活用法を学べます。 AIを活用して、コンテンツ制作を効率化し、収益化を目指しましょう！\n皆さまのご参加を心よりお待ちしております！\n\n\n\n\nそれではセクション１からご受講ください。",
      "target_audience": [
        "ブログ、YouTube、ポッドキャストなど、さまざまなメディアでコンテンツを制作している方",
        "AI技術を使って制作プロセスを効率化し、より質の高いコンテンツを生み出したいと考えている人",
        "広告コピーやSNS投稿、メールマーケティングなど、日々の業務で大量のコンテンツを作成しているマーケッター",
        "Chat GPTを活用して、クリエイティブなアイデアを瞬時に得たいと考えている人",
        "Chat GPTを使って、執筆作業のスピードを上げたり、新しいスタイルやアプローチを模索したいと考えている人",
        "Chat GPT以外の生成AIを活用したいと考えている方"
      ]
    },
    {
      "title": "Data mining для начинающих",
      "url": "https://www.udemy.com/course/data-mining-for-beginners/",
      "bio": "Data Mining для начинающих: Алгоритмы и методы анализа данных для реальных задач",
      "objectives": [
        "Освоите основную терминологию в области Data Mining",
        "Разберетесь что такое ТОС и ОВ, сможете различать их между собой и даже сами составите свои первые ТОС и ОВ",
        "Разберетесь что такое кластеризация, зачем она нужна, для каких задач применяется и научитесь на практике проводить кластеризацию",
        "Разберетесь что же такое классификация, зачем она нужна, для каких задач применяется и научитесь на практике проводить классификацию",
        "Познакомитесь с новыми no-code приложениями для качественного проведения кластеризации и классификации, использование которых не потребует от вас знаний програм"
      ],
      "course_content": {
        "Data mining для начинающих": [
          "Введение",
          "Что такое Data Mining",
          "Что такое Data Mining",
          "Задание 1",
          "Основные формальные объекты исследования в DM: ТОС и ОВ, признак, объект, правил",
          "Задание 2",
          "Основные формальные объекты исследования в DM: ТОС и ОВ, признак, объект, правил",
          "Что такое кластеризация",
          "Задание 3",
          "Что такое кластеризация",
          "Что такое классификация",
          "Что такое классификация",
          "Задание 4"
        ]
      },
      "requirements": [
        "Навыки программирования не требуются, вы научитесь всему необходимому."
      ],
      "description": "Добро пожаловать на курс по Data Mining для начинающих! Если вы хотите научиться извлекать полезную информацию из данных и применять это знание на практике, этот курс — именно то, что вам нужно.\nВ процессе обучения вы освоите основные принципы и методы Data Mining, научитесь работать с реальными наборами данных и узнаете, как использовать популярные алгоритмы и инструменты для анализа данных. Мы разобьём курс на несколько ключевых блоков, охватывающих как теоретические основы, так и практические техники.\nЧто вы получите в этом курсе:\nПонимание того, что такое Data Mining и как этот процесс используется в различных областях: от бизнеса до медицины.\nЗнания о методах подготовки данных.\nУмение применять алгоритмы классификации, кластеризации для решения реальных задач.\nОсновы визуализации данных для лучшего представления результатов анализа.\nКурс идеально подойдёт для студентов, начинающих аналитиков данных, маркетологов и всех, кто хочет улучшить свои навыки в области Data Mining и научиться извлекать ценные инсайты из данных.\nПройдя этот курс, вы сможете:\nПрименять алгоритмы Data Mining для решения задач в своей профессиональной деятельности.\nРаботать с реальными данными и строить модели, которые помогают прогнозировать поведение пользователей или сегментировать аудиторию.\nПонимать, как и какие данные могут быть полезными для анализа в вашем бизнесе или проекте.\nЭтот курс — ваш первый шаг в мир Data Mining. Присоединяйтесь и начните извлекать знания из данных уже сегодня!",
      "target_audience": [
        "Студенты и выпускники ВУЗов (в области компьютерных наук, статистики, экономики, маркетинга и других смежных направлений)",
        "Начинающие специалисты в области аналитики данных и науки о данных (Data Science)",
        "Бизнес-аналитики, маркетологи, специалисты по продуктам",
        "Любители данных и начинающие Data Scientists, ищущие способы углубить свои знания"
      ]
    },
    {
      "title": "Projeto Real do Uber com Python: Análise e Ciência de Dados",
      "url": "https://www.udemy.com/course/projeto-real-do-uber-com-python-analise-e-ciencia-de-dados/",
      "bio": "Data Science, Real World Projects",
      "objectives": [
        "Importação de Dados no Python",
        "Limpeza e Transformação de Dados",
        "Visualização de Dados",
        "Interpretação de Gráficos e Redação de Relatórios"
      ],
      "course_content": {
        "Introdução": [
          "Introdução ao Curso",
          "Instalação do Ambiente de Trabalho"
        ],
        "Importação de Dados": [
          "Dados do Uber (Exploração Inicial)",
          "Importação de Dados usando Anaconda (Python)",
          "Repita todo esse processo"
        ],
        "Transformação e Limpeza de Dados": [
          "Transformação e Limpeza de Dados",
          "Códigos Usados na Transformação e Limpeza de Dados"
        ],
        "Visualizações dos Dados": [
          "Visualizações de Dados",
          "Códigos usados"
        ],
        "Criação de Relatórios": [
          "Criação de Relatórios, Conclusão do Curso",
          "Criar Relatório"
        ]
      },
      "requirements": [
        "O curso é projetado para transformar iniciantes em profissionais experientes, fornecendo uma formação abrangente sem limitações no aprendizado."
      ],
      "description": "O curso \"Análise de Dados com Python Usando um Projeto Real do Uber\" foi cuidadosamente desenvolvido para transformar iniciantes em profissionais altamente competentes no campo da ciência e análise de dados. Com uma abordagem prática e focada, o curso oferece uma formação abrangente e integrada, utilizando um projeto real baseado em dados do Uber.\nObjetivos do Curso:\nDesenvolvimento de Competências Técnicas: Capacitar os participantes com habilidades avançadas em análise de dados, desde a configuração inicial do ambiente de trabalho até a elaboração de relatórios detalhados e persuasivos.\nAplicação Prática: Utilizar dados reais do Uber para proporcionar uma experiência prática e contextualizada, permitindo aos participantes aplicar conceitos teóricos em situações do mundo real.\nFormação Completa: Guiar os alunos através de todo o processo analítico, incluindo a importação, limpeza, transformação e visualização de dados, culminando na interpretação dos resultados e na criação de relatórios profissionais.\nAo longo do curso, os participantes adquiriram conhecimento profundo e habilidades práticas essenciais para a análise de dados, com ênfase em ferramentas e técnicas avançadas. A estrutura do curso foi projetada para garantir que os alunos não apenas compreendam a teoria, mas também possam aplicá-la efetivamente em cenários práticos, preparando-os para enfrentar desafios reais na área de ciência de dados.",
      "target_audience": [
        "Este curso é voltado para iniciantes que desejam se tornar cientistas ou analistas de dados, utilizando um projeto real, com foco na análise de dados do Uber."
      ]
    },
    {
      "title": "Swin Transformer实战目标检测：训练自己的数据集",
      "url": "https://www.udemy.com/course/swint-objdetect/",
      "bio": "计算机视觉目标检测实战",
      "objectives": [
        "掌握Swin Transformer目标检测训练自己的数据集方法",
        "掌握labelImg图像标注方法",
        "掌握数据集自动划分和格式转换方法",
        "学习Swin Transformer原理"
      ],
      "course_content": {},
      "requirements": [
        "熟悉Python和PyTorch"
      ],
      "description": "Transformer发轫于NLP（自然语言处理），并跨界应用到CV（计算机视觉）领域。 Swin Transformer是基于Transformer的计算机视觉骨干网，在图像分类、目标检测、实例分割、语义分割等多项下游CV应用中取得了SOTA的性能。该项工作也获得了ICCV 2021顶会最佳论文奖。\n本课程将手把手地教大家使用labelImg标注和使用Swin Transformer训练自己的数据集。\n本课程将介绍Transformer及在CV领域的应用、Swin Transformer的原理。 课程以多目标检测（足球和梅西同时检测）为例进行Swin Transformer实战演示。\n课程在Windows和Ubuntu系统上分别做项目演示。包括：安装软件环境、安装Pytorch、安装Swin-Transformer-Object-Detection、标注自己的数据集、准备自己的数据集（自动划分训练集和验证集）、数据集格式转换（Python脚本完成）、修改配置文件、训练自己的数据集、测试训练出的网络模型、性能统计、日志分析。",
      "target_audience": [
        "希望学习Swin Transformer目标检测的学员"
      ]
    },
    {
      "title": "SQL结构化查询语言",
      "url": "https://www.udemy.com/course/collenzhao-sql/",
      "bio": "全面介绍SQL相关知识",
      "objectives": [
        "使用SELECT语句在表中检索行数据和列数据",
        "利用SQL函数生成和检索自定义的数据",
        "使用高级查询语言",
        "使用高级查询语言",
        "使用高级子查询搜索数据"
      ],
      "course_content": {
        "第1章-SQL课程概述": [
          "01-SQL课程概述",
          "02-导入虚拟机",
          "03-安装Oracle数据库",
          "04-验证Oracle数据库环境",
          "05-Oracle的基本概念和体系结构",
          "06-Oracle集群的概念"
        ],
        "第2章-基本的select语句": [
          "01-基本查询"
        ],
        "第3章-过滤与排序": [
          "01-过滤",
          "02-排序"
        ],
        "第4章-单行函数": [
          "01-单行函数概述",
          "02-字符函数",
          "03-数值函数",
          "04-日期函数",
          "05-转换函数",
          "06-通用函数",
          "07-条件表达式"
        ],
        "第5章-使用DML语句处理数据": [
          "01-处理数据概述",
          "02-insert语句和update语句",
          "03-delete语句",
          "04-Oracle事务简介"
        ],
        "第6章-创建和管理表": [
          "01-创建表",
          "02-修改表",
          "03-删除表和Oracle的回收站",
          "04-约束"
        ],
        "第7章-常用的数据库对象": [
          "01-视图",
          "02-序列",
          "03-索引",
          "04-同义词"
        ],
        "第8章-分组数据": [
          "01-分组查询概述",
          "02-分组函数的概念",
          "03-使用分组函数1",
          "04-使用分组函数2",
          "05-使用分组函数3",
          "06-Group by子句的使用",
          "07-having子句的使用以及和where的区别",
          "08-在分组查询中使用order by子句",
          "09-分组函数的嵌套",
          "10-Group by语句的增强",
          "11-SQLPLUS报表功能",
          "12-分组查询总结"
        ],
        "第9章-多表查询": [
          "01-多表查询课程概述",
          "02-什么是多表查询",
          "03-笛卡尔集",
          "04-等值连接",
          "05-不等值连接",
          "06-外连接",
          "07-自连接",
          "08-自连接存在的问题和解决办法",
          "09-多表查询总结"
        ],
        "第10章-子查询": [
          "01-子查询概述",
          "02-子查询需要注意的10个问题",
          "03-子查询问题1",
          "04-子查询问题2",
          "05-子查询问题3",
          "06-子查询问题4",
          "07-子查询问题5",
          "08-子查询问题6",
          "09-子查询问题7",
          "10-子查询问题8",
          "11-子查询问题9",
          "12-子查询的类型之单行子查询",
          "13-子查询的类型之多行子查询",
          "14-子查询问题10",
          "15-子查询总结"
        ]
      },
      "requirements": [
        "无需经验，有基本的计算机操作基础即可"
      ],
      "description": "随着信息技术的飞速发展，数据分析技术得到了广泛的发展。SQL目前在数据分析领域中使用的越来越多。因此掌握SQL技术已成了求职加薪必备技能。本套课程从SQL的技术背景介绍，再到SQL技术的基础入门再到高级应用实战，全方位的介绍了SQL。通过此次课程培训，可使学习者获得如下收益：\n学完本课程后，学员将具备以下能力：\n使用SELECT语句在表中检索行数据和列数据、利用SQL函数生成和检索自定义的数据、使用高级查询语言、运行数据操纵语言 (DML) 操纵数据、使用高级子查询搜索数据",
      "target_audience": [
        "对数据库技术和SQL分析感兴趣的学员"
      ]
    },
    {
      "title": "Databricks Delta Lake + APACHE HOP: Carga e Dados",
      "url": "https://www.udemy.com/course/databricks-delta-lake-apache-hop-carga-e-dados/",
      "bio": "Unindo as grandes ferramentas de ingestão de dados e operacionalização de dados no Databricks",
      "objectives": [
        "Entendendo a arquitetura chamada Lakehouse sobre o Data Lake no Databricks",
        "Construindo Delta Lake com processamento em batch, streaming em lote",
        "Controle de transações sobre os dados, como um banco de dados",
        "Trabalhando com características ACID (Atomicidade, Consistência, Isolamento, Durabilidade) ao Delta Lake",
        "Entendendo versionamento dos dados, permite que os dados sejam acessados e revertam para versões anteriores de dados, controle de históricos",
        "Uso das fases de ingestão, refinamento e enriquecimento dos dados",
        "Diferenças das arquiteturas Data Lake x Delta Lake",
        "Aprendendo como otimização dos processos de coleta e tratamento dos dados, reduzindo o tempo de processamento e descartando o que não for útil",
        "Trabalhando a criação de tabelas Delta e como gerar históricos de dados",
        "Trabalhando com cluster, DBFS, Notebook em R, Scala, Pyhton e SQL",
        "Delta Time Travel como retornar versões de dados e comandos de controle",
        "Controle de auditoria, agindo na conformidade de dados quanto de depuração simples para entender como os dados mudaram ao longo do tempo",
        "Executando reversões nos dados, evitando duplicação e realizando refinamento, ajustes, atualizações e exclusões dos dados",
        "Executando scripts batch e streaming",
        "Entendo o que significa checkpoint e controle de gravações dos dados",
        "Trabalhando com Schema Evolution na inclusão de atributos as tabelas delta",
        "O que é  Hop Orchestration Platform",
        "Entendendo sobre fluxos de trabalho e pipelines",
        "Entendendo sobre projetos e ambientes",
        "Instalação do APACHE HOP",
        "Criando pipelines com arquivos texto",
        "Realizando tratamento de dados para entendimento do processo de engenharia de dados",
        "O que são transformações, links e ações dentro de um pipeline",
        "Construindo um workflow, orquestrador da sequência das operações",
        "Entendendo o HOP GUI e seus componentes",
        "Entendendo menu barras, principal e perspectivas",
        "Criando sua área de projetos",
        "Componentes pipelines: Sort, Select value, CSV file input, Value mapper, Filter rows, Dummy, Unique rows, Merge Join, Text File Output",
        "Entendendo o que é : View output, Preview output , Debug output",
        "Componentes pipelines: Number Range, Concat Field, String Operations, Replace in String, IF Field Value is Null, Split Fields, CSV File Input, Mail, File Exis",
        "Leitura de dados em uma API: Rest Client, JSON Input, JSON Output",
        "Construindo Workflow com execução de pipelines",
        "Entendo o uso de variáveis globais no APACHE HOP",
        "Automatização de pipeline ou workflow pelo HOP-RUN",
        "Construindo pipelines em banco de dados Postgresql: Table Input, Table Output, Configurando conexão",
        "Instalação de banco de dados Postgresql, usando PGAdmin",
        "O que é Business Intelligence (BI)",
        "O que é Data Warehouse (DW)",
        "Como criar as tabelas staging, dimensão e fato",
        "Construção da carga dim_tempo",
        "Como o APACHE HOP pode se tornar um integrador de dados e construção de projetos de DW",
        "Entendendo o que é HOP projects",
        "Como funciona um pipeline e um workflow",
        "Interface de trabalho do APACHE HOP",
        "Instalação do APACHE HOP e do banco Postgres",
        "Entendendo sobre Modelagem Multidimensional",
        "Preparação de dados e construção de pipelines e workflow das cargas do DW",
        "O que são dimensões Slow Change Dimension 1 e 2",
        "Executando os pacotes via HOP RUN",
        "Construindo o tratamento de dados e ajustes em campos",
        "Identificando as informações inconsistentes e armazenando no DW para ajustes"
      ],
      "course_content": {
        "APACHE HOP - Integração e Ingestão de dados": [
          "Entendendo o funcionamento e componentes",
          "INFORMAÇÕES IMPORTANTES - Leia antes de começar o curso",
          "Instalação do JAVA",
          "Instalação do APACHE HOP",
          "Configuração extra e iniciando APACHE HOP",
          "Criando projeto e ambiente, primeiros passos",
          "Pipeline de Tratamento: arquivo vinhos",
          "Pipeline de tratamento: filtragem e seleção de atributos - arquivos vinho",
          "Pipeline de tratamento: sort e group by atributos - arquivos vinho",
          "Pipeline de tratamento: gerando arquivo de saída totalizador - arquivos vinho",
          "Pipeline Merge dos dados: Leitura arquivos de entrada",
          "Pipeline Merge dos dados: Sort arquivos de entrada",
          "Pipeline Merge dos dados: Merge arquivos venda e cliente",
          "Pipeline Merge dos dados: Merge arquivos venda com produto e marca",
          "Pipeline Merge dos dados: geração arquivo venda final tratado",
          "Pipeline Tratamento de dados: Arquivo cliente veículos e strings diversos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e ajustes campo hora",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e retirada valores nulos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e junção de atributos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e geração grupos de dados",
          "Pipeline Carga API: Leitura dados CEP e uso de REST GET",
          "Pipeline Carga API: Leitura e armazenamento arquivo JSON",
          "Pipeline Carga API: Tratamento dos dados escolha campos e gravação arquivo texto",
          "Workflow de execução: Parte01",
          "Workflow de execução: Parte02",
          "Banco de dados: Instalação do Postgresql",
          "Banco de dados: Pipeline de tratamento de dados no Postgresql",
          "HOP-RUN: Automatização de pipeline e workflow",
          "Aula Final - Entrega de atividades"
        ],
        "APACHE HOP - Construção de Projetos de Data Warehouse": [
          "Apresentação do curso e primeiros passos",
          "Instalação da JVM e execução do APACHE HOP",
          "Instalação do PostgreSql e do PGAdmin",
          "Conceitos sobre BI, Data Warehouse, Staging e Modelagem Multidimensional",
          "Explicando sobre os dados e construção das tabelas e cargas Staging",
          "Construindo a tabela e carga stg_departamento",
          "Construindo a tabela e carga stg_produto e stg_departamento",
          "Construindo a tabela e carga stg_venda (métricas e códigos)",
          "Criação das tabelas de dimensão e explicando sobre SCD1 e SCD2",
          "Construindo a carga dim_departamento e batimento dos dados",
          "Construindo a carga dim_vendedor e batimento dos dados",
          "Construindo a carga dim_produto e batimento dos dados",
          "Inserção dos dados sobre informações inexistentes no DW",
          "Criação da tabela tempo e da carga dim_tempo",
          "Criação da tabela e da carga Fato - parte01",
          "Criação da carga Fato - parte02",
          "Criação da carga Fato - parte03",
          "Tratando os dados nulos e realizando o batimento de dados",
          "Criação do Workflow de execução da cargas de dimensão e fato",
          "Execução do Workflow Carga Geral via HOP RUN",
          "Aula Extra - Dimensão Dtc_inicio=1900-01-01",
          "Aula Final - Entrega de atividade"
        ],
        "Databricks Delta Lake - Transações de dados e controle": [
          "Introdução a Databricks Delta Lake",
          "Diferenças sobre Data Lake x Delta Lake",
          "Start Databricks e como o ambiente funciona",
          "Passo a passo - Criando uma conta Databricks Community Edition - Free",
          "Carregamento dados compras e controle de dados",
          "Entendo o controle de transações - Delta_log",
          "Describe de versões Delta Lake e restore de versões",
          "Carga de dados Hotel e Otimizando as consultas no Delta Lake",
          "Executando o processo de Delta Time Travel",
          "Construção de tabelas Delta e verificando o controle de transações e constraints",
          "Executando Streaming script e armazenando os dados em uma tabela Delta",
          "Utilizando Schema Evolution em tabelas Delta",
          "Entrega de exercício - aula final",
          "Responda a nossa pergunta"
        ]
      },
      "requirements": [
        "É importante que você conheça um pouco de Python, R, Scala, SQL, não haverá treinamento destas linguagens neste curso",
        "Importante conhecer execução de scripts em Python, R, Scala, SQL",
        "Importante ter conhecimento sobre banco de dados, arquivos de dados",
        "Importante que você conheça lógica de programação",
        "Necessário conhecimento básico de modelagem de dados"
      ],
      "description": "Este é um daqueles cursos que o profissional busca conhecimento sobre como construir um pipeline eficiente e performático e que resolva os problemas da sua organização, mas a pergunta principal seria, como posso manusear estas ferramentas de uma forma orquestrada, organizada que permita a construção de forma rápida e intuitiva?\nPor isso, trazemos a junção do APACHE HOP e do Databricks Delta Lake, que fará com que você resolva seus problemas com dados. O que podemos garantir que aprenderá neste curso:\nNa primeira parte do curso do APACHE HOP que vem completo, com atividades para tratamento e ingestão de dados para que você projete e construa um Data Warehouse, utilizando componentes 100% gráficos e de fácil manuseio, você não precisará digitar nenhum código, o APACHE HOP é low code, será possível combinar, enriquecer, limpar e de muitas outras maneiras manipular dados. A ideia é que você faça a leitura de dados, realize os ajustes e tratamentos no conteúdo (limpeza de inconsistências, criação de campos, composição de campos, dentre outros).\nNa segunda parte com APACHE HOP vamos construir um Data Warehouse com uma explanação sobre o que é BI, DW, como funciona a staging área, o que são dimensões e fatos e tudo que você tem direito sobre este mundo de dados. Iremos construir um projeto do zero para informações sobre vendas, trabalhando com tabelas de departamento, produto e vendedor. Ao final iremos construir um workflow, que terá todos os pipelines de cargas juntos e como podemos executá-lo dentro da ferramenta APACHE HOP e fora dela.\nDepois fecharemos com o curso mais solicitado nas organizações Databricks Delta Lake, faremos uma grande explanação sobre Databricks e suas aplicações, falaremos do que é mais importante no Delta Lake o controle de transações dos dados, onde trabalharemos com arquivos parquet, mas sendo consumidos e trabalhados com operações conhecidas em banco de dados. Databricks Delta Lake é o que de mais moderno em plataforma para cloud que utilizam o SPARK como seu motor de processamento e que permitem controlar todas as transações sobre seus dados de forma nativa.\nEntão venha e comece hoje mesmo!",
      "target_audience": [
        "Estudantes e profissionais de computação, Informática, estatística, data science, analista de dados, engenheiro de dados",
        "Pessoas interessadas em aprender os conceitos sobre ferramentas de ingestão de dados, ou que gostariam adentrar na área de engenharia de dados",
        "Profissionais que, de alguma forma, utilizam dados no seu dia a dia"
      ]
    },
    {
      "title": "关键点检测实战",
      "url": "https://www.udemy.com/course/xssjdxva/",
      "bio": "零基础实战各方向的关键点检测",
      "objectives": [
        "掌握主流深度学习框架Pytorch及OpenCV、Numpy等第三方库的使用",
        "掌握关键点检测在主流分支上的方法及应用",
        "掌握骨骼检测、人脸特征点检测、手部关键点检测等具体应用",
        "帮助学员掌握重要人工智能框架的使用场景"
      ],
      "course_content": {},
      "requirements": [
        "有编程经验"
      ],
      "description": "本课程将直接从深度学习入手，从基础的目标识别与检测，过渡到关键点检测之人体骨骼检测，再一步步过渡到人脸特征点检测、手部关键点检测、3D物体关键点检测和图卷积网络。沿着深度学习的脚步，一步一步向下过渡，探索其关联，由浅入深地让学员快速掌握。本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权,任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "适合企业人脸识别算法工程师",
        "适合企业中高级算法工程师",
        "适合企业中高级自动驾驶工程师"
      ]
    },
    {
      "title": "教你制作数字人分身，高效带货变现",
      "url": "https://www.udemy.com/course/eaidshni/",
      "bio": "数字人分身打造秘笈，带货变现新篇章",
      "objectives": [
        "了解AI数字人发展趋势和未来前景",
        "通过对AI数字人技术在自媒体方面降本增效",
        "了解AI数字人在短视频带货中的巨大潜力",
        "克隆自己的数字人，当你的互联网嘴替"
      ],
      "course_content": {},
      "requirements": [
        "零基础"
      ],
      "description": "随着互联网的快速发展，数字人技术已成为带货变现的热门趋势。然而，许多从业者面临着技术瓶颈和营销难题，导致带货效果不尽如人意。\n阿甜老师，作为小红书学员的知名导师，以其独特的教学方法和深厚的行业背景，将为你揭示数字人分身的制作秘密，让你轻松掌握高效带货的诀窍。\n通过这门课程的学习，你将能够突破行业痛点，提升带货效果，实现个人或品牌的快速发展。无论你是初学者还是有一定基础的从业者，这门课程都将为你提供宝贵的学习机会和成长空间。",
      "target_audience": [
        "想要学习自媒体但是不想自己拍摄的博主",
        "想要做短视频带货但是没有思路的创业者",
        "想要了解最新AI数字人趋势的时代创新者和职场人士"
      ]
    },
    {
      "title": "AI时代下的运营基石课",
      "url": "https://www.udemy.com/course/ai-hpilx/",
      "bio": "ChatGPT赋能运营和营销，大幅提升个人生产力",
      "objectives": [
        "深刻理解AI 2.0的底层逻辑，也能知道个人如何才能在AI时代下用好AI，大幅自己的个人生产力",
        "通过一个核心认知模型，即可清晰理解市面上五花八门的各种运营、营销工作岗位和概念",
        "能学会如何快速找到绝大多数一线运营、营销工作的工作解题思路和关键要点",
        "能学会如何快速找到绝大多数一线运营、营销工作的工作解题思路和关键要点，避免陷入“认知错乱和错位”"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲",
          "引入讲解"
        ],
        "第一章 理解“生成式AI”的本质和生产力提升公式": [
          "理解“生成式AI”的本质和生产力提升公式",
          "理解“生成式AI”的本质",
          "使用“生成式AI”的忠告1-3",
          "生成式AI的核心生产力公式",
          "生成式AI对于个人的主要“生产力”赋能提升可能",
          "案例分析",
          "使用“生成式AI”的忠告4-5",
          "什么样的人才能真正因生成式AI而极大收益",
          "使用“生成式AI”的忠告6-7"
        ],
        "第二章 如何从根本上解构一切运营/营销工作？": [
          "如何通过“运营6要素”来解构一切运营/营销工作",
          "案例分析",
          "分析理解运营/营销工作的3个层次",
          "如何通过“运营6要素”从微观层面解构一切运营/营销工作",
          "运营工作背后的用户路径",
          "三种围绕用户路径的问题+解决思路",
          "案例分析",
          "“6要素”的框架怎么帮助我们更好理解一份工作？",
          "参考练习：6要素分析工作岗位"
        ],
        "第三章 深刻理解业务流程梳理、数据驱动增长和最常见的数据应用": [
          "理解“用户路径”和常见业务指标 的拆解、达成策略间的关系",
          "数据如何驱动业务增⻓",
          "常见数据分析方法",
          "AI如何提升数据分析处理效率"
        ],
        "第四章 建立自己运营/营销武器库，拥有10倍+成长速度": [
          "“案例拆解”的意义和价值",
          "案例展示",
          "如何在“单个案例”的拆解中收获抓住 更多高价值信息",
          "案例拆解实操",
          "案例库示例"
        ],
        "第五章 如何10 倍提升你的内容创作质量？": [
          "内容学习",
          "内容生成",
          "内容优化",
          "温馨提示"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "对AI有初步了解"
      ],
      "description": "ChatGPT的到来改变了很多行业，很多技巧、套路式的运营、营销工作都可以使用AI非常高效的帮我们生成和解决。那么到底未来需要怎样的运营和营销人才呢？\n为了更好解答这个问题，三节课联合黄有璨老师推出本门重磅课程。 这门课程的目标是让运营、营销人可以更好理解生成式AI的本质，知道如何才能更好对于一切运营、营销工作进行分析、解构，找到工作要点，并且也能快速学会如何长期积累和建设自己的专属案例库+优质语料库，帮更多运营、营销背景的同学们可以更高效的从底层真正掌握AI时代的“运营/营销人成功范式”。",
      "target_audience": [
        "工作经验1-7年，至少有1-2年以上运营/营销相关工作经验",
        "对于AI时代下该如何更好利用AI做好运营、营销工作提升个人生产力有强烈困惑+系统学习需求者",
        "对AI有一定了解，希望提高运营和营销能力的人"
      ]
    },
    {
      "title": "MATLAB: Mühendisliğe Giriş Eğitim Seti",
      "url": "https://www.udemy.com/course/matlab-muhendislige-giris-egitim-seti/",
      "bio": "Matlab Eğitim Seti",
      "objectives": [
        "Mühendislik Matematiği Matlab Yetkinliği",
        "Sıfırdan Matlab Programlama",
        "Grafik Oluşturma ve Soru Çözümü",
        "Elektrik Mühendisliği ve Bilgisayar Mühendisliği için Matlab Bilgisi"
      ],
      "course_content": {
        "Matlab Tanıtım Videosu": [
          "Giriş"
        ],
        "Adım Adım Matlab": [
          "Matlab Komut ve Fonksiyonları Tanımı (Açıklamalı)",
          "Matris İşlemleri Tanımlama",
          "Matlab'da Skaler; Vektör Ve Matris İşlemlerine Giriş",
          "Denklemlerle Soru Çözümleri",
          "Sembolik Toplama Soru Çözümü",
          "Türev Soru Çözümleri"
        ]
      },
      "requirements": [
        "PC ve Matlab Kurumu",
        "Matlab'a Meraklılık"
      ],
      "description": "Mühendislik ve Fen bilimlerinde sıklıkla kullanılan MATLAB'ı derinlemesine öğrenmek isteyen birçok kişi kendine uygun,basit ve detaylı anlatıma sahip bir eğitim seti aramaktadır. İşte ilgili Matlab Kılavuzu niteliğindeki eğitimi sizlerle paylaşıyorum. Gelin hep birlite matlab ile A'dan Z'ye farklı uygulamalar tasarlayalım.\nMatlab Hakkında Detaylı Bilgi:\n\n\nMatlab, ilk defa bir matrix programlama dili olarak kullanılmıştır. Şimdi ise makine öğrenmesi, veri bilimi ve derin öğrenme gibi ileri düzey konularda da sıkça kullanılır.\nMatlab Nedir ve Ne işe Yarar?\nMatlab, genellikle mühendislik ve pozitif bilim hesaplamaları için kullanılan bir çeşit bilgisayar programıdır. Matlab, ABD merkezli MathWorks firması tarafından geliştirilen 4. nesil ve çok paradigmalı bir programlama dilidir. İngilizcede “Matrix Laboratory”olan kelimelerinin birleştirilmesi ile ortaya çıkan Matlab, adından da anlaşılacağı gibi matris tabanlı bir çalışma sistemine sahip bir programlama dilidir. Matlab, lineer cebir, optimizasyon, istatistik, nümerik analiz, fourier analizi, optimizasyon gibi pek çok matematiksel hesaplamanın hızlı ve etkili bir şekilde yapılmasına yardımcı olur. Aynı zamanda matlab, 2D ve 3D grafik çizimi yapmak için de sıkça kullanılır.\nMatlab Nerelerde Kullanılır?\nMatlab, genellikle mühendislik uygulamalarında sıkça kullanılır. Matlab, matematiksel hesaplamalarda ve sistemlerin analizinde sıkça kullanılır. Matlabın başlıca kullanım alanları şunlardır:\nData Analizi ve Görselleştirme\nAlgoritma Geliştirme\nSayısal Lineer Cebir Hesaplamaları\nBüyük Veriler için Grafikler Oluşturma\nMakine öğrenmesi\nDerin öğrenme\nData bilimi\nSimülasyon\nUygulama Programlama Arayüzü ve Grafiksel Kullanıcı Arayüzü oluşturma\nMatlab Özellikleri Nelerdir?\nMatlab'ın kullanımı diğer programlama dillerine göre bazı avantajlar sağlar. Matlabın dikkat çeken bazı özellikleri şunlardır;\nMatlab, her veri elementini bir matrix olarak değerlendirir. Yani bir satır ya da sütundan, tam sayıdan oluşan bir matrix olarak değerlendirilir. Matrix toplama, çarpma ve bu işlemlerin tersi gibi çeşitli matrix işlemleri için gömülü ve hazır fonksiyonlar içerir.\nVektörleştirilmiş işlemler bu programda kullanılarak kodların boyutunu önemli ölçüde küçültür.\nAraç kutusunun kullanımı ile birlikte matlabın işlevselliği de önemli ölçüde zenginleştirilir. Mesela statik araç çubuğu, verilerin istatistiksel ve özelleştirilmiş kullanımını sağlar. Excel bağlantısı, verinin Excel tarafından okunabilecek şekilde yazılmasını sağlar.",
      "target_audience": [
        "Tüm Matlab Meraklıları"
      ]
    },
    {
      "title": "Fundamentos do Data Mesh",
      "url": "https://www.udemy.com/course/fundamentos-do-data-mesh/",
      "bio": "O que Você Precisa Saber para Começar",
      "objectives": [
        "Compreender o que é o Data Mesh e por que ele surgiu como alternativa ao modelo centralizado.",
        "Identificar os quatro pilares fundamentais do Data Mesh.",
        "Reconhecer os principais benefícios e desafios dessa abordagem moderna de dados.",
        "Aplicar um checklist prático para avaliar se sua organização está pronta para iniciar com Data Mesh.",
        "Avaliar sua organização com uma Matriz de Maturidade adaptada ao contexto do Data Mesh."
      ],
      "course_content": {
        "Módulo 1 - Fundamentos do Data Mesh": [
          "Introdução ao Problema – Por que Data Mesh?",
          "Limitações das Arquiteturas de Dados Tradicionais",
          "O que é Data Mesh? (Conceito e Definição)",
          "Os Quatro Princípios Fundamentais do Data Mesh",
          "Benefícios Esperados com o Data Mesh",
          "Exemplo Prático: Do Data Lake ao Data Mesh",
          "Analogia Lúdica para Entender o Data Mesh",
          "Recapitulando os Conceitos-Chave e Próximos Passos",
          "Conclusão"
        ],
        "Materiais Complementares": [
          "Check-list de Diagnóstico",
          "Matriz de Maturidade"
        ]
      },
      "requirements": [
        "Nenhum conhecimento prévio é necessário. O curso foi pensado para quem deseja entender o Data Mesh do zero, com explicações claras e exemplos práticos."
      ],
      "description": "Desvendando o Data Mesh – Fundamentos, Diagnóstico e Maturidade\nVocê já ouviu falar em Data Mesh, mas ainda não entendeu exatamente o que é? Ou talvez já tenha lido sobre o assunto, mas não conseguiu conectar os conceitos à realidade da sua empresa? Então este mini-curso introdutório é para você.\nAqui, vamos direto ao ponto: você vai aprender os fundamentos do Data Mesh de forma acessível, prática e estruturada, mesmo que ainda esteja dando seus primeiros passos nesse universo. Sem enrolação, com linguagem clara, analogias lúdicas e materiais complementares que realmente ajudam.\nO que você vai aprender?\nO que é o Data Mesh e por que ele surgiu como uma resposta às limitações das arquiteturas centralizadas;\nOs quatro pilares fundamentais do Data Mesh: Domínios como responsáveis, Dados como Produto, Plataforma de Autosserviço e Governança Federada;\nOs principais benefícios práticos dessa abordagem para a agilidade, escalabilidade, governança e qualidade de dados nas organizações;\nComo diagnosticar se sua empresa está pronta para o Data Mesh com um checklist estruturado;\nComo posicionar sua empresa dentro de uma Matriz de Maturidade do Data Mesh, entendendo onde você está e quais próximos passos seguir.\nRecursos do curso\nChecklist de Diagnóstico Inicial com interpretação de resultados e próximos passos;\nMatriz de Maturidade por dimensão, para guiar sua evolução;\nVideoaulas didáticas com exemplos reais e comparações simples para fixar o conteúdo.",
      "target_audience": [
        "Profissionais de dados, tecnologia ou negócios que desejam entender o que é Data Mesh, como ele funciona e por que está revolucionando a arquitetura de dados."
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第24部 使用Pytorch編寫 Stable Diffusion 上部",
      "url": "https://www.udemy.com/course/generative_ai_24/",
      "bio": "關於Stable Diffusion， U-NET，Forward Process， Reverse Process，latent，ELBO，Autoencoder，CLIP，VAE， Pytorch，Markov chain，",
      "objectives": [
        "深入理解生成模型與概率分布的關係，以及擴散模型的正向（adding noise）與逆向（denoising）過程",
        "掌握 DDPM 論文（Denoising Diffusion Probabilistic Models）中正向與逆向過程的核心數學公式與變分推理方法",
        "學會訓練與採樣新數據的技巧，並能透過無分類器引導（classifier-free guidance）自訂生成結果的風格與品質",
        "熟悉 CLIP 模型在文本—圖像共同嵌入空間中的運作原理與應用場景",
        "掌握潛在擴散模型（Latent Diffusion Model）與變分自動編碼器（VAE）的結合應用，理解潛在空間中圖像生成的高效流程",
        "全面解析 Stable Diffusion 的編碼器（Encoder）與解碼器（Decoder）實現細節，以及整體架構設計"
      ],
      "course_content": {
        "課程準備": [
          "課程工具準備",
          "如何使用uv 作為包管理器和項目管理工具"
        ],
        "什麼是Stable Diffusion & Forward Reverse Process & VAE & CLIP & U-NET & ELBO": [
          "什麼是Stable Diffusion & Forward Reverse Process & VAE & CLIP & U-NET & ELBO"
        ],
        "如何用 Pytorch 編寫 VAE Encoder, VAE Decoder, CLIP, Attention 組件": [
          "如何使用 Pytorch 編寫 VAE Encoder 編碼器",
          "如何用 Pytorch 編寫 VAE Decoder 解碼器",
          "如何編寫自注意力和交叉注意力機制代碼",
          "如何用 Pytorch 編寫 CLIP 文本編碼器"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "本課程從理論到實作，全方位解析 Stable Diffusion 及其背後的擴散模型（Diffusion Models），幫助學員掌握從基礎概念、數學原理到完整架構與編碼實現的整套流程，並具備在實際專案中進行微調與推論的能力。\nStable Diffusion 概述\nStable Diffusion 是一款基於潛在擴散模型（Latent Diffusion Model）的深度學習文字生成影像框架，顛覆了 DALL·E 等專有模型的使用方式，開放源碼且可在常規 GPU 上運行 Wikipedia。\n生成模型與概率分布\n介紹生成模型（Generative Models）如何學習複雜數據的概率分布，並以高斯分佈與變分推理作為實例說明 Wikipedia。\n擴散模型的正向與逆向過程\n正向（forward）過程為逐步加入噪聲至數據；逆向（reverse）過程則學習將噪聲還原成數據的轉換，核心在於有限步數的馬可夫鏈建模 AI Summer。\nDDPM 論文的數學原理\n深入解讀 Jonathan Ho 等人提出的 Denoising Diffusion Probabilistic Models，包含變分下界（ELBO）分解與重構誤差項的推導 Wikipedia。\n模型訓練方法\n實作如何設置噪聲日程（βₜ schedule）、選擇優化器與 loss 函數，並透過 PyTorch 範例演示完整訓練流程 Medium。\n採樣生成新數據\n展示從隨機純噪聲到最終影像的迭代採樣（sampling）演算法，以及影響速度與品質的關鍵參數 Hugging Face。\n控制去噪過程\n演示如何透過無分類器引導（classifier-free guidance）或自定義時間嵌入（time embeddings）調節生成內容的細節與風格 Hugging Face。\n無分類器引導 (Classifier-Free Guidance)\n理解 “guidance scale” 如何在不依賴外部分類器的情況下提升生成品質，並提供範例程式碼示範。\nCLIP 模型\nCLIP（Contrastive Language–Image Pretraining）通過對比學習將文本與圖像映射到同一向量空間，借助 4 億對圖文數據學習通用視覺語義表示 Wikipedia。\n潛在擴散模型與 VAE\n講解 VAE（Variational Autoencoder）如何將高維圖像壓縮到低維潛在空間，再利用擴散模型在潛在空間中進行逐步噪聲與去噪 Wikipedia。\nStable Diffusion 架構\n全面剖析架構：CLIP 文本編碼器、VAE 編碼器/解碼器、U-Net 去噪網絡，以及整合管線 超堆疊。\n編碼器實現\n實作 VAE 編碼器將圖像映射到潛在表示的細節，包括卷積層設計與參數初始化。\n解碼器實現\n演示如何根據潛在向量利用 U-Net 架構及注意力機制（self-attention）逐步還原高解析度影像。",
      "target_audience": [
        "AI/ML 研究者與工程師",
        "產品經理與創意設計師",
        "數據科學家與視覺工程師",
        "所有對 AI 藝術與創新應用有興趣者"
      ]
    },
    {
      "title": "AI数学③文系・中高年の方でも分かる！AIのための数学入門 ( 微分編 ) ー国立大学首席で卒業したプロの講師直伝！",
      "url": "https://www.udemy.com/course/ai3ai-xh/",
      "bio": "導関数・平均変化率・微分係数・極限値・微分公式をゼロから学び、AI・機械学習の仕組みが“意味から”わかるようになる40〜60代のためのやさしい微分講座",
      "objectives": [
        "微分の基本的な考え方を理解し、数式としての導関数を求められるようになる。",
        "「変化率」の直感的イメージから、微分係数へとつながる数学的な流れを理解できる。",
        "微分計算の土台となる極限の概念と、その計算方法を身につける。",
        "多項式・三角関数・指数関数などの代表的な関数の微分公式を習得する。",
        "微分が「グラフの接線の傾き」を表すことを視覚的・直感的に理解する。",
        "損失関数や最適化計算など、AI分野で微分が使われる具体例を知る。"
      ],
      "course_content": {
        "AI理解の基礎となる微分の核心を、導関数から微分公式までやさしく解説します。": [
          "定義による導関数",
          "導関数と微分係数",
          "平均変化率と微分係数 ( 1 )",
          "平均変化率と微分係数( 2 )",
          "微分法の公式を利用",
          "微分法・極限より係数決定",
          "微分法・極限値"
        ]
      },
      "requirements": [
        "高校初級レベルの数学（四則演算・分数・平方根）の理解",
        "中学数学の一次関数・二次関数の基礎",
        "グラフや関数に抵抗がない程度の知識",
        "パソコンまたはタブレットで動画を視聴できる環境",
        "メモを取りながら学習できる意欲",
        "数学に苦手意識があっても基礎から学び直す意思"
      ],
      "description": "AIや機械学習を学ぶとき、多くの方が最初にぶつかる壁のひとつが「微分」です。\n学校で習ったはずの微分も、年月が経つと忘れてしまい、公式だけを丸暗記した記憶がうっすら残っている…という方も多いのではないでしょうか。\nしかし、AIの内部計算、特に機械学習や深層学習（ディープラーニング）では、微分の考え方が欠かせません。\nたとえば、AIが最適なパラメータを探すときには「勾配降下法（こうばいこうかほう）」という方法が使われますが、これはまさに微分を使って傾きを計算し、少しずつ誤差を減らしていく作業です。\n\n\n本講座は、そんなAIの心臓部ともいえる「微分」を、数学が苦手な方でも理解できるようにゼロから丁寧に解説します。\n数式の意味や背景を大事にし、導関数・平均変化率・微分係数・極限値・微分公式などの基礎を、例題を使って学びます。\n\n単なる計算テクニックではなく、「なぜそうなるのか」を理解することで、記憶に定着しやすくなり、実際のAI分野での応用もイメージしやすくなります。\n本講座で扱う内容は以下の通りです。\n微分の基本的な意味と日常でのイメージ\n平均変化率と微分係数の関係\n極限値の考え方と計算\n基本的な微分公式の習得\nグラフと傾きの関係\n\n\nこのコースは、文系出身の方や40代〜60代の学び直し世代を中心に設計しています。\n高校数学でつまずいた経験がある方、公式の丸暗記ではなく意味から理解したい方に最適です。\nまた、AIや機械学習の学習をこれから始めたい方にとっても、土台作りとして非常に有効です。\n\n\n\n\n受講後には、\n「微分の公式を自信を持って使える」\n「AIの仕組みを数学的に理解できる」\n「数学への苦手意識が薄れる」\nという変化を実感していただけるはずです。\n国立大学首席卒の講師が、あなたの“もう一度学びたい”という思いを全力でサポートします。\n\n微分を“壁”ではなく“味方”に変えて、AI時代の学び直しをスタートしましょう！",
      "target_audience": [
        "AIや機械学習の仕組みを数学的に理解したい文系の方",
        "40代・50代・60代の学び直しを目指す社会人",
        "高校数学をやり直したい初学者",
        "AI・データ分析の基礎スキルを身につけたいエンジニア志望者",
        "微分を“公式暗記”ではなく意味から理解したい方",
        "数Ⅱの微分でつまずいた経験があるが、もう一度挑戦したい方"
      ]
    },
    {
      "title": "Data Analysis Professionals Using Python Programming",
      "url": "https://www.udemy.com/course/data-analysis-professionals-using-python-programming/",
      "bio": "Data Analysis using Python programming language",
      "objectives": [
        "Python code",
        "Analysis steps",
        "Work on data set projects to make dashboard",
        "Can do the same on your own data and work as Data Analyst"
      ],
      "course_content": {
        "Lecture1": [
          "Lecture1"
        ],
        "Lecture2": [
          "Lecture2"
        ],
        "Lecture3": [
          "Lecture3-part1"
        ],
        "Lecture3-Part2": [
          "Lecture3-Part2"
        ],
        "Lecture": [
          "Lec4",
          "Lecture4-Part2",
          "Lecture5"
        ]
      },
      "requirements": [
        "Basics of statistics"
      ],
      "description": "In this course you will study below topics and after this course , you will be aware of\n1 - Python programing language code.\n2 - Analysis steps ( Data wrangling process : Data gathering , Data assessing , Cleaning data , Wrangle and analyze data , Visualization )   .\n3-you will work on data sets projects to make dashboards .\n4 - And Finally you can do the same on your own data of your work.\n\n\n--- Main course Topics :\n- Introduction to Python .\n- Data types and operator .\n- Data structure .\n- Control flow .\n- Functions .\n- Scripting .\n- NumPy .\n- Pandas .\n- Project explore data .\n-introduction to data analysis .\n- Jupyter notebook .\n- Data analysis process .\n- Programing workflow for data analysis .\n-Data wrangling process and steps .\n- Data gathering  .\n- Data assessing .\n- Cleaning data .\n- Wrangle and analyze data.\n- Project on your selected dataset.\n-  Project validating .\n- Project solution sharing .\n\n\nPerquisites:\n- statistical knowledge\n- No Code knowledge\nAfter this course , you will be aware of\n1 - Python programing language code.\n2 - Analysis steps ( Data wrangling process : Data gathering , Data assessing , Cleaning data , Wrangle and analyze data , Visualization )   .\n3-you will work on data sets projects to make dashboards .\n4 - And Finally you can do the same on your own data of your work.\n\n\nRequired Programs:\nIt will be mentioned during lectures and source exist as well in sources repo.",
      "target_audience": [
        "Professional analytics"
      ]
    },
    {
      "title": "Mastering PySpark-Big Data Processing for Beginners In Hindi",
      "url": "https://www.udemy.com/course/pyspark-for-beginners-in-hindi/",
      "bio": "Big Data और PySpark को आसान भाषा में सीखें - डेटा, डेटाबेस, बिग डेटा और PySpark का आसान परिचय",
      "objectives": [
        "डेटा, डेटाबेस और बिग डेटा की मूल बातें समझना",
        "बिग डेटा की विशेषताएँ और पारंपरिक सिस्टम क्यों असफल होते हैं, यह जानना",
        "Apache Spark की भूमिका बिग डेटा इकोसिस्टम में समझना",
        "आसान भाषा में PySpark और उसकी आर्किटेक्चर का परिचय",
        "Spark Applications कैसे चलते हैं (Driver, Executors, Cluster Manager) यह समझना",
        "RDDs, DataFrames और Datasets के बीच अंतर सीखना",
        "असली प्रोजेक्ट्स में PySpark DataFrames के फायदे जानना",
        "Understand the basics of Data, Databases, and Big Data in Hindi",
        "Learn the characteristics of Big Data and why traditional systems fail in Hindi",
        "Get a beginner-friendly introduction to PySpark and its architecture in Hindi"
      ],
      "course_content": {
        "Introduction to Big Data and PySpark": [
          "Introductions",
          "What is Data & Database-डेटा क्या है & डेटाबेस क्या है?",
          "What is Big Data-बिग डेटा क्या है?",
          "Characteristics Of Big Data",
          "Role of Apache Spark in Big Data Ecosystem",
          "Introduction to PySpark and its architecture"
        ],
        "Spark Applications and Execution Model": [
          "Components of a Spark application",
          "How Spark runs a job (Driver, Executor, Cluster Manager)",
          "Understanding RDDs vs DataFrames Vs Dataset",
          "Benefits of using PySpark DataFrames"
        ],
        "Account Configurations": [
          "PySpark Account Configurations Options",
          "Create Our Azure Subscriptions",
          "Create Azure Databricks Workspace",
          "Introductions To Azure Databricks Workspace",
          "Create Compute infrastructure In Azure Databricks",
          "Installing and using PySpark in Databricks",
          "Accessing Data (files) Using Pyspark Code from Databricks",
          "Delete Compute infrastructure To save cost",
          "Use Google Collab (colab.research.google.com)",
          "Install Jupyter Notebook",
          "Configure PySpark In Jupyter Notebook",
          "Execute PySpark In Jupyter Notebook"
        ],
        "Working with PySpark DataFrames": [
          "Reading data from CSV-fix Header",
          "Exploring schema and data types",
          "Reading data from Parquet",
          "Reading data from JSON",
          "Read JSON Data With different modes",
          "Performing basic operations: select",
          "Performing basic operations: filter",
          "Performing basic operations: sort",
          "Performing basic operations: withColumn & renaming columns",
          "DataFrame transformations and actions"
        ],
        "Data Processing & Transformation Techniques": [
          "Real-world data cleaning use cases: Handling nulls & dropping duplicates",
          "Using groupBy() And Agg()",
          "Using window functions-Understand Basic Concepts",
          "Window functions Demo",
          "Applying custom functions using UDFs"
        ],
        "Spark SQL": [
          "Registering DataFrames as temporary views & Writing SQL queries inside PySpark",
          "Filtering Data Using Spark SQL & Aggregating using Spark SQL",
          "Comparing DataFrame API vs Spark SQL"
        ],
        "Writing Data & Integration": [
          "Writing DataFrames to CSV",
          "Writing DataFrames to Parquet",
          "Writing DataFrames to Delta",
          "Partitioning basics",
          "Bucketing basics",
          "Simple pipeline use case"
        ],
        "Performance Optimization (Basics)": [
          "Introductions-Performance Optimization",
          "Lazy Evaluation in Spark",
          "Catalyst Optimizer and Tungsten Engine (intro only)",
          "Caching and Persistence techniques",
          "Tips for optimizing PySpark jobs"
        ],
        "Final Project": [
          "Create Databricks Free Edition Account",
          "Create Notebook In Databricks Free Editions",
          "Introductions To Databricks Notebook",
          "Use Serverless Compute In Databricks & Execute Our Pyspark Code",
          "Load Data Into Databrikcs",
          "Read CSV & Parquet Files Using Databricks",
          "Cleaning and analyzing large dataset Using Databricks",
          "Databricks--- Simple Assignment",
          "Big Data Analysis Using Data Bricks Part 1",
          "Big Data Analysis Using Data Bricks Part 2",
          "Big Data Analysis Using Data Bricks Part 3",
          "Big Data Analysis Using Data Bricks Part 4",
          "Saving files to local and cloud storage (Databricks)",
          "End-to-end data pipeline in Databricks using PySpark",
          "joining Data Using Spark SQL",
          "Summary and next steps"
        ],
        "Bonus": [
          "Bnous"
        ]
      },
      "requirements": [
        "A PC / Laptop / Computer or even a Mobile to watch the course videos",
        "अभ्यास के लिए: आप अपने स्वयं के कंप्यूटर का उपयोग कर सकते हैं, या Google Colab या Azure Databricks (सशुल्क) जैसे निःशुल्क प्लेटफ़ॉर्म का उपयोग कर सकते हैं",
        "No prior experience needed – course is designed for absolute beginners in Hindi",
        "For practice: you can use your own computer, or free platforms like Google Colab or Azure Databricks (paid)",
        "Basic curiosity and willingness to learn Big Data and PySpark",
        "Internet connection is require (इंटरनेट कनेक्शन की आवश्यकता है)"
      ],
      "description": "आज की दुनिया में हर जगह डेटा है — सोशल मीडिया, ऑनलाइन शॉपिंग, बैंकिंग लेन-देन या मोबाइल ऐप्स। लेकिन इतना बड़ा डेटा पारंपरिक डेटाबेस संभाल नहीं पाते। यही कारण है कि Big Data और उसके टूल्स की ज़रूरत होती है।\nइस शुरुआती स्तर के कोर्स में हम शुरुआत करेंगे डेटा और डेटाबेस की मूलभूत समझ से, फिर सीखेंगे कि Big Data क्या है और इसकी प्रमुख विशेषताएँ जैसे Volume, Velocity, Variety, Veracity और Value।\nइसके बाद हम जानेंगे कि Apache Spark कैसे Big Data की दुनिया में एक महत्वपूर्ण भूमिका निभाता है और क्यों यह इतना लोकप्रिय है। फिर आप सीखेंगे PySpark, जो Python के ज़रिए Spark के साथ काम करने का आसान तरीका है।\n\n\nकोर्स में शामिल विषय:\n\n\nPySpark और Spark की आर्किटेक्चर\n\n\nSpark Application और Execution Model\n\n\nDriver, Executor और Cluster Manager की भूमिका\n\n\nSpark में RDDs, DataFrames और Datasets का अंतर\n\n\nDataFrames के फायदे और उनके वास्तविक उपयोग\nइस कोर्स के अंत तक, आपके पास बिग डेटा और पायस्पार्क का एक मज़बूत आधार होगा। यह कोर्स छात्रों, शुरुआती प्रोग्रामर्स और बिग डेटा की दुनिया में अपना पहला कदम रखने की चाह रखने वाले सभी लोगों के लिए आदर्श है।\n\n\nयह कोर्स Udemy की 30-दिन की रिफंड पॉलिसी के साथ आता है (Udemy की शर्तें लागू)। इसका मतलब है कि आप बिना किसी जोखिम के इस कोर्स में दाखिला ले सकते हैं और सीखना शुरू कर सकते हैं।\n\n\nAre you curious about how companies like Netflix, Amazon, or Flipkart process huge amounts of data every single day? Do you want to learn how modern data engineers handle “Big Data” in a simple, beginner-friendly way? If yes, then this course is designed just for you.\nIn today’s world, data is everywhere. From social media likes to online shopping transactions, every activity generates data. But traditional databases can’t handle the massive scale, variety, and speed of this data. This is where the world of Big Data begins. In this course, we will start from the very basics — understanding what data is, how databases store it, and why Big Data requires special tools.\nOne of the most powerful tools in the Big Data ecosystem is Apache Spark. Spark is a lightning-fast, open-source framework that allows you to process massive datasets efficiently. It is widely used in data engineering, machine learning, and analytics. Spark plays a key role in helping organizations process data in real time, making it one of the most in-demand skills today.\nTo make Spark more accessible for Python developers, the community introduced PySpark, which allows you to write Spark applications using Python. This course will give you a complete introduction to PySpark and its architecture, explained in Hindi for better understanding.\nWe will begin by exploring the characteristics of Big Data — Volume, Velocity, Variety, Veracity, and Value. These concepts will help you understand why traditional systems fail and why Spark is the perfect choice. Next, we will discuss the role of Apache Spark in the Big Data ecosystem, including how it integrates with other tools like Hadoop and data lakes.\nYou will then learn the architecture of PySpark, including its components and how it fits into Spark’s overall framework. We will explain how Spark applications are structured and executed, covering the execution model step by step. By the end of this section, you will clearly understand the roles of the Driver, Executors, and the Cluster Manager in running a Spark job.\nOnce the basics of Spark execution are clear, we will dive deeper into the core data structures supported by Spark — RDDs (Resilient Distributed Datasets), DataFrames, and Datasets. We will compare them, discuss when to use each, and explain why DataFrames are preferred in PySpark. You’ll also learn about the benefits of using PySpark DataFrames for large-scale data processing, including performance improvements and ease of use.\nBy the end of this course, you will have a solid beginner-friendly foundation in Big Data and PySpark. You will not only understand the theoretical concepts but also gain the confidence to start working with PySpark for real data processing tasks.\nWhether you are a student, a beginner in programming, or someone curious about Big Data, this course will make your learning journey simple, practical, and enjoyable — all in Hindi.\nEnroll today and take your first step into the exciting world of Big Data Processing with PySpark!\nThis course comes with Udemy’s 30-day refund policy (Udemy refund policies apply). That means you can enroll 100% risk-free and start learning with confidence.",
      "target_audience": [
        "उन लोगों के लिए जो pyspark सीखना चाहते हैं",
        "अगर आप एक शुरुआती छात्र हैं और Big Data व PySpark की दुनिया में कदम रखना चाहते हैं – तो यह कोर्स आपके लिए है।",
        "आपने Python सीखी है और अब सोच रहे हैं कि इसे बड़े पैमाने के डेटा पर कैसे इस्तेमाल करें – तो यह कोर्स बिल्कुल सही शुरुआत देगा।",
        "अगर आप डेटा के शौकीन हैं और RDDs, DataFrames और Datasets जैसे कॉन्सेप्ट को प्रैक्टिकल उदाहरणों के साथ सीखना चाहते हैं।",
        "Beginners who want to start their journey in Big Data and PySpark in Hindi.",
        "Students who have basic knowledge of Python and want to apply it to large-scale data."
      ]
    },
    {
      "title": "Advanced Excel for Data Analysis: Techniques and Application",
      "url": "https://www.udemy.com/course/professional-course-for-data-analysis-using-excel/",
      "bio": "Excel Data Analysis From Scratch To Professional Level",
      "objectives": [
        "1-How To Mak Cleaning and Transformation to Data By Using Power Query Editor (Append ,Merge ,Group by ,Remove Columns, Split Columns ,Conditional Column etc)",
        "2-Make Relationships between tables by using Primary Kay and Foreign Key ,,Power Pivot ,, Create Measures and New Columns By Using DAX ,, Create Calendar Table",
        "3-Analyzing Data By Using Pivot Table (Row , Column , Value , Filter)",
        "4-Using Different Pivot Charts To Create Creative Dashboard and Professional Report",
        "5-Working on Real Data and Many Projects",
        "EX: Sales Data Analysis Project"
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Power Query Editor For Cleaning Data and Making Transformation": [
          "How to Import Data to Excel",
          "Remove Rows and use First Row as header",
          "Change Type ,Rounding ,Standard , Statistics",
          "Close and Load To",
          "Format",
          "Merge Columns",
          "Split Columns",
          "Group By",
          "Append Files",
          "How To Import Data From Folder",
          "How To Merge Different Files",
          "Custom Column",
          "Conditional Column"
        ],
        "Data Modeling, DAX, Calendar Table": [
          "Import Data and Clean it",
          "Power Pivot and Primary Key, Foreign Key Concept",
          "Relationship and Calander Table",
          "Creat Column By DAX",
          "Create Different Measures (KPI'S) By DAX",
          "Pivot table",
          "How to Use Different Measures in Pivot Table"
        ],
        "Pivot Table and Dashboard": [
          "Clean Data in Power Query",
          "Data Model and DAX",
          "Pivot Table and Pivot Chart",
          "Dashboard",
          "Pivot Table"
        ]
      },
      "requirements": [
        "no programming experience needed. you will learn everything in this course from scratch.",
        "You Don't Need Any Thing",
        "no need to know any thing before this course"
      ],
      "description": "This Course for any one want to learn data analysis field there is no need to any background for this course ,, in this course you will learn in details many things\n\n\n1-Power Query Editor in Excel To Clean and Transform Data\n(Remove Columns , Remove Rows , Merge Columns , Split Columns , Conditional Columns , Custom Columns ,Append Queries , Merge Queries, Select Data From Folder, Data Types ,Statistics , Standard, Rounding, Group by)\n\n\n2-Pivot Table\n\n\n3-Relationships between tables using Primary Key and Foreign Key ( Explain Primary Key and Foreign Key Concept )\n\n\n4-Create Measures and Columns using DAX(Data Analysis Expression) to Know KPI'S in Data\n(Using Calculate Function , SUM Function , SUMX Function , AVERAGEX Function , Divide Function)\n\n\n5-Create Calendar Table to Analyze Data Based in Many Different Dates (Day , Month , Year , Quarter)\nAnalyzing Data by Using Day of Month or Day of Year or Day of Quarter ,, Analyzing Data by Using Month of Specific Year or Month of Specific Quarter ,, Analyzing Data By Specific Quarter or For All Quarters of all Year ,, Analyzing Data for Specific Year or all Years of Data\n6-Analysisng Data Using Pivot Table\nUsing Rows , Columns Filter , Value on Pivot Table\n\n\n7-Making Professional Dashboard By using Different Pivot Charts\nUsing Par Chart , Pie Chart , Column Chart , Line Chart , Area Chart",
      "target_audience": [
        "Beginner Data Analysis Developers Curios about Data Analysis Field",
        "For Student ,Graduate , Employee ,, any one want to learn Data Analysis Field in Simplest and Easiest Way",
        "For any one Want to Learn The Data Analysis Field",
        "For any Beginners this Course Don't Require any Background"
      ]
    },
    {
      "title": "[NL] Full-Stack AI met Ollama: Llama, Deepseek, Mistral, QwQ",
      "url": "https://www.udemy.com/course/full-stack-ai-met-ollama-llama-deepseek-mistral-qwq/",
      "bio": "Bouw AI-apps met open-source modellen: NLP, chatbots, code, samenvattingen, automatisering en meer.",
      "objectives": [
        "Leer AI-modellen lokaal te installeren en draaien met Ollama.",
        "Bouw AI-apps met LLaMA 3, Mistral, CodeLlama, Mixtral en DeepSeek-R1.",
        "Voer NLP-taken uit: samenvatten, genereren, corrigeren en extraheren.",
        "Ontwikkel AI-assistenten: chatbots, klantenservice en persoonlijke bots.",
        "Genereer en debug code met CodeLlama voor efficiënter programmeren.",
        "Genereer en debug code met CodeLlama voor efficiënter programmeren.",
        "Automatiseer taken: e-mails, vergadernotities en cv’s met AI.",
        "Werk met live data via nieuws- en financiële API’s.",
        "Werk met live data via nieuws- en financiële API’s."
      ],
      "course_content": {
        "Snel van Start – Ollama Instellen en Eerste AI-Model": [
          "Introductie van Sectie: Snel van Start – Ollama Instellen en Eerste AI-Model",
          "Introductie tot Ollama",
          "Ollama Installeren en Configureren",
          "Aan de Slag met Python",
          "Je Eerste AI-Project: AI Chatassistent"
        ],
        "AI voor Tekstverwerking (NLP & LLM’s)": [
          "Introductie van Sectie: AI voor Tekstverwerking (NLP & LLM’s)",
          "AI-tekstsamenvatter met Mistral-model",
          "AI-blog & contentgenerator met LLaMA 3",
          "Codegenerator & debugger met CodeLlama",
          "Grammatica- en spellingscontrole met Deepseek R1",
          "Juridische documentanalyse met Phi-2",
          "Real-time nieuws-samenvatter met Qwen 2.5"
        ],
        "AI voor Conversatiebots en Assistenten": [
          "Introductie van Sectie: AI voor Conversatiebots en Assistenten",
          "Klantenservice-chatbot – QWQ-model",
          "Virtuele Assistent met AI – LLaMA 2",
          "Medische Symptoomchecker – MedLLaMA 2",
          "E-commerce Productaanbeveler – Granite 3.2"
        ]
      },
      "requirements": [
        "Basiskennis van programmeren – Enige ervaring met Python is handig, maar niet verplicht. We begeleiden je stap voor stap door het coderen.",
        "Basisinzicht in AI en Machine Learning – Geen diepgaande ML-kennis nodig, maar weten hoe AI-modellen werken is voordelig.",
        "Bekendheid met webontwikkeling (optioneel) – Enige ervaring met HTML, JavaScript en FastAPI helpt bij het bouwen van AI-gestuurde webapplicaties.",
        "Deze cursus is gestructureerd om absolute beginners te begeleiden bij AI-ontwikkeling, en biedt geavanceerde projecten voor ervaren ontwikkelaars.",
        "Als je nieuw bent in AI, behandelen we alles stap voor stap. Als je ervaren bent, werk je hands-on aan echte AI-projecten met Ollama’s topmodellen."
      ],
      "description": "Full-Stack AI met Ollama: Llama, DeepSeek, Mistral, QwQ, Phi-2, MedLlama2, Granite3.2 is de ultieme praktijkgerichte cursus voor AI-ontwikkeling. Je leert hoe je echte AI-toepassingen bouwt en implementeert met behulp van de nieuwste open-source AI-modellen. Of je nu een beginner bent die AI verkent of een ervaren ontwikkelaar, deze cursus biedt je praktische projecten om grote taalmodellen (LLM’s) te integreren in webapps, automatiseringstools en geavanceerde AI-oplossingen.\nGedurende deze cursus leer je hoe je Ollama installeert, configureert en gebruikt om krachtige AI-modellen lokaal uit te voeren, zonder afhankelijk te zijn van dure cloud-API’s. Je werkt met LLaMA 3, DeepSeek, Mistral, Mixtral, QwQ, Phi-2, MedLlama2, Granite3.2 en CodeLlama, en ontwikkelt vaardigheden in natuurlijke taalverwerking (NLP), tekstgeneratie, code-aanvulling, debugging, documentanalyse, sentimentanalyse en AI-automatisering.\nDe cursus bevat tal van praktijkprojecten. Je ontwikkelt een AI-gedreven nieuws-samenvatter, een tool voor proeflezen, een chatbot voor klantenservice en een slimme assistent voor bedrijfsautomatisering. Elk project biedt hands-on ervaring met FastAPI, Python, Ollama en REST API’s, zodat je full-stack AI-integratie onder de knie krijgt.\nJe leert ook hoe je realtime gegevens ophaalt en verwerkt via API’s—perfect voor iedereen die AI-toepassingen wil bouwen die actuele informatie analyseren. Je ontwikkelt onder meer een realtime nieuwssamenvatter, een AI-gestuurde financiële rapportanalyzer en een tool die sollicitaties automatisch beoordeelt.\nAan het einde van deze cursus heb je meerdere AI-projecten gebouwd die full-stack ontwikkeling, tekstanalyse, natuurlijke taalbegrip, chatbotontwikkeling, automatisering en toepassingen met grote taalmodellen omvatten. Je zult vol vertrouwen AI-modellen kunnen implementeren en integreren in productierijpe applicaties.\nOf je nu een ontwikkelaar, data scientist, ondernemer, onderzoeker of AI-liefhebber bent—deze cursus voorziet je van de vaardigheden om AI-modellen effectief toe te passen. Je krijgt hands-on ervaring met het bouwen van AI-webapps, het integreren van NLP-modellen en het automatiseren van taken met slimme tools.\nBen je klaar om jouw AI-ontwikkelvaardigheden naar een hoger niveau te tillen en innovatieve AI-toepassingen te bouwen? Dan is dit de perfecte cursus voor jou!",
      "target_audience": [
        "Studenten & Zelflerenden – Geïnteresseerd in AI maar geen idee waar te beginnen? Deze cursus vereist geen ervaring en begeleidt je stap voor stap.",
        "Startup-oprichters & AI-innovators – Wil je AI-gedreven producten bouwen? Deze cursus geeft je praktijkprojecten om je AI-reis te starten.",
        "Data-analisten & Onderzoekers – Inzichten halen uit juridische documenten of klantrecensies? Leer grote tekstdatasets analyseren met AI.",
        "Techondernemers & Productmanagers – AI-apps nodig voor je bedrijf? Leer chatbots, content generators en automatiseringstools bouwen.",
        "AI & Machine Learning Enthousiastelingen – Werk met modellen zoals LLaMA 3, Mistral, Mixtral, CodeLlama en DeepSeek-R1. Krijg hands-on ervaring met model deployment.",
        "Ontwikkelaars & Programmeurs – AI integreren in je webapps of tools? Leer hoe je met Python en FastAPI full-stack AI-toepassingen bouwt."
      ]
    },
    {
      "title": "ChatGPT引爆职场新视界转型从容不迷茫",
      "url": "https://www.udemy.com/course/chatgpt-s/",
      "bio": "人工智能赋能职业生涯",
      "objectives": [
        "1.通过GPT来了解所在行业动态、找到职业机会",
        "2.学会如何制定可行的职业转型计划",
        "3.写好简历，通过模拟面试积累实战经验",
        "4.掌握转型的软技能，为转型准备"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲",
          "引入讲解"
        ],
        "课程内容": [
          "GPT助力你捕捉职业转型先机，8招实用指南",
          "职场通关攻略：GPT打磨简历+模拟面试实战指南",
          "职场转型必看：3招使用技能分享"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "零基础"
      ],
      "description": "随着人工智能技术的发展，ChatGPT成为我们接触AI技术最简单、直接的工具。ChatGPT惊人的潜力赋能工作，将大大提升效率。如何在人工智能工具的助力下做好职业规划、捕捉转型的先机？\n为此，三节课邀请了具有多次转型经验的林珍老师带来本次课程。\n本课程围绕ChatGPT在职业生涯不同阶段的应用展开，从前期的了解行业动态来取得转型优势、到简历打磨与模拟面试，以及专门介绍了转型的软技能。学习了本门课程，你将学会如何制定可行的职业转型计划，提前余留好更多的时间，为转型做前置的准备。打磨简历，在求职时能更自信、更容易面试上心仪的岗位。",
      "target_audience": [
        "1.想换工作或者职业的人",
        "2.刚踏入职场的新人",
        "3.职场老手"
      ]
    },
    {
      "title": "Python大数据分析与机器学习商业案例实战",
      "url": "https://www.udemy.com/course/python-gp/",
      "bio": "机器学习算法精讲·商业实践",
      "objectives": [
        "在一周内快速入门目前最火的人工智能编程语言",
        "提升工作效率",
        "培养数据化思维",
        "机器学习算法精讲·商业实践"
      ],
      "course_content": {},
      "requirements": [
        "对Python感兴趣的人"
      ],
      "description": "本课程是《Python金融大数据挖掘与分析》系列课的第8版块(番外篇)，机器学习是人工智能的基石，这一版块将主要讲解机器学习的基础知识点，包括线性回归模型、逻辑回归模型与决策树模型，并通过客户价值回归预测模型，客户流失预警模型，客户违约预测模型等实际商业案例来巩固相关知识点。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。\n课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利\n人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课\n公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位\n提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，\n您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "对Python感兴趣的零基础同学 各个专业的大学生 企业乐于提高自己的员工 终身学习者 对数据分析感兴趣的朋友"
      ]
    },
    {
      "title": "基于机器学习的电商网站支付欺诈识别",
      "url": "https://www.udemy.com/course/clsamdlk/",
      "bio": "大数据算法实战",
      "objectives": [
        "1.了解什么是CRISP-DM",
        "2.了解CRISP-DM工作流程",
        "3.掌握CRISP-DM实操步骤",
        "4.通过基于机器学习的电商网站支付欺诈识别案例，掌握基于CRISP-DM的数据挖掘实操"
      ],
      "course_content": {},
      "requirements": [
        "具备一定编程能力，会用Python"
      ],
      "description": "本门课程，我们特别邀请到历任数据科学家、高级数据与应用科学家、策略运营专家的张宇晖老师，与你讲解一个非常贴近实际工作情况和完整的数据挖掘项目：基于机器学习的电商网站支付欺诈识别。我们将首先了解什么是CRISP-DM标准流程，并进一步遵循标准流程CRISP-DM开展具体的数据挖掘任务，通过案例来加深对整个数据挖掘工作开展的全流程。本堂课程的主要教学目标是帮助你了解具体数据整理、可视化、建模技术在实际工作过程中使用的灵活性、以及它们是如何组合到一起来处理一个实际数据挖掘项目的\n\n\n本节课程是由授课老师与三节课合作制作的。在此，要特别感谢老师的辛苦付出！经历了课程立项、设计、开发中的众多环节，我们才能最终为你呈现现在的这门课程。无论是授课老师还是三节课团队，都希望这门课程能够让你有所收获，希望同学们结合个人工作情况，学以致用。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "1.数据分析方向从业者",
        "2.想要提升数据分析能力的互联网从业者",
        "3.对大数据分析感兴趣的学习者"
      ]
    },
    {
      "title": "从零起步实战SLAM",
      "url": "https://www.udemy.com/course/slam-wkm/",
      "bio": "通过数学、论文、项目全方位实战SLAM",
      "objectives": [
        "掌握SLAM常用数学基础理论/编程调试经验/第三方库使用相关方法",
        "掌握单目/双目/RGB-D相机原理及成像模型等方法原理",
        "掌握从头到尾掌握一个完整的SLAM系统构建过程",
        "提升学员SLAM算法技术应用能力"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "SLAM概览与系统环境配置",
          "SLAM中的基础",
          "李群与李代数",
          "相机成像及常用视觉传感器",
          "最小二乘法",
          "视觉里程计",
          "多视觉几何",
          "视觉里程计中的位姿估计方法",
          "非线性优化",
          "回环检测与重建"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "有编程经验"
      ],
      "description": "本课程侧重如下几点:\n1.从零开始学习视觉SLAM技术，打牢基础，深入理解算法,提升C++编程能力，全面掌握slam核心技术;\n2.通过掌握SLAM常用数学基础理论/编程调试经验/第三方库使用、单目/双目/RGB-D相机原理及成像模型、多视角立体几何原理、特征点法及直接法相机位姿估计方法、非线性优化方法，以及三维重建、回环检测的一般方法，从头到尾掌握一个完整的SLAM系统构建过程。\n全面帮助学员掌握SLAM的知识技术，尤其提升学员技术的实战应用能力",
      "target_audience": [
        "适合初中级企业SLAM算法工程师",
        "适合初中级企业SLAM视觉算法工程师",
        "适合企业感知、SLAM算法及算法专家"
      ]
    },
    {
      "title": "ChatGPT Crash Course for Beginners in Hindi",
      "url": "https://www.udemy.com/course/chatgpt-crash-course-for-beginners-in-hindi/",
      "bio": "Learn ChatGPT in Hindi, Open AI, Artificial Intelligence, Machine Learning, Prompt Engineering",
      "objectives": [
        "Introduction of ChatGPT",
        "Basics of ChatGPT",
        "How to navigate ChatGPT",
        "Different Case studies"
      ],
      "course_content": {
        "Introduction": [
          "Introduction and Basics of ChatGPT",
          "How to Navigate ChatGPT"
        ],
        "ChatGPT Prompts - Different Case studies": [
          "Case study 1 - Applying for a Job",
          "Case study 2 - Making a diet plan for weight loss",
          "Case study 3 - Writing a YouTube script",
          "Case study 4 - Writing a Blog post",
          "Case study 5 - Making a Food recipe"
        ],
        "Conclusion": [
          "Conclusion"
        ]
      },
      "requirements": [
        "Laptop/ PC/ Mobile phone",
        "Good Internet connection",
        "Basic knowledge of Hindi Language"
      ],
      "description": "Welcome to the ChatGPT Crash Course in Hindi on Udemy!\nAre you ready to unlock the power of ChatGPT and take your conversational AI skills to the next level? Look no further! Our comprehensive and hands-on \"ChatGPT Crash Course in Hindi\" is designed just for you.\nCourse Overview: In this course, you'll embark on an exciting journey to master ChatGPT, one of the most advanced language models developed by OpenAI. Whether you're a developer, student, or tech enthusiast, this course is your gateway to understanding and implementing ChatGPT in Hindi.\nWhat You'll Learn:\nIntroduction to ChatGPT: Understand the fundamentals and architecture of ChatGPT\nHow to navigate ChatGPT: Learn how to navigate ChatGPT\nPractical Applications: Discover real-world applications and case studies of ChatGPT in Hindi\nOptimizing Performance: Learn tips and tricks to optimize ChatGPT for efficient and responsive interactions\nWhy This Course?\nLanguage Accessibility: The entire course is conducted in Hindi, ensuring that you grasp every concept with clarity\nHands-On Experience: Gain practical experience through coding exercises and projects\nExpert Guidance: Benefit from insights and tips from experienced instructors well-versed in ChatGPT\nCommunity Support: Connect with fellow learners through forums and discussions for a collaborative learning experience\nWho Is This Course For?\nDevelopers and programmers interested in natural language processing\nStudents aiming to enhance their AI and machine learning skills\nEntrepreneurs looking to integrate conversational AI into their projects\nAnyone curious about the potential of ChatGPT in Hindi applications\nEnroll Now: Don't miss out on this opportunity to master ChatGPT in Hindi! Enroll now to access high-quality video lectures, downloadable resources, and a vibrant people eager to learn alongside you. Let's revolutionize the world of conversational AI together!\nReady to get started? Click the \"Enroll Now\" button and let the ChatGPT Crash Course in Hindi be your guide to unleashing the power of language models.",
      "target_audience": [
        "Anyone who wants to learn ChatGPT in Hindi Language"
      ]
    },
    {
      "title": "Menguasai Fundamental Data Science",
      "url": "https://www.udemy.com/course/belajar-data-science/",
      "bio": "Mulai belajar data science yang sedang sangat dibutuhkan saat ini dan jadi seorang data scientist",
      "objectives": [
        "Mampu Menguasai Fundamental Data Science",
        "Mengetahui penggunaan Numpy",
        "Mampu mengolah data menggunakan Pandas",
        "Mampu memvisualisasikan Data menggunakan Seaborn/Matplotlib"
      ],
      "course_content": {
        "Fundamental Data Science": [
          "Introduction of Google Collab",
          "Shell Commands",
          "Magics",
          "Documentation",
          "Markdown",
          "Intoduction to Numpy",
          "Properties",
          "Membuat Array Numpy",
          "Shape and Operation",
          "Indexing",
          "Mathematics",
          "Pandas Series",
          "Pandas DataFrame",
          "Exploring DataFrame",
          "Filtering",
          "Grouping",
          "Sorting",
          "Histogram Using Categorical Value",
          "Histogram Using Numerical Value",
          "Boxplot",
          "Lineplot",
          "Scatter Plot",
          "Data Preprocessing",
          "Data Visualization"
        ]
      },
      "requirements": [
        "Tidak perlu basic data science"
      ],
      "description": "Menurut Jokowi, Data adalah jenis kekayaan baru. Saat ini data adalah new oil, bahkan lebih berharga dari minyak. Data yang valid menjadi salah satu kunci pembangunan,\nOleh karena itu pengolahan data itu menjadi skill yang sangat penting untuk membantu pengambilan sebuah keputusan dalam bidang apapun.\nMisalnya saja dalam dunia bisnis, dimana data yang diolah dengan baik dapat memaksimalkan keuntungan yang bisa didapatkan.\n\n\nJika Anda ingin sukses di tengah perkembangan zaman hari ini, Anda perlu mempelajari tren. Dengan mengumpulkan dan menganalisis data yang menjadi pusat perhatian Anda, Anda dapat menentukan berbagai jalur dan cara untuk bisa mencapai target dengan hasil yang baik. Segala sesuatu kini bergantung pada data; baik pemerintah, perusahaan multinasional sampai usaha kecil dan menengah. Banyak perusahaan dan organisasi menginvestasikan dana yang besar untuk merekrut orang-orang terbaik yang bisa memformulasikan strategi bisnis yang lebih baik menggunakan data yang sudah dikumpulkan bertahun-tahun. Menguasai keterampilan analisis data ini akan menjamin Anda untuk bisa memiliki karier global di jalur cepat. Kini bayangkan bahwa Anda berada di tengah-tengah segala tren ini dan menjadi orang pertama yang dicari oleh mereka? Inilah yang harus membuat Anda termotivasi untuk belajar data science.\n\n\nMaka dari itu Coding Studio membuat kursus data science with fundamental menggunakan python, di kursus online ini kamu akan belajar dasar-dasar data science yang mempersiapkan kamu untuk belajar skill Data Science dari nol.\n\n\nKenapa Harus Belajar Fundamental Data Science?\nMenjadi profesi paling banyak dicari oleh industri saat ini, karena talent yang menguasai data science masih sedikit\nMempersiapkan skill untuk tren di masa depan, dimana data akan semakin berlimpah\nMendapatkan dasar-dasar untuk belajar data science yang lebih dalam\n\n\nYuk belajar data science sekarang bareng Coding Studio !",
      "target_audience": [
        "Pelajar",
        "Mahasiswa",
        "Programmer",
        "Data Scientist",
        "Akademisi"
      ]
    },
    {
      "title": "【R超入門】速習！初めてのデータ分析と基礎操作",
      "url": "https://www.udemy.com/course/r_quickstart/",
      "bio": "最短でRの基礎を効率良く学ぶことができます！",
      "objectives": [
        "完全初心者でも最短でRの基礎をマスターできる",
        "Rの基本的な文法をこのコース１つでおさえることができる",
        "演習問題を通して基礎的なRのコーディングスキルが身に付く",
        "実務で使える簡単なデータ分析ができるようになる",
        "実務で求められるレベルのイメージがつく"
      ],
      "course_content": {
        "はじめに": [
          "はじめに（※必ず視聴してください）",
          "Udemyのシステムについて",
          "ChatGPTを使ったエラーの解決方法について",
          "本コースの取り組み方について"
        ],
        "Rの基礎と環境構築": [
          "イントロ",
          "Rとは",
          "Rの環境構築（GoogleColab）",
          "本コースで使用するデータセットの読み込み",
          "Rを使った四則演算",
          "出力(print)",
          "コメントアウト",
          "パッケージとライブラリ",
          "演習①",
          "演習①解答例"
        ],
        "データの読み込みと管理": [
          "イントロ",
          "データの読み込み",
          "データの参照",
          "データの追加と変更",
          "データの保存と書き出し",
          "データの削除",
          "演習②",
          "演習②解答例"
        ],
        "データの型と構造の理解": [
          "イントロ",
          "データ型の確認",
          "データ型と構造の基本",
          "Rデータの構造",
          "演習③",
          "演習③解答例"
        ],
        "集計関数とデータ操作": [
          "イントロ",
          "基本的な集計関数",
          "dplyr特有の関数",
          "演習④",
          "演習④解答例"
        ],
        "データの整理": [
          "イントロ",
          "パイプ演算子",
          "データのクリーニング",
          "データのフィルタリングと抽出",
          "データの変換と集計",
          "データの並び替えと変更",
          "データの結合",
          "演習⑤",
          "演習⑤解答例"
        ],
        "データの可視化": [
          "イントロ",
          "基本のプロット",
          "グラフに日本語を表示させる方法",
          "グラフのカスタマイズ",
          "複数データのプロット",
          "棒グラフの作成",
          "ヒストグラムの作成",
          "箱ひげ図の作成",
          "散布図の作成",
          "演習⑥",
          "演習⑥解答例"
        ],
        "（応用）制御構造と自作関数": [
          "イントロ",
          "条件分岐",
          "ループ処理",
          "関数の応用",
          "演習⑦",
          "演習⑦解答例"
        ],
        "応用演習問題": [
          "イントロ",
          "【問題】顧客データのフィルタリングと集計",
          "【解答例】顧客データのフィルタリングと集計",
          "【問題】欠損値の処理",
          "【解答例】欠損値の処理",
          "【問題】売上データの可視化",
          "【解答例】売上データの可視化",
          "【問題】商品カテゴリごとの売上分析",
          "【解答例】商品カテゴリごとの売上分析",
          "【問題】顧客のロイヤリティ分析",
          "【解答例】顧客のロイヤリティ分析",
          "【問題】複数のデータセットの結合",
          "【解答例】複数のデータセットの結合",
          "【問題】販促キャンペーンの効果測定",
          "【解答例】販促キャンペーンの効果測定",
          "【問題】店舗ごとの売上データ分析",
          "【解答例】店舗ごとの売上データ分析",
          "【問題】時系列データのトレンド分析",
          "【解答例】時系列データのトレンド分析",
          "【問題】商品ごとの売上ランキング",
          "【解答例】商品ごとの売上ランキング"
        ],
        "終わりに": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "インターネットに接続できる環境が必要です。難しい設定などは一切必要ありませんのでご安心ください。"
      ],
      "description": "「Rを学んでみたいけど、何から手を付ければいいかわからない…」\n「いろいろ試してみたけれど、なかなか成果が実感できない…」\n\n\nそんなお悩みをお持ちではありませんか？\n\n\nこのコースは、R初心者のあなたが短期間で効率よく基礎を習得できる実践的な入門講座です。\n\n\n【このコースの特徴】\n短期間で学べる: 忙しい方でも取り組みやすいよう、Rの基本操作をコンパクトにまとめ、効率的に学べる内容になっています。\n無駄を省いたシンプルな学び: 初心者に本当に必要な内容だけに絞り、初めてでも迷わず進められます。\n豊富な演習問題: 理論だけでなく、実際に手を動かしてRの操作を体感しながら学べるため、実践力がしっかり身につきます。\nステップアップの道筋も明確: コース修了後も、次に学ぶべき内容やステップがわかるガイダンスが付いています。\n\n\nこの講座は、Rの基礎操作をしっかりと学び、データ分析の最初の一歩を踏み出すために設計されています。プログラミングやデータ分析に不安を感じている方でも、簡単に取り組めるように構成されているので安心してください。\n\n\n「Rは難しそう…」と思っていたあなたも、この講座を通じてスムーズにRの操作を学び、実際に使えるスキルを習得することができます。実務にすぐに応用できる力を身につけ、データ分析の第一歩を踏み出しましょう！\n\n\n※本コースでは環境構築が不要なGoogleColabを使用します。",
      "target_audience": [
        "データ分析に興味があるプログラミング未経験者。",
        "初めてR言語を勉強する方。"
      ]
    },
    {
      "title": "Machine Learning with Python [ Arabic ]",
      "url": "https://www.udemy.com/course/machine-learning-with-python-arabic/",
      "bio": "Learn the Fundamentals of Machine Learning, Data Processing, and Key Algorithms Like Clustering, Regression, SVM, .etc",
      "objectives": [
        "المقدمة: فهم أساسيات التعلم الآلي ومجالات تطبيقه.",
        "التجميع (Clustering): تقسيم البيانات إلى مجموعات ذات خصائص متشابهة.",
        "الانحدار (Regression): استخدام البيانات للتنبؤ بالقيم المستقبلية.",
        "دعم الآلات الشعاعية (SVM): تصنيف البيانات وتحليلها بطرق دقيقة.",
        "شجرة القرار (Decision Trees): بناء نماذج لاتخاذ القرارات بناءً على البيانات.",
        "الخوارزميات الجينية (Genetic Algorithms): حل المشكلات باستخدام استراتيجيات مستوحاة من الطبيعة."
      ],
      "course_content": {
        "Introduction مقدمة": [
          "Introduction",
          "What is Machine Learning",
          "متى بدأ الذكاء الاصطناعي وكيف تتطور",
          "الفرق بين تعليم الذكاء الاصطناعي وتعليم الاله والتعلم العميق",
          "مصطلحات مهمة",
          "فرط التعلم Overfitting",
          "انواع تعليم الاله",
          "خطوات بناء النماذج الاساسية"
        ],
        "(Clustering) التجميع": [
          "Clustering",
          "K-Means Algorithm",
          "K-Means Example",
          "K-Means Python Example",
          "K-Menas Advantages and Disadvantages",
          "Gaussian Mixture Models GMM",
          "GMM Maths Formula",
          "GMM Example",
          "GMM Python Example",
          "GMM using Model",
          "GMM Advantages and Limitations",
          "Hierarchical",
          "Hierarchical Example",
          "Hierarchical Example Python",
          "Hierarchical Advantages and Limitations",
          "DBSCAN",
          "DBSCAN Example",
          "DBSCAN Python Example",
          "DBSCAN Advantages and Limitations",
          "Summary"
        ],
        "(Regression) الانحدار": [
          "Regression",
          "Linear and NonLinear Regression",
          "MSE and R2",
          "Logistic Regression",
          "Quantile Regression",
          "Regularization in Regression",
          "Regression Python Example"
        ],
        "(SVM) دعم الآلات الشعاعية": [
          "Support Vector Machine SMV",
          "SVM in Regression",
          "SVR",
          "Confusion Matrix",
          "SMV Python Example"
        ],
        "(Decision Trees) شجرة القرار": [
          "Decision Trees",
          "Decision Trees - Maths Foundations",
          "Decision Trees - Classification Example",
          "Decision Trees - Regression Example"
        ],
        "(Genetic Algorithms) الخوارزميات الجينية": [
          "Genetic Algorithm الخوارزمية الجينية",
          "Genetic Algorithm Main Steps",
          "Genetic Algorithm Example"
        ]
      },
      "requirements": [
        "مقدمة في البرمجة: معرفة أولية بأي لغة برمجة (يفضل Python) ستجعل التطبيق العملي أسهل.",
        "الرغبة في التعلم: أهم شيء هو الحماس لتعلم الذكاء الاصطناعي والتفاعل مع المحتوى!"
      ],
      "description": "هل ترغب في تعلم التعلم الآلي من الصفر وحتى احتراف الخوارزميات المتقدمة؟ سواء كنت طالبًا، مطور برمجيات، أو محلل بيانات، فهذه الدورة مصممة لتأخذ بيدك خطوة بخطوة في عالم الذكاء الاصطناعي.\nفي هذه الدورة، ستتعرف على الأسس الرياضية والمنطقية للتعلم الآلي، بالإضافة إلى التطبيق العملي باستخدام لغة Python. سنبدأ بفهم المفاهيم الأساسية، ثم ننتقل إلى تطبيق الخوارزميات العملية على بيانات حقيقية، مما يمكنك من بناء مشاريع ذكاء اصطناعي خاصة بك.\nما الذي ستتعلمه في هذه الدورة؟\nفهم أساسيات التعلم الآلي وأنواعه المختلفة (التعلم الموجه، غير الموجه، والتعلم المعزز)\nاستكشاف طرق معالجة البيانات، مثل التنظيف، التحليل، والتعامل مع القيم المفقودة\nتطبيق الخوارزميات الأساسية مثل:\nالتجميع (Clustering) – تصنيف البيانات إلى مجموعات متشابهة\nالانحدار (Regression) – توقع القيم المستقبلية بناءً على البيانات\nدعم الآلات الشعاعية (SVM) – تصنيف وتحليل البيانات بشكل دقيق\nشجرة القرار (Decision Trees) – اتخاذ القرارات بناءً على المعلومات المتاحة\nالخوارزميات الجينية (Genetic Algorithms) – محاكاة التطور الطبيعي لحل المشكلات\nاستخدام مكتبات Python مثل:\nNumPy و Pandas لمعالجة البيانات\nMatplotlib و Seaborn لإنشاء الرسوم البيانية\nScikit-learn لتطبيق خوارزميات التعلم الآلي\nتنفيذ مشاريع عملية مثل:\nتحليل البيانات والتنبؤ بالنتائج\nبناء نماذج تعلم آلي لاكتشاف الأنماط في البيانات\nتطبيق التعلم الآلي على مشكلات واقعية\nلمن هذه الدورة؟\nالمبتدئون الذين يرغبون في تعلم الذكاء الاصطناعي من الصفر\nمحللو البيانات الذين يريدون تعزيز مهاراتهم بالتعلم الآلي\nالمطورون الذين يسعون لاستخدام الذكاء الاصطناعي في مشاريعهم\nأي شخص لديه فضول حول كيفية استخدام البيانات لاتخاذ قرارات ذكية\nمتطلبات الدورة\nلا توجد متطلبات برمجية متقدمة، ولكن يفضل توفر معرفة أساسية بالرياضيات (الجبر والإحصاء)، وفهم بسيط لمفاهيم البرمجة (يفضل Python، ولكن سيتم شرح الأساسيات)، بالإضافة إلى الرغبة في التعلم.\nلماذا تختار هذه الدورة؟\nمحتوى شامل يغطي الجوانب النظرية والعملية\nمشاريع تطبيقية حقيقية لتعزيز الفهم\nشرح مبسط وسهل حتى للمبتدئين\nتمارين واختبارات لضمان استيعاب المفاهيم\nانضم الآن وابدأ رحلتك في تعلم الذكاء الاصطناعي والتعلم الآلي.",
      "target_audience": [
        "المبتدئون في مجال الذكاء الاصطناعي والتعلم الآلي.",
        "محللو البيانات الذين يرغبون في تعزيز مهاراتهم في التعلم الآلي.",
        "مطورو البرمجيات المهتمون بتطبيق تقنيات الذكاء الاصطناعي في مشاريعهم.",
        "أي شخص لديه فضول لمعرفة كيفية استخدام البيانات لاتخاذ قرارات ذكية."
      ]
    },
    {
      "title": "AI时代Python量化交易实战：ChatGPT让量化交易插上翅膀",
      "url": "https://www.udemy.com/course/aipythonchatgpt/",
      "bio": "使用ChatGPT、文心一言、Claude和Gemini等AIGC工具为量化交易赋能",
      "objectives": [
        "学习到量化交易的基本知识和分析方法,包括技术分析、基本面分析等",
        "掌握Python在金融领域的数据分析和策略回测的应用技能",
        "了解常见的量化交易策略模板,学习使用ChatGPT等AI工具辅助量化决策",
        "掌握金融数据获取、清洗、分析、建模、策略回测的完整实战流程",
        "通过案例实践,加深对策略应用及Python编程的理解,提高实际解决问题的能力",
        "接触新兴的人工智能和机器学习在量化交易领域的应用前沿"
      ],
      "course_content": {
        "ChatGPT、Python和量化交易概述": [
          "ChatGPT的应用领域",
          "Python编程在量化交易中的重要性和优势",
          "ChatGPT、Python和量化交易的结合价值和应用前"
        ],
        "量化交易Python语言基础": [
          "Python解释器（**本节可以下载所有课件）",
          "IDE工具（**本节可以下载所有代码）",
          "标识符",
          "关键字",
          "变量明",
          "2.4.4语句",
          "Python代码块",
          "2.4.6 模块",
          "数据类型",
          "运算符",
          "分支语句",
          "循环语句",
          "跳转语句",
          "2.7 序列",
          "2.8 集合",
          "2.9 字典",
          "字符串类型",
          "2.11 函数"
        ],
        "Python量化基础工具库": [
          "NumPy库",
          "创建数组",
          "二维数组",
          "数组的属性",
          "三维数组",
          "访问数组",
          "Pandas库",
          "Series数据结构",
          "DataFrame数据结构",
          "创建DataFrame对象",
          "访问DataFrame数据",
          "【案例】：从CSV文件读取货币供应量数据",
          "【案例】：从Excel文件读取货币供应量数据",
          "【案例】：从数据库读取苹果股票数据"
        ],
        "量化交易可视化库": [
          "量化交易可视化库",
          "使用Matplotlib绘制图表",
          "绘制折线图",
          "绘制柱状图",
          "绘制饼状图",
          "绘制散点图",
          "【案例】：绘制贵州茅台股票OHLC折线图",
          "绘制K线图",
          "【案例】：绘制贵州茅台股票K线图",
          "使用Seaborn绘制图表",
          "箱线图",
          "小提琴图",
          "Dist图",
          "线性回归图",
          "热力图"
        ],
        "数据采集与分析": [
          "数据采集概述",
          "使用urllib爬取静态网页数据",
          "【案例】：爬取纳斯达克股票数据",
          "解析数据",
          "【案例】：解析纳斯达克股票数据",
          "使用Selenium爬取动态网页数据",
          "【案例】：爬取搜狐证券贵州茅台股票数据",
          "【案例】：使用Selenium解析HTML数据",
          "API调用采集数据",
          "使用TushareAPI采集数据",
          "【案例】：使用Tushare API获取贵州茅台股票数据",
          "数据清洗和预处理",
          "【案例】：使用ChatGPT辅助分析股票数据",
          "【案例】：处理股票数据缺失值",
          "【案例】：处理股票数据类型不一致",
          "【案例】：处理股票数据异常值",
          "统计分析",
          "【案例】：股票行业相关性分析",
          "统计描述和摘要",
          "【案例】：苹果股票数据统计描述和摘要分析"
        ],
        "量化交易基础": [
          "量化交易概述",
          "技术分析",
          "基本面分析",
          "ChatGPT辅助技术分析",
          "【案例】：利用ChatGPT对000001.SZ股票进行技术分析",
          "ChatGPT辅助基本面分析",
          "【案例】：利用ChatGPT对某上市公司股票公告解析",
          "量化交易策略的概述"
        ],
        "ChatGPT与量化交易结合": [
          "ChatGPT在市场情报分析中的应用",
          "【案例】：利用ChatGPT对“央行发布降息25个基点”消息的分析",
          "【案例】：利用ChatGPT对“重磅项目获得批复，股价大涨20%”消息的分析",
          "【案例】：ChatGPT预测某城市商业地产市场面临调整",
          "【案例】：ChatGPT用于预测“新能源汽车补贴退坡”的影响",
          "【案例】：猛龙科技获大单，ChatGPT提出交易决策建议",
          "【案例】：某新能源概念股获多项利好，ChatGPT交易建议"
        ],
        "趋势跟踪策略": [
          "趋势跟踪策略概述",
          "趋势跟踪和交易决策中一些主要概念",
          "使用移动平均线进行分析",
          "使用ChatGPT辅助趋势跟踪策略决策过程",
          "【案例】：使用ChatGPT辅助股票移动平均线策略分析",
          "K线图",
          "合并K线图和移动平均线图",
          "初始策略规则",
          "绘制价格和信号图表",
          "ChatGPT辅助回测"
        ],
        "动量策略": [
          "动量策略概述",
          "相对强弱指标",
          "使用ChatGPT辅助动量策略决策过程",
          "【案例】：使用ChatGPT辅助贵州茅台股票价格和RSI交易信号分析",
          "RSI指标计算",
          "RSI指标曲线",
          "交易信号生成",
          "可视化分析"
        ],
        "海龟交易策略": [
          "海龟交易策略概述",
          "使用ChatGPT辅助实施海龟交易策略过程",
          "数据获取和准备数据",
          "编写海龟交易策略程序",
          "可视化分析",
          "ChatGPT辅助结果化分析"
        ]
      },
      "requirements": [
        "具体使用ChatGPT的上网环境"
      ],
      "description": "一、ChatGPT、Python和量化交易概述\n1.1 ChatGPT的应用领域\n1.2 Python编程在量化交易中的重要性和优势\n1.3 ChatGPT、Python结合带给量化交易的价值和应用前景\n\n\n二、量化交易Python语言基础\n2.1 Python解释器\n2.2 IDE工具\n2.3 第一个Python程序\n2.4 Python语法基础\n2.5 数据类型与运算符\n2.6 控制语句\n2.7 序列\n2.8 集合\n2.9 字典\n2.10 字符串类型\n2.11 函数\n2.12 文件操作\n2.13 异常处理\n2.14 多线程\n\n\n三、Python量化基础工具库\n3.1 NumPy库\n3.2 创建数组\n3.3 二维数组\n3.4 创建二维数组更多方式\n3.5 数组的属性\n3.6 数组的轴\n3.7 三维数组\n3.8 访问数组\n3.9 Pandas库\n3.10 Series数据结构\n3.11 DataFrame数据结构\n3.12 访问DataFrame数据\n3.13 读写数据\n\n\n四、量化交易可视化库\n4.1 量化交易可视化库\n4.2 使用Matplotlib绘制图表\n4.3 K线图\n4.4 使用Seaborn绘制图表\n\n\n五、数据采集与分析\n5.1 数据采集概述\n5.2 网页数据采集\n5.3 解析数据\n5.4 使用API调用采集数据\n5.5 数据清洗和预处理\n5.6 统计分析\n\n\n六、量化交易基础\n6.1 量化交易概述\n6.2 金融市场和交易品种概述\n6.3 技术分析和基本面分析基础\n6.4 量化交易策略概述\n\n\n七、ChatGPT与量化交易结合\n7.1 ChatGPT在市场情报分析中的应用\n7.2 使用ChatGPT进行市场预测和趋势识别\n7.3 ChatGPT在交易决策支持中的应用\n\n\n八、趋势跟踪策略\n8.1 趋势跟踪策略概述\n8.2 使用ChatGPT辅助趋势跟踪策略决策过程\n8.3 案例:使用ChatGPT辅助股票移动平均线策略分析\n\n\n九、动量策略\n9.1 动量策略概述\n9.2 相对强弱指标\n9.3 使用ChatGPT辅助动量策略决策过程\n9.4 案例:使用ChatGPT辅助贵州茅台股票价格和RSI交易信号分析\n\n\n十、海龟交易策略\n10.1 海龟交易策略概述\n10.2 使用ChatGPT辅助实施海龟交易策略\n10.3 案例:使用ChatGPT辅助实施海龟交易策略(以中石油为例)\n\n\n十一、高频交易策略\n11.1 高频交易策略概述\n11.2 高频交易策略中的主要概念\n11.3 使用ChatGPT辅助实施高频交易策略过程\n11.4 案例2:基于价差的高频交易策略实施过程\n11.5 案例3:打造自己的高频交易系统\n\n\n十二、套利策略\n12.1 套利策略中的主要概念\n12.2 使用ChatGPT辅助实施套利策略\n12.3 案例1:股票A和跨市场套利\n12.4 案例2:利用美元与欧元汇率差异来套利\n12.5 案例3:同行业相对值套利策略\n12.6 案例4:中国石油和中国石化配对交易套利过程\n\n\n十三、机器学习策略\n13.1 机器学习策略中的主要概念\n13.2 机器学习策略分类\n13.3 分类策略",
      "target_audience": [
        "从事金融、投资工作的初中级从业者",
        "有志于量化系统开发的专业人员",
        "想学习Python在金融领域应用的程序员",
        "希望结合AI技术进行量化分析的人员"
      ]
    },
    {
      "title": "Programmation Réseau : Création et Dissimulation",
      "url": "https://www.udemy.com/course/programmation-reseau-creation-et-dissimulation/",
      "bio": "Apprenez les sockets, la gestion des erreurs, la capture d'images webcam, et le chiffrement des données en Python.",
      "objectives": [
        "Maîtriser les bases des réseaux et la bibliothèque socket pour établir des connexions et communiquer entre appareils",
        "Développer des compétences pour transmettre et traiter des commandes via des réseaux en utilisant des sockets",
        "Apprendre à développer un terminal qui permet de récupérer et afficher des images en direct d'une caméra.",
        "Concevoir et implémenter une bibliothèque vidéo réutilisable pour différents programmes",
        "Comprendre et appliquer des techniques de chiffrement pour sécuriser les données échangées sur le réseau",
        "Apprendre à masquer et sécuriser le code source, puis compiler les programmes en exécutables pour une utilisation efficaces sur la machine cible."
      ],
      "course_content": {
        "INTRODUCTION AU SOCKETS EN PYTHON": [
          "Introduction au sockets en Python,connexions réseaux et ses protocoles"
        ],
        "BACKDOOR : CONSTRUIRE ET CONNECTER NOS PROGRAMMES": [
          "ETABLIR UNE CONNEXION",
          "CHAT INTERPOSEE: ENVOI ET RECEPTION DE NOS DONNEES"
        ],
        "BACKDOOR : CONSTRUCTION DE NOTRE TERMINAL DE COMMANDE": [
          "RECUPERATION INFORMATIONS SYSTEME",
          "CONSTRUCTION DE NOTRE TERMINAL DE COMMANDE",
          "GESTION TAILLE DE NOS DONNEES ET CHANGEMENT DE REPERTOIRE"
        ],
        "EXERCICES CONSOLIDATION DE NOS CONNAISSANCES": [
          "PARENTHESE EXERCICES",
          "PARENTHESE EXERCICES"
        ],
        "INTRODUCTION SUR LA COMMUNICATION ASYNCHRONE ET LES THREADS EN PYTHON": [
          "INTRODUCTION SUR LA COMMUNICATION ASYNCHRONE ET LES THREADS EN PYTHON",
          "RECUPERATION ET TRAITMENT D'IMAGES",
          "RECUPERATION TRAITEMENT ET ENVOI D'IMAGES",
          "ETAPE 3:SYNCHRONISATION,EVENEMENTS ET THEADS EN ACTION"
        ],
        "PARENTHESE EXERCICE": [
          "GESTION DES EXECPTIONS"
        ],
        "INTRODUCTION AUX CHIFFREMENT EN PYTHON": [
          "INTRODUCTION AU CHIFFREMENT AVEC PYTHON",
          "OBSCURCISSEMENT DE NOS DONNEES",
          "CHIFFREMENT DE NOS DONNEES",
          "DISSIMULTAION :ENTRE CYBERSECURITER ET CONTOURNEMENT"
        ],
        "PARENTHESE EXERCICES": [
          "MOT DE PASSE"
        ],
        "PROGRAMME EVOLUTIF : PROPOSITION FONCTIONALITES ET EXPLICATION": [
          "A VOS PROJETS !"
        ]
      },
      "requirements": [
        "Connaissance Python"
      ],
      "description": "Dans ce cours, nous allons entreprendre un projet passionnant qui combine plusieurs aspects de la programmation réseau, la manipulation de la webcam, et la sécurité informatique. Nous commencerons par la création d'une application client-serveur en Python, où nous établirons des sockets pour permettre l'échange de données entre un serveur et une cible. Cette application nous permettra d'exécuter des commandes à distance via un terminal, offrant une compréhension pratique des concepts fondamentaux de la communication réseau.\nNous nous concentrerons également sur la gestion des erreurs et la maintenance des connexions pour assurer une communication continue et robuste. Nous mettrons en place des mécanismes pour détecter et gérer les interruptions de connexion et les commandes non reçues, garantissant ainsi une reconnexion automatique en cas de problème.\nEnsuite, nous élargirons notre application pour inclure la capture d'images à partir de la webcam de la cible. Le serveur pourra prendre des photos à distance, ajoutant des capacités de surveillance à notre projet.\nEnfin, nous aborderons le chiffrement de notre communication pour assurer la confidentialité et la sécurité des données échangées entre le serveur et la cible. En combinant ces techniques, ce cours fournira une expérience pratique et complète en matière de programmation réseau, de manipulation de la webcam et de sécurité informatique.\nPour couronner le tout, nous explorerons des astuces de dissimulation pour une backdoor. Nous apprendrons à intégrer des techniques de camouflage afin de rendre notre application moins détectable, tout en respectant les aspects éthiques et légaux de la sécurité informatique. Cela préparera les étudiants à comprendre les méthodes utilisées pour échapper à la détection et à développer des applications de communication sécurisées et fiables.",
      "target_audience": [
        "DEVELOPPEURS PYTHON DEBUTANTS INTERSEES PAR LA SCIENCE DES DONNEES"
      ]
    },
    {
      "title": "Pelatihan Data Analyst Sertifikasi BNSP",
      "url": "https://www.udemy.com/course/pelatihan-data-analyst-sertifikasi-bnsp/",
      "bio": "Persiapkan Keterampilan Data Analyst yang Diperlukan untuk Mendapatkan Sertifikasi BNSP",
      "objectives": [
        "Memahami Peran dan Alur Kerja Seorang Data Analyst",
        "Menggunakan Microsoft Excel untuk Analisis Dasar dan Pembersihan Data",
        "Menerapkan Python untuk Analisis Data Sederhana",
        "Membuat Dashboard Interaktif Menggunakan Business Intelligence Tools",
        "Menyusun Laporan Analisis Data dan Mempersiapkan Sertifikasi BNSP"
      ],
      "course_content": {
        "Introduction": [
          "Perkenalan & Overview Materi Data Analyst",
          "Alur Kerja, Skillset, dan Tools Seorang Data Analyst",
          "Apa itu Data & Jenis Data",
          "Basis Data",
          "Tipe-Tipe Data",
          "Data LifeCycle",
          "SQL & DBMS",
          "Google Colab",
          "Kuis Sesi 1"
        ],
        "Excel Basic Function": [
          "Mempelajari Interface, Format Angka, dan Tabel di Dalam Excel",
          "Mengetahui dan Praktik Fungsi Dasar (SUM, MAX, MIN, AVERAGE)",
          "Mempelajari dan Praktik Fungsi Logika",
          "Data Cleaning Menggunakan Excel",
          "Visualisasi Data dengan Excel",
          "Kuis Sesi 2"
        ],
        "Python Basic Function": [
          "Introduction and Basic Dataframe (Pandas)",
          "Exploring DataFrame",
          "Basic Statistic",
          "Handling Outlier",
          "Visualisasi Data dengan Python",
          "Kuis Sesi 3"
        ],
        "Business Intelligence": [
          "Membuat Business Intelligence dengan Mengenal Looker Studio Google",
          "Menghubungkan Database dengan Looker Studio",
          "Membuat Visualisasi Data",
          "Membuat Dashboard Interaktif",
          "Kuis Sesi 4"
        ],
        "Menyusun Laporan Hasil Analisis": [
          "Menyusun Laporan Hasil Analisis",
          "Tips & Trik Mengikuti Ujian BNSP",
          "Practice Test Pelatihan Data Analyst"
        ]
      },
      "requirements": [
        "Memiliki pemahaman dasar olah data menggunakan Excel"
      ],
      "description": "Ingin mendapatkan sertifikasi resmi sebagai Data Analyst dari BNSP, tapi masih bingung harus mulai dari mana? Kelas ini dirancang khusus untuk pemula maupun profesional yang ingin memperdalam keahlian analisis data dan mempersiapkan diri menghadapi uji kompetensi BNSP.\nDalam kelas ini, Anda akan mempelajari fondasi penting seorang Data Analyst — mulai dari pemahaman tentang data, alur kerja, hingga berbagai tools yang digunakan. Kita akan mulai dengan memahami konsep data, jenis-jenisnya, serta bagaimana data disimpan dan dikelola melalui basis data dan SQL. Anda juga akan diperkenalkan dengan Google Colab sebagai platform pemrograman berbasis cloud yang user-friendly.\nSelain itu, Anda akan mempelajari pengolahan data menggunakan Excel, visualisasi data yang menarik dan informatif, dasar-dasar Python untuk analisis data, Business Intelligence menggunakan Google Looker Studio, dan tips khusus dalam menghadapi ujian sertifikasi BNSP.\n\n\nMengapa Belajar Bersama Kami?\nPelatihan Data Analyst untuk Sertifikasi BNSP by YEC CO ID menawarkan beragam fasilitas yang dapat membantu Anda mempersiapkan Sertifikasi BNSP, yaitu sebagai berikut:\nPembelajaran Terstruktur: Pelatihan ini menyediakan kurikulum yang terstruktur dan komprehensif, mencakup semua aspek penting dari analisis data.\nBimbingan Ahli: Anda akan mendapatkan bimbingan dari instruktur yang berpengalaman dan ahli di bidangnya, yang dapat membantu Anda memahami konsep analisis data dengan lebih baik.\nSimulasi Langsung: Pelatihan yang efektif memberikan banyak kesempatan untuk praktik langsung, memungkinkan Anda mengasah keterampilan dan membangun portofolio yang kuat.\nPersiapan Ujian: Pelatihan ini akan mempersiapkan Anda untuk menghadapi ujian sertifikasi BNSP, termasuk pemahaman materi dan kisi-kisi sertifikasi.\nJadi, jika Anda ingin mengembangkan karier atau keterampilan sebagai data analyst, pelatihan ini dapat menjadi jawaban atas keresahan Anda.",
      "target_audience": [
        "Orang yang ingin mengikuti sertifikasi BNSP skema Data Analyst"
      ]
    },
    {
      "title": "오렌지(Orange)를 활용한 코딩 없는 AI 데이터 분석 - Lv.7 시계열 분석과 연관 규칙",
      "url": "https://www.udemy.com/course/maso-ds-orange-onc69/",
      "bio": "복잡한 파이썬(python), 느린 엑셀(excel) 데이터 분석은 이제 그만! 노 코드 분석 도구 Orange로 쉽게 하는 시계열 데이터 분석",
      "objectives": [
        "시계열 데이터의 기본 개념 및 데이터의 특성 이해",
        "시계열 분해를 통한 데이터 패턴 분석",
        "시계열 예측 모델의 기본 원리와 실습",
        "벡터 자기 회귀(VAR) 및 ARIMA 모델 학습"
      ],
      "course_content": {
        "학습 내용 안내": [
          "AAF011 학습 내용 안내"
        ],
        "시계열 데이터의 이해": [
          "AAF021 내년에 제품B는 몇 개 팔릴까- CAGR",
          "AAF022 시계열 데이터의 특징- 시간독립변수와 자기상관성",
          "AAF023 시계열 분해- 추세성, 계절성, 순환성, 백색소음",
          "AAF024 시계열 정상성과 비정상성, 그리고 차분"
        ],
        "시계열 데이터 분석 모델": [
          "AAF031 시계열 분석 모델의 유형- AR과 MA",
          "AAF032 이동평균법을 활용한 시계열 분석"
        ],
        "예측적 시계열 분석과 모델 평가": [
          "AAF041 벡터 자기회귀 모델을 활용한 시계열 분석",
          "AAF042 벡터 자기회귀 모델을 활용한 시계열 분석 – 실습",
          "AAF043 ARIMA 모델과 시계열 예측 능력 평가"
        ],
        "연관성 분석의 이해와 활용": [
          "AAF051 연관성 분석의 이해",
          "AAF052 Apriori 알고리즘과 장바구니 분석",
          "AAF053 연관 규칙 분석을 활용한 맞춤형 추천 시스템"
        ]
      },
      "requirements": [
        "본 강의는 인공지능, 코딩, 또는 엑셀 실력과 같은 선수지식을 요구하지 않습니다. 누구나 쉽게 따라올 수 있도록 기초부터 설명 드립니다. 다만, 이전 단계인 오렌지 강의 Lv.1 또는 Lv.2까지 수강하시면 강의 내용을 더욱 원활하게 이해하실 수 있습니다.",
        "오렌지를 일절 사용해보신 적이 없다면, 강의를 더욱 원활하게 진행하기 위해 기본적인 사용 방법이나 설치 방법을 미리 알아보시는 것을 추천 드립니다.",
        "실습 위주의 강의이기 때문에 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기를 함께 준비해주시면 좋습니다.",
        "또한 Windows OS 기반으로 실습이 진행되므로, Windows 환경에서의 강의 수강을 추천해드립니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n\n\n흔한 강의가 아닙니다\n- 정형 / 비정형 데이터의 주요 차이점, 다양한 형태와 구조 설명\n-기본적인 텍스트 전처리의 원리 설명\n-코퍼스, 토큰화, 품사 태깅과 같은 텍스트 마이닝 기법\n- 텍스트 클러스터링 및 TF-IDF 기법을 실제 비즈니스 데이터 예측과 분류에 활용\n- 이미지 데이터 추출의 기초 개념부터 비전 모델, 이미지 분류 및 클러스터링 기법\n\n\n강의 교재 파일 + 개념 설명\n+ 실제 비즈니스 분석에 활용 가능한 풍부한 텍스트 및 이미지 실습 자료\n+ Orange를 활용한 비정형 데이터 분석을 통해 비즈니스 예측과 분류 분석\n\n\n비정형 데이터 분석은 오늘날 많은 기업들이 직면한 중요한 도전 과제입니다.\nOrange를 활용해 비정형 데이터를 손쉽게 분석하고 새로운 통찰력을 발견하세요\n빠르게 변하는 직무 역량과 인재 트렌드 속에서, 데이터 분석 능력은 필수 역량입니다\n\n\n성과로 이어지는 Orange 데이터 분석 강의\n\n\n데이터 분석? 더 이상 전문가들만의 영역이 아닙니다\n비정형 데이터의 개념과 예시, 그리고 관련된 기법들을 이해하기 쉽게 배울 수 있습니다!\n\n\n-복잡한 코딩 기술 없이 누구나 Orange를 통해 비정형 데이터에서 유의미한 결론 이끌어내기\n-텍스트 & 이미지 분석의 기본적인 프로세스부터 결과물까지 한 눈에\n-텍스트와 이미지 데이터를 실무에서 어떻게 다루고 분석하는지에 대한 직관적인 설명\n\n\n비정형 데이터를 활용한 비즈니스 분석은 더 이상 먼 미래의 일이 아닙니다.\n이 강의로, 실질적인 문제 해결을 위해 비정형 데이터를 활용할 수 있는 첫 걸음을 내딛으세요!\n\n\nSTEP 1. 입문자도 접근하기 쉽게, 비정형 데이터의 기초 개념 및 분석 방법 학습\n비정형 데이터의 기본적인 유형, 구조, 형태를 기점으로 이러한 데이터를 분석할 때 발생하는 고유한 도전 과제 이해\n\n\nSTEP 2. 텍스트 마이닝의 기초부터 시작하는 실습\n텍스트 데이터를 전처리하는 과정에서 필요한 핵심 기법들을 배우고, 텍스트 데이터를 컴퓨터가 이해할 수 있는 형태로 변환하는 방법 실습\n\n\nSTEP 3. 텍스트 분류 및 예측을 위한 다양한 기법 학습\n텍스트 데이터의 군집 분석과 분류 기법을 활용해 비즈니스 문제 해결에 적용할 수 있는 실습 진행\n\n\nSTEP 4. 이미지 데이터 분석의 기초부터 응용까지 실습\n이미지 데이터를 다루는 기본 원리를 이해하고 이를 활용해 이미지 분류 및 예측을 실무에 활용하는 방법 습득\n\n\n강의 수강 이후 당신은,\n\n\n+ 비정형 데이터 분석 기법을 통한 분석 역량 강화\n비정형 데이터 분석을 통해 텍스트 및 이미지 데이터의 핵심 패턴을 찾아내는 능력\n+ 텍스트 마이닝 기법을 활용 전처리 및 데이터 활용\n코퍼스 생성, 워드 임베딩 벡터, 중요 키워드 추출, 감성 분석 등 텍스트 데이터 활용\n+ 이미지 데이터를 활용한 예측과 분류 능력 향상\n이미지 임베딩 알고리즘 이해, 이미지 클러스터링과 등 이미지 데이터 분석 기초 능력\n+ 다양한 비정형 데이터 실무 활용 기초 역량 강화\n고객 피드백 이해, 분류와 제품 품질 관리와 같이 실제 비즈니스 분석에 활용 가능\n\n\n\n\n\n\n[ 강 사 소 개 ]\n\n\n최 정 아\n現 마소캠퍼스 콘텐츠랩 이사\n연세대학교 경영학 석사\nYSCEC의 웹마스터로서 연세-게이오(日)-릿쿄(日)-푸단(中) 대학의 YKLP 사업에 초기부터 합류해 성공적으로 론칭시킨 국제 원격교육 전문가입니다. 이후 플레이포럼 편집장으로 자리를 옮겨 MAU 238만 명의 커뮤니티를 7년간 운영하면서 최대 900만 뷰를 달성한 디지털 콘텐츠를 제작했습니다. 언어학, 정보학, 경영학 학위를 소지한 다재다능한 디지털마케팅 전문가로서 데이터를 활용해 디지털 플랫폼에서 최고의 퍼포먼스를 이뤄냈습니다. 효과적인 데이터 마케팅 방법을 다룬 도서를 다수 출간하여 모두 경제경영 분야 베스트셀러에 오른 검증된 지식을 공유하고 있습니다.",
      "target_audience": [
        "실무적 데이터 분석 기술을 강화하고자 하는 분",
        "어려운 코딩 없이 데이터 분석 능력을 향상하고자 하는 분",
        "시계열 데이터 및 연관성 분석을 실용적으로 활용하고자 하는 분",
        "엑셀의 한계를 느끼고 더 간단한 고급 분석 도구를 원하는 분"
      ]
    },
    {
      "title": "构建数据信任之桥-数据质量管理方法深度解读",
      "url": "https://www.udemy.com/course/ctumnxww/",
      "bio": "掌握数据质量管理方法，提升数据质量",
      "objectives": [
        "理解数据质量的概念和原则",
        "识别并解决常见的数据质量问题",
        "识别并解决常见的数据质量问题",
        "帮助学员在实际业务中应用数据质量管理技能"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "第1章": [
          "数据质量利益相关方"
        ],
        "第2章": [
          "数据质量的评价维度"
        ],
        "第3章": [
          "数据质量问题原因分析"
        ],
        "第4章": [
          "数据质量管理实施方法"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "适合对数据质量及数据管理有一定基础的学员"
      ],
      "description": "数据质量（Data Quality）是指数据适合使用的程度，满足特定用户期望的程度，数据质量并不是追求100%，而是满足组织业务，用户的使用需求。 数据质量管理（Data Quality Management）涉及对数据生命周期的每个阶段。\n本课程通过讲解数据质量管理过程中的相关流程与方法，提升学员在实际业务中的数据质量管理能力和方法应用能力。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "适合企业技术及资产管理者",
        "适合企业数据管理相关从业人员",
        "适合对数据质量及数据管理感兴趣的专家学者"
      ]
    },
    {
      "title": "ChatGPT应用指南：个人商业变现",
      "url": "https://www.udemy.com/course/chatgpt-wt/",
      "bio": "如何利用ChatGPT打造个人商业模式",
      "objectives": [
        "全面认识、了解ChatGPT",
        "通过使用ChatGPT，快速掌握市场分析与选择",
        "通过ChatGPT实际操作的学习，优化企业获利策略，提升竞争力",
        "学习实战案例，增强ChatGPT使用技能"
      ],
      "course_content": {
        "课程导读": [
          "课程简介"
        ],
        "人工智能的前世今生": [
          "人工智能的前世今生",
          "什么是AIGC？",
          "人工智能在各行业的应用前景和发展机会",
          "普通人如何利用AI赚钱的8大方法"
        ],
        "什么是ChatGPT？": [
          "什么是ChatGPT？",
          "ChatGPT注册登录",
          "如何使用新版ChatGPT4",
          "ChatGPT调教攻略： 调教5步法、5个提示词模板",
          "100个ChatGPT的角色扮演"
        ],
        "ChatGPT的引应用": [
          "用ChatGPT写小说",
          "用ChatGPT做闲鱼无货源电商副业赚钱",
          "用ChatGPT做自媒体-写小红书爆款文案",
          "用ChatGPT做中视频计划-电影解说类",
          "ChatGPT+剪映5分钟出大片",
          "用ChatGPT生成短视频脚本+做数字人",
          "用ChatGPT做跨境电商"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "对ChatGPT有兴趣，或有业务需求"
      ],
      "description": "什么是AIGC？什么是ChatGPT？如何使用新版ChatGPT？ChatGPT能够帮我赚钱吗？ChatGPT对我个人商业变现是否有帮助？ChatGPT的到来对我个人/企业是否有帮助……\n\n为了回答以上问题，三节课邀请玩转AI时代自媒体运营的500强企业内训讲师陈榕榕老师带来本次课程。\n\n只要你对ChatGPT有兴趣，或有业务需求，这门课程都能带你全面认识、了解ChatGPT，通过实操新版ChatGPT，实现个人快速掌握市场分析与选择，企业优化获利策略，提升竞争力。",
      "target_audience": [
        "有志于实现新媒体技术发展需求的企业和业务管理者",
        "期望通过ChatGPT提升专业技能和拓宽业务领域",
        "想要通过ChatGPT获利的销售、运营及市场营销人士兴趣，或有业务需求"
      ]
    },
    {
      "title": "오렌지(Orange)를 활용한 코딩 없는 AI 데이터 분석 - Lv.2 데이터 전처리와 시각화",
      "url": "https://www.udemy.com/course/maso-ds-orange-onc44/",
      "bio": "복잡한 파이썬(python), 느린 엑셀(excel) 데이터 분석은 이제 그만! 노 코드 분석 도구 Orange로 쉽게 하는 데이터 전처리와 시각화",
      "objectives": [
        "노코딩 인공지능 데이터분석 도구 Orange를 활용한 데이터 전처리 기법",
        "데이터 클렌징과 결측값 처리 방법",
        "데이터 변환, 인코딩, 스케일링 기술",
        "데이터 시각화 기법과 그리드 설정 방법"
      ],
      "course_content": {
        "학습 내용 안내": [
          "AAB012 학습 내용 안내"
        ],
        "피처 엔지니어링 필수 상식": [
          "AAB021 피처 엔지니어링 프로세스",
          "AAB022 피처 엔지니어링의 핵심 단계"
        ],
        "데이터 클렌징": [
          "AAB031 분석에 용이한 데이터 형식",
          "AAB032 멜팅을 활용한 구조적 오류 해결",
          "AAB033 중복된 데이터 제거",
          "AAB034 데이터 셔플링과 정제",
          "AAB035 모든 인스턴스에 같은 규칙 적용하기"
        ],
        "결측값 처리": [
          "AAB041 결측값 처리",
          "AAB042 결측값 처리 실습"
        ],
        "이상값 처리": [
          "AAB051 이상치 처리",
          "AAB052 이상치 처리 실습"
        ],
        "데이터 변환과 인코딩": [
          "AAB061 데이터 변환 기법",
          "AAB062 이산화",
          "AAB063 연속화와 데이터 인코딩"
        ],
        "데이터 스케일링": [
          "AAB071 데이터 정규화와 표준화 스케일링"
        ],
        "데이터 전처리 파이프라인과 샘플링": [
          "AAB081 데이터 전처리 파이프라인 구성하기",
          "AAB082 파이썬 스크립트 연동",
          "AAB083 과대표집과 과소표집"
        ],
        "그룹화와 계산 수식으로 피처 생성": [
          "AAB091 새로운 클래스와 계산열 만들기",
          "AAB092 그룹화로 다양한 집계표 만들기",
          "AAB093 수식으로 새로운 변수 생성"
        ],
        "효과적인 시각화 방법과 그리드": [
          "AAB101 시각화 목적에 알맞은 차트",
          "AAB102 시각화 위젯의 그리드 설정"
        ]
      },
      "requirements": [
        "본 강의는 인공지능에 관심이 생긴 누구나 바로 들어 실무에 활용할 수 있는 역량 제공을 목표로 설계된 강의이나, 오렌지(Orange)를 활용한 코딩 없는 AI 데이터 분석 - Lv.1 데이터 마이닝의 첫 걸음 강의를 먼저 수강하시는 것을 추천드립니다.",
        "실습 위주의 강의이기 때문에 강의 화면과 실습 화면을 분리할 수 있는 듀얼 모니터 또는 여분 기기를 함께 준비해주시면 좋습니다.",
        "오렌지는 무료로 배포되고 있는 소프트웨어이며, 다운로드부터 설치까지 하나하나 가르쳐 드리기 때문에 누구나 손쉽게 인공지능 데이터분석 환경을 구축 가능합니다. Portable 버전을 사용하면 외부 인터넷 연결 없이도 사용 가능하여, 보안 수준이 높은 근무 환경에서도 사용 가능합니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n누구나 할 수 있는 AI 데이터 분석\n개발자, 개발자 하지만 모두 같은 개발자가 아닌 것 알고 계셨나요?\n개발자에도 프론트엔드, 백엔드, 여러 분야의 엔지니어, 그리고 데이터 사이언스 개발자 등\n여러 가지 분야가 존재합니다.\n당연히 각 분야의 수요나 입문 난이도, 그에 따른 평균 연봉의 차이가 존재합니다.\n\n\n그 중에서도 특별한 것은 데이터 사이언스, 특히 머신 러닝/딥러닝 분야를 꼽을 수 있습니다.\n기본적인 코딩 역량에 더해 데이터 사이언스 지식과 인공 지능 역량까지 필요로 하여,\n각종 개발자 대상 조사에서 상위권의 연봉 수준을 차지하고 있습니다.\n물론 연봉 수준이 높다는 것은 일반적으로 아무나 할 수 있다는 뜻이 아닙니다.\n\n\n그러나, 사실은 누구나 인공지능 데이터 분석을 쉽게 수행할 수 있습니다.\n약간의 데이터사이언스 지식과 데이터를 다루는 역량,\n실무에 필요한 분석 기법과 적절한 도구 활용 능력이 있다면\n개발자 없이도 고급 인공지능 데이터 분석을 수행할 수 있습니다.\n\n\n필요한 게 너무 많아 보이신다구요?\n그래서 마소캠퍼스의 이번 강의에서 모든 것을 한번에 준비했습니다.\n이번에 소개할 강의의 사용 툴은 “Orange”입니다.\n누구나 쉽게 분석 데이터를 가져와 만지고, 인공 지능 분석까지 수행할 수 있습니다.\n개발자가 해내는 것 이상으로 자유롭게 의미 있는 분석을 해내는 오렌지는\n무료 도구이면서 각종 네트워크 보안 환경에서도 문제 없이 쓸 수 있는 도구입니다.\n\n\n데이터사이언스 개발자가 부러우셨나요?\n개발 역량이 없이도, 노코딩 도구 오렌지와\n마소캠퍼스에서 제공하는 데이터 분석 역량과 함께라면\n머신 러닝 개발자의 연봉도 꿈이 아닙니다.\n마소캠퍼스의 “코딩 없는 AI 데이터 분석” 과정의 시작인 이 강의에서\n여러분도 몰랐던 여러분의 가능성을 마음껏 펼쳐보시길 바랍니다.\n\n\n\n\n강의 특징\n본 강의는 피처 엔지니어링과 데이터 시각화에 필요한 모든 기법을 코딩 없이 배울 수 있는 구조로 설계되었습니다.\n제대로 된 데이터 분석을 위한 복잡한 코딩 장벽을 허물고, 누구나 쉽게 데이터 시각화 시작할 수 있도록 돕습니다.\n\n\n입문자부터 전문가까지 사용하는 오렌지!\nOrange는 데이터 사이언스 및 머신 러닝 분야 초보자에게 이상적인 도구로,\n복잡한 코딩 없이 데이터 시각화 기능을 시각적이고 직관적으로 수행 가능합니다.\n\n\n\n\n데이터 전처리와 피처 엔지니어링의 개념 소개\nOrange를 활용해 데이터를 쉬운 방법으로 분석하기 편한 형태로 가공하고,\n데이터셋에서 의미 있는 인사이트를 추출할 수 있도록 지원하는 기능을 학습합니다.\n\n\n\n\n결측치와 이상치의 식별 및 처리 방법\n엑셀 데이터부터 여러 가지 형식의 파일, 웹 문서 등에서 데이터를 불러와\n데이터 분석이 의미가 있도록 준비하는 방법을 배워 효율적인 분석이 가능합니다.\n\n\n\n\n여러 가지 고급 데이터 시각화 기법\n데이터 시각화의 기본 개념부터 실무에 가장 많이 쓰이는 대표적인 기법을 활용하여\n실전 사례 시각화를 통한 데이터 사이언티스트 업무를 경험할 수 있습니다.\n\n\n코딩없는 AI 데이터 분석 강의를 듣고 나면\n마소캠퍼스의 코딩 없는 AI 데이터 분석 lv.2 데이터 전처리와 시각화 입문 강의는\n데이터 시각화의 입문자부터 현직자까지 모든 분들에게 적합합니다.\n데이터 전처리와 피처 엔지니어링의 기본 프로세스 이해\n데이터 클렌징 기법을 통한 분석 준비\n결측치 처리 및 이상치 검출 및 처리 방법 습득\n데이터 변환, 인코딩 및 스케일링 기술 활용\n오렌지와 함께 데이터 사이언스 전문 역량을 키워 보세요.\n더 이상 코딩도, 데이터 분석도 겁내지 마세요!\n\n\n-\n\n\n[ 강 사 소 개 ]\n\n\n최 정 아\n現 마소캠퍼스 콘텐츠랩 이사\n연세대학교 경영학 석사\nYSCEC의 웹마스터로서 연세-게이오(日)-릿쿄(日)-푸단(中) 대학의 YKLP 사업에 초기부터 합류해 성공적으로 론칭시킨 국제 원격교육 전문가입니다. 이후 플레이포럼 편집장으로 자리를 옮겨 MAU 238만 명의 커뮤니티를 7년간 운영하면서 최대 900만 뷰를 달성한 디지털 콘텐츠를 제작했습니다. 언어학, 정보학, 경영학 학위를 소지한 다재다능한 디지털마케팅 전문가로서 데이터를 활용해 디지털 플랫폼에서 최고의 퍼포먼스를 이뤄냈습니다. 효과적인 데이터 마케팅 방법을 다룬 도서를 다수 출간하여 모두 경제경영 분야 베스트셀러에 오른 검증된 지식을 공유하고 있습니다.",
      "target_audience": [
        "데이터 시각화를 통해 분석 결과를 명확하게 전달하고자 하는 분들",
        "복잡한 코딩 없이 고급 역량인 시각화를 마스터하고 싶으신",
        "데이터 전처리와 피처 엔지니어링을 간단히 수행하고 싶은 분들",
        "엑셀의 한계를 느끼고 더 간단한 고급 분석 도구를 원하는 분들"
      ]
    },
    {
      "title": "通过数据分析搭建反作弊SOP",
      "url": "https://www.udemy.com/course/sop-kpvw/",
      "bio": "以贝壳找房打击虚假带看为例",
      "objectives": [
        "1.了解互联网作弊产生的背景、现况及危害",
        "2.掌握反作弊目标及关键结果指标",
        "3.梳理现有问题并规划解决方案",
        "4.搭建指标评估体系，实现业务跑通及数据验证"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "一、 了解作弊与反作弊": [
          "1.了解作弊与反作弊"
        ],
        "二、 定义作弊场景": [
          "1.定义作弊场景"
        ],
        "三、 明确目标及关键结果": [
          "1.明确目标及关键结果"
        ],
        "四、 问题现况及解决方案": [
          "1.问题现况",
          "2.解决方案"
        ],
        "五、 业务跑通及数据验证": [
          "1.评估体系搭建",
          "2.试跑效果评估",
          "3.迭代效果评估"
        ],
        "课程回顾": [
          "回顾总结",
          "课后寄语"
        ]
      },
      "requirements": [
        "具有一定的数据分析经验，掌握基本数据分析技能"
      ],
      "description": "作为数据分析反作弊方向的从业新人，如何快速上手业务？数据分析师在反作弊领域如何设计解决方案？想要进入反作弊相关岗位的互联网从业者如何建立行业认知？为了解答这些问题，三节课特别邀请了拥有5年数据分析经验，对数据分析及商业模式有深入理解的王玛丽老师，与你分享她在数据分析搭建反作弊SOP上的思考与总结。课程从基本概念入手，对不同的互联网作弊场景进行解读，从不同场景下的应对方法帮助你进阶思考，希望课程中方法论的总结，能帮助你解决互联网反作弊的问题，并不断迭代优化出更适合你自己的方法论。\n本节课程是由授课老师与三节课合作制作的。在此，要特别感谢老师的辛苦付出！经历了课程立项、设计、开发中的众多环节，我们才能最终为你呈现现在的这门课程。无论是授课老师还是三节课团队，都希望这门课程能够让你有所收获，希望同学们结合个人工作情况，学以致用。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "1. 0-1岁数据分析或反作弊方向从业新人",
        "2. 对反作弊领域感兴趣的数据分析师",
        "3. 有意进入反作弊相关岗位的互联网从业者"
      ]
    },
    {
      "title": "Banco de Dados com MySQL",
      "url": "https://www.udemy.com/course/mysql_database/",
      "bio": "Utilize, projete e administre Bancos de dados Relacionais",
      "objectives": [
        "Gerentes de Projetos",
        "Analistas (financeiro, contabil, controladoria, inteligência de mercado, etc...)",
        "Desenvolvedores",
        "Estudantes de Tecnologia"
      ],
      "course_content": {
        "Conceito I": [
          "Introdução",
          "Introdução ao Banco de",
          "AVISO IMPORTANTE",
          "Instalação do MySQL",
          "Criando BD e Tabelas",
          "CRUD Básico"
        ],
        "Conceitos II": [
          "Operadores Condicionais",
          "Operadores AND e OR",
          "Restrições",
          "Cálculos com SQL",
          "Funções de Agrupamento",
          "Trabalhando com Datas",
          "Trabalhando com Datas",
          "FORMAT / CONCAT",
          "Criando Tabelas Relacionais",
          "JOIN",
          "UNION",
          "CASE",
          "VIEW"
        ],
        "Conceitos III": [
          "DER (Teórica)"
        ],
        "Conceitos IV": [
          "Aviso Importante"
        ]
      },
      "requirements": [
        "Não há pre-requistos, será ensinado do zero"
      ],
      "description": "Dominar o MySQL e conceitos de banco de dados é fundamental em diversas áreas profissionais. Na área de desenvolvimento de software, habilidades em banco de dados permitem a criação de aplicações robustas e escaláveis, possibilitando o armazenamento e recuperação eficiente de dados.\n\n\nEm análise de dados, o conhecimento em MySQL capacita profissionais a gerenciar grandes conjuntos de dados, realizar consultas complexas e extrair insights valiosos para tomada de decisões estratégicas.\n\n\nNa administração de sistemas, o MySQL é amplamente utilizado para gerenciar e otimizar o desempenho de bancos de dados, garantindo a disponibilidade e segurança dos dados armazenados. Além disso, em áreas como segurança da informação, compreender banco de dados é essencial para proteger a integridade e confidencialidade dos dados sensíveis.\n\n\nEm resumo, o conhecimento em MySQL e banco de dados é uma competência versátil e valiosa, com aplicações em uma ampla gama de setores, desde empresas comerciais até organizações sem fins lucrativos e instituições acadêmicas, desempenhando um papel crucial no sucesso e eficiência das operações.\n\n\nCom esse curso você será capaz de utilizar, projetar e administrar banco de dados simples e complexos.\n\n\nEsse curso está dividido em Módulos sendo:\n\n\nConceitos I => Introdução e comandos Básicos\nConceitos II => Evoluindo com SQL\nConceitos III => Projetando Bancos de Dados\nConceitos IV => Comandos Avançados",
      "target_audience": [
        "Desenvolvedores, estudantes, analistas, gerentes que desejam criar conhecimento em banco de dados"
      ]
    },
    {
      "title": "PostgreSQL: Do Zero à Maestria no Backend",
      "url": "https://www.udemy.com/course/postgresql-do-zero-a-maestria-no-backend/",
      "bio": "Aprenda a construir e gerenciar bancos de dados robustos na prática. Desenvolva um projeto financeiro real e domine a ha",
      "objectives": [
        "Postgres",
        "Funções",
        "Views",
        "Montar um banco profissional interagir com o banco da melhor forma e melhores praticas"
      ],
      "course_content": {
        "Instalando e configurando ferramentas": [
          "O que é um banco de dados",
          "Como funciona um banco de dados",
          "Instalando o PostgreSQL"
        ],
        "Criando e entendendo sobre banco": [
          "O projeto",
          "Criando um Banco de Dados",
          "Estrutura de um banco de dados",
          "Atributos e Tipos de Dados",
          "Criando as tabelas do projeto"
        ],
        "Aprendendo sobre os comandos": [
          "O comando INSERT",
          "O comando SELECT",
          "O comando UPDATE",
          "O comando DELETE",
          "Importanto através de planilhas Excel",
          "Restaurando a partir de dumps SQL"
        ],
        "Operadores de busca do SQL": [
          "Uso do LIKE para busca de padrões",
          "Uso do IN para busca de múltiplos valores",
          "Uso do BETWEEN para busca de valores entre intervalos",
          "Uso do LIMIT para limitar a quantidade de valores e criar paginações"
        ],
        "Funções SQL": [
          "Recuperando os valores Mínimo e Máximo",
          "Tirando a Contagem, Média e Soma",
          "Agrupando valores agregados com o GROUP BY"
        ],
        "Unindo tabelas": [
          "Entendendo de vez a Teoria dos Conjuntos",
          "Apelidando tabelas e colunas",
          "Combinando tabelas com o INNER JOIN",
          "Combinando tabelas com o LEFT JOIN",
          "Combinando tabelas com o RIGHT JOIN",
          "Combinando tabelas com o SELF JOIN",
          "Combinando resultados com o UNION",
          "Uso do ANY e ALL juntamente com Sub-SELECT"
        ],
        "Relatórios": [
          "Clientes VIP vs Normais",
          "Saldo por conta e geral",
          "Gastos por categoria",
          "Fluxo de Caixa",
          "Títulos Vencidos (parcelas e soma total)",
          "Títulos futuros (parcelas e soma total)",
          "Maiores devedores e pagadores"
        ],
        "Transações, Funções e Views": [
          "Transações",
          "Funções",
          "Views"
        ],
        "Complementos": [
          "ORMs",
          "Principais bancos de dados do mercado e como trabalhar com cada um",
          "Bancos de dados na nuvem (hospedagem)",
          "Outros tipos de banco de dados (NOSQL)",
          "Se você chegou até aqui parabéns",
          "Trabalhando com Datas como um profissional",
          "Uso do ENUM para normalizar valores"
        ]
      },
      "requirements": [
        "Não é necessário ter experiencia"
      ],
      "description": "Quer se tornar um desenvolvedor backend completo e disputado pelo mercado? Dominar o PostgreSQL, o banco de dados open-source mais avançado do mundo, não é mais um diferencial, é uma necessidade.\nNeste curso, você fará uma jornada completa, saindo do zero absoluto até a maestria em PostgreSQL. Esqueça os tutoriais rasos! Aqui, você vai aprender desde os conceitos fundamentais, como instalar e criar seu primeiro banco, até os comandos mais complexos e poderosos, como JOINs, Sub-Selects e funções de agregação.\nO grande diferencial? Nós aplicaremos tudo isso na construção de um projeto prático de controle financeiro, simulando desafios reais do dia a dia de um desenvolvedor. Ao final, você não apenas entenderá a teoria, mas terá a confiança para modelar, consultar e gerenciar qualquer banco de dados PostgreSQL em suas futuras aplicações. Essa é a habilidade que vai te destacar, abrindo portas para as melhores vagas e projetos de tecnologia do mercado atual.\nIdeal para:\nDesenvolvedores iniciantes que querem construir uma base sólida em bancos de dados.\nProgramadores que já atuam no mercado e precisam dominar o PostgreSQL.\nEstudantes de tecnologia que buscam uma habilidade prática e valorizada.\nDê o passo definitivo para se tornar um especialista em backend. Inscreva-se agora!",
      "target_audience": [
        "Desenvolvedores e DBA"
      ]
    },
    {
      "title": "(PMI-RMP) Simulation Exams",
      "url": "https://www.udemy.com/course/pmi-rmp-simulation-exams/",
      "bio": "دورة الاختبارات التجريبية لشهادة ادارة المخاطر",
      "objectives": [],
      "course_content": {
        "Practice Tests": []
      },
      "requirements": [],
      "description": "Prepare for PMI-RMP® certification with precision and focus. This course is focused on providing you with the essential practice you need to excel in the PMI-RMP exam. With two full-length practice tests, fully aligned with the latest Exam Content outline, you'll have the opportunity to assess your understanding of risk management principles and enhance your exam readiness.\nKey Features:\nTwo Full Practice Tests: Simulate the PMI-RMP exam experience with two comprehensive practice tests, meticulously designed to mirror the actual exam format and level of difficulty. Similar to the original exam, each practice test has 115 questions and 150 minutes to attempt all questions.\nAs per the latest Exam Content Outline, PMBOK® Guide 7th edition, The Process Groups Practice Guide, and the Standard for Risk Management in Portfolios, Programs, and Projects (2019).\nStrategic Questioning: Each question is strategically crafted to assess your knowledge across risk management domains and tasks outlined in the latest PMI-Risk Management professional Exam Content Outline.\nUpdated to include question related to Risk Management on Agile Projects.\nImmediate Feedback: Once you finish the exam, receive the feedback on your performance, allowing you to identify strengths and areas for improvement, maximizing your study efficiency. Explanation is provided for each question which is important to strengthen your concepts.\nNo-frills, No Distractions: This course is designed for those who prefer a straightforward approach. With no videos or additional resources, you can focus solely on honing your exam-taking skills.\nWho Should Enroll:\nPMI-RMP® aspirants seeking targeted exam practice.\nPMP® Aspirants who want to test their concepts if Risk Management.\nWho want to test there knowledge in Risk Management.\nProfessionals with a solid understanding of Risk Management principles.\nIndividuals who prefer a practice-focused learning experience.\nElevate your exam readiness, fine-tune your strategic thinking, and approach the PMI-RMP® exam with confidence. Enroll now and embark on your journey to mastering risk management.\nPMI®, PMI-RMP®, PMP®, and PMBOK® Guide are registered trademarks of the Project Management Institute, Inc.",
      "target_audience": [
        "People who want to pass PMI-RMP exam."
      ]
    },
    {
      "title": "AI工程師必學！Vanna AI Text2SQL 實戰訓練營：打造企業數據分析能力 | 自然語言查詢本地資料庫解決方案",
      "url": "https://www.udemy.com/course/vanna-ai-text2sql/",
      "bio": "深入學習 Vanna AI，實現自然語言轉換為 SQL 查詢，提升數據分析與業務智能能力。",
      "objectives": [
        "掌握 Vanna AI Text2SQL 技術：學員將深入了解 Vanna AI 的 Text2SQL 功能，學習如何將自然語言轉換為 SQL 查詢，從而提升數據查詢的效率和準確性，幫助企業快速獲取數據洞察。",
        "實踐多資料表查詢與數據整合：透過實作練習，學員將能夠掌握如何處理複雜的多資料表查詢，並學習如何將不同數據源整合，進一步提升數據分析的深度和廣度。",
        "應用 Gradio 和 Chainlit 創建自訂介面：學員將學習如何使用 Gradio 和 Chainlit 開發互動性強的數據查詢介面，提升用戶體驗並使數據分析結果更加直觀易懂。",
        "最佳實務與快速部署策略：課程將提供 Vanna AI 的最佳實務，包括安全性管理、性能優化和快速部署方法，幫助學員在實際工作中快速上手，降低項目實施的難度與風險。"
      ],
      "course_content": {
        "介紹": [
          "實作Vanna AI 自然語言轉 SQL 查詢的最快方法",
          "善用 ChatGPT 提升 Vanna AI 查詢質量的策略",
          "Gradio 自訂介面：使用 Vanna AI 進行 Text2SQL 查詢",
          "Chainlit + Vanna AI + 本地數據整合",
          "進階訓練：Vanna AI 的五大必備技巧",
          "Vanna AI 多資料表查詢的實作技巧",
          "從零開始建置銷售數據分析應用服務的最佳實務",
          "建置財務分析應用服務的 Vanna AI Text2SQL 最佳實務",
          "Vanna AI 自選模型與前後端分離設計",
          "使用者驗證與快速生產部署：Vanna AI 的實用指南",
          "Dify_串接VannaAI，實現自然語言呼叫本地數據進行分析對話服務"
        ]
      },
      "requirements": [
        "本課程不需要任何程式撰寫經驗，讓您輕鬆上手，你可以在這裡學到需要的一切，快速掌握 Vanna AI 的強大功能！"
      ],
      "description": "本課程旨在從零開始，全面引導學員掌握 Vanna AI 的 Text2SQL 技術，並將其靈活應用於實際的數據分析和業務智能場景。透過十個精心設計的單元，學員將深入探討 Vanna AI 的原理和功能，學習如何在各種環境中有效部署和運用這項技術。\n課程著重於實踐操作，每個單元都將提供完整的程式碼和範例，確保學員能夠輕鬆實現所學知識，迅速落地應用，並創造出實際價值。\n\n\n誰適合學習本課程：\n數據分析師：希望提升 SQL 能力和數據分析技能的專業人士。\n業務智能專家：需要利用 Vanna AI 提高報告和數據洞察能力的人士。\nIT 和數據工程師：想要掌握最新工具以優化數據處理流程的技術人員。\n學生與學習者：對數據分析和人工智能應用有興趣的初學者或進階學習者。\n企業管理者：希望利用數據分析促進業務決策的管理層人員。\n\n\n以下是課程的10個單元：\n實作Vanna AI 自然語言轉 SQL 查詢的最快方法\n善用 ChatGPT 提升 Vanna AI 查詢質量的策略\nGradio 自訂介面：使用 Vanna AI 進行 Text2SQL 查詢\nChainlit + Vanna AI + 本地數據整合\n進階訓練：Vanna AI 的五大必備技巧\nVanna AI 多資料表查詢的實作技巧\n從零開始建置銷售數據分析應用服務的最佳實務\n建置財務分析應用服務的 Vanna AI Text2SQL 最佳實務\nVanna AI 自選模型與前後端分離設計\n使用者驗證與快速生產部署：Vanna AI 的實用指南\nDify_串接VannaAPI，實現自然語言呼叫本地數據進行分析對話服務",
      "target_audience": [
        "數據分析師：希望提升 SQL 能力和數據分析技能的專業人士。",
        "業務智能專家：需要利用 Vanna AI 提高報告和數據洞察能力的人士。",
        "IT 和數據工程師：想要掌握最新工具以優化數據處理流程的技術人員。",
        "學生與學習者：對數據分析和人工智能應用有興趣的初學者或進階學習者。",
        "企業管理者：希望利用數據分析促進業務決策的管理層人員。"
      ]
    },
    {
      "title": "Data Science & ML avec Python : Le Cours Ultime",
      "url": "https://www.udemy.com/course/data-science-ml-avec-python-le-cours-ultime/",
      "bio": "Apprenez Pandas, NumPy, Scikit-Learn, TensorFlow et Keras pour des projets réels.",
      "objectives": [
        "Comprendre les bases de la science des données et les types de ML (supervisé, non supervisé, renforcement).",
        "Maîtriser statistiques descriptives, probabilités, corrélation, causalité, tests d'hypothèses et A/B testing.",
        "Manipuler et transformer des données avec Python : types, listes, tuples, sets, dictionnaires et compréhensions.",
        "Analyser des données avec Pandas : lire, explorer, nettoyer, filtrer, grouper, agréger et créer des tableaux croisés dynamiques.",
        "Gérer les séries temporelles efficacement avec Pandas pour l'analyse de données chronologiques.",
        "Réaliser des calculs numériques efficaces avec NumPy : arrays, indexation, slicing, opérations mathématiques.",
        "Créer des visualisations de données percutantes avec Matplotlib : lignes, barres, points, histogrammes, boxplots, subplots.",
        "Améliorer les visualisations avec Seaborn : intégration Pandas, pairplot, facetgrid, régressions et heatmaps.",
        "Comprendre les concepts clés de Machine Learning : workflow, sélection de features, overfitting et underfitting.",
        "Appliquer le ML supervisé avec Scikit-Learn : régression linéaire, arbres de décision, forêts aléatoires, SVM, ANN.",
        "Gérer la sélection de features et la réduction de dimensionnalité pour optimiser les modèles ML.",
        "Maîtriser les données déséquilibrées et les techniques de classification avancées.",
        "Comparer et évaluer des modèles ML avec des métriques pertinentes et des méthodes d'ensemble.",
        "Optimiser les modèles via le réglage des hyperparamètres et la validation croisée (Scikit-Learn).",
        "Appliquer le ML non supervisé : K-Means, clustering hiérarchique, réduction de dimensionnalité.",
        "Détecter les anomalies (outliers) dans les ensembles de données pour améliorer la qualité de l'analyse.",
        "Combiner apprentissage supervisé et non supervisé pour des solutions plus robustes.",
        "Introduire au Deep Learning avec TensorFlow et Keras : modèles séquentiels et fonctionnels.",
        "Comprendre Forward et Backpropagation, et les fonctions d'activation (ReLU, Sigmoid, Softmax).",
        "Réaliser le réglage des hyperparamètres pour le Deep Learning avec Optuna.",
        "Développer des CNNs pour la reconnaissance d'images et des modèles séquentiels (RNN, LSTM, GRU).",
        "Découvrir les GANs et les concepts des modèles génératifs.",
        "Mener un projet de Data Science de A à Z : chargement, nettoyage, visualisation, feature engineering, modélisation ML/DL."
      ],
      "course_content": {
        "Introduction à la Science des Données": [
          "Qu'est-ce que la Science des Données?"
        ],
        "Fondements Statistiques pour la Science des Données": [
          "Statistiques Descriptives : Moyenne, Médiane et Écart Type",
          "Distributions de Probabilités : Distributions Normale et Binomiale",
          "Corrélation et Causalité",
          "Tests d'Hypothèses et Valeurs-p",
          "Tests A/B en Pratique"
        ],
        "Structures et Types de Données en Python": [
          "Types de Données Fondamentaux : Entier, Flottant, Chaîne de Caractères, Booléen",
          "Listes, Tuples, Ensembles et Dictionnaires",
          "Compréhensions de Listes et de Dictionnaires"
        ],
        "Manipulation de Données avec Pandas": [
          "Introduction à Pandas et aux DataFrames",
          "Chargement et Sauvegarde des Données (CSV, Excel, SQL, JSON)",
          "Exploration et Analyse des Données",
          "Nettoyage et Prétraitement des Données (Valeurs manquantes, Doublons)",
          "Tri, Filtrage et Regroupement des Données",
          "Fonctions d'Agrégation",
          "Tableaux Croisés Dynamiques (Pivot Tables)",
          "Fusion et Combinaison de Données",
          "Travailler avec les Séries Temporelles"
        ],
        "Calculs Numériques avec NumPy": [
          "Introduction à NumPy et aux Tableaux (Arrays)",
          "Création de Tableaux",
          "Indexation et Tranchage (Slicing) de Tableaux",
          "Opérations Mathématiques avec NumPy",
          "Broadcasting et Comparaison d'Efficacité"
        ],
        "Visualisation de Données avec Matplotlib": [
          "Introduction à Matplotlib",
          "Diagrammes Linéaires",
          "Diagrammes à Barres",
          "Nuages de Points",
          "Histogrammes",
          "Boîtes à Moustaches (Boxplots)",
          "Sous-Graphiques (Subplots) et Personnalisation des Axes",
          "Visualisations Spécialisées",
          "Personnalisations Avancées"
        ],
        "Visualisation de Données avec Seaborn": [
          "Introduction à Seaborn",
          "Intégration Pandas",
          "Boîtes à Moustaches et Diagrammes en Violon",
          "Pairplot et FacetGrid",
          "Nuages de Points et Diagrammes Linéaires",
          "Histogrammes et Densité",
          "Tracés de Régression et Cartes de Chaleur (Heatmaps)"
        ],
        "Introduction à l'Apprentissage Automatique": [
          "Qu'est-ce que l'Apprentissage Automatique?",
          "Aperçu des Types d'Apprentissage Automatique",
          "Algorithmes d'Apprentissage Automatique",
          "Le Flux de Travail de l'Apprentissage Automatique",
          "Sélection de Caractéristiques (Features) et Préparation des Données",
          "Comprendre le Surapprentissage et le Sous-apprentissage"
        ],
        "Apprentissage Supervisé avec Scikit-Learn": [
          "Introduction à Scikit-Learn",
          "Régression Linéaire et Régression Multiple",
          "Sélection de Caractéristiques et Réduction de Dimensionalité",
          "Réduction de Dimensionalité",
          "Arbres de Décision et Forêts Aléatoires (Random Forest)",
          "Machines à Vecteurs de Support (SVM)",
          "Réseaux de Neurones Artificiels (ANN) dans Scikit-Learn",
          "Données Déséquilibrées et Classification",
          "Comparaison de Modèles et Méthodes d'Ensemble",
          "Réglage des Hyperparamètres et Validation Croisée",
          "Évaluation de Modèles avec des Métriques"
        ],
        "Apprentissage Non Supervisé avec Scikit-Learn": [
          "Introduction à l'Apprentissage Non Supervisé",
          "Clustering K-Means",
          "Clustering Hiérarchique",
          "Réduction de Dimensionalité",
          "Analyse d'Association",
          "Détection d'Anomalies (Détection des Outliers)",
          "Combinaison avec l'Apprentissage Supervisé"
        ]
      },
      "requirements": [
        "Aucune connaissance préalable n'est requise. Je vous guiderai pas à pas à travers chaque concept."
      ],
      "description": "Ce cours utilise l'intelligence artificielle.\nMaîtrisez la science des données — et passez du simple code aux vraies analyses.\nVous en avez assez de ne pas savoir par où commencer avec vos données, de perdre du temps à nettoyer des fichiers CSV, ou de ne pas comprendre pourquoi votre modèle ne fonctionne pas ? Ce cours va vous guider pas à pas — de vos premières lignes de code jusqu’à vos propres modèles prédictifs.\nQue vous soyez débutant en Python ou que vous ayez déjà une base en programmation, ce cours vous transformera en praticien de la Data Science. Vous apprendrez à manipuler, analyser, visualiser et modéliser des données comme un professionnel.\nFini les scripts brouillons, les erreurs incompréhensibles et les heures perdues sur Google. Place à une pratique claire, structurée et efficace de la Data Science.\nCe que vous allez apprendre\nComprendre les bases statistiques essentielles à la science des données\nManipuler efficacement des données avec Pandas et NumPy\nVisualiser des données avec Matplotlib et Seaborn\nConstruire des modèles de Machine Learning avec Scikit-Learn\nCréer des réseaux neuronaux avec TensorFlow et Keras\nMettre en œuvre des projets concrets de bout en bout\nStructure du cours – Ce qui vous attend\n1. Introduction à la Data Science\nQu’est-ce que la science des données, pourquoi est-elle essentielle aujourd’hui, et quelles sont les compétences clés à maîtriser ?\n2. Fondamentaux statistiques pour la Data Science\nApprenez les concepts essentiels : moyenne, écart-type, distributions, corrélation vs causalité, p-valeurs, A/B testing…\n3. Python pour la Data Science\nMaîtrisez les structures de données Python (listes, dictionnaires, ensembles, etc.) et apprenez les techniques modernes comme les compréhensions.\n4. Manipulation de données avec Pandas\nImportation, nettoyage, filtrage, regroupement, fusion… Vous saurez tout sur la préparation des données.\n5. Calculs numériques avec NumPy\nCréez et manipulez des tableaux numériques haute performance, et effectuez des calculs vectorisés.\n6. Visualisation de données\nApprenez à créer des graphiques percutants avec Matplotlib et Seaborn : histogrammes, scatter plots, heatmaps, boxplots, et plus encore.\n7. Machine Learning avec Scikit-Learn\nConstruisez des modèles supervisés et non supervisés, testez-les, optimisez-les et comprenez leurs performances.\n8. Deep Learning avec TensorFlow & Keras\nCréez vos premiers réseaux neuronaux, CNNs, RNNs, et explorez même les GANs pour générer vos propres données.\n9. Projet final : application complète\nUn projet concret où vous mettrez en œuvre tout ce que vous avez appris : nettoyage, visualisation, modélisation et prédiction.\nÀ qui s’adresse ce cours ?\nDébutants en Python curieux de découvrir la science des données\nÉtudiants ou professionnels souhaitant ajouter une compétence recherchée à leur profil\nDéveloppeurs autodidactes voulant structurer leur apprentissage\nToute personne voulant passer de simples analyses Excel à de vraies prédictions basées sur les données\nPrérequis\nAucun ! Vous apprendrez tout étape par étape. Il vous suffit d’un ordinateur, d’une connexion internet, et de votre motivation.\nPourquoi suivre ce cours ?\nApprendre la Data Science, c’est ouvrir la porte à l’un des métiers les plus recherchés au monde. Mais ce cours ne vous enseigne pas seulement des concepts — il vous donne des compétences concrètes et pratiques, avec des outils professionnels, pour que vous puissiez les utiliser dès aujourd’hui.\nAlors, prêt(e) à transformer vos données en décisions ?\nRejoignez-moi dans ce voyage passionnant — et devenez un vrai Data Scientist.\nÀ très vite dans le cours !\n– Mika",
      "target_audience": [
        "Débutants en science des données : Toute personne désireuse d'acquérir une base solide en science des données, même sans expérience préalable en programmation ou en statistiques.",
        "Développeurs Python : Développeurs cherchant à étendre leurs compétences au domaine de la science des données, de l'analyse et du machine learning.",
        "Étudiants et chercheurs : Ceux qui ont besoin de comprendre et d'appliquer les méthodes de science des données pour leurs projets universitaires ou de recherche.",
        "Professionnels en reconversion : Quiconque souhaite se lancer dans une carrière en science des données et maîtriser les outils essentiels du secteur.",
        "Curieux de l'IA et du ML : Toute personne désireuse de comprendre les algorithmes de machine learning et de deep learning et leurs applications concrètes.",
        "Futurs Data Scientists : Ceux qui visent une carrière de Data Scientist et veulent maîtriser les compétences techniques demandées par les entreprises.",
        "Développeurs souhaitant optimiser leurs solutions avec des modèles prédictifs et de l'IA.",
        "Analystes de données et professionnels du BI : Ceux qui souhaitent enrichir leurs compétences en analyse de données avec des techniques avancées et le machine learning."
      ]
    },
    {
      "title": "Statistical Average",
      "url": "https://www.udemy.com/course/statistical-average/",
      "bio": "Learn Statistical Average : Advance",
      "objectives": [
        "Statistical average or Measure of central tendency",
        "Objects and Functions of Statistical Average",
        "Kinds of statistical average",
        "Statistical Series",
        "Mean or Arithmetic Mean or Average",
        "Methods of calculation of mean in various series :",
        "1. Individual series Questions",
        "2. Discrete series Questions",
        "3. continuous series Questions",
        "Median : Meaning of Median",
        "Characteristics of Median",
        "Methods of calculation of Median in various series :",
        "1. Individual Series Questions",
        "2. Discrete series Questions",
        "3. continuous series Questions",
        "Mode : Meaning of Mode",
        "Methods of calculation of Mode in various series :",
        "1. Individual Series Questions",
        "2. Discrete series Questions",
        "3. continuous series Questions",
        "Mean, Median, Mode In One Questions",
        "Partition Values",
        "Quartiles",
        "Decile",
        "PERCENTILE"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Lecture - 2",
          "Lecture - 3",
          "Lecture - 4",
          "Lecture - 5",
          "Lecture - 6",
          "Lecture - 7",
          "Lecture - 8",
          "Lecture - 9",
          "Lecture - 10",
          "Lecture - 11",
          "Lecture - 12",
          "Lecture - 13",
          "Lecture - 14",
          "Lecture - 15",
          "Lecture - 16",
          "Lecture - 17",
          "Lecture - 18"
        ]
      },
      "requirements": [
        "Basic Accounting Knowledge"
      ],
      "description": "Statistical average or Measure of central tendency\nObjects and Functions of Statistical\nKinds of statistical average Average\n(A) Mathematical Average :\n1. Mean/ arithmetic mean\n2. Geometric mean\n3. Harmonic mean\n4. Quadratic mean\n(B) Average of position :\n1. Median\n2. Mode\n(C) Commercial Average :\n1. Moving average\n2. Progressive average\n3. Composite average\nStatistical Series\n1. Individual series : Under this category, every item or values are personally shown differently. Under this category and groups of items and values are not made. Values are presented in accordance to the number of items.\n2. Discrete series : When there are more classes in an investigation and their values are confirm then individual value (items) which are different from each other and are complete, are written and their frequencies are written in their front. There are two columns, in one column value of items and other column, frequency of each item is written.\n3. Continuous series : When data’s are presented on the basis of class intervals, then this series is called continuous series.\nMEAN or Arithmetic Mean or Average : Meaning of Mean\nMethods of calculation of mean in various series\nIndividual Series Question\nDiscreate Series Question\nContinuous Series Question\nMEDIAN : Meaning of Median\nMethods of calculation of Median in various series\nIndividual Series Question\nDiscreate Series Question\nContinuous Series Question\nMODE : Meaning of Mode\nMethods of calculation of Mode in various series\nIndividual Series Question\nDiscreate Series Question\nContinuous Series Question\nPartition Values\nQuartile :\nCalculation of Quartile in individual series\nCalculation of quartile in discrete series\nCalculation of Quartile in Continuous series\nDecile :\nCalculation of Decile in individual series\nCalculation of Decile in discrete series\nCalculation of Decile in Continuous series\nPercentile :\nCalculation of Percentile in individual series\nCalculation of Percentile in discrete series\nCalculation of Percentile in Continuous series",
      "target_audience": [
        "Any Student who pursuing in B,com M,com BBA MBA 11th & 12th Commerce C.A. C.S. and C.M.A."
      ]
    },
    {
      "title": "AI运营实战，10倍速内容生产实现流量翻倍",
      "url": "https://www.udemy.com/course/ai10-hrh/",
      "bio": "ChatGPT实战操盘经验总结",
      "objectives": [
        "1.剖析AI内容生产底层心法",
        "2.“AI+运营”实战场景应用",
        "3.“AI助力”SEO流量翻倍增长",
        "4.运营模型如何结合AI落地"
      ],
      "course_content": {
        "课程导读": [
          "课程简介"
        ],
        "课程内容": [
          "AI+个体，助力超级个体成长",
          "AI创作心法，10倍速内容生产",
          "ChatGPT内容生产心法",
          "ChatGPT内容应用场景",
          "ChatGPT面临的现实挑战",
          "提高网站SEO流量转化技巧",
          "AI+业务模型，运营高阶成长利器"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "1.对AI实战感兴趣，学会使用生产力工具",
        "2.用户增长负责人，低成本项目实战复盘",
        "3.私域运营操盘手，掌握AI创作内容的方法"
      ],
      "description": "当前，AI正在深刻影响我们的世界，劳动密集型公司越来越少，越来越多的超级个体开始出现。大公司开始瘦身，产业开始以人驱动转变为算法和算力驱动。不难看出，AI的出现，进一步拉开人和人的差距，人人都可能会成为提示工程师。这意味着只有尽早通过AI实现内容生产，才能快人一步适应大环境。\n\n为此，三节课邀请了具有10年营销沉淀，拥有线上线下运营经验的胡先务老师带来这门课程。\n\n通过学习本课程，你将准确掌握AI运营实战的关键技能，实现AI与SEO、业务模型的结合，提升业务效率。\n\n\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权,任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "不设限，只要想学总能学会！"
      ]
    },
    {
      "title": "Transformer原理与代码精讲（PyTorch）",
      "url": "https://www.udemy.com/course/transformer-pytorch/",
      "bio": "深度学习新范式",
      "objectives": [
        "学习注意力机制和自注意力机制",
        "掌握Transformer原理",
        "掌握Transformer的Pytorch实现代码",
        "学习利用Transformer进行机器翻译"
      ],
      "course_content": {
        "课程介绍": [
          "课程介绍"
        ],
        "Transformer原理精讲": [
          "注意力机制和自注意力机制",
          "Transformer的架构概述",
          "Transformer Encoder的多头注意力 （Multi-Head Attention）",
          "Transformer Encoder的位置编码（Positional Encoding）",
          "Transformer 残差链接、LayerNorm、FFN",
          "Transformer Decoder",
          "Transformer 训练及性能",
          "Transformer机器翻译工作流程"
        ],
        "Transformer代码精讲（Pytorch）": [
          "安装Pytorch",
          "Transformer的Encoder代码解读",
          "Transformer的Decoder代码解读",
          "Transformer的超参设置代码解读",
          "Transformer的训练示例（人为随机数据）代码解读",
          "Transformer的训练示例(德语-英语机器翻译)代码解读"
        ]
      },
      "requirements": [
        "熟悉python和pytorch"
      ],
      "description": "Transformer发轫于NLP（自然语言处理），并跨界应用到CV（计算机视觉）领域。目前已成为深度学习的新范式，影响力和应用前景巨大。\n本课程对Transformer的原理和PyTorch代码进行精讲，来帮助大家掌握其详细原理和具体实现。\n原理精讲部分包括：注意力机制和自注意力机制、Transformer的架构概述、Encoder的多头注意力（Multi-Head Attention）、Encoder的位置编码（Positional Encoding）、残差链接、层规范化（Layer Normalization）、FFN（Feed Forward Network）、Transformer的训练及性能、Transformer的机器翻译工作流程。\n代码精讲部分使用Jupyter Notebook对Transformer的PyTorch代码进行逐行解读，包括：安装PyTorch、Transformer的Encoder代码解读、Transformer的Decoder代码解读、Transformer的超参设置代码解读、Transformer的训练示例（人为随机数据）代码解读、Transformer的训练示例(德语-英语机器翻译)代码解读。",
      "target_audience": [
        "希望学习Transformer原理与PyTorch实现代码的学员"
      ]
    },
    {
      "title": "家用移动机器人标准解读",
      "url": "https://www.udemy.com/course/tcgivimp/",
      "bio": "解读家用服务机器人系列国家标准，指明机器人研发目标和评价方法",
      "objectives": [
        "解读家用服务机器人系列国家标准",
        "了解机器人研发目标和评价方法",
        "通过学习机器人国标的技术要求和试验方法，掌握家用服务机器人的性能测试方法",
        "具备竞品分析能力"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "第一章 行业发展": [
          "历史演进",
          "行业标准"
        ],
        "第二章家用环境": [
          "房间布局",
          "地面材质"
        ],
        "第三章 性能测试": [
          "运动控制",
          "定位导航",
          "清洁除尘",
          "智能越障",
          "智能避障",
          "电源管理",
          "人机交互"
        ],
        "第四章 安全测试": [
          "电气安全",
          "结构安全",
          "环境安全"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "从事工程师工作的人员"
      ],
      "description": "随着ICT技术不断深化和传统场景的结合，自动化、智能化相融合已经成为ICT技术的下一代浪潮，以工业机器人、服务机器人、自动驾驶等的新一代技术浪潮目前已经方兴未艾，成为又一波热点。而作为次级操作系统的ROS则提供了一系列的调试、仿真工具，能支持激光导航、视觉导航等算法，是切入机器人和自动驾驶技术的重要基石。\n机器人是一个复合型的领域，涉及软件、算法、硬件、结构等诸多方向，是一个理论性和实践性并重的行业，考虑到其复杂性和讲解的循序渐进，整个系列课程将分为三个系列即入门系列、中级系列、高级系列。\n在入门系列中，我们将介绍ROS的基础知识(机器人基础知识、ROS开发环境等)、ROS配置管理(系统架构、参数管理、Launch启动、编译配置以及如何基于源代码开发等)、ROS系统调试（代码调试、可视化调试、消息回放、单元测试等）。\n在中级系列中，我们将围绕机器人仿真涉及的URDF机器人模型、Gazebo仿真环境、坐标变换、运动控制等展开介绍，并随着课程的深入，将会深度使用RVIZ、Gazebo等仿真和调试工具。\n在高级系列中，我们将着眼于机器人的国家标准解读、人工智能框架及算法，分享机器人开发涉及的运动控制、SLAM、语音交互、计算机视觉等。逐层递进，为大家一层层剥开机器人的神秘面纱。\n本系列课程的特色在于：\n1、从基础知识、编译管理、通信机制、系统调试等4个方面循序渐进、逐步深化，知识覆盖全面，便于深度认知；\n2、从基本理论、源码解读、工程示例等领域开展ROS系统入门知识的深度介绍和分析，源于工程实践，利于快速上手；\n3、基于全新的环境Ubuntu 20.04、ROS Noetic、Gazebo 11、GMapping、Cartographer、tensorFlow 2.*、OpenCV 4.*等讲解，紧跟时代前沿。\n整个系列的课程将会逐步开发并上线，三个系列是一个逐步深入、环环相扣的课程内容，感兴趣的同学可以开始学习啦。",
      "target_audience": [
        "从事扫地机器人、净化机器人、陪伴机器人等领域的软件工程师、硬件工程师、算法工程师、质量工程师、产品经理等"
      ]
    },
    {
      "title": "ClickHouse技术实战教程",
      "url": "https://www.udemy.com/course/clickhouse/",
      "bio": "深度解析PMBOK第六版：项目管理知识体系精讲",
      "objectives": [
        "理解ClickHouse的基本概念和架构：学员将了解ClickHouse的核心概念、体系结构和基本工作原理，为后续的实践奠定基础",
        "掌握ClickHouse的数据建模和设计：学员将学习如何进行数据建模和设计，以最大程度地利用ClickHouse的性能和功能，满足不同的数据分析和查询需求",
        "学习ClickHouse的数据导入和导出：学员将了解如何将数据导入到ClickHouse中，并学习各种数据导入和导出的方法和工具，以支持数据的高效传输和交换",
        "进行ClickHouse的查询和分析：学员将学习如何编写和执行高效的查询语句，以实现快速的数据分析和查询结果。课程将介绍ClickHouse的查询语法、索引优化和性能调优等关键技术"
      ],
      "course_content": {
        "课程介绍": [
          "课程简介",
          "教师简介",
          "课程大纲"
        ],
        "第一章 ClickHouse课程介绍": [
          "课程介绍"
        ],
        "第二章 ClickHouse入门": [
          "课程介绍",
          "介绍&特点",
          "安装_准备工作",
          "安装_单机安装",
          "数据类型",
          "引擎介绍",
          "MergeTree引擎_简单使用",
          "MergeTree引擎_分区详解",
          "MergeTree引擎_主键",
          "MergeTree引擎_Order by",
          "MergeTree引擎_二级索引",
          "MergeTree引擎_TTL",
          "ReplacingMergeTree引擎",
          "SummingMergeTree引擎",
          "开发中引擎的选择",
          "SQL操作_Update和Delete",
          "SQL操作_查询和函数介绍",
          "SQL操作_多维分析函数",
          "SQL操作_alter&导出",
          "副本引擎",
          "分片集群介绍",
          "分片集群实操"
        ],
        "第三章 ClickHouse高级": [
          "课程介绍",
          "新版本安装&.官网在线demo介绍",
          "执行计划_plan&AST",
          "执行计划_syntax&pipeline",
          "执行计划_老版本如何查看",
          "建表优化_注意数据类型",
          "建表优化_分区和索引",
          "表参数&写入和删除优化",
          "CPU参数设置",
          "内存参数设置",
          "存储优化",
          "语法优化规则_准备测试用表",
          "语法优化规则_count优化",
          "语法优化规则_子查询重复字段&谓词下推",
          "法优化规则_聚合计算外推&聚合函数消除",
          "语法优化规则_删除重复字段(不同语法下)",
          "语法优化规则_标量替换&三元运算优化",
          "单表查询优化_prewhere&采样",
          "单表查询优化_数据裁剪&Orderby用法",
          "单表查询优化_避免构建虚拟列",
          "使用uniqCombined",
          "单表查询优化_使用物化视图&其他事项",
          "多表关联_使用IN代替JOIN",
          "多表关联_大小表JOIN",
          "多表关联_谓词下推",
          "多表关联_字典表&其他",
          "数据一致性_数据准备",
          "数据一致性_手动执行",
          "数据一致性_通过Group by去重",
          "数据一致性_使用Final&总结",
          "物化视图_概述",
          "物化视图_实操",
          "MaterializeMySQL引擎_概述",
          "MaterializeMySQL引擎_实操",
          "常见问题排查"
        ],
        "第四章 ClickHouse监控": [
          "章节概述",
          "Prometheus&Grafana安装",
          "ClickHouse配置",
          "配置监控实现"
        ],
        "第五章 ClickHouse备份": [
          "手动实现备份及恢复",
          "使用clickhouse-backup"
        ],
        "课程回顾": [
          "课程结语"
        ]
      },
      "requirements": [
        "学员需要具备基本的项目管理知识，了解项目生命周期、项目管理过程和常用的项目管理工具和技术。"
      ],
      "description": "《PMBOK第六版精讲解读》课程旨在通过深度解析PMBOK第六版，全面讲解项目管理知识体系的核心内容和要点。课程将提供详细的解读和解释，帮助学员理解PMBOK第六版中的各个知识领域和过程组。\n课程内容将包括以下方面：\n框架和结构解读：学员将深入了解PMBOK第六版的框架和结构，包括项目管理过程组、知识领域和过程间的关系，以及项目管理的核心概念和原则。\n知识领域精讲：学员将逐个学习和讲解PMBOK第六版中的十个知识领域，包括整合管理、范围管理、时间管理、成本管理、质量管理、人力资源管理、沟通管理、风险管理、采购管理和相关方管理。\n过程组解析：学员将详细解析项目管理的五个过程组，包括启动、规划、执行、监控与控制、收尾，了解每个过程组中的关键步骤、输入输出和最佳实践。\n实例和案例分析：课程将提供实际的项目管理实例和案例，帮助学员将PMBOK第六版中的理论知识与实际项目管理实践相结合，加深理解和应用能力。\n通过该课程的学习，学员将获得以下能力和收益：\n深入理解PMBOK第六版的核心概念、框架和知识体系。\n掌握各个知识领域和过程组的关键要点和最佳实践。\n能够将PMBOK第六版中的理论知识应用于实际项目管理实践中。\n准备PMP（Project Management Professional）认证考试或提升项目管理能力。\n该课程适用于已具备一定项目管理基础知识的学员，包括项目经理、项目团队成员、项目管理专业人士以及对项目管理感兴趣的学生和研究人员。无论是准备PMP认证考试，还是希望深入了解和应用项目管理知识体系的人员，都可以通过该课程获得丰富的知识和实践经验。",
      "target_audience": [
        "项目经理和项目团队成员",
        "项目管理专业人士"
      ]
    },
    {
      "title": "通义千问AI大模型人工智能实战课程",
      "url": "https://www.udemy.com/course/ai-wnyeb/",
      "bio": "通义千问大模型：AI实战技能全解锁",
      "objectives": [
        "深入理解通义千问AI大模型的架构、功能和应用场景",
        "掌握使用AI大模型解决实际问题的技能和方法",
        "学习如何将AI大模型应用于数据分析、自然语言处理等领域",
        "增强科技感知力"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "1、通义千问AI大模型人工智能实战教程概述",
          "2、资深Al专业讲师分享！通义千问人工智能Al提示词交互技巧",
          "3、通义干问Al实战教学，手把手教你如何写好公众号文章，轻松吸粉！",
          "4、用通义千问AI对文章进行优化的高效方法来啦，不仅能优化还能扩写",
          "5、通义千问Al学习小助手!解题、看图写话、批改作业等需求都能实现",
          "6、如何使用通义千问Al进行快速阅读？这里有专业Al讲师实例讲解！",
          "7、再也不怕读文献，用通义千问A提炼文献重点内容，还附带思维导图",
          "8、音视频转文字？通义千问Al就能做到，还能提炼重点，实时转换！",
          "9、读完书就忘？看通义千问Al如何帮你留佳书中精华，生成走心读后感",
          "10、用通义千问AI竟然可以写出爆款短剧剧本，纯干货教程速看！",
          "11、用通义千问Al生成活动方案总是简单不能用？那可能是指令没下对",
          "12、使用通义千问Al生成教案的教程分享，不想写教案的老师们快来用！",
          "13、用通义千问A!辅助填报高考志愿？一定要给好指令，学校推荐才精准",
          "14、别再花钱咨询高考志愿填报了，通义千问Al能回答你所有的问题！"
        ],
        "课程回顾": [
          "回顾总结"
        ]
      },
      "requirements": [
        "无需经验"
      ],
      "description": "《通义千问AI大模型人工智能实战课程》是一门结合理论与实践的课程，专注于AI大模型在人工智能领域的应用。本课程旨在教授学员如何有效利用通义千问AI大模型解决复杂的实际问题。通过本课程，学员将能够深入理解AI大模型的工作原理，并掌握在不同领域应用AI技术解决实际问题的能力。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "对人工智能和机器学习有浓厚兴趣，希望了解AI大模型的基础知识",
        "需要在数据分析和机器学习项目中应用AI大模型的专业人士",
        "希望将AI技术集成到应用程序中的软件开发者"
      ]
    },
    {
      "title": "强化学习——原理与实例精讲",
      "url": "https://www.udemy.com/course/urtdwwhx/",
      "bio": "掌握强化学习领域必备经典算法",
      "objectives": [
        "掌握强化学习经典算法原理及其应用领域",
        "熟练使用PyTorch框架构建强化学习算法",
        "熟悉强化学习建模环境并进行实战应用",
        "熟悉强化学习算法中的数学思想，掌握数学原理推导"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "强化学习简介及其应用": [
          "强化学习简介",
          "应用领域与工作流程",
          "计算机眼中的状态与行为"
        ],
        "PPO算法与公式推导": [
          "PPO算法简介",
          "任务概述",
          "目标分析公式推导",
          "baseline方法",
          "On Policy与Off Policy策略",
          "Importance Sampling的作用",
          "PPO算法整体思路解析"
        ],
        "PPO实战：月球登陆器训练实例": [
          "Critic的作用与效果",
          "PPO2版本公式解读",
          "参数与网络结构定义",
          "得到动作结果",
          "奖励获得与计算",
          "参数迭代与更新"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "对人工智能感兴趣"
      ],
      "description": "强化学习是一种学习如何从状态映射到行为以使得获取的奖励最大的学习机制。这样的一个agent需要不断地在环境中进行实验，通过环境给予的反馈（奖励）来不断优化状态——行为的对应关系。因此，反复实验（trial and error）和延迟奖励（delayed reward）是强化学习最重要的两个特征。\n本套强化学习课程主要包括经典算法原理讲解与案例实战两大部分。通俗讲解当下主流强化学习算法思想，结合实例解读算法整理应用流程并结合案例展开代码实战。整体风格通俗易懂，适合准备入门强化学习并进阶提升的同学们。",
      "target_audience": [
        "对人工智能，强化学习方向感兴趣的同学",
        "企业内中高级机器学习工程师，AI工程师等",
        "想要深入研究深度学习算法的科研人员及在校生等"
      ]
    },
    {
      "title": "Domina la Ciencia de Datos con Python: Desde Cero a Experto",
      "url": "https://www.udemy.com/course/ciencia-de-datos-con-python-desde-cero/",
      "bio": "Aprende a analizar, visualizar y predecir datos con Python, usando Pandas, NumPy, Matplotlib y Machine Learning.",
      "objectives": [
        "Conceptos básicos de ciencia de datos.",
        "Manejo de bibliotecas esenciales como NumPy, Pandas y Matplotlib.",
        "Proceso completo de la ciencia de datos: desde la obtención hasta la visualización de datos.",
        "Técnicas avanzadas de manipulación de datos con Pandas.",
        "Exploración, limpieza y división de datasets para análisis.",
        "Creación de gráficos (barras, histogramas, dispersión, cajas, pastel, líneas).",
        "Visualización de datasets reales como el Titanic y bienes raíces.",
        "Conceptos de estadística descriptiva e inferencial.",
        "Probabilidad, correlación, regresión y pruebas de hipótesis.",
        "Aplicación de estadística con datasets reales.",
        "Técnicas y gráficos para descubrir patrones e insights en los datos.",
        "Métodos para transformar y optimizar datos: One Hot Encoding, Ordinal Encoding, Binary Encoding, Binning e Imputación.",
        "Funciones avanzadas como apply, tablas dinámicas, multi-índices, pivotes y series temporales.",
        "Conceptos clave de Machine Learning y sus aplicaciones.",
        "Implementación de modelos de regresión lineal desde la teoría hasta la práctica.",
        "Análisis y visualización de datos del Titanic y bienes raíces.",
        "Desarrollo de modelos predictivos con regresión lineal."
      ],
      "course_content": {},
      "requirements": [
        "Conocimientos básicos de programación Aunque cubriremos conceptos de Python, se recomienda tener una comprensión básica de programación.",
        "Python instalado Es necesario tener instalado Python 3.x en tu computadora para seguir las lecciones prácticas.",
        "Familiaridad con los conceptos básicos de matemáticas y estadísticas será útil pero no es obligatorio.",
        "Ganas de aprender y explorar el mundo de la ciencia de datos."
      ],
      "description": "Este curso está diseñado para proporcionarte una base sólida en Python y sus aplicaciones en la Ciencia de Datos. A lo largo de las semanas, adquirirás habilidades para manipular, analizar y visualizar datos utilizando herramientas fundamentales como Pandas, Matplotlib y Seaborn. También profundizaremos en conceptos estadísticos esenciales, análisis exploratorio de datos, y técnicas avanzadas como la ingeniería de características y el aprendizaje automático con Scikit-Learn.\nA lo largo de 15 semanas, aprenderás:\nConceptos básicos de Python: Familiarízate con la sintaxis y las estructuras fundamentales del lenguaje.\nIntroducción a la ciencia de datos: Explora los principios que guían la manipulación y análisis de datos.\nManipulación de datos con Pandas: Aprende a manejar conjuntos de datos con la biblioteca más popular en ciencia de datos.\nVisualización de datos con Matplotlib y Seaborn: Crea gráficos informativos que faciliten la comprensión de datos complejos.\nIntroducción a la estadística: Adquiere una base sólida en estadística para el análisis de datos.\nAnálisis Exploratorio de Datos (AED): Desarrolla habilidades para encontrar patrones y relaciones clave en los datos.\nIngeniería de Características: Descubre cómo mejorar tus modelos a través de la creación de nuevas variables.\nPandas Avanzado: Domina técnicas avanzadas para gestionar grandes volúmenes de datos.\nIntroducción al aprendizaje automático: Comprende los fundamentos de los algoritmos de machine learning.\nSobreajuste e infraajuste: Aprende a ajustar tus modelos para un mejor desempeño.\nScikit-Learn: Aplica las técnicas más avanzadas de machine learning con esta poderosa biblioteca.\nAprendizaje supervisado: Explora los algoritmos que utilizan datos etiquetados para realizar predicciones.\nAprendizaje no supervisado: Analiza los algoritmos que identifican patrones sin supervisión humana.\nMétricas de evaluación: Evalúa el desempeño de tus modelos y optimiza su precisión.\nSelección de modelos y ajuste de hiperparámetros: Mejora tus resultados ajustando los parámetros clave de los modelos.\nAl finalizar este curso, serás capaz de analizar grandes cantidades de datos de manera efectiva, crear visualizaciones impactantes, y desarrollar modelos predictivos usando Python. ¡Comienza tu viaje en la ciencia de datos con nosotros y prepárate para dar los siguientes pasos en tu carrera!",
      "target_audience": [
        "Principiantes en Ciencia de Datos",
        "Programadores y Desarrolladores",
        "Profesionales de Negocios y Marketing",
        "Emprendedores y Freelancers",
        "Estudiantes Universitarios"
      ]
    },
    {
      "title": "الطريق إلى الحرية المالية عبر التداول",
      "url": "https://www.udemy.com/course/wdypefto/",
      "bio": "فهم كيفية عمل الأسواق المالية وأنواع الأصول المتاحة للتداول.",
      "objectives": [
        "السيناريو: السعر يكسر مستوى المقاومة.",
        "المتداولون الأذكياء: انتظروا إعادة الاختبار عند المقاومة السابقة (الدعم الآن).",
        "محفز الدخول: يدخل السعر إلى المنطقة ويشكل شمعة ابتلاع صعودية.",
        "وقف الخسارة: أسفل منطقة إعادة الاختبار.",
        "جني الأرباح: مستوى المقاومة التالي أو منطقة السيولة."
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "مقدمة عن التداول والأسواق المالية",
          "أنواع الأصول المالية (الأسهم، الفوركس، العملات الرقمية، السلع)",
          "الفرق بين الاستثمار والتداول"
        ],
        "القسم الثاني: الأساسيات التي يجب أن يعرفها كل متداول": [
          "أنواع أوامر البيع والشراء في الأسواق المالية",
          "أوقات التداول وأفضل الأوقات لدخول السوق",
          "تمرين عملي: تنفيذ أول عملية تداول تجريبية"
        ]
      },
      "requirements": [
        "فهم أساسيات الأسواق المالية – التعرف على كيفية عمل الأسواق المالية، أنواع الأصول المتداولة (الأسهم، العملات، السلع، العملات الرقمية)، وأساسيات العرض والطلب."
      ],
      "description": "وصف الدورة: \"احتراف اللعب من الصفر إلى القمة\"\nهل لديك شغف في أسواق المالية وترغب في معرفة كيفية التعرف على التفريغ، ولكن لا تعرف من أين تبدأ؟ سواء كنت مبتدئًا تمامًا أو لديك بعض المعرفة، هذه الدورة مخصصة لتعلمك بالمهارات والمعرفة القادرة على فهم المهارات الأساسية واستثمارها.\nتبدأ فترة طويلة من الأساسيات، حيث ستتعلم كيفية التخصصات الأساسية، والأنواع المتاحة مثل الخبرة المهنية والتقنية الرقمية، وعوامل تفعيلها. وبعد ذلك، سيتم الانتقال إلى التحليل الفني والأساسي، حيث يتم التعرف على كيفية قراءة التأثيرات الانعكاسية، والأدوات والمؤشرات الفنية، والتعرف على الطاقة المستخدمة في المعرفة.\nإلى جانب ذلك، ستتعلم كيفية إدارة رأس المال بالكامل، ووعد الأشخاص، والحركات التي يمكن القيام بها أثناء اللعب. كما ستستفيد من تطبيق ما تعلمته من خلال إنشاء حساب تداول للتداول، مما يساعدك على اكتساب خبرة لا تحتاج إلى العديد من الأسئلة الأساسية.\nماذا ستتعلم في هذه الدورة؟\nفهم كيفية عمل التخصصات وأنواع الأصول المتاحة للتداول.\nتعلم التحليل الفني والأساسي للمؤشرات المتنوعة المدروسة.\nتطوير متنوع وفريد من نوعه للموارد المالية لكل شخص.\nتطبيق أسس إدارة العديد والانضباط النفسي على الاستدامة التأمين والمدفوعات العامة.\nاكتسبت التجربة خلال التجربة قبل الدخول الكامل.\nلماذا تختار هذه المدة؟\nدورة شاملة تناسب المبتدئين ولا تتطلب أي خبرة سابقة في اللعب.\nتحتوي على دروس تطبيقية وأمثلة عملية لتوضيح المفاهيم بسهولة.\nإمكانية التعلم حسب جدولك الزمني من أي مكان وفي أي وقت.\nولأنك إرشادات من الخبراء في المجال، مما يسمح لك بتجنب المشاكل الشائعة في النجاح في التخصصات الأساسية.\nإذا كنت تريد تحديدها وتعمل على بناء أساس قوي في اللعب، وفهم المكونات الأساسية، وتنوعها، فإن هذه الدورة هي الخيار لك. انضم الآن وابدأ رحلتك نحو تحقيق أهدافك المالية واحترافية.",
      "target_audience": [
        "إدارة رأس المال والتحكم في العواطف – اكتساب مهارات إدارة الأموال، تقليل الخسائر، التحكم في المشاعر مثل الطمع والخوف، والالتزام بخطة تداول فعالة."
      ]
    },
    {
      "title": "Machine Learning con Python: Guida Completa a Scikit e AI",
      "url": "https://www.udemy.com/course/mastering-ai-con-python-scikit-learn-decision-trees-2025/",
      "bio": "Corso completo dedicato a Scikit-Learn, ai decision tree e all'integrazione con MySQL!",
      "objectives": [
        "Comprendere i fondamenti dell'intelligenza artificiale e del machine learning.",
        "Utilizzare Scikit-Learn per la preparazione dei dati, la modellazione e la valutazione delle performance.",
        "Costruire e ottimizzare decision tree per risolvere problemi di classificazione e regressione.",
        "Integrare MySQL per esplorare il dataset Iris e gestire grandi moli di dati."
      ],
      "course_content": {},
      "requirements": [
        "Non è necessaria esperienza di programmazione. Conoscenze base di Python e voglia di imparare sono sufficienti."
      ],
      "description": "Scopri il potere dell’intelligenza artificiale applicata alla pratica in questo corso completo dedicato a Scikit-Learn, ai decision tree e all'integrazione con MySQL! Che tu sia un principiante nel campo della data science o un professionista desideroso di approfondire, questo percorso ti guiderà passo dopo passo attraverso i concetti fondamentali e le tecniche avanzate per costruire, ottimizzare e interpretare modelli decisionali.\nCosa imparerai:\nFondamenti di AI e Machine Learning: Comprendi le basi dell'intelligenza artificiale e il funzionamento degli algoritmi di machine learning.\nScikit-Learn in Profondità: Approfitta di una panoramica completa di Scikit-Learn, dagli strumenti principali alle tecniche per l'analisi e la preparazione dei dati.\nDecision Trees: Analizza in dettaglio i decision tree: teoria, implementazione pratica e metodi per migliorare le performance dei modelli.\nProgetto Finale con Dataset Iris e MySQL: Metti in pratica quanto appreso nel progetto finale, in cui importerai ed esplorerai il famoso dataset Iris, integrandolo con MySQL per gestire e analizzare grandi quantità di dati.\nBest Practices e Ottimizzazione del Modello: Scopri come evitare gli errori comuni e implementare tecniche di fine-tuning per ottenere il massimo dal tuo modello.\nPerché scegliere questo corso:\nApproccio Pratico e Interattivo: Impara attraverso esempi reali, esercitazioni pratiche e un progetto finale che ti permetterà di mettere subito in pratica le competenze acquisite.\nRisorsa Completa per il Mercato del Lavoro: Acquisisci le skills richieste nel mondo dell’analisi dei dati e preparati a sfide professionali reali.\nSupporto Continuo e Community: Accedi a supporto dedicato e confrontati con una community di appassionati e professionisti del settore.\nStrumenti e Tecnologie Moderni: Dal popolare Scikit-Learn a MySQL, utilizza i tool più diffusi e richiesti nel campo della data science e dell'intelligenza artificiale.\nPreparati a rivoluzionare il tuo approccio al machine learning e a entrare nel mondo dell’intelligenza artificiale con competenze concrete e progetti reali. Se cerchi un corso aggiornato, pratico e orientato al risultato, questo è il percorso che fa per te!",
      "target_audience": [
        "Destinato a sviluppatori Python principianti e appassionati di data science interessati a sperimentare con AI e decision tree."
      ]
    },
    {
      "title": "Numpy数据操纵的艺术",
      "url": "https://www.udemy.com/course/numpy-tomge/",
      "bio": "数据分析师之术NumPy，一课掌握！",
      "objectives": [
        "掌握数据分析环境的安装。",
        "全面掌握 Numpy 的基础知识 。",
        "全面掌握基础索引、布尔索引、花式索引，通用函数特性，向量化操作。",
        "全面掌握 ndarray 的变形、转置、轴对换、拼接和分裂、广播和排序。"
      ],
      "course_content": {
        "Numpy 基础篇": [
          "NumPy介绍",
          "NumPy中的数据",
          "多维数组对象- ndarray",
          "ndarray的创建",
          "基本的索引和切片操作",
          "布尔型索引",
          "ndarray的变形",
          "花式索引",
          "应用：自动驾驶车道线标注"
        ],
        "NumPy 高级篇": [
          "ndarray的转置和轴对换",
          "ndarray的拼接和分裂",
          "探索NumPy的通用函数",
          "通用函数特性",
          "向量化操作数据",
          "条件逻辑运算",
          "数学统计函数",
          "应用：星巴咖啡营销决策",
          "Numpy 广播",
          "ndarray的排序"
        ],
        "NumPy 练习": [
          "NumPy基础练习1 ~ 10题",
          "ndarray操作练习11 ~ 20题",
          "NumPy打印设置练习 21 ~ 24题",
          "NumPy数据分析练习25 ~ 30题"
        ],
        "赠课：数据科学开发环境安装": [
          "macOS - 如何安装和使用 Anaconda 详细讲解",
          "Windows - 如何安装和使用 Anaconda 详细讲解",
          "Linux - 如何安装和使用 Anaconda 详细讲解",
          "如何使用Jupyter Notebook：探索编程基本概念",
          "Jupyter Notebook 高级用法详解：魔法命令",
          "Markdown 语言用法详解：掌握标记语言的编写技巧"
        ]
      },
      "requirements": [
        "基础 Python 开发"
      ],
      "description": "《Numpy数据操纵的艺术》是一门专为数据科学爱好者和专业人士设计的课程。在本课程中，讲师凭借超过20年的研发经验和深厚的专业知识，精心挑选了一系列典型案例，采用独创的教学手法，为学习者提供生动形象的教学体验。\n内容全面：课程从基本的NumPy概念讲起，逐步深入，涵盖向量化操作等高级主题，确保学习者能够获得知识点的全方位深度覆盖。\n案例驱动：通过真实世界的典型案例，让学习者能够将理论知识与实践相结合，加深理解和应用。\n深度讲解：讲师将利用多年的经验，对NumPy的内部机制和高级特性进行深入讲解，帮助学习者从根本上掌握NumPy。",
      "target_audience": [
        "对数据科学感兴趣的Python开发人员"
      ]
    },
    {
      "title": "Learn Data Management Concepts In Arabic",
      "url": "https://www.udemy.com/course/learn-data-management-concepts-in-arabic/",
      "bio": "*Course for Arabic Speakers* Unlocking the Power of Data: Concepts, Technologies, and Career Paths",
      "objectives": [
        "What is Data?",
        "Data Management Main Operations",
        "Data Management Technologies",
        "Data Jobs and How to Land a Job in the data domain"
      ],
      "course_content": {
        "Introduction": [
          "What is Data?"
        ],
        "Data Management 5 Main Operations": [
          "Data Main Operations",
          "Data Collection Operation",
          "Data Storage Operation",
          "Data Organize Operation",
          "Data Apply Operation",
          "Data Governance Operation"
        ],
        "Data Management Technologies": [
          "Data Management Technology"
        ],
        "Data Domain Jobs & Roles": [
          "Data Domain Jobs",
          "How to Find a Job on The Data Domain"
        ]
      },
      "requirements": [
        "Arabic Language",
        "Time & Self Learning"
      ],
      "description": "Embark on an immersive journey into the dynamic world of data management with our expert-led course. Dive deep into fundamental data management concepts and operations, gaining a comprehensive understanding of data collection, storage, analysis, and presentation. Explore cutting-edge data technologies such as big data, machine learning, and data visualization, and grasp how they are reshaping industries globally. Discover an array of career opportunities in the data domain, from data analyst to data scientist, data engineer, and more. Acquire priceless insights on how to launch your career in this rapidly expanding field, including guidance on portfolio development, networking strategies, and technical proficiency. Whether you're an aspiring data professional or a seasoned practitioner seeking career advancement, this course equips you with the knowledge and skills essential to thrive in today's data-driven landscape. Additionally, we delve into case studies and discuss the top companies leading the charge in the data domain, offering valuable insights into industry trends and best practices. Join us today and uncover the limitless possibilities awaiting you in the realm of data management and analytics.\n\n\nانطلق في رحلة شاملة إلى عالم إدارة البيانات مع دورتنا القائمة على الخبراء. اغمر نفسك في المفاهيم الأساسية لإدارة البيانات، مكتسباً فهماً قوياً لجمع البيانات، وتخزينها، وتحليلها، وعرضها. استكشف التكنولوجيات الحديثة للبيانات وتعلم كيف تقوم بتحليل البيانات. اكتشف مختلف فرص العمل في مجال البيانات، بدءًا من محلل البيانات إلى عالم البيانات، واكتسب رؤى قيمة حول كيفية بدء مسارك المهني في هذا المجال الذي ينمو بسرعة. سواء كنت مبتدئًا أو محترفًا مخضرمًا، تزودك هذه الدورة بالمعرفة والمهارات اللازمة للنجاح في عالم البيانات",
      "target_audience": [
        "Beginners who would like to start a career in the Data Domain"
      ]
    },
    {
      "title": "Python数据分析行业案例课程：学习数据可视化",
      "url": "https://www.udemy.com/course/python-uo/",
      "bio": "从实际案例数据的可视化需求出发，在实战中学习matplotlib+seaborn包的使用方法",
      "objectives": [
        "学习如何使用Matplotlib+Seaborn进行数据信息的精美呈现",
        "学习如何综合使用Pandas + Matplotlib + Searborn环境完成数据可视化工作",
        "了解数据可视化的相关理论知识",
        "为后续进一步进行数据分析建模和数据挖掘打下坚实基础"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "准备软件环境": [
          "Python中数据可视化工具介绍",
          "本课程的内容安排",
          "IDE简介",
          "Anaconda的安装与配置",
          "Notebook演示"
        ],
        "第2章 matplotlib绘图操作入门": [
          "设置figure对象",
          "用plot函数绘图",
          "设置图形格式",
          "输出图形",
          "Matplotlib+seaborn绘图环境设定"
        ],
        "数据可视化理论入门": [
          "统计图的基本信息维度",
          "统计图的基本框架",
          "展示单分类变量信息的统计图",
          "展示单连续变量信息的统计图",
          "双变量统计图：分类vs分类变量",
          "双变量统计图：含有数值变量",
          "展示多变量信息的统计图"
        ],
        "单变量信息的可视化": [
          "CCSS项目介绍",
          "简单条图",
          "饼图，半圆图与圆环图",
          "条带图",
          "直方图，KDE图与地毯图",
          "箱图和增强箱图",
          "提琴图"
        ],
        "复杂条图，线图与面积图": [
          "带误差线的条图",
          "分组条图，堆积条图与百分条图",
          "用matplotlib绘制线图",
          "用seaborn绘制线图",
          "误差图与面积图"
        ],
        "散点图": [
          "普通散点图",
          "变量间的回归趋势考察",
          "复杂回归曲线的拟合",
          "考察回归残差的分布",
          "分组考察回归关系",
          "联合变量分布的散点图",
          "Hexbin图和等高线图",
          "散点图矩阵",
          "三维散点图"
        ],
        "在图形中纳入更多变量信息": [
          "设置图例",
          "混合图形与双轴图",
          "使用行列面板"
        ],
        "子图与图形网格": [
          "图形叠加和图中图",
          "用subplot命令绘制子图",
          "用subplots命令绘制子图",
          "调整子图间距",
          "复杂网格：Gridspec方法",
          "子图与图形网络"
        ],
        "色彩搭配": [
          "色彩搭配的基本原则",
          "如何自定义理想的色系",
          "色板的指定方法",
          "分类色板",
          "连续色板",
          "离散色板"
        ]
      },
      "requirements": [
        "掌握matplotlib、seaborn的基础使用"
      ],
      "description": "matplotlib包是基于Python平台的统计绘图利器，是在python平台上完成数据可视化不可或缺的工具，而基于matplotlib进一步开发的seaborn，更是将数据呈现与可视化的可用性推到了一个新的高度， pandas+ matplotlib + searborn已经构成了数据管理与可视化的一套完整环境。\n\n本课程将从中国消费者信心指数项目这一实际案例数据的可视化需求出发，在实战中学习matplotlib+seaborn包的使用方法\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。\n未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "有对应Python编程基础的同学",
        "企业内初中级数据分析师和Python数据分析师",
        "希望成为Python工程师和数据分析师的跨界人才",
        "企业内有一定编程基础的业务营销人员"
      ]
    },
    {
      "title": "【初心者向け】音声AIでクローンボイスを作りOpenAIのAPIと組み合わせてチャットボットを構築してみよう！",
      "url": "https://www.udemy.com/course/ai_audio/",
      "bio": "高精度な音声合成AI「Cartesia」を使って自分のクローンボイスを作ってみよう！また作ったクローンボイスをAPIで呼び出してOpenAIの音声認識APIと組み合わせて簡易的なチャットボットを作っていこう！",
      "objectives": [
        "Cartesiaを使ったクローンボイスの作成手順",
        "PythonからAPIを利用してクローンボイスを呼び出す方法",
        "OpenAIの音声認識APIを用いた音声→テキスト変換の実装",
        "Streamlitを使った簡易的なUIの作成方法",
        "音声AIを活用した簡易的なチャットボット開発方法",
        "Pythonの基礎"
      ],
      "course_content": {
        "はじめに": [
          "イントロダクション",
          "音声AI「Cartesia」の紹介",
          "自分の音声をクローンしてみよう！"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Python構文の復習"
        ],
        "Pythonを使ってCartesiaを呼び出してみよう！": [
          "次のレクチャーのライブラリのバージョンについて",
          "PythonでCartesiaで作ったクローンボイスを使ってみよう！"
        ],
        "テキストを入力したらクローンボイスで読み上げてくれるUIを作っていこう！": [
          "次のレクチャーのライブラリのバージョン & エディタの準備とPythonの準備",
          "環境構築と準備をしていこう！",
          "StreamlitのUIやクローンボイスの処理を作っていこう！",
          "入力したテキストをクローンボイスで再生する完成形を見ていこう！",
          "コードのミスを修正：model → mode"
        ],
        "ユーザーの音声を聞き取って回答を音声で生成してくれるチャットボットを作っていこう！": [
          "OpenAIのAPIキー取得方法",
          "ライブラリのインストールと準備",
          "音声をテキストに変換するSTT処理を実装していこう！",
          "AIの返答を生成し返答を音声化する処理を実装していこう！",
          "チャットの履歴を残して表示する処理を実装していこう！",
          "会話実装の結果を見ていこう！",
          "テキストの出力をStream出力にしてみよう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学びますのでプログラミングの知識は特に必要ありません"
      ],
      "description": "本コースへようこそ！\n\n\n本コースでは、まず高精度な音声合成AI「Cartesia」を使って自分のクローンボイスを作成し、そのクローンボイスをAPI経由で呼び出す方法を学びます。\n\n\nそしてCartesiaの使い方を学んだ後は、OpenAIの音声認識AIとテキスト生成AIを組み合わせて、音声で会話できる高精度なチャットボットを構築していきます。UIはPythonのStreamlitで作成するため、必要最低限の機能が盛り込まれたシンプルなWebアプリとして構築！\n\n「音声認識」「音声合成」「テキスト生成」といった最先端のAIを連携させることで、受講後には実用的な音声対話アプリケーションを自分で作れるようになります！\n\n\nPythonの基礎編を除いた本編は1時間ちょっとのコンパクトコース！1時間ちょっとで高精度なクローンボイスを使ったチャットボットを作ってみましょう！",
      "target_audience": [
        "音声AI（TTS/STT）やボイスクローン技術に興味がある方",
        "音声認識や音声合成を取り入れたサービスを企画・開発したい方",
        "Pythonでの音声チャットボット開発に興味のある方",
        "高精度なクローンボイスを作ってみたい方"
      ]
    },
    {
      "title": "les bases de la statistique et de l'analyse de données",
      "url": "https://www.udemy.com/course/les-bases-de-la-statistique-et-de-lanalyse-de-donnees/",
      "bio": "comprendre en s’exerçant : acquérir les bases de la statistique descriptive et du coding sur python",
      "objectives": [
        "Comprendre la statistique descriptive dans le contexte de l'analyse de données",
        "Savoir utiliser les outils de l'analyse statistique et en comprendre le sens et l'utilité",
        "Etre capable de produire des analyses statistiques de données",
        "S'initier au coding statistique sur python"
      ],
      "course_content": {
        "les bases de la statistique descriptive et de la modélisation sur python": [
          "Introduction",
          "Les Mesures de tendance centrale",
          "Les Mesures de forme de distribution ou de densité ( Kurtosis et Skewness )",
          "Les Mesures de dispersion ( Variance , Ecart Type et Ecart Interquartile ICQ )",
          "Les Lois de Probabilité",
          "Analyse des résultats et Conclusion",
          "Explications et analyse de la Moyenne Géométrique",
          "La Variance / La Covariance et le Coefficient de Corrélation",
          "La Régression Linéaire Simple",
          "La régression Linéaire Multiple",
          "Le Coefficient de Détermination",
          "Exercice Pratique sur Python partie 1 : Machine Learning",
          "Exercice Pratique sur Python Partie 2 : Machine Learning"
        ]
      },
      "requirements": [
        "La formation s'adresse aux débutants qui disposent du minimum de connaissances en statistique"
      ],
      "description": "Ce cours vous permettra de débuter votre apprentissage en statistique et en analyse de données sur de bonnes bases en abordant les problématiques de tendance centrale , dispersion, densité et loi de probabilité et enfin mesures de forme tout cela en optant pour une approche qui regroupe l'aspect théoriques et pratique a travers des exemples vivants.\nNous utiliserons du coding Python sur Colab en avançant étape par étape pour assimiler en profondeur le sens et l'utilité de chaque concept étudié , l'objectif étant d'être capable a la fin de ce cours de produire des analyses statistiques cohérentes.\nCette formation s'adresse aux débutants qui souhaitent se familiariser avec les statistiques et s'autonomiser pour être capable de comprendre les données et cela quel que soit le domaine d'activité et le cursus académique de l'apprenant en démarrant de la base théorique de chaque concept et ne schématisant en recourant a des exemples vivants .\nCe cours de 2h30 s'efforce aussi dans l'optique d' éviter de tomber dans la longueur qui peut rapidement disperser l'apprenant, de synthétiser au maximum et d'aller directement a l'essentiel pour éviter de se perdre mais aussi pour permettre un apprentissage plus rapide.\n\n\nNous aborderons donc les problématiques de :\n\n\nMesures de tendance centrale ( Moyenne Géométrique et Moyenne arithmétique , Médiane , Mode , Quantiles , Min et Max )\nMesures de forme de distribution ou de densité ( Kurtosis et Skewness )\nMesures de dispersion ( Variance , Ecart Type et Ecart Interquartile ICQ )\nLois de Probabilité\nIntroduction a l'utilisation de Python ( Colab )",
      "target_audience": [
        "a des débutants en statistique qui souhaitent utiliser l'outil statistique pour effectuer des analyses de données",
        "a des débutants qui souhaitent s'initier au Coding statistique sur python"
      ]
    },
    {
      "title": "通过Q-Learning掌握强化学习【中字】",
      "url": "https://www.udemy.com/course/q-learning/",
      "bio": "探索未知的优化之路：深入剖析Q学习算法",
      "objectives": [
        "强化学习的基本概念",
        "如何使用Python和NumPy等常用库从零开始实现Q-Learning",
        "设计高效的探索-开发策略和优化Q表的技术",
        "在复杂环境中导航并找到最佳路径以实现预期目标的方法"
      ],
      "course_content": {
        "课程介绍": [
          "课程介绍"
        ],
        "通过Q-Learning掌握强化学习": [
          "1 通过一个简单的项目学习基础知识",
          "2 创建二维网格的Q表",
          "3 在网格环境中显示最佳路径",
          "4 在网格环境中添加奖励",
          "时间缩短1000倍",
          "6 优化代码，随时更改目标状态"
        ]
      },
      "requirements": [
        "对Python编程有基本了解",
        "熟悉基本数据结构，如列表、字典和数组"
      ],
      "description": "通过一门精心制作的课程，深入强化学习的迷人世界，并掌握Q学习的艺术。无论你是初学者还是志向远大的数据科学家，这门课程都将引导你走向成为强化学习专家的旅程。\n通过一系列引人入胜且具有挑战性的项目，你将探索强化学习的原理，并见证Q学习的实际作用。从简单的网格环境到更复杂的场景，你将逐步提高你的技能和理解力，最终在一个旨在测试你掌握程度的项目中达到高潮。\n在本课程中，你将学习：\n强化学习的基本概念，包括Q学习算法。\n如何使用Python和流行的库（如NumPy）从头开始实现Q学习。\n设计有效的探索-开发策略和优化Q表的技术。\n在复杂环境中导航并找到达到期望目标的最佳路径的策略。\n可视化和解释Q学习模型结果的最佳实践。\n除了理论知识，你还将深入研究实践项目，这些项目将挑战你应用新发现的技能。从易于理解的基于网格的环境到更复杂的模拟，每个项目都将促使你批判性地思考、实验并完善你的方法。\n在本课程结束时，你不仅将深入了解强化学习和Q学习，而且还将掌握解决现实世界问题的实用技能。无论你对人工智能、机器人还是决策感兴趣，这门课程都将为你提供在你的努力中取得成功的工具和技术。\n现在报名，开始一段激动人心的旅程，通过Q学习项目掌握强化学习的艺术！",
      "target_audience": [
        "机器学习与人工智能领域的初学者，希望扩展自己的知识和技能",
        "有志于探索强化学习潜力的数据科学家和人工智能爱好者",
        "具有计算机科学、数学或工程学背景，希望将所学技能应用于实际问题的学生"
      ]
    },
    {
      "title": "Python ile Finansal Veri Analizi: Hisse Senetleri",
      "url": "https://www.udemy.com/course/python-ile-finansal-veri-analizi-hisse-senetleri/",
      "bio": "Algoritmik İşlemler, Hisse Senedi Analizi",
      "objectives": [
        "Python ile kodlama",
        "Finansal Veri Analizi",
        "Teknik Analiz",
        "Algoritmik alım satım"
      ],
      "course_content": {
        "Tarihsel Veri Alma İşlemi": [
          "Tarihsel Veri Alma İşlemi | importData"
        ],
        "Teknik Analiz İndikatörleri": [
          "Hareketli Ortalamalar (MA) | applyMA",
          "Veri Görselleştirme (MA) | visualiseMA",
          "Parametre Optimizasyonu (MA) | optimiseMA",
          "Indikatör Kombinasyonu (MA ve ADX) | applyMADX",
          "Parametre Optimizasyonu (MA ve ADX) | optimiseMADX"
        ],
        "Performans Analizi": [
          "Performans Analizi | getTradeStatistics",
          "Performans Analiz Grafiği | compareMethods"
        ],
        "Canlı Sinyaller": [
          "Günlük Periyot Sinyalleri | searchAllSymbols"
        ],
        "Gün İçi İşlemler": [
          "Gün İçi - Tarihsel Veri Alma İşlemi | importData_Intra",
          "Gün İçi - Hareketli Ortalamalar | applyMA_Intra",
          "Gün İçi - Parametre Optimizasyonu | optimiseMA_Intra",
          "Gün İçi - Indikatör Kombinasyonu | applyMADX_Intra",
          "Gün İçi - Parametre Optimizasyonu | optimiseMADX_Intra",
          "Gün İçi - En İyi Periyot Analizi | getBestPeriods",
          "Gün İçi - Sembol Bazlı Optimizasyon Kontrolü | symOptimControllr",
          "Gün İçi - Veri Görselleştirme | visualiseMADX_Intra",
          "Canlı Piyasa İşlemleri | searchBestKSymbols"
        ]
      },
      "requirements": [
        "Giriş seviyesinde Python bilgisi"
      ],
      "description": "Bu eğitim, finansal yatırımlarında yeni nesil teknolojileri kullanmak isteyen bireysel ve kurumsal yatırımcılar için hazırlanmıştır. Python kullanarak Yahoo Finance'den veri alma işlemiyle başlayan bu yolculuk, canlı olarak piyasayı izleyen bir yapıya dönüşmektedir. Stratejilerin nasıl optimize edileceğini ve yapılan alım satımların tarihsel performansını anlamak için görselleştirme yöntemleri fonksiyonel programlama ile sunulmuştur.\nEğitimin sonunda, katılımcılar piyasa verilerini nasıl etkin bir şekilde toplayacaklarını, analiz edeceklerini ve bu verilerle nasıl bilinçli yatırım kararları alacaklarını öğrenmiş olacaklar. Python programlama dilini kullanarak, canlı piyasa verilerini takip edebilme yetkinliği kazanacaklar. Ayrıca, alım satım stratejilerini optimize etmek ve tarihsel performans analizleri yapmak için gerekli görselleştirme tekniklerini de öğrenecekler. Bu kapsamlı eğitim, katılımcıların finansal piyasaları daha iyi anlamalarına ve yatırım kararlarını daha stratejik bir şekilde almalarına yardımcı olacak.\nFinans piyasalarında çalışan profesyoneller için ise bu eğitim, mevcut bilgi ve becerilerini ileriye taşıma fırsatı sunmaktadır. Python programlama dili ve fonksiyonel programlama teknikleriyle, veri analizini daha hızlı ve verimli bir şekilde gerçekleştirebilirler. Canlı piyasa verilerini takip ederek anlık stratejik kararlar alabilir, tarihsel verileri analiz ederek gelecekteki eğilimleri öngörebilirler. Bu eğitim, finans sektöründe rekabet avantajı sağlamak isteyen profesyoneller için önemli bir araç olacaktır. Piyasa dinamiklerine hakim olma ve teknolojiyi etkin kullanma becerisi, kariyerlerinde önemli bir adım atmalarına yardımcı olacaktır. Eğitim süresince kazandıkları bilgilerle, daha stratejik ve bilgili bir şekilde finansal kararlar alabilirler.\nÖnemli Not: Bu eğitim, herhangi bir sermaye piyasası aracının alım satım tavsiyesi içermemektedir. Kursumuz, yalnızca Python programlama dili ve veri analiz tekniklerini kullanarak finansal verileri nasıl işleyebileceğinizi öğreten bir yazılım eğitimidir. Yatırım kararlarınızı verirken kendi araştırmanızı yapmanız veya profesyonel danışmanlık almanız önemlidir.",
      "target_audience": [
        "Bireysel yatırımcılar",
        "Yatırım ve portföy yönetim şirketi çalışanları",
        "Hazine departmanı çalışanları"
      ]
    },
    {
      "title": "用DeepSeek搞定编程：开发新手的趣味入门课",
      "url": "https://www.udemy.com/course/deepseek-k/",
      "bio": "开发新手的趣味入门课",
      "objectives": [
        "通过对DeepSeek的学习，学员将能够编写简单的程序，为后续深入学习人工智能打下坚实基础",
        "学员将了解这些技术的基本概念、工作原理和应用场景，从而能够更好地理解和应用人工智能技术",
        "学员将学会如何分析问题、设计解决方案，并通过编程实现这些方案",
        "学员将会为未来进入软件开发、数据分析等技术领域打下坚实基础。"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "第一章 基础操作入门": [
          "1.1 使用工具介绍",
          "1.2 小游戏案例",
          "1.3 基本操作流程"
        ],
        "第二章 基于算法的工具设计": [
          "2.1 2048小游戏案例",
          "2.2 汇率计算器工具案例",
          "2.3 环形面积计算器案例"
        ],
        "第三章 进阶算法的工具设计": [
          "3.1 进阶算法的基础原理",
          "3.2 色阶工具设计思路拆解",
          "3.3 色阶工具设计案例"
        ],
        "第四章 文件打开新建与输出": [
          "4.1 贷款计算器工具案例",
          "4.2 代码编辑器工具案例",
          "4.3 复杂工具生成技巧"
        ],
        "第五章 复杂工具设计流程分析": [
          "5.1 工具设计基础思路",
          "5.2 MD笔记工具设计",
          "5.3 复杂工具设计流程复盘"
        ],
        "第六章 复杂工具设计思路拆解": [
          "6.1 复杂工具规划逻辑",
          "6.2 个人工作管理工具案例",
          "6.3 复杂工具设计思路复盘"
        ],
        "第七章 轻量化工具的迭代思维": [
          "7.1 迭代的基本逻辑",
          "7.2 批量图生成工具案例（上）",
          "7.3 批量图生成工具案例（下）",
          "7.4 批量图迭代案例"
        ],
        "第八章 复盘与总结": [
          "8.1 常见语法复盘",
          "8.2 使用技巧与常见问题",
          "8.3 R1深度思考模式"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "无经验"
      ],
      "description": "想学编程却被复杂的代码劝退？DeepSeek——当下最热门的AI工具，帮你轻松搞定！结合 MarsCode 封装代码，双工具协同，带你高效入门编程！\n这是一门专为编程新手设计的高效入门课，通过 “生成→封装→实战” 的完整学习路径，带你从零基础到独立开发工具，轻松搞定编程！\n课程从基础操作开始，通过趣味案例、小游戏快速上手；再到进阶，拆解复杂工具设计；最后深入，了解工具开发，掌握迭代思维与设计逻辑。\n\n有案例有工具，让你在动手实践中掌握编程核心技能，告别枯燥学习，成为高效开发的达人！",
      "target_audience": [
        "初创企业产品经理",
        "转行者或职场提升者",
        "小型工作室需要快速掌握编程技能的成员"
      ]
    },
    {
      "title": "ECBA 商业/业务分析师 (初级)认证培训课程：商业分析和商业分析规划与监督",
      "url": "https://www.udemy.com/course/ecba-wyo/",
      "bio": "ECBA商业分析师启航：精通商业分析规划、执行与监督策略",
      "objectives": [
        "让你全面了解商业分析职业，开始您的 BA 职业所需的基础知识和核心技能",
        "能够使用行业标准的BA方法，提供更安全、更高质量的输出，同时也提高了效率和一致性",
        "能够协助团队通过数据分析增加市场潜力，企业/组织可以根据BA专业团队的建议使其业务多样化，进入有利可图的细分市场",
        "考取ECBA证书可以成为入门级业务需求分析师BA专业能力/技能的识别"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲",
          "0 前言"
        ],
        "第一章 商业分析和商业分析职业": [
          "第1节 商业分析和商业分析职业"
        ],
        "第二章 商业分析关键概念": [
          "第1节 商业分析关键概念（A1）",
          "第2节 商业分析关键概念（A2）",
          "第3节 商业分析关键概念（B）",
          "第4节 商业分析关键概念（C）"
        ],
        "第三章 商业分析规划与监督": [
          "第1节 商业分析关键概念（A1）",
          "第2节 商业分析关键概念（A2）",
          "第3节 商业分析关键概念（B）",
          "第4节 商业分析关键概念（C1）",
          "第5节 商业分析关键概念（C2）",
          "第6节 商业分析关键概念（D）",
          "第7节 商业分析关键概念（E）",
          "第8节 商业分析关键概念（F1）",
          "第9节 商业分析关键概念（F2）"
        ],
        "回顾总结": [
          "课后寄语"
        ]
      },
      "requirements": [
        "无需前置经验"
      ],
      "description": "在当今竞争激烈的商业环境中，精准的商业洞察与高效的业务规划是企业持续成功的关键。为了培养具备扎实商业分析技能及卓越项目规划与监督能力的初级商业/业务分析师，《ECBA 商业/业务分析师 (初级) 认证培训课程》特别设计了“商业分析和商业分析规划与监督”这一核心模块，旨在通过全面而深入的学习，帮助学员掌握从问题识别到解决方案实施的全过程管理。\n程首先夯实商业分析的基础理论，包括商业分析的概念、作用、流程以及所需的核心技能。学员将学习如何运用数据分析、市场调研、利益相关者分析等工具和方法，深入洞察业务问题，识别潜在机会。在理解商业分析基本原理的基础上，课程将进一步讲解商业分析项目的规划与执行策略。学员将学习如何制定详细的项目计划，明确项目目标、范围、时间表和预算，同时掌握项目管理工具和技术，确保项目高效推进。为确保商业分析成果的有效转化，课程还将重点介绍商业分析项目的监督与评估机制。学员将学习如何建立有效的监控体系，跟踪项目进展，及时发现并解决问题；同时，掌握评估商业分析成果的方法和标准，为决策提供有力支持。\n无论您是刚刚踏入商业分析领域的新手，还是希望提升项目管理能力的从业者，《ECBA 商业/业务分析师 (初级) 认证培训课程：商业分析和商业分析规划与监督》都将是您职业成长道路上的重要里程碑。加入我们，开启您的商业分析之旅，共创辉煌职业未来！",
      "target_audience": [
        "ECBA非常适合刚进入职场的大学生、职场新人、或者希望转岗/过渡到 BA职业的专业人士",
        "在我国,目前绝大多数的项目经理/产品经理/管理层，也都在扮演BA的角色，也同样适合学",
        "ECBA认证考试无门槛,所有人都可以学,都可以考，ECBA已有中文版考试。ECBA的进阶考试是CCBA(中级)以及CBAP(专家级)"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第29部 神經網絡2.0 - KAN vs 傳統MLP",
      "url": "https://www.udemy.com/course/generative_ai_29/",
      "bio": "關於Kolmogorov-Arnold， KAN， MLP， B-Spline，基底函數，貝茲曲線",
      "objectives": [
        "深入瞭解什麼是 MLP 多層感知器 & 如何在 Pytorch 中實現 MLP",
        "深入瞭解什麼是 KAN 架構 & 貝茲曲線 & B-Spline",
        "深入瞭解基底函數 & 局部控制 & 網格擴展",
        "學會如何用 Python 製作神經元結構 & B-Spline 基底函數"
      ],
      "course_content": {
        "課程環境準備": [
          "課程需要的軟體如何安裝",
          "如何使用uv 作為包管理器和項目管理工具"
        ],
        "什麼是 MLP 多層感知器 & 如何在 Pytorch 中實現 MLP": [
          "什麼是 MLP 多層感知器 & 如何在 Pytorch 中實現 MLP",
          "如何用 MLP 實現真實數據訓練和測試評估"
        ],
        "什麼是 KAN 架構 & 貝茲曲線 & B-Spline & 基底函數 & 局部控制 & 網格擴展": [
          "什麼是 KAN 架構 & 貝茲曲線 & B-Spline & 基底函數 & 局部控制 & 網格擴展"
        ],
        "如何用 Python 製作 KAN": [
          "如何用 Python 製作神經元結構 & B-Spline 基底函數",
          "如何用 Python 將 KAN 神經元結合 Feed Forward 前饋神經網絡"
        ]
      },
      "requirements": [
        "一臺電腦"
      ],
      "description": "課程將帶領學員從傳統神經網絡（MLP）的基礎出發，逐步深入理解 KAN（Kolmogorov–Arnold Network） 的結構、數學原理與實作方法。\n\n\n課程內容：\n什麼是 MLP 多層感知器 & 如何在 PyTorch 中實現 MLP？\nMLP 是所有深度學習模型的基礎建築單元，你學會它，就能理解大多數 AI 模型的骨架\n\n\n如何用 MLP 實現真實數據訓練和測試評估\n這是實際部署 AI 模型的必備能力\n\n\n什麼是 KAN 架構 & 貝茲曲線 & B-Spline & 基底函數 & 局部控制 & 網格擴展\nKAN（Kernel-based Activation Networks）是對傳統 MLP 結構的一種突破，它用數學曲線（如 B-spline）來取代固定的 activation function\n\n\n基底函數（basis function） ⇒ 這是類似於 Radial Basis Function (RBF)、Fourier series 等模型的核心思想\n\n\nBézier 曲線、B-Spline ⇒ 你可以使用數學工具更細膩地控制神經元行為\n\n\n局部控制 / 局部學習 ⇒ 對應於神經元只對一小區域輸入敏感，這種性質非常適合高維/稀疏資料\n\n\n網格擴展 ⇒ 可以學習如何讓模型具備更強的「解析能力」與「數值穩定性」",
      "target_audience": [
        "AI 工程師，希望探索 MLP 之外的新型網絡",
        "資料科學家，想解決複雜函數建模問題",
        "深度學習研究人員，想掌握下一代神經網絡理論",
        "想從理論進入實作，追求數學 + 程式雙重能力提升者",
        "對可解釋 AI、終身學習等方向有興趣的從業者或學生"
      ]
    },
    {
      "title": "Tensorflow für Python Programmierer",
      "url": "https://www.udemy.com/course/tensorflow-fuer-python-programmierer/",
      "bio": "Einfach neuronale Netze erstellen mit dem Tensorflow 2 und Keras",
      "objectives": [
        "Neuronale Netze mit Tensorflow 2 erstellen",
        "Nützliche Praxisbeispiele",
        "Ergänzungen und kontinuierliche Erweiterung des Kurses"
      ],
      "course_content": {
        "Einleitung": [
          "Installation auch für die Grafikkarte",
          "Tensoren",
          "Grundlagen für ein neuronales Netz"
        ],
        "Das erste neuronale Netz": [
          "Das neuronale Netz erstellen",
          "Daten vorbereiten",
          "Metriken",
          "Das Training",
          "Plotten"
        ],
        "Alternativen für Mnist": [
          "Mnist in kurzem TF 2.0 Code",
          "Convolutional Neural Networks"
        ],
        "Übung": [
          "Fashion MNIST"
        ],
        "Google Colab": [
          "Google Colab"
        ],
        "Projekt: Lego Steine erkennen": [
          "Datensatz",
          "Datensatz aufteilen",
          "Daten laden",
          "Das neuronale Netz",
          "Speichern, Laden",
          "Graphen plotten"
        ],
        "Objekt-Segmentierung": [
          "Daten laden",
          "Das neuronale Netz",
          "Training"
        ],
        "Generative Adversarial Networks - Bilder erstellen": [
          "Daten",
          "Bilder generieren mit dem Generator",
          "Der Discriminator",
          "Die Fehler",
          "Die Trainingsschleife",
          "Das Training"
        ],
        "Textverarbeitung mit dem Imdb Datensatz": [
          "Daten",
          "Daten #2",
          "Das Modell",
          "Vorhersagen",
          "Mit Rekurrenten Netzen"
        ]
      },
      "requirements": [
        "Dieser Kurs richtet sich an Python-Programmierer. Ein wenig Python-Erfahrung wird vorausgesetzt."
      ],
      "description": "Dieser Kurs bietet einen Einstieg zum berühmten Framework Tensorflow 2 von Google, welches weltweit für neuronale Netze genutzt wird.\nIn der neuesten Version ist nun auch Keras enthalten und bietet eine einfache Schnittstelle zu einem sehr komplexen Thema. So können schwere Projekte schnell und intuitiv realisiert werden.\nIn diesem Kurs werden einige Praxisprojekte erstellt, welche verschiedene und ähnliche Herangehensweisen an\n* Bilderkennung\n* Bildgenerierung\n* Texterkennung\n* Plotting\n* Speichern von Zuständen\n* und mehr\nbietet.\nDie Projekte finden auf bekannten, berühmten Datensätzen statt. Jeder muss zur Bilderkennung den MNIST Datensatz genutzt haben. Es gibt jedoch auch Abwandlungen wie den Fashion Mnist Datensatz. Bildgenerierung mit GANs - Generative Adversarial Networks - ist mit Deepfakes allgegenwärtig, es scheint nur um so wichtiger, sich mit solchen Themen auseinanderzusetzen. Texterkennung ist ein ebenso spannendes Thema, etwa mit dem Imdb Datensatz, welcher Reviews enthält, die natürlich eine gewisse Stimmung enthalten. All das und noch vieles mehr können neuronale Netze lernen.\nDer Kurs wird zudem natürlich ständig erweitert werden um weitere Projekte - etwa mehr vom selben zur Übung oder aber neues wie Videoerkennung.\nDazu benötige ich euer Feedback, damit ich den Kurs noch besser gestalten kann.\nWeitere mögliche Themen sind:\n* Videoerkennung\n* Videogenerierung\n* Audio\n* Reinforcement Learning an Spielen und mehr\nDaher - schnell zuschlagen, lange profitieren, denn der Kurs wächst dynamisch.\nDazu gehören selbstverständlich auch die übliche 30-Tage Rückgabegarantie und lebenslanger Zugriff.\nViel Spaß",
      "target_audience": [
        "Python-Entwickler mit fortgeschrittenen (jedoch keinen Experten-)Fähigkeiten mit Interesse an Data Science"
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第28部 LLM 對齊革命 - PPO X DPO 策略優化",
      "url": "https://www.udemy.com/course/generative_ai_28/",
      "bio": "關於KL懲罰，Frozen Model，Entropy，Advantage Function ，Value Function，Bradley-Terry 偏好模型",
      "objectives": [
        "深入瞭解 PPO Policy Gradient & PPO Clipped Objective",
        "深入瞭解 Value Function Loss & Policy Entropy & Total PPO Loss PPO 總損失",
        "深入瞭解什麼是 DPO & 如何解決約束優化問題",
        "學會如何使用 Pytorch實現 SFT 監督微調",
        "學會如何使用 Pytorch實現 DPO 直接偏好優化 Direct Preference Optimization"
      ],
      "course_content": {
        "課程準備": [
          "課程工具準備",
          "如何使用uv 作為包管理器和項目管理工具"
        ],
        "PPO 的原理 & 如何用 Pytorch 實現 PPO": [
          "什麼是 PPO Policy Gradient & PPO Clipped Objective & Value Function Loss",
          "如何使用 Pytorch 訓練 PPO 並計算對數機率 & KL 散度 & 策略熵"
        ],
        "DPO 的原理&如何使用 Pytorch 實現 DPO": [
          "什麼是 DPO & 如何解決約束優化問題",
          "如何使用 Pytorch實現 SFT 監督微調",
          "如何使用 Pytorch實現 DPO 直接偏好優化 Direct Preference Optimization"
        ]
      },
      "requirements": [
        "一臺電腦"
      ],
      "description": "(Ken Cen出品)Generative AI第28部 LLM 對齊革命 - PPO X DPO 策略優化\n\n\n課程會在(Ken Cen出品)Generative AI第27部的基礎上，深入發掘 PPO 和 DPO 對修正 AI 行為背後的原理的 Pytorch 實際操作。\n\n\n為什麼要學習 PPO 和 DPO？\n隨著大模型快速發展，我們愈來愈關注一個核心問題：\n模型的回答是否符合人類偏好？是否「對齊」人類的價值與需求？\n本課程介紹的 PPO（Proximal Policy Optimization） 和 DPO（Direct Preference Optimization） 是目前最主流的兩種對齊技術。掌握這些技術，你將能：\n訓練出 對使用者更友善、更精確的 LLM\n學會如何實作如 ChatGPT背後的策略調整機制\n跟上大型 AI 公司對「對齊問題（Alignment）」的技術趨勢\n\n\n課程內容重點介紹\nPPO 對齊技術精解\nPPO 損失函數組成與剪裁（Clipping）\n避免模型劇烈更新，提升穩定性。\nAdvantage Function & Value Function\n評估「採取行動比預期好多少」，是強化學習的核心。\nEntropy（熵）獎勵：鼓勵探索、避免陷入局部最優\n熵越高 → 模型更願意嘗試新策略。\nFrozen Model & KL懲罰：防止「作弊」學壞\n固定參考模型，並限制與其差異，防止模型偏離人類偏好。\nDPO 對齊革命性新方法\n從獎勵模型到 Bradley-Terry 偏好模型\n從 pairwise 比較中學習人類偏好。\nDPO 損失函數推導與數學解析解\n理論 + 工程實作，讓你掌握真正原理。\nKL 散度約束與 Lagrange 乘子技術\n精準控制策略偏移與對齊速度。\nPyTorch實戰：從理論到實作\n你將學會如何用 PyTorch 完整實現：\nPPO 訓練流程：包括策略梯度、值函數損失、熵項與總損失計算\nDPO 訓練流程：用偏好資料直接優化策略，無需建立獎勵模型\nSFT（Supervised Fine-Tuning）監督微調流程\n計算 Log Probability、KL 散度、Entropy 等關鍵指標",
      "target_audience": [
        "對 AI 感興趣的學員",
        "AI 高薪從業者"
      ]
    },
    {
      "title": "UNet（TensorFlow2）图像语义分割实战：训练自己的数据集",
      "url": "https://www.udemy.com/course/unet-tensorflow2/",
      "bio": "计算机视觉图像语义分割实战",
      "objectives": [
        "学习TensorFlow2版本的U-Net图像语义分割技术来训练自己的数据集",
        "学习labelme图像分割标注工具",
        "掌握多类物体的图像分割方法",
        "学习UNet语义分割原理"
      ],
      "course_content": {
        "课程介绍": [
          "课程介绍"
        ],
        "图像语义分割介绍": [
          "图像分割任务及数据集",
          "图像分割性能指标"
        ],
        "U-Net图像语义分割原理": [
          "U-Net图像语义分割原理"
        ],
        "Kaggle盐体识别竞赛U-Net实战(TensorFlow2)": [
          "安装TensorFlow2（ubuntu和windows）",
          "Kaggle盐体识别：比赛介绍",
          "Kaggle盐体识别：数据集下载及整理",
          "Kaggle盐体识别：U-Net实战"
        ],
        "Pothole语义分割U-Net实战（TensorFlow2）": [
          "labelme图像标注",
          "制作mask图像",
          "Pothole分割U-Net实战"
        ],
        "Kaggle细胞核分割竞赛U-Net实战(TensorFlow2)": [
          "Kaggle细胞核分割-比赛介绍",
          "Kaggle细胞核分割U-Net实战"
        ]
      },
      "requirements": [
        "熟悉Python和TensorFlow2"
      ],
      "description": "U-Net是一种基于深度学习的图像语义分割方法，尤其在医学图像分割中表现优异。\n本课程将手把手地教大家使用labelme图像标注工具制作自己的数据集，生成Mask图像，并使用U-Net训练自己的数据集，从而能开展自己的图像分割应用。\n本课程首先讲述图像分割的任务说明、常用数据集，然后介绍UNet网络的原理。\n本课程有三个项目实践：\n(1) Kaggle盐体识别比赛 ：利用U-Net进行Kaggle盐体识别\n(2) Pothole语义分割：对汽车行驶场景中的路坑进行标注和语义分割\n(3) Kaggle细胞核分割比赛 ：利用U-Net进行Kaggle细胞核分割\n本课程使用TensorFlow2版本的U-Net，在Ubuntu系统上用Jupyter Notebook做项目演示。 包括：数据集标注、数据集格式转换和Mask图像生成、编写U-Net程序文件、训练自己的数据集、测试训练出的网络模型、性能评估。项目代码也可在Windows上运行，课程提供Windows环境搭建方法。\n\n\n本课程提供项目的数据集和Python程序代码。",
      "target_audience": [
        "希望掌握TensorFlow2版本的U-Net图像语义分割实战技术的同学们"
      ]
    },
    {
      "title": "Análisis Exploratorio de Datos con Python y R",
      "url": "https://www.udemy.com/course/analisis-exploratorio-de-datos-con-python-y-r/",
      "bio": "Análisis y manejo de datos con Python y R.",
      "objectives": [
        "Qué es el análisis exploratorio de datos",
        "Qué es la estadística, medidas de tendencia central y de dispersión",
        "Manejo de datos en Python y R: transformación, agrupación, filtros y otros.",
        "Principales librerías de Python y R para el manejo y análisis de datos",
        "Gráficas y otras técnicas avanzadas en Python y R"
      ],
      "course_content": {
        "Introducción": [
          "Introducción curso",
          "Contenido del curso"
        ],
        "Introducción al análisis de datos": [
          "Análisis exploratorio de datos.",
          "Definición de estadística",
          "Cuestionario estadística"
        ],
        "Herramientas para el análisis exploratorio de datos": [
          "Introducción sección 3",
          "Interfaz programas",
          "Interfaz Jupyter Notebook (Python)",
          "Interfaz R-Studio (R)",
          "Tipos de datos en Python y R",
          "Tipos de datos en Python y R",
          "Manejo de datos numéricos",
          "Manejo de datos numéricos",
          "Actividad práctica - análisis de estructuras de datos",
          "Actividad práctica - análisis de estructuras de datos (Python)",
          "Actividad práctica - análisis de estructuras de datos (R)",
          "Principales librerías de Python y R",
          "Cuestionario pasos básicos de Python y R"
        ],
        "Análisis y procesamiento de los datos": [
          "Introducción",
          "Exportación e importación de bases de datos",
          "Apertura de bases de datos con Python",
          "Apertura de base de datos con R",
          "Importación y exportación base de datos con Python",
          "Importación y exportación base de datos R",
          "Actividad apertura, importación y exportación de bases de datos",
          "Exploración, entrando a la base de datos",
          "Exploración base de datos en Python",
          "Exploración base de datos R",
          "Actividad exploración de datos",
          "Transformación y otras técnicas para el manejo de datos",
          "Tranformación de base de datos en Python",
          "Transformación base de datos R",
          "Actividad tranformación bases de datos",
          "Unión de bases de datos",
          "Unión de bases de datos en Python",
          "Unión de bases de datos en R",
          "Actividad unión de bases de datos",
          "Prueba final del capítulo",
          "Prueba final del capítulo"
        ],
        "Gráficos para análisis de datos": [
          "Introducción",
          "Gráficos de porcentajes",
          "Gráficos de barras",
          "Gráfico con datos de gapminder",
          "Prueba de gráficos"
        ],
        "Medidas de tendencia central y de dispersión": [
          "Introducción medidas de tendencia central",
          "Medidas de tendencia central en Python",
          "Medidas de tendencia central en R",
          "Gráficos de tendencia central en Python",
          "Gráficos de tendencia central en R",
          "Actividad medidas de tendencia central",
          "Actividad medidas de tendencia central",
          "Introducción medidas de dispersión",
          "Medidas de dispersión en Python",
          "Medidas de dispersión en R",
          "Actividad medidas de dispersión"
        ]
      },
      "requirements": [
        "Lo único que se necesitan son las ganas de aprender y un computador que soporte los programas que se van instalar.",
        "Algo de matemáticas para realizar operaciones sencillas y algunos conocimientos básicos de estadística son un plus.",
        "Manejo de computadores para la instalación de programas y para entender qué se hace a través de la programación."
      ],
      "description": "El análisis exploratorio de datos (EDA, por sus siglas en inglés, Exploratory Data Analysis) es el proceso o tratamiento estadístico al cual se someten los datos de una muestra con la que se busca representar a una población. Incluye la elaboración de gráficos y estadísticos que permiten explorar la distribución de los datos, identificando características como: valores atípicos o outliers, saltos o discontinuidades, concentraciones de valores, forma de la distribución, etc. Esto permite conocer la naturaleza de los datos, entender su distribución y explorarlos mediante análisis estadístico, para posteriormente realizar el mejor modelo posible que permita sacar conclusiones sobre dichos datos. Este curso puede ser tenido en cuenta como un paso inicial para arrancar tu carrera como científico de datos (Data Scientist).\n\n\nSección 1: Día a día vivimos rodeados de datos y estadísticas: cuando abrimos el periódico, cuando hacemos una transacción financiera, cuando vemos el noticiero, entre otros. Tenemos que asegurarnos de entender qué hay detrás de esos datos para asegurarnos de si debemos confiar o no en ellos. Además, podemos aprender a generarlos. Esta sección contiene la introdicción del curso y los pasos a seguir para completarlo satisfactoriamente.\nSección 2: Esta parte del curso es una introducción a qué es la estadística, qué es el análisis exploratorio de datos y cuáles son las principales diferencias entre la estadística descriptiva y la inferencial. Además, veremos cuáles son los programas que se utilizarán durante el curso y cuál es la razón de que sean estos y no otros. Hasta acá, las dos primeras secciones del curso son cortas y concisas. En adelante, las siguientes son mucho más largas y contienen más material.\nSección 3: En esta sección vamos a ver cómo se descargar los programas que soportan los lenguajes de programación Python y R, y vamos a ver cómo instalarlos en los dispositivos con sistema operativo Mac y Windows para poder usarlos de la mejor manera posible. Además, estudiaremos sus interfaces, para entender cómo funcionan y qué características tienen. Finalmente, veremos cuáles son las principales estructuras de datos en esos dos lenguajes de programación y cómo deben ser manejadas para no obtener errores en los resultados al manejar bases de datos y/o al crear nuevas variables.\nSección 4: Una vez hemos instalado los principales programas que nos permite ejecutar Python y R, y habiendo explorado los principales tipos y estructuras de datos en estos dos lenguajes, esta sección nos introduce al Análisis Exploratorio de Datos (EDA, por sus siglas en inglés), a través de un conjunto de funciones iniciales que traen consigo las principales librerías descargadas e instaladas en la sección final del tema anterior: Pandas, Numpy y Matplotlib, en el caso de Python y; dplyr, tidyr y ggplot en R. Aprenderemos a importar bases de datos de Excel y otro tipo de archivos con extensión csv, siglas que responden a Comma Separated Values (en inglés) o valores separados por comas, así como archivos del programa estadístico Stata. A las variables contenidas en las bases abiertas les aplicaremos algunas transformaciones, agrupaciones, filtros y otras técnicas para su respectivo manejo y exploración. ¡Vamos con toda!\nSección 5: Adicional a las librerías utilizadas para hacer transformaciones y manejos directamente a la base de datos, Python y R también tienen paquetes especializados para la generación de gráficos a partir de datos contenidos en datasets o a partir de datos que se le pueden indicar dentro del mismo código al gráfico deseado. En este caso, estaremos viendo algunos de los gráficos más utilizados en el análisis de datos, por lo básicos, pero efectivos que son a la hora de mostrar de una forma más agradable la información contenida en la base de datos: gráfico de barras, gráficos de porcentajes como el pie o torta, y otros gráficos un poco más avanzados.\nSección 6: Ya ha conocido los dos programas y lenguajes de programación usados principalmente en la ciencia de datos, así como sus principales librerías, paquetes y funciones. Además, ha trabajado algunos de los manejos que se les pueden dar a los datos a través de Python y R, como filtros, agrupaciones, unión o pegado. Ahora, vamos a ver uno de los conceptos y mediciones primordiales de la estadística descriptiva: las medidas de tendencia central. Veremos acá la media, la mediana, la moda y los percentiles (cuartiles, quintiles, entre otros), así como los histogramas y boxplot para verlos gráficamente.",
      "target_audience": [
        "Personas interesadas en el manejo de software estadísticos y de lenguajes de programación para el análisis de datos, sin importar si son profesionales o no.",
        "Desarrolladores principantes de Python y/o R con interés en la ciencia de datos y en la estadística.",
        "Estudiantes y trabajadores que quieren soltar el Excel y aprender a manejar datos y hacer gráficos con Python y R."
      ]
    },
    {
      "title": "Data science pour le E-Business et le E-Marketing | 2025",
      "url": "https://www.udemy.com/course/data-science-pour-le-e-business-et-le-e-marketing/",
      "bio": "Les leviers du marketing digital, stratégie SEM et SEO, Marketing de contenu, SMSing et emailing / Analyse facebook ads",
      "objectives": [
        "Maîtriser les compétences essentielles en matière de Data Science (science des données)",
        "Comparaison marketing et marketing digital",
        "Les leviers du marketing digital",
        "Stratégie SEM et SEO",
        "Marketing de contenu",
        "SMSing et emailing",
        "Analyse facebook ads",
        "Google ads"
      ],
      "course_content": {
        "Introduction": [
          "Bienvenue !!",
          "Dr. Firas Partenaire formateur Udemy",
          "Présentation rapide : \"Qui suis-je ?\"",
          "Les méthodes et outils pédagogiques de la formation",
          "FAQ Udemy",
          "Bienvenue sur Udemy ! Présentez-vous !"
        ],
        "Atelier Marketing et marketing digital": [
          "Introduction aux marketing",
          "Marketing digital de A à Z",
          "Les leviers de marketing digital",
          "Marketing de contenu",
          "Stratégie SEM et SEO",
          "Analyse FB Ads",
          "Marketing des réseaux sociaux",
          "Google ADS et publicité en ligne",
          "Email marketing",
          "Inbound vs outbound marketing"
        ],
        "Data science et Marketing digital": [
          "Job profil DATA Analyst",
          "Transformation du data science sur le marketing digital",
          "Panorama du marché: avancement, arbitrage et impact sur le marketing digital",
          "Data mining vs Data science",
          "Big Data et le modéle 5V",
          "Transformer votre équipe en data scientist",
          "Retour de l'expérience Data science"
        ],
        "ATELIER - PYTHON": [
          "Support de cours",
          "Installation Python 3.8.3",
          "Exécuter le programme Python",
          "Les fonctions",
          "Les opérations de base",
          "Ordre et priorité",
          "Les types de nombre part-1",
          "Les types de nombre part-2",
          "Fonction INPUT",
          "Manipulation de chaine de caractère",
          "Manipulation de chaine de caractère part-2",
          "Changer les types avec les fonctions prédéfini avec Python",
          "Changer les types dans le input",
          "Les variables",
          "Changer les types des variables",
          "Les règles pour la création des variables",
          "Opérations sur place",
          "Type boolean",
          "Lancer l'éditeur de code Atom",
          "Les structures de contrôle",
          "Plusieurs conditions de contrôle",
          "Plusieurs conditions de contrôle Part-2",
          "Plusieurs conditions de contrôle Part-3",
          "Les conditions logiques",
          "Exercice avec les conditions",
          "Correction Exercice avec les conditions",
          "Structure de contrôle avec boucle While",
          "Structure de contrôle avec boucle While Part-2",
          "Structure de contrôle avec boucle While Part-3",
          "Création des listes",
          "Manipulation de la liste Part-1",
          "Manipulation de la liste Part-2",
          "Manipulation de la liste Part-3",
          "Manipulation de la liste Part-4",
          "Les recherches dans une liste",
          "Les fonctions dans les listes",
          "Application des méthodes sur les listes",
          "EXERCICE : manipulation des listes",
          "Exercice avec les listes",
          "Manipulation des listes avec les boucles",
          "La boucle FOR Part-1",
          "La boucle FOR Part-2",
          "La boucle FOR Part-3",
          "Création des dictionnaires",
          "Chercher la valeur d'une clé",
          "Mettre une liste dans un dictionnaire",
          "Ajouter un nouveau clé à un dictionnaire",
          "Recherche d'une clé",
          "Méthode Get",
          "Méthode KEYS",
          "Exercice avec la manipulation des dictionnaires",
          "Exercice avec les dictionnaires",
          "Définition d'une fonction",
          "Création d'une fonction",
          "Utilisation de RETURN dans une fonction",
          "Exercice: Fonction",
          "Exercice avec une fonction",
          "Les types d'erreurs dans Python"
        ],
        "Obtenir le certificat": [
          "Obtenir le certificat"
        ],
        "BONUS": [
          "Bonus"
        ]
      },
      "requirements": [
        "Aucune connaissance technique particulière n’est nécessaire"
      ],
      "description": "Les data scientists avec une spécialisation Marketing/Connaissance Client sont très demandés.\nLa transformation digitale et le web 2.0 invitent donc les entreprises à rechercher des compétences à haute valeur ajoutée. Des experts qui sauront extraire et analyser des données pour prédire des comportements d’achat de produits et de services.\nJe vous propose deux parcours dédiés à ce domaine.\nVous allez apprendre à :\nComparaison marketing et marketing digital\nLes leviers du marketing digital\nSynthétiser le cycle de vie de la donnée\nStratégie SEM et SEO\nMarketing de contenu\nSMSing et emailing / Analyse facebook ads\nGoogle ads\nPython\nNotez bien :\nLa formation se déroulera sous forme de cours théorique & pratique, d'exemples concrets et d'ateliers pour permettre aux participants de mettre en pratique les concepts appris. Des exercices, des mises en situation et des études de cas seront utilisés pour renforcer les connaissances.\n\n\nRessources d’apprentissage complémentaires :\nAtelier en ligne\nDocumentation\nConsultez des exemples de tableaux de bord, de rapports et de fichiers de bureau.\nEnfin, je m'engage à vous fournir la formation la plus complète possible sur Udemy pour vous permettre de réussir dans votre apprentissage.\nJe m'engage à répondre rapidement à vos questions pour vous aider à comprendre les concepts de la formation.\nJe vais ajouter des cas pratiques sur demande pour vous donner des exemples concrets de ce que vous apprenez.\nJe vais vous accompagner avec des cas pratiques et d'autres ressources utiles pour vous aider à mettre en pratique ce que vous apprenez.\nCes ajouts de vidéos seront, bien entendu, gratuits si vous avez acquis la formation.\nComment me contacter ? Je reste disponible dans la rubrique Question/Réponses d'Udemy pour répondre à vos questions.\nÀ la fin de ce cours, si vous le suivez en entier et réussissez l'ensemble des quizz : Obtenez votre certification électronique à insérer dans votre CV et profil LinkedIn.\n\nDr. Firas",
      "target_audience": [
        "Ce cours a pour objectif de donner les outils nécessaires et essentiels à l'analyse de données recueillis dans le cadre des expériences."
      ]
    },
    {
      "title": "TiDB数据库从零开始",
      "url": "https://www.udemy.com/course/tidb-opz/",
      "bio": "全面介绍国产TiDB数据库相关知识",
      "objectives": [
        "学习并掌握TiDB的体系架构",
        "学习并掌握TiDB安装部署",
        "学习并掌握TiDB的管理与维护",
        "学习并掌握TiDB的诊断监控"
      ],
      "course_content": {
        "TiDB国产数据库从零开始": [
          "TiDB课程简介",
          "Demo演示：TiDB分布式数据库"
        ],
        "第01章-TiDB的体系架构": [
          "01-01-TiDB的体系架构概述",
          "01-02-TiDB简介",
          "01-03-TiDB的核心功能及与MySQL的兼容性",
          "01-04-TiDB的整体架构",
          "01-05-TiKV的架构",
          "01-06-TiKV的底层存储：RocksDB",
          "01-07-键值对与Region",
          "01-08-MVCC机制",
          "01-09-TiDB实例的功能",
          "01-10-TableID和RowID",
          "01-11-表数据和KV的映射关系",
          "01-12-TiDB实例的SQL层",
          "01-13-TiDB的调度架构：PD实例",
          "01-14-什么是TSO？",
          "01-15-使用TIDB的命令行工具",
          "01-16-使用TiKV的命令行工具",
          "01-17-使用PD的命令行工具",
          "01-18-TiDB集群的配置文件"
        ],
        "第02章-安装部署TiDB数据库": [
          "02-01-安装国产银河麒麟Linux操作系统",
          "02-02-使用TiUP部署本地TiDB测试集群",
          "02-03-免密码登录的原理和配置",
          "02-04-使用TiUP部署TiDB伪分布式集群",
          "02-05-使用TiUP部署TiDB全分布式集群",
          "02-06-离线部署TiDB数据库集群",
          "02-07-使用TiDB的审计日志",
          "02-08-安装MySQL数据库"
        ],
        "第03章-管理用户安全": [
          "03-01-管理用户安全概述",
          "03-02-TiDB的用户管理",
          "03-03-用户的资源限制",
          "03-04-用户的资源限制示例",
          "03-05-密码的复杂度设置",
          "03-06-用户密码的过期设置与用户的锁定",
          "03-07-丢失了root用户密码",
          "03-08-TiDB的权限系统",
          "03-09-用户权限的验证过程",
          "03-10-权限与用户信息",
          "03-11-使用grant语句和revoke语句",
          "03-12-TiDB的权限生效机制和访问控制",
          "03-13-角色的作用",
          "03-14-基于TiDB角色的访问控制",
          "03-15-角色的授权表"
        ],
        "第04章-操作TiDB数据库对象": [
          "04-01-本章课程概述",
          "04-02-TiDB的数据类型",
          "04-03-AUTO_INCREMENT与AUTO_RANDOM",
          "04-04-TiDB表的基本操作",
          "04-05-数据的约束条件",
          "04-06-关于检查约束",
          "04-07-表中的碎片",
          "04-08-查看表的统计信息",
          "04-09-收集表的统计信息",
          "04-10-Placement Rules in SQL",
          "04-11-使用临时表",
          "04-12-什么是分区表",
          "04-13-使用分区表",
          "04-14-使用缓存表",
          "04-15-使用表的预分区",
          "04-16-索引的基本知识",
          "04-17-主键索引之聚簇索引",
          "04-18-主键索引之非聚簇索引",
          "04-19-二级索引",
          "04-20-其他特殊的索引",
          "04-21-TiDB中的视图"
        ],
        "第05章-事务与锁": [
          "05-01-事务与锁概述",
          "05-02-事务简介与特征",
          "05-03-控制事务的操作",
          "05-04-事务的并发与隔离级别",
          "05-05-事务的脏读问题",
          "05-06-事务的不可重复读",
          "05-07-非事务DML语句",
          "05-08-TiDB中锁的类型",
          "05-09-悲观锁和悲观事务",
          "05-10-乐观锁和乐观事务",
          "05-11-死锁",
          "05-12-监控TiDB的锁"
        ],
        "第06章-备份与恢复": [
          "06-01-备份与恢复概述",
          "06-02-全量（快照）备份与恢复",
          "06-03-全量备份的流程",
          "06-04-全量恢复的流程",
          "06-05-日志备份的流程",
          "06-06-日志恢复的流程",
          "06-07-备份集群快照",
          "06-08-备份 TiDB 集群指定库表的数据",
          "06-09-备份统计信息",
          "06-10-备份数据加密",
          "06-11-恢复集群快照备份数据",
          "06-12-恢复备份数据中指定库表的数据",
          "06-13-恢复加密的快照备份数据",
          "06-14-启动日志备份",
          "06-15-启动加密日志备份任务",
          "06-16-管理日志备份任务",
          "06-17-恢复到指定时间点PITR",
          "06-18-使用Dumpling导出数据",
          "06-19-使用TiDB Lightning导入数据",
          "06-20-什么是闪回",
          "06-21-闪回集群",
          "06-22-闪回数据库和闪回表"
        ],
        "第07章-从MySQL迁移数据": [
          "07-01-从MySQL迁移数据概述",
          "07-02-TiDB的数据迁移工具",
          "07-03-TiDB DM快速上手",
          "07-04-数据源操作",
          "07-05-配置数据迁移的黑白名单",
          "07-06-配置需要过滤的操作",
          "07-07-配置数据源表到目标TiDB表的映射",
          "07-08-合并MySQL的分库分表",
          "07-09-分库分表迁移的悲观模式和乐观模式",
          "07-10-通过SQL表达式过滤DML",
          "07-11-处理出错的DDL语句",
          "07-12-部署TiDB DM集群"
        ],
        "第08章-从TiDB数据同步": [
          "08-01-从TiDB数据同步概述",
          "08-02-TiCDC简介",
          "08-03-快速上手TiCDC",
          "08-04-什么是Changefeed？",
          "08-05-同步数据到MySQL",
          "08-06-Kafka简介与环境搭建",
          "08-07-测试Kafka的消息机制",
          "08-08-同步数据到Kafka",
          "08-09-Changefeed的日志过滤器",
          "08-10-Changefeed的事件过滤器",
          "08-11-TiCDC的双向复制",
          "08-12-灾难场景的最终一致性复制",
          "08-13-TiCDC集群的安装部署",
          "08-14-TiCDC集群的运维管理"
        ],
        "第09章-TiSpark与TiProxy": [
          "09-01-TiDB工具箱概述",
          "09-02-大数据的基础",
          "09-03-大数据与Spark基础",
          "09-04-部署Spark环境",
          "09-05-Spark的客户端工具",
          "09-06-什么是Spark SQL？",
          "09-07-使用TiSpark",
          "09-08-使用TiSpark连接TiDB和其他数据源",
          "09-09-TiProxy简介",
          "09-10-快速上手TiProxy",
          "09-11-部署TiProxy集群环境",
          "09-12-基于标签的负载均衡",
          "09-13-基于地理位置的负载均衡"
        ]
      },
      "requirements": [
        "无需编程经验"
      ],
      "description": "本课程对数据库的研发人员、数据库构师、数据库运维人员而设置，将重点覆盖TiDB数据库。具体内容包括：数据库的体系架构与安装配置、数据库的用户管理、数据库的并发与锁、备份与恢复技术、数据库的监控优化等知识。通过课程学习让学员全面系统的掌握TiDB。\n\n\nTiDB是PingCAP公司自主设计、研发的开源分布式关系型数据库，是一款同时支持在线事务处理与在线分析处理(Hybrid Transactional and Analytical Processing,HTAP)的融合型分布式数据库产品，具备水平扩容或者缩容、金融级高可用、实时HTAP、云原生的分布式数据库、兼容MySQL协议和MySQL生态等重要特性。目标是为用户提供一站式OLTP(Online Transactional Processing)、OLAP(Online Analytical Processing)、HTAP解决方案。TiDB适合高可用、强一致要求较高、数据规模较大等各种应用场景。",
      "target_audience": [
        "想要系统学习国产TiDB数据库的学员"
      ]
    },
    {
      "title": "Aprendizaje Automático con Python en Google Colab",
      "url": "https://www.udemy.com/course/aprendizaje-automatico-con-python-en-google-colab/",
      "bio": "Domina las herramientas clave para convertir datos en predicciones.",
      "objectives": [
        "Domina fundamentos prácticos para ML",
        "Implementar modelos IA con Python en un entorno profesional",
        "Realizar proyectos completos y construir un portafolio",
        "Adquirir las competencias para adquirir un trabajo en el sector"
      ],
      "course_content": {
        "Introduccion": [
          "Video Introductorio"
        ],
        "Módulo 1: Introducción y Configuración": [
          "Introducción a Google Colab",
          "Cartilla Introducción a Google Colab",
          "Fundamentos de Python para ML",
          "Cartilla Python"
        ],
        "Módulo 2: Preprocesamiento de Datos": [
          "Limpieza de Datos",
          "Cartilla Limpieza de Datos",
          "Feature Engineering",
          "Cartilla Ingenieria de Características"
        ],
        "Módulo 3: Modelos Supervisados": [
          "Regresión",
          "Cartilla Regresión",
          "Clasificación",
          "Cartilla Clasificación"
        ],
        "Módulo 4: Modelos No Supervisados": [
          "Clustering",
          "Cartilla Clustering",
          "Reducción de Dimensionalidad",
          "Cartilla Reduccion de Dimensionalidad"
        ],
        "Módulo 5: Redes Neuronales y Deep Learning": [
          "Redes Neuronales Básicas",
          "Redes Neuronales",
          "CNN para imágenes",
          "Redes Convolucionales"
        ],
        "Módulo 6: Proyecto Final": [
          "Proyecto: Sistema de clasificación de imágenes"
        ]
      },
      "requirements": [
        "Python",
        "Google colab"
      ],
      "description": "Descubre el poder de la inteligencia artificial desde cualquier lugar con nuestro curso integral de Aprendizaje Automático con Python utilizando Google Colab. Este curso está diseñado para entusiastas de los datos, desarrolladores, estudiantes y profesionales que desean dominar los fundamentos y las técnicas avanzadas del machine learning sin la necesidad de una configuración compleja de software o hardware. Google Colab, una plataforma basada en Jupyter Notebooks que se ejecuta en la nube, será tu laboratorio; solo necesitas un navegador web y una cuenta de Google para comenzar a crear modelos inteligentes.\nA lo largo del curso, te sumergirás en el ecosistema de Python, utilizando bibliotecas esenciales como NumPy y Pandas para la manipulación de datos, Matplotlib y Seaborn para la visualización, y Scikit-learn para implementar, entrenar y evaluar algoritmos clásicos de aprendizaje supervisado y no supervisado. Cubriremos desde modelos de regresión y clasificación hasta técnicas de clustering y reducción de dimensionalidad, todo de manera práctica. Aprenderás a optimizar hiperparámetros, evitar el sobreajuste y entender las métricas clave para medir el rendimiento de tus modelos.\nLa ventaja de usar Colab es innegable: acceso gratuito a GPUs y TPUs, lo que te permitirá entrenar modelos más rápido y trabajar con conjuntos de datos más grandes. Al finalizar, no solo tendrás una base sólida en los principios del machine learning, sino también un portafolio de proyectos prácticos que demuestran tu capacidad para resolver problemas reales. Desbloquea el potencial de los datos y da el primer paso hacia una carrera en una de las fields más demandadas de la tecnología.",
      "target_audience": [
        "Profesionales de todas las disciplinas"
      ]
    },
    {
      "title": "Mastering Power BI: From Basics to Advanced Analytics",
      "url": "https://www.udemy.com/course/professional-course-for-data-analysis-using-power-bi/",
      "bio": "Data Analysis Using Power BI from Scratch to Professional Level",
      "objectives": [
        "1-How To Mak Cleaning and Transformation to Data by Using Power Query Editor (Append, Merge, Group by, Remove Columns, Split Columns, Conditional Columns)",
        "2-Make Relationships between tables by using Primary Kay and Foreign Key , Create Measures and New Columns By Using DAX ,, Create Calendar Table",
        "3-Analyzing Data By Using DAX Functions",
        "4-Using Different Charts To Create Creative Dashboard and Professional Report , 5-Working on Real Data and Many Projects"
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Powe Query Editor in Power BI for Making Data Cleaning and Transformation": [
          "Introduction To Data Analysis",
          "How To Get Data To Power BI",
          "How To Clean Data",
          "How To Merge Columns and How To Split Columns",
          "Using Group By in Power BI",
          "Using Append Files in Power BI",
          "Using Merge Files in Power BI",
          "Using Custom Column and Conditional Column in Power BI"
        ],
        "Data Modeling , DAX , Calendar Table": [
          "How To Import and Load Data in Power BI",
          "Meke Relationships Between Tables in Power BI",
          "Make Calendar Table in Power BI",
          "DAX (Create Measures For KPI'S)Part1",
          "DAX (Create Measures For KPI'S) Patr2"
        ],
        "Create Professional Report by Using Different Visualization in Power BI": [
          "Clean Data and Load it in Power BI",
          "Creat Measures By DAX",
          "Use Different Visualization in Power BI(Card , Pie Chart , Donte Chart )",
          "Use Different Visualization in Power BI(Area Chart , Line Chart ,Funnel Chart",
          "Use Different Visualization in Power BI(TreeMap Chart , Ribbon Chart )",
          "Use Different Visualization in Power BI(Table Chart , Matrix Chart , Gauge Chart",
          "Use Different Visualization in Power BI(Slicer , Map Chart )"
        ]
      },
      "requirements": [
        "No need to know anything before taking this course",
        "No need any thing before this course"
      ],
      "description": "In this Course You Will Learn Everything Related to Power BI to Make Data Analysis and Professional Report :\n1-Power Query Editor in Excel To Clean and Transform Data\n\n\n(Remove Columns , Remove Rows , Merge Columns , Split Columns , Conditional Columns , Custom Columns ,Append Queries , Merge Queries, Select Data From Folder, Data Types ,Statistics , Standard, Rounding, Group by)\n\n\n2-Pivot Table\n\n\n3-Relationships between tables using Primary Key and Foreign Key ( Explain Primary Key and Foreign Key Concept )\n\n\n4-Create Measures and Columns using DAX(Data Analysis Expression) to Know KPI'S in Data\n\n\n(Using Calculate Function , SUM Function , SUMX Function , AVERAGEX Function , Divide Function)\n\n\n5-Create Calendar Table to Analyze Data Based in Many Different Dates (Day , Month , Year , Quarter)\n\n\nAnalyzing Data by Using Day of Month or Day of Year or Day of Quarter ,, Analyzing Data by Using Month of Specific Year or Month of Specific Quarter ,, Analyzing Data By Specific Quarter or For All Quarters of all Year ,, Analyzing Data for Specific Year or all Years of Data\n\n\n6-Analysisng Data Using Many Functions by DAX\n\n\n7-Making Professional Dashboard By using Different  Charts\n\n\nUsing Par Chart , Pie Chart , Column Chart , Line Chart , Area Chart , Waterfall Chart , Ribbon Chart , Map Chart , Guage Chart , Slicers , Card Chart , and more",
      "target_audience": [
        "This Course for any one want to learn data analysis field there is no need to any background for this course ,, in this course you will learn in details many things",
        "for any one want to learn data analysis course"
      ]
    },
    {
      "title": "Основы работы с данными для бизнес лидеров",
      "url": "https://www.udemy.com/course/dela_data_management/",
      "bio": "На примерах дата проектов в Ритейле, Энергетики, Финансах, Телекома и Нефтегаза",
      "objectives": [
        "Что такое данные? Какие бывают данные. Жизненный цикл данных.",
        "Стандарты и нормативы управления данными. Регулирование данных. Стандарты работы с данными. Этика данных.",
        "Что такое качественные данные? Как обеспечить качество данных? Что такое \"интероперабельность данных\" и как её обеспечить? Основные принципы - рекомендации.",
        "Примеры Дата проектов в отраслевых и кросс-отраслевых организациях (Alfa Bank Казахстан, X5 Retail Group, ИнтерРАО).",
        "Экономические и социальные эффекты от работы с данными. Воздействия и дивиденды полученные от данных. Практические примеры.",
        "Организация хранилищ данных. Обзор инструментов для работы с данными.",
        "Цели, задачи и уровни проектирования модели данных.",
        "Принципы построения информационной безопасности. Формула построения надежной защиты в организации.",
        "Системы анализа данных. Цикл работы с данными: от постановки задач до принятия решений. Визуализация данных и релевантные способы отображения.",
        "Примеры построения Системы управления данными в организациях. (Газпромнефть, PepsiCo в СНГ)."
      ],
      "course_content": {
        "Практика построения системы управления данными.": [
          "Introduction",
          "Базовые вопросы управления данными",
          "Стандарты и нормативы управления данными",
          "Качество данных.",
          "Примеры Дата проектов. Alfa Bank Казахстан.",
          "Примеры Дата проектов. X5 Retail Group.",
          "Примеры Дата проектов. Интер РАО",
          "Круглый стол. Alfa Bank Казахстан, X5 Retail Group, ИнтерРАО",
          "Экономические и социальные эффекты от работы с данными",
          "Экономические и социальные эффекты от работы с данными. Примеры",
          "Организация хранилищ данных",
          "Модели данных",
          "Принципы построения информационной безопасности",
          "Системы анализа данных",
          "Визуализация, как инструмент для быстрого принятия решений",
          "Примеры дата проектов. Газпромнефть",
          "Примеры дата проектов. Pepsico",
          "Формирование каталога данных"
        ]
      },
      "requirements": [
        "Этот курс подойдет всем, кто желает углубить понимание принципов построения систему управления данными."
      ],
      "description": "Что такое управление данными?\nУправление данными - это практика сбора, организации, защиты и хранения данных организации, чтобы их можно было анализировать для принятия бизнес-решений. Поскольку организации создают и потребляют данные с беспрецедентной скоростью, решения по управлению данными становятся необходимыми для анализа огромных объемов данных.\n\n\nУправление данными - это важнейший первый шаг к использованию эффективного анализа данных в масштабе, который позволяет получить важные сведения, повышающие ценность для ваших клиентов и улучшающие итоговые показатели. Благодаря эффективному управлению данными сотрудники всей организации могут находить и получать доступ к достоверным данным для своих запросов.\n\n\nВ этом курсе, на примерах из бизнеса вы изучите принципы и инструменты, которые помогут создать эффективную систему управления данными.  Своим опытом поделятся цифровые лидеры из разных сфер бизнеса, которые участвовали в создании системы управления данными в своих компаниях. Среди них эксперты из Газпромнефть, PepsiCo в СНГ, Альфа банк Казахстан, X5 Retail Group, Сбербанк, Интер РАО и другие.\n\n\nВы изучите:\nЧто такое данные и какой у них жизненный цикл;\nКак обеспечить качество данных;\nКак формировать каталоги данных? Вы поймете зачем нужны каталоги данных и что они включают в себя. вы увидите, как могут выглядеть каталоги данных.\nКак защитить данные;\nВы научитесь использовать визуализацию данных, как инструмент для быстрого принятия решений. Научитесь формировать требования для принятия управленческих решений. Рассмотрим BI инструментарий и релевантные способы отображения.\nКак быстро принимать решения на основе данных;\nКакие экономические и социальные эффекты от работы с данными.\nПреподаватели курса:\n\n\nЮрий Линьков, начальник отдела цифровой экономики, Мегафон\nЕкатерина Линкевич, директор по управлению данными, Альфа-Банк Казахстан\nТигран Саркисов, директор по управлению данными, X5 Retail групп\nРуслан Гарамов, НТЦ газпромнефть\nМихаил Платонов, директор по информационным технологиям, ПепсиКо СНГ\nАлександр Малахов – руководитель направления цифровой развития в центре стратегического развития\nОльга Саваровская, зам. руководителя департамента управления данными Аналитического центра\nЮрий Кирьянов, корпоративный архитектор, Сбербанк\nЕлена Верещага, архитектор данных\nАлексей Мамонов, руководитель дирекции управления данными, ИнтерРАО\nЕвгения Незговорова, эксперт по направлению информационной безопасности информационных технологий\nЕвгений Соломатин, руководитель программы МВА – Телеком, бизнес школы МИРБИС",
      "target_audience": [
        "Этот курс будет полезен для: Директор по данным (Chief Data Officer, CDO); Специалист по изучению данных (data scientist); Директор по цифровым технологиям Chief Digital Officer, CDO; ИТ-директор (CIO - Chief Information Officer); Директор по информационной безопасности (Chief information security officer, CISO); Финансовый директор (CFO - Chief Financial Officer); Системный администратор; DataOps (data operations, конвейер данных); Специалист по работе с большими данными (big data).",
        "Для всех, кто отвечает за управление данными и непосредственно вовлечен в следующие процессы работы с данными: Анализ данных; Моделирование данных; Управление базами данных; Работа с хранилищами данных; Извлечение, преобразование и загрузка данных; Добыча данных; Обеспечение качества данных; Защита данных; Шифрование данных; Управление метаданными (репозиториями данных); Архитектура данных."
      ]
    },
    {
      "title": "数据埋点实操课",
      "url": "https://www.udemy.com/course/fkjppzks/",
      "bio": "快速上手数据采集方案设计工作，掌握撰写埋点需求文档的方法论及注意事项，根据需求输出数据埋点方案",
      "objectives": [
        "了解如何利用SDK采集数据，了解数据采集的内容来源、埋点模型等实操细节",
        "熟悉数据采集流程，快速上手数据采集方案设计",
        "掌握撰写埋点需求文档的方法论，掌握撰写埋点需求文档的注意事项",
        "了解数据全生命周期，知晓各阶段的主要工作，了解埋点需求从设计到上线的所有环节与各角色职责",
        "掌握根据业务数据需求输出数据埋点方案的流程与方法"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "数据采集方案设计": [
          "本章导读",
          "什么是数据采集方案？",
          "搭框架：设计数据流体系",
          "搭流程：设计采集数据流程",
          "填内容：确定采集内容和来源",
          "本章小结"
        ],
        "数据卖点需求文档的撰写": [
          "什么是埋点需求文档？",
          "为什么需要埋点需求文档？",
          "如何撰写一份埋点需求文档？",
          "埋点需求文档撰写实战",
          "本章小结"
        ],
        "埋点管理流程规范的设计": [
          "为什么要管理产品的数据埋点？",
          "如何设计埋点管理流程规范？",
          "第一阶段：需求评审阶段",
          "第二阶段：埋点开发阶段",
          "第三阶段：埋点发布阶段",
          "本章小结"
        ],
        "回顾总结": [
          "课后寄语"
        ]
      },
      "requirements": [
        "了解数据埋点的概念和目的"
      ],
      "description": "数据的全生命周期可以划分为采集、治理、存储、建模和应用这5个阶段。在数据全生命周期内进行数据埋点管理，就可以获得更准确、更规范、更安全、更合理的数据，从而达到高效应用数据进行分析的效果。\n\n为了帮助大家掌握规范科学的埋点方法，三节课特别邀请了数据分析专家韩城老师带来《数据埋点实操课》。本节课程围绕数据埋点工作，介绍了数据采集方案设计、数据埋点需求文档的撰写、埋点管理流程规范的设计三大部分内容。\n\n首先，课程分享了一套数据采集方案的设计方法。希望帮助到从事数据产品设计、数据分析或业务产品设计工作的你，了解数据采集的流程与实操细节，快速上手数据采集方案设计工作。\n\n采集用户行为数据是为了更好的分析用户行为，从而更好的满足用户诉求，进而实现业务增长。课程从基本概念切入，结合案例，层层递进、深入解析，希望课程中方法论的总结，能帮助你解决数据分析的应用问题，并不断迭代优化出更适合你自己的方法论。\n\n数据口径定义不清晰，沟通困难？离职交接不完整，总是带来麻烦？多人同时定义口径，标准不统一？你是否也遇到过这些麻烦？设计埋点管理流程规范就可以解决这个问题，第三章为你介绍设计规范流程的三阶段。\n\n希望课程能帮助从事数据相关工作的你更好规范的管理埋点数据，助你掌握根据业务数据需求输出数据埋点方案的流程与方法。",
      "target_audience": [
        "想要轻松熟练地与数据团队沟通数据需求的业务产品经理",
        "想要将业务的数据需求转化为埋点需求的数据产品经理",
        "想要提升数据采集与埋点能力的1-3年的数据分析师"
      ]
    },
    {
      "title": "无人驾驶综合导论",
      "url": "https://www.udemy.com/course/zlqrjnvo/",
      "bio": "从零搭建L4级自动驾驶系统",
      "objectives": [
        "掌握四大自动驾驶核心知识点:感知、定位、规划、控制",
        "掌握三大主流自动驾驶学习算法:深度学习、强化学习、模仿学习",
        "掌握一套完整的自动驾驶系统搭建和解读",
        "提升学员自动驾驶知识技能"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "第1课 自动驾驶概述",
          "软件环境基础（ROS CMake）",
          "感知基础",
          "感知实战：目标检测",
          "感知实战：物体跟踪",
          "视觉定位",
          "高精地图与车路协同设备",
          "无人车定位系统",
          "预测系统",
          "路径规划",
          "控制理论",
          "基于强化学习的自动驾驶系统"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "有自动驾驶研究经验"
      ],
      "description": "本课程将首次全面公开基于L4级别的全自动驾驶汽车的各项核心技术，从Google、Uber、BAT等公司的先进架构和算法展开，主要包括如下内容:\n1.四大自动驾驶核心知识点:感知、定位、规划、控制\n2.三大主流自动驾驶学习算法:深度学习、强化学习、模仿学习3.一套完整的自动驾驶系统搭建和解读:硬件->软件->仿真->路测\n三位讲师均为自动驾驶领域的算法专家，担任核心模块的技术研发Leader，拥有丰富的实战经验和研究经历。本课程中，他们将深度讲解全自动驾驶汽车的核心技术和常用算法以及完整的自动驾驶研发流程，可以让大家高效掌握顶级自动驾驶工程师的经验和技能。",
      "target_audience": [
        "适合特定行业中的自动驾驶工程师"
      ]
    },
    {
      "title": "Dominio de Data Science: De Cero a Pro",
      "url": "https://www.udemy.com/course/dominio-de-data-science-de-cero-a-pro/",
      "bio": "Pasa del caos de datos a insights claros. Aprende Python, Pandas, ML y Deep Learning para proyectos reales.",
      "objectives": [
        "Comprender los fundamentos de la ciencia de datos y los tipos de ML (supervisado, no supervisado, por refuerzo).",
        "Dominar estadísticas descriptivas, probabilidades, correlación, causalidad, pruebas de hipótesis y A/B testing.",
        "Manipular y transformar datos con Python: tipos, listas, tuplas, conjuntos, diccionarios y comprensiones.",
        "Analizar datos con Pandas: leer, explorar, limpiar, filtrar, agrupar, agregar y crear tablas dinámicas.",
        "Gestionar series temporales de manera eficiente con Pandas para el análisis de datos cronológicos.",
        "Realizar cálculos numéricos eficientes con NumPy: arrays, indexación, slicing, operaciones matemáticas.",
        "Crear visualizaciones de datos impactantes con Matplotlib: líneas, barras, puntos, histogramas, boxplots, subplots.",
        "Mejorar las visualizaciones con Seaborn: integración Pandas, pairplot, facetgrid, regresiones y heatmaps.",
        "Comprender los conceptos clave de Machine Learning: flujo de trabajo, selección de características, overfitting y underfitting.",
        "Aplicar ML supervisado con Scikit-Learn: regresión lineal, árboles de decisión, bosques aleatorios, SVM, ANN.",
        "Gestionar la selección de características y la reducción de dimensionalidad para optimizar los modelos de ML.",
        "Dominar los datos desequilibrados y las técnicas avanzadas de clasificación.",
        "Comparar y evaluar modelos de ML con métricas relevantes y métodos de conjunto.",
        "Optimizar modelos mediante el ajuste de hiperparámetros y la validación cruzada (Scikit-Learn).",
        "Aplicar ML no supervisado: K-Means, clustering jerárquico, reducción de dimensionalidad.",
        "Detectar anomalías (outliers) en los conjuntos de datos para mejorar la calidad del análisis.",
        "Combinar aprendizaje supervisado y no supervisado para soluciones más robustas.",
        "Introducción al Deep Learning con TensorFlow y Keras: modelos secuenciales y funcionales.",
        "Comprender Forward y Backpropagation, y las funciones de activación (ReLU, Sigmoid, Softmax).",
        "Realizar el ajuste de hiperparámetros para Deep Learning con Optuna.",
        "Desarrollar CNNs para el reconocimiento de imágenes y modelos secuenciales (RNN, LSTM, GRU).",
        "Descubrir los GANs y los conceptos de los modelos generativos.",
        "Llevar a cabo un proyecto de Ciencia de Datos de la A a la Z: carga, limpieza, visualización, ingeniería de características, modelado ML/DL."
      ],
      "course_content": {},
      "requirements": [
        "No se requieren conocimientos previos. Te guiaré paso a paso a través de cada concepto."
      ],
      "description": "Este curso utiliza inteligencia artificial.\nDomina la Ciencia de Datos — Y Pasa de un Simple Código a Análisis Reales.\n¿Cansado de no saber por dónde empezar con tus datos, de perder el tiempo limpiando archivos CSV, o de no entender por qué tu modelo no funciona? Este curso te guiará paso a paso — desde tus primeras líneas de código hasta tus propios modelos predictivos.\nYa seas un principiante en Python o ya tengas una base en programación, este curso te transformará en un practicante de la Ciencia de Datos. Aprenderás a manipular, analizar, visualizar y modelar datos como un profesional.\nSe acabaron los scripts desordenados, los errores incomprensibles y las horas perdidas en Google. Es hora de una práctica de la Ciencia de Datos clara, estructurada y eficaz.\nLo que aprenderás\nComprender los fundamentos estadísticos esenciales para la ciencia de datos\nManipular datos eficazmente con Pandas y NumPy\nVisualizar datos con Matplotlib y Seaborn\nConstruir modelos de Machine Learning con Scikit-Learn\nCrear redes neuronales con TensorFlow y Keras\nImplementar proyectos concretos de principio a fin\nEstructura del Curso – Lo que te espera\nIntroducción a la Ciencia de Datos ¿Qué es la ciencia de datos, por qué es esencial hoy en día y cuáles son las habilidades clave a dominar?\nFundamentos Estadísticos para la Ciencia de Datos Aprende los conceptos esenciales: media, desviación estándar, distribuciones, correlación vs causalidad, p-valores, A/B testing…\nPython para la Ciencia de Datos Domina las estructuras de datos de Python (listas, diccionarios, conjuntos, etc.) y aprende técnicas modernas como las comprensiones.\nManipulación de Datos con Pandas Importación, limpieza, filtrado, agrupación, fusión… Lo sabrás todo sobre la preparación de datos.\nCálculos Numéricos con NumPy Crea y manipula arrays numéricos de alto rendimiento, y realiza cálculos vectorizados.\nVisualización de Datos Aprende a crear gráficos impactantes con Matplotlib y Seaborn: histogramas, diagramas de dispersión, mapas de calor, diagramas de caja y más.\nMachine Learning con Scikit-Learn Construye modelos supervisados y no supervisados, pruébalos, optimízalos y comprende su rendimiento.\nDeep Learning con TensorFlow & Keras Crea tus primeras redes neuronales, CNNs, RNNs, e incluso explora los GANs para generar tus propios datos.\nProyecto Final: Aplicación Completa Un proyecto concreto donde implementarás todo lo aprendido: limpieza, visualización, modelado y predicción.\n¿A quién va dirigido este curso?\nPrincipiantes en Python curiosos por descubrir la ciencia de datos\nEstudiantes o profesionales que deseen añadir una habilidad muy demandada a su perfil\nDesarrolladores autodidactas que quieran estructurar su aprendizaje\nCualquier persona que quiera pasar de simples análisis de Excel a predicciones reales basadas en datos\nRequisitos Previos ¡Ninguno! Aprenderás todo paso a paso. Solo necesitas un ordenador, una conexión a internet y tu motivación.\n¿Por qué seguir este curso? Aprender Ciencia de Datos es abrir la puerta a una de las profesiones más solicitadas del mundo. Pero este curso no solo te enseña conceptos, te proporciona habilidades concretas y prácticas, con herramientas profesionales, para que puedas usarlas desde hoy.\nEntonces, ¿listo/a para transformar tus datos en decisiones? Acompáñame en este emocionante viaje — y conviértete en un verdadero Data Scientist. ¡Nos vemos pronto en el curso! – Mika",
      "target_audience": [
        "Principiantes en ciencia de datos: Cualquier persona que desee adquirir una base sólida en ciencia de datos, incluso sin experiencia previa en programación o estadísticas.",
        "Analistas de datos y profesionales de BI: Aquellos que deseen enriquecer sus habilidades de análisis de datos con técnicas avanzadas y machine learning.",
        "Desarrolladores Python: Desarrolladores que buscan expandir sus habilidades al campo de la ciencia de datos, el análisis y el machine learning.",
        "Estudiantes e investigadores: Aquellos que necesitan comprender y aplicar métodos de ciencia de datos para sus proyectos universitarios o de investigación.",
        "Profesionales en reorientación laboral: Cualquiera que desee iniciar una carrera en ciencia de datos y dominar las herramientas esenciales del sector.",
        "Curiosos de la IA y el ML: Cualquier persona que desee comprender los algoritmos de machine learning y deep learning y sus aplicaciones concretas.",
        "Futuros Data Scientists: Aquellos que aspiran a una carrera de Data Scientist y quieren dominar las habilidades técnicas demandadas por las empresas.",
        "Desarrolladores que desean optimizar sus soluciones con modelos predictivos e IA."
      ]
    },
    {
      "title": "Python para Investidores: Dados Financeiros com Fundamentus",
      "url": "https://www.udemy.com/course/python-com-fundamentus/",
      "bio": "Aprenda a coletar, analisar e visualizar dados de ações com Python e a API Fundamentus, do zero à prática.",
      "objectives": [
        "Configurar o ambiente Python e utilizar a API Fundamentus para extrair dados financeiros de empresas listadas na bolsa.",
        "Identificar indicadores de mercado, performance, patrimônio e crescimento com funções práticas da API.",
        "Listar papéis, consultar setores e organizar dados em CSV ou tabelas prontas para análise.",
        "Construir um dashboard interativo com Streamlit para visualizar resultados financeiros em tempo real."
      ],
      "course_content": {
        "Introdução": [
          "Preparando o Ambiente",
          "Review API",
          "Função list_papel_all()"
        ],
        "Função get_detalhes_papel( ) → Analisando a fundo a empresa": [
          "Função get_detalhes_papel() → Introdução",
          "Parte 1 → Identificação da Empresa",
          "Parte 2 → Indicadores de Mercado",
          "Parte 3 → Indicadores de Patrimônio",
          "Parte 4 → Indicadores Fundamentalistas",
          "Parte 5 → Indicadores de Rentabilidade",
          "Parte 6 → Indicadores de Crescimento"
        ],
        "Função get_resultado": [
          "Função get_resultado( )",
          "Projeto: App Top Empresas da Bolsa"
        ],
        "Funções utilitárias": [
          "Trabalhando com setores da Bovespa",
          "Imprimir tabelas e exportar para Excel"
        ]
      },
      "requirements": [
        "Conhecimentos básicos de Python, como uso de funções, listas e dicionários",
        "Familiaridade com bibliotecas como pandas e requests com dataframes (nível iniciante).",
        "Noções de mercado financeiro, como saber o que é uma ação, indicadores e setores.",
        "Desejo de aprender a coletar e analisar dados financeiros automaticamente.",
        "Ter o Python instalado no computador (preferencialmente com Jupyter ou VSCode)."
      ],
      "description": "Neste curso, você vai aprender como utilizar Python para acessar e analisar dados financeiros do mercado de ações brasileiro com a API Fundamentus. O objetivo é tornar você capaz de automatizar coletas de dados e construir suas próprias ferramentas de análise fundamentalista, mesmo que esteja iniciando na programação.\n\n\nAbaixo, você confere a estrutura do curso dividida por tópicos:\n\n\nPreparando o ambiente\nInstalação dos módulos necessários\nConfiguração do ambiente de desenvolvimento\n\n\nConhecendo a API Fundamentus\nVisão geral das funcionalidades da API\nComo acessar e explorar as principais vantagens\n\n\nExtraindo dados financeiros com Python\nlist_papel_all() – Lista de todos os papéis disponíveis\nget_detalhes_papel() – Detalhes completos das empresas\nDados por categoria:\nIdentificação da empresa\nIndicadores de mercado\nIndicadores fundamentalistas\nIndicadores patrimoniais\nIndicadores de performance\nIndicadores de crescimento\n\n\nVisualizando resultados\nget_resultado() – Resultados financeiros completos\nProjeto prático com Streamlit: construção de página com interação com usuário\n\n\nAnalisando setores do mercado\nprint_setores(), list_papel_setor(), get_setor_id()\n\n\nExportando os dados\nprint_csv() e print_table() – Exportação em formatos organizados\n\n\nAo final do curso, você terá criado sua própria aplicação de análise fundamentalista com Python e Streamlit, capaz de acessar e visualizar dados financeiros de forma automatizada. Estará apto a aplicar esse conhecimento para tomar decisões mais estratégicas no mercado de ações, seja como investidor individual, analista financeiro ou desenvolvedor interessado em finanças. Além disso, você terá construído uma base sólida para criar novas ferramentas personalizadas, adaptar os códigos para outras APIs e expandir suas habilidades em ciência de dados voltada ao mercado financeiro. Tudo isso com uma abordagem prática, clara e voltada para o mundo real.",
      "target_audience": [
        "Investidores iniciantes que querem aprender a analisar ações com dados reais.",
        "Entusiastas de programação que desejam aplicar Python no mercado financeiro.",
        "Estudantes de finanças, economia ou engenharia buscando automatizar análises.",
        "Profissionais da área financeira interessados em ferramentas de análise com dados atualizados.",
        "Desenvolvedores Python que queiram explorar APIs e criar projetos práticos com Streamlit."
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第22部 如何推理 Llama 大語言模型 下部",
      "url": "https://www.udemy.com/course/generative_ai_22/",
      "bio": "關於 Llama3，RoPE，GQA，KV Cache，RMSNorm，Top-P，",
      "objectives": [
        "學員將學習KV Cache（鍵值緩存）加速推理的原理與實現方式",
        "學員將學會Grouped Query Attention (GQA) 如何平衡效果與效率",
        "學員將學會Rotary Positional Embeddings (RoPE) 的數學原理及其相對位置編碼的優勢",
        "學員將瞭解RMSNorm 為何被 Llama 3 選用"
      ],
      "course_content": {
        "介紹": [
          "課程工具準備",
          "如何使用uv 作為包管理器和項目管理工具",
          "如何從 Meta 官網下載模型權重文檔"
        ],
        "如何用 Python編寫 Llama 的架構": [
          "如何接入 Llama Transformer Class 的基本參數",
          "如何創建Llama3 的 RMSNorm & FFN SwiGLU",
          "如何計算 RoPE 複數頻率",
          "如何實現 RoPE 旋轉位置編碼複數轉換實數",
          "如何創建Attention 組合 RoPE & GQA & KV 緩存",
          "如何創建TransformerBlock 和組織Llama 模型"
        ],
        "如何使用 LlaMA3 模型進行文本生成": [
          "如何導入 Llama3 權重文檔和 Tokenizer model 文檔",
          "如何使用 Tokenizer 進行編碼和解碼",
          "如何將特殊 ID 和 Prompt 結合在一起",
          "如何構建LlaMA3 實例",
          "如何輸入Prompt 列表生成 Tokens 並轉化為文本",
          "如何用Top_p按照累積概率和選擇下一個 Token ID"
        ]
      },
      "requirements": [
        "一台電腦"
      ],
      "description": "從核心原理到 PyTorch 高效推理實戰\n\n\n你是否厭倦了僅僅調用 API，卻對大型語言模型 (LLM) 的內部運作一知半解？\n你是否驚嘆於 Llama 3 的強大能力，並渴望深入理解其背後的魔法——那些讓它高效、強大的關鍵技術，如 KV Cache、Grouped Query Attention (GQA)、旋轉位置編碼 (RoPE) 和 RMSNorm？\n現在，機會來了！本課程將帶你從零開始，一步步揭開 Llama 3 的神秘面紗，不僅讓你理解其核心架構和關鍵組件的理論精髓，更能親手用 PyTorch 庫編寫、優化並運行你自己的 Llama 3 推理流程！\n在本課程中，你將獲得：\n深度理解 Llama 3 核心機制： 不再是黑箱！我們將深入淺出地講解 Llama 3 相較於原版 Transformer 的關鍵改進，包括：\nKV Cache： 為何它能讓 LLM 推理速度產生質的飛躍？如何實現？\nGrouped Query Attention (GQA): 在多頭注意力 (MHA) 和多查詢注意力 (MQA) 之間取得的精妙平衡，如何在保證質量的同時提升效率？\n旋轉位置編碼 (RoPE): 這種新穎的位置編碼方式是如何工作的？為什麼它比絕對位置編碼更受青睞？\nRMSNorm： 為什麼 Llama 選擇它而不是 Layer Normalization？它有何優勢？\n硬核 PyTorch 推理實戰： 我們將基於提供的實戰代碼，帶你：\n使用 Pytorch 高效加載預訓練 Llama 3 模型和分詞器。\n親手實現逐 Token 生成循環，掌控文本生成的每一步。\n靈活應用 KV 緩存，體驗推理加速的快感。\n掌握 Top-P、Temperature、Repetition Penalty 等核心採樣策略，精調你的模型輸出風格。\n編寫設備自動檢測代碼 (CUDA / MPS / CPU)，讓你的推理代碼適配不同硬件，充分利用加速能力。\n學會工程化技巧：處理 Padding、實現 EOS 判斷、優化 Prompt 等。\n從理論到實踐的閉環： 完美結合 Llama 3 內部原理講解與動手編碼實踐，讓你知其然，更知其所以然。\n使用 model.generate()： 推导下一个 Token 及文本生成，真正理解並控制生成過程的每一個細節，為未來更複雜的模型定制和優化打下堅實基礎。",
      "target_audience": [
        "渴望深入理解 LLM 內部原理的 AI 工程師、研究者",
        "希望從 API 調用者進階為模型掌控者的開發者",
        "對 PyTorch 和 Transformer 有一定基礎，想挑戰 Llama 級別模型實戰的學習者",
        "任何對 Llama 3 及現代 LLM 技術核心感興趣的技術愛好者"
      ]
    },
    {
      "title": "Mastering Blogger: Building Engaging Websites from Scratch",
      "url": "https://www.udemy.com/course/mastering-blogger-websites-from-scratch/",
      "bio": "Create Stunning Blogs and Websites with Blogger's Powerful Platform",
      "objectives": [
        "Introduction to Blogging: Understand the concept of blogging, its importance, and its potential impact.",
        "Understand the basics of blogging and its significance in today's digital landscape.",
        "Be proficient in setting up a Blogger website, customizing its design, and managing content.",
        "Develop skills in creating engaging and SEO-friendly blog posts.",
        "Know how to effectively engage and expand their audience through various channels.",
        "Explore monetization options and strategies for growing their blog's visibility and influence."
      ],
      "course_content": {
        "Introduction": [
          "Introduction - How to Start a Successful Blog and Make Money",
          "How to Create Account",
          "Blogger Dashboard Overview",
          "How to Upload Free Theme",
          "How to Upload Logo",
          "How to Create Categories",
          "How to Post on Blogger",
          "How to Create Sub-categories",
          "How to Post in Sub-categories",
          "How to Fix 404 Error",
          "How to Embed Youtube Video link",
          "Last Part - Blogger Footer Customization"
        ]
      },
      "requirements": [
        "No Major Requirements",
        "You have Just Laptop and Good Internet Connection"
      ],
      "description": "Welcome to the ultimate guide to mastering Blogger! Whether you're a novice looking to create your first blog or a seasoned user aiming to enhance your skills, this course is your comprehensive roadmap to unlocking the full potential of Blogger's platform.\nWhat You'll Learn:\nGetting Started with Blogger: Explore the fundamentals of Blogger, from setting up your account to navigating the interface and understanding its features.\nDesigning Engaging Websites: Learn to craft visually appealing and user-friendly blogs and websites using Blogger's customization tools and templates.\nContent Creation & Optimization: Discover strategies for creating compelling content, optimizing it for search engines, and engaging your audience effectively.\nMonetization & Growth Strategies: Explore various monetization methods, including advertising, affiliate marketing, and leveraging your blog's growth potential.\nAdvanced Tips & Tricks: Delve into advanced features, customization options, and hacks to take your Blogger website to the next level.\nWhy Take This Course:\nComprehensive Learning: Gain a thorough understanding of Blogger's features and functionalities through step-by-step guidance and practical examples.\nExpert Insights: Learn from experienced bloggers and web development professionals who share their tips, tricks, and best practices.\nHands-On Projects: Apply your knowledge with hands-on exercises and projects to create your own stunning Blogger website.\nWho Is This Course For:\nBeginners interested in starting a blog or website with Blogger\nBloggers seeking to enhance their skills and maximize their Blogger platform\nEntrepreneurs and marketers looking to leverage Blogger for their online presence\nPrerequisites:\nNo prior experience with Blogger is required. Basic knowledge of navigating the internet and a desire to create engaging online content will be beneficial.\nJoin this course now and embark on a journey to create captivating blogs and websites using Blogger's versatile platform!",
      "target_audience": [
        "Beginners: Individuals with little to no experience in blogging, eager to grasp the fundamentals, including setting up a blog, understanding content creation, and navigating platform tools.",
        "Intermediate Bloggers: Those already running a blog but looking to refine their skills in content strategy, SEO optimization, monetization techniques, and audience engagement to take their blog to the next level."
      ]
    },
    {
      "title": "PyBI Analytics: Gdzie Python spotyka Power BI",
      "url": "https://www.udemy.com/course/pybi-analytics-gdzie-python-spotyka-power-bi/",
      "bio": "Naucz się używać skryptów Pythona w Power BI!",
      "objectives": [
        "Nauczysz się importować i manipulować źródłami danych w Power BI za pomocą Pythona.",
        "Zobaczysz, jak wygląda tworzenie wizualizacji w Power BI używając bibliotek Pythona: Seaborn oraz Matplotlib.",
        "Stworzysz model uczenia maszynowego w PBI.",
        "Poznasz możliwości pracy z Pythonem w Power BI, ale również jego ograniczenia."
      ],
      "course_content": {
        "Wstęp": [
          "Wstęp"
        ],
        "Wprowadzenie do skryptów Pythona": [
          "Wprowadzenie do Pythona",
          "Instalacja Pythona",
          "Pierwszy skrypt"
        ],
        "Python i Power Query": [
          "Początek",
          "Dodanie i usunięcie kolumn",
          "Zmniejszenie tabeli danych",
          "Praca z brakującymi wartościami",
          "Zastępowanie wartości",
          "Sortowanie danych",
          "Grupowanie danych",
          "Złączenia danych"
        ],
        "Zewnętrzny IDE": [
          "Przejście do zewnętrznego IDE"
        ],
        "Wizualizacja danych z użyciem bibliotek Pythona": [
          "Wizualizacje z Seaborn, pt. 1",
          "Wizualizacje z Seaborn, pt. 2",
          "Wizualizacje z Seaborn, pt. 3"
        ],
        "Machine learning w PBI": [
          "Podstawy uczenia maszynowego w Power BI"
        ],
        "Zakończenie": [
          "Podziękowania i słowa końcowe"
        ]
      },
      "requirements": [
        "Powinieneś znać podstawy pracy z Power BI.",
        "Wymagana jest podstawa programowania w Pythonie, a najlepiej względna znajomość podstawowych bibliotek do analizy danych."
      ],
      "description": "Odkryj możliwości, jakie daje integracja Pythona z Power BI! Zapraszam na wyjątkowy kurs online, który krok po kroku wprowadzi Cię w świat zaawansowanej analityki danych.\nPodczas kursu nauczysz się, jak zainstalować Pythona oraz kluczowe moduły do analizy danych na Twoim lokalnym komputerze. Dzięki prostym instrukcjom z łatwością skonfigurujesz środowisko, które umożliwi Ci dynamiczną pracę z danymi w Power BI.\nNastępnie przejdziemy do jednego z najważniejszych elementów kursu – importowania i przekształcania danych z pomocą Pythona bezpośrednio w edytorze Power Query. Ta umiejętność pozwoli Ci na elastyczną i zaawansowaną obróbkę danych, znacznie zwiększając Twoje możliwości analityczne.\nPodczas kursu nie ograniczymy się tylko do Power BI. Pokażę Ci, jak efektywnie korzystać z zewnętrznego IDE, które ułatwi programowanie i testowanie kodu. Poznasz również narzędzia do wizualizacji danych, takie jak Matplotlib i Seaborn, dzięki którym stworzysz interaktywne, estetyczne raporty bezpośrednio w Power BI.\nNa zakończenie wprowadzę Cię w podstawy uczenia maszynowego, co otworzy przed Tobą drzwi do zaawansowanych analiz predykcyjnych.\nKurs jest przeznaczony zarówno dla początkujących, jak i średniozaawansowanych użytkowników Power BI. Dzięki niemu nauczysz się łączyć świat Pythona z Power BI, zwiększając swoją efektywność w analizie danych. Nie czekaj! Dołącz do kursu i zyskaj praktyczne umiejętności, które pozwolą Ci wyróżnić się na rynku pracy.",
      "target_audience": [
        "Kurs ten jest przeznaczony dla analityków danych i PBI developerów, którzy chcieliby poszerzyć swój wachlarz umiejętności i zacząć analizować i przedstawiać dane w PBI za pomocą Pythona."
      ]
    },
    {
      "title": "【Pythonで実践】AI・画像認識のためのデータ拡張（Data Augmentation）マスター講座",
      "url": "https://www.udemy.com/course/pythonaidata-augmentation/",
      "bio": "少ないデータで精度を劇的UP！OpenCV・Albumentationsを使いこなし、過学習を防ぎながら高汎化性能モデルを構築する全手順",
      "objectives": [
        "AI開発におけるデータ拡張の重要性を理解し、自分のプロジェクトに導入する判断ができる。",
        "回転、反転、拡大縮小、明るさ変更といった基本的なデータ拡張を、Pythonコードで自在に実装できる。",
        "実務で必須のライブラリ「Albumentations」を使いこなし、複雑なデータ拡張もわずか数行のコードで実現できる。",
        "学習データに対して「オンザフライ」でデータ拡張を適用するパイプラインを構築し、効率的な学習フローを実装できる。",
        "データ拡張の有無によってモデルの精度がどう変化するかを体感的に理解し、その効果を説明できるようになる。"
      ],
      "course_content": {
        "はじめに": [
          "はじめに",
          "グーグルコラボの使い方"
        ],
        "基本的なデータ拡張手法の実装": [
          "準備と幾何学的変換：回転",
          "幾何学的変換：反転・拡大縮小",
          "幾何学的変換：並進・せん断（オプション）",
          "色彩的変換：明るさ変更",
          "色彩的変換：コントラスト変更",
          "色彩的変換：彩度変更",
          "ノイズ追加"
        ],
        "Albumentationsライブラリ活用入門": [
          "Albumentationsライブラリについて",
          "準備・Albumentationsの基本：単一変更処理",
          "複数の変換処理を組み合わせる：Compose,OneOf,SomeOf",
          "演習・まとめ"
        ],
        "オンザフライでのデータ拡張実践": [
          "準備と画像の前処理",
          "データ拡張関数とデモンストレーション",
          "オンザフライのメリットとまとめ"
        ],
        "簡単なモデルでの効果測定": [
          "データセットの準備",
          "簡単なCNNモデルの作成と学習（データ拡張なし）",
          "データ拡張をした場合の学習と学習結果の比較・考察"
        ],
        "まとめ": [
          "まとめ"
        ]
      },
      "requirements": [
        "Pythonの基本的な文法（変数、関数、リスト、ループなど）の知識",
        "NumPy, OpenCV, Pillow などのライブラリに触れた経験があると、よりスムーズに学習を進められます。"
      ],
      "description": "コースの説明\nAIモデルの「精度」の壁を、\"データ拡張\"で打ち破りませんか？\n「頑張ってAIモデルを作ったのに、なぜか精度が頭打ちになってしまう…」\n「学習データをもっと集めたいけど、時間もコストもかけられない…」\n「\"データ拡張\"という言葉は知っているけど、どう実装すれば効果的なのか分からない…」\nもしあなたがAI・画像認識モデルの開発でこのような悩みを抱えているなら、このコースはまさにあなたのための「実践的データ拡張（Data Augmentation）バイブル」です。\n本コースでは、手元にある限られた画像データセットを、Pythonプログラミングによって擬似的に10倍、100倍に増やすための全技術を、ハンズオン形式でゼロから徹底的に解説します。データ拡張をマスターすれば、AIモデルの精度と汎化性能（未知のデータへの対応力）を劇的に向上させることが可能です。\nこのコースで得られること・学べること\nデータ拡張がなぜAIモデルの精度向上に不可欠なのかを深く理解できます。\n回転、反転、拡大縮小、明るさ・コントラスト変更、ノイズ追加といった、代表的なデータ拡張の手法をPythonコードで自在に実装できるようになります。\n業界標準の高速データ拡張ライブラリ「Albumentations」の基本から、複数の処理を組み合わせた実践的なパイプライン構築までを習得できます。\nデータ拡張の「あり/なし」で、モデルの精度がどれだけ変わるのかを自分の目で確認し、その絶大な効果を体感できます。\nあなたのAI開発プロジェクトに明日からすぐ応用できる、実践的なデータ拡張の知識とコーディングスキルが身につきます。\nコース内容\nこのコースは、単にライブラリの使い方をなぞるだけではありません。まずはOpenCVやPillowといった基本的なライブラリを使ってデータ拡張を”手作り”で実装し、「なぜそうなるのか」という仕組みの根本から理解を深めます。\nその上で、実務で必須の高速ライブラリAlbumentations へとステップアップ。基本から応用までを学び、最終的には学習ループに組み込むデータ拡張パイプラインを構築します。\nさらに、オプションの章では簡単な画像分類モデルを使い、データ拡張がモデルの精度に与える影響を数値で比較検証します。理論だけでなく、結果で効果を実感できる構成です。\nもう「データが足りない」と悩むのは終わりにしましょう。 このコースでデータ拡張という強力な武器を手に入れ、あなたのAIモデルを次のレベルへと進化させてください。\nこんな方におすすめ\nAI・画像認識モデルの精度に伸び悩んでいる初～中級者の方\n少ない学習データセットから、より汎化性能の高いモデルを構築したい方\n過学習（Overfitting）に悩まされており、その具体的な対策方法を学びたい方\nPythonと画像処理ライブラリ（OpenCV, Pillowなど）の基本を知っており、実務的なスキルへステップアップしたい方\n強力なデータ拡張ライブラリAlbumentationsの使い方を体系的に学びたい方\n受講における必要条件\nPythonの基本的な文法（変数、リスト、関数、if文、for文など）の知識。\n（推奨）Google Colaboratory や Jupyter Notebook の使用経験があるとスムーズです。コース内でも基本的な使い方はフォローします。\n（推奨）機械学習や画像認識に関する基本的なキーワード（「学習」「モデル」「精度」など）を知っていると、より理解が深まります。\nさあ、あなたもこのコースでデータ拡張をマスターし、AI開発者として大きな一歩を踏み出しましょう！ コースでお会いできるのを楽しみにしています。",
      "target_audience": [
        "手持ちの画像データが少なく、AIモデルの精度が上がらずに悩んでいる方",
        "作成したAIモデルが訓練データに過剰に適合してしまう「過学習（Overfitting）」に困っている方",
        "画像認識AI開発のスキルをもう一段階レベルアップさせたいエンジニア、学生、研究者の方",
        "データ拡張のテクニックを武器に、AIコンペティションで上位を目指したい方",
        "少ないデータセットからでも、ロバスト（頑健）で実用的なAIモデルを作りたいと考えているすべての方"
      ]
    },
    {
      "title": "Membuat Transkrip Podcast menggunakan AI",
      "url": "https://www.udemy.com/course/membuat-transkrip-podcast-menggunakan-ai/",
      "bio": "Menguasai Transkripsi Audio Otomatis dengan AI dan Python.",
      "objectives": [
        "Menggunakan AI untuk memudahkan pekerjaanmu",
        "Mengenal ASR ( Automatic Sound Recognition)",
        "Dapat membuat aplikasi pengenalan suara",
        "Case study melakukan transcribe pada podcast"
      ],
      "course_content": {
        "Course Introduction": [
          "Introduction",
          "Apa itu Automatic Speech Recognition"
        ],
        "Membuat Transkrip Audio menggunakan AI": [
          "Using Speech Recognition on Local",
          "Using Speech Recognition on Huggingface",
          "Using Speech Recognition API from OpenAI-API"
        ],
        "(Project) Membuat Transkrip Audio Spotify Podcast": [
          "Build Function to download and transcribe the podcast",
          "Build function to download podcast"
        ]
      },
      "requirements": [
        "Python Beginner"
      ],
      "description": "Kursus ini dirancang untuk para Python Developer yang sudah dan ingin mendalami aplikasi AI / Machine Learning dalam pemrosesan suara. Anda akan mempelajari cara membuat transkripsi audio otomatis dengan memanfaatkan teknologi machine learning dan pustaka Python. Dengan pendekatan praktis dan studi kasus nyata, kursus ini memberikan pengetahuan mendalam yang dapat langsung diterapkan. Kami akan menggunakan pustaka HuggingFace, OpenAI, dan Spotify DLX, serta podcast sebagai contoh proyek.\nApa yang Akan Anda Pelajari:\nPenerapan konsep machine learning dalam pemrosesan suara\nIntegrasi pustaka AI seperti HuggingFace, OpenAI, dan Spotify DLX\nTeknik-teknik pemrosesan suara lanjutan\nMembangun aplikasi transkripsi audio yang efisien dan akurat\nOptimasi model untuk meningkatkan performa transkripsi\nPemahaman tentang arsitektur AI dan algoritma yang digunakan\nStudi kasus dan contoh proyek menggunakan podcast\nMengapa Mengambil Kursus Ini:\nMemperdalam pemahaman tentang machine learning dan AI\nMeningkatkan kemampuan pemrograman Python di bidang pemrosesan suara\nMembangun proyek nyata yang dapat diterapkan di berbagai industri\nBelajar dari studi kasus nyata dan penerapan praktis\nMendapatkan keterampilan yang sangat dicari dalam industri teknologi\nSiapa yang Cocok untuk Kursus Ini:\nPengembang Python tingkat lanjut\nProfesional di bidang AI dan machine learning\nSiapapun yang ingin memperdalam pengetahuan tentang pemrosesan suara otomatis\nBergabunglah sekarang dan tingkatkan keterampilan Anda dalam membuat transkripsi audio menggunakan AI dan Python!",
      "target_audience": [
        "Python developer that interested in learning AI"
      ]
    },
    {
      "title": "Looker - Projeto LookML e Camada Semantica",
      "url": "https://www.udemy.com/course/looker-lookml-do-basico-ao-avancado/",
      "bio": "Dimensions, Measures, Filters, Parameters, Model, Views, Liquid e Explore. Este curso não aborda Dashboards",
      "objectives": [
        "Criar LookML: Models, Tabelas derivadas, dimensions, measures, filters, parameters, suggestion, conditions e muito mais",
        "Criar conexão com Big Query",
        "Configurar um novo projeto",
        "Deploy e configuração do Git (em breve)",
        "Liquid",
        "Explore",
        "Outras aulas estão em produção"
      ],
      "course_content": {
        "Introdução": [
          "O que é Looker?"
        ],
        "Linguagem Liquid": [
          "Conhecendo o Liquid",
          "Editor de Liquid Online",
          "Variáveis: String",
          "Variáveis: Number",
          "Variáveis: Array com Split e Join",
          "IF/ELSE usando Contains",
          "FOR",
          "String com Remove e Capitalize"
        ],
        "Connections": [
          "Arquivos do dataset e tabelas",
          "Criando uma conta de serviço no GCP",
          "Criando conexão com BigQuery"
        ],
        "Project e Model": [
          "Criando um novo Project e Model"
        ],
        "LookML": [
          "Criando um arquivo Model e configurando a conexão do BigQuery",
          "Criando a primeira view e explore",
          "Tabela derivada",
          "Dimension",
          "Dimensions: type",
          "Measures",
          "Adicionando a segunda View e JOIN",
          "Exercício: Crie as demais views e faça JOIN",
          "Filter, Condition e Suggestion",
          "Download de arquivos - Map Layer",
          "Map Layer",
          "Parameter",
          "Estamos gravando novas aulas - Logo postaremos. Fique atento!!!"
        ],
        "Explore": [
          "Conhecendo o Explore",
          "Estamos gravando novas aulas."
        ]
      },
      "requirements": [
        "Ter conhecimentos básicos de alguma linguagem de programação"
      ],
      "description": "Atenção:\nNeste curso, não abordaremos Dashboards.\nDashboards são bem simples de implementar no Looker.\n\nSobre o curso e Looker:\nNeste curso, você apredenrá sobre esta fantástica ferramenta de BI do Google.\nO looker é umas das mais poderosas ferramentas com poder de realtime.\nCrie scrips em LookML, explore seus dados.\nO curso te levará, de uma forma clara e objetiva, a descobrir como funciona o uso de uma base de dados Big Query dentro do Looker.\n\n\nMais sobre o Looker:\nLooker Data Sciences, Inc. é uma empresa americana de software de computador com sede em Santa Cruz, Califórnia. Foi adquirido pelo Google em 2019 e agora faz parte do Google Cloud Platform.\nA Looker comercializa uma plataforma de inteligência de negócios de descoberta e exploração de dados.\nLooker está reinventando a inteligência comercial para a empresa moderna. O Looker funciona da maneira que a Internet faz: baseada em navegador, a linguagem de modelagem exclusiva permite que qualquer funcionário aproveite o trabalho dos melhores analistas de dados. Operando 100% no banco de dados, o Looker utiliza os bancos de dados analíticos mais novos e mais rápidos para obter resultados reais, em tempo real. A arquitetura aberta e leve do Looker facilita para os desenvolvedores criar, implantar e iterar de forma rápida e flexível os aplicativos de dados personalizados.\n\nEstes são alguns tópicos do curso:\nDimensions\nMeasures\nFilters\nParameters\nModel\nViews\nLiquid\nExplore",
      "target_audience": [
        "Desenvolvedores e profissionais de Big Data"
      ]
    },
    {
      "title": "Mastering NumPy: From Basics to Advanced Array Manipulation",
      "url": "https://www.udemy.com/course/mastering-numpy-from-basics-to-advanced-array-manipulation/",
      "bio": "الطريقة الإسهل للتعامل مع المصفوفات والمعادلات الرياضية العلمية، من اضافه، حذف، حفظ، تحويل و تغيير المصفوفات بالبايثون",
      "objectives": [
        "Create, reshape, and manipulate 1D and 2D NumPy arrays - إنشاء وتغيير شكل المصفوفات أحادية وثنائية الأبعاد باستخدام مكتبة نمباي",
        "Perform arithmetic, logical, and comparison operations on arrays - تنفيذ العمليات الحسابية والمنطقية والمقارنة على المصفوفات",
        "Understand broadcasting and apply it in array operations - فهم مفهوم البث وتطبيقه في العمليات على المصفوفات",
        "Work with different array data types - التعامل مع أنواع البيانات المختلفة في المصفوفات",
        "Generate arrays using functions like arange, linspace, and random - إنشاء المصفوفات باستخدام دوال مثل arange وlinspace وrandom",
        "Use advanced indexing methods (boolean, cross, ellipsis) - استخدام طرق الفهرسة المتقدمة (المنطقية، المتقاطعة، النقطية)",
        "Perform aggregation operations such as sum, product, min/max, and mean - تنفيذ عمليات التجميع مثل الجمع، الضرب، الحد الأدنى/الأقصى، والمتوسط",
        "Handle missing values, NaN, and infinity in numerical datasets - التعامل مع القيم المفقودة واللانهاية في البيانات العددية",
        "Apply linear algebra techniques using NumPy (dot product, matrix inversion, etc.) - تطبيق تقنيات الجبر الخطي باستخدام مكتبة نمباي",
        "Perform statistical analysis including variance, standard deviation, and median - إجراء التحليل الإحصائي بما في ذلك التباين، الانحراف المعياري، والوسيط",
        "Split, stack, repeat, and reshape arrays efficiently - تقسيم، دمج، تكرار، وتغيير شكل المصفوفات بكفاءة",
        "Save and load arrays in .npy, .txt, and .zip formats - حفظ واستيراد المصفوفات بصيغ .npy و .txt و .zip",
        "Build a strong foundation for data science, machine learning, and numerical computing - بناء أساس قوي في علم البيانات، تعلم الآلة، والحوسبة العددية"
      ],
      "course_content": {
        "Introduction": [
          "Introduction to numpy course - مقدمة في مكتبة نمباي",
          "Install enviroment - تنصيب بيئة العمل",
          "2.1 Create 1D array",
          "2.2 Create 2D array"
        ],
        "Arithmetic and Mathematical Operations - العمليات الحسابية والرياضية": [
          "3.1 Arithmetic Operations on arrays - Operation on 1D array",
          "3.2 Arithmetic Operations on arrays - Operation on 2D array"
        ],
        "Broadcasting - البث (التوزيع)": [
          "4 Reshaping arrays",
          "5.1 Broadcasting rules",
          "5.2 Broadcasting rules - illustration",
          "5.3 Broadcasting function",
          "5.4 Broadcasting arrays",
          "5.5 Broadcasting to"
        ],
        "Data Types and Type Handling - أنواع البيانات والتعامل معها": [
          "6.1 Array's Data Types",
          "6.2 Differences of data types",
          "6.3 Real size of an array - Numerical Type",
          "6.4 Real size of an array - Object Type",
          "7 Upcasting data types"
        ],
        "Array Creation Methods - طرق إنشاء المصفوفات": [
          "8.1 Types of arrays - zeros array",
          "8.2 Types of arrays - ones array",
          "8.3 Types of arrays - full array",
          "8.4 Types of arrays - empty array",
          "9. Create Vander array",
          "10 Create arange - array range",
          "11.1 Create Linspace - 1D array",
          "11.2 Create linspace - 2D array",
          "12 Complex Arrays and functions"
        ],
        "Randomness in Arrays - العشوائية في المصفوفات": [
          "13.1 Randomness on arrays - random integer function",
          "13.2 Randomness on arrays - random random function",
          "13.3 Randomness on arrays - choice function",
          "13.4 Randomness on arrays - shufle function"
        ],
        "Comparisons and Logic Gates - المقارنات والبوبات المنطقية": [
          "14.1 Comparisons - compare 1D array",
          "14.2 Comparisons - compare 2D array",
          "15.1 Logic Gates - AND gate",
          "15.2 Logic Gates - OR gate",
          "15.3 Logic Gates - NOT gate",
          "16 Finding Elements on arrays using is_in fun"
        ],
        "Indexing and Addressing - الفهرسة والعنونة": [
          "17.1 Address and Indexing - 1D array",
          "17.2 Address and Indexing - 2D array",
          "17.4 Address and Indexing - Boolean indexing",
          "17.5 Address and Indexing - cross indexing ix"
        ],
        "Aggregation Functions - دوال التجميع": [
          "18.1 Aggregation function - summation",
          "18.2 Aggregation function - production",
          "18.3 Aggregation function - maximum and minimum",
          "18.4 Aggregation function - argmin and argmax",
          "18.5 Aggregation function - Amax and Amin",
          "18.6 Aggregation function - min and max",
          "18.7 Aggregation function - Absolute Value"
        ],
        "Element-Wise Operations - العمليات على مستوى العناصر": [
          "19 Add & Append Elements",
          "20 Differences of numbers - Diff function",
          "21 Integer & Fractions - modf function",
          "22 Inverting Sign on elements - sign function",
          "23 Copying Elements sign - copy sign function",
          "24 Rounding Numbers by adding - Round & Aroun",
          "25 Checking Rounded Numbers - Allclose function",
          "26 Squaring Numbers - square & Square root"
        ]
      },
      "requirements": [
        "Basic knowledge of Python syntax (variables, functions, loops, etc.) - معرفة أساسية بصيغة بايثون (المتغيرات، الدوال، الحلقات، إلخ)",
        "A working Python environment (e.g., Anaconda, Jupyter Notebook, or any Python IDE) - أو أي محرر نصوص Jupyter Notebook وال Anaconda بيئة عمل بايثون جاهزة مثل",
        "Very basic math understanding (no advanced mathematics required) - فهم بسيط جداً للرياضيات (لا يُشترط معرفة رياضيات متقدمة)"
      ],
      "description": "وغيرها من التخصصات Deep learning ألي Machine learning لمحللين البيانات ومهندسي الذكاء الاصطناعي بداية من numpy تعد أهميه\n\n\nوبما ان نمباي مبنيه علي المعادلات الرياضية، فأن دراستك ل نمباي لها أهميه بأنها تجعلك تستطيع بناء نموذج آلي بشكل جيد، لاعتماده هذا المجال علي المعادلات الرياضية، وستعرف جيداً كيف يعمل النموذج الآلي ويعطي تنبأ (توقع).\n\n\npandas كما تستخدم نمباي في مجال تحليل البيانات وعلم البيانات لإعتمادها علي الأرقام والمعادلات الإحصائية بجانب البيانات بشكل عام علي  Data frame  الذي يجعلك تتعامل مع جداول تسمي\n\n\nوتتكامل نمباي مع ادوات آخري تستخدم جانباً الي جنب مثل.\nتعتمد علي التعامل مع البيانات علي هيئة جداول في مجالي علم البيانات وهندسه الذكاء الاصطناعي Pandas\nلرسم البيانات علي مخطط ثنائي وثلاثي الابعاد Matplotlip\nولها مميزات كثيره في رسم المخططات الإحصائية matplotlip  لرسم علي مخطط أيضاً مثل Seaborn\n\n\nوتستخدم نمباي في ادوات الخاصة بالذكاء الاصناعي... مثل\nScikit-learn\nPytorch\nوغيرها.\n\n\nاذا كان لديك فكره برنامج سطح مكتب Desk-top وترغب في تنفيذها وهذا الفكرة (البرنامج) يتطلب معادلات رياضية علميه معقده.\n\n\nأذاً نمباي هو الاختيار الأمثل!\n\n\nستتعلم استخدام نمباي بطريقة مختلفة، ليست فقط كلام مجرد، بل ستعرف كيفية استخدامها عن طريق رسوم توضيحية، توضح طريقة عمل نمباي مما يساهم في جعلك تفهم كيفية بناء نموذج آلي بوضوح، بتعلمك لادوات نمباي ستعرف كيفه تفهم وتقرأ البيانات سواء كنت محلل ببانات او مهندس ذكاء أصطناعي او مبرمج تطبيقات سطح مكتب.\n\n\nستدرس نمباي نظري بالرسوم التوضيحية + عملي.\n\n\nكل ما عليك هو معرفه بلغه بايثون، الادوات الاساسية.\n(Anaconda يفضل بيئة عمل) تحميل بيئة العمل",
      "target_audience": [
        "Python beginners who want to learn how to work with arrays and numerical data - المبتدئون في بايثون الذين يرغبون في تعلم كيفية التعامل مع المصفوفات والبيانات العددية",
        "Data science and AI learners looking to master the foundational NumPy library - Numpy متعلمو علم البيانات والذكاء الاصطناعي الذين يسعون لإتقان مكتبة",
        "Computer science and engineering students working on numerical or matrix-based problems - طلاب علوم الحاسب والهندسة الذين يعملون على مسائل عددية أو مبنية على المصفوفات",
        "Developers and analysts who want to speed up data processing using NumPy - Numpy المطورون والمحللون الذين يرغبون في تسريع معالجة البيانات باستخدام",
        "Anyone preparing for data-centric roles or technical interviews involving NumPy - Numpy أي شخص يستعد لأدوار مهنية تعتمد على البيانات أو لمقابلات تقنية تتطلب معرفة بـ",
        "Enthusiasts who enjoy working with data and want to build a solid computational skillset - المهتمون بالبيانات والراغبون في بناء مهارات حسابية قوية"
      ]
    },
    {
      "title": "混沌科学系列科普课程",
      "url": "https://www.udemy.com/course/vvpbuaea/",
      "bio": "本系列课程，联合陈关荣、王雄、李春彪、张旭、马军、刘坚、王青云、叶国栋、禹思敏九位国内的混沌理论研究专家及相关跨学科研究的资深学者，发起了 \"混沌科学系列科普课程\" 。",
      "objectives": [
        "了解混沌科学的形成和发展",
        "掌握混沌科学的一些基础知识",
        "知悉混沌科学的各种基本概念和理论前沿动态",
        "学习如何利用混沌科学赋能自身发展"
      ],
      "course_content": {
        "介绍": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "混沌科学-历史与故事": [
          "课前介绍 (混沌科学一历史与故事)",
          "从经典三体问题谈起",
          "现代混沌科学的诞生",
          "混沌工程技术的希望",
          "离散混沌和文史故事",
          "漫无边际的混沌宇宙"
        ],
        "连续系统里的混沌: 从一到无穷多": [
          "课前介绍 (连续系统里的混沌: 从一到无穷多)",
          "课程大纲 (连续系统里的混沌: 从一到无穷多)",
          "常微分方程: 从线性到非线性",
          "空间: 从一维、二维到三维",
          "平衡点: 从结点到鞍焦点",
          "平衡点稳定性: 从平衡点到吸引子",
          "经典吸引子:从点吸引子到吸引环、吸引环面",
          "混沌吸引子: 从整数维到分数维",
          "更复杂丰富的动力学: 从Lorenz系统到Chen系统",
          "连续系统里的混沌:从一到无穷多",
          "多吸引子共存:从单吸引子到多吸引子共存",
          "众妙之门: 从对称到对称性自发破缺"
        ],
        "混沌吸引子调控与忆阻混沌振荡器设计": [
          "课前介绍 (混沌吸引子调控与忆阻混沌振荡器设计)",
          "引言 (混沌吸引子调控与忆阻混沌振荡器设计",
          "混沌吸引子的几何调控",
          "混沌吸引子的分布调控",
          "忆阻器与忆阻混沌振荡器",
          "忆阻混沌振荡器的调控设计",
          "总结讨论 (混沌吸引子调控与忆阻混沌振荡器设计)"
        ],
        "混沌马蹄理论分析及构造": [
          "课前介绍(混沌马蹄理论分析及构造",
          "马蹄的历史",
          "数学基础简介",
          "系统中的马蹄"
        ],
        "时空混沌和斑图": [
          "课前介绍(时空混沌和斑图)",
          "时空系统分类与概述",
          "局域动力学模型表达",
          "耦合通道属性与表达",
          "赫姆霍兹定理与能量",
          "缺陷与异质性的形成",
          "网络同步与斑图稳定"
        ],
        "复混池系统及分形": [
          "课前介绍 (复混沌系统及分形)",
          "引言 (复混沌系统及分形)",
          "复混沌系统及其动力学",
          "复混沌系统的同步控制",
          "分形的产生",
          "复动力系统的分形集: Mandelbort集和Julia集",
          "分形控制"
        ],
        "神经系统的混沌和分贫动力学": [
          "课前介绍(神经系统的混沌和分岔动力学）",
          "非线性系统的概念和特征",
          "混沌与分岔的提出和实例",
          "神经系统的混沌与分岔",
          "分岔分析在神经系统中的应用"
        ],
        "混沌在图像保密通讯中的应用": [
          "课前介绍(混沌在图像保密通讯中的应用)",
          "图像加密--背景介绍",
          "图像加密--预备知识",
          "图像加密一加密流程",
          "图像加密一实验与分析",
          "图像加密一总结与展望",
          "图像隐藏-背景",
          "图像隐藏预备知识",
          "图像隐藏-视觉有意义图像加密算法",
          "图像隐藏一实验与分析",
          "图像隐藏结论"
        ],
        "混沌电路设计": [
          "课前介绍",
          "讲座开场白",
          "混沌电路设计所需的一些基础知识",
          "混沌系统中简单非线性函数对应的电路设计",
          "混沌电路三种设计方法概述",
          "设计流程图和框图",
          "变量比例压缩变换、微分-积分转换、时间尺度变换",
          "模块化设计的一般方法",
          "模块化设计的两个实例",
          "改进型模块化混沌电路设计",
          "改进型模块化混沌电路设计的两个实例",
          "蔡氏电路的个性化设计、模块化设计、改进型模块化设计",
          "离散时间混沌电路设计",
          "电路仿真与电路实现演示及若干问题"
        ]
      },
      "requirements": [
        "有理科基础，希望学习混沌理论点人群"
      ],
      "description": "21世纪是复杂性的世纪，理解混沌是探索复杂性的关键环节。在科学、工程中，混沌与非线性方法已经成为研究动态系统的主要手段，加深了对气候、生态、大脑、流行病等诸多复杂系统问题的理解，并在湍流、加密、数据分析以及生命科学中有广泛应用。在社会、商业领域，混沌理论在通讯、交通、金融市场、疾病与信息传播等问题中亦有诸多启发和应用。随着混沌现象的进一步系统研究和广泛应用，它正在从一套理论发展为一门科学。\n\n\n为了向跨学科学习者普及混沌科学的理论本质，从而能将混沌科学应用到自己的研究、探索中，帮助大家分析、理解、认知其中的复杂性，集智学园特别策划混沌科学系列课程，导师团队由著名混沌理论学者、香港城市大学讲席教授、欧洲科学院院士陈关荣领衔，联合王雄、李春彪、张旭、马军、刘坚、王青云、叶国栋、禹思敏等国内的混沌理论研究专家及相关跨学科研究的资深学者，开出了 “混沌科学”系列科普课程 。",
      "target_audience": [
        "本课程面向数学、力学、机械、电子、信息安全和脑科学等专业的大学生、研究生、博士生以及相关的从业者",
        "适合希望了解混沌理论、并进行跨学科应用的同学"
      ]
    },
    {
      "title": "电商商品推荐系统项目实战",
      "url": "https://www.udemy.com/course/hiuhnefk/",
      "bio": "基于百万电商数据的建模过程",
      "objectives": [
        "移动电商商品推荐的业务背景",
        "特征处理与特征构建方法",
        "基于规则的预估方法",
        "基于K-MEANS的负采样算法",
        "LR与GBDT模型完成预测",
        "深度学习方法WIDE＆DEEP模型",
        "FM模型及改讲模型NFM",
        "推荐项目的评估指标与优化"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "第一阶段 电商商品推荐系统的介绍与准备": [
          "第1课：商品推荐的项目背景",
          "第2课：商品推荐相关比赛介绍",
          "第3课：商品推荐的环境配置",
          "第4课：商品推荐的数据处理"
        ],
        "第二阶段 电商商品推荐系统的特征工程": [
          "第5课：商品推荐的数据分析与可视化",
          "第6课：基于规则的预测方法",
          "第7课：特征提取相关方法",
          "第8课：特征构建的代码实现"
        ],
        "第三阶段：商品推荐系统模型构建": [
          "第9课：协同过滤算法实现",
          "第10课：逻辑回归算法模型",
          "第11课：GBDT算法模型",
          "第12课：GBDT算法的调参技巧"
        ],
        "第四阶段：商品推荐系统迭代优化": [
          "第13课：推荐项目整体回顾",
          "第14课：Wide & Deep算法模型",
          "第15课：FM与NFM算法模型",
          "第16课：NFM算法代码解读"
        ],
        "课程回顾": [
          "回顾总结"
        ]
      },
      "requirements": [
        "有一定的编程经验"
      ],
      "description": "电商业务在全球各大互联网公司的营收中都占有极其重要的地位，推荐系统对用户推荐商品的质量好坏直接影响了巨头们的股价，商品推荐团队是公司各大算法团队中的核心团队，有着绝对地位的优势。\n本课程为完整的电商商品推荐项目，采用阿里巴巴淘宝电商 真实公开数据集，根据用户在商品全集上的移动端行为数据及百万级的商品信息，建立推荐模型，并预估用户在接下来一天对商品子集购买行为。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课\n公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "有一定机器学习基础",
        "对推荐系统领域感兴趣",
        "有志于从事推荐算法工作"
      ]
    },
    {
      "title": "如何通过ChatGPT提高自己的工作效率",
      "url": "https://www.udemy.com/course/chatgpt-gr/",
      "bio": "以产品经理为例，正确认识AIGC工具，提升职场竞争力",
      "objectives": [
        "能够对AIGC有清晰的认知",
        "能够在工作中充分借助ChatGPT提高工作效率",
        "掌握使用ChatGPT的原则与规范",
        "掌握如何使用ChatGPT提示词提去需求"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍",
          "讲师介绍",
          "课程大纲"
        ],
        "AIGC与其他内容工具有何区别": [
          "AIGC不是什么",
          "AIGC是什么"
        ],
        "ChatGPT的正确使用方式": [
          "应用的指导思想",
          "提示词的使用原则",
          "提示词的使用方法"
        ],
        "产品经理办公场景应用案例": [
          "产品经理办公场景应用案例"
        ],
        "课程回顾": [
          "课程寄语"
        ]
      },
      "requirements": [
        "无需经验"
      ],
      "description": "欢迎来到如何通过ChatGPT提高自己的工作效率课堂，ChatGPT自发布以来就一直是讨论的热点，应运而生的就是ChatGPT在各领域的应用。\n本节课主要为大家讲解什么是AIGC，以及大家在使用AIGC产品时要注意的原则、使用方法以及使用规范。最后以产品经理岗位为例，为大家讲解在实际工作场景中，一些使用AIGC产品的技巧和案例。\n希望经过本节课的学习，大家能够了解并动手使用AIGC，提高工作效率和自身的核心竞争力。",
      "target_audience": [
        "渴望通过Chatgpt提高工作效率的产品经理",
        "对AIGC感兴趣者",
        "想要提升职场竞争力的人群"
      ]
    },
    {
      "title": "AI通过强化Q-Learning学习《猫抓老鼠》游戏【中字】",
      "url": "https://www.udemy.com/course/aiq-learning/",
      "bio": "与汤姆和杰瑞一起学习强化学习：制作一个Q-Learning游戏",
      "objectives": [
        "强化Q-Learning的基本原理。",
        "如何使用Python和Turtle图形创建“猫和老鼠”游戏。",
        "设置游戏画面并创建游戏元素。",
        "为Q-learning算法定义状态空间和动作空间。",
        "奖励塑造及其在强化学习中的作用。",
        "在Q-learning过程中平衡探索和开发。",
        "使用Q-learning训练猎物（杰瑞）和捕食者（汤姆）智能体。",
        "根据奖励和预期未来奖励更新Q表。",
        "在游戏环境中处理障碍并达成目标。",
        "微调超参数，提高学习效率。",
        "通过Python编程和Turtle图形获得实践经验。",
        "培养解决问题的能力和算法思维能力。"
      ],
      "course_content": {},
      "requirements": [
        "具备Python编程语言的基础知识。",
        "熟悉基本编程概念（变量、循环、条件、函数）。"
      ],
      "description": "通过创建一个有趣且互动的“猫和老鼠”游戏项目来学习强化Q-Learning！在这个综合课程中，您将深入了解强化学习的世界，并使用Python和Turtle图形库构建Q-learning代理。\n\n\n强化Q-Learning是机器学习中一种流行的方法，它使智能体能够通过反复试验来学习环境中的最佳行为。通过在经典的“猫和老鼠”游戏中实施该算法，您将深入了解Q-learning的工作原理以及如何将其应用于解决现实世界的问题。\n\n\n在整个课程中，您将逐步学习如何开发游戏项目。首先，您将使用Turtle库设置游戏画面并创建游戏元素，包括汤姆和杰瑞角色。接下来，您将定义状态空间和动作空间，作为Q-learning算法的基础。\n\n\n课程将涵盖奖励塑造、折扣系数和探索-开发权衡等重要概念。您将学习如何使用Q-learning训练猎物（杰瑞）和捕食者（汤姆）智能体，根据奖励和未来预期奖励更新其Q表。通过迭代更新Q表，智能体将学习最佳行动，以在游戏环境中导航并实现目标。\n\n\n在整个课程中，您将探索各种场景和挑战，包括躲避障碍物、到达目标海龟以及优化智能体的策略。您将分析智能体的表现，并观察它们的Q表在每次训练迭代中的变化。此外，您还将学习如何微调Q学习算法的超参数，以提高智能体的学习效率。\n\n\n在本课程结束时，您将深入了解强化Q学习，并了解如何将其应用于在游戏环境中创建智能代理。您将掌握Python、Turtle图形和Q学习算法的实践经验。无论您是机器学习领域的初学者还是经验丰富的从业者，本课程都将提升您的技能，让您有能力解决复杂的强化学习问题。\n\n\n立即注册，通过“汤姆和杰瑞”游戏项目开始掌握强化Q-Learning的激动人心的旅程！让我们训练汤姆和杰瑞智胜对方，在这个充满活力和吸引力的学习体验中实现他们的目标。",
      "target_audience": [
        "机器学习初学者，希望深入研究强化学习。",
        "希望扩展技能以学习Q-learning的Python开发者。",
        "希望在实际项目中获得强化学习实践经验的学生或专业人士。",
        "希望通过有趣且互动的游戏来了解Q-learning的概念和应用。"
      ]
    },
    {
      "title": "JASP統計分析實務(3)",
      "url": "https://www.udemy.com/course/sem-kychen/",
      "bio": "結構方程模型分析篇",
      "objectives": [
        "1. 利用JASP軟體執行結構方程模型分析",
        "2. 運用驗證性因素分析技術，檢測量表的信效度",
        "3. 運用路徑分析技術，驗證構面間的因果關係",
        "4. 運用Sobel Test、Bootstrap等技術，進行中介效果檢定",
        "5. 運用多群組分析技術，進行干擾效果檢定",
        "6. 理解與實作測量恆等性分析與模型泛化檢定"
      ],
      "course_content": {
        "何謂結構方程模型": [
          "觀察變數 vs. 潛在變數",
          "觀察變數與潛在變數的關係",
          "測量潛在變數—使用單一觀察變數",
          "測量潛在變數—使用多題項尺度",
          "測量潛在變數—使用降維技術",
          "何謂結構方程模型",
          "結構方程模型的目的",
          "結構方程模型的構造",
          "結構方程模型的原理"
        ],
        "發展結構方程模型的步驟": [
          "第1步驟—理論發展",
          "第2步驟—模型界定",
          "第3步驟—模型識別",
          "第4步驟—抽樣與測量",
          "第5步驟—參數估計",
          "第6步驟—模型配適度估計",
          "第7步驟—模型修改",
          "第8步驟—討論與結論"
        ],
        "模型的配適度指標": [
          "絕對配適度指標",
          "增量配適度指標",
          "精簡配適度指標"
        ],
        "結構方程模型於論文中的應用": [
          "SEM的實務分析流程",
          "結構方程模型的論文型態",
          "SEM論文型態—基本型態",
          "SEM論文型態—以現存著名之模型或理論為基礎",
          "SEM論文型態—競爭模型",
          "SEM論文型態—恆等性檢定",
          "SEM論文型態—量表發展",
          "SEM論文型態—中介、干擾模型"
        ],
        "信度與效度分析": [
          "信度簡介",
          "信度分析實作",
          "項目分析—題項總分相關法簡介",
          "項目分析—題項總分相關法實作",
          "效度簡介",
          "因素分析技術的種類",
          "因素分析的數學模型",
          "因素負荷量的意義",
          "共通性的意義",
          "特徵值的意義",
          "因素分析的基本步驟(1)—前提條件",
          "因素分析的基本步驟(2)—因素萃取",
          "因素分析的基本步驟(3)—因素命名",
          "因素分析的基本步驟(4)—計算因素得分",
          "以主成分分析簡化資料",
          "探索性因素分析簡介",
          "探索性因素分析實作",
          "驗證性因素分析簡介",
          "EFA vs CFA—作法上的差異",
          "EFA vs CFA—目的上的差異",
          "EFA vs CFA—應用上的差異",
          "EFA與CFA的結合",
          "CR值與AVE值簡介",
          "驗證性因素分析實作",
          "共同方法變異之基本概念",
          "檢測共同方法變異實作"
        ],
        "結構方程模型分析實作": [
          "範例論文—Brand Image",
          "Lavaan的基本語法簡介",
          "範例論文的測量模型",
          "範例論文的結構模型",
          "範例論文的測量模型分析實作",
          "範例論文的結構模型分析實作",
          "模型修正簡介",
          "模型修正的範例"
        ],
        "中介效果檢定": [
          "中介效果簡介",
          "中介效果檢定—Sobel Test",
          "中介效果檢定—Bootstrapping法"
        ],
        "干擾效果檢定": [
          "干擾效果簡介",
          "干擾效果檢定—多群組結構方程模型分析",
          "干擾效果檢定—潛在交互作用項"
        ],
        "恆等性檢驗": [
          "恆等性概念簡介",
          "測量恆等性檢定實作",
          "模型泛化性檢定實作"
        ]
      },
      "requirements": [
        "須具備JASP軟體的基本操作基礎。"
      ],
      "description": "這門課程旨在系統性介紹結構方程模型（Structural Equation Modeling, SEM）的理論基礎與實務應用，適合已具備基礎統計學與研究方法訓練的學員。課程將從 SEM 的基本概念與特徵出發，逐步說明路徑分析、驗證性因素分析與潛在變項的建構邏輯，並深入探討模型估計、適配度評估及修正策略。除理論講授外，課程也強調實際操作，將帶領學員使用JASP統計軟體進行資料處理與模型分析，並透過案例練習加強實務技能。學員不僅能學習如何建構與驗證理論模型，還能培養解讀與批判 SEM 研究的能力。課程結束後，學員將能獨立完成結構方程模型的研究設計與分析，並將其應用於社會科學、教育、管理及其他相關領域的研究與實務問題中。",
      "target_audience": [
        "任何希望使用JASP軟體，進行結構方程模型分析的大學教師、資料分析師或研究方法學家"
      ]
    },
    {
      "title": "【AI研究者が解説】データサイエンス入門 - PythonとAIで学ぶデータ分析の基礎から応用",
      "url": "https://www.udemy.com/course/ai-pythonai/",
      "bio": "Google Colabで学ぶデータ分析の実践力。統計からディープラーニングまで、データの分析手法とAIモデルの実装を網羅的に解説",
      "objectives": [
        "Pythonを使用したデータ前処理から高度な分析手法まで、実践的なデータサイエンススキルを習得。Pandas、NumPy、Scikit-learnなどの主要ライブラリを使いこなし、ビジネスデータの分析ができるようになります。",
        "統計的分析から機械学習モデルの構築まで、データに基づく意思決定手法を体系的に学習。実際のビジネスケースを用いて、問題解決のための分析アプローチを身につけます。",
        "Google Colaboratoryを活用した効率的な分析環境の構築方法を習得。大規模データの処理から視覚化まで、クラウド環境を活用した実践的なデータ分析スキルを身につけます。",
        "機械学習モデルの評価指標や最適化手法を理解し、モデルの性能向上に必要な技術を習得。さらに、分析結果の効果的な可視化とビジネス提案への活用方法を学びます。"
      ],
      "course_content": {
        "はじめに - AIへの第一歩": [
          "コース概要",
          "なぜデータサイエンス・AIを学ぶのか",
          "自己紹介",
          "【教養】人工知能の歴史",
          "コースの概要一覧（再喝）"
        ],
        "データサイエンスの基礎": [
          "Google Colabの環境設定と基本操作",
          "【教養】 CPUとGPUの違いとは？",
          "データサイエンスの基礎のスタート（NumPyから）",
          "numpy配列の作成",
          "numpy配列の属性確認",
          "numpy配列の要素にアクセス",
          "スライス操作の基本",
          "配列の初期化",
          "【少しひと休み】なぜ配列操作が大事なのか？",
          "範囲指定で配列を作成",
          "配列の操作の基本",
          "統計関数",
          "データフレームの作成",
          "特定の行・列・要素の選択",
          "データのフィルタリング",
          "titanic.csv",
          "titanic.csvのダウンロード",
          "titanic.csvのデータ構造を見ていく",
          "matplotlibのインポート",
          "シンプルな図の作成",
          "基本的なプロットの作成",
          "2 x 2の図の図示",
          "プロットのスタイリング",
          "軸のスケールの設定",
          "タイタニックデータの可視化",
          "発展：Seabornによる高度な可視化",
          "発展：Plotlyによるインタラクティブな可視化"
        ],
        "データ収集と自動化 - Webスクレイピング入門": [
          "スクレイピングとは？",
          "実際のwebサイトの閲覧",
          "スプレッドシートとの連携",
          "BeautifulSoupでhtmlを解析",
          "Beutifulsoupで取得したデータをスプレッドシートに保存",
          "Seleniumとは？",
          "ドライバーの設定",
          "Seleniumを使って動的にスクレイピングしてみよう",
          "Seleniumで取得したデータをスプレッドシートに保存"
        ],
        "データを扱うための準備 - 前処理の重要性": [
          "欠損値の処理",
          "外れ値の検出と処理",
          "データ型の変換",
          "正規化と標準化の違い",
          "正規化と標準化のコードを書いてみよう"
        ],
        "データ分析手法の基礎と応用": [
          "記述統計の基礎",
          "相関分析",
          "仮説検定の基礎",
          "t検定のコードを書いてみよう",
          "回帰分析とは？",
          "回帰分析のコードを書いてみよう",
          "NotoSansJP-VariableFont_wght.ttf",
          "rashomon.txt",
          "テキスト分析（形態素分析）の前準備",
          "単語の頻度分析をしてみよう①",
          "単語の頻度分析をしてみよう②",
          "WordCloudを使ってみよう"
        ],
        "機械学習の基礎": [
          "線形回帰モデル",
          "平均二乗誤差とは？",
          "線形回帰モデルで予測をしてみよう",
          "決定木とは",
          "決定木で予測をしてみよう",
          "クラスタリングの基礎（k-means)",
          "バギング手法とブースティング手法について",
          "ランダムフォレスト",
          "勾配ブースティング（XGBoost）",
          "勾配ブースティング（LightGBM）"
        ],
        "ディープラーニングの基礎と実践": [
          "ディープラーニングとは？",
          "ディープラーニングの全体像",
          "ディープラーニングの仕組み",
          "誤差逆伝播法",
          "勾配降下法",
          "畳み込みニューラルネットワークについて",
          "TensorFlowについて",
          "データ準備（MNISTデータ）",
          "CNNモデルの構築",
          "CNNモデルの学習"
        ],
        "終わりに": [
          "全体の振り返り",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "プログラミングの基礎知識（PythonやそれCのプログラミング言語の基本的な理解）",
        "基礎的な数学の知識（高校数学レベルの統計、確率の理解）",
        "Googleアカウント（Google Colaboratoryを使用するため）",
        "データ分析に対する興味と学習意欲"
      ],
      "description": "「データサイエンスって難しそう...」「AI開発は専門家だけのもの？」そんな不安を抱えていませんか？\n\n\n本コースでは、プログラミング初心者でも理解できるよう、データサイエンスとAIの基礎から実践的なスキルまでを段階的に学んでいきます。\n\n\n【このコースで学べること】\n\n\n- Google Colabを使った実践的な環境構築\n- NumPy/Pandasによるデータ操作の基礎\n- matplotlib/Seaborn/Plotlyを使った魅力的なデータ可視化\n- Webスクレイピングによる自動データ収集\n- 実務で必須のデータ前処理テクニック\n- 統計分析から機械学習、ディープラーニングまでの基本概念と実装\n\n\n特徴的なのは、単なる理論解説ではなく、実際のデータ（Titanicデータセットなど）を使った分析や、小説『羅生門』のテキスト分析など、実践的なプロジェクトを通じて学べること。また、AIの歴史や技術の背景も解説するので、「なぜ」を理解しながら学習できます。\n\n\n【こんな方におすすめ】\n\n\n- データサイエンスやAIの基礎を体系的に学びたい方\n- プログラミング初心者でもAI技術に挑戦したい方\n- 理論だけでなく実践的なスキルを身につけたい方\n- 自分でデータ分析からモデル構築までできるようになりたい方\n\n\n80のレクチャーを通じて、NumPyの基礎からCNNモデルの構築まで、データサイエンスとAIの全体像を把握できるカリキュラム構成になっています。\n\n\nプログラミングが初めての方でも安心して学べるよう、基本的な操作から丁寧に解説。データサイエンスの力を身につけて、あなたのキャリアに新たな可能性を広げましょう！",
      "target_audience": [
        "データ分析やAIの実務への活用方法を体系的に学びたいビジネスパーソン",
        "マーケティング、営業、経営企画などでデータドリブンな意思決定を行いたい方",
        "データサイエンティストやAIエンジニアを目指す方",
        "自社のデータを活用して業務改善や新規サービス開発を行いたい方"
      ]
    },
    {
      "title": "Fundamentals of Mathematics for Machine Learning | Arabic",
      "url": "https://www.udemy.com/course/fundamentals-of-mathematics-for-machine-learning-arabic/",
      "bio": "Mathematics Essentials with Derivations: Linear Algebra, Calculus, Probability, Statistics and Information Theory",
      "objectives": [
        "Linear Algebra concepts like vectors and matrices",
        "How to perform operations on vectors like dot product",
        "Linear transformations on vectors",
        "Matrix inversion and how to derive it",
        "Linear independence of vectors, span and basis of vector spaces",
        "Intuition behind derivatives and integrals",
        "How to derive derivatives and integrals",
        "Chain rule and its proof",
        "Gradients and partial derivatives",
        "Intuition behind different aspects of probability and statistics",
        "Derivation of various probability distributions like normal distribution",
        "Bayes' rule and Bayesian inference and its derivation",
        "Monte Carlo sampling",
        "Central Limit Theorem and law of big numbers",
        "Estimators, bias and variance",
        "Information theory fundamentals like entropy",
        "Cross entropy and Kullback–Leibler divergence"
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Linear Algebra": [
          "Linear Algebra"
        ],
        "Calculus and Integrals": [
          "Calculus and Integrals"
        ],
        "Probability and Statistics": [
          "Probability",
          "Statistics"
        ],
        "Information Theory": [
          "Information Theory"
        ]
      },
      "requirements": [
        "Basics of mathematics obtained from school"
      ],
      "description": "This course will give you a deep and comprehensive understanding of various branches of mathematics, including linear algebra, calculus, probability, statistics, and information theory. You will explore fundamental concepts such as vectors, matrices in linear algebra; limits, derivatives, integrals, and the chain rule in calculus; random variables, probability distributions, the normal distribution, and Bayes' theorem in probability; and entropy, mutual information, and the Kullback-Leibler divergence in information theory.\nAdditionally, this course will not only introduce you to the key formulas but will also provide their derivations, proofs, and intuitive explanations, ensuring you truly understand the reasoning behind them. You don’t need to be an expert in mathematics to take this course. So, whether you want to dive into data science, machine learning, or deep learning, or if you simply seek to build a solid foundation in mathematics to confidently tackle more advanced topics, this course is perfectly designed for you. Hope you enjoy learning!\nستمنحك هذه الدورة فهمًا عميقًا وشاملاً لمختلف فروع الرياضيات، بما في ذلك الجبر الخطي، والتفاضل والتكامل، والاحتمالات، والإحصاء، ونظرية المعلومات. ستتعلم أساسيات مثل المتجهات (Vectors)، والمصفوفات (Matrices) في الجبر الخطي؛ النهايات (Limits)، والمشتقات (Derivatives)، والتكاملات (Integrals)، وقاعدة السلسلة (Chain Rule) في التفاضل والتكامل؛ المتغيرات العشوائية (Random Variables)، والتوزيعات الاحتمالية (Probability Distributions)، والتوزيع الطبيعي (Normal Distribution)، ونظرية بايز (Bayes' Theorem) في الاحتمالات؛ والإنتروبيا (Entropy)، والمعلومات المتبادلة (Mutual Information)، وتباعد كولباك-ليبلر (Kullback-Leibler Divergence) في نظرية المعلومات.\nعلاوة على ذلك، لن تقتصر هذه الدورة على تعريفك بالمعادلات والقوانين فقط، بل ستوفر لك اشتقاقاتها وإثباتاتها وتفسيرها المنطقي، مما يجعلك تفهم بعمق الأسس الرياضية وراء كل مفهوم. لا تحتاج إلى أن تكون خبيرًا في الرياضيات للانضمام إلى هذه الدورة. لذلك، سواء كنت ترغب في التعمق في علوم البيانات أو تعلم الآلة أو التعلم العميق، أو إذا كنت تسعى إلى بناء أساس قوي في الرياضيات لتكون أكثر ثقة عند التعامل مع الموضوعات المتقدمة، فهذه الدورة مصممة خصيصًا لك. أتمنى لك تعلمًا ممتعًا!",
      "target_audience": [
        "Anyone who is interested to understand the fundamental mathematics with their proofs and derivations and not only memorizing them",
        "Anyone who is interested in computer science, data science, machine learning or deep learning."
      ]
    },
    {
      "title": "ChatGPT应用指南：日常生活的专业后援团",
      "url": "https://www.udemy.com/course/chatgpt-kc/",
      "bio": "让ChatGPT成为你的生活助理",
      "objectives": [
        "1.全面了解ChatGPT在学习、生活上的工具性作用",
        "2.通过进一步对ChatGPT的学习，优化学习策略，提升自主学习能力",
        "3.通过使用ChatGPT，加快对金融市场的分析",
        "4.增强跨行业沟通技能，文化壁垒带来的不便"
      ],
      "course_content": {
        "课程内容": [
          "ChatGPT学习提升篇",
          "ChatGPT+PDF：速读文件，提效神器",
          "6款精品插件_应用——把ChatGPT玩出花",
          "让ChatGPT成为你的定制化导游",
          "让ChatGPT成为你懂金融的朋友",
          "让ChatGPT成为你懂教育的朋友",
          "让ChatGPT成为你懂装修设计的朋友"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "具备初步的ChatGPT基础知识即可"
      ],
      "description": "在学习、生活过程中，你是否也有以下问题：英语学习过程中找不到合拍的伙伴？阅读海量文献时无法速度内容，提出核心观点？旅游过程中攻略无从下手？想要金融投资，徘徊不定没有可行性策略？想要教育辅导没有因材施教的方法？想要装修独特，却只能听从他人摸不到门路。\n\n为此，三节课邀请知名自媒体人、玩转新媒体工具的陈榕榕老师带来本次课程。\n\n只要你对将ChatGPT运用于生活中感兴趣，课程将带你全面了解ChatGPT在学习、生活上的全新工具性作用，增强跨行业的实操技能，打破认知以及文化壁垒带来的不便。",
      "target_audience": [
        "1.对将ChatGPT运用于生活中感兴趣的学员",
        "2.期望通过ChatGPT提升学习效率与技能的人员",
        "3.想要提升自身装修灵感以及金融认知的学员"
      ]
    },
    {
      "title": "JASP統計分析實務(2)",
      "url": "https://www.udemy.com/course/jasp2-kychen/",
      "bio": "基礎統計分析篇",
      "objectives": [
        "能妥適運用各種統計分析功能，並正確解析分析結果",
        "能具備獨立規劃研究之能力",
        "能瞭解高品質期刊文章中的研究設計、執行過程與成果",
        "能具備各種基礎統計分析技能，以作為進階統計分析之基礎"
      ],
      "course_content": {
        "相關分析": [
          "單元39_相關分析的基本概念",
          "單元40_求算Pearson相關係數—範例1",
          "單元41_求算Pearson相關係數—範例2",
          "單元42_Spearman等級相關係數",
          "單元43_偏相關分析的基本概念",
          "單元44_求算偏相關係數"
        ],
        "卡方檢定": [
          "單元45_交叉表與卡方檢定的關係",
          "單元46_卡方檢定簡介",
          "單元47_卡方檢定的種類",
          "單元48_卡方獨立性檢定實作",
          "單元49_卡方適合度檢定實作",
          "單元50_無回應偏差—卡方同質性檢定的應用"
        ],
        "兩樣本的平均數差異性檢定—t檢定": [
          "單元51_推論統計的概念",
          "單元52_假設檢定的基本概念",
          "單元53_假設檢定的基本步驟",
          "單元54_單一樣本t檢定簡介",
          "單元55_單一樣本t檢定實作",
          "單元56_獨立樣本t檢定簡介",
          "單元57_獨立樣本t檢定—範例1",
          "單元58_獨立樣本t檢定—範例2",
          "單元59_獨立樣本t檢定—範例3",
          "單元60_成對(相依)樣本t檢定簡介",
          "單元61_成對(相依)樣本t檢定—範例1",
          "單元62_成對(相依)樣本t檢定—範例2"
        ],
        "多群組的平均數差異性檢定—單因子變異數分析": [
          "單元63_變異數分析簡介",
          "單元64_變異數分析的原理",
          "單元65_單因子變異數分析的基本步驟",
          "單元66_單因子變異數分析—範例1",
          "單元67_實務顯著性",
          "單元68_單因子變異數分析—範例2",
          "單元69_單因子相依樣本變異數分析簡介(1)",
          "單元70_單因子相依樣本變異數分析簡介(2)",
          "單元71_單因子相依樣本變異數分析實作"
        ],
        "迴歸分析": [
          "單元72_迴歸分析簡介",
          "單元73_簡單線性迴歸簡介",
          "單元74_多元迴歸模型簡介",
          "單元75_多元迴歸模型的分析步驟",
          "單元76_多元迴歸模型的評鑑—殘差分析",
          "單元77_多元迴歸模型分析實作",
          "單元78_自變數含類別變數的迴歸分析"
        ]
      },
      "requirements": [
        "本課程從統計學基本概念開始，以漸進式方式進行介紹，因此無需事先瞭解 JASP 軟體或具備任何統計學基礎。",
        "須熱衷於統計資料分析工作，或對研究工作有興趣者。"
      ],
      "description": "JASP是一套免費、開源、圖形化介面的統計軟體，操作直觀，支援貝葉斯(Bayes)與傳統統計，功能相當強大，甚至超越SPSS。本課程內容涵蓋了基礎統計分析時，所需用到的各種統計方法，諸如：卡方檢定、t檢定、變異數分析、相關分析、迴歸分析等。而且課程中幾乎所有的範例都是實際碩士論文的原始資料與分析結果，期盼讓讀者能身歷其境，融入統計分析之實作情境中。本課程特別適用於初學者，當作基礎統計學或應用統計學等課程的實習教材。另外，亦可作為學術論文寫作或製作畢業專題之統計分析指導手冊。",
      "target_audience": [
        "希望能精熟JASP統計技術，並在高影響力期刊上發表學術論文的碩、博士生和研究人員。",
        "希望能運用JASP並提升資料分析技能的教職人員。",
        "以市場調查、行銷研究為職業生涯的專業人士。"
      ]
    },
    {
      "title": "AI数学④ 文系・中高年の方でも分かる！AIのための数学入門（確率編） ― 国立大学首席卒の講師がゼロから解説！",
      "url": "https://www.udemy.com/course/ai4-ai-o/",
      "bio": "40代・50代・60代からの学び直しに最適！ 数学が苦手でも「条件付き確率」や「確率の乗法定理」を理解し、AIの判断ロジックや未来予測の仕組みが“見える化”できる",
      "objectives": [
        "確率の基本的な考え方と日常生活やAIにおける役割",
        "確率の加法定理・乗法定理を使った計算の仕組み",
        "条件付き確率の意味と計算方法",
        "スパム判定や医療診断に応用されるベイズ的な確率思考",
        "機械学習・AIにおける確率モデルの基盤的な理解",
        "数学が苦手でも確率を「概念」として理解し、応用できる力"
      ],
      "course_content": {
        "確率の乗法定理と条件付き確率": [
          "積事象の確率",
          "条件付き確率の公式の成り立ち( 1 )",
          "条件付き確率の公式の成り立ち ( 2 )",
          "条件付き確率 ( 具体例 ) の従属と独立 ( 1 )",
          "条件付き確率 ( 具体例 ) の従属と独立 ( 2 )",
          "AとBが互いに独立の場合 ( 乗法定理 )",
          "乗法定理の利用 ( 証明 )",
          "乗法定理と条件付き確率の利用 ( 例題 )"
        ]
      },
      "requirements": [
        "高校レベルの数学を完全に理解している必要はありません",
        "四則演算や分数・割合などの基礎的な計算ができれば十分です",
        "確率を初めて学ぶ方、昔習ったけど忘れた方でも受講可能です",
        "AIや機械学習に関心があることが最大の前提条件です",
        "パソコンや特別なソフトは不要、ノートと筆記用具で学べます",
        "「数学は苦手だけど、AIを理解したい！」という気持ちがあればOKです"
      ],
      "description": "AIが未来を予測したり、データから最適な判断を下すとき、その背後で欠かせないのが「確率」です。\n\nたとえばスパムメールの判定、医療診断、株価予測、レコメンド機能…。私たちの日常を支えるAIは、常に「確率」をもとに動いています。そのため、AIを本質的に理解するには、この「確率」を避けて通ることはできません。\n\n\nしかし、多くの方が「確率＝難しい」「公式を暗記するもの」という苦手意識を持っています。そこで本講座では、確率の基礎を“文系でもわかるように”丁寧に解説。特に、AIや機械学習で中心的な役割を果たす 「確率の乗法定理」 や 「条件付き確率」 を重点的に学びます。\n\n\nこのコースでは次のようなステップで理解を深めます。\n基礎からスタート：「確率とは何か？」を事例で解説。\n確率の計算方法：乗法定理をシンプルに整理。\n条件付き確率：AIの判断ロジックの核心を具体例で学ぶ。\n\n\n講師は、国立大学を首席で卒業した教育のプロフェッショナル。これまで行列・積分・微分を学んできた流れを踏まえ、AI数学シリーズ第4弾として「確率」を徹底的にわかりやすく解説します。\nこのコースで得られること\n数学が苦手でも確率の基礎が理解できる\n「条件付き確率」を通じてAIの判断プロセスが見えるようになる\n機械学習・深層学習に進むための土台ができる\n日常の意思決定にも役立つ「確率思考」を身につけられる\nこんな方におすすめ\n数学に苦手意識がある文系・中高年の方\nAIや機械学習を学びたいが、数学がハードルになっている方\nデータ分析やPythonを学ぶ前に、数学の基礎を固めたい方\nリスキリング・キャリア再構築を目指す40代～60代の方\nAIの仕組みを“ブラックボックスのまま”にしておきたくない方\nAI数学シリーズ④「確率編」で、AI時代に不可欠な「確率思考」を一緒に身につけていきましょう！",
      "target_audience": [
        "数学に苦手意識がある文系の方",
        "40代～60代でリスキリングや学び直しを考えている方",
        "AIや機械学習の基礎を理解したい社会人・学生",
        "データ分析やPython学習に進む前に基礎を固めたい方",
        "AIの仕組みを“ブラックボックス”のままにしておきたくない方",
        "理論の背景を理解し、仕事や日常に活かしたい方"
      ]
    },
    {
      "title": "通义千问AI大模型私有化部署",
      "url": "https://www.udemy.com/course/ai-ykwkc/",
      "bio": "阿里通义千问大模型私有化部署：AIGC从理论到实践的全面解析",
      "objectives": [
        "学员通过本课程将全面掌握通义千问大模型的私有化部署技术，包括模型训练、调优、部署等核心技术，从而提升自己的技术能力，成为大模型私有化部署领域的专家。",
        "私有化部署使得企业能够根据自身业务需求进行模型的定制和优化，激发企业的自主创新能力，推动业务快速发展。",
        "通过私有化部署，企业可以将模型和数据存储在本地，有效保障数据安全与隐私，避免数据泄露和滥用风险，增强企业的数据治理能力。",
        "私有化部署的通义千问大模型将为企业带来更高效的数据处理和分析能力，优化业务流程，提升决策质量和效率。"
      ],
      "course_content": {
        "课程导读": [
          "课程介绍"
        ],
        "课程内容": [
          "第一章_大模型（LLM）概述_1.1_大模型到底“大”在哪里？",
          "第一章_大模型（LLM）概述_1.2_大模型底层架构？",
          "第一章_大模型（LLM）概述_1.3_大模型如何选型",
          "第一章_大模型（LLM）概述_1.4_大模型的存储格式",
          "第一章_大模型（LLM）概述_1.5_大模型的上下游生态",
          "第二章_通义千问技术选型_通义千问大模型私有化部署",
          "第三章_通义千问环境搭建_通义千问大模型私有化部署",
          "第四章_大模型基本应用_通义千问大模型私有化部署",
          "第五章_大模型产品化封装_通义千问大模型私有化部署"
        ],
        "课程回顾": [
          "课程总结"
        ]
      },
      "requirements": [
        "零基础"
      ],
      "description": "随着大数据时代的到来，AI大模型在各个领域的应用越来越广泛。然而，在实际应用中，许多企业面临着模型训练时间长、性能不稳定等挑战。此外，由于数据安全和隐私保护的需求，越来越多的企业开始考虑将AI大模型私有化部署。为了解决这些行业问题，三节课邀请李晓华老师带来《通义千问大模型私有化部署》课程。本课程将围绕通义千问大模型的私有化部署展开，从理论到实践，为学员提供全面的指导和支持。通过学习本课程，学员将能够掌握私有化部署的关键技术，解决模型训练和应用中的痛点问题，提升企业智能化水平，实现业务价值的最大化",
      "target_audience": [
        "企业中的技术决策者",
        "数据科学家和机器学习工程师",
        "IT架构师和系统管理员",
        "对AI和大数据有兴趣的专业人士"
      ]
    },
    {
      "title": "【データ分析】エクセルでできる判別分析！画像検査・工程診断・異常検知などAIを使わず自分で解析と最適化を可能にするコース",
      "url": "https://www.udemy.com/course/mt_method/",
      "bio": "ＡＩでやっているパターン認識を仕事で使ってみたいけど、どんなふうにできるのか、何に使えるのかイメージが湧かないという人のためのコースです。機械学習と同等に実用化が進んでいるＭＴ法で解説します。受講後すぐに自分の課題に使うことができます。",
      "objectives": [
        "判別分析の計算法（ＭＴ法，ＲＴ法，誤圧）",
        "職場のどんなところで判別分析が有効か",
        "自工程完結、画像検査などの実務に応用する方法",
        "エクセルで解析するスキル"
      ],
      "course_content": {
        "はじめに": [
          "このコースの全体像と学べること",
          "このコースで得られるもの",
          "実践できる人だけが成果を得ることができる"
        ],
        "判別分析の手法": [
          "このセクションで学べること",
          "ＡＩの定義について",
          "深層学習とＭＴ法の比較",
          "ＭＴシステムの計算法"
        ],
        "計算に必要な知識": [
          "このセクションで学べること",
          "データの規準化",
          "ＳＮ比の計算式",
          "計算に使うエクセル関数"
        ],
        "ＭＴ法の計算と演習": [
          "このセクションで学べること",
          "ＭＴ法の考え方",
          "ＭＴ法の計算イメージ",
          "MT法の計算手順",
          "主な活用分野、いろいろな活用例",
          "適用事例の紹介",
          "エクセル計算の実演（1）ＭＤの計算",
          "エクセル計算の実演（2）項目選択",
          "（ワーク）ＭＴ法の計算演習を 自分でもやってみましょう"
        ],
        "ＲＴ法の計算と演習": [
          "このセクションで学べること",
          "ＲＴ法とは",
          "ＲＴ法の計算手順",
          "適用事例の紹介",
          "エクセル計算の実演",
          "（ワーク）ＲＴ法の計算演習を 自分でもやってみましょう"
        ],
        "誤圧の計算と演習": [
          "このセクションで学べること",
          "誤圧とは",
          "誤圧の計算手順",
          "適用事例の紹介",
          "エクセル計算の実演",
          "（ワーク）誤圧の計算演習を自分でもやってみましょう"
        ],
        "計算法の比較": [
          "このセクションで学べること",
          "誤圧の事例をＲＴ法で計算してみる",
          "誤圧の事例をＭＴ法で計算してみる",
          "計算法比較のまとめ",
          "（ワーク）このセクションの計算演習を自分でもやってみましょう"
        ],
        "機械学習との比較": [
          "このセクションで学べること",
          "機械学習と同じことができるか",
          "アヤメの分類で比較する",
          "（ワーク）身のまわりにあるデータを使って 判別計算をやってみましょう"
        ],
        "活用するために": [
          "このセクションで学べること",
          "定量化が必要",
          "どんな事例があるか",
          "ソフトウェア，参考文献"
        ],
        "お礼とまとめ": [
          "お礼とまとめ",
          "ラストメッセージ"
        ]
      },
      "requirements": [
        "Microsoft EXCELが使えること"
      ],
      "description": "■はじめに\nＱＥアドバイザーの林　憲一です。\n企業における技術開発の効率化や工程の改善をお手伝いしています。\n会社に在籍していたときに技術職として技術開発や品質改善の実践をしてきました。\n県の教育機関の要請で講座も行っており、\n長期間型講座ではコンサルティングに近い形で受講生のテーマ解決をしてきました。\n開発や製造技術の現場に近い立場で、実践的なフォローをしています。\n\n\n■このコースの概要説明\nこの度は、本コースにご興味を持っていただきありがとうございます。\nＡＩ（人工知能）が進化するとともに、多くの場面で実用化が進んでいます。\nこの進化は今後もさらに続くと見られています。\n\n\n主な使われ方は大きく2つあり、パターン認識と推定です。\n今回のコースでは、このうちのパターン認識のみ扱います。\n\n\nパターン認識の実用化では、\n自動車の自動運転における環境認識，カメラ画像における人の認識，文字認識など\n様々な用途で研究が進められ、実用化も進んでいます。\n\n\n会社の中でも、パターン認識の活用はされています。\n画像検査，工程の異常検知，設備診断（予知保全），加工課程の管理・・・\n\n\n生活に近い分野での適用は、複雑な手順を通してプログラミングされていますが、\n企業の適用については、データを収集する計測器からデータが飛んでくれば\nその次の解析はそれほど難しいものではないようです。\n\n\nなので、ムリにＡＩ，機械学習，といった流行りを当てはめなくても\n目的とする改善，効率化を実現することはできます。\nその有効な手段が、ここで紹介するＭＴ法です。\nやっていることは同じ，目的とする対象は似ていて、\nそれを手軽に実践できる手段。\n機械学習よりも計算が簡単なので、高速化が可能，\nなので、装置に組み込みやすい計算方法といえます。\n\n\n機械学習を簡単に体験できる本からデータをもってきて、\nそれをＭＴ法で解析したら、ＭＴ法のほうが精度が良かった\nということも講座の中で紹介します。\nもちろん、それぞれ得手不得手があるので、\nその結果はたまたまＭＴ法が有利なデータだったとも言えるでしょう。\nでは、どんなときにどんな解析法が有効か？\nそれをイメージできる力が身につくコースになっています。\n\n\n参考までに、今回このコースで取り上げた事例は以下になります。\n・作業者がその作業に向いているかどうかの識別\n・手書き数字の判別\n・干し柿の製造条件の評価\n・アヤメの分類\n色々な分野で使われていますが、詳細は講座の中で紹介していきます。\n\n\nちょっと難しい計算でも\nエクセルの関数を使えば計算できるようになりました。（エクセルも進化しました）\n解析は全てエクセルで計算します。\nエクセルのワークシートも添付しますので、\n講座と同じ手順を手軽に実習することができます。\n\n\nとにかく「実践してもらえること」を重視して構成していますので、\nぜひ、一歩一歩、いっしょに取り組んでいきましょう！\n\n\n■コースを受講することで\n・一般的なＡＩ以外の判別分析の方法（ＭＴ法）を知ることができる\n・簡単な判別（パターン認識）を、エクセルで計算できるようになる\n・判別分析が何に使えるかイメージできるようになる\n・自分の課題を試しにやってみることができるようになる\n\n\n■こんな方が受講に向いています\n・判別分析・パターン認識を仕事に使ってみたいと考えている人\n・工程改善を推進する製造管理者・製造技術者\n・ＡＩや機械学習といったものに漠然と興味がある人\n・ＡＩ導入が困難だったけど、それに代わる方法で導入を検討している人\n・プログラムが苦手だけど、判別分析・パターン認識を体験してみたい人\n・工程改善の新しい考え方を知りたい人\n・品質工学のＰＤは勉強したけど、ＭＴ法も知りたいと思っている人\n・ＭＴ法を自分の課題に使ってみたいと思っている人\n\n\n■このコースは全部で11セクションです\nセクション1：はじめに\nセクション2：判別分析の手法\nセクション3：計算に必要な知識\nセクション4：ＭＴ法の計算と演習\nセクション5：ＲＴ法の計算と演習\nセクション6：誤圧の計算と演習\nセクション7：計算法の比較\nセクション8：機械学習との比較\nセクション9：活用するために\nセクション10：お礼とまとめ\nセクション11：ボーナスレクチャー\n全部で4時間19分のコースです。\nその他、ワークシートが用意されています。\nワークシートに沿って実践していただくことで、技術の構築を進めることができます。\n\n\n■最後に\n本コースに興味をもっていただいた方は、動画終了後に「コース登録」へ進んでください。\nもっと検討したいという方はプレビューで講座の一部が見れますので、ぜひ講座を覗いてみてください。\nそれでは、コースのなかでお会いできることを楽しみにしています！",
      "target_audience": [
        "画像検査ソフトを作るプログラマー（画像検査プログラムの製作）",
        "職場で独自の検査プログラムを作成したい人",
        "職場の効率化のため自工程完結を実現したい人",
        "仕事に限らず、判別分析（正常と異常を判別するなど）の評価をやりたい人"
      ]
    },
    {
      "title": "(Ken Cen 出品) Generative AI 第 32 部：多模態融合：視覺+語言模型高效推論 (下)",
      "url": "https://www.udemy.com/course/generative_ai_32/",
      "bio": "Multi Modal，RoPE，GQA，KVCache，MLP，RMS 歸一化",
      "objectives": [
        "深入瞭解如何用Pytorch製作 RoPE 旋轉位置編碼",
        "深入瞭解如何用 Pytorch編寫 GQA 分組查詢注意力",
        "深入瞭解如何用 Pytorch 編寫 KVCache & RMS 歸一化 & MLP 多層感知器",
        "深入瞭解為什麼需要殘差連接 & 為什麼Gemma 要設定前置層歸一化 & 為什麼要乘以sqrt(hidden_size)",
        "深入瞭解如何使用Pytorch 實現 PaliGemma 推理過程"
      ],
      "course_content": {
        "課程環境準備": [
          "課程工具準備",
          "如何使用uv 作為包管理器和項目管理工具"
        ],
        "如何用Pytorch製作 PaliGemma 架構": [
          "如何用Pytorch製作 RoPE 旋轉位置編碼",
          "如何用 Pytorch編寫 GQA 分組查詢注意力",
          "如何用 Pytorch 編寫 KVCache & RMS 歸一化 & MLP 多層感知器",
          "為什麼需要殘差連接 & 為什麼Gemma 要設定前置層歸一化 & 為什麼要乘以sqrt(hidden_size)",
          "如何合併圖片特徵 & 文字特徵 & Pad Token ID"
        ],
        "如何使用Pytorch 實現 PaliGemma 推理過程": [
          "如何使用Pytorch 實現 PaliGemma 推理過程"
        ]
      },
      "requirements": [
        "一臺電腦"
      ],
      "description": "本課程會繼續在Generative AI 第 31 部的視覺模型的基礎上，繼續多模態模型的架構的編寫。\n深入瞭解多模態模型如何在一個投影層上合併文字嵌入和圖像嵌入。\n而多模態模型要同時處理文字+图像信息時會有明顯的差異。\n而 PaliGemma 多模態模型為什麼要把歸一化放在注意力層 & MLP 層的前面？\n輸入的嵌入為什麼要乘以sqrt(hidden_size)，而不是除以sqrt(hidden_size)？\n殘差連接對於防止梯度消失有什麼意義？\n這些問題會在課程中，一一為您解答。\n\n\n課程內容：\n如何用Pytorch製作 RoPE 旋轉位置編碼\n如何用 Pytorch編寫 GQA 分組查詢注意力\n如何用 Pytorch 編寫 KVCache & RMS 歸一化 & MLP 多層感知器\n為什麼需要殘差連接 & 為什麼Gemma 要設定前置層歸一化 & 為什麼要乘以sqrt(hidden_size)\n如何合併圖片特徵 & 文字特徵 & Pad Token ID\n如何使用Pytorch 實現 PaliGemma 推理過程",
      "target_audience": [
        "AI/機器學習工程師 (AI/ML Engineers)",
        "數據科學家 (Data Scientists)",
        "對生成式 AI 有濃厚興趣的開發者 (Developers Interested in Generative AI)",
        "學生 (Students)"
      ]
    },
    {
      "title": "Python数据分析行业案例课程--学习数据挖掘",
      "url": "https://www.udemy.com/course/python-qg/",
      "bio": "全面掌握数据挖掘的关键数据模型，通过多项训练，提升数据建模能力",
      "objectives": [
        "掌握Python机器学习与数据挖掘相关技术",
        "提升专业的数据预处理",
        "学会特征的筛选与信息浓缩",
        "掌握多种模型的训练、集成与参数优化"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "python机器学习与数据挖掘概述": [
          "如何用python做机器学习或数据挖掘？",
          "课程内容介绍",
          "使用sklearn的样本数据集",
          "skearn基本操作入门"
        ],
        "第2章 数据的预处理": [
          "连续变量的标准化",
          "考虑异常分布的标准化",
          "分类变量的预处理",
          "缺失值的填充",
          "生成多项式特征",
          "极端值与异常值的处理"
        ],
        "特征选择与信息浓缩": [
          "特征筛选概述",
          "基于简单统计特征进行筛选",
          "基于统计误差进行筛选",
          "基于建模结果进行筛选",
          "数据降维与信息浓缩"
        ],
        "回归类模型的训练": [
          "回归类模型概述",
          "回归类模型的种类",
          "线性回归的sklearn实现",
          "多项式回归",
          "岭回归的基本原理",
          "岭回归的实现",
          "LASSO回归与弹性网络",
          "最小角回归",
          "梯度下降法的基本原理",
          "随机梯度下降回归"
        ],
        "类别预测模型的训练": [
          "类别预测模型概述",
          "类别预测模型的实现原理",
          "类别预测模型的种类",
          "logistic回归",
          "神经网络的基本原理",
          "神经网络的实现",
          "树模型的基本原理",
          "树模型的实现",
          "随机梯度下降分类"
        ],
        "聚类模型的训练": [
          "聚类分析概述",
          "聚类分析的种类",
          "K均值聚类",
          "birch聚类",
          "DBSCAN聚类"
        ],
        "评估模型效果": [
          "类别预测模型的评价",
          "分类模型评价：混淆矩阵",
          "分类模型评价：准确率与召回率",
          "分类模型评价：结果的汇总",
          "分类模型评价：ROC曲线",
          "回归模型的评价",
          "聚类模型的评价",
          "将模型结果与随即预测结果相比较"
        ],
        "数据的拆分": [
          "数据拆分方法概述",
          "二分法的sklearn实现",
          "交叉验证的sklearn的实现1",
          "交叉验证的sklearn实现2"
        ],
        "模型参数优化": [
          "如何改进数据挖掘模型的效果",
          "参数的网格搜索",
          "参数的随机搜索",
          "验证曲线",
          "学习曲线"
        ]
      },
      "requirements": [
        "具备Python基础知识"
      ],
      "description": "本课程以以CRISP-DM为理论指导，系统介绍了sklearn在数据挖掘/机器学习各个环节的功能实现，从数据挖掘实战的角度出发详细介绍如何在sklearn中完成数据预处理、数据降维、数据建模、模型评估等各种操作，并突出特征选择、模型调参，模型集成等在数据挖掘实战环境中的重要课题。\n课程弱化了各种统计模型的基本原理，强化其具体操作及衍生模型。学习完本课程后，学员将能够独立使用sklearn完成数据挖掘或机器学习实际项目。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。\n未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "转行大数据处理的小伙伴",
        "想要深入学习数据挖掘的同学",
        "适合企业中高级数据分析师提升数据挖掘硬技能",
        "适合Python数据分析师掌握数据挖掘能力"
      ]
    },
    {
      "title": "Microsoft Power BI Practice Tests and Interview Questions",
      "url": "https://www.udemy.com/course/microsoft-power-bi-practice-tests-and-interview-questions/",
      "bio": "Test & Improve your Microsoft Power BI skills | All topics included | Practice Questions | Common Interview Questions",
      "objectives": [],
      "course_content": {
        "Practice Tests": []
      },
      "requirements": [],
      "description": "Power BI is a technology-driven business intelligence tool provided by Microsoft for analyzing and visualizing raw data to present actionable information. It combines business analytics, data visualization, and best practices that help an organization to make data-driven decisions. In February 2019, Gartner confirmed Microsoft as Leader in the \"2019 Gartner Magic Quadrant for Analytics and Business Intelligence Platform\" as a result of the capabilities of the Power BI platform.\n\n\nFollowing are the reasons why Power BI is so popular and needed in the BI domain:\nAccess to Volumes of Data from Multiple Sources\nInteractive UI/UX Features\nExceptional Excel Integration\nAccelerate Big Data Preparation with Azure\nTurn Insights into Action\nReal-time Stream Analytics\nPower BI desktop app is used to create reports, while Power BI Services (Software as a Service - SaaS) is used to publish the reports, and Power BI mobile app is used to view the reports and dashboards.\n\n\nWhat does this course offer you?\nThis course consists of 3 practice tests.\nPractice test consists of 30 questions each, timed at 30 minutes with 50% as passing percentage.\nThe questions are multiple-choice.\nThe answers are randomized every time you take a test.\nQuestions are of varying difficulty - from easy to moderate to tough.\nOnce the test is complete, you will get an instant result report with categories of strength to weakness.\nYou can re-take the tests over and over again as and when it suits you.\nNew set of questions will be added frequently and you can practice along without having to buy the course again.\nLearning Resources will be shared over email frequently to all enrolled students, along with any latest updates/news/events/knowledge.\n\nWith this course you will get lifetime-long access to around 100 Interview and Practice Questions on Power BI that are updated frequently. After the test you will become more confident in these areas and will be able easily perform basic and advanced tasks while working on any project - be it development of a dashboard, or creating a power query - these practices work in all areas of varied kind of situations. Not just that, you will have the required knowledge to pass the Power BI Certification Exams and also clear your next Job Interview !\nBut most important is that you will UNDERSTAND Power BI fundamentals.\nYou will also get 30-days money-back guarantee. No questions asked!\nDon't wait and join the course now!",
      "target_audience": [
        "PowerBI professionals looking to sharpen their skills",
        "Students / professionals looking to learn and master Power BI as career path",
        "Anyone preparing for Power BI Developer Interview"
      ]
    },
    {
      "title": "R for Data Analysis, Statistics and Data Science",
      "url": "https://www.udemy.com/course/statistical-data-analysis-using-r/",
      "bio": "Data Analysis & Data Science using R : Descriptive & Inferential Statistics, Data Visualization, Hypothesis Testing",
      "objectives": [
        "About Qualitative, Quantitative, Bivariate and Multivariate Data",
        "Descriptive Statistics ie of Mean, Median, Quartiles, Quantiles, Variance and Standard Deviation",
        "Correlation and Covariance",
        "Applications of Descriptive Statistics on Stock Price Data",
        "Probability Distributions",
        "Inferential Statistics - Hypothesis Testing",
        "Fundamentals of R Programming & Work with RStudio",
        "Use Vectors, Matrices, Lists, Data Frames",
        "Importing and Handling CSV files",
        "Using dplyr Package for Data Wrangling or Handling",
        "Data Visualization in R"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Population Vs Sample",
          "Statistics Introduction"
        ],
        "Basic R Programming Fundamentals": [
          "Installing R on Windows",
          "Installing RStudio & Look around RStudio Interface",
          "First R Program & Basic Mathematical Operations",
          "Data Types & Variables",
          "Relational & Logical Operators"
        ],
        "Vectors, Matrices, Lists and Dataframes": [
          "Creating Vectors",
          "Logical Vectors",
          "Factors",
          "Creating Matrices & diag Function",
          "Creating Lists",
          "What are Data Frames",
          "Creating Data Frames",
          "Subseting Data Frame",
          "Import Data from Text & CSV Files",
          "Missing Data in Data Frames"
        ],
        "Data Handling using dplyr Package": [
          "dplyr Package",
          "dplyr select() - Select Columns of Data Frame",
          "dplyr filter() - Extract Rows from Data Frame",
          "dplyr arrange - Sort or Reorder rows of Data Frame",
          "dplyr rename() - Renaming Columns of Data Frame",
          "dplyr mutate() - Mutate Data Frames",
          "dplyrgroup_by() - Generate Summary Statistics",
          "dplyr %% - Pipeline Operator"
        ],
        "Data Visualization in R": [
          "Bar Plots",
          "Histograms",
          "Scatter & Line Plots",
          "Box Plots",
          "Multiple Plots in a Layout"
        ],
        "Qualitative and Quantitative Data": [
          "Qualitative Data",
          "Visualizing Qualitative Data",
          "Quantitative Data",
          "Visualizing Quantitative Data",
          "Visualizing Stock Price Quantitative Data"
        ],
        "Descriptive Statistics": [
          "Min, Max, Sum, Prod and Sort functions on Quantitative Data",
          "Mean or Arithmetic Mean",
          "Geometric Mean",
          "Applications of Geometric Mean",
          "Harmonic Mean",
          "Median and Mode",
          "Outliers",
          "Quartiles and Quantiles",
          "Variance and Standard Deviation",
          "Stock Price Data - Variance and Standard Deviation",
          "Correlation and Covariance",
          "Stock Price Data - Correlation and Covariance"
        ],
        "Bivariate and Multivariate Data": [
          "Bivariate Qualitative Data",
          "Bivariate Quantitative Data",
          "Multivariate Data"
        ],
        "Probability Distributions": [
          "Probability Distribution",
          "Uniform Distribution",
          "Normal Distribution"
        ],
        "Inferential Statistics - Hypothesis Testing": [
          "p-value - Statistical Hypothesis",
          "Degrees of Freedom",
          "Confidence Interval",
          "Hypothesis Testing",
          "Chi-squared test"
        ]
      },
      "requirements": [
        "No prior knowledge or technical backgrounds is required"
      ],
      "description": "Welcome to this course of R for Data Analysis, Statistics, and Data Science, and become an R Professional which is one of the most favored skills, that employers need.\nWhether you are new to statistics and data analysis or have never programmed before in R Language, this course is for you! This course covers the Statistical Data Analysis Using R programming language. This course is self-paced. There is no need to rush, you can learn on your own schedule.\nThis course will help anyone who wants to start a саrееr as a Data Analyst or Data Scientist.\nThis course begins with the introduction to R that will help you write R code in no time. This course will provide you with everything you need to know about Statistics.\nIn this course we will cover the following topics:\n· R Programming Fundamentals\n· Vectors, Matrices & Lists in R\n· Data Frames\n· Importing Data in Data Frame\n· Data Wrangling using dplyr package\n· Qualitative and Quantitative Data\n· Descriptive and Inferential Statistics\n· Hypothesis Testing\n· Probability Distribution\nThis course teaches Data Analysis and Statistics in a practical manner with hands-on experience with coding screen-cast.\nOnce you complete this course, you will be able to perform Data Analysis to solve any complex Analysis with ease.",
      "target_audience": [
        "Beginner who wants to apply R for Statistics and Data Analysis"
      ]
    },
    {
      "title": "AI Bible: From Beginner to Builder in 100 Projects",
      "url": "https://www.udemy.com/course/ai-bible-from-beginner-to-builder-in-100-projects/",
      "bio": "Master AI by building 100 real-world projects using Python, LLMs, agents, tools like LangChain, Ollama, and Streamlit",
      "objectives": [
        "Build and deploy 100 practical AI and ML projects from scratch",
        "Understand core concepts in NLP, computer vision, and agents",
        "Use libraries like PyTorch, TensorFlow, HuggingFace, and LangChain",
        "Create AI apps with Streamlit, FastAPI, and Gradio",
        "Fine-tune LLMs and build RAG and agentic systems locally",
        "Apply AI in real-world domains: health, finance, education, etc.",
        "Integrate speech, image, and text models into full-stack apps",
        "Evaluate and test LLMs for safety, alignment, and accuracy",
        "Use tools like ChromaDB, Ollama, and LangGraph offline",
        "Develop ethical, aligned, and human-centered AI systems"
      ],
      "course_content": {},
      "requirements": [
        "A basic understanding of Python programming (variables, functions, loops)",
        "Familiarity with using Jupyter Notebooks or any Python IDE",
        "An interest in exploring how AI works through real-world projects",
        "A computer with at least 8GB of RAM and a stable internet connection",
        "(Optional) Basic knowledge of machine learning or data science concepts",
        "No prior AI/ML experience is required. This course will guide you from foundational topics to advanced projects step by step."
      ],
      "description": "Welcome to the AI Bible — your ultimate, hands-on guide to mastering artificial intelligence through 100 real-world projects. This isn’t just another theory-heavy AI course. It’s a practical, immersive journey designed to help you learn AI by building, from day one.\nWhether you’re a beginner, a self-taught developer, or a seasoned engineer looking to pivot into the AI space, this course gives you the tools, confidence, and structure to go from zero to building production-ready AI applications. You’ll not only gain an understanding of core concepts like machine learning, deep learning, natural language processing, and computer vision, but you’ll actually use them to create projects that solve real problems.\nOver 100 days, you’ll work on 100 standalone projects that cover everything from basic AI models to cutting-edge systems involving LLMs, agents, tool use, voice processing, search, memory, and multi-agent orchestration. Each project comes with clear code, explanations, and ideas for customization—making it the perfect resource for portfolio building, interviews, or startups.\nYou’ll explore and integrate powerful open-source tools including:\nLangChain, for chaining together LLM prompts and tools\nOllama, to run local LLMs like LLaMA 3, Mistral, and Phi-2\nStreamlit and Gradio, for building interactive AI-powered web apps\nChromaDB, for local vector search and RAG (Retrieval-Augmented Generation)\nCrewAI and LangGraph, to build advanced multi-agent systems\nUnlike most courses, you won’t be dependent on cloud APIs. This curriculum emphasizes offline, local AI development, ensuring you learn to build powerful applications with full data privacy, portability, and control.\nBy the end of this course, you will:\nUnderstand and apply machine learning and deep learning fundamentals\nUse transformers and pretrained LLMs in practical applications\nBuild tools like AI chatbots, search engines, recommender systems, and speech agents\nImplement your own AI agents with memory, tools, reflection, and reasoning\nEvaluate models using your own LLM evaluation suite and red team test sets\nDevelop an ethical AI mindset by writing your own AI Manifesto and alignment strategy\nThis course is also a reflection on how we build AI: the final project asks you to create a Personal AI Manifesto, helping you align your skills with the kind of world you want to create.\nWhether you want to become an AI engineer, launch your own AI startup, or just understand the technology shaping the future, the AI Bible gives you everything you need—one project at a time.",
      "target_audience": [
        "Aspiring AI engineers who want to build real-world projects and gain hands-on experience",
        "Developers and software engineers looking to transition into AI and machine learning",
        "Students and self-learners who want a structured, project-based way to master AI",
        "Startup founders and tech entrepreneurs seeking to prototype AI-powered applications",
        "Educators and tech mentors who want ready-to-use projects to teach AI in practical settings",
        "Anyone curious about AI and motivated to learn by building instead of just reading theory"
      ]
    },
    {
      "title": "Machine learning with Scikit-learn",
      "url": "https://www.udemy.com/course/machine-learning-with-scikit-learn/",
      "bio": "Learn the most important machine learning techniques using the best machine learning library available",
      "objectives": [
        "Load data into scikit-learn; Run many machine learning algorithms both for unsupervised and supervised data.",
        "Assess model accuracy and performance",
        "Being able to decide what's the best model for every scenario"
      ],
      "course_content": {
        "Introduction to Scikit-learn": [
          "Introduction",
          "Installing scikit-learn",
          "Data manipulation: from Pandas to scikit-learn",
          "Creating synthetic data"
        ],
        "Supervised methods": [
          "Naive Bayes : Bernoulli - Multinomial",
          "Detecting spam in real SMS Kaggle data",
          "Linear Support Vector Machines (SVM): SVM and LinearSVC",
          "Linear Support Vector Machines (SVM): NuSVM",
          "SVM",
          "Logistic regression",
          "Predicting if income >50k using real US Census Data",
          "Isotonic regression",
          "Linear regression - Lasso - Ridge",
          "Lasso - Ridge",
          "Decision trees",
          "Introduction to ensemble methods",
          "Averaging ensemble methods - Part 1: Bagging",
          "Averaging ensemble methods - Part 2: Random forests",
          "Digit Classification via Random Forests",
          "Boosting ensemble methods",
          "Grid Search Cross Validation",
          "Predicting real house prices in the US using ExtraTreesRegressor"
        ],
        "Unsupervised methods": [
          "Density Estimation",
          "Principal Components",
          "Principal Components",
          "K-Means",
          "DBScan",
          "Clustering",
          "Clustering and PCA on real countries data from Kaggle",
          "Outlier detection",
          "Novelty detection"
        ]
      },
      "requirements": [
        "Some Python and statistics knowledge is required: Being able to code loops, functions, classes in Python is necessary. Understanding what are random variables, what is a Gaussian distribution, and the underlying concepts behind linear regression are necessary as well."
      ],
      "description": "This course will explain how to use scikit-learn to do advanced machine learning. If you are aiming to work as a professional data scientist, you need to master scikit-learn!\nIt is expected that you have some familiarity with statistics, and python programming. It's not necessary to be an expert, but you should be able to understand what is a Gaussian distribution, code loops and functions in Python, and know the basics of a maximum likelihood estimator. The course will be entirely focused on the python implementation, and the math behind it will be omitted as much as possible.\nThe objective of this course is to provide you with a good understanding of scikit-learn (being able to identify which technique you can use for a particular problem). If you follow this course, you should be able to handle quite well a machine learning interview. Even though in that case you will need to study the math with more detail.\nWe'll start by explaining what is the machine learning problem, methodology and terminology. We'll explain what are the differences between AI, machine learning (ML), statistics, and data mining. Scikit-learn (being a Python library) benefits from Python's spectacular simplicity and power. We'll start by explaining how to install scikit-learn and its dependencies. And then show how can we can use Pandas data in scikit-learn, and also benefit from SciPy and Numpy. We'll then show how to create synthetic data-sets using scikit-learn. We will be able to create data-sets specifically tailored for regression, classification and clustering.\nIn essence, machine learning can be divided into two big groups: supervised and unsupervised learning. In supervised learning we will have an objective variable (which can be continuous or categorical) and we want to use certain features to predict it. Scikit-learn will provide estimators for both classification and regression problems. We will start by discussing the simplest classifier which is \"Naive Bayes\". We will then see some powerful regression techniques that via a special trick called regularization, will help get much better linear estimators. We will then analyze Support Vector Machines, a powerful technique for both regression and classification. We will then use classification and regression trees to estimate very complex models. We will see how we can combine many of the existing estimators into simpler structures, but more robust for out of sample performance, called \"ensemble\" methods. In particular random forests, random trees, and boosting methods. These methods are the ones winning most data science competitions nowadays.\nWe will see how we can use all these techniques for online data, image classification, sales data, and more. We also use real datasets from Kaggle such as spam SMS data, house prices in the United States, etc. to teach the student what to expect when working with real data.\nOn the other hand, in unsupervised learning we will have a set of features (but with no outcome or target variable) and we will attempt to learn from that data. Whether it has outliers, whether it can be grouped into groups, whether we can remove some of those features, etcetera. For example we will see k-means which is the simplest algorithm for classifying observations into groups. We will see that sometimes there are better techniques such as DBSCAN. We will then explain how we can use principal components to reduce the dimensionality of a data-set. And we will\nuse some very powerful scikit-learn functions that learn the density of the data, and are able to classify outliers.\nI try to keep this course as updated as possible, specially since scikit-learn is constantly being updated. For example, neural networks was added in the latest release. I tried to keep the examples as simple as possible, keeping the amount of observations (samples) and features (variables) as small as possible. In real situations, we will use hundreds of features and thousands of samples, and most of the methods presented here scale really well into those scenarios. I don't want this course to be focused on very realistic examples, because I think it obscures what we are trying to achieve in each example. Nevertheless, some more complex examples will be added as additional exercises.",
      "target_audience": [
        "Students with some analytics/data-science knowledge aiming at being able to comfortable model in scikit-learn",
        "Experienced data scientists working in R/SAS/MATLAB, wanting to transition into ML with Python"
      ]
    },
    {
      "title": "Pomodoro Technique for Effective Developers and Programmers",
      "url": "https://www.udemy.com/course/pomodoro-technique-for-effective-developers-and-programmers/",
      "bio": "Master the Pomodoro Technique to Boost Your Productivity and Efficiency as a Programmer or Software Developer",
      "objectives": [
        "Using Pomodoro technique to become efficient programmers",
        "Tips of acing the Pomodoro technique",
        "Review of the best apps to help in practicing pomodoro",
        "Understanding the challenges and benefits of using this technique to improve productivity"
      ],
      "course_content": {
        "Introduction": [
          "Welcome",
          "What is Pomodoro Technique",
          "History"
        ],
        "Understanding Pomodoro and why it is effective": [
          "Who Should Try Pomodoro?",
          "Benefits of Pomodoro Technique",
          "Programming and Pomodoro"
        ],
        "Doing Pomodoro : Steps and Best Practices": [
          "How to do Pomodoro",
          "Tips for doing Pomodoro in a better way",
          "Focusing on Breaks during Pomodoro",
          "Few things you shouldn't worry about",
          "Challenges you will face while doing Pomodoro",
          "Best Websites / Apps to help manage Time and Tasks while performing Pomodoro"
        ],
        "End Notes": [
          "Conclusion",
          "Congratulations"
        ]
      },
      "requirements": [
        "No experience needed, we will learn everything from the scratch !"
      ],
      "description": "Welcome to the Pomodoro Technique for Efficient Programmers and Developers Course!\nAs a programmer or developer, you know that time is of the essence. You have deadlines to meet, projects to complete, and clients to satisfy. It's no secret that being productive and efficient with your time is key to achieving success in this field.\nThat's where the Pomodoro Technique comes in. This time management method was created in the late 1980s by Francesco Cirillo and has since become a popular tool for maximizing productivity and efficiency.\nThe Pomodoro Technique is based on the idea of breaking your workday into focused, 25-minute intervals called \"Pomodoros,\" followed by short breaks. This system helps you stay focused and avoid distractions, while also ensuring that you take regular breaks to prevent burnout.\nIn this course, you'll learn how to use the Pomodoro Technique to become a more efficient programmer or developer. You'll discover how to set goals and prioritize tasks, how to stay focused and avoid distractions, and how to manage your time effectively.\nThrough a series of interactive lessons, you'll learn the key principles of the Pomodoro Technique and how to apply them to your workday. You'll also have access to a range of resources and tools to help you track your progress and stay motivated.\nBy the end of this course, you'll have the skills and knowledge you need to become a more productive and efficient programmer or developer. So why wait? Sign up today and start mastering the Pomodoro Technique!",
      "target_audience": [
        "Busy professionals : If you juggle multiple projects and responsibilities, this course is perfect for you.",
        "Procrastinators : to help you overcome this habit and become more productive",
        "Students: If you need to balance coursework with other commitments, the Pomodoro Technique can be a game-changer.",
        "Freelancers: If you need to manage your time and workload efficiently, the Pomodoro Technique can help you stay on track"
      ]
    },
    {
      "title": "Data Visualization with Python and Power BI",
      "url": "https://www.udemy.com/course/data-visualization-with-python-and-power-bi/",
      "bio": "Learn to create Power BI reports and visual charts with Python Matplotlib and Seaborn. Power bi business intelligence",
      "objectives": [
        "You will learn to create various visualization charts in Power BI",
        "You will also learn to create advanced charts by writing python code using seaborn and matplotlib",
        "You will learn to create Line chart, Scatterplot, and Violin chart",
        "You will also learn to create Strip plot, box plot and Lmplot chart"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Resource files"
        ],
        "Data Visualization with Python": [
          "Installing package and defining path",
          "Creating a Line chart with matplotlib",
          "Putting labels and creating dashed scatterplot",
          "Violin chart with seaborn",
          "More on Violin chart"
        ],
        "Advanced Python charts": [
          "Stripplot Part-1",
          "Stripplot Part-2",
          "Boxplot Part-1",
          "Boxplot Part-2",
          "Lmplot or align plot"
        ],
        "Other charts": [
          "Ribbon Chart",
          "Table and Matrix",
          "Drill Down Table and Matrix",
          "Donut Ring chart",
          "Simple Map and modes"
        ],
        "Working with web data and creating Report": [
          "Working with web data and creating Report"
        ],
        "Filters": [
          "Slicer- Basics",
          "Slicers- Date Slicer"
        ],
        "Power Query": [
          "Removing Null values"
        ],
        "Assignment": [
          "Create Visualization charts with Python and Power BI"
        ]
      },
      "requirements": [
        "Before taking this course you must have power bi and python installed on you computer."
      ],
      "description": "Python is one of the most popular and advanced programming language used in various domains such as machine learning and data science. Python helps you reduce the lines of code into as short as possible while keeping it in a readable format so that anyone can easily understand the implication of python code. In this course you will learn about some of the libraries in python and some methods used to create data visualization charts and data science projects. Here, you will learn about creating data visualization charts using python and Power BI business intelligence software. Power BI is an advanced software used for wide range of application areas such as Data Science, Machine Learning, Enterprise Resource Planning, Data Analysis and much more. And it makes the process of data cleaning, modelling and visualization very interactive and easy.\nAlthough we could create various kinds of charts in Power Bi even without writing a single line of code. But there are various complex problems in data science that can be solved with the help of python libraries such as matplotlib and seaborn. Here in this course you will learn to create some of the advanced charts in power bi by writing python programs to create data visualizations for driving insights and finding outliers that may not be done by using default charts, one such example could be Violin chart. By creating a Violin chart you could easily spot the distribution range or concentration of values based on a certain category. This chart would make it intuitive to spot any segregation of values, and uniformity of distribution. It would be very difficult to represent such insights using any other default charts. Moreover, you would be learning many of such advanced custom charts in power bi that can be created by writing python codes.\nThe skills you learn in this course can be used in various domains related to data science and data analytics to business intelligence and machine learning.\nIn this course, you will be learning following concepts and visualization charts using python libraries such as pandas, matplotlib and seaborn-\nInstalling python packages and defining path\nCreating a Line chart with matplotlib\nPutting labels and creating dashed scatterplot\nViolin chart with seaborn\nMore on Violin chart\nStripplot\nBoxplot\nLmplot or align plot\nMoreover, you will also learn to create other visualization charts in power bi and other concepts such as creating slicer filters and map chart-\nRibbon Chart\nTable and Matrix\nDrill Down Table and Matrix\nDonut Ring chart\nSimple Map and modes\nSlicer- Basics\nSlicers- Date Slicer",
      "target_audience": [
        "Anyone who is curious to learn Data Science and Data Visualization",
        "Students, Developers and professionals interested in learning Power BI and python",
        "Interested to create custom charts using matplotlib and seaborn in python"
      ]
    },
    {
      "title": "Talend DI + TMC + AWS - Zero to Hero",
      "url": "https://www.udemy.com/course/talend-di-zero-to-hero/",
      "bio": "Talend DI + TMC + AWS - Zero to Hero",
      "objectives": [
        "Learn Talend Open Studio for Data Integration",
        "Learn Talend Management Cloud",
        "Learn Talend Open Studio for Data Integration with scenarios to implement",
        "Learn Basic concepts of ETL",
        "Learn Talend Cloud AWS components"
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Installation of Java, Talend": [
          "Resources",
          "Installation of Talend 8",
          "Generic Folder Structure on the machine as best practice"
        ],
        "Talend Studio Tour": [
          "Repository, Designer, Palette, Outline, Configuration tab",
          "Creating your first job, Java behind Talend",
          "Few Tips"
        ],
        "Import/Export jobs in Talend": [
          "Importing/Exporting job"
        ],
        "Reading the data from files (Extract)": [
          "Extracting from File Excel - tFileInputExcel",
          "Extracting from File delimited - tFileInputDelimited",
          "Extracting from File delimited/Excel using Metadata",
          "Assignment"
        ],
        "Reading the data from Databse (Extract)": [
          "Extracting from DB table/using Metadata - tDBInput",
          "Assignment"
        ],
        "Process the Data (Transformation) - Processing components": [
          "Processing component - tFilterRow",
          "tFilterColumn",
          "tSortRow",
          "Assignment"
        ],
        "Load the data (Load)": [
          "Load the data into File, Excel - tFileOutputDelimited, tFileOutputExcel",
          "Load the data into Table - tDBOutput",
          "Assignment"
        ],
        "File Management Components": [
          "Connection Links",
          "tFileList",
          "tFileCopy, tFileDelete",
          "tFileArchive, tFileUnarchive",
          "tFileCompare, tFileRowCount, tFileProperties",
          "tChangeFileEncoding, tFileTouch",
          "Assignment"
        ],
        "Processing Component": [
          "tMap Basics",
          "tMap Advance",
          "tMap Join",
          "tJoin",
          "tReplace,tConvertType",
          "tAggregateRow, tAggregateRowSorted",
          "tNormalize, tDenormalize",
          "tSampleRow",
          "Assignment"
        ]
      },
      "requirements": [
        "No Programming experience needed, you will learn everything during the course. Follow through the class and practice!!"
      ],
      "description": "Talend is an Open Source/Enterprise ETL Tool, which can be used by Small to Large scale companies to perform Extract Transform and Load their data into Databases or any File Format (Talend supports almost all file formats and Database vendors available in the market including Cloud and other niche services).\nThis Course is for anyone who wants to learn Talend from Zero to Hero, it will also help in Enhancing your skills if you have prior experience with the tool.\nIn the course we teach Talend DI- ETL tool that you would need to work and excel in the organization or freelance.\nWe give real world scenarios and try to explain the use of component so that it becomes more relevant and useful for your real world projects.\nPrepares you for the Certification Exam.\nBy the end of the Course you will become a Professional in Talend Data Integration and will help you land the job as ETL or Talend Developer, which is high in demand.\n\n\nPrerequisites ?\nBasic Knowledge of working on PC\nTarget Audience ?\nAnyone who wants to enter the IT industry from non technical background.\nAnyone who wants to enhance their concepts of Talend Studio to perform data integration.\nAnyone who wants to get job as a Talend Developer.\nSystem Requirements ?\nPC or Laptop with preferably more than 4GB RAM and i3 above processor.\nTalend Open Studio Software - FREE for everyone\nPostgreSQL Database - FREE for local implementation",
      "target_audience": [
        "Anyone who wants to get through the Talend Certification or want to get job as ETL developer"
      ]
    },
    {
      "title": "Data Science Mastery: Journey into Machine Learning",
      "url": "https://www.udemy.com/course/data-science-mastery-journey-into-machine-learning-2023/",
      "bio": "Learn Machine Learning, Data Science and Deep Learning with Python",
      "objectives": [
        "Gain proficiency in using Python libraries commonly used in data science and machine learning, such as NumPy, Pandas, and Matplotlib.",
        "Learn how to clean and preprocess datasets, including handling missing data, outliers, and feature scaling.",
        "Acquire knowledge of exploratory data analysis techniques to extract insights and patterns from data.",
        "Master the fundamentals of statistical analysis and apply statistical methods to interpret and draw conclusions from data.",
        "Understand the principles of machine learning and its various algorithms, such as regression, classification, and clustering.",
        "Learn how to select appropriate machine learning models and techniques for different types of problems and datasets.",
        "Develop skills in feature engineering and selection to enhance the performance of machine learning models."
      ],
      "course_content": {
        "Introduction to Numpy": [
          "Introduction to Numpy",
          "Numpy ndarray",
          "ndarray",
          "Data Types",
          "Arithmetic",
          "Indexing and Slicing",
          "Indexing and Slicing - 2",
          "Indexing and Slicing - 3",
          "Boolean Indexing",
          "Fancy Indexing in Numpy",
          "Transposing and Swapping",
          "Universal Functions",
          "Array Oriented Programming",
          "Expressing Conditional Logic",
          "Methods involving Math and Statistics",
          "Boolean Array Methods",
          "The Sorting",
          "Unique Set Logic",
          "Linear Algebra",
          "Pseudorandom Number Generator",
          "Random Walks (An example)",
          "Simulation of plenty of Random Walks"
        ],
        "Introduction to Pandas": [
          "Introduction to Pandas",
          "Series",
          "Series - 2",
          "Series - 3",
          "DataFrame",
          "DataFrame - 2",
          "DataFrame - 3",
          "DataFrame - 4",
          "Index Objects",
          "Reindexing",
          "Reindexing - 2",
          "Axis and the Dropping of Values",
          "Indexing",
          "Indexing - 2",
          "Using loc and iloc for Selection",
          "Integer Indexes",
          "Data Alignment & Arithmetic",
          "Data Alignment & Arithmetic - 2",
          "Fill Values with Arithmetic Methods",
          "DataFrame and Series and the Operation",
          "Application and Mapping",
          "Application and Mapping - 2",
          "Ranking and Sorting",
          "Ranking and Sorting - 2",
          "Axis Indexes",
          "Computing Descriptive Statistics",
          "Computing Descriptive Statistics - 2",
          "Value Counts, Membership, Unique Values"
        ],
        "Data Preparation and Data Cleaning": [
          "Lets Handle Missing Data",
          "Filtration of the Missing Data",
          "Filling of the Missing Data",
          "Duplicates Removal",
          "Function or Mapping and Transformation",
          "Function or Mapping",
          "Function or Mapping - 2",
          "Values Replacing",
          "Axis Indexes Renaming",
          "Discretization and Binning",
          "Discretization and Binning - 2",
          "Discretization and Binning - 3",
          "Filtering and Detecting the Outliers",
          "Random Sampling and Permutations",
          "Indicator Computing",
          "Indicator Computing - 2",
          "Indicator Computing - 3",
          "Indicator Computing - 4",
          "String Object Methods",
          "String Object Methods - 2",
          "Regular Expressions",
          "Regular Expressions - 2",
          "Regular Expressions - 3",
          "Vectorized String Functions",
          "Vectorized String Functions - 2",
          "Hierarchical Indexing",
          "Hierarchical Indexing - 2",
          "Hierarchical Indexing - 3",
          "Reordering and the Sorting Levels",
          "Summarizing Statistics and Indexing with DataFrames Columns",
          "DataFrame Join with Database Style",
          "DataFrame Join with Database Style - 2",
          "DataFrame Join with Database Style - 3",
          "Merging on Index",
          "Merging on Index - 2",
          "Merging on Index - 3",
          "Merging on Index - 4",
          "Concatenating Along an Axis",
          "Concatenating Along an Axis - 2",
          "Concatenating Along an Axis - 3",
          "Data Combining with the Overlap",
          "Hierarchical Indexing and Reshaping",
          "Hierarchical Indexing and Reshaping - 2",
          "pd.melt"
        ],
        "Introduction to Matplotlib": [
          "Introduction",
          "Figures and Subplots",
          "Figures and Subplots - 2",
          "Figures and Subplots - 3",
          "Markers, Line Styles and Colors",
          "Labels, Legends and Ticks, Title, Ticklabels, Titles",
          "Labels, Legends and Ticks, Adding a Legend",
          "Drawing on a Subplot",
          "Line Plots",
          "Bar Plots",
          "Bar Plots - 2",
          "Bar Plots - 3",
          "Histograms",
          "Scatter Plots",
          "Categorical Data and Facet Grids"
        ],
        "Introduction to Group Operations": [
          "Introduction",
          "Mechanics of the GroupBy",
          "Mechanics of the GroupBy - 2",
          "Iterating over the Groups",
          "Selecting a Column",
          "Grouping with Dicts",
          "Grouping with Functions",
          "Grouping with Functions - 2",
          "Data Aggregation",
          "Multiple Function Application and Column Wise",
          "Multiple Function Application and Column Wise - 2",
          "Returning Aggregated Data",
          "Split-Apply-Combine",
          "Group Keys and Quantile and Bucket Analysis",
          "Example of Filling Missing Values with respect to the Group-Specific Values",
          "Example of Random Sampling and Permutation",
          "Example of Group Weighted Average and Correlation",
          "Example of Group Weighted Average and Correlation - 2",
          "Example of the Group-Wise Linear Regression",
          "Cross-Tabulation and Pivot Tables",
          "Cross-Tabulation and Pivot Tables - 2",
          "CrossTab"
        ],
        "Time Series in Python": [
          "Time Data Types and Tools and Data",
          "Datetime and String Conversion Between Them",
          "Datetime and String Conversion Between Them - 2",
          "Basics of Time Series",
          "Subsetting, Indexing, Selection",
          "Duplicate Indices and Time Series",
          "Generation of the Date Ranges",
          "Date Offsets and Frequencies",
          "Week of Month Dates",
          "Shifting Data",
          "Shifting Dates with the Offsets",
          "Time Zone Handling",
          "Localization and Conversion of the Time",
          "Aware Timestamp Objects",
          "Different Time Zones and Operations Between Them",
          "Period Arithmetic",
          "Conversion of Period Frequency",
          "Period Frequencies of Quarters",
          "Conversion of Timestamps to Period & Back",
          "PeriodIndex from Arrays",
          "Frequency Conversion and Resampling",
          "Downsampling",
          "Interpolation and Upsampling",
          "Resampling with the Periods",
          "Sliding Window",
          "Exponentially Weighted Functions",
          "Functions of the Binary Moving Window"
        ],
        "Just Some Advanced Pandas": [
          "Categorical Data",
          "Categorical Type",
          "Computations with Categoricals",
          "Fast Performance with Categories",
          "Categorical Methods",
          "Dummy Variables for Modeling",
          "Group Transforms and GroupBy",
          "Resampling of Grouped Time",
          "Method Chaining",
          "Pipe"
        ],
        "Modeling Libraries in Python": [
          "Introduction",
          "Pandas and Model Code",
          "Pandas and Model Code - 2",
          "Patsy",
          "Patsy - 2",
          "Data Transformations",
          "Categorical Data",
          "Estimating Linear Models",
          "Estimating Linear Models - 2",
          "Estimating Time Series",
          "Scikit-Learn",
          "Scikit-Learn - 2"
        ],
        "Data Analysis": [
          "USA.gov Data",
          "Counting Time Zone in Python",
          "Counting Time Zone in Python - 2",
          "Counting Time Zone in Python - 3",
          "MovieLens 1M Dataset",
          "MovieLens 1M Dataset - 2",
          "Rating Disagreement",
          "US Baby Names 1880-2010",
          "US Baby Names 1880-2010 - 2",
          "Analyzing Naming Trends",
          "Increase in Naming Diversity",
          "Increase in Naming Diversity - 2",
          "Last Letter",
          "Last Letter - 2",
          "USDA Food Database",
          "USDA Food Database - 2",
          "USDA Food Database - 3",
          "2012 Federal Election Commission Database",
          "Donation Statistics by Occupation and Employer",
          "Donation Amounts and by States"
        ],
        "Advanced Numpy in Python": [
          "Object Internals",
          "dtype Hierarchy",
          "Reshaping Arrays",
          "C vs Fortran Order",
          "Splitting and Concatenating Arrays and r_ and c_",
          "tile and repeat",
          "take and put",
          "Broadcasting",
          "Broadcasting Over Other Axes",
          "Setting Array Values",
          "ufunc Instance Methods",
          "Writing New ufuncs",
          "Structured, Record Arrays and Nested dtypes",
          "More about Sorting",
          "argsort and lexsort",
          "Alternative Sort Algorithms and Partially Sorting Arrays",
          "numpy.searchsorted",
          "Numba",
          "Identifiers",
          "Reserve Words",
          "Strings"
        ]
      },
      "requirements": [
        "Just passion for learning!"
      ],
      "description": "The Python for Data Science and Machine Learning course is designed to equip learners with a comprehensive understanding of Python programming, data science techniques, and machine learning algorithms.\nWhether you are a beginner looking to enter the field or a seasoned professional seeking to expand your skillset, this course provides the knowledge and practical experience necessary to excel in the rapidly growing field of data science.\n\n\nCourse Objectives:\n1. Master Python Programming: Develop a strong foundation in Python programming, including syntax, data structures, control flow, and functions. Gain proficiency in using Python libraries such as NumPy, Pandas, and Matplotlib to manipulate and visualize data effectively.\n\n\n2. Data Cleaning and Preprocessing: Learn how to handle missing data, outliers, and inconsistent data formats. Acquire skills in data cleaning and preprocessing techniques to ensure the quality and reliability of datasets.\n\n\n3. Exploratory Data Analysis: Understand the principles and techniques of exploratory data analysis. Learn how to extract insights, discover patterns, and visualize data using statistical methods and Python libraries.\n\n\n4. Statistical Analysis: Gain a solid understanding of statistical concepts and techniques. Apply statistical methods to analyze data, test hypotheses, and draw meaningful conclusions.\n\n\n5. Machine Learning Fundamentals: Learn the foundations of machine learning, including supervised and unsupervised learning, regression, classification, and clustering. Understand the strengths and limitations of different machine learning algorithms.\n\n\n6. Machine Learning Implementation: Gain hands-on experience in implementing machine learning models using Python libraries such as scikit-learn. Learn how to train, evaluate, and optimize machine learning models.\n\n\n7. Feature Engineering and Selection: Develop skills in feature engineering to create meaningful and informative features from raw data. Learn techniques for feature selection to improve model performance and interpretability.\n\n\n8. Model Evaluation and Optimization: Learn how to assess the performance of machine learning models using techniques like cross-validation and evaluation metrics. Understand the importance of hyperparameter tuning and regularization for model optimization.\n\n\n9. Deep Learning Concepts: Explore the basics of deep learning, including neural networks, activation functions, and gradient descent optimization. Gain an understanding of deep learning architectures and their applications.\n\n\n10. Practical Deep Learning: Acquire practical experience in building and training neural networks using popular deep learning frameworks such as TensorFlow or PyTorch. Learn how to apply deep learning techniques to solve real-world problems.",
      "target_audience": [
        "Aspiring data scientists and machine learning enthusiasts who have a basic understanding of Python programming.",
        "Learners who want to acquire comprehensive knowledge and practical skills in Python, data science, and machine learning.",
        "The course content is tailored to provide valuable insights and hands-on experience to individuals aiming to excel in data-driven problem-solving and analysis."
      ]
    },
    {
      "title": "CO₂ Emissions Forecasting with ARIMA in Python",
      "url": "https://www.udemy.com/course/arima-forecasting-carbon-dioxide/",
      "bio": "Build Accurate Time Series Forecasts with Python - Energy Sector Application",
      "objectives": [
        "Build ARIMA models to forecast CO2 emissions using Python",
        "Apply a proven 10-step methodology for creating statistically sound and reliable forecasts",
        "Work with real World Bank data to analyze emissions trends for India, China, USA, UK, EU and global averages",
        "Master essential statistical tests including overfitting analysis, naive model benchmarking, and sensitivity analysis",
        "Quantify forecast uncertainty using confidence intervals and error metrics like MAPE",
        "Create publication-ready visualizations of historical trends and future projections",
        "Understand when ARIMA is appropriate for time series forecasting vs other methods",
        "Implement best practices for model validation, hyperparameter tuning, and results interpretation"
      ],
      "course_content": {
        "Introduction": [
          "Overview",
          "Ten step methodology",
          "Resources"
        ],
        "Data Preprocessing": [
          "Introduction",
          "Resources",
          "Data Preprocessing in Python",
          "Download the code for this section",
          "Download all the datasets"
        ],
        "Dataset Split": [
          "Introduction",
          "Polynomial Features",
          "Dataset split"
        ],
        "ARIMA full implementation": [
          "Introduction",
          "Training the models",
          "The JB test",
          "ARIMA training set predictions",
          "Generating the test set predictions",
          "Test set errors",
          "Training set errors",
          "Overfitting analysis",
          "Conducting the naive test",
          "Sensitivity analysis versus hyperparameters",
          "Sensitivity analysis on test errors",
          "Theory on Forecasts",
          "Producing the forecasts",
          "Final selection of models"
        ],
        "ARIMA Optimal Orders": [
          "Introduction",
          "The indicator dataset",
          "Stationary series and kPSS",
          "Stationarity analysis",
          "Differencing",
          "The forecast arima notebook",
          "ACF and PACF plots",
          "Auto ARIMA function",
          "Fitting the ARIMA models",
          "Inverting the differencing operation",
          "Training set predictions",
          "Training and test set MAPE (error)",
          "Overfitting analysis",
          "Generating forecasts",
          "Diagnostic tests"
        ],
        "Conclusions": [
          "Resources",
          "Overview"
        ]
      },
      "requirements": [
        "Absolute beginners welcome!",
        "You'll receive the full Python code, which you can adjust to your own projects",
        "No programming experience? Follow along and learn by doing",
        "No statistics background needed",
        "Just need a computer and enthusiasm"
      ],
      "description": "SPECIAL OFFER:\nSave today! Copy this code at checkout (remove the middle space):    2D69146C46 605E5E4DFD\n\nWHO I AM:\nResearcher and educator specializing in energy data science (PhD in Energy, Imperial College London, 40+ publications)\n\nREGULAR ENHANCEMENTS:\nCourse reviewed periodically with updates.\n\n\nWhat You'll Learn:\nHow to build an ARIMA model in Python that can forecast CO₂ emissions\nHow to achieve high accuracy in the forecasts that you will produce\nHow to work with World Bank historical data\nHow to implement advanced statistical tests\nHow to apply your model to real-world cases (India, China, USA, UK, European Union analysis)\n\nPerfect For:\nEnvironmental consultants and analysts\nEnergy economists and policy makers\nData scientists in sustainability\nClimate professionals\n\nWhy This Matters:\nWith net-zero targets and mandatory carbon reporting, professionals who can produce credible emissions forecasts are in high demand. Master the skills that set you apart in the growing climate economy. Companies now require carbon footprint assessments for regulatory compliance and ESG reporting. Governments need emissions projections for policy planning. Consultancies charge premium rates for these capabilities. Whether you're advancing your current career or transitioning into sustainability, these practical forecasting skills open doors to roles paying $150,000-250,000+ in the rapidly expanding green economy.",
      "target_audience": [
        "Environmental/Climate Analysts seeking quantitative forecasting skills",
        "Sustainability Professionals needing to project emissions for reporting",
        "Energy Sector Professionals wanting data-driven analytical methods",
        "Graduate Students & Researchers in environmental science, energy, or climate studies",
        "Data Scientists/ML Engineers moving into climate and energy applications",
        "ESG Analysts & Consultants requiring emissions projection capabilities",
        "Policy Analysts working on climate strategies and carbon reduction plans",
        "Anyone transitioning to climate tech who needs practical forecasting skills"
      ]
    },
    {
      "title": "How to easily use ANN for prediction mapping using GIS data?",
      "url": "https://www.udemy.com/course/how-to-use-ann-for-prediction-mapping-using-gis-data/",
      "bio": "First Simplified Step-by-Step Artificial Neural Network Methodology in R for Prediction Mapping using GIS Data",
      "objectives": [
        "With Step by step description we will be together facing the common software and code misleadings.",
        "1. Produce training and testing data using automated tools in QGIS (Optional). Or jump this and using your own training/testing data directly.",
        "2. Run NeuralNet function with training data and testing data. (use my QGIS tools as an option OR use your preferable data production technique directly)",
        "3. Plot NN function network and get all the outputs like; Error rate, statistics, Pairwise and Generalized weight plot",
        "4- Prediction and Validation Mapping Accuracy using AUC value of ROC plot",
        "4. Produce and export prediction map using Raster data"
      ],
      "course_content": {
        "Introduction": [
          "Course outlines",
          "Expected Outcomes"
        ],
        "ANN basic background and used packages": [
          "Introduction to ANN and used functions",
          "Introduction to NuralNet package",
          "Introduction Summary"
        ],
        "Create training and testing data in QGIS work environment": [
          "Adding my developed Model tools to QGIS (version 3.14) processing library",
          "Create Land Cover map (convert string observations to numeric) in QGIS",
          "Run the tools Step 1",
          "Run the tools Step 2",
          "Run the tools Step 3"
        ],
        "Manage training and testing data in Excel": [
          "Excel work step 1",
          "Excel work step 2"
        ],
        "Introduction to code settings and data processıng in R studio environment": [
          "Outlines of the code contents",
          "Working directory settings and data input",
          "Convert Slope Aspect Categorical data into Numeric",
          "Convert Land-cover Categorical data into Numeric",
          "Data Scaling",
          "Testing Data processing"
        ],
        "Run ANN NeuralNet (nn) package and get results plots": [
          "Run NeuralNet (nn) function",
          "Plot NeuralNet (nn) and get error estimation",
          "Adding NN function prediction output to training data frame",
          "How to convert values from scaled to original dataframe",
          "Pairwise plot of training dataframe and function output",
          "Generalized weight (GW) plot of training dataframe and function output"
        ],
        "(optional) Run NNET package and plot outputs": [
          "Run NNET function and get variables importance plot",
          "Plot NNET function network",
          "Run Sensitivity test using NNET function"
        ],
        "Prediction map processing using NeuralNet (nn) function": [
          "Run compute function (prediction function) and get cross tabulation results",
          "Update dataframe and run the previous step again",
          "Get cross tabulation for updated dataframe prediction",
          "Run compute function (prediction) with testing data and get cross tabulation",
          "Run ROC for function success and prediction rate results"
        ],
        "Final Prediction map production and visualization using NeuralNet": [
          "Import raster files into R studio",
          "Rasters processing (extents, resampling and stacking)",
          "Scale Rasters stack data",
          "Run compute (prediction) function for Rasters stack data",
          "Produce final prediction Raster map",
          "Export prediction raster map to QGIS"
        ],
        "Code Conclusion and Summary": [
          "Code Conclusion and Summary"
        ]
      },
      "requirements": [
        "No prior knowledge in programming needed",
        "Basic knowledge in R studio environment",
        "Basic knowledge in GIS and QGIS is optional"
      ],
      "description": "Artificial Neural Network (ANN) is one of the advanced Artificial Intelligence (AI) component, through many applications, vary from social, medical and applied engineering, ANN proves high reliability and validity enhanced by multiple setting options.\nUsing ANN with Spatial data, increases the confidence in the obtained results, especially when it compare to regression or classification based techniques. as called by many researchers and academician especially in prediction mapping applications.\nTogether, step by step with \"school-bus\" speed, will cover the following points comprehensively (data, code and other materials are provided) using NeuralNet Package in R and Landslides data and thematics maps.\nProduce training and testing data using automated tools in QGIS OR SKIP THIS STEP AND USE YOUR OWN TRAINING AND TESTING DATA\nRun Neural net function with training data and testing data\nPlot NN function network\nPairwise NN model results of Explanatories and Response Data\nGeneralized Weights plot of Explanatories and Response Data\nVariables importance using NNET Package function\nRun NNET function\nPlot NNET function network\nVariables importance using NNET\nSensitivity analysis of Explanatories and Response Data\nRun Neural net function for prediction with validation data\nPrediction Validation results with AUC value and ROC plot\nProduce prediction map using Raster data\nImport and process thematic maps like, resampling, stacking, categorical to numeric conversion.\nRun the compute (prediction function)\nExport final prediction map as raster.tif\nIMPORTANT: LaGriSU Version 2023_03_09 is available (Free) to download using Github link (please search for /Althuwaynee/LaGriSU_Landslide-Grid-and-Slope-Units-QGIS_ToolPack)\n*LaGriSU (automatic extraction of training / testing thematic data using Grid and Slope units)",
      "target_audience": [
        "All students, researchers and professionals that interested in using data mining with GIS Data",
        "All students, researchers and professionals that work on: Health [viruses susceptibility, noise maps, Epidemic expansions, Infectious Disease, Famine ]",
        "All students, researchers and professionals that work on: Hazards [ flooding, landslides, geological based, drought, air pollution..]"
      ]
    },
    {
      "title": "AI & Python Development Megaclass - 300+ Hands-on Projects",
      "url": "https://www.udemy.com/course/ai-python-development-megaclass-300-hands-on-projects/",
      "bio": "Training in Machine Learning, Deep Learning, Data Science, Computer Vision, NLP, Chatbots, and AI-Powered Applications",
      "objectives": [
        "Master Python programming from scratch, even with no prior experience",
        "Understand the fundamentals of AI, machine learning, and deep learning",
        "Build and deploy real-world AI applications using Python",
        "Work with essential AI libraries like TensorFlow, PyTorch, and OpenCV",
        "Develop practical skills through 100 hands-on AI and Python projects",
        "Learn data analysis, visualization, and preprocessing for AI models",
        "Implement AI-powered applications such as chatbots, recommendation systems, and automation tools",
        "Gain experience in model training, evaluation, and optimization techniques",
        "Understand the ethical and practical considerations of AI development",
        "Build a portfolio of AI and Python projects to showcase skills to employers or clients"
      ],
      "course_content": {
        "Week 1: Python Programming Basics for Artificial Intelligence": [
          "Introduction to Week 1 Python Programming Basics",
          "Day 1: Introduction to Python and Development Setup",
          "Day 2: Control Flow in Python",
          "Day 3: Functions and Modules",
          "Day 4: Data Structures (Lists, Tuples, Dictionaries, Sets)",
          "Day 5: Working with Strings",
          "Day 6: File Handling",
          "Day 7: Pythonic Code and Project Work",
          "Slides and Code for Course"
        ],
        "Week 2: Data Science Essentials for Artificial Intelligence": [
          "Introduction to Week 2 Data Science Essentials",
          "Day 1: Introduction to NumPy for Numerical Computing",
          "Day 2: Advanced NumPy Operations",
          "Day 3: Introduction to Pandas for Data Manipulation",
          "Day 4: Data Cleaning and Preparation with Pandas",
          "Day 5: Data Aggregation and Grouping in Pandas",
          "Day 6: Data Visualization with Matplotlib and Seaborn",
          "Day 7: Exploratory Data Analysis (EDA) Project"
        ],
        "Week 3: Mathematics for Machine Learning and Artificial Intelligence": [
          "Introduction to Week 3 Mathematics for Machine Learning",
          "Day 1: Linear Algebra Fundamentals",
          "Day 2: Advanced Linear Algebra Concepts",
          "Day 3: Calculus for Machine Learning (Derivatives)",
          "Day 4: Calculus for Machine Learning (Integrals and Optimization)",
          "Day 5: Probability Theory and Distributions",
          "Day 6: Statistics Fundamentals",
          "Day 7: Math-Driven Mini Project – Linear Regression from Scratch"
        ],
        "Week 4: Probability and Statistics for Machine Learning and AI": [
          "Introduction to Week 4 Probability and Statistics for Machine Learning",
          "Day 1: Probability Theory and Random Variables",
          "Day 2: Probability Distributions in Machine Learning",
          "Day 3: Statistical Inference - Estimation and Confidence Intervals",
          "Day 4: Hypothesis Testing and P-Values",
          "Day 5: Types of Hypothesis Tests",
          "Day 6: Correlation and Regression Analysis",
          "Day 7: Statistical Analysis Project – Analyzing Real-World Data"
        ],
        "Week 5: Introduction to Machine Learning": [
          "Introduction to Week 5 Introduction to Machine Learning",
          "Day 1: Machine Learning Basics and Terminology",
          "Day 2: Introduction to Supervised Learning and Regression Models",
          "Day 3: Advanced Regression Models – Polynomial Regression and Regularization",
          "Day 4: Introduction to Classification and Logistic Regression",
          "Day 5: Model Evaluation and Cross-Validation",
          "Day 6: k-Nearest Neighbors (k-NN) Algorithm",
          "Day 7: Supervised Learning Mini Project"
        ],
        "Week 6: Feature Engineering and Model Evaluation": [
          "Introduction to Week 6 Feature Engineering and Model Evaluation",
          "Day 1: Introduction to Feature Engineering",
          "Day 2: Data Scaling and Normalization",
          "Day 3: Encoding Categorical Variables",
          "Day 4: Feature Selection Techniques",
          "Day 5: Creating and Transforming Features",
          "Day 6: Model Evaluation Techniques",
          "Day 7: Cross-Validation and Hyperparameter Tuning"
        ],
        "Week 7: Advanced Machine Learning Algorithms": [
          "Introduction to Week 7 Advanced Machine Learning Algorithms",
          "Day 1: Introduction to Ensemble Learning",
          "Day 2: Bagging and Random Forests",
          "Day 3: Boosting and Gradient Boosting",
          "Day 4: Introduction to XGBoost",
          "Day 5: LightGBM and CatBoost",
          "Day 6: Handling Imbalanced Data",
          "Day 7: Ensemble Learning Project – Comparing Models on a Real Dataset"
        ],
        "Week 8: Model Tuning and Optimization": [
          "Introduction to Week 8 Model Tuning and Optimization",
          "Day 1: Introduction to Hyperparameter Tuning",
          "Day 2: Grid Search and Random Search",
          "Day 3: Advanced Hyperparameter Tuning with Bayesian Optimization",
          "Day 4: Regularization Techniques for Model Optimization",
          "Day 5: Cross-Validation and Model Evaluation Techniques",
          "Day 6: Automated Hyperparameter Tuning with GridSearchCV and RandomizedSearchCV",
          "Day 7: Optimization Project – Building and Tuning a Final Model"
        ],
        "Week 9: Neural Networks and Deep Learning Fundamentals": [
          "Introduction to Week 9 Neural Networks and Deep Learning Fundamentals",
          "Day 1: Introduction to Deep Learning and Neural Networks",
          "Day 2: Forward Propagation and Activation Functions",
          "Day 3: Loss Functions and Backpropagation",
          "Day 4: Gradient Descent and Optimization Techniques",
          "Day 5: Building Neural Networks with TensorFlow and Keras",
          "Day 6: Building Neural Networks with PyTorch",
          "Day 7: Neural Network Project – Image Classification on CIFAR-10"
        ],
        "Week 10: Convolutional Neural Networks (CNNs)": [
          "Introduction to Week 10 Convolutional Neural Networks (CNNs)",
          "Day 1: Introduction to Convolutional Neural Networks",
          "Day 2: Convolutional Layers and Filters",
          "Day 3: Pooling Layers and Dimensionality Reduction",
          "Day 4: Building CNN Architectures with Keras and TensorFlow",
          "Day 5: Building CNN Architectures with PyTorch",
          "Day 6: Regularization and Data Augmentation for CNNs",
          "Day 7: CNN Project – Image Classification on Fashion MNIST or CIFAR-10"
        ]
      },
      "requirements": [
        "No prior programming or AI experience required",
        "A computer with internet access for coding and project work",
        "Willingness to learn and experiment with Python and AI concepts",
        "Basic familiarity with using a computer and installing software",
        "An interest in AI, machine learning, and automation",
        "A mindset for problem-solving and hands-on learning",
        "Optional: A Google Colab or Jupyter Notebook setup for running Python code"
      ],
      "description": "Dive into the ultimate AI and Python Development Bootcamp designed for beginners and aspiring AI engineers. This comprehensive course takes you from zero programming experience to mastering Python, machine learning, deep learning, and AI-powered applications through 100 real-world projects. Whether you want to start a career in AI, enhance your development skills, or create cutting-edge automation tools, this course provides hands-on experience with practical implementations.(AI)\nYou will begin by learning Python from scratch, covering everything from basic syntax to advanced functions. As you progress, you will explore data science techniques, data visualization, and preprocessing to prepare datasets for AI models. The course then introduces machine learning algorithms, teaching you how to build predictive models, analyze patterns, and make AI-driven decisions. You will work with TensorFlow, PyTorch, OpenCV, and Scikit-Learn to create AI applications that process text, images, and structured data.\nAs you advance, you will develop chatbots, recommendation systems, sentiment analyzers, and automation tools using real-world datasets. You will gain expertise in natural language processing (NLP), computer vision, and reinforcement learning, mastering how AI is applied in various industries. The course also covers AI ethics, model optimization, and deployment strategies, ensuring you understand how to scale AI projects efficiently.\nBy the end of the course, you will have 100 hands-on projects that demonstrate your skills in AI development, automation, and machine learning. Whether you’re looking to launch an AI-driven startup, enhance your resume with in-demand AI skills, or automate business processes, this course equips you with everything you need. Join now and become proficient in Python and AI development, unlocking endless opportunities in the tech industry.",
      "target_audience": [
        "Absolute beginners with no prior programming or AI experience",
        "Aspiring AI engineers looking to build a strong foundation in Python and AI",
        "Students and professionals who want hands-on experience with real-world AI projects",
        "Developers transitioning into AI and machine learning from other fields",
        "Data enthusiasts who want to apply Python for AI-driven applications",
        "Entrepreneurs and business professionals interested in leveraging AI for automation",
        "Tech enthusiasts looking to explore Python and AI through practical projects",
        "Educators and trainers seeking structured AI and Python learning resources",
        "Researchers and analysts who want to enhance their AI and data science skills",
        "Anyone interested in learning AI development through a project-based approach"
      ]
    },
    {
      "title": "Machine Learning and Deep Learning A-Z: Hands-On Python",
      "url": "https://www.udemy.com/course/machine-learning-and-deep-learning-a-z-hands-on-python/",
      "bio": "Python Machine Learning and Python Deep Algorithms in Python Code templates included. Python in Data Science | 2021",
      "objectives": [
        "Machine learning isn’t just useful for predictive texting or smartphone voice recognition.",
        "Learn Machine Learning with Hands-On Examples",
        "What is Machine Learning?",
        "Machine Learning Terminology",
        "Evaluation Metrics for Python machine learning, Python Deep learning",
        "What are Classification vs Regression?",
        "Evaluating Performance-Classification Error Metrics",
        "Evaluating Performance-Regression Error Metrics",
        "Supervised Learning",
        "Cross Validation and Bias Variance Trade-Off",
        "Use matplotlib and seaborn for data visualizations",
        "Machine Learning with SciKit Learn",
        "Linear Regression Algorithm",
        "Logistic Regresion Algorithm",
        "K Nearest Neighbors Algorithm",
        "Decision Trees And Random Forest Algorithm",
        "Support Vector Machine Algorithm",
        "Unsupervised Learning",
        "K Means Clustering Algorithm",
        "Hierarchical Clustering Algorithm",
        "Principal Component Analysis (PCA)",
        "Recommender System Algorithm",
        "Python, python machine learning and deep learning",
        "Machine Learning, machine learning A-Z",
        "Deep Learning, Deep learning a-z",
        "Data Visualization",
        "Machine learning is constantly being applied to new industries and new problems. Whether you’re a marketer, video game designer, or programmer",
        "Machine learning describes systems that make predictions using a model trained on real-world data.",
        "Machine learning is being applied to virtually every field today. That includes medical diagnoses, facial recognition, weather forecasts, image processing",
        "It's possible to use machine learning without coding, but building new systems generally requires code.",
        "What is the best language for machine learning? Python is the most used language in machine learning.",
        "Engineers writing machine learning systems often use Jupyter Notebooks and Python together.",
        "Machine learning is generally divided between supervised machine learning and unsupervised machine learning.",
        "Python instructors on Udemy specialize in everything from software development to data analysis, and are known for their effective, friendly instruction",
        "What are the limitations of Python? Python is a widely used, general-purpose programming language, but it has some limitations.",
        "How is Python used? Python is a general programming language used widely across many industries and platforms.",
        "What jobs use Python? Python is a popular language that is used across many industries and in many programming disciplines",
        "How do I learn Python on my own? Python has a simple syntax that makes it an excellent programming language for a beginner to learn.",
        "Data science is everywhere. Better data science practices are allowing corporations to cut unnecessary costs, automate computing, and analyze markets.",
        "What is data science? We have more data than ever before. But data alone cannot tell us much about the world around us.",
        "What does a data scientist do? Data Scientists use machine learning to discover hidden patterns in large amounts of raw data to shed light on real problems.",
        "What are the most popular coding languages for data science? Python is the most popular programming language for data science."
      ],
      "course_content": {
        "Python, Machine Learning and Deep Learning Code Files And Resources": [
          "Section 2 Data Visualisation - Matplotlib Files in Python",
          "Section 3 Data Visualization - Seaborn",
          "Section 4 Data Visualisation - Geoplotlib",
          "Section 5 to 18 Machine Learning Part",
          "Section 19 To 24 Deep Learning Part",
          "FAQ about machine learning and deep learning a-z: hands on python"
        ],
        "Data Visualisation - Matplotlib": [
          "What is Matplotlib",
          "Using Matplotlib",
          "Pyplot – Pylab - Matplotlib",
          "Figure, Subplot and Axes",
          "Figure Customization",
          "Plot Customization",
          "Grid, Spines, Ticks",
          "Basic Plots in Matplotlib I",
          "Basic Plots in Matplotlib II",
          "Quiz"
        ],
        "Data Visualization - Seaborn": [
          "What is Seaborn?",
          "Controlling Figure Aesthetics",
          "Example",
          "Color Palettes",
          "Basic Plots in Seaborn",
          "Multi-Plots in Seaborn",
          "Regression Plots and Squarify",
          "Quiz"
        ],
        "Data Visualisation - Geoplotlib": [
          "What is Geoplotlib?",
          "Example - 1",
          "Example - 2",
          "Example - 3",
          "Quiz"
        ],
        "First Contact with Machine Learning": [
          "What is Machine Learning?",
          "What are Machine Learning Terminologies?",
          "Machine Learning Project Files",
          "Quiz 1 - Machine Learning",
          "Ouiz 2 - Machine Learning A-Z"
        ],
        "Evalution Metrics in Machine Learning": [
          "Classification vs Regression in Machine Learning",
          "Machine Learning Model Performance Evaluation: Classification Error Metrics",
          "Machine Learning Model Performance Evaluation: Regression Error Metrics",
          "Machine Learning With Python",
          "Ouiz in Machine Learning"
        ],
        "Supervised Learning with Machine Learning": [
          "What is Supervised Learning in Machine Learning?",
          "Quiz"
        ],
        "Linear Regression Algorithm": [
          "What is Linear Regression Algorithm in Machine Learning?",
          "Linear Regression Algorithm with Python Part 1",
          "Linear Regression Algorithm with Python Part 2",
          "Linear Regression Algorithm with Python Part 3",
          "Linear Regression Algorithm with Python Part 4",
          "quiz"
        ],
        "Bias Variance Trade-Off in Machine Learning": [
          "What is Bias Variance Trade-Off?",
          "Quiz"
        ],
        "Logistic Regression Algorithm in Machine Learning A-Z": [
          "What is Logistic Regression Algorithm in Machine Learning?",
          "Logistic Regression Algorithm with Python Part 1",
          "Logistic Regression Algorithm with Python Part 2",
          "Logistic Regression Algorithm with Python Part 3",
          "Logistic Regression Algorithm with Python Part 4",
          "Logistic Regression Algorithm with Python Part 5",
          "Quiz"
        ]
      },
      "requirements": [
        "Basic knowledge of Python Programming Language",
        "Be Able To Operate & Install Software On A Computer",
        "Free software and tools used during the course",
        "Determination to learn and patience.",
        "Desire to master on python, machine learning a-z, deep learning a-z",
        "Motivation to learn the the second largest number of job postings relative program language among all others",
        "Data visualization libraries in python such as seaborn, matplotlib",
        "Learn to create Machine Learning and Deep Algorithms in Python Code templates included."
      ],
      "description": "Hello there,\nMachine learning python, python, machine learning, django, ethical hacking, python bootcamp, data analysis, machine learning python, python for beginners, data science, machine learning, django\nWelcome to the “Machine Learning and Deep Learning A-Z: Hands-On Python ” course\nPython Machine Learning and Python Deep Algorithms in Python Code templates included Python in Data Science | 2021\nDo you know data science needs will create 11 5 million job openings by 2026?\nDo you know the average salary is $100 000 for data science careers!\nDeep learning a-z, machine learning a-z, deep learning, machine learning, machine learning & data science a-z: hands on python 2021, machine learning python, machine learning python, machine learning algorithms, python, Itsm, machine learning and deep learning a-z: hands on python, machine learning and deep learning a-z hands pn python, data science, rnn, deep learning python, data science a-z, recurrent neural network,\nMachine learning isn’t just useful for predictive texting or smartphone voice recognition Machine learning is constantly being applied to new industries and new problems Whether you’re a marketer, video game designer, or programmer, my course on Udemy here to help you apply machine learning to your work\n\nData Science Careers Are Shaping The Future\nData science experts are needed in almost every field, from government security to dating apps Millions of businesses and government departments rely on big data to succeed and better serve their customers So data science careers are in high demand\nUdemy offers highly-rated data science courses that will help you learn how to visualize and respond to new data, as well as develop innovative new technologies Whether you’re interested in machine learning, data mining, or data analysis, Udemy has a course for you\nIf you want to learn one of the employer’s most request skills?\nIf you are curious about Data Science and looking to start your self-learning journey into the world of data with Python?\nIf you are an experienced developer and looking for a landing in Data Science!\nIn all cases, you are at the right place!\nWe've designed for you “Machine Learning and Deep Learning A-Z: Hands-On Python ” a straightforward course for Python Programming Language and Machine Learning\nIn the course, you will have down-to-earth way explanations with projects With this course, you will learn machine learning step-by-step I made it simple and easy with exercises, challenges, and lots of real-life examples\nWe will open the door of the Data Science and Machine Learning a-z world and will move deeper You will learn the fundamentals of Machine Learning A-Z and its beautiful libraries such as Scikit Learn\nThroughout the course, we will teach you how to use Python to analyze data, create beautiful visualizations, and use powerful machine learning python algorithms\nWhether you work in machine learning or finance, or are pursuing a career in web development or data science, Python is one of the most important skills you can learn Python's simple syntax is especially suited for desktop, web, and business applications Python's design philosophy emphasizes readability and usability Python was developed upon the premise that there should be only one way (and preferably one obvious way) to do things, a philosophy that has resulted in a strict level of code standardization The core programming language is quite small and the standard library is also large In fact, Python's large library is one of its greatest benefits, providing a variety of different tools for programmers suited for many different tasks\n\nBecause data can mean an endless number of things, it’s important to choose the right visualization tools for the job Whether you’re interested in learning Tableau, D3 js, After Effects, or Python, Udemy has a course for you\nIn this course, we will learn what is data visualization and how does it work with python\nThis course has suitable for everybody who is interested data vizualisation concept\nFirst of all, in this course, we will learn some fundamentals of pyhton, and object-oriented programming ( OOP ) These are our first steps in our Data Visualisation journey After then we take a our journey to the Data Science world Here we will take a look at data literacy and data science concepts Then we will arrive at our next stop Numpy library Here we learn what is NumPy and how we can use it After then we arrive at our next stop Pandas library And now our journey becomes an adventure In this adventure we'll enter the Matplotlib world then we exit the Seaborn world Then we'll try to understand how we can visualize our data, data viz But our journey won’t be over Then we will arrive at our final destination Geographical drawing or best known as Geoplotlib in tableau data visualization\nLearn python and how to use it to python data analysis and visualization, present data Includes tons of code data vizualisation\nIn this course, you will learn data analysis and visualization in detail\n\nAlso during the course, you will learn:\n\nThe Logic of Matplotlib\nWhat is Matplotlib\nUsing Matplotlib\nPyplot – Pylab - Matplotlib - Excel\nFigure, Subplot, Multiplot, Axes,\nFigure Customization\nPlot Customization\nGrid, Spines, Ticks\nBasic Plots in Matplotlib\nOverview of Jupyter Notebook and Google Colab\nSeaborn library with these topics\nWhat is Seaborn\nControlling Figure Aesthetics\nColor Palettes\nBasic Plots in Seaborn\nMulti-Plots in Seaborn\nRegression Plots and Squarify\nGeoplotlib with these topics\nWhat is Geoplotlib\nTile Providers and Custom Layers\nThis Machine Learning course is for everyone!\nMy \"Machine Learning with Hands-On Examples in Data Science\" is for everyone! If you don’t have any previous experience, not a problem! This course is expertly designed to teach everyone from complete beginners, right through to professionals ( as a refresher)\nWhy we use a Python programming language in Machine learning?\nPython is a general-purpose, high-level, and multi-purpose programming language The best thing about Python is, it supports a lot of today’s technology including vast libraries for Twitter, data mining, scientific calculations, designing, back-end server for websites, engineering simulations, artificial learning, augmented reality and what not! Also, it supports all kinds of App development\nWhat you will learn?\nIn this course, we will start from the very beginning and go all the way to the end of \"Machine Learning\" with examples\nBefore each lesson, there will be a theory part After learning the theory parts, we will reinforce the subject with practical examples\nDuring the course you will learn the following topics:\nWhat is Machine Learning?\nMore About Machine Learning\nMachine Learning Terminology\nEvaluation Metrics\nWhat is Classification vs Regression?\nEvaluating Performance-Classification Error Metrics\nEvaluating Performance-Regression Error Metrics\nMachine Learning with Python\nSupervised Learning\nCross-Validation and Bias Variance Trade-Off\nUse Matplotlib and seaborn for data visualizations\nMachine Learning with SciKit Learn\nLinear Regression Theory\nLogistic Regression Theory\nLogistic Regression with Python\nK Nearest Neighbors Algorithm Theory\nK Nearest Neighbors Algorithm With Python\nK Nearest Neighbors Algorithm Project Overview\nK Nearest Neighbors Algorithm Project Solutions\nDecision Trees And Random Forest Algorithm Theory\nDecision Trees And Random Forest Algorithm With Python\nDecision Trees And Random Forest Algorithm Project Overview\nDecision Trees And Random Forest Algorithm Project Solutions\nSupport Vector Machines Algorithm Theory\nSupport Vector Machines Algorithm With Python\nSupport Vector Machines Algorithm Project Overview\nSupport Vector Machines Algorithm Project Solutions\nUnsupervised Learning Overview\nK Means Clustering Algorithm Theory\nK Means Clustering Algorithm With Python\nK Means Clustering Algorithm Project Overview\nK Means Clustering Algorithm Project Solutions\nHierarchical Clustering Algorithm Theory\nHierarchical Clustering Algorithm With Python\nPrincipal Component Analysis (PCA) Theory\nPrincipal Component Analysis (PCA) With Python\nRecommender System Algorithm Theory\nRecommender System Algorithm With Python\nMachine learning\nMachine learning python\nEthical hacking, python Bootcamp\nData analysis\nPython machine learning\nPython programming\nPython examples\nPython hands-on\nDeep learning a-z\nMachine learning a-z\nMachine learning & data science a-z\nmachine learning algorithms\nWith my up-to-date course, you will have a chance to keep yourself up-to-date and equip yourself with a range of Python programming skills I am also happy to tell you that I will be constantly available to support your learning and answer questions\n\n\nThis course has suitable for everybody who interested in Machine Learning and Deep Learning concepts\nFirst of all, in this course, we will learn some fundamental stuff of Python and the Numpy library These are our first steps in our Deep Learning journey After then we take a little trip to Machine Learning history Then we will arrive at our next stop Machine Learning Here we learn the machine learning concepts, machine learning workflow, models and algorithms, and what is neural network concept After then we arrive at our next stop Artificial Neural network And now our journey becomes an adventure In this adventure we'll enter the Keras world then we exit the Tensorflow world Then we'll try to understand the Convolutional Neural Network concept But our journey won't be over Then we will arrive at Recurrent Neural Network and LTSM We'll take a look at them After a while, we'll trip to the Transfer Learning concept And then we arrive at our final destination Projects Our play garden Here we'll make some interesting machine learning models with the information we've learned along our journey\n\nDuring the course you will learn:\n\nWhat is the AI, Machine Learning, and Deep Learning\nHistory of Machine Learning\nTuring Machine and Turing Test\nThe Logic of Machine Learning such as\nUnderstanding the machine learning models\nMachine Learning models and algorithms\nGathering data\nData pre-processing\nChoosing the right algorithm and model\nTraining and testing the model\nEvaluation\nArtificial Neural Network with these topics\nWhat is ANN\nAnatomy of NN\nTensor Operations\nThe Engine of NN\nKeras\nTensorflow\nConvolutional Neural Network\nRecurrent Neural Network and LTSM\nTransfer Learning\n\nIn this course, we will start from the very beginning and go all the way to the end of \"Deep Learning\" with examples\nBefore we start this course, we will learn which environments we can be used for developing deep learning projects\nWhy would you want to take this course?\nOur answer is simple: The quality of teaching\nOAK Academy based in London is an online education company OAK Academy gives education in the field of IT, Software, Design, development in English, Portuguese, Spanish, Turkish, and a lot of different languages on the Udemy platform where it has over 1000 hours of video education lessons OAK Academy both increases its education series number by publishing new courses, and it makes students aware of all the innovations of already published courses by upgrading\nWhen you enroll, you will feel the OAK Academy`s seasoned developers' expertise Questions sent by students to our instructors are answered by our instructors within 48 hours at the latest\nWhat are the limitations of Python?\nPython is a widely used, general-purpose programming language, but it has some limitations Because Python is an interpreted, dynamically typed language, it is slow compared to a compiled, statically typed language like C Therefore, Python is useful when speed is not that important Python's dynamic type system also makes it use more memory than some other programming languages, so it is not suited to memory-intensive applications The Python virtual engine that runs Python code runs single-threaded, making concurrency another limitation of the programming language Though Python is popular for some types of game development, its higher memory and CPU usage limits its usage for high-quality 3D game development That being said, computer hardware is getting better and better, and the speed and memory limitations of Python are getting less and less relevant making Python even more popular\nHow is Python used?\nPython is a general programming language used widely across many industries and platforms One common use of Python is scripting, which means automating tasks in the background Many of the scripts that ship with Linux operating systems are Python scripts Python is also a popular language for machine learning, data analytics, data visualization, and data science because its simple syntax makes it easy to quickly build real applications You can use Python to create desktop applications Many developers use it to write Linux desktop applications, and it is also an excellent choice for web and game development Python web frameworks like Flask and Django are a popular choice for developing web applications Recently, Python is also being used as a language for mobile development via the Kivy third-party library, although there are currently some drawbacks Python needs to overcome when it comes to mobile development\nWhat jobs use Python?\nPython is a popular language that is used across many industries and in many programming disciplines DevOps engineers use Python to script website and server deployments Web developers use Python to build web applications, usually with one of Python's popular web frameworks like Flask or Django Data scientists and data analysts use Python to build machine learning models, generate data visualizations, and analyze big data Financial advisors and quants (quantitative analysts) use Python to predict the market and manage money Data journalists use Python to sort through information and create stories Machine learning engineers use Python to develop neural networks and artificial intelligent systems\nHow do I learn Python on my own?\nPython has a simple syntax that makes it an excellent programming language for a beginner to learn To learn Python on your own, you first must become familiar with the syntax But you only need to know a little bit about Python syntax to get started writing real code; you will pick up the rest as you go Depending on the purpose of using it, you can then find a good Python tutorial, book, or course that will teach you the programming language by building a complete application that fits your goals If you want to develop games, then learn Python game development If you're going to build web applications, you can find many courses that can teach you that, too Udemy’s online courses are a great place to start if you want to learn Python on your own\nWhat is data science?\nWe have more data than ever before But data alone cannot tell us much about the world around us We need to interpret the information and discover hidden patterns This is where data science comes in Data science uses algorithms to understand raw data The main difference between data science and traditional data analysis is its focus on prediction Data science seeks to find patterns in data and use those patterns to predict future data It draws on machine learning to process large amounts of data, discover patterns, and predict trends Data science includes preparing, analyzing, and processing data It draws from many scientific fields, and as a science, it progresses by creating new algorithms to analyze data and validate current methods\nWhat does a data scientist do?\nData Scientists use machine learning to discover hidden patterns in large amounts of raw data to shed light on real problems This requires several steps First, they must identify a suitable problem Next, they determine what data are needed to solve such a situation and figure out how to get the data Once they obtain the data, they need to clean the data The data may not be formatted correctly, it might have additional unnecessary data, it might be missing entries, or some data might be incorrect Data Scientists must, therefore, make sure the data is clean before they analyze the data To analyze the data, they use machine learning techniques to build models Once they create a model, they test, refine, and finally put it into production\nWhat are the most popular coding languages for data science?\nPython is the most popular programming language for data science It is a universal language that has a lot of libraries available It is also a good beginner language R is also popular; however, it is more complex and designed for statistical analysis It might be a good choice if you want to specialize in statistical analysis You will want to know either Python or R and SQL SQL is a query language designed for relational databases Data scientists deal with large amounts of data, and they store a lot of that data in relational databases Those are the three most-used programming languages Other languages such as Java, C++, JavaScript, and Scala are also used, albeit less so If you already have a background in those languages, you can explore the tools available in those languages However, if you already know another programming language, you will likely be able to pick up Python very quickly\nHow long does it take to become a data scientist?\nThis answer, of course, varies The more time you devote to learning new skills, the faster you will learn It will also depend on your starting place If you already have a strong base in mathematics and statistics, you will have less to learn If you have no background in statistics or advanced mathematics, you can still become a data scientist; it will just take a bit longer Data science requires lifelong learning, so you will never really finish learning A better question might be, \"How can I gauge whether I know enough to become a data scientist?\" Challenge yourself to complete data science projects using open data The more you practice, the more you will learn, and the more confident you will become Once you have several projects that you can point to as good examples of your skillset as a data scientist, you are ready to enter the field\nHow can I learn data science on my own?\nIt is possible to learn data science on your own, as long as you stay focused and motivated Luckily, there are a lot of online courses and boot camps available Start by determining what interests you about data science If you gravitate to visualizations, begin learning about them Starting with something that excites you will motivate you to take that first step If you are not sure where you want to start, try starting with learning Python It is an excellent introduction to programming languages and will be useful as a data scientist Begin by working through tutorials or Udemy courses on the topic of your choice Once you have developed a base in the skills that interest you, it can help to talk with someone in the field Find out what skills employers are looking for and continue to learn those skills When learning on your own, setting practical learning goals can keep you motivated\nDoes data science require coding?\nThe jury is still out on this one Some people believe that it is possible to become a data scientist without knowing how to code, but others disagree A lot of algorithms have been developed and optimized in the field You could argue that it is more important to understand how to use the algorithms than how to code them yourself As the field grows, more platforms are available that automate much of the process However, as it stands now, employers are primarily looking for people who can code, and you need basic programming skills The data scientist role is continuing to evolve, so that might not be true in the future The best advice would be to find the path that fits your skillset\nWhat skills should a data scientist know?\nA data scientist requires many skills They need a strong understanding of statistical analysis and mathematics, which are essential pillars of data science A good understanding of these concepts will help you understand the basic premises of data science Familiarity with machine learning is also important Machine learning is a valuable tool to find patterns in large data sets To manage large data sets, data scientists must be familiar with databases Structured query language (SQL) is a must-have skill for data scientists However, nonrelational databases (NoSQL) are growing in popularity, so a greater understanding of database structures is beneficial The dominant programming language in Data Science is Python — although R is also popular A basis in at least one of these languages is a good starting point Finally, to communicate findings, data scientists require knowledge of visualizations Data visualizations allow them to share complex data in an accessible manner\nIs data science a good career?\nThe demand for data scientists is growing We do not just have data scientists; we have data engineers, data administrators, and analytics managers The jobs also generally pay well This might make you wonder if it would be a promising career for you A better understanding of the type of work a data scientist does can help you understand if it might be the path for you First and foremost, you must think analytically Data science is about gaining a more in-depth understanding of info through data Do you fact-check information and enjoy diving into the statistics? Although the actual work may be quite technical, the findings still need to be communicated Can you explain complex findings to someone who does not have a technical background? Many data scientists work in cross-functional teams and must share their results with people with very different backgrounds If this sounds like a great work environment, then it might be a promising career for you\nVideo and Audio Production Quality\nAll our videos are created/produced as high-quality video and audio to provide you the best learning experience\nYou will be,\nSeeing clearly\nHearing clearly\nMoving through the course without distractions\n\n\nYou'll also get:\nLifetime Access to The Course\nFast & Friendly Support in the Q&A section\nUdemy Certificate of Completion Ready for Download\nWe offer full support, answering any questions\nIf you are ready to learn the “Machine Learning and Deep Learning A-Z: Hands-On Python ” course\nDive in now! See you in the course!",
      "target_audience": [
        "Machine learning isn’t just useful for predictive texting or smartphone voice recognition. Machine learning is constantly being applied to new industries and new problems. It is for everyone",
        "Anyone who wants to start learning \"Machine Learning\"",
        "Anyone who needs a complete guide on how to start and continue their career with machine learning",
        "Software developer who wants to learn \"Machine Learning\"",
        "Students Interested in Beginning Data Science Applications in Python Environment",
        "People Wanting to Specialize in Anaconda Python Environment for Data Science and Scientific Computing",
        "Students Wanting to Learn the Application of Supervised Learning (Classification) on Real Data Using Python",
        "People who want to learn machine learning, deep learning, python"
      ]
    },
    {
      "title": "Data Visualization in Python for Machine Learning Engineers",
      "url": "https://www.udemy.com/course/data-visualization-in-python-for-machine-learning-engineers/",
      "bio": "The Third Course in a Series for Mastering Python for Machine Learning Engineers",
      "objectives": [
        "You'll learn Matplotlib and Seaborn and have a solid understanding of how they are used in applied machine learning.",
        "You'll work through hands on labs that will test the skills you learned in the lessons.",
        "You'll learn all the Python vernacular specific to data visualization you need to take you skills to the next level.",
        "You'll be on your way to becoming a real world machine learning engineer or data engineer."
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Is this Course for You?",
          "Hello World in matplotlib",
          "Matplotlib Philosopy",
          "Numpy",
          "Lab: First Plot",
          "Summary",
          "Quiz"
        ],
        "Plotting in Matplotlib": [
          "Plotting Multiple Curves",
          "Plotting Curves from an Existing Data Set",
          "Plotting Points",
          "Lab: Scatterplot from Pandas Dataframe",
          "Bar Charts",
          "Multiple Bar Charts",
          "Plotting Stacked Bars",
          "Lab: Plotting Multiple Stacked Bars",
          "The Pie Chart",
          "Plotting a Histogram",
          "Lab: Plotting a Histogram",
          "Plotting Boxplots",
          "Lab: Plotting Multiple Box Plots",
          "Plotting Triangulations",
          "Summary"
        ],
        "Customizing Our Charts": [
          "Adding Styles and Colors",
          "Adding Color to the Scatterplot",
          "Lab: Scatter Plot Grey Scale From a File",
          "EdgeColor Parameter",
          "Adding Color to a Bar Chart",
          "Lab: Bar Chart on Dependent Values",
          "Pie Chart Anatomy",
          "Black and White Boxplots",
          "Controlling Line Pattern and Thickness",
          "Lab: Controlling Pattern and Fill",
          "Working with Markers",
          "Lab: Controlling Marker Size",
          "Lab: Controlling Marker Frequency",
          "Creating Customer Markers",
          "Lab: List as Input for Size Parameter",
          "Creating Personalized Color Schemes",
          "Save Graph to PNG or JPEG",
          "Lab: Save Graph to PDF",
          "Summary",
          "Quiz"
        ],
        "Annotations": [
          "Simple Title Annotation",
          "Labeling the X and Y Axes",
          "Lab: Adding Text Anywhere",
          "Bounded Box Control",
          "Adding an Arrow to a Chart",
          "Lab: Adding a Grid to a Chart",
          "Adding Ticks to a Chart",
          "Lab: Labeling our Ticks",
          "Adding Ticks to Charts (The Easy Way)",
          "Summary",
          "Quiz"
        ],
        "Seaborn": [
          "Seaborn Introduction",
          "Lab: Exploring the Sundry Color Schemes",
          "Creating a Factorplot",
          "Creating a Simple Colormap",
          "Scaling our Seaborn Plots",
          "Lab: Controlling Font Size",
          "The Two Core Functions",
          "How to Set Figure Size",
          "Lab: Figure Level Functions",
          "Lab: Rotate Text on a Seaborn Plot",
          "Summary",
          "Quiz",
          "Bonus Lecture: Tons of Free Machine Learning Content"
        ]
      },
      "requirements": [
        "You've completed the first two courses in the series.",
        "A desire to learn Python.",
        "A basic understanding of machine learning would be beneficial."
      ],
      "description": "Welcome to Data Visualization in Python for Machine learning engineers.\nThis is the third course in a series designed to prepare you for becoming a machine learning engineer.\nI'll keep this updated and list only the courses that are live.  Here is a list of the courses that can be taken right now.  Please take them in order. The knowledge builds from course to course.\nThe Complete Python Course for Machine Learning Engineers\nData Wrangling in Pandas for Machine Learning Engineers\nData Visualization in Python for Machine Learning Engineers (This one)\nThe second course in the series is about Data Wrangling. Please take the courses in order.\nThe knowledge builds from course to course in a serial nature. Without the first course many students might struggle with this one.\nThank you!!\nIn this course we are going to focus on data visualization and in Python that means we are going to be learning matplotlib and seaborn.\nMatplotlib is a Python package for 2D plotting that generates production-quality graphs. Matplotlib tries to make easy things easy and hard things possible. You can generate plots, histograms, power spectra, bar charts, errorcharts, scatterplots, etc., with just a few lines of code.\nSeaborn is a Python visualization library based on matplotlib. Most developers will use seaborn if the same functionally exists in both matplotlib and seaborn.\nThis course focuses on visualizing. Here are a few things you'll learn in the course.\nA complete understanding of data visualization vernacular.\nMatplotlib from A-Z.\nThe ability to craft usable charts and graphs for all your machine learning needs.\nLab integrated. Please don't just watch. Learning is an interactive event.  Go over every lab in detail.\nReal world Interviews Questions.\n**Five Reasons to Take this Course**\n1) You Want to be a Machine Learning Engineer\nIt's one of the most sought after careers in the world. The growth potential career wise is second to none. You want the freedom to move anywhere you'd like. You want to be compensated for your efforts. You want to be able to work remotely. The list of benefits goes on. Without a solid understanding of data wrangling in Python you'll have a hard time of securing a position as a machine learning engineer.\n2) Data Visualization is a Core Component of Machine Learning\nData visualization is the presentation of data in a pictorial or graphical format. It enables decision makers to see analytics presented visually, so they can grasp difficult concepts or identify new patterns. Because of the way the human brain processes information, using charts or graphs to visualize large amounts of complex data is easier than poring over spreadsheets or reports. Data visualization is a quick, easy way to convey concepts in a universal manner – and you can experiment with different scenarios by making slight adjustments.\n3) The Growth of Data is Insane\nNinety percent of all the world's data has been created in the last two years. Business around the world generate approximately 450 billion transactions a day. The amount of data collected by all organizations is approximately 2.5 exabytes a day. That number doubles every month.  Almost all real world machine learning is supervised. That means you point your machine learning models at clean tabular data.\n4) Machine Learning in Plain English\nMachine learning is one of the hottest careers on the planet and understanding the basics is required to attaining a job as a data engineer.  Google expects data engineers and their machine learning engineers to be able to build machine learning models.\n5) You want to be ahead of the Curve\nThe data engineer and machine learning engineer roles are fairly new.  While you’re learning, building your skills and becoming certified you are also the first to be part of this burgeoning field.  You know that the first to be certified means the first to be hired and first to receive the top compensation package.\nThanks for interest in Data Visualization in Python for Machine learning engineers.\nSee you in the course!!",
      "target_audience": [
        "If you want to become a machine learning engineer then this course is for you.",
        "If you need to learn Python for machine learning then this course is for you.",
        "If you want to learn how to use matplotlib for real world applications then this course is for you."
      ]
    },
    {
      "title": "The Complete Intro to Machine Learning",
      "url": "https://www.udemy.com/course/the-complete-intro-to-machine-learning-with-python/",
      "bio": "Hands-on ML with Python, Pandas, Regression, Decision Trees, Neural Networks, and more!",
      "objectives": [
        "Learn the basics of data visualization and pre-processing (Python basics, Numpy, Pandas, Seaborn)",
        "Gain theoretical and practical experience with fundamental machine learning algorithms (Linear and Logistic Regression, K-NN, Decision Trees, Neural Networks)",
        "Understand advanced ML topics (encoding, ensemble learning techniques, etc.)",
        "Submit to your first Kaggle Machine Learning Competition"
      ],
      "course_content": {
        "Welcome to the Course": [
          "Introduction",
          "Google Colab Tour"
        ],
        "Python Review": [
          "Variable Types",
          "Lists and Functions",
          "Implementation"
        ],
        "Numpy": [
          "Numpy Basics",
          "Implementation"
        ],
        "Pandas": [
          "Pandas Basics",
          "Implementation"
        ],
        "Seaborn": [
          "Distribution and Matrix Plots",
          "Categorical Plots, Regression Plots, and Grids/Style",
          "Implementation"
        ],
        "Linear Regression": [
          "Linear Regression Theory",
          "Goals and Types of Machine Learning",
          "Ordinary Least Squares (OLS)",
          "Implementation Part 1",
          "Implementation Part 2"
        ],
        "Logistic Regression": [
          "Logistic Regression Theory",
          "Logistic Regression Metrics and Implementation"
        ],
        "Decision Trees": [
          "Terminology",
          "Splitting Algorithms",
          "Random Forests",
          "Implementation"
        ],
        "Neural Networks": [
          "Origins of Neural Networks",
          "What are neural networks?",
          "Activation Functions",
          "Gradient Descent",
          "Backpropagation",
          "Implementation",
          "Intro to Neural Networks"
        ]
      },
      "requirements": [
        "No programming or theoretical math prerequisites. We'll teach you everything you need to know."
      ],
      "description": "﻿Interested in machine learning but confused by the jargon? If so, we made this course for you.\nMachine learning is the fastest-growing field with constant groundbreaking research. If you're interested in any of the following, you'll be interested in ML:\nSelf-driving cars\nLanguage processing\nMarket prediction\nSelf-playing games\nAnd so much more!\nNo past knowledge is required: we'll start with the basics of Python and end with gradient-boosted decision trees and neural networks. The course will walk you through the fundamentals of machine learning, explaining mathematical foundations as well as practical implementations. By the end of our course, you'll have worked with five public data sets and have implemented all essential supervised learning models. After the course's completion, you'll be equipped to apply your skills to Kaggle data science competitions, business intelligence applications, and research projects.\nWe made the course quick, simple, and thorough. We know you're busy, so our curriculum cuts to the chase with every lecture. If you're interested in the field, this is a great course to start with.\nHere are some of the Python libraries you'll be using:\nNumpy (linear algebra)\nPandas (data manipulation)\nSeaborn (data visualization)\nScikit-learn (optimized machine learning models)\nKeras (neural networks)\nXGBoost (gradient-boosted decision trees)\nHere are the most important ML models you'll use:\nLinear Regression\nLogistic Regression\nRandom Forrest Decision Trees\nGradient-Boosted Decision Trees\nNeural Networks\nNot convinced yet? By taking our course, you'll also have access to sample code for all major supervised machine learning models. Use them how you please!\nStart your data science journey today with The Complete Intro to Machine Learning with Python.",
      "target_audience": [
        "Anyone interested in machine learning, data science, and artificial intelligence. No experience required."
      ]
    },
    {
      "title": "Generative AI & LLMs: Foundations to Hands-on Development",
      "url": "https://www.udemy.com/course/generative-ai-llms-foundations-to-hands-on-development/",
      "bio": "Generative AI, Large Language Models(LLMs), Prompt Engineering, Fine-Tune AI Model,GPT models, Hugging Face,Google Colab",
      "objectives": [
        "Understand Large Language Models (LLMs): Explore the evolution, architectures, and advancements in LLMs, including Transformers and self-attention mechanisms.",
        "Master Prompt Engineering: Learn how to craft effective prompts to optimize AI-generated outputs and improve performance.",
        "Fine-Tune AI Models: Develop expertise in fine-tuning LLMs using Python and Hugging Face to tailor models for specific applications.",
        "Implement Ethical AI Practices: Gain awareness of the ethical and societal implications of AI, including bias and transparency.",
        "Develop AI-Powered Applications: Build a chatbot, a text summarizer, and a fine-tuned model through hands-on projects.",
        "Leverage AI Toolkits and Frameworks: Utilize industry-standard tools such as GPT-2, Hugging Face, and Python libraries to create Generative AI solutions."
      ],
      "course_content": {
        "Introduction to Large Language Models (LLMs)": [
          "Introduction to Large Language Models (LLMs)"
        ],
        "Understanding Language AI": [
          "Understanding Language AI"
        ],
        "Major Advancements and Technologies": [
          "Major Advancements and Technologies"
        ],
        "The Rise of Attention Mechanisms": [
          "The Rise of Attention Mechanisms"
        ],
        "Categories of LLMs Representation and Generative Models": [
          "Categories of LLMs Representation and Generative Models"
        ],
        "Applications and Ethical Considerations": [
          "Applications and Ethical Considerations"
        ],
        "Conclusion and Future Directions": [
          "Conclusion and Future Directions"
        ],
        "Hands-On Project 1 - Develop a Generative AI chatbot in Python": [
          "Develop a Generative AI chatbot in Python",
          "Overview of Cutting-edge Tools"
        ],
        "Quiz 1": [
          "Quiz"
        ],
        "Introduction to Mastering Prompt Engineering for Generative AI": [
          "Introduction Mastering Prompt Engineering for Generative AI"
        ]
      },
      "requirements": [
        "Basic Python Programming Knowledge (for the hands-on exercise)",
        "No Prior Knowledge of LLMs Required"
      ],
      "description": "The rise of Generative AI has transformed the field of artificial intelligence, with Large Language Models (LLMs) leading the way in applications such as chatbots, text generation, and automated summarization. \"Generative AI & LLMs: Foundations to Hands-on Development\" is a hands-on, comprehensive course designed to equip learners with in-depth knowledge of LLMs, prompt engineering, and model fine-tuning. Through theoretical insights and practical labs, participants will gain expertise in developing AI-powered applications using Python and Hugging Face.\nThis course covers essential concepts, including the evolution of LLMs, attention mechanisms, ethical considerations, and best practices. It also delves into prompt engineering techniques and fine-tuning methodologies to customize models for specific tasks. With real-world projects and hands-on labs, learners will apply their knowledge by building AI chatbots, text summarizers, and fine-tuned models.\nWhether you're a student, developer, researcher, or business professional, this course offers invaluable insights and actionable knowledge that will empower you to harness the transformative potential of LLMs. By the end of this course, you will be well-equipped to develop, optimize, and fine-tune Generative AI applications, making them valuable contributors in the AI-driven world.\nTake the first step toward becoming a proficient AI practitioner and join the forefront of innovation in Language AI!",
      "target_audience": [
        "Students and Educators",
        "Data Scientists and AI Enthusiasts",
        "Professionals Transitioning into AI",
        "ChatGPT and Similar Models Enthusiasts",
        "Python Developers Curious about Generative AI"
      ]
    },
    {
      "title": "Big Data & Business Intelligence",
      "url": "https://www.udemy.com/course/big-data-business-intelligence/",
      "bio": "Everything You Need To Know About Big Data and Business Intelligence for the Modern Workplace",
      "objectives": [
        "Describe the purpose and uses of Business Intelligence & Big Data in the business world today",
        "• Identify the terminology used in Big Data and quantitative analysis programs in general",
        "• Build a dataset based on gathering data from multiple sources and merging those databases into a single unified set",
        "• Clean a database through automated methods like winsorizing and evaluation of univariate metrics to determine accuracy of inputs",
        "• Identify key risk issues involved in Big Data and the role that information governance plays."
      ],
      "course_content": {
        "Introduction to Big Data and Business Intelligence": [
          "Introduction",
          "Introduction to Big Data and Business Intelligence Part 2",
          "Introduction to Big Data and Business Intelligence Part 3",
          "Introduction to Big Data and Business Intelligence Part 4",
          "Introduction to Big Data and Business Intelligence Part 5",
          "Introduction to Big Data and Business Intelligence Part 6",
          "Introduction to Big Data and Business Intelligence Part 7"
        ],
        "Data Collection and Cleaning": [
          "Data Collection and Cleaning Part 1",
          "Data Collection and Cleaning Part 2",
          "Data Collection and Cleaning Part 3",
          "Data Collection and Cleaning Part 4",
          "Data Collection and Cleaning Part 5",
          "Data Collection and Cleaning Part 6"
        ],
        "Structuring Data": [
          "Structuring Data Part 1",
          "Structuring Data Part 2",
          "Structuring Data Part 3",
          "Structuring Data Part 4",
          "Structuring Data Part 5",
          "Structuring Data Part 6"
        ],
        "Fundamentals of Data Analysis": [
          "Fundamentals of Data Analysis Part 1",
          "Fundamentals of Data Analysis Part 2",
          "Fundamentals of Data Analysis Part 3",
          "Fundamentals of Data Analysis Part 4",
          "Fundamentals of Data Analysis Part 5",
          "Fundamentals of Data Analysis Part 6",
          "Fundamentals of Data Analysis Part 7"
        ],
        "Using Data Analysis": [
          "Using Data Analysis Part 1",
          "Using Data Analysis Part 2",
          "Using Data Analysis Part 3",
          "Using Data Analysis Part 4",
          "Using Data Analysis Part 5",
          "Using Data Analysis Part 6"
        ],
        "Exercises and Cases": [
          "Case 1",
          "Case 2",
          "Basics of Business Intelligence Analysis Exercise"
        ]
      },
      "requirements": [
        "You should be familiar with basic statistics and basic business concepts"
      ],
      "description": "This course is broken up into four modules.\n\nThe first module will prepare participants to begin business intelligence projects at their own firm. The focus of the course is a hands-on approach to gathering and cleaning data. After taking this course, participants will be ready to create their own databases or oversee the creation of databases for their firm. The focus in this course is on “Big Data” datasets containing anywhere from tens of thousands to millions of observations. While the tools used are applicable for smaller datasets of a few hundred data points, the focus is on larger datasets. The course also helps participants with no experience in building datasets to start from scratch. Finally, the course is excellent for users of Salesforce, Tableau, Oracle, IBM, and other BI software packages since it helps viewers see through the “black box” to the underlying mechanics of Business Intelligence practices.\nThe second module will prepare participants to begin business intelligence projects at their own firm. The focus of the course is a hands-on approach to structuring data including generating new variables based on comparative and relative metrics. The structuring of these variables will be done in Excel, SAS, and Stata to give viewers a sense of familiarity with a variety of different software package structures. The focus in this course will be on financial data though the techniques are also applicable to more general forms of data like that used in marketing or management analyses.\nThe third module will prepare participants to begin running data analysis on databases. Both univariate and multivariate analysis will be covered with a particular focus on regression analysis. Regression analysis will be done in Excel, SAS, and Stata to give viewers a sense of familiarity with a variety of different software package structures. The focus in this course will be on financial data though the techniques are also applicable to more general forms of data like that used in marketing or management analyses.\nThe fourth and final module will prepare participants to review, analyze, and make decisions based on results from business intelligence projects. The course will cover reading and interpreting regression analysis. The course will also give participants the skills to critically analyze and identify potential limitations on analysis. The course will also cover predicting changes in business outcomes based on analysis and identifying the level of certainty or confidence around those predictions. This paves the way for future detailed courses in predictive analytics.",
      "target_audience": [
        "This course will provide an introduction to the practices and procedures involved with Business Intelligence and applied Big Data analysis. Participants will learn what Big Data is and why it is being discussed as a revolutionary approach to many aspects of business and finance. Participants will get hands-on experience with gathering, merging, and cleaning Big Data databases. The program will also entail critical evaluation of existing datasets to check for potential problems or concerns over data integrity. The course will also include a discussion of information governance."
      ]
    },
    {
      "title": "SAP Basics : Reporting Tools",
      "url": "https://www.udemy.com/course/sap-basics-reporting-tools/",
      "bio": "Transform Data into Decisions: Mastering SAP Reporting Tools",
      "objectives": [
        "Learners will gain in-depth knowledge of the various SAP reporting tools available, including their capabilities and applications in business analytics.",
        "Students will learn how to efficiently identify transaction tables within SAP, a critical skill for effective data extraction and report generation.",
        "Enable learners to create, modify, and manage quick reports using SAP Quick Viewer, facilitating efficient data analysis and swift decision-making.",
        "Develop the ability to create, customize, and execute queries using SAP Query, enhancing their capabilities in complex data manipulation and reporting."
      ],
      "course_content": {
        "Embark on Your SAP Reporting Tools Journey": [
          "Your Expert Guide in SAP Reporting",
          "Mapping Out Our Learning Journey"
        ],
        "Diving Deep into SAP Reporting Tools": [
          "Unveiling SAP Reporting Capabilities",
          "Demonstration: SAP Reporting Tools in Action",
          "Decoding Transaction Tables for Reporting",
          "Hands-On: Navigating Transaction Tables",
          "Assessing Your SAP Reporting Toolkit"
        ],
        "Mastering Quick Reporting with SAP Quick Viewer": [
          "The Power of SAP Quick Viewer",
          "Building Your First Quick Report",
          "Quick Viewer Proficiency Check"
        ],
        "Advanced Reporting with SAP Query": [
          "Crafting Detailed Reports with SAP Query",
          "Exercise: Designing a Custom SAP Query",
          "Testing Your SAP Query Skills"
        ],
        "Enhancing Reporting with Infoset Query": [
          "Exploring the Infoset Query for Advanced Reporting",
          "Infoset Query Knowledge Evaluation"
        ],
        "Consolidating Your SAP Reporting Knowledge": [
          "Key Transactions for SAP Reporting",
          "Wrapping Up Our SAP Reporting Adventure",
          "Your Final Mastery Check"
        ]
      },
      "requirements": [
        "Basic Understanding of SAP Interface: Familiarity with navigating the SAP interface will be beneficial.",
        "Foundational Knowledge in Database Management: Understanding basic database concepts and structures is recommended.",
        "No Previous Experience Required: This course is designed to accommodate learners with varying levels of SAP experience, from beginners to those looking to expand their reporting skills."
      ],
      "description": "Welcome to our immersive course designed to master SAP Reporting Tools. As businesses increasingly rely on data-driven decisions, the ability to swiftly navigate, analyze, and report data within the SAP environment becomes indispensable. This course is meticulously crafted to guide you through the complexities of SAP's reporting capabilities, ensuring you emerge with a robust understanding and practical skills applicable in any SAP context.\nStarting with an introduction to the landscape of SAP reporting tools, you'll gain insights into the foundational elements that make SAP a powerful platform for data reporting and business intelligence. You'll explore the nuances of transaction tables, learning how to identify and extract the data essential for creating meaningful reports.\nAs the course progresses, you'll dive into SAP Quick Viewer, mastering the art of generating quick reports that facilitate efficient data analysis and swift decision-making. Further, we'll explore SAP Query, a more advanced tool allowing for the customization of complex reports tailored to specific business needs. Through hands-on demos and exercises, you'll experience the creation of these reports first-hand, solidifying your understanding and skills.\nInfoset Query introduces you to even more sophisticated reporting techniques, enabling comprehensive analyses by aggregating data from multiple sources. This section will expand your capability to handle complex reporting scenarios, making you a valuable asset to any SAP-powered organization.\nBy the end of this course, not only will you be proficient in using SAP's key reporting tools, but you'll also understand how to manage and analyze data efficiently, create impactful reports, and utilize advanced reporting features. Whether you're a beginner looking to carve a niche in the SAP world or an experienced professional aiming to enhance your reporting skills, this course is designed to elevate your expertise to new heights, preparing you for the challenges of tomorrow's data-driven business landscape.",
      "target_audience": [
        "SAP End Users: Individuals who regularly interact with SAP in their organizational roles and wish to improve their efficiency and understanding of reporting tools.",
        "Business Analysts: Professionals seeking to leverage SAP reporting tools for enhanced business analytics and decision support.",
        "SAP Consultants and Developers: Those looking to expand their skill set in SAP reporting to offer more comprehensive solutions to clients or within their organizations.",
        "Data Enthusiasts: Anyone with an interest in data analysis, reporting, and business intelligence within the SAP ecosystem."
      ]
    },
    {
      "title": "Business Statistics Fundamentals",
      "url": "https://www.udemy.com/course/business-statistics-fundamentals/",
      "bio": "Learn everything you need to know about statistics used in businesses",
      "objectives": [
        "Get familiar with almost all important concepts of business statistics",
        "Master statistical tools which can be used for data analysis",
        "Master the art of presenting data using different tools"
      ],
      "course_content": {
        "Course Introduction": [
          "Course Overview"
        ],
        "Introduction to Statistics": [
          "Definition, Types and Importance (1)",
          "Definition, Types and Importance (2)",
          "Types of Data",
          "Important Terms (1)",
          "Important Terms (2)",
          "Basics of Business Statistics"
        ],
        "Graphical Representation of Data": [
          "Need for Graphical Representation",
          "Bar and Column Charts",
          "Line and Area Charts",
          "Pie Charts",
          "Scatter Plots and Bubble Diagrams",
          "Some Other Graphical Representations",
          "Frequency Distribution Plots",
          "Graphical Representation Using MS Excel",
          "Excel Exercise 1: Bar and Column Charts",
          "Excel Exercise 2: Line and Area Charts",
          "Excel Exercise 3: Scatter Diagram and Bubble Plots",
          "Excel Exercise 4: Pie Charts",
          "Excel Exercise 5: Stock Plots",
          "Excel Exercise 6: Radar Charts",
          "Excel Exercise 7: Histograms",
          "Graphical Representation of Data"
        ],
        "Measures of Central Tendency": [
          "What is Central Tendency?",
          "Arithmetic Mean (1)",
          "Arithmetic Mean (2)",
          "Geometric and Harmonic Means",
          "Median",
          "Quartiles and Percentiles",
          "Mode",
          "Calculating Central Tendency with Google Sheet",
          "Measures of Central Tendency"
        ],
        "Measures of Dispersion": [
          "Introduction",
          "Important Notes About Lecture 31",
          "Quartile Deviation",
          "Mean Deviation",
          "Standard Deviation",
          "Calculating Dispersion with Google Sheets",
          "Measures of Dispersion"
        ],
        "Skewness and Kurtosis": [
          "What are Skewness and Kurtosis?",
          "Moments",
          "Measures of Skewness (1)",
          "Measures of Skewness (2)",
          "Measures of Kurtosis",
          "Calculating Skewness and Kurtosis with Google Sheet",
          "Skewness and Kurtosis"
        ],
        "Data Analysis Exercise Part 1 : Global Economy": [
          "Excel Exercise: Univariate Analysis of World Economy"
        ],
        "Bivariate Data Analysis": [
          "Introduction",
          "Covariance and Correlation (1)",
          "Covariance and Correlation (2)",
          "Linear Regression",
          "Other Regression Models",
          "Interpolation and Extrapolation (1)",
          "Interpolation and Extrapolation (2)",
          "Bivariate Data Analysis"
        ],
        "Data Analysis Exercise Part 2 : Global Economy": [
          "Excel Exercise: Bivariate Analysis of World Economy",
          "Bivariate Analysis with Google Sheets"
        ],
        "Index Numbers": [
          "Introduction",
          "Construction of Index Numbers",
          "Tests of Adequacy",
          "Fixed Base and Chain Base Indices",
          "Deflating, Base Shifting and Splicing",
          "Index Numbers"
        ]
      },
      "requirements": [
        "Basic algebra"
      ],
      "description": "Data has become the most powerful tool for businesses today. Use of data has become so pervasive that you will hardly come across a sector or field where data is not used. So, whether you are a working professional, student or entrepreneur, understanding data and statistics is not an optional subject, but a vital ingredient of your success in career.\nThe objective of this course is to develop a strong foundation of all the important concepts of business statistics. Every concept is thoroughly explained with the help of explanatory videos and step by step calculation of example data. Also, you will get a feel of real world data analysis from the MS Excel exercises. You can test yourself with the quiz after every chapter. Not only that, you can also download the PDF files for chapter summaries which can be used as ready reckoner.\nThis course is divided into 11 chapters. It starts from understanding the basic concepts of statistics like definition, types of data, branches of statistics etc. Second chapter discusses the graphical representation of data where you will learn about different types of graphs and diagrams and also which is to be used for what kind of data. In the next few chapters, we discuss about various data analysis tools, descriptive and inferential statistics, probability, index numbers and statistical quality control.",
      "target_audience": [
        "Business professionals who want to learn different concepts of data analysis and presentation",
        "Students of statistics"
      ]
    },
    {
      "title": "Microsoft Fabric Masterclass: A Unified Data &Analytics Tool",
      "url": "https://www.udemy.com/course/microsoft-fabric-masterclass-a-unified-data-and-analytics-tool/",
      "bio": "All in one tool for Data Engineering, Data Factory, Data Science, Data Warehouse, Real-Time Analytics, and Power BI !",
      "objectives": [
        "Microsoft Fabric and its fundamentals",
        "Components of Microsoft Fabric",
        "Creating a Lakehouse in Fabric and using it for semantic Modeling",
        "Step by Step guide on how to orchestrate a Data Pipeline",
        "Writing DAX, creating Activities, SQL Views & much more..."
      ],
      "course_content": {
        "Introduction to Microsoft Fabric": [
          "Introduction to Microsoft Fabric - Features & Use Cases",
          "Summarizing Microsoft Fabric",
          "Understanding the need and uses of Microsoft Fabric",
          "Components of Microsoft Fabric"
        ],
        "Exploring Microsoft Fabric": [
          "Navigating in Fabric UI",
          "Fabric Settings and User Roles",
          "Using Help and Support in Fabric",
          "Workspaces in Fabric - Creating and Managing Workspaces"
        ],
        "Understanding & creating a Data Lakehouse in Microsoft Fabric": [
          "Introduction to Lakehouse",
          "Creating a Lakehouse in a Workspace, Ingesting and Preparing Data",
          "Build Report"
        ],
        "Exploring features of Microsoft Fabric in Power BI - Step by Step Tutorial": [
          "Create a Lakehouse",
          "Add Data Destination",
          "Orchestrate a Data Pipeline",
          "Semantic Model in Lakehouse",
          "Writing DAX Expressions",
          "Create a SQL View",
          "Creating a Report with AutoCreate",
          "Summary and Next Steps"
        ],
        "An End to End Data Science Project in MS Fabric": [
          "Introduction and Setting up Fabric",
          "Adding a Lakehouse",
          "Ingest data into the Lakehouse using Apache Spark",
          "Exploring and Visualizing data using Microsoft Fabric Notebooks",
          "Performing data cleansing and preparation using Apache Spark",
          "Train and register machine learning models in Microsoft Fabric",
          "Perform batch scoring and save predictions to the Lakehouse",
          "Create a Power BI report to Visualize Predictions"
        ],
        "Data Activator Experience in Microsoft Fabric": [
          "Data Activator - Introduction",
          "Data Activator - Core Concepts",
          "Data Activator - Getting Data from PowerBI",
          "Data Activator - Step by Step process to create a Trigger in Data Activator"
        ],
        "Exploring Data Factory in Microsoft Fabric": [
          "Data Factory - Introduction",
          "Data Factory - Creating a Data Pipeline",
          "Data Factory - Creating a Data Flow Gen2"
        ],
        "Closing Notes": [
          "MS Fabric Learning & Other Important Resources",
          "Closing Video"
        ]
      },
      "requirements": [
        "No experience needed, we will learn everything from the scratch !"
      ],
      "description": "At the Microsoft Build 2023 conference, Microsoft unveiled its latest product – Microsoft Fabric. This AI-powered platform demonstrates the company’s commitment in revolutionizing the data analytics solutions. With Fabric, Microsoft aims to bring together various elements of data analytics, including compute, storage, analytics stack, governance and business models, into a cohesive and integrated solution.\nThis 4.5 hour long, very comprehensive and detailed Microsoft Fabric course will help you to become a Data Analytics / Visualization Expert and will enhance your skills by offering you comprehensive knowledge, and the required hands-on experience on this widely used Cloud based end to end Analytics tool, by solving real-time industry-based projects.\n\nTop Reasons why you should learn Microsoft Fabric :\nMicrosoft Fabric is a combination of all the #1 cloud based Data Analytics tools from Microsoft that are used industry wide.\nThe demand for data professionals is on the rise. This is one of the most sought-after profession currently in the lines of Data Science / Data Engineering / Real Time Analytics.\nThere are multiple opportunities across the Globe for everyone with this skill.\nThis is a new skill that has a very few expert professionals globally. This is the right time to get started and learn Microsoft Fabric.\nMicrosoft Fabric has a small learning curve and you can pick up even advanced concepts very quickly.\nYou do not need high configuration computer to learn this tool. All you need is any system with internet connectivity and you can practice Fabric within your browser, no installation required.\nTop Reasons why you should choose this Course :\nThis course is designed keeping in mind the students from all backgrounds - hence we cover everything from basics, and gradually progress towards advanced topics.\nCase Studies and Live Examples of all topics.\nDownloadable datasets to practice along.\nLinks to support portal, documentation and communities.\nAll Doubts will be answered.\nNew content added regularly and useful educational emails are sent to all students.\nMost Importantly, Guidance is offered beyond the Tool - You will not only learn the Software, but important Data & Analytics principles.\nA Verifiable Certificate of Completion is presented to all students who undertake this Microsoft Fabric course.",
      "target_audience": [
        "Microsoft Products and Cloud Computing professionals and enthusiasts",
        "Data Engineers, Data Analysts, Power BI Developers who want to learn how to use Microsoft Fabric to build end-to-end data analytics solutions.",
        "Students pursuing their Bachelors / Masters in Computer Science / Business Analytics who would like to upskill themselves",
        "Data enthusiasts who would love to learn new technologies",
        "Anybody looking to upskill to a technology in demand that pays well"
      ]
    },
    {
      "title": "Linear Regression: Absolute Fundamentals",
      "url": "https://www.udemy.com/course/machine-learning-linear-regression-absolute-fundamentals/",
      "bio": "Explore COVID-19 positive case prediction with scikit-learn's Linear Regression in Python.",
      "objectives": [
        "Machine Learning and Linear Regression: Gain insights into the world of Machine Learning, with a focus on Linear Regression.",
        "Fundamentals of Machine Learning: Grasp the essential concepts and principles that underpin machine learning algorithms.",
        "Starting with Data Science in Python: Learn how to initiate your journey into Data Science using Python as a versatile tool.",
        "Regression Mathematics: Dive into the mathematical foundations of regression analysis, a key technique in predictive modeling"
      ],
      "course_content": {
        "Machine Learning Fundamentals and Linear Regression": [
          "Introduction to Machine Learning",
          "Understanding Linear Regression through graphs",
          "Demand vs Price Problem to understand Linear Regression",
          "Introduction to Optimizers",
          "The Gradient Descent Algorithm",
          "Downloading the dataset and importing Libraries",
          "Reading the dataset",
          "Cleaning the data",
          "The Model",
          "Visualising the data",
          "Overfitting and Underfitting",
          "Concluding Remarks",
          "[UPDATE] - Why does Linear Regression fail for a classification problem"
        ]
      },
      "requirements": [
        "Yes, A basic knowledge in Python 3 is preferred for technical part."
      ],
      "description": "Greetings, everyone! We're excited to announce that our \"Machine Learning Absolute Fundamentals for Linear Regression\" course is now open to all students. This course is specifically designed for novice Python developers who are eager to embark on their journey into the world of machine learning. In this instructional module, we will dive into the practical application of a linear regression model, harnessing the power of the Python scikit-learn library, to predict the total number of COVID-19 positive cases within a specific Indian state.\nBy the end of this course, you will have the knowledge and skills to:\nGain a fundamental understanding of what machine learning is, demystifying its core concepts and principles.\nDefine what a dataset entails and comprehend its significance in the context of machine learning.\nExplore the pivotal functions and roles of machine learning in various domains and applications.\nAttain a comprehensive grasp of the concept of linear regression, a foundational machine learning technique for predictive modeling.\nElaborate on the cost function and delve into the concept of the line of greatest fit, often measured by the Mean Squared Error (MSE).\nLearn how to effectively manipulate and preprocess your dataset using the versatile pandas library functions, ensuring that it's ready for machine learning.\nMaster the art of partitioning your data into training and testing subsets, a critical step in model evaluation.\nHarness the power of Scikit-Learn to create a robust linear regression model and efficiently train it on your dataset.\nEvaluate the performance of your model and make data-driven predictions, enabling you to foresee future COVID-19 positive cases with confidence.\nDevelop your data visualization skills using Matplotlib, allowing you to communicate your findings effectively through compelling graphical representations.\nDiving deeper into the realm of linear regression, we find that this technique leverages linear predictor functions to model relationships within data. The essence of linear regression lies in the estimation of unknown parameters from the available dataset. These models, aptly named linear models, offer valuable insights into the conditional mean of the response variable. Typically, this conditional mean is viewed as an affine function of the explanatory variables, commonly referred to as predictors. Occasionally, in specific applications, other quantiles such as the conditional median are employed.",
      "target_audience": [
        "Beginner Python developers who are curious about Machine Learning"
      ]
    },
    {
      "title": "Creating Online Dashboards & Story Maps using arcGIS Online",
      "url": "https://www.udemy.com/course/creating-online-dashboards-and-storymaps-using-arcgis-online/",
      "bio": "Master in Geospatial Data Visualization and Building Operational Dashboards plus Story Maps using ArcGIS Online",
      "objectives": [
        "Students will upload geospatial data to ArcGIS Online and create captivating maps, dashboards, and story maps. Become a skilled geospatial storyteller!",
        "Students will learn to fetch data from Living Atlas and create captivating dashboards.",
        "Students will also learn about two powerful technologies of ArcGIS: Operational Dashboards and Story Maps.",
        "In this course, students will learn how to publish geographic data in CSV format to ArcGIS Online and create operational dashboards."
      ],
      "course_content": {},
      "requirements": [
        "No prerequisites are required for this course. Once enrolled, students will learn everything step by step, making it accessible to all learners regardless of their prior knowledge or experience.",
        "Exactly! To participate in this course, all you need is a stable internet connection and a computer."
      ],
      "description": "Welcome to 'Creating Online Dashboards & Story Maps using ArcGIS Online,' the ultimate masterclass in geospatial data visualization and building operational dashboards and story maps using the powerful software, ArcGIS Online.\nThis comprehensive step-by-step course is designed to empower you with the skills to transform your geospatial data into captivating and informative visualizations. Whether you're a seasoned GIS professional or a newcomer to the world of mapping, this course will take you on an exciting journey through the realm of data-driven storytelling.\nIn the first section, we'll start by guiding you through the process of creating your ESRI ArcGIS Online account and signing in. You'll gain a thorough understanding of all the buttons and menus within the platform, setting a solid foundation for your dashboard creation. We'll delve into leveraging the existing layers within the Living Atlas Server, showing you how to import and manipulate them seamlessly in ArcGIS Online. To add relevance to your visualizations, we'll walk you through the process of importing Covid-19 layers from the server and demonstrate how to integrate them into your interactive dashboards. Prepare to be amazed as we unravel the secrets of creating various elements, including line charts, bar charts, pie charts, indicators, gauges, head bars, and sidebars – all essential components of a comprehensive dashboard.\n\n\nIn the second section, you'll learn how to harness the power of your own geospatial data in CSV format. We'll guide you through uploading this data to the ArcGIS Online server and plotting it on a map, adding an extra layer of customization to your visualizations. The magic truly happens when we demonstrate how to seamlessly integrate your custom map into the dashboard. Get ready to elevate your dashboard's performance and functionality as we explore advanced techniques like data filtering based on date.\n\n\nThe third and final section of this course focuses on ArcGIS story maps. We'll cover all the available options and buttons, ensuring you understand the full potential of this engaging storytelling tool. By the end of this course, you'll have the knowledge and hands-on experience to craft captivating story maps that will leave a lasting impact on your audience.\n\n\nThroughout this course, I will be by your side, guiding you every step of the way. With a passion for geospatial data and a commitment to delivering clear, concise, and engaging lessons, I'll equip you with the skills and confidence needed to excel in the world of geospatial data visualization.\nJoin us now and unlock your potential in the realm of geospatial data visualization. Enroll in 'Creating Online Dashboards & Story Maps using ArcGIS Online,' and embark on a transformative learning journey that will elevate your skills and make you a master in data-driven storytelling. Your journey to creating stunning and impactful visualizations begins here!",
      "target_audience": [
        "This course is for Data Scientists, Data Analysts, and individuals working with Spatial Data Analysis and Data Visualization."
      ]
    },
    {
      "title": "Optimization with Excel: Operations Research without Coding",
      "url": "https://www.udemy.com/course/optimization-with-excel-operations-research-without-coding/",
      "bio": "Optimization with Gurobi, CBC, IPOPT. Linear programming, nonlinear, genetic algorithm. Using Excel, without coding",
      "objectives": [
        "Solve optimization problems in a very easy way! Using the Excel along with well-known solvers without coding",
        "Nice introduction on mathematical modeling",
        "Gurobi, CBC, IPOPT, Bonmin, Couenne",
        "LP, MILP, NLP, MILNP",
        "Genetic Algorithm and Vehicle Routing Problem (VRPTW)"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "How to solve Optimization Problems and Limitations of using Excel",
          "Preview of the course"
        ],
        "Introduction to Excel": [
          "Excel - the basics",
          "Sum, If, SumIf, SumIfs",
          "SumProduct",
          "SumProduct with Filters",
          "Vlookup",
          "Replicate and Lock Formulas",
          "Limitations of the standard solver from Excel (we will not use this solver!)"
        ],
        "Introduction to Mathematical Modeling": [
          "What is mathematical modeling?",
          "How we solve optimization problems?",
          "Type of variables and what is parameters, indexes and sets",
          "Objective function and constraints",
          "How to model?",
          "Example 1 - Investment Problem",
          "Example 2 - Investment Problem, nonlinear",
          "Example 3 - Cost of production",
          "Example 4 - Routing problem",
          "Example 5 - Team assignment in a construction company",
          "Example 6 - Team assignment with condition",
          "Example 7 - Job scheduling",
          "Example 8 - Job scheduling with limit",
          "References for VRPTW, Jobshop, and TSP",
          "How to learn more"
        ],
        "Linear Programming (LP) and installation of what you need": [
          "LP - Introduction",
          "Installing OpenSolver",
          "Issues with OpenSolver",
          "LP - Example 1 - Base Case",
          "LP - Example 2 - Power generation",
          "LP - Example 3 - Power generation multiperiod",
          "Installing Gurobi",
          "Academic License for Gurobi [Updates]",
          "Selecting different solvers",
          "Formulas and limits for Excel",
          "LP - Concepts"
        ],
        "Mixed-Integer Linear Programming (MILP)": [
          "MILP - Introduction",
          "MILP - Example 1 - Base Case",
          "MILP - Example 2 - Job Scheduling",
          "MILP - Example 3 - Routing Problem",
          "MILP - Example 3 - Routing Problem - Solution",
          "MILP - Example 4 - Large Routing Problem",
          "MILP - Concepts"
        ],
        "Solver Parameters and Tips": [
          "Defining parameters for the solver",
          "How to speed up the construction of problem?",
          "See the progress of the solver"
        ],
        "Template": [
          "The template [download]",
          "Template - Working with variables",
          "Template - Working with parameters",
          "Template - Working with the objective function",
          "Template - Working with constraints",
          "Example - Job scheduling - 100 jobs in 10 days",
          "Example - Job scheduling - 100 jobs in 10 days - Variables and parameters",
          "Example - Job scheduling - 100 jobs in 10 days - Objective function",
          "Example - Job scheduling - 100 jobs in 10 days - Constraints",
          "Example - Job scheduling - 100 jobs in 10 days - Model and Solution"
        ],
        "NonLinear Programming (NLP)": [
          "NLP - Introduction",
          "NLP - Example 1 - Base Case",
          "NLP - Example 2 - Cosines",
          "NLP - Example 3 - Investment",
          "NLP - Concepts"
        ],
        "Mixed-Integer NonLinear Programing (MINLP)": [
          "MINLP - Introduction",
          "MINLP - Example 1 - Base Case",
          "MINLP - Example 2 - Production Cost",
          "MINLP - Example 2 - Production Cost - Solution"
        ],
        "Genetic Algorithm (GA)": [
          "GA - Introduction",
          "GA - Example 1 - Base Case",
          "GA - Example 2 - Production Cost"
        ]
      },
      "requirements": [
        "Some knowledge in Excel, however, I provide a fast introduction using the basic formulas you need for the course.",
        "Why and where to use optimization",
        "You do NOT need to know how to code in this course (we are NOT gonna use any programming language)"
      ],
      "description": "Operational planning and long term planning for companies are more complex in recent years. Information changes fast, and the decision making is a hard task. Therefore, optimization algorithms (operations research) are used to find optimal solutions for these problems. Professionals in this field are one of the most valued in the market.\nAnd if you do not known how to code and/or if you wish to solve optimization problems using Excel, this is a perfect course for you.\nIn this course you will learn what is necessary to solve problems applying (without any coding):\nLinear Programming (LP)\nMixed-Integer Linear Programming (MILP)\nNonLinear Programming (NLP)\nMixed-Integer Linear Programming (MINLP)\nGenetic Algorithm (GA)\nAnd how to solve Vehicle Routing Problems with Time Window  (VRPTW)\n\n\nThe following solvers will be explored: Gurobi – CBC – IPOPT – Bonmin - Couenne\nWe will also use CPLEX, but a limited version from NEOS server.\nAlso, I provide workbooks for you that will facilitate to solve these problems. GA and VRPTW will be solved using workbooks that are very easy to work with.\n\n\nThe course has a nice introduction on mathematical modeling and the main formulas from Excel. Thus, you can easily follow the classes.\n\n\nIn addition to the classes and exercises, the following problems will be solved step by step:\nRoute optimization problem\nMaximize the revenue in a rental car store\nMaintenance planning problem\nOptimal Power Flow: Electrical Systems\nMany other examples, some simple, some complexes, including summations and many constraints.\n\n\n\n\nYou should NOT solve optimization problems in Excel for:\nComplex problems that requires decompositions and iterations. Since we do not use any programming language in the course, our approach would not be recommended to solve problems that requires iterations, such as Benders.\nOperational problems for real-time execution.\nLarge problems that require fast solutions. The approach from the course does not have a limitation, but large problems may take a while to be converted from the Excel's formulas to the solver.\nSolve multi-objective problems.\n\n\nAttention:\nThe approach in this course is NOT using the standard solver from Excel, our approach here has NO limitations on the number of variables or constraints.\nI do NOT show you how to install Excel. But I teach how to install the required tools.\nTo follow the course you will need Excel installed on your computer. Moreover, the tools from the courses have been tested in Windows and MAC only.\nThe classes use examples that are created step by step, from the business concept to the resolution.\n\n\nI hope this course can help you in your carrier. Yet, you will receive a certification from Udemy.\n\n\nOperations Research | Operational Research | Mathematical Optimization",
      "target_audience": [
        "Undergrad, graduation, master program, and doctorate students",
        "If you want or need to solve optimization problems but is not very good with programming languages",
        "People interested in solving complex problems"
      ]
    },
    {
      "title": "Machine learning for chemical industries to boost profit",
      "url": "https://www.udemy.com/course/learn-machine-learning-to-apply-it-in-real-life-industries/",
      "bio": "Learn to create AI application from Industry experts. Special application for chemical , energy and allied industries",
      "objectives": [
        "Master Machine Learning with matlab",
        "Develop intuition for various Machine Learning models",
        "Make accurate predictions",
        "Conduct powerful analysis",
        "Build robust Machine Learning models",
        "Create added value for businesses",
        "Apply Machine Learning for personal purposes",
        "Choose appropriate Machine Learning models for different types of problems",
        "Build an arsenal of powerful Machine Learning models and learn how to combine them to solve any problem.",
        "Develop skills to solve real life industry problem through machine learning"
      ],
      "course_content": {
        "Introduction": [
          "Course Overview"
        ],
        "Introduction to machine learning": [
          "What is machine learning?",
          "Type of machine learning",
          "Real life example of machine learning",
          "Elements of machine learning"
        ],
        "Steps in Machine learning": [
          "Steps in machine learning"
        ],
        "Data Preprocessing": [
          "what is data preprocessing?",
          "Outlier detection",
          "Case study of outlier detection",
          "Missing value",
          "Encoding the data"
        ],
        "Overview of model building and model evaluation": [
          "Overview of regression",
          "Model evaluation and performnace matrices",
          "When and how to use the evalaution matrices",
          "Overfitting and Underfitting",
          "Bias and variance"
        ],
        "Walk through a complete case study of Bio Reactor model building by ML": [
          "BioReactor Case study part1",
          "BioReactor Case study part2",
          "BioReactor Case study part3",
          "BioReactor Case study part4"
        ],
        "Building Machine learning models": [
          "Overview of Regression learner app",
          "Steps to build a ML model",
          "Import and prepare data",
          "Select the model algorithm",
          "Run and evaluate the model",
          "Visualize the result to gain insights"
        ],
        "Real life case study to build softsensor for distillation column": [
          "Distillation column casestudy part1",
          "Distillation column casestudy part2",
          "Distillation column casestudy part3"
        ],
        "Case study toi build MLmodel of catalytic reactor": [
          "Casestudy of catalytic reactor part 1",
          "Casestudy of catalytic reactor part 2",
          "Casestudy of catalytic reactor part 3"
        ],
        "Build ML model for running chemical plant": [
          "case study for chemical plant part 1.",
          "case study for chemical plant part 2"
        ]
      },
      "requirements": [
        "No programming experience needed.",
        "This course will build the skill from scratch",
        "Elementary knowledge of matlab is desirable but not compulsory."
      ],
      "description": "Are you ready to take your machine learning skills to the next level? Look no further than our comprehensive online course, designed to take you from beginner to advanced levels of machine learning expertise. Our course is built from scratch, with a focus on real-life case studies from industry and hands-on projects that tackle real industry problems.\nWe know that machine learning can be a complex field, which is why our course covers all major algorithms and techniques. Whether you're looking to improve your regression models, build better classifiers, or dive into deep learning, our course has everything you need to succeed. And with our emphasis on practical, hands-on experience, you'll be able to apply what you learn to real-world scenarios right away.\nBut what sets our course apart from the rest? For starters, our focus on real-life case studies means that you'll be learning from the experiences of industry professionals who have already solved complex problems using machine learning. This means that you'll be able to see firsthand how machine learning can be applied to a variety of industries, from chemcal,petrochemcal to petroleum refnery.\nIn addition, our hands-on projects are specifically designed to tackle real industry problems, so you'll be able to build your portfolio with projects that have practical applications in the workforce. And with our expert instructors available to answer your questions and provide guidance every step of the way, you'll have all the support you need to succeed in this exciting field.\nSo if you're ready to take your machine learning skills to the next level, enroll in our comprehensive online course today. You'll gain the knowledge and practical experience you need to succeed in this high-demand field, and you'll be on your way to building a rewarding career in no time.\nThe course was created by a Data Scientist and Machine Learning expert from industry to simplify complex theories, algorithms, and coding libraries.\nThe uniqueness of this course is that it helps you develop skills to build machine learning applications for complex industrial problems.\nMoreover, the course is packed with practical exercises that are based on real-life case studies. So not only will you learn the theory, but you will also get lots of hands-on practice building your own models.\nWith over 1000 worldwide students, this course guides you step-by-step through the world of Machine Learning, improving your understanding and skills.\nYou can complete the course in matlab\n\n\nThis course is designed to take you from the basics of machine learning to the advanced level of building machine learning models for real-life problems. Here's a brief overview of what you can expect to learn:\nIntroduction to machine learning: In this section, you'll learn about the types of machine learning, the use of machine learning, and the difference between human learning and machine learning. You'll also gain insight into how machines learn and the difference between AI, machine learning, and deep learning.\nOverview of different types of machine learning: You'll explore real-life examples of machine learning and the different elements of machine learning.\nSteps in machine learning: You'll dive into the steps involved in the machine learning process, from data pre-processing to building machine learning models.\nData pre-processing: In this section, you'll learn how to detect outliers, handle missing values, and encode data to prepare it for analysis.\nOverview of regression and model evaluation: You'll learn about different model evaluation matrices, such as MAE, MSE, RMSE, R square, and Adjusted R square, and how to interpret them. You'll also learn about overfitting and underfitting.\nCase study of Bio reactor modelling: You'll walk through a complete case study of building a machine learning model for bio reactor modelling.\nBuilding machine learning models: You'll learn how to import and prepare data, select the model algorithm, run and evaluate the model, and visualize the results to gain insights.\nDetail of modelling by following algorithm: You'll dive into different modelling algorithms, such as linear regression models, decision trees, support vector machine regression, Gaussian process regression model, kernel approximation models, ensembles of trees, and neural networks.\nReal-life case study to build soft-sensor for distillation column: You'll explore a real-life case study of building a soft-sensor for a distillation column.\nCase study to build an ML model of catalytic reactor: You'll learn about another real-life case study of building an ML model for a catalytic reactor.\nCase study to build an ML model for running plant: You'll explore a case study of building an ML model for a running plant.\nModelling by Artificial Neural Network (ANN): You'll gain insight into artificial neural networks, including ANN learning, training, calculation, and advantages and disadvantages. You'll also explore a case study of ANN.\n\n\nDetail of course:\n1. Introduction to machine learning\n\n\na. What is machine learning(ML)?\nb. Types of machine learning\nc. Use of machine learning\nd. Difference between human learning and machine learning\ne. What is intelligent machine?\nf. Compare human intelligence with machine intelligence\ng. How machine learns?\nh. Difference between AI and machine learning and deep learning\ni. Why it is important to learn machine learning?\nj. What are the various career opportunities in machine learning?\nk. Job market of machine learning with average salary range\n\n\n\n\n2. Overview of different type of machine learning\na. Real Life example of machine learning\nb. Elements of machine learning\n\n\n3. Steps is machine learning\n4. Data pre-processing\na. Outlier detection\nb. Missing Value\nc. Encoding the data\n\n\n5. Overview of regression and model evaluation\na. Model evaluation matrices, eg. MAE,MSE,RMSE,R square, Adjusted R square\nb. Interpretation of these performance matrices\nc. Difference between these matrices\nd. Overfitting and under fitting\n\n\n6. Walk through a complete case study of Bio reactor modelling by machine learning algorithm\n\n\n7. Building machine learning models\na. Overview of regression learner in matlab\nb. Steps to build a ML Model\nc. Import and Prepare data\nd. Select the model algorithm\ne. Run and evaluate the model\nf. Visualize the results to gain insights\n\n\n8. Detail of modelling by following algorithm\nLinear regression models\nRegression trees\nSupport vector machine regression\nGaussian process regression model\nKernel approximation models\nEnsembles of trees\nNeural Network\n\n\n9. Real life case study to build soft-sensor for distillation column\n10. Case study to build ML model of catalytic reactor\n11. Case study to Build ML model for running plant\n\n\n12. Modelling by Artificial Neural Network (ANN)\na. Introduction of ANN\nb. Understanding ANN learning\nc. ANN Training\nd. ANN Calculation\ne. Advantages and Dsiadvantages of ANN\nf. Case study of ANN\n\n\n\n\n\n\nEach section is independent, so you can take the whole course or select specific sections that interest you.\nYou will gain hands-on practice with real-life case studies and access to matlab code templates for your own projects.\nThis course is both fun and exciting, and dives deep into Machine Learning.\nOverall, this course covers everything you need to know to build machine learning models for real-life problems. With hands-on experience and case studies from industry, you'll be well-prepared to pursue a career in machine learning. Enroll now to take the first step towards becoming a machine learning expert!",
      "target_audience": [
        "Chemcal Engieers, Process engineers woking in chemical plant",
        "Chemical engineerng students with knowledge in math looking to learn Machine Learning",
        "Intermediate level individuals familiar with classical algorithms like linear and logistic regression, but want to explore different fields of Machine Learning",
        "Non-coders interested in Machine Learning and easy application on datasets",
        "College students pursuing a career in Data Science or Chemical engineering",
        "Data analysts seeking to advance their Machine Learning skills",
        "Individuals looking to transition into a career as a Data Scientist",
        "Business owners looking to create added value through powerful Machine Learning tools",
        "Experienced engineers (specially chemical engineers) who worked in industry and want to increase profit of their organization with Machine Learning tools"
      ]
    },
    {
      "title": "Python Programming: Machine Learning, Deep Learning | Python",
      "url": "https://www.udemy.com/course/python-programming-machine-learning-deep-learning-python/",
      "bio": "Python Machine Learning and Python Deep Learning with Data Analysis, Artificial Intelligence, OOP, and Python Projects",
      "objectives": [
        "Fundamental stuff of Python and its library Numpy",
        "What is the AI, Machine Learning and Deep Learning",
        "History of Machine Learning and python programming",
        "Turing Machine and Turing Test",
        "The Logic of Machine Learning such as Machine Learning models and algorithms, Gathering data, Data pre-processing, Training and testing the model etc.",
        "What is Artificial Neural Network (ANN)",
        "Anatomy of NN",
        "Tensor Operations",
        "Python instructors on Udemy specialize in everything from software development to data analysis, and are known for their effective.",
        "Machine learning isn’t just useful for predictive texting or smartphone voice recognition. Machine learning is constantly being applied to new industries.",
        "The Engine of NN",
        "Keras",
        "Tensorflow with python programming",
        "Convolutional Neural Network",
        "Recurrent Neural Network and LTSM",
        "Transfer Learning with python programming",
        "Python instructors on Udemy specialize in everything from software development to data analysis, and are known for their effective.",
        "Python (python programming)",
        "Machine Learning, python machine learning",
        "Deep Learning, python deep learning",
        "Machine Learning with Python",
        "Python Programming",
        "Deep Learning with Python",
        "Python instructors on OAK Academy specialize in everything from software development to data analysis, and are known for their effective.",
        "Python is a general-purpose, object-oriented, high-level programming language.",
        "Python is a multi-paradigm language, which means that it supports many programming approaches. Along with procedural and functional programming styles",
        "Python is a widely used, general-purpose programming language, but it has some limitations. Because Python is an interpreted, dynamically typed language",
        "Python is a general programming language used widely across many industries and platforms. One common use of Python is scripting, which means automating tasks.",
        "Python is a popular language that is used across many industries and in many programming disciplines. DevOps engineers use Python to script website.",
        "Python has a simple syntax that makes it an excellent programming language for a beginner to learn. To learn Python on your own, you first must become familiar",
        "Machine learning describes systems that make predictions using a model trained on real-world data.",
        "Machine learning is being applied to virtually every field today. That includes medical diagnoses, facial recognition, weather forecasts, image processing.",
        "It's possible to use machine learning without coding, but building new systems generally requires code.",
        "Python is the most used language in machine learning. Engineers writing machine learning systems often use Jupyter Notebooks and Python together.",
        "Machine learning is generally divided between supervised machine learning and unsupervised machine learning. In supervised machine learning.",
        "Machine learning is one of the fastest-growing and popular computer science careers today. Constantly growing and evolving.",
        "Machine learning is a smaller subset of the broader spectrum of artificial intelligence. While artificial intelligence describes any \"intelligent machine\"",
        "A machine learning engineer will need to be an extremely competent programmer with in-depth knowledge of computer science, mathematics, data science.",
        "Python Machine Learning and Python Deep Learning with Data Analysis, Artificial Intelligence, OOP, and Python Projects"
      ],
      "course_content": {
        "Intro to Deep Learning with Python programming": [
          "Introduction to Deep Learning with Python",
          "Project Files and Course Documents: Python, machine learning, deep learning, oop",
          "FAQ regarding Python Programming"
        ],
        "Data Science: Setting Up Python for Mac and Windows": [
          "Installing Anaconda Distribution and Python Programming",
          "Overview of Jupyter Notebook and Google Colab"
        ],
        "Fundamentals of Python Programming": [
          "Data Types in Python Programming",
          "Operators in Python Programming",
          "Conditionals in Python",
          "Loops in Python 3",
          "Lists, Tuples, Dictionaries and Sets in Python",
          "Data Type Operators and Methods in Python Programming",
          "Modules in Python 3",
          "Functions in Python",
          "Exercise Analyse in Python Programming",
          "Exercise Solution in Python",
          "quiz"
        ],
        "Object Oriented Programming (OOP)": [
          "Logic of OOP",
          "Constructor of Object Oriented Programming (OOP)",
          "Methods in Object Oriented Programming (OOP)",
          "Inheritance in Object Oriented Programming (OOP)",
          "Overriding and Overloading in Object Oriented Programming (OOP)",
          "object-oriented-programming Quiz"
        ],
        "NumPy Library": [
          "Introduction to NumPy Library",
          "Notebook Project Files Link regarding NumPy Python Programming Language Library",
          "The Power of NumPy",
          "6 Article Advice And Links about Numpy, Numpy Pyhon",
          "Creating NumPy Array with The Array() Function",
          "Creating NumPy Array with Zeros() Function",
          "Creating NumPy Array with Ones() Function",
          "Creating NumPy Array with Full() Function",
          "Creating NumPy Array with Arange() Function",
          "Creating NumPy Array with Eye() Function",
          "Creating NumPy Array with Linspace() Function",
          "Creating NumPy Array with Random() Function",
          "Properties of NumPy Array",
          "Reshaping a NumPy Array: Reshape() Function",
          "Identifying the Largest Element of a Numpy Array",
          "Detecting Least Element of Numpy Array: Min(), Ar",
          "Concatenating Numpy Arrays: Concatenate() Functio",
          "Splitting One-Dimensional Numpy Arrays: The Split",
          "Splitting Two-Dimensional Numpy Arrays: Split(),",
          "Sorting Numpy Arrays: Sort() Function",
          "Indexing Numpy Arrays",
          "Slicing One-Dimensional Numpy Arrays",
          "Slicing Two-Dimensional Numpy Arrays",
          "Assigning Value to One-Dimensional Arrays",
          "Assigning Value to Two-Dimensional Array",
          "Fancy Indexing of One-Dimensional Arrrays",
          "Fancy Indexing of Two-Dimensional Arrrays",
          "Combining Fancy Index with Normal Indexing",
          "Combining Fancy Index with Normal Slicing",
          "Operations with Comparison Operators",
          "Arithmetic Operations in Numpy",
          "Statistical Operations in Numpy",
          "Solving Second-Degree Equations with NumPy",
          "quiz"
        ],
        "“(Optional) Recap, Exercises, and Bonus İnfo from the Numpy Library": [
          "What is Numpy?",
          "Why Numpy?",
          "Array and features",
          "Array’s Operators",
          "Numpy Functions",
          "Indexing and Slicing",
          "Numpy Exercises",
          "Using Numpy in Linear Algebra",
          "NumExpr Guide",
          "quiz"
        ],
        "Pandas Library": [
          "Introduction to Pandas Library",
          "Pandas Project Files Link",
          "Creating a Pandas Series with a List",
          "Creating a Pandas Series with a Dictionary",
          "Creating Pandas Series with NumPy Array",
          "Object Types in Series",
          "Examining the Primary Features of the Pandas Series",
          "Most Applied Methods on Pandas Series",
          "Indexing and Slicing Pandas Series",
          "Creating Pandas DataFrame with List",
          "Creating Pandas DataFrame with NumPy Array",
          "Creating Pandas DataFrame with Dictionary",
          "Examining the Properties of Pandas DataFrames",
          "Element Selection Operations in Pandas DataFrames: Lesson 1",
          "Element Selection Operations in Pandas DataFrames: Lesson 2",
          "Top Level Element Selection in Pandas DataFrames: Lesson 1",
          "Top Level Element Selection in Pandas DataFrames: Lesson 2",
          "Top Level Element Selection in Pandas DataFrames: Lesson 3",
          "Element Selection with Conditional Operations in Pandas Data Frames",
          "Adding Columns to Pandas Data Frames",
          "Removing Rows and Columns from Pandas Data frames",
          "Null Values in Pandas Dataframes",
          "Dropping Null Values: Dropna() Function",
          "Filling Null Values: Fillna() Function",
          "Setting Index in Pandas DataFrames",
          "Multi-Index and Index Hierarchy in Pandas DataFrames",
          "Element Selection in Multi-Indexed DataFrames",
          "Selecting Elements Using the xs() Function in Multi-Indexed DataFrames",
          "Concatenating Pandas Dataframes: Concat( Function",
          "Merge Pandas Dataframes: Merge() Function: Lesson 1",
          "Merge Pandas Dataframes: Merge() Function: Lesson 2",
          "Merge Pandas Dataframes: Merge() Function: Lesson 3",
          "Merge Pandas Dataframes: Merge() Function: Lesson 4",
          "Joining Pandas Dataframes: Join() Function",
          "Loading a Dataset from the Seaborn Library",
          "Examining the Data Set 1",
          "Aggregation Functions in Pandas DataFrames",
          "Examining the Data Set 2",
          "Coordinated Use of Grouping and Aggregation Functions in Pandas Dataframes",
          "Advanced Aggregation Functions: Aggregate() Function",
          "Advanced Aggregation Functions: Filter() Function",
          "Advanced Aggregation Functions: Transform() Function",
          "Advanced Aggregation Functions: Apply() Function",
          "Examining the Data Set 3",
          "Pivot Tables in Pandas Library",
          "Accessing and Making Files Available",
          "Data Entry with Csv and Txt Files",
          "Data Entry with Excel Files",
          "Outputting as an CSV Extension",
          "Outputting as an Excel File",
          "Pandas Quiz"
        ],
        "Machine Learning": [
          "FAQ regarding Machine Learning",
          "AI, Machine Learning and Deep Learning",
          "History of Machine Learning",
          "Turing Machine and Turing Test",
          "What is Deep Learning",
          "Learning representations from data",
          "Workflow of Machine Learning",
          "Machine Learning Methods",
          "Supervised Machine Learning Methods - 1",
          "Supervised Machine Learning Methods - 2",
          "Supervised Machine Learning Methods - 3",
          "Supervised Machine Learning Methods - 4",
          "Unsupervised Machine Learning Methods",
          "Gathering data",
          "Data pre-processing",
          "Choosing the right algorithm and model",
          "Training and testing the model",
          "Evaluation",
          "Machine Learning Quiz"
        ],
        "Artificial Neural Network": [
          "What is Artificial Neural Network (ANN)?",
          "Anatomy of Neural Network",
          "Creating a Simple ANN",
          "Tensor Operations",
          "Tensor Operations 2",
          "Keras API",
          "Optimizers",
          "What is TensorFlow",
          "quiz"
        ],
        "Convolutional Neural Network (CNN)": [
          "What is CNN?",
          "quiz"
        ]
      },
      "requirements": [
        "Python Coding skills are a plus",
        "Math skills will boost your understanding",
        "Be able to download and install all the free software and tools needed to practice",
        "A strong work ethic, willingness to learn and plenty of excitement about the back door of the digital world",
        "Just you, your computer and your ambition to get started now!",
        "Basic knowledge of Python Programming Language",
        "Free software and tools used during the machine learning a-z course",
        "Determination to learn machine learning and patience.",
        "Curiosity for machine learning python",
        "Desire to learn Python",
        "Desire to work on python machine learning",
        "Desire to learn Python 3",
        "Desire to learn numpy",
        "Desire to learn numpy python, machine learning, deep learning",
        "Desire to learn artificial intelligence with python, numpy python, python deep learning, python machine learning"
      ],
      "description": "Hello there,\nWelcome to the “Python Programming: Machine Learning, Deep Learning | Python” course\nPython, machine learning, python programming, django, ethical hacking, data analysis, python for beginners, machine learning python, python bootcamp\nPython Machine Learning and Python Deep Learning with Data Analysis, Artificial Intelligence, OOP, and Python Projects\nComplete hands-on deep learning tutorial with Python Learn Machine Learning Python, go from zero to hero in Python 3\n\nPython instructors on OAK Academy specialize in everything from software development to data analysis, and are known for their effective, friendly instruction for students of all levels\nWhether you work in machine learning or finance, or are pursuing a career in web development or data science, Python is one of the most important skills you can learn Python's simple syntax is especially suited for desktop, web, and business applications Python's design philosophy emphasizes readability and usability Python was developed upon the premise that there should be only one way (and preferably one obvious way) to do things, a philosophy that has resulted in a strict level of code standardization The core programming language is quite small and the standard library is also large In fact, Python's large library is one of its greatest benefits, providing a variety of different tools for programmers suited for many different tasks\nMachine learning isn’t just useful for predictive texting or smartphone voice recognition Machine learning is constantly being applied to new industries and new problems Whether you’re a marketer, video game designer, or programmer, this course is here to help you apply machine learning to your work\nIt’s hard to imagine our lives without machine learning Predictive texting, email filtering, and virtual personal assistants like Amazon’s Alexa and the iPhone’s Siri, are all technologies that function based on machine learning algorithms and mathematical models Python programming: machine learning deep learning | python, python programming: machine learning deep learning, machine learning python, deep learning, machine learning, deep learning python, python programming machine learning deep learning, python programming machine learning, oak academy, python\nIn this course, we will learn what is Deep Learning and how does it work\nThis course has suitable for everybody who interested in Machine Learning and Deep Learning concepts in Data Science\nFirst of all, in this course, we will learn some fundamental stuff of Python and the Numpy library These are our first steps in our Deep Learning journey After then we take a little trip to Machine Learning Python history Then we will arrive at our next stop Machine Learning in Python Programming Here we learn the machine learning concepts, machine learning a-z workflow, models and algorithms, and what is neural network concept After then we arrive at our next stop Artificial Neural network And now our journey becomes an adventure In this adventure we'll enter the Keras world then we exit the Tensorflow world Then we'll try to understand the Convolutional Neural Network concept But our journey won't be over Then we will arrive at Recurrent Neural Network and LTSM We'll take a look at them After a while, we'll trip to the Transfer Learning concept And then we arrive at our final destination Projects in Python Bootcamp Our play garden Here we'll make some interesting machine learning models with the information we've learned along our journey\nIn this course, we will start from the very beginning and go all the way to the end of \"Deep Learning\" with examples\nThe Logic of Machine Learning such as Machine Learning models and algorithms, Gathering data, Data pre-processing, Training and testing the model etc\nBefore we start this course, we will learn which environments we can be used for developing deep learning projects\nDuring the course you will learn:\nFundamental stuff of Python and its library Numpy\nWhat is the Artificial Intelligence (Ai), Machine Learning, and Deep Learning\nHistory of Machine Learning\nTuring Machine and Turing Test\nThe Logic of Machine Learning such as\nUnderstanding the machine learning models\nMachine Learning models and algorithms\nGathering data\nData pre-processing\nChoosing the right algorithm and model\nTraining and testing the model\nEvaluation\nArtificial Neural Network with these topics\nWhat is ANN\nAnatomy of NN\nTensor Operations\nThe Engine of NN\nKeras\nTensorflow\nConvolutional Neural Network\nRecurrent Neural Network and LTSM\nTransfer Learning\nReinforcement Learning\nFinally, we will make four different projects to reinforce what we have learned\n\nWhat is machine learning?\nMachine learning describes systems that make predictions using a model trained on real-world data For example, let's say we want to build a system that can identify if a cat is in a picture We first assemble many pictures to train our machine learning model During this training phase, we feed pictures into the model, along with information around whether they contain a cat While training, the model learns patterns in the images that are the most closely associated with cats This model can then use the patterns learned during training to predict whether the new images that it's fed contain a cat In this particular example, we might use a neural network to learn these patterns, but machine learning can be much simpler than that Even fitting a line to a set of observed data points, and using that line to make new predictions, counts as a machine learning model\nWhat is machine learning used for?\nMachine learning a-z is being applied to virtually every field today That includes medical diagnoses, facial recognition, weather forecasts, image processing, and more In any situation in which pattern recognition, prediction, and analysis are critical, machine learning can be of use Machine learning is often a disruptive technology when applied to new industries and niches Machine learning engineers can find new ways to apply machine learning technology to optimize and automate existing processes With the right data, you can use machine learning technology to identify extremely complex patterns and yield highly accurate predictions\nDoes Machine learning require coding?\nIt's possible to use machine learning data science without coding, but building new systems generally requires code For example, Amazon’s Rekognition service allows you to upload an image via a web browser, which then identifies objects in the image This uses a pre-trained model, with no coding required However, developing machine learning systems involves writing some Python code to train, tune, and deploy your models It's hard to avoid writing code to pre-process the data feeding into your model Most of the work done by a machine learning practitioner involves cleaning the data used to train the machine They also perform “feature engineering” to find what data to use and how to prepare it for use in a machine learning model Tools like AutoML and SageMaker automate the tuning of models Often only a few lines of code can train a model and make predictions from it\nWhat is the best language for machine learning?\nPython is the most used language in machine learning using python Engineers writing machine learning systems often use Jupyter Notebooks and Python together Jupyter Notebooks is a web application that allows experimentation by creating and sharing documents that contain live code, equations, and more Machine learning involves trial and error to see which hyperparameters and feature engineering choices work best It's useful to have a development environment such as Python so that you don't need to compile and package code before running it each time Python is not the only language choice for machine learning Tensorflow is a popular framework for developing neural networks and offers a C++ API There is a complete machine learning framework for C# called ML NET Scala or Java are sometimes used with Apache Spark to build machine learning systems that ingest massive data sets\nWhat are the different types of machine learning?\nMachine learning is generally divided between supervised machine learning and unsupervised machine learning In supervised machine learning, we train machine learning models on labeled data For example, an algorithm meant to detect spam might ingest thousands of email addresses labeled 'spam' or 'not spam ' That trained model could then identify new spam emails even from data it's never seen In unsupervised learning, a machine learning model looks for patterns in unstructured data One type of unsupervised learning is clustering In this example, a model could identify similar movies by studying their scripts or cast, then group the movies together into genres This unsupervised model was not trained to know which genre a movie belongs to Rather, it learned the genres by studying the attributes of the movies themselves There are many techniques available within\nIs Machine learning a good career?\nMachine learning python is one of the fastest-growing and popular computer science careers today Constantly growing and evolving, you can apply machine learning to a variety of industries, from shipping and fulfillment to medical sciences Machine learning engineers work to create artificial intelligence that can better identify patterns and solve problems The machine learning discipline frequently deals with cutting-edge, disruptive technologies However, because it has become a popular career choice, it can also be competitive Aspiring machine learning engineers can differentiate themselves from the competition through certifications, boot camps, code repository submissions, and hands-on experience\nWhat is the difference between machine learning and artifical intelligence?\nMachine learning is a smaller subset of the broader spectrum of artificial intelligence While artificial intelligence describes any \"intelligent machine\" that can derive information and make decisions, machine learning describes a method by which it can do so Through machine learning, applications can derive knowledge without the user explicitly giving out the information This is one of the first and early steps toward \"true artificial intelligence\" and is extremely useful for numerous practical applications In machine learning applications, an AI is fed sets of information It learns from these sets of information about what to expect and what to predict But it still has limitations A machine learning engineer must ensure that the AI is fed the right information and can use its logic to analyze that information correctly\nWhat skills should a machine learning engineer know?\nA python machine learning engineer will need to be an extremely competent programmer with in-depth knowledge of computer science, mathematics, data science, and artificial intelligence theory Machine learning engineers must be able to dig deep into complex applications and their programming As with other disciplines, there are entry-level machine learning engineers and machine learning engineers with high-level expertise Python and R are two of the most popular languages within the machine learning field\nWhat is python?\nMachine learning python is a general-purpose, object-oriented, high-level programming language Whether you work in artificial intelligence or finance or are pursuing a career in web development or data science, Python bootcamp is one of the most important skills you can learn Python's simple syntax is especially suited for desktop, web, and business applications Python's design philosophy emphasizes readability and usability Python was developed on the premise that there should be only one way (and preferably, one obvious way) to do things, a philosophy that resulted in a strict level of code standardization The core programming language is quite small and the standard library is also large In fact, Python's large library is one of its greatest benefits, providing different tools for programmers suited for a variety of tasks\nPython vs R: What is the Difference?\nPython and R are two of today's most popular programming tools When deciding between Python and R in data science , you need to think about your specific needs On one hand, Python is relatively easy for beginners to learn, is applicable across many disciplines, has a strict syntax that will help you become a better coder, and is fast to process large datasets On the other hand, R has over 10,000 packages for data manipulation, is capable of easily making publication-quality graphics, boasts superior capability for statistical modeling, and is more widely used in academia, healthcare, and finance\nWhat does it mean that Python is object-oriented?\nPython is a multi-paradigm language, which means that it supports many data analysis programming approaches Along with procedural and functional programming styles, Python also supports the object-oriented style of programming In object-oriented programming, a developer completes a programming project by creating Python objects in code that represent objects in the actual world These objects can contain both the data and functionality of the real-world object To generate an object in Python you need a class You can think of a class as a template You create the template once, and then use the template to create as many objects as you need Python classes have attributes to represent data and methods that add functionality A class representing a car may have attributes like color, speed, and seats and methods like driving, steering, and stopping\nWhat are the limitations of Python?\nPython is a widely used, general-purpose programming language, but it has some limitations Because Python in machine learning is an interpreted, dynamically typed language, it is slow compared to a compiled, statically typed language like C Therefore, Python is useful when speed is not that important Python's dynamic type system also makes it use more memory than some other programming languages, so it is not suited to memory-intensive applications The Python virtual engine that runs Python code runs single-threaded, making concurrency another limitation of the programming language Though Python is popular for some types of game development, its higher memory and CPU usage limits its usage for high-quality 3D game development That being said, computer hardware is getting better and better, and the speed and memory limitations of Python are getting less and less relevant\nHow is Python used?\nPython is a general programming language used widely across many industries and platforms One common use of Python is scripting, which means automating tasks in the background Many of the scripts that ship with Linux operating systems are Python scripts Python is also a popular language for machine learning, data analytics, data visualization, and data science because its simple syntax makes it easy to quickly build real applications You can use Python to create desktop applications Many developers use it to write Linux desktop applications, and it is also an excellent choice for web and game development Python web frameworks like Flask and Django are a popular choice for developing web applications Recently, Python is also being used as a language for mobile development via the Kivy third-party library\nWhat jobs use Python?\nPython is a popular language that is used across many industries and in many programming disciplines DevOps engineers use Python to script website and server deployments Web developers use Python to build web applications, usually with one of Python's popular web frameworks like Flask or Django Data scientists and data analysts use Python to build machine learning models, generate data visualizations, and analyze big data Financial advisors and quants (quantitative analysts) use Python to predict the market and manage money Data journalists use Python to sort through information and create stories Machine learning engineers use Python to develop neural networks and artificial intelligent systems\nHow do I learn Python on my own?\nPython has a simple syntax that makes it an excellent programming language for a beginner to learn To learn Python on your own, you first must become familiar with the syntax But you only need to know a little bit about Python syntax to get started writing real code; you will pick up the rest as you go Depending on the purpose of using it, you can then find a good Python tutorial, book, or course that will teach you the programming language by building a complete application that fits your goals If you want to develop games, then learn Python game development If you're going to build web applications, you can find many courses that can teach you that, too Udemy’s online courses are a great place to start if you want to learn Python on your own\nWhat is data science?\nWe have more data than ever before But data alone cannot tell us much about the world around us We need to interpret the information and discover hidden patterns This is where data science comes in Data science uses algorithms to understand raw data The main difference between data science and traditional data analysis is its focus on prediction Data science seeks to find patterns in data and use those patterns to predict future data It draws on machine learning to process large amounts of data, discover patterns, and predict trends Data science includes preparing, analyzing, and processing data It draws from many scientific fields, and as a science, it progresses by creating new algorithms to analyze data and validate current methods\nWhat does a data scientist do?\nData Scientists use machine learning to discover hidden patterns in large amounts of raw data to shed light on real problems This requires several steps First, they must identify a suitable problem Next, they determine what data are needed to solve such a situation and figure out how to get the data Once they obtain the data, they need to clean the data The data may not be formatted correctly, it might have additional unnecessary data, it might be missing entries, or some data might be incorrect Data Scientists must, therefore, make sure the data is clean before they analyze the data To analyze the data, they use machine learning techniques to build models Once they create a model, they test, refine, and finally put it into production\nWhat are the most popular coding languages for data science?\nPython is the most popular programming language for data science It is a universal language that has a lot of libraries available It is also a good beginner language R is also popular; however, it is more complex and designed for statistical analysis It might be a good choice if you want to specialize in statistical analysis You will want to know either Python or R and SQL SQL is a query language designed for relational databases Data scientists deal with large amounts of data, and they store a lot of that data in relational databases Those are the three most-used programming languages Other languages such as Java, C++, JavaScript, and Scala are also used, albeit less so If you already have a background in those languages, you can explore the tools available in those languages However, if you already know another programming language, you will likely be able to pick up Python very quickly\nHow long does it take to become a data scientist?\nThis answer, of course, varies The more time you devote to learning new skills, the faster you will learn It will also depend on your starting place If you already have a strong base in mathematics and statistics, you will have less to learn If you have no background in statistics or advanced mathematics, you can still become a data scientist; it will just take a bit longer Data science requires lifelong learning, so you will never really finish learning A better question might be, \"How can I gauge whether I know enough to become a data scientist?\" Challenge yourself to complete data science projects using open data The more you practice, the more you will learn, and the more confident you will become Once you have several projects that you can point to as good examples of your skillset as a data scientist, you are ready to enter the field\nHow can I learn data science on my own?\nIt is possible to learn data science on your own, as long as you stay focused and motivated Luckily, there are a lot of online courses and boot camps available Start by determining what interests you about data science If you gravitate to visualizations, begin learning about them Starting with something that excites you will motivate you to take that first step If you are not sure where you want to start, try starting with learning Python It is an excellent introduction to programming languages and will be useful as a data scientist Begin by working through tutorials or Udemy courses on the topic of your choice Once you have developed a base in the skills that interest you, it can help to talk with someone in the field Find out what skills employers are looking for and continue to learn those skills When learning on your own, setting practical learning goals can keep you motivated\nDoes data science require coding?\nThe jury is still out on this one Some people believe that it is possible to become a data scientist without knowing how to code, but others disagree A lot of algorithms have been developed and optimized in the field You could argue that it is more important to understand how to use the algorithms than how to code them yourself As the field grows, more platforms are available that automate much of the process However, as it stands now, employers are primarily looking for people who can code, and you need basic programming skills The data scientist role is continuing to evolve, so that might not be true in the future The best advice would be to find the path that fits your skillset\nWhat skills should a data scientist know?\nA data scientist requires many skills They need a strong understanding of statistical analysis and mathematics, which are essential pillars of data science A good understanding of these concepts will help you understand the basic premises of data science Familiarity with machine learning is also important Machine learning is a valuable tool to find patterns in large data sets To manage large data sets, data scientists must be familiar with databases Structured query language (SQL) is a must-have skill for data scientists However, nonrelational databases (NoSQL) are growing in popularity, so a greater understanding of database structures is beneficial The dominant programming language in Data Science is Python — although R is also popular A basis in at least one of these languages is a good starting point Finally, to communicate findings, data scientists require knowledge of visualizations Data visualizations allow them to share complex data in an accessible manner\nIs data science a good career?\nThe demand for data scientists is growing We do not just have data scientists; we have data engineers, data administrators, and analytics managers The jobs also generally pay well This might make you wonder if it would be a promising career for you A better understanding of the type of work a data scientist does can help you understand if it might be the path for you First and foremost, you must think analytically Data science is about gaining a more in-depth understanding of info through data Do you fact-check information and enjoy diving into the statistics? Although the actual work may be quite technical, the findings still need to be communicated Can you explain complex findings to someone who does not have a technical background? Many data scientists work in cross-functional teams and must share their results with people with very different backgrounds If this sounds like a great work environment, then it might be a promising career for you\nMost programmers will choose to learn the object oriented programming paradigm in a specific language That’s why Udemy features a host of top-rated OOP courses tailored for specific languages, like Java, C#, and Python\nLearn more about Object Oriented Programming\nObject-oriented programming (OOP) is a computer programming paradigm where a software application is developed by modeling real world objects into software modules called classes Consider a simple point of sale system that keeps record of products purchased from whole-sale dealers and the products sold to the customer An object-oriented language would implement these requirements by creating a Product class, a Customer class, a Dealer class and an Order class All of these classes would interact together to deliver the required functionality where each class would be concerned with storing its own data and performing its own functions This is the basic idea of object-oriented programming or also called OOP\nWhat does it mean that Python is object-oriented?\nPython is a multi-paradigm language, which means that it supports many programming approaches Along with procedural and functional programming styles, Python also supports the object-oriented style of programming In object-oriented programming, a developer completes a programming project by creating Python objects in code that represent objects in the actual world These objects can contain both the data and functionality of the real-world object To generate an object in Python you need a class You can think of a class as a template You create the template once, and then use the template to create as many objects as you need Python classes have attributes to represent data and methods that add functionality A class representing a car may have attributes like color, speed, and seats and methods like driving, steering, and stopping The concept of combining data with functionality in an object is called encapsulation, a core concept in the object-oriented programming paradigm\nWhy would you want to take this course?\nOur answer is simple: The quality of teaching\nOAK Academy based in London is an online education company OAK Academy gives education in the field of IT, Software, Design, development in English, Portuguese, Spanish, Turkish and a lot of different language on Udemy platform where it has over 1000 hours of video education lessons OAK Academy both increase its education series number by publishing new courses, and it makes students aware of all the innovations of already published courses by upgrading\nWhen you enroll, you will feel the OAK Academy`s seasoned developers expertise Questions sent by students to our instructors are answered by our instructors within 48 hours at the latest\nVideo and Audio Production Quality\nAll our videos are created/produced as high-quality video and audio to provide you the best learning experience\nYou will be,\nSeeing clearly\nHearing clearly\nMoving through the course without distractions\n\n\nYou'll also get:\nLifetime Access to The Course\nFast & Friendly Support in the Q&A section\nUdemy Certificate of Completion Ready for Download\nWe offer full support, answering any questions\nIf you are ready to learn “Python Programming: Machine Learning, Deep Learning | Python”\nDive in now! See you in the course!",
      "target_audience": [
        "Anyone who has programming experience and wants to learn machine learning and deep learning.",
        "Statisticians and mathematicians who want to learn machine learning and deep learning.",
        "Tech geeks who curious with Machine Learning and Deep Learning concept.",
        "Data analysts who want to learn machine learning and deep learning.",
        "If you are one of these, you are in the right place. But please don't forget. You must know a little bit of coding and scripting.",
        "Anyone who need a job transition",
        "Anyone eager to learn python for data science and machine learning bootcamp with no coding background",
        "Software developer whom want to learn python,",
        "Anyone interested in machine learning a-z",
        "People Wanting to Specialize in Anaconda Python Environment for Data Science and Scientific Computing",
        "Students Interested in Beginning Data Science Applications in Python 3 Environment",
        "People who want to learn deep learning python, machine learning, numpy"
      ]
    },
    {
      "title": "The Ultimate Beginners Guide to Fuzzy Logic in Python",
      "url": "https://www.udemy.com/course/the-ultimate-beginners-guide-to-fuzzy-logic-in-python/",
      "bio": "Understand the basic theory and implement fuzzy systems with skfuzzy library! Step by step implementations",
      "objectives": [
        "Understand the theoretical concepts of fuzzy logic, such as: linguistic variables, antecedents, consequent, membership, fuzzification, and defuzzification",
        "Learn defuzzification calculations using the following methods: centroid, bisector, MOM, SOM and LOM",
        "Implement fuzzy systems using skfuzzy library",
        "Simulate a fuzzy system to choose the percentage of tip that would be given in a restaurant",
        "Simulate a fuzzy system to adjust the suction power of a vacuum cleaner, according to the type of surface and amount of dirt",
        "Implement data clustering using the fuzzy c-means algorithm"
      ],
      "course_content": {},
      "requirements": [
        "Basic Python programming"
      ],
      "description": "Fuzzy Logic is a technique that can be used to model the human reasoning process in computers. It can be applied to several areas, such as: industrial automation, medicine, marketing, home automation, among others. A classic example is the use in industrial equipments, which can have the temperature automatically adjusted as the equipment heats up or cools down. Other examples of equipments are: vacuum cleaners (adjustment of suction power according to the surface and level of dirt), dishwashers and clothes washing machines (adjustment of the amount of water and soap to use), digital cameras (automatic focus setting), air conditioning (temperature setting according to the environment), and microwave (power adjustment according to the type of food).\nIn this course, you will learn the basic theory of fuzzy logic and mainly the implementation of simple fuzzy systems using skfuzzy library. All implementations will be done step by step using the Python programming language! Below you can see the main content, which is divided into three parts:\n\n\nPart 1: Basic intuition about fuzzy logic. You will learn topics such as: linguistic variables, antecedents, consequent, membership functions, fuzzification and mathematical calculations for defuzzification\nPart 2: Implementation of fuzzy systems. You will implement two examples: the calculation of tips that would be given in a restaurant (based on the quality of the food and the quality of service) and the calculation of the suction power of a vacuum cleaner (based on the type of surface and the amount of dirt )\nPart 3: Clustering with fuzzy c-means algorithm. We will cluster a bank's customers based on the credit card limit and the total bill. You will understand how fuzzy logic can be applied in the area of Machine Learning\nAll implementations will be done step by step using Google Colab on-line, so you don't need to worry about installing the libraries on your own machine. At the end, you will be able to create your own projects using fuzzy logic!",
      "target_audience": [
        "Anyone interested in fuzzy logic",
        "Students who are taking courses on Artificial Intelligence or Data Science",
        "Data Scientists who want to increase their knowledge in artificial intelligence algorithms"
      ]
    },
    {
      "title": "CO₂ Emissions Forecasting with Shallow Neural Nets in Python",
      "url": "https://www.udemy.com/course/shallow-neural-networks-for-time-series-forecasting/",
      "bio": "Build Accurate Time Series Forecasts with Python - Energy Sector Application",
      "objectives": [
        "Build Shallow Neural Network models to forecast CO2 emissions using Python",
        "Apply a proven 10-step methodology for creating statistically sound and reliable forecasts",
        "Work with real World Bank data to analyze emissions trends for India, China, USA, UK, EU and global averages",
        "Master essential statistical tests including overfitting analysis, naive model benchmarking, and sensitivity analysis",
        "Quantify forecast uncertainty using confidence intervals and error metrics like MAPE",
        "Create publication-ready visualizations of historical trends and future projections",
        "Understand when Shallow Neural Network modelling is appropriate for time series forecasting vs other methods",
        "Implement best practices for model validation, hyperparameter tuning, and results interpretation"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Multivariate versus univariate models",
          "Overview of the ten-step methodology",
          "Resources"
        ],
        "Data Preprocessing": [
          "Introduction",
          "Data Preprocessing",
          "Download the original data",
          "Resources"
        ],
        "Dataset split": [
          "Introduction",
          "Resources",
          "Polynomial Features",
          "Dataset split"
        ],
        "Dataset scaling": [
          "Introduction",
          "Scaling the data and the features matrices"
        ],
        "Shallow Neural Networks": [
          "Introduction",
          "Compiling the models",
          "Fitting and drawing the models",
          "Drawing in detail",
          "Explanation of the activation function",
          "Generating predictions",
          "Test set errors",
          "Training set errors",
          "Overfitting analysis",
          "Naive model test",
          "Sensitivity analysis and hyperparameter tuning",
          "Sensitivity analysis",
          "Forecasts: theory and methodology",
          "Generating the forecasts",
          "Final selection of the models"
        ],
        "Conclusion": [
          "Conclusion",
          "Resources"
        ]
      },
      "requirements": [
        "Absolute beginners welcome!",
        "You'll receive the full Python code, which you can adjust to your own projects",
        "No programming experience? Follow along and learn by doing",
        "No statistics background needed",
        "Just need a computer and enthusiasm"
      ],
      "description": "SPECIAL OFFER:\nSave today! Copy this code at checkout (remove the middle space):     B8E286284 4253DF8DBA5\n\nWHO I AM:\nResearcher and educator specializing in energy data science (PhD in Energy, Imperial College London, 40+ publications)\n\nREGULAR ENHANCEMENTS:\nCourse reviewed periodically with updates.\n\n\nWhat You'll Learn:\nHow to build a Shallow Neural Network model in Python that can forecast CO₂ emissions\nHow to achieve high accuracy in the forecasts that you will produce\nHow to work with World Bank historical data\nHow to implement advanced statistical tests\nHow to apply your model to real-world cases (India, China, USA, UK, European Union analysis)\n\nPerfect For:\nEnvironmental consultants and analysts\nEnergy economists and policy makers\nData scientists in sustainability\nClimate professionals\n\nWhy This Matters:\nWith net-zero targets and mandatory carbon reporting, professionals who can produce credible emissions forecasts are in high demand. Master the skills that set you apart in the growing climate economy. Companies now require carbon footprint assessments for regulatory compliance and ESG reporting. Governments need emissions projections for policy planning. Consultancies charge premium rates for these capabilities. Whether you're advancing your current career or transitioning into sustainability, these practical forecasting skills open doors to roles paying $150,000-250,000+ in the rapidly expanding green economy.",
      "target_audience": [
        "Environmental/Climate Analysts seeking quantitative forecasting skills",
        "Sustainability Professionals needing to project emissions for reporting",
        "Energy Sector Professionals wanting data-driven analytical methods",
        "Graduate Students & Researchers in environmental science, energy, or climate studies",
        "Data Scientists/ML Engineers moving into climate and energy applications",
        "ESG Analysts & Consultants requiring emissions projection capabilities",
        "Policy Analysts working on climate strategies and carbon reduction plans",
        "Anyone transitioning to climate tech who needs practical forecasting skills"
      ]
    },
    {
      "title": "Practical Introduction to Machine Learning with Python",
      "url": "https://www.udemy.com/course/practical-machine-learning/",
      "bio": "Quickly Learn the Essentials of Artificial Intelligence (AI) and Machine Learning (ML)",
      "objectives": [
        "Fundamentals of Artificial Intelligence (AI) and Machine Learning",
        "Practical business applications of machine learning",
        "Classification, regression, clustering, anomaly detection",
        "How machines learn from data",
        "Supervised, unsupervised, reinforcement, and transfer learning",
        "How to identify problems suitable for machine learning",
        "How to collect and prepare data suitable for training and testing machine learning models",
        "Different types of machine learning models and how to choose among them",
        "Machine learning development and production deployment process",
        "How to train models using GPU instances in the cloud"
      ],
      "course_content": {},
      "requirements": [
        "Some Python programming is helpful, but not required",
        "Math concepts such as linear algebra and calculus are helpful, but not required"
      ],
      "description": "LinkedIn released it's annual \"Emerging Jobs\" list, which ranks the fastest growing job categories. The top role is Artificial Intelligence Specialist, which is any role related to machine learning. Hiring for this role has grown 74% in the past few years!\nMachine learning is the technology behind self driving cars, smart speakers, recommendations, and sophisticated predictions. Machine learning is an exciting and rapidly growing field full of opportunities. In fact, most organizations can not find enough AI and ML talent today.\nIf you want to learn what machine learning is and how it works, then this course is for you. This course is targeted at a broad audience at an introductory level. By the end of this course you will understand the benefits of machine learning, how it works, and what you need to do next. If you are a software developer interested in developing machine learning models from the ground up, then my second course, Practical Machine Learning by Example in Python might be a better fit.\nThere are a number of machine learning examples demonstrated throughout the course. Code examples are available on github. You can run each examples using Google Colab. Colab is a free, cloud-based machine learning and data science platform that includes GPU support to reduce model training time. All you need is a modern web browser, there's no software installation is required!\nJuly 2019 course updates include lectures and examples of self-supervised learning. Self-supervised learning is an exciting technique where machines learn from data without the need for expensive human labels. It works by predicting what happens next or what's missing in a data set. Self-supervised learning is partly inspired by early childhood learning and yields impressive results. You will have an opportunity to experiment with self-supervised learning to fully understand how it works and the problems it can solve.\nAugust 2019 course updates include a step by step demo of how to load data into Google Colab using two different methods. Google Colab is a powerful machine learning environment with free GPU support. You can load your own data into Colab for training and testing.\nMarch 2020 course updates migrate all examples to Google Colab and Tensorflow 2. Tensorflow 2 is one of the most popular machine learning frameworks used today. No software installation is required.\nApril/May 2020 course updates streamline content, include Jupyter notebook lectures and assignment. Jupyter notebook is the preferred environment for machine learning development.",
      "target_audience": [
        "IT managers, business analysts, software architects, and developers interested in a quick start into the exciting and rapidly growing field of machine learning.",
        "Business analysts or non-technical people who want to leverage their skills to add value in machine learning development project",
        "Anyone wanting to learn where they can be productive in a changing economy where machines are climbing the corporate ladder"
      ]
    },
    {
      "title": "DeepSeek Course: Learn DeepSeek R1, Build Apps, GenAi, LLM",
      "url": "https://www.udemy.com/course/deepseek-r1-build-app-and-website-gen-ai-llm/",
      "bio": "Become a DeepSeek Master: Create AI Apps, Visualizations & analyze data, automate tasks with DeepSeek R1, ChatGPT",
      "objectives": [
        "Create and optimize AI-driven applications (calculator, piano, puzzle game) using DeepSeek without coding.",
        "Master DeepSeek for education, business, and personal tasks like data analysis, SEO, and content creation.",
        "Build interactive data visualizations (maps) and SaaS tools (image converters) with Python and AI integration.",
        "Compare DeepSeek’s cost, speed, and features (DeepThink R1) against ChatGPT for optimal AI solutions."
      ],
      "course_content": {},
      "requirements": [
        "Basic computer skills (file management, web browsing.",
        "No coding experience needed; familiarity with HTML/CSS/JS or Python is optional but helpful.",
        "Tools: Free DeepSeek account, text editor (Notepad/VS Code), web browser.",
        "For Python projects: Google Colab (no local installation required)."
      ],
      "description": "This course is a hands-on guide to using DeepSeek for building web and software applications without needing advanced coding skills.\n\n\nYou will learn how to create projects ranging from a simple calculator and a piano application to a puzzle game and even a no-code SaaS tool. The course is designed to be friendly and easy to follow, with clear steps and practical examples that show you how AI can help you develop creative and functional projects.\n\n\nWe start by guiding you through the basics of setting up your DeepSeek account and exploring its many features. You will learn how to navigate the platform and discover its applications in education, personal development, business, and software development. This initial section is crafted to build your confidence as you learn to work with AI-driven tools.\n\n\nThroughout the course, you will work on several projects that bring ideas to life. One project walks you through building a fully functional calculator using HTML, CSS, and JavaScript. In another lesson, you create a piano application that you can customize to suit your style. There is also a project focused on game development, where you build a fun puzzle game. In addition, you will learn how to visualize data on an interactive map using Python and Google Colab. As you progress, the course also shows you how to run Python projects locally on your computer using tools like Microsoft Visual Studio Code. You will even create a no-code SaaS application that converts images from JPEG to WebP, giving you a taste of software development without writing complex code. Each project is explained step by step, making it easy to follow along, even if you are new to programming.\n\n\nWho Is This Course For?\n\n\nStudents, Learn practical skills that can complement your academic studies.\nProfessionals, Explore how AI can streamline software development and enhance productivity.\nHobbyists, Discover a fun and creative way to build interactive applications\nEntrepreneurs, Gain insights into no-code tools that can help you prototype ideas quickly.\n\n\nWhy This Course?\n\n\nNo Advanced Coding Required, Perfect for beginners or those who want to avoid complex programming.\nPractical Projects, Each project is designed to be functional and relevant, giving you tangible results. AI-Powered\nDevelopment, Learn how to leverage AI tools like DeepSeek to simplify and accelerate development.\nStep-by-Step Guidance, Clear instructions ensure you can follow along, even if you're new to programming.\n\n\nBy the end, you’ll confidently use DeepSeek, DeepThink R1 to solve real-world problems, saving time and resources.\nEnroll now and start building smarter with AI!",
      "target_audience": [
        "AI enthusiasts seeking hands-on experience with DeepSeek for personal or professional projects.",
        "Educators, developers, and entrepreneurs aiming to automate tasks or build apps without coding.",
        "Data analysts and marketers interested in AI-driven SEO, visualization, and business insights.",
        "Beginners exploring AI tools to enhance creativity, productivity, and technical skills."
      ]
    },
    {
      "title": "Artificial Intelligence (AI) in Education",
      "url": "https://www.udemy.com/course/artificial-intelligence-ai-in-education/",
      "bio": "Essential Knowledge and Strategies for Teachers to Integrate Artificial Intelligence in the Classroom",
      "objectives": [
        "Understand the basics of Artificial Intelligence (AI) in Education",
        "Gain understanding of AI technologies in the educational setting",
        "Understand the current usage of AI in classrooms",
        "Identify the ethical considerations of AI in education",
        "Acquire the essential knowledge and skills for incorporating AI in the classroom today",
        "Prepare for the future advancements of AI in education"
      ],
      "course_content": {},
      "requirements": [
        "Learners should have some knowledge of classroom or homeschool settings and educational practices."
      ],
      "description": "This course is designed for educators who are interested in understanding the basics of Artificial Intelligence (AI) in Education. The course will provide an overview of AI in education and help you gain an understanding of AI technologies in the educational setting. You will learn about the current usage of AI in classrooms and identify the ethical considerations of AI in Education. Additionally, you will acquire the essential knowledge and skills for incorporating AI in the classroom today and prepare for the future advancements of AI in Education. This course is suitable for teachers, homeschool educators, administrators, teacher aides, substitute teachers, preservice teachers, and parents who are shaping students for a high-tech future.\nLearning objectives:\nUnderstand the basics of Artificial Intelligence (AI) in Education\nGain an understanding of AI technologies in the educational setting.\nUnderstand the current usage of AI in Classrooms\nIdentify the ethical considerations of AI in Education\nAcquire the essential knowledge and skills for incorporating AI in the classroom today\nPrepare for the future advancements of AI in Education\nModule 1: I. Introduction to Artificial Intelligence in Education\nWhat is AI?\nOverview of Artificial Intelligence in education\nPotential benefits and challenges\nModule 2: Understanding AI Technologies in Education\nTypes of AI in Education\nModule 3: How AI is currently implemented in the Classroom\nUse cases for AI in education\nExamples of AI-powered educational tools and resources\nBest practices for integrating AI into instruction\nModule 4: Ethical Considerations of AI in Education\nPrivacy and security concerns\nBias and fairness in AI systems\nImpact on student learning and motivation\nModule 5: Essential Knowledge and Skills for Incorporating AI in the Classroom Today\nHow students are using AI\nHow can teachers make assignments for students where AI is not helpful?\nModule 6: Preparing for the Future of AI in Education\nStaying current with developments in AI research\nBuilding a culture of innovation and experimentation in the classroom\nProfessional development opportunities for teachers",
      "target_audience": [
        "This resource is intended for a wide range of individuals who play a critical role in shaping students for a high-tech future, including teachers, homeschool educators, administrators, teacher aids, substitute teachers, preservice teachers, and parents. Whether you are a classroom teacher looking to integrate technology into your instruction, a homeschool parent seeking to provide your children with a well-rounded education, or an administrator looking to support your staff in implementing technology-rich instruction, this resource has something for you."
      ]
    },
    {
      "title": "Math 0-1: Probability for Data Science & Machine Learning",
      "url": "https://www.udemy.com/course/probability-data-science-machine-learning/",
      "bio": "A Casual Guide for Artificial Intelligence, Deep Learning, and Python Programmers",
      "objectives": [
        "Conditional probability, Independence, and Bayes' Rule",
        "Use of Venn diagrams and probability trees to visualize probability problems",
        "Discrete random variables and distributions: Bernoulli, categorical, binomial, geometric, Poisson",
        "Continuous random variables and distributions: uniform, exponential, normal (Gaussian), Laplace, Gamma, Beta",
        "Cumulative distribution functions (CDFs), probability mass functions (PMFs), probability density functions (PDFs)",
        "Joint, marginal, and conditional distributions",
        "Multivariate distributions, random vectors",
        "Functions of random variables, sums of random variables, convolution",
        "Expected values, expectation, mean, and variance",
        "Skewness, kurtosis, and moments",
        "Covariance and correlation, covariance matrix, correlation matrix",
        "Moment generating functions (MGF) and characteristic functions",
        "Key inequalities like Markov, Chebyshev, Cauchy-Schwartz, Jensen",
        "Convergence in probability, convergence in distribution, almost sure convergence",
        "Law of large numbers and the Central Limit Theorem (CLT)",
        "Applications of probability in machine learning, data science, and reinforcement learning"
      ],
      "course_content": {
        "Welcome": [
          "Introduction",
          "Outline",
          "Where to Get the Code",
          "How to Succeed in this Course"
        ],
        "Probability Basics": [
          "Probability Basics Section Introduction",
          "What Is Probability?",
          "Wrong Definition of Probability (Common Mistake)",
          "Wrong Definition of Probability (Example)",
          "Probability Models",
          "Venn Diagrams",
          "Properties of Probability Models",
          "Union Example",
          "Law of Total Probability",
          "Conditional Probability",
          "Bayes' Rule",
          "Bayes' Rule Example",
          "Independence",
          "Mutual Independence Example",
          "Probability Tree Diagrams",
          "Probability Basics Section Summary",
          "Suggestion Box"
        ],
        "Random Variables and Probability Distributions": [
          "Discrete Random Variables and Distributions Section Introduction",
          "What is a Random Variable?",
          "The Bernoulli Distribution",
          "The Categorical Distribution",
          "The Binomial Distribution",
          "The Geometric Distribution",
          "The Poisson Distribution",
          "Visualizing Probability Distributions in Python",
          "Discrete Random Variables Section Summary"
        ],
        "Continuous Random Variables and Probability Density Functions": [
          "Continuous Random Variables and Distributions Section Introduction",
          "Continuous Random Variables and Continuous Distributions",
          "Physics Analogy",
          "More About Continuous Distributions",
          "The Uniform Distribution",
          "The Exponential Distribution",
          "The Normal Distribution (Gaussian Distribution)",
          "The Laplace (Double Exponential) Distribution",
          "Visualizing Continuous Probability Distributions in Python",
          "Continuous Random Variables Section Summary"
        ],
        "More About Probability Distributions and Random Variables": [
          "More About Probability Distributions and Random Variables Section Introduction",
          "Cumulative Distribution Function (CDF)",
          "Exercise: CDF of Geometric Distribution",
          "CDFs for Continuous Random Variables",
          "Exercise: CDF of Normal Distribution",
          "Change of Variables (Functions of Random Variables) pt 1",
          "Change of Variables (Functions of Random Variables) pt 2",
          "Joint and Marginal Distributions pt 1",
          "Joint and Marginal Distributions pt 2",
          "Exercise: Marginal of Bivariate Normal",
          "Conditional Distributions and Bayes' Rule",
          "Exercise: Conditioning with Joint Normal and Linear Regression",
          "Independence",
          "Exercise: Bivariate Normal with Zero Correlation",
          "Multivariate Distributions and Random Vectors",
          "Multivariate Normal Distribution / Vector Gaussian",
          "Multinomial Distribution",
          "Exercise: MVN to Bivariate Normal",
          "Exercise: Multivariate Normal, Zero Correlation Implies Independence",
          "Multidimensional Change of Variables (Discrete)",
          "Multidimensional Change of Variables (Continuous)",
          "Convolution From Adding Random Variables",
          "Exercise: Sums of Jointly Normal Random Variables (Optional)",
          "Visualizing CDFs and Joint Distributions in Python",
          "CDFs and Multiple Random Variables Section Summary"
        ],
        "Expectation and Expected Values": [
          "Expectation Section Introduction",
          "Expected Value and Mean",
          "Properties of the Expected Value",
          "Variance",
          "Exercise: Mean and Variance of Bernoulli",
          "Exercise: Mean and Variance of Poisson",
          "Exercise: Mean and Variance of Normal",
          "Exercise: Mean and Variance of Exponential",
          "Moments, Skewness and Kurtosis",
          "Exercise: Kurtosis of Normal Distribution",
          "Covariance and Correlation",
          "Exercise: Covariance and Correlation of Bivariate Normal",
          "Exercise: Zero Correlation Does Not Imply Independence",
          "Exercise: Correlation Measures Linear Relationships",
          "Conditional Expectation pt 1",
          "Conditional Expectation pt 2",
          "Law of Total Expectation",
          "Exercise: Linear Combination of Normals",
          "Exercise: Mean and Variance of Weighted Sums",
          "Expectation Section Summary"
        ],
        "Generating Functions": [
          "Generating Functions Section Introduction",
          "Moment Generating Functions (MGF)",
          "Exercise: MGF of Exponential",
          "Exercise: MGF of Normal",
          "Characteristic Functions",
          "Exercise: MGF Doesn't Exist",
          "Exercise: Characteristic Function of Normal",
          "Sums of Independent Random Variables",
          "Exercise: Distribution of Sum of Poisson Random Variables",
          "Exercise: Distribution of Sum of Geometric Random Variables",
          "Moment Generating Functions for Random Vectors",
          "Characteristic Functions for Random Vectors",
          "Exercise: Weighted Sums of Normals",
          "Generating Functions in Python",
          "Generating Functions Section Summary"
        ],
        "Inequalities": [
          "Inequalities Section Introduction",
          "Monotonicity",
          "Markov Inequality",
          "Chebyshev Inequality",
          "Cauchy-Schwartz Inequality",
          "Inequalities Section Summary"
        ],
        "Limit Theorems": [
          "Limit Theorems Section Introduction",
          "Convergence In Probability",
          "Weak Law of Large Numbers",
          "Convergence With Probability 1 (Almost Sure Convergence)",
          "Strong Law of Large Numbers",
          "Application: Frequentist Perspective Revisited",
          "Convergence In Distribution",
          "Central Limit Theorem",
          "LLN and CLT in Python",
          "Limit Theorems Section Summary"
        ],
        "Advanced and Other Topics": [
          "The Gamma Distribution",
          "The Beta Distribution",
          "Chain Rule of Probability",
          "Why Does the Normal Distribution Integrate to 1?"
        ]
      },
      "requirements": [
        "College / University-level Calculus (for most parts of the course)",
        "College / University-level Linear Algebra (for some parts of the course)"
      ],
      "description": "Common scenario: You try to get into machine learning and data science, but there's SO MUCH MATH.\nEither you never studied this math, or you studied it so long ago you've forgotten it all.\nWhat do you do?\nWell my friends, that is why I created this course.\nProbability is one of the most important math prerequisites for data science and machine learning. It's required to understand essentially everything we do, from the latest LLMs like ChatGPT, to diffusion models like Stable Diffusion and Midjourney, to statistics (what I like to call \"probability part 2\").\nMarkov chains, an important concept in probability, form the basis of popular models like the Hidden Markov Model (with applications in speech recognition, DNA analysis, and stock trading) and the Markov Decision Process or MDP (the basis for Reinforcement Learning).\nMachine learning (statistical learning) itself has a probabilistic foundation. Specific models, like Linear Regression, K-Means Clustering, Principal Components Analysis, and Neural Networks, all make use of probability.\nIn short, probability cannot be avoided!\nIf you want to do machine learning beyond just copying library code from blogs and tutorials, you must know probability.\nThis course will cover everything that you'd learn (and maybe a bit more) in an undergraduate-level probability class. This includes random variables and random vectors, discrete and continuous probability distributions, functions of random variables, multivariate distributions, expectation, generating functions, the law of large numbers, and the central limit theorem.\nMost important theorems will be derived from scratch. Don't worry, as long as you meet the prerequisites, they won't be difficult to understand. This will ensure you have the strongest foundation possible in this subject. No more memorizing \"rules\" only to apply them incorrectly / inappropriately in the future! This course will provide you with a deep understanding of probability so that you can apply it correctly and effectively in data science, machine learning, and beyond.\nAre you ready?\nLet's go!\n\n\nSuggested prerequisites:\nDifferential calculus, integral calculus, and vector calculus\nLinear algebra\nGeneral comfort with university/collegelevel mathematics",
      "target_audience": [
        "Python developers and software developers curious about Data Science",
        "Professionals interested in Machine Learning and Data Science but haven't studied college-level math",
        "Students interested in ML and AI but find they can't keep up with the math",
        "Former STEM students who want to brush up on probability before learning about artificial intelligence"
      ]
    },
    {
      "title": "Master Scientific Computing in Python with NumPy",
      "url": "https://www.udemy.com/course/scientific-computing-with-numpy/",
      "bio": "Explore data science in Python by doing linear algebra, image processing, simple machine learning and more in NumPy!",
      "objectives": [
        "Learn to confidently work with vectors and matrices in NumPy.",
        "Learn basic functionality like sorting, calculating means, and finding max/min values.",
        "Learn to draw line plots, bar plots, and scatterplots.",
        "Learn to generate different types of random vectors.",
        "Learn to modify and reshape matrices to your advantage.",
        "Learn Boolean indexing and advanced slicing to extract useful information.",
        "Learn to do basic linear algebra in NumPy like solving linear systems, calculating inverses, and more!",
        "Get an understanding of how ndarrays work and utilize this to create fast code.",
        "Learn Fourier transforms with NumPy and use this to manipulate images and audio.",
        "Learn advanced linear algebra like the QR decomposition and partial least squares.",
        "Learn how to preserve your NumPy objects in different formats.",
        "Learn about neighboring libraries and that NumPy is used everywhere in Python's data science stack."
      ],
      "course_content": {
        "Introduction": [
          "Introduction to the Course",
          "Download all the Material",
          "Installing Anaconda",
          "Markdown Cells",
          "Code Cells",
          "Importing NumPy"
        ],
        "Working with Vectors": [
          "Introduction",
          "Creating Vectors",
          "Create a vector",
          "Changing Values",
          "Basic Operations",
          "Basic Operations",
          "NumPy Datatypes",
          "Slicing Vectors",
          "Slicing",
          "Sorting Vectors",
          "Copies vs. Views",
          "Vectors",
          "Aggregate Funcitons",
          "Exercise Set - Temperature Data"
        ],
        "Universal Functions and Plotting": [
          "Introduction",
          "Universal Functions",
          "Universal Functions",
          "Function Plot",
          "Universal and Plotting",
          "Bar and Scatter Plot",
          "Exercise Set - Temperature Data Continued"
        ],
        "Randomness and Statistics": [
          "Introduction",
          "Generators and Random Integers",
          "Dice Values",
          "Random, Shuffle, and Choice",
          "Random Number Generator",
          "The Normal Distribution",
          "Basic Statistics",
          "Mean, Median and Standard Deviation",
          "Finding Unique Values",
          "Exercise Set - Linear Regression"
        ],
        "Making and Modifying Matrices": [
          "Introduction",
          "Making and Modifying Matrices",
          "Getting Rows and Columns",
          "Attributes of a Matrix",
          "Changing the Shape of a Matrix",
          "Changing the Shape",
          "Specifying an Axis",
          "Taking the Maximum Over Rows",
          "Boolean Matrices",
          "Exercise Set - Rain Data"
        ],
        "Broadcasting and Advanced Indexing": [
          "Introduction",
          "Basic Broadcasting",
          "Broadcasting Rules",
          "Broadcasting",
          "2D Slicing",
          "Slicing Practice",
          "Advanced Indexing",
          "Finding Even and Odd Numbers",
          "Exercise Set - Monochromatic Images"
        ],
        "Basic Linear Algebra": [
          "Introduction",
          "Basic Linear Algebra",
          "Cross Product and Length",
          "Cross and Dot Product",
          "Matrix Operations",
          "Matrix Operations",
          "Solving Linear Systems I",
          "Linear Systems",
          "Solving Linear Systems II",
          "Exercise Set - Basic Linear Algebra"
        ],
        "Understanding ndarrays": [
          "Introduction",
          "Making Higher Dimensional Arrays",
          "Higher Dimensional Arrays",
          "Slicing and Aggregate Functions",
          "Using Aggregate Functions",
          "Colored Images",
          "What are Strides?",
          "Exercise Set - Color Images"
        ],
        "Fourier Transforms": [
          "Introduction",
          "Complex Numbers",
          "Fourier Transforms I",
          "Fourier Transforms II",
          "Smoothing a Signal",
          "2D Fourier Transforms",
          "Exercise Set - Fourier Transforms"
        ],
        "Advanced Linear Algebra": [
          "Introduction",
          "Finding Eigenvalues and Eigenvectors",
          "Types of Matrices",
          "Working with Orthogonal Matrices",
          "QR Decomposition",
          "QR Decomposition and Eigenvalues",
          "Partial Least Squares",
          "Exercise Set - Quadratic Approximations & More"
        ]
      },
      "requirements": [
        "A basic understanding of variables, lists, and functions in Python.",
        "Some knowledge of mathematics (linear algebra, complex numbers) is useful.",
        "No previous experience with NumPy is required!",
        "A willingness to write loads of NumPy code!"
      ],
      "description": "Do you want to learn NumPy and get started with data analysis in Python? This course is both a comprehensive and hands-on introduction to NumPy!\n\n\nWhat this course is all about:\nIn this course, we will teach you the ins and outs of the Python library NumPy. This library is incredibly powerful and is used for scientific computing, linear algebra, image processing, machine learning, and more. If you are interested in one of these topics or simply want to get started with data science in Python, then this is the course for you!\nThe course will teach you everything you need to know to professionally use NumPy. We will start with the basics, and then gradually move on to more complicated topics. As NumPy is the fundamental building block for other popular Python libraries like Pandas, Scikit-Learn, and PyTorch, it's a great library to get you started with data science in Python.\n\n\nWhy choose us?\nThis course is a comprehensive introduction to NumPy! We don't shy away from the technical stuff and want you to stand out with your newly learned NumPy skills.\nThe course is filled with carefully made exercises that will reinforce the topics we teach. In between videos, we give small exercises that help you reinforce the material. Additionally, we have larger exercises where you will be given a Jupiter Notebook sheet and asked to solve a series of questions that revolve around a single topic. We give exercises on awesome topics like audio processing, linear regression, and image manipulation!\nWe're a couple (Eirik and Stine) who love to create high-quality courses! In the past, Eirik has taught both Python and NumPy at the university level, while Stine has written learning material for a university course that has used NumPy. We both love NumPy and can't wait to teach you all about it!\n\n\nTopics we will cover:\nWe will cover a lot of different topics in this course. In order of appearance, they are:\nIntroduction to NumPy\nWorking with Vectors\nUniversal Functions and Plotting\nRandomness and Statistics\nMaking and Modifying Matrices\nBroadcasting and Advanced Indexing\nBasic Linear Algebra\nUnderstanding n-dimensional Arrays\nFourier Transforms\nAdvanced Linear Algebra\nSaving and Loading Data\nBy completing our course, you will be comfortable with NumPy and have a solid foundation for topics like data science and machine learning in Python.\n\n\nStill not decided?\nThe course has a 30-day refund policy, so if you are unhappy with the course, then you can get your money back painlessly. If are still uncertain after reading this, then take a look at some of the free previews and see if you enjoy them. Hope to see you soon!",
      "target_audience": [
        "Anyone who wants to get a good understanding of NumPy.",
        "Students who want to implement topics like linear algebra, machine learning, and image processing in Python.",
        "Python developers who are curious about NumPy and data science!"
      ]
    },
    {
      "title": "Data Lake Fundamentals",
      "url": "https://www.udemy.com/course/data-lake-fundamentals-ftd/",
      "bio": "Harness the power of advanced data analytics, AI, and machine learning",
      "objectives": [
        "Data Lake architecture, principles, and component",
        "How Data Lakes differ from other architectures",
        "How to evaluate your data architecture needs",
        "Benefits, challenges, and best practices for Data Lakes",
        "Implementing Data Lakes",
        "Data Lake Security",
        "Future Trends Related to Data Lakes"
      ],
      "course_content": {
        "Introduction": [
          "Welcome and Intro",
          "What you should know",
          "Getting Started",
          "Overview of Data Lakes"
        ],
        "Understanding Data Lakes": [
          "Data Lake Architecture",
          "Principles of Data Lakes"
        ],
        "Data Lake vs. Other Architectures": [
          "Data Lake vs Data Warehouse",
          "Data Lake vs Data Swamp"
        ],
        "Implementing Data Lake Architectures": [
          "Use Cases and Evaluating Needs",
          "Data Lake Technologies and Vendors",
          "Planning Your Data Lake",
          "Selecting an Ingestion Strategy",
          "Picking Data Formats",
          "Developing a Metadata Management Strategy",
          "Selling Data Lakes to Dev Teams"
        ],
        "Challenges and Best Practices": [
          "Security Considerations",
          "Benefits, Challenges, and Best Practices"
        ],
        "Looking Ahead": [
          "Trends and Future Outlook",
          "Final Thoughts"
        ],
        "Real-World Applications": [
          "Dustin Vannoy on Data Lakes"
        ]
      },
      "requirements": [
        "No prior data experience necessary"
      ],
      "description": "Discover the Depths of Data with Our Data Lake Fundamentals Course\n\n\nIn the era of big data, understanding the intricate world of data lakes is essential for anyone looking to harness the power of data analytics, AI, and machine learning. Our Data Lake Fundamentals course is your gateway to mastering the architecture, management, and strategic utilization of data lakes. Whether you're a data scientist, a business analyst, or a developer, this course will equip you with the knowledge and skills you need to navigate the vast seas of digital data.\n\n\nWhy Enroll in Data Lake Fundamentals?\n\n\nComprehensive Curriculum: Dive into every aspect of data lakes, from their architecture and components to advanced analytics and emerging trends. Our course is designed to cover the essentials and beyond, ensuring you're well-equipped for the data-driven challenges of today and tomorrow.\nExpert Instructors: Learn from seasoned professionals with real-world experience in designing, implementing, and managing data lakes across various industries. Our instructors bring insights from the frontline, offering practical knowledge and tips you won't find anywhere else.\nFuture-Proof Your Career: Data is the currency of the digital age. By understanding data lakes, you're not just enhancing your resume; you're ensuring your place in the future of technology and business.\n\n\nCourse Highlights:\n\n\nData Lake Architecture: Unpack the layers and components that make up a data lake, understanding how they work together to store and process vast amounts of data.\nIngestion and Storage Strategies: Master the techniques for efficiently ingesting and storing data, choosing the right formats, and organizing your data lake for optimal access and analysis.\nSecurity and Governance: Navigate the crucial aspects of data security, privacy, and governance. Learn how to safeguard your data lake against threats and ensure compliance with global regulations.\nEmerging Technologies and Trends: Stay ahead of the curve with insights into the latest in data lake technologies, including AI integration, real-time analytics, and the evolution of Data Lakehouse architectures.\n\n\nJoin Us and Unlock the Power of Your Data!\n\n\nReady to dive in? Enroll in our Data Lake Fundamentals course today and embark on a journey that will transform the way you view, manage, and leverage data. Whether you're looking to advance your career, drive your business forward, or simply satisfy your curiosity about the world of data, this course is for you.",
      "target_audience": [
        "Data Executives",
        "Technology Leaders",
        "Data Professionals",
        "Data Architects",
        "Solution Architects",
        "Infrastructure Engineers"
      ]
    },
    {
      "title": "Data Science: Bitcoin Data Visualization & Price Prediction",
      "url": "https://www.udemy.com/course/cryptocurrency-data-visualization-bitcoin-price-prediction/",
      "bio": "Data Science: Hands-on & Practical Cryptocurrency Data Visualization & Bitcoin Price Forecasting using Machine Learning",
      "objectives": [
        "Learn to Visualize the entire Cryptocurrency Market using Candlesticks charts, Area graph, Line graph, Scatter plot, Box plot, Violin plot and Pie chart.",
        "Learn to Create a a Machine learning Time series Facebook Prophet Model",
        "Learn to Forecast the Price of Bitcoin 30 days into the Future using Facebook Prophet",
        "Financial Data Extraction using Google Finance within Google Sheets",
        "Learn to Create Excellent quality graphs and charts with just one line of code that will make your audience go \"WOW\"",
        "Financial Data Visualization"
      ],
      "course_content": {
        "Importing all the necessary Libraries and Dataset into the Colab environment": [
          "Project Overview & Importing all the necessary Libraries",
          "Importing the Dataset & Exploring it"
        ],
        "Cryptocurrency Data Visualization using Plotly Express": [
          "Visualizing Dataset- Table",
          "Visualizing Price and Volume- Violin plot, Box plot, Pie chart",
          "Visualizing the entire Cryptocurrency market-Scatter Plot"
        ],
        "Crypto Specific Data Visualization- Bitcoin": [
          "Importing the Bitcoin Dataset",
          "Bitcoin Data Visualization- Area graph, Line graph and Violin Plot",
          "Bitcoin Financial Data Visualization- Candlestick Charts"
        ],
        "Facebook Prophet Modelling and Forecasting": [
          "Facebook Prophet- An Introduction",
          "Data Preparation",
          "Modelling-Facebook Prophet Time series Model Creation",
          "Forecasting",
          "Downloading the Forecast data in Csv Format"
        ],
        "Forecast Evaluation using Google Sheets": [
          "Forecast Evaluation using Google Sheets"
        ]
      },
      "requirements": [
        "Basic knowledge of Python Programming is recommended but if you have no prior experience, you will be able to complete this project as is it beginner friendly"
      ],
      "description": "On 16th March 2020, Bitcoin was $5000. Today, Just 1 year later, Bitcoin was trading over $60,000 during its peak which is more than 1200% return in just 1 year. Just Imagine, if you had invested in Bitcoin 1 year ago, you would have multiplied your wealth by 12 times.\n\n\nMissed it? Well, that was past. Now let’s talk about the FUTURE.\n\n\nWhat if we knew what the Price of Bitcoin could be 30 days from now?\nWhat if there was a way to predict the price of Bitcoin a few weeks into the future?\n\n\nWith the advancement in Machine Learning and Time-series Forecasting, we can actually predict the price of Bitcoin or any other cryptocurrency or perhaps even your favourite stocks like TSLA, AAPL, AMZN, GOOG with fairly good accuracy.\n\n\nSo,\n\n\nWould you like to learn to build a Facebook Prophet Machine Learning Model inorder to Forecast the Price of Bitcoin 30 days into the future?\nWould you like to learn to Visualize the entire market of Cryptocurrencies in order to find hidden patterns?\nWould you like to trade Cryptocurrencies like Bitcoin but don't know where to start?\n\n\nIf the answer to any of the questions is \"YES\" then this course is for you.\n\n\nThis is a Practical, Hands-on, Guided Course where you will be writing the codes alongside the lectures and Visualizing Cryptocurrencies using Plotly Express and Predicting the price of Bitcoin 30 days into the Future using Facebook Prophet Time-series Machine Learning Algorithm.\n\n\nLet AI (not gurus) tell you which coin to buy and which not to buy. Explore the Entire Cryptocurrency market and learn to Visualize and Forecast the Price of Bitcoin. Learn to use AI & Data science to decide What to buy (using Data Visualization) and when to buy (Machine learning Forecasting).\n\n\nThis is the only course in Bitcoin and Cryptocurrency that you need.\n\n\nIn the next 2 hours, learn practical real-life data visualization and Machine learning skills and Forecast the Price of Bitcoin 30 days into the future.\n\n\nLearn to make forecasts using Facebook Prophet\nLearn to find patterns using Data Visualization with Plotly Express with just 1 line of Code\nLearn to create Machine learning Time-series Model\n\n\nNew to Python? No problem. This course is beginner-friendly. You will learn everything you need to know. I will guide you through every single line of code and every single step. No extra software needed. You just need a reliable Internet connection and you are good to go.\n\n\nWhat will you learn?\n\n\nImporting all the necessary libraries including Facebook Prophet for Forecasting and Plotly Express for Data Visualization\nImporting the Dataset and Exploring it\nVisualizing the 5 years Historical Performance of 12 Major Cryptocurrencies using Box plot, Pie Chart & Violin plot\nComparing all the major Cryptocurrencies using Scatter Plots\nBitcoin Data Visualization - Visualizing historical Volume & Price using Area graph, Line Graph, Violin Chart\nBitcoin Financial Data Visualization- creating a Candlestick chart\nIntroduction to Facebook Prophet- Everything you need to know\nData Preparation\nFacebook Prophet Time-series Model Creation\nForecasting the Price of Bitcoin 30 days into the future\nDownloading the Forecast Data for Proper evaluation\nExtracting the Actual Price of Bitcoin using Google Finance within Google Sheets\nComparing the Forecast Price against the Actual Price of Bitcoin\n\n\nWe will be using 5-year Historical Data (Daily Price & Volume) of 12 Major Cryptocurrencies that represents well over 95% of the Cryptocurrency Market: Bitcoin, Litecoin, Ethereum, Ripple, Dash, Tether, Tron, Stellar, Bitcoin Cash, Binance coin, Cardano & Chainlink.\n\n\nSo What are you waiting for?\n\n\nGrab a Coffee, Open your Laptop and click on the \"Enroll Now\" button and get this course right now.\n\n\nP.S: Although this course deals in Cryptocurrencies and teaches you to Forecast the Price of Bitcoin, it should be noted that this course is for educational purposes only and is not a piece of Financial Advice. Our goal as Instructors is to provide you with skill so that you can make an informed decision.\n\n\nAll the best and Happy Learning.",
      "target_audience": [
        "Anyone who is interested in Cryptocurrencies",
        "Anyone who wants to learn to create a Machine learning Time series Facebook Prophet Model",
        "Anyone who is interested in Machine Learning",
        "Anyone who is interested in Data Visualization",
        "Anyone who is interested in Facebook Prophet",
        "Anyone who wants to learn how to Forecast the price of Bitcoin 30 days into the future",
        "Cryptocurrency Investors and Traders",
        "Bitcoin Day Traders"
      ]
    },
    {
      "title": "Python for Data Science: Learn Data Science From Scratch",
      "url": "https://www.udemy.com/course/python-for-data-science-learn-data-science-from-scratch/",
      "bio": "Data Science with Python, NumPy, Pandas, Matplotlib, Data Visualization Learn with Data Science project & Python project",
      "objectives": [
        "Fundamentals of Pandas Library (Data science, Python data science, data science project, python project)",
        "Learn Fundamentals of Python for effectively using Data Science",
        "Installation of Anaconda and how to use for Python, Pandas, Numpy",
        "Using Jupyter notebook",
        "Numpy arrays",
        "Series and Features in Python for Data science, numpy and pandas",
        "Combining Dataframes, Data Munging and how to deal with Missing Data",
        "How to use Matplotlib library and start to journey in Data Visualization",
        "Also, why you should learn Python and Pandas Library (numpy, pandas, python numpy pandas)",
        "Learn Data Science with Python, Numpy and pandas",
        "OAK offers highly-rated data science courses that will help you learn how to visualize and respond to new data, as well as develop innovative new technologies",
        "Whether you’re interested in machine learning, data mining, or data analysis, Udemy has a course for you.",
        "Data science is everywhere. Better data science practices are allowing corporations to cut unnecessary costs, automate computing, and analyze markets.",
        "Data science is the key to getting ahead in a competitive global climate.",
        "Data science uses algorithms to understand raw data. The main difference between data science and traditional data analysis is its focus on prediction.",
        "Data Scientists use machine learning to discover hidden patterns in large amounts of raw data to shed light on real problems.",
        "Python is the most popular programming language for data science. It is a universal language that has a lot of libraries available.",
        "Data science requires lifelong learning, so you will never really finish learning.",
        "It is possible to learn data science on your own, as long as you stay focused and motivated. Luckily, there are a lot of online courses and boot camps available",
        "Some people believe that it is possible to become a data scientist without knowing how to code, but others disagree.",
        "A data scientist requires many skills. They need a strong understanding of statistical analysis and mathematics, which are essential pillars of data science.",
        "The demand for data scientists is growing. We do not just have data scientists; we have data engineers, data administrators, and analytics managers."
      ],
      "course_content": {
        "Data Science: Python is Easy To Learn, Data science Project": [
          "Be Smart and Use Data But How: Answer is Data Science with Python",
          "FAQ regarding Data Science with Numpy, Pandas",
          "FAQ regarding Python with Numpy, Pandas",
          "Project Files and Course Documents for Python Data Science, Numpy, Pandas Course"
        ],
        "Data Science: Setting Up Python for Mac and Windows": [
          "Python: Installing Anaconda for Windows",
          "Python: Installing Anaconda for Mac",
          "Ptyhon: Let's Meet Jupyter Notebook for Windows",
          "Python: Basics of Jupyter Notebook for Mac"
        ],
        "Fundamentals of Python": [
          "Data Types in Python",
          "Operators in Python",
          "Conditionals in Python",
          "Loops in Python",
          "Lists, Tuples, Dictionaries and Sets in Python",
          "Data Type Operators and Methods in Python",
          "Modules in Python",
          "Functions in Python",
          "Exercise Analyse in Python",
          "Exercise Solution in Python",
          "Quiz"
        ],
        "Python For Data Science: Data Science": [
          "What Is Data Science?",
          "Data Literacy",
          "Python Data Science Quiz"
        ],
        "Using Numpy for Data Manipulation": [
          "Introduction to NumPy Library",
          "Notebook Project Files Link regarding NumPy Python Programming Language Library",
          "The Power of NumPy",
          "6 Article Advice And Links about Numpy, Numpy Pyhon",
          "Creating NumPy Array with The Array() Function",
          "Creating NumPy Array with Zeros() Function",
          "Creating NumPy Array with Ones() Function",
          "Creating NumPy Array with Full() Function",
          "Creating NumPy Array with Arange() Function",
          "Creating NumPy Array with Eye() Function",
          "Creating NumPy Array with Linspace() Function",
          "Creating NumPy Array with Random() Function",
          "Properties of NumPy Array",
          "Reshaping a NumPy Array: Reshape() Function",
          "Identifying the Largest Element of a Numpy Array",
          "Detecting Least Element of Numpy Array: Min(), Ar",
          "Concatenating Numpy Arrays: Concatenate() Functio",
          "Splitting One-Dimensional Numpy Arrays: The Split",
          "Splitting Two-Dimensional Numpy Arrays: Split(),",
          "Sorting Numpy Arrays: Sort() Function",
          "Indexing Numpy Arrays",
          "Slicing One-Dimensional Numpy Arrays",
          "Slicing Two-Dimensional Numpy Arrays",
          "Assigning Value to One-Dimensional Arrays",
          "Assigning Value to Two-Dimensional Array",
          "Fancy Indexing of One-Dimensional Arrrays",
          "Fancy Indexing of Two-Dimensional Arrrays",
          "Combining Fancy Index with Normal Indexing",
          "Combining Fancy Index with Normal Slicing",
          "Operations with Comparison Operators",
          "Arithmetic Operations in Numpy",
          "Statistical Operations in Numpy",
          "Solving Second-Degree Equations with NumPy",
          "Numpy Quiz"
        ],
        "(Optional) Recap, Exercises, and Bonus İnfo from the Numpy Library": [
          "What is Numpy?",
          "Array and Features in Numpy",
          "Array Operators in Numpy",
          "Indexing and Slicing in Numpy",
          "Numpy Exercises",
          "Quiz"
        ],
        "Pandas: Using Pandas for Data Manipulation": [
          "Introduction to Pandas Library",
          "Pandas Project Files Link",
          "Creating a Pandas Series with a List",
          "Creating a Pandas Series with a Dictionary",
          "Creating Pandas Series with NumPy Array",
          "Object Types in Series",
          "Examining the Primary Features of the Pandas Series",
          "Most Applied Methods on Pandas Series",
          "Indexing and Slicing Pandas Series",
          "Creating Pandas DataFrame with List",
          "Creating Pandas DataFrame with NumPy Array",
          "Creating Pandas DataFrame with Dictionary",
          "Examining the Properties of Pandas DataFrames",
          "Element Selection Operations in Pandas DataFrames: Lesson 1",
          "Element Selection Operations in Pandas DataFrames: Lesson 2",
          "Top Level Element Selection in Pandas DataFrames: Lesson 1",
          "Top Level Element Selection in Pandas DataFrames: Lesson 2",
          "Top Level Element Selection in Pandas DataFrames: Lesson 3",
          "Element Selection with Conditional Operations in Pandas Data Frames",
          "Adding Columns to Pandas Data Frames",
          "Removing Rows and Columns from Pandas Data frames",
          "Null Values in Pandas Dataframes",
          "Dropping Null Values: Dropna() Function",
          "Filling Null Values: Fillna() Function",
          "Setting Index in Pandas DataFrames",
          "Multi-Index and Index Hierarchy in Pandas DataFrames",
          "Element Selection in Multi-Indexed DataFrames",
          "Selecting Elements Using the xs() Function in Multi-Indexed DataFrames",
          "Concatenating Pandas Dataframes: Concat () Function",
          "Merge Pandas Dataframes: Merge() Function: Lesson 1",
          "Merge Pandas Dataframes: Merge() Function: Lesson 2",
          "Merge Pandas Dataframes: Merge() Function: Lesson 3",
          "Merge Pandas Dataframes: Merge() Function: Lesson 4",
          "Joining Pandas Dataframes: Join() Function",
          "Loading a Dataset from the Seaborn Library",
          "Examining the Data Set 1",
          "Aggregation Functions in Pandas DataFrames",
          "Examining the Data Set 2",
          "Coordinated Use of Grouping and Aggregation Functions in Pandas Dataframes",
          "Advanced Aggregation Functions: Aggregate() Function",
          "Advanced Aggregation Functions: Filter() Function",
          "Advanced Aggregation Functions: Transform() Function",
          "Advanced Aggregation Functions: Apply() Function",
          "Examining the Data Set 3",
          "Pivot Tables in Pandas Library",
          "Accessing and Making Files Available",
          "Data Entry with Csv and Txt Files",
          "Data Entry with Excel Files",
          "Outputting as an CSV Extension",
          "Outputting as an Excel File",
          "Pandas Quiz"
        ],
        "(Optional) Recap, Exercises, and Bonus İnfo from the Pandas Library": [
          "What is Pandas?",
          "Series and Features in Pandas",
          "Data Frame Attributes and Methods in Pandas",
          "Data Frame Attributes and Methods Part – II in Pandas",
          "Data Frame Attributes and Methods Part – III in Pandas",
          "Multi Index in Pandas",
          "Groupby Operations in Pandas",
          "Missing Data and Data Munging in Pandas",
          "Missing Data and Data Munging Part II in Pandas",
          "How We Deal with Missing Data?",
          "Combining Data Frames in Pandas",
          "Combining Data Frames Part – II in Pandas",
          "Work with Dataset Files in Pandas",
          "Pandas Quiz"
        ],
        "Python For Data Science: Data Visualization": [
          "What is Matplotlib?",
          "Using Matplotlib",
          "Pyplot – Pylab - Matplotlib",
          "Figure, Subplot and Axes in Matplotlib",
          "Figure Customization in Matplotlib",
          "Plot Customization in Matplotlib",
          "Quiz"
        ],
        "Data Science: Hands-On Projects": [
          "Analyse Data With Different Data Sets: Titanic Project",
          "Titanic Project Answers in Data Science project",
          "Data Science Project II: Bike Sharing",
          "Bike Sharing Project Answers in Data Science project",
          "Data Science Project III: Housing and Property Sales",
          "Answer for Housing and Property Sales Project",
          "Data Science Project IV : English Premier League",
          "Answers for English Premier League Project"
        ]
      },
      "requirements": [
        "No prior data science, python knowledge is required",
        "Free software and tools used during the python data science course",
        "Basic computer knowledge",
        "Desire to learn data science",
        "Curiosity for python programming",
        "Desire to learn Python",
        "Desire to work on data science Project",
        "Desire to learn python with numpy, pandas, matplotlib",
        "Desire to learn python data science with python, numpy, pandas, matplotlib",
        "LIFETIME ACCESS, course updates, new content, anytime, anywhere, on any device",
        "Nothing else! It’s just you, your computer and your ambition to get started today"
      ],
      "description": "Hello there,\nWelcome to my \"Python for Data Science: Learn Data Science From Scratch\" course.\nData science, data science Project, data science projects, data science from scratch, data science using python, python for data science, python data science, Numpy, pandas, matplotlib\nData Science with Python, NumPy, Pandas, Matplotlib, Data Visualization Learn with Data Science project & Python project\nOAK Academy offers highly-rated data science courses that will help you learn how to visualize and respond to new data, as well as develop innovative new technologies. Whether you’re interested in machine learning, data mining, or data analysis, Udemy has a course for you. data literacy, python, data science python, pandas Project, python data science projects, data, data science with Project, pandas projects, pandas, data science with python, NumPy\nData science is everywhere. Better data science practices are allowing corporations to cut unnecessary costs, automate computing, and analyze markets. Essentially, data science is the key to getting ahead in a competitive global climate.\nPython instructors at OAK Academy specialize in everything from software development to data analysis and are known for their effective, friendly instruction for students of all levels.\nWhether you work in machine learning or finance or are pursuing a career in web development or data science, Python is one of the most important skills you can learn. Python's simple syntax is especially suited for desktop, web, and business applications. Python's design philosophy emphasizes readability and usability. Python was developed upon the premise that there should be only one way (and preferably one obvious way) to do things, a philosophy that has resulted in a strict level of code standardization. The core programming language is quite small and the standard library is also large. In fact, Python's large library is one of its greatest benefits, providing a variety of different tools for programmers suited for many different tasks.\n\nReady for a Data Science career?\nAre you curious about Data Science and looking to start your self-learning journey into the world of data with Python?\nAre you an experienced developer looking for a landing in Data Science!\nIn both cases, you are at the right place!\nWelcome to Python for Data Science: Learn Data Science From Scratch course\nPython is the most popular programming language for the data science process in recent years and also do not forget that data scientist has been ranked the number one job on several job search sites!  With Python skills, you will encounter many businesses that use Python and its libraries for data science. Almost all companies working on machine learning and data science use Python’s Pandas library. Thanks to the large libraries provided, The number of companies and enterprises using Python is increasing day by day. The world we are in is experiencing the age of informatics. Python and its Pandas library will be the right choice for you to take part in this world and create your own opportunities,\nIn this course, we will open the door of the Data Science world and will move deeper.  You will learn the fundamentals of Python and its beautiful libraries such as Numpy, Pandas, and Matplotlib step by step.\nThroughout the course, we will teach you how to use Python to analyze data, create beautiful visualizations, and use powerful machine learning algorithms and we will also do a variety of exercises to reinforce what we have learned in this Python for Data Science course.\n\n\nIn this course you will learn;\nHow to use Anaconda and Jupyter notebook,\nFundamentals of Python such as\nDatatypes in Python,\nLots of datatype operators, methods, and how to use them,\nConditional concept, if statements\nThe logic of Loops and control statements\nFunctions and how to use them\nHow to use modules and create your own modules\nData science and Data literacy concepts\nFundamentals of Numpy for Data manipulation such as\nNumpy arrays and their features\nHow to do indexing and slicing on Arrays\nLots of stuff about Pandas for data manipulation such as\nPandas series and their features\nDataframes and their features\nHierarchical indexing concept and theory\nGroupby operations\nThe logic of Data Munging\nHow to deal effectively with missing data effectively\nCombining the Data Frames\nHow to work with Dataset files\nAnd also you will learn fundamentals thing about Matplotlib library such as\nPyplot, Pylab and Matplotlib concepts\nWhat Figure, Subplot and Axes are\nHow to do figure and plot customization\nData science project\nPython Projects\nPandas projects\nPython data science Projects\nData literacy\nFull stack data science\nAnd we will do many exercises.  Finally, we will also have 4 different final projects covering all of these subjects.\nWhy would you want to take this course?\nWe have prepared this course in the simplest way for beginners and have prepared many different exercises to help them understand better.\nNo prior knowledge is needed!\nIn this course, you need no previous knowledge about Python, Pandas or Data Science.\nThis course will take you from a beginner to a more experienced level.\nIf you are new to data science or have no idea about what data science does no problem, you will learn anything you need to start data science.\nIf you are a software developer or familiar with other programming languages and you want to start a new world, you are also in the right place. You will learn step by step with hands-on examples.\n\nWhat is data science?\nWe have more data than ever before. But data alone cannot tell us much about the world around us. We need to interpret the information and discover hidden patterns. This is where data science comes in. Data science python uses algorithms to understand raw data. The main difference between data science and traditional data analysis is its focus on prediction. Python data science seeks to find patterns in data and use those patterns to predict future data. It draws on machine learning to process large amounts of data, discover patterns, and predict trends. Data science using python includes preparing, analyzing, and processing data. It draws from many scientific fields, and as a python for data science, it progresses by creating new algorithms to analyze data and validate current methods.\nWhat does a data scientist do?\nData Scientists use machine learning to discover hidden patterns in large amounts of raw data to shed light on real problems. This requires several steps. First, they must identify a suitable problem. Next, they determine what data are needed to solve such a situation and figure out how to get the data. Once they obtain the data, they need to clean the data. The data may not be formatted correctly, it might have additional unnecessary data, it might be missing entries, or some data might be incorrect. Data Scientists must, therefore, make sure the data is clean before they analyze the data. To analyze the data, they use machine learning techniques to build models. Once they create a model, they test, refine, and finally put it into production.\nWhat are the most popular coding languagws for data science?\nPython for data science is the most popular programming language for data science. It is a universal language that has a lot of libraries available. It is also a good beginner language. R is also popular; however, it is more complex and designed for statistical analysis. It might be a good choice if you want to specialize in statistical analysis. You will want to know either Python or R and SQL. SQL is a query language designed for relational databases. Data scientists deal with large amounts of data, and they store a lot of that data in relational databases. Those are the three most-used programming languages. Other languages such as Java, C++, JavaScript, and Scala are also used, albeit less so. If you already have a background in those languages, you can explore the tools available in those languages. However, if you already know another programming language, you will likely be able to pick up.\nHow long does it take to become a data scientist?\nThis answer, of course, varies. The more time you devote to learning new skills, the faster you will learn. It will also depend on your starting place. If you already have a strong base in mathematics and statistics, you will have less to learn. If you have no background in statistics or advanced mathematics, you can still become a data scientist; it will just take a bit longer. Data science requires lifelong learning, so you will never really finish learning. A better question might be, \"How can I gauge whether I know enough to become a data scientist?\" Challenge yourself to complete data science projects using open data. The more you practice, the more you will learn, and the more confident you will become. Once you have several projects that you can point to as good examples of your skillset as a data scientist, you are ready to enter the field.\nHow can ı learn data science on my own?\nIt is possible to learn data science projects on your own, as long as you stay focused and motivated. Luckily, there are a lot of online courses and boot camps available. Start by determining what interests you about data science. If you gravitate to visualizations, begin learning about them. Starting with something that excites you will motivate you to take that first step. If you are not sure where you want to start, try starting with learning Python. It is an excellent introduction to programming languages and will be useful as a data scientist. Begin by working through tutorials or Udemy courses on the topic of your choice. Once you have developed a base in the skills that interest you, it can help to talk with someone in the field. Find out what skills employers are looking for and continue to learn those skills. When learning on your own, setting practical learning goals can keep you motivated.\nDoes data science require coding?\nThe jury is still out on this one. Some people believe that it is possible to become a data scientist without knowing how to code, but others disagree. A lot of algorithms have been developed and optimized in the field. You could argue that it is more important to understand how to use the algorithms than how to code them yourself. As the field grows, more platforms are available that automate much of the process. However, as it stands now, employers are primarily looking for people who can code, and you need basic programming skills. The data scientist role is continuing to evolve, so that might not be true in the future. The best advice would be to find the path that fits your skillset.\nWhat skills should a data scientist know?\nA data scientist requires many skills. They need a strong understanding of statistical analysis and mathematics, which are essential pillars of data science. A good understanding of these concepts will help you understand the basic premises of data science. Familiarity with machine learning is also important. Machine learning is a valuable tool to find patterns in large data sets. To manage large data sets, data scientists must be familiar with databases. Structured query language (SQL) is a must-have skill for data scientists. However, nonrelational databases (NoSQL) are growing in popularity, so a greater understanding of database structures is beneficial. The dominant programming language in Data Science is Python — although R is also popular. A basis in at least one of these languages is a good starting point. Finally, to communicate findings.\nIs data science a good career?\nThe demand for data scientists is growing. We do not just have data scientists; we have data engineers, data administrators, and analytics managers. The jobs also generally pay well. This might make you wonder if it would be a promising career for you. A better understanding of the type of work a data scientist does can help you understand if it might be the path for you. First and foremost, you must think analytically. Data science from scratch is about gaining a more in-depth understanding of info through data. Do you fact-check information and enjoy diving into the statistics? Although the actual work may be quite technical, the findings still need to be communicated. Can you explain complex findings to someone who does not have a technical background? Many data scientists work in cross-functional teams and must share their results with people with very different backgrounds.\n\nWhat is python?\nMachine learning python is a general-purpose, object-oriented, high-level programming language. Whether you work in artificial intelligence or finance or are pursuing a career in web development or data science, Python bootcamp is one of the most important skills you can learn. Python's simple syntax is especially suited for desktop, web, and business applications. Python's design philosophy emphasizes readability and usability. Python was developed on the premise that there should be only one way (and preferably, one obvious way) to do things, a philosophy that resulted in a strict level of code standardization. The core programming language is quite small and the standard library is also large. In fact, Python's large library is one of its greatest benefits, providing different tools for programmers suited for a variety of tasks.\nPython vs. R: What is the Difference?\nPython and R are two of today's most popular programming tools. When deciding between Python and R in data science , you need to think about your specific needs. On one hand, Python is relatively easy for beginners to learn, is applicable across many disciplines, has a strict syntax that will help you become a better coder, and is fast to process large datasets. On the other hand, R has over 10,000 packages for data manipulation, is capable of easily making publication-quality graphics, boasts superior capability for statistical modeling, and is more widely used in academia, healthcare, and finance.\nWhat does it mean that Python is object-oriented?\nPython is a multi-paradigm language, which means that it supports many data analysis programming approaches. Along with procedural and functional programming styles, Python also supports the object-oriented style of programming. In object-oriented programming, a developer completes a programming project by creating Python objects in code that represent objects in the actual world. These objects can contain both the data and functionality of the real-world object. To generate an object in Python you need a class. You can think of a class as a template. You create the template once, and then use the template to create as many objects as you need. Python classes have attributes to represent data and methods that add functionality. A class representing a car may have attributes like color, speed, and seats and methods like driving, steering, and stopping.\nWhat are the limitations of Python?\nPython is a widely used, general-purpose programming language, but it has some limitations. Because Python in machine learning is an interpreted, dynamically typed language, it is slow compared to a compiled, statically typed language like C. Therefore, Python is useful when speed is not that important. Python's dynamic type system also makes it use more memory than some other programming languages, so it is not suited to memory-intensive applications. The Python virtual engine that runs Python code runs single-threaded, making concurrency another limitation of the programming language. Though Python is popular for some types of game development, its higher memory and CPU usage limits its usage for high-quality 3D game development. That being said, computer hardware is getting better and better, and the speed and memory limitations of Python are getting less and less relevant.\nHow is Python used?\nPython is a general programming language used widely across many industries and platforms. One common use of Python is scripting, which means automating tasks in the background. Many of the scripts that ship with Linux operating systems are Python scripts. Python is also a popular language for machine learning, data analytics, data visualization, and data science because its simple syntax makes it easy to quickly build real applications. You can use Python to create desktop applications. Many developers use it to write Linux desktop applications, and it is also an excellent choice for web and game development. Python web frameworks like Flask and Django are a popular choice for developing web applications. Recently, Python is also being used as a language for mobile development via the Kivy third-party library.\nWhat jobs use Python?\nPython is a popular language that is used across many industries and in many programming disciplines. DevOps engineers use Python to script website and server deployments. Web developers use Python to build web applications, usually with one of Python's popular web frameworks like Flask or Django. Data scientists and data analysts use Python to build machine learning models, generate data visualizations, and analyze big data. Financial advisors and quants (quantitative analysts) use Python to predict the market and manage money. Data journalists use Python to sort through information and create stories. Machine learning engineers use Python to develop neural networks and artificial intelligent systems.\nHow do I learn Python on my own?\nPython has a simple syntax that makes it an excellent programming language for a beginner to learn. To learn Python on your own, you first must become familiar with the syntax. But you only need to know a little bit about Python syntax to get started writing real code; you will pick up the rest as you go. Depending on the purpose of using it, you can then find a good Python tutorial, book, or course that will teach you the programming language by building a complete application that fits your goals. If you want to develop games, then learn Python game development. If you're going to build web applications, you can find many courses that can teach you that, too. Udemy’s online courses are a great place to start if you want to learn Python on your own.\nYou'll also get:\nLifetime Access to The Course\nFast & Friendly Support in the Q&A section\nUdemy Certificate of Completion Ready for Download\nDive in now Python for Data Science: Learn Data Science From Scratch course\nWe offer full support, answering any questions.\nSee you in the Python for Data Science: Learn Data Science From Scratch course!",
      "target_audience": [
        "Anyone who wants to learn data science,",
        "Anyone who plans a career in data scientist,",
        "Software developer whom want to learn python data science,",
        "Anyone eager to learn Data Science python with no coding background",
        "Anyone eager to learn Python with no coding background",
        "Anyone who wants to learn Pandas",
        "Anyone who wants to learn Numpy",
        "Anyone who wants to learn Matplotlib",
        "Anyone who wants to work on real data science project",
        "Anyone who wants to learn data visualization projects.",
        "people who want to learn python projects, data science projects"
      ]
    },
    {
      "title": "Data Analytics and Artificial Intelligence for Beginners",
      "url": "https://www.udemy.com/course/data-analytics-and-artificial-intelligence-for-beginners/",
      "bio": "Learn the basic concepts of data analytics, AI, business intelligence, big data, machine learning, and deep learning.",
      "objectives": [
        "A brief overview of the history of analyzing data, from medieval statistics to the sophisticated techniques developed by the likes of Google and Microsoft.",
        "A look at data stores, which are growing exponentially, and the challenges of wrangling “big data.”",
        "Understanding of data mining—what it entails, different approaches, and who’s leading the way.",
        "A two-part discussion of business intelligence, including the principles of sound dashboard design and data presentation.",
        "The key differences between the four types of analytics—diagnostic, descriptive, predictive, and prescriptive",
        "An overview of specific analytics processes and models.",
        "A first look at AI, its evolution, its functions, and what it can do for businesses today.",
        "An exploration of machine learning—how systems can learn from data, identify patterns, and make decisions with little human intervention.",
        "A survey of deep learning technologies, including a variety of neural networks.",
        "An overview of the most important machine learning data modeling techniques",
        "A practical and honest appraisal of the analytics and AI landscape today and moving forward, including the tremendous promise and the potential pitfalls.",
        "Resources for continued study on these topics."
      ],
      "course_content": {
        "Analytics Beginnings": [
          "Introduction",
          "WATCH ME: Essential Information for a Successful Training Experience",
          "DOWNLOAD ME: Course Instructor Files",
          "DOWNLOAD ME: Course Exercise Files",
          "History of Analytics",
          "Introduction to Data and Big Data",
          "Data Mining - Part 1",
          "Data Mining - Part 2",
          "Business Intelligence - Part 1",
          "Business Intelligence - Part 2",
          "4 Types of Analytics",
          "Types of Analytics Methods",
          "Section Quiz"
        ],
        "Artificial Intelligence": [
          "Artificial Intelligence - Part 1",
          "Artificial Intelligence - Part 2",
          "Machine Learning - Part 1",
          "Machine Learning - Part 2",
          "Deep Learning",
          "Other AI Analytics Techniques - Part 1",
          "Other AI Analytics Techniques - Part 2",
          "Other AI Analytics Techniques - Part 3",
          "Conclusion",
          "Section Quiz"
        ],
        "Exercise & Course Close": [
          "Exercise 1",
          "Course Close"
        ]
      },
      "requirements": [
        "No prior knowledge required. This course is suitable for beginners"
      ],
      "description": "**This course includes downloadable exercise files to work with**\n\n\nThe richest data store is only as good as your ability to search, sort, analyze, and present the data within it. This introductory-level course will give students a broad overview of the theory and practice of data analytics and the many ways in which artificial intelligence (AI) contributes to it.\n\n\nYour instructor will begin with a brief history of data analytics and then proceed into discussions of data warehouses, data mining, business intelligence, machine learning, and other emerging AI techniques to make sense of big data.\n\n\nStudents will learn how data is captured, cleansed, analyzed, and presented on business intelligence dashboards that captivate and persuade an audience. “It is a capital mistake to theorize before one has data,\" Sherlock Holmes once said.\n\n\nWhether you are investigating analytics as a potential career move or wish to better understand the terminology you encounter with increasing frequency in your professional circles, this course will give you the foundation you are looking for.\n\n\nThis program includes 3 hours of instruction and a practice-based assessment, which will help students simulate real-world data analytics scenarios that are critical for success in today's increasingly complex workplace.\n\n\nStudents will gain:\nA brief overview of the history of analyzing data, from medieval statistics to the sophisticated techniques developed by the likes of Google and Microsoft.\nA look at data stores, which are growing exponentially, and the challenges of wrangling “big data.”\nUnderstanding of data mining—what it entails, different approaches, and who’s leading the way.\nA two-part discussion of business intelligence, including the principles of sound dashboard design and data presentation.\nThe key differences between the four types of analytics—diagnostic, descriptive, predictive, and prescriptive—and how they relate to and build upon each other, and how they apply to various industries.\nAn overview of specific analytics processes and models.\nA first look at AI, its evolution, its functions, and what it can do for businesses today.\nAn exploration of machine learning—how systems can learn from data, identify patterns, and make decisions with little human intervention.\nA survey of deep learning technologies, including a variety of neural networks.\nAn overview of the most important machine learning data modeling techniques\nA practical and honest appraisal of the analytics and AI landscape today and moving forward, including the tremendous promise and the potential pitfalls.\nResources for continued study on these topics.\n\n\nThis course includes:\n3 hours of video tutorials\n20 individual video lectures\nCourse and Exercise files to follow along\nCertificate of completion",
      "target_audience": [
        "People who want to start their careers in data analytics",
        "Those who want to learn the basic concepts of data analytics and AI",
        "Individuals who want to kickstart their data science skills"
      ]
    },
    {
      "title": "100 Days Data Science Bootcamp: Build 100 Real Life Projects",
      "url": "https://www.udemy.com/course/real-world-data-science-projects/",
      "bio": "Build & Deploy Data Science, Machine Learning, Deep Learning (Python, Flask, Django, AWS, Azure, GCP, Heruko Cloud)",
      "objectives": [
        "Conduct feature engineering on real world case studies",
        "Make powerful analysis, Make robust Machine Learning models",
        "Make robust Machine Learning models, Master Machine Learning on Python",
        "Real life case studies and projects to understand how things are done in the real world",
        "Implement Machine Learning Algorithms",
        "Learn to perform Classification and Regression modelling",
        "Know which Machine Learning model to choose for each type of problem",
        "Understand the full product workflow for the machine learning lifecycle."
      ],
      "course_content": {
        "Introduction": [
          "Introduction To The Course",
          "Course Outline Video",
          "Course Bonuses: Cheat Sheets, Downloads, Mind maps, Guides.",
          "Udemy Course Feedback"
        ],
        "Project-1: Pan Card Tempering Detector App -Deploy On Heroku": [
          "Introduction",
          "Loading Libraries and Dataset",
          "Creating the Pan Card Detector with Opencv",
          "Creating the Flask App",
          "Creating important Functions",
          "Deploy the App in Heroku",
          "Testing the Deployed Pan Card Detector",
          "Download The Project Files"
        ],
        "Project-2: Dog breed prediction Flask App": [
          "Introduction to Dog Breed Prediction Flask App",
          "Importing the Data and Libraries",
          "Data Preprocessing",
          "Build and Train Model",
          "Testing the Model",
          "Creating the Flask App",
          "Running the App in System",
          "Download The Project Files"
        ],
        "Project-3: Image Watermarking": [
          "Introduction",
          "Importing Libraries",
          "Create Text and image Watermark",
          "Creating the App",
          "Deploy the App in Heroku",
          "Download the project files"
        ],
        "Project-4: Traffic sign classification": [
          "Introduction to Traffic Sign Classification",
          "Importing the Data and Libraries",
          "Image Processing",
          "Creating and Testing the Model",
          "Creating Model for Test Set",
          "Download the project files"
        ],
        "Project-5: Text Extraction From Images Application": [
          "Introduction",
          "importing Libraries and Data",
          "Extracting the Test from Image",
          "Modifying the Extractor",
          "Creating the Extractor App",
          "Running the Extractor App",
          "Download The Project Files"
        ],
        "Project-6: Plant Disease Prediction Streamlit App": [
          "Introduction to Plant Disease",
          "Importing Libraries and Data",
          "Understanding the Data and Data Preprocessing",
          "Model Building",
          "Creating an App using Streamlit",
          "Download The Project Files"
        ],
        "Project-7: Vehicle Detection And Counting Flask App": [
          "Introduction",
          "Importing Libraries and Data",
          "Transforming Images and Creating Output",
          "Creating a Flask App",
          "Download The Project Files"
        ],
        "Project-8: Create A Face Swapping Flask App": [
          "Introduction",
          "Importing Libraries and data",
          "Data Preprocessing and Creating Output",
          "Creating a Flask App",
          "Download The Project Files"
        ],
        "Project-9: Bird Species Prediction Flask App": [
          "Introduction",
          "Importing libraries and Data",
          "Data Processing",
          "Creating ML Model",
          "Creating a Flask App",
          "Download The Project Files"
        ]
      },
      "requirements": [
        "Basic knowledge of machine learning"
      ],
      "description": "In This Course, Solve Business Problems Using Data Science Practically. Learn To Build & Deploy Machine Learning, Data Science, Artificial Intelligence, Auto Ml, Deep Learning, Natural Language Processing (Nlp) Web Applications Projects With Python (Flask, Django, Heroku, AWS, Azure, GCP, IBM Watson, Streamlit Cloud).\n\n\nAccording to Glassdoor, the average salary for a Data Scientist is $117,345/yr. This is above the national average of $44,564. Therefore, a Data Scientist makes 163% more than the national average salary.\nThis makes Data Science a highly lucrative career choice. It is mainly due to the dearth of Data Scientists resulting in a huge income bubble.\nSince Data Science requires a person to be proficient and knowledgeable in several fields like Statistics, Mathematics, and Computer Science, the learning curve is quite steep. Therefore, the value of a Data Scientist is very high in the market.\nA Data Scientist enjoys a position of prestige in the company. The company relies on its expertise to make data-driven decisions and enable them to navigate in the right direction.\nFurthermore, the role of a Data Scientist depends on the specialization of his employer company. For example – A commercial industry will require a data scientist to analyze their sales.\nA healthcare company will require data scientists to help them analyze genomic sequences. The salary of a Data Scientist depends on his role and type of work he has to perform. It also depends on the size of the company which is based on the amount of data they utilize.\nStill, the pay scale of Data scientists is way above other IT and management sectors. However, the salary observed by Data Scientists is proportional to the amount of work that they must put in. Data Science needs hard work and requires a person to be thorough with his/her skills.\nDue to several lucrative perks, Data Science is an attractive field. This, combined with the number of vacancies in Data Science makes it an untouched gold mine. Therefore, you should learn Data Science in order to enjoy a fruitful career.\n\n\nIn This Course, We Are Going To Work On 100 Real World Projects Listed Below:\n\n\nProject-1: Pan Card Tempering Detector App -Deploy On Heroku\nProject-2: Dog breed prediction Flask App\nProject-3: Image Watermarking App -Deploy On Heroku\nProject-4: Traffic sign classification\nProject-5: Text Extraction From Images Application\nProject-6: Plant Disease Prediction Streamlit App\nProject-7: Vehicle Detection And Counting Flask App\nProject-8: Create A Face Swapping Flask App\nProject-9: Bird Species Prediction Flask App\nProject-10: Intel Image Classification Flask App\n\n\nProject-11: Language Translator App Using IBM Cloud Service -Deploy On Heroku\nProject-12: Predict Views On Advertisement Using IBM Watson -Deploy On Heroku\nProject-13: Laptop Price Predictor -Deploy On Heroku\nProject-14: WhatsApp Text Analyzer -Deploy On Heroku\nProject-15: Course Recommendation System -Deploy On Heroku\nProject-16: IPL Match Win Predictor -Deploy On Heroku\nProject-17: Body Fat Estimator App -Deploy On Microsoft Azure\nProject-18: Campus Placement Predictor App -Deploy On Microsoft Azure\nProject-19: Car Acceptability Predictor -Deploy On Google Cloud\nProject-20: Book Genre Classification App -Deploy On Amazon Web Services\n\n\nProject 21 : DNA classification for finding E.Coli - Deploy On AWS\nProject 22 : Predict the next word in a sentence. - AWS - Deploy On AWS\nProject 23 : Predict Next Sequence of numbers using LSTM - Deploy On AWS\nProject 24 : Keyword Extraction from text using NLP - Deploy On Azure\nProject 25 : Correcting wrong spellings - Deploy On Azure\nProject 26 : Music popularity classification - Deploy On Google App Engine\nProject 27 : Advertisement Classification - Deploy On Google App Engine\nProject 28 : Image Digit Classification - Deploy On AWS\nProject 29 : Emotion Recognition using Neural Network - Deploy On AWS\nProject 30 : Breast cancer Classification - Deploy On AWS\n\n\nProject-31: Sentiment Analysis Django App -Deploy On Heroku\nProject-32: Attrition Rate Django Application\nProject-33: Find Legendary Pokemon Django App -Deploy On Heroku\nProject-34: Face Detection Streamlit App\nProject-35: Cats Vs Dogs Classification Flask App\nProject-36: Customer Revenue Prediction App -Deploy On Heroku\nProject-37: Gender From Voice Prediction App -Deploy On Heroku\nProject-38: Restaurant Recommendation System\nProject-39: Happiness Ranking Django App -Deploy On Heroku\nProject-40: Forest Fire Prediction Django App -Deploy On Heroku\n\n\nProject-41: Build Car Prices Prediction App -Deploy On Heroku\nProject-42: Build Affair Count Django App -Deploy On Heroku\nProject-43: Build Shrooming Predictions App -Deploy On Heroku\nProject-44: Google Play App Rating prediction With Deployment On Heroku\nProject-45: Build Bank Customers Predictions Django App -Deploy On Heroku\nProject-46: Build Artist Sculpture Cost Prediction Django App -Deploy On Heroku\nProject-47: Build Medical Cost Predictions Django App -Deploy On Heroku\nProject-48: Phishing Webpages Classification Django App -Deploy On Heroku\nProject-49: Clothing Fit-Size predictions Django App -Deploy On Heroku\nProject-50: Build Similarity In-Text Django App -Deploy On Heroku\n\n\nProject-51: Black Friday Sale Project\nProject-52: Sentiment Analysis Project\nProject-53: Parkinson’s Disease Prediction Project\nProject-54: Fake News Classifier Project\nProject-55: Toxic Comment Classifier Project\nProject-56: IMDB Movie Ratings Prediction\nProject-57: Indian Air Quality Prediction\nProject-58: Covid-19 Case Analysis\nProject-59: Customer Churning Prediction\nProject-60: Create A ChatBot\n\n\nProject-61: Video Game sales Analysis\nProject-62: Zomato Restaurant Analysis\nProject-63: Walmart Sales Forecasting\nProject-64 : Sonic wave velocity prediction using Signal Processing Techniques\nProject-65 : Estimation of Pore Pressure using Machine Learning\nProject-66 : Audio processing using ML\nProject-67 : Text characterisation using Speech recognition\nProject-68 : Audio classification using Neural networks\nProject-69 : Developing a voice assistant\nProject-70 : Customer segmentation\n\n\nProject-71 : FIFA 2019 Analysis\nProject-72 : Sentiment analysis of web scrapped data\nProject-73 : Determining Red Vine Quality\nProject-74 : Customer Personality Analysis\nProject-75 : Literacy Analysis in India\nProject-76: Heart Attack Risk Prediction Using Eval ML (Auto ML)\nProject-77: Credit Card Fraud Detection Using Pycaret (Auto ML)\nProject-78: Flight Fare Prediction Using Auto SK Learn (Auto ML)\nProject-79: Petrol Price Forecasting Using Auto Keras\nProject-80: Bank Customer Churn Prediction Using H2O Auto ML\n\n\nProject-81: Air Quality Index Predictor Using TPOT With End-To-End Deployment (Auto ML)\nProject-82: Rain Prediction Using ML models & PyCaret With Deployment (Auto ML)\nProject-83: Pizza Price Prediction Using ML And EVALML(Auto ML)\nProject-84: IPL Cricket Score Prediction Using TPOT (Auto ML)\nProject-85: Predicting Bike Rentals Count Using ML And H2O Auto ML\nProject-86: Concrete Compressive Strength Prediction Using Auto Keras (Auto ML)\nProject-87: Bangalore House Price Prediction Using Auto SK Learn (Auto ML)\nProject-88: Hospital Mortality Prediction Using PyCaret (Auto ML)\nProject-89: Employee Evaluation For Promotion Using ML And Eval Auto ML\nProject-90: Drinking Water Potability Prediction Using ML And H2O Auto ML\n\n\nProject-91: Image Editor Application With OpenCV And Tkinter\nProject-92: Brand Identification Game With Tkinter And Sqlite3\nProject-93: Transaction Application With Tkinter And Sqlite3\nProject-94: Learning Management System With Django\nProject-95: Create A News Portal With Django\nProject-96: Create A Student Portal With Django\nProject-97: Productivity Tracker With Django And Plotly\nProject-98: Create A Study Group With Django\nProject-99: Building Crop Guide Application with PyQt5, SQLite\nProject-100: Building Password Manager Application With PyQt5, SQLite\n\n\nTip: Create A 50 Days Study Plan Or 100 Day Study Plan, Spend 1-3hrs Per Day, Build 100 Projects In 50 Days Or  100 Projects In 100 Days.\n\n\nThe Only Course You Need To Become A Data Scientist, Get Hired And Start A New Career\n\n\nNote (Read This): This Course Is Worth Of Your Time And Money, Enroll Now Before Offer Expires.",
      "target_audience": [
        "Beginners in data science"
      ]
    },
    {
      "title": "Video Segmentation with Python using Deep Learning Real-Time",
      "url": "https://www.udemy.com/course/instance-segmentation-with-python/",
      "bio": "Video, Image Instance Segmentation for Computer Vision with Python. Train, Deploy Deep Learning Models YOLOv8, Mask RCNN",
      "objectives": [
        "Real-Time Video Instance Segmentation with Python and Pytorch using Deep Learning",
        "Build, Train, & Test Deep Learning Models on Custom Data & Deploy to Your Own Projects",
        "Introduction to YOLOv8 and its Deep Learning Architecture",
        "Video Instance Segmentation using YOLOv8 with Python",
        "Introduction to Mask RCNN and its Deep Learning Architecture",
        "Instance Segmentation using Mask RCNN with Python",
        "Configuration of Custom Vehicles Dataset with Annotations for Instance Segmentation",
        "HyperParameters Settings for Training Instance Segmentation Models",
        "Training Instance Segmentation YOLOv8 and Mask RCNN Models on Custom Datasets",
        "Testing Instance Segmentation Trained Models on Videos and Images",
        "Perform Car, Motorbike, and Truck Instance Segmentation",
        "Deploy Trained Instance Segmentation Models"
      ],
      "course_content": {
        "Introduction to Course": [
          "Introduction"
        ],
        "What is Video Instance Segmentation": [
          "Introduction to Image Instance Segmentation",
          "Introduction to Video Instance Segmentation"
        ],
        "Introduction to YOLO and its Architecture": [
          "Introduction to YOLO and its Architecture"
        ],
        "YOLOv8 for Real-time Video Instance Segmentation": [
          "Introduction to YOLOv8 for Real-time Video Instance Segmentation",
          "Google Colab for Writing Python Code",
          "Instance Segmentation with Python using YOLOv8"
        ],
        "Custom Vehicles Instance Segmentation Dataset": [
          "Vehicles Dataset for Instance Segmentation",
          "Vehicles Instance Segmentation Dataset"
        ],
        "Google Colab for Writing Python Code": [
          "Google Colab for Writing Python Code",
          "Connect Google Colab With Google Drive To Read And Write Data"
        ],
        "HyperParameters for Training Instance Segmentation Model": [
          "HyperParameters for Training Instance Segmentation YOLO8 Model",
          "Python Code"
        ],
        "Training Instance Segmentation YOLOv8 on Vehicles Data": [
          "Training YOLOv8 for Image and Video Instance Segmentation",
          "Python Code for Model Training"
        ],
        "Testing Segmentation YOLOv8 on Videos and Images": [
          "Testing Segmentation YOLOv8 on Images",
          "Testing Segmentation YOLOv8 on Videos",
          "Python Code to Segment Instances in Videos and Images"
        ],
        "Deploy Trained Video Segmentation Model": [
          "Deploy Trained Video Segmentation Model",
          "Python Code to Deploy Model"
        ]
      },
      "requirements": [
        "A Google Gmail account is required to get started with Google Colab to write Python Code",
        "Python Programming experience is an advantage but not required"
      ],
      "description": "Introduction: Step into the dynamic realm of computer vision and get ready to be the maestro of moving pixels! Dive into the world of 'Video Instance Segmentation with Python Using Deep Learning.' Unleash the magic hidden in each frame, master the art of dynamic storytelling, and decode the dance of pixels with the latest in deep learning techniques. This course is your passport to unlocking the secrets hidden within the pixels of moving images. Whether you're a novice or an enthusiast eager to delve into the intricacies of video analysis, this journey promises to demystify the world of deep learning in the context of dynamic visual narratives.\nInstance segmentation is a computer vision task to detect and segment individual objects at a pixel level. Unlike semantic segmentation, which assigns a class label to each pixel without distinguishing between object instances, instance segmentation aims to differentiate between each unique object instance in the image. Instance segmentation is a computer vision task to detect and segment individual objects at a pixel level. Instance segmentation goes a step further than object detection and involves identifying individual objects and segment them from the rest of the region. The output of an instance segmentation model is a set of masks or contours that outline each object in the image, along with class labels and confidence scores for each object. Instance segmentation is useful when you need to know not only where objects are in an image, but also what their exact shape is. So, Instance segmentation provides a more detailed understanding of the scene by recognizing and differentiating between specific instances of objects. This fine-grained recognition is essential in applications where precise object localization is required. For example In the context of autonomous vehicles, instance segmentation is valuable for understanding the surrounding environment. It helps in identifying and tracking pedestrians, vehicles, and other obstacles with high precision, contributing to safe navigation.\nDeep learning is one of the most effective approach to Instance segmentation, which involves training a neural network to learn complex relationships between pixels and able to learn rich feature representations. The goal of Instance segmentation is to train a Deep Learning model which can look at the image of multiple objects and able to detect and recognize individual objects at pixel level. In this course, you will perform real time video Instance segmentation with latest YOLO8 which is a deep CNN and you will also do instance segmentation using Mask RCNN which is a region based CNN.\nImportance: Understanding video instance segmentation is at the forefront of technological innovation. It goes beyond mere object detection, offering a pixel-level understanding of each object's motion and shape over time. The importance of this skill extends across industries, influencing advancements in robotics, autonomous systems, healthcare, entertainment, and more.\nApplications:\nSurveillance and Security: Contribute to the development of advanced security systems by mastering video instance segmentation for accurate object identification.\nAutonomous Systems: Enhance your skills for applications like self-driving cars and drones, where precise object tracking is crucial for decision-making.\nMedical Imaging: Dive into the medical field, where pixel-level understanding in video sequences aids in precise localization and tracking for diagnostic purposes.\nEntertainment Industry: Join the league of creators in the entertainment industry, mastering the art of visually engaging effects through detailed object segmentation in videos.\nCourse Key Objectives:\nIn this course, You will follow a complete pipeline for real time video instance segmentation:\nReal-Time Video Instance Segmentation with Python and Pytorch using Deep Learning\nBuild, Train, & Test Deep Learning Models on Custom Data & Deploy to Your Own Projects\nIntroduction to YOLOv8 and its Deep Learning Architecture\nIntroduction to Mask RCNN and its Deep Learning Architecture\nVideo Instance Segmentation using YOLOv8 with Python\nInstance Segmentation using Mask RCNN with Python\nConfiguration of Custom Vehicles Dataset with Annotations for Instance Segmentation\nHyperParameters Settings for Training Instance Segmentation Models\nTraining Instance Segmentation YOLOv8 and Mask RCNN Models on Custom Datasets\nTesting  Instance Segmentation Trained Models on Videos and Images\nPerform Car, Motorbike, and Truck Instance Segmentation\nDeploy Trained Instance Segmentation Models\n\n\nSo, Are you ready to take your understanding of deep learning to the next level and learn how to apply it to real-world problems? This course is especially designed to give you hands-on experience using Python and Pytorch to build, train and Test deep learning models for Instance segmentation applications.“ At the end of this course, you will be able to perform real time video instance segmentation to your own real word problem on custom datasets using Python. Acquire hands-on experience with Python and deep learning frameworks, gaining a skill set that's in high demand across industries. Become a visual storyteller, interpreting the language of pixels in moving images. Seize the opportunity to be at the forefront of technological advancements and make a lasting impact in fields where video analysis is the key to unlocking the future.\nEmbark on this learning journey, where the fusion of Python, deep learning, and video instance segmentation awaits your exploration. Don't miss your chance to be a part of this transformative experience. Enroll now and turn your passion into expertise!\nSee you inside the course!",
      "target_audience": [
        "This course is tailored for aspiring Computer Vision and Deep Learning enthusiasts, students, and researchers eager to delve into the world of Video Instance Segmentation with Python.",
        "Whether you're a beginner looking to unlock the mysteries of pixels in motion or a seasoned professional aiming to expand your skill set, this course offers a dynamic learning experience. If you're passionate about mastering deep learning techniques for video analysis and Instance Segmentation, this course is designed just for you."
      ]
    },
    {
      "title": "Mastering Probability & Statistic Python (Theory & Projects)",
      "url": "https://www.udemy.com/course/mastering-probability-and-statistics-in-python/",
      "bio": "Statistic & Probability for Machine Learning & Data Science: Learning Statistics, Probability & Bayes Classifier, Python",
      "objectives": [
        "The importance of Statistics and Probability in Data Science.",
        "The foundations for Machine Learning and its roots in Probability Theory.",
        "The important concepts from the absolute beginning with comprehensive unfolding with examples in Python.",
        "Practical explanation and live coding with Python.",
        "Probabilistic view of modern Machine Learning.",
        "Implementation of Bayes classifier (Machine Learning Model) on a real dataset with basic and simple concepts of probability and statistics."
      ],
      "course_content": {},
      "requirements": [
        "No prior knowledge needed. You start from the basics and gradually build your knowledge in the subject.",
        "A willingness to learn and practice.",
        "A basic understanding of Python will be a plus."
      ],
      "description": "Unlock the Power of Data with Mastering Probability and Statistics in Python!\nIn today's fiercely competitive business landscape, Probability and Statistics reign supreme as the essential tools for success. They provide businesses with the invaluable insights needed to make informed decisions across a wide spectrum of areas, from market research and product development to optimal product launch timings, in-depth customer data analysis, precise sales forecasting, and even optimizing employee performance.\n\n\nBut why should you master Probability and Statistics in Python?\nThe answer lies in the boundless potential it unlocks for your career. Proficiency in Probability, Statistics, and Data Science empowers you to propel your professional journey to unprecedented heights.\n\n\nOur meticulously crafted course, Mastering Probability and Statistics in Python, has been designed to impart the most sought-after skills in the field. Here's why it stands out:\nEasy to Understand: We break down complex concepts into simple, digestible modules\nExpressive: Gain a profound understanding of the subject matter through clear and articulate explanations\nComprehensive: Covering everything from the fundamentals to advanced concepts, this course leaves no stone unturned\nPractical with Live Coding: Learn by doing with hands-on coding exercises and real-world applications\nConnecting Probability and Machine Learning: Discover the crucial links between Probability, Statistics, and Machine Learning\nBut what sets this course apart?\nThis course caters to beginners while gradually delving into deeper waters. It inspires you to not just learn but also to explore beyond the confines of the syllabus. At the end of each module, you'll tackle homework assignments, quizzes, and activities designed to assess your understanding and reinforce your knowledge.\n\n\nA fulfilling career in machine learning promises not only the thrill of solving complex problems but also the allure of substantial financial rewards. By establishing a strong foundation in Statistics and Probability with Data Science, you're primed for unparalleled career growth.\n\n\nOur affordable and all-encompassing course equips you with the skills and knowledge needed for success in Probability, Statistics, and Data Science, all at a fraction of the cost you'd find elsewhere. With 75+ concise video lessons and detailed code notebooks at your disposal, you'll be on your way to mastering these crucial skills.\nDon't wait any longer; the time to learn Probability and Statistics in Python is now. Dive into the course content, soak up the latest knowledge, and elevate your career to new heights. Listen, pause, understand, and start applying your newfound skills to solve real-world challenges.\n\n\nAt our core, we're passionate about teaching. We're committed to making learning a breeze for you. Our online tutorials are designed to be your best guides, providing crystal-clear explanations that enable you to grasp concepts with ease. With high-quality video content, up-to-date course materials, quizzes, course notes, handouts, and responsive support, we've got all your learning needs covered.\n\n\nCourse Highlights:\nDifference between Probability and Statistics\nSet Theory\nRandom Experiment and Probability Models\nDiscrete and Continuous Random Variables\nExpectation, Variance, and Moments\nEstimation Techniques and Maximum Likelihood Estimate\nLogistic Regression and KL-Divergence\n\n\nUpon successfully completing this course, you'll be empowered to:\nApply the concepts and theories in Machine Learning with a foundation in Probabilistic reasoning\nUnderstand the methodology of Statistics and Probability with Data Science using real datasets\n\n\nWho is this course for?\nIndividuals looking to enhance their data-driven decision-making abilities\nAspiring Data Scientists keen to delve into Statistics and Probability with real-world datasets\nEnthusiasts passionate about numbers and programming\nProfessionals eager to learn Statistics and Probability while practically applying their newfound knowledge\nData Scientists and Business Analysts keen to upskill\n\n\nReady to take your career to the next level? Enroll in Mastering Probability and Statistics in Python today!",
      "target_audience": [
        "People who want to learn Statistics and Probability along with its implementation in realistic projects.",
        "Data Scientists and Business Analysts Newbies",
        "People who want to upgrade their data speak.",
        "People who want to learn Statistics and Probability with real datasets in Data Science.",
        "Individuals who are passionate about numbers and programming."
      ]
    },
    {
      "title": "Deep Learning for Object Detection with Python and PyTorch",
      "url": "https://www.udemy.com/course/object-detection-with-python/",
      "bio": "Object Detection for Computer Vision using Deep Learning with Python. Train and Deploy (Detectron2, Faster RCNN, YOLO11)",
      "objectives": [
        "Learn Object Detection with Python and Pytorch Coding",
        "Learn Object Detection using Deep Learning Models",
        "Single-Stage Object Detection vs Two-Stage Objection Detection with Python",
        "Learn RCNN, Fast RCNN, Faster RCNN, Mask RCNN and YOLO8, YOLO11 Architectures",
        "Perform Object Detection with Fast RCNN and Faster RCNN",
        "Perform Real-time Video Object Detection with YOLOv8 and YOLO11",
        "Train, Test and Deploy YOLOv8 for Video Object Detection",
        "Introduction to Detectron2 by Facebook AI Research (FAIR)",
        "Preform Object Detection with Detectron2 Models",
        "Explore Custom Object Detection Datasets with Annotations",
        "Perform Object Detection on Custom Datasets using Deep Learning",
        "Train, Test, Evaluate Your Own Object Detection Models and Visualize Results",
        "Perform Object Instance Segmentation at Pixel Level using Mask RCNN",
        "Perform Object Instance Segmentation on Custom Dataset with Pytorch and Python"
      ],
      "course_content": {
        "Introduction to Course": [
          "Introduction"
        ],
        "Object Detection and How it Works": [
          "What is Object Detection and How it Works"
        ],
        "Single-shot vs Two-shot Object Detection": [
          "Single-Stage vs Two-Stage Object Detection",
          "YOLOs vs RCNNs"
        ],
        "Deep Learning Architectures for Object Detection (R-CNN Family)": [
          "Introduction to CNN",
          "RCNN Deep Learning Architectures",
          "Fast RCNN Deep Learning Architecture",
          "Faster RCNN Deep Learning Architectures",
          "Mask RCNN Deep Learning Architectures"
        ],
        "Google Colab for Writing Python Code": [
          "Set-up Google Colab for Writing Python Code",
          "Connect Google Colab with Google Drive to Read and Write Data"
        ],
        "Detectron2 for Ojbect Detection": [
          "Detectron2 for Ojbect Detection with PyTorch",
          "Perform Object Detection using Detectron2 Pretrained Models",
          "Python and PyTorch Code"
        ],
        "Annotation tools to Label Your Own Dataset for Object Detection": [
          "Annotate Your Own Dataset for Object Detection"
        ],
        "Custom Dataset for Object Detection": [
          "Custom Dataset for Object Detection",
          "Dataset for Object Detection"
        ],
        "Training, Evaluating and Visualizing Object Detection on Custom Dataset": [
          "Train, Evaluate Object Detection Models & Visualizing Results on Custom Dataset",
          "Python and PyTorch Code"
        ],
        "Complete Code and Custom Dataset for Object Detection": [
          "Resources: Code and Custom Dataset for Object Detection"
        ]
      },
      "requirements": [
        "Object Detection using Deep Learning with Python and PyTorch is taught in this course by following a complete pipeline from Zero to Hero",
        "No prior knowledge of Semantic Segmentation is assumed. Everything will be covered with hands-on trainings",
        "A Google Gmail account is required to get started with Google Colab to write Python Code"
      ],
      "description": "Are you ready to dive into the fascinating world of object detection using deep learning? In our comprehensive course \"Deep Learning for Object Detection with Python and PyTorch\", we will guide you through the essential concepts and techniques required to detect, classify, and locate objects in images. Object Detection has wide range of potential real life application in many fields. Object detection is used for autonomous vehicles to perceive and understand their surroundings. It helps in detecting and tracking pedestrians, vehicles, traffic signs, traffic lights, and other objects on the road. Object Detection is used for surveillance and security using drones to identify and track suspicious activities, intruders, and objects of interest. Object Detection is used for traffic monitoring, helmet and license plate detection, player tracking, defect detection, industrial usage and much more.\nWith the powerful combination of Python programming and the PyTorch deep learning framework, you'll explore state-of-the-art algorithms and architectures like R-CNN, Fast RCNN and Faster R-CNN. Throughout the course, you'll gain a solid understanding of Convolutional Neural Networks (CNNs) and their role in Object Detection. You'll learn how to leverage pre-trained models, fine-tune them for Object Detection using Detectron2 Library developed by by Facebook AI Research (FAIR).\nThe course covers the complete pipeline with hands-on experience of Object Detection using Deep Learning with Python and PyTorch as follows:\nCourse BreakDown:\nLearn Object Detection with Python and Pytorch Coding\nLearn Object Detection using Deep Learning Models\nIntroduction to Convolutional Neural Networks (CNN)\nLearn RCNN, Fast RCNN, Faster RCNN, Mask RCNN and YOLO8, YOLO11 Architectures\nPerform Object Detection with Fast RCNN and Faster RCNN\nPerform Real-time Video Object Detection with YOLOv8 and YOLO11\nTrain, Test and Deploy YOLOv8 for Video Object Detection\nIntroduction to Detectron2 by Facebook AI Research (FAIR)\nPreform Object Detection with Detectron2 Models\nExplore Custom Object Detection Dataset with Annotations\nPerform Object Detection on Custom Dataset using Deep Learning\nTrain, Test, Evaluate Your Own Object Detection Models and Visualize Results\nPerform Object Instance Segmentation at Pixel Level using Mask RCNN\nPerform Object Instance Segmentation on Custom Dataset with Pytorch and Python\nBy the end of this course, you'll have the knowledge and skills you need to start applying Deep Learning to Object Detection problems in your own work or research. Whether you're a Computer Vision Engineer, Data Scientist, or Developer, this course is the perfect way to take your understanding of Deep Learning to the next level. Let's get started on this exciting journey of Deep Learning for Object Detection with Python and PyTorch.\nSee you inside the class!",
      "target_audience": [
        "This course is designed for a wide range of Students and Professionals, including but not limited to: Machine Learning Engineers, Deep Learning Engineers, Data Scientists, Computer Vision Engineers, and Researchers who want to learn how to use PyTorch to build and train deep learning models for Object Detection",
        "In general, the course is for anyone who wants to learn how to use Deep Learning to extract meaning from visual data and gain a deeper understanding of the theory and practical applications of Object Detection using Python and PyTorch"
      ]
    },
    {
      "title": "Predictive Analytics With R",
      "url": "https://www.udemy.com/course/predictive-analytics-with-r/",
      "bio": "Enhance you analytics by Predictive Analytcis with R. Become an Analyst with easy programming code of R.",
      "objectives": [
        "Understand the fundamentals of Predictive Analytics in R.",
        "Enhance skills by applying them to Model Data.",
        "Get accustom to Predictive Analytics as career option with practical knowledge on some of the techniques that are currently in demand, such as Hypothesis Testing, Linear Regression, Multiple Regression, Logistic Regression, Correlations, Chi-Square Test etc.",
        "Use Predictive Modelling Techniques on different types of data.",
        "Work with different types of data and perform Data Manipulation and Preparation.",
        "Develop constructive approach to solve business queries with R.",
        "Analyze real time data and perform learnt skills."
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Prerequisites for Predictive Modelling",
          "Course Overview"
        ],
        "Introduction to predictive modelling": [
          "What is predictive modelling?",
          "Why predictive modelling?",
          "Applications of predictive modelling"
        ],
        "Introduction to R": [
          "What is R?",
          "Introduction to the interface of R",
          "Why R for predictive modelling?"
        ],
        "Basic Statistics in R": [
          "Mean",
          "Mode",
          "Median",
          "Variance",
          "Standard Deviation",
          "Skewness",
          "Kurtosis",
          "Correlation",
          "Assignment Questions"
        ],
        "Data Manipulation in R": [
          "Group Manipulation Concept",
          "Group Manipulation Hands On",
          "Aggregate Function",
          "Dplyr Package",
          "String Manipulation Concept",
          "String Manipulation Hands On",
          "Transform and Split",
          "Handling missing values",
          "Assignment Questions"
        ],
        "Predictive Modelling Techniques": [
          "Hypothesis Test Concept",
          "Hypothesis Testing Hands On",
          "Chi-square Test Concept",
          "Chi-Square Test Hands On",
          "T-Test Concept",
          "T-Test Hands On",
          "Z-Test Concept",
          "Z-Test Hands On",
          "Assignment Questions"
        ],
        "Regression": [
          "Introduction to Regression Analysis",
          "Linear Regression Concept",
          "Implementing Linear Regression in R",
          "Multiple Regression Concept",
          "Implementing Multiple Regression Concept in R",
          "Logistic Regression Concept",
          "Implementing Logistic Regression Concept in R",
          "Assignment Questions"
        ]
      },
      "requirements": [
        "You should have some basic idea about R tool and its objective",
        "If you have knowledge about basic statistics previously, it would be an added advantage for you."
      ],
      "description": "In this course you will learn about predictive analytics using R language\n\nIt starts with an introduction to the predictive modelling along with its application.\nAlso you learn about R and and how R is used for Predictive modelling\nYou will also design statistical experiments and analyze the results using modern methods\nYou will also learn Data manipulation methods and predictive Modelling techniques in R.\nCollectively, this course will help you internalize a core set of practical and effective predictive analytics methods and concepts, and apply them to solve some real world problems.\nThis course contains lectures as videos along with the hands-on implementation of the concepts, additional assignments are also provided in the last section for your self-practice.",
      "target_audience": [
        "Developers who want to step-up as 'Data Scientists'",
        "Analytics Consultants",
        "R Professionals",
        "Data Analysts, Data Engineers",
        "Statisticians"
      ]
    },
    {
      "title": "CO₂ Emissions Forecasting with Deep Learning in Python",
      "url": "https://www.udemy.com/course/deep-learning-for-time-series-forecasting-on-co2/",
      "bio": "Use Machine Learning methodologies in Python - a step by step methodology for accurate forecasts",
      "objectives": [
        "Build Deep Neural Network models to forecast CO2 emissions using Python",
        "Apply a proven 10-step methodology for creating statistically sound and reliable forecasts",
        "Work with real World Bank data to analyze emissions trends for India, China, USA, UK, EU and global averages",
        "Master essential statistical tests including overfitting analysis, naive model benchmarking, and sensitivity analysis",
        "Quantify forecast uncertainty using confidence intervals and error metrics like MAPE",
        "Create publication-ready visualizations of historical trends and future projections",
        "Create publication-ready visualizations of historical trends and future projections",
        "Understand when Deep Neural Network modelling is appropriate for time series forecasting vs other methods",
        "Implement best practices for model validation, hyperparameter tuning, and results interpretation"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Resources",
          "Multivariate versus Univariate modelling",
          "The 10-step methodology for accurate forecasts"
        ],
        "Data Preprocessing": [
          "Introduction",
          "Resources",
          "Data Preprocessing step by step",
          "Download data and plots - part 1",
          "Download data and plots - part 2",
          "Download data and plots - part 3"
        ],
        "Dataset split": [
          "Polynomial features",
          "Dataset split"
        ],
        "Dataset scaling": [
          "Introduction",
          "Data scaling and features matrices"
        ],
        "Deep Neural Networks": [
          "Introduction",
          "Compiling the models",
          "Fitting the models",
          "Drawing the models. The activation function.",
          "Generating the predictions",
          "The test-set errors",
          "The training set errors",
          "Overfitting analysis",
          "The naive model test",
          "Sensitivity analysis versus hyperparameters",
          "Sensitivity analysis",
          "The theory of forecasts and methodologies.",
          "Producing the forecasts",
          "Final selection of models"
        ],
        "Conclusions": [
          "Overview",
          "Resources"
        ]
      },
      "requirements": [
        "Absolute beginners welcome!",
        "You'll receive the full Python code, which you can adjust to your own projects",
        "No programming experience? Follow along and learn by doing",
        "No statistics background needed",
        "Just need a computer and enthusiasm"
      ],
      "description": "SPECIAL OFFER:\nSave today! Copy this code at checkout (remove the middle space):      5246E8520 D5429861E51\n\nWHO I AM:\nResearcher and educator specializing in energy data science (PhD in Energy, Imperial College London, 40+ publications)\n\nREGULAR ENHANCEMENTS:\nCourse reviewed periodically with updates.\n\n\nWhat You'll Learn:\nHow to build a Deep Neural Network model in Python that can forecast CO₂ emissions\nHow to achieve high accuracy in the forecasts that you will produce\nHow to work with World Bank historical data\nHow to implement advanced statistical tests\nHow to apply your model to real-world cases (India, China, USA, UK, European Union analysis)\n\nPerfect For:\nEnvironmental consultants and analysts\nEnergy economists and policy makers\nData scientists in sustainability\nClimate professionals\n\nWhy This Matters:\nWith net-zero targets and mandatory carbon reporting, professionals who can produce credible emissions forecasts are in high demand. Master the skills that set you apart in the growing climate economy. Companies now require carbon footprint assessments for regulatory compliance and ESG reporting. Governments need emissions projections for policy planning. Consultancies charge premium rates for these capabilities. Whether you're advancing your current career or transitioning into sustainability, these practical forecasting skills open doors to roles paying $150,000-250,000+ in the rapidly expanding green economy.",
      "target_audience": [
        "Environmental/Climate Analysts seeking quantitative forecasting skills",
        "Sustainability Professionals needing to project emissions for reporting",
        "Energy Sector Professionals wanting data-driven analytical methods",
        "Graduate Students & Researchers in environmental science, energy, or climate studies",
        "Data Scientists/ML Engineers moving into climate and energy applications",
        "ESG Analysts & Consultants requiring emissions projection capabilities",
        "Policy Analysts working on climate strategies and carbon reduction plans",
        "Anyone transitioning to climate tech who needs practical forecasting skills"
      ]
    },
    {
      "title": "Linear Regression, GLMs and GAMs with R",
      "url": "https://www.udemy.com/course/linear-regression-glms-and-gams-with-r/",
      "bio": "How to extend linear regression to specify and estimate generalized linear models and additive models.",
      "objectives": [
        "Understand the assumptions of ordinary least squares (OLS) linear regression.",
        "Specify, estimate and interpret linear (regression) models using R.",
        "Understand how the assumptions of OLS regression are modified (relaxed) in order to specify, estimate and interpret generalized linear models (GLMs).",
        "Specify, estimate and interpret GLMs using R.",
        "Understand the mechanics and limitations of specifying, estimating and interpreting generalized additive models (GAMs)."
      ],
      "course_content": {
        "Introduction to Course and to Linear Modeling": [
          "Introduction to Course",
          "Preliminaries: Installing R, RStudio, R Commander, Course Materials and Exercise",
          "Beginning Agenda (slides)",
          "What is Linear Modeling? (slides, part 1)",
          "Assumptions of Linear Modeling (slides, part 2)",
          "Desirable Properties of Beta-hat (slides, part 3)",
          "Example: Estimate Age of Universe (slides)",
          "Example: Estimate Age of Universe Live in R (part 1)",
          "Example: Estimate Age of Universe Live in R (part 2)",
          "Example: Estimating Age of the Universe (part 3)",
          "Finish Example and More Notes on Linear Modeling",
          "Linear Modeling Exercises"
        ],
        "Generalized Linear Models (GLMs) Part 1": [
          "Introduction to GLMs (slides, part 1)",
          "Introduction to GLMs (slides, part 2)",
          "Introduction to GLMs (slides, part 3)",
          "Introduction to GLMs (slides, part 4)",
          "Example: Binomial (Proportion) Model with Heart Disease (part 1)",
          "Example: Binomial (Proportion) Model with Heart Disease (part 2)",
          "Example: Binomial (Proportion) Model with Heart Disease (part 3)",
          "Example: Binomial (Proportion) Model with Heart Disease (part 4)",
          "GLM Exercises"
        ],
        "Generalized Linear Models Part 2": [
          "Current Agenda",
          "Linear Regression Exercise Solutions (part 1)",
          "Linear Regression Exercise Solutions (part 2)",
          "GLM Exercise Solutions (part 3)",
          "Example: Poisson Model with Count Data (part 1)",
          "Example: Poisson Model with Count Data (part 2)",
          "Example: Binary Response Variable (part 1)",
          "Example: Binary Response Variable (part 2)",
          "Exercise: GLM to GAM",
          "Example: Log-Linear Model for Categorical Data",
          "More on Deviance and Overdispersion (slides)"
        ],
        "Generalized Additive Models Explained": [
          "What are GAMS? (Crawley, slides, part 1)",
          "What are GAMs? (Crawley, slides, part 2)",
          "Demonstrate GAM Ozone Data (part 1)",
          "Demonstrate GAM Ozone Data (part 2)",
          "General Approaches for Fitting GAMs (slides)",
          "What are GAMs? (Wood, slides, part 1)",
          "Univariate Polynomial GAMs (Wood, slides, part 2)",
          "Univariate Polynomial GAMs (Wood, slides, part 3)",
          "GAMs as 4th Order Polynomials (slides, part 1)",
          "GAMs as 4th Order Polynomials (slides, part 2)",
          "GAMs as Regression Splines (slides)",
          "Cubic Splines (slides, part 1)",
          "Cubic Splines (slides, part 2)",
          "Function to Establish Basis for Spline (slides)",
          "Build-a-GAM (slides, part 1)",
          "Build-a-GAM (slides, part 2)",
          "Build-a-GAM (slides, part 3)",
          "Build-a-GAM Demonstration in R Script",
          "Build-a-GAM Cross Validation",
          "Bivariate GAMs with 2 Explanatory Independent Variables (slides, part 1)",
          "Bivariate GAMs with 2 Explanatory Independent Variables (slides, part 2)",
          "Exercises"
        ],
        "Detailed GAM Examples": [
          "Current Agenda (slides)",
          "Cherry Trees and Finer Control (slides, part 1)",
          "Finer Control of GAM (slides, part 2)",
          "Using Smoothers with More than One Predictor (slides)",
          "More on Alternative Smoothing Bases (slides)",
          "Parametric Model Terms (slides)",
          "Example: Brain Imaging (part 1)",
          "Example: Brain Imaging (part 2)",
          "Example: Brain Imaging (part 3)",
          "Example: Brain Imaging (part 4)",
          "Example: Brain Imaging (part 5)",
          "Example: Air Pollution in Chicago (part 1)",
          "Example: Air Pollution in Chicago (part 2)",
          "Air Pollution in Chicago (part 3)",
          "More Exercises"
        ]
      },
      "requirements": [
        "Students will need to install R and R Commander software but ample instruction for doing so is provided."
      ],
      "description": "Linear Regression, GLMs and GAMs with R demonstrates how to use R to extend the basic assumptions and constraints of linear regression to specify, model, and interpret the results of generalized linear (GLMs) and generalized additive (GAMs) models. The course demonstrates the estimation of GLMs and GAMs by working through a series of practical examples from the book Generalized Additive Models: An Introduction with R by Simon N. Wood (Chapman & Hall/CRC Texts in Statistical Science, 2006). Linear statistical models have a univariate response modeled as a linear function of predictor variables and a zero mean random error term. The assumption of linearity is a critical (and limiting) characteristic. Generalized linear models (GLMs) relax this assumption of linearity. They permit the expected value of the response variable to be a smoothed (e.g. non-linear) monotonic function of the linear predictors. GLMs also relax the assumption that the response variable is normally distributed by allowing for many distributions (e.g. normal, poisson, binomial, log-linear, etc.). Generalized additive models (GAMs) are extensions of GLMs. GAMs allow for the estimation of regression coefficients that take the form of non-parametric smoothers. Nonparametric smoothers like lowess (locally weighted scatterplot smoothing) fit a smooth curve to data using localized subsets of the data. This course provides an overview of modeling GLMs and GAMs using R. GLMs, and especially GAMs, have evolved into standard statistical methodologies of considerable flexibility. The course addresses recent approaches to modeling, estimating and interpreting GAMs. The focus of the course is on modeling and interpreting GLMs and especially GAMs with R. Use of the freely available R software illustrates the practicalities of linear, generalized linear, and generalized additive models.",
      "target_audience": [
        "This course would be useful for anyone involved with linear modeling estimation, including graduate students and/or working professionals in quantitative modeling and data analysis.",
        "The focus, and majority of content, of this course is on generalized additive modeling. Anyone who wishes to learn how to specify, estimate and interpret GAMs would especially benefit from this course."
      ]
    },
    {
      "title": "Deep Learning: Natural Language Processing with Transformers",
      "url": "https://www.udemy.com/course/modern-natural-language-processingnlp-using-deep-learning/",
      "bio": "Use Huggingface transformers and Tensorflow to build Sentiment analysis, Translation, Q&A, Search, Speech,... projects",
      "objectives": [
        "The Basics of Tensors and Variables with Tensorflow",
        "Mastery of the fundamentals of Machine Learning and The Machine Learning Developmment Lifecycle.",
        "Basics of Tensorflow and training neural networks with TensorFlow 2.",
        "Sentiment Analysis with Recurrent neural networks, Attention Models and Transformers from scratch",
        "Neural Machine Translation with Recurrent neural networks, Attention Models and Transformers from scratch",
        "Recurrent Neural Networks, Modern RNNs, training sentiment analysis models with TensorFlow 2.",
        "Intent Classification with Deberta in Huggingface transformers",
        "Conversion from tensorflow to Onnx Model",
        "Building API with Fastapi",
        "Deploying API to the Cloud",
        "Neural Machine Translation with T5 in Huggingface transformers",
        "Extractive Question Answering with Longformer in Huggingface transformers",
        "E-commerce search engine with Sentence transformers",
        "Lyrics Generator with GPT2 in Huggingface transformers",
        "Grammatical Error Correction with T5 in Huggingface transformers",
        "Elon Musk Bot with BlenderBot in Huggingface transformers"
      ],
      "course_content": {
        "intro": [
          "Welcome",
          "General Introduction",
          "About this Course",
          "Link to Code"
        ],
        "[PRE-REQUISITE] Tensors and Variables": [
          "Link to Code",
          "Basics",
          "Initialization and casting",
          "Indexing",
          "Maths Operations",
          "Linear algebra operations",
          "Common methods",
          "Ragged tensors",
          "Sparse tensors",
          "String tensors",
          "Variables"
        ],
        "[PRE-REQUISITE] Building Neural Networks with TensorFlow": [
          "Link to Code",
          "Link to Dataset",
          "Task Understanding",
          "Data Preparation",
          "Linear Regression Model",
          "Error Sanctioning",
          "Training and Optimization",
          "Performance Measurement",
          "Validation and Testing",
          "Corrective Measures",
          "TensorFlow Datasets"
        ],
        "Text Preprocessing for Sentiment Analysis": [
          "Understanding Sentiment Analysis",
          "Text Standardization",
          "Tokenization",
          "One-hot encoding and Bag of Words",
          "Term frequency - Inverse Document frequency (TF-IDF)",
          "Embeddings"
        ],
        "Sentiment Analysis with Recurrent neural networks": [
          "Link to Code",
          "How Recurrent neural networks work",
          "Data Preparation",
          "Building and training RNNs",
          "Advanced RNNs (LSTM and GRU)",
          "1D Convolutional Neural Network"
        ],
        "Sentiment Analysis with transfer learning": [
          "Understanding Word2vec",
          "Integrating pretrained Word2vec embeddings",
          "Testing",
          "Visualizing embeddings"
        ],
        "Neural Machine Translation with Recurrent Neural Networks": [
          "Link to Code",
          "Understanding Machine Translation",
          "Data Preparation",
          "Building, training and testing Model",
          "Understanding BLEU score",
          "Coding BLEU score from scratch"
        ],
        "Neural Machine Translation with Attention": [
          "Link to Code",
          "Understanding Bahdanau Attention",
          "Building, training and testing Bahdanau Attention"
        ],
        "Neural Machine Translation with Transformers": [
          "Link to Code",
          "Understanding Transformer Networks",
          "Building, training and testing Transformers",
          "Building Transformers with Custom Attention Layer",
          "Visualizing Attention scores"
        ],
        "Sentiment Analysis with Transformers": [
          "Link to Code",
          "Sentiment analysis with Transformer encoder",
          "Sentiment analysis with LSH Attention"
        ]
      },
      "requirements": [
        "Basic Math",
        "No Programming experience."
      ],
      "description": "Deep Learning is a hot topic today! This is because of the impact it's having in several industries. One of the fields in which deep learning has the most influence today is Natural Language Processing.\nTo understand why Deep Learning based Natural Language Processing is so popular; it suffices to take a look at the different domains where giving a computer the power to understand and make sense out of text and generate text has changed our lives.\nSome applications of Natural Language Processing are in:\nHelping people around the world learn about any topic ChatGPT\nHelping developers code more efficiently with Github Copilot.\nAutomatic topic recommendation in our Twitter feeds\nAutomatic Neural Machine Translation with  Google Translate\nE-commerce search engines like those of Amazon\nCorrection of Grammar with Grammarly\nThe demand for Natural Language Processing engineers is skyrocketing and experts in this field are highly paid, because of their value. However, getting started in this field isn’t easy. There’s so much information out there, much of which is outdated and many times don't take the beginners into consideration :(\nIn this course, we shall take you on an amazing journey in which you'll master different concepts with a step-by-step and project-based approach. You shall be using Tensorflow 2 (the world's most popular library for deep learning, built by Google) and Huggingface transformers (most popular NLP focused library ). We shall start by understanding how to build very simple models (like Linear regression model for car price prediction and RNN text classifiers for movie review analysis) using Tensorflow to much more advanced transformer models (like Bert, GPT, BlenderBot, T5, Sentence Transformers and Deberta).\nAfter going through this course and carrying out the different projects, you will develop the skill sets needed to develop modern deep learning for NLP solutions that big tech companies encounter.\nYou will learn:\nThe Basics of Tensorflow (Tensors, Model building, training, and evaluation)\nText Preprocessing for Natural Language Processing.\nDeep Learning algorithms like Recurrent Neural Networks, Attention Models, Transformers, and Convolutional neural networks.\nSentiment analysis with RNNs, Transformers, and Huggingface Transformers (Deberta)\nTransfer learning with Word2vec and modern Transformers (GPT, Bert, ULmfit, Deberta, T5...)\nMachine Learning Operations (MLOps) with Weights and Biases (Experiment Tracking, Hyperparameter Tuning, Dataset Versioning, Model Versioning)\nMachine translation with RNNs, attention, transformers, and Huggingface Transformers (T5)\nModel Deployment (Onnx format, Quantization, Fastapi, Heroku Cloud)\nIntent Classification with Deberta in Huggingface transformers\nNamed Entity Relation with Roberta in Huggingface transformers\nNeural Machine Translation with T5 in Huggingface transformers\nExtractive Question Answering with Longformer in Huggingface transformers\nE-commerce search engine with Sentence transformers\nLyrics Generator with GPT2 in Huggingface transformers\nGrammatical Error Correction with T5 in Huggingface transformers\nElon Musk Bot with BlenderBot in Huggingface transformers\nSpeech recognition with RNNs\n\n\nIf you are willing to move a step further in your career, this course is destined for you and we are super excited to help achieve your goals!\nThis course is offered to you by Neuralearn. And just like every other course by Neuralearn, we lay much emphasis on feedback. Your reviews and questions in the forum will help us better this course. Feel free to ask as many questions as possible on the forum. We do our very best to reply in the shortest possible time.\n\n\nEnjoy!!!",
      "target_audience": [
        "Python Developers curious about Deep Learning for NLP",
        "Deep Learning Practitioners who want gain a mastery of how things work under the hoods",
        "Anyone who wants to master deep learning fundamentals and also practice deep learning for NLP using best practices in TensorFlow.",
        "Natural Language Processing practitioners who want to learn how state of art NLP models are built and trained using deep learning.",
        "Anyone wanting to deploy ML Models",
        "Learners who want a practical approach to Deep learning for Natural Language Processing"
      ]
    },
    {
      "title": "Complete Python for data science and cloud computing",
      "url": "https://www.udemy.com/course/complete-python-for-data-science-and-cloud-computing/",
      "bio": "A complete & in-depth use case course taught by data science PHD & business consultants with thousand examples",
      "objectives": [
        "Become a true data scientist & machine learning expert with full industry knowledge",
        "Apply different predictive models and machine learning algorithms into use cases in different business areas",
        "Present analytical results to various users",
        "Master Text Mining & Natural Language Processing (NLP) using Python & Spark for sentimental analysis",
        "Work on Python with SQL on SQLite, Redshift, SAS, MongoDB, Spark and other data sources",
        "Become industry expert in banking, marketing, credit risk and product-user recommender system",
        "Collect and analyze Big Data in different systems",
        "Use AWS and Azure for Cloud Computing",
        "Master fundamental Python programming",
        "Apply generic Object Oriented Programming (OOP)",
        "Conduct real world capstone projects to build up career path",
        "Master useful data engineering knowledge and skills",
        "Convert homework and practices into your own knowledge and skills",
        "Use all famous graphics tools such as matplotlib, plotly, seaborn and ggplot into data visualization"
      ],
      "course_content": {
        "Python Fundamental": [
          "Introduction",
          "Python environment and versions",
          "Download lecture materials",
          "Install Anaconda",
          "Demonstrate Jupyter notebook",
          "Demonstrate Spyder",
          "Your first homework",
          "Data objects in Python (1)",
          "Data objects in Python (2)",
          "Data objects in Python (3)",
          "Demonstrate programming for data objects",
          "Understand String and operations",
          "Demonstrate programming for String objects (1)",
          "Demonstrate programming for String objects (2)",
          "Scalar variables and operations",
          "Examples of Scalar variables and operations",
          "Understand date and time objects",
          "Demonstrate examples of date and time objects",
          "Comments in Python",
          "Demonstrate examples of comments in Python",
          "Learn tuples objects in Python",
          "Demonstrate tuple examples",
          "Learn list objects in Python",
          "Demonstrate list examples (1)",
          "Demonstrate list examples (2)",
          "Demonstrate list examples (3)",
          "Demonstrate list examples (4)",
          "Demonstrate list examples (5)",
          "Understand dictionary objects",
          "Show use cases about dictionary objects",
          "Introduce set objects",
          "Demonstrate programming on Set objects",
          "Control flow structure in Python",
          "Examples about control flow programming (1)",
          "Examples about control flow programming (2)",
          "Examples about control flow programming (3)",
          "Examples about control flow programming (4)",
          "User Defined Functions (UDF)",
          "Demonstrate examples of UDF",
          "Create Python packages",
          "Demonstrate how to create Python packages",
          "File input and output in Python (1)",
          "File input and output in Python (2)",
          "Introduce Iterators and generators",
          "Learn error handling in Python",
          "Introduce assert statement",
          "Object Orientated Programming (OOP) in Python",
          "Demonstrate use case of OOP (1)",
          "Demonstrate use case of OOP (2)",
          "Demonstrate use case of OOP (3)",
          "Homework of Python fundamental",
          "Solution to homework of Python fundamental (1)",
          "Solution to homework of Python fundamental (2)"
        ],
        "Python Numpy for Data Science": [
          "Introduce Python Numpy",
          "Introduce Python Numpy (2)",
          "Create Numpy arrays (1)",
          "Create Numpy arrays (2)",
          "Create Numpy arrays (3)",
          "Create Numpy arrays (4)",
          "Introduce multi-dimensions Numpy arrays",
          "Learn properties of Numpy arrays",
          "Slicing Numpy arrays (1)",
          "Slicing Numpy arrays (2)",
          "Show cases of Numpy arrays",
          "Use array to slice Numpy arrays",
          "Examples of fancy indexing for Numpy arrays",
          "Transpose Numpy arrays",
          "Examples of transposing Numpy arrays",
          "Merge or stack Numpy arrays",
          "Introduce useful functions of Numpy arrays",
          "Data processing functions of Numpy arrays (1)",
          "Data processing functions of Numpy arrays (2)",
          "Data processing functions of Numpy arrays (3)",
          "Data sampling and generation",
          "Load and write data using Numpy",
          "Examples of loading and writing data using Numpy",
          "Introduce first homework of Numpy",
          "Solution to first homework of Numpy arrays (1)",
          "Solution to first homework of Numpy arrays (2)",
          "Solution to first homework of Numpy arrays (3)",
          "Solution to first homework of Numpy arrays (4)",
          "Solution to first homework of Numpy arrays (5)",
          "Introduce second homework of Numpy",
          "Solution to second homework of Numpy arrays (1)",
          "Solution to second homework of Numpy arrays (2)",
          "Solution to second homework of Numpy arrays (3)"
        ],
        "Python Pandas for Data Science": [
          "Introduce series objects",
          "Overview of Pandas",
          "Create Pandas data frames",
          "Show examples of creating Pandas data frames",
          "Read external files into data frames (1)",
          "Read external files into data frames (2)",
          "Demonstrate examples of reading external files",
          "Data conversion in data frames (1)",
          "Data conversion in data frames (2)",
          "Arithmetic operations of data frames",
          "Examples of arithmetic operations of data frames",
          "Slicing data frames (1)",
          "Slicing data frames (2)",
          "Show examples of slicing data frames (1)",
          "Show examples of slicing data frames (2)",
          "Manipulate data frames (1)",
          "Manipulate data frames (2)",
          "Manipulate data frames (3)",
          "Manipulate data frames (4)",
          "Examples of manipulating data frames (1)",
          "Examples of manipulating data frames (2)",
          "Sort and rank data frames (1)",
          "Sort and rank data frames (2)",
          "Examples of sorting and ranking data frames (1)",
          "Examples of sorting and ranking data frames (2)",
          "Examples of sorting and ranking data frames (3)",
          "Combine data frames",
          "Demonstrate examples of combining data frames",
          "Indexing methods in data frames",
          "Examples indexing methods in data frames (1)",
          "Examples indexing methods in data frames (2)",
          "Examples indexing methods in data frames (3)",
          "Examples indexing methods in data frames (4)",
          "Reshape data frames",
          "Examples of reshaping data frames (1)",
          "Examples of reshaping data frames (2)",
          "Treat missing values in data frames (1)",
          "Treat missing values in data frames (2)",
          "Treat missing values in data frames (3)",
          "Treat duplicated values in data frames",
          "Examples of treating missing and duplicated values (1)",
          "Examples of treating missing and duplicated values (2)",
          "Examples of treating missing and duplicated values (3)",
          "Examples of treating missing and duplicated values (4)",
          "Examples of treating missing and duplicated values (5)",
          "Examples of treating missing and duplicated values (6)",
          "Summarize data using Pandas data frames (1)",
          "Summarize data using Pandas data frames (2)",
          "Examples for summarizing data (1)",
          "Examples for summarizing data (2)",
          "Examples for summarizing data (3)",
          "Examples for summarizing data (4)",
          "Examples for summarizing data (5)",
          "Examples for summarizing data (6)",
          "Examples for summarizing data (7)",
          "Categorical data analysis (1)",
          "Categorical data analysis (2)",
          "Categorical data analysis (3)",
          "Categorical data analysis (4)",
          "Categorical data analysis (5)",
          "Categorical data analysis (6)",
          "Access other data sources",
          "Access SQLite with Python (1)",
          "Access SQLite with Python (2)",
          "Scrape web site data with Python",
          "Test data scraping with Python Pandas",
          "First homework of Pandas",
          "Solution to first homework of Pandas",
          "Second homework of Pandas",
          "Solution to second homework of Pandas",
          "Introduce MongoDB and work with Python",
          "Install MongoDB",
          "Programs: Interact Python with MongoDB (1)",
          "Programs: Interact Python with MongoDB (2)"
        ],
        "Data Visualization with Python": [
          "Graph with Matplotlib and examples (1)",
          "Graph with Matplotlib and examples (2)",
          "Introduce and install Seaborn",
          "Demonstrate data visualization with Seaborn (1)",
          "Demonstrate data visualization with Seaborn (2)",
          "Introduce and install ggplot",
          "Demonstrate data visualization with ggplot",
          "Introduce and install plotly",
          "Demonstrate data visualization with offline plotly (1)",
          "Demonstrate data visualization with offline plotly (2)",
          "Demonstrate data visualization with online plotly (1)",
          "Demonstrate data visualization with online plotly (2)"
        ],
        "Statistical Analysis and Modeling with Python": [
          "Introduce statistical tests",
          "One sample and two samples tests (1)",
          "One sample and two samples tests (2)",
          "Real world case: two samples tests",
          "Non-parametric tests with Python",
          "Multiple groups tests – ANOVA (1)",
          "Multiple groups tests – ANOVA (2)",
          "Multiple groups tests – ANOVA (3)",
          "Multiple groups tests – ANOVA (4)",
          "Case study for ANOVA with Python",
          "Introduce interaction by examples",
          "Work with interaction in ANOVA with Python",
          "Statistical tests with repeated measures",
          "Different types of pair tests",
          "Statistical tests for categorical data",
          "Chi-Square test",
          "Proportion test",
          "Examples of statistical tests using Python (1)",
          "Examples of statistical tests using Python (2)",
          "Examples of statistical tests using Python (3)",
          "Examples of statistical tests using Python (4)",
          "Examples of statistical tests using Python (5)",
          "Examples of statistical tests using Python (6)",
          "Examples of statistical tests using Python (7)",
          "Examples of statistical tests using Python (8)",
          "Examples of statistical tests using Python (9)",
          "Examples of statistical tests using Python (10)",
          "Examples of statistical tests using Python (11)",
          "Homework & solutions to statistical tests with Python",
          "Linear regression and application (1)",
          "Linear regression and application (2)",
          "Linear regression and application (3)",
          "Linear regression and application (4)",
          "Feature engineering in modeling",
          "Feature selection in modeling",
          "Python codes for feature engineering",
          "Logistic regression and application (1)",
          "Logistic regression and application (2)",
          "Logistic regression and application (3)",
          "Logistic regression and application (4)",
          "Logistic regression and application (5)",
          "Logistic regression and application (6)",
          "Logistic regression and application (7)",
          "Logistic regression and application (8)",
          "Logistic regression and application (9)",
          "Logistic regression and application (10)",
          "Logistic regression and application (11)",
          "Logistic regression and application (12)",
          "Logistic regression and application (13)",
          "Use cases of statistical models (1)",
          "Use cases of statistical models (2)",
          "Use cases of statistical models (3)",
          "Use cases of statistical models (4)",
          "Use cases of statistical models (5)",
          "Use cases of statistical models (6)",
          "Use cases of statistical models (7)",
          "Use cases of statistical models (8)",
          "Use cases of statistical models (9)",
          "Use cases of statistical models (10)",
          "Use cases of statistical models (11)",
          "Introduce homework of statistical models",
          "Solution to homework of statistical models (1)",
          "Solution to homework of statistical models (2)",
          "Solution to homework of statistical models (3)",
          "Introduce homework of fraud detection project",
          "Solution to fraud detection project (1)",
          "Solution to fraud detection project (2)",
          "Solution to fraud detection project (3)",
          "Solution to fraud detection project (4)",
          "Solution to fraud detection project (5)",
          "Solution to fraud detection project (6)",
          "Solution to fraud detection project (7)",
          "Solution to fraud detection project (8)"
        ],
        "Data Science & Machine Learning Capstone Projects with Python": [
          "Introduce project: predict online product sales",
          "Explain Python codes for predicting online product sales (1)",
          "Explain Python codes for predicting online product sales (2)",
          "Explain Python codes for predicting online product sales (3)",
          "Explain Python codes for predicting online product sales (4)",
          "Introduce project: credit risk analysis – develop score cards",
          "Lecture on Python program for credit risk analysis (1)",
          "Lecture on Python program for credit risk analysis (2)",
          "Lecture on Python program for credit risk analysis (3)",
          "Lecture on Python program for credit risk analysis (4)",
          "Lecture on Python program for credit risk analysis (5)",
          "Lecture on Python program for credit risk analysis (6)",
          "Lecture on Python program for credit risk analysis (7)",
          "Lecture on Python program for credit risk analysis (8)",
          "Lecture on Python program for credit risk analysis (9)",
          "Lecture on Python program for credit risk analysis (10)",
          "Project overview: measure sales promotion Program",
          "Explain project: measure sales promotion Program (1)",
          "Explain project: measure sales promotion Program (2)",
          "Explain project: measure sales promotion Program (3)",
          "Explain project: measure sales promotion Program (4)",
          "Explain project: measure sales promotion Program (5)",
          "Explain project: measure sales promotion Program (6)",
          "Project: predict product price based on text mining (1)",
          "Bag of words and TF/IDF",
          "Project: market sale model and price elasticity (2)",
          "Python interpretation: price prediction based on NLP (1)",
          "Python interpretation: price prediction based on NLP (2)",
          "Python interpretation: price prediction based on NLP (3)",
          "Python interpretation: price prediction based on NLP (4)",
          "Python interpretation: price prediction based on NLP (5)",
          "Python interpretation: price prediction based on NLP (6)",
          "Python interpretation: price prediction based on NLP (7)",
          "Python interpretation: price prediction based on NLP (8)",
          "Python interpretation: price prediction based on NLP (9)",
          "Python interpretation: price prediction based on NLP (10)",
          "Python interpretation: price prediction based on NLP (11)",
          "Python interpretation: price prediction based on NLP (12)",
          "Explain Python codes: pricing model and elasticity estimate (1)",
          "39) Explain Python codes: pricing model and elasticity estimate (2)",
          "39) Explain Python codes: pricing model and elasticity estimate (3)",
          "39) Explain Python codes: pricing model and elasticity estimate (4)",
          "Project: build customer and product recommender (1)",
          "Project: build customer and product recommender (2)",
          "Explain Python codes: customer and product recommender (1)",
          "Explain Python codes: customer and product recommender (2)",
          "Explain Python codes: customer and product recommender (3)",
          "Explain Python codes: customer and product recommender (4)",
          "Explain Python codes: customer and product recommender (5)",
          "Explain Python codes: customer and product recommender (6)"
        ],
        "Python Spark for Big Data Analysis and Cloud Computing in AWS and Azure": [
          "Learn Spark, Hadoop and usages (1)",
          "Learn Spark, Hadoop and usages (2)",
          "Lecture on Amazon Web Services (AWS)",
          "Hands-on: register and login AWS",
          "Hands-on: set up AWS and work on Spark (1)",
          "Hands-on: set up AWS and work on Spark (2)",
          "Hands-on: set up AWS and work on Spark (3)",
          "Hands-on: set up AWS and work on Spark (4)",
          "Hands-on: set up AWS and work on Spark (5)",
          "Hands-on: set up AWS and work on Spark (6)",
          "Python Spark: RDD programming on Zeppelin (1)",
          "Python Spark: RDD programming on Zeppelin (2)",
          "Python Spark: RDD programming on Zeppelin (3)",
          "Python Spark: RDD programming on Zeppelin (4)",
          "Python Spark: RDD programming on Zeppelin (5)",
          "Python Spark: RDD programming on Zeppelin (6)",
          "Python Spark: RDD programming on Zeppelin (7)",
          "Python Spark: RDD programming on Zeppelin (8)",
          "Python Spark: RDD programming on Zeppelin (9)",
          "Python Spark: RDD programming on Zeppelin (10)",
          "Python Spark: RDD programming on Zeppelin (11)",
          "Python Spark: RDD programming on Zeppelin (12)",
          "Python Spark: RDD programming on Zeppelin (13)",
          "Python Spark: RDD programming on Zeppelin (14)",
          "Python Spark: RDD programming on Zeppelin (15)",
          "Introduce Spark Data Frame by examples",
          "Understand and use persistent under Spark",
          "Save data under Spark by example",
          "Understand and use accumulator and broadcast",
          "Interact Python Spark and Parquet file storage",
          "Create Spark & Pandas data frame under AWS S3",
          "Example of saving Pandas data frame to AWS S3",
          "Review AWS and Zeppelin",
          "Introduce and create Microsoft Azure account",
          "Set up Microsoft Azure Dashboard for Spark (1)",
          "Set up Microsoft Azure Dashboard for Spark (2)",
          "Set up Microsoft Azure Dashboard for Spark (3)",
          "First example of Python Spark under Azure",
          "Spark data frame and SQL – RDD to spark data frame (1)",
          "Spark data frame and SQL – Spark SQL (2)",
          "Spark data frame and SQL -- read Json files (3)",
          "Spark data frame and SQL – read Parquet files (4)",
          "Spark data frame and SQL – treat missing values (5)",
          "Spark data frame and SQL -- aggregation function (6)",
          "Spark data frame and SQL – aggregation function (7)",
          "Spark data frame and SQL – UDF (8)",
          "Spark data frame and SQL – UDF (9)",
          "Spark data frame and SQL – other DF APIs (10)",
          "Spark data frame and SQL – other DF APIs (11)",
          "Spark data frame and SQL – other DF APIs (12)",
          "Example of Logistic regression under Spark",
          "Apply NLP TF/IDF under Spark",
          "K-means for segmentation under Spark",
          "Text mining case study using TF/IDF under Spark",
          "Project: sentimental analysis under Spark in AWS",
          "Explain decision tree used in credit risk analysis",
          "Python Spark codes for sentimental analysis in AWS (1)",
          "Python Spark codes for sentimental analysis in AWS (2)",
          "Python Spark codes for credit risk analysis in AWS (1)",
          "Python Spark codes for credit risk analysis in AWS (2)",
          "Exam and solution for Python Spark",
          "Introduce Python working with AWS Redshift",
          "Lecture on use cases: Python works with Redshift (1)",
          "Lecture on use cases: Python works with Redshift (2)",
          "Lecture on use cases: Python works with Redshift (3)",
          "Lecture on use cases: Python works with Redshift (4)"
        ]
      },
      "requirements": [
        "Any one should be able to use computer including being able to install software",
        "Desire to learn Python, Data Science and Cloud Computing",
        "Prior exposure to programming languages will be helpful",
        "Basic knowledge and skills of math"
      ],
      "description": "In this nearly 50 hours course, we will walk through the complete Python for starting the career in data science and cloud computing!\nThis is so far the most comprehensive guide to mastering data science, business analytics, statistical tests & modelling, data visualization, machine learning, cloud computing, Big data analysis and real world use cases with Python.\nData science career is not just a traditional IT or pure technical game – this is a comprehensive area, and above all, you must know why you conduct data analysis and how to deploy your results to generate values for the company you are working for or your own business. Therefore, this course not only covers all aspects of practical data science, but also the necessary data engineering skills and business model & knowledge you need in different industries.\nWhether you are working in financing, marketing, health companies, or you are running start-up, knowing the complete application of Python for data science and cloud computing is the must to achieving various business objective and looking insights into data.  Yes, this complete course introduces you to a solid foundation based on the following contents and features\n·       Python programming for data analytics, including Python fundamentals, Numpy array, Pandas Data Frames and Scipy functions.\n·       How big data are collected and analyzed based on many real world examples. such as using Python scraping web data, communicating with flat files, parquet files, SAS data, SQLite, MongoDB and Redshift on AWS\n·       Statistics and its application into various types of business use cases, such as the most useful statistical techniques you’ll need for banking, risk, marketing, pricing, social medium, fraud detection, customers churn & life value analysis and more.\n·       Machine learning algorithms in each use case – all necessary theories and usages for real world applications. Note, this part is taught by both business analyst and PHD mathematician with more than 20 years experience, we teach you ‘why’ from the root, rather than just  ‘model.fit()   model.predict()’ instructed in many other courses.\n·       Data visualization combined with statistical analysis use cases to help students develop a working familiarity to understand data by graph. We will teach you how to apply all famous graphics tools such as matplotlib, plotly online and offline, seaborn and ggplot into many practical cases.\n·       Many hands-on real world projects to review and improve what you have learned in the lectures. For example, we have provided the following typical use cases along with the business backgrounds:  Pricing retail products by checking elasticity; Online sales forecasting using time course data; Recommender system by transaction segmentation; Consumer credit score system; Fraud detection and performance tracking; Natural Language Processing for sentimental analysis and more.\n·       Spark for big data analysis, cloud computing, machine learning on AWS and Azure. We provide detailed technical explanation and real word uses cases on the real cloud environments including the specific process of system configuration.\n·       Features for listening by doing:  the best way to become an expert is to practice while learning. This course is not an exception. Not only we’ll each programming codes and theories, but also need your involvement into reviewing you have learned.\n·       Hundreds to thousands exercises, projects and homework along with detailed solutions. You can hardly find any other similar course with so many hands-on opportunities to solve so many practical problems\n·       Our experts team will provide comprehensive online support. The course will also be on-going updated with announcement\nUpon completing this course, you’ll be able to apply Python to solve various data science, machine learning, statistical analysis and business problems under different environments and interfaces. You can answer different job interview questions and integrate Python and cloud computing into complete applications.\nWant to be successful? then join this course and follow each learning-practicing step! You’ll learn by doing and meet various challenges to become a real data scientist!",
      "target_audience": [
        "Anyone interested in Python for data science, machine learning (theories and usages) and cloud computing (detailed set-up and configuration) to help their current job or start a new career",
        "Anyone who needs to use the course as the referenced material or quick card solutions for Python in data science and machine learning.",
        "Anyone who needs complete interpretation in statistics and business",
        "Any one who needs large scale of practices (home work and real projects) after listening",
        "Anyone looking to solve various business problems and generate value using data driven methods",
        "Business owners, professionals in financing, marketing, health roles who are interested in understanding data better and apply data science way to make decisions",
        "Developers who are looking to build applications such as investment, marketing, e-commerce, risk management, pricing, fraud and clinical trials. social network using Python and cloud computing"
      ]
    },
    {
      "title": "Market Basket Analysis & Linear Discriminant Analysis with R",
      "url": "https://www.udemy.com/course/market-basket-analysis-linear-discriminant-analysis-with-r/",
      "bio": "Master: Association rules (MBA) & it's usage, Linear Discriminant Analysis (LDA) for classification & variable selection",
      "objectives": [
        "Students will know what is association rules (Market Basket Analysis)?",
        "How do association rules work?",
        "How to do market basket analysis using Excel & R",
        "What is linear discriminant analysis?",
        "How to do linear discriminant analysis using R?",
        "How to understand each component of the linear discriminant analysis output?",
        "Practical usage of linear discriminant analysis"
      ],
      "course_content": {
        "Part 1 - Association Rules (Market Basket Analysis)": [
          "Section Overview",
          "How to study this course?",
          "What is Market Basket Analysis (MBA) / Association rules ?",
          "Usage of Association Rules",
          "How does an association rule look like?",
          "Strength of an association rule - Support measure",
          "Strength of an association rule - Confidence measure",
          "Strength of an association rule - Lift measure",
          "Basic Algorithm to derive rules"
        ],
        "Part 1- Association rules demo & quiz": [
          "Demo of Basic Algorithm to derive rules (BFS and DFS)",
          "Demo Using R on Fruit transaction data",
          "Demo Using R on another transaction data",
          "Try your learning - assignment",
          "Revisit your learning",
          "Assignment solution"
        ],
        "Part 2 - Linear Discriminant Analysis (LDA)": [
          "Section Overview",
          "Need of a classification model",
          "Purpose of Linear Discriminants",
          "A case for classification",
          "Formal definition of LDA",
          "Analytics techniques applicability",
          "First practical use of LDA - LDA for Variable Selection",
          "Demo of using LDA for Variable Selection"
        ],
        "Part 2 : Second practical usage of LDA - LDA for classification": [
          "Intuitive Understanding of LDA for classification",
          "First complexity : distance calculation - Euclidean distance",
          "First complexity : distance calculation (enhanced) - Mahalanobis distance 01",
          "First complexity : distance calculation (enhanced) - Mahalanobis distance 02",
          "Second complexity : Linear Discriminant Function",
          "Third complexity : Posterior Probability (Bays Theorem)",
          "Demo of LDA using R part 01",
          "Demo of LDA using R part 02",
          "LDA vs PCA side by side",
          "Demo of LDA for more than two classes - part 01",
          "Demo of LDA for more than two classes - part 02",
          "Industrial usage of LDA",
          "Handling Special Cases (biased sample / differential misclassification) in LDA",
          "Revisit your learning of LDA",
          "Revisit your learning of LDA - 02",
          "Closing Note"
        ]
      },
      "requirements": [
        "Basic understanding of R and R studio",
        "Basic understanding of statistics as the course will assume knowledge of linear regression, variance etc.",
        "Basic fmiliarity with udemy platform - user should know how to download files etc"
      ],
      "description": "This course has two parts. In part 1 Association rules (Market Basket Analysis) is explained. In Part 2, Linear Discriminant Analysis (LDA) is explained. L\n--------------------------------------------------\n\nDetails of Part 1 - Association Rules / Market Basket Analysis (MBA)\n----------------------------------------------------\nWhat is Market Basket Analysis (MBA) or Association rules\nUsage of Association Rules - How it can be applied in a variety of situations\nHow does an association rule look like?\nStrength of an association rule -\nSupport measure\nConfidence measure\nLift measure\nBasic Algorithm to derive rules\nDemo of Basic Algorithm to derive rules - discussion on breadth first algorithm and depth first algorithm\nDemo Using R - two examples\nAssignment to fortify concepts\n--------------------------------------------------\nDetails of Part 2 - Linear  (Market Basket Analysis)\n----------------------------------------------------\nNeed of a classification model\nPurpose of Linear Discriminant\nA use case for classification\nFormal definition of LDA\nAnalytics techniques applicability\nTwo usage of LDA\nLDA for Variable Selection\nDemo of using LDA for Variable Selection\nSecond usage of LDA - LDA for classification\nDetails on second practical usage of LDA\nUnderstand which are three important component to understand LDA properly\nFirst complexity of LDA - measure distance :Euclidean distance\nFirst complexity of LDA - measure distance enhanced  :Mahalanobis distance\nSecond complexity of LDA - Linear Discriminant function\nThird complexity of LDA - posterior probability / Bays theorem\nDemo of LDA using R\nAlong with jack knife approach\nDeep dive into LDA outputn\nVisualization of LDA operations\nUnderstand the LDA chart statistics\nLDA vs PCA side by side\nDemo of LDA for more than two classes: understand\nData visualization\nModel development\nModel validation on train data set and test data sets\nIndustry usage of classification algorithm\nHandling Special Cases in LDA",
      "target_audience": [
        "Market Research Professionals",
        "Business Analytics professionals",
        "Data Scientists"
      ]
    },
    {
      "title": "Unleash Machine Learning: Build Artificial Neuron in Python",
      "url": "https://www.udemy.com/course/unleash-machine-learning-build-artificial-neuron-in-python/",
      "bio": "A journey into Machine Learning concepts using your very own Artificial Neural Network: Load, Train, Predict, Evaluate",
      "objectives": [
        "Build from scratch your own Artificial Neural Network",
        "Know the fundamentals of Machine Learning and ANN",
        "Train your ANN using 3 different datasets with increasing complexity",
        "Predict the correct output using your trained ANN",
        "Evaluate the accuracy of your predictions",
        "Use scikit-learn, numpy and opencv"
      ],
      "course_content": {
        "Introduction": [
          "Overview",
          "Github ANN Course repository"
        ],
        "Neuron": [
          "Biological Neuron",
          "Artificial Neuron",
          "Compute a logical function",
          "Linear Separability",
          "Compute another logical function",
          "Trick to remove the inside threshold",
          "Weights",
          "Decision boundary",
          "Perceptron learning",
          "Quiz 1"
        ],
        "Implementation": [
          "Top down design",
          "Predict (forward)",
          "Train part 1",
          "Train part 2",
          "The XOR problem",
          "Add hyperbolic tangent activation function",
          "Refactor activation function",
          "Improve weight initialization",
          "Intuition XOR is hard",
          "Intuition ANN == universal approximator",
          "Approximate a strange function example"
        ],
        "Applications": [
          "Iris Classifier",
          "Digits Classifier",
          "Save and Load functionality",
          "Save and Load FIX",
          "MNIST classifier"
        ],
        "Valuable Resources": [
          "AIception and AIcrafters Resources"
        ]
      },
      "requirements": [
        "Install scikit learn (for windows use anaconda)",
        "Python 2.7.X working",
        "ipython notebook working"
      ],
      "description": "Cars that drive themselves hundreds of miles with no accidents?\nAlgorithms that recognize objects and faces from images with better performance than humans?\nAll possible thanks to Machine Learning!\nIn this course you will begin Machine Learning by implementing and using your own Artificial Neuronal Network for beginners.\nIn this Artificial Neuronal Network course you will:\nunderstand intuitively and mathematically the fundamentals of ANN\nimplement from scratch a multi layer neuronal network in Python\nload and visually explore different datasets\ntransform the data\ntrain you network and use it to make predictions\nmeasure the accuracy of your predictions\nuse machine learning tools and techniques\n\n\nJump in directly:\nAll sourcecode and notebooks on public GitHub\nApply Machine Learning: section 4\nImplement the ANN: section 3\nFull ride: section 1, 2, 3, 4",
      "target_audience": [
        "SHOULD NOT: beginners in Python",
        "SHOULD NOT: experts in Machine Learning",
        "SHOULD: students that want to begin Machine Learning with concepts and tools",
        "SHOULD: students who want to learn and gain insights into why Artificial Neural Networks are such a powerful and unique tool"
      ]
    },
    {
      "title": "PyTorch for Deep Learning Computer Vision Bootcamp 2025",
      "url": "https://www.udemy.com/course/deep-learning-pytorch/",
      "bio": "Master Computer Vision in PyTorch/Python: Beginner to Pro with Expert Tips on Convolutional Neural Networks (CNNs)",
      "objectives": [
        "Master how to Perform Computer Vision Task with Deep Learning",
        "Learn to Work with PyTorch",
        "Convolutional Neural Networks with Torch Library",
        "Build Intuition on Convolution Operation on Images",
        "Learn to Implement LeNet Architecture on CIFAR10 dataset which has 60000 images"
      ],
      "course_content": {
        "Welcome Aboard": [
          "Why PyTorch is Powerful"
        ],
        "Introduction": [
          "Introduction to Pytorch",
          "Getting System Ready",
          "Create Tensors in Pytorch",
          "Tensor Slicing and Reshape",
          "Mathematical Operations on Tensors",
          "Numpy in Pytorch",
          "What is CUDA",
          "Pytorch on GPU",
          "Download Materials",
          "Assignment on Pytorch Basics"
        ],
        "AutoGrad in Pytorch": [
          "Autograd in Pytorch",
          "Implementing Gradient Descent using Autograd",
          "Download Materials",
          "Assignment on Autograd"
        ],
        "Creating Deep Neural Networks in Pytorch": [
          "Building first neural network",
          "Writing Deep neural network",
          "Writing Custom NN module",
          "Download Materials",
          "Assignment on Deep Neural Networks"
        ],
        "CNN on Pytorch": [
          "Data Loading - CIFAR10",
          "Data Visualization",
          "CNN Recap",
          "First CNN",
          "CNN Deep layers",
          "Download Materials"
        ],
        "LeNet Architecture in Pytorch": [
          "LeNet Overview",
          "LeNet Model in Pytorch",
          "Preparation & Evaluation",
          "Download Materials"
        ],
        "Optional Learning- Python Basics": [
          "Why Computer Programming Language",
          "Why Python?",
          "Getting System Ready - Installing Jup[yter Notebook",
          "Jupyter Notebook - Tips & Tricks",
          "What is Covered in this section",
          "Variables in Python",
          "Print Function",
          "Numeric Data Type",
          "String Data Type",
          "Boolean Data Type",
          "Type Conversion & Type Casting",
          "Adding Comments in Python Programming Language",
          "Data Structures in Python",
          "Tuples & Sets in Python",
          "Python Dictionaries",
          "Conditional Statements in Python - if",
          "Conditional Statements in Python - While",
          "Inbuilt Functions in Python - range & input",
          "For Loops",
          "Functions in Python",
          "Classes in Python"
        ],
        "Mini Project with Python Basics": [
          "Section Attachment",
          "Mini Project - Hangman",
          "Writing a class",
          "Mini Project - Continued",
          "Logic Building",
          "Logic for Single Letter input",
          "Final Testing"
        ],
        "Python for Data Science - Numpy": [
          "Numpy Library Code",
          "Why Numpy?",
          "Numpy",
          "Resize & Reshape of Arrays",
          "Slicing",
          "Broadcasting",
          "Mathematical Operations & Functions in Numpy"
        ],
        "Python for Data Science - Pandas": [
          "Section Attachments",
          "Pandas Library",
          "Pandas Dataframe",
          "Pandas Dataframe - Load from External file",
          "Working with null values",
          "Slicing Pandas Dataframe",
          "Imputation"
        ]
      },
      "requirements": [
        "Basic Machine learning with Python Programming Language"
      ],
      "description": "Dive into Computer Vision with PyTorch: Master Deep Learning, CNNs, and GPU Computing for Real-World Applications - 2024 Edition\"\nUnlock the potential of Deep Learning in Computer Vision, where groundbreaking advancements shape the future of technology. Explore applications ranging from Facebook's image tagging and Google Photo's People Recognition to fraud detection and facial recognition. Delve into the core operations of Deep Learning Computer Vision, including convolution operations on images, as you master the art of extracting valuable information from digital images.\nIn this comprehensive course, we focus on one of the most widely used Deep Learning frameworks – PyTorch. Recognized as the go-to tool for Deep Learning in both product prototypes and academia, PyTorch stands out for its Pythonic nature, ease of learning, higher developer productivity, dynamic approach for graph computation through AutoGrad, and GPU support for efficient computation.\nWhy PyTorch?\nPythonic: PyTorch aligns seamlessly with the Python programming language, offering a natural and intuitive experience for learners.\nEasy to Learn: The simplicity of PyTorch makes it accessible for beginners, allowing a smooth learning curve.\nHigher Developer Productivity: PyTorch's design prioritizes developer productivity, promoting efficiency in building and experimenting with models.\nDynamic Approach for Graph Computation - AutoGrad: PyTorch's dynamic computational graph through AutoGrad enables flexible and efficient model development.\nGPU Support: PyTorch provides GPU support for accelerated computation, enhancing performance in handling large datasets and complex models.\nCourse Highlights:\nGain a foundational understanding of PyTorch, essential for delving into the world of Deep Learning.\nLearn GPU programming and explore how to access free GPU resources for efficient learning.\nMaster the AutoGrad feature of PyTorch, a key aspect for dynamic graph computation.\nImplement Deep Learning models using PyTorch, transitioning from theory to practical application.\nExplore the basics of Convolutional Neural Networks (CNNs) in PyTorch, a fundamental architecture for computer vision tasks.\nApply CNNs to real-world datasets, developing hands-on experience with practical applications.\nOur Approach:\nWe believe that true learning extends beyond theoretical understanding; it involves building confidence through practical application. Throughout the course, we've incorporated assignments at the end of each section, enabling you to measure your progress and reinforce your learning. We aspire to empower you with the skills and confidence needed to navigate the dynamic field of Deep Learning in Computer Vision.\nEmbark on this journey with Manifold AI Learning, where innovation meets education. We look forward to welcoming you inside the course and witnessing your success. Best of luck!\nManifold AI Learning",
      "target_audience": [
        "Software Developer",
        "Machine Learning Practitioner",
        "Data Scientist",
        "Anyone interested to learn PyTorch",
        "Anyone interested in Deep learning"
      ]
    },
    {
      "title": "Azure Open AI & Prompt Engineering Zero to Hero with Chatgpt",
      "url": "https://www.udemy.com/course/azopenai/",
      "bio": "Become an expert in Azure Open AI, Chatgpt & Prompt Engineering from scratch with practical examples - The Master Course",
      "objectives": [
        "Understand the concepts and applications of Azure Open AI and Prompt Engineering",
        "Understand the concepts and applications of Azure Open AI and Prompt Engineering",
        "Discover various Azure cognitive services and how to use them in Open AI and Prompt Engineering",
        "Dive deep into Prompt Engineering and learn how to create and fine-tune AI models using GPT-3 and other OpenAI models",
        "Get tips and insights from experienced AI and Azure professionals on how to optimize your Azure Open AI and Prompt Engineering projects",
        "Practice your skills with real-world examples and exercises, including building a chatbot with OpenAI's and deploying it on Azure."
      ],
      "course_content": {
        "Introduction to Azure Open AI": [
          "Introduction",
          "Modules",
          "Azure Open AI Introduction",
          "Azure Open AI Features",
          "Azure Open AI : Use Cases",
          "Open AI vs Azure Open AI",
          "Request Access for Azure Open AI",
          "Concept: Prompts & Completion",
          "Concept: Tokens",
          "Example: Prompts , Completions & Tokens",
          "Learnings: Few Shot, One Shot and No Shot",
          "Concept: Davinci",
          "Concept: Curie",
          "Concept: Babbage",
          "Concept: Ada",
          "Concept: Codex",
          "Prompt Engineering",
          "Concept: Generative",
          "Create Azure Open AI Resource",
          "First Look of Azure Open AI Studio and Create your first model.",
          "Demo: Davinci in Azure Open AI Studio",
          "Demo: Deep Dive with Examples in Azure Open AI Studio",
          "Demo: Working with Code in the playground",
          "Concept: Datasets",
          "Concept: Fine tuning"
        ],
        "Designing Application: ChatGPT using Azure Open API": [
          "Architecture of the Application",
          "Getting Started: Configuring the Environment",
          "Building ChatGPT like Application Part 1",
          "Building ChatGPT like Application Part 2",
          "Building ChatGPT like Application Part 3",
          "Building ChatGPT like Application Part 4",
          "Final ChatGPT like Application",
          "Chat Playground in Azure Open AI Studio"
        ],
        "Embeddings": [
          "Create a deployment model",
          "Concept: Embeddings",
          "Demo: Embedding"
        ],
        "Demo: Azure Open AI Studio(Overview)": [
          "Demo: Azure Open AI Studio"
        ],
        "Demo: Create a Bot": [
          "Bot"
        ]
      },
      "requirements": [
        "Basic knowledge of Azure Cloud Platform"
      ],
      "description": "Welcome to the \"Azure Open AI & Prompt Engineering Zero to Hero with Chatgpt\" course!\nIn this course, you will learn how to work with Azure OpenAI, specifically the GPT-3.5/4 model and how to use it for prompt engineering, which is the art of crafting effective prompts to generate high-quality text responses. You will start with the basics of Azure OpenAI and progress to more advanced topics, such as prompt engineering, data preparation, and model fine-tuning.\nBy the end of this course, you will have a strong understanding of Azure OpenAI and how to use it for prompt engineering, as well as the skills to build your own powerful AI applications using GPT-3.5.\nThis course is designed for developers and data scientists who are interested in learning how to work with Azure OpenAI and want to become proficient in prompt engineering.\n\n\nLearn about the fundamentals of Azure Open AI and Prompt Engineering.\nUnderstand the concept of natural language processing and how it works with AI.\nDive deep into the principles of prompt engineering, and how it can be used to generate human-like text.\nExplore the different tools and platforms offered by Azure for Open AI and Prompt Engineering.\nUnderstand the importance of pre-training and fine-tuning in creating robust AI models.\nDiscover how to use GPT-3 models for text completion and generation.\nLearn how to train and deploy GPT-3 models on Azure.\nGain insights into best practices for working with Open AI and Prompt Engineering.\nLearn about the ethical considerations and potential risks associated with AI and how to mitigate them.\n\n\nBy the end of this course, you will have a solid understanding of Azure Open AI and Prompt Engineering and be able to apply this knowledge to create powerful and effective AI models. Whether you are a developer, data scientist, or AI enthusiast, this course will provide you with the skills and knowledge you need to take your AI projects to the next level.\n\n\nEnroll today and start your journey to becoming an Azure OpenAI and prompt engineering expert!",
      "target_audience": [
        "Anyone interested in AI and language processing and wants to learn how to use OpenAI GPT models and prompt engineering in Azure cloud.",
        "Developers and engineers who want to learn how to build AI-powered applications",
        "Data scientists and analysts who want to expand their knowledge of AI and natural language processing",
        "If you would like to become Prompt Engineer"
      ]
    },
    {
      "title": "Statistics for Data Analysts and Scientists 2023",
      "url": "https://www.udemy.com/course/statistics-for-data-analysts-and-scientists/",
      "bio": "Ultimate course to master practical and business applications of essential statistical tests and concepts",
      "objectives": [
        "Develop a deep understanding of key statistical concepts, such as homoscedasticity of variance, multicollinearity, and homogeneity of variance",
        "Gain the skills to apply statistical tests and concepts to real-world situations and communicate insights to key stakeholders",
        "Understand how statistical tools can be used to gain insights into complex data sets and how these insights can be used to drive critical business decisions",
        "Learn through practical examples, and case studies that will help them understand how statistical tests can be applied in real-world situations",
        "Gain the confidence and expertise to excel as a data analyst or scientist, and apply statistical methods to a wide range of data-driven challenges",
        "Understand the practical and business applications of essential statistical tests, including the Chi Square test, t-tests, correlation, Regression, etc",
        "Learn how to conduct and interpret key statistical tests, including one-sample t-test, independent sample test, correlation and linear regression, OneWay ANOVA"
      ],
      "course_content": {},
      "requirements": [
        "No programming or prior experience of statistics required"
      ],
      "description": "Welcome to \"Statistics for Data Analysts and Scientists\" - the ultimate course to help you master the practical and business applications of essential statistical tests and concepts!\nAre you struggling to make sense of statistical tests like the Chi-Square test of independence, t-tests, correlation, and Analysis of Variance (ANOVA)? Are you looking to understand how these tests can be applied in real-world situations, and how they can be used to drive critical business decisions?\nThis comprehensive course is designed to equip you with the knowledge and skills to excel as a data analyst or scientist. You will learn how to conduct and interpret key statistical tests such as the one-sample t-test, independent sample t-test, dependent sample t-test, correlation, simple and multiple linear regression, and one-way ANOVA. You will also gain a deep understanding of key statistical concepts like homoscedasticity of variance, multicollinearity, and homogeneity of variance.\nWith an exciting and engaging teaching style, this course will take you on a journey of discovery that will transform your understanding of statistics. You will learn through a combination of theory, practical examples, and case studies that will help you understand how statistical tests can be applied in real-world situations.\nBy the end of this course, you will have the confidence and expertise to apply statistical tests and concepts to drive critical business decisions. You will be able to use statistical tools to gain insights into complex data sets, and you will be equipped with the skills to communicate these insights to key stakeholders.\nSo, what are you waiting for? Sign up for \"Statistics for Data Analysts and Scientists\" today, and take the first step towards becoming a master of statistical analysis!",
      "target_audience": [
        "Data analysts who want to improve their statistical skills and knowledge",
        "Scientists who need to understand and analyze statistical data in their research",
        "Business professionals who use data to drive decision-making and want to gain a deeper understanding of statistical concepts and tests",
        "Students studying statistics, data science, or a related field who want to develop a strong foundation in statistical methods",
        "Anyone who is interested in learning more about statistics and how it can be applied in practical settings"
      ]
    },
    {
      "title": "Data Augmentation in NLP",
      "url": "https://www.udemy.com/course/data-augmentation-in-nlp/",
      "bio": "Augment your Dataset and Outperform",
      "objectives": [
        "Data Augmentation using Word Embeddings",
        "Data Augmentation using Word Embeddings - Implementation",
        "Data Augmentation using BERT",
        "Data Augmentation using BERT - Implementation",
        "Data Augmentation using Back Translation",
        "Data Augmentation using Back Translation - Implementation",
        "Data Augmentation using T5",
        "Data Augmentation using T5 - Implementation",
        "Improving Quality of Augmented Data using Similarity Filter",
        "Ensemble Approach for Data Augmentation",
        "Comparison of Data Augmentation Techniques"
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Word embeddings": [
          "Data augmentation using word embeddings",
          "Implementation"
        ],
        "BERT": [
          "Data augmentation using BERT",
          "Implementation"
        ],
        "Back Translation": [
          "Data augmentation using Back Translation",
          "Implementation"
        ],
        "T5": [
          "Data augmentation using T5",
          "Implementation"
        ],
        "Ensemble Approach": [
          "Similarity filter",
          "Ensemble Approach"
        ],
        "Comparison": [
          "Comparison"
        ]
      },
      "requirements": [
        "Basic knowledge of machine learning and NLP is good to have"
      ],
      "description": "You might have optimal machine learning algorithm to solve your problem. But once you apply it in real world soon you will realize that you need to train it on more data. Due to lack of large dataset you will try to further optimize the algorithm, tune hyper-parameters or look for some low tech approach. Most state of the art machine learning models are trained on large datasets. Real world performance of machine learning solutions drastically improves with more data.\nThrough this course you will learn multiple techniques for augmenting text data. These techniques can be used to generate data for any NLP task. This augmented dataset can help you to bridge the gap and quickly improve accuracy of your machine learning solutions.",
      "target_audience": [
        "Anyone interested in machine learning and NLP."
      ]
    },
    {
      "title": "Deep Reinforcement Learning: Hands-on AI Tutorial in Python",
      "url": "https://www.udemy.com/course/deep-reinforcement-learning-a-hands-on-tutorial-in-python/",
      "bio": "Develop Artificial Intelligence Applications using Reinforcement Learning in Python.",
      "objectives": [
        "The concepts and fundamentals of reinforcement learning",
        "The main algorithms including Q-Learning, SARSA as well as Deep Q-Learning.",
        "How to formulate a problem in the context of reinforcement learning and MDP.",
        "Apply the learned techniques to some hands-on experiments and real world projects.",
        "Develop artificial intelligence applications using reinforcement learning."
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Course Structure",
          "Environment Setup"
        ],
        "Jump into Reinforcement Learning": [
          "Introduction",
          "RL Applications",
          "RL vs. Supervised and Unsupervised Learning",
          "What is reinforcement learning?"
        ],
        "RL Algorithms": [
          "Markov Decision Process",
          "Optimal Policy",
          "Bellman Equation",
          "Q-Learning",
          "Step-by-step Example",
          "Sarsa",
          "Deep Q-Network",
          "Exploration vs. Exploitation",
          "Define RL Problem - Examples",
          "Reinforcement learning algorithms",
          "SARSA algorithm"
        ],
        "Hands-on Project 1 - Maze Problem": [
          "Overall Design",
          "Create Project",
          "Create files",
          "Create Maze Environment class",
          "Implement Building Maze Grid",
          "Test build_maze method",
          "Render and Reset methods",
          "Implement getting next state and reward",
          "Create Agent class",
          "Implement adding states",
          "Implement choosing action",
          "Implement learn method",
          "Create App",
          "Implement main method",
          "Implement plotting results",
          "Run the App",
          "Expand Maze Environment"
        ],
        "Hands-on Project 2 - Stock Trading": [
          "Overall Design",
          "Start project",
          "Prepare dataset",
          "Create Market Environment class",
          "Implement getting data",
          "Implement getting all states",
          "Implement getting next state and reward",
          "Create Agent class",
          "Implement creating deep learning model and reset method",
          "Implement getting action",
          "Implement buy and sell",
          "Implement experience replay",
          "Create training app",
          "Test training app",
          "Create evaluation app",
          "Implement plotting results",
          "Run training and evaluation",
          "Extending Stock Trading with Multiple Features",
          "Multiple Feature Stock Trader"
        ],
        "Summary": [
          "Summary"
        ]
      },
      "requirements": [
        "Students are assumed to be familiar with python and have some basic knowledge of statistics, and deep learning."
      ],
      "description": "In this course we learn the concepts and fundamentals of reinforcement learning, it's relation to artificial intelligence and machine learning, and how we can formulate a problem in the context of reinforcement learning and Markov Decision Process. We cover different fundamental algorithms including Q-Learning, SARSA as well as Deep Q-Learning. We present the whole implementation of two projects from scratch with Q-learning and Deep Q-Network.",
      "target_audience": [
        "Machine learning and AI enthusiasts and practitioners, data scientists, machine learning engineers."
      ]
    },
    {
      "title": "Python Image Processing, Face & Motion Detection with OpenCV",
      "url": "https://www.udemy.com/course/computer-vision-in-python-face-detection-image-processing/",
      "bio": "Master Computer Vision using OpenCV to Implement Image Processing, Face Recognition and Motion Detection Using Python",
      "objectives": [
        "Use OpenCV to work with image files",
        "Understanding the fundamentals of computer vision & image processing",
        "Use Python and OpenCV to draw shapes on images and videos",
        "Get started with image manipulation with OpenCV, including smoothing, blurring, thresholding, and morphological operations.",
        "OpenCV Image Manipulation Fundamentals using Python. Also includes a Python basics refresher session.",
        "Open and Stream video with Python and OpenCV",
        "Detect Objects, including corner, edge, and grid detection techniques with OpenCV and Python",
        "Create Face Detection Software Using Haar Classifier",
        "Have a toolbox of the most powerful Computer Vision models",
        "Understand the theory behind Computer Vision",
        "Create powerful Computer Vision applications"
      ],
      "course_content": {},
      "requirements": [
        "Basic Python programming knowledge"
      ],
      "description": "Unlock the power of computer vision with our comprehensive course and also get a FREE comprehensive eBook that will accompany you along in this course, “Python Face Detection & Image Processing in Computer Vision with a FREE Coding Book”. Designed for beginners, this course will guide you through the fascinating world of computer vision, equipping you with the skills to create your own image and video processing applications.\nWhat You’ll Learn:\nIntroduction to Computer Vision: Understand the basics and significance of computer vision in today’s technology-driven world.\nPyCharm, NumPy, and OpenCV Setup for Beginners: Step-by-step instructions to set up your development environment and essential libraries.\nWorking with NumPy in Computer Vision: Learn how to manipulate and process images using NumPy arrays.\nHow to Read an Image in OpenCV: Master the techniques to load and display images using OpenCV.\nHow to Read a Video in OpenCV: Discover how to capture and process video streams.\nFace Detection Using Haar Cascade Classifier: Implement face detection algorithms to identify faces in images.\nEye Detection Using Haar Cascade Classifier: Extend your skills to detect eyes within detected faces.\nFace Detection in a Video: Apply face detection techniques to real-time video streams.\nEye Detection in a Video: Enhance your video processing skills by detecting eyes in video streams.\nHow to Handle Mouse Click Events in OpenCV: Learn to interact with images using mouse events.\nImage Thresholding in Computer Vision: Explore various thresholding techniques to segment images.\nWorking with Matplotlib in Computer Vision: Visualize your image processing results using Matplotlib.\nMorphological Transformations in Computer Vision: Perform advanced image processing tasks like erosion, dilation, opening, and closing.\nImage Filtration Processes in Computer Vision: Implement filters to enhance or detect features in images.\nImage Pyramids in Computer Vision: Understand and apply image pyramids for multi-scale image processing.\nContours in Computer Vision: Detect and analyze contours in images for shape analysis.\nGeometric Shapes Analysis in Computer Vision: Analyze and manipulate geometric shapes within images.\nWhy Enroll in This Course?\nHands-On Learning: Engage in practical exercises and projects to solidify your understanding.\nExpert Guidance: Learn from experienced instructors who are passionate about computer vision.\nComprehensive Curriculum: Cover all essential topics from basic setup to advanced image processing techniques.\nReal-World Applications: Gain skills that are directly applicable to real-world projects and job roles.\nCommunity Support: Join a community of learners and professionals to share knowledge and collaborate on projects.\nWho Should Enroll?\nBeginners: No prior experience in computer vision or Python is required.\nAspiring Developers: Ideal for those looking to start a career in computer vision and image processing.\nTech Enthusiasts: Perfect for anyone interested in exploring the capabilities of computer vision.\nEnroll Now!\nTake the first step towards mastering computer vision with Python and OpenCV. Enroll in “Computer Vision In Python | Face Detection & Image Processing using OpenCV” today and transform your passion for technology into practical skills!\n\n\nComputer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do. Computer vision is concerned with the automatic extraction, analysis and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding. As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems.\n\n\nDistinctions\nThe fields most closely related to computer vision are image processing, image analysis and machine vision. There is a significant overlap in the range of techniques and applications that these cover. This implies that the basic techniques that are used and developed in these fields are similar, something which can be interpreted as there is only one field with different names. On the other hand, it appears to be necessary for research groups, scientific journals, conferences and companies to present or market themselves as belonging specifically to one of these fields and, hence, various characterizations which distinguish each of the fields from the others have been presented.\nComputer graphics produces image data from 3D models, computer vision often produces 3D models from image data. There is also a trend towards a combination of the two disciplines, e.g., as explored in augmented reality.\nThe following characterizations appear relevant but should not be taken as universally accepted:\nImage processing and image analysis tend to focus on 2D images, how to transform one image to another, e.g., by pixel-wise operations such as contrast enhancement, local operations such as edge extraction or noise removal, or geometrical transformations such as rotating the image. This characterization implies that image processing/analysis neither require assumptions nor produce interpretations about the image content.\nComputer vision includes 3D analysis from 2D images. This analyzes the 3D scene projected onto one or several images, e.g., how to reconstruct structure or other information about the 3D scene from one or several images. Computer vision often relies on more or less complex assumptions about the scene depicted in an image.\nMachine vision is the process of applying a range of technologies & methods to provide imaging-based automatic inspection, process control and robot guidance in industrial applications. Machine vision tends to focus on applications, mainly in manufacturing, e.g., vision-based robots and systems for vision-based inspection, measurement, or picking (such as bin picking). This implies that image sensor technologies and control theory often are integrated with the processing of image data to control a robot and that real-time processing is emphasized by means of efficient implementations in hardware and software. It also implies that the external conditions such as lighting can be and are often more controlled in machine vision than they are in general computer vision, which can enable the use of different algorithms.\nThere is also a field called imaging which primarily focuses on the process of producing images, but sometimes also deals with processing and analysis of images. For example, medical imaging includes substantial work on the analysis of image data in medical applications.\nFinally, pattern recognition is a field which uses various methods to extract information from signals in general, mainly based on statistical approaches and artificial neural networks. A significant part of this field is devoted to applying these methods to image data.\nApplications\nApplications range from tasks such as industrial machine vision systems which, say, inspect bottles speeding by on a production line, to research into artificial intelligence and computers or robots that can comprehend the world around them. The computer vision and machine vision fields have significant overlap. Computer vision covers the core technology of automated image analysis which is used in many fields. Machine vision usually refers to a process of combining automated image analysis with other methods and technologies to provide automated inspection and robot guidance in industrial applications. In many computer-vision applications, the computers are pre-programmed to solve a particular task, but methods based on learning are now becoming increasingly common. Examples of applications of computer vision include systems for:\nAutomatic inspection, e.g., in manufacturing applications;\nAssisting humans in identification tasks, e.g., a species identification system\nControlling processes, e.g., an industrial robot;\nDetecting events, e.g., for visual surveillance or people counting, e.g., in the restaurant industry;\nInteraction, e.g., as the input to a device for computer-human interaction;\nModeling objects or environments, e.g., medical image analysis or topographical modeling;\nNavigation, e.g., by an autonomous vehicle or mobile robot; and\nOrganizing information, e.g., for indexing databases of images and image sequences.\n\n\nMedicine\nOne of the most prominent application fields is medical computer vision, or medical image processing, characterized by the extraction of information from image data to diagnose a patient. An example of this is detection of tumors, arteriosclerosis or other malign changes; measurements of organ dimensions, blood flow, etc. are another example. It also supports medical research by providing new information: e.g., about the structure of the brain, or about the quality of medical treatments. Applications of computer vision in the medical area also includes enhancement of images interpreted by humans—ultrasonic images or X-ray images for example—to reduce the influence of noise.\n\n\nMachine Vision\nA second application area in computer vision is in industry, sometimes called machine vision, where information is extracted for the purpose of supporting a manufacturing process. One example is quality control where details or final products are being automatically inspected in order to find defects. Another example is measurement of position and orientation of details to be picked up by a robot arm. Machine vision is also heavily used in agricultural process to remove undesirable food stuff from bulk material, a process called optical sorting.\n\n\nMilitary\nMilitary applications are probably one of the largest areas for computer vision. The obvious examples are detection of enemy soldiers or vehicles and missile guidance. More advanced systems for missile guidance send the missile to an area rather than a specific target, and target selection is made when the missile reaches the area based on locally acquired image data. Modern military concepts, such as \"battlefield awareness\", imply that various sensors, including image sensors, provide a rich set of information about a combat scene which can be used to support strategic decisions. In this case, automatic processing of the data is used to reduce complexity and to fuse information from multiple sensors to increase reliability.\n\n\nAutonomous vehicles\nOne of the newer application areas is autonomous vehicles, which include submersibles, land-based vehicles (small robots with wheels, cars or trucks), aerial vehicles, and unmanned aerial vehicles (UAV). The level of autonomy ranges from fully autonomous (unmanned) vehicles to vehicles where computer-vision-based systems support a driver or a pilot in various situations. Fully autonomous vehicles typically use computer vision for navigation, e.g. for knowing where it is, or for producing a map of its environment (SLAM) and for detecting obstacles. It can also be used for detecting certain task specific events, e.g., a UAV looking for forest fires. Examples of supporting systems are obstacle warning systems in cars, and systems for autonomous landing of aircraft. Several car manufacturers have demonstrated systems for autonomous driving of cars, but this technology has still not reached a level where it can be put on the market. There are ample examples of military autonomous vehicles ranging from advanced missiles to UAVs for recon missions or missile guidance. Space exploration is already being made with autonomous vehicles using computer vision, e.g., NASA's Curiosity and CNSA's Yutu-2 rover.\n\n\nTactile Feedback\nMaterials such as rubber and silicon are being used to create sensors that allow for applications such as detecting micro undulations and calibrating robotic hands. Rubber can be used in order to create a mold that can be placed over a finger, inside of this mold would be multiple strain gauges. The finger mold and sensors could then be placed on top of a small sheet of rubber containing an array of rubber pins. A user can then wear the finger mold and trace a surface. A computer can then read the data from the strain gauges and measure if one or more of the pins is being pushed upward. If a pin is being pushed upward then the computer can recognize this as an imperfection in the surface. This sort of technology is useful in order to receive accurate data of the imperfections on a very large surface. Another variation of this finger mold sensor are sensors that contain a camera suspended in silicon. The silicon forms a dome around the outside of the camera and embedded in the silicon are point markers that are equally spaced. These cameras can then be placed on devices such as robotic hands in order to allow the computer to receive highly accurate tactile data.\nOther application areas include:\nSupport of visual effects creation for cinema and broadcast, e.g., camera tracking (matchmoving).\nSurveillance.\nDriver drowsiness detection\nTracking and counting organisms in the biological sciences\n[Reference: Wikipedia]",
      "target_audience": [
        "Anyone interested in Data Science, Computer Vision or Artificial Intelligence",
        "Beginners who wants to start with Python Computer Vision using OpenCV",
        "Anyone interested to build computer vision applications",
        "Anyone who wants to level up in programming this year",
        "Anyone who wants to advance his/her career in python programming"
      ]
    },
    {
      "title": "LangGraph Mastery: Develop LLM Agents with LangGraph",
      "url": "https://www.udemy.com/course/langgraph-mastery-develop-llm-agents-with-langgraph/",
      "bio": "Master the Power of LLM Agents with LangChain and LangGraph: Create AI Workflows, Automate Tasks and Transform Your Apps",
      "objectives": [
        "How to create ReAct agents from scratch.",
        "Gain a good understanding of LangGraph concepts and core components.",
        "Implement advanced agents.",
        "Dive deep into nodes, edges, and conditional edges.",
        "Learn about Tavily AI and agentic search.",
        "Understand LLM patterns such as reflection and reflexion.",
        "Explore LangSmith and learn how to debug and trace LLM applications with it.",
        "Learn about flow engineering.",
        "This will be a learning-by-doing experience. Together, we'll build agentic LLM apps step-by-step, line-by-line.",
        "Create a Knowledge Base for RAG from Scratch",
        "Projects: 1. Create a ReAct agent from scratch 2. Develop a ChatBot app using LangGraph 3. Build a Tweet generator using reflection 4. Create an essay writer.",
        "Master Project 5: Build a Research Agent with LangGraph, GPT-4o, RAG, Pinecone, ArXiv, and Google SerpAPI",
        "Learn how to build a complex agentic LLM app step by step."
      ],
      "course_content": {
        "Getting Started": [
          "Course Prerequisites",
          "Join Our Online Community!",
          "Course Resources"
        ],
        "Building a Simple ReAct Agent from Scratch": [
          "Introduction to Agents and ReAct",
          "Creating the Agent Class",
          "Creating the ReAct Prompt",
          "Creating the Tools",
          "Testing the Agent",
          "Automating the Agent",
          "Project Source Code"
        ],
        "Building with LangGraph": [
          "LangGraph Concepts and Core Components",
          "Building a ChatBot",
          "Visualizing the Graph",
          "Running the ChatBot",
          "Tavily AI",
          "Enhancing the ChatBot with Tools",
          "Adding Memory to the ChatBot",
          "Project Source Code"
        ],
        "Reflection - Tweet Generator": [
          "Intro to Reflection",
          "Generate",
          "Reflect and Repeat",
          "Define the Graph - Part 1",
          "Define the Graph - Part 2",
          "Running the App",
          "Project Source Code"
        ],
        "LangSmith: Platform for Building Production-grade LLM Apps": [
          "LangSmith",
          "Setting up LangSmith",
          "Tracing with LangSmith",
          "Tracing the Reflection Agentic App with LangSmith",
          "Project Source Code"
        ],
        "Reflexion - Essay Writer": [
          "Project Overview",
          "Defining the AgentState and the Prompts",
          "Implementing the Agents and the Nodes",
          "Defining the Conditional Edge",
          "Defining the Graph",
          "Running the Agentic App",
          "Tracing the App with LangSmith",
          "Project Source Code"
        ],
        "Master Project: Build a Research Agent with LangGraph, GPT-4o, RAG,ArXiv,SerpAPI": [
          "Quick Note",
          "Providing an Overview of the Application",
          "Extracting Data from ArXiv into a Pandas DataFrame and Saving it as JSON",
          "Downloading the Research Papers (PDFs)",
          "Loading and Splitting PDF Files into Chunks, Expanding the DataFrame",
          "Building a Knowledge Base for the RAG System Using Embeddings",
          "Creating a Pinecone Index",
          "Populating the Knowledge Base and Uploading it to Pinecone",
          "Developing Custom Tools",
          "Implementing the ArXiv Fetch Tool",
          "Integrating Google SerpAPI for Web Search",
          "Implementing Web Search Tools with Google SerpAPI",
          "Creating RAG Tools for Retrieval-Augmented Generation",
          "Implementing the Final Answer Generation Tool",
          "Initializing the \"Oracle\" LLM",
          "Testing the Oracle and the Tools",
          "Building a Decision-Making Pipeline",
          "Defining the Agent State",
          "Defining the Graph for Decision-Making",
          "Generating Reports",
          "Building a Final Research Report",
          "Concluding the Project",
          "Project Source Code"
        ],
        "[Appendix]: Object Oriented Programming in Python": [
          "README",
          "Intro to Object Oriented Programming (OOP)",
          "OOP Demonstration: The Turtle",
          "Defining Classes and Objects",
          "The __init__ Method",
          "The __del__ Method",
          "Instance Attributes and Class Attributes",
          "Magic Methods",
          "TypedDict: Type Hints for Dictionaries with a Fixed Set of Keys - Part 1",
          "TypedDict: Type Hints for Dictionaries with a Fixed Set of Keys - Part 2",
          "Python OOP Cheat Sheet"
        ],
        "BONUS SECTION": [
          "Congratulations",
          "BONUS: THANK YOU GIFT!"
        ]
      },
      "requirements": [
        "This course is not for beginners. Good knowledge of Python and LangChain is required.",
        "Proficiency in Python and LangChain, including knowledge of flow control, data structures, functions, type annotations, OOP, environment variable management, OpenAI ChatCompletions API, Prompt Templates, Chains, and Output Parsers."
      ],
      "description": "Welcome to this brand new course on LangGraph, which allows us to build agentic LLM applications. Unleash the Full Potential of AI with LangGraph & LangChain!\n\n\nBy the end of this course, you will be equipped with the skills to seamlessly integrate LLM agents into your applications, opening up new possibilities and horizons.\n\n\nWe are witnessing a rapid ascent in AI capabilities, with groundbreaking advancements occurring annually. This swift progress has the potential to significantly reshape our world in the coming years.\n\n\nThree pivotal advancements are poised to make a profound impact: Infinite Context Windows, Text to Action, and Agents.\n\n\nAgents: The New Frontier in AI\nAgents are autonomous intelligent entities designed to perform tasks, process information, and interact within a language-based framework. These agents are significantly expanding the potential of AI across various domains.\n\n\nAgentic AI is revolutionizing industries, offering enhanced applications in fields such as legal document analysis, medical diagnostics, and software development. Imagine an army of skilled programmers working around the clock to develop software solutions for you.\n\n\nIn this course, we will delve into LangGraph, an extension of LangChain specifically designed for agent and multi-agent workflows. LangGraph enables highly customizable and controllable agent flows, ideal for complex scenarios.\nWe will also explore LangSmith, a platform for tracing and debugging your production-grade LLM applications.\n\n\nWhat You'll Learn:\nMaster LangGraph: Explore nodes, edges, and state management for advanced agent workflows.\nLangChain Integration: Connect LLMs to real-world tools for powerful multi-agent applications.\nDevelop Autonomous Agents: Build agents that can observe, reflect, and improve with memory and tool observation.\nRAG & Embeddings: Implement Retrieval-Augmented Generation (RAG) with Pinecone for enhanced search capabilities.\nDebug & Scale: Use LangSmith to debug and trace production-grade AI applications.\n\n\nWhy Enroll in This Course?\nCutting-Edge Skills: You'll master LangGraph and LangChain, tools at the forefront of AI development.\nPractical Applications: Build real-world AI solutions that can be integrated into businesses, research, and more.\nStep-by-Step Guidance: Whether you're experienced in AI or just getting started, our comprehensive tutorials will guide you through each project.\nJoin the AI Revolution: The demand for AI professionals is skyrocketing—position yourself at the forefront by mastering these critical technologies.\n\n\nHands-On Projects:\nReAct Agent from Scratch: Build a fully functional agent with LangGraph.\nCustom Chatbot: Develop an intelligent chatbot powered by LangChain.\nContent Generation Tools: Create AI tools that generate essays, tweets, and more using LangGraph’s reflection pattern.\nMaster Project: Build a robust research agent integrating GPT-4, Pinecone, ArXiv, and Google SerpAPI.\nReady to build AI agents that can transform industries? Enroll now and take your AI development skills to the next level with LangGraph!\nLooking forward to seeing you in the course!",
      "target_audience": [
        "Software Developers aiming to build Generative AI applications using LangChain and LangGraph.",
        "Enthusiasts who want to explore the new frontier of LLM agents."
      ]
    },
    {
      "title": "LookML A-Z: Google Looker for Developers",
      "url": "https://www.udemy.com/course/lookml-google-looker-for-developers/",
      "bio": "Learn LookML, Google Looker's modeling language, to get complete control of the visualization process | LookML mastery",
      "objectives": [
        "Learn LookML - the language that powers Looker",
        "Dimensions in Looker and managing them using LookML",
        "Measures in Looker and managing them using LookML",
        "Types of joins and syntax in LookML",
        "Version control using Git"
      ],
      "course_content": {
        "Introduction": [
          "Why to use LookML"
        ],
        "LookML": [
          "Advantages of LookML",
          "Course resources",
          "This is a Milestone!",
          "LookML important terms",
          "Interface of LookML",
          "How to create Views in LookML",
          "SQL runner in Looker",
          "Quiz"
        ],
        "Dimensions in Looker": [
          "Dimensions - Syntax ed",
          "Dimensions - Number",
          "Dimensions - String",
          "Dimensions - YesNo",
          "Dimensions - Tier",
          "Dimensions - Location - Tier",
          "Dimensions - Date Time and Others"
        ],
        "Creating Dimensions in Looker": [
          "Dimensions in looker - Data sample and import",
          "Dimensions in looker - For Airport view",
          "Dimensions in looker - Creating single view explore",
          "Dimensions in looker - Creating Airport dashboard",
          "Dimensions in looker - Explore and look for Flight view",
          "Quiz"
        ],
        "Measures": [
          "Measures - Syntax",
          "Measures - Average",
          "Measures - Average Distinct",
          "Measures - Count and Count Distinct",
          "Measures - Other common measures",
          "Measures - Running total",
          "Measures - Percent of previous",
          "Measures - Percent of total",
          "Measures - List",
          "Measures - YesNo",
          "Quiz"
        ],
        "Creating Measures in Looker": [
          "Measures in Looker - Data Sample and Measures calculation",
          "Measures in Looker - Creating Measures",
          "Measures in Looker - Measures in a look"
        ],
        "Substitution operator": [
          "Substitution operator",
          "Quiz"
        ],
        "Joins Prerequisites": [
          "Types of joins - Introduction and Left Join",
          "Types of joins - Full Outer join",
          "Types of joins - Inner Join",
          "Types of joins - Cross Join",
          "Relationships for joins - Introduction",
          "Relationships for joins - Why should we use relationships for joins",
          "Primary Keys",
          "Quiz"
        ],
        "Creating Joins in Looker": [
          "Joins in Looker - Syntax",
          "Joins in Looker - Syntax Example",
          "Joins in Looker - Creating joins",
          "Joins in Looker - Exploring joins in a look"
        ],
        "Customization in Looker": [
          "Customizing explore menu - Concepts and Syntax",
          "Customizing explore menu - Application in looker",
          "Customizing Field Picker - Concepts and Syntax",
          "Quiz"
        ]
      },
      "requirements": [
        "You just need a PC with good internet connection"
      ],
      "description": "If you are searching for a course to learn LookML, the language that powers Google Looker, then this is the training for you.\nIn this course, we will start from the very basic level and cover all the important aspects of LookML\nThis is a concise, only four hour course and can be easily completed in just one weekend.\nBelow are some frequently asked questions about LookML and Looker:\nWhat is LookML used for?\nLookML is a language for describing dimensions, aggregates, calculations, and data relationships in a SQL database. Looker uses a model written in LookML to construct SQL queries against a particular database.\nIs LookML easy to learn?\nLooker ML is a very simple language that anyone can learn, once they have mastered the fundamentals. In this course, we will go step-by-step to learn this from beginner level to advanced level.\nIs LookML similar to SQL?\nIn short, LookML is SQL evolved. It leverages SQL's power in a way that's familiar to analysts, while abstracting away the low-level concerns that analysts usually have to manage. It's a powerful language with a huge community of developers who support each other.\n\n\nA Verifiable Certificate of Completion is presented to all students who undertake this LookML course.\nWhy should you choose this course?\nThis is a complete and concise tutorial on LookML which can be completed within 4-5 hours. We know that your time is important and hence we have created this fast paced course without wasting time on irrelevant operations.\nWhat makes us qualified to teach you?\nThe course is taught by Abhishek and Pukhraj. Instructors of the course have been teaching Data Science and Machine Learning for over a decade. We have in-depth understanding on and practical exposure to Google Looker and Data Visualization.\nWe are also the creators of some of the most popular online courses - with over 1,000,000 enrollments and thousands of 5-star reviews like these ones:\nI had an awesome moment taking this course. It broaden my knowledge more on the power use of Excel as an analytical tools. Kudos to the instructor! - Sikiru\nVery insightful, learning very nifty tricks and enough detail to make it stick in your mind. - Armand\nOur Promise\nTeaching our students is our job and we are committed to it. If you have any questions about the course content, Google Looker, LookML or anything related to any topic, you can always post a question in the course or send us a direct message.\nAnd so much more!\nBy the end of this course, your confidence in using LookML will soar. You'll have a thorough understanding of how to use LookML for creating insightful dashboards and beautiful reports.\nGo ahead and click the enroll button, and I'll see you in lesson 1 of this Google Data Studio course!\nCheers\nStart-Tech Academy",
      "target_audience": [
        "This course is for Looker developers or business users who wish to understand & learn LookML"
      ]
    },
    {
      "title": "Machine Learning with Remote Sensing in Google Earth Engine",
      "url": "https://www.udemy.com/course/machine-learning-and-earth-observation-big-data/",
      "bio": "Learn to apply machine learning, remote sensing, big spatial data using the Google Earth Engine cloud computing",
      "objectives": [
        "Learn to learn applying machine learning algorithms using satellite data",
        "Learn processing analyzing large volume of remotely sensed satellite data with the Earth Engine API",
        "Learn to collect reference training data for image classification",
        "Learn to remove clouds from Landsat imageries",
        "Learn to calculate multi-spectral indices with satellite bands",
        "Learn to assess the accuracy of classification"
      ],
      "course_content": {
        "Get Started with Earth Engine API": [
          "Welcome",
          "Introduction to Earth Engine",
          "Explore Earth Engine",
          "Sign Up"
        ],
        "Code Editor": [
          "Code Editor",
          "JavaScript Syntax"
        ],
        "Linear Regression": [
          "Linear Regression",
          "Assignment: Linear Regression"
        ],
        "Clustering": [
          "Clustering"
        ],
        "Training Data": [
          "Training Data"
        ],
        "CART": [
          "CART"
        ],
        "Random Forests": [
          "Random Forests"
        ],
        "Final Project": [
          "Final Project"
        ],
        "Bonus Lectures": [
          "Bonus"
        ]
      },
      "requirements": [
        "This course has no requirements."
      ],
      "description": "Do you want to learn how to access, process, and analyze remote sensing data using open-source cloud-based platforms?\nDo you want to master machine learning algorithms to predict Earth Observation big data?\nDo you want to start a spatial data scientist career in the geospatial industry?\nEnroll in my new course to master Machine Learning with Remote Sensing in Google Earth Engine.\nI will provide you with hands-on training with example data, sample scripts, and real-world applications.\nBy taking this course, you will take your geospatial data science skills to the next level by gaining proficiency in applying machine learning algorithms to predict satellite data using an open-source big data analytics tool, Earth Engine API, a cloud-based Earth observation data visualization analysis by powered by Google.\n\n\nIn this Machine Learning with Earth Engine API course, I will help you get up and running on the Google Earth Engine cloud platform. Then you will apply various machine learning algorithms including linear regression, clustering, CART, and random forests. We will use Landsat satellite data to predict land use land cover classification. All sample data and scripts will be provided to you as an added bonus throughout the course.\nJump in right now to enroll. To get started click the enroll button.",
      "target_audience": [
        "Anyone who want to understand the application of various machine learning techniques using satellite data.",
        "Anyone who wants to learn big Earth observation data analysis on the cloud.",
        "Anyone who wants to start a career in spatial data science."
      ]
    },
    {
      "title": "Advanced Reinforcement Learning: policy gradient methods",
      "url": "https://www.udemy.com/course/advanced-rl-pg/",
      "bio": "Build Artificial Intelligence (AI) agents using Deep Reinforcement Learning and PyTorch: (REINFORCE, A2C, PPO, etc)",
      "objectives": [
        "Master some of the most advanced Reinforcement Learning algorithms.",
        "Learn how to create AIs that can act in a complex environment to achieve their goals.",
        "Create from scratch advanced Reinforcement Learning agents using Python's most popular tools (PyTorch Lightning, OpenAI gym, Optuna)",
        "Learn how to perform hyperparameter tuning (Choosing the best experimental conditions for our AI to learn)",
        "Fundamentally understand the learning process for each algorithm.",
        "Debug and extend the algorithms presented.",
        "Understand and implement new algorithms from research papers."
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Reinforcement Learning series",
          "Google Colab",
          "Where to begin",
          "Complete code",
          "Connect with me on social media"
        ],
        "Refresher: The Markov Decision Process (MDP)": [
          "Elements common to all control tasks",
          "The Markov decision process (MDP)",
          "Types of Markov decision process",
          "Trajectory vs episode",
          "Reward vs Return",
          "Discount factor",
          "Policy",
          "State values v(s) and action values q(s,a)",
          "Bellman equations",
          "Solving a Markov decision process"
        ],
        "Refresher: Monte Carlo methods": [
          "Monte Carlo methods",
          "Solving control tasks with Monte Carlo methods",
          "On-policy Monte Carlo control"
        ],
        "Refresher: Temporal difference methods": [
          "Temporal difference methods",
          "Solving control tasks with temporal difference methods",
          "Monte Carlo vs temporal difference methods",
          "SARSA",
          "Q-Learning",
          "Advantages of temporal difference methods"
        ],
        "Refresher: N-step bootstrapping": [
          "N-step temporal difference methods",
          "Where do n-step methods fit?",
          "Effect of changing n"
        ],
        "Refresher: Brief introduction to Neural Networks": [
          "Function approximators",
          "Artificial Neural Networks",
          "Artificial Neurons",
          "How to represent a Neural Network",
          "Stochastic Gradient Descent",
          "Neural Network optimization"
        ],
        "Refresher: REINFORCE": [
          "Policy gradient methods",
          "Representing policies using neural networks",
          "Policy performance",
          "The policy gradient theorem",
          "REINFORCE",
          "Parallel learning",
          "Entropy regularization",
          "REINFORCE 2"
        ],
        "PyTorch Lightning": [
          "PyTorch Lightning",
          "Link to the code notebook",
          "Create the policy",
          "Create the environment",
          "Create the dataset",
          "Create the REINFORCE algorithm - Part 1",
          "Create the REINFORCE algorithm - Part 2",
          "Check the resulting agent"
        ],
        "REINFORCE for continuous control tasks": [
          "REINFORCE for continuous action spaces",
          "Link to the code notebook",
          "Create the policy",
          "Create the inverted pendulum environment",
          "Create the dataset",
          "Creating the algorithm - Part 1",
          "Creating the algorithm - Part 2",
          "Check the resulting agent"
        ],
        "Advantage Actor Critic (A2C)": [
          "A2C",
          "Link to the code notebook",
          "Create the policy and value network",
          "Create the environment",
          "Create the dataset",
          "Implement A2C - Part 1",
          "Implement A2C - Part 2",
          "Check the resulting agent"
        ]
      },
      "requirements": [
        "Be comfortable programming in Python",
        "Completing our course \"Reinforcement Learning beginner to master\" or being familiar with the basics of Reinforcement Learning (or watching the leveling sections included in this course).",
        "Know basic statistics (mean, variance, normal distribution)"
      ],
      "description": "This is the most complete Reinforcement Learning course series on Udemy. In it, you will learn to implement some of the most powerful Deep Reinforcement Learning algorithms in Python using PyTorch and PyTorch lightning. You will implement from scratch adaptive algorithms that solve control tasks based on experience. You will learn to combine these techniques with Neural Networks and Deep Learning methods to create adaptive Artificial Intelligence agents capable of solving decision-making tasks.\nThis course will introduce you to the state of the art in Reinforcement Learning techniques. It will also prepare you for the next courses in this series, where we will explore other advanced methods that excel in other types of task.\nThe course is focused on developing practical skills. Therefore, after learning the most important concepts of each family of methods, we will implement one or more of their algorithms in jupyter notebooks, from scratch.\n\n\nLeveling modules:\n\n\n- Refresher: The Markov decision process (MDP).\n- Refresher: Monte Carlo methods.\n- Refresher: Temporal difference methods.\n- Refresher: N-step bootstrapping.\n- Refresher: Brief introduction to Neural Networks.\n- Refresher: Policy gradient methods.\n\n\n\n\nAdvanced Reinforcement Learning:\n\n\n- REINFORCE\n- REINFORCE for continuous action spaces\n- Advantage actor-critic (A2C)\n- Trust region methods\n- Proximal policy optimization (PPO)\n- Generalized advantage estimation (GAE)\n- Trust region policy optimization (TRPO)",
      "target_audience": [
        "Developers who want to get a job in Machine Learning.",
        "Data scientists/analysts and ML practitioners seeking to expand their breadth of knowledge.",
        "Robotics students and researchers.",
        "Engineering students and researchers."
      ]
    },
    {
      "title": "Panel and hvPlot: A high-level Data Visualization for Python",
      "url": "https://www.udemy.com/course/panel-and-hvplot-a-high-level-data-visualization-for-python/",
      "bio": "Simplify Visualization and Interactive Dashboards with Super Easy and Flexible Holoviz tools including Panel and hvPlot",
      "objectives": [
        "Understand the key concepts of data visualization and its significance in analyzing and communicating data effectively.",
        "Develop proficiency in using Panel and hvPlot libraries to create interactive and visually appealing data visualizations.",
        "Explore the advanced features and customization options of Panel for building interactive dashboards.",
        "Apply data visualization techniques to real-world datasets and gain insights from data.",
        "Learn best practices for designing visually appealing and impactful data visualizations.",
        "Gain practical experience in creating end-to-end data visualization projects using Panel and hvPlot."
      ],
      "course_content": {
        "Introduction to the Course": [
          "Money-off on my Udemy courses",
          "Anaconda Installation",
          "What are Panel and hvPlot in Holoviz?",
          "Installation and Setting up"
        ],
        "hvPlot Gallery": [
          "hvPlot (Part1)",
          "hvPlot (Part2)"
        ],
        "Customization": [
          "Plot Customization (Part1)",
          "Plot Customization (Part2)"
        ],
        "Indicators": [
          "Indicators (Part1)",
          "Indicators (Part2)"
        ],
        "Widgets": [
          "Widgets (Part1)",
          "Widgets (Part2)"
        ],
        "Controlling Style using CSS": [
          "Controlling Style & Layout Design"
        ],
        "Layout Design": [
          "Layout 1 (Row, Columns, Divider, and Spacer)",
          "Layout 2 (Grid Box, Widget Box, and GridSpec)",
          "Layout 3 (Tabs, Card, FloatPanel, Templates)",
          "Layout 4 (Arrange Components)",
          "Layout 5 (Applying a Design)",
          "Take-home assignment: Working with HTML and CSS"
        ],
        "Interaction with Widgets": [
          "Interaction (Part1)",
          "Interaction (Part2)",
          "Interaction (Part3)",
          "Interaction (Part4)",
          "Interaction (Part5)",
          "Interaction (Part6)",
          "Interaction (Part7)"
        ],
        "Interaction with DataFrame": [
          "Interaction with DF (Part1)",
          "Interaction with DF (Part2)",
          "Interaction with DF (Part3)",
          "Interaction with DF (Part4)",
          "Interaction with DF (Part5)"
        ],
        "Dashboard Design": [
          "Case Study 1 (BASIC - tricks and customizations)",
          "Case Study 2 (INTERMEDIATE - tricks and customizations)",
          "Case Study 3 (ADVANCED - tricks and customizations)",
          "Take-home assignment: Interactive Clustering Dashboard Design using Panel"
        ]
      },
      "requirements": [
        "Basic Python Knowledge: A fundamental understanding of Python programming is necessary to follow along with the course materials. Familiarity with Python syntax, data types, variables, and functions will help you grasp the concepts more effectively.",
        "Data Analysis and Visualization Basics: Having a basic understanding of data analysis and visualization principles will be helpful. This includes concepts like data manipulation, data structures, and basic plotting techniques (e.g., Matplotlib).",
        "Jupyter Notebooks: A basic understanding of Jupyter notebooks will be beneficial as the course may involve working with Jupyter notebooks for code demonstrations and exercises. Knowing how to execute code cells and navigate through a notebook will enhance your learning experience."
      ],
      "description": "Unlock the power of data visualization in Python with Panel and hvPlot! In this comprehensive Udemy course, you will dive into the world of high-level data visualization techniques using two powerful libraries: Panel and hvPlot. Whether you're a data scientist, analyst, or developer, this course will equip you with the skills and knowledge to create stunning visualizations and interactive dashboards with ease. Join now and take your data visualization skills to new heights!\n\n\nBy the end of this course, learners will be able to:\n\n\nMaster the fundamentals of Panel and hvPlot: Gain a comprehensive understanding of Panel and hvPlot libraries, their key concepts, and how they fit into the Python data visualization ecosystem.\nCreate interactive dashboards: Learn how to design and build interactive data dashboards using Panel, enabling users to explore and analyze data with ease.\nEnhance visualizations with hvPlot: Explore the powerful capabilities of hvPlot to create stunning and dynamic visualizations, incorporating a wide range of chart types, customizations, and interactivity.\nIntegrate Panel and hvPlot with existing workflows: Discover how to seamlessly integrate Panel and hvPlot into your existing Python data analysis workflows, leveraging their compatibility with popular data manipulation and analysis libraries.\nCustomize and style your visualizations: Unlock the ability to customize and style your visualizations in Panel and hvPlot, allowing you to create visually appealing and professional-looking dashboards tailored to your specific needs.\nDeploy and share your dashboards: Learn how to deploy and share your interactive dashboards created with Panel and hvPlot, enabling you to collaborate with others, present insights, and showcase your work effectively.\nManage data visualization challenges in your real-world projects and applications: Apply your newly acquired knowledge to real-world projects and explore practical use cases across various domains, ensuring you are well-prepared to tackle data visualization challenges in your professional career.\nBy the end of this course, you will have the skills and confidence to leverage Panel and hvPlot to create powerful, interactive, and visually compelling data visualizations and dashboards in Python.\n\n\nEnroll now and unlock the potential of these high-level tools for your data visualization projects.",
      "target_audience": [
        "This course is designed for Python developers, data analysts, data scientists, and anyone interested in harnessing the power of Panel and hvPlot libraries for high-level data visualization in Python. Whether you are a beginner looking to expand your data visualization skills or an experienced practitioner seeking to enhance your toolkit, this course provides a comprehensive introduction and in-depth exploration of Panel and hvPlot."
      ]
    },
    {
      "title": "ChatGPT Mastery : The Ultimate Guide to Prompt Engineering",
      "url": "https://www.udemy.com/course/chatgpt-mastery-command-prompt-engineering/",
      "bio": "Master ChatGPT Interactions, One ChatGPT prompt at a Time!",
      "objectives": [
        "Understanding the Fundamentals of ChatGPT: Grasp the basic principles and mechanics of how ChatGPT processes and responds to prompts.",
        "Crafting Effective Prompts: Learn techniques to formulate clear, concise, and targeted prompts that guide ChatGPT towards desired responses.",
        "Context Management: Master skills to manage and maintain context within a conversation with ChatGPT, ensuring coherent and relevant responses.",
        "Navigating AI Limitations: Gain insights into the limitations of ChatGPT and strategies to work around these constraints effectively.",
        "Application in Various Domains: Understand how to apply prompt engineering in diverse fields such as marketing, creative writing, tech, and customer service.",
        "Prompt Refinement Techniques: Learn how to iteratively refine prompts based on the AI's responses to achieve more accurate and useful outcomes.",
        "Real-World Scenarios and Case Studies: Analyze real-world examples and case studies to understand the practical applications of prompt engineering.",
        "Advanced Prompt Techniques: Delve into more sophisticated prompt crafting techniques, including conditional, iterative, and role-play prompts.",
        "Error Detection and Correction: Acquire skills to identify and correct errors in ChatGPT's responses, enhancing accuracy and reliability.",
        "Promoting Critical Thinking with Prompts: Explore how to construct prompts that encourage ChatGPT to demonstrate critical thinking and complex problem-solving.",
        "Customizing Responses for Specific Audiences: Gain the ability to tailor ChatGPT's responses to suit different target audiences, enhancing engagement."
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Free vs Paid",
          "Limitations of ChatGPT"
        ],
        "Prompt Foundations": [
          "Basic Prompting Techniques",
          "Structure & Sequential Prompting",
          "Context Specific Prompting"
        ],
        "Language & Communication Techniques": [
          "Creativity & Conceptual Techniques",
          "Language Translation & Transformation Techniques",
          "Audience & Evaluation Techniques"
        ],
        "Role Based & Instruction Techniques": [
          "Perspective & Positioning Prompts",
          "Exploration & Critical Thinking Prompts",
          "Structure & Progression Prompts"
        ],
        "Memory & Perspective Techniques": [
          "Cognitive & Memory Techniques",
          "Analysis & Prolem Solving Techniques",
          "Verification Techniques"
        ],
        "Style & Genre Techniques": [
          "Style & Format Techniques"
        ],
        "BONUS - Create Powerpoints Using ChatGPT": [
          "PowerPoint Using ChatGPT."
        ],
        "Conclusion - Thank You!": [
          "Conclusion - Thank you!"
        ]
      },
      "requirements": [
        "No Prerequisite Required"
      ],
      "description": "Imagine having the power to talk to AI and get exactly what you need—whether it’s solving problems, brainstorming ideas, or writing something amazing. That’s what \"ChatGPT Mastery : The Ultimate Guide to Prompt Engineering\" is all about. This course is your ticket to understanding how to work with ChatGPT, OpenAI’s powerful AI model, and making it do exactly what you want.\nThink of it as learning the language of AI. The course takes you step-by-step through the art of crafting prompts, essentially, figuring out how to ask ChatGPT questions in a way that gets you clear, helpful, and meaningful answers. It’s not just about knowing what to type; it’s about knowing how to think when you interact with AI.\nYou’ll learn all about what ChatGPT can do, where it shines, and even where it might need a little nudge. Whether you’re in a professional field or just love tech, this course shows you how to use AI tools like ChatGPT for everything from solving tough problems to creating incredible stories and content.\nIt’s a hands-on journey into the world of AI, touching on important topics like how AI works, how it generates responses, and even the ethics of using it responsibly. By the end of it, you’ll not only be confident in working with ChatGPT but also have a solid understanding of how AI is shaping the world around us.\nWhether you’re an AI newbie or a tech-savvy pro, this course is designed to help you unlock the full potential of ChatGPT, turning it into your go-to tool for innovation and creativity.\n\n\nSo, what are you waiting for? Join me in this exciting journey to master ChatGPT and unlock the endless possibilities of AI. Let’s get started, I'll see you in the course!",
      "target_audience": [
        "ideal for AI enthusiasts, content creators, developers, business professionals, educators, and students seeking to enhance their AI interaction skills for varied applications."
      ]
    },
    {
      "title": "Data Science for Sports - Sports Analytics and Visualization",
      "url": "https://www.udemy.com/course/data-science-for-sports/",
      "bio": "Learn how to perform sports analytics and visualization using Python.",
      "objectives": [
        "Learn how to perform analysis of different kinds of sports data using the 2018 NFL season data.",
        "Learn how to visualize sports statistics.",
        "Learn how to create a sports field and visualize players on top of it.",
        "Learn how to standardize sports data."
      ],
      "course_content": {
        "Introduction": [
          "Welcome to the course!",
          "About the datasets"
        ],
        "Working on the datasets": [
          "Analyzing the NFL games",
          "Knowing the NFL players",
          "Understanding the NFL plays"
        ],
        "Visualizing the sports field": [
          "Visualizing the American Football Field",
          "Adding Players onto the Field"
        ],
        "End of Course": [
          "End of Course",
          "Bonus Lecture"
        ]
      },
      "requirements": [
        "Basic understanding of Python, Pandas and Matplotlib."
      ],
      "description": "Are you a fan of sport but also interested in the numbers? Deep dive into the world of sports analytics with this course on 'Data Science for Sports - Sports Analytics and Visualization', created by The Click Reader.\nThis course provides insights and knowledge into how you can perform analysis on sports data and then, visualize it using Python. We will start the course by looking at the games in the 2018 NFL season. Then, we will move on to look at the player statistics in order to understand the players in the season. We will also look at the plays of the NFL season and finally, end the course by building a data visualization project where we will be visualizing the American Football Field and players on top of it.\nAfter completing this course, you will be able to play around with the various available datasets and visualize them in different ways. This course contains hands-on exercises at the end of each lecture and the knowledge you gain through this course can be extended to any other domain of sports.\nWhy you should take this course?\nUpdated 2022 course content: All our course content is updated as per the latest technologies and tools available in the market\nPractical hands-on knowledge: This course is oriented to providing a step-by-step implementation guide rather than just sticking to the theory.\nGuided support: We are always there to guide you through the Q/As so feel free to ask us your queries.",
      "target_audience": [
        "Any developer looking to learn how to analyze and visualize sports data using Python."
      ]
    },
    {
      "title": "Data Mining with Rattle",
      "url": "https://www.udemy.com/course/data-mining-with-rattle/",
      "bio": "Learn to use the GUI-based comprehensive Data Miner data mining software suite implemented as the rattle package in R",
      "objectives": [
        "Perform and support life-cycle data mining tasks and activities using the popular Data Miner (\"Rattle\") software suite.",
        "Understand the functionalities implicit in the data, explore, test, transform, cluster, associate, model, evaluate, and log tabs in the Data Miner (\"Rattle\") GUI software platform.",
        "Know how to explore, visualize, transform, and summarize data sets in Rattle.",
        "Know how to create advanced, interactive Ggobi visualizations of data.",
        "Know how to use, estimate and interpret: cluster analyses; association analyses mining rules; decision trees; random forests; boosting; and support vector machines using Rattle."
      ],
      "course_content": {
        "Introduction, Orientation, and Demos": [
          "Course Overview",
          "Class Agenda and Introduction to Data Mining",
          "Explanation of Class Materials",
          "Demonstrations of Rattle",
          "More Rattle Demonstrations",
          "Exercise for Introduction Section"
        ],
        "Rattle Interface Tabs and Introductory Script Demonstrations": [
          "Session Agenda",
          "Rattle Interface and Tabs (part 1)",
          "Rattle Interface and Tabs (part 2)",
          "Rattle Interface and Tabs (part 3)",
          "Script Demonstrations (part 1)",
          "Script Demonstrations (part 2)",
          "Script Demonstrations (part 3)"
        ],
        "Loading and Exploring Data": [
          "Loading and Describing Data in Rattle",
          "Describing and Exploring Data in Rattle",
          "Exploring the Data in Rattle",
          "Exploring Data with Plots in Rattle",
          "Script to Load Data and Read Files",
          "More Data Visualization with Scripts",
          "Continue Plotting with Scripts"
        ],
        "Data Visualizations with Ggobi and Data Transformation in Rattle": [
          "Interactive Data Exploration",
          "Ggobi Demonstrations",
          "Data Transformation in Rattle (part 1)",
          "Data Transformation in Rattle (part 2)",
          "Reshaping Data"
        ],
        "Cluster Analysis": [
          "Introduction to Cluster Analysis using Rattle",
          "Similarity-based Cluster Analysis Demos using Scripts (part 1)",
          "Distance-based Cluster Analysis Demos using Scripts (part 2)",
          "Data Exploration Options (part 1)",
          "Data Exploration Options (part 2)",
          "Cluster Analysis Example: Ancient Pottery Shards",
          "Cluster Analysis Example: Classifying Exoplanets (part 1)",
          "Cluster Analysis Example: Classifying Exoplanets (part 2)"
        ],
        "Association Analysis": [
          "Cluster Analysis Exercise Solution",
          "Introduction to Association Analysis",
          "Introduction to Association Analysis using R Script",
          "Introduction to Association Analysis using Rattle",
          "Working with Rules",
          "Visualizing Association Rules (part 1)",
          "Visualizing Association Rules (part 2)",
          "Visualizing Association Rules (part 3)",
          "Association Analysis Exercise"
        ],
        "Decision Trees and Recursive Partitioning": [
          "Association Analysis Exercise Solution",
          "What are Decision Trees ?",
          "Introduction to Decision Trees and Rattle Demo (part 1)",
          "Introduction to Decision Trees and Rattle Demo (part 2)",
          "Introduction to Decision Trees and Rattle Demo (part 3)",
          "Introduction to Decision Trees and Rattle Demo (part 4)",
          "Recursive Partitioning Demo with Bodyfat Data (part 1)",
          "Recursive Partitioning Demo with Bodyfat Data (part 2)",
          "Recursive Partitioning Demo with Bodyfat Data (part 3)",
          "Recursive Partitioning Demo with Glaucoma Data (part 1)",
          "Recursive Partitioning Demo with Glaucoma Data (part 2)",
          "Recursive Partitioning Demo with Glaucoma Data (part 3)"
        ],
        "Random Forests": [
          "Recursive Partitioning Exercise Solutions",
          "Introduction to Random Forests",
          "Random Forest Rattle Tutorial with Weather Data (part 1)",
          "Random Forest Rattle Tutorial with Weather Data (part 2)",
          "Random Forest Rattle Tutorial with Weather Data (part 3)",
          "Random Forest Modeling with R Weather Data (part 1)",
          "Random Forest Modeling with R Weather Data (part 2)",
          "Random Forest Modeling with R Weather Data (part 3)",
          "Decision Tree Iris Data",
          "Random Forest Iris Data (part 1)",
          "Random Forest Iris Data (part 2)",
          "Random Forest Exercise"
        ],
        "Boosting": [
          "Random Forest Exercise Solution (part 1)",
          "Random Forest Exercise Solution (part 2)",
          "Introduction to Boosting",
          "Boosting Tutorial using Rattle",
          "Basics of Boosting Demo using R",
          "Replicating Adaboost using Rpart (part 1)",
          "Replicating Adaboost using Rpart (part 2)",
          "Boosting Extensions and Variants",
          "Boosting Exercise"
        ],
        "Support Vector Machines": [
          "Introduction to Support Vector Machines (SVMs)",
          "Boosting Exercise Solution",
          "Demonstrate Basis of SVM using R Scripts",
          "SVM Tutorial in Rattle",
          "SVM Model Evaluation (part 1)",
          "SVM Model Evaluation (part2)",
          "SVM Model Evaluation (part 3)"
        ]
      },
      "requirements": [
        "Students will need to install the R console and RStudio software (instructions are provided)."
      ],
      "description": "Data Mining with Rattle is a unique course that instructs with respect to both the concepts of data mining, as well as to the \"hands-on\" use of a popular, contemporary data mining software tool, \"Data Miner,\" also known as the 'Rattle' package in R software. Rattle is a popular GUI-based software tool which 'fits on top of' R software. The course focuses on life-cycle issues, processes, and tasks related to supporting a 'cradle-to-grave' data mining project. These include: data exploration and visualization; testing data for random variable family characteristics and distributional assumptions; transforming data by scale or by data type; performing cluster analyses; creating, analyzing and interpreting association rules; and creating and evaluating predictive models that may utilize: regression; generalized linear modeling (GLMs); decision trees; recursive partitioning; random forests; boosting; and/or support vector machine (SVM) paradigms. It is both a conceptual and a practical course as it teaches and instructs about data mining, and provides ample demonstrations of conducting data mining tasks using the Rattle R package. The course is ideal for undergraduate students seeking to master additional 'in-demand' analytical job skills to offer a prospective employer. The course is also suitable for graduate students seeking to learn a variety of techniques useful to analyze research data. Finally, the course is useful for practicing quantitative analysis professionals who seek to acquire and master a wider set of useful job skills and knowledge. The course topics are scheduled in 10 distinct topics, each of which should be the focus of study for a course participant in a separate week per section topic.",
      "target_audience": [
        "Anyone interested in data mining seeking to master the use of a powerful popular contemporary (and no-cost) Data Mining software suite",
        "Data analytics professionals seeking to augment their data mining skill sets with a popular and useful data mining package.",
        "Undergraduate and graduate students seeking to attain in-demand data mining skills for data analysis/mining tasks to offer to prospective employers."
      ]
    },
    {
      "title": "Mastering Time Series Forecasting with Python",
      "url": "https://www.udemy.com/course/complete-practical-time-series-forecasting-in-python/",
      "bio": "Learn Python, Time Series Model Additive, Multiplicative, AR, Moving Average, Exponential, ARIMA models",
      "objectives": [
        "Python Programing",
        "Basic to Advanced Time Series Methods",
        "Time Series Visualization in Python",
        "Auto Regressive Methods,",
        "Moving Average, Exponential Moving Average",
        "Linear Regression and Evaluation",
        "Additive and Multiplicative Models",
        "ARMA, ARIMA, SARIMA in Python",
        "ACF and PACF",
        "Auto ARIMA in Python",
        "Stationary and Non Stationary",
        "GARCH Models"
      ],
      "course_content": {
        "Introduction": [
          "What is Time Series Data",
          "Time Series Components",
          "Download the Resources",
          "Good Learning Practice"
        ],
        "Setting Google Colab": [
          "Install Google Colab to your mail id",
          "Integrate Google Drive to Colab to Load Data"
        ],
        "Time Series Visualizations": [
          "Download the Resources",
          "Types of Charts for Time Series",
          "Setting up Google Colab",
          "Load the Data",
          "Line Chart",
          "Hue the Line Chart",
          "Area Chart",
          "Bar Plot",
          "Proposition and Stacked Bar, Area Chart",
          "Heatmaps"
        ],
        "Linear Regression Intution": [
          "Download the Resources",
          "Intuition of Linear Regression",
          "Exploratory Data Analysis",
          "EDA - Quantitative Technique",
          "EDA - Graphical Technique",
          "Simple Linear Regression - Python",
          "Simple Linear Regression - Sklearn (Python)",
          "Simple Linear Regression - Statsmodels (Python)",
          "Model Evaluation - R^2, ANOVA",
          "Model Evaluation - Python"
        ],
        "Regression for Time Series Forecasting": [
          "Regression with Time",
          "Download the Resources",
          "Data Preprocessing in Python",
          "Splitting Data into Training and Testing Sets in Python",
          "Train Regression Model with Time in Python",
          "Forecasting with Confidence Interval and Visualizations in Python"
        ],
        "Additive Time Series Model with Statsmodels": [
          "Additive Model",
          "Data Analysis in Python",
          "Creating Seasonal Features",
          "Splitting Data into Training and Testing Sets",
          "Training Additive Model in Statsmodels",
          "Additive Model Forecasting and Visualizations"
        ],
        "Multiplicative Time Series Model": [
          "Multiplicative Model",
          "Step-1: Trend Model",
          "Step-2: Calculate Seasonal Deviation",
          "Step-3: Seasonal Corrector Factor",
          "Fitted values and Forecasting with Multiplicative Model",
          "Margin of Error and Confidence Interval",
          "Visualizing Forecasted Data"
        ],
        "Auto Regressive Methods": [
          "Auto Regressive Methods",
          "Download the Resources",
          "Setting Up for Model Building",
          "Data Preprocessing",
          "ACF & PACF",
          "Making Data Stationary",
          "Training AR Model",
          "Fitted and Forecasting values with AR Model",
          "AR Model Evaluation"
        ],
        "Smoothing Methods (Moving Average)": [
          "Smoothing Techniques",
          "Download the Resources",
          "Naive Forecasting Model",
          "Naive Forecasting Model in Python - part 1",
          "Naive Forecasting Model in Python - part 2",
          "Simple Moving Average",
          "Simple Moving Average in Python",
          "Simple Moving Average order (q) in Python",
          "Weighted Moving Average",
          "Weighted Moving Average in Python",
          "Exponential Moving Average",
          "Exponential Moving Average in Python"
        ],
        "Non Seasonal ARIMA models": [
          "ARMA",
          "Non Seasonal ARIMA",
          "Downloads Data and Notebook",
          "ARMA - Load Data",
          "ARMA - Split the Data into train and test sets",
          "ARMA - Steps to Build the Models",
          "ARMA - Augmented Dickey Fuller test for stationary",
          "ARMA - Converting Data into Stationary",
          "ARMA - ACF & PACF , Train ARMA(p,q)",
          "ARMA - Evaluation",
          "ARMA - Visualizing Prediction Results",
          "ARMA - Convert Stationary to Non - Stationary Data",
          "ARIMA",
          "ARIMA : Visualize the output"
        ]
      },
      "requirements": [
        "Basics knowledge in Statistics",
        "Basic understand on Python",
        "Should have Gmail Account and should able to open Google Drive"
      ],
      "description": "Welcome to Mastering Time Series Forecasting in Python\nTime series analysis and forecasting is one of the areas of Data Science and has a wide variety of applications in the industries in the current world. Many industries looking for a Data Scientist with these skills. This course covers all types of modeling techniques for forecasting and analysis.\nWe start with programming in Python which is the essential skill required and then we will exploring the fundamental time series theory to help you understand the modeling that comes afterward.\nThen throughout the course, we will work with a number of Python libraries, providing you with complete training. We will use the powerful time-series functionality built into pandas, as well as other fundamental libraries such as NumPy, matplotlib, statsmodels, Sklearn, and ARCH.\nWith these tools we will master the most widely used models out there:\nAdditive Model\nMultiplicative Model\nAR (autoregressive model)\nSimple Moving Average\nWeighted Moving Average\nExponential Moving Average\nARMA (autoregressive-moving-average model)\nARIMA (autoregressive integrated moving average model)\nAuto ARIMA\n\n\n\n\nWe know that time series is one of those topics that always leaves some doubts.\nUntil now.\nThis course is exactly what you need to comprehend the time series once and for all. Not only that, but you will also get a ton of additional materials – notebooks files, course notes – everything is included.",
      "target_audience": [
        "Anyone who are interested to do time series analysis and forecasting",
        "Want to do advanced real time forecasting"
      ]
    },
    {
      "title": "Data Science Methods and Techniques [2025]",
      "url": "https://www.udemy.com/course/data-science-methods-and-techniques-2024/",
      "bio": "Learn Data Science Methods and Techniques for Data Analysis and Machine Learning [2025]",
      "objectives": [
        "Knowledge about Data Science methods, techniques, theory, best practices, and tasks",
        "Deep hands-on knowledge of Data Science and know how to handle common Data Science tasks with confidence",
        "Detailed and deep Master knowledge of Regression, Prediction, Classification, Supervised Learning, Cluster Analysis, and Unsupervised Learning",
        "Hands-on knowledge of Scikit-learn, Statsmodels, Matplotlib, Seaborn, and some other Python libraries",
        "Advanced knowledge of A.I. prediction models and automatic model creation",
        "Cloud computing: Use the Anaconda Cloud Notebook (Cloud-based Jupyter Notebook). Learn to use Cloud computing resources"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Setup of the Anaconda Cloud Notebook",
          "Download and installation of the Anaconda Distribution (optional)",
          "The Conda Package Management System (optional)"
        ],
        "Master Regression, Prediction and Supervised Learning": [
          "Regression, Prediction, and Supervised Learning. Section Overview (I)",
          "The Traditional Simple Regression Model (II)",
          "The Traditional Simple Regression Model (III)",
          "Some practical and useful modelling concepts (IV)",
          "Some practical and useful modelling concepts (V)",
          "Linear Multiple Regression model (VI)",
          "Linear Multiple Regression model (VII)",
          "Multivariate Polynomial Multiple Regression models (VIII)",
          "Multivariate Polynomial Multiple Regression models (VIIII)",
          "Regression Regularization, Lasso and Ridge models (X)",
          "Decision Tree Regression models (XI)",
          "Random Forest Regression (XII)",
          "Voting Regression (XIII)"
        ],
        "Master Classification and Supervised Learning": [
          "Classification and Supervised Learning, overview",
          "Logistic Regression Classifier",
          "The Naive Bayes Classifier",
          "K-Nearest Neighbor Classifier (KNN) [Extra Video]",
          "The Decision Tree Classifier",
          "The Random Forest Classifier",
          "Linear Discriminant Analysis (LDA) [Extra Video]",
          "The Voting Classifier"
        ],
        "Master Cluster Analysis and Unsupervised Learning": [
          "Overview",
          "K-Means Cluster Analysis",
          "Auto-updated K-Means Cluster Analysis, introduction and simulation",
          "Density-Based Spatial Clustering of Applications with Noise (DBSCAN)",
          "Four Hierarchical Clustering algorithms",
          "Principal Component Analysis (PCA)"
        ]
      },
      "requirements": [
        "Basic knowledge of the Python programming language and preferably the Pandas library",
        "The four ways of counting (+-*/)",
        "Everyday experience using a computer with either Windows, MacOS, iOS, Android, ChromeOS, or Linux is recommended",
        "Access to a computer with an internet connection"
      ],
      "description": "Welcome to the course Data Science Methods and Techniques for Data Analysis and Machine Learning!\nData Science is expanding and developing on a massive and global scale. Everywhere in society, there is a movement to implement and use Data Science Methods and Techniques to develop and optimize all aspects of our lives, businesses, societies, governments, and states.\nThis course will teach you a large selection of Data Science methods and techniques, which will give you an excellent foundation for Data Science jobs and studies. This course has exclusive content that will teach you many new things regardless of if you are a beginner or an experienced Data Scientist, Data Analyst, or Machine Learning Engineer.\n\n\nThis is a three-in-one master class video course which will teach you to master Regression, Prediction, Classification, Supervised Learning, Cluster analysis, and Unsupervised Learning.\nYou will learn to master Regression, Regression analysis, Prediction and supervised learning. This course has the most complete and fundamental master-level regression content packages on Udemy, with hands-on, useful practical theory, and also automatic Machine Learning algorithms for model building, feature selection, and artificial intelligence. You will learn about models ranging from linear regression models to advanced multivariate polynomial regression models.\nYou will learn to master Classification and supervised learning. You will learn about the classification process, classification theory, and visualizations as well as some useful classifier models, including the very powerful Random Forest Classifiers Ensembles and Voting Classifier Ensembles.\nYou will learn to master Cluster Analysis and unsupervised learning. This part of the course is about unsupervised learning, cluster theory, artificial intelligence, explorative data analysis, and some useful Machine Learning clustering algorithms ranging from hierarchical cluster models to density-based cluster models.\n\n\nYou will learn\nKnowledge about Data Science methods, techniques, theory, best practices, and tasks\nDeep hands-on knowledge of Data Science and know how to handle common Data Science tasks with confidence\nDetailed and deep Master knowledge of Regression, Regression analysis, Prediction, Classification, Supervised Learning, Cluster Analysis, and Unsupervised Learning\nHands-on knowledge of Scikit-learn, Statsmodels, Matplotlib, Seaborn, and some other Python libraries\nAdvanced knowledge of A.I. prediction models and automatic model creation\nCloud computing: Use the Anaconda Cloud Notebook (Cloud-based Jupyter Notebook). Learn to use Cloud computing resources\nOption: To use the Anaconda Distribution (for Windows, Mac, Linux)\nOption: Use Python environment fundamentals with the Conda package management system and command line installing/updating of libraries and packages – golden nuggets to improve your quality of work life\nAnd much more…\n\n\nThis course includes\nan easy-to-follow guide for using the Anaconda Cloud Notebook (Cloud-based Jupyter Notebook). You may learn to use Cloud Computing resources in this course\nan easy-to-follow optional guide for downloading, installing, and setting up the Anaconda Distribution, which makes anyone able to install a Python Data Science environment useful for this course or for any Data Science or coding task\ncontent that will teach you many new things, regardless of if you are a beginner or an experienced Data Scientist, Data Analyst, or Machine Learning Engineer\na large collection of unique content, and this course will teach you many new things that only can be learned from this course on Udemy\na course structure built on a proven and professional framework for learning.\na compact course structure and no killing time\n\n\nThis course is an excellent way to learn to master Regression, Prediction, Classification, and Cluster analysis!\nThese are the most important and useful tools for modeling, AI, and forecasting.\n\n\nIs this course for you?\nThis course is for you, regardless if you are a beginner or an experienced Data Scientist\nThis course is for you, regardless if you have a Ph.D. or no education or experience at all\n\n\nThis course is the course we ourselves would want to be able to enroll in if we could time-travel and become new students. In our opinion, this course is the best course to learn to Master Regression, Prediction, Classification, Supervised Learning, Cluster analysis, and unsupervised learning.\n\n\nCourse requirements\nBasic knowledge of the Python programming language and preferably the Pandas library\nThe four ways of counting (+-*/)\nEveryday experience using a computer with either Windows, MacOS, iOS, Android, ChromeOS, or Linux is recommended\nAccess to a computer with an internet connection\nThe course only uses costless software\nWalk-you-through installation and setup videos for Cloud computing and Windows 10/11 is included\n\n\nEnroll now to receive 15+ hours of video tutorials with manually edited English captions, and a certificate of completion after completing the course!",
      "target_audience": [
        "This course is for you, regardless if you are a beginner or an experienced Data Scientist",
        "This course is for you, regardless if you have a Ph.D. or no education or experience at all"
      ]
    },
    {
      "title": "Python Data Science Fundamentals: Getting Started",
      "url": "https://www.udemy.com/course/python-data-science-fundamentals-getting-started/",
      "bio": "Python Data Science Fundamentals: Dive into NumPy, Pandas, Matplotlib, and Scikit-learn for Powerful Data Insights",
      "objectives": [
        "Master data analysis using NumPy & Pandas for efficient manipulation",
        "Create impactful data visualizations with Matplotlib, conveying insights effectively",
        "Gain an introduction to Scikit-learn, building and evaluating predictive models",
        "Enhancing practical skills in data analysis, visualization, & basic machine learning techniques"
      ],
      "course_content": {
        "Introduction": [
          "Introduction to Course : Python Data Science Fundamentals: Getting Started",
          "Welcome Note by the Author",
          "Prerequisite for This Course: Embark on Your Data Science Journey"
        ],
        "Setting up the Environment": [
          "Download and Install Anaconda Environment"
        ],
        "Introduction to NumPy: Foundations of Numerical Computing": [
          "Introduction to NumPy",
          "Create a NumPy ndarray Object",
          "NumPy Array Indexing",
          "NumPy Array Slicing [ Numerical Python ]",
          "NumPy Array Copy vs View [ Numerical Python ]",
          "NumPy Array Reshaping [ Numerical Python ]",
          "NumPy Array Iterating [ Numerical Python ]"
        ],
        "Introduction to Pandas: A Powerful Data Analysis Library": [
          "Pandas Introduction",
          "Pandas DataFrames",
          "Pandas Read CSV & Analyzing DataFrames",
          "Pandas - Cleaning Empty Cells",
          "Pandas - Removing Duplicates",
          "Pandas - Data Correlations"
        ],
        "Matplotlib Tutorial": [
          "Matplotlib Tutorial Part 1"
        ],
        "Scikit-learn Essentials: Python's ML Powerhouse [Getting started ]": [
          "Python Machine Learning: Scikit-Learn [Getting started ]",
          "Python Machine Learning: Scikit-Learn [Data Preprocessing ]",
          "Python Machine Learning: Scikit-Learn [ Model Training ]",
          "Python Machine Learning: Scikit-Learn [Model Building & Evaluation ]"
        ]
      },
      "requirements": [
        "Computer/ Mobile",
        "Basic Python Knowledge"
      ],
      "description": "Course Description: Python for Machine Learning: A Beginner's Kickstart\nWelcome to the Python for Machine Learning: A Beginner's Kickstart course! This introductory course is designed to provide you with the fundamental skills and knowledge needed to dive into the exciting world of machine learning using Python.\nCourse Overview: In this course, you'll gain hands-on experience with essential Python libraries for data manipulation, analysis, visualization, and machine learning. The course focuses on three core libraries: NumPy, Pandas, Matplotlib, and Scikit-learn. These libraries are the backbone of data science and machine learning in Python, and mastering them will give you a solid foundation to explore more advanced machine learning topics.\nWhat You'll Learn:\nNumPy: Learn how to efficiently work with arrays and matrices, perform mathematical operations, and manipulate data in Python using NumPy.\nPandas: Discover the power of Pandas for data wrangling and manipulation, from handling data frames to performing data analysis and cleaning.\nMatplotlib: Explore data visualization techniques using Matplotlib to create meaningful plots and charts.\nScikit-learn: Dive into the world of machine learning with Scikit-learn. Understand the basics of data preprocessing, model building, training, evaluation, and prediction.\nLaunch Your Data Science Journey: Embark on a transformative learning journey that will equip you with the fundamental skills and knowledge needed to excel in the field of data science. With Python at the heart of this course, you'll harness the power of NumPy, Pandas, Matplotlib, and Scikit-learn to become a proficient data scientist.\n\n\nWhy Start Here: This course is designed to be your first step into the thrilling world of data science and machine learning. We'll take you on a beginner-friendly adventure, focusing on essential Python libraries: NumPy for numerical computing, Pandas for data manipulation, Matplotlib for data visualization, and Scikit-learn for introductory machine learning.\nBuild Essential Skills: Discover the power of Python in data science as we guide you through the fundamental concepts of each library. By the end of the course, you'll have a solid understanding of how to perform basic data analysis, visualization, and even create simple machine learning models.",
      "target_audience": [
        "Beginners with basic programming experience looking to enter the field of data science.",
        "Aspiring data analysts or data scientists seeking to build a strong foundation in Python for data manipulation and analysis",
        "Professionals from diverse backgrounds aiming to enhance their data analysis and visualization skills",
        "Individuals interested in understanding the basics of machine learning and its applications in real-world scenarios"
      ]
    },
    {
      "title": "Deploying machine learning models with flask for beginners",
      "url": "https://www.udemy.com/course/deploying-machine-learning-models-with-flask-for-beginners/",
      "bio": "How to deploy a machine learning model. How to create an API for machine learning. #machinelearning, #datascience",
      "objectives": [
        "You can create your own API endpoint for your machine learning models",
        "You learn how to use flask",
        "You know how to quickly deploy a userfriendly html page to make image classification predictions",
        "You use transfer learning",
        "You train your knowlege about keras",
        "You will train your data science skills"
      ],
      "course_content": {
        "Deploying machine learning models with flask for beginners - quick and easy": [
          "1 Hello and welcome everyone",
          "Downloadsection",
          "One important thing before you start",
          "3 Quick Introduction to Flask - Hello world web server application",
          "4 Defining and training the model",
          "5 Evaluating and saving the trained model",
          "6 Testing the model availability and make a first prediction",
          "7 How to define the boundaries of our input data",
          "8 Create our flask application - get started",
          "9 Creating the flask endpoint and ensure data quality checks",
          "10 Testing our API endpoint - lets get some predictions",
          "11 Introduction to the Image Classification Part",
          "12 Flask Application - An enpoint for our Image classification API",
          "13 The HTML Template explained",
          "14 Predicting Images on our hosted Flask Web application",
          "15 Congratulations and final words of wisdom"
        ],
        "BONUS SECTION How to deploy your ML Models to the web for free": [
          "Student Bonus - How to deploy your model on the internet for free",
          "More to learn is here"
        ]
      },
      "requirements": [
        "Basic knowlege of python",
        "Basic knowledge about neural networks",
        "The flask part and deployment is for beginners. We start from scratch and quickly acquire the skills together",
        "Your personal interest in the topic and a hands on mentality",
        "This course is hands on - instead of theory we implement the code and I explain what we do and why we do it"
      ],
      "description": "About this course\nLet's dive into data science with python and learn how we can create our own API (Application Programming Interface) where we can send data to and let our model return a prediction.\nThis course is a practical hands on course where we learn to deploy our trained machine learning models aka neural networks with the flask web framework.\nThis is a beginners class. You don't need any pre-knowlege about flask but you should know about neural networks and python. We will learn and code step by step together and I will explain what we do along the way.\nBesides machine learning apis we will also use transferlearning to use an advanced neural network and use a userfriendly HTML template to give the enduser a visual appealing interface for our application. The user can upload an image and our model will return an image classification prediction\nAll the resources will be provided and you can download all the used tools completely for free.\nSounds interesting? I hope so! Let's dive in and do this together. Let's acquire new skills and create new opportunities for us.\n\n\nIn General\nWhy datascience and machine learning? Well...\nIn the world of today and especially tomorrow machine learning and artificial intelligence will be the driving force of the economy. Data science  No matter who you are, an entrepreneur or an employee, and in which industry you are working in, machine learning (especially deep learning neural networks) will be on your agenda.\n\n\nfrom me personal:\n\"From my personal experience I can tell you that companies will actively searching for you if you aquire some skills in the data science field. Diving into this topic can not only immensly improve your career opportunities but also your job satisfaction!\"\nIt's time to get your hands dirty and dive into one of the hottest topics on this planet.",
      "target_audience": [
        "beginners to intermediate students in neural networks and machine learning who already know the basics",
        "students who are eager to learn and dive into one of the hottest topics currently out there",
        "you want to learn how to create an api endpoint for your neural network using flask",
        "you want to learn about creating a neural network web service using flask"
      ]
    },
    {
      "title": "Python Data Science basics with Numpy, Pandas and Matplotlib",
      "url": "https://www.udemy.com/course/python-data-science-basics-with-numpy-pandas-and-matplotlib/",
      "bio": "Covers all Essential Python topics and Libraries for Data Science or Machine Learning Beginner.",
      "objectives": [
        "Essential Python data types and data structure basics with Libraries like NumPy and Pandas for Data Science or Machine Learning Beginner."
      ],
      "course_content": {
        "Course Introduction and Table of Contents": [
          "Course Introduction and Table of Contents"
        ],
        "Introduction to Python, Pandas and Numpy": [
          "Introduction to Python, Pandas and Numpy"
        ],
        "System and Environment Setup": [
          "System and Environment Setup"
        ],
        "Python Strings": [
          "Python Strings - Part 1",
          "Python Strings - Part 2"
        ],
        "Python Numbers and Operators": [
          "Python Numbers and Operators - Part 1",
          "Python Numbers and Operators - Part 2"
        ],
        "Python Lists": [
          "Python Lists - Part 1",
          "Python Lists - Part 2",
          "Python Lists - Part 3",
          "Python Lists - Part 4",
          "Python Lists - Part 5"
        ],
        "Tuples in Python": [
          "Tuples in Python"
        ],
        "Sets in Python": [
          "Sets in Python - Part 1",
          "Sets in Python - Part 2"
        ],
        "Python Dictionary": [
          "Python Dictionary - Part 1",
          "Python Dictionary - Part 2"
        ],
        "NumPy Library - Introduction": [
          "NumPy Library Intro - Part 1",
          "NumPy Library Intro - Part 2",
          "NumPy Library Intro - Part 3"
        ]
      },
      "requirements": [
        "A decent configuration computer and the willingness to lay the corner stone for your big data journey."
      ],
      "description": "Welcome to my new course Python Essentials with Pandas and Numpy for Data Science\n\n\nIn this course, we will learn the basics of Python Data Structures and the most important Data Science libraries like NumPy and Pandas with step by step examples!\n\n\nThe first session will be a theory session in which, we will have an introduction to python, its applications and the libraries.\n\n\nIn the next session, we will proceed with installing python in your computer. We will install and configure anaconda which is a platform you can use for quick and easy installation of python and its libraries. We will get ourselves familiar with Jupiter notebook, which is the IDE that we are using throughout this course for python coding.\n\n\nThen we will go ahead with the basic python data types like strings, numbers and its operations. We will deal with different types of ways to assign and access strings, string slicing, replacement, concatenation, formatting and f strings.\n\n\nDealing with numbers, we will discuss the assignment, accessing and different operations with integers and floats. The operations include basic ones and also advanced ones like exponents. Also we will check the order of operations, increments and decrements, rounding values and type casting.\n\n\nThen we will proceed with basic data structures in python like Lists tuples and set. For lists, we will try different assignment, access and slicing options. Along with popular list methods, we will also see list extension, removal, reversing, sorting, min and max, existence check , list looping, slicing, and also inter-conversion of list and strings.\n\n\nFor Tuples also we will do the assignment and access options and the proceed with different options with set in python.\n\n\nAfter that, we will deal with python dictionaries. Different assignment and access methods. Value update and delete methods and also looping through the values in the dictionary.\n\n\nAnd after learning all of these basic data types and data structures, its time for us to proceed with the popular libraries for data-science in python. We will start with the NumPy library. We will check different ways to create a new NumPy array, reshaping , transforming list to arrays, zero arrays and one arrays, different array operations, array indexing, slicing, copying. we will also deal with creating and reshaping multi dimensional NumPy arrays, array transpose, and statistical operations like mean variance etc using NumPy\n\n\nLater we will go ahead with the next popular python library called Pandas. At first we will deal with the one dimensional labelled array in pandas called as the series.  We will create assign and access the series using different methods.\n\n\nThen will go ahead with the Pandas Data frames, which is a 2-dimensional labelled data structure with columns of potentially different types. We will convert NumPy arrays and also pandas series to data frames. We will try column wise and row wise access options, dropping rows and columns, getting the summary of data frames with methods like min, max etc. Also we will convert a python dictionary into a pandas data frame. In large datasets, its common to have empty or missing data. We will see how we can manage missing data within dataframes. We will see sorting and indexing operations for data frames.\n\n\nMost times, external data will be coming in either a CSV file or a JSON file. We will check how we can import CSV and JSON file data as a dataframe so that we can do the operations and later convert this data frame to either CSV and json objects and write it into the respective files.\n\n\nAlso we will see how we can concatenate, join and merge two pandas data frames. Then we will deal with data stacking and pivoting using the data frame and also to deal with duplicate values within the data-frame and to remove them selectively.\n\n\nWe can group data within a data-frame using group by methods for pandas data frame. We will check the steps we need to follow for grouping. Similarly we can do aggregation of data in the data-frame using different methods available and also using custom functions. We will also see other grouping techniques like Binning and bucketing based on data in the data-frame\n\n\nAt times we may need to use custom indexing for our dataframe. We will see methods to re-index rows and columns of a dataframe and also rename column indexes and rows. We will also check methods to do collective replacement of values in a dataframe and also to find the count of all or unique values in a dataframe.\n\n\nThen we will proceed with implementing random permutation using both the NumPy and Pandas library and the steps to follow. Since an excelsheet and a dataframe are similar 2d arrays, we will see how we can load values in a dataframe from an excelsheet by parsing it. Then we will do condition based selection of values in a dataframe, also by using lambda functions and also finding rank based on columns.\n\n\nThen we will go ahead with cross Tabulation of our dataframe using contingency tables. The steps we need to proceed with to create the cross tabulation contingency table.\n\n\nAfter all these operations in the data we have, now its time to visualize the data. We will do exercises in which we can generate graphs and plots. We will be using another popular python library called Matplotlib to generate graphs and plots. We will do tweaking of the grpahs and plots by adjusting the plot types, its parameters, labels, titles etc.\n\n\nThen we will use another visualization option called histogram which can be used to groups numbers into ranges. We will also be trying different options provided by matplotlib library for histogram\n\n\nOverall this course is a perfect starter pack for your long journey ahead with big data and machine learning. You will also be getting an experience certificate after the completion of the course(only if your learning platform supports)\n\n\nSo lets start with the lessons. See you soon in the class room.",
      "target_audience": [
        "Data science enthusiasts who want to begin their career"
      ]
    },
    {
      "title": "Machine Learning & Training Neural Network in MATLAB",
      "url": "https://www.udemy.com/course/machine-learning-training-neural-network-in-matlab/",
      "bio": "Machine Learning | Learn concepts of Machine Learning and how to train a Neural Network in MATLAB on Iris data-set.",
      "objectives": [
        "Students enrolled will be able yo learn basic concepts of Machine Learning and Train neural networks in MATLAB"
      ],
      "course_content": {
        "Introduction to Course": [
          "Introduction to Machine Learning"
        ],
        "Introduction to ANN": [
          "Introduction to ANN"
        ],
        "Iris Data Download": [
          "Iris Data Download"
        ],
        "Importing Data in MATLAB": [
          "Importing Data in MATLAB"
        ],
        "Converting the Data": [
          "Converting the Data"
        ],
        "Training the Network and Analyzing": [
          "Training the Network and Analyzing"
        ]
      },
      "requirements": [
        "MATLAB Software",
        "English Language"
      ],
      "description": "Machine Learning is the most evolving branch of Artificial Intelligence. Through this course, you will get a basic understanding of Machine Learning and Neural Networks.\nYou will also learn to train a Neural Network in MATLAB on Iris data-set available on UCI Machine Learning repository. The data set is simple and easy to understand and also small in size.\nMATLAB  is a multi-paradigm numerical computing environment..",
      "target_audience": [
        "Anyone who is interested in learning basic concepts of Machine Learning and Neural networks"
      ]
    },
    {
      "title": "Data Science Skillpath: SQL, ML, Looker Studio & Alteryx",
      "url": "https://www.udemy.com/course/data-science-skillpath/",
      "bio": "[4-in-1 Bundle] Covers SQL, Data viz using Google's Looker Studio, Machine Learning using Python and ETL using Alteryx",
      "objectives": [
        "Master SQL and perform advanced queries on relational databases.",
        "Develop expertise in data visualization using Google's Looker Studio and create interactive dashboards.",
        "Explore machine learning algorithms and apply them to real-world data problems.",
        "Master Python libraries such as NumPy, Pandas, and Scikit-learn for data analysis and modeling.",
        "Understand the ETL process and learn how to use Alteryx for data preparation and cleansing.",
        "Learn how to build and evaluate regression and classification models",
        "Develop skills in data storytelling and communicate insights effectively."
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Course Resources"
        ],
        "Installation and getting started": [
          "Installing PostgreSQL and pgAdmin in your System",
          "This is a milestone",
          "If pgAdmin is not opening..."
        ],
        "Fundamental SQL statements": [
          "CREATE",
          "Exercise 1: Create DB and Table",
          "Solutions to all Exercises",
          "INSERT",
          "Import data from File",
          "Exercise 2: Inserting and Importing data",
          "SELECT statement",
          "Quick coding exercise on Select Statement",
          "SELECT DISTINCT",
          "Quick coding exercise on Distinct Command",
          "WHERE",
          "Quick coding exercise on Where Statement",
          "Logical Operators",
          "Quick coding exercise on Logical Operators",
          "Exercise 3: SELECT, WHERE & Logical",
          "UPDATE",
          "Quick coding exercise on Update Command",
          "DELETE",
          "Quick coding exercise on Delete Command",
          "ALTER - Part 1",
          "ALTER - Part 2",
          "Quick coding exercise on Alter Command",
          "Exercise 4: Update, Delete and Alter Table",
          "Quiz"
        ],
        "Restore and Back-up": [
          "Restore and Back-up",
          "Debugging restoration issues",
          "Creating DB using CSV files",
          "Debugging summary and Code for CSV files",
          "Exercise 5: Restore and Back-up"
        ],
        "Selection commands: Filtering": [
          "IN",
          "Quick coding exercise on IN operator",
          "BETWEEN",
          "Quick coding exercise on Between Operator",
          "LIKE",
          "Quick coding exercise on Like operator",
          "Exercise 6: In, Like & Between",
          "Quiz"
        ],
        "Selection commands: Ordering": [
          "Side Lecture: Commenting in SQL",
          "ORDER BY",
          "Quick coding exercise on Order by Clause",
          "LIMIT",
          "Quick coding exercise on Limit Command",
          "Exercise 7: Sorting"
        ],
        "Alias": [
          "AS",
          "Quick coding exercise on AS operator"
        ],
        "Aggregate Commands": [
          "COUNT",
          "Quick coding exercise on Count function",
          "SUM",
          "Quick coding exercise on Sum function",
          "AVERAGE",
          "Quick coding exercise on Average function",
          "MIN & MAX",
          "Quick coding exercise on MIN & MAX function",
          "Exercise 8: Aggregate functions",
          "Quiz"
        ],
        "Group By Commands": [
          "GROUP BY",
          "Quick coding exercise on Group By Clause",
          "HAVING",
          "Quick coding exercise on Having Clause",
          "Exercise 9: Group By",
          "Quiz"
        ],
        "Conditional Statement": [
          "CASE WHEN",
          "Quick coding exercise on CASE WHEN Statement"
        ]
      },
      "requirements": [
        "A PC with internet connection. Installation instructions for all tools used are covered in the course."
      ],
      "description": "If you're a data professional looking to level up your skills and stay ahead of the curve, this is the course for you. Do you want to be able to analyze and manipulate data with ease, create stunning visualizations, build powerful machine learning models, and streamline data workflows? Then join us on this journey and become a data science rockstar.\nIn this course, you will:\nDevelop expertise in SQL, the most important language for working with relational databases\nMaster data visualization using Looker Studio, a powerful platform for creating beautiful and interactive dashboards\nLearn how to build machine learning models using Python, a versatile and widely-used programming language\nExplore the world of ETL (Extract, Transform, Load) and data integration using Alteryx, a popular tool for automating data workflows\nWhy learn about data science? It's one of the most in-demand skills in today's job market, with companies in all industries looking for professionals who can extract insights from data and make data-driven decisions. In this course, you'll gain a deep understanding of the data science process and the tools and techniques used by top data scientists.\nThroughout the course, you'll complete a variety of hands-on activities, including SQL queries, data cleaning and preparation, building and evaluating machine learning models, and creating stunning visualizations using Looker Studio. By the end of the course, you'll have a portfolio of projects that demonstrate your data science skills and a newfound confidence in your ability to work with data.\nWhat makes us qualified to teach you?\nThe course is taught by Abhishek (MBA - FMS Delhi, B. Tech - IIT Roorkee) and Pukhraj (MBA - IIM Ahmedabad, B. Tech - IIT Roorkee). As managers in the Global Analytics Consulting firm, we have helped businesses solve their business problems using Analytics and we have used our experience to include the practical aspects of business analytics in this course. We have in-hand experience in Business Analysis.\nWe are also the creators of some of the most popular online courses - with over 1,200,000 enrollments and thousands of 5-star reviews like these ones:\nThis is very good, i love the fact the all explanation given can be understood by a layman - Joshua\nThank you Author for this wonderful course. You are the best and this course is worth any price. - Daisy\nOur Promise\nTeaching our students is our job and we are committed to it. If you have any questions about the course content, practice sheet, or anything related to any topic, you can always post a question in the course or send us a direct message.\nDon't miss out on this opportunity to become a data science expert. Enroll now and start your journey towards becoming a skilled data scientist today!",
      "target_audience": [
        "Recent graduates or job seekers who want to break into the field of data science and acquire a comprehensive skillset.",
        "Small business owners who want to learn how to effectively analyze data and create reports to inform their business decisions.",
        "Analysts who want to enhance their skills in data management and visualization using SQL, Looker Studio, and Alteryx"
      ]
    },
    {
      "title": "Natural Language Processing | Build LLM Web App | RNN & LSTM",
      "url": "https://www.udemy.com/course/nlp-natural-language-processing/",
      "bio": "Create App Using Streamlit | Sentiment Analysis | Speech to text | Spam Detection",
      "objectives": [
        "You will gain insights on what Natural Language Processing(NLP) is, its Applications & Challenges",
        "You will learn Sentence Segmentation, Word Tokenization, Stemming, Lemmatization, Parsing, POS & Ambiguities in NLP",
        "You will learn to execute using Machine Learning, NLTK & Spacey",
        "You will learn to work with Text Files with Python",
        "You will utilize Regular Expressions for pattern searching in text",
        "You will use Part of Speech Tagging to automatically process raw text files",
        "You will visualize POS and NER with Spacy",
        "You will understand Vocabulary Matching with Spacy",
        "You will use NLTK for Sentiment Analysis"
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Key concepts in NLP": [
          "Sentence Segmentation",
          "Tokenization",
          "Regular Expressions Refresher",
          "Stemming",
          "Lemmatization",
          "Stop Words",
          "Parts of Speech",
          "Dependency Parsing",
          "Encoding | BPE",
          "Ambiguities in NLP"
        ],
        "Ambiguities in NLP": [
          "Lexical Ambiguity",
          "Syntactic Ambiguity",
          "Pragmatic Ambiguity",
          "Ellipsis Handling",
          "Structural Ambiguity and Metaphorical Language",
          "Sarcasm Detection"
        ],
        "Case Studies (with walk through of the codes)": [
          "Case Study 1: Sentiment Analysis & Word Cloud",
          "Case Study 2: Speech to Text deployment in a call center",
          "Case Study 3: Text Summarization",
          "Case Study 4: Spam Classification Using Machine Learning"
        ],
        "Deep Learning in NLP": [
          "Why do you need RNN",
          "Math Behind RNN",
          "LSTM",
          "Build a Spam Detection Model Using RNN and LSTM",
          "Transformers and Building Q&A system for a pdf file"
        ],
        "Creating an NLP Web App Using Streamlit": [
          "Infrastructure for Streamlit",
          "Creating a very simple web app and Getting started with streamlit",
          "Header and Sub Header",
          "Reading and displaying contents of a file",
          "Uploading a file",
          "NLP Wordcloud App",
          "Deploying the app in Heroku",
          "Deploying the app in streamlit"
        ],
        "Create a ChatGPT powered app using Streamlit": [
          "LLM Web App"
        ],
        "Bonus Lecture": [
          "Bonus Lecture"
        ]
      },
      "requirements": [
        "None. (Python is covered extensively in the course)"
      ],
      "description": "Recent Updates:\nNov 2022: Updated videos for RNN and LSTM\nApr 2023: Added a video lecture on transformers\nSep 2023: Added a video lecture on how to build an LLM web application\n\n\nNatural Language Processing (NLP) is a very interesting field associated with AI and is at the forefront of many useful applications like a chatbot. Knowledge of NLP is considered a necessity for those pursuing a career in AI. This course covers both the theory as well as the applications of NLP. Case studies are explained along with a walkthrough of the codes for a better understanding of the subject.\nA detailed explanation of how to build a web app for NLP using Streamlit is also explained.\nNLP is a subfield of computer science and artificial intelligence concerned with interactions between computers and human (natural) languages. It is used to apply machine learning algorithms to text and speech.\nFor example, we can use NLP to create systems like speech recognition, document summarization, machine translation, spam detection, named entity recognition, question answering, autocomplete, predictive typing and so on.\nNowadays, most of us have smartphones that have speech recognition. These smartphones use NLP to understand what is said. Also, many people use laptops whose operating system has built-in speech recognition.\n\n\nSome Examples:\n1.Cortana\nThe Microsoft OS has a virtual assistant called Cortana that can recognize a natural voice. You can use it to set up reminders, open apps, send emails, play games, track flights and packages, check the weather and so on.\n2.Siri\nSiri is a virtual assistant of the Apple Inc.’s iOS, watchOS, macOS, HomePod, and tvOS operating systems. Again, you can do a lot of things with voice commands: start a call, text someone, send an email, set a timer, take a picture, open an app, set an alarm, use navigation and so on.\n\n\nIn this course we will deal with:\na)NLP Introduction:\n· What is NLP\n· Applications of NLP\n· Challenges in NLP\n\n\nb)Key concepts in NLP:\n· Sentence Segmentation\n· Word Tokenization\n· Stemming\n· Lemmatization\n· Parsing\n· POS\n· Ambiguities in NLP\n\n\nc)NLP in Action\n· NLTK\n· Sentence Tokenization\n· Word Tokenization\n· Stemming\n· Lemmatization\n· Noise Removal\n· Spacy\n· Parts of Speech Tagging\n· Dependency Parsing\n· Spell Correction\n· Point of View\n· Regular Expressions\n· Flash Text\n· Named Entity Recognition - NER\n\n\nd)Case studies:\n· Speech recognition\n· Sentiment analysis\n· Word Cloud\n· Spam detection\n\n\nYou will not only get fantastic technical content with this course, but you will also get access to both our course-related Question and Answer forums, as well as our live student chat channel, so you can team up with other students for projects, or get help on the course content from myself and the course teaching assistants.\nAll of this comes with a 30-day money back guarantee, so you can try the course risk-free.\nWhat are you waiting for? Become an expert in natural language processing today!",
      "target_audience": [
        "Data Scientists, Python Programmers, ML Practitioners, IT Managers managing data science projects",
        "Python developers interested in learning how to use Natural Language Processing"
      ]
    },
    {
      "title": "Machine Learning and Deep Learning Projects in Python",
      "url": "https://www.udemy.com/course/machine-learning-and-deep-learning-projects-in-python/",
      "bio": "20 practical projects of Machine Learning and Deep Learning and their implementation in Python along with all the codes",
      "objectives": [
        "Introducing the structure of Machine Learning and Deep Learning and their application in real problems",
        "Introducing Machine Learning and Deep Learning algorithms and launching them in projects",
        "Implementing Machine Learning and Deep Learning algorithms in Python",
        "Familiarity with Python syntax for using Machine Learning and Deep Learning",
        "Familiarity with Prediction Models",
        "Data preparation and Visualization for use in Machine Learning and Deep Learning algorithms",
        "Using Case Studies in projects",
        "Learning how to use APIs to collect up-to-date data and learn about different Data sets",
        "Introducing and using different Machine Learning and Deep Learning libraries in Python",
        "Getting to know different Neural Networks and using them in real projects",
        "Image processing using Artificial Neural Network (ANN) in Python",
        "Classification with Neural Networks using Python",
        "Familiarity with Natural Language Processing (NLP) and its use in projects",
        "Forecasting the amount of sales, product price, sales price, etc.",
        "Introducing and using algorithm validation metrics such as: Confusion matrix, Accuracy score, Precision score, Recall score, F1 score, etc.",
        "+40 Cheat Sheets of Data Science, Machine Learning, Deep Learning and Python"
      ],
      "course_content": {
        "Introduction": [
          "Introduction to Machine Learning"
        ],
        "Waiter Tips Prediction with Machine Learning": [
          "Requirements",
          "Waiter Tips Prediction with Machine Learning",
          "Codes"
        ],
        "Future Sales Prediction with Machine Learning": [
          "Requirements",
          "Future Sales Prediction with Machine Learning",
          "Codes"
        ],
        "Cryptocurrency Price Prediction with Machine Learning": [
          "Cryptocurrency Price Prediction for the next 30 days",
          "Codes"
        ],
        "Stock Price Prediction with LSTM Neural Network": [
          "Stock Price Prediction with LSTM Neural Network",
          "Codes"
        ],
        "Image Classification with Neural Networks": [
          "Requirements",
          "Image Classification with Neural Networks",
          "Codes"
        ],
        "Visualize a Machine Learning Algorithm": [
          "Requirements",
          "Visualize a Machine Learning Algorithm",
          "Codes"
        ],
        "Instagram Reach Analysis with Machine Learning": [
          "Requirements",
          "Instagram Reach Analysis with Machine Learning",
          "Codes"
        ],
        "Mobile Price Classification with Machine Learning": [
          "Requirements",
          "Mobile Price Classification with Machine Learning",
          "Codes"
        ],
        "Gold Price Prediction with Machine Learning": [
          "Gold Price Prediction with Machine Learning",
          "Codes"
        ]
      },
      "requirements": [
        "Basic Python"
      ],
      "description": "Machine learning and Deep learning have revolutionized various industries by enabling the development of intelligent systems capable of making informed decisions and predictions. These technologies have been applied to a wide range of real-world projects, transforming the way businesses operate and improving outcomes across different domains.\nIn this training, an attempt has been made to teach the audience, after the basic familiarity with machine learning and deep learning, their application in some real problems and projects (which are mostly popular and widely used projects).\nAlso, all the coding and implementation of the models are done in Python, which in addition to machine learning, students' skills in Python language will also increase and they will become more proficient in it.\nIn this course, students will be introduced to some machine learning and deep learning algorithms such as Logistic regression, multinomial Naive Bayes, Gaussian Naive Bayes, SGDClassifier, ... and different models. Also, they will use artificial neural networks for modeling to do the projects.\nThe use of effective data sets in different fields, data preparation and pre-processing, visualization of results, use of validation metrics, different prediction methods, image processing, data analysis and statistical analysis are other parts of this course.\nMachine learning and deep learning have brought about a transformative impact across a multitude of industries, ushering in the creation of intelligent systems with the ability to make well-informed decisions and accurate predictions. These innovative technologies have been harnessed across a diverse array of real-world projects, reshaping the operational landscape of businesses and driving enhanced outcomes across various domains.\nWithin this training course, the primary aim is to impart knowledge to the audience, assuming a foundational understanding of machine learning and deep learning concepts. The focus then shifts to their practical applications in addressing real-world challenges and undertaking projects, many of which are widely recognized and utilized within the field.\nMoreover, the entirety of coding and models implementation is conducted using the Python programming language. This dual approach not only deepens the students' grasp of machine learning but also contributes to their proficiency in the Python language itself.\nThe curriculum of this course encompasses the introduction of several fundamental machine learning and deep learning algorithms, including Logistic Regression, Multinomial Naive Bayes, Gaussian Naive Bayes, SGDClassifier, and some other algorithms among others, alongside diverse model architectures. As a pivotal component of the course, students delve into the utilization of artificial neural networks for modeling, which serves as the cornerstone for executing the various projects.\nComprehensive utilization of pertinent datasets spanning diverse domains, coupled with comprehensive data preparation and preprocessing techniques, takes precedence. The students are further equipped with the skills to visualize and interpret outcomes effectively, employ validation metrics judiciously, explore varied prediction methodologies, engage in image processing, and undertake data analysis and statistical analysis. These facets collectively constitute the multifaceted landscape covered by this course.\nAnd at the end, more than 40 complete and practical cheat sheets in the field of data science, machine learning, deep learning and Python have been given to you.",
      "target_audience": [
        "Developers",
        "Data Scientists",
        "Data Analysts",
        "Researchers",
        "Teachers",
        "Managers",
        "Students",
        "Job seekers"
      ]
    },
    {
      "title": "LLM - Fine tune with custom data",
      "url": "https://www.udemy.com/course/llm-fine-tune/",
      "bio": "Learn how to fine tune GPT 3.5 Turbo models using OpenAI, Gradient platforms with your own datasets",
      "objectives": [
        "Understanding Fine tuning vs training data",
        "Fine tune using GPT models, GPT 3.5 Turbo models, Open AI models",
        "Preparing, creating, and uploading training and validation datasets",
        "Fine tuning using Gradient Platform",
        "Create Elon Mush Tweet Generator",
        "Build a data extraction fine-tune model"
      ],
      "course_content": {
        "Introduction": [
          "What is fine-tuning?",
          "Training vs Fine-tuning",
          "The Foundation models",
          "Why Fine-tune?",
          "Ways to fine-tune a model",
          "Model parameters"
        ],
        "Fine tune using GPT models": [
          "Models availability, and use cases",
          "Prepare the sample data",
          "Format the sample data",
          "Token counting function",
          "Check warning and OpenAI cost",
          "Understanding model fine-tuning",
          "Training vs Validation data",
          "Uploading training and validation data to OpenAI",
          "Create a fine tune job",
          "QA using your new model"
        ],
        "Fine tune using gradient platform": [
          "Gradient platform - Setting up login",
          "Gradient platform - Interface",
          "What are some of the pre-trained model available?",
          "Create a new model with sample data",
          "What is epochs?",
          "Fine tuning the model and QA"
        ],
        "Elon Musk tweet generator": [
          "Prepare the datasets with OpenAI",
          "Create a fine-tune model",
          "Testing the model in OpenAI playground",
          "Elon Musk Tweet Generator Streamlit app"
        ],
        "Data Extraction fine-tune model": [
          "Extract any valuable information from raw text"
        ],
        "The Math behind Fine Tuning": [
          "Quantization",
          "Custom precision and inference",
          "Floating point to binary representation",
          "Symmetric quantization",
          "Asymmetric quantization",
          "Post training quantization",
          "Quantization aware training (QAT)"
        ],
        "Quantizing any LLM": [
          "Base model to GGUF model",
          "Quantization, and uploading to Huggingface"
        ],
        "Fine Tuning with Unsloth": [
          "Introduction to Unsloth Framework",
          "Install unsloth FastLanguageModel",
          "Load IMDB Movie datasets",
          "Setup Model, Tokenizer and get PEFT Model",
          "Setup supervise fine tune trainer (SFTTrainer) model",
          "Test and save the model"
        ],
        "Fine Tune any LLMs using LLaMA Factory": [
          "Create a fine tune model for docker commands NLP",
          "Train the model with LLaMA Factory"
        ],
        "Fine-Tuning Use Cases": [
          "Fine-tuning LLMs are cheaper and faster",
          "Use Cases of Fine Tune Models",
          "When not to use Fine Tuning"
        ]
      },
      "requirements": [
        "Basic python knowledge"
      ],
      "description": "Welcome to LLM - Fine Tune with Custom Data!\n\n\nIf you're passionate about taking your machine learning skills to the next level, this course is tailor-made for you. Get ready to embark on a learning journey that will empower you to fine-tune language models with custom datasets, unlocking a realm of possibilities for innovation and creativity.\n\n\nIntroduction to LLM and Fine Tuning\n\n\nIn this opening section, you'll be introduced to the course structure and objectives. We'll explore the significance of fine-tuning in enhancing language models and delve into the foundational models that set the stage for customization. Discover the reasons behind the need for fine-tuning and explore various strategies, including an understanding of critical model parameters. Gain a comprehensive understanding of the fundamental principles and advanced concepts in artificial intelligence and language modeling.\n\n\nFine Tune Using GPT Models\n\n\nThis section focuses on practical applications. Survey available models and their use cases, followed by essential steps in preparing and formatting sample data. Understand token counting and navigate potential pitfalls like warnings and cost management. Gain a comprehensive understanding of the fine-tuning process, differentiating between training and validation data. Learn to upload data to OpenAI, create a fine-tune job, and ensure quality assurance for your model.\n\n\nUse Gradient Platform to quickly fine tune\n\n\nGradient AI Platform : The only AI Agent platform that supports fine-tuning, RAG development, and purpose built LLMs out-of-the-box. Pre-tuned, Domain Expert AI i.e. Gradient offers domain-specific AI designed for your industry. From healthcare to financial services, we've built AI from the ground up to understand domain context. Use the platform to upload and train base foundations models with your own dataset.\n\n\nCreate a Elon Musk Tweet Generator\n\n\nTrain a foundation model with Elon Mush sample tweets, and then used the 'New Fine Tune Model' to create Elon Mush style tweets. Create a streamlit app to demonstrate side-by-side a normal tweet generated by OpenAI vs your very own model.\n\n\nData Extraction fine-tune model\n\n\nLearn how to extract 'valuable information' from a raw text. Learn how to pass sample datasets with question and answers, and then pass any raw text to get valuable information. Use real-world example of identifying person, amount spend and item from raw expense transactions and much more.\n\n\nEnroll now to learn how to fine-tune large language models with your own data, and unlock the potential of personalized applications and innovations in the world of machine learning!",
      "target_audience": [
        "Anyone who want to explore the world of AI",
        "Anyone who want to step into AI world with practical fine tuning models",
        "Data engineers, database administrators and data professionals curious about the emerging field of model fine tuning",
        "Software developers interested in integrating their own data into large language models",
        "Data scientists and machine learning engineers."
      ]
    },
    {
      "title": "Data Science for Beginners: Data Science Intro Course",
      "url": "https://www.udemy.com/course/data-science-for-the-beginner/",
      "bio": "A data science intro course. Data Science concepts, methodology, illustration of machine learning via chatbot, and more!",
      "objectives": [
        "Explanation of key concepts in data science: big data, data mining, libraries, datasets, API's",
        "Programming languages and which ones to learn",
        "Data Science Methodology, expressed via Healthcare Insurance Company Case Study",
        "Experience The Power of Machine Learning and Natural Language Processing via Chatbot Example",
        "GitHub; how to use it for collaboration and version control."
      ],
      "course_content": {
        "Introduction to Data Science Concepts": [
          "Matching Activity: Match Project and Data Role",
          "Intro to Data Science",
          "What a Data Scientist Does?",
          "Big Data",
          "Data Mining",
          "Machine Learning vs. Deep Learning",
          "Advice to Data Scientists"
        ],
        "Programming Languages": [
          "Intro to Programming Languages",
          "Python",
          "SAS",
          "R",
          "SQL"
        ],
        "Data Science Methodology": [
          "Data Science Methodology/Process Intro",
          "Business Understanding",
          "Data Understanding",
          "Data Prep",
          "Modeling",
          "Evaluation",
          "Deployment",
          "What Would You Pick?"
        ],
        "Data Science Via Chatbot": [
          "Purpose of this Section",
          "What is a Chatbot?",
          "Signing up for Watson Assistant",
          "Creating a name - Healthcare Service Chatbot",
          "Intents",
          "Entities",
          "Suggestions for More Learning",
          "Section Recap: Natural Language Processing , Machine Learning, and Use Cases"
        ],
        "Libraries, API's, Datasets": [
          "Libraries",
          "API's",
          "Datasets"
        ],
        "Github": [
          "Intro to Github",
          "Create a Repository",
          "Creating Branch and Commit Changes",
          "Pull Request and Merging Pull Request"
        ],
        "Final Section and Survey": [
          "Quick Survey (2 questions)",
          "Bonus Offer"
        ]
      },
      "requirements": [
        "No. This is ideal for a beginner to Data Science."
      ],
      "description": "Welcome! If you see Data Science as a potential career in your future, this is the perfect course to get started with.\nOur course does not require any previous Data Science experience. The goal of 'Data Science for Beginners' is to get you acquainted with Data Science methodology, data science concepts, programming languages, give you a peek into how machine learning works, and finally show you a data science tool like GitHub, which lets you collaborate with your colleagues.\nNow, while this is a beginner course,  it does not mean that it is an easy course. For example in the Data Science methodology section, many different concepts are introduced. But please keep in mind that a. you will get concrete examples of what each concept means when it is brought up b. you can ask questions in the Q and A and c. most importantly, you are not meant to understand all the concepts.  Going through the methodology is meant to introduce you to concepts, not prepare you to fully apply them. You will get a chance to do this in other courses (ours or other providers).\nBeyond this, you will get to build a simple chatbot. This hands-on activity will illustrate in a more interactive way how machine learning works and how you can provide a machine learning service such as this in your future career.\nSo, don't hesitate. Start your Data Science learning journey today!",
      "target_audience": [
        "Beginners to Data Science.",
        "Individuals considering switching fields.",
        "Individuals who want to get a general overview before focusing on specific Data Science topics."
      ]
    },
    {
      "title": "Practical Neural Networks & Deep Learning In R",
      "url": "https://www.udemy.com/course/practical-neural-networks-deep-learning-in-r/",
      "bio": "Artificial Intelligence & Machine Learning for Practical Data Science in R",
      "objectives": [
        "Be Able To Harness The Power Of R For Practical Data Science",
        "Read In Data Into The R Environment From Different Sources & Carry Out Basic Pre-processing Tasks",
        "Master The Theory Of Artificial Neural Networks (ANN)",
        "Implement ANN For Classification & Regression Problems In R",
        "Implement Deep Learning In R",
        "Learn The Usage Of The Powerful H2o Package",
        "Learn The Implementation Of Both ANN & DNN Using The H2o Package Of R Programming Language"
      ],
      "course_content": {
        "INTRODUCTION TO THE COURSE: The Key Concepts and Software Tools": [
          "Introduction",
          "Data and Scripts For the Course",
          "Installing R and R Studio",
          "Read in CSV & Excel Data",
          "Read in Online CSV",
          "Read in Data from Online HTML Tables-Part 1",
          "Read in Data from Online HTML Tables-Part 2",
          "Remove Missing Values",
          "More Data Cleaning",
          "Introduction to dplyr for Data Summarizing-Part 1",
          "Introduction to dplyr for Data Summarizing-Part 2",
          "Exploratory Data Analysis(EDA): Basic Visualizations with R",
          "More Exploratory Data Analysis with xda",
          "Difference Between Supervised & Unsupervised Learning"
        ],
        "Introduction to Artificial Neural Networks (ANN)": [
          "Theory Behind ANN (Artificial Neural Network) and DNN (Deep Neural Networks)",
          "Neural Network for Binary Classifications",
          "Neural Network with PCA for Binary Classifications",
          "Evaluate Accuracy",
          "Implement a Multi-Layer Perceptron (MLP) For Supervised Classification",
          "Neural Network for Multiclass Classifications",
          "Neural Network for Image Type Data",
          "Multi-class Classification Using Neural Networks with caret",
          "Neural Network for Regression",
          "More on Neural Networks- with neuralnet",
          "Identify Variable Importance in Neural Networks"
        ],
        "Start With Deep Neural Network (DNN)": [
          "Implement a Simple DNN With \"neuralnet\" for Binary Classifications",
          "Implement a Simple DNN With \"deepnet\" for Regression",
          "A Package for DNN Modelling in R-H2o",
          "Working with External Data in H2o",
          "Implement an ANN with H2o For Multi-Class Supervised Classification",
          "Implement a DNN with H2o For Multi-Class Supervised Classification",
          "Implement a (Less Intensive) DNN with H2o For Supervised Classification",
          "Identify Variable Importance",
          "What Are Activation Functions?",
          "Implement a DNN with H2o For Regression",
          "Autoencoders for Unsupervised Learning",
          "Autoencoders for Credit Card Fraud Detection",
          "Use the Autoencoder Model for Anomaly Detection",
          "Autoencoders for Unsupervised Classification"
        ],
        "ANN & DNN With MXNet Package in R": [
          "Install MXnet in R and RStudio",
          "MXNEt Installation Code For R",
          "Implement an ANN Based Classification Using MXNet",
          "Implement an ANN Based Regression Using MXNet",
          "Implement a DNN Based Multi-Class Classification With MXNet",
          "Evaluate Accuracy of the DNN Model",
          "Implement MXNET via \"caret\""
        ],
        "Convolution Neural Networks (CNN)": [
          "What is a CNN?",
          "Implement a CNN for Multi-Class Supervised Classification",
          "More About Our CNN Model Accuracy",
          "Implement CNN on Actual Images with MxNet",
          "RNNs With Temporal Data",
          "Github",
          "What Is Data Science?"
        ]
      },
      "requirements": [
        "Be Able To Operate & Install Software On A Computer",
        "Prior Exposure To Common Machine Learning Terms Such As Unsupervised & Supervised Learning",
        "Prior Exposure To What Neural Networks Are & What They Can Be Used For"
      ],
      "description": "YOUR COMPLETE GUIDE TO PRACTICAL NEURAL NETWORKS & DEEP LEARNING IN R:\nThis course covers the main aspects of neural networks and deep learning. If you take this course, you can do away with taking other courses or buying books on R based data science.\nIn this age of big data, companies across the globe use R to sift through the avalanche of information at their disposal. By becoming proficient in neural networks and deep learning in R, you can give your company a competitive edge and boost your career to the next level!\n\n\nLEARN FROM AN EXPERT DATA SCIENTIST:\nMy name is Minerva Singh and I am an Oxford University MPhil (Geography and Environment) graduate. I recently finished a PhD at Cambridge University.\nI have +5 years of experience in analyzing real life data from different sources using data science related techniques and producing publications for international peer reviewed journals.\nOver the course of my research I realized almost all the R data science courses and books out there do not account for the multidimensional nature of the topic .\nThis course will give you a robust grounding in the main aspects of practical neural networks and deep learning.\nUnlike other R instructors, I dig deep into the data science features of R and give you a one-of-a-kind grounding in data science...\nYou will go all the way from carrying out data reading & cleaning  to to finally implementing powerful neural networks and deep learning algorithms and evaluating their performance using R.\nAmong other things:\nYou will be introduced to powerful R-based deep learning packages such as h2o and MXNET.\nYou will be introduced to deep neural networks (DNN), convolution neural networks (CNN) and recurrent neural networks (RNN).\nYou will learn to apply these frameworks to real life data including credit card fraud data, tumor data, images among others for classification and regression applications.\nWith this course, you’ll have the keys to the entire R Neural Networks and Deep Learning Kingdom!\n\n\nNO PRIOR R OR STATISTICS/MACHINE LEARNING KNOWLEDGE IS REQUIRED:\nYou’ll start by absorbing the most valuable R Data Science basics and techniques. I use easy-to-understand, hands-on methods to simplify and address even the most difficult concepts in R.\nMy course will help you implement the methods using real data obtained from different sources. Many courses use made-up data that does not empower students to implement R based data science in real-life.\nAfter taking this course, you’ll easily use data science packages like caret, h2o, mxnet to work with real data in R...\nYou’ll even understand the underlying concepts to understand what algorithms and methods are best suited for your data.\nWe will also work with real data and you will have access to all the code and data used in the course.\nJOIN MY COURSE NOW!",
      "target_audience": [
        "People Wanting To Master The R & R Studio Environment For Data Science",
        "Anyone With Prior Exposure To Common Machine Learning Concepts Such As Supervised Learning",
        "Students Wishing To Learn The Implementation Of Neural Networks On Real Data In R",
        "Students Wishing To Learn The Implementation Of Basic Deep Learning Concepts In R"
      ]
    },
    {
      "title": "The Fun and Easy Guide to Machine Learning using Keras",
      "url": "https://www.udemy.com/course/machine-learning-fun-and-easy-using-python-and-keras/",
      "bio": "Learn 16 Machine Learning Algorithms in a Fun and Easy along with Practical Python Labs using Keras",
      "objectives": [
        "You will learn the fundamentals of the main Machine Learning Algorithms and how they work on an Intuitive level.",
        "We teach you these algorithms without boring you with the complex mathematics and equations.",
        "You will learn how to implement these algorithms in Python using sklearn and numpy.",
        "You will learn how to implement neural networks using the h2o package",
        "You will learn to implement some of the most common Deep Learning algorithms in Keras",
        "Build an arsenal of powerful Machine Learning models and how to use them to solve any problem.",
        "You will learn to Automate Manual Data Analysis Tasks."
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Setting up your Python Integrated Development Environment (IDE) for Course Labs": [
          "Download and Install Python Anaconda Distribution",
          "\"Hello World\" in Jupyter Notebook",
          "Installation for Mac Users",
          "Datasets, Python Notebooks and Scripts For the Course"
        ],
        "=======Regression=======": [
          "Regression"
        ],
        "Linear Regression": [
          "Linear Regression - Theory",
          "Linear Regression - Practical Labs"
        ],
        "Decision Tree - Classification and Regression Trees": [
          "Decision Tree - Theory",
          "Decision Tree - Practical Labs"
        ],
        "Random Forests": [
          "Random Forest - Theory",
          "Random Forest Practical Labs"
        ],
        "=======Classification=======": [
          "Classification"
        ],
        "Logistic Regression": [
          "Logistic Regression - Theory",
          "Logistic Regression Classification - Practical Labs"
        ],
        "K Nearest Neighbors": [
          "K -Nearest Neighbors - Theory",
          "KNN Classification - Practical Labs"
        ],
        "Support Vector Machines (SVM)": [
          "Support Vector Machine -Theory",
          "Linear SVM - Practical Labs",
          "Non Linear SVM - Practical Labs"
        ]
      },
      "requirements": [
        "PC/ Laptop to implement the Practical Labs, running Windows or Mac.",
        "High school knowledge in mathematics.",
        "Willingness to Learn and Open Mind.",
        "Background in engineering, data science, computer science and statistics is recommended (but not a requirement)",
        "Basic Python or Programming Background recommended (but not a requirement)."
      ],
      "description": "Welcome to the Fun and Easy Machine learning Course in Python and Keras.\n\nAre you Intrigued by the field of Machine Learning? Then this course is for you! We will take you on an adventure into the amazing of field Machine Learning. Each section consists of fun and intriguing white board explanations with regards to important concepts in Machine learning as well as practical python labs which you will enhance your comprehension of this vast yet lucrative sub-field of Data Science.\nSo Many Machine Learning Courses Out There, Why This One?\nThis is a valid question and the answer is simple. This is the ONLY course on Udemy which will get you implementing some of the most common machine learning algorithms on real data in Python. Plus, you will gain exposure to neural networks (using the H2o framework) and some of the most common deep learning algorithms with the Keras package.\nWe designed this course for anyone who wants to learn the state of the art in Machine learning in a simple and fun way without learning complex math or boring explanations.  Each theoretically lecture is uniquely designed using whiteboard animations which can maximize engagement in the lectures and improves knowledge retention. This ensures that you absorb more content than you would traditionally would watching other theoretical videos and or books on this subject.\nWhat you will Learn in this Course\nThis is how the course is structured:\nRegression – Linear Regression, Decision Trees, Random Forest Regression,\nClassification – Logistic Regression, K Nearest Neighbors (KNN), Support Vector Machine (SVM) and Naive Bayes,\nClustering - K-Means, Hierarchical Clustering,\nAssociation Rule Learning - Apriori, Eclat,\nDimensionality Reduction - Principle Component Analysis, Linear Discriminant  Analysis,\nNeural Networks - Artificial Neural Networks, Convolution Neural Networks, Recurrent Neural Networks.\nPractical Lab Structure\nYou DO NOT need any prior Python or Statistics/Machine Learning Knowledge to get Started. The course will start by introducing students to one of the most fundamental statistical data analysis models and its practical implementation in Python- ordinary least squares (OLS) regression. Subsequently some of the most common machine learning regression and classification techniques such as random forests, decision trees and linear discriminant analysis will be covered. In addition to providing a theoretical foundation for these, hands-on practical labs will demonstrate how to implement these in Python. Students will also be introduced to the practical applications of common data mining techniques in Python and gain proficiency in using a powerful Python based framework for machine learning which is Anaconda (Python Distribution). Finally you will get a solid grounding in both Artificial Neural Networks (ANN) and the Keras package for implementing deep learning algorithms such as the Convolution Neural Network (CNN). Deep Learning is an in-demand topic and a knowledge of this will make you more attractive to employers.\nExcited Yet?\nSo as you can see you are going to be learning to build a lot of impressive Machine Learning apps in this 3 hour course. The underlying motivation for the course is to ensure you can apply Python based data science on real data into practice today. Start analyzing  data for your own projects, whatever your skill level and IMPRESS your potential employers with an actual examples of your  machine learning abilities.\n\nIt is a practical, hands-on course, i.e. we will spend some time dealing with some of the theoretical concepts related to data science. However, majority of the course will focus on implementing different  techniques on real data and interpret the results. After each video you will learn a new concept or technique which you may apply to your own projects.\nTAKE ACTION TODAY! We will personally support you and ensure your experience with this course is a success. And for any reason you are unhappy with this course, Udemy has a 30 day Money Back Refund Policy, So no questions asked, no quibble and no Risk to you. You got nothing to lose. Click that enroll button and we'll see you in side the course.",
      "target_audience": [
        "Student who starting out or interested in Machine Learning or Deep Learning.",
        "Students with Prior Python Programming Exposure Who Want to Use it for Machine Learning",
        "Students interested in gaining exposure to the Keras library for Deep Learning.",
        "Data analysts who want to expand into Machine Learning.",
        "College students who want to start a career in Data Science."
      ]
    },
    {
      "title": "Data Science Hands On (PowerBI, SQL, Tableau, Spark, Python)",
      "url": "https://www.udemy.com/course/data-science-hands-on/",
      "bio": "Delve Into Hands-On Data Science: Build 5 Unique Projects Using Python, SQL, Spark, PowerBI, & Tableau.",
      "objectives": [
        "Master PowerBI & Tableau to build interactive dashboards that effectively communicate data-driven insights.",
        "Develop a solid understanding of SQL, the bedrock of data manipulation and querying, enabling you to analyze complex datasets with ease.",
        "Dive into Apache Spark's distributed computing system to process and analyze large-scale data, and construct efficient data pipelines.",
        "Get hands-on with Python, learning to load, clean, analyze, & visualize data using Jupyter Notebooks, a tool cherished by data science professionals worldwide.",
        "Apply your skills to real-world projects, reinforcing your understanding and preparing you to tackle data science challenges in your career or future studies."
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Using This Course"
        ],
        "PowerBI Fundamentals": [
          "Introduction and PowerBI Overview",
          "PowerBI Setup",
          "Connecting to Your Data",
          "Transforming Data",
          "Creating a Data Model",
          "Building Reports",
          "Advanced Filtering of Reports",
          "Building a Dashboard",
          "Formatting Your Dashboard"
        ],
        "Sales Dashboard in Tableau": [
          "Tableau Setup",
          "Visual Exploration",
          "Building a Dashboard",
          "Sharing on Tableau Public"
        ],
        "Analyzing Employee Data with SQL": [
          "Intro and Setup",
          "Employee Data Structure",
          "Analyzing Employee Data"
        ],
        "Services Analysis with Spark": [
          "Spark Setup on Databricks",
          "Working with Data in Spark",
          "Aggregating data in Spark",
          "Visualizing Data in Spark"
        ],
        "Sales Analysis in Python": [
          "Python Setup in Jupyter Notebooks",
          "Working in Pandas",
          "Presenting Analysis in Notebooks"
        ],
        "Insights from Data Leaders": [
          "Skills that Set Data Pros Apart",
          "What Programming Language is Best",
          "Apache Spark Deep Dive",
          "OpenCV Deep Dive - Giving Computers Vision"
        ],
        "Outro": [
          "Outro"
        ]
      },
      "requirements": [
        "Basic understanding of data structures",
        "Familiarity with programming languages",
        "Knowledge of Data Visualizations"
      ],
      "description": "Unlock your potential with the power of data. Welcome to Data Science Hands On, your one-stop-shop to master the world of Data Science. Dive deep into the core concepts and tools that will empower you to interpret, analyze, and leverage data in a meaningful way.\nOur expert-led, comprehensive online course caters to both beginners and experienced professionals, covering the most sought-after skills in the data industry - SQL, Spark, Tableau, PowerBI, and Python.\n\n\nPowerBI: Learn how to create interactive and visually appealing dashboards using PowerBI. You will explore data visualization techniques, build compelling reports, and leverage advanced features to effectively communicate data-driven insights.\nTableau: Dive into the world of Tableau and master the art of data visualization. Discover how to transform raw data into compelling visual representations, build interactive dashboards, and utilize Tableau's extensive set of tools to analyze and present data in an intuitive manner.\nSQL: Develop a strong foundation in SQL (Structured Query Language), the standard language for managing and querying relational databases. Learn how to retrieve, manipulate, and analyze data efficiently using SQL commands, and gain valuable skills for data extraction and data manipulation tasks.\nPython: Explore the versatile programming language, Python, which is widely used in data science. From data manipulation and cleaning to statistical analysis and machine learning, you will learn how to leverage Python's extensive libraries and frameworks to work with data effectively.\nSpark: Discover Apache Spark, a powerful open-source distributed computing system designed for big data processing. You will understand the fundamental concepts of Spark, explore its ecosystem, and learn how to leverage its capabilities to process large-scale data, perform advanced analytics, and build scalable data pipelines.\nThis course goes beyond the theoretical, focusing on practical, hands-on exercises and real-world applications of these tools. By the end of this course, you will have a comprehensive understanding of the entire data science process, and you'll be ready to apply your new skills to start solving real-world problems.\nWhether you're looking to advance your career, kickstart a new one, or simply eager to unravel the mysteries hidden within data, Data Science Hands On will guide you every step of the way. We provide lifetime access to all course materials, regular updates as technologies evolve, and a supportive online community to foster your learning journey.\nJoin the \"Data Science Hands On\" online course today, and start your journey towards becoming a Data Science expert. The world of data is at your fingertips!",
      "target_audience": [
        "Beginners Interested in Data Science",
        "Business Analysts and Managers",
        "Professionals Looking to Upskill",
        "Academics and Researchers",
        "Data Enthusiasts",
        "Entrepreneurs & Business Owners",
        "Students in STEM Fields",
        "Those who are considering a career change into data science",
        "Individuals from non-technical fields who deal with data regularly and want to learn how to analyze and interpret it more effectively."
      ]
    },
    {
      "title": "Mastering Power BI and Gen AI Integration for Analytics",
      "url": "https://www.udemy.com/course/mastering-power-bi-and-gen-ai-integration-for-analytics/",
      "bio": "Unlock powerful insights and drive data-driven decisions with Power BI and Generative AI integration.",
      "objectives": [
        "Integrate Gen AI with Power BI: Learn how to seamlessly integrate Generative AI tools with Power BI for enhanced analytics.",
        "Data Visualization Mastery: Develop skills to create compelling and insightful visualizations using Power BI.",
        "Automate Data Analysis: Understand how to automate data analysis and reporting using Power BI and AI techniques.",
        "Advanced Analytical Techniques: Explore advanced analytical methods and how to apply them in Power BI for deeper insights."
      ],
      "course_content": {
        "Getting Started with Power BI": [
          "Power BI Overview and Setup",
          "Installing Power BI Desktop",
          "Your First Visualization: Column Charts"
        ],
        "Building Basic Visualizations": [
          "Creating Stacked Bar Charts",
          "Pie and Donut Charts",
          "Funnel, Ribbon Charts, and Exporting Visuals"
        ],
        "Mapping Your Data": [
          "Introduction to Map Visualizations",
          "Advanced Map Customization",
          "Filled Maps and Maps with Data Labels"
        ],
        "Mastering Map Visualizations": [
          "Formatting Maps for Impact",
          "Background Maps and Advanced Features",
          "Real-World Example: COVID-19 Data Visualization"
        ],
        "Tables and Matrices for Detailed Insights": [
          "Creating and Formatting Tables",
          "Conditional Formatting and Matrix Basics",
          "Advanced Matrix Techniques and Number Formatting"
        ],
        "Key Performance Indicators (KPIs) with Cards": [
          "Number and Text Cards",
          "Date Cards and Multi-Row Cards",
          "Enhancing Cards with Filters and Formatting"
        ],
        "Advanced Card and Slicer Techniques": [
          "Best Practices for Effective Cards",
          "Using Text Slicers to Filter Data",
          "Formatting Text and Date Slicers"
        ],
        "Building Interactive Dashboards with Slicers": [
          "Advanced Date and Number Slicer Techniques",
          "Creating a Basic Sales Dashboard",
          "Building a Comprehensive Sales Summary Dashboard"
        ],
        "Designing Effective Dashboards": [
          "Enhancing Dashboards with Text Slicers",
          "Advanced Slicer Interactions",
          "Creating a Detailed Superstore Sales Dashboard"
        ],
        "Data Transformation with Power Query": [
          "Deep Dive into Sales Summary Dashboard",
          "Introduction to Data Transformation",
          "Navigating the Power Query Editor"
        ]
      },
      "requirements": [
        "Basic Knowledge of Power BI: Familiarity with the basics of Power BI, including data loading and basic visualization.",
        "Understanding of Data Analysis: A basic understanding of data analysis concepts and practices.",
        "Access to Power BI: Access to Power BI Desktop or Power BI service for hands-on practice.",
        "Interest in AI: A keen interest in learning how AI can enhance data analytics."
      ],
      "description": "Welcome to \"Mastering Power BI and Gen AI Integration for Analytics\"! This course is designed to take your data analytics skills to the next level by integrating the robust capabilities of Power BI with the cutting-edge potential of Generative AI. Whether you're a beginner looking to get started or a seasoned professional aiming to enhance your analytics toolkit, this course has something for everyone.\nIn this course, you will:\nMaster Power BI Fundamentals: Learn to navigate the Power BI interface, create compelling visualizations, and develop interactive dashboards that provide deep insights into your data.\nIntegrate Generative AI: Understand the principles of Generative AI and how it can be harnessed to enhance your data analytics, providing you with predictive insights and advanced data manipulation capabilities.\nReal-world Applications: Apply what you've learned through practical projects and real-world scenarios that mimic the challenges faced in today's data-driven world.\nOptimize Data Workflows: Learn to automate and streamline your data processing tasks, making your workflows more efficient and effective.\nAdvanced Analytics Techniques: Dive into advanced concepts such as machine learning integration, natural language processing, and automated report generation.\nBy the end of this course, you'll have the knowledge and skills to harness the full potential of Power BI and Generative AI, enabling you to make smarter, data-driven decisions and stand out in your field. Join us on this journey and transform your data analytics capabilities today!\nEnrol now and unlock the future of data analytics with Power BI and Generative AI!",
      "target_audience": [
        "Data Analysts: Analysts who want to leverage AI to enhance their data analysis capabilities.",
        "Business Intelligence Professionals: BI professionals looking to integrate advanced AI techniques into their workflows.",
        "Developers and IT Professionals: Developers interested in expanding their skills in data analytics and AI integration.",
        "Business Managers: Managers looking to gain deeper insights from their data through advanced analytics techniques."
      ]
    },
    {
      "title": "AI Machine Learning Complete Course: for PHP & Python Devs",
      "url": "https://www.udemy.com/course/ai-machine-learning-complete-course/",
      "bio": "Build real-world AI & machine learning apps using both PHP & Python. No prior ML knowledge required. Full Code Included.",
      "objectives": [
        "Build real-world AI applications right after the course",
        "Master AI & machine learning concepts and approaches",
        "Build AI applications using Google's TensorFlow, the most powerful Machine Learning framework",
        "Develop machine learning applications using PHP & Python",
        "Build Neural Network Applications for any Machine Learning purpose",
        "Build advanced Machine Learning models and know how to use them to solve any problem",
        "Learn how Neural Networks & Deep Neural Networks work",
        "Understand Deep Learning",
        "Understand how Google's TensorFlow works and how to use it",
        "Use TensorFlow Hub for faster and easier Machine Learning application development",
        "Understand the math behind Neural Networks",
        "Take their products and solutions to the next level with AI and Machine Learning"
      ],
      "course_content": {
        "Understanding AI & Machine Learning": [
          "What is Artificial Intelligence?",
          "Artificial Intelligence History",
          "What is Logic & Rule Based AI (a.k.a Symbolic Reasoning)",
          "What is Machine Learning?",
          "Machine Learning Example",
          "Important Links"
        ],
        "Machine Learning Types & Algorithms": [
          "Supervised Learning",
          "Semi-supervised Learning",
          "Unsupervised Learning",
          "Reinforcement Learning",
          "Machine Learning Algorithms Explained",
          "Neural Networks & Deep Neural Networks Algorithm Explained",
          "What Algorithm to Use? (Algorithm Cheat Sheet)",
          "Conclusion",
          "Important Links"
        ],
        "Coding Example: Dominant Color Detector (Neural Networks Algorithm)": [
          "Let's Code: Preparation",
          "Solution Planning",
          "Coding Lab: Training",
          "Coding Lab: Prediction",
          "Important Links"
        ],
        "Coding Example: Language Detection (Support Vector Machine Algorithm)": [
          "Solution Planning",
          "Coding Lab: Training",
          "Coding Lab: Prediction",
          "Conclusion",
          "Important Links"
        ],
        "Python & PHP": [
          "Introduction",
          "Python Syntax Explained (Python Crash Course)",
          "Important Links"
        ],
        "Coding Example: Simple Neural Network (Built from scratch without libraries!)": [
          "Problem Explained",
          "Solution Planning",
          "Coding Lab: Full Program",
          "Conclusion",
          "Assignment",
          "Assignment Article",
          "Important Links"
        ],
        "Important Neural Networks Concepts": [
          "Activation Functions",
          "Input Dimention",
          "Dense Layers & Dropout Layers",
          "Learning Rate",
          "Model Loss",
          "Epochs & Batch Size",
          "Training Data vs Validation Data vs Test Data",
          "Important Links"
        ],
        "Coding Example: Language Detection with Google's TensorFlow (Real-world example)": [
          "What is Google's TensorFlow?",
          "Solution Planning",
          "Data Extraction",
          "Coding Lab: Preparation",
          "Coding Lab: Variables & Utility Functions",
          "Coding Lab: Defining Alphabet for Neural Networks",
          "Code Lab: Data Cleaning",
          "Code Lab: Data Vectorization",
          "Coding Lab: Data StandardScaler Transformation",
          "Coding Lab: Creating a Deep Learning Neural Network with TensorFlow",
          "Coding Lab: Evaluation & Reporting",
          "Coding Lab: Prediction",
          "Important Links"
        ],
        "TensorFlow Hub": [
          "Machine Learning is Fun!",
          "What is TensorFlow Hub?",
          "Coding Lab: Text Feature Extraction & Text Similarity",
          "Coding Lab: Video Classification, and Action Recognition",
          "Important Links"
        ],
        "Bonus Section: Building a Neural Network using Plain Math": [
          "Introduction",
          "Forward Propagation",
          "Backward Propagation",
          "Important Links"
        ]
      },
      "requirements": [
        "Basic programming knowledge"
      ],
      "description": "Become an AI & Machine Learning developer, one of employer's most requested skills for 2018/2019!\nAdd value to your solutions and products, it is time to start using AI & Machine Learning now!\n\nThis course is different than any other AI or Machine Learning course; it requires no prior knowledge in AI or Machine Learning before, and you will be able to have your own AI Machine Learning application up and running right after the course.\nThis course is straight-forward, practical, and gives you all what you need to start your career in Machine Learning and Data Science. If you are a developer, programmer, technical student, manager, team leader, and you have not explored AI and Machine Learning before, this course is the best, most exciting, and complete course for you.\nExamples of how you can build applications that identifies a string language, identify colors, identify human actions \"like jump, sleep, anger, sadness  etc.\" in a video, identify if a tweet or a Facebook post is positive or negative, that are all a few examples of what you can do in this course, all explained and you can do it all by yourself during the step by stop journey in this course.\nThis course will make all AI concepts, terminology, and approaches clear for you, so you understand how everything around you is going, and takes you in a series of a very interesting hands-on step by step examples on how to build amazing AI applications.\n\n\nPremium resources you get:\nExclusive membership to our growing invitation only \"EarlyBirdClub\" Slack community, where you can discuss and engage with course authors, your course colleagues, and a group of technology geeks, entrepreneurs and business owners.\nPower Point presentation used in the video, and you can freely edit it and use it.\nFull source code for all examples in the course including training data used for machine learning.\n\n\nThe following topics are covered:\nAI\nRule & Logic Based AI\nMachine Learning\nMachine Learning Types (Supervised, Unsupervised, Reinforced, etc.)\nMachine Learning Algorithms\nNeural Networks & Deep Neural Networks\nDeep Learning\nPHP Step by Step Examples\nPython Step by Step Examples\nLanguage Detection\nColor Detection\nHuman Actions Identification in Videos\nGeneral String Classification\nHandling numerical data, string data, image data, voice data, and video data.\nPHP-ML\nscikit-learn\nnumpy\nTensorFlow\nTensorFlow Hub\nNeural Networks Math Step by Step\nAnd Much More!\n\n\nYou will get lifetime access to over 60 lectures and many articles & resources.\nSo what are you waiting for? Learn AI & Machine Learning in a way that will advance your career and increase your knowledge, all in a fun and practical way!",
      "target_audience": [
        "Anyone interested in Machine Learning.",
        "Any developer or programmer with basic knowledge in PHP or Python",
        "Any students in college who want to start a career in Data Science.",
        "Managers who need to understand AI & machine learning",
        "Technical team leaders who want to use AI & machine learning in their projects",
        "Entrepreneurs that want to bring AI & machine learning to their solutions and products right away"
      ]
    },
    {
      "title": "Mastering GenAI: Fine-Tune & Adapt LLMs Effectively",
      "url": "https://www.udemy.com/course/fine-tuning-and-adapting-genai-models/",
      "bio": "Harness Advanced Techniques in AI: From Fine-Tuning to Ethical Deployment and Optimization",
      "objectives": [
        "Understand and describe the architecture of Generative AI models like GPT and BERT.",
        "Apply fine-tuning methods to adapt LLMs to specific tasks and industries.",
        "Evaluate and optimize LLM performance through advanced techniques",
        "Implement ethical guidelines and best practices in the deployment of GenAI models"
      ],
      "course_content": {
        "Introduction": [
          "What is Gen AI ?",
          "What are LLMs ?"
        ],
        "Understanding LLMs": [
          "Advantages and Disadvantages of Large Language Models",
          "Varieties of Large Language Models",
          "Prompt engineering",
          "Demo : Zero-Shot Classification"
        ],
        "Understanding Foundation Models": [
          "Understanding the Basics of Foundation Models",
          "Operational Mechanics of Foundation Models"
        ]
      },
      "requirements": [
        "Basic understanding of AI concepts and terminology; no advanced technical skills required.",
        "Familiarity with Python programming to follow along with coding demos and exercises."
      ],
      "description": "Explore the cutting-edge field of Generative AI with our course, 'Mastering GenAI: Fine-Tune & Adapt LLMs Effectively.' Designed for professionals and enthusiasts alike, this course offers a deep dive into the mechanisms of large language models such as GPT and BERT. You'll learn how to fine-tune these models to meet specific requirements, ensuring they perform optimally across various industries.\nThrough a mix of theoretical insights and practical exercises, participants will explore different fine-tuning techniques including supervised, unsupervised, and reinforcement learning methods. The course will also address the critical aspects of model optimization, such as hyperparameter tuning and avoiding overfitting, to enhance both efficiency and accuracy.\nA significant focus will be on the ethical deployment of these technologies. You'll learn to navigate the complexities of AI ethics, ensuring your AI solutions are fair and equitable. This course will prepare you to effectively adapt and deploy AI models, making you a valuable asset in any tech-driven industry.\nBy the end of this course, participants will not only understand the theoretical underpinnings of generative AI but also be proficient in implementing and optimizing these models in a practical, ethical, and efficient manner. Whether you’re looking to innovate within your organization, kickstart a career in AI, or academically explore AI technologies, this course will serve as a vital stepping stone to achieving those goals.",
      "target_audience": [
        "This course is ideal for AI enthusiasts, data scientists, and developers interested in extending their expertise into the realm of fine-tuning and adapting large language models",
        "Suitable for IT professionals looking to leverage GenAI for improving business processes and creating innovative solutions.",
        "Perfect for academic researchers and students in computer science who want practical experience with state-of-the-art AI technologies.",
        "Security architects and engineers who aim to understand the cybersecurity implications of deploying generative AI models in their operations."
      ]
    },
    {
      "title": "Master Data Analysis with Python - From Beginner to Pro",
      "url": "https://www.udemy.com/course/master-data-analysis-with-python-from-beginner-to-pro/",
      "bio": "Learn Python for data analysis from scratch build practical skills to land your first job in data science or analytics",
      "objectives": [
        "Python Fundamentals for Data Science",
        "Numerical Computing",
        "Data Manipulation & Analysis",
        "Clean, prepare, and transform messy datasets with ease",
        "Stunning Data Visualization",
        "Exploratory Data Analysis (EDA) Techniques"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Variables & Data Types",
          "List & Dictionary",
          "Loops & Conditionals",
          "Simple Python calculations and list Iteration",
          "Introduction to pandas and Data Frames",
          "Load and Explore a Simple Dataset (e.g., Titanic or Iris)",
          "Data Cleaning and Preparation",
          "Handling Missing Data (NaN) & Filtering Data using Conditions",
          "Sorting and Indexing and Creating new Columns",
          "Data Type Conversion & Cleaning Messy Dataset",
          "EDA and Data Distribution",
          "Grouping and Aggregating (groupby) & Value Counts and Unique Values",
          "Simple Narrative Using Markdown and Code",
          "Capstone Project",
          "Class Project 1",
          "Class Project 2"
        ]
      },
      "requirements": [
        "No experience required"
      ],
      "description": "Are you ready to transform raw data into powerful insights? Do you want to master the most sought-after skills in today's data-driven world? This comprehensive course is your complete roadmap to becoming a highly proficient data analyst using Python, even if you've never written a line of code before!\nWhat You'll Learn:\nThe fundamentals of Python programming with a focus on data tasks\nHow to use data manipulation and analysis\nWorking with numerical operations\nCreating stunning data visualizations\nData cleaning techniques for real-world messy datasets\nImporting, transforming, and exporting data\nApplying exploratory data analysis (EDA) to uncover insights\nBuilding end-to-end mini-projects to reinforce your learning\nWho is this course for?\nAbsolute Beginners: No prior programming or data analysis experience required. We start from scratch!\nWhy Choose This Course?\nHands-on Learning: Engaged of practical lectures, coding exercises, and real-world projects.\nClear & Concise Explanations: Complex concepts broken down into easily digestible lessons.\nBy the end of this course, you'll not only understand the core concepts of data analysis — you’ll have the confidence and skills to work with real-world datasets, solve practical problems, and pursue roles in data analytics or data science. Don't just look at data – understand it, interpret it, and master it! Enroll now and embark on your journey to becoming a Master Data Analyst with Python!",
      "target_audience": [
        "Anyone who wants to analyze and visualize data using Python"
      ]
    },
    {
      "title": "Full Stack Data Science with Python, Numpy and R Programming",
      "url": "https://www.udemy.com/course/full-stack-data-science-with-python-numpy-and-r-programming/",
      "bio": "Learn data science with R programming and Python. Use NumPy, Pandas to manipulate the data and produce outcomes | R",
      "objectives": [
        "Learn R programming without any programming or data science experience. R programming, full stack data science, full stack data science with python numpy and r",
        "If you are with a computer science or software development background you might feel more comfortable using Python for data science. R programming, full stack",
        "In this course you will learn R programming, Python and Numpy from the beginning. R programming, full stack data science, full stack data science with python",
        "Learn Fundamentals of Python for effectively using Data Science",
        "Fundamentals of Numpy Library and a little bit more. R programming, full stack data science, full stack data science with python numpy and r programming",
        "Data Manipulation with python, python data science, python machine learning, python pandas, data analysis, machine learning a-z",
        "Learn how to handle with big data, python machine learning, python data science, r programming and python",
        "Learn how to manipulate the data, data science, python machine learning, numpy python, numpy, python numpy,",
        "Learn how to produce meaningful outcomes, r programming, data science, r python, python r, python and r programming, data science, python r",
        "Learn Fundamentals of Python for effectively using Data Science",
        "Learn Fundamentals of Python for effectively using Numpy Library",
        "Numpy arrays with python",
        "Numpy functions",
        "Linear Algebra",
        "Combining Dataframes, Data Munging and how to deal with Missing Data",
        "How to use Matplotlib library and start to journey in Data Visualization",
        "Also, why you should learn Python and Pandas Library",
        "Learn Data Science with Python",
        "Examine and manage data structures",
        "Handle wide variety of data science challenges",
        "Create, subset, convert or change any element within a vector or data frame",
        "Most importantly you will learn the Mathematics beyond the Neural Network",
        "The most important aspect of Numpy arrays is that they are optimized for speed. We’re going to do a demo where I prove to you that using a Numpy.",
        "You will learn how to use the Python in Linear Algebra, and Neural Network concept, and use powerful machine learning algorithms",
        "Use the “tidyverse” package, which involves “dplyr”, and other necessary data analysis package",
        "OAK offers highly-rated data science courses that will help you learn how to visualize and respond to new data, as well as develop innovative new technologies",
        "Whether you’re interested in machine learning, data mining, or data analysis, Udemy has a course for you.",
        "Data science is everywhere. Better data science practices are allowing corporations to cut unnecessary costs, automate computing, and analyze markets.",
        "Data science is the key to getting ahead in a competitive global climate.",
        "Data science uses algorithms to understand raw data. The main difference between data science and traditional data analysis is its focus on prediction.",
        "Data Scientists use machine learning to discover hidden patterns in large amounts of raw data to shed light on real problems.",
        "Python is the most popular programming language for data science. It is a universal language that has a lot of libraries available.",
        "Data science requires lifelong learning, so you will never really finish learning.",
        "It is possible to learn data science on your own, as long as you stay focused and motivated. Luckily, there are a lot of online courses and boot camps available",
        "Some people believe that it is possible to become a data scientist without knowing how to code, but others disagree.",
        "A data scientist requires many skills. They need a strong understanding of statistical analysis and mathematics, which are essential pillars of data science.",
        "The demand for data scientists is growing. We do not just have data scientists; we have data engineers, data administrators, and analytics managers.",
        "The R programming language was created specifically for statistical programming. Many find it useful for data handling, cleaning, analysis, and representation.",
        "R is a popular programming language for data science, business intelligence, and financial analysis. Academic, scientific, and non-profit researchers use the R",
        "Whether R is hard to learn depends on your experience. After all, R is a programming language designed for mathematicians, statisticians, and business analysts",
        "What is Python? Python is a general-purpose, object-oriented, high-level programming language.",
        "Python vs. R: what is the Difference? Python and R are two of today's most popular programming tools.",
        "What does it mean that Python is object-oriented? Python is a multi-paradigm language, which means that it supports many programming approaches.",
        "What are the limitations of Python? Python is a widely used, general-purpose programming language, but it has some limitations.",
        "How is Python used? Python is a general programming language used widely across many industries and platforms.",
        "What jobs use Python? Python is a popular language that is used across many industries and in many programming disciplines.",
        "How do I learn Python on my own? Python has a simple syntax that makes it an excellent programming language for a beginner to learn.",
        "What is machine learning? Machine learning describes systems that make predictions using a model trained on real-world data."
      ],
      "course_content": {
        "Data Science: Python Setup": [
          "Installing Anaconda Distribution For MAC: R programming, Numpy, Full stack",
          "Installing Anaconda Distribution For Windows: Numpy Python",
          "Installing Python and PyCharm For MAC: Full stack data science",
          "Installing Python and PyCharm For Windows: R programming, Numpy python",
          "Installing Jupyter Notebook For MAC",
          "Installing Jupyter Notebook For Windows: Full Stack Data Science, R programming",
          "Project Files and Course Documents: R programming, Data science, Numpy",
          "FAQ regarding Data Science: R and Python",
          "FAQ regarding Python and R"
        ],
        "If there are variables there is Python 3": [
          "What is a variable: Numpy python, R Programming, Data Science",
          "Quiz"
        ],
        "Math is not so confusing with Python": [
          "Numbers and Math Operators with example: Python data science",
          "Quiz"
        ],
        "Strings in Python Programming": [
          "Strings and Operations",
          "Data type Conversion in Python",
          "Python: Exercise",
          "Quiz"
        ],
        "Conditionals in Python": [
          "Conditionals in Python Programming",
          "Bool() Function in Python",
          "Comparison and logical Operators in Python",
          "If Statements in Python",
          "Exercise: Calculator in Python",
          "Exercise: User Login in Python",
          "Quiz"
        ],
        "Loops in Python": [
          "Loops in Python",
          "While Loops in Python",
          "For Loops in Python",
          "Range Function in Python",
          "Control Statements in Python",
          "Exercise : Perfect Numbers in Python",
          "Exercise : User Login with Loops in Python",
          "Quiz"
        ],
        "Functions in Python Bootcamp": [
          "Functions in Python Programming for Python Numpy",
          "Create A New Function and Function Calls for Python Numpy",
          "Return Statement in Python",
          "Lambda Functions in Python",
          "Exercise 9: Finding Prime Number in Python",
          "Quiz"
        ],
        "Modules in Python 3": [
          "Logic of Using Modules in Python",
          "How It is Work in Python",
          "Create A New Module in Python",
          "Python Exercise: Number Game",
          "Quiz"
        ],
        "Lists in Python": [
          "Lists and List Operations in Python",
          "List Methods in Python",
          "List Comprehensions in Python",
          "Exercise: Fibonacci Numbers in Python",
          "Exercise: Merging Name and Surname in Python",
          "Quiz"
        ],
        "Tuples in Python": [
          "Tuples in Python",
          "Quiz"
        ]
      },
      "requirements": [
        "No prior python and r knowledge is required",
        "Free software and tools used during the course",
        "Basic computer knowledge",
        "Desire to learn data science",
        "Nothing else! It’s just you, your computer and your ambition to get started today",
        "Curiosity for r programming",
        "Desire to learn Python",
        "Desire to work on r and python",
        "Desire to learn machine learning a-z, numpy python, data analysis, python pandas, pandas"
      ],
      "description": "Hello Dear,\nWelcome to Full Stack Data Science with Python, Numpy, and R Programming course.\nR programming, r process automation, r programming language, python, machine learning python, python programming, python django, machine learning a-z\nLearn data science with R programming and Python. Use NumPy, Pandas to  manipulate the data and produce outcomes | R\n\nOAK Academy offers highly-rated data science courses that will help you learn how to visualize and respond to new data, as well as develop innovative new technologies. Whether you’re interested in machine learning, data mining, or data analysis, Udemy has a course for you.\nIt’s hard to imagine our lives without machine learning. Predictive texting, email filtering, and virtual personal assistants like Amazon’s Alexa and the iPhone’s Siri, are all technologies that function based on machine learning algorithms and mathematical models.\nData science is everywhere. Better data science practices are allowing corporations to cut unnecessary costs, automate computing, and analyze markets. Essentially, data science is the key to getting ahead in a competitive global climate.\nPython instructors on OAK Academy specialize in everything from software development to data analysis and are known for their effective, friendly instruction for students of all levels.\nWhether you work in machine learning or finance or are pursuing a career in web development or data science, Python is one of the most important skills you can learn. Python's simple syntax is especially suited for desktop, web, and business applications. Python's design philosophy emphasizes readability and usability. Python was developed upon the premise that there should be only one way (and preferably one obvious way) to do things, a philosophy that has resulted in a strict level of code standardization. The core programming language is quite small and the standard library is also large. In fact, Python's large library is one of its greatest benefits, providing a variety of different tools for programmers suited for many different tasks.\nMachine learning and data analysis are big businesses. The former shows up in new interactive and predictive smartphone technologies, while the latter is changing the way businesses reach customers. Learning R from a top-rated Oak Academy instructor will give you a leg up in either industry. R is the programming language of choice for statistical computing. Machine learning, data visualization, and data analysis projects increasingly rely on R for its built-in functionality and tools. And despite its steep learning curve, R pays to know.\nDo you want to learn Python from scratch?\nDo you think the transition from other popular programming languages like Java or C++ to Python for data science?\nDo you want to be able to make data analysis without any programming or data science experience?\n\nWhy not see for yourself what you prefer?\nIt may be hard to know whether to use Python or R for data analysis, both are great options. One language isn’t better than the other—it all depends on your use case and the questions you’re trying to answer.\n\nIn this course, we offer R Programming, Python, and Numpy!  So you will decide which one you will learn.\nThroughout the course's first part, you will learn the most important tools in R that will allow you to do data science. By using the tools, you will be easily handling big data, manipulate it, and produce meaningful outcomes.\nIn the second part, we will teach you how to use Python to analyze data, create beautiful visualizations, and use powerful machine learning algorithms and we will also do a variety of exercises to reinforce what we have learned in this course.\n\nIn this course, you will also learn Numpy which is one of the most useful scientific libraries in Python programming.\nThroughout the course, we will teach you how to use the Python in Linear Algebra, and Neural Network concept, and use powerful machine learning algorithms and we will also do a variety of exercises to reinforce what we have learned in this Full Stack Data Science with Python, Numpy and R Programming course.\nAt the end of the course, you will be able to select columns, filter rows, arrange the order, create new variables, group by and summarize your data simultaneously.\nIn this course you will learn;\nHow to use Anaconda and Jupyter notebook,\nFundamentals of Python such as\nDatatypes in Python,\nLots of datatype operators, methods and how to use them,\nConditional concept, if statements\nThe logic of Loops and control statements\nFunctions and how to use them\nHow to use modules and create your own modules\nData science and Data literacy concepts\nFundamentals of Numpy for Data manipulation such as\nNumpy arrays and their features\nNumpy functions\nNumexpr module\nHow to do indexing and slicing on Arrays\nLinear Algebra\nUsing NumPy in Neural Network\nHow to do indexing and slicing on Arrays\nLots of stuff about Pandas for data manipulation such as\nPandas series and their features\nDataframes and their features\nHierarchical indexing concept and theory\nGroupby operations\nThe logic of Data Munging\nHow to deal effectively with missing data effectively\nCombining the Data Frames\nHow to work with Dataset files\nAnd also you will learn fundamentals thing about Matplotlib library such as\nPyplot, Pylab and Matplotlb concepts\nWhat Figure, Subplot and Axes are\nHow to do figure and plot customization\nExamining and Managing Data Structures in R\nAtomic vectors\nLists\nArrays\nMatrices\nData frames\nTibbles\nFactors\nData Transformation in R\nTransform and manipulate a deal data\nTidyverse and more\nMachine learning,\nmachine learning python,\npython,\ndata science,\npython for data science and machine learning bootcamp,\nr,\nmachine learning a-z,\npython data science,\ndeep learning\nAnd we will do some exercises.  Finally, we will also have hands-on projects covering all of the Python subjects.\nWhat is machine learning?\nMachine learning describes systems that make predictions using a model trained on real-world data. For example, let's say we want to build a system that can identify if a cat is in a picture. We first assemble many pictures to train our machine learning model. During this training phase, we feed pictures into the model, along with information around whether they contain a cat. While training, the model learns patterns in the images that are the most closely associated with cats. This model can then use the patterns learned during training to predict whether the new images that it's fed contain a cat. In this particular example, we might use a neural network to learn these patterns, but machine learning can be much simpler than that. Even fitting a line to a set of observed data points, and using that line to make new predictions, counts as a machine learning model.\nWhat is machine learning used for?\nMachine learning is being applied to virtually every field today. That includes medical diagnoses, facial recognition, weather forecasts, image processing, and more. In any situation in which pattern recognition, prediction, and analysis are critical, machine learning can be of use. Machine learning is often a disruptive technology when applied to new industries and niches. Machine learning engineers can find new ways to apply machine learning technology to optimize and automate existing processes. With the right data, you can use machine learning technology to identify extremely complex patterns and yield highly accurate predictions.\nDoes machine learning require coding?\nIt's possible to use machine learning without coding, but building new systems generally requires code. For example, Amazon’s Rekognition service allows you to upload an image via a web browser, which then identifies objects in the image. This uses a pre-trained model, with no coding required. However, developing machine learning systems involves writing some Python code to train, tune, and deploy your models. It's hard to avoid writing code to pre-process the data feeding into your model. Most of the work done by a machine learning practitioner involves cleaning the data used to train the machine. They also perform “feature engineering” to find what data to use and how to prepare it for use in a machine learning model. Tools like AutoML and SageMaker automate the tuning of models. Often only a few lines of code can train a model and make predictions from it. An introductory understanding of Python will make you more effective in using machine learning systems.\nWhat is data science?\nWe have more data than ever before. But data alone cannot tell us much about the world around us. We need to interpret the information and discover hidden patterns. This is where data science comes in. Data science python uses algorithms to understand raw data. The main difference between data science and traditional data analysis is its focus on prediction. Python data science seeks to find patterns in data and use those patterns to predict future data. It draws on machine learning to process large amounts of data, discover patterns, and predict trends. Data science using python includes preparing, analyzing, and processing data. It draws from many scientific fields, and as a python for data science, it progresses by creating new algorithms to analyze data and validate current methods.\nWhat does a data scientist do?\nData Scientists use machine learning to discover hidden patterns in large amounts of raw data to shed light on real problems. This requires several steps. First, they must identify a suitable problem. Next, they determine what data are needed to solve such a situation and figure out how to get the data. Once they obtain the data, they need to clean the data. The data may not be formatted correctly, it might have additional unnecessary data, it might be missing entries, or some data might be incorrect. Data Scientists must, therefore, make sure the data is clean before they analyze the data. To analyze the data, they use machine learning techniques to build models. Once they create a model, they test, refine, and finally put it into production.\nWhat are the most popular coding languages for data science?\nPython for data science is the most popular programming language for data science. It is a universal language that has a lot of libraries available. It is also a good beginner language. R is also popular; however, it is more complex and designed for statistical analysis. It might be a good choice if you want to specialize in statistical analysis. You will want to know either Python or R and SQL. SQL is a query language designed for relational databases. Data scientists deal with large amounts of data, and they store a lot of that data in relational databases. Those are the three most-used programming languages. Other languages such as Java, C++, JavaScript, and Scala are also used, albeit less so. If you already have a background in those languages, you can explore the tools available in those languages. However, if you already know another programming language, you will likely be able to pick up.\nHow long does it take to become a data scientist?\nThis answer, of course, varies. The more time you devote to learning new skills, the faster you will learn. It will also depend on your starting place. If you already have a strong base in mathematics and statistics, you will have less to learn. If you have no background in statistics or advanced mathematics, you can still become a data scientist; it will just take a bit longer. Data science requires lifelong learning, so you will never really finish learning. A better question might be, \"How can I gauge whether I know enough to become a data scientist?\" Challenge yourself to complete data science projects using open data. The more you practice, the more you will learn, and the more confident you will become. Once you have several projects that you can point to as good examples of your skillset as a data scientist, you are ready to enter the field.\nHow can ı learn data science on my own?\nIt is possible to learn data science projects on your own, as long as you stay focused and motivated. Luckily, there are a lot of online courses and boot camps available. Start by determining what interests you about data science. If you gravitate to visualizations, begin learning about them. Starting with something that excites you will motivate you to take that first step. If you are not sure where you want to start, try starting with learning Python. It is an excellent introduction to programming languages and will be useful as a data scientist. Begin by working through tutorials or Udemy courses on the topic of your choice. Once you have developed a base in the skills that interest you, it can help to talk with someone in the field. Find out what skills employers are looking for and continue to learn those skills. When learning on your own, setting practical learning goals can keep you motivated.\nDoes data science require coding?\nThe jury is still out on this one. Some people believe that it is possible to become a data scientist without knowing how to code, but others disagree. A lot of algorithms have been developed and optimized in the field. You could argue that it is more important to understand how to use the algorithms than how to code them yourself. As the field grows, more platforms are available that automate much of the process. However, as it stands now, employers are primarily looking for people who can code, and you need basic programming skills. The data scientist role is continuing to evolve, so that might not be true in the future. The best advice would be to find the path that fits your skillset.\nWhat skills should a data scientist know?\nA data scientist requires many skills. They need a strong understanding of statistical analysis and mathematics, which are essential pillars of data science. A good understanding of these concepts will help you understand the basic premises of data science. Familiarity with machine learning is also important. Machine learning is a valuable tool to find patterns in large data sets. To manage large data sets, data scientists must be familiar with databases. Structured query language (SQL) is a must-have skill for data scientists. However, nonrelational databases (NoSQL) are growing in popularity, so a greater understanding of database structures is beneficial. The dominant programming language in Data Science is Python — although R is also popular. A basis in at least one of these languages is a good starting point. Finally, to communicate findings.\nIs data science a good career?\nThe demand for data scientists is growing. We do not just have data scientists; we have data engineers, data administrators, and analytics managers. The jobs also generally pay well. This might make you wonder if it would be a promising career for you. A better understanding of the type of work a data scientist does can help you understand if it might be the path for you. First and foremost, you must think analytically. Data science from scratch is about gaining a more in-depth understanding of info through data. Do you fact-check information and enjoy diving into the statistics? Although the actual work may be quite technical, the findings still need to be communicated. Can you explain complex findings to someone who does not have a technical background? Many data scientists work in cross-functional teams and must share their results with people with very different backgrounds.\n\nWhat is python?\nMachine learning python is a general-purpose, object-oriented, high-level programming language. Whether you work in artificial intelligence or finance or are pursuing a career in web development or data science, Python bootcamp is one of the most important skills you can learn. Python's simple syntax is especially suited for desktop, web, and business applications. Python's design philosophy emphasizes readability and usability. Python was developed on the premise that there should be only one way (and preferably, one obvious way) to do things, a philosophy that resulted in a strict level of code standardization. The core programming language is quite small and the standard library is also large. In fact, Python's large library is one of its greatest benefits, providing different tools for programmers suited for a variety of tasks.\nPython vs. R: What is the Difference?\nPython and R are two of today's most popular programming tools. When deciding between Python and R in data science , you need to think about your specific needs. On one hand, Python is relatively easy for beginners to learn, is applicable across many disciplines, has a strict syntax that will help you become a better coder, and is fast to process large datasets. On the other hand, R has over 10,000 packages for data manipulation, is capable of easily making publication-quality graphics, boasts superior capability for statistical modeling, and is more widely used in academia, healthcare, and finance.\nWhat does it mean that Python is object-oriented?\nPython is a multi-paradigm language, which means that it supports many data analysis programming approaches. Along with procedural and functional programming styles, Python also supports the object-oriented style of programming. In object-oriented programming, a developer completes a programming project by creating Python objects in code that represent objects in the actual world. These objects can contain both the data and functionality of the real-world object. To generate an object in Python you need a class. You can think of a class as a template. You create the template once, and then use the template to create as many objects as you need. Python classes have attributes to represent data and methods that add functionality. A class representing a car may have attributes like color, speed, and seats and methods like driving, steering, and stopping.\nWhat are the limitations of Python?\nPython is a widely used, general-purpose programming language, but it has some limitations. Because Python in machine learning is an interpreted, dynamically typed language, it is slow compared to a compiled, statically typed language like C. Therefore, Python is useful when speed is not that important. Python's dynamic type system also makes it use more memory than some other programming languages, so it is not suited to memory-intensive applications. The Python virtual engine that runs Python code runs single-threaded, making concurrency another limitation of the programming language. Though Python is popular for some types of game development, its higher memory and CPU usage limits its usage for high-quality 3D game development. That being said, computer hardware is getting better and better, and the speed and memory limitations of Python are getting less and less relevant.\nHow is Python used?\nPython is a general programming language used widely across many industries and platforms. One common use of Python is scripting, which means automating tasks in the background. Many of the scripts that ship with Linux operating systems are Python scripts. Python is also a popular language for machine learning, data analytics, data visualization, and data science because its simple syntax makes it easy to quickly build real applications. You can use Python to create desktop applications. Many developers use it to write Linux desktop applications, and it is also an excellent choice for web and game development. Python web frameworks like Flask and Django are a popular choice for developing web applications. Recently, Python is also being used as a language for mobile development via the Kivy third-party library.\nWhat jobs use Python?\nPython is a popular language that is used across many industries and in many programming disciplines. DevOps engineers use Python to script website and server deployments. Web developers use Python to build web applications, usually with one of Python's popular web frameworks like Flask or Django. Data scientists and data analysts use Python to build machine learning models, generate data visualizations, and analyze big data. Financial advisors and quants (quantitative analysts) use Python to predict the market and manage money. Data journalists use Python to sort through information and create stories. Machine learning engineers use Python to develop neural networks and artificial intelligent systems.\nHow do I learn Python on my own?\nPython has a simple syntax that makes it an excellent programming language for a beginner to learn. To learn Python on your own, you first must become familiar with the syntax. But you only need to know a little bit about Python syntax to get started writing real code; you will pick up the rest as you go. Depending on the purpose of using it, you can then find a good Python tutorial, book, or course that will teach you the programming language by building a complete application that fits your goals. If you want to develop games, then learn Python game development. If you're going to build web applications, you can find many courses that can teach you that, too. Udemy’s online courses are a great place to start if you want to learn Python on your own.\nWhat is R and why is it useful?\nThe R programming language was created specifically for statistical programming. Many find it useful for data handling, cleaning, analysis, and representation. R is also a popular language for data science projects. Much of the data used for data science can be messy and complex. The programming language has features and libraries available geared toward cleaning up unorganized data and making complex data structures easier to handle that can't be found in other languages. It also provides powerful data visualization tools to help data scientists find patterns in large sets of data and present the results in expressive reports. Machine learning is another area where the R language is useful. R gives developers an extensive selection of machine learning libraries that will help them find trends in data and predict future events.\nWhat careers use R?\nR is a popular programming language for data science, business intelligence, and financial analysis. Academic, scientific, and non-profit researchers use the R language to glean answers from data. R is also widely used in market research and advertising to analyze the results of marketing campaigns and user data. The language is used in quantitative analysis, where its data analysis capabilities give financial experts the tools they need to manage portfolios of stocks, bonds, and other assets. Data scientists use R in many industries to turn data into insights and predict future trends with its machine learning capabilities. Data analysts use R to extract data, analyze it, and turn it into reports that can help enterprises make better business decisions. Data visualization experts use R to turn data into visually appealing graphs and charts.\nIs R difficult to learn?\nWhether R is hard to learn depends on your experience. After all, R is a programming language designed for mathematicians, statisticians, and business analysts who may have no coding experience. For some beginning users, it is relatively simple to learn R. It can have a learning curve if you are a business analyst who is only familiar with graphical user interfaces since R is a text-based programming language. But compared to other programming languages, users usually find R easier to understand. R also may have an unfamiliar syntax for programmers who are used to other programming languages, but once they learn the syntax, the learning process becomes more straightforward. Beginners will also find that having some knowledge of mathematics, statistics, and probabilities makes learning R easier.\nWhy would you want to take this course?\nOur answer is simple: The quality of teaching.\nWhen you enroll, you will feel the OAK Academy's seasoned instructors' expertise.\nFresh Content\nIt’s no secret how technology is advancing at a rapid rate and it’s crucial to stay on top of the latest knowledge. With this course, you will always have a chance to follow the latest trends.\nVideo and Audio Production Quality\nAll our content are created/produced as high-quality video/audio to provide you the best learning experience.\nYou will be,\nSeeing clearly\nHearing clearly\nMoving through the course without distractions\n\n\nYou'll also get:\nLifetime Access to The Course\nFast & Friendly Support in the Q&A section\nUdemy Certificate of Completion Ready for Download\nDive in now!\nFull Stack Data Science with Python, Numpy and R Programming\nWe offer full support, answering any questions.\nSee you in the course!",
      "target_audience": [
        "Anyone interested in data sciences",
        "Anyone who plans a career in data scientist,",
        "Software developer whom want to learn python,",
        "Anyone eager to learn python and r with no coding background",
        "Statisticians, academic researchers, economists, analysts and business people",
        "Professionals working in analytics or related fields",
        "Anyone who is particularly interested in big data, machine learning and data intelligence",
        "Anyone eager to learn Python with no coding background",
        "Anyone who wants to learn Pandas",
        "Anyone who wants to learn Numpy",
        "Anyone who wants to work on real r and python projects",
        "Anyone who wants to learn data visualization projects.",
        "People who want to learn r programming, numpy, data science, r abd python, machine learning",
        "People who want to learn r programming, python, numpy, numpy python, full stack data science, data science"
      ]
    }
  ]
}