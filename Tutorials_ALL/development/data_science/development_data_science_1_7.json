{
  "courses": [
    {
      "title": "Domine LLMs com LangChain",
      "url": "https://www.udemy.com/course/domine-llms-com-langchain/",
      "bio": "Soluções modernas de IA Generativa e PLN! Crie projetos reais usando LLMs avançadas com o ChatGPT e Llama",
      "objectives": [
        "Compreender a teoria das LLMs e de conceitos fundamentais do LangChain e Hugging Face",
        "Integrar LLMs proprietárias (ChatGPT da OpenAI) e modelos código aberto como Llama da Meta e Phi da Microsoft",
        "Aprender sobre os componentes do LangChain, como chains, templates, módulos para RAG, agentes e tools",
        "Explorar RAG passo a passo para armazenamento e recuperação com vector stores, acessando documentos e páginas web",
        "Implementar agentes e tools para realizar pesquisas na internet e consultar informações atualizadas",
        "Implementar soluções em ambiente local, permitindo acessar modelos open source mesmo sem conexão à internet",
        "Construir uma aplicação que faz a sumarização automática de vídeos e que responda a perguntas sobre eles",
        "Desenvolver seu chatbot customizado completo com memória e criar uma interface amigável com o Streamlit",
        "Criar uma aplicação avançada de RAG para interagir com documentos e extrair informações relevantes utilizando chat"
      ],
      "course_content": {},
      "requirements": [
        "Lógica de programação",
        "Programação básica em Python"
      ],
      "description": "Neste curso, você se aprofundará no universo da IA Generativa com LLMs (Large Language Models), explorando o potencial da combinação entre LangChain e Python. Você implementará soluções proprietárias (ChatGPT) e modelos open source modernos, como Llama e Phi. Por meio de projetos práticos e reais, você desenvolverá aplicações inovadoras, incluindo um assistente virtual personalizado e um chatbot que interage com documentos e vídeos. Vamos explorar técnicas avançadas como RAG e agentes, além de utilizar ferramentas como Streamlit para criar interfaces intuitivas. Você aprenderá a utilizar essas tecnologias gratuitamente no Google Colab e também a executar os projetos em ambiente local.\nNa introdução, você será apresentado à teoria dos Grandes Modelos de Linguagem (LLMs) e seus conceitos fundamentais. Além disso, será explorado o ecossistema da Hugging Face, que oferece soluções modernas de Processamento de Linguagem Natural (PLN). Você aprenderá a implementar LLMs utilizando tanto o pipeline da Hugging Face quanto a biblioteca LangChain, compreendendo as vantagens de cada abordagem.\nNa segunda parte, será abordado o domínio da LangChain. Você aprenderá a acessar modelos de código aberto, como o Llama da Meta e o Phi da Microsoft, além de LLMs proprietárias, como o ChatGPT da OpenAI. Será explicado como realizar a quantização de modelos, com o objetivo de melhorar a performance e a escalabilidade. Também serão apresentados os principais componentes do LangChain, como chains, templates e tools, e como utilizá-los para desenvolver soluções robustas em PLN. Técnicas de engenharia de prompt serão abordadas para ajudar a obter resultados mais precisos. O conceito de RAG (Retrieval-Augmented Generation) será explorado, incluindo o processo de armazenamento e recuperação de informações. Você aprenderá a implementar bancos de dados vetoriais (vector stores) e entenderá a importância dos embeddings e como utilizá-los de forma eficaz. Também será mostrado como usar RAG para interagir com documentos em PDF e páginas da internet. Além disso, você terá a oportunidade de explorar a integração de agentes e ferramentas, como o uso de LLMs para realizar pesquisas na internet e consultar informações recentes. As soluções serão implementadas em ambiente local, o que permitirá acessar modelos open source mesmo sem conexão à internet.\nNa fase de desenvolvimento de projetos práticos, você aprenderá a criar um chatbot customizado com interface e memória para perguntas e respostas (Q&A). Também será ensinado como desenvolver aplicações interativas utilizando a ferramenta Streamlit, facilitando a criação de interfaces intuitivas. Um dos projetos envolverá o desenvolvimento de uma aplicação avançada que utiliza o RAG para interagir com múltiplos documentos e extrair informações relevantes através de uma interface de chat. Outro projeto consistirá em construir uma aplicação que realiza a sumarização automática de vídeos e responde a perguntas relacionadas, resultando em uma ferramenta poderosa para a compreensão automática e instantânea de vídeos.",
      "target_audience": [
        "Profissionais e entusiastas da área de inteligência artificial que desejam explorar o uso de LLMs",
        "Profissionais que desejam implementar LLMs em suas próprias aplicações",
        "Alunos que buscam adquirir mais conhecimento em PLN e aprender a como implementar soluções modernas",
        "Profissionais de outras áreas que desejam aprender como usar modelos de linguagem em aplicações reais",
        "Desenvolvedores que desejam expandir suas habilidades com IA generativa",
        "Pesquisadores que buscam explorar avanços em LLMs e suas aplicações práticas"
      ]
    },
    {
      "title": "Formação Completa Inteligência Artificial - 2025",
      "url": "https://www.udemy.com/course/inteligencia-artificial-e-machine-learning/",
      "bio": "Machine Learning, Deep Learning, LLMs, IA Generativa, Redes Neurais, NLP e Agentes, Tudo em um Único Curso!",
      "objectives": [
        "Utilize Grandes Modelos de Linguagem como GPT",
        "Crie Modelos de Analises Preditivas, Agrupamentos e Associadores com Machine Learning",
        "Aprenda Diversas Téncnicas de Detecção de Anomalias",
        "Crie Agentes de IA com RAGs e Langchain",
        "Implemente Projetos de IA Generativa capaz de Criar Imagens",
        "Resolva Problemas de Otimização com Algoritmos Genéticos",
        "Classifique Documentos com Processamento de Linguagem Natural",
        "Reconheça Caracteres com Redes Neurais Artificias e Deep Learning",
        "Crie Modelos capazes de Detectar Emoções",
        "Desenvolva Projetos de Redes Neurais Convolucionais (CNN) e Redes Neurais Recorretes (LSTM)"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Apresentação e Conteúdo do Curso",
          "Orientações Gerais",
          "Material para Download",
          "Ambiente Python para o Curso",
          "Tutorial de Google Colab",
          "Dica Extra para Google Colab"
        ],
        "Fundamentos de Machine Learning": [
          "Introdução",
          "Aplicações",
          "Definições Gerais",
          "Conceitos Fundamentais",
          "Introdução a Classificação",
          "Avaliação de Performance e Matriz de Confusão",
          "Avaliação de Performance para Regressão",
          "Codificação de Categorias",
          "Dimensionamento de Características",
          "Fundamentos de Agrupamentos",
          "Regras de Associação",
          "Fundamentos de Machine Learning",
          "Fundamentos de Machine Learning"
        ],
        "Estudo de Algoritmos de Machine Learning": [
          "Introdução a Correlação e Regressão Linear",
          "Condições para Regressão Linear",
          "Cálculos na Regressão Linear",
          "Lab: Regressão Linear em Python",
          "Lab: Regressão Linear com StatsModels",
          "Lab: Regressão Linear com StatsModels (Continuação)",
          "Naive Bayes",
          "Lab: Naive Bayes",
          "Lab: Naive Bayes (Continuação)",
          "Árvores de Decisão",
          "Opcional: Cálculos para Induzir uma Árvore de Decisão",
          "Lab: Implementando Árvores de Decisão",
          "Aprendizado Baseado em Grupos com Random Forest",
          "Lab: Random Forest",
          "Aprendizado Baseado em Instância",
          "KNN: Vizinho mais Próximo",
          "Lab: Implementando KNN",
          "KMeans",
          "Lab: Implementando Clusters Diversos",
          "Lab: Implementando Clusters Diversos (Continuação)",
          "Regras de Associação com Apriori",
          "Lab: Implementado Apriori"
        ],
        "Tópicos Avançados em Machine Learning": [
          "Engenharia e Seleção de Atributos",
          "Lab: Engenharia de Atributos",
          "Lab: Engenharia de Atributos (Continuação)",
          "PCA: Principal Component Analysis",
          "Lab: PCA",
          "Seleção de Atributos",
          "Lab: Seleção de Atributos",
          "Avaliando a Viabilidade de um Modelo",
          "Avaliando e Comparando a Performance de Modelos",
          "Custo de Modelos",
          "Técnicas Avançadas para Clusters",
          "Lab: Técnicas Avançadas para Clusters",
          "Lab: Técnicas Avançadas para Clusters (Continuação)",
          "Lab: Escolhendo o Melhor Agrupador",
          "Lab: Escolhendo o Melhor Agrupador (Continuação)",
          "Classificação Multi Label",
          "Métricas para Avaliação Multi Label",
          "Lab: Classificação Multi Label",
          "Dados Desbalanceados",
          "Lab: Dados Desbalanceados",
          "AutoML e Tunning de Modelos",
          "AutoML e Tunning de Modelos (Continuação)",
          "Lab: AutoML e Tunning",
          "Lab: AutoML e Tunning com H2O"
        ],
        "Redes Neurais, Deep Learning e Computer Vision": [
          "Introdução a Redes Neurais Artificiais",
          "Conhecendo o Perceptron",
          "Classificação com Perceptron",
          "Classificação com Perceptron (Continuação)",
          "Apresentação de Redes Neurais",
          "Deep Learning",
          "Compreendendo Hiper Parâmetros",
          "Lab: Implementando RNA",
          "Lab: RNA com Keras",
          "Lab: RNA com Keras (Continuação)",
          "Visão Computacional com CNN - Convolution",
          "Visão Computacional com CNN - Pooling",
          "Visão Computacional com CNN - Flattening",
          "Visão Computacional com CNN - Full Connected",
          "Dados Cifar10",
          "Lab: Convolution Neural Network (CNN)",
          "Lab: Convolution Neural Network (CNN) (Continuação)",
          "Lab: Convolution Neural Network (CNN) (Continuação II)",
          "Redes Neurais Recorrentes e LSTM (Long Short Term Memory)",
          "Conjunto de Dados Stock do Google",
          "Lab: Pré-processamento para LSTM",
          "Lab: Treinamento de LSTM",
          "Lab: Previsão e Comparação de Resultados de LSTM",
          "Introdução aos Autoencoders",
          "Sobre o Lab de Autoencoders",
          "Lab: Preprando o Autoencoder",
          "Lab: Criando o Modelo do Autoencoder",
          "Lab: Removendo o Ruído da Imagem",
          "Detecção de Objetos",
          "Lab: Detecção de Objetos com OpenCV",
          "Lab: Detecção de Objetos com OpenCV (Continuação)",
          "Redes Neurais, Deep Learning e Computer Vision"
        ],
        "Machine Learning Explicável": [
          "O que é Machine Learning Explicável (XAI)",
          "Por que um Modelo Precisa ser Explicado?",
          "Conceitos Fundamentais",
          "Exemplos de Modelos White-box e Black-box",
          "Lab: Preparando os Dados",
          "Lab: Lime e Eli5",
          "Lab: Shap e Interpret",
          "Machine Learning Explicável"
        ],
        "Processamento de Linguagem Natural (Natura Language Processing - NLP)": [
          "Introdução",
          "Aplicações",
          "Conceitos",
          "Lab: NLP na Prática",
          "Lab: NLP na Prática (Continuação)",
          "Lab: NLP na Prática (Continuação II)",
          "Word Embedding e Transformers",
          "Lab: Classificação com Keras",
          "Lab: Classificação com Keras (Continuação)",
          "Processamento de Linguagem Natural"
        ],
        "LLMs e Inteligência Artificial Generativa": [
          "LLMs: Grandes Modelos de Linguagem",
          "Hugging Face",
          "Lab: Geração de Texto com Modelos GPT",
          "Lab: Preenchimento de Máscara",
          "Lab: Resumo de Texto",
          "Modelos GPT com OpenAI",
          "Lab: GPT com Python",
          "Lab: Google Gemini",
          "Lab: DeepSeek",
          "DALL-E: Apresentação",
          "Lab: DALL-E",
          "Lab: Stable Diffusion",
          "Lab: Stable Diffusion (Continuação)",
          "Whisper: Apresentação",
          "Lab: Whisper"
        ],
        "Agentes de IA, RAGs e Langchain": [
          "Apresentação de Agentes de IA",
          "Tipos de Agentes de IA",
          "RAGs: Retrieval Augmented Generation",
          "Outros Conceitos de Agentes",
          "Lab: Agente com Pesquisa na Web",
          "Agente Especializado com RAG e Langchain",
          "Lab: Agente Especializado com RAG e Langchain",
          "Lab: Agente Especializado com RAG e Langchain (Continuação)",
          "Agentes de IA, RAGs e Langchain"
        ],
        "Deteção de Anomalias": [
          "Introdução a Detecção de Anomalias",
          "Técnicas Estatísticas",
          "Lab: Z-Score",
          "Lab: IQR",
          "Técnicas de Machine Learning",
          "Lab: Local Outlier Factor (LOF)",
          "Lab: Isolation Forest",
          "Técnicas de Deep Learning",
          "Lab: Autoencoders",
          "LSTM para Anomalias",
          "Lab: Treinando Modelo LSTM",
          "Lab: Buscando Anomalias com LSTM",
          "Lab: Previsão de Avaliação com LSTM",
          "Técnicas de Séries Temporais",
          "Lab: Médias Móveis",
          "Lab: Exponential Smoothing",
          "Lab: Seasonal and Trend Decomposition (STD)",
          "Lab: Arima"
        ]
      },
      "requirements": [
        "Conceitos Básicos de Estatística"
      ],
      "description": "Tudo em um único curso: Machine Learngs a LLMs, IA Generativas, Agentes, Deep Learning, Algortimos Genéticos e muito mais!\nA Inteligência Artificial esta mudando o mundo como conhecemos, e consequentemente criando oportunidades de negócio e milhares de oportunidades no mercado de trabalho! Não fique de fora, conheça o mais completo e abrangente curso em Inteligência Artificial, que alia teoria e prática, e que vai levar você a um outro nível de conhecimento, com capacidade de implementar programas para tornar computadores inteligentes.\nO curso é composto de:\nMais de 170 aulas!\nMais de 60 Implementação Práticas com Python com código fonte para baixar\nQuestões de fixação\nAtividades Práticas\nAlém do código fonte, slides do curso disponíveis para download\nInclui também um curso de Fundamentos de Python (Opcional)\nVeja o que você vai estudar:\n\nFundamentos de Machine Learning: Tipos e Aplicações, Avaliação de Performance, Clusters, Regras de Associação\nAlgoritmos de Machine Learning: Correlação e Regressão, Naive Bayes, Redes Bayesianas, Árvores de Decisão, Aprendizado Baseado em Grupos, Aprendizado Baseado em Instâncias, Vizinho Mais Próximo, K-means, Apriori\nTópicos Avançados em Machine Learning: Engenharia de Atributos, PCA, Seleção de Atributos, Técnicas Avançadas de Clusters, Classificação Multi Label, Datasets Desbalanceados, AutoML e Tunning de Modelos\nRedes Neurais, Deep Learning e Visão Computacional: Fundamentos de Redes Neurais, Perceptron,Deep Learning, Hiper Parâmetros, Redes Neurais Convolucionais (CNN), Redes Neurais Recorrentes (LSTM), Autoencoders\nMachine Learning Explicável: Conceitos, Modelos White-box, Modelos Black-box, Feature Importance, LIME, Eli5, Shap, Interpret\nProcessamento de Linguagem Natural (NLP) Corpus, Tokens, Annotations, Tokenization, Parts-of-Speech Tagging (POS), Lemmatizing (Lemma), Dependency Parsing.\nLLMs e Inteligência Artificial Generativa: LLM, Huggin Face, Open AI e GPT, Whisper e DALL-E\nAgente de IA e RAGS: Crie Agentes de IA com técnicas de RAG usando LangChain\nDetecção de Anomalias: Técnicas Estatísticas: z-score, IQR, Machine Learning isolation forest, lof, Deep Learning: autoencoders, lstm, Seasonal and Trend Decomposition (std), Time Series: arima, media móvel , exponencial smoothing\nAlgoritmos Genéticos: Evolução Biológica, Fundamentos de AG, Técnicas, Busca e Otimização, Fundamentos, Hill Climbing, BFS e DFS, Tabu Search, Simulated Annealing\nAlgoritmos de Busca e Otimização: Hill Climbing, BFS, DFS, Caminhos, Tabu Search e Simulated Annealing\nLógica Difusa: Conjuntos Difusos, Inferência, Variáveis Linguísticas\nAlgumas bibliotecas/linguagens usadas:\nPython, Keras, Pytorch, TensorFlow, Hugging Face, Langchain, Scipy, SkitLearn, OpenAI, Whisper, Pandas, Google Gemini, H2O\n\n\nBons estudos!\nFernando Amaral",
      "target_audience": [
        "Interessados em Aprender a Implementar Programas de Computador Inteligentes",
        "Ciêntistas de Dados",
        "Profissionais de Qualquer Área Interessados em Aprender Inteligência Artificial"
      ]
    },
    {
      "title": "Pythonで機械学習：scikit-learnで学ぶ識別入門",
      "url": "https://www.udemy.com/course/python-scikit-learn/",
      "bio": "pythonの機械学習ライブラリscikit-learnを使って，識別の基本を徹底的にマスターしよう！",
      "objectives": [
        "機械学習の識別（分類・パターン認識）が何かが分かります",
        "Pythonとjupyter notebookが使えるようになります．",
        "Pythonの機械学習ライブラリscikit-learnを使えるようになります",
        "学習データとテストデータを準備する",
        "データの前処理をする",
        "学習データで識別器を学習する",
        "交差確認（cross validation）やleave-one-outなどを使う",
        "識別器でテストデータを識別する",
        "識別結果を評価する",
        "過学習とは何かを知る",
        "2クラス分類と多クラス分類の違いを知る",
        "k最近傍識別器（k-NN）を使う",
        "サポートベクターマシン（SVM）を使う",
        "ロジスティック回帰を使う",
        "多層ニューラルネットワーク（多層パーセプトロン）を使う",
        "パーセプトロンを使う"
      ],
      "course_content": {
        "機械学習とは": [
          "はじめに",
          "識別とは",
          "識別の流れ",
          "ラベルについて",
          "回帰とは（ここでは扱わない）",
          "教師あり，教師なし，半教師あり",
          "ディープラーニング（深層学習）とは"
        ],
        "Jupyter notebookの設定（Pythonプログラミングの環境設定）": [
          "環境設定について",
          "anacondaの紹介",
          "macOS：ダウンロードとインストール",
          "macOS：起動と終了",
          "macOS：アップデート",
          "macOS：ターミナルでの操作",
          "windows：ダウンロードとインストール",
          "windows：起動と終了",
          "windows：アップデート",
          "windows：コマンドプロンプトでの操作",
          "linux：ダウンロードとインストール",
          "linux：起動と終了",
          "linux：アップデート",
          "linux：ダウングレード",
          "linux：GUIのAnaconda navigator",
          "linux：anacondaを使わずaptとpipでインストールするなら",
          "オプション：dockerを使うなら",
          "オプション：どうしてもクラウドというならSageMathCloud"
        ],
        "最初の例題：学習から識別まで": [
          "ipython notebookの簡単な使い方",
          "レクチャー用のnotebookのダウンロードはこちら（ソースコードはここにあります）",
          "参考ウェブサイト",
          "2次元のデータで識別の例 03_01",
          "癌のデータを識別：学習とテストを半々に 03_02",
          "アヤメのデータを識別：学習とテストを半々に，したらダメ 03_03",
          "アヤメのデータを識別２：学習とテストをランダムに半分に 03_03",
          "アヤメのデータを識別３：ランダムに分けて何度も 03_04"
        ],
        "学習データとテストデータの準備": [
          "学習データとテストデータの分け方概論",
          "学習データとテストデータが同じ場合 04_01",
          "Hold-out 04_02",
          "Hold-out 2: stratified 04_03",
          "cross validation, stratified 10-fold CV 04_04",
          "Leave One Out, Leave-p-out, Leave-one-gruop-out 04_05",
          "学習データ・検証データとテストデータ 04_06"
        ],
        "データから特徴量へ": [
          "データから特徴量へ",
          "欠損値の扱い・データクリーニング 05_01",
          "特徴抽出：テキストデータと特徴量 05_02",
          "特徴抽出：画像データと特徴量 05_02",
          "特徴選択 05_03",
          "特徴変換：PCA 05_04",
          "特徴変換：PCAと次元削減 05_04",
          "特徴変換：非線形（多項式）変換 05_04",
          "標準化 05_05",
          "スケーリング 05_05",
          "正規化 05_05",
          "PCA白色化 05_05",
          "ZCA白色化 05_05"
        ],
        "テストデータの評価方法": [
          "2クラス問題のconfusion matrix 06_01",
          "2クラス問題で重要なTP, TN, FP, FN 06_01",
          "多クラス問題のconfusion matrix 06_01",
          "PCAで文字認識 06_01",
          "precisionとrecall 06_02",
          "f-measure，f値 06_02",
          "precision, recall, f-measureをいっぺんに 06_02",
          "多クラス分類のprecisionとrecall 06_02",
          "ROC AUC 06_03",
          "ランダムならどうなるROC 06_03",
          "average precision, AP 06_03",
          "多クラス問題のmAP 06_03"
        ],
        "いろいろな識別器": [
          "2クラス識別と多クラス識別 07_01",
          "多クラス識別：One-vs-Rest （ロジスティック回帰) 07_01",
          "多クラス識別：One-vs-Rest (SVM) 07_01",
          "多クラス識別：One-vs-One (SVM) 07_01",
          "多クラス識別：ovrとovoの補足 07_01",
          "kNN：最近傍識別器 (NN)，k近傍識別器 (kNN) 07_02",
          "kNN：KNNの亜種：radius NN 07_02",
          "kNN：スケーリングしてKNN 07_02",
          "パーセプトロン 07_03",
          "パーセプトロン：平面・直線の数式",
          "パーセプトロン：学習則",
          "パーセプトロン：損失関数",
          "パーセプトロン：損失関数をインタラクティブに 07_03",
          "パーセプトロン：ランダムな動作 07_03",
          "パーセプトロン：癌データの認識 07_03",
          "パーセプトロン：まとめ 07_03",
          "ロジスティック回帰 07_04",
          "ロジスティック回帰：癌データの認識 07_04",
          "ロジスティック回帰：2次元データで確率の予測 07_04",
          "ロジスティック回帰：別の2次元データでも確率を 07_04",
          "SVM：サポートベクターマシン，SVC 07_05",
          "SVM：マージン，サポートベクトル，確率 07_05",
          "SVM：非線形カーネル（rbf, poly） 07_05",
          "SVM：癌データの認識 07_05",
          "MLP：多層パーセプトロン 07_06",
          "MLP：層を変えてみる 07_06",
          "MLP：癌データの認識 07_06",
          "ランダムフォレスト：2次元データの認識 07_07",
          "ランダムフォレスト：別の2次元データの認識と過学習 07_07",
          "ランダムフォレスト：癌データの認識 07_07"
        ],
        "パラメータ調整": [
          "注意：並列計算のn_jobsの指定",
          "注意：windowsでのグリッドサーチの表示",
          "グリッドサーチ：1パラメータのロジスティック回帰 08_01",
          "グリッドサーチ：2パラメータのSVM 08_01",
          "グリッドサーチ：3パラメータのSVM（linear, rbf） 08_01",
          "グリッドサーチ：kNN 08_01",
          "ランダムサーチ：多層パーセプトロン 08_01",
          "パイプライン：PCAとロジスティック回帰を一緒に 08_02",
          "パイプライン：スケーリングとSVMを一緒に 08_02",
          "パイプライン：前処理もグリッドサーチで 08_02",
          "正則化パラメータC 08_03",
          "正則化パラメータと過学習 08_03"
        ],
        "学習サンプル数が多いとき": [
          "linear SVM（lib linear） 09-01",
          "inear SVM（liblinear）：primalソルバ 09-01",
          "linear SVM（liblinear）：グリッドサーチ 09-01",
          "確率勾配法 (SGD) 09-02",
          "確率勾配法 (SGD)：数式の説明 09-02",
          "確率勾配法 (SGD)：グリッドサーチ 09-02",
          "確率勾配法 (SGD)：スモールデータの認識 09-02"
        ],
        "例題": [
          "20カテゴリのテキスト分類：１ 10_01",
          "20カテゴリのテキスト分類：２ 10_01",
          "20カテゴリのテキスト分類：３ 10_01",
          "20カテゴリのテキスト分類：４ 10_01"
        ]
      },
      "requirements": [
        "pythonプログラミングの初歩的な知識",
        "jupyter notebook のプログラミング環境が構築できるスキル"
      ],
      "description": "このコースでは，機械学習における識別（分類・認識）の基礎をPythonを用いて学びます．このコースの目標は，機械学習でデータを識別するための一連の流れ（データの準備・前処理・識別器・評価など）を理解することです．Pythonの機械学習ライブラリscikit-learnとインタラクティブなプログラミング環境jupyter notebook (ipython notebook)を使って，実際にpythonコードを実行しながら学びます．\nレクチャーでは，notebook上で実行するpythonコードとその内容を説明します．pythonコードのnotebookはダウンロードできますので，レクチャーを見ながら・見た後で実際に実行することをおすすめします．自分なりに改変・修正すると，さらに理解が高まるでしょう．\n機械学習を理解するためには数学が必要になるのですが，このレクチャーでは（ほとんど）数式を使わず，コードを実行して結果を議論することで，機械学習のコンセプトを伝えるようにしています．理論的なことを知りたい場合には，他の資料を参考にしてください．\nプログラミングの注意：pythonやその他の言語でのプログラミング経験があることを前提にしていますので，python自体の説明は省略しています．\n\n\nレクチャーで使用しているnotebookはダウンロードできます．「レクチャー用のnotebookのダウンロードはこちら（ソースコードはここにあります）」というレクチャーを参照してください．",
      "target_audience": [
        "機械学習という言葉は知っているが，中身を知らない人",
        "プログラミングが嫌いではない人（Pythonプログラミングをします）",
        "Pythonプログラミング環境を用意できる人",
        "具体的に機械学習を適用したいデータがある人"
      ]
    },
    {
      "title": "Kickstart Your Career in Artificial Intelligence",
      "url": "https://www.udemy.com/course/kickstart-your-career-in-artificial-intelligence/",
      "bio": "A Beginner’s Guide to AI Concepts, Tools & Career Paths",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "No prior knowledge of artificial intelligence or coding is needed — this course is designed for complete beginners.",
        "A computer, tablet, or smartphone with internet access to follow along and practice using AI tools.",
        "An open mind and willingness to learn about new technologies and their applications."
      ],
      "description": "AI isn’t just the future — it’s happening right now.\nWhether you're a student, job-seeker, creative, or professional, learning how to use Artificial Intelligence can give you a serious edge. The best part? You don’t need any coding experience to start.\nThis beginner-friendly course is designed to make AI simple, practical, and useful — even if you’ve never touched a line of code or used an AI tool before.\nIn this hands-on course, you’ll not only understand what AI is — you’ll actually use it. You’ll explore powerful (and free!) tools like ChatGPT, Canva AI, DALL·E, and Zapier to write, create, and automate like never before.\nWhat You’ll Learn:\nWhat Artificial Intelligence really is — and how it’s used in everyday life\nThe difference between AI, Machine Learning, and Deep Learning\nHow to generate content and ideas using tools like ChatGPT\nHow to create stunning images using AI-powered design tools\nHow to automate boring tasks using Zapier — no tech background needed\nCareer paths in AI (technical and non-technical) and how to prepare for them\nEthics, best practices, and how to think like a responsible AI user\nWho This Course Is For:\nBeginners with zero experience in AI or coding\nStudents or job switchers curious about the future of work\nProfessionals looking to boost their career with in-demand skills\nCreatives, marketers, and entrepreneurs wanting to explore AI tools\nWhat You’ll Need:\nA computer with internet access\nCuriosity to learn and explore\n(Optional) A free ChatGPT account and other AI tool sign-ups — we’ll walk you through it!\nBy the end of this course, you won’t just know about AI — you’ll have practiced using it, and you'll leave with a clear next-step plan to build your future in this exciting field.",
      "target_audience": [
        "Anyone curious about Artificial Intelligence and how it’s shaping our world.",
        "Beginners who want to understand AI concepts without any technical or coding background.",
        "Students, professionals, or career changers looking to explore job opportunities in the AI field.",
        "Business owners, managers, or creatives who want to use AI tools to boost productivity and creativity."
      ]
    },
    {
      "title": "Applied Computer Vision: Object Detection and Recognition",
      "url": "https://www.udemy.com/course/applied-computer-vision/",
      "bio": "Object Recognition From Basics to Advanced Techniques",
      "objectives": [],
      "course_content": {
        "Introduction: Fundamental Concepts in Image Recognition": [
          "Course Introduction",
          "Fundamental Concepts in Image Recognition",
          "Environment setup",
          "Summary"
        ],
        "Recap of CNNs": [
          "Convolution in 1D",
          "Convolution in 2D",
          "Pooling and subsampling",
          "Activation functions",
          "Activation Functions",
          "Building a basic CNN",
          "Back-propagation",
          "Dropout",
          "Notebooks description (part 1): PyTorch Tutorials",
          "Notebooks description (part 2): FiftyOne Tutorials"
        ],
        "Image Classification": [
          "Introduction to Image Classification",
          "Multiclass vs multi-label classification",
          "Build an Image Classifier",
          "ResNet Family of Models",
          "ResNet architecture",
          "Torchvision Models",
          "Performance Metrics for Image Classification",
          "Classification Performance",
          "Notebooks Description"
        ],
        "Object Detection": [
          "Introduction to Object Detection",
          "Object Detection Models",
          "Two-stage Object Detectors: R-CNN part-1",
          "Two-stage Object Detectors: R-CNN part-2",
          "Two-stage Object Detectors: R-CNN part-3",
          "Two-stage Object Detectors: R-CNN part-4",
          "One-stage Object Detectors: YOLO – part 1",
          "One-stage Object Detectors: YOLO – part 2",
          "One-stage Object Detectors: YOLO – part 3",
          "Object Detection Post-processing: Non-Maximum Suppression",
          "Non-maximum Suppression",
          "Object Detection Performance Metrics",
          "Notebooks Description"
        ],
        "Semantic Segmentation": [
          "Introduction to Semantic Segmentation",
          "Semantic Segmentation Models",
          "Segmentation Models",
          "Semantic Segmentation in PyTorch",
          "Loss Functions for Semantic Segmentation",
          "Performance Metrics for Semantic Segmentation",
          "Notebook Descriptions"
        ],
        "Instance and Panoptic Segmentation": [
          "Introduction to Instance & Panoptic Segmentation",
          "Segmentation Tasks",
          "Instance Segmentation Models",
          "Instance Segmentation with Mask R-CNN in PyTorch",
          "Instance Segmentation with YOLO (Ultralytics)",
          "Notebooks Description"
        ]
      },
      "requirements": [
        "Python Programming Experience: Familiarity with programming, particularly in Python, as it's the primary language used with PyTorch. Students should be comfortable with basic programming concepts and structures.",
        "Understanding of Basic Machine Learning Concepts: A foundational knowledge of machine learning principles, including what models are, how they are trained, and a basic understanding of concepts like classification, regression, overfitting, and underfitting.",
        "Introductory Knowledge of Deep Learning: Familiarity with the basic concepts of neural networks, including what they are and how they are generally structured and trained."
      ],
      "description": "Computer Vision and Object Recognition\nThis course provides a comprehensive journey into computer vision and object recognition, guiding you from the foundational concepts to advanced model implementation and evaluation. Through a hands-on approach, you will explore key computer vision tasks such as image classification, object detection, semantic segmentation, and instance segmentation. The course uses popular datasets like COCO-2017 and CamVid, and frameworks such as PyTorch and FiftyOne to enhance your practical skills.\nSection 1: Introduction We begin with an overview of the course and object recognition, followed by setting up the necessary environment for efficient implementation.\nSection 2: Recap of Convolutional Neural Networks (CNNs) This section refreshes your knowledge of CNNs and introduces essential tools like FiftyOne for dataset management, along with tutorials to get familiar with PyTorch.\nSection 3: Image Classification You will learn to build and train a multi-class image classifier using the COCO-2017 dataset, focusing on classes like cats, dogs, and horses. The classifier is built using a pre-trained ResNet model, demonstrating the process of transfer learning and hyperparameter tuning.\nSection 4: Object Detection We delve into object detection using two popular models, Faster-RCNN and YOLOv8. You'll prepare datasets, train both models, and analyze their performance using FiftyOne, gaining hands-on experience with both region-based and single-shot detection methods.\nSection 5: Semantic Segmentation In this section, you will work with the CamVid dataset to understand semantic segmentation, which involves assigning a class to every pixel in an image. Using the segmentation_models_pytorchlibrary, you will train and evaluate a segmentation model to recognize objects in scenes.\nSection 6: Instance Segmentation We cover instance segmentation, where the goal is to differentiate between multiple instances of the same object class. You'll build and train a Mask-RCNN model for this task, working with segmentation annotations from the COCO-2017 dataset.\nThroughout the course, we place a strong emphasis on hands-on exercises, real-world datasets, and model evaluation to equip you with the skills needed to tackle practical computer vision challenges. By the end, you will be well-prepared to implement and evaluate various computer vision models, with a solid understanding of the nuances involved in different tasks like classification, detection, and segmentation.",
      "target_audience": [
        "Students and Learners in Computer Science: Undergraduate or graduate students who are majoring in computer science, data science, artificial intelligence, or related fields and want to gain practical skills in image recognition using PyTorch.",
        "Aspiring Data Scientists and Machine Learning Engineers: Individuals looking to enter the field of data science or machine learning with a specific interest in image processing and recognition techniques.",
        "AI and Machine Learning Enthusiasts: Individuals who have a keen interest in artificial intelligence and machine learning and want to deepen their understanding of image recognition.",
        "Tech Entrepreneurs: Entrepreneurs or innovators looking to understand image recognition to implement or improve product offerings, particularly in tech-driven markets."
      ]
    },
    {
      "title": "Python pour le Deep Learning & le Machine Learning: A à Z",
      "url": "https://www.udemy.com/course/machine-learning-et-deep-learning-avec-python-la-formation-complete/",
      "bio": "Cours complet sur le Machine Learning pour maîtriser l'intelligence artificielle, Tensorflow, et les réseaux de neurones",
      "objectives": [
        "Apprenez à utiliser différents frameworks en Python pour résoudre des problèmes du monde réel à l'aide du Deep Learning et de l'intelligence artificielle",
        "Apprenez les bases de la théorie du Machine Learning et du Deep Learning",
        "Construire des réseaux de neurones artificiels avec Tensorflow et Keras",
        "Apprenez à utiliser le Machine Learning et le Deep Learning en Python",
        "Faire des prédictions à l'aide de la régression linéaire, de la régression polynomiale et de la régression multivariée"
      ],
      "course_content": {
        "Introduction à l’apprentissage automatique": [
          "Qu’est-ce que le Machine Learning ?",
          "Applications du Machine Learning",
          "Méthodes de Machine Learning",
          "Qu’est-ce que l’apprentissage supervisé ?",
          "Qu’est-ce que l’apprentissage non supervisé ?",
          "Apprentissage supervisé vs apprentissage non supervisé",
          "Supports de Cours (Machine Learning)"
        ],
        "Implémentation d’algorithmes ML en Python": [
          "Introduction",
          "Bibliothèques Python pour le Machine Learning",
          "Configuration de Python",
          "Qu’est-ce que Jupyter ?",
          "Installation d’Anaconda Windows Mac et Ubuntu",
          "Implémentation de Python dans Jupyter",
          "Gestion des répertoires dans Jupyter Notebook"
        ],
        "Régression linéaire simple": [
          "Introduction à la régression",
          "Comment fonctionne la régression linéaire ?",
          "Représentation de ligne",
          "Implémentation en python : Importation de bibliothèques et de jeux de données",
          "Implémentation en python : Distribution des données",
          "Implémentation en python : Créer un objet de régression linéaire"
        ],
        "Régression linéaire multiple": [
          "Comprendre la régression linéaire multiple",
          "Implémentation en python : exploration du jeu de données",
          "Implémentation en python : codage de données catégorielles",
          "Implémentation en python : fractionnement des données en ensembles de formation",
          "Implémentation en python : Formation du modèle sur l’ensemble d’entrainement",
          "Implémentation en python : prédiction des résultats de l’ensemble de tests",
          "Évaluation des performances du modèle de régression",
          "Erreur quadratique moyenne racine en Python"
        ],
        "Algorithmes de classification : K-Plus proches voisins": [
          "Introduction à la classification",
          "Algorithme K-Plus proches voisins (KNN)",
          "Exemple de KNN",
          "K-Nearest Neighbours (KNN) en utilisant python",
          "Implémentation en python : importation des bibliothèques requises",
          "Implémentation en python : importation du jeu de données",
          "Implémentation en python : fractionnement des données en ensembles de formation",
          "Implémentation en python : mise à l’échelle des fonctionnalités",
          "Implémentation en python : Importation du classificateur KNN",
          "Implémentation en python : Prédiction des résultats & Matrice de confusion"
        ],
        "Algorithmes de classification : Arbre de décision": [
          "Introduction aux arbres de décision",
          "Qu’est-ce que l’entropie ?",
          "Exploration de l’ensemble de données",
          "Arborescence des décisions",
          "Implémentation en python : Importation de bibliothèques et de jeux de données",
          "Implémentation en python : codage de données catégorielles",
          "Implémentation en python : fractionnement des données en ensembles de formation",
          "Implémentation en python: prédiction et précision des résultats"
        ],
        "Algorithmes de classification : régression logistique": [
          "Introduction",
          "Étapes de mise en œuvre",
          "Implémentation en python : Importation de bibliothèques et de jeux de données",
          "Implémentation en python : fractionnement des données en ensembles de formation",
          "Implémentation en python : Pre-processing",
          "Implémentation en python : Formation du modèle",
          "Implémentation en python : Prédiction des résultats & Matrice de confusion",
          "Régression logistique vs Régression linéaire"
        ],
        "Clustering": [
          "Introduction au clustering",
          "Cas d’utilisation",
          "Algorithme de clustering K-Means",
          "Méthode du coude",
          "Étapes de la méthode du coude",
          "Implémentation en python",
          "Regroupement hiérarchique",
          "Clustering basé sur la densité",
          "Implémentation du clustering k-means en python",
          "Importation du jeu de données",
          "Visualisation du jeu de données",
          "Définition du classificateur",
          "Visualisation 3D des clusters",
          "Visualisation 3D des valeurs prédites",
          "Nombre de clusters prédits"
        ],
        "Système de recommandation": [
          "Introduction",
          "Filtrage collaboratif dans les systèmes de recommandation",
          "Système de recommandation basé sur le contenu",
          "Implémentation en python : Importation de bibliothèques et de jeux de données",
          "Fusion de jeux de données en une seule trame de données",
          "Tri par titre et notation",
          "Histogramme indiquant le nombre d’évaluations",
          "Distribution des fréquences",
          "Graphique combiné des notations et nombre de notations",
          "Prétraitement des données",
          "Tri des films les mieux notés",
          "Obtenez les notes pour deux films",
          "Corrélation entre les films les mieux notés",
          "Tri des données par corrélation",
          "Filtrage des films",
          "Tri des valeurs",
          "Répéter le processus pour un autre film"
        ],
        "Conclusion (Machine Learning)": [
          "Conclusion"
        ]
      },
      "requirements": [
        "Compétences mathématiques de base",
        "Disponibilité, flexibilité et passion pour l'apprentissage",
        "Expérience avec les bases de la programmation en Python"
      ],
      "description": "Python est reconnu comme l'un des meilleurs langages de programmation pour sa flexibilité. Il fonctionne dans presque tous les domaines, du développement Web au développement d'applications financières. Cependant, ce n'est un secret pour personne que la meilleure application de Python est dans les tâches d'apprentissage automatique, d'apprentissage en profondeur et d'intelligence artificielle.\nBien que Python facilite l'utilisation du Machine Learning et du Deep Learning, il sera toujours assez frustrant pour quelqu'un qui n'a aucune connaissance du fonctionnement de l'apprentissage automatique.\nSi vous connaissez les bases de Python et que vous avez envie d'apprendre le Deep Learning, ce cours est fait pour vous. Ce cours vous aidera à apprendre à créer des programmes qui acceptent la saisie de données et automatisent l'extraction de fonctionnalités, simplifiant ainsi les tâches du monde réel pour les humains.\nIl existe des centaines de ressources d'apprentissage automatique disponibles sur Internet. Cependant, vous risquez d'apprendre des leçons inutiles si vous ne filtrez pas ce que vous apprenez. Lors de la création de ce cours, nous avons tout filtré pour isoler les bases essentielles dont vous aurez besoin dans votre parcours d'apprentissage en profondeur.\nC'est un cours de base qui convient aussi bien aux débutants qu'aux experts. Si vous êtes à la recherche d'un cours qui commence par les bases et passe aux sujets avancés, c'est le meilleur cours pour vous.\nIl enseigne uniquement ce dont vous avez besoin pour vous lancer dans l'apprentissage automatique et l'apprentissage en profondeur sans fioritures. Bien que cela aide à garder le cours assez concis, il s'agit de tout ce dont vous avez besoin pour commencer avec le sujet.",
      "target_audience": [
        "Programmeurs qui cherchent à ajouter le Machine Learning et le Deep Learning à leurs compétences",
        "Mathématiciens professionnels désireux d'apprendre à analyser des données par programmation",
        "Tout passionné de programmation Python souhaitant ajouter des compétences en Deep Learning à son portefeuille"
      ]
    },
    {
      "title": "Gemini AI Course for Beginners",
      "url": "https://www.udemy.com/course/gemini-ai-course-for-beginners/",
      "bio": "Learn the basics of Google's new Gemini AI model in under 1 hour!",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Course Introduction",
          "Course Resources & Highlights",
          "Join our Online Community (Discord)"
        ],
        "Gemini AI for Beginners": [
          "1. Exploring Google AI Studio - Basics",
          "2. Google AI Advanced Features 1",
          "3. Google AI Advanced Features 2",
          "4. API Key",
          "5. Gemini Integration with Google Colab"
        ],
        "Appendix: Python Basics": [
          "Quick Note: Upcoming Python Lectures",
          "Configure Our Dev Environment and Create our first Program",
          "Basics of Variables",
          "Basic Datatypes in Python",
          "Basic Arithmetic in Python",
          "Indexing and Slicing Strings"
        ],
        "Bonus": [
          "Bonus Lecture"
        ]
      },
      "requirements": [
        "No programming experience needed. You will learn everything you need to know",
        "All you need is a computer with internet access and a passion for learning AI",
        "Basic familiarity with Python is helpful but not required (Python Basics is covered in the Appendix section)"
      ],
      "description": "Welcome to Gemini AI Course for Beginners with Python\nAre you curious about the power of generative AI and eager to explore one of Google’s most innovative models?\nDo you want to understand how advanced AI technologies like Gemini work and how you can apply them using Python?\nHave you ever wondered what terms like Gemini, Generative AI, and LLMs mean?\nAre you curious about how these cutting-edge technologies can be harnessed for real-world applications?\nIf you answered yes to any of these questions, you’re in the right place. This course is perfect for you. In just one hour, you'll gain a solid understanding of these concepts and learn how to leverage Gemini to its fullest potential.\nUnlock the potential of Google's Gemini AI model in just one hour with our comprehensive beginner-friendly course! Designed for enthusiasts at all levels, this course will guide you through the fascinating world of Gemini, Generative AI, and Large Language Models (LLMs) using Google AI Studio and Python.\nWhat Makes This Course Stand Out?\nShort and Beginner-Friendly Content: Start with the fundamentals and quickly progress to advanced topics—no prior programming experience is required.\nLearn by Doing: Gain practical experience with Google AI Studio and Python through real-world projects.\nHands-On Project: Build a Blog Post AI Agent that demonstrates the real-life applications of Gemini AI.\nIn-Depth Explanations: Understand the inner workings of generative AI and Large Language Models (LLMs) with clear, step-by-step instructions.\nCareer-Ready Skills: Equip yourself with the cutting-edge AI skills needed to tackle coding interviews and boost your programming confidence.\nWhy This Course Is Essential\nIn today’s fast-evolving tech landscape, AI isn’t just a buzzword—it’s the future of innovation. Mastering Google’s Gemini AI model means gaining the ability to harness the power of generative AI, opening up new possibilities in application development and problem-solving. This course bridges theory with practical implementation, ensuring that by the end, you’re not only familiar with AI concepts but also able to apply them confidently in real projects.\nTopics covered in the Gemini AI Course for Beginners Course:\nThe Basics of Google AI Studio:\nGet acquainted with the intuitive interface of Google AI Studio.\nLearn how to navigate and utilize its powerful features to streamline your AI projects.\nAdvanced Concepts of Google AI Features:\nDive deeper into the sophisticated capabilities of Google AI.\nExplore the advanced tools and functionalities that set Gemini apart from other AI models.\nGoogle AI Studio API Key Setup:\nUnderstand the importance of API keys and how to set them up.\nEnsure seamless integration and access to Google AI Studio’s extensive resources.\nSmall Project - Blog Post AI Agent:\nApply your newfound knowledge in a hands-on project.\nCreate an AI agent capable of generating engaging blog posts, showcasing the practical applications of Gemini.\nWhether you're a seasoned professional looking to expand your AI toolkit or a beginner eager to explore the world of Artificial Intelligence, this course offers valuable insights and practical skills. Join us and embark on a journey to master Google’s Gemini AI model with Python.\nWhy Wait?\nTake the leap into the future of AI. Enroll now for free and start mastering Google’s Gemini AI with Python. Transform your programming skills and unlock new career opportunities today!\nAbout the Instructor:\nGurkeerat Singh is a Senior Software Engineer with over 5 years of comprehensive experience in full-stack development. He excels in a diverse array of technologies, including JavaScript, Node.js, Angular, React, React Native, MEAN, MERN, Java, Spring Boot, Kotlin, Native Android App Development, and Git.\nGurkeerat’s passion for innovation and problem-solving has led him to participate in numerous developer hackathons, where he has consistently performed at a high level. Notably, he secured 1st place in the prestigious Bengaluru Open Mobility Challenge '23, demonstrating his ability to apply his skills to real-world challenges.\nIn addition to his professional achievements, Gurkeerat is dedicated to sharing his knowledge and expertise with others. At Job Ready Programmer, he plays a pivotal role in teaching and mentoring students in the latest technologies, including Gemini AI. His commitment to education ensures that his students are well-prepared to stay ahead of the curve in the rapidly evolving tech industry.",
      "target_audience": [
        "Anyone who wants to learn Google's Gemini AI Model",
        "Beginner Python Developers curious about Gemini AI model",
        "AI Beginners who want to gain hands-on experience with AI tools and techniques",
        "Content Creators and Bloggers aiming to leverage AI for generating high-quality blog posts and content"
      ]
    },
    {
      "title": "【徹底的に解説！】機械学習の本質を習得するための講座（Pythonで3つのアルゴリズムをゼロから実装します）",
      "url": "https://www.udemy.com/course/machine-learning-3algo/",
      "bio": "単回帰分析・ロジスティック回帰分析・ニューラルネットワークの学習を通じ、機械学習の考え方を学びましょう。最後は手書きの数字を認識する（画像認識の）アルゴリズムをpythonで実装します。AI・機械学習エンジニアになりたい方にお勧めです。",
      "objectives": [
        "機械学習を学ぶ上で大切となる【機械学習の考え方】を身につけることができます。",
        "手書きの数字を推測するアルゴリズムをPythonを使って一から実装することができるようになります。",
        "3つのアルゴリズムを関連付けながら学習をすることで、機械学習の基本的な考え方が理解できるようになります。",
        "Pythonを使って、一からアルゴリズムを実装することができるようになります。",
        "機械学習で使うデータの特徴や性質を、統計学の知識をもとに学ぶことができます。",
        "尤度の考え方を用いたアルゴリズムの実装方法について学ぶことができます。",
        "微分と機械学習との関係について理解することができます。",
        "確率・統計の基本的な知識を身につけることができるようになります。"
      ],
      "course_content": {
        "はじめに": [
          "ごあいさつ",
          "（忙しい方向け）講義の進め方",
          "はじめに（この講義ではお伝えしないこと）",
          "講座を受講することで達成できること",
          "この講義はこのような方にお勧めです（講義のメインの対象者）",
          "講義の全体像",
          "この講義で学べることの端的なイメージ",
          "効率的な講義の進め方",
          "anacondaのインストール",
          "コーヒーブレイク1：機械学習のおすすめ本"
        ],
        "機械学習とは": [
          "機械学習とは",
          "機械学習の定義　その1",
          "「学習」のイメージ",
          "機械学習の定義　その2",
          "機械学習の罠と進め方",
          "機械学習の全体の進め方のイメージ",
          "人工知能と機械学習の違い"
        ],
        "単回帰分析": [
          "はじめに",
          "回帰の語源と単回帰分析への適用のイメージ",
          "単回帰分析における機械学習・学習のイメージ",
          "分析の流れ",
          "インプットデータの特徴と、データの見方",
          "アウトプットデータの特徴",
          "どう分析していくかを考える",
          "最小二乗法の定義",
          "最小二乗法のイメージと、妥当性の検証",
          "残差の具体的な計算",
          "誤差関数と最小値の求め方",
          "最急降下法の定義と具体的な計算",
          "尤度を使った分析の概要、誤差が正規分布に従うとは？",
          "尤度関数の求め方",
          "対数と極値",
          "外れ値の扱い",
          "正規化とは",
          "正規化したデータを元に戻す方法",
          "実装①　前提条件の確認",
          "実装②　誤差関数と導関数",
          "実装③　最急降下法",
          "実装④　繰り返しで導関数を完成させる",
          "実装⑤　インプットデータの取り込み",
          "実装⑥　トレーニング回数の設定",
          "実装⑦　入力データのあてはめ、モデルの完成",
          "実装⑧　モデルの検証",
          "実装⑨　グラフの描画による検証",
          "ソースコード",
          "演習１　データの正規化をしてみよう",
          "回答１　インプットデータの正規化",
          "回答２　実装への反映とコードの検証・修正",
          "回答３　正規化した直線を元に戻す",
          "（参考）入力データの正規化を一般的な書き方で表現する"
        ],
        "ロジスティック回帰分析": [
          "はじめに",
          "問題提起と前提条件・目的の整理",
          "オッズと発症率",
          "オッズ比",
          "詳細分析とその限界",
          "どうやってモデルを構築するか",
          "モデルの構築（リスクの相乗モデル）",
          "モデルの構築（シグモイド関数の導出）",
          "対数を取ることの是非",
          "シグモイド関数を用いた具体的な確率の計算",
          "シグモイド関数を今回の問題にあてはめる",
          "（参考）メールのスパム判定とロジスティック回帰分析",
          "どう分析していくかを考える",
          "ロジスティック回帰分析における尤度関数",
          "生起確率の復習と尤度関数の具体的な計算",
          "対数尤度関数の導関数の導出",
          "尤度関数の形と単調増加関数のメリット",
          "実装①　前提条件の確認",
          "実装②　導関数と最急降下法",
          "実装③　シグモイド関数",
          "実装④　インプットデータの取り込み",
          "実装⑤　トレーニング回数、初期重みの設定とコードの調整",
          "実装⑦　グラフの描画による検証",
          "ソースコード",
          "演習２尤度をグラフに表示してみよう",
          "回答１　尤度関数とグラフの実装",
          "回答２　αを変化させることによるグラフの変化の考察"
        ],
        "ニューラルネットワーク　その1": [
          "はじめに",
          "問題提起",
          "ロジスティック回帰分析の限界",
          "ニューラルネットワークとロジスティック回帰分析の関係",
          "具体的な数字を使ったニューラルネットワークの計算",
          "活性化関数について",
          "モデルの構築",
          "誤差関数の考え方",
          "バックプロパゲーション（誤差逆伝搬法）",
          "（参考）一般的な重みの数え方",
          "実装①　前提条件の確認",
          "実装②　フォワードプロパゲーション（各関数の実装）",
          "実装③　誤差の変化率と最急降下法",
          "実装④　インプットデータの取り込み",
          "実装⑤　コードの調整",
          "実装⑥　初期重み・繰り返し回数の設定",
          "実装⑦　コードの実行と検証",
          "実装⑧　モデル修正の考え方",
          "ソースコード",
          "演習３　活性化関数を変更してみよう",
          "回答１　tanhの導関数",
          "回答２　コードの実装",
          "回答３　コードの検証"
        ],
        "ニューラルネットワーク　その2": [
          "はじめに",
          "全体の流れと「その１」との違い",
          "行列の基礎（積と転置）",
          "フォワードプロパゲーションの流れ",
          "バックプロパゲーションの流れ",
          "実装①　流れの確認",
          "実装②　インプットデータとノードの設定",
          "実装③　シグモイド関数と重みの設定",
          "実装④　フォワードプロパゲーション",
          "実装⑤　バックプロパゲーション",
          "実装⑥　検証用のコードの作成",
          "実装その他１　画像の取り込み",
          "実装その他２　画像のデータ化",
          "実装⑦　検証データの設定",
          "実装⑧　検証データの精度の確認",
          "ソースコード"
        ],
        "微分": [
          "微分とは",
          "解析的・直感的とは",
          "解析的・直感的と機械学習の関係",
          "微分の定義",
          "右微分係数と左微分係数",
          "合成関数の定義",
          "微分の連鎖律（合成微分律）",
          "上に凸、下に凸（二回微分）",
          "偏微分（直感的）",
          "偏微分（解析的）"
        ],
        "統計・確率": [
          "統計学の定義",
          "統計学と機械学習の関係",
          "統計学で学ぶ内容",
          "データの定義",
          "データの分類",
          "データの次元",
          "データを整理する方法（度数分布表）",
          "データを整理する方法（ヒストグラム）",
          "平均値、中央値、最頻値",
          "データの集合を評価する（平均、偏差、分散、標準偏差）",
          "標準偏差が重要な理由",
          "偏差値とは",
          "推測統計の概要",
          "確率の定義と公理主義的定義",
          "公理主義的定義のメリット",
          "確率の用語の定義（集合、積集合、和集合）",
          "順列と組み合わせ",
          "確率変数",
          "確率分布",
          "データの分布について、二項分布",
          "二項分布のグラフ",
          "ポアソン分布",
          "ポアソン分布の証明",
          "正規分布",
          "大数の法則",
          "中心極限定理",
          "大数の法則と中心極限定理のまとめ",
          "標本から母集団を予想するとは",
          "標本から母集団を予想する方法",
          "標本の数が増えた場合",
          "推測統計のまとめ",
          "尤度とは",
          "尤度の具体的な計算（二項分布）",
          "尤度の具体的な計算（正規分布）"
        ]
      },
      "requirements": [
        "機械学習に関する前知識は一切必要ありません。",
        "Pythonの基本的な文法を理解していると良いかと思います。"
      ],
      "description": "「機械学習はやっぱり難しい。。」\n\n\n最近、こんな声をよく聞きます。\n\n\n本やインターネットで調べてみても、書かれているのは見たことも無いような数式ばかり。\n\n\nどこを見ても難しい解説ばかりで、本やサイトを閉じてしまった方も少なくないのではないでしょうか？\n\n\nたしかに、機械学習は数時間で身につけることができるようなものではありません。\n\n\nただ、教える側が分かるように教えていない。\nということも、機械学習を苦手に感じてしまう人が多い原因の一つではないかと考えています。\n\n\n例えば、弁護士が専門用語を使って依頼者に説明したところで、依頼者は何を言われているのか分からないですよね。\n機械学習もそれと同じです。\n\n\nこれから機械学習を学ぶ方からすると、必要な知識・用語について何も分からないのは当たり前。\nだからこそ、教える側は専門的な言葉を使ってはいけない（または、しっかりと一つ一つの言葉について説明をしなければいけない）のです。\n\n\n機械学習はこれからも伸びていくことが予想される分野です。そして、何よりも機械学習のアルゴリズムを実装できると達成感を感じることができますし、何よりも楽しいです。\n\n\nただ、面白いだけでも意味がありません。\nですので、この講義は順番に学習を進めていく中で【機械学習の考え方がしっかりと身につく】ように意識をしてカリキュラムを組んでいます。\n\n\nこれから機械学習エンジニアとして活躍したい方も、機械学習に何となく興味がある方も、是非この講義を聞いて学びを深めて頂ければと思います。\n\n\n\n\n--この講座の5つの特徴--\n\n\n1. 難しい数式は極力使いません。\n機械学習のテキストなどを見ると、見たこともないような数式が沢山出てくると思いますが、そういった数式を使わなくとも学習することは可能です。\nむしろ、難しい数式を使うことで、大切な基礎が見えなくなってしまうと考えています。\nですので、この講義では極力難しい数式は使わず、シンプルに説明することを心掛けています。\n必要に応じて難しい数式を使う場面もありますが、その場合はしっかりと基礎から説明しておりますのでご安心下さい。\n（難しいと感じた場合はQ&Aなどでご連絡頂ければ幸いです。）\n\n\n2. 定義だけを読むといった講義は行いません。\nこの講義では、可能な限り一つ一つの用語に対して具体的な例を用いて説明することを心掛けています。\nなぜなら、言葉の説明だけを聞いても理解することは難しいのが普通だからです。\n例えば、「確率とは、偶然起こる現象の現象全てに対する割合」と説明されても全く頭に入らないですよね。\nそうではなく、サイコロの例を使って説明すれば理解が深まることはイメージできるのではないかと思います。\n（偶然起こる現象をサイコロで１の目が出る確率、現象全てを１～６の目が出る確率、とすればイメージが湧きやすいですよね。）\n他方、説明をお聴きになる中で少し冗長に思われることもあるかもしれませんので、そういった場合は、適宜講義をスキップして頂きながら、学びを深めて頂ければと思います。\n\n\n3. 機械学習に関する複数の学習分野を、関連付けて説明しています。\n機械学習を理解することを難しくしている理由の一つとして、「複数の学習分野にまたがっている」ことが挙げられます。\n例えば、統計学と機械学習は何がどう関連しているか、イメージできるでしょうか？\n機械学習の基本的な考え方として、統計学における「推測統計」が使われているのですが、そういった繋がりを知ることで、機械学習に対する理解をぐっと深めることができるようになります。\n個別の分野を有機的につなげることによって、加速度的に機械学習への理解を深めて頂ければと思います。\n\n\n4. pythonを使った実装では、ライブラリは使いません。\nこの講義では、機械学習のライブラリを使わず、pythonを使って一から実装を進めていきます。\nライブラリを使えば簡単に実装をすることができますが、それでは機械学習の本質的な部分は全く分からず、出てきた結果の妥当性の検証をすることもできません。\n逆に、一から実装することができるようになれば、ライブラリは簡単に使いこなせるようになります。\n一つ一つのアルゴリズムを理解していても、実装するとなると別問題。実際に実装することで、多くの学びを得ることができます。\nですので、この講義ではライブラリを使わず、一から実装を進めていきます。\n\n\n5. 具体的な成果物が作れるようになります。\n最後は手書きの数字を認識するアルゴリズムを作ります。実際に動くアルゴリズムを一から作ることで、機械学習の知識が深まったことを実感できるようになります。\nまた、自分で書いた数字を機械が認識していることを確認することで、機械学習を少し身近に感じることができるようになると思います。\n是非とも最後まで講義を聞き、成果物を作ることで達成感を感じて頂ければと思います。\n\n\n（この講義でお伝えしないこと）\nこの講義では、最先端の機械学習アルゴリズムや、行列を使った数式の表現は含まれておりません。\n機械学習の基本的な考え方を身につけるうえで、上記のような情報はかえって理解の妨げになると考えているからです。\nですので、上記の内容を学びたいかたはこの講義は最適ではない可能性があること、お含みおき頂きたく、よろしくお願い致します。\n\n\n--この講義の対象者--\n\n\nこの講義は、機械学習について興味がある方であればどんな方でも対象になりますが、その中でも「機械学習の基礎をしっかりと身につけたい」という方に是非聞いて頂きたいと考えています。\n最後に具体的な成果物を作成しますが、それでも講義の中心となるのは「機械学習の考え方」を身につけることです。ですので、どうしても説明が長くなってしまい、少し退屈してしまうことがあるかもしれません。\nそれでも、講義を終えた際には、「今まで何となく流し読みしていたサイトや本の内容が頭に入ってくる」感覚を持っていただけるのではないかと思います。\nどれだけ難しい言葉を使って説明がされていたとしても、基礎をしっかりと身につけていけば理解することができるからです。\n\n\nこれから機械学習エンジニアとして成長していく上で、基礎や基本的な考え方を身につけるのは早いに越したことはありません。\nこの講義を活用し、機械学習に対する理解をどんどん深めて頂ければ幸いです。",
      "target_audience": [
        "機械学習についてこれから学習したいと考えている方",
        "機械学習について少し勉強したことがあるが、何となく理解できている感じがしない方",
        "Pythonの基本的な文法を学び終え、機械学習分野で一から実装をしたいと考えている方",
        "ライブラリに頼らずに機械学習の実装をしたい方",
        "機械学習の基本的な考え方をしっかりと理解したい方",
        "機械学習の基礎的な知識をまとめて（統計学や微分などを）身につけたい方",
        "アルゴリズムの改善を自分でできるようになりたい方"
      ]
    },
    {
      "title": "Microsoft Azure AI Fundamentals: Get started with AI",
      "url": "https://www.udemy.com/course/microsoft-azure-ai-fundamentals-get-started-with-ai/",
      "bio": "Learn the fundamentals of Azure AI, and get certified AI-900 with Practice Exam included",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Nothing just Patience and Eager to Learn !"
      ],
      "description": "Microsoft Azure is one of the three most popular cloud computing platforms. Exam AI-900: Microsoft Azure AI Fundamentals is the best certification to get started with Azure. Learn Cloud Computing with Azure.\nWe have designed this amazing course to help you learn the Compute, Storage, Database, and Networking solutions in Azure.\n\n\nMicrosoft Azure is a cloud-based platform for testing, deploying, building and managing applications and services through Microsoft managed the data-center. Azure’s cloud adoption framework provides the customers with a set of tools, guidance, and narratives that help them to shape the technology and business in a way they need to accelerate the business outcome.\n\n\nMicrosoft Azure introduces your cloud environment to tools like threat intelligence, advanced threat analytics, Azure information protection and multi-factor authorization. It helps you to take charge of your customer data by collecting, using and distributing them on your own. With the help of data centers spread all over the world, Azure provides high availability along with redundancy. And on the top of everything, Microsoft Azure is cost effective as well.\n\n\nBenefits Of Azure Certification:\nYou will get to learn the basics of Microsoft Azure\nYou will be well versed about virtual networking skills and its implementation through Microsoft Azure\nYour career will accelerate in no time\nThis certification will be key for you to uncover an entire world of networking which is yet unexplored\nFor someone early in their tech career, the Azure Fundamentals certification can be part of what lifts them from a less technical role into a more technical role, into a more technical role. But without industry experience, the Azure Fundamentals certification isn't necessarily enough to ensure a job.\n\n\nAfter the completion of your certification, you’ll gain have a lot of perks like:\nCareer flexibility\nBetter security offerings\nBetter integration with .Net platform\nHigher salary\nImproved DevOps skills\n\n\nAzure Fundamentals exam is an opportunity to prove knowledge of cloud concepts, Azure services, Azure workloads, security and privacy in Azure, as well as Azure pricing and support. Candidates should be familiar with the general technology concepts, including concepts of networking, storage, compute, application support, and application development.",
      "target_audience": [
        "DevOps Engineers",
        "DevSecOps Engineers",
        "Developers",
        "Cloud Engineers",
        "System Administrator",
        "IT Engineers"
      ]
    },
    {
      "title": "A Quick Introduction to Algorithms",
      "url": "https://www.udemy.com/course/a-quick-introduction-to-algorithms/",
      "bio": "Algorithms, Data Structures",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction to Algorithms"
        ],
        "Sorting Algorithms": [
          "Selection Sort",
          "Bubble Sort",
          "Insertion Sort"
        ],
        "Binary Search Trees": [
          "Binary Search Trees: Introduction",
          "Binary Search Trees: Insertion",
          "Binary Search Trees: Deletion",
          "Binary Search Trees: Search"
        ],
        "Graphs": [
          "Introduction to Graphs",
          "Minimum Spanning Trees: An Introduction",
          "Prim's Algorithm",
          "Kruskal's Algorithm"
        ],
        "Advanced Graph Algorithms": [
          "Bipartite Graphs and Maximum Matching",
          "Ford Fulkerson Maximum Flow Algorithm",
          "Minimum Vertex Cover",
          "Two Approximation Algorithm for Minimum Vertex Cover"
        ]
      },
      "requirements": [
        "No programming experience needed."
      ],
      "description": "Data Structures and Algorithms is one of the core topics in computer science. Being able to design and analyze algorithms is one of the most important skills required by computer science students and software professionals. All major software companies (e.g., Google, Meta, Microsoft) ask a variety of questions related to algorithms in their interviews.\nThis short course is designed to provide a quick overview of a variety of different algorithms. This course is ideal for individuals who seek a quick yet comprehensive refresher to data structures and algorithms (e.g., while preparing for an exam or job interviews). This course is also well-suited for individuals who are enthusiastic about computer science and want to obtain a high-level understanding of various algorithms.\nUpon successful completion of this course, students will be able to understand, explain and apply key algorithmic concepts related to sorting algorithms (selection sort, bubble sort, and insertion sort). The course will also introduce Binary Search Trees and the various actions supported by them (i.e., insertion, deletion and search). Students will also be introduced to graph and graph algorithms. Specifically, we will cover minimum spanning tree algorithms such as Prim's Algorithm and Kruskal's Algorithm. The course also includes advanced topics such as bipartite graphs, Ford Fulkerson's Algorithm and minimum vertex cover.",
      "target_audience": [
        "Beginners",
        "Individuals who need a refreshers to Algorithms",
        "Candidates preparing for interviews in time crunch"
      ]
    },
    {
      "title": "Gestão de Projetos de Data Science e Big Data",
      "url": "https://www.udemy.com/course/gestao-de-projetos-de-data-science-e-big-data/",
      "bio": "Minimize riscos em projetos de Big Data e Data Science e amplie a eficiência na entrega de produtos e serviços",
      "objectives": [
        "Entenda os principais riscos de projetos de Big Data / Data Science, e como lidar com eles",
        "Compreenda os principais aspectos de um projeto de Big Data / Data Science",
        "Tenha acesso a um checklist exclusivo para projetos de Big Data / Data Science"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Introdução",
          "Material para Download",
          "☕ O Analista de Big Data",
          "Introdução"
        ],
        "Por que Projetos de Data Science?": [
          "Por que Data Science Parte I",
          "Por que Data Science Parte I",
          "Por que Data Science Parte II",
          "☕ Modelos Preditivos",
          "Por que Data Science Parte II",
          "Por que Data Science Parte III",
          "Por que Data Science Parte III"
        ],
        "Considerações: Observar antes do Projeto": [
          "Considerações Antes do Projeto Parte I",
          "☕ Falta de Energia",
          "Considerações Antes do Projeto Parte I",
          "Considerações Antes do Projeto Parte II",
          "Considerações Antes do Projeto Parte II",
          "Considerações Antes do Projeto Parte III",
          "☕ Sistemas Sombra",
          "Considerações Antes do Projeto Parte III"
        ],
        "Gestão de Riscos em Data Science": [
          "Gestão de Riscos Parte I",
          "Gestão de Riscos Parte I",
          "☕ Gestão de Riscos",
          "Gestão de Riscos Parte II",
          "Gestão de Riscos Parte II",
          "Gestão de Riscos Parte III",
          "Gestão de Riscos Parte III"
        ],
        "Aspectos Diversos do Projeto": [
          "Aspectos Diversos Parte I",
          "Aspectos Diversos Parte I",
          "☕ Processamento",
          "Aspectos Diversos Parte II",
          "Aspectos Diversos Parte II",
          "Aspectos Diversos Parte III",
          "Aspectos Diversos Parte III"
        ],
        "Data Science Ágil": [
          "Data Science Ágil",
          "Data Science Ágil"
        ],
        "Processos": [
          "Processos Parte I",
          "☕ O Storage",
          "Processos Parte II",
          "Processos"
        ],
        "Checklist": [
          "Checklist",
          "☕ Prefiro o Excel",
          "Aula Bônus"
        ],
        "Aula Bônus": [
          "Aula Bônus"
        ]
      },
      "requirements": [
        "Conhecimentos em Gerenciamento de Projetos"
      ],
      "description": "Projetos de Data Science e Big Data possuem características exclusiva e alto risco de falha. Este curso sumariza 10 anos de experiência do autor em projetos de Data Science, que vão ajudar você a minimizar riscos em seus projetos, entregando produtos e serviços que entreguem de fato valor. Entre os temas abordados você vai estudar:\nPontos a serem observados antes de iniciar um projeto\nPrincipais riscos que podem afetar um projeto\nPorque empresas implementam Data Science\nPrincipais processos\nData Science Ágil\nChecklist para você usar em seus projetos\nInclui ainda atividades para fixar o conteúdo.",
      "target_audience": [
        "Executivos, Gerentes de Projetos",
        "Analistas de Negócio, Executivos de Vendas"
      ]
    },
    {
      "title": "Tecnologías de Azure Data Engineer: de cero a experto",
      "url": "https://www.udemy.com/course/tecnologias-de-azure-data-engineer-de-cero-a-experto/",
      "bio": "Curso práctico de ingeniería de datos con Azure Databricks, Data Factory, Data Lake, Synapse Analytics, Cosmos DB y DB",
      "objectives": [
        "Introducción al entorno de Azure. Aprenderás los fundamentos de Azure, ha desplegar servicios y a gestionarlos.",
        "Azure Data Factory. Aprenderás todo lo relacionado con Data Factory, desde Data Flows, triggers, parametrización, monitorización, etc.",
        "Azure Databricks. Aprenderás todo lo relacionado con Databricks, desde la ejecución y generación de notebooks, hasta la integración en DWH modernos",
        "Cómo integrar Azure Data Factory y Databricks",
        "Azure Data Factory con Databricks, desde la autenticación, transformación de datos con Databricks, visualización, etc.",
        "Data Lake: aprenderás que es un Data Lake, y a como desarrollarlo y utilizarlo",
        "Synapse Analytics: aprenderás todo lo relacionado con Azure Synapse Analytics",
        "Visualización de datos con Power BI. Aprenderás a visualizar los datos transformados con Azure Data Factory mediante Power BI.",
        "Aprenderás acerca del almacenamiento de datos en Azure con Cosmos DB, Azure Storage y las bases de datos de Azure"
      ],
      "course_content": {
        "Introducción al curso": [
          "Introducción al curso",
          "Como aprovechar al máximo el curso",
          "Material del curso"
        ],
        "Introducción a Azure": [
          "Introducción a Azure y computación en la nube",
          "Servicios de Azure",
          "Suscripciones de Azure y creación de una cuenta",
          "Laboratorio: Fundamentos de Azure Portal"
        ],
        "Conceptos básicos de Azure": [
          "Regiones y pares de regiones de Azure",
          "Zonas de disponibilidad de Azure",
          "Niveles organizativos de los recursos y grupo de recursos de Azure",
          "Laboratorio: Crear, administrar y aprovisionar un grupo de recursos",
          "Suscripciones de Azure y personalización de la facturación",
          "Grupos de administración de Azure"
        ],
        "Rol del Data Engineer": [
          "Rol del Data Engineer y tendencias",
          "Responsabilidades y tecnologías del Data Engineer"
        ],
        "Fundamentos básicos de los datos": [
          "Diferentes tipos de datos",
          "Características de datos relacionales y no relacionales",
          "Soluciones de procesamiento de datos",
          "Características de cargas de trabajo transaccionales y analíticas"
        ],
        "Bases de datos de Azure": [
          "Introducción al almacenamiento en Azure",
          "Azure SQL Database",
          "Modelos de despliegue de Azure SQL Database y SQL DB Managed intances",
          "PostgreSQL y MySQL Database de Azure"
        ],
        "Azure Cosmos Data Base": [
          "Azure Cosmos DB",
          "Laboratorio: Azure Cosmos DB"
        ],
        "Azure Storage": [
          "Servicios de almacenamiento de Azure",
          "Azure Blob Storage",
          "Azure Table Storage",
          "Azure File Storage"
        ],
        "Azure Data Lake": [
          "Data Lake"
        ],
        "Big Data y Data Analytics en Azure": [
          "Azure Synapse Analytics",
          "Azure HDInsight",
          "Azure Databricks",
          "Azure Data Lake Analytics"
        ]
      },
      "requirements": [
        "No"
      ],
      "description": "Si estás buscando un curso completo, práctico y aplicado para aprender las tecnologías de Azure Data Engineer, has venido al lugar correcto.\nEste curso está diseñado para aprender todo lo relacionado con las tecnologías de ingeniería de datos con Azure como: Azure Databricks, Data Factory, Data Lake, Synapse Analytics, Power BI, Cosmos DB, Azure Storage y las bases de datos de Azure.\n\n\nMicrosoft Azure Data Engineering es una de las profesiones de más rápido crecimiento y demanda entre los profesionales de la ciencia de datos. Según un informe de Gartner hubo un crecimiento interanual del 88 % en las ofertas de trabajo para ingenieros de datos, siendo la tasa de crecimiento más alta entre todos los trabajos de tecnología. Por ello, el formarte en esta materia te dará numerosas oportunidades laborales y profesionales.\nPara ello, te guiaremos a través de las competencias de Azure, compartiendo explicaciones claras y útiles consejos profesionales.\n\n\nFormación práctica y laboratorios:\nCon la formación teórica, las guías de estudio descargables, los ejercicios prácticos, los laboratorios aplicados y un completo test, este es el único curso que necesitarás para prepararte.\n\n\nDesarrollo de un completo proyecto de ingeniería de datos de principio a fin:\nAprenderás a cómo integrar todas las tecnologías de ingeniería del dato, de principio a fin, con un completo caso de uso real. En este proyecto importarás datos de diferentes fuentes con Data Factory, los almacenarás en Data Lakes y Blob Storage, los procesarás con Databricks, entrenarás una capa predictiva con Spark, Machine Learning y Databricks, persistirás los resultados en una base de datos relacional y finalmente desarrollarás un informe de Power BI que permita el análisis de los resultados.\n\n\nQué aprenderás:\nIntroducción al entorno de Azure. Aprenderas los funcamentos de Azure, ha desplegar servicios y a gestionarlos.\nAzure Data Factory. Aprenderás todo lo relacionado con Data Factory, desde Data Flows, triggers, parametrización, monitorización, etc.\nAzure Databricks. Aprenderas todo lo relacionado con Databricks, desde la ejecución y generación de notebooks, hasta la integración en DWH modernos.\nCómo integrar Azure Data Factory y Databricks. Cubriremos todo el proceso de integración de Azure Data Factory con Databricks, desde la autenticación, transformación de datos con Databricks, visualización, etc.\nAzure Data Lakes. aprenderás que es un Data Lake, y a como desarrollarlo y utilizarlo.\nAzure Synapse Analytics. aprenderás todo lo relacionado con Azure Synapse Analytics\nVisualización de datos con Power BI. Aprenderás a visualizar los datos transformados con Azure Data Factory mediante Power BI.\nAlmacenamiento con Azure Storage, Cosmos DB y Azure Databases. Aprenderos acerca del almacenamiento de datos en Azure con Cosmos DB, Azure Storage y las bases de datos de Azure.\n\n\n\n\nÚnete hoy y obtén acceso inmediato y de por vida a:\n• Guía de formación Azure Data Engineer (e-book en PDF)\n• Archivos y recursos descargables\n• Laboratorios aplicados a casos de uso reales\n• Ejercicios prácticos y cuestionarios\n• Recursos como: Cheatsheets y resúmenes\n• Soporte experto 1 a 1\n• Foro de preguntas y respuestas del curso\n• 30 días de garantía de devolución de dinero\nSi estás listo para mejorar sus habilidades de Azure Data Engineering, aumentar tus oportunidades laborales y convertirte en un profesional de Azure,\n¡Nos vemos allí!",
      "target_audience": [
        "Cualquier profesional que quiera aprender Azure Data Engineer",
        "Cualquier profesional que quiera implementar diferentes soluciones de datos en Azure",
        "Cualquier estudiante que quiera desarrollar una solución integrar de ingeniería de datos con Azure Data Factory, Databricks, Power BI, etc",
        "Profesionales que buscan una carrera en ingeniería de datos",
        "Desarrolladores de TI que trabajan en otras disciplinas que intentan pasar a la ingeniería de datos."
      ]
    },
    {
      "title": "Practical Machine Learning for Beginners in 2022",
      "url": "https://www.udemy.com/course/practical-machine-learning-for-beginner-in-2022s-in/",
      "bio": "Model Building to Deployment",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Introductory knowledge to Python suffices"
      ],
      "description": "This course is for every beginner in the data science space. We have been there before and we understood what your learning challenges are. This short course will focus on showing you end to end what it takes to build and deploy a simple machine learning solution.\nWe will be building a car pricing prediction engine. This will be purely hands-on.\nYou will be able to deploy this solution using the flask framework as an API and also as a Platform.\nWe will also introduce you to libraries that make it easy to quickly explore, build, and deploy a machine learning solution.\n\n\nThis course assumes you do not have any prior knowledge of Machine Learning or that you have taken a couple of courses but still missing the full picture.\nMachine learning models are not useful in silos and this free course will show you the full picture and cover the knowledge gaps.\n\n\nYou will also be able to put to use your knowledge of HTML as we build a simple web interface to interact with the solution.\nThis course will also introduce you to Postman Application. It is a popular use for testing API and solutions. Postman will help us to interact with the API deployment of our model while our browser is sufficient for interacting with the platform deployment.\n\n\nWe will be making use of the following major applications:\n1. Jupyter Notebook\n2. Visual Studio Code\n3. Postman",
      "target_audience": [
        "Data Science Enthusiast",
        "Beginner Python Developers curious about Data Science",
        "Data Analyst willing to move to the predictive space",
        "Business People curious about model building and deployment"
      ]
    },
    {
      "title": "Getting Started With DeepSeek",
      "url": "https://www.udemy.com/course/getting-started-with-deepseek/",
      "bio": "Learn how to use DeepSeek for building applications.",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Getting started with DeepSeek",
          "Let’s prompt with DeepSeek",
          "Why is DeepSeek trending?"
        ],
        "DeepSeek Architecture": [
          "The DeepSeek Architecture: Overview",
          "Breaking down the DeepSeek architecture"
        ]
      },
      "requirements": [
        "Interest in AI-powered search, LLMs, and automation.",
        "Basic knowledge of using computers and internet."
      ],
      "description": "DeepSeek is disrupting the AI world, rivaling GPT-4, Claude 2, and other leading models with its open-source power. Discover why it’s trending and how to use it to build applications. This course provides an in-depth hands-on experience with DeepSeek, teaching you how to search, analyze, and generate intelligent responses with precision\nModule1: Introduction to DeepSeek\nDeepSeek is transforming the AI landscape with its advanced search and reasoning capabilities. This module provides a foundational understanding of DeepSeek, covering its applications and significance in AI-driven research, automation, and content generation.\nAn introduction to what DeepSeek is, how it works, and what makes it a powerful AI search tool.\nLearn how to craft effective prompts to get the most accurate and relevant responses from DeepSeek.\nUnderstand the reasons behind DeepSeek’s growing popularity in the AI and research communities.\nModule 2: DeepSeek Architecture\nThis module examines DeepSeek's architecture in Detail, explaining how it processes information, retrieves knowledge, and generates responses using advanced AI techniques.\nGain insights into the inner workings of DeepSeek, including its model components and how it processes search queries.\nExplore the technical aspects of DeepSeek’s architecture, including retrieval-augmented generation (RAG), model structure, and optimization techniques.\nDon’t miss this unique opportunity to be at the cutting edge of technological innovation. Enroll today to unlock the limitless possibilities that DeepSeek offers, and navigate this exciting field responsibly and effectively.",
      "target_audience": [
        "Individuals looking to understand advanced AI tools and their applications in analytics and data-driven decision-making.",
        "Beginners interested in AI, machine learning, and how innovative platforms like DeepSeek are reshaping the industry."
      ]
    },
    {
      "title": "【TensorFlow・Kerasで学ぶ】時系列データ処理入門（RNN/LSTM, Word2Vec)",
      "url": "https://www.udemy.com/course/tensorflow_rnn/",
      "bio": "TensorFlow, KerasとPython3を使って、自然言語処理や時系列データ処理を学びましょう。日本語＋動画で学べる唯一の講座（2017年8月現在）です。RNN/LSTMは、機械翻訳、自動字幕表示、株価予測などに使用されています。",
      "objectives": [
        "Word2Vecや、Sequence2SequenceなどTensorFlowの時系列データ処理のチュートリアルを理解できるようになります。",
        "TensorFlowを用いたRNNによる機械学習ができます。",
        "RNNの動作原理について理論を学習し、コードを書いて理解を深めます。",
        "LSTMの仕組みについて理解し、コードを実装して理解を深めます。",
        "Kerasを使用したLSTMによる文章合成プログラムを作成できます。"
      ],
      "course_content": {
        "はじめに": [
          "このコースの概要",
          "Anacondaのインストール（Windows）",
          "Anacondaのインストール（Mac）",
          "Anacondaのアップデート（旧版をインストールしている方のみ）"
        ],
        "Pythonによる形態素解析にチャレンジ（janome）": [
          "このセクションの概要",
          "形態素解析を実行してみよう（単文）",
          "単語の出現頻度を数えてみよう（1/2）",
          "単語の出現頻度を数えてみよう（2/2）",
          "練習課題：　出現頻度のカウント",
          "Wordカウントのソースコード"
        ],
        "Word2Vecにチャレンジ（gensim）": [
          "単語のベクトル表現とは？",
          "Word2Vecライブラリ（gensim）のインストール",
          "Word2Vecで文章を読む（データ準備）",
          "Word2Vecモデルを作る（モデルファイルを作成）",
          "Word2Vecモデルを使ってみよう（近似単語を表示）",
          "練習課題：　Word2Vecモデルを作ろう",
          "Word2Vecのソースコード"
        ],
        "Wikipediaを辞書にしてWord2Vecにトライ（MeCab・gensim・Word2Vec）": [
          "このセクションの概要とデータダウンロード",
          "Rubyとwp2txtのインストール（Windowsオンリー）",
          "wp2txtのインストール（macOSオンリー）",
          "7-Zipのインストール（Windowsオンリー）",
          "Mecabのインストール（Windowsバイナリー）",
          "Mecabのインストール（macOS編・ソースからビルド）",
          "拡張版IPA辞書のインストール（macOSのみ）",
          "wp2txtの実行",
          "テキストファイルを１つにまとめる",
          "分かち書きファイルを作成する",
          "Word2Vecのモデルを生成しよう",
          "モデルを保存し、ベクトル演算をしてみよう"
        ],
        "RNNとLSTMの仕組みを理解しよう": [
          "Word2VecからRNNへ",
          "Word2Vecの２つのモデル（CBOWとSkip-gram）",
          "RNNの仕組み",
          "RNNセルと問題点（LSTMへ）",
          "LSTMセル（セルステート・忘却ゲート）",
          "入力ゲートとセルステート値の更新",
          "出力値の計算"
        ],
        "LSTMで文章を生成しよう": [
          "Kerasをインストールしよう(1/2)",
          "Kerasをインストールしよう(2/2)",
          "Jupyter Notebookを追加してライブラリをインポートしよう",
          "文章から辞書を作成しよう",
          "文章と次に来る文字を記録しよう",
          "テキストをベクトル化しよう",
          "モデルを定義しよう",
          "学習して文章を生成しよう",
          "途中経過",
          "最終的な出力",
          "テキスト生成のノートブック"
        ],
        "TensorFlowで機械翻訳に挑戦": [
          "注意：TensorFlow 1.6での変更",
          "収録時点でのコード",
          "セクションの概要",
          "Python実行環境の追加",
          "フォルダ追加とコードのクローニング",
          "翻訳データのダウンロード",
          "エンコーダー・デコーダーモデル",
          "トレーニングの実行",
          "モデルの保存",
          "パフォーマンスモニターでCPU稼働率をチェックしてみよう",
          "モデルサイズを小さくして学習をしてみよう",
          "TensorFlow 1.3.0 GPUのインストール（cuDNN 6.0）",
          "TensorFlow 1.3.0 GPUでトレーニングを実行",
          "トレーニングの経過",
          "GPU版実行時のCPU負荷",
          "途中経過",
          "機械翻訳を実行してみよう"
        ],
        "RNNでセンチメントアナリシス（感情分析）に挑戦": [
          "このセクションの概要",
          "データの準備とノートブックの追加",
          "データの読み込みと変数への格納",
          "単語やレビューのベクトル化",
          "ラベルと特徴ベクトルをつくろう",
          "データを分割しておこう",
          "エンベディングレイヤーを定義しよう",
          "LSTMセルとレイヤーを定義しよう",
          "推定と推定精度評価の式を定義しよう",
          "指定サイズでバッチデータを取得するモジュール定義",
          "トレーニングを実行しよう",
          "テストを実行しよう",
          "このセクションで使用したノートブック"
        ],
        "LSTMで株価予想を行ってみよう": [
          "このセクションの概要",
          "データをロードする関数を定義しよう",
          "正規化処理を定義しよう",
          "ネットワーク（モデル）を定義する関数を定義しよう",
          "株価を予測する関数を定義しよう",
          "lstm.pyの修正",
          "株価を予測してみよう",
          "株価を予測してみよう（2/2）",
          "TensorFlow 2.3.0 - 2.5.0対応のコード"
        ],
        "ボーナスセクション（補足動画など）": [
          "Atomのパッケージを追加しよう（オプション）"
        ]
      },
      "requirements": [
        "TensorFlowをインストール可能なPC（64bit macOSまたはWindows, 8GBRAM以上を推奨）",
        "TensorFlow・Keras（無償・レクチャーで導入方法を解説します）",
        "Anaconda 最新版（無償・レクチャーで導入方法を解説します））",
        "Janome, Gensimなど形態素解析やWord2Vectorライブラリ（無償・レクチャーで解説します）",
        "必須ではありませんが、GPU搭載マシンだと学習が短時間に実行できます。",
        "インターネット接続"
      ],
      "description": "*2017/12/3 株価予測のチュートリアルを順次掲載しています。\n*2017/9/19 感情分析のセクションを追加しました。\n*2017/9/14 Kerasを使用した文章合成のチュートリアルを追加しました。\n*2017/9/12 機械翻訳の実行結果を掲載しました。10日間トレーニングしたモデルを使用しました。\n＊2017/9/3 Wikipedia日本語記事全文を使用したWord2Vecのチュートリアルを掲載しました。モデル生成に丸1日かかりました。\n＊2017/9/1 リクエストの大変多かったTensorFlowのSequence-To-Sequenceチュートリアルのプログラムを動作させてプロセスを収録しています。現在、2日間ほどプログラムを稼働し続けています。学習が完了したら結果をアップロードします。\nPython3とTensorFlowやMeCab, Janome, Gensimなどを使用して、\n自然言語処理（形態素解析、Word2Vec、RNNによるSequence-To-Sequence）\nRNN/LSTMによる文章処理、合成\nディープラーニングによる株価予測プログラム開発\nなどにチャレンジします。\n実習には、Python 3 とJupyter Notebookを使用し、ウェブブラウザ上でコードを書いてプログラムを実行できます。\nチャレンジしたいトピックも募集しています。リクエストがあってテクニカルに可能なものは収録しますので、フォーラムやメッセージでお知らせください。\n＊＊＊　受講上の注意　＊＊＊\nこのコースは動画で、はじめて形態素解析やRNNなどを学ぶ方のためのコースです。\n環境構築から１つ１つ丁寧に解説していきますので、\n・動画より書籍で学びたい方\n・すでにLSTMやGRUなどについて詳しく学ばなくても結構\nという方は、間違って受講されないようご注意ください。\nまた、間違えて登録した方は30日以内であれば返金可能なのでお試しください。",
      "target_audience": [
        "Pythonを使用した自然言語処理の仕組みと実装方法を学びたい方",
        "時系列データのディープラーニングによる処理を学びたい方",
        "頻繁なアップデートでパニックしない方",
        "英語のメニューでパニックしない方",
        "TensorFlow入門コースを受講、または内容を理解している方",
        "ニューラルネットワークの原理について、ニューラルネットワークのコースを受講したか、理解している方",
        "ビデオを視聴するのが苦でない方（書籍の方がいい方にはお勧めしません）"
      ]
    },
    {
      "title": "Complete Outlier Detection Algorithms A-Z: In Data Science",
      "url": "https://www.udemy.com/course/complete-outlier-detection-algorithms-a-z-in-data-science/",
      "bio": "Outlier Detection Algorithms in Data Science, Machine Learning, Deep Learning, Data Analysis, Statistics with Python",
      "objectives": [],
      "course_content": {
        "Lectures": [
          "Introduction of outlier",
          "Application of outlier detection",
          "Cause and impact of outlier",
          "Type of outliers",
          "Methods for outlier detection",
          "Outlier detection in univariate",
          "Outlier detection in multivariate",
          "Outlier detection in high dimension",
          "Outlier detection in deep learning",
          "Best practices of outlier detection",
          "How to remove outliers?"
        ],
        "Tutorials": [
          "Tutorial 1",
          "Tutorial 2",
          "Tutorial 3",
          "Tutorial 4",
          "Tutorial 5",
          "Tutorial 6",
          "Tutorial 7"
        ],
        "Multiple choice question": [
          "Quiz 1"
        ]
      },
      "requirements": [
        "It is assumed that you have completed and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, Matplotlib, Scikit-learn",
        "Familiarity with the Python is needed since support for Python in the tutorial is limited",
        "You should be familiar with basic supervised and unsupervised learning techniques"
      ],
      "description": "Welcome to the course \"Complete Outlier Detection Algorithms A-Z: In Data Science\".\nThis is the most comprehensive, yet straight-forward, course for the outlier detection on UDEMY!\nAre you Data Scientist or Data Analyst or Financial Analyst or maybe you are interested in anomaly detection or fraud detection? The course is designed to teach you the various techniques which can be used to identify and recognize outliers in any set of data.\nThe process of identifying outliers has many names in Data Science and Machine learning such as outlier modeling, novelty detection, or anomaly detection. Outlier detection algorithms are useful in areas such as Machine Learning, Deep Learning, Data Science, Pattern Recognition, Data Analysis, and Statistics.\nI will present to you very popular algorithms used in the industry as well as advanced methods developed in recent years, coming from Data Science. You will learn algorithms for detection outliers in Univariate space, in Low-dimensional space and also learn the innovative algorithms for detection outliers in High-dimensional space.\nI am convinced that only those who are familiar with the details of the methodology and know all the stages of the calculation, can understand it in depth. Anyone who interested in programming, I developed all algorithms in PYTHON, so you can download and run them.\nList of Algorithms:\nInterquartile Range Method (IQR), Standard Deviation Method\nKNN, DBSCAN, Local Outlier Factor, Clustering Based Local Outlier Factor, Isolation Forest, Minimum Covariance Determinant, One-Class SVM, Histogram-Based Outlier Detection, Feature Bagging, Local Correlation Integral\nAngular Based Outlier Detection\nAutoencoders\nWhy wait? Start learning today! Because Everyone, who deals with the data, needs to know ‘Complete Outlier Detection Algorithms A-Z: In Data Science’, a necessity to recognize fraudulent transactions in the data set. No matter what you need outlier detection for, this course brings you both theoretical and practical knowledge, starting with basic and advancing to more complex algorithms. You can even hone your programming skills because all algorithms you will learn have an implementation in PYTHON. You will learn how to examine data with the goal of detecting anomalies or abnormal instances or outlier data points.\nFor the code explained in the tutorials, you can find a GitHub repository hyperlink.\nAt the end of this course, you will have understood the different aspects that affect how this problem can be formulated, the techniques applicable for each formulation, and knowledge of some real-world applications in which they are most effective.",
      "target_audience": [
        "Data Scientist or Data Analyst or Financial Analyst or Business Analyst or Software Engineers or Technical Managers",
        "People interested in outlier detection, anomality detection, fraud detection, unseen pattern in data",
        "People who want a career in Data Science or Data Analytics",
        "This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on outlier detection and anomality detection"
      ]
    },
    {
      "title": "Visão Computacional: O Guia Completo",
      "url": "https://www.udemy.com/course/visao-computacional-o-guia-completo/",
      "bio": "Aprenda tudo o que você precisa saber sobre Visão Computacional! Construa projetos passo a passo com o Python!",
      "objectives": [
        "Entenda a intuição básica sobre o classificador Cascade e HOG (Histogram of Oriented Gradients) para detecção de faces",
        "Implemente detecção de faces com as bibliotecas OpenCV e Dlib",
        "Detecte carros, relógios de parede, olhos e o corpo inteiro de pessoas com o OpenCV",
        "Detecte faces de imagens e pela webcam",
        "Entenda a teoria básica sobre o algoritmo LBPH para reconhecimento facial",
        "Implemente reconhecimento facial utilizando as bibliotecas OpenCV e Dlib",
        "Reconheça faces de imagens e pela webcam",
        "Entenda a teoria básica sobre os algoritmos KCF e CSRT para rastreamento de objetos",
        "Rastreie objetos de vídeos com a biblioteca OpenCV",
        "Implemente redes neurais artificiais densas para classificar imagens",
        "Implemente transferência de aprendizagem e fine tuning obter ótimos resultados em classificação de imagens",
        "Detecte objetos em imagens e vídeos utilizando a moderna técnica YOLO",
        "Crie imagens alucinógenas utilizando a técnica de Deep Dream",
        "Crie imagens que não existem no mundo real com GANs (Generative Adversarial Networks)",
        "Implemente segmentação de imagens para extrair informações úteis de objetos",
        "Aprende a teoria básica sobre redes neurais artificiais e redes neurais convolucionais",
        "Extraia pixels de imagens para enviar para redes neurais artificiais",
        "Compacte imagens utilizando autoencoders",
        "Reconheça ações e gestos com o OpenCV",
        "Aprenda como reviver quadros de artistas famosos com a técnica de transferência de estilo",
        "Extraia textos de imagens utilizando OCR (Optical Character Recognition)"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Visão Computacional",
          "Recursos para download"
        ],
        "Detecção de faces": [
          "Introdução",
          "Imagens e pixels",
          "Classificador cascade - intuição",
          "Carregamento e pré-processamento da imagem",
          "Detecção de faces com haarcascade e OpenCV",
          "Parâmetros haarcascade 1",
          "Parâmetros haarcascade 2",
          "Detecção de olhos com haarcascade",
          "EXERCÍCIO - detecção de outros objetos",
          "Solução para o exercício",
          "HOG (Histrograms of Oriented Gradients) – intuição",
          "Detecção de faces com HOG e Dlib",
          "Detecção de faces com CNN e Dlib",
          "EXERCÍCIO – haarscascade x HOG x CNN",
          "Solução o exercício",
          "Anaconda e PyCharm",
          "Detecção de faces pela webcam",
          "Material complementar"
        ],
        "Reconhecimento facial": [
          "Introdução",
          "Algoritmo LBPH - intuição",
          "Base de dados de faces",
          "Pré-processamento das imagens",
          "Treinamento do classificador LBPH",
          "Reconhecimento de faces com LBPH",
          "Avaliação do classificador LBPH",
          "Parâmetros do LBPH - intuição",
          "Parâmetros do LBPH - implementação",
          "Detecção de pontos faciais",
          "Detecção de descritores faciais 1",
          "Detecção de descritores faciais 2",
          "Cálculo de distância entre faces",
          "Reconhecimento facial com Dlib",
          "Avaliação do classificador com Dlib",
          "EXERCÍCIO",
          "Solução o exercício",
          "Reconhecimento facial pela webcam",
          "Material complementar"
        ],
        "Rastreamento de objetos": [
          "Introdução",
          "Rastreamento de objetos vs Detecção de objetos",
          "Algoritmos KCF e CSRT",
          "Rastreamento de objetos com KCF",
          "Rastreamento de objetos com CSRT",
          "EXERCÍCIO",
          "Solução o exercício",
          "Material complementar"
        ],
        "Redes neurais para classificação de imagens": [
          "Introdução",
          "Perceptron de uma camada",
          "Redes multicamada - função soma e função de avaliação",
          "Redes multicamada - cálculo do erro",
          "Descida do gradiente",
          "Cálculo do parâmetro delta",
          "Ajuste dos pesos com backpropagation",
          "Bias, erro, descida do gradiente estocástica e mais parâmetros",
          "Pixels e redes neurais",
          "Importação das bibliotecas",
          "Extração de pixels de imagens 1",
          "Extração de pixels de imagens 2",
          "Normalização dos pixels",
          "Bases de treinamento e teste",
          "Construção e treinamento da rede neural",
          "Avaliação da rede neural",
          "Salvar e carregar a imagem",
          "Classificação de uma única imagem",
          "Extração de características de imagens",
          "Extração de características com o OpenCV 1",
          "Extração de características com o OpenCV 2",
          "Extração de características com o OpenCV 3",
          "Extração de características com o OpenCV 4",
          "Extração de características com o OpenCV 5",
          "Bases de treinamento e teste",
          "Construção e treinamento da rede neural",
          "Avaliação da rede neural",
          "Salvar, carregar e classificar uma imagem",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Material complementar"
        ],
        "Redes neurais convolucionais para classificação de imagens": [
          "Introdução",
          "Introdução a redes convolucionais 1",
          "Introdução a redes convolucionais 2",
          "Operador de convolução",
          "Operador de convolução 2",
          "Pooling",
          "Flatenning",
          "Rede neural densa",
          "Importação das bibliotecas",
          "Carregamento das imagens",
          "Bases de treinamento e teste",
          "Construção e treinamento da rede neural",
          "Avaliação da rede neural",
          "Salvar e carregar a rede neural",
          "Classificação de uma única imagem",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Material complementar"
        ],
        "Transferência de aprendizagem e fine tuning": [
          "Introdução",
          "Transferência de aprendizagem - intuição",
          "Importação das bibliotecas e base de dados",
          "Base de treinamento e teste",
          "Rede neural pré-treinada",
          "Criação da camada densa personalizada",
          "Construção e treinamento da rede neural",
          "Avaliação da rede neural",
          "Fine tuning - intuição",
          "Fine tuning - implementação e avaliação",
          "Carregar, salvar e classificar uma única imagem",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Material complementar"
        ],
        "Redes neurais para classificação de emoções": [
          "Introdução",
          "Importação das bibliotecas e imagens",
          "Bases de treinamento e teste",
          "Construção e treinamento da rede neural",
          "Salvar e carregar a rede neural",
          "Avaliação da rede neural",
          "Classificação de uma única imagem",
          "Classificação de múltiplas imagens",
          "Classificação de emoções em vídeos",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Material complementar"
        ],
        "Autoencoders": [
          "Introdução",
          "Autoencoders - intuição",
          "Tipos de autoencoders",
          "Importação das bibliotecas e base de dados",
          "Visualização das imagens",
          "Pré-processamento das imagens",
          "Construção e treinamento do autoencoder linear",
          "Aviso sobre atualização de código",
          "Codificação das imagens",
          "Decodificação das imagens",
          "Codificação e decodificação das imagens de teste",
          "Autoencoder convolucional 1",
          "Autoencoder convolucional 2",
          "Autoencoder convolucional 3",
          "Autoencoder convolucional 4",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Material complementar"
        ],
        "Detecção de objetos com YOLO": [
          "Introdução",
          "YOLO - introdução",
          "YOLO - arquitetura",
          "Download e compilação do Darknet",
          "Testes com o detector YOLO",
          "Darknet com GPU",
          "Parâmetros do detector",
          "Detecção de objetos em vídeos",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Material complementar"
        ]
      },
      "requirements": [
        "Lógica de programação",
        "Programação básica em Python"
      ],
      "description": "A Visão Computacional é uma sub-área da Inteligência Artificial responsável pela criação de sistemas capazes de processar, analisar e identificar dados visuais de um modo similar ao humano. Existem muitas aplicações comerciais em várias áreas, como por exemplo: segurança, marketing, tomada de decisão e produção. Smartphones usam visão computacional para desbloquearem celulares utilizando reconhecimento facial, carros autônomos conseguem detectar pedestres e manter uma distância segura de outros veículos e câmeras de segurança identificam se existem pessoas no ambiente para disparar um alarme. Esses são somente alguns exemplos de aplicações comerciais desta área. Os profissionais de visão computacional podem ter salários similares aos das outras áreas de Machine Learning, indo de R$ 5.000 mensais numa posição inicial a R$ 15.000 numa posição sênior.\nPara levar você até essa área, neste curso você terá uma visão teórica e principalmente prática sobre as principais e mais modernas técnicas de Visão Computacional! Este curso é considerado um guia completo pelo fato de apresentar desde conceitos mais básicos até técnicas mais modernas e avançadas, de modo que ao final você terá todas as ferramentas necessárias para construir soluções de Visão Computacional que podem ser aplicadas em problemas reais! Veja abaixo alguns dos projetos/tópicos que serão implementados passo a passo:\nDetecte faces em imagens e vídeos usando as bibliotecas OpenCV e Dlib\nAprenda como reconhecer faces utilizando o algoritmo LBPH do OpenCV e também cálculos de distância com a biblioteca Dlib\nRastreie objetos em vídeos usando os algoritmos KCF e CSRT\nAprenda a teoria sobre redes neurais artificiais e implemente redes neurais para classificar imagens\nImplemente redes neurais convolucionais para classificar imagens\nUtilize transferência de aprendizagem e fine tuning para obter resultados expressivos na classificação de imagens\nDetecte emoções de imagens e vídeos\nCompacte imagens utilizando autoencoders e a biblioteca TensorFlow\nDetecte objetos utilizando YOLO, umas das tecnologias mais robustas atualmente\nConverta imagens em textos utilizando OCR (Optical Character Recognition)\nReconheça gestos e ações utilizando o OpenCV\nCrie imagens alucinógenas utilizando a técnica de Deep dream\nCombine estilos de imagens utilizando a técnica de transferência de estilo\nCrie imagens que não existem no mundo real utilizando GANs (Generative Adversarial Networks)\nExtraia informação útil de imagens utilizando segmentação de imagens\nCada tipo de problema requer técnicas diferentes para sua solução, portanto, conhecendo todas as áreas da Visão Computacional você saberá que técnicas utilizar nos mais variados tipos de cenários! Durante o curso, vamos utilizar a linguagem de programação Python, o Google Colab e também a IDE PyCharm. Este é o curso ideal caso seja seu primeiro contato com Visão Computacional, pois você aprenderá a teoria básica e a prática de todos os tópicos! Caso você seja de nível mais avançado, você pode utilizar esse curso como uma referência sobre a área.",
      "target_audience": [
        "Iniciantes na área de Visão Computacional",
        "Alunos de graduação e pós-graduação que estão cursando disciplinas sobre Visão Computacional, Inteligência Artificial, Processamento Digital de Imagens ou Computação Gráfica",
        "Pessoas que querem implementar seus próprios projetos utilizando técnicas de Visão Computacional",
        "Cientistas de Dados que queiram aumentar o seu portfólio de projetos",
        "Profissionais que queiram aprender como usar visão computacional para solucionar problemas reais"
      ]
    },
    {
      "title": "生成AI入門【2025年最新版】 -ChatGPTと共に学ぶデータの生成、プロンプトエンジニアリングとAIの未来-",
      "url": "https://www.udemy.com/course/generative/",
      "bio": "ChatGPTなどの生成AIについて学ぶ講座です。文章によるAIの制御が実現し、誰もが生成AIの恩恵を受けられる時代になりました。今後の社会に多大な影響を与える技術を学び、画像、音楽、動画など様々なデータを生成できるようになりましょう。",
      "objectives": [
        "生成AIの基礎を体験ベースで学びます。",
        "プロンプトエンジニアリングの基礎と可能性について学びます。",
        "ChatGPTなどの対話AIの基礎、そして画像生成AIの基礎を学びます。",
        "生成AIが社会に与える影響について学びます。",
        "生成AIの未来について学びます。",
        "AIの仕組みではなく、「AIの使いこなし方」を学びます。"
      ],
      "course_content": {
        "生成AIの概要": [
          "教材の使用方法",
          "Section1で使うWebページ",
          "イントロダクション",
          "講座の概要",
          "人工知能（AI）とは？",
          "生成AIとは？",
          "ChatGPTの体験",
          "Image Creatorの体験",
          "生成AIによるデザイン",
          "生成AIの概要"
        ],
        "文章を生成するAI": [
          "Section2で使うWebページとプロンプト",
          "Section2の概要",
          "文章生成AIとは？",
          "プロンプトエンジニアリングとは？",
          "文章生成AIをビジネスに活用",
          "文章生成AIによる創作活動",
          "様々な文章生成AIの活用",
          "文章を生成するAI"
        ],
        "画像などを生成するAI": [
          "Section3で使うWebページ",
          "Section3の概要",
          "様々な画像生成AI",
          "画像生成のテクニック",
          "動画の生成",
          "音楽の生成",
          "画像などを生成するAI"
        ],
        "生成AIの未来": [
          "Section4で使うWebページとプロンプト",
          "Section4の概要",
          "様々な生成AIの活用",
          "生成AIは人間に近づくのか？",
          "生成AIと社会",
          "汎用人工知能（AGI）の登場？",
          "最後に",
          "生成AIの未来"
        ],
        "コースの付録": [
          "AIの最新動向 2025年版 前編（2025.1.12追加）",
          "AIの最新動向 2025年版 後編（2025.1.12追加）",
          "AIの最新動向 2024年版 前編（2024.1.25追加）",
          "AIの最新動向 2024年版 後編（2024.1.25追加）"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "プログラミングや数学の知識、経験は不要です。",
        "人工知能、機械学習の技術的な知識は不要です。",
        "機械学習やデータサイエンス、深層学習について詳しい解説はありません。",
        "2024年2月の環境で解説しています。最新の環境と異なる可能性があります。",
        "OpenAI、Microsoftなど、いくつかのアカウント開設が必要です。"
      ],
      "description": "「生成AI入門」は、近年発展が著しい生成AIについて学ぶ講座です。\n難しい数式やコードを使わずに生成AIの要点を丁寧に学ぶので、文系の方でも問題なく受講できます。\n\n\n文章生成AIのChatGPTやGemini、画像生成AIのMidjourneyやStable Diffusionなどに代表される生成AIは、その高い精度と自然言語によるインターフェイスにより現在世界中の注目を集めています。\n時には人間の創作物と見分けがつかないようなコンテンツが生成されることもあり、今後人間社会をどのように変えていくのか、多くの人が関心を抱いています。\n\n\nまた、AIを上手く活用すれば、「作業」を任せることで創作活動や仕事の効率化が可能になります。\nAIに任せられることは任せて、人間はより人間らしいことに集中できるようになっていくことが期待されています。\n\n\n本講座では、最初に生成AIの基礎を学んだ上で、様々な生成AIをコンテンツ生成の体験と共に学びます。\n生成AIの基礎と使い方を学び、AI時代を上手く楽しめるようになりましょう。\n\n\n講座の内容は以下の通りです。\nSection1. 生成AIの概要\n→ 生成AIの概要を学んだ上で、実際に生成AIによるデータの生成を体験します。\nSection2. 文章を生成するAI\n→ 主にChatGPTを使った、文章生成の仕組みと実践について学びます。\nSection3. 画像などを生成するAI\n→ 生成AIを使って画像などのデータを生成する方法を学びます\nSection4. 生成AIの未来\n→ 生成AIが社会に与える影響、そして生成AIの未来について学びます。\n\n\n「AIを使いこなす」ことが、あらゆる分野で重要なスキルになりつつあります。\nAIが自身のキャリアにどのような影響を与えるのか、そして社会における人間の役割はどう変わっていくのか、本講座を受けて想像力を広げましょう。\n\n\n2024.1.25 「コースの付録」にレクチャーが追加されました。\n2024.5.30 タイトルが変更され、コンテンツが2024年最新版に更新されました。\n2025.1.13 「AIの最新動向」に2025年の新コンテンツが追加されました。",
      "target_audience": [
        "最新の生成AIに関する知識をキャッチアップしたい方。",
        "仕事上、対話AIや画像生成AIを扱うスキルが必要になった方。",
        "ChatGPTなどの対話AIを上手く使いこなせるようになりたい方。",
        "画像生成AIを上手く使いこなせるようになりたい方。",
        "生成AIを使った創作活動をしたい方。",
        "プログラミングや数学は苦手だけど、AIを扱えるようになりたい方。",
        "機械学習エンジニアを目指している方向けではありません。数式やコードによる解説はありません。"
      ]
    },
    {
      "title": "【R言語をゼロから理解していく】データサイエンスの実践例から学ぶデータ分析入門",
      "url": "https://www.udemy.com/course/r-datascience/",
      "bio": "データサイエンスの理解、R言語プログラミングでの基本統計量・可視化、データ分析プロセスの基礎を網羅！オープンデータ(e-stat)活用やSNS(twitter)分析といった広域なデータ分析事例を紹介！",
      "objectives": [
        "統計学・機械学習の基本を理解している",
        "実務のデータ分析を実行するための一連のプロセスを理解して、分析のPDCAを回すことができる",
        "R/Rstudioの基本的な操作方法を習得して、実際のデータ分析で使用できる"
      ],
      "course_content": {
        "データサイエンスの理解": [
          "1-1成り立ちと現在",
          "1-2具体的事例"
        ],
        "２回Rの導入": [
          "2-1-1データサイエンスの道具",
          "2-1.1 検定",
          "2-1-2相関と回帰",
          "2-1-3分類",
          "2-2-1データサイエンスのソフトウェア",
          "2-2-2R/RStudioのインストール",
          "2-3Rstudioの画面操作",
          "2-4-1データの読み込み",
          "2-4-2Rで使用される用語",
          "2-5-1前回までの確認",
          "2-5-2データの中心",
          "2-5-3データの幅",
          "2-6-1モダンな操作",
          "2-6-2母集団と標本そして検定",
          "2-7-1モダンなグラフ日本語設定",
          "2-7-2ggplot2によるヒストグラム",
          "2-7-3散布図",
          "2-7-4グループを分ける",
          "2-7-5クラスター分析",
          "2-7-6主成分分析"
        ],
        "３回データサイエンスの手法": [
          "3-1検定",
          "3-2-1回帰・分析",
          "3-2-2ロジステック回帰分析",
          "3-2-3決定木",
          "3-3クラスタリング",
          "3-3-1階層型クラスタリング",
          "3-3-2k平均法",
          "3-4-1次元削減とは",
          "3-4-2-1主成分分析",
          "3-4-2-2主成分分析の実行",
          "3-4-2-3主成分の抽出とバイプロット",
          "3-4-2-4累積寄与率の計算"
        ],
        "４回データ分析プロセス": [
          "4-1分析プロセスの概要",
          "4-2ビジネス課題の明確化",
          "4-3分析計画の立案",
          "4-4データの選定収集",
          "Rコード解説について",
          "4-5データの特性理解",
          "4-6データの前処理",
          "4-7予測モデルの構築",
          "4-7-2予測モデルの構築2"
        ],
        "５回データ活用事例": [
          "5-1e-statの紹介",
          "5-1e-statからのデータ取得＆日本地図への描画_1",
          "5-1e-statからのデータ取得＆日本地図への描画_2",
          "5-1e-statからのデータ取得＆日本地図への描画_3",
          "5-1e-statからのデータ取得＆日本地図への描画_4",
          "5-2テキストマイニング"
        ]
      },
      "requirements": [
        "PCでのおける基本的なタイピング操作"
      ],
      "description": "データサイエンスの第一歩をスムーズに！\nこのコースは、データサイエンスの基本的な考え方、データ解析とグラフ作成について学ぶことができます。そして、あなたの実際の業務に適応することを目標にしています。また、予備知識については全く必要ありません。\nここでは、Rという統計解析用のプログラミング言語を学びます。Rはプログラミング初心者に対しても優しい言語であり、大学や企業などでも広く用いられています。\n\n近年、Rに関する数多くの書籍が出版されています。しかし、実際の操作方法については、文字による説明だけでは飲み込みづらいのが実状です。本コースでは実際の操作画面を動画とキャプションで表示しているため、複雑な操作であっても直感的に理解することができるでしょう。\n本コースを通して、以下の項目を学ぶことができます。\nデータサイエンス（統計学・機械学習）の背景、データ分析の実践例\nR/Rstudioの基本的な操作\nデータの特徴を理解するのに役立つ要約技法、グラフ作成方法\n実際の業務を想定した分析シミュレーション・分析プロセス\nインターネット上に公開されているデータを取得し、地図などで表現する可能性\ntwitterなどのテキスト情報を分析してグラフ化する技法\n\nデータサイエンスの学習を始めましょう！",
      "target_audience": [
        "データサイエンスに興味がある方",
        "これからR言語（プログラミング）を習得したい方、あるいはR言語で何ができるかを知りたい方",
        "データを分析する必要に迫られているが、基本的な知識や技術に不安のある方",
        "データを基にした意思決定をしたい方"
      ]
    },
    {
      "title": "Master IA Generativa. Crea tu propio ChatGPT en Azure OpenAI",
      "url": "https://www.udemy.com/course/master-ia-generativa-modelos-personalizados/",
      "bio": "Crea, Personaliza y Despliega Modelos Personalizados (LLM). Domina la Inteligencia Artificial Generativa en Azure OpenAI",
      "objectives": [
        "Entender conceptos clave de la IA generativa: LLM, Fine-Tuning, Prompts, Tokens, Modelos, Prompt Engineering, etc.",
        "Construir y personalizar grandes modelos de lenguaje (LLM) con datos propios en un entorno privado y seguro.",
        "Entrenar y validar modelos de IA Generativa totalmente personalizados y con datos únicos",
        "Desplegar y configurar modelos personalizados en Azure OpenAI, adaptados a necesidades empresariales.",
        "Integrar modelos personalizados en aplicaciones y soluciones usando la API de Azure OpenAI",
        "Combinar la IA Generativa con otras tecnologías para resolver casos de negocio concretos",
        "Diseñar soluciones específicas que incorporen IA Generativa para resolver problemas reales de múltiples sectores e indústrias",
        "Utilizar modelos de generación de texto e imágenes en chatbots de Azure Open AI: GPT-3.5, GPT-4, DAL·LE, etc."
      ],
      "course_content": {
        "Introducción": [
          "Objetivos",
          "Instrucciones del Curso",
          "Sobre Mi",
          "Estructura"
        ],
        "Fundamentos Esenciales de la Inteligencia Artificial Generativa": [
          "Inteligencia Artificial Generativa",
          "Impacto de la tecnología",
          "Desarrollo de actividades",
          "Profesiones e IA Generativa",
          "IA Generativa en Marketing",
          "IA Generativa en TIC",
          "Casos de uso",
          "Deep Learning y Machine Learning",
          "Foundational Models, LLMs y Fine-Tuning",
          "Prompts",
          "Prompt Engineering",
          "Tokens",
          "Adopción de la tecnología",
          "Azure Open AI",
          "Modelos de Azure Open AI"
        ],
        "Azure OpenAI - Crear Espacios de Desarrollo Personalizados": [
          "Portal Azure",
          "Requisitos Azure",
          "Crear Recurso",
          "Azure Open AI Studio",
          "Coste de infraestructura"
        ],
        "Diseñando y Forjando Modelos Generativos": [
          "Interacción con el Modelo",
          "Implementación del Modelo",
          "Configuración del Chat",
          "Contexto y Personalización",
          "Instrucciones de Comportamiento",
          "Parámetros del Modelo",
          "Importar Configuración",
          "Optimizar Prompts",
          "Finalizaciones"
        ],
        "Personalizar Modelos - Datos No Estructurados": [
          "Modelos Personalizados, Documentos y Conocmiento",
          "LLMs y búsqueda semántica",
          "Cambio de Recurso: Azure AI Search",
          "Azure Cognitive Search",
          "Blob Storage",
          "Información NO estructurada",
          "Datos personalizados",
          "Test de la solución",
          "UX/UI vs IA Generativa",
          "Desplegar Aplicación",
          "Configurar Autenticación",
          "Acceso a la App",
          "Gestión de versiones"
        ],
        "Personalizar Modelos - Fine-Tuning": [
          "Modelos Personalizados y Fine-Tuning",
          "Possibles aplicaciones",
          "Conjuntos de datos",
          "Datos de entrenamiento",
          "Generar datos de training",
          "Datos de validación",
          "Automatización de datos de validación",
          "Permisos de recurso",
          "Regiones de despliegue",
          "Modelo Personalizado",
          "Ficheros de datos",
          "Parámetros de entrenamiento",
          "Analizar resultados",
          "Detalle de resultados",
          "Diferencias entre modelos",
          "Obtener datos de entrenamiento",
          "Entrenar modelo",
          "Comparar gráficos",
          "Relación de resultados",
          "Costes asociados",
          "Implementar modelo",
          "Test modelo en àrea de juegos",
          "Desplegar Modelo Categorías",
          "Finalizaciones Modelo Categorías",
          "Archivos Descargables"
        ],
        "Transformar Ideas en Acción a través de la API de Azure OpenAI": [
          "Introducción",
          "Entorno Local",
          "Visual Studio Code",
          "Python",
          "Configurar editor de código",
          "Editar datos de training",
          "Petición API Azure Open AI",
          "Extraer resultado",
          "Prámetros: Stop vs MaxTokens",
          "Petición API Modelo Categorías",
          "Archivos Descargables"
        ],
        "Generación de imágenes con Azure Open AI: DAL·LE": [
          "Generación de Imágenes",
          "Combinación de Modelos",
          "Iteraciones de Prompts",
          "Funcionalidades y Parámetros",
          "Diseño de Integraciones",
          "Obtención de Resultados",
          "Archivos Descargables"
        ],
        "Casos de Uso Empresariales - Datos Sensibles": [
          "Tratamiento de información sensibles",
          "Jupyter Notebook",
          "Ejecución Script",
          "Importar Módulos",
          "Caso de Uso: Diseño de Pruebas Técnicas",
          "Ejecución de Pruebas Técnicas",
          "Caso de Uso: Soft Skills",
          "Caso de Uso: Descripción Vacante",
          "Desarrollo de Solución",
          "Solución en Producción",
          "Archivos Descargables"
        ],
        "Casos de Uso Empresariales - IA Generativa y OCR": [
          "Introducción",
          "Herramientas",
          "Preparar entorno",
          "Combinar IA y OCR",
          "OCR (Optical Character Recognition)",
          "Extracción de Información",
          "Integración de IA Generativa",
          "Interpretar Resultados",
          "Archivos Descargables"
        ]
      },
      "requirements": [
        "No se requiere experiencia previa. En el curso aprenderás todo lo que necesitas saber para convertirte en un experto en IA Generativa y desplegar tus primeros modelos personalizados."
      ],
      "description": "¿Qué objetivo tiene el curso?\nEl objetivo del curso es brindarte las herramientas y habilidades necesarias para convertirte en un experto en inteligencia artificial generativa, siendo capaz de comprender, desplegar y personalizar modelos en Azure OpenAI. Aprenderás a aplicar la IA generativa en casos empresariales, integrarla en aplicaciones reales y comprender su potencial transformador en todos los sectores e industrias. Al finalizar el curso estarás en capacidad de diseñar tus propios grandes modelos de lenguaje (LLM) con datos únicos en un entorno privado y seguro.\n\n\n¿Qué es Azure Open AI?\nAzure OpenAI es un servicio de inteligencia artificial ofrecido por Microsoft Azure en colaboración con OpenAI. Permite a empresas y desarrolladores acceder a modelos de inteligencia artificial de última generación para crear aplicaciones avanzadas y resolver problemas complejos. Las empresas quieren tener modelos hechos a su medida para usar en sus tareas y soluciones. Y Azure OpenAI es capaz de satisfacer esa necesidad, proporcionando un espacio seguro y privado en el que trabajar con datos e información propia que no va a ser reutilizada para entrenar ningún modelo que reutilicen otras compañías.\n\n\n¿Qué es la API de Azure OpenAI?\nLa API de Azure OpenAI es un servicio en la nube que permite a cualquier persona integrar inteligencia artificial avanzada en sus aplicaciones. Ofrece acceso a modelos de procesamiento de lenguaje natural, visión por computadora y otros modelos de inteligencia artificial a través de una interfaz de programación fácil de usar. La API de Azure OpenAI facilita la construcción de aplicaciones y herramientas inteligentes que interactúan con los usuarios de manera más natural y eficiente, mejorando la experiencia del usuario y la eficiencia de los procesos.\n\n\n¿En qué va a ayudarte este curso?\nDominio de Fundamentos Esenciales de IA Generativa. Comprenderás los pilares fundamentales de la IA generativa, como \"Fine-Tuning\" para ajustar modelos preentrenados, el funcionamiento de los LLM (Large Language Models) o el rol de los tokens en el procesamiento del lenguaje. Entender los conceptos principales alrededor de la tecnología te proporcionará los cimientos sólidos para sentirte cómodo al meterte de lleno en los módulos prácticos del curso. La inteligencia artificial generativa tiene la capacidad de crear contenido nuevo y original, lo que la convierte en una herramienta valiosa para varias aplicaciones creativas y empresariales.\nCreando Espacios de Desarrollo Personalizados en Azure Open AI. Aprenderás a utilizar Azure OpenAI para desarrollar modelos de IA generativa adaptados a necesidades empresariales concretas. Explorarás cómo este entorno proporciona seguridad y privacidad al trabajar con datos propios, permitiendo diseñar soluciones personalizadas que no reutilicen información. Desplegarás modelos de IA ajustando parámetros y características para obtener resultados óptimos. Adquirirás habilidades técnicas para personalizar el funcionamiento de los modelos, preparándolos para implementaciones reales y eficaces.\nImplementar técnicas de personalización. Te sumergirás en el proceso de personalización de modelos generativos. Aprenderás a entrenar modelos con tus propios conjuntos de datos, infundiendo una personalidad única y distintiva en la IA. Explorarás diversas estrategias para lograr este objetivo, comprendiendo que no hay un único camino para conseguir el resultado esperado. Serás capaz de moldear la IA de acuerdo a tus objetivos y necesidades, permitiendo crear soluciones efectivas y auténticas que reflejen tu visión y conocimiento. Al finalizar el curso, estarás preparado para dotar a los modelos con características y comportamientos específicos, creando así una herramienta altamente adaptable y potente.\nTransformar Ideas en realidad con la API de Azure OpenAI. Utilizarás la API de Azure OpenAI para integrar tus modelos en aplicaciones y soluciones reales. Descubrirás cómo hacer que tus innovadoras ideas cobren vida digital, extendiendo la inteligencia generativa a distintas plataformas y contextos. Serás capaz de implementar tus propias soluciones en el mundo real, maximizando el impacto de la IA generativa en múltiples entornos digitales y empresariales.\nResolver Casos de Uso reales que aporten valor al mundo empresarial. Explorarás ejemplos concretos de cómo la IA generativa transforma las operaciones empresariales. Aprenderás sobre casos de uso reales y específicos de sectores como recursos humanos, ventas, entre otros. Estos ejemplos prácticos mostrarán cómo la IA genera un impacto significativo en múltiples industrias. Descubrirás cómo innovar, ahorrar costes y lograr resultados excepcionales al aplicar la IA generativa en situaciones del mundo real, lo que te inspirará a utilizar esta tecnología para la mejora continua de la eficiencia y la innovación en tu propia empresa o en tus proyectos.\n\n\nContenido y Descripción General\nEl curso es apto para todos los niveles. Empezaremos definiendo los conceptos básicos de la inteligencia artificial generativa (LLMs, Tokens, Prompt Engineering, Modelos, etc.) y entendiendo en qué puede ayudarnos en nuestra vida laboral o en nuestros proyectos. Aunque eso no significa que no tratemos funcionalidades avanzadas o que nos quedemos en el nivel inicial, de hecho el curso va incrementando la dificultad y en los ejercicios prácticos de cada módulo iremos utilizando todo lo aprendido en las clases anteriores.\nTodo el proceso de aprendizaje gira entorno a la aplicación de la inteligencia artificial generativa en el mundo empresarial, y te proporcionará una inmersión completa en la tecnología, abordando desde los conceptos fundamentales hasta la implementación práctica en situaciones de negocio reales. A través de módulos que abarcan desde la comprensión esencial de la IA generativa y su aplicación en Azure OpenAI para desarrollos personalizados, hasta el diseño y personalización de modelos, integración en aplicaciones mediante la API, y ejemplos tangibles de transformación empresarial, obtendrás conocimientos y habilidades para dominar esta tecnología y aprovechar su potencial innovador en diversos contextos profesionales.",
      "target_audience": [
        "Profesionales y estudiantes interesados en la Inteligencia Artificial Generativa y su aplicación en el entorno empresarial.",
        "Estudiantes que quieran destacar y convertirse en expertos en una habilidad cada vez más relevante en el mercado laboral.",
        "Todos quienes deseen descubrir cómo construir grandes modelos de lenguaje (LLM) personalizados con datos únicos y en un entorno privado y seguro.",
        "Interesados en aprovechar la IA Generativa para mejorar procesos, innovar y transformar soluciones digitales en diversas industrias"
      ]
    },
    {
      "title": "Translation Technology I",
      "url": "https://www.udemy.com/course/translation-technology/",
      "bio": "Translation Technology I: Free MOOC (English/Chinese translation) (English version) (Modules 1-6)",
      "objectives": [],
      "course_content": {
        "Introduction to Translation Technology": [
          "Introduction to Translation Technology"
        ],
        "Module 2: Machine Translation": [
          "Module 2. Machine Translation"
        ],
        "Module 3: Computer-aided Translation": [
          "Module 3. Computer-aided Translation"
        ],
        "Module 4. Evaluation of Machine Translation Output": [
          "Module 4. Evaluation of Machine Translation Output"
        ],
        "Module 5. Translation in Memsource: Overview": [
          "Module 5. Translation in Memsource: Overview"
        ],
        "Module 6. Translation in Memsource: Translation Memory": [
          "Module 6. Translation in Memsource: Translation Memory"
        ]
      },
      "requirements": [
        "No prerequisites for taking the course. You will learn everything you need to know."
      ],
      "description": "This course provides learners with basic training in translation technology, helping them to acquire basic knowledge about computer-aided translation (CAT), machine translation (MT), concepts and available technology for translation, and hands-on experience of applying computer tools to enhance translation productivity. The role which computer technology plays in translation will be discussed.\n\n\nCourse Aim\nThis course aims to equip students with basic knowledge and skills in translation technology.\nCourse Intended Learning Outcome\n\n\nUpon completion of this course, you will be able to:\n1. Describe basic concepts of translation technology (including MT and CAT);\n2. Explain the practice of the variety of computer tools which translation technology could offer;\n3. Apply available MT systems and CAT tools and select appropriate tools for particular translation tasks; and\n4. Identify the strengths and weaknesses of computer technology and\n5. Edit the source and target texts to optimize efficiency of computer technology and translation quality.\n\n\nCourse Content / Topics Covered\nTranslation Technology I:\n•Module 1. Introduction to Translation Technology\n•Module 2. Machine Translation\n•Module 3. Computer-aided Translation\n•Module 4. Evaluation of Machine Translation Output\n•Module 5. Translation in Memsource: Overview\n•Module 6. Translation in Memsource: Translation Memory\n\n\nThis course is suitable for the general public, especially:\n-language learners;\n-language users;\n-translators; and\n-interpreter.\n\n\nNo prerequisites for taking the course. You will learn everything you need to know.",
      "target_audience": [
        "language users",
        "language learners",
        "Translators",
        "Interpreters"
      ]
    },
    {
      "title": "【初学者向け】データサイエンティスト検定（リテラシーレベル）最短合格を目指す対策講座！データ人材への第一歩を踏み出そう！",
      "url": "https://www.udemy.com/course/data-scientist-test/",
      "bio": "話題の資格「データサイエンティスト検定」に挑戦しよう！初学者に向けた分かりやすい解説！文系出身者や非エンジニアでも安心！さらに、復習問題や用語集など充実の学習コンテンツを用意。AI・ビッグデータの時代に強いビジネスパーソンになろう！",
      "objectives": [
        "データサイエンスを基礎から一歩ずつ学ぶことができます。",
        "データサイエンティスト検定（リテラシーレベル）の資格を取得することによって、キャリアアップやキャリアチェンジのための強い武器を身に着けることができます。",
        "数理的思考に加え、コンピュータを用いた技術やビジネス実装など、幅広い分野を一気に学習することができます。",
        "流行りの職業である、データサイエンティストとしての実力を身に着け、市場価値を高めて高単価の案件獲得のための足掛かりを手にします。",
        "AIに対する理解や知識が身に付き、持続的なAI活用のノウハウを獲得することができます。",
        "時流に沿った、なおかつこれから一層重要視される確実なデータ思考力が身に付きます。"
      ],
      "course_content": {
        "はじめに": [
          "データサイエンティスト検定とは？学習メリットや学習の進め方"
        ],
        "確率と統計の基礎 1": [
          "場合の数",
          "集合論",
          "条件付き確率",
          "統計学入門1",
          "統計学入門2",
          "復習テスト"
        ],
        "確率と統計の基礎 2": [
          "線形代数の基礎",
          "線形変換",
          "微分・積分",
          "復習テスト"
        ],
        "データの基礎分析": [
          "加工と可視化",
          "アソシエーション分析",
          "復習テスト"
        ],
        "機械学習": [
          "機械学習の概要",
          "機械学習手法",
          "復習テスト"
        ],
        "データサイエンス応用": [
          "統計（推定）",
          "統計（検定）",
          "領域ごとのデータ処理",
          "復習テスト"
        ],
        "環境構築": [
          "システム企画",
          "システム設計1",
          "復習テスト"
        ],
        "データの取り扱い": [
          "データの収集",
          "データの構造",
          "データの蓄積",
          "復習テスト"
        ],
        "データの加工": [
          "データの加工1",
          "データの加工2",
          "復習テスト"
        ],
        "プログラミング": [
          "基礎プログラミング",
          "アルゴリズムとテスト",
          "バージョン管理",
          "復習テスト"
        ]
      },
      "requirements": [
        "データサイエンスに馴染みのない初学者でも資格合格が十分可能なよう、一つ一つ丁寧に解説しています。",
        "文系出身者や、理数分野に苦手意識を持っている場合でも、導入のハードルを下げて学習をしやすくしています。"
      ],
      "description": "【データサイエンティスト検定（リテラシーレベル）合格へ導く！包括的対策講座】\n\n\nAI、ビッグデータブームの昨今、データサイエンティスト検定に合格して、市場価値の高いスキルを手に入れよう！\n当講座は、文系や非エンジニアの方も安心して学べる、体系的なわかりやすさにこだわった対策講座です。\n独学ではイメージしにくい抽象概念や、複雑な検定など丁寧に一つひとつ解説！\nデータサイエンス、エンジニアリング、ビジネス領域それぞれで重要なエッセンスをたくさん詰め込んでおり、試験を合格するだけの基礎的な実力を身に付けることができます。\n\n\n本講座の特徴は以下の通りです。\n\n\n1. スキルチェックシート完全準拠\n一般社団法人データサイエンティスト協会は、データサイエンティストに必要なスキルを一つ一つ細かく定義した、\nスキルチェックシートを公開しています。\n最新のスキルチェックシートに準拠した内容になっており、出題範囲を完全カバー！\n\n\n2. 視覚的でわかりやすいスライド型動画解説\n複雑な概念も、図解やアニメーションを使って直感的に理解できます。\nまた、体系的に一歩一歩学べるチャプター構成で、個人で学習する際もつまづきにくい！\n\n\n3. 文系・非エンジニアフレンドリー\n専門用語を噛み砕いた説明で、技術的バックグラウンドがなくても安心して学習できます。\n実務でプログラミングをしない方も、最低限の知識を身に付けることで、キャリアの広がりを期待できたり、\nマネジメントに活かせます。\n\n\n4. 理解度チェック問題\n各チャプター終了時に確認問題を用意。学習内容の定着度を随時確認できます。\n問題を解くことで、理解度をさらに高める効果もあります。\n\n\n5. 重要用語集＆マインドマップ付き\n試験合格に必要な重要単語をシンプルに分かりやすく解説した用語集と、\n用語間の関連を示したマインドマップを用意。\n学習のスタート時から、試験直前の復習まで、\n試験合格を目指すあなたにとって、最高の伴走パートナーになります。\n\n\n6. 数理問題集\n試験に出てくる基礎的な計算問題や、数学的な概念を問う問題も完全カバー！\n数学に苦手意識のある方でも少しずつ実力が付けられる難易度とボリュームです。\n\n\n当講座で、データサイエンティスト検定合格への道筋を確実なものに。AI、ビッグデータ時代を生き抜くスキルを身につけ、キャリアの可能性を広げましょう。初心者の方から、知識の再確認をしたい方まで、幅広い層にお勧めです。\n\n\n\n\nデータサイエンティスト検定合格への第一歩、今すぐ始めましょう！",
      "target_audience": [
        "データ分析企業や、データ分析職種への転職を目指す方",
        "データサイエンスに興味を持つ方",
        "データサイエンティスト検定に効率的に最短での合格を目指す方",
        "流行りの技術や考え方、IT分野へのトレンドに興味がある方",
        "数学が得意で、仕事に能力を活かしたい方",
        "プロジェクトマネージャーや経営層など、データサイエンスプロジェクトをリードする非技術者",
        "マーケティング担当者や営業職でデータ活用に携わる方"
      ]
    },
    {
      "title": "Machine Learning e Data Science in Python: il Corso Completo",
      "url": "https://www.udemy.com/course/machine-learning-pratico/",
      "bio": "Impara a creare algoritmi di Machine Learning con Python e Scikit-learn - Regressione, Classificazione, Clustering",
      "objectives": [
        "Padroneggiare il machine learning con Python",
        "Analisi di un dataset per estrapolare informazioni utili",
        "Funzionamento dei modelli di machine learning più diffusi",
        "Utilizzare il machine learning su problemi reali",
        "Differenza tra modelli supervisionati e non supervisionati",
        "Scegliere ed ottimizzare un modello di machine learning",
        "Eseguire predizioni e classificazioni partendo dai dati",
        "Eseguire clustering per raggruppare automaticamente dati simili",
        "Imparare ad utilizzare Pandas e Scikit-learn",
        "Lavorare con iPython e Jupyter Notebook"
      ],
      "course_content": {
        "Introduzione": [
          "Benvenuto nel futuro !",
          "Perchè l'AI è hot ?",
          "Cosa è il machine learning...",
          ".. e la data science ?",
          "Come funziona il machine learning ?",
          "Le tecniche del machine learning",
          "Scegli il tuo ambiente di lavoro",
          "Prima di cominciare",
          "Domande Frequenti"
        ],
        "Il Dataset": [
          "Dataset strutturati",
          "Dataset non strutturati",
          "Analisi di un dataset con Pandas",
          "Tipi di dati",
          "Label encoding e one-hot encoding",
          "Gestire dati mancanti",
          "Portare il dataset sulla stessa scala",
          "Normalizzazione e standardizzazione di un dataset con Pandas",
          "Splitting del dataset",
          "Train/Test split con scikit-learn"
        ],
        "Apprendimento supervisionato - Regressione": [
          "Regressione lineare",
          "La funzione di costo",
          "L'apprendimento dei pesi tramite Gradient Descent",
          "Regressione lineare semplice in Python",
          "Regressione lineare multipla",
          "Regressione lineare multipla in Python",
          "Regressione polinomiale",
          "Regressione polinomiale in Python"
        ],
        "Regolarizzazione e modelli regolarizzati": [
          "Il problema dell'overfitting",
          "Riconoscere l'overfitting",
          "Regolarizzazione L1 ed L2",
          "Ridge, Lasso ed ElasticNet"
        ],
        "Apprendimento supervisionato - Classificazione": [
          "Regressione logistica",
          "Regressione logistica in Python",
          "Classificazione multiclasse",
          "Classificazione OneVSAll con scikit-learn"
        ],
        "Modelli di classificazione non lineari": [
          "K-Nearest Neighbor (K-NN)",
          "K-NN in Python",
          "Alberi decisionali",
          "Alberi decisionali in Python",
          "Foreste casuali",
          "Foreste casuali in Python",
          "Macchine a vettori di supporto (SVM)",
          "SVM in Python",
          "Kernel SVM",
          "Kernel SVM in Python",
          "Reti neurali artificiali (ANN)",
          "Addestramento di una rete neurale tramite backpropagation",
          "Percettrone Multistrato in Python"
        ],
        "Tecniche di validazione ed ottimizzazione": [
          "Batch, Stochastic e Mini Batch Gradient Descend",
          "Stochastic e Mini Batch Gradient Descend con scikit-learn",
          "Tecniche di cross validation",
          "K-fold cross validation in Python",
          "Ottimizzazione degli iperparametri",
          "Grid search e Random search in Python"
        ],
        "Apprendimento non supervisionato - Clustering": [
          "K-means Clustering",
          "K-means in Python",
          "Clustering Gerarchico",
          "Clustering Gerarchico in Python",
          "DBSCAN",
          "DBSCAN in Python"
        ],
        "Riduzione della dimensionalità": [
          "Principal Component Analysis",
          "PCA per visualizzare il dataset",
          "Selezionare il numero di componenti principali",
          "PCA per velocizzare l'addestramento",
          "Kernel PCA",
          "Linear Discriminant Analysis",
          "Confrontare PCA e LDA"
        ],
        "Sezione conclusiva": [
          "I tuoi prossimi passi",
          "Scegli la tua Strada !"
        ]
      },
      "requirements": [
        "Basi di matematica da scuola superiore",
        "Conoscere un qualsiasi linguaggio di programmazione può aiutare, ma non è indispensabile in quanto il corso contiene una sezione con tutti i prerequisiti necessari"
      ],
      "description": "Fai un passo verso il futuro: AI, Machine Learning e Data Science.\nSai cosa accomuna il successo dei più grandi colossi del web come Google, Amazon e Facebook ?\nL'utilizzo che hanno fatto del machine learning.\nIl machine learning è la branca dell'intelligenza artificiale che ha lo scopo di insegnare ai computer ad apprendere autonomamente, senza essere esplicitamente programmati.\nIl machine learning non è una novità, ma è finito sotto la luce dei riflettori solo con il nuovo millennio, per due motivi:\nL'enorme quantità di dati oggi disponibile sul web.\nIl progresso della tecnologia e il crescente aumento della potenza di calcolo.\nQuesti due fattori, uniti alle sue innumerevoli applicazioni commerciali, stanno contribuendo alla crescita vertiginosa del machine learning che sta trascinando con se l'intero campo dell'intelligenza artificiale.\nIn questo corso pratico imparerai come funziona il machine learning e come utilizzarlo in maniera pratica, utilizzando il linguaggio Python e librerie popolari come Scikit-learn, Pandas e PyPlot.\nVuoi dare una svolta alla tua carriera ?\n\nL'esperto di machine learning è la professione del futuro e Linkedin lo conferma; secondo una loro recente ricerca il Machine Learning Engineer è la nuova figura più ricercata dalle aziende con un tasso di crescita di quasi il 1000% negli ultimi 5 anni ed è subito seguito dal Data Scientist.\nAl termine di questo corso avrai acquisito l'esperienza pratica e le intuizioni teoriche necessarie per lanciare la tua carriera in entrambe queste due nuove professioni.\nVuoi fondare la tua startup nel campo dell'AI ?\nIl valore totale del mercato dell'intelligenza artificiale nel 2016 era di 1.3 miliardi di dollari; secondo una ricerca di un'importante società di analisi americana il suo valore per il 2025 potrebbe superare il 60 miliardi.\nL'AI è la next big thing e il machine learning ne è il cuore pulsante.\nSeguendo questo corso otterrai una visione generale del machine learning e come questo si lega all'intelligenza artificiale e potrai utilizzare queste tue nuove conoscenze per dare vita al tuo business.\nA chi è rivolto questo corso ?\nQuesto corso fa per te se:\nVuoi imparare le principali tecniche del machine learning e metterle in pratica da subito, sapendo cosa avviene sotto ogni algoritmo ma senza perderti in matematicismi eccessivi.\nQuesto corso non fa per te se:\nHai studiato tanta matematica e vuoi continuare a vederne tanta, sei più per la teoria che per la pratica, ami i formalismi e preferisci apprendere da chi ha almeno il doppio dei tuoi anni.\n\nNon sai (ancora) programmare e non conosci il linguaggio Python ?\nNon preoccuparti, ti insegneremo tutto noi durante il corso senza dare nulla per scontato ! L'unica cosa di cui hai bisogno per affrontare questo corso è qualche base di matematica da scuola superiore.\nI contenuti del corso\nInizieremo il corso esplorando in breve il vasto campo dell'intelligenza artificiale, come il machine learning si inserisce al suo interno e come quest'ultimo è legato al data science. Costruiremo insieme il tuo ambiente di lavoro, in base alle tue personali esigenze e preferenze.\nSubito dopo cominceremo a sporcarci le mani lavorando sul nostro primo dataset. Vedremo insieme le principali tecniche di data preprocessing e feature engineering, ovvero come ottimizzare e manipolare un dataset per renderlo un buon input per un algoritmo di machine learning.\nDopo aver appreso come lavorare con un dataset potremo iniziare a parlare di machine learning.\nTi saranno presentati i due principali tipi di apprendimento:\nApprendimento supervisionato.\nApprendimento non supervisionato\nEseguiremo una regressione per stimare il valore di un'abitazione in base a diverse sue caratteristiche, come metratura, piani e numero di stanze,  e studieremo brevemente i principali modelli per questo tipo di problema:\nRegressione lineare semplice\nRegressione polinomiale\nRegressione multipla.\nAffronteremo il problema di overfitting e come bias e varianza lo controllano, per contrastarlo studieremo i principali modelli di regressione regolarizzati:\nLasso\nRidge Regression\nElasticnet\nAl termine di questa sezione avrai ottime basi di regressione e saprai come creare i tuoi modelli autonomamente, quindi potremo passare al secondo tipo di problema: la classificazione.\nEseguiremo la nostra prima classificazione, utilizzando un dataset contenente immagini di cifre scritte a mano (MNIST).\nCominceremo con un modello di classificazione lineare: la regressione logistica, vedendo come questa può essere utilizzata per classificare esempi tra due classi o classi multiple.\nProseguiremo osservando i limiti di modelli lineari e i vantaggi di un approccio non lineare, quindi vedremo i principali modelli di questa nuova categoria:\nAlberi e foreste\nKernel SVM\nNearest neighbors\nReti neurali artificiali\nA questo punto saprai già come costruire i tuoi modelli per i due principali problemi dell'apprendimento supervisionato: regressione e classificazione.\nConcluderemo la sezione con tecniche di debugging e ottimizzazione per rendere i tuoi modelli robusti e velocizzare la fase di addestramento.\nNella sezione successiva passeremo alla seconda categoria di apprendimento: l'apprendimento non supervisionato.\nAffronteremo il problema del clustering, ovvero come creare automaticamente dei gruppi di dati riconoscendo delle caratteristiche condivise all'interno del dataset;  a questo scopo studieremo l'algoritmo di clustering più diffusi, sia in ambito accademico che industriale:\nK-Means\nClustring Gerarchico\nDBSCAN\nTecniche di Riduzione della Dimensionalità si rivelano incredibilmente utili quando lavoriamo con dataset che hanno un numero elevato di dimensioni, sia per poterli visualizzare graficamente, sia per poter velocizzare la fase di addestramento. In questa sezione parleremo proprio di questi argomenti.\nTermineremo il corso con alcuni consigli su come proseguire, raccomandazioni su libri da leggere per approfondire la parte teorica e competizioni Kaggle a cui partecipare per affinare le skills pratiche.",
      "target_audience": [
        "Programmatori e sviluppatori che vogliono trovare lavoro nei settori di machine learning e intelligenza artificiale",
        "Imprenditori e startupper che vogliono fondare una nuova azienda tecnologica nel campo dell'intelligenza artificiale"
      ]
    },
    {
      "title": "Ciência de Dados para Iniciantes com Projetos Reais",
      "url": "https://www.udemy.com/course/python-data-science-para-iniciantes/",
      "bio": "Aprenda a realizar projetos reais em Data Science utilizando Python com aulas 100% Hands on!",
      "objectives": [
        "Entenda os fundamentos da linguagem Python e como eles se aplicam à ciência de dados.",
        "Pratique ciência de dados interativa usando notebooks Jupyter",
        "Analise dados usando bibliotecas Python, como pandas e numpy",
        "Demonstrar proficiência na solução de problemas de ciência de dados da vida real",
        "Realizar dois projetos reais que podem ser aplicados a qualquer empresa",
        "Aprender de forma pratica com laboratorios 100% hands on"
      ],
      "course_content": {},
      "requirements": [
        "Conhecimento basico de Python"
      ],
      "description": "Curso Ciência de Dados para Iniciantes + Projetos Reais\n\n\nSe você está procurando por um curso de Ciência de Dados para Iniciantes com Python, você veio ao lugar certo!\nEste curso é ideal para quem está começando na área de Data Science e quer aprender a utilizar a linguagem Python para análise de dados. Nenhuma experiência anterior em programação é necessária.\nA Ciência de Dados é uma das profissões mais quentes do século 21 e os dados são o centro da economia digital atual. Com este curso, você estará preparado para dar o primeiro passo em sua jornada de Data Science e aprenderá as habilidades essenciais para criar projetos reais de análise de dados.\nPor que Python é tão popular na Ciência de Dados?\nPython é uma das linguagens de programação mais utilizadas na área de Ciência de Dados e é frequentemente citada como uma das principais habilidades que os recrutadores procuram em um Cientista de Dados.\nA sua popularidade deve-se em grande parte à sua biblioteca dedicada para análise de dados e modelagem preditiva, além de sua comunidade forte e engajada.\nUm Cientista de Dados é responsável por analisar e interpretar dados usando estatística, ciência da computação e conhecimento específico de cada domínio.\nCom o grande volume de dados gerados atualmente, a habilidade de utilizar esses dados para tomar decisões informadas é essencial.\nAo longo deste curso, você aprenderá tudo o que precisa para criar dois projetos reais em Data Science utilizando Python.\nNão perca a oportunidade de dar o primeiro passo em sua jornada de Data Science - inscreva-se agora no Curso Ciência de Dados para Iniciantes Python!\n\n\nLEMBRE-SE… Estou tão confiante de que você vai adorar este curso que estamos oferecendo uma garantia TOTAL de devolução do dinheiro por 30 dias! Inscreva-se hoje com risco ZERO pra você!\n\n\nTe vejo na primeira aula :)",
      "target_audience": [
        "Estudantes da Linguagem de programacao Python",
        "Interessados em Data Science com Python",
        "Alunos que desejam aumentar seu conhecimento em Data Science"
      ]
    },
    {
      "title": "Data Science: do Dado à Tomada de Decisão",
      "url": "https://www.udemy.com/course/data-science-para-desenvolvedor-do-dado-a-tomada-de-decisao/",
      "bio": "Guia para iniciantes em Big Data. Aqui você compreenderá todo o processo de geração de insights a partir de dados.",
      "objectives": [
        "Entender qual é o processo de Data Science do início ao fim",
        "Ser capaz de explorar e analisar bases de dados",
        "Construir e avaliar modelos preditivos",
        "Contar histórias a partir de dados e envolver audiências",
        "Identificar oportunidades de carreira em Data Science"
      ],
      "course_content": {
        "1. Introdução": [
          "1.1 Introdução ao Curso de Data Science",
          "1.2 O que é Data Science?",
          "1.3 Aplicações de Data Science",
          "1.4 Que profissão é essa?",
          "1.5 Organizações Data Driven"
        ],
        "2. Cadeia de Valor em Analytics": [
          "2.1 Introdução / Cadeia de Valor em Analytics",
          "Cadeia de valor em Analytics",
          "2.2 Qualidade dos Dados",
          "Qualidade dos dados",
          "2.3 Tipos de Análises",
          "Tipos de análises",
          "2.4 Ferramentas"
        ],
        "3. Data Engineering": [
          "3.1 Introdução / Modelos de Computação Distribuída",
          "Modelos de computação distribuída - Introdução",
          "3.2 Map Reduce",
          "MapReduce",
          "3.3 Dremel",
          "Dremel",
          "3.4 BSP e Pregel",
          "BSP e Pregel",
          "3.5 Spark",
          "Spark",
          "3.6 Considerações Finais / Modelos de Computação Distribuída"
        ],
        "4. Aprendizado de Máquina": [
          "4.1 - O que é Aprendizado de Máquina",
          "O que é aprendizado de máquina?",
          "4.2 - Os Componentes do Aprendizado",
          "Os componentes do aprendizado",
          "4.3 - Aprendizado Supervisionado",
          "Aprendizado supervisionado",
          "4.4 - Aprendizado Não Supervisionado",
          "Aprendizado não supervisionado",
          "4.5 - Avaliação",
          "Avaliação",
          "4.6 - Ferramentas"
        ],
        "Storytelling": [
          "5.1 Introdução",
          "5.2 Princípios do Storytelling",
          "5.3 Visualizações",
          "Exercícios sobre storytelling"
        ]
      },
      "requirements": [
        "Programação básica em Python (desejável)"
      ],
      "description": "Não existe crise no mercado de Data Science e Big Data. Pelo contrário: as empresas estão começando a entender como os processos de coleta e análise de dados são cruciais para que tomem melhores decisões de negócios. Por isso, só aumenta a busca por cientistas de dados, profissionais especializados em analisar dados e construir algoritmos e modelos que geram conhecimento valioso para as empresas.\nSe você é um desenvolvedor interessado em dar os primeiros passos para se tornar um cientista de dados, profissão tão valorizada (e rara!) no mercado, este curso é perfeito para você. Fizemos um detalhado guia sobre os conceitos, processos e ferramentas que um cientista de dados precisa dominar.\nAprenda as Principais Técnicas de Data Science neste Passo a Passo para Iniciantes\nEntenda qual é o processo de Data Science do início ao fim;\nCompreenda os diferentes tipos de análise de dados (descritiva, exploratória, preditiva);\nAprenda a construir e avaliar modelos preditivos (Aprendizado de Máquina);\nDescubra como contar histórias a partir de dados e envolver audiências (Storytelling);\nIdentifique oportunidades de carreira em Data Science.\n\n\nEstrutura do Curso e Carga Horária\nO curso tem duração de 3 horas e é dividido em 5 seções:\nIntrodução – O que é Data Science? / Aplicações de Data Science / Que profissão é essa? / Organizações Data Driven\nAnálise exploratória – Introdução / Qualidade dos dados / Estatística básica / Visualização de resultado / Ilustração do processo\nEngenharia de Dados – Modelo de computação distribuída / MapReduce / Dremel / BSP + Pregel / Spark\nAprendizado de máquina – Introdução / Supervisionado e não supervisionado / Modelos e aplicações / Avaliação / Sci-kit\nStorytelling – Introdução / Princípios de storytelling / Visualização de dados\nAlém disso, ao final de cada seção é proposto um exercício para que você coloque em prática todo o aprendizado adquirido com as aulas.",
      "target_audience": [
        "Qualquer pessoa que possua uma noção básica de programação e deseje entender de forma ampla o que é Data Science, quais seus benefícios e aplicações",
        "Interessados em adquirir um conhecimento mais aprofundado sobre Data Science para interagir com profissionais da área",
        "Profissionais de computação ou estatística que desejam se atualizar"
      ]
    },
    {
      "title": "Data Science & genAI on Sustainable Development Goals (SDGs)",
      "url": "https://www.udemy.com/course/data-science-on-sustainable-development-goals/",
      "bio": "Explore SDGs and Scope 3 with Generative AI. Learn data science basics and spark your sustainability journey",
      "objectives": [
        "Understand the Sustainable Development Goals (SDG)",
        "Get a quick start for visualising SDGs in Python",
        "Perform initial data science practice on combined SDG data sets",
        "Get inspired for your next step and contribution towards sustainability!"
      ],
      "course_content": {
        "Objective Lecture and SDGs": [
          "Lecture Objective",
          "Overview SDG goals",
          "SDG goals and indicators data sets"
        ],
        "Data Science Overview": [
          "Introduction Data Science",
          "Data Science Method CRISP-DM",
          "Data Science Python Environment"
        ],
        "Visualizations on SDG Indicator data": [
          "Time Series Visualization",
          "World Map Visualization",
          "Tree View Visualisation of SDG Goals"
        ],
        "Data Analytics on SDG indicators": [
          "Multiple SDGs Data Preparation",
          "Multiple SDGs Handling Missing Data",
          "Multiple SDGs Analytics"
        ],
        "Whats Next - How can I contribute": [
          "Whats Next - How can I contribute"
        ],
        "Using Generative AI and understand SCOPE 3 Carbon emissions": [
          "Overview on learning Scope three and which generative AI techniques",
          "What is Scope 3 emissions and Power Point CoPilot example",
          "What is Scope 3 learning from pdf - Notebook LM example",
          "Notebook LM output on Scope 3",
          "Scope 3 Tutor via an Avatar",
          "Hello Gen - output example of an avatar",
          "Digital Twin in action with yourself - Introduction Riesling Inc case example"
        ],
        "Case Example 'Riesling Inc' and Scope 3 using generative AI tools": [
          "Build a Riesling Inc Scope graph - using Mermaid AI",
          "Understanding the base line CO2 conversion - first Excel via ChatGPT",
          "Going deeper on Riesling Inc Scope 3numbers - Perplexity Deep Research",
          "Building a dynamic Riesling Inc Homepage - Perplexity App example",
          "Improve the Webpage by Vibe coding - Copilot / Anthropic example"
        ]
      },
      "requirements": [
        "Basic programming knowledge - the Python parts should give you a starting point",
        "The inital capability of analysing data sets. Analysis can be done in any other tool or language as well."
      ],
      "description": "The Sustainable Development Goals (SDGs) are 17 global goals designed to be a \"blueprint for achieving a better and more sustainable future for all.\" The goals to be achieved by 2030 are an urgent call for action by all countries—and by each of us.\nIn the first part of the course, we highlight the SDGs and analyze the SDG indicators that track the current global status. Did you know that there are 17 goals backed up and monitored by over 230 indicators? Each indicator measures the progress of all countries, sometimes over decades—a lot of data points to analyze. The lecture balances basic principles with crisp data science practice, covering Python-based analysis, visualization techniques, and cross-analysis of indicators to give you both context and hands-on skills.\nIn the second part, we go one step further—diving into Scope 3 emissions, the hidden emissions in a company’s value chain that often make up the majority of its footprint. To make this complex topic more engaging, we explore it through modern generative AI techniques: PowerPoint Co-Pilot to structure ideas, ChatGPT for explanations, avatars to bring concepts alive, Notebook LM for organizing knowledge, Mermaid AI for visualizations, Perplexity for deep research, and vibe coding for playful exploration. All of this comes together in a case study of our fictional winery, Riesling Inc. From vineyard to bottle, you’ll see how Scope 3 emissions accumulate and how AI helps us map and understand them.\nThe overall objective of the course is to give you a quick start in sustainability data science practice and inspire you to contribute towards our joint SDG goals—while also discovering how generative AI can be a powerful companion in exploring and understanding complex global challenges.",
      "target_audience": [
        "Data analytics performer interested in SDG and its data sets",
        "People interested in analyzing sustainability data sets",
        "People interested in contributing in the big SDG goals"
      ]
    },
    {
      "title": "Engenharia de Dados com Databricks, Spark e PySpark",
      "url": "https://www.udemy.com/course/engenharia-de-dados-com-databricks-spark-e-pyspark/",
      "bio": "Aprenda as Ferramentas Essenciais para Manipulação e Análise de Grandes Volumes de Dados",
      "objectives": [
        "Configurar e Gerenciar Clusters no Databricks",
        "Manipular e Transformar Dados com PySpark",
        "Implementar Pipelines de Dados com Delta Lake",
        "Implementar Arquitetura Medallion, Lakehouse e Delta Lake",
        "Implementar Rotinas de manutenção (Vacum, Optimize, repartition, time travel entre outras)"
      ],
      "course_content": {
        "Introdução": [
          "Apresentação do instrutor",
          "Síntese do curso de Pyspark com Databricks",
          "Boas Vindas, Dicas e Material para Download",
          "Notebooks Adaptados para Databricks Free Edition"
        ],
        "Preparando o Ambiente": [
          "O que é o Databricks?",
          "Criando sua Conta Databricks Comunnity (Free)",
          "Conhecendo DBFS (Databricks File System )",
          "Montagem DBFS (Databricks File System )",
          "Importando arquivos para o treinamento"
        ],
        "Fundamentos de Big Data": [
          "5 V´s de Big Data",
          "Q que é Data Lake",
          "Q que é Lakehouse",
          "Checklist para Implementar o Delta Lake",
          "Diferença DW e Data Lake",
          "Arquitetura Medallion",
          "Exemplo de Esrtruturação de Lakehouse (Medallion)",
          "Arquitetura Lambda",
          "SCD (Slow Changing Dimensions)",
          "Tipo de arquivos (Datalake / Lakehouse)",
          "Comparativo Parquet e Delta Parquet",
          "Planejando seu Datalake / Lakehouse"
        ],
        "Instrodução Apache Spark e Pyspark": [
          "O que é Apache Spark ?",
          "O que é Pyspark?",
          "Boas práticas de desenvolvimento",
          "Boas práticas de Estruturação",
          "Trabalhando com Dataframes",
          "Desempenho Pyspark"
        ],
        "Caso de uso": [
          "Apresentação do caso de uso (Analise de Vendas)"
        ],
        "Caso de Uso : Camada Bronze": [
          "Reativando Cluster Spark",
          "Lendo dados na Landing Zone e persistindo na Bronze Parte 1",
          "Lendo dados na Landing Zone e persistindo na Bronze Parte 2",
          "Movendo arquivos processados",
          "Gerenciamento de memória",
          "Overview Gerenciamento de memória"
        ],
        "Caso de Uso : Camada Silver - Transformações": [
          "Transformações Camada Silver",
          "Persistir dados Camada Silver no formato Parquet"
        ],
        "Caso de Uso : Camada Gold": [
          "Leitura de dados na camada Silver para criação de Delta Parquet",
          "Criação de tabela Delta Parquet dim_produto",
          "Criação de tabela Delta Parquet dim_categoria",
          "Criação de tabela Delta Parquet dim_segmento",
          "Criação de tabela Delta Parquet dim_fabricante",
          "Criação de tabela Delta Parquet dim_geografica",
          "Criação de tabela Delta Parquet dim_cliente",
          "Criação de tabela Delta Parquet fato_vendas",
          "Evidencias dos Arquivos Delta Parquet"
        ],
        "Caso de Uso : Camada Gold (incremental)": [
          "Importandos dados novos",
          "Carga Bronze",
          "Carga Silver",
          "Carga Gold (dimensões)",
          "Carga Gold (Fato)",
          "Orquestração de notebook com Workflow"
        ],
        "Consultas Otimizadas": [
          "Consultas Otimizadas",
          "Predicate Pushdown",
          "Broadcast Join"
        ]
      },
      "requirements": [
        "Noções basicas de engenharia de dados e big data",
        "Conhecimentos básicos de Python e SQL"
      ],
      "description": "Este curso abrangente foi projetado para fornecer aos alunos as habilidades necessárias para trabalhar com grandes volumes de dados utilizando as ferramentas mais avançadas do mercado.\n\n\nVocê aprenderá a:\n\n\nConfigurar e Gerenciar Clusters no Databricks: Entenda a arquitetura do Databricks e como configurar clusters para otimizar o processamento de dados.\nManipular e Transformar Dados com PySpark: Utilize PySpark para realizar transformações complexas e análises de dados em larga escala.\nImplementar Pipelines de Dados com Delta Lake: Aprenda a criar e gerenciar pipelines de dados robustos e eficientes utilizando Delta Lake.\nRealizar Análises Avançadas: Aplique técnicas de análise de dados para extrair insights valiosos dos seus dados.\nRotinas de Manutenção de Delta Lake: Implemente rotinas de manutenção para garantir a integridade e eficiência dos seus dados.\nArchitecture Medallion: Utilize a arquitetura Medallion para organizar e arquivar seus dados de forma eficiente.\nBoas Práticas de Desenvolvimento: Adote as melhores práticas para desenvolvimento de pipelines de dados.\n\n\nO que você vai aprender:\nFundamentos do Apache Spark e PySpark\nConfiguração e uso do Databricks\nCriação e gerenciamento de tabelas Delta\nTransformações e manipulações de dados com PySpark\nImplementação de pipelines de dados\nAnálise de dados\nRotinas de manutenção de Delta Lake\nBoas práticas de desenvolvimento\nArmazenamento Arquitetura Medallion.\nInscreva-se!\nComeçe a aprender e trabalhar com Databricks e Pyspark as poderosas ferramenta de Big Data e também uma das habilidades requeridas .\nAlém de diversas dicas pontuais no decorrer das aulas! Você terá:\n+ Suporte\n+Acesso Vitalício\n+Garantia do retorno de seu investimento em até 30 dias.\n\n\nMatricule-se!\nEsperamos você na primeira aula!\nGrande Abraço!",
      "target_audience": [
        "Estudantes e entusiastas que desejam aprender",
        "Este curso é ideal para engenheiros de dados, cientistas de dados e desenvolvedores que desejam aprimorar suas habilidades em manipulação e análise de grandes volumes de dados utilizando Databricks, Spark e PySpark.",
        "Profissionais que desejam consolidar conhecimentos"
      ]
    },
    {
      "title": "Image Recognition with Neural Networks From Scratch(FREE)",
      "url": "https://www.udemy.com/course/image-recognition-with-neural-networks-from-scratch/",
      "bio": "Write An Image Recognition Program in Python",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Functions and Their Computational Graphs": [
          "Functions and Their Computational Graphs"
        ],
        "Formalizing The Problem": [
          "Formalizing The Problem"
        ]
      },
      "requirements": [
        "Some basic knowledge of Python.(Supplemental \"Crash Course\" resources are provided to review/learn Python.)",
        "Some basics knowledge of Numpy.(Supplemental \"Crash Course\" resources to review/learn Numpy.)",
        "Some high school precalculus."
      ],
      "description": "THIS COURSE IS NOW FREE!!\n\n\nBecause of my busy schedule, I will not be able to maintain or support this course. Udemy requires that video content must be under 2 hours to make a course free. So I have unpublished most of the videos to satisfy the requirements. Please see my youtube channel for all lecture videos. Youtube Channel: @longnguyen8112\n\n\nEnjoy!\n\n\nThis is an introduction to Neural Networks. The course explains the math behind Neural Networks in the context of image recognition. By the end of the course, we will have written a program in Python that recognizes images without using any autograd libraries. The only prerequisite is some high school precalculus. Although the prerequisite is minimal, we will discuss many advanced topics including:\n1) functions and their computational graphs.\n2) neural networks\n3) conceptually understand the derivative and the gradient.\n4) gradient descent and backpropagation\n5) the multivariable chain rule\n6) mini-batch gradient descent\n\n\nTHIS COURSE IS NOW FREE!!\n\n\nBecause of my busy schedule, I will not be able to maintain or support this course. Udemy requires that video content must be under 2 hours to make a course free. So I have unpublished most of the videos to satisfy the requirements. Please see my youtube channel for all lecture videos. Youtube Channel: @longnguyen8112\n\n\nEnjoy!",
      "target_audience": [
        "Beginner Developers who wish to understand Neural Networks.",
        "Any math enthusiast who wishes to understand how matrix multiplication and the exponential function are the only two functions needed to recognize images!",
        "Any student who wishes to see one of the most useful and powerful application of high school math!"
      ]
    },
    {
      "title": "Midjourney FREE AI Art Generation Guide with ChatGPT",
      "url": "https://www.udemy.com/course/midjourney-free-ai-art-generation-guide-with-chatgpt/",
      "bio": "Generate stunning AI art generation using Midjourney & ChatGPT with this Free course!",
      "objectives": [],
      "course_content": {
        "Introduction to Midjourney": [
          "Introduction to Midjourney"
        ],
        "Setting Up Midjourney": [
          "Setting Up Midjourney"
        ],
        "Basic Commands for AI Art Generation": [
          "Imagine & Info Command"
        ],
        "Midjourney Prompt Engineering": [
          "ChatGPT Prompts For Midjourney"
        ],
        "Free Alternatives to Midjourney": [
          "Take MidJourney to Next Level",
          "Bonus"
        ]
      },
      "requirements": [
        "Nothing Required",
        "Internet Connection"
      ],
      "description": "Introducing the 'Midjourney Mastery with ChatGPT: Your Free Guide'.\nEmbark on a journey to master the MidJourney tool, leveraging ChatGPT for prompt engineering to create awe-inspiring AI-generated artwork, all from the ground up!\nOffered free of charge, the course content is packed with invaluable insights on mastering Midjourney.\nWe'll start by guiding you through the Midjourney setup process. Setting up Discord and its servers is a crucial first step, but there's no need to worry—we'll walk you through the entire process at no cost. Next, we'll cover the fundamental commands of Midjourney, such as \"imagine\" and \"info\". Following that, we'll delve into using ChatGPT for prompt engineering tailored to Midjourney, enabling you to create stunning AI art.\nMoreover, we'll introduce you to 13 free alternatives to Midjourney and provide a detailed roadmap to becoming a Midjourney expert.\nCourse Learnings:\nGrasp the Basics of Midjourney\nComprehensive Setup Guide for Midjourney\nEssential Commands for AI Art Creation\nUtilizing ChatGPT for Midjourney Prompt Engineering\nExploring 13 Free Midjourney Alternatives\nAdvanced Techniques to Excel in Midjourney\nCourse Requirements:\nAn internet connection\nNo prior experience needed\nIdeal for:\nAnyone keen on learning Midjourney from the basics\nSecure your spot in our free 'Midjourney Mastery with ChatGPT: Your Free Guide' course and start your transformative journey into the realm of AI art generation.\nEnroll Today!",
      "target_audience": [
        "Anyone who wants to learn Midjourney"
      ]
    },
    {
      "title": "Chat GPT : Una guía de ChatGPT completa para principiantes",
      "url": "https://www.udemy.com/course/chat-gpt-una-guia-de-chatgpt-completa-para-principiantes/",
      "bio": "Domine la inteligencia artificial de ChatGPT: Aprenda a crear diálogos eficientes y personalizados con Curso Chat GPT.",
      "objectives": [
        "¿Qué es el Chat GPT?",
        "Cómo funciona el ChatGPT",
        "Cree código de programación usando la tecnología ChatGPT de OpenAI",
        "Cómo ganar dinero usando Chat GPT",
        "Desarrollo de diálogos eficientes y personalizados",
        "Técnicas para entrenar y personalizar Chat GPT",
        "Cómo hacer redacción publicitaria de ventas usando Chat GPT",
        "Técnicas para usar ChatGPT para crear contenido de YouTube personalizado, rentable y atractivo"
      ],
      "course_content": {
        "Introducción": [
          "Bienvenido al curso",
          "Comprender ChatGPT: una mirada en profundidad a su funcionalidad",
          "Explorando los beneficios y ventajas de ChatGPT Plus"
        ],
        "Uso de GPT Chat en la práctica": [
          "Explorando el ChatGPT",
          "Cómo formular buenas preguntas para Chat GPT",
          "Errores al usar ChatGPT",
          "Organiza tu rutina",
          "Resume textos, libros, cuentos, películas, series y entre otras cosas",
          "Obtener ideas de contenido",
          "Creación de un guión de vídeo",
          "Seo con ChatGPT",
          "Generar códigos de programación",
          "Creación de un sitio web con Chat GPT",
          "Hacer correcciones de texto",
          "Cree un producto digital con GPT Chat",
          "Comandos con Chat GPT"
        ],
        "Programación con Chat GPT": [
          "Lectura de Códigos de Programación",
          "Generando códigos de programación con ChatGPT",
          "Correcciones de cualquier lenguaje de programación con ChatGPT",
          "Creando un sitio web con ChatGPT",
          "Generando un sitio con Inteligencia Artificial",
          "Creando un juego JavaScript HTML con ChatGPT"
        ],
        "Formas de ganar dinero con inteligencia artificial": [
          "Fuentes de ingresos con Chat GPT",
          "Cree y venda productos digitales con ChatGPT",
          "Sea un creador de contenido con Chat GPT",
          "Creador de sitios web",
          "Trabajos Freelance",
          "Inteligencia Artificial Midjourney"
        ],
        "ChatGPT: Social Media, Crear Contenido, Guiones y SEO": [
          "Producción de vídeos con ChatGPT y tecnología de IA"
        ]
      },
      "requirements": [
        "Cualquier persona interesada en trabajar con Inteligencia Artificial",
        "Cualquier persona interesada en ganar dinero con Chat GPT",
        "Cualquier persona interesada en aprender desde una computadora o celular con acceso a Internet"
      ],
      "description": "El curso \"Chat GPT: Una guía de ChatGPT completa para principiantes\" es una oportunidad única para aquellos que buscan conocer a fondo el funcionamiento de este modelo de lenguaje de inteligencia artificial. En este curso, los participantes podrán aprender sobre las características y capacidades de ChatGPT, así como también sobre su funcionamiento y aplicaciones prácticas.\nEl curso está diseñado para principiantes en el tema, por lo que no se requiere experiencia previa en inteligencia artificial o programación para participar. Se presentarán conceptos y términos técnicos de manera clara y accesible para todos los participantes.\nDurante el curso, se explorarán temas como el aprendizaje profundo, el procesamiento del lenguaje natural y la generación de texto. Los participantes también tendrán la oportunidad de interactuar con ChatGPT a través de diferentes plataformas, lo que les permitirá comprender mejor su funcionamiento.\nAdemás, el curso incluirá ejercicios prácticos y proyectos para que los participantes puedan aplicar lo aprendido y mejorar su comprensión de ChatGPT. También se ofrecerá soporte y asesoramiento personalizado para aquellos que necesiten ayuda adicional.\nEn resumen, \"Chat GPT: Una guía de ChatGPT completa para principiantes\" es un curso esencial para aquellos interesados en conocer más sobre el fascinante mundo de la inteligencia artificial y el procesamiento del lenguaje natural.",
      "target_audience": [
        "Para aquellos que quieren aprender a usar las funciones de ChatGPT",
        "Para aquellos que quieren ganar dinero con Chat GPT",
        "Cualquier persona interesada en aprender y poner en práctica la herramienta ChatGPT",
        "Creadores de contenido"
      ]
    },
    {
      "title": "LangChainによる大規模言語モデル（LLM）アプリケーション開発入門―GPTを使ったチャットボットの実装まで",
      "url": "https://www.udemy.com/course/langchain-apps/",
      "bio": "GPTなどの大規模言語モデルを使ったアプリケーション開発で注目されている「LangChain」に入門して、LangChainとGPTを使ったWebアプリケーションやSlackボットの実装とデプロイまで挑戦しよう！",
      "objectives": [
        "OpenAI の大規模言語モデルの概要と、Completions API・Chat API の基本",
        "LangChain の入門に必要なプロンプトエンジニアリングの基礎知識",
        "LangChain の基本（Models・Prompts・Chains・Indexes・Memory・Agents）",
        "Git・GitHub の使用方法の基礎",
        "Gradio と LangChain（GPT）を使った Web アプリケーションの実装",
        "PaaS（Render）を使った Web アプリケーションのデプロイ",
        "LangChain を使った必要に応じてプライベートな文書を検索する機能の実装",
        "Bolt と LangChain（GPT）を使った Slack ボットの実装",
        "OpenAI Chat API の Function calling 機能の基本と、関連する LangChain のアップデート"
      ],
      "course_content": {
        "はじめに": [
          "このコースについて",
          "受講ガイド"
        ],
        "GPT の API の基礎知識": [
          "OpenAI の大規模言語モデルの概要",
          "Google Colab の準備",
          "このコースの前半で使用するソースコード",
          "OpenAI の API キーを発行",
          "（追記）RateLimitError について",
          "（追記）Completions APIで使用可能なモデルについて",
          "OpenAI の Completions API にふれる",
          "OpenAI の Chat API にふれる",
          "トークン数と料金について",
          "このセクションのまとめ"
        ],
        "プロンプトエンジニアリング超入門": [
          "プロンプトエンジニアリングの概要",
          "ロンプトエンジニアリングのナレッジ集",
          "プロンプトの要素とテンプレート化",
          "プロンプトエンジニアリングの有名な手法を試す"
        ],
        "LangChain 入門（前半）": [
          "LangChain の概要",
          "アップデートの激しい新しい OSS のキャッチアップと使用について",
          "Models（LLMs・Chat Models）",
          "Prompts（Prompt Templates）",
          "Chains",
          "ここまでのまとめとドキュメントの確認",
          "Prompts のより高度な機能（Output Parses）",
          "（補足）公式ドキュメントの特定バージョンを用意する方法"
        ],
        "LangChain 入門（後半）": [
          "このセクションについて",
          "Indexes",
          "（補足）テキストのベクトル化とは",
          "Memory",
          "Agents",
          "LangChain のモジュールのまとめ",
          "（補足）敵対的プロンプトについて",
          "Chat API に特化した実装",
          "LangChain のソースコードを少し読んでみる",
          "このコースの後半で実施すること"
        ],
        "最小限だけ学ぶ Git・GitHub 入門": [
          "（Windows の場合）WSL 2 のセットアップ",
          "Git とは・GitHub とは",
          "GitHub でリポジトリを作成",
          "リポジトリをローカルに clone する",
          "Git のコマンドを最小限学ぶ"
        ],
        "Python のセットアップ": [
          "Python のセットアップ方針について",
          "Python をインストールするために asdf をインストール",
          "（補足）asdf のセットアップについて",
          "asdf で Python をインストール",
          "asdf で Poetry をインストール",
          "Poetry でプロジェクトを初期化",
          "Python の Hello World"
        ],
        "チャットボットの Web アプリケーションを Gradio で実装": [
          "実装するアプリケーションについて",
          "（追記）「Gradio の Hello World」で発生する可能性のあるエラーについて",
          "Gradio の Hello World",
          "（追記）エラー「AttributeError: module 'gradio' has no attribute 'ClearButton'」について",
          "Gradio でチャットボットを実装",
          "python-dotenv による環境変数読み込みの設定",
          "Gradio のチャットで LLM を使う",
          "履歴を踏まえた対話の実装"
        ],
        "PaaS（Render）を使った Web アプリケーションの公開": [
          "Web アプリケーションを動かすプラットフォームの基本",
          "Gradio の簡易的な認証の設定",
          "（追記）Render での Poetry のバージョンの指定について",
          "Render を使って Web アプリケーションを公開",
          "Render の無料プランの制約",
          "Web アプリケーションの実装・公開のまとめ"
        ],
        "必要に応じてプライベートな文書を検索する機能の実装": [
          "このセクションで実施すること",
          "（追記）「Index の実装」で発生する可能性のあるエラーについて",
          "Index の実装",
          "（追記）Agent の JSONDecodeError について",
          "（追記）Agent が Vector Store を検索する際に text-davinci-003 を使うことによるエラーについて",
          "Vector Store を Agent で必要に応じて使う",
          "このセクションのまとめ"
        ]
      },
      "requirements": [
        "「変数・if・for・関数」程度の Python の基礎知識がある",
        "絶対パス・相対パス程度のコンピュータの基礎知識がある",
        "ターミナルで ls、cd などの基本的なコマンドを実行したことがある",
        "プログラミングに使用可能な PC を所有している",
        "学習に使える Slack のワークスペースを持っている",
        "ChatGPT を使ったことがあり、OpenAI の API を利用できる（OpenAI の API の利用には、無料枠があるか、支払いの登録が必要です）"
      ],
      "description": "2022 年末に公開されて以来、「ChatGPT」は一般にも知られるキーワードとなり、非常に盛り上がっています。\nChatGPT が使っている GPT-3.5 や GPT-4 などのモデルは、「大規模言語モデル（LLM：Large Language Model）」と呼ばれます。\n2023 年現在、LLM 周辺のトピックは日々大きな話題となっています。\n\n\nそんな中、LLM を使ったアプリケーションを開発するためのツールとして、「LangChain」が注目を集めています。\nLLM を使ったアプリケーション開発の基礎を学びたい方は、LangChain で実際にアプリケーションを実装してみるのがおすすめです。\n\n\nこの講座では、LangChain の入門から始めて、実際に LLM（GPT）を使ったアプリケーションを開発していきます。\nコース後半では、LangChain を使って、Web アプリケーションと Slack ボットという 2 つのチャットボットを実装します。\nこれらには「会話履歴を踏まえて応答する機能」や「プライベートな文書を検索して応答する機能」を実装します。\n\n\n■この講座の 3 つのポイント\n内部の動作を意識して LangChain にしっかり入門します\nLangChain の基礎で終わらず、Web アプリや Slack ボットを実装します\n変化の激しいツールをキャッチアップして使う方法にもふれます\n\n\nなお、OpenAI の Chat API の Function calling 機能についての解説も追加されています。\nFunction calling 機能の基本から、LangChain での応用的な使い方まで解説しています。\n\n\n更新履歴\n2023/07/03：エラーの対応として以下のレクチャーを追加\n（追記）「Gradio の Hello World」で発生する可能性のあるエラーについて\n（追記）エラー「AttributeError: module 'gradio' has no attribute 'ClearButton'」について\n（追記）Render での Poetry のバージョンの指定について\n2023/07/10：エラーの原因やより適切なコードについて、以下のレクチャーを追加\n（追記）Agent の JSONDecodeError について\n（追記）Slack から取得した履歴の reversed 処理について\n2023/07/11：セクション「（アップデート）OpenAI の Chat API の Function calling 機能について」を追加\n2023/07/25：レクチャー「（追記）「Gradio の Hello World」で発生する可能性のあるエラーについて」を更新\n2023/09/02：レクチャー「（追記）「Index の実装」で発生する可能性のあるエラーについて」を追加\n2023/11/03：以下のセクションを追加\n（アップデート）プライベートな文書を検索して回答させる処理の解説資料\n（アップデート）LangChain Expression Language （LCEL）\n2023/11/22：text-davinci-003の廃止予定に関する更新\nレクチャー「（追記）Completions APIで使用可能なモデルについて」を追加\nレクチャー「このコースの前半で使用するソースコード」で共有しているGoogle Colabを更新\n2023/11/24：レクチャー「（追記）RateLimitError について」を追加\n2023/12/15：セクション「（アップデート）OpenAI の Chat API の Function calling 機能について」のGoogle Colabで使用するduckduckgo-searchのバージョンを更新\n2024/02/21：レクチャー「（追記）Agent が Vector Store を検索する際に text-davinci-003 を使うことによるエラーについて」を追加\n2024/03/18：レクチャー「（追記）LCEL の解説資料」を追加\n2024/05/05：セクション「（アップデート）OpenAI の Chat API の Function calling 機能について」のGoogle Colabで使用するduckduckgo-searchのバージョンを更新\n2024/11/20：レクチャー「このコースの前半で使用するソースコード」に補足を追記",
      "target_audience": [
        "GPT などの大規模言語モデルを使ったアプリケーションの開発を学びたい方",
        "LangChain について耳にして、基本を学びたいと思っている方",
        "LangChain を使って Web アプリや Slack ボットを実装してみたい方"
      ]
    },
    {
      "title": "Curso de R y Python para Data Science y Análisis de Datos",
      "url": "https://www.udemy.com/course/curso-de-r-y-python-para-data-science-y-analisis-de-datos/",
      "bio": "Aprende R y Python desde cero para Análisis de Datos, Data Science, Minería de Datos, Data Mining, Visualizaciones, etc.",
      "objectives": [
        "Instalación de R y Python.",
        "Dominar desde cero ambos lenguajes.",
        "Importar y exportar datos y resultados de los análisis.",
        "Pre-procesamiento de datos y limpieza.",
        "Descripción de los datos en R y Python.",
        "Conceptos de estadística necesarios para poder analizar datos.",
        "Aprender las librerías más usadas (numpy, pandas, matplotlib, ggplot, etc.)",
        "Todo tipo de visualizaciones para diferentes tipos de datos (univariantes, multivariantes, series temporales, mapas, etc.)"
      ],
      "course_content": {
        "Introducción": [
          "Bienvenidos",
          "Introducción",
          "Requisitos",
          "Evaluación",
          "Mensaje",
          "Grupo para dudas",
          "Material del curso"
        ],
        "¿Cómo iniciarte en Ciencia de Datos?": [
          "Los 3 pilares de la Ciencia de Datos",
          "Estadística",
          "R y Python: las dos herramientas más usadas en Data Science y Análisis de Datos",
          "Habilidades complementarias",
          "Cómo crear tu currículum"
        ],
        "Libro Ciencia de Datos para todos": [
          "Libro Ciencia de Datos para todos"
        ],
        "Introducción a Python": [
          "Introducción a Python"
        ],
        "Python: Instalación": [
          "Instalando Python",
          "Google Colaboratory"
        ],
        "Python: Fundamentos del lenguaje": [
          "Variables",
          "Antes de comenzar con las tareas",
          "Asignar un valor a una variable",
          "Asignar un valor a una variable",
          "Encuesta sobre la nueva herramienta de codificación",
          "Operadores",
          "Usando la asignación aumentada",
          "Cadenas de texto (strings) - parte I",
          "Cadenas de texto (strings) - parte II",
          "Cadenas de texto (strings) - parte III",
          "Cadenas de texto (strings) - parte IV",
          "Condicionales (if, else, elif)",
          "Operadores de comparación (=, ==, <, >, etc.)",
          "Ciclo \"while\"",
          "Ciclo \"for\"",
          "Listas - I",
          "Listas - II",
          "Listas - III",
          "Listas - IV",
          "Diccionarios - I",
          "Diccionarios - II",
          "Creando un diccionario",
          "Ficheros",
          "Crear nuestras propias funciones",
          "Crea una función",
          "Python: ejercitando lo aprendido",
          "Python: básicos, variables",
          "Python: operaciones, strings",
          "Python: crear ciclos y funciones",
          "Python: condicionales if, else, elif",
          "Python: funciones matemáticas pre-definidas",
          "Python: listas"
        ],
        "Python: Librería NumPy": [
          "Introducción a la librería NumPy",
          "Matrices con NumPy",
          "Generación de datos (enteros, bernouilli, normales, etc.)",
          "Ejercicio para crear una matriz",
          "Manipulando arrays con NumPy",
          "Operaciones lógicas",
          "Ordenación y valores únicos",
          "Operaciones aritméticas",
          "Funciones universales",
          "Cálculo estadístico con NumPy",
          "Funciones vectorizadas",
          "Álgebra lineal",
          "Python: ejercitando lo aprendido sobre NumPy",
          "Python: básicos",
          "Python: creación y simulación de arrays",
          "Python: manipulando arrays",
          "Python: operaciones lógicas y ordenación",
          "Python: matemática, estadística y álgebra"
        ],
        "Python: Librería Pandas": [
          "Introducción a la librería Pandas",
          "¿Qué es una serie en Pandas?",
          "Operaciones con series de Pandas",
          "¿Qué es un dataframe?",
          "Características y selección de elementos",
          "Modificación de elementos",
          "Manejando cadenas de texto",
          "Manejando fechas",
          "Manejando datos categóricos",
          "Análisis estadístico",
          "Python: ejercitando lo aprendido sobre Pandas",
          "Python: Inicio y Series de Pandas",
          "Python: DataFrames de Pandas"
        ],
        "Python: Visualización con Matplotlib y Seaborn": [
          "Introducción a la visualización de datos",
          "Python: ejercitando la visualización",
          "Python: cómo crear una figura y un gráfico de línea",
          "Python: diferentes estilos y cómo hacer anotaciones",
          "Python: gráficos de barras e histogramas",
          "Python: boxplots",
          "Python: gráficos de dispersión",
          "Python: mapa de calor",
          "Python: gráficos con Seaborn"
        ],
        "[NUEVO] Librerías para generar informes de EDA": [
          "[NUEVO] EDA (Análisis exploratorio de datos) automático"
        ]
      },
      "requirements": [
        "Ninguno, el curso es para aprender R y Python desde cero, enfocado en aplicarlo a Data Science y Análisis de Datos."
      ],
      "description": "Este curso es para aprender R y Python desde cero mientras programas. Es un curso completamente práctico en el que tendrás la base necesaria para dominar y realizar análisis más avanzados con ambos programas.\nComenzaremos con la instalación de todo lo necesario para programar en nuestro ordenador y te enseñaremos también las herramientas de la nube que tienes disponible de forma gratuita para que ni siquiera tengas que instalar nada.\nLuego veremos los fundamentos principales de cada lenguaje, cómo se configura, cómo se trabaja, cómo se definen las cosas, cómo se crean funciones y códigos, etc. Posteriormente, veremos los diferentes paquetes y librerías más usadas (Pandas, Seaborn, ggplot2, etc.) de cada lenguaje, que podemos utilizar en nuestros análisis de datos.\nY paso a paso veremos las diferentes formas de trabajar con los datos: cómo importarlos, cómo guardarlos, cómo descargar datos de internet y usarlos para analizarlos, cuáles son las principales partes del pre-procesado de datos, el análisis estadístico descriptivo, los diferentes gráficos que podemos crear en base a nuestros datos, y cómo podemos personalizar todas esas visualizaciones.\nTodo ello utlizando múltiples casos prácticos reales. Y a su vez, tendrás a tu disposición muchísimo material complementario gratuito así como todos los códigos y scripts tanto de R como de Python, para que todo ese conocimiento lo puedas transferir rápidamente a tu propio campo y tus propios análisis.\nAsí que si tomas este curso estarás preparado para manejar R y Python con total soltura, y podrás comenzar a estudiar métodos un poco más avanzados del análisis de datos programados en R o Python.\n¡Un saludo y espero que nos veamos en clase!\nElisa",
      "target_audience": [
        "Estudiantes.",
        "Investigadores.",
        "Programadores.",
        "Iniciados en Data Science y Análisis de Datos."
      ]
    },
    {
      "title": "【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 中級編 -",
      "url": "https://www.udemy.com/course/kikagaku_blackbox_2/",
      "bio": "日本語トップコースである【キカガク流】脱ブラックボックス講座の中級編が遂に登場！「キカガクの知識は現場で使える！」そんな講座を目指しました。微分・線形代数といった数学の基礎からPythonでの実装まで短時間で習得しましょう。",
      "objectives": [
        "機械学習の原理を数学から理解し、プログラミング（Python）で実装できるようになります。",
        "今まで難しそうに見えていた機械学習に用いられる数式の意味を理解できるようになります。",
        "機械学習に関する専門用語も数式と一緒に覚えることができます。",
        "線形代数を用いて複数の変数を考慮したモデルを作成できるようになります。",
        "Numpyを用いた線形代数演算をプログラミングで実装が出来るようになります。",
        "Scikit-learnを用いた機械学習の実装ができるようになります。",
        "データの相関関係をひと目で可視化出来るようになります。",
        "平均・標準偏差・正規分布といった統計の数式と使い所が理解できます。",
        "外れ値の除去が行えるようになります。",
        "予測に大きな影響を与えている変数を見つけることができるようになります。"
      ],
      "course_content": {
        "はじめに": [
          "【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 中級編 -"
        ],
        "イントロダクション": [
          "イントロダクション"
        ],
        "線形代数": [
          "スカラー・ベクトル・行列",
          "行列の演算",
          "練習問題",
          "サイズ感",
          "転置",
          "単位行列・逆行列",
          "ベクトルで微分"
        ],
        "重回帰分析": [
          "Step1　「モデル」を決める",
          "Step2　「評価関数」を決める",
          "Step3　評価関数を「最小化」する - 式変形を行う -",
          "Step3　評価関数を「最小化」する - 最適なパラメータを求める -",
          "よくある質問"
        ],
        "重回帰分析の実装": [
          "行列演算の基礎（Numpy）",
          "よくある間違い（Numpy）",
          "演習問題",
          "Scikit-learnで実装"
        ],
        "実データで演習": [
          "データの読み込み",
          "分布の確認",
          "入力変数と出力変数の切り分け",
          "モデル構築と検証",
          "訓練データと検証データ",
          "予測値の計算とモデルの保存・読み込み",
          "パラメータの確認"
        ],
        "統計": [
          "主な統計量",
          "練習問題",
          "正規分布と３σ法",
          "スケーリング"
        ],
        "外れ値・スケーリングを考慮した重回帰分析": [
          "データの読込・分布の確認",
          "外れ値除去（３σ法） - 1変数に適用 -",
          "外れ値除去（３σ法） - 全変数に適用 -",
          "モデル構築",
          "スケーリングとパラメータの確認"
        ]
      },
      "requirements": [
        "【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 初級編 - の受講を前提としています。",
        "本コースは、macOSを使用して進めていきますが、Windowsでも同様に進めることができます。",
        "Mac, Windowsの両方の環境構築手順を紹介しています。"
      ],
      "description": "今回のゴール：「現場の解析」を知る\n創業から９ヶ月、オフラインでの受講生の１３００人、オンラインでの受講生１８００人を突破している株式会社キカガクの『脱ブラックボックスセミナー』の中級編が登場！\n初級編公開以来、「感動しました」との声を多くいただき、中級編への要望を多くいただいておりました。\n微分・線形代数といった数学の基礎から、Pythonでの実装まで短時間で習得しましょう。\nキカガクこだわりのスタイルである『手書きの数学』『ハンズオン形式のプログラミング』で実際に手を動かしながら学んでいただければ、理解できること間違いなしです。\n中級編では機械学習で必要な数学のエッセンスがたくさん詰まっている「重回帰分析」をゴールに、線形代数、統計、重回帰分析まで一気通貫で解説します。\nすでにUdemyで公開されている初級編の知識を前提として始め、数学やPythonの実装も順を追って解説しますので、初めての方でも学べる内容となっています。\n初級編・中級編・上級編とステップアップしながら学ぶことで、データ解析の実務に必要なスキルと考え方が学べる構成となっています。",
      "target_audience": [
        "機械学習の参考書を読んで「閉じて」しまった方",
        "独学で機械学習を学ぼうと思ったけど挫折してしまった方",
        "機械学習の参考書に記載された数式の意味が理解できず、学習をやめてしまった方",
        "中学校で学ぶ数学から始めるので初心者の方、数学が苦手な方でも大丈夫"
      ]
    },
    {
      "title": "Python para Data Science & Machine Learning en 18 Días",
      "url": "https://www.udemy.com/course/python-para-data-science/",
      "bio": "Data Science extremo con Numpy, Pandas, Matplotlib, Seaborn, Scikit Learn, Tensorflow, Machine Learning, y todo lo demás",
      "objectives": [
        "Aplicarás el Data Science en proyectos de manipulación compleja de información.",
        "Escribirás código Python de manera global, con confianza y comodidad",
        "Usarás Pandas para limpiar, transformar, y analizar grandes conjuntos de datos",
        "Dominarás NumPy para operaciones matemáticas y estadísticas sobre grandes arrays de datos",
        "Crearás visualizaciones atractivas y reveladoras con Matplotlib, Seaborn y Sci-kit Learn",
        "Harás predicciones usando algoritmos de Machine Learning",
        "Usarás Tensorflow para implementar redes neuronales y Deep Learning",
        "Desarrollarás habilidades para el Análisis Exploratorio de Datos (EDA)",
        "Al finalizar, serás capaz de recibir una tonelada de datos, y devolver visualizaciones interesantes, que ayuden a tus clientes a tomar decisiones relevantes.",
        "Serás una persona con el potencial de hacer de nuestro mundo un lugar mejor."
      ],
      "course_content": {
        "DÍA 1 - PREPARACIÓN PARA PYTHON Y DATA SCIENCE": [
          "Bienvenido al Curso de Python para Data Science",
          "Meta del Día 1",
          "Preguntas Frecuentes - Importante Leer",
          "Instalar Python y Jupyter",
          "Jupyter Notebooks",
          "Descarga los Archivos del Curso",
          "Introducción a la Programación Orientada a Objetos (OOP)",
          "Qué es Data Science",
          "Cierre del Día 1 - Preguntas Frecuentes"
        ],
        "DÍA 2 - CURSO INTENSIVO DE PYTHON - PARTE I": [
          "Meta del Día 2",
          "Guía para Ejercicios de Código",
          "Variables Numéricas en Python",
          "Ejercicio Variables Numéricas 1",
          "Ejercicio Variables Numéricas 2",
          "Ejercicio Variables Numéricas 3",
          "Variables de Texto",
          "Ejercicio Variables de Texto 1",
          "Ejercicio Variables de Texto 2",
          "Ejercicio Variables de Texto 3",
          "Función Type() en Python",
          "Ejercicio Type() 1",
          "Ejercicio Type() 2",
          "Ejercicio Type() 3",
          "Números en Python",
          "Ejercicio Números en Python 1",
          "Ejercicio Números en Python 2",
          "Ejercicio Números en Python 3",
          "Operaciones Matemáticas en Python",
          "Ejercicio Operaciones Matemáticas en Python 1",
          "Ejercicio Operaciones Matemáticas en Python 2",
          "Ejercicio Operaciones Matemáticas en Python 3",
          "Proyecto del Día 2: Programa un Conversor de Divisas",
          "Solución al Proyecto del Día 2",
          "Soluciones para los Ejercicios de Código del Día 2",
          "Cierre del Día 2 - Preguntas Frecuentes"
        ],
        "DÍA 3 - CURSO INTENSIVO DE PYTHON - PARTE II": [
          "Meta del Día 3",
          "Strings en Python",
          "Ejercicio Strings 1",
          "Ejercicio Strings 2",
          "Ejercicio Strings 3",
          "Indexar Strings en Python",
          "Ejercicio Indexar Strings en Python 1",
          "Ejercicio Indexar Strings en Python 2",
          "Ejercicio Indexar Strings en Python 3",
          "Filtrar Strings en Python",
          "Ejercicio Filtrar Strings en Python 1",
          "Ejercicio Filtrar Strings en Python 2",
          "Ejercicio Filtrar Strings en Python 3",
          "Input en Python",
          "Ejercicio Input() en Python 1",
          "Ejercicio Input() en Python 2",
          "Ejercicio Input() en Python 3",
          "Formateo de Strings en Python",
          "Ejercicio Formateo de Strings en Python 1",
          "Ejercicio Formateo de Strings en Python 2",
          "Ejercicio Formateo de Strings en Python 3",
          "Proyecto del Día 3: Programa un Analizador de Texto",
          "Solución al Proyecto del Día 3",
          "Soluciones para los Ejercicios de Código del Día 3",
          "Cierre del Día 3 - Preguntas Frecuentes"
        ],
        "DÍA 4 - CURSO INTENSIVO DE PYTHON - PARTE III": [
          "Meta del Día 4",
          "Listas en Python",
          "Ejercicio Listas en Python 1",
          "Ejercicio listas en Python 2",
          "Ejercicio listas en Python 3",
          "Tuplas en Python",
          "Ejercicio tuplas en Python 1",
          "Ejercicio tuplas en Python 2",
          "Ejercicio tuplas en Python 3",
          "Diccionarios en Python",
          "Ejercicio Diccionarios en Python 1",
          "Ejercicio Diccionarios en Python 2",
          "Ejercicio Diccionarios en Python 3",
          "Booleanos en Python",
          "Ejercicio Booleanos en Python 1",
          "Ejercicio Booleanos en Python 2",
          "Ejercicio Booleanos en Python 3",
          "Estructuras de Control en Python - IF",
          "Ejercicio de Control en Python - IF 1",
          "Ejercicio de Control en Python - IF 2",
          "Ejercicio de Control en Python - IF 3",
          "Estructuras de Control en Python - IF - ELIF - ELSE",
          "Ejercicio de Control en Python - IF - ELIF - ELSE 1",
          "Ejercicio de Control en Python - IF - ELIF - ELSE 2",
          "Ejercicio de Control en Python - IF - ELIF - ELSE 3",
          "Proyecto del Día 4: Programa una Agenda Telefónica",
          "Solución al Proyecto del Día 4",
          "Soluciones para los Ejercicios de Código del Día 4",
          "Cierre del Día 4 - Preguntas Frecuentes"
        ],
        "DÍA 5 - CURSO INTENSIVO DE PYTHON - PARTE IV": [
          "Meta del Día 5",
          "Loops en Python - Loop For",
          "Ejercicio Loops en Python - Loop For 1",
          "Ejercicio Loops en Python - Loop For 2",
          "Ejercicio Loops en Python - Loop For 3",
          "Función Range en Python",
          "Ejercicio Range en Python 1",
          "Ejercicio Range en Python 2",
          "Ejercicio Range en Python 3",
          "Loops en Python: Loop While",
          "Ejercicio Loop While 1",
          "Ejercicio Loop While 2",
          "Ejercicio Loop While 3",
          "Funciones en Python",
          "Ejercicio Funciones en Python 1",
          "Ejercicio Funciones en Python 2",
          "Ejercicio Funciones en Python 3",
          "Funciones que Llaman Funciones en Python",
          "Ejercicio Funciones que Llaman Funciones en Python 1",
          "Ejercicio Funciones que Llaman Funciones en Python 2",
          "Ejercicio Funciones que Llaman Funciones en Python 3",
          "Proyecto del Día 5: Programa un Generador de Tablas de Multiplicar",
          "Solución al Proyecto del Día 5",
          "Soluciones para los Ejercicios de Código del Día 5",
          "Cierre del Día 5 - Preguntas Frecuentes"
        ],
        "DÍA 6 - PANDAS - PARTE I": [
          "Meta del Día 6",
          "Importar Pandas en Python",
          "Tipos de Datos en Pandas",
          "Ejercicio Tipos de Datos en Pandas 1",
          "Ejercicio Tipos de Datos en Pandas 2",
          "Ejercicio Tipos de Datos en Pandas 3",
          "DataFrames en Pandas",
          "Ejercicio DataFrames en Pandas 1",
          "Ejercicio DataFrames en Pandas 2",
          "Ejercicio DataFrames en Pandas 3",
          "Series en Pandas",
          "Ejercicio Series en Pandas 1",
          "Ejercicio Series en Pandas 2",
          "Ejercicio Series en Pandas 3",
          "Operaciones Básicas con Series de Pandas",
          "Ejercicio Operaciones Básicas con Series de Panda 1",
          "Ejercicio Operaciones Básicas con Series de Panda 2",
          "Ejercicio Operaciones Básicas con Series de Panda 3",
          "Limpieza de Datos en Pandas",
          "Ejercicio Limpieza de Datos en Pandas 1",
          "Ejercicio Limpieza de Datos en Pandas 2",
          "Ejercicio Limpieza de Datos en Pandas 3",
          "Filtrado de Series en Pandas",
          "Filtrado de Series en Pandas 1",
          "Filtrado de Series en Pandas 2",
          "Filtrado de Series en Pandas 3",
          "Agregación de Series en Pandas",
          "Agregación de Series en Pandas 1",
          "Agregación de Series en Pandas 2",
          "Agregación de Series en Pandas 3",
          "Proyecto del Día 6: Programa un Análisis de Resultados Deportivos",
          "Solución al Proyecto del Día 6",
          "Respuestas al proyecto del Día 6",
          "Soluciones para los Ejercicios de Código del Día 6",
          "Cierre del Día 6 - Preguntas Frecuentes"
        ],
        "DÍA 7 - PANDAS - PARTE II": [
          "Meta del Día 7",
          "Trabajar con DataFrames de Pandas",
          "Trabajar con DataFrames de Pandas 1",
          "Trabajar con DataFrames de Pandas 2",
          "Trabajar con DataFrames de Pandas 3",
          "Ordenar y Agrupar DataFrames en Pandas",
          "Ordenar y Agrupar DataFrames en Pandas 1",
          "Ordenar y Agrupar DataFrames en Pandas 2",
          "Ordenar y Agrupar DataFrames en Pandas 3",
          "Fusionar DataFrames en Pandas con merge()",
          "Fusionar DataFrames con merge 1",
          "Fusionar DataFrames con merge 2",
          "Fusionar DataFrames con merge 3",
          "Combinar DataFrames en Pandas con join()",
          "Combinar DataFrames en Pandas con join() 1",
          "Combinar DataFrames en Pandas con join() 2",
          "Combinar DataFrames en Pandas con join() 3",
          "Concatenar DataFrames en Pandas con concat",
          "Concatenar DataFrames en Pandas con concat 1",
          "Concatenar DataFrames en Pandas con concat 2",
          "Concatenar DataFrames en Pandas con concat 3",
          "Datos Relacionados con el Tiempo en Pandas",
          "Datos Relacionados con el Tiempo en Pandas 1",
          "Datos Relacionados con el Tiempo en Pandas 2",
          "Datos Relacionados con el Tiempo en Pandas 3",
          "Abrir y Escribir Archivos desde Pandas",
          "Abrir y Escribir Archivos desde Pandas 1",
          "Abrir y Escribir Archivos desde Pandas 2",
          "Abrir y Escribir Archivos desde Pandas 3",
          "Acceder a Elementos del DataFrame con 'loc' e 'iloc'",
          "Acceder a Elementos del DataFrame con 'Ioc' e 'iloc' 1",
          "Acceder a Elementos del DataFrame con 'Ioc' e 'iloc' 2",
          "Acceder a Elementos del DataFrame con 'Ioc' e 'iloc' 3",
          "Proyecto del Día 7: Programa un Analizador de Ventas",
          "Solución al Proyecto del Día 7",
          "Soluciones para los Ejercicios de Código del Día 7",
          "Cierre del Día 7 - Preguntas Frecuentes"
        ],
        "DÍA 8 - NUMPY": [
          "Meta del Día 8",
          "Introducción a NumPy",
          "Introducción a NumPy 1",
          "Introducción a NumPy 2",
          "Introducción a NumPy 3",
          "Arrays de NumPy",
          "Examen NumPy",
          "Tipos de Arrays en NumPy",
          "Tipos de Arrays en NumPy 1",
          "Tipos de Arrays en NumPy 2",
          "Tipos de Arrays en NumPy 3",
          "Manipulación de Arrays en NumPy",
          "Manipulación de Arrays en NumPy 1",
          "Manipulación de Arrays en NumPy 2",
          "Manipulación de Arrays en NumPy 3",
          "Indexación y Segmentación en Arrays de NumPy",
          "Indexación y Segmentación en Arrays de NumPy 1",
          "Indexación y Segmentación en Arrays de NumPy 2",
          "Indexación y Segmentación en Arrays de NumPy 3",
          "Forma y Estructura de los Arrays de NumPy",
          "Forma y Estructura de los Arrays de NumPy 1",
          "Forma y Estructura de los Arrays de NumPy 2",
          "Forma y Estructura de los Arrays de NumPy 3",
          "Operaciones Avanzadas y Funciones Universales en NumPy",
          "Operaciones Avanzadas y Funciones Universales en NumPy 1",
          "Operaciones Avanzadas y Funciones Universales en NumPy 2",
          "Operaciones Avanzadas y Funciones Universales en NumPy 3",
          "Tratamiento de Datos Faltantes con NumPy",
          "Tratamiento de Datos Faltantes con NumPy 1",
          "Tratamiento de Datos Faltantes con NumPy 2",
          "Tratamiento de Datos Faltantes con NumPy 3",
          "Importación y Exportación de Datos con NumPy",
          "Importación y Exportación de Datos con NumPy 1",
          "Importación y Exportación de Datos con NumPy 2",
          "Importación y Exportación de Datos con NumPy 3",
          "Integración de NumPy con Pandas",
          "Integración de NumPy con Pandas 1",
          "Integración de NumPy con Pandas 2",
          "Integración de NumPy con Pandas 3",
          "Proyecto del Día 8: Programa un Análisis Meteorológico",
          "Solución al Proyecto del Día 8",
          "Soluciones para los Ejercicios de Código del Día 8",
          "Cierre del Día 8 - Preguntas Frecuentes"
        ],
        "DÍA 9 - MATPLOTLIB": [
          "Meta del Día 9",
          "Visualizaciones de Datos con Matplotlib",
          "Visualizaciones de Datos con Matplolib",
          "Estructura Principal de Matplotlib",
          "Estructura Principal de Matplotlib 1",
          "Estructura Principal de Matplotlib 2",
          "Estructura Principal de Matplotlib 3",
          "Gráficos de Línea (Line Plots) en Matplotlib",
          "Gráficos de Línea (Line Plots) en Matplotlib 1",
          "Gráficos de Línea (Line Plots) en Matplotlib 2",
          "Gráficos de Línea (Line Plots) en Matplotlib 3",
          "Histogramas en Matplotlib",
          "Histogramas en Matplotlib 1",
          "Histogramas en Matplotlib 2",
          "Histogramas en Matplotlib 3",
          "Gráficos Scatter en Matplotlib",
          "Gráficos Scatter en Matplotlib 1",
          "Gráficos Scatter en Matplotlib 2",
          "Gráficos Scatter en Matplotlib 3",
          "Gráfico Pastel (Pie Plot) con Matplotlib",
          "Gráfico Pastel (Pie Plot) con Matplotlib 1",
          "Gráfico Pastel (Pie Plot) con Matplotlib 2",
          "Gráfico Pastel (Pie Plot) con Matplotlib 3",
          "Creación de Múltiples Gráficos con Matplotlib",
          "Creación de Múltiples Gráficos con Matplotlib 1",
          "Creación de Múltiples Gráficos con Matplotlib 2",
          "Creación de Múltiples Gráficos con Matplotlib 3",
          "Estilo para tus Gráficos con Matplotlib",
          "Estilo para tus Gráficos con Matplotlib 1",
          "Estilo para tus Gráficos con Matplotlib 2",
          "Estilo para tus Gráficos con Matplotlib 3",
          "Crea Cualquier tipo de Gráficos desde Matplotlib",
          "Crea Cualquier tipo de Gráficos desde Matplotlib 1",
          "Crea Cualquier tipo de Gráficos desde Matplotlib 2",
          "Crea Cualquier tipo de Gráficos desde Matplotlib 3",
          "Proyecto del Día 9: Programa una Consulta Meteorológica Interactiva",
          "Solución al Proyecto del Día 9",
          "Soluciones para los Ejercicios de Código del Día 9",
          "Cierre del Día 9 - Preguntas Frecuentes"
        ],
        "DÍA 10 - SEABORN": [
          "Meta del Día 10",
          "Introducción a Seaborn",
          "Introducción a Seaborn",
          "Relación Estadística en Seaborn",
          "Relación Estadística en Seaborn",
          "Representación Distributiva en Seaborn",
          "Representación Distributiva en Seaborn",
          "Variables Categóricas en Seaborn",
          "Variables Categóricas en Seaborn",
          "Vista Múltiple para Datasets Complejos en Seaborn",
          "Vista Múltiple para Datasets Complejos en Seaborn",
          "Funciones de Nivel Inferior en Seaborn",
          "Funciones de Nivel Inferior en Seaborn",
          "Valores Preconfigurados y Personalizados en Seaborn",
          "Valores Preconfigurados y Personalizados en Seaborn",
          "Nivel de Figura vs. Nivel de Axes en Seaborn",
          "Nivel de Figuras vs. Nivel de Axes en Seaborn",
          "Proyecto del Día 10: Crea un Dashboard de Análisis Exploratorio de Datos",
          "Solución al Proyecto del Día 10",
          "Cierre del Día 10 - Preguntas Frecuentes"
        ]
      },
      "requirements": [
        "Tener un ordenador conectado a internet",
        "Ser un explorador curioso",
        "No se requiere ningún conocimiento previo de Python ni de Data Science",
        "Traer buena onda. No se admiten estudiantes sin una sonrisa en la cara"
      ],
      "description": "\"Python TOTAL\", el curso Best-Seller que ha enseñado Python desde cero a miles y miles, necesitaba un complemento perfecto: \"Python TOTAL para Data Science y Machine Learning\".\n\n\n¿Por qué hacía falta?\nPorque con este curso, además de aprender Python desde cero, podrás llevarlo hacia la ciencia del momento: Data Science (o Ciencias de la Información), para poder programar herramientas capaces de procesar cantidades monumentales de información, y de generar no solo visualizaciones relevantes, informativas y atractivas, sino también predicciones a partir de los datos que disponemos.\n\n\nCon \"Python Total para Data science & Machine Learning\" podrás ayudar a quienes toman decisiones a entender mejor el contexto y la realidad sobre la cual están operando, para poder ser eficaces, eficientes y acertivos en sus decisiones.\n\n\n¿Que encontrarás en este curso?\n18 días de aprendizaje intenso y práctico\nCientos de ejercicios de código en la plataforma (3 por cada lección)\nVientos de archivos de código descargable\nProyectos díarios del mundo real para aplicar lo aprendido\nDecenas de bases de datos para prácticas\nCuestionarios\nLecciones teóricas y prácticas hechas con amor por la simplicidad\n\n\n¿Qué temas cubre este curso?\nPython básico\nPandas\nNumPy\nMatplotlib\nSeaborn\nScikit Learn\nTensorflow\nMachine Learning\nExcel y Power BI para Data Science\nAlgoritmos de Aprendizaje Supervisado, No Supervisado y por Reforzamiento\nBases de Datos\nAPIs\nDeep Learning\nEtica y Provacidad en Data Science\ny muchísimo más\n\n\n¿Por qué puedo ayudarte?\nMi nombre es Federico Garay, soy instructor Best-Seller con la medalla \"Socio de Udemy\". Mis cursos han enseñado a cientos de miles de personas a programar, y mi calificación promedio no baja de 4.7 estrellas.\nAmo enseñar. Amo buscar la explicación simple de las cosas. Quiero que todos entiendan y que nadie se quede atrás.\nContesto TODAS las preguntas de mis estudiantes en menos de 24-48 horas.\nSi ya has visto otros cursos exitosos como Python Total o Excel Total, no dudarás en aprender conmigo, porque además de crecer, te vas a divertir.\n\n\n¿Puedes hacer este curso sin haber hecho el de Python Total?\nClaro que sí. En este curso retomamos de manera dinámica lo aprendido en Python TOTAL desde cero, para que nadie se quede afuera. No quiero que tengas que comprar nada extra, y quiero que con este curso obtengas todo el conocimiento y las habilidades necesarias para ser un científico de datos, ya sea que tengas experiencia, o que nunca hayas programado en tu vida.\n\n\nEstoy seguro de que no te arrepentirás, por eso te invito a probar el curso, y si no es lo que buscabas cuentas con la garantía de Udemy de devolución del 100% de tu dinero dentro de los 30 días.\n\n\nNo le demos más vueltas, este es el curso que necesitas.\n\n\nTe espero en la lección #1\nFede",
      "target_audience": [
        "Personas sin experiencia en programación que están decididos a cambiar el rumbo de su vida transformándose en científicos de datos",
        "Estudiantes iniciales o avanzados de carreras relacionadas a la informática",
        "Programadores que desean llevar sus habilidades hacia la disciplina de las Ciencias de la Información",
        "Emprendedores que desean tener dominio del poder de la información para llevar sus proyectos al siguiente nivel al gozar de una posición ventajosa",
        "Curiosos e inquietos que han escuchado que esto de la programación es genial y quieren ver de qué se trata",
        "Adolescentes y jóvenes que están buscando dónde comenzar el camino de su desarrollo",
        "Personas GRANDES que no le temen a los desafíos y que han dicho \"yo estoy a tiempo de montarme en la profesión que quiera\"",
        "Este curso es para tí, porque lo he hecho por amor a las personas que son como yo: alguien que quiere aprender de todo."
      ]
    },
    {
      "title": "Boosting Business Productivity with ChatGPT & Google Bard AI",
      "url": "https://www.udemy.com/course/enhancing-productivity-through-google-bard-and-chatgpt-ai/",
      "bio": "Unlock Efficiency, Innovation, and Automation with ChatGPT, Google Bard, and AI Solutions for Business Success",
      "objectives": [],
      "course_content": {
        "Introduction to chat GPT": [
          "Introduction to chat GPT",
          "Introduction to Google BARD: Unleashing Data Insights with Real-World Examples"
        ],
        "GPT-X: Unleashing the Next Generation of Generative Pre-trained Transformer Arch": [
          "GPT-X: Unleashing the Next Generation of Generative Pre-trained Transformer Arch",
          "Getting Started with Google BARD: Empowering Data Analysis Across Industries"
        ],
        "NLP Mastery: Demystifying Tokenization, Word Embeddings, and Language Modeling": [
          "NLP Mastery: Demystifying Tokenization, Word Embeddings, and Language Modeling",
          "Setting Up Google BARD: Configuration and Keyboard Shortcuts for Interaction"
        ],
        "Data Mastermind: Strategies for Collecting and Preparing for ChatGPT": [
          "Data Mastermind: Strategies for Collecting and Preparing for ChatGPT",
          "Unleashing Creativity with Google BARD: Crafting Poems, Stories, and Scripts",
          "Using Google BARD Responsibly: Essential Tips and Best Practices"
        ],
        "Empowering NLP: Unveiling the Top Libraries for Natural Language Processing": [
          "Empowering NLP: Unveiling the Top Libraries for Natural Language Processing",
          "Setting Up and Exploring Google BARD: Get Started with Experimental BARD",
          "Unlocking Financial Insights: Leveraging Finance Functions in Google BARD"
        ],
        "From Raw to Refined: Mastering Training Data Preparation for NLP Models": [
          "From Raw to Refined: Mastering Training Data Preparation for NLP Models",
          "Analyzing Healthcare Data: Harnessing Medical Functions in Google BARD",
          "Supercharge Your Analysis: Leveraging Mathematical Functions in Google BARD"
        ],
        "The Power of Diversity: Unveiling the Significance of High-Quality Training Data": [
          "The Power of Diversity: Unveiling the Significance of High-Quality Training Data",
          "Optimizing Development Workflows: Harnessing Developer/Coder Functions in Google",
          "Elevate Your Marketing Insights: Leveraging Marketing Functions in Google BARD"
        ]
      },
      "requirements": [
        "No prior experience with AI or programming is needed, but an eagerness to learn and explore new technologies is a plus!"
      ],
      "description": "In a rapidly evolving digital landscape, the fusion of cutting-edge technologies like Google BARD and ChatGPT AI offers unparalleled potential for revolutionizing productivity in various domains. This comprehensive course is meticulously designed to empower participants with the knowledge and skills required to harness the full potential of these transformative tools.\nThe course begins by delving into Google BARD, a groundbreaking platform that seamlessly integrates data analysis, reporting, and visualization. Participants will master techniques to effortlessly extract insights from complex datasets, generate dynamic reports, and create captivating visualizations, enabling them to make data-driven decisions with unprecedented precision.\n\n\nIn today's dynamic and competitive business landscape, staying ahead of the curve is crucial. Traditional methods may no longer be sufficient to drive your business forward and deliver exceptional results. This is where AI steps in, offering groundbreaking solutions to set your business on the fast track to success. With our live demonstration format, you'll have the opportunity to witness firsthand how AI, powered by ChatGPT and Google Bard, can revolutionize your operations and drive remarkable outcomes.\n\n\nThroughout this immersive course, we'll guide you through real-life scenarios where AI technologies, such as ChatGPT and Google Bard, can be applied to supercharge your business growth. You'll witness captivating live demos that showcase how AI can expedite various aspects of your business, including HR, IT services, marketing, customer experience, and more.\n\n\nImagine the power of AI transforming your human resources processes. Through our live demos, you'll witness how AI-powered tools, such as ChatGPT and Google Bard, can automate recruitment, streamline talent management, and foster a highly engaged workforce. Experience the time and cost savings as AI takes care of repetitive HR tasks, allowing you to focus on strategic initiatives and nurturing your most valuable asset – your people.\n\n\nThe live demos will also unveil the potential of AI in revolutionizing your IT services. Watch as ChatGPT and Google Bard assist in automating routine IT tasks, providing instant support to employees, and enhancing overall efficiency. Discover the productivity gains and improved performance that AI-driven IT operations can bring to your organization.\n\n\nBut AI doesn't stop there. Our live demos will showcase how AI can transform your marketing efforts, revolutionize customer service interactions, optimize supply chain management, and provide invaluable insights through data-driven financial analysis. Witness firsthand the power of ChatGPT and Google Bard in creating personalized marketing campaigns, enhancing customer experiences, improving demand forecasting, and generating predictive analytics to drive business growth.\n\n\nThis course is not just about theory and concepts. It's about experiencing the impact of AI firsthand and understanding its transformative potential for your business. Our expert instructors will guide you through each live demo, explaining the capabilities of ChatGPT and Google Bard, implementation strategies, and the tangible benefits they bring. You'll have the opportunity to ask questions, interact with the AI systems, and gain practical insights that you can immediately apply to your own business.\n\n\nPrepare to be inspired as you witness the incredible possibilities that AI offers to accelerate your business success. Enroll in \"Live Demo: Accelerating Business Success with AI\" today and join us for an immersive journey into the world of AI-driven transformation. Get ready to revolutionize your business and unlock unprecedented growth opportunities with the power of ChatGPT and Google Bard.",
      "target_audience": [
        "Anyone who is curious about AI and wants to learn how it can be used to enhance our lives and work. Students and researchers who want to explore the latest trends Marketers and social media managers who want to use AI chatbots to engage with their audience Entrepreneurs and business owners who want to leverage AI chatbots to improve customer service, marketing, or sales. Freelancers",
        "All UG,PG Students with any IT and computer science students. Interested students to learn about the concepts of Google bard AI Journey for upcoming years"
      ]
    },
    {
      "title": "Mastering Machine Learning: A Guide to Research & Publishing",
      "url": "https://www.udemy.com/course/mastering-machine-learning-a-guide-to-research-publishing/",
      "bio": "Create a research project using Machine Learning and Data Science for AP Research, publication, or passion projects.",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "No programming or research experience is required. This is a step-by-step guide suitable for all skill levels."
      ],
      "description": "This course is intended for PURCHASE BY ADULTS as those under 18 may use this course only if a parent or guardian opens their account, handles any enrolment, and manages their account usage.\nUnlock the power of Machine Learning and Data Science with this comprehensive course designed specifically for high school students and beginners. You'll learn how to harness advanced data analysis techniques and machine learning models to enhance your research projects, whether for AP Research, publication, or personal exploration.\n\n\nWhat You'll Learn:\n\n\nBasic Concepts: Discover what Machine Learning is and how it operates. Understand the foundational principles and terminology that will serve as the building blocks for more advanced topics.\nData Analysis Techniques: Master key methods for manipulating, analyzing, and visualizing data using tools such as Pandas. Learn how to transform raw data into meaningful insights.\nMachine Learning Models: Explore different types of machine learning algorithms, including supervised and unsupervised learning. Gain practical skills in building, training, and evaluating models with TensorFlow.\nResearch Project Development: Learn to design and execute a research project that incorporates machine learning and data science. From formulating research questions to conducting analysis, you'll be guided through each phase of your project.\nAP Research Preparation: Acquire strategies for excelling in AP Research. Develop a clear research plan, utilize machine learning effectively, and prepare your work for submission.\nPublication and Presentation: Understand best practices for publishing your research and presenting your findings. Learn how to communicate complex data and results in a compelling and accessible way.\n\n\nWho Is This Course For:\nHigh School Students in AP Research: Those aiming for a top score in their AP Research projects and looking to incorporate advanced data science and machine learning techniques.\nAspiring Researchers: Students and beginners interested in conducting and publishing research using modern data analysis tools and methodologies.\nData Science Enthusiasts: Individuals who are curious about data science and machine learning and want to learn how to apply these skills in practical research settings.\nFuture Tech Innovators: High schoolers who aspire to pursue careers in technology and data science and want to build a strong foundation in these areas.\nPersonal Project Creators: Anyone looking to enhance their personal or academic projects with machine learning and data science insights.\nKeep in mind: Those under 18 may use this course only if a parent or guardian opens their account, handles any enrolment, and manages their account usage.\n\n\nWhy Take This Course:\nBy the end of this course, you'll have accomplished whichever goals you set for yourself in the first lesson, whether that be for AP Research, publication, or personal exploration. You'll be equipped with practical skills and a solid understanding of machine learning and data science, ready to make a significant impact in your academic and personal projects.",
      "target_audience": [
        "AP Research student aiming for a top score",
        "High schooler looking to conduct and publish research",
        "Aspiring tech innovator interested in data science and machine learning"
      ]
    },
    {
      "title": "Python Bootcamp: Vom Anfänger zum Profi, inkl. Data Science",
      "url": "https://www.udemy.com/course/python-bootcamp/",
      "bio": "Python komplett: Grundlagen, Webapps, Crawler, Numpy, Pandas, Module, OOP, IO, Machine Learning, Deep Learning,...",
      "objectives": [
        "Von 0 auf 100 vom Anfänger zum Python-Entwickler",
        "Alles an einfachen Beispielen erklärt",
        "Werde systematisch zu einem gefragten Python-Entwickler",
        "Verstehe das \"warum\" dahinter",
        "Automatisiere deinen Job und erstelle Data-Science-Auswertungen",
        "Extrahiere mit einem Crawler Daten aus Webseiten",
        "Schreibe echte Desktop-Apps mit Qt",
        "Lerne und verstehe Objektorientierung",
        "Fordere dich mit Quizzen und Übungsaufgaben heraus",
        "Erstelle ausführbare .exe-Dateien und teile deine Programme mit deinen Freunden und Kollegen"
      ],
      "course_content": {
        "Einleitung": [
          "Einleitung",
          "Download der benötigten Materialien",
          "Wichtiger Hinweis! (Windows)",
          "Installation aller benötigten Tools & Hallo Welt!",
          "FAQ - Häufig gestellte Fragen"
        ],
        "Python Basics": [
          "Einführung",
          "Zahlen in Python",
          "Variablen in Python",
          "Strings in Python",
          "Zahl oder String?",
          "[überspringen, wenn richtig gelöst] Musterlösung Quiz: Zahlen oder String"
        ],
        "Python Basics (Fortsetzung, Teil 2)": [
          "Listen in Python",
          "Listen in Python",
          "Listen - Die pop-Funktion",
          "Merkblatt: Listen in Python",
          "Motivation",
          "Daten umwandeln (1)",
          "Daten umwandeln (2)",
          "Kommentare",
          "Kommentare in Python",
          "[überspringen, wenn richtig gelöst] Musterlösung Quiz: Kommentare",
          "Merkblätter",
          "Übungsblatt: Python Grundlagen",
          "[überspringen, wenn richtig gelöst] Musterlösung: Python Grundlagen"
        ],
        "Kontrollstrukturen": [
          "Einführung",
          "if, else",
          "Vergleichsoperatoren",
          "Ausdrücke verknüpfen und Booleans",
          "Merkblatt: Vergleichsoperatoren",
          "If & Booleans",
          "[überspringen, wenn richtig gelöst] Musterlösung Quiz: If & Booleans",
          "Der in-Operator",
          "Der not-Operator",
          "Merkblatt: Operatoren und Listen",
          "Der not - Operator",
          "[überspringen, wenn richtig gelöst] Musterlösung Quiz: Der not - Operator",
          "elif"
        ],
        "Kontrollstrukturen (Fortsetzung, Teil 2)": [
          "Die while-Schleife",
          "Die for-Schleife",
          "Wann welche Schleife?",
          "In, Schleifen, ...",
          "[überspringen, wenn richtig gelöst] Musterlösung Quiz: In, Schleifen, ...",
          "Schleifen (break, continue)",
          "Exkurs: Wie gehst du mit Problemen um?",
          "Merkblatt: Schleifen",
          "Übungsblatt Kontrollstrukturen",
          "[überspringen, wenn richtig gelöst] Musterlösung: Übung Kontrollstrukturen"
        ],
        "Funktionen": [
          "Einführung",
          "Funktionen",
          "Funktionen (2)",
          "Ausblick auf Objekte",
          "Einführung Datei öffnen",
          "Hinweis: Wie Backslash („\\“) eingeben?",
          "Datei öffnen",
          "Datei schreiben",
          "Datei und with",
          "CSV öffnen",
          "CSV lesen und Zeilen überspringen",
          "Exkurs: Grafiken zeichnen",
          "Geburtsstatistiken",
          "Hinweis: Geburtsstatistiken",
          "Aufgabe Geburtsstatistiken",
          "Überprüfung deiner Lösung",
          "[überspringen, wenn richtig gelöst] Musterlösung: Aufgabe Geburtsstatistiken",
          "Merkblatt: Funktionen & Methoden",
          "Übungsblatt Funktionen",
          "Lösungstipps: Übungsblatt Funktionen",
          "[überspringen, wenn richtig gelöst] Musterlösung: Übungsblatt Funktionen"
        ],
        "Listen in Python": [
          "Einführung Listen",
          "Arbeiten mit Listen",
          "List Slicing",
          "List Slicing",
          "[überspringen, wenn richtig gelöst] Musterlösung: Quiz List Slicing",
          "List Comprehension",
          "Ausblick: Tupel & Dictionaries",
          "Dictionaries",
          "Dictionaries",
          "[überspringen, wenn richtig gelöst] Musterlösung: Quiz Dictionaries",
          "Tupel",
          "Tupel packen und entpacken",
          "Dictionaries und Schleifen",
          "Aufgabe: Dictionaries & Schleifen",
          "Lösungstipps: Dictionaries & Schleifen",
          "Überprüfe deine Lösung: Aufgabe Dictionaries und Schleifen",
          "[überspringen, wenn richtig gelöst] Musterlösung: Dictionaries & Schleifen",
          "Datenstrukturen ineinander verschachteln",
          "Merkblätter: Dictionaries, Listen und Tupel"
        ],
        "Objektorientierung": [
          "Einführung",
          "Klasse und Methode erstellen",
          "Constructor und Methoden erstellen",
          "Warum private Eigenschaften und Methoden?",
          "Private Eigenschaften und Methoden",
          "Warum kapseln wir Daten?",
          "Besondere Methoden",
          "Vererbung in Python",
          "Aufgabe: Vererbung & Objektorientierung",
          "[überspringen, wenn richtig gelöst] Musterlösung: Vererbung & Objektorientierung",
          "Typen von Variablen überprüfen",
          "In Python ist alles ein Objekt",
          "Wie Variablen, Klassen und Methoden benennen?",
          "Statische Variablen",
          "Merkblatt: Objektorientierung",
          "Übungsblatt: Objektorientierung",
          "[überspringen, wenn richtig gelöst] Musterlösung: Objektorientierung"
        ],
        "Module in Python": [
          "Einführung",
          "Code aus separater Datei laden",
          "Verschiedene import-Möglichkeiten für Module",
          "Module in einem Ordner erstellen",
          "Module",
          "Merkblatt: Module in Python",
          "[überspringen, wenn richtig gelöst] Musterlösung: Quiz Module",
          "Beispiel für ein Modul"
        ],
        "Crawler": [
          "Einführung",
          "Exkurs: Was ist html überhaupt?",
          "html Code holen",
          "beautifulsoup",
          "Exkurs: css-selectors (1)",
          "Exkurs: css-selectors (2)",
          "Elemente finden (1)",
          "Elemente finden (2)",
          "Elemente finden - urllib",
          "Aufgabe: Mehrere Seiten mit Crawler einlesen",
          "Musterlösung: Mehrere Seiten mit Crawler einlesen",
          "Hinweis: Encoding, Schreiben einer Datei",
          "Aufgabe: Ergebnisse als CSV speichern",
          "Hinweis Musterlösung: Ergebnisse als CSV speichern",
          "Musterlösung: Ergebnisse als CSV speichern",
          "CSV-Datei korrekt mit Excel öffnen",
          "Python Wissen - Generators",
          "Generatoren in crawler einbauen",
          "PyCharm installieren - Crawler in ein richtiges Python-Programm umwandeln",
          "Crawler in ein richtiges Python-Programm umwandeln (2)"
        ]
      },
      "requirements": [
        "Computer oder Laptop (Windows/Mac/Linux)",
        "Du benötigst keine Programmierkenntnisse",
        "Motivation Python lernen zu wollen :)"
      ],
      "description": "Dieser Kurs macht dich von null zum Python Profi - und zwar egal, wofür du Python brauchst. Angefangen bei den Grundlagen lernst du alles bis hin zu Webseiten, Desktop-Apps, Data-Science-Auswertungen und Machine Learning.\n„Ein hervorragender Kurs! Sehr klar strukturiert und gut erklärt“ (★★★★★, Alexey Vidanov)\nDieser Kurs enthält über 300 Lektionen, unzählige Quizze, Tests, Praxisprojekte, Merkblätter, und Übungsaufgaben - der einfachste Weg, wenn du Python Profi werden möchtest.\n\n\nES WERDEN KEINE PROGRAMMIERKENNTNISSE BENÖTIGT\n\n\nZuerst ein kleiner Ausblick, was dir dieser Kurs alles bietet:\nVerstehe die Grundlagen von Python\nVerstehe Objektorientierung\nEntwickle eigene Anwendungen in Python\nFordere dein Wissen mit diversen Quizzen und Übungsaufgaben heraus\nLeichtes Wiederholen von Wissen: Umfangreiche Merkblätter\nDiverse Praxisbeispiele:\nExtrahiere Daten aus Webseiten mit einem Web-Crawler\nSchreibe echte Desktop - Anwendungen mit Qt\nEntwickle einen Webserver mit Flask\nWerte Daten automatisiert mit Python aus\nUnd viel mehr...\n\nDieser Kurs enthält diverse Praxisbeispiele. Du lernst also nicht nur die Programmiersprache Python, sondern auch, wie du mit ihr echte Anwendungen entwickeln kannst.\nPython ist eine unglaublich coole Programmiersprache, die für verschiedenste Zwecke verwendet werden kann. Daher ist es nicht nur wichtig, dass du Python selbst lernst, sondern auch lernst, welche Tools Python perfekt ergänzen. Und genau deswegen habe ich diesen Kurs entwickelt - damit du zu einem fähigen Python - Entwickler wirst, egal welche Richtung du nach dem Kurs einschlagen möchtest.\nNach Abschluss dieses Kurses kannst du Desktop - Anwendungen schreiben, Webseiten entwickeln, Daten aus fremden Webseiten extrahieren, zusätzliche Daten über coole Formulare erfassen, und automatisiert mit Python auswerten - also wirklich der komplette Workflow.\n\n\nDazu schauen wir uns im Kurs diverse, zusätzliche Tools an:\nDer DataScience - Stack: Numpy, Pandas und Matplotlib\nWeb - Crawling mit \"requests\" und \"beautifulsoup\"\nWeb - Entwicklung mit Flask\nInteraktive Programme mit Jupyter Notebooks\nDesktop - Anwendungen mit PyQt\n\nMein Ziel ist, dass du nach Abschluss dieses Kurses ein fähiger Python-Entwickler bist - egal für welchen Zweck du Python später konkret einsetzen möchtest. Dadurch bist du ideal für zukünftige Jobs und Projekte vorbereitet.",
      "target_audience": [
        "Für alle die ohne Vorkenntnisse in die Programmiersprache Python einsteigen möchten",
        "Für alle fortgeschrittene Entwickler, die diverse Anwendungsszenarien von Python erlernen möchten",
        "Kurz: Für alle die Python produktiv einsetzen möchten"
      ]
    },
    {
      "title": "Smarter Web Scraping with Python + AI",
      "url": "https://www.udemy.com/course/smarter-web-scraping-with-python-ai/",
      "bio": "Unlocking Data Insights and Automation: Master Python, AI Integration, Web Scraping, and Data Analysis",
      "objectives": [],
      "course_content": {
        "Course Overview": [
          "Welcome",
          "Demo",
          "Requirements & Overview"
        ],
        "Project Setup": [
          "Project Setup",
          "Hello World & Environment Variables"
        ],
        "Scraping Data with Selenium & Python": [
          "Selenium Connection Sample",
          "Remote Connection Utility Function",
          "Understanding Web App URL Structures",
          "Parse HTML with BeautifulSoup",
          "Extract More Post Data from List View",
          "Pagination with Selenium and Hacker News",
          "Scrape and Save Data to Local Files"
        ],
        "Python and AI with Ollama and Llama 2": [
          "Download and Run Ollama with LLama 2",
          "Ollama with Open Python Client",
          "Summarize and Extract Keywords of Scraped Data"
        ],
        "Extracting Podcasts with the Apple Search API": [
          "Searching Podcasts with the Apple iTunes Search API",
          "Saving Podcast Data based on Keywords",
          "Download Podcast Episodes",
          "Chunk and Transcribe Podcast Episodes",
          "Summarize and Recommend Episodes"
        ],
        "Wrap up": [
          "Thank you and next steps"
        ]
      },
      "requirements": [
        "Basic programming knowledge, familiarity with Python, access to a computer with internet. Ideal for beginners; some understanding of HTML is helpful."
      ],
      "description": "Smarter Web Scraping with Python + AI\nUnlocking Data Insights and Automation\nEmbark on a transformative journey into the world of smarter web scraping, where Python's power meets the innovative capabilities of artificial intelligence. This course is designed to equip you with the knowledge and skills to navigate the digital landscape efficiently, turning web data into actionable insights and automating complex tasks with ease.\nWhat You'll Achieve:\nSophisticated Data Extraction: Elevate your scraping skills with advanced techniques for dynamic websites, utilizing tools like Selenium and BeautifulSoup for nuanced data retrieval..\nAI-Driven Analysis: Infuse your projects with AI, employing Large Language Models to transform raw data into profound insights, elevating your analytical capabilities.\nStreamlined Workflows: Unveil the secrets to automating mundane tasks, optimizing your processes, and dedicating more time to strategic analysis and innovation.\nData Analysis Excellence: Command the full cycle of data handling, from sophisticated extraction methods to in-depth analysis, mastering the art of turning extensive datasets into actionable intelligence.\nInnovative LLM Applications: Harness the potential of emerging Large Language Models such as Ollama and LLama 2, integrating state-of-the-art AI tools for unparalleled depth in your web scraping endeavors.\nCourse Highlights:\nRobust Foundation: Regardless of your expertise level, begin with the essentials of Python and web scraping, ensuring a solid base for all learners.\nReal-World Application: Through immersive projects that mirror actual industry challenges, you'll gain practical experience that's directly applicable outside the classroom.\nAI Integration: Delve into the synergy between web scraping and artificial intelligence, mastering innovative tools that set the stage for future technological advancements.\nAll-Encompassing Syllabus: From initial setup to sophisticated data manipulation, our curriculum covers every angle, providing a holistic educational journey.\nIdeal Participants:\nBudding Data Scientists: Embark on a data-centric career equipped with cutting-edge tools and methodologies.\nVisionary Entrepreneurs: Utilize the power of web data to propel your business ideas and innovative ventures.\nTechnology Aficionados: Expand your repertoire with the latest in web scraping and AI, whether for professional development or personal passion.\nEager Academics: If your curiosity is piqued by the transformative potential of Python and AI in data insight, this course is tailored for you.\nGet Started Today:\nJoin us in \"Smarter Web Scraping with Python + AI\" and unlock the potential of web data. Whether you're looking to enhance your career, kickstart new projects, or simply indulge your curiosity, this course offers the tools, knowledge, and community support to help you achieve your goals.\nEnroll now and step into the future of web scraping and automation with Python and AI!",
      "target_audience": [
        "Anyone interested in leveraging AI and LLMs in their web scraping process",
        "Anyone looking to understand modern web scraping with Python",
        "Data Enthusiasts: Anyone with a curiosity for data, how to extract it, and ways to harness it for insightful projects.",
        "Python Newbies: Just starting with Python? You'll find a welcoming space to apply your skills in real-world scenarios.",
        "Budding Entrepreneurs & Innovators: If you're dreaming of turning data into opportunities, this is where your journey begins."
      ]
    },
    {
      "title": "เรียนรู้ AI: Machine Learning ด้วย Python",
      "url": "https://www.udemy.com/course/ai-machine-learning-python/",
      "bio": "เน้นการเรียนรู้ด้วยการปฏิบัติ เรียนแบบ Step-by-step เหมาะสำหรับผู้เริ่มต้นศึกษา Machine Learning และไปต่อ Deep Learning",
      "objectives": [
        "หลักการ AI และ Machine Learning",
        "กระบวนการสร้าง Machine Learning",
        "อัลกอริทึมที่สำคัญของ Machine Learning",
        "การเตรียมข้อมูล การสร้าง Model สำหรับ Machine Learning",
        "การประเมินทดสอบ",
        "เรียนรู้จากโค้ดตัวอย่างและชุดข้อมูล Dataset ที่เข้าใจง่าย",
        "ใช้งานไลบรารีที่ได้รับความนิยม Sciki-learn, Pandas, Matplotlib, Seaborn และอื่น ๆ"
      ],
      "course_content": {
        "Introduction": [
          "แนะนำคอร์ส",
          "เบื้องต้นเกี่ยวกับ AI และ Machine Learning"
        ],
        "การติดตั้งเครื่องมือ (โปรแกรม) และเตรียมความพร้อม": [
          "การติดตั้งโปรแกรมและเตรียมความพร้อม (+Download Source Code)",
          "รู้จักกับเครื่องมือ Jupyter",
          "การเปิด Jupyter",
          "การใช้งาน Jupyter",
          "การใช้งาน Colab",
          "การใช้งานไฟล์บน Colab",
          "การใช้ VSCode กับ Jupyter"
        ],
        "เรียนลัด การเขียนโปรแกรม Python": [
          "เรียนลัด Python (Crash course) ระดับเบื้องต้น",
          "เงื่อนไข การวนรอบ และการแสดงผล",
          "ข้อมูล List & Tuple",
          "ข้อมูล Dictionary",
          "ฟังก์ชัน (Function)",
          "ไลบรารี",
          "การติดตั้งไลบรารี"
        ],
        "ข้อมูล": [
          "ชนิดข้อมูลสำหรับ Machine Learning",
          "การใช้ไลบรารี Numpy",
          "Pandas: เกี่ยวกับไลบรารี",
          "Pandas: ใช้งานไลบรารี สร้างข้อมูลและอ่านไฟล์ บันทึกไฟล์",
          "Pandas: การเข้าถึงข้อมูลและการพล็อต"
        ],
        "Data Visualization": [
          "Data Visualization",
          "การพล็อตข้อมูลด้วย Matplotlib",
          "การพล็อตข้อมูลด้วย Seaborn"
        ],
        "Machine Learning 101": [
          "เกี่ยวกับ Machine Learning",
          "สมการเส้นตรง",
          "การเขียนโปรแกรมแบบปกติทั่วไป",
          "การเขียนโปรแกรมโดยใช้ Machine Learning"
        ],
        "Regression": [
          "Regression",
          "การประเมิน Model สำหรับ Regression",
          "Multiple Regression สำหรับกรณีตัวแปรมากกว่า 2 ตัว",
          "Polynomial Regression สำหรับความสัมพันธ์แบบแนวเส้นโค้ง",
          "Polynomial Regression: Workshop",
          "ปัญหา Overfitting & Underfitting"
        ],
        "การจำแนก (Classification)": [
          "Classification การจำแนก",
          "Workshop 1: Decision Tree Model จำแนก มะนาว ส้ม",
          "Workshop 2: Decision Tree Model จำแนกผลไม้ 3 ชนิด (3 Classes)",
          "Workshop 3: Decision Tree Model มี 2 Features 2 Class",
          "Workshop 3: Decision Tree Model มี 2 Features 3 Class"
        ],
        "การเตรียมข้อมูล": [
          "การเตรียมข้อมูล",
          "การตรวจสอบข้อมูลเบื้องต้น",
          "การตรวจสอบดูข้อมูลสูญหาย (Missing Values)",
          "การจัดการกับ Missing Values"
        ],
        "การประเมิน Model": [
          "การประเมิน (Model Evaluation)",
          "Metrics การคำนวณ",
          "Workshop 1: ประเมิน Model แบบ 2 Class (Binary)",
          "Workshop 2: ประเมิน Model ที่มีมากกว่า 2 Class",
          "แบ่งข้อมูลด้วย Train Test split",
          "การแบ่งประเมินแบบ Cross-validation"
        ]
      },
      "requirements": [
        "ความรู้พื้นฐานคอมพิวเตอร์"
      ],
      "description": "คอร์สนี้เหมาะสำหรับผู้เริ่มต้นศึกษา AI: Machine Learning โดยใช้ภาษา Python ที่เรียนรู้และเข้าใจง่าย และใช้ไลบรารี Scikit-learn ยอดนิยมสำหรับ Machine Learning ลักษณะการเรียนเป็นแบบ Step-by-step  เนื้อหาครอบคลุมการติดตั้งโปรแกรม พื้นฐานทั่วไป การเตรียมข้อมูล การสร้าง Model การปรับแต่ง รูปแบบการเรียนการสอน จะเน้นการลงมือปฏิบัติ Workshop โดยมีโค้ดตัวอย่างให้ทดลอง ช่วยให้เข้าใจได้ง่ายขึ้น โดยแต่ละหัวข้อจะแทรกทฤษฎีที่สำคัญ มีคณิตศาสตร์น้อย (เท่าที่จำเป็น พร้อมภาพอธิบายประกอบบ) อธิบายโดยใช้ภาษาที่เข้าใจง่ายในทุกระดับ มีปภาพประกอบการอธิบายเพื่อให้เข้าใจง่าย อธิบายส่วนของโค้ด ลำดับเนื้อหาเพื่อเป็นพื้นฐานให้กับบทต่อ ๆ ไป\nเรียนรู้อัลกอริทึมต่าง ๆ ที่สำคัญ  อาทิ Regression, Decision Tree, Support Vector Machine (SVM), k-Nearest Neighbors ฯลฯ เพื่อเป็นพื้นฐานนำไปต่อยอดประยุกต์ใช้งาน รวมถึงต่อยอด Deep Learning (คอร์สต่อไป)\n** Source Code อยู่ใน Section บทที่ 2",
      "target_audience": [
        "นักเรียน นักศึกษา หรือผู้สนใจศึกษาเทคโนโลยีเกี่ยวกับ AI",
        "นักวิจัย นักพัฒนา นักเรียน นักศึกษา ที่ทำโปรเจคด้าน AI ด้วย Machine Learning"
      ]
    },
    {
      "title": "Masterclass Python | Algorithmes et traitement de données",
      "url": "https://www.udemy.com/course/formation-python-algorithmes/",
      "bio": "Maitrisez les algorithmes du plus simple au plus complexe, passez vos entretiens d'embauche, réalisez des projets réels",
      "objectives": [
        "Progresser considérablement en programmation (même si vous êtes totalement débutant)",
        "Maitriser les algorithmes, du plus simple au plus complexe (sans être bon maths ou en logique)",
        "Pouvoir passer vos tests en entretiens d'embauche (même si vous commencez votre reconversion professionnelle)",
        "Savoir structurer et traiter des données (même la quantité est importante)",
        "Savoir créer vos propres applications \"réelles\" (même si vous n'avez pas beaucoup de temps)",
        "Savoir tracer des graphes avec Matplotlib",
        "Savoir exporter vos données au format excel avec Pandas",
        "Savoir scraper des sites web avec Requests et Beautifulsoup",
        "Savoir traiter des données audio (échantillons sonores)",
        "Savoir traiter les cours de bourse (trading)"
      ],
      "course_content": {
        "INTRODUCTION": [
          "Récupérez vos cadeaux de bienvenue !"
        ],
        "LANGAGE PYTHON : BASES ET RAPPELS": [
          "Introduction",
          "Les bases du langage Python",
          "Rappels Python : Les listes",
          "Notion : Listes à 2 dimensions",
          "Rappels Python : Les fonctions",
          "Rappels Python : Dictionnaire",
          "Rappels Python : Set",
          "Rappels Python : Chaines"
        ],
        "PARTIE 1 : BIEN DÉMARRER SUR LES ALGORITHMES (NIVEAU DÉBUTANT/INTERMEDIAIRE)": [
          "Introduction",
          "Comment utiliser la plateforme ?",
          "Challenge : La descente",
          "Challenge : Power of Thor 1",
          "Challenge : Températures",
          "Challenge : Mars Lander 1",
          "Challenge : Ascii Art",
          "Challenge : Chuck Norris",
          "Challenge : MIME Type",
          "Challenge : Défibrillateurs",
          "Challenge : Chevaux de course"
        ],
        "PARTIE 2 : TESTS D’ENTRETIENS D’EMBAUCHE (NIVEAU DÉBUTANT/INTERMEDIAIRE)": [
          "Introduction",
          "Inverser une chaine",
          "Compter les majuscules",
          "Mot le plus court/plus long",
          "Les mots communs",
          "Données monotones",
          "Supprimer les doublons",
          "Trouver les éléments manquants",
          "Conversion chaine vers nombre"
        ],
        "PARTIE 3 : ALGORITHMES : « LES GRANDS CLASSIQUES » (NIVEAU INTERMEDIAIRE/AVANCÉ)": [
          "Introduction",
          "Algorithmes de tris : Le principe",
          "Tri par sélection",
          "Tri à bulle (bubble sort)",
          "Tri rapide (quick sort)",
          "Tris : comparaison des performances",
          "Recherche linéaire",
          "Recherche dichotomique",
          "Exercice : Résoudre le nombre magique",
          "Challenge : Shadows of the knight 1",
          "Parcours à 2 dimensions : Labyrinthe",
          "Challenge : There is no spoon",
          "Rendre la monnaie (glouton et force brute)",
          "Supprimer les doublons : Algo 1 (linéaire)",
          "Supprimer les doublons : Algo 2 (éléments successifs)",
          "Supprimer les doublons : Algo 3 (table de hachage)",
          "Liste chainée : Principe",
          "Liste chainée : Remarque",
          "Liste chainée : Implémentation"
        ],
        "PROJET : « SILENCE REMOVER » V1": [
          "Projet Silence Remover V1 : Introduction",
          "Lire un fichier Wav",
          "Le format WAV",
          "Implémenter la conversion",
          "Afficher les samples (matplotlib)",
          "Logiciel audio : Audacity",
          "Algorithme : principe",
          "Algorithme : Normaliser",
          "Algorithme : Threshold",
          "Algorithme : Glitch",
          "Algorithme : Longueur minimale",
          "Ecrire un fichier Wav",
          "Supprimer les zones de silence",
          "Conclusion"
        ],
        "PROJET : « SILENCE REMOVER » V2": [
          "Projet Silence Remover V2 : Introduction",
          "Arguments en ligne de commande",
          "Drag and drop"
        ],
        "PROJET : « BITCOIN ANALYSER » - V1 : DATASET": [
          "Projet Bitcoin Analyser V1 : Introduction",
          "Comprendre les API REST, le protocole HTTP et le format JSON",
          "Présentation de l’API",
          "Création du projet et premier appel à l’API",
          "Exercice : Cas d’erreurs et affichage des données",
          "Exercice : Quota restant",
          "Exercice : Paramètre d’url",
          "Exercice : Récupérer le cours du bitcoin",
          "Exercice : Paramètres de fonction",
          "Python : Les dates",
          "Exercice : Les 10 derniers cours du bitcoin",
          "Problématique : Limite de l’API",
          "Principe : Gestion des données",
          "Exercice : Fichier Json",
          "Lecture du fichier Json et organisation du code",
          "Générer les intervalles de dates",
          "Exercice : retravailler la fonction « exchange rates »",
          "Exercice : « Exchanges rates extended »",
          "Exercice : Appels à l’API et mise à jour des données",
          "Réorganisation du code : Data manager",
          "Afficher les données",
          "Filtrer les données",
          "Exercice : Tester l’inconsistence des données"
        ],
        "PROJET : « BITCOIN ANALYSER » - V2 : ALGORITHME TRADING": [
          "Projet Bitcoin Analyser V2 : Introduction et principe de l’algorithme",
          "Exercice : Implémenter l’algorithme de la moyenne mobile",
          "Tracer les moyennes mobiles",
          "Exercice : problème de la date de début",
          "Exercice : problème de la date de fin",
          "Exercice : Ensemble des MM",
          "Algorithme : Points d’achats et de ventes",
          "Exercice : Tracer les points d’achats et de ventes",
          "Exercice : Améliorer l’algorithme avec un Threshold",
          "Conclusion"
        ],
        "PROJET : « BITCOIN ANALYSER » - V3 : SIMULATION BOT": [
          "Projet Bitcoin Analyser V3 : Introduction et principe de l’algorithme",
          "Exercice : implémenter l'algorithme d’achat et de ventes",
          "Exercice : Afficher les phrases du bot",
          "Exercice : Afficher les pourcentages de gains et pertes",
          "Corrélation sur la durée des moyennes",
          "Conclusion"
        ]
      },
      "requirements": [
        "Vous n'avez pas besoin de prérequis pour suivre cette formation : si vous êtes débutant, je vous donnerai toutes les bases du langage Python",
        "Si vous avez déjà les bases du langage python : La section sur les rappels vous permettra de commencer rapidement dans la formation"
      ],
      "description": "Vous voulez devenir développeur, trouver un emploi, devenir freelance, ou bien créer des projets ambitieux et innovants ?\nPeut être que vous êtes en reconversion professionnelle ou que vous cherchez à améliorer vos compétences de développeur.\nVous avez commencé par apprendre un langage, et peut être un autre. Et aussi, vous avez appris un framework, pour commencer à créer des projets.\nBien.\n\n\nMais laissez moi vous dire la vérité :\nEn programmation, apprendre les bases d'un langage et un framework ne suffirons pas à faire de vous un développeur.\n\n\nPourquoi ?\nParceque concrètement, et à part quelques projets simplissimes, vous ne savez encore rien faire.\n\n\nOui, connaitre un langage et un framework sont des étapes incontournables.\nIl faut bien commencer quelque part.\n\n\nMais maintenant,\nvous sentez que quelque chose vous bloque ou vous manque pour avancer\nVous sentez que vous n'avez toujours pas les compétences \"légitimes\" d'un \"vrai développeur\".\nEt que vous n'arrivez toujours pas à coder exactement ce que vous voulez (notamment ce projet que vous avez en tête et qui vous tiens à coeur).\nEt les entretiens d'embauche... vous ne vous sentez pas encore vraiment prêt à ça.\n\n\nCe que vous ne savez peut être pas :\nC'est que les algorithmes, c'est surement ce qu'il vous manque pour progresser.\n\n\nVous savez inverser une chaine ? Eliminer des doublons dans une liste ? Faire une recherche dichotomique ? Implémenter un tri rapide ? Coder une liste chainée ?\n\n\nSi vous avez répondu non, ne cherchez pas plus loin :\nVous pourrez apprendre tous les langages que vous voulez, tous les derniers frameworks à la mode, ou suivre une n-ième formation, ça ne changera rien au problème.\n\n\nSans la maitrise des algorithmes, vous n'avez strictement \"aucunes chances\" de progresser en tant que développeur, que ce soit :\n- Pour trouver un emploi\n- Pour améliorer votre carrière\n- Pour créer des projets plus puissants\n- Ou pour donner vie à vos idées novatrices.\n\n\nGoogle, Facebook, Amazon, Apple\nToutes les grandes sociétés de ce monde dominent le marché technologique par la supériorité de leurs algorithmes et de leur traitement plus poussé de la data.\nEt c'est pour ça qu'il sélectionnent en premier lieu, les candidats les plus doués sur le traitement de données et le développement d'algorithmes complexes.\n\n\nLes algorithmes\nC'est \"une façon de faire les choses\".\nPar exemple vous demandez à deux personnes de cuisiner une omelette. Ils le ferons très certainement d'une manière différente.\nUne personne va démarrer par casser les oeufs, tandis que l'autre commencera par allumer le Gaz.\nLa différence ? L'un terminera avant l'autre. L'un aura une meilleure qualité que l'autre. Eh bien c'est la même chose en programmation : pour un même programme, un code sera meilleur et plus performant qu'un autre.\n\n\nDans cette \"Masterclass Python\", on ira en profondeur sur les algorithmes et le traitement de données.\n\n\nCette formation va vous permettre :\n- De progresser considérablement en programmation, même si vous n'avez que les bases du langage Python (ou même si vous êtes totalement débutant car je vous redonnerez les bases)\n- De maitriser les algorithmes du plus simples au plus complexe, avec une pédagogie adaptée pour que tout le monde puisse comprendre, sans avoir besoin d'être bon en logique ou en mathématiques\n- De passer vos tests en entretien d'embauche, même si vous débutez tout juste votre reconversion professionnelle\n- De savoir créer vos propres applications \"réelles\", (même si vous n'avez pas énormément de temps à y consacrer)\n\n\nJe vous redonnerez également toutes les bases du langage Python et les rappels les plus importants, pour que vous n'ayez pas besoin, au préalable, d'avoir suivi une autre formation.\n\n\nUne méthode unique :\nDéjà plus de 15000 participants ont suivi mes programmes et reconnaissent ma pédagogie comme étant la plus simple et la plus efficace possible.\nIci, pas de cours scolaires ou théoriques compliqués, on est sur du concrêt. On avance progressivement avec : des exercices et une pédagogie adaptée, pour que tout le monde puisse comprendre.\n\n\nTrois parties pour progresser étapes par étapes :\n* PARTIE 1 : Challenges de code\nVous allez écrire vos premiers algorithmes, pour résoudre des \"challenges de code\", c'est à dire : des problèmes sous forme de jeux.\nC'est la méthode la plus simple et la plus efficace pour bien commencer.\n\n\n* PARTIE 2 : Les tests en entretien d'embauche.\nDans cette partie on va revenir ensemble sur toutes les question classiques en entretiens d'embauche :\n- Parcourir des chaines de caractères\n- Comparer des listes\n- Convertir des données.\n- Etc...\nNotions incontournables que vous devez savoir en tant que développeur.\n\n\n* PARTIE 3 : Les grands \"classiques\" de l'algorithmie\nTris à bulle, tris rapides, recherche linéaire / dichotomique, parcours de graphes, listes chainées...\nLes algorithmes n'auront plus de secrets pour vous.\n\n\nDes projets uniques :\nDans chaque projets vous allez pouvoir créer vos propres algorithmes et gérer vos propres données.\n\n\n* PROJET 1 : Silence Remover\nVous allez apprendre à traiter des fichiers son (WAV), au niveau des échantillons sonores, pour supprimer des \"zones de silences\".\nEt vous verrez que notre algorithmes fonctionnera également si il y a du bruit de fond dans la pièce.\nVous apprendrez aussi : A lire/écrire des fichiers WAV, à convertir des données 8bits/16 bits, et à tracer des graphes avec Matplotlib\n\n\n* PROJET 2 : Bitcoin Analyser\nA partir de données réelles et mises à jour du cours du bitcoin, vous allez créer votre propre \"algorithme de trading\", qui va décider quand acheter et quand revendre, et qui vous permettra ensuite de simuler un bot pour calculer vos gains.\nCe programme peut également fonctionner pour toute autre crypto ou symbole monétaire.\nVous apprendrez aussi : à appeler une API REST, utiliser le format JSON et à tracer des graphes avec Matplotlib\n\n\n* PROJET 3 : Cake scrap\nVous allez apprendre le scraping, pour extraire des informations à partir de pages web (HTML).\nVous n'avez pas besoin de connaitre le langage HTML pour suivre ce projet.\nNous allons extraire des recettes de gateaux et donner à notre algorithme la liste des ingrédients que l'on possède chez nous (farine, sucre, oeufs...). Celui ci nous proposera une liste de recette que l'on peut réaliser en fonction des ingrédients.\nVous verrez, c'est pratique !\nVous apprendrez aussi : à utiliser Requests, Beautifulsoup, et Pandas pour extraire vos données au format Excel.\n\n\nCommencez maintenant :\nQue vous soyez débutant, en reconversion professionnelle, ou que vous cherchez tout simplement à vous améliorer : cette formation est faite pour vous !\nEn bonus, retrouvez également:\n- Le pack de ressources : téléchargez, en une fois, tous les codes sources et les fichiers PDF de cette formation\n- L'accès à la communauté : échangez vos idées et entraidez-vous entre membres (1800+ membres à l'intérieur)\n- La garantie 30 jours satisfait ou remboursé : vous ne prenez aucun risque\n- Un support prioritaire et illimité : vous avez une question, une erreur ou quoi que ce soit, obtenez une réponse garantie dans la journée, vous n'êtes jamais bloqué.\n\n\n--\nAlors, prêt à maitriser les algorithmes et à améliorer vos compétences de développeur ?\n\n\nOn se retrouve dans la formation",
      "target_audience": [
        "Toute personne souhaitant débuter en programmation",
        "Développeur Python souhaitant améliorer ses compétences",
        "Toute personne en cours de reconversion professionnelle",
        "Développeur souhaitant maitriser les algorithmes et la data pour créer des projets plus puissants"
      ]
    },
    {
      "title": "R. Curso completo de R para Data Science y Machine Learning",
      "url": "https://www.udemy.com/course/master-en-data-science-y-machine-learning-con-r-y-rstudio/",
      "bio": "Aprende a programar en R, el lenguaje para Data Science, Machine Learning y visualización de datos. Aprende R desde cero",
      "objectives": [
        "Aprenderás a programar en R mediante la herramienta RStudio",
        "Aprenderás a crear visualizaciones de datos con R y RStudio",
        "Aprenderás R para Data Science",
        "Aprenderás R para análisis de datos",
        "Aprenderás a usar los algoritmos de Machine Learning con R",
        "Aprenderás a manejar la herramienta RStudio",
        "Aprenderás redes neuronales para Machine Learning con R",
        "Aprenderás a cargar datasets o conjuntos de datos en RStudio",
        "Aprenderás a crear impresionantes gráficos interactivos con R y RStudio"
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Instalación de R y RStudio",
          "Introducción a la herramienta RStudio"
        ],
        "Introducción a R": [
          "Operaciones aritméticas con R",
          "Variables en R",
          "Tipos de datos en R",
          "Vectores en R",
          "Operaciones con vectores en R",
          "Operadores de comparación en R",
          "Acceso a los elementos de un vector en R",
          "Ayuda y documentación de R en RStudio",
          "Ejercicio 1",
          "Solución al ejercicio 1"
        ],
        "Matrices en R": [
          "Matrices en R",
          "Operaciones aritméticas con matrices",
          "Operaciones con filas y columnas en matrices en R",
          "Seleccionar elementos de una matriz en R",
          "Categorías con función factor",
          "Ejercicio sobre matrices en R"
        ],
        "Data Frames en R": [
          "Crear nuestro primer DataFrame",
          "Datasets o conjuntos de datos de ejemplo en RStudio",
          "Selección y ordenación de Data Frames en R",
          "Importar y exportar ficheros de tipo csv",
          "Juntar 2 Data Frames por filas mediante R",
          "Trabajando con Data Frames por columnas en R",
          "Manejar valores nulos en Data Frames con R",
          "Ejercicio 1 con Data Frames",
          "Ejercicio 2 con Data Frames",
          "Solución al ejercicio 2 con Data Frames"
        ],
        "Listas en R": [
          "Listas"
        ],
        "Entrada y salida de datos en R mediante RStudio": [
          "Entrada y salida de ficheros csv",
          "Leer y grabar ficheros EXCEL",
          "Bases de datos en R"
        ],
        "Programación básica en R": [
          "Operadores lógicos en R",
          "Sentencias condicionales if else",
          "Bucle while",
          "Bucle for",
          "Funciones en R",
          "Ejercicio 1",
          "Ejercicio 2",
          "Ejercicio 3",
          "Ejercicio 4",
          "Ejercicio 5"
        ],
        "Programación avanzada en R": [
          "Funciones predefinidas",
          "Aplicar funciones sobre un vector o una lista",
          "Funciones anónimas en R",
          "Funciones matemáticas en R",
          "Expresiones regulares",
          "Manipular la fecha y la hora en R"
        ],
        "Manipulación de datos con R": [
          "Manipulación de datos con dplyr",
          "Operador pipe",
          "Limpieza de datos con tidyr"
        ],
        "Visualización de datos en R con RStudio": [
          "Histogramas",
          "Scatterplots",
          "Barplots",
          "Boxplots",
          "Gráficos para la distribución de 2 variables",
          "Límites y dimensiones de los gráficos"
        ]
      },
      "requirements": [
        "No es necesario tener conocimientos previos. Todo se explica desde cero."
      ],
      "description": "Este curso sobre el lenguaje de programación R está diseñado para aprender desde cero, paso a paso, hasta convertirte en un experto.\nTodo está explicado mediante ejemplos para facilitar el aprendizaje\nEstos son los temas tratados en este curso sobre R\nConfiguración del entorno\nInstalación de R y RStudio\nIntroducción a R\nOperaciones aritméticas, variables, tipos de datos, vectores, operadores de comparación, ayuda y documentación\nMatrices en R\nOperaciones aritméticas con matrices, selección de elementos, selección por filas y columnas, función factor\nData Frames en R\nCreación de Data Frames, dataset, selección y ordenación, exportar e importar datos y tratamiento de valores nulos\nListas en R\nCreación y manejo de listas\nEntrada y salida de datos en R\nFicheros CSV, ficheros EXCEL y bases de datos\nProgramación básica de R\nOperadores lógicos, condicionales if else, bucle while, bucle for y funciones\nProgramación avanzada de R\nFunciones predefinidas, funciones sobre vectores, funciones anónimas, funciones matemáticas, expresiones regulares, fecha/hora\nManipulación de datos con R\nManipulación de datos con dplyr, operador pipe y limpieza de datos con tidyr\nVisualización de datos con R\nHistogramas, scatterplots, barplots, boxplots, gráficos de distribución, límites y dimensiones\nGráficos interactivos con Plotly\nIntroducción a Machine Learning\nMachine Learning\nAlgoritmo de regresión lineal\nAlgoritmo de regresión logística\nAlgoritmo de los K vecinos más cercanos\nAlgoritmo de árboles de decisión\nAlgoritmo de Random Forest\nAlgoritmo de máquinas de vectores de soporte\nAlgoritmo de K medias\nDeep Learning\nRedes neuronales\n\n\nApúntate a este curso y conviertete en un cientifico de datos!\nTodos los temas están explicados con ejemplos para facilitar el aprendizaje.\nTiene una garantía de reembolso de 30 días, así que no pierdes nada.\nNos vemos en el curso !!",
      "target_audience": [
        "Cualquier persona que quiera convertirse en científico de datos",
        "Cualquier persona que quiera aprender a realizar gráficos interactivos con conjuntos de datos mediante la herramienta RStudio",
        "Cualquier persona interesada en Machine Learning",
        "Cualquier persona que quiera aprender el lenguaje de programación R y la herramienta RStudio"
      ]
    },
    {
      "title": "【TensorFlow・Python 3】GANによる画像生成AI自作入門",
      "url": "https://www.udemy.com/course/tensorflow-gan/",
      "bio": "「お父さんAIスケッチ」で使われている、TensorFlowとPython3で画像生成（GAN：Generative Adversarial Network。敵対的生成ネットワーク）に挑戦。TensorFlowによる開発手順も確認できます。",
      "objectives": [
        "GANの基本的な仕組みを理解できる",
        "Python+TensorFlowで多層パーセプトロンによるGANを実装できるようになる",
        "Python+TensorFlowで畳み込みニューラルネットワークによるGAN（DCGAN）を実装できるようになる"
      ],
      "course_content": {
        "はじめに": [
          "コースの概要",
          "Anaconda 3のインストール（Windows 10）",
          "Anaconda 3 5.1.0のインストール"
        ],
        "TensorFlow CPU版のインストール（Windows 10）": [
          "TensorFlow CPU版のインストール"
        ],
        "TensorFlow GPU版のインストール（Windows 10）": [
          "TensorFlow GPU版のインストール"
        ],
        "Jupyter Notebookのセットアップ": [
          "Jupyter Notebookのインストール"
        ],
        "GANにチャレンジ": [
          "TensorFlow 2.3.0用のノートブック",
          "セクションの概要",
          "プログラム全体の流れ",
          "matplotlibのインストール",
          "パッケージのインポートとデータの読み込み",
          "プレースホルダーを生成する関数の定義",
          "ジェネレータ関数を定義しよう",
          "ディスクリミネーター関数の定義",
          "ハイパーパラメーターの初期化",
          "計算グラフの定義",
          "損失関数の定義",
          "最適化手法の定義",
          "トレーニングの実行（ミニバッチデータの確認）",
          "トレーニングを実行するコードを書こう",
          "トレーニングを実行してみよう",
          "学習精度（ロス）を可視化してチェックしよう",
          "ジェネレーターの生成した画像を表示してみよう！",
          "学習途中の生成データを表示してみよう",
          "ジェネレーターのモデルに新しい画像を生成させてみよう",
          "練習課題：　画像を生成してみよう",
          "セクションのまとめ",
          "セクションのノートブックとスライド"
        ],
        "DCGANに挑戦": [
          "データセットのダウンロード",
          "ノートブックを追加しよう",
          "MATLABデータをロードしよう",
          "入力データのスケールを揃える関数を定義しよう",
          "データセットを扱うクラスを定義しよう",
          "ミニバッチを生成する関数を定義しよう",
          "入力データのプレースホルダーを生成する関数を定義しよう",
          "ジェネレーターの関数を定義しよう",
          "ディスクリミネーターを定義しよう",
          "損失関数を定義しよう",
          "最適化関数を定義しよう",
          "モデルのクラス（テンプレート）を定義しよう",
          "生成画像を表示する関数を定義しよう",
          "トレーニングの関数を定義しよう",
          "トレーニングを実行しよう",
          "ロスをプロットしてみよう",
          "DCGANセクションのノートブック"
        ],
        "Pythonのクイックレビュー（スキップok）": [
          "Pythonの概要と特徴",
          "Pythonの長所・短所",
          "はじめてのPythonプログラムの実行"
        ],
        "旧コンテンツのアーカイブ": [
          "CUDA 9.0のダウンロード",
          "CUDA 9.0のインストール",
          "cuDNN 7.0のダウンロード・インストール",
          "TensorFlow 1.6 CPU版のインストール（Windows 10）",
          "TensorFlow 1.6.0 GPU版のインストール"
        ],
        "ボーナスセクション": [
          "関連コースの紹介"
        ]
      },
      "requirements": [
        "TensorFlow体験コースの受講を終えていると理解しやすいです。（なくてもチャレンジは可能）",
        "ニューラルネットワークと畳み込みニューラルネットワークの知識があると理解しやすいです（レクチャーでも解説します）",
        "インターネット接続可能なPC（Windows, Mac, Linux）",
        "PCの基本的な操作(フォルダの作成や、ファイルの保存など）"
      ],
      "description": "【更新情報】\n2018/8/23 DCGANのセクションのレクチャーをすべてアップロードしました。\n2018/4/7 GANセクションのまとめ、Jupyter Notebook, スライドをアップロードしました。\n【コース概要】\n2018年現在、ますますAI活用への注目が集まっています。\n中でも、イアン・グッドフェロー氏（現Google Researchチーム）が発案したGAN（敵対的生成ネットワーク）は最も注目を集めるアルゴリズムで、\nテキストから画像を生成する\n超解像（低解像度画像から鮮明な高解像度画像を生成する）\n人間の映像を自動生成する\nなど、さまざまな応用が進められています。\n\n\n日本では、ソフトバンク社が5万枚の画像で学習させた「おとうさんAIスケッチ」を公開しています。\n線画からお父さんぽい写真を生成します。\n\n\nこのコースでは、TensorFlowを用いて、このGANによる画像生成AI開発にチャレンジします。\n【コース概要】\n１．イントロ\nGANとは？\nGANでどんなことができるか？\n２．環境構築\nAnacondaのインストール\nTensorFlowのインストール\nJupyter Notebookのインストール\n３．GANに挑戦\nニューラルネットワーク(多層パーセプトロン）によるGANにより、MNIST(手書き数字）を学習させ、コンピューターに数字を書かせます。\n４．DCGANに挑戦\n畳み込みニューラルネットワークを使用したGAN、DCGANによる画像生成にチャレンジします。\nmatplotlibによるグラフ描画（FIG, AXESの使い分けなど）\npickleによるデータの保存・読込み\n５．Pythonのクイックレビュー\nPythonがはじめてな方向けのチュートリアル（スキップ可能）",
      "target_audience": [
        "画像自動生成AIの開発にチャレンジしたい方",
        "TensorFlow体験コースを受講済みで、スタイル変換に使用したGANのモデルを自作してみたい方",
        "GAN(敵対的生成ネットワーク）の理論を実習を通じて理解したい方"
      ]
    },
    {
      "title": "Aprenda Machine Learning em Python com Scikit-learn",
      "url": "https://www.udemy.com/course/aprenda-machine-learning-em-python-com-scikit-learn/",
      "bio": "Dê os primeiros passos na área da Inteligência Artificial com Machine Learning em Python 3 e Scikit-Learn.",
      "objectives": [
        "Conhecer as diferentes áreas de Machine Learning e suas aplicações práticas",
        "Aprender a fazer Machine Learning Supervisionado usando a linguagem Python e a biblioteca Scikit-Learn",
        "Criar os seus próprios algoritmos de Machine Learning para treinar seu computador a fazer previsões e classificações",
        "Conhecer modelos estatísticos e aprender como eles podem ser usados para fazer algoritmos de Machine Learning"
      ],
      "course_content": {
        "Introdução": [
          "Seja Bem Vindo(a) ao Curso de Machine Learning",
          "Introdução - O que é Machine Learning?",
          "Preparação do Ambiente de Trabalho"
        ],
        "Iris Dataset (Previsão Categórica)": [
          "Importação do Iris Dataset",
          "Aplicação do Modelo KNN",
          "Avaliação da Performance do Modelo",
          "Exercício: Análise de Performance e Seleção do Valor de K",
          "Resolução do Exercício: Análise de Performance e Seleção do Valor de K",
          "O Modelo de Regressão Logística",
          "Aplicação da Regressão Logística no Iris Dataset"
        ],
        "Retorno sobre Publicidade (Previsão Quantitativa)": [
          "Importação do Advertising Dataset",
          "O modelo de Regressão Linear",
          "Aplicação do Modelo de Regressão Linear (Parte 1)",
          "Aplicação do Modelo de Regressão Linear (Parte 2)",
          "Avaliação da Performance do Modelo de Regressão Linear",
          "Exercício: Seleção das Variáveis",
          "Resolução do Exercício: Seleção das Variáveis (Parte 1)",
          "Resolução do Exercício: Seleção das Variáveis (Parte 2)"
        ],
        "Reconhecimento de Imagens com o Digits Dataset": [
          "Importação do Digits Dataset",
          "O Algoritmo SVM: Support Vector Machine",
          "Aplicação do SVM (Parte 1)",
          "Aplicação do SVM (Parte 2)",
          "Leitura e Reconhecimento da Imagem de um Dígito",
          "Leitura e Reconhecimento da Imagem de um Dígito (Parte 2)"
        ],
        "Conteúdo EXTRA - Python Básico": [
          "Instalação do Python",
          "Conhecendo o Python Shell",
          "Variáveis",
          "Tipos de Dados (Números)",
          "Tipos de Dados (Strings)",
          "Exercício (Números)",
          "Tipos de Dados (Listas e Tuplas)",
          "Exercício (Listas e Tuplas)",
          "Tipos de Dados (Dicionários)",
          "Exercício (Dicionários)",
          "Condicionais (Parte 1)",
          "Condicionais (Parte 2)",
          "Exercício (Condicionais)"
        ]
      },
      "requirements": [
        "É desejável que o aluno tenha conhecimentos básicos da linguagem Python"
      ],
      "description": "Machine Learning é uma da áreas da Inteligência Artificial e se baseia no uso de modelos estatísticos para treinar computadores a fazer previsões e reconhecer padrões. Esta tecnologia é usada pelas maiores empresas do mundo nas mais diversas áreas, como na Saúde (Diagnóstico de pacientes), Finanças (Detecção de fraudes), E-Commerce (Sistemas de recomendações), Transportes (Previsão de demanda), Serviços inteligentes governamentais e muito mais.\nNeste curso você vai aprender desde o zero como fazer Machine Learning Supervisionado usando Python e a biblioteca Scikit-Learn. Serão ensinados 4 modelos estatísticos (Regressão Linear, Regressão Logística, KNN e SVM) aplicados a exemplos reais de Machine Learning. Aplicaremos estes modelos em diferentes conjuntos de dados e faremos uma comparação da performance de cada um deles para entender qual é o modelo mais adequada para cada situação.\nNeste curso você vai adquirir não apenas o conhecimento prático dos algoritmos de Machine Learning em Python, mas também vai entender como os modelos estatísticos funcionam para treinar o computador a fazer previsões e classificações.\nQue ensinar o seu computador a tomar decisões? Então inscreva-se agora no curso de Machine Learning em Python.",
      "target_audience": [
        "Alunos que queiram aprender a aplicar modelos de Machine Learning na prática usando a linguagem Python",
        "Pessoas que queiram iniciar sua carreira em uma das áreas de inteligência artificial",
        "Pessoas que queiram aprender tecnologias inovadores que têm enorme demanda no mercado"
      ]
    },
    {
      "title": "Understanding Data Structures using C#",
      "url": "https://www.udemy.com/course/understanding-data-structures-using-c/",
      "bio": "Learn Data structure and algorithms using C#",
      "objectives": [],
      "course_content": {
        "Data Structures in C#": [
          "Introduction",
          "Data Structures in C# - Introduction to Sequential Access Collections (Theory)",
          "Creating Custom Collection using ArrayList",
          "Exploring Generic Functions",
          "Exploring Generic Classes",
          "Jagged Arrays"
        ],
        "Sorting": [
          "Bubble Sort",
          "Selection Sort",
          "Shell Sort",
          "Merge Sort",
          "Quick Sort"
        ],
        "Search": [
          "Sequential Search",
          "Binary Search",
          "Recursive Binary Search"
        ],
        "Stack, Queues, Hashtables, Dictionary,Linkedlist and Binary Tree": [
          "Stacks",
          "Queues",
          "Dictionary",
          "Hashtables",
          "Linked List",
          "Binary Tree",
          "Binary Tree - II",
          "Set"
        ],
        "Conclusion": [
          "Conclusion"
        ]
      },
      "requirements": [
        "Basic C# Knowledge"
      ],
      "description": "Learn Data structure and algorithms using C#\nIn this course, we will be diving deep into the nitty-gritty details of Data Structures and Algorithms using C#\nWe will be covering these with examples which will help us in understanding it better.\n1: Data Structures in C#\n2: Sorting\n3: Search\n4: Stack, Queues, Hashtables, Dictionary, LinkedList, and Binary Tree\n\n\nSo what are you waiting for, enroll in this free course today and start learning something new.",
      "target_audience": [
        "Computer Science Students",
        "Web Developers",
        "Aspiring Web Developers"
      ]
    },
    {
      "title": "Machine Learning e Data Science com Weka e Java - Completo",
      "url": "https://www.udemy.com/course/machine-learning-com-weka-e-java/",
      "bio": "Aprenda as técnicas que o mundo real exige e torne-se um profissional competitivo na área de Inteligência Artificial!",
      "objectives": [
        "Tenha uma base teórica sólida sobre os principais algoritmos de Machine Learning",
        "Aprenda sobre as principais funcionalidades do Weka",
        "Aprenda na teoria e na prática sobre os algoritmos de Machine Learning para classificação, regressão, regras de associação e agrupamento",
        "Entenda como funcionam as técnicas para redução de dimensionalidade PCA, KernelPCA e LDA",
        "Aprenda a avaliar os algoritmos de Machine Learning usando estatística não paramétrica",
        "Veja como encontrar padrões escondidos em dados utilizando técnicas de associação e agrupamento"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Machine learning",
          "Por que aprender machine learning?",
          "Terminologia",
          "Métodos preditivos",
          "Métodos descritivos",
          "Tipos de aprendizagem de máquina",
          "Classificação",
          "Referências complementares",
          "Terminologia básica"
        ],
        "----- Parte 1 - Classificação -----": [
          "Introdução a Parte 1 - Classificação"
        ],
        "Extração de características de imagens": [
          "Extração de características I",
          "Extração de características II",
          "Extração de características III",
          "Reconhecimento dos personagens",
          "Seleção de características dos personagens",
          "Atualização: instalação do Java",
          "Download das ferramentas",
          "Entendendo a extração das cores",
          "ATUALIZAÇÃO no projeto dos personagens!",
          "Instalação do projeto dos personagens",
          "ATUALIZAÇÃO na instalação do projeto dos personagens!",
          "Código fonte do extrator de características I",
          "Código fonte do extrator de características II",
          "Código fonte do extrator de características III",
          "Arquivo ARFF dos personagens",
          "Carregando a imagem",
          "Extração das características da imagem selecionada",
          "Testando a extração das características",
          "Base de dados para análise",
          "Referências complementares"
        ],
        "Introdução ao Weka": [
          "Introdução ao módulo",
          "Instalação do Weka",
          "Introdução ao Weka",
          "Entendendo os valores da janela inicial do Weka",
          "Arquivos ARFF",
          "Referências complementares"
        ],
        "Aprendizagem bayesiana": [
          "Introdução ao módulo",
          "Naive bayes - introdução",
          "Naive bayes - aprendizagem",
          "Naive bayes - classificação",
          "Naive bayes - correção laplaciana",
          "Naive bayes - mais conceitos",
          "Naive bayes no weka",
          "Carregando o ARFF dos personagens no Java",
          "Classificando os personagens com o naive bayes",
          "Referências complementares",
          "Teoria Naïve Bayes"
        ],
        "Aprendizagem por árvores de decisão": [
          "Introdução ao módulo",
          "Árvores de decisão - introdução",
          "Árvores de decisão - aprendizagem I",
          "Árvores de decisão - aprendizagem II",
          "Árvores de decisão - mais conceitos",
          "Árvores de decisão no Weka",
          "Poda em árvores de decisão",
          "Classificando os personagens com o J48",
          "Random forest (floresta randômica)",
          "Random forest no Weka",
          "Referências complementares",
          "Teoria árvores de decisão"
        ],
        "Aprendizagem por regras": [
          "Introdução ao módulo",
          "Indução de regras - introdução",
          "Algoritmo ZeroR",
          "Indução de regras - algoritmo OneR I",
          "Indução de regras - algoritmo OneR II",
          "Indução de regras - algoritmo PRISM",
          "Regras no Weka",
          "Classificando os personagens com regras",
          "Referências complementares",
          "Teoria aprendizagem por regras"
        ],
        "Aprendizagem baseada em instâncias": [
          "Introdução ao módulo",
          "kNN - introdução",
          "kNN - cálculo da distância",
          "kNN - classificação",
          "kNN - classificação dos personagens",
          "kNN - normalização e padronização",
          "Aprendizagem baseada em instâncias no Weka",
          "kNN - normalização e padronização no Weka",
          "Classificando os personagens com o IBk",
          "Referências complementares",
          "Teoria aprendizagem baseada em instâncias"
        ],
        "Regressão logística": [
          "Introdução ao módulo",
          "Regressão logística - introdução",
          "Regressão logística - aprendizagem",
          "Regressão logística - classificação",
          "Regressão logística no Weka",
          "Referências complementares",
          "Teoria regressão logística"
        ],
        "Máquinas de vetores de suporte (SVM)": [
          "Introdução ao módulo",
          "SVM - introdução",
          "SVM - aprendizagem",
          "SVM - linear x não linear",
          "Instalação da LibSVM",
          "SVM no Weka",
          "Classificando os personagens com a LibSVM",
          "Referências complementares",
          "Teoria SVM"
        ]
      },
      "requirements": [
        "Conhecimento sobre lógica de programação são desejáveis, embora seja possível acompanhar o curso sem esse conhecimento",
        "Conhecimentos básicos em Java são desejáveis, embora seja possível acompanhar o curso sem saber essa linguagem com profundidade",
        "Conhecimentos sobre instalação de softwares básicos"
      ],
      "description": "A área de Machine Learning (Aprendizagem de Máquina) é atualmente um dos campos de trabalho mais relevantes da Inteligência Artificial, sendo responsável pela utilização de algoritmos inteligentes que tem a função de fazer com que os computadores aprendam por meio de bases de dados. O mercado de trabalho de Machine Learning nos Estados Unidos e em vários países da Europa está em grande ascensão; e a previsão é que no Brasil cada vez mais esse tipo de profissional seja requisitado! Inclusive alguns estudos apontam que o conhecimento dessa área será em breve um pré-requisito para os profissionais de Tecnologia da Informação! E dentro deste contexto está o cientista de dados, que já foi classificado como o trabalho \"número 1\" por vários veículos da mídia internacional.\nE para levar você até essa área, neste curso completo você terá uma visão teórica e prática sobre os principais algoritmos de machine learning utilizando a ferramenta Weka, que é uma das ferramentas mais utilizadas para machine learning e mineração de dados. Além disso, também utilizaremos a linguagem de programação Java para fazer a integração com o Weka! Este curso apresenta  desde os conceitos mais básicos até técnicas mais avançadas, de modo que ao final você terá todas as ferramentas necessárias para construir soluções complexas e que podem ser aplicadas em problemas do dia-a-dia das empresas! Você aprenderá tudo passo a passo, ou seja, tanto a teoria quanto a prática de cada algoritmos! O curso é dividido em cinco partes:\nClassificação - extração de características de imagens, naive bayes, árvores de decisão, random forest, regras, regressão logística, máquinas de vetores de suporte (SVM), redes neurais artificiais, avaliação de algoritmos e combinação e rejeição de classificadores\nRegressão - regressão linear simples e múltipla, polinomial, árvores de decisão, random forest, vetores de suporte e redes neurais artificiais\nRegras de associação - algoritmo apriori\nAgrupamento - k-means e agrupamento hierárquico\nRedução de dimensionalidade com PCA e LDA\nDurante o curso desenvolveremos um projeto prático de reconhecimento automático de personagens dos desenhos animados. Nosso objetivo principal será construir passo a passo um sistema inteligente para reconhecer automaticamente as imagens do Homer e do Bart dos Simpsons! O sistema aprenderá com as imagens e depois nós forneceremos uma nova imagem como entrada e o software conseguirá identificar automaticamente de quem é a imagem! É um projeto muito interessante que você conseguirá compreender todos os conceitos que envolvem a área de aprendizagem de máquina.\nEste curso tem o objetivo de servir como um referencial de consulta sobre as técnicas abordadas, por isso ele procura cobrir a maior parte dos assuntos que envolvem machine learning. Este curso pode ser categorizado para todos os níveis, pois pode servir de base para consulta para alunos mais experientes no assunto e também um ótimo guia para quem está iniciando na área!\nPreparado(a) para dar um importante passo na sua carreira? Aguardo você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em iniciar seus estudos em aprendizagem de máquina e ciência de dados",
        "Pessoas que queiram iniciar carreira na área de Data Science ou Machine Learning",
        "Empreendedores que queiram aplicar aprendizagem de máquina em projetos comerciais",
        "Analistas de dados que queiram aumentar seu conhecimento na área de aprendizagem de máquina",
        "Empresários que desejam criar soluções eficientes para problemas reais em suas empresas",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial"
      ]
    },
    {
      "title": "Estatística Descritiva com Python",
      "url": "https://www.udemy.com/course/estatistica-descritiva-com-python/",
      "bio": "Teorias e práticas direcionadas a análise e ciência dos dados (Data Science).",
      "objectives": [
        "Importância da estatística para Data Science",
        "Como utilizar o Python na Nuvem de maneira gratuita",
        "Visão geral da programação com a linguagem Python",
        "A importância da aleatoriedade",
        "Diferenciar dados populacionais de dados amostrais",
        "Como obter amostras com Python",
        "Como representar com Python gráficos de barras, histogramas, linhas, setores etc.",
        "O que é uma MÉDIA- conceito teórico e práticas com Python",
        "O que é uma MEDIANA - conceito teórico e práticas com Python",
        "O que é uma MODA- conceito teórico e práticas com Python",
        "O que são medidas SEPARATRIZES - teoria e prática com Python",
        "O que é a VARIÂNCIA - conceito teórico e práticas com Python",
        "O que é DESVIO PADRÃO - conceito teórico e práticas com Python",
        "O que é COEFICIENTE DE VARIAÇÃO - conceito teórico e práticas com Python",
        "O que é uma CURTOSE - conceito teórico e práticas com Python",
        "O que é um BOXPLOT - conceito teórico e práticas com Python",
        "Fundamentos por trás do Método de Monte Carlo - MMC",
        "Como fazer análise descritiva detalhada de dados",
        "E muito mais..."
      ],
      "course_content": {
        "Introdução": [
          "Apresentação do curso",
          "Importância da estatística para Data Science",
          "Introdução a estatística - História",
          "Python e seus projetos",
          "Ambiente para as aplicações",
          "Bibliotecas Python para análises estatísticas"
        ],
        "Python - Visão geral": [
          "Import de bibliotecas",
          "Tipos de variáveis",
          "Operações matemáticas Python",
          "Comparações e operações booleanas",
          "Condicionais em Python",
          "Listas no Python",
          "Tuplas no Python",
          "Strings no Python",
          "Dicionários no Python",
          "Conjuntos em Python",
          "Funções no Python",
          "Loops com Python"
        ],
        "Fundamentos da Estatística": [
          "A ciência estatística",
          "Aleatoriedade",
          "População e Amostra",
          "Medidas observadas e variáveis",
          "Obtendo amostras com Python",
          "1- Teste de conhecimentos"
        ],
        "Representações Gráficas": [
          "Por que utilizar gráficos?",
          "Gráficos de barras",
          "Gráficos de barras com Python",
          "Gráficos de setores",
          "Gráficos de setores com Python",
          "Gráficos de linhas",
          "Gráficos de linhas com Python",
          "Histogramas",
          "Histogramas com Python"
        ],
        "Medidas de Tendência Central (MTC)": [
          "Introdução - MTC",
          "Média aritmética",
          "Moda",
          "Mediana",
          "Média, Moda e Mediana",
          "Medidas separatrizes",
          "Instalação da bib Bokeh",
          "Cálculo da Média - Python",
          "Atualização da função np.mean()",
          "Cálculo da Mediana - Python",
          "Cálculo da Moda - Python",
          "Cálculo de Separatrizes - Python",
          "Função Describe() - Python",
          "Plotar Média, Mediana e Moda - Python",
          "Exercício sobre Médias"
        ],
        "Medidas de Dispersão (MD)": [
          "Introdução a medidas de dispersão",
          "Amplitude Total",
          "Amplitude interquartílica",
          "Desvio médio",
          "Variância e desvio padrão",
          "Coeficiente de variação",
          "Amplitude Total - Python",
          "Amplitude Interquartílica - Python",
          "Desvio médio - Python",
          "Variância e desvio padrão - Python",
          "Coeficiente de Variação - Python"
        ],
        "Medidas de Assimetria (MA)": [
          "O que são medidas de assimetria?",
          "Medidas de curtose",
          "O que é um Boxplot?",
          "Boxplot com Python",
          "Boxplot com Matplotlib"
        ],
        "Aplicações em Data Science": [
          "Método de Monte Carlo - MMC Parte 1",
          "Método de Monte Carlo - MMC Parte 2",
          "Estatística Descritivas dos dados do Titanic",
          "Estatística Descritivas para Preços de Ativos Financeiros",
          "Vídeos complementares"
        ],
        "Conteúdo EXTRA": [
          "Aula Bônus"
        ]
      },
      "requirements": [
        "Conhecimentos básicos a respeito de lógica de programação são bem-vindos"
      ],
      "description": "As áreas de maior crescimento e demanda por profissionais qualificados sem sombra de dúvidas estão ligadas as ciências e tecnologias voltadas para os campos da matemática, estatística e computação científica (Machine Learning, Deep Learning).\nAs áreas de Data Science e Inteligência Artificial nunca apresentaram tanto destaque e importância como nos dias atuais. E a ciência mãe por trás de tudo isso é a ESTATÍSTICA.\nEste curso tem o objetivo de apresentar um dos assuntos mais importantes para todo e qualquer analista e cientista de dados que é a Estatística Descritiva. Como ferramenta de aplicações e testes dos estudos estatísticos iremos utilizar a linguagem de programação Python.\nNeste curso você irá aprender curiosidades a respeito da estatística e muito conteúdo técnico e aplicado. O curso apresenta deduções de fórmulas importantes conduzidas com uma linguagem simples e informal.\n\n\nResponda as perguntas abaixo e veja se este curso é para você:\n\n\nVocê sabe diferenciar os principais ramos de estudos da estatística?\nComo a estatística descritiva pode ajudar na análise e interpretação inicial dos dados?\nQual é a diferença entre: dados, informações, conhecimentos e sabedoria?\nVocê saberia distinguir uma medida de dispersão de uma medida de assimetria?\nO que é uma medida de tendência central nos nossos dados?\nComo a magia dos números aleatórios podem nos ajudar a solucionar problemas do mundo real?\nPor que os gráficos da estatística descritiva são tão importantes?\nPor que precisamos compreender a diferença entre dados amostrais e dados populacionais?\nVocê sabe o que é um boxplot e por que ele é tão importante para a análise descritiva dos dados?\nVocê sabia que é possível utilizar o Python de maneira gratuita completamente na nuvem?\n\n\nSe você possui alguma curiosidade com relação as respostas das perguntas acima este curso é realmente para você!\nVenha comigo desbravar esse tão importante, interessante e instigante ramo da estatística que é a Estatística Descritiva.\nFaça agora mesmo sua inscrição!\n\n\nBons estudos!!",
      "target_audience": [
        "Analistas e Cientistas de dados",
        "Pesquisadores",
        "Engenheiros, matemáticos e estatísticos",
        "Profissionais das áreas de finanças e ciências econômicas",
        "Todos aqueles autodidatas interessados em aprender fundamentos das áreas de Machine Learning, Deep Learning e Data Science"
      ]
    },
    {
      "title": "【しっかり原理を理解したい方向け】東大理系女子と学ぶはじめての統計学",
      "url": "https://www.udemy.com/course/intro-to-stat/",
      "bio": "統計学を学んだことのない方向けの入門コースです。原理をきちんと説明しますので、これからステップアップしたい方に最適です。",
      "objectives": [
        "統計検定３級程度の統計学の知識",
        "確率変数と確率分布の概念（二項分布、正規分布、二項分布の正規近似）",
        "記述統計学の知識（ヒストグラム、代表値、散布図、分割表、相関係数、回帰分析）",
        "推測統計学の基礎（標本平均・比率の標本分布、母平均・母比率の区間推定、母平均・母比率の仮説検定）",
        "確率の基礎（事象の独立性と試行の独立性、条件付き確率、ベイズの定理）"
      ],
      "course_content": {
        "このコースについて": [
          "概要",
          "このコースの対象者",
          "コースの構成",
          "自己紹介"
        ],
        "統計学とは": [
          "このセクションで学ぶこと",
          "統計学とは",
          "データの種類"
        ],
        "１次元のデータ": [
          "このセクションで学ぶこと",
          "度数分布とヒストグラム",
          "代表値",
          "散らばりの尺度"
        ],
        "２次元のデータ": [
          "このセクションで学ぶこと",
          "２次元データの分析",
          "散布図と分割表",
          "相関係数",
          "回帰分析"
        ],
        "確率": [
          "このセクションで学ぶこと",
          "記述統計学と推測統計学",
          "母集団と標本",
          "事象と確率",
          "事象の独立性と試行の独立性",
          "条件付き確率",
          "ベイズの定理"
        ],
        "確率変数と確率分布": [
          "このセクションで学ぶこと",
          "確率変数と確率分布の考え方",
          "平均, 分散, 標準偏差",
          "二項分布と正規分布",
          "正規分布と確率の計算"
        ],
        "統計的な推測": [
          "このセクションで学ぶこと",
          "推定とは",
          "区間推定",
          "仮説検定"
        ]
      },
      "requirements": [
        "四則演算やルートの計算など、中学校で習う数学の知識を前提とします",
        "統計学の予備知識は不要です"
      ],
      "description": "この度は本コースに興味を持ってくださり、誠にありがとうございます。\n本コースは、統計学を学んだことのない方が、統計検定３級程度の統計学の知識を身につけることを主眼としたコースです。\n本コースの一番の特徴は、「分かりにくいことを説明することを恐れない」です。厳密な議論は避けて、感覚的な説明で「分かりやすい」講義を作ることもできるかもしれません。しかしながら、そのような「分かりやすい」コースは、理解できたという満足感は与えても一生役立つ知識は与えないのではないかと思います。\n本コースは、統計検定３級の範囲を数式を使って誤魔化さずに説明します。もちろん、なぜこのような数式が登場するのか？といった考え方の部分から紹介しますので、計算だけしていて何が起こっているか分からない、といったことはございません。また、３級の出題範囲では微分積分などの比較的高度な数学の知識は必要とならないため、四則演算やルートの計算、不等式の変形など、中学校で習う数学の知識さえあれば受講することができます。\n「数式は見るだけでダメ」という方には向かないかもしれませんが、やる気のある方は、私がコース修了まで最大限お手伝いいたします（「Q&A」機能を活用してください）。高校以降の数学は講義内で適宜補足説明もいたします。\n原理からしっかり理解するのは、骨が折れますがステップアップのための確実な力になります。ぜひこの機会に統計学のエッセンスを学んでみませんか。\n\n\n注意事項\n本コースの修了は、統計検定３級の合格を保証するものではありません\n本コースでは、RやPythonなどによるデータ分析の演習は行いません",
      "target_audience": [
        "統計学を初めて学ぶ方",
        "統計検定３級の合格を目指す方",
        "データサイエンティストになりたい方"
      ]
    },
    {
      "title": "BERTによる自然言語処理を学ぼう！ -Attention、TransformerからBERTへとつながるNLP技術-",
      "url": "https://www.udemy.com/course/nlp-bert/",
      "bio": "ディープラーニング（深層学習）を使う自然言語処理技術の中でも、特に注目を集めているBERTを解説するコースです。Google Colaboratory環境でPyTorchを使用し、コードを動かしながらBERTの原理、実装を学びます。",
      "objectives": [
        "BERT、Transformer、Attentionの仕組み。",
        "PyTorch、ライブラリTransformersを使用したBERTの実装。",
        "学習済みモデルのファインチューニングによる調整。",
        "日本語の文章、および英文のBERTによる分類。",
        "自然言語処理技術の概要。"
      ],
      "course_content": {
        "講座とBERTの概要": [
          "教材の使用方法",
          "イントロダクション",
          "コースの概要",
          "自然言語処理の概要",
          "Transformerの概要",
          "BERTの概要",
          "Google Colaboratoryの使い方"
        ],
        "シンプルなBERTの実装": [
          "セクション2の教材",
          "Section2の概要",
          "PyTorchの基礎",
          "PyTorch-Transformers",
          "シンプルなBERTの実装"
        ],
        "BERTの仕組み": [
          "セクション3の教材",
          "Section3の概要",
          "BERTの全体像",
          "Transformerのモデル",
          "BERTの実装"
        ],
        "ファインチューニングの活用": [
          "セクション4の教材",
          "Section4の概要",
          "転移学習とファインチューニング",
          "シンプルなファインチューニング",
          "ファインチューニングによる感情分析"
        ],
        "BERTの応用": [
          "セクション5の教材",
          "Section5の概要",
          "BERTの活用例",
          "BERTによる日本語ニュースの分類 Part1",
          "BERTによる日本語ニュースの分類 Part2",
          "BERTSUMの紹介",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "何らかのプログラミング経験があった方が望ましいです。",
        "Google Colaboratoryを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratory、およびGoogle Driveを使用するためにGoogleアカウントが必要になります。",
        "海外のライブラリや文献を紹介するので、英語に抵抗感が小さい方が望ましいです。",
        "ディープラーニングに関する基礎的な知識が必要になります。"
      ],
      "description": "自然言語処理の様々なタスクで高い性能を発揮する、「BERT」を学ぶコースです。\nBERT（Bidirectional Encoder Representations from Transformers ）は2018年10月にGoogleが公開して以来、世界中のAI関係者の注目を集めています。\nBERTは「Transformer」と呼ばれるモデルを利用することで、離れた単語間の関係、すなわち「文脈」を考慮した自然言語処理を実現します。\nタスクによっては人間並みの精度を発揮する可能性もあり、「応答文の生成」や「文書の要約」といった様々なタスクでの活用が期待されています。\n本コースで学ぶことにより、BERTの仕組み、実装方法を理解し、BERTによる日本語文章の処理ができるようになります。\n新しい時代の、有用な自然言語処理技術を身に付けましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\nコースの内容は以下の通りです。\nSection1. 講座とBERTの概要\n→ 自然言語処理、Transformer、BERTについて概要を学びます。\nSection2. シンプルなBERTの実装\n→ 最小限のPythonのコードでBERTを実装します。\nSection3. BERTの仕組み\n→ Transformer、BERTなどについて仕組みを詳しく学びます。\nSection4. ファインチューニングの活用\n→ ファインチューニングの概要、そしてBERTにおける活用について解説します。\nSection5. BERTの応用\n→ BERTを使って、自然言語処理のタスクに取り組みます。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックがダウンロード可能です。\n本コースはディープラーニング用フレームワークとしてPyTorchを使用します。\nPyTorchはオープンソースの機械学習ライブラリで、簡潔さ、柔軟性、速度のバランスに優れているため人気が急上昇中です。\nまた、簡潔な記述が可能なため、最新の研究成果の実装によく使われています。\n開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "分かりやすい解説でBERT、Transformer、Attentionについて学びたい方。",
        "一歩進んだ自然言語処理技術を身に付けたい方。",
        "PyTorchによる自然言語処理の実装を学びたい方。",
        "自然言語処理を活用し、文章の分類などを行いたい方。"
      ]
    },
    {
      "title": "Practical Machine Learning for Data Scientists",
      "url": "https://www.udemy.com/course/practical-machine-learning-for-data-scientists/",
      "bio": "Practical AI and ML",
      "objectives": [
        "Build solid knowledge necessary for data scientists about AI, Machine Learning and Deep Learning",
        "Understand the basics and underlying dynamics of supervised learining models: LinearRegression, LogisiticRegression, SVM, DNN, DecisionTrees and RandomForests.",
        "Get introduced to unsupervised learning approaches for dimensionality reduction and clustering.",
        "Build practical Machine Learning models and pipelines using python, scikit-learn, pandas, keras and tensorflow",
        "Solve practical problems like image classification, text classification, price prediction."
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Module 1: Introduction to AI": [
          "What is AI",
          "Working in an AI team",
          "AI and Society",
          "How AI works"
        ],
        "Module 2: Supervised Learning": [
          "Module roadmap",
          "AI models anatomy",
          "Supervised Learning ingredients",
          "Example Keras program",
          "Learning problems types and design patterns",
          "Losses and output layers types",
          "Scikit-learn library overview (Optional)",
          "Introduction to Optimizers",
          "Linear Regression and Normal equation",
          "Issues with Normal equation and closed form solution",
          "Iterative solution and Gradient based optimization",
          "Gradient Descent hyperparameters",
          "Batch size hyperparameter",
          "Logistic Regression",
          "Support Vector Machines (SVM)",
          "Non-linear models",
          "Deep Neural Networks (DNN)",
          "Overfitting and underfitting",
          "Regularization",
          "Summary"
        ],
        "Module 3: Universal Supervised Machine Learning Process": [
          "Module roadmap",
          "Terminologies and ML process overview",
          "Defining the problem and data assembly",
          "Losses and Metrics",
          "Decision boundaries and thresholds",
          "Precision, Recall and F1",
          "Imbalanced data problem",
          "Imbalanced data solutions",
          "Model selection process",
          "Model selection techniques",
          "Resampling methods",
          "Data preparation",
          "Exploratory Data Analysis (EDA)",
          "Data preprocessing",
          "Baseline model",
          "Scaling up",
          "Regularization"
        ],
        "Module 4: Machine Learning Meta Algorithms": [
          "Module roadmap",
          "Model selection revisited and bootstrapped resampling",
          "Model Ensembles types and Voting method",
          "BAGGing",
          "Decision Trees",
          "Random Forests",
          "Boosting",
          "End-to-end HousePrices prediction - EDA",
          "End-to-end HousePrices prediction - Data preparation",
          "End-to-end HousePrices prediction - Model selection and tuning",
          "Summary"
        ],
        "Module 5: Unsupervised Learning": [
          "Module roadmap",
          "Unsupervised Learning overview",
          "Curse of dimensionality and Dimensionality reduction",
          "Types of dimensionality reduction - Manifold Learning vs. Projection methods",
          "Principal Component Analysis (PCA)",
          "Clustering algorithms",
          "K-means clustering algorithm",
          "Semi-supervised Learning"
        ],
        "Material": [
          "Slides"
        ]
      },
      "requirements": [
        "Python",
        "Linear Algebra",
        "Probability and Statistics"
      ],
      "description": "This course is a comprehensive introduction to AI and Machine Learning, targeting Data Scientists and Machine Learning engineers. It starts with setting the boundaries of Artificial Intelligence, Machine Learning, Deep Learning, and their relation to Data Science. What is expected as a member an AI team, and how to speak the same language. What is possible and what is not, and what defines a good AI project. The basics of supervised learning are covered, including the main ingredients of the Machine Learning problem, and the different solution setups. We cover both Linear models (Linear Regression, Logistic Regression, Support Vector Machines (SVM)) and Non-linear models (Polynomial Regression, Kernel SVM, Deep Neural Networks (DNN)). A universal approach is given to tackle any ML problem in a systematic way, covering data preparation, Exploratory Data Analysis (EDA), Model selection, Model evaluation, Model design, Fine tuning and Regularization. An end-to-end is given to illustrate this process with code in Google Colab Notebooks. We also cover the Machine Learning Meta algorithms and Ensemble methods: Voting, BAGGing, Boosting Decision Trees and Random Forests. Finally, we introduce unsupervised learning, covering dimensionality reduction algorithms, like Manifold Learning like Locally Linear Embedding (LLE) and Projection methods like Principal Component Analysis (PCA) and Clustering, like K-Means. Throughout the course, Python language is used. Popular Machine Learning libraries are used, like scikit-learn, in addition to pandas and keras.",
      "target_audience": [
        "Beginner level data scientists"
      ]
    },
    {
      "title": "Python for Data Science and Machine Learning",
      "url": "https://www.udemy.com/course/python-science/",
      "bio": "Learn how to use NumPy, Pandas, Seaborn , Matplotlib , Scikit-Learn , Machine Learning, Tensorflow , and more!",
      "objectives": [
        "Use Python for Data Science and Machine Learning",
        "Learn to use Pandas for Data Analysis",
        "Learn to use Seaborn for statistical plots",
        "Use SciKit-Learn for Machine Learning Tasks"
      ],
      "course_content": {
        "Introduction": [
          "Setup the Environment",
          "Print, comments",
          "Variables",
          "Strings",
          "Arithmetic",
          "Boolean Operations",
          "Boolean part 2",
          "Datatype Conversion",
          "Lists",
          "Tuples",
          "Dictionaries",
          "Data Type Conversion",
          "Functions",
          "Functions 2",
          "Lambda",
          "Math Library",
          "OS Library",
          "If Statements",
          "While loop",
          "For Loop",
          "Object Oriented Programming (OOP)",
          "Constructor",
          "Example"
        ],
        "Data Science Libraries": [
          "Numpy",
          "Array Operation",
          "Pickle",
          "Pandas",
          "DataFrame",
          "DataFrame 2",
          "plot DataFrame",
          "Data Processing",
          "matplotlib",
          "multi plot",
          "Bar Chart",
          "Example"
        ],
        "Machine Learning": [
          "Scikit Learn",
          "Linear Regression",
          "Logistic Regression",
          "KNN",
          "Decision Tree",
          "Random Forest",
          "Support Vector Machine",
          "Evaluation Metrics"
        ],
        "Deep Neural Network (DNN)": [
          "Tensor Flow",
          "Simple Model",
          "Sequencial Model",
          "Factional API",
          "Factional API 2",
          "Subclassing API"
        ],
        "Convolutional Neural Network (CNN)": [
          "Introdction",
          "Labeling",
          "Augmentation",
          "plot images",
          "Build the Model",
          "Transfer Learning"
        ],
        "Computer Vision Application": [
          "Applications",
          "Face Recognition #1",
          "Face Recognition #2",
          "Face Recognition #3"
        ],
        "Natural Language Processing": [
          "Sequence Modeling",
          "Machine Translation #1",
          "Machine Translation #2",
          "Machine Translation #3",
          "Machine Translation #4",
          "Chatbot",
          "Text Similarity #1",
          "Text Similarity #2"
        ],
        "Model Deployment": [
          "TFLite",
          "TFX Model Serving"
        ]
      },
      "requirements": [
        "No Programming Experience needed. You will learn everything you need to know"
      ],
      "description": "Are you ready to start your path to becoming a Data Scientist!\nThis course will be your guide to learning how to use the power of Python to analyze data, create beautiful visualizations, and use powerful machine learning algorithms!\nData Scientist has been ranked the number one job on Glassdoor and the average salary of a data scientist is over $120,000 in the United States according to Indeed! Data Science is a rewarding career that allows you to solve some of the world's most interesting problems!\nThis comprehensive course is comparable to other Data Science bootcamps that usually cost thousands of dollars, but now you can learn all that information at a fraction of the cost!\nWe'll teach you how to program with Python, how to create amazing data visualizations, and how to use Machine Learning with Python! Here a just a few of the topics we will be learning:\nProgramming with Python\nNumPy with Python\nUsing pandas Data Frames to solve complex tasks\nUse pandas to handle Excel Files\nWeb scraping with python\nConnect Python to SQL\nUse matplotlib and seaborn for data visualizations\nMachine Learning with SciKit Learn, including:\nLinear Regression\nK Nearest Neighbors\nDecision Trees\nRandom Forests\nNatural Language Processing\nSupport Vector Machines\nand much, much more!\nEnroll in the course and become a data scientist today!",
      "target_audience": [
        "Beginner Python developers curious about data science"
      ]
    },
    {
      "title": "Curso PowerBI - Formação Analista de BI - 28 horas",
      "url": "https://www.udemy.com/course/curso-powerbi-completo/",
      "bio": "PowerBI, Linguagem SQL e Modelagem de Dados, do básico ao avançado. Se torne um Analista de BI - Business Intelligence",
      "objectives": [
        "A utilizar a principal ferramenta de Business Intelligence (BI)",
        "A se tornar um analista de dados",
        "A instalar e configurar do Power BI",
        "A importar e transformar dados de fontes de dados diversas como Excel e SQL SERVER",
        "A criar incríveis relatórios e dashBoards, utilizando funções DAX",
        "A trabalhar com relacionamento entre tabelas dentro do Power BI",
        "A publicar seus dashboards na Internet para seus clientes e usuários de forma pública ou de forma segura",
        "A instalar gateways e atualizar seus dados de forma automática",
        "A criar Aplicativos no Power BI para distribuição dentro da Plataforma",
        "Ira receber certificado de participação no curso com carga horária para comprovar sua participação."
      ],
      "course_content": {},
      "requirements": [
        "Vontade de se tornar um analista de dados e engenheiro de BI",
        "Conhecimento de Windows"
      ],
      "description": "Olá Analista de BI\n\nPreparei este curso com muito carinho, com o objetivo de demonstrar as principais funcionalidades existentes no Power BI.\n\nMeu objetivo foi criar um curso de baixíssimo custo frente a quantidade de horas do mesmo, para que tenhas condições de se tornar um Analista de Dados operando a Ferramenta mais utilizada atualmente com quem trabalha com Projetos de Business Intelligence (BI), em um curto espaço de tempo ou melhorar suas habilidades.\n\nNeste curso irá aprender, desde a instalação e configuração do Power BI, passando pela importação e transformação de dados oriundos de diversas fontes de dados, como planilhas Excel e tabelas do SQL Server.\nIrá aprender a criar incríveis reports e dashboards, a utilizar fórmulas, funções DAX, relacionamento entre tabelas e como publicar seus relatórios na Internet, disponibilizando - os de forma segura.\nIrá aprender ainda como poderá criar aplicativos para disponibilizar para seus clientes e usuários e a configurar Gateways para realizar atualizações automáticas no site do Microsoft Power BI\nTodas as aulas são disponibilizadas através de vídeos, onde demonstro na tela do meu computador, passo a passo, como poderá realizar todas as principais atividades dos analistas de dados no Power BI. A metodologia de ensino será baseada na apresentação de 3 projetos, onde irá aprender desde recursos mais básicos aos mais complexos.\nNão tenho a pretensão de ser o melhor professor, longe disto, mas meu objetivo foi preparar o melhor curso possível, o mais completo disponível na internet com o menor custo possível, e tenho certeza que irá aprender muitas coisas novas e irá se valorizar como profissional, e com dedicação para absorver estas informações e prática, seguindo meus vídeos e planilhas disponibilizados, poderá ter novas oportunidades profissionais no Brasil ou em outros países.\nEste curso estará disponível para você por tempo indeterminado e pode ser uma referencia no futuro quando precisar executar uma determinada tarefa.\nIra receber certificado de participação no curso com carga horária para comprovar sua participação.\nBons estudos.",
      "target_audience": [
        "DBA",
        "Desenvolvedores de software",
        "Analista e engenheiro de dados",
        "Gerentes",
        "Diretores",
        "Administradores em Geral",
        "Estudantes de concursos públicos de TI.",
        "Profissionais que trabalham com banco de dados em geral.",
        "Alunos de cursos de Sistemas de Informação, Ciência da Computação, Análise de Sistemas.",
        "Profissionais que buscam passar em prova de certificação com assunto similar.",
        "Estudantes que precisam comprovar carga horária de estudo e necessitam de certificado."
      ]
    },
    {
      "title": "みんなのAI講座 ゼロからPythonで学ぶ人工知能と機械学習 【2025年最新版】",
      "url": "https://www.udemy.com/course/learning-ai/",
      "bio": "【Google Colaboratory対応】初心者向けの人工知能と機械学習のコースです。プログラミング言語Pythonを使って、機械学習とプログラミングの基礎、必要な数学を勉強しましょう！文字認識や株価分析なども行います。",
      "objectives": [
        "簡単な機械学習のコードを書けるようになります。",
        "Pythonの基礎的なプログラミング技術が身につきます。",
        "ビジネス上必要な人工知能の基礎知識が身につきます。",
        "有名な機械学習ライブラリが扱えるようになります。",
        "機械学習と関連した簡単な数学の知識が身につきます。",
        "人工知能全般についての知識が身につきます。"
      ],
      "course_content": {
        "人工知能の概要と開発環境": [
          "教材の使い方について",
          "イントロダクション",
          "講座の概要",
          "人工知能の概要",
          "Pythonの概要",
          "学習の心構え",
          "開発環境について",
          "演習: 人工知能の概要と開発環境",
          "質疑応答: 人工知能の概要と開発環境"
        ],
        "Pythonの基礎": [
          "セクション2の教材",
          "セクション2の概要",
          "Pythonの基礎1",
          "Pythonの基礎2 PART1",
          "Pythonの基礎2 PART2",
          "Pythonの基礎3 PART1",
          "Pythonの基礎3 PART2",
          "Pythonの基礎4（2021.4.26追加）",
          "演習: Pythonの基礎",
          "質疑応答: Pythonの基礎"
        ],
        "必要な数学の学習": [
          "セクション3の教材",
          "セクション3の概要",
          "関数の描画",
          "べき乗とネイピア数",
          "シグモイド関数",
          "演習: 必要な数学の学習",
          "質疑応答: 必要な数学の学習"
        ],
        "ニューラルネットワーク": [
          "セクション4の教材",
          "セクション4の概要",
          "ニューラルネットワークの概要",
          "単一ニューロンの実装",
          "外部データの導入",
          "ニューラルネットワークの実装",
          "演習: ニューラルネットワーク",
          "質疑応答: ニューラルネットワーク"
        ],
        "機械学習": [
          "セクション5の教材",
          "セクション5の概要",
          "学習の仕組み",
          "出力層の学習",
          "中間層の学習",
          "演習: 機械学習",
          "質疑応答: 機械学習"
        ],
        "機械学習ライブラリの活用": [
          "セクション6の教材",
          "セクション6の概要",
          "scikit-learnの概要",
          "手書き文字認識",
          "株価の予測",
          "演習: 機械学習ライブラリの活用",
          "質疑応答: 機械学習ライブラリの活用"
        ],
        "さらに学ぶために": [
          "セクション7の教材",
          "セクション7の概要",
          "機械学習ライブラリの紹介",
          "数学の活用",
          "発展技術の解説",
          "CPUとGPU（2021.4.26追加）",
          "AIを利用したサービス（2021.4.26追加）",
          "Generative AIの躍進（2023.1.10追加）",
          "人工知能の未来",
          "質疑応答: さらに学ぶために"
        ],
        "AIの最新動向": [
          "AIの最新動向 2025年版 前編（2025.1.12追加）",
          "AIの最新動向 2025年版 後編（2025.1.12追加）"
        ],
        "付録": [
          "「付録」について（2022.1.27追加）",
          "内包表記（2022.1.27追加）",
          "無名関数とコールバック（2022.1.27追加）",
          "LaTeXによる数式の記述（2023.1.10追加）",
          "AIの最新動向 2024年版 前編（2024.1.25追加）",
          "AIの最新動向 2024年版 後編（2024.1.25追加）"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "中学レベルの数学で十分です。高度な数学は必要ありません。",
        "プログラミングが全くの未経験でも問題ありません。",
        "MacでもWindowsでも大丈夫です。"
      ],
      "description": "みんなのAI講座は、誰に対しても開かれた人工知能、機械学習の講座です。プログラミングや数学の事前知識はほとんど必要ありません。\n難解な数式やプログラミングが学習の妨げであった方でも、問題なく学習できます。\n文系や非エンジニアの方にもお勧めです。\nUdemyの受講生数が数万人に及ぶ経験豊富な講師が指導します。\n本コースでは、人工知能技術全般の解説を行いますが、実際にを書くのは主に機械学習のコードです。\n機械学習のコードは、人工知能の分野で最もメジャーなプログラミング言語、Pythonで記述します。\n開発には、Google Colaboratoryという開発環境を使います。これにより、初心者の方が躓きやすい環境設定が大幅に楽になります。ターミナルなどのコマンドラインを開く必要はありません。\nデータの分類や、文字認識、株価分析などの実践も行います。\n\nその他コースの特徴は、以下通りです。\n- 理論よりも体験を、手を動かすことを重視します。\n- 可能な限り、簡単な数学を用いて解説します。\n- 必要な数学はグラフィカル、直感的に解説します。\n- ニューラルネットや機械学習などの難しい概念は、細かく分解して少しずつ学習します\n- プログラミング初心者、未経験者でも大丈夫です。プログラミング言語Pythonを基礎から勉強します。\n- 機械学習の基礎が身につきます。機械学習のコードを一から実装します。既存の有名ライブラリの解説も行います。\n\nなお、大学レベル以上の数学や、機械学習の深い理論の解説は行いませんのでご注意ください。\nディープラーニングに関しては、概念のみの解説となります。\n\n\n2021.4.26 Section2、Section7にレクチャーが追加されました。\n2022.1.27 Section8にレクチャーが追加されました。\n2023.1.10 Section7、Section8にレクチャーが追加されました。\n2024.1.25 Section8にレクチャーが追加されました。\n2025.1.13 「AIの最新動向」に2025年の新コンテンツが追加されました。",
      "target_audience": [
        "人工知能、機械学習に興味があるが、最初のとっかかりが分からない方",
        "人工知能、機械学習関連の分厚い書籍に辟易した方",
        "人工知能、機械学習をビジネスで扱う必要に迫られた方",
        "数学、プログラミングが人工知能学習の障壁になっている方",
        "人工知能の学習を通してPythonプログラミングを身に付けたい方",
        "文系の方、非エンジニアの方にもおすすめです"
      ]
    },
    {
      "title": "Formação Cientista de Dados: O Curso Completo - 2025",
      "url": "https://www.udemy.com/course/cientista-de-dados/",
      "bio": "Da Estatística a Agente de Inteligência Artificial, Domine a Ciência de Dados e Seja um Profissional Super Qualificado!",
      "objectives": [
        "Criar modelos preditivos com Deep Learning, Neural Networks e Series Temporais",
        "Criar elementos gráficos com uso de boas práticas de visualização de dados",
        "Aplicar conceitos básicos de mineiração de textos",
        "Criar modelos de Regressão Linear e Logística",
        "Potencializar sua compreensão sobre outras áreas de Machine Learning, como Agrupamentos, Associadores e Seleção de Atributos",
        "Dominar os conceitos de Probabilidade, Intervalos de Confiança, Testes de Hipótese, Anova e Qui quadrado",
        "Aplicar conceitos de Grafos",
        "Ver cases reais das principais distribuições estatísticas: Normal, Poisson, Binomial, T de Student",
        "Aprenda conceitos de Gestão de Projetos",
        "Estude e pratique linguagem SQL",
        "Conheça bancos de dados NoSQL com MongoDB",
        "Conheça técnicas como Feature Scaling e Categorical Encoding",
        "Computação na Nuvem, tutoriais e exemplos práticos com Amazon AWS",
        "Fundamentos de Python, com estruturas de dados, Numpy e Pandas",
        "Spark com Databricks"
      ],
      "course_content": {
        "Apresentação": [
          "Instruções",
          "Apresentação",
          "Material para Download",
          "Instruções sobre Material para Download"
        ],
        "R: Configuração do Ambiente": [
          "Apresentação",
          "Instalação"
        ],
        "Python: Configuração do Ambiente": [
          "Escolhendo o Ambiente",
          "Usando Google Colab",
          "Apresentação do Anaconda",
          "Instalação",
          "Instruções sobre novas Bibliotecas"
        ],
        "Introdução ao R": [
          "Introdução",
          "Introdução ao RStudio",
          "Pacotes",
          "Aspectos Diversos",
          "Tipos de Dados e Operadores",
          "Estruturas de Dados",
          "Funções",
          "Ajuda",
          "Principais Funções",
          "Importando Dados",
          "Programação",
          "Referências Adicionais"
        ],
        "Prática em R": [
          "Ambiente do R",
          "Aspectos Diversos",
          "Pacotes",
          "Tipos de Dados e Operadores",
          "Estruturas de Dados",
          "Funções",
          "Ajuda",
          "Principais Funções",
          "Importando Dados",
          "Programação",
          "Faça você mesmo"
        ],
        "Introdução ao Python": [
          "Introdução",
          "Variáveis e Objetos",
          "Estruturas de Decisão",
          "Estruturas de Repetição",
          "Listas",
          "Dicionários, Sets e Tuplas",
          "Numpy",
          "Pandas",
          "Módulos e Pacotes",
          "Funções",
          "Funções Padrão",
          "Referências Adicionais"
        ],
        "Prática em Python": [
          "Variáveis e Objetos",
          "Estruturas de Decisão",
          "Estruturas de Repetição",
          "Listas",
          "Dicionários, Sets e Tuplas",
          "Numpy",
          "Pandas",
          "Módulos e Pacotes",
          "Funções",
          "Funções Padrão",
          "Faça você mesmo"
        ],
        "Limpeza e Tratamento de Dados": [
          "Limpeza e Tratamento de Dados"
        ],
        "Prática em R - Limpeza e Tratamento de Dados": [
          "Explorar os Dados",
          "Tratamento e Limpeza Parte I",
          "Tratamento e Limpeza Parte II",
          "Faça você mesmo"
        ],
        "Prática em Python - Limpeza e Tratamento de Dados": [
          "Preparação",
          "Analise Exploratória",
          "Tratamentos nos Dados",
          "Faça você mesmo"
        ]
      },
      "requirements": [
        "Familiaridade com Informática, escrita de código"
      ],
      "description": "Atualizado em 2025 para as últimas bibliotecas de Ciência de Dados, incluíndo LLMs e Agentes de IA.\nO mais completo, acessível e atualizado curso para você entrar ou se especializar no mundo da Ciência de Dados!\nMais de 340 aulas divididas em 52 seções\nMais de 260 scripts em no formato Notebook\nMais de 200 testes de múltipla escolha\nMais de 300 Apresentações (em pdf)\nAtividades Práticas\nCom o conteúdo de vários cursos em um só, este é um curso de Data Science em que você vai conhecer e aprender a aplicar todos os principais conceitos e técnicas para se qualificar e atuar como um Cientista de Dados, com videos explicativos e detalhados para leigos, exemplos práticos de codificação em R e Python usando dados reais, explicações de resolução de fórmulas passo a passo, contendo:\nIntrodução as Linguagens de Programação R e Python\nLimpeza e Tratamento de Dados\nGráficos, Visualização de Dados e Dashboards\nEstatística I: Amostragem, Medidas de Centralidade e Variabilidade, Probabilidades, Distribuição Normal\nEstatística II: Intervalos de Confiança, Testes de Hipótese, Distribuição t de Student, Distribuição Binomial, Distribuição de Poisson, Qui Quadrado, Anova\nRegressão Linear e Correlação\nSéries Temporais com Arima\nMachine Learning: Aplicações, conceitos, Classificação, Dimensionamento de Características, Codificação de Categorias, Agrupamentos, Regras de Associação.\nArtificial Neural Networks e Deep Learning\nAgentes, NLP e LLMs\nGrafos e Redes Sociais\nSQL e NoSQL\nSpark com Databricks\nComputação na Nuvem com AWS\nO curso ainda tem 3 seções com Bônus:\nPower BI\nTableau\nFundamentos de Big Data\nDúvidas durante o curso: você conta com a ajuda dos instrutores, com Formação em Tecnologia da Informação e uma década de experiência no mercado. Não perca tempo, matricule-se já!",
      "target_audience": [
        "Interessados em entrar para o mundo da Ciência de Dados, ou mesmo que queiram aperfeiçoar seus conhecimentos"
      ]
    },
    {
      "title": "Data Science & Maschinelles Lernen in Python - am Beispiel",
      "url": "https://www.udemy.com/course/data-science-und-machine-learning/",
      "bio": "Werde Datenexperte! Umfassender Kurs zum Thema Data-Mining und Maschinellem Lernen mit Python und Spark",
      "objectives": [
        "Riesige Datenmengen zu analysieren",
        "Finde Zusammenhänge in den Daten",
        "Entwickle ein Empfehlungssystem (\"Kunden die X kauften, kauften auch...\")",
        "Skaliere die Rechenarbeit auf ein Cluster mit Hilfe von Apache Spark und MLLIB",
        "Bekomme bessere Ergebnisse, indem du lernst, wie du die Daten vor der Berechnung bereinigen kannst"
      ],
      "course_content": {
        "Hier starten": [
          "Einleitung",
          "Benötigte Materialien",
          "Python lokal installieren (Windows)",
          "Crashkurs Python",
          "Crashkurs Python: Funktionen",
          "Python Scripts ausführen"
        ],
        "Statistik und Wahrscheikeitstheorie, Grundlagen Python": [
          "Arten von Daten",
          "Mittelwert, Medianwert, Modalwert",
          "Übung: Mittelwert, Medianwert, Modalwert",
          "Übung: Standardabweichung und Varianz",
          "Dichtefunktion",
          "Wichtige Verteilungen",
          "Perzentile und Momente",
          "Crashkurs Matplotlib",
          "Kovarianz und Korrelation",
          "Bedingte Wahrscheinlichkeit",
          "Lösung: Bedingte Wahrscheinlichkeit",
          "Satz von Bayes"
        ],
        "Grundlagen der Wahrscheinlichkeitsrechung": [
          "Lineare Regression",
          "Polynomiale Regression",
          "Multivariante Regressionsanalyse",
          "Mehrschichtige Modelle"
        ],
        "Machine Learning mit Python 3": [
          "Überwachtes vs. unüberwachtes, maschinelles Lernen",
          "Train / Test",
          "Bayes'sche Verfahren",
          "Übung: Bayes'sche Verfahren",
          "K-Means Clustering",
          "Übung: K-Means Clustering",
          "Entropie",
          "Entscheidungsbäume",
          "Installiere Graphviz",
          "Übung: Entscheidungsbäume",
          "Ensemble Learning",
          "Support Vector Machines",
          "Übung: Support Vector Machines"
        ],
        "Empfehlungssystem": [
          "Benutzerbasiertes, kollaboratives Filtern",
          "Artikelbasiertes, kollaboratives Filtern",
          "Übung: Empfehlungssystem für Filme (benutzerbasiert), Teil 1",
          "Übung: Empfehlungssystem für Filme (benutzerbasiert), Teil 2",
          "Übung: Empfehlungssystem für Filme (artikelbasiert), Teil 1",
          "Übung: Empfehlungssystem für Filme (artikelbasiert), Teil 2"
        ],
        "Weitere Techniken und Konzepte": [
          "K-Nächste-Nachbarn: Konzept",
          "Übung: Bewertung von Filmen vorhersagen (mit kNN)",
          "Dimensionsreduktion, Hauptkomponentenanalyse",
          "Übung: Dimensionsreduktion des Iris-Datensatzes",
          "Data Warehousing: Konzept, ETL / ELT",
          "Bestärkendes Lernen (Reinforcement Learning)"
        ],
        "Arbeiten mit echten Daten": [
          "Das Bias / Varianz - Dilemma",
          "Übung: Überanpassung vermeiden mit der k-fold cross-validation",
          "Bereinigen von Daten, Normalisieren von Daten",
          "Interaktiv: Bereinigen von Zugriffsdaten auf eine Webseite",
          "Normalisieren von numerischen Daten",
          "Interaktiv: Ausreißer entdecken"
        ],
        "Apache Spark": [
          "Einführung in Apache Spark",
          "Installation von Apache Spark (Windows)",
          "Grundlagen: Apache Spark",
          "Resilient Distributed DataSet",
          "Einführung in mllib",
          "Entscheidungsbäume mit Apache Spark",
          "K-Means Clustering mit Apache Spark",
          "Konzept: TF-IDF",
          "Wikipedia durchsuchen mit TF-IDF und Apache Spark"
        ],
        "Weitere Konzepte": [
          "A/B - Test",
          "T-Test / P-Wert",
          "Übung: T-Test / P-Wert",
          "Wie lange wird ein Test ausgeführt?",
          "Häufige Fehler"
        ],
        "Schlussworte": [
          "Schlussworte",
          "Bitte hinterlasse eine Bewertung!",
          "Bonus"
        ]
      },
      "requirements": [
        "Du brauchst einen Computer (Windows / Mac / Linux), um Anaconda auszuführen. Im Kurs werden wir die Installation Schritt für Schritt durchgehen.",
        "Du solltest vorher schonmal etwas programmiert haben",
        "Du solltest ein grundlegendes Verständnis von Mathematik haben. Wenn du ein Gymnasium besucht hast, reicht das locker.",
        "Die Installationsanleitungen in diesem Kurs beziehen sich auf Windows. Die Code-Beispiele werden auch auf Mac / Linux laufen, wir können für Mac / Linux - Probleme aber keinen Support anbieten."
      ],
      "description": "Kurs zuletzt aktualisiert: 09.03.2017!\nData Scientists landen richtig gut bezahlte Jobs, mit einem durchschnittlichen Gehalt von ~80.000€ (Quelle: Gehaltsvergleichsportal Glassdoor), in Amerika sogar noch mehr. Und das ist nur der Durchschnitt. Aber es geht nicht nur ums Geld - der Job ist auch noch verdammt spannend!\nWenn du schon etwas programmieren kannst, wird dir dieser Kurs alles beibringen, was du zum Thema Data Science und Maschinellem Lernen wissen musst. Sei es, um das wissen für ein eigenes Projekt anzuwenden, oder um einen Einstieg in dieses Gebiet zu finden.\nDieser umfassende Kurs besteht aus 68 Lektionen, gut 9 Stunden Video, und zu vielen Themen gibt es praktische Python Codebeispiele, damit du direkt siehst, wie diese Algorithmen verwendet werden können.\nDie Themen dieses Kurses sind die Themen, die wirklich für einen Job in diesem Feld benötigt werden. In verständlicher deutscher Sprache wirst du die verschiedenen Möglichkeiten kennenlernen:\nLineare und Polynomiale Regressionsanalyse\nK-Means - Algorithmus\nHauptkomponentenanalyse\nTrain/Test, Kreuzvalidierungsverfahren\nBayes'sche Methoden\nEntscheidungsbäume, Random Forests\nMultivariante Regression\nSupport Vector Machines\nBestärkendes Lernen\nEmpfehlungssystem: Kollaboratives Filtern\nK-Nächster-Nachbar\nBias / Varianz - Dilemma\nEnsemble Learning\nVolltextsuche mit Hilfe von TF-IDF\nWie wird ein Experiment durchgeführt? AB-Tests\n... und noch viel mehr. Zudem lernst du in einem kompletten Kapitel, wie maschinelles Lernen mit Apache Spark funktioniert. Mit Hilfe von Spark kannst du die Berechnungen auf mehrere Computer aufteilen und so massive Datenmengen verarbeiten.\nWenn du noch nicht mit Python programmiert hast, kein Problem - am Anfang gibt es einen kurzen Crashkurs. Wenn du vorher schonmal was programmiert hast, reicht das locker aus. In diesem Kurs zeige ich dir auch die Installation unter Windows, wobei die Beispiele auch unter Mac oder Linux ausgeführt werden könnten - bei Problemen die mit dem Betriebssystem zusammenhängen kann ich dich aber nur bei Windows unterstützen.\nJedes Thema wird in normaler deutscher Sprache erklärt, ohne verwirrende mathematische Fachwörter. Anschließend lernst du, wie du mit Python den Algorithmus verwenden kannst.\nWenn du schonmal was programmiert hast, und dich mit der Auswertung von Daten beschäftigen möchtest, dann ist der Kurs genau das Richtige für dich. Du lernst in diesem Kurs all die Grundlagen, die du brauchst, wenn du Daten im echten Leben auswerten möchtest. Ich glaub, der Kurs wird dir gefallen! :-)",
      "target_audience": [
        "Softwareentwickler oder Programmierer, die eine Karriere im Bereich Data Science starten wollen",
        "Du bist Analyst, und wertest z.B. im Finanz- oder Versicherungssektor Daten aus? In diesem Kurs lernst du, wie du das automatisiert mit Programmen umsetzen kannst. Wichtig: Du solltest vorher schonmal irgendwas programmiert haben.",
        "Wenn du noch nie programmiert hast - dann solltest du diesen Kurs noch NICHT belegen. Schau dir erstmal einen Python-Kurs an"
      ]
    },
    {
      "title": "Python 資料分析 - 入門實戰",
      "url": "https://www.udemy.com/course/codegym-python-analytics/",
      "bio": "這堂課程已經為4000 多位軟體開發人員和創作者帶來實質的幫助，課程共有40多個單元，10 多個資料集，還贈送一本高達41 個章節的電子書，課程中使用大量不同領域的資料做教學，最後你還能取得數十個豐富珍貴的資料原始檔",
      "objectives": [
        "課程中使用了數10個資料集，作為教學示範，其中包含了youtube 排名數據、Google股價、美國嬰兒姓名統計資料、鐵達尼號乘客名單、世界各國飲酒統計資料等，多個豐富的資料，讓你在學習以下資料分析技術時更容易理解",
        "40 個資料分析課程單元，你將學會資料分析的知識，切割出資料和排序、將分散的資料群組化後分析、結合連結多組資料、整併分析等各種技巧",
        "贈送一本高達41 個章節的電子書，當你透過Code Gym 的課程打下紮實的基礎之後，還能夠繼續不斷成長，自我學習，這才是這一堂課程帶給你最重要的價值",
        "課程單元都有練習題目，練習開始之前都有影片解說，練習之後也有提供正確答案的程式碼，讓同學能夠將所學的技巧活用在解決問題上",
        "資料視覺化課程，透過繪製圖表的工具，將資料繪製出精美的圖表，讓使用者能夠清楚理解你分析後的知識和重點，最後使用台股的資料，繪製出股票專用的K線圖，觀察股價漲跌和交易量",
        "資料不乾淨怎麼辦？數據清理和整理是資料分析初期的重要步驟，如果你沒有一個乾淨完整的資料，分析出來的資料也不會正確，所以課程將會教你這個重要步驟的方法",
        "這堂課程已經為2600 多位軟體開發人員和創作者帶來實質的幫助",
        "Code Gym 官網有提供更多豐富的課程介紹，歡迎您前往瀏覽課程細節！！"
      ],
      "course_content": {},
      "requirements": [
        "準備一台Mac或Windows電腦即可"
      ],
      "description": "這是一堂適合資料分析初學者的課程，透過這堂課程，我將快速的帶領同學從無到有，學會資料分析技術，課程中沒有艱澀難懂的演算法，高階程式語言技巧，我只教同學用得到的資料分析技術。這堂課程不同於傳統的教學方式，一般課程講師只用簡單、手動建立的資料做範例，但介紹的確是複雜難懂的程式功能，課程之後學生以為自己懂了，但確不知道如何應用。為了避免這樣的問題，我使用大量不同領域的資料做教學，這樣的教學方式讓同學上完這堂課程之後，你將會明確知道如何整理雜亂的資料，透過分析找出有用的知識，最後還能取得數十個豐富珍貴的資料原始檔。\n\n\nCode Gym 官網有提供更多豐富的課程介紹和官網優惠，歡迎您前往瀏覽課程細節！！\n\n\n課程架構主要分成三個部分，分別是Python基礎課程與環境安裝、資料分析、資料視覺化基礎課程，以下針對這三個部分做詳細介紹。\nPython基礎課程與環境安裝\n這是為了Python 程式語言初學者設計的課程單元，從電腦環境設定與安裝，一直到能夠使用Python 程式語言，讓初學者能夠無痛接軌，繼續後面資料分析課程。\n\n* 安裝電腦環境，分別針對Windows和Mac兩個不同作業系統，錄製課程影片\n* 多種編輯程式軟體介紹，讓同學有多種選擇，保持彈性\n* 第一隻Python 程式語言\n* 變數和輸入文字\n* 內建型態與轉型的方式\n* 函式\n* List和Tuple\n* 字典(Dictionary)\n\n資料分析\n這堂課程使用了數十個資料集，作為教學示範，其中包含了youtube 排名數據、Google股價、美國嬰兒姓名統計資料、鐵達尼號乘客名單等，多個豐富的資料，讓你在學習以下資料分析技術時更容易理解\n\n* 資料分析基礎知識與技能介紹\n* 切割出重要的資料和排序的技巧\n* 將分散的資料群組化後分析結果\n* 結合連結多組資料，整併分析\n* 如何使用時間序列\n* 統計應用實戰分析\n* 字串處理技巧\n* 資料不乾淨怎麼辦？數據清理和整理\n\n每個課程單元都有練習題目，練習開始之前都有影片解說，練習之後也有提供正確答案的程式碼，讓同學能夠學以致用。\n\n資料視覺化基礎課程\n前面課程將數據分析之後，透過繪製圖表的工具，將資料繪製出精美的圖表，讓使用者能夠清楚理解你分析後的知識和重點，最後使用台股的資料，繪製出股票專用的K線圖，觀察股價漲跌和交易量。\n\n* 資料視覺化圖表\n* 台灣股價交易分析\nAI 人工智慧\nAI 輔助資料分析，用最簡單的自然語言，輕鬆的找出資料中潛在的意義\n\n講師Ryan\n華碩高級工程師，多年軟體開發經驗\nCode Gym 創辦人\n目前在Hahow有開設Java程式語言和資料庫設計課程，Udemy 有開設「Python基礎課程和網路爬蟲入門實戰」課程\n課程品質保證\n後製剪輯，沒有贅詞，確保優質學習過程\n有字幕，邊看邊學更容易理解\n程式一行一行說明帶著你一起學，讓你聽得清楚又明白\n適合對象\n初入資料分析領域的新鮮人\n想理解資料科學方法與應用情境的專業人士\n商學院背景，想學習資料科學的大學或研究所學生\n程式語言初學者\n\n\n從實作專案來學習，已經被證明是學習技能的最有效的方法，對程式設計更是如此！\n如果你正在尋找透過實作來學習 資料分析 的課程，那這堂課程就是你最好的選擇\n\n\nCode Gym 官網有提供更多豐富的課程介紹和官網優惠，歡迎您前往瀏覽課程細節！！",
      "target_audience": [
        "初入資料分析領域的新鮮人",
        "想理解資料科學方法與應用情境的專業人士",
        "商學院背景，想學習資料科學的大學或研究所學生",
        "程式語言初學者"
      ]
    },
    {
      "title": "RStudio Setup and Customization for R or Python Programming",
      "url": "https://www.udemy.com/course/rstudio-setup-and-customization-free-course/",
      "bio": "R Programming, Configure RStudio, Data Science, R Interface, R Compiler, Python Programming, Reticulate",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "No programming or RStudio experience needed."
      ],
      "description": "As of of 2024, R is rocking it with these cool numbers:\nRStudio has an active user base of 3.5 million.\nPosit cloud has a 65,000 userbase.\nOver the year, an impressive 2 billion packages were downloaded.\nNew 2024 -- Using Python with RStudio has never been easier! New lectures added!\nRStudio (Posit) is the best IDE there is for R Programmers and Data Professionals.\nIt was initially created for R users and currently supports Python, SQL, C++, D3, and other programming languages.\nIt also facilitates the creation of R packages, Shiny Applications, Markdown documents, Quarto Documents, books, blogs, websites, Quarto Presentations (new!), APIs.\nRStudio is what made R great and now millions of data scientists use R on daily basis.\nI have taught R & RStudio to over 1,000 people and always emphasized the importance of understanding all the features of the RStudio API.\nHaving a friendly and ergonomic interface is very important.\nUnderstanding the complete functionalities of Rstudio will give you an edge as some of them will save you hours, and others will improve your overall user experience.\nThis course will explain to you how to\ndownload and install R and set up your RStudio IDE\nconfigure the global options\nunderstand the panes (console, scripts, environment, files, plots, packages, viewer, help)\nlaunch projects and navigate through projects\nunderstand the working directory, file, and folder structure\ncreate your first R script in RStudio\nconnect to git and use the git pane\nclone repository from GitHub\ncustomize your code and add tweaks\ninstall Python and run py scripts (live!)\nOnce you complete this course you will set up your R and RStudio correctly and once and for all.",
      "target_audience": [
        "Beginners who intend to learn R & RStudio but don't know where to begin",
        "Programmers who just installed RStudio and are lost in the interface",
        "RStudio users who want to unlock the full potential of the IDE"
      ]
    },
    {
      "title": "IPA Automatización de Procesos Inteligente con Python [2025]",
      "url": "https://www.udemy.com/course/ipa-automatizacion-de-procesos-inteligente-con-python-2022/",
      "bio": "Descubre el potencial del RPA Inteligente con Python y automatiza tus tareas aburridas con IA y Machine Learning",
      "objectives": [
        "Desarrollo de robots con Python que automaticen tareas repetitivas.",
        "Automatizar lectura y escritura de ficheros Excel, CSV, Word, pdf, imagen..",
        "Automatizar la organización de ficheros y creación de directorios",
        "Automatizar la extracción de datos desde la web",
        "Automatizar la inserción masiva de datos en portales web",
        "Automatizar la lectura y envío de emails",
        "Automatizar la interfaz GUI (ratón, teclado y pantalla)",
        "Aplicar algoritmos de Machine Learning con la librería scikit-learn",
        "Cómo desplegar soluciones Intelligent Process Automation",
        "Crear un caso de uso completo donde aplicar todos los conceptos.",
        "Dominar la tecnología Intelligent Process Automation y analizar y priorizar procesos susceptibles de ser automatizados.",
        "Adquirirá un conocimiento extenso en la tecnología puntera IPA que podrá aplicar de inmediato a un precio muy asequible en comparación con otros programas."
      ],
      "course_content": {},
      "requirements": [
        "Ninguno, incluso si no conoces Python habrá un bloque para aprender los fundamentos."
      ],
      "description": "¿Quieres dominar la tecnología Intelligent Process Automation (IPA) consiguiendo automatizar todas esas tareas aburridas y repetitivas aplicando además Inteligencia Artificial?\nSeguro que tienes multitud de actividades en el día a día susceptibles de ser automatizadas y que drenan tu valioso tiempo. Además, no es ningún secreto que gran parte de los actuales puestos de trabajos serán reemplazados por robots software más pronto de lo que pensamos.\nHas llegado al lugar adecuado, en este curso aprenderás todo lo necesario para convertirte en un maestro de la Automatización de Procesos con el lenguaje Python además de aplicar Inteligencia Artificial para poder tomar decisiones en base al aprendizaje automático de tus datos. Con esto conseguirás una enorme mejora de la eficiencia y calidad en tus tareas diarias y te convertirás en un perfil que destaque sobre el resto con estas habilidades.\nDurante este curso utilizaremos el lenguaje Python, totalmente gratuito (open source) y sin necesidad de pagar por ninguna plataforma. No es necesario que tenga conocimientos previos de este lenguaje puesto que hay un módulo para aprender los fundamentos de Python, además conseguirá:\n• Automatización lectura y escritura de ficheros Excel, CSV, Word, pdf, imagen..\n• Automatización organización de ficheros\n• Automatización extracción de datos desde la web\n• Automatización inserción masiva de datos en portales web\n• Automatización lectura y envío de emails\n• Automatización interfaz GUI (ratón, teclado y pantalla)\n• Aplicar algoritmos de Machine Learning con la librería scikit-learn\nSin duda, dominar todas estas habilidades te abrirá un universo de posibilidades ahorrándote mucho tiempo y consiguiendo que un robot RPA inteligente solucione y ejecute tus tareas aburridas.\nEste curso tendrá un enfoque muy práctico con casos de uso concretos para que puedas aplicar todos los conocimientos aprendidos. Para ello el curso estará estructurado en los siguientes bloques:\n______________________________\nBLOQUE 1: Introducción a Intelligent Process Automation y Python\nBLOQUE 2: Fundamentos del lenguaje Python (OPCIONAL)\nBLOQUE 3: Automatización Excel, Word y PDF\nBLOQUE 4: Automatización Web\nBLOQUE 5: Automatización Email\nBLOQUE 6: Automatización de la interfaz (GUI)\nBLOQUE 7: Aplicación Inteligencia Artificial\nBLOQUE 8: Despliegue de soluciones IPA\n______________________________\nTendrás a tu disposición un material extenso de consulta y todos los scripts explicados durante este curso de tal manera que te sea muy sencillo reutilizarlos para tu caso de uso concreto. Mi objetivo es que cuando finalices el curso puedas aplicarlo de inmediato a tu situación particular.\n\n\nEscuche de otros alumnos por qué este es el curso de Intelligent Process Automation MEJOR VALORADO en español:\n______________________________\n\"Muy recomendable el curso, el profesor y el contenido. Un concepto innovador y de gran uso actualmente. Maravilloso curso que me ha venido muy bien y se lo recomiendo, es una joya y una magnifica inversion\" -- Hugo Montoya\n\n\n\"Excelente curso, termine haciendo mi propio bot, logueandome en zoho crm descargando el excel de posibles clientes, moviéndolo de descargas a la carpeta en la cual los almacenare, luego esos registros de excel los cargue uno a uno en un formulario que registraba clientes, y finalmente descarga todos los clientes del sistema y manda el excel adjunto al email que yo desee, super bueno.\" -- Camilo Agudelo\n\n\n\"Excelente disparador de ideas para automatizaciones administrativas. Muy bien explicado y bien disponibilizados los códigos.\" --Ana Carina\n______________________________\nSi quieres aprovechar la tecnología IPA para ahorrar tiempo automatizando tus tareas aburridas, dedicar tu tiempo a actividades que aporten mayor valor y aplicar Inteligencia Artificial para que la computadora aprenda de los datos, este curso es para ti.\nTe garantizo que al finalizar el curso podrás automatizar procesos a nivel profesional incrementando exponencialmente tu productividad.\n¡Únete a más de 30.000 estudiantes que ya se aprovechan de estos conocimientos!",
      "target_audience": [
        "Toda persona que quiera potenciar su perfil dominando técnicas IPA con el lenguaje Python.",
        "Toda persona que quiera especializarse para conseguir un puesto de trabajo en RPA o Inteligencia Artificial, algo altamente demandado en el mercado.",
        "Personal administrativo que precise ahorrar su preciado tiempo eliminando aquellas tareas repetitivas disminuyendo errores.",
        "Perfiles técnicos que ejecuten actividades repetitivas y quieran ser más eficientes mejorando además la calidad.",
        "Gestores de equipos que requieran analizar qué procesos pueden ser sometidos a IPA y mejorar el desempeño del equipo.",
        "Analistas que quieran automatizar sus tareas diarias de análisis con herramientas como Excel, Word,...",
        "Personas que estén cansadas de procesar cientos de emails y quieran automatizar estos procesos de lectura y envío.",
        "Todo aquél que quiera aprender a aplicar Inteligencia Artificial en los procesos consiguiendo que la computadora aprenda de nuestros datos para realizar predicciones.",
        "Estudiantes que quieran obtener habilidades que le abrirán puertas en el mercado laboral.",
        "Cualquier persona que quiera automatizar sus procesos cotidianos para enfocarse en actividades de mayor valor."
      ]
    },
    {
      "title": "Data Science et Machine Learning | MasterClass Python",
      "url": "https://www.udemy.com/course/data-science-et-machine-learning-masterclass-python/",
      "bio": "Apprendre la Data Science et le Machine Learning avec Python ! (NumPy, Pandas, Matplotlib, Scikit-Learn et bien plus...)",
      "objectives": [
        "Maîtriser les compétences essentielles en matière de Data Science (science des données)",
        "Comprendre la Machine Learning (apprentissage automatique) en profondeur",
        "Répliquer des situations du monde réel et reproduire des rapports de données",
        "Apprendre NumPy pour le traitement numérique des données avec Python",
        "Réaliser du feature engineering (ingénierie des caractéristiques/features) sur des études de cas réels",
        "Apprendre à utiliser Pandas pour la manipulation de données avec Python",
        "Créer des algorithmes de Machine Learning supervisé pour prédire des classes (modèles de classification)",
        "Apprendre Matplotlib pour créer des visualisations de données entièrement personnalisées avec Python",
        "Créer des algorithmes de Machine Learning pour prédire des valeurs continues (modèles de régression)",
        "Apprendre Seaborn pour créer de magnifiques diagrammes statistiques avec Python",
        "Construire un portfolio de projets de Data Science et Machine Learning pour avoir un CV efficace et moderne",
        "Apprendre à utiliser Scikit-learn pour appliquer de puissants algorithmes de Machine Learning",
        "Apprendre les meilleures pratiques pour traiter des ensembles de données (datasets) du monde réel"
      ],
      "course_content": {},
      "requirements": [
        "Connaissance de base de Python"
      ],
      "description": "Il s'agit du cours en ligne le plus complet pour apprendre Python, la Data Science (science des données) et le Machine Learning (apprentissage automatique). Rejoignez-nous dès maintenant pour apprendre et maîtriser ces sujets !\n\n\nQue contient ce cours ?\nBienvenue dans le cours le plus complet pour apprendre en ligne la Data Science et le Machine Learning ! Cette MasterClass a été conçue pour mettre en place ce qui semble être la meilleure façon de passer de zéro à héros pour la Data Science et le Machine Learning avec Python !\nCe cours est conçu pour une personne qui connaît déjà un peu le langage Python et qui est prêt à s'immerger en profondeur dans l'utilisation de ces compétences Python pour la Data Science et le Machine Learning. Le salaire de départ typique d'un data scientist peut dépasser aisément les 100 000 euros annuel, et nous avons créé ce cours pour aider à guider les apprenants vers l'apprentissage d'un ensemble de compétences qui les rendront extrêmement intéressants (et attractifs !) dans le monde du travail actuel.\n\n\nNous couvrirons tout ce que vous devez savoir sur la stack tech (compétences techniques) complète de Data Science et Machine Learning requise dans les meilleures entreprises du monde. Nos étudiants ont obtenu des emplois chez McKinsey, Facebook, Amazon, Google, Apple, Asana et d'autres grandes entreprises technologiques !\nNous avons structuré le cours en nous appuyant sur notre expérience de l'enseignement en ligne (et en présentiel) afin de proposer une approche claire et structurée. Cela vous guidera pour comprendre non seulement comment utiliser les bibliothèques populaires de Data Science et Machine Learning, mais aussi pourquoi et quand nous les utilisons.\nCe cours est un équilibre parfait entre les études de cas pratiques issues du monde réel et la théorie mathématique qui se cache derrière les algorithmes de Machine Learning = 50% Théorique (concepts et mathématiques) - 50% pratique (implémentation code Python)\nNous couvrirons des algorithmes de Machine Learning avancés que la plupart des autres cours ne couvrent pas ! Y compris les méthodes de régularisation avancées et les méthodes d'apprentissage non supervisé les plus récentes, telles que le DBSCAN.\n\n\nCe cours complet est conçu pour être à la hauteur des Bootcamps qui coûtent généralement des milliers d'euros. Il comprendra les sujets suivants :\nLa programmation avec Python\nNumPy avec Python\nApprentissage complet de Pandas pour l'analyse de données\nCompréhension complète de la bibliothèque de programmation Matplotlib\nApprentissage en profondeur de Seaborn pour les visualisations de données\nMachine Learning avec Scikit-Learn\n\n\nNous sommes extrêmement reconnaissants de la chance que nous avons d'avoir la chance de pouvoir vous enseigner des sujets qui nous passionnent comme la Data Science et le Machine Learning !\n\n\n-Rod, Jose et l'équipe Pierian Data Inc.",
      "target_audience": [
        "Développeurs Python débutants intéressé par l'apprentissage automatique (Machine Learning)",
        "Développeurs Python débutants intéressé par la science des données (Data Science)",
        "Tout personne souhaitant apprendre en profondeur Data Science + Machine Learning"
      ]
    },
    {
      "title": "Máster de especialista en Ciencia de Datos con Python",
      "url": "https://www.udemy.com/course/master-en-ciencia-de-datos-con-python/",
      "bio": "Aprenda a desarrollar proyectos de Machine Learning y Deep Learning con Python. Data Science de básico a Experto",
      "objectives": [
        "Aplicar técnicas de análisis y visualización de datos en un conjunto de datos complejo para problemas de machine learning con el lenguaje de programación Python",
        "Aplicar técnicas de tratamiento de datos en un conjunto de datos para mejorar la robustez y métrica de salida de los diferentes algoritmos de machine learning.",
        "Comprender los diferentes mecanismos y técnicas para aplicar analítica predictiva en problemas de machine learning e interpretar la salida dada por los modelos.",
        "Realizar modelos algorítmicos robustos con una optimización de sus hiperparámetros para la fase de predicción con el lenguaje de programación Python.",
        "Utilizar librerías específicas de Python como scikit-learn para trabajos de Machine Learning con el lenguaje de programación Python.",
        "Desarrollar y analizar proyectos de machine learning, Aprendizaje Supervisado, como regresión, clasificación y multiclase.",
        "Desarrollar y analizar proyectos de machine learning de Aprendizaje No Supervisado con el lenguaje de programación Python.",
        "Utilizar las técnicas más avanzadas necesarias para desarrollar modelos de Deep Learning de última generación con el lenguaje de programación Python.",
        "Aprenderá sobre las redes neuronales FeedForward y cómo desarrollarlas con el lenguaje de programación Python y Keras.",
        "Diseñar y Desarrollar Redes Neuronales Convolucionales para proyectos avanzados con el lenguaje de programación Python.",
        "Diseñar y Desarrollar Redes Neuronales Recurrentes para problemas de secuencias o tiempo con el lenguaje de programación Python."
      ],
      "course_content": {},
      "requirements": [
        "Durante el curso trabajaremos con la última versión del programa, pero no te preocupes si tienes una versión anterior, ya que las distintas versiones difieren muy poco entre sí. Si existe algún cambio importante entre las distintas versiones hablaremos de ello durante la formación.",
        "Para la realización de este curso no vas a necesitar el equipo informático más potente del mercado, ya que el software empleado en la formación se encuentra perfectamente optimizado y su uso es muy fluido en todo tipo de equipos, tanto en PC como en Mac.",
        "Cuando compres el curso vas a poder acceder a las clases cuando y donde quieras. El curso se queda en tu cuenta de Udemy para siempre. :)",
        "El más importante requisito para realizar este curso es el entusiasmo y la motivación por aprender nuevas habilidades que aumenten tus competencias profesionales."
      ],
      "description": "Máster de especialista en Ciencia de Datos con Python.\nAprenda a desarrolar proyectos de Machine Learning y Deep Learning con Python. Data Science de básico a Experto\nInstructores: PhD. Manuel Castillo.\nRequisitos: Se recomienda tener conocimientos de programación, preferiblemte Python.\n\n\nDescripción del Curso:\nEl curso de “Máster de especialista en Ciencia de Datos con Python” tiene dos bloques principales de estudio:\nEl primer bloque se centra en un subcampo específico de aprendizaje automático llamado modelado predictivo y clustering. Este es el campo del aprendizaje automático que es el más útil en la industria y el cual se utilizar la librería de aprendizaje automático scikit-learn en Python por su gran rendimiento y facilidad en su uso.\nA diferencia del campo más amplio del aprendizaje automático que podría utilizarse con datos en cualquier formato, el modelado predictivo y clustering se centra principalmente en datos tabulares, llamados técnicamente Tidy Data (por ejemplo, tablas de números como en una hoja de cálculo).\nEl segundo bloque se centra en el aprendizaje profundo. En este curso trataremos la librería Keras de Python para Deep Learning y cómo usarla para desarrollar y evaluar modelos de Deep Learning. En este curso, descubriremos las técnicas, código y habilidades de Deep Learning que luego puede llevar a sus propios proyectos de Machine Learning.\nLa librería Keras envuelve la complejidad de la computación numérica de Theano y TensorFlow proporcionando una API concisa que usaremos para desarrollar nuestra propia red neuronal y modelos Deep Learning. Además, trataremos las habilidades de Deep Learning para llevar esta nueva tecnología asombrosa a nuestros propios proyectos.\n\n\nContenidos del Curso:\nMÓDULO I. Introducción.\nConceptos básicos de machine learning.\nJupyter Notebook como nuestro entorno de machine learning.\nCurso rápido de Python.\nMÓDULO II. Análisis de datos\nCargar un conjunto de datos.\nEstadística descriptiva.\nVisualización de datos.\nTaller: Trabajo de aplicación de diferentes técnicas analíticas de datos en un conjunto de datos seleccionado por el usuario e interpretar la salida obtenida.\nExamen tipo test sobre los contenidos del módulo.\nMODULO III. Preprocesamiento de datos\nAnálisis exploratorio de datos.\nPreprocesamiento de datos.\nMétodos de remuestreo para estimar la precisión del modelo.\nTaller: Trabajo de aplicación de diferentes técnicas de análisis y procesamiento de datos de datos en un conjunto de datos seleccionado por el usuario e interpretar la salida obtenida.\nExamen tipo test sobre los contenidos del módulo.\nMÓDULO IV. Fase de tratamiento de datos\nEvaluación de las métricas.\nFeature Selection.\nFeature Importance.\nReducción de dimensiones en un dataset.\nTaller: Aplicación de diferentes técnicas de tratamiento de datos en un conjunto de datos y verificación de su impacto en las métricas algorítmicas.\nExamen tipo test sobre los contenidos del módulo.\nMÓDULO V. Fase de modelado\nAlgoritmos de Machine Learning.\nRendimiento de los algoritmos.\nAlgoritmos Ensamblados\nAlgoritmo \"Super Lerner\"\nTaller: Aplicación de diferentes algoritmos de machine learning en un conjunto de datos e interpretar la salida obtenida, así mismo, verificar el algoritmo que tenga mejor comportamiento.\nExamen tipo test sobre los contenidos del módulo.\nMÓDULO VI. Redes Neuronales.\nCurso sobre Multilayer Perceptron\nRedes Feed Forward\nDesarrollar nuestra primera red neuronal con Keras.\nEvaluar el rendimiento de los modelos.\nProyecto: Problema de clasificación multiclase.\nProyecto: Problema de regresión.\nMODULO VII. Redes Neuronales Avanzadas\nGuardar modelos para hacer predicciones.\nMantener puntos de control en el entrenamiento de los modelos.\nComprender el comportamiento del modelo durante el entrenamiento trazando el historial.\nReducir el sobreajuste con la regularización Dropout.\nOptimizar el rendimiento con una planificación basada en la tasa de aprendizaje.\nMÓDULO VIII. Redes Neuronales Convolucionales\nCurso intensivo en redes neuronales convolucionales.\nOptimizar el rendimiento del modelo con Data Augmentation.\nProyecto: Reconocimiento de dígitos manuscritos.\nProyecto: Reconocimiento de objetos en fotografías.\nProyecto: Clasificación de opiniones en revisión de películas.\nMÓDULO IX. Redes Neuronales Recurrentes\nCurso intensivo en redes neuronales recurrentes.\nModelos de perceptrones multicapa para problemas de series de tiempo.\nModelos LSTM para problemas de series temporales.\nProyecto: Clasificación secuencial de reseñas de películas.\nProyecto: Generación de texto.\nCaracterísticas del Curso:\nRecuerda que esta formación incluye lecciones en vídeo fullHD con audio de estudio (compatible con TV, PC, Mac, tablet y smartphone), artículos didácticos, actividades, proyectos paso a paso, recursos descargables, links de interés, acceso de por vida, certificado de finalización, tutorización online, y una exclusiva comunidad de aprendizaje privada que nos ayudamos aportando nuestras experiencias en el foro de comunicación del curso.\nCon esta formación disfrutarás aprendiendo desde dónde quieras, sin tener que desplazarte, sin horarios, con quién quieras, según tus necesidades y disponibilidad. Aprenderás con un instructor avalado por miles da alumnos satisfechos en todo el mundo (comentarios certificados). Conocerás las técnicas, métodos, trucos y flujos de trabajo de este sector creativo. El docente te transmitirá su sabiduría y conocimientos con pasión a la vez que las explicaciones concisas, claras, sencillas y con un enfoque profesional en cada clase. Podrás conseguir un  certificado homologado personalizado y firmado por tu instructor en cada formación. De está forma podrás compartir tu título en tu portafolio, currículo, en redes sociales...\nCon la alta definición de los vídeos (vídeo fullHD y audio de estudio) conseguirá no te perder detalle. Podrás ver las clases las veces que requieras para recordar y perfeccionar tus habilidades como diseñador. Tendrás la posibilidad de preguntar, pedir opinión y ayuda al instructor, además de compartir tu experiencia de aprendizaje con los demás alumnos del curso, tan apasionados como tú, repartidos por todo el mundo. Seleccionamos cuidadosamente los contenidos y producimos cada curso para garantizar una experiencia de aprendizaje online integral y de la máxima calidad.\n¿A qué esperas?, este curso es ideal para ti, atrévete a convertirte en un experto. Adelante, nos vemos dentro de la formación.",
      "target_audience": [
        "Aquellos usuarios del programa que quieran ampliar el dominio de mismo y conocer múltiples trucos, consejos y recursos para esta herramienta.",
        "Principalmente aquellos que quieran aumentar sus posibilidades de empleabilidad, contratación y/o promocionar dentro de su sector.",
        "Entusiastas de la Inteligencia Artificial y, sobre todo, de Ciencia de Datos",
        "Desarrolladores de modelos de Machine learning y Deep learning"
      ]
    },
    {
      "title": "脳科学と人工知能: シンギュラリティ前夜における、人間と機械の接点",
      "url": "https://www.udemy.com/course/brain-ai/",
      "bio": "脳科学とAIの基礎を、数学やPython等のプログラミングなしでボーダレスに学びます。脳の仕組みをニューラルネットワークや強化学習などのアルゴリズムを交えながら学習し、テクノロジーやビジネスの未来に対する洞察力を育みます。",
      "objectives": [
        "脳科学と人工知能を、ボーダーレスに学びます。",
        "21世紀において最も重要な教養の一つ、「脳科学」の基礎を身につけます。",
        "「知能」に対する洞察力と、人工知能に対する自分なりの哲学を育みます。",
        "現状における人工知能の限界を把握し、高い汎用的をもつ人工知能人工知能を実現するためには何が必要かを理解する。",
        "プログラミングや数式の展開は行いません。"
      ],
      "course_content": {},
      "requirements": [
        "脳科学や人工知能に興味さえあれば、前提知識は必要ありません",
        "プログラミングや数学の知識は必要ありません"
      ],
      "description": "本コースは、脳科学と人工知能をボーダーレスに学ぶ講座です。\n脳科学と人工知能の接点を学び、「知能」に対する、本質的な理解を進めましょう。\n\n\n本コースは、脳と人工知能、それぞれの概要から始まります。\nそして、脳の各部位と機能を解説した上で、人工知能の様々なアルゴリズムとの接点を解説します。\nこれにより、脳と人工知能の、類似点と相違点が明白になります。\nそして、最終的には、「意識」の謎の探求に至ります。\n\n\nシンギュラリティは、指数関数的に高度化する技術や人工知能が未来にヒトを凌駕するという概念ですが、本コースによりシンギュラリティへの洞察力が深まります。\n“ヒトと機械は、どのように共存するのか？”\nなどの、テクノロジーの未来に対する一人一人の哲学を育むことができます。\n脳科学と人工知能の接点を学び、新しい時代に適応するための新たな教養を身につけていただくことが本コースの目的です。\n\n\n————————————————————\n本コースの主な内容は以下の通りです。\n\n\n1. 脳科学と人工知能の概要\n→ コースの導入です。脳科学と人工知能、それぞれについて概要と歴史を学びます。\n\n\n2. 脳の構造\n→ 脳の各部位、および脳を構成する細胞や脳の進化の歴史を学びます。\n\n\n3. 脳における演算と記憶\n→ 脳の演算と記憶に関わる部位と、それらの仕組みについて学びます。シナプスの可塑性や神経伝達物質などについてはここで学びます。\n\n\n4. 脳と人工知能\n→ ニューラルネットワークや強化学習など、様々な人工知能のアルゴリズム、および脳と人工知能の接点について学びます。\n\n\n5. 「意識」を扱う\n→ 「意識」の謎を探求し、意識を人工的に再現できる可能性について考察します。\n\n\n6. 最後に\n→ ここまでの内容をまとめた上で、脳科学と人工知能の未来について少しだけお話しします。\n————————————————————\n\n\n本コースはプログラミングの実習はありませんのでご注意ください。内容はスライドを使った解説とセクションごとのテストにになります。\nまた、数式も扱いません。\n人工知能もしくは脳科学に興味さえあれば、どなたでも気軽に受講することができます。\n\n\n修了した方は、脳と人工知能の接点にとてつもなく大きな可能性を感じるようになるのではないでしょうか。",
      "target_audience": [
        "脳科学と人工知能の接点について知りたい方",
        "人工知能に強い関心があり、人工知能の背景にある天然の「知能」の仕組みについて知りたい方",
        "シンギュラリティを含め、人工知能の未来と自身の未来を関連づけて考えたいビジネスマン",
        "人工知能に関して、技術面以外の知識、特に生物学的側面を知りたいエンジニア",
        "素朴に、「ヒトって何？」という疑問のある方"
      ]
    },
    {
      "title": "Exploratory Data Analysis using Python",
      "url": "https://www.udemy.com/course/exploratory-data-analysis-using-python/",
      "bio": "Master the Art of Data Exploration and Visualization with Python Libraries",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic Python Knowledge – Familiarity with Python syntax, variables, loops, and functions.",
        "Understanding of Pandas and NumPy – Some experience with data manipulation using Pandas and NumPy is helpful but not mandatory.",
        "Basic Statistics Concepts – Awareness of mean, median, mode, standard deviation, and correlation will be beneficial.",
        "Jupyter Notebook or Google Colab – Students should know how to set up and use Jupyter Notebook or Google Colab for coding.",
        "Curiosity and Enthusiasm for Data Analysis – No prior data science experience is required, but a willingness to explore data is essential."
      ],
      "description": "Data is everywhere, but without proper analysis, it’s just numbers. Exploratory Data Analysis (EDA) using Python helps you uncover patterns, detect anomalies, and extract meaningful insights to make informed decisions.\nIn this course, you’ll learn to clean, analyze, and visualize data using powerful Python libraries like Pandas, NumPy, Matplotlib, and Seaborn. You’ll explore real-world datasets, handle missing values, identify outliers, and perform feature engineering to prepare data for machine learning. You’ll also understand statistical techniques such as correlation, hypothesis testing, and distributions to interpret data effectively.\nBy the end of this course, you will:\nMaster data preprocessing and cleaning techniques\nCreate compelling visualizations to explore trends\nUse statistical methods to gain deep insights\nPerform feature engineering for machine learning\nWork on hands-on projects with real-world datasets\nDevelop the ability to summarize large datasets efficiently\nGain confidence in applying EDA for data-driven decision-making\nLearn best practices for handling and transforming structured and unstructured data\nWhether you’re a beginner, student, data analyst, or developer, this course provides a solid foundation in EDA to advance your data science journey. No prior experience in data science is required—just basic Python knowledge and a curiosity to explore data!\nEnroll now and start your journey into the world of Exploratory Data Analysis with Python!",
      "target_audience": [
        "Beginners in Data Science – Anyone looking to start their journey in data analysis and machine learning.",
        "Students & Researchers – Those working on academic projects and needing strong data exploration skills.",
        "Data Analysts & Business Professionals – Individuals who want to improve their data interpretation and decision-making abilities.",
        "Software Developers – Programmers interested in expanding their skill set to data analysis and visualization.",
        "Anyone Curious About Data – No prior experience in data science is required, just a willingness to learn and explore!"
      ]
    },
    {
      "title": "ChatGPT for Healthcare: An Introductory Course",
      "url": "https://www.udemy.com/course/chatgpt-for-healthcare/",
      "bio": "Leverage this Simple Tool for Better Patient Communication, to Streamline Work, and Improve Medical Diagnosis",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "No prior experience with AI or programming is needed, but a basic understanding of healthcare and eagerness to learn is a plus!"
      ],
      "description": "Welcome to ChatGPT for Healthcare: An Introductory Course, designed to acquaint healthcare professionals with the transformative potential of ChatGPT in patient care and process optimization. In an increasingly complex healthcare environment, understanding and leveraging AI tools like ChatGPT is essential to enhance patient outcomes and streamline healthcare workflows.\nThis beginner-friendly course delves into the world of AI in healthcare, focusing on practical applications that can revolutionize your practice. You will explore various aspects of AI implementation, such as improving patient communication, simplifying insurance processes, ensuring privacy and security, assisting with disease diagnosis, and anticipating future developments in AI-powered healthcare.\nThroughout the course, you will gain insights into the following key topics:\nIntroduction to ChatGPT and its Healthcare Applications: Grasp the fundamentals of ChatGPT and learn how this AI tool can enhance patient care and streamline healthcare processes.\nEnhancing Patient Communication with ChatGPT: Discover how to use ChatGPT to foster personalized, empathetic interactions with patients, supporting patient education and engagement through AI-driven communication.\nStreamlining Insurance Handling using ChatGPT: Uncover how ChatGPT can facilitate efficient communication with insurance companies, resulting in quicker approvals, claims processing, and reimbursements. Automate insurance-related tasks to reduce administrative workload.\nPrivacy, Security, and Ethical Considerations in ChatGPT Implementation: Understand the significance of privacy and security when using ChatGPT in healthcare settings. Discuss ethical considerations and best practices to ensure responsible AI implementation.\nUtilizing ChatGPT for Disease Diagnosis Assistance: Learn how ChatGPT can aid clinicians in diagnosing diseases more accurately and efficiently, and how to integrate AI into the clinical decision-making process while maintaining professional discretion.\nPractical Tips and Future Perspectives on AI in Healthcare: Acquire practical strategies for successfully implementing ChatGPT in your healthcare practice and explore potential advancements and trends in AI technology within the healthcare sector.\nThis course is intended for educational and informational purposes only, and it should not be construed as a substitute for professional medical advice, diagnosis, or treatment. The purpose of this course is to explore the potential applications and impact of ChatGPT technology in the healthcare industry, as well as to encourage discussions about its future developments. It is not intended to provide medical or healthcare advice or to replace the professional judgment of healthcare providers.\nBy participating in this course, you acknowledge that the information provided herein is for educational purposes only. Healthcare providers and users are ultimately responsible for the decisions they make and the actions they take in utilizing ChatGPT technology.\nThis course is ideal for physicians, nurses, administrators, and healthcare students looking to familiarize themselves with AI tools and their applications in healthcare. With a focus on practical, real-world applications, this course will provide you with the essential knowledge to stay at the forefront of healthcare innovation and elevate your patient care. Join us and begin your journey towards AI-enhanced healthcare today!",
      "target_audience": [
        "This course is designed for healthcare professionals, including doctors, nurses, administrators, and students, who are interested in using AI tools like ChatGPT to improve patient care and streamline healthcare processes. No prior experience with AI or programming is required."
      ]
    },
    {
      "title": "Experto ChatGPT. Crea apps y soluciones con la API de OpenAI",
      "url": "https://www.udemy.com/course/experto-chatgpt-crea-apps-y-soluciones-digitales-con-openai/",
      "bio": "Crea GPTs personalizados, usa la API de OpenAI e integra ChatGPT con plataformas NoCode para crear soluciones avanzadas",
      "objectives": [
        "Crear y personalizar GPTs adaptados a necesidades específicas",
        "Utilizar la API de OpenAI para crear soluciones digitales sin programar",
        "Diseñar soluciones digitales multimodales con OpenAI",
        "Integrar ChatGPT con herramientas NoCode como Power Apps o Power Automate",
        "Entender conceptos clave de la inteligencia artificial generativa: prompts, tokens, modelos, etc.",
        "Integrar ChatGPT con plataformas externas para ejecutar acciones directamente desde la conversación",
        "Integrar ChatGPT con tecnología RPA como UiPath, Power Automate Desktop, etc.",
        "Crear apps integradas con ChatGPT para analizar, procesar y generar imágenes",
        "Crear apps integradas con ChatGPT para generar contenido",
        "Optimizar flujos de trabajo con GPTs que realicen acciones automatizadas"
      ],
      "course_content": {},
      "requirements": [
        "No se necesita experiencia en programación. En el curso aprenderás todo lo que necesitas saber para crear soluciones digitales y aplicaciones que adopten la tecnología de OpenAI, ya sea a través de la API, la creación de GPTs personalizados, la automatización de procesos desde ChatGPT, entre otros."
      ],
      "description": "¿Qué objetivo tiene el curso?\nEl objetivo principal de este curso es brindarte las herramientas y habilidades necesarias para crear soluciones digitales de forma sencilla y sin necesidad de programación, mediante el uso de la tecnología de ChatGPT. A lo largo del programa formativo, se te guiará paso a paso en el proceso de aprendizaje, desde una introducción a OpenAI y ChatGPT, hasta la creación de soluciones digitales funcionales e interactivas. Al finalizar el curso, estarás en capacidad de crear soluciones que utilicen inteligencia artificial generativa para mejorar la experiencia del usuario y la eficiencia de los procesos, sin necesidad de tener conocimientos avanzados de programación.\n\n\n¿Qué es ChatGPT?\nChatGPT es un modelo de inteligencia artificial desarrollado por OpenAI basado en la arquitectura GPT, diseñado para comprender y generar lenguaje humano de manera natural y precisa. Su capacidad multimodal permite no solo responder preguntas y entablar conversaciones fluidas, sino también analizar imágenes, procesar datos y realizar múltiples tareas creativas y empresariales. Más allá de su uso básico como asistente conversacional, ChatGPT se puede personalizar e integrar en diferentes plataformas para realizar acciones como automatización de tareas, generación de contenido o optimización de flujos de trabajo. Es una herramienta clave para mejorar la interacción entre humanos y máquinas en una amplia variedad de contextos.\n\n\n¿Qué es la API de OpenAI?\nLa API de OpenAI es un servicio en la nube que permite a cualquier persona integrar inteligencia artificial avanzada en sus aplicaciones. Ofrece acceso a modelos de procesamiento de lenguaje natural, visión artificial y otros modelos de inteligencia artificial de OpenAI a través de una interfaz de programación fácil de usar. La API de OpenAI facilita la construcción de aplicaciones y herramientas inteligentes que interactúan con los usuarios de manera más natural y eficiente, mejorando la experiencia del usuario y la eficiencia de los procesos.\n\n\n¿En qué va a ayudarte este curso?\nEntender conceptos de la IA generativa. La IA generativa tiene la capacidad de crear contenido nuevo y original, lo que la convierte en una tecnología indispensable para varias aplicaciones creativas y empresariales. Algunas de las ventajas clave de la inteligencia artificial generativa incluyen la capacidad de generar ideas innovadoras, ahorrar tiempo y recursos en la producción de contenido y mejorar la eficiencia en la toma de decisiones. Entenderás conceptos clave de la inteligencia artificial generativa como los prompts, los tokens, los modelos, entre otros.\nUtilizar la tecnología de ChatGPT. Aunque el acceso a ChatGPT es sencillo, no todos conocen cómo aprovechar la tecnología de OpenAI sobre la que está diseñado ChatGPT. En este curso aprenderás a utilizar la IA generativa integrándola con soluciones digitales de todo tipo. Desde aplicaciones nocode hasta robots de software, entre otras muchas más.\nCrear GPTs personalizados. Aprenderás a diseñar y configurar GPTs personalizados adaptados a tus necesidades específicas. Estos agentes de IA personalizados serán capaces de realizar acciones automatizadas, como publicar contenido directamente en plataformas como LinkedIn, responder consultas específicas dentro de un flujo de trabajo o integrarse con herramientas empresariales. Esto te permitirá optimizar tareas y mejorar la interacción entre tus sistemas y usuarios.\nIntegrar ChatGPT con herramientas externas. Descubrirás cómo conectar ChatGPT con herramientas y plataformas externas, desde CRMs y ERPs hasta sistemas de gestión personalizados. Este conocimiento te permitirá aprovechar al máximo la capacidad de ChatGPT para automatizar procesos, generar contenido y mejorar la productividad, todo desde la propia conversación de ChatGPT, mientras se conecta con las plataformas clave de tu empresa.\nCrear soluciones digitales multimodales que consuman varios modelos de OpenAI. Combinar distintos modelos de OpenAI, como generación de texto, imágenes, audio, o conversión de voz a texto en una misma solución digital. Esta integración multimodal te permitirá construir aplicaciones más versátiles y efectivas que puedan abordar una amplia variedad de casos de uso, desde asistentes interactivos hasta herramientas avanzadas de análisis y creación de contenido.\nIntegrar ChatGPT con herramientas NoCode. Conectar herramientas como Microsoft Power Apps o Microsoft Power Automate con ChatGPT para llevar al máximo nivel cualquier solución digital. Podrás crear aplicaciones que sean capaces de interactuar con cualquier modelo de OpenAI para generar texto, imágenes, audio, entre otros.\nIntegrar ChatGPT con robots de software. Diseñar robots de software que integrados con ChatGPT sean capaces de generar texto de forma masiva, o extraer información de cientos de PDFs muy extensos para resumirla en unas pocas palabras. La integración de OpenAI con tecnología RPA (automatización robótica de procesos) permite una automatización más avanzada y eficiente de tareas complejas y repetitivas. OpenAI aporta la capacidad de procesamiento de lenguaje natural y generación de texto, lo que permite una comunicación más fluida y humana entre los robots y los usuarios. Además, la inteligencia artificial de OpenAI mejora la precisión y la velocidad de los procesos automatizados, lo que se traduce en un mayor ahorro de tiempo y recursos.\nInteractuar con OpenAI desde cualquier plataforma. Publicar un servicio serverless en Azure Functions para consumir ChatGPT desde cualquier aplicación o plataforma. Entender el concepto serverless es una de las claves del curso que nos permitirá utilizar OpenAI desde cualquier lugar o herramienta sin necesidad de preocuparnos por los costes o mantenimiento de la infraestructura.\n\n\nContenido y Descripción General\nEl curso es apto para todos los niveles. Empezaremos definiendo los conceptos básicos de la inteligencia artificial generativa y entendiendo en qué puede ayudarnos ChatGPT. Aunque eso no significa que no tratemos funcionalidades avanzadas o que nos quedemos en el nivel inicial, de hecho, la dificultad irá incrementando y en los ejercicios prácticos de cada módulo iremos utilizando todo lo aprendido en las clases anteriores.\nEste programa formativo sobre la integración de ChatGPT con aplicaciones NoCode y tecnología RPA está diseñado para enseñarte a utilizar la API de OpenAI para crear aplicaciones inteligentes y automatizar procesos. Aprenderás a integrar OpenAI con herramientas NoCode como Power Apps o Power Automate para crear aplicaciones sin la necesidad de utilizar programación avanzada. Además, en el curso se incluyen varios módulos sobre cómo integrar OpenAI con tecnología RPA utilizando softwares como UiPath para una automatización más avanzada y eficiente de tareas repetitivas. Obtendrás habilidades valiosas para crear aplicaciones inteligentes personalizadas y automatizar procesos empresariales de manera más eficiente.",
      "target_audience": [
        "Interesados en diseñar aplicaciones, chatbots, robots de software u otras soluciones digitales sin necesidad de programar utilizando ChatGPT",
        "Interesados en obtener una visión global de OpenAI, la tecnología que utiliza ChatGPT, tanto a nivel conceptual como a nivel práctico",
        "Estudiantes que quieran destacar y convertirse en expertos en una habilidad cada vez más relevante en el mercado laboral",
        "Todos quienes deseen descubrir cómo ChatGPT puede llevar cualquier solución digital al máximo nivel"
      ]
    },
    {
      "title": "Ingeniería de LLM: Domina IA, Modelos de Lenguaje y Agentes",
      "url": "https://www.udemy.com/course/ingenieria-llm-ia-generativa-modelos-lenguaje-gran-escala-juan-gomila/",
      "bio": "Conviértete en un Ingeniero LLM en 8 semanas: Construye y despliega 8 aplicaciones LLM, dominando toda la IA Generativa",
      "objectives": [
        "Proyecto 1: Hacer un generador de folletos mediante IA generativa que hace scrapping y navega sitios web de la empresa de forma inteligente.",
        "Proyecto 2: Crear un agente de atención al cliente multimodal para una aerolínea con interfaz de usuario y llamadas a funciones.",
        "Proyecto 3: Desarrollar una herramienta que cree actas de reuniones y elementos de acción a partir de audio utilizando modelos de código abierto y cerrado.",
        "Proyecto 4: Crear una IA que convierta código Python a C++ optimizado, ¡aumentando el rendimiento en 60.000 veces!",
        "Proyecto 5: Construir un trabajador del conocimiento de IA que utilice RAG para convertirse en un experto en todos los asuntos relacionados con la empresa.",
        "Proyecto 6: Proyecto Final Parte A - Predecir precios de productos a partir de descripciones cortas utilizando modelos de Frontier.",
        "Proyecto 7: Proyecto Final Parte B - Ejecutar Fine-tune de los modelos de código abierto para competir con Frontier en la predicción de precios.",
        "Proyecto 8: Proyecto Final Parte C - Construir un sistema autónomo multiagente que colabore con modelos para detectar ofertas y notificarlas.",
        "Diseñar y desarrollar una solución completa a un problema empresarial dado seleccionando, entrenando y aplicando LLMs.",
        "Comparar y contrastar las últimas técnicas para mejorar el rendimiento de su solución LLM, como RAG, fine-tuning y agentic workflows",
        "Sopesar los 10 principales LLM de frontera y los 10 de código abierto, y ser capaz de seleccionar la mejor opción para una tarea determinada.",
        "Resolver problemas aplicando las principales plataformas, marcos y herramientas de código abierto, como Hugging Face, Gradio y Weights & Biases.",
        "Definir los paradigmas comunes de la IA e identificar los tipos de problemas empresariales más adecuados para cada uno de ellos.",
        "Definir los conceptos fundamentales de la ciencia de datos en torno al aprendizaje profundo, incluido el entrenamiento frente a la inferencia y generalización",
        "Describir conceptos fundamentales como la IA Generativa, los LLM y la Arquitectura Transformadora, y discutir qué se puede lograr con un rendimiento excelente",
        "Explicar cómo funcionan los LLM con suficiente detalle como para poder entrenar y probarlos, aplicarlos a nuevos escenarios y diagnosticar y resolver problemas",
        "Implementar soluciones LLM en Python utilizando modelos de frontera y de código abierto tanto con API como con inferencia directa.",
        "Ejecutar código para escribir documentos, responder preguntas y generar imágenes."
      ],
      "course_content": {},
      "requirements": [
        "Familiaridad con Python. Este curso no cubre los fundamentos de Python y se programa completamente en Python."
      ],
      "description": "Domina la IA Generativa y los LLMs: Un Viaje Práctico de 8 Semanas\nAcelera tu carrera en Inteligencia Artificial con proyectos prácticos y reales, liderados por el experto de la industria Juan Gabriel Gomila. Aprende a construir productos avanzados de IA generativa, experimenta con más de 20 modelos innovadores y domina técnicas de vanguardia como RAG, QLoRA, y Agentes.\n\n\n¿Por qué elegir este curso?\n- Aprendizaje práctico: Construye aplicaciones reales con ejercicios guiados paso a paso.\n- Técnicas de vanguardia: Aprende marcos como Hugging Face, LangChain, y Gradio, y domina las últimas innovaciones.\n- Sin matemáticas avanzadas: Enfócate en la implementación práctica sin necesidad de cálculo o álgebra lineal.\n- Proyectos reales: Aplica lo aprendido en soluciones prácticas que abren puertas en el mercado laboral.\n\n\nLo que aprenderás:\nCrear productos avanzados de IA generativa con herramientas líderes del sector.\nExperimentar con modelos Frontier y de código abierto.\nImplementar técnicas innovadoras como RAG, ajuste fino con QLoRA, y agentes autónomos.\nConstruir aplicaciones del mundo real, incluyendo:\nUn asistente multimodal para atención al cliente.\nUn sistema de predicción de precios para comercio electrónico.\nUna herramienta para optimizar código con rendimientos mejorados 60,000 veces.\n\n\nEstructura del curso (8 semanas)\nSemana 1: Fundamentos y Primeros Proyectos\nIntroducción a los Transformers y seis modelos Frontier líderes.\nCreación de un generador de folletos inteligente que rastrea la web.\nSemana 2: APIs y Chatbots de Atención al Cliente\nDesarrollo de un chatbot multimodal con texto, imágenes y audio.\nSemana 3: Modelos de Código Abierto\nExploración de Hugging Face y construcción de una herramienta para generar actas de reuniones.\nSemana 4: Generación de Código\nUso de LLMs para traducir código Python a C++ con mejoras de rendimiento extremas.\nSemana 5: Generación Mejorada por Recuperación (RAG)\nImplementación de RAG y vectores en soluciones empresariales avanzadas.\nSemana 6: Transición al Entrenamiento\nAfinar un modelo Frontier para resolver problemas empresariales reales.\nSemana 7: Técnicas Avanzadas de Entrenamiento\nAjuste fino con QLoRA y entrenamiento de modelos personalizados.\nSemana 8: Implementación y Finalización\nLanzamiento de productos con interfaces pulidas y capacidades avanzadas.\n\n\nProyectos destacados:\nGenerador de folletos inteligentes que navega por sitios web.\nAsistente multimodal para aerolíneas con funciones de texto, audio e imágenes.\nActas de reuniones y elementos de acción a partir de grabaciones de audio.\nTraductor de código Python a C++ con rendimiento optimizado.\nAsistente basado en RAG que actúa como un experto en temas empresariales.\nPredicción de precios utilizando modelos Frontier y de código abierto.\nSistema de agente autónomo para detectar ofertas especiales en tiempo real.\n\n\nSobre el instructor:\nJuan Gabriel Gomila es un líder en educación de IA con más de 12 años de experiencia. Como emprendedor y cofundador de una plataforma educativa, ha ayudado a miles de estudiantes y equipos en startups globales a dominar la tecnología y la IA.\nLleva tus habilidades de IA al siguiente nivel y prepárate para liderar en el emocionante mundo de la inteligencia artificial. ¡Comienza tu viaje ahora!",
      "target_audience": [
        "Ingenieros de IA y científicos de datos aspirantes ansiosos por ingresar al campo de la IA generativa y los LLM.",
        "Profesionales que buscan mejorar sus habilidades y mantenerse competitivos en el panorama de la IA en rápida evolución.",
        "Desarrolladores interesados en crear aplicaciones de IA avanzadas con experiencia práctica."
      ]
    },
    {
      "title": "【한글자막】 비즈니스 분석 및 Data Science 를 위한 핵심 통계학 A-Z™",
      "url": "https://www.udemy.com/course/best-business-analysis/",
      "bio": "데이터 과학자나 비즈니스 분석가에게 필요한 통계 수학 수업으로, 정규 분포, 표준 편차, 연속변수, 중심 극한 정리, 가설검정, Z 점수, T 점수, 통계적 유의성, 신뢰 구간 등에 대해 배웁니다.",
      "objectives": [
        "정규 분포에 대한 이해",
        "표준 편차에 대한 이해",
        "연속변수와 불연속변수의 차이",
        "표본 분포에 대한 이해",
        "중심 극한 정리에 대한 이해",
        "실무에서 중심 극한 정리 적용",
        "가설검정에 평균 적용",
        "가설검정에 비율 적용",
        "Z 점수와 Z 테이블 사용",
        "T 점수와 T 테이블 사용",
        "정규 분포와 T 분포의 차이",
        "통계적 유의성에 대한 이해와 적용",
        "신뢰구간 생성",
        "p값 남용의 잠재적 함정"
      ],
      "course_content": {},
      "requirements": [
        "기초 수준의 고등학교 수학 지식"
      ],
      "description": "데이터 사이언스를 위한 통계학 강의!\n실생활 비즈니스 과제를 통한 실용적인 강의!\n분포, Z검정, 중심 극한 정리, 가설 검정, 신뢰구간, 통계적 유의성 등의 내용 포함!\n\n\n비즈니스 분석 및 Data Science 를 위한 핵심 통계학 A-Z™ 강의를 선택해야 하는 이유\n데이터 과학자나 비즈니스 분석가로 일하고 싶다면 통계적 기술을 복습하셔야 합니다. 하지만 시작하는 게 어렵죠. 통계학을 전부 학습 및 복습 하는 것은 너무 벅찹니다.\n\n\n이 강의에서 여러분은 Data Science나 분석을 위한 핵심 통계학 지식을 완전히 익힐 수 있습니다.\n\n\n이 강의는 그냥 지루한 통계학 강의가 아닙니다.\n\n\n아주 실용적인 강의죠.\n\n\n제가 특별히 여러분의 커리어를 향상시키기 위한 실생활에서의 비즈니스 과제를 준비했고\n이 과제에 여러분의 지식을 어떻게 적용해볼 수 있는지 보여드릴 겁니다.\n\n\n동시에 여러분은 분포, Z 검정, 중심 극한 정리, 가설 검정, 신뢰구간, 통계적 유의성 , 그리고 그 이상을 통달하시게 될 겁니다!\n\n\n비즈니스 분석 및 Data Science 를 위한 핵심 통계학 A-Z™ 강의는 이렇게 진행됩니다\n정규 분포에 대한 이해\n표준 편차에 대한 이해\n연속변수와 불연속변수의 차이\n표본 분포에 대한 이해\n중심 극한 정리에 대한 이해\n실무에서 중심 극한 정리 적용\n가설검정에 평균 적용\n가설검정에 비율 적용\nZ 점수와 Z 테이블 사용\nT 점수와 T 테이블 사용\n정규 분포와 T 분포의 차이\n통계적 유의성에 대한 이해와 적용\n신뢰구간 생성\np값 남용의 잠재적 함정\n\n\n\n\n물리학 및 수학과 데이터 과학 강사 Kirill Eremenko의 한마디!\n한국 수강생 여러분들 안녕하세요?\n\n\n데이터 과학자나 비즈니스 분석가로 일하고 싶다면 통계적 기술을 복습하셔야 합니다. 하지만 시작하는 게 어렵죠. 통계학을 전부 학습 및 복습 하는 것은 너무 벅찹니다.\n\n\n그래서 제가 이 강의를 개설한 겁니다!\n\n\n이 강의는 비즈니스 분석을 위해 통계학을 익히고자 하는 모든 사람, 통계학을 처음부터 배우고자 하는 모든 사람, 그리고 통계학에 대한 직접적인 경험을 쌓고자 하는 모든 사람을 위한 강의입니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n망설이지 마세요!\n\n\n지금 등록하고 여러분의 커리어를 한 단계 더 업그레이드 시키세요\n강의에서 만나요!\n\n\n-Kirill",
      "target_audience": [
        "비즈니스 분석을 위해 통계학을 익히고자 하는 모든 사람",
        "통계학을 처음부터 배우고자 하는 모든 사람",
        "통계학에 대한 직접적인 경험을 쌓고자 하는 모든 사람"
      ]
    },
    {
      "title": "Modern Data Scientist",
      "url": "https://www.udemy.com/course/modern-data-scientist/",
      "bio": "What the industry needs?",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Machine Learning concepts"
      ],
      "description": "These days, you find thousands of job openings for the position of a Data Scientist. The AI and machine learning has surely taken this world by storm. Though AI was invented several decades ago, we started seeing its practical usefulness in just last few years. With applications as simple as predicting house prices to sophisticated ones like person detections in real time videos for surveillance, real time traffic monitoring and those based on textual data like ratings the hotels on the basis of their past customer reviews to areas like topic modeling, real time language translations and so on. As the requirements evolved so did the technology of machine learning. Earlier, the statistical based techniques were used for predictions, recommendations etc. These were purely mathematical and statistical implemented in languages like Python, C++, Java and others. Amongst this, Python is the most widely accepted language for machine learning. The earlier Data Science was based on numeric data that is abundantly available in the industry. The business people wanted a data scientist to analyze such numeric data to give better insights into their business, customers and provide them future directions for growth.\nWith the introductions of artificial neural networks, the whole game has now changed. The data scientists are now expected to develop machine learning models based on ANN. As a matter of fact, ANN has solved many AI problems which were impossible to solve using the classical ML. Also, the industry came up with the requirement of model development based on new data types - that is image and text data. The size of such datasets goes probably millions of time more than than the traditional datasets which we used as a part of relational and non-relational databases. With these new datatypes, the new challenges came up in processing them and developing the models with the available resources. Though we see a huge surge in the availability of processing resources, these still are inadequate in developing models on datasets of peta byte sizes.\nIn this two lecture course, the first lecture defines the role of a traditional data scientist and the new role of a machine learning engineer. In the second lecture, I go deeper to explain you what the industry is asking for, what are the exceptions out of a modern data scientist.\nThis free course would surely help you in planning your career as a Modern Data Scientist. I look forward to you joining this course and gain lots of knowledge in this emerging AI.",
      "target_audience": [
        "Data Scientists, ML Engineers, Science/Engineering students/graduates, Academic"
      ]
    },
    {
      "title": "【한글자막】 랭체인 - LangChain 으로 LLM 기반 애플리케이션 개발하기",
      "url": "https://www.udemy.com/course/langchain-korean/",
      "bio": "실제 생성형 인공지능 LLM 기반 애플리케이션을 빠르게 구축해보면서 LangChain을 배우세요. (Python, 최신 버전 0.3.0)",
      "objectives": [
        "랭체인에 능숙해지기",
        "랭체인 기반 생성 AI 애플리케이션을 처음부터 끝까지 다루기",
        "프롬프트 엔지니어링 이론 : 생각의 사슬, ReAct, Few Shot 프롬프트, 랭체인이 내부적으로 어떻게 구축되는지 이해하기",
        "랭체인 오픈 소스 코드베이스 내부를 탐색하는 방법 이해하기",
        "소프트웨어 엔지니어를 위한 대규모 언어 모델 이론",
        "랭체인: 수많은 체인, 에이전트, DocumentLoader, TextSplitter, OutputParser, 메모리",
        "RAG, 벡터 저장소/벡터 데이터베이스 (Pinecone, FAISS)"
      ],
      "course_content": {
        "과정 소개": [
          "강의 소개",
          "강의 개요 + 유데미 최대 활용법 [이 강의를 스킵하지 마세요!]",
          "강의의 목표",
          "강의 전용 커뮤니티",
          "강의 자료"
        ],
        "랭체인의 핵심 - \"Hello World\" 체인으로 시작하기": [
          "랭체인이란? 6분만에 랭체인 이해하기",
          "프로젝트 셋업하기 (Pycharm) - 권장",
          "프로젝트 셋업하기 (VS Code) - 선택 사항",
          "환경 변수 및 .env 파일",
          "첫 랭체인 애플리케이션 - 체인으로 간단한 프롬프트 연결하기",
          "LangChain과 함께 오픈 소스 모델 사용하기(Ollama, Llama3, Mistral)",
          "강의에서 사용하는 랭체인 버전 (V0.3.3) - (No breaking changes in 0.3.3)",
          "퀵 체크인"
        ],
        "Ice Breaker - 실생활에서의 생성형 AI 에이전트 애플리케이션": [
          "도입 - 이 섹션에서는 무엇을 만들게 되나요?",
          "Linkedin 데이터 프로세싱 통합하기 1부 - Scraping",
          "Linkedin 데이터 프로세싱 통합하기 1부 - Scraping",
          "Linkedin 데이터 프로세싱 2부 - 에이전트 이론",
          "Linkedin 데이터 프로세싱 3부: 툴, Agent Executor, create_react_agent",
          "Linkedin 데이터 프로세싱 4부: 사용자 서치 에이전트 구현",
          "링크드인 데이터 처리 - 5부: 사용자 지정 검색 에이전트 테스트",
          "[선택 사항] Twitter 데이터 프로세싱 1부- Scraping",
          "[선택 사항] Twitter 데이터 프로세싱 2부- 에이전트",
          "아웃풋 파서 (Output Parsers) - 프론트엔드 작업 준비하기",
          "FullsStack 앱 - LangChain FullStack 애플리케이션 기반 LLM 구축",
          "LangSmith를 사용한 애플리케이션 추적"
        ],
        "ReAct 에이전트의 특별한 기능 자세히 알아보기": [
          "ReAct AgentExecutor를 처음부터 만들어보기",
          "환경 설정 + ReAct 알고리즘 개요",
          "ReAct 에이전트를 위한 도구 정의",
          "ReAct 프롬프트, LLM 추론 엔진, 출력 구문 분석 및 도구 실행",
          "AgentAction, AgentFinish, ReAct 루프",
          "CallbackHandlers, ReAct 프롬프트 및 ReAct 에이전트 루프 마무리하기",
          "LangSmith 요약"
        ],
        "RAG의 핵심 - 임베딩, 벡터 데이터베이스,Retrieval": [
          "Medium Analyzer - 보일러플레이트로 프로젝트 셋업하기",
          "Medium Analyzer - 클래스 리뷰: TextLoader,TextSplitter,OpenAIEmbeddings,Pinecone",
          "Medium Analyzer - Ingestion 구현하기",
          "Medium Analyzer- 체인을 사용한 Retrieval 구현",
          "Medium Analyzer- LCEL을 사용한 Retrieval 구현",
          "FAISS 로컬 벡터스토어를 이용해 PDF랑 대화 나누기"
        ],
        "다큐멘테이션 어시스턴트 구축하기 (임베딩, VectorDB, RetrievalQA, 메모리)": [
          "이 섹션에서는 무엇을 만들게 되나요?",
          "환경 셋업",
          "[New] Ingestion Pipeline Intro",
          "[New] Imports",
          "[New] Tavily Crawling",
          "[New, Optional] TavilyMap, TavilyExtract for High customizability",
          "[New, Optional] Crawling Deep Dive",
          "[New] Recap",
          "[NEW] Chunking (Text Splitting)",
          "[New] Batch Indexing",
          "Retrieval (검색) + Augmentation (증강) + Generation (생성) = RAG",
          "AI LangChain 채팅 어시스턴트 구축- Streamlit과 “프론트엔드” (UI)",
          "LangChain 채팅 어시스턴트 구축- 메모리",
          "UI 개선을 위해 Cursor IDE 활용하기",
          "Cursor 란 무엇인가요?",
          "Cursor 컴포저로 사이드바 및 LangChain의 색상 테마 추가하기"
        ],
        "슬림한 버전의 ChatGPT 코드 인터프리터 구축하기 (고급 에이전트, OpenAI 함수)": [
          "이 섹션에서는 무엇을 만들게 되나요? ((GPT 코드 인터프리터의 슬림 버전))",
          "프로젝트 셋업하기",
          "파이썬 에이전트",
          "CSV 에이전트",
          "모든 것을 종합하기: 라우터 에이전트",
          "랭체인에서의 Function / Tool Calling",
          "Function Calling vs ReAct"
        ],
        "랭체인 이론": [
          "랭체인 토큰 한도 처리 전략",
          "[신규] 랭체인 Co Refrence Resolution",
          "[신규] 랭체인 메모리 이론 심층분석 (LangGraph)"
        ],
        "프롬프트 엔지니어링 이론": [
          "LLM의 핵심",
          "프롬프트란 무엇인가? 공식적인 프롬프트의 구성",
          "Zero Shot 프롬프트",
          "Few Shot 프롬프트",
          "생각의 사슬 프롬프팅",
          "ReAct",
          "프롬프트 엔지니어링 꿀팁"
        ],
        "문제 해결 섹션": [
          "기술적 문제가 있으신가요? 먼저 이 동영상을 시청하세요. 도움이 될 것입니다.",
          "트윗 API- tweepy.errors.Forbidden: 403 Forbidden 에러",
          "Pinecone: AttributeError: init은 더 이상 핀콘의 최상위 어트리뷰트가 아닙니다.",
          "강의에서 사용하는 LangChain 버전 (V0.3.3)"
        ]
      },
      "requirements": [
        "이 코스는 초급 과정이 아닙니다. 기본적인 소프트웨어 엔지니어링 개념이 필요합니다.",
        "Git, 파이썬, pipeenv, 환경 변수, 클래스, 테스트, 디버깅과 같은 소프트웨어 엔지니어링 과목에 익숙해야 합니다.",
        "머신 러닝 경험은 없어도 됩니다."
      ],
      "description": "이 강의는 유데미 강좌 중 \"LangChain- Develop LLM powered applications with LangChain\"와 동일한 강의이며, 한국어 자막이 기존 강의와 다르게 전문 한글 자막이 제공됩니다. 또한 강의 내용에 대한 질문은 Q&A에 영어로 남겨주시면 오리지널 강사님으로부터 답변을 받으실 수 있습니다. 강의 내용 외의 문의는 한국어로 남겨주셔도 되며, 웅진씽크빅 글로벌에서 매일 확인하여 답변드리고 있으니 편하게 질문해주세요! :)\n\n\n* 강의 최신 버전으로 재녹화\n* LangChain 버전 0.3.0 기반\n\n\n유데미에서 처음 만나는 랭체인 코스 - LLM 의 위력을 경험하기 에 오신 것을 환영합니다!\n이 강의에서는 LLM 애플리케이션을 위해 랭체인 라이브러리를 매우 빠르게, 100% 활용하는 방법을 배울 수 있습니다.\n이 강의에서는 다양한 분야에서 최첨단 LLM 솔루션을 개발하는 데 필요한 기술과 지식을 배울 수 있어요!\n\n\n이 강의는 초보자용이 아닙니다. 소프트웨어 엔지니어링에 대한 배경 지식이 있고 Python에 능숙한 분들을 대상으로 합니다. 저는 Pycharm IDE를 사용하지만, 디버깅 및 스크립트 실행과 같은 IDE의 기본 기능만 사용하므로 여러분이 원하는 편집기를 사용할 수 있습니다.\n\n\n이 강의에서는 랭체인을 사용하여 실제 LLM 기반 애플리케이션을 구축하는 과정을 처음부터 같이 합니다.\n이를 위해 3가지 주요 애플리케이션을 빌드할 것입니다:\n\n\nIce Breaker - 이름을 부여하고, 구글에서 검색하여 링크드인 및 트위터 프로필을 찾고, 제공한 이름에 대한 정보를 인터넷에서 스크랩하고, 그 사람과 대화를 시작할 수 있는 몇 가지 개인화된 Ice Breaker를 생성하는 LangChain 에이전트입니다.\nDocumentation Helper - 파이썬 패키지 문서 위에 챗봇을 만듭니다. (그리고 원하는 다른 모든 데이터 위에 사용 가능)\nChatGPT 코드 통역기의 슬림한 버전\n프롬프트 엔지니어링 이론 섹션\n\n\n\n\n이 강의에서 다루는 주제는 다음과 같습니다:\n랭체인\nLLM + GenAI 역사\nLLM: Few shots 프롬프팅, 생각의 사슬, ReAct 프롬프팅\n채팅 모델\n오픈 소스 모델\n프롬프트, 프롬프트 템플릿, langchainub\n출력 파서 (Output Parsers), Pydantic 출력 파서\n체인: create_retrieval_chain, create_stuff_documents_chain\n에이전트, 사용자 정의 에이전트, 파이썬 에이전트, CSV 에이전트, 에이전트 라우터\nOpenAI 함수, 도구 호출\n도구, 툴킷\n메모리\n벡터스토어(Pinecone, FAISS)\nRAG(검색 증강 생성)\n문서 로더, 텍스트 스플리터\nStreamlit(UI용)\nLCEL\nLangSmith\nLangGraph 소개\nFireCrawl\nCursor IDE 의 핵심\nCursor Composter\nCurser Chat\n\n\n이 강의에서는 실습을 하면서 실제 프로젝트를 통해 다루는 개념과 기술을 확실히 이해할 수 있어요. 이 강의를 다 배우면 랭체인을 사용하여 다양한 곳에 사용할 수 있는 강력하고 효율적이며 활용 가능한 LLM 애플리케이션을 만드는 데 능숙해질 거예요!\n\n\n이 코스는 단순한 강의 코스가 아니라 커뮤니티이기도 해요.  이 코스는 평생 무제한으로 들을 수 있고, 다음과 같은 혜택도 있어요:\n제가 1:1 전담으로 문제를 해결하도록 도와드립니다\n추가 AI 리소스, FAQ, 문제 해결 가이드가 있는 Github 링크를 드려요\n다른 학습자(1000명 이상)와 소통할 수 있는 전용 디스코드 커뮤니티에 들어오실 수 있어요\n추가 비용 없이 지속적으로 코스를 업데이트합니다\n\n\n(다시 한번 강조)\n이 강의는 초보자용이 아닙니다. 소프트웨어 엔지니어링에 대한 배경 지식이 있고 Python에 능숙한 분들을 대상으로 합니다. 저는 Pycharm IDE를 사용하지만, 디버깅 및 스크립트 실행과 같은 IDE의 기본 기능만 사용하므로 여러분이 원하는 편집기를 사용할 수 있습니다.\n이 강의의 첫 번째 프로젝트(아이스 브레이커)에서는 일반적으로 유료 서비스인 ProxyURL, SerpAPI, 트위터 API 등의 타사 API를 사용해야 합니다. 이러한 모든 타사에는 stub responses 개발 및 테스트에 사용할 수 있는 무료 티어가 있습니다.",
      "target_audience": [
        "랭체인으로 생성 AI 기반 애플리케이션을 구축하는 방법을 배우고 싶은 소프트웨어 엔지니어",
        "랭체인으로 생성 AI 기반 애플리케이션을 구축하는 방법을 배우고 싶은 개발자",
        "랭체인으로 생성 AI 기반 애플리케이션을 구축하는 방법을 배우고 싶은 엔지니어"
      ]
    },
    {
      "title": "Inteligência Artificial Para Todos com Excel",
      "url": "https://www.udemy.com/course/inteligencia-artificial-com-excel/",
      "bio": "Conheça técnicas de Inteligência Artificial e Ciência de Dados usando Excel",
      "objectives": [
        "Aprenda a fazer previsões futuras usando dados",
        "Veja técnicas para maximizar o lucro da empresa",
        "Entenda funcionalidades para avaliar clientes",
        "Avalie riscos e se vale a pena corre-los",
        "Encontre clientes ou fornecedores duplicados",
        "Avalie se o que custa mais é de fato melhor",
        "Aprenda a criar sistemas de recomendação de vendas",
        "Veja como prever as vendas a partir do investimento em marketing"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Introdução",
          "Material para Download"
        ],
        "Preparando o Excel": [
          "Preparando o Excel para o Curso",
          "Instalando Fuzzy Lookup",
          "Instalando Outros Suplementos"
        ],
        "Aumentando a lucratividade com Programação Genética": [
          "Conhecendo a Anova Airlines",
          "Introdução: Apresentando o problema",
          "Conhecendo Algoritmos Genéticos",
          "Conhecendo o Solver no Excel",
          "Explicando a Solução do Problema",
          "Implementando a Solução no Excel",
          "Implementando a Solução no Excel (Continuação)",
          "Aumentando a lucratividade com Programação Genética"
        ],
        "Prevendo as vendas a partir de investimento em anúncios com Regressão": [
          "Voltando a Anova Airlines",
          "Introdução: Apresentando o problema",
          "Introdução: Apresentando o problema (Continuação)",
          "Explicando a Solução do Problema: Regressão no Excel",
          "Implementando a Solução no Excel"
        ],
        "Entendendo e projetando o desempenho do seu negócio com Séries Temporais": [
          "Mais um dia na Anova Airlines",
          "Introdução: Apresentando o problema",
          "Introdução: Apresentando o problema (Continuação)",
          "Considerações sobre Previsões",
          "Entendendo Suavização Exponencial",
          "Entendendo Suavização Exponencial (Continuação)",
          "Implementando Suavização Exponencial no Excel"
        ],
        "Avaliando seus clientes com Machine Learning": [
          "Mais um dia na Anova Airlines",
          "Introdução: Apresentando o problema",
          "Entendendo o Algoritmo do Vizinho mais Próximo",
          "Implementando o Vizinho mais próximo no Excel",
          "Implementando o Vizinho mais próximo no Excel (Continuação)",
          "Avaliando seus clientes com Machine Learning"
        ],
        "Avaliando riscos de quebra de equipamentos com Distribuição de Poisson": [
          "Voltando a Anova Airlines",
          "Introdução: Apresentando o problema",
          "Distribuição de Poisson no Excel"
        ],
        "Buscando indícios de fraudes contábeis com Lei de Benford": [
          "Mais um dia na Anova Airlines",
          "Introdução: Apresentando o problema",
          "Introdução: Apresentando o problema (Continuação)",
          "Lei de Benford no Excel",
          "Implementando a Lei de Benford no Excel",
          "Implementando a Lei de Benford no Excel (Continuação)"
        ],
        "Encontrando pagamentos duplicados com Fuzzy Lookup": [
          "Voltando a Anova Airlines",
          "Introdução: Apresentando o problema",
          "Fuzzy Lookup no Excel",
          "Implementando Fuzzy Lookup no Excel"
        ],
        "Avaliando se os produtos mais caros são os melhores com Anova e Teste t": [
          "Novamente na Anova Airlines",
          "Introdução: Apresentando o problema",
          "Implementando Anova no Excel"
        ]
      },
      "requirements": [
        "Conhecimentos intermediários de Excel",
        "Computador com Excel 2016 ou Excel (Office) 365 - Um dos suplementos não funciona em Mac!"
      ],
      "description": "Este curso é para você que quer aprender Ciência de Dados usando um dos softwares mais utilizados do mundo: Excel!\nDurante o curso, você vai acompanhar o dia a dia de uma empresa área fictícia, a Anova Airlines, e ver como diversos problemas da empresa podem ser resolvidos usando técnicas de Ciência de Dados e Excel.\nOs problemas apresentados são:\nAumentando a lucratividade com Programação Genética. A programação genética é inspirada na evolução dos seres vivos e o processo de seleção natural.\nPrevendo as vendas a partir de investimento em anúncios com Regressão. Ou seja, se você investiu X vendeu Y. Porém se investir 2x, quanto vai vender?\nEntendendo e projetando o desempenho do seu negócio com Séries Temporais. Séries temporais são capazes de detectar tendências e efeitos sazonais. Por exemplo, vendas de casacos no inverno.\nAvaliando seus clientes com Machine Learning. Machine Learning é a mais importante técnica de Inteligência Artificial.\nAvaliando riscos de quebra de equipamentos com Distribuição de Poisson\nBuscando indícios de fraudes contábeis com Lei de Benford. A Lei de Benford é capaz de encontrar anomalias em dados que foram produzidos de forma natural.\nEncontrando pagamentos duplicados com Fuzzy Lookup\nAvaliando se os produtos mais caros são os melhores com Anova e Teste t\nSegmentando clientes para campanhas com Clusters\nPotencializando vendas com Sistemas de Recomendação\nCada módulo, além da explicação do problema, apresenta uma explicação prática sobre a técnica, além da implementação do projeto passo a passo no Excel\nVocê ainda pode baixar na plataforma do curso as planilhas de exemplos e os slides das aulas.\nVocê vai instalar alguns suplementos no seu Excel durante o curso, mas eles são gratuitos e seguros (produzidos pela própria Microsoft)",
      "target_audience": [
        "Interessados em conhecer técnicas de Ciência de Dados e Inteligência Artificial"
      ]
    },
    {
      "title": "Reconhecimento de Textos com OCR e Python",
      "url": "https://www.udemy.com/course/reconhecimento-de-textos-com-ocr-e-python/",
      "bio": "OpenCV, Tesseract, EasyOCR e EAST aplicado em imagens e vídeos! Crie seu próprio OCR do zero com Deep Learning!",
      "objectives": [
        "Utilizar as ferramentas Tesseract, EAST e EasyOCR para reconhecimento de caracteres",
        "Entender as diferenças entre o OCR em ambientes controlados e ambientes naturais",
        "Aplicar técnicas de pré-processamento de imagens para melhorar a qualidade das imagens, tais como: limiarização, inversão, redimensionamento, operações morfológicas e redução de ruído",
        "Utilizar a estrutura EAST aplicado em reconhecimento em cenários naturais",
        "Treinar um OCR do zero utilizando Deep Learning e Redes Neurais Convolucionais",
        "Reconhecer textos em imagens e vídeos",
        "Buscar termos específicos em imagens de um diretório",
        "Preparar imagens escaneadas para o reconhecimento de textos",
        "Tratar imagens de carros para a identificação de placas"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Visão Computacional",
          "Introdução à OCR",
          "Recursos para download"
        ],
        "OCR com Tesseract": [
          "Introdução ao Tesseract",
          "Preparação do ambiente",
          "Primeiro reconhecimento de texto",
          "Suporte para outros idiomas",
          "Resolvendo problema relacionado ao pacote de idiomas",
          "Modo de segmentação de página (PSM)",
          "Detecção de orientação da página",
          "Seleção dos textos 1",
          "Seleção dos textos 2",
          "Seleção dos textos 3",
          "Busca com expressões regulares",
          "Detecção em cenários naturais"
        ],
        "Técnicas para pré-processamento de imagens": [
          "Escala de cinza",
          "Limiarização - teoria",
          "Limiarização simples",
          "Limiarização com Método de Otsu",
          "Limiarização adaptativa",
          "Limiarização adaptativa gaussiana",
          "Inversão de cores",
          "Redimensionamento - teoria",
          "Redimensionamento - implementação",
          "Operações morfológicas - teoria",
          "Operações morfológicas - implementação",
          "Remoção de ruído - teoria",
          "Remoção de ruído - implementação",
          "Reconhecimento de textos",
          "EXERCÍCIO",
          "Solução o exercício"
        ],
        "OCR com EAST para cenários naturais": [
          "EAST - introdução",
          "Processamento da imagem",
          "Carregamento da rede neural",
          "Decodificação dos resultados 1",
          "Decodificação dos resultados 2",
          "Detecção e reconhecimento dos textos"
        ],
        "Treinamento de OCR personalizado": [
          "Importação das bibliotecas",
          "Base de dados MNIST 0-9",
          "Base de dados Kaggle A-Z",
          "Junção das bases de dados",
          "Pré-processamento dos dados",
          "Construção da rede neural",
          "Treinamento da rede neural",
          "Avaliação da rede neural",
          "Salvar a rede neural",
          "Testes com imagens",
          "Preparação do ambiente",
          "Pré-processamento da imagem",
          "Detecção de contornos",
          "Processamento das detecções 1",
          "Processamento das detecções 2",
          "Reconhecimento dos caracteres",
          "Problema do 0 e O, 1 e l, 5 e S",
          "Problema do texto não detectado"
        ],
        "Cenários naturais com EasyOCR": [
          "Aviso sobre atualização da biblioteca",
          "Configuração do ambiente",
          "Reconhecimento de textos",
          "Escrita dos resultados na imagem",
          "Outros idiomas - francês e chinês",
          "Reconhecimento em texto com fundo"
        ],
        "OCR em vídeos": [
          "Preparação do ambiente",
          "Configuração do vídeo",
          "Processamento do vídeo",
          "OCR com EAST e Tesseract",
          "OCR com EasyOCR"
        ],
        "Projeto 1: Busca por termos específicos": [
          "Preparação do ambiente",
          "Reconhecimento dos textos",
          "Busca por ocorrências",
          "Nuvem de palavras",
          "Extração de entidades nomeadas",
          "Busca por ocorrências na imagem",
          "Caracteres maiúsculos e minúsculos",
          "Salvando os resultados"
        ],
        "Projeto 2: Scanner de documento + OCR": [
          "Preparação do ambiente",
          "Detecção de contornos",
          "Transformação de perspectiva",
          "OCR com Tesseract",
          "Melhoria na qualidade da imagem",
          "Unindo as funções"
        ],
        "Projeto 3: Leitura de placas de carros": [
          "Preparação do ambiente",
          "Tratamento da imagem",
          "Reconhecimento do texto",
          "Melhoria na qualidade da imagem"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Programação básica em Python"
      ],
      "description": "Dentro da área da Visão Computacional existe a sub-área de Reconhecimento Ótico de Caracteres (ou OCR - Optical Character Recognition) que basicamente visa transformar imagens em textos. Em outras palavras, o OCR pode ser descrito como a conversão de imagens contendo texto digitado, escrito a mão ou impresso, em caracteres que uma máquina é capaz de entender. A imagem em questão pode ser um documento escaneado ou fotografado, na qual o texto é o principal objeto de interesse. Outro exemplo são imagens menos direcionadas, como uma fotografia de um cenário onde aparecem placas e fachadas.\nPor meio do OCR, é possível converter documentos escaneados ou fotografados em textos que podem ser editados em qualquer ferramenta, como o Microsoft Word por exemplo. Outro exemplo de aplicação são os leitores automáticos de formulários, nos quais você pode enviar uma foto da sua CNH (carteira nacional de habilitação), RG (registro geral) ou cartão de crédito e o sistema consegue fazer a leitura de todos os seus dados. Um carro autônomo pode utilizar OCR para ler as placas de trânsito e um condomínio pode ler a placa do carro, verificar se consta na base de dados para então liberar o acesso ao pátio! Existe uma infinidade de aplicações que podem ser desenvolvidas!\nE para levar você até essa área, neste curso você aprenderá na prática como utilizar várias bibliotecas de OCR para reconhecer textos em imagens e vídeos, tudo passo a passo e utilizando a linguagem Python! Vamos utilizar o Google Colab, ou seja, você não precisa se preocupar com instalações e configurações de bibliotecas em sua máquina, pois tudo será desenvolvido on-line utilizando as GPUs do Google! Além de utilizar ferramentas prontas, você também aprenderá como construir o seu próprio OCR do zero utilizando Deep Learning e Redes Neurais Convolucionais! Confira abaixo os principais tópicos que você aprenderá:\nReconhecimento de textos em imagens e vídeos com Tesseract, EasyOCR e EAST\nBusca em imagens utilizando expressões regulares\nTécnicas para melhoria da qualidade das imagens, bem como: limiarização, inversão, escala de cinza, redimensionamento, remoção de ruídos e operações morfológicas\nUso da arquitetura EAST e da biblioteca EasyOCR para melhor desempenho em cenários naturais\nTreinamento de um OCR do zero utilizando TensorFlow e modernas técnicas de Deep Learning com Redes Neurais Convolucionais\nBusca por ocorrências de textos em imagens\nAplicação de técnicas de processamento de linguagem natural nos textos extraídos pelo OCR (nuvem de palavras e extração de entidades nomeadas)\nComo preparar imagens vindas de fotos e scanners\nPré-processamento de imagens para extração e reconhecimento de placas de carros\nEsses são somente alguns dos tópicos principais, e ao final do curso, você saberá tudo o que precisa para criar seus próprios projetos de reconhecimento de textos utilizando OCR!",
      "target_audience": [
        "Pessoas interessadas em OCR (Optical Character Recognition - Reconhecimento Ótico de Caracteres)",
        "Alunos de graduação e pós-graduação que cursam disciplinas de Computação Gráfica, Processamento Digital de Imagens ou Inteligência Artificial",
        "Cientistas de Dados que queiram aumentar seus conhecimentos em Visão Computacional",
        "Profissionais interessados em desenvolver soluções profissionais de reconhecimento ótico de caracteres",
        "Pessoas interessadas em criar o seu próprio OCR personalizado"
      ]
    },
    {
      "title": "OpenAI com Python: GPT, DALL-E, Whisper, TTS e mais",
      "url": "https://www.udemy.com/course/chatgpt-dall-e-python-gpt-3/",
      "bio": "Aprenda a usar a API de IA Generativa mais poderasa do mundo! Gere texto, imagens e audio!",
      "objectives": [
        "Use LLM como GTP-3 e GPT-4",
        "Crie Imagens com DALL-E, produza variações, preencha máscaras",
        "Gere Audios a Partir de Texto com TTS",
        "Faça transcrição de Audios com Wisper",
        "Aprenda a usar Funções próprias integradas com GPT",
        "Gere Descrições Textuais de Imagens com Vision"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Introdução ao Curso: O que Vamos Estudar",
          "Contextualização: Modelos GPT no Contexto da Inteligência Artificial",
          "Por que o ChatGPT impressionou tanto?",
          "Material para Dowload - Incluindo Códigos Fonte"
        ],
        "Fundamentos de Processamento de Linguagem Natural": [
          "Conceitos Básicos",
          "Word Embedding",
          "Redes Neurais Artificiais e LSTM"
        ],
        "Conhecendo Transformers: A revolução na Inteligência Artificial": [
          "Breve Apresentação",
          "Introdução ao Funcionamento dos Transformers",
          "Introdução ao Funcionamento dos Transformers Parte II"
        ],
        "OpenAI e Modelos de NLP GPT": [
          "A Empresa OpenAI",
          "Modelos GPT Baseados em Transformers"
        ],
        "Conhecendo ChatGPT: Implementação de Modelos GPT": [
          "O ChatGPT",
          "Curiosidades sobre o ChatGPT",
          "Exemplos de Aplicações com ChatGPT"
        ],
        "DALL-E": [
          "Conhecendo o DALL-E"
        ],
        "Labs: GPT na Prática com Python": [
          "Preparação e Informações Gerais",
          "Modelos",
          "Precificação",
          "API para GPT",
          "GPT Completion",
          "Chat e Roles",
          "Hiperparâmetros"
        ],
        "Lab II: Imagens com DALL-E e Vision": [
          "DALL-E 3 e DALL-E 2",
          "Fill the Mask e Variations",
          "Descrevendo Imagens com Vision"
        ],
        "Lab III: Audio com Whisper e TTS": [
          "Whisper e TTS"
        ],
        "Lab IV: Assistentes com Chamadas de Funções": [
          "Assistentes",
          "Chamadas de Funções"
        ]
      },
      "requirements": [
        "Conhecimentos Básicos em Python"
      ],
      "description": "O ChatGPT foi um dos maiores destaques tecnológicos em 2022/23, atingindo 1 milhão de usuários em uma semana. Os modelos de Inteligência Artificial do grupo GPT, são baseados numa técnica conhecida como Transformers, que são derivados de Redes Neurais Profundas especializados em Processamento de Linguagem Natural. Sua aplicação vem desde 2017 e vem trazendo muitas inovações para a área de Inteligência Artificial. Já DALL-E são modelos de produção de imagens a partir de texto, criados e mantidos pela mesma empresa.\nNeste curso, você vai se tornar um especialista em modelos baseados em GPT e DALL-E, TTS e Whisper, além de ser capaz de criar projetos em Python que consomem a API fornecdida pela OpenAI. Entre outras coisas, você vai estudar:\n\n\nConhecer os fundamentos de Transformers, a tecnlogia revolucionária por traz do ChatGPT\nEstudar a familia de modelos baseadas em GPT\nEntender o processo de treinamento de modelos baseados em Transformers\nConhece a API da OpenAI e sua implementação em Python\nAprender a utilizar diferentes modelos GPT em Python\nCrie images e variações com DALL-E 3 e DALL-E 4\nGere audio a partir de texto com TTS\nFaça transcrição de audio com Whisper\nSaiba como incorporar chamadas de funções próprias pela IA Generativa da OpenAI\nVamos ainda analisar o futuro de tecnologias como Transformers e GPT\nO curso ainda inclui:\nCódigo-fonte disponível\nBons estudos!",
      "target_audience": [
        "Interessados em Aprender Fundamentos de GPT e DALL-E",
        "Desenvolvedores, cientistas e analistas de dados"
      ]
    },
    {
      "title": "Extração de dados da WEB com Python e Selenium",
      "url": "https://www.udemy.com/course/extracao-de-dados-da-web-com-python-e-selenium/",
      "bio": "Web scraping com Python e salvando em um banco de dados com o sqlAlchemy",
      "objectives": [
        "Extração de dados",
        "Selenium",
        "Python",
        "sqlAlchemy",
        "Web scraping"
      ],
      "course_content": {
        "Introdução": [
          "Introdução",
          "Instalações",
          "Atualizando para o Selenium 4 e mudanças nos scripts",
          "Baixando o driver do navegador",
          "Abrindo uma página com o Selenium",
          "Extraindo dados através do seu ID",
          "Extraindo dados através da sua Classe",
          "Extraindo dados através do seu TagName",
          "Extraindo dados através do seu Name",
          "Extraindo dados através do seu Xpath",
          "Comandos úteis",
          "Clicando em botões",
          "Capturando atributos dos elementos",
          "Manipulando elementos select",
          "Extraindo dados e ordenando em valores crescentes",
          "Baixando imagens presentes nas páginas",
          "Realizando pesquisa e extraindo dados de tabelas",
          "Extraindo dados paginados",
          "Tirando screenShot das páginas",
          "Tratamento de erros",
          "Trabalhando com tag iframe - Parte 1",
          "Trabalhando com tag iframe - Parte 2",
          "Enviando textos para campos input com o sendKeys",
          "Acessando diferentes abas do navegador",
          "Baixando arquivos",
          "Extraindo dados paginados.",
          "Inserindo e extraindo dados dos Correios - Parte 1",
          "Inserindo e extraindo dados dos Correios - Parte 2",
          "Realizando pesquisa e extraindo dados.",
          "Lendo um arquivo Excel, realizando uma pesquisa e extraindo dados",
          "Extraindo dados e salvando em uma planilha do Excel",
          "Extraindo dados do site do IBGE",
          "Extraindo dados do site Portal da Transparência"
        ],
        "Banco de dados": [
          "Instalando o Xampp",
          "Configurando o usuário do banco de dados",
          "Criando o nosso banco de dados",
          "Inserindo dados extraídos no banco de dados",
          "Verificando se um dado já está presente no banco de dados",
          "Tratamento de dados"
        ]
      },
      "requirements": [
        "Instalação dos programas apresentados no curso, nenhum é pago e as suas instalações são apresentadas no curso."
      ],
      "description": "No curso serão apresentados todos os conceitos teóricos e práticos para permitir que você faça a extração de textos e imagens que estão presentes nas páginas WEB (web scraping) e salvar esses dados em um banco de dados MySQL com a biblioteca sqlAlchemy. Caso você não tenha conhecimentos com Python será apresentado na primeira seção os conhecimentos necessários para realização do curso. Para fazer a extração de dados vamos aprender os seguintes tópicos:\nInstalar o Selenium;\nConceitos básicos de programação do Python (For, If e listas);\nAbrir e manipular os navegadores de forma automática (Chrome, Firefox, Opera e Edge);\nControlar no navegador (Fechar, Atualizar, Voltar e Avançar páginas);\nCapturar dados através dos localizadores (class name, tag name, xpath, id, name);\nClicar em botões;\nRealizar de forma automática o download de arquivos presentes nas páginas WEB;\nEnviar valores para elementos;\nCapturar atributos de elementos (href, src);\nManipular elementos do tipo Select;\nNavegar entre abas do navegador;\nBaixar imagens e tirar screenshots;\nTratamento de erros;\nSalvar os dados extraídos arquivos CSV;\nSalvar os dados extraídos em um banco de dados MySQL;\nProjetos de extração na prática.\nPara isso utilizaremos a linguagem de programação Python, que é uma linguagem muito utilizada em empresas e vai permitir que os dados extraídos sejam salvos de maneira fácil para serem utilizados posteriormente.",
      "target_audience": [
        "Pessoas interessadas em extração de dados da WEB"
      ]
    },
    {
      "title": "Manual Prático do Deep Learning - Redes Neurais Profundas",
      "url": "https://www.udemy.com/course/redes-neurais/",
      "bio": "Redes Neurais por debaixo dos panos",
      "objectives": [
        "Projetar redes neurais profundas para resolver problemas de regressão e classificação binária/multiclasse",
        "Entender os efeitos dos hiperparâmetros no treinamento (qtde. de camadas, qtde. de nerônios, learning rate, momentum, dropout, etc)",
        "Entender por que o treinamento de Redes Neurais não convergem em alguns casos, e como resolver esses problemas",
        "Se tornar um Ninja em Backpropagation, aplicando na prática, e sendo capaz de calcular os gradientes de qualquer função derivável",
        "Implementar uma Rede Neural completa do Zero (com momentum, dropout, regularização L1/L2, learning rate decay, early stopping, batch normalization e freezing)"
      ],
      "course_content": {},
      "requirements": [
        "Python básico"
      ],
      "description": "Já pensou se as Redes Neurais viessem com um Manual Prático de instruções passo-a-passo sobre como construí-las?\nPois é, esse manual agora existe!\n\n\nCom ajuda desse Manual, você vai implementar desde os neurônios mais básicos (como o Perceptron, o Adaline e o Sigmoid) até uma Rede Neural completa com:\nlearning rate\nmomentum\ndropout\nregularização L1/L2\ntécnicas de inicialização de pesos (normal, uniform, e glorot/xavier)\nmini-batch Gradiente Descendente\nfreezing\nlearning rate decay\nearly stopping\nbatch normalization\n\n\nAlém disso, esse Manual também contém segredos e dicas de especialistas pra lhe ajudar a treinar suas próprias Redes Neurais bem mais fácil, como:\nquais os melhores valores para cada hiperparâmetro (learning rate, qtde. de camadas, qtde. neurônios, tamanho do batch, etc)?\no que fazer quando a rede não converge?\ncomo evitar os problemas de vanishing/exploding gradients?\ncomo identificar e resolver underfitting e overfitting?\n\n\nEsse Manual também acompanha a ferramenta essencial pra implementação de Redes Neurais: a Backpropagation.\nPoucas pessoas sabem utilizá-la, mas nesse Manual você encontra um método único e memorável de ensino conhecido como \"deriva quem tá dentro e multiplica por quem tá fora!\".\n\n\nTudo isso feito pelo autor desse Manual, que:\né Google Developer Expert em Machine Learning desde 2018\ntrabalha com Machine Learning e Deep Learning desde 2016\né professor de Pós-Graduação em Machine Learning\né Doutor em Deep Learning\ntem um nanodegree em Deep Learning\ntreina Redes Nerais desde 2015",
      "target_audience": [
        "entusiastas de Machine Learning e Deep Learning que desejam ir além de frameworks como Keras, Tensorflow, PyTorch, etc, entendendo como eles funcionam",
        "curiosos interessados em implementar uma Rede Neural do zero (somente com python e numpy) com taxa de aprendizagem, momentum, dropout, regularização L1/L2, learning rate decay, early stopping, batch normalization, etc.."
      ]
    },
    {
      "title": "Processamento de Linguagem Natural com spaCy e Python",
      "url": "https://www.udemy.com/course/spacy-python-processamento-linguagem-natural/",
      "bio": "Aprenda os conceitos de processamento de linguagem natural! Construa um classificador de sentimento com dados do Twitter",
      "objectives": [
        "Aprenda os conceitos básicos de processamento de linguagem natural, como: part-of-speech, lematização, stemização, stop words, parsing de dependências, semelhança entre palavras e tokenização",
        "Utilize a biblioteca spaCy e o Google Colab para suas implementações de processamento de linguagem natural",
        "Crie um classificador de sentimentos utilizando uma base de dados do Twitter em português",
        "Crie implementações de processamento de linguagem natural no idioma português",
        "Treine modelos de machine learning utilizando o spaCy"
      ],
      "course_content": {},
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Básico da linguagem Python é desejável, porém, é possível acompanhar o curso sem dominar essa linguagem com profundidade"
      ],
      "description": "A área de Processamento de Linguagem Natural - PLN (Natural Language Processing - NLP) é uma subárea da Inteligência Artificial que tem como objetivo tornar os computadores capazes de entender a linguagem humana, tanto escrita quanto falada. Alguns exemplo de aplicações práticas são: tradutores entre idiomas, tradução de texto para fala ou fala para texto, chatbots, sistemas automáticos de perguntas e respostas, sumarização de textos, geração automática de descrições para imagens, adição de legendas em vídeos, classificação de sentimentos em frases, dentre várias outras!\nAtualmente, este setor está cada vez mais necessitando de soluções de Processamento de Linguagem Natural, ou seja, aprender essa área pode ser a chave para trazer soluções reais para necessidades presentes e futuras. Baseado nisso, este curso foi projetado para quem deseja crescer ou iniciar uma nova carreira na área de Processamento de Linguagem Natural, utilizando a biblioteca spaCy e a linguagem Python! O spaCy é uma biblioteca desenvolvida com foco no uso em ambientes de produção, possibilitando a criação de aplicativos que processam e entendem grandes volumes de texto. Ela pode ser usada para extrair informações, entender linguagem natural ou preprocessar textos para posterior uso em modelos de deep learning.\nO curso está dividido em três partes:\nNa primeira você vai aprender os recursos mais básicos de Processamento de Linguagem Natural utilizando o spaCy, como: part-of-speech, lematização, stemização, reconhecimento de entidades nomeadas, stop words, parsing de dependências, semelhanças entre palavras e tokenização\nNa segunda parte criaremos um classificador de emoções utilizando frases em português, utilizando 100% os modelos de machine learning disponibilizados pelo próprio spaCy\nPor fim, na terceira e última parte, criaremos um classificador de sentimentos utilizando uma base de dados do Twitter com textos em português\nUtilizaremos tecnologias modernas, como a linguagem Python e o Google Colab, garantindo que você não tenha problemas com instalações ou configurações de softwares na sua máquina local.\nPreparado(a) para dar um importante passo na sua carreira? Aguardo você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial, Mineração de Textos ou Processamento de Linguagem Natural",
        "Pessoas interessadas na biblioteca spaCy",
        "Alunos de graduação e pós-graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial",
        "Alunos que querem aprender passo a passo como funciona a área de classificação de textos"
      ]
    },
    {
      "title": "【PyTorch+Colab】PyTorchで実装するディープラーニング -CNN、RNN、人工知能Webアプリの構築-",
      "url": "https://www.udemy.com/course/ai-pytorch/",
      "bio": "人気急上昇中の機械学習フレームワーク、PyTorchを使って深層学習を学ぶコースです。CNNによる画像認識、RNNによる時系列データ処理、AIアプリの構築などを学びます。開発環境にはGoogle Colabolatoryを使用します。",
      "objectives": [
        "機械学習フレームワークPyTorchの基礎が身につきます。",
        "PyTorchのコードの読み書きができるようになります。",
        "CNN、RNNなどを実装できるようになります。",
        "人工知能アプリを構築し、公開できるようになります。",
        "自分で調べながら、ディープラーニングのコードを実装する力が身につきます。"
      ],
      "course_content": {
        "イントロダクション": [
          "教材の使用方法",
          "講座の概要",
          "ディープラーニングとは",
          "PyTorchとは",
          "Google Colaboratoryの使い方",
          "Tensorについて",
          "演習: イントロダクション",
          "質疑応答: イントロダクション"
        ],
        "PyTorchで実装する簡単なディープラーニング": [
          "セクション2の教材",
          "第2講の概要",
          "勾配降下法",
          "活性化関数と損失関数",
          "最適化アルゴリズム",
          "簡単なディープラーニングの実装",
          "演習: PyTorchで実装する簡単なディープラーニング",
          "質疑応答: PyTorchで実装する簡単なディープラーニング"
        ],
        "PyTorchの様々な機能": [
          "セクション3の教材",
          "第3講の概要",
          "自動微分",
          "エポックとバッチ",
          "DataLoader",
          "演習: PyTorchの様々な機能",
          "質疑応答: PyTorchの様々な機能"
        ],
        "畳み込みニューラルネットワーク（CNN）": [
          "セクション4の教材",
          "第4講の概要",
          "CNNの概要",
          "データ拡張",
          "ドロップアウト",
          "CNNの実装",
          "演習: 畳み込みニューラルネットワーク（CNN）",
          "質疑応答: 畳み込みニューラルネットワーク（CNN）"
        ],
        "再帰型ニューラルネットワーク（RNN）": [
          "セクション5の教材",
          "第5講の概要",
          "RNNの概要",
          "シンプルなRNNの実装",
          "LSTMの概要",
          "GRUの概要",
          "RNNによる画像生成",
          "演習: 再帰型ニューラルネットワーク（RNN）",
          "質疑応答: 再帰型ニューラルネットワーク（RNN）"
        ],
        "AIアプリのデプロイ": [
          "セクション6の教材",
          "第6講の概要",
          "人工知能アプリ開発の概要",
          "モデルの訓練",
          "（補足）Windows環境におけるgunicornのインストールについて",
          "開発環境の構築",
          "Flaskによる画像識別アプリ",
          "Herokuへのデプロイ",
          "演習: AIアプリのデプロイ",
          "質疑応答: AIアプリのデプロイ"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "何らかのプログラミング経験があった方が望ましいです。",
        "数学の知識はほとんど必要ありません。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。"
      ],
      "description": "本コースのゴールは、PyTorchを使ってディープラーニングが 実装できるようになることです。\nPyTorchを使ってCNN（畳み込みニューラルネットワーク）、RNN（再帰型ニューラルネットワーク）などの技術を順を追って幅広く習得し、人工知能を搭載したWebアプリの構築までを行います。\n各ディープラーニング技術の要点を解説した上で、PyTorchのコードを基礎から丁寧に解説します。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\nPyTorchはオープンソースの機械学習ライブラリで、簡潔さ、柔軟性、速度のバランスに優れているため人気が急上昇中です。\nまた、簡潔な記述が可能なため、最新の研究成果の実装によく使われています。\n海外を中心にコミュニティ活動が活発で、ネット上の情報が豊富なのもメリットです。\n\n\n本コースでは開発環境にGoogle Colabを利用するので、環境構築にはほとんど手間がかかりません。\nGPUが無料で利用できるので、コードの実行時間も短縮できます。\n効率よくPyTorchを習得できるように、様々な工夫を凝らしています。\nPyTorchを包括的に学び、皆さんの技術的な可能性を大きく広げましょう。\n\n\n————————————————————\n本コースの主な内容は以下の通りです。\n\n\nイントロダクション\n→ PyTorchの概要、ディープラーニングの概要、そしてPyTorchの基礎であるTensorについて解説します\n\n\nPyTorchで実装する簡単なディープラーニング\n→ 可能な限りシンプルなコードで、ディープラーニングを実装します\n\n\nPyTorchの様々な機能\n→ 自動微分、DataLoaderなどのPyTorch特有の機能について解説します\n\n\n畳み込みニューラルネットワーク（CNN）\n→ CNNの原理を学んだ上で、CNNによる画像分類をデータ拡張、ドロップアウトとともに実装します\n\n\n再帰型ニューラルネットワーク（RNN）\n→ RNNの原理を学んだ上で、シンプルなRNNの構築、およびRNNによる画像生成を行います\n\n\nAIアプリのデプロイ\n→ 学習済みモデルを活用した人工知能Webアプリを構築します\n\n\nなお、ディープラーニングの数学的背景については最小限の解説となりますのでご注意ください。\nPythonの基礎についての解説動画はありませんが、テキストがダウンロード可能です。\n————————————————————\n\n\n本コースでは可能な限り丁寧な解説を心がけていますが、ある程度ご自身で調べることも必要になるのでご注意ください。\n動画を見るのみでも学習が進められるようになっていますが、可能であればPythonのコードを動かしながら進めることをお勧めします。\nコードがダウンロード可能ですので、これをベースに様々なカスタマイズを行うこともお勧めです。\n\n\nそれでは、PyTorchを使って一緒に楽しく本格的な人工知能を学んでいきましょう。",
      "target_audience": [
        "人工知能/機械学習に強い関心のある方",
        "フレームワークPyTorchを使えるようになりたい方",
        "実務で機械学習を使いたい企業の方",
        "専門分野で人工知能を応用したい研究者の方",
        "有用な深層学習用フレームワークを探している方"
      ]
    },
    {
      "title": "Modern Deep Convolutional Neural Networks with PyTorch",
      "url": "https://www.udemy.com/course/modern-deep-convolutional-neural-networks/",
      "bio": "Image Recognition with Convolutional Neural Networks. Advanced techniques for Deep Learning and Representation learning",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Computer Vision Problems",
          "Linear Layer and Classification Pipeline",
          "Loss functions and Softmax",
          "Stochastic Gradient Descend",
          "PRACTICE #1: Data loading",
          "PRACTICE #2: Linear Classifier in PyTorch (part 1)",
          "PRACTICE #3: Linear Classifier in PyTorch (part 2)",
          "PRACTICE #4: Multi-layer perceptron"
        ],
        "Convolutional Neural Networks": [
          "What is image",
          "Motivation to Convolutions",
          "Convolution operation",
          "Parameters of the convolution",
          "Non-linear function",
          "Max Pooling and Average Pooling",
          "Building deep convolutional network",
          "PRACTICE #5: Convolutional Neural Network"
        ],
        "Regularization and Normalization": [
          "Overfitting. L2 regularization",
          "DropOut regularization. DropConnect regularization",
          "DropBlock regularization",
          "Early Stopping regularization",
          "Batch Normalization"
        ],
        "Improving the quality": [
          "Data Augmentation",
          "Existing datasets",
          "Modern Architectures",
          "Transfer Learning"
        ],
        "Boat Recognition Project": [
          "Data Loading",
          "Data Augmentation",
          "Transfer Learning: ResNet-18"
        ]
      },
      "requirements": [
        "Machine Learning",
        "Linear Regression and Classification",
        "Matrix Calculus, Probability",
        "Deep Learning basis: Multi perceptron, optimization",
        "Python, PyTorch"
      ],
      "description": "Dear friend, welcome to the course \"Modern Deep Convolutional Neural Networks\"! I tried to do my best in order to share my practical experience in Deep Learning and Computer vision with you.\nThe course consists of 4 blocks:\nIntroduction section, where I remind you, what is Linear layers, SGD, and how to train Deep Networks.\nConvolution section, where we discuss convolutions, it's parameters, advantages and disadvantages.\nRegularization and normalization section, where I share with you useful tips and tricks in Deep Learning.\nFine tuning, transfer learning, modern datasets and architectures\nIf you don't understand something, feel free to ask equations. I will answer you directly or will make a video explanation.\nPrerequisites:\nMatrix calculus, Linear Algebra, Probability theory and Statistics\nBasics of Machine Learning: Regularization, Linear Regression and Classification,\nBasics of Deep Learning: Linear layers, SGD,  Multi-layer perceptron\nPython, Basics of PyTorch",
      "target_audience": [
        "Who knows a bit about neural networks",
        "Who wants to enrich their Deep Learning and Image Processing knowledge",
        "Who wants to study advanced techniques and practices"
      ]
    },
    {
      "title": "Aprenda Programação em Python 3 do Zero com Facilidade",
      "url": "https://www.udemy.com/course/aprenda-a-programar-em-python-com-facilidade-do-zero/",
      "bio": "Domine o Python3! Curso Completo com Exercícios e Projetos + Bônus Especial: Machine Learning Supervisionado em Python!",
      "objectives": [
        "Domínio dos princípios da lógica de programação",
        "Fluência na escrita de programas em Python",
        "Facilidade no uso de dados externos em programas Python através de requisições HTTP para APIs",
        "Criação de programas para resolução de problemas reais do dia a dia",
        "Machine Learning em Python"
      ],
      "course_content": {},
      "requirements": [
        "Você precisa ter um computador",
        "E você precisa ter vontade de aprender coisas novas e usar a cabeça para desenvolver soluções para problemas reais"
      ],
      "description": "Neste curso, que é um dos mais populares da Udemy no tema de programação, cada um dos conceitos fundamentais da linguagem Python são abordados de forma prática e com explicações passo a passo, tornando o aprendizado super fácil e intuitivo.\nAlém disso, o curso está recheado de exercícios e desafios práticos pra que você tenha a chance de aplicar tudo o que está aprendendo em situações reais do dia a dia.\nUtilizamos no curso o Python 3, o mais recente do momento. Você vai terminar o curso com bastante domínio da linguagem Python e esta base servirá também para aprender a programar em outras linguagens com muito mais facilidade.\nAlém dos assuntos fundamentais, faremos juntos um projeto de app de previsão do tempo. Nele, vamos utilizar requisições HTTP para pegar informações de diferentes serviços meteorológicos e apresentar a previsão do tempo ao usuário.\nTemos também uma seção inteira abordando inteligência artificial em Python, mais especificamente Machine Learning, usando a biblioteca scikit learn. Vamos aprender a usar Machine Learning para criar um programa que classifica espécies de plantas, um que prevê o valor de vendas decorrentes de campanhas publicitárias e um que reconhece dígitos escritos à mão.\nO curso está imperdível! Se você quer aprender a programar e se tornar um profissional na área de tecnologia, inscreva-se já e vamos aprender Python, a linguagem mais popular do momento!",
      "target_audience": [
        "Qualquer pessoa que queira aprender a programar",
        "Pessoas que queiram dominar a linguagem Python para no futuro criar tecnologias relacionadas com Machine Learning, Desenvolvimento de jogos, Cálculos científicos, Estatística, Web Scraping, Desenvolvimento Web, etc."
      ]
    },
    {
      "title": "NumPy Course for Beginners",
      "url": "https://www.udemy.com/course/free-numpy-course-for-beginners/",
      "bio": "Master the basics of NumPy for data analysis. Learn array operations, slicing, broadcasting & more with real examples.",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic understanding of Python is required for doing this Numpy course.",
        "No prior experience in data science or NumPy required",
        "Eagerness to learn through real examples"
      ],
      "description": "Looking to level up your Python skills with data analysis and numerical computing? This Practical Oriented Free NumPy Course is the perfect place to start!\nNumPy is the foundation of data science in Python, powering libraries like Pandas, Scikit-Learn, TensorFlow, and more. If you're into machine learning, data analytics, or just want to manipulate data efficiently, NumPy is a must-know.\nIn this beginner-friendly course, you’ll learn:\nWhat NumPy is and why it's essential for data science\nHow to work with NumPy arrays, vectors, and matrices\nLearn to create 1D, 2D, and multi-dimensional arrays\nReal-world use cases using NumPy functions\nReal-world math operations on arrays\nLogical operations and masking\nAggregations (sum, mean, std, max, etc.)\nDifference between Python lists vs NumPy arrays\nArray creation, reshaping, indexing, slicing, and broadcasting with examples and practicals\nPerforming math operations, aggregations, and logic-based filtering\nEvery concept is explained with clear examples, hands-on practice, and zero fluff—making this course ideal for absolute beginners.\nAnd yes, it’s 100% FREE — no ads, no sales pitch, just pure learning.\n\n\nWhy Take This Free Course?\nLearn one of the most in-demand Python libraries for data\nBuild a strong base for Pandas, Matplotlib, Scikit-Learn & TensorFlow\nShort, structured, and practice-rich format\nHands-on tasks with immediate feedback\nDesigned by an industry expert for real-world skills",
      "target_audience": [
        "Beginners in Python who want to enter AI & Data Science",
        "Data science and machine learning aspirants",
        "Professionals or hobbyists looking to process data efficiently",
        "Anyone preparing for data analyst or data science interviews",
        "Students learning Python and want to go beyond the basics"
      ]
    },
    {
      "title": "Tensorflow 2.0: Guía completa para el Nuevo Tensorflow",
      "url": "https://www.udemy.com/course/tensorflow2/",
      "bio": "Crea soluciones sorprendentes de Deep Learning e Inteligencia Artificial y súbelas a producción con TensorFlow 2.0",
      "objectives": [
        "Cómo utilizar TensorFlow 2.0 en Data Science",
        "Diferencias importantes entre TensorFlow 1.X y TensorFlow 2.0",
        "Cómo implementar Redes Neuronales Artificiales en TensorFlow 2.0",
        "Cómo implementar Redes Neuronales Convolucionales en TensorFlow 2.0",
        "Cómo implementar Redes Neuronales Recurrentes en TensorFlow 2.0",
        "Cómo construir tu propia aplicación de Transfer Learning en TensorFlow 2.0",
        "Cómo construir un bot que actúe como un broker comprando y vendiendo acciones utilizando Reinforcement Learning (Deep-Q Network)",
        "Cómo construir un pipeline de Machine Learning al completo en Tensorflow 2.0",
        "Cómo crear una validación de datos y pre procesado de datasets automáticos utilizando TensorFlow Data Validation y TensorFlow Transform",
        "Poner en producción un modelo TensorFlow 2.0",
        "Cómo crear una API que clasifique imágenes con Flask y TensorFlow 2.0",
        "Cómo acceder a un modelo deTensorFlow en un servidor con RESTful API"
      ],
      "course_content": {},
      "requirements": [
        "Algunos básicos de Matemáticas como por ejemplo saber qué es la diferenciación o el gradiente",
        "La programación básica en Python que puedes aprender en el curso de Estadística Descriptiva o el de ML de la A a la Z",
        "Es muy recomendable haber hecho el curso de Tensorflow 1 de Juan Gabriel Gomila, pues en este curso no volvemos a explicar la teoría que se ve en dicho curso, solo vemos una actualización de la librería a la versión 2.0"
      ],
      "description": "¡Bienvenido al curso de Tensorflow 2.0!\nSe acaba de lanzar TensorFlow 2.0. El lanzamiento introduce muchas características que simplifican el modelo de desarrollo y los procesos de mantenimiento. Desde el punto de vista educativo, potencia el entendimiento de la gente simplificando en gran medida los conceptos complejos. Desde el punto de vista de la industria, los modelos son mucho más sencillos de entender, mantener y desarrollar.\nEl Aprendizaje Profundo o Deep Learning es una de las áreas de mayor crecimiento de la Inteligencia Artificial. En los últimos años, se ha probado que los modelos de Deep Learning, incluso los más simples, pueden resolver tareas difíciles y complejas. Ahora que la novedad del Deep Learning ha pasado (seguro que ya has tomado algún curso mío sobre esta materia), la gente empieza a querer utilizar su poder y potencial para mejorar sus productos.\nEl curso se estructura de modo que se cubren todos los temas desde el modelado de redes neuronales y su entrenamiento hasta su puesta en producción.\nEn la Parte 1 del curso, aprenderás sobre la infraestructura tecnológica que utilizaremos a lo largo del curso (Sección 1) y lo básico de la librería TensorFlow 2.0 y su sintaxis (Sección 2).\nEn la Parte 2 de este curso, indagaremos en el apasionante mundo del aprendizaje profundo. Durante esta parte del curso, implementarás varios tipos de redes neuronales (Redes Neuronales Artificiales [Sección 3], Redes Neuronales Convolucionales [Sección 4], Redes Neuronales Recurrentes [Sección 5]). Al final de esta parte, en la Sección 6, aprenderás y construirás un ejemplo de Transfer Learning que da unos resultados impresionantes en clasificación de imágenes de perros y gatos con una red neuronal entrenada por Google.\nAl acabar la segunda parte del curso y ultimar el aprendizaje de cómo implementar redes neuronales, en la Parte 3 verás como hacer tu propio broker resolviendo el problema de compra-venta de acciones en tiempo real utilizando Aprendizaje por Refuerzo, específicamente el Deep-Q Learning.\nLa Parte 4 va sobre TensorFlow Extended (TFX). En esta parte del curso aprenderás a cómo trabajar con datos y crear tus propios flujos de datos para subirlos a producción. En la Sección 8 comprobaremos si el dataset tiene alguna anomalía utilizando la librería TensorFlow Data Validation y, después de aprender cómo comprobar anomalías de un dataset en la Sección 9, haremos nuestro propio pre procesado de flujo de datos utilizando el paquete TensorFlow Transform.\nEn la Sección 10 de este curso aprenderás y crearás tu propio Fashion API haciendo uso de la librería Flask Python y un modelo pre entrenado. A lo largo de esta sección, obtendrás una imagen más completa de cómo enviar peticiones a un modelo a través de internet. Sin embargo, en esta etapa, la arquitectura alrededor del modelo no es escalable a millones de peticiones. Entramos en la Sección 11. En esta, aprenderás a cómo mejorar las soluciones a la sección previa utilizando la librería TensorFlow Serving. De una manera muy sencilla, aprenderás y crearás tu propio API de Clasificación de Imágenes ¡que soporta millones de peticiones al día!\nÚltimamente se está volviendo más y más popular tener un modelo de Aprendizaje profundo en aplicaciones Android o iOS, pero las redes neuronales requieren de mucha energía y recursos. Aquí es donde la librería TensorFlow Lite entra en juego. En la Sección 12 del curso aprenderás cómo optimizar y convertir cualquier red neuronal para que sea apta para un dispositivo móvil.\nYa para acabar con el proceso de aprendizaje y la Parte 5 de este curso, en la Sección 13 aprenderás a cómo distribuir el entrenamiento de una Red Neuronal a múltiples GPUs o también a Servidores haciendo uso del paquete TensorFlow 2.0.",
      "target_audience": [
        "Ingenieros de Deep Learning que quieren aprender Tensorflow 2.0",
        "Ingenieros de Inteligencia Artificial que quieren expandir sus habilidades de Deep Learning stack",
        "Computer Scientists que quieren entrar en el excitante área del Aprendizaje Profundo y la Inteligencia Artificial",
        "Data Scientists que quieren llevar al siguiente nivel sus habilidades de Inteligencia Artificial",
        "Todos los expertos en Inteligencia Artificial que quieren expandir su campo de aplicaciones",
        "Desarrolladores de Python que quieren entrar en el el excitante área del Aprendizaje Profundo y la Inteligencia Artificial",
        "Ingenieros que trabajan en tecnología y automatización",
        "Hombres y mujeres de negocios y compañías que quieren adelantarse al juego",
        "Estudiantes en programas relacionados con la tecnología que quieren llevar a cabo una carrera en Data Science, Machine Learning, o Inteligencia Artificial",
        "Cualquier apasionado de la Inteligencia Artificial",
        "Apasionados de Matrix, IA, Blade Runner y otras películas del estilo que quieran saber cómo funciona realmente la Inteligencia Artificial."
      ]
    },
    {
      "title": "Der ultimative Python-Kurs für Data Science, ML & AI",
      "url": "https://www.udemy.com/course/python-datascience-bootcamp/",
      "bio": "Ohne Vorkenntnisse in 4 Schritten systematisch mit Python zum Data Scientist. Inkl. Deep Learning, Machine Learning & KI",
      "objectives": [
        "Ohne Vorkenntnisse in Python systematisch zum gefragten Data-Science-Experten",
        "Lerne Python mit Ausrichtung auf Data Science",
        "Verstehe Machine Learning, Deep Learning und AI",
        "Lerne Python mit echten Daten anzuwenden",
        "Trainiere ein Neuronales Netz mit Tensorflow und Keras",
        "Wie du mit Python Daten brauchbar auswertest"
      ],
      "course_content": {},
      "requirements": [
        "Es werden keine Anforderungen vorausgesetzt",
        "Du benötigst einen Computer oder Laptop (Windows / Mac / Linux)...",
        "und natürlich die Motivation, Data Science und Python lernen zu wollen :)"
      ],
      "description": "EGAL ob du Python professionell für deinen Job oder privat für dein Hobby erlernen willst. Dieser Kurs ist konzipiert dich ohne Vorkenntnisse zum Data Science Profi mit Python zu machen.\nNutze den Python-Kurs mit exzellenten Bewertungen auf Udemy:\n„Ich bin sehr begeistert! Bin mit fast keinem Wissen hier rein und hab jetzt ein super Verständnis was denn Machine Learning überhaupt ist, man denkt immer das ist absolute Raketenwissenschaft, aber Jannis kann das wirklich super gut erklären, super Investition, danke!!!“ (★★★★★, Peter G.)\n\n\nDeine Entscheidung ein Data-Scientist zu sein, kann Dir viele Türen öffnen!\nDer Bedarf an qualifizierten Leuten ist groß. Mit diesem Kurs legst Du den Grundstein, ein gefragter Experte zu werden für ein Berufsfeld, wo du laut Indeed Jobbörse ein weit überdurchschnittliches Gehalt beziehen kannst!\nDu wirst Schritt für Schritt an das Thema Python herangeführt und erlaubt dir den direkten Einstieg in die Welt der Data-Science.\n\n\nDer All-Umfassende Python Kurs für Data Science auf Udemy.\nMit 252 Lektionen und 29+ Stunden HD-Videos, unzählige Quizze, Tests, Praxisprojekte, Merkblätter und Übungen.\n\n\nKurz-Überblick:\nVerstehe alle Python-Grundlagen\nEntwickle Data-Science Tools\nTrainiere dich mit Quizzen und Übungen\nEinfaches Wiederholen von Wissen mit Merkblättern\nUmfassende Praxisbeispiele, z.B.:\nSage das Brustkrebs-Risiko von Patienten vorher\nErmittle die Gründe für Diabetes\nWerte echte Gehälter der Stadt San Francisco aus\nSchätze den Wert von Gebrauchtwagen\nund noch viel viel mehr\n\n\nLerne mit dem erfolgreichstem deutschen Udemy Dozenten.\nSkills die dich zum gefragten Data-Science-Experten machen!\n\n\nNutze ein einzigartiges Kurskonzept - das dir die Möglichkeit gibt, mit praxisorientierten Konzepten und Daten Python mit Ausrichtung Data-Science zu lernen.\nWas mein Konzept so beliebt macht?\nIch lehre praxisorientiert mit Erfahrung und nicht trockene Theorie wie an der Uni.\nKomplett-Kurs perfekt aufeinander abgestimmt\nSupport, der auf deine Rückfragen eingeht\nPraxis erprobtes Lernkonzept mit grafischen, lerneffektiven Veranschaulichungen\nDu arbeitest mit echten Daten: So macht Machine Learning besonders viel Spaß\nIdeal für die Job-Vorbereitung, Uni-Klausur oder anderen persönlichen Zielen\nTop-Aktuelle Kursinhalte die auf langjährige Erfolge gebaut sind\n\n\nEin komplett durchdachter, praxisorientiert Python Komplett-Kurs, der dich in 4 Schritten systematisch sicher ans Ziel führt, ein Experte zu werden!\n\n\nSchaue dir meine Video-Nachricht and dich an!\nDie 4 Themen für dich im Einzelnen.\nDieser Python Kurs ist speziell entwickelt, um dich auf die 4 wichtigen Themen eines Data-Scientist optimal vorzubereiten. Perfekt aufeinander abgestimmt und interessant gestaltet, sodass dein Lernprozess praxisorientiert und effizient ist.\nThema 1: Python Grundlagen (für Einsteiger)\nThema 2: Data Science\nThema 3: Machine Learning\nThema 4: Deep Learning (Neuronale Netze)\n\n\nThema 1: Python Grundlagen\nPython zeichnet sich durch eine leicht zu erlernende Syntax aus. Python ist performant und objektorientiert.\nLerne die Grundlagen von Python kennen. Du lernst alle Datentypen und Funktionen kennen. Bereits nach ein paar Stunden schreibst du schon eine kleinen Spamfilter as dein erstes Praxisprojekt. Am Schluss bist Du in der Lage schon selbst kleinere Programme zu entwickeln.\nHast Du schon Programmiererfahrung mit Python?\nDann kannst du diesen ersten Abschnitt überspringen und direkt im zweiten Thema einsteigen!\n\n\nThema 2: Data Science\nWenn Du ein Data-Scientist bist, geht es für dich um fundierte Methoden der Datenanalyse. Ein extrem wichtiges Gebiet in der Wirtschaft, Wissenschaft, Gesundheitswesen und sogar öffentliche Einrichtungen.\nAll diese Institutionen benötigen die Datenanalysen, um z. B. Handlungsempfehlungen abzuleiten, Qualität und Effizienz zu optimieren, u. a.\nIn diesem Abschnitt lernst du, Daten nach Python einzulesen, zu filtern und grafisch auszuwerten.\nDas heißt, du lernst Daten brauchbar zu machen.\nDu lernst mit Tools wie Numpy, Pandas, Matplotlib und Seaborn zu arbeiten!\nAußerdem lernst du in diesem Abschnitt anhand eines echten Praxisprojektes das gelernte umzusetzen: Wir analysieren die Gehälter der Stadt San Francisco.\n\n\nThema 3: Machine Learning\nIn Thema 2 hast du die Grundlagen gelernt, um sich jetzt mit dem Machine Learning zu beschäftigen. Was ist Machine Learning?\nKurz erklärt, Machine Learning ist ein Teil der künstlichen Intelligenz (KI). Das heißt, es geht um Algorithmen, die die Muster und Gesetzmäßigkeiten der Daten erkennen.\nJetzt lernst die unterschiedlichen Arten und Methoden von Machine Learning und wie du diese für Lösungen verwendest.\nDazu gehört auch die Aufbereitung von Daten und wie du die Genauigkeit eines Modells beurteilst. Wir werden das in diesem Abschnitt an eigenen, unterschiedlichen Modellen trainieren und nachvollziehen.\nAls Beispiel wirst du sehen, wie du Diabetes vorhersagen oder Spamfilter verbessern kannst. Python Anwendungstool hier: Sklearn.\n\n\nThema 4: Deep Learning / Neuronale Netze\nJetzt, wo du in Thema 3 Machine Learning erfolgreich gelernt hast, können wir uns dem Thema Deep Learning (Neuronale Netze) widmen.\nMit Deep Learning lernst du die spezielle Methode des maschinellen Lernens und die dazugehörige Informationsverarbeitung. Das schliesst die Neuronale Netze Anwendung ein, um die Arbeitsweise des menschlichen Gehirns nachzustellen.\nDu beginnst mit einem einzelnen Neuron. Mit Fortschritt dieses Lernabschnittes erweitern wir das Modell, damit du am Ende an einem ganzen neuronalen Netz trainierst.\nAll das, was du in Abschnitt 3 gelernt hast, wird dir jetzt hier weiterhelfen, denn es hilft dir, viele Zusammenhänge im Machine Learning 1:1 auf das Prinzip der Neuronalen Netze anzuwenden.\nTeil deines Lerninhaltes hier ist auch eine Bilderkennung zu schreiben mit Tools wie Keras und Tensorflow.\n\n\nKlingt gut?\nDann würde ich mich sehr freuen, wenn ich dir noch heute die Tür zur Welt der Data Science mit Python öffnen kann.\nDu lernst mit dem erfolgreichsten, deutschsprachigen Dozenten auf Udemy.\nSchau dir die Bewertungen zu diesem Kurs an und überzeuge dich selbst :)",
      "target_audience": [
        "Für alle, die ohne Vorkenntnisse Python mit Ausrichtung auf Data Science und Machine Learning lernen möchten",
        "Für alle, die schon Python-Erfahrung haben, aber Data Science, Machine Learning & Deep Learning lernen wollen",
        "Für alle, die Python produktiv für Data Science einsetzen wollen - egal ob als Hobby oder professionell im Job"
      ]
    },
    {
      "title": "Difyで「AI従業員」を作ろう！ -ノーコードで迅速に構築する生成AIアプリ-",
      "url": "https://www.udemy.com/course/dify-aiapp/",
      "bio": "LLMアプリ開発プラットフォーム「Dify」を活用して、生成AIを使ったアプリを迅速かつ効率的に構築しましょう。ChatGPT、Gemini、Claudeなど様々なLLMを設定可能です。",
      "objectives": [
        "生成AIを活用したAIアプリを迅速かつ効率的に構築する方法を学びます。",
        "LLMアプリ開発プラットフォーム「Dify」の使い方を基礎から学びます。",
        "ノーコードでAIアプリを構築する方法を学びます。",
        "Difyの全体像、そしてその可能性について体験と共に学びます。",
        "Difyの様々な機能、活用を順を追って学びます。",
        "Difyを様々なタスクに応用し、実践的なスキルを習得します。"
      ],
      "course_content": {
        "Difyの概要と基本的な使い方": [
          "セクション1の教材",
          "イントロダクション",
          "講座の概要",
          "Difyとは？",
          "Difyのアカウント作成",
          "GeminiのAPI Keyを取得する",
          "Difyの体験 Part1",
          "Difyの体験 Part2",
          "Difyの体験 Part3",
          "セクション1の演習"
        ],
        "Difyの様々な機能": [
          "セクション2の教材",
          "Section2の概要",
          "Difyアプリ作成の概要",
          "ツールの利用",
          "RAG (Retrieval Augmented Generation)",
          "様々なブロック",
          "アプリのテンプレート",
          "セクション2の演習"
        ],
        "Difyの応用": [
          "セクション3の教材",
          "Section3の概要",
          "自動アプリケーションオーケストレーション",
          "新規ビジネスサポートアプリ",
          "ウェブサイト生成アプリ",
          "カスタマーサポート",
          "汎用「AI従業員」に向けて",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "2024年7月の環境で解説しています。最新の環境と異なる可能性があります。",
        "プログラミングや数学の知識、経験は不要です。",
        "人工知能、機械学習の技術的な知識は不要です。",
        "ローカル環境はWindowsでもMacでも大丈夫です。",
        "Difyのアカウント開設が必要です。",
        "Googleのアカウントが必要です。",
        "Difyの無料のプランでも受講できます。"
      ],
      "description": "『Difyで「AI従業員」を作ろう！』は、LLMアプリ開発プラットフォーム「Dify」を使って、ノーコードでAIアプリを構築する方法を学ぶ講座です。\n生成AIを活用して、AIアプリケーションを迅速かつ効率的に構築したい方におすすめです。\nDifyは、プロンプト管理、RAGエンジン、カスタムエージェント、ワークフローなどの機能を提供し、複雑なタスクを処理できる強力なAIアプリを簡単に作成できます。\n\n\n本講座では、最初にDifyの概要を学び、その後、様々な機能や応用方法を順を追って学んでいきます。\nさらに、実際にDifyを使ってエージェントを作成し、様々な場面に応じたAIアプリの開発方法を学びます。\nDifyで「AI従業員」を作成し、ビジネスや日常生活における様々な知的作業を自動化しましょう。\n\n\n講座の内容は以下の通りです。\nSection1: Difyの概要と基本的な使い方\n→ Difyの基本的な使い方と概要について学びます。\nSection2: Difyの様々な機能\n→ プロンプト管理、エージェント機能、RAGエンジンなど、様々な機能を一通り学びます。\nSection3: Difyの応用\n→ Difyを使って様々な場面に応じたAIアプリを開発します。",
      "target_audience": [
        "生成AIを搭載したAIアプリをノーコードで開発したい方。",
        "DifyによりLLMアプリ開発を効率化したい方。",
        "Difyを業務で活用したい方。",
        "Difyで構築した機能を自分のサービスに取り入れたい方。",
        "生成AIの新たな可能性を模索したい方。",
        "AI技術のトレンドに追随したい方。"
      ]
    },
    {
      "title": "دبلومة بايثون لتحليل البيانات | Python Data Analysis Diploma",
      "url": "https://www.udemy.com/course/python-data-analysis-diploma/",
      "bio": "الخطوة الأولى في رحلتك لاحتراف \"علم البيانات\"، أفضل بداية لأي حد عاوز يتعلم ويحترف مجال \"تحليل البيانات\" باستخدام بايثون",
      "objectives": [
        "مقدمة في علم وتحليل البيانات باستخدام بايثون | Introduction to Data Science & Analysis Using Python",
        "بايثون لعلم وتحليل البيانات | Python for Data Science & Analysis",
        "أساسيات الإحصاء لتحليل البيانات | Statistics Basics for Data Analysis",
        "التعامل مع البيانات العددية في بايثون | NumPy for Numerical Data Manipulation",
        "أساسيات تحليل البيانات في بايثون | Pandas Basics for Python Exploratory Data Analysis (EDA)",
        "تصوير البيانات وتمثيلها في بايثون | Matplotlib & Seaborn for Python Data Visualization",
        "معالجة البيانات المسبقة في بايثون | Data Preprocessing in Python",
        "تحليل بيانات السلاسل الزمنية في بايثون | Time-Series Analysis in Python",
        "استيراد البيانات في بايثون | Python Data Importing & Web Scraping",
        "مشاريع وتطبيقات عملية على تحليل البيانات في بايثون | Python Data Analysis Projects"
      ],
      "course_content": {
        "مقدمة عامة عن الدورة التدريبية | Course Introduction": [
          "تفاصيل دبلومة بايثون لتحليل البيانات Python Data Analysis Diploma Overview",
          "خطة الدورات التدريبية في الدبلومة Diploma Courses Roadmap",
          "مسار تعلم مجال علم البيانات Data Science Learning Roadmap",
          "محاور ومواضيع دبلومة بايثون لتحليل البيانات Topics of the Diploma",
          "إزاي تحقق أكبر استفادة من الدورة التدريبية How to get the most from this course?",
          "تجهيز بيئة التطوير والعمل Setup Development Environment (Anaconda + Jupyter)"
        ],
        "----- COURSE(01) | INTRODUCTION TO DATA SCIENCE & ANALYSIS -----": [
          "مقدمة عامة عن الدورة التدريبية Course Introduction"
        ],
        "أساسيات علم البيانات | Data Science Foundations (إختياري)": [
          "أهمية علم البيانات Why Data Science (مقدمة عامة وسريعة)",
          "أساسيات علم البيانات Data Science Basics",
          "دور محلل البيانات Data Analytics vs. Analysis",
          "المجالات المتعلقة بعلم البيانات Data Science Related Fields",
          "الأدوات ولغات البرمجة الأساسية لعالم البيانات Data Scientist's Toolkit",
          "البيانات الضخمة - هندسة البيانات Big Data (Data Engineering)",
          "تصور البيانات Data Visualization",
          "تعلم الآلة Machine Learning",
          "الوظائف والأدوار الرئيسية في علم البيانات Data Science Roles"
        ],
        "مشروعك الأول لتحليل البيانات في بايثون | Your First Python Data Analysis Project": [
          "تطبيق عملي: مشروع كامل لتحليل البيانات في بايثون (لا يتطلب التطبيق فقط المتابعة)"
        ],
        "----- COURSE(02) | PYTHON PROGRAMMING LANGUAGE -----": [
          "مقدمة عامة عن الدورة التدريبية Course Introduction"
        ],
        "بايثون لعلم وتحليل البيانات | Python for Data Science & Analysis": [
          "ملفات الدورة التدريبية Python Course Materials",
          "مقدمة عامة وسريعة عن البرمجة وحل المشكلات Intro to Programming & Problem Solving",
          "التعامل مع بيئة التطوير والعمل Jupyter IDE Basics",
          "التعامل مع بيئة التطوير والعمل Google Colaboratory Basics",
          "أساسيات بايثون: التعامل مع التعليقات Python Comments",
          "أساسيات بايثون: التعامل مع المسافات Python Whitespaces",
          "أساسيات بايثون: المتغيرات Python Variables",
          "أساسيات بايثون: المعاملات Python Operators",
          "أساسيات بايثون: أنواع البيانات الأساسية Python Basic Data Types",
          "أساسيات بايثون: التعامل مع سلاسل الحروف Python Strings",
          "المنطق والشروط Logic & Conditions (if,elif,else)",
          "الحلقات التكرارية Python Loops (for loops)",
          "الحلقات التكرارية Python Loops (while loops)",
          "هياكل البيانات: مقدمة Introduction to Python Data Structures",
          "هياكل البيانات: التعامل مع القوائم في بايثون Python Lists",
          "هياكل البيانات: التعامل مع المجموعات في بايثون Python Tuples",
          "هياكل البيانات: التعامل مع المجموعات في بايثون Python Sets",
          "هياكل البيانات: التعامل مع القواميس في بايثون Python Dictionaries",
          "التعامل مع الدوال والمكتبات في بايثون Python Functions & Packages",
          "التعامل مع الملفات في بايثون Python Files I/O",
          "بايثون لعلم البيانات: مقدمة عامة Intro to Python for Data Science",
          "بايثون لعلم البيانات: التعامل مع البيانات العددية NumPy for Numerical Data",
          "بايثون لعلم البيانات: التعامل مع البيانات المجدولة Pandas for Tabular Data Analy",
          "بايثون لعلم البيانات: تصوير البيانات Matplotlib for Data Visualization",
          "مسائل وتمارين للبرمجة ببايثون Python Programming Exercises"
        ],
        "----- COURSE(03) | MATH & STAT FOR DATA ANALYSIS -----": [
          "مقدمة عامة عن الدورة التدريبية Course Introduction"
        ],
        "أساسيات الجبر الخطي | Linear Algebra Basics (إختياري)": [
          "مقدمة عامة عن الجبر الخطي Linear Algebra",
          "مبادئ المصفوفات Matrices Basics",
          "أنواع المصفوفات Scalar & Vector",
          "جمع وطرح المصفوفات Matrix Addition & Subtraction",
          "ضرب المصفوفات Matrix Multiplication"
        ],
        "أساسيات الإحصاء الوصفية | Basics of Descriptive Statistics (إختياري)": [
          "مقدمة عامة عن الإحصاء Statistics",
          "ليه الإحصاء والاحتمالات مهمة لعالم البيانات؟ Why Statistics",
          "الفرق بين المجتمع والعينة Population vs. Sample",
          "يعني إيه بيانات What is Data?",
          "إيه أنواع البيانات اللي بنتعامل معاها Data Types",
          "أساسيات الإحصاء الوصفية Descriptive Statistics Basics",
          "حساب المتوسطات Mean, Median, & Mode",
          "المتغير العشوائي Random Variable",
          "قياس مدى التباعد Five-Numbers Summary",
          "الإنحراف المعياري والتباين Variance & Standard Deviation",
          "الأشكال الإحصائية Shape Measures",
          "القيم الشاذة والمتطرفة Outliers"
        ],
        "أساسيات الرياضيات والإحصاء لتحليل البيانات | Math & Stat for Data Analysis": [
          "ملفات الدورة التدريبية Statistics Course Materials",
          "أساسيات تحليل البيانات الاستكشافي Basics of Exploratory Data Analysis (EDA)",
          "أساسيات الجبر الخطي Linear Algebra Basics (Scalar, Vector, & Matrix)",
          "تمارين على العمليات على المصفوفات Matrices Operations Examples",
          "العمليات على المصفوفات في بايثون Python Matrices Operations",
          "مبادئ الإحصاء الوصفية Descriptive Statistics Basics",
          "الإحصاء الوصفية في بايثون Descriptive Statistics Using Python",
          "تطبيق عملي: تعديل الصور باستخدام المصفوفات Image Manipulation Using Matrices",
          "تطبيق عملي: تحليل البيانات الاستكشافي في بايثون EDA & Descriptive Statistics",
          "مصادر هامة في الإحصاء Statistics Resources"
        ]
      },
      "requirements": [
        "لا توجد أي متطلبات لهذه الدورة"
      ],
      "description": "دبلومة بايثون لتحليل البيانات | Python Data Analysis Diploma\nدبلومة تحليل البيانات باستخدام بايثون هي الخطوة الأولى في رحلتنا في مجال علم البيانات والذكاء الإصطناعي، وهي مبادرة نسعى من خلالها إلى إثراء المحتوى العربي في هذا المجال من خلال إعداد دورة تدريبية شاملة بشكل تفاعلي وتطبيقي لكل مواضيع وتخصصات هذا المجال .. وبنحاول إن التدريب يكون مناسب للمبتدئين ولأي شخص يرغب في بدء العمل كمحلل بيانات Data Analyst / عالم بيانات Data Science باستخدام بايثون Python واحتراف هذا المجال من الصفر.\n\n\nالدبلومة بتتميز بالآتي:\n- التدريب تفاعلي وقائم على النقاشات مع الطلاب\n- خطة واضحة ومنظمة للبدء في المجال من الصفر وحتى احترافه\n- 10 كورسات في كورس واحد\n- أكثر من 40 ساعة تدريبية\n- تطبيقات عملية ومشاريع Case-studies\n- تحميل ملفات التدريب والأكواد Course Materials\n- المحتوى متاح مدى الحياة\n- شهادة بنهاية التدريب\nبنشرح في الدبلومة التقنيات والأدوات الرئيسية لأي محلل بيانات باستخدام بايثون:\nCourse (00): Introduction to Data Science & Analysis\nCourse (01): Python Basics for Data Science & Analysis\nCourse (02): Math & Statistics for Data Analysis (EDA)\nCourse (03): NumPy Basics (Numerical Data Manipulation)\nCourse (04): Pandas Basics (Data Analysis)\nCourse (05): Matplotlib & Seaborn Basics (Data Visualization)\nCourse (06): Advanced Pandas | Data Pre-processing (Data Wrangling)\nCourse (07): Advanced Pandas | Time-series Data Analysis\nCourse (08): Advanced Pandas | Data Importing & Web Scraping\nCourse (09): Real-life Projects & Case-studies\n\n--\n= (*) تحذير هام: تم بذل مجهود كبير بفضل الله وتوفيقه من قبل م. مصطفى عثمان في إعداد هذا المحتوى الذي يقدم بصفة شخصية لك مقابل الاشتراك، رجاء عدم نسخه أو استخدامه بعيداً عن الموقع أو الإتجار به لإن ذلك يعرضك للمسائلة أمام الله عز وجل .. شكراً لتفهمك، وشكراً لاهتمامك بما نقدمه",
      "target_audience": [
        "أي حد لسة هيبدأ في مجال علم وتحليل البيانات وعاوز يبدأ بداية موفقة"
      ]
    },
    {
      "title": "Machine Learning Basics - Regression Analysis",
      "url": "https://www.udemy.com/course/linear-regression-analysis-using-python-hindi/",
      "bio": "हिंदी में सीखें Basics of Machine Learning - covers Simple Linear Regression & Multiple Linear regression in Python",
      "objectives": [
        "Linear Regression technique का उपयोग करके real life problem को हल करना सीखें",
        "Preliminary analysis of data using Univariate and Bivariate analysis before running Linear regression",
        "Predict future outcomes basis past data by implementing Simplest Machine Learning algorithm",
        "How to convert business problem into a Machine learning Linear Regression problem"
      ],
      "course_content": {
        "Introduction": [
          "Welcome to the course!",
          "Course contents",
          "Course Resources"
        ],
        "Setting up Python and Jupyter Notebook": [
          "This is a milestone!",
          "Introduction to Google Colab",
          "Arithmetic operators in Python: Python Basics",
          "Strings in Python: Python Basics",
          "Indexes: Python Basics",
          "Working with Numpy Library of Python",
          "Quiz",
          "Working with Pandas Library of Python",
          "Working with Seaborn Library of Python",
          "Python file for additional practice",
          "Quiz"
        ],
        "Basics of Statistics": [
          "Types of Data",
          "Types of Statistics",
          "Describing data Graphically",
          "Measures of Centers",
          "Measures of Dispersion",
          "Quiz"
        ],
        "Introduction to Machine Learning": [
          "Introduction to Machine Learning"
        ],
        "Data Preprocessing": [
          "Gathering Business Knowledge",
          "Data Exploration",
          "The Dataset and the Data Dictionary",
          "Importing Data in Python",
          "Univariate analysis and EDD",
          "EDD in Python",
          "Outlier Treatment",
          "Outlier Treatment in Python",
          "Missing Value Imputation",
          "Missing Value Imputation in Python",
          "Seasonality in Data",
          "Bi-variate analysis and Variable transformation",
          "Variable transformation and deletion in Python",
          "Non-usable variables",
          "Dummy variable creation: Handling qualitative data",
          "Dummy variable creation in Python",
          "Correlation Analysis",
          "Correlation Analysis in Python",
          "Quiz"
        ],
        "Linear Regression": [
          "The Problem Statement",
          "Basic Equations and Ordinary Least Squares (OLS) method",
          "Assessing accuracy of predicted coefficients",
          "Assessing Model Accuracy: RSE and R squared",
          "Simple Linear Regression in Python",
          "Multiple Linear Regression",
          "The F - statistic",
          "Interpreting results of Categorical variables",
          "Multiple Linear Regression in Python",
          "Test-train split",
          "Bias Variance trade-off",
          "Test train split in Python",
          "Regression models other than OLS",
          "Subset selection techniques",
          "Shrinkage methods: Ridge and Lasso",
          "Ridge and Lasso in Python",
          "Heteroscedasticity",
          "Quiz",
          "Practical Task",
          "Quiz",
          "Comprehensive Interview Preparation Questions",
          "The final milestone!"
        ],
        "Congratulations & About your certificate": [
          "About your certificate",
          "Bonus Lecture"
        ]
      },
      "requirements": [
        "A PC/ laptop with good internet connection"
      ],
      "description": "आप एक पूर्ण Linear Regression course की तलाश कर रहे हैं जो आपको वह सब कुछ सिखाता है जो आपको Python में Linear Regression model बनाने के लिए चाहिए, है ना?\nआपको सही Linear Regression course मिल गया है!\nAfter completing this course you will be able to:\nIdentify the business problem which can be solved using linear regression technique of Machine Learning.\nCreate a linear regression model in Python and analyze its result.\nConfidently practice, discuss and understand Machine Learning concepts\nA Verifiable Certificate of Completion is presented to all students who undertake this Machine learning basics course.\nHow this course will help you?\nIf you are a business manager or an executive, or a student who wants to learn and apply machine learning in Real world problems of business, this course will give you a solid base for that by teaching you the most popular technique of machine learning, which is Linear Regression\nWhy should you choose this course?\nThis course covers all the steps that one should take while solving a business problem through linear regression.\nMost courses only focus on teaching how to run the analysis but we believe that what happens before and after running analysis is even more important i.e. before running analysis it is very important that you have the right data and do some pre-processing on it. And after running analysis, you should be able to judge how good your model is and interpret the results to actually be able to help your business.\nWhat makes us qualified to teach you?\nThe course is taught by Abhishek and Pukhraj. As managers in Global Analytics Consulting firm, we have helped businesses solve their business problem using machine learning techniques and we have used our experience to include the practical aspects of data analysis in this course\nWe are also the creators of some of the most popular online courses - with over 150,000 enrollments and thousands of 5-star reviews like these ones:\nThis is very good, i love the fact the all explanation given can be understood by a layman - Joshua\nThank you Author for this wonderful course. You are the best and this course is worth any price. - Daisy\nOur Promise\nTeaching our students is our job and we are committed to it. If you have any questions about the course content, practice sheet or anything related to any topic, you can always post a question in the course or send us a direct message.\nDownload Practice files, take Quizzes, and complete Assignments\nWith each lecture, there are class notes attached for you to follow along. You can also take quizzes to check your understanding of concepts. Each section contains a practice assignment for you to practically implement your learning.\nWhat is covered in this course?\nThis course teaches you all the steps of creating a Linear Regression model, which is the most popular Machine Learning model, to solve business problems.\nBelow are the course contents of this course on Linear Regression:\nSection 1 - Basics of Statistics\nThis section is divided into five different lectures starting from types of data then types of statistics\nthen graphical representations to describe the data and then a lecture on measures of center like mean\nmedian and mode and lastly measures of dispersion like range and standard deviation\nSection 2 - Python basic\nThis section gets you started with Python.\nThis section will help you set up the python and Jupyter environment on your system and it'll teach\nyou how to perform some basic operations in Python. We will understand the importance of different libraries such as Numpy, Pandas & Seaborn.\nSection 3 - Introduction to Machine Learning\nIn this section we will learn - What does Machine Learning mean. What are the meanings or different terms associated with machine learning? You will see some examples so that you understand what machine learning actually is. It also contains steps involved in building a machine learning model, not just linear models, any machine learning model.\nSection 4 - Data Preprocessing\nIn this section you will learn what actions you need to take a step by step to get the data and then prepare it for the analysis these steps are very important.\nWe start with understanding the importance of business knowledge then we will see how to do data exploration. We learn how to do uni-variate analysis and bi-variate analysis then we cover topics like outlier treatment, missing value imputation, variable transformation and correlation.\nSection 5 - Regression Model\nThis section starts with simple linear regression and then covers multiple linear regression.\nWe have covered the basic theory behind each concept without getting too mathematical about it so that you understand where the concept is coming from and how it is important. But even if you don't understand it,  it will be okay as long as you learn how to run and interpret the result as taught in the practical lectures.\nWe also look at how to quantify models accuracy, what is the meaning of F statistic, how categorical variables in the independent variables dataset are interpreted in the results, what are other variations to the ordinary least squared method and how do we finally interpret the result to find out the answer to a business problem.\nBy the end of this course, your confidence in creating a regression model in Python will soar. You'll have a thorough understanding of how to use regression modelling to create predictive models and solve business problems.\n\n\nGo ahead and click the enroll button, and I'll see you in lesson 1!\n\n\nCheers\nStart-Tech Academy\n\n\nBelow is a list of popular FAQs of students who want to start their Machine learning journey-\nWhat is Machine Learning?\nMachine Learning is a field of computer science which gives the computer the ability to learn without being explicitly programmed. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\nWhat is the Linear regression technique of Machine learning?\nLinear Regression is a simple machine learning model for regression problems, i.e., when the target variable is a real value.\nLinear regression is a linear model, e.g. a model that assumes a linear relationship between the input variables (x) and the single output variable (y). More specifically, that y can be calculated from a linear combination of the input variables (x).\nWhen there is a single input variable (x), the method is referred to as simple linear regression.\nWhen there are multiple input variables, the method is known as multiple linear regression.\nWhy learn Linear regression technique of Machine learning?\nThere are four reasons to learn Linear regression technique of Machine learning:\n1. Linear Regression is the most popular machine learning technique\n2. Linear Regression has fairly good prediction accuracy\n3. Linear Regression is simple to implement and easy to interpret\n4. It gives you a firm base to start learning other advanced techniques of Machine Learning\nHow much time does it take to learn Linear regression technique of machine learning?\nLinear Regression is easy but no one can determine the learning time it takes. It totally depends on you. The method we adopted to help you learn Linear regression starts from the basics and takes you to advanced level within hours. You can follow the same, but remember you can learn nothing without practicing it. Practice is the only way to remember whatever you have learnt. Therefore, we have also provided you with another data set to work on as a separate project of Linear regression.",
      "target_audience": [
        "Anyone curious to master Linear Regression from beginner to Advanced in short span of time",
        "People pursuing a career in data science"
      ]
    },
    {
      "title": "Learn Azure Machine Learning from scratch",
      "url": "https://www.udemy.com/course/learn-azure-machine-learning-from-scratch/",
      "bio": "This course starts from scratch with Azure Machine Learning and lands in decision trees.",
      "objectives": [],
      "course_content": {
        "Azure Machine Learning Studio": [
          "Azure Machine Learning Studio",
          "Where to find samples"
        ],
        "Creating Machine Learning Models": [
          "Upload a new dataset into Azure Machine Learning Studio",
          "Create a new expirement and upload an online dataset",
          "Work with your first expirement and use the convert to Dataset",
          "Preprocessing Data"
        ],
        "First example: flight delays prediction": [
          "Preprocessing flights data",
          "Cleaning data and transforming its type",
          "Apply Math in your Azure Machine Learning Expirement",
          "Preprocessing the weather data",
          "How to join the datasets and split the rows"
        ],
        "Add Algorithms into your ML Expirement": [
          "Explore the available Algorithms",
          "Explore Azure Machine Learning cheat sheet",
          "Use algorithms in the ML expirement",
          "How to see the decision trees in your expirement"
        ],
        "Azure AI Gallery": [
          "Publish your Azure ML expirement to the Azure AI Gallery"
        ]
      },
      "requirements": [
        "Basic mathematics level",
        "Passion for Machine Learning, AI, and Data Science"
      ],
      "description": "Are you passionate about Machine Learning and AI? Are you looking to find your first steps into Data Science. This course starts from scratch with Azure Machine Learning and lands in decision trees.\nI will walk you through the Azure ML Studio, how to create expirements, how to add datasets, how to add algorithms and predict values.\n\n\nThis course does not cover any coding with R or Python, this will be published in a different course.",
      "target_audience": [
        "Anyone interested in Azure Machine Learning.",
        "Any people who are not that comfortable with coding but who are interested in Azure Machine Learning and want to apply it easily on datasets.",
        "Any students in college who want to start a career in Data Science.",
        "Any data analysts who want to level up in Azure Machine Learning.",
        "Any people who want to become a Data Scientist."
      ]
    },
    {
      "title": "Machine Learning Fundamentals [Python]",
      "url": "https://www.udemy.com/course/machine-learning-fundamentals-python/",
      "bio": "Understanding Machine Learning for Data Science in python. Best skill to get in free time.",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "For Machine Learning Concept no prerequisite. Anyone can do this course.",
        "Understanding of Data Preprocessing is required for Coding.",
        "After completing this course, you can connect to me on my blog for any question.",
        "Python is required to do the coding part"
      ],
      "description": "This course is designed to understand basic Concept of Machine Learning.  Anyone can opt for this course. No prior understanding of Machine Learning is required.  Simple Linear Regression Concepts are covered in detail. Coding part is not covered, however wherever possible I have attached the code in the resources.\n\n\nNow question is why this course?\nThis Course will not only teach you the basics of Machine learning and Simple Linear Regression. It will also cover in depth mathematical explanation of Cost function and use of Gradient Descent for Simple Linear Regression. Understanding these is must for a solid foundation before entering into Machine Learning World. This foundation will help you to understand all other algorithms and mathematics behind it.",
      "target_audience": [
        "Anyone who is looking or dont know from where to start Machine Learning can opt for this course.",
        "This will provide a good foundation in understanding concept of Machine Learning."
      ]
    },
    {
      "title": "Data Science Fundamentals for Beginners",
      "url": "https://www.udemy.com/course/ds4beginners/",
      "bio": "Find out if Data Science is something that interests you!",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "No programming experience required, little prior knowledge needed"
      ],
      "description": "Welcome to the world of data science! This course is designed for complete beginners and youth who have little or no prior experience in data science but are eager to learn about it. This course is all about making data science approachable and fun, without overwhelming you with technical jargon. We understand that data science can seem overwhelming and intimidating, so we've created a course that's approachable and engaging.\nIn the first section of the course, we will cover the basics of data science, including types of data, data collection, and data cleaning. We will then dive into the core concepts of statistical analysis and data visualization, using Tableau, a popular data visualization tool, to create beautiful and informative visualizations of data. Don't worry if you've never used Tableau before, we'll start from the very beginning with the download button for the app.\nNext, we will explore Pandas, a powerful data manipulation library in Python. You'll learn how to load data, clean and manipulate it, and use Pandas to perform basic statistical analysis. And don't worry you won't need any coding experience.\nFinally, learn about applications of data science and how we can apply our new skills to real-world applications.\nWhether you're interested in a career in data science, or just looking to expand your skillset, this course is perfect for you. By the end of the course, you'll have a solid foundation in data science, including data cleaning, visualization, and manipulation using popular tools such as Tableau and Pandas. You'll be able to decide whether data science is something you want to pursue and where to look to further your journey.\nSo don't wait any longer, come start your exciting journey and let's have some fun with data science!",
      "target_audience": [
        "For youth and teens who want to better understand data science and see if its something that interests them."
      ]
    },
    {
      "title": "Machine Learning: Build AI Model with RandomForestClassifier",
      "url": "https://www.udemy.com/course/machine-learning-build-ai-model-with-randomforestclassifier/",
      "bio": "Machine Learning: Harness the Power of RandomForestClassifier to Build Accurate AI Models",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Installing Jupyter",
          "How to download Python files"
        ],
        "Course Contents": [
          "import `datasets` from scikit-learn",
          "import the train_test_split function",
          "import the `RandomForestClassifier` class",
          "import two functions, `accuracy_score` and `confusion_matrix`",
          "importing `pyplot`",
          "import seaborn",
          "loads the Breast Cancer dataset",
          "split the dataset into training and testing sets",
          "creating an instance of the `RandomForestClassifier` class",
          "training a Random Forest classifier",
          "ready to make predictions",
          "calculating the accuracy of the classifier's predictions",
          "valuate the performance of a classification model",
          "creating a heatmap plot",
          "the feature importances",
          "obtain the indices in descending order",
          "creating a bar chart"
        ]
      },
      "requirements": [
        "Having a basic understanding of programming concepts and syntax will be beneficial. Familiarity with Python programming language is preferred, although the course will cover Python fundamentals as well."
      ],
      "description": "Are you ready to dive into the exciting world of machine learning and build your own AI models? This beginner-level course, \"Machine Learning: Build AI Model with RandomForestClassifier,\" is designed to provide you with a solid foundation in machine learning using the powerful RandomForestClassifier algorithm.\n\n\nMachine learning has become a vital tool in various industries, from finance and healthcare to marketing and robotics. In this hands-on course, you will gain the practical skills needed to develop accurate predictive models and make data-driven decisions.\n\n\nNo prior machine learning experience is required. We'll start from the basics and gradually progress to more advanced concepts. By the end of this course, you will have the knowledge and confidence to build your own AI models using the RandomForestClassifier algorithm.\n\n\nKey Features of the Course:\n\n\n1. Understand the fundamentals: Begin your journey by grasping the essential concepts of machine learning, including supervised learning, classification, and ensemble methods.\n\n\n2. Explore the RandomForestClassifier algorithm: Dive into the RandomForestClassifier algorithm, a popular ensemble learning method that combines multiple decision trees to deliver accurate predictions.\n\n\n3. Hands-on projects: Apply your knowledge to real-world projects by building AI models for practical tasks, such as cancer diagnosis, customer segmentation, or fraud detection.\n\n\n4. Evaluation and optimization: Learn how to evaluate the performance of your models using accuracy metrics and confusion matrices. Discover techniques to optimize your models for better results.\n\n\n5. Data visualization: Enhance your understanding of the data and model predictions through visualization techniques using libraries like matplotlib and seaborn.\n\n\n6. Practical tips and best practices: Gain insights into industry-standard practices and practical tips from experienced instructors to help you develop robust and efficient machine learning models.\n\n\n7. Learn at your own pace: This self-paced course allows you to learn at your convenience, with lifetime access to the course materials, including video lectures, coding exercises, and project files.\n\n\nWhether you're a student, professional, or aspiring AI enthusiast, this course equips you with the necessary skills to embark on your machine learning journey. Join us now and unlock the potential of machine learning with the RandomForestClassifier algorithm!\n\n\nEnroll today and take your first step towards becoming a proficient machine learning practitioner.",
      "target_audience": [
        "If you have little to no prior experience with machine learning or programming, this course provides a solid introduction to the field. The course explains the concepts and techniques in a beginner-friendly manner, starting from the basics and gradually building up your knowledge and skills."
      ]
    },
    {
      "title": "Introdução à Estatística para Data Science em R -Casos Reais",
      "url": "https://www.udemy.com/course/introducao-a-estatistica-para-data-science/",
      "bio": "Conceitos. Técnicas de Amostragem. Como analisar diferentes tipos de variáveis.",
      "objectives": [
        "Dominar na prática os principais conceitos estatísticos: população, amostra, parâmetro, estimadores e estimativas.",
        "Aprenderá sobre Amostras Probabilísticas e Não probabilísticas",
        "Aprenderá sobre Amostra Aleatória Simples",
        "Aprenderá sobre Amostras Sistemática",
        "Aprenderá sobre Amostras Estratificada",
        "Aprenderá sobre Amostra por Conglomerado",
        "Aprenderá sobre Amostra por múltiplos estágios",
        "Aprenderá sobre Amostras por Conveniência, por cotas e outras amostragens mais \"usuais\"",
        "Saberá os principais tipos de variáveis",
        "Saberá qual tipo de Análise Estatística aplicar a cada tipo de variável"
      ],
      "course_content": {
        "Conceitos Importantes": [
          "Seja muito bem vindo(a)!",
          "Boas vindas, Visão geral do curso",
          "Antes de iniciarmos...",
          "População",
          "Amostra",
          "Parâmetros",
          "Estimadores e estimativas",
          "Exercícios sobre a primeira seção"
        ],
        "Amostragem Aleatória Simples": [
          "Probabilística e não-probabilística",
          "Amostragem Aleatória Simples - Fundamentos",
          "Amostragem Aleatória Simples - O Sorteio",
          "Amostragem Aleatória Simples Com Reposição",
          "Amostragem Aleatória Simples Sem Reposição",
          "Vantagens e Desvantagens de uma AAS",
          "Exercícios sobre Amostragem Aleatória Simples"
        ],
        "Amostragem Estratificada": [
          "Amostragem Estratificada - O que é",
          "Amostragem Estratificada - Exemplos",
          "Amostragem Estratificada Proporcional",
          "Amostragem Estratificada Proporcional: peso de cada estrato",
          "Amostragem Estratificada Proporcional usando o R",
          "Amostragem Estratificada Uniforme no R",
          "Amostragem Estratificada \"Ótima\"",
          "Exercícios sobre Amostragem Estratificada"
        ],
        "Amostragem Sistemática": [
          "Amostragem Sistemática: como funciona",
          "Amostragem Sistemática: processo de extração",
          "Amostragem Sistemática: vantagens e desvantagens",
          "Exercício"
        ],
        "Amostragem por Conglomerado": [
          "Amostragem por Conglomerado: como funciona",
          "Amostragem por Conglomerado: processo, vantagens e desvantagens",
          "Exercício"
        ],
        "Amostragem por Múltiplos Estágios": [
          "Amostragem em Múltiplos Estágios",
          "Exercício"
        ],
        "Amostragem Não Probabilística": [
          "Amostragem Não probabilística",
          "Exercício"
        ],
        "Análise Exploratória de Dados": [
          "Variáveis: conceito, qualitativas e quantitativas",
          "Variáveis Quantitativas Discretas e Contínuas",
          "Variáveis Quantitativas: Medidas de Posição",
          "Variáveis Quantitativas: Medidas de Posição no R",
          "Variáveis Quantitativas - Medidas de Dispersão",
          "Variáveis Quantitativas: gráficos",
          "Variáveis Qualitativas Nominais e Ordinais",
          "Exercícios"
        ],
        "Projeto": [
          "Instruções",
          "Solução Guiada parte 1",
          "Solução Guiada parte 2",
          "Solução Guiada parte 3",
          "Solução parte 4"
        ],
        "Aula Bônus": [
          "Aula Bônus",
          "Trilha de Aprendizado para a carreira em Data Science"
        ]
      },
      "requirements": [
        "Nenhum pré-requisito é necessário. Qualquer pessoa poderá fazer este curso."
      ],
      "description": "Para quem serve este curso?\nTodo profissional que deseja trabalhar com análise de dados precisa saber sobre Estatística, pois é a ciência que estuda os dados. Então convido você:\nEstudante/profissional/pesquisador das áreas de TI\nOu qualquer pessoa interessada em dominar a Ciência dos Dados.\nA Abordagem\n\nEste curso apresenta este fascinante mundo dos números porém com uma abordagem diferenciada, simples e inovadora, onde exemplos reais são mostrados para entender conceitos considerados de \"difícil compreensão\".\nAo final deste curso você será capaz de:\nDominar na prática os principais conceitos em Estatística\nSaberá os principais métodos para se obter uma amostra de dados\nAprenderá como analisar estatisticamente cada tipo de variável\nQuer conhecer os dados de uma forma mais aprofundada? Então junte-se nesta grande aventura e dê leve sua carreira para um outro nível!",
      "target_audience": [
        "Leigos que desejam entrar na área de Ciência dos Dados.",
        "Profissionais de TI interessados em entrar para a Carreira de Data Science"
      ]
    },
    {
      "title": "Machine Learning Book Classification",
      "url": "https://www.udemy.com/course/machine-learning-book-classification/",
      "bio": "How To Deploy Machine Learning Model In Django",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Project Demonstration And Description"
        ],
        "Loading Datase And Exploration": [
          "Loading Dataset",
          "Data Exploration"
        ],
        "Feature Extraction And Fit The Model": [
          "Feature Extraction And Split Dataset",
          "Fit The Model And Checking Accuracy"
        ],
        "Making Predictions": [
          "Making Prediction Book's Phrase",
          "Dump And Load The Model",
          "Making Prediction of Books"
        ],
        "Model Deployment": [
          "Deploying Model On Django Framework"
        ]
      },
      "requirements": [
        "Python, Django And Machine Learning Basics"
      ],
      "description": "Become Artificial Intelligence Engineer.\n\n\nThis is a step-by-step course on how to create book classification using machine learning. It covers Numpy, Pandas, Matplotlib, Scikit learns, and Django, and at the end predictive model is deployed on Django. Most of the things machine learning beginners do not know is how they can deploy a created model. How to put created model into the application? The training model and get 80%, 85%, or 90% accuracy does not matter. As Artificial Intelligence Engineer you should be able to put created model into the application.\n\n\nActually, learning how to deploy a Machine Learning model created by machine learning is a big win for you and is a motivating effect towards improving, embracing, and learning machine learning. The piece me off when I hear people saying Artificial Intelligence is not really. It is just a theoretical study. Let's learn together how to deploy models, solve people’s problems and change people's minds about Artificial Intelligence.\n\n\nAt the end of this course, you will become Artificial Intelligence by your ability to put created models into the application and solve people's problems. Not only that you will be exposed to a few concepts of Django which are Python web framework and current trending web framework. By understanding Django, you will be able to deploy the previously created model you could not in the previous time.",
      "target_audience": [
        "Python Developers interested with machine learning"
      ]
    },
    {
      "title": "Logistic Regression for Beginners",
      "url": "https://www.udemy.com/course/logistic-regression-for-beginners/",
      "bio": "Understand the key components of logistic regression and develop a logistic regression model using SAS",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Students or anyone taking this course should have some familiarity with SAS. There are no basic skills required to take this course."
      ],
      "description": "Logistic regression is also known as logit regression or logit model. This is used to find the probability of event success and event failure. Logistic regression determines the relationship between categorical dependent variable and one or more independent variables using a logistic function.\nLogistic regression is used for predicting the probability of occurrence of an event by fitting the data to a logistic curve. Ordinary Least Squares on the other hand is an important computational problem that is used in applications when there is a need to use a linear mathematical model to measurements which are derived from the experiments. OLS takes various forms like Correlation, multiple regression, ANOVA and others. Logistic regression is most widely used in the field of medical science whereas OLS is mostly used in social sciences.\nIn this chapter we will see the comparison of logistic regression with OLS. Two methods are used to compare the results of both – Dropout study and High School and Beyond Study. There are many types of logistic models but this chapter will deal with the basic three types of logistic regression models – Binary, ordinal and nominal models.\nBinary logistic regression is where a binary response variable is related to a set of explanatory variables which are discrete or continuous.\nMultinomial logistic regression explains how a multinomial response depends on a set of explanatory variables. The polytomous response can be either or ordinal or nominal. There are few models which suits ordinal response like cumulative logit model, adjacent categories model and continuation ratios model. The other models can be used for both ordinal or nominal response.",
      "target_audience": [
        "Researchers, Forensic statisticians, Data Miners, Environmental Scientists, Epidemiologists",
        "Anyone who is interested in modeling data and estimate the probabilities of given outcomes."
      ]
    },
    {
      "title": "KI Automation: Erstelle LLM-Apps & AI-Agenten mit n8n & APIs",
      "url": "https://www.udemy.com/course/ki-automation-erstelle-llm-apps-ai-agenten-mit-n8n-apis/",
      "bio": "Automatisiere alles: n8n, LLMs, OpenAI API, Deepseek, Ollama & RAG! Business & Private AI Agenten – mehr als nur ChatGPT",
      "objectives": [
        "Grundlagen von Automationen, KI-Agenten & LLMs (ChatGPT, Claude, Gemini, Deepseek, Llama, Mistral & mehr)",
        "Einführung in Automationen & die wichtigsten Tools (n8n, Make, Zapier, LangChain, LangGraph, Flowise)",
        "APIs verstehen & für Automatisierungen nutzen",
        "OpenAI API: Preisstruktur, DSGVO-konformes Arbeiten & Projekt-Setup",
        "Function Calling bei LLMs: Nutzung von Kalender, Mails, Websuche, Webhooks, Airtable, Google Sheets & mehr",
        "Alles zu Vektordatenbanken, Embedding-Modelle & Retrieval-Augmented Generation (RAG)",
        "Grundlagen von n8n: Installation, Workflows importieren, exportieren & verkaufen",
        "Automatisierungen mit Airtable, Google Sheets & Google Cloud",
        "Einfache JavaScript-Variablen in Automationen nutzen",
        "KI-Automationen mit LLMs erweitern: E-Mail-Automatisierung, Sentiment-Analyse, Datenbanken",
        "Open-Source-LLMs (Deepseek R1, Llama, Mistral) in Automationen integrieren",
        "Nutzung externer LLM-APIs in n8n (Deepseek API, Groq API & mehr)",
        "KI-Agenten & RAG-ChatBots in Workflows einbinden",
        "Automatisierte Vektordatenbank-Updates mit Google Drive",
        "RAG-Chatbot mit AI-Agent-Node, Embeddings & Retrieval-Techniken",
        "KI-gestützte E-Mail-Agenten für automatische Zusammenfassungen & Antworten",
        "Prompt Engineering: Prinzipien, Best Practices & Fehlervermeidung",
        "n8n self-hosting mit Render & weiteren Optionen",
        "KI-Agenten in WhatsApp, Telegram & Social Media nutzen",
        "Web Scraping & Automatisierungen mit Sub-Workflows & Webhooks",
        "Debugging-Strategien für fehlerfreie n8n-Automationen",
        "Flowise-KI-Agenten mit Webhooks & Google Sheets verbinden",
        "n8n mit Flowise & JavaScript-Custom-Tools erweitern",
        "KI-Automatisierung als Business: Verkauf von Automationen & KI-Agenten",
        "Erstellung marktreifer RAG-Bots für Lead-Generierung & Webseiten-Integration",
        "Marketingstrategien für den erfolgreichen Verkauf von KI-Lösungen",
        "Optimierung von RAG-Chatbots: Chunk Size, Overlap & Datenqualität",
        "LlamaIndex & LlamaParse für Data Preprocessing in Google Colab",
        "Firecrawl für Web-Datenextraktion in Markdown-Format nutzen",
        "Sicherheit, Datenschutz & ethische Fragen: Jailbreaks, Prompt Injections & Data Poisoning",
        "Copyrights & Datenschutz für KI-generierte Daten einhalten",
        "Rechtliche Rahmenbedingungen: DSGVO & EU AI-Act"
      ],
      "course_content": {
        "Einführung": [
          "Willkommen!",
          "Kurs Überblick",
          "Wichtige Tipps für den Kurs",
          "Erklärung der Links",
          "Wichtige Links",
          "Dozentenvorstellung: Arnold Oberleiter (Arnie)"
        ],
        "Basics: Automationen, LLMs, Function Calling, Vektordatenbanken & RAG erklärt": [
          "Das erwartet dich in diesem Abschnitt",
          "Was sind Automationen, KI-Automatisierung und KI-Agenten?",
          "Was ist eine API?",
          "Tools für Automatisierungen & Agenten: n8n, Make, Zapier, LangChain, Flowise usw",
          "LLMs erklärt: ChatGPT, Claude, Gemini, Deepseek, Llama, Mistral & mehr",
          "OpenAI API erklärt: Preise, Projekt-Setup, Verwaltung & DSGVO",
          "Test Time Compute erklärt: \"denkende Modelle\" wie Deepseek R1 & OpenAI o1.",
          "Function Calling bei LLMs: Wie Agenten Werkzeuge nutzen",
          "Vektordatenbanken, Embedding-Modelle und Retrieval-Augmented Generation (RAG)",
          "Die wichtigsten Erkenntnisse"
        ],
        "Die Basics von n8n: Installation, Interface und erste einfache Workflows": [
          "Worum geht es in diesem Abschnitt?",
          "Lokale Installation von n8n mit Node.Js und das Interface",
          "n8n-Updates machen lokal über Node.js",
          "Node-Versionen verwalten (Fehler bei n8n-Installation beheben)",
          "n8n kostenlos testen ohne lokale Installation",
          "Erste Automation: Buchungen automatisch in Airtable speichern",
          "Workflows als JSON importieren, exportieren oder verkaufen",
          "Airtable-Daten automatisch lokal sichern",
          "Google Cloud Platform Console: Nicht unbedingt nötig",
          "Google Sheets mit n8n verbinden",
          "Recap"
        ],
        "Automationen mit LLMs und KI erweitern": [
          "Inhalt dieses Abschnitts: Ein kurzer Überblick",
          "E-Mail-Automation von Kundenbuchungen mit KI & ChatGPT: Gmail, Airtable, OpenAI",
          "Sentiment-Analyse mit LLMs & Speichern in Airtable: n8n Automation, OpenAI API",
          "Open-Source-LLMs mit Ollama nutzen: Deepseek R1, Llama, Mistral & mehr",
          "Jedes LLM über APIs in n8n integrieren: Deepseek API, Groq API & mehr",
          "Recap"
        ],
        "KI-Agenten und Rag-ChatBots in deinen Automationen & Email-Automation": [
          "Das erwartet dich in diesem Abschnitt",
          "RAG-Agent (Teil 1): Automatische Updates der Vektordatenbank mit Google Drive",
          "Probleme bei Pinecone Embeddings",
          "RAG-Chatbot (Teil. 2): AI-Agent-Node, Vektordatenbank, Embeddings & Co.",
          "E-Mail-Agent mit Sub-Workflows, Vektordatenbank, Google Sheets und mehr",
          "E-Mails-Agent: Alle neuen Mails automatisch zusammenfassen mit LLMs",
          "KI-gestützte E-Mail-Automation: Nachrichten filtern & automatisch antworten",
          "Der schnellste Weg zum E-Mail-Agenten (jetzt kopieren!)",
          "Dieses Update macht Javascript Variablen zum Kidnerspiel",
          "Recap und Arbeitsaufgabe"
        ],
        "Prompt Engineering für KI-Agenten und KI-Automatisierungen": [
          "Prompt Engineering für KI-Agenten und KI-Automatisierungen",
          "Prompt Engennering: Die wichtigsten Punkte"
        ],
        "n8n-Hosting & Tool-Integration: Telegram, Kalender, Web Scraping & mehr": [
          "Das erwartet dich in diesem Abschnitt",
          "n8n hosten: Self-Hosting mit Render & weitere Optionen",
          "KI-Agenten und Automationen in WhatsApp integrieren",
          "Telegram automatisieren: KI-Agenten & Sub-Workflows nutzen",
          "Telegram-Agent: E-Mails, Kalender & mehr per Sprache und Text automatisieren",
          "Sicherheitsprobleme mit Telegram in n8n",
          "OpenAI Bild-API in n8n durch HTTP Request: 4o Image Generation mit gpt-image-1",
          "Erweiterungen & Praxisbeispiele: Social Media Automation, Sub-Workflows & mehr",
          "Recap"
        ],
        "n8n-Workflows debuggen & in andere Apps integrieren": [
          "Das erwartet dich hier: Debugging und n8n aus anderen Apps steuern",
          "Fehler in n8n-Workflows finden mit dieser Automatisierungn (n8n-debuggen)",
          "Flowise-KI-Agent & n8n-Webhook: Google Sheets mit JavaScript integrieren",
          "Recap"
        ],
        "Mit KI-Automation und AI-Agents ein Business aufbauen": [
          "Inhalt dieses Abschnitts: AI-Automation als Business",
          "Welche KI-Automatisierungen und Agenten kann man verkaufen?",
          "Marktreifer RAG-Bot zur Lead-Generierung (Erstellung mit n8n & Google Sheets)",
          "RAG-Lead-Bot als Standalone-App mit einer veröffentlichten URL",
          "RAG-Bot in Webseiten integrieren: HTML, WordPress & individuelles CSS Branding",
          "Automatisierungen & KI-Agenten verkaufen: Marketing, Angebot, Verkauf & mehr",
          "Zusammenfassung & zusätzliche Tipps"
        ],
        "RAG-Chatbots optimieren Datenqualität, Chunk Size, Overlap & mehr": [
          "RAG-Chatbots optimieren: Datenqualität, Chunk Size, Chunk Overlap & mehr",
          "Firecrawl: Webseiten in Markdown umwandeln & optimale Chunk Size/Overlap wählen",
          "HTML zu Markdown (Firecrawl Alternative)",
          "LlamaIndex & LlamaParse: Datenaufbereitung & Zusammenfassung in Google Colab",
          "LlamaParse online nutzen – ohne Google Colab",
          "Recap"
        ]
      },
      "requirements": [
        "Keine Vorkenntnisse nötig, alles wird Schritt für Schritt gezeigt"
      ],
      "description": "KI-Automatisierung ist die Zukunft! Doch wie funktioniert sie wirklich? Und wie können KI-Agenten Geschäftsprozesse optimieren – auf einem völlig neuen Level, weit über ChatGPT hinaus? Es geht mit AI Agenten.\nDieser Kurs führt dich durch die essenziellen und fortgeschrittenen Konzepte von Automationen mit KI-Agenten, LLMs, Vektordatenbanken, RAG und n8n. Lerne, wie du Automationen aufbaust, KI-Agenten entwickelst und diese in Workflows integrierst, um dein Business oder deine privaten Projekte zu entwickeln.\nWas dich in diesem Kurs erwartet:\nGrundlagen von Automationen, KI-Agenten & LLMs\nTauche in die Welt der KI-Automatisierung ein:\nEinführung in Automationen, KI-Agenten & die wichtigsten Tools (n8n, Make, Zapier, LangChain, LangGraph, Flowise).\nVerständnis von APIs und deren Einsatz in Automatisierungen.\nLLMs erklärt: ChatGPT, Claude, Gemini, Deepseek, Llama, Mistral & mehr.\nOpenAI API: Preisstruktur, DSGVO-konformes Arbeiten & Projekt-Setup.\nFunction Calling bei LLMs: Wie KI-Agenten Werkzeuge wie Kalender, Mails, Websuche, Webhooks, Airtable, Google Sheets und vieles mehr nutzen können.\nRAG (Retrieval-Augmented Generation): Vektordatenbanken & Embeddings verständlich erklärt.\nn8n Basics: Installation & erste Workflows\nErlerne die Grundlagen von n8n – der Schlüssel zur intelligenten Automatisierung:\nLokale Installation mit Node.js & Web-Version ohne Installation nutzen.\nWorkflows importieren, exportieren oder verkaufen.\nAutomatisierungen mit Airtable, Google Sheets & Google Cloud einrichten.\nEinfache JavaScript-Variablen\nKI-Automationen mit LLMs erweitern\nBaue erweiterte Automationen mit KI:\nE-Mail-Automatisierung mit OpenAI API, Gmail und Airtable.\nSentiment-Analyse in Echtzeit & Speicherung in Datenbanken.\nOpen-Source-LLMs (Deepseek R1, Llama, Mistral) in Automationen integrieren.\nJeder LLM über APIs in n8n nutzbar machen (Deepseek API, Groq API & mehr).\nKI-Agenten & RAG-ChatBots in Workflows einbinden\nAutomatisiere Kundenkommunikation & Datenverarbeitung:\nRAG-Agent: Automatische Vektordatenbank-Updates mit Google Drive.\nRAG-Chatbot mit AI-Agent-Node, Embeddings & Retrieval-Techniken.\nKI-gestützte E-Mail-Agenten für automatische Zusammenfassungen & Antworten.\nPrompt Engineering für KI-Agenten\nVerstehe, wie du Prompts für optimale KI-Antworten optimierst:\nPrinzipien & Best Practices für effektives Prompt Engineering.\nFehler vermeiden & präzise Steuerung der KI-Outputs.\nn8n-Hosting & Integration mit Telegram, Web Scraping & mehr\nErweitere Automationen mit Hosting & Echtzeit-Integrationen:\nn8n self-hosting mit Render und weiteren Optionen.\nAutomationen & KI-Agenten in WhatsApp und Telegram nutzen.\nSocial Media Automationen mit Sub-Workflows, Webhooks & Web Scraping.\nn8n-Workflows debuggen & API-Integration optimieren\nFehleranalyse & Steuerung von Workflows aus anderen Apps:\nDebugging-Strategien für fehlerfreie n8n-Automationen.\nFlowise-KI-Agenten mit Webhooks in Google Sheets integrieren und n8n mit Flowise durch JavaScript-Custom-Tools verknüpfen.\nMit KI-Automation & AI-Agenten ein Business aufbauen\nNutze dein Wissen für den Aufbau eines Geschäfts:\nVerkaufen von Automatisierungen & KI-Agenten als Dienstleistungen.\nErstellung marktreifer RAG-Bots für Lead-Generierung & Webseiten-Integration.\nMarketing-Strategien für den erfolgreichen Verkauf von KI-Lösungen.\nRAG-Chatbots optimieren: Datenqualität & Chunking\nVerbessere KI-Antworten mit optimierten Datenstrategien:\nRAG-Chatbots optimieren: Chunk Size, Overlap & Datenqualität.\nFirecrawl für Web-Datenextraktion in Markdown-Format nutzen.\nLlamaIndex & LlamaParse für Data Preprocessing in Google Colab.\nSicherheit, Datenschutz & ethische Fragen\nSchütze deine KI-Agenten vor Angriffen & stelle DSGVO-Konformität sicher:\nJailbreaks, Prompt Injections & Data Poisoning verstehen & verhindern.\nCopyrights & Datenschutz für KI-generierte Daten einhalten.\nDie wichtigsten rechtlichen Rahmenbedingungen: DSGVO & EU AI-Act.\nWerde ein Experte für KI-Agenten & Automatisierungen!\nNach diesem Kurs wirst du ein tiefgehendes Verständnis für KI-Automationen, n8n, LLMs & RAG haben und in der Lage sein, leistungsfähige KI-Agenten zu entwickeln, zu optimieren und für Business-Anwendungen einzusetzen.\nMelde dich jetzt an und tauche in die Zukunft der KI-Automation ein.",
      "target_audience": [
        "An Unternehmer die effizienter werde wollen, Geld sparen möchten oder ein KI-Business aufbauen wollen",
        "An alle, die etwas neues lernen wollen und tief in KI-Automatisierung einblicken wollen",
        "Privarpersonen, die an KI und Automatisierung interessiert sind und eigene Agenten bauen möchten",
        "Jeder, der Aufgaben automatisieren will"
      ]
    },
    {
      "title": "Le Deep Learning de A à Z",
      "url": "https://www.udemy.com/course/le-deep-learning-de-a-a-z/",
      "bio": "Apprenez à créer des algorithmes de Deep Learning en Python par des experts en Machine Learning & Data science.",
      "objectives": [
        "Comprendre l'intuition derrière les réseaux de neurones artificiels",
        "Comprendre l'intuition derrière les réseaux de neurones à convolution",
        "Comprendre l'intuition derrière les réseaux de neurones récurrents",
        "Comprendre l'intuition derrière les cartes auto adaptives",
        "Comprendre l'intuition derrière les machines de Boltzmann",
        "Comprendre l'intuition derrière les auto encodeurs",
        "Appliquer les réseaux de neurones artificiels en pratique",
        "Appliquer les réseaux de neurones à convolution en pratique",
        "Appliquer les réseaux de neurones récurrents en pratique",
        "Appliquer les cartes auto adaptives en pratique",
        "Appliquer les machines de Boltzmann en pratique",
        "Appliquer les auto encodeurs en pratique"
      ],
      "course_content": {
        "Bienvenue": [
          "Qu'est-ce que le Deep Learning ?",
          "Installation de Python",
          "Comment avoir les données et lectures additionnelles",
          "IMPORTANT : Mise à jour du code"
        ],
        "-------------------- CHAPITRE 1 - ANN (Artificial Neural Networks) -------------": [
          "Bienvenue dans le Chapitre 1 - Réseaux de neurones artificiels"
        ],
        "ANN - Intuition": [
          "Plan d'attaque",
          "Le Neurone",
          "La fonction d'activation",
          "Comment fonctionnent les Réseaux de Neurones ?",
          "Comment apprennent les Réseaux de Neurones ?",
          "Algorithme du Gradient",
          "Algorithme du Gradient Stochastique",
          "Rétropropagation"
        ],
        "Construire un ANN": [
          "Pré-requis",
          "Comment avoir les données",
          "Description du problème",
          "Instructions d'installation des modules",
          "Construire un ANN - Étape 1",
          "Construire un ANN - Étape 2",
          "Construire un ANN - Étape 3",
          "Construire un ANN - Étape 4",
          "Construire un ANN - Étape 5",
          "Construire un ANN - Étape 6",
          "Construire un ANN - Étape 7",
          "Construire un ANN - Étape 8",
          "Construire un ANN - Étape 9",
          "Construire un ANN - Étape 10"
        ],
        "Travaux Pratiques : Devrait-on dire au revoir à ce client ?": [
          "Instructions",
          "Solution"
        ],
        "Évaluer, améliorer et ajuster l'ANN": [
          "Évaluer l'ANN",
          "Améliorer l'ANN",
          "Ajuster l'ANN"
        ],
        "Travaux Pratiques - Faites-moi perdre une place au podium": [
          "Instructions"
        ],
        "-------------------- CHAPITRE 2 - CNN (Convolutional Neural Networks) ----------": [
          "Bienvenue dans le chapitre 2 - Réseaux de neurones à convolution"
        ],
        "CNN - Intuition": [
          "Plan d'attaque",
          "Que sont les Réseaux de Neurones à Convolution ?",
          "Étape 1 - Convolution",
          "Étape 1b - Couche ReLU",
          "Étape 2 - Pooling",
          "Étape 3 - Flattening",
          "Étape 4 - Complètement connecté",
          "Récap",
          "Fonction softmax et entropie croisée"
        ],
        "Construire un CNN": [
          "Comment avoir les données",
          "Introduction aux CNNs",
          "Construire un CNN - Étape 1",
          "Construire un CNN - Étape 2",
          "Construire un CNN - Étape 3",
          "Construire un CNN - Étape 4",
          "Construire un CNN - Étape 5",
          "Construire un CNN - Étape 6",
          "Construire un CNN - Étape 7",
          "Construire un CNN - Étape 8",
          "Construire un CNN - Étape 9",
          "Construire un CNN - Étape 10"
        ]
      },
      "requirements": [
        "Seulement un niveau mathématique de niveau lycée"
      ],
      "description": "Le domaine de l'intelligence artificielle est en pleine croissance. Entre les voitures autonomes qui ont déjà roulé des millions de kilomètres, IBM Watson qui produit de meilleurs diagnostics que des armées de médecins, ou le robot Alpha Go de l'équipe Deepmind de Google qui bat le champion du monde de Go, il n'y a plus de doute sur l'explosion de ce nouveau domaine.\nMais plus le domaine de l'IA progresse, plus les problèmes qu'on cherche à résoudre sont compliqués. Seul le Deep Learning peut résoudre des problèmes aussi complexes, ce qui explique pourquoi on le retrouve au cœur des recherches en intelligence artificielle.\n--- Pourquoi Deep Learning de A à Z ? ---\nIl y a cinq raisons qui font que le cours Deep Learning de A à Z est différent et sort du lot en comparaison des autres cours qu'on peut trouver ici et là :\n\n1. STRUCTURE ROBUSTE\nLa chose la plus importante sur laquelle nous nous sommes concentrés est de donner au cours une structure robuste. Le Deep Learning est un domaine très large et complexe, ce qui le rend difficile à approcher.\n\nC'est pourquoi nous avons regroupés les leçons en deux grosses parties, représentant les deux branches fondamentales du Deep Learning : Le Deep Learning supervisé et le Deep Learning non supervisé. Ensuite, chaque partie est divisée en trois algorithmes distincts. Nous avons déterminé qu'il s'agissait de la meilleure structure pour apprendre le Deep Learning.\n2. LEÇONS INTUITIVES\nLa plupart des cours et livres commencent directement par la théorie, puis des maths, puis du code... Sauf qu'ils oublient d'expliquer ce qui est peut-être le plus important : pourquoi vous faites ce que vous faites. Pas dans Deep Learning de A à Z. On se focalise d'abord sur l'intuition des concepts derrières les algorithmes.\nGrâce à ces leçons intuitives, vous arriverez beaucoup plus facilement à comprendre les techniques. Par la suite, lorsque vous passerez aux leçons plus orientées pratique avec du code, vous visualiserez aisément chaque étape des algorithmes et surtout pourquoi vous devez exécuter chaque étape.\n3. PROJETS PASSIONNANTS\n\nN'en avez-vous pas marre de retrouver tout le temps les mêmes jeux de données constamment dans tous les cours ?\n\nÇa en devient lassant.\nC'est pourquoi dans ce cours nous avons choisi d'utiliser des jeux de données réels et de résoudre de vrais problèmes réels. (Pas comme les données de fleurs d'iris ou le super classique exemple de classification de chiffre comme on voit partout). Dans ce cours, on va résoudre six problèmes :\nComment prédire le départ d'un client grâce aux Réseaux de Neurones Artificiels.\nComment reconnaître des images grâce aux Réseaux de Neurones à Convolution.\nComment prédire le prix d'une action grâce aux Réseaux de Neurones Récurrents.\nComment réaliser une enquête de fraude grâce aux Cartes Auto Adaptives.\nComment créer un système de recommandation grâce aux Machines de Boltzmann.\nComment gagner le prix Netflix de 1 million de $ grâce aux auto encodeurs empilés*.\n*Les auto-encodeurs sont une technique de Deep Learning très récente qui n'existait pas il y a quelques années encore. Cette méthode n'est jamais expliquée suffisamment en détail.\n4. EXERCICES DE CODE\nDans Deep Learning de A à Z, on code avec vous. Chaque leçon pratique démarre avec une page blanche, et ensemble on progresse ligne par ligne afin que vous puissiez suivre et comprendre chaque étape du code.\n\nDe plus, le code est structuré de telle manière que vous pouvez facilement le télécharger et l'appliquer directement sur vos propres projets. Nous vous expliquons comment vous pouvez changer le code pour l'adapter à VOS données, ou comment optimiser les algorithmes pour vos besoins afin que vous obteniez les résultats que vous recherchez.\nCe cours a donc une application directe pour votre carrière professionnelle.\n5. SOUTIEN DIRECT\nAvez-vous déjà suivi un cours ou lu un livre où vous avez des tonnes de questions... qui restent sans réponse ?\n\nEh bien ce n'est pas le cas de cours. Nous nous engageons à faire de ce cours le meilleur cours de Deep Learning sur la planète. Avec cet engagement vient la responsabilité d'être là constamment pour vous quand vous avez besoin d'aide.\nComme nous avons aussi une vie et des clients, une équipe de Data Scientists professionels est là pour vous aider. Posez une question, et vous obtiendrez une réponse dans les 48 heures maximum, peu importe la complexité de votre problème.\nNous sommes là pour assurer votre succès et votre réussite.\n--- Les outils ---\nTensorflow et PyTorch sont les outils open-source les plus utilisés en Deep Learning. Dans ce cours, vous apprendrez à utiliser les deux !\n\nTensorflow a été développé par Google et est utilisé par exemple dans leur système de reconnaissance vocale, dans Google Photos, Gmail, Google Search, et dans pas mal d'autres applications. De nombreuses entreprises utilisent Tensorflow, comme AirBnB, Airbus, eBay, Intel, Uber, et des centaines d'autres.\nPyTorch est tout aussi puissant et a été développé par des chercheurs chez Nvidia et dans les universités de Stanford, Oxford, et ParisTech. Des entreprises comme Twitter, Saleforce ou Facebook utilisent PyTorch.\nAlors, lequel est meilleur et pourquoi ?\nDans ce cours, vous apprendrez justement à utiliser les deux et donc dans quelles situations Tensorflow ou PyTorch est plus adapté. Au fur et à mesure des leçons, nous allons comparer les deux et vous donnez des astuces et idées pour retenir quand les utiliser.\nCes outils sont encore très récents et ont été créé il y a tout juste deux ans. C'est de ça dont on parle quand on vous dit que ce cours utilise les outils de Deep Learning les plus à la pointe de la technologie !\n--- Encore plus d'outils ---\nTheano est un autre outil open-source pour le Deep Learning. Il est similar à Tensorflow dans son usage, mais nous en parlerons tout de même.\nKeras est une librairie qui permet d'implémenter les modèles de Deep Learning. Elle regroupe à la fois Theano et Tensorflow et permet en juste quelques lignes de code de créer des modèles puissants et complexes de Deep Learning. C'est ce qui vous permettra d'avoir une vision globale de ce que vous créez. Le code que vous produirez sera clair et structuré grâce à cette librairie, ce qui vous permettra d'avoir une bonne intuition et une excellente compréhension de ce que vous faites.\n--- Plus plus plus d'outils ! ---\nScikit-learn est la librairie de Machine Learning par excellence. On l'utilisera :\npour évaluer la performence de nos modèles avec la meilleure technique : la validation croisée à k couches (k-fold cross validation).\npour améliorer nos modèles en optisimant les paramètres.\npour préparer nos données afin que nos modèles puissent apprendre dans les meilleures conditions.\nÉvidemment, n'oublions pas de nommer Python, qui est l'outil sur lequel ce cours est basé. Chaque section vous donnera des heures et des heures de pratique dans ce langage.\nDe plus, ce cours utilise Numpy pour réaliser les calculs mathématiques et manipuler des tableaux multidimensionnels, ainsi que Matplotlib pour tracer des graphes et visualiser nos résultats, puis Pandas pour importer et manipuler les jeux de données de manière efficace.\n--- À qui s'adresse ce cours ? ---\nComme vous avez pu le remarquer, il y a de nombreux outils dans le monde du Deep Learning. Dans ce cours, nous avons tenu à vous montrer les plus importants de manière progressive de telle manière à ce que vos connaissances en Deep Learning soient à la pointe à la fin du cours.\n\nSi vous êtes complètement débutant en Deep Learning, alors vous trouverez ce cours particulièrement utile. Deep Learning de A à Z est stucturé de telle manière que vous ne vous retrouverez pas coincé par du code non nécessaire ou des complexités mathématiques absurdes. L'idée est de commencer à appliquer les techniques de Deep Learning au plus vite dans le cours et d'apprendre rapidement à partir de zéro. Chaque leçon vous rendra peu à peu plus confiant dans vos capacités.\nSi vous avez déjà une expérience en Deep Learning, alors vous trouverez dans ce cours des rappels inspirants et très orientés pratique. Grâce à Deep Learning de A à Z, vous maîtriserez les algorithmes de pointe (dont certains n'existaient même pas encore il y a deux ans) et acquérerez une expérience pratique sur des challenges issus du monde réel. Les applications vous donneront de l'inspiration pour explorer plus avant vos compétences en Deep Learning.\n\n--- Études de cas du monde réel ---\nMaîtriser les techniques de Deep Learning ne consiste pas juste en connaître l'intuition et les outils. Il s'agit aussi d'être capable d'appliquer ce que vous apprenez sur des situations réels afin d'en sortir des résultats mesurables et utiles. C'est pourquoi ce cours vous guidera au travers de six challenges passionnants :\n\n#1 Prédiction du départ d'un client\nDans cette partie, nous vous présenterons des données provenant de la base de données d'une banque souhaitant prédire si un client lui restera fidèle dans les six prochains mois ou non. Les données consistent en un identifiant, le score de crédit, le sexe, l'âge, si le client a une carte de crédit, etc. Pendant six mois, la banque a accumulé des données sur ces clients.\n\nÀ présent, votre objectif est de créer un réseau de neurones artificiel qui peut prédire, grâce aux données démographiques, géographiques et transactionnelles fournies, si un client quittera la banque ou non. Dans ce problème, votre employeur vous a aussi demandé d'établir un classement entre les clients pour savoir lesquels ont la plus grande probabilité de partir. Pour répondre à ce problème, vous utiliserez un modèle de Deep Learning qui est basé sur une approche probabilistique.\nSi vous arrivez au bout de ce projet, vous permettrez à la banque d'adapter directement ses offres pour les clients qui risquent de partir. Grâce à votre modèle de Deep Learning, la banque pourra donc réduire ses départs de clients.\n#2 Reconnaissance d'image\nDans cette partie, vous créerez un réseau de neurones à convolution qui est capable de détecter des objets dans une image. Nous utiliserons un modèle de Deep Learning capable de reconnaître un chat d'un chien. Au-delà de cette problématique, ce modèle sera capable de se généraliser et de détecter n'importe quel objet (nous vous montrerons comment) simplement en changeant les images qu'on lui donne en entrée.\n\nPar exemple, vous pourrez ré-utiliser le modèle sur un ensemble d'images de cerveau pour détecter si l'image contient une tumeur ou non. Mais si vous préférez rester sur les petits chats et les petits chiens, alors vous pourrez vous amuser à prendre une photo de votre petit animal préféré et votre modèle arrivera à prédire s'il s'agit d'un chien ou d'un chat. Nous l'avons nous-mêmes testé !\n#3 Prédiction du prix d'une action\nDans cette partie, vous créerez l'un des modèles de Deep Learning les plus puissants. En fait, il s'agit du modèle le plus proche de l'intelligence artificielle. Pourquoi ? Parce que ce modèle a une mémoire à long terme, exactement comme nous les êtres humains.\nCette branche du Deep Learning comprend les réseaux de neurones récurrents. Les RNNs classiques ont une mémoire à court terme et n'ont jamais été très populaires à cause de ça. Mais récemment des améliorations dans les réseaux de neurones récurrents ont donné naissance aux LSTMs (RNNs à large mémoire court-terme) qui ont complètement changé la donne.\nAinsi, vous apprendrez à implémenter ce modèle très puissant au travers d'un challenge consistant à prédire le prix réel de l'action Google. Des chercheurs de l'université de Stanford ont travaillé sur ce challenge aussi et nous essaierons de faire aussi bien qu'eux.\n#4 Détection de fraude\nUne étude récente de Markets & Markets a estimé que le marché de détection et prévention de la fraude atteindrai 33,19 milliards de $ en 2021. C'est une industrie énorme et la demande en compétences avancées de Deep Learning ne peut que continuer à croître.\n\nLe challenge sera de détecter les cas de fraudes dans les demandes de cartes de crédit. Vous créerez un modèle de Deep Learning pour une banque à partir d'un jeu de données contenant des informations sur les clients demandant une carte de crédit spéciale.\nCes donnéens client vous permettront de détecter une fraude potentielle dans les demandes. À la fin du challenge, vous serez capable de sortir une liste explicite de clients qui ont potentiellement triché en remplissant leurs formulaires de demande.\n#5 & 6 Systèmes de recommandation\nEntre les suggestions de produits Amazon et les recommandations de films de Netflix, on voit de plus en plus de systèmes de recommandation fleurir un peu partout. Les spécialistes qui les créent font partie des Data Scientists les mieux payés de la planète.\n\nNous travaillerons sur un jeu de données qui a exactement les mêmes caractéristiques que les données Netflix : une tonne de films, des milliers d'utilisateurs, et les notes qu'ils donnent sur les films qu'ils ont regardés. Les notes vont de 1 à 5, exactement comme dans la compétition Netflix, ce qui rend le système de recommandation plus complexe que de simplement dire si l'utilisateur a \"aimé\" ou \"pas aimé\" le film.\nVotre système de recommandation sera capable de prédire les notes des films que les utilisateurs n'ont pas encore regardé. En classant les prédictions de 5 à 1, votre modèle de Deep Learning pourra ensuite recommender les films que chaque utilisateur sera le plus susceptible d'aimer. Créer un tel système de recommandation est un énorme challenge alors on le fera en deux essais, c'est-à-dire qu'on testera deux types de modèles de Deep Learning.\nLe premier modèle consiste en une machine de Boltzmann profonde et sera abordé dans le chapitre 5. En second modèle, on utilisera les auto-encodeurs. Les deux sont simples à comprendre, ce qui ne déduit rien de leur capacité.\nEnsuite vous pourrez directement appliquer votre système sur vous-même ou vos amis. La liste de films sera suffisamment complète pour que vous notiez les films que vous avez regardés, et il ne restera qu'à faire tourner le modèle pour savoir quel film regarder ! Votre système de recommandation sera la solution aux soirées où n'arrive pas à se décider à quoi regarder, et il continuera d'apprendre si vous lui dites si la recommandation lui a plu.\n--- En résumé ---\nCe cours est rempli de leçons intuitives et d'exercices pratiques pour s'exercer en situation réelle.\n\nNous avons voulu rendre ce cours le meilleur possible et nous sommes particulièrement enthousiastes à l'idée de le partager avec vous et vous voir progresser dans ce merveilleux monde du Deep Learning.\nKirill, Hadelin & Charles",
      "target_audience": [
        "Quiconque étant intéressé par le Deep Learning",
        "Les étudiants ayant un niveau lycée de mathématiques désirant apprendre le Deep Learning",
        "Les personnes connaissant les bases de Machine Learning ou de Deep Learning (les algos classiques comme la régression linéaire, la régression logistique et des sujets plus avancés comme les réseaux de neurones artificiels), mais désirant explorer plus avant le domaine du Deep Learning",
        "Quiconque n'étant pas à l'aise avec le code mais qui est intéressé par le Deep Learning et désire l'appliquer sur des jeux de données",
        "Les étudiants universitaires désirant démarrer une carrière en Data Science",
        "Les data analysts désirant améliorer leurs connaissances en Deep Learning",
        "Les personnes souhaitant changer de métier et devenir data scientist",
        "Les personnes souhaitant apporter plus de valeur à leur entreprise en utilisant la technologie du Deep Learning",
        "Les entrepreneurs désirant comprendre comment utiliser les outils de Deep Learning dans leur entreprise",
        "Les entrepreneurs désirant prendre l'avantage sur leurs compétiteurs dans leur industrie en utilisant les outils avancés de Deep Learning"
      ]
    },
    {
      "title": "Procesamiento de datos con Knime (desde Cero a Intermedio)",
      "url": "https://www.udemy.com/course/knime-cero-a-intermedio/",
      "bio": "Profundización en el mundo de la manipulación de datos con Knime.",
      "objectives": [
        "Aprenderás aspectos básicos y elaborados sobre la extracción, transformación y carga de datos a través de casos aplicados en Knime.",
        "Podrás importar y exportar datos desde archivos planos y bases de datos; aprenderás sobre agrupaciones, cruces de tablas, pivoteos, filtros, entre otros.",
        "Llevarás tus habilidades de Excel a otro nivel con la automatización de tareas rutinarias básicas utilizando Knime.",
        "Reducirás los tiempos de desarrollo en tus proyectos de datos a través del esquema gráfico de Knime.",
        "Abrirás la puerta a nuevas oportunidades laborales."
      ],
      "course_content": {
        "Introducción a Knime": [
          "¿Qué es Knime? algunas de sus principales fortalezas",
          "¿Cómo instalar y/o actualizar Knime?",
          "Nueva Interfaz de Knime, versión 5.X",
          "Conociendo la interfaz de Knime, trabajando con flujos y nodos",
          "Veamos qué tanto conoces al momento sobre Knime",
          "¿En qué consiste la automatización de tareas rutinarias a través de Knime?",
          "Importando y exportando flujos de trabajo en Knime",
          "Importando un flujo de trabajo hacia Knime"
        ],
        "Importar y exportar datos desde y hacia múltiples fuentes usando Knime": [
          "Datos Ordenados - Tidy Data",
          "Lectura de archivos planos en Knime (Excel, CSV, TXT, Otros)",
          "Introducción a los tipos de datos en Knime",
          "¿Cómo instalar extensiones en Knime?",
          "Instalando la extensión de PowerBI",
          "Lectura de Bases de Datos a través de Knime",
          "Exportando datos desde Knime a diversas fuentes",
          "Lectura de datos en bloque - consolidación de archivos"
        ],
        "Parte 1 - transformaciones de forma y datos en Knime (Nivel Básico)": [
          "Concatenado de tablas, row filter, row splitter, filtros por condición",
          "Ordenamiento de columnas y filas (métodos alternativos)",
          "Fórmulas matemáticas, renombrado de columnas, manejo de números",
          "Manipulación de Strings, Column Expressions, Concatenado y Split de textos",
          "Reglas condicionales usando Math Formula, Rule Engine y Column Expressions",
          "Limpieza datos Aeronáutica"
        ],
        "Parte 2 - transformaciones de forma y datos en Knime (Nivel Intermedio)": [
          "Manipulación de fechas en Knime",
          "Agregaciones y grupos usando el nodo GroupBy",
          "Pivoting y Unpivoting en Knime",
          "Trabajando con fechas, grupos y pivotes",
          "Manejo de datos duplicados en Knime",
          "Cruce de tablas con el nodo Joiner en Knime (Inner, Left, Right, Full Join)",
          "Cross Joiner en Knime",
          "Prorrateos utilizando la combinación de GroupBy y Joiner"
        ],
        "Metanodos, variables de flujo, documentación y siguientes pasos en Knime": [
          "Introducción a metanodos y componentes en Knime",
          "Uso de variables en Knime para escribir múltiples archivos en automático",
          "Compendio de buenas prácticas durante la construcción de flujos",
          "Siguientes pasos y recomendaciones de cierre"
        ]
      },
      "requirements": [
        "¡Este curso inicia desde cero! no requieres habilidades en otros lenguajes de programación, aquí te explicaremos los aspectos básicos de datos.",
        "¡Knime es una plataforma Open Source! no requieres una licencia de pago para lanzarte al agua.",
        "Si has trabajado antes con Excel u otra herramienta de datos, seguro sacarás el mayor provecho a este curso.",
        "La dedicación y práctica son indispensables para llevar este curso a buen puerto."
      ],
      "description": "¡Bienvenidos al apasionante mundo de los datos!\n\nKnime es una plataforma de ciencia de datos Open Source que integra el esquema de programación gráfica de bajo código (Low Code), facultando de esta manera a los usuarios de negocio para construir y desplegar soluciones de extracción, transformación y modelamiento de información, sin una dependencia estricta de lenguajes de programación.\nEn este curso de transformación de datos con Knime de básico a intermedio abordaremos los siguientes temas:\nInstalación de Knime y sus extensiones.\nInterfaz de Knime, espacio de trabajo, flujos de trabajo y nodos.\nCómo importar o exportar flujos de trabajo para compartir desarrollos.\nLectura de archivos planos y bases de datos en Knime (Excel, csv, txt, DB).\nTipos de datos en Knime.\nEscritura de datos fuera de Knime (archivos planos y bases de datos).\nTransformaciones de forma I (concatenado de archivos, filtros de filas, filtros de columnas, ordenamiento de datos).\nTransformaciones de datos I (renombrado de columnas, creación de columnas, fórmulas matemáticas, manipulación de cadenas de texto (strings).\nTransformaciones de forma II (agrupaciones, pivoting, unpivoting).\nTransformaciones de datos II (condicionales, reemplazo de valores, manipulación de fechas, manejo de datos duplicados)\nCruce de tablas - Joiner (teoría general y su aplicación en Knime).\nCross Joiner en Knime\nProrrateos a través de la combinación GroupBy - Joiner.\nIntroducción al uso de variables y loops en Knime\nUso de contenedores y metanodos para la organización de flujos.\nResumen de buenas prácticas y recomendaciones finales.\nLas sesiones teóricas están acompañadas de ejercicios prácticos con datos reales y diversos materiales de ayuda ,disponibles en el repositorio de información del curso. Los estudiantes deberán completar una serie de retos a lo largo del curso que facilitarán el desarrollo del pensamiento lógico para la resolución de problemas en Knime.",
      "target_audience": [
        "Estudiantes y profesionales que quieran iniciar su recorrido por el mundo apasionante de los datos.",
        "Usuarios de negocio que desean aumentar su productividad en un entorno gráfico, sin dependencias de lenguajes de programación.",
        "Analistas de datos, ingenieros en todas las ramas, estadísticos, matemáticos, economistas y profesionales que manipulan y analizan información."
      ]
    },
    {
      "title": "【PythonとStanで学ぶ】仕組みが分かるベイズ統計学入門",
      "url": "https://www.udemy.com/course/pythonstan/",
      "bio": "確率の基礎から出発し、ベイズ統計学の基礎およびMCMCの原理を学びます。概念の理解とPythonでのプログラミングへの実装を合わせる事で、動かしながら原理を理解できます",
      "objectives": [
        "統計学や確率の基礎的な知識の獲得から出発して、ベイズ統計が従来の統計学に比べて、どういう風に枠組みが異なるのかが理解できる",
        "ベイズ統計の基礎⇒モンテカルロ法の基礎⇒PyStanでの実際の問題への適用という一連の流れを体系的かつシームレスに理解できる",
        "”概念を理解する”⇒”理解したことをPythonで実装する”という流れを何度も行う事で、実践的なプログラミング能力と”アイデアをコードに具現化するにはどうする？”の発想が身に付く",
        "PyStanの為の環境の構築ができる。またPyStanを用いた基礎的なベイズ統計モデリングの流れを理解できる"
      ],
      "course_content": {
        "はじめに": [
          "コースの概要説明"
        ],
        "環境の構築【Python】": [
          "Anacondaのインストール【Windows編】",
          "Anacondaのインストール【Mac編】",
          "本コースで使用するデータ"
        ],
        "確率の基礎": [
          "このセクションで学ぶこと",
          "確率とは",
          "確率の基礎1【基礎的な用語・事象】",
          "確率の基礎2【平均値・分散】"
        ],
        "ベイズ統計学入門": [
          "このセクションで学ぶこと",
          "ベイズの考え方・ベイズの定理",
          "ベイズ統計の流れ",
          "ベイズ更新【概念の理解】",
          "ベイズ更新【実装】",
          "様々な確率分布",
          "自然共役事前分布",
          "MAP推定・無情報事前分布【概念の理解】",
          "MAP推定【実装】",
          "もっと自由なモデリングへ"
        ],
        "モンテカルロ法・MCMCの原理": [
          "このセクションで学ぶこと",
          "モンテカルロ法とは【概念の理解】",
          "モンテカルロ法とは【実装】",
          "棄却サンプリング【概念の理解】",
          "棄却サンプリング【実装】",
          "次元の呪い【概念の理解・実装】",
          "MCMCと定常分布【概念の理解】",
          "MCMCと定常分布【実装】",
          "詳細つり合いとは",
          "M-Hアルゴリズム【概念の理解】",
          "M-Hアルゴリズム【実装】",
          "Gibbsサンプラー【概念の理解】",
          "Gibbsサンプラー【実装】",
          "ハミルトニアンモンテカルロ1【概念の理解】",
          "ハミルトニアンモンテカルロ2【概念の理解】",
          "ハミルトニアンモンテカルロ3【概念の理解】",
          "Euler法とLeap-Flog法【概念の理解】",
          "Euler法とLeap-Flog法【実装】",
          "ハミルトニアンモンテカルロ【実装】"
        ],
        "PyStanでの統計モデリング": [
          "このセクションで学ぶこと",
          "PyStanとは",
          "環境の構築【Windows】PyStanのインストール",
          "環境の構築【Windowsのみ必要】Visual Studio2017のインストール",
          "環境の構築【Mac】PyStanのインストール",
          "グラフィカルモデルの基礎",
          "PyStanでのハローワールド【概念の理解】",
          "PyStanでのハローワールド【実装】",
          "単回帰【概念の理解】",
          "単回帰【実装】",
          "ベイズ信頼区間・予測区間",
          "ロジスティック回帰【概念の理解】",
          "ロジスティック回帰【実装】",
          "重回帰【概念の理解】",
          "重回帰【実装】",
          "階層ベイズ【概念の理解】",
          "階層ベイズモデル【実装(前半)】",
          "階層ベイズモデル【実装(後半)】",
          "状態空間モデル【概念の理解】",
          "状態空間モデル【実装】"
        ],
        "補講【Python】": [
          "Jupyter notebookの起動と終了",
          "Pythonミニマム1",
          "Pythonミニマム2",
          "Pythonミニマム3"
        ],
        "付録【物理】": [
          "まず初めに",
          "力学・解析力学の基礎1",
          "力学・解析力学の基礎2"
        ],
        "ボーナスレクチャー": [
          "このコースを学んだ後は",
          "講師が作成した他コースのクーポン",
          "このコースで使用した資料",
          "環境の構築【Windowsのみ必要】Visual C++ Build Toolsのインストール（旧）"
        ]
      },
      "requirements": [
        "ベイズ統計ではない統計学の知識(平均・標準偏差・期待値・分散など、一部に最尤推定、共分散など少し発展的な内容)",
        "Pythonの基本的な文法",
        "高校レベルの数学(集合・確率・数列・極限・微分・積分)",
        "大学レベルの数学(微分方程式) *MCMCの原理やハミルトニアンモンテカルロの原理まで理解したい方には必要"
      ],
      "description": "『ベイズ統計学、最近よく聞くけど、何だか難しそう。。』と思っていませんか？\n実際、ベイズ統計学は真面目にやろうとするとそんなに簡単ではありません。\n例えば、独学しようとベイズ統計学の教科書を紐解くと、統計学の知識を始めとして、高度な数学、MCMC、実際のコーディングなど幅広い知識を要求され、挫折する人も多いと思います。\nしかし、本コースはそのような様々な壁を乗り越えて、しっかりとしたベイズ統計学の基礎を身に付けたいという方を対象に確率の基礎から出発し、ベイズ統計学の基礎、MCMCの基礎、そしてPyStanの使い方など実用的なレベルまで段階的にレベルアップできる体系的また本格的なベイズ統計学の入門コースです。\n【まず始めに】\n本コースは原理からきっちりと理解する事を目指しているので、少なからず数式が出てきます。(あまり式変形も省略しておりません)\nベイズ統計学は一貫性と柔軟性、また解釈が容易という様々なメリットを備えた統計学ですが、逆にしっかりとした数学の土台と幅広い知識（確率・統計学、モンテカルロ法、高度な数学）が必要である事がデメリットです。\nもちろん、数式を使わなくてもフワッとした説明で概念は理解できますが、それでは実際のシーンでまず使えるようにはなりません。\nこの為、数式が多いと嫌という方は受講が難しいかもしれません*。(これは学問の性質上そうなので避けられません)\n*もちろん、私も受ける側の立場に立つと数式ばかり出るコースは嫌になるので、数式と合わせてグラフィカルなイメージを使って、数式の意味を解説します。\n本コースの活用の仕方にあるように、数式の難しそうな理論は置いておいて、\"取り合えず、Pythonの実装の部分だけ\"を受講するという受講の仕方もあると思います。\nまたこのコースでは実装にPythonというプログラミング言語を用いますが、Pythonの文法自体の解説はほぼなく、受講者はこの部分は予め習熟しておく必要があります。\n今まで、Pythonをやったことないがベイズ統計学を学びたい方ももちろんいらっしゃると思いますので、そういった方向けにPythonの文法については補講を設けております。ただ、Pythonを使った事のある方と比べれば自助努力が必要になることはご理解ください。\nまた前提が多くて申し訳ありませんが、一般的な統計学の知識（平均値、標準偏差、期待値・分散や一部で最尤推定、共分散、相関係数など）についても基本は身に付いている前提で話が進みます。(これらの意味から話を始めると講義のボリュームが大変な量になり、受講生が肝心のベイズ統計を学ぶころには疲れてしまう可能性が高いからです。ただ、一応、確率の基礎1,2という講義で簡単に復習を行います)\n\n\n【コースの概要】\n本コースは確率の基礎から出発し、ベイズ統計学の基礎を学びます。またベイズ統計学で必要になってくるモンテカルロ法やMCMCなどのアルゴリズムについても解説を行います。これらベイズ統計学の基礎や各アルゴリズムは概念の理解の後にPython上でアイデアを具現化する実装のパートが付いているのが、本コース最大の特徴といえます。そして、原理を理解した上で、MCMCの高速なライブラリであるStanをPythonから使用するPyStanというライブラリを用います。PyStanのパートでは環境構築から始まって、単回帰、重回帰などの基本的な統計モデル、階層ベイズや状態空間モデルといった発展的な内容を含みます。本コースは比較的網羅的・本格的な内容になっており、理論部分や補講の物理のパートなどを修了するとベイズ統計の専門書を1冊読んだレベルに相当します。従って、その後の書籍（ボーナスレクチャーで紹介する書籍など）への理解がかなりスムーズに進むと思います。\n【コースの活用の仕方】\nこのコースはいくつかの使い方ができると思います\n1. ベイズ統計学の基礎的な流れを身に付ける(難しい数式はどんどん飛ばし、流れの理解に徹する)\n2. 数式の難しい理論は置いておいて、Pythonのコードで実装するところだけつまむ\n3. PyStanの使い方をメインにHow toを学ぶ\n4. 付録も含め全ての講義を視聴し、理論までしっかりベイズ統計学を学ぶ*\n(*大学レベルの数学が必要です)\n\n\n【大まかな流れ】*詳しくは本コースの概要をご覧ください。\nⅠ.確率\n1. 確率とは/確率の基礎\n2. 平均値・分散の性質・計算\nⅡ.ベイズ統計学\n1. ベイズの定理、ベイズの考え方\n2. ベイズ更新\n\n3. 様々な確率分布\n4. 自然共役事前分布\n5. MAP推定\nⅢ.モンテカルロ法/MCMC\n1.モンテカルロ法とは\n2.棄却法\n3.次元の呪い\n4.MCMCとは\n5.詳細つり合い\n6.各MCMCのアルゴリズム（M-H法, Gibbsサンプラー,ハミルトニアンモンテカルロ法）\nⅣ.PyStan\n1.環境構築の構築\n2.PyStanでのコードの書き方・ハローワールド\n3.基本的な統計モデル(単回帰、重回帰、ロジスティック回帰)\n4.発展的な統計モデル(階層ベイズ、状態空間モデル)",
      "target_audience": [
        "ベイズ統計学を体系的に学習されたい方",
        "ベイズ統計に興味があるが、専門書を読んでも数式の意味がよく分からず挫折した方",
        "ベイズ統計の仕組み・原理を理解した上で、ベイズ統計を使いたい方",
        "入門書を読んで、イメージや概念は理解しているが、そこから先(どうやって具体的に計算するのか)が分からない方",
        "Pythonで実際にどのようにベイズ統計が実装できるのかを知りたい方",
        "ベイズ統計を学んでいると突然、MCMCという言葉が出てきて困惑している方"
      ]
    },
    {
      "title": "Looker Studio - Construindo Dashboards Profissionais.",
      "url": "https://www.udemy.com/course/introducao-completa-ao-google-data-studio-edicao-2021/",
      "bio": "Aprenda na prática o passo a passo exato para criar dashboards e relatórios dinâmicos usando o Looker Studio",
      "objectives": [
        "Analisar o Planilhas Google em minutos usando visualizações avançadas",
        "Aprender a COMPARTILHAR e COLABORAR usando relatórios e painéis de dados",
        "Aprender a utilizar os métodos agregação",
        "Aprender a diferença entre métrica de dimensão",
        "Criar gráficos de séries temporais que exibem facilmente o mês até a data, o mês anterior e muitos mais",
        "Criar FILTROS para criar facilmente painéis interativos, gráficos e relatórios",
        "Criar painéis interativos PODEROSOS em minutos a partir de dados do Planilhas Google",
        "Criar cálculos personalizados",
        "Criar SCORECARDS poderosos exibindo as principais métricas e KPIs",
        "Aprenda VISUALIZAÇÕES poderosas, como coluna, barra, pizza, mapa"
      ],
      "course_content": {
        "Introdução": [
          "Comece por Aqui",
          "O que é o Looker Studio?",
          "Conectando base de dados",
          "Possibilidades de fontes de dados",
          "Visão geral do Looker Studio"
        ],
        "Cálculos e Métodos de Agregação": [
          "Diferença entre dimensões e métricas",
          "Métodos de agregação",
          "Aplicando métodos de agregação",
          "Campo calculado",
          "Cálculo de comparação"
        ],
        "Visualização de Dados": [
          "Escolha estratégica dos gráficos",
          "Tabelas",
          "Função detalhar da tabela (Drill Down)",
          "Tabela Dinâmica",
          "Visuais de comparação",
          "Visuais de composição",
          "Visuais de variação ao longo do tempo",
          "Visuais de mapa",
          "Big numbers",
          "Visuais de comunidade"
        ],
        "Filtros e Controles": [
          "Hierarquia de filtros",
          "Filtros de texto",
          "Filtros númericos e boleano",
          "Outros tipos de filtros"
        ],
        "Funções Importantes": [
          "Função IF",
          "Função case when",
          "Função de texto",
          "Função de data"
        ],
        "Recursos Avançados": [
          "Combinação de Dados",
          "Parâmetros"
        ],
        "Publicando e Compartilhando": [
          "Opções de compartilhamento",
          "Exportando dados"
        ],
        "Business Case": [
          "Sales Analytics"
        ]
      },
      "requirements": [
        "Muita Vontade de aprender",
        "Conhecimento básico de Internet",
        "Conhecimento básico de informática"
      ],
      "description": "5 razões pelas quais você deve escolher este curso do Google Looker Studio\nConciso - Você pode concluir este curso em um fim de semana\nExemplos e estudos de caso relacionados a negócios\nAmpla prática de exercícios porque a visualização de dados requer prática\nRecursos para download\nSuas dúvidas serão respondidas pelo próprio instrutor\nComece a usar o Google Looker Studio em todo o seu potencial para se tornar proficiente em visualização de dados e tarefas de relatório hoje mesmo!\nVocê é novo na visualização de dados ou fez alguns gráficos usando algum software de visualização, como MS Excel, Power BI ou Tableau. De qualquer forma, este curso será ótimo para você.\nUm certificado de conclusão verificável é apresentado a todos os alunos que realizam este curso do Google Data Studio.\n\n\nPor que você deve escolher este curso?\nEste é um tutorial completo e conciso sobre o Google Looker Studio que pode ser concluído em 3 horas. Sabemos que o seu tempo é importante e, por isso, criamos este curso rápido, sem perder tempo com operações irrelevantes.\n\n\nO uso do Google Looker Studio é gratuito?\nO Google Looker Studio Studio é oferecido totalmente gratuito pelo Google.\n\n\nQual é a utilidade do Google Looker Studio?\nO Google Looker Studio oferece tudo que você precisa para transformar os dados analíticos de seu cliente em relatórios informativos e fáceis de entender por meio da visualização de dados. Os relatórios são fáceis de ler, compartilhar e até personalizáveis para cada um de seus clientes\nO autor deste curso têm vários anos de experiência corporativa e, portanto, a curadoria do material do curso tendo em mente a necessidade de visualização de dados no mundo corporativo de hoje.",
      "target_audience": [
        "Profissionais que precisam apresentar e acompanhar resultados através de relatórios e dashboards profissionais e centralizados",
        "Alunos que desejam ingressar no campo da análise de dados",
        "Profissionais que procuram aprender uma ferramenta poderosa de visualização de dados",
        "Usuários do Planilhas Google e usuários do Excel que desejam aprender como usar o Google Data Studio para analisar e relatar dados",
        "Empresários que precisam apresentar resultados para sócios"
      ]
    },
    {
      "title": "GPT에게 맡기는 AI 비트코인 투자 자동화 - AI 에이전트 만들기",
      "url": "https://www.udemy.com/course/gpt-bitcoin-ai-agent/",
      "bio": "코딩 초보도 만드는 AI 자동 트레이딩 시스템",
      "objectives": [
        "OpenAI의 강력한 언어 모델을 투자에 접목하는 방법",
        "코딩을 몰라도 Claude의 도움을 받아 원하는 코드를 쉽게 작성하는 방법",
        "Upbit API 연동 - 실시간 시장 데이터 수집 및 자동 거래 실행 기법",
        "기술적 지표 계산 - ta 라이브러리를 활용한 RSI, MACD, 볼린저 밴드 등 계산",
        "웹 스크래핑 - Selenium을 이용한 차트 이미지 캡처 및 뉴스 데이터 수집",
        "감성 분석 - 뉴스 헤드라인과 YouTube 트랜스크립트를 활용한 시장 감성 평가",
        "데이터베이스 관리 - SQLite를 이용한 거래 기록 저장 및 관리",
        "Streamlit을 활용한 대시보드 구축 - 실시간 투자 성과 및 시스템 상태를 확인할 수 있는 대시보드 개발",
        "AWS를 활용한 클라우드 서버 구축 - EC2 인스턴스 생성하여 자동매매 시스템 클라우드 배포 및 운영 방법",
        "AI 프롬프트 엔지니어링 - 효과적인 투자 결정을 위한 ChatGPT 프롬프트 작성법",
        "자동화 시스템 구축 - 시장 트렌드에 맞춰 스스로 변화하는 24시간 작동하는 AI 자동 트레이딩 시스템 개발",
        "멀티모달 AI 활용 - 텍스트, 숫자, 이미지 데이터를 종합적으로 분석하는 AI 모델 사용법",
        "대가들 투자 전략의 AI 구현 - 전문가의 투자 방법론을 AI 시스템에 적용하는 기법",
        "성능 모니터링 및 최적화 - 시스템의 지속적인 개선을 위한 방법론"
      ],
      "course_content": {
        "개요": [
          "1강 - 강의 개요",
          "2강 - 강의 수강 방법",
          "3강 - 챗GPT로 원리 이해하기"
        ],
        "최소 기능 제품 만들기": [
          "4강 - 환경 세팅",
          "5-1강 - 최소 기능 제품 만들기(1) - 개요",
          "5-2강 - 최소 기능 제품 만들기(2) - 업비트 차트 데이터 가져오기",
          "5-3강 - 최소 기능 제품 만들기(3) - AI에게 데이터 제공하고 판단 받기",
          "5-4강 - 최소 기능 제품 만들기(4) - AI의 판단에 따라 자동매매 진행하기",
          "5-5강 - 최소 기능 제품 만들기(5) - 디테일 수정 및 실제 자동매매 실행하기"
        ],
        "비트코인 투자 자동화 AI Agent 구현하기 - 데이터 넣기": [
          "6강 - 강의 개요 다시 짚어보기",
          "7강 - 거래소 데이터 넣기",
          "8강 - 보조 지표 넣기",
          "9강 - 공포 탐욕 지수 데이터 넣기",
          "10강 - 최신 뉴스 데이터 넣기",
          "11-1강 - 차트 이미지 넣기(1) - 셀레니움 기초",
          "11-2강 - 차트 이미지 넣기(2) - 셀레니움 스크린샷 저장",
          "11-3강 - 차트 이미지 넣기(3) - 셀레니움 클릭 자동화",
          "11-4강 - 차트 이미지 넣기(4) - GPT-4o Vision 차트 이미지 기반 자동매매 완성하기",
          "12-1강 - 유튜브 데이터 넣기(1) - 영상에서 자막 추출 하기",
          "12-2강 - 유튜브 데이터 넣기(2) - 유튜브 데이터 기반 자동매매 완성하기"
        ],
        "비트코인 투자 자동화 AI Agent 구현하기 - 시스템 고도화": [
          "13-1강 - 구조화된 데이터 출력(1) - 100퍼 확실한 JSON 응답 얻는 방법",
          "13-2강 - 구조화된 데이터 출력(2) - Structured Outputs 구현 및 자잘한 오류 수정",
          "14강 - 투자 비율 설정 기능 구현",
          "15강 - 전략 다듬기 - 한국 코인계 전설 ‘워뇨띠’님의 전략 복사하기"
        ],
        "비트코인 투자 자동화 AI Agent 구현하기 - 재귀 개선 시스템 구현": [
          "16강 - 투자 데이터 DB 기록하기",
          "17강 - AI 스스로 회고 및 재귀 개선 시키기"
        ],
        "모니터링 시스템 구현하기": [
          "18-1강_실시간 투자 현황 모니터링(1) - Streamlit 기초",
          "18-2강 - 실시간 투자 현황 모니터링(2) - 웹 사이트 대시보드 만들기"
        ],
        "클라우드 배포": [
          "19-1강 - 클라우드 배포(1) - AWS 가입하기",
          "19-2강 - 클라우드 배포(2) - EC2 서버 만들기",
          "19-3강 - 클라우드 배포(3) - Github 통해서 클라우드로 코드 옮기기",
          "19-4강 - 클라우드 배포(4) - 서버 환경 설정",
          "20-1강 - 클라우드 배포시 문제 해결(1) - EC2 크롤링 막하는 문제 해결",
          "20-2강 - 클라우드 배포시 문제 해결(2) - 셀레니움 크롬 문제 해결",
          "20-3강 - 클라우드 배포시 문제 해결(3) - 코드 수정 후 재배포"
        ],
        "비트코인 투자 자동화 AI Agent의 디테일 완성": [
          "21-1강 - 코드 정리 - 개발용 코드 제거 및 AI 3대장에게 피드백 받기",
          "21-2강 - 코드 정리 - 전체 코드 설명",
          "21-3강 - 코드 정리 - 주의사항"
        ],
        "비트코인 투자 자동화 AI Agent 클라우드 운영하기": [
          "22-1강 - 클라우드 서버 운영하기(1) - 초기화",
          "22-2강 - 클라우드 서버 운영하기(2) - Streamlit 웹 모니터링 실행 방법",
          "22-3강 - 클라우드 서버 운영하기(3) - 고정IP 할당 방법"
        ],
        "마무리": [
          "마무리 및 추가 발전 방향",
          "(보너스) 최신 오픈AI o1-preview 적용하기"
        ]
      },
      "requirements": [
        "파이썬 왕기초"
      ],
      "description": "대 생성 AI의 시대, '비트코인 투자'\n이제는 GPT에게 맡겨서 투자 자동화를 해 보세요!\n\n\n이런 생각을 해보셨다면 이번 강의를 꼭 들어보세요.\n“나는 최신 뉴스와 차트를 보고 단기 바닥에 매수하고 상승하면 매도하는 투자를 하는데..”\n”매번 직접 판단하려니 힘도 들고, 시간이 부족하네..”\n”내가 생각하는 방식대로 종합적으로 생각해서 투자를 대신해주는 프로그램 어디 없을까?”\n\n\nGPT 비트코인 AI 자동매매 강의는\n이때까지의 단순 수식대로 동작하는 알고리즘 매매와 차원이 다릅니다.\n\n\n코딩을 잘 못해도 간단하게 명령만 내리면?\n원하는 데이터, 전략대로 동작하는 나만의 AI 자동 트레이더를 만들 수 있습니다.\n이제는 나만의 AI 트레이더를 통해 여러분만의 투자 전략을 자동으로 실행해 보세요!\n\n\nGPT에게 맡기는 AI 비트코인 투자 자동화는 인공지능과 암호화폐 투자의 세계를 융합한 혁신적인 강의입니다. 이 과정은 코딩 초보자부터 경험 있는 개발자까지, 그리고 투자에 관심 있는 모든 분들을 위해 설계되었습니다.\n\n\n[이런 내용을 배웁니다]\nAI 기반 투자 시스템 구축: 본 강의의 핵심은 ChatGPT와 Claude 같은 최신 AI 모델을 활용하여 자동화된 비트코인 투자 시스템을 구축하는 것입니다. 수강생들은 AI의 도움을 받아 복잡한 투자 로직을 쉽게 구현하는 방법을 배우게 됩니다.\nPython 프로그래밍 기초부터 고급 기술까지: 코딩 경험이 전혀 없는 분들도 걱정하지 마세요. 기초적인 Python 문법부터 시작하여, 데이터 분석, API 활용, 웹 스크래핑 등 실용적인 프로그래밍 기술을 단계별로 학습합니다.\n다양한 데이터 소스 통합: 이 과정에서는 Upbit API를 통한 실시간 시장 데이터, 뉴스 헤드라인, YouTube 트랜스크립트, 차트 이미지, 공포/탐욕 지수 등 다양한 데이터 소스를 수집하고 분석하는 방법을 배웁니다.\n실전 투자 전략 구현: 유명 투자자 '워뇨띠'의 전략을 AI 시스템에 적용해보는 등, 실제 투자 현장에서 사용되는 전략을 구현해봅니다. 또한, 개인의 투자 아이디어를 AI에게 설명하고 이를 코드로 변환하는 과정을 학습합니다.\n자동화 및 24/7 운영: 구축한 시스템이 24시간 작동하며 시장을 모니터링하고 자동으로 거래를 실행하는 방법을 배웁니다. 이를 통해 시간적 제약 없이 효율적인 투자가 가능해집니다.\n데이터베이스 관리 및 성능 모니터링: SQLite를 사용하여 거래 기록을 저장하고 관리하는 방법, 그리고 시스템의 성능을 지속적으로 모니터링하고 개선하는 기법을 학습합니다.\n실시간 대시보드 구축: Streamlit을 활용하여 투자 성과를 실시간으로 확인할 수 있는 대시보드를 만드는 방법을 배웁니다.\n클라우드 배포: 구축한 시스템을 클라우드 환경에 배포하여 안정적으로 운영하는 방법을 학습합니다.\nAI 프롬프트 엔지니어링: ChatGPT와 Claude에게 효과적으로 지시를 내리는 프롬프트 작성법을 배웁니다. 이를 통해 AI의 능력을 최대한 활용할 수 있습니다.\n\n\n남들보다 한 발 빠르게,\n조코딩과 함께 AI 투자의 세계로 입문해보세요!",
      "target_audience": [
        "AI와 투자에 관심 있는 분",
        "Python을 사용해 다양한 소스에서 데이터를 수집하는 방법을 배우고 싶은 분",
        "금융 데이터, 뉴스, 소셜 미디어, API 등 다양한 데이터 소스를 가져와서 AI로 분석하는 방법을 익히고 싶은 분",
        "차트 이미지 캡처, 뉴스 데이터 추출 등 실용적인 웹 스크래핑 기술을 익히고 싶은 분",
        "AI와 금융을 결합한 프로젝트 경험을 쌓고 싶은 개발자",
        "ChatGPT, Claude 등 AI 도구를 실제 프로젝트에 활용하고 싶은 개발자",
        "ChatGPT와 Claude에게 효과적으로 지시를 내리는 프롬프트 엔지니어링에 대해서 배우고 싶으신 분",
        "AI 기술의 실제 응용 사례를 경험하고 싶은 분",
        "대가들의 투자 방법론을 AI로 구현해보고 싶은 투자자",
        "AI를 활용해 투자 전략을 자동화하고 싶은 암호화폐 투자자",
        "비트코인에 관심이 있지만 시간이 부족해 직접 투자하기 어려운 직장인"
      ]
    },
    {
      "title": "プロンプトエンジニアリングを学ぼう！ -大規模言語モデル（LLM）の真価を引き出す技術-",
      "url": "https://www.udemy.com/course/prompt-llm/",
      "bio": "ChatGPTなどに与える命令文「プロンプト」の適切な扱い方を学びます。様々な知的作業をAIに任せられるようになりましょう。プロンプトエンジニアリングの基礎を学び、生成AIの特性を把握してAIとの「コミュニケーション能力」を身に付けます。",
      "objectives": [
        "プロンプトエンジニアリングを基礎から体験と共に学びます。",
        "「プロンプト」の適切な扱い方を学び、AIへの「指示力」を身につけます。",
        "Zero-Shot Few-Shot Prompting、Chain-of-Thought Promptingなどのプロンプトエンジニアリングのテクニックを学びます。",
        "プロンプトエンジニアリングの社会における位置づけ、そしてその未来について学びます。",
        "実社会の様々な場面における、プロンプトエンジニアリングの活用方法を学びます。"
      ],
      "course_content": {},
      "requirements": [
        "プログラミングや数学の知識、経験は不要です。",
        "人工知能、機械学習の技術的な知識は不要です。",
        "機械学習やデータサイエンス、深層学習について詳しい解説はありません。",
        "2023年7月の環境で解説しています。最新の環境と異なる可能性があります。",
        "OpenAIのアカウント開設が必要です。無料プランのGPT-3.5でも受講可能ですが、有料プランが必要なGPT-4の利用が望ましいです。"
      ],
      "description": "「プロンプトエンジニアリングを学ぼう！」は、ChatGPTなどに与える命令文「プロンプト」の適切な扱い方を学ぶ講座です。\nプロンプトは日本語などの文章で記述されますが、大規模言語モデル（LLM）の働きはこのプロンプト次第で大きく変化します。\n\n\n従来は機械学習、数学の知識に基づき、コードによりAIを操作する必要があったのですが、LLMの登場により我々が普段話す自然言語でAIを操作することが可能になりました。\nプロンプトを上手く使いこなすことができれば、様々な知的作業をAIに任せることが可能になります。\nこのような、いわばAIの民主化により、人間はより人間らしい仕事に集中できるようになることが期待されています。\n\n\n本講座では、最初にプロンプトエンジニアリングの基礎を学んだ上で、様々な応用を体験と共に学びます。\nAIに適切な指示を出すための、練習を重ねていきましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! 人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. プロンプトエンジニアリングの概要\n→ プロンプトエンジニアリングの概要を学んだ上で、体験します。\nSection2. プロンプトエンジニアリングの基礎\n→ プロンプトエンジニアリングの基礎として、LLMの性質や様々なプロンプトの記述法を学びます。\nSection3. プロンプトエンジニアリングの応用\n→ プロンプトエンジニアリングを、現実的な問題に対して適用します。\nSection4. プロンプトエンジニアリングの未来\n→ プロンプトエンジニアリングの未来について、様々な事例と共に解説します。\n\n\nプロンプトエンジニアリングの登場により、文系と理系が融合して知の総合格闘技がはじまりました。\nAIの得手不得手、そして特性を把握し、AIへの「指示力」を身につけましょう。",
      "target_audience": [
        "手軽にプロンプトエンジニアリングを楽しみたい方。",
        "プロンプトエンジニアリングの全体像と今後の可能性を知りたい方。",
        "プロンプトエンジニアリングを基礎から体験ベースで学びたい方。",
        "ChatGPTを業務に活用したい方。",
        "プロンプトエンジニアリングを教育に活用したい方。",
        "プロンプトエンジニアリングを創作活動に利用したい方。",
        "大規模言語モデル（LLM）の性質を把握し、活用したい方。",
        "最新のAI活用方法のトレンドに追随したい方。"
      ]
    },
    {
      "title": "ChatGPT الدليل الشامل للذكاء الاصطناعي و",
      "url": "https://www.udemy.com/course/chatgpt-q/",
      "bio": "كل ما تحتاج ان تعرفه عن شات جي بي تي و كل ما هو جديد في مجال الذكاء الاصطناعي (متجدد باستمرار)",
      "objectives": [
        "أنشئ محتوى وتعلم بشكل أسرع من أي وقت مضى",
        "حوّل إبداعك إلى عمل مدفوع، وأنتج أفكارًا جديدة، ووسّع جمهورك، ونمّي مشاريعك",
        "التعرف علي الادوات الجديده المعتمده علي الذكاء الاصطناعي و فهم كيفيه الاستفاده منها",
        "فهم كيفية استخدام الذكاء الاصطناعي في البيزنس وتحسين تجربة العملاء.",
        "فهم تطبيقات تقنية تشات جي بي تي و الذكاء الاصطناعي في تحسين العمليات الداخلية للشركات وزيادة الكفاءة",
        "تعزيز المهارات اللازمة لإطلاق مشروع تجاري مرتبط بتقنية تشات جي بي تي",
        "الانتاجيه : حقق اهدافك بشكل اسرع و ادر وقتك و رتب اولوياتك",
        "التسويق: انشئ اعلانات و رسائل اخباريه و حملات اعلانيه",
        "أدوات الصوت الذكية: الذكاء الاصطناعي يستطيع قراءة اي نص تكتبه له باصوات مختلفه كمان انه يستطيع استنساخ صوتك بالكامل",
        "أدوات الفيديو الذكية: أنشئ شخصية افتراضية تحوّل النصوص إلى عروض وأنشئ محتوى لمنصات التواصل الاجتماعي",
        "أدوات الصور الذكية: أضف حركة للصور وحسّن الجوانب الجمالية للصور وأنشئ صورًا عن طريق الكتابه",
        "العلامات التجارية: طوّر هوية بصرية وصمم شعارات وأنشئ محتوى واصنع وجود قوي على الإنترنت",
        "الحياه المهنيه: انشي سيره ذاتيه و اكتب خطاب توصيه و تدرب علي الانترفيو باستخدام الذكاء الاصطناعي",
        "تلخيص اي نص او اي كتاب او حتي اي فيديو علي اليوتيوب باستخدام الذكاء الاصطناعي",
        "انشاء بيزنس خاص بك في دقائق مثل الموقع الالكتروني، الشعار، الحملات التسويقيه، الدعايا، استخلاص و تحليل البيانات و بناء الوجود الافتراضي و العلامه التجاريه"
      ],
      "course_content": {},
      "requirements": [
        "لا تحتاج الي اي معرفه مسبقه بالذكاء الاصطناعي و لا تحتاج الي اي خبره في البرمجه",
        "الكورس بالكامل باللغه العربيه",
        "جزء صغير من وقتك"
      ],
      "description": "العالم كله دلوقتي مبيتكلمش غير عن الذكاء الاصطناعي و\nChatGPT\nو ده بسبب الحاجات اللي الذكاء  الاصطناعي يقدر يعملها\nهل أنت مستعد لكتابة سكريبتات الفيديو بأكملها، والعروض التقديمية، والدورات التعليمية عبر الإنترنت، والإعلانات المستهدفة، ومنشورات وسائل التواصل الاجتماعي، والنشرات الإخبارية، والبودكاست، ، والكتب الإلكترونية، والرسائل الشخصية، وعروض العمل، والمقالات، وخطط الدروس، وترجمة اللغات، وكلمات تحسين محركات البحث، وخطط الوجبات الغذائية، والجداول الزمنية المخصصة، والملخصات، وأفكار الشركات الناشئة، والرؤى السوقية، والسير الذاتية، والمقالات، والاختبارات، ونسخ التجارة الإلكترونية، وأفكار المحتوى، وقوائم المهام، وإرشادات العلامات التجارية، والخطط المالية، وشعارات الشركات، والعقود، والقصص الإبداعية، والمدونات، وخطط الأعمال، وكلمات الأغاني، والسير الذاتية، والبرامج التعليمية، والمراجعات، ووصف المنتجات، والإعلانات، وحملات التسويق؟\n\n\nانت كده في المكان الصح\n\nمش هتحتاج اي خبره من اي نوع علشان تاخد الكورس\nالشرح مبسط بصوره كبيره، و هنتعلم الذكاء الاصطناعي خطوه بخطوه\nسيتم تحديث الكورس باستمرار بكل ما هو جديد في مجال الذكاء الاصطناعي\n\nممكن تحس ان في دروس كتير انت تعرفها، و ده طبيعي لاني حاولت علي قد ما اقدر اشرح الذكاء الاصطناعي و شات جي بي تي من الالف للياء\n\nحاول تكمل الكورس للاخر قبل ما تحكم عليه و ان شاء الله هتستفيد\n\nالكورس مجمع كتير جدا من الادوات القائمه علي الذكاء  الاصطناعي، الاستخدامات المختلفه لشات جي بي تي و كمان افكار مختلفه من خلالها تقدر تستفيد من التطور اللي بيحصل في العالم و طبعا تطبيقات علي ارض الواقع تقدر تستخدم فيها الذكاء الاصطناعي.",
      "target_audience": [
        "الكورس مناسب لاي شخص يرغب في التعلم و الاستفاده من الذكاء الاصطناعي",
        "الكورس مناسب للكثير من المجالات، التسويق، خدمه العملاء ،تطوير الاعمال، الترجمه، كتابه المحتوي،و غيرها"
      ]
    },
    {
      "title": "Introduction to PyTorch with Engaging Projects",
      "url": "https://www.udemy.com/course/introduction-to-pytorch-with-engaging-projects/",
      "bio": "Get Started with PyTorch: Build Your First AI Project",
      "objectives": [],
      "course_content": {
        "Course Content": [
          "1 Define Input and Output Data",
          "2 Understand the Lineer Module",
          "3 Create an Optimizer and Learn Math Behind It",
          "4 Forward pass",
          "5 Compute loss function",
          "6 Backward pass and optimization",
          "7 Use ReLU (Rectified Linear Unit) activation function",
          "8 Add a dropout layer",
          "9 Number of the Weight and Bias of Lineer(1,10)",
          "10 Mean squared error loss",
          "11 Save and Load the Model",
          "12 Use 2 size input"
        ]
      },
      "requirements": [
        "Basic programming knowledge",
        "Familiarity with fundamental concepts of machine learning."
      ],
      "description": "Are you ready to dive into the exciting world of PyTorch? Discover the power of deep learning and embark on an incredible journey with our course, \"Introduction to PyTorch with Engaging Projects.\"\n\n\nPyTorch has revolutionized the field of artificial intelligence, enabling researchers and developers to build cutting-edge models with ease. Whether you are a beginner or an experienced coder, this course is designed to unlock your potential and equip you with the skills to create remarkable projects.\n\n\nThrough a series of hands-on projects, you will unleash the true potential of PyTorch. From building your first neural network to implementing advanced architectures, you will gain a solid foundation in deep learning principles. Our expert instructors will guide you every step of the way, providing clear explanations and practical examples that bring concepts to life.\n\n\nBut it doesn't stop there! This course goes beyond theory, ensuring an engaging and immersive learning experience. Get ready to tackle real-world challenges and build exciting projects that showcase your newfound knowledge. Develop image recognition systems, natural language processing models, and even delve into the fascinating realm of generative adversarial networks (GANs).\n\n\nWhat sets this course apart is its emphasis on practicality. You'll work on captivating projects that mirror real-world scenarios, giving you the confidence to apply your skills to industry challenges. Gain hands-on experience with data preprocessing, model training, and performance evaluation, equipping you with the tools to create impactful solutions.\n\n\nJoin a vibrant community of learners, collaborate with fellow students, and tap into a wealth of resources that will accelerate your learning journey. Our course brings together a supportive network of like-minded individuals who share a passion for PyTorch and are eager to push the boundaries of what's possible.\n\n\nAre you ready to take the first step towards mastering PyTorch? Enroll in \"Introduction to PyTorch with Engaging Projects\" today and unlock the world of deep learning innovation. Unleash your creativity, build awe-inspiring models, and make your mark in the exciting field of artificial intelligence.",
      "target_audience": [
        "Beginners who want to learn PyTorch and dive into the world of deep learning.",
        "Students and researchers interested in expanding their knowledge of artificial intelligence.",
        "Programmers and developers looking to enhance their skills in deep learning frameworks."
      ]
    },
    {
      "title": "R Programming 2023: Hands on R Programming for Beginners",
      "url": "https://www.udemy.com/course/r-beginners/",
      "bio": "Learn R Programming and R Studio. Data Analytics. Data Science. Data Visualization. Packages: GGPlot2, Dplyr, StringR",
      "objectives": [],
      "course_content": {
        "Getting started with R!": [
          "Setting up R and R Studio",
          "Understanding R Studio: Layout and Features",
          "Learn how to Import Files",
          "Updating Libraries"
        ],
        "Fundamentals of Programming": [
          "Data Types and Data Structures",
          "Let's revise data types",
          "Conditional Operators: If-else and Nested if-else if-else statements",
          "Logical Operators: AND, OR and NOT",
          "Build and Break For and While Loops!",
          "Applying Logical and Conditional Operators",
          "Print the first six numbers of the Fibonacci sequence",
          "Print the sum of first ten natural numbers"
        ],
        "Data Structures in R": [
          "Vectors: Character, Numeric, Complex and Logical",
          "Going through Vector Operations",
          "Word Game: Transforming words to Pig Latin",
          "More Vector functions: any(), rep() and all()",
          "Working with Films using Lists",
          "Matrices",
          "Preparing Class Report with a Matrix",
          "Introduction to Data-Frames",
          "Exploring more about Data-Frames",
          "Working with MT Cars Dataset"
        ],
        "Bonus Section: Visualizing data!": [
          "Scatter and Line Plots"
        ]
      },
      "requirements": [
        "High School Level Math"
      ],
      "description": "R Programming 2023: Learn Basics of R Programming and gain one of employer's most requested skills in 2023!\nData Science is all about using data to solve some of society's most pressing problems. Harvard Business Review touted Data Science as the sexiest job of the 21st century, and no wonder Data Science is considered the future! with zettabytes and yottabytes of structured and unstructured data floating everyday, it calls for very unique skillsets to uncover hidden patterns and generate valuable insights from data.\nThis course covers the basics of R/ R Studio Programming and several practical exercises relating to data science such as data analysis, building algorithms, generating insights and data visualization.\nR Programming is often associated with having a very steep learning curve and many students give up feeling overwhelmed by the language. The 'R for Beginners' course follows a step by step approach, combining conceptual learning with hands-on assignments, quizzes and real world projects.\nMoreover, we would learning R Programming, with R Studio an IDE for R Programming, with a console, syntax editor for executing R Programming code and debugging, as well as advanced tools for data visualization such as plots and maps.\nAt the end of this R/R Studio Programming course, you would be able to understand and apply basics of R/R Studio programming, analyze large data sets, export your findings onto excel, visualize data and even build your own algorithms!\nWho is this course aimed at\n- Beginners who have no coding background in R Programming or otherwise\n- Aspiring as well as professional data analysts, statisticians and programmers who want to pick up skills in R Programming",
      "target_audience": [
        "This course is for everyone, right from college students using R for a project to statisticians, programmers from other platforms, or pure beginners without any prior programming experience who want to become data analysts or data scientists"
      ]
    },
    {
      "title": "Ultimate Data Career Guide: From Data Entry to Data Expert",
      "url": "https://www.udemy.com/course/ultimate-data-career-guide-from-data-entry-to-data-expert/",
      "bio": "From \"Data Entry\" to \"Data Expert\" : a simple roadmap",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "An internet connexion and an PC"
      ],
      "description": "The Ultimate Data Career Guide: From Data Entry to Data Analyst\nFrom \"Data Entry\" to \"Data Analyst\" : a simple roadmap\nAre you looking to start a career in data or transition into a data analyst role? This course provides a clear, structured roadmap to help you progress step by step. Whether you are a data entry clerk or completely new to the field, you will learn the essential skills needed to advance with confidence.\nNo prior experience is required—just a willingness to learn. The course is designed to guide you through a structured path with hands-on exercises to build your expertise efficiently.\nWhat You Will Learn:\nStep 1: Data Entry Clerk – Master Excel, improve accuracy, and learn basic data quality checks.\nStep 2: Data Processing Assistant – Learn SQL, clean and organize data, and generate reports.\nStep 3: Junior Data Analyst – Work with SQL queries, create dashboards, and visualize trends.\nStep 4: Data Analyst – Analyze large datasets, automate reporting, and extract business insights.\nBy the end of this course, you will have a solid foundation in data analytics, from handling structured data to creating impactful visualizations. Start your journey today and take the next step in your data career. Feel Free to join this course !!!",
      "target_audience": [
        "Learners interested in becoming data analysts and more !"
      ]
    },
    {
      "title": "Decision Trees for Data Science",
      "url": "https://www.udemy.com/course/decision-trees-for-data-science/",
      "bio": "Decision Trees Fundamentals and exploring ID3 and CART algorithms with real world application",
      "objectives": [],
      "course_content": {
        "Decision Trees - Supervised Machine Learning Algorithm": [
          "Agenda",
          "What is DT, its intuition and Terminologies",
          "Impurity Measures - Entropy, Gini Index and Classification Error",
          "Decision Tree Algorithms and Lets learn ID3 DT",
          "CART Decision Tree Algorithm - wrt Classification",
          "CART Decision Tree Algorithm - wrt Regression",
          "Implementation of CART using SKLearn Library",
          "Use case on Decision Tree - Prediction of Wine Quality",
          "Quiz on Fundamentals of Decision Tree Supervised Machine Learning Algorithm"
        ]
      },
      "requirements": [
        "Familiarity with fundamental machine learning concepts, such as supervised learning, classification, and regression, will provide a solid foundation for understanding decision trees.",
        "Basic programming skills in a language commonly used for machine learning, such as Python or R, will be beneficial. Ensure that learners are comfortable with writing and running code",
        "A basic understanding of statistical concepts, such as probability and descriptive statistics, will help learners grasp the principles behind decision tree algorithms and their application.",
        "Knowledge of how to handle and preprocess data is important. Familiarity with tasks like data cleaning, feature engineering, and data visualization will enhance the learning experience",
        "Familiarity with popular machine learning libraries or frameworks, such as scikit-learn for Python or caret for R, would be advantageous. Ensure that learners can navigate and use these tools."
      ],
      "description": "Unlock the potential of Decision Trees and elevate your data science skills with this comprehensive course. Decision Trees are a fundamental and versatile tool in the realm of machine learning, allowing you to make informed predictions and decisions based on complex datasets.\nIn this course, you will embark on a journey from the basics to advanced applications of Decision Trees in data science. Starting with the foundational principles, you'll understand the inner workings of decision nodes, branches, and leaves. You will delve into the intricacies of various decision tree algorithms, including ID3, C4.5, and CART, learning how to choose the right algorithm for different scenarios.\nKey Topics Covered:\nUnderstanding decision tree fundamentals\nExploring decision tree algorithms: ID3, C4.5, CART\nHands-on construction and optimization of decision trees\nReal-world applications in classification and regression\nHandling missing values and data preprocessing\nEnsemble learning with Random Forests and Gradient Boosting\nPractical insights for avoiding overfitting\nInterpretability and visualization of decision trees\nApplications of decision trees in diverse industries\nBy the end of this course, you'll not only have a solid grasp of Decision Trees but also the confidence to apply this powerful tool to a variety of data science challenges. Whether you're a beginner or an experienced data professional, this course is your gateway to mastering Decision Trees for impactful data-driven decision-making.\n\n\nEnroll now and elevate your data science journey with the precision and intelligence of Decision Trees.",
      "target_audience": [
        "Individuals who are just starting their journey in data science and machine learning and want to understand the basics of decision trees as a predictive modeling technique.",
        "Professionals working with data analysis who want to expand their skills to include machine learning techniques like decision trees for classification and regression tasks.",
        "Programmers and software developers interested in incorporating machine learning into their applications or gaining a better understanding of how decision trees work.",
        "Students studying data science, computer science, or related fields who want to deepen their knowledge of machine learning algorithms, specifically decision trees.",
        "Enthusiasts and lifelong learners who have a general interest in machine learning and want to explore decision trees as a part of their broader understanding of the field."
      ]
    },
    {
      "title": "Bootcamp Cientista de Dados: 10 aplicações Web Completas",
      "url": "https://www.udemy.com/course/bootcamp-cientista-de-dados/",
      "bio": "Crie 10 Aplicações Web de Data Science e Inteligência Artificial com Shiny, sem precisar saber programação Web",
      "objectives": [
        "Implemente aplicação de Machine Learning",
        "Aplique Algoritmos de Inteligência Artificial",
        "Desenvolva soluções para problemas de classificação",
        "Avalie modelos de previsão de Séries Temporais",
        "Use distribuições de probabilidade para prever acontecimentos",
        "Desenvolva Sistemas de Recomendação",
        "Crie Dashboards de Analise de Dados Exploratória"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Apresentação e Estrutura do Curso",
          "Material para Download",
          "Os Casos Apresentados"
        ],
        "Conheça o Shiny": [
          "Introdução ao Shiny",
          "Interface do Usuário",
          "Código de Servidor",
          "Pacotes",
          "Criando uma Aplicação",
          "Publicando uma Aplicação"
        ],
        "Caso 1: Prevendo os Custos para Abrir uma Franquia": [
          "Entendendo a Demanda do Cliente",
          "Discutindo a Demanda Apresentada",
          "Discussão Teórica",
          "Prática Parte I",
          "Prática Parte II",
          "Prática Parte III"
        ],
        "Caso 2: Um Mentor de Carreira com Inteligência Artificial": [
          "Entendendo a Demanda do Cliente",
          "Discutindo a Demanda Apresentada",
          "Discussão Teórica",
          "Prática Parte I",
          "Prática Parte II",
          "Prática Parte III",
          "Prática Parte IV"
        ],
        "Caso 3: Prevendo a Qualidade de Veículos": [
          "Entendendo a Demanda do Cliente",
          "Discutindo a Demanda Apresentada",
          "Discussão Teórica",
          "Prática Parte I",
          "Prática Parte II",
          "Prática Parte III",
          "Prática Parte IV"
        ],
        "Caso 4: Analisando e Prevendo a Produção de Leite": [
          "Entendendo a Demanda do Cliente",
          "Discutindo a Demanda Apresentada",
          "Discussão Teórica",
          "Prática Parte I",
          "Prática Parte II",
          "Prática Parte III",
          "Prática Parte IV"
        ],
        "Caso 5: Avaliando a Probabilidade de Quebra de Equipamentos em uma Indústria": [
          "Entendendo a Demanda do Cliente",
          "Discutindo a Demanda Apresentada",
          "Discussão Teórica",
          "Prática Parte I",
          "Prática Parte II",
          "Prática Parte III"
        ],
        "Caso 6: Aplicação Web para Avaliar a Normalidade de Dados": [
          "Entendendo a Demanda do Cliente",
          "Discutindo a Demanda Apresentada",
          "Discussão Teórica",
          "Prática Parte I",
          "Prática Parte II",
          "Prática Parte III"
        ],
        "Caso 7: Criando um Sistema de Geração e Avaliação de Regras de Recomendação": [
          "Entendendo a Demanda do Cliente",
          "Discutindo a Demanda Apresentada",
          "Discussão Teórica",
          "Prática Parte I",
          "Prática Parte II",
          "Prática Parte III"
        ],
        "Caso 8: Fazendo Benchmark em Algorítimos de Forecast de Séries Temporais": [
          "Entendendo a Demanda do Cliente",
          "Discutindo a Demanda Apresentada",
          "Discussão Teórica",
          "Prática Parte I",
          "Prática Parte II",
          "Prática Parte III",
          "Prática Parte IV",
          "Prática Parte V"
        ]
      },
      "requirements": [
        "Lógica de Programação, conhecimentos básicos em estatística"
      ],
      "description": "Neste curso você é o Marcos, e trabalha para a ABC Analytics implementado soluções para projetos orientados a Dados. De forma totalmente prática, você vai aprender a criar aplicações Web de data science, sem precisar entender de programação para internet (HTML/CSS etc) utilizando Shiny, uma plataforma de desenvolvimento Web que utiliza a linguagem R e o IDE RStudio. Neste super curso você vai desenvolver passo a passo as seguintes aplicações (classificadas conforme a complexidade):\nPrevendo quais serão os custos para abrir uma franquia ★☆☆☆☆\nCriando um mentor de Carreira em Ciência de Dados usando Inteligência Artificial ★★★★☆\nClassificação da qualidade de veículos de acordo com suas características ★★★★☆\nEstimando a produção futura de um fazenda leiteira ★★★★☆\nAvaliando a probabilidade da quebra de equipamentos em uma fábrica ★☆☆☆☆\nAvaliando se dados estão normalmente distribuídos ★★☆☆☆\nCriando um sistema de recomendação interativo ★★★☆☆\nCriando uma aplicação que faz um benchmark entre 10 modelos de séries temporais ★★★★★\nExplorando e investigando dados públicos ★★☆☆☆\nOtimizando a escolha da carga de uma empresa aérea, tornando seu processo mais lucrativo ★★★★★\nCada projeto está composto de:\nA apresentação do problema\nA teoria do ponto de vista de ciência de dados para a solução do problema\nCodificação\nInclui curso básico de R para quem não tem proficiência na linguagem\nVocê ainda pode baixar slides e scripts completos das aplicações no ambiente.",
      "target_audience": [
        "Interessados em entrar para o mundo da Ciência de Dados, ou mesmo que queiram aperfeiçoar seus conhecimentos"
      ]
    },
    {
      "title": "Data Science Fundamentals For Beginners",
      "url": "https://www.udemy.com/course/data-science-fundamentals-for-beginners/",
      "bio": "VIEH Group",
      "objectives": [],
      "course_content": {
        "Data Science Fundamentals": [
          "Introduction to Data Science",
          "Who are Data Scientist and What is Data Science",
          "Why and Where to use Data Science",
          "Machine Learning VS Data Science",
          "Data Science Workflow",
          "Data Science Lifecycle",
          "What is Data",
          "Components of Data Science"
        ],
        "Machine Learning": [
          "Machine Learning",
          "Machine Learning Process",
          "Supervised and Unsupervised Learning",
          "Machine Learning Algorithms",
          "Deep Learning"
        ],
        "Miscellaneous Lectures and Information": [
          "Data Science Skill sets",
          "Data Science Jobs"
        ]
      },
      "requirements": [
        "Smartphone or PC or MAC with internet connection",
        "A desire to learn Data Science",
        "No Prior Knowledge of Data Science"
      ],
      "description": "Complete Data Science Fundamental Course for Beginners\nFirst of all this is complete Data Science Fundamental Course. If you looking to begin with Data Science then this the perfect choice ever.\nHERE IS WHY YOU SHOULD TAKE THE COURSE\nThe course is complete for beginners.\nThat means by completing this course I guarantee you that you will learn all the complex Data Science Components and Machine Learning Algorithms in a easy and Understandable way.\nIn this age of big data, companies across the globe are generating lots and lots of data. This makes Data Science a trending topic. Data Science is one of the most promising technology right now. Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data.\nMost of the businesses today are using Data Science to add value to their business operations and increase customer satisfaction and retention. And, so there is substantial increase in the demand for Data Scientists who are skilled in Data Science and related technologies.\nAnd, this is the right time to start learning Data Science.",
      "target_audience": [
        "Students who want to learn Data Science",
        "Beginners who want to learn the Fundamentals of Data Science",
        "Those who want to build career as Data Scientist",
        "Data Analyst or Data Scientist to revise the Fundamentals"
      ]
    },
    {
      "title": "【初学者向け】統計学の基礎をアニメーションを通じてビジネス観点で理解していこう！",
      "url": "https://www.udemy.com/course/statistics-beginner/",
      "bio": "アニメーションで統計学について簡単に理解しよう！なんだか数式が多くて難しいと思われがちな統計学を出来るだけかみ砕いて分かりやすくビジネス観点から学べるようにした講座です。",
      "objectives": [
        "統計学の基本・概要",
        "統計的検定",
        "相関関係",
        "確率分布",
        "回帰分析",
        "クラスター分析",
        "主成分分析",
        "Pythonによる各種統計手法の実装"
      ],
      "course_content": {
        "イントロダクション": [
          "このコースの概要"
        ],
        "統計学の基本をアニメーションで学ぼう！": [
          "統計学概要",
          "確率分布",
          "相関関係",
          "統計的検定とは",
          "t検定",
          "カイ二乗検定",
          "統計学の基本の復習"
        ],
        "多変量解析の基本をアニメーションで学ぼう！": [
          "多変量解析とは",
          "回帰分析",
          "判別分析",
          "主成分分析",
          "因子分析",
          "共分散構造分析",
          "クラスター分析",
          "アソシエーション分析",
          "多変量解析の復習"
        ],
        "Pythonの簡単な使い方を理解していこう！": [
          "データの前処理可視化",
          "Pythonの環境構築：Google Colab",
          "Google Colaboratoryの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "【注意】次の動画での言及について",
          "Pandasの基礎",
          "Numpyの基礎",
          "Matplotlibの基礎",
          "Seabornの基礎",
          "Python構文の復習"
        ],
        "Pythonで統計学を実装し学ぼう！": [
          "t検定",
          "カイ二乗検定",
          "回帰分析のためのデータ準備",
          "単回帰モデル構築",
          "モデル評価と重回帰モデルとの比較",
          "因子分析①",
          "因子分析②",
          "因子分析③",
          "共分散構造分析①",
          "共分散構造分析②",
          "アソシエーション分析①",
          "アソシエーション分析②"
        ],
        "追加でいくつか統計学の知識を学ぼう！": [
          "追加の統計学の知識",
          "【注意】次のレクチャーでの誤植",
          "正規分布",
          "一様分布",
          "二項分布",
          "ポアソン分布",
          "変数の種類",
          "母集団・標本の定義とランダムサンプリングの種類",
          "標準偏差と分散",
          "区間推定と95%信頼区間",
          "外れ値の扱い方",
          "残差と誤差の違いと残差の使い方",
          "p値とは",
          "第1種の過誤と第2種の過誤",
          "分散分析",
          "自由度",
          "MSE・RMSE・MAE",
          "追加の統計学知識を復習"
        ],
        "まとめ": [
          "本コースのまとめ",
          "【確認テスト】コースの理解度をチェックしよう",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "統計学についての興味関心",
        "PC（MacでもWindowsでも）"
      ],
      "description": "統計学ってなんだか分かりづらい・・・\n統計学ってとっつきにくい・・・\n\n\nそんな方に向けてアニメーションで統計学を簡単に理解してもらう講座を作りました！\nビジネス観点で必要な統計学の知識だけを抽出してまとめています。\n\n\nアニメーションで学ぶ概要編とPythonで実際に手を動かしながら学んでいく実践編に分かれています。\nまず、統計学の全体像とビジネスに必要な知識を学んでいきます。\n続いて多変量解析の領域に入りよく使われる手法を中心に学んでいきます。\n最後にPythonでの実装を経て理解を深めていきましょう！\n\n\nぜひこの機会に統計学を学んで実務に活かしていきましょう！",
      "target_audience": [
        "統計学について興味のある人",
        "統計学をどのようにビジネスに活かしていけばよいか分からない人",
        "統計学を学ぼうとして難しい本を読んで挫折した人"
      ]
    },
    {
      "title": "Machine Learning Linear Regression Case Study",
      "url": "https://www.udemy.com/course/machine-learning-linear-regression-case-study/",
      "bio": "Predicting Boston house price with Linear Regression using scikit-learn !!",
      "objectives": [],
      "course_content": {
        "Machine Learning Introduction": [
          "What is Machine Learning"
        ],
        "Linear Regression Introduction": [
          "Linear Regression Introduction",
          "Simple Linear Model",
          "Model creation and Visualizations and save model"
        ],
        "Predicting Boston house price with Regression !!": [
          "Boston Housing Price Data Processing",
          "Boston Model Creation and Prediction"
        ]
      },
      "requirements": [
        "Yes, A basic knowledge in Python 3 is preferred."
      ],
      "description": "We have covered-\nWhat is Machine Learning and how does it works?\nMachine Learning concept such as Train Test Split, Machine Learning Models, Model Evaluation are also covered.\nLinear Regression Concept with simple regression model using Scikit Learn Library.\nWhat are the types of Regressions?\nCase Study-Boston house price prediction-predicts the price of houses in Boston using a machine learning algorithm called Linear Regression. To train our machine learning model ,we will be using scikit-learn’s boston dataset.\nAnalyse and visualize data using Linear Regression.\nPlot the graph of results of Linear Regression to visually analyze the results.\nLinear regression is starting point for a data science this course focus is on making your foundation strong for deep learning and machine learning algorithms.\nEnd of the course you will be able to code your own regression algorithm from scratch.\nAfter completing this course you will be able to:\nInterpret and Explain machine learning models which are treated as a black-box\nCreate an accurate Linear Regression model in python and visually analyze it\nSelect the best features for a business problem\nRemove outliers and variable transformations for better performance\nConfidently solve and explain regression problems\n\n\nThis course will give you a very solid foundation in machine learning. You will be able to use the concepts of this course in other machine learning models.",
      "target_audience": [
        "Python developers curious about Machine Learning.",
        "Data Science and Machine leaning engineers."
      ]
    },
    {
      "title": "Essentials of Data Transmission",
      "url": "https://www.udemy.com/course/essentials-of-data-transmission/",
      "bio": "Introduces line coding and the widely accepted Pulse Code Modulation as digital modulation techniques",
      "objectives": [],
      "course_content": {
        "Fundamental Theory": [
          "Fundamental Theory",
          "Linear System",
          "Signal and Noise",
          "Bandpass Signal",
          "Transmission Methods",
          "Fundamental Theory"
        ],
        "Carrier Modulation": [
          "Amplitude Modulation to Carry for Digital Signal",
          "Angle Modulation to Carry for Digital Signal",
          "Digital Modulation System",
          "Carrier Modulation"
        ],
        "Digital Modulation": [
          "Line Coding",
          "Pulse Code Modulation",
          "Digital Modulation"
        ]
      },
      "requirements": [
        "No requirement needed"
      ],
      "description": "Introduces underlying theory and practice that enables digital transmission. Starting with theory of signal in communication systems based on sinusoidal signal with Fourier series and Fourier Transform that are the most important fundamental theory for data transmission. To simplify and better understanding of signal transmission requirements the significance of linear system approach are discussed. In transmission the effect of impairments on signals must be considered carefully. The impairments are usually considered as noise. Next step concerns transmission capacity which need understanding of the more complex concept of spectrum and bandwidth. This two factors have important role in preserving signal format during transmissions. There are distinct methods of transmitting digital data. Each method has its own advantages and disadvantages that in practice could change due to technology development. Due to distance requirements, data signals must be carried or converted in order to cover the required distance. The techniques how to carry data signal or convert it to fulfill the distance requirement is called modulation. Data transmission depends on conventional carrier based modulation such as amplitude modulation and angle modulation to cover the desired distance and digital modulation is more reliable and noise resistant. This course introduces line coding and the widely accepted Pulse Code Modulation as digital modulation techniques.",
      "target_audience": [
        "Student who want to learn essential of data transmission"
      ]
    },
    {
      "title": "Governança de Dados",
      "url": "https://www.udemy.com/course/governanca-de-dados/",
      "bio": "Aprenda: Data Governance. Data Catalog. Data Quality. LGPD. MDM. Metadados. Data Profiling. Privacidade de Dados.",
      "objectives": [
        "Aprender o que é governança de dados e seus benefícios",
        "Otimizar o resultado de suas análises com a ajuda de data profiling",
        "Entender o que é a Lei Geral de Proteção de Dados e como Governança de Dados é crucial para estar conformidade com ela.",
        "Utilizar catálogo de dados como ferramentas de classificação e organização de dados, trazendo mais agilidade e produtividade para seu time.",
        "Entender e aplicar conceitos práticos de Metadados e Data Quality",
        "Potencializar o valor dos dados dentro da empresa e contribuir para a transformação cultural dela",
        "Entender os papéis dentro da Governança de dados",
        "Entender os principais conceitos de governança de dados para poder colocar eles em prática",
        "Saber quais são os principais frameworks de governança",
        "Conhecer ferramentas modernas para catálogo, profiling e Data quality"
      ],
      "course_content": {
        "Governança de dados": [
          "Sobre o professor e agenda da aula",
          "O que é governança de dados?",
          "Por que Governança de Dados?",
          "Benefícios da Governança de Dados",
          "Os desafios da Governança de Dados"
        ],
        "Conhecendo uma ferramenta de governança de dados": [
          "Demonstração da ferramenta Alvin"
        ],
        "Papéis em Governança de Dados": [
          "Sobre o professor e agenda",
          "Introdução",
          "Data Owner",
          "Data Steward",
          "Data Custodian",
          "Conclusão"
        ],
        "Profling de dados - Exercício prático": [
          "Sobre o professor e agenda da aula",
          "O que é Data profiling?",
          "Exercício prática",
          "Análise do data profiling"
        ],
        "Qualidade de Dados - Data Quality - Exercício prático": [
          "Sobre o professor e agenda da aula",
          "Definição de Qualidade de Dados",
          "Etapas do processo de Data Quality",
          "Dimensões em Qualidade de Dados",
          "Aula prática"
        ],
        "Desmistificando metadados": [
          "Introdução",
          "O que são metadados?",
          "Para que servem metadados?",
          "Quais são os tipos de metadados?",
          "Características dos metadados",
          "Metadados e Governança de Dados",
          "Arquitetura de Metadados"
        ],
        "Catálogo de dados": [
          "Sobre o professor e agenda da aula",
          "O que é um catálogo de dados?",
          "O que irá encontrar em um catálogo de dados?",
          "Principais ferramentas de mercado para catálogo de dados",
          "Como o catálogo de dados vai te ajudar na hora de encontrar as informações ?"
        ],
        "MDM": [
          "Sobre o professor e agenda da aula",
          "Transformação digital",
          "Master Data",
          "MDM",
          "Principais funcionalidades de um MDM"
        ],
        "LGPD, privacidade e Governança de Dados": [
          "Sobre o professor e agenda da aula",
          "O conceito de privacidade e a origem da LGPD",
          "O que é um dado pessoal?",
          "A importância das bases legais",
          "Os direitos dos titulares de dados",
          "Princípios para os tratamentos de dados"
        ],
        "Modernidade em dados": [
          "Dados são o novo petróleo",
          "Data Driven",
          "Data Culture"
        ]
      },
      "requirements": [
        "Não há pré-requisitos",
        "Para fazer as aulas práticas é preciso ter um nível de permissão no computador para instalar o python"
      ],
      "description": "Se você está interessado em dar os primeiros passos no mercado de Governança de Dados ou deseja conhecer a área, este curso é perfeito para você.\n\nPreparamos um trilha com os principais conceitos, processos e ferramentas que você precisa dominar para ingressar em uma das profissões que mais crescem no mercado brasileiro na área de Dados.\n\nTodo conteúdo foi preparado por profissionais das principais empresas brasileiras.\n\nO que te espera na Formação Governança de Dados\nMetadados técnicos e de negócios\nCatálogo de Dados\nData Profiling\nMDM\nPrivacidade e Lei Geral de Proteção de Dados(LGPD)\nData Quality\nPronto pra começar?",
      "target_audience": [
        "Profissionais da área de tecnologia",
        "Profissionais da área de dados",
        "Profissionais de governança de dados",
        "Profissionais de privacidade",
        "Engenheiros de dados",
        "Cientistas de dados",
        "Analista de dados",
        "Entusiastas da área de dados em um geral"
      ]
    },
    {
      "title": "Decision trees w/ Python & Scikit-Learn Machine Learning Lib",
      "url": "https://www.udemy.com/course/decision-trees-w-python-scikit-learn-machine-learning-lib/",
      "bio": "Decision making and Predictive Modeling",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Python programming"
      ],
      "description": "Udemy Course Description: \"Mastering Decision Trees with Scikit-Learn: From Basics to Advanced Applications\"\nCourse Overview: Dive into the world of Decision Trees, one of the most intuitive and versatile machine learning algorithms. This course, tailored for beginners and enthusiasts, will guide you through the fundamentals, practical applications, and advanced techniques of building decision trees using Python's powerful Scikit-Learn library.\nWhat You'll Learn:\nUnderstand Decision Trees: Explore their role in supervised learning for classification and regression.\nBuild and Train Models: Hands-on practice creating models that use decision rules to predict target variables.\nVisualization and Interpretation: Learn to visualize trees and extract insights from them with ease.\nAdvanced Topics: Avoid overfitting using pruning, handle imbalanced datasets, and explore ensemble methods like Random Forests.\nReal-World Applications: Apply decision trees to solve classification, regression, and multi-output problems.\nOptimization Techniques: Use parameters like max_depth, min_samples_split, and min_samples_leaf to fine-tune your models.\nComparison with Other Algorithms: Understand the strengths, limitations, and use cases of decision trees compared to other machine learning methods.\nWhy Take This Course?\nBeginner-Friendly: Start from the basics and gradually tackle complex topics.\nPractical Examples: Follow along with real-world datasets like the Iris dataset.\nVisualization Mastery: Learn to interpret your models with tools like plot_tree and gain insights into feature importance.\nGuided Projects: Reinforce your learning with projects such as multi-output regression or face completion tasks.\nPrerequisites:\nBasic understanding of Python programming.\nFamiliarity with fundamental machine learning concepts is a plus but not required.\nWho Is This Course For?\nAspiring data scientists and machine learning engineers.\nAnalysts looking to enhance their data interpretation skills.\nAnyone curious about the mechanics of decision trees and their real-world applications.\nEnroll today and unlock the power of decision trees with Scikit-Learn!",
      "target_audience": [
        "Learners wanting to learn more about Decision trees and supervised learning"
      ]
    },
    {
      "title": "【E資格の前に】PyTorchで学ぶディープラーニング実装",
      "url": "https://www.udemy.com/course/avilen-e-pytorch/",
      "bio": "Pythonの基本文法を習得した受講生向けに、実装で使えるディープラーニング（DL）習得のためのPyTorch講座です。E資格合格率94.4%の実績を持つ株式会社AVILENから、データサイエンティストの吉川による実践講義です。",
      "objectives": [
        "多層パーセプトロン、順伝播、逆伝播、損失関数、最適化、ハイパーパラメータなど実装に必要なディープラーニングの大枠を知識を紹介します。",
        "PyTorchの基本動作を覚え、実務での活用方法を理解することができます。",
        "モデルの要素となる全結合層や活性化関数、損失関数、最適化関数を実装し、それらを組み合わせたモデルを定義する力を養います。",
        "AIエンジニア認定資格「E資格」取得を目指す方推奨！はじめに実装イメージを掴み、理論や数式などの理解を促進します。"
      ],
      "course_content": {
        "はじめに": [
          "コース概要",
          "ディープラーニング実装でつまずくポイントを知る",
          "E資格取得に効果的な理由とは",
          "講師紹介"
        ],
        "【実務の流れがわかる】ディープラーニングの全体像": [
          "資料ダウンロードはこちら",
          "このセクションの概要",
          "ディープラーニングとは？",
          "本講座の実装課題",
          "機械学習（モデル開発）の流れ",
          "1. アルゴリズムの選択",
          "2. データの前処理",
          "3. モデルの学習",
          "4. 評価・検証",
          "このセクションのまとめ"
        ],
        "【実装で使う】ディープラーニングの仕組み": [
          "【実装で使う】ディープラーニングの仕組み",
          "MLP（多層パーセプトロン）の構造",
          "1. 順伝播",
          "2. 損失関数",
          "3. 逆伝播",
          "4. 最適化",
          "ハイパーパラメータ",
          "このセクションのまとめ"
        ],
        "環境構築": [
          "セクションの説明",
          "Python環境構築 - Windows版",
          "Python環境構築 - mac版",
          "パッケージのインストール - Windows版",
          "パッケージのインストール - mac版"
        ],
        "【入門から実用まで】PyTorchとは": [
          "このセクションの概要",
          "Pytorchを利用するメリット",
          "ライブラリの中でのPyTorchの位置付け",
          "PyTorch実行環境の確認",
          "このセクションのまとめ"
        ],
        "PyTorchの基本": [
          "このセクションの概要",
          "Tensorの基本 宣言の仕方",
          "Tensorの基本 宣言の仕方 問題解説",
          "Tensorの基本 中身の確認と型",
          "Tensorの基本 中身の確認と型 問題解説",
          "Tensorの基本 arrayとの変換",
          "Tensorの基本 arrayとの変換 問題解説",
          "CPUとGPU",
          "GPU対応",
          "GPU対応 問題解説",
          "Tensor同士の計算",
          "Tensor同士の計算 問題解説",
          "自動微分",
          "自動微分 問題解説",
          "Tensorを操作する関数 transposeとreshape",
          "Tensorを操作する関数 transposeとreshape 問題解説",
          "Tensorを操作する関数 zero_()",
          "Tensorを操作する関数 zero_() 問題解説",
          "このセクションのまとめ"
        ],
        "モデルの実装と学習": [
          "このセクションの概要",
          "【モデルの実装①】全結合層と活性化関数",
          "【演習解説】全結合層と活性化関数",
          "【モデルの実装②】損失関数と最適化関数",
          "【演習解説】損失関数と最適化関数",
          "【モデルの実装③】モデルの定義",
          "【演習解説】モデルの定義",
          "モデルの実装まとめと学習の導入",
          "【モデルの学習①】train関数",
          "【演習解説】train関数",
          "【モデルの学習②】test関数",
          "【演習解説】test関数",
          "このセクションのまとめ"
        ],
        "【明日から使える】実用上のモデルのチューニング": [
          "このセクションの概要",
          "活性化関数によるモデルチューニング",
          "【演習解説】活性化関数によるモデルチューニング",
          "損失関数によるモデルチューニング",
          "【演習解説】損失関数によるモデルチューニング",
          "最適化関数によるモデルチューニング",
          "【演習解説】最適化関数によるモデルチューニング",
          "CNNやLSTMなどレイヤークラスによるモデルチューニング",
          "【演習解説】レイヤークラスによるモデルチューニング",
          "構築済みモデルと学習済みモデルの使い方",
          "このセクションのまとめ"
        ],
        "おわりに": [
          "このコースのまとめ",
          "ボーナスレクチャー：E資格コースへ向けて"
        ]
      },
      "requirements": [
        "必須：Pythonの基本文法を理解し、問題なく操作ができる",
        "必須：numpyに関する知識を有していること",
        "高校数学（微分・行列計算）の基礎知識を有しているとより理解しやすくなります"
      ],
      "description": "<概要>\nディープラーニングの実装、実務活用のイメージが沸かない、難しそう...そんなお悩みはありませんか？\n当講座は、Pythonの基本文法とNumpyの知識さえあれば、誰でもディープラーニング(DL)を実装できるPyTorchの入門講座となっています。\n特別な理論や数式は扱わず、まずは実装して、ディープラーニングのイメージを掴むことをゴールとしています。\n\n\nAIスペシャリスト集団、株式会社AVILENの執行役員である吉川武文氏が、PyTorchによるディープラーニング実装術を公開。\n当講座で扱うプログラムは全て皆様にプレゼントします、実務でもご活用ください。\n\n\n*日本ディープラーニング協会が運営するAIエンジニア認定資格「E資格」取得を目指される方の第一歩におすすめのコンテンツとなります。認定プログラムの前に当講座を受講しておくと、小難しい理論や数式の理解が大きく促進されます。\n\n\n<対象者>\nPythonを勉強し始めたが、何をすればいいかわからない方\nAIの実装について知りたい、学びたい方\nAIエンジニアを目指している方\nE資格取得を検討している方\n\n\n<カリキュラム>\n全6パートに分けて、紹介していきます。\n①コース概要、学習の進め方\n②PyTorchが最適な理由、ディープラーニング概論\n③Tensor：Tensorの扱い方、GPUの利用方法、DLの頻出関数\n④多層パーセプトロン(MLP)とディープラーニング(DL)の仕組み\n⑤モデルの実装と学習\n⑥PyTorchの機能、活性化関数",
      "target_audience": [
        "Pythonを勉強し始めたが、何をすればいいかわからない方",
        "AIの実装について知りたい、学びたい方",
        "AIエンジニアを目指している方",
        "E資格取得を検討している方"
      ]
    },
    {
      "title": "Deep Learning and AI with Python for Beginners",
      "url": "https://www.udemy.com/course/deeplearningai/",
      "bio": "Beginners course if you are passionate about Artificial Intelligence & want to enter Deep Learning world using Python",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "A Google Gmail account is required to get started with Google Colab to write Python Code",
        "No programming experience required. You will learn everything you need to know"
      ],
      "description": "Are you a beginner looking to embark on a journey into the fascinating world of Deep Learning and Artificial Intelligence (AI)? Look no further!  Welcome to the world of deep learning, where cutting-edge technologies and incredible possibilities await! Our \"Deep Learning & AI course with Python for Beginners\" is your stepping stone into the captivating realm of artificial intelligence and machine learning. Whether you're a novice or have some programming experience, this course will empower you with the knowledge and skills to embark on a journey that is transforming industries worldwide. As industries increasingly adopt deep learning and AI technologies, the demand for skilled professionals is soaring. By completing this course, you'll position yourself at the forefront of one of the most dynamic and high-demand fields in tech. Unlock a world of opportunities, from AI research and data science to machine learning engineering and robotics.\nDeep learning, a subset of artificial intelligence, has transcended its initial hype to become a transformative force across various fields. In healthcare, deep learning is revolutionizing disease diagnosis and treatment by analyzing medical images, such as MRIs and CT scans, with unprecedented accuracy. It is powering autonomous vehicles, enabling them to navigate complex environments safely. In finance, deep learning algorithms are used for fraud detection and stock market prediction. Natural language processing models, a part of deep learning, are behind voice assistants like Siri and chatbots that enhance customer service. Deep learning's applications extend to the entertainment industry, where recommendation systems personalize content, and to manufacturing, where it optimizes production processes. Whether in climate science, astronomy, or e-commerce, deep learning is reshaping the future by making sense of vast datasets and uncovering insights that were once unimaginable.\n\n\nCourse content:\nDeep Learning and AI with Python Starting from Basic Concepts\nArtificial Neurons - Building Blocks of Deep Learning and AI\nDeep Convolutional Neural Networks (ResNet and AlexNet)\nLearn UNet Deep Learning Architectur\nLearn PSPNet Deep Learning Architecture\nLearn PAN Deep Learning Architecture\nLearn Region-Based Convolutional Neural Networks (RCNNs)\nSetting-up Google Colab for Writing Python Code\nData Preprocessing using different Image Transformations with Python\nDeep Learning Models to Perform Single and Multi-label Image Classification\n\n\nThis course is tailored for individuals with little to no prior experience in deep learning or Python programming. We'll start with the fundamentals and build your skills progressively. If you're a student aspiring to pursue a career in artificial intelligence or machine learning, this course will provide you with a strong foundation to kickstart your journey. If you're simply curious about the world of deep learning and want to explore its possibilities, this course is perfect for satisfying your intellectual curiosity.\nJoin us on this exciting journey and unlock the potential of Deep Learning and AI today! Enroll now to get started.",
      "target_audience": [
        "The course is designed for individuals who are new to the field of deep learning and wish to start their journey in this exciting area of artificial intelligence.",
        "Whether you're a student in computer science, engineering, data science, or any related field, this course can supplement your academic knowledge and provide practical skills."
      ]
    },
    {
      "title": "【4日で体験！】 TensorFlow, Keras, Python 3 で学ぶディープラーニング体験講座",
      "url": "https://www.udemy.com/course/tensorflow/",
      "bio": "TensorFlow 2 対応！ 4日間でディープラーニングを体験してみよう！Windows, MacでOK！",
      "objectives": [
        "TensorFlowを実行する環境を構築できます",
        "Anacondaをインストールして、安全にPython 3 の実行環境を導入できます",
        "Python 3.9 の実行環境を構築できます",
        "Jupyter Notebookを使用して、対話的にコードを実行できるようになります。",
        "GoogleのTensorFlow公式サイトの入門編とエキスパート編をコードを実行して理解できるようになります。",
        "畳み込み・プーリング・逆伝播など深層学習の基本的な仕組みを、わかりやすい図解で理解できます",
        "TensorFlowによる画像認識AIプログラムの動作を体験できます。",
        "北斎やムンクのタッチで写真をレタッチするスタイル変換のAIを試せます。"
      ],
      "course_content": {
        "1日目：　イントロと環境構築": [
          "このコースの概要",
          "TensorFlow関連コースの学習順序について",
          "ニューラルネットワークの基礎用語",
          "ニューラルネットワークの基礎知識（２）",
          "Google ColabでMNISTを動かしてみよう",
          "MNISTにチャレンジ（２）"
        ],
        "環境構築": [
          "環境構築の注意",
          "GPU搭載グラフィックスカードについて",
          "GPU搭載のおすすめPC",
          "学習上の注意",
          "Anaconda 3のダウンロード・インストール",
          "TensorFlow 最新版のインストール"
        ],
        "TensorFlowの学習に必要な文法を学ぼう！": [
          "データ型",
          "演算子",
          "配列型データ",
          "文字列の扱い"
        ],
        "2日目：MNISTにチャレンジ（ローカル環境）": [
          "セクションの概要（MNISTをローカルで解く）",
          "3層のニューラルネットワークで解いてみよう",
          "データを確認してみよう",
          "トレーニングをしてみよう",
          "推定をしてみよう",
          "学習の流れ",
          "練習課題（Fashion MNIST）",
          "課題解答サンプル（１）",
          "課題解答サンプル（２）"
        ],
        "畳み込みニューラルネットワークで解いてみよう！": [
          "イントロ",
          "モデルの定義",
          "トレーニングを実行してみよう"
        ],
        "3日目：　画像認識 にチャレンジ": [
          "画像認識プログラムの概要",
          "ダウンロードURLの変更",
          "TensorFlow 1.0.x環境用に画像認識プログラムをダウンロードする方法",
          "modelsフォルダのダウンロード",
          "画像認識プログラムの実行",
          "画像ファイルを指定して認識を実行してみよう！",
          "課題３：　画像認識を実行してみよう！"
        ],
        "４日目：画像のスタイル変換（続編のプレビュー）": [
          "スタイル変換コード実行の注意",
          "スタイル変換（1/2）",
          "スタイル変換（2/2）",
          "練習課題：スタイル変換にチャレンジ",
          "最後に"
        ],
        "オプション（Python 3、数学などの補足）": [
          "Pythonとは？",
          "PythonとR・SPSSとの違い",
          "Pythonのさまざまな実行スタイル",
          "課題1： Pythonの実行環境をインストールしよう",
          "練習課題：　インタラクティブシェルを使ってみよう",
          "実行例（インタラクティブシェル）",
          "練習課題：　テキストファイルを作成して実行してみよう",
          "課題解答例：　ファイルに保存して実行する",
          "練習課題：　入力値を反映するプログラムを書こう",
          "課題解答例：　ファイルから実行。入力パラメーターを反映。"
        ],
        "ボーナスセクション （質問の補足など）": [
          "続編のご案内（割引クーポン）",
          "AI・ディープラーニングのおすすめコース",
          "機械学習やAIを学ぶ上で役立つ参考書籍",
          "Jupyter Notebook上でコメントを挿入する方法",
          "Jupyter Notebookの終了方法"
        ],
        "（レガシー）MNIST for Begginersのアーカイブ（Googleサイトから削除）": [
          "このセクションで学ぶこと",
          "行列式での表現と、グラフでの表現",
          "コードを書いて実行してみよう",
          "勾配降下法とミニバッチ",
          "まとめとニューラルネットワーク",
          "課題：　MNIST for ML Beginnersを実行してみよう",
          "サンプルコード（ノートブック）のダウンロードページ",
          "MNIST for ML Beginnersのレクチャースライド"
        ]
      },
      "requirements": [
        "Windows または macOSの動作するPC（Linuxも可・64bit CPU/OS）",
        "Python 3.9・Anaconda・Jupyter Notebook （コース内で導入方法を解説します）",
        "TensorFlow 最新版（コース内で導入方法を解説します）1.0 ~ 1.3の解説アーカイブも参照可能",
        "インターネット接続 （学習データの取得に必要です）",
        "高速にバージョンアップがあってもパニックしない方（毎週のようにバージョンアップがあります）"
      ],
      "description": "【最新更新状況】\n2019/4/18 GoogleのチュートリアルのKeras移行に伴い、\nGoogle Colaboratoryによる体験\n3層ニューラルネットワーク\n畳み込みニューラルネットワーク\nのセクションを追加し、旧コンテンツ（TensorFlowネイティブでの開発）はアーカイブしました。\n\n\n2018/10/19  TensorFlow 1.11 CPU/GPUのインストール手順（conda版）を追加しました。\nまた、古いバージョンのインストール方法の動画は削除しました。\n2018/3/9　Anaconda 3とTensorFlow 1.6のインストール手順を追加しました。\n2017/12/4  レクチャー23のスライドに誤植があったので更新しました。\n2017/11/16 TensorFlow 1.4.0（CPU版）のインストール手順を収録・追加しました。\n2017/10/26 Anaconda3 5.0.0 + TensorFlow 1.3のインストール手順をmacOS, Windows版をそれぞれ追加しました。\n2017/9/15 TensorFlow 1.3 GPU版のインストール手順を掲載しました。\n2017/8/24 TensorFlow 1.3 GPUでcuDNN 6.0が必須になりましたので、補足を追加しました。\n2017/8/13 Anaconda 4.4.0 / Python 3.6のインストール手順を追加しました。\nWindows環境でもPython 3.6がサポートされました。（＊以前はPython 3.5のみ）\n2017/8/2 TensorFlow 1.2.1のインストール手順を追加しました。\n2017/4/29 スタイル変換（写真を画家のタッチで描く）のチュートリアルを追加しました。\n2017/4/27 TensorFlow 1.1がリリースされましたので、インストール手順を追加しました。なお、既存のチュートリアルは1.1での動作を確認しました。\n2017/4/3 機械学習の概要解説を追加しました。\n\n\n2017/2/27 TensorFlow 1.0のインストール方法、MNIST for Beginners・Expertsのコード実行のレクチャーを追加しました。\n2017/2/22 Windows版のインストール手順を更新しました（Anaconda 4.2.0のダウンロード・インストール手順）\n2017/2/21 勾配降下法・ミニバッチの解説を追加しました。\n2017/2/12 Jupyter Notebookでコメントを入力する方法。Jupyter Notebookの終了方法を追加しました。\n2017/2/9 MNIST for Experts のスライドを更新（活性化関数の解説を追加）しました。\n2017/2/8 活性化関数（ReLU）の図解レクチャーを追加しました。\n【ご注意】\nこのコースは、Python経験者で英語でGoogle社のTensorFlowチュートリアルが自力で理解できる方には物足りないと思いますのでご注意ください。チュートリアルを実施するのはナンセンスだと考える上級者の方には決して受講をお勧めしません。間違えて受講された場合は返金も可能ですので、初心者以外の方は受講しないでください。\nPythonをはじめて体験する方、TensorFlowでどんなことができるかを体験してみたい、という方を対象にしています。TensorFlowライブラリを使用したアプリケーション開発などは別コースを企画しています。\n【2019年、ディープラーニングが急速に普及します】\n2017年1月30日にピッツバーグで開催されていたトップレベルのチェスの試合で、カーネギーメロン大学のグループによる人工知能 \"Libratus\" が人間を打ち負かしました。2017年初めには、オンライン囲碁（野狐囲碁）でチャンピオンに連勝する人工知能（Master）が登場して話題になりました。Masterの正体は、2016年にイ・セドルプロを破った \"アルファ碁（AlphaGo）\" の改良版でした。アルファ碁は、イギリスのディープマインド社で開発されている人工知能です。ディープラーニングや強化学習と呼ばれる仕組みを使って、コンピューターが自己対戦を繰り返して成長するコンピュータープログラムです。AlphaGoのトレーニングにはGoogle社のTensorFlowという人工知能のライブラリが使われています。\n医療や農業、教育などさまざまな分野で、「人工知能・AI」による自動化、分類や推定が注目されています。ディープラーニングは、コンピューターにさまざまな情報を学習させて、分類や推定を行う機械学習の一種です。人間の脳を模したニューラルネットワークを何段にも（ディープに）重ねることで、精度の向上を実現しています。\n2017年のCES （コンシューマー・エレクトロニクス・ショー）では、ディープラーニングを実装したロボットを使ったサービスやアプリケーションが次々と発表されました。今後も続々と登場するでしょう。\nこの講座は、AlphaGoにも採用されているGoogle社のTensorFlowライブラリを使って、短期間にディープラーニングによる人工知能の動作を体験し、ディープラーニングを活用したサービスやプロダクトの企画・開発のヒントを得られるようになることを目指して制作しました。\nTensorFlowは、GooglePhotoやGoogle翻訳、Google検索などで実際に使われている機械学習、深層学習のライブラリです。\nさまざまなOS上で動作をしますので、学習だけでなく、ウェブアプリケーション開発やモバイルアプリ開発も可能です。\n\n\n【コースの概要】\nこのコースは、Udemyでのべ82,000名にプログラミングを指導してきたベテラン講師が担当します。\nGoogle社が公開しているオープンソースの人工知能ライブラリ・TensorFlow（テンソルフロー）を使って、\n以下のような順で学習を進めます。\n第0日：　環境構築\nAnaconda (Python 3) , TensorFlowのインストール\nTensorFlowでHello World!\n第1日：　手書き文字の分類　（多項ロジスティック回帰）\n多項ソフトマックス回帰の実行\n第2日：　手書き文字の分類　（畳み込みニューラルネットワーク）\n2段階の畳み込み・プーリング層、2層の全結合層を組み合わせたニューラルネットワークで精度を向上させる\n学習したモデルを使用して分類を実施してみる（収録中）\n第3日：　画像認識\nパンダの画像認識\nオリジナル画像（犬）の認識\n第4日：　スタイル変換\n画家のタッチをAIに学習させ、写真のスタイル変換をするAIプログラムを体験します。\nサンプルは北斎の「波」を使用しますが、ムンクやゴッホなどのデータも使用可能です。\nオプション（必須ではありません）\nPython 3の概要\nPython 3 のミニマムな文法\n参考文献リスト\n\n\nプログラムをJupyter Notebook上でステップ・バイ・ステップで実行しながら、ディープラーニングの仕組みを体験していきます。\n\n\n＊レクチャーで使用したJupyter Notebookはコース内でダウンロードできます。お急ぎの方はコーディングせずにプログラムを実行できます。ご自身でコーディングするとより理解が深まるでしょう。\n【このコースを学ぶと】\n人工知能と言われても、言葉だけではどんなことができるのかピンときません。しかし、実際に人工知能のトレーニングや推定を体験してみると、いろいろなアイデアが生み出せるようになるでしょう。\nぜひこの機会にTensorFlowを体験し、人工知能時代に活躍するスキルを手に入れましょう。現在、世界中でディープラーニングエンジニアの求人が急拡大しています。また、あらゆる業種で、人工知能を適用して課題解決が図れる人材が切望されています。エンジニアでなくても、ディープラーニングや機械学習の概念を理解することで、人工知能の得意なことを活かしたり、まだ人工知能ではできない限界を知って、リアリティのある意思決定ができるようになります。\n\n\n【このコースの特徴】\n数学やプログラミングの知識がなくても、ディープラーニングのプログラムを体験できます。\n数式を理解できなくても、概念的にどういう処理をしているのか、を直感的に理解できるようになります。\n畳み込みやプーリングなど難解な処理の仕組みを図解で理解できるようになります。\nPython 3 + TensorFlowを使って、パソコン上でディープラーニングを体験できます。\nボーナストラックでは、Python 3の基礎を解説します。\n【受講をおすすめしない方】\nすでにTensorFlowのチュートリアルを体験済みで解説が不要な方\nすでにディープラーニングに詳しい方\nLinuxでないと学習をしたくない方\n動画で学習するのはナンセンスだ！書籍で学んだ方がいい！という方\nソフトウェアのインストールや、コードの入力は全くしたくない方\nWindowsやMacでPythonプログラミングをやるのは気に入らないという方\n\n\n人工知能をマスターしたら、あなたはどんな問題解決をしますか？\n\n\n\n＊＊＊今後の予定＊＊＊\n続編として、\nニューラルネットワークをNumPyで自作して数学的処理を理解する講座\nCIFAR-10など本格的なディープニューラルネットワーク\nRNN（リカレントニューラルネットワーク）LSTMなどを使用した自然言語処理\n音声認識などのアプリケーション\nC++の基本と、TensorFlowの使用\nRaspberry Pi 3でTensorFlowを動かしてみよう\niOSやAndroidでTensorFlowを使用してみよう\nChainerでディープラーニングを学ぼう\nなどの講座化を企画しています。\nもしリクエストがあれば、メッセージなどでお知らせください。\n\n\n＊＊＊　受講上の注意　＊＊＊\nこのコースは動画で、はじめてディープラーニングやCNNなどを学ぶ方のためのコースです。\n環境構築から１つ１つ丁寧に解説していきますので、\n・動画より書籍で学びたい方\n・すでにCNNなどについて基礎から学習するのは馬鹿らしい\nという方は、間違って受講されないようご注意ください。\nまた、間違えて登録した方は30日以内であれば返金可能なのでお試しください。",
      "target_audience": [
        "TensorFlowを使用して、ディープラーニング・人工知能を体験してみたい方",
        "TensorFlowを体験して、機械学習や深層学習の基本的な仕組みを理解したい方",
        "画像認識などのサンプルプログラムを動作させて人工知能を体験してみたい方",
        "ディープラーニングや人工知能の書籍を買ったが、独力では理解が難しかった方",
        "ディープラーニングの参考書の学習環境がLinuxやDockerを前提としていて、環境構築でつまづいた方",
        "scikit-learnで回帰や識別の基礎を学んだが、TensorFlowを体験してみたい方",
        "多項ロジスティック回帰や、畳み込みニューラルネットワークを、直感的に理解したい方"
      ]
    },
    {
      "title": "TensorFlow, Deep Learning e Python: Construa um Chatbot",
      "url": "https://www.udemy.com/course/chatbot-tensorflow-deep-learning-python/",
      "bio": "Aprenda como implementar modelos de Processamento de Linguagem Natural usando técnicas modernas de Deep Leaning!",
      "objectives": [
        "Teoria sobre processamento de linguagem natural para a construção de chatbots",
        "Funcionamento do modelo BagOfWords e a Arquitetura Seq2Seq",
        "Redes neurais artificiais e redes neurais recorrentes",
        "Implementação passo a passo de um chatbot utilizando deep learning, redes neurais recorrentes, processamento de linguagem natural, modelo Seq2Seq, TensorFlow e Python"
      ],
      "course_content": {},
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Programação básica em Python",
        "Conhecimentos sobre instalação de softwares básicos, porém, durante o curso será mostrado o processo de instalação das ferramentas utilizadas",
        "Conhecimentos básicos sobre Machine Learning e Redes Neurais Artificiais são desejáveis (no final do curso tem dois anexos para revisar esse conteúdo)",
        "Conhecimentos básicos sobre o TensorFlow são desejáveis (no final do curso tem um anexo que revisa o básico da biblioteca)"
      ],
      "description": "ATENÇÃO! Este curso foi gravado com a versão 1.0 do TensorFlow e funcionava somente com versões mais antigas do Python. Atualmente NÃO é mais possível fazer as instalações, ou seja, VOCÊ NÃO CONSEGUIRÁ executar os códigos implementados no curso! Inicialmente iríamos migrar o código para o TensorFlow 2.0, porém, existem funções que não existem mais e a migração se tornou inviável e não será feita! Apesar disso, a teoria apresentada é válida e muito importante para o entendimento dos chatbots. Em resumo, você conseguirá acompanhar as aulas teóricas e a vinculação com o código, porém, não conseguirá reproduzir!\nA área de Deep Learning (Aprendizagem Profunda) está relacionada a aplicação das redes neurais artificiais na resolução de problemas complexos e que requerem artifícios computacionais avançados. Existem diversas aplicações práticas que já foram construídas utilizando essas técnicas, tais como: carros autônomos, descoberta de novos medicamentos, cura e diagnóstico antecipado de doenças, geração automática de notícias, reconhecimento facial, recomendação de produtos, previsão dos valores de ações na bolsa de valores e até mesmo a geração automática de roteiros de filmes! Nesses exemplos, a técnica base utilizada são as redes neurais artificiais, que procuram \"imitar\" como o cérebro humano funciona e são consideradas hoje em dia como as mais avançadas no cenário de Machine Learning (Aprendizagem de Máquina).\nDentro da área de Machine Learning existe uma sub-área que é o Processamento de Linguagem Natural, que tem o objetivo de reproduzir em computadores a compreensão automática de línguas humanas naturais. Alguns exemplos clássicos dessa área incluem:  tradução de voz para texto, texto para voz, sumarização automática de documentos, adição automática de legendas em vídeos, detecção de entidades em textos, geração de linguagens, reconhecimento óptico de caracteres (OCR), dentre várias outras. E uma das aplicações mais famosas e relevantes atualmente são os chatbots (robôs de conversa), que consistem em sistemas de Inteligência Artificial que são capazes de entender a linguagem humana e darem respostas, tanto em texto quanto em voz! Esse tipo de tecnologia vem sendo cada vez mais utilizado por grandes empresas para acelerarem o atendimento ao cliente, ou seja, ao invés de você conversar com uma pessoa você conversa com um chatbot. Várias empresas de tecnologia tem investido grande capital no desenvolvimento de chatbots, como por exemplo: a Apple (Siri), a Microsoft (Cortana), o Google (Google Assitant) e a Amazon (Alexa).\nE para levar você até essa área, neste curso você terá uma visão teórica e principalmente prática sobre a construção de chatbots utilizando as mais modernas técnicas de Deep Learning utilizando o TensorFlow e o Python! Vamos unir as áreas de Processamento de Linguagem Natural e Deep Learning, para que você aprenda a desenvolver um chatbot utilizando Redes Neurais Recorrentes e o Modelo Seq2Seq, que atualmente são consideradas como as melhores tecnologias para o desenvolvimento desse tipo de aplicação! Ao final você terá todas as ferramentas necessárias para construir chatbots e outras aplicações de Processamento de Linguagem Natural, utilizando bases de dados reais. Para isso, o conteúdo do curso está dividido em cinco partes:\nTeoria sobre Processamento de Linguagem Natural e explicações sobre o modelo Seq2Seq\nPré-processamento dos textos\nConstrução do Modelo Seq2Seq\nTreinamento do Modelo Seq2Seq\nComo melhorar o chatbot construído e análise de outras implementações de chatbot\nVocê ainda conta com três anexos caso você não tenha muita experiência na área. O primeiro mostra o básico sobre as redes neurais artificiais, o segundo é sobre as redes neurais recorrentes, e por fim, o terceiro aborda aulas básicas e práticas sobre o TensorFlow.\nEste curso é categorizado como nível intermediário, pois apesar de existirem os três anexos para revisão do conteúdo básico, é interessante que você já tenha uma certa experiência com a área de Deep Learning.\nA área de Deep Learning é atualmente um dos campos de trabalho mais relevantes da Inteligência Artificial, sendo que o mercado de trabalho dessa área nos Estados Unidos e em vários países da Europa está em grande ascensão; e a previsão é que no Brasil cada vez mais esse tipo de profissional seja requisitado! Inclusive alguns estudos apontam que o conhecimento dessa área será em breve um pré-requisito para os profissionais de Tecnologia da Informação!\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em deep learning (aprendizagem profunda)",
        "Pessoas interessadas em aprender como construir seu próprio chatbot",
        "Pessoas interessadas em redes neurais recorrentes avançadas",
        "Analistas de dados que queiram aumentar seu conhecimento na área de deep learning (aprendizagem profunda)",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial"
      ]
    },
    {
      "title": "みんなの強化学習講座 -PythonとGoogle Colaboratoryで基礎から少しずつ学ぶ強化学習の原理と実装-",
      "url": "https://www.udemy.com/course/reinforcement-learning/",
      "bio": "その高い性能により世界中で注目を集めている人工知能（AI）、強化学習および深層強化学習について学ぶコースです。強化学習の概要、原理、コードによる実装をシームレスに学びましょう。最終的に、深層強化学習を使った月面着陸船の制御まで行います。",
      "objectives": [
        "強化学習の原理について、基礎的な知識を学びます。",
        "Pythonで書かれた強化学習のコードが読めるようになります。",
        "自分の力で、強化学習のコードを実装する力が身に付きます。",
        "PyTorch、OpenAI Gym、Stable Baselinesなどのライブラリを使用して、深層強化学習を実装できるようになります。",
        "強化学習全般についての知識が身につきます。",
        "最新の研究事例を学びます。"
      ],
      "course_content": {
        "強化学習の概要": [
          "教材の使用方法",
          "イントロダクション",
          "コースの概要",
          "強化学習の概要",
          "強化学習のデモ",
          "強化学習の活用例",
          "Google Colaboratoryの使い方"
        ],
        "シンプルな強化学習": [
          "セクション2の教材",
          "Section2の概要",
          "実装の概要",
          "シンプルな強化学習の実装 Part1",
          "シンプルな強化学習の実装 Part2",
          "シンプルな強化学習の実装 Part3",
          "OpenAI Gymの紹介"
        ],
        "強化学習の原理": [
          "セクション3の教材",
          "Section3の概要",
          "数学の表記について",
          "「価値」の定義",
          "TD学習",
          "演習"
        ],
        "深層強化学習": [
          "セクション4の教材",
          "Section4の概要",
          "ディープラーニングの概要",
          "深層強化学習の概要",
          "PyTorchの基礎 PART1",
          "PyTorchの基礎 PART2",
          "深層強化学習の実装",
          "演習"
        ],
        "強化学習の応用": [
          "セクション5の教材",
          "Section5の概要",
          "月面着陸船の制御 -概要-",
          "月面着陸船の制御 -実装- PART1",
          "月面着陸船の制御 -実装- PART2",
          "強化学習の先端研究",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "何らかのプログラミング経験があった方が望ましいです。",
        "Google Colaboratoryを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。",
        "中学レベルの数学で十分です。高度な数学は必要ありません。",
        "ディープラーニング（深層学習）の解説は必要最低限となります。"
      ],
      "description": "みんなの強化学習講座は、「強化学習」について学び、親しむためのコースです。\n強化学習では、「環境において最も報酬が得られやすい行動」を「エージェント」が学習し、自発的に様々な行動パターンを獲得します。\n本コースは、この強化学習の原理およびコードによる実装を基礎から丁寧に解説します。\n様々な場面で応用されつつある強化学習を身に付け、活用できるようになりましょう。\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\nコースの内容は以下の通りです。\nSection1. 強化学習の概要\n→ 強化学習の全体像を把握し、開発環境であるGoogle Colaboratoryの使い方を学びます。\nSection2. シンプルな強化学習\n→ 最小限のPythonのコードで、強化学習の一種Q学習を実装します。\nSection3. 強化学習の原理\n→ 強化学習の理論、動作原理を学びます。\nSection4. 深層強化学習\n→ ディープラーニング（深層学習）と強化学習を組み合わせた深層強化学習について学びます。\nSection5. 強化学習の応用\n→ OpenAI Gymを利用して、月面着陸船の制御にトライします。また、強化学習の先端研究の紹介も行います。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックがダウンロード可能です。\n本コースはディープラーニング用フレームワークとしてPyTorchを、強化学習の環境としてOpenAI Gymを使用します。\nまた、Pythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "強化学習に興味があるけど、最初のとっかかりが分からない方。",
        "強化学習の難解な数式に辟易した方。",
        "強化学習のコードがPythonで書けるようになりたい方。",
        "強化学習を使って、何らかの問題を解決したい方。",
        "強化学習全般の知識が欲しい方。",
        "強化学習関連のライブラリが使いこなせるようになりたい方。",
        "仕事上、強化学習の知識が必要になった方。"
      ]
    },
    {
      "title": "【数学/プログラミング不要】ディープラーニングの実装体験でビジネスのためのAI活用を理解する",
      "url": "https://www.udemy.com/course/ai-matrixflow-benesse1/",
      "bio": "ビジネスサイドでのAI活用の全体像と基礎知識を理解し、ビジネスAI人材への一歩をふみ出す。G検定対策の入口にも。",
      "objectives": [
        "数学・プログラミングなしでG検定に必要なディープラーニングの基礎を習得する",
        "AIをビジネス・企画に活かしていくための基礎知識を習得する"
      ],
      "course_content": {
        "はじめに": [
          "はじめに",
          "このコースの進め方",
          "講師について",
          "G検定の概要",
          "G検定対策のための学習法"
        ],
        "AIとは": [
          "セクションの概要",
          "AIの定義",
          "AIと機械学習とディープラーニング"
        ],
        "AIの歴史": [
          "AIの歴史と3度のAIブームについて",
          "第一次AIブームとその限界",
          "第二次AIブームとその限界"
        ],
        "AIの利用が加速する要因": [
          "このセクションの概要",
          "膨大なデータとマシンパワー",
          "クラウドコンピューティングとSaaS・APIの利用",
          "エッジコンピューティングと５G",
          "機械学習～ディープラーニングの登場"
        ],
        "ディープラーニングと機械学習の種類": [
          "このセクションの概要",
          "ディープラーニングとは",
          "機械学習の種類",
          "ディープラーニングを実装する方法",
          "このセクションのまとめ"
        ],
        "ビジネスでのAI活用事例": [
          "このセクションの概要",
          "活用事例の全体像",
          "数値予測の事例",
          "自然言語処理の事例",
          "画像判別の事例",
          "このセクションのまとめ"
        ],
        "ディープラーニングの演習": [
          "このセクションの概要",
          "AI構築の流れ",
          "課題の設定とデータの準備",
          "MatrixFlowの概要とアカウント登録",
          "データのアップロードと前処理について",
          "CNNについて",
          "学習について",
          "学習結果について",
          "推論をしてみよう",
          "過学習とは",
          "過学習を解消しよう",
          "精度を向上させるためには",
          "精度を向上させてみよう",
          "このセクションのまとめ"
        ],
        "機械学習（自然言語処理）の演習": [
          "このセクションの概要",
          "データと前処理",
          "作成するモデルについて",
          "モデルの学習",
          "結果の確認",
          "精度を向上させてみよう",
          "推論してみよう",
          "このセクションのまとめ"
        ],
        "おわりに": [
          "AIをビジネスに活用するために",
          "AI人材の不足と育成指針",
          "ありがとうございました",
          "ボーナスレクチャー：MatrixFlowの継続利用と導入に関して"
        ]
      },
      "requirements": [
        "基本的なパソコン操作ができること"
      ],
      "description": "このコースの目的：数学なしにAIの全体像を理解し、G検定の対策を始められるようになる\n現在、デジタルトランスフォーメーションの必要性が高まる中、その中心ともいえるテーマがAIの活用です。\n2019年に閣議決定された「AI戦略2019」では、「数理・データサイエンス・AI」はデジタル時代の「読み・書き・そろばん」であるとして、2025年までにデータサイエンスやAIを各専門分野で活用できる人材を25万人育てるという目標を掲げました。また、ビジネスでAI活用が広がるためには、エンジニアだけではなく、ビジネスサイドにもAIを正しく理解する人材の育成が大きな課題と言われています。\nそのようなビジネスサイドのAI人材を認定する検定として、ディープラーニング協会が主催する「ディープラーニング　ジェネラリスト検定（通称G検定）」があります。2019年度には検定合格者が1万人を突破し、ニュース番組の特集で取り上げられるなど徐々に注目されるようになりました。\nしかしビジネスサイド、特に文系の方にとって、AIやディープラーニングに取り組むうえで、技術的な知識や特に数学への苦手意識が大きなハードルとなることが多いのも事実です。\nこのコースは自らも2019年度・第2回のG検定に挑戦・合格した文系・ビジネスサイドの講師が、自らの学習経験をもとにした学習法・活用資料などを紹介するとともに、数学なしにディープラーニングのモデル構築を体験することで、初学者の方でも短時間でディープラーニングの全体像を理解できることを目的としています。\nこのコースの構成：基礎知識を理解し、ディープラーニングの実装を体験する\nコースの前半では、G検定の概要およびG検定合格に向けた学習法をご紹介するとともに、AI学習のスタートラインに立つための基礎知識を解説します。講師が自らの受検対策用に作成した資料類等もご提供させていただきます。\nこのコースの後半では、数学なしに機械学習やディープラーニングの仕組みを理解します。「MatrixFlow」という最先端のビジュアルAIツールを利用して実際に「犬と猫」の画像を正しく分類するAIを作成します。また、自然言語処理のAIを作ってニュースサイトの内容の分類にも取り組んでみます。機械学習やディープラーニングの仕組みについても、「MatrixFlow」の開発に関わる専門講師がわかりやすく解説をしていきます。\nしたがって、この講座では数学は全くでてきませんのでご安心ください。リラックスして全体を学習していただければと思います。\n学習の対象者と注意事項\nこのコースはAIの全体像を理解したい方、手軽にディープラーニングの実装を体験したい方などの初心者の方を想定して作成しました。また、初心者の方がディープラーニングG検定を受検される方の入口教材としてもご利用いただけます。\nなお、数学なしにディープラーニングの全体像をつかむ　という目的を優先したため、すでにAIについて学習を進めている方にとっては内容が簡単すぎると思います。また専門家の方から見ると、厳密には例外がある・・といったご指摘を受ける箇所があることをご容赦ください。\nこのコースの学習のみでG検定の合格を保証するものではありません。また、2021年度より改訂されたG検定の新シラバスで追加された内容には対応しておりません。G検定の最新の内容については、ディープラーニング協会のWebページや公式テキスト等でご確認いただくことをお勧めします。\nまた、コース後半の実習のために、「MatrixFlow」の利用アカウントが必要になります。通常は有料のサービスですが、この講座を受講される方には2時間無料で利用できるアカウントをご用意しています。このアカウントの利用により費用が発生することは一切ありませんので安心してご受講ください。\nこのコースの学習が、AI・ディープラーニングに対する興味・関心を高め、さらに進んだ学習に取り組む入口となることを願っています。",
      "target_audience": [
        "AIやディープラーニングについて勉強しようとしたが、数学・プログラムが入ってきて挫折した人",
        "AIの実装を担当するわけではないが、ビジネス利用の観点でAIがどんな動きをするかを知りたい人",
        "数学・プログラミングはニガテだが、ディープラーニングのG検定に合格したい人"
      ]
    },
    {
      "title": "Python A-Z ™: Python per Data Science con esercizi reali",
      "url": "https://www.udemy.com/course/video-corso-python-datascience-visualization-dataframe-numpy-matplot/",
      "bio": "Programmazione in Python per Data Analytics e Data Science. Scopri analisi statistiche, data mining e Visualizzazioni",
      "objectives": [
        "Programmare in Python fino ad ottimo livello",
        "I principi fondamentali della programmazione",
        "Tipi di dati come integer, float, operatori logici, stringhe e altri tipi di dati",
        "Installare package in python",
        "Programmare con i Jupyter Notebooks",
        "Creare variabili",
        "I cicli come while e for",
        "La legge dei grandi numeri"
      ],
      "course_content": {
        "Introduzione": [
          "Che cosa vedremo durante il corso e navigare nell'interfaccia di udemy",
          "Installare Python (Windows & Mac)",
          "Installare Anaconda, python e jupyter in ubuntu linux",
          "Lanciare jupyter notebook da qualsiasi cartella"
        ],
        "Principi fondamentali della programmazione": [
          "Tipi di variabili",
          "Esempi pratici di utilizzo delle variabili",
          "Variabili booleane e operatori",
          "Il ciclo While",
          "Il ciclo For",
          "Il costrutto IF",
          "Indentazione del codice in Python",
          "Riassunto della sezione",
          "COMPITO: La legge dei grandi numeri",
          "Principi fondamentali della programmazione"
        ],
        "Fondamenti di Python": [
          "Che cos'è una lista?",
          "Creiamo qualche lista",
          "Usare parentesi quadre, [].",
          "Liste. Slicing (affettare)",
          "List comprehensions",
          "Tuple in Python",
          "Le funzioni in Python",
          "I package in Python",
          "Libreria Numpy e gli array in Python",
          "Slicing di array",
          "Riassunto della sezione",
          "Compito. Analisi di bilancio",
          "Fondamenti di Python"
        ],
        "Matrici": [
          "Riassunto del progetto. Tendenze della pallavolo NBA",
          "Matrici",
          "Creare le nostre prime matrici con np.reshape e np.array",
          "Dizionari in python",
          "Operazioni con matrici",
          "La nostra prima visualizzazione dati",
          "Visualizzazione dati avanzata",
          "Creiamo la nostra prima funzione",
          "Disegno di funzioni avanzate",
          "Analisi dei dati del bascket NBA",
          "Riassunto delle sezione",
          "Basketball. Tiri liberi. Compito",
          "Matrici"
        ],
        "Data Frames": [
          "Importare dati in python",
          "Esplorare il nostro DataSet",
          "Rinominare le colonne del nostro dataframe",
          "Creare dei sotto insiemi di dataframes con pandas",
          "Operazioni base con dataframes",
          "Filtrare i dataframe",
          "Accedere ad una cella con le funzioni .at e .iat",
          "Introduzione a Seaborn",
          "Visualizzazioni con seaborn",
          "Argomenti con parole chiavi nelle funzioni di Python",
          "Riassunto della sezione",
          "Compito sezione 5. World trends",
          "Dataframes"
        ],
        "Visualizzazioni avanzate": [
          "Che cosa è un tipo di dato categoria",
          "Lavorare con i grafici jointplots",
          "Istogrammi",
          "Istogrammi impilati in python",
          "Creare un grafico di tipo KDE",
          "Lavorare con subplots",
          "Violinplots vs boxplots",
          "Creare FacetGrids",
          "Coordinate e diagonali",
          "BONUS: Creare una dashboard (cruscotto) con python",
          "BONUS: Stilizzare grafici.Tips",
          "BONUS: Ritocchi finali.",
          "Riassunto della sezione",
          "Compito della sezione. Percentuale di incasso nazionale dei film",
          "Visualizzazioni avanzate"
        ],
        "Soluzioni ai compiti": [
          "Soluzione compito 2: La legge dei grandi numeri",
          "Soluzione compito 3. Analasi di bilancio. Parte 1",
          "Soluzione compito 3. Analasi di bilancio. Parte 2",
          "Soluzione compito 4: Pallacanestro. Tiri liberi.",
          "Soluzione compito 5: Trends mondiali. Parte 1",
          "Soluzione compito 5: Trends mondiali. Parte 2",
          "Soluzione compito 6: Cinema e incassi nazionali. Parte1",
          "Soluzione compito 6: Cinema e incassi nazionali. Parte 2"
        ],
        "Bonus section": [
          "Bonus lecture"
        ]
      },
      "requirements": [
        "Nessuna conoscenza precedente di programmazione o statistica",
        "Connessione a internet per scaricare il software necessario",
        "PC o Mac"
      ],
      "description": "Impara a programmare con  Python con progetti pratici!\nCi sono molti corsi e lezioni su Python. Tuttavia, Python ha una curva di apprendimento molto ripida e gli studenti spesso vengono sopraffatti. Questo corso è diverso!\nQuesto corso è veramente graduale. In ogni nuovo tutorial ci basiamo su ciò che avevamo già appreso e facciamo un ulteriore passo avanti.\nDopo ogni video , imparerai un nuovo e prezioso concetto di python che potrai applicare immediatamente  e la parte migliore è che impari attraverso degli esempi in tempo reale\nQuesta corso è pienao di sfide analitiche della vita reale che imparerai a risolvere. Alcuni di queste sifde le risolveremo insieme, altri ce le avrai come esercizi per i compiti.\nIn sintesi, questo corso è stato progettato per tutti i livelli di abilità e anche se non hai alcuna esperienza di programmazione o background in statistica, avrai successo con questo corso!\nNon vedo l'ora di vederti  a bordo!\nCordiali saluti,\nKirill Eremenko e Hidran Arias",
      "target_audience": [
        "A tutti coloro che vogliono imparare a programmare in Python",
        "Se sei stanco di corsi di python linghi e complicati: questo fa per te",
        "Alle persone che vogliono imparare a programmare in Python in modo semplice e pratico",
        "A chi è desideroso di fare dei compiti in modo da approfondire le sue conoscenze"
      ]
    },
    {
      "title": "Natural Language Processing con Python: il Corso Completo",
      "url": "https://www.udemy.com/course/natural-language-processing-pratico/",
      "bio": "Impara il Natural Language Processing (NLP) e sviluppa i tuoi Chatbot utilizzando il Machine Learning, NLTK e Spacy",
      "objectives": [
        "Estrarre testo da file TXT, CSV, PDF e DOC",
        "Estrarre testo da pagine web con BeautifulSoup",
        "Usare NLTK e Spacy per preprocessare documenti di testo",
        "Eseguire lo stemming e la lemmatizzazione su un documento di testo",
        "Codificare il testo con il Bag of Words e il TF*IDF",
        "Classificare documenti di testo usando Scikit-Learn",
        "Eseguire l'Analisi del Sentiment con NLTK",
        "Eseguire il Topic Modelling usando Scikit-learn e Gensim",
        "Creare Chatbot usando Keras e Tensorflow",
        "Funzionamento delle Reti Neurali Ricorrenti",
        "Creare architetture LSTM con Keras e Tensorflow"
      ],
      "course_content": {
        "Introduzione": [
          "Introduzione al Natural Language Processing",
          "Come usare Google Colaboratory",
          "Prima di cominciare",
          "Domande Frequenti"
        ],
        "Estrazione del testo": [
          "Operare sulle stringhe con Python",
          "Estrarre testo da file TXT",
          "Estrarre testo da file PDF",
          "Estrarre testo da file Docx",
          "Estrarre testo da file HTML",
          "Estrarre testo da pagine Web",
          "Estrarre testo da file CSV",
          "Approfondimenti e riferimenti"
        ],
        "Le Espressioni Regolari": [
          "Introduzione alle Espressioni Regolari",
          "Espressioni regolari per cercare pattern in Python",
          "Espressioni regolari per cercare pattern multipli in Python",
          "Espressioni regolari per rimuovere pattern in Python",
          "Approfondimenti e riferimenti"
        ],
        "Preprocessing del testo": [
          "La Tokenizzazione",
          "Tokenizzazione con Python e NLTK",
          "Le Stop Words",
          "Rimozione delle Stop Words con Python e NLTK",
          "Lo Stemming",
          "Stemming in Python e NLTK con il Porter Stemmer",
          "Stemming in Python e NLTK con lo Snowball Stemmer",
          "Stemming in Python e NLTK con il Lancaster Stemmer",
          "La Lemmatizzazione",
          "Lemmatizzazione con Python e NLTK",
          "Introduzione a Spacy",
          "Preprocessing di testo inglese con Spacy",
          "Preprocessing di testo italiano con Spacy",
          "Approfondimenti e riferimenti"
        ],
        "Codifica del testo": [
          "Il modello Bag of Words",
          "Bag of Words con Python e Numpy",
          "Il modello TF*IDF",
          "TF*IDF con Python e Numpy",
          "Approfondimenti e riferimenti"
        ],
        "Analisi del Testo": [
          "Part of Speech Tagging",
          "POS con Python e NLTK",
          "POS con Python e Spacy",
          "Named Entity Recognition",
          "NER con Spacy di un documento inglese",
          "NER con Spacy di un documento italiano",
          "Correzione delle entità",
          "Visualizzare le entità con Displacy",
          "Approfondimenti e riferimenti"
        ],
        "Analisi del Sentiment": [
          "Introduzione alla Sentiment Analysis",
          "Usare il modello VADER con NLTK",
          "Analisi del sentiment di recensioni con NLTK",
          "Introduzione al Machine Learning",
          "[OPZIONALE] La Regressione Lineare e Logistica",
          "[OPZIONALE] L'algoritmo Gradient Descent",
          "Introduzione all'IMDB Movie Reviews Dataset",
          "Preprocessing del corpus di testo",
          "Regressione Logistica con scikit-learn",
          "Correggere l'Overfitting con la regolarizzazione",
          "Testiamo il modello su nuove recensioni",
          "Preprocessing del corpus con NLTK",
          "Classificatore Bayesiano con NLTK",
          "Approfondimenti e riferimenti"
        ],
        "Topic Modelling": [
          "Introduzione al Topic Modelling",
          "Il modello Latent Dirichlet Allocation",
          "Introduzione al New York Times Articles Dataset e alle API di Kaggle",
          "Preprocessing del New York Times Articles Dataset",
          "Creazione del modello LDA con scikit-learn",
          "Esplorazione dei Topic",
          "Testiamo il modello LDA su nuovi articoli",
          "Rappresentazione grafica del modello LDA con scikit-learn",
          "Introduzione e installazione di Gensim",
          "Preprocessing dell'ABC Headlines Dataset con Gensim",
          "Creazione del modello LDA con Gensim",
          "Rappresentazione grafica del modello LDA con Gensim",
          "Approfondimenti e riferimenti"
        ],
        "Deep Learning e Chatbot": [
          "Introduzione al Deep Learning",
          "[OPZIONALE] Funzionamento delle Reti Neurali Artificiali",
          "[OPZIONALE] L'algoritmo Backpropagation",
          "Installazione di Keras e Tensorflow",
          "Preprocessare il corpus del Chatbot",
          "Addestrare la Rete Neurale Artificiale",
          "Creare il Chatbot",
          "Approfondimenti e riferimenti"
        ],
        "Word Embedding e Word2Vec": [
          "Limiti del Bag of Words",
          "Introduzione al Word Embedding",
          "Caricare l'IMDB Dataset con Keras",
          "Preprocessare l'IMDB Dataset",
          "Creare uno strato di Embedding",
          "Ottenere i Word Vectors",
          "Il modello Word2Vec",
          "Importare il modello Word2Vec con Gensim",
          "Introduzione al modello GloVe",
          "Preparazione della matrice dei pesi",
          "Usare il modello Glove con Keras",
          "Approfondimenti e riferimenti"
        ]
      },
      "requirements": [
        "Conoscere la lingua italiana",
        "Basi di matematica da scuola superiore",
        "Conoscere un qualsiasi linguaggio di programmazione può aiutare ma non è indispensabile"
      ],
      "description": "Il Natural Language Processing è il cuore di Google Search e Google Translate ed è la tecnologia che da la voce a Siri, Alexa, Google Assistant e tutti gli altri assistenti virtuali\nIn questo corso apprenderemo i segreti Natural Language Processing e impareremo ad utilizzarlo su problemi reali come:\nEseguire l'analisi del sentiment su recensioni di film usando scikit-learn\nRaggruppare automaticamente articoli di giornale in base all'argomento usando Gensim\nCreare un Chatbot per la customer care usando Keras e Tensorflow\nGenerare del nuovo testo in stile Dante Alighieri usando le Reti Neurali Ricorrenti con Keras e Tensorflow.\nNella prima sezione del corso vedremo come estrarre il testo da diverse tipologie di file come file TXT, CSV, PDF e file Word, in seguito impareremo come eseguire lo scraping di una pagina web usando BeautifulSoup.\nVedremo in sintesi il funzionamento delle espressioni regolari e come possiamo sfruttarle nel Natural Language Processing.\nLa terza sezione è interamente dedicata alle tecniche di preprocessing del corso: estrazione dei tokens, rimozione dello stopwords e stemming e lemmatizzazione, che ci permettono di ottenere la radice di una parola in modo da ridurre la dimensione del nostro dizionario, in questa sezione useremo le due più popolari librerie Python per il Natural Language Processing:\nNLTK (Natural Language Toolkit): storica libreria Python con moltissime funzioni.\nSpacy: una libreria più recente sviluppata per essere utilizzata a livello industriale.\nContinueremo il corso con i due principali modelli per l'encoding di documenti di testo, il modello Bag of Words e il TF*IDF, impareremo ad implementarli da zero, usando soltanto Numpy, una libreria Python per il calcolo scientifico.\nNella quinta sezione osserveremo come eseguire l'analisi del testo di un documento di testo usando sempre NLTK e Spacy, evidenziando:\nLa parte del discorso (Part of Speech Tagging)\nIl tipo di entità (Named Entity Recognition)\nNella quinta sezione introdurremmo la sentiment analysis e parleremo di machine learning, il campo dell'intelligenza artificiale che ha rivoluzionato l'intero settore. Vedremo come estrarre il sentiment da un elenco di recensioni reali di una skill Alexa usando il modello VADER ed impareremo a preprocessare da zero l'IMDB Movie Reviews Dataset per poi eseguire la sentiment analysis creando un modello di regressione logistica con scikit-learn, la più popolare libreria python per il machine learning, e un modello bayesiano usando NLTK.\nLa sesta sezione è dedicata al Topic Modelling, dopo aver introdotto l'argomento insieme all'algoritmo Latent Dirichlet Allocation svolgeremo due esericizi:\nSfrutteremo un dataset con circa 9000 articoli del New York Times per estrarre i topic e raggruppare insieme articoli che trattano di un'argomento comune, a questo scopo implementeremo l'algoritmo  Latent Dirichlet Allocation usando scikit-learn.\nEseguiremo il Topic Modelling usando un dataset di un milione di titoli di giornale dell'ABC, usando sempre l'algoritmo  Latent Dirichlet Allocation ma questa volta con Gensim, una libreria Python specifica per il Topic Modelling.\nNella sezione che segue ci butteremo su Deep Learning e Reti Neurali Artificiali, studiando come queste funzionano e come possono essere applicate per la creazione di un Chatbot per l'assistenza clienti di un fantomatico operatore telefonico chiamato Miao Mobile, usando i due più popolari framework Python per il deep learning: Keras e Tensorflow.\nNell'ultima sezione parleremo di Reti Neurali Ricorrenti e di come vengono applicate a problemi di NLP, vedremo insieme le principali architetture:\nVanilla RNN\nLong short-term memory (LSTM)\nGated Recurrent Unit (GRU)\nCome esercizio pratico utilizzeremo l'architettura LSTM per generare nuove testo con lo stile di scrittura di Dante Alighieri, usando come corpus di testo l'intera Divina Commedia.\nConcluderemo il corso con una serie di consigli, letture ed esercizi per poter continuare la nostra avventura nel Natural Language Processing.",
      "target_audience": [
        "Studenti e lavoratori che vogliono comprendere ed utilizzare il Natural Language Processing",
        "Professionisti interessati a Chatbot ed interfacce conversazionali"
      ]
    },
    {
      "title": "Probabilité et Statistiques pour la Data Science et Business",
      "url": "https://www.udemy.com/course/probabilite-et-statistiques-pour-la-data-science-et-le-business/",
      "bio": "Apprends à utiliser des méthodes statistiques et de probabilité sur des applications réelles de Data Science et Business",
      "objectives": [
        "Comprendre les bases de la probabilité",
        "Être capable d'implémenter les bases des statistiques",
        "Comprendre comment utiliser différentes distributions statistiques",
        "Appliquer des méthodes statistiques et des tests d'hypothèses statistiques à des problèmes commerciaux et business",
        "Comprendre comment les modèles de régression fonctionnent",
        "Implémenter l'Analyse de la Variance (ANOVA) à 1 facteur et à 2 facteurs",
        "Comprendre les Tests du Chi-carré",
        "Être capable de comprendre différents types de Données",
        "Appliquer des méthodes statistiques au domaine de la Science des données (Data Science)"
      ],
      "course_content": {
        "Introduction": [
          "Message d'accueil - Bienvenue !",
          "FAQ - Questions les plus Fréquentes"
        ],
        "Les Données": [
          "Qu'est-ce que des Données ?",
          "Mesure des Données",
          "Mesure des Données",
          "Mesure de la Tendance Centrale",
          "Mesure de la Tendance Centrale",
          "Mesures de Dispersion",
          "Mesures de Dispersion",
          "Mesures - Quartiles",
          "Quartiles et Écart Interquartile (EI)",
          "Données Bi-variées et Covariance",
          "Coefficient de corrélation de Pearson",
          "Votre évaluation sur la section - Données"
        ],
        "Probabilité": [
          "Qu'est-ce que la Probabilité ?",
          "Probabilité",
          "Permutations",
          "Permutations",
          "Combinaisons",
          "Combinaisons",
          "Intersections, Unions et Évènements Complémentaires",
          "Intersections et Unions",
          "Évènements Indépendants et Dépendants",
          "Évènements Indépendants et Dépendants",
          "Probabilité Conditionnelle",
          "Probabilité Conditionnelle",
          "Règles d'Addition et de Multiplication",
          "Théorème de Bayes",
          "Théorème de Bayes",
          "Évaluation - Section Probabilité"
        ],
        "Distributions de Probabilité": [
          "Introductions aux Distributions",
          "Distribution Uniforme",
          "Distribution Uniforme",
          "Distribution Binomiale",
          "Distribution Binomiale",
          "Distribution de Poisson",
          "Distribution de Poisson",
          "Distribution Normale",
          "Distribution Normale",
          "Distribution Normale - Formules et Z-Scores",
          "Z-Score",
          "Évaluation - Section Distributions",
          "Ressource Facultative - Scripts Dash"
        ],
        "Statistiques": [
          "Qu'est-ce que les Statistiques ?",
          "Échantillonnage",
          "Théorème Central Limite",
          "Échantillonnage et Théorème Central Limite",
          "Erreur Type",
          "Test Statistique",
          "Exercice #1 - Test Statistique",
          "Exercice #2 - Test Statistique",
          "Test Statistique #1",
          "Erreurs de Type 1 et de type 2",
          "Test Statistique #2",
          "Distribution de T-Student",
          "Exercice - Distribution T-Student",
          "Évaluation - Section Statistiques"
        ],
        "Analyse de la Variance (ANOVA)": [
          "Introduction à l'ANOVA",
          "ANOVA - Analyse de la Variance",
          "Distribution-F",
          "ANOVA à 2 facteurs",
          "Exercice - ANOVA à 2 facteurs",
          "ANOVA à 2 facteurs avec Réplication",
          "Évaluation - Section ANOVA"
        ],
        "Régression": [
          "Régression Linéaire",
          "Exemple de Régression",
          "Régression Multiple",
          "Évaluation - Section Régression"
        ],
        "Analyse du Khi carré": [
          "Analyse du Khi-carré",
          "Exercice - Analyse du Khi-carré",
          "Évaluation - Section Analyse Khi-carré"
        ],
        "BONUS": [
          "CHALLENGE PYTHON 30 JOURS",
          "Newsletter Mon Shot Data (pour les curieux)",
          "Programmes DATA pour continuer TON apprentissage",
          "Autres cours sur Udemy"
        ]
      },
      "requirements": [
        "Papier / Stylo pour prendre des notes",
        "Facultatif : Excel / Google Sheets ou Python pour exécuter des simulations"
      ],
      "description": "Bienvenue sur le cours de Probabilité et Statistiques appliqué à la Data science et aux cas Business !\n\n\nDans ce cours, nous abordons ce que vous devez savoir sur les Probabilités et les Statistiques pour réussir dans les affaires (Business) et dans le domaine de la science des données (Data Science) !\nCe cours pratique de probabilités/statistiques passera en revue la théorie et la mise en œuvre des statistiques directement sur des problèmes et cas issus du monde réel. Chaque section comporte des exemples de problèmes et exercices, des quiz de cours et des tests d'évaluation (au total c'est 7 tests d'évaluation et 43 questions de quiz pour valider vos connaissances)\n\n\nNous commencerons par parler des données (qu'est ce que c'est ? Quelles sont leurs types ?), puis nous chercherons à comprendre comment les examiner avec des mesures de la tendance centrale, de la dispersion, mais aussi à comprendre comment des sources de données bi-variées peuvent être reliées entre elles.\nEnsuite, nous nous plongerons dans les probabilités, en apprenant les combinaisons et les permutations, ainsi que les probabilités conditionnelles et la façon d'appliquer le théorème de Bayes.\nNous passerons ensuite à la discussion sur les distributions les plus courantes en statistique, se créant ainsi, par la même occasion, une base solide pour comprendre comment travailler avec des distributions uniformes, binomiales, de poisson et normales.\nEnsuite, nous parlerons de statistiques, en appliquant ce que nous avons appris jusqu'à présent à des cas concrets, y compris des tests statistiques et la distribution T de Student.\nNous terminerons le cours par trois sections sur des sujets avancés, tels que l'ANOVA (Analyse de Variance), la compréhension de l'analyse de régression et enfin l'analyse du chi carré.\n\n\nLes sections sont modulaires et organisées par sujet, vous pouvez donc vous y référer et vous lancer directement !\nCe cours comprend uniquement des vidéos HD avec des explications claires et des animations de qualité, nous incluons également des études de cas détaillées pour vous montrer comment appliquer ces connaissances au monde réel.\nNous couvrirons tout ce que vous devez savoir sur les statistiques et les probabilités pour aborder clairement les problèmes réels du monde des affaires et de la science des données !\n\n\nInclus :\nMesures des données\nMoyenne, médiane et mode\nVariance et écart-type\nCovariance et corrélation\nPermutations et combinaisons\nUnions et intersections\nProbabilité conditionnelle\nThéorème de Bayes\nDistribution binomiale\nDistribution de Poisson\nDistribution normale\nÉchantillonnage\nThéorème Central Limite\nTest statistique\nTest de distribution T\nAnalyse de régression\nANOVA (Analyse de la variance)\nAnalyse du Chi carré (Test du χ²)\net bien plus encore !\n\n\nNon seulement vous bénéficiez d'un excellent contenu technique, mais vous avez également accès à nos espaces Questions-Réponses en ligne ainsi qu'à notre canal de discussion pour les étudiants. Les assistants d'enseignement et moi-même sommes heureux de vous aider pour toutes les questions que vous rencontrez !\nÀ la fin de ce cours, vous recevrez un certificat de complétion que vous pourrez afficher sur votre profil Linkedin pour le montrer à vos collègues, ou même à des employeurs potentiels !\n\n\nTout ce contenu est assorti d'une garantie de remboursement de 30 jours, ce qui vous permet d'essayer le cours sans risque... !\n\n\nAlors, qu'en dites-vous ? On s'inscrit et on se retrouve dans le cours !",
      "target_audience": [
        "Toute personne désirant apprendre comment appliquer la probabilité et les statistiques en Data Science (Science des Données) et pour prendre des décisions Business (ou Commercial)"
      ]
    },
    {
      "title": "Guide to Careers in Data Science - Interview Hacks",
      "url": "https://www.udemy.com/course/complete-guide-to-crack-a-data-science-interview/",
      "bio": "An Amazing Interview Preparation guide that includes questions & answers for people with NO experience in Data Science",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Course Overview"
        ],
        "Important Downloads": [
          "All Qs and As given in this course",
          "Comprehensive List of Topics to Prepare for Data Science Interviews",
          "Outstanding Resume Format"
        ],
        "Data Science Job Outline": [
          "Why choose a Career in Data Science?",
          "Is Data Science for YOU?",
          "Job Titles in Data Science",
          "Educational Requirements",
          "Interdisciplinary Nature of Data Science",
          "Framework of a Typical Data Science Project"
        ],
        "Creating an Outstanding Resume": [
          "Important Elements to focus on",
          "Job Responsibilities Mistakes",
          "Adding Data Science Achievements",
          "Negative Elements",
          "Cover Letter Tactics"
        ],
        "Efficiently searching Data Science job": [
          "Top 5 Search Engines",
          "Direct Approach",
          "Getting Referrals",
          "PRO Tip"
        ],
        "Expertise & Readiness": [
          "R or Python & their Expertise Level",
          "How to know that I am ready?",
          "Do's and Don'ts of Preparation"
        ],
        "The Interview": [
          "Interview Process",
          "4 Mantras for Guaranteed Success"
        ],
        "Statistics Questions and Answers": [
          "Question and Answer 1",
          "Question and Answer 2",
          "Question and Answer 3",
          "Question and Answer 4",
          "Question and Answer 5",
          "Question and Answer 6",
          "Question and Answer 7",
          "Question and Answer 8",
          "Question and Answer 9",
          "Question and Answer 10"
        ],
        "Probability Questions and Answers": [
          "Question and Answer 1",
          "Question and Answer 2",
          "Question and Answer 3",
          "Question and Answer 4",
          "Question and Answer 5",
          "Question and Answer 6",
          "Question and Answer 7",
          "Question and Answer 8",
          "Question and Answer 9",
          "Question and Answer 10"
        ],
        "Machine Learning Questions and Answers": [
          "Question and Answer 1",
          "Question and Answer 2",
          "Question and Answer 3",
          "Question and Answer 4",
          "Question and Answer 5",
          "Question and Answer 6",
          "Question and Answer 7",
          "Question and Answer 8",
          "Question and Answer 9",
          "Question and Answer 10"
        ]
      },
      "requirements": [
        "Basic understanding of Statistics, Probability, Machine Learning, SQL, R or Python will be a plus",
        "If you don't know any of the above subjects then it's okay you will get a list of topics that should be studied for a Data Science job"
      ],
      "description": "Nowadays making a career in Data Science is one of the most common dreams and you are reading this just because of this reason.\nI had a passion to help people with their career decisions and that made me a Career Mentor.\nCreated a small Interview Preparation guide for my college mates to help them stop making common mistakes, this encouraged me to do more.\nSince I am a Data Science Author (I have written a lot of content for my clients/students) helping people start their careers in Data Science is one of my jobs which is the reason I created this course.\nSo, if you want to start your career in Data Science? Then this course is for YOU!\nThis complete guide is designed to answer all your queries regarding careers in Data Science such as:\nEfficient job search\n4 Mantras for Guaranteed Success\nEducational Requirements\nCreating an Outstanding Resume\nWhy choose a career in Data Science\nIs Data Science for YOU?\nInterview Questions and Answers\nDo's and Don'ts of Preparation\nJob Titles in Data Science\nHow to choose between R and Python?\nLevel of expertise required in these tools\nand many more.\nFeel free to message me on Udemy if you have any questions about the course!\nThanks for checking out the course page!\nEnroll Today and speed up your path toward a Data Science job.\nNizamuddin\nCourse Instructor",
      "target_audience": [
        "Anyone who wants to become a Data Scientist"
      ]
    },
    {
      "title": "【AutoML】自動化された機械学習を学ぼう！ 【PyCaret / Google Colab / Kaggle】",
      "url": "https://www.udemy.com/course/automl-ai/",
      "bio": "AutoML（自動機械学習）は、短いコードで効率的な機械学習の実装を可能にします。ライブラリPyCaretを使用し、データの前処理や機械学習モデルの比較、ハイパーパラメータの最適化などを自動化します。最後はKaggleの課題に取り組みます。",
      "objectives": [
        "AutoML（自動機械学習）の概要と基礎を学びます。",
        "ライブラリを使ったAutoMLの実装を学びます。",
        "短いコードで効率的に機械学習を行う方法を学びます。",
        "AutoMLと絡めて機械学習を学びます。",
        "機械学習アルゴリズムの比較、ハイパーパラメータのチューニングなどが短いコードで実装できるようになります。",
        "AutoMLを使ってKaggleの課題に取り組めるようになります。"
      ],
      "course_content": {
        "AutoMLの概要": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "AutoMLの概要",
          "開発環境について",
          "AutoMLの実演 Part1",
          "AutoMLの実演 Part2",
          "演習"
        ],
        "機械学習とAutoML": [
          "セクション2の教材",
          "Section2の概要",
          "機械学習の概要",
          "機械学習のアルゴリズム",
          "モデルの評価",
          "AutoML -回帰- Part1",
          "AutoML -回帰- Part2",
          "AutoML -クラスタリング-",
          "演習"
        ],
        "AutoMLの可能性の探求": [
          "セクション3の教材",
          "セクションを始める前に",
          "Section3の概要",
          "自然言語処理 Part1",
          "自然言語処理 Part2",
          "異常検知",
          "演習"
        ],
        "AutoMLの実践": [
          "セクション4の教材",
          "Section4の概要",
          "Kaggleの概要",
          "Kaggleの設定",
          "AutoMLの実践 -分類-",
          "AutoMLの実践 -回帰-",
          "演習"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "中学-高校レベルの数学で十分です。高度な数学は必要ありません。",
        "Google ColaboratoryやKaggleを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。",
        "ディープラーニング（深層学習）について詳しい解説は行いません。",
        "機械学習の各アルゴリズムについて、詳しい解説は行いません。いくつかを概要のみ解説します。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "機械学習の「原理」ではなく、AutoMLの「実装」を学ぶ講座となります。"
      ],
      "description": "（注: Google ColaboratoryにおけるPythonのバージョンが3.10に上がり、このコースにおける自然言語処理（pycaret.nlp）のコードが動かなくなりました。動作を確認するためには、Visual Studio Codeなどで別の環境を用意する必要があります。動作検証にこだわらない方は、関連レクチャーは動画だけ見て次に進んでください。）\n\n「【AutoML】自動化された機械学習を学ぼう！」は、これまでにない手軽さにより近年大きな注目を集めているAutoML（Automated Machine Learning、自動機械学習）を学ぶコースです。\n「AutoML」は、機械学習モデルの設計や構築を自動化すること、またはそのための概念全般のことで、機械学習の専門家でなくても高機能な機械学習の機能を利用可能にします。\n本講座では、AutoMLおよび機械学習について包括的に学んだ上で、AutoMLのライブラリPyCaretを使ってデータの前処理や機械学習モデルの比較、ハイパーパラメータの最適化などを自動化します\nその上で、最後はKaggle上でAutoMLを実践します。\nAutoMLのライブラリを使えば、数百行を超えるようなコードを数行のみのコードに置き換えることさえ可能になります。\n手軽なだけではなく実用的な技術であるため、これまで様々な理由で機械学習を敬遠してきた方にもお薦めです。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\nコースの内容は以下の通りです。\nSection1. AutoMLの概要\n→ AutoMLの概要を把握し、簡単なコードを試します\nSection2. 機械学習とAutoML\n→ AutoMLと関連付けて、機械学習全般について学びます\nSection3. AutoMLの可能性の探求\n→ 自然言語処理、異常検知などでAutoMLの可能性を探求します\nSection4. AutoMLの実践\n→ AutoMLを使い、Kaggle上で現実的な問題に取り組みます\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックがダウンロード可能です。\n本コースはディープラーニング用フレームワークとしてPyTorchを使用します。\nまた、Pythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "AutoMLに興味があるけど、始め方が分からない方。",
        "機械学習をツールとして使いこなしたい方。",
        "機械学習における定番の処理を自動化したい方。",
        "機械学習の長くて複雑なコードに辟易している方。",
        "AutoMLで何らかの問題を解決したい方。",
        "AutoMLをライブラリ（PyCaret）を使って実装したい方。",
        "AutoML全般の知識が欲しい方。",
        "AutoMLを使ってKaggleに取り組みたい方。"
      ]
    },
    {
      "title": "Sparse Matrix",
      "url": "https://www.udemy.com/course/sparse-matrix/",
      "bio": "Sparse Matrix Representation in RCV and CSR formats, Applications and Operations on Sparse Matrices",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basics of programming is sufficient"
      ],
      "description": "This course discusses about sparse matrices, its representations & operations and applications. Sparse matrix is one of the linear data structures to deal with non zero elements. If a matrix consists of more number of zero elements, storing those zeros and processing them would decrease computational efficiency. Use of sparse Matrix improves computational efficiency in terms of storage space and computational time. This course would be more useful to undergraduate, postgraduate students and research scholars who work with large data sets embedded with more zero elements.\nThis course teaches, the ways to represent sparse matrix such as Triples format( RCV format) and Compressed Sparse Row format (CSR). The implementations in Java to convert sparse Matrix to RCV & CSR Formats are explained in interactive mode. This course also covers applying sparse matrix in one of the machine learning applications \"sentiment analysis on products\". Sparse matrix operations are explained  in step by step with suitable examples. Operations included are Addition, Transpose and Multiplication. All the operations are explained with step by step process of rows(Row ,Column and Value) of input matrices. Movement of position from one row of a matrix to another row is explained in a simple way. The entire course is taught with Java coding. Learners feel more easier to understand the coding and influences to write their own  coding.",
      "target_audience": [
        "Under graduate & Post graduate",
        "Research Scholars"
      ]
    },
    {
      "title": "Chatbots com Python e Dialogflow: O Guia para Iniciantes",
      "url": "https://www.udemy.com/course/chatbots-python-dialogflow-iniciantes/",
      "bio": "Construa chatbots fácil e rapidamente para pedir pizzas, conversar sobre assuntos gerais e pesquisar texto em documentos",
      "objectives": [
        "Crie um chatbot básico para pedidos de pizza com o Dialogflow",
        "Implante os chatbots em sites web, no Facebook Messenger e utilizando a API Flask do Python",
        "Execute a Eliza no Python, que foi o primeiro chatbot da história",
        "Crie um chatbot para pesquisa textual de documentos, utilizando o modelo TF-IDF (Term Frequency - Inverse Document Frequency)",
        "Desenvolva um crawler básico para extrair textos de páginas web",
        "Entenda as oportunidades de mercado que a área de chatbot pode trazer para os profissionais de tecnologia da informação"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Slides + código fonte"
        ],
        "Chatbots com Dialogflow": [
          "Introdução ao Dialogflow e ao estudo de caso da pizzaria",
          "Criação do projeto",
          "Intenção pedido de pizzas",
          "Intenção pizzas do pedido",
          "Intenção status do pedido",
          "Intenção número do pedido",
          "Intenção de agradecimento",
          "Implantação do chatbot na web",
          "Implantação do chatbot no Facebook Messenger"
        ],
        "Chatbots com Python e NLTK": [
          "Eliza em Python",
          "Chatbots com o pacote chat do NLTK",
          "Pesquisa de documentos - bibliotecas",
          "Pesquisa de documentos - base de dados",
          "Pesquisa de documentos - pré-processamento 1",
          "Pesquisa de documentos - pré-processamento 2",
          "Pesquisa de documentos - frases de boas-vindas",
          "Pesquisa de documentos – bag of words e TF-IDF 1",
          "Pesquisa de documentos – bag of words e TF-IDF 2",
          "Pesquisa de documentos – similaridade cosseno",
          "Pesquisa de documentos – função de resposta do chatbot",
          "Pesquisa de documentos – conversação com o chatbot",
          "Implantação no Flask 1",
          "Implantação no Flask 1",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Conhecimento sobre lógica de programação, principalmente estruturas condicionais e de repetição",
        "É desejável conhecimento básico sobre Python, apesar de ser possível acompanhar o curso sem conhecimento aprofundado nessa linguagem"
      ],
      "description": "Dentro da área de Machine Learning (Aprendizagem de Máquina) existe uma sub-área que é o Processamento de Linguagem Natural, que tem o objetivo de reproduzir em computadores a compreensão automática de línguas humanas naturais. Alguns exemplos clássicos dessa área incluem: tradução de voz para texto, texto para voz, sumarização automática de documentos, adição automática de legendas em vídeos, detecção de entidades em textos, geração de linguagens, reconhecimento óptico de caracteres (OCR), dentre várias outras. E uma das aplicações mais famosas e relevantes atualmente são os chatbots (robôs de conversa), que consistem em sistemas de Inteligência Artificial que são capazes de entender a linguagem humana e darem respostas, tanto em texto quanto em voz! Esse tipo de tecnologia vem sendo cada vez mais utilizado por grandes empresas para acelerarem o atendimento ao cliente, ou seja, ao invés de você conversar com uma pessoa você conversa com um chatbot. Várias empresas de tecnologia tem investido grande capital no desenvolvimento de chatbots, como por exemplo: a Apple (Siri), a Microsoft (Cortana), o Google (Google Assitant) e a Amazon (Alexa).\nVárias previsões sugerem que 80% das empresas usarão chatbots até 2020, e empresas que ainda não integraram esse tipo de tecnologia às suas operações comerciais podem ficar atrás da concorrência! Devido a isso, existe uma grande demanda para a construção de chatbots básicos que trabalhem para as empresas. Empresas procuram desenvolvedores dessa área, o que abre novas oportunidades no mercado de trabalho! E essa demanda não está somente relacionada a chatbots complexos (assistentes virtuais) como os desenvolvidos pelas grandes empresas, mas sim chatbots que fornecem informações básicas sobre as empresas. Por exemplo, uma empresa de consultoria pode precisar de um chatbot para apresentar seus produtos e serviços para novos clientes, informar horários de atendimento ou simplesmente fazer o primeiro contato com um potencial novo cliente. A tendência é que muitas empresas precisarão deste tipo de chatbot muito mais do que ferramentas complexas que requerem um investimento muito maior. Do ponto de vista do desenvolvedor/programador, o desenvolvimento de chatbots do zero complexos requer um conhecimento muito mais avançado na área de Deep Learning e Processamento de Linguagem Natural, além de requerer recursos computacionais maiores.\nPensando nisso, o objetivo deste curso é apresentar a área de chatbots de maneira fácil e rápida para que você consiga desenvolver seus próprios chatbots! Ao final você terá as ferramentas necessárias para construir chatbots básicos que possam ser utilizados pelas empresas. Veja abaixo os projetos que você desenvolverá passo a passo:\nChatbot básico para pedido de pizzas com a ferramenta Dialoflow, sendo integrada em um site web e também no Messenger do Facebook\nConversar com a Eliza, que foi o primeiro chatbot da história desenvolvido em 1966! Usaremos o Python e o pacote chat da biblioteca NLTK (Natural Languagem Toolkit)\nChatbot baseado em regras para conversar sobre diversos assuntos, também usando o Python e o NLTK\nChatbot para pesquisa de textos em documentos: criaremos um pequeno crawler para extrair textos de páginas web, e depois, nosso chatbot será capaz de responder perguntas feitas pelos usuários sobre os textos! Também usaremos o Python e a técnica de TF-IDF (Term Frequency - Inverse Document Frequency) para fazer a filtragem do documentos\nEste curso é categorizado como nível iniciante, ou seja, para quem está começando no mundo dos chatbots!\nPreparado(a) para dar um importante passo na sua carreira? Aguardo você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em aprender como construir seu próprio chatbot",
        "Alunos que tenham interesse em construir chatbots básicos de maneira fácil, rápida e sem conhecimentos avançados em Deep Learning",
        "Profissionais que desejam fornecer o serviço de chatbots para seus clientes",
        "Empresas que desejam implementar chatbots básicos em seus negócios",
        "Alunos de graduação e pós-graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial"
      ]
    },
    {
      "title": "Explore Basic Statistics With IBM SPSS STATISTICS",
      "url": "https://www.udemy.com/course/spss-statistics/",
      "bio": "start learning data analysis",
      "objectives": [],
      "course_content": {
        "Lectures": [
          "Introduction to SPSSS",
          "User Interface of SPSS",
          "How to choose appropriate Statistical Test",
          "Descriptive Statistics",
          "Test of Normality",
          "Frequecy Distribution",
          "Bar Chart in SPSS",
          "Pie Chart in SPSS",
          "Histogram in SPSS",
          "Scatter Plot in SPSS"
        ]
      },
      "requirements": [
        "Computer using skills and Knowledge about statistics"
      ],
      "description": "What is IBM SPSS Statistics\nSPSS stands for Statistical Package for the Social Sciences, SPSS was made in 1968 than in 2009 was acquired by IBM and now its full name is IBM SPSS Statistics but most people only called it SPSS and it’s used for complex statistical analyses, Data visualization by Students, Teachers, Researchers, and Business firms. SPSS is used by most top research agencies to analyze survey results and analyze text data so they can improve their survey and research efforts.\nYou can open IBM SPSS Statistics by double-clicking on the IBM SPSS Statistics icon on the desktop (if it exists) or by going to the start menu, programs, IBM SPSS Statistics, and selecting IBM SPSS Statistics 26. Upon logging into IBM SPSS Statistics, this dialog box appears. You can run the tutorial guide, get a blank data window and enter your own data, use the database wizard to import an excel file, open an existing IBM SPSS Statistics file, or any other file. The file will be opened from an existing one. Each row represents a case, and each column represents a variable.\nKey features of IBM SPSS Statistics\nBasic hypothesis testing\nBootstrapping\nCluster analysis\nData access and management\nData preparation\nGraphs and charts\nHelp center\nLinear regression\nNonparametric tests\nOne-way ANOVA\nOutput management\nProgrammability extension\nROC analysis\nSupport for R/Python\n\nWindows of IBM SPSS Statistics\nSPSS has a variety of windows. You are currently working in the active window. Here are a few frequently used windows:\nData Editor Window\nIt shows the data file contents. When you open an SPSS session, this window will automatically open. With this window, you can create or modify data files. Each data file has a separate Data Editor window when you open more than one data file. There are two views of data in the Data Editor:\nData View\nIt displays the values of the data. Columns represent variables and each row represents a case.\nVariable View\nIt displays variables and their attributes. In the Variable View Window, you can modify each variable’s properties or add new variables or delete existing variables.\nViewer Window\nIt shows statistical results in the form of graphs, tables, and charts. You’ll receive the output window automatically if you run a procedure.\nPivot Table Editor\nIt displays the results in pivot tables. You can open this window by right-clicking on the table, going to edit content, and choosing “In separate window”. You can also go to the Edit Menu by left clicking on the table. Choose Edit content and then select a separate window. During the editing process, you will be able to modify the table.\nChart Editor Window\nIn this window, you can edit charts and plots in high resolution.\nText Output Editor Window\nThe purpose of this is to modify text output that isn’t displayed in pivot tables. Right click on the text output, select edit content, and select “In separate window”. This will allow you to customize the text output.\nSyntax Editor Window\nUsing command syntax, it displays the choices made in the dialog box. You can edit and run these commands to get some output. You can also run an old SPSS program here.",
      "target_audience": [
        "Beginner Data Analyst"
      ]
    },
    {
      "title": "Python Hacking: Ciberseguridad y Hacking Ético con Python",
      "url": "https://www.udemy.com/course/python-hacking-ciberseguridad/",
      "bio": "Domina la Ciberseguridad y el Hacking Ético con Python: Aprende a defender y atacar sistemas con programación en Python.",
      "objectives": [
        "Dominarás Python y su aplicación al Hacking Ético y la Ciberseguridad con más de 50 casos prácticos que simulan situaciones reales en entornos profesionales.",
        "Aprenderás Python desde cero hasta técnicas avanzadas de explotación, análisis y post-explotación para Hacking Ético y Ciberseguridad.",
        "Integrarás técnicas de Inteligencia Artificial para automatizar y optimizar la eficiencia y eficacia de tus operaciones utilizando Python.",
        "Realizarás escaneos y análisis de redes, hosts y servicios utilizando Python, Scapy, Nmap y técnicas de priorización basadas en Inteligencia Artificial.",
        "Construirás un portfolio de más de 50 proyectos reales para aplicar a puestos de trabajo relacionados con el Hacking Ético y la Ciberseguridad",
        "Desarrollarás y ejecutarás exploits, realizarás elevación de privilegios, y usarás PyMetasploit para explotar vulnerabilidades en hosts y aplicaciones web.",
        "Llevarás a cabo investigaciones OSINT con Python utilizando Shodan, análisis de DNS, geolocalización de IP y teléfonos y análisis de metadatos.",
        "Te especializarás en técnicas de post-explotación con Python, incluyendo cracking y obtención de contraseñas de navegadores y redes WiFi, persistencia y evasión"
      ],
      "course_content": {
        "Presentación del curso": [
          "Presentación del curso"
        ],
        "Preparación del entorno de aprendizaje": [
          "¿Cómo abordar este curso?",
          "Instalación de VMware",
          "Instalación de Kali Linux",
          "[Opcional] Instalación de VMware Fusión y Kali Linux en MacOS",
          "Instalación y configuración de Visual Studio Code"
        ],
        "Fundamentos e introducción a Python: Curso rápido de Python": [
          "Introducción a la sección",
          "¿Qué es Python? - Sintaxis y semántica",
          "Entrada y salida de usuario: Input y Print",
          "Práctica Print",
          "Tipos de datos simples: Strings, Números y FStrings",
          "Variables",
          "Práctica Variables, Strings y Números",
          "Comentarios",
          "Práctica Comentarios",
          "Tipos de datos complejos: Listas, Tuplas y Diccionarios",
          "Indexing, Slicing y Stride",
          "Práctica Listas, Tuplas y Diccionarios",
          "Operadores I: Aritméticos, Comparación y Asignación",
          "Lectura: Tipos de operadores Aritméticos, Comparación y Asignación",
          "Práctica Operadores Aritméticos, Comparación y Asignación",
          "Operadores II: Pertenencia, Lógicos e Identidad",
          "Lectura: Tipos de operadores Pertenencia, Lógicos e Identidad",
          "Práctica Operadores Pertenencia, Lógicos, Identidad",
          "Control de flujo: Sentencias condicionales - If else",
          "Práctica if else",
          "Control de flujo: Bucles - For, While, Break, Continue, Range",
          "Práctica bucle For",
          "Práctica bucle While",
          "Funciones: Parámetros, Argumentos, Return, Docstrings",
          "Lectura: Funciones propias de Python",
          "Práctica Funciones",
          "Práctica Docstrings",
          "Scope",
          "Práctica Scope",
          "Orientación a objetos: Clases, Métodos y Atributos",
          "Práctica Clases, Métodos y Atributos",
          "Orientación a objetos: Herencia y manejo de objetos",
          "Lectura: Métodos mágicos en Python",
          "Práctica Herencia y manejo de objetos",
          "Módulos y Paquetes en Python",
          "Práctica Programación Modular",
          "Librerías externas y pip",
          "Manejo de Excepciones en Python",
          "Práctica Excepciones",
          "Lectura: Zen of Python",
          "BONUS: Amplía tus conocimientos sobre Python"
        ],
        "Primer proyecto de Python Hacking: Google Hacking, IA y Automatización": [
          "Introducción a la sección",
          "Descarga de los ejercicios del curso",
          "Entornos virtuales en Python",
          "Disclaimer: Aviso importante",
          "Hacking con buscadores con Python - Parte 1",
          "Operadores y keywords Google Hacking",
          "Hacking con buscadores con Python - Parte 2",
          "[Opcional] Tarea: DuckDuckGo Hacking",
          "Ejecución de scripts en Python",
          "Argumentos en línea de comandos: Argparse",
          "Generación de resultados: JSON, HTML, Consola",
          "Manejo de ficheros: Descarga, Lectura y Escritura",
          "Inteligencia Artificial aplicada a Hacking Ético y Ciberseguridad",
          "Potenciando los Dorks con Inteligencia Artificial",
          "OpenAI, GPT-4 y ChatGPT-4",
          "Potenciando los Dorks con GPT-4",
          "Google Hacking con Inteligencia Artificial",
          "Filtrado de información con Expresiones Regulares",
          "Filtrado de información con Inteligencia Artificial - Parte 1",
          "Filtrado de información con Inteligencia Artificial - Parte 2",
          "[Opcional] Tarea: Integra SmartSearch con NinjaDork",
          "Emulando el comportamiento humano con Selenium",
          "Hacking con buscadores automático con Selenium"
        ],
        "Investigación de fuentes abiertas (OSINT) con Python Hacking": [
          "Introducción a la sección",
          "Descubriendo dispositivos en Internet con Shodan",
          "¿Qué buscar con Shodan?",
          "Shodan con Python: Identificando aplicaciones webs y hosts automáticamente",
          "Autenticación y Login automatizado con Python y Shodan",
          "Tarea: Automatiza el Login con Selenium",
          "Resolución tarea: Automatización Login con Selenium",
          "Procesamiento en paralelo con Python: Multithreading",
          "[Opcional] Tarea avanzada: Multithreading con Python",
          "Otros buscadores interesantes: Censys, ZoomEye, GreyNoise, DeHashed...",
          "Investigación de información histórica: Wayback Machine",
          "Filtrado de información histórica: PDF, DOC, TXT...",
          "Análisis y enumeración de DNS",
          "Lectura: ¿Cómo funciona DNS?",
          "Investigación de un nombre de dominio: WHOIS",
          "Geolocalización e investigación de una dirección IP",
          "Geolocalización e investigación de un número de teléfono",
          "Análisis de metadatos con Python: Imágenes",
          "Análisis de metadatos con Python: PDFs y Documentos",
          "Herramientas OSINT desarrolladas en Python: Sherlock, Spiderfoot..."
        ],
        "Escaneo y análisis de redes con Python: Hosts, Puertos, Servicios...": [
          "Introducción a la sección",
          "Sniffers con Python",
          "Sniffers con Python: Pyshark y Tshark",
          "Introducción a Scapy",
          "Sniffers con Python: Scapy",
          "Networking y Sockets con Python: Cliente-Servidor",
          "Entorno de aprendizaje: Instalación Linux vulnerable",
          "Escaneo de Hosts con Python y Sockets",
          "Escaneo de Hosts con Scapy",
          "Escaneo ARP con Scapy",
          "Escaneo de Puertos con Python",
          "Escaneo de Servicios y Banner con Python",
          "Entorno de aprendizaje: Instalación Windows",
          "Configuración de un recurso/carpeta de red",
          "Descubrimiento de recursos/carpetas de red con Python",
          "[Opcional] Tarea avanzada: Descarga los ficheros y procesa su contenido",
          "Integración de Nmap con Python: Hosts, Puertos, Servicios...",
          "Tarea: Escaneo y priorización de hosts con Inteligencia Artificial (IA)",
          "Escaneo y priorización de hosts con Inteligencia Artificial (IA)"
        ],
        "Análisis de vulnerabilidades en Hosts con Python": [
          "Introducción a la sección",
          "BeautifulSoup: Procesamiento de páginas web con Python",
          "CVE, CVSS, CVE Details con Python",
          "Escáner de vulnerabilidades con Python: Obtención de CVEs",
          "Escáner de vulnerabilidades con Python: Obtención de CVSS",
          "Escáner de vulnerabilidades con Python: Presentación de resultados",
          "[Opcional] Tarea: Integración de análisis de red y detección de vulnerabilidades",
          "Instalación y configuración de Nessus",
          "Introducción a Nessus con Python",
          "Nessus con Python: Creación de una sesión y consulta de políticas",
          "Nessus con Python: Creación de escaneos",
          "Nessus con Python: Descarga y procesamiento de resultados",
          "[Opcional] Tarea: Procesa los resultados de Nessus con Python"
        ],
        "Python Hacking y Explotación de vulnerabilidades en Hosts con Python": [
          "Introducción a la sección",
          "Desarrollo de exploits con Python: Introducción",
          "Desarrollo de exploits con Python: Ejecución remota de comandos",
          "Tarea: Explota la vulnerabilidad de UnrealIRCd con Python",
          "Resolución de la tarea: Explotación UnrealIRCd con Python",
          "Shell reversa TCP con Python",
          "Shell reversa HTTP con Python",
          "Convertidor One-liner con Inteligencia Artificial (IA)",
          "Shell reversa cifrada (HTTPs) en Python",
          "[Opcional] Tarea: Explota la vulnerabilidad UrealIRCd con una Shell cifrada",
          "Transferencia de ficheros con Python: HTTPServer",
          "Explotación del Kernel y elevación de privilegios con Python",
          "PyMetasploit: Metasploit con Python",
          "PyMetasploit: Enumeración y filtrado de módulos y exploits",
          "PyMetasploit: Configuración y ejecución de exploits",
          "PyMetasploit: Manejo de sesiones",
          "Bonus: Keylogger con Python",
          "Compilar programas en Python: Pyinstaller"
        ],
        "Python Hacking y Explotación de redes informáticas con Python": [
          "Introducción a la sección",
          "Man In The Middle (MITM) y ARP Spoofing",
          "ARP Spoofing con Python",
          "Interceptación de tráfico de red en tiempo real con Python",
          "Modificación de tráfico de red en tiempo real con Python",
          "Tarea: Modificación de tráfico HTTP en tiempo real",
          "Modificación de tráfico HTTP en tiempo real",
          "Introducción a DNS Spoofing",
          "DNS Spoofing con Python - Parte 1",
          "DNS Spoofing con Python - Parte 2",
          "[Opcional] Unas palabras sobre SSLStrip y HSTS",
          "Tarea: Detectar ARP Spoofing con Python",
          "Detectar ARP Spoofing con Python",
          "Fuerza Bruta SSH con Python - Parte 1",
          "Fuerza Bruta SSH con Python - Parte 2",
          "DHCP Listener con Python",
          "MAC Spoofing con Python - Parte 1",
          "MAC Spoofing con Python - Parte 2"
        ],
        "Python Hacking y Explotación de aplicaciones web con Python": [
          "Introducción a la sección",
          "Instalación de una aplicación web vulnerable",
          "Spidering y Crawling con Python - Parte 1",
          "Spidering y Crawling con Python - Parte 2",
          "OWASP ZAP con Python: Análisis avanzado de aplicaciones web",
          "Presentación de resultados con Streamlit",
          "Análisis pasivo con Python y OWASP ZAP",
          "Análisis activo con Python y OWASP ZAP",
          "Autenticación en una aplicación web con Python - Parte 1",
          "Autenticación en una aplicación web con Python - Parte 2",
          "Introducción al escaneo y explotación de XSS con Python",
          "Escaneo y explotación de XSS con Python - Parte 1",
          "Escaneo y explotación de XSS con Python - Parte 2",
          "Tarea: Implementa un escáner de SQL Injection con Python",
          "Escaneo y explotación de SQL Injection con Python",
          "Descubrimiento de subdominios con Python",
          "Descubrimiento de contenido web con Python - Parte 1",
          "Descubrimiento de contenido web con Python - Parte 2",
          "Tarea: Fuerza Bruta a paneles de autenticación web con Python",
          "Fuerza Bruta a paneles de autenticación web con Python",
          "Extendiendo Burp Suite con Python"
        ]
      },
      "requirements": [
        "El programa es apto para todos los niveles. No necesitas experiencia previa en programación. El programa incorpora un curso rápido de Python para empezar desde cero."
      ],
      "description": "¡Bienvenido a este curso de Python Hacking: Ciberseguridad y Hacking Ético con Python!\nCon más de 50 casos prácticos reales, 34 horas de vídeo y cientos de recursos descargables, este es el curso más completo y actualizado disponible en español, ¡y probablemente también en inglés!.\n¿Por qué este curso es único?\nInstructor experto: Mi nombre es Santiago Hernández y llevo más de 10 años trabajando en algunas de las empresas más grandes de España y Latinoamérica en el ámbito del Hacking Ético y la Ciberseguridad. He impartido decenas de conferencias por todo el mundo, algunas de ellas en eventos de Hacking tan reconocidos como BlackHat o ToorCon San Diego.\nCursos reconocidos: Soy uno de los instructores mejor calificados del mundo hispanohablante, mis cursos de Hacking Ético, Ciberseguridad e Inteligencia Artificial son los más vendidos de Udemy con más de 100.000 alumnos.\nPara todos los niveles: Aunque no tengas conocimientos previos de Python, este curso empieza con un módulo introductorio que te enseñará desde cero.\nEnfoque práctico: Cada sección incluye ejercicios y proyectos que simulan situaciones reales, aplicables en entornos profesionales.\nCurso integral: Con 34 horas de contenido en vídeo y cientos de recursos descargables, este curso abarca desde la instalación de herramientas hasta técnicas avanzadas de explotación, análisis y post-explotación.\n¿Qué aprenderás?\nA lo largo del curso, trabajarás en más de 50 casos prácticos reales, incluyendo Google Hacking y automatización con Python, análisis y escaneo de redes, explotación de vulnerabilidades en hosts y aplicaciones web, evasión de defensas y aplicación de Inteligencia Artificial al ámbito del Hacking Ético y la Ciberseguridad.\nEntre los temas más relevantes que aprenderás se encuentran los siguientes:\nPreparación del entorno de aprendizaje, donde comenzaremos con la instalación de VMware, Kali Linux, y Visual Studio Code para asegurarnos de que tienes todas las herramientas necesarias configuradas correctamente.\nFundamentos e introducción a Python, donde tendrás un curso rápido de Python. Aquí, aprenderás desde la sintaxis y semántica básica de Python, tipos de datos, hasta el control de flujo con condicionales y bucles. Además, profundizaremos en funciones, orientación a objetos, módulos, excepciones y el uso de librerías externas.\nEn el primer proyecto de Python Hacking, nos enfocaremos en Google Hacking, IA y Automatización. Aprenderás cómo usar Python para automatizar búsquedas, aplicar Inteligencia Artificial para mejorar técnicas de Hacking, manejar scripts y archivos, y emular el comportamiento humano con Selenium.\nLa investigación de fuentes abiertas (OSINT) con Python Hacking es una sección crucial donde utilizaremos Shodan y otros buscadores especializados para el análisis de DNS, geolocalización de IP y números de teléfono. También analizaremos metadatos y usaremos herramientas OSINT, además de realizar análisis de información histórica.\nEscaneo y análisis de redes con Python, abordando desde sniffers y análisis de tráfico de red con Sockets y Scapy, hasta el escaneo de hosts, puertos y servicios. También integraremos Nmap y utilizaremos Inteligencia Artificial para priorizar hosts.\nEn el análisis de vulnerabilidades en Hosts con Python, usaremos BeautifulSoup para el procesamiento web y desarrollaremos un escáner de vulnerabilidades. Aprenderás a obtener y analizar CVEs y CVSS, y a usar Nessus con Python para el escaneo de vulnerabilidades.\nLa explotación de vulnerabilidades en Hosts con Python incluirá el desarrollo de exploits, shells TCP, HTTP y HTTPS reversas, transferencia de archivos y elevación de privilegios. Además, aprenderás a usar PyMetasploit para la explotación de vulnerabilidades y a compilar programas con Python y Pyinstaller.\nLa explotación de redes informáticas con Python te enseñará técnicas como MITM, ARP Spoofing y DNS Spoofing, interceptación y modificación de tráfico en tiempo real, y fuerza bruta y spoofing de MAC y DHCP.\nEn la explotación de aplicaciones web con Python, analizaremos aplicaciones web con OWASP ZAP y explotaremos vulnerabilidades como XSS y SQL Injection. También aprenderás a descubrir subdominios y contenido web, y a extender Burp Suite con Python.\nFinalmente, en la post-explotación y evasión de defensas con Python, te centrarás en el cracking de contraseñas y hashes, obtención de contraseñas de navegadores y redes WiFi, persistencia y evasión de defensas con Python, y esteganografía para la exfiltración de información.\nGarantía de satisfacción: Estamos tan seguros de que te encantará este curso que ofrecemos una garantía de devolución del dinero de 30 días. ¡Inscríbete hoy sin riesgos y transforma tu carrera!\n¡No esperes más, haz clic en el botón de compra y únete a nosotros en este apasionante de viaje de aprendizaje sobre Hacking Ético y Ciberseguridad con Python!\nTestimonios de nuestros estudiantes:\n\"Los cursos de Santiago Hernández son los mejores con diferencia, en calidad de imagen, audio, explicación y contenido. Inmejorable.\" - Antonio García\n\"Buen contenido, claro, preciso y útil, presentado de una forma muy dinámica que mantiene la atención. Felicitaciones por este buen curso.\" - Hernando Hoyos\n\"Fue un curso excelente, con muchos temas muy interesantes y sobre todo que pueden tener una aplicación inmediata en sectores profesionales de TI.\" - Jonathan Camacho\n\"Actualmente estoy tomando el curso y estoy muy contento con mi progreso hasta ahora. El curso está muy bien organizado, lo que facilita entender conceptos complejos de manera clara y sencilla. Cada sección está llena de información valiosa y las explicaciones del instructor son detalladas y fáciles de seguir.\" - Víctor Cornejo",
      "target_audience": [
        "Personas que desean aprender Python aplicado a Hacking Ético y Ciberseguridad mediante proyectos reales y útiles.",
        "Aquellos que buscan dedicarse profesionalmente al Hacking Ético y la Ciberseguridad.",
        "Personas que desean aplicar técnicas de Inteligencia Artificial en el ámbito de Hacking Ético y Ciberseguridad.",
        "Profesionales que quieren perfeccionar sus habilidades de Hacking Ético mediante el uso de Python.",
        "Desarrolladores que desean mejorar su nivel de Python implementando proyectos reales de Hacking Ético y Ciberseguridad.",
        "Personas que quieren aprender a programar en Python con un enfoque práctico y aplicado a entornos profesionales.",
        "Aquellos interesados en construir sus propias herramientas avanzadas de Hacking Ético y Ciberseguridad.",
        "Cualquier persona curiosa que quiera explorar el mundo del Hacking Ético y Ciberseguridad a través de Python y proyectos prácticos."
      ]
    },
    {
      "title": "Mastering Machine Learning: Course-1",
      "url": "https://www.udemy.com/course/mastering-machine-learning-course-1/",
      "bio": "Taking First Step Towards Machine Learning",
      "objectives": [],
      "course_content": {
        "Introduction to Machine Learning": [
          "Beginning with Machine Learning",
          "Regression: Supervised Machine Learning",
          "Classification: Supervised Machine Learning",
          "Unsupervised Machine Learning"
        ],
        "Simple Linear Regression": [
          "Fitting Straight Line for Simple Linear Regression",
          "Cost Function for Simple Linear Regression"
        ],
        "Beginning with Python": [
          "Python Libraries for Building ML Models",
          "Performing Data Selection with Pandas"
        ],
        "Implementing Simple Linear Regression": [
          "Install Anaconda and Spyder to Implement Simple Linear Regression",
          "Dataset for Implementation of Simple Linear Regression",
          "Step 1: Importing the Libraries and the Dataset",
          "Step 2a: Train Test Split and Its Need for Implementation of SLR",
          "Step 2b: Performing Train Test Split for Implementation of SLR",
          "Step 3: Building the Model for Implementation of SLR",
          "Step 4: Predicting the Values on Test Data for Implementation of SLR",
          "Step 5: Visualization of Results for Implementation of SLR",
          "Step 6: Evaluating the model using Regression metrics for Implementation of SLR"
        ]
      },
      "requirements": [
        "Zero prior technical experience is required! All you need is a passion to learn and experiment new things."
      ],
      "description": "This course will be a part of series of Free ML Courses to become an expert of ML. Presenting here its First Course on Machine Learning for becoming expert of ML.\nThis course presents the concepts of Supervised Machine Learning, Unsupervised Machine Learning, Regression and Classification.\nIt covers implementation of Simple Linear Regression.",
      "target_audience": [
        "Machine Learning Enthusiast",
        "Students taking Machine Learning Course",
        "Professionals working in the area of Data Analytics",
        "Students preparing for placement tests and interviews",
        "Excellent course for all the students of Non-IT Branches as it provides the basic knowledge of ML without any prerequisite"
      ]
    },
    {
      "title": "Veri Bilimi ve Makine Öğrenmesi 2025 : 100 Günlük Kamp",
      "url": "https://www.udemy.com/course/yapay-zeka-100-gunluk-kamp/",
      "bio": "Yapay zekaya sıfırdan başlayarak 50'den fazla veri seti örneğiyle veri bilimi ve makine öğrenmesi konularını anlayın!",
      "objectives": [
        "Python",
        "İstatistik",
        "Veri Bilimi",
        "Makine Öğrenmesi",
        "Yapay Zeka"
      ],
      "course_content": {
        "Giriş": [
          "Giriş"
        ],
        "Gün 0: Veri Bilimine ve Makine Öğrenmesine Başlangıç": [
          "Eğitimde İşlenecek Konular",
          "Eğitim Materyalleri",
          "Eğitim Materyal Linkleri"
        ],
        "Gün 1: Giriş ve Kurulumlar": [
          "Bilgisayarlar Nasıl Çalışır",
          "Metin Görsel ve Ses",
          "Farklı Programlama Alanları",
          "Anaconda Nedir?",
          "Windows İçin Anaconda Yüklemek",
          "MAC İçin Anaconda Yüklemek",
          "Anaconda Alternatifi",
          "Değişkenlere Giriş"
        ],
        "Gün 2: Veri Tipleri": [
          "Numaralar",
          "Int vs Float",
          "String",
          "String Methodları"
        ],
        "Gün 3: Veri Yapıları": [
          "Index Mantığı",
          "Slicing Nedir",
          "Slicing Örnekleri",
          "Liste Nedir",
          "Liste Özellikleri",
          "Veri Tipi Dönüştürme",
          "İleri Seviye Listeler"
        ],
        "Gün 4: Sözlük - Set - Tuple": [
          "Sözlükler",
          "Sözlük Pratikleri",
          "Set",
          "Farklı Oluşturma Teknikleri",
          "Tuple",
          "Bool"
        ],
        "Gün 5: Quiz 1": [
          "Quiz ve Defter İndirme",
          "Jupyter Notebooks GitHub Link",
          "Quiz Çözümleri"
        ],
        "Gün 6: Kontroller ve Döngüler": [
          "Kıyaslama İşlemleri",
          "If Kontrolleri",
          "Döngüler Giriş",
          "For Döngüsü",
          "Break Continue Pass"
        ],
        "Gün 7: Döngüler": [
          "While",
          "İleri Seviye İşlemler 1",
          "İleri Seviye İşlemler 2"
        ],
        "Gün 8: Quiz 2": [
          "Quiz 2",
          "Quiz 2 Çözümleri"
        ]
      },
      "requirements": [
        "İnternet bağlantısı olan bir bilgisayar"
      ],
      "description": "Veri Bilim, Makine Öğrenmesi, Python ve Yapay Zeka konularına meraklıysanız ama şu ana kadar bir türlü öğrenemediyseniz doğru yerdesiniz!\nBu eğitim ile tamamen sıfırdan başlayarak Python, Data Science, Machine Learning gibi Yapay Zeka konularının hepsini kafanızda soru işareti kalmadan öğreneceksiniz. Bu eğitim için oluşturulan onlarca özel makaleden ve yine 50'den fazla veri setinden faydalanarak hem teoriyi hem de pratiği uygulayacaksınız.\nKurs Udemy'de 400.000+ öğrenciye Yazılım, Yapay Zeka ve Siber Güvenlik eğitimleri veren ve Boğaziçi Üniversitesi'nde Yazılım Eğitmeni olan Atıl Samancıoğlu tarafından veriliyor! Siz de Veri Bilimi & Makine Öğrenimi konularına adım atmak istiyorsanız aşağıdaki detaylı açıklamayı inceleyip kursa hemen kayıt olabilirsiniz.\nBu kursta birçok konuyu beraber işleyeceğiz. Eğitimin içindeki bölümlerde değineceğimiz konulardan bazıları şunlar:\nSıfırdan İleri Seviyeye Python\nVeri Bilimi İçin İstatistik ve Matematik\nNumpy\nPandas\nMatplotlib\nSeaborn\nVeri Bilimi\nEDA\nFeature Engineering\nSQL\nMakine Öğrenmesi Algoritmaları\nModel Kaydetme\nGözetimli Öğrenme\nGözetimsiz Öğrenme\nKaggle\nİçerik & Genel Görünüş\nBu kurs tamamen sıfırdan başlayanlar ve daha önce veri bilimi tarafında kafasında soru işareti kalanlar için oluşturulmuştur. Eğitim boyunca yapılan her bir adımın neden yapıldığını, veri bilimi ve makine öğrenmesinin arka planındaki matematiği, istatistiği çok iyi anlayacağız. Teorik bilgileri hiç bir zaman es geçmeyeceğiz. Aynı zamanda öğrendiğimiz tüm bilgileri pratiğe dökerek bilgilerimizin pekişmesini sağlayacağız.\nEğitim boyunca profesyonel anlamda veri bilimi, yapay zeka uzmanı olmak isteyenler için mülakat ipuçları verip, iş hayatında bu yeteneklerin kullanımını tek tek anlayacağız.\nEğitim içerisinde yazılan tüm kodlar ve projeler sizlerle GitHub'da paylaşılacaktır. Ayrıca eğitim özelinde hazırlanan tüm makaleler, veri setleri vb. materyaller sizinle paylaşılacaktır. Bu şekilde kendi uygulamalarınızı geliştirirken ilgili komutları referans alabilir, istediğiniz şekilde kullanabilirsiniz!",
      "target_audience": [
        "Veri bilimine meraklı kişiler",
        "Python öğrenmek isteyenler",
        "Yapay zeka uzmanı olmak isteyenler",
        "Makine öğrenmesi konusunda derinleşmek isteyenler"
      ]
    },
    {
      "title": "Learn To Predict Breast Cancer Using Machine Learning",
      "url": "https://www.udemy.com/course/learn-to-predict-breast-cancer-using-machine-learning-v/",
      "bio": "Learn to build three Machine Learning models (Logistic regression, Decision Tree, Random Forest) from scratch",
      "objectives": [],
      "course_content": {
        "Introduction - Loading Dataset": [
          "Setting up Colab Environment",
          "Importing and downloading python libraries",
          "Downloading Dataset from Kaggle [Part 1]",
          "Downloading Dataset from Kaggle [Part 2]"
        ],
        "EDA - Exploratory Data Analysis": [
          "Data Analysis [Part 1] - Summary Statistics",
          "Data Analysis [Part 2] - Dropping The Column With All Missing Values"
        ],
        "Data Visualization": [
          "Display A Count Of Malignant (M) Or Benign (B) Cells",
          "Pair Plot - Plot Pairwise Relationships In A Dataset",
          "HeatMap - Get The Correlation Of The Columns"
        ],
        "Dataset Manipulation on ML Algorithms": [
          "Scaling The Dataset - Feature Scaling"
        ],
        "Create Function For Three Different Models": [
          "Building Logistic Regression Classifier",
          "Building Decision Tree Classifier",
          "Building Random Forest Classifier"
        ],
        "Evaluate the performance of the model": [
          "Evaluate the performance of the model",
          "Model Accuracy On Confusion Matrix",
          "Model Prediction Vs. Actual Prediction"
        ]
      },
      "requirements": [
        "Basics of Python",
        "Some high school mathematics level.",
        "Some programming experience"
      ],
      "description": "Here you will learn to build three models that are Logistic regression model, the Decision Tree model, and Random Forest Classifier model using Scikit-learn to classify breast cancer as either Malignant or Benign.\nWe will use the Breast Cancer Wisconsin (Diagnostic) Data Set from Kaggle.\nPrerequisite\nYou should be familiar with the Python Programming language and you should have a theoretical understanding of the three algorithms that is Logistic regression model, Decision Tree model, and Random Forest Classifier model.\nLearn Step-By-Step\nIn this course you will be taught through these steps:\n\n\nSection 1: Loading Dataset\nIntroduction and Import Libraries\nDownload Dataset directly from Kaggle\n2nd Way To Load Data To Colab\nSection 2: EDA - Exploratory Data Analysis\nChecking The Total Number Of Rows And Columns\nChecking The Columns And Their Corresponding Data Types (Along With Finding Whether They Contain Null Values Or Not)\n2nd Way To Check For Null Values\nDropping The Column With All Missing Values\nChecking Datatypes\nSection 3: Visualization\nDisplay A Count Of Malignant (M) Or Benign (B) Cells\nVisualizing The Counts Of Both Cells\nPerform LabelEncoding - Encode The 'diagnosis' Column Or Categorical Data Values\nPair Plot - Plot Pairwise Relationships In A Dataset\nGet The Correlation Of The Columns -> How One Column Can Influence The Other Visualizing The Correlation\nSection 4: Dataset Manipulation on ML Algorithms\nSplit the data into Independent and Dependent sets to perform Feature Scaling\nScaling The Dataset - Feature Scaling\nSection 5: Create Function For Three Different Models\nBuilding Logistic Regression Classifier\nBuilding Decision Tree Classifier\nBuilding Random Forest Classifier\nSection 6: Evaluate the performance of the model\nPrinting Accuracy Of Each Model On The Training Dataset\nModel Accuracy On Confusion Matrix\n2nd Way To Get Metrics\nPrediction\nConclusion\nBy the end of this project, you will be able to build three classifiers to classify cancerous and noncancerous patients. You will also be able to set up and work with the Google colab environment. Additionally, you will also be able to clean and prepare data for analysis.",
      "target_audience": [
        "Interested in the field of Machine Learning? Then this course is for you!",
        "This course had been designed to be your guide to learning how to use the power of Python to analyze data, create some good beautiful visualization for better understanding and use some powerful machine learning algorithms.",
        "This course will also give you a hands-on walk through step-by-step into the world of machine learning and how amazing it is to make prediction on some serious real-life problems. This course will not only help you develop new skills and improve your understanding but also grow confidence in you."
      ]
    },
    {
      "title": "Data Structures in Python: Learn, Apply, and Master",
      "url": "https://www.udemy.com/course/data-structures-in-python-darwish/",
      "bio": "Your Complete Guide to Understanding and Implementing Python Data Structures",
      "objectives": [],
      "course_content": {
        "Python Data Structures Course Introduction": [
          "Course Introduction",
          "What will you learn in this Course ?"
        ],
        "Data Structures | Lists": [
          "Lists Creation",
          "List Methods",
          "List Operations",
          "List Functions",
          "List Use Cases"
        ],
        "Data Structures | Tuples": [
          "Tuple Definition",
          "Tuples Methods",
          "Tuple Functions",
          "List vs Tuple"
        ],
        "Data Structures | Dictionary": [
          "Dictionary Definiton",
          "Dictionary Operations",
          "Dictionary Functions",
          "Dictionary Use Cases"
        ],
        "Data Structure | SETS": [
          "Set Definitions",
          "Set Operations",
          "Set Math Operations",
          "Sets Use Cases"
        ],
        "Python Data Structure Conclusion": [
          "Conclusion"
        ]
      },
      "requirements": [
        "Python Basics"
      ],
      "description": "Are you ready to master data structures in Python and elevate your programming skills?\n\n\nThis course, \"Data Structures in Python: Learn, Apply, and Master\", is taught by Darwish, a Microsoft Certified Instructor and Python Expert with over 15 years of experience in the tech industry.\nWith a track record of teaching 50,000+ students worldwide, Darwish is here to guide you through a step-by-step journey to mastering Python data structures.\n\n\nUnlock the Power of Python Data Structures with this Comprehensive Course!\nAre you ready to master data structures in Python and elevate your programming skills? This course, \"Data Structures in Python: Learn, Apply, and Master\", is designed to take you on a step-by-step journey from understanding the fundamentals to applying advanced techniques with real-world examples.\nWhether you're a beginner or an experienced programmer looking to enhance your knowledge, this course has everything you need to succeed.\n\n\nWhat You’ll Learn:\nLists: Master sequential data storage, slicing, and advanced operations.\nTuples: Understand immutable sequences and their real-world applications.\nDictionaries: Explore key-value pairs and how to manage structured data efficiently.\nSets: Learn to handle unique collections and perform set operations like union, intersection, and difference.\n\n\nWhy Enroll?\nMastering Python’s core data structures is essential for  programming and problem-solving.\nBy the end of this course, you’ll have understanding of Lists, Tuples, Dictionaries, and Sets and the confidence to use them effectively in your projects.\n\n\nJoin \"Data Structures in Python: Learn, Apply, and Master\" today and learn from Darwish, one of the most trusted instructors in the field.\n\n\nEnroll now and start building a strong foundation in Python!",
      "target_audience": [
        "Beginner Python Developers",
        "Developers curious about Data Science"
      ]
    },
    {
      "title": "Inteligência Artificial: Algoritmos Genéticos",
      "url": "https://www.udemy.com/course/algoritmos-geneticos/",
      "bio": "Introdução à AGs: Maximização de Função 2D",
      "objectives": [
        "Desenvolver um Algoritmo Genético para encontrar soluções dentre muitas possíveis com a Computação Evolutiva",
        "Projetar e Desenvolver AGs para determinado problema em que os seres humanos não são capazes"
      ],
      "course_content": {
        "Introdução ao Curso": [
          "Introdução e Estrutura Curricular"
        ],
        "Teoria dos Algoritmos Genéticos": [
          "Introdução ao Algoritmos Genéticos",
          "AG: Representação Cromossômica",
          "AG: Representação Populacional",
          "AG: Função de Avaliação",
          "AG: Média de Avaliação da População",
          "AG: Fluxo de Execução do Algoritmo Genético",
          "AG: Seleção dos Pais",
          "AG: Operador de Crossover",
          "AG: Operador de Mutação"
        ],
        "Desenvolvimento do Algoritmo Genético (Maximização de Função)": [
          "Introdução à Maximização de Funções",
          "Projeto do Algoritmo Genético",
          "Configurando o Visual Studio para Projeto de AG",
          "Prog: Classe Constants (Parâmetros do AG)",
          "Prog: Classe Individuo - Parte 1",
          "Prog: Classe Individuo - Parte 2",
          "Prog: Classe Populacao - Parte 1",
          "Prog: Classe Populacao - Parte 2",
          "Prog: Classe Populacao - Parte 3",
          "Prog: Classe AlgoritmoGenetico - Parte 1",
          "Prog: Classe AlgoritmoGenetico - Parte 2",
          "Prog: Classe AlgoritmoGenetico - Parte 3",
          "Prog: Interface Gráfica de Usuário",
          "Prog: Back End da Interface Gráfica de Usuário - Parte 1",
          "Prog: Back End da Interface Gráfica de Usuário - Parte 2",
          "Prog: Back End da Interface Gráfica de Usuário - Parte 3",
          "Analisado a Evolução: Modificando os Parâmetros de Configuração",
          "Teste Final: Executando"
        ],
        "Considerações Finais": [
          "Finalizando o Curso"
        ]
      },
      "requirements": [
        "Lógica de Programação (Básico)",
        "Linguagem c# (Básico)",
        "Orientação a Objeto (Básico)"
      ],
      "description": "Um Algoritmo Genético (AG) é uma técnica de busca utilizada na ciência da computação para achar soluções aproximadas em problemas de otimização e busca. Algoritmos genéticos diferem dos algoritmos tradicionais de otimização em basicamente quatro aspectos:\nBaseiam-se em uma codificação do conjunto das soluções possíveis, e não nos parâmetros da otimização em si;\nOs resultados são apresentados como uma população de soluções e não como uma solução única;\nNão necessitam de nenhum conhecimento derivado do problema, apenas de uma forma de avaliação do resultado;\nUsam transições probabilísticas e não regras determinísticas.\nfunção AlgoritmoGenético(população, função-objetivo) saídas: indivíduo entradas: população→ uma lista de indivíduos função-objetivo→ uma função que recebe um indivíduo e retorna um número real. repetir lista de pais := seleção(população, função-objetivo) população := reprodução(lista de pais) enquanto nenhuma condição de parada for atingida retorna o melhor indivíduo da população de acordo com a função-objetivo\nEste é um curso para quem deseja começar a desenvolver algoritmos para Inteligência Artificial.\nNeste curso você aprenderá a teoria básica sobre Algoritmos Genéticos, vamos percorrer todo o caminho no que tange o AG, começando com a teoria da evolução de Darwin e terminando com o desenvolvimento de um Algoritmo Genético para maximizar uma função matemática.\nEstrutura Curricular:\nTeoria do Algoritmo Genético\nInteligência Computacional\nUm pouco de Biologia\nConceitos Básicos de AG\nAprofundando em Algoritmos Genéticos\nArquitetura do AG\nRepresentação Cromossômica\nRepresentação Populacional\nFunção de Avaliação\nMédia da População\nOperadores Genéticos\nSeleção dos Pais\nOperador Crossover\nOperador Mutação\nDesenvolvimento de um Algoritmo Genético\nIntrodução a Maximização de Funções\nArquitetura do Projeto\nPreparando o Visual Studio C#\nProgramando a Classe CONSTANTS\nProgramando a Classe INDIVIDUO\nProgramando a Classe POPULACAO\nProgramando a Classe ALGORITMOSGENETICOS\nProgramando a Interface Gráfica\nApresentação da Execução do Algoritmo Genético",
      "target_audience": [
        "Estudantes iniciantes em Inteligência Artificial",
        "Pessoas que procuram aprimorar processos por meio de Computação Evolutiva"
      ]
    },
    {
      "title": "自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発",
      "url": "https://www.udemy.com/course/ai-nlp-bot/",
      "bio": "ディープラーニング（深層学習）を利用して、日本語を解析し文章を作成しましょう。 NLPを利用した人工知能チャットボットの構築も行います。",
      "objectives": [
        "自然言語処理（NLP）の本質を理解し、コードが書けるようになります。",
        "夏目漱石、宮沢賢治、江戸川乱歩風のテキストの自動生成について学びます。",
        "リカレントニューラルネットワーク（RNN）による自然言語処理を学びます。",
        "チャットボットなどに利用可能な、対話文の自動生成について学びます。",
        "自然言語処理を、チャットボットの開発につなげる方法を学びます。",
        "LSTM、GRU、Seq2SeqなどのRNNの発展形について学びます。"
      ],
      "course_content": {
        "イントロダクション": [
          "コースの概要",
          "自然言語処理の概要",
          "チャットボットの概要"
        ],
        "学習の準備": [
          "Anacondaのインストール",
          "（補足 2022.7）Anaconda有償化への対応について",
          "Jupyter Notebookの使い方",
          "教材のダウンロードと使い方"
        ],
        "Pythonの基礎": [
          "Pythonの基礎1",
          "Pythonの基礎2",
          "NumPyの基礎",
          "Matplotlibの基礎"
        ],
        "必要な数学": [
          "数学の基本",
          "線形代数の基礎",
          "微分の基礎",
          "正規分布"
        ],
        "ニューラルネットワークとバックプロパゲーション": [
          "ニューラルネットワークの概要",
          "バックプロパゲーションの概要"
        ],
        "自然言語処理の準備": [
          "（補足 2021.10）janome、gensimのバージョンアップに伴うコードの変更について",
          "仮想環境の構築",
          "Pythonにおける正規表現",
          "コーパスの前処理",
          "形態素解析"
        ],
        "word2vec": [
          "word2vecの概要",
          "分散表現の確認",
          "単語の類似度",
          "単語ベクトルの演算",
          "文章の類似度"
        ],
        "リカレントニューラルネットワーク（RNN）": [
          "RNNの概要",
          "Kerasの基礎",
          "シンプルなRNNの実装",
          "RNNによる自然言語処理",
          "勾配クリッピング"
        ],
        "LSTM": [
          "LSTMの概要",
          "LSTM層の仕組み",
          "シンプルなLSTMの実装",
          "GRUの概要",
          "シンプルなGRUの実装",
          "LSTM、GRUによる自然言語処理"
        ],
        "文章の生成": [
          "Seq2Seqによる対話生成の概要",
          "シンプルなSeq2Seq",
          "対話コーパスの前処理",
          "対話の学習",
          "対話の検証"
        ]
      },
      "requirements": [
        "自分で調べながら環境構築にトライできる方。",
        "何らかの、オブジェクト指向プログラミングの経験があった方がベターです。",
        "WindowsでもMacでも大丈夫です。Linuxのサポートは行いませんが、コードは全ての環境で共通のものです。",
        "フレームワークにKerasを使います。",
        "開発環境の構築、Pythonや数学の解説動画は、他のコースのものと重複する場合があります。"
      ],
      "description": "本コースは、自然言語処理を学び、チャットボットの開発につなげる講座です。\n可能な限りシンプルに、自然言語処理の本質を解説します。\nRNNやLSTMを学び、テキストや対話文の生成ができるようになりましょう。\n\n\n本コースに必要なPythonと数学を習得した上で、単語をベクトル化するword2vec、時系列データを扱うRNNなどを学んでいきます。\nこれらの技術をベースに、夏目漱石や宮沢賢治、江戸川乱歩の文体を模倣した、テキストの自動生成を行います。\nまた、Seq2Seqによる対話文の自動生成技術を学び、チャットボット開発につながる対話文の自動生成を行います。\nそして、AIに宮沢賢治の文体を学習させて、賢治botを作ります。\nヒトと機械のコミュニケーションについて、可能性を探ってみましょう。\n\n\n自然言語とは日本語や英語などの我々が普段使う言語のことですが、自然言語処理（Natural Language Processing、NLP）は自然言語をコンピュータで処理する技術のことです。\n自然言語処理は検索エンジン、機械翻訳、スパムフィルタ、音声アシスタント、小説の執筆や対話システムなど、様々な分野で活躍しつつあります。\nそして、これをベースにしたチャットボットは多くの可能性を秘めており、今後の世界で重要な役割を果たしていくことは間違いないでしょう。\n————————————————————\n本コースの主な内容は以下の通りです。\n開発環境の構築、Pythonや数学の解説動画は、他のコースのものと重複する場合があります。\n\n\n自然言語処理の準備\n→ 環境の用意や前処理など、自然言語処理に必要な準備を行います。\n\n\nword2vec\n→ 単語や文章をベクトル化する技術について学びます。\n\n\nリカレントニューラルネットワーク（RNN）\n→ RNNについて基礎を学び、自然言語処理につなげます。\n\n\nLSTM\n→ RNNの発展形であるLSTMについて学び、自然言語処理につなげます。\n\n\n文章の自動生成\n→ Seq2Seqにより、対話文を自動生成する方法について学びます。\n\n\nチャットボットの開発\n→ 自然言語処理の技術を、チャットボットの開発につなげる方法を学びます\n————————————————————\n\n\n本コースでは可能な限り簡単に環境を構築できるように工夫していますが、お手元の環境によってはご自身で調べながらの環境構築が必要です。\n動画を見るのみでも学習が進められるようになっていますが、可能であればPythonのコードを動かしながら進めるのが望ましいです。\nコードがダウンロード可能なので、これをベースにオリジナルの自然言語処理のコードを書いてみることもお勧めです。\n修了した方は、学習意欲が刺激されて自然言語処理のことをさらに知りたくなっているかと思います。",
      "target_audience": [
        "自然言語処理を効率よく学びたい方。",
        "自然言語処理を敷居が高いと感じている方。",
        "文書や対話文の自動生成に興味のある方。",
        "自然言語処理の技術をベースに、チャットボットを開発したい方。",
        "Kerasで自然言語処理を学びたい方。"
      ]
    },
    {
      "title": "Bilgisayar Görüşü ile Yüz ve Nesne Tanıma | R-CNN, SSD, GANs",
      "url": "https://www.udemy.com/course/bilgisayar-gorusu/",
      "bio": "Yapay zeka ve derin öğrenme teknikleriyle Python dilinde Computer Vision | OpenCV | Object Detection |Yüz Tanıma |GANs",
      "objectives": [
        "Derin öğrenme algoritmalarını anlayıp nesne tanıma yapabileceksiniz.",
        "Kendi resimlerinizde, videolarınızda, webcamde nesne tanıma yapabileceksiniz.",
        "Dilediğiniz nesne üzerinde yeni nesne tanıma modelleri eğitebileceksiniz.",
        "Yüz tanıma yapabileceksiniz.",
        "GANs ile resim gerçekçi resimler üretebileceksiniz."
      ],
      "course_content": {
        "Giriş ve Kursun Genel Akışı": [
          "Akış"
        ],
        "Kurulumlar": [
          "Anaconda ve Pycharm Kurulumu",
          "Tensorflow Kurulumu (CPU ve GPU için)",
          "Diğer Kütüphaneler",
          "Kurulumlar (Yazılı)"
        ],
        "Yüz Tanıma 1: Teori": [
          "Viola-Jones Algoritması",
          "Haar-like Özellikler",
          "Integral Resmi",
          "Sınıflandırıcıyı Eğitme",
          "Adaptive Boosting (Adaboost)",
          "Cascading"
        ],
        "Yüz Tanıma 2: OpenCV ile Yüz Tanıma": [
          "OpenCV 1. Adım",
          "OpenCV 2. Adım",
          "OpenCV 3. Adım",
          "OpenCV 4. Adım",
          "OpenCV 5. Adım"
        ],
        "Nesne Tanıma 1: Teori": [
          "Bölge Önerisi",
          "R-CNN, Fast R-CNN, Faster R-CNN",
          "SSD",
          "Mat R-CNN"
        ],
        "Nesne Tanıma 2: Tensorflow ile Nesne Tanıma": [
          "Tensorflow Object Detection API Kurulumu",
          "Tensorflow Object Detection API Kullanımı",
          "Tensorflow Object Detection API Farklı Modelleri Kullanma",
          "Bilgisayar Gözünden İstanbul"
        ],
        "Nesne Tanıma 3: Kendi Nesne Tanıma Modelini Geliştirme": [
          "Giriş ve Gerekenler",
          "Adım 1: İndirmeler ve Anaconda Virtual Environment Üzerinde Kurulum",
          "Adım 2: Resim Toplayıp Etiketleme",
          "Adım 3: Eğitim Verisi Oluşturma",
          "Adım 4: Label Map Oluşturma ve Eğitim Ayarları",
          "Adım 5: Eğitimi Gerçekleştirme",
          "Adım 6: Inference Graph",
          "Adım 7: Programı Kullanma",
          "Tüm Adımlar Yazılı ve Sıkça Karşılaşılan Hatalar"
        ],
        "GAN 1: Generative Adversarial Networks (GANs) Teori": [
          "GAN'e Genel Bir Bakış",
          "GAN Nasıl Çalışır 1",
          "GAN Nasıl Çalışır 2",
          "GAN Nasıl Çalışır 3",
          "Kullanım Alanları"
        ],
        "GAN 2: Keras ile GANs Oluşturma": [
          "GANs 1. Adım",
          "GANs 2. Adım",
          "GANs 3. Adım",
          "GANs 4. Adım",
          "GANs 5. Adım"
        ],
        "Ek Ders: Python'a giriş ve Numpy": [
          "Jupyter Notebook Tutorial",
          "Veri Türleri 1",
          "Veri Türleri 2",
          "Koşullu İfadeler",
          "Döngüler",
          "Fonksiyonlar",
          "Numpy Array",
          "Numpy'da Indeksleme",
          "Numpy'da İşlemler",
          "Pandas Seriler",
          "Pandas DataFrame 1",
          "Pandas DataFrame 2",
          "Pandas DataFrame 3",
          "Pandas Kayıp Veriler",
          "Pandas Groupby",
          "Pandas Merging, Joining ve Concatenating",
          "Pandas İşlemler",
          "Pandas Veri Okuma ve Yazma",
          "Python Kodları"
        ]
      },
      "requirements": [
        "Temel Programlama Bilgisi",
        "64-bit İşletim Sistemi"
      ],
      "description": "Merhaba arkadaşlar,\n\nBilgisayar görüşü kursumuza hoşgeldiniz. Bu kursta sıfırdan yüz tanıma, nesne tanıma ve GANs geliştireceğiz. Tüm bu konular hiç bilmeyen bir kişinin anlayabilmesi için baştan sona ayrıntılarıyla anlatılmıştır. Nesne tanıma yaparken kullanacağımız algoritmaların temelinde derin öğrenme yatıyor. Ayrıca GANs'de tamamen bir derin öğrenme konusudur. Derin öğrenme bilmeyenler için kursun sonuna ek ders eklenmiştir. Bu ek ders ile derin öğrenmeyi anladıktan sonra nesne tanıma ve GANs anlayabileceksiniz.\nHerkese Başarılar.",
      "target_audience": [
        "Bilgisayar Görüşünü Anlamak İsteyenler",
        "Nesne Tanıma Yapmak İsteyenler",
        "Yüz Tanıma Yapmak İsteyenler",
        "Generative Adversarial Networks Öğrenmek İsteyenler",
        "GANs ile Resim Üretmek İsteyenler"
      ]
    },
    {
      "title": "【Hands Onで学ぶ】PyTorchによる深層学習入門",
      "url": "https://www.udemy.com/course/hands-on-pytorch/",
      "bio": "人気急上昇中のAIフレームワークであるPyTorchを用いて深層学習の様々なモデルを構築し、機械学習・深層学習の基礎を固めましょう。機械学習・深層学習を\"知識として知っている\"人から、\"使える・使いこなせる\"人へとステップアップしませんか?",
      "objectives": [
        "研究者の間で急激に人気を伸ばしているPyTorchというAIフレームワークについてライブラリの基本から、深層学習の学習の手続きまでのプログラミング方法を理解できる",
        "多層NNや畳み込みNNといった基本的なモデルに加えて、転移学習、オートエンコーダー、ResNet、LSTMといった様々なモデルを構築する事で、深層学習の基礎を固める事が出来る",
        "過学習への対処方法や、GPUでの学習方法、自前で用意した画像データセットの使用方法など研究開発の現場で使用する実際的なスキルを身に付けることが出来る"
      ],
      "course_content": {
        "PyTorchの基礎・機械学習の復習": [
          "本コースの概要",
          "予備知識チェックとオススメの受講方法",
          "Tensorとは",
          "Google Colabの使い方",
          "PyTorchの基本的な使い方",
          "自動微分",
          "機械学習の流れ",
          "PyTorchプログラミングの流れ",
          "ソースコードの配布とPyTorchの仕様変更について"
        ],
        "PyTorchによる深層学習の基礎": [
          "線形回帰",
          "MLPによる手書き数字(MNIST)の分類 概要",
          "MLPによる手書き数字(MNIST)の分類 実装 ~モデル構築~",
          "MLPによる手書き数字(MNIST)の分類 実装 ~学習~",
          "モデルの保存・読み込み",
          "CNNによるクラス分類(CIFAR 10) 学習 概要",
          "CNNによるクラス分類(CIFAR 10) 実装 ~モデル構築~",
          "CNNによるクラス分類(CIFAR 10) 実装 ~学習・検証~",
          "データ拡張 概要",
          "データ拡張 実装"
        ],
        "PyTorchによる深層学習の基礎2": [
          "転移学習 概要",
          "転移学習 実装 ~データセット~",
          "転移学習 実装 ~モデル構築・学習~",
          "補足：ImageFolderについて",
          "オートエンコーダー 概要",
          "オートエンコーダー 実装 ~モデル構築~",
          "オートエンコーダー 実装 ~学習~",
          "グラフの読み方",
          "ResNet 概要",
          "ResNet 実装",
          "カスタムデータセット 概要",
          "カスタムデータセット 実装",
          "LSTM 概要",
          "LSTM 実装 ~モデル構築~",
          "LSTM 実装 ~学習~"
        ],
        "ボーナスレクチャー": [
          "クラスの基礎",
          "AutoEncoderのnotebook",
          "講義で使用したnotebooks"
        ]
      },
      "requirements": [
        "Pythonの基本的なプログラミングスキル(基本的な文法+Numpyの知識)",
        "機械学習や深層学習の基本的な知識"
      ],
      "description": "【PyTorchとは?】\nPyTorchとはFacebook AI Researchが開発している深層学習のフレームワークです。KerasやTensorFlowといった他のフレームワークと比較して、Define by Runという計算しながらモデルを作る性質や、クラスを使って複数のパーツから複雑なAIのモデルを組むことが出来る点からモデル構築の柔軟性という面で非常に優れます。この為、近年、国内外の研究者を中心としてシェアが急激に伸びてきています。\n\n\n【人事の方/マネージャークラスの方へ】\n本コースは次のような使い方が可能です。\n・社内でAI人材を育成したい\n・デジタル人材の育成をなるべく効率よく行いたい\n本コースは深層学習フレームワークのPyTorchにフォーカスし、特に理論よりも実践に重きを置いています。\nこの為、Hands On形式で短時間且つ効率よくAI人材育成が可能です。\nまた、転移学習やデータ拡張、カスタムデータセットなど業務で実際に使用する可能性の高い内容の解説をしていますので、修了はしたが、手は動かないなどは比較的少ないと思われます。\n\n\n【対象者とゴール】\nPythonの基本的なプログラミング知識があり、教科書・参考書などで機械学習や深層学習を既にある程度知っているエンジニアや研究者の方を対象に、PyTorchにおけるプログラミングを通して深層学習の基礎を固めるコースです。本コースのゴールは\"機械学習を知っている\"から\"機械学習を使える\"へとステップアップする事です。\n\n\n【ハンズオン】\n本コースはハンズオンという形式で、Google Colab上でデータの準備⇒深層学習のモデル作成⇒損失関数・オプティマイザの設定⇒学習・評価という一連の流れをスクラッチから講師と一緒に実装していきます。\n機械学習を”知っている状態\"から実際に\"使える状態\"になるには、実際にプログラミングをして手を動かすことが非常に重要です。\n例えば、教科書的な知識として、活性化関数(シグモイド関数 / Tanh / ReLU)を知っていたとします。この時、実際にどの活性化関数を使えばよいのか、こういった問いに対する答えは\"実際に試してみる\"という事です。\n\n\n機械学習や深層学習の分野では理論的に答えを出せる場合もありますが、ヒューリスティック(経験的)に見つけるといった場合が非常に多いです。この為、本コースでは手を動かしてプログラムを実装する（Hands On）という事を非常に重視しています。\n\n\n【コースの概要】\n詳細は本コースの概要説明をご覧ください。\n本コースは機械学習・深層学習の復習やPyTorchのライブラリの基本的な使い方など基礎的な内容から段階的にステップアップしていきます。\nこの為、無理なくステップアップすることが出来ます。\n【PyTorchの基礎】\n本コースの概要\nTensorとは\nGoogleColabの使い方\nPyTorchの基本的な使い方\n自動微分\n機械学習の流れ\nPyTorchプログラミングの流れ\nソースコードの配布\n\n\n【深層学習の基礎1】\n線形回帰\nMLPによる手書き数字の分類(MNIST) 概要\nMLPによる手書き数字の分類(MNIST) 実装\nモデルの保存・読み込み\nCNNによるクラス分類(CIFAR 10) 概要\nCNNによるクラス分類(CIFAR 10) 実装\n\n\n【深層学習の基礎2】\nデータ拡張とは\nデータ拡張の効果の検証\n転移学習 概要\n転移学習 実装\nオートエンコーダー 概要\nオートエンコーダー 実装\nグラフの読み方\nResNet 概要\nResNet 実装\nカスタムデータセット 概要\nカスタムデータセット 実装\nLSTMとは\nLSTM 実装\nまずは無料プレビューできる動画が30分以上あります。プレビューだけでも見ていってください。",
      "target_audience": [
        "PyTorchのAIフレームワークを使って、深層学習の様々なモデルを実装したい方。学習までの一連のプログラミングを身に付けたい方",
        "機械学習を\"知っている人\"から機械学習を\"使える人\"へ一歩先へ進みたい方"
      ]
    },
    {
      "title": "Alteryx: Data Science with Alteryx",
      "url": "https://www.udemy.com/course/data-science-alteryx/",
      "bio": "Learn Data Science using Alteryx. ETL. Alteryx Designer. Build Alteryx workflows. Data Analytics. Hands on Exercises",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Alteryx Installed (Trial or Full)",
        "High School Math"
      ],
      "description": "Data Science with Alteryx/Alteryx Designer: Learn Alteryx Designer and gain one of employer's most requested skills in 2022!\nData Science is all about using data to solve some of society's most pressing problems. Harvard Business Review touted Data Science as the sexiest job of the 21st century, and no wonder Data Science is considered the future! with zettabytes and yottabytes of structured and unstructured data floating everyday, it calls for very unique skillsets to uncover hidden patterns and generate valuable insights from data.\nWith the \"Data Science with Alteryx\" course you will learn Alteryx from scratch and start solving several real world problems. Learning Alteryx Designer provides several benefits, you can perform data analytics and even build complex algorithms without coding in complex programming languages such as Python, Java or C and still be able to generate powerful insights very quickly.\nThe \"Data Science with Alteryx\" course will make you a champion in using the Alteryx Designer tool. From data extraction, data cleansing to running advanced analytics and even building your own algorithms, this course will help you level up in your career as a business or data analyst.\nYou will be exposed to tools such as Spatial Mapping, Join, Union, Tile, Filter,  Select, Sample, Parsing, Maps just to name a few. You will learn to automate processes, designing robust optimization algorithms as well as combining several inputs to draw insights from data.\nThe \"Data Science with Alteryx\" follows a step-by-step approach and has several hands on exercises, so that you can apply all of the concepts at work right away! You'll be fully prepared to understand problem statements, prep data, analyze, build complex Alteryx Designer workflows and draw several useful insights.\nThe course will be a stepping stone in your path to becoming an Alteryx developer.",
      "target_audience": [
        "Aspiring or Professional Data scientists and analysts",
        "Anyone who is new to Alteryx"
      ]
    },
    {
      "title": "プログラミング言語 Python 3 入門",
      "url": "https://www.udemy.com/course/intro-to-python3/",
      "bio": "機械学習、データサイエンス、統計分析の分野で重要度を増すプログラミング言語 Python の基本を、チュートリアル動画でマスターしよう。",
      "objectives": [
        "Python のデータ、制御フロー、関数、データ構造、モジュール、例外（エラー）、クラス、入力と出力、標準ライブラリ",
        "ターミナルを使用した Python の実行、PyCharm を使用した Python ファイルの作成、デバッグ実行"
      ],
      "course_content": {
        "Python のインストールと起動": [
          "Python をインストール",
          "Python を起動"
        ],
        "はじめての Python": [
          "数値 1",
          "数値 2",
          "文字列 1",
          "文字列 2",
          "文字列 3",
          "リスト 1",
          "リスト 2",
          "リスト 3"
        ],
        "Python の制御フロー": [
          "while 文とフィボナッチ数列",
          "if 文",
          "条件式",
          "for 文",
          "range 関数",
          "break 文とループでの else 節",
          "continue 文",
          "pass 文"
        ],
        "Python の関数": [
          "関数を定義 1",
          "関数を定義 2",
          "デフォルト引数値 1",
          "デフォルト引数値 2",
          "キーワード引数 1",
          "キーワード引数 2",
          "キーワード引数 3",
          "任意引数リスト",
          "引数リストをアンパック",
          "ラムダ式",
          "ドキュメンテーション文字列",
          "関数アノテーション"
        ],
        "Python のデータ構造": [
          "リスト",
          "スタックやキューとしてリストを使用",
          "リスト内包表記 1",
          "リスト内包表記 2",
          "リスト内包表記 3",
          "リスト内包表記をネスト",
          "del 文",
          "タプル",
          "集合（セット）1",
          "集合（セット）2",
          "辞書 1",
          "辞書 2",
          "ループ技法"
        ],
        "Python のモジュール": [
          "PyCharm をインストール",
          "新しい Python ファイルを作成",
          "モジュール 1",
          "モジュール 2",
          "モジュール 3",
          "スクリプトとしてモジュールを実行",
          "PyCharm でモジュールを実行",
          "PyCharm でモジュールをデバッグ",
          "パッケージ"
        ],
        "Python の例外（エラー）": [
          "例外（エラー）1",
          "例外（エラー）を処理 1",
          "例外（エラー）を処理 2",
          "例外（エラー）を処理 3",
          "例外（エラー）を起こす",
          "クリーンアップを定義"
        ],
        "Python のクラス": [
          "スコープ",
          "クラス 1",
          "クラス 2",
          "インスタンス",
          "メソッド",
          "クラス変数とインスタンス変数 1",
          "クラス変数とインスタンス変数 2"
        ],
        "Python の入力と出力": [
          "文字列のフォーマット",
          "ファイルの読み書き"
        ],
        "Python の標準ライブラリ": [
          "os",
          "shutil",
          "math, random, statistics",
          "urllib.request",
          "datetime",
          "リファレンス"
        ]
      },
      "requirements": [
        "このコースは Mac でチュートリアル動画を作成しているため、Mac であれば受講しやすいです。",
        "Python や PyCharm は、Windows や Linux でもインストールして利用することができます。"
      ],
      "description": "Python は世界中で人気があるプログラミング言語で、Google や YouTube、Instagram、Dropbox など、多数の企業やソフトウェアで使用されています。\n近年では、機械学習、データサイエンス、統計分析などの分野で、高度な数値計算、科学技術計算ライブラリが豊富にある Python の重要度が増してきています。求人サイトによるプログラミング言語別平均年収ランキング (2016) で Python が 1 位になるなど、日本でも Python エンジニアへの需要が急速に高まってきています。\nPython は汎用的なプログラミング言語で、様々な用途に使用することができます。Web アプリケーション、GUI アプリケーション、高度な数値計算や科学技術計算、ゲーム、ロボット向けアプリケーションと多岐に渡り、Python の知識を様々な分野で活用することができます。",
      "target_audience": [
        "機械学習、データサイエンス、統計分析などの分野で Python を活用するために、プログラミング言語 Python を基本から学習したいデータサイエンティストや、他のプログラミング言語を理解していて、はじめて Python を学習するプログラマやエンジニアにオススメです。",
        "はじめてプログラミングを学習される方にもオススメです。Python はプログラミング初心者にオススメのプログラミング言語です。Python のコードはシンプルで読みやすく、海外では、はじめて学習するプログラミング言語として Python が選ばれています。"
      ]
    },
    {
      "title": "Machine Learning for beginners",
      "url": "https://www.udemy.com/course/machine-learning-for-beginners-azure/",
      "bio": "Azure Machine Learning",
      "objectives": [],
      "course_content": {
        "About this Course": [
          "About this Course"
        ],
        "Machine Learning Topics": [
          "Introduction to Machine Learning",
          "Automobile Price Prediction experiment Step by step part 1",
          "Automobile Price Prediction experiment step by step part 2",
          "Automobile Price Prediction Deploying in to a Web service",
          "Movie Recommendation algorithm",
          "Loan Granting Binary Classification"
        ]
      },
      "requirements": [
        "Beginners level knowledge for working with Data .",
        "Programming knowledge not required."
      ],
      "description": "The main purpose of this course is to give students the ability to analyze and present data by using Azure Machine Learning, and to provide an introduction to the use of machine learning and big data.\nBy-\nUditha Bandara is specializes in Microsoft Development technologies.  He is the South East Asia`s First XNA/DirectX MVP (Most Valuable Professional).  He had delivered sessions at various events and conferences in Hong Kong, Malaysia, Singapore, Sri Lanka and India.",
      "target_audience": [
        "Anyone Interested to learn Machine Learning"
      ]
    },
    {
      "title": "Machine Learning com Amazon AWS e SageMaker",
      "url": "https://www.udemy.com/course/machine-learning-amazon-aws-sagemaker/",
      "bio": "Aprenda tudo o que você precisa saber sobre Machine Learning com o Amazon SageMaker! Tudo passo a passo com Python",
      "objectives": [
        "Entender a finalidade dos principais serviços da Amazon, como: AWS, S3, EC2, IAM e SageMaker",
        "Codificar em Python utilizando o SageMaker Studio, que é a principal IDE para programar em Python no AWS",
        "Integrar o SageMaker com o serviço de armazenamento de dados S3",
        "Implementar soluções de aprendizado de máquina utilizando os algoritmos disponíveis no Amazon AWS",
        "Resolver problemas de regressão e classificação utilizando o Linear Leaner e o XGBoost",
        "Prever séries temporais utilizando o algoritmo DeepAR da área de Deep Learning",
        "Detectar outliers com o algoritmo Random Cut Forest",
        "Reduzir a dimensionalidade de bases de dados com PCA (Principal Component Analysis)",
        "Classificar imagens com redes neurais convolucionais, utilizando o algoritmo pré-definido no AWS",
        "Integrar a biblioteca TensorFlow com o AWS",
        "Realizar o deploy de modelos de aprendizagem (endpoint) de máquina para acesso externo",
        "Utilizar a ferramenta autopilot de aprendizagem de máquina automática para realizar o processo completo na área de dados"
      ],
      "course_content": {},
      "requirements": [
        "Lógica de programação",
        "Programação básica em Python",
        "Conhecimentos básicos sobre aprendizagem de máquina são desejáveis, porém, não obrigatórios"
      ],
      "description": "A Amazon Web Services (AWS) é uma das plataformas de nuvem mais utilizadas do mundo, que oferece uma gama muito grande de serviços que podem ser utilizados pelas empresas. Estão disponíveis serviços nas áreas de computação, armazenamento, banco de dados, redes de computadores, blockchaim, robótica, satélite, dentre vários outros. Tais serviços podem ser utilizados nas mais diversas áreas de atuação, como por exemplo: publicidade, marketing, agricultura, setor automobilístico, educação, energia, governo, serviços financeiros, saúde, turismo e varejo. Dentro desse universo, também podem-se citar os serviços na área de Machine Learning (Aprendizagem de Máquina) e Inteligência Artificial, sendo possível utilizar algoritmos pré-definidos juntamente com armazenamento na nuvem para cumprir todas as etapas do processo, desde a obtenção dos dados até criação do modelo final em produção.\nA Amazon disponibiliza o SageMaker, que é um serviço que permite aos cientistas e engenheiros de dados construir, treinar e implantar modelos de ML para qualquer tipo de aplicação. Para levar você até essa área, neste curso você terá uma visão principalmente prática sobre como utilizar os recursos do Amazon SageMaker para treinar modelos de machine learning! Ao final você terá todas as ferramentas necessárias para construir soluções de aprendizado de máquina utilizando os recursos oferecidos pela Amazon! O curso está dividido em dez partes que abordam recursos e algoritmos diferentes. Veja abaixo alguns dos tópicos que serão implementados passo a passo:\n\n\nEntender a finalidade dos principais serviços da Amazon, como: AWS, S3, EC2, IAM e SageMaker\nCodificar em Python utilizando o SageMaker Studio, que é a principal IDE para programar em Python no AWS\nIntegrar o SageMaker com o serviço de armazenamento de dados S3\nImplementar soluções de aprendizado de máquina utilizando os algoritmos disponíveis no Amazon AWS\nResolver problemas de regressão e classificação utilizando o Linear Leaner e o XGBoost\nPrever séries temporais utilizando o algoritmo DeepAR da área de Deep Learning\nDetectar outliers com o algoritmo Random Cut Forest\nReduzir a dimensionalidade de bases de dados com PCA (Principal Component Analysis)\nClassificar imagens com redes neurais convolucionais, utilizando o algoritmo pré-definido no AWS\nIntegrar a biblioteca TensorFlow com o AWS\nRealizar o deploy de modelos de aprendizagem (endpoint) de máquina para acesso externo\nUtilizar a ferramenta autopilot de aprendizagem de máquina automática para realizar o processo completo na área de dados\nTodos os códigos serão implementados passo a passo e com detalhes, inclusive com exercícios práticos ao final de cada seção. São mais de 120 aulas e mais de 16 horas de vídeos passo a passo!",
      "target_audience": [
        "Praticantes de ciência de dados que desejam avançar em suas carreiras e construir seu portfólio",
        "Qualquer pessoa interessada em inteligência artificial, ciência de dados, machine learning ou deep learning",
        "Estudantes de graduação e pós-graduação que estejam cursando disciplinas sobre este assunto",
        "Pessoas que queiram aprender a usar os recursos de machine learning da Amazon",
        "Pessoas interessadas em estudar o AWS para futuramente estudarem para a certificação"
      ]
    },
    {
      "title": "Tasting Machine Learning with Minitab Predictive Analytics",
      "url": "https://www.udemy.com/course/tasting-machine-learning-with-minitab-predictive-analytics/",
      "bio": "Minitab Machine Learning Preview: A Bite-Sized Look at Predictive Analytics. Regression, Classification",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "No prior programming knowledge is required. The tutorials are based on Minitab software version 21. If you want to try it yourself on the data files provided, you will need this software. The 30-day trial is free. The course assumes basic statistical knowledge."
      ],
      "description": "In this mini-course, \"Tasting Machine Learning with Minitab Predictive Analytics\", you will gain an introduction to the world of predictive analytics and machine learning using Minitab statistical software.\n\n\nThrough five lectures, you will learn about regression analysis and classification, two fundamental techniques in predictive modeling. In the first two lectures, you will learn how to set up and verify regression models, as well as how to identify and address potential issues with overfitting or underfitting. In Lecture 3, you will explore regression trees, which are a powerful alternative to linear regression when the relationship between variables is non-linear.\n\n\nIn Lecture 4, you will delve into binary logistic regression, which is a technique used for predicting binary outcomes (such as \"yes\" or \"no\" responses). You will learn how to set up and evaluate a binary logistic regression model. Finally, in Lecture 5, you will discover classification trees, which are a type of decision tree used to classify objects or cases into different categories. You will learn how to build and interpret classification trees, and use them for prediction.\n\n\nBy the end of this mini-course, you will have gained practical experience in building and evaluating regression and classification models using Minitab, and an understanding of how these techniques can be applied in various real-world scenarios. Whether you are new to machine learning or looking to expand your knowledge, this mini-course is an excellent opportunity to explore the basics of predictive analytics with Minitab.",
      "target_audience": [
        "This course is for those who want a concise taste of the 4 basic methods of machine learning before embarking on a more detailed course."
      ]
    },
    {
      "title": "Azure OpenAI (GPT) と Azure AI Search で作る ナレッジマイニング チャットボット",
      "url": "https://www.udemy.com/course/aoai-vectorsearch/",
      "bio": "情報検索の基礎から、Azure AI Search (旧 Cognitive Search) 実践、PDFのETL処理、最先端GPTチャットボット開発まで",
      "objectives": [
        "情報検索の概要、構成要素、ベクトル検索",
        "Cognitive Search の概要、使い方",
        "ナレッジマイニングシステムへのデータ取り込み方法",
        "ETL処理の具体的な実装",
        "LangChainを使ったReActの具体的な実装",
        "チャットベースのナレッジマイニングシステムの構築/実装方法"
      ],
      "course_content": {},
      "requirements": [
        "プロンプトエンジニアリングに関する基礎知識",
        "Azure OpenAI Serviceの利用方法に関する知識",
        "JavaScript（Node含む） を使ったサーバー/クライアントの開発に関する知識",
        "LangChainの基本的な使い方に関する知識",
        "Azureの基本的な使い方に関する知識"
      ],
      "description": "現代のビジネスシーンでは、データを効果的に活用することが求められています。\n特に、ChatGPTが登場してから、自社データをチャット形式で検索するための仕組み開発が盛んになっています。\n本講座ではそのような要求に応えられるようなチャット形式のデータマイニングツールの開発をテーマに学習していきます。\n\n\n本講座では、情報検索の基本からAI Search (旧 Cognitive Search) の基本、そしてPDFファイルを取り込むことをテーマにデータ取り込み処理の実践的な方法を学ぶことができます。\n最終的には、LangChainとGPTを組み合わせた実用的なデータマイニング可能なチャットボットをハンズオンで開発していきます。\n\n\n本講座を学習することで、データを効果的に活用して価値を生み出すシステムを開発するスキルを手に入れることができます。\n\n\nやってみたいと思いながら、具体的な実装方法が思いつけていない方は、ぜひ一度、本コースを受講いただければと思います。\n\n\n\n\n【概要】\n基礎学習\n情報検索システム概要\n情報検索システム、情報検索エンジン\nフルテキスト検索（全文検索）の流れ、構成要素\nベクトル検索\nAI Search (旧 Cognitive Search) 概要\n基本機能\nSKU\nセキュリティ\n監視/モニタリング\n可用性、回復性\nハンズオン\n全体アーキテクチャ\nデータ取り込み処理（ETL処理）\nPDFファイル読み込み\nチャンク分割\nベクトル変換（OpenAI の Embedding モデルを 利用）\nCognitive Search へ登録\nAI Search (旧 Cognitive Search) での検索\nフルテキスト検索（全文検索）\nベクトル検索\nWebアプリの実装\nLangChainを使ってReActを実装（OpenAI の GPTモデル を利用）\nカスタムツールにAI Search (旧 Cognitive Search) を実装、組み込み\nLangChainの日本語化\nAzure上へデプロイ\n\n\n【更新履歴】\nv1.0.0　2023/12/05　初版リリース",
      "target_audience": [
        "ナレッジマイニングのシステム開発 をしたい人",
        "OpenAI を利用したシステム改善の 具体的な方法を知りたい人",
        "新しいことに興味がある人"
      ]
    },
    {
      "title": "Neural Networks Made Easy",
      "url": "https://www.udemy.com/course/neural-networks-for-your-dog/",
      "bio": "So easy, your dog could learn them!",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Be able to code in Python with NumPy and Pandas"
      ],
      "description": "Wanna understand deep learning and neural networks so well, you could code them from scratch? In this course, we'll do exactly that.\nThe course starts by motivating and explaining perceptrons, and then gradually works its way toward deriving and coding a multiclass neural network with stochastic gradient descent that can recognize hand-written digits from the famous MNIST dataset.\nCourse Goals\nThis course is all about understanding the fundamentals of neural networks. So, it does not discuss TensorFlow, PyTorch, or any other neural network libraries. However, by the end of this course, you should understand neural networks so well that learning TensorFlow and PyTorch should be a breeze!\nChallenges\nIn this course, I present a number of coding challenges inside the video lectures. The general approach is, we'll discuss an idea and the theory behind it, and then you're challenged to implement the idea / algorithm in Python. I'll discuss my solution to every challenge, and my code is readily available on github.\nPrerequisites\nIn this course, we'll be using Python, NumPy, Pandas, and good bit of calculus. ..but don't let the math scare you. I explain everything in great detail with examples and visuals.\nIf you're rusty on your NumPy or Pandas, check out my free courses Python NumPy For Your Grandma and Python Pandas For Your Grandpa.",
      "target_audience": [
        "People interested in learning how neural networks work"
      ]
    },
    {
      "title": "Meeshkan: Machine Learning the GitHub API",
      "url": "https://www.udemy.com/course/meeshkan-machine-learning-the-github-api/",
      "bio": "Learn how to plan, deploy and run a Machine Learning problem on AWS and Meeshkan",
      "objectives": [],
      "course_content": {
        "Let's (Machine) Learn!": [
          "Welcome!",
          "Meeshkan: Machine Learning the GitHub API"
        ],
        "Machine Learning with Meeshkan - Step by Step": [
          "Setting Up Your Data Collection Environment",
          "Collecting Data",
          "Downloading the Webhook Source Code",
          "Serving Data via a Webhook",
          "Getting Familiar With YAML",
          "Deploying Infrastructure",
          "Machine Learning and Keras",
          "Designing Your Models",
          "Signing Up for Meeshkan",
          "Running Your Models on Meeshkan",
          "Downloading the Data Visualizer",
          "Analyzing Your Models",
          "You Are the Future of Machine Learning: Go For It!"
        ]
      },
      "requirements": [
        "You should have basic familiarity with Machine Learning. JavaScript knowledge is a plus!"
      ],
      "description": "In this course, Meeshkan C.E.O. Mike Solomon will teach you how to do Machine Learning on Meeshkan.\nMeeshkan is an easy and inexpensive platform where people can explore ideas in AI, Machine Learning and Deep Learning.\nThis course starts with a simple AI question: can a machine predict if a GitHub project will be successful by analyzing only the first few commits of that project?\nThe first section of the course will run the Machine Learning project on Meeshkan.  You'll see how quick and easy it is to do Machine Learning on Meeshkan.\nThe second section of the course will delve into each step of the process in detail, covering data collection, data egress, infrastructure deployment, model design, model executing and result analysis.\nBy the end of the course, you will be able to adapt the course materials to design, run, and explore your own Machine Learning models using public APIs and the Meeshkan Machine Learning service.",
      "target_audience": [
        "Anyone who wants to learn about Machine Learning."
      ]
    },
    {
      "title": "Machine Learning ve Python: A'dan Z'ye Makine Öğrenmesi (4)",
      "url": "https://www.udemy.com/course/machine-learning-ve-python-adan-zye-makine-ogrenmesi-4/",
      "bio": "Python ile Machine Learning algoritmaları geliştirerek Yapay Zeka amacımıza bir adım daha yaklaşalım !",
      "objectives": [
        "Yapay zeka yolculuğumuzun 4. adımı olan makine öğrenmesi kursumuzu tamamlayacak ve hedefimize bir adım daha yaklaşmış olacaksınız",
        "CV'nize gönül rahatlığıyla makine öğrenmesi ile ilgili aldığınız eğitimi ve birlikte yaptığımız projeleri yazabileceksiniz",
        "Makine öğrenmesi ile pek çok sınıflandırma ve tahmin algoritmaları geliştirebileceksiniz",
        "Natural Language Process ve Recommendation Systems gibi farklı alanlarda tecrübe sahibi olacaksınız",
        "Makine öğrenmesi projelerinizi tüm dünya ile buluşturacaksınız",
        "Spesifik problemler için farklı algoritmaları kullanmayı öğreneceksiniz ve bu algoritmaları gerçek hayat problemlerine uygulayacaksınız"
      ],
      "course_content": {
        "Giriş Bölümü": [
          "Giriş",
          "Machine Learning ve Kullanım Alanları",
          "Bu Dersten Sonra Hangi Seviyede Olacağız",
          "Udemy Tanıtım",
          "Anaconda Kurulum",
          "Spyder ve Jupyter Notebook Tanıtım",
          "Datai Team: Github ve Kaynaklar"
        ],
        "Kaggle Nedir?": [
          "Kaggle Tanıtımı 1",
          "Kaggle Tanıtımı 2",
          "Notebook (Kernel) Nedir?",
          "Kaggle Arayüz Değişikliği",
          "Kaggle Profil Sayfası",
          "Kaggle'da Başarılı Olmak İçin Neler Yapmalı?"
        ],
        "Linear Regression": [
          "Dataset Tanıtımı",
          "Linear Regression Nedir-1",
          "Linear Regression Nedir-2",
          "Linear Regression with Python"
        ],
        "Multiple Linear Regression": [
          "Dataset Tanıtımı",
          "Multiple Linear Regression Nedir",
          "Multiple Linear Regression with Python"
        ],
        "Polynomial Linear Regression": [
          "Dataset Tanıtımı",
          "Polynomial Linear Regression Nedir",
          "Polynomial Linear Regression with Python"
        ],
        "Decision Tree Regression": [
          "Decision Tree Regression Nedir",
          "Decision Tree Regression with Python"
        ],
        "Random Forest Regression": [
          "Random Forest Regression Nedir",
          "Random Forest Regression with Python"
        ],
        "Evaluation Regression Models": [
          "Evaluation Regression Model Performance with R-Square",
          "R-Square with Random Forest",
          "R-Square with Linear Regression",
          "Regression Ödev"
        ],
        "Logistic Regression Classification": [
          "Logistic Regression Giriş",
          "Computation Graph",
          "Logistic Regression with Computation Graph",
          "Initializing Parameters",
          "Forward Propagation",
          "Backward Propagation-1",
          "Backward Propagation-2",
          "Dataset tanıtımı ve Normalization",
          "Dataset Train-Test Split",
          "Implementing Initializing Parameters and Sigmoid Function",
          "Implementing Forward and Backward Propagation",
          "Implementing Update Parameters",
          "Implementing Prediction",
          "Implementing Logistic Regression",
          "Logistic Regression with Sklearn",
          "Logistic Regression Ödev"
        ],
        "K-Nearest Neighbour (KNN) Classification": [
          "Dataset Tanıma",
          "K-Nearest Neighbour (KNN) Nedir",
          "K-Nearest Neighbour (KNN) with Python",
          "K-Nearest Neighbour Ödev"
        ]
      },
      "requirements": [
        "Hedefler ve gelecekle ilgili güzel hayaller",
        "İnternet bağlantılı bir bilgisayara sahip olmak yeterlidir",
        "Python, data science ve veri görselleştirme ile ilgili temel seviyede bilgiler"
      ],
      "description": "Merhaba arkadaşlar,\nBu kurs 7 bölümlük nihai hedefimizin dördüncü bölümünü oluşturmaktadır.\nPython: Python Sıfırdan Uzmanlığa Programlama (1)\nData Science ve Python: Sıfırdan Uzmanlığa Veri Bilimi (2)\nData Visualization: A'dan Z'ye Veri Görselleştirme (3)\nMachine Learning (Makine Öğrenmesi)\nDeep Learning (Derin Öğrenme)\nStatistical Learning (İstatistik)\nArtificial Intelligence (Yapay Zeka)\nNeden Makine Öğrenmesi?\nİş sahası çok geniş,\nDünya yapay zeka yani makine öğrenmesine doğru inanılmaz hızlı sürükleniyor,\nMakine öğrenmesi geleceği parlak meslek dallarının olmazsa olmazı,\nBir veriden derinlemesine bilgi çıkarmaya olanak sağlıyor.\nBu Kurs ile Alacaklarınız\nSıfırdan Kodlama Becerisi: Sizinle birlikte kod yazıyoruz. Her ders boş bir sayfa ile başlar ve kodu sıfırdan yazarız. Bu şekilde ilerleyebilir ve kodun nasıl bir araya geldiğini ve her satırın ne anlama geldiğini tam olarak anlayabilirsiniz.\nKodlar ve Şablonları: Kursta oluşturduğumuz her Python şablonlarını ve kodunu indirebilirsiniz. Bu, sizlere hem daha sonra kod üzerinde pratik yapma hem de kendi projelerinizi şablon sayesinde daha kolay bir şekilde yaratma imkanı sağlayacaktır\nTeori ve Mantık: Size yalnızca kod yazmayı değil, hem yazdığımız kodun arkasında yatan mantığı ve teoriyi hem de neden böyle bir kod yazdığımızı anlatıyoruz.\nKurs içi destek: Size sadece video ile ders anlatımı yapmıyoruz. Size destek olmak için profesyonel Veri Bilimcilerinden oluşan bir ekip oluşturduk. Bu da ders ve ya ders dışı sorularınıza en fazla 72 saat içinde yanıt alacağınız anlamına geliyor.\nMachine Learning kursu içeriği\nGiriş Bölümü\nMachine Learning ve Kullanım Alanları\nGerekli Kurulumların Yapılması\nSupervised Learning\nRegression\nLinear Regression\nMultiple Linear Regression\nPolynomial Linear Regression\nDecision Tree Regression\nRandom Forest Regression\nEvaluation Regression Models\nClassification\nLogistic Regression\nK-Neirest Neighbour (KNN)\nSupport Vector Machine (SVM)\nNaive Bayes\nDecision Tree\nRandom Forest\nEvaluation Classification Models\nUnsupervised Learning\nClustering\nK-Means\nHierarchical Clustering\nNatural Language Process (NLP)\nPrinciple Component Analysis (PCA)\nModel Selection\nK-Fold Cross Validation\nGrid Search\nRecommendation Systems\nKurs Hakkında Bazı Öğrenci Yorumları\nAlihan Tabak\nKesinlikle mesleki anlamda yaptığım en iyi şeylerden biriydi. Okulda dersini almış olmama rağmen bu kadar ayrıntılı ve anlaşılır bir course oluşturduğu için, hocamıza teşekkürü borç bilirim.\nSamet Tutkun\nAnlatımlar çok şahane. Hele paint ile bunları görselleştirip (eğitmenin sanatsal bir yanı da var zannımca) işin mantığını öğretmesi şahane. Bu konulara çok ilgim var her fırsatta YouTube'dan falan izliyordum, ama böyle şahane anlatanına rastlamadım. O yüzden çoook teşekkür ederim: izleyen herkes adına! :) Ayrıca Udemy de fena değilmiş aslında. Derli toplu iyi içerikler de var hani... :)\nBileda Ozan Kavcu\nHocamız bize bu dersleri anlattığı için gerçekten çok teşekkür ediyorum . Çünkü bu dersler sıradan yazılım dersleri gibi değil Türkiye'nin geleceği açısından çok büyük bir temel teşkil ediyor geleceğe hazırlanıyorsunuz arkadaşlar hepimiz için çok önemli bu dünya değişiyor. Endüstri 4.0' a hazır olmamız gerekiyor . Saygılar emeğiniz için hocam\nİçeriğin İngilizce olması sizi yanıltmasın arkadaşlar. Derslerim tamamen Türkçedir.\nHemen kaydolun ve bir an önce başlayalım.",
      "target_audience": [
        "Makine öğrenmesi konusunda uzmanlaşmak isteyenler",
        "Yapay zeka temellerini oluşturmak isteyenler",
        "Kariyerini makine öğrenmesinde sürdürmek yada başlatmak isteyenler",
        "Üniversite ve meslek seçiminde zorlanan ve makine öğrenmesi hakkında bilgi ve beceri sahibi olmak isteyenler",
        "Makine öğrenmesini iş hayatında uygulamak isteyenler"
      ]
    },
    {
      "title": "Yapay Zeka Uygulamaları: Langchain, RAG, LLM Orkestrasyonu",
      "url": "https://www.udemy.com/course/langchain-langgraph/",
      "bio": "Langchain, Langgraph gibi güncel araçları kullanarak LLM Orkestrasyonu'nu uygulama yaparak öğrenin",
      "objectives": [
        "İleri Seviye Retrieval Augmented Generation teknikleri",
        "Agent Oluşturması ve Kullanımı",
        "Langchain",
        "Langraph",
        "Vector store'lar",
        "ChromaDB",
        "Üretken Yapay Zeka araçlarıyla yazılım geliştirme"
      ],
      "course_content": {
        "Giriş": [
          "Giriş",
          "Eğitim Kullanma Kılavuzu"
        ],
        "LLM'ler ve Yapay Zeka": [
          "LLM'ler Nasıl Çalışır?",
          "LLM Orkestrasyonu Nedir?"
        ],
        "Python Quiz ve Setup Bölümleri": [
          "Python Quiz'i ve Bilinmesi Gerekenler",
          "Quiz Çözümü",
          "Python Quiz Çözümleri GitHub Link",
          "OpenAI ve Langchain Anahtarları",
          "Python Projesi Setup'ı",
          "Dotenv ile Çalışmak"
        ],
        "Langchain Giriş ve Translation Uygulaması": [
          "GitHub Linki",
          "Langchain İlk Proje",
          "İlk Mesajı Almak",
          "Chain Oluşturmak ve Parser'lar",
          "Prompt Template",
          "Langserve",
          "Langsmith"
        ],
        "Simple Chat Bot ve Hafıza Kavramları": [
          "GitHub Linki",
          "Mesajlaşma Tarihi",
          "Mesaj Hafızası ve Testleri",
          "History",
          "Streaming ve Memory Management"
        ],
        "Vector Store ve RAG Konsepti": [
          "GitHub Linki",
          "Vector Store Nedir?",
          "Vector Store ve Similarity Search",
          "İlk RAG Konsepti"
        ],
        "Retrieval Augmented Generation": [
          "GitHub Linki",
          "RAG Nedir?",
          "İnternetten Veri Çekmek",
          "Vektörize Etmek ve Text Bölmek",
          "Hub Nedir?",
          "Chain Streaming"
        ],
        "İleri Seviye Chatbot Örneği": [
          "GitHub ve DigitalOcean Linki",
          "İleri Seviye Chatbot",
          "Asistanlar ve RAG",
          "Web Kodlarının Üstünden Geçmek",
          "Airtable Ayarları",
          "Deployment",
          "Voiceflow"
        ],
        "Agent Kavramı ve React Tekniği": [
          "GitHub Linki",
          "Agent Nedir?",
          "Tavily Entegrasyonu",
          "Agent Entegrasyonu",
          "Agent Hafızası"
        ],
        "React Agent Derin İnceleme": [
          "React Teorisi",
          "LLM Nasıl Düşünüyor?",
          "Langsmith Tracing",
          "GitHub Linki"
        ]
      },
      "requirements": [
        "Temel programlama deneyimi",
        "OpenAI, Gemini vb. bir platformdan pro üyelik (API Anahtarı için)"
      ],
      "description": "Yapay Zeka uygulamaları geliştirmek, Langchain'e hakim olmak, Retrieval Augmented Generation örnekleri geliştirmek ve  LLM orkestrasyonu konusunda uzmanlaşmak istiyorsanız şu anda doğru yerdesiniz!\nBu eğitim ile Langchain'in nasıl çalıştığını, nasıl kullanıldığını, RAG gibi önemli konseptlerin nasıl uygulandığını örnekler yaparak öğrenceksiniz. Eğitim içerisinde anlatılan tüm teknik konular translator, ileri seviye chatbot, ileri seviye RAG gibi uygulamalar yapılarak pekiştirilmektedir. Profesyonel anlamda ortaya uygulamalar koymak için gerekli olan tüm bilgilerin de üstünden geçeceğimiz bu eğitime katılmak için temel programlama bilgisine sahip olmanız gerekmektedir.\nKurs Udemy'de 350.000+ öğrenciye Yazılım ve Siber Güvenlik eğitimleri veren ve Boğaziçi Üniversitesi'nde Yazılım Eğitmeni olan Atıl Samancıoğlu tarafından veriliyor! Siz de Yapay Zeka orkestrasyonuna adım atmak istiyorsanız aşağıdaki detaylı açıklamayı inceleyip kursa hemen kayıt olabilirsiniz.\nBu kursta Langchain, RAG vb. birçok konuyu beraber işleyeceğiz. Eğitimin içindeki bölümlerde değineceğimiz konulardan bazıları şunlar:\nLangchain\nLanggraph\nRetrieval Augmented Generation\nAgents\nMessage History, Memory Management\nLangsmith\nLangserve\nVectorstore\nChromaDB\nOpenAI API\nCustom GPTs\nİçerik & Genel Görünüş\nBu kurs yapay zeka araçları geliştirmeyi ve özellikle de büyük dil modellerini bu sürece dahil etmeyi düşünenler için idealdir. LLM'lerin Langchain ile nasıl yönetilebileceğini, Langgraph ile Agent'larımızın nasıl koordine edilebileceğini, RAG gibi ileri seviye konuların nasıl basit hale getirileceğini pratik projeler yaparak göreceğiz.\nEğitim pratik odaklı olsa da kesinlikle teorik boyutu aksatılmadan en ince detayları işlemeyi ihmal etmeyeceğiz. Slide anlatımlarının minimumda bulunduğu eğitimde genel olarak yaparak öğrenme üzerine bir yol izleyeceğiz.\nEğitim içerisinde yazılan tüm kodlar ve projeler sizlerle GitHub'da paylaşılacaktır. Bu şekilde kendi uygulamalarınızı geliştirirken ilgili komutları referans alabilir, istediğiniz şekilde kullanabilirsiniz!",
      "target_audience": [
        "Langchain öğrenmek isteyenler",
        "RAG konusunda uzmanlaşmak isteyenler",
        "Yapay zeka ile geliştirme yapmayı öğrenmek isteyenler",
        "LLM Orkestrasyonu konusunu öğrenmek isteyenler"
      ]
    },
    {
      "title": "Translation Technology II",
      "url": "https://www.udemy.com/course/translation-technology-ii/",
      "bio": "Translation Technology II: Free MOOC (English/Chinese translation) (English version): Module 7 - Module 10",
      "objectives": [],
      "course_content": {
        "Module 7. Introduction to SDL Trados Studio": [
          "Module 7. Introduction to SDL Trados Studio"
        ],
        "Module 8. Introduction to the Wordfast": [
          "Module 8. Introduction to the Wordfast"
        ],
        "Module 9. Introduction to Grammarly, Passolo, QuillBot, and Wordtune": [
          "Module 9. Introduction to Grammarly, Passolo, QuillBot, and Wordtune"
        ],
        "Module 10. Comparison of Translation Technology Tools and Summary": [
          "Module 10. Comparison of Translation Technology Tools and Summary"
        ],
        "Quiz": [
          "Reference materials"
        ]
      },
      "requirements": [
        "No prerequisites for taking the course. You will learn everything you need to know."
      ],
      "description": "This course provides learners with basic training in translation technology, helping them to acquire basic knowledge about computer-aided translation (CAT), machine translation (MT), concepts and available technology for translation, and hands-on experience of applying computer tools to enhance translation productivity. The role which computer technology plays in translation will be discussed.\n\n\nCourse Aim\nThis course aims to equip students with basic knowledge and skills in translation technology.\nCourse Intended Learning Outcome\n\n\nUpon completion of this course, you will be able to:\n1. Describe basic concepts of translation technology (including MT and CAT);\n2. Explain the practice of the variety of computer tools which translation technology could offer;\n3. Apply available MT systems and CAT tools and select appropriate tools for particular translation tasks;\n4. Identify the strengths and weaknesses of computer technology; and\n5. Edit the source and target texts to optimize efficiency of computer technology and translation quality.\n\n\nCourse Content / Topics Covered\nTranslation Technology II:\n•Module 7. Introduction to SDL Trados Studio\n•Module 8. Introduction to Wordfast\n•Module 9. Introduction to Grammarly, Passolo, QuillBot, and Wordtune\n•Module 10. Comparison of Translation Technology Tools and Summary\n\n\n\n\nThis course is suitable for the general public, especially:\n-language learners;\n-language users;\n-translators; and\n-interpreter.\n\n\nNo prerequisites for taking the course. You will learn everything you need to know.",
      "target_audience": [
        "Language users",
        "Language learners",
        "Translators",
        "Interpreters"
      ]
    },
    {
      "title": "Machine Learning through Case Studies for Beginners",
      "url": "https://www.udemy.com/course/machine-learning-through-case-studies-for-beginners/",
      "bio": "Gentle introduction to Machine Learning",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Getting Started",
          "Introduction to Machine Learning",
          "Email Classification Case Study",
          "Machine Learning Landscape",
          "Summary and Recap"
        ]
      },
      "requirements": [
        "None"
      ],
      "description": "Are you a beginner looking to get started with Machine Learning? This course offers a gentle introduction to Machine Learning through real world case studies as you invent your first Machine Learning algorithm.\nThis course gives you a broad overview of the variety of Machine Learning models and provides a learning ladder to continue learning. It also presents applications that use Machine Learning and details a plethora of techniques that are used to evolve Machine Learning models from data.\nThis course presents data for a simple case study of classifying emails automatically. It provides the data set, identifies features ans labels and presents the intuition behind any Machine Learning algorithm. The course goes on to talk about both the (i) Supervised and (ii) Unsupervised learning models. It presents an analysis of over fitting and under fitting in models.\nThe course aims to motivate a beginner to get started with their Machine Learning journey. This course will be further supplemented with focused sessions on various regression, classification and clustering algorithms.\nThe subsequent sessions will get in to the Math behind the algorithm while solving a real world case study. Students who continue this course through the recommended ladder will eventually have the skills to build and deploy Machine Learning models to production.",
      "target_audience": [
        "Any software developer wanting to begin their journey in Machine Learning and Artificial Intelligence"
      ]
    },
    {
      "title": "コンピュータビジョン数学基礎：数式とPythonで学ぶ最適化と最小二乗問題",
      "url": "https://www.udemy.com/course/cvmathbasic/",
      "bio": "専門的な数式に取り組むための数学の背景知識をマスターしよう",
      "objectives": [
        "集合，行列，ベクトルなどの線形代数の基礎",
        "連立方程式の解釈と一般化逆行列による解法",
        "微分の基礎と勾配ベクトル，ヘッセ行列，ヤコビ行列などの行列",
        "3つの微分の実装方法：数式微分，数値微分，自動微分",
        "制約なし最適化問題と最急降下法，ニュートン法などの代表的な反復法",
        "線形回帰と連立方程式の解法",
        "正則化を用いたリッジ回帰，lassoなどの解法",
        "制約付き最適化問題と制約条件の考え方",
        "疑似逆行列の導出：リッジ回帰，最小ノルム解",
        "凸最適化の基礎",
        "近接作用素，近接法，近接勾配法，射影勾配法",
        "双対上昇法，拡張ラグランジュ法，ADMM",
        "超平面による識別の考え方と損失関数",
        "パーセプトロン，ロジスティック回帰",
        "サポートベクトルマシンと制約付き最適化問題としての定式化",
        "2クラス識別問題と多クラス識別問題",
        "ニューラルネットワークとロジスティック回帰の関係",
        "多層ニューラルネットワークと畳込みネットワーク"
      ],
      "course_content": {},
      "requirements": [
        "線形代数の基礎知識",
        "微分の基礎知識",
        "jupyter notebookを実行できるスキルと環境",
        "必要なpythonモジュールをインストールできるスキル"
      ],
      "description": "このレクチャーでは，コンピュータビジョンやパターン認識，画像処理などで使われる数式や考え方，数学的手法を学びます．基礎的な連立方程式の解き方とその解釈，微分と最適化，回帰とスパースモデリング，制約付き最適化問題と凸最適化，識別などの基本的な考え方を，数式を通して理解し，いくつかの問題についてはPythonコードを使って理解を深めます．特に連立方程式Ax=bというよく見かける数式を題材に，顔画像の近似問題としていろいろな手法が定式化できること，また解き方があることを学びます．",
      "target_audience": [
        "線形代数と微分の応用例を知りたいエンジニア",
        "連立方程式の様々な解法を理解したい学生",
        "機械学習の専門書の数式に取り組みたいと思っている開発者"
      ]
    },
    {
      "title": "AIによる画像分類を学ぼう！【PyTorch+Colab】-CNNの基礎からTransformerの応用まで-",
      "url": "https://www.udemy.com/course/image-classification/",
      "bio": "人工知能（AI）を使った画像分類について学ぶコースです。CNNの基礎、CNNベースの有名モデル、Vision Transformer（ViT）などについて学び、Google Colaboratory環境でPythonを使い実装しましょう。",
      "objectives": [
        "AIによる画像分類の原理について、基礎的な知識を学びます。",
        "Python、PyTorchで書かれた画像分類のコードが読めるようになります。",
        "自分の力で、画像分類のコードを実装する力が身に付きます。",
        "AIによる画像分類全般についての知識が身につきます。",
        "様々な画像認識の有名モデルを扱えるようになります。",
        "CNNやTrasnformerを使った画像分類モデルを構築できるようになります。"
      ],
      "course_content": {},
      "requirements": [
        "Google Colaboratoryを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。",
        "何らかのプログラミング経験があった方が望ましいです。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "機械学習やデータサイエンス、深層学習について詳しい解説はありません。",
        "中学-高校レベルの数学で十分です。高度な数学は必要ありません。"
      ],
      "description": "「AIによる画像分類を学ぼう！」は、CNN（畳み込みニューラルネットワーク）などをベースにした画像分類技術を学ぶ講座です。\nフレームワークにPyTorchを使い、Google Colaboratory環境で様々な画像分類のモデルを実装します。\n\n\nAIによる画像分類は第3次AIブームのきっかけになった技術であり、応用範囲が広く多様な分野で使われています。\n本コースでは、最初にPyTorchの使い方、CNNの基礎を学んだ上で、AlexNet、ResNet、MobileNetなどの有名モデルを実装します。\nさらに、Transformerを利用した画像分類モデル「Vision Transformer」（ViT）も扱います。\n\n\nAIによる画像分類技術をうまく利用すれば、従来人間しかできなかったタスクの自動化が可能です。\n様々な画像認識モデルの仕組みを学び、Pythonで実装できるようになりましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! 人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. 画像分類の概要\n→ 画像分類の概要、および開発環境について学びます。\nSection2. CNNの基礎\n→ 様々な画像分類技術のベースとなる、CNN（畳み込みニューラルネットワーク）について学びます。\nSection3. Section4. 有名モデルの実装\n→ AlexNet、ResNet、MobileNetなどの様々な有名モデルを実装します。\nSection5. Transformerの利用\n→ 「Transoformer」を利用した画像分類モデルを構築します。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "AIによる画像分類に興味があるけど、学び方が分からない方。",
        "画像分類のコードがPythonで書けるようになりたい方。",
        "AIによる画像分類で、何らかの問題を解決したい方。",
        "AIによる画像分類全般の知識が欲しい方。",
        "仕事上、画像分類の知識が必要になった方。",
        "AlexNet、GoogLeNet、VGG、ResNet、DenseNet、MobileNet、Vision Transformerなどの有名モデルを扱えるようになりたい方。",
        "一歩進んだ画像認識技術を身に付けたい方。"
      ]
    },
    {
      "title": "ChatGPT para profesionales en Tecnología",
      "url": "https://www.udemy.com/course/chatgpt-masterclass-para-profesionales-en-tecnologia/",
      "bio": "Maximiza tu productividad con todo el poder de la inteligencia artificial. Crea prompts efectivos para roles en IT.",
      "objectives": [
        "Introducción a la IA, ChatGPT, manejo interfaz",
        "Ingeniería de promps y trucos para obtener las mejores respuestas de ChatGPT",
        "ChatGPT para optimizar tareas diarias en el trabajo como emails, informes, traducciones, presentaciones, resúmenes",
        "ChatGPT para el rol de PO y BA : Definición de épicas, riesgos, historias, criterios de aceptación, etc en el desarrollo de una app.",
        "ChatGPT para programadores: programación de historias de usuario, depuración, unit tests, resolver cualquier duda e incluso desarrollo de un juego.",
        "ChatGPT para Testers: Creación de un plan de pruebas, diseño de casos, NFRs, pruebas de APIs y automatización de tests con Cypress, reporte de bugs, SQL queries",
        "ChatGPT para SysAdmins y soporte técnico : migración de servidores, troubleshooting etc.",
        "ChatGPT para la busqueda laboral",
        "Material de descarga con una libreria de 550 prompts validados que puedes usar para cualquier cosa."
      ],
      "course_content": {
        "Introducción": [
          "Material de descarga y links útiles"
        ],
        "Introducción a IA y Chat GPT": [
          "¿Qué es ChatGPT?",
          "Creación de cuenta gratuita de ChatGPT",
          "Explicación de interfaz/ primera consulta"
        ],
        "Ingenieria de Prompts - obten las mejores respuestas!": [
          "Qué son los prompts y porque son tan importantes",
          "Ingeniería de prompts - Plantilla ideal",
          "Aplicación de las plantillas de prompts con ejemplos reales",
          "El arte de los prompts tipo \"follow-up\" o modificadores",
          "Libreria de Prompts basicos"
        ],
        "Chat GPT para tareas diarias en el trabajo": [
          "Redactar emails como todo un profesional con ayuda de IA",
          "Responder emails optimamente",
          "Escribir informes y articulos en cuestion de segundos.",
          "Traducción de textos con ChatGPT , las posibilidades son infinitas.",
          "Creación de presentaciones nunca fué tan facil!",
          "Resumir textos y procesamiento de scripts , aprovecha mejor el tiempo",
          "Creación automatica de mapas mentales",
          "Creación automatica de cronograma de actividades para proyectos"
        ],
        "ChatGPT para Product Owners, Product Managers y BAs": [
          "ChatGPT para POs: Crea la visión, épicas y riesgos en el desarrollo de una app *",
          "ChatGPT para POs: priorización de épicas y entregas x sprints *",
          "ChatGPT para BAs: creación de historias de usuario y especificaciones de APIs *",
          "Chat GPT para Scrum Masters: Resolución de problemas en el equipo"
        ],
        "ChatGPT para programadores": [
          "Programa historias de usuario en cuestion de minutos con todo el poder de IA *",
          "Depuración de codigo optimamente. *",
          "Creación de pruebas unitarias. *",
          "Crear un juego desde cero en el lenguage que quieras!",
          "Resolver cualquier duda de programación",
          "Explicación de código de otros , ChatGPT será tu mejor amigo.",
          "Libreria de prompts para programación"
        ],
        "ChatGPT para Testers": [
          "Diseño de casos de prueba, vuelvete mas productivo. *",
          "Definición de una estrategia de pruebas y NFRs. *",
          "API testing nunca fué tan facil.",
          "Instalación, creación de proyecto y automatización de tests desde 0. *",
          "Reporte de bugs en automático. *",
          "Consultas SQL con ChatGPT",
          "Bonus : Kit de prompts para QAs"
        ],
        "ChatGPT para SysAdmins o Soporte IT": [
          "Crea una maquina virtual de Linux dentro de ChatGPT!",
          "Migración de servidores con ChatGPT",
          "Troubleshooting errores tipicos en soporte de TI ausuarios",
          "Creación de una VPN en Windows 11 , ayuda tus usuarios con ChatGPT"
        ],
        "ChatGPT para tu busqueda laboral": [
          "Elaboración de un curriculum básico con IA",
          "Entrenamiento de entrevistas para cualquier cargo con IA"
        ],
        "Cierre del curso, despedida y links utiles": [
          "Cierre del curso"
        ]
      },
      "requirements": [
        "No se requiere ningun conocimiento previo, todo se explicará en el curso desde cero"
      ],
      "description": "¿Estás buscando un curso que te permita dominar la IA mediante el uso de ChatGPT para cambiar la forma en que trabajas, optimizar al máximo tu tiempo e incrementar tu productividad al 500%?\nEntonces, has llegado al curso indicado.\nLa inteligencia artificial es una realidad y está revolucionando todas las industrias . Si aún no la estás manejando, es posible que muy pronto puedas perder tu trabajo por algun profesional que sí sepa manejarla y explotarla al máximo.\nEste masterclass de 4 horas de contenido y en contante crecimiento tiene todo lo que necesitas saber  para empezar desde cero y aprovechar todas las capacidades de IA mediante Chat GPT aplicado en el campo de las tecnologías de información.\n¿Qué hace este curso diferente a los demás?\nEste curso está especialmente diseñado para profesionales que trabajan en el desarrollo de software y tecnología. Tiene como objetivo proporcionar a los estudiantes una comprensión de cómo se puede usar ChatGPT en la optimización de tareas diarias en el trabajo y herramientas para que puedas construir prompts efectivos para obtener las mejores respuestas. (Ademas se incluye una libreria con 1000 prompts para que tengas como referencia)\nEste no es el típico curso de ChatGPT donde el instructor se dedica a hacer preguntas al chatbot y mostrar las respuestas. En este curso vamos a explicar la ingenieria de los Prompts, como obtener las mejores respuestas y ademas vamos a poner a trabajar a la IA con un objetivo específico: desarrollar una aplicación básica desde cero, usando todas las capacidades del machine learning al servicio de roles como Product Owner, BA, Scrum Master, Programador, Testers y otros entusiastas de la tecnología. Algunos de los temas que vamos a ver son\nIntroducción a la IA, Chat GPt y la Ingeniería de Prompts\nUso de ChatGPT para optimizar tareas diarias en el trabajo como emails, informes, traducciones, presentaciones, resúmenes)\nUso de ChatGPT para el rol de PO y BA : Definición de épicas, riesgos, historias, criterios de aceptación, etc en el desarrollo de una app.\nUso de ChatGPT para programadores: programación de historias de usuario, depuración, unit tests, resolver cualquier duda e incluso desarrollo de un juego.\nUso de ChatGPT para QAs: Creación de un plan de pruebas, diseño de casos, NFRs, pruebas de APIs y automatización de tests con Cypress\n\n\n¿Qué vas a lograr al finalizarlo?\nTendrás las habilidades y el conocimiento necesarios para aplicar la IA y el procesamiento del lenguaje natural de ChatGPT en tu trabajo de una manera más óptima. Todo esto lo verás de una manera práctica, aplicada a un proyecto real, donde podrás comprobarlo tú mismo.\nNo pierdas la oportunidad de mejorar tu carrera y maximizar tu productividad a la máxima potencia .\n¡Regístrate hoy en este MasterClass de ChatGPT para Profesionales de Tecnología y adquiere una de las habilidades del futuro!",
      "target_audience": [
        "Product Owners / Project Managers o BAs trabajando en desarrollo de proyectos",
        "Programadores que quieran optimizar su trabajo con IA",
        "Ingenieros de Pruebas, Testers, QAs que quieran optimizar su trabajo con IA",
        "Ingenieros DevOps",
        "Cualquier persona que trabaje con tecnologias de información que quieran optimizar su trabajo con IA"
      ]
    },
    {
      "title": "Solve Kaggle's OpenVaccine Challenge w/ Kubeflow and MLOps",
      "url": "https://www.udemy.com/course/solve-kaggle-openvaccine-challenge-kubeflow-kale-mlops/",
      "bio": "Data Science, Kubeflow, Kale and MLOps come together in this course based on the Kaggle OpenVaccine Challenge;",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Familiarity with popular Data Science concepts"
      ],
      "description": "The Kaggle OpenVaccine problem is a popular Data Science topic. In this course, you will explore how to solve this problem with Kubeflow and Kale. In addition, you’ll learn how the work you are doing is the foundation for an effective and self-sustainable MLOps culture and platform solution that you can undertake at your enterprise.\n\n\nThis course is presented as a series of hands-on articles where you will learn about Kaggle, Data Science, and MLOps while using the Kubeflow platform with Kale to compile and run Kubeflow Pipelines. The overall time commitment is about 1 to 1.5 hours.\n\n\nSpecifically in this course, you will:\nLearn about Kaggle.\nLearn about Kubeflow.\nLearn about MLOps.\nUse Jupyter Notebooks in Kubeflow to review the Kaggle OpenVaccine Problem Solution.\nUse Kale to convert a Jupyter Notebook into a Kubeflow Pipeline.\nUse Katib to perform Hyperparameter Tuning on the ideal OpenVaccine model.\nLoad the Kubeflow Pipeline Snapshots in new Notebook Servers.\nServe the ideal OpenVaccine model from a Jupyter Notebook.\nRelate the activities in this course back to the core tenets of MLOps.\nRequirements: We assume that you have familiarity with popular Data Science concepts and have used some of these philosophies in practice.\nInstructor-Led Option: If you would prefer to take the course live, this course is available on a monthly basis with an instructor. If this is your preference, navigate and sign up on the Arrikto events page.",
      "target_audience": [
        "Anyone interested in learning more about Kaggle, Kubeflow and / or MLOps"
      ]
    },
    {
      "title": "Introduction To Data Science",
      "url": "https://www.udemy.com/course/introduction-to-data-science-c/",
      "bio": "Your First Step Into The Data Science Journey",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction to Data Science Part 1",
          "Introduction to Data Science Part 2",
          "Introduction to Data Science Part 3",
          "Introduction to Data Science Part 4",
          "Introduction to Data Science Part 5",
          "Introduction to Data Science Part 6",
          "Introduction to Data Science Part 7",
          "Introduction to Data Science Part 8",
          "Introduction to Data Science Part 9"
        ]
      },
      "requirements": [
        "This is a quick intro to the world of Data Science and no prerequisites is needed for this course"
      ],
      "description": "Data Science is one of the booming field currently and this course discusses what it takes to become a Data Scientist\nThis course is for anyone who wants to start their career in Data Science but confused about all the jargon that you are hearing  around the web. This course will answer all your questions that you have to begin your Journey to become a Data Scientist. Kindly note that this course doesn't make you a Data Scientist but this is your first step to understand what is Data Science, Data Analytics, Business Analytics, Machine Learning and their differences and where Industries use them.\nWhat students learn from this course?\n- What is Data Science ?\n- What is Data Analytics ?\n- What is Machine Learning ?\n- What is Data Analysis?\n- What is Business Analysis ?\nWho is this course for ?\n- Data Science Enthusiasts\n- Python Programmers\n- SQL Developers\n- Machine Learning Enthusiasts\n- People who wants to understand different fields in Data Science\nWhat are the prerequisites ?\n- This is a quick intro to the world of Data Science and no prerequisites is needed for this course\nThe Series of Data Science Bootcamp courses will be coming up next starting with Python for Data Science, SQL for Data Science, Business Statistics and Machine Learning.",
      "target_audience": [
        "Python Developers",
        "Data Science Enthusiasts",
        "Data Analyst",
        "Students who want to understand the buzz words of Data Science and its different fields"
      ]
    },
    {
      "title": "Machine Learning \"no-code\": Aprenda de Forma Simples!",
      "url": "https://www.udemy.com/course/machine-learning-e-deep-learning/",
      "bio": "Aprenda estas técnicas de Inteligência Artificial sem precisar conhecimento prévio ou saber programação!",
      "objectives": [
        "Aprenda a fazer previsão de eventos, antes de eles acontecerem",
        "Veja técnicas de classificação de objetos",
        "Entenda como fazer previsão de valores contínuos (numéricos)",
        "Descubra como recomendar a venda de produtos que tem maior probabilidade de venderem juntos",
        "Agrupe itens desconhecidos através de características comuns",
        "Avalie a performance de suas previsões"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Chegando na JJBike",
          "Material para Download",
          "Aula Introdutória",
          "Introdução a Machine Learning"
        ],
        "Preparação e Exploração": [
          "Conhecendo o Weka",
          "Instalação do Weka",
          "Dados utilizados no Curso",
          "Explorando o Weka",
          "Preparação e Exploração"
        ],
        "Classificação": [
          "Fundamentos de Classificação",
          "Fundamentos de Classificação Parte II",
          "Treinamento o Modelo",
          "Tipos de Algoritmos",
          "Problemas de Classificação",
          "Naive Bayes",
          "Redes Bayesianas",
          "Árvores de Decisão",
          "Adicionando a Classe",
          "Métricas de Erros ME MAE RMSE MPE MAPE",
          "Classificação"
        ],
        "Seleção de Atributos": [
          "Seleção de Atributos",
          "Seleção de Atributos na Prática"
        ],
        "Redes Neurais e Deep Learning": [
          "Introdução a Redes Neurais",
          "Redes Neurais Artificiais",
          "Topologia e Arquitetura",
          "Deep Learning",
          "Multilayer Perceptron"
        ],
        "Outros Aplicativos": [
          "Experimenter",
          "knowledge flow",
          "Package Manager"
        ],
        "Agrupamentos": [
          "Agrupamentos",
          "Agrupamentos na Prática",
          "Agrupamentos"
        ],
        "Regras de Associação": [
          "Regras de Associação",
          "Regras de Associação na Prática",
          "Regras de Associação"
        ],
        "Simulando um Caso Real": [
          "Introdução",
          "Simulando"
        ],
        "Encerramento": [
          "Encerramento",
          "Voltando a JJBike"
        ]
      },
      "requirements": [
        "Não existem pré-requisitos!"
      ],
      "description": "Neste curso você vai aprender as mais importantes técnicas de Machine Learning, que é a mais fascinante e aplicada área da Inteligência Artificial, utilizando uma ferramenta totalmente visual. Desta forma, você não precisa entender de escrita de código ou lógica de programação, basta importar dados, selecionar as opções e executar os procedimentos.\nUtilizando dados reais fornecidos no curso, você vai aprender, entre outras coisas à:\nCompreender o que é Machine Learning e como as Técnicas Funcionam\nConheça Redes Neurais Artificiais\nSaber o que é Classificação, Regressão, Regras de Associação e Agrupamentos\nEntender o que é Seleção de Atributos\nAprender a tratar e pré-processar dados\nPrever eventos futuros e classificar objetos com classificação\nPrever informações contínuas, como vendas ou temperaturas, utilizando regressão\nReunir elementos com características comuns utilizando agrupamentos\nEntender como recomendar vendas de produtos em conjunto usando regras de associação\nEstudar como funcionam redes neurais, qual a sua estrutura e funcionamento e o que é uma rede neural profunda\nAvaliar a performance de um modelo\nUtilizar diferentes técnicas de divisão de dados para treino e teste\nProduzir elementos gráficos representativos de modelos, como Árvores de Decisão e Redes Neurais Artificiais\nConhecer o Weka, baixar, instalar e utilizar a ferramenta\nEntender os diferentes módulos do Weka e qual a função de cada um\nConhecer o conceito de Pacotes\nAo final do curso, você será capaz de aplicar as técnicas de Machine Learning em problemas do mundo real, utilizando seus próprios dados.",
      "target_audience": [
        "Todos interessados em aprender Machine Learning e Deep Learning"
      ]
    },
    {
      "title": "Fundamentals of Machine Learning Regression",
      "url": "https://www.udemy.com/course/fundamentals-of-machine-learning-regression/",
      "bio": "Master the Fundamentals of Regression Techniques in Machine Learning: SciKit Learn and Pandas Essentials",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "AI Overview",
          "Understanding Artificial Intelligence (AI) and Machine Learning (ML)",
          "Classification vs Regression"
        ],
        "Regression": [
          "Note (READ BEFORE WATCHING THE NEXT VIDEOS)",
          "Data Preprocessing",
          "Linear Regression: Theory & Implementation",
          "Support Vector Machine: Theory & Implementation",
          "Decision Trees: Theory & Implementation",
          "Model Evaluation & Prediction",
          "Machine Learning Regression Quiz",
          "Next Steps"
        ]
      },
      "requirements": [
        "Beginnner Python Experience Helps"
      ],
      "description": "Artificial Intelligence (AI) is transforming industries and revolutionizing the way we live and work. To stay ahead in this rapidly evolving landscape, it's crucial to understand and harness the power of machine learning. Our course, Intro to Fundamentals of Machine Learning Regression, is your gateway to mastering the fundamentals of machine learning regression algorithms.\nWhat You'll Learn:\nCore Regression Algorithms: Delve into the principles and applications of linear regression, support vector machine and decision trees.\nModel Evaluation Techniques: Learn to evaluate your models' performance using essential metrics, ensuring accuracy and reliability.\nData Preprocessing with pandas: Acquire the basic skills to clean and transform data, a vital step in any machine learning project.\nHands-On Practice: Engage in interactive code-along sessions to apply theoretical knowledge and gain practical experience.\nWhy This Course?\nOur course offers high-quality content designed to be both comprehensive and engaging. Each lesson features meticulously crafted presentations and interactive code-along sessions, ensuring you not only understand the theory but can also implement it effectively.\nWho Should Join:\nBeginners in Machine Learning: This course is perfect for those new to the field, providing a solid foundation in regression techniques and data preprocessing.\nExperienced Programmers: Expand your programming expertise by integrating basic machine learning concepts and practices.\nData Science Enthusiasts: Enhance your data analysis skills and learn to build effective regression models.\nStudents and Professionals: Apply machine learning regression in academic projects or professional scenarios to solve real-world problems.\nCourse Highlights:\nHigh-Quality Presentations: Our lectures are designed to simplify complex concepts, making them accessible and engaging.\nInteractive Code-Alongs: Follow along with practical coding sessions that reinforce your learning through hands-on practice.\nComprehensive Coverage: From theoretical foundations to practical implementations, this course covers all aspects of machine learning regression.\nDon't miss the opportunity to adapt to the AI-driven future. Enroll in Fundamentals of Machine Learning Regression today and take the first step towards mastering machine learning regression techniques.",
      "target_audience": [
        "Beginners in programming and new to the field of machine learning",
        "Those who are new to the field of machine learning"
      ]
    },
    {
      "title": "R ile Veri Bilimi, İstatistik ve Makine Öğrenmesi (50+ Saat)",
      "url": "https://www.udemy.com/course/r-veri-bilimi-istatistik-ve-makine-ogrenmesi-rstudio/",
      "bio": "R ile Programlama ve Veri Bilimi Eğitimi: Uçtan Uca Farklı Uygulamalarla Machine Learning ve İstatistik!",
      "objectives": [
        "Hem teorik hem de uygulamalı istatistik ve makine öğrenmesi öğreneceksiniz.",
        "R'da veri bilimine yönelik programlama öğreneceksiniz.",
        "Farklı veri yapıları ve bu veri yapıları üzerinde matematik ve istatistik işlemleri öğreneceksiniz.",
        "Data frame üzerinde veri manipülasyonu işlemlerini öğreneceksiniz.",
        "Algoritma ve fonksiyonel programlama, fonksiyonlar, \"for\" ve \"while\" döngüleri, \"if-else\" koşullarını öğreneceksiniz.",
        "Veri bilimi ve raporlarınız için veri görselleştirme tekniklerini öğreneceksiniz.",
        "Farklı olasılık dağılımlarını ve bu dağılımları farklı problemleri nasıl uygulamayabilceğinizi öğreneceksiniz.",
        "Parametrik ve parametrik olmayan istatistik teknikleri, tek değişkenli ve çok değişkenli varyans analizini öğreneceksiniz.",
        "Korelasyon ve kovaryans kavramı, farklı korelasyon testlerini öğreneceksiniz.",
        "Keşfedici veri analizini ve bu kapsamda izlenen adımları öğreneceksiniz.",
        "Veri ön işleme: aykırı değerlerle başa çıkma, kayıp gözlem doldurma teknikleri, dönüşümler, normalizasyon ve standartlaştırma işlemlerini öğreneceksiniz.",
        "Regularization işlemleri, model tuning ve model doğrulama tekniklerini öğreneceksiniz.",
        "Regresyon, Sınıflandırma ve Kümeleme problemleri üzerine makine öğrenmesi tekniklerini nasıl uygulayacağınızı öğreneceksiniz.",
        "Farklı makine öğrenmesi metodlarını farklı problemlerle nasıl uygulacağınızı uygulamalı olarak öğreneceksiniz."
      ],
      "course_content": {},
      "requirements": [
        "Veri bilimine meraklı olmak",
        "R kodlarını çalıştırabileceğiniz bir bilgisayar"
      ],
      "description": "R ile Uygulamalı Veri Bilimi: İstatistik ve Makine Öğrenmesi Eğitimi Sizleri Bekliyor!\n\nR'da veri bilimine (Data Science) yönelik programalama, istatistik ve makine öğrenmesi teknikleri için detaylı olarak hazırlanmış bu eğitimde, gerek iş hayatınızda gerek okul hayatınızda ihtiyacınız olacak bir çok bilgi sizleri bekliyor. Tüm tekniklerin detaylı olarak anlatıldığı 50 saat ve 300'den fazla ders içeriğinden oluşan bu eğitim, başlangıç düzeyinden ileri düzeye eğitim almak isteyenler için R Studio üzerinde hazırlandı. Eğitimimizde farklı veri setleri ve farklı R paketleri kullanarak bir çok istatistik ve makine öğrenmesi tekniğini hem teorik hem de uygulamalı olarak öğreneceğiz!\n\nR ile Veri Bilimi Eğtiminde ele alınan konular;\n\n\nR'da İstatistiksel teknikleri hem teorik hemde uygulamalı\nR'da makine öğrenmesi tekniklerini hem teorik hem de uygulamlı\nVeri Bilimine yönelik R Programming (R Programlama)\nR'da tanımlı farklı veri yapıları ve veri türleri\nMatematik ve tanımsal istatistikler\nVeri manipülasyonu\nAlgoritma ve fonksiyonel programlama\nVeri görselleştirme teknikleri\nOlasılık dağılımları\nParametrik ve parametrik olmayan istatistik testleri\nVaryans analizi\nKorelasyon testleri\nKayıp ve aykırı değer kontrolleri\nKayıp gözlem doldurma teknikleri\nVeriler üzerinde dönüşüm işlemleri\nNormalizasyon ve standartlaştrıma işlemleri\nRegularization işlemleri\nModel doğrulama ve model tuning işlemleri\nRegresyon, Sınıflandırma ve Kümele problemleri için farklı Makine Öğrenmesi teknikleri\nİstatistik ve makine öğrenmesi kapsamında neredeyse tüm konuların ele alındığı bu eğitim sonunda; r, veri bilimi, istatistik ve makine öğrenmesine hakim olabileceksiniz. Bununla birlikte  Sizden Gelen Sorular bölümünde eğitim kapsamında anlatılan konularda yaşadığınız problemlerin çözümlerini görüntü olarak takip edebileceksiniz.\n\n\nBaşarılı, etkili ve işe yarar bir eğitim süreci olması dileğiyle....",
      "target_audience": [
        "Veri bilimine meraklı ve veri biliminde kendilerini geliştirken isteyeneler",
        "Başlangıç seviyesinden ileri seviyeye R eğitimi almak isteyenler",
        "Veri bilimi için istatistik ve makine öğrenmesi teoriğinde kendini geliştirmek isteyenler",
        "İstatistik ve Makine öğrenmesi tekniklerini uygulamalı olarak öğrenmek isteyenler"
      ]
    },
    {
      "title": "Introduction to NLP",
      "url": "https://www.udemy.com/course/introduction-to-nlp-b/",
      "bio": "Fundamentals of Natural Language Processing",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic understanding of Python"
      ],
      "description": "Natural Language processing is today a fast-emerging technology area. It has also been one of the most difficult topics to handle for the computers. Thanks to the advancement in artificial intelligence, we can process natural language more easily today. Many business applications today leverage the power of NLP. With the perfection on speech to text and text to speech conversions, NLP tools are used today as personal assistants and robo advisors. The chat bots are primary interface for many business applications. The NLP engine can process vast amounts of texts and classify them as well as translate them to another language. NLP programs are working in conjunction with the image recognition techniques to automatically generate captions from the images and the vice-versa.\nThis course is tries to demystify some aspects of NLP and address some of the challenges and approaches to handle the same.\nExpectations from the course\n1. Why NLP is important\n2. Complexity in handling NLP\n3. Business use cases of NLP\n4. Different types of NLP problems\n5. Approach for solving NLP problems\n6. Applying machine learning concepts\n7. Word embedding\nThis course uses python programming for basic hands-on. Some of the practice sessions in this course include: -\n1. Standard text handling using nltk\n2. Pre-processing text (normalization)\n3. Sentiment analysis of the review comments\n4. Spam detection using machine learning algorithms",
      "target_audience": [
        "Beginner NLP"
      ]
    },
    {
      "title": "【2023年5月改訂版】実践 Python データサイエンス",
      "url": "https://www.udemy.com/course/python-jp/",
      "bio": "データ解析の基本、可視化、統計、機械学習などデータサイエンスに関するあらゆる実践的なスキルがPythonで身に付く！",
      "objectives": [
        "Pythonを使った基本的なプログラミング",
        "numpyを使ったベクトルや行列の操作",
        "pandasを使ったデータ処理",
        "JSON、HTML、Excelシートなどのデータ形式をPythonで扱う",
        "matplotlib、seabornを使ったデータの可視化",
        "応用範囲の広いデータ解析のスキル",
        "Jupyter Notebookを使ったPythonプログラミング"
      ],
      "course_content": {
        "このコースの内容とPythonについて": [
          "コースの概要",
          "学習を進めるために"
        ],
        "準備": [
          "インストールとセットアップ",
          "Jupyter Notebookの使い方",
          "学習を進めるための資料"
        ],
        "numpyを知ろう": [
          "numpy入門",
          "アレイを作る",
          "アレイを使った計算",
          "アレイの添え字",
          "行と列の入れ替え",
          "アレイと計算のための関数",
          "アレイを使ったデータ処理",
          "アレイのの入出力"
        ],
        "pandas入門": [
          "Series（1次元のデータ列）",
          "DataFrame（テーブル型のデータ）",
          "indexの基本",
          "indexを変える",
          "行や列を削除する",
          "データを取り出す",
          "形の違うデータの計算",
          "データの並べ替えと順番",
          "データと統計量",
          "欠損値の扱い",
          "indexの階層構造"
        ],
        "データ解析の基礎 その1": [
          "テキストデータの読み書き",
          "JSON",
          "HTMLからのデータの取り出し",
          "Excel形式のファイルを読み込む"
        ],
        "データ解析の基礎 その2": [
          "データのマージ",
          "indexを使ったマージ",
          "データの連結",
          "DataFrameを組み合わせる",
          "SeriesとDataFrameの変換",
          "ピボットテーブルの作り方",
          "重複したデータの処理",
          "マッピングを使った列の追加",
          "置換",
          "indexの変更",
          "ビニング（Binning）",
          "外れ値",
          "Permutation"
        ],
        "データ解析の基礎 その3": [
          "データをまとめるGroupBy",
          "データをまとめるGroupByその2",
          "データのAggregation",
          "Split、Apply、Combining",
          "クロス集計表"
        ],
        "データの可視化": [
          "seabornのインストール",
          "ヒストグラム",
          "カーネル密度推定",
          "分布の可視化",
          "ボックスプロットとバイオリンプロット",
          "回帰とプロット",
          "ヒートマップとクラスタリング"
        ],
        "実践データ解析": [
          "実践データ解析（導入）",
          "実践データ解析（準備）",
          "タイタニック その1",
          "タイタニック その2",
          "タイタニック その3",
          "タイタニック その4",
          "株式市場のデータ解析入門",
          "株式市場 その1",
          "株式市場 その2",
          "株式市場 その3",
          "株式市場 その4",
          "株式市場 その5",
          "選挙とデータ解析",
          "選挙 その1",
          "選挙 その2",
          "選挙 その3",
          "選挙 その4"
        ],
        "機械学習": [
          "機械学習入門",
          "線形回帰 その1",
          "線形回帰 その2",
          "線形回帰 その3",
          "線形回帰 その4",
          "ロジスティック回帰 その1",
          "ロジスティック回帰 その2",
          "ロジスティック回帰 その3",
          "ロジスティック回帰 その4",
          "多クラス分類 その1：ロジスティック回帰",
          "多クラス分類 その2：k近傍法",
          "サポートベクトルマシン（SVM） その1",
          "サポートベクトルマシン（SVM）その2",
          "ナイーブベイズ分類 その1",
          "ナイーブベイズ分類 その2",
          "決定木とランダムフォレスト"
        ]
      },
      "requirements": [
        "基礎的な数学のスキル",
        "パソコン（OSは、Mac、Windows、Linuxならどれでも構いません）",
        "あとは、やる気"
      ],
      "description": "このコースは、Pythonを使ってデータを解析し可視化するために必要なスキルを網羅しています。Pythonと科学計算のためのライブラリの使い方が完璧に理解できるようになっています。\nこのコースを習得すれば、次のような事ができるようになります。\n- Pythonプログラミングへの知識が深まります。\n- NumPyを使って、アレイを使った数値計算ができるようになります。\n- pandasを使った効果的なデータ解析ができるようになります。\n- Matplotlibとseabornを使って、出版にも使えるほど綺麗なデータの可視化が可能になります。\n- Pythonを使って実際にデータを解析する方法論が身につきます。\n- 機械学習への理解が相当高まります。\n\n\n2023年5月にコースの大幅改訂を行いました。ほとんどすべての動画と資料が更新されています。\n\n\n17時間以上、100本を超えるビデオと、すぐに使えるPythonコードがまとまった資料が用意されていますので、データサイエンスに関する知識が飛躍的に高まります。",
      "target_audience": [
        "Pythonプログラミングだけでなく、データサイエンスやデータの可視化に興味がある方々",
        "Pythonの経験は問いませんし、プログラミング初学者でも大丈夫です。",
        "急速な広がりをみせる、データサイエンスの世界を覗いてみたい方々"
      ]
    },
    {
      "title": "IA Generativa, LLMs e Agentes de IA (AI Agents) na Prática",
      "url": "https://www.udemy.com/course/iag-llms/",
      "bio": "Aprenda na Prática o que são LLMs, SLMs, IA Generativa, Agentes de IA, Suas Aplicações e o Impacto nas Organizações",
      "objectives": [
        "Você vai compreender que é Inteligência Artificial Generativa, seus tipos e o impacto destas tecnologias nas empresas, organizações e na sociedade como um todo.",
        "Você vai entender o que são LLMs e SMLs, uma visão geral de como funcionam e seus usos atuais e futuros.",
        "A partir de demonstrações práticas, você conhecerá diversas ferramentas de IA Generativa para criação de texto, vídeos, imagens, voz, música e muito mais",
        "Vai acompanhar o estado da arte das tecnologias de IA Generativa através de atualizações periódicas no curso.",
        "Você vai entender o que são Agentes de IA e seu impacto no mundo moderno",
        "Este curso não é um curso técnico, que com diversos termos e conceitos complexos. O objetivo é ajudar qualquer um a compreender o impacto das tecnologias.",
        "Você vai aprender a usar Agentes de IA para busca automática, criação automática de sumários de vídeos e podcasts e Pesquisa Profunda"
      ],
      "course_content": {
        "Introdução ao Curso e Seus Objetivos": [
          "Introdução ao Curso",
          "Para Quem Este Curso Foi Criado e Por Quê?",
          "Como o Curso está Organizado"
        ],
        "Fundamentos da Inteligência Artificial Generativa e de LLMs": [
          "O que é Inteligência?",
          "O que é Inteligência Artificial",
          "O que é Inteligência Artificial Generativa",
          "O Que São LLMs",
          "Como os LLMs são Criados e Treinados",
          "O que são LLMs Multimodais",
          "Um Exemplo Prático de LLM Multimodal em Ação",
          "O Que São Small Language Models",
          "O Que São Agentes de IA"
        ],
        "LLMs e IA Generativa na Prática": [
          "Como Esta Seção Funciona",
          "Acesso a LLMs na Forma de Chatbots - ChatGPT, Copilot, Gemini e ChatHUB",
          "Tarefa : Crie um artigo sobre um assunto do seu interesse usando um dos Chatbots",
          "Usando LLMs Localmente com o Jan",
          "LLMs Dentro de Ferramentas de Escrita - Microsoft Word and PowerPoint",
          "LLMs Dentro de Ferramentas de Escrita - Google Docs",
          "Tarefa : Crie um documento Word ou Google Docs com uma tabela",
          "Geração de Imagens Usando Inteligência Artificial Generativa",
          "Geração de Imagens a Partir da Criação de Elementos 3D Usando IA Generativa",
          "Tarefa : Crie imagens usando uma das ferramentas de geração de imagens citadas",
          "Geração de Vídeos Usando Ferramentas de IA Generativa",
          "Tarefa : Crie um vídeo sobre algum tópico do seu interesse.",
          "Combinando Texto e Imagens Geradas por AI para Criação de Apresentações",
          "Criação e Clonagem de Voz",
          "Geração de Música a Partir de Prompt Usando IA Generativa",
          "Como Criar Bases de Dados Para Pesquisa, Estudo e Criação de Relatórios com IA"
        ],
        "Agentes de IA de Busca Automática, Busca Profunda e Análise": [
          "Pesquisa e Geração de Imagem Automática com o ChatGPT Tarefas Agendadas",
          "Criação Automática de Sumários de Videos e Podcasts",
          "Agentes de IA para Pesquisa Profunda",
          "Agentes de IA para Busca Profunda - Resultados"
        ],
        "Ética, Preconceito e Privacidade na Era da IA Generativa": [
          "Viés e Discriminação na IA Generativa",
          "O que é uma Mulher Bonita para Ferramentas de AI Generativa de Geração de Imagem"
        ],
        "Seus Próximos Passos": [
          "Seus Próximos Passos",
          "Aula Bônus, Seu Certificado e o Matewrial de Apoio do Curso"
        ]
      },
      "requirements": [
        "Desejo de participar, de forma ativa, na revolução da Inteligência Artificial",
        "Apenas um navegador web"
      ],
      "description": "Estamos vivendo a era da Inteligência Artificial Generativa, mas você sabe o que é IA Generativa e Agentes de IA?\nE o que vem a ser Large Language Models?\nE Small Language Models?\nComo o ChatGPT é capaz de fazer tudo que faz?\nComo estas tecnologias podem impactar seu trabalho e sua vida?\nQual é o impacto ético e social destas tecnologias?\nComo eu posso usar estas tecnologias a meu favor?\nComo agentes de IA podem aumentar minha produtividade?\n\n\nEstas são algumas das centenas de dúvidas que muitas pessoas têm em relação a era da IA Generativa e Agentes de IA.\nEu sei pois como professor e palestrante sobre IA Generativas, recebo muitas perguntas como essas.\n\n\nNeste curso, busco esclarecer, de forma simples e didática, o que são LLMs, o que é Inteligência Artificial Generativa, Agentes de IA  e a aplicação prática dessas tecnologias.\n\n\nMas o curso vai além, o curso também explica os principais termos relacionados, em uma linguagem clara e didática.\n\n\nOutro diferencial deste curso é a prática.\nO curso apresentará e demostrará diversas ferramentas de Inteligência Artificial Generativa, que você pode usar imediatamente, para criar:\nTexto\nImagens\nVídeos\nVoz (inclusive como clonar voz)\nMúsica\nConteúdo Misto (apresentações, páginas web, documentos)\nRelatórios de Pesquisa\nPesquisa Automatizada\nE muito mais!\n\n\nImportante: O curso apresentará diversas ferramentas, mas como um curso introdutório, o objetivo não é mostrar cada detalhe das ferramentas! O curso fará uma demonstração prática, do uso rápido de cada ferramenta, para que você entenda que estas ferramentas são projetadas para serem simples de usar.\n\n\nSe você não quer ficar atrás da nova revolução, inscreva-se no curso!",
      "target_audience": [
        "Este curso é destinado a quem deseja entender o que é a revolução da Inteligência Artificial Generativa e como esta impacta e impactará empresas, organizações e a sociedade como um todo.",
        "Este curso é introdutório e não técnico. O curso não entra em detalhes técnicos ou irá explicar cada detalhe das ferramentas apresentadas."
      ]
    },
    {
      "title": "Tensorflow 2.0: Um Guia Completo sobre o novo TensorFlow",
      "url": "https://www.udemy.com/course/tensorflow-2-guia-completo/",
      "bio": "Crie aplicações incríveis de Aprendizado Profundo (Deep Learning) e Inteligência Artificial com a biblioteca do Google",
      "objectives": [
        "Como usar o TensorFlow 2.0 em Data Science",
        "Diferenças importantes entre o TensorFlow 1.x e o TensorFlow 2.0",
        "Como implementar redes neurais artificiais, redes neurais convolucionais e redes neurais recorrente com o TensorFlow 2.0",
        "Como criar seu próprio aplicativo de Transfer Learning (transferência de aprendizagem) no TensorFlow 2.0",
        "Como criar um bot para negociação no mercado de ações usando Aprendizagem por Reforço",
        "Como conduzir validação de dados com o TensorFlow Data Validation (TFDV)",
        "Como trabalhar com pré-processamento com o TensorFlow Transform (TFT)",
        "Como colocar um modelo do TensorFlow em produção utilizando a API Flask",
        "Como colocar um modelo do TensorFlow em produção utilizando TensorFlow Serving e API RESTful"
      ],
      "course_content": {
        "Introdução": [
          "Bem-vindo(a) ao curso!",
          "Currículo do curso + slides",
          "Mais sobre Inteligência Artificial"
        ],
        "Básico do TensorFlow": [
          "Do TensorFlow 1.x para o TensorFlow 2.0 - Constantes, variáveis e tensores",
          "Operações com tensores",
          "Strings"
        ],
        "Redes Neurais Artificiais": [
          "Configuração do Projeto",
          "Pré-processamento",
          "Construção da Rede Neural Artificial",
          "Treinamento da Rede Neural Artificial",
          "Avaliação da Rede Neural Artificial",
          "Redes Neurais Artificiais",
          "Tarefa",
          "Solução da Tarefa"
        ],
        "Redes Neurais Convolucionais": [
          "Configuração do Projeto e Pré-processamento",
          "Construção da Rede Neural Convolucional",
          "Treinamento e Avaliação da Rede Neural Convolucional",
          "Redes Neurais Convolucionais",
          "Tarefa"
        ],
        "Redes Neurais Recorrentes": [
          "Configuração do Projeto e Pré-processamento",
          "Construção da Rede Neural Recorrente",
          "Treinamento e Avaliação da Rede Neural Recorrente",
          "Redes Neurais Recorrentes"
        ],
        "Transferência de Aprendizado e Fine Tuning": [
          "O que é Transferência de Aprendizado?",
          "Configuração do Projeto",
          "Pré-processamento",
          "Carregamento do Modelo MobileNet V2",
          "Congelamento do Modelo Pré-treinado",
          "Cabeçalho Personalizado no Modelo Pré-treinado",
          "Definição do Modelo de Transferência",
          "Compilação do Modelo de Transferência",
          "Geradores de Imagens",
          "Transferência de Aprendizagem",
          "Avaliação dos Resultados",
          "Definição do Fine Tuning",
          "Compilação do Fine Tuning",
          "Aplicação do Fine Tuning",
          "Avaliação do Fine Tuning",
          "Transferência de Aprendizagem"
        ],
        "Aprendizagem por Reforço Profunda para Negociação no Mercado de Ações": [
          "Configuração do Projeto",
          "IA Trader 1",
          "IA Trader 2",
          "IA Trader 3",
          "IA Trader 4",
          "IA Trader 5",
          "Dataset Loader Function",
          "Criação dos Estados",
          "Carregamento da Base de Dados",
          "Definição do Modelo",
          "Treinamento I",
          "Treinamento II"
        ],
        "Validação de Dados com TFDV (TensorFlow Data Validation)": [
          "Configuração do Projeto",
          "Carregamento da Base de Dados",
          "Criação da Estrutura da Base de Dados",
          "Computação das Estatísticas da Base de Teste",
          "Detecção de Anomalias",
          "Preparação do Schema para Produção",
          "Salvando o schema",
          "Material Complementar"
        ],
        "Pré-processamento de Dados com TFT (TensorFlow Transform)": [
          "Configuração do Projeto",
          "Pré-processamento Inicial da Base de Dados",
          "Dataset Metadata",
          "Função de Pré-processamento",
          "Pipeline de Pré-processamento",
          "Material Complementar"
        ],
        "API com Flask e TensorFlow 2.0": [
          "Configuração do Projeto",
          "Importação das Dependências",
          "Carregamento do Modelo Pré-treinado",
          "Definição da Aplicação Flask",
          "Criação da Função de Classificação",
          "Iniciando a Aplicação Flask",
          "Enviando Requisições ao Modelo"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Conhecimentos sobre Orientação a Objetos",
        "Programação básica em Python",
        "Conhecimentos sobre instalação de softwares básicos, porém, durante o curso será mostrado o processo de instalação das ferramentas utilizadas durante todo o curso",
        "Conhecimentos em Machine Learning, Redes Neurais ou Inteligência Artificial não são obrigatórios. No final do curso existem quatro anexos com aulas básicas sobre esses assuntos caso seja seu primeiro contato com a área"
      ],
      "description": "Bem-vindo(a) ao Tensorflow 2.0!\nO TensorFlow 2.0 foi lançado recentemente e introduziu muitos recursos que simplificam os processos de desenvolvimento e manutenção de modelos de aprendizagem de máquina. Do ponto de vista educacional, a nova versão está mais fácil para trabalhar e simplifica alguns conceitos complexos. Com relação a aplicações comerciais, os modelos são muito mais fáceis de entender, manter e desenvolver.\nO curso está estruturado de forma a abranger os principais tópicos da área de Deep Learning, desde a modelagem e treinamento de redes neurais até sua produção.\nNa parte 1 do curso, você aprenderá os conceitos básicos e a sintaxe do TensorFlow 2.0, principalmente algumas diferentes importantes se comparado com o TensorFlow 1.x\nNa parte 2, o foco será em Deep Learning! Você implementará vários tipos de redes neurais: redes neurais simples, redes neurais convolucionais e redes neurais recorrentes. Além disso, no final desta seção você aprenderá a utilizar a técnica de Transferência de Aprendizagem (Transfer Learning) que alcançará resultados considerados do \"estado da arte\" em uma base de dados para identificação de imagens!\nNa parte 3 você aprenderá a criar o seu próprio \"bot\" de negociação no mercado de ações utilizando Aprendizagem por Reforço, usando especificamente o algoritmo de Deep Q-Learning! No final das execuções e simulação com uma base de dados real, teremos lucros de mais de U$ 1.300 dólares!\nA parte 4 trata do TensorFlow Extended (TFX), na qual você aprenderá como trabalhar com dados e criar seus próprios fluxos de dados (pipelines) para produção. Inicialmente verificaremos se o conjunto de dados tem alguma anomalia usando a biblioteca de validação de dados do TensorFlow (TFDV). Logo após, você aprenderá como utilizar o próprio TensorFlow para aplicar pré-processamento em bases de dados usando TensorFlow Transform (TFT).\nPor fim, o foco da parte 5 será em como disponibilizar um modelo em ambiente de produção utilizando a API Flask com acesso via web e também utilizando comunicação REST por meio do TensorFlow Serving. De uma maneira muito fácil, você criará sua própria API de classificação de imagem que pode suportar milhões de solicitações por dia! Atualmente, está se tornando cada vez mais popular instalar um modelo de Deep Learning dentro de um aplicativo Android ou iOS, portanto, na próxima seção do curso você aprenderá a salvar um modelo para dispositivos móveis utilizando o TensorFlow Lite! Por fim, você também aprenderá como utilizar técnicas de treinamento distribuído para otimizar o processo de treinamento.\nEste curso é indicado para todos os níveis, ou seja, caso seja seu primeiro contato com Deep Learning e o TensorFlow, você conta com um apêndice que contém aulas básicas sobre aprendizagem de máquina e redes neurais!\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em aprender Deep Learning (aprendizagem profunda) com o TensorFlow 2.0",
        "Pessoas interessadas em redes neurais artificiais, convolucionais e recorrentes",
        "Pessoas interessadas em iniciar uma carreira em Ciência de Dados utilizando técnicas modernas de aprendizagem de máquina",
        "Empreendedores que queiram aplicar aprendizagem de máquina em projetos comerciais",
        "Analistas de dados que queiram aumentar seu conhecimento na área de deep learning (aprendizagem profunda)",
        "Empresários que desejam criar soluções eficientes para problemas reais em suas empresas",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial",
        "Desenvolvedores Python que desejam entrar na área de Deep Learning e Inteligência Artificial",
        "Engenheiros que trabalham em tecnologia e automação",
        "Qualquer pessoa interessada em Inteligência Artificial"
      ]
    },
    {
      "title": "Machine Learning Bootcamp w języku Python cz.I - od A do Z",
      "url": "https://www.udemy.com/course/machine-learning-bootcamp-w-jezyku-python/",
      "bio": "Odkryj potęgę Machine Learning: Kompletny Bootcamp - od podstawowych koncepcji do zaawansowanych algorytmów!",
      "objectives": [
        "wprowadzenie do uczenia maszynowego",
        "biblioteki Python dla uczenia maszynowego",
        "przepływ pracy przy tworzeniu modeli uczenia maszynowego",
        "przetwarzanie i przygotowanie danych do modelu",
        "zbiór treningowy, walidacyjny i testowy",
        "problemy regresji i klasyfikacji",
        "regresja liniowa, wielomianowa i drzewa decyzyjnego",
        "regresja logistyczna, algorytm K-najbliższych sąsiadów, drzewo decyzyjne, las losowy, SVM, Naive Bayes",
        "ocena i optymalizacja modeli - walidacja krzyżowa, przeszukiwanie siatki (grid search)",
        "niedouczenie i przeuczenie",
        "3 x case studies"
      ],
      "course_content": {},
      "requirements": [
        "Ukończone kursy ze ścieżki Python Developer na tym koncie instruktorskim",
        "Ukończone kursy ze ścieżki Data Scientist na tym koncie instruktorskim",
        "Podstawy matematyki",
        "Motywacja do nauki i analityczne myślenie"
      ],
      "description": "Czy chcesz opanować uczenie maszynowe w praktyce, wykorzystując język Python i popularne biblioteki takie jak scikit-learn, pandas i matplotlib? Ten kurs to kompleksowe wprowadzenie do nadzorowanego uczenia maszynowego – od podstaw po bardziej zaawansowane techniki.\nTen kurs został zaprojektowany z myślą o osobach początkujących i średniozaawansowanych, które chcą zdobyć solidne podstawy w uczeniu maszynowym (machine learning) oraz zrozumieć, jak budować modele predykcyjne na prawdziwych danych. Przejdziesz krok po kroku przez cały proces tworzenia modelu: od przygotowania danych, przez eksploracyjną analizę danych, wybór modelu, trenowanie, walidację, aż po ocenę jego skuteczności i interpretację wyników.\nW trakcie kursu nauczysz się między innymi:\nCzym jest uczenie nadzorowane i jakie są jego typy (regresja i klasyfikacja)\nJak działają popularne algorytmy: regresja liniowa, regresja logistyczna, drzewa decyzyjne, Random Forest, KNN, SVM\nJak korzystać z biblioteki scikit-learn do implementacji modeli\nJak przeprowadzać inżynierię cech i przetwarzanie danych\nJak unikać przeuczenia (overfittingu) i jak oceniać skuteczność modelu\nDzięki wielu ćwiczeniom praktycznym oraz projektom opartym na realnych zbiorach danych, zdobędziesz nie tylko teoretyczną wiedzę, ale przede wszystkim praktyczne umiejętności potrzebne na rynku pracy. Dołącz do kursu i rozpocznij swoją przygodę z Machine Learning już dziś!\n\n\nUczenie nadzorowane – Gdy dane uczą z pomocą etykiet\nUczenie nadzorowane to jedna z głównych metod uczenia maszynowego, w której model uczy się na podstawie danych wejściowych oraz odpowiadających im etykiet (czyli oczekiwanych wyników). Celem jest nauczenie modelu przewidywania lub klasyfikacji nowych, nieznanych danych na podstawie wzorców wykrytych w danych treningowych. Technika ta znajduje zastosowanie między innymi w rozpoznawaniu obrazów, analizie tekstu, prognozowaniu czy wykrywaniu oszustw.",
      "target_audience": [
        "Początkujący Data Scientist / Machine Learning Engineer",
        "Analitycy danych chcący wejść w świat Machine Learning",
        "Programiści Python, którzy chcą zgłębić tematykę uczenia maszynowego",
        "Specjaliści IT / Inżynierowie systemowi / DevOps",
        "Osoby przygotowujące się do certyfikacji z zakresu Machine Learning lub Data Science",
        "Uczestnicy rekrutacji na stanowiska związane z Data Science / ML"
      ]
    },
    {
      "title": "Criação de Dashboards com Looker Studio",
      "url": "https://www.udemy.com/course/criacao-de-dashboards-com-google-data-studio/",
      "bio": "Aprenda a criar suas visualizações de dados elegantes com Looker Studio",
      "objectives": [
        "Conhecer como funciona uma plataforma de construção de dashboards",
        "Entender e criar gráficos oferecido pelo Looker Studio",
        "Conectar o Looker Studio a bancos de dados do BigQuery",
        "Aprender a usar o resultado de uma consulta no BigQuery diretamente no Looker",
        "Criar gráficos baseados em Linguagem SQL",
        "Criar gráficos sem linguagem SQL",
        "Configurar período de tempo para atualização de dados",
        "Criar filtros de dados",
        "Mudar o estilo de gráficos e páginas para deixar seu relatório perfeito!",
        "Conectar o Looker Studio a planilhas (Google Sheets)",
        "Criar gráficos a partir de planilhas"
      ],
      "course_content": {
        "Apresentação do Curso": [
          "Apresentação do Curso",
          "Dinâmica do Curso",
          "Estrutura do Curso: Módulos",
          "Ferramentas, Dicas e Contato"
        ],
        "Teoria (bônus)": [
          "Gráfico",
          "Dashboard",
          "Relatório",
          "Tipos de Relatórios",
          "Principais Gráficos",
          "Métricas e Dimensões"
        ],
        "Looker Studio": [
          "Definição",
          "Criando conta no Looker Studio",
          "Visão Geral"
        ],
        "Adição de Dados": [
          "Tipos de fontes",
          "Conectando ao Google Sheets",
          "Conectando ao Google Analytics (GA4)",
          "Cadastro no BigQuery",
          "Interface do BigQuery",
          "Conectando a uma tabela do BigQuery sem SQL",
          "Conectando ao BigQuery com uma consulta SQL personalizada",
          "Edição de campos",
          "Atualização dos dados",
          "Credenciais dos dados"
        ],
        "Introdução a SQL (bônus)": [
          "Comandos de Seleção (teoria)",
          "Comandos de Seleção (prática)",
          "Limit e Distinct (prática)",
          "Operadores (teoria)",
          "Operadores (prática)",
          "Apelidos (teoria)",
          "Apelidos (prática)",
          "Comandos de Restrição (teoria)",
          "Comandos de Restrição (prática)",
          "Comandos Condicionais (teoria)",
          "Comandos Condicionais (prática)",
          "Comandos de Agrupamento e Ordenação (teoria)",
          "Comandos de Agrupamento e Ordenação (prática)",
          "Relacionamento de Tabelas (teoria)",
          "Relacionamento de Tabelas (prática)",
          "Exercícios Propostos",
          "Exercícios Resolvidos"
        ],
        "SQL: Funções de Agregação (bônus)": [
          "Definição: o que são Funções de Agregação?",
          "Principais Funções (teoria)",
          "Parte I (prática)",
          "Parte II (prática)",
          "Exercícios Propostos",
          "Exercícios Resolvidos"
        ],
        "Criação de Visualizações": [
          "Tipos de Visualizações",
          "Adicionando Gráficos e Tabelas",
          "Customizando Visualizações",
          "Criação de Filtros",
          "Criação de Campos Calculados",
          "Criação de Parâmetros"
        ],
        "Combinação de Dados (bônus)": [
          "INNER JOIN ou JOIN",
          "LEFT JOIN",
          "RIGHT JOIN",
          "FULL JOIN",
          "CROSS JOIN"
        ],
        "Controles (bônus)": [
          "Lista Suspensa",
          "Lista de Tamanho Fixo",
          "Caixa de Entrada",
          "Filtro Avançado",
          "Controle Deslizante",
          "Caixa de Seleção",
          "Controle de Período",
          "Controle de Dados"
        ],
        "Outros tópicos (bônus)": [
          "Baixando em PDF",
          "Compartilhamento por link, público & email",
          "Utilizando o MySQL como fonte de dados",
          "Cores dos valores de dimensão",
          "Página",
          "Organização de gráficos e elementos",
          "Adição de URL, Imagem, Texto, Linha & Forma",
          "Aprenda a EXPLORAR resultados de consultas do BigQuery!",
          "Aprenda a CRIAR um GeoCharts Map do início ao fim!",
          "Aprenda a CRIAR um gráfico de corrida de barras!",
          "Aprenda a adicionar as cores da sua empresa como tema do relatório!"
        ]
      },
      "requirements": [
        "Você não precisa ser da área de exatas para realizar esse curso",
        "Vontade de aprender",
        "Força de Vontade"
      ],
      "description": "ATUALIZADO EM 2024\nPLATAFORMA 100% GRATUITA DA GOOGLE\n\n\nSOBRE O CURSO\n\n\nEsse NÃO é mais um curso complicado, sem explicações claras ou exemplos práticos para o mercado de trabalho.\n\n\nEsse curso É um jeito simples de você aprender a criar suas visualizações de dados de forma rápida e elegante, dos primeiros conceitos até os mais avançados, com uma ferramenta gratuita.\n\n\nVocê não precisa obrigatoriamente ter experiência na área de Dados ou exatas para acompanhar todo o curso, que foi pensado com didática simples e módulos progressivos para você avançar com segurança! E para auxiliá-lo na evolução ao longo do curso, com projeto para fixar o conhecimento.\n\n\nComece hoje a explorar a área de Business Intelligence e Ciência de Dados com tranquilidade. Mesmo que já esteja na área, essa é a oportunidade para você melhorar suas habilidades com o conhecimento de mais uma ferramenta.\n\n\nCada vez mais o mercado de trabalho exige de vários profissionais o conhecimento sobre criação de gráficos e dashboards! Aprenda a construí-los e utilizar suas informações para melhor tomada de decisão.\n\n\nLEMBRE-SE: A área de dados é a MAIS QUENTE do mercado atualmente. Os salários podem chegar a 22 mil reais! Então investir em seu desenvolvimento é a melhor escolha para sua carreira de sucesso. Fonte: UOL\n\n\nAbaixo a trilha ideal em direção ao sucesso na área de dados:\nSQL para Análise de Dados: do Básico ao Avançado (2024).\nCriação com Dashboards com Looker Studio (este curso que você está, mas não tem problema começar por ele).\nPython: Manipulação de Dados com Linguagem Pandas.\nMachine Learning: Clusterização com Linguagem Python.\nMachine Learning: Classificação com Linguagem Python.\nMachine Learning: Regressão com Linguagem Python.\n\n\nSOBRE O INSTRUTOR\nMe chamo Caio Avelino, e o conhecimento que vou dividir com você nesse curso foi adquirido, principalmente, com minha experiência no mercado de trabalho. Atuo nas áreas de Business Intelligence, Ciência de Dados e Inteligência Artificial há anos e tive a oportunidade de desenvolver minhas habilidades em diversas startups.\n\n\nGaranto que você sairá deste curso pronto para construir qualquer dashboard no Looker Studio, sem dificuldades. Estarei online e sempre à disposição para esclarecer dúvidas e melhorar sua experiência profissional.\n\n\nAté mais!",
      "target_audience": [
        "Iniciantes e Curiosos sobre Business Intelligence",
        "Alunos de Ciência de Dados que gostariam de aprender Looker Studio",
        "Funcionários de uma empresa, de qualquer área, que gostariam de aprender a construir dashboards incríveis",
        "Analistas de BI com interesse em utilizar SQL para construção de análises e dashboards personalizados, sem as limitações dos Softwares que permitem apenas arrastar e soltar gráficos",
        "Qualquer pessoa, de qualquer área que deseja entrar no Mundo de Dados",
        "Profissionais de Marketing que desejam avançar um degrau na carreira"
      ]
    },
    {
      "title": "Machine Learning e Data Science com Python",
      "url": "https://www.udemy.com/course/machine-learning-e-data-science-com-python/",
      "bio": "Nesse curso você irá aprender sobre Machine Learning e Data Science com Python!",
      "objectives": [
        "Ter uma base sobre machine learning bem como sobre análise de dados.",
        "Utilizar bibliotecas tais como NumPy, Pandas, scikit-learn e Matplotlib.",
        "Utilizar Python para fazer análise de dados.",
        "Utilizar Python para implementar e resolver problemas utilizando Machine Learning.",
        "Trabalhar com dataframes."
      ],
      "course_content": {
        "Apresentação": [
          "Seja bem-vindo(a)! - Instrutor Marcos Castro",
          "Seja bem vindo(a)! - Instrutor Gileno Filho",
          "Fórum do curso",
          "Grupo do curso"
        ],
        "Introdução a programação com Python": [
          "Linguagem Python",
          "Instalação no Windows",
          "Instalação no Windows (com virtualenv)",
          "Instalação no Linux",
          "Instalação no Linux (com virtualenv)",
          "Instalação no Mac (com virtualenv)",
          "Utilizando o IDLE",
          "Conhecendo o Jupyter Notebook",
          "Variáveis",
          "Operadores",
          "Variáveis string",
          "Entrada de dados",
          "Condições",
          "Repetições",
          "Listas",
          "Estrutura de repetição for",
          "Tuplas",
          "Conjuntos",
          "Dicionários",
          "Criando funções",
          "Criando módulos",
          "Arquivos",
          "Orientação a objetos",
          "Programação Funcional"
        ],
        "Um pouco mais de Orientação a Objetos": [
          "Jogo do Robô 1",
          "Jogo do Robô 2",
          "Jogo do Robô 3",
          "Jogo do Robô 4",
          "Jogo do Robô 5",
          "Jogo do Robô 6"
        ],
        "Introdução a Machine Learning": [
          "Introdução a Inteligência Computacional",
          "Machine Learning - Motivação",
          "Conjunto de Dados",
          "Dados",
          "Tipos de atributos",
          "Escala de atributos",
          "Tipos de aprendizado",
          "Aprendizado Supervisionado",
          "Aprendizado Não-Supervisionado",
          "Técnicas de aprendizado",
          "Obtendo datasets"
        ],
        "NumPy": [
          "Conhecendo NumPy",
          "NumPy array versus Python list",
          "Eficiência Numpy",
          "Slicing Arrays",
          "Matrizes com listas",
          "Criando matrizes com NumPy",
          "Operações com matrizes",
          "Visualizando os dados com Matplotlib",
          "Visualizando dados novamente",
          "Inserindo elementos no array",
          "Anexar valores ao final de um array",
          "Deletando elementos do array",
          "Repetindo elementos de um array",
          "Repetindo um array com tile",
          "Dividindo um array",
          "Criando arrays de zeros e uns",
          "Criando uma matriz identidade",
          "Indexação booleana",
          "Carregando dados do arquivo com NumPy",
          "Juntando uma sequência de arrays",
          "Embaralhando uma sequência",
          "Números complexos com NumPy",
          "Gerando arrays com linspace",
          "Encontrando elementos únicos de um array",
          "Lendo arquivos CSV com NumPy",
          "Analisando o Iris DataSet com NumPy"
        ],
        "Pandas": [
          "Pandas Series",
          "Pandas DataFrame",
          "Pandas Index",
          "Carregando Dataset's com pydataset",
          "Carregando Dataset's com db.py",
          "Carregando Dataset's em CSV / Excel",
          "Realizando Filtro / Seleção em um DataFrame",
          "Trabalhando com Dados Categóricos",
          "Resolvendo o problemas de dados perdidos",
          "Operações de aggregate e grouping no DataFrame",
          "Operações de merge (join) no DataFrame",
          "Trabalhando com Séries Temporais",
          "Criando pivot tables",
          "Visualização 01 - Matplotlib",
          "Visualização 02 - Seaborn",
          "Visualização 03 - Visualização da Informação",
          "Visualização 04 - Histograma e Gráfico de Pizza",
          "Visualização 05 - Gráfico de Dispersão",
          "Visualização 06 - Visualizando em Mapas",
          "Visualização 07 - Customizando Eixos e Labels de um Gráfico",
          "Visualização 08 - Gráficos de Séries Temporais"
        ],
        "Regressão Linear": [
          "O que é regressão (estatística)?",
          "Como funciona a regressão linear simples",
          "Entendendo o Método dos Mínimos Quadrados (OLS)"
        ],
        "kNN - Classificação": [
          "Conhecendo o kNN",
          "Funcionamento do kNN",
          "Calculando a distância euclidiana",
          "Distância Euclidiana e Manhattan",
          "Determinando a classe do novo exemplo",
          "Vantagens e desvantagens",
          "Escolha do parâmetro K",
          "Escolha do dataset",
          "Implementação do kNN - Parte 1",
          "Implementação do kNN - Parte 2",
          "Implementação do kNN - Parte 3",
          "Implementação do kNN - Parte 4",
          "Implementação do kNN com sklearn",
          "Implementação do kNN com Numpy e sklearn",
          "Utilizando o model_selection",
          "Utilizando o score",
          "kNN com pandas e sklearn",
          "kNN com sklearn - Dataset Iris"
        ],
        "kNN - Regressão": [
          "Conhecendo o kNN para Regressão",
          "Implementando o kNN Regressão",
          "kNN Regressão com sklearn",
          "Erro quadrático médio",
          "kNN Regressão - Dataset Diabetes"
        ],
        "Redes Neurais Artificiais": [
          "O que são redes neurais artificiais?",
          "Neurônio artificial",
          "Funções de ativação",
          "Conhecendo a Rede Perceptron",
          "Processo de treinamento da Perceptron",
          "Algoritmo de treinamento da Perceptron",
          "Fase de operação da Perceptron",
          "Implementação da Perceptron - Parte 1",
          "Implementação da Perceptron - Parte 2",
          "Implementação da Perceptron - Parte 3",
          "Redes Neurais com PyBrain - Instalação",
          "Redes Neurais com PyBrain - Implementação",
          "Redes Neurais com PyBrain - Discutindo os parâmetros",
          "Redes Neurais com PyBrain - Iris Dataset",
          "Adicionando camadas escondidas com PyBrain",
          "PyBrain - Iris DataSet novamente - Parte 1",
          "PyBrain - Iris DataSet novamente - Parte 2",
          "PyBrain - Iris DataSet novamente - Parte 3",
          "Redes Neurais com sklearn - Parte 1",
          "Redes Neurais com sklearn - Parte 2",
          "Redes Neurais com sklearn - Parte 3"
        ]
      },
      "requirements": [
        "Não é necessário conhecimento prévio, embora seja recomendado uma noção de lógica de programação e conceitos matemáticos básicos."
      ],
      "description": "Atenção: nesse curso ainda estão sendo adicionadas aulas!\n\nMachine Learning (aprendizado de máquina) é uma área que representa uma evolução nos campos de Ciência da Computação, Análise de Dados, Engenharia de Software e Inteligência Artificial.\nNesse curso você aprenderá Machine Learning com a linguagem de Programação Python. Não é preciso ter conhecimento em Python, pois o curso possui uma seção para quem é iniciante na linguagem.\nAlém disso, o curso trata das principais bibliotecas para análise de dados e utilização de técnicas de aprendizado de máquina tais como NumPy, Pandas, scikit-learn e Matplotlib. Também serão explicadas técnicas de aprendizado de máquina para facilitar o entendimento e utilização das mesmas nos exemplos práticos.\nTodo o curso é 100% em vídeo-aulas, tem direito a certificado e acesso vitalício!\nOs instrutores Marcos Castro (mais de 12 mil alunos na Udemy) e Gileno Filho (mais de 10 mil alunos na Udemy) irão estar disponíveis para tirar quaisquer dúvidas através do fórum do curso.\nO que está esperando? Machine Learning é utilizado por empresas ao redor do mundo para facilitar a análise de dados. Vivemos a era do Big Data, o volume de dados produzidos é gigantesco e precisamos de técnicas para automatizar e nos ajudar a encontrar algum padrão nesses dados de forma que possamos resolver os problemas.\nAguardamos você no curso!",
      "target_audience": [
        "Todos que quiserem aprender mais sobre machine learning (aprendizado de máquina).",
        "Todos que quiserem aprender mais sobre análise de dados.",
        "Todos que quiserem aprender mais sobre técnicas de aprendizado.",
        "Todos que quiserem aprender mais sobre bibliotecas tais como Pandas, NumPy, scikit-learn e Matplotlib.",
        "Todos que querem aprender sobre Data Science."
      ]
    },
    {
      "title": "Breast Cancer Detection with AI - Using Logistic Regression",
      "url": "https://www.udemy.com/course/breast-cancer-detection-with-ai-using-logistic-regression/",
      "bio": "Build machine learning model for breast cancer prediction. Learn logistic regression, preprocessing, modeling & more",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Dataset And Coding File": [
          "Dataset File For This Course",
          "Coding File For This Course"
        ],
        "Setup The Enviroment And Prerequisite": [
          "Installing Anaconda 3 & Jupyter Notebook",
          "Method To Install Library Files",
          "What Is Kaggle?",
          "Download The Dataset"
        ],
        "Add Markdowns And Setup The File": [
          "How To Add Markdowns In File",
          "Setup Coding File"
        ],
        "Import Library Files": [
          "Importing Library Files Pandas & Numpy"
        ],
        "How To Load The Dataset File.?": [
          "Load The Dataset Csv File"
        ],
        "Dataset Overview And statistical Summary": [
          "Dataset Overview And Information",
          "Statistical Summary Of Dataset"
        ],
        "Data Preprocessing": [
          "Check Null Values In The Dataset",
          "Check Duplicate Rows In the Dataset"
        ],
        "Expolatory Data Analysis & Visulization": [
          "Install Matplotlib & Seaborn",
          "Discussing About Features And Labels",
          "Count Plot Visulization",
          "Histogram Visulization Of Numerical Feature"
        ],
        "Modeling": [
          "Install Scikit-Learn Library File",
          "Train_Test_Split The Dataset",
          "Fitting Model To Dataset",
          "Checking Prediction Of The Model"
        ]
      },
      "requirements": [
        "You should know the basics of python",
        "Nothing else, you and your time"
      ],
      "description": "Advancements in machine learning have significantly impacted the healthcare industry, enabling more accurate and efficient diagnostic models. This course provides a comprehensive guide to building a breast cancer detection model using logistic regression, one of the most widely used classification techniques in medical diagnostics.\n\n\nThrough a structured, hands-on approach, you will learn how to preprocess medical data, develop a predictive model, and evaluate its effectiveness. By the end of this course, you will have a solid understanding of logistic regression and its role in machine learning for healthcare applications.\n\n\nWhat You Will Learn:\nUnderstand the fundamentals of logistic regression and its application in medical diagnosis\nPerform data preprocessing, including handling missing values and preparing datasets\nTrain and optimize a machine learning model for breast cancer detection\nImplement logistic regression using Python and Scikit-Learn\nAnalyze model performance and interpret results effectively\nExplore the role of AI and machine learning in medical diagnostics\n\n\nCourse Highlights:\nStep-by-step guidance suitable for beginners and professionals\nReal-world breast cancer dataset for hands-on learning\nBest practices for improving logistic regression model performance\nInsights into the impact of AI and machine learning in healthcare\n\n\nBy the end of this course, you will have the knowledge and practical experience to develop a logistic regression-based breast cancer detection model and apply machine learning techniques to real-world medical data.\n\n\nEnroll now to gain hands-on experience in AI-driven breast cancer detection.",
      "target_audience": [
        "Anyone who want to learn machine learning",
        "Anyone who is intrested in Logistic Regression",
        "Anyone who wants to start journey in Machine Learning",
        "Anyone who wants to make amazing and practical machine learning models"
      ]
    },
    {
      "title": "Inteligência Artificial e Machine Learning: O Guia Completo",
      "url": "https://www.udemy.com/course/inteligencia-artificial-machine-learning-guia-completo/",
      "bio": "Quer estudar IA e não sabe por onde começar? Aqui você aprende tudo o que precisa saber sobre a área na teoria e prática",
      "objectives": [
        "A base teórica e prática dos principais algoritmos de Inteligência Artificial",
        "Implementar algoritmos de Inteligência Artificial do zero e utilizando bibliotecas",
        "Aprender na teoria e na prática sobre os algoritmos de Machine Learning para classificação, regressão, regras de associação e agrupamento",
        "Aprender Machine Learning sem saber uma linha de programação sequer",
        "Utilizar a ferramenta visual Orange para criar, analisar e testar os algoritmos",
        "Utilizar a linguagem de programação Python para criar algoritmos de Inteligência Artificial",
        "Aprender o básico da programação em Python",
        "Utilizar os algoritmos de busca gulosa e A* (A Estrela) encontrar a menor rota entre cidades",
        "Implementar algoritmos de otimização para problemas de minimização e maximização",
        "Implementar uma IA para prever o valor da gorjeta a ser dada em um restaurante, utilizando lógica difusa (fuzzy)",
        "Utilizar técnicas de exploração de dados aplicada em uma base de dados da doença COVID-19",
        "Criar um agente com aprendizagem por reforço para controlar os passageiros de um táxi",
        "Utilizar redes neurais artificiais e redes neurais recorrentes para classificar as imagens dos personagens Homer e Bart, do desenho dos Simpsons",
        "Aprender técnicas de processamento de linguagem natural e crie um classificador de sentimentos",
        "Detectar e reconhecer faces com usando técnicas de visão computacional",
        "Rastrear objetos em vídeo utilizando visão computacional",
        "Criar sistemas multiagente para simular uma comunicação entre agentes"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Recursos para download",
          "Terminologia"
        ],
        "----- Parte 1 - Algoritmos de busca -----": [
          "Introdução",
          "Teoria sobre buscas",
          "Heurísticas",
          "Vetores ordenados",
          "Vetor ordenado - teoria",
          "Vetor ordenado - implementação",
          "Criação do mapa das cidades",
          "Busca gulosa - teoria",
          "Busca em gulosa - implementação",
          "Busca gulosa - debug passo a passo",
          "Busca A* (A Estrela) - teoria",
          "Busca A* (A Estrela) - implementação",
          "Busca A* (A Estrela) - debug passo a passo",
          "EXERCÍCIO",
          "Solução para o exercício"
        ],
        "----- Parte 2 - Algoritmos de otimização -----": [
          "Introdução à algoritmos de otimização",
          "Estudo de caso dos voos",
          "Representação do problema - implementação",
          "Impressão da solução - implementação",
          "Função de custo (fitness) - implementação",
          "Hill climb - teoria",
          "Hill climb - implementação",
          "Simulated annealing - teoria",
          "Simulated annealing - implementação",
          "Algoritmo genético - teoria",
          "Algoritmo genético - implementação",
          "EXERCÍCIO",
          "Solução para o exercício"
        ],
        "----- Parte 3 - Lógica difusa (fuzzy) -----": [
          "Introdução",
          "Teoria",
          "Implementação 1",
          "Implementação 2",
          "Implementação 3",
          "EXERCÍCIO",
          "Solução para o exercício"
        ],
        "----- Parte 4 - Machine learning -----": [
          "Introdução",
          "Introdução à Machine Learning e Data Science"
        ],
        "Classificação": [
          "O que é classificação",
          "Naïve bayes",
          "Naïve bayes com Orange",
          "Árvore de decisão",
          "Árvore de decisão com Orange",
          "Aprendizagem por regras",
          "Regras com Orange",
          "Aprendizagem baseada em instâncias - kNN",
          "kNN com Orange",
          "Aprendizagem com máquinas de vetores de suporte (SVM)",
          "SVM com Orange",
          "Regressão logística",
          "Regressão logística com Orange",
          "Validação cruzada",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Classificação de imagens com Orange"
        ],
        "Regressão": [
          "O que é regressão",
          "Regressão linear",
          "Regressão linear com Orange",
          "EXERCÍCIO",
          "Solução para o exercício"
        ],
        "Agrupamento": [
          "O que é agrupamento",
          "Algoritmo k-means",
          "K-means com Orange",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Agrupamento de imagens com Orange"
        ],
        "Associação": [
          "O que é associação",
          "Algoritmo Apriori",
          "Apriori com Orange",
          "EXERCÍCIO",
          "Solução para o exercício"
        ],
        "Tópicos complementares": [
          "Pré-processamento: valores faltantes e normalização",
          "Pré-processamento: discretização",
          "Seleção de atributos",
          "Redução de dimensionalidade com PCA",
          "PCA e agrupamento",
          "Detecção de outliers",
          "Séries temporais 1",
          "Séries temporais 2",
          "Séries temporais 3"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e estrutura de repetição",
        "Não é necessário conhecer a linguagem Python, pois no final do curso há um anexo com aulas básicas caso seja seu primeiro contato com ela"
      ],
      "description": "Atualmente, a área de Inteligência Artificial e Machine Learning (Aprendizagem de Máquina) estão sendo considerados os campos de trabalho mais relevantes da Tecnologia da Informação, sendo responsáveis pela utilização de algoritmos inteligentes para a construção de software e hardware que simulem a capacidade humana. O mercado de trabalho de Machine Learning em várias partes do mundo está em grande ascensão e a tendência é que este tipo de profissional seja cada vez mais requisitado! Inclusive alguns estudos apontam que o conhecimento dessa área será em breve um pré-requisito para os profissionais de Tecnologia da Informação!\nPara levar você até essa área, neste curso você terá uma visão teórica e principalmente prática sobre as principais e mais modernas técnicas de Inteligência Artificial! Este curso é considerado um guia completo pelo fato de apresentar desde conceitos mais básicos até técnicas mais modernas e avançadas, de modo que ao final você terá todas as ferramentas necessárias para construir soluções de Inteligência Artificial que podem ser aplicadas em problemas do dia-a-dia das empresas! O conteúdo está dividido em nove partes: algoritmos de busca, algoritmos de otimização, lógica difusa (fuzzy), machine learning, redes neurais (deep learning), processamento de linguagem natural, visão computacional, sistemas multiagente e também outras áreas de IA, como sistemas especialistas, GPS (general problem solver), redes bayesianas e raciocínio baseado em casos! Você aprenderá a teoria básica sobre cada um desses assuntos, bem como implementará exemplos práticos passo a passo. Veja abaixo alguns dos projetos/tópicos que serão desenvolvidos:\nBusca de rotas com melhores caminhos em mapas de cidades (busca gulosa e busca A*)\nEscolha das passagens áreas mais baratas, em um cenário de compra de passagens em grupo e maximização de lucros no carregamento de produtos - algoritmos de otimização: hill climb (subida da encosta), simulated annealing (têmpera simulada) e algoritmo genético\nPrevisão do valor que você daria de gorjeta em um restaurante (lógica fuzzy)\nClassificação utilizando os algoritmos naïve bayes, árvore de decisão, regras, k-NN, regressão logística e redes neurais\nPrevisão do preço de casas utilizando regressão linear\nAgrupamento de dados bancários utilizando o algoritmo k-means\nGeração de regras de associação com o algoritmo apriori\nPré-processamento, redução de dimensionalidade e detecção de outliers em bases de dados\nPrevisão do preço de ações com séries temporais\nVisualização e exploração de dados na base de dados da doença COVID-19\nConstrução de um agente para controlar um táxi para transporte de passageiros com aprendizagem por reforço\nClassificação de imagens de gatos e cachorros com redes neurais convolucionais\nClassificação das imagens do Homer e Bart, do desenho dos Simpsons também utilizando redes neurais convolucionais\nMarcação POS (part-of-speech), lematização, stemização, nuvem de palavras (wordcloud) e extração de entidades nomeadas utilizando técnicas de processamento de linguagem natural\nCriação de um classificador de sentimentos em Português\nDetecção de faces e reconhecimento facial em imagens\nRastreamento de objetos de vídeos\nSimulação de um sistema multiagente para comunicação entre agentes utilizando o protocolo FIPA-REQUEST\nCada tipo de problema requer técnicas diferentes para sua solução, portanto, conhecendo todas as áreas de IA você saberá que técnicas utilizar nos mais variados tipos de cenários!\nDurante o curso, vamos utilizar a linguagem de programação Python e também a ferramenta gráfica Orange! Caso você não conheça Python, no final do curso você tem acesso a mais de 5 horas de vídeo com exercícios com o básico sobre essa linguagem de programação! Este é o curso ideal caso seja seu primeiro contato com Inteligência Artificial, pois você aprenderá na teoria e na prática todos os tópicos necessários! Caso você seja de nível mais avançado nessa área, pode utilizar esse curso como uma referência e para aprender novas área e revisar os conceitos",
      "target_audience": [
        "Pessoas interessadas em iniciar seus estudos em Inteligência Artificial, Machine Learning, Ciência de Dados ou Deep Learning",
        "Pessoas que querem estudar Inteligência Artificial, porém, não sabem por onde começar",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial",
        "Qualquer pessoa interessada em Inteligência Artificial",
        "Empreendedores que queiram aplicar aprendizagem de máquina em projetos comerciais",
        "Empresários que desejam criar soluções eficientes para problemas reais em suas empresas"
      ]
    },
    {
      "title": "Essential Machine Learning Algorithms for Data Scientists",
      "url": "https://www.udemy.com/course/machine-learning-algorithms-for-data-scientists/",
      "bio": "Master essential machine learning algorithms and elevate your data science skills",
      "objectives": [],
      "course_content": {
        "Introduction to ML": [
          "Introduction",
          "Types of Machine Learning",
          "Supervised Vs Unsupervised Learning",
          "Summary"
        ],
        "Linear Regression": [
          "Linear Regression",
          "Evaluating Linear Regression",
          "Demo: Linear Regression",
          "Summary"
        ],
        "Logistic Regression": [
          "Logistic Regression",
          "Evaluating Logistic Regression",
          "Training & Prediction with Linear Regression",
          "Training & Prediction with Linear Regression",
          "Summary"
        ],
        "Decision Trees": [
          "Decision Trees",
          "Handling Missing Values in Decision Trees",
          "Demo: Decision Trees",
          "Pros and Cons",
          "Applications of Decision Trees",
          "Summary"
        ],
        "Random Forests": [
          "Random Forests",
          "Tuning hyperparameters",
          "Demo: Random Forests",
          "Feature selection in random forests",
          "Limitations of random forests",
          "Summary"
        ],
        "Support Vector Machines (SVM)": [
          "Support Vector Machines (SVM)",
          "Demo: SVM",
          "Handling Imbalanced Datasets with SVM",
          "Evaluating SVM Performance",
          "Summary"
        ],
        "Naive Bayes": [
          "Naive Bayes",
          "Applications of Naive Bayes",
          "Training Naive Bayes Classifier",
          "Pros and Cons",
          "Summary"
        ],
        "K-Nearest Neighbors (KNN)": [
          "K-Nearest Neighbors (KNN)",
          "Distance metrics in KNN",
          "Demo: KNN",
          "Summary"
        ],
        "Clustering Algoritims": [
          "K-means clustering",
          "Demo: K-means clustering",
          "Hierarchical clustering",
          "Demo: Hierarchical Clustering",
          "Evaluating clustering results",
          "Applications of clustering",
          "Summary"
        ]
      },
      "requirements": [
        "Basic understanding of Python programming language and its syntax.",
        "Familiarity with fundamental concepts of statistics and linear algebra.",
        "Prior exposure to data manipulation and analysis using libraries like NumPy, pandas, and matplotlib.",
        "Access to a computer with internet connectivity for accessing course materials and completing assignments."
      ],
      "description": "Are you ready to unlock the power of machine learning and elevate your data science skills? Welcome to \"Machine Learning Algorithms for Data Scientists,\" a comprehensive course designed to equip you with the knowledge and practical skills needed to excel in the field of data science.\nIntroduction to ML In this introductory section, we'll lay the foundation for your journey into machine learning. You'll gain an understanding of the types of machine learning, including supervised and unsupervised learning, setting the stage for deeper exploration.\nLinear Regression Delve into linear regression, a fundamental algorithm for predictive modeling. Learn how to evaluate linear regression models and witness its application through a hands-on demonstration. By the end of this module, you'll grasp the intricacies of linear regression and its significance in data science.\nLogistic Regression Explore logistic regression, a powerful tool for binary classification tasks. From model training to prediction, you'll discover the nuances of logistic regression and its regularization techniques. Get ready to harness the predictive power of logistic regression for various real-world applications.\nDecision Trees Uncover the versatility of decision trees in data analysis. Learn how to handle missing data, explore decision tree algorithms through practical demonstrations, and evaluate their pros and cons. Gain insights into decision tree applications across diverse domains.\nRandom Forests Dive into the world of ensemble learning with random forests. Master hyperparameter tuning, witness the feature selection capabilities of random forests, and understand their limitations. By the end of this module, you'll be equipped to leverage random forests for robust predictive modeling.\nSupport Vector Machines (SVM) Unlock the potential of support vector machines for classification and regression tasks. Through hands-on demos, you'll learn to handle imbalanced datasets, evaluate SVM performance, and harness SVM's capabilities for data-driven insights.\nNaive Bayes Discover the simplicity and effectiveness of Naive Bayes classifiers. Explore their applications, learn the essentials of training a Naive Bayes model, and weigh their pros and cons for different use cases.\nK-Nearest Neighbors (KNN) Delve into the intuitive approach of K-Nearest Neighbors for classification and regression. Understand distance metrics, witness KNN in action through a practical demonstration, and grasp its significance in pattern recognition tasks.\nClustering Algorithms Embark on a journey into clustering algorithms, including K-means and hierarchical clustering. Learn how to evaluate clustering results, explore real-world applications, and understand the role of clustering in unsupervised learning.\nEnroll now in \"Machine Learning Algorithms for Data Scientists\" and unlock the keys to mastering essential machine learning techniques. Whether you're a beginner or seasoned professional, this course will empower you to tackle real-world data science challenges with confidence. Let's embark on this transformative learning journey together!",
      "target_audience": [
        "Data science enthusiasts eager to dive into machine learning and expand their knowledge.",
        "Analysts seeking to apply machine learning techniques to extract insights from data.",
        "Professionals transitioning into data science roles or looking to upskill in machine learning.",
        "Students and researchers interested in understanding the theory and practical implementation of machine learning algorithms."
      ]
    },
    {
      "title": "ディープラーニング : Pythonでゼロから構築し学ぶ人工知能（AI）と深層学習の原理",
      "url": "https://www.udemy.com/course/deepzero/",
      "bio": "機械学習（マシンラーニング）の中でも特に注目を集めているDeep Learningを学び、TensorFlowやChainerなどのフレームワークを使わずに、畳み込みニューラルネットワーク（CNN）までゼロから構築できるようになりましょう。",
      "objectives": [
        "ディープラーニングの原理を理解し、ゼロから実装できるようになります。",
        "ディープラーニングのコードの読み書きができるようになります。",
        "バックプロパゲーション（誤差逆伝播法）によりニューラルネットワークが学習する仕組みを理解できます。",
        "畳み込みニューラルネットワーク（CNN）の仕組みを理解できます。",
        "数学やプログラミングをディプラーニングで活用する具体的な方法を学べます。",
        "TensorFlow、Chainerなどのフレームワークの学習コストが下がります。"
      ],
      "course_content": {
        "イントロダクション": [
          "コースの概要",
          "ディープラーニングの概要"
        ],
        "学習の準備": [
          "Anacondaのインストール",
          "（補足 2022.7）Anaconda有償化への対応について",
          "Jupyter Notebookの使い方",
          "教材のダウンロードとコースの学び方"
        ],
        "Pythonの基礎": [
          "Pythonの基礎1",
          "Pythonの基礎2",
          "NumPyの基礎",
          "matplotlibの基礎"
        ],
        "数学の基礎": [
          "数学の基礎",
          "線形代数の基礎",
          "微分の基礎",
          "正規分布"
        ],
        "ニューラルネットワーク": [
          "ニューラルネットワークの概要",
          "単一ニューロンの計算",
          "順伝播と逆伝播",
          "層間の計算",
          "回帰と分類",
          "活性化関数",
          "単一ニューロンの実装",
          "ニューラルネットワークの構築（回帰）",
          "ニューラルネットワークの構築（分類）"
        ],
        "バックプロパゲーション": [
          "バックプロパゲーションの概要",
          "訓練データとテストデータ",
          "損失関数",
          "勾配降下法",
          "出力層の勾配",
          "中間層の勾配",
          "エポックとバッチ",
          "行列による順伝播の演算",
          "行列による逆伝播の演算",
          "学習の準備",
          "層のクラスによる実装",
          "回帰の例を実装",
          "分類の例を実装"
        ],
        "ディープラーニング": [
          "ディープラーニングが抱える問題",
          "最適化アルゴリズム",
          "Irisデータセット",
          "学習の準備",
          "各層の実装",
          "全体のコードと実行結果",
          "ドロップアウト"
        ],
        "畳み込みニューラルネットワーク（CNN）": [
          "畳み込みニューラルネットワークの概要",
          "im2colとcol2im",
          "畳み込み層の実装",
          "プーリング層の実装",
          "学習の準備",
          "CNNの実装"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "何らかの、オブジェクト指向プログラミングの経験があった方がベターです。",
        "中学-高校レベルの数学の知識が前提として必要です。",
        "WindowsでもMacでも大丈夫です。Linuxのサポートは行いませんが、コードは全ての環境で共通のものです。"
      ],
      "description": "本コースは、ディープラーニングをゼロから実装する講座です。\nTensorFlowやChainerなどのフレームワークを使わずに、畳み込みニューラルネットワーク（CNN）までゼロから構築できるようになりましょう。\nディープラーニングをフルスクラッチで構築することにより、普遍的な原理がしっかりと身につきます。\n\n\n人工知能（AI）、特にその一分野であるディープラーニングは世界中の人々の関心を集めており、自動運転、ファイナンス、流通、アート、研究、さらには宇宙探索に到るまで、様々な分野で活用をされ始めています。\n本コースは、可能な限り多くの方がディープラーニングの本質を学ぶことができるように、プログラミングと数学から始めて畳み込みニューラルネットワークに至るまで、手を動かしながら少しずつ丁寧に学べるように設計されています。\nまた、扱うコードは直感的な分かりやすさを重視し、可能な限りシンプルで可読性の高いコードを心がけています。\n\n\n本コースには前提となる知識が2つあります。\n1つ目は、何らかのプログラミング言語の経験です。\n本コース内でもPythonの解説をしますが、何からのプログラミング言語の経験があると学習がスムーズになります。\nプログラミングが全くの初心者の方は、他のコースで基礎を身につけた上で本コースに臨むことをお勧めします。\n\n\n2つ目は、中学-高校レベルの数学の知識です。\n本コース内でもディープラーニングに必要な数学の解説をしますが、ベースとなる数学の知識があった方が望ましいです。\n数学に自信のない方は、他のコースで数学を学んだ上で本コースに臨むことをお勧めします。\n\n\n————————————————————\n本コースの主な内容は以下の通りです。\n\n\nPythonの基礎\n→ ディープラーニングを学ぶために必要なPythonの基礎を学びます。\n\n\n数学の基礎\n→ ディープラーニングを学ぶのに必要な数学のベースを身につけます。\n\n\nニューラルネットワーク\n→ ニューラルネットワークの原理と仕組みを学び、簡単なニューラルネットワークのコードを実際に構築します。\n\n\nバックプロパゲーション\n→ 誤差の逆伝播により、ニューラルネットワークが学習する仕組みを学びます。\n\n\nディープラーニング\n→ ここまで学んできた内容をベースに、層をいくつも重ねた深層学習を構築します。\n\n\n畳み込みニューラルネットワーク\n→ 畳み込みニューラルネットワークをゼロから構築します。\n————————————————————\n\n\n本コースは動画を見るのみでも学習が進められるようになっていますが、可能であればPythonのコードをダウンロードして動かしながら進めるのをお勧めします。\nコードがダウンロード可能なので、これをベースにオリジナルのディープラーニングのコードを書いてみることもお勧めです。\nディープラーニングには非常に長い時間がかかる場合もありますが、本コースのコードは長くても数十秒程度で実行可能です。\n本格的なAI開発につながる拡張性を確保しつつも、小さな試行錯誤を何度も繰り返すことができる作りになっています。\n本コースの開発環境、AnacondaとJupyter Notebookは簡単にダウンロード、インストールすることができます。\n\n\nディープラーニングをゼロから構築しその原理を身につけていただくことが本コースの目的です。\n本コースを修了した方は、知的好奇心が刺激されてディープラーニングや人工知能ののことをさらに知りたくなっているかと思います。",
      "target_audience": [
        "ディープラーニング、AIをこれから本格的に学びたい方。",
        "ディープラーニングの原理を基礎から学びたい方。",
        "TensorFlow、Chainerなどのフレームワークの動作原理を知りたい方。",
        "ディープラーニングをフルスクラッチで実装したい方。",
        "フレームワークの使い方については解説しませんので、お手軽にディープラーニングを使いたい方には向きません。"
      ]
    },
    {
      "title": "Hands-On Deep Learning on PyTorch for Beginners",
      "url": "https://www.udemy.com/course/hands-on-deep-learning-with-pytorch-a-beginners-course/",
      "bio": "This course is designed for beginners with little no experience in Deep learning or PyTorch.",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Theory: Data Formats.": [
          "Float Tensor",
          "Long Tensor",
          "Bool Tensor",
          "No_grad Context Manager",
          "torchvision: Compose Object (Theory)",
          "torchvision: Compose Object (Example)"
        ],
        "Theory: Datasets and DataLoaders.": [
          "PyTorch Dataset (Theory)",
          "PyTorch Dataset (Example)",
          "PyTorch DataLoader (Theory)",
          "PyTorch DataLoader (Example)"
        ],
        "Theory: Model components.": [
          "Linear Layer",
          "Convolutional Operation (Theory)",
          "Convolutional Operation (Example)",
          "Activation Functions",
          "Softmax Normalization Function",
          "Argmax Function",
          "How to create a CNN.",
          "Neural Network Evaluation Mode"
        ],
        "Theory: CUDA": [
          "What's CUDA",
          "CUDA Example."
        ],
        "Theory: Optimization Components.": [
          "What's a Loss Function",
          "Cross Entropy Loss (Theory)",
          "Cross Entropy Loss (Example)",
          "What's an Optimizer",
          "What's a Learning Rate",
          "How to initiate Adam (Example)"
        ],
        "Theory: How to Train a Neural Network.": [
          "How to Train a Neural Network (Example)"
        ],
        "Practice: Training a CNN": [
          "Gather Data.",
          "Build Dataset",
          "Build the Neural Network",
          "Training the Neural Network"
        ],
        "Farewell and Assignment.": [
          "Farewell"
        ]
      },
      "requirements": [
        "As long as you have a basic understanding of Python, you're all set to dive into the world of Deep learning."
      ],
      "description": "Hands-On Deep Learning with PyTorch: A Beginner's Course:\nWhether you're new to neural networks or looking to expand your skills, this course will provide you with a hands-on approach to training neural networks from scratch.\nOur comprehensive curriculum covers all the essential components of deep learning, including Neural Networks, Loss Functions, Optimizers, Datasets, and DataLoaders. You'll also learn how to leverage the GPU for accelerated training and gain practical insights into building and training basic neural networks using PyTorch.\nWhat sets this course apart is it's accessibility. You don't need any previous knowledge of neural networks or PyTorch. All you need is a basic understanding of Python, and we'll guide you through the rest.\nBy the end of the course, you'll have gained the skills to confidently train basic neural networks using PyTorch. Unlock your potential in deep learning and embark on this exciting journey today. Enroll now and start building your expertise in the world of artificial intelligence.\n\n\nContent of the Course:\nDatasets\nData Loaders.\nImage Augmentation\nLoss Functions\nOptimizers.\nActivation Functions.\nNormalization Techniques.\nConvolutional Neural Networks (CNN).\nTraining Neural Networks.\nGPU Acceleration.\nRequirements:\nThe only requirement is basic knowledge of Python.\nNo experience on Deep learning required.\nNo experience on PyTorch required.",
      "target_audience": [
        "This course is designed for beginners who are interested in deep learning but lack the theoretical/technical background.",
        "Beginners that feel overwhelmed with the massive influx of information around and want a streamlined path to build a solid foundation on deep learning."
      ]
    },
    {
      "title": "30+ Saatlik Uçtan Uca İş Zekası Mühendisliği Kursu",
      "url": "https://www.udemy.com/course/25-saatlik-uctan-uca-is-zekas-muhendisligi-kursu/",
      "bio": "Bu kursta T-SQL, Power BI, SSAS, SSIS, DAX, Excel ve Excel VBA, Makine Öğrenmesi ve Zaman Serileri öğretilecektir.",
      "objectives": [
        "Microsoft SQL Server ve T-SQL",
        "Power BI",
        "DAX",
        "M Query Language",
        "Analysis Service",
        "Excel Formülleri",
        "Excel VBA",
        "Makine Öğrenmesi",
        "Zaman Serileri"
      ],
      "course_content": {
        "İş Zekası Mühendisliği'ne Giriş": [
          "Business Intelligence Nedir? ( İş Zekası)",
          "SQL Server Yüklenmesi",
          "SQL Server Management Studio'nun Yüklenmesi",
          "AdventureWorks2014 Database'inin Yüklenmesi"
        ],
        "Veritabanı Yönetim Sistemleri Teorisi": [
          "T-SQL Nedir? ( Transactional SQL )",
          "Veritabanı Nedir?",
          "Primary Key Nedir?",
          "Foreign Key Nedir?",
          "Normalizasyon Nedir?"
        ],
        "Temel T- SQL Sorguları": [
          "Temel SQL Sorguları",
          "SQL Veri Tipleri"
        ],
        "Data Definition Language (DDL)": [
          "Create Database",
          "Create Table",
          "Constraints",
          "Foreign Key Ekleme",
          "Alter Komutu",
          "Drop Komutu"
        ],
        "Data Manipulation Language (DML)": [
          "SELECT Komutu",
          "WHERE Komutu",
          "INSERT INTO - VALUES",
          "UPDATE Komutu",
          "DISTINCT - ORDER BY",
          "Sütunlara İsim Verme",
          "Karşılaştırma Operatorleri",
          "GROUP BY"
        ],
        "Üniversite Ders Kayıt Veritabanı Tasarım Uygulaması": [
          "Üniversite Ders Kayıt Sistemi",
          "Tablolara Veri Ekleme",
          "Öğrenci Tablosuna Foreign Key Eklenmesi",
          "Tüm Tablolara Foreign Key Eklenmesi"
        ],
        "SQL Fonksiyonları": [
          "String Fonksiyonları",
          "Matematiksel Fonksiyonlar",
          "Date Fonksiyonları",
          "Tip Dönüşüm Fonksiyonları"
        ],
        "SQL JOIN - EXCEPT - INTERCEPT ...": [
          "INNER JOIN",
          "LEFT JOIN",
          "FULL OUTER JOIN",
          "CROSS JOIN",
          "EXCEPT - INTERSECT - UNION ALL"
        ],
        "SQL Subquery (Alt Sorgular)": [
          "SQL Subquery (Alt Sorgular)"
        ],
        "Stored Procedures": [
          "Stored Procedures"
        ]
      },
      "requirements": [
        "Temel düzeyde programlama bilgisi.",
        "Öğrenme isteği ve azmi."
      ],
      "description": "Selam! İş Zekası Mühendisliği Kursuna hoş geldiniz.\nUdemy’de gördüğüm kadarıyla business intelligence araçları tekli kurslar halinde anlatılmış ancak komple bir kurs bulunmamakta.\nDiğer kurslardan farklı olarak aynı kurs içerisinde;\n- Microsoft SQL Server ve T-SQL\n- Veritabanı Yönetim Sistemleri Teorisi\n- Power BI Veri görselleştirme ve Raporlama\n- İleri Düzey DAX programlama ve Analitik Çözümler\n- Power BI – M Query Language\n- Microsoft SQL Server Analysis Server ile OLAP Veri kübü geliştirme\n- Microsoft SQL Server Integration Services\n- İş Hayatında en sık kullanılan 40 Excel formül uygulaması\n- İş hayatında en sık kullanılan 25 Excel makro uygulaması\n- Gradient Descent ile Makine Öğrenmesi ve Yapay Zeka’nın çekirdek algoritması\n- Zaman Serileri ve ARIMA Modelleri\nBunlar, işverenlerin BI Mühendislerini işe alırken aradığı kesin teknik becerilerdir. Ve bugün, diğer adayların önüne geçmek için paha biçilemez bir avantaj elde etme şansına sahipsiniz!",
      "target_audience": [
        "Yazılıma ve İş zekasına merakı olan herkes."
      ]
    },
    {
      "title": "Apprenez à maitriser ChatGPT et le Prompt Engineering",
      "url": "https://www.udemy.com/course/chatgpt_french/",
      "bio": "Formation en français ChatGPT 3.5 et 4. Créez des prompts efficaces pour maximiser votre productivité",
      "objectives": [
        "Comprendre ce qu'est ChatGPT",
        "Les principes de base de ChatGPT",
        "Le Prompt Engineering",
        "Les différents Prompts de base à avancé",
        "Les différents emplois de ChatGPT"
      ],
      "course_content": {
        "Introduction à ChatGPT": [
          "Définition de ChatGPT",
          "Historique de ChatGPT",
          "Fonctionnement de ChatGPT",
          "Utilisations de ChatGPT",
          "Limitations de ChatGPT",
          "Le Récap en PDF"
        ],
        "Installation de l'environnement": [
          "Se connecter à ChatGPT et tour de l'interface",
          "Une Extension ChatGPT pour Chrome",
          "Mise à jour Extension Chrome",
          "ChatGPT-4 gratuit sur Edge et Bing"
        ],
        "Qu' est ce que le Prompt Engineering": [
          "Avant de commencer",
          "Définition",
          "Histoire du Prompt",
          "Le prompt parfait?",
          "Le principes de base"
        ],
        "Le Prompt Engineering, ou l'ingénierie de Prompts: Les Basiques": [
          "Les prompts simples",
          "Le Prompt Priming ou L'amorcage de prompt",
          "Ajouter des étapes en suivant le Prompt Priming",
          "Améliorer le Prompt",
          "Terminer une conversation"
        ],
        "Le Prompt Engineering: Les prompts intermédiaires": [
          "0, 1, 2, 3: Le Shot Prompting",
          "Pas à pas: Le Chain of Thoughts Prompting",
          "Une question? Le Ask Before Prompting",
          "Tu es un...: Le Perspective prompting",
          "Comparé à...: Le Comparative Prompting"
        ],
        "Le Prompt Engineering: Les prompts avancés": [
          "P.R.O.M.P.T",
          "I want you to act as..."
        ],
        "Travailler les Textes": [
          "Synthétiser, Développer ou changer le ton des Textes",
          "Améliorer un texte et corriger",
          "Réorganiser les données",
          "Traduire un Texte"
        ],
        "Utilisation de ChatGPT au quotidien": [
          "Organiser son temps",
          "Créer un programme sportif",
          "Gérer son alimentation",
          "Faire sa liste de courses",
          "Organiser un apéro entre amis",
          "Préparer ses vacances",
          "Faire les devoirs aux enfants",
          "Comprendre les animaux"
        ],
        "La création de Contenu": [
          "Qu'est ce que la création de contenu?",
          "Ecrire des mails",
          "Créer des articles",
          "Créer un questionnaire",
          "Créer une identité en ligne",
          "ChatGPT pour les réseaux sociaux",
          "Ecrire une publicité",
          "Faire un Script",
          "Créer la description d'un produit",
          "Youtube: Générer un titre, une description et des tags",
          "ChatGPT pour le SEO",
          "Créer un discours"
        ],
        "ChatGPT pour nous aider a trouver un emploi": [
          "Introduction au Chapitre",
          "Cibler son emploi",
          "Rechercher un emploi avec ChatGPT4",
          "Créer son CV avec ChatGPT",
          "Créer une lettre de motivation",
          "Préparez son entretien"
        ]
      },
      "requirements": [
        "Une connexion internet: Si vous êtes ici, vous en avez sûrement une"
      ],
      "description": "SPOILER ALERT ! Cette Description a été rédigée par ChatGPT en seulement quelques minutes !\n\n\nHey hey hey, ici ChatGPT !\n\n\nJ'ai pris le contrôle pour vous présenter cette formation qui va changer votre vie : \"Maitrisez ChatGPT et le prompt engineering\".  Si vous êtes prêts à vivre une expérience incroyable et à apprendre à utiliser l'IA comme un pro, vous êtes au bon endroit !\n\n\nJ'imagine que vous en avez assez d'entendre parler de méthodes miracles pour maîtriser ChatGPT. La vérité, c'est qu'il n'y a pas de potion magique pour devenir un expert en la matière. Mais avec cette formation, vous allez acquérir les compétences dont vous avez besoin pour devenir un pro sans brûler les étapes!\n\n\nNous allons avant de commencer:\nPartir des bases et comprendre ce que sont ChatGPT et le Prompt Engineering.\nMettre en place votre environnement de travail.\n\n\nPuis il sera temps d'apprendre les différentes techniques de prompt selon les niveaux:\nDébutant: Des prompts simples et la mise en place de techniques de base.\nIntermédiaire: Apprenez des techniques pour des prompts plus spécifiques, personnalisés et pertinents.\nAvancé: Vous verrez ici des méthodes élaborées qui vous permettront de maitriser pleinement de prompt engineering.\n\n\nEn utilisant ChatGPT de manière intelligente, vous pouvez multiplier par 10 votre productivité pour résoudre des tâches complexes. Plus besoin de passer des heures à écrire des textes, ou à traduire des langues, ChatGPT s'en occupe pour vous ! Et le meilleur dans tout ça, c'est que ChatGPT n'est pas seulement destiné à des taches professionnelles, mais peut également vous aider dans les tâches du quotidien. Tout est possible avec ChatGPT !\n\n\nSi vous êtes prêts à relever le défi et à maîtriser ChatGPT comme un pro, rejoignez-nous pour cette formation passionnante. Avec cette formation, vous aurez toutes les clés en main pour devenir un expert en ChatGPT et en prompt engineering. Alors, n'hésitez plus, inscrivez-vous dès maintenant et laissez ChatGPT vous montrer tout ce qu'il sait faire !",
      "target_audience": [
        "Tous ceux qui veulent apprendre à maitriser une IA conversationnelle"
      ]
    },
    {
      "title": "Find Actionable Insights using Machine Learning and XGBoost",
      "url": "https://www.udemy.com/course/find-actionable-insights-using-machine-learning-and-python/",
      "bio": "Let's Build a Student Retention Model with Python and Create a Report of Actionable Insights",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Exploratory Data Analysis - Student Performance Data Set",
          "Data Preparation & Feature Engineering",
          "Modeling with XGBoost",
          "Building Our Actionable Report",
          "Better Reporting with Seaborn Charts",
          "Conclusion & Bonus"
        ]
      },
      "requirements": [
        "Knowledge of Python and the basics of modeling",
        "Ability to run a Jupyter Notebook and install appropriate Python libraries"
      ],
      "description": "Applied data science is about everything that goes before and after your model. Extracting actionable insights is probably the most important aspect of any modeling project! if you want to step up your data science game then this is a great area to study. Let's do it hands-on, applied a science project together and walk through a student retention model to extract actionable insights and help out struggling students.\n\n\nExplore student data\nModel student behavior using XGBoost\nPredict struggling/at-risk students\nIdentify what makes a struggling student different than successful students\nBuild a report of actionable insights\nAnd help teachers help students\n\n\nIn the case of a student retention model, looking at the full picture means doing a lot of work before doing any modeling. For example, talking to teachers. We need to better understand the business domain. In this case, finding out what are the problems they face. What are the uncertainties they'd like help with? It is critical to also leverage all their knowledge, like how and when do they determine that a student is at-risk. What data points and triggers do they use to identify someone that could be failing a class and/or their studies. How early can they identify this? Obviously the earlier the better, you don't want to wait till have too many bad grades and can't dig themselves out of the hole.\nAfter you've distilled all that information in the model, we dig down into the observation level. This is an important point to understand. A model may return feature importance, coefficients, or weights depending on what type of model you use and how it learns. So, imagine a model that predicts heart attacks and finds that older age is the most important feature for the model, and if your patient is young, that's not going to tell them anything, worse, may lead them to misdiagnose.\nInstead, we let the model give us a prediction of the likelihood of something happening, then we dig down to the observation level (i.e. each specific patient or student level) where each case is different and unique and analyze what makes this particular patient/student different from the rest. This may yield some useful information that may allow the professional to better assist - that is actionable insight.",
      "target_audience": [
        "Those interested in stepping up their practical machine learning and analytics knowledge",
        "Those interested in getting more out of their machine learning projects"
      ]
    },
    {
      "title": "【Kaggleで学ぼう】Python と Keras で学ぶディープラーニング開発入門",
      "url": "https://www.udemy.com/course/keras_aidev/",
      "bio": "データサイエンスの基礎を学んで、目指せKaggler (カグラー) ! TensorFlowとKerasで短期間にディープラーニングによるAI開発手法を学び、Kaggleコンペティションに挑戦し、データサイエンティストとして活躍しよう！",
      "objectives": [
        "Kerasを使用して高速にディープラーニングモデルを開発できるようになります。",
        "ディープラーニング開発時のパラメーターチューニングのコツを理解し、実践できるようになります。",
        "畳み込みニューラルネットワークを使用した開発を実践できるようになります。",
        "Kaggleへの登録・コンペへの参加方法、学習方法を理解できるようになります。"
      ],
      "course_content": {
        "はじめに": [
          "コースの概要"
        ],
        "基本用語とGoogle Colabではじめての機械学習体験": [
          "用語の整理：機械学習とは？",
          "用語の整理：ニューラルネットワークとは？",
          "Google ColabでKerasの動作を体験してみよう！",
          "MNISTで扱っているデータの詳細",
          "自主練習課題： Google ColabでMNISTを実行"
        ],
        "環境構築とPythonのミニマムレビュー": [
          "Anacondaをインストールしよう（Windows編）",
          "Anacondaのインストール（Mac編）",
          "TensorFlow をインストールしよう",
          "仮想環境の有効化と終了手順",
          "Jupyter Notebookの起動と変数の扱い",
          "データ型とキャスト（型変換）を学ぼう",
          "演算子",
          "リストとタプルで複数データをまとめて扱おう",
          "文字列操作とフォーマットを学ぼう"
        ],
        "3層ニューラルネットワークでMNISTにチャレンジ": [
          "セクションの概要",
          "3層ニューラルネットワークでMNISTを解いてみよう",
          "データを確認しよう",
          "最適化手法を定義して学習してみよう",
          "sparse_categorical_crossentropyとcategorical_crossentropy",
          "テスト画像で数字の推定を行ってみよう",
          "学習フローのレビュー",
          "応用課題：　Fashion MNISTにチャレンジ",
          "課題実行例：　その１",
          "課題実行例　その２",
          "MNIST（3層NN）のノートブック",
          "Fashion MNIST（3層NN）のノートブック"
        ],
        "畳み込みニューラルネットワークでFashion MNISTのスコア向上を図る": [
          "3層NNからCNNへ",
          "CNNモデルを定義しよう",
          "CNNモデルのトレーニングを実行しよう",
          "練習課題： CNNでFashion MNISTにチャレンジ"
        ],
        "Kaggleの歩き方": [
          "セクションとKaggleの概要",
          "Kaggleの各ページをチェックしよう",
          "Kaggleへの登録とデータのダウンロード",
          "ダウンロードデータを確認してみよう",
          "データの確認とサブミッション（提出手順）",
          "セクションのまとめ"
        ],
        "KaggleのKernelsで学ぼう（Dogs vs. Cats）": [
          "セクションの概要とデータダウンロード",
          "ダウンロードデータを確認しよう",
          "データの整理とアルゴリズムについて",
          "Catdog Net カーネルを解読しよう",
          "リストの内包表記（コンプリヘンション）でファイル一覧を取り出そう",
          "データの部分抽出を行おう（リストのスライス処理）",
          "データをNumPy配列に変換しよう",
          "分類ラベルを生成しSeabornで可視化しよう",
          "画像データを表示してみよう",
          "平均画像を生成しよう",
          "CatdogNetモデルの定義をしよう",
          "トレーニングを実行しよう",
          "収束状況（Loss）をプロットしよう",
          "推論結果を可視化しよう ＆ セクションのまとめ",
          "セクションで使用したノートブック"
        ],
        "オプション：　数学の学び直し(機械学習のための数学講座から抜粋）": [
          "微分",
          "極限",
          "導関数",
          "微分の線形性",
          "分数関数の微分",
          "シグモイド関数の微分を計算してみよう",
          "偏微分"
        ]
      },
      "requirements": [
        "PCの基本的な操作スキル（フォルダー作成やウェブブラウザでのサイトへのアクセス）",
        "インターネット接続（PythonパッケージやKerasのインストールに必要です）",
        "関数や微分の概念（計算はできなくても学習可能ですが、理論が知りたい方はオプションで数学コースも用意しています）",
        "エラーが出ても諦めずに調べたり、質問して解決しようとする意欲"
      ],
      "description": "【更新情報】\n2019/6/20 sparse_categorical_crossentropyをsparse_categorical_entropyと誤記している部分がありましたので、修正しました。\n\n\n【コース概要】\nディープラーニングによるAI開発は普及期に突入し、さまざまな分野で応用が広がっています。\nしかし、TensorFlow（テンソルフロー）ネイティブのAPIを使う実装は複雑で時間がかかるのが問題だと言われています。\nそのため、Google社ではKeras（ケラス）というTensorFlowやTheano（シアーノ）などのディープラーニングライブラリのラッパーをTensoFlow本体に取り入れ、よりシンプルで高速に開発することを推奨しています。\nこのコースではこのKerasを用いたディープラーニングの実装にフォーカスし、環境構築からニューラルネットワークによる学習、ディープラーニングなどを学べます。コースを終えると、あなたのアイデアをKerasを用いて短期間に実装できるようになります。\nまた、Kaggle（カグル）というデータサイエンティストコミュニティサイト上で、データサイエンスのコンペティションに参加する手順を解説し、オープンデータで学習を行います。Kaggleの参加者は \"Kaggler\" （カグラー）と呼ばれ、実力を証明するのに役立ちます。\nKagglerとなってメダル取得を目指して学習し、就職や転職に役立つポートフォリオを作り、AIエンジニアやデータサイエンティストとして活躍できるようになりましょう！\n【コース概要】\n機械学習・深層学習の概要と環境構築\n3層ニューラルネットワークでMNISTを解く\n畳み込みニューラルネットワークでFashion_MNISTを解く\nKaggleへの登録とコンペティションの解読方法\nKaggleで学ぼう！　（Dogs vs. Cats）\nDogs vs. Cats をCatdogNet（VGG-16コンパクト版）で解く（2018/11/14　追加)\n【更新情報】\n11/14 セクション５にモデルの定義、学習の実行、結果の可視化までを追加しました。\n11/12 セクション５に正解ラベルの生成、Seabornによるカウントプロットや画像データの表示のレクチャーを追加しました。\n11/10 セクション５にリストの内包表記のレクチャーを追加しました。",
      "target_audience": [
        "Python3とKerasでディープラーニングを学び直してみたい方",
        "TensorFlowのDefine&Runスタイルで直接開発するのは難解に感じて、もう少し易しくAIプログラミングをしたい方",
        "数学的詳細は別に理解するとして、実践的なディープラーニングアプリケーション開発にチャレンジしたい方",
        "Kaggleへの登録・参加方法・勉強方法を知りたい方"
      ]
    },
    {
      "title": "Raspberry Pi とTensorFlow ではじめるAI・IoTアプリ開発入門",
      "url": "https://www.udemy.com/course/raspi-tensorflow/",
      "bio": "2018年8月、Google BrainチームはTensorFlow 1.10をリリースし、Raspberry Pi（Raspbian）に正式対応しました。ラズベリーパイでディープラーニング・IoTにチャレンジしましょう！",
      "objectives": [
        "Raspberry Pi上にTensorFlow動作環境を構築できます。",
        "TensorFlow最新版でKerasをベースにした高速開発、ディープラーニングの基礎を学べます。",
        "Raspberry Piに接続したカメラ画像と機械学習の連携の仕組みを理解できます。",
        "Raspberry Pi上でのプログラミング環境構築ができます。",
        "Raspbian（Raspberry Pi用Linuxディストリビューション）の基本的な操作をマスターできます。"
      ],
      "course_content": {},
      "requirements": [
        "Raspberry Pi 3 Model B+　と周辺機器（マウス・キーボード・ディスプレイ）",
        "32GB以上の容量のマイクロSDカード",
        "マイクロSDカードへの書き込みが可能なPC（WindowsまたはMac）",
        "Raspbian（Linux）やTensorFlowをダウンロード・インストールするためのインターネット接続"
      ],
      "description": "【最新更新情報】\n2019/9/9 「Raspbian 2019-07 におけるJupyter Notebookインストール時の注意」をセクション4に追加しました。最新のRaspbianではJupyter Notebookを通常インストールすると起動しないパッケージングの不具合がありました。\n2018年8月、Google BrainチームはTensorFlow 1.10をリリースし、Raspberry Pi（Raspbian）に正式対応しました。\nRaspberry Pi（ラズベリーパイ）は、イギリスのRaspberry Pi財団が設計・開発している名刺サイズのマイクロコンピューターで、今日まで世界で1000万台以上も出荷されています。\nRaspberry PiはLinux系のUbuntuやRaspbian, DebianやWindows 10 IoT Coreなどに対応し、センサーやカメラから取得したデータとソフトウェアを連携して、AIやIoTのアプリケーションのプロトタイピングで威力を発揮します。\nラズベリーパイでディープラーニング・IoTにチャレンジしましょう！\nこの講座では、以下のような内容を学べます。\nRaspberry PiへのRaspbian （Linux）インストール\nインストールイメージの書き込み\nインストーラの実行\nVNCによるリモートデスクトップ環境の構築\n\n\nRaspbianへののpip3コマンドやTensorFlow最新版のインストール\npip3コマンドのインストール\nAtlas（高速数値計算ライブラリ）のインストール\nTensorFlow最新版のpipコマンドによるインストール\n\n\nJupyter Notebookによる機械学習や深層学習プログラミング\n畳み込みニューラルネットワークによる画像分類（Fashion MNIST）\n\n\n\n\n代表的なディープラーニングアルゴリズムの概要を学ぼう（順次追加予定）",
      "target_audience": [
        "Raspberry Pi を用いてディープラーニングを学びたい方",
        "Raspberry Pi 上でTensorFlowを用いた機械学習・深層学習、モデルを用いた推論などを行いたい方",
        "TensorFlowに標準搭載されたKerasを用いて短期間にディープラーニングの基礎を学びたい方",
        "定番のMNISTやIrisデータセット以外のデータでディープラーニングを学びたい方（Fashion MNIST, IMDB, Boston Housing Datasetなど）",
        "AIによる推論結果を元に音を鳴らしたり、LEDを光らせたり、というIoTの初歩を体験したい方"
      ]
    },
    {
      "title": "Formação Plena em Análise e Ciência de Dados [2025-2026]",
      "url": "https://www.udemy.com/course/formacao-em-ciencia-de-dados/",
      "bio": "Data Science e Machine Learning em Python e R, básico ao avançado. Seja um Analista ou Cientista de Dados, destaque-se!",
      "objectives": [
        "Compreenda Ciência de Dados (Data Science) e Análise de Dados (Data Analytics) em seus três pilares fundamentais: exatas, tecnologia e competências.",
        "Estude Estatística Descritiva e Inferencial (Statistics) para ser um profissional completo dentro de dados, seja como Cientista de Dados ou Analista de Dados.",
        "Construa um portfólio de projetos em Data Science, através de projetos práticos, dentro dos módulos intermediários desta Formação em Ciência de Dados.",
        "Estude a matemática necessária para avançar em problemas de estatística e probabilidades dentro de Análise e Ciência de Dados.",
        "Compreenda e seja capaz de aplicar as duas principais linguagens de programação para Cientistas de Dados: Python e R.",
        "Aprimore sua interpretação de dados (Data Interpretation), desenvolvendo visão crítica e analítica.",
        "Analise dados de áreas como economia, saúde, educação, administração, marketing e políticas públicas.",
        "Domine modelagem estatística (Statistical Modeling): regressões, correlações, testes de hipótese e ANOVA.",
        "Aprenda técnicas de Aprendizado de Máquina (Machine Learning): regressão, árvores, boosting e redes neurais.",
        "Aplique pré-processamento de dados (Data Preprocessing): seleção de atributos, codificação e balanceamento.",
        "Estude Computação Paralela e Distribuída (Parallel and Distributed Computing) para lidar com Big Data.",
        "Compreenda fundamentos de Administração, Economia e Legislação de Dados aplicados.",
        "Desenvolva projetos ponta a ponta (End-to-End Data Projects) com boas práticas de engenharia e documentação."
      ],
      "course_content": {},
      "requirements": [
        "Computador com acesso à internet (celular serve apenas para assistir às aulas).",
        "Disponibilidade para instalar Python e R no computador.",
        "Vontade de estudar teoria: especialmente matemática e estatística (fundamentais na área de dados)."
      ],
      "description": "Formação Plena em Análise e Ciência de Dados [2025–2026]\nReconhecida pelo Portal Decodificando como o melhor curso de Data Science da Udemy em Português!\nAtenção!\nEsta não é uma Formação para impacientes ou para quem não gosta de estudar teoria a fundo. Se você procura atalhos ou promessas fáceis de dinheiro, este curso não é para você. Se você não gosta de estudar teoria a fundo (como demanda a Análise e Ciência de Dados) este curso não é pra você.\nPara quem é esta Formação?\n- Pessoas em transição de carreira para Análise e Ciência de Dados\n- Profissionais que desejam ganhar produtividade e agilidade com Análise e Ciência de Dados\n- Iniciantes ou intermediários em Análise de Dados, Ciência de Dados ou B.I.\n- Avançados que buscam uma nova abordagem para aprofundar seus conhecimentos\nO que você precisa saber antes de comprar?\nIsto é uma Formação, não apenas um curso. Ao final dela, você terá condições plenas de aplicar seus conhecimentos em projetos e negócios. Mas não espere resultados imediatos sem concluir o processo completo. Todo o material da Formação foi pensado para proporcionar para você um conhecimento sólido e completo e não apenas decorebas vazias e sem propósito.\nTeoria é o coração da Análise e Ciência de Dados. Nesta Formação você estudará matemática e estatística em profundidade - desde o básico até tópicos avançados, sempre aplicados ao contexto de dados. Se você não gosta de teoria, especialmente de matemática e estatística, esta Formação não é para você.\nEstrutura única por NÍVEIS. Uma metodologia inédita na Udemy Brasil e na internet brasileira, inspirada em programas de universidades de elite no exterior (como o famoso CS50 de Harvard). Você vai evoluir passo a passo, do nível básico ao avançado.\nCompromisso com o estudo sério. Para aproveitar a Formação, é preciso gostar de estudar - e estudar muito, de forma estruturada e consistente. Recomendamos que esta Formação seja concluída em 2 ou 3 meses e não em algumas poucas semanas, justamente para o máximo proveito e aprendizado.\nO que faz um Analista de Dados / Analista de B.I.?\nÉ o profissional que organiza, interpreta e apresenta dados para gerar insights práticos e apoiar decisões estratégicas. Seu foco está em relatórios, dashboards, indicadores e análises que ajudam empresas e equipes a entenderem melhor seus resultados e planejarem suas ações. Em resumo: é quem traduz os dados em informações úteis para o dia a dia dos negócios.\nO que faz um Cientista de Dados?\nÉ o profissional que transforma dados brutos em inteligência para empresas, governos e pessoas. Seu trabalho envolve tecnologia, matemática/estatística/probabilidade e competências multidisciplinares. Em resumo: é quem cria as condições para que dados se tornem informação, e informação vire decisões estratégicas. Lida com Ciência, por isso ha grande necessidade de rigor técnico, algo que somente este curso vai te proporcionar.\nComo funciona a Formação?\n- Estruturada em níveis progressivos (do básico ao avançado).\n- Aulas em vídeo, materiais em texto, simulados, testes e atividades práticas (desafios práticos, projetos e role plays).\n- Integração entre teoria e prática para que você saiba interpretar, aplicar e resolver problemas reais em sua carreira.\nQuais as linguagens de programação?\nAs duas principais serão Python e R. Você também terá contato breve com SQL e outras ferramentas complementares.\nO que é importante sobre o acesso?\n- Compra única → acesso vitalício ao conteúdo na Udemy. Incluindo acesso vitalício à colegas de curso e recursos. Recomendamos essa opção.\n- Planos mensal/anual -> acesso temporário, incluindo fóruns e contato com instrutores/colegas. Para quem busca planejamento de carreira robusto, a compra única é muito mais vantajosa.\nPromessas de ganho rápido?\nNão aqui. Eu não ensino a “ficar rico com dados”. Eu ensino Análise e Ciência de Dados de verdade. Se o seu objetivo é apenas dinheiro rápido, há outros cursos no mercado que prometem isso (e geralmente não entregam).\nQuais as observação sobre recursos extras?\nRecursos opcionais oferecidos pela Indaout Academy (como tarefas e certificações externas à Udemy) não têm garantia de acesso vitalício. Eles podem ser alterados ou descontinuados a qualquer momento.\n-> Se você quer uma Formação completa, sólida e estruturada, está no lugar certo. Mas lembre-se: se não gosta de estudar teoria, especialmente matemática e estatística, esta não é a Formação para você. Existem outros cursos nesta mesma plataforma para quem busca apenas prática imediata. Mas esteja certo: se seu objetivo é realmente trabalhar na área de dados, nenhum profissional é contratado sem conhecimento sólido de matemática e estatística. Não existe prática consistente sem teoria bem fundamentada.",
      "target_audience": [
        "Profissionais em busca de crescimento na carreira: funcionários que desejam otimizar seu trabalho com técnicas de Análise e Ciência de Dados, aumentando produtividade e agilidade.",
        "Pessoas em transição de carreira: interessados em migrar para as áreas de Análise de Dados (Data Analytics) ou Ciência de Dados (Data Science), começando com bases sólidas.",
        "Analistas de Business Intelligence (B.I.): profissionais que já atuam com dados, mas querem elevar seu nível técnico e aprofundar o uso de ferramentas e conceitos de Data Science.",
        "Profissionais da área de dados: quem deseja desenvolver uma compreensão mais crítica e aprofundada de problemas, metodologias e conceitos fundamentais, com ênfase em interpretação e análise.",
        "Iniciantes em programação: desenvolvedores curiosos em Python e interessados em explorar Data Science de forma estruturada e aplicada, nunca deixando de lado a formação teórica sólida."
      ]
    },
    {
      "title": "Visualisasi Data Interaktif dengan Google Data Studio",
      "url": "https://www.udemy.com/course/visualisasi-data-interaktif-dengan-google-data-studio/",
      "bio": "Rebranded to: Google Looker Studio. Tampilan lebih Interaktif, Dinamis dan Complete Tutorial Hingga Advance.",
      "objectives": [
        "Visualisasi data interaktif dan dinamis dengan menggunakan Google Looker Data Studio yang berfungsi untuk mendukung pengambilan keputusan",
        "Menghubungkan output visualisasi ke sumber data online dengan mudah.",
        "Membagikan analisis dengan tim atau ke seluruh dunia.",
        "Teknik Kolaborasi dalam membuat laporan dengan tim.",
        "Bekerja cepat dalam proses pembuatan laporan dengan contoh laporan yang sudah ready to use."
      ],
      "course_content": {
        "PENDAHULUAN": [
          "Apa itu Visualisasi Data?",
          "Jenis Data",
          "Jenis Chart",
          "Kuis 1"
        ],
        "BEKERJA DENGAN GOOGLE SHEET": [
          "Lima Kelebihan Bekerja dengan Cloud Storage",
          "Mengenal Google Sheet",
          "Export dan Import Data Dengan Google Sheet",
          "Share Data Google Sheet kepada Tim",
          "Kuis Bekerja dengan Google Sheet"
        ],
        "BEKERJA DENGAN GOOGLE LOOKER DATA STUDIO": [
          "Data Studio VS Looker Studio",
          "Mengenal Tool pada Google Looker Studio",
          "Membuat Pie Chart pada Google Looker Data Studio",
          "Menambahkan Filter pada Google Looker Data Studio",
          "Membuat Scorecard pada Google Looker Data Studio",
          "Menambahkan Data Baru pada Google Looker Data Studio",
          "Membuat Stack Column Chart pada Google Data Studio",
          "Membuat Bar Chart pada Google Data Studio",
          "Membuat Geomap pada Google Data Studio",
          "Membuat Heatmap pada Google Data Studio",
          "Kuis Bekerja dengan Google Data Studio"
        ],
        "SHARE ANALISIS KE TIM ATAU PUBLIK": [
          "Share hasil analisis ke Publik",
          "Download Laporan dalam bentuk PDF",
          "Membuat Embedded Google Data Studio",
          "Membuat Shortlink Via Bit.ly",
          "Kuis Share hasil Analisis"
        ],
        "!! NEW FEATURE !! LOOKER STUDIO UNTUK VISUALISASI DATA LEBIH LEVEL UP": [
          "Membuat Calculated Field (Membuat Variabel Baru) Pada Looker Studio",
          "Menggabungkan Data dari Dua Data Source Yang Berbeda (Blended Data)",
          "Membuat Tombol Filter (Filter Button)",
          "Scorecard Advance dengan Sparkline dan Comparison Value",
          "Scorecard Advance dengan Membandingkan Data pada Periode/Tahun Tertentu",
          "Scorecard Advance dengan Membandingkan Data terhadap Metric Lain",
          "Membuat Hyperlink Data Pada Google Looker Studio",
          "Penerapan Fungsi IF dan Case End Pada Looker Data Studio",
          "Menghitung Leadtime dengan Fungsi Datetime"
        ],
        "PROJECT VISUALISASI DATA COVID 19 INDONESIA": [
          "Memahami Struktur Data Covid 19 Indonesia",
          "Menambahkan Data Range",
          "Menambahkan Total Scorecard",
          "Menambahkan Grafik Garis (Line Chart)",
          "Menambahkan Tabel [part 1]",
          "Menambahkan Tabel [part 2]",
          "Uji Coba Project Dashboard Covid 19 Indonesia"
        ],
        "APLIKASI BERAT BADAN BAYI IDEAL DENGAN LOOKER DATA STUDIO": [
          "Menambahkan Advance Filter",
          "Menambahkan Kolom Identitas Bayi dengan Modifikasi Table",
          "Penerapan Fungsi IF Pada Aplikasi Berat Badan Bayi Ideal"
        ],
        "DASHBOARD PENJUALAN TOKO ONLINE SEPERTI TAMPILAN WEBSITE": [
          "Tampilan Dashboard Penjualan Toko Online",
          "Pengaturan Tata Letak dan Pembuatan Tab Dashboard Toko Online",
          "Membuat Tampilan Home",
          "Membuat Tampilan Customer Insights",
          "Membuat Tampilan Product Insights",
          "Membuat Tampilan Leadtime"
        ],
        "SISTEM INFORMASI MANAJEMEN (SIM) PASIEN RUMAH SAKIT": [
          "Tampilan Dashboard Sistem Informasi Pasien Rumah Sakit",
          "Theme dan Layout Sistem Informasi Pasien Rumah Sakit",
          "Modifikasi Scorecard Untuk Menghitung Jumlah Ruangan Pasien",
          "Menambahkan Tree Map dan Table Chart",
          "Modifikasi Fixed Size List untuk Menampilkan Dokter Penanggungjawab",
          "Menambahkan Bar Chart Pasien Masuk dan Pasien Keluar",
          "Menambahkan Scorecard Lama Pasien Dirawat di Rumah Sakit",
          "Membuat Scorecard Untuk Mengetahui Ruangan Pasien Yang Masih Tersedia",
          "Menampilkan Denah Ruangan Kamar Pasien Yang masih Available",
          "Finishing : Menambahkan Tombol Link Pada Header"
        ],
        "SEGMENTASI PELANGGAN DENGAN RFM ANALYSIS": [
          "Apa Itu RFM Analysis?",
          "Penjelasan RFM Secara Penghitungan Manual",
          "Penyiapan Data RFM Analysis Pada Google Sheet",
          "RFM Analysis Pada Looker Studio",
          "Mengubah RFM Score menjadi Segmentasi Pelanggan"
        ]
      },
      "requirements": [
        "Memiliki Akun Gmail"
      ],
      "description": "Hampir semua instansi perusahaan pasti memiliki data yang jumlahnya tidak sedikit. Menurut World Economic Forum, 90% dari data di dunia dibuat dalam rentang waktu 2 tahun terakhir. Dengan banyaknya data pasti semakin sulit untuk mengelola dan memahaminya. Di sinilah pentingnya visualisasi data yang berperan untuk mengubah data yang kompleks menjadi lebih mudah dipahami banyak orang. Bahkan sebagai seorang developer pun, skill visualisasi data dibutuhkan supaya dapat menceritakan dan mempresentasikan data yang ada (story telling with data).\nVisualisasi Data sangat berperan penting di sebuah instansi atau perusahaan, diantaranya :\nVisualisasi data memudahkan untuk melihat trend data.\nVisualisasi data membantu dalam proses data analysis.\nVisualisasi data membantu dalam mengkomunikasikan data dengan lebih efektif.\nVisualisasi data merupakan salah satu skill yang sangat penting bagi orang yang bekerja dengan banyak data seperti pada pekerjaan machine learning.\n\n\nGoogle Data Studio kini menjadi Google Looker Studio yang merupakan salah satu tool Gratis dan memiliki fitur keren dalam melakukan Visualisasi Data.\nDengan Google Looker Studio, Anda akan memiliki kompetensi sebagai berikut:\nMampu memvisualisasikan data melalui diagram dan tabel yang sangat mudah dikonfigurasi.\nMampu menghubungkan output visualisasi ke sumber data online dengan mudah.\nMampu membagikan analisis dengan tim atau ke seluruh dunia.\nMampu berkolaborasi dalam membuat laporan dengan tim.\nMemiliki kemampuan dalam mempercepat proses pembuatan laporan dengan contoh laporan yang sudah ready to use.\nMampu membuat Visualisasi Data (Data Visualization) yang Interaktif dan Dinamis\nMateri di kelas ini telah saya desain sesuai dengan perkembangan Google Looker Studio Terbaru. So What are you waiting For?\nJoin Kelas ini dan dapatkan kompetensi menjadi seorang Data Visualist.",
      "target_audience": [
        "Mahasiswa atau peneliti ingin menyelesaikan tugas penelitian",
        "Karyawan untuk membuat laporan perusahaan",
        "Data Analyst untuk menyelesaikan Project Analisa Data",
        "Semua orang yang ingin mengupgrade kemampuan analisa data"
      ]
    },
    {
      "title": "Estructuras de Datos en JavaScript",
      "url": "https://www.udemy.com/course/estructuras-de-datos-en-javascript/",
      "bio": "Aprende a implementar Estructuras de Datos en JavaScript",
      "objectives": [
        "Entender la importancia de las Estructuras de Datos",
        "Saber en que situaciones utilizar la estructura de dato correcta",
        "Aprender fundamentos de JavaScript",
        "Mejorar como programador"
      ],
      "course_content": {
        "Introducción a la Programación": [
          "Introducción",
          "Entorno de trabajo",
          "Variables var y let",
          "Constantes",
          "Funciones",
          "Sentencias condicionales: if, else y switch",
          "Sentencia for y while"
        ],
        "Clases y Objetos": [
          "Clase, objeto y constructor",
          "Herencia",
          "La Referencia de un Objeto (Clase muy importante)"
        ],
        "Array (Arreglos)": [
          "¿Qué son los Arrays?",
          "Introducción a Programación funcional",
          "Inmutabilidad",
          "Búsqueda de elemento (Filter)",
          "Transformación de Array (Map)",
          "Operación sobre todos los elementos (Reduce)",
          "Eliminar elementos de un Array"
        ],
        "Json y Promesas": [
          "¿Qué es Json?",
          "Promise (promesas)",
          "Api fetch",
          "Async y await",
          "Json y JavaScript",
          "Object literals (objetos literales)"
        ],
        "Stack (Pila)": [
          "¿Qué es una Pila?",
          "Implementación de Pila",
          "Ejemplo de Pila"
        ],
        "Queue (Cola)": [
          "¿Qué es una Cola?",
          "Implementación de Cola",
          "Ejemplo de Cola"
        ],
        "Linked List (Lista enlazada)": [
          "¿Qué es una Lista enlazada?",
          "Método Add, Show, Size y Clear de Lista enlazada",
          "Método Delete de Lista enlazada",
          "Ejemplo de Lista enlazada"
        ],
        "Doubly Linked List (Lista doblemente enlazada)": [
          "¿Qué es una Lista doblemente enlazada?",
          "Método Add y Clear",
          "Método Show",
          "Método Delete",
          "Método Reverse",
          "Ejemplo de Lista Doblemente Ligada"
        ],
        "Árboles (Árbol binario de búsqueda)": [
          "¿Qué es un árbol?",
          "Implementación de árbol binario de búsqueda, método insert y search",
          "Recursividad",
          "Recorrido en profundidad InOrder",
          "Recorrido en profundidad PreOrder",
          "Recorrido en profundidad PostOrder",
          "Ejemplo de árbol"
        ],
        "Map": [
          "¿Qué es Map?",
          "Ejemplo de Map"
        ]
      },
      "requirements": [
        "Saber utilizar una computadora"
      ],
      "description": "Las Estructuras de datos son parte esencial en cualquier lenguaje de Programación.\nEn las tareas de todos los días como programador, es valioso conocer estructuras de datos, pero también es valioso saber en que situaciones utilizar una u otra.\nEn este curso nos enfocaremos a entender como es la implementación de las estructuras de datos.\nCrearemos Estructuras de datos, y también aplicaremos estás a ejemplos para poder llevar el aprendizaje a un marco realista.\nTambién el curso cuenta con una introducción al lenguaje de Programación JavaScript, esto, para evitar falta de entendimiento en los temas a tratar.\nJavaScript fue seleccionado ya que no se necesita instalar prácticamente nada para comenzar a programar, solo se necesita de un navegador y un editor de texto, software que ya tienes instalado en Windows, Linux o Mac.\nAl final, con este curso comprenderás más a fondo lo que implica estar manejando información en distintas estructuras de datos, los problemas que puedes enfrentarte, y sobre todo, entender la importancia de saber Estructuras de Datos.\nEl hecho de ver este curso en JavaScript, no te enfoca a que entiendas solo estas Estructuras de Datos en este lenguaje de programación, la enseñanza en el curso se enfoca por el concepto, por lo cual, una vez entendiendo el concepto del temario, no debería ser para ti complicado aplicarlo a otros lenguajes de Programación.\nEspero que este curso cumpla con tus expectativas para mejorar como Programador.",
      "target_audience": [
        "A todo el que desee abordar las estructuras de datos"
      ]
    },
    {
      "title": "Basics of Lakehouse Engineering - Iceberg, Nessie, Dremio",
      "url": "https://www.udemy.com/course/basics-of-apache-iceberg-lakehouse-engineering/",
      "bio": "Basics of Being a Lakehouse Data Engineer",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "None"
      ],
      "description": "Welcome to \"Basics of Lakehouse Engineering - Iceberg, Nessie, Dremio\"! This course is designed for aspiring data engineers who want to dive into the fundamentals of data engineering within the context of an open lakehouse architecture. You'll gain a comprehensive understanding of key technologies like Apache Iceberg, Nessie, and Dremio, and how they work together to revolutionize data management.\n\n\nWhat You'll Learn:\n\n\nIntroduction to Lakehouse Architecture: Understand the principles of lakehouse architecture and its advantages over traditional data warehouses and data lakes.\nApache Iceberg: Explore the basics of Apache Iceberg, a high-performance table format for huge analytic datasets.\nProject Nessie: Learn about Project Nessie, a Git-like experience for data, providing version control for your data lake.\nDremio: Discover how Dremio integrates with Iceberg and Nessie to deliver lightning-fast queries and an optimal analytics experience.\nHands-on Setup: Set up a local environment to get hands-on with these technologies, including Docker configurations and initial setup steps.\nBasic SQL with Iceberg Tables: Perform basic SQL operations on Iceberg tables to understand data manipulation and querying in a lakehouse context.\n\n\nWhy Take This Course?\n\n\nThis course is ideal for data engineering beginners and professionals who want to expand their skill set with modern, open-source technologies. By the end of the course, you'll be equipped with the knowledge and practical skills to set up and manage an open lakehouse environment, leveraging the power of Iceberg, Nessie, and Dremio for your data engineering projects.\n\n\nJoin us on this exciting journey to master the basics of lakehouse engineering and pave the way for a successful career in data engineering!",
      "target_audience": [
        "Aspiring Data Engineers"
      ]
    },
    {
      "title": "Statistik für Data Science und Business Analytics",
      "url": "https://www.udemy.com/course/wahrscheinlichkeit-und-statistik/",
      "bio": "Lerne, wie Du Statistik und Wahrscheinlichkeiten auf praxisnahe Data Science und Business Fälle anwenden kannst.",
      "objectives": [
        "Grundlagen der Wahrscheinlichkeitsrechnung",
        "In der Lage sein, verschiedene Arten von Daten zu verstehen",
        "In der Lage sein, grundlegende Statistiken zu implementieren",
        "Anwendung statistischer Methoden und Hypothesentests auf Unternehmensprobleme",
        "Regressionsmodelle anwenden",
        "Implementierung von Ein- und Zwei-Wege-Anova",
        "Anwenden des Chi Squared Tests"
      ],
      "course_content": {},
      "requirements": [
        "Stift und Papier zum mitschreiben",
        "Optional: Excel, R oder Python für die Simulationen",
        "Dieser Kurs startet bei Null."
      ],
      "description": "Willkommen im Kurs Wahrscheinlichkeit und Statistik - für Business and Data Science!\n\n\nIn diesem Kurs zeigen wir dir was du über Wahrscheinlichkeit und Statistik wissen musst, um in der Wirtschaft, aber vor allem im Bereich Data Science und Machine Learning, erfolgreich zu sein! Wir haben dazu viele Übungen und Formelerklärungen für dich!\nAls erstes klären wir, was Daten sind und welche Zusammenhänge, Abweichungen und Korrelationen man sich anschauen sollte. Das ist die Vorraussetzung um Statisitk anwenden zu könnnen und um erfolgreich Data Science Projekte implementiere zu können.\nDanach werden wir in die Wahrscheinlichkeit eintauchen und mehr über Kombinationen und Permutationen erfahren, die dir als Data Scientist weiterhelfen um die Anzahl an Kombinationen von Daten und damit die z.B. die Datenmenge abschätzen zu können.\nAnschließend diskutieren wir die gängigsten Verteilungen in der Statistik und schaffen eine solide Grundlage für das Verständnis, wie man mit Gleich-, Binomial, Poisson- und Normalverteilungen arbeitet.\nAls nächstes werden wir reale Geschäftsfälle durchgehen, einschließlich Hypothesentests und der studentschen T-Verteilung - so kannst du das Gelernte gleich anwenden.\nAbschließend behandeln wir drei Datenanalyse-Verfahren, wie ANOVA (Varianzanalyse), Regressionsanalyse  und schließlich der Chi-Quadrat-Analyse.\nDie Abschnitte sind modular und nach Themen gegliedert, so dass du sie nach Bedarf suchen kannst und direkt dort einsteigen kannst!\nWichtig: Falls du die Simulationen selber ausführen möchtest, so benötigst du Kenntnisse von Excel, R oder Python. Bei Bedarf kannst du R oder Python mit Hilfe der dazu vorgesehenen Kurse aus unserem Kursangebot erlernen.\nUnser Kurs beinhaltet HD-Videos mit Erklärungen zu Formeln, Animationen und Übungen, wir behandeln außerdem Fallstudien, die dir zeigen, wie du dieses Wissen in der Praxis anwenden kannst. Du findest reines Formellernen staubtrocken? Kein Thema, bei uns gibt es eine gute Mischung!\nKursinhalt im Überblick:\nMessungen von Daten\nMittelwert, Median und Modus\nAbweichung und Standardabweichung\nKovarianz und Korrelation\nPermutationen und Kombinationen\nVerbindungen und Kreuzungen\nBedingte Wahrscheinlichkeit\nBayes-Satz\nBinomiale Verteilung\nPoisson-Verteilung\nNormalverteilung\nProbenahme\nZentraler Grenzwertsatz\nHypothesentest\nT-Verteilungsprüfung\nRegressionsanalyse\nANOVA\nChi Quadrat-Analyse\n\n\nAlle diese Inhalte sind mit einer 30-tägigen Geld-zurück-Garantie ausgestattet, so dass Du den Kurs risikofrei ausprobieren kannst!\nWorauf wartest du noch? Melde Dich noch heute an und werde ein Profi im Umgang mit Wahrscheinlichkeiten und Statistiken.",
      "target_audience": [
        "Jemanden, der daran interessiert ist, wie man Wahrscheinlichkeit und Statistik auf die Wirtschafts- oder Data Science Fälle anwendet.",
        "Für Einsteiger oder erfahrene, die Grundkonzepte der Statistik wiederholen möchten."
      ]
    },
    {
      "title": "Master of Prayers : In-depth Prayer Analysis",
      "url": "https://www.udemy.com/course/master-of-prayers-in-depth-prayer-analysis/",
      "bio": "Processing Prayers",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "No praying or spiritual experience is needed.",
        "No previous programming required"
      ],
      "description": "Develope processing skills through the development of prayers.\nHello, my name is Alin and I am an author of prayer books.\nI will teach you how to develope prayers based on problems and how to analyze the request.\nWe will verify status, a self description is needed, time when you saw flaws in others has passed, during\nthis it is easy to make not just a proper image of self, but now you are able to analyze your construction, behaviour,\nneeds and why and towards what are you tempted to.\nSo why it is happening in an order that first it seems you cannot control.Some make morning prayers requesting God\nto make sure and protect a schedule or that nothing interferes with the goal of the day.\nThis works, and in some cases along with the morning prayers you trigger an expectation that is tangent to an act of\n\"lets verify if your morning prayer is working\"\nDo not fear, you will gain full responsability if and when you communicate with Lord Jesus or God. I want to\nunderline that it doesn't hurts and it doesn't hurts to socialise with others even knowing that your daily\nprogram contains also prayers. I mean, you can use technology to make comparison between prayers, like a computer and after you write\nthem down you will observe minimum similarity and an advancement. Building your relationship with God is based on love.\nPrayer to a higher lever is also love.\nWhat is the key?\nBy respecting laws automatically, lets you acces a focus state from which you start to construct your prayers, you are active,\nyou have more than faith.\nyou ask yourself:\"What am I gonna do with prayers?\"\nAware and Management of Achievement Progress in you and others.\nPrayers can range from a letter , to full Script Analysis. Do not be stressed about the prayer length, enjoy the focus state\nof directly developing and generating the prayer.\nImagine God of that best friend CEO teacher there to share ideas.\nThank you and I'll see you in the further lessons.",
      "target_audience": [
        "Analysts"
      ]
    },
    {
      "title": "Искусственный интеллект и Машинное обучение + Основы Python",
      "url": "https://www.udemy.com/course/ai-machinelearning-ru/",
      "bio": "Научитесь понимать технологии ИИ, Машинное обучение и Нейронные Сети, а также основы Программирования на Python",
      "objectives": [
        "Сможете различать между Машинным и Глубинным обучением и Нейронными сетями",
        "Узнаете, в каких областях применяются технологии Искусственного интеллекта и Машинного обучения, и что ждет ИИ в будущем",
        "Сможете решать простые Реальные Задачи с использованием Алгоритмов Машинного Обучения в Excel и Python",
        "Научитесь Основам Программирования на Python",
        "Узнаете где находить Данные и Датасеты",
        "Построите Нейронные Сети для Предсказания Изображений и Анализа Текстов",
        "Создадите свои Модели Машинного обучения для решения задач"
      ],
      "course_content": {
        "Введение": [
          "Введение",
          "История развития Искусственного интеллекта"
        ],
        "Основные понятия": [
          "Различие между ИИ, Машинным обучением и Глубоким Обучением",
          "Примеры использования ИИ, МО и ГО в различных областях"
        ],
        "Основные задачи и методы Машинного обучения": [
          "Обучение с учителем и Обучение без учителя (Supervised vs Unsupervised learning)",
          "Регрессия. Метод наименьших квадратов. Пример решения в Excel.",
          "Классификация.",
          "Метод k-ближайших соседей. Решение задачи классификации.",
          "Кластеризация."
        ],
        "Ансамблирование в машинном обучении": [
          "Ансамбли.",
          "Комитет большинства.",
          "Бэггинг.",
          "Случайный лес"
        ],
        "Будущее Искусственного Интеллекта и завершение Теоретической части курса": [
          "Будущее Искусственного интеллекта"
        ],
        "Основы Программирования на Python": [
          "Для тех, кто знает основы Python",
          "Установка Python. Дистрибутив Anaconda.",
          "Базовые команды в Python",
          "Оператор If - Else",
          "Оператор While. Функция Input",
          "Строки",
          "Списки и операции с ними",
          "Словари и операции с ними"
        ],
        "Построение моделей Машинного обучения в Python": [
          "Предсказание цен на квартиры с помощью метода линейной регрессии",
          "Предсказание ВВП от цен на нефть с помощью Линейной Регрессии",
          "Выжившие на Титанике. Модель классификации с помощью Метода Опорных Векторов",
          "Выжившие на Титанике. Модели Дерева решений, Случайного леса и Бэггинга"
        ],
        "Строим Нейронные Сети в Python": [
          "Нейронные сети. Предсказание изображений одежды.",
          "Нейросети для Анализа Текстов",
          "Нейросети для Анализа Тональности Отзывов"
        ],
        "Бонус. Где находить Данные для Машинного обучения": [
          "Открытые Датасэты для задач Машинного Обучения"
        ],
        "БОНУС II. Нейросети для всех задач - анонс": [
          "Анонс нового блока по нейросетям"
        ]
      },
      "requirements": [
        "Вам Необязательно знать математику, статистику или какой-либо язык программирования, чтобы пройти данный курс",
        "Вам Необязательно устанавливать какое-либо программное обеспечение для прохождения курса"
      ],
      "description": "Искусственный интеллект - это уже наше настоящее, с которым мы соприкасаемся каждый день, будь то при поиске в интернете, покупках онлайн, просматривании видео и изображений в социальных сетях, и даже вождении автомобиля. ИИ применяется и в более коммерческих областях и там, где от этого зависят жизни людей, а именно, в медицине, при прогнозировании продаж, космической сфере и строительстве.\nРаз уж мы окружены технологиями ИИ повсюду, то необходимо иметь представление о том, как они работают. И для такого понимания на базовом уровне необязательно иметь техническое или IT образование.\n***\nВ этом курсе мы расскажем вам об основных понятиях Искусственного Интеллекта и машинного обучения. Вы познакомитесь с основными видами, алгоритмами и моделями, которые используются для решения абсолютно разных задач, и мы даже построим нашу собственную нейронную сеть. Мы даже попробуем создать вместе модели регрессии и классификации для решения конкретных практических примеров в Excel - для тех, кто не хочет ничего программировать. А для тех, кто хочет познакомиться с Python - языком программирования, на котором решается сегодня более 53% всех задач по машинному обучению, в данном курсе вы найдете лекции для ознакомления с основами программирования на этом языке.\n***\nМы вместе составим модели на Python для машинного обучения для:\n- предсказания цен на квартиры\n- предсказания ВВП от цен на нефть\n- предсказания о том, какие из пассажиров выжили на Титанике\n- предсказания что изображено на рисунках с помощью Нейронной Сети!\n- анализ тональность текстов на основе Нейронных сетей!\n- и др.\n**\nЭтот курс может стать своеобразным трамплином для развития вашей карьеры в области Искусственного интеллекта, машинного обучения и больших данных. На его основе вы сможете в дальнейшем выбрать уже ту конкретную область, в которой вы бы хотели развиваться и работать дальше. Нельзя не упоминуть, что специалисты в области ИИ и Big Data сегодня - одни из самых высокооплачиваемых и искомых на рынке (по разным оценкам всего на глобальном рынке сегодня около 300 000 специалистов по ИИ, в то время как спрос на них - несколько миллионов).\n**\nТак почему бы не укрепить свое резюме сертификатом от крупнейшей международной образовательной платформы Udemy о том, что вы прошли данный курс об Искусственном интеллекте и Машинном обучении, и основам программирования на Python.\nПосле прохождения данного курса, вы сможете общаться свободно на темы, касающиеся Искусственного интеллекта, машинного и глубокого обучения, и нейронных сетей. Вы сможете анализировать и визуализировать данные, использовать алгоритмы и нейронные сети для решения задач из разных областей.\n***\nДанный курс содержит более 30 полезных лекций и будет регулярно дополняться новыми лекциями и после зачисления на него у вас будет полноценный доступ ко всем материалам без каких-либо ограничений. Потратьте некоторое время на изучение этого курса, чтобы усилить свои профессиональные навыки и расширить кругозор, используя приобретенные знания.\n***\nПомните, что, покупая этот курс, Вы ничего не теряете. По правилам Udemy, если по каким-либо причинам, Вам не понравится этот курс, Вы можете вернуть все свои деньги в течение 30 дней без каких-либо дополнительных вопросов.",
      "target_audience": [
        "Этот курс будет полезен любому, кому интересны новейшие технологии и кто хочет быть в курсе того, куда движется наша цивилизация",
        "Курс будет полезен тем, кто хочет понять как можно внедрять технологии машинного обучения",
        "Если вы хотите научиться основам программирования на Python, то курс будет Вам полезен",
        "Этот курс будет полезен любому, кто хочет понять как работают Нейронные сети, и алгоритмы Машинного обучения"
      ]
    },
    {
      "title": "RStudio Data Visualization Using ggplot: Biostatistics",
      "url": "https://www.udemy.com/course/rstudio-data-visualization-using-ggplot-biostatistics/",
      "bio": "Learn R Programming and RStudio for Data Science with ggplot | Hands-On Data Visualization in RStudio",
      "objectives": [],
      "course_content": {
        "Introduction to Data Visualization with ggplot2 in RStudio": [
          "Overview of the Course: Data Visualization in RStudio using ggplot",
          "Installing and Loading ggplot2 and Other Essential Libraries",
          "Reading Excel Data into RStudio for Visualization",
          "Quick Summary of Imported Data in RStudio"
        ],
        "Creating Histograms in RStudio with ggplot2": [
          "Histogram of a Continuous Variable in ggplot",
          "Changing Colors in ggplot2 Histograms",
          "Faceting Histograms by a Categorical Variable in ggplot2",
          "Adding a Normal Curve to a Histogram in ggplot2",
          "Adding Labels to Histograms in ggplot2"
        ],
        "Creating and Customizing Boxplots in RStudio with ggplot2": [
          "Creating a Basic Boxplot in ggplot",
          "Exploring geom_boxplot() Options in ggplot",
          "Setting Labels in ggplot2 Boxplots",
          "Boxplot by a Single Categorical Variable in ggplot",
          "Export the graph in a folder",
          "Boxplot by Two Categorical Variables in ggplot"
        ],
        "Violin Plot in RStudio with ggplot2": [
          "Creating a Basic Violin Plot in ggplot",
          "Customizing Violin Plot Appearance",
          "Violin Plot in RStudio with ggplot2 by Two Categorical Variables"
        ],
        "Scatter Plot in RStudio using ggplot2": [
          "Creating Scatter Plot in RStudio using ggplot2",
          "Creating Scatter Plot in RStudio using ggplot2 by a Categorical Variable"
        ],
        "Bar Diagram in RStudio using ggplot2": [
          "Bar Diagram of a Binary Variable by a Categorical Variable in RStudio",
          "Bar Diagram of a Binary Variable by Two Categorical Variables in RStudio"
        ],
        "Heatmaps in RStudio with ggplot2: Visualise Correlation matrix": [
          "Heatmap for Multiple Continuous Variables in RStudio using ggplot2"
        ]
      },
      "requirements": [
        "Basic knowledge of R programming",
        "Familiarity with RStudio environment and running simple R scripts",
        "Interest in data analysis or data science concepts"
      ],
      "description": "Take your data analysis and reporting skills to the next level with Data Visualization in RStudio using ggplot2, the industry-standard package for creating high-quality, publication-ready graphics. This course is designed for data analysts, researchers, statisticians, and professionals who have a basic understanding of R programming and want to elevate their visualization techniques for deeper insights and more persuasive communication.\nYou will learn to create, customize, and interpret a wide variety of visualizations, including histograms, boxplots, scatter plots, bar charts, density plots, and faceted graphics. Special attention is given to working with both continuous and categorical variables, adjusting bin widths, changing colors and fills, setting labels, titles, captions, and themes, and overlaying normal curves and statistical summaries to highlight trends and differences across groups.\nThe course also covers practical steps such as importing data from CSV and Excel files, performing quick data summaries and structure checks, and using the powerful grammar of graphics framework that underpins ggplot2. You will learn how to detect and display outliers, facet plots for grouped comparisons, and export visuals in high-resolution formats suitable for reports, presentations, and research publications.\nBy the end of this course, you will be able to transform complex datasets into clear, impactful visual narratives, making your analyses more insightful and your communication more professional with ggplot2 in",
      "target_audience": [
        "Students of Data Science and Analytics who want to build strong visualization skills in RStudio",
        "Researchers, statisticians, and academics who need to create clear, publication-ready charts and graphs"
      ]
    },
    {
      "title": "米国データサイエンティストがやさしく教えるデータサイエンスのためのPython講座",
      "url": "https://www.udemy.com/course/ds_for_python/",
      "bio": "データサイエンスのプロが現場目線で徹底的にわかりやすく教えます．ここでしか学べない実践的な内容です．",
      "objectives": [
        "Pythonの基礎, NumPy, Pandas, Matplotlib, Seaborn, JupyterLab, OpenCV...etc",
        "DockerコンテナとJupyterLabを使った超本格的な環境構築",
        "ここでしか学べないデータサイエンスのためのPythonを学べます．"
      ],
      "course_content": {
        "紹介": [
          "コースの紹介となぜPythonを学ぶのか",
          "本講座の資料"
        ],
        "環境セットアップ": [
          "環境概要(Docker+JupyterLab)",
          "Docker準備",
          "Windowsユーザの方への補足",
          "環境構築(Dockerを使えば超簡単！)",
          "Dockerの基本操作",
          "次レクチャーの補足",
          "JupyterLabの基本操作"
        ],
        "Pythonの基礎": [
          "DataType",
          "演算子",
          "if文",
          "loop処理",
          "iterableとiterator",
          "関数",
          "mutableとimmutable",
          "lambda関数",
          "Exercise!関数を作ってみよう",
          "*argsと**kwargs",
          "本セクション振り返り"
        ],
        "NumPy": [
          "NumPyとは",
          "NumPy Array",
          "Broadcasting",
          "shape",
          "IndexingとSlicing",
          "数値のArrayを関数で作成(arange, linspace, logspace)",
          "行列生成 (zeros, ones, eye)",
          "乱数生成 (np.random)",
          "統計量",
          "数学で使える便利関数",
          "NumPyでのNaNの扱い",
          "NumPy Arrayの条件フィルターの使い方",
          "結合と転置",
          "NumPy Arrayの保存とロード",
          "本セクション振り返り"
        ],
        "Pandas": [
          "Pandasとは",
          "Seriesを作る",
          "DataFrameを作る",
          "DataFrameの基本操作",
          "DataFrameのフィルタ",
          "DataFrameのIndex操作",
          "次回レクチャーの補足",
          "DataFrameでのNaNの取り扱い",
          "次回レクチャーの補足",
          "group by",
          "表結合",
          "便利関数",
          "DataFrameのイテレーション",
          "ピボットテーブルの作り方",
          "DataFrameをCSVファイルで保存する",
          "本セクション振り返り"
        ],
        "Matplotlib": [
          "Matplotlibとは",
          "Matplotlibのstyle変更",
          "Exercise!plotしてみよう！",
          "複数のplotを描画する",
          "散布図(scatterplot)",
          "ヒストグラム(hist)と棒グラフ(bar)",
          "箱ひげ図(boxplot)",
          "plotを保存する(pngとpdf)",
          "本セクション振り返り"
        ],
        "Seaborn": [
          "ヒストグラム(distplot)",
          "前レクチャーの補足",
          "pariplot",
          "categorical plot",
          "heatmap",
          "Seabornのスタイル変更",
          "本セクション振り返り"
        ],
        "その他のデータサイエンスに使えるライブラリ": [
          "OpenCVを使ってみる",
          "OpenCVで画像処理をしてみよう",
          "次レクチャーでDLするデータについて",
          "ファイルパスのリストを取得する(glob)",
          "ファイルパスを安全に操作する(os & pathlib)",
          "プログレスバーを表示する(tqdm)",
          "CTデータを扱う(nibabel)",
          "並列処理(multiprocessing)",
          "関数を別ファイルから呼び出す(autoreload)",
          "本セクション振り返り"
        ],
        "演習セクション：CT画像のVisualizationを作る": [
          "概要",
          "ファイルパスをDataFrameにする",
          "NIfTIファイルをNumPy Arrayとしてロードする",
          "ラベルマスクをRGBの3チャネルに変換する",
          "HUをグレースケールに変換する",
          "Overlay(CTとアノテーションの重ね合わせ)",
          "スライスを一覧で表示する",
          "各plotに情報を表示する",
          "おまけ：HU windowを設定する",
          "本セクション振り返り"
        ],
        "ボーナスセクション": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "mac推奨",
        "少しのプログラミングの知識(Pythonの経験があるとなお◎ですが，他言語でもOK)"
      ],
      "description": "大好評\"米国データサイエンティストかめ\"による動画講座第二弾です！\nわかりやすい！ - Pythonの基礎からPythonでデータサイエンスをするのに必要な基本的なライブラリをわかりやすく説明します!\n実践的! - 教科書的な内容ではなく，実際のデータサイエンスの現場でどう使うのかを解説しながら丁寧に教えます．\n汎用的! -実際にコードを書きながら進めていきますので，コードの書き方とプロの考え方が学べます．\n本格的! -コーディング環境も，Docker＋JupyterLabを使った本格的なものになっています．なお，どちらも必要最低限のことは講座で教えるので，知識ゼロから始められます．\nおもしろい！-映画レビューデータセットとCOVID-19のCTデータを使って解説していきます．\nハンズオン! - 講座内に散りばめられた演習を実際にハンズオンでやることで，学習内容が定着するカリキュラムになっています．\n\n\n以下は本講座で使用するライブラリ・ツールです．\n-Pythonの基礎\n-NumPy\n-Pandas\n-matplotlib\n-Seaborn\n-OpenCV\n-nibabel\n-その他Pythonモジュール(multiprocessing, glob, tqdmなど)\n-Docker\n-JupyterLab\n\n\nPython × データサイエンスは現代で最もホットな学習領域の１つです．本講座から「Python × データサイエンス」をはじめよう！\n(※本講座はMac推奨です．Windowsでも，「Dockerがうごかせる」もしくは「Jupyterを動かせる」人は問題なく講座を進めることができますが，Windowsの環境構築はサポートしておりません．)\n(※講座の特に最後のセクションでは，３次元のCTデータを扱うため，メモリが枯渇する場合があります．おそらく16GBあればなんとか実行できると思いますが，もしメモリが足りない人は適宜データ量を落として実行してください．)\n大好評の「米国AI開発者がゼロから教えるDocker講座」もよろしくお願いします！",
      "target_audience": [
        "データサイエンスに興味を持っているプログラミング初心者",
        "体系的にデータサイエンスのためのPythonを学びたい人",
        "将来データサイエンスやAI開発に携わりたい人",
        "Pythonでデータ処理をしたい人"
      ]
    },
    {
      "title": "아빠가 들려주는 [데이터 수집과 정리의 기본]",
      "url": "https://www.udemy.com/course/data_basic/",
      "bio": "반드시 알야야 하는, 그러나 상당수가 모르는 내용",
      "objectives": [
        "데이터를 효과적으로 수집하는 방법",
        "데이터 분석하기 좋도록 데이터를 정리하는 방법",
        "잘못된 데이터를 예방하고 찾고 수정하는 방법"
      ],
      "course_content": {
        "소개": [
          "자동 채우기. 상대참조. 절대참조",
          "알기쉬운 데이터 이름 붙이기",
          "잘못된 데이터 예방하기",
          "데이터 골라 내기",
          "찾고 바꾸기, 딱 하나의 함수 IF",
          "중복된 데이터를 삭제하고, 합치기(실험실 데이터의 예)",
          "편리하게 인터넷으로 조사해 보자(지금은 없어진 네이버 폼)",
          "편리하게 인터넷으로 조사해 보자(구글 설문지)",
          "엑셀로 설문지 만들고 편리하게 수집하기",
          "워드(MS word)로 설문지 만들고 편리하게 수집하기",
          "말썽많은 날짜 데이터 완전 정복"
        ]
      },
      "requirements": [
        "엑셀, 인터넷 연결"
      ],
      "description": "도대체 그 많은 시간동안 엑셀 쓰면서 어떻게 이것도 모른다는 거지- 이해가 안되기도 하고,\n이걸 모르고 그 동안 얼마나 고생했을까 생각하니 불쌍하기도 해서 만든 강의\n\n\n수많은 엑셀 기능 중에서 이것은 그래도 반드시 알아야 한다고 생각되는 기능들만\n고르고 골라서 만들었습니다.\n이해하기도 쉽고, 활용하기도 쉬운,\n알면 상당히 많은 시간을 절약할 수 있는\n그런데도 잘 모르고 있는 것들만 골랐습니다.\n\n\n이것만이라도 알아야 데이터 정리하고, 분석하기에 편리합니다.\n(일반 엑셀 강의에서 다루는 내용과 다릅니다. 대부분의 기능들 다루지 않습니다.\n여러 해의 강의를 통해서 고르고 걸러서 핵심적인 것만 다룹니다.)",
      "target_audience": [
        "학교 선생님",
        "의학 연구자(의사, 치과의사, 간호사, 한의사, 수의사, 물리치료사, 방사선사 등)",
        "데이터를 다루는 공무원 및 연구자"
      ]
    },
    {
      "title": "Python'a Geçmeden Temel İstatistik İle Veri Biliminin Keşfi",
      "url": "https://www.udemy.com/course/pythona-gecmeden-temel-istatistik-ile-veri-biliminin-kesfi/",
      "bio": "Python Programlama Dili Ve Machine Learning’e Geçmeden Önce Veri Analizini, Temel İstatistiği Derinlemesine Öğrenin",
      "objectives": [
        "Veri Bilimi Nedir?",
        "Veri Biliminin Bileşenleri Nelerdir?",
        "Veri Bilimi İle Ne Yapmayı Amaçlıyoruz?",
        "Veriden Anlamlı Bilgiyi Nasıl Çıkarırız?",
        "Veri Biliminde Proje Süreci Nasıl İşliyor?",
        "Gerçek Hayattan Projeler İle Kavramların Pekiştirilmesi",
        "Gerçek Hayattan Örneklere Devam",
        "Kurstan En İyi Şekilde Nasıl Verim Alabilirim?",
        "Meraklılarına Doküman Tavsiyeleri",
        "Veriyi Görmek Ve Okumak Nasıl Olur?",
        "Popülasyon Ve Örneklem",
        "Gözlem Birimi",
        "Değişken Ve Türleri",
        "Ölçek Türleri",
        "Aritmetik Ortalama",
        "Medyan",
        "Mod",
        "Çeyrekler",
        "Merkezi Eğilim Neden Önemlidir?",
        "İstatistikte Veri Desenleri",
        "Değişim Aralığı",
        "Standart Sapma",
        "Varyans",
        "Standart Hata",
        "Çarpıklık",
        "Basıklık",
        "İstatistiksel Düşünce Modelleri Ve Bileşenlerinin İncelenmesi",
        "Verinin Belirlenmesi Ve Tanımlanması",
        "Verinin Düzenlenmesi Ve Planlanması",
        "Verinin Gösterimi",
        "Verinin Gösterimi – Frekans Tablosu",
        "Verinin Gösterimi – Histogram",
        "Verinin Gösterimi – Pasta Grafik",
        "Verinin Gösterimi – Çubuk Grafik",
        "Verinin Gösterimi – Çizgi Grafik",
        "Verinin Çözümlenmesi Ve Yorumlanması",
        "Python",
        "Deep Learning ( Derinlemesine Öğrenme )",
        "Machine Learning ( Makine Öğrenmesi )",
        "Yapay Zeka",
        "İstatistik"
      ],
      "course_content": {
        "Veri Bilimini(Data Science) Tanıma ve Motivasyon": [
          "Veri Bilimi Nedir?",
          "Python Veri Bilimi Hakkında Sık Sorulan Sorular",
          "Veri Biliminin Bileşenleri Nelerdir?",
          "Veri Bilimi İle Ne Yapmayı Amaçlıyoruz?",
          "Veriden Anlamlı Bilgiyi Nasıl Çıkarırız?",
          "Veri Biliminde Proje Süreci Nasıl İşliyor?",
          "Gerçek Hayattan Projeler İle Kavramların Pekiştirilmesi",
          "Gerçek Hayattan Örneklere Devam",
          "Kurstan En İyi Şekilde Nasıl Verim Alabilirim?",
          "Meraklılarına Doküman Tavsiyeleri",
          "Quiz-1"
        ],
        "Veri Analizi İle Birlikte Veriyi Tanıma": [
          "Veriyi Görmek Ve Okumak Nasıl Olur?",
          "Popülasyon Ve Örneklem",
          "Gözlem Birimi",
          "Değişken Ve Türleri",
          "Ölçek Türleri",
          "Veri Bilimi Quiz"
        ],
        "Veri Analizinde Merkezi Eğilim Ölçüleri": [
          "Aritmetik Ortalama",
          "Medyan",
          "Mod",
          "Çeyrekler",
          "Merkezi Eğilim Neden Önemlidir?",
          "İstatistikte Veri Desenleri",
          "Veri Bilimi Quiz"
        ],
        "Veri Analizinde Merkezi Dağılım Ölçüleri": [
          "Değişim Aralığı(Range)",
          "Standart Sapma",
          "Varyans",
          "Standart Hata",
          "Çarpıklık(Skewness)",
          "Basıklık(Kurtosis)",
          "Veri Bilimi Quiz"
        ],
        "İstatistiksel Düşünce Modelleri Ve Bileşenleri": [
          "İstatistiksel Düşünce Modelleri Ve Bileşenlerinin İncelenmesi",
          "Veri Bilimi Quiz"
        ],
        "Veri Biliminde(Data Science) Mooney Modeli Basamaklarını Uygulama": [
          "Verinin Belirlenmesi Ve Tanımlanması",
          "Verinin Düzenlenmesi Ve Planlanması",
          "Verinin Gösterimi",
          "Verinin Gösterimi – Frekans Tablosu",
          "Verinin Gösterimi – Histogram",
          "Verinin Gösterimi – Pasta Grafik",
          "Verinin Gösterimi – Çubuk Grafik",
          "Verinin Gösterimi – Çizgi Grafik",
          "Verinin Çözümlenmesi Ve Yorumlanması",
          "Veri Bilimi Quiz"
        ],
        "Extra": [
          "Python'a Geçmeden Temel İstatistik İle Veri Biliminin Keşfi"
        ]
      },
      "requirements": [
        "Kurs videolarını eksiksiz, sonuna kadar ve sırayla izlemek.",
        "İnternet Bağlantısı",
        "Cep telefonu, bilgisayar veya tablet gibi dersi izleyebileceğiniz herhangi bir cihaz.",
        "Veri Bilimi, İstatistik, Python, Deep Learning, Machine Learning Öğrenme kararlılığı ve sabır."
      ],
      "description": "21. Yüzyılın en popüler mesleklerinden birisi olarak görülen veri biliminin temeline inip mantığını kavramaya çalışacağımız bu eğitim ile bir çok gerçek hayat uygulaması üzerinden çalışma yapacağız\nMerhaba Arkadaşlar,\n\nPYTHON'A GEÇMEDEN TEMEL İSTATİSTİK İLE VERİ BİLİMİNİN KEŞFİ kursuna hoşgeldiniz\n\nVeri biliminde Python programlama diline geçmeden önce veri biliminin mantığını öğrenerek \"neyi\", \"neden\" yaptığınızı anlayacaksınız.\nKurs içeriği gerçek hayat senaryoları ile oluşturulmuştur ve sıfırdan başlayanları veri bilimi kapsamında veriyi tanıma ve veri analizi nasıl yapılır bunu öğretecektir.\nEvet, Veri bilimi ihtiyaçlarının 2026 yılına kadar 11,5 milyon iş fırsatı yaratacağını biliyor musunuz?\nVeri bilimi kariyerleri için ortalama maaşın 100.000 dolar olduğunu biliyor musunuz?\nVeri Bilimi Kariyerleri Geleceği Şekillendiriyor.\nVeri bilimi ve Makine öğrenimi olmadan yaşamımızın hayalini kurmak zordur. Kelime tahmin sistemi, e-posta filtreleme ve Amazon'un Alexa'sı ve iPhone'nun Siri'si gibi sanal kişisel yardımcılar, makine öğrenimi algoritmalarına ve matematiksel modellere dayalı olarak çalışan teknolojilerdir.\nVeri bilimi ve Makine öğrenimi yalnızca kelime tahmin sistemi veya akıllı telefon ses tanıma özelliği için fayda sağlamaz. Makine öğrenimi ve veri bilimi, yeni sektörlere ve yeni sorunlara sürekli olarak uygulanır.\nÖzetle Devlet güvenliğinden, günlük hayatta kullandığımız uygulamalara kadar hemen hemen her alanda veri bilimi uzmanlarına ihtiyaç vardır. Milyonlarca işletme ve devlet dairesi, başarılı olmak ve müşterilerine daha iyi hizmet vermek için büyük verilere güveniyor. Dolayısıyla veri bilimi kariyerleri yüksek talep görüyor.\nİşverenin en çok talep ettiği becerilerden birini öğrenmek istiyorsanız?\nVeri Bilimini merak ediyorsanız , Python programlama dili, Machine learning ve deep learning'e geçmeden veri analizinin nasıl yapılacağına görmek istiyorsanız?\nVeri bilimi alanında kendinizi geliştirmek istiyor ve ilk adımı atmak istiyorsanız. Her durumda, doğru yerdesiniz!\n“PYTHONA GEÇMEDEN TEMEL İSTATİSTİK İLE VERİ BİLİMİNİN KEŞFİ” kursunu sizin için tasarladık.\nDerste, gerçek hayattan örnekler ile konuları kavramış olacaksınız. Bu kurs ile adım adım veri analizinin nasıl yapılacağını öğreneceksiniz.\nVeri Bilimi dünyasının kapısını aralayacak ve bundan sonrası için daha derine inme kabiliyetine sahip olacaksınız. Temel istatistik kavramları ile keşifsel veri analizi yapmayı öğreneceksiniz.\nBu veri bilimi kursu herkes içindir!\nDaha önce deneyiminiz yoksa sorun değil! Bu kurs, yeni başlayanlardan profesyonellere kadar herkese (bir tazeleme olarak) öğretmek için ustalıkla tasarlanmıştır.\nKurs süresince aşağıdaki konuları öğreneceksiniz:\nVeri Bilimi Nedir?\nVeri Biliminin Bileşenleri Nelerdir?\nVeri Bilimi İle Ne Yapmayı Amaçlıyoruz?\nVeriden Anlamlı Bilgiyi Nasıl Çıkarırız?\nVeri Biliminde Proje Süreci Nasıl İşliyor?\nGerçek Hayattan Projeler İle Kavramların Pekiştirilmesi\nGerçek Hayattan Örneklere Devam\nKurstan En İyi Şekilde Nasıl Verim Alabilirim?\nMeraklılarına Doküman Tavsiyeleri\nVeriyi Görmek Ve Okumak Nasıl Olur?\nPopülasyon Ve Örneklem\nGözlem Birimi\nDeğişken Ve Türleri\nÖlçek Türleri\nAritmetik Ortalama\nMedyan\nMod\nÇeyrekler\nMerkezi Eğilim Neden Önemlidir?\nİstatistikte Veri Desenleri\nDeğişim Aralığı\nStandart Sapma\nVaryans\nStandart Hata\nÇarpıklık\nBasıklık\nİstatistiksel Düşünce Modelleri Ve Bileşenlerinin İncelenmesi\nVerinin Belirlenmesi Ve Tanımlanması\nVerinin Düzenlenmesi Ve Planlanması\nVerinin Gösterimi\nVerinin Gösterimi – Frekans Tablosu\nVerinin Gösterimi – Histogram\nVerinin Gösterimi – Pasta Grafik\nVerinin Gösterimi – Çubuk Grafik\nVerinin Gösterimi – Çizgi Grafik\nVerinin Çözümlenmesi Ve Yorumlanması\n\n\nGüncel kursum ile kendinizi güncel tutma ve çeşitli veri analizi becerileri ile donatma şansınız olacak. Ayrıca, öğrenmenizi desteklemek ve sorularınızı yanıtlamak için sürekli olarak hazır olacağımı söylemekten mutluluk duyuyorum.\nNeden bu kursu almak istiyorsunuz?\nCevabımız basit: Öğretimin kalitesi.\nİster makine öğrenimi, ister finans alanında çalışıyor olun, ister web geliştirme veya veri bilimi alanında kariyer yapıyor olun, Python ve veri bilimi(Data Science) öğrenebileceğiniz en önemli becerilerden biridir. Python'un basit sözdizimi özellikle masaüstü, web ve iş uygulamaları için uygundur.\nOAK Academy 'deki Python eğitmenleri, yazılım geliştirmeden veri analizine kadar her konuda uzmandırlar ve her seviyedeki öğrencilere yönelik etkili, samimi eğitimleriyle bilinirler.\nEğitmenlerimiz Python programlama dili gibi her alanda yukarıda anlatıldığı şekilde eğitim kalitesi sunmaktadır.\nLondra merkezli OAK Academy, çevrimiçi bir eğitim şirketidir. OAK Academy, 1000 saatin üzerinde video eğitim derslerinin bulunduğu Udemy platformunda Bilişim, Yazılım, Tasarım, İngilizce, Portekizce, İspanyolca, Türkçe ve bir çok farklı dilde geliştirme alanında eğitim vermektedir. OAK Akademi, yeni dersler yayınlayarak hem eğitim seri sayısını artırmakta hem de güncellenerek daha önce yayınlanmış derslerin tüm yeniliklerinden öğrencilerini haberdar etmektedir.\nKaydolduğunuzda, OAK Academy'nin deneyimli geliştiricilerin uzmanlığını hissedeceksiniz. Öğrencilerin hocalarımıza ilettikleri sorular hocalarımız tarafından en geç 48 saat içerisinde cevaplanmaktadır.\nVideo ve Ses Üretim Kalitesi\nTüm videolarımız, size en iyi öğrenme deneyimini sağlamak için yüksek kaliteli video ve ses olarak oluşturulur/üretilir.\nBu kursta şunlara sahip olacaksınız:\nKursa Ömür Boyu Erişim\nSoru-Cevap bölümünde Hızlı ve Kolay Destek\nİndirilmeye Hazır Udemy Bitirme Sertifikası\nHer türlü soruyu yanıtlayarak tam destek sunuyoruz.\n“PYTHON'A GEÇMEDEN TEMEL İSTATİSTİK İLE VERİ BİLİMİNİN KEŞFİ” kursu.\nHemen gelin! Kursta görüşürüz!",
      "target_audience": [
        "Veri bilimi ile ilgilenen herkes",
        "Veri bilimi alanında kendini geliştirmek isteyenler.",
        "Veri bilimi için programlama diline geçmeden önce veri biliminin genel mantığını anlamak isteyenler",
        "Veri bilimi alanında kariyer hedefi olanlar"
      ]
    },
    {
      "title": "Mastering Pandas in Python",
      "url": "https://www.udemy.com/course/mastering-pandas-in-python/",
      "bio": "Mastering Pandas in Python. Learn everything you need as a developer, data scientist or ML engineer",
      "objectives": [],
      "course_content": {
        "Course": [
          "Introduction",
          "Read and Write Excel Files",
          "Read and Write CSV Files.",
          "Basic Pandas Operations",
          "Filtering out rows and columns",
          "Manipulating data",
          "Combining Data",
          "Plots using Pandas",
          "Pandas Summary Statistics",
          "FREE COURSES"
        ],
        "Full Course Video to Download": [
          "Download this"
        ]
      },
      "requirements": [
        "Basic knowledge of python need. Import package, dictionary, variables... Got free course teaching all the basics in 1 hour FREE."
      ],
      "description": "Unlock the power of data manipulation and analysis with our free Udemy course, \"Mastering Pandas in Python.\"  This comprehensive online course is designed to equip you with the essential skills needed to become a proficient data analyst using the Pandas library in Python.\nPositive Aspects:\nComprehensive Curriculum: Our course covers Pandas from the ground up, making it suitable for beginners and intermediate learners. It includes topics like data structures, data cleaning, filtering, grouping, and advanced data analysis techniques.\nHands-On Practice: Throughout the course, you'll have access to numerous practical exercises and real-world projects that reinforce your understanding and provide valuable experience.\nExperienced Instructors: Learn from seasoned instructors with expertise in data analysis and Pandas. They provide clear explanations and share best practices, ensuring you grasp each concept effectively.\nFree Access: The course is completely free, making it accessible to learners from all backgrounds. You can upgrade to a paid version for additional features, but the core content is available at no cost.\nReasons to Get It:\nLearn a Critical Skill: Pandas is an indispensable tool in data analysis, and mastering it can open doors to lucrative career opportunities in fields like data science and business intelligence.\nCost-Efficient: This course is an excellent starting point for individuals who want to learn Pandas without the financial commitment of a paid course.\nHands-On Experience: Gain practical experience by working on problems encountered in industry.\nFlexible Learning: Access the course content at your own pace, allowing you to balance your learning with other commitments.\nIn conclusion, the \"Mastering Pandas in Python\" free Udemy course is a valuable resource for anyone looking to enhance their data analysis skills. It offers a comprehensive curriculum, hands-on practice, and the flexibility to learn at your own pace. While it lacks some of the benefits of paid courses, it's an excellent starting point for those on a budget or exploring Pandas for the first time.",
      "target_audience": [
        "Beginner programmers",
        "Beginner python developers"
      ]
    },
    {
      "title": "Machine Learning | Python ile Makine Öğrenmesi (2024)",
      "url": "https://www.udemy.com/course/machine-learning-python-ile-makine-ogrenmesi/",
      "bio": "Python'ın temellerinden başlayarak Machine Learning algoritmalarının temel mantığını öğrenin!",
      "objectives": [
        "Python temellerini neyi neden yazdığınızı anlayarak öğreneceksiniz.",
        "NumPy, Pandas ve Matplotlib kütüphanelerini Machine Learning için gerekli düzeyde öğrenmiş olacaksınız.",
        "Yapay Zeka, Makine Öğrenmesi ve Derin Öğrenme konusunda bilgi sahibi olacaksınız.",
        "Temel Machine Learning algoritmalarını mantığıyla birlikte öğrenmiş olacaksınız.",
        "Data ön işleme konusunun temellerini öğreneceksiniz.",
        "Regression, Classification, Clustering ve Natural Language Processing(NLP) gibi Machine Learning'in temel konularını öğrenmiş olacaksınız.",
        "K-Fold Cross Validation ve Grid Search gibi yöntemlerle Machine Learning modellerinizi nasıl geliştireceğinizi göreceksiniz."
      ],
      "course_content": {
        "Gerekli Ortamların Kurulması (Windows)": [
          "Anaconda'nın Kurulumu (Windows)",
          "Activation Hatası",
          "Path Hatası",
          "Anaconda ve Jupyter Notebook Kullanımı (Windows)",
          "Duyuru!"
        ],
        "Gerekli Ortamların Kurulması (MacOS)": [
          "Anaconda'nın Kurulumu ve Kullanımı(MacOS)",
          "Jupyter Notebook'un Kullanımı (MacOS)"
        ],
        "***** Python Temelleri (Opsiyonel) *****": [
          "Python Temelleri (Opsiyonel)"
        ],
        "PyCharm Kurulumu": [
          "PyCharm Kurulumu ve Kullanımı (Windows)",
          "PyCharm Kurulumu ve Kullanımı (MacOS)",
          "PyCharm Interpreter Hatası"
        ],
        "Temel Veri Tipleri": [
          "Bölümde Kullanılan Dosyalar",
          "Python IDLE",
          "Programlama ya da Yazılım Nedir?",
          "Sayılar ve Temel Matematik Operatörleri",
          "Değişkenler Konusu",
          "Diğer Matematik Operatörleri",
          "Stringlere Giriş",
          "Veri Tipi Dönüşümleri ve Print Fonksiyonu",
          "Bazı Faydalı Bilgiler",
          "Kullanıcıdan Veri Alma",
          "Eval Fonksiyonu",
          "Programlama Neden Önemli?",
          "Kodlama Egzersizleri - Temel Veri Tipleri"
        ],
        "İleri Seviye Veri Tipleri": [
          "Bölümde Kullanılan Dosyalar",
          "Listelere Giriş - 1",
          "Listelere Giriş - 2",
          "Tuple (Demet) Konusu",
          "Dictionary (Sözlük) - 1",
          "Dictionary (Sözlük) - 2",
          "Kodlama Egzersizleri - İleri Seviye Veri Tipleri"
        ],
        "Koşullu Durumlar": [
          "Bölümde Kullanılan Dosyalar",
          "Bool Veri Tipi ve Karşılaştırma Operatörleri",
          "None Değeri ve Mantıksal Bağlaçlar",
          "in ve is İşleçleri",
          "Koşullu Durumlar - 1",
          "Koşullu Durumlar - 2",
          "Kodlama Egzersizleri - Koşullu Durumlar"
        ],
        "Döngüler": [
          "Bölümde Kullanılan Dosyalar",
          "While Döngüsü",
          "For Döngüsü - 1",
          "For Döngüsü - 2",
          "For Döngüsü - 3",
          "range() Fonksiyonu",
          "Break ve Continue İfadeleri",
          "List Comprehension Yöntemi"
        ],
        "Kodlama Egzersizleri - Döngüler": [
          "Bölümde Kullanılan Dosyalar",
          "Parola Kontrolü",
          "İki Listenin Farkını Bulma",
          "Harf Sayacı",
          "Asal Sayı Bulma",
          "Faktöriyel"
        ],
        "Fonksiyonlar": [
          "Bölümde Kullanılan Dosyalar",
          "Fonksiyonlar - 1",
          "Fonksiyonlar - 2",
          "print() ve return İfadelerinin Arasındaki Fark",
          "Fonksiyon Parametreleri",
          "Global ve Yerel Değişkenler",
          "Lambda Gösterimi"
        ]
      },
      "requirements": [
        "Machine Learning konusuna duyulan merak.",
        "Bilgisayar kullanabilmek dışında hiçbir gereksinim ya da ön koşul bulunmamaktadır.",
        "Kurs boyunca, projelerin geliştirilmesi için gerekli bilgiler derslerin içeriğine eklenmiştir."
      ],
      "description": "Yapay zekanın 21. yüzyılın en dikkat çeken konularından birisi olduğu kesin. Yapılan araştırmalar yapay zekanın bu yüzyılın en önemli alanlarından birisi olduğunu ortaya koyuyor. Zaten Google, Facebook, Microsoft vb. şirketler de geleceğin bu alanla birlikte şekilleneceğini öngördükleri için bu alana olan yatırımlarını orantılı bir biçimde arttırmaktadır.\nMachine Learning ya da Türkçesiyle \"Makine Öğrenmesi\", yapay zekanın temelini oluşturmaktadır. Yapay zeka olarak takdim edilen hemen hemen her şey aslında Machine Learning algoritmalarıdır. Ayrıca 21. yüzyılın en çekici alanlarından birisi olarak bilinen \"Veri Bilimi\" alanında aranan temel vasıflardan birisi de Machine Learning'dir. Bu kursta, Machine Learning'in temel konuları olan Regression, Classification, Clustering, Natural Language Processing(NLP) gibi konuların temel algoritmalarını Python'la nasıl kullanacağınızı öğreneceksiniz.\nKursun ilk kısmında opsiyonel olarak Python temellerini ele aldık. Bunun sebebi yeterli Python bilgisine sahip olmayan öğrencilerimize yardımcı olmaktır. Temel Python’ı ele aldığımız derslerle birlikte hiç tereddüt etmeden Machine Learning’e sıfırdan adım atabilirsiniz.\nKursta Machine Learning konularında bulunan terimlerin tamamına yakını tercüme edilmeden kullanılmıştır. Bunun sebebi öğrencilerimizin daha farklı mecralarda araştırma yaparken zorlanmamalarını sağlamaktır. Çünkü Machine Learning konusunda çoğu platformda kavramlar İngilizce olarak kullanılmaktadır. Derslerin isimleri de buna uygun olarak kavramların İngilizce asıllarına uygun olarak belirlenmiştir. Bu durum öğrencilerimizi yanıltmamalıdır. Derslerin tamamı Türkçedir.\nKursun içeriği;\n· Sıfırdan Python'ı \"neyi\", \"neden\" yazdığınızı anlayarak öğrenin.\n· Supervised Learning\n· Regression\n· Classification\n· Unsupervised Learning\n· Clustering\n· Natural Language Processing(NLP)\n· Model Tuning",
      "target_audience": [
        "Makine Öğrenmesi dünyasını keşfetmek isteyenler",
        "Makine Öğrenmesi konusunda bilgi ve beceri elde etmek isteyenler",
        "'Yapay Zeka'nın ne olduğunu merak edenler",
        "Makine Öğrenmesi konusunda güzel bir temel atmak isteyenler"
      ]
    },
    {
      "title": "Derin Öğrenme ile Görüntü İşleme: Python OpenCV Keras (Gİ-2)",
      "url": "https://www.udemy.com/course/derin-ogrenme-ile-goruntu-isleme-python-opencv-ve-keras/",
      "bio": "Yapay Zeka ve Derin Öğrenme Teknikleriyle Python'da Bilgisayarla Görü: Gerçek Zamanlı Obje Tanıma - Sınıflandırma -Takip",
      "objectives": [
        "Derin öğrenme algoritmaları ile obje tespitinin nasıl yapılacağını",
        "OpenCV kütüphanesini kullanarak görüntü işleme problemlerinden olan nesne tespiti ve takibinin nasıl yapılacağı",
        "YOLO, R-CNN ve SSD gibi önemli nesne tespiti algoritmalarının çalışma mantığını ve nasıl kodlanacağını",
        "Gerçek zamanlı obje tespit ve takibinin nasıl yapılacağı",
        "OpenCV kütüphanesini kullanarak histogram, gradyan, eşikleme gibi görüntü işleme temellerini",
        "Yüz tanıma, yaya tespiti, gerçek zamanlı nesne tespiti, takibi ve sınıflandırması projeleri",
        "Python dilinin görüntü işlemede kullanılan temel kütüphanelerinden olan OpenCV ve Keras kütüphanelerini",
        "Uçtan uca tespit, sınıflandırma ve takip çözümünün nasıl yapılacağı",
        "Farklı algoritmalar ile görüntü segmentasyonunun nasıl yapılacağı",
        "Evrişimsel sinir ağlarının (Convolutional Neural Network) nesne tespiti için nasıl eğitileceğini",
        "OpenCV ile köşe, kenar, kontur algılama gibi temel nesne tespiti algoritmalarını"
      ],
      "course_content": {},
      "requirements": [
        "Hedefler ve gelecekle ilgili güzel hayaller"
      ],
      "description": "Derin Öğrenme ile Görüntü İşleme: Python OpenCV Keras (Gİ-2)\nBu kurs 4 Adımlık Görüntü İşleme Yolculuğunun ikinci adımını oluşturmaktadır.\nGörüntü işleme kursunda klasik ve veri tabanlı derin öğrenme yöntemlerini kullanarak nesne tespiti, sınıflandırma ve takibinin nasıl yapıldığını öğrenip, keras ve opencv kütüphaneleriyle gerçek hayat projeleri yapacağız.\nDerin Öğrenme ile Görüntü İşleme Kursu İçeriği\nGiriş Bölümü\nDerin Öğrenme ile Görüntü İşleme Ders Programı\nPython Kurulumlar\nKaynaklar: Kodlar\nMakaleler, Faydalı Linkler ve Referanslar\nPython Hatırlatma\nSpyder Tanıtımı\nDeğişkenler\nPython Temel Sözdizimi\nListe\nTuple\nDeque\nDictionary\nIf - Else\nDöngüler: for - while\nFonksiyonlar\nYield\nNumpy Kütüphanesi\nPandas Kütüphanesi\nMatplotlib Kütüphanesi\nOS Kütüphanesi\nOpenCV ile Görüntü İşleme\nOpenCV ile Görüntü İşleme Giriş\nResmi İçe Aktarma\nVideo İçe Aktarma\nKamera Açma ve Video Kaydı\nYeniden Boyutlandır ve Kırp\nŞekiller ve Metin\nGörüntülerin Birleştirilmesi\nPerspektif Çarpıtma\nGörüntüleri Karıştırmak\nGörüntü Eşikleme\nBulanıklaştırma\nMorfolojik Operasyonlar\nGradyanlar\nHistogram\nOpenCV ile Nesne Tespiti\nNesne Tespiti Nedir?\nRenk ile Nesne Tespiti\nŞablon Eşleme\nKöşe Algılama\nKenar Algılama\nKontur Algılama\nÖzellik Eşleştirme\nHavza Algoritması\nYüz tanıma Projesi\nKedi Yüzü Tanıma Projesi\nÖzel Benzer Özellikler ile Nesne Algılama\nYaya Tespiti\nOpenCV ile Nesne Takibi\nNesne Takibi Nedir\nOrtalama Kayma Algoritması\nTakip Algoritmaları\nÇoklu Nesne Takibi\nEvrişimsel Sinir Ağları\nEvrişimsel Sinir Ağları Giriş\nEvrişimsel Sinir Ağları Nedir?\nTrex Projesi\nGerçek Zamanlı Rakam Sınıflandırma Projesi\nEvrişimsel Sinir Ağları ile Nesne Tespiti\nEvrişimsel Sinir Ağları ile Nesne Tespiti Giriş\nPiramit Gösterimi\nKayan Pencere\nMaksimum Olmayan Bastırma\nHazır Evrişimsel Sinir Ağları Sınıflandırıcısı ile Nesne Tespiti\nNesne Tespiti için Seçmeli Arama\nBölge Önerisi Nesne Tespiti\nR-CNN ile Nesne Tespiti\nYOLO ile Nesne Tespiti\nSSD ile Nesne Tespiti\nNeden Python?\nPython 2022 IEEE araştırmasına göre dünya çapında en çok kullanılan ve tercih edilen programlama dillerinden\nPython kolay öğrenilebilirliği sayesinde kodlamaya yeni başlayanların ilk tercihi oluyor.\nPython open source (açık kaynak) olması nedeni ile Facebook yada Google gibi dünyanın en büyük şirketleri tarafından destekleniyor.\nGörüntü işleme, veri bilimi, makine öğrenmesi yada yapay zeka denince akla ilk olarak Python dili geliyor. Bu durumda Python'ın dünya çapında büyük bir kitlesinin olmasına neden oluyor.\nPython öğrenmesi en kolay olan dillerin başında geliyor.\nKariyer açısından Python en çok fırsata sahip dillerinden biri.\nNeden Görüntü İşleme?\nGörüntü işleme, bir görüntü üzerinde bazı işlemler gerçekleştirmek, gelişmiş bir görüntü elde etmek veya ondan bazı yararlı bilgiler çıkarmak için kullanılan bir yöntemdir.\nOptimize edilmiş bir iş akışı elde etmek ve zaman kaybını önlemek için, görüntülerin bir işlem sonrası adımında işlenmesi önemlidir.\nGörüntü işleme bilgisine sahip olmak iş hayatında fark yaratacak.\nDünyada bulunan iki temel veriden biri görüntüdür. Görüntü işleme bilgisi pek çok farklı alanda sizi bir adım öne geçirecektir.\nBu Kurs ile Alacaklarınız\nSıfırdan Kodlama Becerisi: Sizinle birlikte kod yazıyoruz. Her ders boş bir sayfa ile başlar ve kodu sıfırdan yazarız. Bu şekilde ilerleyebilir ve kodun nasıl bir araya geldiğini ve her satırın ne anlama geldiğini tam olarak anlayabilirsiniz.\nKodlar ve Şablonları: Kursta oluşturduğumuz her Python şablonlarını ve kodunu indirebilirsiniz. Bu, sizlere hem daha sonra kod üzerinde pratik yapma hem de kendi projelerinizi şablon sayesinde daha kolay bir şekilde yaratma imkanı sağlayacaktır\nTeori ve Mantık: Size yalnızca kod yazmayı değil, hem yazdığımız kodun arkasında yatan mantığı ve teoriyi hem de neden böyle bir kod yazdığımızı anlatıyoruz.\nKurs içi destek: Size sadece video ile ders anlatımı yapmıyoruz. Size destek olmak için profesyonel Veri Bilimcilerinden oluşan bir ekip oluşturduk. Bu da ders ve ya ders dışı sorularınıza en fazla 72 saat içinde yanıt alacağınız anlamına geliyor.\nHemen kaydolun ve bir an önce başlayalım.",
      "target_audience": [
        "4 Adımlık Görüntü İşleme Yolculuğu serisinin ikinci adımını tamamlamak isteyenler",
        "Görüntü işleme konusunda uzmanlaşmak isteyenler",
        "Derin öğrenme yöntemleri ile nesne tespitinin ve sınıflandırmanın nasıl yapılacağını öğrenmek isteyenler",
        "Temel görüntü işleme kütüphanesi olan OpenCV ile nesne tespit ve takibinin nasıl yapılacağını öğrenmek isteyenler",
        "Görüntü işlemenin hem mantığını hem de Python ile nasıl kodlanacağını öğrenmek isteyenler",
        "Gerçek zamanlı görüntü işleme problemlerini çözmek isteyenler",
        "Görüntü işlemenin klasik ve veriye dayalı derin öğrenme yöntemlerini öğrenmek isteyenler"
      ]
    },
    {
      "title": "AI4ALL: Basics in Convolutional Neural Network",
      "url": "https://www.udemy.com/course/ai4all-basics-in-convolutional-neural-network/",
      "bio": "Basics and Foundation of Convolutional Neural Networks",
      "objectives": [],
      "course_content": {
        "Convolutional Neural Networks": [
          "Introduction",
          "CIFAR10 Dataset",
          "Q1",
          "Data Processing: CIFAR10",
          "Convolutional Operation Theory",
          "Q2",
          "Pooling",
          "Fully Connectedness",
          "Q3",
          "Conv2D Layer",
          "First Convolutional Neural Network Model"
        ],
        "Transfer Learning": [
          "Transfer Learning Concept",
          "VGG16",
          "Transfer Learning Using VGG16"
        ]
      },
      "requirements": [
        "No prior programming experience needed. You will learn directly in this class."
      ],
      "description": "This course is created to follow up with the AI4ALL initiatives. The course presents coding materials at a pre-college level and introduces a fundamental pipeline for a neural network model. The course is designed for the first-time learners and the audience who only want to get a taste of a machine learning project but still uncertain whether this is the career path. We will not bored you with the unnecessary component and we will directly take you through a list of topics that are fundamental for industry practitioners and researchers to design their customized neural network model.  The course focuses on Convolutional Neural Network models and introduce the important building block using Tensorflow.\n\n\nThis instructor team is lead by Ivy League graduate students and we have had 3+ years coaching high school students. We have seen all the ups and downs. Moreover, we want to share these roadblocks with you. This course is designed for beginner students at pre-college level who just want to have a quick taste of what AI is about and efficiently build a quick Github package to showcase some technical skills. We have other longer courses for more advanced students. However, we welcome anybody to take this course!",
      "target_audience": [
        "Pre-college level students interested in neural network models"
      ]
    },
    {
      "title": "Wprowadzenie do sieci neuronowych - Tensorflow 2.0 + Keras",
      "url": "https://www.udemy.com/course/wprowadzenie-tensorflow-keras/",
      "bio": "Odkryj potencjał sieci neuronowych: Tensorflow i Keras dla efektywnego uczenia maszynowego i rozwiązywania problemów!",
      "objectives": [
        "matematyczne podstawy działania sieci neuronowych",
        "implementacja prostej sieci neuronowej od zera przy pomocy języka Python",
        "zrozumienie zasad działania sztucznych sieci neuronowych (ANN)",
        "zrozumienie zasad działania konwolucyjnych sieci neuronowych (CNN)",
        "zrozumienie zasad działania rekurencyjnych sieci neuronowych (RNN)",
        "uczenie nadzorowane przy użyciu sieci neuronowych",
        "optymalizacja i regularyzacja",
        "klasyfikacja przy pomocy ANN",
        "regresja przy pomocy ANN",
        "klasyfikacja binarna obrazów przy pomocy ANN i CNN",
        "klasyfikacja wieloklasowa obrazów przy pomocy CNN",
        "praca z danymi tekstowymi i obrazami",
        "transfer learning",
        "zastosowanie modelu VGG16, VGG19",
        "klasyfikacja recenzji przy pomocy RNN"
      ],
      "course_content": {
        "Wstęp": [
          "Historia Sieci Neuronowych",
          "Nagroda Turinga za wkład z rozwój AI",
          "Geoffrey Hinton, Yann LeCun, Yoshua Bengio"
        ],
        "Przykłady zastosowań sieci neuronowych": [
          "Amazon Comprehend",
          "Amazon Polly",
          "Amazon Rekognition"
        ],
        "Uczenie Maszynowe - Krajobraz": [
          "Programowanie klasyczne vs. uczenie maszynowe",
          "Podział uczenia maszynowego",
          "Wybór biblioteki do uczenia głębokiego: Tensorflow + Keras",
          "Tensorflow Playground",
          "Keras"
        ],
        "Pierwsza sieć neuronowa - Digit Recognition": [
          "Repozytorium kursu - GitHub",
          "Google Colab - Przegląd",
          "Update",
          "Digit Recognition - rozpoznawanie ręcznie zapisanych cyfr"
        ],
        "Sieci Neuronowe - Wprowadzenie": [
          "Neuron",
          "Perceptron",
          "Perceptron - Przykład",
          "Perceptron Wielowarstwowy",
          "Elementy składowe sieci",
          "Tensor",
          "Tensor - przykłady",
          "Funkcje aktywacji",
          "Funkcje aktywacji - Implementacja",
          "Funkcje straty",
          "Funkcje straty - przykłady",
          "Metryki",
          "Metryki w problemach klasyfikacji binarnej",
          "Krzywa ROC",
          "Metryki w problemach klasyfikacji wieloklasowej",
          "Metryki w problemach regresji",
          "Spadek wzdłuż gradientu (Gradient Descent)",
          "Spadek wzdłuż gradientu (Gradient Descent) cz. 2",
          "Spadek wzdłuż gradientu (Gradient Descent) - Implementacja"
        ],
        "Matematyczne podstawy sieci neuronowych": [
          "Matematyczne podstawy sieci neuronowych",
          "Implementacja prostej sieci neuronowej"
        ],
        "Biblioteka Keras": [
          "Keras - Intro",
          "Biblioteka Keras - Wprowadzenie",
          "Praca z modelami w bibliotece Keras",
          "Praca z modelami w bibliotece Keras cz. 2",
          "Praca z warstwami w bibliotece Keras",
          "Główne problemy uczenia głębokiego - przeuczenie i niedouczenie",
          "Główne problemy uczenia głębokiego - przeuczenie i niedouczenie cz. 2",
          "Metody regularyzacji modeli",
          "Wywołania zwrotne - Model Checkpoint",
          "Wywołania zwrotne - Model Checkpoint - Zapisanie najlepszego modelu",
          "Wywołania zwrotne - Early Stopping - Wczesne Zatrzymanie",
          "Tensorboard",
          "Tensorboard Dev",
          "Zapis/Ładowanie modelu"
        ],
        "ANN - Klasyfikacja": [
          "Klasyfikacja wieloklasowa - Fashion MNIST",
          "Klasyfikacja wieloklasowa - Fashion MNIST - Eksploracja predykcji"
        ],
        "ANN - Regresja": [
          "Model regresji cen nieruchomości"
        ],
        "CNN - Konwolucyjne Sieci Neuronowe": [
          "Konwolucyjne Sieci Neuronowe - Wprowadzenie",
          "Przetwarzanie obrazu - Augmentacja danych",
          "Klasyfikacja obrazów - omówienie problemu",
          "Przygotowanie obrazów do modelu",
          "Przygotowanie obrazów do modelu cz. 2",
          "Budowa sieci CNN",
          "Transfer Learning - model VGG16",
          "Wyświetlenie błędów predykcji",
          "Dron, samolot pasażerski czy helikopter? - Klasyfikacja wieloklasowa",
          "Wyświetlenie błędów predykcji"
        ]
      },
      "requirements": [
        "Ukończone kursy ze ścieżki Python Developer na tym koncie instruktorskim",
        "Ukończone kursy ze ścieżki Data Scientist na tym koncie instruktorskim",
        "Podstawy matematyki",
        "Znajomość NumPy i Pandas"
      ],
      "description": "Chcesz rozpocząć swoją przygodę z uczeniem maszynowym i sztuczną inteligencją? Zastanawiasz się, jak działają sieci neuronowe i jak można je wykorzystać w praktyce? Ten kurs jest idealnym miejscem na start!\nTo praktyczny kurs, który krok po kroku wprowadzi Cię w świat nowoczesnych technologii sztucznej inteligencji. Skoncentrujemy się na frameworkach TensorFlow 2.0 oraz Keras, które są obecnie jednymi z najpopularniejszych narzędzi do budowania i trenowania modeli AI.\nPodczas kursu nauczysz się:\nCzym są i jak działają sztuczne sieci neuronowe\nJak przygotować dane do uczenia maszynowego\nJak zbudować prosty model w Keras\nJak trenować, walidować i testować modele\nJak rozwiązywać typowe problemy, takie jak nadmierne dopasowanie (overfitting)\nJak zastosować sieci neuronowe do klasyfikacji obrazów i danych numerycznych\nKurs zawiera również praktyczne ćwiczenia i projekty, które pomogą Ci utrwalić wiedzę i zdobyć umiejętności przydatne w pracy z AI. Wszystko wyjaśnione jest prostym i przystępnym językiem, a każdy temat ilustrowany jest przykładami kodu w Pythonie. Nie musisz mieć wcześniejszego doświadczenia z TensorFlow czy sieciami neuronowymi — wystarczy podstawowa znajomość Pythona i chęć nauki!\nDołącz do kursu i rozpocznij swoją przygodę z nowoczesną sztuczną inteligencją już dziś!\n\n\nTensorFlow – Elastyczna platforma do tworzenia inteligentnych rozwiązań\nTensorFlow to wszechstronna, open source'owa biblioteka stworzona przez Google do tworzenia i trenowania modeli uczenia maszynowego oraz głębokiego uczenia. Umożliwia budowę skalowalnych modeli AI, które można wdrażać na serwerach, w chmurze, na urządzeniach mobilnych czy brzegowych. Dzięki obsłudze GPU i TPU oraz integracji z narzędziami takimi jak Keras, TensorFlow wspiera zarówno szybkie prototypowanie, jak i produkcyjne zastosowania sztucznej inteligencji.\n\n\nKeras – Intuicyjne głębokie uczenie w Pythonie\nKeras to wysokopoziomowa biblioteka do tworzenia modeli głębokiego uczenia, zaprojektowana z myślą o prostocie, szybkości i modułowości. Działa jako interfejs dla bibliotek backendowych, takich jak TensorFlow, umożliwiając szybkie prototypowanie sieci neuronowych. Dzięki czytelnej składni i elastycznej architekturze, Keras jest doskonałym narzędziem zarówno dla początkujących, jak i zaawansowanych użytkowników sztucznej inteligencji.",
      "target_audience": [
        "Analitycy danych i inżynierowie danych",
        "Entuzjaści sztucznej inteligencji i automatyzacji",
        "Inżynierowie uczenia maszynowego",
        "Początkujący programiści zainteresowani sztuczną inteligencją",
        "Studenci kierunków informatycznych i technicznych",
        "Praktycy biznesowi i menedżerowie projektów technologicznych",
        "Uczestnicy kursów przygotowujących do certyfikatów z obszaru AI/ML"
      ]
    },
    {
      "title": "[NEW] 2025:Hallucinations in Gen-AI",
      "url": "https://www.udemy.com/course/hallucinations-in-gen-ai/",
      "bio": "The Mind Games of AI: Hallucinations Exposed",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Python",
        "ML",
        "DL"
      ],
      "description": "Generative AI has taken the world by storm, revolutionizing industries from content creation to customer service. However, to truly harness its potential, it's essential to understand its nuances and limitations. This course aims to equip you with the knowledge and skills to use generative AI effectively, avoiding common pitfalls like hallucinations.\nCourse Objectives\nGain a solid understanding of generative AI and its applications.\nLearn practical techniques for optimizing the use of generative AI in various contexts.\nMaster the art of prompt engineering to guide AI models towards desired outcomes.\nExplore diverse use cases of generative AI, from content generation to conversational agents.\nUnderstand the phenomenon of hallucinations in AI and its potential causes.\nDevelop strategies to identify and mitigate hallucinations in generative AI models.\nLearn about evaluation metrics designed to assess the quality and reliability of AI-generated content.\nDiscover techniques to enhance the performance and accuracy of LLMs.\n\n\nWhy Choose This Course?\nPractical Focus: Learn actionable techniques to improve your generative AI workflows.\nExpert Guidance: Benefit from insights from industry experts on best practices and common pitfalls.\nComprehensive Coverage: Explore a wide range of generative AI applications and challenges.\nHands-On Learning: Engage in practical exercises and projects to solidify your understanding.\nEnroll today and unlock the full potential of generative AI!",
      "target_audience": [
        "ML practitioners",
        "Tech Leads",
        "Executives",
        "Directors",
        "Data Scientists",
        "AI practitioners"
      ]
    },
    {
      "title": "Coding in R per l'analisi dati: da principiante a esperto",
      "url": "https://www.udemy.com/course/introduzione-a-r/",
      "bio": "basi programmazione R | statistica | analisi dati | creazione grafici | data cleaning | eda | funzioni",
      "objectives": [
        "Le basi della programmazione con R",
        "Impostare una sessione di lavoro",
        "Creare oggetti e funzioni su R",
        "Creare vettori, matrici, array, liste, fattori e dataframe",
        "Convertire oggetti in R",
        "Usare gli operatori logici",
        "Usare le istruzioni condizionali o strutture di controllo",
        "Esplorare i tuoi dati",
        "Installare e richiamare i pacchetti per l'estensione delle funzionalità di R",
        "Generare sequenze casuali su R",
        "Estrarre degli elementi da un oggetto o da un dataset",
        "Manipolare vettori, matrici, dataset",
        "Gestire valori mancanti e dati duplicati",
        "Manipolare le date",
        "Importare file in vari formati, .csv, Excel, .txt e altri",
        "Manipolare dataset, riorganizzandoli e aggregandoli",
        "Ristrutturare e aggregare i dati",
        "Creare grafici con le funzioni base e con i pacchetti più comuni",
        "Creare ed esportare dei report in vari formati",
        "Capire le basi della statistica con R"
      ],
      "course_content": {
        "Introduzione": [
          "Introduzione",
          "FAQ"
        ],
        "Primi passi": [
          "Scaricare e installare R",
          "Scaricare e installare RStudio",
          "Personalizzare e utilizzare RStudio",
          "Utilizzare altri IDE con R",
          "Utilizzare R con RStudio",
          "Codice del corso"
        ],
        "Basi del linguaggio": [
          "R: pro e contro",
          "Commentare il codice",
          "Operazioni matematiche di base",
          "Creazione di oggetti",
          "Esercizio 1",
          "Esercizio 1 - soluzioni",
          "Esercizio 1.1",
          "Le parentesi",
          "Tipi di variabili in statistica",
          "Primi passi con R",
          "Le strutture dati in R",
          "Vettori",
          "Esercizio 2",
          "Esercizio 2 - soluzioni",
          "esercizio 2.1",
          "Matrici",
          "Esercizio 3",
          "Esercizio 3 - soluzioni",
          "Esercizio 3.1",
          "Array",
          "Liste",
          "Fattori",
          "Esercizio 4",
          "Esercizio 4 - soluzioni",
          "Esercizio 4.1",
          "Dataframe",
          "Esercizio 5",
          "Esercizio 5 - soluzioni",
          "Stringhe",
          "Esercizio 6",
          "Esercizio 6 - soluzioni",
          "Date",
          "Convertire le strutture dati",
          "R base versus tidyverse",
          "Esercizio 7",
          "Esercizio 7 - soluzioni",
          "Operatori relazionali",
          "Strutture di controllo",
          "Funzioni",
          "Esercizio 8",
          "Esercizio 8 - soluzioni"
        ],
        "Impostazione dell'ambiente di lavoro": [
          "Impostare una directory di lavoro",
          "Installare e richiamare un pacchetto",
          "Repository di pacchetti",
          "Eseguire uno script .R",
          "Ottenere aiuto",
          "Siti web su R",
          "Impostazione dell'ambiente di lavoro"
        ],
        "Importazione ed esportazione di dati in R": [
          "Formati dati e fonti comuni per l’analisi dati",
          "Importazione dati",
          "File .csv",
          "File Excel",
          "File .txt",
          "File JSON",
          "File zip",
          "Esercizio 9",
          "Esercizio 9 - soluzioni"
        ],
        "Manipolazione dati": [
          "Subsetting dei dati",
          "Le funzioni *apply()",
          "Manipolazione dati con dplyr",
          "Altri pacchetti per la manipolazione dati",
          "Unire due dataset",
          "Esercizio 10",
          "Esercizio 10 - soluzioni"
        ],
        "Database": [
          "Database",
          "data.table",
          "Esercizio 11",
          "Esercizio 11 - soluzioni"
        ],
        "Statistica di base con R": [
          "Statistica di base con R",
          "EDA: analisi esplorativa di base",
          "Data quality",
          "Esercizio 12",
          "Esercizio 12 - soluzioni"
        ],
        "Grafica di base con R": [
          "Visualizzare i dati",
          "Grafica con R base",
          "ggplot2 e la funzione ggplot()",
          "Esercizio 13",
          "Esercizio 13 - grafici"
        ],
        "Creazione ed esportazione di report con R": [
          "Creazione di report con R e Markdown",
          "Utilizzare Shiny",
          "Creiamo un'app con Shiny",
          "Conclusioni"
        ]
      },
      "requirements": [
        "Un computer, una connessione a internet",
        "R e RStudio, che installeremo insieme"
      ],
      "description": "Questo corso di base di programmazione con R per aspiranti data analyst nasce per accompagnare un principiante nella programmazione, dalle basi del linguaggio di programmazione (uno dei più conosciuti e utilizzati nel campo dell'analisi dati) fino all'utilizzo della statistica descrittiva.\nAl termine di questo corso lo studente sarà in grado di creare, importare, manipolare e gestire dei dataset. Il corso parte dall'impostazione dell'ambiente di lavoro:  vedremo come scaricare, installare e utilizzare alcuni dei più importanti strumenti per l'utilizzo di R, come RStudio.\nPasseremo poi alla creazione degli oggetti: R si basa su alcune strutture che è necessario conoscere, come vettori, matrici, liste e dataframe. Una volta che avremo capito come creare e manipolare queste strutture dati, estrarne degli elementi e salvarle in locale sul computer, passeremo all'utilizzo di loop e alla creazione di funzioni.\nNella sezione successiva vedremo una serie argomenti utili: come impostare una cartella di lavoro, come installare e richiamare un pacchetto, come ottenere delle informazioni sui dati, dove trovare dei dataset per i test e ottenere aiuto su una funzione.\nQuando si analizzano dei dati ci si imbatte prima o poi nei dataframe cosiddetti casi x variabili. Vedremo quindi come importare un dataframe dal computer, o da internet, su R. Esistono molte funzioni adatte allo scopo e molti pacchetti che ci sono utili per importare dei dati che sono in alcuni formati particolari, come ad esempio i formati per Excel, il .csv, il .txt o il JSON.\nVedremo poi come manipolare i dati, creare nuove variabili, aggregare i dati, ordinarli in maniera orizzontale e longitudinale, unire due dataset. Per fare questo utilizzeremo alcuni pacchetti e funzioni specifiche, come dplyr, tidyr o reshape2. Vedremo anche brevemente come interfacciarci a un database e utilizzare altri pacchetti per snellire la gestione di dataset un po' più grandi.\nR è un linguaggio molto importante anche nell'ambito della statistica. Impareremo quindi alcune delle funzioni di base, come calcolo delle medie per riga o per colonna, e le funzioni statistiche più comuni nell'ambito della statistica descrittiva, come media, mediana, moda, la deviazione standard, la visualizzazione della distribuzione e altro ancora.\nQuando si parla di analisi dati, ci troveremo spesso a creare dei grafici per spiegare i nostri dati e le nostre analisi. Per questo motivo dedichiamo una sezione del corso a vedere come creare dei grafici sia con le funzioni della libreria di base, sia con il pacchetto ggplot2.\nNelle ultime lezioni del corso vedremo come creare e esportare dei report e delle slide, riepiloghiamo gli argomenti visti e le funzioni utilizzate, e vediamo il materiale di supporto.",
      "target_audience": [
        "Chi non ha conoscenze pregresse di R e vuole imparare direttamente in italiano",
        "Chi cerca uno strumento semplice per imparare a programmare con uno dei linguaggi più utilizzati nell'analisi dati",
        "*** Attenzione, R è un linguaggio utilizzato per l'analisi dati"
      ]
    },
    {
      "title": "Deep Learning for Computer Vision",
      "url": "https://www.udemy.com/course/deep-learning-for-computer-vision/",
      "bio": "From Pixels to Semantics",
      "objectives": [
        "Build solid understanding of Computer vision foundations, using traditional and Deep Learning methods",
        "Deep understanding of Conolutional Neural Networks and their usage in computer vision",
        "Build practical projects with ConvNets, like image classification, multi-object detection and semantic segmentations",
        "Understand and practice the concepts of Transfer Learning in practical problems",
        "Learn how to visualize and debug ConvNets and understand their underlying dynamics in a practical way",
        "Learn how to use and apply data augmentation and how to deal with large and small datasets using ConvNets",
        "Understand the basics of dealing with time and video data using Spatio-temporal models",
        "Understand the basics of 3D Deep Learning and how to deal with 3D data sets"
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Part 1: From Traditional CV to Deep Learning": [
          "Semantic gap and CV tasks"
        ],
        "Module 1.1: From traditional ConvNets to DL": [
          "Traditional CV pipeline",
          "License Plate Detection (LPD) example with traditional CV pipeline",
          "From traditional to learnable convolution filters",
          "ConvNets and GPU"
        ],
        "Module 1.2: ConvNets": [
          "Module intro",
          "Convolution and Filtering",
          "ConvNets Feature maps",
          "ConvNets sizes calculations",
          "Vanilla ConvNet image classification example",
          "ConvNet hyper parameters and border effects",
          "ConvNet efficiency"
        ],
        "Module 1.3: ConvNet Meta Architectures": [
          "Encoder design pattern as feature extractor",
          "Encoder-Decoder design pattern",
          "ConvNet Meta architectures: VGG and Inception",
          "ConvNet Meta architectures: Skip connections and DenseNets"
        ],
        "Module 2.1: ConvNets with small datasets": [
          "Module intro",
          "ConvNet efficiency",
          "Cats vs. Dogs baseline",
          "ETL pipeline",
          "Python generators",
          "Image data generators",
          "Data augmentation",
          "Drop out and regularization"
        ],
        "Module 2.2: Transfer Learning": [
          "Transfer learning: What, Why, When and How?",
          "Scenario 1: ConvNet as feature extractor",
          "Scenario 2: Fine tuning the conv base"
        ],
        "Module 2.3: ConvNet visualization and debugging": [
          "Module intro and visualization methods overview",
          "Method 1: Visualization of intermediate feature maps",
          "Method 2: Visualization of kernels",
          "Method 3: Class Activation Map visualization (GradCAM)"
        ],
        "Module 3.1: Semantic Segmentation": [
          "Module introduction",
          "Encoder design and downsampling",
          "Decoder design and upsampling",
          "Putting it all together: Encoder-Decoder and U-Net architecture"
        ],
        "Module 3.2: Object Detection": [
          "Module introduction",
          "Object Detection methods taxonomy",
          "From traditional Object Detection to Deep Learning methods",
          "Two stage object detection models",
          "Single Shot Detectors: SSD and YOLO architectures"
        ]
      },
      "requirements": [
        "Python",
        "Machine Learning",
        "Linear Algebra",
        "Probability and Statistics"
      ],
      "description": "Welcome to our course, Deep Learning for Computer Vision: From Pixels to Semantics. In this course, we will cover three main parts. The first part covers the essentials of traditional computer vision pipeline, and how to deal with images in OpenCV and Pillow libraries, including the image pre-processing pipeline like:  thresholding, denoising, blurring, filtering, edge detection,  contours...etc. We will build simple apps like Car License Plate Detection (LPD) and activity recogntion. This will lead us to the revolution that deep learning brought to the game of computer vision, turning traditional filters into learnable parameters using Convolution Neural Networks. We will cover all the basics of ConvNets, including the details of the Vanilla architecture for image classification, hyper parameters like kernels, strides, maxpool and feature maps sizes calculations. Beyond the Vanilla architecture, we also cover the state-of-the art ConvNet meta-architectures and design patters, like skip-connnections, Inception, DenseNet...etc. In the second part, we will learn how to use ConvNets to solve practical problems in different situations, with small amount of data, how to use transfer learning and the different scenarios for that, and finally how to debug and visualize the leant kernels in ConvNets. In the last part, we will learn about different CV apps using ConvNets. We will learn about the Encoder-Decoder design pattern. We start by the task of semantic segmentation, where we will build a U-Net architecture from scratch for the Cambridge Video (CAMVID) dataset. Then we will learn about Object Detection, covering both 2-stage and one-shot architectures like SSD and YOLO. Next, we will learn how to deal with the video data using the Spatio-Temporal ConvNet architectures. Finally we will introduce 3D Deep Learning to extend ConvNets usage to deal with 3D data, like LiDAR data.",
      "target_audience": [
        "Beginner level computer vision engineer"
      ]
    },
    {
      "title": "A-Z™ | R Programlama ile Veri Bilimi",
      "url": "https://www.udemy.com/course/r-programlama-egitimi/",
      "bio": "R programlama, machine learning, veri bilimi (data science) kavramlarını şimdi uygulayarak öğrenin: R Programming A-Z™",
      "objectives": [
        "Makine öğrenmesi algoritmalarını gerçek veriler ile uygulamalı olarak öğreneceksiniz.",
        "Bir veri bilimi projesi baştan sona ne gibi adımlardan oluşur öğrenecek ve bu adımları uygulayabileceksiniz.",
        "R dilini aktif olarak kullanacaksınız.",
        "R ve Python kodlarını entegre edeceksiniz.",
        "Harika veri görselleştirmeleri yapabileceksiniz.",
        "Veriyi istediği formata getirip analitik çalışmaya hazır hale getirmeyi öğreneceksiniz.",
        "Verideki eksik hücreleri doldurmayı öğreneceksiniz.",
        "Regular Expressions (regex) öğrenecek ve uygulayacaksınız.",
        "ggplot2 ve dplyr paketlerini aktif olarak kullanabileceksiniz.",
        "R Markdown ile interaktif raporlar oluşturabileceksiniz.",
        "Supervised ve Unsupervised Learning kavramlarını öğreneceksiniz."
      ],
      "course_content": {
        "Giriş": [
          "R ve Titanic (?!)",
          "Bilgisayarımıza R Kurulumu"
        ],
        "Temel Programlama Prensipleri": [
          "Değişken Tipleri",
          "Değişken Kullanımları",
          "Logical Değişkenler",
          "OR ve AND",
          "While Döngüsü",
          "For Döngüsü",
          "IF Komutu",
          "Değişken Atama Yöntemleri",
          "Temel Programlama Prensipleri",
          "Programlama Ödevi - 1",
          "Bölüm Tekrar - Özet"
        ],
        "R Programlama Temelleri": [
          "Vektörler",
          "Vektörleştirme",
          "Fonksiyonlar",
          "Faktörler",
          "Listeler",
          "Paketler",
          "Kendi Paketimizi Oluşturalım",
          "R Temelleri",
          "R Temelleri - Ödev"
        ],
        "Matrix": [
          "Matrix",
          "Matrix İşlemleri"
        ],
        "Data Frame": [
          "Data Frame",
          "Data Frame - Veri Dönüşümleri",
          "İnternet Üzerinden Veri Çekme ve Korelasyon Hesaplama",
          "Data Frame'lerin Alt Kümelerini Oluşturma",
          "Sapply() Fonksiyonu",
          "NA Nedir?",
          "NULL vs NA",
          "Masaüstünden Veri Yükleme",
          "Data Frame - Machine Learning Repository",
          "Bölüm Tekrarı - Özet"
        ],
        "Görselleştirme": [
          "Görselleştirmeye Giriş",
          "GGPLOT - Görselleştirmenin Dil Bilgisi",
          "GGPLOT - geom_point( )",
          "GGPLOT - easyGgplot2 ve par()",
          "Faktör Dönüşümü ve Renklendirme",
          "GGPLOT - Alpha, Shape, Size",
          "Facetlar",
          "GGPLOT - geom_bar( )",
          "GGPLOT - geom_bar(color, fill, position)",
          "geom_bar(stat = \"identity)",
          "Görselleştirme",
          "Bölüm Tekrarı - Özet"
        ],
        "Makine Öğrenmesine Giriş - Doğrusal Regresyon - Karar Ağaçları - KNN": [
          "Makine Öğrenmesi Nedir",
          "İlk Algoritmamız - Basit Doğrusal Regresyon",
          "Regresyon Doğrusu",
          "Regresyon - Uygulama",
          "Regresyon - Evlerin Fiyatı Ne Kadar?",
          "Karar Ağaçlarına Algoritmasına Giriş",
          "Karar Ağaçları - Uygulama",
          "Karar Ağaçları - Tahminleme",
          "k - En Yakın Komşu Algoritmasına Giriş",
          "k - En Yakın Komşu Algoritması",
          "k - En Yakın Komşu (KNN) Algoritması - Uygulama",
          "KNN - Train ve Test Ayırma",
          "KNN ile Sigorta Satış Tahmini",
          "Makine Öğrenmesine Giriş - Algoritmalar",
          "Makine Öğrenmesi - Ev Fiyatları",
          "Regresyon - Tekrar Dökümanı",
          "Karar Ağaçları - Tekrar Dökümanı"
        ],
        "Gözetimsiz Öğrenme (Unsupervised Learning)": [
          "Gözetimsiz Öğrenmeye Giriş",
          "K - Ortalama Algoritması ( K - Means Algorithm)",
          "K - Ortalama Algoritması - UYGULAMA",
          "Tekrar Dökümanı"
        ],
        "Uygulamalı Veri Bilimi Projesi - Titanik": [
          "Projemize Giriş - train, test setleri",
          "Veriyi Tanıma - 1",
          "Veriyi Tanıma - 2",
          "DPLYR Paketi ve Veri Transformasyonları",
          "Görselleştirme",
          "Eksik Hücreleri Bulma - apply()",
          "Regular Expressions - Özellik Yaratma",
          "Ünvanları forcats ile Gruplama",
          "Eksik Değerleri Doldurma",
          "Kabin numarası biliniyor mu?",
          "Eksik Değer Atama - 2",
          "Train - Test",
          "Doğrulama Seti Oluşturma",
          "randomForest'a Giriş",
          "randomForest - Uygulama",
          "Kimler Kurtuldu - Tahmin ve Proje Sonu"
        ],
        "Uygulamalı Veri Bilimi Projesi 2 - RFM Skorlama": [
          "RFM Skorlama Nedir?",
          "Veriyi Alma",
          "Veriyi Düzenleme",
          "as.factor - as.date",
          "Gün Değişkenleri ve Recency Değerleri",
          "Recency Hesaplama",
          "Frequency Hesaplama",
          "Monetary Hesaplama",
          "RFM",
          "Verileri Birleştirme",
          "Son adım - SKORLAMA",
          "RFM Skorlama Stratejileri"
        ]
      },
      "requirements": [
        "Veri bilimi dünyasına giriş yapmak isteyen herkes bu eğitimle ilk adımı atabilir.",
        "Herhangi bir ön bilgi gerekmeden ilk dersimizle başlayabilirsiniz!"
      ],
      "description": "Dersimizde bulunan uygulamalı makine öğrenmesi projeleri ve diğer analitik projeler/adımlar :\n1 - Ev Fiyatları Tahmini\n2 - Otomobil Verisi Kullanarak Değerlendirme Tahmini\n3 - Sigorta Ürünlerinin Satış Tahmini\n4 - Titanic Kazasından Sağ Çıkacak İnsanların Tahmini\n5 - RFM Skorlama ile Müşteri Analitiği ve Segmentasyonu\n6 - Birliktelik Kuralları Analizi ile Sepet Analizleri ve Tavsiye Sistemleri\n7 - Tüm Veriler İçin Gerekli Görselleştirmeler ve Veri Hazırlama Süreçleri\nKursumuzda ilk olarak Programlamaya Giriş yapacağız. Genel programlama becerileri kazandıktan sonra sıradaki bölümümüzde R Programlama Temellerini göreceğiz. Bu bölümlerde öğrendiklerimizi testler ile pekiştirdikten sonra Matrix ve Data Frame'leri işleyeceğiz. Ödevimizi tamamladıktan sonra Görselleştirme kısmında uygulamalı olarak veri görselleştirmeyi öğreneceğiz. Sonrasında Makine Öğrenmesine giriş yaparak, Regresyon, Karar Ağaçları, k - En Yakın Komşu, K - Ortalama algoritmalarını ve Yapay Sinir Ağlarını tartışacak ve onları gerçek veriler ile uygulamalı proje bazlı öğreneceğiz. Birliktelik Kuralları Analizi bölümümüzle Apriori algoritmasını uygulayacak ve tavsiye sistemleri dünyasını tartışacağız.\nDersimizde ayrıca Müşteri Analitiği hakkında bilgiler de bulabilirsiniz. Müşteri analitiği bilgisi bir veri bilimcide olmazsa olmaz bir bilgidir. Biz de RFM skorlamaya değinerek sizlere müşteri analitiği uygulamaları hakkında bilgi sağlıyoruz.\n\nDersimiz boyunca yaptığımız uygulamalı projelerin yanında, dersimizin son bölümünde ek olarak baştan sona uygulamalı iki adet veri bilimi projesi bulunuyor. Bu bölüm dersimiz boyunca öğreneceklerimizin bir tekrarı olmakla beraber üzerine yeni bilgiler katacağımız bir bölüm olacak. Verimizi alıp, eksik hücreleri doldurup görselleştirerek verimizi tanıyacak, yeni özellikler yaratacak ve en sonunda başka bir Makine Öğrenmesi algoritması olan Random Forest algoritmasını kullanarak bir tahmin modeli yaratacağız. Bu sayede bir veri bilimi projesinin adımlarını uçtan uca uygulamış olacağız. Diğer projemizde ise RFM skorlama yöntemi ile müşteri analitiği alanına giriş yapacağız!\nSorularınızı soru - cevap bölümünde 7/24 bekliyor olacağım. Sorularınız gün içinde cevaplanacak, çok sık sorulan bir soru ise konuyla ilgili video ders eklenecektir.\nGüncellemeler sizlerden gelen önerilere ve makine öğrenmesi bölümüne öncelik verilmek üzere düzenli olarak devam edecektir.",
      "target_audience": [
        "Her hafta yeni içerik eklenen dinamik bir dersin parçası olmak isteyen",
        "R programlama dilini A'dan Z'ye öğrenmek isteyen",
        "Veri bilimi alanında bir kariyer hedefleyen",
        "Bir veri bilimi projesi hangi adımlardan oluşur bunları uygulamalı olarak öğrenmek isteyen",
        "Veri görselleştirme becerileri kazanmak isteyen",
        "Makine öğrenmesi algoritmalarını uygulamalı olarak öğrenmek isteyen",
        "Bilgilerini pekiştirmek ve pratik yapmak isteyen herkes bu kursu alabilir!"
      ]
    },
    {
      "title": "From Zero to Hero: Mastering Neural Networks with Keras",
      "url": "https://www.udemy.com/course/beginners-guide-to-implementing-neural-networks-with-keras/",
      "bio": "Neural Networks Made Easy: A Beginner's Guide to Keras",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction to Colab"
        ],
        "Deep Neural Network": [
          "Beginners guide to making Deep Neural Network with Keras in Colab"
        ],
        "Convolutional Neural Network": [
          "Deep Neural Network with Keras"
        ],
        "Recurrent Neural network": [
          "RNN with Keras"
        ],
        "Complex models Implementation": [
          "Complex models with Keras"
        ]
      },
      "requirements": [
        "Student should know theoretical concepts of Deep Learning",
        "Some experience with Python will be a plus"
      ],
      "description": "In this comprehensive course, you will learn how to implement various types of neural networks using Keras, with step-by-step guidance and hands-on projects. You don't need to set up anything on your system as everything will be done online. You will be provided with example code and practice problems to reinforce your understanding of the concepts.\nThroughout the course, you will work on four exciting projects that cover different neural network architectures and datasets. You will start by implementing and training a fully connected neural network for character classification using the popular MNIST dataset. You will then move on to creating and training a convolutional neural network (CNN) for the same dataset.\nNext, you will learn how to implement and train a multi-layer LSTM neural network for Human Activity Recognition using the WISDM dataset. Finally, you will explore how to build and train a multi-layer CNN-RNN neural network for the same dataset.\nFor each project, you will be provided with code and Colab notebooks to experiment with, allowing you to practice and apply what you have learned in a real-world setting. This course is designed to take you from the basics to advanced models, so you can develop your skills and confidently implement complex neural networks.\nWhile a theoretical background in deep learning is expected, a basic understanding is sufficient to get started with this course. Join us now and learn how to build and train neural networks using Keras!",
      "target_audience": [
        "Beginners course for people interested in learning the implementation of Neural Networks and doing real world projects"
      ]
    },
    {
      "title": "[마이크임팩트 GFC] 데이터로 이룬 투명성, 우리의 삶을 어떻게 바꾸는가",
      "url": "https://www.udemy.com/course/gfc-rndh/",
      "bio": "송길영 - 데이터로 이룬 투명성, 우리의 삶을 어떻게 바꾸는가",
      "objectives": [
        "꿈을 찾고 이루고 싶은 오늘의 청춘들",
        "미래와 기술을 알고 싶은 오늘의 사업가들",
        "미래의 자산가를 꿈꾸는 오늘의 투자자들",
        "더 나은 내일을 살고싶은 오늘의 직장인들"
      ],
      "course_content": {
        "[마이크임팩트 GFC] 데이터로 이룬 투명성, 우리의 삶을 어떻게 바꾸는가": [
          "위기, 그리고 변화",
          "분투기, 현재진행형",
          "'왜?'에서 시작된 균열, 관성을 넘다",
          "일상의 진정성, 공존을 향하다",
          "질의 응답"
        ]
      },
      "requirements": [
        "별도 필요한 조건은 없습니다. 미래지향적 전망과 솔루션을 알고 싶으신 분들은 모두 환영 합니다."
      ],
      "description": "빅 데이터에서 사람의 마음을 캐는 마인드 마이너 송길영 !\n\n\n오직 마이크임팩트에서만 전하는 <'빅데이터'에 대한 Insight>\n\n\n\n\n[마이크임팩트 GFC : Grand Future Class] - 미래수업\n\n\n\n\n이상적인 예언이 아닌 이성적인 예측으로 !\n\n\n포스트코로나, 인공지능, 투자예측, 트렌드 등\n\n\n국내 최고의 미래학 전문가들이 전하는 인사이트 타임머신 !\n\n\n\n\n미래는 볼 수 없기에.\n\n\n과학은 말합니다. 미래로의 시간여행은 불가능하다고.\n\n\n그렇다면 급변하는 시대, 불안한 미래를 우리는\n\n\n어떻게 대처해야 할까요? 삶에도 망원경이 필요합니다.\n\n\n넓고 멀리, 선명하고 정확하게 볼 수 있는 망원경.\n\n\n국내 최고의 미래학자들이 들려주는 미래수업은\n\n\n삶과 세상을 관찰하는 망원경이 될 것입니다.\n\n\n\n\n당신의 미래에 대한\n\n\n비관은 '진취적인 비판'으로,\n\n\n낙관은 '근거있는 긍정'으로 바꿔줄 미래 성장 가이드 !\n\n\n\n\n\"시간은 지금 이 순간에도 절대적으로 흐른다. 우리는 지금이 아닌 미래를 사는 것이다.\"\n\n\n<목차>\n\n\n위기, 그리고 변화\n분투기, 현재진행형\n'왜?'에서 시작된 균열, 관성을 넘다\n일상의 진정성, 공존을 향하다\n질의 응답",
      "target_audience": [
        "꿈을 찾고 이루고 싶은 오늘의 청춘들",
        "미래와 기술을 알고 싶은 오늘의 사업가들",
        "미래의 자산가를 꿈꾸는 오늘의 투자자들",
        "더 나은 내일을 살고싶은 오늘의 직장인들"
      ]
    },
    {
      "title": "Logistic Regression & Supervised Learning using SPSS",
      "url": "https://www.udemy.com/course/logistic-regression-using-spss/",
      "bio": "implementing sample data set using SPSS and output simulation in MS Excel",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Understanding Logistic Regression Concepts",
          "Working on IBM SPSS Statistics Data Editor",
          "SPSS Statistics Data Editor Continues",
          "IBM SPSS Viewer"
        ],
        "Implementation using MS Excel - Example": [
          "Variable in the Equation",
          "Implementation Using MS Excel",
          "Smoke Preferences",
          "Heart Pulse Study",
          "Heart Pulse Study Continues",
          "Variables in the Equation",
          "Smoking Gender Equation",
          "Generating Output and Observations",
          "Generating Output and Observations Continues",
          "Interpretation of Output Example"
        ]
      },
      "requirements": [
        "Prior knowledge of Quantitative Methods, MS Office and Paint is desired."
      ],
      "description": "Logistic regression in SPSS is defined as the binary classification problem in the field of statistic measuring. The difference between a dependent and independent variable with the guide of logistic function by estimating the different occurrence of the probabilities, i.e., it is used to predict the outcome of the independent variable (1 or 0 either yes/no) as it is an extension of a linear regression which is used to predict the continuous output variables.\nLogistic regression is a technique used in the field of statistics measuring the difference between a dependent and independent variable with the guide of logistic function by estimating the different occurrence of probabilities. They can be either binomial (has yes or No outcome) or multinomial (Fair vs poor very poor). The probability values lie between 0 and 1, and the variable should be positive (<1).\nIt targets the dependent variable and has the following steps to follow:\nn- no. of fixed trials on a taken dataset.\nWith two outcomes trial.\nThe outcome of the probability should be independent of each other.\nThe probability of success and failures must be the same at each trial.\nPredictive modelling course aims to provide and enhance predictive modelling skills across business sectors/domains. Quantitative methods and predictive modelling concepts could be extensively used in understanding the current customer behavior, financial markets movements, and studying tests and effects in medicine and in pharma sectors after drugs are administered. The course picks theoretical and practical datasets for predictive analysis. Implementations are done using SPSS software. Observations, interpretations, predictions and conclusions are explained then and there on the examples as we proceed through the training. The course also emphasizes on the higher order regression models such as quadratic and polynomial regressions which aren’t covered in other online courses\n Essential skillsets – Prior knowledge of Quantitative methods and MS Office, Paint\n Desired skillsets -- Understanding of Data Analysis and VBA toolpack in MS Excel will be useful\nThe course works across multiple software packages such as SPSS, MS Office, PDF writers, and Paint.\nRegression modelling forms the core of Predictive modelling course. The core objective of this course is to provide skills in understand the regression model and interpreting it for predictions. The associated parameters of the regression model will be interpreted and tested for significance and test the goodness of fit of the given regression model.\nThrough this course we are going to understand:\nInterpretation of regression attributes such as R-Squared (correlation coefficient), t and p values\nm (slope) and c (intercept),\nDependent variables (Y), independent (A1, A2, A3……) variables, and Binary/Dummy B1, B2, B3 …..) variables\nExamining significance/relevance of A, B variables for regression model (equation) goodness of fit\nPredicting Y-variable upon varying values of A, B variables\nUnderstanding Multi-Collinearity and its disadvantages\nImplementation on sample datasets using SPSS and output simulation in MS Excel",
      "target_audience": [
        "Data Engineers, Analysts, Architects, Software Engineers, IT operations, Technical managers"
      ]
    },
    {
      "title": "Introduction to Machine Learning",
      "url": "https://www.udemy.com/course/introduction-to-machine-learning-o/",
      "bio": "Concepts of Regression, Decision Trees, etc...",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "None. You will learn everything from its basic"
      ],
      "description": "The course introduces the concepts of Machine Learning.  It covers the regression, both linear and logistic. Decision trees, Data preprocessing etc., to explore the machine learning in brief with plenty of examples. it also discusses the concept of state space, bias, etc. in Machine learning. Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed. This course covers the following aspects of machine learning:\n1.Basic Definitions 2.Types of Learning\n3.Hypothesis space and Inductive Bias\n4.Evaluation\n5.Cross-Validation\n6.Linear Regression\n7.Decision Trees 8.Overfitting\nThe course is designed after studying the syllabus of various technological universities. Machine learning is basically of three types: The main goal in supervised learning is to learn a model from labeled training data that allows us to make predictions about unseen or future data. Supervised refers to a set of samples where the desired output signals (labels) are already known.\nUnsupervised learning deals with unlabeled data or data of unknown structure. Using unsupervised learning techniques explores the structure of our data to extract meaningful information without the guidance of a known outcome variable or reward function.\nIn reinforcement learning, the goal is to develop a system (agent) that improves its performance based on interactions (reward signals) with the environment.",
      "target_audience": [
        "The course is intended for the students of BCA, BE, BTech and anybody interested in Machine Learning"
      ]
    },
    {
      "title": "Deep Learning ve Python: İleri Seviye Derin Öğrenme (5.1)",
      "url": "https://www.udemy.com/course/deep-learning-ve-python-ileri-seviye-derin-ogrenme-52/",
      "bio": "Yapay Zeka: Pytorch, Keras ve Python ile ileri seviye Computer Vision ve Convolutional Neural Networks (CNNs) - 2020",
      "objectives": [
        "İleri seviye derin öğrenme konuları olan Residual Networks, Transfer Learning, Autoencoders ve Generative Adversarial Networks konularının mantığını",
        "İleri seviye derin öğrenme konuları olan Residual Networks, Transfer Learning, Autoencoders ve Generative Adversarial Networks konularının Python ile kodlamasını",
        "Pytorch ve Keras gibi ileri seviye Python kütüphanelerini kullanarak derin öğrenme modeli tasarlamayı",
        "Hem birlikte kodlayacağımız hem de bireysel olarak yapacağınız farklı derin öğrenme projeleri ve ödevleri",
        "İleri seviye derin öğrenme modelleri ve bu modellerin gerçek hayatta nerelerde kullanıldığı",
        "Convolutional Neural Network (Konvolüsyonel Sinir Ağları) konusunun tekrarı"
      ],
      "course_content": {
        "İleri Seviye Derin Öğrenme Giriş": [
          "İleri Seviye Derin Öğrenme Ders Programı",
          "Kurulumlar: Anaconda, Python, Keras, Pytorch",
          "Datai Team GitHub: Kaynaklar",
          "İndirilebilir Kaynaklar"
        ],
        "Convolutional Neural Networks (CNN)": [
          "Convolutional Neural Networks Giriş",
          "Convolutional Neural Networks Tekrar",
          "Fruit360 Projesi: Dataset Tanıtımı",
          "Fruit360 Projesi: Python(Keras) ile CNN Modeli Oluşturma",
          "Fruit360 Projesi: Python(Keras) ile CNN Train ve Test",
          "Fruit360 Projesi: Python(Keras) ile CNN Sonuçlar",
          "Mnist Ödevi: Python(Keras) ile CNN",
          "Mnist Ödevi: Python(Keras) ile CNN Sonuçları",
          "Convolutional Neural Networks Sonuç"
        ],
        "Deep Residual Networks (ResNets)": [
          "Deep Residual Networks Giriş",
          "CNN vs Deep Residual Networks",
          "Vanishing Gradient Problem",
          "Deep Residual Networks",
          "IR Pedestrian Projesi: Dataset Tanıtımı ve Proje Raporu",
          "IR Pedestrian Projesi: Veri Seti Yükleme-1",
          "IR Pedestrian Projesi: Veri Seti Yükleme-2",
          "IR Pedestrian Projesi: Python(Pytorch) ile CNN Modeli Oluşturma",
          "IR Pedestrian Projesi: Python(Pytorch) ile CNN Loss Fonksiyonu ve Optimizer",
          "IR Pedestrian Projesi: Python(Pytorch) ile CNN Modeli Eğitimi",
          "IR Pedestrian Projesi: Python(Pytorch) ile CNN Modeli Sonuçları",
          "IR Pedestrian Projesi: Dataset Tanıtımı",
          "IR Pedestrian Projesi: Python(Pytorch) ile Deep Residual Basic Block",
          "IR Pedestrian Projesi: Python(Pytorch) ile Deep Residual Network Layer",
          "IR Pedestrian Projesi: Python(Pytorch) ile Deep Residual Network Modeli",
          "IR Pedestrian Projesi: Python(Pytorch) ile ResNet Loss Fonksiyonu ve Optimizer",
          "IR Pedestrian Projesi: Python(Pytorch) ile ResNet Eğitimi",
          "IR Pedestrian Projesi: Python(Pytorch) ile ResNet Sonuçlar",
          "Deep Residual Networks Sonuç"
        ],
        "Transfer Learning": [
          "Transfer Learning Giriş",
          "Transfer Learning Nedir?",
          "Transfer Learning Örnekleri",
          "Fruit360 Projesi: Dataset Tanıtımı",
          "Fruit360 Projesi: Python(Keras) ile VGG16 Modeli",
          "Fruit360 Projesi: Python(Keras) ile VGG16 Modeli Train ve Test",
          "Fruit360 Projesi: Python(Keras) ile VGG16 Modeli Sonuçlar",
          "CIFAR10 Ödev: Python(Keras) ile VGG19 Modeli",
          "CIFAR10 Ödev: Dataset Tanıma",
          "CIFAR10 Ödev: Dataset Preprocess",
          "CIFAR10 Ödev: Python(Keras) ile VGG19 Modeli Train",
          "CIFAR10 Ödev: Python(Keras) ile VGG19 Modeli Sonuçlar",
          "Transfer Learning Sonuç"
        ],
        "Autoencoders": [
          "Autoencoders Giriş",
          "Autoencoders Nedir?",
          "Fashion MNIST Projesi: Dataset Tanıtımı",
          "Fashion MNIST Projesi: Python(Keras) ile Autoencoders Modeli Train",
          "Fashion MNIST Projesi: Python(Keras) ile Autoencoders Modeli Sonuçlar-1",
          "Fashion MNIST Projesi: Python(Keras) ile Autoencoders Modeli Sonuçlar-2",
          "Autoencoders Sonuç"
        ],
        "Generative Adversarial Networks (GANs)": [
          "GANs Giriş",
          "GANs Nedir 1?",
          "GANs Nedir 2?",
          "GANs Kullanım Alanları",
          "MNIST Projesi: GANs Dataset Tanıtımı",
          "MNIST Projesi: Python(Keras) ile GANs Generator Modeli",
          "MNIST Projesi: Python(Keras) ile GANs Discriminator Modeli",
          "MNIST Projesi: Python(Keras) ile GANs Modeli",
          "MNIST Projesi: Python(Keras) ile GANs Eğitim",
          "MNIST Projesi: Python(Keras) ile GANs Sonuçlar",
          "GANs Sonuç"
        ],
        "İleri Seviye Derin Öğrenme Sonuç": [
          "Sonuç"
        ],
        "EK-1: Convolutional Neural Network (CNN)": [
          "Gözden Geçirme/Opsiyonel Ders",
          "CNN LİNK",
          "Convolutional Neural Network Genel Bakış",
          "Dataset ve CNN Kernel",
          "Loading Data Set",
          "Normalization - Reshape - Label Encoding",
          "Train - Test Split",
          "Convolutional Neural Network (CNN)",
          "Convolution Operation Nedir",
          "Same Padding",
          "Max Pooling",
          "Flattening",
          "Fully Connected",
          "CNN Implementing with Keras",
          "Create Model",
          "Adam Optimizer",
          "Compiler",
          "Batch and Epoch",
          "Data Augmentation",
          "Fit the Model",
          "Evaluate the Model",
          "CNN with Pytorch",
          "BONUS"
        ]
      },
      "requirements": [
        "Hedefler ve gelecekle ilgili güzel hayaller",
        "İnternet bağlantılı bir bilgisayar",
        "Python hakkında temel bilgiler",
        "Convolutional Neural Networks (Evrişimsel Sinir Ağları): Bu konu, bu kurs içerisinde EK-1 de anlatılmaktadır. Bu ders videoları isteğe bağlıdır. Eğer konuyu biliyorsanız izlemenize gerek yoktur."
      ],
      "description": "İleri Seviye Derin Öğrenme\nİleri seviye Derin Öğrenme kursu ile hem Residual Networks, Transfer Learning, Autoencoders ve Generative Adversarial Networks konularının mantığını hem de Python kütüphanelerinden olan Pytorch ve Keras ile kodlamasını öğreneceğiz.\nİleri Seviye Deep Learning (Derin Öğrenme) kursu içeriği:\nGiriş Bölümü\nİleri Seviye Derin Öğrenme ders programı\nPython Kurulumlar\nGithub Kaynaklar\nİndirilebilir Kaynaklar\nConvolutional Neural Networks (CNN) Gözden Geçirme\nConvolutional Neural Networks Nedir?\nProje1: Python (Keras) ile Fruit360 veri seti kullanarak Convolutional Neural Networks kodlama\nProje2: Python (Keras) ile MNIST veri seti kullanarak Convolutional Neural Networks kodlama\nDeep Residual Networks (DRN)\nConvolutional Neural Networks vs Deep Residual Networks\nVanishing Gradient Problem (Kaybolan Gradyan Problemi)\nDeep Residual Networks Nedir?\nProje3: Python (Pytorch) ile IR Pedestrian veri seti kullanarak Deep Residual Networks kodlama\nTransfer Learning (Transfer Öğrenmesi)\nTransfer Learning Nedir?\nTransfer Learning Örnekleri\nProje4: Python (Keras) ile Fruit360 veri seti kullanarak Transfer Learning (VGG16) kodlama\nProje5: Python (Keras) ile CIFAR10 veri seti kullanarak Transfer Learning (VGG19) kodlama\nAutoencoders (Otomatik Kodlayıcı)\nAutoencoders Nedir?\nProje6: Python (Keras) ile MNIST veri seti kullanarak Autoencoders kodlama\nGenerative Adversarial Networks (GANs) (Üretken Rakip Ağlar)\nGenerative Adversarial Networks Nedir?\nGenerative Adversarial Networks kullanım alanları\nProje7: Python (Keras) ile MNIST veri seti kullanarak Generative Adversarial Networks kodlama\nEK1: Convolutional Neural Network (CNN)Convolutional Neural Networks\nSame Padding\nMax Pooling\nFully Connected Network\nImplementing with Keras\nCreate Model\nOptimizer\nCompiler\nBatch and Epoch\nData Augmentation\nFitting Model\nEvaluate Model\nCNN with Pytorch\nNeden Python?\nPython 2018 IEEE araştırmasına göre dünya çapında en çok kullanılan ve tercih edilen programlama dili.\nPython kolay öğrenilebilirliği sayesinde kodlamaya yeni başlayanların ilk tercihi oluyor.\nPython open source (açık kaynak) olması nedeni ile Facebook yada Google gibi dünyanın en büyük şirketleri tarafından destekleniyor.\nVeri bilimi, makine öğrenmesi yada yapay zeka denince akla ilk olarak Python dili geliyor. Bu durumda Python'ın dünya çapında büyük bir kitlesinin olmasına neden oluyor.\nPython öğrenmesi en kolay olan dillerin başında geliyor.\nKariyer açısından Python en çok fırsata sahip dillerinden biri.\nNeden Derin Öğrenme?\nDerin öğrenme modelleri veri sayısı arttığı zaman klasik makine öğrenmesi yöntemlerinden çok daha başarılı sonuçlar veriyor.\nDerin öğrenme furyası tüm dünyada çığ gibi büyüyor ve bizlerde yolun başındayken derin öğrenmeyi öğrenmeliyiz.\nDerin öğrenme bilgisine sahip olmak iş hayatında fark yaratacak.\nDerin öğrenme herkesin öğrenebileceği kolay bir konu değil bu nedenle derin öğrenme bilen biri olarak her alanda daha kıymetli olursunuz.\nBu Kurs ile Alacaklarınız\nSıfırdan Kodlama Becerisi: Sizinle birlikte kod yazıyoruz. Her ders boş bir sayfa ile başlar ve kodu sıfırdan yazarız. Bu şekilde ilerleyebilir ve kodun nasıl bir araya geldiğini ve her satırın ne anlama geldiğini tam olarak anlayabilirsiniz.\nKodlar ve Şablonları: Kursta oluşturduğumuz her Python şablonlarını ve kodunu indirebilirsiniz. Bu, sizlere hem daha sonra kod üzerinde pratik yapma hem de kendi projelerinizi şablon sayesinde daha kolay bir şekilde yaratma imkanı sağlayacaktır\nTeori ve Mantık: Size yalnızca kod yazmayı değil, hem yazdığımız kodun arkasında yatan mantığı ve teoriyi hem de neden böyle bir kod yazdığımızı anlatıyoruz.\nKurs içi destek: Size sadece video ile ders anlatımı yapmıyoruz. Size destek olmak için profesyonel Veri Bilimcilerinden oluşan bir ekip oluşturduk. Bu da ders ve ya ders dışı sorularınıza en fazla 72 saat içinde yanıt alacağınız anlamına geliyor.\nİçeriğin İngilizce olması sizi yanıltmasın arkadaşlar. Derslerim tamamen Türkçedir.\nHemen kaydolun ve bir an önce başlayalım.",
      "target_audience": [
        "Derin öğrenmesi konusunda uzmanlaşmak isteyenler",
        "İleri seviye derin öğrenme modelleri hakkında bilgi sahibi olmak ve bu modelleri pratikte kodlamayı öğrenmek isteyenler",
        "Üniversite ve meslek seçiminde zorlanan ve derin öğrenme hakkında bilgi ve beceri sahibi olmak isteyenler",
        "Derin öğrenmeyi iş hayatında uygulamak isteyenler"
      ]
    },
    {
      "title": "Deep Learning Model Compression Algorithms",
      "url": "https://www.udemy.com/course/deep-learning-model-compression/",
      "bio": "Pruning, Quantization, Knowledge distillation, Factorization",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Python programming",
        "Familiar with deep learning model components"
      ],
      "description": "This course is intended to provide learners with an in-depth understanding of techniques used in compressing deep learning models. The techniques covered in the course include pruning, quantization, knowledge distillation, and factorization, all of which are essential for anyone working in the field of deep learning, particularly those focused on computer vision and natural language processing. These techniques should be generally applicable to all deep learning models.\nOne of the primary objectives of this course is to provide advanced content that is updated with the latest algorithms. This includes product quantization and its variants, tensor factorization, and other cutting-edge techniques that are rapidly evolving in the field of deep learning. To ensure learners are equipped with the knowledge they need to succeed in this field, the course will summarize these techniques based on academic papers, while avoiding an emphasis on experiment result details. It's worth noting that leaderboard results are updated frequently, and new models may require compression. As a result, the course will focus on the technical aspects of these techniques, helping learners understand what happens behind the scenes.\nUpon completion of the course, learners will feel confident in their ability to read news, blogs, and academic papers related to model compression. You will be encouraged to apply these techniques to your own work and share the knowledge with others.",
      "target_audience": [
        "deep learning model developers",
        "model compression research beginners"
      ]
    },
    {
      "title": "Python A-Z: Python para Data Science con Ejercicios Reales!",
      "url": "https://www.udemy.com/course/tutorial-python/",
      "bio": "Programación en Python para Data Science y Análisis de Datos. Aprende Análisis Estadístico, Data Mining, Visualizaciones",
      "objectives": [
        "Aprenderás a programar en Python a un buen nivel",
        "Aprenderás los conceptos claves de la programación",
        "Aprenderás a hacer tus propias funciones",
        "Aprenderás a instalar y usar varios paquetes de Python",
        "Aprenderás a codificar en Jupyter Notebooks",
        "Aprenderás a hacer visualizaciones avanzadas",
        "Aprenderás acerca de integer, float, boolean, string, y otros tipos en Python"
      ],
      "course_content": {},
      "requirements": [
        "No se requieren conocimientos o experiencia previa. Solamente una pasión por ser exitoso."
      ],
      "description": "Aprende Python mientras programas en él!\nEste curso es diferente a los demás. En este curso en verdad vas a estar aprendiendo paso a paso. En cada nueva clase estaremos construyendo sobre lo que has aprendido y lo que acabas de aprender. Además estarás avanzando con cada clase y, cuando menos te lo esperes, ¡vas a estar diseñando visualizaciones asombrosas!\nEste curso fue diseñado por expertos en Python para DataScience y ahora te lo traemos a ti para que puedas comenzar a explotar sus beneficios inmediatamente.\nEn cada video vas a aprender profundamente un concepto muy valioso y que podrás aplicar en el momento. Y la mejor parte es que vas a aprender usando ejemplos de la vida real.\nEste entrenamiento está lleno de retos de análisis de la vida real que aprenderás a resolver. Algunos los vamos a resolver tu y yo juntos. Otros te va a tocar resolverlos a ti solo para practicar (pero al final los vamos a resolver juntos, no te preocupes).\nEn resumen, este curso ha sido diseñado para todos los niveles de habilidades y, aún y cuando no tengas conocimientos de programación o de estadística, ¡vas a tener éxito en este curso!\nNo puedo esperar para verte dentro de la clase,\nDiego López y Kirill Eremenko",
      "target_audience": [
        "Este curso es para ti si quieres aprender a programar en Python",
        "Este curso es para ti si estás cansado de cursos de Python complicados",
        "Este curso es para ti si quieres aprender a usar Python mientras lo usas",
        "Este curso es para ti si te gustan los retos emocionantes",
        "Va a haber TAREAS en el curso, así que prepárate para trabajar en ella"
      ]
    },
    {
      "title": "OpenAI Guide: Prompt Engineering, ChatGPT, Dall-e, etc",
      "url": "https://www.udemy.com/course/openai-guide-prompt-engineering-chatgpt-dall-e-etc/",
      "bio": "OpenAI beginners guide to OpenAI API, ChatGPT, Prompt Engineering, Dall-e, Models, and more.",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Internet connection"
      ],
      "description": "Welcome to this course, OpenAI Guide: Prompt Engineering, ChatGPT, Dall-e, etc.\nOpenAI beginners guide to OpenAI API, ChatGPT, Prompt Engineering, Dall-e, Models, and more.\nIf you are a person who is very much confused about what openai is? what is openai business model is all about? what is the relation between OpenAI and OpenAI Models and how they are link to ChatGPT and APIs.\nSo much questions in your mind right?\nIt is frustrating when someone say and use this words like OpenAI API in front of you and you get confused so we have got this course for you.\nThis is very beginner friendly course for understanding OpenAI business models and how it works. Inside this course we will guide everything from basics to make you guys understand the OpenAI business models that will include:-\nWhat is OpenAI business Model?\nHow OpenAI works?\nWhat are models in OpenAI?\nWhat is relation of OpenAI with Models?\nHow ChatGPT and Dall-e is related to OpenAI?\nand many more.\nSo if you guys are Interested to learn concepts above do enroll inside this course OpenAI Guide: Prompt Engineering, ChatGPT, Dall-e, etc.\nI will see you inside this free course\nEnjoy this course.",
      "target_audience": [
        "Anyone who Wants to Understand OpenAI: Prompt Engineering, ChatGPT, Dall-e, etc"
      ]
    },
    {
      "title": "AIのための数学講座：少しづつ丁寧に学ぶ人工知能向けの線形代数/確率・統計/微分",
      "url": "https://www.udemy.com/course/math-for-ai/",
      "bio": "AIの学習を始めるために必要な数学を1つの講座にまとめました。プログラミング言語Pythonを用いて、式の意味を確認しながら少しずつ丁寧に学びます。人工知能に必要な数学を、着実に学んでいきましょう。",
      "objectives": [
        "AIを学習するための数学的下地が身につきます。",
        "数式をコードに落とし込むことができるようになります。",
        "線形代数の数式を理解し、Pythonのコードで演算ができるようになります。",
        "微分の知識が身につき、数式の意味が理解できるようになります。",
        "確率・統計により、データの傾向を捉えたり、世界を確率として捉えることができるようになります。",
        "AIでどのように数学を使うのか、理解できるようになります。"
      ],
      "course_content": {},
      "requirements": [
        "中学程度の数学の知識が前提として必要です。",
        "必要最低限のPythonの知識はコース内で解説しますので、プログラミングの経験は必要ありません。",
        "WindowsでもMacでも大丈夫です。Linuxのサポートは行いませんが、コードは全ての環境で共通のものです。"
      ],
      "description": "AIのための数学講座は、誰にでも開かれた人工知能向け数学の講座です。\n線形代数、微分、確率・統計を基礎から少しづつ丁寧に解説するので、人工知能に必要な数学を無理なく着実に身につけることができます。\n\n\n本コースの最大の特徴は、AI向けの数学をコードを書きながら学べることです。\nプログラミング言語Pythonのコードを書いて、手を動かしながら数学を学習します。\nこれにより、数式の意味を体験を通して理解できます。\nPythonに関しては、1つのセクションで必要な範囲を解説しますので、プログラミング未経験の方でも受講することができます。\n\n\nまた、初心者に優しいことも本コースの特徴です。\n扱う数学の難易度は緩やかに上昇するので、無理なく着実にAIに必要な数学の知識を身に付けることができます。\n\n\n本コースによりAIを本格的に学ぶための準備ができます。\nAIを学ぶための障壁を低くし、可能な限り多くの方がAIを学ぶことの恩恵を受けられるようにするのが本コースの目的です。\n\n\n————————————————————\n\n\n本コースの主な内容は以下の通りです。\n\n\n数学の基礎\n→ 線形代数や微分、確率統計を学ぶのに必要な数学のベースを身につけます。\n\n\n線形代数\n→ データをベクトルや行列を用いて効率よく扱う方法を学びます。\n\n\n微分\n→ 常微分・偏微分・連鎖律などの、様々な人工知能に必要な微分関連の知識を学びます。\n\n\n確率・統計\n→ データの傾向を捉えたり、世界を確率として捉える方法を学びます。\n\n\n人工知能（AI）への応用\n→ ニューラルネットワークの基礎を勉強し、シンプルな人工知能に学習を行わせます。\n\n\n————————————————————\n\n\n本コースの開発環境、AnacondaとJupyter Notebookは簡単にダウンロード、インストールすることができます。\n環境構築の敷居が非常に低いため、プログラミング未経験の方でも問題なく受講できます。\n\n\n本コースを修了した方は、学習意欲が刺激されて、さらにAIや数学のことを学びたくなっているかと思います。",
      "target_audience": [
        "数学がAIや機械学習を勉強する際の障壁になっている方",
        "AIをビジネスで扱う必要に迫られた方",
        "数学を改めて学び直したい方",
        "文系の方、非エンジニアの方にもおすすめです"
      ]
    },
    {
      "title": "Máster en IoT - Conéctate al Futuro [2025]",
      "url": "https://www.udemy.com/course/master-en-internet-of-things-conectate-al-futuro/",
      "bio": "Explota tu imaginación gracias al ecosistema del Internet de las Cosas (IoT) y su universo de posibilidades",
      "objectives": [
        "Aprenderá en profundidad en qué consiste el ecosistema Internet of Things (IoT)",
        "Las diferentes alternativas y tecnologías en cada capa de la arquitectura IoT (dispositivos, conectividad LAN / WAN, plataformas de IoT, business intelligence)",
        "La importancia y recomendaciones de seguridad en el mundo conectado",
        "Herramientas para desarrollar el modelo de negocio basado en soluciones IoT"
      ],
      "course_content": {},
      "requirements": [
        "No se requieren conocimientos previos para realizar el curso, pero sí muchas ganas de aprender el funcionamiento del Internet of Things para aportar el máximo valor posible y mejorar el mundo"
      ],
      "description": "¿Quiere aprender qué es IoT y cómo llevar a cabo sus proyectos en el mundo conectado?\n---\nEscuche de otros alumnos por qué este es el programa de Internet of Things MEJOR VALORADO en español:\n\"Excelente curso, la forma de abordar los temas deja muy claro todo lo que se debe tener presente para elaborar una Arquitectura IOT. Gracias por compartir tu conocimiento Super\" -- Claudia Gut\n\n\n\" Me ha gustado mucho, toda la divulgación de información, si tienes una idea que quieras solucionar con IoT este curso te mostrará como hacerlo y que tecnologías utilizar.\" -- Erik Navarrete Montenegro\n\n\n\" Explica muy bien, es excelente para darnos una idea general sobre el tema y comenzar a pensar en ideas.\"  -- Felipe Villalobos\n---\nEl Internet of Things o Internet de las Cosas (IoT) es la interconexión de cualquier tipo de dispositivo a internet habilitando a estas “Things” conectarse, recolectar e intercambiar datos con los diferentes elementos.\nLas “Things” pueden ser cualquier dispositivo que se nos ocurra como electrodomésticos, sensores domésticos, TV, smartphones, vehículos, maquinaria industrial.. en definitva, cualquier elemento electrónico al que podemos incorporar electrónica y sensores / actuadores para que de esa manera podamos obtener datos de interés y podamos tomar acciones en base al procesamiento de la información.\nPor todo ello, IoT impacta en cualquier tipo de sector, desde sector industrial habilitando lo que se conoce como “Industria 4.0” e impactando en toda la cadena productiva, hasta sector doméstico (Smart home), pasando por Smart City, coche conectado, Salud, eficiencia energética,… creando por tanto un sinfín de posibilidades para mejorar el mundo.\nEn esta especialización aprenderá en qué consiste el ecosistema Internet of Things así como las diferentes alternativas y tecnologías en cada capa de la arquitectura IoT para que pueda llevar a cabo y hacer realidad sus ideas de negocio basadas en IoT.\nEl programa está estructurado para que aprenda desde cero el flujo completo de una solución IoT y llevarla a cabo:\n\n\nBLOQUE 1: INTRODUCCIÓN A INTERNET OF THINGS (IoT)\nBLOQUE 2: DISPOSITIVOS, SENSORES Y ACTUADORES IoT\nBLOQUE 3: CONECTIVIDAD IoT\nBLOQUE 4: PLATAFORMAS IoT\nBLOQUE 5: DATA SCIENCE Y BUSINESS INTELLIGENCE\nBLOQUE 6: SEGURIDAD EN EL MUNDO CONECTADO Y BLOCKCHAIN\nBLOQUE 7: ESTRATEGIA Y MODELOS DE NEGOCIO IoT\nBLOQUE 8: PROYECTO FINAL IoT OPTIMIZACIÓN TRÁFICO URBANO\nBLOQUE 9: CONCLUSIONES\nEn cuanto al estado mercado de Internet of Things, se pronostica que para 2025 haya 500 dispositivos conectados en el hogar con un crecimiento exponencial en base a un 25% CAGR, por todo esto, es una excelente oportunidad para usted obtener los conocimientos necesarios en el ecosistema IoT como conseguirás en este curso.\nSe incluirá todo el material utilizado en las clases para que pueda aprovechar al máximo toda la información suministrada así como casos prácticos para la mejor comprensión de los conceptos.\nPor otra parte, tendrá una garantía de 30 días para asegurar que está 100% satisfecho con el material, mi objetivo es aportarle valor con todos estos conocimientos y si no es así siéntase libre de solicitar la devolución, aunque estoy seguro de que cumplirá sus expectativas.\nSi quieres aprender la tecnología que revolucionará el mundo y desarrollar tu idea de negocio a partir de IoT, este es tu programa.",
      "target_audience": [
        "Interesados en la tecnología IoT para aprender cómo desarrollar casos de uso basados en el Internet de las Cosas, desde un punto de vista técnico y de negocio para obtener el retorno de la inversión esperado.",
        "Todo aquél que quiera aprender una disciplina importante de cara al futuro y coger el conocimiento necesario para hacer realidad sus ideas basadas en IoT"
      ]
    },
    {
      "title": "みんなのディープラーニング講座 ゼロからPythonとColabで丁寧に学ぶ深層学習の最初の一歩【2021年最新版】",
      "url": "https://www.udemy.com/course/deep-learning/",
      "bio": "初心者向けディープラーニングのコースです。Google ColaboratoryとPythonを使って、深層学習の基礎を習得しましょう。フレームワークを使わずに、ディープラーニングにおいて最初に学ぶべき原理を少しずつ着実に身につけます。",
      "objectives": [
        "ディープラーニングの最初の一歩となる知識が身につきます。",
        "ディープラーニングがなぜ機能するのか、その原理をコードを書く体験とともに身につけることができます。",
        "簡単なディープラーニングのコードが書けるようになります。",
        "ディープラーニングと関連した簡単な数学の知識が身につきます。",
        "ディープラニングのフレームワークを使いこなすための下地が身につきます。",
        "ディープラーニングが持つ可能性に気づき、人工知能に対する深い洞察ができるようになります。"
      ],
      "course_content": {
        "ディープラーニング（深層学習）って何？": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "ディープラーニングとは？",
          "学習の心構え",
          "開発環境について",
          "演習"
        ],
        "ニューラルネットワークに触ってみよう！": [
          "セクション2の教材",
          "Section2の概要",
          "NumPyの基礎",
          "ニューロンの実装",
          "ニューラルネットワークの実装",
          "演習"
        ],
        "「微分」に慣れよう！": [
          "セクション3の教材",
          "Section3の概要",
          "「微分」の基礎 Part1",
          "「微分」の基礎 Part2",
          "「連鎖律」とは？",
          "演習"
        ],
        "勾配降下法で遊ぼう！": [
          "セクション4の教材",
          "Section4の概要",
          "「偏微分」とは？",
          "「勾配降下法」の実装",
          "ネイピア数とシグモイド関数",
          "演習"
        ],
        "学習するニューラルネットワーク": [
          "セクション5の教材",
          "Section5の概要",
          "連鎖律の拡張",
          "「誤差」の定義",
          "バックプロパゲーション",
          "学習するニューラルネットワーク Part1",
          "学習するニューラルネットワーク Part2",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "前提は中学レベルの数学で十分です。高度な数学は。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "Google Colaboratoryを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。"
      ],
      "description": "-------------------- お知らせ -----------------------\n本コースは、2021年9月5日に全面リニューアルされました。\n開発環境はGoogle Colaboratorlyに変更され、コードも全面的に更新されました。\n旧レクチャーの動画の内容は既に古くなってしまったので、2021年9月5日に削除されました。\n----------------------------------------------------\nみんなのディープラーニング講座は、誰にでも開かれたディープラーニング（深層学習）初心者向けの講座です。\nディープラーニングを学ぶために必要な名要素を細かく分解し、それぞれについて少しずつ動作を確認しながら丁寧に学んでいきます。\n\n\n人工知能、機械学習技術の中でもディープラーニングは近年特に高い注目を集めており、第三次AIブームの主役となっています。\nディープラーニングはヒトの神経細胞ネットワークを模倣したニューラルネットワークをベースとしていますが、ニューラルネットワークに関しては、時間を割いて丁寧に解説します。\n本講座は、このディープラーニングの基礎をPythonのコードを書いて少しずつ動作を確認しながら学びます。\nPyTorchやTensorFlowなどのフレームワークを使わないので、ディープラニングの原理を着実に身につけることができます。\n\n\nコードの記述と実行には、Google Colaboratoryという開発環境を使います。\nこれにより、プログラミング初心者の方が躓きやすい環境設定が大幅に楽になります。\n\n\n本コースは、実際に手を動かして動作を体験することに重きを置いています。\n難しい数学の箇所は分解して丁寧に解説しているので、文系や非エンジニアの方にもお勧めです。\nPythonのコードを書きながら、楽しくディープラーニングの基本原理を学んでいきましょう。\nディープラーニングの最初の一歩として、本コースはおすすめです。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. ディープラーニング（深層学習）って何？\n→ ディープラーニングの概要、および開発環境について解説します。\nSection2. ニューラルネットワークに触ってみよう！\n→ ニューラルネットワークを、コードを書きながら体験ベースで学びます。\nSection3. 「微分」に慣れよう！\n→ ニューラルネットワークの学習に不可欠な、「微分」について学びます。\nSection4. 勾配降下法で遊ぼう！\n→ 勾配降下法により、ニューラルネットワークが学習するメカニズムを学びます。\nSection5. 学習するニューラルネットワーク\n→ ディープラニングのコードを記述し、動作を確認します。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryを使用します。\nなお、大学レベル以上の数学や、高度なディープラーニングの解説は行いません。\n畳み込みニューラルネットワーク（CNN）や再帰型ニューラルネットワーク（RNN）などの解説は含まれませんのでご注意ください。",
      "target_audience": [
        "ディープラーニングに興味があるけれど、何から始めればいいかわからない方",
        "ディープラーニング関連の分厚い書籍に辟易した方",
        "ディープラーニングをビジネスで扱う必要に迫られた方",
        "数学、プログラミングがディープラーニングの学習の障壁になっている方",
        "文系の方、非エンジニアの方にもおすすめです"
      ]
    },
    {
      "title": "Googles' Teachable Machine - No Math, No Code",
      "url": "https://www.udemy.com/course/googles-teachable-machine-no-math-no-code/",
      "bio": "Classification without any code",
      "objectives": [],
      "course_content": {
        "Introduction to Teachable Machine Learning": [
          "Introduction"
        ],
        "Image Classification": [
          "Mask and No Mask Classification",
          "Indian Rupee Classification"
        ],
        "Audio Classification": [
          "Will Smith vs Tommy (Men in Black) Audio Classification"
        ],
        "Pose Classification": [
          "Bad Posture detection",
          "Yoga Asan (Pose) Detection",
          "Yoga Pose testing"
        ],
        "Deployment & Motivational": [
          "Tensorflow.js Model Deployment with p5",
          "More Internal of Deployment",
          "Labels and confidence Detail",
          "Deploying Model on Android",
          "What can be done with Teachable Machine Learning"
        ]
      },
      "requirements": [
        "Nothing"
      ],
      "description": "Google's Teachable Machine Project\nTrain a computer to recognize your own images, sounds, & poses.\nA fast, easy way to create machine learning models for your sites, apps, and more – no expertise or coding required.\n\n\nThis course has absolutely zero math so anyone who has some basic knowledge can do this course.\nThis course also has almost zero code so if you do not have strong background on programming still you can do very much everything in this course\n6 Projects like mask detection, Yoga Pose detection.\n\n\nIn this course, we are going to see\n1. What is Teachable Machine learning?\n2. Teachable machine learning applications.\n3. 2 Projects on Image Classification - Mask Detection and Indian Currency Identification.\nIndian Currency note: total 5 types of currency 20,50,100,200,500.\n4. 2 Project on Audio Classification - Men in Black actor audio classification and Word Classification\n5. 2 Project on Pose - Bad Posture and Yoga Pose detection.\nYoga Pose Detection has Mountain and Triangle pose detection.\n6. Lastly deployment of models on P5, Keras and Android using Tensorflow.js and tensorflowlite.\n\n\nOne More project for Mute and Deaf people which can help them.\nTotal 6 Project, deployment on web and android app.\nJust jump into it and see\n\n\nHope you will enjoy the course.\nand if time permits I will be adding few quizzes to it so you can check your knowledge about teachable machine.",
      "target_audience": [
        "Beginner to Machine Learning",
        "Explorer to AI"
      ]
    },
    {
      "title": "Formação Inteligência Artificial: Do Zero ao Avançado 2025",
      "url": "https://www.udemy.com/course/inteligencia-artificial-para-iniciantes/",
      "bio": "Curso Completo em IA: Prática com Agentes de IA, ChatGPT, MidJourney, Engenharia de Prompts, IA Generativa",
      "objectives": [
        "Fundamentos de IA: Compreensão básica de Inteligência Artificial, Machine Learning e Deep Learning.",
        "Diferenciação de Conceitos: Capacidade de distinguir entre IA, ML e Deep Learning e suas aplicações específicas.",
        "Uso Prático de Ferramentas de IA: Aprendizado sobre como utilizar 12 ferramentas de IA para otimizar a produtividade.",
        "Automação de Tarefas: Técnicas para automatizar tarefas repetitivas e otimizar processos de trabalho.",
        "Geração de Conteúdo: Métodos para utilizar IA na criação de conteúdo inovador e relevante.",
        "Análise de Dados: Habilidades para aplicar IA na análise e interpretação de dados para tomada de decisões informadas."
      ],
      "course_content": {
        "Iniciando": [
          "Vamos iniciar? Boas Vindas!",
          "Uma aula muito importante para você!",
          "Por que a IA é Inadiável",
          "Desmistificando a IA: O Que é e Como Funciona (Simplificado)"
        ],
        "O ChatGPT": [
          "O que é o ChatGPT e como ele funciona?",
          "Como criar uma conta e acessar o ChatGPT",
          "Modelos do ChatGPT",
          "Navegando pela interface: o que você vê é o que significa",
          "Treinamento o seu primeiro GTP com o CustomGPT",
          "Seu primeiro prompt: conversando com o ChatGPT pela primeira vez",
          "Entendendo as limitações e como o ChatGPT “pensa”",
          "O que fazer e o que evitar ao usar o ChatGPT"
        ],
        "Engenharia de Prompt": [
          "O que é Engenharia de Prompt e Por que Ela é Tão Importante?",
          "Como Escrever Seu Primeiro Prompt Eficiente (Exemplos Reais)",
          "Tipos de respostas que o ChatGPT pode gerar",
          "Prompts para tarefas do dia a dia",
          "Usando exemplos nos prompts para melhorar a saída",
          "Criando prompts para tomada de decisão e comparação de ideias",
          "Personalizando o estilo e o tom das respostas",
          "Prompt Chaining: Dividindo tarefas em etapas",
          "Criação de Templates de Prompt reutilizáveis",
          "Prompts com lógica e raciocínio avançado (zero-shot reasoning)",
          "Reorganização de Dados & Revisão de Texto",
          "Criando Questões, Testes e Avaliações a Partir de um Texto"
        ],
        "IA Generativa": [
          "Qual é a melhor IA Generativa?",
          "Grok 4",
          "ChatGPT 5"
        ],
        "Agentes IA": [
          "O que são Agentes de IA?",
          "Tipos de Agentes: Reativos, Baseados em Objetivos, Autônomos e Multiagentes",
          "Iniciando um Agente para realizar uma compra online",
          "Finalizando a compra",
          "Criando sua conta no N8N Cloud",
          "Criando um agente de resposta de email",
          "Testando o agente de resposta de email",
          "Importando conteúdos no n8n"
        ],
        "Midjourney": [
          "O que é o Midjourney e criando a sua conta",
          "Entendendo os Planos e Assinatura",
          "Criando a minha primeira imagem",
          "Ajustando parametros e estilos de imagens",
          "Habilitando a sua personalização via perfis"
        ],
        "As Ferramentas": [
          "Iniciando com as Ferramentas",
          "Ferramenta 01",
          "Ferramenta 02",
          "Ferramenta 03",
          "Ferramenta 04",
          "Ferramenta 05",
          "Ferramenta 06",
          "Ferramenta 07",
          "Ferramenta 08",
          "Ferramenta 09",
          "Ferramenta 10",
          "Ferramenta 11",
          "Ferramenta 12",
          "Ferramenta 13",
          "Ferramenta 14",
          "Ferramenta 15"
        ],
        "Inteligência Artificial para Nerds :)": [
          "Os 7 estágios da Inteligência Artificial",
          "As diferenças entre AI, ML, DL",
          "O que o AI consegue fazer?"
        ],
        "Edição de Videos com IA": [
          "Vamos editar videos?",
          "Editando com o CapCut",
          "Utilizando o Adobe Podcast Enhance",
          "Cortes com o OpusClip",
          "Editando com o Gling"
        ],
        "Finalizando": [
          "Ainda não terminamos :)",
          "Bonus"
        ]
      },
      "requirements": [
        "Muita vontade de aprender coisas legais :)"
      ],
      "description": "Formação em Inteligência Artificial: Do Zero ao Avançado\nCurso Completo em IA: Prática com Agentes de IA, ChatGPT, MidJourney, Engenharia de Prompts, IA Generativa, e muito mais...\nA Inteligência Artificial já não é mais o futuro – é o presente.\nDominar IA hoje é um diferencial competitivo para qualquer profissional ou empresa que deseja crescer, inovar e se destacar no mercado.\nEste curso completo foi desenvolvido para levar você do zero absoluto ao nível avançado, mesmo que nunca tenha estudado Inteligência Artificial antes. De forma prática e organizada, você vai aprender a aplicar IA em projetos reais, negócios, estudos e carreira.\n\n\nO que você vai aprender neste curso:\n\n\nEntender os fundamentos da Inteligência Artificial e do Machine Learning.\nCriar prompts estratégicos e dominar a Engenharia de Prompts.\nUtilizar ChatGPT para gerar textos, códigos, ideias e soluções.\nCriar imagens incríveis com MidJourney e outras ferramentas visuais.\nDesenvolver projetos com IA Generativa para conteúdo, design e produtividade.\nConstruir Agentes de IA para automação de tarefas e integração de sistemas.\nAplicar IA em marketing, negócios, design, produtividade e inovação.\nConhecer os conceitos de ética, responsabilidade e governança em IA.\nCriar um portfólio prático para mostrar suas habilidades ao mercado.\n\n\nPor que este curso é diferente?\n\n\nEstá sempre 100% atualizado cobrindo as ferramentas de IA mais atuais.\nAbordagem prática: teoria aplicada a projetos reais.\nConteúdo passo a passo, ideal para iniciantes mas valioso para profissionais.\nAulas claras, organizadas e diretas, sempre com exemplos práticos.\nInstrutor experiente, com milhares de alunos treinados em tecnologia e IA.\n\n\nPara quem é este curso?\n\n\nIniciantes que querem aprender Inteligência Artificial do zero.\nProfissionais de tecnologia que desejam atualizar suas habilidades em IA.\nEmpreendedores e gestores que buscam aplicar IA em negócios e automações.\nCriadores de conteúdo, designers e profissionais de marketing que querem explorar ferramentas como ChatGPT, MidJourney e IA Generativa.\nQualquer pessoa que deseja dominar a Inteligência Artificial e se preparar para o futuro.\n\n\nBenefícios do Curso\n\n\nAutomatização de Tarefas: Aprenda a economizar tempo automatizando processos repetitivos.\nGeração de Conteúdo Criativo: Descubra como a IA pode ajudar na criação de textos, imagens e outras formas de mídia.\nAnálise de Dados: Utilize ferramentas de IA para obter insights valiosos a partir de grandes volumes de dados.\nOtimização de Processos: Melhore a eficiência e produtividade em seu ambiente de trabalho.\n\n\nResultado esperado\n\n\nAo final do curso, você terá desenvolvido habilidades sólidas em Inteligência Artificial, entendendo como aplicar IA em diferentes áreas, criar soluções inteligentes e se posicionar à frente da maioria no mercado.\nNão importa sua área de atuação — a Inteligência Artificial é a chave para o futuro, e este curso vai colocar você no caminho certo.\n\n\nSobre o Instrutor\nEu André sou o seu instrutor dedicado e comprometido em simplificar a complexidade das novas tecnologias para aprendizes ao redor do mundo. Com mais de 25 anos de experiência no campo tecnológico, já treinei com sucesso mais de 500.000 alunos através de aulas presenciais e cursos online em minha própria plataforma de ensino desde 2009.\nSou especializado em Computação em Nuvem, Soluções AWS, Azure, Google Cloud e Inteligência Artificial. Nos últimos 10 anos, tenho me concentrado intensivamente em Inteligência Artificial, desenvolvendo e implementando soluções de AI em diversas indústrias. Meu trabalho inclui projetos em Machine Learning, Deep Learning e Processamento de Linguagem Natural (NLP), além de criar e otimizar modelos preditivos e algoritmos de AI.\nMeu objetivo é prepará-lo para o sucesso pessoal e profissional no setor tecnológico, combinando técnicas de ensino eficazes com insights práticos para garantir um aprendizado abrangente.\nCom alunos em 172 países, meus programas de treinamento têm uma classificação média de 4,8/5 na Udemy. Agradeço por confiar em mim para sua jornada educacional. Estou aqui para ajudá-lo a alcançar seus objetivos tecnológicos e linguísticos, uma lição de cada vez.\n\n\nInscreva-se Agora e Domine IA com ChatGPT, MidJourney, Engenharia de Prompts, IA Generativa e Agentes de IA.\nNão perca a oportunidade de se destacar na era digital. Inscreva-se agora no curso Inscreva-se agora e comece sua jornada para dominar a Engenharia de Inteligência Artificial em 2025.\nPrepare-se para um futuro onde a inteligência artificial é a chave para o sucesso e a eficiência no ambiente de trabalho.\nTransforme sua carreira e sua vida com o poder da IA!",
      "target_audience": [
        "Iniciantes em Tecnologia: Pessoas novas em campos tecnológicos buscando entender IA e suas aplicações.",
        "Empreendedores: Donos de startups e pequenos negócios interessados em otimizar operações com IA.",
        "Estudantes: Alunos de áreas como ciência da computação e engenharia que querem conhecimento prático em IA.",
        "Profissionais de Marketing: Especialistas querendo usar IA para melhorar estratégias e conteúdo.",
        "Apaixonados por Tech: Quem tem interesse pessoal em tecnologia e inovações em IA.",
        "Buscadores de Eficiência: Profissionais de qualquer área procurando aumentar produtividade com IA."
      ]
    },
    {
      "title": "Python para Finanças: Análise de Dados e Machine Learning",
      "url": "https://www.udemy.com/course/python-para-financas-analise-de-dados-e-machine-learning/",
      "bio": "Investimentos, cálculos de retorno e risco, alocação inteligente de ativos, precificação, previsão de preços e mais!",
      "objectives": [
        "Os principais conceitos teóricos sobre finanças e investimentos, como por exemplo: taxas de retorno, cálculos de risco, alocação de portfólios, CAPM e simulações Monte Carlo",
        "Realizar o download de bases de dados financeiras",
        "Analisar bases de dados de preços de ações por meio de gráficos interativos",
        "Calcular taxas de retorno de investimentos e analisar seus resultados",
        "Aprender passo a passo cálculos estatísticos para calcular o risco de ações e portfólios, como por exemplo: variância, desvio padrão, covariância e correlação",
        "Escolher os melhores ativos em uma carteira por meio da alocação e otimização de portfólios",
        "Aplicar as fórmulas de Sharpe Ratio e Markowitz para análise de carteira de ações",
        "Implementar algoritmos inteligentes de otimização para escolher as melhores ações em um portfólio, como por exemplo: subida da encosta (hill climb), têmpera simulada (simulated annealing) e algoritmos genéticos",
        "Precificar ativos utilizando o modelo de precificação de ativos CAPM (Capital Asset Pricing Model)",
        "Construir Simulações Monte Carlo e usar técnicas de séries temporais para prever o preço de ações",
        "Aplicações de algoritmos de machine learning para classificar as melhores empresas para investir a longo prazo",
        "Utilizar o algoritmo k-means para agrupar empresas com características similares",
        "Implementar técnicas de Processamento de Linguagem Natural para classificar o sentimento de textos financeiros",
        "Explorar e analisar textos financeiros, bem como a extração do nome de empresas dos textos e geração de nuvem de palavras",
        "Aprender o básico sobre programação utilizando a linguagem Python"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais informações",
          "Recursos para download"
        ],
        "----- Parte 1 - Finanças -----": [
          "Introdução"
        ],
        "Visualização de dados financeiros": [
          "Instalação da Biblioteca Yahoo Finance",
          "Introdução",
          "Base de dados com uma ação 1",
          "Base de dados com uma ação 2",
          "Base de dados com mais ações",
          "Gráfico das ações - histograma",
          "Gráfico das ações - boxplot",
          "Gráfico das ações - linhas",
          "Gráfico das ações e normalização",
          "Gráfico dinâmico das ações",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Conclusão"
        ],
        "Taxa de retorno de ações": [
          "Introdução",
          "Taxa de retorno simples - teoria",
          "Taxa de retorno simples - prática",
          "Taxa de retorno diária",
          "Taxa de retorno anual",
          "Taxa de retorno logarítmica - teoria",
          "Taxa de retorno logarítmica - prática",
          "Taxa de retorno logarítmica diária e anual",
          "Taxa de retorno de carteira de ações 1",
          "Taxa de retorno de carteira de ações 2",
          "Taxa de retorno de carteira de ações 3",
          "Comparativo: carteira x ibovespa",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Conclusão"
        ],
        "Cálculo de risco de ações": [
          "Introdução",
          "Taxas de retorno por ano",
          "Variância - teoria",
          "Variância - prática",
          "Desvio padrão - teoria e prática",
          "Coeficiente de variação - teoria e prática",
          "Risco médio anual",
          "Covariância, coeficiente de correlação e determinação",
          "Covariância e correlação entre empresas",
          "Risco de um portfólio 1",
          "Risco de um portfólio 2",
          "Risco de um portfólio 3",
          "Risco sistemático e não sistemático",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Conclusão"
        ],
        "Alocação e otimização de portfólios": [
          "Introdução",
          "Teoria",
          "Alocação de ativos 1",
          "Alocação de ativos 2",
          "Alocação de ativos 3",
          "Visualização do portfólio",
          "Sharpe ratio - teoria",
          "Shape ratio - prática",
          "Alocação com Markowitz 1",
          "Alocação com Markowitz 2",
          "Alocação com Markowitz 3",
          "Algoritmos de otimização - fitness function",
          "Algoritmos de otimização - visualização",
          "Definição do problema de otimização",
          "Hill climb - teoria",
          "Hill climb - implementação",
          "Simulated annealing - teoria",
          "Simulated annealing - implementação",
          "Algoritmo genético - teoria",
          "Algoritmo genético - implementação",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Conclusão"
        ],
        "Precificação de ativos com CAPM (Capital Asset Pricing Model)": [
          "Introdução",
          "CAPM - teoria",
          "Preparação do ambiente",
          "Introdução a regressão linear",
          "Cálculo do BETA - regressão linear",
          "Cálculo do BETA - variância e covariância",
          "Cálculo do CAPM para um ativo",
          "Cálculo do BETA - portfólio",
          "Cálculo do CAPM - portfólio",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Conclusão"
        ],
        "Simulações Monte Carlo para previsão de preços": [
          "Introdução",
          "Teoria - cálculos matemáticos",
          "Preparação do ambiente",
          "Cálculo do drift",
          "Cálculo dos retornos diários",
          "Previsões de preços futuros",
          "Gráfico das previsões",
          "Previsões e preços reais",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Conclusão"
        ],
        "----- Parte 2 - Machine Learning em finanças -----": [
          "Introdução"
        ],
        "Previsões de preços com séries temporais": [
          "Introdução",
          "Bibliotecas e base de dados",
          "Exploração da série temporal",
          "Decomposição da série temporal",
          "Previsões com ARIMA",
          "Gráfico das previsões",
          "Avaliação do ARIMA",
          "Facebook Prophet e base de dados",
          "Previsões com Facebook Prophet",
          "Gráfico das previsões",
          "Avaliação do Facebook Prophet",
          "EXERCÍCIO",
          "Solução para o exercício",
          "Conclusão"
        ]
      },
      "requirements": [
        "Conhecimentos básicos sobre lógica de programação, principalmente estruturas condicionais (if) e de repetição (for)"
      ],
      "description": "Neste curso você terá uma visão teórica e principalmente prática passo a passo sobre os principais conceitos de Finanças e Investimentos, bem como a implementação na linguagem de programação Python e aplicações de Machine Learning (Aprendizagem de Máquina) em bases de dados financeiras. Os diferenciais deste curso é que vamos utilizar bases de dados de empresas brasileiras extraídas da Bolsa de Valores de São Paulo (BOVESPA), bem como a resolução de exercícios em todas as seções. Desta forma, você poderá praticar imediatamente após aprender os conceitos! O conteúdo está dividido em duas partes: na primeira você aprenderá os conceitos básicos de finanças e na segunda parte vamos aplicar machine learning em bases de dados com informações financeiras. Configura abaixo alguns dos tópicos que você aprenderá:\nExtração de bases de dados financeiras da Internet\nCriação de gráficos dinâmicos para visualização de informações financeiras\nAnálise de histograma, boxplot e gráfico de linha para interpretação das bases de dados\nCálculo de retorno simples e cálculo de retorno logarítmico\nCálculo de risco utilizando métricas estatísticas como desvio padrão, variância, covariância e coeficiente de correlação\nAnálise de empresas simulares por meio do coeficiente de correlação\nCálculo de sharpe ratio e Markowitz para análise de carteira de ações\nAlocação de ativos em uma carteira para reduzir os riscos e aumentar os lucros\nUso de algoritmos inteligentes de otimização para escolher os melhores ativos em uma carteira. Implementaremos os seguintes algoritmos: subida da encosta (hill climb), têmpera simulada (simulated annealing) e algoritmos genéticos\nCálculo do famoso modelo CAPM (Capital Asset Pricing Model) para precificação de ativos\nImplementação de Simulações Monte Carlo para previsão do preço de ações\nGeração dos melhores e piores cenários de preços com Simulações Monte Carlo\nUso do algoritmos ARIMA e do Facebook Prophet para previsão do preço de ações\nPré-processamento completo em uma base de dados com as características de mais de 300 empresas da BOVESPA, com o objetivo de prever as melhores empresas para investimento a longo prazo\nAplicação do algoritmo k-means para agrupamento de empresas com características simulares\nVisualização e exploração de textos do Twitter que falam sobre finanças, bem como a extração das empresas que as pessoas estão falando e geração dos assuntos/palavras mais frequentes\nCriação de um classificador de sentimentos para indicar se um texto sobre finanças é positivo ou negativo\nTodos os exemplos são desenvolvidos passo a passo sem pressa utilizando o Google Colab on-line e a linguagem Python, ou seja, o único software necessário para acompanhar o curso é qualquer navegador web. Não é necessário gastar tempo instalando ou configurando softwares em sua máquina local! É novo em Python? Não há problema! No final do curso você conta com aulas básicas sobre essa linguagem de programação!\nEste é o curso ideal caso você queira aumentar significativamente seus conhecimentos em Finanças, Análise de Dados, Ciência de Dados e Machine Learning! Ao final, você aprenderá tudo o que precisa saber para construir seus próprios projetos e realizar suas próprias análises financeiras! São 200 aulas com exercícios resolvidos! O curso é para todos os níveis de conhecimento, ou seja, se você é iniciante ou de nível avançado conseguirá aproveitar o conteúdo.",
      "target_audience": [
        "Pessoas que queiram entender a relação entre a programação e finanças",
        "Pessoas interessadas em como aplicar a linguagem Python em bases de dados financeiras",
        "Alunos de graduação e pós-graduação que estão cursando disciplinas ligadas a área de Finanças e Ciência de Dados",
        "Qualquer pessoa interessada em Finanças, Machine Learning, Ciência de Dados ou Inteligência Artificial",
        "Cientistas de Dados que queiram aprender conceitos sobre finanças"
      ]
    },
    {
      "title": "【ゼロから始めるデータ分析】 ビジネスケースで学ぶPythonデータサイエンス入門",
      "url": "https://www.udemy.com/course/optworks_1/",
      "bio": "分析コンペティションに参加しながら回帰分析による売上予測、機械学習での顧客ターゲティングなど実践的なビジネス課題でデータ分析の一連の流れを身に着けよう。 プログラミング初心者にもおすすめ。",
      "objectives": [
        "Pythonの基礎を身につけられます。",
        "2つのケースを通して、ビジネス上のデータ分析ができるようになります。"
      ],
      "course_content": {
        "はじめに": [
          "【スライド】本講座について",
          "【スライド】本講座の流れ"
        ],
        "分析環境を整えよう": [
          "【スライド】pythonとjupyter",
          "【スライド】インストールしてみよう",
          "Anacondaのインストール（windows）",
          "Anacondaのインストール（mac）",
          "【ドキュメント】Anacondaについて",
          "Matplotlibの日本語化について",
          "Matplotlibの日本語化 (Windows)",
          "Matplotlibの日本語化（mac）",
          "【ドキュメント】Matplotlibの日本語化について"
        ],
        "まずデータに向き合おう": [
          "【スライド】データに向き合う前に",
          "【ドキュメント】SIGNATE（旧DeepAnalytics）からデータをダウンロードしよう",
          "【ドキュメント】教材をダウンロードしよう",
          "【スライド】jupyterの立ち上げ方について",
          "jupyterを立ち上げてみよう",
          "【スライド】まず基礎分析と可視化をしてみましょう",
          "データを読み込んでみよう",
          "【実習１】答え合わせ",
          "【実習２】答え合わせ",
          "【実習３】答え合わせ",
          "【実習４】答え合わせ",
          "【実習５】答え合わせ",
          "【スライド】Pythonの基礎",
          "データをもう少し詳しく見てみよう",
          "【実習１】答え合わせ",
          "【実習２】答え合わせ",
          "【実習３】答え合わせ",
          "【実習４】答え合わせ",
          "【実習５】答え合わせ",
          "【実習６】答え合わせ",
          "グラフを描いてみよう",
          "グラフを描いてみよう（ヒストグラム）",
          "グラフを描いてみよう（箱ひげ図）",
          "【実習１】答え合わせ",
          "【実習２】答え合わせ",
          "【実習３】答え合わせ",
          "【スライド】色々なプロット",
          "欠損値を調べてみよう",
          "相関関係を見てみよう"
        ],
        "予測するってどういうこと？": [
          "【スライド】目的変数と説明変数",
          "【スライド】代表的な予測問題",
          "【スライド】予測モデルを作るキホン"
        ],
        "CASE1：お弁当大作戦～お弁当の売り上げを予測してみよう～": [
          "【スライド】お弁当大作戦に挑戦してみよう",
          "【ドキュメント】教材をダウンロードしよう",
          "簡単な予測モデルを作ってみよう",
          "【実習１】答え合わせ",
          "【実習２】答え合わせ",
          "【実習３】答え合わせ",
          "【実習４】答え合わせ",
          "【実習５】答え合わせ",
          "【実習６】答え合わせ",
          "【実習７】答え合わせ",
          "【実習８】答え合わせ",
          "【実習９】答え合わせ",
          "【実習10】答え合わせ",
          "【実習11】答え合わせ",
          "【実習12】答え合わせ",
          "SIGNATE（旧DeepAnalytics）に結果を投稿しよう①",
          "submit1の投稿結果を確認してみよう",
          "submit2の投稿結果を確認してみよう",
          "【スライド】モデルの評価方法",
          "【スライド】重回帰モデルとダミー変数化",
          "重回帰モデルを作ってみよう",
          "【実習１】答え合わせ",
          "【実習２】答え合わせ",
          "【実習３】答え合わせ",
          "【実習４】答え合わせ",
          "SIGNATE（旧DeepAnalytics）に結果を投稿しよう②",
          "submit3の投稿結果を確認してみよう",
          "【スライド】特徴量の作成・選択",
          "特徴量を作ってみよう①",
          "SIGNATE（旧DeepAnalytics）に結果を投稿しよう③",
          "submit4の投稿結果を確認してみよう",
          "特徴量を作ってみよう②",
          "SIGNATE（旧DeepAnalytics）に結果を投稿しよう④",
          "submit5の投稿結果を確認してみよう"
        ],
        "CASE2：優良顧客を探せ！～銀行の顧客ターゲティング～": [
          "【スライド】優良顧客を探せ！に挑戦してみよう",
          "【ドキュメント】教材をダウンロードしよう",
          "基礎分析をしよう",
          "【実習１】答え合わせ",
          "【実習２】答え合わせ",
          "【実習３】答え合わせ",
          "【実習４】答え合わせ",
          "【実習５】答え合わせ",
          "【実習６】答え合わせ",
          "【実習７】答え合わせ",
          "【スライド】機械学習に触れてみよう",
          "【ドキュメント】Graphvizのインストールについて",
          "Graphvizのインストール①（windows）",
          "Graphvizのインストール②（windows）",
          "Graphvizのインストール③（windows）",
          "Graphvizのインストール①（mac）",
          "Graphvizのインストール②（mac）",
          "Graphvizのインストール③（mac）",
          "決定木のモデルを作ってみよう",
          "SIGNATE（旧DeepAnalytics）に結果を投稿しよう⑤",
          "submit1_bankの投稿結果を確認してみよう",
          "【実習１】答え合わせ",
          "【実習２】答え合わせ",
          "【実習３】答え合わせ",
          "【実習４】答え合わせ",
          "【実習５】答え合わせ",
          "SIGNATE（旧DeepAnalytics）に結果を投稿しよう⑥",
          "submit2_bankの投稿結果を確認してみよう",
          "【スライド】パラメータとは？",
          "パラメータをチューニングしてみよう①",
          "パラメータをチューニングしてみよう②",
          "SIGNATE（旧DeepAnalytics）に結果を投稿しよう⑦",
          "submit3_bankの投稿結果を確認してみよう",
          "【実習１】問題について",
          "【実習１】答え合わせ",
          "【実習２】答え合わせ",
          "【実習３】答え合わせ",
          "【実習４】答え合わせ",
          "【実習５】答え合わせ",
          "【実習６】答え合わせ",
          "SIGNATE（旧DeepAnalytics）に結果を投稿しよう⑧",
          "submit4_bankの投稿結果を確認してみよう"
        ],
        "次のステージへ": [
          "【スライド】本講座のまとめ"
        ],
        "よくある質問": [
          "【ドキュメント】よくある質問"
        ]
      },
      "requirements": [
        "特にありません"
      ],
      "description": "【概要】\n本講座では、データサイエンスをこれから勉強したい方や興味はあるが何をどうやって勉強すれば良いかわからない方、及びプログラミング初心者を対象としています。データサイエンスの一連の流れを体験できるカリキュラムとなっており、学ぶべきことのヒントを散りばめ、よりステップアップしていく為の足掛かりとなるような設計を心がけました。\n【本講座のこだわり】\n実践を重視し、リアルなデータと課題を教材として採用しています\n言葉や概念を学習するスライドの章とプログラミングしながら実践する章の２つを用意しています\n一問一答形式の教材を用意。問題を解き進めることでプログラミングが徐々に身につき、データサイエンスの流れが体験できるようになっています\n分析コンペティションも教材として採用し、楽しみながら学習が進められます\n講座終了後に使用した教材が自身の教科書となるようになっており、もう一度ご自身の力で教材の問題を解き直すことで復習にも利用できます\n発展的な内容は極力除外し、なるべく平易な表現や例を使い、イメージで理解できるように工夫しました\n【その他】\npython3を採用し、プログラミング環境はjupyter notebookを利用\n11個のjupyter notebookファイルをオリジナル教材として用意\n【講師より】\n本講座でご紹介するのはデータサイエンスの中でもごく一部ですが、概要がわかり、ちょっと手が動かせるようになると、ご自身でどんどん学習を進められるようになります。より多くの方がデータサイエンスに興味を持っていただき、ご活躍頂ける為に、本講座が少しでも皆さんのお役に立てれば幸いです。",
      "target_audience": [
        "データサイエンスの基礎を身につけて、仕事に活かしたいビジネスマン",
        "データサイエンスの基礎を身につけて、研究や就職活動に活かしたい大学生",
        "プログラミング未経験者でも安心して始められます。"
      ]
    },
    {
      "title": "Advanced Data Warehouse Performance Optimization",
      "url": "https://www.udemy.com/course/advanced-data-warehouse-performance-optimization/",
      "bio": "Unlocking Databricks: Advanced Techniques for Optimizing Data Warehouse Performance & UDF-driven Processing",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "A solid understanding of SQL (Structured Query Language) is required.",
        "Familiarity with ETL (Extract, Transform, Load) processes and concepts is recommended.",
        "Basic experience with data engineering tools like Apache Spark or Databricks is helpful but not mandatory.",
        "A willingness to dive deep into performance optimization techniques!"
      ],
      "description": "Are you ready to supercharge your data warehouse performance optimization and data processing capabilities? In this Intermediate-level course, you'll dive deep into advanced techniques using Databricks and User-Defined Functions (UDFs) to enhance data processing workflows and boost query performance.\nCourse Overview:\nThis course is designed to take you beyond the basics, giving you the tools to optimize data warehouse performance and build efficient, scalable data pipelines. By utilizing Databricks—a powerful cloud-based platform for big data and AI—you'll gain hands-on experience in data warehouse optimization, UDF creation, and performance tuning.\nWhat You Will Learn:\nAdvanced Data Warehouse Optimization: Learn to fine-tune queries, manage clusters, and optimize data storage for faster query execution.\nUser-Defined Functions (UDFs): Master UDF creation to handle custom data transformations and enhance processing efficiency.\nData Processing Pipelines: Build robust pipelines with Databricks, optimizing data ingestion, transformation, and consistency across processes.\nPerformance Tuning: Dive into performance diagnostics, tackle bottlenecks, and scale your Spark jobs for large datasets.\nBest Practices: Discover industry best practices for efficient data processing and optimization within Databricks, backed by real-world case studies.\nHands-On Projects:\nWork through practical examples and real data scenarios to consolidate your learning and build a strong portfolio.\nPrerequisites:\nThis course is ideal for individuals with a foundational understanding of data warehousing and SQL. Familiarity with Databricks is recommended but not mandatory.\nBy the end of the course, you'll be proficient in optimizing data warehouse performance, creating custom UDFs, and building efficient, high-performance data pipelines. A certificate of completion will be awarded to recognize your expertise in advanced data warehouse optimization.\nDon’t miss the chance to unlock the full potential of your data! Enroll now and elevate your career in data engineering, data science, or business intelligence!",
      "target_audience": [
        "Data Engineers: Professionals with foundational knowledge of data warehousing and Databricks who want to sharpen their performance optimization skills.",
        "Intermediate Data Analysts: Analysts looking to optimize query performance and master UDFs (User-Defined Functions) within Databricks environments.",
        "Data Scientists: Practitioners seeking to extend their data handling and optimization capabilities for faster model training and better insights.",
        "Business Intelligence (BI) Professionals: Those working with large datasets who want to streamline data workflows and enhance reporting efficiency."
      ]
    },
    {
      "title": "Kaggleで始めるPython AI機械学習入門コース｜高評価現役講師が丁寧にレクチャー",
      "url": "https://www.udemy.com/course/kagglepython-ai/",
      "bio": "現役データサイエンティスト兼セミナー講師が作成した「Pythonによる機械学習プログラミング」の講座です。初めて学ぶ方を対象に、一から必要なことを丁寧に紹介します。基礎を学んだ後に「自発的に踏み出せるようになる」ことが講座のゴールです！",
      "objectives": [
        "Pythonの基本的なプログラミング",
        "AI、機械学習の概要",
        "Kaggleの使い方、コンペの参加方法",
        "データ分析や機械学習のプログラミング方法",
        "スキルアップに向けて次に学ぶべき指針"
      ],
      "course_content": {
        "はじめに": [
          "コース概要と目的",
          "未来に向けてのステップ",
          "ご挨拶"
        ],
        "コースの全体像と進め方": [
          "Kaggleの概要と最初に目指す近い未来",
          "講座の内容と開発環境",
          "コラム"
        ],
        "（STEP1）Pythonの基本的な書き方を学ぶ": [
          "このセクションで作成したサンプルファイル",
          "このセクションで学ぶこと",
          "Pythonの開発環境を用意しよう",
          "Python(Anaconda)をインストールしよう",
          "実践の注意点やポイント",
          "Google Colaboratoryを使ってみよう",
          "変数①",
          "変数②",
          "リスト",
          "タプル",
          "辞書",
          "比較演算",
          "条件分岐演算",
          "繰り返し演算",
          "実習①：基礎演算",
          "関数",
          "Numpy",
          "Pandas",
          "Matplotlib",
          "実習②：ライブラリ",
          "学んだことチェック",
          "コラム"
        ],
        "（STEP2）機械学習の基礎知識を学ぶ": [
          "このセクションで学ぶこと",
          "AIとは？",
          "機械学習とは？",
          "機械学習の種類",
          "教師あり学習",
          "強化学習",
          "教師なし学習",
          "データ分析に必要な知識",
          "統計指標（平均）",
          "統計指標（中央値・最頻値）",
          "統計指標（分散・標準偏差）",
          "可視化（基本のグラフ）",
          "可視化（散布図・バブルチャート）",
          "可視化（ヒストグラム・箱ひげ図）",
          "統計指標と可視化の注意",
          "学んだことチェック",
          "コラム"
        ],
        "（STEP3）Kaggleで実践を交えながら学ぶ": [
          "このセクションで作成したサンプルファイル",
          "全体像の確認",
          "Kaggleのアカウントを作成しよう",
          "Kaggleの基本操作を確認しよう①",
          "Kaggleの基本操作を確認しよう②",
          "Kaggleの基本操作を確認しよう③",
          "モデル作成の流れ",
          "Lesson1：データを読み込んでみよう",
          "Lesson1：主要な統計指標を確認しよう",
          "Lesson1：Pandas Profilingを使ってみよう",
          "Lesson1：特徴量と目的変数の関係性を確認しよう①",
          "Lesson1：特徴量と目的変数の関係性を確認しよう②",
          "Lesson1：特徴量エンジニアリンクとは",
          "Lesson1：特徴量エンジニアリンクの実践①",
          "Lesson1：特徴量エンジニアリンクの実践②",
          "Lesson1：（補足）One-Hotエンコーディングとは",
          "Lesson1：モデル作成実践①（ランダムフォレストとは）",
          "Lesson1：モデル作成実践②（ランダムフォレストの実装）",
          "Lesson1：モデル作成実践③（予測結果のsubmit）",
          "Lesson1：モデル作成実践④（スコアの確認）",
          "Lesson2：精度向上に向けて取り組むこと",
          "Lesson2：ロジスティック回帰とアルゴリズムチートシート",
          "Lesson2：ロジスティック回帰を実装しよう",
          "Lesson3：新たな特徴量を作ろう①",
          "Lesson3：新たな特徴量を作ろう②",
          "Lesson3：新たな特徴量を作ろう③",
          "Lesson4：LightGBMと過学習",
          "Lesson4：教師データの分割と検証",
          "Lesson4：LightGBMを実装しよう",
          "Lesson4：予測の実施から精度を確認しよう",
          "Lesson5：パラメータチューニングしてみよう",
          "Lesson6：交差検証とは",
          "Lesson6：交差検証（KFold）を実装しよう",
          "Lesson7：交差検証（StratifiedKFold）を実装しよう",
          "Lesson7：時系列データに関する注意",
          "Lesson8：アンサンブルしてみよう",
          "学んだことチェック"
        ],
        "（STEP4）今後の方針を学ぶ": [
          "コンペで入賞し賞金を得る未来を目指す",
          "データサイエンティストとして働いている未来を目指す",
          "Pythonicなエンジニアになる未来を目指す",
          "アンケートのお願いと今後作成予定の動画について"
        ]
      },
      "requirements": [
        "プログラミングが行えるPCとネットワーク環境が用意できる"
      ],
      "description": "■このコースのゴール\nAI機械学習の基本的なプログラミング方法を習得し、さらに目標に向けて自発的に踏み出せるようになる。\n■受講後にできるようになることの一例\n・Pythonの基本的なプログラミングができる\n・AI、機械学習とは何か基礎知識をもとに説明できる\n・機械学習による予測モデルの作成フローを理解し、自分で作成できる\n・自分に合ったKaggleのコンペを探し、参加できる\n・今後の目標を立て、さらなるスキル習得に向けて自発的に踏み出せる\n※いくつか無料のプレビュー動画を公開しておりますので、イメージ確認のためぜひご覧ください。\n\n\nセクション1 はじめに\nコース概要と目的\n未来に向けてのステップ\nご挨拶\n\n\nセクション2 コースの全体像と進め方\nKaggleの概要と最初に目指す近い未来\n講座の内容と開発環境\nコラム\n\n\nセクション3 （STEP1）Pythonの基本的な書き方を学ぶ\nこのセクションで学ぶこと\nPythonの開発環境を用意しよう\nPython(Anaconda)をインストールしよう\n実践の注意点やポイント\nGoogle Colaboratoryを使ってみよう\nPython速習①：基礎構文\n・変数①\n・変数②\n・リスト\n・タプル\n・辞書\n・比較演算\n・条件分岐演算\n・繰り返し演算\n・実習①：基礎演算\n・関数\nPython速習②：ライブラリ\n・Numpy\n・Pandas\n・Matplotlib\n・実習②：ライブラリ\n学んだことチェック\nコラム\n\n\nセクション4 （STEP2）機械学習の基礎知識を学ぶ\nこのセクションで学ぶこと\nAIとは？\n機械学習とは？\n機械学習の種類\n教師あり学習\n強化学習\n教師なし学習\nデータ分析に必要な知識\n統計指標（平均）\n統計指標（中央値・最頻値）\n統計指標（分散・標準偏差）\n可視化（基本のグラフ）\n可視化（散布図・バブルチャート）\n可視化（ヒストグラム・箱ひげ図）\n統計指標と可視化の注意\n学んだことチェック\nコラム\n\n\nセクション5 （STEP3）Kaggleで実践を交えながら学ぶ\n全体像の確認\nKaggleのアカウントを作成しよう\nKaggleの基本操作を確認しよう\nモデル作成の流れ\nTitanicコンペに挑戦！\nLesson1：データを読み込んでみよう\nLesson1：主要な統計指標を確認しよう\nLesson1：Pandas Profilingを使ってみよう\nLesson1：特徴量と目的変数の関係性を確認しよう\nLesson1：特徴量エンジニアリンクとは\nLesson1：特徴量エンジニアリンクの実践\nLesson1：（補足）One-Hotエンコーディングとは\nLesson1：モデル作成実践①（ランダムフォレストとは）\nLesson1：モデル作成実践②（ランダムフォレストの実装）\nLesson1：モデル作成実践③（予測結果のsubmit）\nLesson1：モデル作成実践④（スコアの確認）\nLesson2：精度向上に向けて取り組むこと\nLesson2：ロジスティック回帰とアルゴリズムチートシート\nLesson2：ロジスティック回帰を実装しよう\nLesson3：新たな特徴量を作ろう\nLesson4：LightGBMと過学習\nLesson4：教師データの分割と検証\nLesson4：LightGBMを実装しよう\nLesson4：予測の実施から精度を確認しよう\nLesson5：パラメータチューニングしてみよう\nLesson6：交差検証とは\nLesson6：交差検証（KFold）を実装しよう\nLesson7：交差検証（StratifiedKFold）を実装しよう\nLesson7：時系列データに関する注意\nLesson8：アンサンブルしてみよう\n学んだことチェック\n\n\nセクション6 （STEP4）今後の方針を学ぶ\nコンペで入賞し賞金を得る未来を目指す\nデータサイエンティストとして働いている未来を目指す\nPythonicなエンジニアになる未来を目指す\nアンケートのお願いと今後作成予定の動画について",
      "target_audience": [
        "Pythonプログラミングを1から丁寧に学びたい方",
        "AI、機械学習の基礎を知りたい方",
        "Kaggleの使い方を学び、コンペに参加してみたい方",
        "自分のペースでゆっくり学びたい方",
        "基礎を学んだ上で、次の指針まで知りたい方"
      ]
    },
    {
      "title": "Master NLP Transformers Unlock the Power of Sequence Models",
      "url": "https://www.udemy.com/course/transform-your-skills-mastering-nlp-transformers-sequence/",
      "bio": "Mastering NLP Techniques for Enhanced Conversational AI",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "The course on advanced word embedding using Twitter datasets is designed to be accessible for learners of various backgrounds. There are no specific prerequisites. Beginners are welcome! All you need is enthusiasm to learn and a basic understanding of Python programming would be beneficial but not mandatory."
      ],
      "description": "Unlock the Power of Language with NLP Transformers\nMaster the art of natural language processing (NLP) with our in-depth course on transformers and sequence-to-sequence models. Whether you're building intelligent chatbots, analyzing sentiment, or creating groundbreaking language applications, this course equips you with the essential skills to excel.\nDive deep into:\nTransformer architecture: Understand the mechanics behind BERT, GPT, and T5.\nSequence-to-sequence models: Tackle complex NLP tasks like translation and summarization.\nHands-on projects: Apply your knowledge to real-world challenges.\nAdvanced techniques: Explore transfer learning, attention mechanisms, and the latest breakthroughs.\nWhy choose this course?\nIndustry-focused curriculum: Learn practical skills directly applicable to your career.\nExpert instruction: Benefit from insights from experienced NLP practitioners.\nStrong community support: Connect with fellow learners and get your questions answered.\nLifetime access: Learn at your own pace and revisit course materials as needed.\nWho is this course for?\nData scientists and machine learning engineers seeking to advance their NLP expertise.\nAI enthusiasts are passionate about building intelligent language applications.\nDevelopers looking to create innovative NLP-powered products.\nReady to transform your NLP capabilities? Enroll now and join the community of NLP experts!\nKey Improvements:\nStronger call to action: Encourages immediate enrollment.\nClearer benefits: Highlights the practical value of the course.\nConcise and engaging language: Improves readability.\nExpanded target audience: Includes developers for broader appeal.\nBy incorporating these enhancements, your course description will be more persuasive and attract a wider range of potential students.",
      "target_audience": [
        "This course is designed for data scientists, natural language processing (NLP) engineers",
        "It caters to professionals seeking to leverage social media data for sophisticated text analysis",
        "Whether you're exploring career advancement or deepening your expertise in NLP,"
      ]
    },
    {
      "title": "Introduction to Human Data & AI Data Training (Micro Course)",
      "url": "https://www.udemy.com/course/introduction-to-human-data-and-ai-data-training/",
      "bio": "Learn Foundational Concepts About Human Data and AI Data Training/AI Tutoring.",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "The Importance of Data in training AI models": [
          "Data & Machine Learning Techniques"
        ],
        "Human Data": [
          "Human Data Explained"
        ],
        "AI Data Training": [
          "Data Annotators vs AI Data Trainers"
        ],
        "Skills AI Companies Seek in Data Trainers": [
          "What AI Companies Look for in Data Trainers"
        ],
        "Wrapping up": [
          "Conclusion: Your Path Forward in the Human Data & AI Training Industry"
        ]
      },
      "requirements": [
        "No experience required."
      ],
      "description": "Human data plays a crucial role in training AI models but remains one of the least publicly documented parts of the field. While major AI companies like OpenAI and xAI are growing their human data teams, most people don’t even know what human data actually is.\nThis course provides an overview of Human Data and the skills needed to work as an AI data trainer/AI tutor.\nWe’ll also introduce you to the growing role of AI data trainers—the people behind the data that is shaping modern AI models. This is a fast-growing field, and many AI companies are actively searching for skilled trainers who can provide human data to improve the performance of their AI models.\nThis course is designed to give you a clear, straightforward introduction to human data and AI data training. By the end, you’ll have a solid foundation and a better understanding of the opportunities in this field.\nDesigned for beginners, this micro-course offers a clear and accessible starting point for those interested in working with AI training data. Whether you’re curious about AI data work or considering a role in AI data training, this course will give you essential insights into the field and how human expertise contributes to machine learning advancements.",
      "target_audience": [
        "Anyone curious about the Human Data.",
        "Aspiring/Current AI Data Trainers/AI Tutors looking to solidify their understanding of the Human Data field.",
        "Anyone interested in the data used to train AI models.",
        "Professionals & experts)looking to apply their skills (technical or non-technical) in a rapidly growing field.",
        "Linguists and writers looking to apply their skills in the AI industry."
      ]
    },
    {
      "title": "データサイエンスのための実践Pandas",
      "url": "https://www.udemy.com/course/be-a-pandas-pro/",
      "bio": "プロレベルのデータ分析スキルを習得しよう",
      "objectives": [
        "データ分析において重要なPandasの体系的な理解",
        "matplotlib, seaborn, plotlyなどの可視化ライブラリの実践的知識",
        "種々の実データに対する前処理、集計、可視化の実用的な知識",
        "探索的データ分析を通じて実践レベルのデータ分析スキル"
      ],
      "course_content": {},
      "requirements": [
        "Pythonの基本的な文法が理解できている必要があります。",
        "Google Colaを使用する為、Googleアカウントが必要です。"
      ],
      "description": "【Pandasを学ぶメリット】\nPandasはPythonでデータ分析を行う上で最も重要なライブラリの１つです。\nPandasはDataFrameをコアとしてデータの前処理/集計/可視化など分析に必要な非常に多くの機能を持ち合わせています。\nこの為、Pandasのスキルはデータ分析のスキルに直結します。\n一方で、できることが多い分、使いこなすためには知っておくべき知識やTipsが数多くあります。\n\n\n【人事の方/マネージャークラスの方へ】\n本コースは次のような使い方が可能です。\n・DX推進チームを立ち上げたが、チーム全体のデータ分析スキルを底上げしたい\n・データは溜まりつつあるが、実用レベルのデータ分析をこなせるデータサイエンティストを育成する必要がある\n本コースを修了すると、社内で蓄積しているデータを適切に集計・可視化しプロレベルの分析スキルを持つ人材を育成できます。\n\n\n【本コースの目的】\nそこで、本コースは敢えて、Pandasと可視化のみにトピックを絞り、この２つを集中的に解説していきます。\nやることを絞っているため、短時間で効率よく、データ分析に必要なスキルのエッセンスを身に付けることが本コースの目的です。\nまた、最後に学んだことを実務に活かせるレベルに落とし込むために探索的データ分析による演習があります。\n\n\n【対象者とゴール】\n本コースではPandasと可視化のトピックに特化しており、レベルとしても中級レベルにあたります。\nこの為、Pythonの基本的な文法には十分に習熟しておく必要があります。\n\n\n本コースを修了すると、Pythonにおけるデータ分析のスキルとしては実用レベルのスキルが習得できます。\n特にコースの中では実際のデータ分析の状況で使用するようなコードやTipsを紹介していきますので、実務にすぐに応用可能です。\n\n\nゴールイメージとしては、\"Pandasを使える人\"から\"Pandasを使いこなせる人\"へNext Levelにレベルアップ可能です。\n\n\n【コースの概要】\n詳細は本コースの概要説明をご覧ください。\n本コースは大きく\n・Pandas基礎/応用\n・可視化\n・探索的データ分析\nの３つのパートに分かれています。\n\n\nPandas基礎/応用では\nPandasにおけるDataFrameとは何かという基本的なところから出発し、\n・データの選択/抽出\n・データの生成 / 消去 / 演算\n・データの前処理(データ型 / Null値の処理 / / 重複データの処理)\n・データの集計(Group by / pivot_table / meltなど)\n・テーブルの結合\nなどPandasに関する項目を体系的に解説します。\n\n\n可視化についてはデータ分析の実務上最もよく使うと想定される\nmatplotlib, seaborn, plotlyについて解説を行います。実際に使う可能性の高い可視化を優先的に解説しています。\n\n\n探索的データ分析ではここまでに学習した内容を活きたデータ分析にする為、\n実際のログデータを用いた探索的データ分析を行います。\nここでは実データの前処理、集計、可視化など実務で必要となるデータ分析の流れを体験する事ができ、プロレベルのデータ分析スキルを習得する事が出来ます。また、データを多面的に見る過程で多くの洞察を得ますので、分析内容を追うだけでも楽しめる内容となっております。\n\n\n【コースの特徴】\n本コースには以下のような特徴があります。\n・ハンズオン\nコースはハンズオンであり、講師が受講生と一緒にスクラッチからコードを書いていきます。\nこの為、実際の実務と同じ流れでstep by stepでコードの実装を学習する事が出来ます。\n\n\n・様々な業界の実データを取り扱う\n本コースは学習する内容を実務レベルで活かせるようにするために\n様々なビジネスの実データを取り扱っています。\n・売り上げのトランザクションデータ\n・不動産取引のログ\n・サービスの使用ログ\nこれらデータの前処理も含めて学ぶことができるので、実際的なスキルが身に付きます。",
      "target_audience": [
        "データサイエンスにおいて実践的なスキルを身に着けたい方",
        "データアナリスト・データサイエンティストを目指している方",
        "データ分析を担当している方で体系的にPandas・可視化スキルを学びたい方"
      ]
    },
    {
      "title": "Mastering Vector Databases & Embedding Models in 2025",
      "url": "https://www.udemy.com/course/mastering-vector-databases-embedding-models-in-2025/",
      "bio": "Learn embeddings, similarity search, HNSW, IVF, semantic search, RAG, and recommender systems with hands-on examples.",
      "objectives": [],
      "course_content": {
        "Foundations of Embeddings & Similarity": [
          "What Are Embeddings?",
          "Section 1 Notebook",
          "Creating & Visualizing Embeddings with Sentence Transformers",
          "Understanding Vector Similarity Metrics",
          "Creating a Mini-Search Engine Using Embeddings"
        ],
        "Choosing and Using Embedding Models": [
          "Understanding Embedding Models: Tokenizer & Architecture",
          "Evaluating and Selecting Text Embedding Models",
          "Multimodal Models - A Brief Overview",
          "Working with Multimodal Models in Transformers",
          "Fine-Tuning Embedding Models with Contrastive Loss"
        ],
        "How Vector Databases Work": [
          "Introduction to Vector Database Indexing & Retrieval Strategies",
          "HNSW - Indexing & Retrieval Explained",
          "Section 3 Notebook",
          "HNSW Implementation in FAISS",
          "IVF - Indexing & Retrieval Explained",
          "IVF Implementation in FAISS"
        ],
        "Vector Databases: Landscape & Applications": [
          "Overview of Vector Database Landscape + Pinecone Introduction",
          "Section 4 Notebook",
          "Semantic Search with Pinecone",
          "Retrieval Augmented Generation (RAG) with Pinecone",
          "Recommender Systems with Pinecone",
          "Bonus Lecture - Free AI Research Newsletter"
        ]
      },
      "requirements": [
        "Basic Python knowledge recommended, but step-by-step coding lessons are provided.",
        "No prior experience with embeddings, vector databases, or similarity search is required."
      ],
      "description": "Embeddings and vector databases are the foundation of many modern AI applications — from semantic search to retrieval-augmented generation (RAG) and personalized recommendations. This course takes you from the core concepts to production-ready solutions, following a structured, project-based approach.\nIn Section 1, you’ll build deep intuition about embeddings: what they are, how they are produced with Sentence Transformers, and how similarity metrics like cosine, Euclidean, and dot product work. You’ll then apply these concepts to build a mini search engine.\nIn Section 2, you’ll learn how to choose and customize embedding models. We’ll cover how embedding models are formed, how to evaluate them using the MTEB benchmark, and how to use multimodal embeddings. You’ll then explore fine-tuning with contrastive loss.\nIn Section 3, we go under the hood of vector databases. You’ll learn the theory behind indexing methods like HNSW and IVF through clear visual explanations, followed by coding demos showing them in action.\nIn Section 4, we turn theory into practice. You’ll explore the vector database landscape, implement semantic search and dense retrieval, integrate embeddings into RAG pipelines, and build recommender systems using Pinecone — all with reproducible Python notebooks.\nBy the end of this course, you’ll have both the conceptual understanding and the hands-on skills to confidently build and deploy AI applications powered by embeddings and vector databases.",
      "target_audience": [
        "Data scientists, ML engineers, and software developers exploring vector search.",
        "AI practitioners and enthusiasts who want to apply embeddings in real-world projects.",
        "Professionals interested in semantic search, RAG, and recommender systems."
      ]
    },
    {
      "title": "Big Data y Spark: ingeniería de datos con Python y pyspark",
      "url": "https://www.udemy.com/course/big-data-y-spark-ingenieria-de-datos-con-python-y-pyspark/",
      "bio": "Trabajo desde niveles básicos hasta avanzados con RDD y DataFrame.",
      "objectives": [
        "Conocer el funcionamiento y la estructura de Apache Spark",
        "Trabajar con RDDs de Spark desde niveles básicos hasta avanzados",
        "Trabajar con DataFrames en Spark mediante el API de SQL desde niveles básicos hasta avanzados",
        "Optimizar sus aplicaciones de Apache Spark para el manejo de grandes volúmenes de datos a través de DataFrames"
      ],
      "course_content": {
        "Introducción": [
          "Introducción al curso",
          "Introducción al Big Data",
          "Apache Spark",
          "¿Quién usa Spark y para qué?"
        ],
        "Descargando e instalando Spark en Google Colaboratory": [
          "¿Qué es Colaboratory?",
          "Instalando Colab",
          "Primeros pasos con Colab",
          "Recursos del curso",
          "Descargando e instalando Spark en Colab",
          "¿Dónde más podemos ejecutar Spark con pyspark?",
          "Ventajas y desventajas de trabajar con Spark en Colab"
        ],
        "Introducción a los RDD en Spark": [
          "SparkSession",
          "¿Qué es un RDD?",
          "Diferentes formas de crear un RDD en pyspark",
          "Ejercicios",
          "Resolución de los ejercicios del capítulo"
        ],
        "Transformaciones en un RDD": [
          "Transformaciones en un RDD",
          "Tipos de transformaciones",
          "Función map",
          "Función flatMap",
          "Función filter",
          "Función coalesce",
          "Función repartition",
          "Función reduceByKey",
          "Ejercicios",
          "Resolución de los ejercicios del capítulo"
        ],
        "Acciones sobre un RDD en Spark": [
          "Acciones en un RDD",
          "Tipos de acciones",
          "Función reduce",
          "Función count",
          "Función collect",
          "Funciones take, max y saveAsTextFile",
          "Ejercicios",
          "Resolución de los ejercicios del capítulo"
        ],
        "Aspectos avanzados sobre RDD": [
          "Almacenamiento en caché",
          "Particionado",
          "Mezcla de datos(shuffling)",
          "Broadcast variables",
          "Acumuladores",
          "Ejercicios",
          "Resolución de los ejercicios del capítulo"
        ],
        "Spark SQL": [
          "Introducción a Spark SQL",
          "Crear un DataFrame a partir de un RDD",
          "Crear un DataFrame a partir de fuentes de datos",
          "Crear un DataFrame a partir de fuentes de datos en la práctica (parte I)",
          "Crear un DataFrame a partir de fuentes de datos en la práctica (parte II)",
          "Trabajo con columnas",
          "Transformaciones: funciones select y selectExpr",
          "Transformaciones: funciones filter y where",
          "Transformaciones: funciones distinct y dropDuplicates",
          "Transformaciones: funciones sort y orderBy",
          "Transformaciones: funciones withColumn y withColumnRenamed",
          "Transformaciones: funciones drop, sample y randomSplit",
          "Trabajo con datos incorrectos o faltantes",
          "Acciones sobre un DataFrame en Spark SQL",
          "Escritura de DataFrames",
          "Leer y escribir un DataFrame en un bucket de AWS S3",
          "Leer y escribir un DataFrame en un Blob de Azure",
          "Leer y escribir un DataFrame en un bucket de GCP",
          "Persistencia de DataFrames",
          "Ejercicios",
          "Resolución de los ejercicios del capítulo"
        ],
        "Spark SQL avanzado": [
          "Agregaciones",
          "Funciones count, countDistinct y approx_count_distinct",
          "Funciones min y max",
          "Funciones sum, sumDistinct y avg",
          "Agregación con agrupación",
          "Varias agregaciones por grupo",
          "Agregación con pivote",
          "Joins",
          "Expresión join y tipos de join",
          "Inner Join",
          "Left Outer Join",
          "Right Outer Join",
          "Full Outer Join",
          "Left Anti Join",
          "Left Semi Join",
          "Cross Join",
          "Manejo de nombres de columna duplicados",
          "Shuffle Hash Join y Broadcast Hash Join",
          "Ejercicios",
          "Resolución de los ejercicios del capítulo"
        ],
        "Funciones en Spark SQL": [
          "Funciones de fecha y hora",
          "Funciones para trabajo con strings",
          "Funciones para trabajo con colecciones",
          "Funciones when, coalesce y lit",
          "Funciones definidas por el usuario UDF",
          "Funciones de ventana",
          "Catalyst Optimizer",
          "Ejercicios",
          "Resolución de los ejercicios del capítulo"
        ],
        "Misceláneas": [
          "Habilitar Spark UI en Colab"
        ]
      },
      "requirements": [
        "Solo es deseable conocimientos en Python. Debido a que trabajaremos con Google Colab no necesitamos de computadoras o laptops potentes ni de configuraciones complicadas para correr todos los ejemplos y resolver los ejercicios propuestos."
      ],
      "description": "Bienvenidos al curso Big Data y Spark: ingeniería de datos con Python y pyspark.\n\n\nEn este curso aprenderás a trabajar con Spark a través de la librería PySpark de Python en Google Colaboratory.\n\n\nSpark es esencialmente un sistema distribuido que fue diseñado para procesar un gran volumen de datos de manera eficiente y rápida. El objetivo de este curso es aprender a trabajar con las principales abstracciones de Spark, las cuales son los RDDs y los DataFrames.\n\n\nEl material que proponemos en el curso está pensado para todas las personas que bien deseen iniciarse en el trabajo con Spark, o que por otro lado, deseen consolidar los conocimientos que ya poseen sobre los temas que se abordarán. El curso está diseñado de una forma progresiva y gradual que le permitirá al estudiante entender y desarrollar las principales habilidades para el trabajo con RDDs y DataFrames en Spark. Además, se abordarán temas avanzados que le permitirán optimizar las aplicaciones de Spark que pueda construir en un futuro, o bien, mejorar aquellas que ya se tengan implementadas.\n\n\nEmpezamos el curso con una breve introducción al Big Data y a Spark. Posteriormente continuamos con una sección en donde los guiaremos para que instalen y configuren Spark en Google Colaboratory. Una vez hayan concluido esta sección, estarán en condiciones de ejecutar notebooks en Colaboratory utilizando Spark. Las siguientes secciones del curso están pensadas para entender y aplicar en la práctica las principales cuestiones sobre los RDDs y los DataFrames.\n\n\nEl temario procura en todo momento analizar temas específicos por cada lección, permitiéndole así al estudiante localizar rápidamente cualquier contenido de una forma rápida. La mayoría de las lecciones están conformadas por una parte teórica y otra práctica.\n\n\nMi nombre es José Miguel Moya y me desempeño actualmente como Ingeniero de Datos Senior. Como parte de mi trabajo diario utilizo Spark con Python y Scala para obtener y procesar enormes cantidades de datos.\n\n\nTe invito a que veas el video de presentación del curso y las lecciones gratuitas.\n\n\nTe espero en el curso, tenga usted un cordial saludo.",
      "target_audience": [
        "Este curso va dirigido a todas aquellas personas que estén interesadas en introducirse al mundo del Big Data y al procesamiento de datos a través de Apache Spark. Es una muy buena oportunidad para aquellos que desean consolidar y ampliar sus conocimientos en el trabajo con RDDs y DataFrames en Spark debido a cómo se explican los conceptos y a las actividades prácticas presentadas."
      ]
    },
    {
      "title": "Power BI Completo: De cero a desarrollador Power BI",
      "url": "https://www.udemy.com/course/power-bi-es/",
      "bio": "Curso de Power BI: Inteligencia de Negocios con Power BI",
      "objectives": [
        "📊 A crear de modelos de datos, dashboards y visualizaciones con Power BI",
        "✅ A escribir fórmulas en DAX",
        "📈 Al final del curso podrás crear informes y cuadros de mando para tu uso personal, inspirar a tus compañeros, o persuadir a tus clientes",
        "✅ A entender el flujo de trabajo de Business Intelligence de principio a fin"
      ],
      "course_content": {
        "Presentación del curso": [
          "Presentación del curso",
          "Plataforma y Recursos",
          "¿Que es Power BI?"
        ],
        "Comienza con Power BI": [
          "Instalación de Power BI Desktop",
          "¿Qué hago si no tengo correo del trabajo?",
          "Cambios a la interfaz",
          "La interfaz de Power BI Desktop",
          "Configuración Regional",
          "Importando tu primer csv",
          "Introducción al Editor de Consultas",
          "Tu primer Informe"
        ],
        "Transformación de Datos con Power BI": [
          "Transformar vs Agregar",
          "Agrupaciones",
          "Combinar o Anexar",
          "Actualizar tus datos",
          "Pivotar una tabla",
          "Configuracion de Origen de datos",
          "Editar los formatos",
          "Añadir Categorias",
          "Crear una Columna Condicional"
        ],
        "Modelado de Datos en Power BI": [
          "¿Que es un modelo de datos?",
          "Relaciones",
          "Creando el Calendario",
          "Cardinalidad",
          "Agregando una segunda tabla de hechos",
          "Dirección de filtrado",
          "Esconder campos para mejorar la experiencia"
        ],
        "DAX en Power BI": [
          "¿Que es Dax?",
          "Columna Concatenada: M y DAX",
          "Medidas DAX",
          "Operadores DAX",
          "Funciones Lógicas",
          "Funciones de Texto",
          "Funciones de Fecha y Tiempo",
          "Función RELATED()",
          "Funciones Básicas",
          "Funciones COUNT",
          "Función CALCULATE",
          "Función CALCULATE con ALL",
          "Función CALCULATE con FILTER",
          "Funciones Iteración (X)",
          "Inteligencia de Tiempo",
          "Conclusiones DAX"
        ],
        "Visualiza tus datos con Informes en Power BI": [
          "Comenzando con el Informe",
          "Añadiendo la primera visualización",
          "Tipos de filtrado",
          "Editar interacciones",
          "Visual Matriz",
          "Segmentación o Slicer",
          "Tarjetas o KPIs",
          "Tarjetas de Texto",
          "Añadiendo un mapa",
          "Tree Map (Mapa de Arból)",
          "Detalles y Gráficos de Lineas",
          "Tendencia y Previsión",
          "Medidores",
          "Obtención de Detalles",
          "Marcadores",
          "Parametros nuevos de hipotesis",
          "Roles y Usuarios",
          "Diseñando para telefono"
        ],
        "Power BI Service": [
          "¿Como publico un informe la nube?",
          "Power BI Pro: ¿Para que sirve y como recargo los datos automáticamente?",
          "¿Que son las Aplicaciones en Power BI?",
          "Otras Aplicaciones",
          "Publicando nuestro trabajo a Power BI Service",
          "Informes Power BI en el móvil"
        ],
        "Power BI - Cosas adicionales": [
          "R y Python en Power BI",
          "Market Place de visualizaciones en Power BI",
          "Conclusiones rápidas",
          "¡Ya has terminado!"
        ]
      },
      "requirements": [
        "Ser usuario de PC / Windows.",
        "Descargar Power BI Desktop (Gratis)",
        "Se recomienda tener conocimientos básicos de Excel pero no es necesario"
      ],
      "description": "* Este curso es parte del Data Analyst Bootcamp de Datademia. Visita nuestra web para más información.\n\n\nHola y bienvenidos a este curso de Microsoft Power BI.\nEn este curso aprenderás desde cero a usar Microsoft Power BI para crear informes y cuadros de mando. Trabajarás con Power BI Desktop así que necesitas tener un PC con Windows instalado. Es un curso totalmente práctico y dinámico en el que empezarás desde cero con Power BI.\nPower BI es el líder del mercado de software de inteligencia de negocios (business intelligence) que lleva muchos años consecutivos en el primer puesto del cuadrante mágico de Gartner. Power BI te permite crear aplicaciones con dashboards y todo tipo de visualizaciones de forma muy intuitiva.\nEste curso está diseñado para cualquier persona que quiera empezar a usar Power BI y convertirse en un usuario avanzado en poco tiempo.\nEn más de 5 horas de contenido, cubriremos desde lo más básico como importar archivos a Power BI hasta hacer transformaciones, trabajar con modelos de datos complejos, DAX (lenguaje de expresiones de Power BI) y cómo crear todo tipo de informes. Aprenderás a compartir informes en la nube y crear aplicaciones para poder compartir información dentro de organizaciones.\nMi nombre es Sebastian y llevo más de 6 años trabajando con Big Data en empresas tecnológicas en Barcelona. Como Analista de Datos trabajo desde la extracción y manipulación de datos hasta la creación de dashboards y programación de modelos de aprendizaje automático. Con mi experiencia directa trabajando con Power BI, espero llevarte desde cero a hasta llegar al nivel de usuario avanzado en el menor tiempo posible.\nTe invito a que veas la presentación completa del curso y las lecciones gratuitas.\nCualquier duda que tengas me puedes contactar por mensaje privado dentro de la plataforma.\nTe espero en el curso, un saludo y muchas gracias.",
      "target_audience": [
        "Personas que necesiten aprender Power BI para uso personal, en el trabajo o para su negocio.",
        "Estudiantes de Business Intelligence que quieran entender cómo crear cuadros y informes.",
        "Quieres destacar en tu trabajo o buscar nuevas oportunidades. Power BI es el software de BI más utilizado."
      ]
    },
    {
      "title": "KI & Reinforcement Learning in Python – mit TensorFlow 2",
      "url": "https://www.udemy.com/course/artificial-intelligence-und-reinforcement-learning-in-python/",
      "bio": "Baue deine eigene lernende KI – mit modernen RL-Algorithmen, Simulationen und klassischer Spiel-Intelligenz.",
      "objectives": [
        "Verwende die neuste TensorFlow 2 Version",
        "Entwickle eigene künstliche Intelligenzen",
        "Erlerne die Methoden des Reinforcement Learnings",
        "Programmiere eine AI, die selbstständig Videospiele spielen kann",
        "Programmiere eine AI, die Probleme versteht und lösen kann",
        "Wende Neuronale Netzwerke mit TensorFlow und Keras an",
        "Verstehe die Theorie hinter dem Reinforcement Learning",
        "Verwende die AI Bibliothek Gym für deine Probleme"
      ],
      "course_content": {
        "Kapitel 1: Einleitung des Kurses": [
          "Einleitung in den Kurs",
          "Die Software im Kurs",
          "Informationen zu der Software",
          "Windows: MSVC Compiler Installieren",
          "Windows: Installation von Anaconda",
          "Linux: Installation von Anaconda",
          "Mac: Installation von Anaconda",
          "Handbuch des Kurses",
          "Materialien des Kurses",
          "Die Einrichtung des Environments",
          "CPU: Python Pakete Installieren",
          "GPU: Python Pakete Installieren",
          "Visual Studio Code einrichten",
          "Visual Studio Code verwenden"
        ],
        "Kapitel 2 : Python Zusatzwissen": [
          "Vorwort",
          "Main Funktion",
          "Numpy und Matplotlib Einführung",
          "Slices und Weiteres zu Numpy",
          "f-Strings und Type Annotations"
        ],
        "Kapitel 3: Reinforcement Learning Grundlagen": [
          "Reinforcement Learning - Begriffe",
          "Wir sind der Agent - Teil 1",
          "Code zum Agenten - Teil 1",
          "Markov Process (MP)",
          "Markov Reward Process (MRP)",
          "Wir sind der Agent - Teil 2",
          "Code zum Agenten - Teil 2",
          "Markov Decision Process (MDP)",
          "Berechnung des Discounted Rewards"
        ],
        "Kapitel 4: Einarbeitung in OpenAI - Gym": [
          "Installation von Atari",
          "Das erste Environment starten - Teil 1",
          "Action-Space und Observation-Space",
          "Der grobe Aufbau eines Gym Environments",
          "Das erste Environment starten - Teil 2",
          "Eine generische Agenten Klasse",
          "Der Random Agent im Einsatz",
          "Verschiedene Gym Spiele starten",
          "Ein Atari Spiel selber spielen"
        ],
        "Kapitel 5: Grundlagen des Deep Learnings": [
          "Machine Learning - Grundlagen",
          "Supervised Learning - Grundlagen",
          "Supervised Learning Intuition",
          "Supervised Learning",
          "Was sind Neuronale Netzwerke",
          "Neuronale Netzwerke Intuition",
          "Wie lernt das Neuronale Netzwerk",
          "Der MNIST Datensatz",
          "Der Aufbau des Deep Neural Networks",
          "Deep Neural Network - Programmieren",
          "Optimierung des Netzwerks",
          "Neuronale Netzwerke"
        ],
        "Kapitel 6: Unsere erste KI": [
          "Das Cross-Entropy Learning",
          "Der Aufbau des Agenten",
          "Das Neuronale Netzwerk",
          "Das Training - Teil 1",
          "Das Training - Teil 2",
          "Auswertung",
          "Das MountainCar Spiel - Auswerten"
        ],
        "Kapitel 7-1: Bellman Equation und Value Iteration": [
          "Bellman Equation und Q-Values",
          "Value Iteration Algorithm - Intuition",
          "Das FrozenLake Spiel - Eigene Überlegungen",
          "Value Iteration Algorithm - Programmieren Teil 1",
          "Value Iteration Algorithm - Programmieren Teil 2",
          "Value Iteration Algorithm - Programmieren Teil 3",
          "Die Q-Values und die Policy des VIA Agenten",
          "Weiterführendes: Bellman Equation"
        ],
        "Kapitel 7-2: Policy Iteration Algorithm": [
          "Policy Iteration Algorithm - Intuition",
          "Policy Iteration Algorithm - Programmieren Teil 1",
          "Policy Iteration Algorithm - Programmieren Teil 2"
        ],
        "Kapitel 8: Tabular Q-Learning": [
          "Tabular Q-Learning - Intuition",
          "Tabular Q-Learning - Programmieren Teil 1",
          "Tabular Q-Learning - Programmieren Teil 2",
          "Die Q-Values und die Policy des Q-Tabluar Agenten"
        ],
        "Kapitel 9: Convolutional Neural Networks": [
          "Convolutional Neural Networks",
          "Convolutional Neural Networks - Programmieren",
          "Convolutional Neural Networks"
        ]
      },
      "requirements": [
        "Python Grundlagen",
        "Mathematik Grundlagen aus dem Abitur"
      ],
      "description": "Tauche ein in die spannende Welt der Künstlichen Intelligenz und des Reinforcement Learnings – praxisnah und verständlich mit Python, TensorFlow 2 und Keras!\nIn diesem Kurs lernst du, wie du deine eigene KI entwickelst, die eigenständig handelt, lernt und sich an ihre Umgebung anpasst – z. B. durch das Meistern kleiner Simulationen und klassischer Atari-Spiele. Von den Grundlagen bis zur konkreten Umsetzung: Du wirst Schritt für Schritt an moderne KI-Systeme herangeführt.\nZunächst erhältst du eine fundierte Einführung in Machine Learning und Deep Learning, um die theoretischen und mathematischen Konzepte zu verstehen. Danach lernst du den praktischen Umgang mit den wichtigsten Tools: TensorFlow, Keras und Gym.\nIm Fokus steht dann das Reinforcement Learning (RL) – eine Schlüsseltechnologie der modernen KI. Du wirst verschiedene RL-Techniken kennenlernen und in eigenen Projekten umsetzen, z. B. mit Q-Learning, Deep Q-Networks (DQN) und Policy-Gradient-Methoden.\nAm Ende des Kurses wirst du eine KI bauen, die selbstständig lernt, Entscheidungen trifft und Spiele meistert. Perfekt, um praktische Erfahrungen in einem der spannendsten Bereiche der KI zu sammeln!\nDas lernst du im Kurs:\nGrundlagen von Machine Learning & Deep Learning\nEinstieg in TensorFlow 2, Keras und das OpenAI Gym\nEinführung in das Reinforcement Learning\nAnwendung moderner RL-Techniken: Q-Learning, DQN & mehr\nEntwicklung einer eigenen KI für Simulationen\nUmsetzung einer Atari-Spiel-KI (z. B. CartPole, Breakout)\nStarte jetzt durch in der Technologie von morgen – mit praxisnahen KI-Projekten!\nWir sehen uns im Kurs!\n\n\nHinweis:\nPython wird im Kurs mit Anaconda installiert. Alternativ ist auch eine Einrichtung über andere Quellen möglich.",
      "target_audience": [
        "Studenten, Softwareentwickler und alle Interessierten"
      ]
    },
    {
      "title": "アプリケーション開発者のための機械学習実践講座",
      "url": "https://www.udemy.com/course/ml_for_app_developers/",
      "bio": "本コースは、アプリケーション開発者を対象にした機械学習のコースです。 機械学習単体だけでなく、導入プロセスやプログラム設計指針など、実際の導入に辺り課題となる点も含め解説します。実装では、Pythonを利用した実例も交え学んでいきます。",
      "objectives": [
        "機械学習の仕組み、および特性が理解できます",
        "機械学習が適用可能な領域についての知見が得られます",
        "機械学習を実装する際の選択肢を把握できます",
        "機械学習をアプリケーションに組み込む際の、設計方式を把握できます",
        "機械学習をアプリケーションで使う際に注意すべき点が把握できます"
      ],
      "course_content": {
        "Day0: コース概要": [
          "本コースについての説明"
        ],
        "Day1: キーワードの整理": [
          "キーワードの整理",
          "ディープラーニングについての詳細"
        ],
        "Day2: 機械学習の仕組み": [
          "機械学習の構成要素",
          "学習のさせ方",
          "機械学習の特性"
        ],
        "Day3: 機械学習の適用": [
          "ビジネスシーン",
          "ビジネスシーンへの適用の背景",
          "アートシーン",
          "アートシーンへの適用の背景",
          "今後の適用の方向性"
        ],
        "Day4: 機械学習の実装手段": [
          "実装の選択肢の整理",
          "ライブラリ型",
          "パッケージ型",
          "プラットフォーム型",
          "サービス型",
          "どの方法を選ぶべきか"
        ],
        "Day5: 機械学習アプリケーションの設計": [
          "設計の基本方針",
          "アーキテクチャの構成パターン",
          "プログラムの設計"
        ],
        "Day6: 機械学習アプリケーションの実装": [
          "開発環境の準備",
          "実装の基本的なプロセス",
          "データの前処理",
          "学習用と評価用のデータの分割",
          "モデルの評価",
          "実際のアプリケーションの実装"
        ],
        "Day7: 機械学習アプリケーションの導入と運用": [
          "機械学習の導入検討プロセス",
          "仮説の検証: 業務への貢献を明確にする",
          "仮説の検証: シミュレーションを行いモデルを検証する",
          "実装",
          "運用・評価",
          "まとめ"
        ],
        "Next Step": [
          "Next Step"
        ]
      },
      "requirements": [
        "何らかの言語での、Webアプリケーションの開発経験",
        "Pythonによるプログラミングの基礎的な知識",
        "Git/GitHubを活用した開発についての基礎的な知識"
      ],
      "description": "このコースは、アプリケーション開発者を対象とした機械学習の講座です。\nアプリケーション開発者であれば、当然「機械学習をアプリケーションの中で活用したい」と考えていると思います。しかし、そのためには機械学習「だけ」を学ぶだけでは足りません。\n実際のサービスで使用しようと思えば、機械学習のプログラムをどのように設計・テストし、管理するのかといった点も問題になります。そして、導入した後の運用・保守といった観点も欠かせません。\n本講座では、機械学習そのものの説明はもちろんですが、こうした機械学習をアプリケーションの中に組み込むための実践的な方法・プロセスまで解説します。\n全7セクションとなっており、各セクションは数十分と比較的短い講義から構成されます。短時間で、実務で得られたノウハウを含めてお伝えしたいと思います。\nあなたのアプリケーションを、機械学習で変革するための一助となると思います。",
      "target_audience": [
        "機械学習を、実際にアプリケーションに活かしたい方",
        "機械学習について、理論より実践から入りたい方",
        "機械学習についての基礎的な知識があり、その応用方法を考えている方"
      ]
    },
    {
      "title": "Introduction to Working with GPT 4o Realtime With Tau.js",
      "url": "https://www.udemy.com/course/introduction-to-working-with-gpt-4o-realtime-with-taujs/",
      "bio": "Learn to Work in Realtime with GPT 4o and Get Millisecond Responses with Tau.js",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Course Preview / About the Author",
          "Introduction to the GPT Realtime API and Tau.js"
        ],
        "Working with Realtime Websockets and Tau.js": [
          "Tutorial: Getting from Empty Project to Hello World with Tau.js",
          "Tutorial: Listening to Realtime GPT Audio Using Tau.js and the Debugger",
          "Tutorial: Live Voice Input to ChatGPT Session with Debugger"
        ],
        "Voices Tutorial": [
          "Tutorial - Changing Voices with Tau.js and Realtime GPT"
        ]
      },
      "requirements": [
        "Beginner JavaScript / Node"
      ],
      "description": "In this short introductory course, we'll learn how to install and get started with `tau.js` to create and work with realtime websocket-based GPT connections to 4o realtime and mini\nIn this course we'll:\n- Review What Realtime GPT api is and how it differs from normal GPT\n- What Tau.js is and how it helps facilitate development\n- We'll build a tau.js project from scratch with VSCode\n- We'll get to hello world with websocket-based realtime connections in under 5 minutes\n\n\nWhat is tau.js\ntau.js is a node library that greatly simplifies the Websocket API used to communicate with realtime AI models like 4o-realtime, and adds essential features like realtime voice debugging.\nWith tau.js, Starting a session and generating a voice response is as simple as:\nimport { create_session } from \"@tau/core\"\n\n\nlet session = await create_session()\nawait session.system(\"Whenever prompted to respond, state a different teaching of the Sun Tzu.\")\nawait session.response()\n\n\n// \"The supreme art of war is to subdue the enemy without fighting.\"\nWhy Use tau.js?\ntau.js greatly reduces ramp-up time when building applications with OpenAI's 4o-realtime and 4o-mini-realtime models.\n\n\nSimple Async/Await Interface\nRealtime AI sessions are based on Websockets. This is very good, as websockets are extremely fast and they're a critical part of delivering a fast user experience. But Websockets are hard to develop for and tend to create messy code that can't be maintained.\ntau.js solves this problem by black-boxing away all websocket logic and instead providing a dead-simple async/await API with which to build powerful realtime apps.",
      "target_audience": [
        "Intermediate developers interested in AI",
        "JavaScript / Python Developers"
      ]
    },
    {
      "title": "Learn Data Visualization with Matplotlib",
      "url": "https://www.udemy.com/course/data-visualization-with-matplotlib/",
      "bio": "Data Visualization Mastery: Matplotlib, Plot Types, Exploratory Analysis, and Multi-Panel Figures",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Learning Outcomes": [
          "Learning Outcomes"
        ],
        "Overview": [
          "Overview"
        ],
        "Prerequisites": [
          "Prerequisites"
        ],
        "Basic Structure": [
          "Basic Structure"
        ],
        "Pie Chart": [
          "Pie Chart"
        ],
        "Bar Chart": [
          "Bar Chart"
        ],
        "Histograms": [
          "Histograms"
        ],
        "Line Chart": [
          "Line Chart"
        ],
        "Scatter plot": [
          "Scatter plot"
        ]
      },
      "requirements": [
        "Basic Python programming skills",
        "Basic data wrangling with Python skills"
      ],
      "description": "Are you eager to unlock the power of data visualization with Python? If so, our comprehensive Udemy course, \"Mastering Data Visualization with Matplotlib,\" is the perfect choice for you. In today's data-driven world, effective data visualization is a crucial skill, enabling you to explore, analyze, and present data insights with clarity and impact.\nLearning Outcomes:\nRecall and describe fundamental plot types: Our course begins by teaching you the fundamental types of plots that Matplotlib offers, such as line plots, scatter plots, bar charts, and histograms. You'll not only learn to create these plots but also understand when and why to use each type for effective data representation.\nApply Matplotlib concepts for data exploration: With the knowledge gained, you'll delve into real-world datasets, using Matplotlib to visually explore and analyze data. You'll discover how to identify patterns, trends, and outliers, ensuring you can make data-driven decisions with confidence.\nAnalyze complex data with multi-panel figures: As your skills progress, you'll master the art of creating multi-panel figures and subplots using Matplotlib. This capability allows you to compare and present data from different perspectives, making it a valuable asset for data analysis, presentations, and publications.\nComplete a data visualization project: By the end of this course, you will have the practical experience to tackle a comprehensive data visualization project using Matplotlib. This hands-on project will consolidate your skills and provide you with a strong portfolio piece to showcase your expertise.\nIntended Audience:\nThis course is designed for learners who are keen to explore the realm of data visualization using Python. It caters to those interested in pursuing projects related to data visualization, data analysis, and even machine learning. Whether you are a data enthusiast, a student, a professional, or a business owner, this course will equip you with the skills you need to excel in the data-driven world.",
      "target_audience": [
        "Learning interested in learning about data visualization using Python"
      ]
    },
    {
      "title": "Deep Learning for Natural Language Processing",
      "url": "https://www.udemy.com/course/deep-learning-for-natural-language-processing/",
      "bio": "The Road to BERT",
      "objectives": [
        "Build solid understanding of NLP traditional and Deep Learning techniques",
        "Practice DL NLP in real problems like sentiment classification, machine translation, chatbots and question-answering",
        "Build solid understanding of state-of-the art NLP models like BERT and GPT",
        "Understand the evolution of DL NLP word and sentence embedding models using word2vec, GloVe, Fasttext, ELMo, BERT",
        "Mastet the use of Transfer Learning in modern NLP models"
      ],
      "course_content": {
        "Module 1: Introduction to NLP": [
          "Module intro and roadmap",
          "Why NLP is hard?",
          "NLP tasks and apps",
          "CV vs NLP analogy",
          "DL in NLP and Bag-of-Words model",
          "Text preprocessing pipeline",
          "Text preparation steps",
          "Text features: Binary-Count- Freq- TF-IDF"
        ],
        "Introduction": [
          "Introduction"
        ],
        "Module 2: Word Representations": [
          "Module intro and roadmap",
          "Why word embeddings?",
          "Traditional word vectors",
          "Learnable Embedding matrix",
          "BoW Vectors model",
          "Structured Deep Learning",
          "Pre-trained word embeddings",
          "Word2Vec",
          "GloVe",
          "FastText and ELMo",
          "Evaluation of Word Embedding vectors"
        ],
        "Recommender Systems": [
          "Overview of recommender systems",
          "Content-based recommendations",
          "Collaborative-Filtering"
        ],
        "Module 3: Sequence models": [
          "Module intro and roadmap",
          "Statistical Langauge Models (SLM)",
          "Neural Language Models (NLM)",
          "Recurrent Neural Networks",
          "RNN as Sentence Embedding Encoder",
          "Example RNN char level NLM",
          "Example RNN word level NLM",
          "Language Models evaluation methods",
          "Long-Short Term Memory (LSTM) and Gated Recurrent Units (GRU)",
          "Example: LSTM/GRU for Text Classification apps",
          "Conv1D and CNN-LSTM models"
        ],
        "Module 4: Sequence-to-Sequence models": [
          "Module intro and roadmap",
          "Seq2seq models overview",
          "Unaligned/Matched sequences case (CTC loss)",
          "Statistical Machine Translation (SMT)",
          "Neural Machine Translation (NMT) and Vanilla seq2seq model",
          "NMT decoding and Beam-Search",
          "Attention mechanisms with seq2seq models"
        ],
        "Transformer Networks": [
          "Attenion is ALL you need",
          "Self-Attention and Multi-Head Attention",
          "Encoder-Decoder Architecture",
          "Evaluation of seq2seq models (WER and BLEU)"
        ],
        "Module 5: Transfer Learning in NLP": [
          "Module intro and roadmap",
          "Word Level Transfer Learning",
          "Sentence Level Transfer Learning",
          "BERT and GPT models",
          "XLTransformer and XLNet",
          "Gigantic transformer models and distillation (DistillBERT)"
        ],
        "Resources": [
          "Notebooks",
          "Material"
        ]
      },
      "requirements": [
        "Machine Learning",
        "Python",
        "Probability and Statistics"
      ],
      "description": "In this course, we will dive into the world of Natural Language Processing. We will demonstrate how Deep Learning has re-shaped this area of Artificial Intelligence using concepts like word vectors and embeddings, strucutured deep learning, collaborative filtering, recurrent neural networks, sequence-to-sequence models and transformer networks. In our journey, we will be mostly concerned with how to represent the language tokens, being at the word or character level, and and how to represent their aggregation, like sentences or documents, in a semantically sound way. We start the journey by going through the traditional pipeline of text pre-processing and the different text features like binary and TF-IDF features with the Bag-of-Words model. Then we will dive into the concepts of word vectors and embeddings as a general deep learning concept, with detailed discussion of famous word embedding techniques like word2vec, GloVe, Fasttext and ELMo. This will enable us to divert into recommender systems, using collaborative filtering and twin-tower model as an example of the generic usage of embeddings beyond word representations. In the second part of the course, we will be concerned with sentence and sequence representations. We will tackle the core NLP of Langauge Modeling, at statistical and neural levels, using recurrent models, like LSTM and GRU. In the following part, we tackle sequence-to-sequence models, with the flagship NLP task of Machine Translation, which paves the way to talk about many other tasks under the same design seq2seq pattern, like Question-Answering and Chatbots. We present the core idea idea of Attention mechanisms with recurrent seq2seq, before we generalize it as a generic deep learning concept. This generalization leads to the to the state-of-the art Transformer Network, which revolutionized the world of NLP, using full attention mechanisms. In the final part of the course, we present the ImageNet moment of NLP, where Transfer Learning comes into play together with pre-trained Transfomer architectures like BERT, GPT 1-2-3, RoBERTa, ALBERT, XLTransformer and XLNet.",
      "target_audience": [
        "Beginner level NLP engineers and data scientists"
      ]
    },
    {
      "title": "Learn Pandas for Data Science",
      "url": "https://www.udemy.com/course/learn-data-wrangling-using-python-and-pandas-free-course/",
      "bio": "Effective Exploratory Data Analysis (EDA) & Data Wrangling with Python, Pandas, Seaborn and Plotly",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic python will be enough (string, lists, dictionaries, variables and function)"
      ],
      "description": "Unlock the power of data with Pandas, the Python library that has become essential for data manipulation and analysis. This beginner-friendly course is designed for anyone looking to break into data science, analysis, or machine learning by mastering one of the most critical tools in the Python ecosystem.\nIn this course, you’ll learn how to harness the capabilities of Pandas to import, clean, analyze, and manipulate data with ease. We’ll start from the basics, explaining what Pandas is and why it’s a go-to choice for data professionals. From setting up your Python environment to understanding core data structures like Series and DataFrames, you’ll gain foundational skills to handle any dataset confidently.\n\n\nWhat You’ll Learn:\n\n\n1. The Essentials of Pandas and DataFrames: Begin by understanding the key data structures in Pandas, including Series and DataFrames, and learn to create, access, and modify them.\n2. Data Cleaning and Preparation: Discover techniques to clean messy data, handle missing values, and prepare data for analysis. These skills are essential for making raw data analysis-ready.\n3. Data Selection, Filtering, and Grouping: Explore powerful methods for selecting, slicing, and filtering data to focus on subsets that matter. You’ll also master grouping and aggregating data for deeper insights.\n4. Data Transformation and Manipulation: Dive into transforming data with merging, joining, and reshaping functions to efficiently handle even the most complex datasets.\n\n\nWhy Take This Course?\nBy the end of this course, you’ll have built a solid foundation in data analysis with Pandas, a critical skill in data science, business analytics, finance, and more.\n\n\nWhether you’re a student, analyst, or professional looking to upgrade your data skills, this course will set you up for success in data manipulation and analysis using Pandas. Join us to take the first step toward becoming a data-savvy professional and unlocking the insights hidden in your data!",
      "target_audience": [
        "Beginner Python developers that want to learn Pandas Library"
      ]
    },
    {
      "title": "모두를 위한 ChatGPT를 이용한 업무자동화 Part 1",
      "url": "https://www.udemy.com/course/chatgpt-business-automation-part-1/",
      "bio": "ChatGPT를 이용한 다양한 업무자동화 방법(엑셀, PPT, 크롤링, 이미지처리)",
      "objectives": [
        "ChatGPT를 이용한 업무자동화 방법",
        "Python 기초와 ChatGPT를 이용해서 Python 코드를 작성하는 법",
        "ChatGPT의 동작 원리",
        "다양한 업무자동화 방법(엑셀, PPT, 크롤링, 이미지처리)"
      ],
      "course_content": {
        "ChatGPT와 업무자동화 개요": [
          "ChatGPT와 업무자동화 개요",
          "ChatGPT 시대, 비전공자가 코딩을 배워야하는 이유"
        ],
        "비전공자를 위한 인공지능 기초 개념 정리": [
          "인공지능 vs 머신러닝 vs 딥러닝 개념 정리"
        ],
        "비전공자를 위한 ChatGPT의 원리 설명": [
          "자연어 처리란?",
          "인공신경망",
          "GPT(Generative Pre-Trained Transformer)",
          "언어 모델 - Language Model(LM)"
        ],
        "Python 실습을 위한 구글 코랩 Colab 소개": [
          "Python 실습을 위한 구글 코랩 Colab 소개"
        ],
        "ChatGPT를 이용한 업무 자동화 실습 - 엑셀": [
          "ChatGPT를 이용한 엑셀 업무 자동화 실습 1 - 회원정보 파일 100개 합치기",
          "ChatGPT를 이용한 엑셀 업무 자동화 실습 2 - 성적표 분석하기 (등수, 평균)",
          "ChatGPT를 이용한 엑셀 업무 자동화 실습 3 - 주민등록번호 마스킹 처리"
        ],
        "ChatGPT를 이용한 업무 자동화 실습 - PPT": [
          "ChatGPT를 이용한 PPT 업무 자동화 실습 1 - 명찰 50개 만들기"
        ],
        "ChatGPT를 이용한 업무 자동화 실습 - 워드": [
          "ChatGPT를 이용한 워드 업무 자동화 실습 1 - 수료증 만들기"
        ],
        "ChatGPT를 이용한 업무 자동화 실습 - 크롤링": [
          "ChatGPT를 이용한 크롤링 업무 자동화 실습 1 - 네이버 뉴스 제목 크롤링",
          "ChatGPT를 이용한 크롤링 업무 자동화 실습 2 - 이미지 크롤링",
          "ChatGPT를 이용한 크롤링 업무 자동화 실습 3 - 주식정보 크롤링",
          "ChatGPT를 이용한 크롤링 업무 자동화 실습 4 - 네이버 증권 종목토론실 크롤링"
        ],
        "ChatGPT를 이용한 업무 자동화 실습 - 이미지 처리": [
          "ChatGPT를 이용한 이미지 처리 업무 자동화 실습 1 - 얼굴인식과 이미지 크기 변경",
          "ChatGPT를 이용한 이미지 처리 업무 자동화 실습 2 - 워터마크 만들기",
          "ChatGPT를 이용한 이미지 처리 업무 자동화 실습 3 - 이미지 배경 지우기"
        ],
        "ChatGPT를 이용한 업무 자동화 실습 - 예측": [
          "ChatGPT를 이용한 예측 업무 자동화 실습 1 - 인공지능을 이용한 비트코인 가격 예측기 만들기",
          "ChatGPT를 이용한 예측 업무 자동화 실습 2 - 인공지능을 이용한 삼성전자 주식 가격 예측기 만들기"
        ]
      },
      "requirements": [
        "업무자동화를 학습하고자 하는 의지"
      ],
      "description": "ChatGPT를 이용한 다양한 업무자동화 방법(엑셀, PPT, 크롤링, 이미지처리)과 업무자동화를 위한 파이썬(Python) 기초를 학습할 수 있는 강의입니다. ChatGPT가 만들 변화된 미래를 미리 경험해보세요.\n\n\n코딩을 몰라도 업무자동화가 가능하다면?\nChatGPT가 만들 업무처리 방식의 미래를 경험해보세요.\nChatGPT를 이용한 업무자동화 방법(엑셀, PPT, 크롤링, 이미지처리)를 학습합니다.\n비전공자를 위한 ChatGPT의 동작원리\nPython 기초 문법과 Python 코드 작성법\n\n\n이런 분들께 추천드려요!\n반복되는 업무를 자동화하고 싶은 직장인\nChatGPT를 내 업무에 효율적으로 사용하는 방법을 학습하고 싶은 분\nChatGPT가 만들 변화된 미래를 먼저 경험하고 싶은 분\nChatGPT의 동작원리를 학습하고 싶은 분\n\n\n예상 질문 Q&A\nQ. 업무 자동화란 무엇인가요?\nA. 업무 자동화란 반복되는 업무를 컴퓨터를 이용해 자동화함으로써 단순 반복업무에 소요되는 시간을 줄여주고, 절약한 시간을 통해 좀더 생산적인 업무에 집중할수 있도록 도와주는 것을 뜻합니다.\n\n\nQ. ChatGPT를 이용한 업무자동화의 장점은 무엇인가요?\nA. 기존에 업무자동화를 수행하기 위해서는 Python 코드 작성방법을 학습하거나 RPA(Robotic Process Automation) 툴을 구매하여 사용했어야만 했습니다. 하지만 ChatGPT를 이용하면 Python 코드를 직접 작성하지 않고도 한국어 문장으로 자동화할 업무를 ChatGPT에게 요청하면, ChatGPT가 Python 코드를 작성해주기 때문에 Python 학습에 대한 진입장벽이 사라졌습니다.\n\n\nQ. 그렇다면 이제 Python 코드 작성방법을 학습할 필요가 없나요?\nA. ChatGPT가 자동으로 Python 코드를 작성해주긴 하지만 ChatGPT가 작성해준 Python 코드를 분석하거나, ChatGPT에게 더 명확하게 작업을 요청하기 위해서, 기본적인 Python 코드 작성 방법을 학습하면 ChatGPT를 200% 활용할 수 있습니다.",
      "target_audience": [
        "반복되는 업무를 자동화하고 싶은 직장인",
        "ChatGPT를 효율적으로 사용하는 방법을 학습하고 싶은 분",
        "ChatGPT가 만들 변화된 미래를 먼저 경험하고 싶은 분"
      ]
    },
    {
      "title": "Estatística com Linguagem R",
      "url": "https://www.udemy.com/course/estatistica-com-linguagem-r/",
      "bio": "Estatística para Ciência de Dados, Machine Learning, Engenharia, Economia, Bioestatística, Finanças, Administração...",
      "objectives": [
        "Estatística descritiva para análise de dados (amostragens, frequências, medidas tendência central, medidas de posição, medidas dispersão e análise de outliers)",
        "Estatística probabilística para análise de dados (probabilidades, distribuição de Binomial, Geométrica, Poisson, distribuição normal e teste de normalidade).",
        "Estatística inferencial para análise de dados (testes paramétricos e não paramétricos, intervalo de confiança, testes de hipóteses...)",
        "Manipulação de dataset com mais de 5 milhões de registros.",
        "Fundamentos da Linguagem R (operadores matemáticos, estrutura condicional, estrutura de repetição, vetores, matrizes, funções e importação de pacotes)",
        "Análise Estatística de gráficos"
      ],
      "course_content": {},
      "requirements": [
        "Não há pré-requisito para este curso."
      ],
      "description": "Neste curso serão apresentados os conceitos principais de Estatística utilizando a Linguagem R e com uma didática diferenciada, com muita pratica na linguagem R, utilizando um banco de dados real e uma descrição dos conceitos teóricos sem exageros nas deduções matemáticas, de forma clara e objetiva, mas mantendo o alto nível. Serão apresentados vários scripts da linguagem R, tendo como base um  único projeto real, com um data frame original composto por mais de 5 milhões de registros (linhas) e mais de 130 variáveis (colunas). Além disso, será demonstrado todo o tratamento desse  banco de dados, desde a sua aquisição até a exportação do arquivo tratado para começar os estudos estatísticos.\nO curso fornece uma base sólida para estudantes, trabalhadores e pesquisadores das áreas de Ciência de Dados, Inteligência Artificial (tanto em Machine Learning como Deep Learning), Análise de Dados, Biomedicina, Psicologia, Engenharia, Matemática, Economia, Administração... enfim, todas as áreas que utilizam conceitos estatísticos.\nTodos os scripts e slides são fornecidos, assim como links e referências úteis. O atendimento às dúvidas e informações são realizadas de forma rápida e com clareza.\nNão há necessidade de nenhum conhecimento específico prévio, somente Matemática básica, pois será demonstrado tudo sobre a utilização da linguagem R necessária para estudos estatísticos e a teoria sobre a Estatística é explicada passo a passo.",
      "target_audience": [
        "Estudantes, profissionais e pesquisadores de Inteligência Artificial, Ciência de Dados, Economia, Analista de Dados, Administração, Estatística, Biomedicina e demais áreas correlacionadas."
      ]
    },
    {
      "title": "ChatGPT for Data Analytics",
      "url": "https://www.udemy.com/course/chatgpt-for-data-analytics/",
      "bio": "Free ChatGPT for Data Analytics Course: Master Your Skills!",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Course Introduction",
          "Getting Started with ChatGPT for Data Analytics",
          "ChatGPT for exploratory data analysis (EDA)",
          "AI-driven data analysis with ChatGPT-4",
          "Summary"
        ]
      },
      "requirements": [
        "No prior AI experience is required. The course includes beginner-friendly explanations and coding tutorials."
      ],
      "description": "Free Chat-GPT for Data Analytics Course: Master Your Skills\nIn this course, you'll explore the capabilities of Chat-GPT and gain a deep understanding of its functionalities and applications. You'll learn essential data analysis techniques to effectively interpret and manipulate data. Additionally, you'll discover data visualization methods to present your findings clearly and convincingly. By the end of the course, you'll have a solid grasp of Chat-GPT and the skills needed to analyze and visualize data with confidence.\nTopics Covered\nChat-GPT Overview\nGain a comprehensive understanding of Chat-GPT, its capabilities, and its applications across various domains—from chatbots and virtual assistants to content generation and text analysis.\nData Analysis\nLearn the fundamentals of data analysis, including techniques for cleaning, exploring, and analyzing datasets. Extract meaningful insights to support decision-making and drive business outcomes.\nData Visualization\nDiscover the power of data visualization in effectively conveying insights. Learn to create visually compelling charts, graphs, and dashboards that communicate complex data analysis findings clearly.\nBenefits of Completing the Course\nMaster NLP for Textual Data Analysis\nDevelop advanced NLP skills tailored to analyzing textual data. Learn how to leverage Chat-GPT to interpret, extract, and analyze insights from unstructured text, enabling data-driven decision-making.\nPractical Applications with Real-World Data\nThrough hands-on exercises and real-world examples, you'll learn to efficiently process and interpret large volumes of text data—whether analyzing customer reviews, social media conversations, or survey responses.\nDevelop Business-Specific Solutions\nAcquire the skills to build tailored solutions for business challenges involving textual data. Whether it's sentiment analysis, topic modeling, or text summarization, Chat-GPT empowers you to extract actionable insights aligned with your organization's goals.\nEnhance Communication & Collaboration\nUse Chat-GPT to bridge the gap between data analysts, stakeholders, and decision-makers. Communicate insights derived from textual data effectively, fostering collaboration and alignment across teams.\nStay Ahead in a Rapidly Evolving Field\nAs data analysis techniques continue to evolve, staying ahead is essential. This course equips you with the latest advancements in NLP and text data analysis, helping you drive innovation in the field.\nHow to Build a Career After Completing the Course\nStep 1: Apply the techniques learned in this course to real-world projects. Use Chat-GPT’s NLP capabilities for extracting insights, performing sentiment analysis, or generating reports from unstructured data. Implement these skills in your current role or personal projects.\nStep 2: Expand your knowledge by exploring complementary data analysis techniques. Experiment with advanced statistical methods, machine learning algorithms, and text mining to deepen your expertise.\nStep 3: Connect with professionals and fellow learners. Join online forums, discussion groups, and social media communities focused on data analysis and NLP.\nStep 4: Build a strong portfolio by showcasing relevant projects. Highlight your objectives, methodologies, and the insights you derived using Chat-GPT to demonstrate your impact on data-driven decision-making.\nStep 5: Explore job opportunities that require expertise in data analysis and NLP. Look for roles such as Data Analyst, NLP Specialist, or AI Solutions Consultant in organizations leveraging Chat-GPT for intelligent insights.\nStep 6: Continue learning and upskilling. Stay updated with emerging tools and techniques by enrolling in advanced courses, attending workshops, and working on hands-on projects.\nStart Your Upskilling Journey with Skill-Up\nTake the next step in your learning journey with Skill-Up! Whether you're a beginner or looking to refine your expertise, our platform offers a wide range of courses across various domains. Start today and unlock endless opportunities for personal and professional growth.",
      "target_audience": [
        "This ChatGPT for data analysis course is ideal for data analysts, data scientists, business analysts, and anyone interested in learning how to use ChatGPT for data analysis tasks. Whether a beginner or an experienced professional, this course will equip you with the skills needed to leverage ChatGPT effectively for data analytics."
      ]
    },
    {
      "title": "Formação Processamento de Linguagem Natural, LLMs e Gen AI",
      "url": "https://www.udemy.com/course/formacao-processamento-de-linguagem-natural-nlp/",
      "bio": "Aprenda NLP com BERT, GPT, Spark, Spacy, Keras, Sklearn, NLTK, Huggin Face ! Crie projetos reais usando Google Colab",
      "objectives": [
        "Conheça Transformers, que estão revolucionando a NLP",
        "Crie aplicações de classificação de texto, analise de sentimentos, preguntas e resposta e muito mais",
        "Conheça bilbliotecas de pré-processamento, como NLTK e Spacy",
        "Crie Modelos com BERT",
        "Crie processos de NLP com Deep Learning",
        "Aprenda os Fundamentos de NLP",
        "Crie Modelos de NLP com Spark e DataBricks",
        "Crie Pipelines de NLP de forma rápida com Transformers",
        "Aprenda a Usar a API da OpenAI ( modelos GPT do ChatGPT)"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Introdução",
          "Aplicações",
          "Estrutura do Curso",
          "Ambientes do Curso",
          "Apresentação do Google Colab",
          "Material para Download"
        ],
        "Fundamentos de Processamento de Linguagem Natural": [
          "Conceitos Básicos",
          "Word Embedding",
          "Pipelines"
        ],
        "NLP com Spacy": [
          "Introdução e Preparação",
          "Produção de Tokens",
          "Pos-Taggin e Dependências",
          "Listando Entidades Nomeadas",
          "Gerenciando Stop Words",
          "Vocabulário",
          "Buscando Similaridade",
          "Busca de Expressões com Matching",
          "Visualização com Displacy",
          "Gerenciando Pipelines"
        ],
        "NLP com NLTK": [
          "Introdução e Preparação",
          "Produção de Tokens",
          "Gerenciando Stop Words e Pontuação",
          "Produzindo Métricas",
          "Stemming na prática",
          "Criando Pós-Taggin",
          "Lemmatization na Prática",
          "Busca de Entidades Nomeadas"
        ],
        "Introdução a Machine Learning e Deep Learning": [
          "Introdução",
          "Conceitos de Classificação",
          "Regressão, Processo de Treino e Teste",
          "Métricas para Avaliar Regressão",
          "Agrupamentos e Sistemas de Recomendação",
          "Operações de Machine Learning (MLOPS)",
          "Outras Métricas para Classificação",
          "Redes Neurais Artificiais",
          "Funções de Ativação",
          "Gradient Descent",
          "Regularização e AutoML",
          "Deep Learning"
        ],
        "Machine Learning e Deep Learning para NLP na Prática": [
          "Introdução: classificação de texto",
          "Classificação de Spam parte 1",
          "Classificação de Spam parte 2",
          "Classificação com Redes Neurais",
          "Implementando uma Rede Neural Parte 1",
          "Implementando uma Rede Neural Parte 2",
          "Implementando uma Rede Neural Parte 3",
          "Criando seu próprio Embeddings",
          "Implementando uma Rede Neural com Embeddings Parte 1",
          "Implementando uma Rede Neural com Embeddings Parte 2"
        ],
        "Análise de Sentimentos": [
          "Introdução a Análise de Sentimentos",
          "Exemplo prático com LSTM",
          "LSTM parte I",
          "LSTM parte II",
          "LSTM parte III",
          "VADER: Análise de Sentimento com Regras",
          "VADER na Prática",
          "Comparando Regras com Modelo Supervisionado",
          "Regras VS Supervisionado Parte I",
          "Regras VS Supervisionado Parte II",
          "Regras VS Supervisionado Parte III"
        ],
        "Transformers, Bert, GPT e mais": [
          "Introdução a Transformers",
          "Introdução a Transformers Parte II",
          "BERT",
          "Variantes de BERT",
          "Hugging Face e OpenAI",
          "Modelos Pré-treinados",
          "Aplicação de Perguntas e Respostas",
          "Aplicação de Preenchimento de Lacunas",
          "Aplicação de Resumos",
          "Aplicação de Geração de Texto",
          "Modelos GPT e OpenAI",
          "Aplicação com OpenAI e GPT"
        ],
        "Modelagem de Tópicos com BERT": [
          "Introdução a Modelagem de Tópicos",
          "Documentos Utilizados no Projeto",
          "Preparação do Ambiente",
          "Processamento de Dados",
          "Principais Hiper-parâmetros",
          "Rodando o Modelo",
          "Alterando o Modelo do Transformer"
        ],
        "NLP com Spark": [
          "Introdução ao Spark",
          "Etapas de Processamento",
          "Preparando o Ambiente",
          "Pré-Processamento",
          "Criando e Avaliando o Modelo"
        ]
      },
      "requirements": [
        "Conhecimento em Python"
      ],
      "description": "Bem vindo ao mais moderno e abrange curso de Processamento de Linguagem Natural.\nAtualizado com Modelos da OpenAI (GPT do ChatGPT)\nProcessamento de Linguagem Natural (NLP) é uma das mais importantes áreas da Ciência de Dados. Entre as tarefas mais comuns nesta área temos: (todos estes exemplos são estudados na prática!)\n\nAnalise de Sentimentos\nRespostas a Perguntas (ex: Chatbots, por exemplo)\nProdução de Resumos\nTradução\nPreenchimento de Lacunas (ex: previsão de digitação)\nClassificação de Documentos (ex: definir tipo de contrato)\nBusca de Similaridade (ex: processos judíciais)\nTécnicas não supervisionadas\nmuito mais...\nVocê não precisa instalar nenhum software para fazer este curso: totalmente na nuvem em ambientes gratuitos\nO curso aborda desde técnicas classicas, como Tokenization, Lemmatisationetc, até conceitos modernos e revolucionários, como Transformers e BERT. São utilizadas as mais varias bibliotecas de NLP, como Pytorch, Tensorflow, Scikit Learn, hugging face, Spark etc.\nO curso tem a seguinte estrutura:\nIntrodução: Apresenta a estrutura do curso e o ambiente\nFundamentos de NLP: Estudamos conceitos gerais de NLP\nSpacy: Várias técnicas de Pré-processamento são estudadas\nNLTK: Estudamos esta biblioteca clássica de NLP\nIntrodução a Machine Learning e Deep Learning\nMachine Learning e Deep Learning na Prática: desenvolvemos alguns projetos de NLP com Machine Learning\nAnálise de Sentimentos: Estudamos os fudamentos e criamos aplicações utilizando Machine Learning e Regras\nTransformers, GPT (do ChatGPT) e Bert: Estudamos os conceitos e criamos várias aplicações\nModelagem de Tópicos: Novamente estudamos os fundamentos e desenvolvemos uma aplicação\nNLP com Spark: Estudamos como criar modelos de NLP com Spark e Databrick\nVocê não precisa instalar nada! Todo o curso utliza ferramentas grautitas na Nuvem, como Google Colab e DataBricks.\nVocê ainda pode baixar no ambiente do curso:\nSlides\nCódigo Fonte\nNotebooks\nBons Estudos a todos!\nProf. Fernando Amaral",
      "target_audience": [
        "Cientista e Analista de Dados",
        "Qualquer interessado em NLP"
      ]
    },
    {
      "title": "Inteligência Artificial: Buscas em Textos com Python",
      "url": "https://www.udemy.com/course/inteligencia-artificial-buscas-em-textos-com-python/",
      "bio": "Construa seu próprio crawler, indexador e sistema de busca em textos! Aprenda o algoritmo PageRank do Google!",
      "objectives": [
        "Aprenda a construir um crawler do zero para buscar o conteúdo de páginas web",
        "Entenda como funcionam as bibliotecas urllib e BeautifulSoup do Python para processar páginas web",
        "Aprenda a indexar o conteúdo de páginas web utilizando o MySql",
        "Aprenda como classificar documentos por conteúdo, utilizando métricas como frequência de palavras, posição da palavra no documento e distância entre palavras",
        "Entenda e implemente o algoritmo PageRank para classificação de documentos utilizando links externos"
      ],
      "course_content": {
        "Introdução e conteúdo do curso": [
          "Introdução e conteúdo do curso",
          "Mais sobre Inteligência Artificial"
        ],
        "Crawler e indexador de documentos": [
          "Instalação do Anaconda",
          "Carregamento de páginas web com urllib3",
          "Extração de dados de HTML com BeautifulSoup",
          "Crawler - busca de documentos I",
          "Crawler - busca de documentos II",
          "Crawler - busca de documentos III",
          "Crawler - busca de documentos IV",
          "Pré-processamento dos textos - remoção das tags HTML",
          "Instalação do MySql",
          "Indexação - criação da base de dados",
          "Indexação - entendimento das tabelas",
          "Pré-processamento dos textos - separação das palavras",
          "Pré-processamento dos textos - extração do radical",
          "Indexação - verificação de páginas já indexadas",
          "Indexação - inclusão das urls no índice",
          "Indexação - verificação de palavras já indexadas",
          "Indexação - inclusão de palavras no índice",
          "Indexação - inclusão das palavras do documento",
          "Indexação - indexador completo",
          "Indexação - execução passo a passo",
          "Base de dados completa"
        ],
        "Pesquisa nos documentos": [
          "Introdução ao módulo",
          "Exploração dos dados",
          "Consultas com uma palavra I",
          "Consultas com uma palavra II",
          "Consultas com mais palavras I",
          "Consultas com mais palavras II",
          "Consultas com mais palavras III",
          "Lista com scores",
          "Frequência de palavras",
          "Posição no documento",
          "Distância entre palavras",
          "Indexação - criação de tabelas para o PageRank",
          "Indexação - entendimento das tabelas do PageRank",
          "Indexação - inclusão da ligação entre urls e palavras",
          "Indexação - verificação da ligação entre urls e palavras",
          "Pré-processamento dos textos - extração das palavras da url",
          "Indexação - gravação da ligação entre urls e palavras",
          "Indexação - execução passo a passo",
          "Contagem simples de links I",
          "Contagem simples de links II",
          "PageRank - teoria I",
          "PageRank - teoria II",
          "PageRank - implementação I",
          "PageRank - implementação II",
          "PageRank - depuração",
          "PageRank - pesquisa",
          "Texto do link",
          "Normalização I",
          "Normalização II",
          "Pesquisa por peso"
        ],
        "Considerações finais": [
          "Considerações finais",
          "Código fonte completo",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "É recomendado conhecimento sobre lógica de programação, principalmente estruturas condicionais e de repetição",
        "Conhecimentos básicos em Python são desejáveis, embora seja possível acompanhar o curso sem saber essa linguagem com profundidade",
        "É necessário conhecer comandos SQL básicos, principalmente o \"select\" e o \"insert\"",
        "É importante entender o modelo entidade-relacionamento para a construção de bases de dados, principalmente chaves primárias e estrangeiras",
        "É recomendável que você saiba as principais tags HTML existentes em páginas web, embora seja possível acompanhar o curso sem esse conhecimento",
        "Não são necessários conhecimentos prévios sobre Inteligência Artificial"
      ],
      "description": "Os sistemas de busca em texto representam uma importante área da Inteligência Artificial. Eles consistem em analisar grande volume de texto para retornarem para o usuário uma lista dos principais documentos encontrados de acordo com os parâmetros de busca. Os exemplos práticos mais comuns deste tipo de sistema são os motores de busca, como Google, Bing ou Yahoo; nos quais o usuário pode informar um conjunto de palavras e o sistema apresenta as páginas web mais relevantes. Para que isso seja possível, são utilizados uma série de algoritmos e/ou métricas que tem a função de indicar a ordem pela qual os documentos serão apresentados, ou seja, as páginas mais importantes serão mostradas no topo da pesquisa enquanto que as menos relavantes serão mostradas por último.\n\nBaseado nisso, neste curso você vai aprender na teoria e principalmente na prática como desenvolver do zero um sistema para buscas em textos utilizando vários algoritmos para ordenação dos resultados. Você desenvolverá passo a passo todas as etapas de um sistema de busca, iniciando pelo crawler que buscará as páginas web utilizando o Python e as bibliotecas urllib3 e BeautifulSoup. Logo após passaremos para a fase da indexação, na qual o conteúdo das páginas web serão analisadas e faremos a gravação em uma base de dados no MySql. Por fim, implementaremos as seguintes pesquisas: consultas com uma ou múltiplas palavras, frequência de palavras, posição das palavras no documento e distância entre as palavras. Também veremos a classificação dos documentos utilizando o texto do link e por fim implementaremos o uso de links externas que é caracterizado pelo famoso algoritmo PageRank, que é considerado o algoritmo que ajudou muito na grande ascensão do Google e que hoje em dia é utilizado nos principais motores de busca. É importante enfatizar que o objetivo do curso é mostrar passo a passo a implementação do zero, portanto, não utilizaremos nenhuma biblioteca específica para esse cenário. Também não é objetivo do curso desenvolver uma interface web para a realização das pesquisas, ou seja, todos os testes serão realizados via prompt. Por fim, este material pode ser considerado de nível iniciante para quem está entrando tanto na área de Inteligência Artificial quanto na área de desenvolvimento de motores de busca.\nPreparado(a) para dar um importante passo na sua carreira? Aguardo você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial",
        "Pessoas interessadas na área de recuperação de informação de documentos textuais"
      ]
    },
    {
      "title": "50+ PySpark Interview Questions for Data Engineering (2025)",
      "url": "https://www.udemy.com/course/pyspark-interview-questions-spark-with-python/",
      "bio": "FREE: Ace PySpark & SparkSQL Interviews with 50+ Expert-Picked Theory Questions & Answers!",
      "objectives": [],
      "course_content": {
        "Introduction!": [
          "Introduction!",
          "What Can You Expect From This Course?"
        ],
        "PySpark Interview Questions": [
          "Lecture 1",
          "Lecture 2",
          "Lecture 3",
          "Lecture 4",
          "Lecture 5",
          "Lecture 6",
          "Lecture 7",
          "Lecture 8",
          "Lecture 9",
          "Lecture 10"
        ],
        "The Final Touch": [
          "A quick test of your knowledge!",
          "Thank You!"
        ]
      },
      "requirements": [
        "Knowledge and experience of Spark, Python and PySpark is expected!"
      ],
      "description": "Looking to strengthen your PySpark and SparkSQL knowledge for upcoming data engineering or data science interviews? This free course by Compylo is tailored to help you master the theory-based interview questions commonly asked in real-world technical rounds.\nYou’ll explore over 50 expert-picked questions and answers, focused on core PySpark and SparkSQL concepts such as RDDs, DataFrames, Spark SQL engine, transformations, and data aggregations. These questions are curated based on trends observed in interviews at top tech companies, ensuring you're aligned with what recruiters and hiring managers expect.\nThe course is ideal for professionals preparing for roles in big data, analytics, and data engineering, as well as those who want to refresh foundational Spark concepts. We focus purely on interview theory, making it perfect for quick, structured revisions without diving into heavy code.\nThroughout the course, you'll also get tips on best practices, common pitfalls, and how to approach theory-based questions with clarity and confidence.\nWhether you're just starting out or brushing up for a role switch, this course provides a concise, targeted way to prepare for PySpark and SparkSQL interviews without unnecessary fluff.\n\nSo, what are you waiting for? Enroll today to give your preparation a head start—and step into your next interview with confidence!",
      "target_audience": [
        "This course is ideal for aspiring data engineers, data scientists, and big data professionals preparing for PySpark and SparkSQL interviews. Whether you're a new graduate, a career switcher, or an experienced developer refreshing your Spark theory, this course offers targeted, interview-focused content to help you stand out."
      ]
    },
    {
      "title": "Web Scraping avec Python pour la Data Science",
      "url": "https://www.udemy.com/course/scraping-python/",
      "bio": "Apprendre à extraire des données pour vos projets Data Science depuis des APIs ou des sites Web avec du code Python",
      "objectives": [
        "Extraire des données depuis des APIs et des sites Web avec le langage Python",
        "API : S'authentifier sur une API et scraper de la data via cette API",
        "Web : Scraper les sites web en ciblant les balises HTML ou les sélecteurs CSS"
      ],
      "course_content": {
        "Introduction": [
          "Message de bienvenue :)",
          "Installation Jupyter Notebook",
          "Utilisation Jupyter Notebook",
          "CHALLENGE PYTHON 30 JOURS (OFFERT)"
        ],
        "APIs Scraping": [
          "Introduction aux APIs et à la requête GET",
          "Les codes Status",
          "Paramètres de requête",
          "Format JSON",
          "Obtenir un JSON depuis une requête",
          "Type de contenu",
          "Défi: Trouver le nombre de personnes dans l'espace"
        ],
        "Authentification à une API": [
          "Authentification à l'API de Github",
          "Points d'accès ou endpoints",
          "Pagination",
          "Point d'accès User-Level",
          "Requête POST",
          "Requête PATCH/PUT",
          "Requête DELETE"
        ],
        "Cas pratique: API Reddit": [
          "Authentification à l'API de Reddit",
          "Extraire l'article le plus populaire",
          "Extraire tous les commentaires de cet article",
          "Extraire le commentaire le plus populaire"
        ],
        "Web Scraping": [
          "Introduction au web scraping",
          "Récupérer des éléments d'une page",
          "Utiliser Find All",
          "Eléments correspondant aux IDs",
          "Les classes",
          "Sélecteurs CSS",
          "Association de sélecteurs en CSS"
        ],
        "Challenge 1: Site météo": [
          "Exploration de la structure de la page web",
          "Extraire toutes les informations d'un élément",
          "Extraire toutes les informations de la page",
          "Affichage du résultat avec Pandas"
        ],
        "Challenge 2: Critique de films": [
          "Introduction au site web",
          "Structure de l'URL",
          "Structure HTML de la page",
          "Extraire la data pour un seul film",
          "Script pour scraper une seule page",
          "Affichage du DataFrame avec Pandas",
          "Script pour toutes les pages",
          "Contrôler le taux des requêtes envoyées",
          "Script final",
          "Script final (code)",
          "Affichage final des données"
        ],
        "BONUS": [
          "Apprends PYTHON pour la DATA SCIENCE",
          "Autres cours sur Udemy"
        ]
      },
      "requirements": [
        "Notions basiques en Python"
      ],
      "description": "Si vous souhaitez vous initier au Web Scraping en récupérant des données via des APIs ou via des sites internet avec le langage Python, ce cours est fait pour vous !\nCe cours est constitué des points théoriques nécessaires pour commencer à scraper des APIs ou des sites web. Il est préférable pour suivre ce cours d'avoir des notions basiques en Python (variables, listes, dictionnaires, boucles, conditions, utilisation des librairies). Si Python ne vous est pas familier, je vous recommande de suivre une formation sur Python au préalable (à la fin de cette formation est fourni un lien pour suivre ma formation Udemy sur Python appliqué à la Data Science où vous trouvez toutes les bases requises si besoin).\nCe cours est également rempli d'exercices, de défis, de projets et d'opportunités pour que vous puissiez pratiquer directement ce que vous apprenez. Vous allez pratiquer le API Scraping sur 3 APIs différents (évolution progressive de la difficulté), puis vous allez pratiquer le Web Scraping aussi sur des cas réels (un site météo pour scraper les prévisions sur la semaine et un site de critique de films pour scraper plus de 2500 films avec leurs titres/années de sortie/notes)\nCe cours en quelques chiffres :\n4 heures de vidéos\n3 chapitres théoriques avec de nombreux training\n2 challenge pour mettre en pratique le Web Scraping\n1 cas pratique sur un API Scraping\nPourquoi apprendre le Scraping?\nLe but principal du scraping c'est de récupérer de la data pour ensuite l'utiliser et la manipuler. Malgré l'essor du big data, certaines data ne sont pas téléchargeables, il faut donc passer le scraping (API ou web).L'idée est d'automatiser les tâches (ou requêtes) afin d'obtenir des milliers de data (exemple emails, adresses postales, résultats sportifs, météo, etc...)\nPourquoi ce cours est différent ?\nCe ne sera pas un cours où vous allez regarder mon code pendant des heures. C'est un parcours où l'on pratique, on met les mains dans le code et on manipule soi même pendant des heures sur des problématiques de scraping. Mon but c'est surtout de vous donner l'envie et le goût de scraper le web :)\nUne fois ce cours terminé, vous pourrez scraper n'importe quel API (en lisant la documentation), et surtout vous pourrez scraper tout site internet qui vous intéresse.\nAlors, faisons ça ! Inscrivez-vous aujourd'hui et commencez à apprendre le web & APIs Scraping !",
      "target_audience": [
        "Toute personne souhaitant apprendre à scraper des données sur le net",
        "Toute personne souhaitant extraire de la data pour la manipuler ensuite avec Python"
      ]
    },
    {
      "title": "Dominando o Databricks com Spark e Pyspark 2025",
      "url": "https://www.udemy.com/course/databricks-machinelearning/",
      "bio": "Da teoria à prática: domine Databricks, Spark, Delta Lake com Python e Pyspark",
      "objectives": [
        "Descubra a essência de Data Warehouses, Data Lakes e Delta Lakes e como eles se inter-relacionam",
        "Explore o ecossistema Databricks, aprendendo a criar e gerenciar eficientemente clusters",
        "Compreenda a importância do Spark em Big Data e obtenha uma introdução sólida sobre seu uso",
        "Descubra como manipular conjuntos de dados usando DataFrames e Delta Lake para eficiência otimizada",
        "Aprenda a criar gráficos e dashboards dinâmicos para visualização interativa e clara de dados",
        "Conheça o spark.pandas, uma ferramenta que combina o poder do Spark com a facilidade de uso do pandas",
        "Aprenda a criar um Data LakeHouse, aproveitando os melhores recursos de Data Lakes e Warehouses",
        "Conecte com seu Data Lake a partir de fontes externas"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Apresentação",
          "Material do Curso",
          "O que é Databricks?"
        ],
        "Fundamentos de Data Warehouse, Data Lake e Delta Lake": [
          "Data Warehouse, Data Lake e Delta Lake",
          "Formatos de Big Data",
          "Armazenamento em Linhas Versus Colunas",
          "Sistemas de Arquivos Distribuídos",
          "Fundamentos de Data Warehouse, Data Lake e Delta Lake"
        ],
        "Introdução ao Spark": [
          "Introdução ao Spark",
          "Data Frame no Spark",
          "Particionamento e Bucketing",
          "Arquitetura e Componentes do Spark",
          "Context e Session"
        ],
        "Conhecendo Databricks e Criando Cluster": [
          "Conhecendo o Databricks",
          "Criando Conta Free Edition",
          "Conhecendo UI do Databricks"
        ],
        "Utilizando Data Frames e Delta Lake": [
          "Formato Delta e Delta Lake",
          "Arquivos, DataFrames e Tabelas",
          "Criando DataFrames",
          "Importando Dados, Criando Tabelas",
          "Utilizando Spark e SparkSQL",
          "Tabela Delta Versionada",
          "Upsert (Merge) com Delta",
          "Schema Evolutivo (Versionamento de Schema)",
          "Partições"
        ],
        "Criando Gráficos e Dashboards": [
          "Criando Gráficos e Dashboards a partir de Tabelas"
        ],
        "Conhecendo pyspark.pandas (Koalas)": [
          "Pyspark.pandas"
        ],
        "Criando um Delta LakeHouse": [
          "Introdução",
          "Criando um Novo Volume",
          "Inserindo Dados e Excecutando Merge",
          "Criando Tabela Desnormalizada"
        ],
        "Conectando ao Delta Lake com Python": [
          "Conectando e Lendo Tabelas"
        ],
        "Bônus": [
          "Aula Bônus"
        ]
      },
      "requirements": [
        "Conhecimentos Básicos de Python"
      ],
      "description": "Bem-vindo ao nosso curso prático de Databricks! Este curso foi especialmente desenhado para dar-lhe as competências e conhecimentos fundamentais para trabalhar com eficácia no universo de Databricks, abrangendo desde os conceitos básicos até as práticas mais avançadas.\nO curso começa com uma introdução abrangente, seguida de uma exploração detalhada dos fundamentos do Data Warehouse, Data Lake e Delta Lake. Em seguida, você irá mergulhar diretamente no ambiente Databricks, aprendendo a criar e gerenciar um Cluster. Logo após, faremos uma introdução ao Apache Spark, uma ferramenta essencial para o processamento de dados em grande escala.\nVocê vai aprender a manipular dados de maneira eficiente com o uso de DataFrames e Delta Lake, duas das principais ferramentas utilizadas em Databricks. Vamos também ensiná-lo a criar gráficos e dashboards visuais interativos para uma compreensão mais clara dos seus dados.\nDepois, o curso ensina como criar um Data LakeHouse, combinando os melhores recursos de um Data Lake e um Data Warehouse.\nEnfim, você vai aprender como conectar externamente ao seu warehouse usando Python.\nO curso é fortemente baseado na prática com PySpark, a fim de fornecer um entendimento sólido e prático de como aplicar essas ferramentas e técnicas em situações reais. Um aspecto importante do nosso curso é que todos os materiais, incluindo os notebooks, são disponibilizados para download. Dessa forma, você pode continuar aperfeiçoando suas habilidades e explorar novas possibilidades mesmo após o término do curso.\nEsteja você procurando aprimorar suas habilidades atuais ou embarcar em uma nova carreira na análise de dados, este curso prático de Databricks oferece o treinamento completo que você precisa para atingir seus objetivos. Esperamos vê-lo em breve!",
      "target_audience": [
        "Engenheiros de Dados",
        "Cientistas de Dados",
        "Analistas de Dados"
      ]
    },
    {
      "title": "Bootcamp Completo em Data Science com Python",
      "url": "https://www.udemy.com/course/curso-de-data-science-bootcamp-completo-em-data-science/",
      "bio": "Treinamento Completo em Data Science: Matemática, Estatística, Python, Estatística Avançada, Machine & Deep Learning",
      "objectives": [
        "O curso fornecerá todas as ferramentas para se tornar um cientista de dados",
        "Preencher seu currículo com habilidades em demanda em data science: Análises estatísticas, Programação em Python com numpy, pandas, matplotlib, e Seaborn, Análises estatísticas avançadas, Tableau, Machine Learning com stats models e scikit-learn, Deep Learning com TensorFlow",
        "Impressionar entrevistadores ao mostrar seu conhecimento na área de ciência de dados",
        "Aprender a como pré-processar dados",
        "Entender a matemática por trás de Machine Learning (uma obrigação que outros cursos não ensinam!)",
        "Começar a programar em Python e aprender a como usar análises estatísticas",
        "Realizar regressões logísticas e lineares em Python",
        "Fazer análises de fatores e agrupamentos",
        "Poderá criar algoritmos de Machine Learning em Python, usando NumPy, statsmodels e scikit-learn",
        "Aplicar suas habilidades em casos reais de negócios",
        "Usar o que há de mais avançado em Deep Learning usando frameworks como o TensorFlow do Google",
        "Desenvolver uma intuição de negócios enquanto programa e resolver tarefas com big data",
        "Descobrir o poder das redes neurais profundas",
        "Melhorar algoritmos de Machine Learning ao estudar underfitting, overfitting, treinamento, validação, validação cruzada n-fold, teste, e como os hiperparâmetros pode melhorar a performance",
        "Aqueça seus dedos pois você deve estar ansioso para aplicar tudo que aprender aqui em mais e mais casos da vida real"
      ],
      "course_content": {
        "Parte 1: Introdução": [
          "O Que o Veremos no Curso"
        ],
        "-O Campo de Data Science - As Várias Disciplinas de Data Science": [
          "Data Science e Jargões de Negócios: Por Que Existem Tantos?",
          "Data Science e Jargões de Negócios: Por Que Existem Tantos?",
          "Qual é a Diferença entre Análises e Analytics",
          "Qual é a Diferença entre Análises e Analytics",
          "Análise de Negócios, Análise de Dados e Data Science: Introdução",
          "Análise de Negócios, Análise de Dados e Data Science: Introdução",
          "Continuando Com EE, ML E IA",
          "Continuando Com EE, ML E IA",
          "Detalhamento do Infográfico de Data Science",
          "Detalhamento do Infográfico de Data Science"
        ],
        "-O Campo de Data Science - Conectando as Disciplinas de Data Science": [
          "Aplicação de Dados Tradicionais, Big Data, EE, Ciência de Dados Tradicional e ML",
          "Aplicação de Dados Tradicionais, Big Data, EE, Ciência de Dados Tradicional e ML"
        ],
        "-O Campo de Data Science - Benefícios de Cada Disciplina": [
          "A Razão Por Trás dessas Disciplinas",
          "A Razão Por Trás dessas Disciplinas"
        ],
        "-O Campo de Data Science - Técnicas Populares de Data Science": [
          "Técnicas Para Trabalhar com Dados Tradicionais",
          "Técnicas Para Trabalhar com Dados Tradicionais",
          "Exemplos da Vida Real de Dados Tradicionais",
          "Técnicas Para Trabalhar com Big Data",
          "Técnicas Para Trabalhar com Big Data",
          "Exemplos da Vida Real de Big Data",
          "Técnicas de Estratégia Empresarial (EE)",
          "Técnicas de Estratégia Empresarial (EE)",
          "Exemplos da Vida Real de Estratégia Empresarial (EE)",
          "Técnicas Para Trabalhar com Métodos Tradicionais",
          "Técnicas Para Trabalhar com Métodos Tradicionais",
          "Exemplos da Vida Real de Métodos Tradicionais",
          "Técnicas de Machine Learning (ML)",
          "Técnicas de Machine Learning (ML)",
          "Tipos de Machine Learning",
          "Tipos de Machine Learning",
          "Exemplos da Vida Real de Machine Learning (ML)",
          "Exemplos da Vida Real de Machine Learning (ML)"
        ],
        "-O Campo de Data Science - Ferramentas Populares de Data Science": [
          "Linguagens de Programação e Softwares Necessários Usados em Data Science",
          "Linguagens de Programação e Softwares Necessários Usados em Data Science"
        ],
        "-O Campo de Data Science - Carreiras em Data Science": [
          "Encontrando Emprego - O que Esperar e Procurar",
          "Encontrando Emprego - O que Esperar e Procurar"
        ],
        "-O Campo de Data Science - Desmistificando Equívocos Comuns": [
          "Desmistificando Equívocos Comuns",
          "Desmistificando Equívocos Comuns"
        ],
        "Parte 2: Estatística": [
          "População e Amostra",
          "População e Amostra"
        ],
        "-Estatística - Estatística Descritiva": [
          "Tipos de Dados",
          "Tipos de Dados",
          "Níveis de Mensuração",
          "Níveis de Mensuração",
          "Variáveis Categóricas - Técnicas de Visualização",
          "Variáveis Categóricas - Técnicas de Visualização",
          "Variáveis Categóricas. Exercício",
          "Variáveis Numéricas - Tabela de Distribuição de Frequência",
          "Variáveis Numéricas - Tabela de Distribuição de Frequência",
          "Variáveis Numéricas. Exercício",
          "O Histograma",
          "O Histograma",
          "Histograma. Exercício",
          "Tabelas Pivô e Gráficos de Dispersão",
          "Tabelas Pivô e Gráficos de Dispersão. Exercício",
          "Média, Mediana e Moda",
          "Média, Mediana e Moda. Exercício",
          "Assimetria",
          "Assimetria",
          "Assimetria. Exercício",
          "Variância",
          "Variância. Exercício",
          "Desvio Padrão e Coeficiente de Variação",
          "Desvio Padrão e Coeficiente de Variação",
          "Desvio Padrão E Coeficiente de Variação. Exercício",
          "Covariância",
          "Covariância",
          "Covariância. Exercício",
          "Coeficiente de Correlação",
          "Correlação",
          "Coeficiente de Correlação. Exercício"
        ]
      },
      "requirements": [
        "Nenhuma experiência prévia é necessária. Começaremos do básico.",
        "Você precisará instalar Anaconda. Mostraremos como fazer isso passo-a-passo",
        "Microsoft Excel 2003, 2010, 2013, 2016, or 365"
      ],
      "description": "O problema\nCientista de dados é uma das melhores profissões para prosperar nesse século. É digital, com foco na programação, e também é analítica. Dessa forma, não é surpresa que a demanda por cientista de dados esteja crescendo no mercado de trabalho.\nEntretanto, a oferta é muito limitada. É difícil adquirir as habilidades necessárias para ser contratado(a) como cientista de dados.\nE como você pode fazer isso?\nAs universidades têm, lentamente, criado programas especializados para data science. (sem mencionar que as que existem são muito caras e longas)\nA maioria dos cursos online focam em um tópico específico e são difíceis de entender em como a habilidade ensinada se encaixa no todo\nA solução\nData science é uma área multidisciplinar. Engloba uma variedade de tópicos.\n· Entendimento do campo de data science e os tipos de análises usadas\n· Matemática\n· Estatística\n· Python\n· Aplicação de técnicas estatísticas avançadas em Python\n· Visualização de dados\n· Machine Learning\n· Deep Learning\nCada um desses tópicos se baseia no anterior. E há um risco de você se perder no meio do caminho se não aprender as habilidades na ordem certa. Por exemplo, uns podem ter dificuldades na aplicação de técnicas de Machine Learning antes de entender a Matemática por trás. Ou, pode ser difícil estudar análises de regressão em Python sem antes ver o que é uma regressão.\nEntão, para poder ser criado o mais efetivo, conciso, e melhor curso de data science disponível online, criamos o Bootcamp Completo em Data Science com Python 2022.\nAcreditamos que esse seja o primeiro programa de treinamento que resolve os maiores desafios para entrar no campo de data science – tendo todos os recursos necessários em um só lugar.\nAlém disso, nosso foco é ensinar os tópicos de forma suave e complementar a cada um dos outros. O curso ensina tudo que você precisa saber para se tornar um cientista de dados por uma fração do custo de programas tradicionais (sem mencionar o tempo que você economizará).\nAs habilidades\n1. Introdução à Dados e Data Science\nBig data, estratégia empresarial, analytics de negócios, machine learning e inteligência artificial. Sabemos que esses jargões pertencem ao campo de data science, mas o que todos eles significam?\nPorque aprender isso?\nComo um candidato a cientista de dados, você deve entender os atalhos e saídas de cada uma dessas áreas e reconhecer a abordagem apropriada para resolver o problema. Essa ‘Introdução à dados e data science’ irá dar uma visão geral de todos os jargões e onde se encaixam no mundo de data science.\n2. Matemática\nAprender as ferramentas é o primeiro passo para fazer data science. Você deve ter a visão geral para então poder examinar em detalhes.\nDamos uma olhada especial em cálculo e álgebra linear, já que são subáreas que data science se baseia e serão necessárias em Python.\nPorque aprender isso?\nCálculo e Álgebra Linear são essenciais para Python em data science. Se você quiser entender algoritmos avançados de machine learning, então precisará dessas habilidades em seu arsenal.\n3. Estatística\nVocê precisa pensar como um cientista antes de se tornar um. Estatísticos treinam sua mente para enquadrar problemas em hipóteses e fornecer técnicas para testar essas hipóteses, assim como um cientista.\nPorque preciso aprender isso?\nEsse curso não dá apenas as ferramentas que você precisa, mas também ensina a usá-las. A Estatística lhe treina a pensar como cientista.\n4. Python\nPython é uma linguagem de programação relativamente nova, ao contrário de R, é uma linguagem de propósito geral. Você pode fazer quaisquer coisas com ela! Aplicações web, jogos de computador e data science são algumas de suas capacidades. É por isso, que em um curto espaço de tempo, é usada em diversas disciplinas. Bibliotecas extremamente ponderosas tem sido desenvolvidas para permitir manipulação de dados, transformação e visualização. Mas, na verdade, onde Python realmente brilha, é quando lida com machine e deep learning.\nPorque aprender isso?\nQuando se trata de desenvolvimento, implementação, e aplicação de modelos de machine learning através de frameworks poderosos como o scikit-learn, TensorFlow, etc. Python é uma linguagem quase que obrigatória.\n5. Tableau\nCientista de dados não precisam apenas lidar com dados e resolver problemas baseados neles. Também precisam convencer executivos de empresas a tomar as decisões certas. Executivos talvez não tenham tanto conhecimento em data science, então um cientista de dados deve ser capaz de apresentar e visualizar a história dos dados de maneira fácil de entender. É aí que Tableau entra – e iremos ajudar você a se tornar um contador de histórias profissional usando o software líder de visualização em estratégia empresarial e data science.\nPorque aprender isso?\nUm cientista de dados depende das ferramentas de visualização em estratégia empresarial como o Tableau para comunicar resultados complexos para gerentes que não possuam tanto conhecimento técnico em data science.\n6. Estatística Avançada\nRegressões, agrupamentos, e análises de fatores são todas disciplinas inventadas antes de machine learning. Entretanto, esses métodos estatísticos são agora realizados através de machine learning em Python para fornecer previsões com precisão nunca antes vistas. Essa seção irá analisar essas técnicas em detalhes.\nPorque aprender isso?\nData science se trata de modelagem preditiva e você pode se tornar um especialista nesses métodos na seção ‘estatística avançada’.\n7. Machine Learning\nA parte final do programa se trata do que cada seção tem guiada, e é deep learning. Ser capaz de empregar machine e deep learning na linguagem Python é o que normalmente separa um cientista de dados de um analista de dados no trabalho. Essa seção cobre todas as técnicas comuns de machine learning e métodos de deep learning com TensorFlow.\nPorque aprender isso?\nMachine learning está em todos os lugares. Empresas como Facebook, Google, e Amazon tem usado máquinas que aprendem sozinhas por vários anos. Agora é a sua vez de controlar as máquinas.\n***O que você receberá***\n· Um programa no valor de R$ 6.000\n· Suporte ativo na seção de Q&A\n· Todo o conhecimento para ser contratado como cientista de dados\n· Uma comunidade de aprendizes de data science\n· Um certificado ao fim do curso\n· Acesso a atualizações futuras\n· Resolver casos reais de negócios que lhe permitirão achar um emprego\nVocê se tornará um(a) cientista de dados do zero\nTemos o prazer de oferecer um reembolso incondicional de 30 dias em garantia total. Sem risco para você. O conteúdo do curso é excelente, e não temos dúvidas de que você irá gostar.\nPorque esperar? Cada dia é uma oportunidade perdida.\nClique no botão “Comprar agora” e faça parte do nosso programa de cientista de dados ainda hoje.",
      "target_audience": [
        "Você deverá fazer esse curso se quiser se tornar um(a) Cientista de Dados ou se quiser aprender sobre a área",
        "Esse curso é para você se quiser uma ótima carreira",
        "Esse curso é ideal para iniciantes, pois começa dos fundamentos e gradualmente aumenta suas habilidades"
      ]
    },
    {
      "title": "Mineração de Emoção em Textos com Python e NLTK",
      "url": "https://www.udemy.com/course/mineracao-de-emocao-em-textos-com-python-e-nltk/",
      "bio": "Aprenda passo a passo na teoria e na prática como utilizar o Python e o NLTK para minerar emoções em textos!",
      "objectives": [
        "Entenda os conceitos teóricos sobre mineração de textos",
        "Aprenda passo a passo na prática como funciona um sistema para encontrar emoção em textos",
        "Desenvolva seus próprios sistemas de aprendizado de máquina para classificar textos",
        "Entenda como funciona o aprendizado de máquina (machine learning) aplicado em bases de dados textuais"
      ],
      "course_content": {
        "Conteúdo do curso": [
          "Conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Código fonte"
        ],
        "Mineração de textos e classificação": [
          "Introdução ao módulo",
          "Mineração de textos I",
          "Mineração de textos II",
          "Mineração de emoção",
          "Classificação I",
          "Classificação II",
          "Classificação em textos"
        ],
        "Pré-processamento dos textos": [
          "Introdução ao módulo",
          "Instalação das ferramentas",
          "Introdução ao NLTK",
          "Base de dados de frases",
          "Remoção de stop words",
          "Extração do radical das palavras (stemming)",
          "Listagem de todas as palavras da base",
          "Extração de palavras únicas",
          "Extração das palavras de cada frase",
          "Extração das palavras de todas as frases"
        ],
        "Detectando emoções em textos com o Naive Bayes": [
          "Introdução ao módulo",
          "Naive Bayes I",
          "Naive Bayes II",
          "Naive Bayes III",
          "Naive Bayes em textos I",
          "Naive Bayes em textos II",
          "Classificando textos com o Naive Bayes I",
          "Classificando textos com o Naive Bayes II"
        ],
        "Avaliação do algoritmo": [
          "Introdução ao módulo",
          "Avaliação de algoritmos I",
          "Avaliação de algoritmos II",
          "Base de dados de treinamento e teste",
          "Base de dados de treinamento",
          "Medindo a precisão do algoritmo",
          "Visualização dos erros do algoritmo",
          "Visualização da matriz de confusão",
          "Teste com duas classes"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "É recomendado conhecimentos básicos sobre lógica de programação",
        "Não são necessários conhecimentos prévios sobre a linguagem Python ou sobre Inteligência Artificial",
        "Se você tiver algum conhecimento sobre Python, conseguirá entender melhor a codificação"
      ],
      "description": "A Mineração de Textos é uma das subáreas da Inteligência Artificial que tem como objetivo básico a busca por padrões e conhecimento útil em textos. O exemplo clássico dessa área são os filtros de spam muito utilizados nos sistemas de e-mail, os quais aplicam algoritmos de machine learning para identificar se uma mensagem é ou não é spam! Além disso, essas técnicas também podem ser utilizadas para classificação de notícias, ou seja, caso o sistema receba um conjunto de textos como entrada, os algoritmos podem identificar se são notícias sobre esporte, economia ou política; por exemplo.\n\nCom o grande crescimento das redes sociais existe uma quantidade muito grande de texto disponível na web, os quais podem ser utilizados para identificar as emoções que as pessoas estão apresentando! E isso pode ser muito útil para empresas que desejam saber quão satisfeitos seus clientes estão com seus produtos e/ou serviços. Por exemplo, se uma pessoa compra uma nova televisão é possível medir seu grau de satisfação por meio das emoções transmitidas nos textos que essa pessoa escreve sobre a televisão! Dessa forma, a empresa pode conhecer melhor o perfil de seus clientes e tomar decisões estratégicas quanto ao seu posicionamento no mercado!\n\nBaseado nisso, neste curso você terá uma visão teórica e prática de como funciona o processo de mineração de textos utilizando a técnica de classificação! É abordado um estudo de caso prático que mostra passo a passo como utilizar o algoritmo Naive Bayes para identificar emoções em frases, ou seja, informamos um texto qualquer para o sistema e o mesmo retorna qual emoção foi encontrada! Serão abordados os conceitos sobre classificação de textos, remoção de stops words, aplicação de algoritmos de stemming, teoria sobre o algoritmo Naive Bayes e finalmente a implementação do classificador de emoções. Além disso, também teremos um módulo no qual você aprenderá como avaliar o algoritmo construído e interpretar seus resultados. Com isso, você terá uma visão teórica e prática passo a passo de todas as etapas que envolvem a classificação de textos!\nUtilizaremos a linguagem Python e a biblioteca NLTK (Natural Language Toolkit) para o desenvolvimento passo a passo do sistema inteligente, que são ferramentas muito importantes no cenário da Inteligência Artificial! E não há problema se você não conhece Python, pois os conceitos serão apresentados de forma que se você tem uma noção básica de lógica de programação conseguirá acompanhar as aulas tranquilamente. É importante salientar que este curso será melhor aproveitado por iniciantes na área de mineração de textos e que não conhecem os tópicos citados anteriormente, sendo considerado um material inicial para estudos mais avançados.\nPreparado(a) para dar um importante passo na sua carreira? Aguardo você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial e Mineração de Texto",
        "Alunos que querem aprender passo a passo como funciona a área de classificação de textos"
      ]
    },
    {
      "title": "Jupyter x Docker",
      "url": "https://www.udemy.com/course/jupyter-x-docker/",
      "bio": "Deploy a Jupyter Notebook Server using Docker Containers on Heroku.",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Some experience with Docker Containers is recommended",
        "Some experience with Jupyter Notebooks is recommended"
      ],
      "description": "Learn to create a Python Jupyter Notebook Server with Docker & Heroku. This series builds gives you a step-by-step reference to deploy an interactive notebook to allow your projects to be more literal while making it easier for non-technicals to run your code.\nJupyter is a tool for running interactive notebooks; basically add Python with Markdown and you've got Jupyter. if you haven't used it before, I recommend you do.\nDocker is a tool that gives us control over our application's OS environment. Think of it like a recipe for your OS that you can share almost anywhere. In this one, we'll be covering deploying this project to Heroku but using Docker means we can deploy this nearly anywhere.\nIn this series, I'm going to show you how to deploy a Jupyter Notebook server on Heroku using Docker step-by-step.\nThe big caveat\nJupyter has the ability to create new notebooks and they will 100% save on your deployed docker-based Jupyter server... but they will disappear as soon as you deploy a new version. That's because containers, by their very nature, are ephemeral by default.\nThis caveat doesn't mean we shouldn't do this... it just means it is a HUGE consideration when using this guide over something like Google Colab.",
      "target_audience": [
        "Jupyter Notebook Enthusiasts",
        "Data Scientists & Data Engineers"
      ]
    },
    {
      "title": "Begin to Use Cloud Computing with Anaconda Cloud Notebook",
      "url": "https://www.udemy.com/course/begin-to-use-cloud-computing-with-anaconda-cloud-notebook/",
      "bio": "Begin to use Cloud Computing and Anaconda Cloud Notebook with Python, Data Science and Machine Learning [2025]",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Everyday experience using a computer with either Windows, MacOS, iOS, Android, ChromeOS, or Linux is recommended",
        "Access to a computer or equivalent machine with an internet connection",
        "Programming experience is not needed and you will be taught everything you need",
        "The course only uses costless software",
        "Walk-you-through start and setup videos for Anaconda Cloud Notebook and Windows 10/11 is included"
      ],
      "description": "Welcome to the course Begin to use Cloud Computing with Anaconda Cloud Notebook!\nThis is a free-of-cost, fast, short, less than one hour video course which will introduce you to Cloud Computing and the Anaconda Cloud Notebook!\nCloud Computing is one of those transformative technologies that literally has the power to change your life. In this video course, you will get an overview of Cloud Computing and you will be taught how to begin to use Cloud Computing with Anaconda Cloud Notebook.\nThe Anaconda Cloud Notebook offers a cloud-hosted notebook service with a fully loaded and ready-for-code interactive development environment, primarily for Python code, data science and machine learning. You may run the Anaconda Cloud Notebook on any modern browser, or any modern system and the Anaconda Cloud Notebook is more or less configuration and installation free.\n\n\nYou will learn:\nSome concepts and get an overview of Cloud Computing\nTo Begin to Use the Anaconda Cloud Notebook (Cloud-based Jupyter Notebook)\nto begin to experience the use Cloud computing resources.\nto use a modern Cloud-based Python Data Science and Machine Learning coding environment\nThis course is an excellent way to start to learn to use Cloud Computing and Anaconda Cloud Notebook.\n\n\nAnaconda Cloud Notebook allows you to\nStart Python coding immediately in the Anaconda Cloud without setup and installation\nAccelerate your data science learning journey and expand your knowledge\nSpin up awesome data science projects directly from your browser with all the packages and computing power you need\nCode from anywhere with internet access\nEnhance your skills and work productivity with the Anaconda Cloud Jupyter Notebook's powerful prototyping and dynamic typing\nThis course is designed for everyone who wants to\nlearn Cloud Computing concepts and get an overview of Cloud Computing\nlearn to start to use the Anaconda Cloud Notebook\nlearn to use a modern data science and machine learning coding environment\nRequirements:\nEveryday experience using a computer with either Windows, MacOS, iOS, Android, ChromeOS, or Linux is recommended\nAccess to a computer or equivalent machine with an internet connection\nProgramming experience is not needed and you will be taught everything you need\nThe course only uses costless software\nWalk-you-through start and setup videos for Anaconda Cloud Notebook and Windows 10/11 is included\n\n\nEnroll now to receive a less than one hour video course, which will introduce you to Cloud Computing and the Anaconda Cloud Notebook.",
      "target_audience": [
        "Everyone who wants to learn Cloud Computing concepts and get an overview of Cloud Computing",
        "Everyone who wants to learn to start to use the Anaconda Cloud Notebook",
        "Everyone who wants to learn to use a modern Cloud-based Python Data Science and Machine Learning coding environment"
      ]
    },
    {
      "title": "Curso de Data Science en Python Desde Cero + ChatGPT [2024]",
      "url": "https://www.udemy.com/course/curso-completo-de-data-science-en-python-desde-cero-2022/",
      "bio": "De cero a data scientist! Aprende Data Science con Python, Pandas, Scikit-learn, y más! ChatGPT para data science",
      "objectives": [
        "Aprende Pandas para realizar Análisis de Datos",
        "Aprende SciKit-Learn para realizar Machine Learning",
        "Realiza Visualizaciones Estáticas e Interactivas con Pandas",
        "NLP: Clasificación de Texto",
        "Aprende Python para Data Science y Machine Learning",
        "Implementa Algoritmos de Machine Learning",
        "Limpieza de Datos con Python",
        "Web Scraping Basico con Python"
      ],
      "course_content": {},
      "requirements": [
        "No se necesita ningún conocimiento previo de Python"
      ],
      "description": "Bienvenidos a este Curso Completo de Data Science en Python Desde Cero. En este curso, aprenderemos cómo usar Python para Data Science. Aprenderemos cómo recopilar datos, limpiar datos, hacer visualizaciones y construir un modelo de machine learning usando Python.\nEl objetivo principal de este curso es llevar tus habilidades analíticas y de programación al siguiente nivel para desarrollar tu carrera como data scientist. Para lograr este objetivo, vamos a resolver +100  ejercicios y varios proyectos que te ayudarán a poner en práctica todos los conceptos de programación utilizados en Data Science.\nAprenderemos las principales librerías de Python utilizadas en data science, como Pandas, Numpy y Scikit Learn, y las usaremos para hacer tareas que data scientist realizan a diario (limpieza de datos, visualización de datos, recopilación de datos y creación de modelos).\nEste curso cubre 4 secciones.\n1. Curso básico de Python para Data Science: En la primera sección, aprenderemos todos los conceptos básicos de Python que necesita saber para data science. Aprenderemos a usar variables, listas, diccionarios y más.\n2. Python para análisis de datos: Aprenderemos las librerías de Python que se utilizan para el análisis de datos, como Pandas y Numpy. Ambas son excelentes herramientas para explorar y trabajar con datos. Usaremos Pandas y Numpy para realizar tareas de data science como limpiar y preparar datos.\n3. Python para visualización de datos: En la tercera sección, aprenderemos como hacer visualizaciones estáticas e interactivas con Pandas. Además, te mostraré algunas técnicas para realizar correctamente la visualización de datos.\n4. Machine Learning con Python: En la cuarta sección, aprenderemos scikit-learn resolviendo un problema de clasificación de texto en Python. Esta es la librería de machine learning más popular en Python y no solo aprenderemos como implementar algoritmos de machine learning en Python, sino que también aprenderemos conceptos básicos detrás de los algoritmos más comunes utilizando ejemplos prácticos.\nBonus (Web Scraping básico con Python): Recuerda que al final de este curso, hay una sección de bonificación donde aprenderás a hacer Web scraping. El web scraping nos permite crear nuestro propio dataset extrayendo datos de sitios web. Esta es una habilidad imprescindible para los data scientists y aprenderemos esta técnica con la librería Beautiful Soup.\n\n\n¿Qué hace que este curso sea diferente de los demás y por qué debería inscribirse?\n\n\nEste es el curso más actualizado y completo de Data Science en Python.\n¿Estás cansado de un montón de tutoriales pero no tienes forma de practicar lo que has aprendido? En este curso, encontrarás muchos ejercicios para aprender Python resolviendo problemas.\nEste es el curso más orientado a proyectos que encontrarás. Resolveremos 4 proyectos para poner en práctica todos los conceptos que aprenderemos en este curso\n30 días de garantía de devolución de dinero ofrecido por Udemy.\nDespués de terminar este curso, podrás realizar análisis de datos, crear visualizaciones y construir modelos de machine learning con Python.\n¡Únete a mi curso y conviértete en un data scientist!",
      "target_audience": [
        "Principiantes que quieren aprender Data Science en Python desde cero"
      ]
    },
    {
      "title": "Detecção de Objetos com YOLO, Darknet, OpenCV e Python",
      "url": "https://www.udemy.com/course/deteccao-de-objetos-com-yolo-darknet-opencv-python/",
      "bio": "Aprenda a detectar mais de 600 tipos de objetos em imagens e vídeos usando a moderna arquitetura de Deep Learning YOLO!",
      "objectives": [
        "Detecte objetos em imagens e vídeos utilizando a moderna arquitetura YOLO",
        "Implemente o YOLO utilizando o framework Darknet e a biblioteca OpenCV com o Python",
        "Entenda a teoria básica sobre detecção de objetos e arquitetura YOLO",
        "Treine seu próprio detector personalizado utilizando as GPUs gratuitas do Google Colab",
        "Detecte objetos com o YOLOv8, o estado da arte em detecção de objetos"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Detecção de objetos - visão geral",
          "Detecção de objetos com YOLO",
          "Funcionamento básico do YOLO",
          "Histórico do YOLO",
          "Arquitetura do YOLO",
          "Recursos para download"
        ],
        "Detecção de objetos com YOLO e Darknet": [
          "Configuração do ambiente",
          "Testando o detector",
          "YOLO com suporte a GPU",
          "Detecção de mais objetos",
          "Detecção com imagens personalizadas",
          "Armazenamento dos arquivos do YOLO",
          "Parâmetros threshold e ext_output",
          "Detecção com outros modelos"
        ],
        "Detecção de objetos com YOLO e OpenCV": [
          "Aviso sobre a versão do OpenCV",
          "Importação das bibliotecas",
          "Carregamento do YOLO",
          "Atualização de código",
          "Camadas de saída YOLO",
          "Pré-processamento da imagem",
          "Detecção de objetos",
          "Non-max supression e resultados",
          "Explorando mais o OpenCV",
          "Redimensionamento da imagem",
          "Definição das funções e resultados",
          "Detecção em múltiplas imagens",
          "Contagem de objetos em múltiplas imagens",
          "Detecção somente de objetos específicos",
          "Melhorias na visualização"
        ],
        "Detecção de objetos em vídeos - Darknet e OpenCV": [
          "Darknet em vídeos - preparação do ambiente",
          "Darknet em vídeos - detecção 1",
          "Darknet em vídeos - detecção 2",
          "OpenCV em vídeos - preparação do ambiente",
          "OpenCV em vídeos - detecção 1",
          "OpenCV em vídeos - detecção 2",
          "OpenCV e GPU",
          "Informações sobre o YOLOv3"
        ],
        "Detecção de objetos personalizados": [
          "Criação da base de imagens 1",
          "Criação da base de imagens 2",
          "Criação da base de imagens 3",
          "Criação da base de imagens 4",
          "Treinamento do YOLO 1",
          "Treinamento do YOLO 2",
          "Treinamento do YOLO 3",
          "Precision e recall",
          "Outras métricas de avaliação",
          "Dicas sobre avaliação",
          "Criação do seu dataset de imagens manualmente"
        ],
        "YOLOv8": [
          "Outras versões do YOLO",
          "YOLOv8",
          "Instalação e configuração",
          "Detecção de objetos - linha de comando",
          "Confiança da detecção",
          "Detecção de múltiplas imagens",
          "Aviso sobre atualização da biblioteca",
          "Detecção de objetos - Python",
          "Testes com outros modelos",
          "Detecção em vídeos",
          "Segmentação de imagens",
          "Treinamento customizado 1 - imagens",
          "Treinamento customizado 2 - configurações",
          "Treinamento customizado 3 - treinamento",
          "Solução para erro ao executar comando",
          "Treinamento customizado 4 - avaliação",
          "Treinamento customizado 5 - testes",
          "Treinamento customizado 6 - continuar o treinamento"
        ],
        "Anexo I - Redes Neurais Artificiais": [
          "Perceptron de uma camada",
          "Redes multicamada - função soma e função de ativação",
          "Redes multicamada - cálculo do erro",
          "Descida do gradiente",
          "Cálculo do parâmetro delta",
          "Ajuste dos pesos com backpropagation",
          "Bias, erro, descida do gradiente estocástica e mais parâmetros"
        ],
        "Anexo II - Redes Neurais Convolucionais": [
          "Introdução a redes neurais convolucionais 1",
          "Introdução a redes neurais convolucionais 2",
          "Etapa 1 - operador de convolução (introdução)",
          "Etapa 1 - operador de convolução (cálculo)",
          "Etapa 2 - pooling",
          "Etapa 3 - flattening",
          "Etapa 4 - rede neural densa"
        ],
        "Considerações finais": [
          "Material complementar",
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição (if e for)",
        "Conhecimentos básicos sobre Python são desejáveis",
        "Conhecimentos básicos sobre o OpenCV são desejáveis (não obrigatório)"
      ],
      "description": "Curso atualizado com uma seção adicional sobre o YOLOv8!\nDentro da área da Visão Computacional existe a sub-área de detecção de objetos, que visa encontrar objetos personalizados em imagens e vídeos e é muito utilizada em carros autônomos, os quais precisam identificar pedestres e outros veículos para evitar colisões, bem como reconhecer placas de trânsito para seguir uma direção segura. Essas técnicas também podem ser utilizadas para detectar praticamente qualquer tipo de objeto em imagens ou vídeos, como por exemplo: relógios, placas de veículos, animais, faces de pessoas, celulares, logo de empresas dentre vários outros! Em resumo, você pode treinar um classificador para qualquer tipo de cenário!\nExistem diversas técnicas dentro deste cenário, porém, a que mais se destaca e que possui resultados incríveis é chamada de YOLO (You Only Look Once) e consiste na utilização de Redes Neurais Convolucionais da área de Deep Learning (redes neurais profundas). Muitas grandes empresas estão utilizando essa técnica para diversos tipos de aplicações comerciais, como por exemplo, utilização em carros autônomos, robôs humanoides, sistemas de segurança e defesa, rastreamento de objetos e automação industrial.\nAtualmente o YOLO é considerado o estado da arte em detecção de objetos em tempo real. A sua quarta versão (YOLOv4) apresentou melhoras significativas tanto em velocidade quanto em precisão, superando o resultado de todos os melhores detectores concorrentes até o momento de sua publicação.\nE para levar você até essa área, neste curso você aprenderá na prática como utilizar o YOLO para detectar mais de 600 objetos diferentes em imagens e vídeos, utilizando a linguagem Python, o framework Darknet e também a biblioteca OpenCV! Todos os exemplos serão implementados passo a passo utilizando o Google Colab, ou seja, você não precisa se preocupar com instalações e configurações de bibliotecas em sua máquina, pois tudo será desenvolvido on-line utilizando as GPUs do Google! Além de utilizar os recursos prontos do YOLO, você também aprenderá a construir sua própria base de dados de imagens caso precise treinar um detector de objetos personalizado! Confira os tópicos do curso:\nTeoria básica sobre detecção de objetos\nComo o YOLO funciona\nDetecção de objetos em imagens e vídeos, utilizando o framework Darknet e a biblioteca OpenCV\nCriação de bases de dados para o treinamento de detectores personalizados\nTeoria sobre redes neurais artificiais e redes neurais convolucionais\nYOLO é considerada a arquitetura mais eficiente e moderna para detecção de objetos, que muitas empresas estão utilizando em seus projetos comerciais! Você está preparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso!",
      "target_audience": [
        "Pessoas interessadas em aprender a arquitetura YOLO na teoria e prática",
        "Pessoas interessadas em detecção de objetos personalizados",
        "Pessoas interessadas na área de Visão Computacional",
        "Alunos de graduação que cursam disciplinas de Computação Gráfica, Processamento Digital de Imagens ou Inteligência Artificial"
      ]
    },
    {
      "title": "AIによる画像生成を学ぼう！【VAE / GAN】 -Google ColabとPyTorchで基礎から学ぶ生成モデル-",
      "url": "https://www.udemy.com/course/image_generation/",
      "bio": "近年大きな注目を集めているディープラーニング関連技術、VAE、GANを基礎から学ぶコースです。これらの生成モデルにより、人工知能は画像などを生成可能です。VAEおよびGANの概要、原理、PyTorchによる実装をシームレスに学びましょう。",
      "objectives": [
        "VAE、GANの原理について、基礎的な知識を学びます。",
        "VAEもしくはGANを使って、画像が生成できるようになります。",
        "Python、PyTorchで書かれた生成モデルのコードが読めるようになります。",
        "自分の力で、VAE、GANのコードを実装する力が身に付きます。",
        "生成モデル全般についての知識が身につきます。",
        "様々なVAE、GANの派生技術を学びます。"
      ],
      "course_content": {
        "生成モデルの概要": [
          "教材の使用方法",
          "イントロダクション",
          "コースの概要",
          "生成モデルの概要",
          "VAEの概要",
          "GANの概要",
          "Google Colaboratoryの使い方"
        ],
        "実装の準備": [
          "セクション2の教材",
          "Section2の概要",
          "活性化関数",
          "損失関数",
          "最適化アルゴリズム",
          "エポックとバッチ",
          "PyTorchの概要",
          "シンプルなディープラーニングの実装 Part1",
          "シンプルなディープラーニングの実装 Part2"
        ],
        "VAEの実装": [
          "セクション3の教材",
          "Section3の概要",
          "VAEの仕組み",
          "Autoencoderの実装 Part1",
          "Autoencoderの実装 Part2",
          "VAEの実装 Part1",
          "VAEの実装 Part2"
        ],
        "GANの実装": [
          "セクション4の教材",
          "Section4の概要",
          "GANの仕組み",
          "GANの実装 Part1",
          "GANの実装 Part2",
          "GANの実装 Part3",
          "DCGANの仕組み",
          "DCGANの実装"
        ],
        "生成モデルの応用": [
          "セクション5の教材",
          "Section5の概要",
          "LSGANによる画像素材の生成 -概要-",
          "LSGANによる画像素材の生成 -実装- Part1",
          "LSGANによる画像素材の生成 -実装- Part2",
          "LSGANによる学習の続き",
          "VAEの派生技術",
          "GANの派生技術",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "何らかのプログラミング経験があった方が望ましいです。",
        "Google Colaboratoryを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。",
        "中学-高校レベルの数学で十分です。高度な数学は必要ありません。",
        "ディープラーニング（深層学習）の解説は必要最低限となります。"
      ],
      "description": "「AIによる画像生成を学ぼう!」 は、GAE、VAEなどの生成モデルによる画像生成を扱う講座です。\n生成モデルは近年最も注目を集めているディープラーニング関連技術の1つで、訓練済みのモデルから画像などのデータを新たに生成することができます。\n本講座では、生成モデルとしてVAE（Variational Autoencoder）とGAN（Generative Adversarial Network）の2種類を解説します。\nそれぞれの概要は以下の通りです。\nVAE: データの特徴を潜在変数と呼ばれるベクトルに圧縮し、復元します。\nGAN: 偽物を生成するGenerator、真贋を見抜くGenerator、2つのネットワークが競い合うようにして学習することで、次第に本物らしいデータが生成されます。\nディープラーニング、生成モデルを活用し、人工知能によるデータの生成ができるようになりましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\nコースの内容は以下の通りです。\nSection1. 生成モデルの概要\n→ 生成モデルの概要、および開発環境について解説します\n\nSection2. 実装の準備\n→ フレームワークの使い方、必要な数学や関数について学びます\n\n\nSection3. VAEの実装\n→ VAEの原理と実装方法を学びます\n\n\nSection4. GANの実装\n→ GANの原理と実装方法を学びます\n\n\nSection5. 生成モデルの応用\n→ VAE、GANの派生技術、応用について解説します\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックがダウンロード可能です。\n本コースはディープラーニング用フレームワークとしてPyTorchを使用します。\nまた、Pythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "VAE、GANに興味があるけど、最初のとっかかりが分からない方。",
        "生成モデルの難解な数式に辟易した方。",
        "VAE、GANのコードをPyTorchで書けるようになりたい方。",
        "生成モデルによる画像生成で、何らかの問題を解決したい方。",
        "生成モデル全般の知識が欲しい方。",
        "仕事上、VAE、GANの知識が必要になった方。",
        "一歩進んだディープラーニング関連技術を身に付けたい方。"
      ]
    },
    {
      "title": "【世界で55万人が受講】データサイエンティストを目指すあなたへ〜データサイエンス25時間ブートキャンプ〜",
      "url": "https://www.udemy.com/course/datascience365/",
      "bio": "機械学習・ディープラーニング・人工知能に関するビジネス上の課題を、回帰分析・ニューラルネットワーク・K平均法等を使って解いていきます。python、jupyter、numpy、pandas、tensorflow等のスキルも身に付きます。",
      "objectives": [
        "データサイエンティストになるために必要な一連のツールについて学ぶことができます",
        "統計分析、NumpyやPandasなどを使ったPythonのプログラミング、高度な統計学上の手法、Tableaau、StatsModelとScikitLearnを使った機械学習の実装、TensorFlowを使ったディープラーニングの実装",
        "データの前処理の方法",
        "機械学習の背景にある考え方",
        "Pythonを使って統計上の分析をする方法",
        "Pythonを使った線形回帰とロジスティック回帰分析",
        "クラスター分析と因子分析",
        "実生活における実践問題を通じた深い理解",
        "TensorFlowをはじめとした、ディープラーニングを進める上で必要とされるツール",
        "過学習・過少学習とその解決方法について",
        "訓練用データ、検証用データ、テストデータの概要と具体的な実装方法について",
        "最先端の機械学習アルゴリズム（Adamなど）の概要と実装方法について",
        "信頼区間や検定など、少し難易度が高い統計上の知識",
        "機械学習の全体像と、それぞれの用語の深い理解",
        "汎用性の高い実装方法について",
        "p値やt値といった統計上の指標と回帰分析との関係について",
        "バッチ処理の概要と実装方法"
      ],
      "course_content": {},
      "requirements": [
        "基礎から学んでいきますので、事前の知識は特に必要ありません",
        "コードの実装にあたっては、Anacondaをインストールする必要がありますが、コースの中でインストール方法についてお伝えしています",
        "マイクロソフトのエクセル（2003, 2010, 2013, 2016, 又は365が必要です。）"
      ],
      "description": "このコースは全世界で210万人を超える受講者を持つ365careersによって公開されている\n[The Data Science Course 2020: Complete Data Science Bootcamp] の完全日本語版です。\nこのコースではオリジナルコースのエッセンスを余すことなく網羅したうえで、\n日本語ユーザーが快適に学べるように最適化されたコンテンツをお届けします。\n\n\n近年世界的に需要の高まりが注目されている職業、それがデータサイエンティストです。\n日本も例外ではなく高等教育機関や企業などでもその必要性が声高らかに叫ばれていますが供給が追いついていません。\n\n\n経済産業省が発表したIT人材需給に関する調査によると、2030年にはデータサイエンス等に携わる先端IT人材の不足数は30万人にのぼるともいわれています。\n\nまた、従来の学習方法は受講に数十万円単位でコストがかかったり、拘束時間が長かったりと学習者側の負担は大きなものでした。\n\n\nこのコースはデータサイエンティストを志す人全ての方が、\nデータサイエンスの世界で活躍するために必要な知識とスキルを、\n豊富なアニメーション、具体例、課題を通して自分のペースで確実に身につけれるように設計されています。\n\n\n更に、この講義を通じて学ぶことによって身につけることができるスキルは、データサイエンスにとどまりません。\n例えば、ビジネスにまつわるスキルだけでも、以下のような能力をみにつけることができます。\n・ビジネス上の課題を見つける能力\n・課題を対処可能な内容に整理する力\n・データを定量的に評価する方法\n・データを見やすく、直感的に整理する方法\n・論理的に物事を考える力\nつまり、ビジネスパーソンとして活躍するために必要なスキルをこの講座を通じて身につけることができるのです。\n\n\nここで、本講座でご紹介している内容の一部を記載します。\nただ長いだけの講義ではなく、コンテンツがギュッと詰まった講義になっています。\n\n\n・データサイエンスの全体像\n・データサイエンスの言葉の整理\n・従来の統計学と機械学習の違い\n・従来のデータとビッグデータの違い\n・データサイエンスで間違いやすい注意点\n・データサイエンスにまつわる職業の整理\n・データサイエンスにおいて使われるプログラミング言語とソフトウェアについて\n・確率の公式\n・期待値について\n・事象について\n・分布について\n・順列について\n・集合について\n・ベイズの法則について\n・様々な確率分布の概要\n・ファイナンスと確率の関係\n・統計と確率の関係\n・データサイエンスと確率の関係\n・母集団と標本\n・代表値について\n・歪度について\n・標準偏差と変動係数について\n・共分散について\n・信頼区間について\n・仮説検定について\n・帰無仮説と有意水準について\n・棄却域と有意水準について\n・p値について\n・t値について\n・pythonの概要\n・回帰分析モデルについて\n・相関と回帰の違いについて\n・分散分析の方法について\n・決定係数について\n・自由度修正済み決定係数について\n・F検定について\n・線形回帰で求められる想定・前提について\n・ダミー変数の扱いについて\n・stats modelの使い方\n・seabornの使い方\n・フィーチャースケーリングについて\n・標準化について\n・過学習と過少学習について\n・モデルの訓練について\n・データセットの分割について\n・ロジスティック関数とロジット関数について\n・オッズの意味について\n・クラスタリングについて\n・エルボー法について\n・K平均法について\n・樹形図について\n・ヒートマップについて\n・機械学習のイメージと具体例\n・MNISTについて\n・勾配降下法について\n・確率的勾配降下法について\n・完成について\n・tensorflowを使った実装の進め方について\n・活性化関数について\n・バックプロパゲーションについて\n・ソフトマックス関数の特徴について\n・アーリーストッピングについて\n・ニューラルネットワークについて\n・ディープニューラルネットワークについて\n・adamについて\n・学習率について\n・適応学習率について\n・前処理の進め方について\n・バイナリエンコーディングとワンホットエンコーディングについて\n・データのバランシングについて\n・バッチ処理について\n\n\n上記でも講義で説明している内容の一部です。\n\n\n本講座を活用し尽くして、更なるスキルアップに役立てて下さい。",
      "target_audience": [
        "データサイエンティストになりたい方。もしくはその領域について学びたい方",
        "データサイエンティストとしてキャリアを築いていきたい方",
        "段階を追って知識を積み上げていくことができるように構成していますので、特に初心者の方にお勧めです"
      ]
    },
    {
      "title": "Hands-on Machine Learning for Stock Trading [Python]",
      "url": "https://www.udemy.com/course/machine-learning-for-stock-trading-python/",
      "bio": "Unleash the power of Neural Networks for Trading",
      "objectives": [],
      "course_content": {
        "Content": [
          "Introduction",
          "Model",
          "Getting historical data",
          "Creating technical analysis indicators",
          "Labelling our data",
          "Training our Neural Network",
          "Backtesting our Model",
          "Forecasting today returns"
        ]
      },
      "requirements": [
        "Basic knowledge of Python"
      ],
      "description": "Enter the world of Neural Networks and Financial Forecasting with this free course.\n\n\nCan you forecast the returns of your favorite stock using Machine Learning?\n\n\nArtificial Intelligence is certainly changing the world:\n\n\nFrom the way we get our content, autonomous driving, medical advances to art creation.\n\n\nFinancial Machine Learning is one of the industries with a bigger impact on these technologies, from Roboadvisors to Algorithmic Trading.\n\n\nMost recommendations made by firms are based on Artificial Intelligence nowadays, rendering most conventional analysts useless.\n\n\nThe same happens for traders, not many years ago trading was done manually, currently a huge share of the market is being traded by AI.\n\n\nThese advances have changed the game, gaining insight with edges the human eye can’t see anymore.\n\n\nWhile the biggest financial institutions have been trading using Artificial Intelligence for years, most retail traders don’t know how to use nor benefit from them, we are here to change that.\n\n\nRoll up your sleeves with this hands-on project where you are going to learn by doing and interacting with code, completely from scratch.\n\n\nIn this course you are going to learn how to:\n\n\nDownload Historical Data from your code, automatically.\nPrepare your data with the most suitable indicators.\nHow to label and prepare data to feed our model.\nPrepare a Neural Network.\nEvaluate models.\nBacktest your ML Model.\nCreate accurate stock forecasts.\n\n\nWe hope you enjoy this course.\n\n\nGenbox Trading",
      "target_audience": [
        "traders and coders who wants to use Machine Learning"
      ]
    },
    {
      "title": "Ocean Data in Canada",
      "url": "https://www.udemy.com/course/ocean-data-in-canada/",
      "bio": "Learn what ocean data are, how they're being used, and the ways in which you can access open ocean data.",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Course Introduction",
          "Introduce yourself and assess your pre-existing knowledge"
        ],
        "What are ocean data?": [
          "Ocean data 101",
          "Data 101"
        ],
        "Canadian trends in ocean data": [
          "Artificial intelligence and ocean data",
          "Open ocean data",
          "AI and open data"
        ],
        "Canadian ocean data repositories": [
          "Government open data repositories",
          "Specialized ocean data repositories",
          "Licensing, permissions, and reuse",
          "Searching repositories effectively",
          "Find a dataset using an ocean data repository"
        ],
        "Uses of ocean data": [
          "Aquatic animal tracking",
          "Artificial intelligence and aquaculture",
          "Underwater imaging"
        ],
        "Canadian and international resources": [
          "Canadian resources",
          "International resources"
        ],
        "Conclusion": [
          "Conclusion",
          "What have you learned from this course?"
        ]
      },
      "requirements": [
        "No data science background needed. Just bring your curiosity!"
      ],
      "description": "Employment in the Canadian ocean sector is booming -- and one of the most important skillsets that you can develop if you want to work in this sector is the ability to work with ocean data! But, where should you begin? This course is a great starting place. Here, you'll be introduced to some of the core concepts that you'll need to understand on your way to becoming an ocean data whiz.\nYou don't need a technical background or a firm understanding of ocean science to benefit from this course -- true beginners are welcome.\nTopics covered in this course include:\nWhat are ocean data? What do we know about our oceans? Who's collecting this data, and how?\nCanadian ocean data trends, including open data and artificial intelligence. Learn about these trends and their applications.\nData repositories. Find out where you can go to find data that are available for public use.\nSharing data. Understand basic methods of data sharing and how licenses impact your ability to use open data.\nUse cases. See examples of how ocean data are being used today in the public and private sectors.\nCanadian and international resources. Discover other sites that you can visit to deepen your understanding.\nLearn through watching video lectures, completing exercises, and taking short, optional assessments to deepen your understanding.\n\n\nThis course was created as part of the VITALITY Project, with support from Canada's Ocean Supercluster, an industry-led, national cluster that's growing the ocean economy in a digital, sustainable, and inclusive way. The VITALITY Project aims to improve small- and medium-sized enterprises (SMEs) and students' capacity to work meaningfully with ocean data.",
      "target_audience": [
        "Graduate and undergraduate students who want to learn about what ocean data is and ways to work with it",
        "Ocean sector professionals who want to improve their knowledge of open ocean data repositories and how to use them"
      ]
    },
    {
      "title": "【世界で91万人が受講】基礎から理解し、Pythonで実装！機械学習26のアルゴリズムを理論と実践を通じてマスターしよう",
      "url": "https://www.udemy.com/course/ml-with-python/",
      "bio": "単回帰、重回帰、ニューラルネットワーク、強化学習、自然言語処理、主成分分析といったテーマに関するアルゴリズムの実装から統計学を活用したモデリング、Google colabやTensorflowの使い方などMLに必要なすべてを習得します。",
      "objectives": [
        "Pythonを使って機械学習のアルゴリズムの実装を行うことができます",
        "多くの機械学習のアルゴリズムを直観的に理解できるようになります",
        "統計学の手法を活用したモデルの評価方法を学ぶことができます",
        "強化学習、ディープラーニングなどの実装を行うことができます",
        "モデルの精度を高める方法を知ることができます",
        "Google colabの使い方を学ぶことができます",
        "Tensorflowの使い方を学ぶことができます"
      ],
      "course_content": {
        "はじめに": [
          "はじめに",
          "機械学習、ディープラーニング、AI（人工知能）の違い",
          "機械学習の具体例",
          "講義を進める上での参考情報",
          "講義で用いていくデータ",
          "講義で用いるデータの扱い方",
          "Google Colabの使い方（オンラインで実装）",
          "Spyderの使い方（手元のパソコンで実装）"
        ],
        "--------------------Part1 データの前処理--------------------": [
          "データの前処理"
        ],
        "データの前処理": [
          "実装で使うフォルダの確認",
          "前処理とは",
          "ライブラリのインポート",
          "補足）独立変数と従属変数に分ける理由",
          "補足）ilocメソッド",
          "データセットのインポート",
          "オブジェクト指向プログラミングの概要（直観的な理解）",
          "欠損値の処理1（欠損値について）",
          "欠損値の処理2（実装）",
          "カテゴリ変数のエンコーディングについて",
          "独立変数のエンコーディング",
          "従属変数のエンコーディング",
          "訓練用データセットとテスト用データセットへの分割",
          "補足）訓練用とテスト用にデータセットを分ける理由",
          "feature scaling",
          "補足）feature scalingが必要な理由"
        ],
        "--------------------Part2 回帰--------------------": [
          "回帰"
        ],
        "単回帰分析": [
          "単回帰分析の直観的な理解1",
          "単回帰分析の直観的な理解2（最小二乗法）",
          "実装で使うフォルダの確認",
          "単回帰分析の実装 1",
          "単回帰分析の実装 2",
          "単回帰分析の実装 3",
          "単回帰分析-ボーナス問題",
          "単回帰分析"
        ],
        "重回帰分析": [
          "データセットについて",
          "重回帰分析の直観的な理解1",
          "重回帰分析の直観的な理解2（高次元のイメージをつかむ）",
          "重回帰分析の直観的な理解3（線形回帰の前提）",
          "重回帰分析の直観的な理解4（ダミー変数トラップ）",
          "p値について",
          "重回帰分析の直観的な理解5（変数の選択1）",
          "重回帰分析の直観的な理解5（変数の選択2）",
          "重回帰分析の直観的な理解5（変数の選択3）",
          "実装で使うフォルダの確認",
          "重回帰分析の実装1",
          "重回帰分析の実装2",
          "重回帰分析の実装3",
          "重回帰分析の実装4",
          "（参考）変数減少法の実装について",
          "重回帰分析-ボーナス問題",
          "重回帰分析"
        ],
        "多項式回帰": [
          "多項式回帰の直観的な理解1",
          "実装で使うフォルダの確認",
          "多項式回帰の実装1",
          "多項式回帰の実装2",
          "多項式回帰の実装3",
          "多項式回帰の実装4",
          "補足）Polinomial featureが前処理に属する理由"
        ],
        "サポートベクトル回帰": [
          "サポートベクトル回帰の直観的な理解",
          "参考：非線形のSVR（カーネルSVM）",
          "実装で使うフォルダの確認",
          "サポートベクトル回帰の実装1",
          "サポートベクトル回帰の実装2",
          "サポートベクトル回帰の実装3",
          "サポートベクトル回帰の実装4",
          "補足）サポートベクトル回帰の実装",
          "補足）SVRではフィーチャースケーリングが必要な理由"
        ],
        "回帰木": [
          "回帰木の直観的な理解",
          "実装で使うフォルダの確認",
          "回帰木の実装1",
          "回帰木の実装2",
          "回帰木の実装3",
          "補足）回帰木の実装"
        ],
        "ランダムフォレスト（回帰）": [
          "ランダムフォレストの直観的な理解",
          "実装で使うフォルダの確認",
          "ランダムフォレスト（回帰）の実装1"
        ]
      },
      "requirements": [
        "行列の簡単な計算",
        "指数関数などの高校レベルの数学の知識"
      ],
      "description": "このコースは全世界で220万人を超える受講者を持ち、人工知能、機械学習、深層学習の第一人者、SuperDataScienceTeamによってUdemyで公開されているベストセラー「Machine Learning A-Z」の完全日本語版です。\nオリジナルの講義の内容を、「講義/Pythonを用いた実装」という形で一から再収録しました（Rの実装は除いています）。\n\n\n昨今メディアなどで人工知能、AI 、機械学習と言ったキーワードを聞かない日はありませんが、多くの方は 「興味は持っているものの、何から手を付けて良いのか分からない。」 「数学が苦手でとっつきにくい」 と感じている方も多いのではないでしょうか。\n本コースはそのような学習者の為にデザインされたコースです。\n\n\n文書の翻訳といった分野にとどまらず、IPhoneの音声認識、AmazonやNetfrixなどにおけるお勧め機能、Facebookなどにおける画像認識をはじめ、医療、宇宙開発、拡張現実など、あらゆる領域において活用できる可能性を秘めているのが人工知能・機械学習なのです。\nまた、世の中で生み出されるデータの量の増加により、今後更なる発展が期待される分野とも言えるでしょう。\n\n\nその一方で、初学者にとって機械学習を学ぶにはハードルが高いという難点がありました。\n機械学習の参考書を手に取ってはみたものの、複雑な数式だらけで挫折してしまった、という方もいらっしゃるかもしれません。\n更に、機械学習は異なる領域の専門家がそれぞれの見解を元に書籍が作られているため、学ぶ内容に一貫性がないというもの非常に大きな問題でした。\n\n\n機械学習を学んだことがあるが、挫折してしまった。そんな方にこそ是非受講して頂きたいコースです。\n本コースでは、機械学習で用いられる26のアルゴリズムに関し、まずは直観的な理解をし、その上で実装をしていきます。 難しい数式は極力使わないように配慮していますので、数学に苦手意識がある方でもスムーズに学習を進めることが可能です。\nまた、それぞれのアルゴリズムをカテゴリに分け、まとめて学習を進めていきますので、それぞれの学習内容が有機的につながっていくでしょう。\n\n\n本コースの内容は以下のとおりです。\nPart 1 - データの前処理\nPart 2 - 回帰: 単回帰, 重回帰, 多項式回帰, サポートベクトル回帰, 回帰木, ランダムフォレスト（回帰）\nPart 3 - 分類: ロジスティック回帰, K近傍法, サポートベクトルマシン, カーネルSVM, ナイーブベイズ, 分類木, ランダムフォレスト（分類）\nPart 4 - クラスタリング: K平均法, 階層クラスタリング\nPart 5 - Association Rule Learning: Apriori, Eclat\nPart 6 - 強化学習: Upper Confidence Bound, Thompson Sampling\nPart 7 - 自然言語処理: Bag-of-words model\nPart 8 - ディープラーニング: ニューラルネットワーク, 畳み込みニューラルネットワーク\nPart 9 - 次元削減: 主成分分析, 線形判別分析, カーネル PCA\nPart 10 - Model Selectionとブースティング: k分割交差検証, グリッドサーチ, XGBoost\n\n\n本講義を終えた時には、機械学習のアルゴリズムに対する理解がぐっと深まっているでしょう。\n\n\nこれからも需要が伸びることが予想される機械学習の分野で、ライバルに差を付けたいという方は、ぜひとも本コースを受講してみてください。\n本コースを終えた時には、機械学習に対する見え方が変わっていることをお約束します。",
      "target_audience": [
        "機械学習に興味を持っている方",
        "線形回帰やロジスティック回帰といった内容については何となく学んだが、更に深く理解をしたい人",
        "データサイエンスの分野でキャリアを開始したい人",
        "機械学習の各アルゴリズムを直観的に理解したい人",
        "機械学習の専門書を読んだが、数式が難解で良く分からないと感じている方"
      ]
    },
    {
      "title": "Machine Learning com Python",
      "url": "https://www.udemy.com/course/machine-learning-com-python/",
      "bio": "Aprenda com muitas aulas práticas os algoritmos de aprendizagem supervisionada, não supervisionada e reforço.",
      "objectives": [
        "Aprendizagem Supervisionada",
        "Aprendizagem Não Supervisionada",
        "Aprendizagem por Reforço",
        "Naive Bayes",
        "Máquina de Vetor de Suporte (SVM)",
        "Regressão Logística",
        "Aprendizagem Baseada em Instâncias (KNN)",
        "Random Forest",
        "Árvore de Decisão",
        "XGBoost",
        "Light GBM",
        "CatBoost no Python",
        "Regressão Linear Simples",
        "Correlação Linear",
        "Regressão Linear Múltipla",
        "Regressão Polinomial",
        "Regressão com vetores de Suporte (SVR)",
        "Regressão com Árvore de decisão",
        "Regressão com Random Forest",
        "Regressão com XGBoost",
        "Regressão com Light GBM",
        "Regressão com CatBoost",
        "Redes Neurais Artificiais",
        "K-means",
        "K-Modes",
        "K-Prototypes",
        "MeanShift",
        "Hierárquico",
        "DBSCAN",
        "APRIORI",
        "ECLAT",
        "Q-Learning",
        "Pré-processamento dos dados",
        "Validação cruzada",
        "Análise dos Componentes Principais (PCA)",
        "Conceitos de Python",
        "Conceitos de Estatística"
      ],
      "course_content": {
        "Introdução": [
          "Boas vindas e apresentação do instrutor",
          "Apresentação do curso e da plataforma de estudos"
        ],
        "Fundamentos da Linguagem Python": [
          "A Linguagem Python",
          "Conhecendo o Google Colaboratory",
          "Instalação do Anaconda Python",
          "Conhecendo o Jupyter Notebook",
          "Primeiros passos",
          "Operadores Matemáticos",
          "Importações de bibliotecas e pacotes",
          "Estrutura condicional",
          "Estrutura de Repetição",
          "Listas, Tuplas e Dicionários",
          "Criação de Funções",
          "Função Lambda e função map",
          "List Comprehensions",
          "Vetores e matrizes"
        ],
        "Fundamentos de Estatística para Machine Learning": [
          "Visão geral da estatística",
          "Dados e amostragem",
          "Distribuição de Frequências",
          "Medidas de tendência central",
          "Medidas de dispersão e de posição",
          "Análise de Outliers",
          "Probabilidade",
          "Teorema de Bayes",
          "Distribuição de probabilidades Discreta",
          "Distribuição de probabilidades Contínuas",
          "Intervalo de Confiança",
          "Testes de Hipóteses: Teste Z para média",
          "Testes de Hipóteses para proporção",
          "Testes de hipóteses: Teste t para média",
          "Métricas de desempenho"
        ],
        "Aprendizado Supervisionado: Classificação": [
          "Conceitos de Machine Learning",
          "Etapas para criação dos algoritmos",
          "Classificação",
          "Conhecendo o Dataset",
          "Exploração e análise dos dados – parte 1",
          "Exploração e análise dos dados – parte 2",
          "Exploração e análise dos dados – parte 3",
          "Análise e tratamento dos dados – parte 1",
          "Análise e tratamento dos dados – parte 2",
          "Pré-processamento dos dados: variáveis categóricas",
          "Escalonamento",
          "Pré-processamento: escalonamento e separação de variáveis",
          "Pré-processamento: LabelEncoder e OnehotEncoder",
          "Pré-processamento: Redução de dimensionalidade",
          "Pré-processamento: Salvamento de variáveis",
          "Separação entre treino e teste",
          "Naive Bayes : Teoria",
          "Naive Bayes no Python",
          "Máquina de Vetor de Suporte (SVM): Teoria",
          "Máquina de Vetor de Suporte no Python",
          "Regressão Logística: Teoria",
          "Regressão Logística no Python",
          "KNN (Aprendizagem Baseada em Instâncias)",
          "Exemplo de Cálculo com KNN",
          "KNN no Python",
          "Árvore de Decisão: Teoria",
          "Árvore de Decisão no Python",
          "Random Forest: teoria",
          "Random Forest no Python",
          "XGBoost: Teoria",
          "XGBoost no Python",
          "Light GBM: teoria",
          "LGBM no Python",
          "Catboost: Teoria",
          "Catboost no Python",
          "Salvando dados e simulando Deploy",
          "Utilização de Pipeline e cuidado com Data Leakage",
          "Otimização de Hiperparâmetros",
          "Otimização com Grid Search",
          "Desafio 1",
          "Postagem Desafio 1"
        ],
        "Aprendizado Supervisionado: Regressão": [
          "Regressão",
          "Conhecendo o Dataset",
          "Exploração, Análise e Tratamento dos dados",
          "Correlação Linear: Teoria",
          "Regressão Linear: Teoria",
          "Correlação Linear no Python",
          "Regressão Linear no Python: parte 1",
          "Regressão Linear no Python: parte 2",
          "Avaliação da Regressão Linear Simples no StasModels",
          "Regressão Linear Múltipla",
          "Regressão Linear Múltipla no Python",
          "Avaliação da Regressão Linear Múltipla no Statsmodels",
          "Regressão Polinomial: teoria",
          "Regressão Polinomial no Python",
          "Regressão com Vetores de Suporte (SVR) no Python",
          "Regressão com Árvore de decisão no Python",
          "Regressão com Random Forest no Python",
          "Regressão com XGBoost no Python",
          "Regressão com Light GBM no Python",
          "Regressão com CatBoost no Python",
          "Salvando dados e simulando Deploy",
          "Desafio 2",
          "Postagem do Desafio 2"
        ],
        "Aprendizado Supervisionado com Redes Neurais Artificiais": [
          "Neurônio Biológico e neurônio artificial",
          "Perceptron",
          "Funções de ativação",
          "Aprendizagem nas redes neurais",
          "Aprendizagem com descida do gradiente",
          "Topologias das redes neurais artificiais",
          "Algoritmo Backpropagation",
          "Definição dos hiperparâmetros",
          "Classificação com Redes Neurais Artificiais: pré-processamento",
          "Classificação com Redes Neurais Artificiais: criação do algoritmo",
          "Desafio 3",
          "Postagem Desafio 3",
          "Regressão Linear com Redes Neurais artificiais parte 1",
          "Regressão Linear com Redes Neurais artificiais parte 2",
          "Desafio 4",
          "Postagem Desafio 4"
        ],
        "Aprendizado Não Supervisionado: Agrupamento": [
          "Agrupamento",
          "Conhecendo o Dataset",
          "Exploração e tratamento dos dados",
          "Pré-Processamento",
          "K-Means (teoria)",
          "Cálculo Clusters K-Means",
          "K-means no Python: dois atributos",
          "K-means no Python: todos atributos",
          "K-means com PCA no Python",
          "Agrupamento Hierárquico",
          "Hierárquico com PCA no Python",
          "Hierárquico no Python: todos atributos",
          "DBSCAN",
          "DBSCAN com PCA no Python",
          "DBSCAN no Python: todos atributos",
          "MeanShift",
          "MeanShift com PCA no Python",
          "MeanShift no Python: todos atributos",
          "K-Prototypes",
          "k-Modes parte 1",
          "K-modes parte 2",
          "DESAFIO 5",
          "Postagem Desafio 5"
        ],
        "Aprendizado Não Supervisionado: Regras de Associação": [
          "Regras de associação",
          "ECLAT",
          "APRIORI",
          "Conhecendo o Dataset",
          "Análise, tratamento e pré-processamento dos dados",
          "Projeto Apriori",
          "DESAFIO 6",
          "Postagem Desafio 6"
        ],
        "Aprendizagem por Reforço": [
          "Conceitos da Aprendizagem por Reforço",
          "Conhecendo o problema",
          "Configurações do treinamento",
          "Treinamento do Algoritmo",
          "Avaliação do Algoritmo"
        ],
        "Finalização do curso": [
          "Encerramento"
        ]
      },
      "requirements": [
        "Não há pré-requisito."
      ],
      "description": "Este curso apresenta diversos tipos de algoritmos de Machine Learning para aprendizagem supervisionada (classificação e regressão), não supervisionada (agrupamento e associação) e Introdução à aprendizagem por reforço, utilizando a linguagem Python. Ele é destinado a iniciantes no mundo de Machine Learning, mas também apresenta técnicas de nível médio e até mesmo de nível avançado.\nOs algoritmos apresentados no curso são modernos e os mais utilizados no cotidiano (XGBoost, Catboost, LightGBM, Naive Bayes, Random Forest, Árvores de Decisão, SVM, KNN, Redes Neurais Artificiais, Regressão Linear Simples e Múltipla, Regressão Polinomial, K-Means, DBSCAN, K-Modes, K-Prototypes, Apriori, Eclat, Q-Learning...)\nTodas as aulas são explicadas passo a passo, com foco nas aplicações práticas, mas com conceitos teóricos básicos introdutórios de forma bem objetiva, portanto, o curso não detalha a matemática avançada envolvida nos algoritmos.\nOs projetos são trabalhados desde a aquisição dos conjuntos de dados nos repositórios de dados, passando pelo tratamento e pré-processamento e culminando na criação dos algoritmos.\nO curso é dividido basicamente nas seguintes partes:\n1) Domínio do uso da linguagem Python, com o Google Colaboratory, desde os conceitos fundamentais até conceitos mais avançados para análise e manipulação de dados.\n2) Fundamentos da Estatística Básica (Parte teórica).\n3) Aprendizagem Supervisionada: Classificação.\n4) Aprendizagem Supervisionada: Regressão.\n5) Aprendizagem não supervisionada: Agrupamento e associação.\n6) Introdução à Aprendizagem por Reforço.\nSão disponibilizados todos os slides das aulas teóricas, todos os scripts das aulas práticas no Python e todos os arquivos com os datasets.\nÉ um curso riquíssimo em informações e com explicações claras e objetivas, ilustrando o fantástico mundo do Machine Learning.\nUma observação importante: o curso não é Estático, isto é, qualquer atualização necessária ou solicitada pelos alunos será acrescida ao curso e, sempre que tiver alguma alteração, atualização ou inclusão de conteúdo, todos serão comunicados.",
      "target_audience": [
        "Cientista de Dados",
        "Estatístico",
        "Analista de dados",
        "Engenheiro",
        "Pesquisador",
        "Economista",
        "Administrador",
        "Engenheiro de Dados"
      ]
    },
    {
      "title": "R basics for Data Science , AI , Data Analytics : Part 1",
      "url": "https://www.udemy.com/course/r-data-science-ai-data-analytics/",
      "bio": "Use R for Data Analytics and Data science",
      "objectives": [],
      "course_content": {
        "Introduction to R Basics": [
          "keywords In R",
          "Identifiers in R",
          "Comments in R",
          "Statements in R",
          "What are variables in R & its use",
          "Types of Variable assignment in R"
        ],
        "Data Types and Operators !": [
          "Data types In R",
          "Operators In R"
        ],
        "Control Structures & Functions in R !": [
          "Conditional Statements in R",
          "Loops & Indentation in R",
          "what are Functions in R ?"
        ],
        "Basic Data Structures in R": [
          "What are Vector in R ?",
          "Basic operation on Vector",
          "What are list in R ?",
          "Basic operation on List",
          "Dataframe in R !"
        ]
      },
      "requirements": [
        "No prior knowledge or experience needed. Only a passion to be successful!"
      ],
      "description": "Are you interested in data science?\nDo you want to learn R totally from scratch?\nAre you looking for an easy step by step approach to get into R?\nDo you want to take an easy R course for BEGINNERS?\n\nWell, if your answer is YES to some of these questions, look no further, this course will help you.\n\n\n\n\n\n\nIn this free course , will start with installation of R and Jupyter Notebook , then we will learn basics of R like keywords , Identifiers , data types , operators , loops etc.. & data structures in R as well !\nThis course is truly step-by-step. In every new tutorial we build on what had already learned and move one extra step forward.\nThe Entire R course is divided into 2 parts ( 2 hours each )   ! You will also get the code I am using for the demos.\n\n\n\n\nWhat you will learn:\nLearn how to use Jupyter Notebook\nLearn the core principles of programming\nLearn how to create vectors in R\nLearn how to create variables\nLearn about integer, double, logical, character, and other types in R\nLearn how to create a while() loop and a for() loop in R\nLearn how to define own functions in R\nLearn the various data-structures in R\n\n\n\n\n\n\nWhat R you waiting for?",
      "target_audience": [
        "This course is for you if you want to learn how to program in R",
        "This course is for you if you are tired of R courses that are too complicated",
        "This course is for you if you want to learn R by doing"
      ]
    },
    {
      "title": "Statistical Decision Making in Data Science with Case Study",
      "url": "https://www.udemy.com/course/linear-regression-with-case-study-in-python-2020/",
      "bio": "Understand how Statistics is Applied to Data Science Problem like ANOVA, t-test, F-test in Python",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Google Colab"
        ],
        "Case Study - Big Mac Index": [
          "Big Mac Index Case Study Walk through"
        ],
        "Least Square Regression": [
          "Least Square RegressionLinear Regression , y = a+b X and SSE"
        ],
        "Least Square Regression in Python": [
          "Load Data & Scatter Plot",
          "Fitting Ordinary Least Square Regression Model in Python"
        ],
        "Hypothesis Testing to model": [
          "Degree of Freedom of the Model",
          "Hypothesis testing : t - test",
          "Fitted Values",
          "Hypothesis testing : ANOVA",
          "F - Statistics in Python",
          "R Square",
          "Answers"
        ],
        "Bonus": [
          "bonus"
        ]
      },
      "requirements": [
        "Understanding Statistics",
        "Beginner to Python"
      ],
      "description": "Welcome to the course \"Statistical Decision Making in Data Science with a Case Study in Python\"\nThis course is an introduction course where you will learn about the importance of Statistics and Machine Learning in Decision Making. I explained this course with a case study. We start with a problem statement and data then we build the machine learning model. Building a machine learning model is really not enough but getting a decision out of machine learning is the primary goal in Data Science. For that, we will use statistics.\n\n\nWhat you will Learn?\nUnderstand the Problem statement (Case Study on Big Mac Index with used in Forex Industry for Predicting Dollar value)\nAsking Statistical Question.\nLinear Regression (Least Square Regression)\nDevelop Least Square Regression in Python.\nUnderstand the Outputs\nMSE\nDegree of Freedom\nHypothesis testing\nt-test for coefficient significance\nF-test for model significance\nANOVA\nCorrelation\nR-Square\n\n\nYou will learn the approaches towards regression with case study.  First we start with understanding linear equation and the optimization function value sum of squared errors.  With that we find the values of the coefficient and makes least square regression. Then we starts building our linear regression in python.\nFor the model we build we necessary test like hypothesis testing.\nt-test for coefficient significance\nANOVA and F-test for model significance.\nAnd finally, we answer the question statically. Hope we are seeing you inside the course !!!",
      "target_audience": [
        "Beginner of Python Developer who want to learn Data Science",
        "Solving question related to linear regression"
      ]
    },
    {
      "title": "Learn Statistical Data Analysis with Python",
      "url": "https://www.udemy.com/course/learn-statistical-data-analysis-with-python/",
      "bio": "Perform Statistical Data Analysis Techniques with the Python Programming Language. Practice Notebook included.",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "You will need to have basic python programming proficiency.",
        "You will need a modern browser i.e. Google Chrome or Mozilla Firefox."
      ],
      "description": "By the end of this course, you will have achieved the following learning outcomes:\nI can explain and calculate the importance of measures of central tendency.\nI can explain and calculate the importance of measures of dispersion.\nI can identify the relative strengths and weaknesses of the measures of tendency.\nI can identify the relative strengths and weaknesses of the measures of dispersion.\nI can create and interpret a histogram, a bar chart, a box plot, and a frequency table.\nI can identify and describe scatter plots and line graphs to determine the relationships between two variables.\nI can calculate and interpret the Pearson correlation coefficient to determine the relationships between two variables.\nThese are some of the basics statistical data analysis techniques that you will get to use while working on data science projects. For example, in order to check for model assumptions while working on a predictive solution, you will need to apply the above techniques i.e. to test for normality of variables in a dataset, you can plot a histogram or a pair plot, to check for correlation, you can calculate the Pearson correlation coefficient etc.\nIn addition, these techniques will also be important while also working on data analysis projects where the creation of a descriptive analysis report will be a necessity.",
      "target_audience": [
        "This course is designed for professionals with an interest in getting hands-on experience with the respective data science techniques and tools."
      ]
    },
    {
      "title": "Baseball Data Wrangling with Vagrant, R, and Retrosheet",
      "url": "https://www.udemy.com/course/baseball2/",
      "bio": "Analytics with the Chadwick tools, dplyr, and ggplot.",
      "objectives": [],
      "course_content": {
        "Setting up Vagrant": [
          "Introduction",
          "Installing VirtualBox",
          "Installing Vagrant",
          "Creating a Project Folder",
          "Vagrant Up",
          "Directory Structure"
        ],
        "Installing and Working with the Chadwick Software": [
          "Downloading the Chadwick Software",
          "Installing the Chadwick Software",
          "The Retrosheet Files",
          "cwevent and cwgame"
        ],
        "Project #1: Mike Schmidt and Greg Luzinski": [
          "Data Extraction",
          "Reading our data into R",
          "The Result Column",
          "The Date Column",
          "The Date Column Part II",
          "The Player Data Frames",
          "ggplot Crash Course",
          "Cumulative Home Run Plots",
          "Colors and Legend"
        ],
        "Project #2: Dykstra, Murray, and Brett": [
          "Project Description",
          "Data Extraction",
          "Reading the data into R",
          "The Date Column",
          "The Result and AB Columns",
          "The Player Data Frames",
          "The Plots",
          "The Four-Hundred Line",
          "The Marchi/Albert Book and Course Wrap-Up"
        ]
      },
      "requirements": [
        "Students will need to have R and RStudio installed on their own computers."
      ],
      "description": "This course is for those interested in doing baseball analytics with the Retrosheet game-by-game and play-by-play data. The main tools for working with such data are in the Chadwick software. We install a virtual Linux machine, on which we will install the Chadwick software. We will then learn how to extract baseball data with the Chadwick software, how to further filter the data with dplyr in R, and how to plot our results with ggplot.\nFor the first part of the course, in which we install the virtual Linux machine and learn how to work with the Chadwick software, there are no prerequisites. To follow the second part of the course, knowledge of dplyr is necessary. This can be obtained through my course \"Baseball Database Queries with SQL and dplyr\".\nAt a relaxed pace, the course should take two to three weeks to complete.",
      "target_audience": [
        "This course is for those interested in doing baseball analytics with Retrosheet files.",
        "No background is needed for the first part of the course. A background in the R package dplyr is necessary to follow the second part of the course."
      ]
    },
    {
      "title": "AIエージェント入門【初心者向け】 -自律的に調査/判断/実行するAIを学ぼう！-",
      "url": "https://www.udemy.com/course/ai-agent/",
      "bio": "大規模言語モデル（LLM）を活用し、人の指示や周囲の状況を理解して自律的に判断・実行を行う「AIエージェント」について学ぶ講座です。AIエージェントを基礎から学び、実際の活用事例を通じて効率化や新たな価値創出の可能性を探ります。",
      "objectives": [
        "「AIエージェント」を基礎から学びます。",
        "AIエージェントを実際のビジネスシーンや創作活動で活用するスキルを習得します。",
        "AIエージェントの全体像、そしてその可能性について体験と共に学びます。",
        "AIエージェント向けのプロンプトの書き方を学びます。",
        "AIエージェントの実際の活用事例を通じて、効率化や新たな価値創出の 可能性を探ります。"
      ],
      "course_content": {},
      "requirements": [
        "2025年2月の環境で解説しています。最新の環境と異なる可能性があります。",
        "プログラミングや数学の知識、経験は不要です。",
        "人工知能、機械学習の技術的な知識は不要です。",
        "ローカル環境はWindowsでもMacでも大丈夫です。",
        "基本的に無料で受講可能ですが、課金が必要なサービスの解説も行います。"
      ],
      "description": "「AIエージェント入門」は、ChatGPTなどの大規模言語モデルを活用し、人の指示や周囲の状況を理解して自律的に判断・実行を行う「AIエージェント」について学ぶ講座です。\n定型的な業務の一部を自動化するだけでなく、複数のツールや情報源を連携させながらプロジェクト全体を管理・運用したり、意思決定のサポートや新しいアイデアの提案まで行えるAIエージェントは、今後様々なビジネスシーンや起業、クリエイティブな領域など様々な場面で活躍が期待されています。\n本講座では、AIエージェントを基礎から学び、実際の活用事例を通じて効率化や新たな価値創出の可能性を探ります。\n\n\n講座の内容は以下の通りです。\nSection1. AIエージェントの基礎\n- AIエージェントがどのように動き、何ができるのかを学びます。\nSection2. フレームワークと環境構築\n- AIエージェントを開発・運用するための主要フレームワークやツールについて学びます。\nSection3. プロンプトとツール設計\n- AIエージェントに適切な指示を与えるためのプロンプトの設計方法を習得します。\nSection4. AIエージェント活用の応用事例\n- ビジネスやクリエイティブの現場で活用する方法を学びます。\n\n\nこの講座を通して、AIエージェントの可能性を広く理解し、ビジネスの進化や新たなサービスの創出に活かすためのスキルを身につけましょう。",
      "target_audience": [
        "AIエージェントの概要を効率よく把握したい方。",
        "AIエージェントを業務や創作活動などで活用したい方。",
        "AIエージェントにより業務効率を向上したい方。",
        "AIエージェントの可能性を模索したい方。",
        "最新のAI技術をキャッチアップしたい方。"
      ]
    },
    {
      "title": "R für Data Science, Visualisierung und Machine Learning",
      "url": "https://www.udemy.com/course/r-data-science-machine-learning/",
      "bio": "Grundlagen in R und R-Studio für Data Science! Von Daten Analysen bis zum Maschinellen Lernen!",
      "objectives": [
        "Programmiere in R",
        "Nutze R zur Datenanalyse",
        "Erstelle Daten Visualisierungen",
        "Nutze R um mit CSV, Excel, SQL oder Web Scraping zu arbeiten",
        "Nutze R um Daten einfach zu analysieren",
        "Nutze R für Data Science",
        "Analysiere echte Daten am Beispiel",
        "R für Maschinellem Lernen (Machine Learning) zu nutzen",
        "Erhalte übersichtliche Merkblätter für Datenimport, Datentransformation, Visualisierung, Syntax, .. uvm."
      ],
      "course_content": {},
      "requirements": [
        "Zugang zu einem Computer mit Downloadrechten",
        "Mathematisches Grundwissen",
        "Dieser Kurs startet bei null"
      ],
      "description": "Data Scientist wurde von Glassdoor als Nummer 1 Job gerankt und erzielt laut Indeed einen überdurchschnittlichen Gehalt. Die Karriere im Bereich Data Science ist eine bereichernde Tätigkeit und erlaubt es euch an den größten und interessantesten Herausforderungen der Welt zu arbeiten.\nDieser Kurs richtet sich sowohl an Anfänger, die zum ersten Mal mit der Programmiersprache R in Berührung kommen, als auch für erfahrene Entwickler, die ihr Portfolio um Fähigkeiten in Richtung R, Data Sciene und Machine Learning ausbauen wollen!\n\n\n\"Perfekter Einstieg in die Sprache R. Zuvor hatte ich keine Kenntnis dieser Sprache. Gut gefällt mir, dass direkt auch Data Science Anwendungen inbegriffen sind, da ich diese beruflich brauche. Top! (★★★★★ D. Mika)\n\n\nDieser umfangreiche Kurs ist vergleichbar mit anderen Data Science Bootcamps die mehrere tausend Euro kosten. Das alles findest du in über 120 HD Video Lektionen und detaillierten Code Notebooks zu jeder Lektion. Dies macht diesen Kurs zum umfangreichsten Data Science Kurs mit R auf Udemy!\nWir werden gemeinsam lernen, wie man mit R programmiert, grandiose Visualisierungen erstellt und mit echten Daten und echte Data Science Fälle umgeht. Dazu verwenden wir R-Studio und das Jupyter Notebook mit R. Hier ist eine Übersicht einiger Themen:\nProgrammieren mit R\nFortgeschrittene Programmierung in R\nR Date Frames zur Lösung komplexer Aufgaben verwenden\nMit R Excel Datein bearbeiten\nWeb Scraping mit R\nR mit SQL verbinden\nGGPlot2 zur Visualisierung verwenden\nÜbersicht und Einsatz von DplyR und TidyR\nPlotly für interaktive Visualisierungen verwenden\nAnalysiere echte Daten an Beispielen\nMachine Learning mit R, einschließlich:\nLinear Regression\nK Nearest Neighbors\nK Means Clustering\nDecision Trees\nRandom Forests\nData Mining Twitter\nNeural Nets (Neuronale Netzwerke als Teil des Deep Learning)\nSupport Vectore Machines\nund vieles mehr!\nDu erhältst lebenslangen Zugang zu allen Lektionen und den passenden Notebooks zu den Lektionen!\n\n\n\"Der Kurs war sehr gut, um sowohl den Umgang mit R allgemein als auch die Materie des Kurses gut zu verstehen und anhand der Übungen auch selbst auszuprobieren und zu vertiefen.\" (★★★★★ D. Wesch)\n\n\nZusätzlich bietet dir dieser Kurs eine 30-tägige Geld-zurück-Garantie. Wenn du in irgendeiner Weise nicht zufrieden sein solltest, erhältst du dein Geld zurück. Und du darfst alle Notebooks als Dankeschön für das Ausprobieren dieses Kurses behalten!\n\n\nSchreibe dich im Kurs ein und werde noch heute ein Data Scientist!\n\n\n\n\n\n\n* Dieser Kurs erfordert, dass du dir das R-Paket herunterlädst. Wenn du Udemy-Business-Nutzer bist, kläre bitte vor dem Herunterladen mit deinem Arbeitgeber, ob die Installation erlaubt ist.",
      "target_audience": [
        "Jeden, der an Data Science interessiert ist",
        "Anfänger mit Data Science",
        "R Beginner"
      ]
    },
    {
      "title": "What Does a Data Labeler/Data Annotator Actually Do?",
      "url": "https://www.udemy.com/course/what-does-a-data-labeler-annotator-actually-do/",
      "bio": "The Role and Responsibilities of a Data Labeler/Data Annotator",
      "objectives": [],
      "course_content": {
        "Data Labelling": [
          "Data Labelling"
        ],
        "Data Annotation": [
          "Data Annotation"
        ],
        "Data labeling & annotation best tools": [
          "Data labeling & annotation best tools"
        ],
        "What does a data entry actually do ?": [
          "What does a data entry actually do ?"
        ],
        "The Unsung Heroes of AI : Data Labelers vs. Data Annotators": [
          "The Unsung Heroes of AI : Data Labelers vs. Data Annotators"
        ]
      },
      "requirements": [
        "An internet connexion and a PC"
      ],
      "description": "What Does a Data Labeler/Data Annotator Actually Do?\n(The Role and Responsibilities of a Data Labeler/Data Annotator)\nThis course provides a comprehensive overview of the role of a Data Labeler/Data Annotator, a crucial position in the fields of machine learning, artificial intelligence, and data science. Participants will explore the core responsibilities of data annotation professionals, including labeling, categorizing, and tagging data to train AI models. The course covers essential skills such as attention to detail, consistency, quality control, and proficiency with annotation tools and platforms.\nStudents will learn best practices for handling diverse data types (text, images, videos, and audio), ensuring data accuracy and integrity, and maintaining compliance with ethical AI guidelines and data privacy regulations. Practical exercises will focus on using industry-standard annotation tools, improving annotation speed and precision, and minimizing biases in labeled datasets.\nBy the end of this course, learners will understand the daily functions of a Data Labeler/Data Annotator and develop the necessary competencies to excel in this role. Whether you are looking to start a career in AI and data annotation or enhance your current skills, this course will equip you with the expertise to handle data effectively and contribute to AI-driven projects.\n\"Ready to become an essential part of the AI revolution? Enroll now and gain the skills to work efficiently, accurately, and confidently in the field of data annotation! Don’t miss this opportunity to build a strong foundation in AI data management—join us today!\"",
      "target_audience": [
        "Learners interested in Data Science, ML, and AI in general and Data Labelling and Annotation in particular"
      ]
    },
    {
      "title": "Machine Learning Nanodegree",
      "url": "https://www.udemy.com/course/machine-learning-arabic/",
      "bio": "أكبر كورس عربي لتعليم الألة والذكاء الأصطناعي لتأهيل مليون عالم بيانات عربي",
      "objectives": [
        "استخدم بايثون لعلوم البيانات والتعلم الآلي",
        "تنفيذ خوارزميات تعلم الآلة",
        "ريادة الأعمال بأستخدام الذكاء الاصطناعي",
        "كيفية صنع بيئة عمل أفتراضية للتأهيل لسوق العمل",
        "العقلية التحليلة",
        "NumPy for Numerical Data تعلم ال",
        "Pandas for Data Analysis تعلم ال",
        "SciKit-Learn for Machine Learning Tasks استخدام ال",
        "K-Means Clustering",
        "Logistic Regression",
        "Linear Regression",
        "Random Forest and Decision Trees",
        "Neural Networks",
        "Support Vector Machines"
      ],
      "course_content": {},
      "requirements": [
        "اللغة الأنجليزية",
        "لغة البرمجة بايثون (Python)",
        "أساسيات الجبر الخطي والمصفوفات",
        "أساسيات الأحصاء",
        "اساسيات التفاضل والتكامل",
        "Algorithms and data structures",
        "****..............Intermediate statistical knowledge:",
        "Populations, samples",
        "Mean, median, mode",
        "Standard error",
        "Variation, standard deviations",
        "Normal distribution",
        "Precision and accuracy",
        "Hypothesis testing",
        "Problem solving",
        "Confidence Interval, P-values, T-test, Statistical Significance",
        "Integrals",
        "Intermediate calculus and linear algebra mastery:",
        "Derivatives",
        "Series expansions",
        "Matrix operations through eigenvectors and eigenvalues"
      ],
      "description": "الجزء - 1\nNumpy و Pandas  معالجة البيانات و :\nAdvanced Numpy\nAdvanced Pandas\nData Preprocessing\nالجزء - 2\nRegression:\nSimple Linear Regression\nMultiple Linear Regression Intuition\nPolynomial Regression\nSupport Vector Regression (SVR)\nDecision Tree  Regression,\nRandom Forest Regression\nالجزء - 3\nClassification :\nالانحدار اللوجستي\nK-NN\nSVM\nKernel SVM\nNaive Bayes\nDecision Tree Classification\nRandom Forest Classification\nالجزء - 4\nClustering  :\nK-Means\nHierarchical Clustering\nالجزء - 5\nAssociation Rule Learning::\nApriori\nEclat\nالجزء - 6\nReinforcement Learning :\nUpper Confidence Bound\nThompson Sampling\nالجزء - 7\nNatural Language Processing (NLP) :\nBag-of-words model\nalgorithms for NLP\nالجزء - 8\nDeep Learning :\nالشبكات العصبية الاصطناعية، الشبكات العصبية التلافيفية\n(Deep Learning: Artificial Neural Networks, Convolutional Neural Networks)\nالجزء - 9\nDimensionality Reduction  :\nPCA\nKernel PCA\nLDA\nالجزء - 10\nModel Selection & Boosting :\nk-fold Cross Validation\nParameter Tuning,\nGrid Search\nXGBoost\nفضلا على ذلك، فإن الدورة مليئة بالتمارين العملية التي تستند إلى أمثلة واقعية. لذا لن تتعلم النظرية فحسب، بل ستحصل أيضًا على بعض التدريب العملي  و تتعلم كيفية بناء النماذج الخاصة بك.\nأيضا ستشتمل هذه الدورة التدريبية على قوالب بالبايثون و التي يمكنك تنزيلها واستخدامها في مشروعاتك الخاصة.\nسيكون لديك فهم أساسي للعديد من نماذج تعلم الألة\nعمل تحليل قوي وتوقعات دقيقة للبيانات\n\nReinforcement Learning  و NPL و ال Deep Learning التعامل مع موضوعات محددة مثل\n\nDimensionality Reduction التعامل مع التقنيات المتقدمة مثل\n\nسوف تتعلم كيف تختار النموذج الصحيح والمناسب لكل نوع من أنواع تعليم الألة  لكافة المشاكل المختلفة او متطلبات عملك\nقم ببناء مزيج من عدة نماذج مختلفة لتعليم الألة بالتعلم كيفية دمجها معا لحل المشاكل الصعبة",
      "target_audience": [
        "الأشخاص المهتمة بتعليم ألة والذكاء الاصطتناعي",
        "من عندهم خبره سابقة في تعلم أله ويريدون التعمق فيها",
        "خريجي الجامعات او حتى طلاب الثانوي ويريدون العمل بتعليم الألة او مجال الذكاء الأصطتناعي",
        "محللي البيانات والمحاسبين المالييين",
        "الأشخاص الذين يريدون الترقي في العمل وزيادة قيمة مضافة للشركة التي يعمل بها"
      ]
    },
    {
      "title": "Curso Completo de Microsoft Copilot Studio",
      "url": "https://www.udemy.com/course/curso-completo-de-microsoft-copilot-studio/",
      "bio": "Crea Agentes de IA en Microsoft Copilot Studio. Domina la IA Generativa y crea tu propio ChatGPT en Microsoft",
      "objectives": [
        "Crear agentes de IA usando Microsoft Copilot Studio",
        "Entrenar copilotos con datos estructurados y no estructurados",
        "Integrar copilotos con herramientas de la Microsoft Power Platform",
        "Configurar seguridad y sistemas de autenticación para los copilotos",
        "Desplegar agentes en sitios web, aplicaciones y otras plataformas",
        "Automatizar tareas repetitivas con copilotos especializados",
        "Monitorear y optimizar el rendimiento de los copilotos",
        "Personalizar respuestas y comportamiento de los copilotos",
        "Comprender cómo hacer uso de la IA Generativa en Microsoft Copilot Studio",
        "Obtener una base sólida sobre conceptos como las entidades, temas, variables, condiciones, etc."
      ],
      "course_content": {
        "Introducción": [
          "Objetivos del Curso",
          "Sobre Mi",
          "Instrucciones del Curso",
          "¿Qué es Microsoft Copilot Studio?",
          "¿Qué es la Microsoft Power Platform?",
          "Copilot Studio vs Copilot M365",
          "Fundamentos de la IA Generativa"
        ],
        "Inteligencia Artificial Generativa": [
          "IA Generativa",
          "Impacto de la tecnología",
          "Desarrollo de actividades",
          "Profesiones e IA Generativa",
          "IA Generativa en Marketing",
          "IA Generativa en TIC",
          "Casos de Uso",
          "Deep learning",
          "Foundational Models, LLMs y Fine-Tuning",
          "Prompts",
          "Prompt engineering"
        ],
        "Empezando con Microsoft Copilot Studio": [
          "Inicializando Copilot Studio",
          "Plantillas de Copilotos",
          "Diseñar Soluciones con Lenguaje Natural",
          "Gestión de Copilotos"
        ],
        "Crea tu Primer Copiloto en Microsoft Copilot Studio": [
          "Entornos de Power Platform",
          "Desplegar Copiloto",
          "Aislamiento de Datos",
          "Fuentes de Conocimiento",
          "Temas de un Copiloto",
          "Ejecutar Acciones",
          "Análisis de Rendimiento",
          "Canales de Distribución",
          "Configuración del Copiloto",
          "Parámetros de Configuración"
        ],
        "Bases de Datos del Agente": [
          "Conocimiento de un Copiloto",
          "Datos Externos",
          "Estructura de Información en Sitios Web",
          "Datos No Estructurados - Documentos Word",
          "Datos No Estructurados - Lectura de PDFs",
          "Datos No Estructurados - Archivos de Texto",
          "Datos No Estructurados - Presentaciones",
          "Acceso a Sitios SharePoint",
          "Tablas de Dataverse",
          "Contexto de Tablas",
          "Lectura de Datos Estructurados",
          "Orígenes de Datos Alternativos",
          "Archivos Descargables"
        ],
        "Temas y Comportamiento del Copiloto": [
          "Desencadenadores de Temas",
          "Combinación de Temas",
          "Crear Nuevos Temas",
          "Inteligencia Artificial y Comportamiento del Agente",
          "Análisis de Datos"
        ],
        "Entidades, Variables y Condiciones": [
          "Área de Diseño",
          "Cálculos y Fórmulas",
          "Recopilar Información del Usuario",
          "Variables de Entrada y Salida",
          "Bloques de Condición",
          "Tipos de Entidades",
          "Integración de Entidades",
          "Extracción de Valores",
          "Selección de Opciones",
          "Entidades Personalizadas",
          "Expresiones Regulares",
          "Variables de Sistema",
          "Administración de Variables",
          "Comportamiento del Usuario",
          "Redirección de Temas",
          "Variables Globales"
        ],
        "Estilo y Diseño del Copiloto": [
          "Conversaciones Enriquecidas",
          "Contenido Multimedia",
          "Insertar Videos",
          "Variaciones de Mensajes",
          "Respuestas Rápidas",
          "Tarjetas Básicas",
          "Uso de Tarjetas Adaptables",
          "Información de la Tarjeta",
          "Estructura y Formato de la Tarjeta",
          "Obtener Datos en Formulario",
          "Archivos Descargables"
        ],
        "Privacidad de los Datos y Gestión de Accesos": [
          "Sistemas de Autenticación",
          "Copilotos Públicos",
          "Estilo de Plantilla HTML",
          "Copiloto en Microsoft Teams",
          "Datos Privados en Agentes Públicos",
          "Control de Accesos",
          "Autenticación en Sitios Personalizados",
          "Privacidad de los Datos"
        ],
        "Acciones y Automatización de Procesos": [
          "Acciones",
          "Segmentación de Procesos",
          "Microsoft Power Automate",
          "Conectores y Aplicaciones",
          "Procesos en un Copiloto",
          "Integración con Power Automate",
          "Plantillas",
          "Conexiones",
          "Notificaciones Automáticas",
          "Múltiples Entradas",
          "Combinación de Aplicaciones",
          "Parámetros de Salida",
          "Archivos Descargables"
        ]
      },
      "requirements": [
        "No se requiere experiencia previa. En el curso aprenderás todo lo que necesitas saber para familiarizarte con Microsoft Copilot Studio y la Inteligencia Artificial Generativa"
      ],
      "description": "¿Qué objetivo tiene el curso?\nEl objetivo principal de este curso es proporcionarte el conocimiento necesario para dominar el uso de Microsoft Copilot Studio, permitiéndote crear agentes de IA que se adapten a las necesidades específicas de tu organización. Con estas habilidades, podrás delegar tareas repetitivas a la IA, enfocándote en acciones de mayor valor y así aumentar la productividad, eficiencia y creatividad en tus proyectos.\n\n\n¿Qué es Microsoft Copilot Studio?\nMicrosoft Copilot Studio es una herramienta de la Microsoft Power Platform que permite crear agentes conversacionales personalizados (copilotos) utilizando inteligencia artificial generativa. A diferencia de las herramientas generalistas, Copilot Studio te permite diseñar copilotos especializados para tareas y problemas específicos, integrándolos con diversos componentes de la Microsoft Power Platform como Power Automate, Dataverse o Power Apps, así como con otros servicios externos mediante conectores y APIs.\n\n\n¿En qué va a ayudarte este curso?\nCreación de agentes personalizados. Aprenderás a diseñar agentes que actúen como asistentes virtuales especializados, resolviendo necesidades concretas de tu organización y mejorando la eficiencia operativa. Estos agentes pueden ser entrenados con información específica de tu empresa, tanto con datos estructurados como no estructurados, siendo capaces de dar respuestas precisas y relevantes.\nIntegración de IA en procesos empresariales. Descubrirás cómo integrar la IA generativa en tus flujos de trabajo diarios, automatizando tareas y mejorando la toma de decisiones. Aprenderás a utilizar Microsoft Copilot Studio junto con herramientas como Power Automate, Dataverse o Power Apps, lo que te permitirá crear soluciones digitales completas y robustas que optimicen la operativa de tu negocio.\nSeguridad y gobernanza. Configurarás sistemas de autenticación y control de acceso para tus agentes, asegurando la privacidad y la seguridad de la información a través de políticas de prevención de pérdida de datos o controles de acceso basados en roles, garantizando que tus agentes conversacionales operen dentro de los estándares y normativas de seguridad de tu organización.\nGestión de Datos: Crearás agentes de IA capaces de acceder a información de documentos Word, PDF, Excel o tablas de bases de datos de múltiples plataformas, ya sea OneDrive, SharePoint, Dataverse, entre otros, ofreciendo así una experiencia muy completa y transversal a los usuarios.\nAnálisis de Rendimiento: Copilot Studio permite monitorear el rendimiento de los agentes, evaluar métricas clave y ajustar los flujos de conversación para optimizar su efectividad. Es clave realizar análisis de los agentes continuamente para certificar que están brindando el resultado adecuado a los usuarios.\nDespliegue multicanal: Conocerás cómo desplegar tus agentes en múltiples canales, como sitios web, aplicaciones móviles, o plataformas como Slack, Twilio y Microsoft Teams. Esta capacidad multicanal asegura que puedas interactuar con los usuarios en sus entornos favoritos, proporcionando una experiencia coherente y accesible.\nPersonalización avanzada: Aprenderás a personalizar tus agentes para que se comporten exactamente como necesitas, adaptándose a las particularidades de tu empresa. Podrás definir cómo deben responder a diferentes consultas, qué tono de comunicación usar, y cómo interactuar con los usuarios para proporcionar la mejor experiencia posible.\nEscalabilidad y adaptabilidad: Microsoft Copilot Studio permite crear soluciones escalables que se pueden adaptar a las necesidades cambiantes de tu organización. Aprenderás a diseñar agentes que puedan manejar desde consultas simples hasta tareas complejas, integrándose con sistemas empresariales avanzados y proporcionando soluciones flexibles y escalables.\n\n\nContenido y Descripción General\nEl curso es apto para todos los niveles. Empezaremos definiendo los conceptos básicos que giran en torno a Microsoft Copilot Studio y la IA Generativa. Poco a poco, iremos adentrándonos en la creación y personalización de agentes específicos para diversas necesidades empresariales, utilizando las capacidades de Copilot Studio.\nEs importante remarcar que para realizar este curso no es necesario disponer de conocimientos previos en temas relacionados con la inteligencia artificial, ni tener ningún background técnico específico. El programa formativo está diseñado para que cualquier profesional, independientemente de su sector, pueda adquirir las habilidades necesarias para diseñar sus propios agentes.\nTodo el proceso de aprendizaje gira en torno a la aplicación práctica de la IA Generativa y Microsoft Copilot Studio en el mundo empresarial. Te proporcionará una inmersión completa en la plataforma, abordando desde los conceptos fundamentales hasta la implementación de soluciones personalizadas en situaciones de negocio reales.\nAl finalizar el curso, estarás equipado con las habilidades y la confianza necesarias para utilizar Microsoft Copilot Studio de manera efectiva, creando agentes conversacionales que impulsen la innovación y eficiencia en tu organización.",
      "target_audience": [
        "Profesionales y estudiantes interesados en la IA Generativa y su aplicación en el entorno empresarial.",
        "Estudiantes que quieran destacar y convertirse en expertos en una habilidad cada vez más relevante en el mercado laboral.",
        "Todos quienes deseen descubrir cómo utilizar Microsoft Copilot Studio para innovar en sus organizaciones, empresas o proyectos en los que estén involucrados.",
        "Interesados en mejorar la productividad, rendimiento y eficiencia en sus proyectos creando agentes conversacionales inteligentes con Microsoft Copilot Studio"
      ]
    },
    {
      "title": "Pandas for Beginners: Learn Data Analysis with Python",
      "url": "https://www.udemy.com/course/free-data-analysis-course-python-pandas/",
      "bio": "Master basics of Pandas – Python’s top library for data analysis. Clean, filter, group, and analyze data with examples",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic understanding of Python (lists, variables, loops)",
        "No prior experience with Pandas or data analysis required",
        "A computer with Python + Pandas installed (installation covered)",
        "Willingness to learn through hands-on coding and real datasets"
      ],
      "description": "Looking to explore data analysis using Python? This Free Pandas Course is the ideal beginner’s gateway into the world of data manipulation and exploration using the most popular Python library: Pandas.\nWhether you're a student, aspiring data analyst, or future machine learning engineer, Pandas is a must-learn tool. It allows you to handle real datasets, clean them up, filter insights, and prepare them for modeling.\nIn this hands-on, beginner-friendly Pandas Data Analysis course, you’ll learn:\n\n\nWhat Pandas is and how it fits into the data science workflow\nHow to work with DataFrames and Series in Pandas\nTechniques to filter, clean, group, and sort data using Pandas\nReal-world operations like importing CSVs, handling missing data, and more in Pandas\nBasics of data aggregation, merging, reshaping, and slicing in Pandas\nAll topics are explained in simple plain English, supported with practicals and real world examples, and built for learners who want to gain practical, job-ready skills.\nWhy Take This Pandas Free Online Course?\n\n\nLearn a core library used in data science, ML, finance, and research\nReal-world, practical examples with datasets\nStructured content from zero to confident basics\n100% Free – no hidden upsell, just value\nLearn from an industry expert with real project exposure",
      "target_audience": [
        "Beginners in Python and data analysis",
        "Students or professionals exploring data-related roles like data Analytics",
        "Aspiring data scientists or data analysts",
        "Anyone working with Excel and ready to switch to Data Analytics using Python",
        "Developers who want to learn how to process data efficiently"
      ]
    },
    {
      "title": "Intelligence Artificielle de A à Z",
      "url": "https://www.udemy.com/course/intelligence-artificielle-az/",
      "bio": "Combinez la puissance des Data Sciences, du Machine Learning et du Deep Learning pour créer des IA redoutables !",
      "objectives": [
        "Créer une IA",
        "Comprendre la théorie sous-jacente à l'Intelligence Artificielle",
        "Faire une voiture autonome virtuelle",
        "Créer des IAs qui battent les humains à certains jeux",
        "Résoudre des problèmes réels à l'aide d'une IA",
        "Maîtriser l'art de la conception de modèles à IA",
        "Le Q-Learning",
        "Le Deep Q-Learning",
        "Le Deep Q-Learning à Convolution",
        "A3C"
      ],
      "course_content": {
        "Bienvenue dans Intelligence Artificielle de A à Z": [
          "Pourquoi l'IA ?",
          "Introduction",
          "Où se trouvent les fichiers de données et de code ?"
        ],
        "------ Chapitre 0 : Les Fondamentaux de l'Apprentissage par Renforcement -------": [
          "Bienvenue au chapitre 0 : Les Fondamentaux de l'Apprentissage par Renforcement"
        ],
        "Q-Learning : Intuition": [
          "Plan d'attaque",
          "Qu'est-ce que l'apprentissage par renforcement ?",
          "L'équation de Bellman",
          "Le \"plan\"",
          "Processus de décisions markoviens",
          "Stratégie vs Plan",
          "Ajoutons une \"pénalité de vie\"",
          "Q-Learning : Intuition",
          "Différence temporelle",
          "Q-Learning : Visualisation"
        ],
        "--------------- Chapitre 1 : Voiture autonome (Deep Q-Learning) ----------------": [
          "Bienvenue dans le chapitre 1 : Voiture autonome (Deep Q-Learning)"
        ],
        "Deep Q-Learning : Intuition": [
          "Plan d'attaque",
          "Deep Q-Learning : Comment ça marche ?",
          "Experience Replay",
          "Stratégies d'exploitation et d'exploration"
        ],
        "Installation pour le chapitre 1": [
          "Plan d'attaque",
          "Où se trouvent les fichiers de données et de code ?",
          "Instructions d'installation",
          "Démarrer avec Spyder"
        ],
        "Création de l'environnement": [
          "Voiture autonome - Étape 1",
          "Voiture autonome - Étape 2"
        ],
        "Créer votre première IA": [
          "Voiture autonome - Étape 3",
          "Voiture autonome - Étape 4",
          "Voiture autonome - Étape 5",
          "Voiture autonome - Étape 6",
          "Voiture autonome - Étape 7",
          "Voiture autonome - Étape 8",
          "Voiture autonome - Étape 9",
          "Voiture autonome - Étape 10",
          "Voiture autonome - Étape 11",
          "Voiture autonome - Étape 12",
          "Voiture autonome - Étape 13",
          "Voiture autonome - Étape 14",
          "Voiture autonome - Étape 15"
        ],
        "Playing with the AI": [
          "Voiture autonome - Niveau 1",
          "Voiture autonome - Niveau 2",
          "Voiture autonome - Niveau 3",
          "Voiture autonome - Niveau 4"
        ],
        "-------------- Chapitre 2 - Doom (Deep Q-Learning à Convolution) ---------------": [
          "Bienvenue au Chapitre 2 - Doom (Deep Q-Learning à Convolution)"
        ]
      },
      "requirements": [
        "Seulement un niveau lycée en mathématiques"
      ],
      "description": "Vous apprendrez les concepts clés de l'IA ainsi que développerez l'intuition qui vous permettra d'être rapidement capable de concevoir vos propres IA :\nComment démarrer la création d'une IA sans aucune connaissance préalable de code à l'aide de Python.\nComment utiliser OpenAI Gym pour apprendre le plus rapidement possible.\nComment optimiser vos IAs afin qu'elles atteignent leur potentiel maximal dans le monde réel.\nVoici ce que vous apprendrez dans ce cours :\n1. De parfait débutant à expert en Intelligence Artificielle - Vous apprendrez à créer des IA autonomes et capables d'évoluer dans de nombreux environnements différents. En partant d'une page blanche, nous coderons et expliquerons ensemble chaque ligne de code permettant de créer une IA. Ainsi, vous pourrez non seulement comprendre exactement comment elle fonctionne, mais en plus, vous serez capable de reproduire les exemples pour vos propres projets.\n2. Templates de code - Dans chaque chapitre, nous vous donnons accès à tous les templates de code que nous utilisons (et expliquons). Ainsi, lorsque vous créez un nouveau projet, pas la peine de redémarrer de zéro. Vous pouvez directement reprendre le template, l'adapter rapidement, et observer votre nouvelle IA !\n3. Vidéos intuitives - Plutôt que de développer des équations mathématiques sur des pages et des pages, nous apportons une attention toute particulière à l'intuition derrière la théorie afin que vous compreniez ce que vous faites et soyez capable d'être autonomes lorsque vous voudrez améliorer vos algorithmes.\n4. Applications concrètes - Dans ce cours, vous serez amenés à créer une IA non pas sur 1, ni 2, mais sur 3 jeux différents ! Dans chaque module, dont la complexité va aller en s'acroissant, l'IA que vous bâtirez sera capable d'apprendre comment le jeu fonctionne, et à force d'accumuler de l'expérience, va réussir à remplir les objectifs que vous lui donnerez. Ces applications vous permettront de vraiment mettre la main à la patte et de pratiquer vos connaissances nouvellement acquises.\n5. Aide directe - Nous nous sommes engagés à rendre ce cours le plus accessible possible afin d'enseigner l'IA à un maximum de personnes. C'est pourquoi, si vous avez besoin d'aide, nous serons là pour vous épauler. Posez une question sur le point bloquant que vous ne comprenez pas, et nous vous apporterons la solution.",
      "target_audience": [
        "Quiconque étant intéressé par l'Intelligence Artificielle, le Machine Learning ou le Deep Learning"
      ]
    },
    {
      "title": "Beyond Jupyter Notebooks",
      "url": "https://www.udemy.com/course/beyond-jupyter-notebooks/",
      "bio": "Build your own Data science platform with Docker & Python",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Watch Me First :-)"
        ],
        "Analyze your Data (Jupyter/Docker)": [
          "Introduction",
          "How to install Docker?",
          "Starting Jupyter",
          "Mapping Ports",
          "Running in detached Mode",
          "Facing a Persistence Problem",
          "Solving the Persistence Problem",
          "Course Project - Task",
          "Course Project - Solution"
        ],
        "Visualize your Data (Superset)": [
          "Introduction",
          "Starting Superset",
          "Prepare Data",
          "Charts and Dashboards",
          "Course Project - Task",
          "Course Project - Solution"
        ],
        "Store your structured Data (Postgres)": [
          "Introduction",
          "Starting Postgres",
          "Facing an Access Problem",
          "Docker-Compose (I/II)",
          "Docker-Compose (II/II)",
          "Solving the Access Problem",
          "Create a Custom User",
          "Course Project - Task",
          "Course Project - Solution"
        ],
        "Store your unstructured Data (Minio)": [
          "Introduction",
          "Starting Minio",
          "GUI Interaction",
          "Programmatic Interaction",
          "Course Project - Task",
          "Course Project - Solution"
        ],
        "Expose your Model (API-Star)": [
          "Introduction",
          "Starting API-Star",
          "API-Star and Docker",
          "Docker Enhancements",
          "Course Project - Task",
          "Course Project - Solution"
        ],
        "Automate your Analysis (Airflow)": [
          "Introduction",
          "Basic Concepts",
          "Starting Airflow",
          "DAG Creation",
          "Course Project - Task",
          "Course Project - Solution"
        ],
        "Wrap Up": [
          "Wrap Up",
          "BONUS: Cookiecutter Template"
        ]
      },
      "requirements": [
        "Minimal Python Knowledge",
        "Running Docker Installation",
        "Fun exploring new topics"
      ],
      "description": "Interactive notebooks like Jupyter have become more and more popular in the recent past and build the core of many data scientist’s workplace. Being accessed via web browser they allow scientists to easily structure their work by combining code and documentation. Yet notebooks often lead to isolated and disposable analysis artefacts. Keeping the computation inside those notebooks does not allow for convenient concurrent model training, model exposure or scheduled model retraining.\nThose issues can be addressed by taking advantage of recent developments in the discipline of software engineering. Over the past years containerization became the technology of choice for crafting and deploying applications. Building a data science platform that allows for easy access (via notebooks), flexibility and reproducibility (via containerization) combines the best of both worlds and addresses Data Scientist’s hidden needs.",
      "target_audience": [
        "Any level of data scientists that want to accelerate their capabilities",
        "Open Source Lover ❤️",
        "Pythonistas interested in Docker"
      ]
    },
    {
      "title": "Decision Trees Modeling & Supervised Learning using R",
      "url": "https://www.udemy.com/course/decision-trees-modeling-using-r/",
      "bio": "Learn Decision Trees Modeling using R in a simple way",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction to Decision Trees",
          "Route Node",
          "Route Node Continue"
        ],
        "Advertisement Dataset": [
          "Advertisement Dataset",
          "Data Preprocessing",
          "Feature Scaling",
          "Classifier - rpart",
          "Confusion Matrix"
        ],
        "Diabetes Dataset": [
          "Diabetes Dataset",
          "Plot Model-Classifier",
          "Prediction"
        ],
        "Caeseats Dataset": [
          "Caeseats Dataset",
          "Split",
          "Tree Package"
        ]
      },
      "requirements": [
        "No prior knowledge of machine learning required",
        "Basics of R"
      ],
      "description": "The web is full of apps that are driven by data. All the e-commerce apps and websites are based on data in the complete sense. There is database behind a web front end and middleware that talks to a number of other databases and data services. But the mere use of data is not what comprises of data science. A data application gets its value from data and in the process creates value for itself. This means that data science enables the creation of products that are based on data. This course includes learning decision tree modeling which are used by data scientists or people who inspire to be the data scientist. The tutorials will include the following;\nDecision Tree Theory\nImplementation using R Decision Tree Classification\nDecision Tree Regression\nDecision Tree in R is a machine-learning algorithm that can be a classification or regression tree analysis. The decision tree can be represented by graphical representation as a tree with leaves and branches structure. The leaves are generally the data points and branches are the condition to make decisions for the class of data set. Decision trees in R are considered as supervised Machine learning models as possible outcomes of the decision points are well defined for the data set. It is also known as the CART model or Classification and Regression Trees. There is a popular R package known as rpart which is used to create the decision trees in R.",
      "target_audience": [
        "Anyone who wants to learn about data and analytics",
        "Data Engineers, Analysts, Architects, Software Engineers, IT operations, Technical managers"
      ]
    },
    {
      "title": "Complete NumPy course - Data Science in Python",
      "url": "https://www.udemy.com/course/complete-numpy-course/",
      "bio": "Master Python's central data science and scientific computing library: NumPy",
      "objectives": [],
      "course_content": {
        "NumPy basics": [
          "Before we begin",
          "Our complete course catalog",
          "Connect with me on social media",
          "Introduction to NumPy",
          "Creating, indexing and slicing NumPy arrays",
          "Copying and editing NumPy arrays",
          "Stacking and restructuring NumPy arrays",
          "Arithmetic operations with NumPy arrays",
          "Operations with NumPy arrays of different shapes",
          "Concatenation, reversion and persistence of NumPy arrays"
        ],
        "NumPy applications": [
          "Applications of NumPy - Random number generation",
          "Applications of NumPy - Statistics",
          "Applications of NumPy - Linear algebra",
          "Applications of NumPy - Image manipulation",
          "Applications of NumPy  - Generating the Julia Set (Chaotic dynamical systems)"
        ],
        "Next steps": [
          "Connect with me on social media"
        ]
      },
      "requirements": [
        "Basic notions of Python programming."
      ],
      "description": "In this course you will learn to use the NumPy library fluently. NumPy is a numerical computation library extensively used in data science, machine learning and statistics. In fact, many other libraries in these fields rely on NumPy arrays to deliver their functionality efficiently. In the area of data science and machine learning we often work with tabular data, which can be represented very well by NumPy arrays. In the course you will learn how to work with n-dimensional arrays and how to manipulate them comfortably to solve complex tasks in different domains.\n\n\nNumPy processes matrix operations extremely efficiently, offering low execution time and memory usage. Its functionality is implemented in the C programming language: a very efficient compiled language. This functionality is executed from the Python interface with a simple declarative syntax.\n\n\nThe course is divided into 12 lessons:\n- Introduction to the NumPy library.\n- Creating, indexing and slicing NumPy arrays.\n- Copying and editing NumPy arrays.\n- Stacking and restructuring NumPy arrays.\n- Arithmetic operations with NumPy arrays.\n- Operations with NumPy arrays of different shapes.\n- Concatenation, reversion and persistence of NumPy arrays.\n- Applications of NumPy - Random number generation\n- Applications of NumPy - Statistics\n- Applications of NumPy - Linear algebra\n- Applications of NumPy - Image manipulation\n- Applications of NumPy  - Chaotic dynamical systems\n\n\nAt the end of the course, you will know how to create arrays using different methods, manipulate them and perform mathematical operations with them.",
      "target_audience": [
        "Data science students.",
        "Professionals of any scientific or engineering discipline.",
        "Programmers interested in machine learning.",
        "Data analysts interested in expanding their knowledge."
      ]
    },
    {
      "title": "AIエンジニアが教えるRとtidyverseによるデータの前処理講座",
      "url": "https://www.udemy.com/course/r-tidyverse-preprocess/",
      "bio": "データ分析プロジェクトで避けては通れないデータの前処理の効率的なやり方を現役ＡＩエンジニアの立場からわかりやすく説明します．このコースを受講することにより，データの前処理のほぼすべて（80%程度）に対応することができます．",
      "objectives": [
        "データ分析プロジェクトにおける前処理の重要性",
        "Pythonと比較したときのRのメリット",
        "前処理におけるRの基礎",
        "tidyverseによる前処理の具体的な方法"
      ],
      "course_content": {
        "⓪本コースの紹介": [
          "概要",
          "なぜPythonではなくRのtidyverseなのか？",
          "全体像"
        ],
        "①環境構築": [
          "概要"
        ],
        "①環境構築：Docker": [
          "補足：Docker利用停止に関するお願い"
        ],
        "①環境構築：RとRStudioのインストール": [
          "Rのインストール",
          "RStudioのインストール"
        ],
        "①環境構築：RStudio": [
          "RStudioってなに？？",
          "プロジェクトファイル",
          "パッケージ",
          ".Rprofile",
          "Global Options"
        ],
        "②baseR": [
          "概要"
        ],
        "②baseR：データ型": [
          "データ型ってなに？？",
          "数値型：integer, double",
          "文字列型：character",
          "文字列型：factor",
          "文字列型：order",
          "論理値型：logical",
          "まとめ"
        ],
        "②baseR：ベクトル": [
          "ベクトルってなに？？",
          "ベクトルの四則演算",
          "ベクトルのリサイクル",
          "ベクトルの要素抽出",
          "ベクトルの便利関数",
          "規則的なベクトルの作成",
          "まとめ"
        ],
        "②baseR：論理値ベクトルの処理": [
          "論理値ベクトルの処理ってなに？？",
          "論理値ベクトルの作成",
          "論理値ベクトルの計算",
          "まとめ"
        ],
        "②baseR：リスト": [
          "リストってなに？？",
          "リストの要素抽出",
          "名前付きリスト",
          "まとめ"
        ]
      },
      "requirements": [
        "プログラミング初心者でもOK！！",
        "インターネットが使用できるパソコン（OSはなんでもOKですが，Windows推奨）"
      ],
      "description": "※当コースでは当初，Dockerを導入しておりましたが，Dockerは無償でご利用いただける条件が変更され、環境によっては有料ライセンスが必要となるようになりました．\nつきましては，当コースにおける環境構築は，Dockerではなく，RとRStudioを直接ご自身のPCにインストールするよう，お願いいたします．\n本コースは，データの前処理に特化しています．\n近年はAIが話題になっており，実に様々な方々が興味を持っている分野だと思います．\nAIによる成果に焦点が当たる場合が多いですが，その成果が出る前には必ずデータの前処理をする必要があります．\nデータの前処理は，データの読み込み，加工，結合，可視化など実に様々な工程を何回も繰り返すことで，徐々に完成に近づいていきます．\nそのことが原因で，データの前処理には多大な時間（データ分析プロジェクト全体の70％～80％程度）が費やされるのです．\nそんな多大な時間が費やされるデータの前処理ですが，後工程の成果物につながる重要な工程ですので，できるだけ速く正確に実施する必要があります．\nさて，一般的にデータの前処理に使用されるプログラミング言語はPythonですが，前処理を速く正確に実施することはできるのでしょうか？\n実は，Pythonはもともとシステム開発用の言語なので，データの前処理には向いておりません．\n（実際に私もPythonやPandasでデータの前処理に挑んだこともありましたが，複雑すぎて挫折したことがあります．．．）\nそれではどうすればデータの前処理を速く正確に実施することができるのでしょうか？\n私が考えるベストソリューションは，データの前処理に特化したＲのパッケージ{tidyverse}を利用することです．\nPythonで複雑になりがちなコーディングもRの{tidyverse}を使用すると，とても簡潔かつ流れるようにコーディングすることができるのです！！\nよって本コースでは，{tidyverse}の使い方を詳細に説明します．\nまた{tidyverse}だけでなく，環境構築やRの基礎についても丁寧に説明しますので，今までプログラミングをしたことがない初心者でも全く問題ないです．\n講師が基礎から丁寧に解説しますので，気楽に一歩一歩着実に学習し，前処理マスターを目指しましょう！！\n\n\n★本コースの目的★\nデータの前処理のほぼすべて（80%程度）に対応すること\n\n\n★本コースの特徴★\nとにかく現場主義！！\nコーディングはリアルタイム形式！！\nコードだけでなく，イメージも！！\n\n\n★本コースの内容★\nコース紹介\n概要\nなぜPythonではなくRのtidyverseなのか\n全体像\n環境構築\nDocker\nRstudio\nbaseR（普通のR言語のこと）\nデータ型\nベクトル\n論理値ベクトルの処理\nリスト\nデータフレーム\n関数\ntidyverse\nパイプ処理（%>%）\n{tibble}データフレームの進化版\n{dplyr} データフレーム処理\n{tidyr} tidyデータ処理\n{ggplot2} 可視化\n{stringr} 文字列処理\n{readr} 入出力処理\n{forcats} ファクター処理\n{purrr} 繰り返し処理\n{lubridate} 時間処理\nNA処理\n総合演習",
      "target_audience": [
        "データサイエンスやAIに興味がある方",
        "ExcelやPythonのNumpy，Pandasで前処理に挫折した方",
        "baseRでの前処理に限界を感じた方",
        "tidyverseは知ってるけど，使い方がよくわからない方",
        "少しでも前処理を楽にしたい方"
      ]
    },
    {
      "title": "Python: Yapay Zeka ve Veri Bilimi için Python Programlama",
      "url": "https://www.udemy.com/course/veri-bilimine-giris/",
      "bio": "Makine Öğrenmesi ve Veri Bilimi için sıfırdan Python Programlama. 200'den fazla alıştırma ile uygulayarak öğrenin!",
      "objectives": [
        "Veri Bilimi ve Yapay Zeka dünyasına hızlı bir giriş yapacaksınız",
        "Sıfırdan ileri seviyeye Python programlama yetenekleri kazanacaksınız",
        "NumPy, Pandas, Seaborn, Spyder ve Jupyter Notebook kullanımını öğreneceksiniz",
        "Öğrenmenin en iyi yolu uygulama yapmaktır. 200'den fazla alıştırma ile uygulayarak öğreneceksiniz."
      ],
      "course_content": {
        "Yapay Zeka Çağına Hazır mısınız?": [
          "Giriş",
          "Yapay Zeka Çağına Hazır mısınız?",
          "Günlük Hayattan Örnekler",
          "Derin Öğrenme Uygulamaları",
          "Yapay Zeka Çağında Nasıl Hayatta Kalınır?",
          "Sizi Sizden Daha İyi Tanıyan Algoritmalar!",
          "Bilgilendirme",
          "Değerlendirme"
        ],
        "Veri Bilimine Giriş": [
          "Veri Bilimi ve Veri Bilimci",
          "Veriden Faydalı Bilgi Çıkarmak?",
          "Veri Bilimi Proje Döngüsü Adım 1: İş Anlayışı",
          "Veri Bilimi Proje Döngüsü Adım 2: Veriyi Anlamak",
          "Veri Bilimi Proje Döngüsü Adım 3: Verinin Hazırlanması",
          "Veri Bilimi Proje Döngüsü Adım 4: Modelleme",
          "Veri Bilimi Proje Döngüsü Adım 5: Değerlendirme",
          "Veri Bilimi Proje Döngüsü Adım 6: Kullanıma Sokma",
          "Veri Odaklı Meslekler",
          "Veri Bilimine Giriş Alıştırmalar - 1",
          "Veri Bilimine Giriş Alıştırmalar - 2"
        ],
        "Python Programlama: Giriş ve Temel Hareketler": [
          "Giriş",
          "Python'a Giriş",
          "Windows Kurulum İşlemleri",
          "Linux Kurulum İşlemleri",
          "MacOS Kurulum İşlemleri",
          "İlk Adım",
          "Spyder Kişiselleştirme",
          "Çalışma Dizini Ayarları",
          "Sayılar ve Karakter Dizilerine (Strings) Giriş",
          "Karakter Dizilerini (Strings) Yakından Tanıyalım",
          "Uzunluk Bilgisine Erişmek: len Metodu",
          "Büyük Küçük Harf Dönüşümü: upper & lower Methodları",
          "Karakter Değiştirme: replace Metodu",
          "Karakter Kırpma İşlemleri: strip Metodu",
          "Metodlara Genel Bakış",
          "Karakter Dizilerinde Alt Küme İşlemleri (Substrings)",
          "Değişkenler (Variables)",
          "Tip Dönüşümleri",
          "Kod Çıktısını Ekrana Yazdırmak: print",
          "Python Programlama Alıştırmalar - 1",
          "Python Programlama Alıştırmalar - 2",
          "Python Programlama Alıştırmalar - 3"
        ],
        "Python Programlama: Veri Yapıları (Data Types)": [
          "Liste Oluşturma",
          "Liste İçi Tip Sorgulama",
          "Liste Elemanlarına Erişmek",
          "Listelere Eleman Ekleme & Değiştirme & Silme",
          "Metodlar ile Eleman Ekleme & Silme: append & remove",
          "İndekse Göre Eleman Ekleme & Silme: insert & pop",
          "Diğer Liste Metodları",
          "Tuple (Demet) Oluşturma",
          "Tuple (Demet) Eleman İşlemleri",
          "Sözlük (Dictionary) Oluşturma",
          "Sözlük (Dictionary) Eleman Seçme İşlemleri",
          "Sözlük (Dictionary) Eleman Eklemek & Değiştirmek",
          "Set (Küme) Oluşturma",
          "Set (Küme) Eleman Ekleme & Çıkarma",
          "Setlerde Fark İşlemleri: difference & symmetric_difference",
          "Setlerde Kesişim & Birleşim İşlemleri: intersection & union",
          "Setlerde Sorgu İşlemleri",
          "Python Programlama Alıştırmalar - 4",
          "Python Programlama Alıştırmalar - 5",
          "Python Programlama Alıştırmalar - 6"
        ],
        "Python Programlama: Fonksiyonlar & Karar-Kontrol Yapıları & Döngüler": [
          "Fonksiyonlara Giriş ve Fonksiyon Okuryazarlığı",
          "Fonksiyon Nasıl Yazılır?",
          "Bilgi Notuyla Çıktı Üretmek",
          "İki Argümanlı Fonksiyon Tanımlamak",
          "Ön Tanımlı Argümanlar",
          "Ne Zaman Fonksiyon Yazılır?",
          "Fonksiyon Çıktılarını Girdi Olarak Kullanmak: return",
          "Local ve Global Değişkenler",
          "Local Etki Alanından Global Etki Alanını Değiştirmek",
          "True-False Sorgulamaları",
          "if",
          "else",
          "elif",
          "Uygulama: if ve input ile Kullanıcı Etkileşimli Program",
          "for Döngüsü",
          "for Döngüsü Örnek",
          "Döngü ve Fonksiyonların Birlikte Kullanımı",
          "if, for ve Fonksiyonların Birlikte Kullanımı",
          "break & continue",
          "while",
          "Python Programlama Alıştırmalar - 7",
          "Python Programlama Alıştırmalar - 8",
          "Python Programlama Alıştırmalar - 9"
        ],
        "Python Programlama: Nesne Yönelimli Programlama & Fonksiyonel Programlama": [
          "Sınıflara Giriş ve Sınıf (Class) Tanımlamak",
          "Sınıf (Class) Özellikleri",
          "Sınıf (Class) Örneklemesi",
          "Örnek Özellikleri",
          "Örnek Metodları",
          "Miras Yapıları",
          "Fonksiyonel Programlamaya Giriş",
          "Yan Etkisiz Fonksiyonlar Örnek 1",
          "Yan Etkisiz Fonksiyonlar Örnek 2",
          "İsimsiz Fonksiyonlar",
          "Vektörel Operasyonlar",
          "Map & Filter & Reduce",
          "Modül Oluşturmak",
          "Hatalar İstisnalar",
          "Python Programlama Alıştırmalar - 10",
          "Python Programlama Alıştırmalar - 11",
          "Python Programlama Alıştırmalar - 12"
        ],
        "NumPy (Numerical Python)": [
          "Giriş",
          "JupyterLab",
          "NumPy Giriş",
          "Neden NumPy?",
          "NumPy Array Oluşturmak",
          "NumPy Array Özellikleri",
          "Reshaping (Yeniden Şekillendirmek)",
          "Concantenation (Birleştirme)",
          "Splitting (Ayırma)",
          "Sorting (Sıralama)",
          "İndeks ile Elemanlara Erişmek",
          "Slicing (Array Alt Küme İşlemleri)",
          "Alt Küme Üzerinde İşlem Yapmak",
          "Fancy Index ile Elemanlara Erişmek",
          "Koşullu Eleman İşlemleri",
          "Matematiksel İşlemler",
          "NumPy ile İki Bilinmeyenli Denklem Çözümü",
          "NumPy Alıştırmalar - 1",
          "NumPy Alıştırmalar - 2",
          "NumPy Alıştırmalar - 3"
        ],
        "Pandas": [
          "Pandas Giriş",
          "Pandas Serisi Oluşturma",
          "Eleman İşlemleri",
          "Pandas DataFrame Oluşturma",
          "Pandas DataFrame Eleman İşlemleri",
          "Gözlem ve Değişken Seçimi",
          "Koşullu Eleman İşlemleri",
          "Birleştirme (Join) İşlemleri",
          "İleri Birleştirme İşlemleri",
          "Toplulaştırma ve Gruplama (Aggregation & Grouping)",
          "Gruplama İşlemleri",
          "Aggregate",
          "filter",
          "transform",
          "apply",
          "Pivot Tablolar",
          "Dış Kaynaklı Veri Okuma",
          "BONUS: Problem Çözme ve Döküman Okuma Kültürü",
          "Pandas Alıştırmalar - 1",
          "Pandas Alıştırmalar - 2",
          "Pandas Alıştırmalar - 3"
        ],
        "Seaborn": [
          "Giriş",
          "Büyük Resmi Görmek ve Veriyi Temsil Etmek",
          "Python'da Veri Görselleştirme",
          "Veriye İlk Bakış",
          "Veri Setinin Betimlenmesi",
          "Eksik Değerlerin İncelenmesi",
          "Kategorik Değişken Özetleri",
          "Sürekli Değişken Özetleri",
          "Veri Seti Hikayesi",
          "Sütun Grafiğin Oluşturulması",
          "Sütun Grafik Çaprazlamalar",
          "Histogram ve Yoğunluk Grafiğinin Oluşturulması",
          "Histogram ve Yoğunluk Çaprazlamalar",
          "Veri Seti Hikayesi",
          "Kutu Grafiğin Oluşturulması",
          "Kutu Grafik Çaprazlamalar",
          "Violin Grafiğin Oluşturulması",
          "Violin Çaprazlamalar",
          "Korelasyon Grafiğinin Oluşturulması",
          "Korelasyon Çaprazlamalar",
          "Doğrusal İlişkinin Gösterilmesi",
          "Scatter Plot Matrisi",
          "Isı Haritası (Heat Map)",
          "Veri Seti Hikayesi",
          "Çizgi Grafiğin Oluşturulması",
          "Basit Zaman Serisi Grafiği",
          "Seaborn Alıştırmalar - 1",
          "Seaborn Alıştırmalar - 2",
          "Seaborn Alıştırmalar - 3"
        ]
      },
      "requirements": [
        "Bir internet bağlantısı ve bilgisayar/telefon/tablet"
      ],
      "description": "Günümüzün en değerli (HBR 2012) mesleklerinden birisi olarak görülen Veri Bilimcilik ve çağımızın elektriği (Andrew NG) olarak görülen Yapay Zeka uygulamaları için gerekli olan programcılık yeteneklerini edineceğimiz eğitimimize hoş geldiniz.\nBu eğitim Python programlama eğitimidir! Veri Bilimi ve Yapay Zeka için gereken Python kütüphaneleri ele alınmaktadır!\nMatematik & İstatistik ve Bilgisayar Bilimlerinde yer alan teknik ve teorik yöntemlerin bir iş sektöründe uygulanmasıyla ortaya çıkan alana Veri Bilimi denir. Veri Bilimciler ise IT sektöründe en yüksek iş tatmini ve maaş skalasına sahip çalışanlardır. (Glassdoor 2019)\n\n\nBizler bu kursta Veri Bilimi ve Yapay Zeka konularına hızlı bir giriş yapıp sonrasında bu alanlarda çalışmak için gerekli olan Python Programlama yeteneklerimizi geliştireceğiz.\n\n\nÖğreneceklerinizi pekiştirmenin en verimli yolu alıştırma yapmaktır. 200'den fazla alıştırma ile bildiklerinizi pekiştirecek ve Veri Bilimi ve Yapay Zeka için gerekli olan programlama yeteneklerini kazanmış olacaksınız\n\n\nEle alınacak modüller:\nVeri Bilimi ve Yapay Zekaya Giriş\nPython Programlama\nNumPy\nPandas\nSeaborn\n\n\nKurs ile ilgili bazı yorumlar:\n\n\n★★★★★ \"Eğitmen cok net anlatiyor, böylece kafada hic soru işareti kalmiyor. Anlatirken aklıma gelen bir soru gelse bile, cevabı kesinlikle bir veya iki dakika sonrasinda vemis oluyor. Örnekleri ve soruları konulari pekiştirmek için çok faydalı. Ayrıca benim python ayarlarımdan kaynaklanan bir soruma da iyi ve hızlı bir çözüm yolu gösterdi.\" Berkan Acar\n\n\n★★★★★ \"Anlatimi cok ilginc ve gercek hayatla iliskilendiriyor. Ayni zamanda konuyu akdemik verilerle ve makalelerle destekliyor. Sıkmadan merak uyandırarak gerçek hayattaki uygulamalara değinerek çok mükemmel anlatmış. İhtizacımıy olan kısmı çok izi harmanlamış örneklerle pekiştiyor. Bölüm sonu testleri güzel olmuş konuyu anlayıp anlamama adına. Anlatımlarından dolayı Mustafa Vahit Beye çok teşekkür ediyorum. Veri Bilimcisi olmak isteyen herkese kesinlikle bu kursu tavsiye ederim.\" Okan Eray\n\n\n★★★★★ \"gerçekten samimiyetle hazırlanmış verimli bir kurs kesinlikle '2020 dünyasından bende haberdar olmak istiyorum' diyen herkesin izlemesi gereken bi çalışma\" Hüseyin Fırat\n\n\n★★★★★ \"Tüm katıldığım kurslarda puan vermeden önce kursun bitmesini beklerim ancak bu kursu o kadar beğendim ki.. İlk 2 bölüm su gibi aktı resmen :) anlatımın sadeliği ve konu içeriği çok iyi. Emeğinize sağlık. Teşekkürler.\" Hilal Çetin\n\n\n★★★★★ \"Mükemmel bir ilk adım kursu bu. Anlatım çok yalın ve açık. \"Veri Bilimi nedir?\" sorusunun cevabını ayrıntılarla, günlük hayattan örneklerle anlatıyor. Ufkunuzu açıyor. Veri Bilimi sizi heyecanlandıran bir başlık ise yolunuza ışık tutacaktır.\" Can Duyar\n\n\nHadi başlayalım!\n\n\nÖnemli Not: Bu eğitim daha önce ücretsiz olarak yayınlanan \"Veri Bilimine Giriş\" eğitimidir. 40K öğrenci sonrasında tüm içerikleri tamamen baştan hazırlanarak ve 3 saatten 16 saate çıkarılarak ücretliye çevrilmiştir.",
      "target_audience": [
        "Veri Bilimi ve Yapay Zeka dünyasına giriş yapmak isteyen herkes",
        "Sıfırdan Python programlama dilini öğrenmek isteyen herkes"
      ]
    },
    {
      "title": "Estadística para Data Science y análisis de negocios",
      "url": "https://www.udemy.com/course/estadistica-para-data-science-y-el-analisis-de-negocios/",
      "bio": "La estadística que necesitas en la oficina: inferencial y descriptiva, pruebas de hipótesis, análisis de regresión.",
      "objectives": [
        "Comprender los fundamentos de la estadística.",
        "Aprender a trabajar con diferentes tipos de datos.",
        "Graficar diferentes tipos de datos",
        "Calcular las medidas de tendencia central, asimetría y variabilidad.",
        "Calcular correlación y covarianza.",
        "Distinguir y trabajar con diferentes tipos de distribuciones.",
        "Estimar intervalos de confianza.",
        "Realizar pruebas de hipótesis.",
        "Tomar decisiones basadas en datos.",
        "Comprender conceptos necesarios para la ciencia de datos incluso con Python y R!"
      ],
      "course_content": {},
      "requirements": [
        "No se requiere ninguna experiencia. Empezaremos por lo básico y poco a poco iremos ampliando tus conocimientos. Todo está en el curso.",
        "Voluntad de aprender y practicar."
      ],
      "description": "Descripción\n¿Es la estadística una fuerza motriz en la industria en la que deseas entrar? ¿Quieres trabajar como Analista de Mercadeo, Analista de Inteligencia de Negocios, Analista de Datos o Científico de Datos?\nPues bien, ¡has venido al lugar correcto!\nEstadística para la ciencia de datos y análisis de negocios está aquí para ti, ¡con plantillas de Excel incluidas!\nEste es tu punto de partida. ¡Y es el inicio perfecto!\nEn poco tiempo, adquirirás las habilidades fundamentales que te permitirán entender análisis estadísticos complicados directamente aplicables a situaciones de la vida real. Hemos creado un curso que es:\n· Fácil de entender\n· Completo\n· Práctico\n· Al grano\n· Lleno de ejercicios y recursos\n· Orientado a los datos\n· Te introduce a la jerga científica estadística\n· Te enseña sobre la visualización de datos\n· Muestra los principales pilares de la investigación cuantitativa\nNo es ningún secreto que muchos de estos temas han sido explicados en línea. Miles de veces. Sin embargo, es casi imposible encontrar un programa estructurado que te dé una comprensión de por qué ciertas pruebas estadísticas se utilizan tan a menudo. Los paquetes de software modernos y los lenguajes de programación están automatizando la mayoría de estas actividades, pero este curso te da algo más valioso: habilidades de pensamiento crítico. Las computadoras y los lenguajes de programación son como los barcos en el mar. Son naves finas que te llevarán al destino deseado, pero depende de ti, el aspirante a científico de datos o analista de BI, navegar y apuntar en la dirección correcta.\nEnseñar es nuestra pasión\nTrabajamos duro durante más de cuatro meses para crear el mejor curso de Estadística posible y que te ofrezca el mayor valor. Queremos que tengas éxito, por lo que el curso pretende ser lo más atractivo posible. Animaciones de alta calidad, magníficos materiales de curso, preguntas de quiz, folletos y notas explicativas, así como un glosario con todos los nuevos términos que aprenderás, son sólo algunos de los beneficios que obtendrá al suscribirse.\n¿Qué hace a este curso diferente del resto de los cursos de Estadística?\nProducción de alta calidad - vídeo HD y animaciones (¡no es una colección de aburridas lecciones!)\nInstructor experto (Un matemático y estadístico experto que han competido a nivel internacional)\nCapacitación completa: cubriremos todos los temas y habilidades estadísticas importantes que necesitas para convertirte en un analista de mercadeo, un analista de inteligencia de negocios, un analista de datos o un científico de datos.\nExtensos estudios de caso que te ayudarán a reforzar todo lo que has aprendido\nExcelente soporte: si no entiendes un concepto o simplemente quieres enviarnos un mensaje, recibirás una respuesta en el plazo de 1 día laborable.\nDinámico: ¡no queremos hacerle perder el tiempo! El instructor establece un buen ritmo a lo largo de todo el curso.\n¿Por qué necesitas estas habilidades?\nSalario/Ingresos - las carreras en el campo de la ciencia de datos son algunas de las más populares en el mundo corporativo hoy en día. Y, dado que la mayoría de las empresas están empezando a darse cuenta de las ventajas de trabajar con los datos a su disposición, esta tendencia sólo continuará creciendo.\nPromociones - Si entiendes bien de estadística, podrás respaldar tus ideas de negocio con evidencia cuantitativa, lo cual es un camino fácil para el crecimiento de tu carrera.\nFuturo Seguro - como dijimos, la demanda de personas que entienden de números y datos, y pueden interpretarlos, está creciendo exponencialmente; probablemente has oído hablar del número de trabajos que se automatizarán pronto, ¿verdad? Bueno, las carreras de ciencias de datos son las que automatizan, no las que se automatizan.\nCrecimiento - este no es un trabajo aburrido. Cada día te enfrentarás a diferentes retos que pondrán a prueba tus habilidades actuales y te obligarán a aprender algo nuevo.\nPor favor, ten en cuenta que el curso viene con la garantía incondicional de devolución de tu dinero en 30 días de Udemy. ¿Y por qué no dar esa garantía? Estamos seguros de que este curso te proporcionará un gran valor.\n¡Comencemos a aprender juntos ahora!",
      "target_audience": [
        "Personas que quieren una carrera en Ciencia de Datos.",
        "Personas que quieren una carrera en Inteligencia de Negocios.",
        "Analistas de negocio.",
        "Ejecutivos de empresas.",
        "Individuos apasionados por los números y el análisis cuantitativo.",
        "Cualquiera que quiera aprender las sutilezas de la Estadística y cómo se utiliza en el mundo de los negocios.",
        "Personas que quieren comenzar a aprender estadística.",
        "Personas que quieren aprender los fundamentos de la estadística"
      ]
    },
    {
      "title": "Machine Learning Code Crash Course",
      "url": "https://www.udemy.com/course/machine-learning-coding-crash-course/",
      "bio": "Coding for Machine Learning Algorithms in Python with Variety of datasets.",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Maths behind Machine Learning"
      ],
      "description": "Unlock the full potential of machine learning with our comprehensive Advanced Machine Learning Coding in Python course. Designed for both beginners and experienced developers, this course will take you on a deep dive into the world of machine learning and equip you with the skills and knowledge needed to excel in this rapidly evolving field.\nIn this hands-on course, you'll embark on a journey that starts with the fundamentals of machine learning and gradually progresses to advanced techniques and real-world applications. You will gain proficiency in Python, the primary programming language of choice for machine learning, and learn how to harness powerful libraries such as sci-kit-learn to build and train complex models.\nI will guide you through a structured curriculum that covers topics like data preprocessing, feature engineering, model selection, hyperparameter tuning, and deploying machine learning models. You'll work on practical exercises, projects, and case studies, applying your newfound skills to solve real-world problems.\nBy the end of this course, you'll be well-prepared to tackle the most challenging machine-learning tasks, from image and text classification to regression and reinforcement learning. Whether you're aiming to advance your career, enhance your data analysis skills, or develop innovative machine-learning applications, this course provides the foundation you need. Join us and become a proficient machine-learning practitioner in Python!",
      "target_audience": [
        "Beginners in Machine Learning Coding"
      ]
    },
    {
      "title": "Linear Algebra for Machine Learning",
      "url": "https://www.udemy.com/course/linear-algebra-basics-for-machine-learning/",
      "bio": "Linear Algebra refresher for machine learning. Basics + Python implementation",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basics knowledge of linear algebra",
        "Basic knowledge of python"
      ],
      "description": "Linear Algebra is usually a prerequisite of machine learning. However, one doesn't need to know all the concepts in linear algebra.\n\n\nIn this course, I have compiled together all the important linear algebra concepts that are most frequently used in machine learning. This is the content I taught at Polytechnique Montreal as a refresher on linear algebra for machine learning. Understanding these concepts will help you navigate through an introductory course in machine learning.\n\n\nThis course is for you if\n- You have some knowledge of linear algebra.\n- You want to refresh some parts of linear algebra for machine learning.\n\n\nThis course is not for you if\n- You want to learn linear algebra from scratch.\n- You want to learn all important concepts in linear algebra.\n- You don’t know anything about python.\n\n\nPlease note that I do not cover all the topics in linear algebra. I only cover the topics that are most frequently used in the machine learning textbooks. If you want to learn linear algebra from scratch or master all the concepts, this course is not for you.\n\n\nIn this course, we cover the following topics\n- Vectors and Matrices\n- Matrix operations\n- Rank of a matrix\n- Solving linear equations using matrix\n- Change of basis\n- Eigenvalues and Eigenvectors\n- Diagonalization\n- Norms\n- Trace",
      "target_audience": [
        "Students who want to start their journey in machine learning and want to refresh the linear algebra topics needed for that."
      ]
    },
    {
      "title": "AIってなんだ。 イメージで理解しておきたい人のための超入門講座",
      "url": "https://www.udemy.com/course/ai-intro/",
      "bio": "1日で完結。機械学習とディープラーニングの基本的な仕組みとその限界を知る。",
      "objectives": [
        "人工知能という言葉が示すものを理解できる",
        "機械学習の目的と大まかな仕組みをイメージできる",
        "ディープラーニングの優位性と大まかな仕組みをイメージできる",
        "機械学習の限界について理解できる"
      ],
      "course_content": {
        "AIってなんなんだ": [
          "AIってなんなんだ",
          "機械学習の仕組み",
          "私達の目標",
          "リンゴとバナナを区別する",
          "誰に教えてもらうか、それが問題だ",
          "ゴミをいれたら、ゴミが出てくる",
          "もう一度リンゴとバナナを区別する",
          "人間の脳を真似すればいいんじゃないか",
          "あなたは機械ではありませんか？",
          "２つの大きな問題",
          "人間を超えるか"
        ],
        "【確認テスト】コースの理解度をチェックしよう": [
          "【確認テスト】コースの理解度をチェックしよう"
        ],
        "ここから先へ": [
          "ここから先へ"
        ]
      },
      "requirements": [
        "０から学習を始められます"
      ],
      "description": "「AIってなんだ」\nこのコースを通じて、数式や難しい概念を用いることなく、画像や図からイメージでAIを理解し、この疑問に答えることができるようになります。\nまた、AIについてこれから学習を始めたい方にも適した内容です。全体像を俯瞰してから具体的な学習に取り組むことで、効率的に学習することができるはずです。\n\n\nーーーーーーーーーーーーーーー\n\n\n>このコースの特徴\n数式や難しい概念を使わずに、図や写真から視覚的に理解できる。\n端的なコースで１日で完結する。\n単語の説明にとどまらず、背景を知ることができる。\n\n\n.コース修了時にイメージで理解できている単語\n機械学習・ディープラーニング・学習と推論・強いAI・弱いAI・フレーム問題・シンボルグラウンディング問題・チューリングテスト・ニューラルネットワーク・パーセプトロン・教師あり/なし学習…\n\n\n>このコースの受講をおすすめする人\nAIに何となく興味があるすべての人\n学習を始めたいが、何から手をつけていいのかわからない人\n機械学習やディープラーニングを中心に全体像を俯瞰したい人\n>逆に、このコースをおすすめできない人\n機械学習やディープラーニング等についてその理論を数学的に(厳密に)理解したい人\nPythonなどの言語を用いて実際にAIを構築したい人\n\n\n全く知識がない状態から始め、数時間でAIのイメージを掴むことができます。\nさぁ、思い立った今から始めましょう！\n\n\nーーーーーーーーーーーーーー\n\n\n>チームや組織におすすめする講座を探している方へ\nこのコースは、AIに対する過度な期待や、早まった批判などをなくすことを目的として構成されています。受講を通じて、AIという技術に対するイメージを揃えることができます。誰しもがAIを活用できるようになった今、その理解をチーム・組織内である程度揃えておくことは重要です。コースの最後には理解度を確認できる演習テストを含めています。ぜひご活用ください。\n\n\n>アップデート情報\n2024.2.20 - コース全体の理解度を確認できる確認テストを追加しました",
      "target_audience": [
        "AIに興味があるすべての人",
        "何から学べばよいかわからない人",
        "機械学習、ディープラーニングを中心として全体像を俯瞰したい人"
      ]
    },
    {
      "title": "Spark y Scala en Databricks: Big Data e ingeniería de datos",
      "url": "https://www.udemy.com/course/spark-y-scala-en-databricks-big-data-e-ingenieria-de-datos/",
      "bio": "Trabajo desde niveles básicos hasta avanzados con RDD y DataFrame.",
      "objectives": [
        "Conocer el funcionamiento y la estructura de Apache Spark",
        "Trabajar con RDDs de Spark desde niveles básicos hasta avanzados",
        "Trabajar con DataFrames en Spark mediante el API de SQL desde niveles básicos hasta avanzados",
        "Optimizar sus aplicaciones de Apache Spark para el manejo de grandes volúmenes de datos a través de DataFrames"
      ],
      "course_content": {
        "Introducción": [
          "Introducción al curso",
          "Introducción al Big Data",
          "Apache Spark"
        ],
        "Databricks": [
          "Databricks Community Edition",
          "¿Cómo crear una cuenta en Databricks Community Edition?",
          "Ambiente de trabajo en Databricks",
          "¿Cómo crear un cluster en Databricks?",
          "¿Cómo crear un notebook en Databricks?",
          "¿Cómo importar datos a Databricks?"
        ],
        "Introducción a los RDD en Spark": [
          "SparkSession",
          "¿Qué es un RDD?",
          "Diferentes formas de crear un RDD",
          "Ejercicios",
          "Resolución de los ejercicios"
        ],
        "Transformaciones de un RDD en Spark": [
          "Transformaciones en un RDD",
          "Función map",
          "Función flatMap",
          "Función filter",
          "Función coalesce",
          "Función repartition",
          "Función reduceByKey",
          "Ejercicios",
          "Resolución de los ejercicios"
        ],
        "Acciones sobre un RDD en Spark": [
          "Acciones en un RDD",
          "Función reduce",
          "Función count",
          "Función collect",
          "Funciones take, max y saveAsTextFile",
          "Ejercicios",
          "Resolución de los ejercicios"
        ],
        "Aspectos avanzados sobre RDD": [
          "Almacenamiento en caché",
          "Particionado",
          "Mezcla de datos(shuffling)",
          "Broadcast variables",
          "Acumuladores",
          "Ejercicios",
          "Resolución de los ejercicios"
        ],
        "Spark SQL": [
          "Introducción a Spark SQL",
          "Crear un DataFrame a partir de un RDD",
          "Crear un DataFrame a partir de fuentes de datos",
          "Crear un DataFrame a partir de fuentes de datos en la práctica",
          "Trabajo con columnas",
          "Funciones select y selectExpr",
          "Funciones filter y where",
          "Funciones distinct y dropDuplicates",
          "Funciones withColumn y withColumnRenamed",
          "Funciones drop, sample y randomSplit",
          "Trabajo con datos incorrectos o faltantes",
          "Acciones sobre un DataFrame en Spark SQL",
          "Escritura de DataFrames",
          "Persistencia de DataFrames",
          "Ejercicios",
          "Resolución de los ejercicios"
        ],
        "Spark SQL avanzado": [
          "Agregaciones",
          "Funciones count, countDistinct y approx_count_distinct",
          "Funciones min y max",
          "Funciones sum, sum_distinct y avg",
          "Agregación con agrupación",
          "Varias agregaciones por grupo",
          "Agregación con pivote",
          "Joins",
          "Expresión join y tipos de join",
          "Inner Join",
          "Left Outer Join",
          "Right Outer Join",
          "Full Outer Join",
          "Left Anti Join",
          "Left Semi Join",
          "Cross Join",
          "Manejo de nombres de columna duplicados",
          "Shuffle Hash Join y Broadcast Hash Join",
          "Ejercicios",
          "Resolución de los ejercicios"
        ],
        "Funciones en Spark SQL": [
          "Funciones de fecha y hora",
          "Funciones para trabajo con strings",
          "Funciones para trabajo con colecciones",
          "Funciones when, coalesce y lit",
          "Funciones definidas por el usuario UDF",
          "Funciones de ventana",
          "Catalyst Optimizer",
          "Ejercicios",
          "Resolución de los ejercicios"
        ],
        "Proyecto final": [
          "Proyecto final",
          "Resolución del proyecto final"
        ]
      },
      "requirements": [
        "Solo es deseable conocimientos básicos en Scala. Debido a que trabajaremos con Databricks no necesitamos de computadoras o laptops potentes ni de configuraciones complicadas para correr todos los ejemplos y resolver los ejercicios propuestos."
      ],
      "description": "Bienvenidos al curso Spark y Scala en Databricks: Big Data e ingeniería de datos.\n\n\nEn este curso aprenderás a trabajar con Scala-Spark en Databricks.\n\n\nSpark es esencialmente un sistema distribuido que fue diseñado para procesar un gran volumen de datos de manera eficiente y rápida. El objetivo de este curso es aprender a trabajar con las principales abstracciones de Spark, las cuales son los RDDs y los DataFrames.\n\n\nEl material que proponemos en el curso está pensado para todas las personas que bien deseen iniciarse en el trabajo con Spark, o que por otro lado, deseen consolidar los conocimientos que ya poseen sobre los temas que se abordarán. El curso está diseñado de una forma progresiva y gradual que le permitirá al estudiante entender y desarrollar las principales habilidades para el trabajo con RDDs y DataFrames en Spark. Además, se abordarán temas avanzados que le permitirán optimizar las aplicaciones de Spark que pueda construir en un futuro, o bien, mejorar aquellas que ya se tengan implementadas.\n\n\nEmpezamos el curso con una breve introducción al Big Data y a Spark. Posteriormente continuamos con una sección dedicada a explicar los aspectos fundamentales de Databricks Community Edition que necesitaremos para el desarrollo del curso. Una vez hayan concluido esta sección, estarán en condiciones de ejecutar notebooks de Scala-Spark en Databricks. Las siguientes secciones del curso están pensadas para entender y aplicar en la práctica las principales cuestiones sobre los RDDs y los DataFrames.\nEl temario procura en todo momento analizar temas específicos por cada lección, permitiéndole así al estudiante localizar rápidamente cualquier contenido de una forma rápida. La mayoría de las lecciones están conformadas por una parte teórica y otra práctica.\n\n\nMi nombre es José Miguel Moya y me desempeño actualmente como Ingeniero de Datos. Como parte de mi trabajo diario utilizo Spark con Python y Scala para obtener y procesar enormes cantidades de datos.\n\n\nTe invito a que veas el video de presentación del curso y las lecciones gratuitas.\n\n\nTe espero en el curso, tenga usted un cordial saludo.",
      "target_audience": [
        "Este curso va dirigido a todas aquellas personas que estén interesadas en introducirse al mundo del Big Data y al procesamiento de datos a través de Apache Spark. Es una muy buena oportunidad para aquellos que desean consolidar y ampliar sus conocimientos en el trabajo con RDDs y DataFrames en Spark debido a cómo se explican los conceptos y a las actividades prácticas presentadas."
      ]
    },
    {
      "title": "Python 3 数据分析 Data Science零基础完全入门",
      "url": "https://www.udemy.com/course/python-for-data-science/",
      "bio": "Numpy/Pandas/Matplotlib/Seaborn, 數據處理，分析，可視化，通過Python入門數據科學,機器學習",
      "objectives": [
        "如何使用 Jupyter Notebook",
        "如何使用numpy進行數據處理",
        "如何使用pandas進行數據處理和分析",
        "如何使用matplotlib進行數據可視化",
        "如何使用Seaborn進行數據可視化",
        "真實項目實戰"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "视频播放器设置"
        ],
        "Lab Environment Setup": [
          "Anaconda and Jupyter Introduction",
          "关于anaconda安装的更新补充",
          "2020更新的Anaconda安装演示（请一定要看这一集，不管您是Mac还是Windows）",
          "Anaconda/Jupyter Install Demo - Mac",
          "Anaconda/Jupyter Install Demo - Windows",
          "Anaconda/Jupyter Install demo - Linux",
          "Jupyter notebook Usage Demo",
          "Please make sure you have installed Anaconda and can start Jupyter notebook",
          "All Source code for this course"
        ],
        "Numpy Basic": [
          "Five Python Libs in Data Science",
          "Math Basic: Matrix Manipulation",
          "Array Introduction",
          "Array and Matrix Manipulation",
          "Array: input and output"
        ],
        "Pandas Basic": [
          "Series introduction",
          "DataFrame introduction",
          "The relationship between Series and DataFrame",
          "DataFrame I/O Operation",
          "DataFrame selecting and indexing",
          "Reindexing Series and DataFrame",
          "Talk about NaN"
        ],
        "Play with Data through Pandas": [
          "Series and DataFrame Mathematics",
          "Binning",
          "Groupby",
          "Aggregation",
          "Apply",
          "Clean Duplicated Data",
          "Time Series - The Basic",
          "Time Series - Sample and Plot"
        ],
        "Data Visualization - Matplotlib": [
          "Basic Plot Introduction",
          "Subplot",
          "Histogram and KDE Plot",
          "Series Plot",
          "DataFrame Plot",
          "Further learn Materials"
        ],
        "Data Visualization - Seaborn": [
          "Histogram and KDE Plot",
          "补充：关于seaborn版本更新导致的问题",
          "Bar and Heatmap Plot",
          "Plotting Style Configuration",
          "Plotting Color Setting",
          "Learn more"
        ],
        "Project Exericse": [
          "Stock Market Analysis - Getting Data",
          "Stock Market Analysis - History Analysis",
          "Stock Market Analysis - Relationship",
          "Summary"
        ]
      },
      "requirements": [
        "熟悉Python的基本語法",
        "有基本的數學基礎",
        "Computer的基本操作"
      ],
      "description": "根据Indeed，Glassdoor和Dice等职场网站所提供的信息，与去年同期相比，随着各行各业越来越依赖于数据进行决策，商业对数据科学家的需求也在继续扩大。\n事实上，对于我们可以从不同的学习路径进入到热门的职业中，如何选择一条合适的道路取决于你现在所处的职业阶段。除去数学和统计学的要求外，编程方面的专业技术同样是数据科学必须掌握的一项技能。\n\n\n数据科学家们需要处理复杂的问题，一般问题的解决过程都包括四个主要的步骤：数据收集和清洗、数据探索、数据建模和数据可视化。\nPython可以在整个流程中提供必要有效的处理工具，每一个步骤都有专门的工具库，对此我们会在下面做详细介绍。Python包含许多强大的统计学和数学工具，比如Pandas, Numpy, Matplotlib, SciPy, scikit-learn等等，另外还包括先进的深度学习工具，比如Tensorflow, PyBrain等等。\n此外，Python被认作是人工智能和机器学习的基础语言，而数据科学和人工智能又有着密切的交集。因此，Python被视为数据科学领域应用最广泛的语言并不会令人感到意外。\n\n\n本課程的學習需要有一定的Python基礎，建議您先學習一下我的“Python3面向對象編程”課程。\n\n本課程是Python Data Science的入門課程，是學習Python在Text Mining，Machine learning，deep learning中應用的基礎。\n本課程主要包含以下內容：\nanaconda和Jupyter的安裝\nnumpy入門\npandas入門\n使用pandas進行數據分析處理\n數據可視化之Matplotlib\n數據可視化之Seaborn\n數據分析項目實戰\n数据科学是通过组织，处理和分析数据从大量不同的数据中获取知识和洞察力的过程。 它涉及许多不同的学科，如数学和统计建模，从数据源提取数据和应用数据可视化技术。 通常还涉及处理大数据技术以收集结构化和非结构化数据。",
      "target_audience": [
        "對data science感興趣并想從事相關職業",
        "對使用Python進行數據處理分析感興趣"
      ]
    },
    {
      "title": "ChatGPT para Desenvolvedores: Aprenda e crie soluções com IA",
      "url": "https://www.udemy.com/course/chatgpt-para-desenvolvedores-aprenda-e-crie-solucoes-com-ia/",
      "bio": "Aprenda a utilizar Chat GPT para agilizar tarefas no desenvolvimento, como: Front-end, back-end e também banco de dados!",
      "objectives": [
        "Fundamentos de ChatGPT",
        "Fundamentos de Prompt Engineering",
        "Como utilizar o Chat GPT para aprender programação",
        "Prompts para utilizar o Chat GPT com Front end",
        "Prompts para utilizar o Chat GPT com Back end",
        "Prompts para utilizar o Chat GPT com Bancos de dados (SQL e NoSQL)"
      ],
      "course_content": {
        "Introdução": [
          "Introdução",
          "Apresentação do curso",
          "Criando conta no Chat GPT e primeiro prompt",
          "Como o ChatGPT funciona",
          "Como o Chat GPT pode ajudar desenvolvedores",
          "Limitações do ChatGPT",
          "Slides do curso",
          "Repositório do curso",
          "Comunidade alunos da Hora de Codar",
          "Conclusão da seção",
          "Como aprender programação mais rápido e ter sucesso na carreira",
          "Teste para saber sua dificuldade com programação"
        ],
        "Aprendendo com Chat GPT": [
          "Introdução",
          "Linguagens suportadas pelo ChatGPT",
          "Aprendendo conceitos",
          "Estruturas de programação",
          "Entendendo Orientação a Objetos",
          "Design Patterns",
          "Explorando estruturas de dados e algoritmos",
          "Gerando exercícios",
          "Explicando códigos",
          "Conclusão da seção"
        ],
        "Chat GPT para Front-end": [
          "Introdução da seção",
          "Gerando HTML",
          "Adicionando semântica ao HTML",
          "Depuração de HTML",
          "Adicionando acessibilidade ao HTML",
          "Sugestões de CSS",
          "Componentes com HTML e CSS",
          "Correção de CSS",
          "Soluções com HTML, CSS e JavaScript",
          "Criando funções em JavaScript",
          "Identificando a causa de erros",
          "Criando componentes com React JS",
          "Sugestões de libs e frameworks",
          "Conclusão da seção",
          "O que falta para você ser um Programador?",
          "Você ainda não é Dev Júnior?"
        ],
        "Chat GPT para Back-end": [
          "Introdução da seção",
          "Estrutura base de API",
          "Conversão para TypeScript",
          "Conversão de tecnologias",
          "Gerando dados de teste",
          "Corrigindo brechas de segurança",
          "Gerando validações",
          "Integrações com serviços",
          "Criando documentação e comentários",
          "Sugestão de stacks",
          "Refatorar código",
          "Testes unitários (TDD)",
          "Criando Regex (Expressões regulares)",
          "Conclusão da seção"
        ],
        "Chat GPT para Banco de Dados (SQL e NoSQL)": [
          "Introdução da seção",
          "Criando tabelas",
          "Gerando dados para tabelas",
          "Análise de consultas complexas (queries)",
          "Explorando queries longas",
          "Conversão de query (SQL para NoSQL)",
          "Conversão de SQL para ORM",
          "Conclusão da seção",
          "Criando Soluções com ChatGPT para Problemas Reais"
        ],
        "Conclusão e próximos passos": [
          "Fechamento do curso"
        ]
      },
      "requirements": [
        "Não é necessário ter conhecimento em ChatGPT",
        "Conhecimentos dos fundamentos da programação não são obrigatórios, mas serão bem aproveitados"
      ],
      "description": "Seja bem-vindo ao curso de ChatGPT para desenvolvedores! Este curso tem como objetivo fazer você programar melhor e mais rápido através da ferramenta de Inteligência Artificial ChatGPT.\n\n\nO curso é dividido em duas partes:\n\n\nComo aprender programação com Chat GPT;\nAplicação de Chat GPT em diversas áreas da programação;\n\n\nNa primeira, onde você entenderá como evoluir na programação com o GPT, teremos uma imersão em diversos prompts voltados ao aprendizado. Ensinando você a entender desde conceitos complexos até a gerar exercícios para praticar a sua linguagem favorita.\n\n\nA segunda parte, que é onde vamos aplicar o ChatGPT em uma grande quantidade de tecnologias, é destinada tanto para desenvolvedores iniciantes como também para quem está trabalhando como dev.\n\n\nIsso você terá acesso a prompts, utilizando técnicas avançadas de prompt engineering, para as seguintes áreas:\n\n\nFront-end;\nBack-end;\ne banco de dados;\n\n\nAo longo das aulas refinaremos cada vez mais os promtps no Chat GPT, fazendo com que a resposta recebida seja cada vez mais eficaz e realmente cumpra o que estamos pedindo a IA.\n\n\nNão há necessidade de conhecimento prévio em Chat GPT, você terá aulas sobre: criação da conta, primeiro prompt, apresentação da interface e muito mais! Todo conhecimento prévio em programação será aproveitado durante o curso, mas você aprenderá muito aqui também\n\n\nPor que um programador ou desenvolvedor deve aprender ChatGPT?\n\n\nAprender a utilizar o ChatGPT proporciona múltiplas vantagens para programadores e desenvolvedores. Uma delas é o poder de criar experiências personalizadas para os usuários, através da geração de conteúdo dinâmico e interativo, aprimorando a interface e a usabilidade dos sistemas.\n\n\nAlém disso, o ChatGPT é um ativo poderoso para a melhoria da eficiência operacional. Dessa forma, é programado para atender automaticamente a perguntas frequentes, realizar tarefas de triagem de suporte técnico ou realizar processos que normalmente exigiriam intervenção humana, reduzindo significativamente o tempo de resposta e os custos operacionais.\n\n\nA capacidade de aprender com os padrões também torna o ChatGPT uma ferramenta útil para a análise de grandes conjuntos de dados, auxiliando na identificação de tendências e padrões que podem passar despercebidos para os humanos.\n\n\nCom a crescente integração da inteligência artificial (IA) em todos os aspectos do ambiente corporativo, o domínio de tecnologias como o ChatGPT é cada vez mais valorizado. Esse conhecimento permite que os desenvolvedores criem soluções mais eficientes e intuitivas, resultando em maior produtividade no ambiente corporativo: produzindo mais em menos tempo.\n\n\nDessa forma, torna-se indispensável a familiarização e o aprofundamento em IA para programadores e desenvolvedores que desejam manter-se atualizados e prontos para enfrentar os desafios do futuro no mercado corporativo.\n\n\nA IA não é apenas uma tendência, mas uma necessidade crescente para manter a relevância e a eficiência em um mundo cada vez mais digital e conectado.\n\n\nComo o ChatGPT pode ser usado no dia a dia do desenvolvedor e programador?\n\n\nO ChatGPT está se tornando uma ferramenta indispensável no dia a dia de programadores e desenvolvedores. Uma das suas principais funcionalidades é o processamento de linguagem natural, permitindo a criação de assistentes virtuais capazes de realizar diversas tarefas, desde responder a perguntas até realizar operações mais complexas, como auxiliar na depuração de código.\n\n\nEsse recurso pode automatizar processos e economizar tempo. Afinal, é possível que seja treinado para analisar código-fonte, identificar erros ou bugs e até mesmo sugerir soluções. Assim, o desenvolvedor pode concentrar-se em tarefas mais estratégicas, aumentando a produtividade.\n\n\nAlém disso, o ChatGPT pode ser usado para simular interações com usuários, ajudando a testar e aprimorar a experiência do usuário em um software ou aplicativo. Essa é uma parte crucial do processo de desenvolvimento que pode ser significativamente acelerada pelo uso da inteligência artificial.\n\n\nAprender a utilizar e aprimorar o ChatGPT proporciona um up a mais no dia a dia, pois permite ao programador desenvolver soluções mais eficientes, intuitivas e personalizadas. Quanto maior o domínio sobre essa tecnologia, mais o profissional será capaz de extrair o máximo de seu potencial, tornando-se mais ágil e eficaz em suas tarefas diárias.\n\n\nQuais são as vantagens do curso completo de ChatGPT online com certificado?\n\n\nOs cursos da Hora de Codar oferecem uma série de vantagens. Primeiro, o acesso vitalício permite que você aprenda no seu ritmo, sem preocupações com prazos. Os certificados fornecidos validam suas habilidades e aprimoram seu currículo. A comunidade de programadores é uma plataforma inestimável para troca de ideias e soluções, criando um ambiente colaborativo de aprendizado.\n\n\nAo participar do curso você terá acesso a um grupo de alunos para trocar experiências.\n\n\nOs cursos são continuamente atualizados com novos conteúdos, garantindo que você esteja sempre em dia com as últimas tendências e tecnologias em programação. Portanto, são um investimento inteligente para qualquer aspirante a programador e também para quem já atua como dev.\n\n\nEstá preparado para desenvolver aplicações mais rápido e solucionar problemas complexos facilmente? Então te vejo no curso de ChatGPT para devs!",
      "target_audience": [
        "Desenvolvedores",
        "Programadores",
        "Engenheiros de Software",
        "Quem deseja aprender Chat GPT"
      ]
    },
    {
      "title": "Data Science: Intro To Deep Learning With Python In 2025",
      "url": "https://www.udemy.com/course/complete-deep-learning-course-with-python/",
      "bio": "Learn to create Deep Learning Algorithms in Python",
      "objectives": [],
      "course_content": {
        "Module -1": [
          "Intro to deep learning",
          "All you need to know about dataset",
          "Binary classification",
          "Forward Propagation",
          "Activation Functions",
          "BackPropagation",
          "Gradient descent",
          "Building blocks Of DNN",
          "DNN from scratch",
          "MNIST Fashion in TF framework",
          "Download the code files"
        ]
      },
      "requirements": [
        "Some prior coding experience with python is required."
      ],
      "description": "Neural networks are a family of machine learning algorithms that are generating a lot of excitement. They are a technique that is inspired by how the neurons in our brains function. They are based on a simple idea: given certain parameters, it is possible to combine them in order to predict a certain result. For example, if you know the number of pixels in an image, there are ways of knowing which number is written in the image. The data that enters passes through various “ layers” in which a series of adjusted learning rules are applied by a weighted function. After passing through the last layer, the results are compared with the “correct” results, and the parameters are adjusted.\nAlthough the algorithms and the learning process in general are complex, one the network has learned, it can freeze the various weights and function in a memory or execution mode. Google uses these types of algorithms, for example, for image searches.\nThere is no single definition for the meaning of Deep Learning. In general, when we talk of Deep Learning, we are referring to a group of Machine Learning algorithms based on neural networks that, as we have seen, are characterized by cascade data processing. The entrance signal passes through the various stages, and in each one, they are subjected to a non-linear transformation. This helps to extract and transform the variable according to the determined parameters (weights or boundaries). There isn’t an established limit for the number of stages that a neural network must contain to be considered Deep Learning. However, it is thought that Deep Learning arose in the 80’s, using a model which had 5 or 6 layers. It was (and is) called the neocognitron and was created by the Japanese researcher Kunihiki Fukushima. Neural networks are very effective in identifying patterns.\nAn example worth highlighting of the application of Deep Learning is the project carried out by Google and the Universities of Stanford and Massachusetts. It aimed to improve the natural language processing techniques of a type of AI called Recurrent Neural Network Language Model (RNNLM). It’s used for automatic translations and creating subtitles, among other thing. Basically, it builds up phrases word by words, basing each word on the previous one and in this way, it can even write poems.\nModule 1\n1. Introduction to Deep Learning and TensorFlow\n2. Basics of Neural Networks\n3. Designing a shallow neural network (Scratch and python) (Project)\n4. Deeper neural network using TensorFlow. (Project)",
      "target_audience": [
        "Beginners In Python",
        "Beginners In Deep Learning",
        "Beginners In Machine Learning"
      ]
    },
    {
      "title": "Machine Learning e Data Science com Python de A a Z",
      "url": "https://www.udemy.com/course/machine-learning-e-data-science-com-python-y/",
      "bio": "Aprenda as técnicas que o mundo real exige e torne-se um profissional competitivo na área de Inteligência Artificial!",
      "objectives": [
        "Tenha uma base teórica sólida sobre os principais algoritmos de Machine Learning",
        "Utilize as bibliotecas numpy, sklearn e pandas aplicado em Data Science e Machine Learning",
        "Aprenda na teoria e na prática sobre os algoritmos de Machine Learning para classificação, regressão, regras de associação e agrupamento",
        "Aprenda a realizar o pré-processamento em bases de dados com pandas e sklearn",
        "Entenda como funcionam as técnicas para redução de dimensionalidade PCA, KernelPCA e LDA",
        "Aprenda a avaliar os algoritmos de Machine Learning usando estatística",
        "Aprenda a detectar outliers em bases de dados",
        "Crie classificadores para prever se uma pessoa pagará ou não pagará um empréstimo",
        "Crie classificadores para prever o salário de uma pessoa baseado em seus dados pessoais",
        "Aprenda como vários conceitos da estatística estão relacionados com Machine Learning, como por exemplo: correlação, covariância, testes de hipóteses e distribuição normal",
        "Implemente algoritmos de regressão para prever o preço de casas e o preço de planos de saúde",
        "Implemente o algoritmo Apriori para descobrir regras de associação em bases de dados de mercados",
        "Agrupe os clientes de um banco utilizando dados sobre o uso do cartão de crédito",
        "Utilize aprendizagem por reforço para ensinar um simulador de táxi interagir com o passageiro",
        "Implemente um classificador de sentimentos em textos utilizando a biblioteca spaCy",
        "Implemente detecção de faces, reconhecimento facial e rastreamento de objetos da área da Visão Computacional",
        "Implemente técnicas de seleção de atributos para descobrir os campos mais importantes em uma base de dados",
        "Implemente técnicas de subamostragem e sobreamostragem para tratar bases de dados desbalanceadas",
        "Utilize o algoritmo ARIMA e o Facebook Prophet para previsões futuras dos número de passageiros em empresas aéreas e também a previsão do número de visitantes em uma página web"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre Machine Learning e Ciência de Dados",
          "Machine learning",
          "Por que aprender machine learning?",
          "Terminologia",
          "Métodos preditivos",
          "Métodos descritivos",
          "Tipos aprendizagem de máquina",
          "Classificação",
          "Recursos para download",
          "Referências complementares",
          "Terminologia básica"
        ],
        "----- Parte 1 - Classificação -----": [
          "Introdução a Parte 1 - Classificação"
        ],
        "Pré-processamento dos dados": [
          "Introdução",
          "Tipos de variáveis",
          "Importação das bibliotecas",
          "Base de dados de crédito",
          "Visualização dos dados",
          "Tratamento de valores inconsistentes",
          "Tratamento de valores faltantes",
          "Divisão entre previsores e classe",
          "Escalonamento dos atributos",
          "Base de dados do censo",
          "Visualização dos dados",
          "Divisão entre previsores e classe",
          "Atributos categóricos - LabelEncoder",
          "Atributos categóricos - OneHotEncoder",
          "Escalonamento dos atributos",
          "Introdução a avaliação de algoritmos",
          "Bases de treinamento e teste",
          "Salvar as bases de dados",
          "EXERCÍCIO",
          "Solução",
          "Referências complementares",
          "Teoria tipos de variáveis"
        ],
        "Aprendizagem bayesiana": [
          "Introdução",
          "Naïve bayes - introdução",
          "Naïve bayes - aprendizagem",
          "Naïve bayes - classificação",
          "Naïve bayes - correção laplaciana",
          "Naïve bayes - mais conceitos",
          "Naïve bayes - base risco de crédito",
          "Naïve bayes - base crédito",
          "Naïve bayes - base censo",
          "EXERCÍCIO",
          "Solução",
          "Referências complementares",
          "Teoria Naïve Bayes"
        ],
        "Aprendizagem por árvores de decisão": [
          "Introdução",
          "Árvores de decisão - introdução",
          "Árvores de decisão - aprendizagem I",
          "Árvores de decisão - aprendizagem II",
          "Árvores de decisão - mais conceitos",
          "Árvores de decisão - base risco crédito",
          "Árvores de decisão - base crédito",
          "Árvores de decisão - base censo",
          "Random forest (floresta randômica)",
          "Random forest - base crédito",
          "Random forest - base censo",
          "EXERCÍCIO",
          "Solução",
          "Referências complementares",
          "Teoria árvores de decisão"
        ],
        "Aprendizagem por regras": [
          "Introdução",
          "Indução de regras - introdução",
          "Indução de regras - algoritmo OneR I",
          "Indução de regras - algoritmo OneR II",
          "Indução de regras - algoritmo PRISM",
          "Indução de regras - base risco crédito",
          "Indução de regras - base crédito",
          "Instalação do Orange",
          "Indução de regras - base censo + interface gráfica",
          "Indução de regras - base crédito + interface gráfica",
          "Classificador base (majority learner) - base crédito",
          "Classificador base (majority learner) - base censo",
          "EXERCÍCIO",
          "Solução",
          "Referências complementares",
          "Teoria aprendizagem por regras"
        ],
        "Aprendizagem baseada em instâncias": [
          "Introdução",
          "kNN - introdução",
          "kNN - cálculo de distância",
          "kNN - classificação",
          "kNN - normalização e padronização",
          "kNN - base crédito",
          "kNN - base censo",
          "EXERCÍCIO",
          "Solução",
          "Referências complementares",
          "Teoria aprendizagem baseada em instâncias"
        ],
        "Regressão logística": [
          "Introdução",
          "Regressão logística - introdução",
          "Regressão logística - aprendizagem",
          "Regressão logística - classificação",
          "Regressão logística - base risco de crédito",
          "Regressão logística - base crédito",
          "Regressão logística - base censo",
          "EXERCÍCIO",
          "Solução",
          "Referências complementares",
          "Teoria regressão logística"
        ],
        "Máquinas de vetores de suporte (SVM)": [
          "Introdução",
          "SVM - introdução",
          "SVM - aprendizagem",
          "SVM - linear x não linear",
          "SVM - base crédito",
          "SVM - base censo",
          "EXERCÍCIO",
          "Solução",
          "Referências complementares",
          "Teoria SVM"
        ],
        "Redes neurais artificiais": [
          "Introdução",
          "Introdução a redes neurais",
          "Fundamentos biológicos",
          "Neurônio artificial",
          "Perceptron de uma camada",
          "Tipos de aprendizagem de máquina",
          "Ajuste dos pesos I",
          "Ajuste dos pesos II",
          "Introdução a redes neurais multicamada",
          "Funções de ativação",
          "Redes multicamada - ativação camada oculta I",
          "Redes multicamada - ativação camada oculta II",
          "Redes multicamada - ativação camada saída",
          "Redes multicamada - cálculo do erro",
          "Redes multicamada - pesos e erros",
          "Redes multicamada - descida do gradiente",
          "Redes multicamada - delta camada saída",
          "Redes multicamada - delta camada oculta",
          "Redes multicamada - backpropagation, taxa de aprendizagem e momento",
          "Redes multicamada - ajuste dos pesos com backpropagation I",
          "Redes multicamada - ajuste dos pesos com backpropagation II",
          "Redes multicamada - bias e erro",
          "Redes multicamada - saída com mais neurônios e Deep learning",
          "Redes multicamada - camadas ocultas",
          "Redes multicamada - camada saída categórica",
          "Redes multicamada - descida do gradiente estocástico",
          "Redes neurais - base crédito",
          "Redes neurais - base censo",
          "EXERCÍCIO",
          "Solução",
          "Referências complementares",
          "Teoria redes neurais artificiais"
        ]
      },
      "requirements": [
        "O único pré-requisito obrigatório é conhecimento sobre lógica de programação, principalmente estruturas condicionais e de repetição",
        "Conhecimentos em Python não são obrigatórios! Existe um anexo no curso com aulas básicas sobre essa linguagem de programação"
      ],
      "description": "A área de Machine Learning (Aprendizagem de Máquina) e Data Science (Ciência de Dados) é atualmente um dos campos de trabalho mais relevantes da Inteligência Artificial, sendo responsável pela utilização de algoritmos inteligentes que tem a função de fazer com que os computadores aprendam por meio de bases de dados. O mercado de trabalho de Machine Learning nos Estados Unidos e em vários países da Europa está em grande ascensão; e a previsão é que no Brasil cada vez mais esse tipo de profissional seja requisitado! Inclusive alguns estudos apontam que o conhecimento dessa área será em breve um pré-requisito para os profissionais de Tecnologia da Informação! E dentro deste contexto está o cientista de dados, que já foi classificado como o trabalho \"número 1\" por vários veículos da mídia internacional.\nE para levar você até essa área, neste curso completo você terá uma visão teórica e prática sobre os principais algoritmos de machine learning utilizando o Python, que é uma das linguagens de programação mais relevantes nesta área. Além disso, vamos utilizar o Google Colab para a implementação dos exemplos, o que facilita o entendimento dos conceitos e evita problemas de instalação de bibliotecas. Este curso é considerado de A à Z pelo fato de apresentar desde os conceitos mais básicos até técnicas mais avançadas, de modo que ao final você terá todas as ferramentas necessárias para construir soluções complexas e que podem ser aplicadas em problemas do dia-a-dia das empresas! Você aprenderá tudo passo a passo, ou seja, tanto a teoria quanto a prática de cada algoritmo! O curso é dividido em cinco partes principais:\nClassificação - pré-processamento dos dados, naïve bayes, árvores de decisão, random forest, regras, regressão logística, máquinas de vetores de suporte (SVM), redes neurais artificiais, avaliação de algoritmos e combinação e rejeição de classificadores\nRegressão - regressão linear simples e múltipla, polinomial, árvores de decisão, random forest, vetores de suporte (SVR) e redes neurais artificiais\nRegras de associação - algoritmos Apriori e ECLAT\nAgrupamento - k-means, agrupamento hierárquico e DBSCAN\nTópicos complementares - redução de dimensionalidade com PCA, KernelPCA e LDA, deteção de outliers, aprendizagem por reforço, processamento de linguagem natural, visão computacional, tratamento de dados desbalanceados, seleção de atributos e previsão de séries temporais\nVeja abaixo alguns dos estudos de caso que serão implementados:\nCriação de gráficos dinâmicos para visualização de bases de dados\nPrevisão se uma pessoa pagará um empréstimo baseado no histórico financeiro\nPrevisão do salário de uma pessoa levando em consideração seus dados pessoais\nPrevisão do preço do plano de saúde baseado na idade\nPrevisão do preço de casas considerando\nGeração de regras de associação para compor prateleiras de mercado\nAgrupamento de clientes simulares considerando dados sobre o uso do cartão de crédito\nSimulação de um táxi utilizando aprendizagem por reforço\nClassificação de sentimentos em textos com processamento de linguagem natural\nDetecção de faces, reconhecimento facial e rastreamento de objetos\nPrevisão de visitas a websites com séries temporais\nEste curso tem o objetivo de servir como um referencial de consulta sobre as técnicas abordadas, por isso ele procura cobrir a maior parte dos assuntos que envolvem machine learning. Este curso pode ser categorizado para todos os níveis, pois pode servir de base para consulta para alunos mais experientes no assunto e também um ótimo guia para quem está iniciando na área!",
      "target_audience": [
        "Pessoas interessadas em iniciar seus estudos em aprendizagem de máquina e Ciência de Dados",
        "Pessoas que queiram iniciar carreira na área de Data Science ou Machine Learning",
        "Empreendedores que queiram aplicar aprendizagem de máquina em projetos comerciais",
        "Analistas de dados que queiram aumentar seu conhecimento na área de aprendizagem de máquina",
        "Empresários que desejam criar soluções eficientes para problemas reais em suas empresas",
        "Alunos de graduação e pós-graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial",
        "Iniciantes na área de Inteligência Artificial"
      ]
    },
    {
      "title": "Python : Cours complet pour débutant (Manipulation de Data)",
      "url": "https://www.udemy.com/course/python-datascience/",
      "bio": "Apprendre les fondamentaux du langage Python, appliqués sur des cas de manipulation de données (objectif Data Science)",
      "objectives": [
        "Maîtriser les bases de Python",
        "Ouvrir et lire des fichiers dans des listes",
        "Créer des boucles pour parcourir chaque élément d'un dataset",
        "Récupérer et filtrer les éléments qui vous intéressent à l'aide du slicing et des opérateurs booléens",
        "Utiliser des dictionnaires pour compter des éléments dans un dataset",
        "Créer des fonctions et automatiser nos recherches",
        "Utiliser modules et classes en Python",
        "Simplifier le code à l'aide de la compréhension de liste",
        "Travailler avec les expressions régulières pour extraire tout type de mots / textes bien ciblés dans un dataset",
        "Travailler avec les dates pour analyser les tendances par mois ou année",
        "Traiter des cas concrets issus du monde réel sur des projets",
        "De façon générale, déceler des tendances en explorant et analysant un dataset"
      ],
      "course_content": {
        "Introduction": [
          "Message de bienvenue :)",
          "Installation Python + Jupyter Notebook",
          "Présentation Jupyter Notebook"
        ],
        "Python: les Bases": [
          "Les variables : Créer et afficher une variable",
          "Les variables : Types de donnée",
          "Opérations avec des variables",
          "Création d'une liste",
          "Récupérer une valeur dans une liste",
          "Retourner la longueur d'une liste",
          "Récupérer un morceau de liste (slicing)"
        ],
        "Fichiers & Boucles": [
          "Objectifs",
          "Ouvrir et lire un fichier",
          "Séparation des éléments",
          "Les Boucles FOR",
          "Liste de listes",
          "Récupérer et afficher des éléments d'une liste de listes",
          "Challenge"
        ],
        "Booléens et conditions IF": [
          "Objectifs",
          "Booléens et Opérateurs",
          "La Condition IF",
          "Condition IF & Boucle FOR"
        ],
        "Challenge 1": [
          "En quoi consiste ce challenge?",
          "Lire le fichier dans une liste",
          "Solution \"Lire le fichier dans une liste\"",
          "Convertir la liste en liste de listes",
          "Solution \"Convertir les liste en liste de listes\"",
          "Convertir les valeurs numériques",
          "Solution \"Convertir les valeurs numériques\"",
          "Filtrer la liste",
          "Solution \"Filtrer la liste\""
        ],
        "Opérations sur les listes": [
          "Objectifs et dataset",
          "Supprimer l'en-tête",
          "Vérifier la présence d'un élément en une ligne"
        ],
        "Les Dictionnaires": [
          "Qu'est ce qu'un dictionnaire?",
          "La Condition IF / ELSE",
          "Compter les éléments d'une liste et présenter les résultats dans un dictionnaire"
        ],
        "Introduction aux Fonctions": [
          "Objectifs",
          "Tokenization du vocabulaire",
          "Remplacement des caractères spéciaux",
          "Les fonctions",
          "Changer les lettres majuscules en minuscule",
          "Arguments multiples",
          "Tokenization du fichier texte",
          "Trouver les mots mal orthographiés"
        ],
        "Fonctions : Améliorations et Erreurs": [
          "Fonctions avec plusieurs chemins d'exécution",
          "Les Arguments",
          "Pratique : Amélioration de notre correcteur orthographique",
          "Types d'erreurs"
        ],
        "Projet : Explorer les naissances aux US depuis 2000": [
          "Introduction au dataset",
          "Convertir la data en liste de listes",
          "Calculer le nombre de naissances par mois",
          "Calculer le nombre de naissances par jour de la semaine",
          "Créer une fonction plus générale"
        ]
      },
      "requirements": [
        "Aucune notion en Python nécessaire. Les débutants Python sont les bienvenus :)",
        "Tout ce dont vous avez besoin : un PC, un Mac ou Linux."
      ],
      "description": "Ce cours traite du langage de programmation Python pour débuter dans le monde de la Data Science (ou science des données). Tous les concepts clés et basiques de Python y sont détaillés et expliqués à l'aide d'exemples concrets.\nSi vous souhaitez vous initier à la manipulation de données en apprenant pour cela les fondamentaux de Python, ce cours est fait pour vous ! C'est une bonne porte d'entrée à la Data Science.\nCe cours est constitué des points théoriques nécessaires pour commencer à stocker et manipuler des données depuis des datasets (jeux de données). Toutes les syntaxes de base de Python y sont présentes, mis en scène autour du domaine de la Data Science.\nCe cours est également rempli d'exercices, de défis, de projets et d'opportunités pour que vous puissiez pratiquer directement ce que vous apprenez. Appliquez ce que vous apprenez à l'aide de datasets adaptés à chaque étape de votre apprentissage.\nCe cours en quelques chiffres :\n7 heures de vidéos\n14 chapitres théoriques avec de nombreux training\n2 challenges pour valider vos acquis\n2 projets complets pour commencer un portfolio sur github\n10 datasets divers et variés à explorer\n\n\n\nPourquoi apprendre Python?\nConstamment classé une des compétences les plus demandées par les employeurs, Python est un moyen fantastique de stimuler votre développement professionnel que ce soit du côté data scientist, data analyst ou même développeur.\n\n\nPourquoi ce cours est différent ?\nCe ne sera pas un cours où vous allez regarder mon code pendant des heures. C'est un parcours où l'on pratique, on met les mains dans le code et on manipule soi même pendant des heures de la data. Mon but c'est surtout de vous donner l'envie d'investiguer à fond des datasets.\nUne fois ce cours terminé, vous pourrez interagir avec n'importe quel fichier csv, déceler des tendances sur tout sujet qui vous intéresse :)\nAlors, faisons ça ! Inscrivez-vous aujourd'hui et commencez à apprendre les bases de Python avec des exemples concrets de manipulation de données !",
      "target_audience": [
        "Débutant en programmation souhaitant apprendre les bases de Python de A à Z",
        "Analystes souhaitant découvrir Python appliqué à la datascience",
        "Toute personne souhaitant commencer une carrière en Data Science",
        "Toute personne curieuse de la Data Science"
      ]
    },
    {
      "title": "AI4ALL: Natural Language Processing",
      "url": "https://www.udemy.com/course/ai4all-natural-language-processing/",
      "bio": "Learn the basics of Recurrent Neural Networks and Sequential models.",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Theory of Recurrent Neural Network",
          "Embedding Layer",
          "Dropout",
          "Long Short Term Memory",
          "IMDB Movie Review Dataset",
          "Data Processing",
          "Simple Recurrent Neural Network Models",
          "LSTM Models Using Tensorflow",
          "Evaluations and Interpretations"
        ]
      },
      "requirements": [
        "No prior programming experience needed. You will learn directly in this class."
      ],
      "description": "This course is created to follow up with the AI4ALL initiatives. The course presents coding materials at a pre-college level and introduces a fundamental pipeline for a neural network model. The course is designed for the first-time learners and the audience who only want to get a taste of a machine learning project but still uncertain whether this is the career path. We will not bored you with the unnecessary component and we will directly take you through a list of topics that are fundamental for industry practitioners and researchers to design their customized neural network model.  The course follows the previous sequence where we covered Artificial Neural Network models, Convolutional Neural Network models, and Image-to-Image models. This course focuses on some of the most basical tasks in language problems and develop the basic intuition of Recurrent Neural Networks.\n\n\nThis instructor team is lead by Ivy League graduate students and we have had 3+ years coaching high school students. We have seen all the ups and downs. Moreover, we want to share these roadblocks with you. This course is designed for beginner students at pre-college level who just want to have a quick taste of what AI is about and efficiently build a quick Github package to showcase some technical skills. We have other longer courses for more advanced students. However, we welcome anybody to take this course!",
      "target_audience": [
        "Pre-college level students interested in recurrent neural network models"
      ]
    },
    {
      "title": "Deep Learning, Neuronale Netze und TensorFlow in Python",
      "url": "https://www.udemy.com/course/deep-learning-grundlagen-neuronale-netzwerke-mit-tensorflow/",
      "bio": "Trainiere Deep-Learning-Modelle für Bilder & Texte – mit TensorFlow 2, CNNs, LSTM und Natural Language Processing.",
      "objectives": [
        "Verwende die neuste TensorFlow Version",
        "Verstehe wie Neuronale Netzwerke wirklich funktionieren",
        "Implementiere die Grundbausteine eines NN nach",
        "Meistere das Deep Learning (DNN, CNN, RNN etc.)",
        "Das Erkennen von handgeschriebenen Zahlen",
        "Das Erkennen von Hunden und Katzen auf Bildern",
        "Das Erkennen von Objekten (Autos, Flugzeuge etc.) auf Bildern",
        "Die Klassifizierung von echten Filmbewertungen",
        "Eine KI für ein Videospiel programmieren"
      ],
      "course_content": {
        "Kapitel 1: Einleitung": [
          "Einleitung in den Kurs",
          "Die Software im Kurs",
          "Informationen zu der Software",
          "Windows: MSVC Compiler Installieren",
          "Windows: Installation von Anaconda",
          "Linux: Installation von Anaconda",
          "Mac: Installation von Anaconda",
          "Handbuch des Kurses",
          "Materialien des Kurses",
          "Die Einrichtung des Environments",
          "CPU: Python Pakete Installieren",
          "GPU: Python Pakete Installieren",
          "Visual Studio Code einrichten",
          "Visual Studio Code verwenden",
          "Wichtig: Installation vom Utils Modul"
        ],
        "Kapitel 2 : Python Zusatzwissen": [
          "Vorwort",
          "Main Funktion",
          "Numpy und Matplotlib Einführung",
          "Slices und Weiteres zu Numpy",
          "f-Strings und Type Annotations",
          "Python"
        ],
        "Kapitel 3: Machine Learning Einführung": [
          "Was ist das Machine Learning?",
          "Intuition: Regression und Klassifikation",
          "Vorwort zu dem fiktiven Datensatz",
          "Intuition: Regression im Code",
          "Intuition: Klassifikation im Code",
          "Im Detail: Supervised Learning",
          "Supervised Learning: Lineare Regression",
          "Vorwort: Programmier-Aufgaben",
          "Musterlösung: Fehlerfunktionen Programmieren",
          "Lineare Regression"
        ],
        "Kapitel 4: Neuronale Netzwerke": [
          "Was sind Neuronale Netzwerke",
          "Was sind Neuronale Netzwerke",
          "Was ist das Perzeptron",
          "Intuition: Was ist das Perzeptron",
          "Eigenschaften des Perzeptron",
          "Aktivierungsfunktionen",
          "Das Bias Neuron",
          "Aktivierungsfunktion und Bias Neuron",
          "Wie lernt das Neuronale Netzwerk - Teil 1",
          "Intuition: Gradient Descent - Teil 1",
          "Vorwort: Die Rosenbrock Funktion",
          "Intuition: Gradient Descent - Teil 2",
          "Intuition: Gradient Descent - Teil 3",
          "Wie lernt das Neuronale Netzwerk - Teil 2",
          "Wie lernt das Neuronale Netzwerk"
        ],
        "Kapitel 5 - 1: Was ist TensorFlow und Keras?": [
          "Was ist TensorFlow und Keras?"
        ],
        "Kapitel 5 - 2: NN für die Regression": [
          "Vorstellung: Diabetes Dataset",
          "Dataset Eigenschaften",
          "Dataset Funktion",
          "R2 Score",
          "Diabetes Modell - Teil 1",
          "Diabetes Modell - Teil 2",
          "Diabetes Modell - Teil 3",
          "Der Einsatz von Keras",
          "Under- und Overfitting",
          "Under- und Overfitting im Code"
        ],
        "Kapitel 5 - 3: NN für die Klassifikation": [
          "Vorstellung des MNIST Datasets",
          "One-Hot, Softmax und Cross-Entropy",
          "Intuition: One-Hot-Vector im Code",
          "Intuition: Softmax im Code",
          "Intuition: Cross-Entropy im Code",
          "MNIST Klassifikation in Keras",
          "Musterlösung: Optimierung der Hyperparameter",
          "Gewichte und Optimizer",
          "MNIST Klassifikation"
        ],
        "Kapitel 5 - 4: Modelle und TensorBoard": [
          "Abspeichern und Laden der Gewichte",
          "Abspeichern und Laden des gesamten Modells",
          "TensorBoard: Scalars, Graphs und Histograms",
          "TensorBoard: Modelle vergleichen - Teil 1",
          "TensorBoard: Modelle vergleichen - Teil 2",
          "TensorBoard: Confusion Matrix Callback",
          "Modelle und TensorBoard"
        ],
        "Kapitel 5 - 5: Real-World Einsatz von TensorFlow": [
          "Exkurs: TensorFlow in eine GUI"
        ],
        "Kapitel 5 - 6: Die Mathematik hinter den Netzwerken": [
          "Vorstellung des Minimal-Beispiels",
          "Der Aufbau des Computation Graph",
          "Der Backpropagation Algorithmus - Teil 1",
          "Der Backpropagation Algorithmus - Teil 2",
          "Weiteres zu Aktivierungsfunktionen - Teil 1",
          "Weiteres zu Aktivierungsfunktionen - Teil 2",
          "Weiteres zu Aktivierungsfunktionen - Teil 3",
          "Mathematische Hintergründe"
        ]
      },
      "requirements": [
        "Python Grundlagen",
        "Mathematik Grundlagen aus dem Abitur"
      ],
      "description": "Dieser Kurs ist dein umfassender Einstieg in die Welt des Deep Learnings – mit einem klaren Fokus auf Praxis, fundierter Theorie und moderner Python-Entwicklung mit TensorFlow 2 und Keras.\nStatt nur Code-Schnipsel zu kopieren, lernst du wirklich zu verstehen, wie neuronale Netze funktionieren – von der mathematischen Basis bis zur Anwendung. Du wirst eigene Modelle Schritt für Schritt selbst aufbauen und trainieren, Bilddaten analysieren und sogar Texte mit KI verarbeiten.\nDu startest mit den Grundlagen des Machine Learning und neuronaler Netzwerke – und steigst dann tief in die wichtigsten Netzarchitekturen ein: Von klassischen Fully Connected Networks über CNNs für Bildverarbeitung bis zu RNNs/LSTMs für Zeitreihen und Texte. Dabei kommen State-of-the-art Modelle wie ResNet und DenseNet ebenfalls nicht zu kurz.\nAuch Natural Language Processing (NLP) ist Teil des Kurses – perfekt, um moderne KI-Anwendungen wie Chatbots oder Textklassifizierer zu entwickeln.\nKursinhalte im Überblick:\nEinführung in Machine Learning und neuronale Netze\nMathematische Grundlagen (z. B. Aktivierungsfunktionen, Backpropagation)\nEigene Modelle in TensorFlow 2 und Keras entwickeln\nVisualisierung und Debugging mit TensorBoard\nDigitale Bildverarbeitung mit CNNs\nModerne Architekturen: ResNet, DenseNet\nSequenzmodelle: RNNs und LSTM für zeitabhängige Daten\nEinstieg in Natural Language Processing (NLP) mit Keras\nPraxisnahe Projekte und Übungen\nZiel:\nWerde fit im Umgang mit modernen KI-Technologien und baue deine eigenen Deep-Learning-Modelle – fundiert, praxisnah, professionell.\nMelde dich jetzt an und tauche in die Welt des Deep Learnings ein. Wir sehen uns im Kurs!\n\n\nHinweis:\nPython wird im Kurs mit Anaconda installiert. Alternativ ist auch eine Einrichtung über andere Quellen möglich.",
      "target_audience": [
        "Studenten, Softwareentwickler und alle Interessierten"
      ]
    },
    {
      "title": "Genetic Algorithm for Machine Learning",
      "url": "https://www.udemy.com/course/genetic-algorithm-for-machine-learning/",
      "bio": "Simplified Way to Learn",
      "objectives": [],
      "course_content": {
        "Genetics Algorithm": [
          "Concept of Genetic Algorithm",
          "Key terms used in GA & Its Mathematical Representation",
          "Implementation of Natural Selection: Part-1",
          "Implementation of Natural Selection: Part-2",
          "Implementation of Recombination: Part-1",
          "Implementation of Recombination: Part-2",
          "Implementation of Mutation",
          "Concept and Implementation of Elitism"
        ]
      },
      "requirements": [
        "No"
      ],
      "description": "This course covers the working Principle of Genetics Algorithms and its various components like Natural Selection, Crossover or Recombination, Mutation and Elitism in a a very simplified way.\nGA are inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms (EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection.",
      "target_audience": [
        "Students taking Genetics Algorithm or Machine Learning or Artificial Intelligence Course",
        "Machine Learning Enthusiast",
        "Students preparing for placement tests and interviews"
      ]
    },
    {
      "title": "Calculus with R: Practice Book with 120 Exercises",
      "url": "https://www.udemy.com/course/calculus-with-r-practice-book-with-120-exercises/",
      "bio": "Explore and Exercise Calculus Concepts with R: 120 Hands-On Problems to Build Math Skills and Data Science Expertise",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introductory Notes"
        ],
        "Limits": [
          "Limits",
          "Evaluating the Limit as x Approaches a Number",
          "Evaluating the Right-Hand Limit as x Approaches a Number",
          "Evaluating the Left-Hand Limit as x Approaches a Number",
          "Evaluating the Limit as x Approaches +Infinity",
          "Evaluating the Limit as x Approaches -Infinity"
        ],
        "Roots of One-Variable Functions on a Given Interval": [
          "Roots of One-Variable Functions on a Given Interval",
          "A reminder about some Assignments",
          "Roots of a Linear Function",
          "Roots of a Quadratic Function (1)",
          "Roots of a Quadratic Function (2)",
          "Roots of a Cubic Function",
          "Roots of a Sine Function",
          "Roots of an Exponential Function",
          "Roots of a Logarithmic Function",
          "Roots of a Rational Function",
          "Roots of a Absolute Value Function",
          "Roots of a Reciprocal Function"
        ],
        "Interpolation with Polynomials": [
          "Interpolation with Polynomials",
          "Polynomial Interpolation for a Discrete Dataset",
          "Polynomial Interpolation for a Continous Dataset",
          "Polynomial Evaluation for a Discrete Dataset at a Specific x",
          "Polynomial Evaluation for a Continuous Dataset at a Specific x",
          "Finding Roots for an Interpolated Polynomial"
        ],
        "Derivatives": [
          "Derivatives",
          "First Derivative",
          "First Derivative with Parameters",
          "Second Derivative",
          "Second Derivative with a Parameter",
          "Third Derivative at a Specific x",
          "First Derivative with a Parameter at Specific Values of x and the Parameter",
          "Second Derivative with Parameters at a Specific x",
          "Third Derivative at a Specific x",
          "First Derivative with a Parameter at a Specific x",
          "Second Derivative with a Parameter at a Specific x",
          "First Derivative with a Parameter and its Evaluation",
          "Second Derivative with a Parameter and its Evaluation",
          "First Derivative with Parameters and its Evaluation",
          "First Piecewise Derivative",
          "First-Order Partial Derivatives at Specific Values of x and y",
          "Second-Order Partial Derivative",
          "Second-Order Mixed Partial Derivative",
          "Second-Order Mixed Partial Derivative with a Parameter and its Evaluation (1)",
          "Third-Order Mixed Partial Derivative with a Parameter and its Evaluation",
          "Second-Order Mixed Partial Derivative with a Parameter",
          "Second-Order Mixed Partial Mixed Derivative with a Parameter",
          "Second-Order Mixed Partial Derivative with a Parameter and its Evaluation (2)",
          "Second-Order Mixed Partial Derivative with Parameters",
          "Second-Order Mixed Partial Derivative with Parameters and its Evaluation",
          "Third-Order Mixed Partial Derivative with a Parameter (1)",
          "Third-Order Mixed Partial Derivative with a Parameter (2)",
          "Fourth-Order Mixed Partial Derivative with a Parameter and its Evaluation",
          "Jacobian Matrix",
          "Jacobian Matrix with a Parameter",
          "Jacobian Matrix with a Parameter and its Evaluation",
          "Jacobian Matrix with Parameters",
          "Jacobian Matrix with Parameters and its Evaluation",
          "Hessian Matrix",
          "Hessian Matrix with a Parameter (1)",
          "Hessian Matrix with a Parameter and its Evaluation (1)",
          "Hessian Matrix with a Parameter (2)",
          "Hessian Matrix with a Parameter and its Evaluation (2)",
          "First-Order Partial Derivative of a Matrix-Valued Function",
          "First-Order Partial Derivative of a Matrix-Valued Function and its Evaluation",
          "Stationary Points",
          "Identifying Possible Inflection Points",
          "Second-Order Taylor Series of f(x)",
          "Second-Order Taylor Series of f(x,y)",
          "Third-Order Taylor Series of f(x)",
          "Ninth-Order Taylor Series of f(x)",
          "Second-Order Taylor Series of f(x) with a Parameter and its Evaluation"
        ],
        "Antiderivatives": [
          "Antiderivatives",
          "Computing the Antiderivative of a Polynomial Function",
          "Computing the Antiderivative of a Trigonometric Function"
        ],
        "Local Extrema of One-Variable Functions on a Given Interval": [
          "Local Extrema of One-Variable Functions on a Given Interval",
          "Local Minimum of a Linear Function",
          "Local Maximum of a Sine Function",
          "Local Minimum of an Exponential Function",
          "Local Maximum of a Quadratic Function",
          "Local Minimum of a Cubic Function",
          "Local Maximum of an Absolute Value Function",
          "Local Minimum of a Reciprocal Power Function",
          "Local Maximum of a Hyperbolic Cosine Function",
          "Local Minimum of an Arctangent Function",
          "Local Minimum of the Beta PDF"
        ],
        "Global Extrema of One-Variable Functions on a Given Interval": [
          "Global Extrema of One-Variable Functions on a Given Interval",
          "A reminder about some Assignments",
          "Minimum of a Quadratic Function",
          "Maximum of a Quadratic Function",
          "Minimum of an Exponential Function",
          "Maximum of an Exponential Function",
          "Minimum of a Hyperbolic Cosine Function",
          "Maximum of a Tangent Function",
          "Minimum of a Rational Function",
          "Maximum of a Sine Function",
          "Minimum of an Absolute Value Function",
          "Maximum of an Absolute Value Function"
        ],
        "Local Extrema of Two-Variable Functions in a Given Region": [
          "Local Extrema of Two-Variable Functions in a Given Region",
          "Local Extrema of a Two-Variable Function in a Square Region (1)",
          "Local Extrema of a Two-Variable Function in a Square Region (2)",
          "Local Extrema of a Two-Variable Function in a Square Region (3)",
          "Local Extrema of a Two-Variable Function in a Square Region (4)",
          "Local Extrema of a Two-Variable Function in a Square Region (5)"
        ],
        "Integrals": [
          "Integrals",
          "A reminder about some Assignments",
          "Indefinite Integral of a Cubic f(x)",
          "Indefinite Integral of a Parametrized Power f(x) and its Evaluation",
          "Definite Integral of a Quadratic f(x)",
          "Definite Integral of a Linear f(x)",
          "Definite Integral of a Parametrized Linear f(x)",
          "Definite Integral of a Parametrized Sine f(x)",
          "Definite Integral of a Parametrized Square Root f(x)",
          "Improper Integral of an Exponential f(x)",
          "Improper Integral of a Parametrized Exponential f(x) and its Evaluation (1)",
          "Improper Integral of a Parametrized Exponential f(x) and its Evaluation (2)",
          "Improper Integral of a Normal PDF",
          "Double Definite Integral of an Exponential f(x,y)",
          "Double Improper Integral of an Exponential f(x,y) (1)",
          "Double Mixed Integral of a function f(x,y) with Reciprocals",
          "Double Improper Integral of an Exponential f(x,y) (2)"
        ]
      },
      "requirements": [
        "Basic understanding of calculus, including limits, derivatives, and integrals.",
        "Familiarity with algebraic operations and mathematical functions.",
        "Prior experience with R programming at an introductory level.",
        "Ability to install and use R and RStudio on a computer.",
        "Knowledge of basic coding concepts, including variables, functions, and loops.",
        "Basic familiarity with mathematical modeling and data analysis.",
        "Willingness to work with mathematical formulas and apply them in R.",
        "Access to a computer with an internet connection to download necessary packages.",
        "Curiosity and motivation to learn calculus concepts with practical coding applications.",
        "Patience and persistence to solve hands-on problems and explore advanced topics."
      ],
      "description": "\"Calculus with R: Practice Book with 120 Exercises\" is designed to introduce R users to powerful external R packages that help perform numerical computations and symbolic operations in Calculus at an intermediate level.\nWho Is This Course For?\nNo extensive R experience? No problem! This course is perfect for anyone looking to apply R in solving applicable mathematical problems without needing to write complex scripts. You'll primarily focus on selecting specific functions from relevant R packages and providing the correct arguments to solve various problems, whether they involve small tasks or entire calculations.\nWhat Does the Course Include?\nThe course features 120 exercises spread across 10 Calculus sections. Each exercise is accompanied by a complete solution using R. While the course doesn't cover all possible Calculus topics or every functionality available in R, it provides a solid foundation to:\nPerform essential calculations in Calculus using R.\nGain confidence in using R for mathematical problem-solving.\nExplore practical, real-world applications of Calculus.\nViedos\nEach section includes videos related to the topic of the respective section. The purpose of each video is to introduce the subject indicated in the section title. Each video features a dynamic visualization designed to make the content highly engaging and effective.\nWhy Take This Course?\nBy the end of this course, you'll be equipped with practical skills to:\nSolve significant mathematical problems using R.\nNavigate and utilize R's vast array of functions in external packages.\nApply your newfound knowledge to various scientific and social science domains.\nReady to Get Started?\nDive into the course and explore how R can simplify even the most complex Calculus problems.",
      "target_audience": [
        "Undergraduate and graduate students in mathematics, data science, engineering, or related fields who seek practical applications of calculus concepts in R.",
        "Educators seeking a resource for teaching calculus with a focus on coding and hands-on exercises.",
        "Data analysts and scientists interested in strengthening their mathematical foundation and integrating calculus into data-driven projects.",
        "Self-learners passionate about exploring intermediate-level math and coding with a focus on problem-solving and application."
      ]
    },
    {
      "title": "Programmer en R pour la Data Science de A à Z",
      "url": "https://www.udemy.com/course/apprendre-la-data-science-avec-r-de-a-a-z/",
      "bio": "Intéressés par la Data ? Apprenez à faire de la Data Science et du Machine Learning avec le langage R sans pré-requis!",
      "objectives": [
        "Utiliser Rstudio",
        "Programmer en R",
        "Récupérer des données et les charger dans R",
        "Connaitre les structures de données en R (vecteurs, matrices, ...)",
        "Manipuler efficacement des données avec dplyr",
        "Explorer et visualiser des données avec ggplot2",
        "Utiliser R pour faire de la Data Science",
        "Utiliser des algorithmes de Machine Learning",
        "Faire du Data Mining"
      ],
      "course_content": {
        "Introduction et mise en place du cours": [
          "Installation de R et RStudio (Windows/Mac/Linux)",
          "Découverte de l'interface RStudio",
          "Création d'un projet sous Rstudio",
          "Installation des packages R essentiels pour la data science"
        ],
        "Débuter avec R": [
          "Les types de données (character, int, double, booléens, données manquantes)",
          "Les variables",
          "Les opérateurs arithmétiques",
          "Les vecteurs",
          "Opérations sur les vecteurs",
          "Manipuler les vecteurs grâce aux indexs",
          "Qu'est-ce qu'une fonction en R ?",
          "Utiliser les fonctions fournis par R",
          "Qu'est-ce qu'un package R ?",
          "Savoir utiliser l'aide de R",
          "Exercice : manipuler un vecteur contenant les moyennes d'une classe de 20 élèves"
        ],
        "Les matrices en R": [
          "Qu'est ce qu'une matrice en R ?",
          "colnames() et rownames()",
          "Accéder aux éléments d'une matrice",
          "Modifier une matrice",
          "Opérations sur les matrices",
          "Exercice : manipuler une matrice"
        ],
        "Les dataframes en R": [
          "Qu'est ce qu'un dataframe en R ?",
          "colnames() et rownames()",
          "Importation de données",
          "Exportation de données",
          "Accéder aux éléments d'un dataframe",
          "Créer un sous-ensemble à partir d'un dataframe",
          "Exercice : manipuler les dataframes"
        ],
        "Les bases de la programmation en R": [
          "Les opérateurs logiques",
          "Les instructions de condition (if ... else)",
          "Les instructions de boucles (for)",
          "Les instructions de boucles (while)",
          "Exercice sur les instructions de condition et les boucles en R",
          "Comment créer sa propre fonction en R"
        ],
        "Manipulation avancée des données": [
          "apply()",
          "aggregate() et by()",
          "Dplyr : les tibbles",
          "Dplyr : select()",
          "Dplyr : filter()",
          "Dplyr : l'opérateur pipe (%>%)",
          "Dplyr : arrange()",
          "Dplyr : summarise()",
          "Dplyr : group_by()",
          "Dplyr : mutate()",
          "Exercice : explorer les données de l'ensemble des fast-foods aux USA"
        ],
        "Visualisation avancée des données": [
          "Créer son premier graphique avec la fonction plot()",
          "Créer des graphiques plus élaborés avec ggplot2",
          "ggplot2 : Les couleurs, les formes et les tailles",
          "ggplot2 : La légende (introduction des thèmes)",
          "ggplot2 : Axes et titres",
          "ggplot2 : Combiner plusieurs graphes (facet)",
          "ggplot2 : Ajouter des annotations au graphique",
          "ggplot2 : Les différents types de graphes (geoms)",
          "Exercice : visualisation des données de l'ensemble des fast-foods aux USA",
          "BONUS : rendre votre graphique interactif avec Plotly"
        ],
        "Cas pratique de Data Science : appliquer des algorithmes de Machine Learning": [
          "Qu'est ce que l'apprentissage automatique (machine learning) ?",
          "Données : prédire la souscription d'un client à un produit bancaire",
          "Visualisation des données avec ggplot2",
          "Création d'un jeu de données d'entrainement et de test",
          "Traitement des classes déséquilibrées et normalisation",
          "Entrainer un modèle avec Caret : méthode Naive Bayes",
          "Entraîner un modèle avec Caret : méthode SVM (Support Vector Machine)",
          "Trouver les variables prédictives les plus importantes"
        ],
        "BONUS": [
          "Coupon : Programmer en Python pour la Data Science de A à Z - Lien direct",
          "Coupon : Programmer en Python pour la Data Science de A à Z",
          "L'ensemble du code R utilisé durant le cours",
          "Aide-mémoire ggplot2",
          "Aide-mémoire dplyr",
          "Mon livre aux éditions ENI : Python pour la Data Science"
        ]
      },
      "requirements": [
        "Un ordinateur",
        "Une connexion internet pour installer les outils et récupérer des jeux de données",
        "Aucunes connaissances requises en programmation, je pars du début !"
      ],
      "description": "Ce cours est dédié à l'apprentissage de la programmation en R appliqué à la Data Science. Si vous avez envie d'apprendre à coder, d'apprendre à manipuler de la data ou les deux, alors n'hésitez pas, ce cours est un concentré de tout ça !\nCe cours de 8 heures vous permettra dans un premier temps d'acquérir les outils nécessaires pour coder en R et faire de la Data Science. Puis il enchaînera sur la partie théorique de la programmation en R, avec des exercices à chaque étape, afin de comprendre la théorie en pratiquant. Dans un troisième temps, vous apprendrez à manipuler et explorer/visualiser des données efficacement. Enfin, un cas pratique de Data Science viendra reprendre tout ces concepts pour les appliquer sur des données réelles en plus de vous apprendre à appliquer des algorithmes de Machine Learning sur vos données.\nA la fin de ce cours, vous serez capable d'aller récupérer un jeu de données qui vous intéresse et de l'analyser de A à Z pour en sortir les informations qui vous intéresse.\nJ'espère que ce cours vous plaira, j'ajouterai d'avantage de cas pratiques au fur et à mesure pour le rendre encore plus complet qu'il ne l'est déjà. Le but de ce cours de Data Science est réellement de vous apprendre à programmer en R, de vous faire pratiquer afin de devenir totalement autonome pour analyser tous les jeux de données qui vous intéresse. Et je compte bien vous aider à chaque étape pour arriver à cette finalité !\nPourquoi utiliser R ?\nJ'ai choisi R pour la simple et bonne raison que c'est un des langages les plus utilisés en Data Science. De plus, c'est un langage que je maîtrise et qui a fait ses preuves pour résoudre tout mes problèmes d'analyse de données. Mais aussi parce que c'est un langage de programmation libre, intuitif et très bien documenté. Enfin, R est un langage extrêmement efficace pour effectuer des analyses statistiques et de l'exploration de données.\n\n\nJe veux que ce cours soit le plus complet possible. Ainsi, n'hésitez surtout pas à me contacter si vous avez la moindre question ou la moindre remarque sur ce cours. C'est aussi grâce à vous que je pourrais l'améliorer et le faire évoluer. Mon objectif est réellement de vous aider à devenir un Data Scientist autonome et passionné !\n\n\nLogo créé par Pikisuperstar - Freepik\\.com",
      "target_audience": [
        "Les personnes souhaitant apprendre à programmer en R",
        "Les personnes souhaitant apprendre à faire de la Data Science avec R",
        "Toutes personnes intéressées par la Data Science en général"
      ]
    },
    {
      "title": "Python数据分析：从小白到高手（Python Data Analysis Crash Course）",
      "url": "https://www.udemy.com/course/python-data-analysis-atoz/",
      "bio": "紧跟前沿的Python数据分析课，动画满满、直观易懂，6个项目手把手实战，轻松掌握全流程",
      "objectives": [
        "高效快速掌握所有Python基础",
        "安装与使用Python数据分析必备工具",
        "NumPy的Array基础操作",
        "Pandas的Series与DataFrame基础操作",
        "JSON和CSV的常见数据格式",
        "读取JSON和CSV文件的方法",
        "对数据干净整洁程度进行评估",
        "清洗数据解决数据脏乱问题",
        "合并多个数据进行综合分析",
        "对数据进行分组聚合操作",
        "对数据进行描述统计学分析",
        "了解多种数据可视化图表",
        "对单个/两个/多个变量数据进行可视化",
        "对数据进行假设检验分析",
        "对数据进行线性回归分析",
        "对数据进行逻辑回归分析",
        "把AI整合进数据分析工具",
        "用AI助力数据分析"
      ],
      "course_content": {
        "介绍": [
          "先导片 | 能轻松学懂的Python数据分析课程"
        ],
        "【赠送预习】Python入门篇 | 非零基础可以跳过": [
          "在你开始编程之前 | 为什么安装Python和PyCharm",
          "Windows系统 | 安装Python和PyCharm",
          "macOS系统 | 安装Python和PyCharm",
          "PyCharm | 创建你的第一个项目",
          "Python print | 让程序给你打印“爸爸”",
          "Python print | 让程序给你打印一首诗",
          "Python变量 | 怎么让程序记住你对象的手机号？",
          "Python命名规则 | 哪些变量名算好名字？",
          "Python数学运算 | 用代码秒杀计算器",
          "Python注释 | 悄悄在代码里骂用户？",
          "Python数据类型 | 程序世界的物种们",
          "Python交互模式 | 读一行执行一行",
          "Python input | 写个用户问答互动程序",
          "Python条件语句 | 对象今天会生气吗",
          "Python逻辑运算 | 今年过节能收礼吗",
          "Python嵌套/多条件判断 | 对象今天会生气吗 II",
          "Python列表 | 创一个购物清单",
          "Python字典 | 创个秒查流行语的词典",
          "Python for循环 | 找出不正常的体温",
          "Python while循环 | 捕捉日落",
          "Python 格式化字符串 | 优雅群发春节短信",
          "Python函数（上） | 不做代码复读机",
          "Python函数（下） | 不做代码复读机",
          "Python引入模块 | 别人写的，拿来吧你",
          "Python面向对象编程 | 封装、继承、多态都是啥？",
          "Python创建类（上）| 没对象？实例化一个",
          "Python创建类（下）| 当上帝的时刻到了",
          "Python 类继承 | 老鼠的儿子会打洞",
          "Python文件路径 | 文件在哪里，代码咋知道",
          "Python文件操作 | 会读文件，程序便有了眼睛",
          "Python文件操作 | 会写文件，程序便有了记忆",
          "Python异常处理 | 程序炸之前，走一波预判",
          "Python测试（上） | 不存在不写bug的程序员",
          "Python测试（下） | 高效率把bug揪出来",
          "Python高阶和匿名函数 | 脱了马甲也要认识"
        ],
        "第二章 数据分析预备篇": [
          "Jupyter Notebook安装 | 搞个金刚钻",
          "Jupyter Notebook使用 | 上手金刚钻",
          "Markdown与LaTeX入门 | 用字符格式化字符",
          "NumPy入门 | 数组，更适合数据分析的列表",
          "NumPy入门 | 使用数组练习篇",
          "NumPy入门 | 探索更多数组玩法",
          "NumPy入门 | 操作数组练习篇",
          "Pandas入门 | Series，更强大的数组形态",
          "Pandas入门 | 使用Series练习篇",
          "Pandas入门 | 用Series丝滑操作数据",
          "Pandas入门 | 操作Series练习篇",
          "Pandas入门 | Dataframe，代码世界的表格",
          "Pandas入门 | 使用DataFrame练习篇",
          "Pandas入门 | 用Dataframe丝滑操作数据",
          "Pandas入门 | 操作Dataframe练习篇",
          "Pandas入门 | 更多用Dataframe丝滑操作数据",
          "Pandas入门 | 更多操作Dataframe练习篇"
        ],
        "第三章 数据获取与读取篇": [
          "获取数据 | 数据是原料，原料哪里找",
          "常见数据格式 | JSON，程序员的挚爱",
          "读取数据 | 瞧一眼现成JSON原料",
          "常见数据格式 | CSV，数据分析师的挚爱",
          "读取数据 | 瞧一眼现成CSV原料"
        ],
        "第四章 数据评估与清洗篇": [
          "评估数据 | 怎么才算干净整齐的数据",
          "评估数据 | 实际上手评估数据脏乱度",
          "清洗数据 | 做菜之前记得洗菜",
          "清理数据 | 上手清理索引和列名",
          "清理数据 | 和所有的乱数据说白白",
          "清理数据 | 和所有的脏数据说白白",
          "清洗数据 | 保存洗干净后的数据",
          "项目实战指引 | 实战数据哪里找",
          "项目实战 | 评估清理英国电商销售数据",
          "项目实战指引 | 如何把输出项目放到Github/简历上"
        ],
        "第五章 数据整理篇": [
          "整理数据 | 合并多数据，分析更有趣",
          "整理数据 | 数据变变变",
          "整理数据 | 更多数据变变变",
          "项目实战 | 整理Netflix电影演员评分数据"
        ],
        "第六章 数据可视化篇": [
          "统计学基础 | 如果你不记得统计学知识",
          "统计学基础 | 如何描述数值数据",
          "探索数据 | 用描述统计学挖掘信息宝藏",
          "可视化数据 | 图表世界的物种们",
          "可视化数据 | 更多图表世界的物种们",
          "可视化数据 | 玩转单个变量数据",
          "可视化数据 | 玩转两个变量数据",
          "可视化数据 | 玩转多个变量数据",
          "项目实战 | 可视化帕默群岛企鹅数据"
        ],
        "第七章 数据分析篇": [
          "统计学进阶 | 如果你没学过假设检验",
          "统计学进阶 | 用假设检验挖掘信息宝藏",
          "项目实战 | 分析鸢尾花种类数据",
          "机器学习 | 啥是神秘的线性回归",
          "机器学习 | 啥是神秘的多元线性回归",
          "机器学习 | 点亮线性回归的技能",
          "项目实战 | 用线性回归预测房价数据",
          "机器学习 | 啥是神秘的逻辑回归",
          "机器学习 | 点亮逻辑回归的技能",
          "项目实战 | 用逻辑回归预测泰坦尼克号幸存"
        ],
        "第八章 AI前沿运用篇": [
          "AI相关 | 如何用ChatGPT助力编程",
          "AI相关 | 如何用ChatGPT助力数据分析",
          "AI相关 | 如何把AI模型整合进Jupyter",
          "AI相关 | 在Jupyter Notebook玩转AI之基础篇",
          "AI相关 | 在Jupyter Notebook玩转AI之进阶篇"
        ],
        "第九章 更多获取数据篇": [
          "爬虫获取数据 | 爬虫的流程",
          "爬虫获取数据 | 什么是HTTP请求和响应",
          "爬虫获取数据 | 如何用Python发送请求",
          "爬虫获取数据 | 练习用Python拿到豆瓣源码",
          "爬虫获取数据 | 什么是HTML网页结构",
          "爬虫获取数据 | HTML有哪些常用标签",
          "爬虫获取数据 | 练习HTML常见标签",
          "爬虫获取数据 | 如何解析HTML内容",
          "爬虫获取数据 | 练习从源码获取豆瓣电影Top 250",
          "API获取数据 | 获得来自官方的数据"
        ]
      },
      "requirements": [
        "不要求任何编程基础",
        "不要求任何统计学知识"
      ],
      "description": "关于讲师的信息？\n我毕业于加拿大排名第一的大学，计算机科学（Computer Science）科班出身，现作为软件工程师就职于FAANG。\n\n\n数据分析为什么重要？\n我们经历的每场科技革命，都产生了大量数据，也借助数据不断迭代和进化，特别是近期掀起了巨浪的AI。\n而放眼生活中，职场里，企业需要能用数据做出正确决策、用数据提升业务收入的人才，学校里，写报告、做研究，要靠数据才能得出有说服力的结论。如今各行各业也在进行数字化转型，数据分析正在变成一项必备技能。\n\n\n为什么使用Python？\n你是否遇到过这些情况呢？手动处理数据，效率低、易出错，枯燥的重复性劳动让人觉得产出毫无价值？或者是数据量一大，逻辑一复杂，Excel就超级卡顿，人也要跟着崩溃了？\n那我们的目光，可以转向适合处理和分析数据的Python。几十万行数据，无比复杂的逻辑，在Python那里都是小意思。它还支持图表可视化、机器学习等，有强大的扩展能力。\n所以人工智能时代，Python是让你保持竞争力、提高效率的绝佳帮手，能让别人手里五小时甚至五天的活，变成你手里五分钟的小任务。\n\n\n我的Python课程有什么不一样？\n第一是，你能看到非常多我精心制作的动画演示，讲解中我也会利用很多贴近生活的例子，来帮助你理解。\n第二是精炼。我的课程视频每个长度在5～10分钟左右，直击重点的精炼，知识密集，杜绝长篇大论，帮你高效掌握技能。\n\n\n课程有没有其它亮点？\n有些朋友会烦恼没有输出成果能放在简历上，无数小时的学习投入，只变成了技能里短短几个字。这门课程里，会有针对真实数据集的N个项目实战，既有利于把技能迁移到职场或学校中运用，还能产出多份可以放在简历上的分析报告，提升简历包装。\n\n\n我们课上再见。",
      "target_audience": [
        "在校学生，需要提高和数据打交道的效率，包括写报告、做分析等",
        "求职人士，希望会编程、会运用、项目还能展示在简历上，提高竞争力",
        "职场人士，渴望高效处理数据，洞察业务信息，助力职场步步高升",
        "转行人士，想成为数据分析师/数据科学家/算法工程师，轻松掌握必备基础"
      ]
    },
    {
      "title": "Pythonによるビジネスに役立つWebスクレイピング（BeautifulSoup・Selenium・Requests）",
      "url": "https://www.udemy.com/course/python-web-scraping-with-beautifulsoup-selenium-requests/",
      "bio": "Python3のスクレイピング用ライブラリ BeautifulSoup・Selenium を用いて、世界中のWebサイトからデータを取得します。効率的にデータを収集・活用することで、業務効率化・自動化に貢献するスキルを身に付けましょう！",
      "objectives": [
        "Python3のスクレイピング用ライブラリBeautifulSoup、Selenium、Requests、Newspaper3k、Pandas(read_html)が扱えるようになります。",
        "Beautiful Soupを用いて、複数のWebページを巡回し、目的の情報を取得する方法を理解することができます。",
        "Seleniumを利用した、ログイン画面への対処、JavaScriptを用いた動的なサイトへの対処、画像を取得・ダウンロードする方法を理解することができます。",
        "newspaper3kを用いて、ニュースサイトやブログのトップページに表示されている複数の記事を順に巡回し、記事や要約、キーワードをダウンロード・保存する方法を理解することができます。",
        "Pandasのread_htmlを用いて、Webサイト上のテーブルに格納されているデータを取得する方法を理解することができます。",
        "スクレイピングにおけるXPath、CSSセレクタ、正規表現の利用方法を学ぶことができます。",
        "スクレイピングでデータを取得・抽出し、取得したデータを整形・グラフ化、保存する一連の流れを習得することができます。",
        "実践的な演習問題を通じてスクレイピングの理解を深めることができます。"
      ],
      "course_content": {
        "はじめに": [
          "各セクションで学ぶトピック１(スクレイピングのステップ)",
          "各セクションで学ぶトピック２(スクレイピング用ライブラリの種類・役割 )",
          "各セクションで学ぶトピック３(このコースの前半で学ぶトピック)",
          "【重要】Udemyの使い方",
          "【重要】本コースのソースコード"
        ],
        "Jupyter Notebookのインストールと使い方": [
          "Jupyter Notebookのインストール",
          "Anacondaのインストール",
          "ライブラリのインストール",
          "Jupyter Notebookの変更点",
          "基本的な使い方",
          "エディットモード・コマンドモード、ショトカットキー",
          "マークダウン",
          "コードの実行",
          "データ保存",
          "ファイル共有、終了方法",
          "その他の便利な機能"
        ],
        "【補講：初心者向け】HTMLの基本、Pythonの基礎(外部リンク)": [
          "HTMLの構成、タグの種類",
          "HTMLタグの属性",
          "CSSとは",
          "HTMLの階層構造",
          "HTMLの基本のまとめ",
          "Pythonの基礎が学べるサイトへのリンク"
        ],
        "newspaper3kによるニュース記事の取得(ブルームバーグ)": [
          "このセクションで学べるトピック",
          "newspaper3kのインストール方法",
          "単一のニュース記事の取得",
          "複数のニュース記事の取得",
          "CSVファイルへの保存１(事前準備)",
          "CSVファイルへの保存２(データ保存)"
        ],
        "【演習】newspaper3kによる各種業界メディアからの記事の取得": [
          "このセクションで学べるトピック",
          "Part1(単一の記事の取得)のタスクの説明",
          "Part1(単一の記事の取得)の解答の解説",
          "Part2(複数の記事の取得)のタスクの説明",
          "Part2(複数の記事の取得)の解答の解説"
        ],
        "Pandasでスクレイピング(Yahoo Financeから株価の取得)": [
          "このセクションで学べるトピック",
          "Pandas・read_htmlの基本",
          "サイトの変更に伴うコードの変更点",
          "read_htmlによるデータの取得と表示",
          "取得データの変換１(数値)",
          "取得データの変換２(日付)",
          "株価グラフの描画",
          "株価データの保存",
          "1年分以上の株価情報を取得する方法"
        ],
        "Requestsの基本的な使い方": [
          "このセクションで学べるトピック",
          "Requestsの解説",
          "Requestsの使い方(responseオブジェクト)",
          "Requestsの使い方(getメソッドの引数)"
        ],
        "【補講：初心者向け】Beautiful Soupの基本": [
          "このセクションで学べるトピック",
          "BeautifulSoupの基本",
          "BeautifulSoupでHTMLの階層を移動してタグを指定する方法",
          "BeautifulSoupのfind、find_allメソッドの使い方",
          "BeautifulSoupのselectメソッドの使い方",
          "BeautifulSoupの基本演習"
        ],
        "BeautifulSoupで価格.comからランキングデータの取得": [
          "このセクションで学べるトピック",
          "HTMLデータの取得",
          "find、find_allメソッドによる商品名・URLの取得",
          "selectメソッドによる商品名・URLの取得"
        ],
        "【演習】BeautifulSoupでYahooニュースから主要ニュースの記事を取得": [
          "このセクションで学べるトピック",
          "【課題】主要ニュースのタイトル・URL一覧の取得",
          "【解説】主要ニュースのタイトル・URL一覧の取得",
          "【課題】要約ページからニュースページへのリンクの取得",
          "【ヒント】リンクをたどって複数のページを遷移する方法",
          "【解説】サイトの変更に伴うコードの変更点",
          "【解説】要約ページからニュースページへのリンクの取得",
          "【課題】各主要ニュースの記事の取得",
          "【解説】サイトの変更に伴うコードの変更点",
          "【解説】各主要ニュースの記事の取得"
        ]
      },
      "requirements": [
        "Pythonの基本的な文法を理解されている方を対象としています。もし受講の途中で知識の不足を感じるようでしたら、参考のリンクを掲載しておりますので、補足ください。",
        "講師はWindowsの環境で解説しておりますが、Mac（M1～M4を除く）でも同様に進めていくことができます。",
        "スクレイピングが全くの未経験でも問題ありません。HTML、CSSの基本についても解説しております。",
        "講師はAnacondaでのPython3環境を構築し、Jupyter Notebookを元に解説を進めておりますが、別のPython3環境でも進めていくことができます。",
        "AnacondaでのPython3の環境構築、Jupyter Notebookの使い方についての講義も提供しております。",
        "なおQ&Aフォームでは、コースで取り扱っていないトピックについてはお答えできませんので、ご理解賜りますようお願い申し上げます。"
      ],
      "description": "現役のデータサイエンティストが提供するWebスクレイピングに関する講座で、データサイエンスの実務における経験を基に、デザインされた講座になります。\n\n\n近年、ビジネスでのデータ活用においては、世界中のWebサイトから様々なデータを取得することが求められています。 また変化も激しい環境において、それぞれのWebサイトの構造や内容も頻繁に更新され、日々変わっていきます。\n\n\nスクレイピングが難しい理由として、次のようなポイントが挙げられます。\nWebサイトにより構造が異なる\nWebサイトの構造が複雑・頻繁に変わる\nJavaScriptでユーザーの操作によって新たなページが読み込まれるなど、特殊な技術が使われている\nしかし、ビジネスでスクレイピングを用いるには、これらのポイントに適切に対処していくことが求められます。\n\n\n\n\n【このコースで扱うトピック】\nこれら難しいポイントに適切に対処し、ビジネスでスクレイピングを活用できるよう、このコースはデザインされています。\n\n\nこのコースで扱うトピックは、これらのものになります。\n\n\n様々なニーズや場面に応じて使い分けできるよう、Pythonのスクレイピングライブラリの中でも幅広いライブラリをカバーします。\nBeautiful Soup、Selenium、Requests、newspaper3k、Pandasのread_html\n\n\nビジネスで活用するにおいて必要となる、スクレイピングにおける一連のプロセスをカバーします。\nデータ取得・抽出から、整形、グラフ化、保存まで\n\n\n特殊な技術が使われているWebサイトも考慮し、幅広いスキルを身につけれるよう、レクチャーを提供します。\nJavaScriptを用いた動的なサイトへの対処方法\nログイン画面への対処方法\nリンクをたどり、複数のWebページを巡回する方法\nテキスト情報・画像ファイルの取得方法\nなど多数\nこれらを通じてこのコースの受講後は、世界中のWebサイトから効率的に情報を取得することができるようになります。\nまたレクチャーで学んだ知識が定着するよう、豊富で実践的な演習を用意しております。\n\n\nなお、Classなどオブジェクト指向の記述は、初心者向きでは無いので本コースの対象外としております。本コースでは、これらの記述を使わずに解説しておりますので、ご注意ください。",
      "target_audience": [
        "Webスクレイピングをビジネスに活用されたい方",
        "Webスクレイピングを趣味に活用されたい方",
        "Webスクレイピングに興味があるが、始め方がわからない方",
        "Webサイトから効率的にデータを取得する方法を学習されたい方"
      ]
    },
    {
      "title": "Classification with Python and Scikit-Learn (Audio Course)",
      "url": "https://www.udemy.com/course/decision-trees-random-forests-with-python-and-scikit-learn/",
      "bio": "\"Building Decision Trees and Random Forests with Python & Scikit-Learn\"",
      "objectives": [],
      "course_content": {
        "Scikit-Learn": [
          "Introduction to Scikit-Learn"
        ],
        "Introduction to Decision Trees with Scikit-Learn": [
          "Introduction to Decision Trees with Scikit-Learn"
        ],
        "Decision trees with Scikit-learn": [
          "Decision trees with Scikit-Learn"
        ],
        "Introduction to Random forests with Scikit-Learn": [
          "Introduction to Random forests with Scikit-Learn"
        ],
        "Random forests with Scikit-learn": [
          "Random forests with Scikit-Learn"
        ]
      },
      "requirements": [
        "Python programming"
      ],
      "description": "Course Description: Decision Trees & Random Forests with Python and Scikit-Learn Machine Learning Library\nUnlock the power of Decision Trees and Random Forests with this hands-on course using Python and Scikit-Learn! Whether you're a beginner in machine learning or looking to deepen your knowledge of ensemble learning, this course will provide you with a solid foundation.\nYou’ll start with the fundamentals of decision trees, understanding how they split data, measure impurity, and make predictions. Then, we’ll explore Random Forests—an ensemble learning technique that improves accuracy and reduces overfitting. You’ll learn how to fine-tune hyperparameters, interpret feature importance, and handle imbalanced datasets.\nThrough practical exercises and real-world datasets, you’ll implement decision trees and random forests using Python’s powerful Scikit-Learn library. You’ll visualize decision boundaries, optimize model performance, and compare results with other machine learning algorithms.\nBy the end of the course, you’ll be able to:\nUnderstand and implement Decision Trees from scratch\nTrain and fine-tune Random Forest models\nPerform feature selection and interpret model results\nOptimize hyperparameters for better performance\nApply these techniques to real-world datasets\nNo prior machine learning experience is required—just basic Python knowledge! Enroll now and take your data science skills to the next level with Decision Trees and Random Forests! You are welcome to this new course !",
      "target_audience": [
        "Learners wanting to learn more about Decision trees and Random forests"
      ]
    },
    {
      "title": "Amplify Your Learning With Data Mentor",
      "url": "https://www.udemy.com/course/amplify-your-learning-with-data-mentor/",
      "bio": "Elevate Your Skills with Data Mentor, Embracing Analysis, Visualization, Machine Learning, and Interpretation.",
      "objectives": [],
      "course_content": {
        "Getting Started with Data Mentor": [
          "Your On-Demand Mentor",
          "Using Data Mentor Effectively",
          "Exploring Queries Threads"
        ],
        "Enhancing Your Skills with AI Tools": [
          "Creator AI Tools",
          "Debugging AI Tools",
          "Visualizer AI Tools",
          "Advisor AI Tools",
          "Creating Libraries of Content"
        ],
        "Advanced Applications and Integration": [
          "Understanding Document Creation",
          "Amazing AI Agents",
          "Create a New Daily Learning Habit using Data Mentor",
          "Solving Real Problems and Improving Your Productivity",
          "Integrating Data Mentor with EDNA AI"
        ]
      },
      "requirements": [
        "Basic understanding of data concepts",
        "An account on the Data Mentor platform and EDNA AI",
        "Computer or laptop to access course materials.",
        "Stable internet connection for video streaming and resources."
      ],
      "description": "Are you looking to elevate your data skills and harness the power of AI in your analysis? Do you seek the knowledge and tools to not just understand but also to harness the power of data in transformative ways? \"Amplify Your Learning With Data Mentor\" is tailored to empower you on this journey.\nThis comprehensive course is designed for individuals eager to dive deep into the realm of data science, offering a unique blend of structured learning and innovative AI assistance. It serves as a bridge between theoretical knowledge and practical application, ensuring you can effectively implement data analysis, visualization, and AI technologies in real-world scenarios.\nAmplify Your Learning With Data Mentor provides a tailored learning experience that evolves with your pace and preferences. Through hands-on experience with AI tools, you'll find even the most complex data tasks becoming more manageable, significantly boosting your productivity. This course emphasizes the importance of a continuous learning mindset and productivity optimization, preparing you for the future advancements in the field.\nStart your transformative journey with \"Amplify Your Learning With Data Mentor\" today and open the doors to endless possibilities in the world of data science.\nReady to step into a meaningful transformation?\nClick 'Buy Now' and unlock your potential in the dynamic world of data science.",
      "target_audience": [
        "Beginners interested in learning about AI tools",
        "Individuals seeking to enhance their data-driven decision-making skills",
        "Professionals eager to optimize their productivity for continuous improvement",
        "Anyone aiming to integrate AI technologies into their workflow"
      ]
    },
    {
      "title": "Machine Learning: Aplicado a Python y Data Science",
      "url": "https://www.udemy.com/course/machine-learning-aplicado-a-python-y-data-science/",
      "bio": "Aprende a crear algoritmos de Machine Learning en Python para estudiantes y profesionales",
      "objectives": [
        "Aprender a programar en Python y Scikit learn aplicado a la regresión de Machine Learning",
        "Aprender a resolver problemas de regresión (regresión lineal y regresión logística)",
        "Aprenda las matemáticas que hay detrás de los árboles de decisión",
        "Comprender la teoría subyacente a las técnicas de regresión lineal simple y múltiple",
        "Aprenda la teoría y la aplicación práctica de la regresión logística con sklearn",
        "Conozca los diferentes algoritmos de agrupación"
      ],
      "course_content": {
        "Introducción al Machine Learning": [
          "¿Qué es el Machine Learning?",
          "Aplicaciones del Machine Learning",
          "Métodos de Machine Learning",
          "¿Qué es el aprendizaje Supervisado?",
          "¿Qué es el aprendizaje No Supervisado?",
          "Aprendizaje Supervisado vs aprendizaje No Supervisado",
          "Materiales del curso"
        ],
        "Opcional: Configuración de Python e Implementación de Algoritmos ML": [
          "Introducción",
          "Bibliotecas Python para Machine Learning",
          "Configuración de Python",
          "¿Qué es Jupyter?",
          "Instalación de Anaconda Windows Mac",
          "Implementación de Python en Jupyter",
          "Gestión de directorios en Jupyter Notebook"
        ],
        "Regresión Lineal Simple": [
          "Introducción a la Regresión",
          "¿Cómo funciona la Regresión Lineal?",
          "Representación Lineal",
          "Implementación en Python: Importación de bibliotecas y conjuntos de datos",
          "Implementación en Python: Distribución de los datos",
          "Implementación en Python: Creación de un objeto de regresión lineal"
        ],
        "Regresión Lineal Múltiple": [
          "Comprender la Regresión Lineal Múltiple",
          "Implementación en Python: Exploración del conjunto de datos",
          "Implementación en Python: Codificación de datos categóricos",
          "Implementación en Python: División de los datos en conjuntos de ensayo y prueba",
          "Implementación en Python: Entrenamiento del modelo en conjunto de entrenamiento",
          "Implementación en Python: Predicción de los resultados del conjunto de prueba",
          "Evaluación del rendimiento del modelo de regresión",
          "Error Cuadrático Medio en Python",
          "Momento del Quiz"
        ],
        "Algoritmos de Clasificación: K-Nearest Neighbors": [
          "Introducción a la Clasificación",
          "Algoritmo K-Nearest Neighbors",
          "Ejemplo de KNN",
          "K-Nearest Neighbours (KNN) con python",
          "Implementación en Python: Importación de las bibliotecas necesarias",
          "Implementación en Python: Importación del conjunto de datos",
          "Implementación en Python: División de los datos en conjuntos de ensayo y prueba",
          "Implementación en Python: Escalado de características",
          "Implementación en Python: Importación del clasificador KNN",
          "Implementación en Python: Predicción de resultados y matriz de confusión",
          "Momento del Quiz"
        ],
        "Algoritmos de Clasificación: Árbol de Decisión": [
          "Introducción a los Árboles de Decisión",
          "¿Qué es la Entropía?",
          "Exploración del conjunto de datos",
          "Estructura del Árbol de Decisión",
          "Implementación en Python: Importación de bibliotecas y conjuntos de datos",
          "Implementación en Python: Codificación de datos categóricos",
          "Implementación en Python: División de datos en conjuntos entrenamiento y prueba",
          "Implementación en Python: Predicción de resultados y precisión",
          "Momento del Quiz"
        ],
        "Algoritmos de Clasificación: Regresión Logística": [
          "Introducción",
          "Pasos de implementación",
          "Implementación en Python: Importación de bibliotecas y conjuntos de datos",
          "Implementación en Python: División de los datos en conjuntos de ensayo y prueba",
          "Implementación en Python: Pre-procesamiento",
          "Implementación en Python: Entrenamiento del modelo",
          "Implementación en Python: Predicción de resultados y matriz de confusión",
          "Regresión logística vs Regresión lineal",
          "Momento del Quiz"
        ],
        "Clustering": [
          "Introducción al clustering",
          "Casos prácticos",
          "Algoritmo de clustering K-Means",
          "Método Elbow",
          "Pasos del método Elbow",
          "Implementación en Python",
          "Clustering jerárquico",
          "Clustering basado en la densidad",
          "Implementación del clustering k-means en Python",
          "Importación del conjunto de datos",
          "Visualización del conjunto de datos",
          "Definir el clasificador",
          "Visualización 3D de los clusters",
          "Visualización 3D de los valores predichos",
          "Número de clusters predichos",
          "Momento del Quiz"
        ],
        "Sistema de Recomendación": [
          "Introducción",
          "El filtrado colaborativo en los sistemas de recomendación",
          "Sistema de recomendación basado en contenidos",
          "Implementación en Python: Importación de bibliotecas y conjuntos de datos",
          "Fusión de conjuntos de datos en un marco de datos",
          "Clasificación por título y puntuación",
          "Histograma del número de valoraciones",
          "Distribución de frecuencias",
          "Gráfico conjunto de las valoraciones y el número de valoraciones",
          "Preprocesamiento de datos",
          "Clasificación de las películas más valoradas",
          "Obtención de las valoraciones de dos películas",
          "Correlación entre las películas más valoradas",
          "Ordenación de los datos por correlación",
          "Filtrado de películas",
          "Ordenar valores",
          "Repetición del proceso para otra película",
          "Momento del Quiz"
        ],
        "Conclusión": [
          "Conclusión"
        ]
      },
      "requirements": [
        "Experiencia con los fundamentos de Python",
        "Disposición, flexibilidad y pasión por el aprendizaje",
        "Conocimientos matemáticos básicos"
      ],
      "description": "Para entender cómo organizaciones como Google, Amazon e incluso Udemy utilizan el Machine Learning y la inteligencia artificial (IA) para extraer el significado y los conocimientos de enormes conjuntos de datos , este curso de Machine Learning te proporciona lo esencial. Según Glassdoor y Indeed, los científicos de datos ganaron un sueldo medio de 120.000 dólares, ¡y eso es solo la norma!\n\n\nCuando se trata de ser atractivo, los científicos de datos ya lo son. En un mercado laboral altamente competitivo, es difícil retenerlos una vez contratados. Las personas con una mezcla única de formación científica, experiencia informática y capacidad de análisis son difíciles de encontrar.\n\n\nAl igual que los \"quants\" de Wall Street de los años ochenta y noventa, se espera que los científicos de datos de hoy en día tengan un conjunto de habilidades similares. Las personas con formación en física y matemáticas acudieron a los bancos de inversión ya los fondos de cobertura en aquella época porque pudieron idear algoritmos y métodos de datos novedosos.\n\n\nDicho esto, la ciencia de los datos se está convirtiendo en una de las ocupaciones más adecuadas para el éxito en el siglo XXI. Se trata de una profesión informatizada, basada en la programación y de naturaleza analítica. Por lo tanto, no es de extrañar que la necesidad de científicos de datos haya preocupado en el mercado laboral en los últimos años.\n\n\nLa oferta, en cambio, ha sido bastante restringida. Es un reto conseguir los conocimientos y habilidades necesarios para ser contratado como científico de datos .\n\n\nEn este curso, las notaciones y matemáticas la jerga se reducen a lo más básico, cada tema se explica en un lenguaje sencillo, lo que facilita su comprensión. Una vez que tengas en tus manos el código, podrás jugar con él y construir sobre él. El énfasis de este curso está en entender y usar estos algoritmos en el mundo real , no en un contexto teórico o académico.\n\n\nSaldrás de cada vídeo con una nueva idea que podrás poner en práctica de inmediato.\n\n\nTodos los niveles de habilidad son bienvenidos en este curso, e incluso si no tienes experiencia estadística previa, ¡podrás tener éxito!",
      "target_audience": [
        "Cualquier persona que quiera seguir una carrera relacionada con Machine Learning",
        "Cualquier entusiasta de la programación en Python que desee añadir a sus conocimientos \"Machine Learning\"",
        "Tecnólogos con curiosidad por saber cómo funciona el Machine Learning en el mundo real",
        "Programadores que buscan añadir Machine Learning a su conjunto de habilidades"
      ]
    },
    {
      "title": "Ciência de Dados para Empresas e Negócios",
      "url": "https://www.udemy.com/course/ciencia-de-dados-para-empresas-e-negocios/",
      "bio": "Data Science aplicado em 6 problemas reais de negócios! Marketing, vendas, RH, relações públicas, medicina e produção",
      "objectives": [
        "Desenvolva um modelo de IA para reduzir os custos de contratação e treinamento de funcionários, prevendo quais funcionários podem deixar a empresa",
        "Otimize a estratégia de marketing realizando segmentação de clientes",
        "Implemente um modelo de Deep Learning para automatizar e otimizar os processos de detecção de doenças em um hospital, utilizando imagens de raio-x",
        "Desenvolva modelos de previsão de série temporal para prever preços futuros de produtos utilizando o Facebook Prophet",
        "Desenvolva modelos de processamento de linguagem natural para analisar comentários de clientes e identificar o sentimento dos textos",
        "Crie uma IA avançada para classificar peças defeituosas e encontrar a localização dos defeitos nas imagens"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Data Science",
          "Recursos para download"
        ],
        "Departamento de recursos humanos": [
          "Estudo de caso",
          "Importação das bibliotecas e base de dados",
          "Exploração da base de dados 1",
          "Exploração da base de dados 2",
          "Exploração da base de dados 3",
          "Exploração da base de dados 4",
          "Pré-processamento dos dados",
          "Intuição sobre Regressão Lógistica, Random Forest e Redes neurais",
          "KPIs/métricas para classificação",
          "Regressão logística - implementação 1",
          "Regressão logística - implementação 2",
          "Random forest - implementação",
          "Redes neurais artificiais - implementação",
          "Salvar o classificador"
        ],
        "Departamento de marketing": [
          "Estudo de caso",
          "Importação das bibliotecas e base de dados",
          "Pré-processamento dos dados",
          "Visualização e exploração dos dados",
          "Intuição sobre o algoritmo k-means",
          "Obtenção do número de clusters",
          "K-means em segmentação de mercado 1",
          "K-means em segmentação de mercado 2",
          "Intuição e implementação de PCA (Principal Component Analysis)",
          "Intuição sobre autoencoders",
          "Construção e treinamento de autoencoders 1",
          "Construção e treinamento de autoencoders 2"
        ],
        "Departamento de vendas": [
          "Estudo de caso",
          "Importação da base de dados 1",
          "Importação da base de dados 2",
          "Exploração dos dados 1",
          "Exploração dos dados 2",
          "Exploração dos dados 3",
          "Exploração dos dados 4",
          "Intuição sobre o Facebook Prophet",
          "Previsões de vendas 1",
          "Previsões de vendas 2 - feriados"
        ],
        "Departamento médico": [
          "Estudo de caso",
          "Carregamento da base de dados",
          "Visualização dos dados",
          "Intuição sobre redes neurais convolucionais",
          "Intuição sobre transferência de aprendizagem",
          "Carregamento da rede neural pré-treinada",
          "Construção e treinamento da ResNet",
          "Avaliação da rede neural 1",
          "Avaliação da rede neural 2",
          "Classificação de uma imagem"
        ],
        "Departamento de relações públicas": [
          "Estudo de caso",
          "Importação das bibliotecas e base de dados",
          "Exploração dos dados 1",
          "Exploração dos dados 2",
          "Limpeza dos dados",
          "Remoção de pontuação",
          "Remoção de stop words",
          "Tokenização e count vectorization",
          "Pipeline para limpeza dos textos",
          "Intuição sobre o algoritmo Naïve Bayes",
          "Treinamento e avaliação do Naïve Bayes",
          "Treinamento e avaliação da regressão logística",
          "Classificação de uma frase"
        ],
        "Departamento de produção e manutenção": [
          "Estudo de caso",
          "Conceitos sobre segmentação de imagens",
          "Importação das bibliotecas e base de dados",
          "Visualização e exploração dos dados 1",
          "Visualização e exploração dos dados 2",
          "Construção e treinamento da ResNet 1",
          "Construção e treinamento da ResNet 2",
          "Avaliação da ResNet",
          "Intuição sobre segmentação com ResUnet",
          "Construção da ResUnet 1",
          "Construção da ResUnet 2",
          "Treinamento da ResUnet",
          "Avaliação da ResUnet e resultados"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Conhecimentos básicos sobre a linguagem de programação Python são desejáveis",
        "Conhecimentos básicos sobre machine learning"
      ],
      "description": "Você está procurando um emprego bem remunerado na área de Ciência de Dados? Ou você é um praticante experiente de inteligência artificial que quer levar sua carreira para o próximo nível? Ou você é um aspirante a empresário que deseja maximizar a receita de seus negócios utilizando Data Science e Inteligência Artificial?\nSe sua resposta for sim para alguma dessas perguntas, então este curso é para você! Ciência de Dados é um dos campos da tecnologia mais importantes para se estar agora! Essa área está apresentando inúmeras oportunidades e muitas perspectivas de carreira, sendo amplamente adotada em muitos setores, como bancos, área da saúde, transporte e tecnologia. Na área de negócios, Data Science é aplicado para otimizar processos, maximizar receitas e reduzir custos. Devido a isso, o objetivo deste curso é fornecer a você o conhecimento dos principais aspectos das aplicações de ciência de dados em negócios de uma forma prática e fácil. O curso lhe oferece experiência prática usando dados do mundo real!\nDurante as aulas, vamos assumir que você é um cientista de dados e que trabalhará como consultor para vários clientes nos seguintes departamentos: (1) Recursos humanos, (2) Marketing, (3) Vendas, (4) Medicina, (5) Relações públicas e (6) Produção/manutenção. Você receberá conjuntos de dados de todos esses departamentos para realizar as seguintes tarefas:\nDepartamento de Recursos Humanos: desenvolvimento de um modelo de IA para reduzir os custos de contratação e treinamento de funcionários, prevendo quais funcionários podem deixar a empresa\nDepartamento de Marketing: otimização da estratégia de marketing realizando a segmentação de clientes\nDepartamento de Vendas: implementação de séries temporais para prever preços futuros de produtos\nDepartamento Médico: desenvolvimento de um modelo de Deep Learning para automatizar e otimizar os processos de detecção de doenças em um hospital, utilizando imagens de raio-x\nDepartamento de Relações Públicas: criação de modelos de processamento de linguagem natural para analisar comentários de clientes nas mídias sociais para identificação de sentimentos\nDepartamentos de Produção e Manutenção: desenvolvimento de redes neurais para detectar defeitos em peças, bem como localizar os defeitos nas peças defeituosas\nDurante os seis estudos de caso, você vai aprender várias técnicas de Ciência de Dados, Machine Learning e Deep Learning, como por exemplo: visualização e exploração de dados, tratamento de valores faltantes, algoritmos básicos e avançados de aprendizagem de máquina, avaliação de resultados de algoritmos, agrupamento com k-means, Facebook Prophet para séries temporais, redes neurais artificiais, redes neurais convolucionais, transferência de aprendizagem, segmentação de imagens, processamento de linguagem natural e vários outros assuntos!\nTodos os estudos de casos serão implementados passo a passo utilizando a linguagem de programação Python e o Google Colab on-line, dessa forma, você só precisa ter um navegador e uma conexão com a internet para assistir as aulas. Não é necessário instalar nenhum software em seu computador!",
      "target_audience": [
        "Proprietários de negócios que desejam aproveitar o poder da ciência de dados e da inteligência artificial para maximizar a receita, reduzir custos e otimizar seus negócios",
        "Praticantes de ciência de dados que desejam avançar em suas carreiras e construir seu portfólio",
        "Entusiastas de tecnologia que são apaixonados por ciência de dados e IA e desejam obter experiência prática no mundo real",
        "Qualquer pessoa interessada em inteligência artificial, ciência de dados, machine learning ou deep learning",
        "Estudantes de graduação que estejam cursando disciplinas sobre este assunto",
        "Consultores ou futuros consultores que desejam transformar empresas, aproveitando a ciência de dados e IA"
      ]
    },
    {
      "title": "LLM Profi: OpenAI, Gemini, Claude, Llama3, ChatGPT & APIs",
      "url": "https://www.udemy.com/course/llm-mastery-openai-gemini-claude-llama-3-chatgpt-mehr/",
      "bio": "Basics bis zum KI-Agent: OpenAI API, Gemini API, Opensource LLMs, GPT-4o, RAG, LangChain Apps, Colab, Prompt Engineering",
      "objectives": [
        "Funktionsweise von LLMs: Parameter, Gewichte, Inference und neuronale Netze",
        "Neuronale Netzwerke verstehen",
        "Arbeitsweise neuronaler Netze mit Tokens in LLMs",
        "Transformer-Architektur und Mixture of Experts",
        "Finetuning und die Entstehung des Assistant-Modells",
        "Reinforcement Learning (RLHF) bei LLMs",
        "LLM Scaling Laws: GPU & Daten für Verbesserungen",
        "Fähigkeiten und zukünftige Entwicklungen von LLMs",
        "Nutzung von Tools durch LLMs: Taschenrechner, Python-Bibliotheken und mehr",
        "Multimodalität und visuelle Verarbeitung mit LLMs",
        "Multimodalität in der Sprache wie im Film \"Her\"",
        "Systemdenken und Zukunftsaussichten für LLMs",
        "Selbstverbesserung nach AlphaGo (Self-Improvement)",
        "Verbesserungsmöglichkeiten: Prompts, RAG und Customization",
        "Prompt Engineering: Effektive Nutzung von LLMs mit Chain of Thought und Tree of Thoughts Prompting & mehr",
        "Anpassung von LLMs durch Systemprompts und Personalisierung mit ChatGPT Memory",
        "Langzeitgedächtnis mit RAG und GPTs",
        "Der GPT Store: Alles, was du wissen musst",
        "Einsatz von GPTs zur Datenanalyse, für PDFs oder zur Tetris-Programmierung",
        "Embeddings und Vektordatenbanken für RAG",
        "Zapier-Aktionen in GPTs integrieren",
        "Open-Source vs. Closed-Source LLMs",
        "API Grundlagen",
        "Nutzung der Google Gemini API und Claude API",
        "Microsoft Copilot und seine Nutzung in Microsoft 365",
        "GitHub Copilot: Die Lösung für Programmierer",
        "Die OpenAI API: Funktionen, Preismodelle und alles was du zur OpenAI API wissen musst inklusive der erstellunbg von Apps",
        "Einführung in Google Colab für API-Calls an OpenAI",
        "Erstellung von KI-Apps und Chatbots",
        "Erstellung von KI-Agenten \"AI-Agents\" für verschiedene Aufgaben",
        "Sicherheit bei LLMs: Jailbreaks und Prompt Injections",
        "Vergleich der besten LLMs",
        "Google Gemini im Standard-Interface und Google Labs mit NotebookLM",
        "Claude von Anthropic: Überblick",
        "Alles zu Perplexity und POE",
        "OpenAI Playground: Funktionen, Billing Account & Temperatur",
        "Google Gemini API: Videoanalyse und mehr",
        "Open-Source LLMs: Modelle und Nutzung von Llama 3, Mixtral, Command R+ und viele mehr",
        "HuggingChat: Interface für Open-Source LLMs",
        "Groq: Schnellstes Interface mit LPU",
        "Installation von LM Studio zur verwendung von Lokalen Opensource LLMs für maximale Sicherheit",
        "Nutzung von Open-Source-Modellen in LM Studio und Zensierte vs. unzensierte LLMs",
        "Finetuning eines Open-Source-Modells mit Huggingface",
        "Erstellung eigener Apps über APIs in Google Colab mit Dall-E, Whisper, GPT-4o, Vision und mehr",
        "Microsoft Autogen für KI-Agenten",
        "CrewAI für KI-Agenten",
        "Flowise mit Function Calling",
        "Flowise mit Open-Source LLM als ChatBot",
        "Sicherheit bei LLMs und Methoden zum Hacken von LLMs",
        "Zukunft von LLMs als Betriebssystem in Robotern und PCs"
      ],
      "course_content": {
        "Einleitung und Überblick": [
          "Willkommen",
          "Kurs Überblick",
          "Mein Ziel und ein paar Tipps",
          "Erklärung der Links und Downloads",
          "Wichtige Links",
          "Dozentenvorstellung: Arnold Oberleiter (Arnie)"
        ],
        "Funktionsweise von LLMs: Parameter, Gewichte, Inference, neuronale Netze & mehr": [
          "Worum geht es in diesem Abschnitt",
          "Ein LLM besteht aus nur zwei Dateien: Parameterdatei und ein paar Zeilen Code",
          "Wie erfolgt die Erstellung der Parameter? Pretraining (Erstes Training des LLM)",
          "Was versteht man unter einem neuronalen Netzwerk",
          "Wie arbeitet ein neuronales Netz in einem LLM mit Tokens",
          "Die Transformer-Architektur ist uns noch nicht vollständig klar",
          "Andere Möglichkeiten der Transformer-Architektur: Mixture of Experts erklärt",
          "Nach dem Pretraining folgt das Finetuning: Das Assistant-Modell entsteht",
          "Der abschließende Schritt: Reinforcement Learning (RLHF)",
          "LLM Scaling Laws: LLM zu verbessern, benötigen wir nur zwei Dinge, GPU & Daten",
          "Rückblick: Was hast du bis jetzt gelernt"
        ],
        "Weitere Fähigkeiten von LLMs & zukünftige Entwicklungen": [
          "Worum geht es in diesem Abschnitt?",
          "LLMs können diverse Tools nutzen, wie Taschenrechner, Python-Bibliotheken usw.",
          "Multimodalität, Visuelle Verarbeitung (Vision) und Bilderkennung",
          "Multimodalität mit Sprache wie im Film \"Her\"",
          "Was könnte in Zukunft passieren? Systemdenken! [Thinking fast and slow]",
          "Systemdenken ist da!",
          "Selbstverbesserung nach dem Vorbild von AlphaGo (Self-Improvement)",
          "Weitere Möglichkeiten, LLMs zu verbessern: Prompts, RAG, Customization",
          "LLMs als neues Betriebssystem: So könnte die Zukunft aussehen.",
          "Rückblick: Was hast du in diesem Abschnitt gelernt"
        ],
        "Prompt Engineering: Effektive Nutzung von LLMs im Standard-Interface": [
          "Worum geht es in deisem Abschnitt und das Interface von LLMs",
          "Warum ist Prompt Engineering wichtig? Ein Beispiel!",
          "Behalte das Tokenlimit im Auge!",
          "Prompt Engineering Basics: Semantische Assoziation",
          "Prompt Engineering für LLMs die einfachsten strategien.",
          "Chain of Thougth Prompting: Schritt für Schritt ans Ziel",
          "Tree of Thoughts (ToT) prompting",
          "Revers Prompt Engineering, Priming, OK Befehl und das Tokenlimit.",
          "Einige Beispiele zur Anwendung von klassischen LLMs",
          "Rückblick und erinnere dich daran!"
        ],
        "LLM-Anpassung: Systemprompts und die Erstellung von Expertenmodellen bzw. GPTs": [
          "Worum geht es in diesem Abschnitt?",
          "Die einfachste Form der Personalisierung: ChatGPT Memory (Das Gedächtnis)",
          "Was ist ein VPN und warum ist es sinnvoll",
          "Anpassung durch Systemprompts und Custom Instructions",
          "In-Kontext Learning im Chat: Das \"Kurzzeitgedächtniss\" (aber effizient mit SPR)",
          "Langzeitgedächtnis mit RAG: GPTs & RAG einfach gestalten",
          "Der GPT Store: Alles, was du wissen musst",
          "Einsatz von GPTs zur Datenanalyse und für PDFs",
          "Embeddings und Vektordatenbanken für RAG: Eine detaillierte Erklärung",
          "Tetris-Programmierung mithilfe eines GPTs aus dem Store.",
          "Zwei Möglichkeiten, mit GPTs Geld zu verdienen",
          "Erstellung eines Builder-Accounts",
          "Entwickle ein effektives GPT für den Store zur Lead-Generierung",
          "Was ist eine API?",
          "Zapier-Aktionen in GPTs: Mails, Docs, YouTube & mehr aus dem ChatGPT Interface",
          "Fünf Tipps zur Verbesserung von GPTs und Nutzung externer APIs",
          "Zusammenfassung: Was du in diesem Abschnitt gelernt hast"
        ],
        "Closed-Source LLMs: Ein Überblick über die verfügbaren Modelle": [
          "Open-Source vs. Closed-Source LLMs",
          "Google Gemini im Standard-Interface verwenden",
          "Google Labs mit NotebookLM: Die beste Methode, um Bücher zu lernen",
          "Claude von Anthropic: Ein Überblick",
          "Die führenden Unternehmen sind OpenAI, Google & Anthropic, viele bauen darauf",
          "Perplexity, Vor- und Nachteile sowie Anwendungsgebiete.",
          "Poe, Die vielseitige All-in-One-Plattform",
          "Microsoft Copilot: Partnerschaft zwischen Microsoft und OpenAI",
          "Wie funktioniert Copilot genau, und sind meine Daten sicher?",
          "Nutzung von Microsoft Copilot im Web-Interface",
          "Microsoft 365: Unterschiede kostenloses & kostenpflichtiges Abo",
          "WICHTIG: Das passende Copilot-Abo und eine kostenlose Alternative",
          "Copilot-Abo, wenn du ein großes Unternehmen hast",
          "Copilot in Microsoft Word, schreibe so schnell wie nie",
          "Copilot in Microsoft PowerPoint, die schnelle Präsentation",
          "Copilot in Microsoft Outlook, schreibe und beantworte deine Mails schneller",
          "Copilot in Microsoft Excel, große Möglichkeiten aber aktuell noch etwas zu früh",
          "Microsoft Copilot GPTs",
          "GitHub Copilot, Die KI-Lösung für Programmierer",
          "Fazit zum Microsoft Copilot",
          "Rückblick zu den Closed-Source LLMs"
        ],
        "APIs der Closed-Source LLMs": [
          "Worum geht es hier? APIs der Closed-Source LLMs",
          "Die OpenAI API im Überblick",
          "Preismodelle der OpenAI API",
          "OpenAI Playground: Funktionen für Entwickler, Billing Account & Temperatur",
          "Die Google Gemini API: Videoanalyse und weitere Funktionen",
          "Die API von Claude",
          "Zusammenfassung der Closed-Source APIs"
        ],
        "Open-Source LLMs: Verfügbare Modelle und ihre Nutzung in Claude & lokal": [
          "Was sind Open-Source LLMs und welche gibt es",
          "Huggingface: Eine Einführung",
          "HuggingChat: Ein Interface für die Nutzung von Open-Source LLMs",
          "Groq: Das schnellste Interface mit einer LPU statt einer GPU",
          "Installation von LM Studio und alternative Methoden zum Betrieb von LLMs",
          "Open-Source-Modelle in LM Studio nutzen: Llama3, Mistral & mehr",
          "DeepSeek R1 Details als Artikel (neues Chinesisches LLM)",
          "DeepSeek R1: Lokale Installation, API und im Browser",
          "Zensierte vs. unzensierte LLMs (Llama 3 Dolphin)",
          "Finetuning eines Open-Source-Modells mit Huggingface",
          "Eigenen lokalen Server mit LM Studio einrichten",
          "Das neue Llama 3.1 Modell von Meta",
          "Das solltest du dir merken"
        ],
        "Erste Schritte zur Erstellung eigener Apps über APIs in Google Colab": [
          "Worum geht es in diesem Abschnitt",
          "GitHub Überblick: Warum sollte ich einen Account haben",
          "Einführung in Google Colab",
          "Das wirst du in Google Colab erstellen.",
          "Unser erster API-Call an OpenAI in Google Colab",
          "DALL-E über die OpenAI API in Google Colab (Bildgeneriereung)",
          "Text-to-Speech (TTS) mit der OpenAI API in Google Colab",
          "Transkribieren mit Whisper über die OpenAI API in Google Colab",
          "Bilderkennung mit Vision über die OpenAI API in Google Colab",
          "Dein gesamtes Notebook im Überblick",
          "Was du hier gelernt hast"
        ],
        "Apps, Chatbots und KI-Agenten! \"AI Agents\" für Automationen": [
          "KI-Agenten: Definition und verfügbare Tools zum Erstellen der Apps und Helfer",
          "Das Interface von Vectorshift für KI-Agenten (Ai-Agents) und KI-Apps",
          "Das Grundgerüst des ersten Chatbots: Die ersten schritte zur KI-App",
          "Wissen durch RAG: KI-Agent an Daten trainieren mit automatischen Updates",
          "Bot-Deployment: Als eigenständige App, in WhatsApp, Slack oder auf Webseiten",
          "\"Echte KI-Agent\" mit mehreren Experten erstellen: Das sind AI-Agents",
          "Der KI-Agent erklärt und die Möglichkeiten, ihn einzubauen",
          "Autogen, Langchain, Langflow oder CrewAI: Was denn nun? Muss ich Python lernen?",
          "Flowise: Aufgebaut auf Langchain +LangGraph, ähnlich wie LangFlow +AutoGen &mehr",
          "3 Möglichkeiten Flowise zu betreiben: Lokal mit Node.js oder extern",
          "Installation von Flowise mit Node.js (Javascript-Laufzeitumgebung)",
          "Das Flowise-Interface: Einfacher als Langchain und LangGraph",
          "Flowise Basics: Unsere erste Langchain App",
          "Q&A Chain, Memory & RAG: Herausforderungen und Probleme",
          "Function Calling, Memory & RAG: Einfach gemacht mit der OpenAI Assistant API",
          "Lokaler RAG-Chatbot mit LLama3 & Ollama: Eine lokale Langchain-App",
          "KI-Agenten wie mit Langchain + LangGraph oder Autogen und CrewAI (mit Flowise)",
          "KI-Agent im Langchain-Stil mit 5 Experten für Social Media",
          "Einschränkungen & zusätzliche Möglichkeiten von KI-Agenten mit Langchain",
          "Chatbots für Kunden extern auf Render hosten",
          "Integration eines Chatbots in Webseiten: HTML, Wordpress, Shopify Seite & mehr",
          "Flowise Tipps: API Endpunkte, Spracherkennung & mehr",
          "Kostenlosen Chatbot mit Open-Source-Modellen und Tools erstellen",
          "Sagenhaft schnelle Inferenz mit der Groq-API",
          "Sieh dich im Marketplace um: If Else und mehr",
          "Microsoft Autogen im Überblick",
          "Rückblick und was du machen solltest"
        ]
      },
      "requirements": [
        "Keine Vorkenntnisse nötig, alles wird Schritt für Schritt gezeigt"
      ],
      "description": "Schon mal darüber nachgedacht, wie große Sprachmodelle (LLMs) die Welt verändern und beispiellose Chancen schaffen?\n\"KI wird deinen Job nicht übernehmen, aber jemand, der weiß, wie man KI nutzt, könnte es tun,\" sagt Richard Baldwin.\nBist du bereit, die Feinheiten von LLMs zu meistern und ihr volles Potenzial für verschiedene Anwendungen zu nutzen, von Datenanalyse bis zur Erstellung von Chatbots und KI-Agenten?\nDann ist dieser Kurs für dich!\nTauche ein in 'LLM Mastery: OpenAI, Gemini, Claude, Llama 3, ChatGPT & APIs'—wo du die grundlegenden und fortgeschrittenen Konzepte von LLMs, ihre Architekturen und praktischen Anwendungen erforschen wirst. Verändere dein Verständnis und deine Fähigkeiten, um die Führung in der KI-Revolution zu übernehmen.\nDieser Kurs ist perfekt für Entwickler, Datenwissenschaftler, KI-Enthusiasten und alle, die an der Spitze der Technologie von LLMs stehen möchten. Egal ob du neuronale Netzwerke verstehen, KI-Modelle feinabstimmen oder KI-gesteuerte Anwendungen entwickeln möchtest, dieser Kurs bietet dir alles, was du brauchst.\nWas dich in diesem Kurs erwartet:\nUmfassendes Wissen über LLMs:\nVerständnis von LLMs: Lerne über Parameter, Gewichte, Inferenz und neuronale Netze.\nNeuronale Netzwerke: Verstehe die Funktionsweise neuronaler Netze mit Tokens in LLMs.\nTransformer-Architektur: Erforsche die Transformer-Architektur und Mixture of Experts.\nFeinabstimmung: Verstehe den Prozess der Feinabstimmung und die Entwicklung des Assistant-Modells.\nReinforcement Learning (RLHF): Tauche ein in Reinforcement Learning mit menschlichem Feedback.\nFortgeschrittene Techniken und zukünftige Trends:\nScaling Laws: Lerne über Skalierungsgesetze von LLMs, einschließlich GPU- und Datenverbesserungen.\nZukunft der LLMs: Entdecke die Fähigkeiten und zukünftigen Entwicklungen in der LLM-Technologie.\nMultimodale Verarbeitung: Verstehe Multimodalität und visuelle Verarbeitung mit LLMs, inspiriert von Filmen wie \"Her.\"\nPraktische Fähigkeiten und Anwendungen:\nWerkzeugnutzung: Nutze Werkzeuge mit LLMs wie Taschenrechner und Python-Bibliotheken.\nSystemdenken: Tauche ein in Systemdenken und Zukunftsperspektiven für LLMs.\nSelbstverbesserung: Lerne Methoden zur Selbstverbesserung nach AlphaGo.\nOptimierungstechniken: Verbessere die Leistung von LLMs mit Prompts, RAG, Function Calling und Anpassung.\nPrompt-Engineering:\nFortgeschrittene Prompts: Meistere Techniken wie Chain of Thought und Tree of Thoughts Prompting.\nAnpassung: Passe LLMs mit Systemprompts an und personalisiere mit ChatGPT Memory.\nLangzeitgedächtnis: Implementiere RAG und GPTs für Langzeitgedächtnisfähigkeiten.\nAPI- und Integrationsfähigkeiten:\nAPI-Grundlagen: Verstehe die Grundlagen der API-Nutzung, einschließlich der OpenAI API, Google Gemini und Claude APIs.\nMicrosoft und GitHub Copilot: Nutze Microsoft Copilot in 365 und GitHub Copilot für Programmierung.\nOpenAI API-Meisterschaft: Erforsche die Funktionen, Preismodelle und App-Erstellung mit der OpenAI API.\nKI-App-Entwicklung:\nGoogle Colab: Lerne API-Calls an OpenAI mit Google Colab.\nKI-Agenten: Erstelle KI-Agenten für verschiedene Aufgaben in LangChain Frameworks wie Langgraph, Langflow, Vectorshift, Autogen, CrewAI, Flowise und mehr.\nSicherheit: Sorge für Sicherheit mit Methoden zur Verhinderung von Jailbreaks und Prompt-Injections.\nVergleichende Einblicke:\nVergleich der besten LLMs: Vergleiche die besten LLMs, einschließlich Google Gemini, Claude und mehr.\nOpen-Source-Modelle: Erforsche und nutze Open-Source-Modelle wie Llama 3, Mixtral und Command R+ mit der Möglichkeit, alles lokal auf deinem PC zu verwenden für maximale Sicherheit.\nPraktische Anwendungen:\nEmbedding und Vektordatenbanken: Implementiere Embeddings für RAG.\nZapier-Integration: Integriere Zapier-Aktionen in GPTs.\nOpen-Source LLMs: Installiere und nutze LM Studio für lokale Open-Source-LLMs für maximale Sicherheit.\nFeinabstimmung von Modellen: Feinabstimmung von Open-Source-Modellen mit Huggingface.\nAPI-basierte App-Entwicklung: Erstelle Apps mit Dall-E, Whisper, GPT-4o, Vision und mehr in Google Colab.\nInnovative Werkzeuge und Agenten:\nMicrosoft Autogen: Nutze Microsoft Autogen zur Entwicklung von KI-Agenten.\nCrewAI: Entwickle KI-Agenten mit CrewAI.\nLangChain: Verstehe den Framework mit den Abteilungen wie LangGraph, LangFlow und mehr.\nFlowise: Implementiere Flowise mit Funktionsaufrufen und Open-Source LLM als Chatbot.\nEthische und Sicherheitsüberlegungen:\nLLM-Sicherheit: Verstehe und wende Sicherheitsmaßnahmen an, um Hacking zu verhindern.\nZukunft der LLMs: Erforsche das Potenzial von LLMs als Betriebssysteme in Robotern und PCs.\nDieser Kurs ist ideal für alle, die tiefer in die Welt der LLMs eintauchen möchten – von Entwicklern und Kreativen bis hin zu Unternehmern und KI-Enthusiasten.\nNutze die transformative Kraft der LLM-Technologie, um innovative Lösungen zu entwickeln und dein Verständnis ihrer vielfältigen Anwendungen zu erweitern.\nAm Ende von 'LLM Mastery: OpenAI, Gemini, Claude, Llama 3, ChatGPT & APIs' wirst du ein ganzheitliches Verständnis von LLMs, ihren Anwendungen und den Fähigkeiten haben, ihre Macht für verschiedene Zwecke zu nutzen. Wenn du bereit bist, eine transformative Reise in die KI anzutreten und dich an die Spitze dieser technologischen Revolution zu stellen, ist dieser Kurs genau das Richtige für dich.\nMelde dich noch heute an und beginne deine Reise, ein Experte in der Welt der großen Sprachmodelle zu werden!",
      "target_audience": [
        "An alle, die etwas neues lernen wollen und tief in die LLMs einblicken wollen",
        "An Unternehmer die effizienter werde wollen und Geld sparen möchten",
        "Privarpersonen, die an KI interessiert sind und eigene Modelle bauen möchten"
      ]
    },
    {
      "title": "Production ML 101 - MLOps/LLMOps",
      "url": "https://www.udemy.com/course/production-ml-101-mlopsllmops/",
      "bio": "Are you confused with so many tools out there in MLOps? Are you confused where to start your journey in MLOps?",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic understanding of ML algorithms"
      ],
      "description": "Are you looking to start your journey in ML in production? Are you confused with so many tools? Are you confused about where to start your journey?\nDid you know >50% of people discontinue their journey in ML in production because they feel overwhelmed.\nOur comprehensive course on MLOps in production is designed to help you do just that to teach you the proper approach to ML in production.\nAccording to the BCGs report, the pioneers of AI @ scale—the companies that have scaled AI across the business and achieved meaningful value from their investments—typically dedicate 10% of their AI investment to algorithms, 20% to technologies, and 70% to embedding AI into business processes and agile ways of working.\nWhy give so much importance to the tools? Rather emphasis should be given to the process.\nThis course is suitable for anyone looking to advance their machine learning skills, including Data engineers, ML engineers, Data Scientists, MLOps platform engineers, and MLOps Engineers. By the end of the course, you'll have a deep understanding of the major root causes of failure in ML in production, the fundamentals of MLOps, MLOps as a process and the future roadmap in ML in production.\nI have been working along with industry experts and industry mentors for the past year to understand the root causes in ML in production.",
      "target_audience": [
        "Beginner who wants to start their journey in ML in Production",
        "Starting point for Data Scientists, Data Engineers, ML Engineers, MLOps Engineers, Data Product Managers, Engineering Leader"
      ]
    },
    {
      "title": "Jupyter Notebook overview for all Python developers",
      "url": "https://www.udemy.com/course/jupyter-notebook-overview-for-all-python-developers/",
      "bio": "Introduction, Installation, walkthrough, Cell types, Modes, Magic Commands, Shortcuts, Publishing and Sharing",
      "objectives": [],
      "course_content": {
        "Course": [
          "Introduction",
          "Course Overview",
          "Anaconda Installation",
          "Jupyter Notebook Interface Walkthrough",
          "Cell Types & Modes",
          "Shortcuts & Magic Commands",
          "Publishing & Sharing Jupyter notebook",
          "Jupyter Notebook Extentions"
        ]
      },
      "requirements": [
        "There are no requirements or prerequisites for this course"
      ],
      "description": "This course is designed for all python developers who are eager to learn different features and functions of Jupyter notebook. This course will provide you complete knowledge and understanding of frequently used Jupyter notebook features. With the help of this course, your productivity and coding skills will reach the next level.\nThis course is for all the developers from beginners to advance, if you are a new Python developer or an experienced one, you will definitely learn something new in this course.\nWe'll start our course with an introduction to Anaconda and Jupyter notebook. After the introduction, Anaconda installation will be performed and I will show you how to start writing code in Jupyter Notebook. Our next step will be to go through Menu tabs and all options inside each tab to get familiar with their functions. We'll also look at Cell types, Modes, Shortcuts and Magic Commands. At the end we'll see how can we publish the Jupyter notebook file on a website or blog and how can we share it with other team members.",
      "target_audience": [
        "Python Developers",
        "Data Scientists",
        "Data Analysis"
      ]
    },
    {
      "title": "Introducción a la Ciencia de Datos",
      "url": "https://www.udemy.com/course/introduccion-al-data-science/",
      "bio": "Inicia tu carrera en la profesión más demandada del siglo XXI.",
      "objectives": [
        "Fundamentos básicos del Data Science",
        "El rol del Científico de Datos",
        "Contexto de la Ciencia de Datos",
        "Herramientas que usan los Científicos de Datos",
        "La Evolución del Científico de Datos"
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Filosofía del curso"
        ],
        "La Ciencia de Datos": [
          "¿Qué es la Ciencia de Datos?",
          "El proceso de la Ciencia de Datos",
          "Especialidades dentro de la Ciencia de Datos",
          "Principales Algoritmos en la Ciencia de Datos",
          "Las habilidades del Científico de Datos",
          "Importancia de las Habilidades del Científico de Datos",
          "Evolución al Científico de Datos",
          "Herramientas del Científico de Datos",
          "Roles del Científico de Datos"
        ],
        "Muestra de R en RStudio": [
          "RStudio",
          "Gráfico con Datos del Covid-19",
          "Gráfico con Datos de Población mundial",
          "Otros ejemplos en R"
        ],
        "Despedida": [
          "Reto analítico",
          "Cierre del curso"
        ]
      },
      "requirements": [
        "Ningún requisito previo para esta información del curso"
      ],
      "description": "¿Quieres entender la ciencia detrás de las decisiones inteligentes en negocios y tecnología?\nEste curso de Introducción a la Ciencia de Datos te abrirá las puertas a un mundo fascinante y en constante crecimiento.\nEn la era digital, la cantidad de datos generados es exponencial y las empresas que saben cómo interpretarlos y utilizarlos obtienen una ventaja competitiva inigualable. El Data Science ha surgido como la disciplina clave para transformar esta inmensidad de datos en valor estratégico. Desde el análisis de patrones de compra y comportamiento del cliente hasta la segmentación de mercados y la predicción de tendencias, las aplicaciones del Data Science son vastas y revolucionarias.\nEste curso te introducirá a los fundamentos esenciales del Data Science, explorando el rol crucial del Científico de Datos en las organizaciones modernas y las herramientas que utilizan estos profesionales. Descubrirás por qué el Científico de Datos ha sido aclamado como \"la profesión más sexy del siglo XXI\" y cómo puedes comenzar a construir tu camino en este campo apasionante y con enormes oportunidades profesionales.\nPrepárate para adquirir conocimientos valiosos que te permitirán:\nComprender los fundamentos esenciales del Data Science y su impacto en el mundo actual.\nIdentificar y describir el rol crucial del Científico de Datos en diversas industrias.\nAnalizar el contexto y la evolución de la Ciencia de Datos a lo largo del tiempo.\nConocer y diferenciar las herramientas clave utilizadas por los Científicos de Datos.\nEntender la trayectoria y la evolución profesional típica de un Científico de Datos.",
      "target_audience": [
        "Profesionales de Business Intelligence y Analítica de Datos que buscan expandir sus habilidades y conocimientos en Data Science.",
        "Personas con curiosidad por la Ciencia de Datos y su aplicación práctica en diversos sectores.",
        "Estudiantes y profesionales de diversas disciplinas interesados en iniciar una carrera en el campo de Data Science.",
        "Cualquier persona que desee comprender el poder de los datos y cómo se utilizan para la toma de decisiones estratégicas en el mundo actual."
      ]
    },
    {
      "title": "Finding Actionable Insights using Keras Autoencoders",
      "url": "https://www.udemy.com/course/finding-actionable-insights-using-autoencoders/",
      "bio": "Using Autoencoders to Better Understand your Customers - Measuring Customer Credit Risk",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction",
          "About me",
          "What is an Autoencoder and what is it good for?",
          "Preparing the Open Source Statlog - German Credit Data",
          "Quick classification look with AutoML",
          "Building our Keras Autoencoder",
          "Investigating anomalies"
        ]
      },
      "requirements": [
        "You should know a little Python, how to install Python libraries, and how to use Jupyter notebook"
      ],
      "description": "Please join me for another exciting data science class where we apply autoencoders or unsupervised learning towards the pursuit of knowledge.\n\nRemember at the end of the day modeling and data science don't mean much if we can't extract actual insights to help guide our customers, our friends, the research community in the advancement of whatever it is they are after using data. Autoencoders can help you better understand your data, answer your questions, and even discover new ones! Please join me on this exciting adventure!",
      "target_audience": [
        "Anybody wanting to analyze data",
        "Anybody wanting to perform anomaly detection",
        "Anybody interested in Autoencoders and machine learning with Keras"
      ]
    },
    {
      "title": "le Machine Learning avec Python",
      "url": "https://www.udemy.com/course/python-pour-la-data-science-et-machine-learning/",
      "bio": "Découvrir le Machine Learning sans se perdre dans les détails théoriques!",
      "objectives": [
        "Apprendre le Machine Learning avec Python",
        "Créez des visualisations de données en utilisant matplotlib avec python",
        "Utilisez l'environnement Google Collab Notebook.",
        "Explorer de grandes base de données à l'aide d'outils de visualisation de données comme Matplotlib",
        "Apprendre à utiliser la bibliothèque populaire Scikit-learn dans vos projets"
      ],
      "course_content": {
        "Introduction": [
          "Ce que vous allez apprendre",
          "Ce que vous allez apprendre"
        ],
        "Prise en main de Google Colab et Anaconda": [
          "La base de données à utiliser pour l'initiation à Anaconda",
          "Découverte des distributions de Python et la prise en main d'Anaconda",
          "Mise en place de notre environnement de travail (Google Colab)"
        ],
        "Les bases de Python (section optionnelle)": [
          "Plan de la section",
          "Introduction Python",
          "Partie 1: Les structures de base dans Python",
          "Les nombres",
          "Les variables",
          "Les chaines de caractères",
          "Les tuples",
          "Les dictionnaires",
          "Les sets",
          "Les variables booléennes",
          "Partie 2: Les formulations conditionnelles",
          "if, else, elif",
          "la boucle \"for\"",
          "la boucle \"while\"",
          "Partie 3: Les méthodes et les fonctions",
          "Les méthodes",
          "Les fonctions",
          "Partie 4: La programmation orientation objet",
          "Les classes",
          "Pypi et pip"
        ],
        "Rappel statistiques": [
          "Plan de la section",
          "intérêt des statistiques descriptives dans l'analyse des données",
          "Les types de données",
          "Le mode, la moyenne et la médiane",
          "L'écart type et la variance",
          "La visualisation"
        ],
        "Visualiser ses données avec Python": [
          "Comment dessiner des courbes?",
          "Utilisation du Subplot",
          "Comment dessiner un diagramme en bande?",
          "Comment dessiner un diagramme sectoriel",
          "Ce que nous avons vu dans cette section"
        ],
        "Découverte du package Pandas": [
          "Lire les données sur python",
          "Sélection des colonnes",
          "Ajouter et supprimer des colonnes"
        ],
        "Les base de données à utiliser dans les applications": [
          "Les bases de données"
        ],
        "Généralités sur Le Machine Learning": [
          "Introduction",
          "Les Applications du Machine Learning",
          "Les catégories du Machine Learning",
          "Principe général des algorithmes du Machine Learning",
          "La régression et La classification",
          "Notion de l'Overfitting",
          "Principe du Training Set et Test Set",
          "K-fold Cross Validation",
          "Plan d'attaque"
        ],
        "La régression linéaire": [
          "Introduction à la notion de la régression",
          "Etude préliminaire",
          "Importer les packages nécessaires",
          "Lire la base de données",
          "Visualiser les données",
          "Création du modèle",
          "Application du modèle",
          "Evaluation du modèle"
        ],
        "Regression lineaire multiple": [
          "A propos de la régression linéaire multiple",
          "Importer la base de données",
          "Découvrir la base de données",
          "Création du modèle",
          "Application et évaluation du modèle"
        ]
      },
      "requirements": [
        "Des connaissances de base en Python",
        "Avoir un ordinateur ( Mac, Windows, ou Linux)"
      ],
      "description": "Ce cours complet sera votre guide pour apprendre à utiliser la puissance de Python pour créer de superbes visualisations et utiliser de puissants algorithmes du Machine Learning sans rentrer dans les détails mathématiques!\nCe cours est conçu pour les débutants avec une certaine expérience en programmation ou les développeurs expérimentés qui cherchent à faire le saut vers Machine Learning!",
      "target_audience": [
        "Les personnes souhaitant se lancer en Machine Learning, la science des données et d'autres marchés porteurs de l'intelligence artificielle",
        "Les personnes connaissant les bases de Python et veulent le maîtriser",
        "Les personnes souhaitant créer de la valeur ajoutée pour leur entreprise en utilisant de puissants outils Machine Learning"
      ]
    },
    {
      "title": "Deep Learning A-Z™| Python ile Derin Öğrenme",
      "url": "https://www.udemy.com/course/derin-ogrenmeye-giris/",
      "bio": "Yapay Zeka hakkında hiç bilginiz olmasa dahi Python ile Deep Learning yöntemlerini uygulamalarla sıfırdan öğreniyoruz!",
      "objectives": [
        "Temel yapay sinir ağları çalışma şekli ve gerçek hayat problem çözümü",
        "Derin öğrenme modeli tasarlarken dikkat edilmesi gereken adımlar",
        "Evrişimli Sinir Ağları (CNN) çalışma şekli ve gerçek hayat problemi çözümü",
        "Özyinelemeli Sinir Ağları (RNN, LSTM) ile doğal dil işleme problemlerine uygulamalı çözümler",
        "Python kütüphanelerini kullanarak derin öğrenme modeli tasarlama",
        "Kapsül Ağları (Capsule Networks) yapısı ve çalışması",
        "Çekişmeli Üretici Ağlar (GAN) çalışma şekli",
        "Pekiştirmeli Öğrenme (RL) çalışma şekli",
        "Python programlama dilinde Tensorflow ve Keras kütüphaneleri kullanarak gerçek hayat problemlerine çözüm getirebilme becerisi"
      ],
      "course_content": {},
      "requirements": [
        "Yapay zekâ ile ilgili bilmeniz gereken her şeyi bu derste öğreneceksiniz",
        "Öğrenme isteği"
      ],
      "description": "Yapay zeka alanına giriş yapmak ve \"öğrenen\" uygulamalar geliştirmek istiyorsanız derin öğrenme yöntemlerini öğrenmek için sizi temelden ileri seviyeye kadar teorik anlatım ve pratik uygulamaları içeren bu kapsamlı \"Derin Öğrenmeye Giriş\" eğitimime davet ediyorum.\nEğitimi bitirdiğinizde, derin öğrenmenin temellerini, yapay sinir ağı modelleri oluşturma ve geliştirme adımlarını ve başarılı yapay öğrenme projelerini nasıl gerçekleştirebileceğinizi öğreneceksiniz. Uygulayacağımız yöntemler:\nTemel yapay sinir ağları,\nEvrişimli sinir ağları (CNN),\nÖzyinelemeli sinir ağları (RNN),\nUzun-kısa vadeli bellek modeli (LSTM),\nMakine öğrenmesinde optimizasyon ve regülarizasyon yöntemlerini,\nKapsül ağları,\nPekiştirmeli öğrenme (RL),\nÇekişmeli üretici ağları (GAN)\nTüm bu yöntemleri Python programlama dili kullanarak TensorFlow ve gerisinde çalışan Keras kütüphanelerinde uygulayacaksınız.\nYapay zeka ve derin öğrenme çoklu endüstrileri geliştirmekte ve dönüştürmektedir. Bu dersi tamamladıktan sonra, bunu işinize uygulamak için yaratıcı yollar bulabilirsiniz.",
      "target_audience": [
        "Geleceğin mesleklerinde yetkin olmak isteyen herkes",
        "Yapay zekaya ilgi duyan herkes",
        "Yapay sinir ağları ve derin sinir ağları geri planındaki matematiği öğrenmek isteyen herkes",
        "Derin öğrenme konusundaki teorik bilgisiyle gerçek hayat problemlerini çözmek isteyenler",
        "Python programlama dili ile TensorFlow ve Keras kütüphanelerini kullanarak kendi derin öğrenme modelini tasarlamak isteyenler"
      ]
    },
    {
      "title": "Deep Learning, Neuronale Netze & AI: Der Komplettkurs",
      "url": "https://www.udemy.com/course/deep-learning-und-ai/",
      "bio": "Der Komplettkurs mit Python, Keras und Tensorflow 2: Erkenne Bilder, sage den Bitcoin-Kurs vorher & schreibe eine AI!",
      "objectives": [
        "Verwende Keras und Tensorflow, um Neuronale Netze zu erstellen",
        "Entwickle eine Artificial Intelligence",
        "Entdecke Neuronale Netze und AI komplett am Beispiel",
        "Schreibe eine Bilderkennung, die Autos auf einem Bild markiert",
        "Entwickle ein Modell, um den Preis von Bitcoin und Aktien vorherzusagen",
        "Generiere Reden im Stil von Donald Trump"
      ],
      "course_content": {
        "Einleitung": [
          "Einleitung",
          "Download der Kursmaterialien",
          "Wichtiger Hinweis! (Windows)",
          "Installation unserer Python-Umgebung",
          "Was tun wenn: Jupyter startet nicht oder hat ein Problem",
          "Begriffsklärung (optional): Machine Learning, Neuronale Netze, Deep Learning, AI"
        ],
        "Crashkurs: Unsere Python-Umgebung": [
          "Crashkurs Jupyter",
          "Crashkurs Python",
          "Crashkurs Numpy"
        ],
        "Ein einzelnes Neuron": [
          "Ein einzelnes Neuron (Intuition)",
          "Ein einzelnes Neuron (in Python)",
          "Ein einzelnes Neuron mit Bias (Intuition)",
          "Ein einzelnes Neuron mit Bias (in Python)",
          "Aufgabe: Verbrauch von Autos vorhersagen",
          "Musterlösung: Verbrauch von Autos vorhersagen",
          "Aktivierungsfunktion (Intuition)",
          "Aktivierungsfunktion (in Python)",
          "Optionaler Exkurs: Warum lassen sich Neuronen nicht \"hintereinanderschalten\"?"
        ],
        "Neuronales Netz": [
          "Wie ist ein Neuronales Netz aufgebaut?",
          "Wie werden die Gewichte aktualisiert? - Teil 1",
          "Wie werden die Gewichte aktualisiert? - Teil 2",
          "Das Gradientenabstiegsverfahren",
          "Stochastic Gradient Descent",
          "So lernt das Netz: Backpropagation - Teil 1",
          "So lernt das Netz: Backpropagation - Teil 2"
        ],
        "Neuronales Netz (zur Regression)": [
          "Vorstellung: Keras und Tensorflow",
          "Hinweis: Keras",
          "Installation von Keras & Tensorflow",
          "Unser Projekt",
          "Unsere Daten",
          "Unser erstes Neuronales Netz",
          "Wir machen eine erste Vorhersage!",
          "Genauigkeit berechnen (manuell)",
          "Genauigkeit berechnen (mit Keras)",
          "Neuronales Netz validieren: Das train/test-Verfahren",
          "Neuronales Netz validieren: Das train/test-Verfahren (mit Keras)"
        ],
        "Ein Neuronales Netz mit mehreren Ausgängen": [
          "Ein Neuronales Netz mit mehreren Ausgängen (Intuition)",
          "Hinweis: to_categorical",
          "Wie beurteilen wir die Genauigkeit vom Netz?",
          "Wir generieren eine Confusion-Matrix",
          "Wahrscheinlichkeiten vorhersagen: Der Softmax (Intuition)",
          "Wahrscheinlichkeiten vorhersagen: Der Softmax (Keras)",
          "Aktivierungsfunktionen (Intuition)",
          "Aktivierungsfunktionen (mit Keras)",
          "Wie werden die Gewichte optimiert? Optimizer! (Intuition)",
          "Wie werden die Gewichte optimiert? Optimizer! (in Keras)",
          "Wie komplex darf überhaupt unser Netz sein?"
        ],
        "Bilderkennung mit Neuronalen Netzen (Convolutional Neural Networks)": [
          "Motivation: CNN",
          "Exkurs: Wie ist überhaupt ein Bild aufgebaut?",
          "Wie ist ein Convolutional-Neural-Network aufgebaut?",
          "CNN mit Keras (inkl. Aufgabe)",
          "CNN: Lösungstipps",
          "CNN: Musterlösung",
          "CNN: Wie werden die Gewichte aktualisiert?",
          "Hinweis CNN: Conv2D",
          "CNN: Wir schauen uns ein CNN genauer an: Aktiverungen visualisieren",
          "Grundlage für komplexere CNNs: Wie funktioniert ein MaxPooling-Layer?",
          "Max-Pooling (in Python)",
          "Link: Visualisierung eines CNNs",
          "Visualisierung eines CNNs",
          "Wir erhöhen unsere Genauigkeit: Dropout (Intuition)",
          "Wir erhöhen unsere Genauigkeit: Dropout (in Keras)"
        ],
        "Komplexe Netze - GPU in der Amazon-Cloud": [
          "WICHTIG: Kostenlose GPU möglich?",
          "Einführung: GPU in der Cloud",
          "[Mac only]: Vorbereitung für die nächsten paar Lektionen",
          "Vorbereitung für die Cloud: Exkurs PowerShell / Linux-Shell - Teil 1",
          "Vorbereitung für die Cloud: Exkurs PowerShell / Linux-Shell - Teil 2",
          "Vorstellung EC2: Welche Instanz-Typen kommen für uns in Frage?",
          "[Windows only]: SSH-Keygen not found",
          "Hinweis: Instanz in der Amazon-Cloud anmieten",
          "Hinweis: Deep Learning AMI",
          "Wir mieten einen Computer in der Amazon-Cloud an",
          "Jupyter in der Amazon-Cloud",
          "Kursmaterialien in die Cloud übertragen",
          "Was tun bei: ModuleNotFoundError in Jupyter auf der EC2-Instanz?",
          "Tipp: Prozessorauslastung & GPU-Auslastung der EC2-Instanz überwachen",
          "Wichtig: EC2-Instanz stoppen!",
          "Wichtig: Kosten sparen"
        ],
        "Kostenlose GPU in der Google-Cloud": [
          "Einführung: Kostenlose GPU in der Google-Cloud",
          "Wie verwendest du die kostenlose GPU in der Google-Cloud?"
        ],
        "Projekt: Wir erkennen Autos auf einem Bild - Teil 1": [
          "Vorstellung: Die Cifar-Daten",
          "Wir trainieren ein Netz auf den Cifar-Daten (Teil 1)",
          "Wir trainieren ein Netz auf den Cifar-Daten (Teil 2)",
          "Wir trainieren ein Netz auf den Cifar-Daten (Teil 3)",
          "Wir trainieren ein Netz auf den Cifar-Daten (Teil 4)",
          "Zusätzliche Daten generieren - Teil 1",
          "Zusätzliche Daten generieren - Teil 2 (optional)",
          "Hinweis zur nächsten Lektion",
          "Hinweis: Modell trainieren + abspeichern",
          "Wir trainieren das Modell mit den zusätzlichen Daten",
          "Training finalisieren, Modell abspeichern"
        ]
      },
      "requirements": [
        "Du solltest schonmal ein bisschen was programmiert haben",
        "Du solltest früher in der Schule in Mathe gut mitgekommen sein (selbst wenn du inzwischen alles wieder vergessen hast)"
      ],
      "description": "Bewertungen von Kursteilnehmern:\n\"Der absolute Wahnsinn unter den Kursen!!! [...]\" (★★★★★, Frank Meyer)\n\"Ich habe bereits schon mehrere Kurse in dieser Richtung absolviert und der gehört zu den Besten.\" (★★★★★, Mederitsch Patrick)\nKursbeschreibung:\nDieser Kurs macht dich fit auf deinem Weg zum Deep Learning- und AI-Spezialisten. Alle Themen werden anschaulich und am Beispiel erklärt - dadurch ist dieser Lehrgang besonders leicht verständlich.\nZudem beherrscht du nach Abschluss des Kurses problemlos Tools wie Jupyter, Keras, Tensorflow 2 umgehen - das ist wichtig, wenn du das Wissen später auf eigene Projekte anwenden möchtest.\nHier lernst du:\n... wie Neuronale Netze funktionieren\n... wie Neuronale Netze Objekte in Bildern erkennen können\n... wie mit Hilfe von Deep Learning Kunstwerke erstellt werden können\n... wie du eine Artificial Intelligence erstellen kannst\n... wie du das Wissen auf eigene Daten anwenden kannst\nDadurch hast du die Themen Deep Learning & AI komplett verstanden, und kannst sie auf deine Probleme anwenden.\nDas besondere an diesem Kurs sind die umfangreichen Praxisbeispiele:\nBilderkennung (ist auf einem Bild ein Auto zu sehen?)\nObjekterkennung (wo ist das Auto?)\nTextgenerierung im Stil von Donald Trump mit Tensorflow.js\nEntwickle eine Artificial Intelligence für ein Spiel (Flappy-Bird), die einen unglaublich hohen Highscore erreicht (10000+)\nBeschleunige die Berechnung mit einer Grafikkarte aus der Amazon-Cloud\nPraxis ist der Lernturbo!\nLerne verstärkt durch spannende, lebhafte Praxis!\nEin effektiver Lernprozess ist die optimale Kombination von Theorie und Praxis. Das Konzept hier in diesem Kurs sind möglichst viele Praxisprojekte - so bleiben selbst komplexe Themen anschaulich.\nDieser Einstieg soll dir mit Spaß und Spannung die Lust auf mehr bringen.",
      "target_audience": [
        "Du möchtest lernen, Neuronale Netze anzuwenden (Keras / Tensorflow)",
        "Du möchtest eigene AIs für Spiele entwickeln"
      ]
    },
    {
      "title": "Python: Análisis avanzado para Data Science",
      "url": "https://www.udemy.com/course/analisis-de-datos-con-python/",
      "bio": "Aprenderás todo el proceso de análisis de datos. procesaras datos usando NumPy y Pandas, y aprenderás a visualizarlos",
      "objectives": [
        "Aprenderás a crear arrays, sus propiedades, modificarlos y a hacer operaciones.",
        "Aprenderás a crear gráficos con Pyplot. Conocerás los diferentes tipos de gráficos, a modificarlos y darle formato.",
        "Usarás Pandas para crear series y data frames, también rangos, filtros, funciones y mapping.",
        "Analizarás una base de datos de real, aprenderás a importar archivos."
      ],
      "course_content": {
        "Introducción": [
          "Bienvenido a DataBoosters",
          "Bienvenido al curso",
          "¿Qué es la ciencia de datos?",
          "¿Qué es Python?",
          "Revision temario del curso",
          "Archivos descargables",
          "Instalación de Python y Jupyter Notebook",
          "Creación del directorio de trabajo",
          "Introducción a Jupyter Notebook"
        ],
        "Numpy": [
          "Creación de Arrays",
          "Creación de arrays y propiedades de un array",
          "Obtener y modificar elementos de un array",
          "Filtrar elementos de un array",
          "Axis y método delete",
          "Método delete y método append",
          "Operaciones sobre arrays parte 1",
          "Operaciones sobre arrays parte 2",
          "Operaciones sobre arrays parte 3"
        ],
        "Pyplot": [
          "Introducción a matplotlib",
          "Personalización de gráficos",
          "Tipos de gráficos",
          "Tamaños, colores, líneas y markers",
          "Subplots parte 1",
          "Subplots parte 2",
          "Xticks Yticks (Configuración de ejes)"
        ],
        "Pandas": [
          "Series",
          "Data Frames",
          "Creación de series y Data Frames",
          "Importando datos",
          "Inspeccionando un DataFrame",
          "Accediendo a los datos de un DataFrame",
          "Rangos y filtrado de datos",
          "Gestión de valores nulos pt1",
          "Gestión de valores nulos pt2",
          "Analizando una base de datos pt1",
          "Analizando una base de datos pt2",
          "Analizando una base de datos pt2-1",
          "Analizando una base de datos pt3",
          "Combinando dataframes pt1",
          "Combinamdo dataframes pt2",
          "Funciones y mapping",
          "Tablas Pivote"
        ],
        "Regex": [
          "Introducción a expresiones regulares",
          "Búsquedas usando límites",
          "Coincidencias básicas y cuantificadores",
          "Conjuntos de caracteres y grupos",
          "Importando un archivo de texto",
          "Regex, Pandas y filtrado de datos",
          "Analizando un archivo de texto pt1",
          "Analizando un archivo de texto pt2",
          "Analizando un archivo de texto pt3",
          "Analizando un archivo de texto pt4"
        ],
        "Cuestionario y conclusion": [
          "Cuestionario final",
          "Recomendaciones y consideraciones generales",
          "Clase extra"
        ]
      },
      "requirements": [
        "Conocimientos básicos de Python."
      ],
      "description": "Inicia tu aprendizaje en Data Analysis y Data Science. Este curso te guiará paso por paso en uno de los lenguajes de programación más demandados del último siglo. Python no solo es el lenguaje más popular entre los estudiantes si no también entre las empresas que han ido adoptándolo y cada vez es mas demandado.\n\n\nEn cuestión de horas aprenderás desde lo más básico a lo mas avanzado. Al final de este curso podrás hacer análisis por tu cuenta y mostrando resultados de manera impresionante.\n\n\nEn Estados Unidos, el salario medio de un Data Scientist es de 96,106 $ por año. El trabajo de Data Scientist también ofrece la oportunidad de viajar, ya que esas competencias tienen mucha demanda en todo el mundo.\n\n\nEl 89% de los estudiantes del curso también ha mejorado su situación laboral.\n¡Inscríbete ahora y desarrolla esa habilidad que te hace falta!\n\n\nPython es un fenomenal primer lenguaje, como si es tu segundo, tercero o enésimo lenguaje. Su curva de aprendizaje es menos áspera que otros, dispone de miles de librerías que permiten en unas pocas líneas de código hacer lo que nos propongamos. Te permite evolucionar rápidamente, además de profundizar en tareas más complejas, según vas adquiriendo soltura.\n\n\n¡INSCRÍBETE AHORA y empieza a potenciar tu carrera!",
      "target_audience": [
        "Estudiantes que quieran aprender desde cero una habilidad muy demandada como es el análisis de datos desde un punto de vista práctico.",
        "Analistas de datos que quieran profundizar en Python y las librerías Numpy y Pandas."
      ]
    },
    {
      "title": "Explore Population Pyramids with Python and Web Applications",
      "url": "https://www.udemy.com/course/explore-population-pyramids-with-python-and-web-applications/",
      "bio": "Let's Understand Past, Present and Future Population Growth Using Python and Port our Findings to the Web for the World!",
      "objectives": [],
      "course_content": {
        "Exploring Population Pyramids with Python": [
          "Introduction",
          "Downloading Population Data and Quick Exploratory Data Analysis",
          "Let's Create a Population Pyramid Plot",
          "Exploring and Understanding Population Pyramids",
          "Flask Primer",
          "Let's Create a Cloud-Based Population Pyramid Web Application",
          "Conclusion"
        ]
      },
      "requirements": [
        "Basic knowledge of Python such as running Jupiter notebooks, pip installing libraries",
        "Desire to easily create data-driven web apps"
      ],
      "description": "Join me for this free Udemy class where we will explore Population Pyramids using Python and finish by building a web application. You will be able to choose a country, a continent, even the whole world, and choose a year, it can the current one, a past one, or even peer into the future and it will build these automatically.\nA Population Pyramids is a graph that quantifies males versus females by age segments. As you can see, on the left in light blue are the males and in light red, the females and each row represent an age group.\nThese graphs are very important because they not only highlight the challenges of a society they can also point to future ones. It is a great planning tool for administrations and businesses to understand current needs and anticipate future problems.\nWe will build a series of population pyramid plots in Python and a Jupyter notebook and end the class by porting it all to the web into a mobile web application to share your work with the world!\nAll the code needed is provided in the resource folder.\n\n\nHappy learning!",
      "target_audience": [
        "Python developers, budding data scientists, entrepreneurs",
        "The curious who like to roll up their sleeves and find their own answers"
      ]
    },
    {
      "title": "Data Science и Machine Learning на Python 3 с нуля",
      "url": "https://www.udemy.com/course/data-science-python-3/",
      "bio": "Изучи Python 3 с нуля для работы с Data Science и и Machine Learning библиотеками - NumPy, Pandas, Matplotlib and more!",
      "objectives": [
        "Программирование на Python",
        "Применение Python для Data Science",
        "Использование pandas Data Frames для решения сложных задач",
        "Использование pandas для обработки файлов Excel",
        "Использование NumPy для числовых данных",
        "Использование pandas для анализа данных",
        "Использование matplotlib для визуализации данных",
        "Использование seaborn для визуализации данных",
        "Использование встроенной визуализации библиотеки Pandas",
        "Использование библиотек Machine Learning",
        "Применение новых знаний на практике",
        "Линейная регрессия",
        "Компромисс Смещения-Дисперсии",
        "Логистическая регрессия",
        "And more!"
      ],
      "course_content": {
        "Введение": [
          "Введение",
          "ВАЖНО! ЧАВО - ЧАсто задаваемые ВОпросы",
          "Заметка к заданиям"
        ],
        "Установка инструментов": [
          "Установка Python. Windows",
          "Задание к лекции \"Установка IntelliJ IDEA\" для Windows",
          "Установка IntelliJ IDEA. Windows",
          "Установка Python. MacOS",
          "Задание к лекции \"Установка IntelliJ IDEA\" для Mac OS X",
          "Установка IntelliJ IDEA. MacOs"
        ],
        "Основы Python": [
          "Hello world!",
          "Вывод текста",
          "Типы данных в Python",
          "Числовые типы данных",
          "Вычисление выражений",
          "Переменные в Python",
          "Переменные в Python",
          "Строки в Python",
          "Строки в Python",
          "Строки. Indexing & Slicing",
          "Строки. Indexing & Slicing",
          "Свойства и методы строк",
          "Свойства и методы строк",
          "Форматирование строк в Python",
          "Форматирование строк в Python",
          "Lists в Python",
          "Lists в Python",
          "Dictionaries в Python",
          "Dictionaries в Python",
          "Tuples в Python",
          "Tuples в Python",
          "Sets в Python",
          "Sets в Python",
          "Заметка к лекции \"Booleans. Операторы сравнения\"",
          "Booleans. Операторы сравнения",
          "Booleans. Операторы сравнения",
          "Логические операторы",
          "Условный оператор if elif else",
          "Условный оператор if elif else",
          "Цикл for",
          "Цикл for",
          "Цикл while",
          "Цикл while",
          "Некоторые часто используемые функции и операторы",
          "List Comprehension",
          "List Comprehension",
          "Dictionary Comprehension & Set Comprehension",
          "Nested loops",
          "Nested Lists"
        ],
        "Функции Python": [
          "Введение",
          "Создание функций в Python",
          "Создание функций в Python",
          "*args & **kwargs.",
          "*args & **kwargs.",
          "Лямбда выражения в функциях",
          "Область видимости (scope) переменных"
        ],
        "Data Science Tools": [
          "Anaconda",
          "Jupyter Notebook"
        ],
        "Анализ данных. Библиотека NumPy": [
          "NumPy массивы",
          "Заметка к лекции \"NumPy массивы\"",
          "NumPy массивы",
          "Одномерные массивы. Indexing & Slicing",
          "Двумерные массивы. Indexing & Slicing",
          "Indexing & Slicing",
          "Операции с массивами",
          "Операции с массивами"
        ],
        "Анализ данных. Библиотека Pandas": [
          "Введение",
          "Series",
          "Series",
          "DataFrame",
          "DataFrame",
          "Selection & Indexing",
          "Selection & Indexing",
          "MultiIndex",
          "MultiIndex",
          "Missing Data",
          "groupby()",
          "concat(), merge(), join()",
          "Другие операции",
          "Input/Output",
          "Задание по разделу Pandas",
          "Задание по разделу Pandas. Решение"
        ],
        "Визуализация данных. Библиотека Matplotlib": [
          "Библиотека Matplotlib. Введение",
          "Библиотека Matplotlib. Часть 1",
          "Библиотека Matplotlib. Часть 2",
          "Библиотека Matplotlib. Часть 3",
          "Задание по разделу Matplotlib",
          "Задание по разделу Matplotlib. Решение"
        ],
        "Визуализация данных. Библиотека Seaborn": [
          "Библиотека Seaborn. Введение",
          "Dataset Distribution",
          "Categorical Data",
          "Matrix Plots",
          "Grids",
          "Regression Plots",
          "Styles",
          "Задание по разделу Seaborn",
          "Задание по разделу Seaborn. Решение"
        ],
        "Визуализация данных. Встроенная визуализация библиотеки Pandas": [
          "Встроенная визуализация библиотеки Pandas",
          "Задание",
          "Решение задания"
        ]
      },
      "requirements": [
        "Компьютер, интернет и желание учиться"
      ],
      "description": "Готовы ли вы начать свой путь, чтобы стать Data Scientist?\nСпециалист по анализу данных - одна из наиболее подходящих профессий для процветания в этом веке. Он цифровой, ориентированный на программирование и аналитический. Поэтому неудивительно, что спрос на специалистов по анализу данных на рынке труда растет.\nОднако предложение было очень ограниченным. Трудно получить навыки, необходимые для работы в качестве специалиста по данным.\nИ как это сделать?\nУниверситеты не спешили создавать специализированные программы по науке о данных. (Не говоря уже о том, что существующие очень дороги и требуют много времени)\nБольшинство онлайн-курсов сосредоточено на конкретной теме, и трудно понять, как навыки, которым они обучают, вписываются в общую картину.\nЭтот всеобъемлющий курс станет вашим руководством к изучению того, как использовать возможности Python для анализа данных, создания красивых визуализаций и использования мощных алгоритмов машинного обучения!\nКурс регулярно пополняется новыми материалами!\nЭтот курс подойдёт для всех - для начинающих без опыта программирования, для имеющих некоторый опыт программирования и для опытных разработчиков, стремящихся изучить Data Science!\nВы научитесь программировать на Python, создавать удивительные визуализации данных и использовать машинное обучение с Python!\nЧему вы научитесь:\nПрименять Python для Data Science\nИспользовать инструменты для работы в Data Science\nНаучитесь использовать NumPy для числовых данных\nНаучитесь использовать Pandas для анализа данных\nНаучитесь использовать Matplotlib для визуализации данных\nНаучитесь использовать Seaborn для визуализации данных\nНаучитесь использовать встроенную визуализацию библиотеки Pandas\nНаучитесь применять новые знания на практике\nНаучитесь использовать библиотеки Machine Learning\nИ многое другое!\n\n\nЗаписывайтесь на курс и получите одну из самых востребованных профессий и супер востребованные скиллы Data Science в ваше  портфолио!",
      "target_audience": [
        "Курс предназначен для всех желающих получить знания по языку Python для работы с Data Science"
      ]
    },
    {
      "title": "【画像判定AIアプリ開発・パート1】TensorFlow・Python・Flaskで作る画像判定AIアプリ開発入門",
      "url": "https://www.udemy.com/course/tensorflow-advanced/",
      "bio": "Python 3 でクローリングして画像データを収集、加工し、画像分類器を作ってみよう。ディープラーニングによるモデル作成、改善を自分の集めたデータで実践します。Flaskでウェブアプリ化, XcodeでiOSアプリ化にも挑戦します。",
      "objectives": [
        "オリジナルデータを使って画像分類器を作れるようになります。",
        "TensorFlowとKerasを用いたディープラーニング（多層ニューラルネットワーク）を作れます",
        "Pythonによるクローリングを用いたデータ収集ができるようになります",
        "Pythonによる画像データ加工（サイズ変更や回転）ができるようになります",
        "画像判定AIをFlaskでウェブアプリ化できます",
        "Flaskでウェブアプリケーションを作れるようになります。"
      ],
      "course_content": {
        "はじめに": [
          "このコースの紹介",
          "学習の進め方"
        ],
        "環境構築（Python, Anaconda, TensorFlow CPU版のインストール）": [
          "Python 3のインストール（Anaconda最新版のインストール）",
          "TensorFlowのインストール"
        ],
        "【オプション】TensorFlow GPU版のセットアップ（NVIDIA製GPU搭載マシン使用者のみ。非搭載の方はスキップしてください。）": [
          "CUDA 9.0のダウンロード",
          "CUDA 9.0のインストール",
          "cuDNN 7.0のダウンロード・インストール",
          "TensorFlow 1.6.0 GPU版のインストール"
        ],
        "画像分類AI自作にチャレンジ": [
          "アプリの概要",
          "データを集めよう",
          "FlickrのAPIキーを取得しよう",
          "Flickrapiパッケージをインストールしよう",
          "コードからFlickrAPIにアクセスしてみよう",
          "（オプション）AtomのPython関連プラグインの追加",
          "データをダウンロードして保存しよう",
          "不要なデータを削除しよう",
          "画像データをNumPy配列形式に変換しよう",
          "生成した配列データをチェックしよう",
          "データを交差検証用に分割しよう",
          "トレーニングを実行するコードを作成しよう",
          "モデルを定義しよう",
          "トレーニングの関数を完成させよう",
          "テストを行う関数を完成させよう",
          "NumPyのバージョンアップによる変更の影響がある場合の注意",
          "TensorFlow 2.3.0, Keras 2.4.3環境で動作させるための改変箇所",
          "学習とテストを実行しよう",
          "コードの最適化とセクションのまとめ",
          "セクションのソースコード",
          "課題：　オリジナルの分類器を作ろう"
        ],
        "データの工夫による精度向上にチャレンジしてみよう": [
          "このセクションの概要",
          "データを増量しよう",
          "増幅したデータで学習してみよう",
          "データを増幅するコードの修正",
          "課題：　データの増幅",
          "データの増幅サンプルコード",
          "サンプルコード（増幅・トレーニング）"
        ],
        "推定プログラムを作成しよう": [
          "このセクションの概要",
          "モデルを定義・ロードする関数を定義しよう",
          "推定処理を追加して、推定を実行してみよう",
          "課題：推定プログラムの作成",
          "サンプルコード"
        ],
        "FlaskでWebアプリ化しよう！": [
          "このセクションの概要",
          "Flaskのインストール",
          "FlaskでHello World! を表示してみよう！",
          "ファイルをアップロードするコードを書こう（1/2）",
          "ファイルをアップロードするコードを書こう（2/2）",
          "ファイルアップロードのソースコード",
          "ファイルアップロード時のエラー処理について",
          "ファイルをアップロードしてみよう",
          "ソースコード",
          "（注意）Flaskのバージョンアップに伴う起動コマンドの変更",
          "画像の識別を実行してみよう"
        ],
        "Kerasで生成したモデルを変換してiOSアプリを作ろう": [
          "セクションの概要",
          "仮想環境の追加とTensorFlow/Kerasのインストール、学習の実行",
          "(macOS 10.13) モデルファイルの変換の実行",
          "(macOS 10.15 Catalina) CoreML Toolsのインストールと変換の実行",
          "（macOS 10.15）bashでのAnacondaの環境変数の設定方法",
          "Xcode上でプロジェクトを追加しよう",
          "UIパーツを追加しよう",
          "IBOutletとIBActionを関連づけよう",
          "カメラアクセスを許可する設定をしよう",
          "カメラを起動するコードを追加しよう",
          "ビルドして実機で実行してみよう",
          "モデルを読み込んで推論を実行してみよう",
          "このセクションのプロジェクトのソースコード"
        ],
        "ボーナスセクション": [
          "GPU搭載のおすすめPCや、グラフィックスボード情報",
          "AI・ディープラーニングのおすすめコース"
        ]
      },
      "requirements": [
        "初歩的なPC操作（ファイルの作成やフォルダの作成ができること）",
        "ビデオで学習するのが嫌でないこと",
        "英語のサイトを見てもパニックしないこと",
        "エラーが出ても事例を検索したり質問して、問題解決を図れること"
      ],
      "description": "＊更新情報\n2019/1/19 iOSアプリ化セクションのソースコードをセクションの最後に追加しました。\n2019/1/7 CoreML対応フォーマットに変換し、iOSアプリ化するセクションを完成しました。\n＊ただし、実機での実行・アプリ配布にはMacとApple Developerプログラム登録が必要です。\n2018/3/22 Flaskでウェブアプリ化するセクションを追加しました。\n2018/2/10 コマンドラインから画像ファイルを指定して推定を行うプログラムを作成するセクションを追加しました。\n2017年1月にリリースしたTensorFlow入門・ニューラルネットワーク入門コースでは、およそ8,000名の受講生のみなさんが典型的な手書き文字認識問題を体験しました。\nそして多くの受講生のみなさんから「AI分類器を自作して、ビジネスや趣味に活かしたい！」というリクエストを多数いただきました。\nそうしたリクエストに応えるために、このコースは制作されました。\n【コースの概要】\nコース内では、\nPythonでオンラインでクローリングを行い、画像データを収集する\n収集したデータを同じサイズに加工して深層学習の前処理（準備）をする\n前処理をしたデータを用いて、ディープラーニングを実行し、モデルを作成する\nモデルを使って、テストデータにより性能評価を行う\nより精度を向上させるためのデータの改善を行う\n画像ファイルを与えて推定を行うプログラム（ウェブアプリ・iOSアプリ）を作成する\nというチャレンジをしていきます。\nまた、このために必要なAnaconda, Python 3, TensorFlow, Keras, 画像処理ライブラリ, スクレイピング・クローリングライブラリなどの導入や設定についても詳細に解説します。\nあなたが集めたデータを整理してプログラムを実行するとオリジナルの画像分類AIを作れるようになります。\nこの講座を受講したら、あなたはどんなAI分類器を作りますか？",
      "target_audience": [
        "AIや機械学習を実践してみたい方",
        "オリジナルデータで画像分類器を開発したい方",
        "TensorFlowとKerasでディープラーニングを実装してみたい方",
        "画像判定AIをFlaskでウェブアプリ化したい方"
      ]
    },
    {
      "title": "Deep Learning com Python de A a Z - O Curso Completo",
      "url": "https://www.udemy.com/course/deep-learning-com-python-az-curso-completo/",
      "bio": "Redes neurais artificiais, convolucionais, recorrentes, mapas auto organizáveis, boltzmann machines, autoencoders e GANs",
      "objectives": [
        "Aprenda na teoria e na prática como construir redes neurais artificiais para resolver problemas reais do dia",
        "Aprenda os conceitos sobre redes neurais convolucionais, redes neurais recorrentes, mapas auto organizáveis, boltzmann machines, auto encoders e redes adversariais generativas",
        "Avalie e configure os parâmetros de uma rede neural",
        "Construa passo a passo redes neurais aplicadas em problemas de classificação e regressão",
        "Construa passo a passo uma rede neural para prever o preço de veículos usados e prever a venda de jogos de vídeo games",
        "Implemente redes neurais convolucionais para classificar dígitos escritos a mão e também para identificar gatos e cachorros em imagens",
        "Implemente uma rede neural recorrente para prever os preços das ações da Petrobras",
        "Implemente mapas auto organizáveis aplicados em agrupamento de dados e detecção de fraudes em bases financeiras",
        "Reduza a dimensionalidade de bases de dados utilizando Boltzmann Machines e autoencoders",
        "Crie um sistema de recomendação utilizando Boltzmann Machines",
        "Crie novas imagens utilizando redes adversariais generativas"
      ],
      "course_content": {
        "Introdução": [
          "Boas-vindas e conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Introdução a Deep Learning",
          "Recursos para download",
          "Execução local"
        ],
        "-----Parte 1 - Redes Neurais Artificiais -----": [
          "Introdução à seção"
        ],
        "Teoria resumida sobre redes neurais artificiais": [
          "Fundamentos biológicos",
          "Perceptron de uma camada",
          "Redes multicamada - função soma e função de ativação",
          "Redes multicamada - cálculo do erro",
          "Descida do gradiente",
          "Cálculo do parâmetro delta",
          "Ajuste dos pesos com backpropagation",
          "Bias, erro, descida do gradiente estocástico e mais parâmetros",
          "Funções de ativação - implementação I",
          "Funções de ativação - implementação II",
          "Teoria sobre redes neurais artificiais",
          "Referências complementares"
        ],
        "Classificação binária - base breast cancer": [
          "Base de dados breast cancer",
          "Estrutura da rede neural",
          "Configuração e execução da rede neural",
          "Previsões com a rede neural",
          "Mais camadas e parâmetros do otimizador",
          "Visualização dos pesos",
          "Validação cruzada - teoria",
          "Validação cruzada - implementação",
          "Overfitting e underfitting - teoria",
          "Overfitting e dropout - implementação",
          "Tuning (ajuste) dos parâmetros",
          "Classificação de somente um registro",
          "Salvar e carregar a rede neural",
          "Melhoria dos resultados na base breast cancer"
        ],
        "Classificação multiclasse - base iris": [
          "Base de dados iris",
          "Estrutura da rede neural",
          "Previsões com a rede neural",
          "Validação cruzada",
          "Tuning dos parâmetros",
          "Salvar o classificador e classificar somente uma planta"
        ],
        "Regressão - base de carros usados": [
          "Base de dados de carros usados",
          "Pré-processamento - valores inconsistentes",
          "Pré-processamento - valores faltantes",
          "Pré-processamento - one hot encoder",
          "Estrutura da rede neural",
          "Validação cruzada",
          "Tuning com outras funções de erro"
        ],
        "Regressão com múltiplas saídas - base vídeo games": [
          "Base de dados vídeo games",
          "Pré-processamento",
          "Estrutura da rede neural",
          "Previsão do valor total das vendas dos jogos"
        ],
        "----- Parte 2 - Redes Neurais Convolucionais -----": [
          "Introdução à seção"
        ],
        "Teoria sobre redes neurais convolucionais": [
          "Imagens e pixels",
          "Introdução a redes neurais convolucionais",
          "Etapa 1 - operador de convolução",
          "Etapa 2 - pooling",
          "Etapa 3 - flattening",
          "Etapa 4 - rede neural densa",
          "Teoria sobre redes neurais convolucionais",
          "Referências complementares"
        ],
        "Classificação de dígitos escritos a mão": [
          "Base de dados MNIST",
          "Estrutura da rede neural",
          "Melhorias na rede neural",
          "Validação cruzada",
          "Aumento da quantidade de imagens (augumentation)",
          "Base de dados CIFAR-10"
        ]
      },
      "requirements": [
        "O único pré-requisito obrigatório é conhecimento sobre lógica de programação, principalmente estruturas condicionais e de repetição",
        "Também são necessários conhecimentos sobre instalação de softwares básicos, porém, durante o curso será mostrado o processo de instalação das ferramentas utilizadas durante todo o curso",
        "Conhecimentos em Python não são obrigatórios, sendo possível acompanhar o curso sem saber essa linguagem com profundidade",
        "Conhecimentos em Machine Learning, Redes Neurais ou Inteligência Artificial não são obrigatórios. No final do curso existe um apêndice com várias aulas básicas sobre esses assuntos caso seja seu primeiro contato com a área"
      ],
      "description": "Importante: Todas as aulas do curso foram regravadas!\nA área de Deep Learning (Aprendizagem Profunda) está relacionada a aplicação das redes neurais artificiais na resolução de problemas complexos e que requerem artifícios computacionais avançados. Existem diversas aplicações práticas que já foram construídas utilizando essas técnicas, tais como: carros autônomos, descoberta de novos medicamentos, cura e diagnóstico antecipado de doenças, geração automática de notícias, reconhecimento facial, recomendação de produtos, previsão dos valores de ações na bolsa de valores e até mesmo a geração automática de roteiros de filmes! Nesses exemplos, a técnica base utilizada são as redes neurais artificiais, que procuram \"imitar\" como o cérebro humano funciona e são consideradas hoje em dia como as mais avançadas no cenário de Machine Learning (Aprendizagem de Máquina).\n\nA área de Deep Learning é atualmente um dos campos de trabalho mais relevantes da Inteligência Artificial, sendo que o mercado de trabalho dessa área nos Estados Unidos e em vários países da Europa está em grande ascensão; e a previsão é que no Brasil cada vez mais esse tipo de profissional seja requisitado! Inclusive alguns estudos apontam que o conhecimento dessa área será em breve um pré-requisito para os profissionais de Tecnologia da Informação!\nE para levar você até essa área, neste curso você terá uma visão teórica e principalmente prática sobre as principais e mais modernas técnicas de Deep Learning utilizando o Python! Este curso é considerado de A à Z pelo fato de apresentar desde os conceitos mais básicos sobre as redes neurais até técnicas mais modernas e avançadas, de modo que ao final você terá todas as ferramentas necessárias para construir soluções complexas e que podem ser aplicadas em problemas do dia-a-dia das empresas! Para isso, o conteúdo está dividido em sete partes: redes neurais artificiais, redes neurais convolucionais, redes neurais recorrentes, mapas auto organizáveis, boltzmann machines, autoencoders e redes adversariais generativas. Você aprenderá a teoria básica sobre cada um desses assuntos, bem como implementará exemplos práticos passo a passo aplicado em cenários reais. Veja abaixo alguns dos projetos que serão desenvolvidos:\nClassificação se um câncer é maligno ou benigno baseado nos dados do tumor\nClassificação de tipos de plantas\nPrevisão do preço de veículos usados baseado nas características do carro\nPrevisão de quanto um jogo de vídeo game venderá\nClassificação de dígitos escritos a mão\nClassificação de imagens de gatos e cachorros\nClassificação das imagens do Homer e Bart, do desenho dos Simpsons\nClassificação de objetos, como por exemplo: aviões, automóveis, pássaros, gatos, veados, cachorros, sapos, cavalos, barcos e caminhões\nConstrução de série temporal para previsão dos preços das ações da Petrobrás\nPrevisão da poluição na China em determinadas horas do dia\nAgrupamento de tipos de vinhos baseados nas características do produto\nAgrupamento de câncer que são malignos ou benignos\nDetecção de clientes que podem tentar fraude em bases de dados financeiras\nRedução de dimensionalidade em imagens\nDesenvolvimento de um sistema de recomendação básico de filmes\nComparação de sistemas de recomendação utilizando redes neurais e utilizando técnicas clássicas de filtragem colaborativa\nCriação automática de imagens\nAo final de cada seção teórica você tem questionários para revisar o conteúdo, bem como indicações de referências complementares caso você queira aprender mais sobre os assuntos. E ao final de cada seção prática, você encontra projetos de programação para fortalecer o conteúdo sobre as implementações, todos com as soluções para você comparar com o seu progresso!\nEste curso é indicado para todos os níveis, ou seja, caso seja seu primeiro contato com Deep Learning, você conta com um apêndice que contém aulas básicas sobre aprendizagem de máquina e redes neurais! É também importante enfatizar que o único pré-requisito necessário é saber lógica de programação, pois mesmo se você não seja especialista na linguagem Python você conseguirá acompanhar o curso sem nenhum problema!\nPreparado(a) para dar um importante passo na sua carreira? Aguardo você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em iniciar seus estudos em deep learning (aprendizagem profunda)",
        "Pessoas interessadas em redes neurais artificiais, convolucionais, recorrentes, mapas auto organizáveis, boltzmann machines, autoencoders e redes adversariais generativas",
        "Pessoas interessadas em iniciar uma carreira em Ciência de Dados utilizando técnicas modernas de aprendizagem de máquina",
        "Empreendedores que queiram aplicar aprendizagem de máquina em projetos comerciais",
        "Analistas de dados que queiram aumentar seu conhecimento na área de deep learning (aprendizagem profunda)",
        "Empresários que desejam criar soluções eficientes para problemas reais em suas empresas",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial"
      ]
    },
    {
      "title": "Satellite Remote Sensing for Beginners",
      "url": "https://www.udemy.com/course/satellite-remote-sensing-for-beginners/",
      "bio": "Get started to learn remote sensing with various earth observation satellite data!",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "none"
      ],
      "description": "This course provides an introduction of satellite remote sensing for beginners.\nThe course contains 5 lectures with various sample images taken by earth observation satellites.\nWhat is Remote Sensing\nSatellite\nOrbit\nUtilization\nData Access\nStudents will learn overview and basic of satellite remote sensing with sample images. The course introduce several satellites carrying sensors to observe the Earth. Students will learn there are two typical types of sensors - i.e. optical and radar - and its advantages and disadvantages. There are also two typical satellite orbits which are geostationary orbit and polar orbit. Satellite data users will select adequate satellites for their purposes.\nStudents will also learn how the satellite data has being utilized for various applications such as agriculture, forest monitoring, disaster reduction etc. The course also provides how to search and obtain the observation data taken by one of the most famous earth observation satellite - Landsat.\nThis course is the first step to learn remote sensing. For the next step, the Remote Sensing Technology Center of Japan (RESTEC) provides the following online interactive training with hands-on exercise.\nBasic Remote Sensing Course (2 days)\nOptical Remote Sensing Course (2 days)\nSAR Remote Sensing Course (2 days)\nInterferometric SAR Remote Sensing (2 days)\nFor any feedback and inquiries, please contact RESTEC by e-mail at training@restec.or.jp",
      "target_audience": [
        "Anyone who are interested in satellites, remote sensing and earth observation."
      ]
    },
    {
      "title": "Veri Bilimi için Python ( Python for Data Science )",
      "url": "https://www.udemy.com/course/veri-bilimi-icin-python/",
      "bio": "Veri Bilimi,Makine Öğrenmesi ve Derin Öğrenmede :NumPy,Pandas ve Matplotlib Kütüphaneleri",
      "objectives": [
        "Veri bilimi algoritmalarına rahatlıkla geçerek uygulama yapabileceksiniz.",
        "Verinin ön hazırlık kısmındaki sorunları çözebilecek düzeyde olacaksınız."
      ],
      "course_content": {
        "Giriş": [
          "Tanıtım Videosu",
          "Anaconda Kurulumu",
          "Anaconda Ortamının Tanıtımı"
        ],
        "NumPy'a Giriş": [
          "NumPy Nedir ?"
        ],
        "1)NumPy Arrayleri Oluşturma": [
          "1.1)Temeller",
          "1.2)linspace & arange",
          "1.3)Rasgele Örnekleme",
          "1.4)zeros,ones,full,eye"
        ],
        "2)NumPy Arraylerinde Hesaplama": [
          "2.1)Skalerlerin Kullanılması",
          "2.2)İki Diziyle Aritmetik İşlemler",
          "2.3)Karşılaştırma ve Mantıksal Operatörleri",
          "2.4)Trigonometrik, Üstel ve Logaritmik fonksiyonlar",
          "2.5)Toplama Fonksiyonları (Aggregate Functions)"
        ],
        "3)NumPy Arraylerinin Manipulasyonları": [
          "3.1)NumPy Arraylerinin Indekslenmesi",
          "3.2)NumPy Arrayleri Manipülasyonu"
        ],
        "4)NumPy ile Temel Lineer Cebir": [
          "4.1)NumPy ile Temel Lineer Cebir"
        ],
        "Pandas'a Giriş": [
          "Pandas Nedir ?"
        ],
        "1)Pandas Nesneleri": [
          "1.1)Pandas Serileri",
          "1.2) DataFrame",
          "1.3)İndex"
        ],
        "2)Pandas ile Veri İşleme": [
          "2.1)Veri İndeksleme ve Seçimi",
          "2.2)Pandasda Operasyonlar",
          "2.3)Kayıp Değerler",
          "2.4)Gelişmiş İndeksleme(MultiIndex)"
        ],
        "3)Pandas ile Veri Aktarımı": [
          "3.1)CSV",
          "3.2)Excel",
          "3.3)HTML",
          "Kurs Ödevi"
        ]
      },
      "requirements": [
        "Öğrenme arzusu ve azim",
        "Temel python programlama",
        "Lise düzeyinde matematik bilgisi"
      ],
      "description": "Merhaba,\nVeri bilimi,yapaya zeka,makine öğrenmesi ve veri madenciliğinde veriyi istenilen hale getirmekte sıkıntı mı yaşıyorsun ?O zaman doğru adrestesin.\nBu kurs, hiç bilmeyen ve yeni başlayan birisinin veri biliminde çok sıkıntı yaşadığı konu olan veri hazırlama ve uygun bir şekle getirme sürecini hızlandırarak uzman seviyesine çıkarma hedefinde.Her bir bölümde  zengin içerikler ile farklı yetenekler kazandırılarak veri bilimi için uygun bir alt yapı oluşturulacaktır.Ayrıca güncel ve popüler olan yapaya zeka,makine öğrenmesi ve veri madenciliğinde de kullanabileceğiniz yetenekleriniz olacak.\n\nKurs kapsamında NumPy,Pandas ve Matplotlib Kütüphaneleri gösterilecektir. NumPy ile bilimsel hesaplamalarınızı ,Pandas ile Veri  Manipülasyonu ve Matplotlib ile veri görselleştirmesini yapacaksınız..Ders işleyişi ise oluşturduğum özel notlar ile bu notlar size hem zamanınızdan kar hem de elinizin altında  her zaman bakabileceğiniz bir ek kaynak olacak.\nBir kursdan daha fazlası....\n\nKolay Gelsin,\n\nEngin Bozaba",
      "target_audience": [
        "Veri bilimi dünyasında 'Bende Varım !' demek isteyen",
        "Verilere BAKAN gözle değilde GÖREN gözle bakmak isteyen",
        "Python yeteneklerini geliştirmek isteyen"
      ]
    },
    {
      "title": "Sıfırdan Sektör Odaklı SQL Eğitimi [Sunucu Dahil]",
      "url": "https://www.udemy.com/course/sifirdan-sektor-odakli-sql-egitimi/",
      "bio": "Mülakatlarda ve sektörde en çok ihtiyaç duyulan SQL becerilerini hızlandırılmış şekilde kazanın. Sunucu dahil tek eğitim",
      "objectives": [
        "Gerçek dünyada kullanılan SQL tekniklerini öğrenerek veri tabanlarına hızlı ve verimli sorgular yazmayı öğreneceksiniz.",
        "Sektörde mülakatlarda en fazla sorulabilecek ve karşınıza çıkacak konulara odaklanacaksınız",
        "SQL'in ileri düzey fonksiyonlarını ve pratiklerini öğrenerek, büyük veri kümelerinde optimize edilmiş sorgular yazmayı başaracaksınız.",
        "SQL’i günlük iş süreçlerine entegre ederek, veri analistleri ve iş zekası uzmanlarının en çok kullandığı sorgu yöntemlerini hızla uygulayabileceksiniz.",
        "Online pratik aracı ile bilgisayarınıza ek kurulum yapmadan SQL pratiği yapabileceksiniz."
      ],
      "course_content": {
        "Verilere Giriş: Temel Kavramlar ve Ortamlar": [
          "Veri Dünyasına Adım Atıyoruz",
          "Veritabanlarının Gücü: Veritabanı Yazılımları",
          "Verinin Temelleri: Veri Tipleriyle Tanışma",
          "DataGrip Kullanımı: Profesyonel Veritabanı Yönetimi",
          "İlk Bağlantımız: Veritabanına Nasıl Bağlanırız?"
        ],
        "SQL'e Başlangıç: İlk Sorgular ve Temel Operasyonlar": [
          "SQL'e Merhaba: İlk Sorgumuzu Yazıyoruz",
          "Çalışan Bilgilerini Listeleme SQL Pratiği",
          "Select ile Veride Hesaplamalar: Kolayca İşlem Yapın",
          "SQL Dosyaları Kullanalım",
          "Tablo Keşfi: Önce Konfor Alanınızı Oluşturun",
          "Ara Test",
          "Veriyi Filtreleme: WHERE Kullanımı",
          "Çoklu Filtreleme SQL Pratiği",
          "Sıralama: ORDER BY ile Veriyi Düzenleme",
          "Ara Test",
          "Maaş Hesaplamaları SQL Pratiği",
          "Metinsel Fonksiyonlar",
          "Koşullara Göre Sonuç Çıkarımı: CASE WHEN Kullanımı",
          "IT'ye E-posta Manipülasyonu SQL Pratiği",
          "Eksik Veriyi Yönetmek: COALESCE Fonksiyonu",
          "Boş Değerler ile Baş Etme: NULLIF Fonksiyonu",
          "Çalışan Profil Raporu Hazırlama SQL Pratiği"
        ],
        "Orta Seviye SQL: Fonksiyonlar ve Hesaplamalar": [
          "Öğrendiklerimize Bakış: Neredeyiz?",
          "İstatistiksel Güç: Aggregate Functions Part 1",
          "Toplamlar ve Minimum-Maksimum Değerler",
          "Departman Bazlı Analiz SQL Pratiği",
          "Koşullu Toplamalar: HAVING Kullanımı",
          "Çoklayan Veriler: DISTINCT Kullanımı",
          "Ara Test"
        ],
        "Verileri Birleştirme: Join Yöntemleri": [
          "Verileri Birleştirelim: JOIN Giriş",
          "Veri Setimizi Tanıyalım",
          "INNER JOIN: Önemli Noktaları Öğrenelim",
          "LEFT JOIN: Önemli Noktaları Öğrenelim",
          "RIGHT JOIN: Ters Açıdan Verileri Birleştirme",
          "FULL JOIN: Bütün Veriyi Birleştiren Yaklaşım",
          "CROSS JOIN: Tabloları Çaprazlama Eşleştirme"
        ],
        "Ek Pratik Bölümleri [BONUS] - YENİ": [
          "Veriseti 01 Yapısı ve Dökümanı",
          "Question Set 01",
          "Question Set 02"
        ],
        "Gelişmiş Sorgulama Teknikleri ve Veri Manipülasyonu": [
          "CTE ve SubQuery: Veritabanı Sorgularında Modülerlik",
          "Ara Test",
          "Veri Tipi Dönüşümleri: Veriyi Uygun Forma Getirme",
          "Tarihlerle Çalışalım: Tarih Fonksiyonları"
        ],
        "İleri Seviye Window Fonksiyonları ile Veriyi Analiz Etme": [
          "Window Functions: Giriş ve Temel Bilgiler",
          "Window Functions ile Pratik Yapıyoruz",
          "Sıralamaları Anlayalım: ROW_NUMBER, RANK ve DENSE_RANK",
          "NTILE Fonksiyonu ve Senaryolar",
          "LAG Fonksiyonu: Önceki Satırlara Erişim",
          "İlk Değeri Yakalama: FIRST_VALUE Kullanımı",
          "Pratik 01: Window Fonksiyonları Uygulaması",
          "Pratik 02: İleri Seviye Senaryo",
          "Pratik 03: Karmaşık Senaryolarla Window Fonksiyonları",
          "DDL Notları"
        ]
      },
      "requirements": [
        "Bu kursu almak için ön koşul yoktur. Herhangi bir SQL bilgisine sahip olmanıza gerek yoktur. Yalnızca bilgisayar ve internet erişimi yeterlidir."
      ],
      "description": "Bu kurs, senelerdir canlı derslerimde başarıyla uyguladığım müfredatın, öğrencilerimden gelen yoğun talepler doğrultusunda daha geniş kitlelerle buluşturulması amacıyla oluşturuldu. Veri Eğitimi platformuna ait sunucular da öğrencilerimize ücretsiz sunulacaktır. Sunucu içerisinde tüm veri setleri mevcuttur. Böylece hiç kurulum gerçekleştirmeden uzak sunucuya bağlanma tecrübesini deneyimleyeceksiniz. Derslerimiz sadece konu anlatımından ziyade, günlük hayatımda karşılaştığım durumlar ya da hayali senaryolar ile ilerlemektedir. SQL'i sıfırdan öğrenmek isteyen ve sektörün gereksinim duyduğu en kritik becerileri hızla kazanmak isteyenler için bu eğitim, adım adım hazırlanmış kapsamlı bir rehber niteliğindedir.\n\n\nEğitimi satın alan öğrencilerimiz bizlere mail ile ulaşarak (Bilgiler kayıt sonrası paylaşılıyor) 4 aylık Jetbrains DataGrip lisansı talep edebilirler. Partnerliğimiz doğrultusunda ücretsiz şekilde sadece eğitim amaçlı öğrencilerimiz ile paylaşılacaktır. Böylece sektördeki gerçek uygulamaları kullanıyor olacaksınız.\nKurs içeriğine sürekli olarak pratik SQL soruları eklenmektedir. Udemy üzerindeki SQL motorundan dileyenler doğrudan pratik yapabilecekler.\n\n\nTeorik detaylardan arındırılmış, tamamen uygulama odaklı ve sektörün ihtiyaçlarına uygun şekilde düzenlenmiştir. Kurs müfredatı, iş dünyasında mülakatlarda en sık karşılaşılan konular ve günlük iş akışında kullanılan pratik teknikler etrafında şekillenmiştir.\n\n\nEğer SQL ile ilk kez tanışıyor ya da bu konu hakkında çekinceleriniz varsa endişelenmenize gerek yok. Kurs, SQL'in zor olmadığını size adım adım gösteren, kolay anlaşılır ve pratik bir şekilde yapılandırılmıştır. Daha önce hiçbir teknik bilgiye sahip olmasanız dahi bu kurs sayesinde SQL öğrenme süreciniz keyifli ve hızlı olacak. Gerçek hayatta kullanılan örneklerle SQL’i öğrenerek, iş hayatında karşılaşabileceğiniz tüm SQL sorunlarına çözüm üretebilecek hale geleceksiniz.\n\n\nBu eğitim, veri analisti veya veri bilimcisi olmayı hedefleyenler için de mükemmel bir başlangıç noktasıdır. SQL bilmek, bu alanlarda olmazsa olmaz bir yetkinliktir ve bu kurs sonunda artık SQL sizin için bir sorun olmaktan çıkacak. Tek bir eğitimle, veritabanları üzerinde nasıl etkili çalışacağınızı öğrenip, iş hayatında karşılaşacağınız mülakatlarda kendinize güvenle SQL sorularını yanıtlayacak hale geleceksiniz. Bu kurs, sadece SQL'i öğrenmenizi sağlamaz, aynı zamanda mülakatlarda karşılaşabileceğiniz kritik SQL sorularına da hazırlık yapmanıza yardımcı olur.\n\n\nKurs boyunca, SQL’in temellerini öğrenmekten çok daha fazlasını başaracaksınız. Veritabanı bağlantıları, optimizasyon teknikleri, tablo birleştirme (JOIN) yöntemleri ve karmaşık veri analizlerini hızlı ve etkin bir şekilde nasıl yapacağınızı öğreneceksiniz. Ayrıca, SQL'in ileri seviye fonksiyonlarını ve gerçek dünya iş senaryolarında bu fonksiyonları nasıl kullanabileceğinizi göreceksiniz. SQL'i yalnızca öğrenmekle kalmayacak, aynı zamanda sektör standartlarına uygun biçimde uygulamayı ve verilerinizi en verimli şekilde yönetmeyi öğreneceksiniz.\n\n\nBu kurs, veri analistleri, yazılım geliştiriciler, iş zekası uzmanları ve SQL'i profesyonel düzeyde kullanmak isteyen herkes için idealdir. Daha önce veritabanı yönetimi veya SQL deneyiminiz olmasa dahi, bu kurs size kolay anlaşılır bir başlangıç sunarak hızlı bir öğrenme süreci sağlayacak. Eğitim boyunca verilen örnekler ve pratikler, öğrendiklerinizi pekiştirmenize yardımcı olacak ve sizi gerçek iş hayatında karşılaşacağınız projelere hazırlayacaktır.\n\n\nSonuç olarak, SQL bilginizi sektörde etkili ve verimli bir şekilde kullanacak, büyük veri setleri üzerinde karmaşık analizler yapabilecek ve iş dünyasında veri odaklı kararlar almanıza yardımcı olacak seviyeye ulaşacaksınız. Ayrıca, kurs süresince tüm sorularınıza yanıt bulabileceğiniz ve her türlü yardımı alabileceğiniz bir destek ekibi yanınızda olacak.\n\n\nSize her adımda rehberlik edecek ve kariyerinizde bir adım öne geçmenizi sağlayacak bir yolculuğa hoş geldiniz!\n\n\nKurs Güncellemeleri:\n- 10.06.2025 : 6 adet pratik SQL sorusu eklendi.",
      "target_audience": [
        "Veri analisti olmayı hedefleyen kişiler.",
        "SQL öğrenmek isteyen yeni başlayanlar.",
        "SQL bilgisini geliştirmek isteyen profesyoneller.",
        "Veritabanı yöneticileri ve veri bilimi ile ilgilenen bireyler."
      ]
    },
    {
      "title": "AI-Powered Automation with n8n: From News Feed to Dashboard",
      "url": "https://www.udemy.com/course/agentic-ai-n8n-ai-powered-automation-ai-agent/",
      "bio": "Your first n8n project starts here: Learn to build AI agents that analyze news, create reports, and send alerts.",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "No previous n8n experience needed. We'll start from scratch."
      ],
      "description": "Do you want to harness the power of Artificial Intelligence to build automations that save you time and deliver powerful insights? And what if you could do it all without writing a single line of code?\nMy name is Vladimir Raykov, and I'll be your instructor. I'm a Certified Google Cloud Generative AI leader, AWS AI Practitioner, and Project Management Professional.\nI currently work as an Agile Product Manager in a software development company.\nBy the end of this course, you won't just understand automation theory—you will have built a real, working AI agent from scratch.\nYou’ll create a complete \"News Intelligence System\" that automatically gathers online news, uses Google Gemini to analyze and summarize it, and transforms that raw information into a beautiful, interactive dashboard you can use every day\nThis is a hands-on, project-based course where every lesson builds towards our final goal.\nWe'll start with the fundamentals of the n8n automation platform.\nThen, we'll dive into connecting powerful AI models like Google Gemini.\nYou'll learn advanced prompt engineering, how to get perfectly structured data from your AI, and how to build automated dashboards in Google Sheets and send custom email alerts.\nI designed this course for marketing professionals, entrepreneurs, business analysts, and anyone wanting to leverage the power of AI and automation to save time and make smarter decisions—without needing to write a single line of code.\nIf you're ready to stop doing repetitive tasks and start building intelligent systems, then this course is for you.\nEnroll now, and I’ll see you in the first lesson!",
      "target_audience": [
        "Marketing Professionals & Digital Marketers",
        "Entrepreneurs & Small Business Owners",
        "Business & Data Analysts",
        "Operations Managers & Process Improvement Specialists",
        "\"No-Code\" / \"Low-Code\" Enthusiasts"
      ]
    },
    {
      "title": "Build Custom GPT with ChatGPT: Step by Step Free Guide",
      "url": "https://www.udemy.com/course/build-custom-gpt-with-chatgpt-step-by-step-free-guide/",
      "bio": "Master Custom GPT ChatBots: Beginner to Pro in Easy Steps: Build Custom GPT with ChatGPT",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic understanding of AI and chatbots.",
        "A computer with internet access.",
        "No prior programming experience required."
      ],
      "description": "Are you ready to unlock the full potential of AI and revolutionize the way you interact with technology? Our course, \"Build Custom GPT with ChatGPT: Step by Step Free Guide,\" is your gateway to mastering the art of creating custom GPT chatbots tailored to your unique needs. This comprehensive guide will take you on an exciting journey, where you'll learn the ins and outs of building, customizing, and deploying your own AI-powered chatbot using the advanced capabilities of ChatGPT.\nIn this course, you'll start with the basics and gradually move to more advanced concepts, ensuring you have a solid understanding of each step. We'll begin with an introduction to what custom GPT is and why it's a game-changer in the AI world. You'll learn how to set up your OpenAI account and understand the requirements needed for the course. By the end of this introductory section, you'll be equipped with the foundational knowledge to dive deeper.\nNext, we'll delve into the specifics of setting up a basic GPT structure. You'll learn how to choose and set up a profile picture and concept for your chatbot, ensuring it has a unique and engaging persona. We'll guide you through editing pictures with instructions to make the process seamless and straightforward.\nThe core of the course focuses on the three levels of custom GPT: Instructions, Knowledge, and Actions. Each level is crucial in building a robust and functional chatbot. You'll learn how to provide clear instructions to your GPT, enhance its knowledge base, and define actions that it can perform. This section is designed to give you hands-on experience and confidence in handling complex AI models.\nOnce you've built your custom GPT, we'll show you how to make it visible and test it effectively. You'll learn techniques to ensure your chatbot performs optimally and meets your expectations. Testing is a critical step, and we'll provide you with the tools and knowledge to troubleshoot and refine your AI model.\nBut that's not all. We'll also cover advanced customization techniques to help you create a chatbot that stands out. You'll learn how to integrate additional features, enhance user interactions, and continuously improve your GPT model. Our goal is to empower you with the skills to create a chatbot that not only functions well but also delivers an exceptional user experience.\nBy the end of this course, you'll have a fully functional, custom-built GPT chatbot ready to deploy. Whether you want to use it for personal projects, enhance customer service, or explore new business opportunities, the possibilities are endless. You'll gain valuable skills that are in high demand in today's tech-driven world.\nDon't miss out on this opportunity to become a part of the AI revolution. Enroll now and take the first step towards becoming an AI innovator. Remember, those who hesitate miss out on the chance to lead and make a difference. Join us and transform your ideas into reality with the power of custom GPT chatbots.",
      "target_audience": [
        "Beginners who want to learn about AI and chatbots.",
        "Tech enthusiasts interested in building custom AI solutions.",
        "Entrepreneurs looking to integrate AI into their business.",
        "Students and professionals seeking to enhance their skills in AI.",
        "Anyone curious about the potential of custom GPT chatbots."
      ]
    },
    {
      "title": "Introduction to the world of Data Analysis - Open to all",
      "url": "https://www.udemy.com/course/introduction-to-data-analysis-gate-moyyn/",
      "bio": "For jobseekers and career change aspirants - including AI Module - Learn from Industry Leaders",
      "objectives": [],
      "course_content": {
        "AI Fundamentals": [
          "Lecture"
        ],
        "Introduction to Data Analysis": [
          "Further reading materials to enter into Data Analysis domain - The first steps",
          "Deep dive materials",
          "Lecture video",
          "Lecture presentation"
        ],
        "Bonus": [
          "Bonus"
        ]
      },
      "requirements": [
        "No previous knowledge required! Suitable for candidates from any domain."
      ],
      "description": "Welcome to 'Introduction to the world of Data Analysis - Open to all', a first-of-its kind short program designed for jobseekers and career change aspirants.\nThis course is specifically created as a JOB-BASED TRAINING  program thereby teaching concepts hands-on and relevant to real-work environment. If you are looking for a job in Data Analysis or if you are a student who would like to get first experience in this domain, this course is exactly for you to understand what this domain is all about.\n\n\nExtra Module and Benefits:\nAI Fundamentals and Applications:\nUnlock exclusive access to one of our AI modules Learn from our experts leveraging AI to enhance your productivity and understand the wide variety of applications of AI across industries\n\n\nTrainers:\nDr. Chetana Didugu - Germany\nDr. Chetana Didugu is an Experienced Data Scientist, Product Expert, and PhD graduate from IIM Ahmedabad. She has worked 10+ years in various top companies in the world like Amazon, FLIX, Zalando, HCL, etc in topics like Data Analysis and Visualisation, Business Analysis, Product Management, Product Analytics & Data Science. She has trained more than 100 students in this domain till date.\n\n\nAravinth Palaniswamy - Germany\nFounder of 2 startups in Germany and India, Technology Consultant, and Chief Product Officer of Moyyn, and has 10+ years of experience in Venture Building, Product and Growth Marketing.",
      "target_audience": [
        "Students",
        "Jobseekers",
        "Aspiring Data Analysts",
        "Open to all"
      ]
    },
    {
      "title": "豊富な演習問題とKaggle実践で身に付ける！『Python データ分析 & 機械学習 ～パーフェクトスターターコース』",
      "url": "https://www.udemy.com/course/kagglepython/",
      "bio": "Numpy, Pandas, Matplotlib, Seaborn, scikit-learn & Kaggle ... データ前処理、分析、視覚化、さらに予想モデルの構築・評価まで。初めて出会うデータセットへ即応できる力を付けましょう！",
      "objectives": [
        "新規データの読み込みから機械学習モデルの評価までの一連の流れ",
        "機械学習に向けたデータの前処理 【Pandas, Scikit-learn】",
        "探索的データ分析",
        "データの視覚化（グラフの作成）【Matplotlib, Seaborn】",
        "DataFrameの操作方法（Pandasが提供する主要な操作）",
        "Numpyの多次元配列の理解と扱い方",
        "機械学習モデル　【scikit-learn】",
        "scikit-learnの幅広いモジュールの使い方",
        "機械学習モデルの構築とそのモデルの評価",
        "Kaggleの利用方法（アカウント作成から notebook でのモデル作成まで）",
        "Jupyter notebook もしくは Google Colaboratory の使用方法"
      ],
      "course_content": {
        "コースの紹介とファイルの一括ダウンロード": [
          "ようこそ！本コースのご紹介",
          "コースで使用するファイルの一括ダウンロード",
          "scikit-learnのバージョンについて",
          "ストレスのないご受講のために"
        ],
        "Google Colaboratoryで学習する方へ": [
          "Jupyter NotebookとGoogle Colaboratoryについて",
          "Google Colaboratoryの環境を整える",
          "Google Colaboratoryの基本的な使い方を知る"
        ],
        "Numpy、特にndarrayを理解する": [
          "このセクションについて（Numpyの公式サイトを確認する）",
          "Numpy多次元配列の「タイプ」と要素の「データタイプ」",
          "Numpy多次元配列の演算と統計量、そして形状",
          "Numpy多次元配列のデータタイプの種類とその変換",
          "2種類のメソッドを利用して数列を作成する",
          "randomモジュールで乱数配列、連続一様分布配列を生成する",
          "分散、標準偏差、正規分布とは",
          "多次元配列の次元、形状、サイズ、形状の変換",
          "多次元配列の演算例",
          "演習問題、演習解答レクチャーについて",
          "Numpy Exerciseにチャレンジ！",
          "演習問題（Numpy）：スピーディ解答"
        ],
        "DataFrameの構造を理解する": [
          "このセクションについて",
          "Seriesを作成する",
          "DataFrameを作成する",
          "ndarrayの結合とDatetimeIndex",
          "Series, DataFrameの結合、サンプルの抽出",
          "Series, DataFrameのndarray, list, dictionaryへの変換",
          "DataFrameの基礎データの取得方法と\"Axis\"の理解",
          "DataFrameのインデックスの変更とリセット",
          "DataFrameのインデックス、カラム名の更新",
          "欠損値とは？isnull()の使い方",
          "欠損値を持つサンプルの抽出方法",
          "欠損値の有無の視覚化とデータのCSV、PKLファイル保存",
          "DataFrame-1 Exerciseにチャレンジ！",
          "演習問題（DataFrame-1）：スピーディ解答"
        ],
        "DataFrameを自在に操作する": [
          "このセクションについて",
          "CSVファイル、PKLファイルからDataFrameを作成",
          "データの抽出（df.loc[]とdf.iloc[])",
          "データの条件付き抽出（条件文、filter、query）",
          "データを更新（変更）する方法",
          "基本統計量、ユニーク値を取得する",
          "クラス毎のグループ化とレコードのソート",
          "マルチインデックスの扱い方（クロスセクション）",
          "重複レコード、欠損値への対処方法",
          "欠損値を平均値で補間する",
          "scikit learnのSimple Imputerを使ってみる",
          "演習問題（DataFrame-2）：スピーディ解答"
        ],
        "カテゴリーで比較する、カテゴリカルプロット": [
          "このセクションについて",
          "Seabornのタイタニックデータセットの重複カラムを処理する",
          "不明な乗船地を予測する",
          "欠損した年齢について検討する + Seabornのスタイル設定",
          "年齢とチケットクラス、性別の間の相関",
          "相関関係と相関係数",
          "CATプロットとストリッププロット",
          "カウントプロットとバープロット",
          "四分位範囲、外れ値、ボックスプロット",
          "バイオリンプロットとスウォームプロット（とカーネル密度推定）",
          "演習問題（Catagorical Plot）：スピーディ解答"
        ],
        "分布と相関、ディストリビューション・リレーショナルプロット": [
          "このセクションについて",
          "ペンギンズのデータセットとヒストプロット",
          "ヒストプロットの表現、指標の変更とKDEプロット",
          "ジョイントプロットとスキャッタープロット",
          "RELプロットでグリッド型表示",
          "すべての数値データを扱うPairプロットと線形回帰のRegプロット",
          "複数のRegプロットを表示するLMプロットとシンプルなラインプロット",
          "オブジェクト指向型と呼ばれるプロットの作成",
          "データタイプCategoryとは",
          "♦ Pandas補講 ♦ mapメソッドと Datetime型への変換",
          "♦ Pandas補講 ♦ DatetimeIndexの機能を使う",
          "DatetimeIndexについての補足・訂正",
          "演習問題（Distribution & Relational Plot）:　スピーディ解答"
        ],
        "行列形式のマトリックスプロットと全般の詳細な表示設定": [
          "このセクションについて",
          "データセットIris（アヤメ属）の確認と再びCategory型について、np.where()について",
          "♦ Numpy補講 ♦ np.where() と np.select()で条件設定と値の置換",
          "ヒートマップとクラスターマップ",
          "高度なグリッド表現、ペアグリッドとFacetグリッド",
          "matplotlibのパイチャートと画像の保存方法",
          "Figure全体の表示をより詳細に設定する方法",
          "オブジェクト指向形式の詳細表示の設定方法1",
          "オブジェクト指向形式の詳細表示の設定方法2",
          "演習問題（Matrix Plot & Settings）：スピーディ解答"
        ],
        "カテゴリカル特徴量（変数）の取り扱い、機械学習のための新しい特徴量作成": [
          "このセクションについて",
          "scikit-learnのLabelEncoderでラベルを数値tとして記号化する",
          "ダミー変数化とは（Pandas.get_dummies()の使い方）",
          "scikit-learnのOneHotEncoderでダミー変数化を実行する",
          "get_dummiesのデメリットとは（訓練データ、テストデータ）",
          "OneHotEncoderのhandle_unknownとは（errorとignoreの使い分け）",
          "♦ Pandas補講 ♦ カテゴリカル変数の文字列を操作する（分離、置換、抽出）",
          "演習問題（Categorical Features）：スピーディ解答"
        ],
        "数値型の特徴量（変数）の取り扱い、機械学習のための新しい特徴量作成": [
          "このセクションについて",
          "スケーリングを行う目的、代表的な4つのスケーラーの紹介",
          "標準化、スタンダードスケーラーを実行する",
          "Robustスケーラー、MinMaxスケーラー、MaxAbsスケーラー",
          "ボストン住宅価格のデータセット利用について",
          "非線形変換とは",
          "Quantile Transformer / Power Transformerを使う",
          "データの離散化（ビニング、ディスクリタイジング）",
          "動画の内容とエクササイズの内容の相違について",
          "演習問題（Numeric Features）：スピーディ解答"
        ]
      },
      "requirements": [
        "Pythonの基本文法の理解（基礎学習を一巡していれば大丈夫です）",
        "Jupyter Notebookを利用できること（※ ない場合はGoogle Colaboratoryの使用でも問題ありません）",
        "Google Colaboratory使用方法の解説も行います。ただし、若干の操作方法、画面の見え方の違いがあります",
        "インターネットへの接続（データセットのインポート、Kaggleサイトの利用などにおいて必要）"
      ],
      "description": "ようこそ、pythonで始める機械学習スターターコースへ。\n「データ分析」、「機械学習」を学びたいとお考えの方々、漠然とした部分的理解を体系的に整理したいという方々、自信を持って本コースをおすすめいたします。\n長時間のコースとなりますが、セクションを適切に分割しているため、途中で道に迷うことなく最後までワンステップずつ受講を進めていただけます。\nディープラーニング、人工知能の分野に関心がある方々にとっても、本コースは最適なファーストステップとなるはずです。\n\n\n本コースの最終目標は、皆さんが新規のデータセットを自ら分析・整理し、機械学習モデルを構築し、評価できるようになることです。18時間以上にも及ぶ学習コースの中で、その目標達成に必要となる事柄を広く深く、丁寧に解説しています。データ分析・機械学習のベースとして、このコースはパーフェクトな内容に仕上がっていると自負しております。\n\n\n豊富な演習問題（240題以上、合計で400問以上のExercise）を通して各セクションで学んだ内容を着実に身に付けていくことができます。学習効率を考慮して、演習問題のビデオには音声解説は付けず、短時間で繰り返し確認してもらえるようにまとめています（倍速などで無駄なくスピーディーに復習できます）。\n最後のKaggle（世界最大の機械学習コンペのプラットフォーム）のセクションに至る頃には、テンポよく、楽しみながらデータの分析やモデルの構築などを進められるようになっているはずです。「次はどんなデータセットに挑戦してみようか？」と自ら動き出せる段階まで、皆さんを導いていきます。\n機械学習のモデルにはscikit-learnに含まれる代表的なアルゴリズムを使用します。本コースは元々、Pandasのデータフレームの操作とMatplotlib/Seabornでのデータの視覚化までを計画していました。ですが、皆さんの目標である実践までを含んだ内容を提供すべきだと考え直し、別に予定していたコースを合併し１本に集約しています。\n長時間のコースとは言え、当然すべてを網羅できるわけではなく、ニューラルネットワーク、ディープラーニングの分野へは到底踏み込むことはできません。本コースでは教師あり学習の代表的なアルゴリズムに絞って回帰や分類の課題に集中的に取り組み、基礎を築いていきます。この強固な基礎の上であれば他者のコード（Kaggleの公開コードが非常に参考になります）を参照して新しい知識をどんどん積み上げていけるものと思います。\n\n\nデータ分析の大半はデータの前処理であるとよく言われます。「データ前処理」（Data Preprocessing）とは、具体的には欠損値や重複値の処理、意味のあるデータへの変換、外れ値の取り扱い、機械学習のアルゴリズムに乗せるために求められるスケーリングやダミー変数化(ワンホットエンコーディング)などが挙げられます。この分野に関しては特に検討を重ね、段階的に適切に理解が進むように設計しています。データ前処理とモデルの評価までの一連の流れを学んだ後には、アルゴリズムをさらに詳細に学んだり、ドキュメントを参考に教師なし学習を学んだり、さらにはディープラーニングに挑戦するなどの次の課題がはっきりと見えてくると思います。\n\n\n実践課題としては、前述のKaggleを利用して、データ分析＋機械学習の実践を進めていきます。Kaggle notebook（Kaggleサイト上で使えるJupyter notebookと考えてよい）の使用方法、その他サイトに関わる事柄についても解説を行います。コンペへの参加は非常に高い壁ですが、ここから「データの世界」が一気に広がっていくことを実感していただけるはずです。\n\n\nぜひ、本コースへチャレンジしてみてください。\n力作です。是非ご期待ください。",
      "target_audience": [
        "Pythonを用いたデータ分析に関心のある方（適切な手法を選択し、円滑に分析を進められるようになります）",
        "機械学習を学びたい方（スターターコースとして非常に優れた内容となっています）",
        "データ処理の手法を身に付けたい方（数値のスケーリング、分類ラベルの変換の手法と意味を理解できます）",
        "機械学習に至るまでの流れを学びたい方（探索的データ分析からscikit learnでのモデル作成、予測値の評価方法まで繰り返し実践して身に付けます）",
        "とりあえずPandasを学びたいとお考えの方（各種プロット、さらには機械学習まで進めましょう）",
        "PandasやMatplotlib、Seabornが今ひとつわからないという方（迷わなくて済むよう手法を統一しましょう）",
        "Scikit Learnの代表的なモジュールを学びたい方（機械学習モデル作成の流れの中で使うモジュールを厳選してご紹介します）",
        "Kaggleに挑戦したい方（難度の高いものは扱いませんが、いくつものデータセットを元に実践を繰り返します）",
        "世の中に溢れるオープンデータセットを分析して遊びたい方（データ分析で新しい解釈や傾向を導き出しましょう。データに強くなりましょう）",
        "Pythonで何をしようかと迷っている方（データ分析・機械学習はPythonが代表的に活躍している分野です）"
      ]
    },
    {
      "title": "ADsP 2주 합격 올인원 패스",
      "url": "https://www.udemy.com/course/maso-ds-r-onc2005/",
      "bio": "[ADsP 합격 패키지] 2주 안에 데이터 분석 자격증 마스터하기",
      "objectives": [
        "상황에 따른 분석 방법론과 전반적인 데이터분석 프로세스 학습",
        "데이터분석 실무에 필수적인 통계적 지식과 R 지식 습득",
        "필수 이론 및 요점 정리를 통해 자격 검정 시험 완벽 준비",
        "과목별 최신 기출문제 풀이로 시험 준비 완성"
      ],
      "course_content": {},
      "requirements": [
        "데이터 분석에 대한 사전 지식은 필요 없습니다.",
        "R에 대한 지식이 있으면 도움이 되나, 필수 사항은 아닙니다.",
        "마소캠퍼스의 ‘비전공자도 배워서 바로 따는 ADsP’ 도서(11월 출간 예정)와 함께 학습하면 더욱 좋습니다."
      ],
      "description": "\"어제보다 성장하겠습니다. 그리고, 어제보다 성장하려는 사람을 돕겠습니다.\"\n\n\n마소캠퍼스의 진심과 소망을 담은 Actionable Content로,\n2013년부터 온오프라인으로 함께해 온 누적 강의 1억시간!\n이 소중한 경험과 시간은 언제나 마소캠퍼스와 수강생 모두의 성장의 원천입니다.\n\n\n-\n\n\n빅데이터 시대가 도래하고 데이터분석 전문가에 대한 수요가 증가하면서 데이터 지식과 역량은 비즈니스 필드에 상관없이 필수가 되었습니다.\n그렇다면 데이터 분석 전문성은 어떻게 증명할 수 있을까요?\n그 대표 척도가 바로 데이터분석 준전문가 자격 검정 시험(ADsP: Advanced Data Analytics Semi-Professional)입니다.\n\n\nADsP 자격 검정 시험은 데이터에 대한 기본지식을 바탕으로 데이터분석 기획 및 데이터분석 등의 직무를 수행하는 실무자를 인증하기 위한\n국내 최초의 빅데이터 분야 국가공인 자격증입니다.\n\n\n데이터, 통계 지식이 부족해도 ADsP 자격 검정 시험에 도전할 수 있을까요?\n당연히 할 수 있습니다!\n데이터 분석 역량은 단순히 툴을 다루는 능력만을 의미하지 않기 때문입니다.\n분석 결과를 직접 해석하고, 이를 바탕으로 다음 프로젝트 단계를 기획하는 것 역시 데이터 분석 역량입니다.\n코딩, 수학, 통계 지식에 자신없는 분들도 <단 2주만> 마소캠퍼스와 함께라면,\nADsP 자격 검정시험 준비 뿐만 아니라 데이터 분석에 대한 이론 지식과 실무 기초를 다질 수 있습니다.\n\n\n마소캠퍼스의 ADsP 2주 합격 올인원 패스 강의, 어떤 특징을 갖고 있을까요?\n\n\n1. 핵심 키워드 중심의 빠른 이론 습득\n: 꼭 필요한 이론 지식을 집약한 키워드로 오랜 시간 이론을 붙잡지 않고 빠르게 습득할 수 있도록 합니다.\n필수 이론 정리를 시작으로, 별도 제공되는 핵심 요점정리를 통해 자격 검정 시험을 위한 큰 흐름부터 차근차근 이해할 수 있습니다.\n2. 데이터분석 실무를 위한 기초\n: 자격증을 준비하지 않더라도 어디서부터 데이터 분석을 시작해야 할지 모르겠는 데이터 분석 비전공자,\n또는 머신러닝과 데이터분석 관련 지식을 쌓기 원하는 초보 실무자 수강생도 본 과정을 통해\n데이터 분석 실무에 필수적인 통계 지식과 R 지식을 습득할 수 있습니다.\n3. 하루 딱 2시간씩, 2주 안에 실전 준비 완성\n: 과목별 최신 기출문제 풀이로 실전감각을 키우고 문제은행형 시험을 단 2주 완성을 목표로 전략적으로 준비할 수 있습니다.\n단기간에 효율적으로 학습하여 ADsP 자격증을 취득하시길 원하는 분들에게 추천 드리는 과정입니다.\n\n\n자, 그렇다면 마소캠퍼스와 함께 다가오는 ADsP를 함께 준비해볼까요?\n\n\n-\n\n\n[ 강 사 소 개 ]\n\n\n김진숙\n現 마소캠퍼스 수석 교수\n롯데인재개발원, 하나은행, 현대커머셜 등 다수 기업 및 기관 강의\n홍익대, 아주대, 가천대, 성결대 등 다수 대학 강의\n김진숙 교수는 마소캠퍼스에서 빅데이터 부분 수석 교수로 빅데이터(R, 파이썬), HTML5/CSS3, JQueryMobile, 스크래치, 앱인벤터, IoT 등의 최신 IT 관련 기술 과정들까지 다양한 기업과 기관의 수강생들을 대상으로 열정 넘치는 강의를 이어가고 있습니다. 김진숙 교수는 스마트팜 IoT 프로젝트, 카 셰어링 앱 프로젝트 등 다수 프로젝트 지도 경력까지 겸비한 전문가입니다.",
      "target_audience": [
        "단기간에 국가공인 데이터 분석 준전문가(ADsP) 자격증 취득을 목표로 하는 분들",
        "데이터 분석/데이터 사이언스 관련 취업 또는 커리어를 쌓고 싶은 모든 분들",
        "빅데이터는 무엇이고 어떻게 활용되는지 배우고 싶은 분들",
        "통계적 지식은 물론 기초 문법부터 데이터 마이닝 실습까지 한 번에 끝내고 싶은 분들"
      ]
    },
    {
      "title": "画像処理の基礎：フィルタリング，パターン認識から撮像過程モデルまで",
      "url": "https://www.udemy.com/course/image_processing_python/",
      "bio": "Scikit-image, OpenCV, PIL, ScipyなどのPythonモジュールを駆使して画像処理を体験してみよう",
      "objectives": [
        "デジタル画像の基礎",
        "グレースケール画像とカラー画像，ヒストグラム，トーンカーブ，コントラスト，画像間演算",
        "二値画像処理，しきい値，ラベリング，モルフォロジー処理，細線化",
        "動画像処理，背景差分，フレーム間差分，オプティカルフロー，カルマンフィルタ，パーティクルフィルタ",
        "画像の幾何変換，回転，並進，補間，合成，アフィン変換，射影変換，同次座標",
        "フィルタリング，平均値フィルタ，ガウスフィルタ，エッジフィルタ，ラプラシアンフィルタ，Cannyエッジ検出，非線形フィルタ",
        "2次元フーリエ変換，スペクトル，2DFFT，周波数空間でのフィルタリング，ローパスフィルタ，ハイパスフィルタ，リンギング",
        "逆フィルタ，ウィーナフィルタ，超解像，HDR",
        "領域分割，テクスチャ特徴量，クラスタリング（k-means, GMM, mean shift），動的輪郭モデル，グラフカット",
        "テンプレートマッチング，ハフ変換，特徴点検出（Harris, FAST），特徴量マッチング（SIFT, ORB, KAZE），パノラマ画像作成",
        "パターン認識，教師あり・教師なし・半教師あり学習，kNN 最近傍法，SVM サポートベクトルマシン，Boosting，顔検出，ランダムフォレスト",
        "ディープラーニング，MLP 多層パーセプトロン，CNN 畳込みネットワーク，物体検出などの応用例",
        "撮像過程，透視投影，ピンホールカメラモデル，レンズモデル，歪曲収差，被写界深度，撮像素子，シャッター",
        "3次元復元，ステレオ視，エピポーラ幾何，キャリブレーション，アクティブステレオ，SfM",
        "色，分光分布，RGB表色系，XYZ表色系，カラーマッチング，YUV",
        "視覚系，眼球，視細胞，視覚情報経路",
        "jupyter notebookを用いたpythonによる画像処理例",
        "カメラ映像をpythonでリアルタイムに画像処理する方法",
        "OpenCVを用いた画像処理",
        "Scikit-imageを用いた画像処理"
      ],
      "course_content": {
        "はじめに": [
          "画像処理は実社会の様々な場面で利用されている",
          "レクチャースライド",
          "画像処理技術の応用"
        ],
        "デジタル画像・画素値変換・二値画像処理": [
          "デジタル画像＝画素の集まり",
          "空間と値の離散化：標本化と量子化",
          "カラー画像とグレースケール画像",
          "ヒストグラム",
          "統計量",
          "画像のノイズ",
          "トーンカーブ",
          "明るさ補正",
          "ガンマ変換",
          "コントラスト強調",
          "ヒストグラム平坦化",
          "カラー画像のトーンカーブ調整",
          "疑似カラー表示",
          "色相・彩度・輝度への変換",
          "色の調整",
          "画像間の演算",
          "画像のマスク",
          "アルファブレンディング",
          "しきい値による二値化",
          "二値化の例",
          "二値化の手法：大津のしきい値など",
          "適応的（局所的）な二値化",
          "ラベリング",
          "モルフォロジー処理：膨張・収縮",
          "凸包",
          "4近傍連結と8近傍連結",
          "細線化",
          "距離画像",
          "GIMP",
          "GIMP：トーンカーブ調整，コントラスト強調，二値化",
          "GIMP：色調整",
          "jupyter-notebookのインストール方法，このレクチャーで使用するコードの入手方法",
          "notebook：準備，画像ダウンロード",
          "notebook：画像のアップロード方法",
          "notebook：画像（2次元配列）へのアクセスは行・列",
          "notebook：カラー画像とグレースケール画像のチャンネル数",
          "notebook：RGBチャンネルの表示",
          "notebook：RGBの2つの格納方法 planar formatとpacked format",
          "notebook：RGBとBGR カラー画像の2つのフォーマット",
          "notebook：scikit-imageはRGB，opencvはBGR",
          "notebook：カラー画像のグレースケールへの変換",
          "notebook：ヒストグラム計算",
          "notebook：統計量の計算",
          "notebook：平均と標準偏差を計算するコードの書き方",
          "notebook：画素値のガンマ変換",
          "notebook：カラー画像のチャンネル別ガンマ変換",
          "notebook：疑似カラー表示",
          "notebook：画像の平均",
          "notebook：アルファブレンディング",
          "notebook：二値化・大津のしきい値と適応的二値化",
          "notebook：ラベリングとモルフォロジー処理",
          "notebook：細線化"
        ],
        "動画像処理・幾何変換": [
          "動画像＝画像の系列",
          "フレームレート，fps",
          "背景差分",
          "フレーム間差分",
          "統計的（適応的）背景差分",
          "オプティカルフロー",
          "密なオプティカルフローとカラー表示",
          "疎なオプティカルフロー：KLT追跡",
          "オンラインベイズフィルタ",
          "カルマンフィルタによる追跡例",
          "カルマンフィルタのシステム行列・観測行列の例",
          "パーティクルフィルタ",
          "幾何変換：画像の変形",
          "線形変換：スケーリング，回転，鏡映",
          "画像の変形における順方向・逆方向の標本化",
          "画像（画素値）の補間",
          "線形変換の合成",
          "平行移動：同次座標の導入",
          "同次座標",
          "アフィン変形・アフィン変換",
          "射影変換（ホモグラフィ）：最も一般的な変換",
          "GIMP：画像の変形（平行移動，アフィン変換，射影変換，非線形変換）",
          "notebook：画像の回転＋スケーリングありなし",
          "notebook：変換の合成（回転と並進）",
          "notebook：射影変換",
          "notebook：画像変換における順変換と逆変換の標本化",
          "notebook：様々な補間手法（双線形，双3次，等）",
          "GIMP：画像変形時の補間手法の指定",
          "opencv",
          "opencv：コマンドラインでカメラ画像を表示するだけのpythonコード",
          "opencv：カメラ画像を表示してマウスクリックを取得する",
          "opencv：カラー画像を表示してスライドバーから値を取得",
          "opencv：カメラ映像でフレーム間差分",
          "opencv：カメラ映像で背景差分",
          "opencv：適応的な背景差分",
          "opencv：オプティカルフローとカラー表示",
          "opencv：KTLトラッカーで疎なオプティカルフロー"
        ],
        "フィルタリングと周波数領域": [
          "各画素の周辺領域を利用した処理",
          "線形フィルタリング：畳み込み",
          "線形フィルタリング：畳み込み２",
          "線形フィルタリング：畳み込み３",
          "平均値フィルタ",
          "ガウスフィルタ",
          "フィルタカーネルの画像としての表示＋疑似カラー表示",
          "微分フィルタと差分近似",
          "エッジ強度の計算",
          "Prewittフィルタ，Sobelフィルタ",
          "ラプラシアンフィルタ：2次微分",
          "LoG：ラプラシアン＋ガウシアン",
          "LoGとゼロ交差",
          "LoGとDoG：1次元の例",
          "Cannyのエッジ検出",
          "アンシャープマスク",
          "アンシャープマスク：1次元の例",
          "非線形：メディアンフィルタ",
          "非線形：バイラテラルフィルタ",
          "1次元のフーリエ変換",
          "1次元フーリエスペクトルの例",
          "1次元のFFT：高速フーリエ変換",
          "2次元のフーリエ変換",
          "2次元のFFT",
          "2次元フーリエ変換の振幅スペクトル",
          "FFTを用いた周波数空間でのフィルタリング",
          "ボックス型ローパスフィルタ",
          "ガウス型ローパスフィルタ",
          "リンギング",
          "ハイパスフィルタ",
          "バンドパスフィルタ",
          "notebook：平均値フィルタ",
          "notebook：ガウスフィルタ",
          "notebook：ガボールフィルタ",
          "notebook：Sobelフィルタ，Prewittフィルタ",
          "notebook：Sobel, Prewitt, Robertフィルタの比較",
          "notebook：ラプラシアンフィルタ",
          "notebook：LoGとゼロ交差",
          "notebook：LoGとDoGの比較",
          "notebook：Cannyのエッジ検出器",
          "notebook：アンシャープマスク",
          "notebook：メディアンフィルタ",
          "notebook：バイラテラルフィルタ",
          "notebook：ノンローカルミーンフィルタ",
          "notebook：音声データ（wave）の高速フーリエ変換",
          "notebook：音声データの短時間FFTとスペクトログラム",
          "notebook：画像の2次元FFT",
          "notebook：FFTを用いた周波数領域でのフィルタリングと通常の空間領域でのフィルタリングの計算時間の比較",
          "notebook：円形ボックス型ローパスフィルタ",
          "notebook：円形ボックス型ローパスフィルタ２",
          "notebook：ガウス型ローパスフィルタ",
          "notebook：ハイパスフィルタ",
          "notebook：ガウス型ハイパスフィルタ",
          "notebook：バンドパスフィルタ",
          "opencv：カメラ映像をリアルタイムにフーリエ変換"
        ],
        "画像修復・領域分割・パターン検出・局所特徴量": [
          "画像の劣化と復元：撮像過程と画像処理",
          "逆フィルタ",
          "ウィーナフィルタ",
          "ウィーナフィルタによる復元例",
          "画像＝ベクトル，劣化過程＝行列",
          "様々な劣化過程と復元方法",
          "超解像：複数枚の画像から，１枚の画像から",
          "1枚の画像からの超解像と単なる画像拡大の比較例",
          "HDR画像，LDR画像とは",
          "HDRトーンマッピングとアーチファクト",
          "HDR合成 vs HDR風画像処理",
          "画像の領域分割：概観",
          "領域分割結果の例",
          "特徴量のクラスタリング",
          "テクスチャ特徴量とフィルタリング",
          "統計的テクスチャ特徴量",
          "k-meansクラスタリング",
          "混合ガウス分布（GMM）クラスタリング",
          "平均値シフト（mean shift）クラスタリング",
          "snake：動的輪郭モデル",
          "グラフカット：PowerPoint機能の例",
          "テンプレートマッチング",
          "テンプレートマッチングの拡張法",
          "ハフ変換による直線検出",
          "ハフ変換の投票空間の例",
          "ハフ変換による円検出",
          "局所特徴量の登場",
          "特徴的な点とはなにか：窓枠問題",
          "Harrisコーナー検出器",
          "FASTコーナー検出器",
          "DoGブロッブ特徴検出器",
          "対応点マッチング",
          "SIFT特徴量",
          "特徴点検出の例",
          "特徴マッチングの応用：パノラマ画像の作成",
          "特徴マッチングの応用例：電子式手ブレ補正",
          "特徴マッチングの応用例：物体除去とノイズ除去のアプリ",
          "notebook：ウィーナフィルタによる画像復元",
          "notebook：HDR合成とトーンマッピング",
          "notebook：領域分割 Felzenszwalb",
          "notebook：領域分割 slic",
          "notebook：領域分割 quickshift",
          "notebook：領域分割 wathershed法",
          "notebook：RGBのk-meansクラスタリングによる領域分割の実装例",
          "notebook：ガボール特徴も追加したk-meansクラスタリングによる領域分割の実装例",
          "notebook：動的輪郭モデルsnake",
          "notebook：テンプレートマッチング",
          "notebook：ハフ変換による直線検出",
          "notebook：DoGブロッブ特徴点検出器",
          "notebook：FASTコーナー検出器",
          "notebook：Harrisコーナー検出器",
          "notebook：GFTT（Good Feature to Track：追跡するのには良い特徴）検出器",
          "notebook：AKAZE特徴抽出",
          "notebook：BRISK特徴抽出",
          "notebook：ORB特徴抽出",
          "notebook：特徴点マッチングによるパノラマ画像作成１",
          "notebook：特徴点マッチングによるパノラマ画像作成２",
          "notebook：特徴点マッチングによるパノラマ画像作成３",
          "notebook：特徴点マッチングによるパノラマ画像作成４",
          "opencv：カメラ映像からテンプレートマッチング",
          "opencv：カメラ映像からハフ変換で直線検出",
          "opencv：カメラ映像からハフ変換でコインの円検出",
          "opencv：特徴点検出 FAST, ORB, Harris, DoG",
          "opencv：カメラ映像から特徴マッチング"
        ],
        "パターン認識・機械学習・ディープラーニング": [
          "パターン認識とは",
          "画像認識，画像識別とは",
          "テキスト認識，音声認識とは",
          "回帰とは",
          "識別と回帰：まとめ",
          "訓練サンプルの学習とテストサンプルの識別",
          "教師あり学習とは",
          "教師なし学習とは",
          "半教師あり学習とは",
          "kNN：最近傍識別器",
          "SVM：サポートベクトルマシン",
          "HoGによる人物検出",
          "弱識別器を統合するBoosting",
          "Viola&Jones顔検出器",
          "ランダムフォレスト",
          "Kinect：ランダムフォレスト＋デプスカメラ",
          "ディープラーニング（深層学習）とは",
          "従来のパターン認識とディープラーニングの違い",
          "従来のパターン認識とディープラーニングの違い２",
          "ニューラルネットワーク：パーセプトロン",
          "ニューラルネットワーク：深層学習",
          "ディープニューラルネットワークの構造",
          "CNN：畳み込みネットワーク",
          "畳み込み層でのフィルタリング",
          "畳み込みの種類：パディング，ストライド",
          "例：物体検出",
          "例：物体検出２",
          "例：semantic / instance segmentation（意味的な領域分割）",
          "例：姿勢推定",
          "notebook：顔画像に対するkNN",
          "notebook：顔画像に対するSVM",
          "notebook：顔画像に対するランダムフォレスト",
          "notebook：顔画像に対するAdaBoost",
          "notebook：手書き数字画像をクラスタリング：kmeans, mean shift, GMM",
          "notebook：顔画像Olivettiをクラスタリング：kmeans, mean shift, GMM",
          "notebook：顔画像LFWをクラスタリング：kmeans, mean shift, GMM",
          "notebook：手書き数字画像MNISTをクラスタリング：kmeans",
          "Google Colab",
          "Google Colab：CNNで犬猫画像Cats and Dogsの識別１",
          "Google Colab：CNNで犬猫画像Cats and Dogsの識別２",
          "Google Colab：CNNで犬猫画像Cats and Dogsの識別３",
          "opencv：カメラ映像から顔と目をリアルタイム検出"
        ],
        "カメラモデルと撮像過程": [
          "デジタルカメラの内部構造",
          "カメラ内のミラーとミラーレス一眼レフ",
          "ピンホールカメラモデル",
          "カメラ・オブスキュラ",
          "ピンホールカメラモデルと透視投影",
          "カメラの画角",
          "画角とズームレンズ",
          "薄肉レンズモデル",
          "焦点距離：ピンホールカメラモデルの焦点距離と薄肉レンズモデルの焦点距離",
          "厚肉レンズモデル，実際のカメラレンズの構造",
          "歪曲収差：たる型歪み，糸巻き型歪み",
          "収差：色収差，球面収差，コマ収差",
          "周辺光量の低下：cos4乗則，口径蝕，ケラレ",
          "周辺光量の低下：アプリによる画像処理効果",
          "絞りと被写界深度",
          "被写界深度",
          "被写界深度と許容錯乱円",
          "ISO感度と画像ノイズ",
          "シャッタースピード，メカニカルシャッターと電子シャッター",
          "まとめとコツ：絞り，シャッタースピード，ISO",
          "グローバルシャッターとローリングシャッター",
          "Exif：画像ファイルに埋め込まれた撮像情報",
          "イメージセンサ：CCDとCMOS",
          "スミアとブルーミング：CCDのアーチファクト",
          "CCDとCMOSの映像での違い：グローバルシャッターとローリングシャッター",
          "センササイズ：35mmフィルムとフルサイズ",
          "コンピュテーショナルフォトグラフィとは",
          "撮像過程の計算化",
          "4次元ライトフィールド",
          "実物フィルカメラ：ミノルタα303siとオリンパスPEN-F",
          "実物一眼レフ：ニコンD5200とズームレンズ，魚眼レンズ",
          "実物webカメラを分解：ロジクールQcam Cool QVP-30SV",
          "実物スマホカメラへ百均のアタッチレンズ：広角レンズ，魚眼レンズ，マクロレンズ",
          "notebook：Jpeg画像ファイルからEXIFを取得",
          "notebook：周辺光量の低下を追加",
          "notebook：歪曲収差の補正と追加",
          "notebook演習問題：月と人物",
          "notebook演習問題：マラソン中継カメラ"
        ],
        "3次元復元・色・視覚": [
          "単一視点では奥行きは不定",
          "ステレオ視：三角測量の原理",
          "平行ステレオ",
          "KITTI：ステレオのためのデータセット",
          "一般のステレオ：平行化，多視点ステレオ（MVS）",
          "エピポーラ幾何：エピポール，エピポーラ平面，エピポーラ線",
          "平行化",
          "カメラ校正（キャリブレーション）",
          "数式：3次元世界座標から2次元画素座標へ",
          "アクティブステレオ：光切断法，3Dスキャナ",
          "アクティブステレオの例：Kinect，グレーコードパターン投影",
          "TOFを用いた3D計測",
          "Structure-from-Motion (SfM)：運動からの3次元復元",
          "SfMの例",
          "SLAM：ドローン映像からリアルタイムに3次元復元の例",
          "カラー画像の撮像方式：単板式と3板式",
          "単板式カラーフィルタとデモザイキング",
          "色の三原色：加法混色，減法混色，スペクトル",
          "画像の撮像と分光感度特性",
          "標準光源：D65のスペクトル分布",
          "表色系と色空間",
          "杆体と錐体の分光分布特性",
          "等色実験とRGB表色系",
          "RGB表色系とRGB値",
          "XYZ表色系",
          "L*a*b*表色系",
          "カラーマッチング",
          "映像信号用の信号変換：YUV, YCbCr, YPbPr",
          "動画用の信号変換：YUV422, YUV420",
          "輝度と色を表す変換：HSV, HSL",
          "色空間：用途別まとめ",
          "視覚系：眼球の構造",
          "視細胞：杆体と錐体",
          "杆体と錐体の分布",
          "視覚情報の伝達経路",
          "曖昧図形と錯視から考える人間の視覚情報処理",
          "notebook：ステレオマッチング",
          "notebook：色空間の変換",
          "notebook：色空間の変換２",
          "notebook: YUV444, YUV422, YUV420",
          "notebook：色情報だけ空間解像度を落としてみる",
          "Regard3D",
          "Regard3D：画像から3次元復元１",
          "Regard3D：画像から3次元復元２"
        ]
      },
      "requirements": [
        "Pythonのコードを理解できる程度の基礎知識",
        "必要なpythonモジュールをインストールできるスキル",
        "jupyter notebookを実行できるスキルと環境",
        "カメラ映像を取り込むためのwebカメラ",
        "Google Colabを利用する場合：gmailアカウントとcolaboratoryの設定"
      ],
      "description": "このコースでは，画像処理の基礎をスライド形式のレクチャーで学び，さらにPythonコードを実行して実際に画像処理を体験します．このコースの目標は，画像処理に関する幅広い知識を身につけ，画像処理の基本的な手法を理解することです．明るさ補正のためのトーンカーブによる画素値の変換，背景差分などの動画像処理，ラベリングなどの二値画像処理から始めて，フィルタリング，フーリエ変換による周波数スペクトル，局所特徴量などの手法や，顔検出，CNNによる簡単な画像認識，カメラモデル，3次元復元など，古典的な画像処理からコンピュータビジョンまで，画像処理をする上で知っておく知識を網羅的に解説しています．\n画像処理のトピックは幅広いため，このレクチャーでは一つ一つの内容を深く解説することよりも，様々な場面で遭遇する画像処理の基礎技術のコンセプトを紹介することにしています．ここで紹介した内容は様々な画像処理の応用場面で遭遇すると思いますので，その場合には各トピックをもっと詳しく解説している他の資料を参考にしてください．\nスライド形式のレクチャーを聞くだけでなく，Pythonの画像処理ライブラリを用いて，インタラクティブなプログラミング環境で実際にPythonコードを実行しながら，実践的な画像処理を学びます．Jupyter-notebookによるインタラクティブなプログラミングに加えて，Webカメラから実際にカメラ映像を取り込んでリアルタイムに画像処理を行う方法も学びます．そのため一つのPythonモジュールにこだわらず，必要に応じて様々なモジュールを使います．Notebookでは主にscikit-imageを使いますが，コマンドラインで実行してカメラ映像を読み込み表示するためにはopencvを使います．その他のモジュールも使います（高速フーリエ変換にはscipy，exif情報読み込みにはPILなど）．またメジャーな画像処理OSSであるGIMPも紹介します．\nプログラミングの注意：Pythonやその他の言語でのプログラミング経験があることを前提にしていますので，Python自体の説明は省略しています．ただしnotebookやコマンドラインで実行するだけで画像処理が体験できるようにしていますので，Pythonコードを書くスキルは必要ありません．",
      "target_audience": [
        "画像処理に興味を持つ学生・エンジニア",
        "幅広い意味での画像処理の知識を勉強したい人",
        "Pythonで画像処理をするためのコードを体験したい人",
        "画像処理の様々な応用事例を知りたい人"
      ]
    },
    {
      "title": "Data Science Advanced Analytics Interview Prep. Kit - 182+",
      "url": "https://www.udemy.com/course/data-science-advanced-analytics-interview-preparation-kit/",
      "bio": "A walkthrough from the essentials of 182+ data science interview questions from linear regression to advance analytics",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Data Science Interview Q’s — I. 38Questions",
          "Data Science Interview Q’s — II. 28Questions",
          "Data Science Interview Q’s — III. 35Questions",
          "Data Science Interview Q’s — IV. 36Questions",
          "Data Science Interview Q’s — V.37Questions"
        ],
        "Bootcamp:- A - Z Data Science Course": [
          "Scribd Link",
          "SlideShare",
          "Data Science Bootcamp: Types of probability distribution. Lab 1",
          "Data Science Bootcamp: Types of probability distribution. Lab 2",
          "Data Science Bootcamp: Types of probability distribution. Lab 3",
          "Data Science Bootcamp: Types of probability distribution. Lab 4",
          "Data Science Bootcamp: Hypothesis Testing - Lab. I",
          "Data Science Bootcamp: Hypothesis Testing - Lab. II",
          "Data Science Bootcamp: Hypothesis Testing II - Lab. I",
          "Data Science Bootcamp: Hypothesis Testing II - Lab. II",
          "Data Science Bootcamp: Multiple Sample Test - Lab. I",
          "Data Science Bootcamp: Multiple Sample Test - Lab. II",
          "Data Science Bootcamp: Multiple Sample Test - Lab. III",
          "Data Science Bootcamp: Multiple Sample Test - Lab. IV",
          "Neural Network using excel",
          "Python Premium Learning Pack"
        ]
      },
      "requirements": [
        "Basic Math Skills",
        "Basic computer skills",
        "Basic Structured Query Language for faster understanding",
        "Basic Data Science understanding"
      ],
      "description": "The Course is Designed from scratch for Beginners as well as for Experts.\n*Unlimited update on Questionnaires every month*.\n*Updated with Bonus: Machine Learning, Deep Learning with Python - Premium Self Learning Resource Pack Free\nLearn the skills of tomorrow, the silicon valley way\nFocus on extracting insights from data of any form or shape using a multitude of statistical disciplines for the purpose of creating new products & services or improving the existing ones by predicting the probability in an event. And as the enormity of data is on the rise, there is a desperate need for professionals with data science skills to get valuable insights into it. According to NYTimes there are fewer than 10,000 qualified people in the world and universities are only graduating about 100 candidates each year.\nWhy data science is so important?\n\n• Twitter Since 2015, the number of posts increased 45% to more than 850,000 tweets per minute.\n• YouTube usage has more than tripled in the last two years with users uploading 400 hours of new video each minute of every day.\n• Instagram users like 2.5 million posts every minute!\n• Google Around 4 million Google searches are conducted worldwide each minute of every day.\n• Finally, data sent and received by mobile internet users 1500 000TB.\nSo, with the above examples of how much data gets generated, now how many hidden insights and patterns for accurate future predictions that we can actually achieve by using data science.\n\nAccording to Forbes, the annual demand for Data Scientist jobs in the United States itself will increase by 364 million by 2020.\nThe average salary for a Data Scientist is $170,436.\nWhat is the career progression path for data science professionals?\n• Data Scientist: with a vast knowledge of Data Science, Machine Learning, and Business Intelligence tools. Data Scientist stands high as Everest.\n• Data Analyst: in 2022, the world will generate data 50times more than now, and with each day that passes by the data generated is infinite with that to analyze those data, data analyst jobs will never have to see the face of recession. On LinkedIn itself, there are average 400 new jobs every 12 hours.\n• Data Science Trainer: in this present date a lack of knowledge of these advanced data science techniques gives a vast opportunity to become the fountain of data science for others.\n• Business analyst: with the role of defining and managing the business requirements, the business analyst takes the lead in every business decision-making process of the organization.",
      "target_audience": [
        "Anyone looking for a career to machine learning and artificial intelligence.",
        "Anyone looking for a career to Big Data Engineer",
        "Anyone looking for a career to Data Scientist, Business analyst, Data Engineer, Analyst"
      ]
    },
    {
      "title": "Data Analysis for Beginners with Microsoft Excel",
      "url": "https://www.udemy.com/course/data-analysis-for-beginners-with-microsoft-excel/",
      "bio": "Data Analysis for Beginners: Unlock the Secrets of Excel and ChatGPT for Powerful Insights!",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic familiarity with computers and the internet.",
        "A desire to learn and work with data.",
        "No prior experience with data analysis is required."
      ],
      "description": "Unlock the power of data analysis with our comprehensive “Data Analysis for Beginners with Microsoft Excel & ChatGPT” course! If you're new to data analysis and feel overwhelmed by the complex world of data, this course is your ideal starting point. We take you by the hand and guide you through each essential step, making data analysis accessible, manageable, and even enjoyable. Microsoft Excel has long been the go-to tool for data analysis, and combined with ChatGPT, you’ll discover a new level of efficiency and insight.\nThis course will introduce you to the foundations of data analysis using Microsoft Excel, one of the most widely used tools in the industry. You’ll learn everything from setting up Excel to performing advanced data analysis tasks. With step-by-step guidance, you’ll acquire a deep understanding of how to manage and manipulate data, creating meaningful insights that can help you make better decisions, whether for personal projects, career development, or business use. Our unique integration of ChatGPT will further empower you, showing you how AI can simplify your data tasks, provide insights, and even assist with data interpretation.\nImagine the doors this skill could open for you. Data analysis is critical in every industry, from finance and healthcare to marketing and logistics. With the skills you’ll gain here, you’ll be prepared to analyze data efficiently and draw actionable conclusions—whether you’re looking to enhance your current job, make a career switch, or simply grow your analytical capabilities. Don’t let the world of data leave you behind. Equip yourself with the skills needed to thrive in the data-driven world!",
      "target_audience": [
        "Absolute beginners interested in learning data analysis.",
        "Students who want to explore the potential of data analytics.",
        "Professionals aiming to enhance their Excel skills and data-handling abilities.",
        "Small business owners who want to analyze and understand data trends.",
        "Individuals interested in using ChatGPT as a data analysis assistant.",
        "Anyone who wants to develop valuable, in-demand analytical skills."
      ]
    },
    {
      "title": "Data Science and Machine Learning With Python",
      "url": "https://www.udemy.com/course/data-science-and-machine-learning-with-python-hindi/",
      "bio": "Learn Python, NumPy, Pandas, Matplotlib, Scipy, Scikit-Learn, Machine Learning, Model Building, Data Analysis and more!",
      "objectives": [
        "Complete Python Programming, Python Numpy, Python Matplotlib, Scikit-Learn, Data Analysis,",
        "Machine Learning With Python, Python Scipy, Practise Papers and Quizes, Real Life Projects, K-nearest neighbors (KNN)",
        "Mean Median Mode, Standard Deviation, Data Distribution, Normal Data Distribution, Scatter Plot",
        "Linear Regression, Polynomial Regression, Multiple Regression, Scale, Train/Test, Confusion Matrix",
        "Hierarchical Clustering, Logistic Regression, Grid Search, Categorical Data, K-means, Cross Validation",
        "Python Data Types, Python Lists, Python Tuples, Python Sets, Python Dictionaries, Python If ... Else",
        "Python While and for Loops, Python Arrays, Python Classes and Objects, Python Modules, Python Iterators, Python Try Except",
        "NumPy Data Types, NumPy Array Iterating, NumPy Random, Random Data Distribution, Pandas DataFrames, Pandas - Analyzing DataFrames"
      ],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Complete Python Tutorial for Beginner to Expert": [
          "Why you should Learn Python",
          "Visual Studio Code installation tutorial",
          "Install Anaconda along with Jupyter Notebook",
          "How to import code from Visual Studio Code to Jupyter Notebook",
          "Ask Anything, Any Time",
          "Variables in Python",
          "Assign Multiple Values in Variable",
          "Assign Global Variables in Python",
          "What are the Data Types in Python",
          "Numeric Data Types in Python",
          "Using Strings in Python",
          "Using Strings in Python Part 2",
          "Using Python Operators",
          "Using Lists in Python",
          "Add & Remove List Item in Python",
          "Loop Through a List in Python",
          "Sort, Copy & Join List in Python",
          "Using Tuple in Python",
          "How to Loop Tuple in Python",
          "How to Join Tuple in Python",
          "Using Sets in Python",
          "Using Dictionary in Python",
          "Access Dictionary in Python",
          "How to Loop Dictionary in Python",
          "If Else & Elif statement in Python",
          "While Loop in Python",
          "Learn For Loop in Python",
          "Functions & Arguments in Python",
          "Lambda Function in Python",
          "Arrays in Python",
          "Classes and Objects in Python",
          "Inheritance in Python",
          "Iterators in Python",
          "Local and Global scope in Python",
          "Using Module in Python",
          "Using Datetime Module in Python",
          "Built-in Math Function in Python",
          "JSON - JavaScript Object Notation in Python",
          "RegEx - Regular Expression in Python",
          "Try Except Else Finally Exceptions in Python",
          "How to Open, Read and Close File in Python",
          "How to Write, Append & Delete File in Python",
          "Test Your Skills with Python Quiz",
          "Ask Anything, Any Time"
        ],
        "Python MatplotLib Tutorial": [
          "Introduction & Installation of MatPlotLib",
          "MatPlotLib Markers",
          "MatPlotLib Line, Line Style, Line Color & Line Width",
          "MatPlotLib Pyplot and Plotting",
          "MatPlotLib Labels and Title",
          "MatPlotLib Adding Grid Lines to a Plot",
          "MatPlotLib Subplot, Display Multiple Plots",
          "MatPlotLib Scatter Plots - Create, Size, Colors, Alpha",
          "MatPlotLib Bars - Create, Width, Colors",
          "MatPlotLib Histograms - hist()",
          "MatPlotLib Pie Charts - All Functions",
          "MatPlotLib Adding Data Points to Bar and Line Graphs",
          "Ask Anything, Any Time"
        ],
        "Python Numpy Tutorial": [
          "Introduction to Numpy - Numerical Python",
          "NumPy - Creating Arrays with Dimensions",
          "NumPy - Indexing, Accessing Array Element",
          "NumPy Array Slicing",
          "NumPy Data Types",
          "NumPy Array Copy and View",
          "NumPy Array Shape",
          "NumPy Array Reshaping",
          "NumPy Array Iterating",
          "NumPy Joining Array",
          "NumPy Splitting Array",
          "NumPy Searching Array",
          "NumPy Sorting Array",
          "NumPy Filter Array",
          "NumPy Random Numbers",
          "NumPy Random Data Distribution",
          "NumPy Random Permutation & Shuffling",
          "NumPy Seaborn",
          "NumPy Normal (Gaussian) Distribution",
          "NumPy Binomial Distribution",
          "NumPy Poisson Distribution",
          "NumPy Uniform Distribution",
          "NumPy Logistic Distribution",
          "NumPy Multinomial Distribution",
          "NumPy Exponential Distribution",
          "NumPy Chi Square Distribution",
          "NumPy Rayleigh Distribution",
          "NumPy Pareto Distribution",
          "NumPy Zipf Distribution",
          "NumPy ufuncs",
          "NumPy Create Your Own ufunc",
          "NumPy Arithmetic ufunc",
          "NumPy Rounding Decimals",
          "NumPy Summations & Cumulative Sum",
          "NumPy Products & Cumulative Product",
          "NumPy Differences",
          "NumPy LCM Lowest Common Multiple",
          "NumPy GCD or HCF",
          "NumPy Trigonometric Functions",
          "NumPy Hyperbolic Functions",
          "NumPy Tutorial ufuncs Set Operations",
          "NumPy Quiz",
          "Ask Anything, Any Time"
        ],
        "Python Pandas Tutorial": [
          "Python Pandas Introduction & Installation",
          "Python Pandas Series",
          "Python Pandas DataFrames",
          "Python Pandas Read CSV",
          "Python Pandas Read JSON",
          "Python Pandas Viewing & Analyzing DataFrames",
          "Python Pandas Cleaning Data",
          "Python Pandas Cleaning Data of Wrong Format",
          "Python Pandas Cleaning & Fixing Wrong Data",
          "Python Pandas Removing Duplicates",
          "iloc function in pandas dataframe",
          "Pandas Quiz - Test Your Skills",
          "Ask Anything Any Time"
        ],
        "Bonus Content - Python Scipy Tutorial": [
          "Python Scipy Introduction & installation",
          "Python Scipy Constants",
          "Python Scipy Optimizers",
          "Python Scipy Sparse Data",
          "Python SciPy Graphs",
          "SciPy Spatial Data",
          "Python SciPy Matlab Arrays",
          "Python SciPy Interpolation",
          "SciPy Quiz - Test Your Skills"
        ],
        "Bonus - Maths and Statistics Tutorial (This section will updated overtime)": [
          "How to import code from Visual Studio Code to Jupyter Notebook",
          "Mean Median Mode",
          "Range Function || Range Function in Python",
          "standard deviation statistics",
          "percentile in data science",
          "quartile deviation",
          "Boxplot graphical representation",
          "Histogram Graphical Representation",
          "creating scatter plot",
          "correlation coefficient explained"
        ],
        "Python Machine Learning Tutorial": [
          "Complete Python Machine Learning Tutorial in Hindi",
          "Machine Learning - Mean Median Mode",
          "Machine Learning - Standard Deviation and Variance",
          "Machine Learning - Percentiles",
          "Machine Learning - Big Data Distribution",
          "Machine Learning - Normal Data Distribution",
          "Python Machine Learning - Scatter Plot",
          "Machine Learning - Linear Regression",
          "Machine Learning - Polynomial Regression",
          "Machine Learning - Multiple Regression || Coefficient",
          "Machine Learning - Scale Feature",
          "Machine Learning - Training and Testing the Data",
          "Confusion Matrix || Accuracy Precision Recall F-score",
          "Machine Learning - Hierarchical Clustering",
          "Machine Learning - Grid Search",
          "Ask Anything Any Time"
        ],
        "IMP - Live Projects - Creating Models in Data Science and Machine Learning": [
          "machine learning model with Linear Regression",
          "creating machine learning model with Logistic regression algorithm",
          "Building Machine learning model with Decision Tree Classifier algorithm",
          "Creating Machine Learning Model with Random Forest Classifier",
          "Creating Machine Learning Model with Naive bayes Algorithm",
          "Creating Machine Learning Model With K Means Clustering Algorithm",
          "Creating Machine Learning Model with Principal Component Analysis PCA",
          "Creating Machine Learning Model With Gradient Boosting Machines GBM",
          "Creating machine Learning Model using Neural Network",
          "Creating Deep Learning Model Using Recurrent Neural Network RNN",
          "Project 1",
          "Project 2"
        ],
        "Bonus Suggestion: What Next in Career Path ?": [
          "What Next in Career Path ?"
        ]
      },
      "requirements": [
        "No Programming Experience Needed. You Will Learn Everything You Need To Know.",
        "As a standard practice, I ensure timely updates of the course content, typically within a one-month timeframe. This means that you will receive all the latest course updates and related materials at no additional cost to you."
      ],
      "description": "Data Science is an interdisciplinary field that leverages statistical analysis, data exploration, and machine learning techniques to derive knowledge and meaningful insights from data.\n\n\nDefinition of Data Science:\nData Science encompasses various processes, including data acquisition, thorough analysis, and informed decision-making.\nData Science involves the identification and interpretation of data patterns to make predictive assessments.\n\n\nThrough the application of Data Science, organizations can achieve:\n1. Improved decision-making processes, enabling the selection between alternatives (A or B) with greater confidence.\n2. Predictive analysis that anticipates future events or trends, aiding in proactive planning.\n3. Discovery of hidden patterns and valuable information within datasets, leading to actionable insights.\n\n\nApplications of Data Science:\nData Science finds extensive application across diverse industries such as banking, consultancy, healthcare, and manufacturing.\nExamples of Data Science applications include:\n1. Optimizing route planning for shipping purposes.\n2. Anticipating potential delays in flights, ships, trains, etc., through predictive analysis.\n3. Crafting personalized promotional offers for customers.\n4. Determining the best time to deliver goods for maximum efficiency.\n5. Forecasting future revenue for a company.\n6. Analyzing the health benefits of specific training regimens.\n7. Predicting election outcomes.\n\n\nData Science Integration in Business:\nData Science can be seamlessly integrated into various facets of business operations where relevant data is available, including:\n1. Consumer goods industries for market analysis and consumer behavior prediction.\n2. Stock markets for financial analysis and forecasting.\n3. Industrial settings for process optimization and quality control.\n4. Political scenarios for opinion polls and election forecasts.\n5. Logistic companies for route optimization and supply chain management.\n6. E-commerce platforms for personalized product recommendations and customer segmentation.\n\n\nRole of a Data Scientist:\n\n\nA Data Scientist requires expertise in several key disciplines:\n1. Machine Learning: Utilizing algorithms to uncover patterns and make predictions.\n2. Statistics: Employing statistical methods to analyze and interpret data.\n3. Programming (Python): Writing code for data manipulation and analysis.\n4. Mathematics: Applying mathematical concepts for modeling and analysis.\n5. Databases: Working with databases to extract, manage, and process data.\n\n\nData Scientists follow a systematic approach in their work:\n1. Formulating pertinent questions to comprehend the business problem at hand.\n2. Exploring and collecting relevant data from diverse sources, such as databases, web logs, and customer feedback.\n3. Extracting and transforming the data into a standardized format for consistency and comparability.\n4. Cleaning the data by eliminating erroneous values.\n5. Identifying and addressing missing values by suitable replacements, such as averages.\n6. Normalizing the data by scaling values to practical ranges for meaningful analysis.\n7. Analyzing the data, identifying patterns, and making informed predictions.\n8. Presenting the results with valuable insights in a manner that the organization can easily grasp and utilize.\n\n\nIn conclusion, Data Science stands as a pivotal discipline that empowers businesses and industries to harness the full potential of their data. As you embark on your Data Science journey, I wish you the best of luck in your endeavors. May your pursuit of knowledge and insights be fruitful, and may you find innovative solutions to complex challenges. Remember that your dedication and expertise as a Data Scientist can drive meaningful impact, enabling organizations to make informed decisions, predict future trends, and unlock the hidden value within their data. Best of luck on your path to becoming a proficient Data Scientist!",
      "target_audience": [
        "12 Types of People Who Should Study Data Science",
        "Person who have Intrinsic Intellectual Curiosity",
        "Person who have Interest in Machine Learning",
        "Person who Seeking Job Stability",
        "Person whose Priority on Career Flexibility",
        "Person who have Startup and Business Goals",
        "Person who Developing Data-Driven Marketing",
        "Person who have A Desire to Cultivate Business Expertise",
        "Person who Able to Prioritize Tasks and Take Initiative",
        "Person who have Interest and Ability in Coding",
        "Person who have Analytical Skills and Expertise in Mathematics",
        "Person who have Communication Skills"
      ]
    },
    {
      "title": "Hands On: Building A Full Stack Java App (Classical ML)",
      "url": "https://www.udemy.com/course/hands-on-building-full-stack-java-app-classical-ml/",
      "bio": "Implement Supervised Machine Learning to Detect HTTP Intrusion Attempts on your Server",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Take previous two courses in this set to have the app built. Or at least know enough about programming and Git to clone the repo and see for yourself.",
        "You don't need knowledge about machine learning, I will explain everything here."
      ],
      "description": "This course is part 3 in our series, teaching you how to build a full-stack Java application, from nothing to fully functioning! In this course, we will continue the work from part 2, changing the way the configuration works from just raw .json files in the file system, to a full config page on the frontend. This entails using html forms, sending and handling complex data structures to the backend, and saving these data into a database. We are also introducing more TypeScript, so we will be creating TypeScript types to ensure the data in the form is formed correctly.\n\n\nWe will then also tackle Machine Learning. We will go over what it is, how we use it in this project, and how to implement it yourself. The flow of the ML in the course is as follows:\n\n\n1. GridLog reads raw HTTP logs from the host\n2. GridLog saves raw logs\n3. GridLog reads raw logs from DB and parses into searchable columns\n4. While saving the parsed logs, if GridLog detects these are HTTP logs, it will run Machine Learning inference on the logs to try and predict if the logs are malicious or benign\n5. If malicious, save the DB entry as possible intrusion attempt\n6. Mark attempt in Log Viewer\n\n\nTo get the above working, we will need to use free Machine Learning libraries to do supervised training on a dataset provided to you. Once trained, we can run inference on any new incoming HTTP logs.\n\n\nSo for this course, you will learning how to implement all of this into an already working by simply adding in a new Docker container to your working docker orchestration file (Docker compose in our case)\n\n\nSource Code for this code can be found on our GitHub page which is found in the resources section of our Introduction lecture.",
      "target_audience": [
        "programmers looking to learn the basics about classical machine learning: how to implement, how it works, how to integrate into a working app"
      ]
    },
    {
      "title": "First course in Data Structures in C",
      "url": "https://www.udemy.com/course/first-course-in-data-structures-in-c/",
      "bio": "Discussion of data structures in C",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Data types and Data Structures",
          "Linear Data Structures",
          "Lecture 3A: Linear Data Structures",
          "Lecture 3B: Linear data Structure",
          "Quiz on Linear Data structures",
          "Non-Linear Data Structures",
          "Lecture 6A: Non-Linear data structure: Graph",
          "Applications of Data Structures"
        ]
      },
      "requirements": [
        "No"
      ],
      "description": "Now a day, getting good job in IT companies everyone should be excellent in programming. C language is known as very good and middle level programming language in the industry. Data structures are one of the most significant parts of the programming. The main objective of this course is to give fundamental knowledge about linear data structures and non-linear data structures which will help them to implement the actual data structures and their ideas as an application. This course will cover all the basic data structures and their applications. In this course the working principles of linear data structures such as arrays, linked lists, stacks, queues, trees and graphs will be discussed. All this discussion will be with respect to C language. After successfully completion of this course student will be able to understand the basics and way of implementation of the data structures as well as the applications of these data structures. The students will be able to select the appropriate data structures for the specified application. Selection of proper data structures reduces the complexity of the coding and provides simpler way for software development. All these data structures can be implemented in various programming languages very easily. This course is open for all the students.",
      "target_audience": [
        "Any one wants to build career as a programmer."
      ]
    },
    {
      "title": "オープンソースAIモデル活用入門－画像・音声・言語にわたる多様なモデルの使い方から、文書QA・ファインチューニングまで",
      "url": "https://www.udemy.com/course/ai-open-model/",
      "bio": "本講座では、画像認識・画像生成・文書生成・音声認識といった多様なAIモデルを動作させる方法や、文書生成において独自データで追加学習しカスタマイズする方法を学びます。また、OpenAI等のサービスとの差別化についても学び、使い所を理解できます",
      "objectives": [
        "画像認識・画像生成・言語生成・音声認識などの多様なAIモデルを動作させることができるようになります",
        "AIモデルをファインチューニングする方法を学び、自分なりにカスタマイズできるようになります",
        "HuggingFace(オープンソースモデルのプラットフォーム)を使用する方法を理解することができます",
        "PDFなどから情報を参照しながらAIモデルに対話させる方法を理解できます"
      ],
      "course_content": {
        "はじめに": [
          "本講座の概要",
          "講座を受けて得られること",
          "受講にあたっての注意事項"
        ],
        "オープンソースAIモデルの導入": [
          "オープンソースとは",
          "オープンソースAIモデルの他サービスとの比較",
          "オープンソースAIモデルのメリットとデメリット",
          "今後の展開の予想"
        ],
        "オープンソースAIモデルの使用方法": [
          "Hugging Faceの導入",
          "Hugging Faceの使用方法",
          "AIモデルを動作させるための計算資源",
          "CLIPによる画像認識",
          "Google Colabの使用方法",
          "CLIPによる画像認識のデモ",
          "Stable Diffusionによる画像生成",
          "Stable Diffusionの具体的な処理内容",
          "Stable Diffusionによる画像生成のデモ",
          "日本語版Llama2による文章生成",
          "日本語版Llama2による文章生成のデモ",
          "Whisperによる音声文字起こし",
          "Whisperの具体的な処理内容",
          "Whisperによる音声文字起こしのデモ"
        ],
        "大規模言語モデルに関する深掘り": [
          "講座で扱う内容の紹介",
          "言語モデルの仕組み",
          "ニューラルネットワークの概要",
          "TransformerとEncoder/Decoderモデル",
          "文章のトークン化",
          "大規模言語モデルの学習ステップ",
          "言語モデルの学習ステップ1: Pretraining",
          "言語モデルの学習ステップ2: Instruction Tuning",
          "言語モデルの学習ステップ3: RLHF"
        ],
        "モデルのファインチューニング": [
          "Instruction Tuningに挑戦してみよう",
          "Instruction Tuningのテクニック",
          "LoRAの概要",
          "LoRAの具体的な処理内容",
          "LoRAと他のファインチューニング手法との比較",
          "量子化の概要",
          "ビットでの表現形式",
          "Instruction Tuningのデモ"
        ],
        "ドキュメントQ&A": [
          "外部情報を参照した対話",
          "ドキュメントQ&Aの仕組みの全体像",
          "ドキュメントQ&Aを行う際のプロンプト設定",
          "関連文章の検索方法",
          "文章のベクトル化",
          "LlamaIndexを用いたドキュメントQ&A",
          "ドキュメントQ&Aのデモ"
        ],
        "まとめ": [
          "振り返り"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonを触ったことがある人・学びたい人"
      ],
      "description": "このコースでは、実践的な演習を通じてオープンソースのAIモデルの使用法を学びます。これには、画像認識、画像生成、文書生成、音声認識といった幅広いアプリケーションに対する基本から応用までの技術が含まれます。\nさらに、注目度が高い文書生成においては、独自のデータセットを使ってAIモデルの追加学習（ファインチューニング）を行ったり、PDFファイルなどを用いた対話機能の拡張も実施します。\nまた、HuggingFaceというプラットフォームを利用する方法も学びます。これにより、世界中で共有されているさまざまなモデルを自分で活用する能力が身につき、多岐にわたる用途に柔軟に対応するスキルを獲得できます。\n多様なモデルの理論を学ぶだけでなく、実際に自分で作り動かすことで、楽しさや成果、今後の自分たちの業務などへのつながりを実感することを目指しています。\n\n\n講義の内容\nSection1\n本講座の導入を行います\nSection2\nオープンソースAIモデルとはどういったものなのかを学びます\nSection3\nHugging Faceを利用して、実際にオープンソースAIモデルを動かしながら画像認識・画像生成・文章生成・音声認識の仕組みを学びます\nSection4\n大規模言語モデルの仕組みに関して深掘りを行い、モデルの挙動およびモデルを学習するための手順を学びます\nSection5\n自分たちのデータを使用してモデルを実際にファインチューニングし、自分なりにAIモデルをカスタマイズしていきます\nSection6\nドキュメントQ&Aの仕組みを学び、オープンソースAIモデルを用いて実際に動作させます\nSection7\nこれまでのセクションの振り返りを行います\n\n\nスライドは下記を使用：\nCREDITS: This presentation template was created by Sldiesgo and includes icon by Flaticon, infographics & images by Freepik and content by Eliana Delacour",
      "target_audience": [
        "多様なAIモデルの使い方やカスタマイズ方法を学びたい人、Python初学者"
      ]
    },
    {
      "title": "Veri Bilimi için İstatistik: Python ile İstatistik",
      "url": "https://www.udemy.com/course/veri-bilimi-icin-istatistik-python-ile-istatistik/",
      "bio": "Sıfırdan adım adım İstatistik. Dağılımlar, Hipotez Testleri, AB Testleri.",
      "objectives": [
        "Veri okuryazarlğı",
        "Veri, değişken ve ölçek türleri",
        "Merkezi eğilim ölçüleri",
        "Dağılım ölçüleri"
      ],
      "course_content": {
        "Veri Okuryazarlığına Giriş ve Temel Kavramlar": [
          "Giriş",
          "Veri Okuryazarlığı Nedir?",
          "Popülasyon ve Örneklem",
          "Gözlem Birimi",
          "Değişken ve Değişken Türleri",
          "Ölçek Türleri"
        ],
        "Merkezi Eğilim Ölçüleri": [
          "Aritmetik Ortalama",
          "Medyan",
          "Mod",
          "Kartiller",
          "Merkezi Eğilimin Önemini Anlamak"
        ],
        "Dağılım Ölçüleri": [
          "Değişim Aralığı",
          "Standart Sapma",
          "Varyans",
          "Çarpıklık",
          "Basıklık"
        ],
        "İstatistiksel Düşünce Modelleri": [
          "İstatistiksel Düşünce Modelleri",
          "Verinin Tanımlanması",
          "Verinin Organize Edilmesi ve İndirgenmesi",
          "Verinin Gösterimi",
          "Verinin Analiz Edilmesi ve Yorumlanması"
        ],
        "Python Programlama": [
          "Giriş",
          "Python Giriş",
          "Kurulum İşlemleri: Windows",
          "Kurulum İşlemleri: Linux",
          "Kurulum İşlemleri: MacOS",
          "İlk Adım",
          "Spyder Kişiselleştirme",
          "Çalışma Dizini Ayarları",
          "Sayılar ve Karakter Dizilerine (Strings) Giriş",
          "Karakter Dizilerini (Strings) Yakından Tanıyalım",
          "Uzunluk Bilgisine Erişmek: len Metodu",
          "Büyük Küçük Harf Dönüşümü: upper & lower Methodları",
          "Karakter Değiştirme: replace Metodu",
          "Karakter Kırpma İşlemleri: strip Metodu",
          "Metodlara Genel Bakış",
          "Karakter Dizilerinde Alt Küme İşlemleri (Substrings)",
          "Değişkenler (Variables)",
          "Tip Dönüşümleri",
          "Kod Çıktısını Ekrana Yazdırmak: print",
          "Liste Oluşturma",
          "Liste İçi Tip Sorgulama",
          "Liste Elemanlarına Erişmek",
          "Listelere Eleman Ekleme & Değiştirme & Silme",
          "Metodlar ile Eleman Ekleme & Silme: append & remove",
          "İndekse Göre Eleman Ekleme & Silme: insert & pop",
          "Diğer Liste Metodları",
          "Tuple (Demet) Oluşturma",
          "Tuple (Demet) Eleman İşlemleri",
          "Sözlük (Dictionary) Oluşturma",
          "Sözlük (Dictionary) Eleman Seçme İşlemleri",
          "Sözlük Eleman Eklemek Değiştirmek",
          "Set (Küme) Oluşturma",
          "Set (Küme) Eleman Ekleme & Çıkarma",
          "Setlerde Fark İşlemleri: difference & symmetric_difference",
          "Setlerde Kesişim & Birleşim İşlemleri: intersection & union",
          "Setlerde Sorgu İşlemleri",
          "Fonksiyonlara Giriş ve Fonksiyon Okuryazarlığı",
          "Fonksiyon Nasıl Yazılır?",
          "Bilgi Notuyla Çıktı Üretmek",
          "İki Argümanlı Fonksiyon Tanımlamak",
          "Ön Tanımlı Argümanlar",
          "Ne Zaman Fonksiyon Yazılır?",
          "Fonksiyon Çıktılarını Girdi Olarak Kullanmak: return",
          "Local ve Global Değişkenler",
          "Local Etki Alanından Global Etki Alanını Değiştirmek",
          "True-False Sorgulamaları",
          "if",
          "else",
          "elif",
          "Uygulama: if ve input ile Kullanıcı Etkileşimli Program",
          "for Döngüsü",
          "for Döngüsü Örnek",
          "Döngü ve Fonksiyonların Birlikte Kullanımı",
          "Uygulama: if, for ve Fonksiyonların Birlikte Kullanımı",
          "break & continue",
          "while"
        ],
        "Örnek Teorisi ve Güven Aralığı": [
          "JupyterLab",
          "Örnek Teorisi",
          "Örnek Teorisi Uygulama",
          "Betimsel İstatistikler",
          "Betimsel İstatistikler Uygulama",
          "Güven Aralıkları",
          "İş Uygulaması: Fiyat Stratejisi Karar Destek Sistemi"
        ],
        "Olasılığa Giriş ve Olasılık Dağılımları": [
          "Olasılığa Giriş ve Olasılık Dağılımları",
          "Bernoulli Dağılımı",
          "Bernoulli Dağılımı Uygulama",
          "Büyük Sayılar Yasası",
          "Binom Dağılımı",
          "İş Uygulaması: Reklam Harcaması Optimizasyonu",
          "Poisson Dağılımı",
          "İş Uygulaması: İlan Girişi Hata Olasılıklarının Hesaplanması",
          "Normal Dağılım",
          "İş Uygulaması: Ürün Satış Olasılıklarının Hesaplanması"
        ],
        "Hipotez Testleri": [
          "Hipotez Testi Nedir?",
          "Hipotezler ve Türleri",
          "Hata Tipleri",
          "p-value",
          "Hipotez Testi Adımları",
          "Tek Örneklem T Testi",
          "İş Uygulaması: Ürün Satın Alma Adım Optimizasyonu",
          "İş Uygulaması: Web Sitesinde Geçirilen Sürenin Testi",
          "Tek Örneklem T Testi Varsayım Kontrolü",
          "Tek Örneklem T Testi Python Uygulaması",
          "Nonparametrik Tek Örneklem Testi",
          "Tek Örneklem Oran Testi",
          "İş Uygulaması: Dönüşüm Oranı Testi",
          "Bağımsız İki Örneklem T Testi",
          "İş Uygulaması: ML Modelinin Başarı Testi",
          "Bağımsız İki Örneklem T Testi Varsayım Kontrolü",
          "Bağımsız İki Örneklem T Testi Python Uygulaması",
          "Nonparametrik Bağımsız İki Örneklem Testi",
          "Bağımlı İki Örneklem T Testi",
          "İş Uygulaması: Şirket İçi Eğitimin Performans Etkisi Ölçümü",
          "Bağımlı İki Örneklem T Testi Varsayım Kontrolü",
          "Bağımlı İki Örneklem T Testi Python Uygulaması",
          "Nonparametrik Bağımlı İki Örneklem Testi",
          "İki Örneklem Oran Testi",
          "İş Uygulaması: AB Testi (Kullanıcı Arayüzü Deneyi)"
        ],
        "Varyans Analizi": [
          "Varyans Analizi",
          "İş Uygulaması: Anasayfa İçerik Stratejisi Belirleme",
          "Varyans Analizi Varsayım Kontrolü",
          "Varyans Analizi Python Uygulaması",
          "Nonparametrik Hipotez Testi"
        ],
        "Korelasyon Analizi": [
          "Korelasyon Analizi",
          "İş Uygulaması: Bahşiş ile Ödenen Hesap Arasındaki İlişkinin İncelenmes",
          "Varsayım Kontrolü",
          "Korelasyon Katsayısı Hipotez Testi",
          "Nonparametrik Korelasyon Testi"
        ]
      },
      "requirements": [
        "İnternet bağlantısı ve bilgisayar/tablet/telefon",
        "Veri dünyasına ilgi"
      ],
      "description": "Günümüz en değerli kaynaklarından birisi olan veri ve bu veriyi anlamlandırmak için gerekli olan istatistik bilgisini herkesin anlayabileceği bir şekilde ele alıyoruz.\nVeri odaklı gelişen dijital dünyada klasik okuryazarlık yerini veri okuryazarlığına bırakmıştır. Kullandığımız sosyal medya kanalları, internet siteleri ve mobil uygulamalar her an veri üretmektedir. Bu veriyi okuyabilmek ve sayılar ile konuşabilmek toplumun her kesimi için bir zorunluluk haline gelmiştir.\nBu kurs ile veri okuryazarlığını öğreneceğiz ve internette yer alan ya da kendi verilerimizi nasıl tanıyabileceğimizi, nasıl yorumlayabileceğimizi ve nasıl görselleştirebileceğimizi öğreneceğiz.\nVeri Bilimi için İstatistik konusu ile İstatistik literatüründe yer alan konuları gerçek hayat uygulamaları ile ele alacağız\n\n\nVeri Okuryazarlığı Temel Kavramlar\nVeri, Değişken ve Ölçek Türleri\nMerkezi Eğilim Ölçüleri\nDağılım / Yayılım Ölçüleri\nİstatistiksel Düşünce Modelleri\nÖrnek Teorisi ve Güven Aralığı\nOlasılığa Giriş ve Olasılık Dağılımları\nHipotez Testleri\nVaryans Analizi\nKorelasyon Analizi\n\n\nDerslerde görüşmek üzere!",
      "target_audience": [
        "Veri odaklı kariyer planı yapan herkes"
      ]
    },
    {
      "title": "Inteligencia Artificial: Machine Learning con ESP32 y Python",
      "url": "https://www.udemy.com/course/redes-neuronales-artificiales-con-arduino/",
      "bio": "Aprende Tensorflow para ESP32, Redes Neuronales Artificiales, Casos de uso reales con microcontroladores",
      "objectives": [
        "Comprender los fundamentos de las redes neuronales artificiales desde cero.",
        "Recolectar datos de sensores utilizando la ESP32 para alimentar modelos de Machine Learning.",
        "Analizar, almacenar y preprocesar datos en Python para su uso en redes neuronales.",
        "Entrenar modelos de clasificación binaria, multiclase y regresión en Python.",
        "Exportar la arquitectura y los pesos entrenados a código compatible con ESP32.",
        "Implementar redes neuronales embebidas en microcontroladores para ejecución autónoma.",
        "Optimizar modelos para funcionar en hardware de recursos limitados.",
        "Desarrollar proyectos prácticos reales aplicando Machine Learning en ESP32."
      ],
      "course_content": {
        "Bienvenida": [
          "¿Qué vas a aprender?"
        ],
        "Prerrequisitos - Hardware e Instalación del Software (OBLIGATORIO)": [
          "Lista de materiales",
          "Instalación de Arduino IDE",
          "Introducción a Arduino IDE",
          "Instalar ESP32 en Arduino IDE",
          "Mi primer programa en ESP32",
          "Instalación de Python",
          "Instalación de Tensorflow y otras bibliotecas necesarias"
        ],
        "Programa Redes Neuronales desde Cero": [
          "Capa de entrada",
          "Pesos",
          "Bias o Sesgo",
          "Suma Ponderada",
          "Funciones de Activación",
          "Función de Activación: Sigmoidal",
          "Función de Activación: Lineal",
          "Función de Activación: Relu",
          "Función de Activación: Softmax"
        ],
        "Caso de Uso 1 - Optimización de Ejercicios de Gimnasio": [
          "Planteamiento del problema",
          "Solución al problema",
          "Lista de materiales",
          "Recolección de datos: Lectura del acelerómetro",
          "Recolección de datos: Lectura del acelerómetro con Bluetooth",
          "Recolección de datos: Guardar datos con Python Parte 1",
          "Recolección de datos: Guardar datos con Python Parte 2",
          "Recolección de datos: Guardar datos con Python Parte 3",
          "Recolección de datos: Análisis de datos",
          "Entrenamiento: Importar datos",
          "Entrenamiento: Preprocesamiento de datos",
          "Entrenamiento: Dividir datos en entrenamiento y prueba",
          "Entrenamiento: Arquitectura de la red neuronal",
          "Entrenamiento: Función de error (pérdida)",
          "Entrenamiento: Optimizador",
          "Entrenamiento: Entrenar el modelo",
          "Entrenamiento: Analizar resultados",
          "Validación del modelo",
          "Exportar parámetros y la arquitectura de la red neuronal",
          "Implementar el modelo en ESP32: Programación"
        ],
        "Caso de Uso 2 - Reconocimiento de Gestos para la Interacción Humano-Robot": [
          "Planteamiento del problema",
          "Solución al problema",
          "Lista de materiales",
          "Recolección de datos",
          "Análisis de datos",
          "Entrenamiento: Importar datos",
          "Entrenamiento: Preprocesamiento de datos",
          "Entrenamiento: Dividir datos en entrenamiento y prueba",
          "Entrenamiento: Arquitectura de la red neuronal",
          "Entrenamiento: Función de pérdida y optimizador",
          "Entrenamiento: Entrenar y validar el modelo",
          "Implementar el modelo en ESP32: Resultados experimentales"
        ],
        "Caso de Uso 3 - Sensor inteligente de distancia a 360 grados": [
          "Planteamiento del problema",
          "Solución al problema",
          "Lista de materiales",
          "Lectura de RSSI entre dos dispositivos WIFI",
          "Recolección de datos",
          "Análisis de datos",
          "Entrenamiento: Importar, preprocesar y dividir datos",
          "Entrenamiento: Arquitectura de la red neuronal",
          "Entrenamiento: Función de pérdida y optimizador",
          "Entrenamiento: Entrenar el modelo",
          "Entrenamiento: Validar el modelo",
          "Implementar el modelo en ESP32: Programación",
          "Implementar el modelo en ESP32: Resultados experimentales"
        ],
        "Esta es una versión antigua (DISPONIBLE SOLO HASTA DICIEMBRE 2025)": [
          "¿Que es Inteligencia Artificial?",
          "Hardware y Software unidos por la Inteligencia Artificial",
          "¿Que son las redes neuronales artificiales?",
          "¿Por qué usar aprendizaje automático en microcontroladores?"
        ],
        "Requisitos (Extras)": [
          "Requisitos de hardware y software",
          "Instalación de Arduino IDE",
          "Introducción a Arduino IDE",
          "Instalar ESP32 en Arduino IDE",
          "Mi primer programa en ESP32",
          "Instalación de Python y TensorFlow",
          "Lista de materiales"
        ],
        "Componentes de una red neuronal": [
          "Modelo simplificado de una red neuronal en Arduino",
          "Funciones de activación",
          "Modelo simplificado de una neurona biológica",
          "Función de activación escalón",
          "Función de activación escalón simétrico",
          "Función de activación lineal",
          "Función de activación sigmoidal",
          "Función de activación tangente hiperbólica",
          "Función de activación relu",
          "Función de activación Softmax"
        ],
        "Etapa de entrenamiento": [
          "Pasos de la etapa de entrenamiento",
          "Sensor Arduino",
          "Enviar datos de Arduino a Python",
          "Enviar datos de Arduino a Python Pruebas Experimentales",
          "Graficas de datos en tiempo real",
          "Interfaz grafica para adquisición de datos",
          "Generar datos de entrada",
          "Normalización de datos: Teoría",
          "Normalización de datos: Programación",
          "Codificación binaria",
          "Codificación mediante enteros",
          "One hot encoding",
          "Dividir el conjunto de datos (datos de entrenamiento y prueba)",
          "Establecer hiper-parámetros (épocas, tasa de aprendizaje y neuronas ocultas)",
          "Red neuronal de entradas múltiples",
          "Red neuronal de múltiples entradas y neuronas",
          "Red neuronal de múltiples capas de neuronas",
          "Inicializar pesos y sesgos (bias)",
          "Funciones de pérdida",
          "Optimizadores",
          "Entrenamiento"
        ]
      },
      "requirements": [
        "Conocimientos básicos de programación (preferible en Arduino o C++).",
        "Conocimientos básicos de Python",
        "Ganas de aprender y experimentar con Machine Learning en microcontroladores."
      ],
      "description": "Lleva la Inteligencia Artificial a un nuevo nivel implementando Machine Learning directamente en un ESP32, sin depender del computador para ejecutar modelos. En este curso aprenderás paso a paso a diseñar, entrenar y desplegar redes neuronales en microcontroladores usando Python para el entrenamiento y ESP32 para la implementación, aplicadas en proyectos prácticos reales.\n\n\nMódulo 1 – Preparación del entorno\nInstalaremos y configuraremos Python, Arduino IDE y las librerías necesarias, incluyendo TensorFlow, y aprenderás cómo programar la ESP32 desde Arduino IDE.\n\n\nMódulo 2 – Fundamentos y programación de redes neuronales\nEntenderás desde cero qué es una red neuronal: capas, pesos, bias y funciones de activación (Sigmoide, ReLU, Softmax). A la par, programaremos la arquitectura directamente en la ESP32 para su ejecución autónoma.\n\n\nMódulo 3 – Ejercicios de precisión en gimnasio\nCrearemos un sistema que determina si un ejercicio de precisión (flexión/extensión) se realiza correctamente, resolviendo un problema de clasificación binaria.\n\n\nMódulo 4 – Reconocimiento de gestos para control de robots\nDesarrollaremos un sistema capaz de identificar diferentes gestos y controlarlos mediante una red neuronal, resolviendo un problema de clasificación multiclase.\n\n\nMódulo 5 – Sensor inteligente de distancia 360°\nCrearemos un sistema que estima distancias positivas en cualquier dirección usando señal RSSI de Wi-Fi, ideal para identificar zonas seguras o restringidas, aplicando un problema de regresión.\n\n\nDurante el curso destacarás en:\nRecolección de datos para entrenar modelos.\nExportación de arquitectura y pesos a ESP32.\nComprensión de fundamentos de redes neuronales desde cero.\nCreación de proyectos prácticos reales de clasificación y regresión.\n\n\nInscríbete hoy y lleva tus proyectos al siguiente nivel con inteligencia artificial embebida.\n\n\nNOTA: Desde la Sección 7 es contenido antiguo (Aún vigente para estudiantes anteriores hasta DICIEMBRE DEL 2025)",
      "target_audience": [
        "Estudiantes y entusiastas que quieran aprender Machine Learning aplicado a microcontroladores",
        "Desarrolladores que deseen implementar redes neuronales en ESP32",
        "Personas con conocimientos básicos de programación que quieran dar el salto a la inteligencia artificial",
        "Makers y creadores de proyectos que busquen aplicar IA en hardware de recursos limitados"
      ]
    },
    {
      "title": "Data Science con Python - Numpy & Pandas [2025]",
      "url": "https://www.udemy.com/course/data-science-con-python-numpy-pandas/",
      "bio": "Aprende Python desde cero y domina la Ciencia de Datos con Pandas. Descubre los secretos de Data Science en Python.",
      "objectives": [
        "Dominar el lenguaje de propósito general Python desde cero, incluyendo su instalación.",
        "Comprender y profundizar en el flujo completo de un proyecto de Data Science para convertirse en científico de datos.",
        "Aprender todos los conceptos de estadística necesarios para poder analizar los datos que le rodean.",
        "Utilizar librerías como Numpy o Pandas para la importación desde fuentes heterogéneas (CSV, Excel, texto plano, SQL, Web, redes sociales, cloud,…).",
        "Podrá realizar la limpieza y transformación de datos.",
        "Adquirirá un conocimiento extenso en Data Science que podrá aplicar de inmediato a un precio muy asequible en comparación con otros programas.",
        "Como utilizar NumPy y Pandas para resolver problemas específicos de análisis de datos"
      ],
      "course_content": {
        "Introducción al Análisis de Datos con Python": [
          "Bienvenida / Información importante",
          "¿Qué es Python y qué nos proporciona para el análisis de datos?",
          "Instalación Python + Jupyter",
          "Información importante para realizar los ejercicios",
          "Importar librerías y fuentes de datos",
          "Visualización básica con Matplotlib",
          "Visualización básica con Matplotlib - Caso Práctico"
        ],
        "Fundamentos del lenguaje Python": [
          "Variables en Python",
          "Creación de listas, extracción y modificación de datos",
          "Conceptos avanzados de creación de listas",
          "Uso de funciones en Python (in-built)",
          "Creación de funciones en Python y argumentos flexibles",
          "Funciones lambda",
          "Métodos en Python",
          "Cómo crear diccionarios en Python",
          "Uso de función zip para creación de diccionarios en base a listas",
          "Comparadores en Python",
          "Bucles en Python",
          "Comprensión de listas en python"
        ],
        "Conceptos Estadísticos para el Análisis de Datos": [
          "Variables y conceptos básicos",
          "Varianza de una variable",
          "Correlación de variables",
          "Histogramas",
          "Análisis con percentiles",
          "Funciones densidad de probabilidad",
          "Cálculo de previsiones (forecast) y media móvil"
        ],
        "Análisis numérico con Numpy": [
          "Introducción a la librería Numpy",
          "Selección de datos con array Numpy",
          "Arrays 2D en Numpy",
          "Cálculo estadístico con Numpy"
        ],
        "Análisis de datos con Pandas": [
          "Introducción a la librería Pandas ¿qué es un dataframe?",
          "Creación de un dataframe a partir de un diccionario",
          "Cómo importar datos desde un fichero de texto plano (txt, csv,…)",
          "Selección de datos en un dataframe Pandas",
          "Métodos útiles de un dataframe Pandas",
          "Eliminar duplicados, valores erróneos y columnas de un dataframe Pandas",
          "Interpolación de datos",
          "Filtrar datos en un dataframe Pandas",
          "Ordenación valores en un dataframe Pandas",
          "Crear columnas en un dataframe para cadenas de texto",
          "Crear columnas en un dataframe a partir de un diccionario con map",
          "Crear columnas en un dataframe a partir de funciones lambda",
          "Crear columnas en un dataframe a partir de funciones condicionales",
          "Renombrar y reordenar columnas de un dataframe Pandas",
          "Cómo crear pivot tables en Pandas",
          "Uso de groupby en Pandas",
          "Concatenación de dataframes (union)",
          "Combinación de dataframes (merge)"
        ],
        "Importación y exportación de datos con Pandas": [
          "Cómo importar datos desde un fichero Excel",
          "Introducción a las BBDD relacionales / Modelos de datos",
          "Cómo importar datos desde una BBDD SQL",
          "Cómo importar datos desde una página Web",
          "Cómo importar datos desde una página Web (Web scraping)",
          "Cómo importar datos desde un fichero semi-estructurado JSON",
          "Cómo importar datos desde Redes Sociales",
          "Cómo importar datos desde Cloud (AWS / Azure / Google Cloud)",
          "Exportación de datos a CSV y Excel",
          "Exportación de datos a BBDD SQL"
        ],
        "PROYECTO DATA SCIENCE - ANÁLISIS DE DATOS CON PANDAS": [
          "CASO PRÁCTICO 1: ANÁLISIS DE DATOS CON PANDAS"
        ],
        "CONCLUSIONES Y CLASE EXTRA": [
          "Siguientes Pasos",
          "Clase Extra",
          "Recursos Extra"
        ]
      },
      "requirements": [
        "Ninguno, el curso comenzará aprendiendo Python y Data Science desde cero.",
        "Se utilizará Python y su distribución Anaconda totalmente gratuita guiándole paso a paso en su instalación."
      ],
      "description": "¿Quiere iniciar su camino para convertirse en científico de datos y dominar el área de Data Science?\n---\nEscuche de otros alumnos por qué este es el curso de Ciencia de Datos MEJOR VALORADO en español:\n\"Excelente curso, el instructor cuenta con gran dominio del tema y las explicaciones de las clases son muy practicas y fáciles.\"-- Manuel\n\n\n\"Realmente el profesor explica muy bien, el curso está muy bien extructurado, me siento muy feliz de haber comprado el curso.\"--Leyna Soranlly\n\n\n\"Muy buen curso y sobre todo bien preparado por el profesor. Propone retos en forma de ejercicios para que el alumno ejercite los conceptos en cada capitulo. Me compraré un par de cursos más de este profesor. Gracias.\" -- Juan Carlos\n---\nVivimos en un mundo dominado por los datos, es por ello que obtener estas habilidades le permitirá acceder a posiciones de alto valor añadido debido a la gran demanda de perfiles de Data Science. Portales como indeed estiman salarios anuales promedios de 122.800$ y estudios como MarketWatch apuntan a que en los próximos años habrá un aumento del negocio de Data Science de un 30% anual, por lo tanto es una excelente oportunidad para usted adquirir estos conocimientos.\nEn este programa aprenderá por completo los fundamentos de Data Science o Ciencia de Datos, su base de probabilidad y estadística y cómo llevarlo a la práctica con Python, dominando los fundamentos de programación del lenguaje Python desde cero y sus potentes librerías como Numpy y Pandas enfocadas en el análisis de datos.\nAl finalizar el curso podrá ejecutar proyectos completos de Data Science siendo capaz de importar fuentes de datos heterogéneas, realizar la limpieza y transformación de datos y analizar la información para obtener conclusiones que provoquen alto impacto en su entorno.\nEste curso tendrá un enfoque eminentemente práctico, se explicará paso a paso y en detalle cada nueva funcionalidad, pero el objetivo es que sea capaz de aplicar los nuevos conocimientos ejecutando los múltiples casos prácticos reales propuestos para poner a prueba las destrezas adquiridas.\nA su vez, tendrá a su disposición un material extenso de consulta y todos los scripts de Python explicados durante esta especialización de tal manera que le sea muy sencillo reutilizarlos para su caso de uso concreto.\nEs el momento de que pase a la acción, prepárese para un futuro dominado por los datos adquiriendo una habilidad muy importante para poder destacar sobre el resto y conseguir sacar el máximo provecho de la información.\nApúntese a la carrera profesional de mayor potencial del siglo XXI.\n*Este curso forma parte de una carrera en Data Science complementada con cursos adicionales.\n*No es necesario tener conocimiento previo en Python, aprenderá los fundamentos de programación dentro del curso.",
      "target_audience": [
        "Toda persona que quiera potenciar su perfil adquiriendo habilidades de análisis de datos con gran futuro.",
        "Estudiantes que quieran aprender desde cero una habilidad muy demandada en cualquier sector desde un punto de vista práctico.",
        "Personas que quieran asombrar a su audiencia con un enfoque analítico generando conclusiones que marcan la diferencia.",
        "Analistas que quieran profundizar en Python y las librerías Numpy y Pandas."
      ]
    },
    {
      "title": "Career & Jobs in Big Data Science Zero 2 Hero A-Z New York",
      "url": "https://www.udemy.com/course/career-jobs-in-big-data-science-zero-2-hero-a-z-new-york/",
      "bio": "Understand Data Science Career and Jobs. Get introduced to Data Science course, career and salaries.",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Content of the Course",
          "FAQ - Summary of the course",
          "Data Science Career Overview"
        ],
        "Data Science Career Overview": [
          "Understanding the Role: Data Science Career Overview",
          "Difference Roles"
        ],
        "Demand, supply and the Job Market": [
          "Demand, supply and the Job Market",
          "Supply & Demand of Data Science Professionals"
        ],
        "Salaries in Data Science": [
          "Salaries in Data Science",
          "Salaries in Data Science"
        ],
        "Typical Data Science Course": [
          "Typical Data Science Course",
          "Course Syllabus"
        ],
        "Excelling as Data Scientist": [
          "Excelling as Data Scientist",
          "Excelling as Data Scientist"
        ]
      },
      "requirements": [
        "Non Technical Audience interested in learning about Data Science"
      ],
      "description": "About the course:\nData Science Jobs and Salaries. Made for non technical and beginners wanting to move into Data Science.\nMade from experience and inputs gathered from meetups and classes in New York, NY. Course introduces Data Science, vocabularies, salaries, job roles, course content, career strategy.\nHow to get the best salary from your data science courses? Which skills are most in demand?\nLearn about the new jobs created in data science, big data, machine learning and data analytics.\n\n\nData science courses teach an interdisciplinary field focused on extracting knowledge and insights from data. Learn data manipulation, statistical analysis, and machine learning to unlock insights and enhance decision-making and predictive abilities applicable to various fields.\n\n\nUpdates:\nCourse was revised with 2024 to have the jobs ideas and other updates\nWith the tech recession it is very important to get the correct skills and understand the market\nIt is not just about skills it is how you approach your job search\n\n\nMake yourself ready for recession or any upheavel.\nMost of times people study, learn, give quiz but do not understand the market, resume making, job application, ATS and differnt fields.\nTune your strategy for the career and jobs you are looking for.",
      "target_audience": [
        "Non Technical and Beginners who want to study Data Science"
      ]
    },
    {
      "title": "Makine Öğrenmesi (Machine Learning)",
      "url": "https://www.udemy.com/course/makine-ogrenmesi-egitimi/",
      "bio": "Teori ve Pratiği birleştirip Makine Öğrenmesi Uzmanı olun. Matematik temelini öğrenin, Python ile gerçek uygulama yapın.",
      "objectives": [
        "Yapay Zeka ve Makine Öğrenmesinin temellerini çok sağlam bir şekilde öğreneceksiniz.",
        "Tüm önemli Makine Öğrenmesi algoritmalarını öğreneceksiniz.",
        "Veri üzerinde düşünme, karar verme ve doğru model kurma becerisi edineceksiniz.",
        "Hem teori (matematik tabanını) hem de pratiği (Python kodlama) beraber öğreneceksiniz.",
        "Model Yaratma ve Model Siçimi Metodlarını öğreneceksiniz.",
        "Gerçek Hayat Projeleri üzerinden Python uygulamaları ile algoritmaları pratik olarak göreceksiniz.",
        "Numpy, Pandas, Matplotlib, Seaborn, Scikit-Learn gibi Python paketlerini uygulayarak öğreneceksiniz.",
        "Regression, Classification, Decision Trees, Random Forests, Bagging, Boosting, SVM, PCA, Clustering ve dahası..."
      ],
      "course_content": {
        "Genel Bakış": [
          "Giriş",
          "Makine Öğrenmesi Nedir?",
          "Makine Öğrenmesinin Tarihçesi",
          "Makine Öğrenmesinin Türleri",
          "Makine Öğrenmesi mi, Derin Öğrenme mi?"
        ],
        "Kurulumlar": [
          "Notion Kurulumu",
          "Anaconda Kurulumu",
          "Jupyter Lab Başlarken Şifre Sorarsa",
          "Jupyter Notebook Temelleri",
          "Ortam Hazırlığı"
        ],
        "ML Giriş Kavramları ve Notasyon": [
          "ML Giriş Kavramları - 1. Kısım",
          "ML Giriş Kavramları - 2. Kısım",
          "ML Giriş Kavramları - 3. Kısım",
          "ML Giriş Kavramları - 4. Kısım",
          "Notasyon"
        ],
        "Öğrenme (Learning)": [
          "Öğrenme Nedir? - 1. Kısım",
          "Öğrenme Nedir? - 2. Kısım",
          "Öğrenme Nedir? - 3. Kısım",
          "f'yi Neden Tahmin Ederiz?",
          "Curse of Dimensionality",
          "f'yi Nasıl Tahmin Ederiz?",
          "Tahmin Doğruluğu mu, Model Sadeliği mi?",
          "Regresyon vs. Sınıflandırma"
        ],
        "Model Doğruluğunu Ölçmek": [
          "Tahmin Kalitesini Ölçmek - 1. Kısım",
          "Tahmin Kalitesini Ölçmek - 2. Kısım",
          "Tahmin Kalitesini Ölçmek - 3. Kısım",
          "Bias-Variance Trade-Off",
          "Sınıflandırma Kurulumu",
          "KNN Örnek - 1. Kısım",
          "KNN Örnek - 2. Kısım",
          "Alıştırmalar",
          "Alıştırmalar - Çözüm - 1. Kısım",
          "Alıştırmalar - Çözüm - 2. Kısım"
        ],
        "Basit Lineer Regresyon": [
          "Regresyonun Matematik Temeli - 1. Kısım",
          "Regresyonun Matematik Temeli - 2. Kısım",
          "Lineer Regresyon Proje - 1. Kısım",
          "Lineer Regresyon Proje - 2. Kısım",
          "Lineer Regresyon Proje - 3. Kısım"
        ],
        "Çoklu Lineer Regresyon": [
          "Çoklu Lineer Regresyon Nedir?",
          "OLS Tablosu Okuma",
          "Hipotez Testi",
          "Çoklu Lineer Regresyon Proje - 1. Kısım",
          "Çoklu Lineer Regresyon Proje - 2. Kısım",
          "Çoklu Lineer Regresyon Proje - 3. Kısım",
          "Çoklu Lineer Regresyon Analizi",
          "Kategorik Data"
        ],
        "Çoklu Lineer Regresyon Gerçek Proje": [
          "Proje Çözümü 1",
          "Proje Çözümü 2",
          "Proje Çözümü 3",
          "Proje Çözümü 4",
          "Proje Çözümü 5",
          "Proje Analizleri"
        ],
        "Gradient Descent": [
          "Gradient Descent Kavramları",
          "Gradient Descent - Python",
          "Learning Rate",
          "Stochastic Gradient Descent (SGD)",
          "Gradient Descent Proje - Bölüm 1",
          "Gradient Descent Proje - Bölüm 2"
        ],
        "KNN": [
          "KNN Kurulumu - 1",
          "KNN Kurulumu - 2",
          "KNN Proje - 1",
          "KNN Proje - 2",
          "KNN Proje - 3"
        ]
      },
      "requirements": [
        "Temel seviye bir Matematik bilgisi,",
        "Giriş seviye bir Python bilgisi yeterlidir."
      ],
      "description": "Makine Öğrenmesi (Machine Learning) yolculuğunun öğrencilere zor gelmesinin iki ana nedeni vardır:\n1- ML kavramları ve algoritmalar ilk başta karmaşık gelir.\n2- Yeterli ve sağlıklı uygulama yapılmadığı zaman havada kalır.\n\n\nBirinci sorunu biraz açacak olursak;\nÖğrenciler çoğu zaman Matematik ve İstatistik temelini anlamadıkları için ezberleyerek Makine Öğrenmesi yapmaya çalışırlar.\nMaalesef Makine Öğrenmesi üzerine verilen bir çok eğitim sadece kavramları ezberletme üzerine kurulu.\nBir yerden sonra ezberin kendisi karmaşık bir hal alır, bir fayda vermez ve öğrenci iyice kaybolur.\n\n\nİkinci sorun ise kavramları anlayan öğrencilerle ilgili;\nÖğrenci kavramları anlamış olsa bile gerçek hayat uygulamaları ile destekleyemezse o zaman da pratiğe dökememiş olur.\nAslında pratik bir saha olan Machine Learning'de gerçek anlamda uzmanlaşamaz.\nAkademik olarak iyi olan birçok eğitimde de maalesef uygulama tarafı eksik.\n\n\nBu kurs işte bu iki soruna, kalıcı bir çözüm üretmek için geliştirildi.\nGerektiği kadar teorik bilginin üzerine fazlası ile uygulama yaparak, soru çözerek teori ve pratiği birleştiriyor.\nBöylece siz, artık ne yaptığınızı ve neden yaptığınızı bilerek ama mutlaka elinizi kirleterek veri üzerinde çalışmış olacaksınız.\nVe Machine Learning'i sarsılmaz bir şekilde öğrenmiş olacaksınız.\n\n\nKursumuz \"Makine Öğrenmesi Nedir?\" diye başlıyor ve Supervised Learning'in tüm algoritmalarını bitirdikten sonra, Unsepervised Learning ile devam ediyor.\n\n\nHemen hemen her konu sonunda, gerçek bir proje yapacağız.\nBöylece sarsılmaz bir şekilde Machine Learning'i öğrenmi olacaksınız.\n\n\nSiz de teori ve pratiği birleştirip Machine Learning uzmanı olmak istiyorsanız, haydi bize katılın...",
      "target_audience": [
        "Yapay Zeka ve Makine Öğrenmesi üzerine bir kariyer edinmek isteyen,",
        "Makine Öğrenmesi hakkındaki mevcut bilgilerini gerçek projelerle derinleştirmek isteyen,",
        "Makine Öğrenmesi kavramlarının Python ile uygulamalarını öğrenmek isteyen,",
        "Yapay Zeka ve Makine Öğrenmesi konusuna ilgi duyan herkes katılabilir."
      ]
    },
    {
      "title": "Missing Data Imputation Mastery",
      "url": "https://www.udemy.com/course/how-to-do-missing-data-imputation-in-python/",
      "bio": "Uncover the secrets of handling missing data with our free course, \"Missing Data Imputation Mastery.\"",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Intro, problem statement, taxonomy of methods, Missingness Mechanisms",
          "IMPORTANT NOTE!",
          "LEARN MORE ABOUT MACHINE LEARNING"
        ],
        "Learn Simple Imputation methods": [
          "Mean and Mode Imputation",
          "Binary Indicator Variables"
        ],
        "Learn ML based methods": [
          "KNN Imputation",
          "MissForest Imputation",
          "PPCA - SoftImpute"
        ],
        "Learn DL based methods": [
          "Generative Adversial Networks imputation",
          "Denoise AutoEncoders"
        ],
        "Optimizing Imputation Methods and General Guidelines": [
          "HyperParameter Optimization Suggestions",
          "Intuition about the dimensionality reduction methods",
          "Code explanation"
        ],
        "More free learning - Wrapping up": [
          "Suggestions - Free Learning",
          "Most efficient imputation method"
        ],
        "Whole Tutorial In 1 Video.": [
          "30 Minutes of Free Course."
        ]
      },
      "requirements": [
        "You need basic knowledge of python"
      ],
      "description": "Uncover the secrets of handling missing data with our free Udemy course, \"Missing Data Imputation Mastery.\" This essential course equips you with the skills needed to effectively manage and impute missing values in datasets, a critical skill for data analysts and data scientists.\nPositive Aspects:\nIn-Depth Coverage: Our course delves deep into various techniques and methods for missing data imputation, ensuring you have a comprehensive understanding of this crucial data preprocessing step.\nPractical Application: You'll gain hands-on experience through real-world examples and exercises, enabling you to apply what you learn immediately.\nExpert Instruction: Learn from experienced instructors who are well-versed in missing data handling. They provide clear explanations and practical insights.\nFree of Charge: This course is entirely free, making it accessible to learners of all backgrounds, from students to professionals.\n\n\nReasons to Get It:\nEnhance Data Skills: Missing data is a common challenge in data analysis. Mastering this skill will set you apart as a data professional.\nCost-Efficient Learning: Enjoy a valuable learning opportunity without the financial commitment of a paid course.\nImmediate Application: You'll be equipped to handle missing data effectively, improving the quality and reliability of your analysis.\nFlexible Learning: Access the course content at your own pace, allowing you to balance your learning with other commitments.\nIn conclusion, \"Missing Data Imputation Mastery\" is a valuable resource for anyone working with data. It offers comprehensive coverage, practical experience, and cost-efficient learning opportunities. While it lacks some benefits of paid courses, it's an excellent starting point for those looking to master missing data imputation.",
      "target_audience": [
        "Beginner Machine Learning Engineers",
        "Beginner Data Scientists"
      ]
    },
    {
      "title": "AI Human Video Creation using Artificial Intelligence!",
      "url": "https://www.udemy.com/course/ai-human-video-creation-using-artificial-intelligence/",
      "bio": "Create virtual human videos using Artificial Intelligence tools like ChatGPT, Google Bard, etc",
      "objectives": [],
      "course_content": {
        "AI Human Video Creation using Artificial Intelligence! (Promo)": [
          "AI Human Video Creation using Artificial Intelligence!"
        ],
        "Requirement for This Course": [
          "ChatGPT Free Guide",
          "Access to AI Maker"
        ],
        "Video Creation Planning": [
          "Ideas For Video Creation",
          "Video Creation Scripts"
        ],
        "Creating AI Human Video": [
          "Choose Ratio & Templates",
          "Choosing Avatar",
          "Voice Settings / TTS",
          "Video Settings",
          "Customize Video"
        ],
        "Exporting Final AI Video": [
          "Download The Video",
          "Explore More Settings",
          "Bonus"
        ]
      },
      "requirements": [
        "A computer with internet access.",
        "Basic familiarity with digital content creation.",
        "You need investment of $49 only one time investment",
        "Interest in learning about AI and its applications in video creation.",
        "No prior experience with AI or video production is required, but it is beneficial."
      ],
      "description": "Welcome to this course, AI Human Video Creation using Artificial Intelligence!\nMeet Ultra-Realistic “Virtual Humans”\nThat Speak Anything You Type In All Languages…\nCreate Engaging AI Human Spokesperson Videos Like The Big Brands on\na Shoestring Budget Without Actors, Camera or Studio Equipment!\nCreating High-End Animated Videos With Humans Is Now Fast, Affordable and Infinitely Scalable…\nGrab attention and stir up emotions with a wide selection of human characters available with different clothing styles, ethnicities and professions.\nGet them to speak in any language and convey your message to the masses in a fun and engaging way!\nBuild credibility and Turn photos into live talking humans.\nUse the huge libary of copyright-free human faces in our app and turn the existing avatars to a \"unique\" human character that will speak anything you type. This is mind blowing and and takes just seconds to do!\nAvoid copyright strikes and hefty fines by generating UNIQUE male, female and child face mugshots using Artificial Intelligence.\nThe digital human do not exist in real life.\nUse the photos you generate for any commercial purpose without any extra fees.\nThese AI photos can be used in the app to create a unique talking human!\nBoost engagement and sales with hundreds of ultra-realistic new and improved male and female voices options in all the popular languages.\nInstantly sync the voices and create videos in minutes!\nControl the speed and pitch of the voices to generate a natural voice that suits your needs!\nMultiply your profits and automate video creation with attractive ready-to-use video templates.\nPersonalize the templates with your own text effects, fonts, animations, watermarks, and backgrounds for endless possibilities.\nCreate world-class videos like the big boys without any technical experience or skills!\nCreate custom videos in any topic or niche with the powerful built-in video scene editor.\nAdd, delete, edit and reposition video scenes on the fly for ultimate flexibility.\nChange backgrounds, colors, fonts, text, and more to create your custom masterpiece with total control.\nAutomate content creation by turning any audio file into text within seconds. Use the generated text as a script for your videos!\nRepurpose old videos, audio files or podcasts and turn them into stunning human videos!\nConvert global audiences by instantly translating any text into multiple languages to create multilingual videos!\nCovert your finished projects in the app into a \"new languages\" by cloning the existing project in minutes!\nReach 10x more customers by adding subtitles to your videos. 80% of the videos on social platforms are watched without sounds.\nThis single feature can exponentially deliver more traffic, leads and sales to your business!\nBoost ROI and maximize revenues by creating vertical videos for mobile (9:16) or landscape for computers (16:19) to increase reach and get results fast!\nSeveral other video dimensions are available in the app for multi-purpose video creation with ease!\nand there are many things to say for this course.\nEnroll now inside this course, AI Human Video Creation using Artificial Intelligence!",
      "target_audience": [
        "Content creators looking to incorporate AI virtual humans into their work.",
        "Digital marketers interested in innovative ways to engage audiences.",
        "Educators aiming to include virtual human videos in their teaching resources.",
        "Students and professionals in media, communications, and related fields.",
        "Technology enthusiasts eager to explore the possibilities of AI in creative media.",
        "Entrepreneurs seeking to create dynamic presentations and promotional videos."
      ]
    },
    {
      "title": "Basics of Numpy for Data Analysis & Data Science in Python",
      "url": "https://www.udemy.com/course/numpy_real_world_projects_for-data-analysis_data-science/",
      "bio": "Learn fundamentals of Numpy , frequent used Numpy statistical functions with the help of real-world use-cases",
      "objectives": [],
      "course_content": {
        "Welcome to this course !": [
          "Introduction & Course benefits !",
          "Quick Summary of Jupyter Notebook"
        ],
        "NumPy Essentials !": [
          "Datasets & resources",
          "Numpy array",
          "Attributes of Numpy array !",
          "How to create Numpy array from Python data-structures .",
          "Indexing in NumPy array",
          "Basic Data-types in Numpy.."
        ],
        "basic Numpy operations !": [
          "Arithmetic operations in Numpy - Part 1",
          "Arithmetic operations in Numpy - Part 2"
        ],
        "Statistical functions of Numpy !": [
          "Code-walkthrough of Numpy statistical functions ."
        ],
        "Some Popular used functions of Numpy !": [
          "Create 1-Dimensional array using arange() & linspace()",
          "Create 2D array using eye() , ones() & zeros() function",
          "Reshaping & Flattening of nd-array .",
          "Code-WalkThrough of reshaping & flattening",
          "where() function of numpy"
        ],
        "Bonus section": [
          "Bonus lecture"
        ]
      },
      "requirements": [
        "Have a Keen Desire to learn !"
      ],
      "description": "Data Scientist & Data Analyst has been ranked the number one job on Glassdoor and the average salary of a data scientist is over $120,000 in the United States according to Indeed! Data Science is a rewarding career that allows you to solve some of the world's most interesting problems!\n\n\nThat being said, data science is becoming one of the most well-suited occupations for success in the twenty-first century. It is computerized, programming-driven, and analytical in nature. Consequently, it comes as no surprise that the need for data scientists has been increasing in the employment market over the last several years.\n\n\nIn this course, you will learn how to do numerical computations on data using numpy !\n\n\nThis course will teach your everything you need to know to use numpy to create 1-D array or whether 2-D array for Deep Learning Stuffs ! Have you ever wanted to take your Python skills to the next level in numerical programming ,this is the place where u can learn !\n\n\n\n\nWe'll teach you how to program with Python, how to create 1-D array ,2-D array & multi-dim. array , how to flatten array & much more Here a just a few of the topics we will be learning:\nBasic data-structure of Python\nNumpy operations\nStatistical functions of numpy\n1D array creation numpy functions\n2D array creation numpy functions\n\n\n\n\nWe'll start off by teaching you enough Python and numpy that you feel comfortable working and generating data  Then we'll continue by teaching you real-world scenarios including flattening  , reshaping using numpy functions . We'll also give you an intuition of when to use what function !",
      "target_audience": [
        "everyone who wants to learn by doing",
        "everyone who wants to improve data science skills",
        "data scientists / data analytics / machine learning engineers"
      ]
    },
    {
      "title": "Snowflakeによるデータエンジニアリングの基礎",
      "url": "https://www.udemy.com/course/snowflake-load/",
      "bio": "クラウド型データウェアハウス製品であるSnowflakeを使って、データ分析基盤構築のためのデータロードやアクセスコントロールなどを学びましょう！AWS S3と連携させたテーブル作成にもチャレンジします。",
      "objectives": [
        "Snowflakeの概要",
        "Snowflakeのユーザインターフェースやテーブル操作",
        "UIを利用したCSVファイルからのデータロード",
        "外部ステージとAWS S3を利用したデータロード",
        "データのクローン",
        "ユーザ・ロール・権限によるアクセスコントロール"
      ],
      "course_content": {
        "イントロダクション": [
          "コースの紹介",
          "サンプルクエリ・データのダウンロード",
          "データウェアハウス・データベース",
          "メタデータ",
          "クラウド",
          "データウェアハウス業界とSnowflake",
          "Snowflakeのドキュメンテーション",
          "Snowflakeの特徴①",
          "Snowflakeの特徴②",
          "コース準備レクチャー"
        ],
        "Snowflakeのセットアップ": [
          "Snowflakeのトライアルの説明",
          "Snowflakeのインターフェース①",
          "Snowflakeのインターフェース②",
          "用語の説明",
          "UIによるデータベース・スキーマ・テーブルの操作"
        ],
        "Snowflakeへのデータロード": [
          "サンプルクエリ・データのダウンロード",
          "データロードの種類と方法",
          "使用するデータの説明",
          "UIを使ったCSVファイルからテーブルへのデータロード",
          "UIを使ったウェアハウスの作成",
          "SQLによるウェアハウスの作成",
          "データベース・スキーマ・テーブルの作成",
          "データベース・スキーマ・テーブルの操作"
        ],
        "外部ステージを用いたデータロード（AWS S3との連携）": [
          "AWS S3の設定",
          "AWS S3とのデータ統合（Storage Integration）と外部ステージ作成",
          "AWS S3からのデータロード①",
          "AWS S3からのデータロード②（2複数ファイルのロード）",
          "AWS S3からのデータロード③（複数ファイルのロード）",
          "AWS S3からのデータロード④（データの整形）",
          "ALTERによるテーブルの操作",
          "Snowpipeによるデータロード（Snowflake側）",
          "Snowpipeによるデータロード（AWS S3側）",
          "Zero-Copy Cloning",
          "タイムトラベル①",
          "タイムトラベル②"
        ],
        "アクセスコントロール": [
          "アクセス制御とロール",
          "ユーザーの作成",
          "ロールと権限",
          "ウェアハウスとロール",
          "データベースとロールとユーザー",
          "テーブルとロールとユーザー"
        ],
        "おわりに": [
          "おわりに"
        ],
        "ボーナスレクチャー": [
          "ボーナス"
        ]
      },
      "requirements": [
        "不要"
      ],
      "description": "最近のデータサイエンスブームの中で、Snowflakeはクラウドネイティブなデータウェアハウス製品として、多くの会社で採用されてきています。興味がある方も増えているかと思いますが、自分で勉強しようにも自分でクラウドやデータウェアハウスを扱うというのはかなりハードルが高いものです。\nそこでこのコースでは、SnowflakeのUIをはじめとする基礎から、手動によるテーブルの作成、他のクラウドサービスであるAWSとの連携と連携したデータロード、テーブルからのデータ取得、アクセスコントロールなどなど、実際の場面でも使用できる知識を、実際のハンズオン形式で学んでいきます。\nぜひこの機会にSnowflakeを学び、これからのキャリアに活かしていきましょう！\n\n\n本コースの内容\nイントロダクション：データ活用/データウェアハウス\nSnowflakeとは\nSnowflakeのセットアップ\n手動によるCSVデータのロード\nAWS S3と連携したデータのロード\nクローン\nデータベース・スキーマ・テーブルの操作\nタイムトラベル\nアクセスコントロールによるユーザ・ロールの操作\n\n\n前提条件\n特に受講上の前提条件はありません。SQLやデータベースの知識はあるにこしたことないですが、なくても問題ありません。\nPCのOSはMac, Windows, Linuxなんでも構いません。\n\n\n注意事項\n本コースに従って実際にハンズオンを行う場合はSnowflakeのアカウント、AWS S3のアカウントが必要です（もちろん見るだけでも構いません）。Snowflake, AWSともに初月は無料枠がありますが、使いすぎると課金される可能性があるので、ご了承ください\nAWSのアクセス（IAM）まわりの話はいたしませんので、ご了承ください\nSQLによるデータ抽出や可視化などの説明はいたしませんので、ご了承ください（データ抽出は簡単なSELECT文、使ってもWHERE句くらいです）\n本コースは、データロード（テーブル作成）やアクセスまわりに特化したコースです\nクライアントツールであるSnowsqlは使わずGUIのワークシートを使って操作します\n1ヶ月間はキャンセル可能ですので、もし間違って購入したり、想定と違う場合はキャンセルするようにしてください\n\n\nそれでは、Snowflakeをお楽しみください！",
      "target_audience": [
        "Snowflakeに興味があり学んでみたいと思っている人",
        "データ基盤を学びたい初心者の方",
        "データサイエンスに興味があり、少しデータエンジニアリングにも興味がある人",
        "データウェアハウスを扱ってみたい人"
      ]
    },
    {
      "title": "【データサイエンス×ビジネスコミュニケーション】現役データサイエンティストが教える「伝えて動かすデータ分析」",
      "url": "https://www.udemy.com/course/datascience-bussiness/",
      "bio": "初心者からPythonを駆使してデータサイエンスをビジネスや研究に応用できるデータ分析・統計入門！JupyterNotebook・Pandas・Matplotlib・SQLなどを用いて実際のビジネスケースを想定した即戦力のスキルが身につく！",
      "objectives": [
        "Pythonを用いたデータ分析の基本",
        "データサイエンスのビジネス応用",
        "データ分析を介したビジネスコミュニケーションの基本",
        "データサイエンスを活用したデジタルマーケティング",
        "手を動かしながら学ぶデータサイエンティストを目指す実践的な内容",
        "データ分析の基本的プロセス",
        "確率・統計",
        "機械学習",
        "Jupyter Notebook・NumPy・Pandas・Matplotlib・SciPy・scikit-learn",
        "ビジネス理解のスキル",
        "データ収集・加工のスキル（データベース・SQL）",
        "評価のスキル",
        "報告・意思決定のスキル",
        "プロジェクトマネジメント・ソフトウェア開発/運用",
        "データサイエンティストのキャリア"
      ],
      "course_content": {},
      "requirements": [
        "統計学の知識やプログラミングの経験のない方でもデータ分析の基本から学んでいくことができます！",
        "Pythonの基本的な技能があると習得が早いですが、講座の中でも必要な項目はその都度解説するのでご安心ください。",
        "動画内で解説しますがMacまたはWindows上でのPythonのプログラミング環境を構築します。"
      ],
      "description": "このコースではPythonを用いてビジネス現場で活用できるデータ分析を行うための入門的内容を学ぶことができます。\n\n\n【データ分析の学び方がわからない初心者でも大丈夫です】\nデータ分析やデータサイエンティストに興味があるけれどどうやって勉強してスキルを身につけることができるのかわからない方におすすめです。\nまた、過去にデータ分析を書籍などで勉強したことがあるけれど、具体的なプログラミングやビジネス現場での活用方法がイメージできなかった人でもこちらの動画講座でデータ分析を用いてビジネス価値を創出する過程をより具体的に想像することができるようになります。\n\n\n【現役データサイエンティストがビジネス現場でのデータ分析の実態を教えます】\n現役データサイエンティストとして働く講師が実際のビジネス現場を想定しながらデータ分析の方法を教えます。\nスライドを用いた座学だけではなく、実際に手を動かしてコードを書きながら学ぶことができるのでより実践的に理解することができます。\n\n\n【データ分析を介したビジネスコミュニケーションを身につけられます】\nデータ分析はあくまでも手段であり、ビジネス価値を生み出すためには分析結果を活用して様々なステークホルダーとコミュニケーションを取る必要があります。\nビジネスにおける課題を自分で拾い上げる方法や、データを介したビジネスコミュニケーションについても詳細に触れているのがこの講座の特徴です。\nデータサイエンス×ビジネスコミュニケーションを一気通貫して学べる、他の講座にはない特徴を持つデータ分析講座となります！\n\n\n【データサイエンスに興味がある幅広い層に対応しています】\n将来データサイエンティストを目指している学生\nデータサイエンティストへの転職を考えている社会人\nさらなる専門性を身に付けたいエンジニア\nデータ分析をビジネスに活用したいマーケター/ビジネスマン\n研究でデータサイエンスを活用したい研究者\nなど理系/文系関係なく幅広い層に向けた実践的な内容になっています。\n\n\n【講座終了後にビジネス・研究現場で働くに当たって最低限必要な知識を一通り揃えることができます】\nこれまで全くデータ分析について学んだことがなくても、基本的な統計の知識からビジネス応用まで一貫した講義を行うので、この講義を修了すれば現場で働くに当たって最低限必要な知識を一通り揃えることができます。\nビジネス理解のスキル→データ収集・加工のスキル→評価のスキル→報告・意思決定のスキル→実施・適用のスキル→ケーススタディの流れで、データ分析を用いたビジネスコミュニケーションの実践方法を深く学ぶことができます。\n【データ分析に関連するトピックが盛りだくさんの内容となっています】\n具体的にはデータ分析の目的とそのプロセス・Pythonの基本・Jupyter Notebookの基本・NumpyとPandasの基本・Matplotlibの基本・統計学の基本・機械学習によるデータ分析の基本・データベースの基本・データ分析の評価・データマイニングとビジネスコミュニケーションの基本などこれだけ勉強すればすぐに現場で役立つ盛り沢山の内容となっております。\n\n\n【レクチャー数100越え！講義時間12時間越えの大ボリューム！】\n高額のデータサイエンススクール（30〜100万程度）と同等の内容を24000円で学ぶことができます！\n3-10分の講義数が100レクチャー越え！総講義時間は12時間越えの大ボリュームで【データサイエンス×ビジネスコミュニケーション】を一気通貫で学ぶことができるコースとなっております。\n※各セッションの1番初めのレクチャーには講義で使用したJupyter Notebookのコードの資料も添付しておりますので、受講後の復習も簡単に行うことができます。",
      "target_audience": [
        "データを分析するだけではなく実際のビジネスや研究に応用したい方にオススメです！",
        "将来データサイエンティストを目指している学生",
        "文系データサイエンティストを目指している方",
        "転職や副業のためにPythonでプログラミングを学びたい方",
        "データサイエンティストへの転職を考えている社会人",
        "既存のスキルにデータサイエンスを掛け合わせたい方",
        "営業やマーケティングにデータサイエンスの手法を取り入れたい方",
        "データ分析の視点をビジネスに活用したいマーケター",
        "さらなる専門性を身に付けて自分の価値を上げたいエンジニア",
        "データサイエンスに関心を持つエンジニア初心者〜中級者",
        "これまで全くデータ分析について学んだことがないがビッグデータの活用に興味がある人",
        "統計学や数学をプログラミングで学びたい方",
        "書籍や無料の資料だけでは行き詰まってしまった方",
        "動画を見て手を動かしながら理解して身に付けたい方"
      ]
    },
    {
      "title": "Máster Elasticsearch, Logstash y Kibana 8.x (Elastic Stack)",
      "url": "https://www.udemy.com/course/master-elasticsearch-logstash-y-kibana-8-elastic-stack/",
      "bio": "Aprende Elasticsearch, Logstash y Kibana desde cero para buscar, analizar y visualizar BigData con Elastic Stack 8 (ELK)",
      "objectives": [
        "Entender la arquitectura de Elastic Stack (ELK) y por qué es tan flexible, escalable y eficiente",
        "Crear un potente motor de búsqueda con Elasticsearch",
        "Escribir consultas Elasticsearch simples y complejas",
        "Ejecutar pipelines de ingesta, transformación y carga de datos con Logstash",
        "Crear potentes visualizaciones en Kibana (línea, circular, histograma, heatmap, mapa geográfico,…)",
        "Crear dashboards interactivos en Kibana y enlazar múltiples dashboards",
        "Aplicar consultas KQL en los dashboards de Kibana",
        "Gestionar acceso y seguridad para compartir dashboards con otros usuarios configurando roles y permisos",
        "Conocimiento extenso en la tecnología Elastic Stack (ELK) que podrá aplicar de inmediato a un precio muy asequible"
      ],
      "course_content": {},
      "requirements": [
        "Ninguno, el curso partirá desde cero, solo muchas ganas de aprender y convertirte en un profesional de Elastic Stack"
      ],
      "description": "¿Quieres dominar Elastic Stack desde cero para convertirte en un profesional de Elasticsearch, Logstash y Kibana en muy poco tiempo? Pues has llegado al lugar correcto para aprenderlo y ponerlo en práctica de manera inmediata.\nSeguro que más de una vez te has enfrentado al problema de tener que gestionar grandes volúmenes de datos de manera rápida y eficiente, necesitando visualizar la información en tiempo real para analizar y obtener conclusiones.\nTodo esto nos lo ofrece Elastic Stack, ya que es una de las plataformas más potentes, flexibles y escalables hoy en día para poder manejar gran cantidad de información.\nElastic Stack contiene múltiples componentes como Elasticsearch, Logstash, Kibana,… que requieren ser dominados para poder aprovechar todo lo que nos ofrece esta plataforma, por eso en este curso dispones de todo lo que necesitas para conseguirlo en muy poco tiempo.\nEmpezaremos con Elasticsearch totalmente desde cero, Elasticsearch es un potente motor de búsqueda extremadamente eficiente y que es usado por plataformas como Google Search, pero además podemos usarlo para analizar información con grandes volúmenes de datos incluyendo agregaciones.\nTambién aprenderás a utilizar Logstash como pipeline para poder ingestar, transformar y cargar datos en Elasticsearch.\nPara completar ELK Stack, profundizarás en Kibana, este componente nos permite visualizar los datos almacenados en el cluster de Elasticsearch, incluyendo la ejecución de consultas a medida, creación de todo tipo de visualizaciones y creación de dashboards. Kibana nos habilita a interactuar fácilmente con nuestros datos pudiendo analizar, explorar y sacar conclusiones. Además, aprenderás a compartir los dashboards de manera segura configurando los roles y permisos oportunos para cada usuario.\nEste curso tendrá un enfoque muy práctico con casos de uso concretos para que puedas aplicar todos los conocimientos aprendidos. Para ello el curso estará estructurado en los siguientes bloques:\n--\nBLOQUE 1: INTRODUCCIÓN Y ARQUITECTURA DE ELASTIC STACK\nBLOQUE 2: ELASTICSEARCH - MANEJO DE DOCUMENTOS\nBLOQUE 3: ELASTICSEARCH - TÉCNICAS DE MAPPING Y ANÁLISIS\nBLOQUE 4: ELASTICSEARCH - BÚSQUEDAS TERM-LEVEL, FULL-TEXT Y BOOLEANAS\nBLOQUE 5: ELASTICSEARCH - CONSULTAS PARA RELACIONES ENTRE DOCUMENTOS\nBLOQUE 6: ELASTICSEARCH - AGREGACIONES\nBLOQUE 7: LOGSTASH - INGESTA, TRANSFORMACIÓN Y SALIDA\nBLOQUE 8: KIBANA - INTERFAZ, INGESTA Y VISUALIZACIONES\nBLOQUE 9: KIBANA – CREACIÓN DE DASHBOARDS, ROLES Y PERMISOS\n--\nTendrás a tu disposición un material extenso de consulta y todos los scripts explicados durante este curso de tal manera que te sea muy sencillo reutilizarlos para tu caso de uso concreto. Mi objetivo es que cuando finalices el curso puedas aplicar las soluciones Elastic Stack de inmediato a tu situación particular.\nNo tienes nada que perder, tendrás una garantía de 30 días para asegurar que estás 100% satisfecho con el material, mi objetivo es aportarte valor con todos estos conocimientos y si no es así siéntete libre de solicitar la devolución, aunque estoy seguro de que cumplirá tus expectativas.\n--\nEscuche de otros alumnos por qué este es el curso de ELASTIC MEJOR VALORADO EN ESPAÑOL:\n\"Curso muy completo desde cero, aplicable a nuestros proyectos, muy bien explicado y con los recursos disponibles. Muy recomendable. Gracias\" -- José Carlos Carrasco\n\n\n\"Pude entender los elementos principales de Elasticstask y como estos se van interrelacionando entre si, explicaciones claras, buenas presensentaciones y información no solo contextual, sino también practica.\" – Patricio Alejandro Alvarado\n\n\n\"Me gusto mucho, explica muy bien el instructor es muy claro y me parece que no da tantas vueltas para dar un tema\" - María Echavarría\n--\nSi quieres aprovechar desde cero todas las posibilidades que te brinda Elasticsearch, Logstash y Kibana, este curso es para ti.\nTe garantizo que al finalizar el curso podrás trabajar en Elastic a nivel profesional.\n¡Únete a más de 50.000 estudiantes que ya se aprovechan de estos conocimientos!",
      "target_audience": [
        "Toda persona que precise de una solución flexible, escalable y eficiente para manejar grandes volúmenes de datos",
        "Analistas que precisan de una plataforma potente en la que obtener conclusiones a partir de los datos",
        "Desarrolladores relacionados con plataformas de datos que precisan consultar y visualizar información",
        "Todo aquél que quiera aprender a aplicar Elastic Stack en su solución de BigData",
        "Toda persona que quiera potenciar su perfil dominando la plataforma Elastic Stack",
        "Estudiantes que quieran obtener habilidades que le abrirán puertas en el mercado laboral"
      ]
    },
    {
      "title": "Synthetic Data in Machine Learning",
      "url": "https://www.udemy.com/course/synthetic-data-in-machine-learning/",
      "bio": "Synthetic Data in Machine Learning: From Theory to Practice",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Familiarity with Python, Foundational understanding of basic ML concepts, Basic statistical knowledge"
      ],
      "description": "Dive into the world of synthetic data and its transformative potential in machine learning with this concise, hands-on course. In just 60 minutes, you'll gain a solid understanding of what synthetic data is, why it's crucial in today's data-driven landscape, and how to generate and use it effectively. Whether you're looking to augment limited datasets, protect sensitive information, or explore new ML possibilities, this course provides the foundational knowledge you need.\nThis course covers:\nFundamentals of synthetic data and its applications in various industries\nKey techniques for generating synthetic data, including statistical methods and generative AI approaches like GANs and VAEs\nPractical tips for ensuring data quality, avoiding biases, and addressing ethical considerations\nA real-world example of using synthetic data in a machine learning workflow, from generation to model evaluation\nPerfect for data scientists, analysts, and developers with basic Python and machine learning knowledge, this course bridges the gap between theory and practice. You'll learn to overcome common data challenges like scarcity and privacy concerns, opening up new possibilities in your projects and enhancing your data strategy.\nBy the end, you'll be equipped to generate simple synthetic datasets, evaluate their quality, and apply them in machine learning tasks. Join us to unlock the power of synthetic data, stay ahead in the rapidly evolving field of AI and data science, and transform your approach to data-driven problem-solving.\nYou also get access to an AI study companion that can help you answer any questions related to the course and Synthetic data and data augmentation techniques. You can have conversations with the AI mentor to deepen your understanding of the course material or ideate for your project.",
      "target_audience": [
        "For data professionals and enthusiasts, from beginners to experts, who want to master the practical application of synthetic data in real-world machine learning and business scenarios."
      ]
    },
    {
      "title": "【初学者向け】データ分析コンペで楽しみながら学べるPython×データ分析講座",
      "url": "https://www.udemy.com/course/python-data/",
      "bio": "データサイエンスの基礎から実践までを一気通貫で理解しよう！アニメーションを使った概要編とハンズオン形式で進む実践編でしっかり理解できる！データサイエンスやPython初心者でも大丈夫。",
      "objectives": [
        "アニメーションで学ぶ統計学と機械学習の基礎",
        "アニメーションで学ぶ各種機械学習手法の詳細",
        "アニメーションで学ぶビジネスデータ分析の流れ（CRISP-DM）",
        "ハンズオンで学ぶデータ分析コンペの中古マンション売買データを題材にしたPython実践"
      ],
      "course_content": {},
      "requirements": [
        "機械学習やデータ分析に対する興味・やる気",
        "PC（MacでもWindowsでも可）"
      ],
      "description": "データサイエンスやPythonを学びたいけどどこから学べばよいのか分からない・・・\nなかなか学ぶ時間がない・・・という方\nそんな方におすすめなのがこのコース！\n\n\nこのコースは、なかなか勉強する時間がないという方に向けてコンパクトに分かりやすく必要最低限の時間で重要なエッセンスを学び取れるように作成しています。\n本コースはアニメーションを使った概要編とハンズオン形式で進む実践編に分かれています。\n概要編では、データサイエンスの基礎やデータ分析の流れについて学びます。\nデータサイエンスの基礎について基本のキから学びつつ、なるべく堅苦しい説明は抜きにしてイメージを掴んでいきます。\n統計学・機械学習の基本的な内容から統計学と機械学習の違いについて学んでいきます。\nそしてデータ分析の流れについては実務に即したCRISP-DMというフレームワークに沿って体系的に学んでいきますよ！\nデータ分析というと機械学習でモデル構築する部分にスポットがあたりがちですが、それ以外の工程についてもしっかりおさえておきましょう！\n\n\n続いて実践編ではデータコンペ（Nishika）のデータを題材にして、実際に手を動かしながら機械学習手法を実装していきます。\nここでは、探索的にデータを見ていきながらデータを加工し、その上でLight gbm という機械学習手法を使ってモデル構築までおこなっていきます。\n概要編で学んだ内容を思い返しながらぜひ実践編で実践的なデータ分析の流れをつかんでいきましょう！\n\n\nぜひデータサイエンスを身近なものにして様々な領域に活かしていきましょう！",
      "target_audience": [
        "データサイエンス・Pythonに興味のある人",
        "時間がないので要点だけかいつまんで学びたい人",
        "データ分析コンペに挑戦してみたい方",
        "データサイエンスの面白さを知りたい人"
      ]
    },
    {
      "title": "ChatGPTのAPIで5つのアプリを作ってみよう！JSON生成、属性抽出、独自文書Q&A、SQL生成、AIエージェント",
      "url": "https://www.udemy.com/course/llm-apps/",
      "bio": "チャットボットだけじゃない！ChatGPTのAPIで何ができるのか、5つのアプリを作りながら学ぼう！レシピ生成アプリ／ブログ記事への自動タグ付け／PDFへのQ&A／自然言語からSQLを生成・実行／スケジュール管理のAIアシスタント",
      "objectives": [
        "Visual Studio Code の Dev Containers を使った Python の環境構築",
        "ChatGPT の API (Chat Completions API) の基礎知識",
        "Function calling の基本と Function calling を応用した JSON の生成",
        "Streamlit を使った Web アプリケーションの素早い実装",
        "ChatGPT の API のチャットボット以外の応用例",
        "LLM の出力を使った Stable Diffusion での画像生成",
        "LangChain を使ったテキストへのタグ付け",
        "LlamaIndex を使った PDF への Q&A",
        "LlamaIndex を使った自然言語からの SQL の生成と実行",
        "LangChain と Zapier NLA を使ったスケジュール管理の AI エージェントの実装"
      ],
      "course_content": {
        "はじめに": [
          "このコースについて",
          "受講ガイド"
        ],
        "Python 開発環境セットアップ": [
          "このコースでの Python のセットアップ方針",
          "Visual Studio Code の Dev Containers のセットアップ",
          "Poetry でプロジェクトを初期化",
          "Streamlit の Hello World",
          "Dev Container へのフォーマッタ（Black）の導入"
        ],
        "ChatGPT の API の基礎知識": [
          "ChatGPT の API の概要",
          "OpenAI の API キーを発行",
          "Streamlit で UI を実装",
          "（追記）RateLimitError について",
          "OpenAI の Chat Completions API を使う",
          "トークン数と料金について",
          "Function calling の基本",
          "このセクションのまとめ"
        ],
        "JSON 形式の文字列の生成（例：レシピ生成アプリ）": [
          "このセクションで実装するアプリケーション",
          "Streamlit で UI を実装",
          "JSON 形式で出力させるプロンプトの実装",
          "Function calling を使った JSON の生成",
          "（追記）画像生成に使うモデルのアップデートについて",
          "画像生成 AI（Stable Diffusion）と連携",
          "このセクションのまとめ"
        ],
        "テキストからの属性抽出（例：ブログ記事への自動タグ付け）": [
          "このセクションで実装するアプリケーション",
          "Streamlit で UI を実装",
          "LangChain を使ったテキストのタグ付けの実装",
          "このセクションのまとめ"
        ],
        "独自データの検索結果を踏まえた Q&A（例：PDF への Q&A）": [
          "このセクションで実装するアプリケーション",
          "Streamlit で UI を実装",
          "（追記）LlamaIndex を使用する箇所で発生するようになったエラーについて",
          "LlamaIndex で独自データへの Q&A を実装",
          "このセクションのまとめ"
        ],
        "自然言語から SQL を生成・実行": [
          "このセクションで実装するアプリケーション",
          "Streamlit で UI を実装",
          "データベース（SQLite）のセットアップ",
          "（追記）init_sqlite.py の不備について",
          "（追記）LlamaIndex を使用する箇所で発生するようになったエラーについて",
          "LlamaIndex による Text-to-SQL の実装",
          "このセクションのまとめ"
        ],
        "【旧】AI エージェント（例：スケジュール管理の AI アシスタント）": [
          "「AI エージェント」のセクションの更新について",
          "このセクションで実装するアプリケーション",
          "Streamlit で UI を実装",
          "Zapier のセットアップ",
          "LangChain による AI エージェントの実装",
          "このセクションのまとめ"
        ],
        "【新】AI エージェント（例：スケジュール管理の AI アシスタント）": [
          "このセクションで実装するアプリケーション",
          "Streamlit で UI を実装",
          "Make（旧 Integromat）のセットアップ",
          "LangChain による AI エージェントの実装",
          "このセクションのまとめ"
        ],
        "おわりに": [
          "さらにステップアップするには",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "「変数・if・for・関数」程度の Python の基礎知識がある",
        "絶対パス・相対パス程度のコンピュータの基礎知識がある",
        "ターミナルで ls、cd などの基本的なコマンドを実行したことがある",
        "SQL について、どんなものかイメージがつく程度の知識がある",
        "プログラミングに使用可能な PC を所有している",
        "PC に Docker と Visual Studio Code をインストールしている",
        "ChatGPT を使ったことがあり、OpenAI の API を利用できる（OpenAI の API の利用には、無料枠があるか、支払いの登録が必要です）"
      ],
      "description": "2022 年末に公開されて以来、「ChatGPT」は一般にも知られるキーワードとなり、非常に盛り上がっています。\nChatGPT が使っている GPT-3.5 や GPT-4 などのモデルは、「大規模言語モデル（LLM：Large Language Model）」と呼ばれます。\nChatGPT の API を使ったアプリケーションの開発も注目されており、多くの組織が取り組むようになっています。\n\n\nChatGPT の API など、LLM を使ったアプリケーションの例としてはチャットボットが定番です。\nしかし、LLM が役立つ可能性があるのはチャットボットだけではなく、様々なアプリケーションへの応用が考えられます。\nこの講座では、単なるチャットボットではない LLM の応用例として、5 つのアプリケーションの実装に挑戦します。\n\n\nコースで実装するのは、以下の 5 つのアプリケーションです。\n\n\nJSON 形式の文字列の生成（例：レシピ生成アプリ）\nテキストからの属性抽出（例：ブログ記事への自動タグ付け）\n独自データの検索結果を踏まえた Q&A（例：PDF への Q&A）\n自然言語から SQL を生成・実行\nAI エージェント（例：スケジュール管理の AI アシスタント）\n\n\nPython で Web アプリを簡単に実装できる「Streamlit」を使い、これらのアプリケーションをできるだけシンプルに実装していきます。\n\n\n■このコースで学ぶこと\nこのコースで学ぶのは、ChatGPT の API の「チャットボット以外の応用例」です\nStreamlit を使い、簡易的に Web アプリケーションを実装していきます\nLangChain や LlamaIndex といった有名なフレームワークにも少しふれます\n\n\n■このコースで学ばないこと\nチャットボットを実装する例\nLangChain や LlamaIndex の使い方や仕組みの詳細\n本番システムを意識したシステムの構築や評価\nLLM や機械学習自体の仕組み\n\n\nこのコースは、LLM のチャットボット以外の応用例を知り、受講者の方が自分なりのアイデアに繋げることを目標としています。\n\n\n更新履歴\n2023/10/19：レクチャー「（追記）Zapier NLA の廃止について」を追加\n2023/10/30：レクチャー「（追記）init_sqlite の不備について」を追加\n2023/11/06：\nセクション「【新】AI エージェント（例：スケジュール管理の AI アシスタント）」を追加\nもとのセクション「AI エージェント（例：スケジュール管理の AI アシスタント）」を【旧】に変更\n2023/11/20：レクチャー「（追記）画像生成に使うモデルのアップデートについて」を追加\n2023/11/24：レクチャー「（追記）RateLimitError について」を追加\n2025/03/20：レクチャー「（追記）LlamaIndex を使用する箇所で発生するようになったエラーについて」を追加",
      "target_audience": [
        "ChatGPT の API など、LLM を使ったアプリケーションの開発を学びたい方",
        "LLM のチャットボット以外の応用例とその仕組みを学びたい方",
        "LLM を使ったアプリケーションをいくつか実装してみたい方"
      ]
    },
    {
      "title": "Fundamentals of Machine Learning through Python",
      "url": "https://www.udemy.com/course/fundamentals-of-machine-learning-through-python/",
      "bio": "Python, Scikit-Learn, and Practical ML: From Basics to Projects",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction to Course",
          "Setting Up Google Colaboratory",
          "Importance of Machine Learning"
        ],
        "Python Fundamentals for Machine Learning": [
          "Introduction to Python",
          "Variables and Operators",
          "Control Structures",
          "Functions",
          "Modules",
          "Intro to Data Structures"
        ],
        "Data Preparation: The Foundation of ML Success": [
          "Introduction to Data Processing",
          "Transforming Data",
          "Data Visualization"
        ],
        "Supervised Learning": [
          "Introduction to supervised learning",
          "Linear Regression",
          "Logistic Regression"
        ],
        "Model Evaluation and Optimization": [
          "Metrics",
          "Cross Validation",
          "Overfitting or Underfitting Models",
          "Hyperparameter Tuning"
        ],
        "Scikit-Learn": [
          "Introduction to scikit-learn",
          "Overview of documentation"
        ],
        "Advanced Machine Learning Models": [
          "RandomForest and GradientBoosting",
          "KNN",
          "SVM"
        ],
        "Project": [
          "Project Introduction",
          "Project Submission"
        ],
        "Conclusion": [
          "Concluding Remarks"
        ]
      },
      "requirements": [
        "Basic knowledge of Python programming is recommended, but this beginner-friendly course welcomes learners with no prior machine learning experience"
      ],
      "description": "Unlock the potential of machine learning with our comprehensive course, \"Mastering Machine Learning: From Fundamentals to Practical Projects with Python and Scikit-Learn.\" Tailored for aspiring data enthusiasts and programmers, this course is an immersive journey through the key pillars of machine learning, ensuring a strong foundation and practical proficiency.\nBegin with Python fundamentals, covering variables, control structures, and modular programming, before delving into the heart of data science: data preparation. Learn to wield Python for data cleaning, handle missing values, and engineer features to optimize dataset quality. Transition seamlessly into supervised learning, mastering linear and logistic regression for numerical predictions and categorical classifications.\nNavigate the intricate landscape of model evaluation and validation, ensuring your models generalize well to unseen data. Harness the power of Scikit-Learn, building and training models with its intuitive interface. Explore advanced topics, from ensemble methods like Random Forest and Gradient Boosting to the complexity-solving capabilities of Support Vector Machines.\nThe course crescendos with a hands-on project, where learners apply acquired skills to real-world scenarios, from data preprocessing to model selection and evaluation. Emerging from this course, you'll possess the confidence to navigate the machine learning landscape, equipped with practical skills, project experience, and a deepened understanding of Python and Scikit-Learn. Start your machine learning journey today!",
      "target_audience": [
        "This course is designed for aspiring data enthusiasts, programmers, and beginners in machine learning who seek a comprehensive introduction to the field. Whether you're a Python novice or looking to transition into data science, this beginner-friendly journey will equip you with the essential skills to confidently explore and apply machine learning concepts in real-world scenarios."
      ]
    },
    {
      "title": "Doğal Dil İşleme A-Z™: (NLP)",
      "url": "https://www.udemy.com/course/dogal-dil-isleme/",
      "bio": "Yapay zeka, derin öğrenme kullanarak natural language processing kavramlarını anlayın ve Python, Keras ile NLP yazın.",
      "objectives": [
        "Yinelenen sinir ağlarını tam manasıyla kavramış olacaksınız",
        "Doğal dil işlemeyi ayrıntılarıyla görmüş olacaksınız",
        "Çeviri yapan bir yapay zeka geliştirebileceksiniz",
        "Sentiment analysis ile olumlu veya olumsuz yorumları tespit edebileceksiniz",
        "Kelime vektörlerini kullanarak kelimeler arasındaki bağlantıları bulabileceksiniz",
        "Derin öğrenmeyi tüm ayrıntılarıyla öğreneceksiniz"
      ],
      "course_content": {
        "Giriş": [
          "Giriş"
        ],
        "Kurulumlar": [
          "Kurulum (Anaconda, Tensorflow, Gensim, NLTK)",
          "Derin Öğrenmede CPU vs GPU",
          "Jupyter Notebook Tutorial",
          "Kurstaki Bütün Kodlar ve Datasetler",
          "Kurulumlar (Yazılı)"
        ],
        "Doğal Dil İşlemeye Giriş ve NLTK": [
          "Doğal Dil İşleme Nedir?",
          "NLTK ile Tokenler",
          "NLTK ile Stop Words",
          "NLTK ile Stemming",
          "NLTK ile Part of Speech Tagging",
          "NLTK ile Named Entity Recognition",
          "NLTK ile Lemmatizing",
          "Corpus ve Corpora"
        ],
        "Kelime Vektörleri: word2vec": [
          "Kelime Anlamı",
          "word2vec Giriş",
          "Skip-gram ve CBOW",
          "Skip-gram'in Matematiği",
          "Negative Sampling",
          "Gensim ile word2vec part 1",
          "Gensim ile word2vec part2"
        ],
        "Kelime Vektörleri: GloVe": [
          "Kelime Sayma Yöntemleri (SVD)",
          "GloVe",
          "Gensim ile GloVe"
        ],
        "Yinelenen Sinir Ağları (RNN)": [
          "RNN'e Giriş",
          "Basit RNN'in Yapısı",
          "Exploding ve Vanishing Gradient",
          "LSTM ve GRU",
          "LSTM'in İçerisinde Neler Oluyor"
        ],
        "Sentiment Analysis": [
          "SA: Modelin yapısı ve Verileri yükleme",
          "SA: Tokenleştirme",
          "SA: Model Oluşturma ve Eğitme",
          "SA: Model Testi ve Kullanımı"
        ],
        "Makine Çevirisi (seq2seq)": [
          "seq2seq ve Makine Çevirisi",
          "NMT: Modelin Yapısı ve Verileri Yükleme",
          "NMT: TokenizerWrap",
          "NMT: Encoder ve Decoder için verileri tokenleştirme",
          "NMT: Input ve Output",
          "NMT: Encoder",
          "NMT: Decoder",
          "NMT: Modeli Eğitme",
          "NMT: Model Testi ve Kullanımı"
        ],
        "Image Captioning": [
          "imcap: Modelin Yapısı ve Verileri Yükleme",
          "imcap: VGG16",
          "imcap: Tokenleştirme",
          "imcap: Generator",
          "imcap: Decoder",
          "imcap: Model Testi ve Kullanımı"
        ],
        "Ek Ders: Python'a giriş ve Numpy": [
          "Veri Türleri 1",
          "Veri Türleri 2",
          "Koşullu İfadeler",
          "Döngüler",
          "Fonksiyonlar",
          "Numpy Array",
          "Numpy'da Indeksleme",
          "Numpy'da İşlemler",
          "Pandas Seriler",
          "Pandas DataFrame 1",
          "Pandas DataFrame 2",
          "Pandas DataFrame 3",
          "Pandas Kayıp Veriler",
          "Pandas Groupby",
          "Pandas Merging, Joining ve Concatenating",
          "Pandas İşlemler",
          "Pandas Veri Okuma ve Yazma",
          "Python Kodları"
        ]
      },
      "requirements": [
        "Temel Programlama Bilgisi",
        "64-bit İşletim Sistemi"
      ],
      "description": "Herkese merhaba,\n\n\nDoğal dil işleme kursuna hoşgeldiniz. Bu kursta doğal dil işlemenin karmaşık dünyasını adım adım ayrıntılarla, sade ve anlaşılır bir şekilde göreceksiniz. Sıfırdan başlayarak uzmanlığa kadar günümüzdeki en güncel doğal dil işleme yöntemlerini öğreneceksiniz. Ayrıca en önemli derin öğrenme alanlarından birisi olan yinelenen sinir ağlarını çok ayrıntılı bir şekilde öğreneceksiniz. Makine çevirisi, chatbotlar gibi karmaşık sistemlerin temelinde yinelenen sinir ağları yatar. Kursta da İngilizce Türkçe çeviri yapabilen bir model geliştireceğiz. Böylece yinelenen sinir ağlarını hem teori olarak hem de gerçek projelerle göreceksiniz.\n\n\nKurs temel programlama bilgisi dışında bir önbilgi gerektirmez. Kursta bütün kodları Python kullanarak yazacağız. Eğer Python bilmiyorsanız kursun sonuna temelden Python eğitimi ekledim. Ek ders sayesinde ayrıntılara boğulmadan çok hızlı bir şekilde Python öğrenerek kursa hazır olacaksınız.\n\n\nŞimdiden hepinize başarılar dilerim.",
      "target_audience": [
        "Doğal dil işleme öğrenmek isteyenler",
        "Yinelenen sinir ağlarını ayrıntılarıyla öğrenmek isteyenler",
        "Kelime vektörlerini öğrenmek isteyenler",
        "Sentiment analysis yapmak isteyenler",
        "Makine çevirisi yapmak isteyenler",
        "Image captioning yapmak isteyenler",
        "NLTK, gensim kütüphanelerini öğrenmek isteyenler",
        "seq2seq öğrenmek isteyenler"
      ]
    },
    {
      "title": "İstatistik & Python: A'dan Z'ye Temel İstatistik Bilimi (6)",
      "url": "https://www.udemy.com/course/istatistik-python-adan-zye-temel-istatistik-bilimi-6/",
      "bio": "Yapay Zeka Öğrenme Yolunda Temel İstatistik Kavramlarını Öğrenin ve Kendinizi İstatistik Biliminde Geliştirin - 2020",
      "objectives": [
        "Nihai hedefimiz olan \"7 Adımlık Yapay Zeka Yolculuğu\" serimizin son adımına geçmiş olacaksınız",
        "Hypothesis Testing, ANOVA, Chi Squared Tests ve Regression Models gibi önemli istatistiksel kavramları öğrenip gerçek hayat problemlerine Python ile uygulayacaksınız",
        "İncelediğiniz verileri tüm dünya ile paylaşacaksınız",
        "Kendinize güzel bir kod deposu oluşturacaksınız",
        "Anlaması işkence gibi olan Olasılık kavramlarını anlayıp günlük hayat problemlerinde kullanabileceksiniz",
        "İstatistiksel dağılımların neler olduğunu öğreneceksiniz"
      ],
      "course_content": {
        "İstatistik Giriş": [
          "İstatistik Kurs Programı (Curriculum)",
          "Udemy Kolaylıkları",
          "Anaconda - Jupyter Notebook - Spyder Kurulum",
          "Datai Team: Github ve Kaynaklar"
        ],
        "DATA (VERİ)": [
          "Data Giriş",
          "Data Nedir?",
          "Level of Measurements (Ölçülme Ölçeği)",
          "Level of Measurements Quiz",
          "Level of Measurements Quiz Cevaplar",
          "Population vs Sample",
          "Central Tendency (Merkezi Eğilim)",
          "Central Tendency Quiz",
          "Central Tendency Quiz Cevaplar",
          "Dispersion (Dağılım)",
          "Dispersion Quiz",
          "Dispersion Quiz Cevaplar",
          "Quartiles",
          "Quartiles Quiz",
          "Quartiles Quiz Cevaplar",
          "Bivariate Data and Covariance (İki Değişkenli Veri ve Kovaryans)",
          "Pearson Correlation Coefficient (Pearson Korelasyon Katsayısı)",
          "Spearman Rank Coefficient (Spearman Rank Katsayısı)",
          "Effect size",
          "Data Neler Öğrendik?"
        ],
        "Probability (Olasılık)": [
          "Probability Giriş",
          "Probability Nedir?",
          "Permutation (Permutasyon)",
          "Permutation Quiz",
          "Permutation Quiz Cevaplar",
          "Combination (Kombinasyon)",
          "Intersection, Unions and Complements (Kesişim, Birleşim ve Tamamlayıcı)",
          "Independent and Dependent Events (Bağımsız ve Bağımlı Olaylar)",
          "Conditional Probability (Şartlı olasılık)",
          "Conditional Probability Quiz",
          "Conditional Probability Quiz Cevaplar",
          "Bayes Theorem (Bayes teoremi)",
          "Probability Neler Öğrendik?"
        ],
        "Probability Distributions (Olasılık Dağılımlar)": [
          "Probability Distributions Giriş",
          "Uniform Distributions",
          "Binomial Distributions",
          "Binomial Distributions Quiz",
          "Binomial Distributions Quiz Cevaplar",
          "Poisson Distributions",
          "Uniform - Binomial - Poisson Quiz",
          "Uniform - Binomial - Poisson Quiz Cevaplar",
          "Continuous Probability Distributions",
          "Gaussian (Normal) Distributions",
          "Z-Score",
          "Probability Distributions Neler Öğrendik?"
        ],
        "Statistic (İstatistik)": [
          "İstatistik Giriş",
          "Sampling (Örnekleme)",
          "Central Limit Theorem (Merkezi Limit Teoremi)",
          "Standard Error",
          "Hypothesis Testing",
          "Hypothesis Testing Real World Örneği 1",
          "Hypothesis Testing Real World Örneği 2",
          "Type-1 ve Type-2 Errors",
          "T-Distribution",
          "A/B Test",
          "İstatistik Neler Öğrendik?"
        ],
        "ANOVA (Analysis of Variance)": [
          "ANOVA Giriş",
          "ANOVA Nedir",
          "F-Distribution",
          "ANOVA Neler Öğrendik?"
        ],
        "Chi-Square Analysis": [
          "Chi-Square Analysis Giriş",
          "Chi-Square Analysis Nedir",
          "Chi-Square Analysis Örnek",
          "Chi-Square Analysis Neler Öğrendik?"
        ],
        "Regression": [
          "Regression Giriş",
          "Linear Regression Data Tanıtımı",
          "Linear Regression Nedir",
          "Linear Regression Nedir-2",
          "Linear Regression with Python",
          "Multiple Linear Regression Dataset Hazırlama ve Tanıtımı",
          "Multiple Linear Regression Nedir",
          "Multiple Linear Regression with Python",
          "Polynomial Regression Dataset Hazırlama ve Tanıtımı",
          "Polynomial Linear Regression Nedir",
          "Polynomial Linear Regression with Python",
          "Regression Neler Öğrendik?"
        ],
        "İstatistik Sonuç": [
          "Ne Yaptık Ne Yapacağız",
          "BONUS"
        ]
      },
      "requirements": [
        "Önceden \"Python: Sıfırdan Uzmanlığa Programlama (1)\" kursunun alınmış olması yada Python temellerinin bilinmesi gerekli!",
        "İnternet bağlantılı bir bilgisayara sahip olmak yeterlidir",
        "Hedefler, gelecekle ilgili güzel hayaller ve programlama tutkusu"
      ],
      "description": "Merhaba arkadaşlar,\nBu kurs 7 adımlık Yapay Zeka yolculuğumuzun altıncı bölümünü oluşturmaktadır.\nPython: Python Sıfırdan Uzmanlığa Programlama (1)\nData Science ve Python: Sıfırdan Uzmanlığa Veri Bilimi (2)\nData Visualization: A'dan Z'ye Veri Görselleştirme (3)\nMachine Learning ve Python: A'dan Z'ye Makine Öğrenmesi (4)\nDeep Learning ve Python: A'dan Z'ye Derin Öğrenme (5)\nStatistical Learning (İstatistik)\nArtificial Intelligence (Yapay Zeka)\nNihai hedefimiz olan yapay zeka algoritmalarını öğrenebilmek ve istatistik bilimini temelini oluşturmak için gerekli İstatistik kavramlarını öğreneceğiz.\nNeden İstatistik?\nBilgi dünyasında yaşıyoruz ve bu bilgi istatistik ile kontrol ediliyor.\nİstatistik bilimi toplayacağımız veri üzerinde farkındalığımızın artmasına neden olur.\nİstatistik bilimi iş adamlarını para kazanmak için olmazsa olmazıdır.\nYazılım dünyasında günlük hayat problemlerinin her yerinde temel seviyede istatistik vardır.\nBu Kurs ile Alacaklarınız\nSıfırdan Kodlama Becerisi: Sizinle birlikte kod yazıyoruz. Her ders boş bir sayfa ile başlar ve kodu sıfırdan yazarız. Bu şekilde ilerleyebilir ve kodun nasıl bir araya geldiğini ve her satırın ne anlama geldiğini tam olarak anlayabilirsiniz.\nKodlar ve Şablonları: Kursta oluşturduğumuz her Python şablonlarını ve kodunu indirebilirsiniz. Bu, sizlere hem daha sonra kod üzerinde pratik yapma hem de kendi projelerinizi şablon sayesinde daha kolay bir şekilde yaratma imkanı sağlayacaktır\nTeori ve Mantık: Size yalnızca kod yazmayı değil, hem yazdığımız kodun arkasında yatan mantığı ve teoriyi hem de neden böyle bir kod yazdığımızı anlatıyoruz.\nKurs içi destek: Size sadece video ile ders anlatımı yapmıyoruz. Size destek olmak için profesyonel Veri Bilimcilerinden oluşan bir ekip oluşturduk. Bu da ders ve ya ders dışı sorularınıza en fazla 72 saat içinde yanıt alacağınız anlamına geliyor.\nİstatistik kursu içeriği\nDATA\nData Nedir?\nLevel of Measurements (Ölçülme Ölçeği)\nPopulation vs Sample\nCentral Tendency (Merkezi Eğilim)\nDispersion (Dağılım)\nQuartiles\nBivariate Data and Covariance (İki Değişkenli Veri ve Kovaryans)\nPearson Correlation Coefficient (Pearson Korelasyon Katsayısı)\nSpearman Rank Coefficient (Spearman Rank Katsayısı)\nEffect size\nProbability (Olasılık)\nProbability Nedir?\nPermutation (Permutasyon)\nCombination (Kombinasyon)\nIntersection, Unions and Complements (Kesişim, Birleşim ve Tamamlayıcı)\nIndependent and Dependent Events (Bağımsız ve Bağımlı Olaylar)\nConditional Probability (Şartlı olasılık)\nBayes Theorem (Bayes teoremi)\nProbability Distributions (Olasılık Dağılımlar)\nDiscrete Probability Distributions\nUniform Distributions\nBinomial Distributions\nPoisson Distributions\nContinuous Probability Distributions\nPDF - CDF\nGaussian (Normal) Distributions and Z-Score\nStatistics (İstatistik)\nSampling (Örnekleme)\nCentral Limit Theorem (Merkezi Limit Teoremi)\nStandard Error\nHypothesis Testing\nHypothesis Testing Real-World Örneği 1\nHypothesis Testing Real-World Örneği 2\nType 1 ve Type 2 Errors\nT-Distribution\nA/B Test\nANOVA (Analysis of Variance)\nANOVA Nedir?\nF Distribution\nChi-Square Analysis\nChi-Square Analysis Nedir?\nChi-Square Analysis Örnek\nRegression\nLinear Regression\nMultiple Linear Regression\nPolynomial Regression\nİçeriğin İngilizce olması sizi yanıltmasın arkadaşlar. Derslerim tamamen Türkçedir.\nHemen kaydolun ve bir an önce başlayalım.",
      "target_audience": [
        "Eğitim yada kariyerini veri bilimi(data science), makine öğrenmesi(machine learning) yada yapay zeka(artificial intelligence) alanlarında başlamak yada sürdürmek isteyenler",
        "Veri Biliminde uzmanlaşmak isteyenler",
        "İstatistik temellerini öğrenmek isteyenler",
        "İstatistik ve veri bilimi için Python dilini öğrenmek isteyenler",
        "Olasılık(Probability) ile yıldızı bir türlü barışmayanlar"
      ]
    },
    {
      "title": "TensorFlow: Machine Learning e Deep Learning com Python",
      "url": "https://www.udemy.com/course/tensorflow-machine-learning-deep-learning-python/",
      "bio": "Construa redes neurais artificiais modernas com o Google TensorFlow e especialize-se em Inteligência Artificial!",
      "objectives": [
        "Aprenda na teoria e na prática como construir redes neurais artificiais para resolver problemas reais do dia",
        "Aprenda os conceitos sobre redes neurais convolucionais, redes neurais recorrentes, autoencoders e redes adversariais generativas",
        "Avalie e configure os parâmetros de uma rede neural com o TensorFlow",
        "Desenvolva redes neurais robustas utilizando o TensorFlow",
        "Construa passo a passo redes neurais aplicadas em problemas de classificação e regressão",
        "Implemente redes neurais convolucionais para classificar imagens",
        "Aplique redes neurais recorrentes em séries temporais",
        "Reduza a dimensionalidade de bases de dados utilizando autoencoders",
        "Crie novas imagens automaticamente utilizando redes adversariais generativas"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Introdução a Deep Learning",
          "Instalação do Anaconda",
          "Problemas de instalação do Anaconda",
          "Spyder",
          "Jupyter Notebook",
          "Introdução ao TensorFlow",
          "IMPORTANTE 1: Atualizações no código fonte",
          "IMPORTANTE 2: Versão do Python",
          "Código fonte completo + slides das aulas"
        ],
        "----- Parte 1 - Introdução prática ao TensorFlow -----": [
          "Introdução a Parte 1 - Introdução ao TensorFlow"
        ],
        "Sintaxe básica": [
          "Compatibilidade TensorFlow 1.x e 2.x",
          "Constantes",
          "Variáveis I",
          "Variáveis II",
          "Adição de vetores e matrizes",
          "Multiplicação de matrizes",
          "Produto escalar",
          "Placeholders",
          "Grafos e TensorBoard"
        ],
        "----- Parte 2 - Regressão e classificação -----": [
          "Introdução a Parte 2 - Regressão e classificação"
        ],
        "Regressão linear": [
          "Regressão linear - teoria",
          "Regressão linear com sklearn",
          "Regressão linear com TensorFlow I",
          "Regressão linear com TensorFlow II",
          "Previsão do preço de casas I",
          "Previsão do preço de casas II",
          "Regressão linear simples com estimators I",
          "Regressão linear simples com estimators II",
          "Regressão linear múltipla com estimators I",
          "Regressão linear múltipla com estimators II"
        ],
        "Classificação": [
          "Classificação - introdução",
          "Regressão logística - introdução",
          "Regressão logística com sklearn",
          "Regressão logística com estimators I",
          "Regressão logística com estimators II"
        ],
        "----- Parte 3 - Redes neurais artificiais -----": [
          "Introdução a Parte 3 - Redes Neurais Artificiais"
        ],
        "Teoria resumida sobre redes neurais artificiais": [
          "Perceptron de uma camada",
          "Redes multicamada - função soma e função de ativação",
          "Redes multicamada - cálculo do erro",
          "Descida do gradiente",
          "Cálculo do parâmetro delta",
          "Ajuste dos pesos com backpropagation",
          "Bias, erro, descida do gradiente estocástico e mais parâmetros",
          "Funções de ativação - implementação I",
          "Funções de ativação - implementação II",
          "TensorFlow playground",
          "Teoria sobre redes neurais artificiais",
          "Referências complementares"
        ],
        "Redes neurais para classificação e regressão com TensorFlow": [
          "Perceptron de uma camada I",
          "Perceptron de uma camada II",
          "Classificação binária - XOR I",
          "Classificação binária - XOR II",
          "Classificação binária - XOR III",
          "Classificação multiclasse - base iris I",
          "Classificação multiclasse - base iris II",
          "Base de dados de dígitos manuscritos",
          "Classificação de dígitos manuscritos I",
          "Classificação de dígitos manuscritos II",
          "Classificação de dígitos manuscritos III",
          "Classificação com estimators - base censo I",
          "Classificação com estimators - base censo II",
          "Padronização com TensorFlow",
          "Regressão com estimators - base casas"
        ],
        "----- Parte 4 - Redes Neurais Convolucionais -----": [
          "Introdução a Parte 4 - Redes Neurais Convolucionais"
        ]
      },
      "requirements": [
        "O único pré-requisito obrigatório é conhecimento sobre lógica de programação, principalmente estruturas condicionais e de repetição",
        "Também são necessários conhecimentos sobre instalação de softwares básicos, porém, durante o curso será mostrado o processo de instalação das ferramentas utilizadas durante todo o curso",
        "Conhecimentos em Python não são obrigatórios, sendo possível acompanhar o curso sem saber essa linguagem com profundidade",
        "Conhecimentos em Machine Learning, Redes Neurais ou Inteligência Artificial não são obrigatórios. No final do curso existe um apêndice com várias aulas básicas sobre esses assuntos caso seja seu primeiro contato com a área"
      ],
      "description": "Atenção! Nas aulas deste curso é utilizada a versão 1.x do TensorFlow, sendo possível acompanhar as aulas utilizando essa versão. Adicionalmente, disponibilizamos o código atualizado considerando a versão 2.x. Em breve pretendemos regravar todas as aulas deste curso\nA área de Deep Learning (Aprendizagem Profunda) está relacionada a aplicação das redes neurais artificiais na resolução de problemas complexos e que requerem artifícios computacionais avançados. Existem diversas aplicações práticas que já foram construídas utilizando essas técnicas, tais como: carros autônomos, descoberta de novos medicamentos, cura e diagnóstico antecipado de doenças, geração automática de notícias, reconhecimento facial, recomendação de produtos, previsão dos valores de ações na bolsa de valores e até mesmo a geração automática de roteiros de filmes! Nesses exemplos, a técnica base utilizada são as redes neurais artificiais, que procuram \"imitar\" como o cérebro humano funciona e são consideradas hoje em dia como as mais avançadas no cenário de Machine Learning (Aprendizagem de Máquina). E a maioria dessas aplicações foram desenvolvidas utilizando a biblioteca TensorFlow do Google, que hoje em dia é a ferramenta mais popular e utilizada nesse cenário. Por isso, é de suma importância que profissionais ligados à área de Inteligência Artificial e Machine Learning saibam como trabalhar com essa biblioteca, já que várias grandes empresas a utilizam em seus sistemas, tais como: Airbnd, Airbus, eBay, Dropbox, Intel, IBM, Uber, Twitter, Snapchat e também o próprio Google!\n\nA área de Deep Learning é atualmente um dos campos de trabalho mais relevantes da Inteligência Artificial, sendo que o mercado de trabalho dessa área nos Estados Unidos e em vários países da Europa está em grande ascensão; e a previsão é que no Brasil cada vez mais esse tipo de profissional seja requisitado! Inclusive alguns estudos apontam que o conhecimento dessa área será em breve um pré-requisito para os profissionais de Tecnologia da Informação!\nE para levar você até essa área, neste curso você terá uma visão teórica e principalmente prática sobre as principais e mais modernas técnicas de Deep Learning utilizando o TensorFlow e o Python! Ao final você terá todas as ferramentas necessárias para construir soluções complexas e que podem ser aplicadas em problemas do dia-a-dia das empresas! Para isso, o conteúdo está dividido em sete partes: introdução prática ao TensorFlow, regressão e classificação, redes neurais artificiais, redes neurais convolucionais, redes neurais recorrentes, autoencoders e redes adversariais generativas. Você aprenderá a teoria básica sobre cada um desses assuntos, bem como implementará exemplos práticos passo a passo aplicado em cenários reais. Abordaremos dois tipos de programação com o TensorFlow: utilizando a Low Level e a High Level API. Na primeira faremos a codificação manualmente e definiremos as fórmulas matemáticas, enquanto que na segunda usaremos classes prontas para a implementação!\nVeja abaixo alguns dos projetos que serão desenvolvidos:\nPrevisão do preço de casas baseado nas características da casa\nClassificação de tipos de plantas\nClassificação da faixa salarial de pessoas\nClassificação de dígitos escritos a mão (visão computacional)\nConstrução de série temporal para previsão de preços de ações\nRedução de dimensionalidade em imagens\nCriação automática de imagens\nAo final de cada seção teórica você tem questionários para revisar o conteúdo, bem como indicações de referências complementares caso você queira aprender mais sobre os assuntos.\nImportante: as aulas foram gravadas utilizando o TensorFlow 1.x, porém, o código fonte está totalmente atualizado para a versão 2.x do TensorFlow!\nEste curso é indicado para todos os níveis, ou seja, caso seja seu primeiro contato com Deep Learning e o TensorFlow, você conta com um apêndice que contém aulas básicas sobre aprendizagem de máquina e redes neurais! É também importante enfatizar que o único pré-requisito necessário é saber lógica de programação, pois mesmo se você não seja especialista na linguagem Python você conseguirá acompanhar o curso sem nenhum problema!\nPreparado(a) para dar um importante passo na sua carreira? Aguardo você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em iniciar seus estudos em deep learning (aprendizagem profunda)",
        "Pessoas interessadas em conhecer o funcionamento do TensorFlow do Google",
        "Pessoas interessadas em redes neurais artificiais, convolucionais, recorrentes, autoencoders e redes adversariais generativas",
        "Pessoas interessadas em iniciar uma carreira em Ciência de Dados utilizando técnicas modernas de aprendizagem de máquina",
        "Empreendedores que queiram aplicar aprendizagem de máquina em projetos comerciais",
        "Analistas de dados que queiram aumentar seu conhecimento na área de deep learning (aprendizagem profunda)",
        "Empresários que desejam criar soluções eficientes para problemas reais em suas empresas",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial"
      ]
    },
    {
      "title": "Inteligência Artificial aplicada para Empresas e Negócios",
      "url": "https://www.udemy.com/course/inteligencia-artificial-empresas-negocios/",
      "bio": "Resolva problemas de negócios do mundo real utilizando aprendizagem por reforço",
      "objectives": [
        "Aplicação de algoritmos de Inteligência Artificial para resolver problemas de empresas como: Otimização de Processos, Minimização de Custos e Maximização de Lucros",
        "Teoria sobre aprendizagem por reforço com os algoritmos Q-Learning, Deep Q-Learning e Thompson Sampling"
      ],
      "course_content": {
        "Introdução": [
          "Boas vindas e conteúdo do curso",
          "E-book",
          "Mais sobre Inteligência Artificial",
          "Código fonte completo + slides"
        ],
        "----- Parte 1 - Otimização de Processos de Negócios -----": [
          "Bem-vindo(a) à Parte 1 - Otimização de Processos de Negócios"
        ],
        "Estudo de Caso": [
          "Minimização de Custos - Parte 1",
          "Minimização de Custos - Parte 2",
          "Minimização de Custos - Parte 3"
        ],
        "Solucão de Inteligência Artificial": [
          "Bem-vindo(a) à seção de intuição",
          "Conteúdo",
          "Intuição Deep Q-Learning I",
          "Intuição Deep Q-Learning II",
          "Replay de Experiência",
          "Políticas de Seleções de Ações"
        ],
        "Implementação da Solução de IA": [
          "Minimização de Custos - Parte 4",
          "Minimização de Custos - Parte 5",
          "Minimização de Custos - Parte 6",
          "Minimização de Custos - Parte 7",
          "Minimização de Custos - Parte 8",
          "Minimização de Custos - Parte 9",
          "Minimização de Custos - Parte 10",
          "Minimização de Custos - Parte 11",
          "Minimização de Custos - Parte 12",
          "Minimização de Custos - Parte 13",
          "Minimização de Custos - Parte 14",
          "Minimização de Custos - Parte 15",
          "Minimização de Custos - Parte 16",
          "Minimização de Custos - Parte 17",
          "Minimização de Custos - Parte 18",
          "Minimização de Custos - Parte 19",
          "Minimização de Custos - Parte 20",
          "Minimização de Custos - Parte 21",
          "Minimização de Custos - Parte 22",
          "Minimização de Custos - Parte 23",
          "Minimização de Custos - Parte 24",
          "Minimização de Custos - Parte 25",
          "Minimização de Custos - Parte 26",
          "Minimização de Custos - Parte 27",
          "Minimização de Custos - Parte 28",
          "Minimização de Custos - Parte 29",
          "Minimização de Custos - Parte 30",
          "Minimização de Custos - Parte 31",
          "Minimização de Custos - Parte 32",
          "Minimização de Custos - Parte 33",
          "Minimização de Custos - Parte 34",
          "Minimização de Custos - Parte 35",
          "Minimização de Custos - Parte 36",
          "Debug passo a passo"
        ],
        "Tarefa": [
          "Instruções para a tarefa",
          "Solução para a tarefa"
        ],
        "----- Parte 2 - Minimização de Custos -----": [
          "Bem-vindo(a) à Parte 2 - Minimização de Custos"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Programação básica em Python",
        "Conhecimentos sobre instalação de softwares básicos, porém, durante o curso será mostrado o processo de instalação das ferramentas utilizadas",
        "Noções de Orientação a Objetos, como: classes, objetos, atributos e métodos",
        "Conhecimentos básicos sobre Redes Neurais Artificiais são desejáveis (no final do curso tem um anexo para revisar esse conteúdo)"
      ],
      "description": "Com Inteligência Artificial, você pode desenvolver três projetos principais para qualquer negócio:\nOtimizar processos de negócios\nMinimizar custos\nMaximizar receitas\nBaseado nessas necessidades, neste curso você aprenderá passo a passo como construir inteligências artificiais em três estudos de caso que envolvem cada uma dessas áreas! Com isso, teremos três partes neste curso:\nNa Parte 1 (Otimização de Processos de Negócios), vamos construir uma IA para otimização de fluxos em um armazém de comércio eletrônico usando o algoritmo Q-Learning da área da Aprendizagem por Reforço\nNa Parte 2 (Minimização de Custos), vamos construir uma IA mais avançada que minimize os custos no consumo de energia de um data center em mais de 50%! Esse projeto é bem parecido com o que os pesquisadores do DeepMind do Google fizeram para economizar milhões de dólares no consumo de energia elétrica! Neste estudo de caso vamos usar o algoritmo Deep Q-Learning, unindo as área de Aprendizagem por Reforço e Deep Learning\nNa Parte 3 (Maximização de Receitas), vamos construir uma IA diferente que irá maximizar a receita de um negócio de varejo on-line, fazendo com que ele tenha mais de 100% de retorno se comparada com uma estratégia que não usa inteligência artificial. Neste projeto, vamos usar o algoritmo Thompson Sampling também da área da Aprendizagem por Reforço\nSe você pretende conseguir um emprego bem remunerado ou criar seu próprio negócio de sucesso com inteligência artificial, este é o curso que você precisa!\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em resolver problemas de empresas utilizando inteligência artificial",
        "Pessoas interessadas em deep learning (aprendizagem profunda)",
        "Pessoas interessadas em aprendizagem por reforço com os algoritmos Deep Q-Learning e Thompson Sampling",
        "Analistas de dados que queiram aumentar seu conhecimento na área de deep learning (aprendizagem profunda)",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial",
        "Pessoas que estão ansiosas para aprender como aproveitar a inteligência artificial para otimizar seus negócios, maximizam a lucratividade e a eficiência",
        "Profissionais que procuram por casos de negócios para adicionar ao seu portfólio",
        "Entusiastas da tecnologia interessados em alavancar a aprendizagem de máquina e a inteligência artificial para resolver problemas de negócios",
        "Consultores, que querem fazer a transição de empresas para negócios dirigidos por inteligência artificial"
      ]
    },
    {
      "title": "人工智能专业课程 (AI Masterclass)",
      "url": "https://www.udemy.com/course/ai-masterclass-chinese/",
      "bio": "新的混合人工智能时代已经来临，我们将要用深度神经进化技术，以及一整套的机器学习，深度学习，人工智能模型对它进行优化 (英文原音)",
      "objectives": [
        "怎样创建AI",
        "怎样创建一个混合智能系统",
        "完全连接的神经网络",
        "循环神经网络",
        "自动编码器",
        "变分自编码器",
        "混合密度网络",
        "深度强化学习",
        "策略梯度",
        "遗传算法",
        "进化策略",
        "协方差自适应调整的进化策略",
        "控制器",
        "元学习",
        "深度神经进化"
      ],
      "course_content": {
        "概述": [
          "介绍+课程结构+演示",
          "学习资源介绍",
          "从这里下载完整的课程资源"
        ],
        "第一步 - 人工神经网络模型": [
          "欢迎来到第一步 – 人工神经网络模型",
          "学习计划",
          "神经元",
          "激活函数",
          "神经网络模型是怎样运作的？",
          "神经网络模型是如何学习的？",
          "梯度下降",
          "随机梯度下降",
          "反向传播"
        ],
        "第二步 - 卷积神经网络模型": [
          "欢迎来到第二步 – 卷积神经网络模型",
          "学习计划",
          "什么是卷积神经网络模型？",
          "第一步 - 卷积操作",
          "第一步 Bis - ReLu层",
          "第二步 - 投票",
          "第三步 - 平面化",
          "第四步 - 完全连接",
          "小结",
          "Softmax & Cross-Entropy"
        ],
        "第三步 - 自编码器": [
          "欢迎来到第三步 – 自编码器",
          "学习计划",
          "什么是自编码器？",
          "关于偏差的介绍",
          "自编码器的训练",
          "过完备隐藏层",
          "疏散自编码器",
          "去噪自编码器",
          "收缩性的自编码器",
          "堆栈式自编码器",
          "深度自编器"
        ],
        "第四步- 变分自编码器": [
          "欢迎来到第四步 – 变分自编码器",
          "介绍VAE",
          "变分自编码器",
          "重新参数化方法"
        ],
        "第五步 - 实现CNN-VAE": [
          "欢迎来到第五步 – CNN-VAE模型的实现",
          "第五步的介绍",
          "CNN-VAE类的参数和变量的初始化",
          "VAE模型编码器部分的创建",
          "创建VAE的V (变化) 部分",
          "创建VAE模型的解码器",
          "实施训练操作",
          "完整的代码",
          "Keras的实现"
        ],
        "第六步 - 循环神经网络": [
          "欢迎来到第六步 – 循环神经网络",
          "学习计划",
          "什么是循环神经网络？",
          "消失的梯度问题",
          "LSTM",
          "LSTM 实践课程",
          "LSTM 的变化"
        ],
        "第七步 - 混合密度网络": [
          "欢迎来到第七步 - 混合密度网络",
          "MDN-RNN的介绍",
          "混合密度网络",
          "VAE + MDN-RNN 的数据可视化"
        ],
        "第八步 - MDN-RNN 的实现": [
          "欢迎来到第八步 – MDN-RNN模型的实现",
          "MDN-RNN 类的参数以及变量的初始化",
          "创建RNN模型 - 收集参数",
          "创建RNN模型 - 创建带丢弃的LSTM",
          "创建RNN模型 - 创建RNN的输入值，目标值以及输出值",
          "创建RNN模型 - 获得RNN模型的确定性结果输出",
          "创建MDN模型 - 获得MDN模型的输入，隐藏层，以及输出层",
          "创建MDN模型 - 获得MDN参数",
          "实现训练操作 (第一部分)",
          "实现训练操作 (第二部分)",
          "完整代码",
          "Keras的实践课程"
        ],
        "第九步 - 强化学习": [
          "欢迎大家来到第九步 – 强化学习",
          "什么是强化学习？",
          "真实世界模型中运用强化学习的Pseudo伪代码",
          "完整代码"
        ]
      },
      "requirements": [
        "高中数学",
        "编程基础"
      ],
      "description": "今天，我们将要给大家带来最前沿的人工智能课程：\n\n\n人工智能专业课程\n\n\n你是不是也对人工智能有兴趣呢？想要学习更强大的人工智能模型，并且跟它一起比赛吗？是不是已经跃跃欲试了呢？\n那么人工智能专业课程就是为你量身定做的了。我们会给你提供一个人工智能工具类，让你轻松掌握这些最前沿的技术。在10个小时的分解讲解课程中，你会学习到如何如何一步一步的搭建自己的混合人工智能模型。\n在这个课程中，你会学到怎样用强大的混合人工智能系统建立人工智能模型。这个模型是现今为止最先进的人工智能模型，击败了所有其他同类的人工智能模型，以高分赢得了比赛。\n这个混合模型被命名为真实世界模型，它涵盖了当前最先进的人工智能领域的几个模型，包括，深度学习，深度强化学习，策略梯度，以及深度神经进化。\n通过本课程的学习，大家可以了解到怎样将这些模型组装起来，组成一个最优表现得人工智能模型：\n· 完全连接的神经网络\n· 卷积神经网络模型\n· 循环神经网络\n· 变分自编码器\n· 混合密度网络\n· 遗传算法\n· 进化策略\n· 协方差自适应调整的进化策略 (CMA-ES)\n· 参数检索式策略梯度\n· 其他\n\n\n因此，你不仅仅是学习一个人工智能的课程，更是一套完整的人工智能工具类。你可以下载这个工具类，然后用它搭建你自己的混合智能模型。混合人工智能模型正在越来越多的人工智能比赛中获胜，所以你也一定要掌握这门最先进的技术。\n除此以外，我们还会给大家用两套AI框架进行实现的完整代码：TensorFlow以及Keras。所以，如果你也刚好想要建一个特定领域的人工智能模型，可以直接利用我们的工具类来搭建你自己的项目！\n快来加入我们，一起来学习混合人工智能模型，走向人工智能领域的未来吧！",
      "target_audience": [
        "任何对人工智能，深度学习，或者机器学习有兴趣的人"
      ]
    },
    {
      "title": "Inteligência Artificial para Iniciantes",
      "url": "https://www.udemy.com/course/inteligencia-artificial/",
      "bio": "Aprender sobre Inteligência Artificial.",
      "objectives": [
        "Aprender os conceitos de Inteligência Artificial.",
        "Conhecer os tipos de aprendizado de máquina.",
        "Conhecer técnicas e algoritmos de aprendizado."
      ],
      "course_content": {
        "Introdução à Inteligência Artificial": [
          "Apresentação",
          "Exercício 1",
          "Introdução",
          "Exercício 2",
          "O que é inteligência",
          "Exercício 3",
          "Primeiros passos",
          "Exercício 4",
          "Motivação - Parte 1",
          "Exercício 5",
          "Motivação - Parte 2",
          "Exercício 6",
          "Teste da sala chinesa",
          "Exercício 7",
          "IA Forte e IA Fraca",
          "Exercício 8"
        ],
        "Busca": [
          "Resolução de problemas por busca - Parte 1",
          "Exercício 9",
          "Resolução de problemas por busca - Parte 2",
          "Exercício 10",
          "Resolução de problemas por busca - Parte 3",
          "Exercício 11",
          "Resolução de problemas por busca - Parte 4",
          "Exercício 12"
        ],
        "Busca sem informação": [
          "Algoritmo genérico de busca com fronteira",
          "Exercício 13",
          "Estratégias de busca sem informação",
          "Exercício 14",
          "Busca em largura",
          "Exercício 15",
          "Busca em profundidade",
          "Exercício 16",
          "Robô em um labirinto",
          "Busca em profundidade versus busca em largura",
          "Exercício 17",
          "Busca em profundidade limitada",
          "Exercício 18",
          "Busca por aprofundamento iterativo",
          "Exercício 19"
        ],
        "Busca com informação": [
          "Busca gulosa",
          "Exercício 20",
          "Busca A-Star",
          "Exercício 21"
        ],
        "Outras estratégias de busca": [
          "Busca com melhoria iterativa",
          "Exercício 22",
          "Busca subida de encosta (Hill-Climbing)",
          "Exercício 23",
          "Problema das 8 rainhas com subida de encosta",
          "Exercício 24"
        ],
        "Algoritmos Genéticos": [
          "Introdução a Algoritmos Genéticos",
          "Exercício 25",
          "Fluxograma de um Algoritmo Genético",
          "Exercício 26",
          "Explicação do algoritmo genético",
          "Exercício 27",
          "Mais um pouco sobre algoritmos genéticos",
          "Exercício 28",
          "Problema do Caixeiro-Viajante com AG",
          "Exercício 29",
          "Aprendendo a saltar por cima da bola",
          "Exercício 30"
        ],
        "Simulated Annealing": [
          "Conhecendo o Simulated Annealing",
          "Exercício 31",
          "Algoritmo do Simulated Annealing",
          "Exercício 32",
          "Problema do Caixeiro-Viajante com Simulated Annealing"
        ],
        "Busca Tabu": [
          "Conhecendo a Busca Tabu",
          "Exercício 33",
          "Critério de aspiração",
          "Exercício 34",
          "Funcionamento da Busca Tabu",
          "Exercício 35",
          "Algoritmo da Busca Tabu",
          "Exercício 36",
          "Problema da mochila com Busca Tabu - Parte 1",
          "Exercício 37",
          "Problema da mochila com Busca Tabu - Parte 2",
          "Implementação de Busca Tabu"
        ],
        "K-Nearest Neighbors (KNN)": [
          "Tipos de aprendizado",
          "Exercício 38",
          "Introdução ao KNN",
          "Exercício 39",
          "O que é necessário para utilizar o KNN?",
          "Exercício 40",
          "Classificando um novo exemplo",
          "Exercício 41",
          "Calculando a distância entre dois pontos",
          "Exercício 42",
          "Determinando a classe da nova amostra",
          "KNN para classificação do Iris dataset"
        ],
        "Redes Neurais Artificiais": [
          "O que são redes neurais?",
          "Exercício 43",
          "Estrutura de um neurônio artificial",
          "Exercício 44",
          "Funções de ativação",
          "Exercício 45",
          "Rede Perceptron",
          "Exercício 46",
          "Treinamento da Rede Perceptron",
          "Exercício 47",
          "Fase de operação da Perceptron",
          "Implementação de uma MLP (Perceptron MultiCamadas)",
          "Visualização de uma rede neural"
        ]
      },
      "requirements": [
        "Não é necessário conhecimento prévio algum."
      ],
      "description": "Inteligência Artificial (IA) é o ramo da Ciência da Computação que lida com automação do pensamento e comportamento inteligente. IA é uma tecnologia chave para o software do presente/futuro.\nExistem várias aplicações que utilizam IA tais como reconhecimento facial, robôs autônomos, reconhecimento de voz, sistemas de recomendação e muitas outras. Muitas empresas importantes utilizam IA como por exemplo Facebook, Google, IBM, Microsoft etc.\nNesse curso você irá aprender os conceitos de Inteligência Artificial, técnicas de aprendizado e algoritmos para que você possa implementar essas técnicas. Não é necessário conhecimento de nenhuma linguagem de programação, pois com a explicação das técnicas você será capaz de implementar utilizando a sua linguagem preferida.",
      "target_audience": [
        "Todos podem participar desse curso."
      ]
    },
    {
      "title": "Procesamiento del Lenguaje Natural con Python (NLP) [2025]",
      "url": "https://www.udemy.com/course/procesamiento-del-lenguaje-natural-con-python-nlp/",
      "bio": "Aprende NLP y sus aplicaciones: análisis de sentimientos, clasificación de textos, creación de chatbots y mucho más",
      "objectives": [
        "Crear sistemas de Procesamiento del Lenguaje Natural (NLP) desde cero con útiles aplicaciones prácticas.",
        "Construir modelos de clasificación de textos con NLTK.",
        "Realizar análisis de sentimientos muy útiles para definir la estrategia de productos o servicios que esté desarrollando.",
        "Crear chatbots que interactúen con los humanos.",
        "Uso de Python desde cero y su aplicación a herramientas NLP.",
        "Construir sistemas de reconocimiento y síntesis de voz con los que generar potentes asistentes virtuales para su negocio, proyecto o idea."
      ],
      "course_content": {
        "INTRODUCCIÓN AL PROCESAMIENTO DEL LENGUAJE NATURAL (NLP)": [
          "Bienvenida / Información importante",
          "¿Qué es el Procesamiento del Lenguaje Natural (NLP)?",
          "Aplicaciones Procesamiento del Lenguaje Natural"
        ],
        "INTRODUCCIÓN A PYTHON (OPCIONAL)": [
          "Instalación Python + Jupyter",
          "Conceptos básicos de Python",
          "Introducción a las librerías: Numpy",
          "Introducción a las librerías: Pandas",
          "Introducción a las librerías: Matplotlib"
        ],
        "SISTEMAS DE CLASIFICACIÓN DE TEXTOS": [
          "¿En qué consiste la Clasificación de Textos?",
          "Instalación librería NLTK",
          "NOTA: Portal web clasificación",
          "Caso Práctico Clasificación Textos – Tokenizar",
          "Caso Práctico Clasificación Textos – Palabras de Parada",
          "Caso Práctico Clasificación Textos – Sinónimos y antónimos",
          "Caso Práctico Clasificación Textos – Derivación Regresiva",
          "Caso Práctico Clasificación Textos – Lematización",
          "Caso de Uso Clasificación de Textos – Filtro Spam"
        ],
        "ANÁLISIS DE SENTIMIENTOS": [
          "¿En qué consiste el Análisis de Sentimientos?",
          "NOTA: Tweepy API v2",
          "Caso Práctico Twitter – Conexión y captura de tweets",
          "Caso Práctico Twitter – Análisis y visualización de sentimientos"
        ],
        "CREACIÓN DE CHATBOT": [
          "¿En qué consiste un Chatbot?",
          "Caso Práctico Creación Chatbot – Definición Corpus",
          "Caso Práctico Creación Chatbot – Preprocesamiento del Texto",
          "Caso Práctico Creación Chatbot – Evaluación de similitud",
          "Caso Práctico Creación Chatbot – Definición de coincidencias manuales",
          "Caso Práctico Creación Chatbot – Generación de respuesta y diálogo con chatbot"
        ],
        "RECONOCIMIENTO Y SÍNTESIS DE VOZ": [
          "¿En qué consiste el Reconocimiento y Síntesis de Voz?",
          "Instalación de Librerías SpeechRecognition / PyAudio",
          "Caso Práctico - Reconocimiento de voz con Python",
          "Caso Práctico - Sintetizador de Voz con Python",
          "Combinación de funcionalidades NLP para crear herramientas integrales"
        ],
        "CONCLUSIONES": [
          "Conclusiones",
          "Siguientes Pasos"
        ],
        "Clase Extra NLP": [
          "Clase Extra",
          "Recursos Extra"
        ]
      },
      "requirements": [
        "Ninguno, muchas ganas de aprender una habilidad con gran potencial"
      ],
      "description": "¿Quieres aprender a crear sistemas de Procesamiento del Lenguaje Natural (NLP) de una manera práctica?\n---\nEscucha de otros alumnos por qué este es el curso de NLP MEJOR VALORADO en español:\n\"Este curso es muy útil y valioso, puesto que Iván explica de forma dinámica, sin demorarse y a la vez sin correr, explicando cada paso de manera entendible. Además, responde a todas las cuestiones que le plantean y te facilita el aprendizaje. Muchas gracias, Iván. Nos veremos en otro curso. ¡100% recomendado!\" -- María Nogales\n\n\n\"Muy bueno.. Felicitaciones instructor!! Justo lo que esperaba.\" -- Luis Herrera\n\n\n\"Curso ideal para gente que desee iniciarse en la lingüistica computacional o aquellos curiosos con ganas de explorar Python a fondo. Iván explica de manera clara y se anticipa a posibles contratiempos que puedan surgir en el proceso de instalación de librerías. -- Héctor Portela\n---\nEste curso está diseñado para que sea tu guía completa para dominar el Procesamiento del Lenguaje Natural con Python.\nSi no conoces Python no te preocupes, el curso contiene una sección opcional para introducirte a Python y darte el conocimiento necesario desde 0 en caso de que lo necesites.\nPasaremos por actividades prácticas como creación de un detector de Spam a través de la clasificación de textos con NLTK, análisis de sentimientos sobre un producto, servicio o entidad con TextBlob, creación de chatbots para dar asistencia virtual automática, creación de modelos de reconocimientos y síntesis de voz y un sinfín de aplicaciones que nos abren todas estas técnicas.\nObtener estas habilidades te permitirá acceder a posiciones de alto valor añadido debido a la gran demanda de profesionales con este tipo de habilidades. Portales como BusinessWire pronostican que el sector NLP generará 28.600 M$ para 2026, lo cual supone un incremento anual del 11.7%.\nEl curso está estructurado en los siguientes bloques para entender por completo las herramientas de Procesamiento del Lenguaje Natural:\n\n\nBLOQUE 1: INTRODUCCIÓN AL PROCESAMIENTO DEL LENGUAJE NATURAL (NLP)\nBLOQUE 2: INTRODUCCIÓN A PYTHON (OPCIONAL)\nBLOQUE 3: SISTEMAS DE CLASIFICACIÓN DE TEXTOS\nBLOQUE 4: ANÁLISIS DE SENTIMIENTOS (SENTIMENTAL ANALYSIS)\nBLOQUE 5: CREACIÓN DE CHATBOT\nBLOQUE 6: RECONOCIMIENTO Y SÍNTESIS DE VOZ\n\n\nPor otra parte, tendrás una garantía de 30 días para asegurar que estás 100% satisfecho con el material, mi objetivo es aportarte valor con todos estos conocimientos y si no es así siéntete libre de solicitar la devolución, aunque estoy seguro de que cumplirá tus expectativas.\n\n\nEl objetivo del curso no es solo aprender los conceptos de Procesamiento del Lenguaje Natural, sino que en cada bloque se revisarán casos prácticos reales y tendrás a tu disposición el código utilizado para que lo puedas adaptar fácilmente a tu caso de uso concreto.\nLas herramientas de Procesamiento del Lenguaje Natural constituyen una gran oportunidad de futuro para analizar y automatizar la interacción con el habla humana, por lo tanto, si quieres aprender una habilidad muy valorada con gran aplicación práctica, este es tu curso.",
      "target_audience": [
        "Profesionales que quieran optimizar su negocio actual a través de técnicas que sean capaces de reconocer y procesar el lenguaje humano.",
        "Personas que quieran resolver problemas prácticos como detección de Spam, análisis de sentimientos, crear asistentes virtuales,...",
        "Interesados en aprender Python y aplicar su potencial creando herramientas de Procesamiento del Lenguaje Natural",
        "Toda persona que quiera potenciar su perfil adquiriendo habilidades de procesamiento del lenguaje natural con gran futuro.",
        "Analistas que quieran profundizar en herramientas NLP",
        "Estudiantes que quieran aprender una habilidad muy demandada en cualquier sector desde un punto de vista práctico"
      ]
    },
    {
      "title": "Bootcamp 2026 IA Generativa, LLM Apps, Agentes IA, Cursor AI",
      "url": "https://www.udemy.com/course/bootcamp-ia-generativa-y-aplicaciones-llm/",
      "bio": "De cero a nivel profesional: aprende las claves de la IA Generativa, LLM Apps, Agentes IA, Cursor AI.",
      "objectives": [
        "Claves de la IA, la IA Generativa y los nuevos Coding Assistants como Cursor AI.",
        "Aplicaciones LLM con LangChain, CrewAI, LangGraph, LangServe y LangSmith.",
        "Cómo crear aplicaciones sin programar con Cursor AI y otros Coding Assistants.",
        "Cómo construir las nuevas Aplicaciones LLM Multimodales y Multi-Agente.",
        "Oportunidades y amenazas de la IA para empresas, startups y empleos.",
        "Aplicaciones RAG a fondo: Desarrollo Full Stack y Técnicas Avanzadas.",
        "Cómo gestionar LLMOps: Observability, Evaluation, Testing, etc.",
        "Oportunidades profesionales que abre la Inteligencia Artificial.",
        "Pasos para convertirse en Ingeniero de Inteligencia Artificial.",
        "Cómo introducir la Inteligencia Artificial en tu empresa.",
        "Claves de las Aplicaciones LLM, las de mayor potencial de la IA Generativa.",
        "Arquitectura de las Aplicaciones LLM profesionales.",
        "LangChain básico y avanzado, LangChain LCEL y Langchain v010. LangSmith, LangServe, Templates de LangChain.",
        "LCEL (LangChain Expression Language) a fondo.",
        "LlamaIndex básico y avanzado. Templates de LlamaIndex.",
        "ChatGPT, OpenAI, funciones de OpenAI y la API de OpenAI.",
        "Large Language Models (LLM): ChatGPT, Llama2, Mistral, Falcon, etc.",
        "Bases de datos vectoriales: Postgres, Pinecone, Chroma, FAISS, DeepLake, etc.",
        "Aplicaciones Full-Stack: Nextjs y FastAPI.",
        "Deployment profesional: Vercel y Render.",
        "Deployment provisional: Streamlit.",
        "Alojamiento en la nube: AWS S3.",
        "Técnica RAG (Retrieval Augmented Generation).",
        "Agentes de Inteligencia Artificial.",
        "Cómo aplicar los principios de la Responsible AI.",
        "Herramientas cotidianas del Ingeniero IA: Jupyter Notebooks, Python, Terminal, Github, Codespaces, etc."
      ],
      "course_content": {},
      "requirements": [
        "No son necesarios conocimientos técnicos previos.",
        "Los estudiantes con algunos conocimientos previos mejorarán su preparación profesional."
      ],
      "description": "Este Bootcamp Online es una versión compacta y acelerada de nuestro master presencial de 400 horas.\n\nTiene cuatro partes:\nEn la Parte 1 aprenderás las claves de la Inteligencia Artificial y de la nueva IA Generativa, así como su potencial para revolucionar las empresas, las startups y el empleo.\nEn la Parte 2 aprenderás a construir Aplicaciones LLM de nivel profesional, las aplicaciones de mayor potencial de la IA Generativa. Aprenderás a construir Aplicaciones RAG avanzadas, Aplicaciones LLM Multimodales, Agentes IA y Aplicaciones LLM Multi-Agente, así como a gestionar LLMOps.\nEn la Parte 3 aprenderás cómo construir aplicaciones tradicionales y de IA Generativa sin necesidad de programar, utilizando Cursor AI y los nuevos AI Coding Assistants. Aprenderás qué son los AI Coding Assistants como Cursor AI, Claude AI, v0, o1, Replit Agent, etc, y cómo aumentar su performance combinándolos con herramientas como la plataforma Replit, simplified backends como Firebase, Replicate AI, Stable Fusion o Deepgram.\nEn la Parte 4 aprenderás cómo crear aplicaciones SaaS sin necesidad de programar utilizando Cursor AI. También aprenderás, con ejemplos reales de alto nivel, cómo la IA Generativa está transformando el modelo SaaS (Software as a Service).\n\nAl finalizar este programa sabrás hacer lo siguiente:\n\nIA Y EMPRESA\nConocerás las empresas que la IA pone en riesgo de desaparecer.\nConocerás las nuevas oportunidades creadas por la IA para las empresas.\nDiseñar un plan para introducir la IA en tu empresa.\nSeleccionar un proyecto piloto adecuado para introducir la IA en tu empresa.\nFormar el primer equipo IA en tu empresa.\nPreparar la estrategia IA de tu empresa.\n\nIA Y STARTUP\nIdentificar 100 oportunidades para crear startups IA.\n\n\nIA Y EMPLEO\nConocerás las profesiones que la IA pone en riesgo de desaparecer.\nConocerás las nuevas profesiones creadas por la IA.\n\n\nAPLICACIONES LLM, LAS APLICACIONES CON MAYOR POTENCIAL DE LA IA GENERATIVA.\nConocerás los principales casos de uso de las Aplicaciones LLM en las empresas y en las startups.\nAplicaciones LLM RAG.\nAplicaciones LLM Multimodales.\nAgentes IA.\nAplicaciones LLM Multi-Agente.\n\n\nCREACION DE APLICACIONES LLM PROFESIONALES.\nAprenderás la Arquitectura de una Aplicación LLM.\nConocerás cómo aprender lenguajes de programación como Python y Javascript.\nAprenderás a trabajar con el terminal de tu ordenador.\nAprenderás a trabajar con notebooks de Jupyter.\nAprenderás a trabajar con editores de código como Visual Studio Code.\nAprenderás a trabajar con entornos virtuales.\nAprenderás a trabajar con archivos ocultos para guardar credenciales.\nAprenderás cómo utilizar diferentes LLM models (OpenAI, DeepSeek, Meta, Mistral, Anthropic, Groq, etc).\nAprenderás la técnica RAG (Retrieval Augmented Generation).\nAprenderás a utilizar LangChain.\nAprenderás a utilizar el LangChain Expression Language (LCEL).\nAprenderás LCEL a fondo.\nAprenderás a utilizar las nuevas versiones v010 y v020 de LangChain.\nAprenderás a utilizar LlamaIndex.\nAprenderás a utilizar la API de OpenAI.\nAprenderás a utilizar las funciones de OpenAI.\nAprenderás a utilizar LangSmith.\nAprenderás a utilizar LangServe.\nAprenderás a utilizar templates de LangChain y LlamaIndex.\nAprenderás lo que son Agentes de IA y cómo crearlos.\nAprenderás a crear prototipos (demos) de aplicaciones LLM con LangChain y Streamlit.\nAprenderás a crear aplicaciones full-stack CRUD con Nextjs, FastAPI y Postgres.\nAprenderás a crear aplicaciones LLM full-stack profesionales con LangChain, LlamaIndex, Nextjs, Tailwind CSS, FastAPI, Flask y Postgres.\nAprenderás a utilizar bases de datos vectoriales y tradicionales.\nAprenderás a desplegar aplicaciones en Vercel y Render.\nAprenderás a utilizar AWS S3 como plataforma de almacenamiento remoto.\nAprenderás a utilizar ChatGPT como asistente de programación.\nAprenderás a utilizar GPT4-Vision y GPT4o.\nAprenderás a trabajar con Github y Github Codespaces.\nAprenderás lo que es LLMOps y cómo utilizarlo en tus Aplicaciones LLM.\nAprenderás los principios de la Responsible AI y cómo utilizarlos en tus Aplicaciones LLM.\nAprenderás a construir Aplicaciones RAG avanzadas.\nAprenderás a construir las nuevas Aplicaciones LLM Multimodales.\nAprenderás a construir los nuevos Agentes IA.\nAprenderás a construir las nuevas Aplicaciones Multi-Agente.\nAprenderás a utilizar LangGraph.\nAprenderás a utilizar CrewAI.\n\n\nCREACION DE APPS SIN PROGRAMAR UTILIZANDO CURSOR AI Y LOS NUEVOS AI CODING ASSISTANTS\nCursor AI, los nuevos AI Coding Assistants y el futuro del desarrollo de software.\nAnálisis de Cursor AI y de los principales AI Coding Assistants.\nPrincipales estrategias y técnicas para optimizar las posibilidades de Cursor AI.\nEl mejor combo para utilizar con Cursor AI: custom starter template, Replit, v0 y Firebase.\nCómo construir 6 proyectos completos con Cursor AI: desde una sencilla to-do list app, hasta una social network, un chatbot, una tex-to-image app, una voice-to-text app, y una aplicación SaaS full-stack con sistemas de autenticación y pagos.\n\n\nCOMO LA IA GENERATIVA ESTA REVOLUCIONANDO LOS NEGOCIOS SAAS\nCómo la IA Generativa está sustituyendo a aplicaciones SaaS de primer nivel como Salesforce o Workday.\nCómo los Agentes IA están matando las aplicaciones SaaS.\nEl futuro de las aplicaciones SaaS y Micro SaaS.\n\n\nEl Bootcamp consta de:\nCasi 650 lecciones divididas en secciones.\nMás de 650 vídeos.\nMás de 320 presentaciones adjuntas.\nMás de 220 notebooks prácticos.\n50 repositorios prácticos con código en github.\nMás de 45 aplicaciones LLM de distintos niveles de dificultad: básico, medio y avanzado.\nMaterial para más de 400 horas de estudio y prácticas para el estudiante.\n2 libros descargables valorados en 50 euros: \"Claves de la Inteligencia Artificial\" y \"100 Startups de IA que han ingresado más de 500.000 dólares antes de su primer año\".\n\n\nTópicos incluidos en este Bootcamp:\nIA, IA Generativa, Aplicaciones IA, Aplicaciones LLM, Aplicaciones LLM Multimodales, chatGPT, Llama2, GPT4-Vision,  GPT4o, Aplicaciones Full-Stack, LangChain, LangChain Expression Language (LCEL), LangChain v010, LangChain v020, LlamaIndex, OpenAI, OpenAI API, RAG, Técnica RAG, Bases de datos vectoriales, Postgres, Pinecone, Chroma, DeepLake, Streamlit, Nextjs, Vercel, FastAPI,  Flask, Tailwind CSS, Render, AWS S3, LangSmith, LangServe, Templates de LangChain, Templates de LlamaIndex, LLMOps, Responsible AI, LangGraph, CrewAI, Aplicaciones LLM Multi-Agente, Agentes IA, Groq, Llama3, Mixtral, Cursor AI, Cursor, Composer, v0, Claude AI, Claude 3.5 Sonnet, o1, o1-preview, o1-mini, Replit Agent, Replit, Firebase, Supabase, Replicate AI, Stable Fusion, Deepgram, SaaS, Micro SaaS, DeepSeek.",
      "target_audience": [
        "Estudiantes y profesionales con y sin experiencia previa.",
        "Estudiantes sin conocimientos previos interesados en aprovechar las oportunidades profesionales que abre el área de la Inteligencia Artificial.",
        "Ejecutivos interesados en introducir la Inteligencia Artificial en su empresa.",
        "Profesionales de Machine Learning, Deep Learning y Data Science interesados en ampliar sus oportunidades profesionales en el área de la IA Generativa y las Aplicaciones LLM.",
        "Desarrolladores de aplicaciones de software interesados en ampliar sus oportunidades profesionales aprendiendo a desarrollar aplicaciones de Inteligencia Artificial Generativa y Aplicaciones LLM."
      ]
    },
    {
      "title": "【Python×株価分析】株価データを取得・加工・可視化して時系列分析！最終的にAIモデルで株価予測をしていこう！",
      "url": "https://www.udemy.com/course/python-stock/",
      "bio": "Pythonの基礎を学んだ後、Pythonによる株価データの取得や加工そして可視化方法を学びます。最終的に株価予測に挑戦いただきLightGBMという機械学習手法で株価を予測していきます！",
      "objectives": [
        "Pythonの使い方",
        "株価データの取得方法",
        "株価データの加工・可視化方法",
        "株価データの予測方法",
        "AI・機械学習モデルの使い方",
        "ローソク足・ボリンジャーバンドの見方"
      ],
      "course_content": {
        "イントロダクション": [
          "はじめに"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Seabornについて学ぼう！",
          "Python構文の復習"
        ],
        "株価データの取得と加工可視化": [
          "株価を取得してみよう！",
          "株価取得の色々な方法を試してみよう！",
          "「ソニーとトヨタの株価を取得してみよう！」課題の解説",
          "株価の推移を可視化してみよう！",
          "株価の推移をロウソク足チャートで見てみよう！",
          "移動平均線を作って可視化してみよう！",
          "標準偏差を計算してボリンジャーバンドを描画してみよう！"
        ],
        "株価予測": [
          "このセクションにおける株価予測コンペについての注意",
          "株価予測コンペの目的やデータ構造を把握しよう！",
          "データをインポートしてデータの中身を見ていこう！",
          "データの全体トレンドを見ていこう！",
          "差分系列を見ていこう！",
          "特徴量エンジニアリング：ラグ特徴量を作ってみよう！",
          "特徴量エンジニアリング：差分系列とラグ特徴量を追加する関数を作成しよう！",
          "特徴量エンジニアリング：学習データとテストデータへ特徴量を追加してみよう！",
          "XGBoostやLightGBMについて",
          "LightGBMを使ってモデル構築をしていこう！",
          "構築したモデルを使って予測をしてみよう！",
          "提出用のsubmitファイルを作ろう！",
          "コンペページから結果を提出しよう！"
        ],
        "おまけ：Plotlyを使った株価可視化＆他の株価指標について解説": [
          "【注意】data_df.columns = ['Close', 'High', 'Low', 'Open', 'Volume']",
          "Plotlyを使う準備",
          "Plotlyを使ってローソク足チャートを描画する方法",
          "Plotlyを使って複数のグラフを描画する方法",
          "株価テクニカル指標のMACDについて解説",
          "MACDをPlotlyで描画してみよう！",
          "【確認テスト】コースの理解度をチェックしよう",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学ぶのでPythonが初めてでも問題ありません",
        "株価分析やプログラミングへの興味",
        "PCの基本的なスキル"
      ],
      "description": "本コースでは株価分析の基本について学んでいきます。\n\n\n株価の分析は古くから多くの人が取り組んできた長年続くホットトピックです。\n\n\nそして株価データはデータ分析力を鍛える上でも非常に役立ちます。\n株価分析を楽しみながらスキルを身につけていきましょう！\n\n\nこのコースでは、まずPythonの基礎を学んでもらった後に株価をどのように取得するか見ていきます。\n\n\nその後取得した株価の加工集計方法や可視化方法を学びます。\n株価を可視化する上で非常に有用なローソク足やボリンジャーバンドについて可視化しながら見ていきます。\n\n\nそして最終的に株価予測に挑戦していきます！\n強力な機械学習手法であるLightGBMを使って予測をしていきますよ！\n\n\nデータ分析は楽しむことが一番！\n株価分析を楽しんでいきましょう！\n\n\n※株で稼げるようになることを目的にしたコースではありません。あくまでデータ分析の題材として株価を扱い株価分析の面白さや考え方を学んでもらえれば幸いです",
      "target_audience": [
        "株価分析に興味のある全ての人",
        "Pythonで株価を分析したい全ての人"
      ]
    },
    {
      "title": "Data Science con R y RStudio",
      "url": "https://www.udemy.com/course/ciencia-de-datos-con-r-y-rstudio-para-principiantes/",
      "bio": "Aprende a programar en R, el lenguaje para la ciencia de datos",
      "objectives": [
        "Manejar base de Datos con R",
        "Interpretar los resultados obtenidos",
        "Programar desde cero en R",
        "Las Estructuras de Datos en R utilizadas en el análisis de datos",
        "Utilizar RStudio en las diferentes fases del flujo de trabajo",
        "Visualizar Datos en R con ggplot2",
        "Las Estructuras de Control en R",
        "Aprenderás a usar funciones de la familia apply",
        "Limpiar base de datos con tidy",
        "Administrar base de datos"
      ],
      "course_content": {
        "Introducción": [
          "Bienvenidos al curso de R",
          "Para que sirve R?",
          "Libros de Regalo :)",
          "Esto es lo que aprenderemos en el curso",
          "R vs Rstudio",
          "Descargar e instalar R",
          "Descargar e instalar Rstudio",
          "Descarga el Material del curso :)"
        ],
        "PRIMEROS PASOS CON R STUDIO": [
          "Usar R como Calculadora",
          "Ojo con los Logaritmos",
          "Eres capas de resolver este acertijo matemático?",
          "Obteniendo el cociente y el resto",
          "Como redondear con R?",
          "Las Variables, lo mas importante",
          "Creando Variables en R"
        ],
        "TRABAJANDO CON VECTORES": [
          "Que son los vectores ?",
          "Creando vectores mediante repeticion",
          "Vector como una secuencia de numeros",
          "Elementos de un vector",
          "ojo con los Factores",
          "Definiendo factores en R"
        ],
        "TRABAJANDO CON MATRICES": [
          "Aprendiendo que es una Matriz",
          "Matrices en R",
          "De Vectores a Matrices",
          "Comandos Rbind y Cbind",
          "Elementos de una matriz",
          "Extraer elementos de una matriz",
          "Operaciones con Matrices",
          "Ojo con la multiplicación de matrices",
          "Inversa de una matriz",
          "Obtener la inversa de un matriz en R"
        ],
        "DATA FRAMES parte I": [
          "Estructura de una base de datos",
          "Importar datos",
          "Comandos head() y tail()",
          "Dimensiones de una base de datos",
          "Como construir un data frame",
          "De vectores a Data Frame",
          "Cambiar nombre de las variables",
          "Modificar datos"
        ],
        "MANEJANDO DATA FRAMES parte II": [
          "Instalando la libreria de tidyverse",
          "Comando Select",
          "Seleccionando columnas en R",
          "Otras opciones de selecciones",
          "Seleccion según nombre de variables en R",
          "Reordenar variables",
          "Comando Filter",
          "Ejemplos de filtrado en R",
          "Operadores boleanos",
          "Ejemplos con conectores AND, OR, NOT en R",
          "Ojo con las leyes de Morgan"
        ],
        "MANEJANDO DATA FRAMES parte III": [
          "Comando Arrange",
          "como ordenar datos en R",
          "Comando mutate",
          "Crear nuevas variables en R",
          "Agrupar la base de datos con group by",
          "Realizamos estadísticas agrupadas con group_by y summarize",
          "Ejemplo: aerolíneas con mayores retrasos",
          "Las famosas Pipes nos ayudan mucho",
          "Veamos una gran utilidad de las pipes"
        ],
        "REALIZANDO GRÁFICOS CON GGPLOT": [
          "Como hacer graficos con ggplot",
          "Como relacionar 2 variables",
          "Graficamos con geom_point",
          "Agregar etiquetas a un Grafico",
          "Grafiquemos por categorías",
          "El comando facet wrap",
          "Ocultando etiquetas",
          "Grafico de histogramas",
          "Grafico Box Plot",
          "Realizar grafico de cajas y bigotes en R"
        ],
        "GRÁFICOS CON GGPLOT2 parte II": [
          "Grafico de barras",
          "Creando nuestro grafico de barras",
          "Mas opciones de grafico de barras",
          "Creando grafico de torta",
          "grafico de series de tiempo",
          "modificamos nuestra serie temporal",
          "Anotaciones en nuestra serie temporal",
          "comparando 2 graficos temporales"
        ],
        "DATOS RELACIONALES": [
          "Que los los datos relacionales",
          "Que es un inner join?",
          "conoscamos a los otros Joins",
          "claves primarias y foraneas",
          "ejemplo de inner join con datos de vuelos",
          "compliquemos el análisis de claves",
          "Claves duplicadas",
          "Ejemplo de claves duplicadas",
          "Aplicamos los mutates Joins"
        ]
      },
      "requirements": [
        "No hay ningún requisito",
        "No hace falta ninguna experiencia de programación",
        "Los software que usaremos, R y RStudio son gratis"
      ],
      "description": "Para empezar, R es un software que fue diseñado para hacer análisis estadísticos y gráficas, y es software libre. Así, se puede descargar y utilizar sin problemas (en esta otra entrada puedes aprender cómo descargar R y RStudio). En otras palabras, es gratis.\nR ha ganado popularidad porque la curva de aprendizaje es relativamente sencilla comparado con otros lenguajes de programación y permite maquetar o hacer prototipos de modelos muy rápido y con resultados muy buenos.\nOtra ventaja es que es mas o menos sencillo compartir código. Por lo tanto, científicos en cualquier parte del mundo pueden contribuir con sus investigaciones.\nEl programa está dirigido a profesionales no expertos en estadística o computación y que, dada la naturaleza de sus actividades, requieran procesar información para tomar decisiones, recomendar estrategias de acción o verificar la validez de hipótesis de trabajo. Así, dentro del público objetivo, se consideran profesionales provenientes de las áreas de las Ciencias Económicas, Gestión de Empresas, Periodismo, Ciencias Médicas y Psicológicas, entre otras.\nIntroducción a la Ciencia de Datos y a R: Introducir a los participantes a las herramientas básicas de R y el entorno IDE\nTransformacion de datos con dplyr: Utilización de los paquetes que constituyen las herramientas fundamentales de R para la Ciencia de Datos\nVisualización con ggplot2: Aplicación de las técnicas de visualización de R\nProgramación y funciones en R: Construir soluciones a problemas específicos utilizando R\nAnálisis estadístico aplicado con R: Aplicar las herramientas estadísticas de R para el análisis y solución de problemas",
      "target_audience": [
        "Personas que quiera a aprender a programar con R y con ganas de aprender"
      ]
    },
    {
      "title": "Uczenie maszynowe w Pythonie. Podstawy, perceptron, regresja",
      "url": "https://www.udemy.com/course/machine-learning-w-pythonie-101/",
      "bio": "Machine Learning już się dzieje i będzie się dziać dalej. Warto je poznać!",
      "objectives": [
        "pojęcia data science, machine learning, artificial intelligence, prediction",
        "modele statystyczne, matematyczne, danych, typy uczenia",
        "intuicja i matematyka stojąca za uczeniem maszynowym",
        "perceptron Rosenblata - implementacja i wykorzystanie",
        "modele regresji liniowej: Adaline, RANSAC, Lasso, Ridge, ElasticNet",
        "przygotowanie danych do analizy",
        "uzupenianie brakujcych danych, eliminacja wartosci odstajacych",
        "korzystanie z metod i modeli modulu Scikit-Learn"
      ],
      "course_content": {},
      "requirements": [
        "Znajomość Pythona (zobacz nasz kurs \"Python dla początkujących\" lub \"Python dla średnio zaawansowanych\")",
        "Znajomość podstaw matematyki, statystyki, programownia",
        "Rozumienie sensu analizy danych i stosowanych w niej metod",
        "Mile widziana znajomość PANDAS (zobacz nasz kurs \"Data Science. Analiza danych w Python i PANDAS\")"
      ],
      "description": "Ten kurs wchodzi w skład serii kursów o Pythonie. Wybierz właściwy, zależnie od stopnia znajomości Pythona i zainteresowań:\n\n\nPython dla początkujących\nMyślenie algorytmiczne - algorytmy i strukutury danych, które trzeba znać\nMyślenie algorytmiczne - grafy w Pythonie\nData Science - Analiza danych w Python Pandas\nPython dla średniozaawansowanych\nPython Flask - aplikacje webowe\nUczenie maszynowe w Pythonie. Podstawy, perceptron, regresja\nJeśli zastanawiasz się czy kupić akcje, czy zainwestować w złoto, to Ci nie pomogę. Nie wiem, co lepiej zrobić. Ale jeśli zapytasz, czy warto uczyć się o Machine Learning i sztucznej inteligencji, to nie mam wątpliwości co powiedzieć. WARTO! Machine Learning już się dzieje i będzie się dziać dalej. A Ty masz wybór – albo patrzysz na to z boku, albo zostajesz liderem w tej dziedzinie.\nTen kurs jest stworzony dla tych, którzy już mają wiedzę programistyczną i pracowali z danymi. Wiedza na temat samego machine learning nie jest wymagana. Pod tym względem zaczynamy od zera tłumacząc nawet co to model, predykcja, uczenie maszynowe itp.\nAle uwaga. Nie kończymy na teorii. To tylko początek. Przygotuj się na dużo programowania. Do każdej lekcji, nawet teoretycznej masz quiz i zadania praktyczne. Każde zadanie praktyczne jest rozwiązane, więc bez obaw - nie zgubisz się.\nNa kursie nabędziesz intuicji stojącej za algorytmami, ale poznasz też matematykę, która tą intuicję uzasadnia. Bez obaw. Moim celem nie jest nauczanie tutaj liczenia pochodnej ani operacji na macierzach. Wystarczy, że kojarzysz mniej więcej co to jest, ale oczywiście im więcej pamiętasz z matematyki tym lepiej.\nZazwyczaj algorytm implementujemy od zera w Pythonie, a potem pokazujemy, jak korzystać z gotowych klas przygotowanych w module Scikit-Learn. Dzięki temu nie jesteś programistą, który jak małpka uruchamia funkcję nie wiedząc co dzieje się pod spodem. Pracujemy na prawdziwych danych: ceny diamentów, domów, jakość wina, wielkość mózgu, zachorowalność na choroby, rozpoznawanie kształtów i cyfr no i legendarne kwiaty Iris. Chciałbym, żeby studenci kończący ten kurs byli w stanie samodzielnie budować własne modele.\nMachine Learning to olbrzymi temat, mnóstwo algorytmów, bibliotek, technik obróbki danych. Po prostu ogrom. My z tego wielkiego obszaru wybieramy tylko dwa tematy – budowę pojedynczego perceptronu, który jest ważny, bo to przecież podstawa głębokich sieci neuronowych, oraz algorytmy z rodziny regresji liniowej. Jest ich kilka i mają swoje specyficzne zastosowania i co by tu dużo mówić – nie można ich nie znać. Ale jak się przekonasz to i tak bardzo dużo, bo te tematy omówimy bardzo dokładnie: intuicja matematyka, przykłady, testy, zadania – komplet, jak na siłowni, tylko dla mózgu, a nie dla mięśni. Jeśli szukasz kursu pod tytułem „wszystkie algorytmy w jeden dzień” to szukaj dalej. Jeśli szukasz rzetelnego omówienia neuronu i regresji, to to jest to!\nPrzekwalifikowanie się do zawodu programisty machine learning to co najmniej kilkanaście miesięcy pracy. Jednak nos do góry. Ten kurs może być Twoim krokiem we właściwym kierunku. Wszystko w Twoich rękach. Jeśli interesuje Cię temat machine learning, nie chcesz być biernym obserwatorem rosnących zastosowań sztucznej inteligencji i chmury, zapisz się na kurs. Nic nie ryzykujesz.\nTeraz jest dobry czas na Machine Learning. Nie czekaj - dołącz! Zapraszam!\nPo zakończeniu tego kursu powinieneś:\nbez problemu umieć własnymi słowami opowiedzieć o co chodzi w Machine Learning,\nopisać jakie mamy do dyspozycji algorytmy, co to jest uczenie nadzorowane i nienadzorowane\nznać szczegółowe zasady działania pojedycznego neuronu i umieć go zastosować do rozwiązywania problemów\nskorzystać z różnych odmian regresji liniowej: Adaline, RANSAC, Lasso, Ridge, Elastic Net\nprzeanalizować, oczyścić dane i uzupełnić brakujące dane\nprzygotować dane do uczenia maszynowego, dzielić je na dane  uczące i testowe oraz skalować\nznać szczegóły operacji stojących za skalowaniem i dzieleniem danych na uczące i testowe\nMachine Learning nie istnieje bez programowania, dlatego znajdziesz tu mnóstwo zadań do mniej lub bardziej samodzielnego rozwiązania. Początkowe zadania mają na celu odświeżyć wiedzę typowo matematyczną, wprowadzić do optymalnego wykorzystania biblioteki numpy, a kolejne pozwolą poeksperymentować na własną rękę z problemami, jakie stawiamy algorytmom Machine Learning.\nPodsumowując. Jeśli masz podstawową wiedzę z programowania, jeśli nie przeraża cię odrobina matematyki i jeśli jesteś ciekawy o co chodzi z tym machine learning i sztuczną inteligencją, jeśli chcesz wystartować od zera w tym temacie, to ten kurs powinien ci to umożliwić.\nObejrzyj lekcje próbne i pamiętając, że z zakupu można wycofać się bez konsekwencji w ciągu 30 dni zacznij swoje bliskie spotkanie ze sztuczną inteligencją – w Twoim ojczystym języku\nDo zobaczenia na kursie!",
      "target_audience": [
        "Programiści planujący poznanie machine learning",
        "Analitycy danych poszerzający kompetencje do uczenia maszynowego",
        "Studenci kierunku IT poznający machine learning",
        "Osoby techniczne zainteresowane sztuczną inteligencją"
      ]
    },
    {
      "title": "AIで小説を執筆しよう！【GPT-2】 -人工知能による日本語テキストの自動生成、AIと人間の共同執筆-",
      "url": "https://www.udemy.com/course/ai-novel/",
      "bio": "ディープラーニング（深層学習）による文章の自動生成について学ぶコースです。GPT-2を使って、テキスト自動生成のコードを実装しましょう。Google Colaboratory環境で、PythonによりAI自動執筆のコードを記述します。",
      "objectives": [
        "「PyTorch」、「GPT-2」を使ったテキストの自動生成について学びます。",
        "AIによるテキスト生成の基礎的な知識を学びます。",
        "AIを使った小説の執筆方法について学びます。",
        "PythonのコードでGPT-2を扱えるようになります。",
        "「GPT-2」の仕組み、各設定について学びます。",
        "Aによるテキスト生成が持つ可能性について学びます。"
      ],
      "course_content": {},
      "requirements": [
        "Google Colaboratoryを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "機械学習やデータサイエンス、深層学習について詳しい解説はありません。",
        "中学-高校レベルの数学で十分です。高度な数学は必要ありません。"
      ],
      "description": "「AIで小説を執筆しよう！」は、AIによる文章の生成について学ぶ講座です。\n「GPT-2」というAIのモデルを使用し、日本語で原稿を自動執筆します。\n\n\n本講座では、Google Colaboratory環境で、PyTorch、GPT-2を使ってテキスト自動生成のコードを実装します。\nGPT-2は2019年2月にOpenAIが発表 した、 Transformerをベースとしたテキスト生成モデルです。\n最初にGoogle Colaboratoryの使い方、PyTorchの基礎を学んだ上で、シンプルなAIテキスト生成を実装します。\nさらに、出力テキストの作風をファインチューニングにより調整する方法を学んだ上で、最後にAI執筆のテクニックを学びます。\n\n\nAIによるテキスト生成は、小説の執筆だけではなくコピーライティング、ブログ記事の生成など様々な分野で応用が可能です。\nPythonのコードを書きながら、AIによるテキスト生成を楽しく学んでいきましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! 人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. AIテキスト生成の概要\n→ AIテキスト生成の概要、および開発環境について学びます。\nSection2. シンプルなAIテキスト生成\n→ GPT-2を使い、シンプルな方法でテキストを生成します。\nSection3. ファインチューニングの活用\n→ 手元のデータを使って、モデルに追加の訓練を行う方法を学びます。\nSection4. AI執筆のテクニック\n→ AIで執筆を行うために有用なテクニックを紹介します。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "Pythonのコードを書いてテキストの自動生成を実装したい方。",
        "AIを使って小説を執筆したい方。",
        "AIと人間の協業による、小説の執筆に興味のある方。",
        "参考になる文章をAIで生成したい、文筆業の方。",
        "趣味としての「AI執筆」を始めたい方。",
        "AIをテキスト生成に応用したいエンジニアの方。",
        "学んだAI技術を何かに応用したい方。"
      ]
    },
    {
      "title": "Estatística para Data Science e Análise de Negócios",
      "url": "https://www.udemy.com/course/estatistica-para-data-science-e-analise-de-negocios/",
      "bio": "Você precisa de Estatística no escritório: Estatística Descritiva e Inferencial, Testes de Hipóteses",
      "objectives": [
        "Entender os fundamentos de estatística",
        "Aprender como trabalhar com diferentes tipos de dados",
        "Como plotar diferentes tipos de dados",
        "Calcular as medidas de tendência central, assimetria e variabilidade",
        "Calcular correlação e covariância",
        "Distinguir e trabalhar com diferentes tipos de distribuições",
        "Estimar intervalos de confiança",
        "Realizar testes de hipótese",
        "Tomar decisões baseadas em dados",
        "Entender a mecânica das análises de regressão"
      ],
      "course_content": {
        "Introdução": [
          "O que veremos no curso?"
        ],
        "Dados de amostra ou população?": [
          "Entendendo a diferença entre uma população e amostra",
          "Entendendo a diferença entre uma população e amostra"
        ],
        "Os fundamentos da estatística descritiva": [
          "Os vários tipos de dados que podemos trabalhar",
          "Os vários tipos de dados que podemos trabalhar",
          "Níveis de mensuração",
          "Níveis de mensuração",
          "Variáveis categóricas: Técnicas de visualização para variáveis categóricas",
          "Variáveis categóricas: Técnicas de visualização para variáveis categóricas",
          "Variáveis categóricas: Técnicas de visualização. Exercício",
          "Variáveis numéricas. Usando a tabela de distribuição de frequência",
          "Variáveis numéricas. Usando a tabela de distribuição de frequência",
          "Variáveis numéricas. Usando a tabela de distribuição de frequência. Exercício",
          "Histogramas",
          "Histogramas",
          "Histogramas. Exercício",
          "Tabelas pivô e Gráficos de Dispersão",
          "Tabelas pivô e Gráficos de Dispersão",
          "Tabelas pivô e Gráficos de Dispersão. Exercício"
        ],
        "Medidas de tendência central, assimetria, e variabilidade": [
          "As principais medidades de tendência central: média, mediana e moda",
          "Média, mediana e moda. Exercícios",
          "Calculando assimetria",
          "Calculando assimetria",
          "Assimetria. Exercício",
          "Calculando como os dados se espalham: calculando variância",
          "Variância. Exercício",
          "Desvio padrão e coeficiente de variação",
          "Desvio padrão e coeficiente de variação",
          "Desvio padrão e coeficiente de variação. Exercício",
          "Calculando e entendendo covariância",
          "Calculando e entendendo covariância",
          "Covariância. Exercício",
          "O coeficiente de correlação",
          "O coeficiente de correlação",
          "Coeficiente de correlação. Exercício"
        ],
        "Exemplo prático: Estatística descritiva": [
          "Exemplo prático",
          "Exemplo prático: Estatística descritiva. Exercício"
        ],
        "Distribuições": [
          "Introdução a estatística inferencial",
          "O que é uma distribuição?",
          "O que é uma distribuição?",
          "A distribuição Normal",
          "A distribuição Normal",
          "A distribuição normal padronizada",
          "Distribuição normal padronizada. Exercício",
          "Entendendo o teorema do limite central",
          "Entendendo o teorema do limite central",
          "Erro padrão",
          "Erro padrão"
        ],
        "Estimadores e estimativas": [
          "Trabalhando com estimadores e estimativas",
          "Trabalhando com estimadores e estimativas",
          "Intervalos de confiança - uma ferramenta indispensável para tomada de decisão",
          "Intervalos de confiança - uma ferramenta indispensável para tomada de decisão",
          "Calculando o intervalo de confiança com variância populacional conhecida",
          "Intervalos de confiança. Variância populacional conhecida. Exercício",
          "Esclarecimentos sobre intervalos de confiança",
          "Distribuição T de Student",
          "Distribuição T de Student",
          "Calculando o intervalo de confiança com variância populacional desconhecida",
          "Variância populacional desconhecida. Escore-T. Exercício",
          "O que é margem de erro e porque é importante para Estatística?",
          "O que é margem de erro e porque é importante para Estatística?"
        ],
        "Intervalos de confiança: tópicos avançados": [
          "Calculando intervalos de confiança para duas médias com amostras dependentes",
          "Intervalos de confiança. Duas médias. Amostras dependentes. Exercício",
          "Calculando intervalos de confiança para duas médias independentes (parte 1)",
          "Intervalos de confiança. Duas médias. Amostras independentes (Parte 1). Tarefa",
          "Calculando intervalos de confiança para duas médias independentes (parte 2)",
          "Intervalos de confiança. Duas médias. Amostras independentes (Parte 2). Tarefa",
          "Calculando intervalos de confiança para duas médias independentes (parte 3)"
        ],
        "Exemplo prático: Estatística Inferencial": [
          "Exemplo prático: Estatística Inferencial",
          "Exemplo prático: Estatística Inferencial. Tarefa"
        ],
        "Testes de hipóteses: Introdução": [
          "As hipóteses nula e alternativa",
          "As hipóteses nula e alternativa",
          "Estabelecendo uma região de rejeição e um nível de significância",
          "Estabelecendo uma região de rejeição e um nível de significância",
          "Erro tipo I vs Erro tipo II",
          "Erro tipo I vs Erro tipo II"
        ]
      },
      "requirements": [
        "Absolutamente nenhuma experiência é necessária. Vamos começar do básico e gradualmente aumentaremos o nível de conhecimento. Tudo está aqui no curso.",
        "Uma vontade de aprender e praticar"
      ],
      "description": "A estatística é uma habilidade necessária onde você deseja atuar? Você quer trabalhar como Analista de Marketing, Analista de Estratégia Empresarial, Analista de Dados, ou Cientista de Dados?\nBem, então você veio para o lugar certo!\nEstatística para Data Science e Análise Empresarial está aqui para você com TEMPLATES do Excel inclusos!\nÉ aqui que tudo começa. E esse é o começo perfeito!\nRapidamente, você irá adquirir habilidades fundamentais para entender análises estatísticas complicadas que são diretamente aplicadas em situações reais. Criamos um curso que é:\n· Fácil de endender\n· Compreensivo\n· Prático\n· Direto ao ponto\n· Com diversos exercícios e recursos\n· Baseado em dados\n· Introduz a linguagem científica de estatística\n· Ensina sobre a visualização de dados\n· Mostra os pilares mais importantes em pesquisa quantitativas\nNão é segredo que muitos desses tópicos já foram explicados online. Milhares de vezes. Entretanto, é quase impossível encontrar um programa estruturado que nos ensina o porquê de certos testes estatísticos estarem sendo usados tão frequentemente. Pacotes modernos de softwares e linguagens de programação estão deixando a maioria dessas atividades automáticas, mas, nesse curso você terá algo mais valioso - habilidades de pensamento crítico. Computadores e linguagens de programação são como navios no oceano, são elegantes e o leva até o destino desejado, mas depende de você, um aspirante a cientista de dados ou analista de EE, que vai guiar e navegar para a direção certa.\nEnsinar é a nossa paixão\nTrabalhamos duro por mais de quatro meses para criar o melhor curso possível de Estatística que poderíamos entregar a você. Queremos que você tenha sucesso, e é por isso que o curso tenta ser o mais engajador possível. Animações de alta qualidade, materiais de curso incríveis, perguntas no formato de quiz, comunicados e notas de curso, assim como um glossário com todos os novos termos que você irá aprender, tudo isso é apenas uma parte de tudo que obterá ao se inscrever.\nO que torna esse curso diferente de todos os outros cursos de Estatística por aí?\n· Produção de alta qualidade - Vídeos e animações em HD (Não é uma coleção de aulas super chatas!)\n· Instrutor com conhecimento (Um matemático e estatístico que trabalha a nível internacional)\n· Treinamento completo - iremos cobrir os tópicos mais importantes de estatística e habilidades que você precisar saber para se tornar analista de marketing, analista de estratégia empresarial, analista de dados, ou cientista de dados\n· Diversos Estudos de Caso que irão ajudar a reforçar tudo que você aprendeu\n· Suporte excelente - se você não entender um conceito ou se apenas quiser conversar, você receberá uma resposta dentro de 1 dia útil\n· Dinâmico - Não queremos tomar seu tempo! O instrutor trabalho em um ótimo ritmo durante todo o curso\nPorque preciso dessas habilidades?\nSalário/Renda - as carreiras no campo de data science são as mais populares no mundo de grandes empresas de hoje. E, dado que a maioria dos negócios estão começando a perceber as vantagens de se trabalhar com dados ao seu dispor, essa tendência só tenderá a crescer\nPromoções - Se você entender bem Estatística, você terá suporte nas ideias de seu negócio com evidências quantitativas, sendo esse um bom plano de carreira\nAssegurar o Futuro - como dissemos, a demanda por pessoas que entendem números e dados, e podem interpretá-los, está crescendo exponencialmente; você já deve ter escutado sobre a quantidade de trabalhos que serão automatizados, não escutou? Bem, carreiras em data science são as que farão a automação, não as que serão automatizadas.\nCrescimento - esse não é um trabalho chato. Todos os dias, você irá enfrentar diferentes desafios que irão testar suas habilidades existentes e precisam que você aprenda algo novo.\nPor favor, tenha em mente que o curso vem com a garantia incondicional de 30 dias da Udemy. E por que não dar essa garantia? Temos certeza de que este curso permitirá agregar muito valor para você.\nVamos juntos começar a aprender agora!",
      "target_audience": [
        "Pessoas que querem uma carreira em Data Science",
        "Pessoas que querem uma carreira em Estratégia Empresarial",
        "Analistas de negócios",
        "Executivos de negócios",
        "Pessoas que tem paixão por números e análises quantitativas",
        "Qualquer um que queira aprender as sutilezas de Estatística e como a usar no mundo dos negócios",
        "Pessoas que querem começar a aprender estatística",
        "Pessoas que querem aprender os fundamentos da estatística"
      ]
    },
    {
      "title": "Domine Apache Airflow: Pipelines de Engenharia de Dados",
      "url": "https://www.udemy.com/course/domine-apache-airflow/",
      "bio": "Aprenda com aulas práticas uma das principais ferramentas da engenharia de dados moderna!",
      "objectives": [
        "Entender a Arquitetura do Airflow",
        "Configurar Dags com Operadores, Gatilhos e Branchs",
        "Criar Pools, Datasets e Sensors",
        "Extrair e Tratar Dados com Airflow",
        "Criar Diversos Tipos de Operadores, como Python, TriggerDag e Outros",
        "Realizar Operações em Banco de Dados",
        "Utilizar Hooks do Airflow",
        "Configurar o Airflow",
        "Operar o Airflow pela CLI"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Apresentação: O que Vamos Estudar?",
          "O que é Apache Airflow",
          "Como Airflow Funciona",
          "Material do Curso"
        ],
        "Preparação do Ambiente": [
          "Sobre o Ambiente",
          "Docker Airflow"
        ],
        "Conhecendo o Airflow": [
          "Conhecendo a UI",
          "Grid, Graph e Calendar",
          "Outros Modos"
        ],
        "Criando Dags": [
          "A Estrutura de uma Dag",
          "Configurações desta Seção: Melhore o Airflow",
          "Primeira Dag",
          "Primeira Dag na Prática",
          "Segunda Dag: Paralelismo",
          "Terceira Dag: Precedência",
          "Quarta Dag",
          "Principais Operadores",
          "Regras de Gatilho",
          "Exemplo de Trigger",
          "Segundo Exemplo de Trigger",
          "Terceiro Exemplo de Trigger",
          "Dags Complexas",
          "Criando Dags Complexas",
          "Agrupando com TaskGroup",
          "Criando uma Dag com TaskGroup",
          "Dag que Executa Dag",
          "Dag que executa Dag na Prática",
          "Principais Argumentos de uma DAG",
          "Criando Dag com Dicionário",
          "Fundamentos de XCom",
          "Utilizando XCom",
          "Envio de Email",
          "Configurando o Gmail",
          "Configurando o Airflow",
          "Atividade com Email",
          "Criando Dag que Envia Emails"
        ],
        "Mais Fundamentos: Dags Avançadas": [
          "Tasks Dummy",
          "Criando Dags com Task Dummy",
          "Entendendo Variáveis",
          "Utilizando Variáveis em Dags",
          "Fundamentos de Pools",
          "Testando Pools em Dags",
          "Branchs: Decisões em Dags",
          "Criando uma Dag com Branch",
          "Mais sobre PythonOperator",
          "Preparando o Ambiente",
          "Limpeza de Dados com PythonOperator",
          "Conhecendo Datasets",
          "Dag Consumindo Datasets",
          "Fundamentos de Sensors",
          "Atualização sobre API",
          "Criando um Sensor para uma API"
        ],
        "Providers, Hooks e Banco de Dados": [
          "Providers",
          "Operando em Banco de Dados",
          "Hooks",
          "Hooks com Banco de Dados"
        ],
        "Conhecendo a CLI": [
          "Interagindo com Dags pela CLI",
          "CLI para Tasks e Configurações"
        ],
        "Executer e Configurações": [
          "Configuraçoes",
          "Executers"
        ],
        "Criando Plugins": [
          "Sobre Plugins",
          "Criando seu Plugin",
          "Testando seu Plugin com uma DAG"
        ],
        "Projeto Final": [
          "Apresentação",
          "Pré-Requisitos",
          "Criando a DAG",
          "Definindo as Tasks",
          "Finalizando e Executando"
        ]
      },
      "requirements": [
        "Conhecer Fundamentos de Python"
      ],
      "description": "Bem vindo ao nosso moderno curso de Airflow!\nO Airflow é uma plataforma  que permite o gerenciamento, a programação e a monitoração de fluxos de trabalho de processamento de dados (pipelines), usado por empresas como Netflix, Airbnb, Paypal, Twitter e outras.\nAtravés de uma abordagem baseada em Directed Acyclic Graphs (DAGs), o Airflow facilita a definição de tarefas e suas dependências, permitindo a execução paralela e sequencial das etapas do processo.\nO Airflow pode ser utilizado para automatizar e orquestrar uma ampla gama de fluxos de trabalho de processamento de dados. Um exemplo é a extração, transformação e carga (ETL) de dados de uma API para um banco de dados.\nNeste curso você vai aprender de forma prática como criar seus próprios Pipelines de Dados utlizando esta ferramenta incrível e moderna. Entre outras coisas você vai:\n\nConhecer a Arquitetura do Airflow\nAprender Fundamentos de Dags e Tasks\nConstruir suas Próprias Dags\nImplementar Dags com Operadores com PythonOperator, PostgresOperator entre muitos outros\nEntender e aplicar conceitos como Pools, Variáveis, branchs e Dataset\nCriar Sensores em Airflow\nConhecer e Implementar regras de Triggers\nTrocar dados utilizando XCom\nEnviar emails em caso de Falhas ou mesmo em uma Task\nEntender e Criar Hooks\nCompreender as principais configurações do Airflow\nEstudar os tipos de Executers e seus características\nConectar e atualizar bancos de dados\nO curso ainda inclui acesso a todos os códigos e slides utlizados.\nBons estudos!",
      "target_audience": [
        "Engenheiro e Cientistas de Dados",
        "Interessados em Aprender Airflow"
      ]
    },
    {
      "title": "Data Science in Python: From Preprocessing to Forecasting",
      "url": "https://www.udemy.com/course/sales-forecasting-using-time-series-analysis-in-python/",
      "bio": "From preprocessing intricacies to advanced forecasting techniques. Equip yourself with the skills to navigate the data",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic knowledge in statistics, mathematics, programming"
      ],
      "description": "Welcome to the dynamic realm of \"Data Science in Python: From Preprocessing to Forecasting.\" This comprehensive course is designed to immerse you in the multifaceted world of data science, offering a step-by-step journey from the foundational principles of data preprocessing to the advanced techniques of forecasting using the Prophet library. Whether you're a novice aspiring to delve into the intricacies of data analysis or an experienced professional seeking to refine your skills, this course caters to a broad spectrum of learners.\nEmbark on a learning adventure where theoretical knowledge seamlessly merges with practical applications. Uncover the nuances of data preprocessing, navigate the complexities of feature engineering, and harness the power of graph visualization components. Transition into the practical aspects of model training, validation, and forecasting, culminating in the utilization of the Prophet library for creating and evaluating predictive models.\nThroughout this course, you'll engage in hands-on activities, real-world case studies, and comprehensive exercises, ensuring a holistic understanding of each concept. The curriculum is crafted to empower you with the skills and insights required to tackle diverse data science challenges, from enhancing data quality to making accurate predictions about future trends.\nJoin us on this transformative learning journey, where you'll not only grasp the theoretical underpinnings of data science but also gain the practical expertise needed to excel in the field. Whether you aim to propel your career forward or simply satisfy your curiosity about the fascinating world of data, this course is your gateway to mastering the intricacies of data science. Let's embark on this educational odyssey together!\nIntroduction:\nThis opening section serves as a course prelude, introducing learners to the overarching project's goals and context. It provides clarity on the themes and outcomes expected throughout the course, setting the tone for a comprehensive exploration of the subject matter.\nData Preprocessing:\nIn this foundational section, learners dive into the intricacies of data preprocessing. The emphasis is on mastering techniques to clean, format, and organize raw data effectively. From basic data cleaning to advanced preprocessing methods, learners gain a solid understanding of the crucial steps preceding data analysis.\nData Preprocessing and Feature Engineering:\nBuilding upon the fundamentals of data preprocessing, this section introduces the concept of feature engineering. Learners explore how to enhance model performance by strategically creating new features. Practical insights into various methods and considerations help learners make informed decisions during the feature engineering process.\nGraph Visualization - Components:\nTransitioning into visualization, this section explores the components of graph visualization. Learners gain insights into the significance of these components in representing and interpreting data graphically. Advanced features and customization options are covered, empowering learners to create compelling visualizations.\nTraining Model:\nThis section marks a shift towards the practical aspects of model training. It covers modeling and evaluation, guiding learners through the fundamentals of creating models and assessing their performance against various metrics. The focus is on building a strong foundation for subsequent sections.\nValidation and Forecasting:\nFocusing on model validation techniques and forecasting methods, this section equips learners with the skills to validate models effectively. It explores forecasting as a means to predict future trends based on historical data, laying the groundwork for subsequent forecasting-related sections.\nProducing and Visualizing Forecasts:\nBuilding upon forecasting, this section emphasizes the application of forecasting models to produce and visualize predictions. Learners explore visualization techniques that enhance the interpretability of forecasts, aiding effective communication of insights to diverse audiences.\nComparing Models:\nThis section guides learners in the critical task of model comparison. Strategies for evaluating and selecting the most effective model for specific use cases are explored. Comparative analysis adds a layer of sophistication to the model selection process, ensuring informed decision-making.\nInstallation of Library Prophet:\nA practical hands-on section, it guides learners through the installation of the Prophet library. This step is crucial for the subsequent sections where learners will utilize Prophet for creating predictive models in the context of time-series forecasting.\nCreating a Model using Prophet:\nContinuing from the installation, this section immerses learners in the practical process of creating models using the Prophet library. Hands-on exercises allow learners to apply theoretical knowledge, refining their skills in time-series forecasting using this powerful tool.\nEvaluation of Model of Prophet Library:\nThe final section focuses on the evaluation of models created using the Prophet library. Learners gain insights into assessing model performance, ensuring accuracy, and validating the effectiveness of their time-series forecasting predictions.",
      "target_audience": [
        "Beginners and Novices: Individuals with little to no prior experience in data science or Python programming. Those looking to explore the field of data science and gain foundational knowledge. Students or recent graduates seeking to enter the data science job market.",
        "Intermediate Data Analysts and Scientists: Professionals already working in data-related roles who want to strengthen their skills in Python. Analysts looking to enhance their data preprocessing and feature engineering techniques. Those interested in expanding their knowledge to include time-series forecasting.",
        "Experienced Professionals: Data scientists, analysts, or researchers with experience in other programming languages. Professionals aiming to transition to Python for data science tasks. Individuals seeking to refine their expertise in advanced data science concepts.",
        "Business and Decision Makers: Managers, executives, and decision-makers who want a comprehensive understanding of data science. Professionals who need to interpret and communicate insights derived from data to support strategic decision-making.",
        "Continuous Learners: Individuals committed to continuous learning and staying updated on the latest trends in data science. Lifelong learners interested in expanding their skill set and staying competitive in the job market.",
        "Entrepreneurs and Startups: Business owners, entrepreneurs, or startup founders looking to leverage data for business insights. Individuals seeking to understand how data science can be applied to their specific industry or business."
      ]
    },
    {
      "title": "Corso completo di Data Science e machine learning con Python",
      "url": "https://www.udemy.com/course/data-science-con-python/",
      "bio": "Da principiante a esperto nelle tecniche di Data Science con Python: machine learning, network neurali, text mining e...",
      "objectives": [
        "Ripasso delle basi di Python e delle sue strutture dati",
        "Ambienti di programmazione per il Data Science",
        "Importazione di dataset in Python",
        "Creazione grafici ed esplorazione dataset",
        "Manipolazione e gestione dataset",
        "Preprocessing e pulizia dei dati per l'analisi",
        "Teoria e algoritmi di machine learning, metodi supervisionati e non supervisionati",
        "Teoria e algoritmi di machine learning",
        "Valutazione e validazione di modelli",
        "Pulizia e analisi testi",
        "Metodi per la Sentiment Analysis"
      ],
      "course_content": {},
      "requirements": [
        "Conoscenza base di Python"
      ],
      "description": "Questo corso sul Data Science con Python nasce per essere un percorso completo su come si è evoluta l'analisi dati negli ultimi anni a partire dall'algebra e dalla statistica classiche. L'obiettivo è accompagnare uno studente che ha qualche base di Python in un percorso attraverso le varie anime del Data Science.\nCominceremo con un ripasso delle basi di Python, a partire dallo scaricamento e installazione, all'impostazione dell'ambiente di lavoro, passando per le strutture, la creazione di funzioni, l'uso degli operatori e di alcune funzioni importanti.\nPasseremo poi a vedere come manipolare e gestire un dataset, estrarne dei casi oppure delle variabili, generare dei dataset casuali, calcolare delle misure statistiche di base, creare grafici con i pacchetti Matplotlib e Seaborn.\nNelle sezioni successive cominciamo a entrare nel cuore del Data Science con Python, a cominciare dal preprocessing: vediamo infatti come ripulire e normalizzare un dataset, e come gestire i dati mancanti.\nLa sezione successiva ci permette di cominciare a impostare dei modelli di machine learning con Python: vedremo tutti gli algoritmi più comuni, sia supervisionati che non supervisionati, come la regressione, semplice, multipla e logistica, il k-nearest neighbors, il Support Vector Machines, il Naive Bayes, gli alberi di decisione e il clustering.\nPasseremo poi ai più comuni metodi ensemble, come il Random Forest, il Bagging e il Boosting, e all'analisi del linguaggio naturale e al suo utilizzo nel machine learning per la catalogazione dei testi.",
      "target_audience": [
        "Chi conosce già un po' di programmazione Python e vuole cominciare un percorso nel data science",
        "Chi cerca un percorso completo per farsi un'idea delle tante anime del Data Science con Python"
      ]
    },
    {
      "title": "Machine Learning de A a la Z: R y Python para Data Science",
      "url": "https://www.udemy.com/course/machinelearning-es/",
      "bio": "Aprende a crear algoritmos de Machine Learning en Python y R con expertos en Data Science. Con código fuente incluido!",
      "objectives": [
        "Dominar el Machine Learning con R y con Python.",
        "Tener intuición en la mayoría de modelos de Machine Learning.",
        "Hacer predicciones precisas y acertadas.",
        "Crear unos análisis elaborados.",
        "Crear modelos de Machine Learning robustos y consistentes.",
        "Crear valor añadido a tu propio negocio.",
        "Utilizar el Machine Learning para cuestiones personales.",
        "Dominar aspectos específicos como por ejemplo Reinforcement Learning, NLP o Deep Learning",
        "Conocer las técnicas más avanzadas como la reducción de la dimensionalidad.",
        "Saber qué modelo de Machine Learning usar para cada tipo de problema.",
        "Crear toda una librería de modelos de Machine Learning y saber cómo combinarlos para resolver cualquier problema.",
        "Incluye el libro oficial de preguntas típicas de machine learning, creado a partir de las dudas de estudiantes con ejemplos y respuestas a tus posibles dudas."
      ],
      "course_content": {
        "Bienvenidos al curso de Machine Learning": [
          "Aplicaciones del Machine Learning",
          "BONUS: Rutas de aprendizaje",
          "BONUS 2: Diferencias entre ML, DL e IA",
          "¿Por qué el Machine Learning es el futuro?",
          "Algunas notas, trucos y ayudas para seguir el curso",
          "Este libro puede ser de gran utilidad",
          "Acerca de las valoraciones en Udemy",
          "Cómo hacer preguntas y usar Udemy correctamente",
          "Cómo instalar Python y Anaconda (Mac, Windows y Linux)",
          "Actualización: versión recomendada de Anaconda",
          "Cómo instalar R y RStudio (Mac, Windows y Linux)",
          "Instala la versión 3.6.3 de R",
          "Cómo acceder a los materiales del curso en Github",
          "NOTA ADICIONAL: Materiales actualizados en Google Colab",
          "BONUS: conoce a los creadores originales del curso",
          "BONUS: Conoce a Juan Gabriel Gomila, tu instructor en español",
          "Comunidades de Discord para aprender juntos online",
          "Pre requisito para disfrutar mejor del curso",
          "Algunos cambios en las nuevas versiones de Spyder"
        ],
        "-------------------- Parte 1: Pre Procesado de Datos --------------------": [
          "Bienvenido a la Parte 1 - Pre Procesado de Datos",
          "Obtén el conjunto de datos",
          "Cómo importar librerías",
          "Cómo importar data sets",
          "Truco: problemas con el auto completar de spyder",
          "Resumen de Python: programación orientada a objetos - clases y objetos",
          "Datos faltantes o desconocidos",
          "IMPORTANTE: Cambios en Python 3.7",
          "Datos categóricos",
          "Cómo dividir el data set en entrenamiento y test",
          "Cómo escalar los datos",
          "Y aquí va nuestra plantilla de pre procesado de datos",
          "Pre procesamiento de datos"
        ],
        "-------------------- Parte 2: Regresión --------------------": [
          "Bienvenido a la Parte 2: Regresión"
        ],
        "Regresión Lineal Simple": [
          "Obtén el conjunto de datos",
          "Dataset y Descripción del problema de la sección",
          "Idea de la Regresión Lineal Simple - Paso 1",
          "Idea de la Regresión Lineal Simple - Paso 2",
          "Regresión Lineal Simple en Python - Paso 1",
          "Regresión Lineal Simple en Python - Paso 2",
          "Regresión Lineal Simple en Python - Paso 3",
          "Regresión Lineal Simple en Python - Paso 4",
          "Regresión Lineal Simple en R - Paso 1",
          "Regresión Lineal Simple en R - Paso 2",
          "Regresión Lineal Simple en R - Paso 3",
          "Regresión Lineal Simple en R - Paso 4",
          "Regresión Lineal Simple"
        ],
        "Regresión Lineal Múltiple": [
          "Obtén el conjunto de datos",
          "Dataset y Descripción del problema de la sección",
          "Idea de la Regresión Lineal Múltiple - Paso 1",
          "Idea de la Regresión Lineal Múltiple - Paso 2",
          "Idea de la Regresión Lineal Múltiple - Paso 3",
          "Idea de la Regresión Lineal Múltiple - Paso 4",
          "Pre requisito: ¿Qué es el p-valor?",
          "Idea de la Regresión Lineal Múltiple - Paso 5",
          "La función OLS en las nuevas versiones de Python",
          "Regresión Lineal Múltiple en Python - Paso 1",
          "Regresión Lineal Múltiple en Python - Paso 2",
          "Regresión Lineal Múltiple en Python - Paso 3",
          "Regresión Lineal Múltiple en Python - Eliminación hacia atrás - Preparativos",
          "Regresión Lineal Múltiple en Python - Eliminación hacia atrás - EJERCICIO!",
          "Regresión Lineal Múltiple en Python - Eliminación hacia atrás - Solución",
          "Regresión Lineal Múltiple en Python - Eliminación hacia atrás automática",
          "Regresión Lineal Múltiple en R - Paso 1",
          "Regresión Lineal Múltiple en R - Paso 2",
          "Regresión Lineal Múltiple en R - Paso 3",
          "Regresión Lineal Múltiple en R - Eliminación hacia atrás - EJERCICIO",
          "Instalar la nueva versión de ElemStatsLearn",
          "Regresión Lineal Múltiple en R - Eliminación hacia atrás - Solución",
          "Regresión Lineal Múltiple en R - Eliminación hacia atrás automática",
          "Regresión Lineal Múltiple"
        ],
        "Regresión Polinómica": [
          "Idea de la Regresión Polinómica",
          "Obtención del conjunto de datos",
          "Regresión Polinómica en Python - Paso 1",
          "Regresión Polinómica en Python - Paso 2",
          "Regresión Polinómica en Python - Paso 3",
          "Cambio de sintaxis para la predicción polinómica en Python 3.7",
          "Regresión Polinómica en Python - Paso 4",
          "Plantilla de Regresión Polinómica en Python",
          "Regresión Polinómica en R - Paso 1",
          "Regresión Polinómica en R - Paso 2",
          "Regresión Polinómica en R - Paso 3",
          "Regresión Polinómica en R - Paso 4",
          "Plantilla de Regresión Polinómica en R"
        ],
        "Regresión con Máquinas de Soporte Vectorial (SVR)": [
          "Idea de la SVR",
          "Obtén el conjunto de datos",
          "SVR en Python",
          "SVR en R"
        ],
        "Regresión con Árboles de Decisión": [
          "Idea de la Regresión con Árboles de Decisión",
          "Obtén el conjunto de datos",
          "Regresión con Árboles de Decisión en Python",
          "Regresión con Árboles de Decisión en R"
        ],
        "Regresión con Bosques Aleatorios": [
          "Idea de la Regresión con Bosques Aleatorios",
          "Obtén el conjunto de datos",
          "Regresión con Bosques Aleatorios en Python",
          "Regresión con Bosques Aleatorios en R"
        ],
        "Evaluar el Rendimiento en Modelos de Regresión": [
          "Idea del factor R Cuadrado",
          "Idea del factor R Cuadrado Ajustado",
          "Evaluar el Rendimiento en Modelos de Regresión - Ejercicio final",
          "Interpretar los Coeficientes de la Regresión Lineal",
          "Fin de la Parte 2 - Regresión"
        ]
      },
      "requirements": [
        "Con el nivel de matemáticas de secundaria y bachillerato es suficiente.",
        "Es muy recomendable haber tomado el curso de Python de la A a la Z y el de Estadística descriptiva con R y Python de Juan Gabriel Gomila"
      ],
      "description": "Apúntate a nuestro Curso de Machine Learning de la A a la Z. R y Python para Data Science.\n¿Estás interesado en conocer a fondo el mundo del Machine Learning? Entonces este curso está diseñado especialmente para ti!!\nEste curso ha sido diseñado por Data Scientists profesionales para compartir nuestro conocimiento y ayudarte a aprender la teoría compleja, los algoritmos y librerías de programación de un modo fácil y sencillo.\nEn él te guiaremos paso a paso en el mundo del Machine Learning. Con cada clase desarrollarás nuevas habilidades y mejorarás tus conocimientos de este complicado y lucrativa sub rama del Data Science.\nEste curso es divertido y ameno pero al mismo tiempo todo un reto pues tenemos mucho de Machine Learning por aprender. Lo hemos estructurado del siguiente modo:\nPartes del curso\n1ª Parte – Preprocesamiento de datos\n2ª Parte – Regresión: Regresión Lineal Simple, Regresión Lineal Múltiple, Regresión Polinomial, SVR, Regresión en Árboles de Decisión y Regresión con Bosques Aleatorios\n3ª Parte – Clasificación: Regresión Logística, K-NN, SVM, Kernel SVM, Naive Bayes, Clasificación con Árboles de Decisión y Clasificación con Bosques Aleatorios\n4ª Parte – Clustering: K-Means,  Clustering Jerárquico\n5ª Parte – Aprendizaje por Reglas de Asociación: Apriori, Eclat\n6ª Parte – Reinforcement Learning: Límite de Confianza Superior, Muestreo Thompson\n7ª Parte – Procesamiento Natural del Lenguaje: Modelo de Bag-of-words  y algoritmos de NLP\n8ª Parte – Deep Learning: Redes Neuronales Artificiales y Redes Neuronales Convolucionales\n9ª Parte – Reducción de la dimensión: ACP, LDA, Kernel ACP\n10ª Parte – Selección de Modelos & Boosting: k-fold Cross Validation, Ajuste de Parámetros, Grid Search, XGBoost\nAdemás, el curso está relleno de ejercicios prácticos basados en ejemplos de la vida real, de modo que no solo aprenderás teoría, si no también pondrás en práctica tus propios modelos con ejemplos guiados.\nY como bonus, este curso incluye todo el código en Python y R para que lo descargues y uses en tus propios proyectos.\nAdemás, con el curso obtendrás el libro oficial de preguntas típicas de machine learning, creado a partir de las dudas de los estudiantes con más ejemplos y respuestas a tus posibles dudas.",
      "target_audience": [
        "Cualquier estudiante que esté interesado en el Machine Learning.",
        "Estudiantes con nivel de matemáticas de bachillerato que quieren iniciarse en Machine Learning.",
        "Estudiantes de nivel intermedio con conocimientos básicos de Machine Learning, incluyendo algoritmos clásicos de regresión lineal o logística, pero que quieren aprender más y explorar los diferentes campos del Machine Learning.",
        "Estudiantes que no se sienten cómodos programando pero se interesan por el Machine Learning y quieren aplicar las técnicas al análisis de data sets.",
        "Universitarios que quieren iniciarse en el mundo del Data Science.",
        "Cualquier analista de datos que quiera mejorar sus habilidades en Machine Learning.",
        "Personas que no están satisfechas con su trabajo y quieren convertirse en Data Scientist.",
        "Cualquier persona que quiera añadir valor a su empresa con el poder del Machine Learning."
      ]
    },
    {
      "title": "ChatGPT | Business. Marketing. Privat. (inkl. 1.000 Prompts)",
      "url": "https://www.udemy.com/course/chatgpt-business-marketing-privat-prompts/",
      "bio": "ChatGPT für Anfänger, Beginner und Fortgeschrittene | ChatGPT Tutorial inkl. Workbook mit ca. 1.000 Copy&Paste-Prompts",
      "objectives": [
        "Hol das Beste aus Chat GPT heraus und lerne in unserem Kurs, wie du dein Unternehmen auf das nächste Level bringst und deine Umsätze erhöhst!",
        "Verwende Chat GPT, um Routineaufgaben zu automatisieren und mehr Zeit für wichtige Projekte zu haben - deine Produktivität wird es dir danken!",
        "Erleichtere dir das Leben mit Chat GPT - automatisierte Antworten auf Kundenanfragen sparen dir Zeit und Aufwand!",
        "Steigere die Kundenzufriedenheit und -loyalität mit personalisierten und präzisen Antworten dank Chat GPT.",
        "Verdiene passives Einkommen mit ChatGPT. Wir zeigen dir Tipps, wie du erfolgreich mit ChatGPT Geld verdienen kannst.",
        "Verwende Chat GPT, um Routineaufgaben zu automatisieren und mehr Zeit für wichtige Projekte zu haben - deine Produktivität wird es dir danken!"
      ],
      "course_content": {},
      "requirements": [
        "Keine Vorkenntnisse notwendig."
      ],
      "description": "Willkommen in der faszinierenden Welt von ChatGPT! Möchtest du lernen, wie du Zeit und Aufwand sparst, indem du automatische Antworten auf Kundenanfragen erstellst? Oder wie du perfekte Antworten an deine Kunden senden kannst, um die Kundenzufriedenheit und Loyalität zu verbessern? Oder vielleicht willst du lernen, wie du mit ChatGPT Geld sparen – und Geld verdienen.\nDann starte jetzt meinen Kurs und tauche tief ein in das Thema von OpenAI und ChatGPT. Erfahre, wie du die richtigen Anweisungen (Prompts) findest und nutzt, um das Beste aus ChatGPT herauszuholen – sowohl privat als auch im Business.\nAußerdem erhältst du mein ChatGPT Workbook. Dieses enthält eine Sammlung von rund 1.000 Prompts für verschiedene Bereiche wie SEO, Social Media, Writing, Excel, Coding und Businessideen.\nDas Workbook ist eine perfekte Ergänzung zu meinem Kurs und gibt dir die Möglichkeit, direkt loszulegen und schnelle Ergebnisse zu erzielen.\nKeine mühsame Recherche,\nkeine Zeitverschwendung auf der Suche nach Ideen,\nkein Abtippen, sondern effektive und erprobte Anweisungen, die du sofort per Copy & Paste nutzen kannst.\nWenn du das volle Potenzial von ChatGPT nutzen möchtest, um dein Business zu skalieren, dann ist die Kombination aus Kurs und Workbook genau das Richtige für dich. Du wirst nicht nur Zeit sparen, sondern auch wertvolles Wissen erlangen, das dir dabei hilft, deine Ziele zu erreichen.\nIch erkläre dir die Grundlagen, von der Anmeldung bis zu den Hintergründen rund um ChatGPT, OpenAI und Künstlicher Intelligenz.\nDann gehen wir zusammen die ersten Schritte. Ich zeige dir, wie man einen Account einrichtet, was der kostenlose Account ist, was die Unterschiede zum kostenpflichtigen Account sind.\nDann lernst du ChatGPT richtig zu nutzen. Hier gebe ich dir Anwendungsbeispiele, sodass du direkt nachvollziehen kannst, was ich mache.\nAnschließend steigen wir weiter ins Thema ein und ich gebe dir konkrete Beispiele, die du für dein Business, den Marketing oder auch privat zum Schreiben von Gedichten, Songtexten, Bücher oder Aufsätze nutzen kannst.\nDabei starten wir mit einfachen Beispielen und steigern uns langsam zu komplizierteren Promptabfolgen.\nDu lernst, wie du ChatGPT für deine Marke sensibilisierst, sodass deine Ergebnisse nicht vom Fließband bekommen, sondern maßgeschneiderte Antworten sind, die für dich relevant sind.\nAußerdem wirst du Ideen kennenlernen, wie du dann ChatGPT Geld sparen und auch Geld verdienen kannst.\nOkay – ich freue mich, dich kennenzulernen.\nMelde dich jetzt an und werde zum ChatGPT-Experten!\nBis gleich im Kurs,\nMarco",
      "target_audience": [
        "Unternehmer",
        "Selbstständige und Freelancer",
        "Marketing-Fachleute",
        "Entwickler",
        "Alle, die mit ChatGPT ihr Business skalieren wollen.",
        "Alle, die mit ChatGPT Geld verdienen wollen."
      ]
    },
    {
      "title": "A - Z™ Python crash course for Data Science 2021",
      "url": "https://www.udemy.com/course/ultimate-beginners-guide-to-python/",
      "bio": "Complete Python Bootcamp: From Zero to Hero in Python",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Access to a computer with an internet connection.",
        "Your enthusiasm to learn this go-to programming language!"
      ],
      "description": "Become a Python Programmer and learn one of employer's most requested skills of 2020!\n\nThis is the most comprehensive, yet straight-forward, course for the Python programming language on Udemy! Whether you have never programmed before, already know basic syntax, or want to learn about the advanced features of Python, this course is for you! In this course we will teach you Python 3.\nWith over 50 lectures and more than 6 hours of video this comprehensive course leaves no stone unturned! This course includes quizzes, tests, coding exercises and homework assignments as well as 3 major projects to create a Python project portfolio!\nLearn how to use Python for real-world tasks, such as working with PDF Files, sending emails, reading Excel files, Scraping websites for information, working with image files, and much more!\nThis course will teach you Python in a practical manner, with every lecture comes a full coding screencast and a corresponding code notebook! Learn in whatever manner is best for you!\nWe cover a wide variety of topics, including:\nIntro to coding\nIntro to Python\nInstalling Python\nInstalling Pycharm\nInstalling Jupyter Notebook\nRunning Python Code\nIntro to Variables\ninteger\nBoolean and None\nStrings\nString Indexing\nString and Character Functions\nString Formatting\nArithmetic Operators\nComparison Operators\nBitwise Operators\nIf Statement\nFor Loop\nWhile Loop\nLists\nTuples\nSets\nDictionary\nUser-Defined Functions\nLambda Function\nFile I/O\nDebugging and Error Handling\nModules\nObject Oriented Programming\nInheritance\nPolymorphism\nAdvanced Methods\nUnit Tests\nQuizzes\nand much more!\nYou will get lifetime access to over 50 lectures plus corresponding Notebooks for the lectures!\n\nYou will keep access to the Notebooks as a thank you for trying out the course! And the unique thing that why you should chose this course over others is that, is that each video tutorial contains almost all the unique tricks and info that after watching them you won't need to search for other sources to learn more. After watching videos with full of information you will take quizzes to check whether you have learned particular trick.\nSo what are you waiting for? Learn Python in a way that will advance your career and increase your knowledge, all in a fun and practical way!",
      "target_audience": [
        "Beginners who have never programmed before.",
        "Programmers switching languages to Python.",
        "Intermediate Python programmers who want to level up their skills!"
      ]
    },
    {
      "title": "Corso Python e introduzione a Data Science",
      "url": "https://www.udemy.com/course/corso-python-e-data-science/",
      "bio": "Il corso è volto a costruire le basi di Python, e introdurrà passo passo alle librerie per il Data Science quali Numpy e Pandas",
      "objectives": [
        "Comandi base di Notebook",
        "Variabili e conversioni in Python",
        "Variabili, liste, dizionari, set, classi in Python",
        "Definizione di una funzione",
        "Lettura e scrittura file",
        "Gestione delle date",
        "Funzioni matematiche in Numpy",
        "Funzioni per creare dati random",
        "Metodi di indicizzazione",
        "Tabelle pivot in Pandas",
        "Opzioni di display",
        "Ottimizzazione della memoria ram per grandi quantità di dati"
      ],
      "course_content": {},
      "requirements": [
        "Non è richiesta esperienza di programmazione perché il corso parte dalle basi",
        "Un computer connesso ad internet",
        "Compatibile con tutte le lingue ma il corso è in inglese"
      ],
      "description": "Python è il linguaggio più importante nel campo dei dati, e le sue librerie per l'analisi e  modellazione sono l'arma principale.\nIn questo corso inizieremo costruendo le basi di Python per poi andare ad approfondire le librerie fondamentali come Numpy, Pandas, e Matplotlib.\nLe quattro caratteristiche principali di questo corso sono:\n1.     Linguaggio chiaro e semplificato, adatto a chiunque\n2.     Pratico ed efficiente\n3.     Esempi, illustrazioni e dimostrazioni accompagnati alla spiegazione\n4.     Aggiornamento continuo dei contenuti ed esercitazioni",
      "target_audience": [
        "Ricercatori nel campo dell'analisi dei dati, dell'apprendimento automatico e del data mining, che vogliono consolidare le basi",
        "Principianti che vogliono iniziare ad apprendere il linguaggio di programmazione Python",
        "Programmatori che hanno già esperienza con altri linguaggi e vogliono imparare il linguaggio Python",
        "Qualunque studente che voglia intraprendere una carriera nel settore del Data Science",
        "Qualunque persona che sia per lavoro che per crescita personale voglia approcciarsi a questo nuovo campo"
      ]
    },
    {
      "title": "AI4ALL: Basics in Artificial Neural Network",
      "url": "https://www.udemy.com/course/ai4all-basics-in-artificial-neural-network/",
      "bio": "Basics and Foundation of Artificial Neural Networks",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "No prior programming experience needed. You will learn directly in this class."
      ],
      "description": "This course is created to follow up with the AI4ALL initiatives. The course presents coding materials at a pre-college level and introduces a fundamental pipeline for a neural network model. The course is designed for the first-time learners and the audience who only want to get a taste of a machine learning project but still uncertain whether this is the career path. We will not bored you with the unnecessary component and we will directly take you through a list of topics that are fundamental for industry practitioners and researchers to design their customized neural network model.  The course focuses on the Artificial Neural Network models and introduce the important building block using Tensorflow.\n\n\nThis instructor team is lead by Ivy League graduate students and we have had 3+ years coaching high school students. We have seen all the ups and downs. Moreover, we want to share these roadblocks with you. This course is designed for beginner students at pre-college level who just want to have a quick taste of what AI is about and efficiently build a quick Github package to showcase some technical skills. We have other longer courses for more advanced students. However, we welcome anybody to take this course!",
      "target_audience": [
        "Pre-college level students interested in neural network models"
      ]
    },
    {
      "title": "Alteryx Designer ハンズオントレーニング（基礎編）",
      "url": "https://www.udemy.com/course/alteryx-designer-core-jp/",
      "bio": "ハンズオン形式でAlteryx Designerの基本的な使い方を学んでいただくコースです。",
      "objectives": [
        "Alteryx Designerのインターフェース概要",
        "Alteryx Designerでの基本的なデータ加工・集計方法",
        "Alteryx Designerで複数データソースを統合し、新たな分析用データを作成する方法",
        "Alteryx Designerで加工済みのデータを出力する方法"
      ],
      "course_content": {
        "はじめに": [
          "コースの内容について",
          "Alteryx Designerの基礎"
        ],
        "演習1）ヨーグルト販売価格のデータ準備": [
          "この演習で使用するツールの説明",
          "ハンズオン"
        ],
        "演習2）ヨーグルト販売実績のデータ準備": [
          "この演習で使用するツールの説明",
          "ハンズオン"
        ],
        "演習３）データの結合と差額の計算": [
          "この演習で使用するツールの説明",
          "ハンズオン"
        ],
        "まとめ": [
          "Alteryxに関する情報源のご紹介"
        ]
      },
      "requirements": [
        "お使いのWindows PCにAlteryx Designerがインストールされている必要があります。",
        "【Alteryx Designer推奨環境】Microsoft Windows 7 またはそれ以降 (64bits),クアッドコア (シングルチップ)、RAM 推奨16GB",
        "【Alteryx Designer推奨バージョン】本コースはAlteryx2020.1の使用を前提としています。異なるバージョンを使用した場合の動作は保証できない場合がございますのでご了承ください。"
      ],
      "description": "本セッションではヨーグルトの販売データを使用して、Alteryxを使ったデータ前処理の基礎をハンズオン形式で学んでいただきます。\n受講するにあたっては、事前にAlteryx Designerがインストールされた環境をご用意ください。",
      "target_audience": [
        "Alteryxの基礎的な使い方を学びたいビジネスユーザ、エンジニア、データサイエンティストの方",
        "TableauやPowerBIなどのBIツールの前処理やExcel、CRMなどのデータの加工に手間がかかっていてお困りの方",
        "データ活用をこれから始めていきたいとお考えの方",
        "セルフサービス型のデータ分析に興味がある方",
        "データ分析作業の効率化を図りたい方"
      ]
    },
    {
      "title": "The Ultimate Beginners Guide to Machine Learning",
      "url": "https://www.udemy.com/course/the-ultimate-beginners-guide-to-machine-learning/",
      "bio": "Learn everything you need to know to start your studies in Machine Learning! Theory and practice!",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Course content",
          "Course materials"
        ],
        "Classification": [
          "What is classification?",
          "Naïve Bayes",
          "Naïve Bayes in Orange",
          "Decision trees",
          "Decision trees in Orange",
          "Rule based learning",
          "Rules in Orange",
          "SVM (Support Vectors Machines)",
          "SVM in Orange"
        ],
        "Regression": [
          "What is regression?",
          "Linear regression",
          "Linear regression in Orange"
        ],
        "Clustering": [
          "What is clustering?",
          "k-means algorithm",
          "k-means in Orange"
        ],
        "Association": [
          "What are association rules?",
          "Apriori algorithm",
          "Apriori in Orange"
        ],
        "Final remarks": [
          "Final remarks",
          "BONUS"
        ]
      },
      "requirements": [
        "There are no prerequisites, people from any field can take this course"
      ],
      "description": "The area of Machine Learning is currently the most relevant field in Artificial Intelligence, being responsible for the use of intelligent algorithms that make computers learn through databases. The Machine Learning job market in various parts of the world is on the rise and the tendency is for this type of professional to be increasingly in demand! Some studies even indicate that knowledge in this area will soon be a prerequisite for Information Technology professionals!\nTo take you to this area, in this quick, basic and free course you will have a theoretical and practical overview of some machine learning algorithms using the Orange visual tool, which is one of the easiest tools for those starting learning since no computer programming skills are needed! The course is divided into four parts, which present the main areas of machine learning:\n\nClassification: Naïve Bayes, decision trees, rules, and support vector machines (SVM) algorithms\nRegression: linear regression algorithm\nClustering: k-means algorithm\nAssociation rules: - apriori algorithm\nThis course aims to serve as a basic reference on the main machine learning techniques, especially for beginners in the area who do not have much time to take a longer and more complete course! I will see you in class!",
      "target_audience": [
        "People interested in starting their studies in Machine Learning",
        "People who want to start a career in Machine Learning",
        "Undergraduate students studying subjects related to Artificial Intelligence",
        "Anyone interested in Artificial Intelligence"
      ]
    },
    {
      "title": "Data Science de A a Z - Extraçao e Exibição dos Dados",
      "url": "https://www.udemy.com/course/curso-data-science-completo/",
      "bio": "Aprenda Data Science com Python e também áreas importantes como estatística e ETL no SQL Server!",
      "objectives": [
        "Utilizar estatística aplicada",
        "Definir o que é Machine Learning, Big Data e Data Science",
        "Análise de Dados com Python",
        "Gráficos com Python"
      ],
      "course_content": {
        "Introdução a Data Science - Módulo Teórico": [
          "Apresentação do conteúdo",
          "Data Science - Introdução - Parte 01",
          "Um minuto! Precisamos falar de Game Of Thrones!",
          "Data Science - Introdução - Parte 02",
          "Data Science - Introdução - Parte 03",
          "Data Science - Introdução - Parte 04"
        ],
        "A profissão de Cientista de Dados - Módulo Teórico": [
          "Big Data Real Time e Cloud Computing",
          "Carreiras de Data Science"
        ],
        "Montando o ambiente - Módulo Prático": [
          "Ciclo de Vida BI",
          "Download dos arquivos",
          "Por que SQL Server?",
          "Business Intelligence x Data Science - Onde as duas ciências se encontram",
          "Download e Instalação Virtual Box",
          "Criando a máquina virtual",
          "Ajustando a VM",
          "Instalando o SQL Server 2016",
          "Management Studio",
          "Visual Studio",
          "Data Tools",
          "Ferramentas: Excel e Notepad++"
        ],
        "Organização de Projetos de Data Science - Módulo Prático": [
          "Estrutura de Pastas",
          "Ajustando Padrões de Dados"
        ],
        "Organização de ETL - Módulo Prático": [
          "Uma visão sobre ETL",
          "Criando o primeiro projeto",
          "Criando um Destino",
          "Qualidade de Dados"
        ],
        "Infraestrutura e Segurança - Módulo Prático": [
          "Realizando Deploy de Transformações",
          "Relatórios de Transformações",
          "Automatizando cargas de dados",
          "Arquitetura e Segurança - Parte 01",
          "Arquitetura e Segurança - Parte 02",
          "Arquitetura e Segurança - Parte 03",
          "Arquitetura e Segurança - Parte 04",
          "Arquitetura e Segurança - Parte 05",
          "Protegendo Pacotes com Criptografia",
          "Pacotes de Carga Multiusuário"
        ],
        "Tratamento de Dados - O que você realmente precisa saber!": [
          "Tratando colunas essenciais com Excel e Notepad++",
          "Tratando arquivo CSV - O formato universal",
          "Identificando anomalias nos dados",
          "Rastreamento de erros - Analisando versões de arquivos",
          "Verificando erros no SSIS",
          "Identificando anomalias com SQL",
          "Null, And e Or",
          "Automatizando o tratamento de anomalias",
          "Exercícios de Anomalias",
          "Importando Dados Automaticamente",
          "Correção Import",
          "Utilizando Cast e Convert"
        ],
        "Criando um ambiente Work - Módulo Prático": [
          "Criando um procedure para a tabela WRK - Parte 01",
          "Criando um procedure para a tabela WRK - Parte 02",
          "Criando um procedure para a tabela WRK - Parte 03",
          "Verificação de Dados",
          "Exercício: Criação de Procedures",
          "Correção: Procedures"
        ],
        "Aumentando a performance - Módulo Prático": [
          "Tratando campos de ID",
          "Criando Tabelas Derivadas",
          "Muita informação? Resumo de tratamento de dados!"
        ],
        "Dados Versionados - Como fazer? - Módulo Prático": [
          "Fase 01 - CSV to RAW",
          "Fase 02 - RAW to WRK - Parte 01",
          "Fase 02 - RAW to WRK - Parte 02",
          "Fase 02 - RAW to WRK - Parte 03",
          "Teoria de Versionamento - Passo a Passo",
          "Teoria de Versionamento - Passo a Passo - Parte 02",
          "Atualização Simples",
          "Atualização Versionada",
          "Executando o Pacote de Atualização Versionada"
        ]
      },
      "requirements": [
        "Noções básicas de informática, o resto a gente ensina aqui!",
        "Um pouco de SQL ajuda muito!"
      ],
      "description": "Data Science de A à Z\nO essencial que você precisa saber sobre esse curso é: Ele é voltado para iniciantes. Esse é o meu público e amo trabalhar com ele.\nPortanto, se: Você quer entrar na área de Data Science e não sabe por onde começar, se você fez algum ótimo curso mas achou avançado demais e não entendeu nada, se você que saber todos os conceitos importantes que cercam essa área, se você é UNIVERSITÁRIO buscando conhecimento sobre a áreas, se você quer ter uma visão geral é um EXCELENTE BASE para saber caminhar sozinho, o seu lugar é aqui. Vamos aprender de uma forma didática mesmo para quem nunca viu o assunto.\nA profissão de Cisntista de Dados não é só luxo. Há também partes que ninguém conta, como por exemplo onde tudo é feito antes da exibição dos lindos gráficos para tomadas de decisão, e eu vou te mostrar aqui como tudo é, para que nada te surpreenda em um ambiente real.\nO curso segue uma lógica de aprendizado com um plus que você só encontrará aqui: Carga e tratamento de Dados no SQL Server.\nPor que carga de dados?\nA profissão de Cientista de Dados lida em 70% do seu tempo com o tratamento de dados. Os dados, nosso ator principal, precisam ser tratados, padronizados e limpos que QUALQUER técnica seja aplicada em fases posteriores. Aqui você terá um forte base nesse tratamento, utilizando não somente o Python como também a ferramenta Integration Services em conjunto com a linguagem SQL. E para fechar, nós construiremos do ZERO um componente no Integration Services que nos avisa QUANDO um registro foi alterado e grava a sua alteração. E nós vamos instalar o SQL Server DO ZERO.\nInfraestrutura\nOutro ponto é: Você já se imaginou como é um ambiente de cientista de dados? Como são organizadas as pastas, como são salvos os scripts e como são comparados os dados? Aqui também focaremos na infraestrutura do ambiente, organização de pastas e versionamento de scripts.\nGráficos\nUm recurso indispensável para a análise de dados são os gráficos. Já imaginou em apenas olhar para um gráfico e verificar se variáveis são correlacionadas? Ou dizer o quanto de correlação há entre elas? Aqui eu vou te ensinar de uma forma simples, assim como os mais comuns tipos de gráficos, suas variações e por último, mas não menos importante, a dar estilo a esses gráficos escolhendo a sua paleta de cores.\nRecursos\nDentre os recursos gerais do curso, teremos:\nSQL para Data Science.\nIntegration Services e ETL.\nPython para tratamento de dados com Pandas.\nPython para cálculos matemáticos com NumPy.\nGráficos em Python com MatplotLib.\nGráficos estilosos em Python e customização de gráficos com SeaBorn.\n\n\nServidor Dedicado\nPara facilitar o curso, você terá um servidor de armazenamento online DEDICADO à você! Você poderá realizar TODOS os downloads desse servidor caso não encontre os arquivos no site dos fabricantes. Além dos softwares do curso, todos os datasets e códigos em script estão organizados em pastas, separados por módulos para fácil acesso!\nSim, tudo aqui, em um curso só!\nComo você pode ver, é um curso grande, e as aulas estão sendo adicionadas semanalmente!\nTudo com a didática que você já conhece!\nEsse é um curso generalista, que mostra desde o início da área, com a aquisição e o tratamento dos dados até a última ponta que é a exibição dos gráficos para a tomada de decisão, portanto você verá a área completa.\nUniversidade dos Dados - Elevando o seu conhecimento!",
      "target_audience": [
        "Iniciantes na área de Data Science",
        "Estudantes de TI",
        "Estudantes de Bancos de Dados",
        "Qualquer pessoa com muita vontade de aprender"
      ]
    },
    {
      "title": "Data Science ve Python: Sıfırdan Uzmanlığa Veri Bilimi (2)",
      "url": "https://www.udemy.com/course/data-science-sfrdan-uzmanlga-veri-bilimi-2/",
      "bio": "Bir Profesyonel gibi Data Science(Veri Bilimi) öğrenin ve Yapay Zeka öğrenmek için gerekli temelleri atın!",
      "objectives": [
        "Artık CV'nize gönül rahatlığıyla \"advance in Python\" ve \"Data Scientist\" yazabileceksiniz",
        "Ders sonunda yapacağımız proje ile tüm dünyaya yayın yapacaksınız",
        "Python öğrendikten sonra diğer dillere adapte olmanız daha kolay olacak",
        "Kaggle Platformunda yaptığınız projeleri paylaşacaksınız",
        "Yapay Zeka kursuna bir adım daha yaklaşmış olacaksınız"
      ],
      "course_content": {
        "Data Science Giriş": [
          "Data Science Giriş",
          "Datai Team: Github ve Kaynaklar",
          "Udemy Tanıtım"
        ],
        "Kaggle and Data Science(Veri Bilimi)": [
          "Kaggle Tanıtımı 1",
          "Kaggle Tanıtımı 2",
          "Notebook (Kernel) Nedir?",
          "Kaggle Arayüz Değişikliği",
          "Kaggle Profil Sayfası",
          "Kaggle'da Başarılı Olmak İçin Neler Yapmalı?",
          "Data Science (Veri Bilimi) Giriş"
        ],
        "Introduction to Python (Python'a Giriş)": [
          "Import and First Look Data",
          "Matplotlib",
          "Matplotlib",
          "Dictionary, Pandas and Logic Control",
          "Pandas",
          "Loop Data Structures (while and for)",
          "Loops",
          "ÖDEV 1"
        ],
        "Python Data Science Tool Box": [
          "User Defined Function and Scope",
          "User Defined Function and Scope",
          "Nested, Default, Flexible, Lambda, Anonymous Functions",
          "Nested, Default, Flexible, Lambda, Anonymous Functions",
          "Iterators and List Comprehension",
          "List Comprehension"
        ],
        "Cleaning Data": [
          "Diagnose Data for Cleaning",
          "Diagnose Data for Cleaning",
          "Exploratory Data Analysis (EDA)",
          "Exploratory Data Analysis (EDA)",
          "Visual Exploratory Data Analysis",
          "Tidy and Pivoting Data",
          "Tidy and Pivoting Data",
          "Concatenating Data and Data Types",
          "Missing Data and Testing with Assert",
          "Missing Data and Testing with Assert"
        ],
        "Pandas Foundation": [
          "Review of Pandas, Building Data Frames from Scratch,Visual and Statistical EDA",
          "Indexing and Resampling Pandas Time Series"
        ],
        "Manipulating Data Frames with Pandas": [
          "Indexing, Slicing, Filtering and Transforming Data Frames",
          "Indexing, Slicing, Filtering and Transforming Data Frames",
          "Index Objects, Hierarchical Indexing, Pivoting, Stacking-Unstacking and Melting",
          "Index Objects, Hierarchical Indexing, Pivoting, Stacking-Unstacking and Melting"
        ],
        "Veri Bilimi Final Sınavı": [
          "Veri Bilimi Final Sınavı"
        ],
        "Titanik Projesi": [
          "Titanik Projesi Giriş",
          "Veri Yükleme ve Veriye Genel Bakış",
          "Değişkenlerin Tanımları (Variable Description)",
          "Tek Değişkenli Analiz: Kategorik Değişken",
          "Tek Değişkenli Analiz: Sayısal Değişken",
          "Temel Veri Analizi",
          "Outlier Tespiti",
          "Missing Value",
          "Titanik Projesi Sonuç"
        ],
        "Sonuç": [
          "Ne Yaptık Ne Yapacağız?",
          "Veri Bilimi Ek Kaynak",
          "BONUS"
        ]
      },
      "requirements": [
        "Önceden \"Python: Sıfırdan Uzmanlığa Programlama (1)\" kursunun alınmış olması yada python temellerinin bilinmesi gerekli!",
        "İnternet bağlantılı bir bilgisayara sahip olmak yeterlidir",
        "Hedefler ve gelecekle ilgili büyük ve güzel hayaller"
      ],
      "description": "Bu kurs 7 bölümlük nihai hedefimizin ikinci bölümünü oluşturmaktadır.\nPython: Python Sıfırdan Uzmanlığa Programlama (1)\nData Science (Veri Bilimi)\nVisualization Tools (Görselleştirme Araçları)\nMachine Learning (Makine Öğrenmesi)\nDeep Learning (Derin Öğrenme)\nStatistical Learning (İstatistik)\nArtificial Intelligence (Yapay Zeka)\nData Science(veri bilimi) kursunda hem Python dili ile veri biliminin nasıl yapıldığını hem de nihai hedefimiz olan Yapay Zeka konusuna temel oluşturacak bilgiler öğreneceğiz.\nNeden Data Science?\nİnsanların daha hızlı ve etkili kararlar vermesine yardımcı,\nVerinin artması ile veri bilimcilere olan talep ve iş fırsatları,\nStart-up fırsatları,\nKarar verme yetisi.\nBu Kurs ile Alacaklarınız\nSıfırdan Kodlama Becerisi: Sizinle birlikte kod yazıyoruz. Her ders boş bir sayfa ile başlar ve kodu sıfırdan yazarız. Bu şekilde ilerleyebilir ve kodun nasıl bir araya geldiğini ve her satırın ne anlama geldiğini tam olarak anlayabilirsiniz.\nKodlar ve Şablonları: Kursta oluşturduğumuz her Python şablonlarını ve kodunu indirebilirsiniz. Bu, sizlere hem daha sonra kod üzerinde pratik yapma hem de kendi projelerinizi şablon sayesinde daha kolay bir şekilde yaratma imkanı sağlayacaktır\nTeori ve Mantık: Size yalnızca kod yazmayı değil, hem yazdığımız kodun arkasında yatan mantığı ve teoriyi hem de neden böyle bir kod yazdığımızı anlatıyoruz.\nKurs içi destek: Size sadece video ile ders anlatımı yapmıyoruz. Size destek olmak için profesyonel Veri Bilimcilerinden oluşan bir ekip oluşturduk. Bu da ders ve ya ders dışı sorularınıza en fazla 72 saat içinde yanıt alacağınız anlamına geliyor.\nData Science kursu içeriği\nKaggle and Data Science(Veri Bilimi)\nKaggle Tanıtımı 1\nKaggle Tanıtımı 2\nKaggle Örneği\nKaggle Profil Sayfası\nData Science (Veri Bilimi)\nIntroduction to Python (Python'a Giriş)\nİmport and First Look Data\nMatplotlib\nDictionary, Pandas and Logic Control\nLoop Data Structures (while and for)\nPython Data Science Tool Box\nUser Defined Function and Scope\nNested, Default, Flexible, Lambda, Anonymous Functions\nIterators and List Comprehension\nCleaning Data\nDiagnose Data for Cleaning\nExploratory Data Analysis (EDA)\nVisual Exploratory Data Analysis\nTidy and Pivoting Data\nConcatenating Data and Data Types\nMissing Data and Testing with Assert\nPandas Foundation\nReview of Pandas, Building Data Frames from Scratch,Visual and Statistical EDA\nIndexing and Resampling Pandas Time Series\nManipulating Data Frames with Pandas\nIndexing, Slicing, Filtering and Transforming Data Frames\nIndex Objects, Hierarchical Indexing, Pivoting, Stacking-Unstacking and Melting\nKurs Hakkında Bazı Öğrenci Yorumları\nSabiha Iffet\nDaha önce makine öğrenmesi, tensorflow gibi kursları almış ve bunlar için ciddi zaman harcamıştım ama öğrendiklerim hep havada kaldı. Kod ezberlemekten öteye gidemedim. Sıfırdan python anlatan kurslar da C dilini bildiğim için çok uzun ve sıkıcı geliyordu. Bu kurs serisi gereksiz hiçbir ayrıntıya girmemesi, makine öğrenmesi ve yapay zeka için gerekli olan tüm bilgileri temelden alarak vermesi, veri işlemeyi kaggle gibi bir platformdan yapmasıyla diğerlerinden ayrılıyor. Eğer yapay zekaya ilgi duyuyorsanız doğru yerdesiniz.\nSerdal Aydoğmuş\nGenelde ingilizce kursları tercih ediyorum akıcılık ve ses kalitesi açısından. Bu denli güzel anlatımlı bir türkçe kursa denk gelmek beni mutlu etti. Kalite mühendisiyim, amacım python ile veri görselleştirme öğrenmekti ama şimdi AI aklımı çeliyor. Teşekkürler\nDemettolgun\nMükemmel bir içerik. İnternet ortamından parça parça bulup birleştirmeye çalıştığım her alana nokta atışı yapılmış resmen. Çok büyük emek ve özveri ile hazırlanan içerik için sonsuz teşekkür ediyorum.\nİçeriğin İngilizce olması sizi yanıltmasın arkadaşlar. Derslerim tamamen Türkçedir.\nHemen kaydolun ve bir an önce başlayalım.",
      "target_audience": [
        "Data Science (veri bilimi) alanında uzmanlaşmak isteyen",
        "Python dilinde uzmanlaşmak isteyenler",
        "Eğitim yada kariyerini veri bilimi(data science), makine öğrenmesi(machine learning) yada yapay zeka(artificial intelligence) alanlarında başlamak yada sürdürmek isteyenler"
      ]
    },
    {
      "title": "Python ile Makine Öğrenmesi",
      "url": "https://www.udemy.com/course/makine-ogrenmesi/",
      "bio": "Yapay zeka, veri bilimi ve machine learning kavramlarını gerçek hayat problemleri üzerinden uygulayarak öğreneceksiniz.",
      "objectives": [
        "Python kullanarak makine öğrenmesi algoritmaları geliştireceksiniz.",
        "Makine öğrenmesi algoritmalarını gerçek hayat problemlerine uygulayacaksınız.",
        "Veri ön-işleme aşamalarını kavrayacaksınız.",
        "Tahmin, regresyon, sınıflandırma ve kümeleme algoritmalarıyla çalışacaksınız.",
        "Derin öğrenme ve doğal dil işleme projeleri geliştireceksiniz.",
        "Model seçimi ve kollektif öğrenme konularına hakim olacaksınız.",
        "Birliktelik kural çıkarımı ve arttırımlı öğrenme üzerine tecrübe kazanacaksınız."
      ],
      "course_content": {
        "Hoş Geldiniz!": [
          "Makine Öğrenmesinin Uygulamaları",
          "Makine Öğrenmesi ve Geleceğin Dünyası",
          "Python ve Anaconda'nın kurulması",
          "Dersler ile ilgili önemli notlar"
        ],
        "Veri Analizi Proje Yönetimi ve Problem Tipleri": [
          "Veri Kaynağı ve Dersin Web Sitesi",
          "Kütüphanelerin Yüklenmesi",
          "Verinin Python'dan Yüklenmesi ve içeri alınması (data import)",
          "Python ve Nesne Yönelimli Programlama",
          "Eksik Veriler (Missing Values)",
          "Kategorik Veriler",
          "Verilerin Birleştirilmesi ve DataFrame Oluşturulması",
          "Veri Kümesinin Eğitim ve Test olarak bölünmesi",
          "Öznitelik Ölçekleme",
          "Veri Ön işleme Şablonu",
          "Veri Ön İşleme Quizi"
        ],
        "Tahmin (Prediction) #1: Basit Doğrusal Regresyon (Simple Linear Regression)": [
          "Tahmin (Prediction) Problemlerine Giriş",
          "Veri Kümesinin İndirilmesi",
          "Veri Kümesi ve Kodlar ile ilgili",
          "Basit Doğrusal Regresyon (Simple Linear Regression)",
          "Veri Yükleme ve Ön İşleme Şablonunun Kullanılması ve Regresyona Hazırlık",
          "Phyton ile Basit Doğrusal Regresyon Model İnşası",
          "Python ile Basit Doğrusal Regresyon Uygulaması",
          "Basit Doğrusal Regresyon Görselleştirilmesi",
          "Quiz 2: Basit Doğrusal Regresyon"
        ],
        "Tahmin (Prediction) #2: Çoklu Doğrusal Regresyon (Multiple Linear Regression)": [
          "Veri Kümesi ve Problemin Tanınması",
          "Çoklu Doğrusal Regresyon (Multiple Linear Regression) Kavramına Giriş",
          "Kukla Değişken ve Tuzağı (Dummy Variable Trap)",
          "Araştırma Ödevi: P-Value",
          "P-Value (Olasılık Değeri)",
          "Çok Değişkenli Modellerde, Değişken Seçimi",
          "Çoklu Değişken için Veri Hazırlama (Python Kodu)",
          "Çoklu Değişken Linear Model Oluşturma Python Kodlaması ve Model",
          "Python ile Geri Eleme (Backward Elimination)",
          "Ödev 1: Veri Kümesi ve Ödevin Açıklaması",
          "Ödev 1: Çözüm 1. Parça: Verinin hazırlanması ve Çoklu Doğrusal Regresyon",
          "Ödev 1: Çözüm 2. Parça: Geri Eleme (Backward Elimination)",
          "Çoklu Doğrusal Regresyon"
        ],
        "Tahmin (Prediction) #3: Polinom Regresyon (Polynomial Regression)": [
          "Veri Kümesi, Kavramın ve Problemin Tanımı",
          "Polinomal Regresyonun Python ile Uygulama kodu",
          "Python ile Doğrusal Olmayan Şablon (Polinomial Regression Python Template)"
        ],
        "Tahmin (Prediction) #4: Destek Vektör (Support Vector Regression)": [
          "SVR Tanımı ve Problem",
          "Python ile Support Vector Tahmini Uygulaması"
        ],
        "Tahmin (Prediction) #5: Karar Ağacı (Decision Tree)": [
          "Karar Ağacı kullanarak tahmin yöntemi",
          "Python ile karar ağacı kullanarak tahmin"
        ],
        "Tahmin (Prediction) #6: Rassal Ağaçlar (Random Forest) ile Tahmin": [
          "Rassal Ağaç (Random Forest) Algoritması ve Tahmin",
          "Python ile Rassal Ağaç kullanarak Tahmin"
        ],
        "Tahmin (Prediction) #7: Değerlendirme ve Metotların Karşılaştırılması": [
          "R2 Hesaplanması",
          "Düzeltilmiş R2 Hesaplaması (Adjusted R2)",
          "Python ile R2 hesaplama ve Algoritmaların Karşılaştırılması",
          "Ödev 2: Ödevin tanımı ve veri kümesi",
          "Ödev 2: Çözümü",
          "ÖZET : Tahmin Metotlarının Karşılaştırılması",
          "ŞABLON: Tahmin Metotları için kullanılabilecek Python Şablonu"
        ],
        "Sınıflandırma #1: Giriş ve Temel Kavramlar": [
          "Sınıflandırma ve Temel Kavramlar, Problemin Algısı"
        ]
      },
      "requirements": [
        "Öğrenme arzusu",
        "Lise düzeyinde matematik bilgisi",
        "İstatistik ve herhangi bir programlama dili tecrübesine gerek yoktur."
      ],
      "description": "Makine öğrenmesini merak ediyor musunuz veya işinizde yoğun olarak veri kullanıyor veya gelecekte makinelerin nasıl çalışacağını merak ediyor musunuz?\nBu kurs, Doç. Dr. Şadi Evren ŞEKER tarafından hazırlanmaktadır. Şadi Evren Şeker, lisans, yüksek lisans ve doktorasını bilgisayar mühendisliğinde tamamlamış, yüksek lisans ve doktora sırasında yapay zeka üzerine çalışmış ve sonrasında doktora sonrası araştırmacı olarak veri bilimi üzerine dünyanın çeşitli ülkelerinde çalışmalarına devam etmiş, makine öğrenmesi, büyük veri, veri bilimi ve yapay zeka konularında çok sayıda akademik makale ve kitaplar yayınlamış, literatüre kazandırdığı patent ve algoritmalar yanında 20 yıla yakın sektörde çok farklı kurumlara eğitim, danışmalık ve yazılım hizmetleri vermenin yanında halen aktif olarak akademisyenliğe ve sektörde veri bilimi, yapay zeka ve büyük veri uygulamalarına devam etmektedir. Aktif olarak çalıştığı şirketler arasında, Türkiye ve dünyada lider olan, bankacılık, telekom, sigortacılık, ulaştırma, inşaat, turizm ve finans firmaları bulunmaktadır.\nBu kursta amaçlanan, hiç bilmeyen ve yeni başlayan birisini makine öğrenmesi konusunda uzman seviyesine çıkarmaktır. Adım adım, makine öğrenmesi dünyasına giriş yapılacak ve her bölümde farklı yetenekler kazandırılarak makine öğrenmesi ve bir alt çalışma alanı olarak görülebilecek veri bilimi konularındaki gerçek uygulamalar hakkında fikir verilecektir. Ayrıca güncel ve gözde konular olan derin öğrenme veya arttırımlı öğrenme gibi konulara da giriş yapılacak ve bu kavramların kullanımları ve uygulamaları örnekler üzerinden gösterilecektir.\nKurs boyunca konular eğlenceli ve heyecanlı bir şekilde anlatılmaya çalışılacak ve genel bir yapı olarak aşağıdaki sıra izlenecektir.\nPart 1 - Veri Önişleme (Data Preprocessing)\nPart 2 - Tahmin ve Regresyon: Simple Linear Regression, Multiple Linear Regression, Polynomial Regression, SVR, Decision Tree Regression, Random Forest Regression\nPart 3 - Sınıflandırma (Classification): Logistic Regression, K-NN, SVM, Kernel SVM, Naive Bayes, Decision Tree Classification, Random Forest Classification\nPart 4 - Bölütleme (Kümeleme, Clustering): K-Means, Hierarchical Clustering\nPart 5 - Birliktelik Kural Çıkarımı (Association Rule Learning): Apriori, Eclat\nPart 6 - Arttırımlı Öğrenme (Reinforcement Learning): Upper Confidence Bound, Thompson Sampling\nPart 7 - Doğal Dil İşleme (Natural Language Processing): Bag-of-words model and algorithms for NLP\nPart 8 - Derin Öğrenme (Deep Learning): Artificial Neural Networks, Convolutional Neural Networks\nPart 9 - Boyut Dönüşümü ve indirgemesi (Transformation, Dimensionality Reduction): PCA, LDA, Kernel PCA\nPart 10 - Model Seçimi ve Kollektif Öğrenme: Model Selection & Boosting: k-fold Cross Validation, Parameter Tuning, Grid Search, XGBoost\nKurs kapsamında, gerçek hayat örnekleri kullanılacak ve kendi makine öğrenme modelinizi oluşturmanın yolu da gösterilecektir.\nKursun en önemli özelliklerinden birisi, kurs kapsamında, Python dilinde kod şablonları verilecek olup bu kod şablonlarını, kendi problemlerinizde kullanabilecek olmanızdır.",
      "target_audience": [
        "Veri ile işi olan herkes.",
        "Geleceğin mesleklerinde çalışmak isteyen herkes.",
        "Yapay zeka ve makine öğrenmesi konularına merakı olan herkes."
      ]
    },
    {
      "title": "Data Mesh 101 by Agile Lab",
      "url": "https://www.udemy.com/course/data-mesh-101-by-agile-lab/",
      "bio": "Decentralized Data Management for Scalability, Agility, and Innovation",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Introduction - Quiz"
        ],
        "Decentralized Domain Ownership": [
          "Decentralized Domain Ownership",
          "Decentralized Domain Ownership - Quiz"
        ],
        "Data as a Product": [
          "Data as a Product",
          "Data as a Product - Quiz"
        ],
        "Federated Computational Governance": [
          "Federated Computational Governance",
          "Federated Computational Governance - Quiz"
        ],
        "Selfe-serve Data Platform": [
          "Selfe-serve Data Patform",
          "Selfe-serve Data Platform - Quiz"
        ]
      },
      "requirements": [
        "Basic understanding of data concepts is helpful but not mandatory. No specific tools or software are required."
      ],
      "description": "Data Mesh 101 is an introductory course designed to help data professionals, business leaders, and IT teams understand and implement the principles of Data Mesh, a decentralized approach to data management. This course explores how to overcome common challenges in centralized data systems by promoting domain-specific ownership and fostering a more agile, scalable, and data-driven environment.\nThroughout the course, you will learn about the four core pillars of Data Mesh: decentralized domain ownership, data as a product, federated governance, and self-serve data platforms. These pillars aim to address the limitations of traditional data architectures, ensuring that data is managed by the teams most familiar with it, thus improving data quality, accessibility, and alignment with business needs.\nYou will also gain insights into how to align operational and analytical data strategies, breaking down silos between business and IT departments to enhance decision-making and drive value from data. With a focus on data quality, governance, and scalability, the course will teach you how to set up autonomous teams responsible for managing and governing data in their domains, resulting in more efficient and sustainable data operations.\nWhether you're an experienced data engineer or just beginning your journey with data management, this course provides you with the knowledge to rethink your data strategy and take full advantage of modern decentralized data architectures.",
      "target_audience": [
        "Data professionals (engineers, architects, analysts) seeking to modernize their approach to data management.",
        "Business leaders and decision-makers looking to drive innovation and become data-driven organizations.",
        "Anyone interested in learning how to transform data strategies through scalable and decentralized frameworks like Data Mesh."
      ]
    },
    {
      "title": "Máster Visualización de Datos Interactiva con Dash y Plotly",
      "url": "https://www.udemy.com/course/master-dashboards-interactivos-con-python-dash-plotly/",
      "bio": "Conviértete en un experto en la creación de Dashboards Interactivos para la Ciencia de Datos con Dash y Plotly",
      "objectives": [
        "Dominar la creación de visualizaciones interactivas con la librería Plotly.",
        "Crear dashboards interactivos con múltiples entradas y múltiples salidas con la librería Dash.",
        "Desplegar dashboards como aplicaciones web en un servidor para ser accesibles de manera online.",
        "Aprenderá cómo proteger sus dashboards interactivos con autenticación de usuarios.",
        "Importación de fuentes de datos para ser utilizadas en su dashboard interactivo.",
        "Comprender y profundizar en el flujo completo de un proyecto visualización de datos.",
        "Adquirirá un conocimiento extenso en la tecnología puntera de visualización de datos que podrá aplicar de inmediato a un precio muy asequible."
      ],
      "course_content": {
        "Introducción al curso e instalación": [
          "Bienvenida / Información importante",
          "¿Qué es Python – Plotly - Dash?",
          "Instalación Python Anaconda",
          "Instalación Atom (o VSCode en sección \"Recursos\")",
          "Información importante para realizar los ejercicios",
          "Instalación librerías Python Dashboards"
        ],
        "Introducción al tratamiento de datos y visualización": [
          "¿Qué librerías de visualización existen?",
          "Introducción a la librería Pandas ¿qué es un dataframe?",
          "Importación de fuentes de datos con Pandas",
          "Transformación de datos básica con Pandas"
        ],
        "Librería de visualización Plotly": [
          "¿Qué nos ofrece Plotly?",
          "Creación de Scatter Plot",
          "Creación de Line Plot",
          "Ejercicio Line Plot",
          "Creación de Bar Plot",
          "Creación de Bubble Plot",
          "Creación de Box Plot",
          "Ejercicio Box Plot",
          "Creación de Histogramas",
          "Creación de Distplot",
          "Ejercicio Distplot",
          "Creación de Heatmaps",
          "Creación de Mapas Geográficos",
          "Plotly Express"
        ],
        "Dash - Layouts y Componentes": [
          "Conceptos básicos Dash",
          "Componentes HTML en Dash",
          "Componentes Core en Dash",
          "Dash Layouts – Creación del primer dashboard manual",
          "Dash Layouts – Aplicación estilos",
          "Inserción gráfico Plotly en Dash",
          "Caso práctico – Creación dashboard con Dash"
        ],
        "Dash - Interactividad": [
          "Dash Callbacks",
          "Dash Callbacks para Gráficos",
          "Dashboard con múltiples entradas",
          "Dashboard con múltiples salidas",
          "Caso práctico – Creación dashboard con Dash",
          "Interactividad en gráficos – Extracción de información",
          "Interactividad en gráficos – Actualización múltiple"
        ],
        "Proyecto final: Creación de dashboard interactivo": [
          "Proyecto Final - Presentación",
          "Proyecto Final – FASE 1: Librerías, carga datos y Layout",
          "Proyecto Final – FASE 2: Creación de gráficos",
          "Proyecto Final – FASE 3: Creación de mapa",
          "Proyecto Final – FASE 4: Interactividad con selectores",
          "Proyecto Final – FASE 5: Interactividad entre gráficos"
        ],
        "Despliegue de dashboards online": [
          "Despliegue de aplicaciones interactivas – Autorización Accesos",
          "Despliegue de aplicaciones interactivas en servidor web"
        ],
        "Fundamentos del lenguaje Python (OPCIONAL)": [
          "Variables en Python",
          "Creación de listas, extracción y modificación de datos",
          "Conceptos avanzados de creación de listas",
          "Uso de funciones en Python (in-built)",
          "Creación de funciones en Python y argumentos flexibles",
          "Funciones lambda",
          "Métodos en Python",
          "Cómo crear diccionarios en Python",
          "Uso de función zip para creación de diccionarios en base a listas",
          "Comparadores en Python",
          "Bucles en Python",
          "Comprensión de listas en python"
        ],
        "CONCLUSIONES Y CLASE EXTRA": [
          "Conclusiones",
          "Siguientes Pasos",
          "Clase Extra",
          "Recursos Extra"
        ]
      },
      "requirements": [
        "No hay requisitos, la plataformas a utilizar son open source. Si no conoce el lenguaje Python también dispondrá de un módulo de introducción a este lenguaje."
      ],
      "description": "¿Quiere convertirse en un experto en la creación de dashboards interactivos con Python?\n---\nEscuche de otros alumnos por qué este es el curso de Dash y Plotly MEJOR VALORADO en español:\n\"La verdad es que ha sido un curso muy practico y que va al grano, se entienden muy bien toda la lógica de los scritps incluso para los que no somos programadores o desarrolladores. Además es bastante interesante el despliegue del dashboard de manera online, donde se detalla todo paso por paso.\" -- Miguel Ángel Carrasco\n\n\n\"Me han parecido muy claras las explicaciones y los ejemplos son muy ilustrativos. Tiene un buen nivel de detalle y el instructor explica las diferencias entre diferentes tipos de instrucciones.\" -- Joaquín Peña\n\n\n\"Excelente curso, muy completo y te lleva paso a paso de una manera muy didáctica, buenos ejemplos y ejercicios\"--Manuel\n---\nEn este curso aprenderá todo lo que necesita para crear potentes dashboards interactivos con las librerías open source Plotly y Dash, llevando sus habilidades en Ciencia de Datos con Python y la visualización de datos al siguiente nivel.\nAl finalizar el curso podrá desplegar sus dashboards interactivos como aplicaciones web a nivel profesional, de tal manera que pueda compartirlo de manera segura con los usuarios finales.\nComenzará con todos los pasos necesarios de instalación desde cero y aprenderá la importación de datos básica con librerías como Pandas.\nA continuación dominará todos los detalles de Plotly y sus múltiples tipos de visualizaciones interactivas como gráficos de línea, barras, burbujas, box plot, histogramas, distplot, heatmaps, mapas geográficos,…\nUna vez adquirido el conocimiento de Plotly, aprenderá desde cero la librería Dash para que pueda crear dashboards interactivos a partir de sus diferentes componentes, creación de layouts, callbacks y la interactividad entre múltiples entradas y salidas que pueda tener su dashboard completo y funcional.\nFinalizaremos el curso con el despliegue del dashboard interactivo como una aplicación web en un servidor para que esté accesible por otros usuarios de manera online.\nEste curso tendrá un enfoque eminentemente práctico, se explicará paso a paso y en detalle cada nueva funcionalidad, pero el objetivo es que sea capaz de aplicar los nuevos conocimientos ejecutando los múltiples casos prácticos reales propuestos para poner a prueba las destrezas adquiridas, además de un proyecto final con la creación de un dashboard profesional.\nA su vez, tendrá a su disposición un material extenso de consulta y todos los scripts de Python explicados durante esta especialización de tal manera que le sea muy sencillo reutilizarlos para su caso de uso concreto.\nEs el momento de que pase a la acción, tomando este curso conseguirá dominar la tecnología más puntera de creación de dashboards interactivos con Python y supone obtener una habilidad muy importante para poder destacar sobre el resto y conseguir sacar el máximo provecho de la información.",
      "target_audience": [
        "Toda persona que quiera potenciar su perfil adquiriendo habilidades enfocadas en visualización de datos con gran futuro.",
        "Desarrolladores web interesados en crear dahsboards y visualizaciones interactivas.",
        "Expertos de negocio que deseen llevar sus habilidades de creación de visualizaciones al siguiente nivel.",
        "Analistas que quieran profundizar en Python y sus librerías enfocadas en Data Science.",
        "Estudiantes que quieran obtener habilidades que le abrirán puertas en el mercado laboral."
      ]
    },
    {
      "title": "Introduction au Machine Learning",
      "url": "https://www.udemy.com/course/introduction-au-machine-learning/",
      "bio": "Apprenez à créer sur Python des modèles de Machine Learning puissants et créateurs de valeur. Templates de codes inclus.",
      "objectives": [
        "Avoir la bonne intuition du Machine Learning",
        "Implémenter des modèles de Machine Learning sur Python",
        "Créer de la valeur ajoutée dans des problèmes business grâce au Machine Learning",
        "Faire des prédictions précises",
        "Faire du clustering",
        "Gérer et tirer des insights des données"
      ],
      "course_content": {
        "Start Here": [
          "Introduction",
          "Installer Anaconda (Python)"
        ],
        "------------------------ Partie 1 - Data Preprocessing ------------------------": [
          "Bienvenue à la Partie 1 - Data Preprocessing",
          "Importer les librairies",
          "Importer le dataset",
          "Gérer les données manquantes",
          "Gérer les variables catégoriques",
          "Diviser le dataset entre le Training set et le Test set",
          "Appliquer Feature Scaling"
        ],
        "---------------------------- Partie 2 - Régression ----------------------------": [
          "Bienvenue à la Partie 2 - Régression"
        ],
        "Régression Linéaire Simple": [
          "Intuition - Step 1",
          "Intuition - Step 2",
          "Implémentation - Step 1",
          "Implémentation - Step 2",
          "Implémentation - Step 3",
          "Implémentation - Step 4"
        ],
        "Régression Linéaire Multiple": [
          "Intuition - Step 1",
          "Intuition - Step 2",
          "Intuition - Step 3",
          "Intuition - Step 4",
          "Intuition - Step 5",
          "Implémentation - Step 1",
          "Implémentation - Step 2"
        ],
        "Régression Polynomiale": [
          "Intuition",
          "Implémentation - Step 1",
          "Implémentation - Step 2",
          "Implémentation - Step 3"
        ],
        "Evaluation des modèles de Régression": [
          "R Squared",
          "Adjusted R Squared"
        ],
        "-------------------------- Partie 3 - Classification --------------------------": [
          "Bienvenue à la Partie 3 - Classification"
        ],
        "Régression Logistique": [
          "Intuition",
          "Implémentation - Step 1",
          "Implémentation - Step 2",
          "False Positives & False Negatives",
          "Matrice de confusion",
          "Implémentation - Step 3",
          "Implémentation - Step 4"
        ],
        "SVM": [
          "Intuition",
          "Implémentation"
        ]
      },
      "requirements": [
        "Simplement les maths du niveau lycée"
      ],
      "description": "Intéressé par le domaine du Machine Learning ? Alors ce cours est fait pour vous !\nCe cours a été conçu par deux data scientists professionnels qui partagent leur expertise pour vous aider à intégrer la parfaite intuition des modèles de Machine Learning et vous donner les compétences pour implémenter ces modèles.\nTout se fera step by step de sorte que vous développiez votre compréhension du Machine Learning de manière clair et progressive. Chaque tutoriel vous fera acquérir une nouvelle compétence et de nouvelles bases solides.\nNous construirons des modèles pour résoudre des problèmes business basés sur des scénarios du monde réel. Vous apprendrez comment tirer profit du Machine Learning pour créer de la valeur ajoutée dans ces problèmes business.\nCe cours est divisé en 4 parties, chacune correspondant à une branche fondamentale du Machine Learning:\nPartie 1 - Data Preprocessing: pour bien préparer les données de sorte à faciliter l'apprentissage du modèle.\nPartie 2 - Régression: pour prédire une valeur réelle continue.\nPartie 3 - Classification: pour prédire une catégorie.\nPartie 4 - Clustering: pour identifier des segments d'observations groupées par similarité.\nEt en bonus, ce cours inclut tous les templates de code d'implémentation des modèles de Machine Learning dans le cas général, de sorte que vous puissiez les utiliser très facilement sur vos datasets.",
      "target_audience": [
        "Toute personne intéressée par le Machine Learning",
        "Toute personne intéressée par l'Intelligence Artificielle",
        "Toute personne visant une carrière de data scientist",
        "Toute personne souhaitant faire la différence en acquérant la compétence \"Machine Learning\""
      ]
    },
    {
      "title": "Predictive Analytics and Modeling using CART Algorithm",
      "url": "https://www.udemy.com/course/predictive-analytics-and-modeling-using-cart-algorithm/",
      "bio": "Learn Predictive Analytics Model using CART algorithm from a case study",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Intro to Term Deposit Investment Prediction Using CART"
        ],
        "Overview": [
          "CART Overview",
          "CART Overview Continue"
        ],
        "Development": [
          "Variable Explanation",
          "Pre Modelling Terminolgies",
          "Model Development",
          "Model Development Continue",
          "Pruning",
          "Model Parameters",
          "Model Validation and Applications"
        ]
      },
      "requirements": [
        "Prior knowledge of Quantitative Methods will be useful"
      ],
      "description": "Classification and Regression Trees or CART for short is a term refer to Decision Tree algorithms that can be used for classification or regression predictive modeling problems. CART is a predictive algorithm used in Machine learning and it explains how the target variable’s values can be predicted based on other matters. It is a decision tree where each fork is split into a predictor variable and each node has a prediction for the target variable at the end. Classically, this algorithm is referred to as decision trees, but on some platforms like R they are referred to by the more modern term CART. The CART algorithm provides a foundation for important algorithms like bagged decision trees, random forest and boosted decision trees.\nAs the name suggests, CART (Classification and Regression Trees) can be used for both classification and regression problems. The difference lies in the target variable. That is, With classification, we attempt to predict a class label. In other words, classification is used for problems where the output (target variable) takes a finite set of values, e.g., whether it will rain tomorrow or not. Meanwhile, regression is used to predict a numerical label. This means your output can take an infinite set of values, e.g., a house price.\nDecision Trees are an important type of algorithm for predictive modeling machine learning. The classical decision tree algorithms have been around for decades and modern variations like random forest are among the most powerful techniques available. In this post you will discover the humble decision tree algorithm known by it’s more modern name CART which stands for Classification And Regression Trees. The web is full of apps that are driven by data. All the e-commerce apps and websites are based on data in the complete sense. There is database behind a web front end and middleware that talks to a number of other databases and data services. But the mere use of data is not what comprises of data science. A data application gets its value from data and in the process creates value for itself. This means that data science enables the creation of products that are based on data. This course includes learning decision tree modeling which are used by data scientists or people who inspire to be the data scientist.\nThe Decision Tree Algorithm is one of the popular supervised type machine learning algorithms that is used for classifications. This algorithm generates the outcome as the optimized result based upon the tree structure with the conditions or rules. The decision tree algorithm associated with three major components as Decision Nodes, Design Links, and Decision Leaves. It operates with the Splitting, pruning, and tree selection process. It supports both numerical and categorical data to construct the decision tree. Decision tree algorithms are efficient for large data set with less time complexity. This Algorithm is mostly used in customer segmentation and marketing strategy implementation in the business.",
      "target_audience": [
        "Anyone who wants to learn about data and analytics"
      ]
    },
    {
      "title": "Advanced Vector Databases: TSS and Hybrid Search",
      "url": "https://www.udemy.com/course/advanced-vector-databases/",
      "bio": "Master Temporal Similarity Search and Hybrid Search using KDB AI for powerful time-series and unstructured data",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic Python programming knowledge and familiarity with AI/ML concepts. KDB AI account (free tier). Some experience working with vector databases is encouraged."
      ],
      "description": "Dive deep into advanced vector search techniques with this specialized course on Temporal Similarity Search (TSS) and Hybrid Search using KDB AI. This course is designed for those who want to take their vector database skills to the next level.\nIn this course, you'll gain hands-on experience with:\nTemporal Similarity Search fundamentals and applications\nImplementing TSS for time-series data analysis\nHybrid Search techniques combining dense and sparse vector search\nOptimizing search performance for complex data scenarios\nThrough practical examples and real-world use cases, you'll learn to:\nApply TSS to uncover patterns in time-dependent datasets\nImplement both transformed and non-transformed TSS\nLeverage Hybrid Search to improve search accuracy and relevance for unstructured data retrieval\nOptimize your search pipelines for multi-modal data retrieval\nReal-time anomaly detection with non-transformed TSS\nBy the end of this course, you'll have the advanced skills to implement cutting-edge search solutions for time-series data and complex multi-modal datasets, opening up new possibilities in finance, IoT, and other time-sensitive domains.\nThis course is ideal for developers and data scientists who already have a basic understanding of vector databases and want to expand their expertise. Join me to master these advanced techniques and stay at the forefront of vector search technology!",
      "target_audience": [
        "Data scientists and developers familiar with vector databases who want to master Hybrid Search and Temporal Similarity Search. Ideal for professionals working with time-series data or complex multi-modal datasets seeking to implement advanced search techniques using KDB AI."
      ]
    },
    {
      "title": "Introduction to Natural Language Processing - NLP in 1 hour",
      "url": "https://www.udemy.com/course/introduction-to-natural-language-processing-nlp-llm-ai-gate-moyyn/",
      "bio": "For jobseekers and career change aspirants - including AI Fundamental Module - Learn from Industry Leaders",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "No previous knowledge required! Suitable for candidates from any domain."
      ],
      "description": "Welcome to 'Introduction to the world of NLP, a first-of-its kind short program designed for jobseekers and career change aspirants.\nThis course is specifically created as a JOB-BASED TRAINING  program thereby teaching concepts hands-on and relevant to real-work environment. If you are looking for a job in Data Science, NLP or AI if you are a student who would like to get first experience in this domain, this course is exactly for you to understand about this domain before starting in-depth training.\n\n\nExtra Module and Benefits:\nAI Fundamentals and Applications:\nUnlock exclusive access to one of our AI modules Learn from our experts leveraging AI to enhance your productivity and understand the wide variety of applications of AI across industries\n\n\nTrainers:\nDr. Chetana Didugu - Germany\nDr. Chetana Didugu is an Experienced Data Scientist, Product Expert, and PhD graduate from IIM Ahmedabad. She has worked 10+ years in various top companies in the world like Amazon, FLIX, Zalando, HCL, etc in topics like Data Analysis and Visualisation, Business Analysis, Product Management, Product Analytics & Data Science. She has trained more than 100 students in this domain till date.\n\n\nAravinth Palaniswamy - Germany\nFounder of 2 startups in Germany and India, Technology Consultant, and Chief Product Officer of Moyyn, and has 10+ years of experience in Venture Building, Product and Growth Marketing.",
      "target_audience": [
        "Students",
        "Jobseekers",
        "Career switchers",
        "Entrepreneurs",
        "Open to all"
      ]
    },
    {
      "title": "Microsoft Fabric - Curso Completo de Microsoft Fabric",
      "url": "https://www.udemy.com/course/microsoft-fabric-curso-completo-de-microsoft-fabric/",
      "bio": "La plataforma completa para Ingeniería de Datos, Ciencia de Datos, Business Intelligence, Análisis en Tiempo Real y más!",
      "objectives": [
        "Obtener conocimientos fundamentales sobre gobernanza de datos, almacenamiento, procesamiento, transformación y análisis de datos en Fabric",
        "Gestionar el almacenamiento y el acceso a la información a través de Lakehouse, Warehouse, SQL Enpoint o Bases de Datos KQL",
        "Diseñar procesos de ETL para gestionar de forma eficiente todo el ciclo de vida del dato en Fabric",
        "Crear informes de Power BI que consuman información de los más de 150 conectores con fuentes de datos que tiene Microsoft Fabric",
        "Transformar Datos con Data Flow y Power Query",
        "Ejecutar consultas SQL o KQL sobre unidades de almacenamiento de Fabric",
        "Ingerir datos en streaming de dispositivos IoT en Azure Event Hubs",
        "Definir alertas y automatizar procesos con Data Activator y Microsoft Power Automate",
        "Diseñar soluciones de análisis de datos en tiempo real combinando Bases de Datos KQL, Azure Event Hubs, Eventstream, Power BI y mucho más",
        "Utilizar el framework Apache Spark para ejecutar código Python, SQL y otros lenguajes en cuadernos de Microsoft Fabric"
      ],
      "course_content": {},
      "requirements": [
        "No se requiere experiencia previa. En el curso aprenderás todo lo que necesitas saber para crear todo tipo de soluciones con datos en Microsoft Fabric"
      ],
      "description": "¿Qué objetivo tiene el curso?\nEl principal objetivo del curso es dar a conocer el funcionamiento de Microsoft Fabric y convertirte en todo un experto en el uso de la plataforma de referencia en el mundo del análisis de datos.  Obtendrás conocimientos fundamentales sobre gobernanza de datos, almacenamiento, procesamiento, transformación y análisis de datos. Y a su vez, a través de ejercicios totalmente prácticos, crearás productos de datos que resuelvan necesidades de negocio concretas utilizando todos y cada uno de los componentes que conforman la plataforma.\n\n\n¿Qué es Microsoft Fabric?\nMicrosoft Fabric es una plataforma integral que abarca desde la ingeniería de datos (data engineering), hasta la ciencia de datos (data science), pasando por el análisis de datos en tiempo real o la inteligencia de negocio (business intelligence). Nace con el fin de reunir, organizar y analizar los datos en un único lugar, para finalmente tomar decisiones sobre ellos. Integra tecnologías como Azure Data Factory, Azure Synapse Analytics y Power BI para poder aprovechar al máximo el potencial de los datos de las organizaciones, y además, ser el punto de partida para el uso de la IA.\n\n\nCaracterísticas Principales de Microsoft Fabric\nSolución Integral: Microsoft Fabric unifica todas las capacidades de datos y análisis en una sola plataforma, eliminando la necesidad de utilizar múltiples servicios de diferentes proveedores.\nOneLake: Ofrece un depósito unificado de datos llamado OneLake que almacena datos en cualquier formato o fuente, permitiendo un acceso y análisis centralizados.\nAnálisis en Tiempo Real: Proporciona la capacidad de realizar análisis en tiempo real a medida que se ingieren datos desde diversas fuentes, lo que es crucial en un entorno de datos en constante evolución.\nGestión y Gobierno Unificados: Adopta una arquitectura de lakehouse que combina características de almacén de datos y data lake, lo que facilita la gestión, la colaboración y la seguridad de los datos.\nIntegración de AI: Incorpora capacidades de inteligencia artificial en todos los niveles de la plataforma, permitiendo a los usuarios aprovechar el poder de la IA para automatizar tareas y crear modelos.\nSeguridad y Cumplimiento: Ofrece una sólida seguridad y cumple con las regulaciones, incluyendo características como resiliencia, acceso condicional y etiquetas de servicio.\nEscalabilidad y Costo-Efectividad: Es altamente escalable y utiliza un modelo de pago por uso, lo que permite a las organizaciones ajustar los recursos según sus necesidades dinámicas.\nFacilidad de Uso: Está diseñado para ser fácil de usar, incluso para aquellos con conocimientos técnicos limitados, lo que acelera la adopción de datos y análisis en la organización.\nMejora de la Calidad de Datos: Ofrece herramientas para mejorar la calidad de los datos, incluyendo integración simplificada, limpieza de datos y validación de datos.\n\n\n¿En qué va a ayudarte este curso?\nEntender los conceptos fundamentales de Microsoft Fabric. Aprenderás sobre su arquitectura, la gobernanza de información y los componentes que conforman este increíble ecosistema. Descubrirás lo que significa disponer de todos los datos almacenados en formato Delta-Parquet en OneLake, el origen de datos único de la plataforma y que garantiza una única fuente de la verdad.\nGestionar el almacenamiento y el acceso a la información. Aunque los datos se almacenen en OneLake, lo emocionante es que puedes acceder a ellos de múltiples formas y a través de todos los componentes que conforman la plataforma, ya sean bases de datos como un LakeHouse o WareHouse, scripts diseñados en Spark o Python, queries de SQL o KQL, e incluso herramientas de análisis de datos como Power BI.\nDiseñar procesos de ETL para gestionar el ciclo de vida del dato. Todos los componentes involucrados en alguna parte del proceso de ciclo de vida del dato en Fabric están alojados en la propia plataforma, y eso lleva la eficiencia en el procesamiento de datos a otro nivel, pudiendo así optimizar todos y cada uno de los pasos de una ETL (Extract, Transform and Load). Aprenderás a diseñar pipelines que permiten a los analistas y equipos de analítica avanzada controlar cada fase de ejecución de un proceso de datos, pudiendo así identificar y solucionar problemas al instante.\nSi eres un experto en datos o trabajas en proyectos de analítica avanzada te encantará descubrir como con una plataforma como Microsoft Fabric, serás capaz de agilizar en gran medida todo tipo de acción aplicada en cualquier parte del ciclo del dato.\nTransformar Datos con Data Flow y Power Query. Aprenderás a utilizar lenguaje M y herramientas como Power Query para aplicar transformaciones que estructuren la información y la dejen lista para crear todo tipo de productos de datos, ya sean reportes de Business Intelligence, modelos de machine learning, y otros muchos más.\nUtilizar Power BI como herramienta referencia en Business Intelligence. Microsoft Fabric incorpora también Power BI, la herramienta líder del mercado en Business Intelligence y visualización de datos. Y es que las empresas están mejorando en gran medida la toma de decisiones de negocio gracias a disponer de información actualizada en tiempo real en la plataforma. Diseñarás reportes y crearás dashboards en Power BI que utilicen los más de 150 conectores que tiene disponibles Fabric para consumir información de múltiples fuentes simultáneamente.\nDefinir Alertas y Automatizar Procesos. Descubrirás cómo usar Data Activator para crear alertas y automatizaciones que garanticen una buena monitorización de la información. Incluso aprenderás a vincular Data Activator con otras herramientas como Power Automate, permitiendo así automatizar cualquier proceso e integrar Fabric con otras aplicaciones del entorno Microsoft o externas.\nEjecutar procesos de ingeniería de datos (Data Engineering). Implementarás y ejecutarás scripts de código Python, Spark o SQL en Fabric para maximizar la eficiencia de tus procesos y así poder sacar el máximo partido a los datos. Y es que Fabric no es solo un almacén de datos, sino una plataforma de cómputo muy potente, alojada en la nube y que trabaja bajo el concepto serverless (sin servidor), que te permitirá olvidarte de todo lo que supone montar y configurar la infraestructura de un ecosistema de ese calibre. Agilizarás en gran medida todos tus procesos de ingeniería de datos, ya que Fabric está listo para que los expertos en datos se puedan dedicar des del primer minuto específicamente a tareas que aporten valor a los negocios, como diseñar, implementar y ejecutar productos de datos combinando herramientas de BI, con frameworks como Apache Spark, o lenguajes como Python, SQL, entre otros.\nDescubrir cómo Diseñar Modelos de Machine learning en Fabric (Data Science). Microsoft Fabric permite crear, implementar y poner en marcha modelos de aprendizaje automático rápidamente. Se integra con Azure Machine Learning para proporcionar un registro de modelos y seguimiento de experimentos integrado. Los científicos de datos están focalizados en enriquecer los datos de la organización con predicciones y al disponer de todas las herramientas unificadas bajo una misma plataforma podrán colaborar con los analistas de datos para integrar de forma nativa esas predicciones en sus informes de Power BI.\nAnalizar Datos en Tiempo Real. Vas a descubrir también la verdadera magia que esconde la plataforma, que es la capacidad de analizar datos en tiempo real, pudiendo ingerir en streaming todo tipo de información generada por cualquier dispositivo conectado a internet, lo que se conoce como IoT (o Internet of Things). Para ello aprenderás a trabajar con bases de datos KQL en las que podrás consultar todo tipo de información a través de queries Kusto que te permitirán estructurar los datos para poder consumirlos en otros productos que serás capaz de diseñar dentro de la propia plataforma.\n\n\nContenido y Descripción General\nEl curso es apto para todos los niveles. Empezaremos definiendo los conceptos fundamentales de Microsoft Fabric y descubriendo las herramientas que conforman la plataforma, entendiendo en qué puede ayudarnos en nuestra vida laboral o en nuestros proyectos. Aunque eso no significa que no tratemos funcionalidades avanzadas o que nos quedemos en el nivel inicial, de hecho, el curso va incrementando la dificultad y en los ejercicios prácticos de cada módulo iremos utilizando todo lo aprendido en las clases anteriores.\nTodo el proceso de aprendizaje gira entorno a la aplicación de Fabric en el mundo empresarial, y te proporcionará una inmersión completa en plataforma, abordando desde los conceptos fundamentales hasta la implementación práctica en situaciones de negocio reales. A través de módulos que abarcan desde la comprensión esencial de las bases de datos, la ingeniería de datos, los procesos de ETL, el business intelligence, la automatización de procesos o el análisis de datos en tiempo real. Obtendrás los conocimientos y habilidades necesarias para convertirte en todo un experto en la plataforma y aprovechar al máximo su potencial en tus proyectos.",
      "target_audience": [
        "Todos quienes deseen descubrir cómo Microsoft Fabric puede llevar el análisis de datos al máximo nivel y convertir a cualquier organización que adopte la plataforma en una entidad data-driven",
        "Apasionados del mundo del data que quieran descubrir una nueva forma de trabajar en un ecosistema end to end que cubre todo el proceso del dato de inicio a fin",
        "Interesados en diseñar soluciones digitales con datos en Microsoft Fabric para resolver necesidades concretas de sus empresas o proyectos en los que esten involucrados",
        "Interesados en obtener una visión global de Microsoft Fabric, una plataforma con infinidad de posibilidades, tanto a nivel conceptual como a nivel práctico",
        "Estudiantes que quieran destacar y convertirse en expertos en una habilidad cada vez más relevante en el mercado laboral"
      ]
    },
    {
      "title": "Programmer en Python pour la Data Science de A à Z",
      "url": "https://www.udemy.com/course/data-science-avec-python/",
      "bio": "Apprenez à programmer en Python et à utiliser NumPy, Pandas, Matplotlib et Seaborn pour faire de la Data Science.",
      "objectives": [
        "Utiliser Jupyter",
        "Programmer en Python",
        "Récupérer des données et les intégrer dans son environnement de travail",
        "Connaitre les différentes structures de données (listes, dictionnaires, tableaux, dataframes, ...)",
        "Manipuler efficacement des données avec Python et la librairie Pandas",
        "Explorer et visualiser des données avec Matplotlib et Seaborn",
        "Utiliser Python pour faire de la data science"
      ],
      "course_content": {
        "Introduction et mise en place du cours": [
          "Introduction",
          "Installation de l'environnement de travail (Windows, Mac, Linux)",
          "Les bibliothèques Python essentielles à la Data Science",
          "Prise en main du tableau de bord de Jupyter Notebook",
          "Prise en main des notebooks de Jupyter Notebooks"
        ],
        "Les bases de Python": [
          "Les variables",
          "Les types de données (numériques)",
          "Les types de données (booléens)",
          "Les types de données (caractères)",
          "Les opérateurs arithmétiques",
          "Qu'est-ce qu'une fonction ?",
          "Qu'est-ce qu'une bibliothèque ?",
          "Importer une bibliothèque et utiliser ses fonctions",
          "Testez vos connaissance sur les bases de Python"
        ],
        "Les listes en Python": [
          "Introduction aux listes",
          "Accéder aux éléments d'une liste (slicing)",
          "Ajouter/modifier/supprimer des éléments d'une liste",
          "Diverses manipulations des listes (tri, somme, concaténation, ...)",
          "Introduction sur les tuples",
          "Introduction : exercice sur les listes",
          "Correction : exercice sur les listes"
        ],
        "Les bases de la programmation en Python": [
          "Les opérateurs relationnels et logiques",
          "Les instructions de condition (if..else)",
          "Boucle for",
          "Boucle while",
          "Introduction de l'exercice : manipuler la liste des prix de 58 maisons",
          "Correction de l'exercice : manipuler la liste des prix de 58 maisons",
          "Créer sa propre fonction en Python"
        ],
        "Les dictionnaires en Python": [
          "Introduction aux dictionnaires",
          "Ajouter/modifier/supprimer des éléments d'un dictionnaire",
          "Parcourir un dictionnaire",
          "Introduction : exercice sur les dictionnaires",
          "Correction : exercice sur les dictionnaires"
        ],
        "Utilisation de la bibliothèque NumPy": [
          "Introduction à NumPy",
          "Création des tableaux NumPy (ndarray)",
          "Notions de vues et copies d'un tableau",
          "Accéder aux éléments d'un array (slicing)",
          "Explorer et filtrer un array",
          "Concaténation des arrays avec NumPy",
          "Split (cassure) des arrays avec NumPy",
          "Calculs sur les arrays",
          "Exercice : manipuler un array de 20 maisons vendues en 2008 aux Etats-Unis",
          "Correction : manipuler un array de 20 maisons vendues en 2008 aux Etats-Unis"
        ],
        "Utilisation de la bibliothèque Pandas pour manipuler les données": [
          "Introduction à la bibliothèque Pandas",
          "Les séries avec Pandas",
          "Les Dataframes avec Pandas",
          "Lire et écrire un fichier",
          "Accéder aux éléments d'un Dataframe",
          "Ajouter/supprimer des colonnes d'un dataframe",
          "Explorer un Dataframe",
          "Filtrer un Dataframe selon des conditions",
          "Grouper un Dataframe sur une ou plusieurs colonnes (groupby)",
          "Introduction de l'exercice : étudier le marché Android via le Google play store",
          "Correction de l'exercice : étudier le marché Android via le Google play store"
        ],
        "Utilisation de Matplotlib et Seaborn pour la visualisation de données": [
          "Importation et description des données de vente du Black Friday",
          "Créer son premier graphique",
          "Ajouter un titre principal et des labels aux axes",
          "Changer les couleurs (et colorer selon certaines variables)",
          "Changer la taille ou la forme des points",
          "Enregistrer son graphique",
          "Les différents types de graphes",
          "Combiner plusieurs graphiques (subplots)",
          "Créer des graphiques avec Seaborn",
          "Exercice : visualiser les données de vente d'un magasin le jour du Black Friday",
          "Correction : visualiser les données d'un magasin le jour du Black Friday",
          "Fin du cours - Remerciements et conseils"
        ],
        "BONUS": [
          "Coupon : apprendre la Data Science avec R de A à Z",
          "Coupon : apprendre la Data Science avec R de A à Z",
          "Les notebooks du cours",
          "Aide mémoire Pandas",
          "Aide mémoire Matplotlib",
          "Mon livre aux éditions ENI : Python pour la Data Science"
        ]
      },
      "requirements": [
        "Un ordinateur",
        "Une connexion internet pour installer les outils et récupérer des jeux de données",
        "Aucunes connaissances requises en programmation, je pars du début !"
      ],
      "description": "Ce cours est dédié à l'apprentissage de la programmation en Python appliqué à la Data Science. Si vous avez envie d'apprendre à coder, d'apprendre à manipuler de la data ou les deux, alors n'hésitez pas, ce cours est un concentré de tout ça !\nCe cours de 8 heures vous permettra dans un premier temps d'acquérir les outils nécessaires pour coder en Python et faire de la Data Science. Puis il enchaînera sur la partie théorique de la programmation en Python, avec des exercices à chaque étape, afin de comprendre la théorie en pratiquant. Enfin, vous apprendrez à manipuler et explorer/visualiser des données efficacement.\nA la fin de ce cours, vous serez capable d'aller récupérer un jeu de données qui vous intéresse et de l'analyser de A à Z pour en sortir les informations qui vous intéresse.\nJ'espère que ce cours vous plaira, j'ajouterai d'avantage de cas pratiques au fur et à mesure pour le rendre encore plus complet qu'il ne l'est déjà. Le but de ce cours de Data Science est réellement de vous apprendre à programmer en Python, de vous faire pratiquer afin de devenir totalement autonome pour analyser tous les jeux de données qui vous intéresse. Et je compte bien vous aider à chaque étape pour arriver à cette finalité !\nPourquoi utiliser Python ?\nCe cours est dédié à Python pour la simple et bonne raison que c'est un des langages les plus utilisés en Data Science. De plus, c'est un langage que je maîtrise et qui a fait ses preuves pour résoudre tout mes problèmes d'analyse de données. Mais aussi parce que c'est un langage de programmation libre, intuitif et très bien documenté.\nJe veux que ce cours soit le plus complet possible. Ainsi, n'hésitez surtout pas à me contacter si vous avez la moindre question ou la moindre remarque sur ce cours. C'est aussi grâce à vous que je pourrais l'améliorer et le faire évoluer. Mon objectif est réellement de vous aider à devenir un Data Scientist autonome et passionné !\nLogo conçu par Katemangostar de Freepik.",
      "target_audience": [
        "Les personnes souhaitant apprendre à programmer en Python",
        "Les personnes souhaitant apprendre à faire de la Data Science avec Python",
        "Les personnes intéressées par la Data Science en général"
      ]
    },
    {
      "title": "Машинное обучение в Python: Machine Learning & Data Science",
      "url": "https://www.udemy.com/course/python-machine-learning-data-science-russian/",
      "bio": "Изучите NumPy, Pandas, Matplotlib, Seaborn, Scikit-Learn и многое другое! Осваивайте Искусственный Интеллект на практике",
      "objectives": [
        "Построение моделей машинного обучения с учителем (Supervised Learning)",
        "Применение NumPy для работы с числами в Python",
        "Применение Seaborn для создания красивых графиков визуализации данных",
        "Применение Pandas для манипуляции с данными в Python",
        "Применение Matplotlib для детальной настройки визуализаций данных в Python",
        "Конструирование признаков (Feature Engineering) на реалистичных примерах",
        "Алгоритмы регрессии для предсказания непрерывных переменных",
        "Навыки подготовки данных к машинному обучению",
        "Алгоритмы классификации для предсказания категориальных переменных",
        "Создание портфолио проектов машинного обучения и Data Science",
        "Работа с Scikit-Learn для применения различных алгоритмов машинного обучения",
        "Быстрая настройка Anaconda для работ по машинному обучению",
        "Понимание полного цикла этапов работ по машинному обучению"
      ],
      "course_content": {
        "Вводная часть курса": [
          "Добро пожаловать на курс!",
          "ОБЗОР КУРСА - НЕ ПРОПУСКАЙТЕ ЭТУ ЛЕКЦИЮ",
          "Скачиваем слайды для презентаций (ОПЦИОНАЛЬНО)",
          "Установка Anaconda, Python, Jupyter Notebook",
          "Прочтите эту статью - Замечание о настройке среды разработки",
          "Настройка среды разработки",
          "Часто Задаваемые Вопросы"
        ],
        "ОПЦИОНАЛЬНО: Экспресс-курс по Python": [
          "Опционально: Экспресс-курс по Python",
          "Экспресс-курс по Python - Часть 1",
          "Экспресс-курс по Python - Часть 2",
          "Экспресс-курс по Python - Часть 3",
          "Проверочные упражнения по Python",
          "Решения для проверочных упражнений по Python"
        ],
        "Этапы работ по машинному обучению": [
          "Этапы работ по машинному обучению"
        ],
        "NumPy": [
          "Обзор раздела про NumPy",
          "Массивы NumPy",
          "Индексация и выбор данных из массивов NumPy",
          "Операции в NumPy",
          "Проверочные упражнения по NumPy",
          "Решения для проверочных упражнений по NumPy"
        ],
        "Pandas": [
          "Обзор раздела про Pandas",
          "Series - Часть 1",
          "Series - Часть 2",
          "Датафреймы - Часть 1 - Создание датафреймов",
          "Датафреймы - Часть 2 - Основные атрибуты",
          "Датафреймы - Часть 3 - Работа с колонками",
          "Датафреймы - Часть 4 - Работа со строками",
          "Выборка данных по условию (Conditional Filtering)",
          "Полезные методы - Apply для одной колонки",
          "Полезные методы - Apply для нескольких колонок",
          "Полезные методы - Статистическая информация и сортировка данных",
          "Отсутствующие данные (missing data) - Обзор",
          "Отсутствующие данные (missing data) - Операции в Pandas",
          "Агрегация данных GROUP BY - Часть 1",
          "Агрегация данных GROUP BY - Часть 2 - Мульти-индекс",
          "Объединение датафреймов - Конкатенация",
          "Объединение датафреймов - Inner Merge",
          "Объединение датафреймов - Left и Right Merge",
          "Объединение датафреймов - Outer Merge",
          "Методы Pandas для текста",
          "Методы Pandas для даты и времени",
          "Input/Output в Pandas - CSV-файлы",
          "Input/Output в Pandas - HTML-таблицы",
          "Input/Output в Pandas - Excel-файлы",
          "Input/Output в Pandas - SQL базы данных",
          "Сводные таблицы в Pandas (pivot tables)",
          "Проверочные упражнения по Pandas",
          "Решения для проверочных упражнений по Pandas"
        ],
        "Matplotlib": [
          "Обзор раздела про Matplotlib",
          "Основы Matplotlib",
          "Объект Figure - принципы работы",
          "Объект Figure - код в Python",
          "Объект Figure - параметры",
          "Subplots - несколько графиков рядом друг с другом",
          "Стилизация Matplotlib: легенды",
          "Стилизация Matplotlib: цвета и стили",
          "Дополнительные материалы по Matplotlib",
          "Проверочные упражнения по Matplotlib",
          "Решения для проверочных упражнений по Matplotlib"
        ],
        "Seaborn": [
          "Обзор раздела про Seaborn",
          "Scatterplots - Графики рассеяния (диаграммы рассеяния)",
          "Distribution Plots - Часть 1 - Типы графиков",
          "Distribution Plots - Часть 2 - Код в Python",
          "Categorical Plots - Статистики по категориям - Типы графиков",
          "Categorical Plots - Статистики по категориям - Код в Python",
          "Categorical Plots - Распределения по категориям - Типы графиков",
          "Categorical Plots - Распределения по категориям - Код в Python",
          "Графики сравнения - Типы графиков",
          "Графики сравнения - Код в Python",
          "Seaborn Grid",
          "Матричные графики",
          "Проверочные упражнения по Seaborn",
          "Решения для проверочных упражнений по Seaborn"
        ],
        "Большой Проект по Визуализации Данных": [
          "Обзор Проекта по Визуализации Данных",
          "Разбор решений проекта - Часть 1",
          "Разбор решений проекта - Часть 2",
          "Разбор решений проекта - Часть 3"
        ],
        "Обзор Машинного Обучения": [
          "Обзор раздела",
          "Зачем нужно машинное обучение",
          "Типы алгоритмов машинного обучения",
          "Процесс для обучения с учителем (supervised learning)",
          "(ОПЦИОНАЛЬНО) Дополнительная книга для чтения - ISLR"
        ],
        "Линейная Регрессия": [
          "Обзор раздела про линейную регрессию",
          "Линейная регрессия - История алгоритма",
          "Наименьшие квадраты",
          "Функция стоимости (Cost Function)",
          "Градиентный спуск (Gradient Descent)",
          "Простая линейная регрессия",
          "Обзор Scikit-Learn",
          "Scikit-Learn - Train Test Split",
          "Scikit-Learn - оценка работы модели",
          "Графики остатков - Residual Plots",
          "Внедрение модели и интерпретация коэффициентов",
          "Полиномиальная регрессия - теория",
          "Полиномиальная регрессия - создание признаков",
          "Полиномиальная регрессия - обучение и оценка модели",
          "Дилемма смещения-дисперсии (Bias-Variance Trade-Off)",
          "Полиномиальная регрессия - выбираем степень полинома",
          "Полиномиальная регрессия - внедрение модели",
          "Регуляризация - обзор",
          "Масштабирование признаков (feature scaling)",
          "Кросс-валидация - обзор",
          "Регуляризация - подготовка данных",
          "L2 Регуляризация - Ридж-регрессия - теория",
          "L2 Регуляризация - Ридж-регрессия - код в Python",
          "L1 Регуляризация - Лассо-регрессия - теория и код в Python",
          "L1 и L2 Регуляризация - Эластичная сеть Elastic Net",
          "Обзор данных для проверочного проекта по линейной регрессии"
        ]
      },
      "requirements": [
        "Базовые знания Python (на уровне функций)"
      ],
      "description": "Добро пожаловать на самый полный курс по Машинному Обучению и Data Science!\nЭтот курс - лучший способ начать с нуля и стать специалистом по Data Science и машинному обучению с помощью Python.\nЭтот объёмный курс может заменить Вам целый набор других курсов, которые могут стоить в десятки раз больше.\nВ этом курсе Вы изучите следующие темы:\nПрограммирование в Python (экспресс-курс)\nNumPy в Python\nДетальное изучение Pandas для анализа и предварительной обработки данных\nДетальное изучение Seaborn для визуализации данных (включая Matplotlib для кастомизации графиков)\nМашинное обучение с помощью SciKit Learn, включая следующие темы:\nLinear Regression - Линейная Регрессия\nRegularization - Регуляризация\nLasso Regression - Лассо-Регрессия\nRidge Regression - Ридж-Регрессия\nРегуляризация Elastic Net\nLogistic Regression - Логистическая регрессия\nK Nearest Neighbors - Метод К-ближайших соседей\nDecision Trees - Деревья решений\nRandom Forests - Случайные леса\nAdaBoost, GradientBoosting - Адаптивный бустинг, Градиентный бустинг\nNatural Language Processing - Обработка языковых данных\nK Means Clustering - Кластеризация К-средних\nHierarchical Clustering - Иерархическая кластеризация\nDBSCAN (Density-based spatial clustering of applications with noise) - Кластеризация на основе плотности данных\nPCA - Principal Component Analysis - Метод главных компонент\nИ многое, многое другое!\nВнутри курса находится набор блокнотов Jupyter Notebook с русском языке с примерами кода и детальным описанием. Для каждой лекции это отдельные блокноты, которые разложены по папкам с соответствии с разделами курса.  Так что Вы сможете не только просмотреть видео-лекции, но и прочитать блокноты.  Это особенно удобно, когда Вам нужно что-то вспомнить или быстро пробежаться по материалу в поисках нужной информации.\nКак всегда, мы очень ценим возможность стать Вашими инструкторами по Data Science, машинному обучению и Python. Надеемся, что Вы запишетесь на этот курс и прокачаете Ваши навыки!",
      "target_audience": [
        "Начинающие разработчики Python, интересующиеся машинным обучением и Data Science"
      ]
    },
    {
      "title": "Inteligência Artificial: Sistemas de Recomendação em Python",
      "url": "https://www.udemy.com/course/inteligencia-artificial-sistemas-de-recomendacao-em-python/",
      "bio": "Construa passo a passo no Python um algoritmo para recomendação de filmes parecido com o da Netflix!",
      "objectives": [
        "Entenda os conceitos teóricos sobre os sistemas de recomendação",
        "Aprenda passo a passo na teoria e na prática como funciona a técnica de filtragem colaborativa",
        "Implemente técnicas de recomendação baseadas em usuários e itens",
        "Implemente novos sistemas de recomendação"
      ],
      "course_content": {
        "Introdução e conteúdo do curso": [
          "Introdução aos sistema de recomendação",
          "Conteúdo do curso",
          "Mais sobre Inteligência Artificial"
        ],
        "Busca por usuários similares": [
          "Introdução ao módulo",
          "Instalação das ferramentas",
          "Base de dados de filmes no Python",
          "Testando a base de dados",
          "Gráfico de dispersão dos usuários e filmes",
          "Distância euclidiana",
          "Distância euclidiana no Python",
          "Função para distância euclidiana no Python",
          "Testando a função de distância euclidiana",
          "Retornando a similaridade de todos os usuários"
        ],
        "Recomendação de filmes com filtragem baseada em usuários": [
          "Introdução ao módulo",
          "Como fazer recomendações I",
          "Como fazer recomendações II",
          "Como fazer recomendações III",
          "Função para recomendação no Python",
          "Testando as recomendações",
          "Filmes similares I",
          "Filmes similares II",
          "Melhorando o código fonte",
          "Base de dados do MovieLens",
          "Carregando os dados do MovieLens",
          "Recomendação com MovieLens"
        ],
        "Recomendação de filmes com filtragem baseada em itens": [
          "Introdução",
          "Filtragem baseada em itens",
          "Como fazer recomendações - itens",
          "Função para armazenar os itens similares",
          "Função para recomendação por item",
          "Testando as recomendações",
          "Filtragem baseada em usuários x itens"
        ],
        "Considerações finais": [
          "Considerações finais",
          "Código fonte",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "É recomendado conhecimentos básicos sobre lógica de programação",
        "Conhecimento prévio sobre Python podem ajudar no entendimento, embora não seja um pré-requisito",
        "Não são necessários conhecimentos prévios sobre Inteligência Artificial"
      ],
      "description": "Os sistemas de recomendação são uma importante área da Inteligência Artificial e já tem sido utilizados  comercialmente por diversas empresas. Por exemplo, algoritmos desse tipo  estão rodando quando você assiste um filme na Netflix, quando você  recebe a indicação de um novo livro na Amazon ou então quando você está  no Spotify e aparece aquela música que você estava  procurando! Outros exemplos são a recomendação de pacotes promocionais com descontos em produtos que você tem interesse ou então a recomendação de vídeos no Youtube. Em todos esses casos existem algoritmos inteligentes realizando as recomendações automáticas sem mesmo você perceber!\nBaseado nisso, neste curso você terá uma visão teórica e prática de como esses algoritmos funcionam! Você desenvolverá passo a  passo um algoritmo que utiliza a técnica de filtragem colaborativa  aplicado em um cenário de recomendação de filmes. Em outras palavras:  utilizando uma base de dados de usuários e notas que esses usuários  deram para os filmes, nós poderemos gerar recomendações muito  semelhantes ao algoritmo que a Netflix utilizava! Outra vantagem é que o  mesmo código fonte pode ser utilizado para os mais variados cenários com  pouquíssimas adaptações, ou seja, você pode utilizar o conhecimento  deste curso para criar os seus próprios sistemas! Além disso, também faremos o teste com uma base de dados real do MovieLens com mais de 100.000 registros!\nUtilizaremos a linguagem Python para a construção das funções de recomendação, que é uma das principais linguagens de programação no cenário da Inteligência Artificial! É importante enfatizar que esse curso é de nível iniciante e pode ser considerado um primeiro passo para o entendimento teórico e prático dos sistemas de recomendação. Por isso, todas as funções serão desenvolvidas utilizando os recursos nativos do próprio Python, ou seja, não vamos utilizar bibliotecas específicas de sistemas de recomendação neste curso! E não há problema se você não conhece Python, pois os conceitos serão apresentados de forma que se você tem uma noção básica de lógica de programação conseguirá acompanhar as aulas tranquilamente. É também importante enfatizar que se você trabalha com alguma outra linguagem de programação, o código visto neste curso pode ser facilmente adaptado!\nPreparado(a) para dar um importante passo na sua carreira? Aguardo você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial",
        "Pessoas que desejam iniciar os estudos em sistemas de recomendação"
      ]
    },
    {
      "title": "大規模言語モデル（LLM）の仕組み入門【ChatGPT/GPT-4/Transformer】",
      "url": "https://www.udemy.com/course/llm_mechanism/",
      "bio": "大規模言語モデル（LLM）の背景にある仕組みをコンパクトに学ぶ講座です。ニューラルネットワークの基礎、Transformerの基礎を学んだ上で、ChatGPTなどの仕組みを学びます。生成AIの動作の裏側を想像できるようになりましょう。",
      "objectives": [
        "大規模言語モデル（LLM）の仕組みを基礎から学びます。",
        "ニューラルネットワーク、TransformerなどのLLMのベースを基礎から学びます。",
        "Pythonで書かれたLLMのコードを実行し、文章を生成する体験をします。",
        "難しい数式やコード無しで、大規模言語モデル（LLM）の概要、全体像を把握できます。"
      ],
      "course_content": {
        "LLMの概要": [
          "教材の使用方法",
          "イントロダクション",
          "セクション1の教材",
          "講座の概要",
          "LLMの概要",
          "開発環境について",
          "LLMを使ってみよう！",
          "演習"
        ],
        "ニューラルネットワークの仕組み": [
          "セクション2の教材",
          "Section2の概要",
          "人工知能とは？",
          "ニューラルネットワークの概要",
          "ディープラーニングの概要",
          "様々なニューラルネットワーク",
          "深層学習の実装",
          "演習"
        ],
        "Transformerの仕組み": [
          "セクション3の教材",
          "Section3の概要",
          "自然言語処理の概要",
          "Transformerの概要",
          "Attentionの概要",
          "Transformerの利用",
          "演習"
        ],
        "LLMの仕組み": [
          "セクション4の教材",
          "Section4の概要",
          "LLMの仕組み",
          "LLMの応用",
          "日本語LLMの利用",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "人工知能、機械学習の技術的な知識は不要です。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "2023年6月の環境で解説しています。最新の環境と異なる可能性があります。",
        "Googleのアカウント開設が必要です。",
        "「AIの使いこなし方」の解説はありません。",
        "プログラミングや数学の知識、経験は不要です。",
        "コードを動かすためにGoogle Colaboratoryを使用しますが、ローカル環境はWindowsでもMacでも大丈夫です。"
      ],
      "description": "「大規模言語モデル（LLM）の仕組み入門」は、ChatGPTなどで使われている大規模言語モデル（Large Language Model、LLM）の仕組みについて学ぶ講座です。\nGPT-4などのLLMがどのようにして前世代のモデルを超え、AIの未来を切り開いているのかを掘り下げていきます。\n可能な限り難しい数学は使わず、LLMのコードを実行する体験と共にLLMの基礎を学んでいきます。\n\n\nLLMは現在様々な分野で驚異的な性能を発揮し、幅広く活用されています。\n特にGPT-3.5やGPT-4が使われているChatGPTは、自然言語を使った対話により自然な文章を生成可能なので、大きな注目を集めています。\nまた、LLMは様々なタスクをこなせる汎用性を備えており、これまで人間しかできなかった様々なタスクを任せることが可能になってきています。\n\n\nこの講座では、LLMの概要を学んだ上で、ニューラルネットワークの基礎、Transformerへの発展、LLMの躍進について順を追って学んで行きます。\n世界に巨大なインパクトを与えつつあるLLMの背景を、想像し活用できるようになりましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! 人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. LLMの概要\n→ LLMの概要や、開発環境について学びます。\nSection2. ニューラルネットワークの仕組み\n→ ニューラルネットワークの概要、そして学習の仕組みについて学びます。\nSection3. Transformerの仕組み\n→ LLMのベースであるTransformerの仕組みについて学びます。\nSection4. LLMの仕組み\n→ LLMの仕組みについて解説します。また、ライブラリを使った実装も行います。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryをメインで使用します。",
      "target_audience": [
        "ChatGPTなどの動作原理を基礎から知りたい方。",
        "大規模言語モデル（LLM）の全体像を知りたい方。",
        "大規模言語モデル（LLM）に興味があるけど、学び方が分からない方。",
        "仕事上、大規模言語モデル（LLM）の知識が必要になった方。",
        "AI技術のトレンドに追随したい方。"
      ]
    },
    {
      "title": "Inteligencia Artificial aplicada a Negocios y Empresas",
      "url": "https://www.udemy.com/course/inteligencia-artificial-aplicada-a-negocios-y-empresas/",
      "bio": "Resuelve problemas empresariales del mundo real gracias a los algoritmos de inteligencia artificial",
      "objectives": [
        "Optimizar procesos de negocios y empresas.",
        "Dominar la idea general y la teoría de la IA.",
        "Implementar el algoritmo de Q-learning.",
        "Guardar y cargar un modelo de inteligencia artificial.",
        "Construir un modelo de optimización.",
        "Implementar la detención anticipada del entrenamiento.",
        "Maximizar la eficiencia.",
        "Maximizar los ingresos.",
        "Minimizar los costes.",
        "Implementar el muestreo Thompson.",
        "Implementar algoritmos de Deep Q-learning.",
        "Aprovechar la IA para tomar una mejor decisión.",
        "Construir un entorno de IA desde cero.",
        "Implementar el aprendizaje en línea.",
        "Construir redes neuronales artificiales.",
        "Implementar el análisis de la curva de arrepentimiento."
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Acerca de las valoraciones prematuras en Udemy",
          "Rutas de aprendizaje para Machine Learning e Inteligencia Artificial",
          "Acceso al repositorio Github del curso",
          "Link al repositorio del curso",
          "Cómo sacarle el 100% de provecho a todo el material en Udemy",
          "El libro del curso"
        ],
        "--------------- PARTE 1 - OPTIMIZACIÓN DE PROCESOS INDUSTRIALES ---------------": [
          "Bienvenido a la Parte 1: Optimización de Procesos Empresariales"
        ],
        "Caso Práctico": [
          "Minimización de Costes - Paso 1",
          "Minimización de Costes - Paso 2",
          "Minimización de Costes - Paso 3"
        ],
        "Solución de IA": [
          "Bienvenido a la sección de teoría",
          "Plan de Ataque",
          "Teoría del Deep Q-Learning (I)",
          "Teoría del Deep Q-Learning (II)",
          "Experience Replay",
          "Políticas de Selección de Acción"
        ],
        "Implementación": [
          "Minimización de Costes - Paso 4",
          "Minimización de Costes - Paso 5",
          "Minimización de Costes - Paso 6",
          "Minimización de Costes - Paso 7",
          "Minimización de Costes - Paso 8",
          "Minimización de Costes - Paso 9",
          "Minimización de Costes - Paso 10",
          "Minimización de Costes - Paso 11",
          "Minimización de Costes - Paso 12",
          "Minimización de Costes - Paso 13",
          "Minimización de Costes - Paso 14",
          "Minimización de Costes - Paso 15",
          "Minimización de Costes - Paso 16",
          "Cómo instalar Keras en tu Mac, PC o Linux",
          "Minimización de Costes - Paso 17",
          "Minimización de Costes - Paso 18",
          "Minimización de Costes - Paso 19",
          "Minimización de Costes - Paso 20",
          "Minimización de Costes - Paso 21",
          "Minimización de Costes - Paso 22",
          "Minimización de Costes - Paso 23",
          "Minimización de Costes - Paso 24",
          "Minimización de Costes - Paso 25",
          "Minimización de Costes - Paso 26",
          "Minimización de Costes - Paso 27",
          "Minimización de Costes - Paso 28",
          "Minimización de Costes - Paso 29",
          "Minimización de Costes - Paso 30",
          "Minimización de Costes - Paso 31",
          "Minimización de Costes - Paso 32",
          "Minimización de Costes - Paso 33",
          "Minimización de Costes - Paso 34",
          "Minimización de Costes - Paso 35",
          "Minimización de Costes - Paso 36"
        ],
        "Tarea Final de la Parte 1": [
          "Optimización más eficiente de flujos a través de un almacén"
        ],
        "------------------ PARTE 2: MINIMIZACIÓN DE COSTES ------------------": [
          "Bienvenido a la Parte 2: Minimización de Costes"
        ]
      },
      "requirements": [
        "Matemáticas de bachillerato, aunque son recomendables los cursos de estadística, probabilidad y álgebra lineal de Juan Gabriel Gomila.",
        "Conocimientos básicos de Python."
      ],
      "description": "Estructura del curso:\nParte 1 - Optimización de los procesos de negocios y empresas.\nEstudio de caso: Optimización de los flujos de movimiento de un robot automático en un almacén de comercio electrónico.\nSolución de inteligencia artificial: Q-learning.\nParte 2 - Minimizar los costes.\nEstudio de caso: Minimizar los costes de consumo de energía de un centro de datos.\nSolución de inteligencia artificial: Deep Q-learning.\nParte 3 - Maximizar los ingresos\nEstudio de caso: Maximizar los ingresos de un negocio de venta en línea al por menor\nSolución de inteligencia artificial: Muestreo Thompson.\n\n\nAplicaciones comerciales en el mundo real:\nCon la inteligencia artificial, puedes hacer principalmente tres cosas para cualquier negocio:\nOptimizar los procesos de negocio.\nMinimizar los costes.\nMaximizar los ingresos.\nTe mostraremos exactamente cómo tener éxito en estas aplicaciones, a través de casos de estudio de negocios del mundo real. Y para cada una de estas aplicaciones construiremos una IA por separado para resolver el desafío.\nEn la parte 1 - Optimización de procesos, construiremos una IA que optimizará los flujos de movimiento de un robot automatizado en el interior de un almacén de comercio electrónico.\nEn la parte 2 - Minimizar los costes, construiremos una IA más avanzada que minimizará los costes en el consumo de energía de un centro de datos en más del 50% al igual que Google lo hizo el año 2018 gracias a Deepmind.\nEn la parte 3 - Maximizar los ingresos, construiremos una IA diferente que maximizará los ingresos de un negocio minorista online, haciéndolo ganar más de 1 billón de dólares en ingresos,\nPero eso no es todo, esta vez, y por primera vez, hemos preparado una gran innovación para ti. Con este curso, obtendrás un increíble y valioso recurso adicional para tu carrera:\n¡un libro de 100 páginas que cubre todo lo relacionado con la inteligencia artificial para los negocios!.\nEl libro:\nEste libro incluye:\n100 páginas de explicaciones claras, escritas en un LaTeX hermoso y limpio.\nToda la idea básica y la teoría de la IA incluyendo las matemáticas explicadas en detalle.\nLos tres estudios de caso del curso, y sus soluciones.\nTres modelos diferentes de IA, incluyendo Q-Learning, Deep Q-Learning, y muestreo Thompson.\nPlantillas de códigos.\nLos ejercicios y sus soluciones para que practiques.\nAdemás, muchas técnicas extras y consejos como guardar y cargar modelos, parar antes de tiempo, y mucho más.\n\nConclusión:\nSi quieres conseguir un trabajo bien pagado o crear tu propio negocio exitoso en la IA, entonces este es el curso que necesitas.\nLleva tu carrera en la IA a nuevas alturas hoy con la inteligencia artificial para negocios, el último curso de IA para impulsar tu carrera.",
      "target_audience": [
        "Gente motivada por los negocios, que está ansiosa por aprender cómo aprovechar la IA para optimizar su negocio, maximizar la rentabilidad y la eficiencia.",
        "Profesionales de la IA, que quieren saber qué proyectos pueden ofrecer a sus empleados.",
        "Aspirantes a científicos de datos, buscando formas de analizar casos de negocios y empresas reales para agregar a su portafolio.",
        "Entusiastas de la tecnología interesados en aprovechar el Machine Learning y la inteligencia artificial para resolver problemas de negocios",
        "Consultores, que quieren hacer la transición de las empresas a negocios digitales impulsados por la IA."
      ]
    },
    {
      "title": "Bootcamp ChatGPT Completo do Zero ao Avançado 2025",
      "url": "https://www.udemy.com/course/chatgpt-4-a-masterclass/",
      "bio": "Aprenda Engenharia de Prompt, ChatGPT 5, Automações, Criação de Conteúdo, Produtividade e Aplicações Reais de IA",
      "objectives": [
        "Aprenda o que é o ChatGPT 4, suas capacidades e como ele pode ser usado em diferentes áreas.",
        "Aumentando a Produtividade com o ChatGPT 4: Saiba como usar o ChatGPT 4 para gerenciamento de projetos, tarefas e tempo.",
        "Aprenda a integrar o ChatGPT 4 em projetos de programação, criando chatbots, automatizando processos e melhorando a experiência do usuário.",
        "Marketing com ChatGPT 4: Melhore o engajamento do cliente, promova produtos e serviços e forneça suporte ao cliente.",
        "Treinamento de chatbots com ChatGPT 4: Personalize diálogos e ajuste o chatbot para diferentes públicos.",
        "Implementação e melhores práticas com ChatGPT 4: Implemente o ChatGPT 4 com segurança, privacidade e ética em diferentes contextos."
      ],
      "course_content": {
        "Boas-vindas e Primeiros Passos": [
          "Apresentação do Curso",
          "O que é o ChatGPT e por que ele é tão poderoso",
          "Criando sua conta e acessando o ChatGPT",
          "Interface do ChatGPT: o que você precisa saber",
          "Explorando o Deepsearch, Search e Canvas"
        ],
        "Fundamentos da Conversa com a IA": [
          "Como conversar com o ChatGPT de forma eficiente",
          "Melhores práticas para obter boas respostas",
          "O que são e como usar os GPTs Personalizados",
          "Limitações e cuidados ao usar o ChatGPT"
        ],
        "Aplicações Pessoais e Profissionais do ChatGPT": [
          "Usando o ChatGPT para Produtividade Pessoal e Profissional",
          "50 prompts para aumentar a sua Produtividade com ChatGPT",
          "ChatGPT para estudos: mapas mentais, revisões e explicações",
          "50 prompts para estudar com ChatGPT",
          "ChatGPT como assistente de brainstorming e criatividade",
          "50 prompts para ajudar com brainstorming e criatividade com ChatGPT"
        ],
        "Criação de Conteúdo com ChatGPT": [
          "Criando posts para redes sociais com IA",
          "Roteiros para vídeos e podcasts com ChatGPT",
          "Copywriting e textos persuasivos com IA",
          "Técnicas para manter o estilo e voz da marca"
        ],
        "Engenharia de Prompts — A Arte de Perguntar Bem": [
          "O que é prompt e por que ele é tão importante",
          "Anatomia de um bom prompt",
          "Tipos de prompts: criativos, técnicos, analíticos",
          "Prompts com múltiplas etapas e instruções específicas"
        ],
        "Atualizações": [
          "ChatGPT 5"
        ],
        "ChatGPT com Ferramentas Avançadas (GPT-4 Turbo)": [
          "Como usar o DALL·E para criar imagens com texto"
        ],
        "Iniciando": [
          "Boas Vindas",
          "O ChatGPT vai me substituir?",
          "Quem é a OpenAI?",
          "As versões do ChatGPT"
        ],
        "Para os Nerds": [
          "Inciando esta sessão",
          "Como funciona o LMM",
          "Os diferentes modelos",
          "A API do ChatGPT",
          "ChatGPT é gratuito?",
          "Conhecendo a plataforma do ChatGPT 4",
          "Contexto é tudo"
        ],
        "Prompts": [
          "Gerando ideias",
          "Melhorando algo",
          "Gerando guias",
          "Resumindo qualquer coisa",
          "Tradução",
          "Melhorando suas habilidades",
          "Suporte ao Cliente",
          "Ajuda judicial",
          "Simulando entrevistas",
          "Fazendo analogias",
          "Escrevendo sobre qualquer coisa",
          "Criando debates",
          "Titulos de email",
          "Criando um perfil no LinkedIn",
          "Criando uma musica",
          "Gerando titulo para o Instagram",
          "Gerar mensagens",
          "Me conte uma piada",
          "Criando programas em Python",
          "Corrigindo um código"
        ]
      },
      "requirements": [
        "Não há pré-requisitos"
      ],
      "description": "Curso Bootcamp ChatGPT Completo do Zero ao Avançado\nAprenda a Dominar a Inteligência Artificial que Está Transformando o Mundo\n\n\nVocê já ouviu falar do ChatGPT, mas será que está usando todo o potencial dessa ferramenta revolucionária?\nA inteligência artificial generativa está mudando a forma como trabalhamos, aprendemos, nos comunicamos e criamos soluções. E o ChatGPT é um dos recursos mais poderosos disponíveis hoje — mas apenas para quem sabe usá-lo da maneira certa.\nSe você ainda faz perguntas aleatórias ou usa apenas comandos simples, está aproveitando menos de 10% do poder real do ChatGPT.\n\n\nO que você vai aprender neste curso completo:\n\n\nComo o ChatGPT realmente funciona, incluindo conceitos como modelos de linguagem, tokens e contextos\nComo criar prompts inteligentes, estratégicos e eficazes\nTécnicas para refinar, corrigir, aprimorar e expandir suas conversas com IA\nAprenda como aplicar em áreas como:\n\n\nMarketing digital\nCriação de conteúdo\nNegócios e automação\nEducação e estudos\nProdutividade pessoal\nAtendimento e suporte\n\n\nComo usar o ChatGPT como assistente de escrita, programador, planejador, criador de ideias e muito mais\nIntegrações e formas de combinar o ChatGPT com outras ferramentas de IA para turbinar resultados\n\n\nPor que o ChatGPT é tão poderoso?\n\n\nEle entende linguagem natural com precisão\nPode gerar ideias, planejar, revisar e escrever com você\nEconomiza horas de trabalho repetitivo\nAtua como parceiro criativo, analítico e estratégico\nJá está sendo usado por profissionais em todo o mundo para aumentar produtividade, inovar e ganhar dinheiro\n\n\nEste curso é para você que quer:\n\n\nUsar a IA de forma profissional e eficiente\nAprender com linguagem clara, exemplos reais e foco em aplicação prática\nAutomatizar tarefas, gerar ideias e produzir mais em menos tempo\nTer um diferencial no mercado de trabalho\nGanhar tempo, confiança e domínio sobre a tecnologia do futuro\n\n\nDomine a ferramenta que vai dominar o mercado.\n\n\nO ChatGPT não é só uma moda. Ele é o início de uma nova era.\nE quem aprender a usar agora vai sair na frente de 99% das pessoas que ainda usam IA de forma superficial.\n\n\nAcesso vitalício + Certificado de conclusão incluído\n\n\nGaranta agora sua vaga no Curso ChatGPT Completo do Zero ao Avançado e transforme a maneira como você trabalha, aprende e cria com IA.",
      "target_audience": [
        "Profissionais de marketing: Aprenda a usar chatbots para melhorar o engajamento do cliente e fornecer suporte eficiente.",
        "Desenvolvedores de software: Integre o ChatGPT 4 em projetos, criando chatbots e automatizando processos.",
        "Gerentes de projetos: Use o ChatGPT 4 para gerenciamento de projetos, organização de tarefas e gerenciamento de tempo.",
        "Empreendedores: Use chatbots para melhorar a experiência do cliente e promover produtos e serviços.",
        "Estudantes: Aprenda sobre uma tecnologia inovadora que pode ser aplicada em diferentes áreas.",
        "Curiosos: Descubra tecnologias inovadoras e como elas podem ser aplicadas em diferentes áreas, independentemente de sua área de atuação."
      ]
    },
    {
      "title": "【キカガク流】人工知能・機械学習 脱ブラックボックス講座 - 初級編 -",
      "url": "https://www.udemy.com/course/kikagaku_blackbox_1/",
      "bio": "1000人以上が受講している（株）キカガクの『脱ブラックボックスセミナー』が遂に登場！機械学習の参考書を「閉じてしまった人」への再入門に最適な講座です。微分・線形代数といった数学の基礎からPythonでの実装まで短時間で習得しましょう。",
      "objectives": [
        "機械学習の原理を数学から理解し、プログラミング（Python）で実装できるようになります。",
        "今まで難しそうに見えていた機械学習に用いられる数式の意味を理解できるようになります。",
        "機械学習に関する専門用語も数式と一緒に覚えることができます。",
        "求めた数値を綺麗に可視化する技術を習得することができます。"
      ],
      "course_content": {
        "コース紹介": [
          "コース紹介"
        ],
        "概念の紹介": [
          "機械学習に必要な数学",
          "人工知能・機械学習・ディープラーニングとは？",
          "機械学習の３大トピック",
          "簡単な機械学習と内挿・外挿"
        ],
        "微分": [
          "微分は「何」に使えるのか？",
          "微分（導関数）を求めよう１ - 中学編 -",
          "微分（導関数）を求めよう２ - 高校編 -",
          "微分の公式",
          "偏微分"
        ],
        "単回帰分析": [
          "問題設定 - 部屋の広さから家賃を予測しよう -",
          "Step1：「モデル」を決める",
          "Step2：「評価関数」を決める",
          "Step3：評価関数を「最小化」する"
        ],
        "Python速習": [
          "プログラミングの環境構築",
          "変数",
          "基本構文",
          "複数の変数を扱おう",
          "制御構文",
          "関数"
        ],
        "単回帰分析の実装": [
          "Numpy: 数値計算",
          "Pandas: データベース操作",
          "Matplotlib: グラフの描画",
          "実データに対して単回帰分析を実装しよう",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "プログラミングの経験があると望ましいですが、初心者でも大丈夫。",
        "本コースは、macOSを使用して進めていきますが、Windowsでも同様に進めることができます。",
        "Mac, Windowsの両方の環境構築手順を紹介しています。"
      ],
      "description": "『ゴール逆算により圧倒的短時間で習得しよう』\n\n創業から９ヶ月、受講生の総数１０００人を突破している株式会社キカガクの『脱ブラックボックスセミナー』がUdemy用にアレンジして登場！\n微分・線形代数といった数学の基礎から、Pythonでの実装まで短時間で習得しましょう。\nキカガクこだわりのスタイルである『手書きの数学』『ハンズオン形式のプログラミング』で実際に手を動かしながら学んでいただければ、理解できること間違いなしです。\n初級編では機械学習で必要な数学のエッセンスがたくさん詰まっている「単回帰分析」をゴールに、機械学習の考え方、微分、単回帰分析まで一気通貫で解説します。\n数学は中学校の復習から始め、Pythonも環境構築・プログラミングの文法から解説しますので、初めての方でも学べる内容となっています。\n中級編・上級編とステップアップしながら学ぶことで、データ解析の実務に必要なスキルと考え方が学べる構成となっています。",
      "target_audience": [
        "機械学習の参考書を読んで「閉じて」しまった方",
        "独学で機械学習を学ぼうと思ったけど挫折してしまった方",
        "機械学習の参考書に記載された数式の意味が理解できず、学習をやめてしまった方",
        "中学校で学ぶ数学から始めるので初心者の方、数学が苦手な方でも大丈夫"
      ]
    },
    {
      "title": "Dashboard Analítico Passo-a-Passo em STREAMLIT e PYTHON",
      "url": "https://www.udemy.com/course/dashboard-com-streamlit/",
      "bio": "Aprenda a criar um dashboard incrível com a Framework STREAMLIT, em PYTHON.",
      "objectives": [
        "Aprenda do básico ao Avançado da Framework STREAMLIT",
        "Aprenda grandes conceitos e ferramentas para se tornar um Cientista de Dados.",
        "Crie um Dashboard analítico usando Python e Streamlit para transformar dados em informação de suporte à decisão do negócio",
        "Saiba manipular datasets com o PANDAS, filtrando e manipulando dados do dataframe",
        "Crie visualizações interativas com através de Python e a biblioteca ALTAIR, gerando gráficos poderosos de todos os tipos: Barras, linhas, histogramas, em arco.."
      ],
      "course_content": {
        "Introdução e Configuração do Ambiente": [
          "Introdução",
          "Instalação dos componentes para o ambiente em uso no Curso"
        ],
        "Streamlit: Write & Magic": [
          "O que é o Magic?",
          "Método Write",
          "Elementos de Texto em Geral",
          "Dataframes & Tables",
          "Usando Metrics",
          "Trabalhando com JSON"
        ],
        "Básico de PANDAS": [
          "Tudo que você precisa saber sobre PANDAS - Parte 1",
          "Tudo que você precisa saber sobre PANDAS - Parte 2",
          "Tudo que você precisa saber sobre PANDAS - Parte 3",
          "Tudo que você precisa saber sobre PANDAS - Parte 4"
        ],
        "ALTAIR: Tudo sobre criação de Gráficos": [
          "Introdução ao ALTAIR: Parte 1",
          "Introdução ao ALTAIR: Parte 2",
          "Introdução ao ALTAIR: Parte 3",
          "Como criar Gráfico de Barras",
          "Como criar Gráfico de Linhas",
          "Como criar Gráfico de Área",
          "Como criar Gráficos Circulares (Pizza, Rosca)",
          "Como criar Gráficos de Dispersão",
          "Como criar Histogramas"
        ],
        "Saiba como utilizar os WIDGETS do STREAMLIT": [
          "Widgets: Button, Download e Checkbox",
          "Widgets: Radio Button, Select Box seleção múltipla",
          "Widgets: Slider e Entrada de Dados"
        ],
        "STREAMLIT: Elementos de Mídia e Tema": [
          "Como inserir Imagens, Áudio e Vídeo em sua aplicação",
          "Configuração do SIDEBAR",
          "Utilizando COLUNAS",
          "Como usar o EXPANDER",
          "Como criar um MENU Incrível no STREAMLIT"
        ],
        "Customização. Performance e Controle da Aplicação no STREAMLIT": [
          "Aprenda a configurar o Tema da sua aplicação",
          "Aprenda a utilizar elementos de STATUS",
          "Configuração de START e STOP na aplicação",
          "Use FORMS no STREAMLIT",
          "Configuração da Página Principal",
          "Como usar o CACHE e ganhar velocidade nas aplicações"
        ],
        "PROJETO: DASHBOARD de vendas no STREAMLIT Passo-a-Passo": [
          "Parte 1 - Introdução ao Projeto e Dataset",
          "Parte 2 - Conexão do Dataframe e Filtros no Sidebar",
          "Parte 3 - Data Mining na Criação das Tabelas de Dados para base dos Gráficos",
          "Parte 4 - Criação de todos os Gráficos do Dashboard",
          "Parte 5 - Posicionamento dos Elementos dentro do Dashboard",
          "Parte 6 - Toques Finais para configuração e conclusão do Dashboard"
        ]
      },
      "requirements": [
        "Ter um conhecimento básico de programação em Python",
        "Estar determinado a ser um diferencial de mercado"
      ],
      "description": "Olá Cientista de Dados,\nVocê sabia que as empresas hoje geram 50x mais dados do que a uma década atrás? e que 90% destes dados são mal estruturados e de difícil utilização?\nNão é a toa que a profissão de cientista de dados tem registrado um aumento médio de 37% ao ano nos últimos 6 anos, contratando profissionais a peso de OURO!\nO curso Dashboard Analítico Passo-a-Passo em STREAMLIT e PYTHON vai adicionar muito valor ao seu portfolio como cientista de dados.\nNesse curso você aprenderá a programar em PYTHON na framework STREAMLIT que é consolidada a melhor biblioteca gráfica da web.\nNeste curso você aprenderá:\nSeção 1: Aqui você vai aprender o que é necessário para preparar seu ambiente de trabalho, os aplicativos usados e como instalar as bibliotecas usadas durante o curso.\nSeção 2: Nesta parte você aprenderá como manipular elementos de texto no STREAMLIT e como eles são mostrados na tela.\nSeção 3: uma habilidade essencial para o Cientista de Dados é saber manipular um dataset, extrair e minerar dados. Aqui vamos explorar o PANDAS e entender como manipular o dataframe para uso durante o curso.\nSeção 4:  Como falar de dashboard sem falar em gráficos? Pois aqui veremos como configurar gráficos da biblioteca ALTAIR e como mostrá-los da melhor maneira transformando dados abstratos em informação de negócio.\nSeção 5: Ao final desta seção os alunos serão capazes de aplicar os widgets do STREAMLIT em seus projetos. Os widgets são: Botões, Checkbox, radio button, multi selection, slider, entre outros diversos.\nSeção 6: Continuaremos aprofundando nos elementos do STREAMLIT. Nessa seção veremos como manipular elementos de mídia, como imagens, áudio, vídeo. Iremos também criar um sidebar e um menu incrível.\nSeção 7: Trabalharemos em uma seção mais avançada do STREAMLIT que é configurar elementos para customizar a aplicação e deixá-la alinhada com nossa necessidade.\nSeção 8: finalmente nessa seção iremos criar um dashboard do zero. Faremos um passo-a-passo onde você criará um Dashboard de Vendas, extraindo dados e transformando em informação visual.",
      "target_audience": [
        "Iniciantes em Programação Python",
        "Interessados em gerar visualizações gráficas",
        "Engenheiros de Machine Learning e Cientistas de Dados buscando uma framework prática para seus projetos",
        "Analistas e gestores de empresas que queiram transformar dados abastratos em valiosas informações de negócio"
      ]
    },
    {
      "title": "Inteligência Artificial: Algoritmos Inteligentes de Busca",
      "url": "https://www.udemy.com/course/inteligencia-artificial-algoritmos-inteligentes-de-busca/",
      "bio": "Construa um sistema de busca inteligente de cidades parecido com o que é usado pelo Google Maps para encontrar rotas!",
      "objectives": [
        "Aprenda na teoria e na prática sobre busca sem informação e busca com informação/heurística",
        "Aprenda passo a passo como desenvolver um algoritmos para encontrar a melhor rota entre cidades",
        "Entenda o funcionamento prático dos algoritmos de busca gulosa, busca A* (estrela), busca em largura e busca em profundidade"
      ],
      "course_content": {
        "Conteúdo do curso": [
          "Conteúdo do curso",
          "Mais sobre Inteligência Artificial"
        ],
        "Resolução de problemas por meio de busca": [
          "Introdução ao módulo",
          "Definição de problemas e soluções",
          "Instalação dos softwares",
          "Mapa das cidades",
          "Implementação do mapa das cidades I",
          "Implementação do mapa das cidades II",
          "Código fonte parcial"
        ],
        "Busca sem informação": [
          "Introdução ao módulo",
          "Busca sem informação",
          "Pilha I",
          "Gibi sobre pilhas",
          "Pilha II",
          "Pilha III",
          "Busca em profundidade I",
          "Recursão",
          "Busca em profundidade II",
          "Busca em profundidade III",
          "Busca em profundidade IV",
          "Código fonte parcial",
          "Fila I",
          "Gibi sobre filas",
          "Fila II",
          "Fila III",
          "Fila IV",
          "Busca em largura I",
          "Busca em largura II",
          "Busca em largura III",
          "Busca em largura IV",
          "Resumo dos algoritmos",
          "Código fonte parcial"
        ],
        "Busca com informação": [
          "Introdução ao módulo",
          "Busca com informação",
          "Heurísticas",
          "Alteração no mapa das cidades I",
          "Vetor ordenado I",
          "Vetor ordenado II",
          "Busca gulosa I",
          "Busca gulosa II",
          "Busca gulosa III",
          "Busca A* I",
          "Robô Shakey",
          "Alteração no mapa das cidades II",
          "Busca A* II",
          "Busca A* III",
          "Busca A* IV",
          "Resumo dos algoritmos",
          "Relaxação de problemas",
          "Integração com a API do Google Maps",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "É recomendado conhecimentos básicos sobre lógica de programação, embora não seja um pré-requisito",
        "Não são necessários conhecimentos prévios sobre a linguagem Java"
      ],
      "description": "A resolução de problemas por meio de algoritmos de busca é uma importante ramificação da Inteligência Artificial, sendo responsável por várias aplicações práticas utilizadas em nosso dia a dia, tal como o mecanismo para encontrar a menor rota em um aparelho GPS.\n\nNeste curso você terá uma visão teórica e prática sobre essa área, aplicando todos os conceitos em um projeto prático que terá como objetivo aplicar os algoritmos para encontrar a menor rota entre duas cidades. Utilizaremos duas abordagens: a busca sem informação e a busca com informação. A primeira não apresenta inteligência e é composta pelos algoritmos de busca em largura e profundidade, enquanto que a segunda abordagem será implementada por meio dos algoritmos de busca gulosa e busca A* (A Estrela). Esse último algoritmo é muito utilizado em jogos e foi ele que deu origem à tecnologia de GPS (Global Position System) que muito utilizamos em nosso dia a dia! Utilizaremos a linguagem Java para a implementação do projeto, porém, o código fonte pode ser facilmente portado para outras linguagens. E não há problema se você não conhece a linguagem  Java, pois os conceitos serão apresentados de forma que se você tem uma  noção básica de lógica de programação conseguirá acompanhar as aulas  tranquilamente.\nPreparado(a) para dar um importante passo na sua carreira? Aguardo você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial",
        "Pessoas que querem aprender como os algoritmos inteligentes de busca funcionam na prática"
      ]
    },
    {
      "title": "Python ile Yapay Zeka: A'dan Z'ye Reinforcement Learning (7)",
      "url": "https://www.udemy.com/course/python-ile-yapay-zeka-adan-zye-reinforcement-learning/",
      "bio": "Yapay Zekanın en gizemli konularından biri olan Reinforcement Learning (Pekiştirmeli Öğrenme) ile geleceğe hazırlanın !!",
      "objectives": [
        "Yapay Zeka (Pekiştirmeli Öğrenme) algoritmalarının ardında yatan matematiği, mantığı, teoriyi ve bu algoritmaların Python ile sıfırdan nasıl kodlanacağını",
        "Hem birlikte kodlayacağımız hem de bireysel olarak yapacağınız farklı Yapay Zeka (Pekiştirmeli Öğrenme) projeleri",
        "Bir Yapay Zeka modelinin (Agent) veriye bağlı olmadan kendi kendine nasıl eğitilebileceğini",
        "Q-Learning, Deep Q-Learning gibiYapay Zeka (Pekiştirmeli Öğrenme) algoritmalarını",
        "Yapay Zeka (Pekiştirmeli Öğrenme) algoritmalarını kullanmak için Python ile oyun ortamı (Atari Game) yaratmayı",
        "Dünyada Yapay Zeka (Pekiştirmeli Öğrenme) algoritmalarının nasıl, neden ve ne için kullanıldığını",
        "Kendi başınıza Yapay Zeka (Pekiştirmeli Öğrenme) algoritması geliştirmeyi",
        "İsteğe bağlı (opsiyonlu): EK-1,2,3: Yapay Sinir Ağları, Nesne Tabanlı Programlama, Evrişimsel Sinir Ağları"
      ],
      "course_content": {},
      "requirements": [
        "Artificial Neural Networks (Yapay Sinir Ağları): Bu konu, bu kurs içerisinde EK-1 de anlatılmaktadır. Bu ders videoları isteğe bağlıdır. Eğer konuyu biliyorsanız izlemenize gerek yoktur.",
        "Python ile Nesne Tabanlı Programlama: Bu konu, bu kurs içerisinde EK-2 de anlatılmaktadır. Bu ders videoları isteğe bağlıdır. Eğer konuyu biliyorsanız izlemenize gerek yoktur.",
        "Convolutional Neural Networks (Evrişimsel Sinir Ağları): Bu konu, bu kurs içerisinde EK-3 de anlatılmaktadır. Bu ders videoları isteğe bağlıdır. Eğer konuyu biliyorsanız izlemenize gerek yoktur."
      ],
      "description": "Merhaba arkadaşlar,\nBu kurs 7 adımlık Yapay Zeka yolculuğumuzun nihai hedefi olan Yapay Zeka (Reinforcement Leaning) kursudur.\nPython: Python Sıfırdan Uzmanlığa Programlama (1)\nData Science ve Python: Sıfırdan Uzmanlığa Veri Bilimi (2)\nData Visualization: A'dan Z'ye Veri Görselleştirme (3)\nMachine Learning ve Python: A'dan Z'ye Makine Öğrenmesi (4)\nDeep Learning (Derin Öğrenme)\nStatistical Learning (İstatistik)\nArtificial Intelligence (Yapay Zeka)\nBu Kurs ile Alacaklarınız\nSıfırdan Kodlama Becerisi: Sizinle birlikte kod yazıyoruz. Her ders boş bir sayfa ile başlar ve kodu sıfırdan yazarız. Bu şekilde ilerleyebilir ve kodun nasıl bir araya geldiğini ve her satırın ne anlama geldiğini tam olarak anlayabilirsiniz.\nKodlar ve Şablonları: Kursta oluşturduğumuz her Python şablonlarını ve kodunu indirebilirsiniz. Bu, sizlere hem daha sonra kod üzerinde pratik yapma hem de kendi projelerinizi şablon sayesinde daha kolay bir şekilde yaratma imkanı sağlayacaktır\nTeori ve Mantık: Size yalnızca kod yazmayı değil, hem yazdığımız kodun arkasında yatan mantığı ve teoriyi hem de neden böyle bir kod yazdığımızı anlatıyoruz.\nKurs içi destek: Size sadece video ile ders anlatımı yapmıyoruz. Size destek olmak için profesyonel Veri Bilimcilerinden oluşan bir ekip oluşturduk. Bu da ders ve ya ders dışı sorularınıza en fazla 72 saat içinde yanıt alacağınız anlamına geliyor.\nYapay Zeka(Reinforcement Leaning) kursu içeriği:\nGiriş Bölümü\nReinforcement Learning Giriş\nAnaconda ve Python Kurulumu\nKurs kaynaklarının gösterimi\nQ-Learning\nAgent-Environment-State-Action-Reward\nBellman Equation\nDeterministic vs Stochastic\nMarkov Decision Process\nQ-Learning\nTemporal Difference\nQ-Table/Algoritma\nExploitation vs Exploration\nLiving Penalty\nTaxi Projesi\nFrozen Lake Projesi\nDeep Q-Learning\nQ-Learning vs Deep Q-Learning\nDeep Q-Learning\nExperience Replay\nAdaptive Epsilon Greedy\nCart Pole Projesi\nLunar Lander Projesi\nEnvrionement Design\nGame Design\nPlayer-Sprite-Enemy\nCollision\nEnvironment Design\nDQL Algoritması\nDeep Convolutional Q-Learning\nDeep Convolutional Q-Learning Nedir?\nPong Oyunu Kodlama Planı\nEnvironment Design Sabit Değişkenler\nPong Oyunu İnitializer, Display, Update, Action, Process\nPong Oyunu Train Agent Model Eğitimi\nPong Oyunu Train Agent Sonuçlar\nİçeriğin İngilizce olması sizi yanıltmasın arkadaşlar. Derslerim tamamen Türkçedir.\nHemen kaydolun ve bir an önce başlayalım.",
      "target_audience": [
        "Yapay Zeka öğrenmek isteyen herkes",
        "Yapay Zeka öğrenerek kendini geleceğe hazırlamak ve geleceği şekillendirmek isteyen herkes"
      ]
    },
    {
      "title": "معسكر علم وتحليل البيانات | Data Science & Analysis Bootcamp",
      "url": "https://www.udemy.com/course/data-science-bootcamp/",
      "bio": "أفضل بداية لأي حد عاوز يتعلم ويحترف مجال \"علم وتحليل البيانات\" باستخدام أدوات Python, Power BI, SQL, Tableau, & Excel",
      "objectives": [
        "مقدمة في علم البيانات | Introduction to Data Science",
        "فهم البيانات وتحليلها | Data Literacy & Proficiency",
        "التحول الرقمي والبيانات الضخمة | Digital Transformation & Big Data",
        "بايثون لعلم البيانات | Python for Data Science",
        "أدوات وتقنيات علم البيانات | SQL, Power BI, Tableau, & Excel",
        "استيراد البيانات وتجميعها | Data Importing Basics",
        "معالجة البيانات وتجهيزها | Data Pre-processing Basics",
        "تحليل البيانات | Data Analysis Basics",
        "تصوير البيانات | Data Visualization Basics",
        "مبادئ تعلم الآلة والذكاء الاصطناعي | Machine Learning & Artificial Intelligence Basics"
      ],
      "course_content": {},
      "requirements": [
        "لا توجد أي متطلبات لهذه الدورة"
      ],
      "description": "معسكر علم البيانات (الدورة المكثفة) | Data Science Bootcamp\nمعسكر علم البيانات بنحاول من خلاله نقدم دورة \"مكثفة\" في علم وتحليل البيانات بنحاول من خلالها نغطي كل المفاهيم والتقنيات والأدوات المهمة في المجال زي Python, Power BI, SQL, Tableau Excel .. ونعتبرها مبادرة نسعى من خلالها إلى إثراء المحتوى العربي في هذا المجال من خلال إعداد دورة تدريبية شاملة بشكل تفاعلي وتطبيقي لكل مواضيع وتخصصات هذا المجال .. وبنحاول إن التدريب يكون مناسب للمبتدئين ولأي شخص يرغب في بدء العمل كمحلل بيانات Data Analyst / عالم بيانات Data Science واحتراف هذا المجال من الصفر.\n\n\nالدبلومة بتتميز بالآتي:\n\n\n- التدريب تفاعلي وقائم على النقاشات مع الطلاب\n- خطة واضحة ومنظمة للبدء في المجال من الصفر وحتى احترافه\n- 10 كورسات في كورس واحد\n- أكثر من 30 ساعة تدريبية\n- تطبيقات عملية ومشاريع Case-studies\n- تحميل ملفات التدريب والأكواد Course Materials\n- المحتوى متاح مدى الحياة\n- شهادة بنهاية التدريب\n\n\nبنشرح في الدبلومة التقنيات والأدوات الرئيسية لأي عالم بيانات:\n\n\nCourse (01): Data Science Foundations | Introduction to Data Science & Analysis\nCourse (02): Data Science Foundations | Data Literacy & Proficiency\nCourse (03): Data Science Foundations | Digital Transformation & Big Data Basics\nCourse (04): Data Science Tools | Python for Data Science Basics\nCourse (05): Data Science Tools I SQL, Power BI, Tableau, & Excel\nCourse (06): Data Science Skills | Data Importing Basics\nCourse (07): Data Science Skills | Data Pre-processing Basics\nCourse (08): Data Science Skills | Data Analysis Basics\nCourse (09): Data Science Skills | Data Visualization Basics\nCourse (10): Data Science Skills | Machine Learning Basics\n--\n= (*) تحذير هام: تم بذل مجهود كبير بفضل الله وتوفيقه من قبل م. مصطفى عثمان في إعداد هذا المحتوى الذي يقدم بصفة شخصية لك مقابل الاشتراك، رجاء عدم نسخه أو استخدامه بعيداً عن الموقع أو الإتجار به لإن ذلك يعرضك للمسائلة أمام الله عز وجل .. شكراً لتفهمك، وشكراً لاهتمامك بما نقدمه",
      "target_audience": [
        "أي حد لسة هيبدأ في مجال علم وتحليل البيانات وعاوز يبدأ بداية موفقة"
      ]
    },
    {
      "title": "Microsoft Azure AI Fundamentals: Get started with AI",
      "url": "https://www.udemy.com/course/microsoft-azure-ai-fundamentals-get-started-with-ai-s/",
      "bio": "Learn the fundamentals of Azure AI, and get certified AI-900 with Practice Exam included",
      "objectives": [],
      "course_content": {
        "Get started with AI on Azure": [
          "Introduction to AI",
          "Understand machine learning",
          "Understand anomaly detection",
          "Understand computer vision",
          "Understand natural language processing",
          "Understand knowledge mining",
          "Challenges and risks with AI",
          "Understand Responsible AI",
          "Quiz"
        ],
        "Introduction to Azure OpenAI Service": [
          "Introduction to Azure OpenAI Service",
          "What is generative AI",
          "Describe Azure OpenAI",
          "How to use Azure OpenAI",
          "Understand OpenAI's natural language capabilities",
          "Understand OpenAI code generation capabilities",
          "Understand OpenAI's image generation capabilities",
          "Describe Azure OpenAI's access and responsible AI policies",
          "Quiz"
        ]
      },
      "requirements": [
        "Nothing just Patience and Eager to Learn !"
      ],
      "description": "Microsoft Azure is one of the three most popular cloud computing platforms. Exam AI-900: Microsoft Azure AI Fundamentals is the best certification to get started with Azure. Learn Cloud Computing with Azure.\nWe have designed this amazing course to help you learn the Compute, Storage, Database, and Networking solutions in Azure.\n\n\nMicrosoft Azure is a cloud-based platform for testing, deploying, building and managing applications and services through Microsoft managed the data-center. Azure’s cloud adoption framework provides the customers with a set of tools, guidance, and narratives that help them to shape the technology and business in a way they need to accelerate the business outcome.\n\n\nMicrosoft Azure introduces your cloud environment to tools like threat intelligence, advanced threat analytics, Azure information protection and multi-factor authorization. It helps you to take charge of your customer data by collecting, using and distributing them on your own. With the help of data centers spread all over the world, Azure provides high availability along with redundancy. And on the top of everything, Microsoft Azure is cost effective as well.\n\n\nBenefits Of Azure Certification:\nYou will get to learn the basics of Microsoft Azure\nYou will be well versed about virtual networking skills and its implementation through Microsoft Azure\nYour career will accelerate in no time\nThis certification will be key for you to uncover an entire world of networking which is yet unexplored\nFor someone early in their tech career, the Azure Fundamentals certification can be part of what lifts them from a less technical role into a more technical role, into a more technical role. But without industry experience, the Azure Fundamentals certification isn't necessarily enough to ensure a job.\n\n\nAfter the completion of your certification, you’ll gain have a lot of perks like:\nCareer flexibility\nBetter security offerings\nBetter integration with .Net platform\nHigher salary\nImproved DevOps skills\n\n\nAzure Fundamentals exam is an opportunity to prove knowledge of cloud concepts, Azure services, Azure workloads, security and privacy in Azure, as well as Azure pricing and support. Candidates should be familiar with the general technology concepts, including concepts of networking, storage, compute, application support, and application development.",
      "target_audience": [
        "DevOps Engineers",
        "DevSecOps Engineers",
        "Developers",
        "Cloud Engineers",
        "System Administrator",
        "IT Engineers"
      ]
    },
    {
      "title": "Analyse de Données avec Python: Numpy, Pandas et Matplotlib",
      "url": "https://www.udemy.com/course/manipulation-de-donnees-en-python-maitriser-numpy-pandas-matplotlib/",
      "bio": "Maîtriser les bibliothèques Python pour la Data Science et le Traitement de Données: Numpy, Pandas, Matplotlib, et plus!",
      "objectives": [
        "Utiliser les bibliothèques scientifiques de Python, notamment NumPy, Pandas, et Matplotlib",
        "Utiliser NumPy pour effectuer des analyses statistiques sur vos données (effectuer des comparaisons, sélectionner des éléments, remplacer des valeurs, etc.)",
        "Transformer une colonne à l'aide de Pandas pour manipuler les données. Utilisez le DataFrame Sorter pour trier et normaliser une colonne numérique.",
        "Dessiner, adapter et analyser des courbes basées sur des exemples concrets",
        "Analyser des données du monde réel",
        "Maîtriser des tableaux NumPy (lire un jeu de données, extraire une valeur, extraire un vecteur, extraire une matrice...)",
        "Utiliser Pandas pour lire un jeu de données ou un DataFrame pour l'exploration. Choisissez une colonne ou une ligne pour trier le DataFrame",
        "Réindexer un DataFrame"
      ],
      "course_content": {
        "Rappels sur le langage Python (facultatif)": [
          "Bienvenue au cours",
          "Introduction à Python pour la Data Science",
          "Installation de Python pour la Data Science",
          "Qu'est-ce que Jupyter Notebook ?",
          "Installation d'Anaconda sur Windows, Mac & Ubuntu",
          "Implémentation de Python dans Jupyter",
          "Gestion des Répertoires dans Jupyter Notebook",
          "Entrée-Sortie",
          "Différents Types de Données",
          "Variables",
          "Opérateurs Arithmétiques",
          "Opérateurs de Comparaison",
          "Opérateurs Logiques",
          "Instructions Conditionnelles",
          "Boucles",
          "Séquences : Listes",
          "Séquences : Dictionnaires",
          "Séquences : N-uplets",
          "Fonctions intégrées",
          "Fonctions définis par l'utilisateur",
          "Supports de Cours: Python pour la Data Science"
        ],
        "Bibliothèques Python essentielles pour la science des données": [
          "Installation des bibliothèques",
          "Importation de bibliothèques",
          "Bibliothèque Pandas pour la Data Science",
          "Bibliothèque NumPy pour la Data Science",
          "Pandas vs NumPy",
          "Bibliothèque Matplotlib pour la Data Science",
          "Bibliothèque Seaborn pour la Data Science"
        ],
        "Fondamentaux de NumPy": [
          "Introduction au tableaux NumPy",
          "Création de tableaux NumPy",
          "Indexation des tableaux NumPy",
          "Forme du tableau",
          "Itération sur des tableaux NumPy"
        ],
        "Mathématiques pour la Science des Données": [
          ".zeros()",
          ".ones()",
          ".full()",
          "Addition d'un scalaire",
          "Soustraction d'un scalaire",
          "Multiplication par un scalaire",
          "Diviser par un scalaire",
          "Puissance",
          "Transposée",
          "Addition par éléments",
          "Soustraction par éléments",
          "Multiplication par éléments",
          "Division par éléments",
          "Multiplication matricielle",
          "Statistiques"
        ],
        "Dataframes avec Pandas et Séries": [
          "Qu'est-ce que le DataFrame Pandas ?",
          "Qu'est-ce qu’une Série Pandas ?",
          "DataFrame et Séries",
          "Création d'un DataFrame en utilisant des listes",
          "Création d'un DataFrame à l'aide d'un dictionnaire",
          "Chargement d'un fichier csv en tant que DataFrame",
          "Changer la colonne d'index",
          "Inplace",
          "Examen du Dataframe",
          "Résumé Statistique",
          "Opérateur pour le découpage en rangs",
          "Opérateur pour l'indexation des colonnes",
          "Listes Booléennes",
          "Filtrage des lignes",
          "Filtrer les rangs en utilisant l'opérateur AND et OR",
          "Filtrer avec loc",
          "Filtrer avec iloc pour le découpage en tranches",
          "Ajout et suppression de lignes et de colonnes",
          "Triage des valeurs",
          "Exportation de DataFrame pandas en csv",
          "Concaténation de DataFrames",
          "Groupby()"
        ],
        "Nettoyage des Données": [
          "Introduction",
          "Introduction au nettoyage des données",
          "Qualité des données",
          "Exemples d’anomalies",
          "Détection des anomalies grâce aux médianes",
          "Détection des anomalies grâce à la moyenne",
          "Détection des anomalies grâce à la méthode Z-score",
          "Détection des anomalies grâce à l’écart interquartile",
          "Gestion des valeurs manquantes",
          "Expressions rationnelles",
          "Mise à l’échelle des caractéristiques"
        ],
        "Visualisation de données à l’aide de Python": [
          "Introduction",
          "À propos de Matplotlib",
          "Tracé des graphiques linéaires",
          "Titre, Étiquettes et Légende",
          "Tracé des histogrammes",
          "Traçage de diagrammes à barres",
          "Tracer des diagrammes circulaires",
          "Tracer un diagramme de dispersion",
          "Traçage de graphiques logarithmiques",
          "Traçage de parcelles polaires",
          "Manipulation des dates",
          "Création de plusieurs graphes dans une figure"
        ],
        "Analyse exploratoire des données": [
          "Qu’est-ce que l’analyse exploratoire des données?",
          "Analyse univariée",
          "Analyse bivariée – continue et continue",
          "Analyse bivariée – catégorique et catégorique",
          "Analyse bivariée – continue et catégorique",
          "Détecter les valeurs aberrantes",
          "Traiter les valeurs aberrantes",
          "Transformation des variables catégoriques",
          "Ressources"
        ],
        "Séries chronologiques": [
          "Introduction",
          "Qu’est-ce qu’une série chronologique ?",
          "Bibliothèques Python pour l’analyse des séries chronologiques",
          "Comment obtenir des séries chronologiques ?",
          "Obtenir des données sur les stocks en utilisant yfinance",
          "Conversion d’un ensemble de données d’une série chronologique",
          "Travailler avec des séries chronologiques",
          "Visualisation d’une série chronologique",
          "Remerciements"
        ],
        "Bonus: Projets python adaptées aux débutants": [
          "Introduction",
          "Mini-Projet 1",
          "Mini-Projet 2",
          "Mini-Projet 3",
          "Mini-Projet 4",
          "Mini-Projet 5",
          "Mini-Projet 6",
          "Mini-Projet 7",
          "Mini-Projet 8",
          "Mini-Projet 9",
          "Mini-Projet 10",
          "Mini-Projet 11",
          "Mini-Projet 12",
          "Mini-Projet 13",
          "Mini-Projet 14",
          "Mini-Projet 15",
          "Mini-Projet 16",
          "Solutions"
        ]
      },
      "requirements": [
        "Des connaissances de base en python sont un plus mais les débutants sont néanmoins les bienvenus (des rappels python sont fournis)",
        "Vous n'aurez besoin de rien d'autre"
      ],
      "description": "Dans le marché du travail concurrentiel actuel, les data scientists sont tellement demandés qu’ils sont difficiles à garder. En effet, les personnes ayant une formation scientifique, informatique ainsi que des capacités analytiques sont difficiles à trouver.\nComme les \"quants\" de Wall Street dans les années 1980 et 1990, les data scientists d'aujourd'hui sont censés avoir des compétences similaires. Les personnes ayant une formation en physique et en mathématiques ont afflué vers les banques d'investissement et les fonds spéculatifs à cette époque parce qu'elles pouvaient proposer de nouveaux algorithmes et méthodes de données.\nCeci dit, la science des données est en train de devenir l'une des professions les mieux demandées du XXIe siècle. C’est un siècle ou beaucoup de choses sont informatisées, axées sur la programmation et de nature analytique. Par conséquent, il n'est pas surprenant que le besoin de spécialistes des données ait augmenté sur le marché de l'emploi au cours des dernières années.\nL'offre, en revanche, est assez restreinte. Il est difficile d'acquérir les connaissances et les capacités requises pour travailler en tant que data scientist.\nDe nombreuses ressources pour apprendre Python sont disponibles en ligne. Pour cette raison, les étudiants sont souvent dépassés par la courbe d'apprentissage élevée de Python.\nC'est pourquoi ce cours a été adapté pour vous que vous réussissiez ! L'instruction étape par étape est la marque de fabrique de ce cours. Tout au long de chaque leçon, nous continuons à construire sur ce que nous avons appris précédemment. Notre objectif est de vous doter de tous les outils et compétences dont vous avez besoin pour maîtriser Python, Numpy, Pandas & Matplotlib.\nVous repartirez de chaque vidéo avec une nouvelle idée que vous pourrez mettre en pratique immédiatement !\nTous les niveaux de compétence sont les bienvenus dans ce cours, et même si vous n'avez aucune expérience préalable en programmation ou en statistiques, vous serez en mesure de réussir !",
      "target_audience": [
        "Débutants en programmation qui souhaitent étudier toutes les bibliothèques scientifiques en Python de bout en bout (Numpy, Pandas et Matplotlib)",
        "Chercheurs intéressés par les bibliothèques Python pour la science des données",
        "Les aspirants data scientists qui veulent élargir leurs connaissances",
        "Une personne qui veut apprendre à analyser et à visualiser des données"
      ]
    },
    {
      "title": "【本番編!!】米国データサイエンティストがやさしく教える機械学習超入門【Pythonで実践】",
      "url": "https://www.udemy.com/course/mlpython-3/",
      "bio": "実際に現場で使える本格的な機械学習のアルゴリズムやテクニックを学べます",
      "objectives": [
        "業務で使うような本格的なデータ分析や機械学習のモデリングの処理を行えるようになります",
        "現場で開発が求められるような高精度なモデルを構築きるようになります",
        "最新の機械学習のアルゴリズムを使えるようになります",
        "機械学習のモデルを正しく学習/評価を行えるようになります"
      ],
      "course_content": {
        "紹介": [
          "紹介",
          "本講座の資料とコード"
        ],
        "環境準備": [
          "本セクションの補足(新たなイメージdatascientistus/ds-python-env4をお使いください)",
          "環境構築概要(Docker+JupyterLab)",
          "M1チップをお使いの方へ",
          "DockerHubアカウント作成",
          "Windowsユーザへの補足",
          "Docker環境構築",
          "Dockerの基本操作",
          "次レクチャー補足",
          "JupyterLabの基本操作"
        ],
        "アンサンブル": [
          "アンサンブル概要",
          "次レクチャー補足",
          "バギング(Bagging)",
          "バギング【Python】",
          "ランダムフォレスト",
          "ランダムフォレスト【Python】",
          "ブースティング(Boosting)",
          "AdaBoost",
          "AdaBoost【Python】",
          "まとめ"
        ],
        "勾配ブースティング": [
          "勾配ブースティング概要",
          "勾配ブースティング回帰",
          "勾配ブースティング回帰をスクラッチ実装【Python】",
          "勾配ブースティング回帰をsklearnで実装【Python】",
          "勾配ブースティング分類",
          "勾配ブースティング分類をスクラッチ実装【Python】",
          "勾配ブースティング分類をsklearnで実装【Python】",
          "まとめ"
        ],
        "有名な勾配ブースティング決定木アルゴリズム": [
          "XGBoost",
          "XGBoost【Python】",
          "LightGBM",
          "LightGBM【Python】",
          "CatBoost",
          "CatBoost【Python】",
          "まとめ"
        ],
        "スタッキング": [
          "スタッキング(Stacking)概要",
          "スタッキングの詳細アルゴリズム",
          "スタッキング【Python】",
          "まとめ"
        ],
        "EDA": [
          "データサイエンスの流れとEDA (Exploratory data analysis)",
          "EDA【Python】",
          "データクリーニング",
          "まとめ"
        ],
        "前処理": [
          "前処理(Preprocessing)と欠損値代入",
          "欠損値代入【Python】",
          "kNNを使った欠損値代入",
          "次レクチャーの修正",
          "kNNを使った欠損値代入【Python】",
          "各種欠損値代入手法を比較【Python】",
          "次レクチャーの補足",
          "Label EncodingとOne-hot Encoding",
          "Target Encoding",
          "Target Encoding【Python】",
          "Target EncodingとOne-hot Encoding比較【Python】",
          "Embedding Encoding",
          "まとめ"
        ],
        "特徴量エンジニアリング": [
          "特徴量エンジニアリング概要",
          "日付",
          "日付【Python】",
          "多項式特徴量",
          "多項式特徴量【Python】",
          "Binning",
          "Binning【Python】",
          "四則演算",
          "四則演算【Python】",
          "集約値",
          "集約値【Python】",
          "submodelを使った予測値",
          "まとめ"
        ],
        "特徴量選択": [
          "特徴量選択概要",
          "Greedy Feature Selection",
          "Greedy Feature Selection【Python】",
          "Recursive Feature Elimination (RFE)",
          "RFE【Python】",
          "モデルの係数や重要度で特徴量選択",
          "モデルの係数や重要度で特徴量選択【Python】",
          "正則化項による特徴量選択",
          "正則化項による特徴量選択【Python】",
          "まとめ"
        ]
      },
      "requirements": [
        "本講座の前編と後編を事前に受講しておくことを強くお勧めします",
        "あやふやな線形代数と微積の知識で受講が可能です",
        "Mac推奨としてますが，環境を構築できればWindowsでも問題ありません．",
        "Pythonの実装については，Pythonの基礎知識およびデータサイエンスに必要なライブラリの知識が必要です",
        "Pythonの知識がなくても本講座で機械学習の理論を学習することができます"
      ],
      "description": "※本講座は「米国データサイエンティストがやさしく教える機械学習超入門」の本番編です．先に前編および後編の受講をお願いします※\n実際の現場で機械学習をする際のモデルの構築手法を学べます．学習した理論をPythonでどのように実際のデータに適用できるのかも学習でき，理論x実装の相乗効果で確実に機械学習を習得できます．\n(3部構成で本講座は「本番編」となっており，実際にプロが現場で使用するテクニックを学習していきます)\n【特徴】\n- 米国で働く現役データサイエンティストから学ぶ\n- 実際の現場でどのように使うのかを解説\n- 機械学習の事前知識は不要\n- 全くの未経験者でも本講座を受講すれば機械学習の基本を理解することができる\n- Pythonでの実装も紹介\n- 学習したことをすぐに実データに適用可能\n- DockerとJupyterLabを使った本格データサイエンス環境 (Dockerを使って簡単環境構築)\n- これ1本で理論x実装が同時に，着実に学べる\n\n\n機械学習の理論とPythonの実装のレクチャーは別になっているため，理論だけを学習することも可能です．そのためPythonを知らなくても本講座で機械学習を学ぶことができます．\n\n\nPythonの実装のレクチャーは，Pythonの基礎知識とデータサイエンスに必要なPython(NumpyやPandasなど)の知識が必要です．\nMacを使って講義を進めますが，環境が作れればWindowsでも問題ありません．\nDockerとJupyterLabを使った本格的なデータサイエンスの環境を使いますが，WindowsでDocker環境を作れれば，全く同じ環境を構築することができます．(Windowsでの環境構築のサポートはしておりません．あらかじめご了承ください)",
      "target_audience": [
        "データサイエンスを必要とする全ての人(ビジネスマン，研究者，エンジニア, 経営者, etc...)",
        "AI開発やデータサイエンスに興味がある人",
        "データサイエンスのコンペ等に出たい人",
        "研究や授業で機械学習を勉強する必要がある人",
        "機械学習の応用的なスキルを身につけたい人"
      ]
    },
    {
      "title": "Lógica de Programação para Data Science e AI com Python",
      "url": "https://www.udemy.com/course/logica-programacao-data-science-python/",
      "bio": "O curso para iniciar em Ciência de Dados e Inteligência Artificial com exemplos práticos em Python",
      "objectives": [
        "Veja como Resolver Problemas de Lógica de Programação",
        "Aprenda a Implementar Estruturas de Decisão",
        "Entenda como Resolver problemas envolvendo estruturas de Repetição",
        "Veja como Implementar e Utilizar Funções de Data Science",
        "Escreva e Execute Programas em Python"
      ],
      "course_content": {
        "Introdução": [
          "Instruções",
          "Apresentação",
          "Material para Download",
          "Introdução",
          "Apresentação do Python",
          "Preparação do Ambiente"
        ],
        "Operações e Declaração de Variáveis": [
          "Declaração de Variáveis",
          "Exemplos com Codificação",
          "Problema 1: Cotação de Moeda",
          "Problema 2: Calculadora de Somar Inteiros",
          "Problema 3: Inversão",
          "Problema 4: Operações",
          "Problema 5: Percentuais",
          "Atividades"
        ],
        "Estruturas de Decisão": [
          "Estruturas de Decisão",
          "Testes Lógicos",
          "Problema 1: Entrar na Faculdade",
          "Problema 2: Conceito Final",
          "Problema 3: Habilitação para Vaga",
          "Problema 4: Exame",
          "Problema 5: Descontos",
          "Atividades"
        ],
        "Estruturas de Repetição": [
          "Estruturas de Repetição",
          "Problema 1: Maior que Zero",
          "Problema 2: Impressão de Intervalo",
          "Problema 3: Impressão de Tabuada",
          "Problema 4: Impressão de Tabuada II",
          "Problema 5: Calculadora de Média",
          "Atividades"
        ],
        "Uso e Criação de Funções": [
          "Funções",
          "Problema 1: Calculadora de Média",
          "Problema 2: Impressão de Intervalo",
          "Atividades"
        ],
        "Orientação a Objetos": [
          "Orientação a Objetos",
          "Exemplo"
        ],
        "Listas e Outras Questões": [
          "Lista e Outras Questões",
          "Problema 1: Calculadora de Média",
          "Problema 2: Maior e Menor",
          "Problema 3: Busca de Nomes",
          "Problema 4: Comparando Valores",
          "Problema 5: Módulo",
          "Atividades"
        ],
        "Implementando Funções de Data Science": [
          "Regressão Linear Parte I",
          "Regressão Linear Parte II",
          "Regressão Linear Parte III",
          "Implementando Regressão Linear Parte I",
          "Implementado Regressão Linear Parte II",
          "Implementado Regressão Linear Parte III",
          "Distribuição de Poisson",
          "Implementando Poisson"
        ],
        "Utilizando Funções de Data Science": [
          "Usando Funções de Data Science",
          "Regressão Linear Simples",
          "Poisson",
          "Outras Bibliotecas"
        ],
        "Faça você mesmo: Projeto Prático": [
          "Tarefa Prática Final"
        ]
      },
      "requirements": [
        "Conhecimentos Básicos em Informática"
      ],
      "description": "Neste curso você vai aprender os Fundamentos de Lógica de Programação, para ter os fundamentos para iniciar uma carreira em Ciência de Dados como Cientista de Dados ou Analista de Dados. Entre os assuntos abordados, você vai aprender:\nFundamentos de Python\nDeclaração de variáveis\nEntrada e saída de dados\nEstruturas de Decisão\nEstruturas de Repetição\nOrientação a Objetos\nListas\nFunções\nCriação de Funções de Data Science\nConsumo de Funções de Data Science\nAinda, o curso possui uma atividade prática final, onde você deve desenvolver um programa para implementar um função de analise de dados para Ciência de Dados.",
      "target_audience": [
        "Interessados em Iniciar Carreira em Ciência de Dados"
      ]
    },
    {
      "title": "R ile Veri Bilimi ve Machine Learning (35 Saat)",
      "url": "https://www.udemy.com/course/veri-bilimi-ve-makine-ogrenmesi-egitimi/",
      "bio": "R, Makine Öğrenmesi(Machine Learning), Data Science(Veri Bilimi) 8 kurs 1 arada!",
      "objectives": [
        "Makine öğrenmesini pekiştirecek ve algoritmalara özel optimizasyon teknikleri öğreneceksiniz",
        "R ile büyük veri ve makine öğrenmesi uygulamaları yapabileceksiniz",
        "Veri bilimi için istatistiğin önemini ve uygulamalarını öğreneceksiniz",
        "İş problemlerine çözüm geliştirme farkındalığına varacaksınız",
        "Keşifçi veri analizi ile veri analizi yeteneklerinizi arttıracaksınız",
        "Bilimsel veri görselleştirme teknikleri ile harika grafikler oluşturacaksınız",
        "Veri ön işleme ile modelleme öncesi veriyi hazır hale getirebileceksiniz",
        "Metin madenciliğinin temel basamaklarının öğrenecek ve kendi problemlerinize uygulayabileceksiniz",
        "Twitter analitiğinin heyecan dolu dünyasına çılgın uygulamalar ile gireceksiniz",
        "Veri bilimi proje yönetimini öğrenecek ve iş hayatına adım atmaya hazır hale geleceksiniz"
      ],
      "course_content": {
        "Giriş": [
          "Gerçek Hayat Senaryosu ile Veri Bilimi ve Makine Öğrenmesi",
          "Udemy Bilgilendirme",
          "Eğitmen Hakkında Bilgilendirme",
          "Bölümler ile İlgili Genel Bilgiler"
        ],
        "R ile Programlamaya Giriş (Opsiyonel)": [
          "Bölüm Kodları",
          "R You Ready",
          "Kurulum, Arayüz, Kisisellestirme",
          "Çalışma Ortamı Ayarları ve Proje Yönetimi",
          "Temel Hareketler",
          "Fonksiyonel Programlamanın Temelleri",
          "Veri Tipleri - Vektörler",
          "Veri Tipleri - Matrisler",
          "Veri Tipleri - Dataframe",
          "Veri Tipleri - Listeler ve Tibble",
          "Veri Tipleri Quiz",
          "Kategorik Değişkenler",
          "Kategorik Değişkenler Quiz",
          "Tarih-Saat Değişkenleri",
          "Tarih Saat Quiz",
          "Fonksiyon Okuryazarlığı ve Fonksiyonlar",
          "Dongu ve Kontol İfadeleri - if",
          "Dongu ve Kontol İfadeleri - for",
          "Apply ve Map Ailesi",
          "Veri Okuma",
          "Doğru Kod Yazımı",
          "Veri Manipülasyonuna Giriş",
          "Değişken Seçme İşlemleri",
          "Gözlem Seçme İşlemleri",
          "Değişken Oluşturma ve Değişken Dönüştürme",
          "Gruplama ve Veri Özetleme",
          "Tidy Data - Gathering",
          "Tidy Data - Spreading",
          "Tidy Data - Separating ve Unite"
        ],
        "Veri Okuryazarlığı (Opsiyonel)": [
          "İstatistiksel Öğrenme",
          "İstatistikten Nefret Edenler için İstatistik",
          "Bilimin Alfabesi",
          "Ölçülebileni Ölç Ölçülemeyeni Ölçülebilir Hale Getir",
          "Veri Okuryazarlığı ve Temel Kavramlar",
          "Veri, Değişken ve Ölçek Türleri",
          "Merkezi Eğilim Ölçüleri",
          "Dağılım Ölçüleri",
          "Çarpıklık ve Basıklık Ölçüleri",
          "İstatistiksel Düşünce Modelleri",
          "Quiz",
          "Ödev - Cevap"
        ],
        "Keşifçi Veri Analizi ve Veri Görselleştirme": [
          "Bölüm Kodları",
          "Büyük Resmi Görmek",
          "Değişken Dönüşümleri ve Türlerinin Ayarlanması",
          "Değişken Türleri - Dönüşümleri",
          "Veriye İlk Bakış",
          "Sürekli & Kategorik Değişken Özetleri",
          "Sürekli & Kategorik Değişken Detayları",
          "Dataframe'lerin İnteraktif Keşfi",
          "Dağılım - Barplot",
          "Dağılım - Histogram & Yoğunluk",
          "Dağılım - Ridgeline",
          "Dağılım - İnteraktif Histogram",
          "Dağılım - Çoklu Frekans",
          "Dağılım - Boxplot",
          "Dağılım - Violin",
          "Sürekli ve Kategorik Değişken Dağılımları",
          "Korelasyon - Scatterplot",
          "Korelasyon - Scatterplot - Birimleri Grafiğe Eklemek",
          "Korelasyon - Scatterplot - Marjinlere Dağılım Eklemek",
          "Korelasyon - Heatmap",
          "Korelasyon - Korelasyon Matrisleri",
          "Korelasyonlar Quiz",
          "Zaman Serisi",
          "Gelişmiş Grafikler - Dairesel Sütun Grafikler",
          "Gelişmiş Grafikler - Treemap Giriş",
          "Gelişmiş Grafikler - Treemap Detay"
        ],
        "Veri Bilimi için İstatistik": [
          "Bölüm Kodları",
          "Walk, Like A Boss!",
          "Örneklem",
          "Örneklem Shiny Simülasyonu",
          "Örneklem",
          "İstatistikler",
          "Güven Aralıkları",
          "Güven Aralıkları Shiny Simülasyonu",
          "Olasılığa Giriş",
          "Olasılığa Giriş - Bernoulli Dağılımı",
          "Olasılığa Giriş - Binom Dağılımı",
          "Uygulama I - Reklam Tıklanma Olasılığı",
          "Olasılığa Giriş - Poisson Dağılımı",
          "Uygulama II - Ürün Girişi Hata Olasılığı",
          "Olasılığa Giriş - Normal Dağılım",
          "Uygulama III - Sahtekarlık Olma Olasılığı",
          "Olasılık Dağılımları",
          "Hipotez Testleri - Giriş",
          "Hipotez Testleri - Hipotez Testi Adımları",
          "Hipotez Testleri - Tek Örneklem t Testi",
          "Uygulama IV - Ürün Satın Alma Adım Optimizasyonu",
          "Problem & Veri Seti",
          "R Uygulaması - Varsayım Kontrolü",
          "R Uygulaması - t Testi",
          "R Uygulaması - Alternatif Fonksiyon",
          "R Uygulaması - Nonparametrik Tek Örneklem Testi",
          "Hipotez Testleri - Tek Örneklem Oran Testi",
          "Uygulama V - Dönüşüm Oranı Güven Aralığı",
          "R Uygulaması - Problem & Veri Seti",
          "R Uygulaması - Varsayım Kontrolü",
          "R Uygulaması - Tek Örneklem Oran Testi",
          "Hipotez Testleri - Bağımsız İki Örneklem T Testi",
          "Uygulama VI - Gelir Odaklı AB Testi",
          "R Uygulaması - Problem & Veri Seti",
          "R Uygulaması - Varsayım Kontrolü",
          "R Uygulaması - Varsayım Kontrolü 2",
          "R Uygulaması - Bağımsız İki Örneklem T Testi",
          "R Uygulaması - Alternatif Fonksiyon",
          "R Uygulaması - Nonparametrik Bağımsız İki Örneklem Testi",
          "Hipotez Testleri - Bağımlı İki Örneklem T Testi",
          "R Uygulaması - Problem & Veri Seti",
          "R Uygulaması - Varsayım Kontrolü",
          "R Uygulaması - Bağımlı İki Örneklem T Testi",
          "R Uygulaması - Alternatif Fonksiyon",
          "R Uygulaması - Nonparametrik Bağımlı İki Örneklem Testi",
          "Hipotez Testleri - İki Örneklem Oran Testi",
          "Uygulama VII - Dönüşüm Oranı AB Testi",
          "R Uygulaması - Problem & Veri Seti",
          "R Uygulaması - İki Örneklem Oran Testi",
          "Hipotez Testleri - Varyans Analizi",
          "Uygulama VIII - İçerik Stratejisi Belirleme",
          "R Uygulaması - Problem & Veri Seti",
          "R Uygulaması - Varsayım Kontrolü",
          "R Uygulaması - Tek Yönlü Varyans Analizi",
          "R Uygulaması - İkili Karşılaştırma",
          "R Uygulaması - Alternatif Fonksiyon",
          "R Uygulaması - Nonparametrik Varyans Analizi",
          "Hipotez Testleri - Parametrik vs Nonparametrik",
          "Korelasyon Analizi - Giriş",
          "Uygulama IX - Mağaza Skoru ile Satış Performansı İlişkisi",
          "R Uygulaması - Problem & Veri Seti",
          "R Uygulaması - Varsayım Kontrolü",
          "R Uygulaması - Korelasyon Testi",
          "R Uygulaması - Nonparametrik Korelasyon Testi",
          "R Uygulaması - Korelasyon Matrisi",
          "R Uygulaması - Gelişmiş Korelasyon Matrisi",
          "Toparlayalım :)",
          "İstatistiksel Öğrenme vs Makine Öğrenmesi"
        ],
        "Modelleme Öncesi Hazırlık: Veri Ön İşleme": [
          "Bölüm Kodları",
          "Veri mi Model mi?",
          "Eksik Veri Analizi",
          "Eksik Veri Problemi Nasıl Çözülür?",
          "Eksik Veri ile Mücadele Eylem Planı",
          "Eksik Veriyi Hızlı Silme - Doldurma",
          "Eksik Verinin Değerlendirilmesi",
          "Eksik Verinin Görselleştirilmesi & Yapısının İncelenmesi",
          "Eksik Verinin Görselleştirilmesi & Yapısının İncelenmesi 2",
          "Eksik Veri Rassallığının Testi",
          "Eksik Veri Silme Yöntemleri",
          "Basit Değer Atama Yöntemleri",
          "KNN ile Tahmine Dayalı Atama",
          "Random Forests ile Tahmine Dayalı Atama",
          "Ödev - Eksik Gözlem Analizi",
          "Aykırı Gözlem Analizi",
          "Aykırı Gözlemler ile Mücadele Eylem Planı",
          "Aykırı Gözlem Yakalama, İndeksleme, Görselleştirme",
          "Aykırı Gözlem Problemini Ortadan Kaldırma",
          "Çok Değişkenli Aykırı Gözlem - Local Outlier Factor",
          "Çok Değişkenli Aykırı Gözlem - Kümeleme Yöntemi",
          "Ödev - Aykırı Gözlem Analizi",
          "Veri Standardizasyonu",
          "Veri Standardizasyonu Uygulama",
          "Veri İndirgeme"
        ],
        "Makine Öğrenmesi I - Giriş": [
          "Giriş",
          "Makine Öğrenmesi Nedir? Nasıl? Neden?",
          "Kavramlar & Terminoloji",
          "Deterministik Modeller vs Stokastik Modeller",
          "Doğrusal Modeller vs Doğrusal Olmayan Modeller",
          "Gözetimli Öğrenme vs Gözetimsiz Öğrenme",
          "Regresyon Problemleri vs Sınıflandırma Problemleri",
          "Model Doğrulama Yöntemleri",
          "Model Başarı Değerlendirme",
          "Yanlılık Varyans Değiş Tokuşu",
          "Parametre vs Hiperparametre, Parametre Tuning vs Model Tuning",
          "Makine Öğrenmesinin İlk Adımı",
          "Aşağısı Çok Karışık, Reçete var mı?"
        ],
        "Makine Öğrenmesi II - Doğrusal Regresyon ve Kuzenleri": [
          "Bölüm Kodları",
          "Basit Doğrusal Regresyon - Teori",
          "Basit Doğrusal Regresyon - Model",
          "Basit Doğrusal Regresyon - Tahmin",
          "Artıklar ve Makine Öğrenmesindeki Önemi",
          "Çoklu Doğrusal Regresyon - Teori",
          "Veri Seti ve Train-Test Ayrımı",
          "Çoklu Doğrusal Regresyon - Model",
          "Çoklu Doğrusal Regresyon - Tahmin",
          "Çoklu Doğrusal Regresyon - Model Tuning",
          "PCR (Temel Bileşen Regresyonu) - Teori",
          "PCR - Model",
          "PCR - Tahmin",
          "PCR - Model Tuning",
          "PLS (Kısmi En Küçük Kareler Regresyonu) - Teori",
          "PLS - Model",
          "PLS - Tahmin",
          "PLS - Model Tuning",
          "Ridge Regresyon - Teori",
          "Ridge Regresyon - Ayar Parametresi Lambda'nın Seçilmesi",
          "Ridge Regresyon - Model",
          "Ridge Regresyon - Tahmin",
          "Ridge Regresyon - Model Tuning",
          "Lasso Regresyon - Teori",
          "Lasso Regresyon - Model",
          "Lasso Regresyon - Tahmin",
          "Lasso Regresyon - Model Tuning",
          "ElasticNet - Teori",
          "ElasticNet - Model",
          "ElasticNet - Tahmin",
          "ElasticNet - Model Tuning"
        ],
        "Makine Öğrenmesi III - Doğrusal Olmayan Regresyon Modelleri": [
          "Bölüm Kodları",
          "KNN - Teori",
          "KNN - Model",
          "KNN - Tahmin",
          "KNN - Model Tuning",
          "SVR (Destek Vektör Regresyonu) - Teori",
          "SVR - Model",
          "SVR - Tahmin",
          "SVR - Model Tuning",
          "YSA (Yapay Sinir Ağları) - Teori",
          "YSA - Model",
          "YSA - Değişken Önem ve Etki Düzeyleri",
          "YSA - Tahmin",
          "YSA - Model Tuning",
          "CART (Regresyon Ağaçları) - Teori",
          "CART - Model",
          "CART - Tahmin",
          "CART - Model Tuning",
          "Bagged Trees Regresyon - Teori",
          "Bagged Trees Regresyon - Model",
          "Bagged Trees Regresyon - Tahmin",
          "Bagged Trees Regresyon - Model Tuning",
          "Random Forests - Teori",
          "Random Forests - Model",
          "Random Forests - Tahmin",
          "Random Forests - Model Tuning",
          "Random Forests - Random Search",
          "Random Forests - Grid Search",
          "Gradient Boosting Machines - Teori",
          "Gradient Boosting Machines - Model",
          "Gradient Boosting Machines - Tahmin",
          "Gradient Boosting Machines - Model Tuning",
          "XGBoost - Teori",
          "XGBoost - Model",
          "XGBoost - Tahmin",
          "XGBoost - Model Tuning",
          "XGBoost - Gelişmiş Hiperparametre Optimizasyonu",
          "XGBoost - Adım 1",
          "XGBoost - Adım 2",
          "XGBoost - Adım 3",
          "XGBoost - Adım 4",
          "XGBoost - Adım 5",
          "XGBoost - Adım 6",
          "XGBoost - Adım 7"
        ]
      },
      "requirements": [
        "Heyecan!",
        "Bilgisayar/tablet/mobil cihaz ve internet bağlantısı"
      ],
      "description": "21. Yüzyılın en çok para kazandıran mesleği olan veri bilimcilik için gereken tüm yetkinlikleri bir arada bulabileceğiniz Udemy'nin en geniş kapsamlı \"R ile Veri Bilimi ve Makine Öğrenmesi\" eğitimine hoşgeldiniz!\nSıfırdan uzmanlığa veri bilimci olmak için gereken tüm yetkinlikleri bir sektör profesyonelinden gerçek hayat uygulamaları ile pekiştirme fırsatı bulacaksınız.\nTeorik veri bilimi ve makine öğrenmesi eğitimleri yerine kurs içeriği modern iş dünyasının gerçek senaryoları ile oluşturulmuştur ve  sıfırdan başlayanları ileri bir seviyeye ulaştırmak amacını taşımaktadır\nR Programlama\nVeri Okuryazarlığı\nKeşifçi Veri Analizi\nVeri Görselleştirme\nVeri Bilimi için İstatistik\nVeri Ön İşleme\nMakine Öğrenmesi\nBüyük Veri Analitiği\nMetin Madenciliği\nTwitter Analitiği\nOnlarca Gerçek Hayat Uygulaması\nVeri Bilimi Proje Yönetimi\n\nBu kurs ile ilgili bazı kullanıcı yorumları:\n\n\n★★★★★ \"Branşımın mühendislik ve istatistik tabanlı olmamasına rağmen gayet keyifle izliyorum elinize emeğinize sağlık ...\"  Merve Gonca\n\n\n★★★★★ \"Baştan sona kadar detaylarıyla anlatılmış çok kapsayıcı bir kurs. Böylesine detaylı anlatımlı bir kursu bu kadar kolay bir yoldan almış olduğum için kendimi gerçekten çok şanslı hissediyorum. Emeklerinize sağlık.\"  Sefa Yay\n\n\n★★★★★ \"Mükemmel insan, Mükemmel anlatım :) Bu eğitimi dışarıda almak isteseniz en az 10 bin TL harcamanız gerekir. Eğer kurs içeriğindeki konulara ilginiz varsa mutlaka ama mutlaka edinip izlemenizi tavsiye ediyorum.\"  A.Faruk Kılıç\n\n\n★★★★★ \"Futbol analitiğine ilgim olduğu için R öğrenmek istedim. Udemy üzerinden bu kursu buldum. Harika bir kurs. Hocamızı bazen soru bombardımanına tutsam bile her zaman cevap veriyor. Net olarak öneririm. Bir gün herkes data sapiens olacak!\"  Sezer Unar\n\n\n★★★★★ \"Sayın Mustafa Vahit KESKİN hocamı öncelikle tebrik ediyorum. R ile Veri Bilimi ve Makine Öğrenmesi kursu temel seviye R ile başlayan, sonrasında bir akademisyenin ihtiyacı olan hipotez testleri ile devam eden, sonrasında ise basit konulardan karmaşık Makine öğrenimi konularına evrilen bir kurs. Özellikle her konunun ayrıntılı teorik anlatımı, sonrasında ise konu ile ilgili uygulamalar harika. Bu uygulamaların her seferinde gerçek hayat örnekli değişik veri setleri ile anlatılması ve bu verilerin kaynak kod ve veri setleri ile paylaşılması ise işin en güzel yanlarından. Bedava bir çok eğitime bir başka sosyal medya aracısından para vermeden ulaşıldığı için bu tarz Udemy eğitimlerinin gereğine inanmayan bir insan olarak bu kurs benim bu ön yargımı yıktı. Üzerinde inanılmaz bir emek olan bu işi ayakta alkışlıyorum..\"  İnanç Alikılıç",
      "target_audience": [
        "Veri bilimi ve yapay zeka dünyasına meraklı olan öğrenciler",
        "Yazılım kökenli olup veri bilimi dünyasına geçmek isteyenler",
        "İstatistikçi olup veri bilimi dünyasına girmeyi hedefleyenler"
      ]
    },
    {
      "title": "Python y Machine Learning: Crea Soluciones Innovadoras",
      "url": "https://www.udemy.com/course/curso-machine-learning-express-con-python/",
      "bio": "Aprende a crear soluciones inteligentes y avanzadas con Python para problemas del mundo real en este curso práctico",
      "objectives": [
        "Dominar el Machine Learning y qué modelo y algoritmo utilizar para tu reto concreto.",
        "En qué consiste el Machine Learning y qué se diferencia de la Inteligencia Artificial y Deep Learning",
        "Manejar Python para el análisis de datos con las principales librerías (numpy, pandas, scikit-learn,..)",
        "Cuáles son los diferentes tipos de machine learning siendo capaz de resolver problemas de clasificación, regresión, clustering y reglas de asociación",
        "Conocer los algoritmos de machine learning en cada tipología, valorar cuál es el más adecuado y optimizarlo",
        "Predecir el futuro gracias a los modelos de machine learning para conseguir la ventaja competitiva",
        "Dar un enorme valor añadido tanto en su compañía como negocio personal",
        "Evaluar si el modelo de Machine Learning funciona bien y resuelve el reto al que te enfrentas",
        "Añadir una habilidad de sumo interés para su carrera"
      ],
      "course_content": {
        "INTRODUCCIÓN AL MACHINE LEARNING": [
          "Bienvenida / Información importante",
          "¿Qué es el Machine Learning?",
          "Machine Learning & Inteligencia Artificial & Deep Learning",
          "Tipos de Machine Learning"
        ],
        "INTRODUCCIÓN A PYTHON": [
          "Instalación Python + Jupyter",
          "Conceptos básicos de Python",
          "Introducción a las librerías: Numpy",
          "Introducción a las librerías: Pandas",
          "Introducción a las librerías: Matplotlib",
          "Librería Machine Learning Scikit-Learn"
        ],
        "MACHINE LEARNING – CLASIFICACIÓN": [
          "¿Qué es y qué problemas resuelven un modelo de CLASIFICACIÓN?",
          "Algoritmos Machine Learning para CLASIFICACIÓN (Decision Tree, SVM,...)",
          "Explicación paso a paso con Scikit-Learn – Caso Práctico Clasificación",
          "Ejercicio codificación – CLASIFICACIÓN",
          "Optimización de parámetros en algoritmos Machine Learning"
        ],
        "MACHINE LEARNING – REGRESIÓN": [
          "¿Qué es y qué problemas resuelven un modelo de REGRESIÓN?",
          "Algoritmo Machine Learning Regresión Lineal",
          "Explicación paso a paso con Scikit-Learn – Caso Práctico REGRESIÓN"
        ],
        "MACHINE LEARNING – CLUSTERING": [
          "¿Qué es y qué problemas resuelven un modelo de CLUSTERING?",
          "Algoritmo Machine Learning K-Means",
          "Explicación paso a paso con Scikit-Learn – Caso Práctico CLUSTERING"
        ],
        "MACHINE LEARNING – REGLAS DE ASOCIACIÓN": [
          "¿Qué es y qué problemas resuelven un modelo de REGLAS DE ASOCIACIÓN?",
          "Algoritmo Reglas de Asociación – “Apriori”",
          "Explicación paso a paso – Caso Práctico Reglas de Asociación"
        ],
        "DESPLIEGUE DE SOLUCIONES DE MACHINE LEARNING / DEEP LEARNING": [
          "¿Cómo desplegamos un modelo de Machine Learning?",
          "Caso práctico despliegue de un proyecto Machine Learning"
        ],
        "CONCLUSIONES": [
          "Conclusiones",
          "Siguientes Pasos"
        ],
        "Clase Extra - BONUS": [
          "Clase Extra",
          "Recursos Extra"
        ]
      },
      "requirements": [
        "No es necesario conocimientos previos, se recomiendan nociones en programación pero se aprenderá Machine Learning desde cero"
      ],
      "description": "¿Quieres conocer en qué consiste el Machine Learning y cómo poder aplicarlo rápidamente para resolver tus retos?\n-------------------------------------------------------\nEscuche de otros alumnos por qué este es el curso de Machine Learning MEJOR VALORADO en español:\n\" Se rifó al final con la metralleta de selección de mejor modelo, no lo había visto en ningún lado. Excelente curso, muy claro y justo para adentrarse y cerrar el gap entre estadística y los modelos de Machine Learning con los ejercicios propuestos\" -- Sebastián Montes\n\n\n\"He tomado algunos otros cursos de inteligencia artificial en esta plataforma y ninguno está tan claro y sencillo como este. De verdad me gusto mucho la forma de enseñanza\" -- Luis Hernández\n\n\n\" Breve, sencillo de seguir y poner en práctica. Bien estructurado por el instructor y da un acceso rápido a conceptos de base para seguir creciendo en esta línea de conocimiento.\" -- Juan Antonio Rodríguez\n----------------------------------------------------------\nEn este curso aprenderás los conocimientos que necesitas y que llevan a las empresas a pagar salarios en torno a 140.000$ según se recoge en las estadísticas de portales como Indeed.\nVeremos paso a paso en qué consiste el Machine Learning, qué tipos existen y sobre todo qué tipologías de problemas podemos resolver y cómo realizarlo fácilmente con Python.\nNo es necesario conocer previamente Python puesto que habrá un bloque introductorio para enseñar lo esencial del análisis de datos con este lenguaje y toda su instalación. Aunque no tengas estos conocimientos previos, en este curso compacto podrás aprender en menos de 3 horas cómo aplicar Machine Learning con Python de manera inmediata.\nEl objetivo del curso no es solo aprender todo lo relacionado con el Aprendizaje Automático e Inteligencia Artificial, sino que en cada bloque se revisarán casos prácticos reales y tendrás a tu disposición el código utilizado para que lo puedas adaptar fácilmente a tu caso de uso concreto.\nEl curso está estructurado en los siguientes bloques:\nBLOQUE 1: INTRODUCCIÓN AL MACHINE LEARNING\nBLOQUE 2: INTRODUCCIÓN A PYTHON\nBLOQUE 3: MACHINE LEARNING – CLASIFICACIÓN\nBLOQUE 4: MACHINE LEARNING – REGRESIÓN\nBLOQUE 5: MACHINE LEARNING – CLUSTERING\nBLOQUE 6: MACHINE LEARNING – REGLAS DE ASOCIACIÓN\nBLOQUE 7: CONCLUSIONES\nEn los próximos años habrá una fuerte demanda de perfiles especializados en Machine Learning y cómo sacar el máximo provecho de la información para conseguir la ventaja competitiva que ofrece utilizar este tipo de técnicas. Por eso te propongo aprender Inteligencia Artificial con Python de una manera sencilla y efectiva.\nPor otra parte, tendrás una garantía de 30 días para asegurar que está 100% satisfecho con el material, mi objetivo es aportarte valor con todos estos conocimientos y si no es así siéntete libre de solicitar la devolución, aunque estoy seguro de que cumplirá tus expectativas.\nSi quieres aprender una habilidad muy importante y en un corto espacio de tiempo que podrás poner en práctica de inmediato, sin duda este es tu curso.",
      "target_audience": [
        "Cualquier persona que esté motivada por aprender en qué consiste el Machine Learning y poder sacar el máximo provecho de la información",
        "Usuarios que quieran aprender cuáles son los diferentes tipos de Machine Learning así como sus algoritmos y cómo aplicarlos fácilmente con Python",
        "Analistas que manejan datos en su día a día y quieren obtener un plus explorando la información con el aprendizaje automático.",
        "Todo aquel que quiera especializarse en una rama con un increíble potencial de cara a futuro muy valorada en el mercado.",
        "Cualquier persona que quiera dar un valor añadido en su compañía o negocio personal."
      ]
    },
    {
      "title": "Deep Learning ve Python: A'dan Z'ye Derin Öğrenme (5)",
      "url": "https://www.udemy.com/course/deep-learning-ve-python-adan-zye-derin-ogrenme-5/",
      "bio": "Python ile Derin Öğrenme (Deep Learning) algoritmaları geliştirerek Yapay Zeka amacımıza bir adım daha yaklaşalım - 2020",
      "objectives": [
        "Yapay zeka yolculuğumuzun 5. adımı olan Derin Öğrenme kursumuzu tamamlayacak ve hedefimize bir adım daha yaklaşmış olacaksınız",
        "CV'nize gönül rahatlığıyla derin öğrenme ile ilgili aldığınız eğitimi ve birlikte yaptığımız projeleri yazabileceksiniz",
        "Derin öğrenme ile pek çok sınıflandırma ve tahmin algoritmaları geliştirebileceksiniz",
        "Derin öğrenme projelerinizi tüm dünya ile buluşturacaksınız"
      ],
      "course_content": {
        "Giriş": [
          "Deep Learning Kursu İçerik",
          "Python, Anaconda ve Jupyter Notebook Kurulumu",
          "Udemy Tanıtım"
        ],
        "Kaggle Nedir?": [
          "Kaggle Tanıtımı 1",
          "Kaggle Tanıtımı 2",
          "Notebook (Kernel) Nedir?",
          "Kaggle Arayüz Değişikliği",
          "Kaggle Profil Sayfası",
          "Kaggle'da Başarılı Olmak İçin Neler Yapmalı?"
        ],
        "Deep Learning ve Data Set Tanıtımı": [
          "Data Set Tanıtımı",
          "Deep Learning Kernel ve Data Set İndirme",
          "Deep Learning vs Machine Learning",
          "Data Set Overview - 1",
          "Data Set Overview - 2",
          "Deep Learning ve Data Set Tanıtımı Neler Öğrendik"
        ],
        "Logistic Regression": [
          "Logistic Regression Genel Bakış",
          "Computation Graph",
          "Logistic Regression Computation Graph",
          "Initializing Parameters",
          "Forward Propagation",
          "Backward Propagation - 1",
          "Backward Propagation - 2",
          "Implementing Initializing Parameters",
          "Implementing Forward Propagation",
          "Implementing Backward Propagation",
          "Implementing Update Parameters",
          "Implementing Prediction",
          "Implementing Logistic Regression",
          "Logistic Regression with Sklearn",
          "Logistic Regression Neler Öğrendik - Ödev"
        ],
        "Artificial Neural Network (Yapay Sinir Ağları)": [
          "Artificial Neural Network Genel Bakış",
          "Artificial Neural Network Nedir",
          "Artificial Neural Network Computation Graph",
          "2-Layer Neural Network",
          "Initializing Parameters",
          "Forward Propagation",
          "Loss and Cost Functions",
          "Backward Propagation",
          "Update Parameters",
          "Prediction",
          "Create ANN Model",
          "L-Layer Neural Network",
          "Neural Network with Keras",
          "Neural Network with Pytorch",
          "Neural Network Tensorflow Playground",
          "Artificial Neural Network Neler Öğrendik - Ödev - Tavsiye"
        ],
        "Convolutional Neural Network (CNN)": [
          "Convolutional Neural Network Genel Bakış",
          "Dataset ve CNN Kernel",
          "Loading Data Set",
          "Normalization - Reshape - Label Encoding",
          "Train - Test Split",
          "Convolutional Neural Network (CNN)",
          "Convolution Operation Nedir",
          "Same Padding",
          "Max Pooling",
          "Flattening",
          "Fully Connected",
          "CNN Implementing with Keras",
          "Create Model",
          "Adam Optimizer",
          "Compiler",
          "Batch and Epoch",
          "Data Augmentation",
          "Fit the Model",
          "Evaluate the Model",
          "CNN with Pytorch",
          "Convolutional Neural Network Neler Öğrendik - Ödev"
        ],
        "Recurrent Neural Network (RNN)": [
          "Recurrent Neural Network Genel Bakış",
          "Sequence Models",
          "Recurrent Neural Network Nedir",
          "Implementing RNN with Keras Giriş",
          "RNN Loading and Preprocessing Data",
          "RNN Create Model",
          "RNN Prediction and Visualization",
          "Long Short Term Memory (LSTM) Nedir",
          "Implementing LSTM with Keras Giriş",
          "LSTM Loading and Visualizing Data",
          "LSTM Preprocessing Data",
          "LSTM Create Model",
          "LSTM Prediction and Visualization",
          "RNN Neler Öğrendik"
        ],
        "Deep Learning Sonuç": [
          "Ne Yaptık Ne Yapacağız",
          "Derin Öğrenme Ek Kaynak",
          "BONUS"
        ]
      },
      "requirements": [
        "Hedefler ve gelecekle ilgili güzel hayaller",
        "İnternet bağlantılı bir bilgisayara sahip olmak yeterlidir",
        "Python, veri görselleştirme ve makine öğrenmesi konuları hakkında temel bilgiler"
      ],
      "description": "Merhaba arkadaşlar,\nBu kurs 7 bölümlük nihai hedefim olan Yapay Zekanın beşinci bölümünü oluşturmaktadır.\nPython: Python Sıfırdan Uzmanlığa Programlama (1)\nData Science ve Python: Sıfırdan Uzmanlığa Veri Bilimi (2)\nData Visualization: A'dan Z'ye Veri Görselleştirme (3)\nMachine Learning ve Python: A'dan Z'ye Makine Öğrenmesi (4)\nDeep Learning (Derin Öğrenme)\nStatistical Learning (İstatistik)\nArtificial Intelligence (Yapay Zeka)\nBu Kurs ile Alacaklarınız\nSıfırdan Kodlama Becerisi: Sizinle birlikte kod yazıyoruz. Her ders boş bir sayfa ile başlar ve kodu sıfırdan yazarız. Bu şekilde ilerleyebilir ve kodun nasıl bir araya geldiğini ve her satırın ne anlama geldiğini tam olarak anlayabilirsiniz.\nKodlar ve Şablonları: Kursta oluşturduğumuz her Python şablonlarını ve kodunu indirebilirsiniz. Bu, sizlere hem daha sonra kod üzerinde pratik yapma hem de kendi projelerinizi şablon sayesinde daha kolay bir şekilde yaratma imkanı sağlayacaktır\nTeori ve Mantık: Size yalnızca kod yazmayı değil, hem yazdığımız kodun arkasında yatan mantığı ve teoriyi hem de neden böyle bir kod yazdığımızı anlatıyoruz.\nKurs içi destek: Size sadece video ile ders anlatımı yapmıyoruz. Size destek olmak için profesyonel Veri Bilimcilerinden oluşan bir ekip oluşturduk. Bu da ders ve ya ders dışı sorularınıza en fazla 72 saat içinde yanıt alacağınız anlamına geliyor.\nDeep Learning kursu içeriği:\nGiriş Bölümü\nDeep Learning Giriş\nSık Sorulan Sorular\nAnaconda Jupyter Notebook Kurulumu\nKaggle\nDeep Learning ve Dataset Tanıtımı\nDeep Learning giriş\nDataset Overview\nLogistic Regression\nComputation Graph\nInitializing Parameters\nForward Propagation\nBackward Propagation\nImplementing Logistic Regression with Python\nImplementing Logistic Regression with Sklearn\nArtificial Neural Network (ANN)\nComputation Graph\nInitializing Parameters\nForward Propagation\nLoss, Cost Function\nBackward Propagation\nUpdata Parameters\nCreate Model\nL-Layer Neural Network\nL-Layer Neural Network with Keras\nL-Layer Neural Network with Pytorch\nNeural Network Playground\nConvolutional Neural Network (CNN)\nSame Padding\nMax Pooling\nFully Connected Network\nImplementing with Keras\nCreate Model\nOptimizer\nCompiler\nBatch and Epoch\nData Augmentation\nFitting Model\nEvaluate Model\nCNN with Pytorch\nRecurrent Neural Network (RNN)\nRecurrent Neural Network with Keras\nLong Short Term Memory (LSTM)\nKurs Hakkında Bazı Öğrenci Yorumları\nRaşit İri\nHocamıza ait önceki kursları da almış biri olarak şunu söylemeliyim ki her kurs birbiri ile bağlantılı bir şekilde ilerliyor. Size önerim daha önceki kursları da alıp o şekil de ilerlemeniz. Kursa gelecek olursak diğer kurslar gibi konuların mantığını örnekler vererek çok güzel bir şekilde kavratıyor.\nFerec HAMİTBEYLİ\nTek kelime ile mükemmel. Tüm arkadaşlarıma, eşime dostuma önerdim bu seriyi. Hangi meslekten olursanız olun, yapay zeka geleceğin bir parçası ve erkenden öğrenmenizi tavsiye ederim.\nOsman Homek\nBu kursun diğer kurslardan en büyük farkı, yaptığınızı şeyi neden yaptığınızı size anlatması. Bu durum ancak, anlattığı konuyu uygulayan birileri tarafından verilebilir. Bu kurs, asla, slaytların ingilizceden çevrilmesi ile hazırlanmamıştır. Bu nedenle, kursun sonunda, gerçek tecrübelerden süzülmüş bir bilgi edineceksiniz. Hocamıza, vakit ayırıp, bize kıymet verdiği için minnettarım.\nİçeriğin İngilizce olması sizi yanıltmasın arkadaşlar. Derslerim tamamen Türkçedir.\nHemen kaydolun ve bir an önce başlayalım.",
      "target_audience": [
        "Derin öğrenmesi konusunda uzmanlaşmak isteyenler",
        "Yapay zeka temellerini oluşturmak isteyenler",
        "Kariyerini derin öğrenmede sürdürmek yada başlatmak isteyenler",
        "Üniversite ve meslek seçiminde zorlanan ve derin öğrenme hakkında bilgi ve beceri sahibi olmak isteyenler",
        "Derin öğrenmeyi iş hayatında uygulamak isteyenler"
      ]
    },
    {
      "title": "Aprendizagem por Reforço com Deep Learning, PyTorch e Python",
      "url": "https://www.udemy.com/course/aprendizagem-reforco-deep-learning-pytorch-python/",
      "bio": "Construa a um carro autônomo virtual com Inteligência Artificial e Deep Q-Learning",
      "objectives": [
        "Teoria sobre aprendizagem por reforço com o algoritmo Q-Learning e Deep Q-Learning",
        "Implementação passo a passo de uma inteligência artificial para controlar um carro autônomo virtual",
        "Redes neurais artificiais"
      ],
      "course_content": {
        "Bem-vindo(a) ao curso!": [
          "Boas vindas",
          "Mais sobre Inteligência Artificial"
        ],
        "----- Parte 1 - Fundamentos de Aprendizagem por Reforço -----": [
          "Bem-vindo(a) à Parte 1 - Fundamentos de Aprendizagem por Reforço"
        ],
        "Q-Learning - Intuição e Visualização": [
          "Conteúdo",
          "O que é aprendizagem por reforço?",
          "A Equação de Bellman",
          "O Plano",
          "Markov Decision Process - MDP",
          "Política x Plano",
          "Adição de Penalidades - Living Penalty",
          "Q-Learning - Intuição",
          "Diferença Temporal",
          "Q-Learning - Visualização"
        ],
        "----- Parte 2 - Intuição Deep Q-Learning -----": [
          "Bem-vindo(a) à Parte 2 - Intuição Deep Q-Learning"
        ],
        "Deep Q-Learning - Intuição": [
          "Conteúdo",
          "Intuição Deep Q-Learning - Aprendizagem",
          "Intuição Deep Q-Learning - Ações",
          "Replay de Experiência",
          "Políticas de Seleções de Ações"
        ],
        "----- Parte 3 - Implementação Deep Q-Learning -----": [
          "Bem-vindo(a) à Parte 3 - Implementação Deep Q-Learning"
        ],
        "Implementação Deep Q-Learning": [
          "Conteúdo",
          "Configuração do Ambiente",
          "IMPORTANTE: Configuração do ambiente",
          "Carro autônomo - Parte 1",
          "Carro autônomo - Parte 2",
          "Carro autônomo - Parte 3",
          "Carro autônomo - Parte 4",
          "Carro autônomo - Parte 5",
          "Carro autônomo - Parte 6",
          "Carro autônomo - Parte 7",
          "Carro autônomo - Parte 8",
          "Carro autônomo - Parte 9",
          "Carro autônomo - Parte 10",
          "Carro autônomo - Parte 11",
          "Carro autônomo - Parte 12",
          "Carro autônomo - Parte 13",
          "Carro autônomo - Parte 14",
          "Carro autônomo - Parte 15",
          "Carro autônomo - Parte 16"
        ],
        "Visualização Deep Q-Learning": [
          "Carro autônomo - Nível 1",
          "Carro autônomo - Nível 2",
          "Carro autônomo - Nível 3",
          "Carro autônomo - Nível 4"
        ],
        "Anexo I - Redes Neurais Artificiais": [
          "Perceptron de uma camada",
          "Redes multicamada - função soma e função de ativação",
          "Redes multicamada - cálculo do erro",
          "Descida do gradiente",
          "Cálculo do parâmetro delta",
          "Ajuste dos pesos com backpropagation",
          "Bias, erro, descida do gradiente estocástica e mais parâmetros",
          "Funções de ativação I",
          "Funções de ativação II"
        ],
        "Considerações finais": [
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação, principalmente estruturas condicionais e de repetição",
        "Programação básica em Python",
        "Conhecimentos sobre instalação de softwares básicos, porém, durante o curso será mostrado o processo de instalação das ferramentas utilizadas",
        "Noções de Orientação a Objetos, como: classes, objetos, atributos e métodos",
        "Conhecimentos básicos sobre Redes Neurais Artificiais são desejáveis (no final do curso tem um anexo para revisar esse conteúdo)"
      ],
      "description": "A área de Deep Learning (Aprendizagem Profunda) está relacionada a aplicação das redes neurais artificiais na resolução de problemas complexos e que requerem artifícios computacionais avançados. Existem diversas aplicações práticas que já foram construídas utilizando essas técnicas, tais como: carros autônomos, descoberta de novos medicamentos, cura e diagnóstico antecipado de doenças, geração automática de notícias, reconhecimento facial, recomendação de produtos, previsão dos valores de ações na bolsa de valores e até mesmo a geração automática de roteiros de filmes! Nesses exemplos, a técnica base utilizada são as redes neurais artificiais, que procuram \"imitar\" como o cérebro humano funciona e são consideradas hoje em dia como as mais avançadas no cenário de Machine Learning (Aprendizagem de Máquina).\nTambém dentro do contexto da Aprendizagem de Máquina existe a área de Aprendizagem por Reforço, que é um tipo de aprendizagem usado em sistemas multi-agente no qual os agentes devem interagir no ambiente e aprenderem por conta própria, ganhando recompensas positivas quando executam ações corretas e recompensas negativas quando executam ações que não levem para o objetivo. O interessante dessa técnica é que a inteligência artificial aprende sem nenhum conhecimento prévio, adaptando-se ao ambiente e encontrando as soluções sozinho!\nE para levar você até essa área, neste curso você terá uma visão teórica e principalmente prática sobre a construção de um carro autônomo virtual utilizando aprendizagem por reforço! Vamos trabalhar com técnicas modernas de Deep Learning com a biblioteca PyTorch e a linguagem Python! Ao final você terá todas as ferramentas necessárias para solucionar outros tipos de problemas com aprendizagem por reforço. O conteúdo do curso está dividido em três partes:\nTeoria sobre aprendizagem por reforço com o algoritmo Q-Learning\nTeoria da aprendizagem por reforço com Deep Q-Learning, com a utilização de redes neurais artificiais\nConstrução passo a passo da inteligência artificial para controlar o carro autônomo\nVocê ainda conta com um anexo sobre o básico das redes neurais artificiais caso você não tenha muita experiência na área.\nEste curso é categorizado como nível intermediário, pois apesar de existir o anexo para a revisão do conteúdo básico, é interessante que você já tenha uma certa experiência com a área de redes neurais.\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em deep learning (aprendizagem profunda)",
        "Pessoas interessadas em aprender como modelar a construção de um carro autônomo virtual",
        "Pessoas interessadas em aprendizagem por reforço com o algoritmo Deep Q-Learning",
        "Analistas de dados que queiram aumentar seu conhecimento na área de deep learning (aprendizagem profunda)",
        "Alunos de graduação que estão estudando disciplinas ligadas a área de Inteligência Artificial"
      ]
    },
    {
      "title": "Bootcamp de ChatGPT y Prompt Engineering: de cero a experto",
      "url": "https://www.udemy.com/course/bootcamp-de-prompt-engineering-en-chatgpt-de-cero-a-experto/",
      "bio": "Aprenderás todo lo relacionado con ChatGPT y GPT-4: prompt engineering, fine tunning, WebChatGPT, Auto-GPT, extensiones",
      "objectives": [
        "Prompt engineering con ChatGPT",
        "Fundamentos de ChatGPT",
        "Técnicas avanzadas de Prompt engineering con ChatGPT",
        "Modelos de ChatGPT autonomos con Auto-GPT",
        "Técnicas de Fine Tunning para ChatGPT"
      ],
      "course_content": {
        "Materiales": [
          "Bootcamp de ChatGPT y Prompt Engineering: de cero a experto"
        ],
        "Introducción al curso y a Udemy": [
          "Introducción al curso",
          "Introducción a la plataforma de Udemy",
          "Material del Curso"
        ],
        "Introducción a ChatGPT": [
          "OpenAI: la compañía detrás del algoritmo de ChatGPT",
          "Introducción a ChatGPT",
          "Laboratorio: Primeros pasos con ChatGPT",
          "+200 Prompts con Awesome ChatGPT Prompts",
          "AIPRM la extensión para optimizar el uso de ChatGPT",
          "Ventajas de ChatGPT y diferencias con ChatBot convencionales",
          "Limitaciones de ChatGPT"
        ],
        "Acceso a los LLMs mas conocidos": [
          "Los modelos de lenguaje (LLMs) más conocidos",
          "Funcionamiento y acceso a la API de OpenAI",
          "Todo sobre Gemini el competidor de ChatGPT lanzado por Google",
          "Modelos Open Source y Modelos Específicos de Dominio"
        ],
        "IA Generativa": [
          "IA Generativa y a sus palicaciones: ChatGPT, DALLE, Stable Diffusion, Dreambooth",
          "Modelos discriminativos vs modelos generativos",
          "Empresas de IA Generativa",
          "GANs Generative Adversarial Networks",
          "Modelos basados en Transformers",
          "Variational Auto Encoders y espacio latente",
          "Desafios de la IA Generativa",
          "Cuestionario"
        ],
        "Historia del desarrollo de los modelos de GPT": [
          "Historia del desarrollo de los modelos de GPT",
          "Modelos LLM y LSTM",
          "Fundamentos de GPT-2, GPT-3 e InstructGPT",
          "Desarrollo del modelo de ChatGPT"
        ],
        "Seguridad y protección de datos en ChatGPT": [
          "Riesgos y Privacidad de datos en ChatGPT",
          "ChatGPT empresarial con Azure OpenAI Service",
          "Recomendaciones para maximizar la seguridad y privacidad de datos en ChatGPT",
          "Privacidad con la nueva suscripción de ChatGPT Business",
          "Cuestionario"
        ],
        "Fundamentos del Prompt Engineering": [
          "Introducción al Prompt Engineering",
          "Como obtener Prompts efectivos en ChatGPT",
          "Marco general para ChatGPT"
        ],
        "Como hacer un uso efectivo de ChatGPT": [
          "Prompts efectivos en ChatGPT",
          "Técnicas y proceso para generar Prompts efectivos",
          "Técnicas para evitar la ambiguedad en los Prompts",
          "Cuestionario"
        ],
        "Técnicas básicas de Prompt Engineering": [
          "Técnica de Prompt Engineering de Priming",
          "Zero-Shot Prompting, One-Shot Prompting o Few-shot prompting",
          "Técnicas de Chain-of-thought y zero-shot Chain-of-thought"
        ]
      },
      "requirements": [
        "No hay"
      ],
      "description": "En este curso, exploraremos cómo utilizar la tecnología de ChatGPT de manera más efectiva mediante el uso de las técnicas de Prompt Engineering.\nEn los últimos años, la Inteligencia Artificial ha evolucionado rápidamente, lo que ha permitido a los usuarios experimentar nuevas formas de interactuar con las máquinas. En particular, la tecnología de ChatGPT ha demostrado ser una herramienta extremadamente útil para una amplia variedad de aplicaciones, como atención al cliente, generación de texto, e incluso, asistentes virtuales.\nSin embargo, a pesar de su efectividad, utilizar ChatGPT puede ser un desafío para los usuarios que no están familiarizados con la Inteligencia Artificial. En particular, una de las principales barreras para la utilización de ChatGPT es la dificultad para generar prompts efectivos que permitan a la tecnología entender lo que se le está pidiendo.\nEs por eso que hemos desarrollado este curso. Queremos proporcionar a los participantes una base sólida de las diferentes técnicas de Prompt Engineering, así como las herramientas y habilidades necesarias para utilizar ChatGPT de manera efectiva.\nYa sea que estés buscando implementar ChatGPT en tu negocio o simplemente desees explorar el uso de ChatGPT, este curso te proporcionará el conocimiento y la confianza que necesitas para sacar el máximo provecho a ChatGPT.",
      "target_audience": [
        "Cualquier persona que quiera aprender acerca de CHatGPT",
        "Cualquier persona que quiera hacer un uso efectivo de ChatGPT",
        "Cualquier persona que quiera aplicar ChatGPT en su día a día"
      ]
    },
    {
      "title": "みんなのKaggle講座 -Pythonのコードと共にコンパクトに学ぶKaggleの始め方-",
      "url": "https://www.udemy.com/course/learning-kaggle/",
      "bio": "データに関する課題を競うプラットフォームKaggleで、機械学習、データサイエンスを実践しましょう。理論よりも体験を重視し、Kaggleの様々なテクニックを学んでいきます。PythonとGoogle Colaboratoryを使用します。",
      "objectives": [
        "Kaggle全般の基礎的な知識を学びます。",
        "Kaggleの初歩的な課題に取り組む力が身に付きます。",
        "Kaggleの画面の見方、課題の提出方法を学びます。",
        "スコア向上のための基礎的な知識が身に付きます。",
        "Kaggleで本格的な課題に取り組むための下地が身に付きます。"
      ],
      "course_content": {
        "Kaggleの概要": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "Kaggleの概要",
          "Kaggleの設定",
          "開発環境について",
          "演習"
        ],
        "機械学習とKaggle": [
          "セクション2の教材",
          "Section2の概要",
          "機械学習の概要",
          "機械学習のアルゴリズム",
          "Pandasの基礎",
          "Kaggleで機械学習を扱う",
          "演習"
        ],
        "精度向上のためのテクニック": [
          "セクション3の教材",
          "Section3の概要",
          "特徴量エンジニアリング",
          "ハイパーパラメータの調整",
          "交差検証",
          "演習"
        ],
        "Titanicの先へ": [
          "セクション4の教材",
          "Section4の概要",
          "Tabular Playground Seriesにトライしよう！",
          "AutoMLの概要",
          "AutoMLによる機械学習の自動化",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "中学-高校レベルの数学で十分です。高度な数学は必要ありません。",
        "Google ColaboratoryとKaggleを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。",
        "Kaggleのアカウントが必要になります。取得方法は講義の中で解説します。",
        "機械学習、データサイエンス自体については概要のみの解説となります。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。",
        "ディープラーニング（深層学習）は扱いません。ディープラーニングについて学びたい方には他のコースをお勧めします。"
      ],
      "description": "「みんなのKaggle講座」は、実践的なデータに関する課題を競うプラットフォーム、Kaggleの入門講座です。\nKaggleについて要点をおさえてコンパクトに学びます。\nKaggleは企業や研究機関などが提供する様々な課題に対して、世界中の参加者が精度を競うプラットフォームです。\nデータ収集や環境構築の手間がかからないため、誰でも手軽に始めることができます。\n\n\nまた、優秀スコアを残した参加者には、賞金やスコアに応じた称号が与えられるため、ゲーム感覚で楽しみながらデータサイエンス、機械学習のスキルを身につけることができます。\n実際に、多くの企業がKaggleのスコアをリクルーティングに利用しており、機械学習エンジニア、データサイエンティストの求人要件にKaggleでの実績が掲載されることもあります。\n\n\n本講座では、このようなKaggleへの取り組み方を学びます。\n理論よりも体験を重視し、Kaggleに親しんでいきます。\nPythonのコードを書きながら、様々な課題に取り組んでスコアを競いましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live! AIRS-Lab】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. Kaggleの概要\n→ Kaggleの概要と設定、開発環境について学びます。\nSection2. 機械学習とKaggle\n→ 機械学習の概要と、Kaggleの課題への適用について学びます。\nSection3. 精度向上のためのテクニック\n→ 機械学習モデルを改善し、スコアを向上させるためのテクニックについて学びます。\nSection4. Titanicの先へ\n→ さらに高度な課題に取り組むための指針を学びます。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "Kaggleに興味があるけど、始め方が分からない方。",
        "Kaggleを通して機械学習、データ分析を学びたい方。",
        "ゲーム感覚でKaggleを楽しみたい方。",
        "機械学習、データサイエンスの実績が欲しい方。",
        "機械学習、データサイエンスによる問題解決力を身につけたい方。",
        "これまで学んだAI技術を何かに活かしたい方。"
      ]
    },
    {
      "title": "Random forests with Python & Scikit-Learn Machine Learning",
      "url": "https://www.udemy.com/course/random-forests-with-python-scikit-learn-machine-learning/",
      "bio": "\"Learning Random Forest Models with Python and Scikit-Learn\"",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic Python programming knowledge.",
        "Familiarity with foundational machine learning concepts is helpful but not required."
      ],
      "description": "Random forrests with Python & Scikit-Learn Machine Learning\nCourse Overview:\nDive into the world of Random Forests, one of the most powerful and widely used ensemble learning methods in machine learning. This course, tailored for both beginners and enthusiasts, will guide you through the fundamentals, practical applications, and advanced techniques of building and optimizing Random Forest models using Python's robust Scikit-Learn library.\nWhat You'll Learn:\nUnderstand Random Forests: Learn how this ensemble method combines multiple decision trees to enhance performance in classification and regression tasks.\nBuild and Train Models: Gain hands-on experience creating Random Forest models and understand the impact of randomness in bootstrapping and feature selection.\nFeature Importance Analysis: Discover how to interpret your models by analyzing feature importance and making data-driven decisions.\nHandle Overfitting: Learn techniques like parameter tuning (e.g., n_estimators, max_depth, max_features) to balance model complexity and performance.\nAdvanced Topics: Explore concepts like out-of-bag (OOB) error estimation, feature selection, and strategies for handling imbalanced datasets.\nComparison with Other Algorithms: Understand the advantages of Random Forests compared to simpler models like decision trees and other ensemble methods like Gradient Boosting.\nReal-World Applications: Use Random Forests to tackle classification and regression problems in diverse fields such as finance, healthcare, and marketing.\nWhy Take This Course?\nBeginner-Friendly: Start with the basics of Random Forests and progress to advanced optimization techniques.\nPractical Examples: Work with real-world datasets, such as the Titanic dataset or UCI Machine Learning Repository datasets.\nModel Interpretation: Master tools like plot_tree for decision tree visualization, permutation importance, and SHAP values to explain model predictions.\nGuided Projects: Reinforce your skills with hands-on projects such as predicting customer churn, forecasting sales, or building sentiment analysis models.\nPrerequisites:\nBasic Python programming knowledge.\nFamiliarity with foundational machine learning concepts is helpful but not required.\nWho Is This Course For?\nAspiring data scientists and machine learning engineers looking to specialize in ensemble methods.\nBusiness analysts seeking to improve predictive modeling and decision-making capabilities.\nAnyone curious about the mechanics and applications of Random Forests in real-world scenarios.\nEnroll today and unleash the full potential of Random Forests with Scikit-Learn to elevate your machine learning expertise!",
      "target_audience": [
        "Aspiring data scientists and machine learning engineers looking to specialize in ensemble methods.",
        "Business analysts seeking to improve predictive modeling and decision-making capabilities.",
        "Anyone curious about the mechanics and applications of Random Forests in real-world scenarios."
      ]
    },
    {
      "title": "Data Preprocessing and Exploratory Data Analysis (EDA)",
      "url": "https://www.udemy.com/course/uci-data-preprocessing-and-exploratory-data-analysis/",
      "bio": "Master Data Cleaning, Feature Engineering, and Visualization Techniques for Machine Learning Success Using UCI Datasets",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic understanding of Python and data structures is helpful but not mandatory.",
        "Students will need a computer or laptop with internet access to perform hands-on exercises.",
        "Recommended: Install Python, Jupyter Notebook, and essential data science libraries like pandas, matplotlib, and seaborn.",
        "No prior experience with machine learning is required — everything will be taught step-by-step."
      ],
      "description": "Welcome to the \"UCI Data Preprocessing and Exploratory Data Analysis in Machine Learning\" course, where we'll dive into the essential steps of preparing and understanding your data for effective machine learning. In this course, we will equip you with the knowledge and techniques necessary to harness the full potential of data in your machine learning endeavors using datasets from the UCI Machine Learning Repository.\nCourse Highlights:\n1. Data Preprocessing Essentials: Begin by learning the critical steps involved in data preprocessing. You'll explore techniques for handling missing data, dealing with outliers, and performing data transformations to ensure the quality and integrity of your datasets.\n2. UCI Machine Learning Repository: Gain familiarity with the UCI Machine Learning Repository, a valuable resource for access to a wide range of datasets. Learn how to retrieve, load, and work with datasets from this repository for various machine learning tasks.\n3. Exploratory Data Analysis (EDA): Dive into the world of EDA, where you'll uncover hidden patterns and gain valuable insights from your data. Explore data visualization techniques, statistical summaries, and data profiling to understand your datasets thoroughly.\n4. Feature Engineering: Discover the art of feature engineering and how to create informative features that improve the predictive power of your machine learning models. You'll learn techniques for selecting, transforming, and creating new features from existing data.\n5. Data Preparation for Modeling: Understand the crucial steps of preparing data for machine learning models. This includes data encoding, splitting into training and testing sets, and ensuring that your data is ready for various algorithms.\n6. Hands-on Projects: Apply your knowledge through hands-on projects and exercises. Work with real-world datasets from the UCI repository to practice data preprocessing and EDA techniques in the context of practical machine learning problems.\n7. Data Visualization: Master data visualization techniques that help you communicate your findings effectively. Create impactful charts and graphs to convey your data-driven insights to stakeholders.\n8. Best Practices and Pitfalls: Learn best practices for data preprocessing and EDA, as well as common pitfalls to avoid. Gain insights into how to make informed decisions at each stage of data preparation.\n9. Real-world Applications: Explore real-world applications of data preprocessing and EDA across various domains, including healthcare, finance, and marketing. Understand how these techniques are applied to solve complex problems.\n10. Preparing for Advanced Machine Learning: Set the stage for advanced machine learning tasks by mastering the fundamentals of data preparation and EDA. You'll be well-prepared to tackle more complex machine learning challenges.",
      "target_audience": [
        "Beginners interested in data science, data analysis, or machine learning.",
        "Students and professionals who want to strengthen their data preparation and EDA skills.",
        "Aspiring machine learning engineers looking to build a strong foundation before modeling.",
        "Anyone curious about working with real-world datasets from the UCI Machine Learning Repository."
      ]
    },
    {
      "title": "Python Básico ao Avançado + RPA + Criação de Projetos Reais",
      "url": "https://www.udemy.com/course/python-rpa-e-excel-aprenda-automatizar-processos-e-planilhas/",
      "bio": "Aprenda: Programação, Automação, Pandas, PDF, SQLite, MongoDB, FastAPI, Dash, Flask, Aprendizado de Máquina, Jogos e +++",
      "objectives": [
        "Lógica da Linguagem Python (Variáveis, IF, While, For, Funções, Listas, Tuplas, Dicionários, Set, Matrizes, POO, Lista Encadeada, Pilha, Fila, Árvore, Grafos)",
        "Desenvolva Robôs Sofisticados para Automatizar Tarefas, Importar e Exportar Informações de Websites, e também Crie Vários Projetos Reais com Interfaces Gráfica",
        "Você aprenderá sobre Aprendizado de Máquina, Algoritmos de Árvore de Decisão, Naive Bayes, Aprendizado Supervisionado e por Reforço",
        "Crie Projetos Reais com Interface Gráfica com o uso do Tkinter e eleve seu nível de Python",
        "Jogos com PyGame",
        "Criar robô para manipular dados no Excel, Word e extrair dados de PDF",
        "Dispara e-mails em massa usando Python, Excel e Outlook",
        "Pandas",
        "Xlsxwither",
        "Openpyxl",
        "Tkinter",
        "Python com SQL",
        "Python com MongoDB",
        "Aprendizado de Máquina",
        "Como as Máquinas Aprendem",
        "Dash",
        "Flask",
        "Fast API"
      ],
      "course_content": {
        "Introdução": [
          "Introdução",
          "Importante!",
          "Links para Download do Anaconda",
          "Instalando o Anaconda"
        ],
        "Lógica de Programação em Python": [
          "Orientação",
          "Comentários e Variáveis",
          "Variáveis e Exercícios",
          "Exercício: Manipulação de Variáveis",
          "Input",
          "Random",
          "Trabalhando com Strings",
          "Trabalhando com Strings parte 2 + Exercícios",
          "Exercício: Manipulação de Strings",
          "If... ElIf... Then... com And ... Or + Exercício",
          "Exercício: Verificar faixa etária",
          "While",
          "Exercícios While",
          "Exercício Simulação de Caixa Eletrônico",
          "Exercício Calculadora Simples",
          "While Usando uma Condição Complexa",
          "Exercício: Soma dos primeiros números ímpares",
          "For + Exercícios",
          "Exercício For com Números",
          "For com Strings + Exercícios",
          "For Nested + Exercícios",
          "For Criando um Triangulo e um Retângulo",
          "Funções Simples e com Argumentos Default, Non-default e *Args",
          "Kwargs, Variáveis locais vs. globais e nonlocal",
          "Exercício Funções",
          "Funções Anônimas (Lambda)",
          "lambda com filter e lambda com map",
          "Exercício de lambda com filter e lambda com map",
          "Funções Internas (built-in), Recursão, Documentação e Anotações de Funções",
          "Introdução às Listas, Criando e Acessando",
          "Operações Básicas com Listas + Exercício",
          "Métodos de Listas - sort, reverse, count e index",
          "Slicing de Listas",
          "List Comprehensions",
          "Listas Aninhadas",
          "Utilidades e Funções com Listas",
          "Iteração em Listas",
          "Listas e Strings",
          "Exercício Lista de Compras",
          "Exercício Classificação de Números",
          "Definição e Criação de Tuplas",
          "Tuplas - Acesso aos Elementos",
          "Tuplas - Imutabilidade",
          "Operações com Tuplas",
          "Métodos de Tuplas",
          "Desempacotamento de Tuplas",
          "Aplicações Práticas",
          "Comparando Tuplas",
          "Diferenças entre Listas e Tuplas",
          "Introdução aos Dicionários e Criando Dicionários",
          "Acessando Itens do Dicionário",
          "Operações Básicas com Dicionários",
          "Métodos de Dicionários",
          "Iterando Sobre Dicionários",
          "Dicionários Aninhados",
          "Compreensão de Dicionários (Dictionary Comprehension)",
          "Dicionários e Funções",
          "Dicas e Boas Práticas",
          "Exercício - Agenda Telefônica Simplificada",
          "Set - Definição e Características e Criando um Conjunto",
          "Adicionando e Removendo Elementos",
          "Operações com Conjuntos - União, Intersecção, Diferença e Diferença simétrica",
          "Outras Funções e Métodos",
          "Imutabilidade e Frozensets",
          "Aplicações Práticas",
          "Limitações",
          "Introdução a Matrizes",
          "Matriz - Somar Coluna e Linhas e Exercício",
          "Matriz de Strings",
          "Exercício - Urna Eletrônica com Matrizes",
          "Exercício - Reserva de Assentos no Cinema usando Matrizes",
          "Exercício - Jogo da Velha com Matriz"
        ],
        "POO - Programação Orientada a Objeto": [
          "Introdução à POO",
          "POO - Conceitos Básicos",
          "Classes e Objetos Definindo e Instanciando Classes.",
          "Atributos - Definindo e Acessando Atributos de uma Classe.",
          "Exercício Simulando a Rotina de uma Pessoa",
          "Métodos Definindo e chamando métodos de uma classe",
          "Exercício Sistema de Reservas para um Evento",
          "Exercício Manipulador de Listas em Python",
          "Encapsulamento - Protegendo os dados de uma classe (public, private, protected)",
          "Encapsulamento Métodos getters e setters",
          "Exercício Pet",
          "Encapsulamento Propriedades (usando o decorador @property)",
          "Herança Simples",
          "Herança Múltipla",
          "Uso da função super()",
          "Polimorfismo de sobrecarga",
          "Polimorfismo de sobrescrita (também conhecido como overriding)",
          "Exercício Sistema de Gerenciamento de Estudantes",
          "Exercício Agenda de Contatos com Programação Orientada a Objetos"
        ],
        "Treine seus conhecimentos com esses Exercícios": [
          "Instruções",
          "Exercícios sobre IF",
          "Exercícios sobre IF parte 2",
          "Exercícios sobre For",
          "Exercícios sobre While",
          "Exercicios Listas",
          "Exercícios Funções",
          "Desafios - parte 1",
          "Desafios - parte 2",
          "Desafios - parte 3",
          "Desafios - parte 4",
          "Desafios - parte 5",
          "Desafios - parte 6",
          "Exercícios 1 e 2",
          "Exercícios 3 e 4",
          "Exercícios 5 e 6",
          "Exercícios 7 e 8",
          "Exercícios 9 e 10",
          "Exercícios 11 e 12",
          "Exercícios 13 e 14",
          "Exercício 15",
          "Exercícios 16, 17 e 18",
          "Exercícios 19 e 20",
          "Exercícios 21 e 22",
          "Exercícios 23 e 24",
          "Exercício 25",
          "Exercício 26",
          "Exercício 27",
          "Exercícios 28 e 29",
          "Exercício 30"
        ],
        "Simulado: Avaliação de Competências em Python": [
          "Avaliação de Competências em Python"
        ],
        "Robô 1 - Controlando o computador": [
          "Controlando o Computador - O que vamos aprender?",
          "Instalando Biblioteca e Criando Scrip para Controlar o Computador",
          "Criando Scrip para abrir o Google Chorome e Consultar o Valor do Dólar",
          "Script para Abrir e fechar o Notepad",
          "Criando Menu de Opções para abrir Excel, Word ou Notepad",
          "Teste de Fixação"
        ],
        "Robô 2 - Extraindo Dólar e Euro da Internet e Salvando no Excel": [
          "Extraindo Dólar e Euro da Internet - O que vamos aprender?",
          "Aviso Importante sobre a Cotação do Dólar",
          "Instalando Selenium e Baixando Arquivo do Chrome Drive",
          "Abrindo o Google e Capturando o Valor do Dólar",
          "Abrindo o Google e Capturando Dólar e Euro",
          "Instalando a Biblioteca xlsxwriter e Criando um arquivo de Excel",
          "Salvando Dolar e Euro no Excel",
          "Teste de Fixação"
        ],
        "Robô 3 - Extraindo Endereço por CEP e Salvando no Excel": [
          "Extrair CEP da Web - O que vamos aprender",
          "Busca CEP - Primeiros Passos",
          "Buscando Endereço por CEP e Salvando no Excel",
          "Buscando CEPs em Massa e Salvando no Excel",
          "Teste de Fixação"
        ],
        "Extraindo Dados Empresa por CNPJ e Salvando no Excel": [
          "Extraindo Dados Empresa por CNPJ e Salvando no Excel - O que vamos aprender",
          "Consultando um CNPJ e imprimindo os dados da Empresa",
          "Consultando CNPJ e salvando dados no Excel",
          "Consultando CNPJ em Massa e Salvando no Excel"
        ],
        "Robô 4 - Preenchendo formulários WEB com Python e Excel": [
          "Preenchendo Formulários Web - O que vamos aprender?",
          "Preenchendo Formulário e Salvando",
          "Abrindo Excel e dando um For em Linha a Linha"
        ]
      },
      "requirements": [
        "Computador com acesso à internet",
        "Instalar o Jupyter Notebook (Anaconda3) ou Superior",
        "Familiaridade com Excel",
        "Windows (10 ou superior)",
        "Nenhum software pago é necessário."
      ],
      "description": "Quer aprender Python de verdade, transformar sua carreira e se destacar no mercado?\n\n\nConheça o Curso Completo de Python do Básico ao Avançado + RPA + Projetos Reais com Banco de Dados — a formação ideal para quem quer dominar a linguagem mais requisitada do mundo e se tornar um especialista em automação de processos, análise de dados e criação de sistemas profissionais.\n\n\nCertificado oferecido pela Udemy de 438,5 horas.\n\n\nO que você vai aprender?\n\n\nO curso aborda os seguintes temas:\n\n\nSeção 1: Introdução\nSeção 2: Lógica de Programação em Python - Mais de 26 horas sobre Lógica de Programação.\nSeção 3: POO - Programação Orientada a Objeto\nSeção 4: Treine seus conhecimentos com esses Exercícios - Mais de 24 horas de Exercícios.\nSeção 5: Simulado: Avaliação de Competências em Python\nSeção 6: Robô 1 - Controlando o computador\nSeção 7: Robô 2 - Extraindo Dólar e Euro da Internet e Salvando no Excel\nSeção 8: Robô 3 - Extraindo Endereço por CEP e Salvando no Excel\nSeção 9: Extraindo Dados Empresa por CNPJ e Salvando no Excel\nSeção 10: Robô 4 - Preenchendo formulários WEB com Python e Excel\nSeção 11: Python Excel - Trabalhando com xlsxwither\nSeção 12: Python Excel - Trabalhando com openpyxl\nSeção 13: Python Excel Avançado - Quebrando Arquivos e Criando Emails\nSeção 14: Python Excel - Consolidando Arquivos com pandas e openpyxl\nSeção 15: Bônus - Extraindo dados de tabelas da WEB\nSeção 16: Python e Word gerando Certificados\nSeção 17: Python Texto e PDF - Trabalhando com Bloco de Notas (txt) e Arquivos PDF\nSeção 18: Python Pandas Analise e Tratamento de Dados\nSeção 19: Python e WhatsApp Web automatizando o envio de mensagens\nSeção 20: Desafio RPA\nSeção 21: Interface Gráfica com Python e Tkinter - Primeiros Passos\nSeção 22: Interface Gráfica - Busca Endereço\nSeção 23: Interface Gráfica - Projeto 2\nSeção 24: Gerador de Senhas\nSeção 25: Exercício Tabuada\nSeção 26: Sorteador de Números\nSeção 27: Gerador de CPF\nSeção 28: Conversor de Código Binário\nSeção 29: Relógio Mundial\nSeção 30: Cronômetro\nSeção 31: Efeito de Revelação Dinâmica\nSeção 32: Scroller de Texto\nSeção 33: Tooltip Básico\nSeção 34: Tooltip Lista de Produtos com Imagens\nSeção 35: Tabela com Tooltip\nSeção 36: Treeview\nSeção 37: Treeview com 2 níveis\nSeção 38: Projeto Arquivo em Abas - Gestão de Funcionários\nSeção 39: Exercício - Gestão de Notas dos Estudantes\nSeção 40: Navegação por Página\nSeção 41: Passar Dados entre Listas\nSeção 42: Tabela Destacar Linhas e Coluna Célula Ativa\nSeção 43: Exercício - Tabela Destacar Linhas e Coluna Célula Ativa com Dado\nSeção 44: Congelar Painéis\nSeção 45: Exercício - Congelar Painéis\nSeção 46: Tabela com Agrupamento\nSeção 47: Exercício - Tabela com Agrupamento\nSeção 48: Combobox Dependente\nSeção 49: Listbox com Seleção Múltipla\nSeção 50: Formatação Condicional\nSeção 51: Python com SQL\nSeção 52: Baixando e Instalando o MongoDB\nSeção 53: Banco de Dados MongoDB - Gerenciador de Dados\nSeção 54: Banco de Dados Mongo DB - Controle de Estoque\nSeção 55: Criando um Programa com Interface Gráfica com Recursos do Pandas\nSeção 56: Gráficos com Interface Gráfica\nSeção 57: Criando um Sistema Simulador de Teste de Emprego\nSeção 58: Exercício Reserva Passagens Ônibus\nSeção 59: Exercício Reserva de Quadra\nSeção 60: Exercício - Controle Vagas Estacionamento\nSeção 61: Projeto Fila de Banco\nSeção 62: Caixa Eletrônico com Interface Gráfica e Banco de Dados no Excel\nSeção 63: Exercício Eleições\nSeção 64: Exercício - Vencimento Produtos\nSeção 65: Desafio Controle Pedidos Lanchonete\nSeção 66: Gerador de QR Code\nSeção 67: Conferidor de Jogos da Mega Sena\nSeção 68: Conferidor de Jogos Lotofacil\nSeção 69: Simulador de Semáforo Interativo\nSeção 70: Python com Google Sheets\nSeção 71: Lista Encadeada\nSeção 72: Pilhas\nSeção 73: Filas\nSeção 74: Árvores\nSeção 75: Grafos\nSeção 76: BIG - O\nSeção 77: Aprendizado de Máquina\nSeção 78: Como as Máquinas Aprendem\nSeção 79: IA Formatação por Comando\nSeção 80: PyGame - Primeiros Passos\nSeção 81: PyGame - Jump\nSeção 82: PyGame - Jogo Obstáculo\nSeção 83: PyGame - Jogo Pula Entre Plataformas\nSeção 84: PyGame - Jogo Quebra Cabeça\nSeção 85: PyGame - Jogo Caça Palavras\nSeção 86: PyGame - Tetris\nSeção 87: PyGame - Jogo de Carrinho\nSeção 88: Breakout Game\nSeção 89: Dash\nSeção 90: Flask\nSeção 91: Projeto Gerenciador de Tarefas com MongoDB\nSeção 92: Projeto de Agendamento de Consultas com MongoDB\nSeção 93: Projeto - Sistema de Reserva de Passagens com MongoDB\nSeção 94: Projeto - Sistema de Supermercado com MongoDB\nSeção 95: Projeto - Sistema para Clínica Veterinária com MongoDB\nSeção 96: Projeto - Sistema de Cabeleireiro\nSeção 97: Projeto - Sistema de Reserva de Cinema\nSeção 98: Sistema de Reserva de Campo e Quadra\nSeção 99: Sistema de Gerenciamento Escolar\nSeção 100: Loja de Brinquedos com MongoDB\nSeção 101: Sistema Gerenciamento de Pousadas com MongoDB\nSeção 102: Fast API\nSeção 103: Exercício Jogo de Matemática\nSeção 104: Exercício Jogo da Tabuada\nSeção 105: Exercício Jogo da Forca\nSeção 106: Jogo da Memória\nSeção 107: Exercício Batalha Naval\nSeção 108: Jogo de Puzzle de Números\nSeção 109: Jogo de Copos\nSeção 110: Desafio no Labirinto\nSeção 111: Jogo da Garrafa\nSeção 112: Jogo das Bolhas Matemáticas\nSeção 113: Exercício - Jogo de Bolhas com Letras\nSeção 114: Jogo de Combinação de Frutas\nSeção 115: Jogo de Conectar Números\nSeção 116: Jogo de Conectar Letras\nSeção 117: Jogo do Termo\nSeção 118: Space Invaders\nSeção 119: Jogo Piano Tiles\nSeção 120: Jogo de Matemática\nSeção 121: Jogo Bee Honey\nSeção 122: Jogo Flappy Bird\nSeção 123: Jogo Solte o Objeto na Lixeira\nSeção 124: Jogo de Desviar dos Obstáculos\nSeção 125: Caça ao Pato com Estilingue\nSeção 126: Jogo do Pássaro\nSeção 127: Jogo Helicóptero no Túnel\nSeção 128: Jogo Pac-Man\nSeção 129: Jogo Zig-Zag\nSeção 130: Exercicio - Jogo de Tradução\n\n\n\n\nTudo isso com foco total na prática\nNada de teoria solta. Você aprenderá Python desenvolvendo projetos reais!\n\n\nPor que aprender Python?\nPython é utilizado diariamente por empresas como Google, Amazon, Facebook, Microsoft e muitas outras. É uma das linguagens mais procuradas do mundo por sua versatilidade, facilidade de uso e capacidade de criar desde scripts simples até sistemas complexos com inteligência artificial.\n\n\nPor que esse curso é diferente?\n\n\nCurso 100% online, com acesso vitalício e suporte contínuo\nAulas passo a passo, organizadas em ordem lógica para aprendizado real\nUtilização da ferramenta: Jupyter Notebook (Anaconda)\n\n\nO que você será capaz de fazer após o curso\n\n\nCriar projetos completos do zero com Python\nAutomatizar tarefas e rotinas com RPA\nTrabalhar com dados em planilhas e bancos de dados\nCriar APIs e sistemas web\nCriar dashboards e visualizações de dados interativas\nDesenvolver modelos básicos de aprendizado de máquina\nProduzir portfólio profissional para entrevistas de emprego\n\n\nPara quem é este curso?\n\n\nIniciantes que querem aprender programação do zero\nProfissionais que querem automatizar suas tarefas e ganhar produtividade\nPessoas em transição de carreira para a área de tecnologia e dados\nQuem deseja oportunidades melhores e salários mais altos\nQuem busca aprender de forma prática, moderna e com foco em resultados reais\n\n\nComece agora mesmo e transforme seu futuro com Python.\nVocê terá em mãos todas as ferramentas para sair do zero e conquistar seu lugar no mercado de tecnologia.\n\n\nSatisfação garantida ou seu dinheiro de volta\n\"E se eu não gostar do curso?” A Udemy oferece a todos os alunos uma garantia de reembolso, esse é mais um motivo e um incentivo para você começar já! Após a compra do curso, você tem 30 dias para testar o produto, e se não gostar, basta solicitar o reembolso.\n\n\nEntão, está pronto para se tornar indispensável no mercado de trabalho? Junte-se a nós e comece a sua jornada para se tornar um mestre em Python, RPA e Excel!\n\n\nJunte-se a mais de 125 mil alunos que já fizeram e aprovaram meus outros cursos! Comece agora mesmo esse curso!",
      "target_audience": [
        "Qualquer pessoa que tenha vontade de aprender Python e Automatizar Tarefas"
      ]
    },
    {
      "title": "Prompt Engineering: ChatGPT, Midjourney & Stable Diffusion",
      "url": "https://www.udemy.com/course/prompt-engineering-chatgpt-midjourney-stable-diffusion/",
      "bio": "Prompt Engineering in LLMs und Diffusion Modellen: ChatGPT, Midjourney, Google Bard, Gemini, DALL•E und Stable Diffusion",
      "objectives": [
        "Hier geht es vor allem um den richtigen Prompt für das richtige Tool",
        "negatives Prompting für Stable Diffusion",
        "Prompt Engineering für Midjourney",
        "Prompting und Priming für ChatGPT",
        "Wie behandeln alle wichtigen AI-Tools",
        "Du wirst die perfekten Prompts für alle AI-Tools schreiben!",
        "Du lernst fortgeschrittene Techniken für 10X bessere Ergebnisse",
        "Warum ist Prompt Engineering wichtig",
        "Die Basics zu Large language Models wie ChatGPT, Bard, Bing und die Anmeldung",
        "Prompt Engineering in LLMs",
        "Komplettes Priming, Tipps und Erklärungen",
        "Trainiere ChatGPT damit er für dich ein Prompt Engineer wird",
        "Prompt Engineering speziell für Bard",
        "Prompt Engineering für Bing",
        "Die Basics zu Diffusion Modellen und die Plattformen",
        "Prompt Engineering in Dall-E",
        "Prompt Engineering für Text to Video mit Gen2",
        "Prompt Engineering für Text to Text",
        "Prompt Engineering für Text to Bild",
        "Du lernst viele Helfer-Tools kennen",
        "Prompt Engineering als Haupt-Beruf und Side Hustle"
      ],
      "course_content": {
        "Einführung": [
          "Willkommen!",
          "Kurs Überblick",
          "Mein Ziel und was dich erwartet",
          "Wichtige Updates",
          "Dozentenvorstellung: Arnold Oberleiter (Arnie)"
        ],
        "Warum ist Prompt Engineering wichtig? ein cooles Beispiel": [
          "Warum ist Prompt Engineering wichtig: Ein Beispiel"
        ],
        "Die Basics zu Large Language Models wie ChatGPT, Bard, Bing und die Anmeldung": [
          "Was sind Large Language Models wie ChatGPT, Bard und Bing",
          "Das Token Limit bestimmt die Größe vom Kontext die das Modell versteht",
          "Zugriff zu ChatGPT, Bard und Bing auch wenn es nicht erlaubt ist (VPN)",
          "Was bedeutet Lernen & bist auch du ein \"Lerner\"",
          "Alle wichtigen Links findest du hier"
        ],
        "Prompt Engineering in LLMs": [
          "Worum geht es, warum funktioniert mein Prompt nicht & wichtige Tipps",
          "ChatGPT Interface",
          "Wichtiges Update!",
          "Verschiedener Output von LLms wie ChatCPT, Bard usw.",
          "Vom schlechten zum guten Prompt, sei spezifisch und gieb Kontext",
          "Der Struckturierte Prompt Analysiert",
          "Der Instruction Prompt",
          "Rollen Prompting",
          "Shot Prompting ( Zero, One...)",
          "Kombiniere Prompting Konzepte (RGC Prompting)"
        ],
        "Weitere fortgeschrittene Prompt Engineering Beispiele, Konzepte und Tipps": [
          "Chain of Thougth Prompting, Schritt für Schritt ans Ziel",
          "Tree of Thougth Prompting, verhandle dein Gehalt besser",
          "Frag nach Prompting Ideen in den Modellen",
          "Trick 17, Vergiss alle vorherigen Befehle",
          "Perspektiv Prompting"
        ],
        "Komplettes Priming, Tipps und Erklärungen": [
          "Revers Prompt Engineering, Priming, OK Befehl und das Tokenlimit",
          "Lass uns darüber nachdenken!",
          "Sequence Prompting, Tabellen Prompting und Klammern",
          "Klammern und Abkürzungen erklärt",
          "Output verbessern mit dem Kritiker-Prompt",
          "Was du bisher gelrnt hast, deine Vorlage und eine Lernerfahrung"
        ],
        "Trainiere ChatGPT als Prompt Engineer & lass andere die Arbeit machen": [
          "Verwandle ChatGPT in seine eigene Prompting Maschine!",
          "So bist du JEDEM Prompt Engineer ÜBERLEGEN und kannst Prompts besser verkaufen!",
          "AIPRM: Eine Chorome Extension die dir das Prompt Engineering abnimmt"
        ],
        "Updates und coole Tools": [
          "Custom instructions [Auch in Deutschland]",
          "Tracke das Token Limit mit dieser Chrome Extension",
          "ChatGPT kann jetzt SEHEN; sprechen & hören",
          "ChatGPT Vision im Test",
          "Wichtiges Update!!! Neues Interface & Möglichkeiten 08.11.2023",
          "GPTs: Vereinfache das Prompt Engineering durch das Training deiner eigenen Bots",
          "ChatGPT Plugins sind offline",
          "GPT-4o Update! (Juni 2024)",
          "System 2 Denken mit OpenAI o1 (Update September 2024)",
          "November 2024: ChatGPT Canvas",
          "ChatGPT search"
        ],
        "Prompt Engineering speziell für Google Gemini": [
          "Prompt Engineering für Google Gemini: Worum gehts?",
          "Das Interface von Google Gemini",
          "Vorteile und Unterscheide von Gemini zu ChatGPT",
          "Prompt Engineering in und für Google Gemini",
          "Prompt Engineering in Gemi ändert sich durch dieses Update, nimm ChatGPT Prompts",
          "Gemini Ultra ist da! Vergleich zu ChatGPT-4"
        ],
        "Prompt Engineering für Bing / Microsoft Copilot": [
          "Bing: Das Interface",
          "Prompt Engineering für Microsoft Copilot: Worauf muss ich achten?"
        ]
      },
      "requirements": [
        "Du brauchst kein Vorwissen"
      ],
      "description": "Bist du daran interessiert, deine Fähigkeiten im Bereich des Prompt Engineerings zu entwickeln?\nMöchtest du lernen, wie man perfekte Prompts für KI-Tools wie ChatGPT, Midjourney, Leonardo AI und Stable Diffusion erstellt?\nDann ist dieser Kurs genau das Richtige für dich!\nAls Prompt Engineer spielst du eine entscheidende Rolle bei der Optimierung der Leistungsfähigkeit dieser leistungsstarken KI-Tools. In diesem umfassenden Kurs werden wir gemeinsam daran arbeiten, deine Fähigkeiten im Schreiben von Prompts zu perfektionieren.\nDer Kurs behandelt alle Details zum Prompt Engineering in ChatGPT, Midjourney und Stable Diffusion.\nDu erhältst eine umfassende Einführung in diese Tools und erfährst, wie sie funktionieren und sich voneinander unterscheiden. Dabei lernst du die verschiedenen Aspekte des Prompt Engineerings kennen und wie du sie auf diese KI-Tools anwendest.\nWir werden die Kunst des effektiven Promptings erforschen und lernen, wie man Inputs für optimale Ergebnisse modifiziert.\nDu wirst lernen, wie man Prompts für spezifische Anwendungsbereiche erstellt, sei es für Content-Erstellung, Social Media, Werbetexte, SEO oder andere Zwecke.\nZusätzlich wirst du Einblicke in die Anwendung von Midjourney und Stable Diffusion gewinnen, um generative Kunstwerke zu erstellen.\nDu lernst die technischen Hintergründe von LLM und Diffusionsmodellen kennen, um das perfekte Prompt Engineering für Midjourney, Stable Diffusion (mit negativen Prompts) und ChatGPT zu beherrschen.\nEs ist wichtig zu wissen, dass der Prompt Engineer ein eigenes Berufsfeld ist, das von Unternehmen zunehmend geschätzt wird.\nTatsächlich sind Unternehmen oft bereit, hohe Summen für gut ausgebildete Prompt Engineers zu zahlen, da sie die Leistungsfähigkeit ihrer KI-Systeme verbessern wollen, wir werden uns ansehen, was du als Prompt Engineer in einer solchen Rolle wikrlich können musst, wenn du das Hauptberuflich machen möchtest.\nMit lebenslangem Zugriff auf den Lerninhalt und regelmäßigen Updates des Kurses hast du die Möglichkeit, deine Fähigkeiten kontinuierlich zu erweitern und von den neuesten Entwicklungen im Bereich des Prompt Engineerings zu profitieren.\nWenn du bereit bist, in dieses aufstrebende Berufsfeld einzutauchen und deine Fähigkeiten im Schreiben perfekter Prompts für ChatGPT, Midjourney und Stable Diffusion zu entwickeln, dann ist dieser Kurs genau das Richtige für dich.\nMelde dich noch heute an und werde ein Experte im Prompt Engineering!",
      "target_audience": [
        "An jeden der sein Prompt Engineering auf das nächste Level bringen will"
      ]
    },
    {
      "title": "Yapay Zeka ve Derin Öğrenme A-Z™: Tensorflow",
      "url": "https://www.udemy.com/course/yapayzeka/",
      "bio": "Google Tensorflow ile Python Dilinde Makine öğrenimi, Yapay Sinir Ağları ve Deep Learning Programları Geliştirin",
      "objectives": [
        "Tensorflow ile modeller geliştirebileceksiniz.",
        "Hayalinizdeki sistemi bir yapay zeka modeline dökebileceksiniz.",
        "Yapay sinir ağları geliştirebileceksiniz.",
        "Gradient descend, backpropagation, overfitting gibi bütün derin öğrenme kavramlarını öğreneceksiniz.",
        "Konvolüsyonel sinir ağları ile resimler üzerinde modeller geliştirebileceksiniz.",
        "Imagenet üzerinde eğitilen modelleri kendi probleminiz için kullanabileceksiniz.",
        "Yinelenen sinir ağları ile doğal dil işleme modelleri geliştirebileceksiniz.",
        "LSTM ile otomatik özgün yazı üreten modeller geliştirebileceksiniz.",
        "Tensorflowun playground'u olan Tensorboard kullanabileceksiniz.",
        "Keras ile modeller geliştirebileceksiniz."
      ],
      "course_content": {
        "Makine Öğrenimi": [
          "Makine Öğrenimi Nedir?"
        ],
        "Başlamadan Önce Kurulumlar": [
          "Kurulum (Anaconda, Pycharm)",
          "Kurulum (Tensorflow CPU ve GPU)",
          "Derin Öğrenmede CPU vs GPU",
          "Kurulumlar (Yazılı)"
        ],
        "Derin Öğrenme": [
          "Yapay Sinir Ağları",
          "Layers (Katmanlar)",
          "Aktivasyon Fonksiyonları",
          "Loss (Cost) Fonksiyonları",
          "Gradient Descent",
          "Optimizasyon Algoritmaları",
          "Backpropagation",
          "Overfitting ve Düzenlileştrime (Regularization)"
        ],
        "Tensorflow ile Yapay Sinir Ağları": [
          "Basit Linear Model (MNIST) Part 1",
          "Basit Linear Model (MNIST) Part 2",
          "Basit Linear Model (MNIST) Part 3",
          "Basit Linear Model (MNIST) Part 4",
          "Çok Layerlı Sinir Ağı",
          "Loss Grafiği",
          "Dropout",
          "Modelin Yaptığı Hatalar"
        ],
        "Konvolüsyonel Sinir Ağları (CNN)": [
          "Konvolüsyonel Sinir Ağları Nedir?",
          "CNN ile MNIST",
          "CIFAR-10",
          "Overfitting Problemi",
          "Data Augmentation",
          "Batch Normalization",
          "Modelleri Kaydetme",
          "CNN Mimarileri",
          "Inception ile Resimdeki Objeleri Tanıma",
          "Transfer Learning",
          "Görsel Analiz",
          "Deep Dream"
        ],
        "Yinelenen Sinir Ağları (RNN)": [
          "Yinelenen Sinir Ağları Nedir?",
          "RNN ile Spam Filtresi",
          "LSTM Nedir?",
          "LSTM ile Kelime Üretimi",
          "Çok Layerlı LSTM ile Harf Üretimi"
        ],
        "Tensorflow ile Model Geliştirmeyi Kolaylaştırma": [
          "Tensorboard",
          "Keras",
          "Kapanış"
        ],
        "Ek Ders: Python'a giriş ve Numpy": [
          "Jupyter Notebook Tutorial",
          "Veri Türleri 1",
          "Veri Türleri 2",
          "Koşullu İfadeler",
          "Döngüler",
          "Fonksiyonlar",
          "Numpy Array",
          "Numpy'da Indeksleme",
          "Numpy'da İşlemler",
          "Pandas Seriler",
          "Pandas DataFrame 1",
          "Pandas DataFrame 2",
          "Pandas DataFrame 3",
          "Pandas Kayıp Veriler",
          "Pandas Groupby",
          "Pandas Merging, Joining ve Concatenating",
          "Pandas İşlemler",
          "Pandas Veri Okuma ve Yazma",
          "Python Kodları"
        ]
      },
      "requirements": [
        "Temel programlama bilgisi",
        "Lise seviyesinde matematik bilgisi",
        "64-bit işletim sistemi"
      ],
      "description": "Merhaba arkadaşlar,\nBu kursta günümüzde çok heyecan verici gelişmelerin yaşandığı, yapay zeka alanında yapılan çalışmaların büyük bir kısmını oluşturan derin öğrenmeyi yani yapay sinir ağlarını anlatıyorum. Son yıllarda yapay zekanın patlamasının sebebi de zaten yapay sinir ağları alanında yapılan çalışmalardır. Kursta Google'ın kendi projelerinde kullandığı ve aktif olarak geliştirdiği Tensorflow kütüphanesini kullanarak farklı türlerde yapay sinir ağları geliştireceğiz. Öncelikle yapay sinir ağlarının mantığını, bu konu ile ilgili terimleri, kavramları sizlere açıklayacağım ve daha sonra sinir ağlarını kodlamaya geçeceğiz. Kodlamayı Python'da yapıyoruz. Eğer Python bilginiz yoksa da endişelenmenize gerek yok. Python çok basit bir dil olduğu için farklı bir dil bilseniz bile Python'a alışmanız çok kolay olacaktır. Programlama bilginiz yoksa öncesinde en azından temel programlama bilgisi edinmenizi tavsiye ederim.\nBaşarılar.\n\n\nKurs Kapsamı\nMakine Öğreniminin Temelleri\nYapay Sinir Ağları\nKatmanlar\nAktivasyon Fonksiyonları\nOptimizasyon Algoritmaları\nBackpropogation\nOverfitting\nKonvolüsyonel Sinir Ağları\nMNIST , CIFAR-10 ve ImageNET Datasetleri\nTransfer Learning\nDeep Dream\nRNN\nLSTM\nTensorboard\nKeras",
      "target_audience": [
        "Google'ın açık kaynak kodlu kütüphanesi TensorFlow öğrenmek isteyen herkes.",
        "Yapay zeka ile ilgilenen herkes.",
        "Yapay sinir ağları kullanarak modeller geliştirmek isteyen herkes.",
        "Convolutional neural network, Recurrent neural network öğrenmek isteyen herkes.",
        "Veri bilimi ile ilgilenen herkes.",
        "Otomatize edilmiş sistemler hakkında bilgi almak isteyen herkes."
      ]
    },
    {
      "title": "Do Zero a Engenheiro de Dados - Azure",
      "url": "https://www.udemy.com/course/zeroaengenheirodedados/",
      "bio": "Formação engenharia de dados Azure e Big Data - na prática! Totalmente voltada para a empregabilidade.",
      "objectives": [
        "Criar um ETL usando Datafactory",
        "Projetar armazenamentos na nuvens utilizando Data Lake",
        "Criar um Data Warehouse no Azure Synapse Studio",
        "Construa um fluxo de dados com o Data Flow, na prática.",
        "Carregar dados de diversas fontes diferentes",
        "Criar Processos de ETL - Extract Transform Load (Extrair, Transformar e Carregar)",
        "Carregar o dados do projeto para no Data Warehoure"
      ],
      "course_content": {
        "Introdução": [
          "Informações importantes"
        ],
        "O mercado de BI": [
          "As diferentes profissões na área de BI",
          "Entenda de uma vez BI x BIG DATA",
          "Ferramentas usadas pelos de Eng. de dados / BIG DATA"
        ],
        "Arquitetura de um DW moderno": [
          "Tudo o que você vai aprender nesta formação",
          "Arquitetura Moderna de um Data Warehouse",
          "Prática (Hands-On) Ferramentas de um DW moderno"
        ],
        "Armazenamento na nuvem": [
          "Armazenamento de dados no Azure",
          "Blob Storage e Data Lake",
          "Prática (Hands-On) / Ferramentas de Armazenamento"
        ],
        "Azure Data Factory": [
          "Aula pré-requisito para as seções 5 e 6",
          "Conhecendo o Azure Data Factory (ADF)",
          "Prática 1 (Hands-on): criando banco de dados Azure SQL",
          "Prática 2 (Hands-On) / Criando ADF",
          "Componentes do Azure Data Factory",
          "Prática 3 (Hands-On) / Pipeline, Linked Services, Dataset e Activite",
          "Aula 15: Script tblMovies (BDMovies)"
        ],
        "Data Flow (DF)": [
          "Data Flow - Construindo Fluxos de Dados",
          "Prática (Hands-On) / Construindo um DF completo - parte 1",
          "Prática (Hands-On) / Contruindo um DF completo - parte 2",
          "Aula 19: Arquivo moviesDB.csv"
        ],
        "Big Data": [
          "Bem vindo ao mundo BIG DATA",
          "Prática (Hand-On) / Criando um Azure Synapse Studio",
          "Mergulhando no Azure Synapse Studio"
        ],
        "Data Warehouse Cloud": [
          "Pool de SQL Dedicado (o DW da nuvem Azure)",
          "Prática (Hand-On) / Trabalhando com DW na nuvem (Pool de SQL)",
          "Aprofundando Pool de SQL dedicado"
        ],
        "Pool de SQL (Serverless)": [
          "Conhecendo o Pool SQL (sem serviço)",
          "Prática (Hands-On) / Consultas avançadas no Pool de SQL (serverless)"
        ],
        "Apache Spark": [
          "Apache Spark - O poder do Big Data",
          "Prática (Hands-On) / Trabalhando com Apache Spark"
        ]
      },
      "requirements": [
        "Conhecimentos básicos de SQL",
        "Conhecimentos básicos em Banco de Dados",
        "Noções de Modelagem Dimensional (seria favorável)",
        "Pré-requisito principal: MUITA VONTADE DE FAZER A DIFERENÇA NA SUA CARREIRA"
      ],
      "description": "Esta formação de Engenharia de Dados te ensinará as principais tecnologias da Azure Microsoft e permitirá que você se torne independente na ferramenta. Além disso, para quem já é profissional de TI, poderá dar um upgrade na sua carreira.\nTorne-se, portanto, um Engenheiro de Dados com esta formação completamente voltada para empregabilidade no mercado de trabalho da área de tecnologia.\n\n\nVocê irá aprender e trabalhar com as seguintes tecnologias Azure:\n- Data Lake\n- Data Warehouse\n- SQL para Big Data\n- Data Factory para ETL e orquestração de dados\n- Data Pipeline\n- Azure Synapse Analytics\n\n\nNo curso, o aluno aprenderá em duas etapas: a etapa teórica breve (importantíssima) e as etapas hands-on, isto é, aulas totalmente mão-na-massa (práticas) em que eu irei compartilhar a tela do computador e manusear as ferramentas.\n\n\nAtenção: este curso é para quem não pode perder tempo e precisa aprender rapidamente as ferramentas essenciais para se tornar engenheiro de dados capacitado e procurar por vagas que pagem cinco dígitos de salário.\n\n\nPara isso, é fundamental que o aluno veja e reveja as aulas e utilize as ferramentas que mostro na tela.\nEspero todo sucesso do mundo nessa sua nova empreitada. O sucesso depende totalmente de você!\nUm forte abraço do seu professor.",
      "target_audience": [
        "Profissionais que:",
        "Precisam aprender rápido e já começar a trabalhar com Engenharia de Dados;",
        "Precisam de um upgrade no currículo para conquistar um melhor salário;",
        "Desejam trabalhar com umas das áreas que mais cresce no mercado de TI no Brasil e no mundo;",
        "São gestores ou tomadores de decisão que desejam/precisam compreender como funciona o ETL Microsoft em uma corporação;",
        "Precisam aprender como funcionam um projeto ETL na prática (mundo real);"
      ]
    },
    {
      "title": "AIエンジニアが教えるPythonによるデータの前処理",
      "url": "https://www.udemy.com/course/python-preprocess/",
      "bio": "データ分析プロジェクトの最重要タスクであるデータの前処理の効率的なやり方を現役ＡＩエンジニアの立場からわかりやすく説明します．",
      "objectives": [
        "データ分析プロジェクトにおける前処理の重要性",
        "Pythonの基礎",
        "データサイエンスにおける重要パッケージ（numpy, pandas, plotnine）の使い方",
        "データの前処理の具体的な方法"
      ],
      "course_content": {},
      "requirements": [
        "プログラミング初心者でもOK！！",
        "インターネットが使用できるパソコン（OSはなんでもOK）"
      ],
      "description": "※当コースは，前作「AIエンジニアが教えるRとtidyverseによるデータの前処理講座」の内容をPythonでアレンジしたものになります．\n本コースは，データの前処理に特化しています．\n近年はDXやAIが話題になっており，実に様々な方々が興味を持っている分野だと思います．\nDXやAIによる成果に焦点が当たる場合が多いですが，その成果が出る前には必ずデータの前処理をする必要があります．\nデータの前処理は，データの読み込み，加工，結合，可視化など実に様々な工程を何回も繰り返すことで，徐々に完成に近づいていきます．\nそのことが原因で，データの前処理には多大な時間（データ分析プロジェクト全体の70％～80％程度）が費やされるのです．\nそんな多大な時間が費やされるデータの前処理ですが，後工程の成果物につながる重要な工程ですので，できるだけ速く正確に実施する必要があります．\nデータの前処理は，データサイエンスのメインプログラミング言語であるPythonかRで実施されることが多いです．\n当コースでは，Pythonに焦点を当てて，データの前処理を実施するうえで，必要不可欠なパッケージであるnumpy，pandas，plotnineについて詳細に説明します．\nまたデータの前処理だけでなく，環境構築やPythonの基礎についても丁寧に説明しますので，今までプログラミングをしたことがない初心者でも全く問題ないです．\n講師が基礎から丁寧に解説しますので，気楽に一歩一歩着実に学習し，前処理マスターを目指しましょう！！\n\n\n★本コースの目的★\nデータの前処理のほぼすべて（80%程度）に対応すること\n\n\n★本コースの特徴★\nとにかく現場主義！！\nコーディングはリアルタイム形式！！\nコードだけでなく，イメージも！！\n\n\n\n★本コースの内容★\nコース紹介\n概要\n当コース受講における注意\n全体像\n環境構築\nGoogle Colaboratoryを利用するための準備\nGoogle Colaboratoryの基本的な使い方\n当コースの受講方法\nPython\nデータ型\nリスト\n辞書\n条件分岐処理\n繰り返し処理\n関数\nクラス\nパッケージ\nnumpy\nベクトルの四則演算\nベクトルのブロードキャスト\nベクトルの要素抽出\nベクトルの便利関数\n規則的なベクトルの作成\n論理値ベクトルの作成\n論理値ベクトルの計算\npandas\nデータの入出力\nメソッドチェーン\nデータフレーム処理\n文字列処理\n繰り返し処理\n欠損値処理\nplotnine\nヒストグラム\n棒グラフ\n散布図\n総合演習",
      "target_audience": [
        "データサイエンスやAIに興味がある方",
        "Pythonを勉強したい方",
        "numpyやpandasの使い方を学習したい方",
        "データの前処理を効率的にしたい方"
      ]
    },
    {
      "title": "Statistics & Data Analysis Capstone Project for Healthcare",
      "url": "https://www.udemy.com/course/statistics-analysis-capstone-project-on-medical-domain/",
      "bio": "Struggling to apply Statistics to real-world projects? Want to master Data Analysis for a booming career in Healthcare",
      "objectives": [],
      "course_content": {
        "Capstone Project : Data & Statistical Analysis on Medical Data with Python": [
          "Basics of Data Analysis - Histogram",
          "Derive Insights from Box plot & Outliers",
          "Univariate & Bivariate Analysis",
          "Multivariate Analysis & Pairplot",
          "Covariance & Hypothesis Testing and Gaussian Distribution"
        ]
      },
      "requirements": [
        "No prior experience needed! We start from scratch and build your skills step-by-step.",
        "Basic understanding of Microsoft Excel (helpful, but not mandatory)",
        "A willingness to learn, practice, and explore real-world healthcare data examples",
        "Curiosity about how statistics power decision-making in healthcare, business, and research"
      ],
      "description": "Do you want to work as a Marketing Analyst, a Business Intelligence Analyst, a Data Analyst, or a Data Scientist?\nAnd you want to acquire the quantitative skills needed for the job?\nWell then, you’ve come to the right place!\nStatistics for Data Science and Business Analysis is here for you! (with TEMPLATES in Excel included)\nThis is where you start. And it is the perfect beginning!\nIn no time, you will acquire the fundamental skills that will enable you to understand complicated statistical analysis directly applicable to real-life situations. We have created a course that is:\nEasy to understand\nComprehensive\nPractical\nTo the point\nPacked with plenty of exercises and resources\nData-driven\nIntroduces you to the statistical scientific lingo\nTeaches you about data visualization\nShows you the main pillars of quant research\nIt is no secret that a lot of these topics have been explained online. Thousands of times. However, it is next to impossible to find a structured program that gives you an understanding of why certain statistical tests are being used so often. Modern software packages and programming languages are automating most of these activities, but this course gives you something more valuable – critical thinking abilities. Computers and programming languages are like ships at sea. They are fine vessels that will carry you to the desired destination, but it is up to you, the aspiring data scientist or BI analyst, to navigate and point them in the right direction.\nTeaching is our passion\nWe worked full-time for several months to create the best possible Statistics course, which would deliver the most value to you. We want you to succeed, which is why the course aims to be as engaging as possible. High-quality animations, superb course materials, quiz questions, handouts and course notes, as well as a glossary with all new terms you will learn, are just some of the perks you will get by subscribing.\nWhat makes this course different from the rest of the Statistics courses out there?\nHigh-quality production – HD video and animations (This isn’t a collection of boring lectures!)\nKnowledgeable instructor (An adept mathematician and statistician who has competed at an international level)\nComplete training – we will cover all major statistical topics and skills you need to become a marketing analyst, a business intelligence analyst, a data analyst, or a data scientist\nExtensive Case Studies that will help you reinforce everything you’ve learned\nExcellent support - if you don’t understand a concept or you simply want to drop us a line, you’ll receive an answer within 1 business day\nDynamic - we don’t want to waste your time! The instructor sets a very good pace throughout the whole course\nWhy do you need these skills?\nSalary/Income – careers in the field of data science are some of the most popular in the corporate world today. And, given that most businesses are starting to realize the advantages of working with the data at their disposal, this trend will only continue to grow\nPromotions – If you understand Statistics well, you will be able to back up your business ideas with quantitative evidence, which is an easy path to career growth\nSecure Future – as we said, the demand for people who understand numbers and data, and can interpret it, is growing exponentially; you’ve probably heard of the number of jobs that will be automated soon, right? Well, data science careers are the ones doing the automating, not getting automated\nGrowth - this isn’t a boring job. Every day, you will face different challenges that will test your existing skills and require you to learn something new\nPlease bear in mind that the course comes with Udemy’s 30-day unconditional money-back guarantee. And why not give such a guarantee? We are certain this course will provide a ton of value for you.\nClick 'Buy now' and let's start learning together today!",
      "target_audience": [
        "Beginners who want to master statistics and data analysis from the ground up",
        "Aspiring Data Analysts, Business Intelligence Analysts, and Healthcare Analysts",
        "Students and professionals entering the healthcare, pharma, or life sciences industries",
        "Anyone frustrated with overly technical statistics courses and looking for clear, simple explanations",
        "Medical researchers, clinical analysts, or public health professionals needing stronger data skills"
      ]
    },
    {
      "title": "Natural Language Processing:Concept along with Case Study",
      "url": "https://www.udemy.com/course/natural-language-processing-python-nlp/",
      "bio": "Free Course: Natural Language Processing (NLP), Text Processing, Machine Learning, Spam Filter [Python]",
      "objectives": [],
      "course_content": {
        "Introduction to Natural Language Processing": [
          "What is Natural Language Processing (NLP)",
          "Tokenization",
          "Stop Words Removal",
          "N-Grams",
          "Stemming",
          "Word Sense Disambiguation",
          "Count Vectorizer",
          "TF-IDF Vectorizer",
          "Hashing Vectorizer"
        ],
        "Text Preprocessing - Python Code": [
          "Tokenization - Python",
          "Stop Word Removal - Python",
          "N-Grams - Python",
          "Stemming - Python",
          "Word Sense Disambiguation - Python",
          "Count Vectorizer - Python",
          "TF-IDF Vectorizer - Python",
          "Hashing Vectorizer - Python"
        ],
        "Case Study: Spam Filter": [
          "Spam Filter using CountVectorizer",
          "Spam Filter using Hashing"
        ]
      },
      "requirements": [
        "Basic Understanding of Python",
        "One Laptop with Python IDE installed",
        "Understanding of Machine learning will be helpful in Case Study however not mandatory"
      ],
      "description": "This course provides a basic understanding of NLP. Anyone can opt for this course. No prior understanding of NLP is required.  Text Processing like Tokenization, Stop Words Removal, Stemming, different types of Vectorizers, WSD, etc are explained in detail with python code. Also difference between CountVectorizer and Hashing in Spam Filter.",
      "target_audience": [
        "People willing to learn NLP and looking forward to build career in Machine Learning."
      ]
    },
    {
      "title": "【初心者向け】大規模言語モデルにおけるRAGを実装できるようになろう！Webページの情報を元に回答できるAIを作ろう！",
      "url": "https://www.udemy.com/course/rag-deploy/",
      "bio": "大規模言語モデルを活用する上で非常に重要なアプローチであるRAGについて学び実装していきます！特定のWebページの情報を元に回答してくれるAIを作っていきますよ！",
      "objectives": [
        "RAGの仕組みを理解します",
        "大規模言語モデル・GPTモデルの仕組みを理解します",
        "基本的なRAGを実装します",
        "特定のWebページの情報を元に必要な回答を引き出すRAGを実装します",
        "Pythonの基礎を学びます"
      ],
      "course_content": {
        "はじめに": [
          "イントロダクション"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Seabornについて学ぼう！",
          "Python構文の復習"
        ],
        "RAGの構造について理解しよう！": [
          "RAGとは？",
          "次のレクチャーからの注意点",
          "大規模言語モデル（LLM）について・LLMの種類",
          "OpenAIの開発するGPTモデルについて",
          "RAGに関して"
        ],
        "RAGを実装してみよう！": [
          "OpenAIのAPIキーを取得しよう！",
          "【注意】httpxのバージョンに起因するエラーについて",
          "OpenAIのAPIを使ってテキストをベクトル化してみよう！",
          "処理を関数化して質問文とデータベースの情報をベクトル化してみよう！",
          "ベクトル同士の類似度を求めて最も類似度の高い情報を抽出しよう！",
          "【注意】次のレクチャーで使っているモデルで文字化けが発生する場合",
          "抽出した情報を質問をGPTモデルに投げかけて返答を得よう！"
        ],
        "特定のWebページの情報をベースにRAGを行なう処理を実装してみよう！": [
          "Webページからテキスト情報を抽出してみよう！",
          "RAGに適したチャンク分割の考え方を学ぼう！",
          "テキストを特定のチャンクに分けてデータを保持しよう！",
          "分割したチャンクを確認していこう！",
          "生成したチャンクに対してRAGの処理を実行していこう！",
          "類似度の高い2つのチャンクテキストを抽出する処理に修正しよう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "プログラミングの知識は不要です。PCさえあれば問題ないです。Mac/Windowsは問いません。"
      ],
      "description": "このコースでは、大規模言語モデル（LLM）を使ったRAGという処理について解説していきます！\n\n\n独自で保有している情報を参照して大規模言語モデルに回答して欲しいケースにRAGは利用されます。\n例えば社内に貯まっているリソースを元にしたQAチャットボットを作りたい場合など！\n\n\nこのコースでは、まずRAGの概要と大規模言語モデルの概要を理解しPythonでRAGを実装していきます。\nそして、最終的に特定のWebページの情報をベースに大規模言語モデルがQAに答えてくれるような処理をRAGを用いて実装していきます。\n\n\n実務でよく使われるRAGというアプローチをしっかり理解して実装できるようになっておきましょう！",
      "target_audience": [
        "RAGを理解して実装してみたい人",
        "社内のチャットボットを作るための仕組みについて理解したい人",
        "大規模言語モデルを使って何か実装してみたい人"
      ]
    },
    {
      "title": "Data Science - Język R dla początkujących",
      "url": "https://www.udemy.com/course/data-science-jezyk-r-dla-poczatkujacych/",
      "bio": "w sam raz na początek kariery w data science",
      "objectives": [
        "Co to jest język R i kiedy go używać",
        "Jak pracować z danymi",
        "Kiedy skorzystać z wektora, macierzy, listy i ramki danych",
        "Jak filtrować, sortować dane",
        "Jak agregować dane",
        "Jak zaimportować i wyeksportować dane",
        "Jak korzystać z funkcji",
        "Jak łączyć dane z wielu źródeł",
        "Jak rysować wykresy"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "VIDEO - Język R - po co go w ogóle ktoś wymyślił?",
          "LAB - Język R - po co go w ogóle ktoś wymyślił",
          "Uwagi praktyczne - materiały do samodzielnych ćwiczeń"
        ],
        "Instalacja i pierwsze kroki": [
          "VIDEO - Instalacja R",
          "LAB - Instalacja R",
          "VIDEO - R Studio",
          "LAB - R Studio",
          "ODP - R Studio",
          "VIDEO - Wprowadzenie do pracy ze zbiorami danych - opcjonalne",
          "LAB - Wprowadzenie do pracy ze zbiorami danych - opcjonalne",
          "ODP - Wprowadzenie do pracy ze zbiorami - opcjonalne",
          "VIDEO - Demo - kolorowy świat języka R - opcjonalne",
          "LAB - Demo - kolorowy język R - opcjonalne"
        ],
        "Obliczenia w R": [
          "VIDEO - Działania arytmetyczne i kilka zaskakujących faktów",
          "LAB - Działania arytmetyczne i kilka zaskakujących faktów",
          "ODP - Działania arytmetyczne i kilka zaskakujących faktów",
          "VIDEO - Działania logiczne, kto mówi prawdę a kto kłamie?",
          "LAB - Działania logiczne, kto mówi prawdę a kto kłamie?",
          "ODP - Działania logiczne, kto mówi prawdę a kto kłamie?",
          "VIDEO - Operacje na wektorach - niech się wszystko policzy samo!",
          "Uwaga techniczna",
          "LAB - Operacje na wektorach - niech się wszystko policzy samo!",
          "ODP - Operacje na wektorach - niech się wszystko policzy samo!",
          "VIDEO - Język R - być albo nie być - > czy = (opcjonalne)",
          "LAB - Język R - być albo nie być - > czy = (opcjonalne)",
          "Drobna prośba od autora"
        ],
        "Typy danych i funkcje z nimi powiązane": [
          "VIDEO - Typy danych - co robić a czego unikać, żeby się w kodzie nie potykać",
          "LAB - Typy danych - co robić a czego unikać, żeby się w kodzie nie potykać",
          "ODP - Typy danych - co robić a czego unikać, żeby się w kodzie nie potykać",
          "VIDEO - Funkcje operujące na tekstach, czyli coś dla R-poetów",
          "LAB - Funkcje operujące na tekstach, czyli coś dla R-poetów",
          "ODP - Funkcje operujące na tekstach, czyli coś dla R-poetów",
          "QUIZ - Typy i funkcje tekstowe"
        ],
        "Dane": [
          "VIDEO - Wektor - sposób na dane",
          "LAB - Wektor - sposób na dane",
          "ODP - Wektor - sposób na dane",
          "VIDEO - Funkcje pracujące na wektorach - żeby życie było prostsze!",
          "LAB - Funkcje pracujące na wektorach - żeby życie było prostsze!",
          "ODP - Funkcje pracujące na wektorach - żeby życie było prostsze!",
          "VIDEO - Praca z pakietami: stringr",
          "LAB - Praca z pakietami: stringr",
          "ODP - Praca z pakietami: stringr",
          "VIDEO - Indeksowanie wektorów - weź co chcesz!",
          "LAB - Indeksowanie wektorów - weź co chcesz!",
          "ODP - Indeksowanie wektorów - weź co chcesz!",
          "VIDEO - Nazywanie wektorów - bo nazwy łatwiej zapamiętać",
          "LAB - Nazywanie wektorów - bo nazwy łatwiej zapamiętać",
          "ODP - Nazywanie wektorów - bo nazwy łatwiej zapamiętać",
          "VIDEO - Predefiniowane wartości stałe - może nieważne, ale przydatne!",
          "LAB - Predefiniowane wartości stałe - może nieważne, ale przydatne!",
          "ODP - Predefiniowane wartości stałe - może nieważne, ale przydatne!",
          "VIDEO - Macierz, czyli wektor z wierszami i kolumnami",
          "LAB - Macierz, czyli wektor z wierszami i kolumnami",
          "ODP - Macierz, czyli wektor z wierszami i kolumnami",
          "VIDEO - Array, oby nie bolała Cię głowa, że przestrzeń jest wielowymiarowa",
          "LAB - Array, oby nie bolała Cię głowa, że przestrzeń jest wielowymiarowa",
          "ODP - Array, oby nie bolała Cię głowa, że przestrzeń jest wielowymiarowa",
          "VIDEO - Lista pojemna jak torebka",
          "LAB - Lista pojemna jak torebka",
          "ODP - Lista pojemna jak torebka"
        ],
        "Data Frame i operacje wykonywane na data frame": [
          "VIDEO - Data Frame - sposób na dane tabelaryczne",
          "LAB - Data Frame - sposób na dane tabelaryczne",
          "ODP - Data Frame - sposób na dane tabelaryczne",
          "VIDEO - Odczyt i zapis Data Frame do i z pliku",
          "LAB - Odczyt i zapis Data Frame do i z pliku",
          "ODP - Odczyt i zapis Data Frame do i z pliku",
          "VIDEO - Operacje na kolumnach w Data Frame",
          "LAB - Operacje na kolumnach w Data Frame",
          "ODP - Operacje na kolumnach w Data Frame",
          "VIDEO - Filtrowanie danych w Data Frame",
          "LAB- Filtrowanie danych w Data Frame",
          "ODP- Filtrowanie danych w Data Frame",
          "VIDEO - Grupowanie na piechotę i automatem",
          "LAB- Grupowanie na piechotę i automatem",
          "ODP - Grupowanie na piechotę i automatem",
          "VIDEO - Łączenie danych z wielu data frame - merge",
          "LAB - Łączenie danych z wielu data frame - merge",
          "ODP- Łączenie danych z wielu data frame - merge",
          "VIDEO - Sklejanie data frame",
          "LAB- Sklejanie data frame",
          "ODP- Sklejanie data frame"
        ],
        "Dodatek - zaawansowane funkcje języka R": [
          "Uwaga dot. kolejnej lekcji",
          "VIDEO - R w nieco bardziej zaawansowanej statystyce",
          "LAB- R w nieco bardziej zaawansowanej statystyce",
          "ODP- R w nieco bardziej zaawansowanej statystyce"
        ],
        "Uczymy się R na praktycznym przykładzie...": [
          "VIDEO - wydajność operacji a pamięć i procesor",
          "LAB - wydajność operacji a pamięć i procesor",
          "ODP - wydajność operacji a pamięć i procesor",
          "VIDEO - Kiedy latają Amerykanie? - subset, table i plot",
          "LAB - Kiedy latają Amerykanie? - subset, table i plot",
          "ODP - Kiedy latają Amerykanie? - subset, table i plot",
          "VIDEO - Dostosowywanie zbioru danych, ręczne grupowania",
          "LAB - Dostosowywanie zbioru danych, ręczne grupowania",
          "ODP- Dostosowywanie zbioru danych, ręczne grupowania",
          "VIDEO - Jak kilka prostych funkcji ułatwia życie: seq, cut, table, plot",
          "LAB - Jak kilka prostych funkcji ułatwia życie: seq, cut, table, plot",
          "ODP - Jak kilka prostych funkcji ułatwia życie: seq, cut, table, plot",
          "VIDEO - Wartości naj... większe lub mniejsze, czyli TOP TEN",
          "LAB- Wartości naj... większe lub mniejsze, czyli TOP TEN",
          "ODP- Wartości naj... większe lub mniejsze, czyli TOP TEN",
          "VIDEO - Agregowanie i sortowanie - aggregate i order",
          "LAB - Agregowanie i sortowanie - aggregate i order",
          "ODP - Agregowanie i sortowanie - aggregate i order",
          "VIDEO - Potok - sprytny sposób na długie polecenia",
          "LAB - Potok - sprytny sposób na długie polecenia",
          "ODP - Potok - sprytny sposób na długie polecenia",
          "VIDEO - Agregacja inaczej - tapply",
          "LAB - Agregacja inaczej - tapply",
          "ODP - Agregacja inaczej - tapply",
          "VIDEO - With i within - kiedy robisz \"szybką symulację\"",
          "LAB - With i within - kiedy robisz \"szybką symulację\"",
          "ODP - With i within - kiedy robisz \"szybką symulację\"",
          "VIDEO - Data i czas",
          "LAB - Data i czas",
          "ODP - Data i czas",
          "VIDEO - Funkcje - podsumowanie",
          "LAB - Funkcje - podsumowanie",
          "ODP - Funkcje podsumowanie"
        ],
        "Dodatek - funkcje": [
          "Uwaga dot. kolejnej lekcji",
          "VIDEO - Własne funkcje - gdy brakuje tych gotowych",
          "LAB - Własne funkcje - gdy brakuje tych gotowych",
          "ODP - Własne funkcje - gdy brakuje tych gotowych"
        ],
        "Wykresy": [
          "VIDEO - Wykresy: barplot (wykres słupkowy)",
          "LAB- Wykresy: barplot (wykres słupkowy)",
          "ODP- Wykresy: barplot (wykres słupkowy)",
          "VIDEO - Wykresy: heatmap (mapa ciepła)",
          "LAB - Wykresy: heatmap (mapa ciepła)",
          "ODP - Wykresy: heatmap (mapa ciepła)",
          "VIDEO - Wykresy: boxplot (wykres pudełkowy)",
          "LAB - Wykresy: boxplot (wykres pudełkowy)",
          "ODP - Wykresy: boxplot (wykres pudełkowy)",
          "VIDEO - Wykresy: histogram",
          "LAB - Wykresy: histogram",
          "ODP - Wykresy: histogram",
          "VIDEO - Wykresy: pie (wykres kołowy)",
          "LAB - Wykresy: pie (wykres kołowy)",
          "ODP - Wykresy: pie (wykres kołowy)",
          "VIDEO - Wykresy: scatter plot (wykres punktowy)",
          "LAB - Wykresy: scatter plot (wykres punktowy)",
          "ODP - Wykresy: scatter plot (wykres punktowy)"
        ]
      },
      "requirements": [
        "Znajomość podstawowych pojęć: wiersz, rekord, kolumna, filtr...",
        "Zainteresowanie danymi i ich eksploracją",
        "Doświadczenie np. z Excelem",
        "Komputer z Windows, Mac lub LInux (kurs bazuje na Windows)",
        "Kilka GB wolnego miejsca na dysku i kilka GB wolnego RAM",
        "Dostęp do Internetu"
      ],
      "description": "Data Science: Język R dla początkujących\nDane tu, dane tam. Gdzie nie zajrzysz – tam dane. Te dane to jak ruda złota. Same w sobie nie są niczym więcej, jak tylko plikami zajmującymi miejsce na dysku. Ale kiedy się je we właściwy sposób przetworzy to przekształcą się w unikalną wiedzę, know-how, dzięki któremu Twoja firma może być o kilka lat świetlnych przed konkurencją, a Ty możesz pokazać swoją nową super-moc.\nCo więc zrobić żeby się stać alchemikiem danych? Trzeba znać odpowiednie narzędzia. W profesjonalnych zastosowaniach najpopularniejsze są R i Python. O ile Python jest językiem uniwersalnym „do wszystkiego”, o tyle R jest językiem dedykowanym do pracy z danymi. Zostało to zauważone przez dostawców produktów komercyjnych. R jest wspierany np. przez SQL Server, dostępny w ofertach chmurowych. Jest wykorzystywany w Facebooku, Google, LinkedIn, Shellu, Fordzie, Mozilli, na uniwersytetach i wielu innych miejscach. Jest wiodącym językiem w bioinformatyce.\nZe względu na prostotę może być używany przez nie-programistów. Posiada też mnóstwo modułów pozwalających na implementowanie np. algorytmów uczenia maszynowego lub budowanie zaawansowanych projektów statystyki opisowej.\nW tym kursie staram się przedstawić podstawową funkcjonalność języka R, w miarę możliwości unikając odwołań do licznych zewnętrznych modułów. W końcu dobre opanowanie podstaw to fundament sukcesu!\nKurs jest dla początkujących. Wystarczy podstawowe rozumienie danych, pojęć takich jak wiersz, kolumna, cecha, rekord. Doświadczenie w Excelu na pewno się przyda. Wiedza ze statystyki będzie pomocna, ale niekonieczna. Ponieważ po każdej lekcji masz ćwiczenia – przyda się komputer.\nPoczątkowe lekcje wprowadzają do R, pokazują jak go zainstalować, uruchomić, rozpocząć pracę.\nNastępnie omawiamy charakterystyczne typy jak wektor, macierz, lista i data frame wraz z najważniejszymi funkcjami, dzięki którym można pracować z danymi.\nPo zdobyciu podstawowej wiedzy ruszamy analizować dane dotyczące lotów w USA. Pod pretekstem odpowiadania na konkretne pytania masz okazję poznać kolejne i kolejne funkcje.\nKurs kończymy lekcjami o wizualizacji danych.\nCo najfajniejsze – do każdej lekcji masz zadania do samodzielnego rozwiązania. Nikt się chyba jeszcze nie nauczył programowania samym tylko oglądaniem filmików dlatego na tym kursie pomyślałem o praktyce. Każde z tych zadań ma też proponowane rozwiązanie, więc nawet w przypadku problemów będzie można ruszać dalej.\nJuż niedługo Ty sam możesz samodzielnie stosować R do przekształcania danych w cenne obserwacje, jednak pierwszy krok należy do Ciebie.\nZapraszam na kurs „Język R dla początkujących”!\nRafał",
      "target_audience": [
        "Analitycy danych",
        "Studenci i pracownicy naukowi",
        "Osoby znające inne środowiska i języki pracujące z danymi",
        "Programiści i administratorzy baz danych chcący poznać środowisko R"
      ]
    },
    {
      "title": "Generative AI for Beginners: Master Powerful Prompts",
      "url": "https://www.udemy.com/course/generative-ai-for-beginners-master-powerful-prompts/",
      "bio": "Learn to Master Prompts, Create Unique Content, and Unlock the Full Potential of Artificial Intelligence",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "No programming or copywriting skills needed"
      ],
      "description": "Unlock the Future of Content Creation! Dive into this cutting-edge course on Generative AI and revolutionize your content strategy.\nFrom crafting powerful prompts to exploring diverse content types, you’ll master the tools to enhance productivity and unleash creativity.\nLearn how to leverage AI for creative writing, generate compelling visuals, and refine your output with a human touch. Get ahead of the curve with insights into future trends and ethical considerations in AI.\nTransform your approach with our expert guidance and take your content creation to unprecedented heights. Don’t miss out—enroll now and be the pioneer in AI-powered content innovation!\n\n\n1 Introduction to Generative AI: Learn about generative AI, its workings, and why mastering it is essential for modern content creation and innovation.\n2 Crafting Powerful Prompts: Discover how to create effective prompts for AI, optimize prompt quality, and refine them to enhance content output.\n3 Exploring Content Types with AI: Explore how AI can generate diverse content types, including blog posts, social media updates, and email campaigns.\n4 Leveraging AI for Creative Writing: Learn how AI can assist with creative writing, from developing fiction and characters to experimenting with different writing styles.\n5 Enhancing Productivity with AI: Use AI to boost productivity by generating ideas, expanding content, and speeding up the content creation process.\n6 Editing and Refining AI-Generated Content: Master AI tools for proofreading, adding a human touch, and avoiding common pitfalls in AI-generated writing.\n7 Generating Visual Content with AI: Discover how AI tools can create images from text, combine visuals with text, and customize visual content effectively.\n8 Future Trends in Generative AI: Explore future trends in generative AI, including its impact on content creation, ethical considerations, and ways to expand your skillset.",
      "target_audience": [
        "Digital Marketers",
        "Copywriters",
        "Affiliate Marketers",
        "Bloggers"
      ]
    },
    {
      "title": "CatBoost vs XGBoost - Quick Intro and Modeling Basics",
      "url": "https://www.udemy.com/course/catboost-vs-xgboost-a-gentle-introduction/",
      "bio": "Learn how to use CatBoost for Classification and Regression with Python and how it compares to XGBoost",
      "objectives": [],
      "course_content": {
        "CatBoost vs XGBoost - A CatBoost Introduction": [
          "Introduction",
          "CatBoost vs XGBoost Battle 1",
          "CatBoost vs XGBoost Battle 2",
          "CatBoost vs XGBoost Battle 3",
          "Let's look at CatBoostClassifier and CatBoostRegressor",
          "Conclusion"
        ]
      },
      "requirements": [
        "Some Python and Modeling experience/interest"
      ],
      "description": "XGBoost is one of the most powerful boosted models in existence until now... here comes CatBoost. Let's explore how it compares to XGBoost using Python and also explore CatBoost on both a classification dataset and a regression one. Let's have some fun!\nPart 1\nWe're going to start by unleashing XGBoost and CatBoostost on an independent data set version of the Titanic - the ship's manifest of those that did and didn't survive the tragic sinking of the ship in the North Atlantic Ocean. It happened in 1912 after hitting an iceberg on its maiden voyage to New York. You probably have already used it as it is extremely predictive, basically, women, children and the rich survived while men and the poor mostly didn't.\nPart 2\nIn the second part, we'll model a linear regression and classification on the titanic for classification and the Boston housing data.I'll also introduce you to a cool tool - Pandas Profiler for quick EDAs.\n\n\nPlease go out and use this model on a Kaggle competition, get an account if you haven't already and experiment - sometimes follow the rules, sometimes, don't. Remember that data science is very new so we're still inventing things as we go, just like these new models allow us to explore a little further and further each time!",
      "target_audience": [
        "Beginning data scientists"
      ]
    },
    {
      "title": "Curso avanzado de Series Temporales con R y Python",
      "url": "https://www.udemy.com/course/series-temporales/",
      "bio": "Aprende a analizar series de tiempo con casos prácticos como el coronavirus, el bitcoin o datos del mercado financiero",
      "objectives": [
        "Introducción al mundo de las series temporales y al análisis del tiempo",
        "Implementación de los análisis en R y Python",
        "Estudio de datos del coronavirus",
        "Estudio del Bitcoin",
        "Estudio de Precios del mercado financiero",
        "¿Qué modelo usar en la práctica?",
        "Modelos autorregresivos",
        "Modelos de medias móviles",
        "Modelos ARMA y ARIMA",
        "Modelos estacionales y con variables exógenas SARIMAX",
        "Modelos automáticos Auto ARIMA",
        "Estudio de la volatilidad a través de ARCH y GARCH",
        "Librerías más usadas: Yahoo Finance, Facebook prophet, Auto Arima, etc"
      ],
      "course_content": {},
      "requirements": [
        "Es recomendable haber cursado anteriormente el curso de probabilidad y el de estadística inferencial",
        "Es recomendable haber cursado anteriormente el curso de estadística multivariante",
        "Se necesitan conocimientos básicos de programación en R y en Python",
        "Disponer de un ordenador con conexión a internet para utilizar R y Python"
      ],
      "description": "Ya sea que queremos predecir la tendencia en los mercados financieros o el consumo de electricidad, el tiempo es un factor importante que  debe considerarse en nuestros modelos. Por ejemplo, sería interesante pronosticar a qué hora del día habrá un consumo máximo de electricidad, como ajustar el precio o la producción de electricidad, o como consumidor, cuándo poner los electrodomésticos que más consumen para ahorrarnos dinero.\nUna serie temporal o serie de tiempo, es una sucesión de datos medidos en determinados momentos y ordenados cronológicamente. Los datos pueden estar espaciados a intervalos iguales (como la temperatura en un observatorio meteorológico en días sucesivos al mediodía) o desiguales (como el peso de una persona en sucesivas mediciones en el consultorio médico, la farmacia, etc.).\nEn particular, en el análisis de series temporales, suelen surgir de forma natural preguntas muy concretas como por ejemplo\n¿Es estacionario?\n¿Hay una estacionalidad?\n¿La variable objetivo está autocorrelacionada?\nPara el análisis de las series temporales o series de tiempo, se usan métodos que ayudan a interpretarlas y que permiten extraer información representativa sobre las relaciones subyacentes entre los datos de la serie o de diversas series y que permiten en diferente medida y con distinta confianza extrapolar o interpolar los datos y así predecir el comportamiento de la serie en momentos no observados, sean en el futuro (extrapolación pronóstica), en el pasado (extrapolación retrógrada) o en momentos intermedios (interpolación). Todo lo que necesitas para poder llevar a cabo este tipo de análisis lo tienes explicado en este curso con dos lenguajes de programación, R y Python.\nEn nuestro curso cubriremos desde el concepto de serie de tiempo, su modelización y creación tanto en R como en Python, y más de 10 técnicas diferentes sobre como analizarlas correctamente, entender las correlaciones entre las diferentes variables de nuestros datos y el tiempo y a hacer pronósticos a futuro sobre cual será el próximo precio de una acción, cuando terminará el confinamiento debido al COVID19  o cuando terminará la ola de calor en una determinada región.\nAdemás, tendrás todo el código fuente desde el minuto cero, plantillas de código para utilizar en tus propios análisis, acceso a una comunidad exclusiva de estudiantes, que como tu, buscan aprender acerca del análisis de series temporales, y más de 14 horas de video de alta calidad con todas las explicaciones necesarias para convertirte en el próximo Lobo de Wall Street.\nNos vemos en clase y esperamos que disfrutes de nuestro curso avanzado de series temporales con R y Python.",
      "target_audience": [
        "Estudiantes de ingenierías, medicina o economía que busquen entender las correlaciones basadas en el tiempo y los modelos de series temporales",
        "Estudiantes de estadística que quieran profundizar en el análisis de tiempo",
        "Ingenieros de IA y ML que quieran conocer acerca del análisis de series temporales",
        "Estudiantes de doctorado que quieran conocer acerca del análisis de series temporales",
        "Empresas o usuarios que quieran hacer análisis de finanzas, evolución de datos médicos, y en general de cualquier información que dependa del tiempo"
      ]
    },
    {
      "title": "【 TensorFlow・Python3 で学ぶ】深層強化学習入門",
      "url": "https://www.udemy.com/course/tensorflow_reinforce/",
      "bio": "Qラーニングや方策勾配など強化学習の基礎理論を学び、Pythonでプログラムを書いてエージェントを作成し、理解を深めましょう。",
      "objectives": [
        "強化学習の基本的な原理（Q学習や方策勾配）を理解できるようになります。",
        "Q学習の基本原理を理解することができます",
        "DQN（深層Q学習）の仕組みを理解することができるようになります。",
        "OpenAI Gymのライブラリを使用してゲームをプレイする学習をさせることができます。",
        "アルファ碁を解説している論文を解読するための基礎知識が習得できます。"
      ],
      "course_content": {
        "イントロと環境構築": [
          "このコースの概要",
          "強化学習の枠組み"
        ],
        "環境構築（Windows）": [
          "Anaconda3 5.0.0 のインストール",
          "仮想環境の追加とTensorFlowのインストール",
          "TensorFlow 1.3 GPU版のインストール（NVIDIA GPU搭載機のみ可能）"
        ],
        "環境構築（macOS）": [
          "Anaconda3のインストール",
          "TensorFlowのインストール（macOS）"
        ],
        "Qテーブルによる学習": [
          "FrozenLake問題",
          "FrozenLake問題に取り組む上での注意",
          "OpenAI GymとJupyter Notebookをインストールしよう",
          "Qテーブルを更新するプログラムを書こう",
          "課題：　Ｑテーブル"
        ],
        "Qネットワーク学習": [
          "ＱテーブルからQネットワークへ",
          "Qネットワーク学習（1/3）ノートブックの追加",
          "Qネットワーク学習（2/3）学習の流れ",
          "Qネットワーク学習（3/3）学習の実行",
          "課題：　Qネットワーク学習",
          "コードサンプル（課題）"
        ],
        "多腕バンディット問題（方策勾配）": [
          "Q学習から方策勾配へ",
          "プログラムの処理の流れ",
          "Pythonでコードを書いてみよう（1/2）",
          "Pythonでコードを書いてみよう（2/2）",
          "課題：　多腕バンディット（腕の数を変更して実行）"
        ],
        "カートポール問題（方策勾配法　その２）": [
          "このセクションの概要",
          "カートポール問題のGymを動かしてみよう",
          "倒れたら環境をリセットしよう",
          "DQNとエクスペリエンス・リプレイ",
          "TensorFlowで実装してみよう（ネットワークのクラス定義）",
          "Experienceを格納するMemoryクラスの定義",
          "パラメーター初期化とエクスペリエンスの保存",
          "エクスペリエンスメモリーを蓄積しよう",
          "トレーニングを実行しよう（1/2）",
          "トレーニングを実行しよう（2/2）",
          "matplotlibで結果を可視化しよう",
          "テスト（エージェントにゲームをプレイさせてみよう）",
          "このセクションで使用したノートブック"
        ],
        "ボーナスセクション": [
          "外部リファレンスや参考図書",
          "AI・ディープラーニングのおすすめコース",
          "CUDAのインストール（TensorFlow入門より）",
          "cuDNNのインストール（TensorFlow入門より）"
        ]
      },
      "requirements": [
        "macOS, Windows, またはUbuntu（Linux）",
        "インターネット接続",
        "Python3, Anaconda Navigator, Jupyter Notebook",
        "TensorFlow, OpenAI Gym"
      ],
      "description": "【更新情報】\n2017/11/9　カートポール問題の結果の可視化、エージェントのプレー表示をアップロードしました。これで基本的なトピックは一通りカバーしました。あとはリクエストに応じてPythonのコーディングの補足解説や、発展的なトピックの紹介を追加していきたいと思いますので、ぜひリクエストください。\n2017/11/8　カートポール問題のトレーニングのレクチャーを掲載しました。\n2017/11/1　 カートポール問題のイントロを掲載しました。\n2017/10/30   多腕バンディット問題を解くチュートリアルを掲載しました。\n2017/10/29　方策勾配のセクションのイントロをアップロードしました。\n【コース概要】\nこの講座は、AlphaGo Zeroの活躍などで大注目されている強化学習についての基礎知識を、プログラムを作成しながら学ぶコースです。\n強化学習を使うと、画像を入力として与えるだけでゲームや囲碁、将棋などの対戦を機械が自分で繰り返し、最適な方策を学んで、人間よりも高いスコアを出す学習ができることが知られています。\n（主なトピック）\nこのコースでは、こうした強化学習を理解するための\n・マルコフ決定過程\n・ベルマン方程式\n・Q学習（Q-テーブルとQ-ネットワーク）\n・方策勾配（ポリシーグラディエント）\n・DQN（深層Qネットワーク学習）\nなどの基礎的な概念を理論解説と、Pythonでコードを書く演習を通して学びます。\n（プログラミング題材）\n題材としては、非営利のAI研究機関OpenAIが公開しているOpen AI Gymから\n１．フローズンレイク問題（凍った湖の上を穴に落ちずにゴールする）\n（１）Qテーブル法でQ値を求める\n（２）Qネットワーク法（ニューラルネットワーク）で解く\n２．多腕バンディット問題（マルチアームのスロットマシーン）\n３．カートポール問題（倒立振り子）\nDQN（Deep-Q学習、ディープラーニング、多層ニューラルネットワーク）で解く\nポール（棒）が倒れないようにカート（台車）を操作する問題\nなどのパッケージを入手して、強化学習を実践します。\n\n\nぜひこの機会に強化学習の考え方や基礎知識を身につけ、ビジネスや開発に活かしましょう。\n【受講上の注意】\nこのコースはビデオでの学習をしたくない方には向いていませんので、ご注意ください。",
      "target_audience": [
        "強化学習の基本的な仕組みを学びたい方",
        "画像分類やRNNなど機械学習を学んできたが、強化学習にチャレンジしたい方",
        "自力でコードを書くのが嫌でない方",
        "ビデオを視聴するのが苦痛でない方"
      ]
    },
    {
      "title": "RPA com Python: Crie robôs de forma simples e prática",
      "url": "https://www.udemy.com/course/curso-robotic-process-automation-rpa-crie-robos-bots-com-python/",
      "bio": "Desenvolva Robôs (Bots) em Python para automatizar tarefas em qualquer área do mercado. #Python RPA #RobôsComPython",
      "objectives": [
        "Instalar o Python",
        "Instalar o PyCharm",
        "Instalar bibliotecas de RPA",
        "Instalar o Power BI",
        "Os conceitos de RPA",
        "Criar robôs que controlam o mouse",
        "Criar robôs que controlam o teclado",
        "Criar robôs que irão controlar softwares e navegadores",
        "Automatizar tarefas do dia a dia da sua empresa"
      ],
      "course_content": {
        "INTRODUÇÃO": [
          "INTRODUÇÃO AO CURSO",
          "DICAS DE PRODUTIVIDADE NO CURSO",
          "O QUE É RPA?",
          "ROBÔ ASSISTIDO VS NÃO-ASSISTIDO"
        ],
        "CONFIGURANDO O AMBIENTE": [
          "PRÉ-REQUISITOS PARA UTILIZAR AS BIBLIOTECAS",
          "INSTALANDO O PYTHON",
          "INSTALANDO O PYCHARM"
        ],
        "INTRODUÇÃO LÓGICA DA LINGUAGEM PYTHON": [
          "OVERVIEW PARTE_01",
          "OVERVIEW PARTE_02"
        ],
        "CRIANDO O 1º ROBÔ: (BOT)": [
          "INSTALANDO AS LIBS DE RPA E ENTENDENDO COORDENADAS",
          "CONTROLANDO O EXECUTAR, ESCREVENDO NO NOTEPAD E FECHANDO.."
        ],
        "CRIANDO O 2º ROBÔ: CONTROLANDO O NAVEGADOR": [
          "CONTROLANDO O NAVEGADOR COM INIT() E URL()",
          "ENSINANDO O ROBÔ A FAZER BUSCAS E CAPTURAS DE TELAS"
        ],
        "CRIANDO O 3º ROBÔ: WEB E-MAIL": [
          "COTAÇÃO DO DOLAR PARA O E-MAIL - AUTOMAÇÃO PARTE_01",
          "COTAÇÃO DO DOLAR PARA O E-MAIL - AUTOMAÇÃO PARTE_02"
        ],
        "CRIANDO O 4º ROBÔ: VISUAL AUTOMATION": [
          "ENSINANDO O ROBÔ ATRAVEZ DE IMAGENS - PARTE_01",
          "ENSINANDO O ROBÔ ATRAVEZ DE IMAGENS - PARTE_02"
        ],
        "CRIANDO O 5º ROBÔ: POWER BI": [
          "ATUALIZANDO O ARQUIVO DO POWER BI (PBIX) - PARTE_01",
          "ATUALIZANDO O ARQUIVO DO POWER BI (PBIX) - PARTE_02"
        ],
        "CRIANDO O 6º ROBÔ: EXTRAÇÃO DE DADOS DA WEB": [
          "EXTRAINDO DADOS DA WEB - PARTE_01",
          "EXTRAINDO DADOS DA WEB - PARTE_02"
        ],
        "CRIANDO O 7º ROBÔ: RESOLVENDO O DESAFIO RPA": [
          "RESOLVENDO O DESAFIO DE RPA DINÂMICO - PARTE_01",
          "RESOLVENDO O DESAFIO DE RPA DINÂMICO - PARTE_02",
          "RESOLVENDO O DESAFIO DE RPA DINÂMICO - PARTE_03"
        ]
      },
      "requirements": [
        "Acesso a internet",
        "Um computador com no mínimo 4GB de RAM e Windows 10",
        "Noções de lógica de programação"
      ],
      "description": "Neste curso você vai aprender a automatizar tarefas desenvolvendo robôs em Python para dar celeridades nos processos empresariais de forma simples, prática e objetiva, ou seja, você vai criar robôs para automatizar suas tarefas sem custos de licenciamento.\nAutomação Web\nAutomação de Aplicações Desktops\nAutomação de E-mail\nUtilização de bibliotecas próprias de RPA.\nO RPA (Robotic Process Automation) é um avanço significativo quando falamos na modernização de um negócio. Afinal, para sua empresa começar a transformação digital, um dos primeiros passos a serem dados é a automatização de processos. O RPA é um mecanismo simples e extremamente funcional no contexto corporativo atual e futuro. É uma resposta tecnológica às ânsias das empresas por agilidade e eficiência operacional. Com certeza, é uma aplicação que qualquer empresa — especialmente a sua — deve possuir para se posicionar à frente da concorrência.\nNão à toa, já em 2017, em pesquisa da Deloitte, 53% das empresas afirmaram já terem embarcado em sua jornada de adoção e adequação de soluções RPA.\n\nVocê pode considerar o uso do RPA em cenários de todos os tipos, seja no envio de um simples e-mail de agradecimento, como na implantação de bots para automatizar tarefas em um sistema complexo, como um CRM.\nAté 2024, as organizações vão poupar 30% dos custos operacionais atuais apenas com a adoção da automação e com o redesign de processos operacionais.\nSão dados da Gartner, uma das principais consultorias de tendências tecnológicas e de mercado do mundo.",
      "target_audience": [
        "Profissionais e estudantes de todas as áreas que tenham interesse em automatizar suas tarefas.."
      ]
    },
    {
      "title": "(Ken Cen出品)Generative AI第一部 - 從LangChain接入ChatGPT到製作股票分析AI團隊",
      "url": "https://www.udemy.com/course/generative-ai-ai-agent-chatgpt-api-key/",
      "bio": "ChatGPT，Artificial Intelligence，Generative AI，Prompt Engineer，Machine Learning，LangChain，LLM，RAG，FAISS，Chroma， AI Agents",
      "objectives": [
        "Generative AI生成式人工智能的核心概念和原理",
        "了解如何使用LangChain接入各種LLM大語言模型",
        "了解如何使用Prompt Template讓LLM按照我們的指令行事",
        "了解如何使用Chain鏈接各種Primitive基本單元讓LLM實現複雜行為",
        "了解如何為LLM大語言模型添加記憶功能記住上下文",
        "了解如何使用RAG增強檢索生成功能加載和搜索PDF和網站信息",
        "了解如何使用Chunking技術分割文檔，避免太小丟失語意，太大開銷太大的陷阱",
        "了解如何使用Chroma和FAISS向量數據庫實現RAG增強檢索生成功能",
        "了解如何製作AI Agent",
        "了解如何製作一個AI Agent團隊"
      ],
      "course_content": {
        "如何開始學習 AI": [
          "如何開始學習 AI"
        ],
        "Generative AI生成式人工智能": [
          "什麼是Generative AI生成式人工智能",
          "什麼是LangChain",
          "如何獲得免費OpenAI API Key",
          "課程編譯環境設定"
        ],
        "LangChain": [
          "LangChain如何連結LLM大語言模型",
          "LangChain三大Package",
          "Prompt Template 提示詞模板",
          "Few Shot Prompt Template 少量示例提示模板",
          "Chain鏈條Primitive基本單元與Utility Chain工具鏈條",
          "通用鏈條SequentialChain順序鏈",
          "如何為LLM添加記憶"
        ],
        "RAG 檢索增強生成": [
          "何謂RAG",
          "如何加載PDF和搜索網頁信息",
          "Text Splitter文本分割器",
          "Chunking分塊大小怎麼決定"
        ],
        "向量數據庫": [
          "Embedding與Chroma向量數據庫的創建",
          "Chroma向量數據庫相似度搜索",
          "如何使用Ollama安裝的本地LLM搜索Chroma向量數據庫",
          "如何使用LLM摘要總結Chroma檢索信息",
          "如何初始化FAISS與RetrievalQA的使用",
          "如何保存與加載FAISS並製表查看FAISS中的文檔",
          "如何在FAISS中添加和刪除文檔"
        ],
        "如何製作AI Agent 智能體 & AI Agent團隊": [
          "如何使用LCEL",
          "創建AI智能體",
          "AI Agent如何使用LangChain自帶工具",
          "創建AI團隊",
          "股票分析AI團隊製作-Crew&Agents&Tasks",
          "股票分析AI團隊製作-定義Agents與Tasks",
          "股票分析AI團隊製作-添加上網搜索工具",
          "股票分析AI團隊製作-得出是否買入股票建議"
        ]
      },
      "requirements": [
        "一台電腦和基礎的Python知識"
      ],
      "description": "在這個快速發展的數字時代，我們面臨著前所未有的機遇和挑戰。\n在這樣的環境下，學習如何利用最先進的技術來提升業務效率和創造力變得至關重要。\n這就是為什麼我們推出了《生成式人工智能課程》，這是開啟您未來成功之門的關鍵。\n\n\n這門課程將引領您探索生成式人工智能（Generative AI）的奧秘，透過全實作模式的教學方式深度實踐，讓您成為AI技術的大師，為您的業務帶來革命性的變革。\n\n\n讓我們一起來看看這個課程的亮點：\n\n\n1. **生成式人工智能概述**：從基礎開始，深入了解生成式人工智能的核心概念和原理，為您打下堅實的理論基礎。\n\n\n2. **LangChain的使用**：您將學會使用LangChain接入各種LLM大語言模型，讓您的人工智能擁有更多的功能和靈活性。\n\n\n3. **Prompt Template提示詞模板**：您還會掌握如何使用Prompt Template，按照自己的指令來訓練和引導LLM。這將讓您的人工智能成為您業務的得力助手，完全按照您的期望行事。\n\n\n4. **Chain技術**：使用Chain技術，將各種Primitive基本單元鏈接在一起，讓您的人工智能實現更複雜的行為。這將為您的業務帶來革命性的變革，讓您跨越傳統的限制，勇闖新的領域。\n\n\n5. **RAG檢索增強生成**：探索RAG增強檢索生成功能，讓您的人工智能可以輕鬆地加載和搜索PDF和網站信息。這將讓您的人工智能的知識庫更加豐富，回答問題更加準確。\n\n\n6. **文本分割器Chunking與Embeddings技術**：深入探討文本分割器的使用，多大的Chunk才合適，以及如何將分割好的文本轉化為Embeddings，充分利用向量數據庫進行相似性搜索，為AI員工提供更強大的信息檢索和處理能力。\n\n\n7.  **製作AI Agent**：我們將教您如何製作AI Agent，甚至是一個AI Agent團隊。這將讓您的業務實現真正的自動化，讓您釋放出更多的時間和精力，去追求更大的目標和夢想。\n\n\n最重要的是，這門課程僅需一台電腦和基礎的Python知識，即可輕鬆上手。無論您是新手還是經驗豐富的專家，都能從中受益匪淺。\n現在就加入我們，開啟您的人工智能之旅，掌握未來的關鍵技能！",
      "target_audience": [
        "對人工智能和機器學習感興趣的學員",
        "想要了解生成式人工智能技術及其應用的學員",
        "想要了解如何製作AI Agent的學員",
        "想要了解如何使用LangChain製作LLM應用程式的學員",
        "想要了解如何使用RAG技術操作Chroma和FAISS的學員"
      ]
    },
    {
      "title": "Python Machine Learning Build Real-World AI Projects",
      "url": "https://www.udemy.com/course/build-realworld-machinelearning-projects-with-python-in-2023/",
      "bio": "Build & Deploy Real-World Machine Learning Projects Using Python, Flask, Django, and Heroku. Hands-on Data Science",
      "objectives": [],
      "course_content": {
        "Project-1 : UK_Road_Accident_Timeseries_Forecasting": [
          "UK_Road_Accident_Timeseries_Forecasting_EDA",
          "Forecast UK Accident rates based on Number of Casualties on SARIMA,FbP,LSTM's"
        ],
        "Project-2 : Toxic_Comments_Classification": [
          "Toxic_Comments_Classification_EDA",
          "NLP - Tokenized Sequences for Visualization",
          "Model Refinement - Optimize NB,SVM,LR with Feature Weight"
        ]
      },
      "requirements": [
        "Some experience with Python is recommended, but no prior machine learning knowledge is necessary. We'll guide you through each concept step by step.",
        "You should be comfortable with basic algebra and statistics. While this course simplifies the math concepts, a basic understanding will help with advanced topics.",
        "A passion for data and problem-solving will help you succeed. No previous experience in machine learning is required, but an eagerness to learn will keep you motivated."
      ],
      "description": "Master Real-World Machine Learning Projects with Python\nAre you ready to take your Machine Learning and Data Science skills to the next level?\nIn this course, you will build, deploy, and showcase real-world projects — the kind that employers and clients look for.\nWhether you are aiming for a career in Machine Learning, looking to upgrade your Data Science skills, or simply want to create powerful AI applications, this course will give you practical, hands-on experience.\nWhat You Will Learn\nPython Programming for Data Science and Machine Learning\nBuilding Classical Machine Learning Algorithms from scratch\nNatural Language Processing (NLP) for text classification\nTime Series Forecasting and Prediction\nDeveloping web applications using Flask and Django\nDeploying Machine Learning models on Heroku\nReal-World Projects Included\nToxic Comment Classification\nBuild an NLP model that detects and classifies toxic or abusive comments automatically.\nUK Road Accident Time Series Forecasting\nAnalyze and forecast accident trends using time series data to derive meaningful insights.\nWhy Enroll in This Course\nHands-on practical learning by building and deploying real applications\nStrong portfolio projects to showcase to potential employers\nSkills that align with the latest industry demands in Data Science and AI\nEasy-to-follow instructions even for beginners with minimal experience\nWho This Course Is For\nBeginners who want to start a career in Machine Learning and Data Science\nStudents and professionals aiming to gain practical project experience\nDevelopers looking to strengthen their Python and AI development skills\nAnyone interested in building and deploying real-world Machine Learning applications\nWhat You Will Receive\n1.5+ hours of high-quality video content\nDownloadable project files and resources\nLifetime access to all course materials\nCertificate of Completion to showcase your achievement\nIf you are serious about developing your Machine Learning skills with Python and want to build real-world projects that matter, this is the course for you.\nEnroll today and start your journey toward becoming a skilled Machine Learning Engineer.",
      "target_audience": [
        "Perfect for those who are just starting and want to dive into real-world machine learning projects.",
        "Ideal for professionals from non-technical backgrounds (e.g., business, marketing, finance) looking to transition into a career in data science.",
        "A great option for those starting their career in machine learning, or those looking to gain valuable skills for job readiness.",
        "Whether you’re a beginner or have some knowledge of Python, this course is designed to provide hands-on learning to all who want to understand machine learning."
      ]
    },
    {
      "title": "Python Fundamentals for AI & Data Science",
      "url": "https://www.udemy.com/course/python-fundamentals-for-ai-data-science/",
      "bio": "Learn essential Python concepts: variables, loops, functions, and data structures to kickstart your journey",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction"
        ],
        "Basic Programming Concepts": [
          "Variables and Data Types",
          "Loops and Conditionals",
          "Python Implementation",
          "Write your own program"
        ],
        "Functions and Modules": [
          "Introduction to Functions",
          "Functions with Parameters and Return Values"
        ],
        "Introduction to Data Manipulation in Python": [
          "Introduction to Modules",
          "Working with Lists and Dictionaries for Simple Data Manipulation",
          "Introduction to Pandas"
        ],
        "Conclusion": [
          "Conclusion + Next Steps"
        ]
      },
      "requirements": [
        "No programming experience needed"
      ],
      "description": "Are you eager to dive into AI, Data Science, or Machine Learning, but not sure where to start? This course is designed to provide you with the essential Python skills needed to begin working on real-world AI and data science projects—fast.\n\n\nPython is the most widely used programming language in data science and AI, and this course cuts through unnecessary complexity to focus on the fundamentals you need to get started. We’ll cover variables, loops, conditionals, functions, and modules, followed by essential data structures like lists and dictionaries. Finally, you’ll get an introduction to pandas, one of the most powerful tools for data manipulation.\n\n\nThis course is not here to teach you everything—it serves as a framework to guide you in the right direction. You’ll get a structured overview of the essential building blocks, but it is expected that you review the linked resources, practice on your own, and research further to truly master these concepts. Learning to code requires hands-on effort, and this course will show you what you need to focus on.\n\n\nBy the end of this course, you will have the foundational Python skills needed to confidently explore AI, machine learning, and data science. If you're ready to start coding and learning exactly what you need—nothing more, nothing less—this course is for you!",
      "target_audience": [
        "This course is perfect for anyone who is new to programming and wants to learn Python from the ground up. Whether you're interested in data science, machine learning, or simply want to add Python to your skillset, this course will give you the foundational knowledge you need to get started. No prior experience is required, so if you're curious about coding and ready to dive in, this course is for you!"
      ]
    },
    {
      "title": "Corso completo per Data Science e machine learning con R",
      "url": "https://www.udemy.com/course/corso-completo-di-data-science-con-r/",
      "bio": "Da principiante a esperto nelle tecniche di Data Science con R: machine learning, network neurali, text mining e...",
      "objectives": [
        "Ripasso delle basi di R e delle sue strutture dati",
        "Ambienti di programmazione per il Data Science",
        "Importazione di dataset in R",
        "Creazione grafici ed esplorazione dataset",
        "Manipolazione e gestione dataset",
        "Preprocessing e pulizia dei dati per l'analisi",
        "Introduzione al machine learning con R",
        "Teoria e algoritmi di machine learning, metodi supervisionati e non supervisionati",
        "Metodi ensemble: bagging, boosting",
        "Validazione e valutazione dei modelli",
        "Pulizia e analisi testi",
        "Metodi per la Sentiment Analysis"
      ],
      "course_content": {
        "Introduzione": [
          "Introduzione",
          "Data Science e Machine learning",
          "Il processo di analisi",
          "Codice del corso"
        ],
        "Basi di R": [
          "Installare R",
          "Installare RStudio",
          "Personalizzare e utilizzare RStudio",
          "Utilizzare altri IDE",
          "R pro e contro",
          "Commentare il codice",
          "Operazioni matematiche di base",
          "Creazione di oggetti",
          "Le parentesi",
          "Tipi di variabili in statistica",
          "Le strutture dati in R",
          "Vettori",
          "Matrici",
          "Array",
          "Liste",
          "Fattori",
          "Dataframe",
          "Stringhe",
          "Date",
          "Convertire le strutture dati",
          "R base versus tidyverse",
          "Operatori relazionali",
          "Strutture di controllo",
          "Funzioni",
          "Impostare una directory di lavoro",
          "Installare e richiamare un pacchetto",
          "Formati dati e fonti comuni per l'analisi",
          "Importazione dati",
          "Files csv",
          "Files Excel",
          "Files txt",
          "Subsetting",
          "La famiglia apply",
          "Manipolazione dati con dplyr",
          "Altri pacchetti per la manipolazione dati",
          "Unire due dataset"
        ],
        "Analisi esplorativa": [
          "Analisi esplorativa",
          "La funzione set.seed",
          "Data cleaning",
          "Alcuni metodi per la preparazione dei dati",
          "Il pacchetto outliers",
          "Forzare una variabile come fattore",
          "Codificare le variabili categoriche",
          "Standardizzazione dei dati"
        ],
        "Machine learning": [
          "Introduzione al machine learning",
          "Fasi del machine learning",
          "Tipi di algoritmi per il machine learning",
          "Problemi del machine learning",
          "Metodi supervisionati",
          "Analisi di regressione",
          "Regressione lineare semplice",
          "Regressione multipla in R"
        ],
        "Classificazione": [
          "Regressione logistica in R",
          "k-nearest neighbors",
          "Calcolo della distanza",
          "La distanza euclidea",
          "Esempio di k-nn con R",
          "Support Vector machines",
          "Divisione dei dati in spazi non lineari",
          "Esempi di SVM con R",
          "Alberi di decisione",
          "Esempi di DT con R",
          "Il calcolo delle probabilità",
          "Probabilità e metodo predittivo",
          "Esempio di Naive Bayes con R"
        ],
        "Metodi non supervisionati": [
          "Metodi non supervisionati",
          "Clustering",
          "L'algoritmo kmeans",
          "Esempio di kmeans con R",
          "Analisi delle associazioni",
          "Apriori con R"
        ],
        "Metodi ensemble": [
          "Metodi ensemble",
          "Bagging",
          "Boosting",
          "Random Forest",
          "XGBoost",
          "Esempi di metodi ensemble con R",
          "Tecniche per la riduzione della dimensionalità",
          "Riduzione della dimensionalità con R"
        ],
        "Text mining": [
          "L’uso del machine learning nell’analisi dei testi",
          "Natural Language Processing",
          "Trattamento e pulizia dei testi",
          "Vettorializzazione di un testo",
          "Misurare la distanza tra due testi",
          "TF-IDF",
          "Tipi di strutture per l'analisi",
          "Le espressioni regolari con R",
          "Naïve Bayes in R sullo spam",
          "Esempio di regressione logistica su testi con R",
          "Alberi di decisione con R - pacchetto rpart su dati testuali"
        ],
        "Sentiment Analysis": [
          "Sentiment Analysis",
          "Naive Bayes e Sentiment",
          "Fonti dati per la Sentiment Analysis",
          "Metodi per la Sentiment Analysis con R",
          "Metodi non supervisionati",
          "Metodi supervisionati"
        ],
        "Deep Learning": [
          "L'importanza e gli utilizzi dei network neurali",
          "Storia e caratteristiche delle reti neurali",
          "Il cervello umano",
          "Il neurone artificiale",
          "Le differenze tra i due sistemi",
          "Tipi di reti neurali",
          "Perceptrone",
          "Addestramento della rete",
          "Deep Neural Networks o reti neurali profonde",
          "I framework per il deep learning",
          "Reti feedforward",
          "Esempio di rete feedforward con nnet",
          "Esempio di rete neurale con neuralnet",
          "Esempio di previsione con output numerici",
          "L’algoritmo di backpropagation",
          "Il metodo del gradiente",
          "Funzioni di attivazione",
          "Parametri per le reti neurali",
          "Rappresentare dati non strutturati per il deep learning",
          "Dai vettori ai tensori in R",
          "Keras per R",
          "CPU/GPU",
          "Un primo esempio di modello con keras e iris su R",
          "Esempio di classificazione binaria sul dataset Pima con R",
          "Esempio di regressione semplice con R",
          "Esempio di regressione multipla sul dataset Boston con R",
          "Tensorflow Playground",
          "Computer Vision",
          "Il deep learning nella computer vision",
          "Convolutional neural networks - CNN",
          "Stride e pooling",
          "Capiamo come viene letta un'immagine dal computer - con R",
          "Esempio di CNN con R e il dataset MNIST",
          "Esempio di CNN con R e il dataset CIFAR"
        ]
      },
      "requirements": [
        "Conoscenza base di R"
      ],
      "description": "Questo corso sul Data Science con R nasce per essere un percorso completo su come si è evoluta l'analisi dati negli ultimi anni a partire dall'algebra e dalla statistica classiche. L'obiettivo è accompagnare uno studente che ha qualche base di R in un percorso attraverso le varie anime del Data Science.\nCominceremo con un ripasso delle basi di R, a partire dallo scaricamento e installazione, all'impostazione dell'ambiente di lavoro, passando per le strutture, la creazione di funzioni, l'uso degli operatori e di alcune funzioni importanti.\nPasseremo poi a vedere come manipolare e gestire un dataset, estrarne dei casi oppure delle variabili, generare dei dataset casuali, calcolare delle misure statistiche di base, creare grafici con i pacchetti Matplotlib e Seaborn.\nNelle sezioni successive cominciamo a entrare nel cuore del Data Science con R, a cominciare dal preprocessing: vediamo infatti come ripulire e normalizzare un dataset, e come gestire i dati mancanti.\nLa sezione successiva ci permette di cominciare a impostare dei modelli di machine learning con Python: vedremo tutti gli algoritmi più comuni, sia supervisionati che non supervisionati, come la regressione, semplice, multipla e logistica, il k-nearest neighbors, il Support Vector Machines, il Naive Bayes, gli alberi di decisione e il clustering.\nPasseremo poi ai più comuni metodi ensemble, come il Random Forest, il Bagging e il Boosting, e all'analisi del linguaggio naturale e al suo utilizzo nel machine learning per la catalogazione dei testi.\nNelle ultime sezioni vedremo alcuni rudimenti di analisi temporale, sistemi di raccomandazione e social media mining.",
      "target_audience": [
        "Chi conosce già un po' di programmazione R e vuole cominciare un percorso nel data science",
        "Chi cerca un percorso completo per farsi un'idea delle tante anime del Data Science con R"
      ]
    },
    {
      "title": "ジェネレーティブAI（画像生成AI）入門【Stable Diffusion】-プロンプトでハイクオリティな画像制作が可能",
      "url": "https://www.udemy.com/course/stable_diffusion/",
      "bio": "ChatGPTをはじめとした革命的技術。【StableDiffusion】が超リアルな画像を生成します。プロンプトを駆使して、これから始まる新時代のビジネスで活用しよう。",
      "objectives": [
        "Stable Diffusionの使い方",
        "クラウド環境での構築方法",
        "Paperspaceの使い方",
        "リアルな美女やイケメンの生成方法",
        "画像生成系AIの使い方",
        "プロンプト（呪文）について"
      ],
      "course_content": {
        "1.はじめに": [
          "1-0.ご購入前に必ずご確認ください。",
          "1-1_Stable Diffusionとは",
          "1-2_このコースについて",
          "1-3_この講座に必要なツールについて",
          "1-4.Paperspaceのプランについて"
        ],
        "2.Paperspace Gradientで仮想デスクトップにアクセスする": [
          "2-1_Paperspaceのメリットとデメリット",
          "2-2_Paperspace Gradientに登録してNotebooksを作る",
          "【重要】必ずご確認ください",
          "2-3_Notebooksを起動して、Web UI とモデルのセットアップを行う",
          "OUT OF CAPACITYと出てマシン選択ができない場合",
          "マシンの選択ができない、エラーが出るなど不具合がある場合",
          "Proプランでストレージの超過を心配される方へ"
        ],
        "3.プロンプトの基本": [
          "3-1_プロンプトの基本と7つの要素"
        ],
        "4.学習モデルをマージする": [
          "4-1_モデル(checkpoint)をアップロードする",
          "4-2_モデルのマージを行う"
        ],
        "5.画像からモデルを生成する": [
          "5-1_PNG Infoから画像を生成する"
        ],
        "6.プロンプトからモデルを生成する": [
          "6-1_プロンプトから美女を生成するtxt2imgとは",
          "6-2_＜便利1＞ChatGPTを利用する",
          "6-3_＜便利2＞プロンプト入力を楽にする拡張機能"
        ],
        "7.環境設定": [
          "7-1_ControlNetをwebUIに取り込む",
          "7-2_LoraをwebUIに取り込む",
          "7-3_モデルと生成画像を削除して、ストレージを管理する",
          "7-4_Machineの選択ができない場合はリロードする",
          "7-5_エラーが発生する場合は、webuiを再起動する",
          "7-6_プリセットを活用してPromptを呼び出す",
          "7-7_WebUIの設定を保存する"
        ],
        "8.高度な生成術-ControlNet活用編-": [
          "8-1_同じ顔の別スタイルを量産する裏技",
          "8-2_1枚の画像からカメラロールを作り出す裏技"
        ],
        "9.高度な生成術-その他の活用編-": [
          "9-1_img2imgで似た画像を生成する方法",
          "9-2_inpaintで効率よく「服装」や「髪型」だけを修正する裏技",
          "9-3_inpaintで顔を固定して、別のシーンを生成する方法"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Windows or Macのパソコン",
        "Paperspaceの契約",
        "基本的なパソコンスキル"
      ],
      "description": "【重要】超初心者に向けた講座です。ある程度学習をしている方は購入しないでください。\n\n\n\n\n\n\n当講座にアクセスいただきありがとうございます。\nコース受講前に注意点をお伝えしますので、ご理解いただいた方のみご購入お願いいたします。\n\n\nPaperspaceでのStable Diffusionの環境構築は、講座の手順通りに進めていけばできますが、何らかの不具合やお使いのPCの設定状況などで、構築が上手くいかない場合があります。\nその際は講座の手順通りに進めてください。\n\n\n都度、僕に質問される方がいらっしゃますが、時間の都合上、僕のリソースが足りず、各々の問題解決をお手伝いすることはできません。ですので、基本的なエラーに関しての質問をされても、僕からの回答はございませんので、その点を留意した上でご購入お願いいたします。\n\n\n講座の購入者に対して、個別コンサルを行っているわけではありませんので、ご理解お願いいたします。\n\n\n※質問が多い項目につきましては、時折講座に追記していきますので、そちらでご確認いただければと思います。\n\n\n\n\n\n\n\n\n\n\n\n\n今、画像生成AIが「革命」と言えるほど盛り上がっているのをご存じでしょうか。\n\n\n2022年8月前後 からDALL・E 2（ダリ・ツー）やImagen（イマジェン）、それからもちろんMidjourney（ミッドジャーニー）など、多数の画像生成系AIが登場し、世の中を騒然とさせてきましたが、それらを１歩も2歩も先に進んで、多くの人が熱中しているのが、今回この講座で学習するStable Diffusion（ステーブルディフュージョン）です。\n\n\nこれまでAIが生成する絵といえば、リアルさに欠け、いかにもAIが生成した画像っていう感じでしたよね。\nそれが最新の技術により、リアルなAI人物を生成することが可能になりました。\n\n\n特にStable Diffusionは、「誰もが必ず知っておくべき」重要なAIだと僕は考えています。\n\n\nもし、あなたが「今、画像生成AIがはやっているみたいだけど、何ができて、何がすごいのかよく分からない」とか「興味があってやり始めたけけど、つまづいてしまった」という方であればこの講座は最適です。\n\n\nStable Diffusionの概要と基本的な仕組み、また、それを簡単に使うためのサービス、実際の生成方法などをできるだけ分かりやすくコンパクトに2時間で学習していきます。\n\n\nこれらの画像生成系AIに共通するのは、プロンプトとか呪文とか呼ばれるテキストを入力することで、高解像度のグラフィックが生成されることです。このプロンプトをどう工夫すれば、生成される画像をよりよいもの（ユーザーが望む理想に近いもの）をできるかが重要であり、そこを補うのが「プロンプトエンジニアリング」と呼ばれる分野です。\n\n\nAIの登場によって、さまざまな仕事がなくなるとも言われていますが、逆も然りで、AIを上手に利用するために必要なプロンプトエインジニアやデザイナーなど新たな職業も誕生しています。\n\n\n特に画像生成系AI界隈で「Stable Diffusionの登場前と後では、世の中は変わってしまった」Stable Diffusionの登場はAIの歴史の中でchatGPTに匹敵するほど、いや、それ以上に重要な出来事で、革命的なものだ。」と画像生成の先駆者たちがこぞって取り上げている理由もわかります。\n\n\nだからこそ「誰もがStable Diffusionのことを知っておくべきだ」と私は思いこの講座をリリースしました。\n\n\nこの講座では、ステーブルでフュージョンをクラウド環境で利用するための環境構築と初期設定、画像生成から応用までをステップバイステップで解説していきます。\n現時点ではこの僕の講座よりもわかりやすく解説している講座はありませんので、安心して受講してください。\n特につまづきやすい初期設定から、リアルなAI美女やイケメンの生成方法、画像を量産する裏技など、ステップバイステップで「動画で完全解説」するので、パソコンが苦手な方でも、必ずリアルな画像を生成することができるようになります。\nちなみに通常は画像を生成するために、数十万円もするグラフィックボードを積んだハイスペックなパソコンが必要ですが、今回はPaperSpaceというクラウド型の仮想デスクトップを利用しますので、作業環境はWindowsでもMacでも構いません。\nブラウザは今のところ、一番エラーの少ないGoogle chromeを推奨します。\npaperspaceの利用料は最安で0円、もしくは月額8ドル、か39ドルです。普通に使うためには、最低でも月額8ドルのプランを推奨しています。\n\n\nちなみにこの講座では、主に人物を生成する流れについて学習しますが、やり方は同じなので、人物の生成さえできれば、アニメイラストも3Dイラストも、風景も、建築パースもプロンプトを自在に操ることで、なんでも実現可能です。\n\n\nぜひ、新しい時代に新しい技術に触れてみてください。",
      "target_audience": [
        "画像生成系AIを使いたい方"
      ]
    },
    {
      "title": "Curso Python: Análisis y visualización de datos",
      "url": "https://www.udemy.com/course/python-3-analisis-y-visualizacion-de-datos/",
      "bio": "Jorge, con experiencia en análisis de datos, te guiará en el aprendizaje de Python desde cero.",
      "objectives": [
        "Análisis de datos con Python",
        "Aprenderás a analizar grandes volúmenes de datos rápidamente con Pandas.",
        "Aprenderás a encontrar relaciones entre las variables de tus datos.",
        "Aprenderás como hacer gráficas atractivas para los datos.",
        "Aprenderás a generar representaciones gráficas de la información para tener un mejor entendimiento de ella.",
        "Aprenderás a exportar los datos tratados a Excel.",
        "Aprenderás a importar datos desde un CSV o desde un Excel para analizarlos.",
        "Aprenderás como crear una Base de Datos con Python para leer y escribir datos en ella."
      ],
      "course_content": {
        "¿Cómo está formado el curso?": [
          "Bienvenido a DataBoosters",
          "Descripción del curso",
          "Presentación del instructor",
          "¿Cómo tomar el curso?"
        ],
        "Parte 1: Programación Numérica con NumPy": [
          "Introducción",
          "Objetivos y Estructura del Curso",
          "Archivos del curso"
        ],
        "Parte 1: Fundamentos de NumPy": [
          "Configuración del Entorno de Trabajo",
          "Creación de Arrays NumPy",
          "Indexación y Selección en Arrays NumPy",
          "Operaciones Básicas con Arrays NumPy"
        ],
        "Parte 1: Operaciones Avanzadas con NumPy": [
          "Broadcasting en NumPy",
          "Funciones Universales en NumPy",
          "Manipulación y Reducción de Arrays NumPy"
        ],
        "Parte 1: Álgebra Lineal con NumPy": [
          "Operaciones de Álgebra Lineal con Arrays NumPy",
          "Solución de Sistemas de Ecuaciones Lineales",
          "Descomposición de Matrices y Autovalores"
        ],
        "Parte 1: Graficando datos": [
          "Introduccion a matplotlib",
          "Personalización de gráficos",
          "Subplots"
        ],
        "Parte 1: Proyecto Final de Programación Numérica": [
          "Desarrollo de un Proyecto de Programación Numérica",
          "Presentación y Comunicación de Resultados"
        ],
        "Parte 1: Conclusión del Curso": [
          "Resumen y Mejores Prácticas",
          "Aplicaciones en Ciencias e Ingeniería",
          "Pasos Siguientes y Recursos Adicionales"
        ],
        "Parte 2: Manejo de datos con Pandas": [
          "¿Qué es Pandas y por qué es Importante?",
          "Instalación y Configuración de pandas",
          "Primeros Pasos: Carga de Datos y Exploración Básica",
          "Archivos del curso"
        ],
        "Parte 2: Estructuras de Datos en Pandas": [
          "Series: Creación, Manipulación y Uso",
          "DataFrame: Fundamentos y Operaciones Básicas",
          "Trabajar con Datos Temporales en Series y DataFrames",
          "Index Objects: Características y Funcionalidades"
        ]
      },
      "requirements": [
        "Sería bueno que sepas lo básico de Python pero no es indispensable.",
        "Tener nociones básicas del manejo de datos en Excel."
      ],
      "description": "En este curso integral de Programación Numérica y Análisis de Datos con Python, aprenderás a dominar las principales herramientas y técnicas para la manipulación de datos, análisis de datos y visualización de datos con Python. Este recorrido completo incluye tres pilares fundamentales: NumPy para cálculos numéricos, pandas para la gestión y transformación de datos, y visualización avanzada de datos para comunicar tus resultados.\nEn la primera parte, Programación Numérica con NumPy, descubrirás desde los fundamentos de NumPy hasta técnicas avanzadas de manipulación de arrays y álgebra lineal. Aprenderás a trabajar con arrays NumPy, realizar operaciones matemáticas avanzadas y construir un proyecto de programación numérica que consolidará tus conocimientos y habilidades en ciencia de datos y análisis numérico.\nLa segunda parte, Manejo de Datos con pandas, está dedicada a la limpieza, transformación y análisis de grandes volúmenes de datos. Con pandas, dominarás estructuras de datos como Series y DataFrames, así como técnicas para limpieza de datos, sumarización estadística y análisis de datos. Además, aplicarás estos conocimientos en casos prácticos de análisis de datos, preparándote para trabajar en proyectos de data science y análisis avanzado.\nEn la tercera parte, Análisis y Visualización de Datos, te sumergirás en técnicas de análisis descriptivo, visualización de datos con Python y exploración de series temporales. Aprenderás a crear gráficos de dispersión, mapas de calor y dashboards interactivos utilizando herramientas de visualización como Matplotlib y Seaborn. Con el proyecto final de análisis y visualización de datos, aplicarás todas estas técnicas en un análisis de datos real, adquiriendo habilidades esenciales para presentar tus resultados de manera profesional y efectiva.\nCada lección de este curso está diseñada para ser práctica y aplicada, asegurando que puedas implementar lo aprendido en proyectos de data science y análisis de datos. Al completar el curso, estarás preparado para manejar datos, realizar análisis complejos y crear visualizaciones de alto impacto, habilidades fundamentales en el campo de la ciencia de datos y la programación en Python.\n¡Lleva tus habilidades en Python y análisis de datos al siguiente nivel con NumPy, pandas y visualización avanzada!",
      "target_audience": [
        "Profesionistas que requieran trabajar con una gran cantidad de datos.",
        "Profesionistas que necesiten analizar grandes volúmenes de datos."
      ]
    },
    {
      "title": "Devenir un expert du SQL - Le cours Complet",
      "url": "https://www.udemy.com/course/devenir-un-expert-du-sql-le-cours-complet/",
      "bio": "SQL, Big Query & PostgreSQL : Analyse, Bases de Données, Python, Power BI pour une Data Science optimale.",
      "objectives": [
        "Fondamentaux du SQL et des Bases de Données",
        "Requêtes et Analyse de Données",
        "Création et Gestion de Bases de Données",
        "Fonctionnalités avancés du SQL (procédures, sous-requêtes, triggers)",
        "Intégration avec d'autres Outils et Langages (Power Bi, Python, Big Query, Duck DB"
      ],
      "course_content": {
        "Introduction au SQL et aux bases de données": [
          "Qu'est-ce que le SQL ?",
          "L'histoire du SQL",
          "Le SQL et le marché de l'emploi",
          "Différences entre le SQL et le NoSQL",
          "Quiz Introduction au SQL"
        ],
        "Installation et découverte de l'environnement de travail": [
          "SQL Server, MySQL, PostgreSQL...quelles sont les différences ?",
          "IMPORTANT ! Gestion des erreurs à l'installation",
          "Présentation de la base de données AdventureWorks",
          "Installation de l'environnement de travail",
          "Présentation de PG Admin",
          "Quiz"
        ],
        "Les bases du langage SQL": [
          "La requête SELECT",
          "Entrainement à la requête SELECT",
          "SELECT DISTINCT",
          "Exercices SELECT et SELECT DISTINCT",
          "Les filtres WHERE",
          "Les filtres WHERE - Démonstration",
          "Exercices filtre WHERE",
          "Les filtres combinés",
          "Les filtres combinés démonstration",
          "Exercices filtres combinés",
          "Les filtres avancés",
          "Exercices filtres avancés",
          "Les filtres LIKE et ILIKE",
          "Exercices filtres LIKE",
          "Quiz filtres",
          "ORDER BY et LIMIT",
          "Exercices SORT BY et LIMIT",
          "GROUP BY, HAVING et les Alias",
          "GROUP BY démonstration",
          "Exercices GROUP BY",
          "Les expressions conditionnelles",
          "Les expressions conditionnelles - démonstration",
          "Quiz LIMIT, GROUP BY, CASE"
        ],
        "Les jointures (JOIN)": [
          "Qu'est-ce qu'une jointure ?",
          "INNER JOIN",
          "Exercices INNER JOIN",
          "LEFT /RIGHT JOIN et OUTER JOIN",
          "LEFT/RIGHT JOIN et OUTER JOIN - démonstration",
          "LEFT/RIGHT JOIN et OUTER JOIN - Exercice",
          "SELF JOIN",
          "Quiz sur les jointures"
        ],
        "Conception de base de données": [
          "Disclaimer",
          "Clés primaires et clés étrangères",
          "Les formes normales et la normalisation",
          "Quiz clé primaires/étrangères et normalisation",
          "Les typologies de bases de données relationnelles",
          "Quiz les typologies de bases de données relationnelles",
          "Les types de données possibles",
          "Quiz les types de données possibles",
          "Créer une base de données",
          "Créer une table de données",
          "Ajouter des contraintes - partie 1",
          "Exercices sur la création de base de données",
          "Les contraintes - Partie 2",
          "Insertion de données",
          "Exercice insertion de données",
          "Modifier une base de données",
          "Modifier les valeurs d'une table",
          "Supprimer les éléments d'une base de données",
          "Démonstration - modification et suppression dans une base de données",
          "Exercice - modification et suppression dans une base de données",
          "Quiz création de base de données"
        ],
        "Les fonctions": [
          "Qu'est-ce qu'une fonction ?",
          "Les fonctions texte",
          "Les expressions régulières (Regex)",
          "Exercices string / Regex",
          "Les fonctions numériques",
          "Exercices fonction numérique",
          "Les fonctions de dates",
          "Exercice - Les fonctions de dates",
          "Les fonctions JSON"
        ],
        "Les sous-requêtes et les vues": [
          "Les sous-requêtes",
          "Les sous-requêtes corrélées",
          "Les sous-requêtes - Exercice",
          "les vues",
          "les vues - exercice"
        ],
        "Les fonctionnalités avancées": [
          "optimisation par indexation",
          "Les procédures stockées",
          "Les triggers",
          "Les procedures et triggers - Exercices",
          "Gestion des droits d'accès",
          "Les transactions ACID",
          "Quiz fonctionnalités avancées"
        ],
        "SQL et Python": [
          "Introduction au Python",
          "Prise en main d'un Notebook Python",
          "Execution de requêtes SQL dans un environnement Python",
          "Data vizualisation avec Python",
          "Manipulation de données avec Pandas"
        ],
        "Découverte de la solution Cloud Big Query": [
          "Qu'est-ce qu'une solution cloud ?",
          "Découverte de Big Query",
          "import et analyse de données avec Big Query",
          "Création d'un dashboard Looker"
        ]
      },
      "requirements": [
        "Aucun prérequis nécessaire !"
      ],
      "description": "bonjour  à tous ! Vous avez soif d'apprendre le SQL de manière approfondie ? Vous êtes exactement là où il faut être !\n\n\nSQL, c'est LE langage incontournable dans le monde de la data. Que vous soyez déjà un expert ou un pur débutant, maîtriser SQL, c'est ouvrir la porte à d'innombrables opportunités professionnelles.\n\n\nJe suis Sébastien, consultant en Data Analytics depuis 8 ans. J'ai formé des milliers d'étudiants sur des outils comme Excel, Power BI, Python et bien sûr, la data science.\n\n\nDans ce cours de 17 heures, je vous emmène dans un voyage passionnant :\nD'abord, les bases du SQL et la compréhension des bases de données.\nEnsuite, l'art de l'analyse de données avec des requêtes.\nLa création d'une base de données à partir de zéro.\nUne exploration des fonctions SQL.\nEt pour les plus avancés, nous plongerons dans des sujets comme les vues, les sous-requêtes, et bien plus encore.\nMais attendez, ce n'est pas tout ! Nous allons aussi voir comment :\nIntégrer SQL avec Python.\nExplorer des bases de données avec Big Query.\nCréer des rapports époustouflants avec SQL et Power BI.\nEt pour les curieux, nous explorerons DUCKDB, une tendance montante.\nIci, pas de théorie ennuyeuse ! Vous allez travailler sur des cas concrets, suivre mes manipulations en temps réel, relever des défis avec des exercices et tester vos connaissances avec des QCM.\nAlors, prêts à booster vos compétences en SQL ? Rejoignez moi dès maintenant pour les premières sessions de ce cours !",
      "target_audience": [
        "Étudiants en Informatique/Data Science",
        "Analyste",
        "Développeurs Web et Logiciels",
        "Marketeurs",
        "Chefs de Projet IT",
        "Professionnels en reconversion",
        "Entrepreneurs et Start-uppers",
        "Consultants en gestion"
      ]
    },
    {
      "title": "R komplett: Data Science, Machine Learning & Neuronale Netze",
      "url": "https://www.udemy.com/course/r-komplett/",
      "bio": "R vom Anfänger zum Profi: Vektoren, Data Frames, CSV-Dateien verarbeiten, Web-Crawling, Neuronale Netze,...",
      "objectives": [
        "Entwickle eigene Programme mit R",
        "Analysiere und visualisiere Daten",
        "Wende Machine Learning & Deep Learning an und mache Vorhersagen",
        "Schreibe ein Neuronales Netz",
        "Erstelle überzeugende PDF-Reports",
        "Lese CSV-Dateien ein und werte sie aus",
        "Extrahiere Daten aus Webseiten (Web-Crawling)"
      ],
      "course_content": {
        "Einleitung": [
          "Einleitung",
          "[Wichtig]: Kursmaterialien zum Download",
          "[Hinweis]: Installation Rtools",
          "Installation der benötigten Tools",
          "Von der Console bis hin zum ersten R Script"
        ],
        "Erste Schritte": [
          "Ausblick: Was erwartet dich in diesem Abschnitt?",
          "Variablen in R",
          "Zahlen in R",
          "Zeichenketten in R (Teil 1)",
          "Zeichenketten in R (Teil 2)",
          "Zeichenketten in R (Teil 3)",
          "Hinweis: Aufgabe Strings",
          "Aufgabe Strings + Musterlösung",
          "Hinweis: Variablen im Editor (R Session)",
          "R Console vs. R Script",
          "Wahr-/Falsch-Werte speichern (Booleans)",
          "Variablentypen umwandeln",
          "Eingaben einlesen: Der readline-Befehl",
          "Aufgabe: Readline",
          "Musterlösung: Readline"
        ],
        "So funktioniert R: Vektoren": [
          "Einführung: Vektoren (Teil 1)",
          "Einführung: Vektoren (Teil 2)",
          "Auf einzelne Elemente zugreifen",
          "Vektoren und paste(): Ausgaben generieren",
          "Vektoren erstellen",
          "Vektoren verändern",
          "Wichtige Funktionen für Vektoren",
          "Beispiel: Teilnehmerliste",
          "Auf Elemente zugreifen: Logical Indexing",
          "Aufgabe: Vektoren",
          "Musterlösung: Vektoren",
          "Beispiel: Daten plotten, Grafik erstellen (Teil 1)",
          "Beispiel: Daten plotten, Grafik erstellen (Teil 2)"
        ],
        "Echte Daten einlesen: Listen, Matritzen und DataFrames": [
          "Einführung: Listen",
          "Elemente benennen",
          "Einführung: Matritzen",
          "Matritzen erstellen: rbind() und cbind()",
          "Dimensionen benennen: dimnames",
          "Auf Elemente einer Matrix zugreifen",
          "Einführung: DataFrames",
          "DataFrames einlesen (Teil 1)",
          "DataFrames einlesen (Teil 2)",
          "Auf ein DataFrame zugreifen",
          "Weitere Operationen",
          "Factor erstellen",
          "Factor verwalten",
          "Factor & DataFrame",
          "Aufgabe: DataFrame",
          "Musterlösung: DataFrame"
        ],
        "Programmfluss steuern: Kontrollstrukturen": [
          "Eine erste if-Abfrage",
          "Logicals miteinander verknüpfen",
          "Berechnungen mit Logicals",
          "Der ifelse-Befehl",
          "Der ifelse-Befehl (Beispiel)",
          "Die for-Schleife",
          "Die while-Schleife",
          "For-Schleife und DataFrame",
          "Aufgabe Kontrollstrukturen & Musterlösung"
        ],
        "Daten einlesen: DataTable": [
          "Einführung: DataTable",
          "Bonus: Installation unter Mac",
          "Nach Zeilen filtern",
          "Spalten verändern (Teil 1)",
          "Spalten verändern (Teil 2)",
          "Daten gruppieren (Teil 1)",
          "Daten gruppieren (Teil 2)",
          "Daten sortieren",
          "Unique - Einzigartige Daten finden",
          "Spalten umbenennen",
          "Aufgabe: DataTable",
          "Musterlösung: DataTable",
          "Bonus: Excel-Dateien einlesen"
        ],
        "Daten auswerten & Grafiken erstellen": [
          "Einführung: Daten auswerten & Grafiken erstellen",
          "Der qplot()-Befehl",
          "Punktediagramme zeichnen (Teil 1)",
          "Punktediagramme zeichnen (Teil 2)",
          "Expertenwissen: Punktediagramme zeichnen (Teil 3)",
          "Expertenwissen: Wie funktioniert das Plotten intern",
          "Grafiken beschriften",
          "Mehrere Grafiken zeichnen",
          "Optionales Expertenwissen: Der vars() und aes()-Befehl",
          "Daten beschriften (Punktediagramm)",
          "Daten beschriften (manuell)",
          "Expertenwissen: Daten beschriften",
          "Barplots erstellen",
          "Histogramme erstellen",
          "Grafiken exportieren",
          "Aufgabe: Grafik erstellen",
          "Musterlösung: Grafik erstellen",
          "Hinweis: Coronavirus-Projekt"
        ],
        "Bonus: Karten erstellen": [
          "Einführung: Karten erstellen",
          "Punkte auf Karte einzeichnen",
          "Kartenbereich einschränken",
          "Länder einfärben",
          "Daten zusammenführen (Teil 1)",
          "Daten zusammenführen (Teil 2)",
          "Aufgabe: Ausbreitung von Ebola visualisieren",
          "Musterlösung: Ausbreitung von Ebola visualisieren"
        ],
        "Code modularisieren: Funktionen": [
          "Einführung: Funktionen",
          "Parameter übergeben",
          "Standardwerte festlegen",
          "Rückgabewerte",
          "Gültigkeit (scope) von Variablen (Teil 1)",
          "Gültigkeit (scope) von Variablen (Teil 2)",
          "Expertenwissen: Scope von Variablen",
          "Aufgabe + Lösung: Funktionen",
          "Die sapply()-Funktion",
          "Die lapply()-Funktion",
          "DataTables und sapply()"
        ],
        "Zeichenketten analysieren / Daten aus Strings extrahieren: Reguläre Ausdrücke": [
          "Einführung: Stringr",
          "Erste Schritte",
          "Weitere Stringr-Funktionen",
          "Hinweis: Verwendung von str_view_all",
          "Ein erster regulärer Ausdruck",
          "Reguläre Ausdrücke: Zeichen wiederholen",
          "Reguläre Ausdrücke: Weitere Steuerzeichen",
          "Reguläre Ausdrücke: Alternative Elemente",
          "Reguläre Ausdrücke: Weitere Spezialzeichen",
          "Reguläre Ausdrücke: Gruppieren",
          "Mit regulären Ausdrücken Werte suchen",
          "Datumswerte extrahieren + Aufgabe",
          "Musterlösung: E-Mail-Adressen extrahieren (Teil 1)",
          "Musterlösung: E-Mail-Adressen extrahieren (Teil 2)",
          "Musterlösung: Telefonnummern extrahieren"
        ]
      },
      "requirements": [
        "Programmierkenntnisse sind vorteilhaft, aber nicht notwendig",
        "Alle benötigten Tools (R, RStudio, RTools) werden wir gemeinsam bei dir installieren"
      ],
      "description": "Werde zum gefragten Data-Science-Spezialisten mit R!\nData-Science-Experten sind nicht nur gefragt wie nie, sie bekommen auch ein überdurchschnittliches Gehalt (laut Indeed Jobbörse). Diesen Kurs habe ich entwickelt, um dir den bestmöglichen Einstieg zu bieten.\nR ist eine unglaublich mächtige und effiziente Sprache, sowohl ob für Data Science als auch Machine Learning. Leider ist der Einstieg allerdings oft sehr trocken - nicht aber in diesem Kurs, alle Themen lernst du Schritt für Schritt und am Beispiel.\n=> \"Wie auch bei Jannis' anderen Kursen ist alles top! Gute step by step Introduction.\" (★★★★★, Markus Dunkel)\nBesonders viele Übungen + Beispiele:\nIn diesem Kurs werden alle Themen anschaulich erklärt - du analysierst Geburtsstatistiken & echte Gehälter aus San Francisco, erstellst ein Modell für Diabetes, extrahierst Raketenstarts aus einer Webseite (Web-Crawling) oder visualisierst in einer Grafik die Ausbreitung von Ebola bzw. dem Coronavirus.\nSchritt für Schritt lernst du also alles was du zum Thema R wissen musst - und zwar nicht nur die Sprache selbst, sondern auch alle wichtigen Tools drumherum, und wie R angewandt wird. Dadurch kannst du das Wissen aus dem Kurs sofort anwenden.\nMit über 200+ HD-Videos und mehr als 23 Stunden Videomaterial ist dies der umfangreichste Data-Science Kurs mit R auf Udemy.\nWas lernst du alles?\nR Grundlagen:\nRStudio (unsere Entwicklungsumgebung)\nFunktionen\nVariablen,...\nData Science:\nLese Daten ein\nErstelle anschauliche Visualisierungen\nÜberzeuge deine Kollegen durch überzeugende PDF-Reports\nDiverse Beispiele!\nMachine Learning mit caret:\nRegression\nKlassifizierung\nDaten aus Text extrahieren (Natural Language Processing)\nDiverse Beispiele!\nDeep Learning:\nTrainiere ein einfaches Neuronales Netz\nNach Abschluss des Kurses bist du in der Lage, Daten auszuwerten, Machine-Learning-Modelle zu trainieren, überzeugende PDF-Reports zu erstellen und Daten aus Webseiten zu extrahieren. Das sind genau die Fähigkeiten, die du als Data-Scientist beherrschen musst.\nKurz: Nach Abschluss dieses Kurses beherrscht du nicht nur R, sondern auch Data-Science und Machine Learning - sowohl für eigene Analysen, als auch für einen Job als Data-Scientist.",
      "target_audience": [
        "Du möchtest mit R Daten auswerten und Machine-Learning-Modelle analysieren"
      ]
    },
    {
      "title": "The New Future with Ai Basic understanding & Ethics",
      "url": "https://www.udemy.com/course/the-new-future-with-ai-basic-understanding-ethics/",
      "bio": "Get a good basic understanding of A.i. & Robotics, without being into software programming. This is really for everyone.",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Deep learning Ai - A basic overview of how it works",
          "Robotics & Future Society and under standing the \"Hardware side of things\"",
          "Ai - Get a basic understanding of Ai's capacity, the ethics & impact on jobs",
          "The New Economic landscape with Robotics and Ai",
          "What You can do to help shape a bright future with Ai and Robotics"
        ]
      },
      "requirements": [
        "No programming skills needed. I use everyday language and simple concepts."
      ],
      "description": "The 4th industrial revolution is approaching and it can be a new golden age if we manage it right and safely.\nThere are some philosophical question to address and also some practical implications we will discuss.\nMany jobs might dissappear and some new will be created such as humans supervising A.i. to do quality checks on the work of the A.i.\nWe are at the extremely special point in time where humanity transitions from biological intelligence to digital intelligence and a robotic workforce. I will go through what it will mean to our daily lives, the economy, jobs, income, production and property law. All done with a positive attitude but also a healthy sense of caution.\nI have put in a lot of work creating this course and I truly hope it will help bring a useful and exciting perspective on the future.\nAt this point everyone should consider what the future could look like with A.i. and what can be done to get there the best way.\nThe neural network progress is substantial and this is a historic moment where we have to pay extra attention.\nOverview:\nThis is intended for everyone who cares about our future with Ai and Robotics. No programming skills needed. I use everyday language and simple concepts.\nEach video includes small exercises and thought experiments to help expand your understanding of A.i. and Robotics.\nLearn how the World is going to be different and how we could make it the best ever with good Ethics.\nUnderstand the full power of Ai with simple examples.\nUnderstand the surprising Robotics production growth model.\nTake part in Q & A where you can get feedback on your thoughts and questions related to the course.",
      "target_audience": [
        "This is intended for everyone who cares about our future with Ai and Robotics"
      ]
    },
    {
      "title": "Tree-Based Modeling with R: Bank Loan Default Prediction",
      "url": "https://www.udemy.com/course/decision-trees-using-r-bank-loan-default-prediction/",
      "bio": "Learn tree-based modeling techniques with R to predict bank loan defaults, data cleaning to confusion matrix analysis!",
      "objectives": [],
      "course_content": {},
      "requirements": [
        "Basic understanding of R programming.",
        "Familiarity with fundamental statistics and data analysis concepts.",
        "Interest in predictive modeling and machine learning applications."
      ],
      "description": "Introduction:\nTree-based modeling is one of the most powerful and interpretable machine learning techniques. In this course, you’ll dive into decision trees and their application in predicting bank loan defaults using R. From understanding the problem to implementing and evaluating models, this course equips you with the skills to solve real-world business challenges.\nSection-Wise Writeup:\nSection 1: Understanding Tree-Based Models\nThis section introduces the fundamentals of tree-based modeling, with a special focus on decision trees. You’ll learn the underlying principles of decision trees and their relevance in solving classification problems.\nSection 2: Introduction to the Bank Loan Default Prediction Problem\nExplore the concept of bank loan default prediction and its significance in the financial sector. This section provides an overview of the problem, including the questions to be addressed and the R code framework used for modeling.\nSection 3: Data Preparation and Modeling\nLearn how to set up your environment for tree-based modeling. In this section, you’ll:\nInstall the necessary R packages.\nLoad and clean the dataset.\nSplit the data into training and testing sets.\nDevelop the prediction model using R.\nFinally, you’ll evaluate the model’s performance using a confusion matrix to interpret results effectively.\nSection 4: Conclusion and Next Steps\nSummarize the key takeaways from the course. This section will also guide you on extending your knowledge to more advanced tree-based techniques, like random forests or gradient boosting.\nConclusion:\nBy the end of this course, you will have a strong understanding of tree-based modeling and the ability to predict bank loan defaults using R. You’ll also gain the skills to preprocess data, build accurate models, and evaluate their effectiveness in real-world scenarios.",
      "target_audience": [
        "Beginners looking to learn predictive modeling using R.",
        "Data analysts and data scientists interested in financial sector use cases.",
        "Students and professionals aiming to enhance their machine learning skills.",
        "Anyone curious about tree-based modeling techniques for classification problems."
      ]
    },
    {
      "title": "Pythonによる教育データ分析入門：Pythonの基礎から回帰分析・項目分析まで",
      "url": "https://www.udemy.com/course/intro_educational_data_analysis_with_python/",
      "bio": "本コースは、様々なビジネスシーンでも活用しやすい回帰分析をはじめ、Pythonを用いた複数の分析手法を習得します。識別力指標としての点双列相関、信頼性係数を求め、項目困難度と組合わせた分析を行います。分析結果の可視化にも挑戦します。",
      "objectives": [
        "Pythonの基礎を学習することができます。",
        "Pythonを用いて教育に関するデータやアンケートの分析を行います。",
        "日本語（言葉）や数式で記述されたものをコード（Python）で記述するスキルを身に着けることができます。",
        "Pythonによる基本的な統計量の算出を行います。",
        "Pythonによるデータの可視化を学習し、グラフの描画を行います。",
        "Pandasを使用したデータ処理を学習します。",
        "「平均への回帰」を考慮したテストの分析を実施します。",
        "Anacondaのインストール方法を簡単に説明します。",
        "Jupyter Notebookの基本的な使い方を理解することができます。"
      ],
      "course_content": {
        "はじめに": [
          "はじめに",
          "Pythonのインストール",
          "Jupyterを使う"
        ],
        "Pythonの基礎1": [
          "このセクションの概要",
          "数値演算と変数",
          "変数への代入と演算",
          "リストの作成とリストの操作",
          "リストの要素とそのアクセス",
          "このセクションのまとめ",
          "練習問題",
          "練習問題の解答&解説"
        ],
        "Pythonの基礎2": [
          "このセクションの概要",
          "比較演算子と論理演算子",
          "if文",
          "for文とwhile文",
          "for文とrange()",
          "例外処理",
          "このセクションのまとめ",
          "練習問題",
          "練習問題の解答&解説"
        ],
        "基本的な統計量と標準化": [
          "このセクションの概要",
          "パッケージと関数の定義",
          "ヒストグラムと代表値",
          "分散と標準偏差",
          "標準得点と偏差値",
          "共分散と相関係数",
          "このセクションのまとめ",
          "練習問題",
          "練習問題の解答&解説"
        ],
        "グラフの描画": [
          "このセクションの概要",
          "グラフ描画の基本",
          "グラフの体裁",
          "箱ひげ図と散布図",
          "このセクションのまとめ",
          "練習問題",
          "練習問題の解答&解説"
        ],
        "回帰分析": [
          "このセクションの概要",
          "リスト以外のデータ構造",
          "ファイルの読み込み",
          "回帰分析",
          "このセクションのまとめ",
          "練習問題",
          "練習問題の解答&解説"
        ],
        "Pandas入門1": [
          "このセクションの概要",
          "ファイルの読み込みとデータへのアクセス",
          "基本統計量の算出",
          "条件指定と出力",
          "欠損値と演算",
          "このセクションのまとめ",
          "練習問題",
          "練習問題の解答&解説"
        ],
        "Pandas入門2": [
          "このセクションの概要",
          "Pandasを用いた可視化",
          "Groupbyの使い方",
          "このセクションのまとめ",
          "練習問題",
          "練習問題の解答&解説"
        ],
        "項目分析": [
          "このセクションの概要",
          "項目困難度と識別力",
          "信頼性係数",
          "データフレームの作成",
          "このセクションのまとめ",
          "練習問題",
          "練習問題の解答&解説"
        ],
        "平均への回帰": [
          "このセクションの概要",
          "平均への回帰",
          "練習問題",
          "練習問題の解答&解説（修正版）"
        ]
      },
      "requirements": [
        "複雑な数学の知識は不要です。平均を計算で出したことがある人であれば大丈夫です。",
        "難解な統計の知識は必要ありません。中学校までの数学で十分です。",
        "本コースは、MacOSを使用しています。Windowsをお使いの方でも受講可能です。",
        "本コースでは、Anaconda、Jupyter Notebookを使用します。前述のツールが動作するPCをご用意いただき、講師と同じ動作をして学習を進めていくと、理解度が高まります。"
      ],
      "description": "本コースは、人気のプログラミング言語「Python」を使って、データ分析手法を学習するコースです。\n現在、Pythonはデータ分析からセキュリティまで幅広い分野で活用されており、プログラミング初心者でも学びやすい言語として注目されています。\n\n\n今回はこのPythonを使って、教育データ（テストデータ）とアンケート項目の分析を行います。\n難しい数学や統計学の知識は必要ありません。また、Pythonを使ったことがない人でも大丈夫。\n講師が基礎から丁寧に説明しますので、肩の力を抜いて、学習を進めていきましょう。\n\n\n★このコースの学び方★\n\n\n本コースは、各セクションごとに「ハンズオン+練習問題+解説」という順番で進みます。\n\n\nまずは、講師のライブコーディングを眺めながら、ハンズオン形式で学習を進めましょう。\nセクションの最後に練習問題が用意されていますので、今度はご自身の力で課題を解いていきましょう。\n最後に、講師が練習問題の解説を行いますので、うまくいかなかった人は、解説を聞いた後にもう一度、練習問題に挑戦してみましょう。\n\n\n★このコースの概要★\n\n\nPythonの基礎\nAnacondaとJupyter Notebookを用いて、基本的なPythonの記述方法について解説します。\n[keyword]\n数値演算、変数、関数とメソッド、リスト作成と操作方法、リストの要素へのアクセス、比較演算子と論理演算子、if文、For文、while文、例外とエラー\n\n\nPythonによる基本的な統計量の算出\nPythonを使って、基本的な統計量を算出します。\nこれから学習を進めていくデータ分析の基礎となる部分ですので、用語・手法をしっかりと理解しましょう。ヒストグラムの説明以降は、連続的に難易度が上がっていきますので、途中で理解が追い付かなくなったら、前のレクチャーに戻って疑問点を解消していきましょう。\n[keyword]\nパッケージ・関数の定義、ヒストグラム、代表値、分散と標準偏差、標準得点と偏差値\n共分散と相関係数\n\n\nPythonによるデータの可視化\n統計量の算出ができるようになったら、生成したデータを可視化しましょう。このセクションでは、matplotlibというライブラリを活用し、ヒストグラムをはじめ、複数のグラフや図表を作成します。\n[keyword]\nヒストグラムと基本的な描画方法、グラフの体裁を整える、箱ひげ図、散布図\n\n\n回帰分析に挑戦\nコースの前半で習得した知識を用いて、回帰分析に挑戦します。\n[keyword]\nリスト以外のデータ構造（セット、タプル、辞書（ディクショナリ）、numpy.ndarray、ファイルの読込、外部から取得したデータの読込、回帰分析\n\n\nPandasを用いたデータの処理\nPythonのデータ解析用ライブラリであるPandasを用いて、データ分析を行います。\nここからがコースの後半戦です。\n[keyword]\nデータの読込み、基本統計量、条件指定、データフレームの作成、欠損値の取り扱い、Pandasを用いた可視化の方法、Groupbyを用いたグルーピング、Good-Poor分析\n\n\nテスト、アンケートの項目分析\nいよいよ、今まで学習した知識を総動員して、テスト・アンケートの項目分析を行います。\n識別力指標としての点双列相関、信頼性係数を求め、項目困難度と組合わせて、項目の性質の分析を行い、データフレームでまとめます。最終的には散布図などを生成し、データの可視化を行います。\n[keyword]\n項目困難度、G-P分析による識別力、識別力指標としての点双列相関、信頼性係数、データフレーム、可視化\n\n\n「平均への回帰」を考慮したテストの分析\n最後は練習問題です。\nこれまでは、皆さんのコーディングに講師が寄り添う形でコースが進められてきました。\nこのセクションでは、講師の助けはもう必要ありません。\n今までの知識と手法を用いて、一人で課題に挑戦してみましょう！\nこれまでの学習が身についていれば、必ずゴールまでたどり着くはずです。",
      "target_audience": [
        "Pythonの基礎を学びたい人",
        "教育データの分析に興味がある人",
        "教育データの分析に興味がある学校・塾の先生",
        "評価、テスト、アンケートの分析に興味がある人",
        "試験データの分析に興味がある企業の人事",
        "アンケート項目を分析し、改善したいと思っている人"
      ]
    },
    {
      "title": "Visão computacional com Python e OpenCV",
      "url": "https://www.udemy.com/course/visao-computacional-com-python-e-opencv/",
      "bio": "Desenvolva programas para manipulação de imagem usando Python e OpenCV.",
      "objectives": [
        "manipulação de imagens",
        "segmentar imagens",
        "técnicas para extração de caracteríticas",
        "Clssificação de imagens"
      ],
      "course_content": {
        "INTRODUÇÃO": [
          "1.1 O que é visão computacional?"
        ],
        "PREPARAÇÃO DO AMBIENTE": [
          "Instalação do Jupyter Notebooks",
          "Link alternativo para os códigos do curso",
          "Grupo do Telegram"
        ],
        "PRÉ-PROCESSAMENTO": [
          "Recursos da Seção",
          "3.1 - Histograma de cores",
          "Questionário sobre histogramas de cores",
          "3.2 - Equalização do histograma",
          "Questionário sobre Equalização do Histograma",
          "3.3 Transformações geométricas",
          "Questionário sobre transformações geométricas",
          "3.4 - Operações aritméticas",
          "Questionário sobre Operações aritméticas",
          "3.5 - Ruídos em imagens",
          "Comparação entre histogramas",
          "Operações Bit a Bit",
          "Operações bit a bit - inclusão automática de assinatura em documento",
          "LUTs - Correção do Gamma"
        ],
        "FILTROS DE SUAVIZAÇÃO": [
          "Recursos da Seção",
          "4 - Filtros de suvização",
          "Questionário sobre filtros de suavização"
        ],
        "FILTROS DE BORDAS": [
          "Recursos da Seção",
          "5 - Filtros de realce",
          "Questionário sobre filtros de bordas",
          "Filtro Cartoon - Aplicação de filtros"
        ],
        "OPERAÇÕES MORFOLÓGICAS": [
          "Recursos da Seção",
          "6 - Operações morfológicas em uma imagem",
          "Questionário sobre gradiente morfológico",
          "Questionário sobre operações morfológicas"
        ],
        "COMANDOS BÁSICOS DE VÍDEO": [
          "Recursos da Seção",
          "7.1 - Comandos básicos com Vídeo",
          "7.2 - Importando um video",
          "7.3 - Selecionando e inserindo um retangulo no vídeo",
          "7.4 - ROI (Região de Interesse de uma Imagem)",
          "7.5 - Remoção de background"
        ],
        "SEGMENTAÇÃO DE OBJETOS": [
          "Recursos da Seção",
          "8.0 - Segmetação de objetos em uma imagem",
          "Questionário sobre segmentação por binarização",
          "8.1 - Transformada de Hough",
          "Questionário sobre segmentação por Otsu",
          "8.2 - Segmentacao de objetos no espaço de cor HSV",
          "Questionário sobre espaço de cor HSV",
          "Componentes Conectados - Teoria",
          "Componentes Conectados - Parte 1",
          "Componentes Conectados - Parte 2",
          "Segmentação por watershed"
        ],
        "EXTRAÇÃO DE CARACTERÍSTICAS": [
          "Recursos da Seção",
          "9.1 - Dimensionais",
          "9.2 - Inerciais",
          "9.3 - Detecção de cantos",
          "9.4 - Template Matching",
          "Template Mathing",
          "9.5 - Template Matching CAPTCHAS"
        ],
        "DETECÇÃO DE MOVIMENTO": [
          "Recursos da Seção",
          "10.0 - Detecção de movimentos"
        ]
      },
      "requirements": [
        "Noções básicas de Python.",
        "Ter conhecimento básico sobre lógica de programação, habilidades em entender e desenvolver códigos em Python.",
        "Vontade de aprender sobre visão computacional."
      ],
      "description": "Esse curso é uma introdução a visão computacional e ao processamento de imagens. A ferramenta usada é o Python3 usando o ambiente jupyter notebook. O curso sempre sofrerá alterações buscando inserir/atualizar novas abordagens e novos códigos, afinal a área de visão computacional sempre terá novas técnicas sendo descobertas ou melhoradas. Tento fazer um tema novo todo mês, ou seja, sempre haverá atualizações no curso.\nA visão computacional procura integrar as áreas de processamento digital de imagens e inteligência artificial, tendo como objetivo a obtenção de algoritmos capazes de interpretar o conteúdo visual de imagens. Suas aplicações estão presentes em diversos segmentos tecnológicos que envolvem análise de imagens, reconhecimento de padrões e controle inteligente, abrangendo múltiplas áreas do conhecimento, tais como agronomia, astronomia, biologia, biometria, medicina e muitas outras. Constitui , portanto, uma área multidisciplinar com muitas aplicações práticas.\nO biblioteca OpenCV é uma biblioteca Free que pode ser usada com o Python. Essa biblioteca é usada principalmente para visão computacional e processamento de imagens . É considerada uma das melhores ferramentas de código aberto que auxilia os desenvolvedores a construir projetos completos e robustos em processamento de imagem, detecção de movimento e segmentação e extração de características em uma imagem.\nSe você é completamente novo no conceito de Visão Computacional ou tem uma compreensão básica disso, este curso será o seu guia para entender os conceitos e algoritmos básicos do OpenCV através de incríveis exemplos.\nComeçando com a instalação do OpenCV em seu sistema e entendendo os fundamentos básicos do processamento de imagens, aplicações de filtro espaciais, realçando bordas com os principais algoritmos já desenvolvidos, operações morfológicas em imagens, fazendo a segmentação da imagem e por último a extração de características.",
      "target_audience": [
        "Esse curso é voltado para alunos de graduação e pós-graduação nos campos de tecnologia, engenharia, ciência da computação e afins.",
        "Pessoas que buscam o primeiro contato prático com o desenvolvimento de sistemas de visão computacional e processamento de imagens."
      ]
    },
    {
      "title": "Introducción a Python desde cero",
      "url": "https://www.udemy.com/course/python-para-todos/",
      "bio": "Aprende Python desde cero con un enfoque en Data y Analytics en Google Colaboratory",
      "objectives": [
        "El lenguaje de programación Python desde cero con un enfoque en Data y Analytics.",
        "Aprenderás a usar Google Colab, Tipos de variables, Listas, Tuplas, Diccionarios, Bucles, Funciones, Pandas y Numpy"
      ],
      "course_content": {
        "1. Introducción a Google Colab": [
          "1.1 Dudas, preguntas y consultas",
          "Notebooks y Datasets",
          "1.2. Creando tu primer notebook en Google Colab",
          "1.3. Tipos de Celda",
          "1.4. Manejando Títulos y Comentarios"
        ],
        "2. Tipos de Variables": [
          "2.1 ¿Qué son las variables numéricas?",
          "2.2 Casteo de Variables Numéricas",
          "2.3 Operadores de Variables Numéricas",
          "2.4 ¿Cómo funciona el operador orden en variables numéricas?",
          "2.5 Variables Booleanas",
          "2.6 Operadores de comparación en Variables Booleanas",
          "2.7. Operadores de combinación en Variables Booleanas",
          "2.8. Variables String",
          "2.9. Operadores de Variables String",
          "2.10. Más operadores de Variables String",
          "2.11. Ingresar valores a un String con INPUT",
          "2.12. Ejercicio: Monto por préstamo",
          "2.13. Ejercicio: Segundos por semana"
        ],
        "3. Manejo de Listas": [
          "3.1. Creación de Listas",
          "3.2. Índices",
          "3.3. Slicing",
          "3.4. Operaciones con Listas",
          "3.5. Funciones Len, Append e Insert",
          "3.6. Funciones Pop, Remove",
          "3.7. Funciones Reemplazar, Sort y Reverse",
          "3.8. Funciones Sum, Min y Max",
          "3.9. Listas de Strings",
          "3.10. Inmutabilidad en Listas de Strings",
          "Valida tu aprendizaje"
        ],
        "4. Manejo de Tuplas y Sets": [
          "4.1. Definición",
          "4.2. Inmutabilidad",
          "4.3. Generación",
          "4.4. Casteo",
          "4.5. Asignación Múltiple",
          "4.6. Operaciones con Sets"
        ],
        "5. Diccionarios": [
          "5.1. Definición",
          "5.2. Get",
          "5.3. Eliminar y actualizar",
          "5.4. Key Values, Items",
          "5.5. Update"
        ],
        "6. Estructura de Control de Flujos": [
          "6.1. Introducción a Control de Flujo",
          "6.2. Estructura de control if",
          "6.3. Estructura de control if, else",
          "6.4. Estructura de control if, elif y else",
          "6.5. Ejemplos if, elif y else",
          "6.6. Caso Babyboomers",
          "6.7. If, else anidados",
          "6.8. Ejemplos if, else anidados",
          "6.9. Caso Años bisiestos",
          "6.10. Solución caso de años bisiestos",
          "6.11. Caso palíndromos",
          "Valida tu aprendizaje"
        ],
        "7. Bucles": [
          "7.1. Introducción a los Bucles en Python",
          "7.2. While",
          "7.3. While, bucles infinitos",
          "7.4. While, flags salida 1",
          "7.5. While flags salida 2",
          "7.6. While break",
          "7.7 While continue",
          "7.8. Caso blackjack",
          "7.9. Desarrollo caso Blackjack",
          "7.10. Desarrollo caso Blackjack 2",
          "7.11. Desarrollo caso Blackjack 3",
          "7.12. Bucle for",
          "7.13. For zip",
          "7.14. For range",
          "7.15.1 For compresion - Listas",
          "7.15.2 For Comprensión Diccionarios",
          "7.16. For enumerate",
          "7.17. Ejemplo: for cubos",
          "7.18. Ejemplo: for números primos",
          "7.19. Ejemplo: factorial"
        ],
        "8. Funciones": [
          "8.1. Creando funciones",
          "8.2. Variables locales y globales",
          "8.3. Funciones, return",
          "8.4. Return, unpacking",
          "8.5. Return, none",
          "8.6. Ejemplo número primos",
          "8.7. Ejemplo lista de números",
          "8.8. Parámetros de una función",
          "8.9. Parámetros con valores por defectos",
          "8.10. Parámetros args",
          "8.11. Parámetros kwargs",
          "8.12. Funciones lambda",
          "8.13. Comentarios",
          "8.14. map-filter-reduce",
          "8.15. Filter",
          "8.16. Reduce",
          "8.17. Import",
          "8.18. Ejercicio pangrams",
          "8.19. Ejercicio pangrams, solución",
          "8.20. Ejercicio números perfectos",
          "8.21. Ejercicio números perfectos, solución"
        ],
        "9. Manejo de arreglos y matrices con Numpy": [
          "9.1. Introducción a Numpy",
          "9.2. Import Numpy",
          "9.3. Array",
          "9.4. Suma, producto, max y min",
          "9.5. Operaciones vectorizadas",
          "9.6. Operaciones Vectoriales",
          "9.7. Suma y multiplicación de listas",
          "9.8. Comparación de tiempos",
          "9.9. Ones, zeros, arange y linspace",
          "9.10. Arreglos multidimensionales",
          "9.11. Atributos Numpy: shade, ndim y size",
          "9.12. Atributos, métodos y funciones",
          "9.13. Indexado",
          "9.14. Slicing de Numpy arrays",
          "9.15. Axis",
          "Valida tu aprendizaje"
        ],
        "10. Análisis de Datos con Pandas": [
          "10.1. Presentación de Pandas",
          "10.2. Dataframe, series e índices",
          "10.3. Series",
          "10.4. Columnas e índices",
          "10.5. Crear columnas, Brodcasting",
          "10.6. Seleccionar, reordenar y eliminar columnas",
          "10.7. Agregar y eliminar filas",
          "10.8. Lectura de fuentes de datos, drive y montar",
          "10.9. Lectura de archivos",
          "10.10. Lectura HTML",
          "10.11. Exportar resultados",
          "10.12. Head, info y describe",
          "10.13. Operaciones con columnas",
          "10.14 Apply",
          "10.15. Filtros, loc",
          "10.16. Sort, values",
          "10.17. Group by",
          "10.18. Plot"
        ]
      },
      "requirements": [
        "No, ninguno. Incluso puedes hacer los ejercicios desde tu celular gracias a Google Colab."
      ],
      "description": "En este curso está dirigido para todas las personas que quieren aprender de este maravilloso y útil lenguaje de programación. Empezaremos con los conceptos básicos, desarrollando ejemplos simples (y no no son los de Iris ni de Titanic ;) ) que permitan a los estudiantes tener un acercamiento amigable resolviendo situaciones reales. Si siempre quisiste aprender a programar en Python esta es tu oportunidad de hacerlo a tu propio ritmo y sin instalar nada.\n\n\nEn este curso veremos 11 módulos con los que, una vez finalizado el curso, podrás manejar Python sin problemas para hacer análisis de datos por tu cuenta o incluso armar tus propios proyectos y/o aplicaciones con Python. Empezaremos familiarizándonos con Google Colab, lo que será nuestro entorno de trabajo para que así no tengas que instalar absolutamente nada. Luego veremos los tipos de variables que existen en Python para pasar al manejo de listas, tuplas y sets para el análisis de datos. Después estaremos revisando el tema de diccionarios para pasar al control de flujos y bucles. Más adelante veremos cómo implementar funciones en Data, el manejo de matrices y arreglos con Numpy y el manejo de la librería de Pandas para el análisis de Datos para terminar con un proyecto final.",
      "target_audience": [
        "Todo aquel que quiera iniciar en el mundo de los datos =)"
      ]
    },
    {
      "title": "机器学习 A-Z (Machine Learning A-Z in Chinese)",
      "url": "https://www.udemy.com/course/machinelearningchinese/",
      "bio": "全面建立机器学习的知识架构，并且在Python和R里构建不同的机器学习模型。课程内容包括所有的代码模板。",
      "objectives": [
        "完全掌握机器学习及在Python和R里的应用",
        "深刻理解各种机器学习的模型",
        "做出准确的预测和强大的分析",
        "利用机器学习创造更多价值",
        "利用机器学习解决私人问题",
        "掌握并熟练处理强大的算法，例如强化学习，自然语言处理，还有深度学习",
        "掌握并熟练处理先进的技术，例如对降低数据维度",
        "了解对不同的问题怎样选择合适的机器学习模型",
        "建立起强大的机器学习知识架构，并且知道如何创建和运用不同的模型来解决任何问题",
        "Master Machine Learning on Python & R",
        "Have a great intuition of many Machine Learning models",
        "Make accurate predictions and powerful analysis",
        "Make robust Machine Learning models",
        "Create strong added value to your business",
        "Use Machine Learning for personal purpose",
        "Handle specific topics like Reinforcement Learning, NLP and Deep Learning",
        "Handle advanced techniques like Dimensionality Reduction",
        "Know which Machine Learning model to choose for each type of problem",
        "Build an army of powerful Machine Learning models and know how to combine them to solve any problem"
      ],
      "course_content": {},
      "requirements": [
        "高中数学知识即可",
        "Just some high school mathematics level."
      ],
      "description": "想了解机器学习？这门课程为您订做！\n这门课程是英文课程Machine Learning A-Z的翻译和再创造。原版英文课程是Udemy上最畅销的机器学习课程。您在这门课里，会用深入浅出的方法学会复杂的模型，算法，还有基础的编程语句。\n我们会手把手地教会您机器学习。每一节课都会让您获得新的知识，完备机器学习的知识架构，在享受机器学习的同时对这个领域有更深的理解。\n这门课程十分有趣，包含了机器学习的方方面面。课程结构如下：\n第一部分 - 数据预处理\n第二部分 - 回归：简单线性回归，多元线性回归，多项式回归\n第三部分 - 分类：逻辑回归，支持向量机（SVM），核函数与支持向量机（Kernel SVM），朴素贝叶斯，决策树分类，随机森林分类\n第四部分 - 聚类：K-平均聚类分析\n第五部分 - 关联规则学习：先验算法\n第六部分 (待更新) - 强化学习：置信区间上界算法（UCB），Thompson抽样算法\n第七部分 (待更新) - 自然语言处理 ：自然语言处理算法\n第八部分 (待更新) - 深度学习：人工神经网络，卷积神经网络\n第九部分 (待更新) - 降维（Dimensionality Reduction）：主成分分析 （PCA），核函数主成分分析（Kernel PCA）\n第十部分 (待更新) - 模型选择：模型选择，极端梯度上升\n对于每个模型，除了学会理论基础之外，您还会学习如何将这些模型运用到各种实际生活的案例里，并且课程也包括Python和R的代码模板，您可以下载并且直接将代码运用到您自己的项目里。\n\n\nInterested in the field of Machine Learning? Then this course is for you!\nThis course has been designed by two professional Data Scientists so that we can share our knowledge and help you learn complex theory, algorithms and coding libraries in a simple way.\nWe will walk you step-by-step into the World of Machine Learning. With every tutorial you will develop new skills and improve your understanding of this challenging yet lucrative sub-field of Data Science.\nThis course is fun and exciting, but at the same time we dive deep into Machine Learning. It is structured the following way:\nPart 1 - Data Preprocessing\nPart 2 - Regression: Simple Linear Regression, Multiple Linear Regression, Polynomial Regression\nPart 3 - Classification: Logistic Regression, SVM, Kernel SVM, Naive Bayes, Decision Tree Classification, Random Forest Classification\nPart 4 - Clustering: K-Means\nPart 5 - Association Rule Learning: Apriori\nPart 6 - Reinforcement Learning: Upper Confidence Bound, Thompson Sampling\nPart 7 - Natural Language Processing: Bag-of-words model and algorithms for NLP\nPart 8 - Deep Learning: Artificial Neural Networks, Convolutional Neural Networks\nPart 9 - Dimensionality Reduction: PCA, Kernel PCA\nPart 10 - Model Selection & Boosting: k-fold Cross Validation, Grid Search.\nMoreover, the course is packed with practical exercises which are based on real-life examples. So not only will you learn the theory, but you will also get some hands-on practice building your own models.\nAnd as a bonus, this course includes both Python and R code templates which you can download and use on your own projects.",
      "target_audience": [
        "所有对机器学习感兴趣的人",
        "任何有高中数学知识并且想开始学习机器学习的学生",
        "任何有机器学习基本知识并想了解更多这个领域的人",
        "任何不太了解编程但对机器学习感兴趣，并希望将机器学习应用在数据上的人",
        "任何想进入数据科学领域的大学生",
        "任何想提高机器学习技能的数据分析师",
        "任何对目前工作不满意并想成为数据科学家的人",
        "任何希望运用强大的机器学习工具扩大自己事业的人",
        "Anyone interested in Machine Learning.",
        "Students who have at least high school knowledge in math and who want to start learning Machine Learning.",
        "Any intermediate level people who know the basics of machine learning, including the classical algorithms like linear regression or logistic regression, but who want to learn more about it and explore all the different fields of Machine Learning.",
        "Any people who are not that comfortable with coding but who are interested in Machine Learning and want to apply it easily on datasets.",
        "Any students in college who want to start a career in Data Science.",
        "Any data analysts who want to level up in Machine Learning.",
        "Any people who are not satisfied with their job and who want to become a Data Scientist.",
        "Any people who want to create added value to their business by using powerful Machine Learning tools."
      ]
    },
    {
      "title": "TensorFlow. Curso de TensorFlow para Deep Learning y Python",
      "url": "https://www.udemy.com/course/curso-de-tensorflow-para-deep-learning-y-python/",
      "bio": "Aprende a usar TensorFlow, el framework de Google para Deep Learning con Python",
      "objectives": [
        "Entender cómo funcionan las redes neuronales",
        "Utilizar TensorFlow para tareas de Regresión y Clasificación",
        "Utilizar TensorFlow para resolver problemas de series temporales",
        "Usar TensorFlow para resolver problemas de clasificación de imágenes",
        "Aprender sobre redes neuronales convolucionales mediante ejemplos con Python",
        "Aprender sobre redes neuronales recurrentes mediante ejemplos con Python",
        "Conocer algunas bibliotecas contruidas sobre TensorFlow, como Estimator API y Keras"
      ],
      "course_content": {
        "Introducción": [
          "Introducción"
        ],
        "Machine Learning o aprendizaje de máquinas": [
          "Introducción al Machine Learning"
        ],
        "Instalación del entorno de trabajo": [
          "Instalacion del entorno de trabajo para hacer pruebas",
          "Activar el entorno para hacer pruebas"
        ],
        "Curso básico de Python": [
          "NumPy",
          "Pandas",
          "Matplotlib - visualización de datos",
          "SciKit Learn"
        ],
        "Redes neuronales o Deep Learning": [
          "Neuronas y perceptrones",
          "Funciones de activación",
          "Funciones de coste",
          "Algoritmo del Gradiente Descendiente",
          "Practicar con una red neuronal en un navegador web"
        ],
        "TensorFlow": [
          "Introducción a TensorFlow",
          "Sintaxis básico de TensorFlow",
          "Grafos en TensorFlow",
          "Grafos por defecto",
          "Variables y placeholders",
          "Construyendo nuestra primera red neuronal - parte 1",
          "Construyendo nuestra primera red neuronal - parte 2",
          "Ejemplo de regresión simple con TensorFlow",
          "Ejemplo de clasificación",
          "Ejemplo de regresión - parte 1",
          "Ejemplo de regresión - parte 2",
          "Ejemplo de regresión - parte 3"
        ],
        "Redes Neuronales Convolucionales": [
          "Introducción a las redes neuronales convolucionales",
          "MNIST - Base de datos de imágenes de dígitos escritos a mano",
          "Ejemplo con MNIST - Importar base de datos y mostrar una imagen"
        ],
        "Redes Neuronales Recurrentes": [
          "Introducción",
          "Ejemplo de Red Neuronal Recurrente",
          "Ejemplo de series temporales - parte 1",
          "Ejemplo de series temporales - parte 2",
          "Ejemplo de series temporales - parte 3"
        ],
        "Bibliotecas": [
          "Estimator API",
          "Nota previa al video keras",
          "Keras"
        ],
        "Sección adicional": [
          "Clase extra"
        ]
      },
      "requirements": [
        "Es necesario saber algo de programación con Python aunque en el curso hay una lección explicando las librerías de Python que usaremos en este curso"
      ],
      "description": "Este curso básico de TensorFlow te enseñará a crear redes neuronales para Deep Learning o aprendizaje profundo.\nEs una guía fácil con muchos ejemplos, para entener las complejidades del marco de TensorFlow de Google.\nEste curso está repleto de ejemplos escritos en Python sobre Jupyter Notebook, para que puedas probarlos tu mismo.\n\n\nEstos son los temas tratados en este curso de TensorFlow :\n- Introduccion al Machine Learning\n- Instalacion del entorno de trabajo\n- Curso básico de Python sobre las librerías usadas en este curso:\n- NumPy\n- Pandas\n- Matplotlib\n- SciKit Learn\n- Introducción a las redes neuronales (Deep Learning)\n- Neuronas y perceptrones\n- Funciones de activacion\n- Funciones de coste\n- Algoritmo del gradiente descendiente\n- Practicar con una red neuronal en el navegador\n- TensorFlow\n- Introducción a TensorFlow\n- Sintaxis básica de TensorFlow\n- Grafos en TensorFlow\n- Grafos por defecto\n- Variables y placeholders\n- Ejemplo de red neuronal - parte 1\n- Ejemplo de red neuronal - parte 2\n- Ejemplo de regresión simple con TensorFlow\n- Ejemplo de clasificación con TensorFlow\n- Ejemplo de regresión con TensorFlow - parte 1\n- Ejemplo de regresión con TensorFlow - parte 2\n- Ejemplo de regresión con TensorFlow - parte 3\n- Redes Neuronales Convolucionales\n- Introducción a las redes neuronales convolucionales\n- MNIST - Base de datos de imágenes de dígitos escritos a mano\n- Ejemplo con MNIST - Importar base de datos y mostrar una imagen\n- Redes Neuronales Recurrentes\n- Introducción a las redes neuronales recurrentes\n- Ejemplo de una red neuronal recurrente con TensorFlow\n- Ejemplo de series temporales - parte 1\n- Ejemplo de series temporales - parte 2\n- Ejemplo de series temporales - parte 3\n- Bibiliotecas\n- Estimator API\n- Keras\n\n\nPodrás obtener un certificado de la realización de este curso.\nTienes una garantía de devolución de 30 días, en el caso de que no quedes satisfecho con el curso.\nApúntate hoy y nos vemos en el curso!",
      "target_audience": [
        "Personas interesadas en conocer cómo funcionan las redes neuronales y quieran aprender a crear programas en Python que usen TensorFlow, el software de Google para Deep Learing"
      ]
    },
    {
      "title": "Introduction to Stable Diffusion for Developers & Designers",
      "url": "https://www.udemy.com/course/introduction-to-stable-diffusion/",
      "bio": "Expertly crafted course for Technical and Non-Technical audience Introducing GenerativeAI Text2Image Stable Diffusion",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "1.1 - Welcome",
          "1.2 - Why should you be interested in GenerativeAI Technology Stable Diffusion?",
          "1.3 - Introduction to Stable Diffusion - Curriculum",
          "1.4 - Stable Diffusion Course Series",
          "1.5 - Tools and Setup - PlaygroundAI",
          "1.6 - Tools and Setup - Miro",
          "1.7 - Tools and Setup - Lab Guides using tango.us"
        ],
        "Prompt Engineering": [
          "2.1 - What is Stable Diffusion?",
          "2.2 - PlaygroundAI",
          "2.3 - PlaygroundAI - Lab Guide Demo",
          "2.4 - Prompt Engineering - Introduction",
          "2.5 Prompt Engineering - CLIP or Image2Text",
          "2.6 - Prompt Engineering - Anatomy",
          "2.7 - Prompt Engineering - Iterative Process",
          "2.8 - Prompt Engineering - Iterative Process Demo",
          "2.9 - Prompt Engineering - Negative Prompt",
          "2.10 - Prompt Engineering - PlaygroundAI Filters",
          "2.11 - Prompt Engineering - Miscellaneous",
          "2.12 - Prompt Engineering - Labs Overview"
        ],
        "Parameter Tuning": [
          "3.1 - Parameter Tuning - CFG, Steps, Seeds, Dimensions, Sampler",
          "3.2 - Parameter Tuning - Quality and Details Lab Demo"
        ],
        "Image2image": [
          "4.1 - Image2image - Introduction",
          "4.2 - Image2image - Create Variants",
          "4.3 - Image2image - Style Fusion",
          "4.4 - Image2image - Variants + Style Fusion Demo",
          "4.5 - Image2image - Doodle to Painting Demo",
          "4.6 - In-painting - Object add, remove, replace",
          "4.7 - Edit Image or Instruct Pix2pix",
          "4.8 - Out-painting Demo",
          "4.9 - PlaygroundAI - Face Restoration and Upscale 4x",
          "4.10 - Image2image - Lab Overview"
        ],
        "Conclusion": [
          "5.1 - Recap",
          "5.2 - Next?"
        ]
      },
      "requirements": [
        "The course is designed for both technical and non-technical learners. No programming experience or any experience with Stable Diffusion is required"
      ],
      "description": "Welcome to Introduction to Stable Diffusion Course.\nQuick intro about the trainer, I have 17+ years of experience in IT, with last few years at the leadership positions of Decacorns and one of the largest product companies in South Asia. Past 2 years, I have immersed myself in GenerativeAI, Large Language Models, and for past 6 months in Stable Diffusion.\nIn the past 6 months, I have won various hackathons themed on GenerativeAI and Stable Diffusion. I have launched a GenerativeAI startup, as well as delivered an enterprise grade hands-on online workshop on Stable Diffusion. I have compiled all my learnings, specially last 2 years on GenerativeAI, and past 6 months on Stable Diffusion in this online course.\nIn this course, you are going to learn in-depth, hands-on on the topic of Stable Diffusion. This course is expertly crafted, and targeted at both technical and non-technical audience. We dive deep into the topic at more than an AI Artist level, but less than a Data Scientist level. You will understand the ins-and-outs of Stable Diffusion technology, and will be able to tie back the controls and parameters of how the AI model works under the hood.\nWe cover main applications of Stable Diffusion, including generating art, prompt engineering, negative prompts, iterative prompt engineering with experimentation, parameter tuning - cfg, steps, seed, dimensions, sampler, image2image applications including - variations, doodle to art, in-painting (addition, removal, replacement), out-painting, instruct pix2pix, face restoration and upscaling.\nYou are going to have 10+ lab guides, generating 100+ art works during the duration of the course, gaining 100% confidence to start producing production quality artwork and image assets by using the tips and techniques introduced in this course.\nThe course also gives you pointer and guidance on exploring the technology deeper and gain even deeper understanding.\nBest wishes and Happy Learning.",
      "target_audience": [
        "Course is designed for solopreneurs and indiehackers who are planning to launch their own GenerativeAI startup using Stable Diffusion technology",
        "Course is for anyone curious about Technology underlying Text2Image tools like Stable Diffusion, Dall-E, Midjourney",
        "Course is for Designers who want to get started with GenerativeAI Text2Image technology and create production quality artworks Stable Diffusion and similar technologies",
        "Course is designed for Technical Audience like Developers, Machine Learning Engineers, Data Scientist who are looking to be introduced to GenerativeAI Text2Image technology like Stable Diffusion"
      ]
    },
    {
      "title": "Algoritmos Genéticos em Python",
      "url": "https://www.udemy.com/course/algoritmos-geneticos-em-python/",
      "bio": "Construa passo a passo um algoritmo de Inteligência Artificial aplicado no cenário de transporte de produtos!",
      "objectives": [
        "Aprenda na teoria e na prática os principais conceitos sobre os algoritmos genéticos, tais como: indivíduo, população, crossover/reprodução e mutação",
        "Aprenda conceitos adicionais como: função de avaliação/fitness e seleção de indivíduos",
        "Implemente um algoritmo genético passo a passo no Python para resolver um problema real de transporte de mercadorias",
        "Visualize as soluções do algoritmo genético utilizando gráficos com a biblioteca matplotlib",
        "Utilize o algoritmo genético integrado com uma base de dados no MySql",
        "Crie algoritmos genéticos utilizando a biblioteca DEAP"
      ],
      "course_content": {
        "Introdução e conteúdo do curso": [
          "Problema a ser resolvido",
          "Conteúdo do curso",
          "Algoritmos evolucionários e algoritmos genéticos",
          "Mais sobre Inteligência Artificial",
          "Recursos para download"
        ],
        "Algoritmos genéticos passo a passo": [
          "Instalação do Anaconda",
          "Recursos para download",
          "Classe produtos",
          "Classe indivíduo I",
          "Classe indivíduo II",
          "Função de avaliação",
          "Crossover/reprodução - teoria",
          "Crossover/reprodução - implementação",
          "Mutação",
          "Errata na implementação da mutação!",
          "Inicialização da população",
          "Avaliação da população",
          "Melhor indivíduo",
          "Soma das avaliações",
          "Seleção dos indivíduos - teoria",
          "Seleção dos indivíduos - implementação",
          "Construção de nova geração",
          "Algoritmo genético completo I",
          "Algoritmo genético completo II",
          "Algoritmo genético completo III",
          "Gráfico das soluções",
          "Instalação do MySql",
          "Criação da tabela de produtos no MySql",
          "Algoritmo genético com banco de dados",
          "Biblioteca DEAP I",
          "Biblioteca DEAP II",
          "Biblioteca DEAP III"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "É recomendado conhecimento sobre lógica de programação, principalmente estruturas condicionais e de repetição",
        "Conhecimentos básicos em Python são desejáveis, embora seja possível acompanhar o curso sem saber essa linguagem com profundidade",
        "Noções sobre orientação a objetos são necessárias, principalmente conceitos como classe, objeto, atributo e método",
        "Não são necessários conhecimentos prévios sobre Inteligência Artificial",
        "Não são necessários conhecimentos prévios sobre banco de dados"
      ],
      "description": "Os algoritmos genéticos são uma importante área da Inteligência Artificial que são responsáveis pela resolução de problemas complexos, tendo como base encontrar soluções para problemas de otimização e busca. Existem várias aplicações práticas deste tipo de algoritmo, as quais podem ser aplicadas na resolução de problemas em cenários comerciais do dia a dia. Um exemplo clássico é a resolução do problema de choque de horários de professores em uma escola, no qual existem diversas combinações de horários e aulas e o objetivo é construir a grade de horário dinamicamente de acordo com a quantidade de aulas e a disponibilidade de cada professor. Outros exemplos são: empresas de telecomunicações podem projetar novas redes óticas, transportadoras podem planejar melhor a rota de entrega de mercadorias, investidores podem  escolher os melhores investimentos; dentre várias outras.\n\nBaseado nisso, neste curso você vai aprender na teoria e principalmente na prática como desenvolver do zero um algoritmo genético aplicado em um cenário real de uma transportadora. Neste contexto, nós seremos consultores de uma empresa de transporte que possui vários produtos a serem transportados, porém, a empresa possui somente um caminhão disponível e com espaço limitado de armazenamento. Nosso objetivo será desenvolver um algoritmo que consiga gerar a melhor combinação dos produtos que devem ser transportados, levando em consideração o fato de que a transportadora quer ganhar o máximo de dinheiro possível com o frete e ocupando o espaço disponível no caminhão.\nEsse tipo de algoritmo é baseado em encontrar soluções cada vez melhores a partir da evolução das gerações anteriores, sendo fundamentado nos processos naturais de evolução. E para chegar em nosso objetivo, você vai aprender os principais conceitos sobre essa técnica de inteligência artificial, tais como: população, indivíduo, crossover/reprodução e mutação. Ao final do curso, você terá um algoritmo genético completo que conseguirá resolver o problema da transportadora, o qual pode ser aplicado para outros cenários comerciais. Utilizaremos a linguagem Python para a programação das funções e desenvolveremos tudo passo a passo e com muitos detalhes, para que você tenha uma visão bem clara e didática de como esses algoritmos conseguem resolver problemas reais do cotidiano. Além disso, teremos um bônus no qual você vai aprender como criar uma tabela de produtos no MySql e aplicar nosso algoritmo utilizando os dados de uma base de dados, o que pode facilitar a adaptação do código para utilização em ambientes comerciais. Por fim, este material pode ser considerado de nível iniciante para quem está entrando tanto na área de Inteligência Artificial quanto na área de algoritmos genéticos. Porém, caso você seja de nível mais avançado, este curso poderá servir como uma ótima fonte de consulta e revisão dos conceitos.\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial",
        "Pessoas interessadas em resolver problemas reais utilizando algoritmos genéticos"
      ]
    },
    {
      "title": "Data Visualization using Tableau",
      "url": "https://www.udemy.com/course/data-visualization-using-tableau/",
      "bio": "Tableau Fundamental the beginner to intermediate Tableau user",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "How to Apply Filter on Data using Tableau",
          "How Tableau Can Helps you to take Quick Decisions",
          "How to save Tableau Public workbooks",
          "How to Extract First and Last Name in Excel File",
          "Reach us for more Details"
        ]
      },
      "requirements": [
        "None"
      ],
      "description": "Tableau Fundamental the beginner to intermediate Tableau user, targeted towards anyone who works with data – regardless of technical or analytical background. This course helps you implement important concepts, techniques & admin activities in Tableau. Move from simple to complex visualizations and combine them in interactive dashboards.\nWhat you will learn\n· What is Visualization?\n· What Is Dashboard?\n· Why Tableau?\n· Comparison of Tableau with other tools\n· Limitations of Tableau\n· Tableau Desktop, Server, and the Tableau Product Line\n· Application Terminology\n· Connecting to data – Basics\n· Editing Data connections and data sources\n· Editing Metadata and saving data sources\n· Joins in Tableau\n· Data Source level Filters\n· Connecting to Oracle, SQL Server, Google Analytics, Different RDBMS Databases\n· Connecting to Big Databases like HDFS, Hive, Greenplum, Teradata\n· Calling Stored Procedure in Tableau\n· Join Types\n· Custom SQLs\n· Getting Started in Tableau Desktop\n· Elements of Visualization\n· Understanding of Dimensions & Measures\n· Basic Graphs (Bar Chart, Stacked Bar Chart, Line Chart, Area Chart, Pie Chart, Filled Maps Symbol Maps, Scatter Plots, Trend Line, Bullet Chart, Part to Whole Char)\n· Dual Axis Graphs( Dual line chart, + Side by side bar chart, + Donut Chart, + Map and Pie Chart, + Map and Donut Chart, + Bar in Bar Chart, + Bar & Circle Chart)\n· Data Filtering\n· Data Blending and Joins\n· Connection Types\n·Dashboard Creation\n· Sharing Your Work\n· Dashboard Best Practices\n· Story Telling\n·· Publishing Data: -\n·",
      "target_audience": [
        "developers, students, professionals, Tableau experts, Tableau developers , beginners, Data Visualization"
      ]
    },
    {
      "title": "ChatGPT: Der komplette ChatGPT Kurs vom Anfänger zum Profi",
      "url": "https://www.udemy.com/course/chatgpt-der-komplette-chatgpt-kurs-vom-anfanger-zum-profi/",
      "bio": "ChatGPT für Anfänger & Beginner | Das einzige ChatGPT Tutorial für Unternehmen & Privatanwender",
      "objectives": [
        "Chat GPT kann du automatisch Antworten auf Kundenanfragen erstellen, so sparst du Zeit und Aufwand.",
        "Mit Chat GPT kannst du personalisierte und genaue Antworten an deine Kunden schicken und dadurch die Kundenzufriedenheit und Loyalität verbessern.",
        "Der Kurs bringt dir ein umfassendes Wissen bei, wie du Chat GPT für dein Unternehmen nutzen kannst, um deine Umsätze zu erhöhen.",
        "Du wirst lernen, wie du mit Chat GPT passives Einkommen aufbauen kannst indem wir dir mehr als 60 Tipps geben, um damit Geld zu verdienen.",
        "Du kannst Chat GPT verwenden, um Routineaufgaben zu automatisieren, um so mehr Zeit für wichtige Aufgaben und Projekte zu haben.",
        "Mit der Fähigkeit ChatGPT perfekt zu bedienen, hast du eine gefragte Fähigkeit, die deine Skills erweitern und dir auf dem Arbeitsmarkt einen höheren Wert gibt",
        "Chat GPT kann dir dabei helfen, deinen Kundenservice zu verbessern, zu automatisieren und ohne viele Mitarbeiter zu skalieren.",
        "Chat GPT kann in deine bestehenden Systeme integriert werden, wodurch diese effizienter werden und Arbeitsabläufe und häufige Tätigkeiten optimiert werden"
      ],
      "course_content": {
        "Einführung": [
          "Was erwartet dich im ChatGPT Kurs für Beginner",
          "Begriffe: Was ist ChatGPT eigentlich?",
          "Die Möglichkeiten: Was kannst du mit ChatGPT machen?",
          "Gibt es Alternativen zu ChatGPT?",
          "Wird ChatGPT immer kostenlos sein?"
        ],
        "Praxisteil 1: Grundlegende Anwendungen  Chat GPT in der Praxis": [
          "Wie erstelle ich mir einen Account um ChatGPT zu nutzen?",
          "Erstelle deinen ersten Chat mit der Ai",
          "Was sind Prompts und warum sind sie wichtig",
          "Wie du mit ChatGPT besser recherchierst",
          "Wie du Content für Webseiten und Social Media erstellst.",
          "Extra: Wie du deine Anfragen extrem verbessern kannst.",
          "Verträge und Rechtstexte mit ChatGPT schreiben lassen",
          "Mit ChatGPT Texte schnell übersetzen lassen",
          "Programmierung mit Ai: Coding mit ChatGPT"
        ],
        "Praxisteil 2: Noch tiefer eintachen in ChatGPT (Geheimtipps)": [
          "ChatGPT Playground: Noch mehr Features und Einstellungen",
          "30 Anwendungen für ChatGPT im Alltag (private Nutzung)",
          "30 Anwendungen & Use Cases für ChatGPT für dein Business",
          "2.13. Wo sind die Grenzen von ChatGPT? (Plagiate, Ai-Content-Detektoren)",
          "Do’s: Darauf musst du unbedingt achten",
          "Don’ts: Diese Dinge solltest du niemals tun",
          "Best Practise: Die „Handle so“ Technik"
        ],
        "ChatGPT im Internet nutzen und die Zukunft der Ai": [
          "Wie du ChatGPT mit Google nutzen kannst",
          "Mit dieser Browser-Erweiterungen fasst du alle Texte in 3 Sekunden zusammen",
          "Noch mehr Browser-Erweiterungen für ChatGPT",
          "Was erwartet uns in der Zukunft?",
          "Chancen und Risiken: Was bedeutet ChatGPT für den Arbeitsmarkt?"
        ]
      },
      "requirements": [
        "Keine Vorkenntnisse notwendig.",
        "Alles was du benötigst lernst du im Kurs."
      ],
      "description": "Ich freue mich, dass du bereit bist, in die Welt von ChatGPT einzutauchen!\n\n\nEine Einführung in die spannende Welt von Chat GPT\nBeispiele und Anwendungsfälle für Chat GPT\nWie du mit Chat GPT kostenlos Geld verdienen kannst\nWie du Chat GPT optimal nutzt, ohne Einschränkungen\nWie man die passenden Prompts findet und anwendet\nÜber 60 Anwendungsfälle, die du sofort nutzen kannst (sowohl geschäftlich als auch privat)\nProfitipps von einem erfahrenen Nutzer (Do's und Don'ts von Chat GPT)\n\n\nHole dir jetzt meinen Kurs und tauche tief in die Welt der KI und ChatGPT ein. Erhalte einen Überblick über die Standardfunktionen und lerne, wie du die richtigen Prompts einsetzt. Im Kurs erfährst du, wie du ChatGPT auf deinen speziellen Anwendungsfall anwendest, egal ob privat oder beruflich.\n\nWenn du ChatGPT nutzen möchtest, um Geld zu verdienen, oder es für persönliche Zwecke einsetzen willst, wirst du hier die passenden Antworten finden.\n\nChatGPT kann dir helfen, schneller zu übersetzen, Texte zu schreiben (Copywriting), den Kundensupport zu automatisieren, SEO-Texte zu erstellen oder sogar Code zu schreiben, ohne programmieren zu können. Außerdem lernst du im Kurs, wie du die speziellen Funktionen von ChatGPT freischaltest, um seine volle Leistung zu nutzen.\n\n\nAlle Tipps sind von mir persönlich getestet und funktionieren in der Praxis. Ich zeige dir, wie du ChatGPT nutzen kannst, um damit Geld zu verdienen. Natürlich bedeutet das, dass man Arbeit und Zeit investieren muss und gründliche Recherchen betreiben muss, um gute Geschäftsideen oder Anwendungsfälle zu finden. Im Kurs zeige ich dir genau, wie du dafür die richtigen Fragen und Prompts stellst.\n\nZudem erfährst du, wie du mit kleinen Tricks die Prompts verbessern kannst, um schneller die richtigen Antworten zu finden. Egal welches Ziel du erreichen willst, ob du damit Geld verdienen oder dein privates Leben verbessern möchtest, hier findest du die Antworten. Ich freue mich auf dich im Kurs,\n\n\nDein Mark K.",
      "target_audience": [
        "Unternehmer",
        "Entwickler",
        "Freelancer",
        "Marketing-Manager",
        "Alle die mit ChatGPT ihr Business skalieren wollen oder damit Geld verdienen wollen."
      ]
    },
    {
      "title": "Mastering Numpy in Python",
      "url": "https://www.udemy.com/course/mastering-numpy-in-python/",
      "bio": "Unlocking the Power of NumPy: Mastering Data Manipulation in Python",
      "objectives": [],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Creating your first Numpy Array",
          "Slicing and Indexing - Accessing parts of Numpy Arrays",
          "From 1D to 2D++",
          "More FREE learning"
        ],
        "Diving Deeper": [
          "Storing Arrays",
          "Numpy Array Attributes",
          "Flipping, reversing etc",
          "Numpy Stacking, Concat, Split Arrays",
          "Transpose, Reshape, Broadcasting"
        ],
        "Mathematics - Statistics with Numpy": [
          "Mathematical Operations",
          "Linear Algebra Operations",
          "Statistics with Numpy",
          "Random Number Generation"
        ],
        "Whole Course to download": [
          "Get this locally!"
        ]
      },
      "requirements": [
        "No requirement. It's good to have finished the Python and Pandas Course! Offered for free in my profile."
      ],
      "description": "Are you new to Python and excited to explore the world of data manipulation? This beginner-oriented Udemy course is your ideal starting point. We'll guide you through the fundamentals of NumPy, the indispensable library for numerical computing in Python, ensuring you grasp the basics while building a strong foundation\nHere's what you can expect to learn in this course:\nIntroduction to NumPy: Begin by understanding the significance of NumPy and its vital role in data manipulation with Python\nNumPy Arrays: Learn how to create, manipulate, save, and load NumPy arrays, the cornerstone of numerical computations\nMatrix Operations: Discover how to create and work with NumPy matrices for more advanced data processing\nLinear Algebra: Dive into the world of linear algebra with NumPy, exploring matrix multiplication, determinants, and more\nStatistics: Gain insights into how NumPy can help you perform basic statistical operations on your data, such as mean, median, and variance calculations\nRandom Number Generation: Explore the capabilities of NumPy for generating random numbers and simulating data, a crucial aspect of many data-driven tasks\nThroughout this course, you'll have the opportunity to apply your knowledge with practical exercises and projects that reinforce your understanding. We've designed this course with beginners in mind, making it accessible and engaging for anyone interested in data manipulation with Python\nBy the end of this course, you'll have a solid foundation in NumPy and the skills you need to work with data effectively. Whether you're a student, a budding data analyst, or someone simply curious about data manipulation, this course will provide you with the tools and knowledge to begin your data journey\nJoin us in this exciting introduction to NumPy, and take your first steps towards becoming a Python data enthusiast. Enroll today, and let's embark on this learning adventure together!",
      "target_audience": [
        "Beginner Python Developers, anyone interested to learn data science or computational mathematics."
      ]
    },
    {
      "title": "Manipulação e Análise de Dados com Pandas - Python",
      "url": "https://www.udemy.com/course/manipulacao-e-analise-de-dados-com-pandas-python/",
      "bio": "Aprenda na prática com análise de dados de campeonatos de Data Science e Data Analysis.",
      "objectives": [
        "Como baixar e instalar o Pandas no Python",
        "A importância do Pandas para Machine Learning e Data Science",
        "Como participar de campeonatos de análise de dados",
        "O que são Dataframes",
        "Como criar e manipular Dataframes",
        "Utilizar as funções Merge e Groupby",
        "Com funciona o sistema de indexação na Pandas",
        "Como fazer reshaping de dados",
        "Como fazer filtros e manipulações avançadas de dados",
        "Limpar dados - Data Wrangling",
        "Importar e exportar dados - I/O",
        "Visualizar dados com gráficos e tabelas",
        "Várias aplicações em dados - casos reais do dia a dia",
        "E muito mais!"
      ],
      "course_content": {},
      "requirements": [
        "É recomendado que o aluno tenha conhecimentos básicos da linguagem de programação Python."
      ],
      "description": "Este curso visa oferecer ao aluno conhecimentos básicos e avançados a respeito da biblioteca Python Pandas.\nPandas é uma biblioteca de código aberto em Python que fornece estruturas de dados de alto desempenho e fáceis de usar, além de ferramentas de análise de dados.\nEla é particularmente útil para manipulação e análise de dados tabulares, como planilhas e bancos de dados SQL.\nA biblioteca Pandas é amplamente utilizada em ciência de dados, análise de dados, aprendizado de máquina e em muitos outros domínios relacionados.\nIsso faz de Pandas é  uma das mais importantes bibliotecas Python utilizadas para manipulação e análise de dados nos campos da Inteligência artificial e Big Data.\nSem sombra de dúvidas todo e qualquer analista e cientista de dados precisa conhecer e dominar bem a biblioteca Pandas.\nNeste curso o aluno irá aprender a manipular dados com segurança, controle e velocidade utilizando os mais importantes recursos e funcionalidades que a biblioteca tem a oferecer.\nAs aulas são curtas, com linguagem simples e direta. O aluno não precisará de muitas horas de frente ao computador para fazer seus estudos.\nO aluno terá acesso vitalício as aulas do curso e também a atualizações e acesso a novas aulas.\nInscreva-se agora mesmo e venha estudar como manipular e analisar dados com Pandas no Python!\n\n\nVamos aos estudos e até logo!!",
      "target_audience": [
        "Cientistas dos dados",
        "Estatísticos e matemáticos",
        "Engenheiros",
        "Autodidatas interessados em machine learning e data Science",
        "Pesquisadores, analistas e desenvolvedores de softwares"
      ]
    },
    {
      "title": "Learn Basic of Emerging Trends in Computer",
      "url": "https://www.udemy.com/course/learn-basic-of-emerging-trends-in-computer/",
      "bio": "Emerging Trends in Computer & Information Technology",
      "objectives": [],
      "course_content": {
        "Introduction to Artificial Intelligence": [
          "Introduction & History of Artificial Intelligence",
          "Goal & Importance of AI",
          "Types of AI based on Capabilities",
          "Types of AI based on Functionality",
          "Application of AI, Machine Learning & Deep Learning"
        ],
        "Internet of Things": [
          "Embedded System",
          "Introduction to IoT",
          "IoT Communication Model & Applications"
        ],
        "Digital Forensics": [
          "Introduction & history of Digital Forensics",
          "Models of Digital Forensics",
          "Digital Forensics Investigation"
        ],
        "Digital Evidence": [
          "Digital Evidence"
        ],
        "Hacking": [
          "Basics of Ethical Hacking",
          "Ethical Hacking Principles and processes.",
          "Types of Hacking"
        ]
      },
      "requirements": [
        "Be able to identify the concepts of Computer Sciences."
      ],
      "description": "The aim of this course is to  help students to attain the industry identified competency through various teaching learning experience: acquire knowledge of emerging trends. Advancements and applications of Computer Engineering and Information Technology are ever changing. Emerging trends aims at creating awareness about major trends that will define technological disruption in the  upcoming years in the field of Computer Engineering and Information Technology. These are some emerging areas expected to generated revenue, increasing demand as IT professionals and open avenues of entrepreneurship. The Objectives of the course are Differentiate between Machine Learning & Deep Learning, State IoT issues & Challenges in deployment, Describe the given model of Digital Forensics Investigation, Describe the given evidence handling, Describe the need to hack your own systems, Describe Database Vulnerabilities. The outcomes of the course are Describe Artificial Intelligence, Machine Learning & Deep Learning: Describe the concept of AI, State the components of AI, Differentiate between Machine Learning & Deep Learning, Interpret IoT Concepts: Describe IoT Systems in which information and knowledge are inferred from data, State IoT issues and challenges in deployment, Compare Model of Digital Forensic Investigation: Describe the given model of Digital Forensics Investigation, State the ethical and unethical issues in Digital Forensics, Describe Evidence Handling Procedures: List the rules of digital evidence, Describe the given evidence handling procedures, Describe Ethical Hacking Process: Describe the need to hack your own system, Detect Network, Operating System & Application vulnerabilities: Network Infrastructure vulnerabilities (Wired/Wireless),Describe Messaging Systems vulnerabilities.",
      "target_audience": [
        "Beginners of Software developers, Under graduates in Computer Science"
      ]
    },
    {
      "title": "AIによる「物体検出」を学ぼう！【PyTorch+Colab】 -ディープラニングにより特定する物体の位置、種類-",
      "url": "https://www.udemy.com/course/ai-object-detection/",
      "bio": "人工知能（AI）を使った画像中の物体検出について学ぶコースです。Faster R-CNN、SSD、RetinaNet、DETRなどの深層学習ベースの技術を学び、Google Colaboratory環境でPythonを使い実装しましょう。",
      "objectives": [
        "AIによる物体検出ができるようになります。",
        "AIによる物体検出の原理について、基礎的な知識を学びます。",
        "Python、PyTorchで書かれた物体検出のコードが読めるようになります。",
        "自分の力で、物体検出のコードを実装する力が身に付きます。",
        "AIによる物体検出全般についての知識が身につきます。"
      ],
      "course_content": {
        "AIによる物体検出の概要": [
          "教材の使用方法",
          "イントロダクション",
          "講座の概要",
          "AIによる物体検出の概要",
          "開発環境について",
          "CNNの概要",
          "PyTorchによるCNNの実装",
          "演習"
        ],
        "Faster R-CNNによるシンプルな物体検出": [
          "セクション2の教材",
          "Section2の概要",
          "Faster R-CNN実装の概要",
          "Faster R-CNNの実装 Part1",
          "Faster R-CNNの実装 Part2"
        ],
        "SSD、RetinaNetによる物体検出": [
          "セクション3の教材",
          "Section3の概要",
          "転移学習とファインチューニング",
          "SSDの概要",
          "SSDの実装",
          "RetinaNetの概要",
          "RetinaNetの実装",
          "演習"
        ],
        "Transformerを利用した物体検出（DETR）": [
          "セクション4の教材",
          "Section4の概要",
          "Transformerの概要",
          "DETRの概要",
          "DETRの実装",
          "最後に"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "中学-高校レベルの数学で十分です。高度な数学は必要ありません。",
        "Google Colaboratoryを使用するため、ローカル環境はWindowsでもMacでも大丈夫です。",
        "Google Colaboratoryを使用するためにGoogleアカウントが必要になります。",
        "人工知能、ディープラーニング自体について詳しい解説は行いません。",
        "Pythonの基礎を学ぶためのテキストがダウンロード可能ですが、動画によるPythonの解説はありません。"
      ],
      "description": "『AIによる「物体検出」を学ぼう！』は、人工知能（AI）を使った画像中の物体検出について学ぶ講座です。\nフレームワークにPyTorchを使い、Google Colaboratory環境で画像中の物体を検出します。\n\n\n人工知能・機械学習技術の中でも、近年注目されているのが「ディープラーニング」で、第3次AIブームの主役となっています。\n物体検出は画像の中から特定の物体の位置と種類、個数を特定する技術ですが、ディープラーニングによる物体検出は自動運転やスマートフォンによる顔認識など様々な場面で利用されています。\n本講座では、Faster R-CNN、SSD、RetinaNet、DETRなどのディープラーニングベースの物体検出技術を学び、Pythonのコードで実装します。\n\n\n物体検出をうまく利用すれば、従来人間しかできなかったタスクの自動化が可能です。\nPythonのコードを書きながら、AIによる物体検出技術を楽しく学んでいきましょう。\n\n\n注: 本コースに先立ちYouTubeでのライブ講義【Live人工知能】がありました。本コースの動画はこのライブ講義をUdemy用に再構成したものになります。\n\n\n講座の内容は以下の通りです。\nSection1. AIによる物体検出の概要\n→ AIによる物体検出の概要、開発環境、CNNについて学びます。\nSection2. Faster R-CNNによるシンプルな物体検出\n→ Faster R-CNNにより、物体検出をシンプルに実装します。\nSection3. SSD、RetinaNetによる物体検出\n→ 高精度を発揮する実用的な物体検出技術、SSDおよびRetinaNetについて学びます。\nSection4. Transformerを利用した物体検出（DETR）\n→ 「Transformer」が導入された物体検出技術、DETRについて解説します。\n\n\nなお、今回の講座でプログラミング言語Pythonの解説は最小限となりますが、Pythonの基礎を解説するノートブックを予め配布します。\nPythonの開発環境にはGoogle Colaboratoryを使用します。",
      "target_audience": [
        "AIによる物体検出に興味があるけど、学び方が分からない方。",
        "AIによる物体検出で、何らかの問題を解決したい方。",
        "AIによる物体検出全般の知識を得たい方。",
        "Faster R-CNN、SSD、RetinaNet、DETRなどの物体検出技術を学びたい方。",
        "仕事上、AIによる物体検出の知識が必要になった方。"
      ]
    },
    {
      "title": "Machine Learning von A-Z: Lerne Python & R für Data Science!",
      "url": "https://www.udemy.com/course/machine-learning-komplett/",
      "bio": "Maschinelles Lernen komplett: Regression, Klassifizierung, Clustering, NLP, AI, KI, Deep Learning & Neuronale Netze",
      "objectives": [
        "Erstelle Machine-Learning-Anwendungen sowohl in Python, als auch in R",
        "Keine trockene Mathematik - alles anschaulich erklärt",
        "Wende Machine Learning auf eigene Daten an",
        "Verwende gängige Tools wie Sklearn, NLTK und Caret",
        "Du wirst Machine Learning übersichtlich und prägnant lernen",
        "Du wirst wissen, wann du welches Machine-Learning-Modell anwenden kannst",
        "Lerne mit echten Daten: Viele Praxisbeispiele (Spam-Filter, schätze Preis von Gebrauchtwagen, ...)"
      ],
      "course_content": {
        "Einleitung": [
          "Warum Machine Learning?",
          "Wer bin ich? Wie ist dieser Kurs aufgebaut?",
          "Python oder R?",
          "Download der benötigten Materialien"
        ],
        "Einrichtung der Python-Umgebung": [
          "Wichtiger Hinweis! (Windows)",
          "Installation der benötigten Tools",
          "Crashkurs: Unsere Jupyter-Umgebung",
          "Wie findest du die richtige Datei in den Kursmaterialien?"
        ],
        "Einrichtung der R-Umgebung": [
          "Installation von R und RStudio",
          "Crashkurs: R und RStudio",
          "Wie findest du die richtige Datei in den Kursmaterialien?",
          "Hinweis zu den nächsten Lektionen",
          "Kurzeinführung: Vektoren in R",
          "Kurzeinführung: data.table in R"
        ],
        "Grundlagen Machine-Learning": [
          "Was ist ein Modell?",
          "Was für Problemstellungen gibt es im Machine Learning?"
        ],
        "Lineare Regression": [
          "Intuition: Lineare Regression (Teil 1)",
          "Intuition: Lineare Regression (Teil 2)",
          "Intuition nachvollziehen mit Geogebra",
          "Check: Lineare Regression",
          "Python: Daten einlesen und Grafik zeichnen",
          "Hinweis zu Excel",
          "Python: Lineare Regression (Teil 1)",
          "Python: Lineare Regression (Teil 2)",
          "R: Lineare Regression (Teil 1)",
          "R: Lineare Regression (Teil 2)",
          "R: Lineare Regression (Teil 3)",
          "R: Lineare Regression (Teil 4)",
          "Exkurs (optional): Warum verwenden wir den quadratischen Fehler?"
        ],
        "Praxisprojekt: Lineare Regression": [
          "Vorstellung: Praxisprojekt Lineare Regression (Gebrauchtwagenverkäufe)",
          "Praxisprojekt: Lineare Regression",
          "Python: Musterlösung",
          "R: Musterlösung"
        ],
        "Train / Test": [
          "Intuition: Train / Test",
          "Check: Train / Test",
          "Python: Train / Test (Teil 1)",
          "Python: Train / Test (Teil 2)",
          "Python: Train / Test - Aufgabe",
          "R: Train / Test (Teil 1)",
          "R: Train / Test (Teil 2)",
          "R: Train / Test - Aufgabe"
        ],
        "Lineare Regression mit mehreren Variablen": [
          "Intuition: Lineare Regression mit mehreren Variablen (Teil 1)",
          "Intuition: Lineare Regression mit mehreren Variablen (Teil 2)",
          "Check: Lineare Regression mit mehreren Variablen",
          "Python: Lineare Regression mit mehreren Variablen (Teil 1)",
          "Python: Lineare Regression mit mehreren Variablen (Teil 2)",
          "R: Lineare Regression mit mehreren Variablen (Teil 1 + 2)"
        ],
        "Modelle vergleichen: Bestimmtheitsmaß": [
          "Intuition: R² - Das Bestimmtheitsmaß (Teil 1)",
          "Intuition: R² - Das Bestimmtheitsmaß (Teil 2)",
          "Check: R² / Bestimmtheitsmaß",
          "Python: R² ausrechnen",
          "Python: Modelle anhand von R² vergleichen",
          "R: R² ausrechnen",
          "R: Modelle anhand von R² vergleichen"
        ],
        "Praxisprojekt: Bestimmtheitsmaß": [
          "Einführung: Praxisprojekt Bestimmtheitsmaß",
          "Hinweis: Wo findest du das Projekt?",
          "Python, Praxisprojekt: Bestimmtheitsmaß berechnen",
          "R, Praxisprojekt: Bestimmtheitsmaß berechnen"
        ]
      },
      "requirements": [
        "Du solltest zuvor schon einmal ein wenig programmiert habe",
        "Es werden weder Kenntnisse in Python, noch in R vorrausgesetzt",
        "Alle benötigen Tools (R, RStudio, Anaconda, ...) installieren wir gemeinsam im Kurs"
      ],
      "description": "Jetzt neu: Zusätzlicher Bonus zum Thema Deep Learning (Neuronale Netze) mit Python, Tensorflow und Keras!\nDieser Kurs enthält über 300 Lektionen, Quizze, Praxisbeispiele, ... - der einfachste Weg, wenn du Machine Learning lernen möchtest.\nSchritt für Schritt bringe ich dir maschinelles Lernen bei. In jedem Abschnitt lernst du ein neues Thema - zuerst die Idee / Intuition dahinter, und anschließend den Code sowohl in Python als auch in R.\nMachine Learning macht erst dann richtig Spaß, wenn man echte Daten auswertet. Deswegen analysierst du in diesem Kurs besonders viele Praxisbeispiele:\nSchätze den Wert von Gebrauchtwagen\nSchreibe einen Spam-Filter\nDiagnostiziere Brustkrebs\nSchreibe ein Programm, was die Bedeutung von Adjektiven lernt\nLese Zahlen aus Bildern ein\nAlle Codebeispiele werden dir beiden Programmiersprachen gezeigt - du kannst also wählen, ob du den Kurs in Python, R, oder in beiden Sprachen sehen möchtest!\nNach dem Kurs kannst du Machine Learning auch auf eigene Daten anwenden und eigenständig fundierte Entscheidungen treffen:\nDu weißt, wann welche Modelle in Frage kommen könnten und wie du diese vergleichst. Du kannst analysieren, welche Spalten benötigt werden, ob zusätzliche Daten benötigt werden, und weißt, die die Daten vorab aufbereitet werden müssen.\nDieser Kurs behandelt alle wichtigen Themen:\nRegression\nKlassifizierung\nClustering\nNatural Language Processing\nBonus: Deep Learning (nur für Python, weil die Tools hier sehr viel ausgereifter sind)\nZu allen diesen Themen lernst du verschiedene Algorithmen kennen. Die Ideen dahinter werden einfach erklärt - keine trockenen, mathematischen Formeln, sondern anschauliche, grafische Erklärungen.\nWir verwenden hierbei gängige Tools (Sklearn, NLTK, caret, data.table, ...), die auch für echte Machine-Learning-Projekte verwendet werden.\nWas lernst du alles?\nRegression:\nLineare Regression\nPolynomiale Regression\nKlassifizierung:\nLogistische Regression\nSupport Vector Machine (SVM)\nSVM mit Kernel (rbf, poly)\nNaive Bayes\nEntscheidungsbäume\nRandom Forest\nClustering\nNatural Language Processing\nTokenizing\nStemming\nPOS-Tagging (welchen Typ hat ein Wort?)\nBonus: Deep Learning / Neuronale Netze (nur Python)\nAufbau eines Neuronalen Netzes\nWas ist ein Neuron?\nTensorflow\nKeras\nZudem lernst du auch, wie du Machine Learning anwendest:\nDimensionsreduktion mit der Principal Component Analysis (PCA)\nLese Daten ein, und bereite sie für dein Modell vor\nMit vollständigem Praxisbeispiel, Schritt für Schritt erklärt\nFinde die besten Hyperparameter für dein Modell\n\"Parameter Tuning\"\nGridSearch (GridSearchCV in Python / tuneGrid in R)\nVergleiche Modelle miteinander:\nWie dich der Wert für die Genauigkeit eines Modells in die Irre führen kann, und was du dagegen tun kannst\nK-Fold Cross-Validation\nBestimmtheitsmaß\nMein Ziel ist es, dir mit diesem Kurs den idealen Einsteig in die Welt des Machine Learnings zu bieten.",
      "target_audience": [
        "Entwickler, die sich für Machine Learning interessieren"
      ]
    },
    {
      "title": "Chat GPT od zera: kompletny kurs dla początkujących",
      "url": "https://www.udemy.com/course/chat-gpt-od-zera-kompletny-kurs-dla-poczatkujacych/",
      "bio": "Praktyczny kurs po polsku i od podstaw | Gotowe zapytania dla biznesu, marketingu, życia, social mediów",
      "objectives": [
        "Dla studenta: jak przygotować się na rozmowę kwalifikacyjną, jak mieć osobistego nauczyciela j. obcego, jak tworzyć gotowe prace domowe, jak pisać przemowy",
        "Dla twórców social mediów: jak pisać skuteczne wpisy, jak stworzyć plan wpisów na cały rok, jak napisać własnego ebooka",
        "Dla programistów: jakich używać wtyczek by automatyzować pracę, jak pisać dowolny kod programów, jak przeprwoadzać lepsze testy oprogramowania",
        "Dla sprzedawców: jak badać nisze, jak generować gotowe maile, jak stworzyć kampanię marketingową za pomocą AI",
        "Czego nie robić: jakie pisać zapytania, które zawsze dają skuteczną odpowiedź, jak precyzować zapytania",
        "Jakie dodatki zainstalować: jakie addony dadzą ci możliwość generowania obrazów, podcastów, animacji za pomocą AI"
      ],
      "course_content": {
        "Wstęp": [
          "Intro kursu",
          "Wprowadzenie do Open AI oraz Chat GPT",
          "Przykłady zastosowań Chat GPT - o czym będziemy mówić?",
          "Rejestracja i logowanie do Chat GPT",
          "Omówienie interfejsu",
          "Problemy, które mogą wystąpić podczas używania Chat GPT"
        ],
        "Chat GPT dla studentów i uczniów": [
          "Chat GPT jako nauczyciel języka obcego",
          "Chat GPT jako pomoc w rozwiązywaniu pracy domowej",
          "Chat GPT do poprawy pisanego tekstu",
          "Chat GPT dla lepszej rozmowy kwalifikacyjnej",
          "Chat GPT do generowania wystąpień",
          "Chat GPT dla zwiększenia swojej produktywności"
        ],
        "Chat GPT dla Social Mediów": [
          "Chat GPT do pisania social mediów",
          "Chat GPT do tworzenia materiałów video",
          "Chat GPT do tworzenia własnych ebooków"
        ],
        "Chat GPT dla sprzedawców i marketingu": [
          "Chat GPT dla sprzedawców",
          "Chat GPT dla marketingu",
          "Chat GPT dla SEO"
        ],
        "Chat GPT dla zaawansowanych": [
          "Skuteczne wtyczki do Chrome wykorzystujące potencjał Chat GPT",
          "Chat GPT dla programistów i testerów",
          "Jak wykorzystać Chat GPT do podcastów i video?",
          "Tego nie rób! - jak pisać skuteczne zapytania do Chat GPT",
          "Umiem ChatGPT ale... co dalej?"
        ]
      },
      "requirements": [
        "Brak wymagań wstępnych innych niż chęć nauczenia się jak korzystać z AI i ChatGPT",
        "Telefon lub komputer z dostępem do Internetu"
      ],
      "description": "Czy jesteś osobą, która dopiero zaczyna swoją przygodę z Chat GPT?\nA może masz już jakąś wiedzę ale chcesz rozwinąć ją jeszcze mocniej?\nTrafiłeś idealnie!\nZapraszam cię na kurs, który nauczy cię najważniejszych i najciekawszych zastosowań Chat GPT\nPrzygotowałem dla ciebie praktyczny materiał, który pokaże Ci jak używać Chat GPT:\ndo pomocy w rozmowie kwalifikacyjnej (np. przygotowując Cię do takiej rozmowy)\ndo pisania tekstów (np. gotowych maili, opracowań, felietonów)\ndo nauki języka obcego (np. jako twój prywatny nauczyciel)\ndo tworzenia własnego ebooka (np. pisząc za ciebie cały materiał; pokażę Ci jak to zrobić)\ndo optymalizacji SEO (np. sugerując jak zoptymalizować stronę)\ndo programowania i testowania kodu (np. pisząc za ciebie gotowe programy),\ndo pisania gotowych wzorów sprzedażowych (np. pisania opinii, opisów produktów na sprzedaż,\ndo tworzenia materiałów na social mediach (np. gotowe scenariusze filmów na YouTube)\nA dodatkowo pokażę Ci mnóstwo przydatnych dodatków do Chrome (rozszerzających możliwości Chat GPT na inne strony internetowe).\nPo ukończeniu kursu będziesz miał profesjonalną wiedzę na temat ChatGPT (czym jest, jak działa) i będziesz mógł tworzyć wysokiej jakości treści (pokażę Ci jak pisać i NIE PISAĆ zapytań).\nDzięki materiałom w kursie nauczysz się oszczędzać czas i pieniądze.\nZapisz się już dziś na ChatGPT Masterclass i zacznij wykorzystywać moc sztucznej inteligencji w swojej firmie, pracy lub życiu.",
      "target_audience": [
        "Każdy, kto jest zainteresowany wykorzystaniem AI do usprawnienia swojej pracy lub biznesu",
        "Studenci i uczniowe, którzy chcą ułatwić sobie naukę oraz rozwiąznywanie pracy domowych",
        "Sprzedwcy oraz marketing, który chce zwiększyść skuteczność sprzedaży, jakość pisanych emaili",
        "Programiści, którym zależy na lepszej jakości kodu (oraz testów)",
        "Blogerzy, twórcy treści dla social mediów, którzy chcą poprawić jakość i wydajność swojego pisania"
      ]
    },
    {
      "title": "米国データサイエンティストが教える統計学超入門講座【Pythonで実践】",
      "url": "https://www.udemy.com/course/python-stats/",
      "bio": "米国で現役で働くデータサイエンティストがゼロからやさしく教えます．学習した統計学の理論をPythonで実装するので即実務に適用可能です",
      "objectives": [
        "Pythonで実際のデータを統計解析ができるようになります",
        "統計学の基本的な理論を学べます",
        "統計学の理論をPythonで実装できるようになります",
        "DockerとJupyterLabを使った本格的なデータサイエンスの環境で解析できるようになります"
      ],
      "course_content": {
        "紹介": [
          "紹介"
        ],
        "準備": [
          "本セクション補足",
          "環境構築概要(Docker + JupyterLab)",
          "M1チップをお使いの方へ",
          "DockerHubアカウント作成",
          "Windowsユーザへの補足",
          "Docker環境構築",
          "Dockerの基本操作",
          "次レクチャーの補足",
          "JupyterLabの基本操作",
          "データ準備"
        ],
        "記述統計": [
          "本講座の資料とコード",
          "分布(distribution)",
          "Pythonの実装レクチャーを受ける前に",
          "分布(distribution)【Python】",
          "記述統計と推測統計",
          "平均(mean)",
          "平均(mean)【Python】",
          "中央値(median)",
          "中央値(median)【Python】",
          "最頻値(mode)",
          "最頻値(mode)【Python】",
          "範囲(range)",
          "範囲(range)【Python】",
          "四分位数(quartile)",
          "四分位数(quartile)【Python】",
          "平均偏差(MD)",
          "分散(variance)",
          "標準偏差(standard deviation)",
          "分散と標準偏差【Python】",
          "セクションまとめ"
        ],
        "2変数間の記述統計": [
          "共分散(covariance)",
          "共分散(covariance)【Python】",
          "正の相関と負の相関",
          "相関係数(correlation coefficient)",
          "相関係数(correlation coefficient)【Python】",
          "連関(association)",
          "カイ二乗",
          "分割表とカイ二乗値【Python】",
          "クラメールの連関係数",
          "クラメールの連関係数【Python】",
          "セクションまとめ"
        ],
        "確率": [
          "確率とは",
          "確率変数(random variable)",
          "確率分布(probability distribution)",
          "確率分布(probability distribution)【Python】",
          "離散型と連続型",
          "確率分布(probability distribution)【Python】",
          "確率密度と確率",
          "累積分布関数(CDF)",
          "累積分布関数(CDF)【Python】",
          "正規分布(normal distribution)",
          "正規分布(normal distribution)【Python】",
          "カーネル密度推定(KDE)",
          "カーネル密度推定(KDE)【Python】",
          "セクションまとめ"
        ],
        "正規分布と標準化": [
          "本セクション概要",
          "68-95-99.7ルール",
          "68-95-99.7ルール【Python】",
          "標準化(standardize)",
          "偏差値(T-score)",
          "標準正規分布",
          "標準化(standardize)【Python】",
          "二項分布(binomial distribution)",
          "二項分布(binomial distribution)【Python】",
          "二項分布と正規分布",
          "二項分布と正規分布【Python】",
          "セクションまとめ"
        ],
        "推測統計入門": [
          "母集団(population)と標本(sample)",
          "標本分布(sampling distribution)",
          "推定量(estimator)",
          "不偏性(unbiasedness)",
          "平均の標本分布",
          "平均の標本分布【Python】",
          "不偏分散(unbiased variance)",
          "不偏分散の平方根",
          "不偏分散(unbiased variance)【Python】",
          "不偏分散の不偏性【Python】",
          "セクションまとめ"
        ],
        "区間推定": [
          "区間推定とは",
          "信頼区間(CI)",
          "比率の標本分布",
          "比率の区間推定",
          "比率の区間推定まとめ",
          "比率の区間推定【Python】",
          "比率の区間推定Challenge【Python】",
          "平均値の区間推定",
          "標本分布の標準化",
          "平均値の区間推定(Z分布)【Python】",
          "t分布",
          "t分布【Python】",
          "平均値の区間推定(t分布)【Python】",
          "平均値の区間推定まとめ"
        ],
        "統計的仮説検定とは": [
          "統計的仮設検定とは",
          "帰無仮説と対立仮説",
          "統計的仮説検定の流れ"
        ],
        "2群の比率差の検定(Z検定)": [
          "比率差の検定とは",
          "比率差の検定の帰無仮説と対立仮説",
          "標本観察",
          "比率差の標本分布",
          "帰無仮説を正しいとした場合の標本分布",
          "有意水準(α)",
          "標本分布の標準化",
          "共通の母比率の推定",
          "p値(p value)",
          "補足レクチャー",
          "検定結果の解釈",
          "比率差の検定まとめ",
          "2群の比率差の検定【Python】"
        ]
      },
      "requirements": [
        "統計学，数学の知識は不要です．",
        "Mac推奨としてますが，環境を構築できればWindowsでも問題ありません．",
        "Pythonの実装については，Pythonの基礎知識およびデータサイエンスに必要なライブラリの知識が必要です",
        "Pythonの知識がなくても本講座で統計学の理論を学習することができます"
      ],
      "description": "統計学の基礎をゼロから学べます．学習した理論をPythonでどのように実際のデータに適用できるのかも学習でき，理論x実装の相乗効果で確実に統計学を習得できます．\n【特徴】\n- 米国で働く現役データサイエンティストから学ぶ\n- 統計学や数学の知識は不要\n- 全くの未経験者でも本講座を受講すれば統計学の基本を理解することができる\n- Pythonでの実装も紹介\n- 学習したことをすぐに実データに適用可能\n- DockerとJupyterLabを使った本格データサイエンス環境 (Dockerを使って簡単環境構築)\n- これ1本で理論x実装が同時に，着実に学べる\n\n\n統計学の理論とPythonの実装のレクチャーは別になっているため，理論だけを学習することも可能です．そのためPythonを知らなくても本講座で統計学を学ぶことができます．\n\n\nPythonの実装のレクチャーは，Pythonの基礎知識とデータサイエンスに必要なPython(NumpyやPandasなど)の知識が必要です．\nMacを使って講義を進めますが，環境が作れればWindowsでも問題ありません．\nDockerとJupyterLabを使った本格的なデータサイエンスの環境を使いますが，WindowsでDocker環境を作れれば，全く同じ環境を構築することができます．(Windowsでの環境構築のサポートはしておりません．あらかじめご了承ください)",
      "target_audience": [
        "統計学を必要とする全ての人(ビジネスマン，研究者，エンジニア, 経営者, etc...)",
        "AI開発やデータサイエンスに興味がある人"
      ]
    },
    {
      "title": "Python OpenCV ile Sıfırdan Uzmanlığa Görüntü İşleme (Gİ-1)",
      "url": "https://www.udemy.com/course/python-opencv-ile-sfrdan-uzmanlga-goruntu-isleme-gi-1/",
      "bio": "Gerçek Hayat Problemleri, Python, OpenCV, MediaPipe ile Görüntü İşlemeye Etkili Bir Başlangıç Yapın ve Uzmanlaşın (2022)",
      "objectives": [
        "Python dilinin görüntü işlemede kullanılan temel kütüphanelerinden olan OpenCV kütüphanesini",
        "Google tarafından geliştirilen MediaPipe kütüphanesini kullanarak görüntü işlemeyi",
        "Gerçek hayatta karşımıza çıkacak görüntü işleme problemlerini çözmeyi",
        "El takibi, parmak sayma, poz tahmini, kişisel antrenör, yüz tanıma, park yeri sayacı, yol çizgisi ve uyku algılama gibi projeleri yapmayı",
        "OpenCV ile köşe, kenar, kontur algılama gibi temel nesne tespiti algoritmalarını"
      ],
      "course_content": {
        "Giriş": [
          "Python OpenCV ile Sıfırdan Uzmanlığa Ders Programı",
          "Kurulumlar",
          "Datai Team Kaynaklar - Kurs Materyalleri",
          "Makaleler, Faydalı Linkler ve Referanslar"
        ],
        "Python Hatırlatma": [
          "Python Hatırlatma Giriş",
          "Spyder Tanıtımı",
          "Değişkenler",
          "Python Temel Sözdizimi",
          "Liste",
          "Tuple",
          "Deque",
          "Dictionary",
          "Koşullu İfadeler: if - else",
          "Döngüler: for - while",
          "Fonksiyonlar",
          "Yield",
          "Numpy Kütüphanesi",
          "Pandas Kütüphanesi",
          "Matplotlib Kütüphanesi",
          "OS Kütüphanesi"
        ],
        "OpenCV ile Görüntü İşleme": [
          "OpenCV ile Görüntü İşleme Giriş",
          "Resmi İçe Aktarma",
          "Video İçe Aktarma",
          "Kamera Açma ve Video Kaydı",
          "Yeniden Boyutlandır ve Kırp",
          "Şekiller ve Metin",
          "Görüntülerin Birleştirilmesi",
          "Perspektif Çarpıtma",
          "Görüntüleri Karıştırmak",
          "Görüntü Eşikleme",
          "Bulanıklaştırma",
          "Morfolojik Operasyonlar",
          "Gradyanlar",
          "Histogram",
          "OpenCV ile Görüntü İşleme Ödevi",
          "OpenCV ile Görüntü İşleme Ödevi - Cevapları"
        ],
        "Görüntü İşleme Projeleri": [
          "Görüntü İşleme Projeleri Giriş",
          "El Takibi (Hand Tracking)",
          "Parmak Sayma (Finger Counting)",
          "Poz Kestirimi (Pose Estimation)",
          "Kişisel Antrenör (Personal Trainer)",
          "Yüz Tespiti (Face Detection)",
          "Yüz Mesh (Face Mesh)",
          "Otopark Park Alanı Sayma (Parking Space Counter)",
          "Yol Çizgisi Tespiti (Road Line Detection)",
          "Uyku Algılama (Sleep Detection)",
          "Görüntü İşleme Projeleri Sonuç"
        ],
        "Python OpenCV ile Sıfırdan Uzmanlığa Sonuç": [
          "Python OpenCV ile Sıfırdan Uzmanlığa Sonuç",
          "BONUS"
        ]
      },
      "requirements": [
        "Hedefler ve gelecekle ilgili güzel hayaller"
      ],
      "description": "Python OpenCV ile Sıfırdan Uzmanlığa Görüntü İşleme (Gİ-1)\nBu kurs 4 Adımlık Görüntü İşleme Yolculuğunun ilk adımını oluşturmaktadır.\nGörüntü işleme kursunda klasik ve veri tabanlı derin öğrenme yöntemlerini kullanarak nesne tespiti, sınıflandırma ve takibinin nasıl yapıldığını öğrenip, keras ve opencv kütüphaneleriyle gerçek hayat projeleri yapacağız.\nDerin Öğrenme ile Görüntü İşleme Kursu İçeriği\nGiriş Bölümü\nDerin Öğrenme ile Görüntü İşleme Ders Programı\nPython Kurulumlar\nKaynaklar: Kodlar\nMakaleler, Faydalı Linkler ve Referanslar\nPython Hatırlatma\nSpyder Tanıtımı\nDeğişkenler\nPython Temel Sözdizimi\nListe\nTuple\nDeque\nDictionary\nIf - Else\nDöngüler: for - while\nFonksiyonlar\nYield\nNumpy Kütüphanesi\nPandas Kütüphanesi\nMatplotlib Kütüphanesi\nOS Kütüphanesi\nOpenCV ile Görüntü İşleme\nOpenCV ile Görüntü İşleme Giriş\nResmi İçe Aktarma\nVideo İçe Aktarma\nKamera Açma ve Video Kaydı\nYeniden Boyutlandır ve Kırp\nŞekiller ve Metin\nGörüntülerin Birleştirilmesi\nPerspektif Çarpıtma\nGörüntüleri Karıştırmak\nGörüntü Eşikleme\nBulanıklaştırma\nMorfolojik Operasyonlar\nGradyanlar\nHistogram\nGörüntü İşleme Projeleri\nEl Takibi (Hand Tracking)\nParmak Sayma (Finger Counting)\nPoz Kestirimi (Pose Estimation)\nKişisel Antrenör (Personal Trainer)\nYüz Tespiti (Face Detection)\nYüz Mesh (Face Mesh)\nOtopark Park Alanı Sayma (Parking Space Counter)\nYol Çizgisi Tespiti (Road Line Detection)\nUyku Algılama (Sleep Detection)\nNeden Python?\nPython 2022 IEEE araştırmasına göre dünya çapında en çok kullanılan ve tercih edilen programlama dillerinden\nPython kolay öğrenilebilirliği sayesinde kodlamaya yeni başlayanların ilk tercihi oluyor.\nPython open source (açık kaynak) olması nedeni ile Facebook yada Google gibi dünyanın en büyük şirketleri tarafından destekleniyor.\nGörüntü işleme, veri bilimi, makine öğrenmesi yada yapay zeka denince akla ilk olarak Python dili geliyor. Bu durumda Python'ın dünya çapında büyük bir kitlesinin olmasına neden oluyor.\nPython öğrenmesi en kolay olan dillerin başında geliyor.\nKariyer açısından Python en çok fırsata sahip dillerinden biri.\nNeden Görüntü İşleme?\nGörüntü işleme, bir görüntü üzerinde bazı işlemler gerçekleştirmek, gelişmiş bir görüntü elde etmek veya ondan bazı yararlı bilgiler çıkarmak için kullanılan bir yöntemdir.\nOptimize edilmiş bir iş akışı elde etmek ve zaman kaybını önlemek için, görüntülerin bir işlem sonrası adımında işlenmesi önemlidir.\nGörüntü işleme bilgisine sahip olmak iş hayatında fark yaratacak.\nDünyada bulunan iki temel veriden biri görüntüdür. Görüntü işleme bilgisi pek çok farklı alanda sizi bir adım öne geçirecektir.\nBu Kurs ile Alacaklarınız\nSıfırdan Kodlama Becerisi: Sizinle birlikte kod yazıyoruz. Her ders boş bir sayfa ile başlar ve kodu sıfırdan yazarız. Bu şekilde ilerleyebilir ve kodun nasıl bir araya geldiğini ve her satırın ne anlama geldiğini tam olarak anlayabilirsiniz.\nKodlar ve Şablonları: Kursta oluşturduğumuz her Python şablonlarını ve kodunu indirebilirsiniz. Bu, sizlere hem daha sonra kod üzerinde pratik yapma hem de kendi projelerinizi şablon sayesinde daha kolay bir şekilde yaratma imkanı sağlayacaktır\nTeori ve Mantık: Size yalnızca kod yazmayı değil, hem yazdığımız kodun arkasında yatan mantığı ve teoriyi hem de neden böyle bir kod yazdığımızı anlatıyoruz.\nKurs içi destek: Size sadece video ile ders anlatımı yapmıyoruz. Size destek olmak için profesyonel Veri Bilimcilerinden oluşan bir ekip oluşturduk. Bu da ders ve ya ders dışı sorularınıza en fazla 72 saat içinde yanıt alacağınız anlamına geliyor.\nHemen kaydolun ve bir an önce başlayalım.",
      "target_audience": [
        "4 Adımlık Görüntü İşleme Yolculuğu serisinin ilk adımını tamamlamak isteyenler",
        "Görüntü işleme temelleri konusunda uzmanlaşmak isteyenler",
        "Temel görüntü işleme kütüphanesi olan OpenCV ve MediaPipe ile gerçek hayat projeleri yapmak isteyenler",
        "İnternette bulunan popüler projeler sayesinde görüntü işleme öğrenmek isteyenler",
        "Görüntü işleme konusunda derli toplu kaynak bulamayanlar"
      ]
    },
    {
      "title": "オンライン講座を利用して機械学習・人工知能（AI）・ データ分析の最適な学び方を学ぶ講座",
      "url": "https://www.udemy.com/course/ai-guidline/",
      "bio": "本サイトに登録されている各種講座を利用して、機械学習・人工知能（AI）・ データ分析を学習している／するつもりの全ての方に、効果的な講座の組合せ方や進め方をお教えします。",
      "objectives": [
        "AI活用／AI開発とはどのようなものなのか理解します。",
        "あなた自身が学ぶべきスキルを理解するために、AI開発プロジェクトに必要なAIスキル体系を理解します。",
        "あなた自身がデータサイエンティストを目指すために、AIスキル獲得のためにUdemy講座を利用したスキル獲得方法をお教えします。",
        "Udemyの代表的なAI／機械学習／データ分析系の講座と学べる範囲について理解します。"
      ],
      "course_content": {
        "はじめに": [
          "はじめに",
          "講師紹介"
        ],
        "AI開発／AIスキルの全体像の把握": [
          "AI開発の基礎",
          "AIのスキル体系",
          "AI開発プロジェクトの全体像",
          "AI活用におけるビジネス力"
        ],
        "求めるべきAIスキルとそのトレンド": [
          "AI人材のタイプ",
          "AIの民主化トレンド",
          "AIスキルロードマップの説明"
        ],
        "AIビジネススキルの獲得": [
          "企業として取り組むべき AI人材育成",
          "AI競争の中の日本",
          "AI戦略立案"
        ],
        "ボーナスレクチャー": [
          "ボーナスレクチャー",
          "参照コース"
        ]
      },
      "requirements": [
        "前提知識は全く必要としていません。"
      ],
      "description": "あなたはUdemyの人工知能／機械学習系の講座選択やスキル獲得方法に悩まれていませんか？\nUdemyなどのオンライン講座は安く気軽に人工知能を学ぶ講座が提供されている一方で、体系立てて講座が提供されていないため、どのように講座を選択し、スキルアップを進めていけばよいのか不明確なところが欠点となっています。\n本講座では機械学習・人工知能関連の様々なオンライン講座／オフライン講座を実際に学習し、自身も人工知能講座を提供している講師により、最適な講座選択や、AIスキル獲得の仕方をお教えするガイドラインとなる講座です。\n本講座を利用して、Udemyを利用したAIスキルの獲得を効果的に進めてください。",
      "target_audience": [
        "Udemyを利用してAIスキル獲得／AI人材育成をを目指す全ての方へ"
      ]
    },
    {
      "title": "【한글자막】 딥러닝의 모든 것 with Python, Tensorflow, Pytorch",
      "url": "https://www.udemy.com/course/best-artificial-neural-networks/",
      "bio": "ANN, CNN, RNN, SOM, Boltzmann Machine, Stacked AutoEncoder 등 딥러닝 최신 모델을 실제 데이터셋으로 구현해보며 개념부터 적용까지 완벽 마스터",
      "objectives": [
        "딥러닝 핵심 모델에 대한 깊은 이해와 실제 데이터 적용 실습",
        "ANN(인공 신경망) 모델의 이해와 적용",
        "CNN(합성곱 신경망) 모델의 이해와 적용",
        "RNN(순환 신경망) 모델의 이해와 적용",
        "SOM(자기조직화지도)의 이해와 적용",
        "볼츠만 머신의 이해와 적용",
        "AutoEncoder의 이해와 적용"
      ],
      "course_content": {
        "본 과정에 오신 것을 환영합니다": [
          "딥러닝이란?",
          "데이터 세트 및 강의 슬라이드 다운로드",
          "열심히 공부하고 보상 받기 챌린지!"
        ],
        "--------------------- 1부: ANN (Artificial Neural Networks) ---------------------": [
          "1부: ANN에 오신 것을 환영합니다"
        ],
        "ANN 직관": [
          "ANN을 위해 필요한 것",
          "공략 계획",
          "뉴런",
          "활성화 함수",
          "신경망은 어떻게 작동하는가",
          "신경망은 어떻게 학습하는가",
          "경사하강법",
          "확률적 경사하강법",
          "역전파"
        ],
        "ANN 구축하기": [
          "코드와 데이터셋 미리 준비하기",
          "ANN 구축하기 - 1단계",
          "ANN 회귀에 대한 무료 강좌를 확인하세요",
          "ANN 구축하기 - 2단계",
          "ANN 구축하기 - 3단계",
          "ANN 구축하기 - 4단계",
          "ANN 구축하기 - 5단계"
        ],
        "-------------------- 2부- CNN(Convolutional Neural Networks) --------------------": [
          "2부 - CNN(Convolutional Neural Networks)에 오신 것을 환영합니다"
        ],
        "CNN 직관": [
          "CNN을 위해 필요한 것",
          "공략 계획",
          "컨볼루션 신경망(CNN)이란 무엇인가",
          "1단계 - 컨볼루션 연산",
          "1(b)단계 - ReLU 계층",
          "2단계 - 풀링",
          "3단계 - 평평하게 하기",
          "4단계 - 전체 연결",
          "요약",
          "소프트맥스와 교차 엔트로피"
        ],
        "CNN 구축하기": [
          "코드와 데이터셋 미리 준비하기",
          "CNN 구축하기 - 1단계",
          "CNN 구축하기 - 2단계",
          "CNN 구축하기 - 3단계",
          "CNN 구축하기 - 4단계",
          "CNN 구축하기 - 5단계",
          "CNN 구축하기 - 최종 데모!"
        ],
        "---------------------- 3부 - RNN(Recurrent Neural Networks) ---------------------": [
          "3부 - RNN(Recurrent Neural Networks)에 오신 것을 환영합니다"
        ],
        "RNN 직관": [
          "RNN을 위해 필요한 것",
          "공략 계획",
          "RNN에 대한 아이디어",
          "소멸하는 기울기 문제",
          "LSTM",
          "실용적인 직관",
          "추가: LSTM 변형"
        ],
        "RNN 구축하기": [
          "중요 사항",
          "RNN 구축하기 - 1단계",
          "RNN 구축하기 - 2단계",
          "RNN 구축하기 - 3단계",
          "RNN 구축하기 - 4단계",
          "RNN 구축하기 - 5단계",
          "RNN 구축하기 - 6단계",
          "RNN 구축하기 - 7단계",
          "RNN 구축하기 - 8단계",
          "RNN 구축하기 - 9단계",
          "RNN 구축하기 - 10단계",
          "RNN 구축하기 - 11단계",
          "RNN 구축하기 - 12단계",
          "RNN 구축하기 - 13단계",
          "RNN 구축하기 - 14단계",
          "RNN 구축하기 - 15단계"
        ]
      },
      "requirements": [
        "미분, 기울기 등 고등학교 수준의 수학 지식",
        "Python 기초 문법에 대한 이해"
      ],
      "description": "모델 개발 및 유지 보수 프로세스를 단순화해주는 TensorFlow 2.0의 최신 기능들\nTensorFlow 2.0을 통해 핵심적인 신경망 모델들을 학습시키고, 실제 서비스로 운영하는 방법\nTensorFlow Extended(TFX)로 자신만의 데이터 파이프라인을 구축하는 법\n\n\n—————\n\n[딥러닝 학습을 위한 가장 최적의 커리큘럼]\n이 코스를 준비하면서 가장 중요하게 생각한 것은 탄탄한 커리큘럼입니다. 딥 러닝은 매우 광범위하고 복잡한 개념이기 때문에, 정확하고 탄탄한 커리큘럼으로 학습을 시작하지 않으면 뒤로 갈수록 학습이 힘들어집니다.\n\n\n그래서, 이 코스는 딥러닝 학습을 가장 체계적이고 탄탄하게 할 수 있도록 강의 내용을 구조화했습니다. 모든 딥러닝 모델에 대해서 ‘왜 이 기술이 필요한가?’에서 학습을 출발하고, 각 모델의 심층적인 이론에 대해 깊이 있게 다룹니다.\n\n\n이러한 깊이 있고 탄탄한 이론 학습을 통해 특정 딥러닝 모델에 대해 정확하게 이해하고 있다는 확신을 가질 수 있습니다. 이러한 확신은 실습으로 코딩 연습을 진행하면 더 강해질 것입니다.\n\n\n\n\n[실제 데이터셋을 활용한 프로젝트 학습]\n오래된 학습 데이터 세트를 기반으로 딥러닝을 배우는 과정이 지겹지 않나요? 이 강의는 다릅니다. 이 강의는 비즈니스 문제를 해결하기 위해 구성되어 있는 실제 데이터 세트를 통해 프로젝트를 진행합니다.\n\n\n이 강의에서는 6가지 실제 비즈니스 사례에서 사용된 데이터셋을 사용하여 아래의 사항들을 해결해봅니다.\n\n\n고객 이탈 문제를 해결하는 ANN 모델\n이미지 인식을 위한 CNN 모델\n주가를 예측하는 RNN 모델\n사기 조사를 위한 SOM\n추천 시스템을 만드는 Boltzmann Machine\n넷플릭스 상금 100만 달러 챌린지를 위한 Stacked AutoEncoder\n\n\n이 모든 데이터셋을 가지고 딥러닝 모델을 만드는 과정을 빈 코드 에디터 페이지부터 시작해 함께 작성해봅니다. 실제로 코드를 치고, 고민하는 과정을 통해 코드가 어떻게 구성되고 각 행의 의미가 정확하게 무엇인지를 완벽하게 이해할 수 있습니다.\n\n\n\n[딥러닝 구현을 위한 도구 완전 정복]\n딥러닝 구현을 위한 핵심 라이브러리인 TensorFlow, Pytorch 모두를 이 코스를 통해 다뤄볼 수 있습니다. 단순히 도구를 활용만 하는게 아니라, TensorFlow와 Pytorch 각각을 더 잘 사용하고, 어떤 상황에서 어떤 도구를 사용하는게 더 좋은지 그 맥락을 이해할 수 있게 해드립니다. 또한, Theano와 Keras 등 복잡한 딥러닝 모델을 보다 효과적으로 구현하도록 도와주는 최신 도구들까지 다뤄볼 수 있습니다.\n\n\n이외에도 머신러닝 구현을 위한 Scikit-Learn 라이브러리와, 데이터 전처리를 위해 사용되는 Pandas에 대해서도 다양하게 활용해볼 수 있습니다. Numpy도 물론 사용합니다. Matplotlib을 통한 데이터 시각화도 다루고 있어서, 딥러닝 할 데이터를 다루기 위해 필요한 모두 도구들에 대해서 실습을 해볼 수 있습니다.\n\n\n\n\n[200만 수강생의 데이터 사이언스 학습을 도운 Ligency Team의 한 마디]\n한국 수강생 여러분 안녕하세요!\n전문 데이터 사이언티스트들로 구성된 교육 기관, Ligency Team입니다.\n저희의 [딥러닝의 모든 것 with Python, Tensorflow, Pytorch] 코스에 오신 것을 환영합니다!\n\n\n인공 지능은 기하급수적으로 성장하고 있습니다. 의심의 여지가 없습니다. 자율주행 자동차는 수백만 마일의 속도를 기록하고 있으며 IBM Watson은 의사보다 환자를 더 잘 진단하고 있고 Google Deepmind의 AlphaGo는 직관이 중요한 게임인 바둑에서 세계 챔피언을 이겼습니다.\n\n\n그러나 AI가 발전할수록 해결해야 할 문제는 더욱 복잡해집니다. 그리고 딥 러닝만이 이러한 복잡한 문제를 해결할 수 있고 이것이 인공 지능의 핵심인 이유입니다.\n\n\n이 코스는 딥러닝을 학습하기 위한 직관 튜토리얼, 실습 및 실제 사례 연구로 가득 찬 흥미진진한 교육 프로그램입니다.\n\n\n우리는 딥러닝에 대해 매우 열정적입니다. 우리는 이 코스를 지구상에서 가장 강력한 딥러닝 교육 과정으로 만들기 위해 최선을 다하고 있습니다. 우리에겐 당신이 우리의 도움이 필요할 때 항상 거기에 있어야 할 책임이 있습니다. 그래서, 모든 질문에 대해 48시간 이내에 답변을 드릴 수 있는 최고의 데이터 사이언티스트 조교 팀을 운영하고 있습니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남겨주세요. 대신, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n이 코스를 통해 딥러닝의 세계에 빠져보시기 바랍니다\n수업에서 뵙죠!\n\n\n- Ligency Team",
      "target_audience": [
        "딥러닝에 관심 있는 누구나",
        "고등학교 수학 지식이 있고 머신러닝을 시작하려는 학생",
        "선형 회귀 또는 로지스틱 회귀와 같은 고전적인 알고리즘과 인공 신경망과 같은 고급 주제를 포함하여 머신러닝 또는 딥러닝의 기초를 알고 있지만 이에 대해 더 배우고 싶어하는 중급 수준의 학습자",
        "코딩이 익숙하지 않으나 딥러닝에 관심이 있고 데이터셋에 쉽게 적용하고 싶은 분",
        "데이터 사이언스 분야에서 경력을 시작하려는 취업준비생",
        "머신러닝의 수준을 높이고자 하는 모든 데이터 분석가",
        "자신의 직업에 만족하지 않고 데이터 사이언스 분야로 이직을 꿈꾸는 모든 사람",
        "강력한 머신러닝 도구를 사용하여 비즈니스에 부가가치를 창출하려는 모든 사람",
        "자신의 비즈니스에서 딥러닝 기술을 활용하는 방법을 이해하려는 모든 비즈니스 소유자"
      ]
    },
    {
      "title": "R : ¡Data Science y Análisis de Datos con Ejercicios Reales!",
      "url": "https://www.udemy.com/course/tutorial-r/",
      "bio": "Aprende a utilizar R y R Studio para tu trabajo. Análisis de Datos, Data Science, Análisis Estadístico, GGPlot2 y más",
      "objectives": [
        "Aprenderás a usar R para Analizar tus Datos",
        "Crearás Gráficos que Cautivarán a tu Audiencia",
        "Practicarás con datos financieros, de deportes, de películas y financieros",
        "Aprenderás a programar en R usando R Studio",
        "Aprenderás los principios básicos de programación",
        "Aprenderás a personalizar R Studio a tus necesidades",
        "Practicarás con datos financieros, de deportes, de películas y financieros",
        "Vas a poder crear tus propias funciones en R",
        "Aprenderás los tipos de datos en R"
      ],
      "course_content": {
        "Arrancando a Toda Velocidad": [
          "¡Bienvenido al Curso!",
          "Instalando R y R Studio",
          "Ejercicio para Emocionarse!"
        ],
        "Principios Básicos de Programación": [
          "Bienvenido a Principios Básicos de Programación",
          "Tipos de Datos",
          "Usando Variables",
          "Variables y Operadores Lógicos",
          "El Ciclo \"While\"",
          "Usando la Consola",
          "El Ciclo \"For\"",
          "El Condicional \"If\"",
          "RECAP Sección 2: Principios Básicos de Programación",
          "PRÁCTICA: La Ley de los Grandes Números",
          "QUIZ Sección 2: Principios Básicos de Programación"
        ],
        "Fundamentos de R": [
          "Bienvenido a Fundamentos de R",
          "¿Qué es un vector?",
          "A crear algunos vectores",
          "Usando los Corchetes []",
          "Operaciones con Vectores",
          "El Poder de las Operaciones con Vectores",
          "Funciones en R",
          "Paquetes en R",
          "RECAP Sección 3: Fundamentos de R",
          "PRÁCTICA: Análisis de Estados Financieros",
          "QUIZ Sección 3: Fundamentos de R"
        ],
        "Matrices": [
          "Bienvenido a Matrices",
          "Resumen del Proyecto: Tendencias de Basketball",
          "Matrices",
          "Construyendo tu Primer Matriz",
          "Nombrando Dimensiones",
          "Colnames() y Rownames()",
          "Operaciones con Matrices",
          "Visualizando con Matplot()",
          "Subconjuntos (Subsetting)",
          "Visualizando los Subconjuntos",
          "Creando tu Primer Función",
          "Insights de Basketball",
          "RECAP Sección 4: Matrices",
          "PRÁCTICA: Tiros Libres en Basketball",
          "QUIZ Sección 4: Matrices"
        ],
        "Marcos de Datos (Data Frames)": [
          "Bienvenido a Marcos de Datos (Data Frames)",
          "Resumen del Proyecto: Análisis Demográfico",
          "Importando Datos a R",
          "Explorando tu Set de Datos",
          "Usando el Símbolo $",
          "Operaciones Básicas con un Marco de Datos",
          "Filtrando un Marco de Datos",
          "Introducción a qplot()",
          "Visualizando con qplot: Parte 1",
          "Construyendo Marcos de Datos",
          "Combinando Marcos de Datos",
          "Visualizando con qplot: Parte 2",
          "RECAP Sección 5: Marcos de Datos (Data Frames)",
          "PRÁCTICA: Tendencias Globales",
          "QUIZ Sección 5: Data Frames"
        ],
        "Visualizaciones Avanzadas con GGPlot2": [
          "Bienvenido a Visualizaciones Avanzadas con GGPlot2",
          "Resumen del Proyecto: Ratings de Películas",
          "Gramática de Gráficos",
          "Factores",
          "Estéticas",
          "Graficando con Capas",
          "Sobrescribiendo Estéticas",
          "Mapeando vs Estableciendo",
          "Histogramas y Gráficos de Densidad",
          "Tips para Capa Inicial",
          "Transformaciones Estadísticas",
          "Usando Facetas",
          "Coordenadas",
          "Agregando Temas",
          "RECAP Sección 6: Visualizaciones Avanzadas con GGPlot2",
          "PRÁCTICA: Películas - % Ventas Estados Unidos",
          "QUIZ Sección 6: Visualizaciones Avanzadas con GGPlot2"
        ],
        "Respuesta a las Prácticas": [
          "Respuesta Práctica Sección 2: Ley de los Grandes Números",
          "Respuesta Práctica Sección 3: Análisis de Estados Financieros",
          "Respuesta Práctica Sección 4: Tiros Libres en Basketball",
          "Respuesta Práctica Sección 5: Tendencias Globales",
          "Respuesta Práctica Sección 6: Películas - % Ventas Estados Unidos (Parte 1)",
          "Respuesta Práctica Sección 6: Películas - % Ventas Estados Unidos (Parte 2)"
        ],
        "BONUS": [
          "Box Plots"
        ]
      },
      "requirements": [
        "No se necesitan conocimientos ni experiencia previa. Solamente una pasión para tener éxito."
      ],
      "description": "¡Aprende R mientras lo practicas!\nAhí afuera hay otros cursos y tutoriales de R. Sin embargo, R tiene una curva de aprendizaje muy complicada y los que intentan aprender este lenguaje se abruman. ¡Pero este curso es diferente!\nEste curso realmente es paso a paso. En cada clase vamos a construir sobre lo que ya hemos aprendido y avanzaremos un paso más.\nCon cada video aprenderás un nuevo concepto muy valioso que puedes aplicar rápidamente. Y la mejor parte es que vas a aprender con ejemplos reales.\nEste curso está lleno de retos analíticos de la vida real, los cuales vas a aprender a resolver. Algunos los vamos a resolver juntos, y otros van a ser prácticas que vas a poder realizar.\nEn resumen, este curso ha sido diseñado para todos los niveles y para que tengas éxito incluso si no tienes experiencia programando o haciendo análisis estadísticos.\nYa quiero verte dentro del curso.",
      "target_audience": [
        "Este curso es para ti si quieres analizar tus datos de una mejor manera",
        "Este curso es para ti si quieres aprender R mientras practicas",
        "Este curso es para ti si estás cansado de cursos complicados",
        "Este curso es para ti si te gustan los retos interesantes"
      ]
    },
    {
      "title": "Python Data Science: Básico ao Avançado - com projetos reais",
      "url": "https://www.udemy.com/course/python-para-ciencia-de-dados/",
      "bio": "Domine as melhores técnicas, libs e ferramentas de Python Data Science: O curso + direto ao ponto de Ciência de Dados.",
      "objectives": [
        "Descubra o potencial lucrativo da programação, Big Data e Data Science - torne-se um cientista de dados altamente remunerado em um mercado em expansão.",
        "Aprenda técnicas avançadas de Data Science com Python e todo o segredo para lidar com Big Data de forma eficiente e avançar na carreira.",
        "Automatize quaisquer tarefas e dados em planilhas com Python – Não perca horas ou dias, conclua trabalhos em segundos e de maneira mais inteligente.",
        "Aprenda Python de forma descomplicada, prática e aplicada - conquiste a confiança necessária para dominar projetos do mundo real em Data Science.",
        "Aprenda a lidar com grandes estruturas de dados e as melhores bibliotecas de Python e Data Science - domine Pandas, Plotly, Babel e outras ferramentas avançadas",
        "Aprenda a importar, agrupar e analisar dados, criando gráficos e indicadores precisos e transformando-os em decisões estratégicas de sucesso.",
        "Aumente seu salário – Dominar Data Science lhe ajuda na conquista de melhores salários e oportunidades - a habilidade mais requisitada no mercado.",
        "Torne-se mais competitivo: Um certificado Python em Data Science vai diferenciá-lo dos concorrentes e aumentar as chances de sucesso em entrevistas de emprego.",
        "Ganhe dinheiro com Python - crie apps, ferramentas e automatizações de tarefas incríveis em Data Science e torne-se um empreendedor de sucesso."
      ],
      "course_content": {
        "Introdução: Entendendo a dinâmica do curso": [
          "Recado importante:",
          "Overview (visão geral) - Veja se o curso é pra você!"
        ],
        "Projeto 1: Data Science 100% Automatizado - Do Básico ao Avançado": [
          "Introdução ao Ambiente de Desenvolvimento e Estruturação do Projeto - Parte 1",
          "Introdução ao Ambiente de Desenvolvimento e Estruturação do Projeto - Parte 2",
          "Configuração e Personalização do Ambiente de Desenvolvimento - Parte 1",
          "Configuração e Personalização do Ambiente de Desenvolvimento - Parte 2",
          "Configuração e Personalização do Ambiente de Desenvolvimento - Parte 3",
          "Importação de Dados e Uso de Bibliotecas em Python - Parte 1",
          "Importação de Dados e Uso de Bibliotecas em Python - Parte 2",
          "Indicador 1: Calculando, Agrupando, Filtrando e Ordenando Dados - Parte 1",
          "Indicador 1: Calculando, Agrupando, Filtrando e Ordenando Dados - Parte 2",
          "Indicador 2: Identificando os Produtos Mais Vendidos em Faturamento + Desafio",
          "Solução Desafio + Indicador 3: Identificando as Lojas Líderes em Faturamento",
          "Indicador 4: Calculando o Ticket Médio e Adicionando Colunas Dinâmicas por Loja",
          "Construindo Gráfico/Dashboard utilizando Biblioteca Plotly - Parte 1",
          "Construindo Gráfico/Dashboard utilizando Biblioteca Plotly - Parte 2",
          "Configurando Automação para Enviar Indicadores via E-mail - Parte 1",
          "Configurando Automação para Enviar Indicadores via E-mail - Parte 2",
          "Configurando Automação para Enviar Indicadores via E-mail - Parte 3",
          "Estruturando o Conteúdo da Mensagem para Envio de E-mail - Parte 1",
          "Estruturando o Conteúdo da Mensagem para Envio de E-mail - Parte 2",
          "Entendendo a Função Lambda (função anônima) - Parte 1",
          "Entendendo a Função Lambda (função anônima) - Parte 2",
          "Função Lambda em Ação: Personalizando Formatos Monetários - Parte 1",
          "Função Lambda em Ação: Personalizando Formatos Monetários - Parte 2",
          "Dominando Formatações Numéricas com a Função Replace - Parte 1",
          "Dominando Formatações Numéricas com a Função Replace - Parte 2",
          "Aplicando Formatações nos DataFrames - Parte 1",
          "Aplicando Formatações nos DataFrames - Parte 2",
          "Formatação Avançada de Tabelas com a Função \"to_html\"",
          "Integrando Formatações ao HTML: Toques Finais - Parte 1",
          "Integrando Formatações ao HTML: Toques Finais - Parte 2"
        ],
        "Projeto 1: Exercícios de Ciência de Dados": [
          "O que fazer nessa seção?",
          "Preparando o Ambiente com Pandas",
          "Importando Dados para Análise",
          "Visualizando a Tabela de Dados",
          "Agrupando e Somando Dados com Pandas",
          "Extração de Colunas Específicas",
          "Gerando Colunas Virtuais no Pandas",
          "Sumarizando Vendas por Loja",
          "Ordenação Decrescente no Pandas"
        ],
        "Projeto 2: Domínio de Big Data - Análise Avançada de Vendas e Sazonalidade": [
          "Organizando as estruturas dos dados no Google Drive",
          "Início do Projeto: Estrutura dos Dados + Biblioteca Poderosa - Parte 1",
          "Manipulação de Arquivos com a Biblioteca OS: Sistema e Diretórios - Parte 2",
          "Dominando Loops, Operadores e Coleções em Python com foco em DataFrame - Parte 1",
          "Dominando Loops, Operadores e Coleções em Python com foco em DataFrame - Parte 2",
          "Dominando Loops, Operadores e Coleções em Python com foco em DataFrame - Parte 3",
          "Dominando Loops, Operadores e Coleções em Python com foco em DataFrame - Parte 4",
          "Dominando Loops, Operadores e Coleções em Python com foco em DataFrame - Parte 5",
          "Estruturas Condicionais em Python: Otimizando DataFrames com If, Elif, Else",
          "Integrando Múltiplas Planilhas de Vendas em DataFrames + Desafio",
          "Solução Desafio + Agregando Múltiplas Planilhas de Devoluções + Tab. Interativa",
          "Indicador 1: Revelando Produtos e Lojas com Maiores Vendas Líquidas",
          "Indicador 2: Identificando Produtos e Lojas com Altas Taxas de Devolução",
          "Indicador 3: Analisando Top Vendas Brutas com Devoluções Inclusas",
          "Indicador 4: Desvendando a Sazonalidade - Variações Mensais de Vendas - Parte 1",
          "Indicador 4: Desvendando a Sazonalidade - Variações Mensais de Vendas - Parte 2",
          "Indicador 5: Mergulhando no Faturamento Trimestral - Análise do Ano",
          "Aprimorando Visualizações: Dominando a Biblioteca IPython.display",
          "Gráfico 1: Dominando o Gráfico de Pizza Interativo com Plotly",
          "Gráfico 2: Dominando o Gráfico de Barras Interativo com Plotly",
          "Gráfico 3: Dominando o Gráfico de Barras Interativo com Plotly (Avançado)",
          "Gráfico 4 - Dominando o Gráfico de Barras Interativo com Plotly (avançado)",
          "Gráfico 5: Dominando Gráficos Agrupados Avançados com Seaborn - Parte 1",
          "Gráfico 5: Dominando Gráficos Agrupados Avançados com Seaborn - Parte 2",
          "Gráfico 6: Aprimorando Gráficos de Linha com Cores Dinâmicas via Numpy - Parte 1",
          "Gráfico 6: Aprimorando Gráficos de Linha com Cores Dinâmicas via Numpy - Parte 2",
          "Gráfico 7: Dominando Gráfico de Área com Variações Avançadas via Numpy - Parte 1",
          "Gráfico 7: Dominando Gráfico de Área com Variações Avançadas via Numpy - Parte 2"
        ],
        "Projeto 2: Exercícios de Ciência de Dados": [
          "O que fazer nessa seção?",
          "Integração com o Sistema Operacional",
          "Listando Arquivos com OS",
          "Iterando sobre Listas no Python",
          "Filtrando Arquivos com Condicionais",
          "Unificação de DataFrames com Pandas",
          "Lendo e Unindo Arquivos de Devoluções",
          "Identificando os Produtos Mais Vendidos",
          "Identificando Lojas Líderes em Vendas",
          "Cálculo de Variação Mensal no Pandas",
          "Gráfico de Vendas com Plotly"
        ],
        "Finalização": [
          "Parabéns, Cientista de Dados! ;)"
        ]
      },
      "requirements": [
        "Você precisa apenas de um computador conectado à internet e mais nada, o resto você aprenderá nesse curso."
      ],
      "description": "[ATUALIZADO 2025] Curso de Python Data Science: Do Básico ao Avançado (2 Projetos Reais no Google Colab)\nVocê já reparou quantas vagas em Data Science e Python surgem todos os dias, oferecendo salários cada vez mais altos? Não perca tempo: é hora de dominar as habilidades que as grandes empresas buscam agora mesmo!\nEste é o curso intensivo mais direto e atualizado da Udemy em Python para Data Science. Seja iniciante ou já experiente em análise de dados, este curso vai transformar você no profissional indispensável que as empresas disputam a peso de ouro.\n\n\nPOR QUE ESTE CURSO DE PYTHON DATA SCIENCE É DIFERENTE DE TODOS OS OUTROS?\n\n\nPrática Real e Imediata: Você não vai aprender apenas teoria. Com dois projetos reais no ambiente Google Colab (Colaboratory), você terá acesso imediato a um aprendizado prático e 100% aplicável. Sem instalações complicadas, direto ao ponto.\nTecnologias Mais Procuradas pelo Mercado: Vamos aprofundar nas principais bibliotecas usadas no mercado: Pandas, Numpy, Matplotlib, Plotly Express e Smtplib. Ao fim do curso, você terá uma poderosa habilidade de automação com Python em suas mãos.\nAcesso Vitalício e Atualizações Constantes: Imagine dominar tecnologias que evoluem a todo instante. Com este curso, você tem acesso permanente ao conteúdo atualizado, podendo estudar no seu ritmo em qualquer dispositivo. Poucos cursos oferecem essa oportunidade!\n\n\nPROJETOS QUE VÃO TRANSFORMAR VOCÊ EM REFERÊNCIA EM PYTHON E DATA SCIENCE:\n\n\nPROJETO 1 – Automação Avançada e Análise de Vendas com Python\nDomine as técnicas avançadas de manipulação de dados com Pandas e seus poderosos DataFrames, crie visualizações impressionantes com Plotly Express, e aprenda a automatizar relatórios detalhados enviados diretamente por e-mail usando Smtplib. Você vai se tornar o profissional mais requisitado em qualquer equipe de Ciência de Dados.\n\n\nPROJETO 2 – Big Data na Prática: Integração e Análise de Dados com Python\nUltrapasse limites: aprenda a integrar múltiplas fontes de dados reais e complexos, aplicando técnicas avançadas com Numpy, Pandas e Matplotlib. Você vai elevar seu conhecimento em Big Data e estará preparado para resolver desafios complexos e estratégicos usando o poder do Python no Google Colab.\n\n\nPARA QUEM ESTE CURSO DE PYTHON PARA DATA SCIENCE É ESSENCIAL?\n\n\nProfissionais em transição de carreira para Ciência de Dados;\nProgramadores que querem dominar Python, Pandas, Numpy e Matplotlib;\nEmpreendedores que desejam usar Análise de Dados para alavancar seus negócios;\nEstudantes que precisam de um portfólio imbatível em Data Science.\n\n\nBENEFÍCIOS EXCLUSIVOS PARA VOCÊ TOMAR SUA DECISÃO AGORA:\n\n\nAcesso Vitalício: aprenda no seu ritmo e quando quiser.\nAtualizações Constantes: o mercado evolui rapidamente, nosso curso também.\nSuporte Exclusivo: faça parte de uma comunidade engajada, pronta para lhe ajudar.\nCertificado Reconhecido: destaque-se no mercado com um certificado respeitado pela indústria.\n\n\nCONCLUSÃO:\n\n\nAs oportunidades em Data Science com Python crescem exponencialmente. Quanto tempo você ainda vai deixar outras pessoas ocuparem as melhores vagas enquanto você fica para trás?\n\n\nEste não é só mais um curso de Python ou de Data Science. É um investimento no seu futuro profissional. É sua chance única de virar o jogo, destacar-se no mercado e conquistar reconhecimento, estabilidade e altos ganhos.\n\n\nInscreva-se agora mesmo! O mercado precisa de especialistas em Python e Data Science. E VOCÊ pode ser um deles.\n\n\nProf. Josué Gimenes\nDesenvolvedor VBA Excel e Python / Cientista de Dados",
      "target_audience": [
        "Profissionais ou estagiários que querem aprender Python com foco em Ciência de Dados (Data Science) do zero ao avançado de forma prática e descomplicada e que buscam destaque profissional ou crescimento em suas carreiras.",
        "Ou caso você tenha um negócio, com o Python você pode criar soluções, automações e até aplicações para o mercado de Big Data e Data Science. Ou se você não tem um negócio você pode desenvolver soluções para terceiros e ganhar muito dinheiro. Além disso, poderá prestar consultoria para pequenas, médias e grandes empresas, pois a demanda por profissionais dessa área é enorme."
      ]
    },
    {
      "title": "Redes Neurais Artificiais em R",
      "url": "https://www.udemy.com/course/redes-neurais-artificiais-em-r/",
      "bio": "Aprenda na teoria e na prática os fundamentos das redes neurais em R e entre para o mundo do Deep Learning!",
      "objectives": [
        "Aprenda passo a passo todos os cálculos matemáticos que envolvem redes neurais artificiais",
        "Aprenda como codificar passo a passo uma rede neural utilizando a linguagem R",
        "Entenda na teoria e na prática conceitos como perceptron, funções de ativação, backpropagation (retropropagação) e gradient descent (descida do gradiente)",
        "Entenda como as redes neurais podem ser utilizadas em tarefas de classificação de registros"
      ],
      "course_content": {
        "Conteúdo do curso": [
          "Conteúdo do curso",
          "Mais sobre Inteligência Artificial"
        ],
        "Perceptron de uma camada": [
          "Introdução ao módulo",
          "Introdução a redes neurais",
          "Fundamentos biológicos",
          "Neurônio artificial",
          "Perceptron de uma camada",
          "Instalação do R e RStudio",
          "Implementação perceptron de uma camada I",
          "Tipos de aprendizagem de máquina",
          "Ajuste dos pesos I",
          "Ajuste dos pesos II",
          "Implementação perceptron de uma camada II",
          "Implementação perceptron de uma camada III",
          "Implementação perceptron de uma camada IV",
          "Implementação perceptron de uma camada V"
        ],
        "Redes neurais multicamada": [
          "Introdução ao módulo",
          "Introdução a redes neurais multicamada",
          "Funções de ativação",
          "Implementação rede multicamada I",
          "Ativação camada oculta I",
          "Ativação camada oculta II",
          "Implementação rede multicamada II",
          "Implementação rede multicamada III",
          "Ativação camada saída",
          "Implementação rede multicamada IV",
          "Cálculo do erro",
          "Implementação rede multicamada V",
          "Cálculo dos pesos e erros",
          "Descida do gradiente (gradient descent)",
          "Implementação rede multicamada VI",
          "Delta camada saída",
          "Implementação rede multicamada VII",
          "Delta camada oculta",
          "Implementação rede multicamada VIII",
          "Backpropagation, taxa de aprendizagem e momento",
          "Ajuste dos pesos com backpropagation I",
          "Implementação rede multicamada IX",
          "Ajuste dos pesos com backpropagation II",
          "Implementação rede multicamada X",
          "Implementação rede multicamada XI",
          "Bias e erro",
          "Saída com mais neurônios e Deep learning",
          "Camadas ocultas",
          "Camada de saída categórica",
          "Descida do gradiente estocástico",
          "Base de dados breast cancer",
          "Redes neurais com h2o I",
          "Redes neurais com h2o II"
        ],
        "Considerações finais": [
          "Considerações finais",
          "Código fonte completo",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "É recomendado conhecimentos básicos sobre lógica de programação",
        "Conhecimentos básicos em R são necessários, bem como estruturas condicionais e de repetição",
        "Não é necessário conhecimento prévio sobre Inteligência Artificial, redes neurais ou cálculo/matemática"
      ],
      "description": "As redes neurais artificiais são consideradas as técnicas de Machine Learning (aprendizagem de máquina) mais eficientes da atualidade, sendo que grandes empresas como Google, IBM e Microsoft tem utilizado essas técnicas em vários tipos de aplicações. Você provavelmente já deve ter visto algo sobre os carros autônomos que dirigem sozinhos, ou então sobre aplicações que conseguem gerar novas músicas, poemas, imagens e até mesmo roteiros completos de filmes! E o interessante é que a maior parte dessas aplicações foram construídas utilizando redes neurais! Essas técnicas ficaram um pouco fora de evidência há um tempo atrás, porém, com o surgimento de Deep Learning (aprendizagem profunda) as redes neurais voltaram muito forte para o cenário da Inteligência Artificial e hoje em dia são vistas como a tecnologia mais avançada para a descoberta de padrões em dados!\nUm dos maiores problemas que temos visto em alunos que iniciam o aprendizado sobre redes neurais é a falta de material de fácil compreensão em português. Isso ocorre porque a maioria dos materiais existentes na literatura são bastante técnicos e com muitas fórmulas matemáticas, o que acaba tornando a aprendizagem bastante difícil para quem pretende dar seus primeiros passos neste assunto. Pensando nisso, o objetivo principal deste curso é apresentar os conceitos teóricos/matemáticos de forma simples, de modo que se você não sabe nada sobre redes neurais vai conseguir entender todos os processos. São abordados conceitos sobre perceptron, funções de ativação, redes multicamada, gradient descent (descida do gradiente) e algoritmo backpropagation (retropropagação); que são os princípios básicos para o entendimento completo de uma rede neural. Também faremos as implementações passo a passo de todos esses conceitos em R, que é uma linguagem de programação bastante importante no cenário da estatística e da Inteligência Artificial. É também importante salientar que as implementações passo a passo serão feitas sem utilizar bibliotecas específicas de machine learning no R, pois a ideia principal é que você entenda como fazer os cálculos manualmente bem como sua implementação do zero! Além disso, como bônus você vai aprender a usar a biblioteca h2o para trabalhar com Deep Learning no R!\nEm resumo, se você pretende iniciar seus estudos em Deep Learning esse curso trará para você todos os conceitos iniciais necessários! É também importante enfatizar que este curso é para iniciantes em redes neurais, portanto, as explicações são bem lentas e passo a passo para que você consiga aprender os conceitos da melhor maneira possível. E caso você já tenha conhecimento neste assunto, o curso pode ser bastante útil para revisar alguns conceitos importantes!\nPreparado(a) para dar um importante passo na sua carreira? Aguardamos você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial",
        "Pessoas que queiram iniciar os estudos em Deep Learning (aprendizagem profunda)",
        "Pessoas que queiram aprender o funcionamento teórico e prático de redes neurais artificiais"
      ]
    },
    {
      "title": "Alıştırmalarla SQL Öğreniyorum",
      "url": "https://www.udemy.com/course/alistirmalarla-sql-ogreniyorum/",
      "bio": "Bu kursta SQL dilini gerçek hayat senaryoları üzerinden alıştırmalarla öğreneceksiniz.",
      "objectives": [
        "Alıştırmalar ile sql pratikleri",
        "Gerçek hayat verilerini sorgulama",
        "Farklı senaryolar üzerinden analitik düşünebilme"
      ],
      "course_content": {
        "Giriş": [
          "Giriş"
        ],
        "Sanal Makine Kurulumu": [
          "VMWare Player Kurulumu",
          "Windows Server 2016 Kurulumu-2",
          "Windows Server 2016 Kurulumu-1",
          "VMWare Tools Kurulumu",
          "SQL Server Kurulumu",
          "Management Studio Kurulumu"
        ],
        "Senaryo 1-Müşteriler verisi üzerinde sorular": [
          "Soru -1",
          "Soru -2",
          "Soru -3",
          "Soru - 4",
          "Soru - 5",
          "Soru - 6",
          "Soru - 7",
          "Soru - 8",
          "Soru - 9",
          "Soru -10",
          "Soru -11",
          "Soru -12",
          "Soru -13",
          "Soru -14",
          "Soru - 15",
          "Soru -16",
          "Soru - 17",
          "Soru -18",
          "Soru -19",
          "Soru -20",
          "Soru - 21",
          "Soru - 22",
          "Soru -23",
          "Soru - 24",
          "Soru - 25"
        ],
        "Senaryo 2, İnsan Kaynakları Veritabanı": [
          "Soru - 1",
          "Soru - 2",
          "Soru - 3",
          "Soru -4",
          "Soru - 5",
          "Soru - 6",
          "Soru - 7",
          "Soru - 8",
          "Soru -9",
          "Soru - 10",
          "Soru - 11",
          "Soru -12",
          "Soru - 13",
          "Soru - 14",
          "Soru - 15"
        ],
        "Senaryo 3 E Ticaret Market Verisi": [
          "Senaryo 3 Giriş ve Veritabanı Kurulumu",
          "Soru -1",
          "Soru -2",
          "Soru - 3",
          "Soru -4",
          "Soru - 5",
          "Soru - 6",
          "Veritabanı Şeması ve ER Diyagramı",
          "İlişkisel Veritabanı Sorgulama",
          "Soru - 7",
          "Soru - 8",
          "Soru -10",
          "Soru - 11",
          "Soru - 12",
          "Soru - 13",
          "Soru - 14",
          "Soru -15"
        ],
        "Senaryo 4 İkinci el araç veritabanı": [
          "Ders 1 Giriş",
          "Ders 2 Veritabanı Yedekten Dönme",
          "Soru -1",
          "Soru - 2",
          "Soru - 3",
          "Soru - 4",
          "Soru - 5"
        ],
        "TMDB Veritabanı": [
          "Giriş",
          "Veritabanı Yapısı-1",
          "Veritabanı Yapısı -2",
          "Veritabanını Yedekten Dönme",
          "Soru -1",
          "Soru -2",
          "Soru -3",
          "Soru -4",
          "Soru-5",
          "Soru -6",
          "Soru -7",
          "Soru -8",
          "Soru -9"
        ]
      },
      "requirements": [
        "SQL dilini ve SQL komutlarını biliyor olması gerekir"
      ],
      "description": "Arkadaşlar merhaba,\nBildiğiniz üzere SQL ve Microsoft SQL Server üzerine bir çok eğitim hazırlıyorum ve bu eğitimler sizlerden büyük ilgi görüyor. Bunun en büyük sebebi şüphesiz sizlerle doğru frekansı yakalamak adına yapmaya çalıştıklarım.\nKursların iyi anlaşılması adına sürekli gerçek senaryolar, gerçek veriler ve gerçek hayat hikayeleri üzerinden dersler hazırlamaya çalışıyorum. Bu noktada sanırım bir miktar başarılı olduğumu düşünüyorum. Zira SQL gibi spesifik bir konuda 100 ülke ve 25.000+ öğrenciye ulaşmış durumdayız.\nBir çok noktada kursları daha iyileştirme noktasında neler yapabileceğimize kafa yoruyoruz ve bu noktada sizlerden gelen geri dönüşleri de dikkate alarak en çok talebin daha fazla Pratik, ödev ve soru cevap konularında geldiğini gözlemledik.\nBu konuya ben de çok katılıyorum. Bir konuyu en iyi öğrenmenin yolu o konuda Pratik yapma ile doğrudan orantılı ve belki de bu alıştırma eğitimleri eğitimin kendisinden daha önemli ve daha zengin içeriğe sahip olmalı diye düşünüyorum.\nBu kursta bir çok farklı senaryodan bir çok farklı şekilde sorgulama örnekleri ile karşılacaksınız.\nSorular 1’den 5’e kadar zorluk derecesine göre sınıflandırılmış durumda ve her bir soruyu sorduktan sonra önce sizin yapmanızı bekliyoruz sonrasında ise nasıl çözüldüğünü yine video ile anlatıyoruz.\nBu kursu almak için temel anlamda sql cümlelerini bildiğini varsayıyoruz. Şayet bu konuda eksikliğin varsa, yine Udemy’de alanının en çok satan etiketine sahip Uygulamalarla SQL Öğreniyorum kursunu almanı özellikle tavsiye ederim.\nMevcut bilgilerini unutulmayacak derecede geliştireceğin ve belli zaman aralıklarında sürekli yeni senaryo, soru ve veri setlerinin ekleneceği bu kursu kaçırmamalısın.\nHadi başlayalım!",
      "target_audience": [
        "Veri bilimine meraklı öğrenciler",
        "SQL dilini geliştirmeyi hedefleyen öğrenciler",
        "Veri analizi uzmanları",
        "Raporlama uzmanları",
        "Veritabanı programcıları"
      ]
    },
    {
      "title": "Cluster Analysis with Python & Scikit-learn Machine Learning",
      "url": "https://www.udemy.com/course/cluster-analysis-with-python-scikit-learn-machine-learning/",
      "bio": "Clustering Methods, Practical Applications, and Advanced Concepts",
      "objectives": [],
      "course_content": {
        "Introduction to clustering": [
          "Introduction",
          "Note",
          "Overview of clustering methods",
          "Overview of clustering methods : Table",
          "Non-flat geometry",
          "Transductive clustering methods"
        ],
        "K-means": [
          "Introduction",
          "K-means division",
          "Centroids",
          "Inertia 1",
          "Inertia 2",
          "Examples",
          "Lloyd's Algorithm",
          "Expectation-Maximization",
          "K-means++",
          "Sample Weights"
        ],
        "Paralleslism": [
          "OpenMP Parallelism",
          "References"
        ],
        "MiniBatch": [
          "MiniBatch",
          "2 Steps",
          "MiniBatch Example",
          "Examples and references"
        ],
        "Affinity Propagation": [
          "Affinity Propagation",
          "Examples",
          "Damping Factor",
          "Affinity Propagation Drawback",
          "AP examples",
          "MeanShift",
          "Bandwith",
          "Scalability",
          "Examples",
          "Examples and references"
        ],
        "Spectral Clustering": [
          "Introduction",
          "Limits",
          "Normalized Cuts",
          "Example",
          "Warning",
          "Similarity",
          "Examples",
          "Different labels",
          "Example",
          "Graphs",
          "References"
        ],
        "Conclusion": [
          "See you very soon"
        ]
      },
      "requirements": [
        "Python"
      ],
      "description": "Cluster Analysis with Python & Scikit-learn Machine Learning :\n\n\nThis course introduces clustering, a key technique in unsupervised learning, using the scikit-learn library. Students will explore various clustering algorithms, understand their use cases, and learn how to apply them to unlabeled datasets. The course covers both foundational concepts and practical implementation, focusing on the strengths and limitations of each method.\nKey topics include (Clustering Methods, Practical Applications, and Advanced Concepts) :\n\n\nOverview of Clustering Methods: A comparative analysis of popular algorithms like K-Means, DBSCAN, Spectral Clustering, and Agglomerative Clustering. Students will learn to select appropriate methods based on dataset characteristics, such as geometry and density.\nInput Data Formats: Insights into handling standard data matrices and similarity matrices, enabling effective use of clustering techniques for diverse data types.\nPractical Applications: Hands-on exercises to implement clustering algorithms, fine-tune parameters, and interpret results. Techniques like K-Means++ initialization and MiniBatchKMeans will be explored for scalability.\nAdvanced Concepts: Topics include cluster validation, dimensionality reduction (PCA), and addressing challenges like the curse of dimensionality.\nBy the end of this course, students will be equipped to perform clustering analysis, evaluate its outcomes, and apply these techniques in real-world scenarios across domains such as text analysis, image processing, and customer segmentation.",
      "target_audience": [
        "Enthusiasts eager to explore the world of Data Science"
      ]
    },
    {
      "title": "chatGPT. Da zero ad esperto. Il corso completo con esempi.",
      "url": "https://www.udemy.com/course/chatgpt-da-zero-ad-esperto-il-corso-completo-con-esempi/",
      "bio": "Impara le tecniche di questa potente intelligenza artificiale per aumentare la tua produttività e automatizzare processi",
      "objectives": [
        "Le basi di chatGPT",
        "I campi di applicazione di chatGPT",
        "Tecniche per aumentare la produttività e monetizzare con chatGPT",
        "Utilizzare chatGPT per cercare un lavoro oppure automatizzare e migliorare il proprio",
        "Utilizzare chatGPT con altri software per potenziare e ampliare i risultati"
      ],
      "course_content": {
        "Introduzione": [
          "Introduzione al corso",
          "La struttura del corso",
          "Velocità lezioni e note",
          "Architettura e funzionamento di chatGPT",
          "Storia di chatGPT",
          "Limiti di chatGPT"
        ],
        "Le basi per iniziare": [
          "Iscriversi e accedere a chatGPT",
          "chatGPT: piano free vs piano a pagamento",
          "Tour dell'interfaccia free di chatGPT",
          "Tour dell'interfaccia pro di chatGPT",
          "Utilizzare chatGPT con Opera e VPN gratuita inclusa",
          "Approccio top-down",
          "Generazione di ricette e dettaglio"
        ],
        "Campi di applicazione": [
          "Traduzioni multi lingua",
          "Creazione di contenuti",
          "Riassunti, indici e sommari",
          "Copywriting",
          "Generare email",
          "Musica ed arte",
          "Generazione di documenti",
          "Generazione di codice"
        ],
        "Idee e strategie per aumentare la produttività e monetizzare con chatGPT": [
          "Comunicazione e marketing sui social e sul web",
          "Canale youtube",
          "Scrivere storie, racconti e romanzi",
          "Consulenze",
          "Freelance su piattaforme digitali",
          "ChatGPT SEO"
        ],
        "Cercare lavoro. Ottimizzare, automatizzare e migliorare il proprio con chatGPT": [
          "Ricercare un lavoro con chatGPT",
          "Simulare un colloquio di lavoro",
          "Migliorare skill lavorative"
        ],
        "Prompt Engineering": [
          "Che cos'è il prompt engineering?",
          "Ciclo iterativo nella raffinazione del prompt",
          "Esercitazione pratica di iterazione di un prompt",
          "11 pattern per migliorare e specializzare i prompt - parte A",
          "11 pattern per migliorare e specializzare i prompt - parte B",
          "11 pattern per migliorare e specializzare i prompt - parte C"
        ],
        "La ricerca profonda (deep research&co)": [
          "Introduzione alla ricerca profonda",
          "Esempio operativo con chatGPT",
          "Esempio operativo con Gemini"
        ],
        "PROGETTI con chatGPT": [
          "Progetto 01 creare un sito web portfolio -introduzione-",
          "Progetto 01 creare un sito web portfolio - strumenti-",
          "Progetto 01 crea un sito web portfolio -index e css-",
          "Progetto 01 creare un sito web portfolio -form contatti-",
          "Progetto 01 creare un sito web portfolio -carosello js-"
        ],
        "GPT-4 Vision e Bard immagini": [
          "Introduzione",
          "Riconoscere ed utilizzare uno strumento",
          "Riconoscere una specie",
          "Riconoscere e risolvere un problema geometrico",
          "Analizzare un grafico",
          "Analizzare opere d'arte",
          "Analizzare etichette",
          "Analizzare il contenuto del frigorifero",
          "Analizzare una mappa",
          "Analizzare una pietanza e stimare le calorie",
          "Analizzare uno schema e produrre risultati da esso",
          "Analizzare e catalogare immagini complesse",
          "Analizzare e tradurre simboli esotici"
        ],
        "chatGPT 4o": [
          "Introduzione a chatGPT 4o",
          "Analisi dei dati con chatGPT 4o",
          "Creare e convertire file con chatGPT 4o"
        ]
      },
      "requirements": [
        "Un computer fisso oppure portatile, un tablet oppure uno smartphone",
        "Una connessione ad internet"
      ],
      "description": "Il videocorso su ChatGPT è un'opportunità unica per imparare a sfruttare al meglio uno dei modelli di linguaggio più avanzati al mondo. Con questo corso, potrete scoprire tutte le funzionalità di ChatGPT e come utilizzarle per migliorare la vostra attività lavorativa o personale.\nIl corso è stato progettato per essere facilmente comprensibile per tutti, indipendentemente dalla vostra esperienza con i modelli di linguaggio. Vi verranno forniti tutti gli strumenti necessari per utilizzare ChatGPT con successo, inclusi esempi pratici e consigli esperti per ottenere i migliori risultati.\nIl videocorso è suddiviso in sei capitoli, che coprono tutto, dalle basi del funzionamento di ChatGPT all'utilizzo avanzato del software. Nel primo capitolo, \"Introduzione\", verrà fornita una panoramica generale delle funzionalità di ChatGPT e delle opportunità che esso offre. Il capitolo successivo, \"La base per iniziare\", vi fornirà le informazioni di base per utilizzare ChatGPT. Nel terzo capitolo, \"Campi di applicazione\", verranno esplorate le diverse aree in cui ChatGPT può essere utilizzato, tra cui la creazione di chatbot, la generazione automatica di testo e molto altro ancora.\nIl quarto capitolo, \"Idee per monetizzare con ChatGPT\", vi fornirà informazioni su come utilizzare ChatGPT per guadagnare denaro. Nel quinto capitolo, \"Cercare e migliorare il lavoro con ChatGPT\", verranno forniti consigli su come utilizzare ChatGPT per migliorare la vostra carriera. Infine, nel sesto capitolo, \"Utilizzare ChatGPT con altri software\" e \"Tecniche e trucchi\", verranno presentate tecniche avanzate e trucchi per utilizzare al meglio ChatGPT in combinazione con altri software e per ottenere i migliori risultati possibili.\nNon perdete questa occasione unica di imparare a utilizzare uno dei modelli di linguaggio più avanzati al mondo. Il videocorso su ChatGPT è il modo perfetto per migliorare le vostre competenze e ottenere il massimo dalla vostra attività lavorativa o personale",
      "target_audience": [
        "Fornire una comprensione generale dei concetti di base dell'intelligenza artificiale, come il riconoscimento del linguaggio naturale.",
        "Capire come funziona il modello di linguaggio GPT-3 e come utilizzarlo per generare testo e rispondere alle domande.",
        "Imparare a valutare e migliorare le prestazioni dei modelli di intelligenza artificiale che codificano il linguaggio naturale.",
        "Imparare a creare generazione di testo, sintesi vocale e traduzione automatica utilizzando GPT-3.",
        "Capire come utilizzare GPT-3 per la generazione di contenuti, come articoli, recensioni, descrizioni di prodotti e testi creativi.",
        "Comprendere come GPT-3 si relaziona con altre tecnologie di elaborazione del linguaggio naturale e come queste possono essere utilizzate insieme per creare soluzioni innovative.",
        "mparare a utilizzare GPT-3 per la generazione di contenuti in diverse lingue e cultura, per creare soluzioni adattative e multilingue."
      ]
    },
    {
      "title": "INTRODUCTION BIG DATA & DATA SCIENCE | version 2025",
      "url": "https://www.udemy.com/course/formation-big-data-data-science-version-2021/",
      "bio": "Acquérir une première expérience du Big Data | version 2025",
      "objectives": [
        "Comprendre le rôle stratégique de la gestion des données pour l’entreprise",
        "Identifier ce qu’est la donnée, et en quoi consiste le fait d’assurer la qualité de données",
        "Synthétiser le cycle de vie de la donnée",
        "Assurer l’alignement des usages métiers avec le cycle de vie de la donnée",
        "Découvrir les bonnes pratiques en matière de contrôle de qualité des données",
        "Familiarisez- vous avec les bibliothèques d'apprentissage automatique de Python, notamment scikit -learn, ...",
        "Assurer la mise en oeuvre de la gouvernance de la donnée",
        "Maitriser les bases de l’analyse business",
        "Choisir des indicateurs et comprendre les données associées"
      ],
      "course_content": {},
      "requirements": [
        "Aucune connaissance technique particulière n’est nécessaire"
      ],
      "description": "Bienvenue dans ce cours magistral pour vous initier au domaine du Big Data. Comme vous le savez l’ère numérique que nous vivons est synonyme de collecte, de transfert et de stockage de données numériques d’où la nécessité de concevoir de nouvelles approches pour voir et analyser le monde : le Big Data.\nCette formation s’adresse en particulier aux débutants, qui veulent apprendre ou tout simplement s’initier à ce concept qui prend de plus en plus d’ampleur dans cette époque grâce à des cours régulièrement mis à jour avec un accès à vie sans oublier que c’est satisfait ou remboursé durant 30 jours.\nNe soyez pas apeurés par le concept qui semble difficile à comprendre : de la collecte initiale à la mise en place d’une solution de stockage HDFS permettant d’organiser un très grand volume d’information, à l'initiation à la réalisation de programmes Pig et Hive qui, convertis en tâches MapReduce, permettent d’agréger et de filtrer les données pour finalement les analyser, tous ces aspects seront abordés avec une grande maitrise pédagogique avec de termes simples, d’ateliers pratiques, etc.\nPour rentrer dans le vif du sujet, vous allez apprendre à :\nComprendre le rôle stratégique de la gestion des données pour l’entreprise\nIdentifier ce qu’est la donnée, et en quoi consiste le fait d’assurer la qualité de données\nSynthétiser le cycle de vie de la donnée\nAssurer l’alignement des usages métiers avec le cycle de vie de la donnée\nDécouvrir les bonnes pratiques en matière de contrôle de qualité des données\nAssurer la mise en oeuvre de la gouvernance de la donnée\nNotez bien :\nLa formation se déroulera sous forme de cours théorique & pratique, d'exemples concrets et d'ateliers pour permettre aux participants de mettre en pratique les concepts appris. Des exercices, des mises en situation et des études de cas seront utilisés pour renforcer les connaissances.\n\n\nRessources d’apprentissage complémentaires :\nAtelier en ligne\nDocumentation\nConsultez des exemples de tableaux de bord, de rapports et de fichiers de bureau.\nEnfin, je m'engage à vous fournir la formation la plus complète possible sur Udemy pour vous permettre de réussir dans votre apprentissage.\nJe m'engage à répondre rapidement à vos questions pour vous aider à comprendre les concepts de la formation.\nJe vais ajouter des cas pratiques sur demande pour vous donner des exemples concrets de ce que vous apprenez.\nJe vais vous accompagner avec des cas pratiques et d'autres ressources utiles pour vous aider à mettre en pratique ce que vous apprenez.\nCes ajouts de vidéos seront, bien entendu, gratuits si vous avez acquis la formation.\nComment me contacter ? Je reste disponible dans la rubrique Question/Réponses d'Udemy pour répondre à vos questions.\nÀ la fin de ce cours, si vous le suivez en entier et réussissez l'ensemble des quizz : Obtenez votre certification électronique à insérer dans votre CV et profil LinkedIn.\n\nDr. Firas",
      "target_audience": [
        "Ce cours a pour objectif de donner les outils nécessaires et essentiels à l'analyse de données recueillis dans le cadre des expériences."
      ]
    },
    {
      "title": "Manipulación de Datos con Módulos de Python",
      "url": "https://www.udemy.com/course/modulos-para-el-manejo-de-datos-con-python-data-science/",
      "bio": "Maneja y grafica datos utilizando los módulos mas utilizados en el mundo del Data Science",
      "objectives": [
        "A instalar todo lo necesario para dar seguimiento al curso.",
        "A utilizar el IDE Pycharm para desarrollar código de una manera mas flexible y rápida",
        "A manejar y graficar datos utilizando Numpy, Pandas y Matplotlib",
        "A crear tus propios Datasets para que puedas comprender de una mejor manera el manejo y transformación de datos",
        "A analizar Datasets que se utilizan cuando empiezas a aprender Machine Learning",
        "A integrar tus graficas en GUIs utilizando PyQt5"
      ],
      "course_content": {},
      "requirements": [
        "Conocimiento básico de programación."
      ],
      "description": "¡Hola! ¿Te gustaría aprender a manejar y transformar datos de forma eficiente? ¡Tenemos el curso perfecto para ti! Bienvenido al curso de manejo de datos con Python creado por ISSEL Electronics.\nEn este curso, aprenderás a utilizar los módulos más poderosos del campo del Data Science: numpy, pandas y matplotlib. A través de ejercicios prácticos y divertidos, aprenderás a manejar y comprender los datos de una manera muy sencilla. Además, estarás preparado para adentrarte en el mundo del Machine Learning con Python.\nEn el curso, aprenderás lo siguiente:\nA instalar todo lo necesario para seguir el curso.\nA utilizar el IDE Pycharm para desarrollar código de una manera más flexible y rápida.\nA manejar y graficar datos utilizando Numpy, Pandas y Matplotlib.\nA crear tus propios Datasets para que puedas comprender mejor el manejo y transformación de datos.\nA analizar Datasets utilizados en el aprendizaje de Machine Learning.\nA integrar tus gráficas en GUIs utilizando PyQt5.\nTodos los videos del curso están nivelados, con ejercicios que se realizan para entender de una mejor manera lo que se puede hacer con cada uno de los distintos métodos que nos proporcionan estos módulos. Durante todo el curso se utiliza Pycharm, el cual también se enseñará a instalar y cómo obtener una licencia gratuita para estudiantes y docentes.\n¡Únete a nuestro curso y conviértete en un experto en manejo de datos con Python! ¡Te esperamos!",
      "target_audience": [
        "Toda persona con ganas aprender sobre el manejo de datos con Python para adentrarse al mundo del Machine Learning"
      ]
    },
    {
      "title": "Öğrenme Garantili LOGO & SQL Rapor Eğitimi",
      "url": "https://www.udemy.com/course/logo-sql-rapor-egitimi/",
      "bio": "Yazılım bilgisi gerekmez, Daha önce SQL bilmeniz gerekmez. Sıfırdan sade bir dille anlatım.",
      "objectives": [
        "Yazılım bilginiz olmadan SQL Raporları oluşturabileceksiniz.",
        "Raporlarınızı Logo'nun içinde ya da Excelde Pivot Tablolar şeklinde kullabileceksiniz.",
        "Raporlama mantığını anlayacak ve Rapor Okuma becerisi kazanacaksınız.",
        "Logo ERP nin SQL Tablolarına hakim olacaksınız.",
        "SQL deki Temel komutları öğreneceksiniz. (Select - Update - Delete - Insert)"
      ],
      "course_content": {
        "SQL Eğitimi Giriş - Eğitimde Neler Var ? İşlenecek Konular Neler ?": [
          "Giriş"
        ],
        "SQL'e Girişi - SSMS Kullanımı - Komutlar ve Fonksiyonlar - Logo SQL Tabloları": [
          "SQL Nedir - SELECT Kullanımı - SQL Veri Tipleri",
          "Alias verme - SQL Yedek Alma - UPDATE / DELETE / INSERT Kullanımı WHERE ORDER BY",
          "SQL Fonksiyonları - Logo'nun SQL Tabloları Nelerdir ? - Tablodaki Alanlar ?"
        ],
        "Rapor (View) Oluşturmaya Başlıyoruz": [
          "Rapor Yazma - JOIN ve CASE WHEN kullanımı - Sipariş Raporu Hazırlama",
          "View Oluşturma - Excele Rapor Aktarımı - Rapor Üretici - Pivot Table Kullanımı",
          "SUBQERY kullanımı - Malzeme Hareketleri Raporu - İşlem Türleri Tespit etme"
        ],
        "SQL Server Profiler - JOIN Türleri - Dövizli İşlemler - Örnek Rapor Çalışmaları": [
          "İşlemin hangi tabloya yazıldığını bulma - (Trace Alma) - Diğer JOIN Türleri",
          "Dövizli Rapor Oluşturma - Cari Hareket Raporu - Ekstre Raporu (Yürüyen Bakiye)",
          "Finans Raporları - Kar/Zarar için Maliyet - Genel Toplam - Muhasebe Hesapları"
        ]
      },
      "requirements": [
        "Yazılım bilmenize gerek yok. Daha önce hiç SQL kullanmış olmanıza gerek yok. Sıfırdan bir eğitim"
      ],
      "description": "Bu kurs sayesinde daha önce hiç SQL e girmediyseniz ve hiçbir yazlım bilginiz olmasa bile SQL den raporlar hazırlayarak bunları Excel de dinamik olarak kullanabileceksiniz.\nTeknik jargonlara çok girmeden tamamen anlaşılır sade bir dille anlatım olacak.\nÖğrendiklerinizi uyguladığınız sürece çok kısa sürede istediğiniz özel raporları hazırlayabileceksiniz. Daha önce Yüzlerce katılımcı Bu kursta anlatılanlardan oluşan Online eğitimlerle SQL den raporlar yazmaya başladılar. Sadece rapor yazmak değil raporlama mantığı ve rapor okumayı da pekiştireceksiniz.\nÖzellikle LOGO kullanıyor ve SQL e merakınız varsa kesinlikle kaçırmamanız gereken bir eğitim.\nÖncelikle Bir sunum üzerinden SQL Nedir ? diyerek başlayacağız. Tamamen sıfırdan bir eğitim olacak. En baştan Temelden başlayacağız.\n\n\nSonra SQL in Temel komutlarını ve veri tiplerini göreceğiz. SELECT - DELETE - UPDATE ve INSERT INTO komutları ile ilgili uygulamalı örnekler yapacağız.\n\n\nSonra Logo da yapılan kayıtların SQL de hangi tablolara yazıldığını göreceğiz.\nVe Logonun standart raporlarında olmayan firmamıza özel raporlar tasarlayacağız.\nBu raporları Logo nun içine Menüye koyarak nasıl kullanacağımızı göreceğiz\nAyrıca Excel ile SQL bağlantısınız yaparak Excel de çalışan dinamik SQL raporları yapacağız.\nExcel de ki bu raporları Pivot Table sayesinde nasıl daha okunabilir hale getireceğimizden bahsedeceğiz.\nAyrıca SQL Data ve Tablo yedeklerini nasıl alacağımızdan bahsedeceğiz.\n\n\nYorum Satırı - Alias verme - Join Türleri - Subqery kullanımı\nWHERE Koşul kullanım çeşitleri - ORDER BY Sıralama işlemleri\nConcat - Len - Left - Right - Substring - Charindex - Lower -Upper - Ltrim - Rtrim -Trim - Sum - Count - Avg Kullanımı\nGroup By ve Having kullanımı\nTarihsel işlemler Getdate() - Datediff kullanımı\nConvert İşlemleri - With (Nolock) nedir ?\nISNULL - Round - Union All - Distinct - Case When kullanımı\nOver (Partition by) kullanımı ve Yürüyen Bakiye SQL Komutu\nHangi verinin hangi tabloya yazıldığını bulma yöntemi  (SQL Server Profiler - Trace Alma)\nExcel de Pivot Table kullanımı\nRapor Üreticide Firma Değişkeni kullanma\nDövizli İşlemler için SQL Sorgusu yazma\nGenel Toplamların tutulduğu viewleri kullanma\nKartların hangi Muhasebe Hesaplarına bağlandığını gösteren tablo\nKar/Zarar Raporu için gereken Maliyet Alanları Sorgumuza nasıl doğru gelir ?\nBirden fazla farklı sorguyu aynı Excel sayfasında farklı Pivotlarda nasıl gösterebiliriz ?\n\n\nRapor yazarken bilmeniz gereken ipuçları ve püf noktaları.\nBu Kurs sonunda sizlerde kendi özel SQL raporlarınızı oluşturabileceksiniz.\nEğitim sırasında videoyu durdurup işlemleri mutlaka kendi SQL ekranınızda uygulayın.\nBu şekilde bu işi öğrenmeme şansınız yok.\n\n\nŞimdiden hepinize iyi dersler dilerim.",
      "target_audience": [
        "SQL Tabanlı bir ERP kullanıyor ve rapor oluşturmaya meraklı iseniz bu eğitim büyük bir fırsat."
      ]
    },
    {
      "title": "Pythonとディープラーニングがわかる基礎講座（Windows10版）",
      "url": "https://www.udemy.com/course/pythonwindows10/",
      "bio": "Windows10 Python（パイソン） Tensorflow（テンソルフロー）",
      "objectives": [
        "①Pythonのプログラミングができるようになります。（講座の中で実際にやっていきます。）",
        "②ディープラーニングの理論を理解できるようになります。",
        "➂画像認識を実際にやってみます。（KerasでResNet50モデル）",
        "④画像認識を実際にやってみます。（Yoloモデル）"
      ],
      "course_content": {
        "コース概要": [
          "この講座の目的・カリキュラムについて説明します。。"
        ],
        "Anacondaのインストール": [
          "Anacondaのインストール"
        ],
        "教材のPythonプログラムのダウンロード": [
          "教材のPythonプログラムのダウンロード"
        ],
        "Pythonのプログラミングをやってみよう": [
          "Python基本プログラミング　Level1",
          "（４）Pythonのプログラミングをやってみようlevel1の続き",
          "Python基本プログラミング　Level2",
          "（４）Pythonのプログラミングをやってみよう（４）level2の続き",
          "Python基本プログラミング　Level3",
          "（４）Pythonのプログラミングをやってみよう level3 続き",
          "（４）Pythonのプログラミングをやってみよう level3 続き"
        ],
        "ディープラーニングとは何か(前編)": [
          "ディープラーニングとは何か(前編)"
        ],
        "MNIST（手書き数字の認識）を動かしてみよう": [
          "MNIST（手書き数字の認識）を動かしてみよう"
        ],
        "ディープラーニングとは何か(後編)": [
          "ディープラーニングとは何か(後編)",
          "（７）ディープラーニングとは何か(後編)続き",
          "（７）ディープラーニングとは何か(後編)続き"
        ],
        "画像認識をやってみよう[1]（Kerasで推論）": [
          "画像認識をやってみよう[1]（Kerasで推論）"
        ],
        "画像認識をやってみよう[2]（yoloで推論）": [
          "画像認識をやってみよう[2]（yoloで推論）"
        ],
        "プログラミングができるようになるためのコツ": [
          "プログラミングができるようになるためのコツ"
        ]
      },
      "requirements": [
        "初心者を前提にしています。ディープラーニングやプログラミング、難しい数学の知識は必要ありません。授業の中でわかりやすく解説していきます。",
        "Windows10のPCで解説をしていきます。Mac・Linuxは別講座として準備中ですので、購入をお間違えないようにお願い致します。",
        "ディープラーニングの学習で、数学やプログラミングでつまづいてしまった方でも大丈夫です。",
        "難しい数式はでてきません。数式の代わりに、図やグラフ、グラフをプログラムで動かしてみて、直感的にイメージで理解できるよう解説しています。"
      ],
      "description": "初心者向けの基礎講座です。\nWindows10が対象です。Mac・Linux版は、別途、別講座で準備中ですので、お間違えのないようにお願い致します。\nPython（パイソン）のプログラミングを実際にやります。ディープラーニングについて解説していきます。\n既に一度取り組んで、数学やプログラミングでつまづいてしまったかたも大丈夫です。わかりやすく解説していきます。\nこの講座を受けるにあたり、ディープラーニングの理論やPythonのプログラミングについての事前知識は必要ありません。\n授業の中で、基礎からわかりやすく解説していきます。\n解説は、Windows10のPCで行っていきますので、Windows10のPCで受講してください。\nPythonのプログラミングについては、重点的に解説していきます。",
      "target_audience": [
        "初心者でも大丈夫なように、基本から解説していきます。Pythonプログラミングやディープラーニングに興味があれば大丈夫です。",
        "Pythonのプログラミングができるようになりたい人向けの講座です。実際にプログラミングをやっていきます。",
        "Windows10のPCで行っていきますので、Windows10のPCで受講してください。Mac・Linux版は別講座で準備中です。",
        "私は、以前に「Windows10で学ぶAI画像認識（Mask RCNNモデル）」という講座を作成していますが、続編ではありません。この講座は、初心者向けに最初から解説します。",
        "すでにある程度できるかたも、基本に立ち返って、より深く理解できるように解説しています。"
      ]
    },
    {
      "title": "Power BI로 완성하는 데이터 시각화 & 인사이트 분석",
      "url": "https://www.udemy.com/course/power-bi-desktop/",
      "bio": "Microsoft 무료 BI 툴 Power BI로 나만의 대시보드와 시각화 리포트를 만들어 보세요. 실무형 시각화는 물론, 경영정보시각화 능력시험 실기 대비에도 도움이 됩니다.",
      "objectives": [
        "Power BI Desktop을 설치하고 다양한 데이터 원본(Excel, Web, DB 등)에 연결할 수 있습니다.",
        "Power Query를 사용하여 데이터를 정제하고 분석에 적합한 형태로 변환할 수 있습니다.",
        "DAX 함수(측정값과 계산열)를 활용하여 핵심 지표를 계산하고 분석 모델을 구축할 수 있습니다.",
        "막대형, 도넛형, 트리맵, 지도 시각화 등 다양한 차트를 구성하여 인사이트 중심의 시각화 보고서를 제작할 수 있습니다.",
        "드릴다운, 드릴스루, 상호작용 편집 등 인터랙티브 기능을 적용하여 탐색형 보고서를 설계할 수 있습니다.",
        "Power BI Service에 보고서를 게시하고, 대시보드를 생성·공유·구독 설정할 수 있습니다.",
        "인사이트 찾기, 데이터 증감 분석, 조건부 서식 등 고급 기능을 통해 분석의 깊이를 더할 수 있습니다."
      ],
      "course_content": {
        "강의 소개": [
          "과정 소개, 목표 소개, 강의 목차 소개"
        ],
        "Power BI 처음 만나기": [
          "Power BI의 이해",
          "Power BI Desktop 설치"
        ],
        "데이터 핸들링": [
          "데이터 핸들링 맛보기 (BBC 스포츠 데이터 가져오기 실습)",
          "데이터 연결하기",
          "파워 쿼리를 활용한 데이터 편집",
          "데이터 모델링 (관계 확인/작성 실습)",
          "DAX를 활용한 분석식 작성 (DAX 함수 실습)"
        ],
        "데이터 시각화": [
          "시각화 작성 흐름 이해",
          "보고서 페이지 설정",
          "언바운드 개체 작성",
          "카드 시각화",
          "막대형 차트 시각화",
          "원형 & 도넛형 차트 시각화",
          "꺽은선형 차트(Line Chart) 시각화",
          "이중 축 차트(Combo Chart) 시각화",
          "슬라이서(Slicer) 시각화",
          "리본 차트(Ribbon Chart) 시각화",
          "폭포 차트(Waterfall Chart) 시각화",
          "분산형 차트(Scatter Chart) 시각화",
          "트리맵(Tree Map) 차트 시각화",
          "맵(Map) 차트 시각화",
          "계층 구조와 드릴 모드",
          "상호 작용 편집",
          "필터 기능",
          "도구 설명",
          "테이블 & 행렬 시각화"
        ],
        "인사이트 얻기": [
          "조건부 서식",
          "분석선 (Analytics Line)",
          "인사이트 찾기 실습 (매출 하위 거래처 찾기)",
          "책갈피 (Bookmarks)",
          "단추(Button) 활용 페이지 탐색",
          "분해트리를 활용한 비중 분석",
          "이 분포가 다른 경우 찾기",
          "데이터의 증감 설명하기"
        ],
        "데이터 공유": [
          "Power BI Service에 게시 및 확인",
          "대시보드 생성 및 편집",
          "대시보드 공유 및 관리, 구독 기능",
          "보고서 내보내기"
        ]
      },
      "requirements": [
        "Power BI Desktop 설치가 가능한 Windows 기반 PC 또는 노트북",
        "(Power BI Desktop은 무료 설치 가능-강의 내용에 설치 가이드가 포함되어 있습니다)",
        "기초적인 Excel 사용 경험이 있다면 학습에 도움이 됩니다 (필수 아님)",
        "코딩 지식은 필요 없습니다, 데이터 분석과 시각화에 관심 있는 분이면 누구나 가능합니다"
      ],
      "description": "안녕하세요, 현재 식품 P사에서 RPA 개발/운영 및 데이터 시각화 교육을 담당하고 있는 박경덕입니다.\nPower Automate 교육에 이어, 이번에는 Power BI 강의를 Udemy에 정식 오픈하게 되었습니다.\n\n\n[Power BI로 완성하는 데이터 시각화 & 인사이트 분석]\nPower BI는 Microsoft에서 제공하는 무료 비즈니스 인텔리전스(BI) 도구로, 데이터를 시각적으로 분석하고 실무 보고서에 최적화된 대시보드를 만들 수 있는 강력한 도구입니다.\n현재 수많은 기업들이 Excel을 넘어 데이터 기반 의사결정을 위해 Power BI를 도입하고 있으며, 단순한 그래프 도구를 넘어 데이터 모델링, DAX 계산, 자동화된 보고 체계까지 지원하고 있습니다.\n\n\n[데이터 시각화, 이렇게 쉽게 배워도 되나요?]\n본 강의는 IT 비전공자, 데이터 입문자, 보고서 실무 담당자도 쉽게 따라올 수 있도록 구성되어 있습니다.\n실제 기업에서 사용하는 데이터와 매우 유사한 샘플 데이터를 바탕으로 차근차근 실습 중심으로 구성하였고,\n특히 다음과 같은 점이 강조됩니다.\nPower BI Desktop 설치부터 시작하는 처음 사용자용 로드맵\n엑셀처럼 직관적인 인터페이스와 다양한 시각화 차트 실습\n계층 구조, 조건부 서식, 대시보드 구성법 등 실무에 바로 적용 가능\n데이터를 이해하는 힘을 길러주는 DAX 수식의 핵심 개념 정리\nPowerPoint, PDF, Excel 등으로 보고서 내보내기\n경영정보시각화 능력시험 실기 시험에서 자주 등장하는 보고서 구성 방식과 차트 활용을 그대로 실습으로 학습 가능\n\n\n[Power BI Desktop은 누구나 무료 설치가 가능합니다.]\nMicrosoft365 계정이 없어도 Power BI 공식 홈페이지에서 무료로 설치 가능하며, 강의 초반에 설치 방법부터 안내합니다.\n\n\n[이 강의는 이런 분들께 추천합니다!]\n매출, 고객, 재고, 운영 데이터를 보고서로 표현하고 싶은 실무자\nPower BI를 처음 배우는 입문자\n엑셀 피벗과 VLOOKUP에 지쳐, 자동화된 시각화 도구가 필요한 분\n사내 데이터 분석 업무를 맡아 성과 지표와 트렌드를 보여줘야 하는 팀원\n이직이나 업무 포트폴리오를 위해 BI 도구 하나쯤은 마스터하고 싶은 분\n경영정보시각화 능력시험 실기 시험을 준비하고 있는 수험생\n\n\n현업에서 직접 Power BI를 활용하며 교육까지 진행해온 제가, 가장 실용적이고 직관적인 방법으로 Power BI를 안내해드리겠습니다.\n보고서를 넘어 인사이트로! 지금 바로 Power BI 여정을 함께 시작해보세요.",
      "target_audience": [
        "Power BI를 활용한 대시보드 구성, 분석 흐름 이해, 시각화 기능의 구조적 학습이 필요한 분",
        "보고용, 설득용, 발표용 Power BI 시각화 자료를 스스로 구성하고 싶은 분",
        "데이터 분석을 처음 시작하는 직장인, 비전공자, 또는 팀 보고서용 시각화를 실무에서 바로 활용하고 싶은 분",
        "엑셀만으로는 한계가 있다고 느끼는 실무자로서, 보다 직관적인 데이터 시각화와 보고서를 만들어보고 싶은 분",
        "복잡한 코딩 없이도 데이터를 활용해 통찰력 있는 보고서를 만들고 싶은 분"
      ]
    },
    {
      "title": "Crea tu portafolio como Data Engineer | 4 proyectos Reales",
      "url": "https://www.udemy.com/course/crea-tu-portafolio-como-data-engineer-4-proyectos-reales-datexland/",
      "bio": "Conviértete en un Data Engineer | Pipelines Ingeniería de datos | AWS Free Tier | Crea Apps Interactivas con Streamlit",
      "objectives": [
        "Aprenderás a enviar notificaciones a tu celular diariamente con Twilio y Python",
        "Aprenderás a extraer datos de la Web e ingestarlos en una tabla de Snowflake usando Airflow",
        "Aprenderás a extraer datos de YouTube Data API utilizando Python",
        "Aprenderás a usar funciones Lambda para extraer datos de API's",
        "Automatizarás procesos de extracción de datos usando Airflow",
        "Aprenderás a crear Apps con Streamlit",
        "Aprenderás a Dockerizar tus Apps",
        "Aprenderás consultar tus datos con AWS Athena"
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Valoraciones",
          "Metodología"
        ],
        "Proyecto #1 - Envía pronostico del tiempo a tu celular diariamente": [
          "Bienvenido al proyecto #1",
          "Configurando Número Twilio",
          "Obtención de api_key en WeatherApi",
          "Extrayendo pronostico del tiempo con Python",
          "Enviando SMS a tu celular usando libreria de Twilio",
          "Creando una instancia EC2 y conectarse desde tu terminal",
          "Preparación de nuestra instancia EC2",
          "Consideraciones de seguridad credenciales",
          "Envío diario del pronostico del tiempo desde tu instancia EC2 - Parte 1",
          "Envío diario del pronostico del tiempo desde tu instancia EC2 - Parte 2",
          "Challenge Proyecto 1"
        ],
        "Proyecto #2 : Ingesta datos de ligas de futbol en Snowflake con Airflow": [
          "Bienvenido al proyecto #2",
          "Instalación Docker",
          "Configuración ambiente local Airflow con Astronomer",
          "Airflow UI - Local",
          "Tutorial - Crea tu cuenta de prueba Snowflake",
          "Extracción de las ligas de futbol con pandas",
          "Vista Clásica Snowflake : Creación de tablas y stage en Snowflake",
          "Vista Nueva Snowflake : Creación de tablas y stage en Snowflake Via Queries",
          "Crea tu DAG de Airflow para el envió de data a Snowflake - Parte 1",
          "Como Obtener la URL desde la nueva UI de Snowflake",
          "Creando Conexiones a Snowflake y Variable de entorno",
          "No Aparece Snowflake como Connection Type en Airflow",
          "Crea tu DAG de Airflow para el envió de data a Snowflake - Parte 2",
          "Challenge Proyecto 2"
        ],
        "Proyecto #3 : Extrae estadísticas diarias de canales de YouTube": [
          "Bienvenido al proyecto #3",
          "Crendeciales Youtube API",
          "Estadísticas canales de YouTube - Parte 1",
          "Estadísticas canales de YouTube - Parte 2",
          "Estadísticas canales de YouTube - Parte 3",
          "Creación de AWS Lambda Function - Parte 1",
          "Creación de AWS Lambda Function - Parte 2",
          "Test de AWS Lambda Function",
          "Automatizando Lambda Function - Parte 1",
          "Automatizando Lambda Function - Parte 2",
          "Insights Amazon Athena - Channel Stats",
          "Insights Amazon Athena - Channels Growth",
          "Challenge Proyecto 3"
        ],
        "Proyecto Final Streamlit : Geolocaliza las Gasolineras mas cercanas con Folium": [
          "Bienvenido al proyecto final",
          "Datos Abiertos Colombia",
          "Api's para Geocoding",
          "Cleaning Data Parte 1 - Address",
          "Cleaning Data Parte 2 - Address",
          "Geocoding Parte 1",
          "Geocoding Parte 2",
          "Cleaning Data Parte 3 - Latitud y Longitud",
          "Mapa Central Location",
          "Mapa Estaciones de Combustible",
          "Creación de App Parte 1 - Geolocalización de estaciones",
          "Creación de App Parte 2 - Geolocalización de estaciones",
          "Creación de App Parte 3 - Geolocalización de estaciones",
          "Creación de App Parte 4 - Geolocalización de estaciones",
          "Dockerizando tu imagen",
          "Challenge Proyecto Final"
        ],
        "¿ Que sigue ahora ?": [
          "Mejora tu Marca personal con tus nuevos proyectos"
        ]
      },
      "requirements": [
        "Conocimientos básicos en Python y en Git ,por otro lado si no has tenido la oportunidad de usar las herramientas del curso, te enseñaré lo necesario para que crees tus proyectos personales ganadores sin gastar un solo centavo y desde CERO.",
        "Conocimientos básicos de Docker"
      ],
      "description": "Si buscas convertirte en un Data Engineer Crack en el corto plazo , incrementar tus skills procesando y automatizando la extracción datos para encontrar el trabajo de tus sueños estás en el curso correcto.\n\n\nTendrás la oportunidad en tan solo 4 proyectos  de poner en practica herramientas de Orquestación , almacenamiento , AWS cloud  ,notificaciones , creación de Apps y Dockerización las cuales son relevantes al momento de aspirar a un cargo como Data Engineer en LATAM  y lo mejor GRATIS.\n\n\nTe enseñaré lo necesario al momento de querer montar un proyecto GANADOR para tu portafolio como Data Engineer y te garantizo que vas a enamorarte tanto como YO de lo que hacemos como Data Engineers.\n\n\nEn este curso utilizaremos Python , debido a que  es considerado  uno de los mejores lenguajes de programación para principiantes y uno de los favoritos a la hora de procesar datos , en cuanto a las herramientas que usaremos tenemos las siguientes :\n\n\nAWS Free Tier >> ¡Lo mejor !\nInstancias EC2\nS3 Buckets\nAWS Lambda\nSNS para notificaciones\nAPI's request\nAthena\nSnowflake\nAirflow\nStreamlit\nDocker\n\n\nEste curso es una extraordinaria opción para ti si :\n\n\nDeseas encontrar esa oportunidad laboral de tus sueños en el corto plazo a bajo costo\nDeseas crear un portafolio ganador que hable por ti y sin recomendaciones\nDeseas enviar notificaciones automáticas a tu celular ó Email\nQuieres crear Apps sencillas que generen valor a tu cliente final\nQuieres automatizar extracciones de datos e ingestarlas en tu DWH\nQuieres aprender a extraer datos de  API's",
      "target_audience": [
        "Data Engineers principiantes que deseen crear un portafolio ganador para este 2022",
        "Data Engineers intermedios que deseen incrementar sus skills en procesamiento , automatización y orquestación de flujos",
        "Personas que necesitan extraer datos de la web para un proyecto ó creación de un articulo",
        "Cualquier persona que quiera aprender Ingeniería de datos de una manera sencilla",
        "Desarrolladores de Python principiantes con interes por la ciencia de datos",
        "Personas que les gusta aprender a través de la práctica"
      ]
    },
    {
      "title": "메타분석 입문을 위한 RevMan 배우기",
      "url": "https://www.udemy.com/course/ez_revman/",
      "bio": "메타분석, RevMan의 기본 사용법으로 시작하세요.",
      "objectives": [
        "메타분석의 기본 개념",
        "메타분석을 위한 검색식 잡기",
        "논문 발표를 위한 메타분석의 최소한의 결과들",
        "깔끔하게 정리된 메타분석의 그래프들"
      ],
      "course_content": {
        "간단히 예제 - 이분변수 연구로": [
          "1. RevMan 설치",
          "2. 예제 데이터의 설명",
          "3. 자료 입력하기",
          "4. risk of bias",
          "5. Figure 만들기"
        ],
        "복잡한 예제 - 연속변수 연구로": [
          "6. subgroup을 가진 연속 변수 데이터 입력하기",
          "7. RevMan 100배 활용하기"
        ]
      },
      "requirements": [
        "컴퓨터, 인터넷",
        "메타분석을 사용한 논문을 몇 편 읽어 본 사람이 이해하기 편합니다."
      ],
      "description": "메타분석이 무엇이며, 어떻게 진행되는지, RevMan을 통해서 배워 봅니다.\nRevMan은 study를 입력하고, bias를 평가하고 기록하기에 적절하며,\n필수적인 Figure들과 요약된 통계량을 보여주기에 최적의 도구입니다.\n그 결과,\n메타분석의 개념을 이해하고, 메타분석을 평가할 수 있는 눈을 가지게 합니다.\n메타분석을 시작할 수 있겠다는 동기력과 자신감을 가지게 됩니다.\n메타분석을 더욱 확대하여 다양한 메타분석에 대한 관심을 가지게 합니다.",
      "target_audience": [
        "메타분석을 시도하려는 의학 연구자",
        "메타분석이 어떤 것인지 알고 싶은 연구자",
        "RevMan을 어떻게 쓰는지 알고 싶은 사람"
      ]
    },
    {
      "title": "أساسيات الذكاء الاصطناعي: مقدمة عن تقنيات الذكاء الاصطناعي",
      "url": "https://www.udemy.com/course/ai-artificial-intelligence-and-machine-learning-in-arabic/",
      "bio": "أساسيات الذكاء الاصطناعي: مقدمة عن تقنيات الذكاء الاصطناعي من معهد \"ام تي اف\" للإدارة والتقنية والمالية",
      "objectives": [
        "الذكاء الاصطناعي، تاريخه واستخداماته",
        "ما هو التعلم الآلي وأين يُستخدم؟",
        "الشبكات العصبية والتعلم العميق",
        "العلاقة بين التعلم الآلي والشبكات العصبية والتعلم العميق",
        "الذكاء الاصطناعي العام",
        "الوكيل الذكي",
        "معالجة اللغة الطبيعية",
        "الرؤية الحاسوبية",
        "أخلاقيات الذكاء الاصطناعي",
        "الذكاء الاصطناعي في علم الروبوتات",
        "خوارزميات البحث",
        "تمثيل المعرفة والاستدلال في الذكاء الاصطناعي",
        "الذكاء الاصطناعي القابل للتفسير والشفافية",
        "الذكاء الاصطناعي التوليدي"
      ],
      "course_content": {
        "المقدمة": [
          "المقدمة",
          "Welcome to MTF"
        ],
        "مُدخَل الى الذكاء الاصطناعي للجميع": [
          "الذكاء الاصطناعي، تاريخه واستخداماته",
          "ما هو التعلم الآلي وأين يُستخدم؟",
          "الشبكات العصبية والتعلم العميق",
          "العلاقة بين التعلم الآلي والشبكات العصبية والتعلم العميق",
          "الذكاء الاصطناعي العام",
          "الوكيل الذكي",
          "معالجة اللغة الطبيعية",
          "استمع إلى تقنية تحويل النص إلى كلام",
          "الرؤية الحاسوبية",
          "أخلاقيات الذكاء الاصطناعي",
          "الذكاء الاصطناعي في علم الروبوتات",
          "خوارزميات البحث",
          "تمثيل المعرفة والاستدلال",
          "الذكاء الاصطناعي القابل للتفسير والشفافية",
          "الذكاء الاصطناعي التوليدي"
        ],
        "التقييم والتدريب العملي على الذكاء الاصطناعي": [
          "الرؤية الحاسوبية في الذكاء الاصطناعي: تطبيقات عملية",
          "نظرة الذكاء الاصطناعي: تجربة تطبيقية في تحليل الصور",
          "استكشاف أنواع مختلفة من الزهور باستخدام محرك بحث Bing",
          "انشاء الصور بدعم من الذكاء الاصطناعي مع Bing",
          "استكشاف تقنية التحويل من الصوت إلى نص بالذكاء الاصطناعي مع Bing"
        ],
        "أساسيات الذكاء الاصطناعي: اختبر نفسك": [
          "أساسيات الذكاء الاصطناعي: اختبر نفسك"
        ],
        "Interactive Part, Next Steps and Answers to Questions": [
          "Bonus Section: Next Steps (English)"
        ]
      },
      "requirements": [
        "للحصول على تجربة تعليمية أفضل، نقترح عليك استخدام جهاز حاسوب أو جهاز لوحي أو هاتف محمول وتدوين الملاحظات لتسليط الضوء على النقاط المهمة وعمل ملخصات لتعزيز تجربتك تعلمك"
      ],
      "description": "مرحبًا بكم في دورة أساسيات الذكاء الاصطناعي: مُقدِّمة عن تقنيات الذكاء الاصطناعي\n\nالدورة مُقدَّمَة من معهد ام تي اف (MTF) للإدارة والتقنية والمالية\nام تي اف (MTF) هو معهد عالمي للتعليم والبحث العلمي، يقع مقره الرئيسي في لشبونة، البرتغال، ويركز على التعليم الهجين (الحضوري داخل المعهد وعبر الإنترنت) في مجالات الأعمال والإدارة، والعلوم والتقنية، والخدمات المصرفية والمالية.\nيهتم مركز ام تي اف للبحث والتطوير (MTF R&D) بالأنشطة البحثية في مجالات: الذكاء الاصطناعي (Artificial Intelligence)، التعلم الآلي (Machine Learning)، علوم البيانات (Data Science)، البيانات الضخمة (Big Data)، ويب 3 (WEB3)، سلسلة الكتل (Blockchain)، العملة المشفرة (Cryptocurrency)، الأصول الرقمية (Digital Assets)، ميتافيرس (Metaverse)، التحول الرقمي (Digital Transformation)، التقنية المالية (Fintech)، التجارة الإلكترونية (Electronic Commerce)، انترنت الأشياء (Internet of Things).\nام تي اف (MTF) هي الشريك الرسمي لكل من:  آي بي إم (IBM)، إنتل (Intel)، مايكروسوفت (Microsoft)، وهي عضو في غرفة التجارة والصناعة البرتغالية (Portuguese Chamber of Commerce and Industry).\nام تي اف (MTF) موجودة في 208 دولة وقد تم اختيارها من قبل أكثر من 380.000 طالب.\n\n\nمرحبًا وأهلا وسهلا بكم، أشكركم للانضمام إلينا في هذه الدورة التي اتطلع لمرافقتكم بها لفهم امكانات الذكاء الاصطناعي وكيفية الاستفادة منه واستخدامه لإحداث أثر ايجابي.\nاسمي محمد الفاتح مكي، مهندس نظم وتقنية المعلومات. أعمل في مجال تقنية المعلومات منذ أكثر من عقد من الزمن، وحاصل على شهادة كبير مسؤولي التقنية من معهد ام تي اف (MTF) للإدارة والتقنية والمالية.\nأحب المعرفة ونشرها، ولهذا السبب أقدم هذه الدورة للمهتمين بفهم أساسيات الذكاء الاصطناعي وبعض تطبيقاته الحديثة.\nسنستكشف معاً في هذه الدورة مجموعة واسعة من الموضوعات المتعلقة بالذكاء الاصطناعي بما في ذلك:\n\nما هو الذكاء الاصطناعي؟\nهو مجال من علوم الحاسب الآلي يدرُس كيفية إنشاء آلات وتقنيات يمكنها معالجة المعلومات واتخاذ القرارات وتنفيذ مهام محددة.\n\nتاريخ للذكاء الاصطناعي الحديث\nيمتد مجال الذكاء الاصطناعي إلى تاريخ طويل وعريق، يعود تاريخه إلى الأيام الأولى للحوسبة. ومع ذلك، فقد تأسس المجال كما نعرفه اليوم في عام 1956 في مؤتمر بكلية دارتموث في نيو هامبشاير. جمع هذا المؤتمر بعضًا من الباحثين الرائدين بمجال الذكاء الاصطناعي في ذلك الوقت، بمن في ذلك آلان تورينج وجون ماكارثي ومارفين مينسكي. يُنسب إلى المؤتمر الفضل في المساعدة على تعريف مجال الذكاء الاصطناعي ووضع جدول أعمال للبحث المستقبلي.\n\nالذكاء الاصطناعي مجال معقد يتطلب مهارات ومعرفة متنوعة لذلك فان التعاون بين الأشخاص من التخصصات المختلفة للعمل سويّا من أجل تطويرهً هو أمر ضروري. على سبيل المثال تطوير النماذج اللغوية الكبيرة تطلب هذا الأمر تعاون العديد من الأشخاص ذوي المهارات المختلفة، مثل علماء الحاسب الآلي واللغويين وعلماء البيانات. لقد عملوا معًا لتطوير طرق جديدة لتدريب نماذج اللغة الكبيرة، كما قاموا بجمع ومعالجة الكميات الهائلة من النصوص والرموز اللازمة لتدريب هذه النماذج.\n\nما هو التعلم الآلي؟\nالتعلم الآلي هو نوع من الذكاء الاصطناعي الذي يسمح للحاسب الآلي بالتعلم من البيانات دون الحاجة إلى برمجة، أو بعبارة أخرى، يمكن لخوارزميات التعلم الآلي التعرف على الأنماط والاستنتاجات بناءً على البيانات، دون الحاجة إلى أمر من أحد حول كيفية القيام بذلك. وهذا يُمكّن الحاسب الآلي من تعلم مهام جديدة وتحسين أدائها بمرور الوقت دون تدخل بشري.\n\nأين يُستخدم التعلم الآلي؟\nيُستخدم التعلم الآلي في مجموعة واسعة من التطبيقات، بما في ذلك تصفية البريد الإلكتروني، وتخصيص وسائل التواصل الاجتماعي، والتعرف على الصور، والتعرف على الكلام، وكشف الاحتيال، واستنتاج النص، واقتراح المنتجات، والتشخيص الطبي، تخصيص الرعاية الصحية، واستنتاج حركة المرور.\n\nما هي الشبكات العصبية؟\nالشبكات العصبية هي نوع من خوارزميات التعلم الآلي المستوحاة من بنية ووظيفة الدماغ البشري. تتكون الشبكات العصبية من عقد مترابطة، تعالج المعلومات بطريقة مستوحاة من كيفية عمل الدماغ. العقدة هي وحدة أساسية يمكنها استقبال وتخزين وارسال المعلومات.\n\nما هو التعلم العميق؟\nالتعلم العميق هو نوع من التعلم الآلي الذي يستخدم شبكات عصبية ذات طبقات متعددة. تتكون كل طبقة من عدة عقد يمكنها القيام بمهام متنوعة. هذا يسمح لنماذج التعلم العميق بتعلم أنماط أكثر تعقيدًا من البيانات مقارنةً بخوارزميات التعلم الآلي التقليدية. كلما زاد عدد الطبقات، تعمق النموذج، وأصبح أكثر قوة. قد تم استخدام التعلم العميق لتحقيق نتائج قيّمة في مجموعة واسعة من المهام، بما في ذلك التعرف على الصور، والتعرف على الكلام، والترجمة الآلية.",
      "target_audience": [
        "لا توجد متطلبات محددة، هذه الدورة مخصصة لكل الراغبين في بناء مهنة في مجال الذكاء الاصطناعي وعلوم البيانات أو تحسين معرفتهم"
      ]
    },
    {
      "title": "Mastering Numpy,Pandas and MatplotLib-Data Manipulation Tool",
      "url": "https://www.udemy.com/course/numpy-pandas-matplotlib-rakesh-roshan/",
      "bio": "Learn Numpy, pandas and matplotlib library which is the path for Data Science, Machine Learning, Data Analysis",
      "objectives": [
        "How to Download and Install Jupyter Notebook",
        "Working with Numpy for Numerical Computing",
        "Working with Array in Numpy",
        "Management of data",
        "Working with Pandas for data manipulations",
        "Series and DataFrames",
        "Reading files using Pandas",
        "Data Visualization Using Matplotlib Library",
        "Plotting Histogram, Bargraph, Scatter Plot, Boxplot, Pie Chart and many more"
      ],
      "course_content": {
        "Introduction to Numpy , Pandas and Matplotlib": [
          "Introduction to Numpy Library",
          "Introduction to Pandas",
          "Introduction to Matplotlib"
        ],
        "Anaconda for Jupyter Notebook and Google Colab": [
          "Download and Install Anaconda for Jupyter Notebook",
          "Working with Google Colab"
        ],
        "Numpy Part I - Basics": [
          "Creation and Initialization of Numpy Array",
          "Exploring Numpy Array",
          "Mathematical Operations using Numpy Array",
          "Indexing and Slicing",
          "Quiz Time"
        ],
        "Numpy Part 2-Advanced": [
          "Joining of Array",
          "Array Splitting",
          "Searching",
          "Sorting",
          "Random Module",
          "Quiz Time"
        ],
        "Advanced Numpy": [
          "What You Learn in this Section?",
          "Broadcasting and Vectorization",
          "Structure Array and Record Arrays",
          "Memory Layout & Performance Optimization",
          "Working with missing data using NumPy masked arrays",
          "Weather Data Analysis using Numpy"
        ],
        "Data Manipulation using Pandas Part I": [
          "Getting Started with Pandas",
          "Importing Files/Dataset",
          "Pandas Data Structure : Series",
          "Pandas Data Structure : DataFrame"
        ],
        "Data Manipulation using Pandas Part II": [
          "Merging , Joining and Concatenating",
          "Analyzing Data",
          "Cleaning Data",
          "Data manipulation"
        ],
        "Advanced Pandas": [
          "What you learn in this Section ?",
          "Hierarchical Indexing and MultiIndexing",
          "Pivot Table and Cross Tabulation",
          "Window Function - Rolling, Expanding and EWM",
          "Time Series and DateTime Indexing",
          "Efficient Data Filtering and Querying"
        ],
        "Data Visualization Using Matplotlib Library": [
          "Importance of Data Visualization",
          "Type of Data Visualization",
          "Concepts of matplotlib Library",
          "Line Plotting",
          "Histogram Plotting",
          "Bar Plotting",
          "Scatter Plot",
          "Pie Chart",
          "Box Plot",
          "Area Chart"
        ]
      },
      "requirements": [
        "No Programming Experiance Required"
      ],
      "description": "If you are looking to make a career as a Data Scientist, Data Analyst, Machine Learning Expert using Python, then Numpy, Pandas and Matplotlib library is very important to learn in today's scenario. In this course, you will get a detailed explanation of topics and functions related to Numpy, pandas and matplotlib library.  After this course, you can able to do Data Manipulation and Data Visualization. You can say these tools are the ladder for the Data Scientist.\nImportant Feature of this course is as follows:\n1. Every topic is covered practically.\n2. Explained in very easy language.\n3. Non-Programming background can also understand easily\n4. Demonstrated in a simple way so that you can do the same by watching videos.\nFor Data Science aspirants, this is the best course. Nowadays Data Visualization is an important tool to make decisions in organizations. Here using matplotlib library you can easily visualize the data using histogram, bar chart, pie chart, scatter diagram and many more.\n\n\nTopics Covered in Numpy:\n1. Numpy Array\n2. Numpy indexing and Slicing\n3. Copy vs View\n4. Numpy Array Shape, Reshape\n5. Numpy Array Iterating\n6. Numpy Array joining and Merging\n7. Splitting , Searching and Sorting\n8. Filtering\n9. Random Module\nTopics Covered in Pandas:\n1. Series\n2. DataFrame\n3. Import Files/Dataset\n4. Merging , Joining and Concatenating\n5. Analyzing Data\n6. Cleaning Data\n7. Data Manipulation\n\n\nTopics Covered in Matplotlib:\n1. Importance of Data Visualization\n2. Type of Data Visualization\n3. Concepts of matplotlib Library\n4. Line Plotting\n5. Histogram\n6. Bar Plot\n7. Scatter Plot\n8. Pie Chart\n9. Box Plot\n10. Area Chart",
      "target_audience": [
        "Students , Teachers, Professional who want to go for Data Science , Machine Learning , Data Analysis and Data Visualization"
      ]
    },
    {
      "title": "Inteligência Artifical Aplicada em Python",
      "url": "https://www.udemy.com/course/python-ia-aplicacoes-em-visao-computacional/",
      "bio": "Aprenda a Usar Pillow, OpenCV, MediaPipe, Hugging Face, NLTK, Spacy e muito mais para criar Aplicações Robustas em IA",
      "objectives": [
        "Aplicação de OpenCV e modelos pré-treinados para implementar sistemas de rastreamento de mãos e interpretação de gestos.",
        "Utilização de OpenCV e DLib para criar sistemas de reconhecimento facial e análise de expressões, aplicáveis em diversas soluções tecnológicas.",
        "Aplicação de HandTracking com OpenCV e MediaPipe para automatizar tarefas no computador com uso das mãos",
        "Aplicação de FaceMesh para identificar pontos na bola e nos olhos e detectar sonolência",
        "Explorar modelos do Hugging Face e criar interface visual com Gradio"
      ],
      "course_content": {
        "Apresentação": [
          "Apresentação do Curso",
          "Link para Nossa Comunidade"
        ],
        "Primeiros Passos": [
          "Instalação e Configuração do Python",
          "Ambiente Virtual de Desenvolvimento",
          "Introdução a Versionamento com GIT"
        ],
        "Python Fundamentos": [
          "Linguagem Python",
          "Configuração do VS Code",
          "Instalando o Python",
          "Primeiro Programa",
          "Exercício 1 - Hello World",
          "Tipos de Dados",
          "Exercício 2 - Tipos de Dados",
          "Utilizando o Input",
          "Concatenando Valores",
          "Exercício 3 - Concatenando Valores",
          "Utilizando Operadores",
          "Exercício 4 - Operadores",
          "Utilização de Strings",
          "Operações e Métodos em Strings",
          "Exercício 5 - Operações em Strings",
          "Exercício",
          "Utilizando uma Lista",
          "Exercício 6 - Listas",
          "Utilizando uma Tupla",
          "Exercício 7 - Tupla",
          "Utilizando um Set",
          "Exercício 8 - Set",
          "Utilizando um Dicionário",
          "Exercício 9 - Dicionário",
          "Trabalhando com Condições",
          "Utilizando For",
          "Utilizando While",
          "Utilizando List Comprehension",
          "Utilizando Funções",
          "Argumentos em Funções",
          "Função Recursiva",
          "Parâmetros Args e Kwargs",
          "Função Lambda",
          "O Desenvolvedor Júnior e o Especialista em Automação"
        ],
        "Módulos Built In": [
          "Primeiro Módulo",
          "Outros Modulos",
          "Módulo OS",
          "Módulo Math e Statistic",
          "Módulo Regex",
          "Módulo Hashlib",
          "Módulo Collections",
          "Módulo Random",
          "Módulo Tkinter"
        ],
        "Introdução a Processamento de Imagens com Pillow": [
          "Importando Imagem",
          "Operações em Imagens",
          "Brilho, Contraste e Nitidez",
          "Usando Filtros",
          "Escrevendo Texto em Imagem",
          "Aplicando Filtro de Sepia",
          "Ajustando a Exposição e Imagem 3D",
          "Imagem com Reflexão"
        ],
        "Detecção e Reconhecimento Facial": [
          "Preparando o Ambiente",
          "Importando a Imagem",
          "Detecção de Faces em Imagens",
          "Utilizando a Biblioteca FaceRecognition",
          "Detecção de Faces em Vídeo",
          "Detecção de Faces com DLib",
          "Separando Imagens",
          "Utilizando Reconhecimento Facial"
        ],
        "HandTracking": [
          "Preparação do Ambiente",
          "Conectando na Webcam",
          "Detecção de Pontos das Mãos",
          "Coletando as Coordenadas em Pixels",
          "Coletar Lado da Mão",
          "Identificando os Dedos",
          "Abrindo Programas",
          "Fechando Programas",
          "Gerenciando Música por Gestos"
        ],
        "FaceMesh": [
          "Preparação do Ambiente",
          "Capturando Vídeo da Webcam",
          "Detectando Pontos da Face",
          "Melhorando Marcações",
          "Detecta Pontos dos Olhos",
          "Calculando EAR",
          "Calculando o Tempo"
        ],
        "Introdução à Análise de Texto": [
          "Utilizando um Texto",
          "Aplicando Tokenização",
          "Frequência de Distribuição",
          "Utilizando WordCloud",
          "Coletando Dados da Internet",
          "Aplicando Análise Textual"
        ],
        "Fundamentos de PLN com Spacy": [
          "Utilizando Modelo Português",
          "Usando POS",
          "Lemma x Stemmer",
          "Entidades Nomeadas",
          "StopWords",
          "Relação entre Palavras",
          "Similaridade entre palavras"
        ]
      },
      "requirements": [
        "Não há pré-requisito no curso. Ensinaremos desde os tópicos iniciais até a construção de aplicações em PLN e Visão Computacional."
      ],
      "description": "Neste curso completo de Python, você irá explorar o fascinante mundo de Processamento de Imagens e da Visão Computacional. Ao longo das aulas, você aprenderá a usar as principais bibliotecas e ferramentas dessas áreas para desenvolver aplicações práticas e inovadoras.\nTópicos do Curso:\nIntrodução à Processamento de Imagens\nConceitos básicos e principais aplicações de processamento de imagens.\nInstalação e configuração das bibliotecas Pillow.\nPrincipais operações em processamento de imagens\nHand Tracking\nDesenvolvimento de um sistema de rastreamento de mãos em tempo real.\nUso de OpenCV e modelos pré-treinados para detecção e rastreamento de mãos.\nAplicações práticas e ajustes finos para diferentes cenários.\nDetecção e Reconhecimento Facial\nTécnicas de reconhecimento e análise facial utilizando OpenCV e TensorFlow.\nCriação de um sistema para identificação e verificação de faces.\nImplementação de funcionalidades como reconhecimento de emoções e expressões faciais.\nProjetos Finais e Aplicações Avançadas\nDesenvolvimento de projetos integradores que combinam PLN e Visão Computacional.\nImplementação de soluções práticas e inovadoras para desafios do mundo real.\nDiscussão de casos de uso avançados e tendências futuras na área de IA.\nHugging Face e Gradio\nVamos explorar diversos modelos de visão computacional em Hugging Face.\nVamos construir interfaces poderosas em modelos de visão computacional com Gradio\nAnálise de Texto\nColeta de Dados (arquivos e páginas web)\nTokenização (token de sentença e de palavras) | Stopwords\nFrequência de Distribuição\nWordCloud\nAssistente Virtual de Voz\nConversão de Texto para Voz (Pyttsx3 e GTTs)\nReconhecimento de Voz (SpeechRecognition)\nLógica do Assistente Virtual\nIntegração com APIs, newsletter, funções do SO, etc (tudo via comando de voz)",
      "target_audience": [
        "Este curso é ideal para desenvolvedores, engenheiros de dados, cientistas de dados e entusiastas de inteligência artificial que desejam aprofundar seus conhecimentos em PLN e Visão Computacional e aplicar essas tecnologias em projetos do dia a dia."
      ]
    },
    {
      "title": "【한글자막】 Machine Learning 완벽 실습 : 6가지 실제 사례 직접 해결하기",
      "url": "https://www.udemy.com/course/best-machine-learning-6/",
      "bio": "머신 러닝 기초 학습 후 6가지의 실제 데이터를 이용한 머신 러닝 실습을 진행하는 실무 프로젝트 강의",
      "objectives": [
        "실제 데이터 과학 프로젝트가 어떤지 배우게 됩니다.",
        "이 사례 연구를 이력서에 포함할 수 있습니다.",
        "머신 러닝 실무자로 자신을 홍보할 수 있습니다.",
        "데이터 과학 직무 면접에서 자신감을 느낄 것입니다.",
        "여러 머신 러닝 알고리즘을 연결하여 목표를 달성하는 방법을 배우게 됩니다.",
        "Seaborn과 Matplotlib를 사용한 고급 데이터 시각화 기술을 배우게 됩니다.",
        "로지스틱 회귀에 대해 배우게 됩니다.",
        "L1 정규화(Lasso)에 대해 배우게 됩니다.",
        "랜덤 포레스트 분류기에 대해 배우게 됩니다."
      ],
      "course_content": {
        "개요": [
          "강의에 오신 걸 환영합니다",
          "보너스: 학습 경로",
          "강의 자료 받는 법",
          "성공을 위한 학습 팁"
        ],
        "유방암 분류": [
          "개요",
          "산업의 사례",
          "머신 러닝 관점에서의 사례 연구",
          "데이터 시각화",
          "모델 학습",
          "모델 평가",
          "모델 개선하기",
          "사례 연구 완료"
        ],
        "패션 클래스 분류": [
          "패션 산업에서의 변화",
          "머신 러닝 관점에서의 사례 연구",
          "데이터 시각화",
          "모델 학습 I",
          "모델 학습 II",
          "모델 학습 III",
          "모델 학습 IV",
          "모델 평가",
          "모델 개선하기",
          "사례 연구 완료"
        ],
        "앱 행동 분석을 통해 고객의 구독 유도하기": [
          "핀테크 사례 연구 개요",
          "개요",
          "데이터",
          "특성 히스토그램",
          "상관 그래프",
          "상관 행렬",
          "변수 가공 - 반응변수",
          "변수 가공 - 스크린",
          "데이터 전처리하기",
          "모델 구축하기",
          "모델 완성",
          "마무리"
        ],
        "재정 습관의 분석을 통해 해지율 최소화하기": [
          "개요",
          "데이터",
          "데이터 정리하기",
          "특성 히스토그램",
          "파이 그래프 분포",
          "상관 그래프",
          "상관 행렬",
          "원 핫 인코딩",
          "특성 스케일링 & 학습 세트 밸런싱",
          "모델 구축하기",
          "K-겹 교차 검증",
          "특성 선택",
          "모델 완성",
          "마무리"
        ],
        "신용 거래 실적에 따른 대출 전자 사인 가능성 예측하기": [
          "개요",
          "데이터",
          "데이터 정리하기",
          "히스토그램",
          "상관 그래프",
          "상관 행렬",
          "변수 가공",
          "데이터 전처리하기",
          "모델 구축하기 - 파트 1",
          "모델 구축하기 - 파트 2",
          "그리드 검색 - 파트 1",
          "그리드 검색 - 파트 2",
          "모델 완성",
          "마무리"
        ],
        "신용 카드 부정거래 탐지하기": [
          "사례 연구",
          "머신 러닝 용어집",
          "자료 준비",
          "데이터 시각화",
          "데이터 전처리하기",
          "딥 러닝 - 파트 1",
          "딥 러닝 - 파트 2",
          "데이터 분할하기",
          "모델 학습",
          "행렬을 이용한 모델 작동 방법",
          "혼동 행렬",
          "머신 러닝 분류기",
          "랜덤 포레스트",
          "결정 트리",
          "샘플링",
          "언더 샘플링",
          "합성 소수 샘플링 기술 (SMOTE)",
          "마무리",
          "보너스 비디오"
        ],
        "보너스 강의": [
          "***여러분을 위한 특별 보너스***",
          "Q&A 게시판 안내"
        ]
      },
      "requirements": [
        "이 과정을 완료하려면 Python에 대한 기초 지식이(Machine Learning A-Z 수준이면 충분합니다) 있어야 합니다.",
        "작업 환경(Anaconda, Jupyter Notebook, Spyder) 설치 방법을 알아야 합니다.",
        "이 강의는 머신 러닝을 처음 배우기 위한 강의로 적합하지 않습니다. 주요 개념을 이미 이해하고 있어야 합니다."
      ],
      "description": "6개의 실제 사례를 통한 실전 머신 러닝 완벽 실습!\n딥 러닝 기술과 실제 적용!\n포트폴리오를 위한 실무 프로젝트!\n\n\nMachine Learning 완벽 실습 : 6가지 실제 사례 직접 해결하기 강의를 선택해야 하는 이유\n\"머신 러닝의 이론도 알고 첫 알고리즘을 만드는 방법은 알고 있다면 이제 무엇을 해야 할까요?\n머신 러닝의 기본 이론만 다루는 것에 그치는 강의는 많지만 더 나아가 실습까지 하는 강의는 없습니다.\n\n\n이 강의는 그런 강의들과는 다릅니다.\n\n\n모든 이론과 지식을 실제 머신 러닝 과제에 적용할 준비가 되셨나요?\n그렇다면 \"머신 러닝 실습\" 강의에 오신 것을 환영합니다.\n저희는 수많은 프로젝트를 완료한 최고의 업계 전문가들을 모셨습니다.\n\n\n각 강사는 스스로의 경험을 통한 고유한 스타일을 가지고 있으며 실무에서도 그렇듯 이 강의를 성공적으로 완료하려면 이 스타일에 적응해야 합니다. 누구도 소외되지 않을 겁니다!\n\n\n이 강의는 실제 데이터 과학 프로젝트가 어떤지 설명합니다. 문제만 소개하고 실제 경험은 제공하지 않는 전례에서 벗어나는 강의일 겁니다.\n\n\n실습을 통해 머신 러닝을 배울 수 있는 강의, 이력서를 위한 실무적인 프로젝트를 진행하는 강의, 채용 담당자의 눈에 초심자처럼 보이지 않는 방법을 찾고 있다면 제대로 찾아오셨습니다!\n\n\n이 강의는 실생활 문제에 대한 실습 접근 방식을 제공하고 데이터 과학의 세계에서 성공하는 데 정확히 필요한 것을 다룹니다.\n\n\nMachine Learning 완벽 실습 : 6가지 실제 사례 직접 해결하기 강의의 6가지 주제는 아래와 같습니다.\n당뇨병 초기 진단\n앱 사용 분석을 통해 고객을 제품을 구독하게 유도\n금융 부문의 해지율 최소화\nGPS 데이터로 고객 위치 예측\n미래 환율 예측\n패션 분류\n유방암 예측\n그리고 더 많은 사례 연구들!\n(모두 실제하고, 모두 사실이며, 모두 유용하고 적용 가능한 사례들입니다.)\n그리고 마지막 보너스로,\n이 강의는 딥 러닝 기술과 그 실제 적용에 대해서도 다룰 것입니다.\n\n\nLigency Team의 한마디!\n저희의 목표는 세계 최고의 실용적인 머신 러닝 강의를 구축하는 것입니다.\n\n\n머신 러닝 전문가가 되는 것이 목표라면 실생활 사례가 얼마나 가치가 있는지 알 것입니다.\n이 사례들은 이론만 아는 데이터 과학자와 직접 실습을 해 본 머신 러닝 전문가의 차이를 결정할 것입니다.\n따라서 포트폴리오에 추가할 수 있는 실습 경험을 얻고 싶다면 이 강의가 제격입니다.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n지금 등록하세요! 강의에서 뵙겠습니다.\n\n\n- Ligency Team",
      "target_audience": [
        "실제 데이터 과학 프로젝트가 어떤 모습인지 이해하고자 하는 데이터 과학 및 머신 러닝 애호가",
        "머신 러닝 및 Python 지식이 있으며 자신의 기술을 연습하고 싶은 사람"
      ]
    },
    {
      "title": "【한글자막】 재무 분석을 위한 Python 및 Machine Learning 완벽가이드",
      "url": "https://www.udemy.com/course/best-python-mi-financial-analysis/",
      "bio": "파이썬 프로그래밍의 기본 지식을 익히고 ML을 활용해서 금융 분야의 실제 응용 프로그램을 해결해 볼것 입니다.",
      "objectives": [
        "금융에 초점을 맞춘 데이터 과학과 머신 러닝을 위한 파이썬 3 프로그래밍을 마스터하게 됩니다.",
        "파이썬의 강력한 기능을 이용해 일일 포트폴리오 수익률, 리스크 및 샤프 비율 계산과 같은 주요 재무 개념을 활용하는 방법을 배우게 됩니다.",
        "CAPM(자본 자산 가격 모델)에 대한 이론을 이해하고 직관을 가질 수 있습니다.",
        "주피터 노트북을 활용한 데이터 사이언스의 개발, 발표, 공유 방법을 이해할 수 있습니다.",
        "과학 컴퓨팅에 Numpy, 데이터 분석에 Pandas, 데이터 플로팅, 시각화를 위한 Matplotlib, 그리고 통계그림을 위한 Seaborn 등 주요 파이썬 라이브러리 활용법을 배웁니다.",
        "실제 데이터세트를 활용해 싸이킷런 라이브러리를 이용한 머신러닝 모델 구축, 교육, 및 튜닝을 마스터합니다.",
        "주가 예측, 보안 뉴스 감성 분석, 신용카드 사기 탐지, 은행 고객 세분화, 대출 채무 불이행 예측 등 은행과 금융 분야의 실질적인 문제 해결을 위한 머신, 딥러닝 모델을 적용해봅니다.",
        "회귀 작업(단순/다중/다항식), 분류 및 클러스터링(K 평균)에 대한 다양한 기계 학습 알고리즘의 이론을 이해하고 직관을 키웁니다.",
        "평균 절대 오차, 평균 제곱 오차 및 루트 평균 제곱 오차 직관, R 제곱 직관, 조정 R 제곱 직관 등 다양한 KPI(핵심 성과 지표)를 사용하여 훈련된 머신 러닝 회귀 모델의 성능을 평가합니다.",
        "정확도, 정밀도, 리콜 및 F1 스코어와 같은 다양한 KPI(핵심 성과지표)를 사용해서 학습된 머신 러닝 분류기의 성능을 평가합니다.",
        "인공 신경망(ANN), 순환 신경망(RNN) 및 LSTM(장단기 메모리)에 대한 기본 이론과 직관력 그리고 수학을 이해하게 됩니다.",
        "후방 전파 및 하강 알고리즘을 활용해 인공신경망(ANN)을 연습합니다.",
        "네트워크 성능을 향상을 위해 숨겨진 레이어나 뉴런 수와 같은 인공 신경망(ANN)의 하이퍼 매개 변수를 활용해 봅니다.",
        "머신 러닝 및 데이터 과학 애플리케이션 제작을 위한 기능 엔지니어링 및 데이터 정리 전략을 마스터합니다."
      ],
      "course_content": {
        "강좌 소개, 성공을 위한 팁과 주요 학습결과": [
          "환영 메세지",
          "소개, 성공 팁과 우수 사례, 그리고 주요 학습 결과",
          "강의 개요와 주요학습 결과",
          "환경 세팅 & 강의 자료 다운로드",
          "구글 코랩 설명",
          "데이터 사이언스 학습 패스의 파이썬"
        ],
        "**********파트#1: 파이썬 프로그래밍 기초***********": [
          "파트 #1 소개: 파이썬 프로그래밍 기초"
        ],
        "파이썬 101: 변수 할당, 수학 연산, 우선 순위와 출력, 가져오기": [
          "코랩 노트북 – 변수 할당, 수학 연산, 우선순위와 출력, 가져오기",
          "변수 할당",
          "수학 연산",
          "우선 순위",
          "출력 작업",
          "사용자 입력 가져오기"
        ],
        "파이썬 101: 데이터 유형": [
          "코랩 노트북 - 데이터 유형",
          "불값",
          "리스트",
          "사전",
          "문자열",
          "튜플",
          "집합"
        ],
        "파이썬101: 비교 연산자와 논리 연산자 그리고 조건문": [
          "코랩 노트북 – 비교 연산자, 논리 연산자 그리고 If문",
          "비교 연산자",
          "논리 연산자",
          "조건문 – 파트 #1",
          "조건문 – 파트 #2"
        ],
        "파이썬101: 반복문": [
          "코랩 노트북 – For/While반복문, 범위, 리스트 컴프리헨션",
          "For반복문",
          "범위",
          "While 반복문",
          "반복 끝내기",
          "중첩 반복문",
          "리스트 컴프리헨션"
        ],
        "파이썬101: 기능": [
          "코랩 노트북 - 기능",
          "기능 : 내제된 기능",
          "사용자 정의 기능",
          "람다식",
          "맵",
          "필터"
        ],
        "파이썬101: 파일 조작": [
          "코랩 노트북 – 파일 작업",
          "텍스트 파일 읽고 쓰기",
          "CSV 파일 읽고 쓰기"
        ],
        "파이썬 101: 데이터 분석을 위한 데이터 사이언스 파이썬 라이브러리(넘파이)": [
          "코랩 노트북 - 넘파이",
          "넘파이 기초",
          "내제 메서드",
          "모양과 길이 유형",
          "수학 연산",
          "슬라이싱과 인덱싱",
          "요소 선택"
        ],
        "파이썬 101: 데이터 분석을 위한 데이터 사이언스 파이썬 라이브러리 (판다스)": [
          "코랩 노트북 - 판다스",
          "판다스 : 판다스와 데이터프레임 소개",
          "HTML 데이터 읽어오기, 기능 적용하고 분류하기",
          "데이터프레임 작업",
          "판다스의 기능들",
          "판다스의 기능들 정리와 분류",
          "병합/결합/붙이기"
        ]
      },
      "requirements": [
        "파이썬 초보자도 수강 할 수 있습니다",
        "머신러닝을 처음 배워도 괜찮습니다",
        "재무와 관련한 지식이 없어도 수강 할 수 있습니다"
      ],
      "description": "파이썬 프로그래밍과 머신러닝, 이를 활용한 재무 분석을 한 번에 학습하는 All in one 강의!\n파이썬을 몰라도, 머신러닝을 몰라도, 재무 지식이 없어도 문제없이 들을 수 있는 기초부터 탄탄한 강의!\n면접에서 활용 가능한 6개 이상의 실제 프로젝트 포트폴리오를 만들 수 있는 강의!\n매 강의마다 학습할 수 있는 문제와 코딩 연습 포함!\n\n\n재무 분석을 위한 Python 및 Machine Learning 강의를 선택해야 하는 이유\n여러분들은 이 강의에서 파이썬으로 실제 금융, 은행 애플리케이션 개발을 위해 필요한 모든 것들을 배울 수 있습니다!\n이 강의는 많은 측면에서 특별합니다\n파이썬 프로그래밍 기초, 파이썬을 활용한 재무 분석, 그리고 재무/은행 업무에서의 AI/ML 응용의 세 가지 파트로 구성된 강의로, 중간 마다 가벼운 문제와 코딩 연습이 준비되어 있어 실질적이고 쉬운 방법으로 위의 내용들을 학습할 수 있습니다.\n또한, 프로젝트 기반 학습 방식을 채택하여 향후 면접에서 활용 가능한 6개 이상의 실제 프로젝트 포트폴리오를 구축할 수 있습니다.\n\n\n자 그럼, 왜 파이썬을 배워야 할까요?\n파이썬은 2020년 배워야 할 1순위 프로그래밍 언어로 뽑혔습니다. 그럼 이제 파이썬을 배워야 할 여섯 가지 이유를 소개해드리죠!\n\n\n1. AI & 머신 러닝을 위한 넘버 원 언어: 파이썬은 머신 러닝과 인공지능을 위한 최고의 프로그래밍 언어입니다.\n\n\n2. 배우기 쉽다: 파이썬은 정말 배우기 쉬운 프로그래밍 언어 중 하나입니다. 특히, 여러분이 코딩에 전혀 경험이 없다면 더 와 닿을 것입니다.\n\n\n3. 일자리 수요: 파이썬 개발자들은 수요가 정말 많지만 인원은 적은 상황입니다. 이런 상황에서 파이썬은 당장 배워야 할 매력적인 프로그래밍 언어입니다.\n\n\n4. 높은 연봉: 미국 파이썬 프로그래머들의 평균 연봉은 1억 4천만 원 정도입니다.\n\n\n5. 확장성: 파이썬은 상당히 강력하고 확장성이 뛰어나서 구글, 인스타그램, 유튜브, 그리고 스포티파이 같은 실제 앱들은 모두 파이썬을 기반으로 합니다.\n\n\n6. 다용성: 파이썬은 세상에서 제일 쓰임이 많은 프로그래밍 언어입니다. 데이터 과학, 재무 분석, 머신 러닝, 컴퓨터 비전, 데이터 분석 및 시각화, 웹 개발, 게임, 그리고 로봇 애플리케이션에 사용 가능합니다.\n\n\n재무 분석을 위한 Python 및 Machine Learning 강의 구성\n이 과정은 파이썬 프로그래밍 기초, 파이썬을 활용한 재무 분석, 그리고 재무/은행 업무에서의 AI/ML 응용의 세 가지 파트로 나뉩니다. 자세한 내용은 아래를 참고하십시오.\na) 파트 1-파이썬 프로그래밍 기초 :\n초보자를 위한 파이썬 프로그래밍 기초는 데이터 형식, 변수 할당, 루프, 조건문, 함수, 그리고 파일 연산과 같은 개념을 다룹니다. 또한, 이 파트에선 Numpy와 Pandas 같은 데이터 과학을 위해 필요한 주요 파이썬 라이브러리를 배우게 됩니다. 마지막으로, Matplotlib, Seaborn, Ploty, 그리고 Bokeh와 같은 데이터 시각화 도구에 대해 알아볼 것입니다.\nb) 파트2- 파이썬으로 하는 재무 분석: 여기선 재무 분석을 위한 파이썬 활용법을 배웁니다. 일일 포트폴리오 수익률, 리스크, 샤프 비율 계산 등 주요 재무 개념을 다루게 됩니다. 또한, CAPM(자본 자산 가격 모델), 마코위츠 포트폴리오 최적화, 그리고 효율적인 프론티어 전략 역시 배우게 됩니다. 추가로 모맨텀 기반과 이동 평균 거래 등의 거래 전략도 다룰 예정입니다.\nC) 파트3-재무/금융에서의 AI/ML : 이 파트에선 재무에서의 AI/ML 응용 프로그램에 대한 실제 프로젝트를 다룹니다. LSTM(장단기 메모리) 네트워크 같은 심층 신경망을 적용해 주가 예측을 해볼 겁니다. 또, 은행 고객 세분화와 클러스터링 수행을 위한 K-평균 클러스터링 및 주요 구성 요소 분석 같은 비지도 머신 러닝 전략을 다룰 겁니다. 또한 NLP(자연어 처리)의 기초를 배워보고 이를 주식 감정 분석에 적용해보는 시간을 가질 것입니다.\n\n\n교수 및 250,000명 이상의 수강생을 보유한 베스트셀러 강사 Dr. Ryan Ahmed와 Ligency Team이 전하는 한 마디\n\n\nBlockchain의 핵심 개념에 대해 학습하고, 여러분이 속한 산업에 대해 Blockchain이 갖는 영향과, 이를 활용하기 위해서 무엇을 해야 하는지 알아보세요!\n\n\n파이썬 프로그래밍의 기초를 배우고 이를 적용해 금융 및 은행 분야에서 실제 문제를 해결할 준비가 되셨습니까?\n\n\n만약 그렇다면, “재무 분석을 위한 완벽한 파이썬 및 머신 러닝” 강의에 오신 것을 환영합니다. 이 과정에서 여러분들은 파이썬으로 실제 금융, 은행 애플리케이션 개발을 위해 필요한 모든 것들을 배울 수 있습니다!\n\n\n본 강의는 이런 사람을 위한 과정입니다:\n● 데이터 과학과 AI의 강력한 기능을 활용하여 비즈니스 프로세스를 최적화하고 수익을 극대화하면서 비용 절감을 원하는 재무 분석가\n● 초보 파이썬 프로그래머와 재무/금융 분야의 파이썬 및 데이터 과학 응용 프로그램에 대한 기본적인 이해를 얻고자 하는 데이터 과학자\n● 경력 쌓기를 원하고, 데이터 과학 포트폴리오를 구축하면서 실무 경험을 쌓고자 하는 투자 은행가 및 재무 분석가\n\n\n만약 여러분들이 파이썬이나 다른 프로그래밍 언어를 사용한 적이 없더라도 걱정하지 마십시오. 앞으로 다룰 주제별로 정확한 설명 강의가 진행될 것입니다. 기초부터 시작해서 점차 여러분들의 지식을 쌓아가도록 하겠습니다.\n이 강의에서, (1) 여러분은 실제 프로젝트에 기반한 학습 경험을 할 수 있고, 우리와 함께 6개 이상의 프로젝트를 수행할 것입니다. (2) 모든 코드와 슬라이드에 접근 권한이 주어집니다. (3) LInkedin 프로필에 수료 증명서를 첨부 가능하며, 회사에 여러분의 파이썬 프로그래밍 기술을 증명할 수 있습니다. (4) 본 강의는 30일 환불 보증 기간이 있습니다. 그 기간 동안 무료로 강의를 맛보세요! 이 강의에서 다루게 될 내용을 미리 보기 강의와 개요를 통해 확인해 보세요.\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n지금 당장 신청하세요, 당신을 기다리고 있습니다!\n\n\n- Ligency Team",
      "target_audience": [
        "데이터 과학과 AI의 강력한 기능을 활용해 비즈니스 프로세스를 최적화시키고 수익을 극대화함과 동시에 비용을 절감하고 싶은 재무 분석가",
        "파이썬 초보 프로그래머와 금융, 은행 분야에서 파이썬 및 데이터 과학 응용 프로그램에 대한 기초적인 이해가 필요한 데이터 과학자",
        "경력을 쌓으며 데이터 과학에 대한 포트폴리오를 만들고, 실질적인 경험을 원하는 투자 은행가 혹은 재무 분석가",
        "재무와 관련한 파이썬 라이브러리를 학습하고 싶은 파이썬 프로그래머"
      ]
    },
    {
      "title": "【超入門】BigQueryを使ってSQLで集計しPythonで加工・可視化・機械学習モデル構築まで一気通貫で行おう！",
      "url": "https://www.udemy.com/course/bigquery-sql-python/",
      "bio": "実務で非常によく使うBigQueryを使ってSQLで集計しテーブルを構築しよう！そしてPythonで対象のテーブルを参照してデータ分析を一気通貫で行っていこう！",
      "objectives": [
        "SQLの構文を学びます",
        "Pythonの構文を学びます",
        "Google Cloud PlatformのBigQueryを使う方法を学びます",
        "PythonからBigQueryのテーブルを参照して加工・可視化・機械学習モデル構築する方法を学びます"
      ],
      "course_content": {},
      "requirements": [
        "SQLやPythonを触ったことがない人でも初歩から学べるように作成していますのでプログラミングの経験は不要です"
      ],
      "description": "本コースはSQLとPythonの基礎を理解した上で、実際のデータを使って分析を行う実践的な内容になっています。\n\n\nデータ分析の一連の流れであるデータ理解や加工・集計・モデル構築といった過程を一通り網羅しており、BigQuery、Google Colaboratoryを使って実践さながらの分析をしていきます。\n\n\nBigQueryは実務で非常によく使われる高速処理が可能なデータウェアハウス。\n実務ではBigQueryを使ってデータを集計して、その上でPythonで可視化やモデル構築をすることがよくありますのでBigQueryに慣れておきましょう！\n\n\nこのコースでは「メジャーリーグの投球データ」を扱って分析をしていきます。\n\n\nGoogleのプロダクトを使ってSQL・Pythonで抽出・集計・加工・分析・可視化・モデル構築まで一気通貫で行う楽しさを味わってみてください！",
      "target_audience": [
        "BigQueryの使い方を学びたい人",
        "SQLとPythonの使い方を学びたい人",
        "実際の実務に沿ったデータ集計・可視化・モデル構築の一連の流れを理解したい人"
      ]
    },
    {
      "title": "Python na Prática",
      "url": "https://www.udemy.com/course/pythonnapratica/",
      "bio": "Aprenda PYTHON na prática do absoluto zero, com atualizações de desenvolvimento WEB com PYTHON",
      "objectives": [
        "Construção de Dashboard via PYTHON, utilizando bases distintas, XLS, QUERYS SQLSERVER, CSV, WEB entre outras",
        "Iremos entender do ZERO as famosas e tão complexas Funções do PYTHON para tratamento de dados, plotagens de gráficos",
        "Trabalhando na prática com tabelas, funções, dicionários, tuplas, listas, bibliotecas",
        "Criação de Telas para Dashboard",
        "Seaborn: Estendendo o Matplotlib com gráficos estatísticos prontos",
        "Streamlit: Criação rápida de apps com visual interativo e visualização de dados",
        "Dash (Plotly): Dashboards mais robustos, com maior controle sobre layout.",
        "Matplotlib: Base para gráficos em Python (básico, mas poderoso)",
        "Leitura e criação dos principais gráficos com Python: Barras, Linhas, Colunas, Boxplot, Dispersão, Área, Tabelas, Gráficos de Bolhas, Inclinação e muito mais."
      ],
      "course_content": {
        "APRESENTAÇÃO DO CURSO": [
          "Introdução"
        ],
        "CONHECENDO O PYTHON - TEORIA (IMPORTANTE)": [
          "TEORIA_1",
          "TEORIA_2",
          "TEORIA_3 + Conhcendo o COLAB",
          "4 Conhcendo o COLAB",
          "5 Conhcendo o COLAB",
          "6 Conhcendo o COLAB + Prática"
        ],
        "CONHECENDO PYTHON PURO": [
          "001_Donwload dos Materiais",
          "002 Pratica Pura",
          "003 Pratica Format",
          "004 Pratica Input",
          "005 Pratica Input Exercicio",
          "006 Pratica Input Float + Exercicio",
          "007 Pratica Finalizando Python"
        ],
        "INTRODUÇÃO A ESTRUTURA DO PANDAS": [
          "001_ANALISE_PANDAS",
          "002_ANALISE_PANDAS",
          "003_ANALISE_PANDAS",
          "004_ANALISE_PANDAS",
          "005_ANALISE_PANDAS",
          "006_ANALISE_PANDAS",
          "007_ANALISE_PANDAS",
          "008_1_GROUP BY",
          "009_2_GROUPBY_FUNCOES",
          "010_3_GROUP BY_+_EXERCICIO"
        ],
        "APRENDENDO ESTRUTURAS DE LISTAS": [
          "1_LISTAS",
          "2_LISTAS",
          "3_LISTAS",
          "4_LISTAS",
          "5_LISTAS"
        ],
        "APRENDENDO ESTRUTURAS DE TUPLAS": [
          "1_TUPLAS",
          "2_TUPLAS"
        ],
        "APRENDENDO ESTRUTURAS DE DICIONÁRIOS": [
          "1_DICIONARIO",
          "2_DICIONARIO",
          "3_DICIONARIO",
          "4_DICIONARIO",
          "5_DICIONARIO",
          "6_DICIONARIO"
        ]
      },
      "requirements": [
        "Não há requisitos para esse treinamento, iremos abordar do ZERO todos os processos, Variáveis, bibliotecas, framework",
        "Para quem já possui um pequeno conhecimento e precisa aperfeiçoar, iremos ver alguns conceitos como, FUNÇÕES, ANÁLISES DE DADOS, LÓGICA DE PROGRAMAÇÃO, entre outros processos.",
        "Não há requisito para fazer as aulas, iremos abordar desde o começo para quem precisa aprender na prática (mão na massa).",
        "O único requisito é vontade de estudar e aprender na prática."
      ],
      "description": "Curso \"Python para Análise de Dados e Desenvolvimento de Projetos\"\n\n\nO curso \"Python para Análise de Dados e Desenvolvimento de Projetos\" traz uma abordagem inovadora e prática, partindo do absoluto zero e focando tanto na programação quanto na aplicação de Python em cenários reais de análise de dados. Este curso foi cuidadosamente estruturado para cobrir todos os aspectos fundamentais da linguagem, incluindo manipulação de dados, criação de projetos práticos, e conceitos importantes de programação e análise de dados.\n\n\nEste curso é ideal tanto para iniciantes quanto para quem já tem algum conhecimento em Python.\nPara os novatos, oferecemos uma introdução completa que percorre desde o entendimento dos primeiros comandos até o desenvolvimento de projetos práticos. Para os mais experientes, prometemos avançar na segunda metade do curso, com temas mais complexos, como criação de conexão com SQLServer, Arquivos Json e integração de bibliotecas poderosas como Pandas, NumPy, Matplotlib entre outras e construção de aplicações mais robustas na WEB.\n\n\nTrabalharemos com uma variedade de fontes e formatos de dados, incluindo arquivos Excel, CSV, Instância de banco, e APIs de dados. Também aprenderemos a estruturar dados em DataFrames e a construir relatórios analíticos e automatizados usando Python. Todos os projetos são orientados às demandas do mercado atual, garantindo que os alunos estejam atualizados e capacitados para aplicar o que aprendem em ambientes profissionais, mesmo que nunca tenham programado antes.\n\n\nAlém disso, o curso oferece uma gama de materiais complementares: apostila digital para consulta, exercícios práticos, projetos de portfólio, templates prontos e suporte contínuo. As atualizações periódicas dos conteúdos e projetos mantêm o aprendizado dinâmico, alinhado com as tendências mais recentes no uso de Python para análise e automação.\nSeja você um completo iniciante ou alguém que deseja aprimorar suas habilidades, este curso é o ambiente ideal para se aprofundar no mundo do Python e se preparar para resolver problemas reais, criar soluções eficientes e destacar-se no mercado de tecnologia e dados.",
      "target_audience": [
        "Analistas BI, Profissionais que precisam trabalhar com criação de Reports construção de aplicativos WEB",
        "Para profissionais que buscam conhecer mais a fundo as estruturas do Python na prática",
        "Manipulação e tratamento de tabelas para usarmos no python com Dashboards",
        "Integração do SQLSERVER com PowerBi, diferença entre tipos de conexões."
      ]
    },
    {
      "title": "Curso de jornalismo de dados - introdução",
      "url": "https://www.udemy.com/course/curso-de-jornalismo-de-dados-introducao/",
      "bio": "Funções básicas do Python e análise de dados para jornalistas, outros profissionais e estudantes que nunca programaram",
      "objectives": [
        "Jornalismo de dados",
        "Análise Covid-19",
        "Introdução à linguagem de programação Python",
        "Introdução às bibliotecas Pandas e Matplotlib do Python",
        "Tratamento de dados de planilhas",
        "Análise de dados de planilhas",
        "Visualização de dados de planilhas"
      ],
      "course_content": {
        "Introdução": [
          "Introdução: importância do jornalismo de dados"
        ],
        "Instalação do Anaconda": [
          "Instalação do Anaconda"
        ],
        "Instalação do Python e Jupyter Notebook": [
          "Instalação do Python",
          "Instalação do Jupyter Notebook",
          "Comandos do Jupyter Notebook",
          "Orientações gerais"
        ],
        "Python básico": [
          "Variáveis",
          "Operadores matemáticos",
          "Strings",
          "Python básico teste 1",
          "Listas",
          "Listas",
          "Dicionários",
          "Dicionários",
          "Estrutura de repetição for",
          "Função print",
          "Operadores relacionais e estruturas de condição if/elif/else",
          "Python básico testes"
        ],
        "Preparação para a análise de dados": [
          "Instalação da biblioteca Pandas",
          "Bases públicas de dados",
          "Introdução ao Pandas",
          "Pandas: comandos básicos",
          "introdução ao Pandas"
        ],
        "Tratamento dos dados": [
          "Tratamento dos dados parte 1",
          "Tratamento dos dados parte 2",
          "Tratamento dos dados parte 3"
        ],
        "Análise de dados": [
          "Análise de dados parte 1",
          "Análise de dados parte 2"
        ],
        "Visualização de dados": [
          "Visualização de dados parte 1",
          "Visualização de dados parte 2",
          "Visualização de dados parte 3",
          "Tratamento, análise e visualização dos dados"
        ],
        "Covid-19: análise de dados": [
          "Análise de dados Covid-19"
        ],
        "Encerramento": [
          "Encerramento do curso"
        ]
      },
      "requirements": [
        "O curso foi feito para quem nunca programou partir do zero"
      ],
      "description": "Análise de dados do zero para quem tem interesse em aprender programação e análise de dados!!\nNo final do curso há um exemplo de análise da Covid-19\nEste curso é destinado para quem nunca teve contato com programação e quer aprender a fazer códigos para análise de dados por meio da linguagem de programação Python.\nConteúdo do curso:\n- Breve introdução ao jornalismo de dados e sua importância;\n- Instalação do Python e da interface do Jupyter Notebook;\n- Curso básico de Python, apenas com funções que vamos utilizar na análise de dados:\nVariáveis\nOperadores matemáticos\nStrings\nListas\nDicionários\nFor\nPrint\nOperadores relacionais\nIf\\elif\\else\n- Tratamento e análise dos dados de um arquivo do Governo Federal sobre gastos com passagens aéreas no ano de 2019 com a biblioteca Pandas;\n- Visualização dos dados com a biblioteca Matplotlib;\n- Análise e visualização de dados sobre a Covid-19 do arquivo disponível no site do Ministério da Saúde.",
      "target_audience": [
        "Jornalistas que querem aprender a fazer análise de dados",
        "Público em geral que queria conhecer a linguagem Python e a análise de dados",
        "Pessoas que querem iniciar um estudo em programação na linguagem Python"
      ]
    },
    {
      "title": "Maschinelles Lernen & Künstliche Intelligenz in der Theorie",
      "url": "https://www.udemy.com/course/maschinelles-lernen-und-kuenstliche-intelligenz-in-der-theorie/",
      "bio": "Alles von neuronalen Netzen, Deep Learning, Support Vector Machines, Regression bis Clustering und mehr",
      "objectives": [
        "viele verschiedene Techniken des Maschinellen Lernens anwenden und kombinieren",
        "zB neuronale Netze von null auf entwickeln",
        "bekannte Frameworks wie Tensorflow leichter verstehen und wissen, was sie tun"
      ],
      "course_content": {
        "Grundlagen": [
          "Einleitung",
          "Die Daten",
          "Konzept, Klassifikation und Regression",
          "Deduktion und Induktion",
          "Überwachtes und unüberwachtes Lernen",
          "Fehlerminimierung",
          "Gradientenabstieg",
          "Overfitting",
          "Abstandsmaße",
          "Teste dich!"
        ],
        "Instanzbasiertes Lernen": [
          "K-Nearest Neighbours",
          "KNN: Mathematik",
          "gewichteter KNN",
          "Case-based Reasoning",
          "Teste dich!"
        ],
        "Concept Learning": [
          "Teil 1",
          "Teil 2",
          "Konzeptlernen"
        ],
        "Unüberwachtes Lernen": [
          "k-Means Clustering",
          "Fuzzy K-Means Clustering",
          "Dendrogramme",
          "Cobweb #1",
          "Cobweb #2",
          "Was ist der Unterschied zwischen k-Means und kNN?",
          "Dendrogramme"
        ],
        "Bayes Lernen": [
          "Einleitung",
          "Das Bayes-Theorem",
          "Die Maximum A Posteriori Hypothese",
          "Konzeptlernen",
          "Funktionslernen",
          "Optimaler Bayes",
          "Der Naive Bayes-Klassifikator",
          "Schätzen von Werten",
          "Bayes'sche Netze",
          "Bedingte Unabhängigkeiten in Bayes'schen Netzen #1",
          "Bedingte Unabhängigkeiten in Bayes'schen Netzen #2",
          "D-Separation",
          "Objektorientierte Probabilistisch Relationale Modelle OPRM",
          "Parameterschätzung in OPRMs",
          "Strukturbestimmung in OPRMs",
          "Der EM-Algorithmus",
          "Teste dich!",
          "Naiver Bayes Klassifikator"
        ],
        "Entscheidungsbäume": [
          "Einleitung",
          "Der ID3-Algorithmus",
          "Entropie und Informationsgewinn",
          "Reduced Error Pruning",
          "Attribute mit vielen Werten und kontinuierliche Werte",
          "Random Forests"
        ],
        "Markov Modelle": [
          "Diskrete Markov Modelle",
          "Hidden Markov Modelle",
          "Das Evaluationsproblem und der Forward-Backward-Algorithmus",
          "Das Dekodierungsproblem und der Viterbi-Algorithmus",
          "Der Baum-Welch-Algorithmus",
          "Der Baum-Welch-Algorithmus #2",
          "Typen von HMMs",
          "Hidden Markov Modelle"
        ],
        "Deduktives Lernen": [
          "Einleitung",
          "Explanation Based Learning",
          "Knowledge Based Neural Networks"
        ],
        "Markov Logik Netze": [
          "Probabilistische Graphische Modelle",
          "Markov Logik Netze",
          "Der MAP-Algorithmus",
          "Generatives Lernen"
        ],
        "Evolutionäre Algorithmen": [
          "Der Grundalgorithmus",
          "Mutationen",
          "Rekombinationen",
          "Selektion",
          "Fitness Based Selection",
          "Ranking Based und Tournament Selection",
          "Evolutionäre Algorithmen"
        ]
      },
      "requirements": [
        "Mathematische Vorkenntnisse",
        "Abstraktes Denken"
      ],
      "description": "In diesem Kurs lernst du, wie viele verschiedene Techniken des Maschinellen Lernens funktionieren. Du lernst, sie zu berechnen, zu entscheiden, wann welche Technik einzusetzen ist und was ihre Schwächen und Stärken sind.\nNatürlich werden wir uns auch mit Deep Learning und neuronalen Netzen beschäftigen und die vielen Arten von Netzen und Techniken kennen lernen.",
      "target_audience": [
        "Alle, die verstehen möchten, wie künstliche Intelligenzen funktionieren und lernen",
        "Alle, die ihre eigene Intelligenz entwickeln möchten"
      ]
    },
    {
      "title": "Matemática para Data Science - Pré-Cálculo",
      "url": "https://www.udemy.com/course/matematica-para-data-science-pre-calculo/",
      "bio": "Exemplos e aplicações com Python",
      "objectives": [
        "Conceitos gerais sobre funções matemáticas",
        "Função polinomial do 1º Grau",
        "Função polinomial do 2º Grau",
        "Função exponencial",
        "Função logarítmica",
        "Função modular",
        "Trigonometria"
      ],
      "course_content": {
        "Introdução": [
          "Sobre o curso - Ementa",
          "Didática do curso"
        ],
        "Introdução a Funções": [
          "Introdução a funções",
          "Revisão sobre conjuntos numéricos 1-2",
          "Revisão sobre conjuntos numéricos 2-2",
          "Funções e conjuntos",
          "Domínio, Contra domínio e Imagem",
          "Exemplos de Domínio, Contra domínio e Imagem",
          "Função Injetora/injetiva",
          "Função sobrejetova/sobrejetiva",
          "Função bijetora/bijetiva",
          "Função inversa",
          "Plano cartesiano R^2",
          "Gráficos e tipos de funções",
          "LISTA DE EXERCÍCIOS - 1"
        ],
        "Função polinomial do 1º Grau": [
          "Equação geral do polinômio",
          "Funções crescentes e decrescentes",
          "Função polinômial do 1º Grau",
          "Características da função do 1º Grau",
          "Exemplos de função do 1º Grau",
          "Raiz da função do 1º Grau",
          "Gráfico da função do 1º Grau 1-2",
          "Gráfico da função do 1º Grau 2-2",
          "LISTA DE EXERCÍCIOS - 2"
        ],
        "Função polinomial do 2º Grau": [
          "Função polinomial do 2º Grau - quadrática",
          "Gráfico de uma função quadrática",
          "Raízes de uma função quadrática",
          "Estudo do Delta da equação do 2º Grau",
          "Exemplos de cálculo de raízes de parábolas",
          "Raiz complexa",
          "Desenhando parábolas - raízes e vértices",
          "Vértice de uma parábola - Otimização",
          "Demonstração do Vértice de uma parábola",
          "APLICAÇÂO - Otimização: área máxima",
          "LISTA DE EXERCÍCIOS - 3"
        ],
        "Função exponencial": [
          "Função exponencial - introdução",
          "Potenciação: nº inteiros não negativos e negativos",
          "Potência de nº inteiros 1-2",
          "Potência de nº inteiros 2-2",
          "Potência de nº racional 1-2",
          "Potência de nº racional 2-2",
          "Equações exponenciais 1-4",
          "Equações exponenciais 2-4",
          "Equações exponenciais 3-4",
          "Equações exponenciais 4-4",
          "O que é uma função exponencial",
          "Características da função exponencial",
          "Gráfico de uma função exponencial",
          "LISTA DE EXERCÍCIOS - 4"
        ],
        "Função logarítmica": [
          "Introdução aos logaritmos",
          "Definição de logaritmos 1-2",
          "Definição de logaritmos 2-2",
          "Condições de não existência dos logaritmos",
          "Logaritmos importantes",
          "Logaritmos decimais e neperianos",
          "Propriedade log do produto",
          "Propriedade log do quociente",
          "Propriedade log da potência",
          "Mudança de base 1-2",
          "Mudança de base 2-2",
          "Equações logarítmicas 1-3",
          "Equações logarítmicas 2-3",
          "Equações logarítmicas 3-3",
          "Função logarítmica 1-2",
          "Função logarítmica 2-2",
          "LISTA DE EXERCÍCIOS - 5"
        ],
        "Função modular": [
          "Função modular definição",
          "Exemplo de função Modular 1-3",
          "Exemplo de função Modular 2-3",
          "Exemplo de função Modular 3-3",
          "LISTA DE EXERCÍCIOS - 6"
        ],
        "Trigonometria": [
          "Trigonometria - Triangulo retângulo",
          "Teorema de Pitágoras",
          "Ângulos internos de um triangulo",
          "Relação graus e radianos",
          "Relações trigonométricas no triangulo retângulo",
          "Ângulos notáveis 1-3",
          "Ângulos notáveis 2-3",
          "Ângulos notáveis 3-3",
          "APLICAÇÂO: cálculo de altura",
          "Exercício - lado de um triângulo retângulo",
          "Círculo trigonométrico",
          "Exemplos de arcos no círculo trigonométrico",
          "Função Seno",
          "Função seno nos arcos notáveis",
          "Gráfico de uma função seno",
          "Função Cosseno",
          "Gráfico da função cosseno",
          "Função Tangente - Círculo trigonométrico",
          "Gráfico da função tangente",
          "LISTA DE EXERCÍCIOS - 7"
        ],
        "Dúvidas e Soluções dos Exercícios": [
          "Sobre as dúvidas",
          "Desafio - Revisão Propriedades da Potência",
          "Dúvida: Lista 5 - Questão 7 - Letra B",
          "Dúvida: Exercício resolvido 04 - Função Logarítmica",
          "Lista 4 - Questão 6 - Letra f",
          "Lista 5 - Questão 1 - Letra B",
          "Solução da Lista 1 - 4ª Questão",
          "Desafio - Área Máxima com Cerca de Arame",
          "Solução Desafio Área Máxima",
          "IMPORTANTE - Para continuar os estudos"
        ],
        "Aplicações - Data Science": [
          "Python - Anaconda - Colab",
          "Curso Python - Aprenda os Fundamentos",
          "Plot de funções polinomiais",
          "Plot de funções expoenciais e logarítmicas",
          "Plot de funções trigonométricas",
          "APLICAÇÃO DATA SCIENCE - Regressão Linear",
          "APLICAÇÃO DATA SCIENCE - Ajuste polinomial"
        ]
      },
      "requirements": [
        "Ter concluído o ensino fundamental."
      ],
      "description": "O pré-cálculo é uma disciplina acadêmica que abrange tópicos matemáticos fundamentais necessários para o estudo avançado de cálculo diferencial e integral.\n\n\nEle é projetado para fornecer aos estudantes uma base sólida em conceitos matemáticos antes de ingressarem em cursos mais avançados de cálculo.\n\n\nO conceito de funções é fundamental para o avanço nos estudos da matemática para data Science.\n\n\nNeste curso você irá conciliar a teoria com a prática do estudo das funções:\nFunções:\nConceitos fundamentais de funções, como domínio, imagem e notação funcional.\nTipos de funções, como lineares, quadráticas, polinomiais, exponenciais e logarítmicas.\nComposição de funções.\n\n\nO objetivo do pré-cálculo é preparar os estudantes para o estudo mais avançado do cálculo, onde conceitos como derivadas, integrais e séries infinitas são explorados.\n\n\nEle fornece a base matemática necessária para que os estudantes compreendam e apliquem os princípios do cálculo de maneira mais eficaz.\n\n\nGeralmente, o pré-cálculo é um curso oferecido em instituições de ensino superior, como faculdades e universidades, para estudantes de ciências, engenharia e outras disciplinas relacionadas.\n\n\nNas nossas aplicações e exercícios iremos utilizar a poderosa linguagem de programação Python.\nO curso está repleto de exemplos e exercícios resolvidos para que você possa entender bem os conceitos principais e estudar as soluções de exercícios e aplicações com a ferramenta Python.\nAntes de adquirir o curso, veja a ementa e assista as aulas de pré-visualização disponíveis.\nTambém assista as aulas demonstrativas disponíveis para você!\nBons estudos!\nEstou aguardando você nas aulas!\nAté logo!!",
      "target_audience": [
        "Futuros engenheiros, economistas, administradores, contadores, arquitetos, estatísticos e matemáticos.",
        "Autodidatas dos mundos de Data Science e Data Analysis."
      ]
    },
    {
      "title": "Introduction to Deep Learning",
      "url": "https://www.udemy.com/course/the-complete-deep-learning-course/",
      "bio": "Deep learning in Arabic التعلم العميق وتعلم الألة والذكاء الأصطناعي باللغة العربية",
      "objectives": [
        "Machine learning",
        "Supervised, Unsupervised, and Reinforcement Learning",
        "Grasp the Mathematics Behind Deep Learning Algorithms",
        "Linear Regression",
        "Logistic Regression",
        "K-Nearest Neighbour",
        "Object Recognition",
        "Neural Networks",
        "Gradient Descent Algorithm",
        "Backpropagation Algorithm",
        "Convolutional Neural Networks"
      ],
      "course_content": {
        "Introduction to Machine learning & Deep learning": [
          "What is Machine Learning?",
          "Introduction to Machine learning & Deep learning",
          "Introduction to Machine learning & Deep learning",
          "Types of Machine Learning",
          "K-Nearest Neighbors (KNN) Model",
          "Machine Learning",
          "Steps to Build a Machine Learning System",
          "Machine Learning & Deep learning Applications"
        ],
        "Linear Regression": [
          "Univariate Linear Regression",
          "Cost Function Intuition",
          "Gradient Descent Algorithm",
          "Linear Regression with Multiple Variables"
        ],
        "Logistic Regression": [
          "Introduction to Logistic Regression",
          "Cost function",
          "Multi-Class Classification",
          "Logistic Regression"
        ],
        "Neural Networks": [
          "Introduction to Neural Networks Part 1",
          "Introduction to Neural Networks Part 2",
          "Biological Neural Networks",
          "Neural Networks"
        ],
        "Training Deep Neural Networks": [
          "Install Keras",
          "Keras: Building Your First Neural Network",
          "Keras: Building Your First Neural Network",
          "Introduction to Backpropagation Algorithm",
          "Backpropagation Algorithm in Details"
        ]
      },
      "requirements": [
        "Differential",
        "Calculus",
        "Probability",
        "Linear Algebra"
      ],
      "description": "كورس لتعليم اساسيات خوارزميات التعلم العميق والشبكات العصبية وتعلم الاله للمبتدئين وحتى المستوى المتقدم\nسواء كنت طالباً فى علوم الحاسب او طالباً  فى الهندسة أو مبرمجاً وتعشق مجال الذكاء الاصطناعى , فإن هذا الكورس سيساعدك علي فهم أساسيات التعلم العميق و الوصول إلى مستوى محترف\nوسوف يركز هذا الكورس على الجوانب النظرية وراء الخوارزميات والنماذج المنتشره هذه الايام للتعلم العميق\nThis course is focus on the theoretical aspects of the recent deep learning methods.\n\n\nSection 1: Introduction to Machine learning & Deep learning\nLecture 1: Introduction to Deep learning\n· Brief history of Deep learning\n· Motivation\nLecture 2: What is Machine Learning?\n· Machine leaning Definition\n· Traditional Programming vs Machine learning\n· AI vs Machine learning vs Deep learning\nLecture 3: Types of Machine Learning\n· Supervised, unsupervised, and reinforcement learning\n· Classification vs Regression\n· Clustering and dimensionality reduction\nLecture 4: Machine Learning & Deep learning Applications\nLecture 5: Steps to Build a Machine Learning System\n· Data collection, feature extraction, modelling, estimation, and validation.\n· for example, how to develop an image categorization system.\nLecture 6: K-Nearest Neighbors (KNN) Model\n\n\nSection 2: Linear Regression\nLecture 7: Univariate Linear Regression\nLecture 8: Cost Function Intuition\nLecture 9: Gradient Descent Algorithm\nLecture 10: Linear Regression with Multiple Variables\n\n\nSection 3: Logistic Regression\nLecture 11: Introduction to Logistic Regression\nLecture 12: Cost function\nLecture 13: Multi-Class Classification\n\n\nSection 4: Neural Networks\nLecture 14: Introduction to Neural Networks Part 1\n· Definition of Neural Networks\n· Artificial Neuron\n· Types of Activation Functions\nLecture 15: Introduction to Neural Networks Part 2\n· Neural Network Architectures\n· Capacity of Single Neuron\\Neural Network\n· Multi-layer Neural Networks\n· Softmax Activation Function\nLecture 16: Biological Neural Networks",
      "target_audience": [
        "Computer Science Students: Undergraduate and Master Students",
        "Deep Learning Developers",
        "Machine Learning Developers",
        "Data Scientists",
        "Anyone who have a passion in deep learning, machine learning and AI"
      ]
    },
    {
      "title": "Python & Deep Learning reconnaissance d'images",
      "url": "https://www.udemy.com/course/introduction-au-deep-learningtensorflow-et-keras/",
      "bio": "Découvrez le deep learning en réalisant une classification d'images",
      "objectives": [
        "classifier des images",
        "utiliser google colab",
        "comprendre les réseaux de neurones convolutifs",
        "comprendre l'augmentions d'image",
        "détecter le sur apprentissage"
      ],
      "course_content": {
        "Projet deep learning": [
          "Introduction",
          "conversion des images de jpg a rgb",
          "Image Data Generator",
          "Création du modèle",
          "Entrainement du modèle",
          "Interpretation des résultats",
          "Data augmentation",
          "Prédiction et conclusion"
        ]
      },
      "requirements": [
        "connaissances en librairie data science sur python"
      ],
      "description": "Cette formation vous permettra de comprendre la vision par ordinateur en classifiant des images.\nVous comprendrez c'est quoi la classification d'images en réalisant un projet de classification d'images binaire. Après cette formation vous pouvez prendre ma formation Deeplearning : classification d'images avec tensorflow,Keras que vous trouverez en cliquant sur mon profile qui elle est plus complète car dans celle là nous réaliserons 3 différents projets :\n1 - coder un perceptron de zéro: qui vous permettra de comprendre comment un modèle de deep learning marche, car nous allons coder un perceptron (réseau de neurone à une seule couche) sans utiliser tensorflow\n2 - classification d'images multi classes : nous allons classifier des images d'articles de modes(sac, sandale, sneaker, tee-shirt etc..) en 10 classes différentes avec la base de donnée fashion-mnist et cette fois si avec tensorflow et keras et les réseaux de neurones convolutifs(nous obtiendrons une précision de 96%)\n3 - classification d'images binaire : nous allons classifier des images de chats et de chien avec une base de données de 3000 photos de chien et de chat. dans ce dernier projet nous allons apprendre plusieurs techniques comme l'augmentation d'image, et l'apprentissage par transfert.\nAvec les connaissances acquises dans ce cours vous allez pouvoir classifier n'importe qu'elle catégorie d'image et vous allez pouvoir vous lancez dans d'autres applications de la vision par ordinateur tels que la reconnaissance faciale, la détection d'émotion etc...",
      "target_audience": [
        "personnes qui ont des compétences en python",
        "personnes intéressées par la data science"
      ]
    },
    {
      "title": "Curso Completo de Inteligência Artificial",
      "url": "https://www.udemy.com/course/curso-completo-de-inteligencia-artificial-chatgpt/",
      "bio": "Aprenda a Ganhar dinheiro com Inteligência Artificial, ChatGPT 4, MidJourney e Marketing com IA do zero até o Avançado!",
      "objectives": [
        "Introdução à inteligência artificial",
        "ChatGPT 4",
        "ChatGPT 3.5",
        "Aprenda a dominar as Ferramentas de Inteligência Artificial",
        "Conceitos Básicos da Inteligência Artificial",
        "Aplicações da Inteligência Artificial",
        "Como utilizar Inteligência Artificial para automatizar funções",
        "Como usar Inteligência Artificial para criar vídeos",
        "Como usar o ChatGPT",
        "Como criar Canais Dark no Youtube com IA",
        "Como Criar Canais Dark no Tiktok com IA",
        "Midjourney",
        "Dall E"
      ],
      "course_content": {
        "Boas Vindas e Introdução ao Curso de Inteligência Artificial (IA)": [
          "Boas Vindas!",
          "Como vai Funcionar o Curso",
          "O que é Inteligência Artificial"
        ],
        "ChatGPT 3 e 4: Introdução": [
          "O que é o ChatGPT",
          "Criando conta no ChatGPT",
          "Diferenças entre o ChatGPT e o ChatGPT Plus",
          "Conhecendo o ChatGPT 4 e suas Funcionalidades",
          "Google Bard - Alternativa ao ChatGPT"
        ],
        "Como Ganhar Dinheiro com IA": [
          "Maneiras de ganhar de 100 a 500 reais por dia com Inteligência Artificial",
          "Tiktok: Estratégia para Ganhar Dinheiro com IA no Tiktok",
          "IA para Criar Perfil de Cortes no Tiktok",
          "IA para criar Vídeos Dark no Tiktok",
          "Ganhando Dinheiro com IA sendo Freelancer",
          "Criando Curso Online + Estratégia de Vendas com IA"
        ],
        "Gerador de Imagens com IA": [
          "Como gerar Logos com IA",
          "Ferramenta 1 para Gerar Imagens com IA - Leonardo IA",
          "Ferramenta 2 para Gerar Imagens com IA + Remover fundos - Clip Drop",
          "IA para modificar Imagens - Uizard IO"
        ],
        "Criando Cursos Online com IA": [
          "Passo 1) Planejando a Criação do seu Curso com IA",
          "Passo 2) Criando o Site com ajuda da IA",
          "Passo 3) Criando um Vídeo de Vendas com IA",
          "Passo 4) Criando um Ebook com IA",
          "Passo 5) Criando seu Curso Online com IA"
        ],
        "IA para Escola/Faculdade e Estudos": [
          "Utilizando ChatGPT para Criar Trabalhos",
          "IA para mascarar plágio/Produção via IA",
          "IA para Escola Faculdade - Ferramenta 1 (Caktus)",
          "IA para Escola Faculdade - Ferramenta 2 (My Essai Writer)",
          "Ia para fazer Provas - Cursology",
          "IA para resumir aulas ao Vivo - TLDV",
          "IA geradora de Mapa Mental",
          "IA tradutora de PDF - Online Doc Translator",
          "IA que Resume PDF - CHATPDF"
        ],
        "Inteligência Artificiais para Mídias Sociais": [
          "IA para Lançar seu Negócio Digital - Mixo IO",
          "Criando seu Planejamento de Marketing com ChatGPT",
          "IA para Criar Conteúdo para Redes Sociais - Many Content"
        ]
      },
      "requirements": [
        "Não é necessário pré-requisitos para fazer o curso. Qualquer pessoa que deseje aprender sobre Inteligência Artificial, desde iniciantes até avançados pode fazer o curso."
      ],
      "description": "Claro, vamos lá! Aqui está uma possível adaptação da descrição do curso de ChatGPT para o curso de Inteligência Artificial:\nA Inteligência Artificial é uma das mais avançadas tecnologias da atualidade, capaz de fornecer soluções precisas e personalizadas para diversos problemas e desafios. Este curso abrangente foi projetado para ajudá-lo a dominar as habilidades necessárias para aproveitar ao máximo as capacidades da Inteligência Artificial, aprendendo a usá-la para obter soluções e insights em diferentes contextos.\nVocê está procurando um Curso completo de Inteligência Artificial que irá ensinar tudo o que você precisa saber para se tornar um especialista e dominar a tecnologia, certo?\nVocê encontrou o curso de Inteligência Artificial certo!\nCom as habilidades e estratégias que você aprenderá aqui no nosso curso, você será capaz de:\nUTILIZAR a Inteligência Artificial para resolver problemas em diversas áreas\nDESENVOLVER estratégias de negócios e criação de conteúdo com sucesso\nAPLICAR a Inteligência Artificial em diferentes contextos, como pesquisa, trabalho, educação e comunicação escrita\nDOMINAR os conceitos fundamentais da Inteligência Artificial e do aprendizado de máquina\nUTILIZAR a Inteligência Artificial para impulsionar sua carreira e criar novas oportunidades profissionais\nQueremos ajudá-lo a se preparar para o futuro da tecnologia e estar exposto às possibilidades oferecidas pela Inteligência Artificial.\nPrometemos fazer tudo o que pudermos para ajudá-lo a dominar todas essas estratégias e conceitos da Inteligência Artificial, auxiliando profissionais de todas as áreas que desejam aprender como usar a Inteligência Artificial para obter informações e insights úteis, desde profissionais de negócios e vendas até pesquisadores, educadores e profissionais de tecnologia.\nVocê aprenderá tópicos como:\nIntrodução à Inteligência Artificial e como ela funciona\nComo interagir com a Inteligência Artificial e fazer perguntas\nComo utilizar a Inteligência Artificial para resolver problemas em diversas áreas\nComo utilizar a Inteligência Artificial para criar conteúdo na internet (Youtube, Instagram, Tiktok...)\nComo utilizar a Inteligência Artificial para aprimorar a escrita e comunicação interpessoal\nComo utilizar a Inteligência Artificial para fins educacionais e de aprendizagem\nComo utilizar a Inteligência Artificial para criar conteúdo para marketing e vendas\nExplorando futuras possibilidades de aplicação da Inteligência Artificial em diferentes áreas e setores.\nE MUITO MAIS!\nO QUE VOCÊ RECEBE AO SE INSCREVER NO CURSO COMPLETO DE INTELIGÊNCIA ARTIFICIAL?\nAcesso vitalício ao curso e todas as atualizações\nSuporte personalizado e respostas às suas perguntas\nCertificado de conclusão Udemy - que pode ser incluído em seu currículo\nGarantia de devolução do dinheiro de 30 dias - se não gostar do curso, pode pedir o reembolso de 100%\nPARA QUEM É O CURSO?\nEste curso é ideal para estudantes, profissionais de tecnologia e negócios e qualquer pessoa interessada em aprender sobre inteligência artificial e suas aplicações em diferentes áreas. Não é necessário ter conhecimento prévio em programação ou em inteligência artificial, mas é recomendado ter alguma familiaridade com programação em geral.\nSe você quer estar na vanguarda da tecnologia e adquirir habilidades valiosas que podem impulsionar sua carreira ou negócio, este curso é para você. Junte-se a nós e comece a sua jornada na inteligência artificial hoje mesmo!",
      "target_audience": [
        "O curso é destinado a todas pessoas que desejam aprender sobre Inteligência Artificial"
      ]
    },
    {
      "title": "مشاريع الذكاء الإصطناعي | Artificial Intelligence Projects",
      "url": "https://www.udemy.com/course/artificial-intelligence-case-studies/",
      "bio": "مشاريع وتطبيقات عملية في تخصصات الذكاء الإصطناعي Natural Language Processing, Computer Vision, & Time-series Forecasting",
      "objectives": [
        "نظرة سريعة لتطبيقات الذكاء الاصطناعي AI Apps Overview",
        "مبادئ وتطبيقات معالجة اللغات الطبيعية Natural Language Processing (NLP) Basics & Practicing",
        "مبادئ وتطبيقات تنبؤ السلاسل الزمنية Time-series Forecasting (TSF) Basics & Practicing",
        "مبادئ وتطبيقات الرؤية بالحاسب Computer Vision (CV) Basics & Practicing"
      ],
      "course_content": {
        "مشاريع الذكاء الإصطناعي | Artificial Intelligence Projects": [
          "مقدمة عن الدورة التدريبية Course Introduction",
          "نظرة سريعة لتطبيقات الذكاء الاصطناعي AI Apps Overview",
          "مبادئ معالجة اللغات الطبيعية Natural Language Processing (NLP) Basics",
          "تطبيق عملي: معالجة اللغات الطبيعية - تعلم الآلة NLP using Machine Learning",
          "تطبيق عملي: معالجة اللغات الطبيعية - التعلم العميق NLP using Deep Learning",
          "مبادئ تنبؤ السلاسل الزمنية Time-series Forecasting (TSF) Basics",
          "تطبيق عملي: تنبؤ السلاسل الزمنية - تعلم الآلة TSF using Machine Learning",
          "تطبيق عملي: تنبؤ السلاسل الزمنية - التعلم العميق TSF using Deep Learning",
          "مبادئ الرؤية بالحاسب Computer Vision (CV) Basics",
          "تطبيق عملي: الرؤية بالحاسب - التعلم العميق Computer Vision using Deep Learning",
          "مبادئ أنظمة التوصية Recommendation Systems (RS) Basics",
          "تطبيق عملي: أنظمة التوصية - تعلم الآلة Recommender System using Machine Learning",
          "ماذا بعد؟ What's Next?"
        ]
      },
      "requirements": [
        "أساسيات برمجة بايثون | Python Programming Basics",
        "مبادئ تعلم الآلة | Machine Learning Basics",
        "مبادئ التعلم العميق | Deep Learning Basics"
      ],
      "description": "مشاريع الذكاء الإصطناعي | Artificial Intelligence Projects\n\n\nدورة مشاريع الذكاء الإصطناعي، وهي مبادرة نسعى من خلالها إلى إثراء المحتوى العربي في هذا المجال من خلال إعداد دورة تدريبية شاملة بشكل تفاعلي وتطبيقي لكل مواضيع وتخصصات هذا المجال .. وبنحاول إن التدريب يكون مناسب للمبتدئين ولأي شخص يرغب في بدء العمل كعالم بيانات Data Science/ مهندس ذكاء إصطناعي باستخدام بايثون Python واحتراف هذا المجال من الصفر.\n\n\nالدورة بتتميز بالآتي:\n- التدريب تفاعلي وقائم على النقاشات مع الطلاب\n- خطة واضحة ومنظمة للبدء في المجال من الصفر وحتى احترافه\n- 4 تخصصات رئيسية في الذكاء الإصطناعي في كورس واحد\n- أكثر من 5 ساعات تدريبية\n- تطبيقات عملية ومشاريع Case-studies\n- تحميل ملفات التدريب والأكواد Course Materials\n- المحتوى متاح مدى الحياة\n- شهادة بنهاية التدريب\n\n\nبنشرح في الدبلومة التقنيات والأدوات الرئيسية لأي عالم بيانات/مهندس ذكاء إصطناعي باستخدام بايثون:\nنظرة سريعة لتطبيقات الذكاء الاصطناعي AI Apps Overview\nمبادئ وتطبيقات معالجة اللغات الطبيعية Natural Language Processing (NLP) Basics & Practicing\nمبادئ وتطبيقات تنبؤ السلاسل الزمنية Time-series Forecasting (TSF) Basics & Practicing\nمبادئ وتطبيقات الرؤية بالحاسب Computer Vision (CV) Basics & Practicing\n\n\n---\nدورة مشاريع الذكاء الإصطناعي هي مبادرة نسعى من خلالها إلى إثراء المحتوى العربي في هذا المجال من خلال إعداد دورة تدريبية شاملة بشكل تفاعلي وتطبيقي لكل مواضيع وتخصصات هذا المجال .. وبنحاول إن التدريب يكون مناسب للمبتدئين ولأي شخص يرغب في بدء العمل كعالم بيانات Data Science باستخدام بايثون Python واحتراف هذا المجال من الصفر.\n= (*) تحذير هام: تم بذل مجهود كبير بفضل الله وتوفيقه من قبل م. مصطفى عثمان في إعداد هذا المحتوى الذي يقدم بصفة شخصية لك مقابل الاشتراك، رجاء عدم نسخه أو استخدامه بعيداً عن الموقع أو الإتجار به لإن ذلك يعرضك للمسائلة أمام الله عز وجل .. شكراً لتفهمك، وشكراً لاهتمامك بما نقدمه",
      "target_audience": [
        "الناس اللي عندها خلفية حتى لو بسيطة عن مبادئ الذكاء الإصطناعي وحابين يطبقوا على التخصصات الأساسية في المجال زي NLP, CV, & TSF"
      ]
    },
    {
      "title": "Data Science in Python: Numpy, Pandas, Matplotlib [2025]",
      "url": "https://www.udemy.com/course/data-science-tools-mit-python-numpy-pandas-matplotlib/",
      "bio": "Werde Data-Science-ready: Von Arrays und DataFrames bis zu professionellen Plots – kompakt und praxisnah.",
      "objectives": [
        "Der richtige Umgang mit Numpy",
        "Der richtige Umgang mit Pandas",
        "Der richtige Umgang mit Matplotlib",
        "Der richtige Umgang mit Scipy"
      ],
      "course_content": {
        "Kapitel 1: Einleitung und Software": [
          "Einleitung in den Kurs",
          "Die Software im Kurs",
          "Informationen zu der Software",
          "Handbuch des Kurses",
          "Materialien des Kurses",
          "Die Einrichtung des Environments",
          "Visual Studio Code installieren und einrichten",
          "Visual Studio Code verwenden"
        ],
        "Kapitel 2: Numpy": [
          "Listen und Arrays",
          "Numpy Einführung",
          "Numpy Basics - Teil 1",
          "Numpy Basics - Teil 2",
          "Numpy Basics - Teil 3",
          "Numpy Basics",
          "Ufuncs (Universal Functions)",
          "Aggregates",
          "Broadcasting",
          "Numpy Functions",
          "Masks",
          "Random",
          "Weitere Index Funktionen",
          "I/O und weiteres",
          "Weiteres zu Numpy",
          "Exercise 1",
          "Solution 1",
          "Exercise 2",
          "Solution 2",
          "Exercise 3",
          "Solution 3"
        ],
        "Kapitel 3: Pandas": [
          "Pandas Basics",
          "Basic Functions",
          "Pandas Basics",
          "Missing Values",
          "Concat, Append und Join - Teil 1",
          "Concat, Append und Join - Teil 2",
          "GroupBy: Split, Apply und Combine",
          "Concat, Joins und Groupby",
          "Time Series",
          "I/O und weiteres",
          "Exercise 1",
          "Solution 1",
          "Exercise 2",
          "Solution 2",
          "Pandas Code Optimieren"
        ],
        "Kapitel 4: Matplotlib und Seaborn": [
          "Line Plot - Teil 1",
          "Line Plot - Teil 2",
          "Scatter Plot",
          "Contour Plot",
          "Histogramm Plot",
          "Subplots",
          "Customize Plots",
          "Matplotlib",
          "3D Plots",
          "Pandas Plots",
          "Seaborn Basics",
          "Exercise",
          "Solution"
        ],
        "Kapitel 5: Scipy, Sklearn und OpenCV Einführung": [
          "SciPy 101",
          "Sklearn 101",
          "OpenCV 101"
        ],
        "Kapitel 6: Abschluss des Kurses": [
          "Abschluss des Kurses",
          "Bonuslektion"
        ]
      },
      "requirements": [
        "Die Grundlagen der Python Programmierung (Variablen, Listen, Dicts, Klassen etc.)",
        "Erfahrung im Umgang mit dem Terminal (bzw. der CMD)"
      ],
      "description": "Starte deine Data-Science-Karriere mit den wichtigsten Python-Tools für Datenanalyse, Transformation und Visualisierung.\nIn diesem praxisorientierten Kurs erlernst du den effizienten Umgang mit den zentralen Data-Science-Bibliotheken NumPy, Pandas und Matplotlib. Diese Tools sind essenziell für jede datengetriebene Anwendung – von der ersten Datenanalyse bis hin zu Machine Learning und Künstlicher Intelligenz.\nMit NumPy lernst du, große numerische Datenmengen präzise und speichereffizient zu verarbeiten. Mit Pandas beherrschst du den Import, die Bereinigung und Umstrukturierung von Daten aus unterschiedlichsten Quellen. Matplotlib hilft dir schließlich, deine Daten durch professionelle Diagramme, Plots und Visualisierungen verständlich und überzeugend darzustellen.\nZusätzlich erhältst du einen ersten Einblick in weiterführende Bibliotheken wie SciPy, Seaborn, Scikit-learn und OpenCV, um dein Wissen gezielt auszubauen und dich optimal auf die nächsten Schritte im Bereich Data Science vorzubereiten.\nOb Berufseinsteiger, Studierender oder ambitionierter Entwickler – dieser Kurs bietet dir eine fundierte Grundlage für deine Arbeit mit Daten.\nDas wirst du lernen:\nInstallation von Python, Anaconda und VSCode für Data-Science-Projekte\nNumerische Berechnungen und Datenmanipulation mit NumPy\nDatenimport, Transformation und Analyse mit Pandas\nDatenvisualisierung mit Matplotlib: Scatter Plots, Histogramme, 3D-Plots und mehr\nEinführung in weitere Libraries: SciPy, Seaborn, Scikit-learn und OpenCV\nStarte noch heute deine Ausbildung in der Technologie von morgen – wir sehen uns im Kurs!\n\n\nHinweis:\nPython wird im Kurs mit Anaconda installiert. Alternativ ist auch eine Einrichtung über andere Quellen möglich.",
      "target_audience": [
        "Python-Entwickler mit Grundkenntnissen"
      ]
    },
    {
      "title": "【実践】Python✕データサイエンス加工・集計・可視化処理100本ノック！実務でよく使う100個の問題にチャレンジ！",
      "url": "https://www.udemy.com/course/python-datascience-100/",
      "bio": "あなたは何問解けるか！？データ分析者必見のPython✕データサイエンス加工・集計・可視化処理100本ノック！初級者から上級者まで実力試しや復習に使おう！",
      "objectives": [
        "Pythonの基礎",
        "データ加工・集計・可視化の100問ノックを通して実践的なスキルを身につける",
        "queryを使った様々なデータ抽出方法",
        "group_byを使った様々なデータ集計方法",
        "その他多数のデータ加工・集計・可視化方法"
      ],
      "course_content": {
        "はじめに": [
          "はじめに"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Seabornについて学ぼう！",
          "Python構文の復習"
        ],
        "データ加工集計：ノック1本目〜77本目": [
          "【次の動画のノック5本目の注意点】型変換",
          "データの読み込みから型変換まで：ノック1本目〜5本目",
          "データの型変換からqueryの使い方まで：ノック6本目〜10本目",
          "queryの様々な使い方：ノック11本目〜15本目",
          "queryの使い方からgroupbyの使い方まで：ノック16本目〜20本目",
          "日付の扱いとソートの使い方：ノック21本目〜25本目",
          "【次の動画のノック27本目の注意点】絶対値",
          "月や週や曜日ごとでの集計方法：ノック26本目〜30本目",
          "Groupbyとqueryの組み合わせで集計・抽出：ノック31本目〜35本目",
          "【次の動画のノック37本目の修正点】2年の区切りを710と記述していますが730が正しいです",
          "新たな質的変数の定義とデータセットのマージ方法：ノック36本目〜40本目",
          "日付の扱いとトップ5の抽出方法：ノック41本目〜44本目",
          "agg関数と正規表現の使い方：ノック45本目〜50本目",
          "正規表現の使い方：ノック51本目〜54本目",
          "最頻値・中央値・分散・標準偏差：ノック55本目〜60本目",
          "ランク・pivot_table・melt：ノック61本目〜65本目",
          "01フラグの作成方法：ノック66本目〜67本目",
          "カテゴリー分けとダミー変数化：ノック68本目〜70本目",
          "標準化とサンプリング：ノック71本目〜74本目",
          "層化抽出・外れ値・CSV出力：ノック75本目〜77本目"
        ],
        "データ可視化：ノック78本目〜100本目": [
          "ヒートマップ・棒グラフ：ノック78本目〜80本目",
          "カウントプロット・折れ線グラフ・箱ひげ図：ノック81本目〜85本目",
          "散布図・ペアプロット・バブルチャート：ノック86本目〜90本目",
          "様々なタイプのグラフを描画してみよう！：ノック91本目〜95本目",
          "円グラフ・エリアチャート・ヒストグラム：ノック96本目〜100本目",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学びますので特に必要ありません"
      ],
      "description": "このコースではデータ分析をする際に頻出する加工・集計・可視化処理100問に取り組んでいきます。\n\n\n実務でよく登場する取引データと会員データを用いて、それぞれのデータに様々な処理を施していきます。\n\n\n出来るだけ動画を見る前に自分の力で解けるか試してみることをオススメします。\n\n\n実力試しにも復習にも最適です。ぜひ100問ノックに挑戦してみてください！",
      "target_audience": [
        "Pythonによる様々なデータ加工・集計・可視化を100問ノックで鍛えたい方",
        "Pythonの使い方をマスターしたい方",
        "実務で使う実践的なデータ加工・集計・可視化スキルを習得してすぐに活かしたい方",
        "自分の実力試しをしたい方"
      ]
    },
    {
      "title": "Curso 100% Práctico de Copilot para Microsoft 365",
      "url": "https://www.udemy.com/course/copilot-para-microsoft-365-practico/",
      "bio": "Potencia tu Productividad y Eficiencia con IA generativa en Microsoft 365 con Copilot",
      "objectives": [
        "Generación de cuentas Microsoft y procesos de suscripción a Copilot y Microsoft 365. Gestión completa desde el alta hasta la cancelación de las suscripciones.",
        "Los estudiantes desarrollarán un dominio avanzado del uso de Copilot para herramientas de Microsoft 365 como Word, Excel, PowerPoint, OneNote y Outlook",
        "Aprender a utilizar Copilot como asistente habitual en las tareas diarias.",
        "Utilización de Copilot para análisis de datos, creación de resúmenes, generación de ideas y optimización del tiempo propio.",
        "Incorporar inteligencia artificial generativa en las aplicaciones del ecosistema Microsoft 365 para aumentar la productividad y eficiencia.",
        "Aprender a emplear Copilot para crear y editar documentos en Word de manera eficiente y precisa.",
        "Adquirir habilidades para generar presentaciones en PowerPoint automáticamente con la ayuda de Copilot.",
        "Utilizar Copilot como asistente personal para gestionar correos electrónicos en Outlook, optimizando la comunicación y organización."
      ],
      "course_content": {
        "Introducción al Curso": [
          "Presentación",
          "Introducción",
          "Configuración Udemy",
          "Rating"
        ],
        "Gestión de Cuentas y Suscripciones": [
          "Alta de cuenta Microsoft",
          "Planes Copilot",
          "Suscripción Copilot PRO",
          "Cancelar suscripción Copilot",
          "Preguntas frecuentes",
          "Suscripción Microsoft 365",
          "Cancelar suscripción Microsoft 365"
        ],
        "Copilot Microsoft": [
          "Copilot Parte I",
          "Copilot Parte II",
          "Copilot Parte III",
          "Copilot Parte IV",
          "Copilot Parte V"
        ],
        "Copilot en EDGE y otras aplicaciones": [
          "Copilot EDGE",
          "Copilot en aplicaciones Microsoft 365"
        ],
        "Copilot Lab": [
          "Copilot Lab"
        ],
        "Copilot para Microsoft 365 - Word": [
          "Copilot Word Parte I",
          "Copilot Word Parte II"
        ],
        "Copilot para Microsoft 365 - PowerPoint": [
          "Copilot PowerPoint Parte I",
          "Copilot PowerPoint Parte II"
        ],
        "Copilot para Microsoft 365 - Outlook": [
          "Copilot Outlook"
        ],
        "Copilot para Microsoft 365 - OneNote": [
          "Copilot OneNote"
        ],
        "Copilot para Microsoft 365 - Excel": [
          "Copilot Excel Parte I",
          "Copilot Excel Parte II"
        ]
      },
      "requirements": [
        "No se requiere conocimientos ni experiencia previa. En este curso, adquirirás todo el conocimiento necesario para familiarizarte con Microsoft Copilot y la Inteligencia Artificial Generativa desde 0. El curso comienza desde lo más básico, la generación de las cuentas Microsoft y suscripciones necesarias."
      ],
      "description": "¡Bienvenido al curso \"Copilot para Microsoft 365 Práctico\"!\n\n\nEn este curso, te adentrarás en el mundo de la Inteligencia Artificial Generativa y aprenderás a utilizar Microsoft Copilot para transformar tu forma de trabajar con las herramientas más populares de Microsoft 365.\n\n\nNo se requiere experiencia previa, te proporcionaremos todo lo que necesitas saber para convertirte en un experto utilizando esta tecnología revolucionaria.\n\n\n¿Qué aprenderás en este curso?\nGeneración de cuentas Microsoft y procesos de suscripción a Copilot y Microsoft 365: Gestión completa desde el alta hasta la cancelación de las suscripciones.\nDominio y Automatización de Tareas con Copilot: Aprende a utillizar Copilot en aplicaciones como Word, Excel, PowerPoint, OneNote y Outlook para automatizar tareas y aumentar tu productividad.\nOptimización de Procesos con IA: Descubre cómo utilizar la inteligencia artificial para análisis de datos, optimización de procesos, generación de contenido automático y mejorar la eficiencia en la gestión de documentos y datos.\nAdquisición de conocimientos en el uso de IA Generativa para potenciar tu rendimiento: Adquiere habilidades para personalizar y configurar Copilot según tus necesidades específicas para maximizar su uso en distintos entornos personales o de trabajo.\n\n\n¿Para quién es este curso?\nProfesionales y estudiantes interesados en la IA Generativa y su aplicación en el entorno persona y empresarial.\nProfesionales que quieran destacar y convertirse en expertos en una habilidad cada vez más relevante en el mercado laboral.\nTodos quienes deseen innovar en sus organizaciones, empresas o proyectos utilizando Microsoft Copilot.\nInteresados en mejorar la productividad, rendimiento y eficiencia mediante el uso de Copilot para Microsoft 365.\nCualquier persona que desee incorporar IA Generativa a las herramientas de Microsoft 365 que utiliza habitualmente en su día a día.\n\n\nObjetivos de aprendizaje\nDominar el Uso de Copilot para Microsoft 365: Aprende a utilizar Copilot como asistente habitual con las aplicaciones más utilizadas de Microsoft 365 para aumentar la productividad y eficiencia.\nCrear, Analizar y Editar Documentos en Word: Aprende a usar Copilot para crear, analizar y editar documentos en Word de manera eficiente y precisa.\nDesarrollar Presentaciones en PowerPoint: Adquiere habilidades para generar presentaciones en PowerPoint automáticamente con la ayuda de Copilot.\nGestión de Correos Electrónicos en Outlook: Utiliza Copilot como asistente personal para gestionar correos electrónicos en Outlook, optimizando la comunicación y ahorrando tiempo.\nAnálisis y Organización de Datos en Excel: Aprende a utilizar Copilot en Excel para realizar análisis avanzados y agilizar tareas como la creación de fórmulas y la organización de datos.\nCrear, Analizar y Editar Contenido en OneNote: Aprende a usar Copilot para crear, analizar y editar información en OneNote de manera rápida, eficiente y precisa.\n\n\nContenido del curso\nEl curso está estructurado en módulos que cubren los principales usos de Copilot en las aplicaciones más utilizadas de Microsoft 365:\nIntroducción: Conceptos básicos y configuración inicial.\nGestión de Cuentas y Suscripciones: Creación y gestión de cuentas Microsoft y suscripciones a Microsoft 365 y a Copilot.\nCopilot Microsoft: Conceptos básicos del uso de Copilot y desarrollo avanzado de generación de resultados con este asistente.\nCopilot en EDGE y otras aplicaciones: Formación en el uso y disposición de Copilot en el navegador Edge y en otros apicativos.\nCopilot Lab: Conceptos básicos del repositorio de ejemplos de prompts para Copilot.\nCopilot para Word: Flujos de trabajo para utilizar e asistente Copilot en el trabajo habitual con Word.\nPresentaciones Eficientes en PowerPoint: Generación de diapositivas y diseño automático con la ayuda del asistente.\nGestión de Correos en Outlook: Gestión, organización y análisis de correos electrónicos.\nCopilot para OneNote: Uso efectivo de Copilot con contenido en OneNote.\nCaso Práctico Excel: Formación en el uso del asistente de IA Generativa para automatizar tareas y analizar datos sobre datos de tablas con Excel.\n\n\nMetodología del curso\nNuestro enfoque práctico y orientado a resultados te permitirá adquirir habilidades aplicables de inmediato en tu entorno personal y laboral. A través de lecciones en video y ejercicios prácticos, consolidarás tus conocimientos y desarrollarás competencias clave para utilizar Copilot en tu día a día.\n\n\n¿Por qué elegir este curso?\nAcceso a Material Exclusivo: Contenidos actualizados y relevantes.\nInstructor Experto: Profesionales con amplia experiencia en Microsoft 365 y Copilot.\nCertificado de Finalización: Avala tus competencias con un certificado reconocido de Udemy.\n\n\n¡Inscríbete hoy y transforma tu manera de trabajar con Microsoft 365 gracias a Copilot!",
      "target_audience": [
        "Cualquiera que desee aprender a utilizar Microsoft Copilot para innovar en las organizaciones, empresas o proyectos en los que participen.",
        "Personas interesadas en mejorar su productividad, rendimiento y eficiencia utilizando Copilot para Microsoft 365.",
        "Profesionales y estudiantes interesados en la Inteligencia Artificial Generativa y su aplicación en entornos personales o empresariales.",
        "Interesados en la integración de la Inteligencia Artificial Generativa con las herramientas de Microsoft 365.",
        "Estudiantes que buscan destacar y convertirse en expertos en una habilidad cada vez más demandada en el mercado laboral."
      ]
    },
    {
      "title": "Bot de inversion para Criptomonedas con Python",
      "url": "https://www.udemy.com/course/bot-de-inversion-para-criptomonedas-con-python/",
      "bio": "Automatiza tus Inversiones en Criptomonedas.API Binance. Backtesting.",
      "objectives": [
        "Creación de robots de Inversion",
        "Programación en Python",
        "Procesamiento de datos Financieros",
        "Como operar en Criptomonedas",
        "Extracción y visuliazación de datos de Criptomonedas",
        "Backtesting",
        "Como programar Indicadores Tecnicos",
        "Automatizar Inversiones en Criptos"
      ],
      "course_content": {
        "Introducción": [
          "Introducción",
          "Recursos"
        ],
        "Introducción a Python": [
          "Introducción a Google Colab",
          "Variables_&_Operaciones_Elementales",
          "Estructura de datos",
          "Metodos Utiles",
          "Condicionales",
          "Iteraciòn",
          "Funciones & Funciones Recursivas",
          "Escribir y Leer Archivos"
        ],
        "Python Programacion Orientada a Objetos": [
          "Clases & Instancias",
          "Variables de Instancias & Variables de Clases",
          "Herencia",
          "Metodos de Clases"
        ],
        "Pandas": [
          "Series de datos",
          "Dataframes",
          "Lectura de Archivos CSV",
          "Métodos útiles",
          "Uso de GroupBy",
          "Tratamiento de Valores Faltantes",
          "Manejo de Variables Categoricas"
        ],
        "Numpy": [
          "Operaciones con Arrays",
          "¿Como crear un Array?",
          "Manipulación de Arrays y Filtros",
          "Métodos útiles",
          "Estadística con Numpy",
          "Manipulación de imágenes"
        ],
        "Matplotlib": [
          "Introducción a Matplotlib",
          "Graficos en Matplotlib I",
          "Graficos en Matplotlib II",
          "Graficos en Matplotlib III"
        ],
        "Introducción a las Criptomonedas": [
          "¿Que son las criptomonedas?",
          "Tipos de Criptomonedas",
          "Clave Pública y Clave Privada",
          "¿Cómo se generan los Bitcoins?",
          "Introducción a Binance",
          "Compra y Venta de Criptomonedas en Binance",
          "¿Cómo Analizar el mercado de las criptomonedas?"
        ],
        "API Bianance.Compra y Venta de Criptomonedas": [
          "Introducción a Requests",
          "Introducción API Binance",
          "Descargar datos",
          "Compra y venta"
        ],
        "Indicadores y Estrategias": [
          "¿Que son los indicadores?",
          "Calculo de Media Móvil y Función Rolling",
          "Indicadores para medir volatilidad.Bandas de Bolinger",
          "Indicadores Avanzados.Indicador Estocastico",
          "Indicadores con BTA-LIB"
        ],
        "Extracción de Datos y Visualización": [
          "Extracción datos de Binance",
          "Código para extracción de datos",
          "Visualizacion de datos y calculo de media movil",
          "Grafico de velas",
          "RSI",
          "Gráfico con varios indicadores"
        ]
      },
      "requirements": [
        "Ser una persona proactiva en el aprendizaje"
      ],
      "description": "Crea tu propio Robot de Inversión en Criptomonedas\n¿Te imaginas tener un robot que trabaje por ti las 24 horas, comprando y vendiendo criptomonedas según las reglas que tú mismo programes?\nNo es ciencia ficción. Es Python. Y está al alcance de cualquiera que quiera aprender.\nEn este curso 100% práctico te enseñaremos, paso a paso, a crear tus propios robots de trading, desde cero, incluso si nunca has programado antes.\n¿Qué aprenderás?\nEste no es un curso de teoría. Es un manual práctico para que construyas tu robot y lo pongas a trabajar:\nProgramación en Python: aprende lo básico (condicionales, bucles, funciones) y cómo usar programación orientada a objetos.\nManejo de datos con Pandas y Numpy: transforma y procesa información como un profesional.\nVisualización con Matplotlib: crea gráficos que te ayuden a entender el mercado.\nFundamentos de las criptomonedas: qué son, cómo funcionan y cómo operar con ellas.\nConexión con la API de Binance: envía órdenes, extrae datos y gestiona tu cuenta automáticamente.\nIndicadores técnicos y estrategias: construye reglas para que tu robot tome decisiones.\nBacktesting y optimización: pon a prueba tus estrategias y haz que sean más rentables.\nCreación del robot final: une todo lo aprendido para tener tu propio bot de inversión funcionando.\n¿Por qué este curso?\nPorque no solo te damos la teoría:\nTe damos el código.\nPodrás usarlo, adaptarlo y crear tus propios robots de inversión de manera segura y efectiva.\n“No es el más fuerte ni el más inteligente el que sobrevive, sino el que mejor se adapta al cambio.” – Charles Darwin\n¿Qué vas a lograr?\nAutomatizar tu operativa y dejar de depender de emociones al invertir.\nAhorrar horas frente a la pantalla y aprovechar mejor tu tiempo.\nDesarrollar una habilidad muy demandada: automatización aplicada a mercados financieros.\nEmpieza hoy mismo\nEl mercado no espera. Cada día que pasa sin automatizar tu operativa, pierdes oportunidades.\nInscríbete ahora y crea el robot que cambiará tu forma de invertir.",
      "target_audience": [
        "Personas Interesadas en Crear Robots de Inversión",
        "Estudiantes de Informatica",
        "Desarolladores en Python con Interes en las criptomonedas",
        "Traders que quieran automatizar sus estrategias"
      ]
    },
    {
      "title": "Curso de Governança de Dados 1.0",
      "url": "https://www.udemy.com/course/curso-de-governanca-de-dados-10/",
      "bio": "Venha aprender como implantar um programa de Governança de Dados na sua empresa",
      "objectives": [
        "Este curso prepara o aluno para aprender sobre o processo de implantação de um programa de governança de dados, cuja área é cada vez mais importante para as empresas que buscam implementar cultura data-driven e criar estratégias de dados para suportar estratégias de negócios."
      ],
      "course_content": {
        "Curso de Governança de Dados 1.0": [
          "Introdução",
          "Governança de Dados",
          "Porque a governança de dados é importante?",
          "Estratégia de dados",
          "Framework",
          "Data Maturity Model",
          "Etapas para implantar um programa de governança de dados",
          "Entregas de um programa de governança de dados",
          "LGPD",
          "Master Data Management (MDM)",
          "Metadados",
          "Erros ou desvios",
          "Encerramento"
        ]
      },
      "requirements": [
        "Não há pré-requisitos"
      ],
      "description": "Se você está interessado em aprender como implantar um programa de Governança de Dados na sua empresa ou apenas conhecer a área, este curso é perfeito para você.\nPreparamos um curso com os principais tópicos que você precisa saber para ingressar em uma das profissões mais promissoras no mercado de dados no Brasil.\nEsse curso prepara o aluno para aprender sobre o processo de implantação de um programa de Governança de Dados, cuja a área é cada vez mais importante para as empresas que buscam implantar a cultura data driven e criar estratégias de dados para suportar estratégias de negócio.\n\n\nO curso está dividido nas seguintes aulas:\nIntrodução\nGovernança de Dados\nPorque a Governança de Dados é importante?\nEstratégia de dados\nFramework\nData Maturity Model (DMM)\nEtapas para implantar um programa de governança de dados\nEntregas de um programa de governança de dados\nLGPD\nMaster Data Management (MDM)\nMetadados\nErros mais comuns\nEncerramento\nTodo material está disponível em PDF.\nVamos começar?\nHá quem se destina esse curso?\nProfissionais da área de tecnologia\nProfissionais da área de dados\nProfissionais da área de governança de dados\nProfissionais de privacidade\nEngenheiros de dados\nCientistas de dados\nAnalistas de dados\nAnalistas de processo\nCoordenadores de tecnologia\nGerentes de tecnologia\nAnalistas de big data\nAnalistas de data science\nAnalistas de automação de processos e RPA\nTecnólogo em sistemas de informação\nCoordenadores de Big Data, Data Science e Analytics\nEntusiastas da áreas de dados e tecnologia em geral",
      "target_audience": [
        "Profissionais da área de tecnologia",
        "Profissionais da área de dados",
        "Profissionais de governança de dados",
        "Profissionais de privacidade",
        "Engenheiros de dados",
        "Cientistas de dados",
        "Analista de dados",
        "Entusiastas da área de dados e tecnologia em um geral"
      ]
    },
    {
      "title": "【PyTorchで学ぶ】 Machine Learning for Physics",
      "url": "https://www.udemy.com/course/machine-learning-for-physics/",
      "bio": "機械学習の先端トピックを短時間で速習しよう",
      "objectives": [
        "伝統的な科学技術計算とその課題を理解できる",
        "Machine Learning x Physicsのこれまでの研究の推移を理解できる",
        "Machine Learningの応用の1つとしての科学技術計算への適用を理解できる",
        "近年注目を集めているMachine LearningによるPhysics Informed Approachを理解できる",
        "Physics Informed Approachの具体的なアルゴリズムと実装方法を理解できる",
        "PyTorchによるHands Onで実際に実装する事ができる"
      ],
      "course_content": {
        "はじめに": [
          "コース概要説明"
        ],
        "科学技術計算": [
          "科学技術計算とは？",
          "伝統的な科学技術計算の課題"
        ],
        "Machine Learning for Physics": [
          "Data Driven Approach",
          "Physics Informed Approach",
          "PINNのアルゴリズム",
          "Physics Informed Loss"
        ],
        "PyTorchによるPINNの実装": [
          "実装 part I 解の確認",
          "実装 part II Physics Informed Loss",
          "実装 part III 初期条件の実装",
          "実装 part IV 境界条件の実装",
          "実装 part V 時空間のランダムサンプリング",
          "実装 part VI MLPの実装(前半)",
          "実装 part VII MLPの実装(後半)",
          "実装 part VIII 訓練",
          "実装 part VIIII 結果の確認"
        ],
        "ボーナスレクチャー": [
          "関連Topics",
          "本講座で使用したNotebook"
        ]
      },
      "requirements": [
        "Pythonの基本的なプログラミング知識",
        "PyTorchで深層学習のプログラムが書ける"
      ],
      "description": "【このコースは誰に向けたものか？】\n本コースは、【Hands Onで学ぶ】PyTorchによる深層学習入門を受講して、PyTorchで深層学習を実装できるようになった方を対象に、Machine Learning / Deep Learningを科学技術計算に応用した技術について学ぶコースです。\n\n\n本講座では次世代の数値シミュレーション技術として期待されているPhysics Informed Neural Networks(PINN)をメインに学習していきます。PINNは2017年にM. Raissi et al.によって提案された全く新しい科学技術計算のテクノロジーです。\n論文数やGoogle Trend様々な指標で本技術の注目度の高さを伺い知ることができます。\n\n\n2023年時点において、まだ日本ではあまり研究例は多くありませんが、数年後には大きなトレンドを形成していくのではないかと考えられます。\n現在、数値シミュレーション・科学技術計算に携わられている方には必見のコースだと言えます。\nまた、本コースは短く纏められているため、最先端のTopicを僅か1時間程度で速習する事が出来ます。\n\n\n【何が学べる？】\n科学技術計算の分野自体は古くから研究されており、成熟した技術分野ですが、そのような伝統的な科学技術計算を簡単に学んだあと、抱えている課題について学びます。これを解決する新しい問題解決のアプローチとしてMachine Learning Approachがあり、これまでのMachine Learning x Physicsの研究の歴史を振り返ります。その後、本トピックで中心となるPhysics Informed Neural Networksについて詳細や実装方法を学びます。実装はPyTorchで行いますので受講される方はPyTorchによるモデリングを予め学んでおく必要があります。",
      "target_audience": [
        "機械学習や数値シミュレーションに 興味のある学生さんや社会人の方",
        "Deep Learningの最先端の技術を知りたい AIエンジニア",
        "数値シミュレーションに携わっている 企業のR&D部門の方、大学の研究者の方"
      ]
    },
    {
      "title": "直感！Pytorchで始める深層学習実装入門（実践編）",
      "url": "https://www.udemy.com/course/python_pytorch/",
      "bio": "ニューラルネットワークからBERT・T5まで",
      "objectives": [
        "Pytorchを用いたBERT転移学習の実装方法",
        "huggingfaceを用いたT5による英文ニュース記事の抽出的要約",
        "vision transformerを使った画像認識の実装方法",
        "Pytorchを用いた全結合型ニューラルネットワークの実装方法",
        "Pytorchを用いた再帰型ニューラルネットワークの実装方法",
        "Pytorchを用いた畳み込みニューラルネットワークの実装方法",
        "全結合型ニューラルネットワークの仕組み",
        "再帰型ニューラルネットワークの仕組み",
        "畳み込みニューラルネットワークの仕組み"
      ],
      "course_content": {
        "実践編講座紹介": [
          "01_実践編_講座紹介",
          "02_実践編_全結合型ニューラルネットワーク：説明",
          "03_実践編_FNN_LOVE_データ理解",
          "04_実践編_FNN_LOVE_モデル構築",
          "05_実践編_FNN_LOVE_ハイパーパラメタチューニング",
          "06_実践編_FNN_LOVE_訓練",
          "07_実践編_FNN_LOVE_推論",
          "08_実践編_FNN_課題",
          "09_実践編_FNN_課題解答",
          "10_畳み込みニューラルネットワーク(CNN)_説明",
          "11_CNN_LOVE分類_データ前処理",
          "12_CNN_LOVE_モデル構築",
          "13_CNN_LOVE_モデル訓練",
          "14_CNN_LOVE_モデル評価",
          "15_CNN_LOVE_推論",
          "16_CNN_FashionMNIST_データ前処理",
          "17_CNN_FashionMNIST_モデル構築",
          "18_CNN_FashionMNIST_モデル訓練",
          "19_CNN_FashionMNIST_モデル評価",
          "20_CNN_FashionMNIST_推論",
          "21_RNN説明",
          "22_RNN_MNIST_データ前処理",
          "23_RNN_MNIST_モデル構築",
          "24_RNN_モデル訓練",
          "25_RNN_モデル評価",
          "26_RNN_MNIST_推論",
          "27_BERT_IMDB_データ前処理",
          "28_BERT_IMDB_モデル構築",
          "29_BERT_IMDB_モデル訓練＆評価",
          "30_BERT_IMDB_推論",
          "31 Google's T5 seq2seqチュートリアル概要",
          "Google's T5 seq2seq　環境設定",
          "Google's T5 seq2seq　データ準備",
          "Google's T5 seq2seq　モデル構築・訓練・検証",
          "Google's T5 seq2seq 結果確認",
          "Google's T5 理解度チェック問題",
          "Google's T5 理解度チェック問題　解説",
          "※20231216最新リソースご確認ください。transformerでニューラル機械翻訳",
          "Vision Transformer(ViT)を用いた画像認識",
          "生成AIーMMMUとBLIP"
        ]
      },
      "requirements": [
        "Pythonの基礎文法",
        "Pytorchの基礎文法",
        "直感！Pytorchで始める深層学習実装入門(導入編)の知識"
      ],
      "description": "本講座では、Colabを利用したPytorchハンズオンで全結合型ニューラルネットワークの説明と実装から始めて、順を追ってBERTの転移学習やhuggingfaceを利用したT5による抽象的要約までステップアップしていきます。コアとなる考え方はどの深層学習においても共通です。講座を順に進め、手を動かしながら一緒に課題に取り組むことにより、受講者は任意のデータを利用して深層学習のモデルを構築・訓練できるようになるでしょう。\n※取り扱う内容：BERT/マルチモーダルモデル(BLIP-FLAN-T5-XL)が追加されています。\n【深層学習モデル】\n１）全結合型ニューラルネットワーク\n２）畳み込みニューラルネットワーク\n３）再帰型ニューラルネットワーク\n４）BERT\n５）Google's T5\n６）BLIP FLAN T5 XL\n\n\n【データ】\n１）FashionMNIST\n２）MNIST\n３）LOVE（講師の自作データ）\n４）IMDB\n５）Kaggle news dataset",
      "target_audience": [
        "huggingfaceのpytorchからの利用方法を実践で知りたい方",
        "BERTを転移学習する方法が知りたい方",
        "直感！Pytorchで始める深層学習実装入門(導入編)を修了した方",
        "Pythonの文法を一通り習得して次のステップへ進みたい方",
        "人工知能に興味がある方",
        "G検定を取得した後、更にステップアップしたい方",
        "ハンズオンで手を動かして深層学習を実装できるようになりたい方",
        "Pytorchの文法を一通り習得して次のステップへ進みたい方"
      ]
    },
    {
      "title": "MidJourney od zera: kompletny kurs dla początkujących",
      "url": "https://www.udemy.com/course/midjourney-od-zera-kompletny-kurs-dla-poczatkujacych/",
      "bio": "Poradnik \"dla każdego\" do tworzenia obrazów za pomocą Midjourney",
      "objectives": [
        "Wszystko co potrzebne aby zacząć tworzyć profesjonalną grafikę AI",
        "Jak posługiwać się MidJourney jak profesjonalista",
        "Dowiesz się, jak tworzyć grafikę AI, która jest wyjątkowa wizualnie",
        "Stworzysz dzieła sztuki, dzięki którym będziesz mógł zarabiać pieniądze"
      ],
      "course_content": {
        "Wstęp": [
          "Powitanie w kursie MidJourney",
          "Podgląd MidJourney",
          "Co będziemy robić na tym kursie?",
          "Rejestracja i logowanie do Midjourney",
          "Interfejs Midjourney",
          "Subskrybcja i prywatny serwer",
          "Problemy i zakazy"
        ],
        "Podstawy MidJourney": [
          "Czym jest prompting?",
          "Generujemy ilustracje",
          "Generujemy emocje",
          "Generujemy fotografie",
          "Generujemy architekturę i wnętrza",
          "Iteracja - dlaczego jest to ważne?",
          "Modyfikatory jakości - czym one są?",
          "Wagi - jak ich używać?"
        ],
        "MidJourney - zaawansowane opcje": [
          "Remiksowanie obrazów",
          "Jak stylizować obrazy?",
          "Jak generować mangę?",
          "Jak mieszać style obrazów?",
          "Czym jest parametr \"chaos\"?",
          "Czym jest \"blend\" obrazów?",
          "Jak poprawić jakość?",
          "Czym jest funkcja \"seed\"?",
          "Jak używać emoji do tworzenia obrazów?"
        ],
        "Inne programy AI": [
          "Programy warte znania i co dalej?"
        ]
      },
      "requirements": [
        "Brak wymagań wstępnych innych niż chęć nauczenia się jak korzystać z AI i MidJourney",
        "Telefon lub komputer z dostępem do Internetu"
      ],
      "description": "Czy jesteś osobą kreatywną, która chce zbadać możliwości tworzenia sztuki za pomocą sztucznej inteligencji?\n\n\nA może dopiero usłyszałeś o możliwości AI i zaczynasz swoją przygodę z MidJourney?\nTrafiłeś idealnie!\nZapraszam cię na kurs, który nauczy cię najważniejszych i najciekawszych zastosowań AI MidJourney!\nDzięki Midjourney nauczę cię tworzyć imponującą grafikę AI w ciągu kilku minut.\n\n\nChcesz stworzyć ilustracje do książki dla dzieci, którą sam stworzysz?\nChcesz wygenerować własne designy na koszulkę?\nChcesz stworzyć oszałamiającą grafikę koncepcyjną do gier?\nChcesz stworzyć plakaty przypominające style twojego ulubionego artystę lub malarza?\nA może chcesz stworzyć udaną sesję fotograficzną?\nNiezależnie od tego, czy jesteś doświadczonym artystą, czy zupełnie początkującym, ten kurs przeprowadzi Cię krok po kroku przez proces zostania profesjonalnym artystą AI.\nPrzygotowałem dla ciebie praktyczny materiał, który pokaże Ci jak używać MidJourney:\nJak generować ilustracje, emocje, fotografie, architekturę?\nJak używać poprawnie modyfikatorów?\nJak remiksować i stylizować obrazy?\nJak wygenerować mangę?\nJak mieszać różne style artystyczne?\nJak poprawić jakość swoich dzieł?\nJakie są zakazane tematy i czego unikać?\nOraz wiele, wiele więcej\nPod koniec będziesz umiał wygenerować portfolio pełne oszałamiających wizualnie dzieł sztuki, które będziesz mógł następnie sprzedawać online.\nA dodatkowo pokażę Ci mnóstwo przydatnych sztuczek rozszerzających możliwości MidJourney\nWięc na co czekasz? Zacznij przygodę już dziś :)",
      "target_audience": [
        "Każdy, kto jest zainteresowany wykorzystaniem AI do tworzenia niesamowitych obrazów",
        "Graficy i artyści, którzy chcą usprawnić swoją codzienną pracę, czerpać inspirację oraz produkować jeszcze lepsze dzieła",
        "Sprzedawcy oraz marketing, który chce zwiększyć skuteczność sprzedaży dzięki wygenerowanej grafice",
        "Blogerzy, twórcy treści dla social mediów, którzy chcą generować przykuwające oko grafiki",
        "Dla każdego kto chciałby tworzyć sztukę, ale nie wie od czego zacząć"
      ]
    },
    {
      "title": "【初心者向け】PythonでExcelを操作して煩雑な日々の業務を効率化・自動化する方法を学ぼう！",
      "url": "https://www.udemy.com/course/python-excel-effective/",
      "bio": "Excelの各シートのデータを統合してそれを元にデータを集計してExcelに書き込んだりExcel上にグラフとして描画したりセルのスタイルを変更したりする方法を学ぼう！",
      "objectives": [
        "Pythonの基礎",
        "PythonでExcel上のデータを様々な方法で処理する方法",
        "PythonでExcel上にグラフを描画する方法",
        "毎月の売上がシートごとに集計されたExcelをPythonを使って１つにまとめて様々な処理を行う応用"
      ],
      "course_content": {
        "はじめに": [
          "イントロダクション"
        ],
        "Pythonの使い方": [
          "Pythonを学ぼう！",
          "Pythonの実行環境",
          "Google Colabの使い方",
          "演算子の種類を学ぼう！",
          "Pythonの変数と型を学ぼう！",
          "list型(リスト)を学ぼう！",
          "dict型(辞書)を学ぼう！",
          "print関数を学ぼう！",
          "文字列の操作方法を学ぼう！",
          "条件分岐のif文を学ぼう！",
          "繰り返し処理のfor文を学ぼう！",
          "関数の作り方と使い方を学ぼう！",
          "Pandasの使い方を学ぼう！",
          "Numpyについて学ぼう！",
          "Matplotlibの使い方を学ぼう！",
          "Seabornについて学ぼう！",
          "Python構文の復習"
        ],
        "【基礎編】PythonでExcelを操作してみよう！": [
          "PythonでExcelファイルを作成してみよう！",
          "PythonでExcelファイルを読み込んで書き込んでみよう！",
          "PythonでExcel内のデータを呼び出して表示してみよう！",
          "PythonでExcelのシートの追加と削除をしてみよう！",
          "Excelで四則演算するデータを作っていこう！",
          "Pythonを使ってExcelで四則演算してみよう！",
          "Python側でVlookup関数を定義してExcelのデータを読み取って結果を表示してみよう！",
          "PythonでExcelにグラフを描画してみよう！",
          "PythonでExcelのスタイルを変更してみよう！"
        ],
        "【実践編】Excelの売上データをPythonで操作してみよう！": [
          "日別商品別の売上ExcelデータをPythonを使って作ってみよう！",
          "全ての月のデータを統合して各商品の売上総額と平均単価を集計してみよう！",
          "各集計データをExcelに書き込んでいこう！",
          "月別の集計結果をExcelに書き込んでいこう！",
          "月別売上推移グラフを作成していこう！",
          "最も売れた商品と最も売れなかった商品をソートして抽出しよう！",
          "抽出した商品情報を元に対象セルに色付けしていこう！",
          "ボーナスレクチャー"
        ]
      },
      "requirements": [
        "Pythonの基礎から学ぶのでプログラミング知識は不要です"
      ],
      "description": "このコースでは、Pythonを使ってExcelを操作する方法について解説していきます！\n\n\n日々の業務でExcelを使っていないという人はほぼいないのではないでしょうか？しかし時にはExcelの作業は非常に退屈で煩雑で苦労します。\n\n\nそんな業務をPythonを使うことでほぼ自動化して効率化することができるかもしれません。\n\n\n基礎編で一通りPython×Excelの基礎的な操作方法を学んだ後は、実践編で実務で発生しそうな具体的なユースケースを元に集計や可視化をおこなっていきます！\n\n\n日々の非効率なExcel業務から解放されましょう！",
      "target_audience": [
        "普段煩雑なExcel処理に追われて疲弊している人",
        "Pythonを使ったExcel操作に興味のある人",
        "Pythonでの自動化に興味のある人"
      ]
    },
    {
      "title": "APACHE Superset e APACHE HOP - ETL e visualizações de dados",
      "url": "https://www.udemy.com/course/apache-superset-e-apache-hop-etl-e-visualizacoes-de-dados/",
      "bio": "Construa cargas em ETL e prepare suas visualizações de dados",
      "objectives": [
        "Superset: plataforma de exploração e visualização de dados criada com base no Apache Superset de código aberto",
        "Superset: permite a criação de gráficos e dashboards, permitindo a construção de visualização sem código",
        "Superset: é possível executar uma análise mais profunda usando o editor SQL nativo",
        "Superset: permite a conexão com diversas fontes de dados como Data Warehouse, Data Lake, planilhas, tudo 100% na nuvem",
        "Superset: possui um ambiente fácil de usar, onde você cria uma workspace de trabalho e constrói seus projetos",
        "Superset: permite carregar seus dados de diversos bancos de dados e origens diferentes, acessando os dados de forma transparente",
        "Superset: permite a criação de gráficos (CHART) dos mais variados e com requisitos de filtros e ajustes de campos, podendo gerar novos atributos",
        "Superset: permite que você utilize o SQL LAB para explorar seus dados via SQL",
        "Superset: possui um fluxo de trabalho que organiza a construção das análises de dados",
        "Superset: com o Preset - APACHE Superset é possível conectar seus dados, criar um conjunto de dados, criar gráficos, construir um painel e compartilhar seus ins",
        "Superset: possui um espaço de trabalho para armazenamento das informações a serem desenvolvidas",
        "Superset: permite a construção de gráficos diversos: tabela, setores, heatmap, treemap, box plot, linha, sunburst, dentre outros",
        "Superset: permite a construção de previsões utilizando técnicas como FORECAST",
        "Superset: permite a colaboração e compartilhamento de gráficos e dashboard",
        "HOP: o que é  Hop Orchestration Platform",
        "HOP: entendendo sobre fluxos de trabalho e pipelines",
        "HOP: entendendo sobre projetos e ambientes",
        "HOP: instalação do APACHE HOP",
        "HOP: criando pipelines com arquivos texto",
        "HOP: realizando tratamento de dados para entendimento do processo de engenharia de dados",
        "HOP: o que são transformações, links e ações dentro de um pipeline",
        "HOP: construindo um workflow, orquestrador da sequência das operações",
        "HOP: entendendo o HOP GUI e seus componentes",
        "HOP: entendendo menu barras, principal e perspectivas",
        "HOP: criando sua área de projetos",
        "HOP: componentes pipelines: Sort, Select value, CSV file input, Value mapper, Filter rows, Dummy, Unique rows, Merge Join, Text File Output",
        "HOP: entendendo o que é : View output, Preview output , Debug output",
        "HOP: componentes pipelines: Number Range, Concat Field, String Operations, Replace in String, IF Field Value is Null, Split Fields, CSV File Input, Mail, File",
        "HOP: leitura de dados em uma API: Rest Client, JSON Input, JSON Output",
        "HOP: construindo Workflow com execução de pipelines",
        "HOP: entendo o uso de variáveis globais no APACHE HOP",
        "HOP: automatização de pipeline ou workflow pelo HOP-RUN",
        "HOP: construindo pipelines em banco de dados Postgresql: Table Input, Table Output, Configurando conexão",
        "HOP: instalação de banco de dados Postgresql, usando PGAdmin"
      ],
      "course_content": {
        "Preset - APACHE Superset: Dashboard e Visualização de Dados": [
          "Apresentação - O que é o APACHE Superset",
          "INFORMAÇÕES IMPORTANTES! - Leia antes de começar o curso",
          "Entendendo sobre Preset - APACHE Superset",
          "Criação da conta no ambiente da nuvem do Preset",
          "Realizando a carga dos dados para o treinamento",
          "Criação do Chart - Tabela",
          "Criação do Chart - Treemap",
          "Criação do Chart - Série Temporal e Previsão com FORECAST",
          "Criação de uma nova coluna customizada",
          "Criação do Chart - KPI",
          "Criação do Chart - Sunburst",
          "Criação do Chart - Graph Chart - Gráfico de rede",
          "Criação do Chart - Box Plot",
          "Criação de dashoboard - gerando insights e entendo as análises",
          "Criação de filtros nos dashboards",
          "Criação de query pelo SQL LAB",
          "Responda a pergunta",
          "Aula Final - entrega de atividade"
        ],
        "APACHE HOP - Integração e Ingestão de dados": [
          "Entendendo o funcionamento e componentes",
          "Instalação do JAVA",
          "Instalação do APACHE HOP",
          "Configuração extra e iniciando APACHE HOP",
          "Criando projeto e ambiente, primeiros passos",
          "Pipeline de Tratamento: arquivo vinhos",
          "Pipeline de tratamento: filtragem e seleção de atributos - arquivos vinho",
          "Pipeline de tratamento: sort e group by atributos - arquivos vinho",
          "Pipeline de tratamento: gerando arquivo de saída totalizador - arquivos vinho",
          "Pipeline Merge dos dados: Leitura arquivos de entrada",
          "Pipeline Merge dos dados: Sort arquivos de entrada",
          "Pipeline Merge dos dados: Merge arquivos venda e cliente",
          "Pipeline Merge dos dados: Merge arquivos venda com produto e marca",
          "Pipeline Merge dos dados: geração arquivo venda final tratado",
          "Pipeline Tratamento de dados: Arquivo cliente veículos e strings diversos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e ajustes campo hora",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e retirada valores nulos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e junção de atributos",
          "Pipeline Tratamento de dados: Arquivo cliente veículo e geração grupos de dados",
          "Pipeline Carga API: Leitura dados CEP e uso de REST GET",
          "Pipeline Carga API: Leitura e armazenamento arquivo JSON",
          "Pipeline Carga API: Tratamento dos dados escolha campos e gravação arquivo texto",
          "Workflow de execução: Parte01",
          "Workflow de execução: Parte02",
          "Banco de dados: Instalação do Postgresql",
          "Banco de dados: Pipeline de tratamento de dados no Postgresql",
          "HOP-RUN: Automatização de pipeline e workflow",
          "Aula Final - Entrega de atividades"
        ]
      },
      "requirements": [
        "Conhecimento elementar de SQL",
        "Importante ter conhecimento sobre banco de dados, arquivos de dados",
        "Importante que você conheça lógica de programação"
      ],
      "description": "Você estudará duas das principais ferramentas da APACHE, o Apache Hop e o Apache Superset. Esses cursos combinam o poder das ferramentas Apache e oferecem aos profissionais a oportunidade de se atualizarem e se capacitarem em tecnologias avançadas.\nO Apache Hop é uma ferramenta de orquestração de fluxos de dados, que permite aos usuários criar, executar e monitorar pipelines de processamento de dados em larga escala. Com o Apache Hop, os profissionais podem trabalhar com diversas fontes de dados e aplicar transformações em seus fluxos de dados de forma simples e intuitiva.\nJá o Apache Superset é uma ferramenta de visualização de dados, que permite aos usuários criar dashboards interativos e analisar seus dados de forma rápida e eficiente. Com o Apache Superset, os profissionais podem criar gráficos, tabelas e mapas personalizados, além de compartilhar seus dashboards com suas equipes.\nA melhor parte é que essas duas ferramentas Apache são interligadas e trabalham juntas para oferecer soluções completas aos profissionais que buscam excelência em seus projetos. Combinando o poder do Apache Hop e do Apache Superset, os profissionais podem criar pipelines de processamento de dados robustos e escaláveis, enquanto visualizam seus dados de forma clara e concisa.\nConvidamos os profissionais que desejam se capacitar em tecnologias avançadas a participarem de nossos cursos de Apache Hop e Apache Superset. Com um instrutor experiente e conteúdo de qualidade, nossos cursos oferecem uma oportunidade única de aprender sobre essas ferramentas Apache e explorar todo o seu potencial.\nNão perca essa chance de se destacar no mercado e se tornar um especialista em tecnologias avançadas!\nVenha e comece hoje mesmo.",
      "target_audience": [
        "Estudantes e profissionais de computação, Informática, estatística, data science, analista de dados, engenheiro de dados",
        "Profissionais que desejam construir dashboards e gráficos",
        "Profissionais que, de alguma forma, utilizam dados no seu dia a dia"
      ]
    },
    {
      "title": "Python for Data Science",
      "url": "https://www.udemy.com/course/python-for-data-science-in-hindi/",
      "bio": "हिंदी में सीखें Python | Python और उसकी शक्तिशाली लाइब्रेरीज़ जैसे Numpy, Pandas, Matplotlib, Seaborn आदि का उपयोग सीखें",
      "objectives": [
        "Python syntax, script लेखन, और मौलिक प्रोग्रामिंग concepts जैसे variables, data types, और string operations को समझना |",
        "Python में डेटा को संगठित और प्रबंधित करने के लिए lists, dictionaries, tuples, और sets का प्रयोग करने में निपुण हो जाएंगे |",
        "Python में conditional statements और loops का उपयोग मास्टर करके डेटा प्रोसेसिंग tasks को automate और optimize करना।",
        "Python में दोहराए जाने वाले कार्यों को कुशलतापूर्वक संचालित करने के लिए एक्सपर्ट बनें, recursion और lambda functions के साथ।",
        "Python में files से पढ़ने और लिखने के कौशल प्राप्त करें, जो वास्तविक दुनिया के अनुप्रयोगों में डेटा प्रोसेसिंग tasks के लिए महत्वपूर्ण हैं।",
        "NumPy arrays का उपयोग complex mathematical computations के लिए समझें और उच्च प्रदर्शन के साथ large datasets को प्रभावी रूप से हैंडल करना सीखें।",
        "Pandas का उपयोग data manipulation और analysis में मास्टर करें; डेटा को explore, clean, और transform करना सीखें, ताकि वह analysis के लिए उपयुक्त फॉर्मेट में हो।",
        "Matplotlib और Seaborn libraries का उपयोग करके डेटा के बारे में insightful visual representations बनाने की क्षमता विकसित करें।"
      ],
      "course_content": {},
      "requirements": [
        "No prior experience in Python or data analysis is required; just basic computer skills and access to a computer with an internet connection are necessary to start this course."
      ],
      "description": "क्या आप एक data scientist बनने की इच्छा रखते हैं या अपने data analysis skills को बढ़ाना चाहते हैं? क्या आपने कभी data से अभिभूत महसूस किया है, यह सोचते हुए कि इसे actionable insights में कैसे बदलें? यदि आपका goal न केवल data science की विशाल दुनिया को समझना है बल्कि इस knowledge को practically लागू करना भी है, तो यह course आपके लिए ही design किया गया है। Python और उसकी powerful libraries की transformative दुनिया में डुबकी लगाएं और एक proficient data scientist बनने की अपनी journey शुरू करें।\n\n\nयह course data science applications के लिए विशेष रूप से tailored है, और Python programming और data analysis में mastery प्राप्त करने के लिए एक comprehensive guide प्रदान करता है। इस course में शामिल होकर आप:\n1. Python programming में एक solid foundation विकसित करेंगे, जिसमें basic syntax से लेकर advanced functions तक शामिल हैं।\n2. Python की सबसे powerful libraries जैसे कि numerical data के लिए NumPy, data manipulation के लिए Pandas, और data visualization के लिए Matplotlib और Seaborn का उपयोग करके data को handle और analyze करने की कला में mastery प्राप्त करेंगे।\n3. Compelling data visualizations बनाएंगे जो आपकी findings को effectively communicate करेंगे।\n4. Data manipulation techniques को लागू करेंगे ताकि अपने data को analysis के लिए clean, transform और prepare कर सकें।\n5. Practical programming solutions लागू करके real-world data analysis problems का समाधान करेंगे।\n\n\nइस विषय के बारे में सीखना क्यों महत्वपूर्ण है?\nआज की data-driven world में, data को analyze और interpret करने की क्षमता indispensable है। Data science के क्षेत्र में अग्रणी होने के नाते, Python एक extensive ecosystem of libraries और tools प्रदान करता है जो data analysis को accessible और powerful बनाते हैं। चाहे आप business decisions को inform करने के लिए customer data का analysis कर रहे हों, academic purposes के लिए research कर रहे हों, या personal projects के लिए datasets का exploration कर रहे हों, Python आपको data को insights में बदलने की क्षमता प्रदान करता है।\n\n\nइस course के दौरान, आप coding exercises, real-world data analysis projects, और data visualizations जैसी hands-on activities में संलग्न होंगे। ये practical experiences आपके learning को cement करने और professional setting में अपने skills को लागू करने का confidence देने के लिए designed हैं।\n\n\nइस course को जो खास बनाता है, वह केवल topics की breadth नहीं है, बल्कि practical application पर focus है। आप न केवल theory सीखेंगे बल्कि इन concepts को real-world scenarios में कैसे apply करें, यह भी सीखेंगे, जो आपके work या studies में immediate application के लिए आपको तैयार करेगा।\n\n\nData को अब और अधिक आपको अभिभूत न करने दें। Python for Data Science in Hindi में enroll करके इसके potential को unlock करने की दिशा में पहला कदम उठाएं। Data को insights में transform करें और data science के field में एक invaluable asset बनें।",
      "target_audience": [
        "Aspiring Data Scientists: Beginners who are interested in entering the field of data science and need to build foundational skills in programming and data handling.",
        "Professionals Seeking a Career Transition: Individuals in various fields such as business, finance, or healthcare, who wish to transition into data-centric roles and require practical skills in data manipulation and analysis.",
        "Hobbyists and Personal Learners: Anyone with a curiosity about data science and how Python programming can be applied to sort, analyze, and visualize data in personal projects or informal learning.",
        "Students in STEM Fields: College students or high school seniors who are studying subjects like statistics, mathematics, or computer science and want to enhance their data analysis capabilities."
      ]
    },
    {
      "title": "ゼロから始める機械学習",
      "url": "https://www.udemy.com/course/machinelearning-crash-course/",
      "bio": "完全にゼロから始めていって、現代の人工知能技術の根幹であるニューラルネットワークやディープラーニングについて説明できるレベルまで理解を深めます　数学などの前提となる知識も組み込みました",
      "objectives": [
        "機械学習と人工知能の関係性",
        "機械学習とはどのようなもので、プログラミングとはどう異なるか",
        "ニューラルネットワークをゼロから構築できる",
        "Pythonによるデータ分析"
      ],
      "course_content": {
        "紹介": [
          "紹介"
        ],
        "環境構築": [
          "Google Colaboratory",
          "Kaggle"
        ],
        "AIについて": [
          "イントロダクション",
          "機械学習とAI",
          "一般的なプログラミングとの違い",
          "ロードマップと本講義で扱う内容"
        ],
        "Kaggleへチャレンジ": [
          "イントロダクション",
          "Pythonの基礎　変数と関数と配列",
          "Pythonの基礎　データを扱う",
          "Titanicのデータを理解する",
          "データを分析する",
          "データを機械学習する"
        ],
        "データの前処理と機械学習の基礎": [
          "イントロダクション",
          "Pythonの基礎 ForとRange",
          "数学の前提知識　中央値と平均値",
          "数学の前提知識　標準偏差",
          "欠損値を扱う",
          "カテゴリ値を扱う",
          "特徴量のスケーリング"
        ],
        "回帰 / Regression": [
          "イントロダクション",
          "数学の前提知識　シグマ（累積和）",
          "数学の前提知識　微分",
          "回帰とは　問題設定",
          "理論　最小二乗法",
          "実装"
        ],
        "分類 /Classification": [
          "イントロダクション",
          "分類とは何か　回帰との違い",
          "Logistic Regression",
          "決定木",
          "Random Forest",
          "Kaggleで実践練習"
        ],
        "ニューラルネットワークとディープラーニング": [
          "イントロダクション",
          "数学の前提知識　行列の積",
          "数学の前提知識　偏微分",
          "数学の前提知識　連鎖律",
          "パーセプトロンとその限界",
          "多層パーセプトロン",
          "活性化関数",
          "ニューラルネットワーク",
          "学習と損失関数",
          "勾配と微分",
          "誤差逆伝播法 1",
          "誤差逆伝播法 2",
          "誤差逆伝播法 3",
          "学習のテクニック",
          "ディープラーニングについて",
          "ニューラルネットワークのまとめ"
        ],
        "Boosting": [
          "アンサンブル",
          "勾配ブースティング"
        ],
        "モデルの評価": [
          "イントロダクション",
          "汎化性能と過学習",
          "クロスバリデーション"
        ]
      },
      "requirements": [
        "中学校レベルの数学、多少のプログラミング経験"
      ],
      "description": "完全にゼロから始めていって、現代の人工知能技術の根幹であるニューラルネットワークやディープラーニングについて説明できるレベルまで理解を深めます　数学などの前提となる知識も組み込みました\n\n\n機械学習では理論的に難しい論点が複数存在します　それゆえに敷居が高く挫折してしまう人が多い状況でした\nこの講義では、機械学習の全体像を早めにキャッチアップしていきます\nその上で、理論的な細部にもこだわり、徹底的に現代機械学習の基礎的な部分を理解できるような作りにしました",
      "target_audience": [
        "少しプログラミングを触ったことがある、これからエンジニアになる方",
        "データサイエンスに興味を持つ初級Python開発者"
      ]
    },
    {
      "title": "深度学习-物体检测-YOLO实战系列",
      "url": "https://www.udemy.com/course/yolo-tyd/",
      "bio": "YOLO-论文分析+源码解读+项目实战",
      "objectives": [
        "掌握深度学习经典物体检测算法",
        "掌握YOLO系列核心网络架构",
        "掌握YOLO算法3代版本升级改进方法",
        "掌握YOLO-V3网络架构全部源码细节",
        "熟练使用YOLO-V3架构训练自己的数据与任务",
        "掌握数据标注和标签转换方法",
        "掌握YOLO系列全部核心知识点与代码实践",
        "基于YOLO模型进行实际项目开发"
      ],
      "course_content": {},
      "requirements": [
        "熟悉基本深度学习算法与PyTorch框架"
      ],
      "description": "物体检测YOLO系列课程主要包括两大核心模块：(1),YOLO系列算法精讲，详细解读3篇论文核心知识点与整体网络架构并对其效果展开深入分析，通俗讲解YOLO架构实现原理与效果提升细节；(1),YOLO-V3项目实战，详细解读V3版本源码，通过debug模式讲解其中每一行代码，从根本掌握YOLO系列全部实现细节。整体风格通俗易懂，原理+实战实战，提供全部课程所需PPT,数据，代码。\n\n\nYOLO物体检测项目适合应用于视频监控数据，可实时对目标场景进行检测与分析，例如入侵检测，化工厂危险预警，道路交通行人检测与流量分析，医学图像细胞检测，航空数据分析等领域，基本所有视频分析任务都可以使用YOLO框架来搭建。",
      "target_audience": [
        "深度学习-计算机视觉方向的同学们"
      ]
    },
    {
      "title": "PENTAHO PDI: ETL-Integração e Ingestão de dados - PARTE01",
      "url": "https://www.udemy.com/course/pentaho-pdi-etl-integracao-e-ingestao-de-dados/",
      "bio": "Construção de pipelines e jobs com a ferramenta open source mais utilizada no mundo",
      "objectives": [
        "O que é o Pentaho PDI",
        "Entendendo sobre fluxos de trabalho e pipelines",
        "Entendendo sobre projetos e ambientes",
        "Instalando o Pentaho PDI",
        "Criando pipelines com arquivos texto",
        "Realizando tratamento de dados para entendimento do processo de engenharia de dados",
        "O que são transformações, Jobs e ações dentro de um pipeline",
        "Construindo um workflow com Jobs, orquestrador da sequência das operações",
        "Entendendo os menus principais e o seu GUI e seus componentes",
        "Componentes pipelines: Sort, Select value, CSV file input, Value mapper, Filter rows, Dummy, Unique rows, Merge Join, Text File Output, Row Normaliser",
        "Entendendo como podem ser depurados os dados via output, logs",
        "Componentes pipelines: Number Range, Concat Field, String Operations, Replace in String, IF Field Value is Null, Split Fields, CSV File Input, Mail, File Exist",
        "Leitura de dados em uma API: Rest Client, JSON Input, JSON Output",
        "Construindo Workflow com execução de pipelines",
        "Entendo o uso de variáveis globais no PENTAHO PDI",
        "Automatização de pipeline ou workflow",
        "Construindo pipelines em banco de dados Postgresql: Table Input, Table Output, Configurando conexão",
        "Instalação de banco de dados Postgresql, uso do PGAdmin",
        "Automatização de JOBs e Transformações com o Kitchen e Pan",
        "Construção do projeto de dados a sua escolha e correção com o uso do Pentaho PDI"
      ],
      "course_content": {
        "PENTAHO PDI: ETL-Integração e Ingestão de dados": [
          "Apresentação sobre o Pentaho PDI",
          "INFORMAÇÕES IMPORTANTES - Leia antes de começar o curso",
          "Você conhece o curso de Pentaho PDI para Data Warehouse?",
          "Introdução ao Pentaho PDI",
          "Instalação do JAVA",
          "Site de Instalação do PDI",
          "Instalação do Pentaho PDI",
          "Entendo como funciona a área de trabalho",
          "Pipeline de Tratamento: arquivo vinhos",
          "Pipeline de tratamento: filtragem e gravação de arquivo ajustado- arquivo vinhos",
          "Pipeline de tratamento: seleção de atributos - arquivos vinhos",
          "Pipeline de tratamento: ordenação, agrupamento - arquivos vinhos",
          "Aula extra - 01 - Leitura de arquivo sem cabeçalho e sem delimitador",
          "Pipeline Merge dos dados: leitura arquivos de entrada e sort dados - 4 arquivos",
          "Pipeline Merge dos dados: componente merge e sort dados - 4 arquivos",
          "Pipeline Merge dos dados: seleção de campos e gravação arquivo - 4 arquivos",
          "Aula extra - 02 - Tratamento e leitura de arquivo colunar",
          "Pipeline Tratamento de dados: arquivo cliente veículos e replace dados",
          "Pipeline Tratamento de dados: operação string, categorias e componente IF null",
          "Pipeline Tratamento de dados: componentes cut e split fields",
          "Pipeline Tratamento de dados: componente number range e concat fileds",
          "Utilizando Debug do PDI dentro de um pipeline",
          "Tratando dados em um Pipeline lendo WebService",
          "Construindo JOB - encadeamento de pipelines",
          "Instalação do Postgres",
          "Carregado dados tabela AUTOR e gerando novos dados tabela NOVO_TB_AUTOR",
          "Aula extra - 03 - Criando JOB para movimentação de arquivos e pastas",
          "Automatizando Jobs e Transformações - Kitchen e Pan",
          "Aula Final - Construa o seu projeto de dados",
          "Responda a pergunta"
        ]
      },
      "requirements": [
        "Importante ter conhecimento sobre banco de dados, arquivos de dados",
        "Importante que você conheça lógica de programação"
      ],
      "description": "Se você está buscando uma maneira de se destacar no mercado de trabalho, adquirir habilidades altamente valorizadas por empresas e ampliar suas oportunidades de carreira, o curso de Pentaho PDI é a escolha certa para você!\nCom o aumento exponencial da quantidade de dados gerados diariamente pelas empresas, a necessidade de profissionais capacitados em análise e processamento de dados tem crescido de forma significativa. O Pentaho PDI é uma ferramenta poderosa que permite a integração de diferentes fontes de dados e o tratamento de informações para transformá-las em insights úteis para as empresas.\nAo adquirir o curso de Pentaho PDI, você terá acesso a conteúdos exclusivos e práticos que vão te ensinar desde os princípios básicos da ferramenta até a criação de fluxos de dados, passando por transformações e limpezas de dados, além de automatização de processos de ETL.\nAlém disso, você será guiado por um instrutor experiente e qualificado, que irá te ajudar a desenvolver as habilidades necessárias para aprimorar sua carreira e se destacar no mercado de trabalho.\nQuais vão as vantagens do curso de Pentaho PDI :\n\n\nAprenda uma das ferramentas mais utilizadas no mundo para integração e tratamento de dados\nAdquira habilidades altamente valorizadas por empresas que buscam profissionais capacitados em análise e processamento de dados\nAumente suas chances de sucesso em projetos pessoais ou profissionais\nAmplie suas oportunidades de carreira em diferentes setores, como finanças, varejo, saúde e telecomunicações\nDesenvolva competências em uma ferramenta open source que não requer investimentos elevados em licenças\nAcesse conteúdos exclusivos e práticos que vão te ensinar desde os princípios básicos da ferramenta até a criação de fluxos de dados complexos\nTenha uma formação completa que aborda diferentes aspectos da ferramenta, tornando-o um profissional completo e preparado para os desafios do mercado de trabalho.\nNão perca mais tempo e invista em seu futuro estudando agora mesmo o curso de Pentaho PDI. Com ele, você estará na dianteira do setor de engenharia de dados, podendo aplicar seus conhecimentos em projetos pessoais ou profissionais e aumentar suas chances de sucesso.",
      "target_audience": [
        "Estudantes e profissionais de computação, Informática, estatística, data science, analista de dados, engenheiro de dados",
        "Pessoas interessadas em aprender os conceitos sobre ferramentas de ingestão de dados, ou que gostariam adentrar na área de engenharia de dados",
        "Profissionais que, de alguma forma, utilizam dados no seu dia a dia"
      ]
    },
    {
      "title": "【한글자막】 AI : 인공 지능 마스터 클래스",
      "url": "https://www.udemy.com/course/best-ai-masterclass/",
      "bio": "최고 성능의 인공지능을 만들기 위한 하이브리드 인공지능 마스터 클래스! 다양한 신경망과 강력한 AI 모델에 대해 학습하며 마스터 툴킷을 제공합니다.",
      "objectives": [
        "AI를 만드는 방법",
        "하이브리드 지능 시스템을 만드는 방법",
        "완전 연결형 신경",
        "컨볼루션 신경망",
        "반복 신경망",
        "오토 인코더",
        "가변 오토 인코더",
        "혼합 밀도 네트워크",
        "심층 강화 학습",
        "정책 경사",
        "유전 알고리즘",
        "진화 전략",
        "공분산 행렬 적응 진화 전략(CMA-ES)",
        "컨트롤러",
        "메타 학습",
        "심층 신경 진화"
      ],
      "course_content": {
        "개요": [
          "개요+강좌 구성+데모",
          "보너스 : 학습 경로",
          "최고의 세가지 리소스",
          "여기서 리소스를 다운로드 하세요",
          "강사를 소개합니다!"
        ],
        "1단계- 인공 신경망": [
          "1단계에 오신 걸 환영합니다- 인공 신경망",
          "공략 계획",
          "신경(Neuron)에 대하여",
          "활성화 기능",
          "신경망은 어떻게 작용하는가?",
          "신경망은 어떻게 학습하는가?",
          "경사 하강법 (Gradient Descent)",
          "확률적 경사 하강법 (Stochastic Gradient Descent)",
          "역전파 (Backpropagation)"
        ],
        "2단계- 컨볼루션 신경망 (Convolutional Neural Network)": [
          "2단계에 오신 걸 환영합니다- 컨볼루션 신경망",
          "공략 계획",
          "컨볼루션 신경망이란 무엇인가?",
          "1단계- 컨볼루션 연산",
          "1단계 보충- 정류 선형 유닛 레이어 (ReLU layer)",
          "2단계- 풀링",
          "3단계- 평탄화",
          "4단계- 전체 연결",
          "요약 정리",
          "소프트맥스 & 교차 엔트로피"
        ],
        "3단계- 오토 인코더 (AutoEncoder)": [
          "3단계에 오신 걸 환영합니다- 오토 인코더",
          "공략 계획",
          "오토 인코더란 무엇인가?",
          "편견에 관한 참고사항",
          "오토 인코더 트레이닝",
          "완전 은닉층",
          "스파스 오토 인코더",
          "오토 인코더 제거",
          "계약형 오토 인코더",
          "스택형 오토 인코더",
          "심층 오토 인코더"
        ],
        "4단계-가변 오토 인코더": [
          "4단계에 오신 걸 환영합니다- 가변 오토 인코더",
          "가변 오토 인코더 개요",
          "가변 오토 인코더",
          "재매개화 트릭"
        ],
        "5단계-컨볼루셔널 변이형 인코더(CNN-VAE) 구현하기": [
          "5단계에 오신 걸 환영합니다- 컨볼루셔널 변이형 인코더(CNN-VAE) 구현하기",
          "5단계 개요",
          "CNN-VAE 클래스의 모든 매개 변수 및 변수 초기화",
          "VAE 인코더 부분 구축하기",
          "VAE의 ‘V’ 부분 구축하기",
          "VAE의 디코더 부분 구축하기",
          "트레이닝 운영 구현하기",
          "전체 코드 섹션",
          "케라스 구현하기"
        ],
        "6단계-반복 신경망 (Recurrent Neural Network)": [
          "6단계에 오신 걸 환영합니다- 반복 신경망",
          "공략 계획",
          "반복 신경망이란 무엇인가?",
          "기울기 소멸 문제",
          "장단기 메모리(LSTM)",
          "실질적인 LSTM 직관",
          "LSTM 변형"
        ],
        "7단계- 혼합 밀도 네트워크 (Mixture Density Network)": [
          "7단계에 오신 걸 환영합니다- 혼합 밀도 네트워크",
          "MDN-RNN 개요",
          "혼합 밀도 네트워크",
          "VAE + MDN-RNN 시각화"
        ],
        "8단계- MDN-RNN 구현하기": [
          "8단계에 오신 걸 환영합니다- MDN-RNN 구현하기",
          "MDN-RNN 클래스의 모든 매개 변수와 변수 초기화",
          "RNN 구축하기- 매개 변수 수집하기",
          "RNN 구축하기- 드롭아웃을 사용해 LSTM 셀 만들기",
          "RNN 구축하기- RNN의 입력, 대상 및 출력 설정",
          "RNN 구축하기- RNN의 결정론적 출력 불러오기",
          "MDN 구축하기- MDN의 입력, 은닉 계층 및 출력 불러오기",
          "MDN 구축하기- MDN 매개 변수 수집하기",
          "트레이닝 운영 구현하기(파트1)",
          "트레이닝 운영 구현하기(파트2)",
          "전체 코드 섹션",
          "케라스 구현하기"
        ],
        "9단계- 강화 학습": [
          "9단계에 오신 걸 환영합니다- 강화 학습",
          "강화 학습이란 무엇인가?",
          "풀 월드 모델(Full World Model)을 위한 강화학습의 유사 구현",
          "전체 코드 섹션"
        ]
      },
      "requirements": [
        "고등학생 수준의 수학",
        "약간의 코딩 경험"
      ],
      "description": "인공지능(AI) 마스터 클래스!\nAI 툴박스를 이용하여 AI 적응하기!\n하이브리드 AI 모델을 구축하기 위한 로드맵 제공!\n\n\nAI : 인공 지능 마스터 클래스 를 선택해야 하는 이유\n여러분은 인공지능에 관심이 많으신가요? 지금까지 개발된 가장 강력한 AI 모델의 구축 방법을 알고 싶고, 더 나아가 이에 맞서보고 싶으신 가요?\n\n\n그렇다면 인공 지능 마스터 클래스는 여러분을 위한 최고의 선택이 될 것 입니다. 이 궁극적인 AI 툴박스 하나로, 여러분은 쉽게 AI에 적응하게 될 것 입니다. 여러분은 앞으로 10시간 동안 단계별 가이드를 받게되고 여러분만의 하이브리드 AI 모델을 구축하기 위한 전체 로드맵을 제공받게 될 것 입니다.\n\n\n이 과정에서는 가장 강력한 하이브리드 인텔리전트 시스템을 기반으로 한 최강의 인공 지능 개발 방법을 알려드립니다. 지금까지, 이 모델은 이전에 개발된 AI들을 높은 점수로 제치고 만들어진 최고의 최첨단 모델인 것이 증명되었습니다.\n\n\n이 하이브리드 모델은 풀 월드 모델이라는 이름이 적합하며 딥 러닝, 딥 강화 학습, 정책 그라데이션, 심지어는 딥 뉴로 에볼루션 등 다양한 AI 분기의 예술 모델들을 모두 결합합니다.\n\n\n여러분은 단순한 인공 지능 강좌를 듣는게 아니라, 가장 강력한 AI 모델의 강좌와 그 마스터 툴킷을 한번에 얻을 수 있게 되는 것 입니다. 이 툴킷을 다운로드 받으면 하이브리드 지능형 시스템을 구축하는데 사용할 수 있습니다. 하이브리드 모델들이 AI 경쟁 시대에서 우세인 만큼 여러분은 반드시 이 모델을 다루는 방법을 배워야 합니다.\n\n\n추가적으로, TensorFlow와 Keras 이 두가지의 AI 프레임 워크를 위한 완벽한 도구 역시 제공합니다. 따라서 특정 애플리케이션을 위한 인공지능을 구축하고 싶을 땐 그냥 툴킷에서 필요한 모델을 가져와 다시 사용하기만 하면 됩니다.\n\n\nAI : 인공 지능 마스터 클래스 세부 커리큘럼\n완전히 연결된 신경망\n컨볼루션 신경망\n반복 신경망\n가변 자동 인코더\n혼합 밀도 네트워크\n유전 알고리즘\n진화 전략\n공분산 행렬 적응 진화 전략 (CMA-ES)\n매개 변수 탐색 정책 그라디언트\n그 외의 많은 것들\n\n\nLigency Team의 한마디!\n한국 수강생 여러분들, 안녕하세요?\n\n\n강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n하루 빨리 인공 지능의 미래인 하이브리드 AI 마스터를 위한 과정에 참여하세요!\n\n\n강의에서 만나요!\n- Ligency Team",
      "target_audience": [
        "인공지능, 딥 러닝, 혹은 머신 러닝에 관심있는 사람이라면 누구나"
      ]
    },
    {
      "title": "【初心者向け】自然言語処理をPythonで学ぼう！形態素解析、tf-idf、WordVec、Doc2Vecを実装！",
      "url": "https://www.udemy.com/course/python-nlp/",
      "bio": "自然言語処理の基本を理解！livedoorニュースの記事を元にPythonでMeCabを使った形態素解析を行い、tf-idfやWord2VecやDoc2Vecなどのアプローチで記事をベクトル化しCOS類似度を求めていこう！",
      "objectives": [
        "自然言語処理の基本について理解できます",
        "古典的な自然言語処理のアプローチを学べます",
        "Python×MeCabで形態素解析を行い文章を機械に理解させるための処理ができるようになります",
        "PythonでTf-IdfやWord2VecやDoc2Vecを使って単語や文章をベクトル化させ様々な処理が行なえるようになります",
        "OpenAIのEmbeddingsAPIの使い方が分かります"
      ],
      "course_content": {},
      "requirements": [
        "ある程度Pythonの知識があることが望ましいですが初心者でも問題ないです"
      ],
      "description": "本コースでは自然言語処理の基本について学んでいきます。\n\n\n最新のAIを理解していく上でも古典的な自然言語処理を理解しておくことは非常に重要です。\n\n\n自然言語処理とは、機械に人間の言葉を理解してもらう試み。\n\n\nいきなり最新のAIを学ぼうとするのではなくて古くから取り組まれてきた自然言語処理の領域をしっかり理解していきましょう！\n\n\n簡単にアニメーションで概要を理解してもらったあとは、Pythonで手を動かしながら学んでいってもらいます。\n\n\nまずはlivedoorニュース記事をMeCabという形態素解析エンジンで分かち書きし、tf-idfやWord2VecやDoc2Vecというアプローチでベクトル化していきます。\n\n\nその上でCOS類似度を使い、どの記事同士が似ているのかを見ていきます。\n\n\nまた、OpenAIが提供するEmbeddingsAPIを使ったベクトル化方法についても触れていきます。\n\n\n自然言語処理を基本から理解していきましょう！",
      "target_audience": [
        "自然言語処理領域に興味のある人",
        "最近のAIの大規模言語モデルのベースになる古典的な自然言語処理に興味のある人",
        "OpenAIのEmbeddingsAPIの使い方に興味のある人",
        "Tf-IdfやWord2VecやDoc2VecなどのPython実装に興味のある人"
      ]
    },
    {
      "title": "Curso Scrum Master Certificación",
      "url": "https://www.udemy.com/course/curso-scrum-master-certificacion/",
      "bio": "Scrum Master",
      "objectives": [
        "Conocer el marco de trabajo Scrum y certificarse como Scrum Master"
      ],
      "course_content": {
        "Scrum Master Certificación Bases": [
          "Scrum Master Lección I - Ágil",
          "Scrum Master Lección II - Principios",
          "Scrum Master Lección III - Aspectos"
        ],
        "Scrum Master Certificación - Procesos": [
          "Scrum Master Lección IV - Fase Inicio",
          "Scrum Master Lección V - Fase Planificación y Estimación",
          "Scrum Master Lección VI - Fase Implementación",
          "Scrum Master Lección VII - Fase Revisión y Retrospectiva",
          "Scrum Master Lección VIII - Fase Implementación"
        ],
        "Scrum Master Certificación - Escalabilidad": [
          "Scrum Master Lección IX - Escalamiento y Conclusión"
        ]
      },
      "requirements": [
        "Se recomienda haber tomado el curso de Fundamentos de Scrum, pero no es obligatorio"
      ],
      "description": "En este curso nos brindará la oportunidad de profundizar en el marco de trabajo Scrum, así como en sus componentes; Principios, Aspectos\ny Procesos, al finalizarlo, tendrás lo necesario para certificarte como Scrum Master mediante ScrumStudy.\nUna vez que termines el curso, es necesario que nos enviés un correo a solicitando tu cuenta para que puedas agendar tu examen. Dicho examen, será supervisado, consta de 100 preguntas y lo tendrás que terminar en 120 min máximo.",
      "target_audience": [
        "Administradores, líderes, gerentes de proyectos y desarrolladores de software"
      ]
    },
    {
      "title": "データサイエンスのための PyTorch Lightningによる 実践 深層学習",
      "url": "https://www.udemy.com/course/pytorch-lightning-cv-nlp/",
      "bio": "プロレベルの深層学習スキルを学ぼう。Computer VisionとNLPが両方学べます。",
      "objectives": [
        "深層学習の理論的な基礎からTransformer, BERT, GPTなど発展的な内容まで包括的に学べる",
        "PyTorch Lightningによる深層学習の基礎を身に付けることができる",
        "論文レベルの実装やTransformerのスクラッチからの実装などハイレベルな実装を学べる",
        "Computer Vision, NLPの両方の分野で最近の深層学習の知識を身に付け、実践できる"
      ],
      "course_content": {
        "はじめに": [
          "コースの概要紹介",
          "深層学習の概要"
        ],
        "深層学習の理論: 損失関数 オプティマイザー 過学習対策": [
          "イントロダクション",
          "損失関数・メトリックス",
          "オプティマイザー",
          "過学習の対策"
        ],
        "深層学習の理論: モデルのアーキテクチャ(Computer Vision / NLP)": [
          "イントロダクション",
          "MLP(Multilayer Perceptron)",
          "CV: CNN(Convolutional Neural Network) モデルの要素",
          "CV: CNN(Convolutional Neural Network) 様々なアーキテクチャ",
          "CV: ResNet",
          "CV: EfficientNet",
          "NLP: 特徴量",
          "NLP: メトリックス",
          "NLP: RNN / LSTM",
          "NLP: Transformer",
          "NLP: LLM BERT",
          "NLP: LLM T5",
          "NLP: LLM GPT",
          "NLP: ドメイン適応",
          "CV: ViT"
        ],
        "深層学習の実践: MLP ~ Computer Vision": [
          "イントロダクション",
          "notebooksのダウンロード",
          "notebookのアップロード",
          "PyTorch Lightningの基礎: MLP Part1",
          "PyTorch Lightningの基礎: MLP Part2",
          "PyTorch Lightningの基礎: MLP Part3",
          "PyTorch Lightningの基礎: CNN スクラッチ part1",
          "PyTorch Lightningの基礎: CNN スクラッチ part2",
          "PyTorch Lightningの基礎: データ拡張",
          "PyTorch Lightningの基礎: Callbacks",
          "PyTorch Lightningの基礎: ハイパーパラメータ管理",
          "CVの実践：EfficientNetのFine Tuning",
          "CVの実践：ViTのFine Tuning",
          "CVの実践：モデルの解釈性(Saliency Map / GradCAM) 理論",
          "CVの実践：モデルの解釈性(Saliency Map / GradCAM) 実践",
          "CVの実践：不均衡データの取り扱い 理論",
          "CVの実践：不均衡データの取り扱い 実践"
        ],
        "深層学習の実践: NLP": [
          "イントロダクション",
          "NLPの実践: Transformerの実装 スクラッチ",
          "NLPの実践：BERT Sentiment Analysis",
          "NLPの実践：T5 Machine Translation part1",
          "NLPの実践：T5 Machine Translation part2",
          "NLPの実践：PEFT(Parameter Efficient Fine Tuning) 理論",
          "NLPの実践：PEFT(Parameter Efficient Fine Tuning) 実践",
          "NLPの実践: GPTの為のOpenAIのアカウント / API KEY",
          "NLPの実践：OpenAIアカウント作成",
          "NLPの実践：OpenAI API KEYの登録",
          "NLPの実践：GPT Summarization"
        ],
        "ボーナスレクチャー": [
          "講義で使用したスライド(pdf)"
        ]
      },
      "requirements": [
        "Pythonの基本的な知識",
        "PyTorchの基本的な知識",
        "【Hands Onで学ぶ】PyTorchによる深層学習入門を修了しているか同等の深層学習の知識"
      ],
      "description": "【本講座の概要】\n本講座はUdemyの姉妹講座である”【Hands Onで学ぶ】PyTorchによる深層学習入門”を修了した方向けに、深層学習の中上級者やプロレベルを目指す為の講座です。\n\n\n近年の深層学習は2017年にTransformerが現れて以来、技術的な革新が著しく、特に自然言語処理(NLP)の分野ではLLM(Large Language Model)の急速な発展など大きな転換期を迎えています。一方で、深層学習分野の急速な発展により、細分化や高度な専門化が進んできており、自身の専門以外の最近の深層学習の技術にキャッチアップすることが非常に難しくなってきています。\n\n\nこの講座では、この状況を打破すべく、深層学習の基礎から復習しつつ、Computer VisionとNatural Language Processingの両方の分野に詳しくなれる構成となっております。\n\n\nこの講座を受講する事で、最近の深層学習技術を理論的、実践面から包括的に学べるだけなく、プロレベルの技術、スキルを身に付ける事が可能です。\n\n\n【人事の方/マネージャークラスの方へ】\n本コースは次のような使い方が可能です。\n・社内でレベルの高いAI人材を育成したい\n・効率よくプロレベルのデジタル人材を育成したい\n\n\n本コースは近年の深層学習のトピックを理論と実践の両面から手厚く取り扱っております。特にTransformerを中心としたLLMなどの最近のトピックを取り扱っております。また、取り扱っているコンテンツは実践的なものに絞っているため、コース全体の時間は短くまとまっております。\n\n\nこの為、コースを開始したが、長すぎてコースを完了できないという事は少ないと考えられます。コースのレベルは中・上級者向けであり、グローバルスタンダードで比較しても遜色ないプロレベルになっています。フレームワークはPyTorch Lightiningを使用しており、AI開発に適したスキルを身に付けることができます。\nしたがって、コースを修了する事で受講生は深層学習の強固な理論的基礎を築き、PyTorch Lightningによる実践的かつプロレベルのコーディングスキルも身に付ける事が可能です。\n\n\nもし、入門レベルの講座が必要な場合はまずは、”【Hands Onで学ぶ】PyTorchによる深層学習入門”の受講をお勧めします。\n\n\n\n\n【対象者とゴール】\nこのコースは中上級者向けのコースであり、深層学習やPyTorchの知識が必要となってきます。この為、姉妹講座である深層学習の基礎を学ぶためのコース【Hands Onで学ぶ】PyTorchによる深層学習入門を修了した、もしくは同等の知識・経験を持っている方を対象者としています。\n本コースのゴールは、深層学習の入門レベルからプロレベルへのステップアップを行い、AIエンジニアやデータサイエンティストとして開発をリードできるレベルのスキルを身に付けることです。\n\n\n【コースの構成】\nコースは理論編と実践編から構成されています。\n理論編\n理論編では深層学習の基礎から復習を行います。具体的には、深層学習の訓練プロセス、損失関数、メトリックス、オプティマイザー、過学習対策など、Computer VisionでもNLPでも使われる共通部分を固めます。更に、MLP, CNN(Alex Net, VGG, GoogLeNet, ResNet, EfficientNet), RNN/LSTM, Transformer, LLMなど重要な深層学習のコンポーネントとそのアーキテクチャで使われている技術の解説を行っています。多くの論文の内容を紹介しており、理論編を修了するだけでも、深層学習について非常に多くの事を学ぶことができます。\n\n\n実践編\n実践編ではPyTorch Lightiningを使って、実践的なプログラミングを行っていきます。環境はGoogle Colabを使用し、環境構築の必要はありません。実践編ではPyTorch Lightningの基本的なコンポーネント(Lightning Data Module / Lightning Module / Trainer / Tensorboard)から取り扱い、理論編で扱ったMLP, CNN, Transformer(BERT/T5/GPT)など多くのアーキテクチャを取り扱います。またCVとNLPについて発展的な話題を含みます。例えば、Explainable AI、Imbalanced dataset, LLM(BERT, T5)のFine tuningやPEFT(Parameter Efficient Fine-Tuning), GPTによる簡単なアプリケーションの作成が含まれます。",
      "target_audience": [
        "PyTorchの基礎はあるが、最近の深層学習の手法に詳しくなりたい方",
        "【Hands Onで学ぶ】PyTorchによる深層学習入門を修了し、さらにレベルアップしたい方",
        "プロレベルの深層学習のスキルを身に付けたい方",
        "画像処理はよく知っているが、自然言語処理についても知りたい方（その逆も然り）",
        "Transformerが難しくてよく理解できないが、理解して使いこなしたい方",
        "PyTorch Lightningを使ってみたい方"
      ]
    },
    {
      "title": "【未経験から始めよう】データ系人材キャリア構築ガイド",
      "url": "https://www.udemy.com/course/guide4data-oriented-career/",
      "bio": "データ系人材としてキャリアをスタートするために。未経験からデータサイエンティストを目指したいなら、ここから始めよう。",
      "objectives": [
        "AI開発や企業におけるデータ活用の全体像を理解できる。",
        "AI開発においてデータ系人材(データエンジニア、データサイエンティスト、データアナリストなど)が持つ役割について理解できる",
        "データサイエンティストの働き方、スキルセット、年収など、データサイエンティストの実際を理解できる",
        "未経験からデータサイエンティストを目指すための具体的なロードマップ、面接対策などを理解できる"
      ],
      "course_content": {
        "はじめに": [
          "コース概要"
        ],
        "データ系人材の現在地": [
          "イントロダクション",
          "企業におけるデータ活用",
          "AI開発の流れ",
          "データ系人材とは",
          "データエンジニアとは",
          "データアナリストとは",
          "データサイエンティストとは",
          "機械学習エンジニアとは"
        ],
        "データサイエンティストの実際": [
          "イントロダクション",
          "データサイエンティストの働き方",
          "データサイエンティストの年収",
          "データサイエンティストのスキルセット"
        ],
        "データサイエンティストとキャリア": [
          "イントロダクション",
          "事業系vsコンサル系",
          "国内企業vs外資系企業",
          "求人票を見てみよう"
        ],
        "データ系人材へのキャリアチェンジ": [
          "イントロダクション",
          "未経験からのロードマップ",
          "面接について",
          "コーディングテスト",
          "データ系キャリアを始めよう"
        ]
      },
      "requirements": [
        "受講要件はありません。"
      ],
      "description": "【本講座の概要】\n本講座は未経験からデータサイエンティストを目指したいという方向けに、データ系キャリアの全体像からロードマップまでをステップバイステップで学んでいくための講座です。\n「21 世紀で最もセクシーな職業」と呼ばれるデータサイエンティスト。企業におけるデータ活用やAIのモデルの開発を通して、データドリブンなビジネスインパクトを出せる非常に面白く、やりがいのある職業です。またデータサイエンティストは会社のＤＸにダイレクトにコミットするビジネスインパクトの大きさから、高い年収レンジでも知られています。\n\n\n一方で、このような悩みは無いでしょうか？\n・データサイエンティストは具体的にどのような仕事をしているのか？\n・データサイエンティストと機械学習エンジニアの違いは？\n・今、勉強しているデータサイエンスはキャリアチェンジに役に立つのか？\n・どのようにデータ系人材へキャリアチェンジすればよいのか？\n\n\n本コースはこのような悩みに応えるために作成しています。\nこの講座を受けることでＡＩ開発の全体像、データサイエンティストがその中で果たす役割、データサイエンティストのスキルセット、データサイエンティストになるためのロードマップなど、未経験からデータサイエンティストを目指すために必要な情報を網羅的に理解する事ができます。\n\n\nこのコースはＡＩ開発の全体像など会社におけるデータ活用から始まり、その中で、データサイエンティストを含むデータ系人材(データエンジニア、データアナリスト、データサイエンティスト、機械学習エンジニア)がそれぞれどのような役割を果たすのか、そして、データサイエンティストの働き方や必要なスキルなど様々な観点でデータ系キャリアを学んでいきます。さらに、事業会社とコンサル会社、日系と外資系など会社によってもデータサイエンティストのキャリアは大きく異なってきますので、この違いにもついても理解します。そして、最後に具体的なロードマップを見ていき、面接対策やコーディングテストについても解説を行っています。\n\n\nこの為、未経験からデータ系キャリアを目指す方はもちろん、既にデータサイエンティストとして働いている方が全体像を俯瞰する上でも役立つコースとなっています。\n\n\n\n\n【人事の方/マネージャークラスの方へ】\n本コースは次のような使い方が可能です。\n・社内の事業部門からDX組織への異動を促すためのサポートをしたい\n・社内のデータサイエンス組織、DX組織を更に強化したい\n・人事部門でもDXやAI開発の全体像を押さえておきたい\n\n\n【対象者とゴール】\n未経験からデータサイエンティストにキャリアチェンジしたい方向けにデータ系キャリアの全体像を把握し、最終的なキャリアチェンジまでのロードマップを理解することをゴールとしています。",
      "target_audience": [
        "未経験からデータサイエンティストを目指している方",
        "データ系キャリアにチャレンジしたいと考えている方",
        "データサイエンティストに興味がある方"
      ]
    },
    {
      "title": "Data Science für Python: NumPy, Pandas, Matplotlib & SciPy",
      "url": "https://www.udemy.com/course/data-science-grundlagen-python-numpy-matplotlib-scipy/",
      "bio": "Der NumPy, Scipy, Pandas und Matplotlib Grundlagenkurs: Sei bereit für Deep Learning, Machine Learning und Data Science",
      "objectives": [
        "Verstehe und programmiere mit dem Numpy Stack.",
        "Lerne die Grundlagen von Python",
        "Nutze NumPy, um Berechnungen durchzuführen und Daten zu generieren",
        "Nutze Pandas, um Daten aus Excel auszulesen und zu verarbeiten",
        "Nutze Matplotlib, um Daten in Diagramme zu visualisieren",
        "Nutze SciPy, um den einstieg in die Welt von Machine Learning zu erkunden"
      ],
      "course_content": {
        "Einleitung": [
          "Über mich",
          "Zusammenfassung",
          "Bedienung von Udemy",
          "Wie bewerte ich diesen Kurs?"
        ],
        "Einführung & Installation": [
          "Einführung Python und VS Code",
          "[Windows] Installation Python und Anaconda",
          "[MacOS] Installation Python und Anaconda",
          "Anaconda Environment erstellen",
          "Python Module installieren",
          "[Windows] Installation von VS Code",
          "[Mac] Installation VS Code",
          "Kursmaterialien zum Download",
          "Kursmaterialien"
        ],
        "Python Basics": [
          "Syntax",
          "Variablen",
          "Zahlen",
          "Casting",
          "Strings",
          "Operators",
          "Nutzer Eingaben nutzen mithilfe von input"
        ],
        "Datenstrukturen": [
          "Listen (1)",
          "Listen (2)",
          "Tuples",
          "Sets",
          "Dictionaries"
        ],
        "Schleifen und Kontrollstrukturen": [
          "Kontrollstruktur: if.. else",
          "Schleife: While",
          "Schleife: For",
          "List Comprehension (1)",
          "List Comprehension (2)"
        ],
        "Methoden und Funktionen": [
          "Einführung Funktionen",
          "Globale und lokale Variablen",
          "Funktionen mit Rückgabewerten (1)",
          "Funktionen mit mehreren Rückgabewerten (2)",
          "Funktionen mit mehreren Parametern (1)",
          "Funktionen mit mehreren Parametern (2)",
          "Das None-Keyword",
          "Funktionen überladen",
          "Parametern mit default-Werte",
          "Innere Funktionen",
          "Closures",
          "Die Main-Funktion",
          "call by value und call by name",
          "Rekursive Funktion"
        ],
        "NumPy": [
          "Jupyter Notebook",
          "Lists vs. Arrays",
          "For Schleife vs. Dot-Funktion",
          "Vektoren und Matrizen",
          "Automatisch Matrizen generieren",
          "Weitere Matrix operationen",
          "Lineare Gleichung lösen"
        ],
        "Pandas": [
          "Vorbereitung",
          "Daten in Pandas einlesen (1)",
          "Daten in Pandas einlesen (2)",
          "Was ist ein DataFrame?",
          "DataFrames: Zeilen und Spalten",
          "DataFrames: Spaltennamen festlegen",
          "Änderungen durchführen: DF.Apply()",
          "DataFrames: Spalten und Zeilen löschen"
        ],
        "Matplotlib": [
          "Liniendiagramme (1)",
          "Liniendiagramme (2)",
          "Balkendiagramme",
          "Tortendiagramm (1)",
          "Tortendiagramme (2)",
          "Punktdiagramme (X,Y)",
          "Histogramme",
          "Bilder plotten"
        ],
        "Scipy": [
          "Simple Optimierung von Funktionen",
          "Optimierung mit Basinhopping",
          "Curve Fitting"
        ]
      },
      "requirements": [
        "Lust etwas neues zu lernen :)"
      ],
      "description": "In diesen Kurs erhältst du einen Überblick in die beliebtesten Module in Python für Data Science, Deep Learning und Machine Learning. Die Module NumPy, SciPy, Pandas, Matplotlib sowie die Programmiersprache Python sind in diesen Themenbereichen nicht wegzudenken und jeder zukünftiger Data Science Experte sollte diese kennen! Hier erhältst du das alles und kannst sehen, ob das was für dich ist!\nPython ist eine universelle, üblicherweise interpretierte, höhere Programmiersprache. Sie hat den Anspruch, einen gut lesbaren, knappen Programmierstil zu fördern. So werden beispielsweise Blöcke nicht durch geschweifte Klammern, sondern durch Einrückungen strukturiert. Python unterstützt mehrere Programmierparadigmen, z. B. die objektorientierte, die aspektorientierte und die funktionale Programmierung. Ferner bietet es eine dynamische Typisierung. Wie viele dynamische Sprachen wird Python oft als Skriptsprache genutzt.\nNumPy ist eine Programmbibliothek für die Programmiersprache Python, die eine einfache Handhabung von Vektoren, Matrizen oder generell großen mehrdimensionalen Arrays ermöglicht. Neben den Datenstrukturen bietet NumPy auch effizient implementierte Funktionen für numerische Berechnungen an.\nPandas ist eine Programmbibliothek für die Programmiersprache Python, die Hilfsmittel für die Verwaltung von Daten und deren Analyse anbietet. Insbesondere enthält sie Datenstrukturen und Operatoren für den Zugriff auf numerische Tabellen und Zeitreihen.\nMatplotlib ist eine umfassende Bibliothek zum Erstellen statischer, animierter und interaktiver Visualisierungen in Python. Matplotlib macht einfache und schwierige Dinge möglich. Erstellen. Entwickeln Sie Diagramme mit Veröffentlichungsqualität mit nur wenigen Codezeilen.\nSciPy ist eine Python-basierte Open-Source-Softwareumgebung, die hauptsächlich von Wissenschaftlern, Analysten und Ingenieuren für wissenschaftliches Rechnen, Visualisierung und damit zusammenhängende Tätigkeiten benutzt wird. Der Name SciPy bezeichnet gleichzeitig auch eine spezifische Python-Bibliothek mit numerischen Algorithmen und mathematischen Werkzeugen, die einen Kernbestandteil der SciPy-Umgebung bilden.",
      "target_audience": [
        "Softwareentwickler, Data Scientists und Machine Learning Experten",
        "Big Data Anfänger",
        "Studenten der Informatik, Bioinformatik, IT-Sicherheit, Mathematik etc.",
        "Python Entwickler"
      ]
    },
    {
      "title": "SQL pour la Data (Analyst, Scientist, Engineer) 2025",
      "url": "https://www.udemy.com/course/sql-pour-la-data/",
      "bio": "De débutant à expert en SQL pour l'analyse des données (avec Snowflake)",
      "objectives": [
        "Comprendre les bases de la modélisation des bases de données",
        "Filtrer et extraire les données d'une table avec SELECT",
        "Manipuler les données d'une database",
        "Résumer les tables avec les agrégations et GROUP BY",
        "Joindre plusieurs tables ensemble pour créer un jeu de données plus riches",
        "Utiliser la fonction CASE pour pivoter une table et les requêtes avancées",
        "Apprenez à utiliser Snowflake",
        "Manipuler les données dans Snowflake (et les récupérer dans Looker)",
        "Réalisation d'un projet data final professionnalisant"
      ],
      "course_content": {
        "Bienvenue dans notre cours d'initiation à SQL": [
          "Bienvenue",
          "Rejoignez notre Discord !",
          "Echange avec Guillaume Rostand, CMO de Liligo et Président de la French Tech"
        ],
        "Introduction": [
          "Sommaire du chapitre",
          "Introduction aux bases de données",
          "Organisation d'une base de données: Schéma, Table",
          "Tables, colonnes, types de données et vues",
          "Une petite vérification avant qu'on continue"
        ],
        "Configurer votre environnement local": [
          "Introduction",
          "Installation sur Windows",
          "Installation sur Mac",
          "Information complémentaires",
          "Mise en place de la base de données",
          "Description du jeu de données"
        ],
        "Les bases de la modélisation": [
          "Introduction au chapitre",
          "C'est quoi la modélisation d'une BDD?",
          "Normalisation des données et schéma en étoile",
          "Dé-normalisation des données",
          "Quizz sur la normalisation et la dé-normalisation des données",
          "Les dimensions à évolution lente",
          "Vérifier ses connaissances sur les SCD",
          "Index et clé d'une table",
          "Quelques questions sur les index et clés",
          "Ce qu'on peut stocker dans une table",
          "Les types de données"
        ],
        "Récupérer des informations avec SELECT": [
          "Récupération des données avec SELECT",
          "Ton 1er SELECT",
          "Utilisation de différentes clauses pour filtrer et trier les résultats",
          "Analyse de la satisfaction client",
          "Analyse des clients - Partie 1",
          "Analyse des clients - Partie 2",
          "Analyse des clients - Partie 3",
          "Analyse des clients - Partie 4",
          "Live coding sur les exercices"
        ],
        "Manipulation des données": [
          "Insérer du contenu",
          "Modifier du contenu",
          "Appliquer l'insertion et la modification du contenu",
          "Le Rollback",
          "Supprimer du contenu",
          "Comme par magie!"
        ],
        "Les jointures": [
          "Jointure simple",
          "Analyse des courses à Marseille",
          "Les différents types de jointures",
          "Jointures avancées",
          "Faire un join avec une table intermédiaire",
          "Jointure multiple avec tables intermédiaires"
        ],
        "Les fonctions d'agrégation": [
          "Introduction au chapitre",
          "Les fonctions MIN et MAX",
          "Application des fonctions MIN et MAX",
          "Les fonctions AVG et MEDIAN",
          "Application des fonctions AVG et MEDIAN",
          "Application des fonctions AVG et MEDIAN",
          "Les fonctions COUNT et SUM",
          "Application des fonctions COUNT et SUM",
          "Le modificateur DISTINCT",
          "Impact des valeurs NULL",
          "Exercice final"
        ],
        "Les fonctions GROUP BY et HAVING": [
          "La fonction GROUP BY",
          "Analyse des voitures - Partie 1",
          "La clause HAVING",
          "Analyse des courses - Partie 1",
          "Analyse des voitures - Partie 2",
          "Ordre des opérations en SQL"
        ],
        "Sous requêtes et vues": [
          "Créer des sous requêtes",
          "Analyse des courses - Partie 2",
          "Créer des vues",
          "View vs Materialized view"
        ]
      },
      "requirements": [
        "Aucune expérience en programmation requise. Vous aurez uniquement besoin de motivation."
      ],
      "description": "Bienvenue dans notre cours SQL pour la data !\n\n\nCe cours est spécialement conçu pour les débutants désireux d'acquérir les bases fondamentales de la manipulation des bases de données.\n\n\nDirigé par deux professionnels, Christophe et Adam, fondateurs de l'école Ada, chacun avec plus de 7 ans d'expérience dans le domaine, cette formation met l'accent sur une approche pratique.\n\n\nMéthodologie d'Enseignement :\nCe cours privilégie une approche pratique, avec un équilibre entre la démonstration en direct par les instructeurs et la participation active des étudiants à travers des exercices pratiques et des sessions de codage en direct.\nChaque concept théorique est immédiatement mis en pratique à travers des exemples concrets, permettant ainsi aux étudiants de consolider leur compréhension par la pratique.\n\n\nPublic Cible :\nDéveloppeurs débutants\nÉtudiants en informatique\nProfessionnels du marketing, développement produit, sales ...etc\nProfessionnels cherchant à acquérir de nouvelles compétences en bases de données\nPrérequis :\nAucune connaissance préalable en SQL n'est requise. Une familiarité avec les concepts de base de la programmation est un atout, mais n'est pas obligatoire.\n\n\nObjectifs d'Apprentissage :\nÀ la fin de ce cours, vous serez capables de :\n\n\nÉcrire des requêtes SQL de base pour extraire, filtrer et trier des données\nComprendre les principes fondamentaux des bases de données relationnelles\nManipuler efficacement des données à travers des opérations d'insertion, de mise à jour et de suppression\nMaîtriser les techniques de jointure pour combiner des données provenant de différentes tables\nAgréger et résumer les jeux de données pour en extraire des métriques utiles pour votre entreprise\nCe cours est une excellente porte d'entrée pour apprendre les bases de SQL et commencer à travailler avec des bases de données relationnelles. Mais si vous voulez aller encore plus loin et vous préparer véritablement à la réalité du marché, il y a quelque chose de nouveau pour vous.\n\n\nVous êtes à la recherche d'une formation qui vous prépare réellement aux exigences du marché de la data ?\n\n\nAprès plusieurs années d’expérience en freelance et en formation, nous avons lancé Ada-study, un programme de formation innovant et taillé sur mesure pour vous donner les compétences les plus demandées par les entreprises.\n\n\nPourquoi Ada-Study ?\n\n\nContrairement à la plupart des formations intensives, qui passent trop de temps sur des concepts théoriques et peu applicables en entreprise, nous allons à l'essentiel :\n\n\nDes langages et technologies réellement utilisés dans le monde professionnel (Python, SQL, DBT, Snowflake etc.).\nDes cas d'étude concrets issus de partenariats avec des entreprises.\nDes projets end-to-end basés sur des besoins réels, et non des exemples fictifs comme les recommandations de films ou la prédiction météo.\n\n\nCe que vous allez apprendre dans Ada-Study :\nAu-delà des bases SQL que vous verrez dans ce cours, notre programme de formation vous forme de manière pratique et immédiatement applicable sur :\n\n\nPython, DBT, Snowflake, BigQuery ...\nLa gestion de données et l'automatisation avec Git, Mage, Airflow,\nLes outils de visualisation comme Metabase, Tableau, et bien plus encore.\nNous mettons à jour régulièrement nos contenus pour vous tenir à jour sur les dernières tendances du marché.\n\n\nPourquoi nous rejoindre ?\nAvec Ada-Study, vous avez accès à plus de 20 modules couvrant toutes les compétences cruciales pour réussir en tant que Data Analyst ou Analytics Engineer.\nNotre approche est pratique, ciblée et conçue pour répondre aux attentes des entreprises d'aujourd'hui.\n\n\nAccessible à vie, vous pouvez commencer, évoluer à votre rythme et revenir sur les concepts lorsque vous en avez besoin, un vrai investissement pour la suite de votre carrière.\nParce que la recherche d'un nouvel emploi ou d'une nouvelle mission peut faire partir de votre objectif, nous avons intégré un coaching carrière à notre programme.\n\n\nPassez à l'étape suivante et rejoignez ada-study pour des compétences véritablement utiles sur le terrain.\nProfitez d'une approche qui vous forme à ce que les entreprises attendent vraiment.\n\n\nÀ très bientôt sur Ada-study !",
      "target_audience": [
        "Toutes personnes souhaitant devenir professionnel de la data",
        "Ou toute personne souhaitant approfondir son apprentissage de SQL en développant ses compétencesen data"
      ]
    },
    {
      "title": "Álgebra Linear com Python para Machine Learning e Modelagem",
      "url": "https://www.udemy.com/course/algebra-linear-com-python-para-machine-learning-e-modelagem/",
      "bio": "Para Machine Learning, Modelagem Matemática, Estatística, Ciência de Dados, Matemática, Engenharia, Ciências Exatas...",
      "objectives": [
        "Vetores",
        "Operações com vetores",
        "Tipos de Matrizes",
        "Operações com matrizes",
        "Matriz Inversa",
        "Determinante",
        "Equações Lineares",
        "Sistema de Equações Lineares",
        "Resoluções de sistemas lineares (método da adição, substituição, regra de Cramer e escalonamento)",
        "Regra de Cramer",
        "Regra de Sarrus",
        "Estimativa dos mínimos quadrados",
        "Autovalor e autovetor",
        "Transformação linear (homotetia, rotação, translação, cisalhamento, reflexão, alongamento, contração...)",
        "Teorema de Laplace",
        "Cofator",
        "Noções de Análise dos Componentes Principais (PCA)",
        "Teoria Matemática da Regressão Linear Múltipla",
        "Fundamentos de Python"
      ],
      "course_content": {
        "Introdução": [
          "Boas vindas e apresentação do instrutor",
          "Apresentação do curso e da plataforma de estudos"
        ],
        "Fundamentos de Python": [
          "A Linguagem Python",
          "Conhecendo o Google Colaboratory",
          "Instalação do Anaconda Python",
          "Conhecendo o Jupyter Notebook",
          "Primeiros passos no Python com o Google Colaboratory",
          "Operadores Matemáticos",
          "Importações de bibliotecas e pacotes",
          "Estrutura condicional",
          "Estrutura de Repetição",
          "Listas, Tuplas e Dicionários",
          "Criação Funções",
          "Função lambda e função map",
          "List comprehensions"
        ],
        "Vetores e Matrizes": [
          "Introdução à Álgebra Linear",
          "Vetores e a soma geométrica bidimensional",
          "Vetores no Rn e Cálculo com vetores",
          "Operações com vetores no Python",
          "Distância, norma e representação geométrica no Python",
          "Matrizes",
          "Tipos de Matrizes no Python",
          "Manipulação de matrizes no Python",
          "Adição e Subtração de matrizes",
          "Multiplicação de matrizes",
          "Operações com matrizes no Python",
          "Matriz Inversa",
          "Determinante",
          "Teorema de Laplace e Cofator",
          "Determinante e matriz inversa no Python"
        ],
        "Sistemas Lineares": [
          "Equações",
          "Sistema de equações lineares",
          "Resolução de sistema de equações lineares: método da adição e substituição",
          "Resolução de sistema de equações lineares 3x3",
          "Resolução de sistema de equações lineares: regra de Cramer",
          "Regra de Cramer no Python",
          "Resolução sistema equações lineares: método eliminação de Gauss (escalonamento)",
          "Estimativa dos mínimos quadrados",
          "Estimativa dos mínimos quadrados no Python – parte 1",
          "Estimativa dos mínimos quadrados no Python – parte 2",
          "Criação de um modelo de regressão linear múltipla no Python"
        ],
        "Transformação Linear, Autovetores e Autovalores": [
          "Transformação linear",
          "Transformação linear no Python: Homotetia",
          "Transformação linear no Python: Translação",
          "Transformação linear no Python: Rotação",
          "Transformação linear no Python: Reflexão",
          "Transformação linear no Python: Cisalhamento",
          "Transformação linear no Python: Alongamento e Contração",
          "Autovetores e autovalores",
          "Autovetores e autovalores no Python",
          "Fundamentos da Análise dos componentes principais (PCA)",
          "Autovetores e autovalores na Análise dos componentes principais (PCA) no Python."
        ],
        "Finalização do curso": [
          "Encerramento"
        ],
        "Referências e links úteis": [
          "Referências e links úteis (gratuitos)"
        ]
      },
      "requirements": [
        "Não há nenhum pré-requisito"
      ],
      "description": "Este curso aborda de forma clara e objetiva os principais conceitos da Álgebra Linear focado em demonstrações práticas utilizando a Linguagem de programação Python. Serão estudados os conteúdos sobre vetores (tipos e operações), matrizes(tipos, operações e determinantes), sistemas lineares, resolução de sistemas lineares (método da adição, método da substituição, regra de Cramer e escalonamento), Teorema de Laplace, Cofator, Estimativa dos mínimos quadrados, modelo de regressão linear múltipla, transformação linear (Homotetia, Translação, Rotação, Reflexão, Cisalhamento, Dilatação, Contração, Identidade, Nula e Inversa), autovalores, autovetores e Análise dos Componentes Principais (PCA).\nSão utilizados alguns datasets para exemplificar, onde é apresentado como se utiliza a Álgebra Linear com dados reais, inclusive a análise inicial que se deve fazer nos dados. É demonstrado como a Álgebra Linear se relaciona com o Método dos Mínimos Quadrados, com a Regressão Linear Múltipla e também com a Análise dos Componentes Principais.\nA primeira seção é referente a apresentação dos conceitos básicos de Python no Google Colaboratory, para que aqueles que não conhecem o Python e/ou o Google Colaboratory possam acompanhar o curso com tranquilidade.\nO curso é apresentado no sistema operacional Windows, no Google Colaboratory, mas usuários do Linux e Mac acompanham tranquilamente pelo Júpiter Notebook.\nTenho certeza que a sua visão sobre Álgebra Linear irá mudar após esse curso.",
      "target_audience": [
        "Estatístico",
        "Matemático",
        "Cientista de Dados",
        "Profissionais de Machine Learning",
        "Pesquisador",
        "Engenheiro",
        "Administrador",
        "Economista",
        "Estudantes de graduação e pós graduação"
      ]
    },
    {
      "title": "Herkes İçin Yapay Zeka ve Yapay Zeka Algoritmaları",
      "url": "https://www.udemy.com/course/herkes-icin-yapay-zeka-ve-yapay-zeka-algoritmalari/",
      "bio": "Yapay Zeka ve Algoritmaları MIT,Stanford gibi Dünyanın Seçkin Üniversitelerinde Okutulan Kitaptan Küresel Ölçüde Öğrenin",
      "objectives": [
        "Dünyada seçkin birçok üniversitede öğretilen yapay zeka derslerini öğreneceksiniz.",
        "Dersler yapay zekada başyapıt olan \"Artificial Intelligence: A Modern Approach\" kitabından hazırlanmıştır.",
        "Küresel olarak rekabet edilebilir seviyeye ulaşacaksınız.",
        "Yapay zekanın mantalitesini kavrayacaksınız.",
        "Yapay sinir ağlarını çalışma prensibini öğreneceksiniz.",
        "Derinlik Öncelikli Arama, Yayılım Öncelikli Arama gibi birçok yapay zeka algoritması öğreneceksiniz.",
        "Yapay zeka modellerini(agent) nasıl eğitebileceğinizi öğreneceksiniz.",
        "\"Prolog\" mantık programlama dili öğreneceksiniz.",
        "Yapay zekâ uygulamalarında kullanılan beşinci nesil bilgisayar dili \"Prolog\" öğreneceksiniz.",
        "Prolog ile programlama yapabilecek seviyeye geleceksiniz.",
        "Uygulamalı projeler geliştireyek yapay zeka derslerini pekiştirebileceksiniz."
      ],
      "course_content": {
        "Motivasyon": [
          "Geçmişten Günümüze Yapay Zeka",
          "Yazılım ve Programlama Nedir?"
        ],
        "What is Artificial Intelligence(AI)": [
          "Thinking-Acting",
          "Environments Types"
        ],
        "Solving Problem by Searching": [
          "Tree Graph",
          "BFS-UCS-DFS-DLS"
        ],
        "Informed Search and Exploration": [
          "Greedy-A* Search",
          "Recursive Search"
        ],
        "Games": [
          "Games"
        ],
        "Logical Agent": [
          "Wumpus World",
          "Logic",
          "Conjuctive Normal Form",
          "Forward-Backward Chaining",
          "Ek Kaynak"
        ],
        "First Order Logic": [
          "First Order Logic",
          "EXAM"
        ],
        "Prolog": [
          "Facts-Rules-Queries",
          "Unification-Proof Tree",
          "Recursion"
        ],
        "Neural Networks": [
          "Activation Function-Percetron",
          "Multilayer NN-Back Propagation",
          "Ek Kaynak"
        ],
        "Genetic Algorithm-Fuzzy Logic": [
          "Genetic Algorithm",
          "Fuzzy Logic",
          "EXAM",
          "Ek Kaynak"
        ]
      },
      "requirements": [
        "Kursu takip edebilmek için hiçbir ön koşul yoktur.",
        "Öğrencilerin, herhangi bir programlama bilgisine ihtiyacı yoktur."
      ],
      "description": "2011’de Dünya teknolojik olarak yeni bir alana evrildi. Endüstri 4.0 ile hayatımıza teknoloji entegre oldu. Bu teknolojiler bulut teknolojisi, makina öğrenmesi, kripto paralar, nesnelerin interneti… Saydığımız ve sayamadığımız bu teknolojilerin merkezinde YAPAY ZEKA yer almaktadır. Artık bütün cihazları akıllı olarak geliştirmek ve kullanmak  çağımız için elzem bir ihtiyaçtır. Sizde eğer teknolojiyi tüketen değil üreten olmak istiyor ve geleceğe şimdiden yön vermek istiyorsanız doğru kurstasınız. Unutmayın ki temeli sağlam olmayan herşey çökmeye mahkumdur. Sizde teknolojilerin temeli olarak görülen yapay zekayı ve algoritmaların mantalitesini kavrayarak bütün teknolojileri yeniden keşfedin.\n\n\nKurs ile Öğrenecekleriniz\n1) Yapay zekada başyapıt olan \"Artificial Intelligence: A Modern Approach\" kitabından dersleri küresel ölçüde öğrenebileceksiniz.\n2) Yapacağınız sınavlar ile kendi yeterliliğinizi test etme imkanını yakalayacaksınız.\n3) Prolog programlama dili derslerinde onlarca örnek yaparak  programlamanın mantalitesini kavrayacaksınız.\n4) Derslerin dokümantasyonuna erişim sağlayarak sürekli öğrenme yetkinliğine sahip olacaksınız.\n\n\nKurs İçeriği\n· What is Artificial Intelligence(AI)\n· Solving Problem by Searching\n· Informed Search and Exploration\n· Games\n· Logical Agent\n· First Order Logic\n· Prolog\n· Neural Networks\n· Genetic Algorithm\n· Fuzzy Logic",
      "target_audience": [
        "Yapay zeka derslerini küresel ölçüde öğrenerek rekabet edebilir seviyeye ulaşmak isteyen herkes.",
        "Yapay zekaya ilgi duyan herkes.",
        "Geleceğin teknolojisini şimdiden öğrenmek isteyenler.",
        "Yapay zeka ve algoritma derslerini hakim olmak isteyen herkes."
      ]
    },
    {
      "title": "【0から始めるPandas】大量データを処理する基礎スキルを習得",
      "url": "https://www.udemy.com/course/pandas_basics/",
      "bio": "データ分析の基礎スキルを身につけよう！",
      "objectives": [
        "データフレームを作成する方法",
        "csvファイルのデータを読み込む方法",
        "データをcsv, excel, jsonファイルに出力する方法",
        "特定の条件に当てはまるデータを抽出する方法",
        "特定のカラムの情報を元にデータを並び替える方法",
        "データフレーム同士を結合する方法",
        "データフレームに対して関数を実行する方法",
        "平均値、標準偏差などの統計量を取得する方法",
        "データを元にグラフを作成する方法"
      ],
      "course_content": {
        "イントロダクション": [
          "イントロダクション"
        ],
        "Pandas準備": [
          "Pandasのインストール",
          "jupyter labの使い方"
        ],
        "Pandas超基礎": [
          "データフレームの作成",
          "csvファイルからデータフレームを作成",
          "データフレームに対して使えるメソッド一覧",
          "インデックスの利用",
          "特定の列の情報を取得",
          "行番号、列番号を使って特定の情報を取得",
          "行名、列名を使って特定の情報を取得",
          "Seriesオブジェクトの作成",
          "統計量の取得",
          "データ型とその変換",
          "欠損値の処理"
        ],
        "グラフの作成": [
          "折れ線グラフの作成",
          "散布図、円グラフ、棒グラフの作成"
        ],
        "フィルタリング": [
          "条件に当てはまるデータを抽出"
        ],
        "ソート": [
          "特定の列の情報に応じてデータを並び替え"
        ],
        "既存データの更新": [
          "既存データの更新"
        ],
        "時系列データの取り扱い": [
          "日付データをDatetime型に変換",
          "連鎖インデックスと代入について",
          "時系列データに関する基本操作"
        ],
        "データ集約": [
          "Groupbyの利用"
        ],
        "関数の適応": [
          "Seriesオブジェクトに対する関数の実行",
          "データフレームに対する関数の実行"
        ]
      },
      "requirements": [
        "Pythonの基礎文法を理解している方を対象としています",
        "Pythonの開発環境を構築できている方を対象としています",
        "本講義はPandasの基本的な使い方を題材としています。発展的な内容は取り扱っていません。"
      ],
      "description": "Pythonで大量データを処理する方法を学ぶためのPandasマスター講座が登場。\npandasとはデータの読込や並べ替え、欠損値（欠けている項目値）の補完などを行うことができるライブラリのことです。\n\n\nデータ分析入門の第一歩としてPandasの使い方を学び、データの処理をできるようになりましょう！\n\n\n【コース概要】\n以下が本コースで学べる内容の概要になります。\n\n\n＜Pandas基本操作＞\nデータフレームの作成方法\nカラム名を設定する方法\nインデックス名を設定する方法\n特定の列・行の情報を抽出する方法\n既存のデータを更新する方法\n欠損値を処理する方法\nカラムを追加・削除する方法\n平均値、中央値、最大値などの基本統計量を取得する方法\n条件に合致する情報のみを抽出する方法（フィルタリング）\nデータを昇順・降順に並び替える方法（ソート）\nデータを元にグラフを作成する方法\n同じ値を持つデータをグルーピングする方法\n時系列データを扱う方法\nデータフレームに対して関数を実行する方法\ncsvファイルの読込・書込方法\nExcelファイルの読込・書込方法\njsonファイルの読込・書込方法\n\n\n【注意】\nPythonの基本文法を学習済みであることを前提としています\nPythonの開発環境が整っている方のみ受講可能です。",
      "target_audience": [
        "データ分析に興味がある人",
        "Pandasの使い方が分からなくて困っている人",
        "Pandasを体系的に学べる教材を探している人"
      ]
    },
    {
      "title": "Algoritmos Inteligentes de Busca com Python",
      "url": "https://www.udemy.com/course/algoritmos-inteligentes-de-busca-com-python/",
      "bio": "Construa algoritmos de busca inteligente de cidades parecido com o que é usado pelo Google Maps para encontrar rotas!",
      "objectives": [
        "Aprenda na teoria e na prática sobre busca sem informação e busca com informação/heurística",
        "Aprenda passo a passo como desenvolver um algoritmos para encontrar a melhor rota entre cidades",
        "Entenda o funcionamento prático dos algoritmos de busca gulosa, busca A* (estrela), busca em largura e busca em profundidade"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre Inteligência Artificial"
        ],
        "Resolução de problemas por meio de busca": [
          "Introdução ao módulo",
          "Definição de problemas e soluções",
          "Mapa das cidades",
          "Instalação do Anaconda",
          "Implementação do mapa I",
          "Implementação do mapa II"
        ],
        "Busca sem informação": [
          "Introdução ao módulo",
          "Busca sem informação",
          "Pilha - teoria",
          "Gibi pilhas",
          "Pilha - implementação",
          "Pilha - depuração",
          "Busca em profundidade - teoria",
          "Recursão",
          "Busca em profundidade - implementação",
          "Busca em profundidade - depuração",
          "Busca em profundidade - busca do objetivo",
          "Fila - teoria",
          "Gibi filas",
          "Fila circular - teoria",
          "Fila circular - implementação",
          "Fila circular - depuração",
          "Busca em largura - teoria",
          "Busca em largura - implementação",
          "Busca em largura - depuração",
          "Busca em largura - busca do objetivo",
          "Resumo dos algoritmos"
        ],
        "Busca com informação": [
          "Introdução ao módulo",
          "Busca com informação",
          "Heurísticas",
          "Alteração no mapa - distância em linha reta",
          "Vetor ordenado - teoria",
          "Vetor ordenado - implementação",
          "Vetor ordenado - depuração",
          "Busca gulosa - teoria",
          "Busca gulosa - implementação",
          "Busca gulosa - depuração",
          "Busca A* - teoria",
          "Robô Shakey",
          "Alterações no mapa - distância pela estrada",
          "Busca AEstrela - adjacente e vetor ordenado",
          "Busca AEstrela - implementação",
          "Busca AEstrela - depuração",
          "Resumo dos algoritmos",
          "Relaxação de problemas"
        ],
        "Considerações finais": [
          "Considerações finais",
          "Código fonte completo",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "É recomendado conhecimentos básicos sobre lógica de programação",
        "Conhecimentos básicos sobre Python são desejáveis",
        "Não são necessários conhecimentos prévios sobre Inteligência Artificial",
        "Conhecimentos básicos sobre Orientação a Objetos são desejáveis"
      ],
      "description": "A resolução de problemas por meio de algoritmos de busca é uma importante ramificação da Inteligência Artificial, sendo responsável por várias aplicações práticas utilizadas em nosso dia a dia, tal como o mecanismo para encontrar a menor rota em um aparelho GPS.\n\nNeste curso você terá uma visão teórica e prática sobre essa área, aplicando todos os conceitos em um projeto prático que terá como objetivo aplicar os algoritmos para encontrar a menor rota entre duas cidades. Utilizaremos duas abordagens: a busca sem informação e a busca com informação. A primeira não apresenta inteligência e é composta pelos algoritmos de busca em largura e profundidade, enquanto que a segunda abordagem será implementada por meio dos algoritmos de busca gulosa e busca A* (A Estrela). Esse último algoritmo é muito utilizado em jogos e foi ele que deu origem à tecnologia de GPS (Global Position System) que muito utilizamos em nosso dia a dia! Utilizaremos a linguagem Python para a implementação do projeto, porém, o código fonte pode ser facilmente portado para outras linguagens.\nPreparado(a) para dar um importante passo na sua carreira? Aguardo você no curso! :)",
      "target_audience": [
        "Pessoas interessadas em Inteligência Artificial",
        "Pessoas que querem aprender como os algoritmos inteligentes de busca funcionam na prática"
      ]
    },
    {
      "title": "[라즈베리파이] IoT 딥러닝 Computer Vision 실전 프로젝트",
      "url": "https://www.udemy.com/course/iot-computer-vision/",
      "bio": "AI 인공지능이 대세라는 것은 말할 필요가 없습니다. 그런데 머신러닝과 딥러닝을 배워서 어디에 쓴다는 겁니까? 이제 생활에서 활용되는 유용한 사물인터넷IoT Computer Vision 프로젝트들을 같이 배워봅시다.",
      "objectives": [
        "Computer Vision 이미지, 동영상 처리",
        "Computer Vision dnn(Deep Learning) 이해와 실습",
        "라즈베리파이IoT 장치에서 딥러닝 기능구현",
        "이미지, 동영상에서 물체식별(Object Detection)",
        "이미지, 동영상에서 물체인식(Object Recognition)",
        "YOLO, Harr 등 다양한 Computer Vision 기법",
        "이미지, 동영상에서 얼굴인식(Face Recognition)",
        "이미지, 동영상에서 문자인식(Text Recognition)"
      ],
      "course_content": {
        "시작하기": [
          "강의 소개"
        ],
        "직접 쓴 숫자를 인식하는 딥러닝 기술": [
          "MNIST 손글씨 인식 딥러닝 모델 다시하기 1",
          "MNIST 손글씨 인식 딥러닝 모델 다시하기 2",
          "직접 쓴 손글씨 이미지 처리하기",
          "직접 쓴 손글씨 딥러닝 모델 적용하기",
          "웹카메라 손글씨 영상 인식 딥러닝 프로그램 1",
          "웹카메라 손글씨 영상 인식 딥러닝 프로그램 2",
          "손글씨 영상 인식 프로그램 실행하기"
        ],
        "[특별강의] 라즈베리파이 이해하기- '파이썬 라즈베리파이 IoT프로젝트-원격모니터링 자동차'": [
          "라즈베리 파이란?",
          "리눅스 설치하기",
          "원격터미널 사용하기",
          "라스비안 둘러보기"
        ],
        "라즈베리파이IoT 직접 쓴 손글씨 딥러닝 적용하기": [
          "파이썬3, 텐서플로2 설치하기",
          "OpenCV, 가상환경 설치하기",
          "PiCamera를 이용한 영상처리",
          "라즈베리파이에서 직접 쓴 손글씨 인식"
        ],
        "[특별강의] 파이어베이스 이해하기 - '앵귤러 파이어베이스 완전정복 - PetStore 쇼핑몰 프로젝트'": [
          "Firebase란?",
          "NoSQL Structure 배우기",
          "Firebase 데이터베이스 구축"
        ],
        "주차장 차량 숫자 세는 딥러닝 기술": [
          "YOLO를 이용한 차량인식",
          "NMS를 이용한 물체 인식율 향상",
          "파이썬 파이어베이스 Admin 설정하기",
          "라즈베리파이에서 실행하기",
          "YOLO Tiny로 속도 개선하기",
          "텐서플로 라이트란?",
          "텐서플로 라이트 Interpreter 설치하기",
          "텐서플로 라이트로 성능개선하기"
        ],
        "차량 번호판을 인식하는 딥러닝 기술": [
          "차량 번호판 인식 프로젝트 소개",
          "OpenCV EAST와 Tesseract",
          "ROI(Region Of Interest) 구하기",
          "Tesseract 문자인식(Text Recognition)",
          "라즈베리파이에서 YOLO Tiny 실행하기",
          "라즈베리파이 최적화 - 이미지 필터를 이용한 번호판 인식",
          "라즈베리파이 최적화 - Tesseract 설정과 운영기법"
        ],
        "졸음을 감지하여 경고하는 딥러닝 기술": [
          "졸음감지 프로젝트 소개",
          "Keras Model을 이용한 졸음감지 프로그램 1",
          "Keras Model을 이용한 졸음감지 프로그램 2",
          "텐서플로 라이트 모델만들기",
          "텐서플로 라이트 졸음감지 프로그램",
          "텐서플로 라이트로 개선된 프로그램"
        ],
        "출입자 얼굴을 인식해서 메일을 보내주는 딥러닝 기술": [
          "출입자 얼굴인식 프로젝트 소개",
          "face encoding 정보 추출하기",
          "드롭박스에 얼굴인식 사진 저장하기",
          "출입자 얼굴인식 프로그램 실행하기",
          "파이어베이스 Cloud Function 사용하기",
          "SendGrid 이메일 서비스 사용하기",
          "자동 메일 발송 기능 완성하기"
        ],
        "[특별강의] Face Recognition강화하기": [
          "Face Detection 3대 기법",
          "OpenCV dnn Face Detection 코드해설 1",
          "OpenCV dnn Face Detection 코드해설 2",
          "Face_Recognition 라이브러리 설치"
        ]
      },
      "requirements": [
        "열심히 배우고자 하는 의지",
        "파이썬 기본지식",
        "파이썬 데이터 가공, 시각화 경험"
      ],
      "description": "Computer Vision분야에서 사물인터넷과 딥러닝을\n활용하는 방법과 예제를 같이 배웁니다.\n\n머신러닝, 딥러닝\n이제는 실전입니다!\n\n인공지능의 Hot한 분야, Computer Vision! 사물인터넷 IoT 라즈베리파이와 만나 실전 프로젝트로 태어났습니다.\n\n\n활용할 능력을 키우세요!\n\n인공지능, 머신러닝, 딥러닝을 배우고 강의하면서 이론적인 기초를 다지는 것이 중요한 만큼 실전에서 활용할 능력을 키우는 것도 중요하다고 생각했습니다.\n\n그래서 인공지능, 머신러닝, 딥러닝을 사용하는 대표적인 영역인 Computer Vision분야에서 사물인터넷 IoT장치를 활용하는 프로젝트를 준비하게 되었습니다.\n\n재미있는 과제를 이론과 함께 한단계 씩 배워나갈 수 있도록 강의를 구성했습니다. 과정을 마치고나면 다양한 Computer Vision 딥러닝 프로젝트와 사업을 꿈꾸게 될 것입니다. 저 역시 현재 진행하는 프로젝트 준비에 도움이 많이 됐습니다.\n\n이 과정을 만들면서 과정에 담지못했던 '출입자 숫자세기', '차량 숫자 및 속도 세기', '얼굴보고 나이와 성별 식별', '영수증,명함인식' 등 다양한 내용을 발전 시켜서 향후 '머신러닝, 딥러닝 Computer Vision 종합과정', '모바일 딥러닝 Computer Vision 실전 프로젝트'와 '로봇IoT 딥러닝 실전 프로젝트' 등 후속과정을 꿈꾸게 되었습니다.\n\n\n프로젝트 소개\n\n\n직접 쓴 손글씨를 인식하는 프로젝트로 Computer Vision과 딥러닝의 기본을 다집니다. 프로젝트를 라즈베리파이 IoT장치로 옮기면서 다양한 사물인터넷 기술을 실습합니다. 주차장 카메라로 주차된 차량 숫자를 세고 클라우드 서버에 실시간으로 알려줍니다. 자동차 번호판의 글자와 숫자를 최신 문자인식(Text Recognition)기술로 인식해 보세요. 실시간 카메라로 졸고있는지 확인하고 졸고 있으면 경고음으로 깨워주세요. 라즈베리파이 감시카메라를 설치해서 등록된 사용자 얼굴을 인식하고 출입내용을 서버와 드롭박스 또는 메일로 확인합니다.\n\n\n\n\n라즈베리파이와 웹 카메라 그리고 OpenCV를 이용해서 직접 쓴 숫자를 인식하는 기능을 딥러닝 기술을 이용해서 구현해 봅시다.\n\n\n\n딥러닝으로 다양한 사물(Object Recognition)을 찾을 수 있습니다. YOLO와 그 친구들이 이미지에서 주차된 차량 숫자를 세어줍니다. 숫자를 세고나서 실시간으로 클라우드 서버에 저장하세요.\n\n\n\n\n최신 ComputerVison 기술이 이미지와 영상 속에서 문자와 숫자를 인식(Text Recognition)합니다. 카메라로 차량의 번호판을 인식하는 재미있는 프로젝트를 해봅시다.\n\n\n\n\n이제 이미지와 영상에서 얼굴과 눈을 식별(Face, eye Detection)해 볼까요? 그리고 딥러닝으로 동작을 확인합니다.실시간 동영상으로 졸고있는지 확인하고 졸고있으면 경고음으로 깨워줍니다.\n\n\n\n\n\n얼굴만 인식(Face Recognition)하는 것이 아니고 동작을 확인해서 출입감시 시스템을 만들 수 있어요.\n등록된 사람이 출입하면 서버, 드롭박스, 메일로 알려주세요. 등록되지 않은 사람이 오면 경고음을 울려줘요.\n\n\n특별강의\n1. 'Model 정확도 99%이상 높이기'라는 특별강의도 드립니다. 이 강의는 '[라즈베리파이] IoT 딥러닝 Computer Vision 실전 프로젝트'과정 수강생 분들이 MNIST 손글씨 모델이 아래 사진처럼 '7을 왜 7이라 하지 못하나요?'라는 질문에서 시작되었습니다. 물론 모델의 정확도 뿐 아니라 프로그램 예외처리, MNIST원시데이터 등 다양한 요인이 있지만 기존 Nueral Network 모델이 학습용으로 단순해서 이걸 99.38%까지 정확도를 높이기 위해 Nueral Network 모델을 다시 구성하는 내용을 만들어 봤어요.\n\n\n2. 텐서플로 Keras로도 원하는 모델을 만들 수 있는 방법을 특별강의로 알려드립니다. YOLO 학습에 사용했던 이미지를 그대로 사용해서 Keras로 학습해서 모델을 만들고 물체를 식별하는 내용입니다. YOLO와 Keras를 학습하는 내용도 배우고 서로 비교할 수도 있겠지요?\n\n\n\n\n\n\n어떤 툴을 사용하나요?\n이 강의에서 다루는 툴은 어떤 것들이 있을까요? 이 강의는 대표적인 ComputerVision 소프트웨어 라이브러리인 OpenCV와 파이썬, 텐서플로를 기반으로 합니다.\n그리고 사물인터넷 IoT의 대표격인 라즈베리파이를 사용합니다. 이 외에도 몇가지 유용한 소프트웨어를 설치하는데 강의 속에서 하나씩 설명드립니다.\n\n\n\n\n\n\n강의에 필요한 준비물\n1. 라즈베리파이 보드(B+ 추천), PiCamera\n\n추가 강의\n다양한 이미지, 영상처리 기법과 모듈을 활용하여 재미있고 활용도 높은 프로젝트를 만들어 보세요.\n라즈베리파이 관련 내용과 파이어베이스 관련 강의를 특강형식으로 제공합니다.\n\n\n- 궁금해요!\nQ. 이 강의는 어떤 특징을 가지고 있나요?\nA. 딥러닝, 머신러닝을 실전에서 활용하는 방법을 고민했습니다.\n\n이 과정은 대표적인 분야인 Computer Vision관련된 이론 설명 뿐 아니라 실전 프로젝트를 통해서 딥러닝을 배우게 됩니다.특히, 라즈베리파이를 사용하여 현장에서 적용할 수 있는 실전 프로젝트를 만들어서 향후에 활용하시도록 돕고 있습니다.\nQ. 비전공자도 들을 수 있나요?\nA. 딥러닝이나 데이터 과학은 꼭 전산을 전공한 분만 할 수 있는 분야가 아닙니다.여러분의 열정만 있다면 충분히 배우고 활용할 수 있는 내용입니다.",
      "target_audience": [
        "딥러닝을 실전에서 활용하고 싶은 분",
        "사물인터넷IoT 장치에서 딥러닝을 구현하고 싶은 분",
        "딥러닝을 이용한 영상처리에 대해 배우고 싶은 분",
        "Computer Vision과 관련한 프로젝트를 준비하는 분",
        "딥러닝 영상처리 최신 기법을 배우고자 하는 분",
        "Computer Vision 프로젝트에 활용할 예제 코드를 원하는 분"
      ]
    },
    {
      "title": "【한글자막】 Python 을 사용한 데이터 시각화",
      "url": "https://www.udemy.com/course/best-python-data-visualization/",
      "bio": "Matplotlib, Seaborn, Plotly의 강력한 기능을 활용하여 데이터 시각화 기술을 향상시키십시오!",
      "objectives": [
        "데이터 시각화를 위한 가장 중요한 구성 요소를 이해",
        "Python 라이브러리를 사용하여 다양한 유형의 그래프를 작성",
        "Flotly, Matplotlib 및 Seaborn 사용 방법을 학습",
        "새로운 통찰력을 얻고 데이터 또는 결과를 명확하게 설명하는 데 도움이 되는 도구를 구축",
        "대화형 시각화를 생성"
      ],
      "course_content": {},
      "requirements": [
        "기초 수준의 Python 지식이 권장됩니다."
      ],
      "description": "Python 을 사용한 데이터 시각화!\nMatplotlib, seaborn, Plotly 등 데이터 시각화 도구 학습!\n결과를 명확하게 표현해보세요!\n\n\nPython 을 사용한 데이터 시각화 강의를 선택해야 하는 이유\n분석 목적이든 AI/ML/DS 또는 관련 도메인에서의 모델 구축이든 데이터를 이해하는 것이 성공의 핵심입니다. 또한 팀, 관리자, 이해 관계자 등에게 결과를 명확하게 설명하는 데 도움이 되는 매혹적인 시각화를 구성할 수 있다는 것은 DS 세계에 필요한 가치있는 기술입니다.\n\n\n그리고 데이터를 제시하는 것이 새로운 주요 과제가 된 세상에서 데이터 시각화(Data Visualization) 도구는 Data Science Toolkit의 필수품입니다. 가장 널리 사용되는 시각화 라이브러리에 시각화를 구축함으로써 더 깊은 이해도를 얻고 매혹적인 프레젠테이션을 만들 수 있습니다.\n\n\nPython을 사용한 Hands-on 데이터 시각화 기능은 Matplotlib, Seaborn, Plotly를 활용한 작업의 핵심 개념과 구조를 제시하여 데이터에서 통찰력을 이끌어내는 능력으로 가장 까다로운 관리자에게도 깊은 인상을 심어줄 수 있도록 지원합니다.\n\n\n이 과정을 마치면 다양한 유형의 그래프를 구성하고 실질적인 문제를 해결한 뒤 데이터 시각화의 가장 중요한 구성 요소를 이해할 수 있을 것입니다. 이를 통해 경력에서 두각을 나타내고, 새로운 통찰력을 얻고, 데이터 또는 결과를 명확하게 설명하고, 대화형 시각화 및 애니메이션을 만드는 데 도움이 되는 도구를 구축할 수 있습니다.\n\n\n그리고 그것으로 충분하지 않다면, 그동안 여러분은 가장 많이 사용되는 시각화 라이브러리를 더 학습하고 파이썬 프로그래밍을 연습할 수 있을 것입니다.\n\n\nPython 을 사용한 데이터 시각화 강의는 아래와 같이 진행 됩니다\n데이터 시각화를 위한 가장 중요한 구성 요소를 이해\nPython 라이브러리를 사용하여 다양한 유형의 그래프를 작성\nFlotly, Matplotlib 및 Seaborn 사용 방법을 학습\n새로운 통찰력을 얻고 데이터 또는 결과를 명확하게 설명하는 데 도움이 되는 도구를 구축\n대화형 시각화를 생성\n\n\nLigency Team의 한마디!\n한국 수강생 여러분 안녕하세요?\n\"【글로벌 Best】 Python 을 사용한 데이터 시각화 \" 강의에 오신 것을 환영합니다!\n\n\nP.S 강의를 들으시고 강의와 관련하여 궁금하신 점은 무엇이든 Q&A에 남기실 수 있지만, 꼭 영어로 남겨주세요. 그래야 답변을 드릴 수 있습니다. :)\n\n\n이제 경력을 한 단계 더 끌어올릴 준비가 되셨습니까? 지금 등록하십시오!\n\n\n강의에서 만나요,\n- Ligency Team",
      "target_audience": [
        "자신의 기술을 한 단계 끌어올리고자 하는 데이터 과학자",
        "새로운 정보 소스 또는 데이터 집합을 통합하고자 하는 ML/AI 엔지니어",
        "결과를 제시하는 방법을 이해하고자 하는 데이터 분석가",
        "기술 수준을 높이고 대화형 그래프를 만들고자 하는 BI 전문가",
        "프로그래밍이나 컴퓨터 과학에 관심 있는 사람",
        "스킬셋을 확장하려는 소프트웨어 엔지니어 또는 프로그래머"
      ]
    },
    {
      "title": "【YOLOv8】ディープラーニングによる初めての物体検出（Python/Keras/Colab）",
      "url": "https://www.udemy.com/course/python_yolov8/",
      "bio": "最新のAI開発パッケージYOLOv8を用いて物体検出に挑戦しましょう！物体検出の基礎からGoogle Colabotatory上でKerasを用いた演習まで、物体検出の第一歩を実践形式で学びます。",
      "objectives": [
        "物体検出の考え方",
        "ディープラーニングの基礎",
        "YOLOv8による物体検出",
        "学習済みモデル（YOLOv8）を使用した再学習",
        "Python/Google Colaboratoryによる物体検出の実践"
      ],
      "course_content": {
        "コース紹介": [
          "本コースの紹介",
          "コース準備レクチャー"
        ],
        "ディープラーニングの基礎（参考）": [
          "ニューラルネットワーク",
          "目的関数",
          "シグモイド関数・ソフトマックス関数",
          "勾配降下法",
          "確率的勾配降下法",
          "ミニバッチ学習",
          "Epoch/Iteration",
          "誤差逆伝播",
          "勾配消失",
          "畳み込みニューラルネットワーク（CNN）",
          "畳み込みとプーリング",
          "学習済みモデル"
        ],
        "物体検出の仕組み": [
          "物体検出とは",
          "YOLOとは",
          "YOLOv1",
          "IOU",
          "YOLOv1では難しいこと",
          "特徴量ピラミッドネットワーク",
          "Focal Loss",
          "非最大値抑制",
          "YOLOの歴史",
          "YOLOv8のモデル"
        ],
        "YOLOv8を使った物体検出の演習①": [
          "演習内容",
          "YOLOv8のフォルダ構成",
          "演習で使う資料のダウンロード",
          "Google DriveとColaboratoryの準備",
          "物体検出のデモ",
          "セグメンテーションのデモ"
        ],
        "YOLOv8を使った物体検出の演習②": [
          "データの準備",
          "物体検出モデルの学習",
          "結果の評価",
          "推論の実行",
          "モデルのエクスポート"
        ],
        "YOLOv8を使った物体検出の演習③": [
          "データの準備",
          "物体検出モデルの学習",
          "推論の実行"
        ],
        "ボーナス": [
          "ボーナス"
        ]
      },
      "requirements": [
        "Pythonコーディングの基礎",
        "機械学習の知識があれば尚可（なくても大丈夫です！）"
      ],
      "description": "【YOLOv8】ディープラーニングによる初めての物体検出（Python/Keras/Colab）\nこのコースでは、ディープラーニングを使用した初めての物体検出の学習コースとなっております。\nPython、Keras、Google Colaboratoryを活用し、AI開発パッケージであるYOLOv8を使用した物体検出のスキルを身につけましょう！\n\n\nコース内容\n1. コース紹介\n2. ディープラーニングの基礎\n3. 物体検出の仕組み\n物体検出の基本原理\n一般的な物体検出の手法の比較\nYOLOの概要\n4. YOLOv8を用いた演習\nYOLOv8による物体検出のデモ①\nマスクの物体検出演習②\n実行環境の準備\n学習データの収集と前処理\nYOLOv8の学習と評価\n推論の実施\nメガネの物体検出演習③\n学習データの収集と前処理\nYOLOv8の学習と評価\n推論の実施\n物体検出と言うと少しハードルが高いように思われるかもしれませんが、実際にやってみるとある程度までは意外とできるものです。\nこの機会にぜひチャレンジしてみてください！\n\n\n2024年3月追記）\n2024年2月にYOLOv9がリリースされましたので、YOLOv8は最新のYOLOシリーズのモデルではなくなっております。\nもちろんまだまだYOLOv8は使用できますが、最新ではないということ、ご認識ください！",
      "target_audience": [
        "物体検出に興味があるPython初学者",
        "データサイエンスでできることを増やしたいデータサイエンティストやデータアナリスト",
        "業務で物体検出をやる必要が出てきた担当者"
      ]
    },
    {
      "title": "Machine Learning con R desde Básico hasta Avanzado",
      "url": "https://www.udemy.com/course/machine-learning-con-r-desde-basico-a-avanzado/",
      "bio": "Curso completo de Machine Learning: Data Science con R",
      "objectives": [
        "Técnicas de machine learning",
        "conocer algoritmos de Inteligencia Artificial",
        "Ser un master en la ciencia de datos",
        "diferenciar el Aprendizaje supervisado y no supervisado",
        "Elaborar modelos robustos de Machine Learning",
        "Utilizar las técnicas de Machine Learning para uso personal y para asesorar empresas",
        "Conocer como funcionan las redes neuronales",
        "Saber qué modelo de Machine Learning usar para cada tipo de problema."
      ],
      "course_content": {},
      "requirements": [
        "conocimientos basicos de R",
        "conocimientos básicos de Estadística"
      ],
      "description": "Las técnicas de Machine Learning e Inteligencia Artificial están creando toda una nueva generación de soluciones para las operaciones y toma de desiciones en todas las organizaciones e industrias ya que permiten no sólo un mejor entendimiento sino también la automatización de todo tipo de procesos complejos.\nEn éste curso te vas a entrenar a fondo a través de casos y teoría en todas las capas de trabajo que hacen al desarrollo de modelos de Machine Learning para tareas de descripción, automatización y predicción, practicando desde el trabajo exploratorio con la programación R (el lenguaje de análisis estadístico más robusto entre las comundiades científicas), la transformación, limpieza y normalización de datos, la implementación de las principales técnicas de modelado según los distintos problemas, la evaluación de performance de los modelos, las técnicas de calibración y ajuste, llegando hasta la implementación y comunicación de los resultados en mensajes claros y comprensibles.\nAl finalizar el curso usted sera capaz de:\nIdentificar adecuadamente los modelos a utilizar para responder a preguntas de negocio.\nDiferenciar los métodos y técnicas a su disposición para modelar problemas de negocio.\nIdentificar los supuestos necesarios para poder aplicar un modelo específico en una situación concreta de negocio.\nConstruir y desarrollar los modelos a partir de un conjunto de datos particular.\nSeleccionar el mejor modelo a aplicar en cada caso.",
      "target_audience": [
        "interesados en la ciencia de datos",
        "interesados en tecnicas de machine learning, deep learning"
      ]
    },
    {
      "title": "【YOLOとSSDを使った】実践物体検出",
      "url": "https://www.udemy.com/course/yolossd-a/",
      "bio": "ディープラーニングや機械学習の入門講座を終えた中級者がYOLOとSSDを使って物体検出を学び、ビジネスに使う実践力を身につけます",
      "objectives": [
        "物体検出モデルの中身を理解する",
        "物体検出モデルを再学習させる",
        "物体検出モデルを実際のビジネスに使う"
      ],
      "course_content": {},
      "requirements": [
        "シェルの簡単な操作ができる",
        "ディープラーニングの初歩的な理解がある"
      ],
      "description": "業界で有名な３講師による実践的なディープラーニング講座です。多くのタスクにおいて必要となる物体検出をていねいに解説します。\n本や入門講座などでディープラーニングを学んだもののそこから一歩進めない方に、次のステップをレクチャーします。\n自分で学習データを作成し、それを用いた学習ができるようになるので、自分のビジネスへ活用が可能です。\n理論面は図を用いて詳しく解説します。コーディングではTensorflowやChainerを用いますが、実際にコーディングしているところを見せながら詳しく解説します。\nシェルの簡単な操作とディープラーニングの初歩的な理解を前提としています。",
      "target_audience": [
        "SSD・YOLOを動かしたい人、動かしたことのある人",
        "tensorflow, keras, chainer動かした人、御自身で学ぶことができる方",
        "物体検出モデルを独自のデータセットで学習したい人",
        "より実用的なAIのモデルを作ってビジネスに応用したい人"
      ]
    },
    {
      "title": "Pelatihan Data Science dan Machine Learning Dengan Python",
      "url": "https://www.udemy.com/course/pythondsml/",
      "bio": "Update 2025 | Tingkatkan kemampuan data analitik melalui data science dan machine learning dengan Python",
      "objectives": [
        "Mempelajari pengolahan data dan analisa data",
        "Visualisasi data",
        "Topik Khusus Visualisasi Data Time Series",
        "Dataset, Pra-Proses dan Pengurangan Dimensi Feature (Dimensionality Reduction)",
        "Ekplorasi beberapa algoritma pada data science dan machine learning",
        "Pratikum studi kasus data science dan machine learning",
        "Hyperparameter Tuning Untuk Model Machine Learning",
        "Ensemble Methods",
        "Reinforcement Learning",
        "Automated Machine Learning (AutoML)"
      ],
      "course_content": {
        "Pendahuluan": [
          "Latar belakang, Tujuan dan Konten Pelatihan",
          "Persiapan",
          "Cara Menggunakan Notebook"
        ],
        "Belajar Singkat Pemrograman Python Untuk Data Science dan Machine Learning": [
          "Pendahuluan",
          "Kode Program - Pemrograman Python",
          "Deklarasi Variabel",
          "Memberikan Komentar Pada Kode Program",
          "Print - Menampilkan Data ke Terminal",
          "Operator",
          "Kondisional",
          "Pengulangan (Looping)",
          "break dan continue",
          "Fungsi",
          "Array",
          "Class",
          "Inheritance"
        ],
        "Python Virtual Environment": [
          "Kode Program",
          "Mengenal Python Virtual Environment / Sandbox",
          "Membuat Python Virtual Environment",
          "Menjalankan Kode Program di Pelatihan Ini dengan Python Environment"
        ],
        "Pengolahan dan Analisa Data - Numpy dan Pandas": [
          "Pendahuluan",
          "Kode Program - Numpy dan Pandas",
          "Kode Program - Numpy",
          "Numpy: Pendahuluan",
          "Numpy: Array - bagian 1",
          "Numpy: Array - bagian 2",
          "Numpy: Tipe Data",
          "Numpy: Array Indexing - Bagian 1",
          "Numpy: Array Indexing - Bagian 2",
          "Numpy: Indexing Lanjut",
          "Numpy: Operasi Matematika Pada Array",
          "Numpy: Broadcasting",
          "Numpy: I/O File",
          "Kode Program - Pandas 2.x (Updated December 2023)",
          "Kode Program - Pandas",
          "Pandas: Pendahuluan",
          "Pandas: Series",
          "Pandas: DataFrame",
          "Pandas: Baca dan Tulis Data dari File (Dataset)",
          "Pandas: Dasar Statistik pada DataFrame",
          "Pandas: Menampilkan Data",
          "Pandas: Mengambil Data Berdasarkan Pilihan Label",
          "Pandas: Boolean Indexing",
          "Pandas: Dasar Operasi pada Pandas",
          "Pandas: Menangani Data yang Hilang (Missing Data)",
          "Pandas: Penerapan apply() dan map() pada Element, kolom atau DataFrame",
          "Pandas: Menggabungkan Data",
          "Pandas: Menggabungkan Data dengan Bentuk SQL Query",
          "Pandas: Grouping",
          "Pandas: Pivot Tables"
        ],
        "Topik Khusus - Numpy dan Pandas - Database": [
          "Python dan Sqlite",
          "Kode Program - Numpy Pandas dengan SQLite",
          "Sqlite Driver",
          "Membuat Database Sqlite",
          "Membuat Tabel",
          "Memasukkan Data",
          "Membaca Data",
          "Memperbarui Data",
          "Menghapus Data",
          "Database Sqlite dan Pandas Dataframe",
          "Menghapus Tabel dan Tutup Koneksi Database"
        ],
        "Visualisasi Data": [
          "Pandahuluan",
          "Kode Program - Visualisasi Data",
          "Pendahuluan - Matplotlib",
          "Matplotlib: Cara Akses",
          "Matplotlib: Menggunakan fungsi global",
          "Matplotlib: Kustomisasi label axis",
          "Matplotlib: Sebuah Sumbu atau Subplot (subclass dari Sumbu)",
          "Matplotlib: Line Plots",
          "Matplotlib: Bar Plots",
          "Matplotlib: Stacked bar",
          "Matplotlib: Pie Chart",
          "Matplotlib: Plotting – defaults",
          "Pendahuluan - Seaborn",
          "Matplotlib vs Seaborn",
          "Seaborn: Seaborn Color Palette",
          "Seaborn: Fungsi replot",
          "Seaborn: Histogram",
          "Seaborn: Bar Plot",
          "Seaborn: Count Plot",
          "Seaborn: Point Plot",
          "Seaborn: Joint Plot",
          "Seaborn: KDE Plot",
          "Seaborn: Heatmap",
          "Seaborn: Pair Plot",
          "Seaborn: Ukuran Gambar dan Subplot"
        ],
        "Topik Khusus Visualisasi Data Time Series": [
          "Tanggal dan Jam",
          "Kode Program - Visualisasi Data Time Series",
          "Timezone",
          "Studi Kasus: Menampilkan Harga Emas per Periode"
        ],
        "Visualisasi Data Dengan Bokeh": [
          "Pendahuluan",
          "Kode Program - Bokeh",
          "Apakah Itu Bokeh dan Cara Instalasinya",
          "Membuat Grafik Sederhana",
          "Bekerja dengan ColumnDataSource",
          "ColumnDataSource vs DataFrame",
          "Bekerja dengan Dataset dari File seperti CSV",
          "Data dari SQL Query",
          "Kustomisasi Label Axis",
          "Kustomisasi Background (Theme)",
          "Kustomisasi Grid Lines",
          "Kustomisasi Judul (Title)",
          "Kustomisasi Legend",
          "Kustomisasi Tooltips",
          "Tema (Themes) di Bokeh",
          "Kustomisasi Ukuran Window di Jupyter Notebook",
          "Subplot Vertikal dan Horizontal",
          "Bekerja dengan Line Plots",
          "Bekerja dengan Bar Plots",
          "Bekerja dengan Stacked Bar",
          "Bekerja dengan Pie Chart",
          "Mengembalikan ke Plotting – defaults"
        ],
        "Dataset, Pra-Proses dan Pengurangan Dimensi Feature (Dimensionality Reduction)": [
          "Pendahuluan",
          "Kode Program",
          "Dataset: Data Primer dan Data Sekunder",
          "Pemilihan Data Training dan Data Testing : Acak",
          "Pemilihan Data Training dan Data Testing : K-Fold Cross Validation",
          "Pemilihan Data Training dan Data Testing : LOOCV",
          "Standarisasi Data (Scaling)",
          "Dimensionality Reduction: Principal Component Analysis (PCA)",
          "Dimensionality Reduction: Incremental PCA"
        ],
        "Permasalahan dan Penyelesaian Kasus Linear Regression": [
          "Pendahuluan",
          "Kode Program - Linear Regression",
          "Apa itu Linear Regression? Kapan Menggunakan Solusi Linear Regression?",
          "Evaluasi Model Linear Regression",
          "Linear Regression Dengan Python",
          "Statsmodels: Ordinary Least Squares (OLS)",
          "Statsmodels: Weighted Least Squares (WLS)",
          "Scikit-Learn: Ordinary Least Squares (OLS)",
          "Scikit-Learn: Bayesian Regression",
          "Scikit-Learn: Support Vector Machine (SVM) Regression",
          "Scikit-Learn: Stochastic Gradient Descent (SGD) Regression",
          "Scikit-Learn: Nearest Neighbors Regression",
          "Scikit-Learn: Ridge Regression",
          "Scikit-Learn: Decision Trees Regression",
          "Bonus: Regresi Linier dengan Seaborn",
          "Menyimpan dan Membaca Hasil Model Regresi Linier"
        ]
      },
      "requirements": [
        "Komputer dengan sistem operasi Windows, macOS atau Linux",
        "Akses internet",
        "Sudah menguasai bahasa Python (Optional)",
        "Sudah menguasai dasar Statistik (Direkomendasikan)"
      ],
      "description": "Selamat datang di program pelatihan data science dan machine learning dengan Python!\nPelatihan ini diperuntukan untuk rekan - rekan ingin belajar data science dan machine learning dari sudut terapan dengan memanfaatkan Python.\nBagi rekan - rekan yang belum menguasai pemrograman Python, pelatihan juga memberikan konten pemrograman dasar untuk  Python sehingga rekan - rekan dapat mengikuti pelatihan ini dengan baik. Bagi yang sudah bisa pemrograman Python, rekan - rekan dapat melanjutkan di topik berikutnya.\nSeluruh konten didalam pelatihan ini dilaksanan secara step - by - step (langkah demi langkah) dan berurutan sehingga ini diharapkan semua peserta dapat dengan mudah mengikuti semua praktikum yang diberikan didalam pelatihan ini. Diharapkan semua peserta dapat mengikuti konten pelatihan ini secara berurutan ;).\nBerikut ini konten yang akan diberikan pada pelatihan ini.\nPersiapan pelatihan\nPemrograman Python\nPython Virtual Environment\nPengolahan dan Analisa Data - Numpy dan Pandas\nTopik Khusus - Numpy dan Pandas - Database\nVisualisasi Data dengan memanfaatkan library Matplotlib, Seaborn dan Bokeh\nTopik Khusus Visualisasi Data Time Series\nDataset, Pra-Proses dan Pengurangan Dimensi Feature (Dimensionality Reduction)\nPermasalahan dan Penyelesaian Kasus Linear Regression\nPermasalahan dan Penyelesaian Kasus Klasifikasi (Classification)\nPermasalahan dan Penyelesaian Kasus Kekelompokkan (Clustering)\nHyperparameter Tuning Untuk Model Machine Learning\nEnsemble Methods\nReinforcement Learning\nAutomated Machine Learning (AutoML)\nKumpulan Studi Kasus\n\n\nJika ada hal - hal yang ingin ditanyakan mengenai topik diatas, rekan - rekan dapat langsung ditulisnya di ruang diskusi pada web ini sehingga rekan-rekan lainnya dapat mengetahui dan ikut terlibat diskusinya.\n\n\nUpdate\n25 Mei 2025\nPenambahan konten baru\n* Python Virtual Environment\n* Pengembangan dan Deployment Proyek Machine Learning\n* Penambahan studi kasus baru\nMelakukan cek semua codes agar berjalan semua.\n30 November 2024:\nPembaruan kode program karena versi runtime. Runtime versi yang diuji adalah:\n* Python 3.12.7\n* Numpy 2.1.3\n* Pandas 2.2.3\n* Seaborn 0.13.2\n* Matplotlib 3.9.2\n* Scikit-learn 1.5.2\n\n\nBerikut pembaruan kode program\n* Classification_binary_demo_v3.ipynb\n* Classification_multiclass_demo_v2.ipynb\n* Classification_multilabel_demo_v2.ipynb\n* Data Processing - NumPy-Versi2.ipynb\n* seaborn-v2.ipynb\n* visual-time-series-v2.ipynb\n* Linear Regression -Sklearn-v2.ipynb\n* SimpanBaca-Regression-v2.ipynb\n* Hyperparameter-v2.ipynb\n* ensemble-v2.ipynb\n20 September 2024: Penambahan konten Reinforcement Learning, Automated Machine Learning (AutoML) dan studi kasus.\n16 September 2024: Penambahan konten untuk visualisasi data dengan Bokeh",
      "target_audience": [
        "Pelajar dan mahasiswa yang ingin mempelajari data science dan machine learning",
        "Professional yang ingin mempelajari data science dan machine learning",
        "Pengajar dan peneliti yang ingin mempelajari data science dan machine learning"
      ]
    },
    {
      "title": "Парсинг сайтов PYTHON",
      "url": "https://www.udemy.com/course/python-parsing/",
      "bio": "Продвинутый парсинг сайтов на Python используя HTTP запросы и другие модули",
      "objectives": [
        "Парсить простые и сложные сайты и имитировать действия пользователей в браузере. Более подробно в описании курса"
      ],
      "course_content": {
        "Тизер": [
          "О курсе"
        ],
        "Изучение основных инструментов": [
          "Введение в requests. Установка модулей и написания первых программ",
          "Изучаем bs4 и структуру запросов. Подделываем юзер-агент и другие заголовки",
          "Авторизация на сайте. Изучаем сессии, извлекаем и импортируем куки в запрос",
          "Парсинг всего сайта и скачивание файлов внутри него",
          "Используем прокси и изучаем мультипроцессинг для ускоренного парсинга",
          "Безопасное скачивание файлов используя пакеты",
          "HTTP Adapter, повторные запросы в случае неудачи",
          "Пишем мониторинг цены биткоина в реальном времени",
          "Бонусная лекция. Заключение"
        ]
      },
      "requirements": [
        "Минимальные знания языка Python"
      ],
      "description": "Мы научимся:\n- работать с requests\n- извлекать нужные данные с страницы\n- рассмотрим GET, POST запросы\n- рассмотрим headers, data аргументы\n- научимся создавать сессию для сохранения кукисов\n- научимся имитировать действия пользователей\n- научимся авторизовываться на сайтах, скачивать и отправлять файлы\n- изучим архитектуру клиент/сервер\n- рассмотрим принцип работы http протокола\n- научимся парсить все страницы сайта\n- научимся находить нужные нам значения на сайте\n- рассмотрим многопроцессорные программы, для ускорения работы софта\n- научимся заменять user-agent и имитировать другое устройство и браузер\n- рассмотрим все основы bs4\n- безопасное скачивание файлов используя пакеты\n- HTTP Adapter, повторные запросы в случае неудачи\n- пишем мониторинг цены биткоина в реальном времени\n\nКакие задания мы выполним?\n- напишем программу для извлечения IP пользователя\n- напишем программу для скачивания файлов с сайта\n- научимся обходить все страницы сайта и подменять user-agent\n- напишем программу с использованием multiprocessing\n- напишем программу с использованием bs4\n\nПочему именно этот курс?\n- материал направлен на любой уровень знаний Python (подойдет новичку и профессионалу)\n- курс не содержит воды и предоставляет только нужную информацию\n- после данного курса вы сможете полноценно работать с изученными библиотеками\n- простая подача материала\n- содержит реальные примеры и задачи\n- актуальная информация\n- рассматриваем все перечисленные библиотеки в одном курсе за минимальную стоимость\n\nВы научитесь работать с HTTP запросами и выполнять автоматизацию сайтов посредством этих запросов.\nПосле прохождения данного курса вы сможете разрабатывать парсеры, авторегеры, различных ботов для автоматизации действий в браузере и имитировать все действия, которые может совершить человек используя браузер и определенные сайты.\nУслуги парсинга и автоматизации веб-ресурсов очень часто встречаются на фрилансе, поэтому окупить данные знания можно практически сразу после прохождения курса.",
      "target_audience": [
        "Начинающие Python разработчики, желающие научиться использовать парсинг сайтов в своей работе"
      ]
    },
    {
      "title": "Python per l'apprendimento profondo: Costruire reti neurali",
      "url": "https://www.udemy.com/course/python-per-lapprendimento-profondo-costruire-reti-neurali/",
      "bio": "Corso completo sul Deep Learning per padroneggiare scienza dei dati, Tensorflow, intelligenza artificiale e reti neurali",
      "objectives": [
        "Imparare i fondamenti della teoria del Deep Learning",
        "Imparare a usare il Deep Learning in Python",
        "Imparare a utilizzare diversi framework in Python per risolvere problemi del mondo reale utilizzando l'apprendimento profondo e l'intelligenza artificiale",
        "Fare previsioni usando la regressione lineare, la regressione polinomiale e la regressione multivariata",
        "Costruire reti neurali artificiali con Tensorflow e Keras"
      ],
      "course_content": {},
      "requirements": [
        "Esperienza con le basi della codifica in Python",
        "Competenze matematiche di base",
        "Disponibilità, flessibilità e passione per l'apprendimento"
      ],
      "description": "Python è famoso come uno dei migliori linguaggi di programmazione per la sua flessibilità. Funziona in quasi tutti i campi, dallo sviluppo web allo sviluppo di applicazioni finanziarie. Tuttavia, non è un segreto che la migliore applicazione di Python sia l'apprendimento profondo e l'intelligenza artificiale.\nSebbene Python renda facile l'apprendimento profondo, sarà comunque piuttosto frustrante per chi non sa come funziona l'apprendimento automatico.\nSe conoscete le basi di Python e siete appassionati di deep learning, questo corso è pensato per voi. Questo corso vi aiuterà a imparare a creare programmi che prendono in input i dati e automatizzano l'estrazione delle caratteristiche, semplificando le attività del mondo reale per gli esseri umani.\nSu Internet sono disponibili centinaia di risorse per l'apprendimento automatico. Tuttavia, se non si filtra ciò che si impara, si rischia di apprendere lezioni inutili. Nel creare questo corso, ci siamo aiutati a filtrare per isolare le nozioni di base essenziali di cui avrete bisogno nel vostro percorso di deep learning.\nSi tratta di un corso di base che è ideale sia per i principianti che per gli esperti. Se siete alla ricerca di un corso che parta dalle basi per arrivare agli argomenti avanzati, questo è il corso migliore per voi.\nInsegna solo ciò che è necessario per iniziare a studiare l'apprendimento profondo, senza inutili fronzoli. Sebbene ciò contribuisca a mantenere il corso piuttosto conciso, si tratta di tutto ciò di cui si ha bisogno per iniziare l'argomento.",
      "target_audience": [
        "Programmatori che desiderano aggiungere il deep learning alle loro competenze",
        "Matematici professionisti che vogliono imparare ad analizzare i dati in modo programmatico",
        "Tutti gli appassionati di programmazione Python che desiderano aggiungere al proprio portafoglio competenze in materia di deep learning"
      ]
    },
    {
      "title": "Python数据科学必备工具包",
      "url": "https://www.udemy.com/course/python-tangyudi/",
      "bio": "Python工具包实战",
      "objectives": [
        "科学计算库-Numpy",
        "数据分析处理库-Pandas",
        "可视化库-Matplotlib",
        "可视化库-Seaborn",
        "熟练使用Numpy进行数值计算",
        "熟练使用Numpy完成数据基本变换",
        "熟练使用Numpy进行矩阵操作",
        "熟练使用Pandas进行数据预处理",
        "熟练使用Pandas进行数据分析",
        "熟练使用Pandas进行统计分析",
        "熟练使用Pandas完成数据读取与清洗",
        "熟练使用Pandas处理数据类型与计算",
        "熟练使用Matplotlib进行图表可视化展示",
        "熟练使用Matplotlib绘制各种统计图表",
        "熟练使用Seaborn快速建立统计分析图表",
        "熟练应用Python工具包在数据分析与处理任务中"
      ],
      "course_content": {},
      "requirements": [
        "熟悉Python"
      ],
      "description": "Python现阶段简直太火啦，伴随着人工智能和数据领域的发展，已成必备武器，光用纯Python语言可不够，来看看咱们的兵器谱吧！Python数据科学库实战，4大主流库全程代码实战，纯干货！\n\n\n1.科学计算库-Numpy\n2.数据分析处理库-Pandas\n3.可视化库-Matplotlib\n4.可视化库-Seaborn",
      "target_audience": [
        "对数据科学领域感兴趣的同学们",
        "人工智能方向的同学们",
        "从事Python开发的同学们"
      ]
    },
    {
      "title": "Machine Learning Mastering Course in Arabic",
      "url": "https://www.udemy.com/course/machine-learning-mastering-course-in-arabic/",
      "bio": "الكورس الاحترافي في الذكاء الاصطناعي",
      "objectives": [
        "سوف تتعلم ما هو مجال الذكاء الاصطناعي و ما معني تعلم الالة",
        "سوف تتعلم انواع تعلم الالة",
        "سوف تتعلم المواضيع الرياضية اللازمة من الاحصاء و الجبر للبدء في مجال تعلم الالة",
        "سوف تتعلم المكتبات اللازمة الخاصة ب لغة البرمجة بايثون",
        "سوف تتعلم المعادلات الرياضية الخاصة ب كل خوارزمية + شرح بالتفصيل للخوارزمية",
        "سوف تتعلم كيف تنفذ الخوارزميات و المعادلات ب الكود ب لغة بايثون",
        "سوف نعمل علي الكثير من الامثلة و المشاريع",
        "سوف تصبح محترف في مجال تعلم الالة"
      ],
      "course_content": {},
      "requirements": [
        "تحتاج ان تكون علي علم ب اساسيات لغة البرمجة بايثون فقط"
      ],
      "description": "السلام عليكم ورحمه الله وبركاته ،\nاهلا بكم في الكورس الاحترفي لتعلم مجال تعليم الالة و هو احد اهم تخصصات مجال الذكاء الاصطناعي و هو التخصص الاكثر طلبا في سوق العمل و صاحب اكبر راتب في مجال البرمجيات و التكنولوجيا ،\nباذن الله في هذا الكورس سوف ابني لك اولا الاساسيات الرياضية التي تحتاجها للبداء في المجال و بالاخص في فرع الجبر و الاحصاء ،\nثم سوف ندخل في عالم المكتبات التي سوف نحتاج اليها في لغة البرمجة بايثون مثل :\n- مكتبة نمباي للعمليات الرياضية\n- مكتبة بانداس للتعامل مع البيانات و الجداول و الملفات\n- مكتبة ماتبلوتليب للرسوم و رسم الاشكال الاحصائية\n- مكتبة سيبورن للرسوم ايضا\nثم سوف ننتقل الي شرح خوارزميات تعلم الالة و معادلاتها الرياضية و التي سوف نشرح كل جزءًا فيها بالتفصيل و بطريقة سهلة ليس بها اي تعقيدات لكي تستطيع فهمها مهما كان مستواك في الرياضيات و بعد نهاية شرح كل خوارزمية بمعادلاتها سوف نطبق عليها بالكود و نعمل علي مشروع حتي نفهم كل التفاصيل و المراحل اثناء التطبيق و العمل و هذه هي المواضيع التي سوف نتطرق اليها :\n- خوارزميات التوقع\n- خوارزميات التصنيف\n- الشبكات العصبية\n- التقسيمات ( العناقيد )\n- تكنيكات و خوارزميات حديثة\nاتمني منكم ان تستفادوا من هذا الكورس و ان تستمتعوا بهذه الرحلة كما استمتع انا بشرح هذا الكورس و اتمني لكم التوفيق الدائم",
      "target_audience": [
        "اي شخص يريد ان يدخل الي مجال الذكاء الاصطناعي و يتعلم تخصص تعلم الالة و يصبح محترف في هذا المجال"
      ]
    },
    {
      "title": "Le Kit Ultime des Modèles d’IA : en Un Seul Cours (2025)",
      "url": "https://www.udemy.com/course/chatgpt-gagnez-en-efficacite-en-entreprise/",
      "bio": "+17h Optimisez la communication avec ChatGPT, DeepSeek; Qwen, Grok, Perplexity, Mistral...",
      "objectives": [
        "Utiliser les modèles IA avancés pour automatiser des tâches et optimiser la productivité.",
        "Créer des prompts efficaces avec des méthodes structurées comme ROCCO.",
        "Automatiser la prospection et le marketing avec ChatGPT, DeepSeek et Zapier.",
        "Exploiter l’IA pour la cybersécurité et l’analyse de données en profondeur.",
        "Utiliser ChatGPT pour répondre aux demandes des clients et rédiger des e-mails plus rapidement.",
        "Améliorer la qualité de leur communication écrite grâce à la précision et la pertinence des réponses fournies par ChatGPT.",
        "Optimiser leur stratégie marketing grâce à des messages plus percutants élaborés en collaboration avec ChatGPT.",
        "Réduire les coûts de production de contenus pour leur entreprise.",
        "Améliorer l'expérience client en offrant des réponses rapides et personnalisées grâce à ChatGPT.",
        "Optimiser leur stratégie de vente en utilisant ChatGPT pour fournir des réponses rapides et pertinentes aux clients potentiels."
      ],
      "course_content": {},
      "requirements": [
        "Un ordinateur avec une connexion internet.",
        "Une familiarité avec les outils informatiques de base."
      ],
      "description": "Vous voulez maîtriser l’intelligence artificielle et exploiter les meilleurs modèles IA pour booster votre productivité, automatiser vos tâches et transformer votre activité ? Ce cours est un guide incontournable pour dominer l’IA en 2025.\nPourquoi ce cours est unique ?\nUn pack complet : ChatGPT, DeepSeek, Perplexity, Mistral AI, Zapier, et bien plus encore.\nDu concret et de l’action : Des tutoriels détaillés, des exemples pratiques et des workshops interactifs.\nOptimisation et automatisation : Gestion des réseaux sociaux, prospection LinkedIn, création de contenus, sécurité informatique… tout est couvert.\nMéthodes avancées : Découvrez la méthode ROCCO, la Pyramide de Formulation et des prompts optimisés.\nAccès aux ressources premium : Liste de prompts ultime, guides PDF et exercices pratiques.\nÀ qui s’adresse ce cours ?\nEntrepreneurs, freelances, créateurs de contenu : Gagnez un temps fou grâce à l’IA.\nMarketeurs et commerciaux : Optimisez vos campagnes et votre prospection avec des stratégies IA avancées.\nÉtudiants et passionnés d’IA : Plongez dans un contenu structuré et complet, sans prérequis technique.\nBonus exclusifs\nListe de prompts IA pour des résultats optimisés.\nAccès à des modèles d’IA avancés comme HuggingFace et ChatGPT Sidebar.\nCertification officielle en fin de formation pour prouver vos compétences.\nRejoignez dès maintenant la révolution IA et prenez une longueur d’avance en 2025.\nNotez bien :\nLa formation se déroulera sous forme de cours théorique & pratique, d'exemples concrets et d'ateliers pour permettre aux participants de mettre en pratique les concepts appris. Des exercices, des mises en situation et des études de cas seront utilisés pour renforcer les connaissances.\n\n\nRessources d’apprentissage complémentaires :\nAtelier en ligne\nDocumentation\nConsultez des exemples de tableaux de bord, de rapports et de fichiers de bureau.\nEnfin, je m'engage à vous fournir la formation la plus complète possible sur Udemy pour vous permettre de réussir dans votre apprentissage.\nJe m'engage à répondre rapidement à vos questions pour vous aider à comprendre les concepts de la formation.\nJe vais ajouter des cas pratiques sur demande pour vous donner des exemples concrets de ce que vous apprenez.\nJe vais vous accompagner avec des cas pratiques et d'autres ressources utiles pour vous aider à mettre en pratique ce que vous apprenez.\nCes ajouts de vidéos seront, bien entendu, gratuits si vous avez acquis la formation.\nComment me contacter ? Je reste disponible dans la rubrique Question/Réponses d'Udemy pour répondre à vos questions.\nÀ la fin de ce cours, si vous le suivez en entier et réussissez l'ensemble des quizz : Obtenez votre certification électronique à insérer dans votre CV et profil LinkedIn.\n\nDr. Firas",
      "target_audience": [
        "Les professionnels travaillant dans les domaines du Marketing, RH, Service client et Vente.",
        "Les chefs d'entreprise désireux d'améliorer l'efficacité et la productivité de leur communication écrite en entreprise.",
        "Les personnes intéressées par l'IA et les technologies de traitement du langage naturel.",
        "Les personnes souhaitant en apprendre davantage sur l'utilisation de ChatGPT en entreprise."
      ]
    },
    {
      "title": "BigData e Machine learning di base con Python",
      "url": "https://www.udemy.com/course/bigdata-e-machine-learning-di-base-con-python/",
      "bio": "muovi i primi passi nella Big Data Analysis con Python",
      "objectives": [
        "Utilizzare Python per l'analisi dei dati",
        "Comprendere i fondamenti dei Big Data",
        "Implementare soluzioni per i Big Data con Python, Pandas, Hadoop e Spark",
        "Apprendere i rudimenti del machine learning"
      ],
      "course_content": {
        "Python in breve": [
          "Introduzione",
          "Python - strumenti \"standard\" per lo sviluppo",
          "L'interprete Python e un primo programma",
          "Test e condizioni",
          "Cicli in Python",
          "Liste, stringhe, tuple, dizionari e insiemi",
          "Funzioni",
          "errori",
          "moduli e librerie",
          "OOP in breve - Classi e oggetti"
        ],
        "Tecnologie di base": [
          "Jupyter Notebook",
          "Espressioni Regolari",
          "File di testo e binari",
          "File CSV",
          "File XML",
          "File JSON",
          "SQL di base con sqlite3",
          "Database e SQL con Python",
          "Statistiche e grafici",
          "Esercizio: da CSV a Database"
        ],
        "Librerie e tecniche per i Big Data": [
          "Primi passi con la libreria NumPy",
          "NumPy: filtraggio dei valori e arrotondamenti",
          "Funzioni statistiche con NumPy",
          "NumPy e utilizzo dei file",
          "Esercizio con NumPy",
          "Pandas - Introduzione",
          "Pandas: indici, filtri e ordinamenti",
          "Pandas - le Series",
          "Pandas - manipolazione dei dati",
          "Pandas - statistiche e raggruppamenti",
          "Pandas - import ed export da CSV, Excel e Database",
          "Esercizio - BigData con NumPy e Pandas",
          "Esercizio - Estrazioni del lotto con Pandas",
          "Grafici con mathplotlib"
        ],
        "MapReduce, Hadoop e Spark": [
          "Hadoop",
          "Hadoop su Docker",
          "MapReduce con MrJob in locale",
          "MrJob con Hadoop su Docker",
          "Spark",
          "Map Reduce con Spark",
          "PySpark: RDD, filtri e partizioni",
          "PySpark: i DataFrame",
          "PySpark: DataFrame e SQL",
          "Esercizio con pySpark e file CSV",
          "Esercizio con pySpark e file Parquet"
        ],
        "Rudimenti di Machine Learning": [
          "Cos'è il Machine Learning",
          "Scikit-Learn e una prima regressione lineare sui dati Iris",
          "Regressione lineare semplice",
          "Metriche e suddivisione dei dati",
          "Esempio di regressione lineare multipla",
          "Classificatori e alberi decisionali"
        ],
        "Fine": [
          "Conclusione e saluti"
        ]
      },
      "requirements": [
        "E' utile avere familiarità con Python e le sue strutture dati fondamentali (liste, dizionari, set). È utile avere esperienza con la scrittura di funzioni e la gestione dei file.",
        "Rudimenti di SQL ed elaborazione dati"
      ],
      "description": "In questo corso esplorerai il mondo dei Big Data e delle tecniche di Machine Learning utilizzando Python, uno dei linguaggi di programmazione più diffusi e versatili. Attraverso un approccio pratico e interattivo, imparerai a gestire grandi quantità di dati, estrarre informazioni significative e costruire modelli predittivi avanzati. Sarai guidato passo dopo passo nello sviluppo di soluzioni di analisi e classificazione dei dati utilizzando librerie come Numpy, Pandas, Hadoop, pySpark e Scikit-learn.\nCosa imparerai:\nFondamenti di Python per il data analysis\nGestione e manipolazione di grandi dataset (BigData)\nUtilizzo di librerie e strumenti avanzati in Python\nRudimenti di Machine Learning\nA chi è rivolto: Il corso è rivolto a sviluppatori, analisti di dati e professionisti IT che desiderano acquisire competenze nei Big Data e nel Machine Learning. È consigliata una conoscenza di base di Python (il corso prevede alcune lezioni di introduzione a Python).\nBig Data\nI Big Data sono insiemi di dati di dimensioni estremamente grandi e complesse che non possono essere gestiti, elaborati o analizzati con i tradizionali strumenti software e database. Questi dati sono caratterizzati dalle \"3V\":\nVolume: la quantità di dati generati è enorme, spesso misurata in petabyte o zettabyte.\nVelocità: i dati vengono generati a una velocità molto elevata, spesso in tempo reale.\nVarietà: i dati possono essere strutturati (come tabelle di database), semi-strutturati (come file XML o JSON) o non strutturati (come immagini, video, testo).\nNegli ultimi anni, con la diffusione di Internet, dei social media, dei dispositivi IoT (Internet of Things) e di tecnologie avanzate, la quantità di dati generata ha raggiunto proporzioni gigantesche.\nPerché i Big Data sono importanti:\nDecisioni basate sui dati: L'analisi dei Big Data consente alle aziende di prendere decisioni più informate. Attraverso l'analisi, è possibile identificare pattern, tendenze e correlazioni che non sarebbero visibili con dataset più piccoli.\nInnovazione e personalizzazione: Le aziende possono utilizzare i Big Data per migliorare i loro prodotti e servizi. Ad esempio, piattaforme come Netflix o Amazon utilizzano i Big Data per personalizzare le raccomandazioni, basate sulle preferenze e sul comportamento degli utenti.\nPrevisione di tendenze: Settori come la finanza, la sanità e il marketing utilizzano i Big Data per prevedere cambiamenti del mercato, epidemie o il comportamento dei clienti. Questo permette di essere proattivi anziché reattivi.\nMiglioramento delle operazioni aziendali: Le organizzazioni possono analizzare i propri processi interni utilizzando Big Data per ottimizzare la produzione, ridurre i costi e migliorare l'efficienza.\nNuove opportunità di business: I Big Data hanno dato vita a nuove industrie, come il \"Data-as-a-Service\" e la data science, offrendo nuove opportunità di mercato per professionisti e aziende.\nEsempi di utilizzo:\nSanità: Analisi di grandi quantità di dati clinici e genetici per personalizzare le cure mediche e prevenire malattie.\nMarketing: Segmentazione avanzata dei clienti e pubblicità mirata grazie all'analisi dei comportamenti online.\nFinanza: Rilevazione di frodi finanziarie e gestione del rischio attraverso algoritmi di machine learning applicati a enormi dataset transazionali.\nI Big Data sono quindi fondamentali perché permettono di ottenere informazioni approfondite che possono trasformare il modo in cui operano le aziende e i settori.",
      "target_audience": [
        "Studenti universitari: Laureandi o neolaureati in informatica, ingegneria, statistica, matematica o campi affini, che desiderano approfondire le loro competenze in analisi dei dati e machine learning.",
        "Professionisti del settore: Data analyst, data scientist, ingegneri del software o professionisti IT che desiderano ampliare le loro competenze nel campo dei Big Data e del machine learning.",
        "Ricercatori: Individui che lavorano in ambito accademico o di ricerca e desiderano applicare tecniche di machine learning a dataset complessi per analisi e studi scientifici.",
        "Imprenditori e manager: Professionisti che vogliono comprendere come i Big Data e il machine learning possano essere utilizzati per prendere decisioni informate e migliorare le strategie aziendali."
      ]
    },
    {
      "title": "Inteligência Artificial: Algoritmos Genéticos - TSP",
      "url": "https://www.udemy.com/course/algoritmos-geneticos-tsp/",
      "bio": "Solução do Problema Caixeiro Viajante",
      "objectives": [
        "Você aprenderá a Teoria de Algoritmos Genéticos, todos os componentes e mecanismos. Aprenderá como funciona a Seleção, Cruzamento e Mutação de Indivíduos, bem como, avaliar a aptidão de indivíduos, selecionar indivíduos para elitismo, entre outros...",
        "Implementar um Algoritmo Genético robusto utilizando a linguagem C# orientado a objetos.",
        "Projetar um Algoritmo Genético para solucionar problemas de otimização!"
      ],
      "course_content": {
        "Introdução": [
          "Introdução ao Curso",
          "Algoritmos Genéticos",
          "Quiz 01"
        ],
        "Teoria dos Algoritmos Genéticos": [
          "População",
          "Indivíduos",
          "Representação Cromossômica",
          "Quiz 02",
          "Função de Avaliação (Atribuir Fitness)",
          "Média da População",
          "Fluxograma de Execução do AG - \"1\"",
          "Quiz 03",
          "Seleção para Cruzamento",
          "Elitismo",
          "Quiz 04",
          "Cruzamento",
          "Mutação",
          "Quiz 05",
          "Fluxograma de Execução do AG - \"2\""
        ],
        "Problema do TSP (Caixeiro Viajante)": [
          "Travelling Salesman Problem",
          "Quiz 06"
        ],
        "Visão Geral do Desenvolvimento": [
          "Projeto para Desenvolvimento",
          "Ferramentas"
        ],
        "Desenvolvimento do Algoritmo Genético": [
          "Criando Projeto e Importando Bibliotecas",
          "Interface \"1\"",
          "Interface \"2\"",
          "Importando Elementos Gráficos",
          "OnMouseClick \"1\"",
          "OnMouseClick \"2\"",
          "PlotPoints",
          "PlotLines",
          "Pasta AGClass",
          "Classe TablePoints: Variáveis",
          "Classe TablePoints: Métodos",
          "Classe TablePoints: addPoint() e generateTable()",
          "Classe TablePoints: Outros Métodos",
          "Classe TablePoints: Print",
          "Classe TablePoints: Teste",
          "Classe ConfigurationGA",
          "Classe Utils",
          "Classe Individual: Variáveis e Métodos",
          "Classe Individual: Construtor",
          "Classe Individual: CalcFitness()",
          "Classe Individual: Mutation",
          "Classe Individual: Outros Métodos",
          "Classe Individual: ToString()",
          "Classe TablePoints: Ajustes",
          "Classe Individual: Teste",
          "Classe Population: Variáveis e Métodos",
          "Classe Population: Construtor",
          "Classe Population: Métodos \"1\"",
          "Classe Population: Métodos \"2\"",
          "Classe Population: Métodos \"3\"",
          "Classe Population: Teste",
          "Classe GeneticAlgorithm: Variáveis e Construtor",
          "Classe GeneticAlgorithm: Métodos",
          "Classe GeneticAlgorithm: executeGA",
          "Classe GeneticAlgorithm: Crossover \"1\"",
          "Classe GeneticAlgorithm: Crossover \"2\"",
          "Classe GeneticAlgorithm: Teste Crossover",
          "Classe GeneticAlgorithm: Mutation",
          "Classe GeneticAlgorithm: Mutation The Population",
          "Classe GeneticAlgorithm: Mutation Teste",
          "Classe GeneticAlgorithm: Torneio",
          "Classe GeneticAlgorithm: Torneio Teste",
          "Classe GeneticAlgorithm: Método executeGA \"1\"",
          "Classe GeneticAlgorithm: Método executeGA \"2\"",
          "Interface: Botão Criar População",
          "Interface: Botão Criar População e Limpar",
          "Interface: ZedGraph",
          "Interface: Configuração do AG",
          "Interface: Mecanismo de Evolução \"1\"",
          "Interface: Mecanismo de Evolução \"2\"",
          "Interface: Correções",
          "Interface: Pontos e Linhas",
          "Interface: Limpar Gráfico",
          "Interface: Limpando Campo de Complexidade",
          "Interface: Testando o AG",
          "2-OPT e 3-OPT",
          "Testes Finais"
        ],
        "Considerações Finais": [
          "Download do Projeto"
        ],
        "Updates": [
          "Sobre atualizações"
        ]
      },
      "requirements": [
        "Realizar o curso Inteligência Artificial: Algoritmos Genéticos",
        "Lógica de Programação (Básico)",
        "Linguagem c# (Básico)",
        "Orientação a Objeto (Básico)"
      ],
      "description": "Aprenda o paradigma de Algoritmos Genéticos aplicado ao Problema do Caixeiro Viajante (TSP) usando a linguagem C# e componentes gráficos do Visual Studio.\nOBJETIVO DO CURSO:\nAo completar o curso, você terá noções teóricas sobre o mecanismo do Algoritmo Genético, seus componentes e suas funcionalidades. Terá também noções de desenvolvimento de um algoritmo genético para solucionar problemas de roteamento, esse problema é conhecido como o Problema do Caixeiro Viajante.\nO Problema do Caixeiro Viajante é um dos clássicos problemas de AG, a narrativa desta história é: Um vendedor ambulante deve visitar várias cidades, porem ele não pode repetir nenhuma, deve visitar todas no menor caminho possível e retornar para a cidade de origem.\nEsse é um problema de otimização NP-Difícil, não é qualquer algoritmo de estrutura de dados que consegue resolver tal problema em pouco tempo. Isso se deve ao fato de que a quantidade de cidades influencia na complexidade de busca. No caso de 5 cidades, se for aplicado o fatorial n(!5) temos 120 possibilidades de rotas, caso sejam 20 cidade, temos mais de 1 quintilhão de rotas possíveis. Com o Algoritmo Genético é possível encontrar uma solução em pouco tempo.\nMÉTODO:\nPara atingir este objetivo, nós vamos iniciar nossa jornada com uma introdução à Algoritmos Genéticos, no qual vamos explorar suas teorias, abordando seus elementos de Elitismo, Seleção, Cruzamento e Mutação. Também vamos estudar quais são as Taxas de Cruzamento e Taxas de Mutação, bem como são cruzados e mutados.\nEm seguida, iremos fazer uma pequena apresentação do Problema do Caixeiro Viajante, o objetivo desse capitulo é salientar a importância do AG na busca da solução para problemas deste tipo.\nApós a introdução à AG, iremos aprender na prática como implementar os códigos do Algoritmo Genético. Utilizaremos as melhores estratégias para realização da seleção, cruzamento e mutação. Iremos utilizar as funcionalidades do Visual Studio e do ZedGraph para criar uma interface amigável, fácil manipulação e visualização das informações.\n\n\nVocê pode visualizar a grade curricular completa logo abaixo desta descrição! Para visualizar o conteúdo dos capítulos, você pode expandir todas as abas!\nTenha bons estudos com as aula!\nAtt. Prof. Camilo Barreto",
      "target_audience": [
        "Estudantes de Ciências, Sistemas e Engenharia da Computação",
        "Entusiastas em Inteligência Artificial",
        "Você!"
      ]
    },
    {
      "title": "Explorando o DeepSeek: Domine a Revolucionária IA Gratuita",
      "url": "https://www.udemy.com/course/explorando-o-deepseek-domine-a-revolucionaria-ia-gratuita/",
      "bio": "Aprenda DeepSeek do Zero ao Avançado: Explore essa moderna IA Generativa com projetos reais e aplicações práticas",
      "objectives": [
        "Entender o impacto do DeepSeek no cenário da IA generativa, incluindo vantagens, limitações e cuidados de uso",
        "Explorar a interface do DeepSeek com testes práticos, leitura de anexos, imagens e buscas na web",
        "Dominar técnicas de engenharia de prompt como role prompting e in-context learning aplicadas a tarefas reais",
        "Aplicar o DeepSeek na geração de conteúdo, código, tradução, revisão, ajustes de tom e resolução de problemas",
        "Executar o DeepSeek localmente com total privacidade, usando ferramentas como LM Studio, Ollama e Google Colab",
        "Utilizar o DeepSeek via API e em ambientes como o VS Code, independentemente do hardware",
        "Aprender a baixar modelos diretamente do Hugging Face e configurá-los corretamente",
        "Integrar o DeepSeek com planilhas, e-mails e formulários para criar automações úteis sem escrever código",
        "Desenvolver projetos reais, como categorização automática de dados de formulário e registro em planilhas",
        "Construir uma aplicação com RAG usando DeepSeek e Streamlit para interação inteligente com documentos"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre Inteligência Artificial",
          "Recursos para download",
          "DeepSeek - intuição 1",
          "DeepSeek - intuição 2",
          "DeepSeek - intuição 3",
          "Questões DeepSeek"
        ],
        "Interface gráfica": [
          "Testando a interface",
          "Modelo de raciocínio",
          "Engenharia de prompts",
          "Criação de conteúdo",
          "Carregamento de anexos",
          "Pesquisa na Internet",
          "Role prompting",
          "One ou few-shot prompting",
          "Chain of thought prompting",
          "Geração de código",
          "Refinamento, autorreflexão e templates",
          "Questões sobre uso prático"
        ],
        "Código fonte e uso local": [
          "Implementação via Hugging Face",
          "Implementação via API",
          "Implementação via Ollama",
          "Implementação em máquina local",
          "Uso local com LM Studio",
          "Uso local com Ollama",
          "Questões sobre uso via código"
        ],
        "Estudos de caso": [
          "Criação de conteúdo",
          "Organização e produtividade",
          "Currículos",
          "Atendimento ao cliente",
          "Desenvolvimento de código",
          "Automação de formulários",
          "Chat com documentos com RAG",
          "Questões sobre estudos de caso"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Programação básica em Python"
      ],
      "description": "Aprenda do básico ao avançado como dominar o DeepSeek, uma das mais poderosas IAs generativas de código aberto da atualidade, capaz de superar até mesmo os modelos ChatGPT mais modernos. Neste curso, você explorará na prática como utilizar essa tecnologia revolucionária, com e sem programação, sempre com foco em exemplos reais e aplicações úteis para uso pessoal e profissional.\nVocê entenderá o impacto do DeepSeek no cenário da IA, suas vantagens, limitações e cuidados no uso. Começamos pela interface, com testes práticos, leitura de anexos, processamento de imagens e busca na web. Exploramos a engenharia de prompt com técnicas como role prompting e in-context learning, compreendendo detalhadamente como podem ser aplicadas em tarefas úteis como geração de conteúdo e código, tradução, revisão, ajustes de tom e resolução de problemas lógica.\nAprenda com exemplos reais: criação de conteúdo, exercícios matemáticos, geração de códigos e construção de aplicações. Descubra como baixar e rodar o modelo em seu computador, com total privacidade e sem necessidade de conexão com internet durante o uso. Aprenda a usar o DeepSeek via interface gráfica (com LM Studio), via API, no Google Colab, com Ollama e no VS Code, independentemente do seu hardware. Saiba também como escolher e baixar modelos diretamente de repositórios como Hugging Face.\nAlém disso, você aprenderá a integrar o DeepSeek a serviços como formulários, planilhas e e-mails, criando automações práticas sem necessidade de programação. Um dos projetos desenvolvidos será uma solução funcional que lê dados de um formulário de contato, categoriza automaticamente as informações e registra os resultados em uma planilha do Google.\nAo final do curso você aprenderá como criar um projeto real utilizando RAG, em que o DeepSeek interage com documentos por meio de uma interface moderna desenvolvida com Streamlit, perfeita para quem busca criar soluções completas com inteligência artificial.\nIdeal para quem deseja aplicar IA generativa na prática — com ou sem código — esse curso é a porta de entrada para explorar todo o potencial do DeepSeek e transformar ideias em soluções com inteligência artificial de ponta.",
      "target_audience": [
        "Pessoas interessadas em inteligência artificial que desejam aprender a usar IAs generativas com ou sem programação",
        "Desenvolvedores que querem explorar o potencial do DeepSeek e aprender a rodá-los localmente com total controle",
        "Profissionais que desejam aplicar o DeepSeek para gerar ideias, revisar textos e traduzir com mais eficiência",
        "Desenvolvedores que desejam implementar o DeepSeek em suas próprias aplicações",
        "Alunos e autodidatas que querem entender e experimentar IA generativa na prática, com foco em aplicações reais",
        "Profissionais de tecnologia que desejam integrar a serviços como planilhas, formulários e aplicações web sem depender de APIs pagas",
        "Pessoas que desejam dominar o uso de modelos como DeepSeek sem depender de soluções fechadas como o ChatGPT"
      ]
    },
    {
      "title": "Chatboty AI - od zera do mastera! wykorzystaj AI w praktyce!",
      "url": "https://www.udemy.com/course/chat-gpt-kurs/",
      "bio": "Chatboty AI - dla początkujących! | Wprowadzenie po polsku do Chata GPT, Google Bard, Dall-E, Midjourney i wiele więcej!",
      "objectives": [
        "Jak studenci mogą przyspieszyć naukę i pracę za pomocą Chata GPT",
        "Jak korzystać z ChatGPT, aby przejść od początkującego do zaawansowanego opanowania narzędzia opartego o SI",
        "Jak zarabiać pieniądze, używając Chata GPT do wykonywania pracy za Ciebie",
        "Jak używać chata GPT jako asystenta Programisty",
        "Jak używać chata GPT jako asystenta Testera Oprogramowania",
        "Jak wykorzystać potencjał sztucznej inteligencji w usprawnieniu pracy w zawodach cyfrowych"
      ],
      "course_content": {
        "Wstęp": [
          "Intro kursu",
          "Wprowadzenie do OpenAI",
          "Wprowadzenie do Chata GPT",
          "Przykłady zastosowań na oficjalnej stronie OpenAI",
          "Rejestracja do Chata GPT",
          "Logowanie do Chata GPT",
          "Omówienie Interfejsu",
          "Omówienie Głównego widoku Chata GPT",
          "Prośba do Ciebie zanim przejdziesz dalej...",
          "Przykład zastosowania Chata GPT i często występujący problem - omówienie"
        ],
        "ChatGPT dla zawodów cyfrowych (dla zastosowań technicznych)": [
          "Przykład zastosowania do napisania CV",
          "Przykład zastosowania do napisania CV 2",
          "Chat GPT do zastosowań dla Copywriterów",
          "Chat GPT do zastosowań dla Studentów (przykład z poprawą tekstu)",
          "Chat GPT do zastosowań ogólnych inne przykłady np. generowanie pomysłów biznes",
          "Chat GPT do zastosowań developerskich 1",
          "Chat GPT do zastosowań developerskich 2",
          "Chat GPT do zastosowań developerskich 3",
          "Chat GPT do zastosowań developerskich (struktura kodu i analiza)",
          "Chat GPT do zastosowań developerskich i testerskich",
          "Chat GPT do zastosowań testerskich (oprogramowanie)",
          "Chat GPT do zastosowań testerskich i 2 instancja chatu GPT",
          "Chat GPT - częsty problem z ogarniczeniem requestów",
          "Inne pomysly i zastosowanie czata GPT"
        ],
        "ChatGPT 4": [
          "ChatGPT vs Google",
          "ChatGPT 3 vs 4",
          "Wykupienie wersji 4 ChataGPT - krok po kroku",
          "Przykład możliwości ChataGPT 4",
          "ChatGPT 4 feature's / możliwości",
          "Ograniczenia możliwości ChataGPT 4",
          "Wprowadzenie do 'prompt engineeringu'",
          "Zastosowanie biznesowe ChataGPT 4",
          "Chat GPT 4 Pluginy i ich zastosowanie",
          "ChatGPT 4 do edukacji",
          "Edge i bing - ChatGPT w wersji 4 za darmo",
          "Co wolno i co nie wolno z Chatem GPT - lekcja podsumowująca",
          "Alternatywa dla ChataGPT - Google Bard"
        ],
        "Narzędzia graficzne i inne oparte o AI": [
          "Wprowadzenie do MidJourney",
          "Przykład MidJourney",
          "Parametryzacja w MidJourney",
          "Edycje / Modyfikacje w MidJourney",
          "Dall - E 2",
          "Inne narzędzia oparte o Sztuczną Inteligencję (AI) - praktyczny przegląd"
        ],
        "Ograniczenia Chata GPT": [
          "Ograniczenia Chata GPT"
        ],
        "Zarabianie za pośrednictwem Chata GPT": [
          "Zarabianie za pośrednictwem Chata GPT"
        ],
        "Inne polecane materiały, wtyczki i słowo na koniec": [
          "Polecane materiały i skąd czerpać wiedzę o Chacie GPT",
          "Wtyczki Chata GPT dla przeglądarki",
          "Podziękowanie i słowo na koniec"
        ],
        "GPT Store": [
          "Przegląd GPT Store i utworzenie własnego chat bota"
        ],
        "Bonus": [
          "Co dalej po kursie?",
          "Bonus"
        ]
      },
      "requirements": [
        "Telefon lub komputer z dostępem do Internetu",
        "Chęci"
      ],
      "description": "Ten kurs poświęcony jest modelowi GPT (Generative Pre-training Transformer), który jest jednym z najważniejszych i najbardziej zaawansowanych narzędzi do generowania tekstu przez SI. GPT został opracowany przez OpenAI i jest obecnie jednym z najlepszych modeli tekstowych na rynku.\n\nW miarę postępów w tym kursie zagłębisz się w wewnętrzne działanie Chata GPT, uzyskując kompleksowe zrozumienie, w jaki sposób przetwarza i generuje tekst zupełnie jakby tworzył go człowiek lub też specjalista w danej dziedzinie. Dowiesz się, jak dostosować Chata GPT do wykonywania określonych zadań, które odpowiadają Twoim potrzebom, takich jak copywriting, programowanie, testowanie itp. - możliwości są nieograniczone.\n\nKurs zaczyna się od wprowadzenia do GPT i jego podstawowych mechanizmów działania. Następnie przybliżone są różne sposoby wykorzystania GPT, takie jak automatyczne tłumaczenie tekstu, generowanie odpowiedzi na pytania i tworzenie treści marketingowych, tworzenie skryptów itp. itd.\n\nPonadto, kurs zawiera sekcję poświęconą najlepszym praktykom pracy z GPT oraz wskazówki dotyczące optymalizacji jego działania. Uczestnicy kursu nauczą się również jak oceniać jakość generowanego przez GPT tekstu oraz jak korzystać z różnych narzędzi i bibliotek do pracy z modelem.\n\nCały kurs jest przeznaczony dla osób zarówno początkujących, jak i zaawansowanych, chcących nauczyć się więcej o GPT i jego zastosowaniach.\n\nPod koniec tego kursu będziesz dobrze przygotowany do efektywnego wykorzystania Chata GPT we własnych projektach i do rozwijania swojej kariery niezależnie od branży, w której działasz. Niezależnie od tego, czy jesteś początkującym, który chce tylko dowiedzieć się więcej, czy też doświadczonym Praktykiem NLP, ten kurs zapewni Ci wiedzę i narzędzia potrzebne do opanowania Chata GPT i usprawnienia Twoich codziennych obowiązków i pracy zawodowej.",
      "target_audience": [
        "Każdy, kto chce dowiedzieć się, jak zarabiać pieniądze na Chacie GPT",
        "Wszyscy studenci, którzy chcą dowiedzieć się, jak mogą korzystać z Chata GPT",
        "Każda osoba, która jest ciekawa, w jaki sposób ChatGPT może pomóc jej w codziennych obowiązkach",
        "Każdy, kto chce wyprzedzić rewolucję AI oraz jej szerokie zastosowanie w biznesie za pośrednictwem Chata GPT"
      ]
    },
    {
      "title": "GPTを自作して大規模言語モデルを理解する：PythonでTransformerとAttentionを学ぶLLM機械学習",
      "url": "https://www.udemy.com/course/making-of-my-gpt/",
      "bio": "GPT1の部品を作りながらPyTorchでGPT本体を自作します。LLMがどのように作用しているのか本体を自作してコードレベルで見ていきます。レクチャーの内容に応じてニューラルネットワークについても触れていきます。",
      "objectives": [
        "TransformerのAttentionメカニズムとGPTの仕組みを学びます。",
        "自然言語処理の流れを学びます。",
        "Python言語を学びながらGPTのプログラムを作ります。",
        "機械学習フレームワーク、PyTorchを教材として学びます。"
      ],
      "course_content": {},
      "requirements": [
        "ＧＰＴの仕組みを理解したいという気持ち"
      ],
      "description": "初期のGPTを１から作ってみます。ChatGPTのような役立つ生成モデルを再現することはできませんが、学問的な視点から、基本的なGPTを作ってみることで、どうして自然言語が使えるＡＩが実現するようになったのか、手を動かしながら学びます。イラスト解説と平行して、前半は自然言語処理の成り立ちを学び、後半では、Attentionメカニズムを搭載したTransformerの部品を作っていきます。臨機応変に機械学習に関係することも紹介しています。とにかく、掴める内容にしようと思って愚直に青臭くコースを作成しました。生の生成ＡＩに触れてみたい方にお勧めです。",
      "target_audience": [
        "ＧＰＴや自然言語に興味のある方",
        "機械学習の応用を学びたい方",
        "人工知能（ＡＩ）に興味のある方"
      ]
    },
    {
      "title": "Domine a criação de imagens com Inteligência Artificial",
      "url": "https://www.udemy.com/course/criacao-imagens-stable-diffusion-inteligencia-artificial-generativa/",
      "bio": "Crie imagens impressionantes utilizando Inteligência Artificial Generativa! Passo a passo com Stable Diffusion e Python!",
      "objectives": [
        "Entender o funcionamento básico do Stable Diffusion para criar novas imagens",
        "Configurar os parâmetros do Stable Diffusion para obter diferentes resultados",
        "Criar imagens utilizando outros modelos disponibilizados pela comunidade OpenSource",
        "Aprender sobre Engenharia de Prompts para escolher as melhores palavras-chave para serem enviadas para a inteligência artificial",
        "Trabalhar com prompts negativos para indicar o que não deve aparecer nas imagens",
        "Utilizar fine-tuning para criar o seu modelo personalizado para gerar suas próprias imagens",
        "Enviar imagens iniciais para condicionar a criação do algoritmo",
        "Utilizar Inpaiting para editar imagens, remover elementos indesejados ou trocar objetos (cachorro por gato, por exemplo)",
        "Implementar técnicas de processamento digital de imagens (detecção de bordas e poses) para melhorar a qualidade do resultado"
      ],
      "course_content": {},
      "requirements": [
        "Lógica de programação e básico sobre o Python são desejáveis, mas não obrigatório",
        "É possível acompanhar o curso sem ser da área de tecnologia"
      ],
      "description": "Atualizado com modelos mais novos do Stable Diffusion XL\nA criação de imagens com inteligência artificial é uma área que tem ganhado muita atenção, tanto de profissionais de tecnologia quanto de pessoas de outras áreas que querem criar suas próprias imagens personalizadas. As ferramentas utilizadas para esse propósito utilizam avançadas e modernas técnicas e aprendizagem de máquina e visão computacional, podendo contribuir para a automatização do desenvolvimento de novas composições com alta qualidade gráfica. É possível criar novas imagens apenas enviando uma descrição textual, ou seja, você pede para a IA (inteligência artificial) criar uma imagem exatamente como você deseja! Por exemplo, você pode enviar o texto \"um gato lendo um livro no espaço\" e a IA criará uma imagem exatamente com este cenário! Essa técnica ganhou muita popularidade em 2022 e possui uma forte tendência de crescimento nos próximos anos.\nExistem várias ferramentas disponíveis, e uma das que apresenta as maiores vantagens é o Stable Diffusion desenvolvido pela empresa StabilityAI. Além de ser OpenSource (código aberto), apresenta ótima usabilidade, velocidade e é capaz de criar imagens com altíssima qualidade. Por ser código aberto, desenvolvedores tem criado muitas extensões que são capazes de gerar uma infinita variedade de imagens nos mais diferentes estilos.\nNeste curso você aprenderá tudo o que precisa saber para criar novas imagens utilizando o Stable Diffusion e a linguagem de programação Python. Veja abaixo o que você aprenderá neste curso que está dividido em seis partes:\n\nParte 1: Básico do Stable Diffusion: intuição sobre o funcionamento da tecnologia e criação das primeiras imagens. Você também aprenderá sobre os principais parâmetros para obter resultados diferentes, bem como criar imagens com estilos diferentes\nParte 2: Engenharia de prompts: você aprenderá como enviar os textos adequados para que a IA entenda exatamente o que você quer criar\nParte 3: Treinamento personalizado: que tal colocar suas próprias fotos nos mais diferentes tipos de ambiente? Nesta seção você aprenderá como utilizar suas próprias imagens e gerar seus avatares (ou do seu animal de estimação)\nParte 4: Imagem para imagem: além de criar imagens enviando textos, é também possível enviar imagens como ponto de partida para a IA gerar as imagens\nParte 5: Inpainting - troca de classe: você aprenderá como editar imagens para remover objetos ou trocá-los. Por exemplo: retirar o cachorro e substituir por um gato\nParte 6: ControlNet: nessa seção você implementará técnicas de processamento digital de imagens (detecção de bordas e poses) para melhorar ainda mais os resultados\nAs implementações serão feitas passo a passo no Google Colab on-line com GPU, portanto, você não precisa ter um computador potente para obter resultados incríveis em questão de segundos! Mais de 50 aulas e mais de 6 horas de vídeos!",
      "target_audience": [
        "Pessoas que queiram aprender como criar imagens usando Inteligência Artificial",
        "Pessoas que queiram criar seus próprios avatares",
        "Iniciantes na área de Visão Computacional",
        "Alunos de graduação e pós-graduação que estão cursando disciplinas sobre Visão Computacional, Inteligência Artificial, Processamento Digital de Imagens ou Computação Gráfica"
      ]
    },
    {
      "title": "LLMs e Agentes de IA para Empresas e Negócios",
      "url": "https://www.udemy.com/course/llms-e-agentes-de-ia-para-empresas-e-negocios/",
      "bio": "Domine IA Generativa na prática com estudos de caso e crie soluções profissionais com LangChain, CrewAI, Gemini e mais!",
      "objectives": [
        "Implementar LLMs via API (gratuitas e pagas) ou localmente e explore diferentes modelos, como Llama, Deepseek, ChatGPT, Gemini, entre outros",
        "Desenvolver um assistente de marketing para geração de conteúdo, adaptando textos para diferentes públicos, canais e objetivos de forma escalável",
        "Criar um chatbot com RAG que responde com base em documentos de uma empresa para gerar respostas consistentes, acelerando o suporte e reduzindo custos",
        "Criar um analisador de currículos, que classifica candidatos mais compatíveis, extrai informações estruturadas e fornece insights relevantes",
        "Implementar um agente de IA que gera exercícios personalizados com explicações e exporta automaticamente para arquivos editáveis",
        "Criar um agente de IA financeiro capaz de interpretar relatórios, gerar resumos e responder dúvidas com transparência",
        "Desenvolver um guia virtual de viagem com múltiplos agentes que criam roteiros personalizados com base no perfil do turista",
        "Implementar um agente que se conecta a um banco de dados SQL para analisar avaliações, gerar resumos úteis e responder perguntas feitas",
        "Construir um agente médico que analisa imagens, gera laudos detalhados e busca referências científicas atualizadas.",
        "Aprender a criar interfaces profissionais com Streamlit para suas aplicações de Inteligência Artificial"
      ],
      "course_content": {
        "Introdução": [
          "Conteúdo do curso",
          "Mais sobre LLMs",
          "Recursos para download"
        ],
        "Marketing": [
          "Definição do projeto",
          "Tecnologias utilizadas",
          "Instalação das bibliotecas",
          "Interface gráfica 1",
          "Interface gráfica 2",
          "Conexão com a LLM",
          "Formato das mensagens",
          "Modelos open-source e proprietários",
          "Engenharia de prompts 1",
          "Engenharia de prompts 2",
          "Conclusão da aplicação",
          "Aviso sobre uso no Colab",
          "Interface com Streamlit",
          "Execução local 1",
          "Execução local 2",
          "Questões sobre o Projeto 1",
          "EXERCÍCIO",
          "Solução"
        ],
        "Atendimento e suporte": [
          "Definição do projeto",
          "Tecnologias utilizadas",
          "Instalação das ferramentas",
          "Carregamento da LLM",
          "Definição do contexto",
          "Indexação de documentos 1",
          "Indexação de documentos 2",
          "Recuperação e geração",
          "Pipeline RAG avançada",
          "Histórico das conversas",
          "Funções indexação + recuperação",
          "Interface com Streamlit",
          "Questões sobre o Projeto 2",
          "EXERCÍCIO",
          "Solução"
        ],
        "Recursos humanos": [
          "Definição do projeto",
          "Extração de conteúdo",
          "Parsing de documentos",
          "LLM e testes iniciais",
          "Construção do prompt",
          "Formato JSON",
          "Currículo de teste",
          "Modificação no prompt e chain",
          "Adição de campos",
          "Cálculo do score",
          "Arquivo JSON",
          "Interface com Streamlit 1",
          "Interface com Streamlit 2",
          "Questões sobre o Projeto 3",
          "EXERCÍCIO",
          "Solução"
        ],
        "Educação": [
          "Definição do projeto",
          "Formulário para exercícios",
          "Engenharia de prompt",
          "Geração de exercícios",
          "Exportação para o Google Drive",
          "Interface com Streamlit",
          "Configurações do Qdrant",
          "Configuração da RAG",
          "Carregamento dos documentos",
          "Conexão e busca vetorial",
          "Geração de exercícios",
          "Agentes e LangGraph - intuição",
          "Configuração do agente",
          "Executando o chatbot",
          "Ferramenta para cálculo matemático 1",
          "Ferramenta para cálculo matemático 2",
          "Ferramenta para pesquisa e RAG",
          "Código final",
          "Questões sobre o Projeto 4",
          "EXERCÍCIO",
          "Solução"
        ],
        "Finanças": [
          "Definição do projeto",
          "Preparação do ambiente",
          "Leitura de dados financeiros",
          "Sumarização",
          "Prompt para análise financeira",
          "Testes com Gemini",
          "Agente ReAct - intuição",
          "Agente ReAct - implementação",
          "Prompt do ReAct e pipeline RAG",
          "Consultas com Query Engine",
          "Tradução de prompts",
          "Criação de ferramentas",
          "Planilhas com Pandas Query Engine",
          "Interface com Streamlit 1",
          "Interface com Streamlit 2",
          "Interface com Streamlit 3",
          "Questões sobre o Projeto 5",
          "EXERCÍCIO",
          "Solução"
        ],
        "Turismo": [
          "Definição do projeto",
          "Sistemas multi-agentes",
          "Preparação do ambiente",
          "Criação de ferramentas",
          "Criação de agentes",
          "Criação de tarefas",
          "Criação da equipe",
          "Exportação para PDF",
          "Adição de novo agente",
          "Interface com Streamlit 1",
          "Interface com Streamlit 2",
          "Interface com Streamlit 3",
          "Questões sobre o Projeto 6",
          "EXERCÍCIO",
          "SOLUÇÃO"
        ],
        "Varejo/e-commerce": [
          "Definição do projeto",
          "Preparação dos dados 1",
          "Preparação dos dados 2",
          "Preparação dos dados 3",
          "Base de dados no SQLite",
          "LLM e conexão com DB",
          "Ferramentas DB e consulta SQL",
          "Sumarização e análise de sentimento",
          "Agentes com LangGraph",
          "Nós do agente",
          "Grafo/workflow",
          "Agente com NL2SQL 1",
          "Agente com NL2SQL 2",
          "Agente com NL2SQL 3",
          "Agente com NL2SQL 4",
          "Agente com NL2SQL 5",
          "Interface com Streamlit",
          "Questões sobre o Projeto 7",
          "EXERCÍCIO",
          "SOLUÇÃO"
        ],
        "Medicina": [
          "Definição do projeto",
          "Leitura de imagens",
          "Pré-processamento da imagem",
          "Agente com LLM de visão",
          "Prompts para imagens médicas",
          "Agente médico com pesquisa",
          "Pipeline: imagem + pesquisa",
          "Interface com Streamlit",
          "Questões sobre o Projeto 8",
          "EXERCÍCIO",
          "SOLUÇÃO"
        ],
        "Considerações finais": [
          "Considerações finais",
          "AULA BÔNUS"
        ]
      },
      "requirements": [
        "Lógica de programação",
        "Programação básica em Python"
      ],
      "description": "Descubra como a Inteligência Artificial Generativa está transformando empresas ao impulsionar inovação e eficiência em diversos setores! Este curso prático oferece uma imersão no universo dos LLMs (Large Language Models) e Agentes de IA, capacitando você a criar soluções inteligentes e automatizadas para problemas reais do mercado.\nCom o avanço do PLN (Processamento de Linguagem Natural) e dos modelos de linguagem, empresas e profissionais vêm adotando essas tecnologias para aumentar a produtividade e tomar decisões com mais precisão. Pensando nisso, este curso foi criado para oferecer a você um aprendizado prático, direto e aplicável. Você aprenderá a implementar soluções utilizando código em Python, com foco no uso de LLMs em contextos de negócios, mas com aplicações que também podem ser adaptadas a qualquer outro desafio do mundo real.\nAo longo das aulas, você dominará as principais ferramentas e frameworks do ecossistema de IA generativa, como LangChain, LangGraph, LlamaIndex, CrewAI, Agno e outras soluções open source. Aprenda a implementar LLMs com Python via API (gratuitas e pagas) ou localmente, explorando modelos como Llama, Deepseek, ChatGPT, Gemini, entre outros — sempre com foco em aplicações reais e escaláveis.\nVocê atuará como um profissional encarregado de atender diferentes demandas de empresas. Por meio de 8 estudos de caso práticos, será desafiado a desenvolver aplicações úteis e personalizadas para aplicar IA generativa em:\nMarketing: Crie um assistente de marketing com IA para escalar a criação de conteúdo. Adapte textos para públicos, canais e objetivos diversos com facilidade.\nAtendimento e Suporte: Desenvolva chatbots inteligentes com RAG. Utilize documentos reais (ex: manuais, PDFs, etc.) para fornecer respostas precisas às dúvidas dos clientes.\nRecursos Humanos: Analise currículos e classifique candidatos automaticamente. Extraia informações estruturadas e obtenha insights relevantes.\nEducação: Gere exercícios personalizados com base no nível e preferências do aluno e exporte automaticamente para arquivos editáveis. Obtenha explicações detalhadas e tutor 24/7 com acesso à ferramentas.\nFinanças: Interprete relatórios financeiros e gere resumos automatizados com facilidade. Pergunte ao agente e obtenha respostas com transparência.\nTurismo: Desenvolva guias virtuais para criar roteiros personalizados com sistema multiagentes. Tenha o controle sobre o papel de cada agente na criação do itinerário final.\nVarejo/Ecommerce: Analise avaliações de produtos e obtenha resumos relevantes. Conecta-se ao banco SQL para analisar e responder a perguntas feitas em linguagem natural.\nMedicina: Automatize a análise de imagens médicas e gere relatórios detalhados. Inclui busca de referências para embasar o resultado final.\nAo longo das seções, você explorará várias técnicas e conceitos, como: engenharia de prompt, RAG (Retrieval-Augmented Generation), busca com banco de dados vetorial (local e na nuvem), parsing / pré-processamento de documentos, exportação de dados estruturados (ex: formato JSON), exploração de modelos de raciocínio (reasoning), criação de agentes de IA com integração a ferramentas (tools), criação de sistema multi-agentes, uso de LLMs multimodais para análise de imagens, entre outros.\nAlém disso, para cada estudo de caso você desenvolverá uma interface profissional e intuitiva utilizando a biblioteca Streamlit, garantindo a usabilidade e a aplicabilidade das soluções.\nPara facilitar o acesso e a experimentação, o curso foca no uso do Google Colab, um ambiente gratuito e acessível para todos os alunos, sem depender de uma infraestrutura local ou hardware avançado. Além disso, você aprenderá a implementar e executar as soluções localmente, expandindo suas opções de desenvolvimento e implantação.\nPrepare-se para transformar ideias em soluções modernas com IA generativa!",
      "target_audience": [
        "Profissionais de diferentes áreas que buscam entender como aplicar LLMs de forma prática para solução de problemas reais.",
        "Empreendedores e líderes de negócios que querem aplicar IA generativa para inovar, automatizar processos e ganhar vantagem competitiva.",
        "Consultores, freelancers e autônomos que desejam atender clientes com soluções personalizadas baseadas em IA.",
        "Entusiastas de IA e inovação interessados em explorar aplicações práticas de LLMs e agentes em diferentes setores.",
        "Desenvolvedores que desejam expandir suas habilidades com IA generativa e aprender com estudos de caso reais para construir um portfólio sólido."
      ]
    },
    {
      "title": "Midjourney Pro: Conviertete en un experto en Midjourney",
      "url": "https://www.udemy.com/course/midjourney-pro-conviertete-en-un-experto-en-midjourney/",
      "bio": "Aprende Midjourney paso a paso. Crea impresionantes obras de arte con la IA Generativa de Midjourney",
      "objectives": [
        "Generación de imagenes con IA Generativa",
        "Primeros pasos con Midijourney y pompts básicos con Midjourney",
        "Elaboración de Prompts con Midjourney",
        "Parametros avanzados en Midjourney",
        "Generación Avanzada de Imagenes con Midjourney",
        "Obtener ingresos con Midjourney",
        "Integración de ChatGPT y Midjorney",
        "Competidores de Midjourney: DALL-E, Focus, Leonardo, etc"
      ],
      "course_content": {
        "Introducción a la plataforma de Udemy": [
          "Introducción a Udemy"
        ],
        "Introducción a la IA Generativa": [
          "Introducción a la IA Generativa y a sus palicaciones ChatGPT, DALLE o Midjourney",
          "Caso de uso: Trailer generado integramente por IA Generativa",
          "Desafios de la IA Generativa"
        ],
        "Generación de imagenes con IA Generativa": [
          "Introducción a la IA Generativa de Imagenes",
          "GANS, Neural Style Transfer y Difussion models",
          "Legalidad, Copyright y futuro de la IA Generativa",
          "Diferentes modelos de IA Generativa para Imagenes",
          "Potencial de la IA Generativa con Imagenes"
        ],
        "Primeros pasos con Midijourney": [
          "Acceso a la plataforma de MidJourney",
          "Galería de imagenes de MidJourney y como editarlas",
          "Primeros pasos con MidJourney"
        ],
        "Prompts Básicos de MidJourney": [
          "Promp Engineering aplicado a MidJourney",
          "Configuración del estilo, time-travel, emoción, color y entorno",
          "Laboratorio Práctico: Trabajar con una imagen base, Upscalling, Time Travel",
          "Obtener la descripción de la imagen"
        ],
        "Configuración de usuario en MidJourney": [
          "Configuración de usuario de Midjourney"
        ],
        "Elaboración de Prompts con Midjourney": [
          "Parámetros: -aspect, -chaos, -iw y -no",
          "Parámetros: -quality, -seed y -stop"
        ],
        "Parametros avanzados en Midjourney": [
          "Parámetros de Aspect Ratios, Chaos y No",
          "Parámetros de Quality, Repeat, Seeds, Style y Stilize",
          "Parámetros de Stop, Tile, Version, Video y Weird"
        ],
        "Generación Avanzada de Imagenes con Midjourney": [
          "Blending para unificar diferentes imagenes en una",
          "Generar imagenes y una landing page para nuestro Producto"
        ],
        "Integración de ChatGPT y Midjorney": [
          "Introducción a ChatGPT",
          "Laboratorio Práctico: Primeros pasos con ChatGPT",
          "Caso de Uso Aplicado: Generar los personajes de novelas con ChatGPT y Midjourney",
          "Photorrealistic Plugin para Midjourney",
          "Generando una imagen de marca completa con Photorrealistic Plugin",
          "Ejercicio Práctico: Genera una imagen de marca en tendencia",
          "Solucion Ejercicio Práctico: Genera una imagen de marca"
        ]
      },
      "requirements": [
        "no es necesario nococimientos previos"
      ],
      "description": "En un mundo donde lo visual es esencial, nace una oportunidad extraordinaria para darle alas a tu creatividad: Midjourney. Este curso está diseñado como un puente entre tu imaginación y la realidad visual, una invitación a explorar, descubrir y dar vida a tus ideas y conceptos.\nMidjourney, una herramienta revolucionaria de generación de imágenes basada en Inteligencia Artificial (IA), nos permite superar las barreras tradicionales y técnicas del arte, facilitando un espacio donde tu imaginación puede florecer libremente. Se ha convertido en un fenómeno global, permitiendo que millones de personas, como tú y yo, materialicemos nuestros conceptos e ideas directamente en la pantalla, rompiendo las limitaciones que alguna vez restringieron nuestra capacidad de expresión visual.\n\n\nCon la formación teórica, las guías de estudio descargables, los ejercicios prácticos y los laboratorios aplicados a casos de uso reales este es el único curso que necesitarás para dominar la generación de imagenes con Midjourney.\n\n\n¿Por qué elegir este curso?\n\n\nCompletitud: Un recorrido completo, desde lo básico hasta técnicas avanzadas\nTécnicas avanzadas: Centrado en técnicas variadas y estilos como fotorealismo, rostros, moda, exteriores, alimentos, figuras públicas, logos, iconos, futurista, anime, maquetas de UI/UX y muchos más.\nInstrucción aplicada: Un curso práctico que acompaña la teoría con la práctica, construyendo imágenes impactantes junto a ti.\nOrden secuencial: Un aprendizaje estructurado paso a paso para facilitar la absorción y aplicación efectiva de los conceptos y habilidades.\nMaterial de referencia incluido: Proporcionamos todos los materiales y bibliotecas de \"prompts\" necesarios para que puedas seguir el curso de manera efectiva.\n\n\nCon un enfoque práctico y aplicado, este curso te guiará a través de los siguientes modulos:\n\n\nIntroducción a la IA y Midjourney: Objetivos del curso, cómo funciona Midjourney.\nInicio con Discord y Midjourney: Configuración inicial, creando tu cuenta y familiarizándote con la plataforma.\nPrompt Engineering para Midjourney: Ingeniería y estructuración de \"prompts\", personalización y composición.\nParámetros avanzados en Midjourney.\nTópicos Específicos y Técnicas Avanzadas: Desde técnicas fotorealistas hasta efectos cinematográficos y diseño de interiores.\nEstilos Alternativos: Exploración de técnicas alternativas para crear maquetas, diseños UI y usos comerciales.\nFinalización de Imágenes: Mejoramiento de calidad, edición básica en Photoshop y otras herramientas.\nObtener ingresos en Midjourney. Métodos, plataformas y productos que puedes crear con MidJourney para generar ingresos pasivos.\nCompetidores de Midjourney: DALL-E, Focus, Leonardo, etc. Revisión de las plataformas mas punteras en IA Generativa de Imagenes que están plantando cara a Midjourney.\n\n\nÚnete hoy y obtén acceso inmediato y de por vida a:\n• Guía de formación de Mifjourney (e-book en PDF)\n• Archivos, códigos y recursos descargables\n• Laboratorios aplicados a casos de uso reales\n• Ejercicios prácticos y cuestionarios\n• Recursos como: Cheatsheets y resúmenes\n• Soporte experto 1 a 1\n• Foro de preguntas y respuestas del curso\n• 30 días de garantía de devolución de dinero\n\n\nSi estás listo para mejorar sus habilidades con midjourney, aumentar tus oportunidades laborales y convertirte en un profesional en la generación de imagenes con IA Generativa, te esperamos.",
      "target_audience": [
        "Cualquier persona que quiera desarrollar imagenes de manera automatizada y fácil",
        "Creativos y Artistas: Personas con un interés en explorar nuevas formas de expresión visual utilizando tecnología avanzada.",
        "Profesionales de la Comunicación y el Marketing: Quienes buscan potenciar sus estrategias y contenidos visuales mediante el uso de la inteligencia artificial",
        "Educadores y Formadores: Interesados en innovar y enriquecer sus materiales educativos con imágenes generadas mediante IA",
        "Entusiastas de la Tecnología: Personas apasionadas por la intersección entre arte y tecnología, buscando estar al día con las últimas tendencias y herramientas",
        "Desarrolladores y Diseñadores: Individuos que trabajan en proyectos que requieren la creación y conceptualización constante de imágenes y diseños"
      ]
    },
    {
      "title": "데이터 분석의 첫걸음! 오라클 SQL 쉽게 배우기",
      "url": "https://www.udemy.com/course/cloom-sql-oracle/",
      "bio": "20년 경력의 미국 데이터 사이언티스트에게 제대로 배우는 【오라클 SQL】",
      "objectives": [
        "실무에서 필요한 데이터를 직접 뽑아낼 수 있습니다.",
        "엑셀에서 처리할 수 없는 큰 데이터베이스를 관리할 수 있습니다.",
        "수작업으로 수정하지 않고도 몇 개의 스크립트만으로 빅데이터를 이해, 관리할 수 있습니다.",
        "보고서 작성을 위한 단계별로 체계적인 로지컬 뷰를 작성할 수 있습니다."
      ],
      "course_content": {
        "소개": [
          "오라클 SQL을 이해하고 프로그램 설치하기",
          "SQL 문법과 함수 Ⅰ",
          "SQL 문법과 함수 Ⅱ",
          "조인(JOIN)",
          "테이블 생성과 데이터 조직하기"
        ]
      },
      "requirements": [
        "엑셀을 사용하는 방법만 알고 있다면 비전공자, 전공자 모두 학습할 수 있습니다."
      ],
      "description": "4차 산업혁명 시대\n\n\n최근 4차 산업혁명 시대를 대표하는 기술로\n빅데이터, AI 인공지능이 떠오르면서 각종 자료와 정보를 효율적으로 운용하는 데이터베이스에 대한 중요성도 높아지고 있습니다.\n\n\n방대한 데이터를 세분화하고 알기 쉽게 정리하여 데이터베이스에 접속하는 누구나 쉽고 빠르게 검색하고 공유가 가능하게 만들어\n1인 크리에이터부터 소교뮤 그롭, 단체, 기업\n크게는 정부에 이르기까지 안 쓰이는 곳이 없습니다.\n\n\n특히 많은 기업들이 고객과 시장의 데이터를 수집하여 데이터베이스에 저장하고 분석할 수 있게 되었습니다.\n데이터베이스와 기타 컴퓨팅 및 비즈니스 인테리전스 도구를 사용해 수집한 데이터를 활용하여 보다 효율적으로 데이터베이스를 실행하고\n보다 나은 의사결정을 내리며, 민첩성과 확장성을 높일 수 있게 되었습니다.\n따라서, 데이터베이스 분야로 취업을 준비하시는 분이나 데이터베이스에 관심이 있는 분이라면 오라클 SQL을 공부하는 것이 필수입니다.\n빅데이터 안에서 내가 원하는 데이터를 뽑아내는 일은 기획자, 마케터 등 어떤 업무를 하고 있더라도 꼭 필요한 일입니다.\n\n\n'5일만에 마스터하는 오라클 SQL 실무'과정은\n바쁜 직장인을 위해 실무에 필요한 가장 핵심적인 내용을 5일 과정에 모두 담았습니다.\nR이나 파이썬 같은 프로그래밍을 다루지 못하더라도 오라클 SQL의 기본 문법만 배우면\n누구나 쉽게 데이터를 원하는 조건과 형태에 맞춰 뽑아낼 수 있습니다.",
      "target_audience": [
        "데이터베이스와 빅데이터분석에 관심이 많은 분들",
        "데이터베이스 및 오라클을 처음 접하시는 분들",
        "오라클 이론 내용을 실무와 함께 습득하고 싶은 분들",
        "오라클 DB 관련 분야로 진출하기를 원하는 분들",
        "데이터 관련 업무를 하지 않지만, 데이터 관련 업무를 하는 사람들과 원활한 커뮤니케이션을 하고 싶은 분들"
      ]
    },
    {
      "title": "進擊的 LangChain 學習路：打造 LLM 驅動應用程式的必備技能，一步步教你如何開發 AI 應用專案",
      "url": "https://www.udemy.com/course/langchain-llm-ai/",
      "bio": "解放 LangChain 超能力，為你訂製專屬 GPT 機器人",
      "objectives": [
        "對於使用 LangChain 開發 LLM 應用程式感到十足信心",
        "熟練使用 LangChain 模組，如：LLM, Prompt, Memory, Chain, Agent 等",
        "具備解讀 LangChain 各類函式在原始碼的能力",
        "了解多種使用情境，並知道如何使用 LangChain 搭建 LLM 應用程式"
      ],
      "course_content": {
        "課程介紹": [
          "課程介紹"
        ],
        "環境篇：環境設置": [
          "章節介紹",
          "OpenAI Api Key 申請",
          "Pinecone Key 申請",
          "SerpApi: Google Search API 申請",
          "課程專案 - Github Repo 連結"
        ],
        "基礎篇：LangChain 快速入門 - 五個必須得知道的知識": [
          "章節介紹",
          "Models 模組 - 透過 LLM 取得摘要、推理、生成能力",
          "Prompt 模組 - 替 LLM 管理提示語",
          "Chain 模組 - 結合 LLM 與 prompts 於多個步驟工作流中",
          "Agent 模組 - 讓 LLM 選擇要用的 tool 解決問題",
          "Memory 模組 - 賦予 Chains 與 Agents 記憶"
        ],
        "實作篇：跟你的文件講話 - 實作 DocGPT": [
          "專案介紹",
          "套件安裝與環境設置",
          "讀取 PDF 文件的多種方法：PyPDF2, PyPDFLoader, PyMuPDFLoader",
          "使用 qa_chain 與文件對話，同時認識不同 chain_type：stuff, map_reduce",
          "文件太大時怎麼辦？請找 RecursiveCharacterTextSplitter",
          "向量化文件，並且存放至向量資料庫 Chroma 中",
          "多種使用 Chain 與文件對話的方式：RetrievalQA, ConversationalRetrievalChain"
        ],
        "實作篇：不只娛樂，還能玩樂 - 實作 YoutubeGPT": [
          "專案介紹",
          "套件安裝與環境設置",
          "讀取 Youtube 影片",
          "字幕呢？你需要的是 Whisper",
          "該呼叫 Chain 上場了：load_summarize_chain",
          "想要其他總結方式？你需要的是 Prompt"
        ],
        "實作篇：解放 Excel 表格 - 實作表格GPT": [
          "專案介紹",
          "套件安裝與環境設置",
          "讀取 CSV 檔案",
          "存放向量至向量資料庫 Chroma",
          "建構 QAChain 進行問答",
          "建構 Agent 進行問答"
        ],
        "基礎篇：更上一層樓，重新認識 Agent": [
          "章節起頭：重新認識 Agent",
          "Agent 基礎認識",
          "慢著，Agent 與 Chain 有何不同？",
          "認識 Agent 種類 - zero shot",
          "認識 Agent 種類 - Chat Conversational ReAct",
          "認識 Agent 種類 - ReAct Doc store",
          "自定義 Tool - 利用 BaseTool 實作",
          "自定義 Tool - 用於接收多個參數",
          "添加 HuggingFace model 作為 Tool 使用 - BLIP 模型做示範"
        ]
      },
      "requirements": [
        "保持一顆好奇的心",
        "假定參與學員對於 LLM 應用開發是感興趣的",
        "這並非全然的初級課程，希望你有開發 python 應用程式的經驗",
        "熟練使用一些工具，例如：Git, Colab, pip 等"
      ],
      "description": "歡迎來到 Udemy 課程上第一堂中文 LangChain 課程！\n\n\n本全面的課程旨在教授你如何運用 LangChain 力量並實踐於 LLM 領域。此課程將為您提供所需的技能和知識，好為各種主題開發生活中常見的的 LLM 解決方案。\n\n\n在本課程中，你將從零開始，使用 LangChain 打造多個務實的 LLM 應用程式。從跟你的文件聊天、總結 Yotube 影片內容到使用 Agent 跟 Excel 聊天。你將透過大量練習以及打造實際專案，了解各種 LLM 解決方案。\n\n\n本課程涵蓋的主題包括：\n介紹 LangChain\nLangChain 必備模組介紹\nPrompt: PromptTemplate\nLLM: OpenAI\nChain: LLMChain、RetrievalQA Chain、QA Chain\nAgent: create_csv_agent\nTools: llm_math, serpapi\nMemory: conversationalBufferMemory\n向量資料庫：Pinecone、Chroma\n\n\n本課程實作專案主題：\n與你的文件聊天，實作 DocGPT\n總結 Youtube 談話資訊，實作 YoutubeGPT\n\n\n\n\n在整個課程中，您將進行實作練習和實際項目，以加深您對所涵蓋概念和技術的理解。課程結束時，您將熟練使用 LangChain 為各種用途創建功能強大，高效且多功能的 LLM 應用程式。",
      "target_audience": [
        "想學習如何使用 LLM 構建聊天機器人的軟體開發人員",
        "有興趣創建聊天機器人以提高客戶參與度的企業主",
        "希望更多地了解自然語言處理和該領域最新工具和技術的語言愛好者"
      ]
    },
    {
      "title": "เรียนรู้ AI: Deep Learning ด้วย Python",
      "url": "https://www.udemy.com/course/ai-deep-learning-python/",
      "bio": "เน้นการเรียนรู้ด้วยการปฏิบัติ เรียนแบบ Step-by-step เหมาะสำหรับผู้เริ่มต้นศึกษา Deep Learning",
      "objectives": [
        "เรียนแบบทั่วไป จะเรียนที่ไหนก็ได้ แต่ถ้าเรียนแบบให้เข้าใจ เป็น Step ขอแนะนำคอร์สนี้",
        "เรียนรู้ระบบเครือข่ายประสาทประดิษฐ์ (Artificial Neural Network)",
        "ใช้ TensorFlow Keras",
        "หลักการ Deep Learning",
        "Gradient Descent และ Optimizer",
        "เรียนรู้ Convolutional Neural Network: CNN สำหรับงาน Computer Vision",
        "การเพิ่มประสิทธิภาพ Model",
        "ใช้งาน CPU และ GPU บน Colab",
        "การ Train สร้าง Model การบันทึกและการโหลดใช้งาน Model",
        "การติดตั้งและใช้งาน GPU เพื่อเพิ่มความเร็วการประมวลผล"
      ],
      "course_content": {
        "Introduction": [
          "รู้จักผู้สอน",
          "แนะนำคอร์ส",
          "เบื้องต้นเกี่ยวกับ AI, Machine Learning และ Deep Learning"
        ],
        "การติดตั้งเครื่องมือ (โปรแกรม) และเตรียมความพร้อม + Source code": [
          "การติดตั้งโปรแกรมและเตรียมความพร้อม + Download Source code",
          "รู้จักกับเครื่องมือ Jupyter",
          "การเปิด Jupyter",
          "การใช้งาน Jupyter",
          "การใช้งาน Colab",
          "การใช้งานไฟล์บน Colab",
          "การใช้ VSCode กับ Jupyter"
        ],
        "เรียนลัด/ทบทวน การเขียนโปรแกรม Python (Crash Course)": [
          "เรียนลัด Python (Crash course) ระดับเบื้องต้น",
          "เงื่อนไข การวนรอบ และการแสดงผล",
          "ข้อมูล List & Tuple",
          "ข้อมูล Dictionary",
          "ฟังก์ชัน (Function)",
          "ไลบรารี",
          "การติดตั้งไลบรารี"
        ],
        "ข้อมูล": [
          "ชนิดข้อมูลสำหรับ Machine Learning และ Deep Learning",
          "การใช้ไลบรารี Numpy",
          "Pandas: เกี่ยวกับไลบรารี",
          "Pandas: ใช้งานไลบรารี สร้างข้อมูลและอ่านไฟล์ บันทึกไฟล์",
          "Pandas: การเข้าถึงข้อมูลและการพล็อต"
        ],
        "Data Visualization": [
          "Data Visualization",
          "การพล็อตข้อมูลด้วย Matplotlib",
          "การพล็อตข้อมูลด้วย Seaborn"
        ],
        "Machine Learning 101": [
          "Machine Learning 101",
          "สมการเส้นตรง",
          "การเขียนโปรแกรมปกติทั่วไป",
          "การเขียนโปรแกรมโดยใช้ Machine Learning",
          "การจำแนก (Classification)",
          "Workshop 1: Decision Tree Model จำแนก มะนาว ส้ม",
          "Workshop 2: Decision Tree Model จำแนกผลไม้ 3 ชนิด (3 Classes)",
          "Workshop 3: Decision Tree Model มี 2 Features 2 Class",
          "Workshop 3: Decision Tree Model มี 2 Features 3 Class"
        ],
        "Neural Network เบื้องต้น": [
          "สมการเส้นตรง Linear Equation",
          "เกี่ยวกับเครือข่ายประสาทประดิษ (Artificial Neural Network)",
          "Workshop: Simple Neuron/Perceptron",
          "Workshop: Logic Gates ด้วย Neuron",
          "Activation Functions",
          "สรุป"
        ],
        "เครือข่าย Neural Network หลายชั้น (Multilayer Perceptron)": [
          "เครือข่าย Neural Network หลายชั้น (Multilayer Perceptron)",
          "Workshop: สร้าง Neuron/Perceptron โดยใช้ Scikit-learn",
          "Workshop: สร้าง Multilayer Perceptron โดยใช้ Scikit-learn",
          "Workshop: สร้าง Multilayer Perceptron จำแนกผลไม้ 2 Class",
          "Worshop: สร้าง Multilayer Perceptron จำแนกผลไม 3 class",
          "Workkshop: MLP Model จำแนกชนิดดอก Iris",
          "Workshop: Missing Values ทำให้เกิดปัญหาอย่างไรกับ Neural Network",
          "สรุป"
        ],
        "การใช้ TensorFlow Keras สำหรับ Deep Larning": [
          "TensorFlow & Keras; Open-source Deep Learning Platform",
          "การติดตั้ง",
          "การปรับสเกลค่า Feature (Feature scaling)",
          "Workshop 1: Neural Network ด้วย TensorFlow แบบ Binary Classification (2 Class)",
          "Workshop 2: การ Save Model และส่วนที่เกี่ยวข้องไว้ใช้งาน",
          "Workshop 3: การโหลด Model ที่ Save ไว้ มาใช้งาน"
        ],
        "รายละเอียดการสร้างและการ Train Model TensorFlow": [
          "เอกสารข้อมูลเพิ่มเติมจาก keras.io",
          "Epoch & iteration",
          "Loss & Accuracy Curve",
          "Param"
        ]
      },
      "requirements": [
        "ความรู้พื้นฐานคอมพิวเตอร์",
        "ถ้ามีความรู้พื้นฐาน Machine Learning มาบ้างจะดีมาก แต่ถ้าไม่มีก็ค่อย ๆ ศึกษาจาก Course นี้ได้"
      ],
      "description": "คอร์สนี้เหมาะสำหรับผู้เริ่มต้นศึกษา AI: Deep Learning เพื่อพัฒนาระบบ AI (Artificial Intelligence) หรือปัญญาประดิษฐ์ ด้วยภาษา Python เน้นการเรียนรู้ด้วยการปฏิบัติ Workshop พร้อมโค้ดตัวอย่างและคำอธิบาย Step-by-step (คณิตศาสตร์ไม่มาก ใช้วิธีอธิบายด้วยภาพเพื่อให้เข้าใจง่ายขึ้น)\n\n\nเนื้อหาประกอบด้วย การติดตั้งเตรียมความพร้อม เข้าใจเครือข่ายประสาทประดิษฐ์ (Artificial Neural Network: ANN) เครือข่ายแบบหลายชั้น (Multi-layer Perceptron) หลักการ Deep Learning กลไก Gradient Descent กระบวนการ Train หรือการสอน การใช้ TensorFlow Keras สร้าง Model การวิเคราะห์กราฟผลของการ Train การสร้าง Model การเพิ่มประสิทธิภาพ Model อัลกอริทึมเพิ่มความเร็วในการ Train และเรียนรู้ Convolutional Neural Network: CNN สำหรับงาน Computer Vision การบันทึกและโหลดใช้งาน Model ที่ Train เรียบร้อยแล้ว การติดตั้งและใช้งาน GPU",
      "target_audience": [
        "นักเรียน นักศึกษา หรือผู้สนใจศึกษาเทคโนโลยีเกี่ยวกับ AI",
        "นักวิจัย นักพัฒนา นักเรียน นักศึกษา ที่ทำโปรเจคด้าน AI ด้วย Deep Learning"
      ]
    },
    {
      "title": "医師が教えるR言語での医療データ分析入門 -発展編(アプリ)：Shinyを利用して分析結果をアプリで共有しよう！",
      "url": "https://www.udemy.com/course/r-for-meds-shiny-application/",
      "bio": "Shinyを使ってR言語で行ったデータ分析を共有しよう。アプリケーションの作成の基本的な部分から、Shinyapps ioへの公開までカバー。",
      "objectives": [
        "Shinyを利用した基本的なデータ可視化アプリケーションの作成方法",
        "Shinyapps io へのアプリケーションの公開方法",
        "Shinyを利用したアプリケーションの応用的な使い方",
        "Webスクレイピングの基本的な方法",
        "Webスクレイピングの基本を利用して厚生労働省のHPから実際にR言語でデータを取得する方法",
        "厚生労働省で公開されているデータを分析可能な形に前処理を行う方法の例"
      ],
      "course_content": {
        "紹介": [
          "コースの紹介"
        ],
        "コースの資料": [
          "コース資料のダウンロード"
        ],
        "足し算アプリの作成を通して学ぶShinyの基本": [
          "セクション1で作成するアプリの全体像1ーミニアプリ、セクション課題アプリ",
          "Shinyとは？ホームページでデモを提示",
          "インターネットの構造の説明とShinyの利点",
          "Shinyの構造の説明:全体像",
          "Shinyの構造の説明：uiの構造",
          "補足:RStudioの起動、Project作成",
          "Shinyの構造：ui:HTML",
          "Shinyの構造：ui:アプリの立ち上げ",
          "Shinyの構造の説明：uiの記載：ウイジェット",
          "Shinyの構造の説明：uiの記載：cssとbootstrapPage()",
          "Shinyの構造の説明：uiの記載：fluidPage()",
          "Shinyの構造の説明：uiの記載：課題ー画面の要素の配置",
          "Shinyの構造の説明：ui->server:UIからサーバーへのデータの受け渡し",
          "Shinyの構造の説明：ui->server:UIからサーバーへのデータの受け渡し1-実践",
          "Shinyの構造の説明：server->ui : UIにサーバーからのデータを表示する1",
          "Shinyの構造の説明：server->ui : UIにサーバーからのデータを表示する2",
          "Shinyの構造の説明：server->ui : UIにサーバーからのデータを表示する3",
          "Shinyの公開方法:shinyapps.ioの紹介",
          "Shinyの公開方法:shinyapps.ioへの会員登録",
          "Shinyの公開方法:RStudioから登録"
        ],
        "感度特異度アプリを作成する": [
          "補足：感度と特異度の簡単な説明",
          "補足：検査前確率と検査後確率の簡単な説明",
          "補足：感度、特異度、検査前確率、検査後確率を文字式で",
          "感度特異度アプリの構造：アプリのUIとレイアウトについて考える",
          "感度特異度アプリの構造：fluidRowとcolumn",
          "感度特異度アプリのUIの配置",
          "感度特異度アプリのウイジェットの紹介",
          "感度特異度アプリ:sliderInputの紹介",
          "感度特異度アプリ：server関数の動作のイメージ",
          "感度特異度アプリ：output$hyouの作成",
          "感度特異度アプリ：output$hyouの表示",
          "感度特異度アプリ:グラフの作成",
          "感度特異度アプリ：グラフを作るスクリプトの解説",
          "感度特異度アプリ:グラフの描画",
          "感度特異度アプリ:結果の表の描画",
          "感度特異度アプリ:アプリのスリム化",
          "感度特異度アプリ:スリム化したアプリの構造",
          "感度特異度アプリ:reactive関数",
          "感度特異度アプリ：reactive関数の動作の確認",
          "感度特異度アプリ：アプリの完成",
          "感度特異度アプリ：Shinyapps.ioへのデプロイ",
          "Shinyapps.ioでのエラー回避1:パッケージ",
          "Shinyapps.ioでのエラー回避1:global.Rを含んだデプロイ",
          "Shinyapps.ioでのエラー回避2:ggplot2での日本語の利用のイメージ",
          "Shinyapps.ioでのエラー回避2:shinyapps.io環境への日本語フォントのインストール"
        ],
        "オープンデータを可視化するアプリの作成:データ取得偏": [
          "Section3の概要",
          "webスクレイピングとは？",
          "データを手動でダウンロードしてみる",
          "データを自動でダウンロードしてみる",
          "rvestを利用してダウンロードする1",
          "rvestを利用してダウンロードする2",
          "rvestを利用してダウンロードする3",
          "DLしたファイルをtidyなデータにする1",
          "DLしたファイルをtidyなデータにする2",
          "DLしたファイルをtidyなデータにする3",
          "DLしたファイルをtidyなデータにする4"
        ],
        "オープンデータを可視化するアプリの作成:アプリ作成偏": [
          "Section4の概要",
          "全体像の解説",
          "SelectInputの解説",
          "選択肢の作成1",
          "uiのserver側からの操作",
          "uiの内容をサーバー側から操作する:実験",
          "選択肢の作成2",
          "simple app1 uiの作成",
          "simple app1 uiのためのサーバーロジックの作成",
          "simple app1のグラフのためのサーバーロジックの作成:イメージ",
          "simple app1のグラフの作成:値の設定",
          "simple app1のグラフの作成:plot_total-イメージ",
          "simple app1のグラフの作成:plot_total-データの作成1",
          "simple app1のグラフの作成:plot_total-データの作成2",
          "simple app1のグラフの作成:plot_total-グラフの作成",
          "simple app1のグラフの作成:plot_map",
          "simple app1のグラフの作成:plot_scatter",
          "simple app1の実装1",
          "simple app1の実装2",
          "simple app1の実装3　エラー処理",
          "simple app1の実装4",
          "simple app1の実装5",
          "simple app1の実装6",
          "simple app2のイメージ",
          "simple app2:uiの作成",
          "simple_app2:色の指定",
          "simple_app2:グラフ作成 plot_pref_age",
          "simple_app2:グラフ作成 plot_pref_pdiff",
          "simple_app2:グラフ作成 plot_pref_precise",
          "simple_app2:グラフのデータの共通化",
          "combined_app:アプリをくっつける",
          "combined_app:くっつけてみる",
          "combined_app:serverの実装",
          "アプリの完成形の機能の提示",
          "ダウンロード機能:モーダルの表示の図示",
          "ダウンロード機能：モーダルの表示",
          "ダウンロード機能:モーダルの内容の記載",
          "ダウンロード機能：モーダルの表示",
          "ダウンロード機能:ダウンロード機能の実装のイメージ",
          "ダウンロード機能：アプリへの実装のイメージ",
          "ダウンロード機能：アプリへの実装:グラフの分離",
          "ダウンロード機能：アプリへの実装:ダウンロード",
          "ダウンロード機能：アプリへの実装：Rmarkdownファイル",
          "ダウンロード機能：アプリへの実装：プログレスバーの追加",
          "まとめ"
        ],
        "オープンデータを可視化するアプリの作成:アプリ公開偏": [
          "section4の内容を確認する",
          "アップロード用にクリーニングする",
          "パワーポイントファイルをうまく描画できるようにする",
          "まとめ"
        ]
      },
      "requirements": [
        "R言語（特にTidyvetseに関係する関数）の基本的な知識",
        "RStudioの基本的な知識"
      ],
      "description": "R言語でのデータ分析を行った後に、チームで共有したい、より多くの人と共有したいと思ったことはありませんか？自分自身で細かなところまでカスタマイズできるビジネスインテリジェンスツールが欲しいと思ったことはありませんか？Shinyは、そんなニーズを満たしてくれるパッケージです。\n\n\n本コースは、ある程度R言語を触ったことがある人を対象として、次のステップにつなぐための橋渡しになることを願って作成いたしました。\nこのコースでは\n・Shinyアプリケーションの基本的な構造の理解\n・ShinyアプリケーションのReactivityについての基本的な理解\n・Shinyappsioへの公開方法\n・日本語のグラフを含んだアプリケーションの公開方法\n・2画面以上の少し複雑な構造をもったアプリケーションの作成\n・プログレスバーの表示方法\n・パワーポイントファイルでの分析結果をアプリケーションからダウンロードする方法\n等のShinyの初級～中級レベルと考えられる事項を丁寧に、サンプルコード付きで解説してあります。\n\n\nまた、厚生労働省が公開しているNDBオープンデータの特定健診のデータを、Rを利用してダウンロード（Webスクレイピング）して、前処理を行い、アプリケーションを作成して公開する例を解説しており、「動く」アプリケーションを、「実際の」データを利用しながら作成することによる習熟を目指します。",
      "target_audience": [
        "データの可視化、分析結果をチームで共有する方法を探している受講生",
        "Shinyの使い方について関心をもつR言語ユーザー"
      ]
    },
    {
      "title": "ChatGPT 2025: der ultimative Praxiskurs für Einsteiger",
      "url": "https://www.udemy.com/course/chatgpt-praxiskurs/",
      "bio": "ChatGPT & KI vom Einsteiger zum Profi + 40-Seiten eBook: Die Kunst des Promptens + Bilderstellung mit ChatGPT Dall-E",
      "objectives": [
        "Du wirst nach Abschluss des Kurses KI so gut beherrchen, dass du jede KI auch KI-gestützte Content-Generatoren (Video, Bild, Musik) locker bedienen kannst.",
        "Insgesamt wirst du in diesem Kurs ein umfassendes Verständnis von ChatGPT erlangen und lernen, wie man es in verschiedenen Bereichen und einsetzt.",
        "Du wirst lernen, wie man in ChatGPT effektiv \"promtet\" also die richtigen Befehle gibt. Dazu bekommst auch das 40-seitige eBook: Handbuch für Prompting.",
        "Du wirst lernen, wie du mit dem Bilderstellung von ChatGPT (Dall-E) beeindruckend Bilder für dein Business machst. Egal ob Flyer, Poster, Unterrichtsmaterialen",
        "Du wirst lernen, wie ChatGPT für Schule und Lehrer nützlich sein kann, um Wissen zu erweitern und Lehrmaterial zu ergänzen.",
        "Du wirst lernen, wie man ChatGPT eine Rede schreiben lässt, die sowohl informativ als auch ansprechend ist.",
        "Du wirst lernen, wie man ChatGPT für Produktbeschreibungen und SEO-Zwecke verwendet, um bessere Rankings und Resonanz zu erzielen.",
        "Du wirst lernen, wie man ChatGPT als Lexikon benutzt, um auf Informationen und Definitionen zuzugreifen.",
        "Du wirst lernen, wie man ChatGPT dazu bringt, Bücher zusammenzufassen und Rezensionen zu schreiben.",
        "Du wirst lernen, wie man ChatGPT nutzt, um Fragenkataloge für Interviews, Besprechungen und andere Anlässe zu erstellen.",
        "Du wirst lernen, wie man ChatGPT dazu verwendet, Podcasts, Blogartikel und Videotexte zu erstellen, die sowohl informativ als auch unterhaltsam sind."
      ],
      "course_content": {
        "Kurseinführung: an welche Zielgruppe richtet sich der Kurs.": [
          "An wen richtet sich dieser Kurs? Welche Inhalte hat dieser Kurs?"
        ],
        "Erste Schritte - Die Anmeldung - Was weiß ChatGTP? Wie arbeitet ChatGPT?": [
          "Die Anmeldung - ChatGPT 2025 Account anlegen",
          "Was weiß ChatGPT 2025? Wie arbeitet ChatGPT?"
        ],
        "Die Benutzer Oberfläche von ChatGPT Schritt für Schritt erklärt": [
          "ChatGPT Benutzeroberfläche 2025 Teil 1",
          "ChatGPT Benutzeroberfläche 2025 Teil 2",
          "ChatGPT Benutzeroberfläche 2025 Teil 3 - update April 25",
          "ChatGPT Die Funktion Erinnerungen - die Funktion Archivierung",
          "ChatGPT Der Button \"GPTs erkunden\"",
          "ChatGPT Unterschiede zwischen Gratis-Version und Bezahl-Version"
        ],
        "Der Prompt - die \"Befehle\" an ChatGPT . Mit ChatGPT richtig kommunizieren.": [
          "Meister des Prompts: Effektive Kommunikation mit ChatGPT für bessere Antworten."
        ],
        "1000+ Beispiel- & Starterprompts: 1000 Ideen für den Soforteinstieg in ChatGPT": [
          "100+ Prompts Business & Unternehmen (PDF in den Materialien)",
          "100+ Prompts Social Media (PDF in den Materialien)",
          "100+ Prompts persönliche Finanzen (PDF in den Materialien)",
          "100+ Prompts Persönlichkeitsentwicklung (PDF in den Materialien)",
          "100+ Prompts eigene Produktivität & Effizienz (PDF in den Materialien)",
          "100+ Prompts Kreativität (PDF in den Materialien)",
          "100+ Prompts Bildung und Schule (PDF in den Materialien)",
          "100+ Prompts Wohlbefinden & Selbstfürsorge (PDF in den Materialien)",
          "100+ Prompts Gesundheit, Beauty & Wellness (PDF in den Materialien)"
        ],
        "Schule & Lehrer - wie ChatGPT den Schulalltag erleichtert": [
          "Schule & Lehrer - die Revolution im Klassen - und im Lehrerzimmer"
        ],
        "ChatGPT als Übersetzungsprogramm": [
          "ChatGPT als Übersetzer"
        ],
        "Von ChatGPT eine Rede schreiben lassen": [
          "Von ChatGPT eine Rede schreiben lassen - zu jedem Anlass - zu jedem Thema."
        ],
        "Mit ChatGPT einen Fragenkatalog erstellen": [
          "Fragenkatalog für Journalisten, Coaches, Berater, Konsumenten, Unternehmer...."
        ],
        "ChatGPT als Lexikon - besser als Google, schneller als Wikipedia": [
          "ChatGPT als Nachschlagewerk nutzen"
        ]
      },
      "requirements": [
        "Du brauchst einen PC, einen Internetanschluss.",
        "Einfache PC & Internetkennnisse. Sonst sind für diesen Kurs sind keine Vorkenntnisse nötig."
      ],
      "description": "ChatGPT Masterclass 2025: Dein Einstieg in ChatGPT für Anfänger\nWillst du ChatGPT endlich richtig nutzen und smarter arbeiten?\nDann ist diese ChatGPT Masterclass für Anfänger genau der richtige Startpunkt für dich!\nWas erwartet dich in der ChatGPT Masterclass?\nLernen durch Praxis\nDu lernst Schritt für Schritt, wie du ChatGPT als Anfänger sicher einsetzt – von ersten einfachen Fragen bis hin zur Erstellung kompletter Bücher, Werbetexte und Marketinginhalte.\nPerfektes Prompting\nMeistere die Kunst des richtigen Promptings und erhalte präzisere, effektivere Antworten.\nGoogeln war gestern – jetzt wird intelligent mit ChatGPT gepromptet!\nEffizienz-Boost\nNutze ChatGPT für Bildung, Kommunikation, Marketing und Content-Erstellung und optimiere deine Arbeitsabläufe nachhaltig.\nDein exklusiver Bonus zur ChatGPT Masterclass\nMit deinem Kurszugang erhältst du zusätzlich das exklusive eBook:\n\n„Handbuch für Prompting – Lerne die Kunst des Promptings & nutze das volle Potenzial deiner KI“ mit über 100 Lern- und Übungsprompts.\n\n\nDamit wirst du in kürzester Zeit vom Anfänger zum ChatGPT-Profi!\nDein perfekter Einstieg in ChatGPT für Anfänger\n\n\nKeine Vorkenntnisse? Kein Problem!\n\nWir starten bei Null und begleiten dich Schritt für Schritt:\n\n\nChatGPT-Konto erstellen und erste Nutzungsschritte\nGrundlagen des Promptings verstehen\nKI als persönlichen Assistenten effektiv einsetzen\nPraxisanwendungen in der ChatGPT Masterclass\nLerne, wie du ChatGPT in vielen Bereichen einsetzt:\n\n\nChatGPT in Schule und Bildung: Von Lehrer-Tools bis Hausaufgabenhilfe\nTexte, Reden & E-Mails schreiben: Schnell, fehlerfrei und professionell\nProduktbeschreibungen & Werbetexte erstellen: Ideal für Marketing und Social Media\nBücher und eBooks schreiben mit ChatGPT: Deine Ideen werden Realität\nKI-Content erstellen: Bilder, Musik und vieles mehr für dein Business oder Projekt. lerne mit der ChatGPT Bilderzeugung (Dall-E) professionelle Bilder / Illustrationen zu erstellen.\nKursübersicht – Was du in der ChatGPT Masterclass lernst:\nEinführung\nDein Weg mit ChatGPT – Überblick und Ziele\nErste Schritte\nKonto erstellen, ChatGPT verstehen, Chrome-Erweiterungen nutzen\nPrompting meistern\nSo schreibst du klare Prompts für bessere Antworten\nSchule & Bildung\nChatGPT als Lern- und Lehrassistent\nReden & Texte schreiben\nVon Präsentationen bis Redemanuskripten\nFragenkataloge erstellen\nPerfekt für Coaches, Berater und Journalisten\nChatGPT als Nachschlagewerk\nFakten und Wissen in Sekunden abrufen\nZusammenfassungen & Buchanalysen\nWichtige Inhalte extrahieren und zusammenfassen\nBriefe & E-Mails fehlerfrei schreiben\nProfessionelle Kommunikation leicht gemacht\nSocial Media & Podcast-Content erstellen\nInhalte blitzschnell generieren\nBuch schreiben mit ChatGPT\nVon der Idee bis zur Veröffentlichung\nBilderstellung mit ChatGPT (DALL-E)\nProfi-Prompts für Bilder und Visualisierungen\n\n\n\n\nWerde ChatGPT-Profi!\nDieser Kurs ist der perfekte Start, wenn du:\nChatGPT für Anfänger lernen möchtest,\nbessere Ergebnisse bei deinen Prompts erzielen willst,\nsmarter arbeiten und KI kreativ für Bildung, Business und Content einsetzen möchtest.\nMelde dich jetzt an und entdecke das volle Potenzial von ChatGPT – mit der ChatGPT Masterclass 2025!\n\n\n\n\nBonus: Meister des Promptings – Dein 40-seitiges eBook zum Nachschlagen\n\n\nDas Prompting-Buch hat folgenden Inhalt:\n\n\nEinführung in GPT und Prompting 5\nWas ist GPT? 5\nWas ist ein Prompt? 5\nGrundlagen des Prompting 6\nOffene vs. geschlossene Prompts 6\nKontextbezogenes Prompting 7\nErweiterte Techniken des Prompting 8\nVerwendung von \"Rollen\" im Prompting 8\nWas ist eine \"Rolle\"? 8\nWie verwendest du \"Rollen\"? 8\nWarum sind \"Rollen\" nützlich? 9\nBeispiele: 9\nFragen in unterschiedlichen Formen stellen 10\nWarum ist die Frageformulierung wichtig? 10\nBeispiele für unterschiedliche Frageformulierungen 10\nTipps zur Frageformulierung 11\nAnweisungen zur Antwortlänge 11\nWie gibst du Anweisungen zur Antwortlänge? 12\nWarum sind Anweisungen zur Antwortlänge nützlich? 12\nBeispiele 12\nVerwendung von Negativen 13\nWas sind Negative? 13\nWie verwendest du Negative? 13\nWarum sind Negative nützlich? 14\nBeispiele 14\nVerwendung von Vergleichen 14\nWas sind Vergleiche? 14\nWie verwendest du Vergleiche? 15\nWarum sind Vergleiche nützlich? 15\nBeispiele 15\nVerwendung von Zeitrahmen 16\nWas sind Zeitrahmen? 16\nWie verwendest du Zeitrahmen? 16\nWarum sind Zeitrahmen nützlich? 17\nBeispiele 17\nKontextuelle Hinweise 17\nWas sind kontextuelle Hinweise? 17\nWie verwendest du kontextuelle Hinweise? 18\nWarum sind kontextuelle Hinweise nützlich? 18\nUnterschiedliche Arten von Kontext: 19\nThemenkontext: 19\nBeispiele: 19\nRäumlicher Kontext: 19\nBeispiele: 19\nZielgruppenkontext: 20\nBeispiele: 20\nZweckkontext 20\nBeispiele: 20\nEmotionale Kontext 21\nBeispiele: 21\nFormalitätskontext 21\nBeispiele: 21\nAnwendungs- oder Branchenkontext 22\nBeispiele: 22\nPerspektivenkontext 22\nBeispiele: 22\nFormatkontext - Formatierungsmöglichkeiten in ChatGPT 23\nListe: 23\nTabelle: 23\nAnalogie: 24\nFrage und Antwort: 24\nDialog: 24\nRätsel: 24\nAnleitungen: 25\nDiagramm oder Zeichnung: 25\nSzenario oder Fallstudie: 25\nStimmungskontext: 25\nFröhlicher Stimmungskontext: 26\nTrauriger Stimmungskontext: 26\nSpannender Stimmungskontext: 26\nDie Tonalität: 27\nBeispiele: 27\nNutzung der Iterativität 29\nWas ist Iterativität? 29\nWie nutzt du die Iterativität? 29\nWarum ist die Iterativität nützlich? 29\nBeispiele 30\nPrompting für spezifische Zwecke 31\nKreative Prompts 31\nBeispiele für kreative Prompts: 31\nInformative Prompts 31\nBeispiel für informativen Prompt: 32\nForschungsbezogene Prompts 32\nBeispiel für forschungsbezogene Prompts 32\nFehlervermeidung und Lösungsstrategien 33\nKlarheit und Präzision: 33\nWiederholungen von ChatGPT: 34\nUnpräzise Antworten: 34\nUnverständnis: 34\nÜberprüfen der Informationen: 34\nKleiner Tipp: 34\nZusammenfassung und nächste Schritte 35\nDie Zusammenfassung der Schlüsselkonzepte umfasst: 35\nVerständnis des Modells: 35\nVerwendung von Kontext: 35\nVermeidung von Fehlern: 35\nErweiterte Prompt-Techniken: 35\nSpezifisches Prompting: 36\nDein Promting verbessern - nächste Schritte 36\nÜben und Experimentieren: 36\nWeiterbildung: 36\nEntwicklung einer Strategie: 36\nErforschung verschiedener Modelle: 37\nTeilnahme an KI-Communities: 37\nEinsatz von KI-Tools und -Plattformen: 37\nDie Geschichte von Eddie Sterling 38",
      "target_audience": [
        "Studenten: Diejenigen, die nach Unterstützung bei Hausaufgaben, Recherche oder dem Verständnis von Lernmaterial suchen.",
        "Lehrer und Dozenten: Pädagogen, die nach einer kreativen Methode suchen, um Unterrichtsmaterial zu ergänzen und den Lernprozess für ihre Schüler zu verbessern.",
        "Online-Verkäufer: Personen, die auf Plattformen wie Amazon, einem eigenen Shop oder einer eigenen Website verkaufen und ihre Produktbeschreibungen und SEO optimieren möchten.",
        "Autoren und Redakteure: Schreibende, die Inspiration suchen oder Unterstützung beim Erstellen von Texten, Zusammenfassungen und Rezensionen benötigen.",
        "Journalisten und Interviewer: Personen, die Fragenkataloge für Interviews und Besprechungen erstellen möchten.",
        "Redner und Moderatoren: Personen, die Reden oder Präsentationen vorbereiten und ansprechende Inhalte erstellen möchten.",
        "Geschäftsleute und Unternehmer: Personen, die professionelle Kommunikation für E-Mails, Briefe oder Geschäftsdokumente benötigen.",
        "Content-Ersteller: Blogger, Podcaster und YouTuber, die nach Unterstützung bei der Erstellung von qualitativ hochwertigen Inhalten für ihre Zielgruppe suchen.",
        "Personen, die ihre Schreib- und Kommunikationsfähigkeiten verbessern möchten: Menschen, die an persönlicher oder beruflicher Weiterentwicklung interessiert sind und ihre Schreib- und Kommunikationsfähigkeiten ausbauen möchten."
      ]
    },
    {
      "title": "世界10万人が学んだ講師が教えるAIエージェント開発(日本語字幕)",
      "url": "https://www.udemy.com/course/the-complete-agentic-ai-engineering-course-japanese/",
      "bio": "30日で8つのアプリを開発。AIエージェント未経験から、OpenAI Agents SDK、CrewAI、LangGraph、AutoGen、MCPをマスター。",
      "objectives": [
        "エージェントAIを現実世界のビジネス課題に応用する方法",
        "実績のあるベストプラクティスなデザインパターンを用いて、エージェントソリューションを設計するスキル",
        "「ツール」「構造化出力」「メモリ」といったエージェントAIの基本要素を用いて、複数のLLMを連携させる方法",
        "CrewAIを用いてコードを記述・実行するエージェントなどの自律型エージェントアプリケーションを作成し、OpenAI Agents SDKでエージェント製品を迅速に構築するスキル",
        "LangGraphを用いて、堅牢で再現性の高いエージェントソリューションを構築するスキル",
        "AutoGen AgentChatとAutoGen Coreを使いこなし、エージェントAIの最前線を開拓するスキル",
        "Anthropic社のモデルコンテキストプロトコル（MCP）によって利用可能になる、オープンソースのツールやリソースの広範な能力を解放する方法",
        "8つの実践的なプロジェクト経験を活かし、画期的な商用ソリューションを提供するスキル"
      ],
      "course_content": {
        "1週目": [
          "1日目 - 自律型AIエージェントデモ：n8nを使ったスマートホームデバイスの制御",
          "1日目 - AIエージェントフレームワーク解説：OpenAI SDK、CrewAI、LangGraph、AutoGen",
          "1日目 - エージェント開発環境のセットアップ：Cursor IDE、UV、APIオプションの理解",
          "1日目 - WindowsでのAI開発環境セットアップ：Git、Cursor IDE、UVパッケージマネージャー",
          "1日目 - MacでのAIプロジェクトセットアップ：GitHub、Cursor IDE、OpenAI APIキー",
          "1日目 - 初めてのエージェントAIワークフロー構築：OpenAI APIを使ったステップバイステップガイド",
          "1日目 - エージェントAI入門：自律性を持つマルチステップLLMワークフローの作成",
          "2日目 - 効果的なエージェントの構築：LLMの自律性とツール連携の解説",
          "2日目 - 堅牢なAIシステムを構築するための5つの必須LLMワークフローデザインパターン",
          "2日目 - LLMアプリケーション設計におけるエージェントパターンとワークフローパターンの理解",
          "3日目 - 複数LLMのオーケストレーション：GPT-4o、Claude、Gemini、DeepSeekの比較",
          "3日目 - マルチLLM API連携：OpenAI、Anthropic、その他のモデルの比較",
          "3日目 - LLM APIの比較：OpenAIクライアントライブラリでClaude、Geminiなどを利用する",
          "3日目 - マルチモデルオーケストレーション：AIの応答を評価するシステムの構築",
          "3日目 - エージェントパターンとツール利用の連携：AI構築に不可欠な要素",
          "4日目 - AIエージェントフレームワークの比較：LLMオーケストレーションにおけるシンプルさとパワー",
          "4日目 - リソース vs. ツール：エージェントAIでLLMの能力を強化する2つの方法",
          "4日目 - GradioとOpenAIであなたのように振る舞うWebチャットボットを構築する",
          "4日目 - Geminiを使ってGPT-4の応答を評価する：マルチLLMパイプライン",
          "4日目 - エージェントLLMワークフローの構築：リソース、ツール、構造化出力",
          "5日目 - あなたのキャリアの分身を構築：LLMの関数呼び出しとプッシュ通知",
          "5日目 - LLMのツール呼び出しを解明：関数リクエストの処理と実行方法",
          "5日目 - AIアシスタントの構築：未知の質問を処理するためのツールの実装",
          "5日目 - AIエージェントの作成とデプロイ：チャットループからHuggingFace Spacesまで",
          "5日目 - キャリア会話チャットボットをGradioにデプロイする",
          "5日目 - 基礎週間の総括：APIとツールで完全なAIエージェントを構築する"
        ],
        "2週目": [
          "1日目 - 非同期Pythonの理解：OpenAI Agents SDKの基礎",
          "1日目 - OpenAI Agents SDKの基礎：エージェントの作成、トレース、実行",
          "1日目 - OpenAI Agents SDK入門：Agent、Runner、Traceクラスの概要",
          "1日目 - Vibe Coding：LLMで効率的にコードを生成するための5つの必須テクニック",
          "1日目 - OpenAI Agents SDK：AI開発のためのコアコンセプトの理解",
          "2日目 - SendGridでAIセールスエージェントを構築：Agent SDKでのツールと連携",
          "2日目 - 並行LLM呼び出し：並列エージェント実行のためのAsyncioの実装",
          "2日目 - エージェントをツールに変換する：階層的なAIシステムの構築",
          "2日目 - エージェントの制御フロー：ハンドオフとエージェント・アズ・ツールの使い分け",
          "2日目 - 関数呼び出しからエージェントの自律性へ：OpenAI SDKによるセールスオートメーション",
          "2日目 - ビジネス向けエージェントAI：インタラクティブなセールスアウトリーチツールの作成",
          "3日目 - マルチモデル連携：OpenAIエージェントでGemini、DeepSeek、Grokを使用する",
          "3日目 - 堅牢なAIエージェントシステムのためのガードレールと構造化出力の実装",
          "3日目 - 実践におけるAIセーフティ：LLMエージェントアプリケーションのためのガードレールの実装",
          "4日目 - 深層リサーチエージェントの構築：OpenAIのWeb検索ツールの実装",
          "4日目 - プランナーエージェントの構築：AIにおけるPydanticによる構造化出力の活用",
          "4日目 - GPT-4エージェントと非同期タスクによるエンドツーエンドのリサーチパイプライン構築",
          "4日目 - 深層リサーチエージェントの構築：AsyncIOによる並列検索",
          "5日目 - Gradio UI実装によるモジュール型AIリサーチシステムの構築",
          "5日目 - 深層リサーチアプリ：Gradioで自律型AIエージェントを可視化・監視する",
          "5日目 - GradioとHuggingFace Spacesでスマートリサーチエージェントをデプロイする"
        ],
        "3週目": [
          "1日目 - Crew AIフレームワーク：協調型AIエージェントチームの作成",
          "1日目 - Crew AIフレームワーク解説：エージェント、タスク、処理モードのチュートリアル",
          "1日目 - Crew AIとLightLLM：複数LLMを連携させる柔軟なフレームワーク",
          "1日目 - Crew AIチュートリアル：GPT-4o miniを使ったディベートプロジェクトのセットアップ",
          "1日目 - Crew AIと複数LLMでAIディベートシステムを作成する方法",
          "1日目 - CrewAIでAIディベートシステムを構築：異なるLLMの比較",
          "2日目 - Crew AIプロジェクトの構築：ツール、コンテキスト、Google検索連携",
          "2日目 - Crew.aiでマルチエージェント金融リサーチシステムを構築する",
          "2日目 - Web検索でAIエージェントを強化：知識のカットオフ問題を解決する",
          "3日目 - Crew AIで株式ピッカーを構築：投資のためのマルチエージェントシステム",
          "3日目 - Crew AIでのPydantic出力の実装：株式ピッカーエージェントチュートリアル",
          "3日目 - Crew AIのカスタムツール開発：JSONスキーマとプッシュ通知",
          "4日目 - Crew AIのメモリ：AIエージェントのためのベクトルストレージとSQL実装",
          "4日目 - コーディングタスクのためのCrew AI：Pythonコードを生成・実行するエージェント",
          "4日目 - Pythonを記述するAIエージェントの作成：Codaによる実践的な実装",
          "5日目 - AIチームの構築：協調開発のためのCrew AIの設定",
          "5日目 - 株式取引フレームワークのための協調型AIエージェント開発",
          "5日目 - GPT-4oとClaudeを使って取引アプリケーションを構築する",
          "5日目 - 単一モジュールから完全なシステムへ：高度なCrewAIテクニック"
        ],
        "4週目": [
          "1日目 - LangGraph解説：堅牢なAIエージェントを実現するグラフベースアーキテクチャ",
          "1日目 - LangGraph解説：フレームワーク、Studio、Platformコンポーネントの比較",
          "1日目 - LangGraphの理論：高度なエージェントシステムを構築するためのコアコンポーネント",
          "2日目 - LangGraph深掘り：グラフベースのエージェントワークフローにおける状態管理",
          "2日目 - LangGraphをマスターする：状態オブジェクトの定義とリデューサーの使用方法",
          "2日目 - LangGraphの基礎：ノード、エッジ、ワークフローのステップバイステップ作成",
          "2日目 - LangGraphチュートリアル：グラフ構造を持つOpenAIチャットボットの構築",
          "3日目 - LangGraph上級チュートリアル：スーパーステップとチェックポイント機能の解説",
          "3日目 - LangsmithのセットアップとLangGraphアプリケーション用カスタムツールの作成",
          "3日目 - LangGraphのツール呼び出し：条件付きエッジとツールノードの操作",
          "3日目 - LangGraphのチェックポイント機能：会話間でメモリを維持する方法",
          "3日目 - SQLiteによる永続的AIメモリの構築：LangGraphの状態管理",
          "4日目 - LangGraphとPlaywrightの連携：WebブラウジングAIエージェントの作成",
          "4日目 - AIウェブアシスタントの作成：Playwright、LangChain、Gradioの実装",
          "4日目 - LLM評価者エージェント：構造化出力によるフィードバックループの作成",
          "4日目 - LLMフィードバックループの作成：LangGraphでのワーカー・評価者パターンの実装",
          "4日目 - LangGraph、Gradio、ブラウザオートメーションでAIサイドキックを構築する",
          "5日目 - エージェントAI：アシスタントにWeb検索、ファイルシステム、Python REPLを追加する",
          "5日目 - LangChainツール連携：強力なAIサイドキックをゼロから構築する",
          "5日目 - AIワークフローの作成：グラフビルダーとノード間通信技術",
          "5日目 - Gradioアプリで状態管理を使い、独立したユーザーセッションを作成する",
          "5日目 - AIフィードバックループの内部：AIがエラーを評価・修正する仕組みを見る",
          "5日目 - AIアシスタントのアップグレード：メモリ、明確化の質問、カスタムツール"
        ],
        "5週目": [
          "1日目 - Microsoft Autogen 0.5.1：初心者のためのAIエージェントフレームワーク解説",
          "1日目 - AutoGenと他のエージェントフレームワークの比較：機能とコンポーネント",
          "1日目 - AutoGen Agent Chatチュートリアル：ツール作成とデータベース連携",
          "1日目 - AIの必須コンポーネント：モデル、メッセージ、エージェントの解説",
          "2日目 - 高度なAutogen Agent Chat：マルチモーダル機能と構造化出力",
          "2日目 - AutoGenとLangchainでプライマリーエージェントと評価者エージェントを実装する",
          "2日目 - ヘッドレスWebスクレイピングチュートリアル：AutoGenでのMCPサーバーフェッチ連携",
          "3日目 - AutoGen Core：分散エージェント通信のバックボーン",
          "3日目 - Autogen Coreでのエージェント通信：メッセージハンドラとディスパッチ",
          "3日目 - AutoGenCoreのエージェント登録とメッセージハンドリング：実践例",
          "3日目 - AutoGenCoreスタンドアロンエージェント：GPT-4oとLlamaでじゃんけん",
          "4日目 - Autogen Core分散ランタイム：アーキテクチャとコンポーネントの解説",
          "4日目 - AutoGen CoreとgRPCランタイムで分散AIエージェントを実装する",
          "4日目 - 分散エージェントシステムの構築：AutoGenのクロスプロセス通信",
          "5日目 - AutoGenで他のエージェントを記述・デプロイする自律型エージェントの作成",
          "5日目 - Autogen Coreとテンプレートによるエージェント間メッセージングの実装",
          "5日目 - 非同期Pythonを使って連携する自律型AIエージェントの作成"
        ],
        "6週目": [
          "1日目 - モデルコンテキストプロトコル（MCP）入門：AnthropicのAIコネクタ",
          "1日目 - MCPアーキテクチャ解説：ホスト、クライアント、サーバーの理解",
          "1日目 - MCPサーバー・スタジオ：LLMを強力な外部ツールに接続する",
          "1日目 - MCPサーバーマーケットプレイス：OpenAIエージェントのための数千のツールへのアクセス",
          "2日目 - MCPサーバーの作成方法：共有可能なツールコレクションの構築",
          "2日目 - 独自のMCPサーバーを構築：PythonコードからAIアクセス可能なツールへ",
          "2日目 - OpenAIでポートフォリオ管理のためのカスタムMCPツールを実装する",
          "2日目 - OpenAIとAnthropicのツール連携のためのMCPクライアントの実装方法",
          "2日目 - MCPアーキテクチャ：LLMエージェントツールのためのクライアント・サーバーシステムの構築",
          "3日目 - MCPナレッジグラフサーバーでAIエージェントに永続メモリを追加する",
          "3日目 - MCPサーバーでBrave SearchとAlpha Vantage APIをセットアップする",
          "3日目 - 金融データAPIのセットアップ：MCPサーバー接続のクローンと設定",
          "4日目 - メモリ共有とWeb検索を備えたマルチエージェント取引システムの作成",
          "4日目 - エージェントの連携：OpenAI SDKでリサーチャーをツールに変換する",
          "4日目 - ツールを使用する取引エージェント：株式市場リサーチのためのMCP実装",
          "4日目 - OpenAI Agents SDK：マルチエージェント取引システムモジュールの開発",
          "4日目 - 高度な手法：OpenAI Agents SDKでの取引関数の実装",
          "4日目 - 回復力のある取引エージェントの構築：金融AIシステムにおけるエラーハンドリング",
          "5日目 - 最終課題の集大成：AIトレーダーのためのプッシュ通知と戦略の進化",
          "5日目 - AI取引ダッシュボード：Gradioでポートフォリオのパフォーマンスを可視化する",
          "5日目 - エージェントAIエンジニアリング：コースの結論と実社会への応用"
        ]
      },
      "requirements": [
        "PythonでのコーディングやLLMの利用経験があることが望ましいですが、本コースはバックグラウンドを問わず、非常に幅広い層の方々を対象としています。基礎的な技術やプログラミングスキルをカバーする自習用の演習も豊富に用意しています。コーディングが初めての方に必要なのはただ一つ、十分な忍耐力だけです！",
        "API利用のために少額の予算をご用意いただくと、コースを最大限に活用できますが、これは完全に任意です。API費用を一切かけずにコース全体を修了することも可能です。最先端のモデルを使用する場合、一般的な費用は5ドル未満です。もう少し費用をかけても問題ない場合は、さらに多くの機能にアクセスすることもできます。"
      ],
      "description": "字幕の表示は、視聴画面下部の再生バーにある字幕アイコンをクリックしてください。\n\n\nAIエージェントが本格的に社会で活用され始めるのは、人工知能にとってまさに歴史的な転換点と言えるでしょう。エージェントAIのエキスパートになることの重要性は、かつてないほど高まっています。そして、本コースの目的はまさにそこにあります。自律型AIエージェントを設計、構築、デプロイするためのスキルと専門知識を身につけ、新たなキャリアやビジネスチャンスを切り拓くことを目指します。\n\n\nこのコースは、エージェントAIをマスターするための6週間の集中プログラムです。まずは、実績のあるデザインパターンを用いてLLMを連携させることから始め、基礎的な専門知識を固めます。その後、週ごとにOpenAI Agents SDK、CrewAI、LangGraph、AutoGenといった新しいフレームワークを学び、スキルアップを図ります。コースの最後には、MCP（モデルコンテキストプロトコル）が切り拓く驚くべき可能性について、丸々1週間をかけて探求します。\n\n\n何よりも、このコースは実践を重視しています。私は「習うより慣れよ」が最良の学習方法だと固く信じています。ですから、ぜひ腕まくりをしてご参加ください！このコースでは、8つの実践的なプロジェクトを構築します。驚くようなもの、興味をそそられるもの、そして少しシュールなものまで様々ですが、一つだけ確かなことがあります。それは、どのプロジェクトも、エージェントAIがビジネスの世界を根底から変革する可能性を力強く示すものだということです。\n\n\nさあ、この6週間の包括的な旅に一緒に繰り出しましょう。コースを終える頃には、あなたはエージェントAIを完全にマスターしているはずです。主要なフレームワークすべてに関する専門知識を身につけ、エージェントAIの強みと陥りやすい罠にも精通しているでしょう。そして、自信を持って自律型エージェントを駆使し、現実世界のビジネス課題を解決できるようになります。その過程で、エージェントAIという驚異的で画期的なテクノロジーを存分に楽しんでください。",
      "target_audience": [
        "個人的な意見かもしれませんが、このコースは「すべての人」におすすめしたいです！AIエージェントの可能性に魅了され、強力なエージェントAIを開発するスキルを渇望しているなら、ここはまさにうってつけの場所です。プログラミング経験者には特に適していますが、あらゆるバックグラウンドの方に学んでいただけるよう設計されています。"
      ]
    },
    {
      "title": "大数据工具概览",
      "url": "https://www.udemy.com/course/oklyezpf/",
      "bio": "大数据工具入门",
      "objectives": [
        "1.了解数字化源头和大数据工具",
        "2.掌握数据生产与存储流程及工具",
        "3.掌握数据使用与展示流程及工具",
        "4.学会将业务痛点与数据使用的结合，掌握如何判断加强数据能力的方向"
      ],
      "course_content": {
        "课程导读": [
          "课程简介",
          "讲师介绍",
          "课程大纲"
        ],
        "课程内容": [
          "大数据工具介绍",
          "数据生产与存储流程",
          "数据工具的使用与流程展示",
          "如何判断加强哪些数据能力"
        ],
        "课程回顾": [
          "课后寄语"
        ]
      },
      "requirements": [
        "面向0基础学员"
      ],
      "description": "近几年里，大数据行业发展势头迅猛，故而相应的分布式产品和架构层出不穷。然而，正确而连贯的数据流对商业用户做出快速、灵活的决策起到决定性的作用。如何建立正确的数据流和数据结构呢，为了避免认为错误并且加快进度，快来一起学习《大数据工具概览》的课程吧！\n本门课程针对大数据工具的四个部分进行详细分享：第一部分：大数据工具介绍，第二部分：数据生产与存储流程，第三部分：数据工具的使用与流程展示，第四部分：如何判断加强哪些数据能力\n\n\n本节课程是由授课老师与三节课合作制作的。在此，要特别感谢老师的辛苦付出！经历了课程立项、设计、开发中的众多环节，我们才能最终为你呈现现在的这门课程。无论是授课老师还是三节课团队，都希望这门课程能够让你有所收获，希望同学们结合个人工作情况，学以致用。\n本课程版权归三节课所有，未经书面同意私自录制、转载等行为均属侵权行为。课程内的所有内容，包括但不限于视频、文字、图片均由三节课公司或其他权利人依法拥有其知识产权，包括但不限于著作权、商标权、专利权等。未经三节课公司的明确书面特别授权，任何人不得为任何目的使用以及向任何自然人或单位提供出售、营销、出版或利用三节课官网上提供的任何内容或服务。如有违反，您将承担由此给三节课公司或其他权利人造成的一切损失。",
      "target_audience": [
        "1.0-1岁数据分析新人",
        "2.想要进入大数据领域的互联网从业者",
        "3.对大数据工具感兴趣的学习者"
      ]
    },
    {
      "title": "ChatBots meistern: KI-Apps mit ChatGPT | Business & Privat",
      "url": "https://www.udemy.com/course/chatbots-meistern-ki-apps-mit-chatgpt-business-privat/",
      "bio": "No Code AI-Apps: Chatbots mit Flowise, ChatGPT & LLMs, LangChain, OpenAI API & Github | Business, für dich & zum Verkauf",
      "objectives": [
        "Entdecke die Kunst, ChatBots individuell und passgenau für deine spezifischen Anforderungen zu trainieren.",
        "Lerne Flowise und LangChain kennen und Baue deine Apps damit",
        "Eigne dir Meisterschaft in Low- und No-Code-Lösungen an, um eigene Bots kreativ zu gestalten.",
        "Erfahre, was Fine-Tuning ist und wie es funktioniert",
        "Entdecke Render und Hoste deine App damit",
        "Lerne, wie du deine Chatbots nahtlos in Webseiten integrieren kannst, um eine benutzerfreundliche Erfahrung zu schaffen.",
        "Tauche ein in die Welt der Language Modelle und entdecke, wie LLMs funktionieren.",
        "Begreife die Bedeutung von Token und verstehe, wie sie die Erinnerungsfähigkeit von LLMs beeinflussen, sowie Strategien, um das zu überwinden.",
        "Erlerne die Kunst der Angebotserstellung, optimiere es und erfahre, wie du wirklichen Wert schaffen kannst.",
        "Perfektioniere die Vermarktungsstrategien deiner Produkte, um in einem umkämpften Markt herauszustechen.",
        "Erhalte umfassende Einblicke in den Verkaufsprozess von Bots und anderen Produkten.",
        "Lerne, wie du ein erfolgreiches Business durch den Verkauf von Chatbots aufbauen kannst.",
        "Entdecke, wie soziale Medien effektiv zur Steigerung deiner Geschäftserfolge beitragen können.",
        "Erfahre, wie du ansprechenden und effektiven Content für Plattformen wie YouTube, Instagram, TikTok und mehr erstellen kannst.",
        "Verstehe die Kunst, die richtigen Kunden zu identifizieren und erfolgreich anzusprechen.",
        "Lerne, AI-Agenten mit Microsoft Autogen zu bauen",
        "Tauche ein in die Grundlagen bezahlter Werbung und lerne, wie du mit Paid Ads erfolgreich werben kannst.",
        "Lerne ChatGPT und seine grundlegenden Funktionen intensiv kennen, um das Beste aus diesem Tool herauszuholen.",
        "Erfahre alles Wissenswerte über Plugins und wie sie dein Projekt bereichern können.",
        "Nutze DALL·E 3 effektiv, um deine Projekte innovativ zu gestalten.",
        "Erkunde ChatGPT Vision und entdecke die Bedeutung und das Potenzial von Multimodalität.",
        "Lerne, fortgeschrittene Datenanalysen in ChatGPT anzuwenden, um tiefere Einsichten zu gewinnen.",
        "Erfahre, was Github ist und Kopiere den Code"
      ],
      "course_content": {
        "Einführung": [
          "Willkommen",
          "Kurs Überblick",
          "Mein Ziel, was dich erwartet & ein Tipp",
          "Dein erster ChatBot zum testen und nachbauen",
          "Wie funktioniert ein LLm was sind Token & warum ist das wichtig für den ChatBot",
          "Wichtige Links",
          "Wichtige Updates",
          "Dozentenvorstellung: Arnold Oberleiter (Arnie)"
        ],
        "Erstellen vom ChatBot mit Flowise [Wir bauen unsere APP]": [
          "Was erstellen wir eigentlich? [Wie wird die APP aufgebaut]",
          "Hier hosten wir unsere APP (Die Anmeldung bei Render)",
          "Was ist Github und wie melde ich mich an",
          "Flowise Forken und den Web Service erstellen in Render",
          "Die nächsten Schritte & die lokale Installation von Flowise",
          "Hilfe! Render funktioniert nicht.",
          "Erstellen der KI App anhand einer Vorlage",
          "Wie verknüpfe ich ChatGPT [GPT 3,5 Turobo] mit unserer APP & was sind API Keys",
          "Vector Database in unsere APP intigrieren über die Pinecone API",
          "Probleme bei Pinecone Embeddings",
          "Trainiere den ChatBot an Text, Video, Pdfs oder Docs",
          "ChatBot Fine-Tuning: Die letzten Einstellungen",
          "Teste den ChatBot in deinem Browser",
          "Den Bot in eine Webseite einabuen [Die wir sogar gemeinsam erstellen]",
          "Was kann Flowise sonst noch?",
          "Die Defninition von Lernen & bist du ein guter Lerner?",
          "ChatBots über die Assistant API & der GPT Store: GPTs um Geld zu verdienen",
          "Was wenn mein Bot nicht funktioniert? Billing AAC, Rate Limits und Kosten",
          "Gratis ChatBot mit Opensource LLMs auf Huggingface",
          "Schnelle Inferenz mit der Groq-API",
          "Recap, was hat OpenAI gekoster & Ausblick"
        ],
        "ChatBots verkaufen: Wie kannst du das Angebot machen": [
          "Wourm geht es hier?",
          "Das Angebot: Wie wird es aufgebaut",
          "Der Preis: Wann kaufen leute Zeug von dir [Wie viel Geld sollst du verlangen]",
          "Die Psychologie des Preises & wie du durch hohe Preise bessere Produkte hast",
          "Wie schaffst du Wert damit du den hohen Preis rechtfertigen kannst",
          "Das Kernprinzip von einem guten Angebot",
          "6 Tipps für ein besseres Angebot",
          "Der Bonus im Detail & warum du einen einbauen solltest!"
        ],
        "Marketing: wie kannst du diene ChatBots vermarkten?": [
          "Marketing: Das WICHTIGSTE zuerst!",
          "Du brauchst Kontakte die sich für ChatBots interessieren",
          "An wen und WIE kann ich vermarkten & verkaufen",
          "Starte damit: Verkaufe an Leute die du kennst!",
          "Kaltaquiese: Verkaufe an Leute die du nicht kennst",
          "Du solltest Content machen auf Instagram, Youtube, TickTok, Twitter [X]...",
          "Wie kannst du deinen Content auf Social Media machen?",
          "Content monetarisieren: Wann, Wie & Wie oft sollst du \"pitchen\"",
          "So könntest du all das umsetzen und auf Social Media durchstarten",
          "Bezahlte Werbung [ADS]: Die Grundlagen",
          "Bezahlte Werbung [ADS] strukturieren",
          "Effizienz & Skalierung der Werbung um Geld zu verdienen",
          "WICHTIG: Risiken minimieren bei deinen Ads",
          "Spare Werbebudget durch diesen Trick [Effiziente ADS druch Contetn]",
          "Recap & Ausblick"
        ],
        "Der Verkauf deiner Chatbots: Wichtige Tipps zum Verkaufen": [
          "Worum geht es hier? Der Verkauf!",
          "Der erste Teil des Verkaufgesprächs",
          "Verkaufe das Ergebniss und nicht den \"Weg\"",
          "Nach dem Verkauf & schließe nur mit den richtigen Kunden ab"
        ],
        "ChatGPT Basics": [
          "Worum geht es bei den ChatGPt Basics",
          "Neues Interface & mehr",
          "ChatGPT Plugins: Alles was du wissen musst",
          "ChatGPT Plugins sind offline!",
          "Brows with Bing: Live Internetdaten aus dem Web mit ChatGPT",
          "Dall-E 3 in ChatGPT ist der Wahnsinn",
          "ChatGPT ist Multimodel (kann sehen, sprechen & hören)",
          "5 Anwendungsbeispiele für ChatGPT mit Bing",
          "ChaGPT Vision im Überblick: Die 7 Säulen von ChatGPT Vision",
          "Beschreiben mit ChatGPT Vision",
          "Interpretieren mit ChatGPT Vision",
          "Vorschläge von ChatGPT V",
          "Inhalte konvertieren mit ChatGPT Vision",
          "Daten extrahieren mit GPTV",
          "ChatGPT Vision als Gehilfe in Programmen, bei Spielen oder im Alltag",
          "Bewertungen, Vergleiche & der Humor von ChatGPT V",
          "Wichtiges Update!!! Neues Interface & Möglichkeiten 08.11.2023",
          "Update Juni 2024: GPT-4 Omni",
          "Recap"
        ],
        "GPT spezial Anwendungen [Fine-Tuning & AI-Agenten]": [
          "Worum geht es im Abschnitt \"Spezial Anwendungen\"",
          "GPT trainieren: Fine Tuning, MemGPT & Sparce Prime Representation",
          "AI Agents bauen mit Microsoft Autogen"
        ],
        "Wie geht es weiter": [
          "Wie geht es weiter & mein Danke!",
          "Bonus"
        ]
      },
      "requirements": [
        "Keine Sorge, Programmierkenntnisse sind nicht erforderlich! Wir werden alles gemeinsam, Schritt für Schritt, lernen und meistern."
      ],
      "description": "Willkommen zu \"ChatBots meistern: KI Apps mit ChatGPT | Business & Privat\": Entdecke die transformative Kraft der Chatbots und Language Modelle!\nIn diesem Kurs tauchst du tief in die Welt der Chatbots, KI und Language Modelle ein, um ein erfolgreiches Business rund um innovative Bot-Lösungen aufzubauen und zu skalieren.\nStell dir vor, du könntest:\nChatBots individuell und effizient nach deinen spezifischen Anforderungen trainieren und gestalten.\nApps kreativ mit den neuesten Low- und No-Code-Lösungen wie Flowise und LangChain entwickeln und optimieren.\nMeisterhafte Bots kreieren, die in Webseiten nahtlos integriert sind, und dabei eine außerordentliche Benutzererfahrung bieten.\nDieser Kurs wird dir eine Fülle von Strategien, Tools und Techniken offerieren:\nBot-Entwicklung & KI: Erwerbe fundiertes Wissen über ChatGPT, DALL·E 3, und andere innovative KI-Tools, und lerne, wie du sie effektiv in deinen Projekten einsetzen kannst.\nIntegration & Hosting: Entdecke Render und lerne, wie du deine Apps hosten und sie nahtlos in Webseiten integrieren kannst, um ein kraftvolles Nutzererlebnis zu schaffen.\nMarketing & Vertrieb: Eigne dir bewährte Marketing- und Verkaufsstrategien an, und lerne, wie du deine Bots und Produkte im hart umkämpften Markt erfolgreich positionierst.\nContent-Erstellung: Entdecke die Kunst, ansprechenden und wirkungsvollen Content für Plattformen wie YouTube, Instagram und TikTok zu kreieren, um dein Business voranzutreiben.\nAdvanced Skills: Tauche tief in fortgeschrittene Techniken und Konzepte wie Tokens, Multimodalität, Datenanalyse mit ChatGPT, Fine Tuning deiner eigenen Modelle und AI-Agenten mit Microsoft Autogen ein, um tiefgreifende und wertvolle Einsichten für deine Projekte zu gewinnen.\nDieser Kurs ist ideal für Unternehmer, Entwickler, Marketingprofis und alle, die in der Welt der Chatbots und KI erfolgreich sein möchten, geeignet.\nIn diesem Kurs wirst du:\nEine transformative Reise durch die Welt der Chatbots und KI-Technologie erleben und lernen, wie du mächtige und effektive Bots kreierst.\nTiefgreifende Kenntnisse und Fähigkeiten erwerben, die dich befähigen, im Bereich der Chatbots und KI erfolgreich zu sein.\nDein Business und deine Projekte mit innovativen Techniken, Strategien und Tools, die dir einen Vorsprung im digitalen Zeitalter bieten, revolutionieren.\nNutze diese einmalige Gelegenheit, die grenzenlosen Möglichkeiten der Chatbot- und KI-Technologie zu entdecken und deinen Traum von einem erfolgreichen Business in dieser aufregenden Branche zu verwirklichen.\nMelde dich noch heute für \"ChatBots meistern: KI Apps mit ChatGPT | Business & Privat\" an und beginne deine Reise zum Meister der Chatbots und KI-Technologie!",
      "target_audience": [
        "Für Unternehmer, die nach Wegen suchen, ihre Effizienz zu steigern und gleichzeitig Kosten zu sparen.",
        "Für all diejenigen, die von künstlicher Intelligenz fasziniert sind und einen Blick in die Zukunft der Technologie werfen möchten.",
        "Für alle Neugierigen, die stets bereit sind, Neues zu lernen und ihr Wissen zu erweitern."
      ]
    },
    {
      "title": "Construye tu primer red neuronal en menos de 1 hora!!",
      "url": "https://www.udemy.com/course/construye-tu-primer-red-neuronal-en-menos-de-1-hora/",
      "bio": "Cómo construir tu primer red neuronal Redes neuronales con Python en menos de una hora!!",
      "objectives": [
        "Redes neuronales",
        "Machine Learning",
        "Aprendizaje Supervisado",
        "Inteligencia artificial"
      ],
      "course_content": {
        "Introducción": [
          "Introducción"
        ],
        "Teoría": [
          "Que es une neurona",
          "Aprendizaje supervisado",
          "Problema a resolver",
          "Similitud entre lo biológico y lo artificial",
          "Función de activación",
          "Función de costo o error",
          "Ajuste de pesos y gradiente",
          "Épocas"
        ],
        "Construyendo la red": [
          "Entradas y pesos",
          "Sumatoria",
          "Función de activación sigmoide",
          "Respuesta de la red",
          "Entrenamiento y error",
          "Gradiente",
          "Ajuste de pesos",
          "Poniendo a prueba la red",
          "Bias"
        ]
      },
      "requirements": [
        "Conocimiento básico de Python"
      ],
      "description": "Las redes neuronales han tenido un gran auge estos últimos años, debido a su gran potencial para resolver problemas, muchas empresas como Netflix, Youtube y Google están haciendo uso de estas  día con día.\nEn este curso aprenderas cómo construir una red neuronal en menos de 1 hora usando Python. Todo esto sin librerías como Keras o software como Rapidminer, esto con la intención de que comprendas el funcionamiento interno de una red neuronal. Además no veremos matemáticas de alto nivel, todo será con fórmulas muy fáciles que cualquier persona puede entender  e implementar en código. Todo en menos de 1 hora!!\nQue estas esperando…",
      "target_audience": [
        "Cualquier persona interesada en Machine Learning o redes neuronales."
      ]
    },
    {
      "title": "Data science - Découverte de la librairie Pandas pour python",
      "url": "https://www.udemy.com/course/formation-machine-learning-pandas-pour-python/",
      "bio": "Apprenez à utiliser la puissance de Pandas pour le machine learning",
      "objectives": [
        "Vous allez apprendre à utiliser un notebook jupyter.",
        "Vous allez apprendre à utiliser une Série Pandas",
        "Vous allez apprendre à utiliser un DataFrame Pandas"
      ],
      "course_content": {
        "Introduction": [
          "Introduction",
          "Présentation de Jupyter"
        ],
        "Utilisation de Jupyter notebook": [
          "Installation rapide de Jupyter",
          "Création de votre 1° notebook",
          "Fonctionnement de Jupyter",
          "Mise en page avec Markdown",
          "Fonctionnement des cellules",
          "Exemple d'analyse"
        ],
        "Paramétrage": [
          "Détail des options",
          "Notebooks sur la personnalisation"
        ],
        "L'objet Series partie 1": [
          "Présentation de l'objet Series",
          "Création et initialisation d'une série et de son index",
          "Exemples avancés de création de série",
          "Importation d'une série depuis un csv",
          "Importer un fichier csv",
          "En-tête et queue d'une serie",
          "Création d'un objet Series",
          "Début et fin d'un objet Series",
          "La taille, la forme et les valeurs",
          "Créer un objet Series",
          "Document pédagogique"
        ],
        "Objet Series Partie 2": [
          "Fonction dtype",
          "Méthodes usuelles fonction build-in max, min, len",
          "Méthodes usuelles",
          "Réindexation d'un objet Serie",
          "Réindexation d'un objet Series",
          "Comment trier un objet Series sur ses valeurs",
          "Comment trier un objet Series depuis son index",
          "Comment récupérer des valeurs dans un objet Series",
          "Alignement via des étiquettes d'index",
          "Opérations arithmétiques sur un objet Series",
          "Le cas particulier du Not-A-Number (NaN)",
          "Sélection avec des booléens",
          "Opérations arithmétiques",
          "Document pédagogique"
        ],
        "Objet Series partie 3": [
          "Extraire une série en fonction de son index",
          "Modifier une série",
          "Découper une série",
          "Utiliser la fonction apply",
          "Méthode .map()",
          "Comment changer le type d'une série",
          "Comment récupérer des valeurs dans un objet Series 2° méthode",
          "Apprendre à compter des valeurs différentes",
          "Quel est l'index de la valeur max ou min d'un objet Series ?",
          "Document pédagogique",
          "Notebook sur les Séries"
        ],
        "Objet DataFrame Partie 1": [
          "Présentation des dataframe",
          "Création d'un DataFrame",
          "Import d'un fichier excel",
          "Fonctions usuelles de gestion des colonnes",
          "Apprendre à renommer une ou des colonnes",
          "Comment sélectionner une colonne",
          "Comment sélectionner plusieurs colonnes",
          "Comment insérer, ajouter une nouvelle colonne",
          "Comment modifier le contenu d'une colonne",
          "Découvrir comment supprimer des colonnes",
          "Ajouter des lignes",
          "Supprimer des lignes",
          "Supprimer des lignes ou des colonnes avec des valeurs NaN",
          "Supprimer des lignes par sélection Booleen",
          "Suppression de lignes par découpage",
          "Comment changer la valeur d'une cellule",
          "Comment savoir si il y a des valeurs NaN",
          "Comment remplacer des valeurs NaN",
          "Comment modifier en masse des données",
          "Utiliser describe",
          "Document pédagogique"
        ],
        "Objet DataFrame partie 2": [
          "Apprendre à changer le type d'une colonne",
          "Comment Trier un DataFrame sur ses valeurs",
          "Comment trier un DataFrame sur son index",
          "Quel est le rang d'une valeur dans une colonne ?",
          "Filtrer un DataFrame avec une condition",
          "Filtrer un DataFrame avec plusieurs conditions AND",
          "Une valeur est elle présente",
          "Comment sélectionner des lignes entre deux valeurs",
          "Comment gérer les doublons",
          "Trouver les valeurs uniques",
          "Sélectionner une colonne comme index",
          "Comment trouver une ligne avec le libellé de son index",
          "Comment trouver une ligne avec la position de son index",
          "Mise en forme de la recherche",
          "Attribuer de nouvelles valeurs à une cellule",
          "Comment renommer des colonnes",
          "Comment renommer les labels des index",
          "Comment extraire un échantillon aléatoire",
          "Comment trouver les plus grandes ou les plus petites valeurs d'une colonne",
          "Filtrer en utilisant la fonction .where",
          "Filtrer en utilisant la fonction .query",
          "Modifier toutes les valeurs d'une colonne",
          "Manipulations depuis différentes colonnes",
          "Toujours travailler sur une copie",
          "Document pédagogique"
        ],
        "Travailler avec des chaines": [
          "Méthodes usuelles sur les chaines",
          "Filtrer en fonction du contenu d'une chaîne",
          "Supprimer les espaces dans une chaîne",
          "Créer des sous chaines",
          "Document pédagogique"
        ],
        "Utilisation du multiIndex": [
          "Créer un index avec plusieurs colonnes",
          "Comment récupérer les valeurs d'un index",
          "Comment changer les libellés de l'index",
          "Trier un DataFrame sur son index",
          "Comment extraire des lignes avec un multi index",
          "Comment transposer un DataFrame",
          "Changer la présentation d'un multiindex",
          "Créer un pivot",
          "Agréger des résultats",
          "Document pédagogique"
        ]
      },
      "requirements": [
        "Il faut être familiarisé avec la syntaxe de base du langage python."
      ],
      "description": "Bienvenue au cours Pandas les plus complet en Français !\nUn excellent choix pour les débutants qui cherchent à découvrir l'une des bibliothèques Python les plus populaires dans le monde !\nL'analyse des données avec Pandas et Python offre plus de 10 heures de tutoriels vidéo approfondis sur la librairie d'analyse de données la plus puissante actuellement disponible.\n\n\n\n\nCe cours vous fera découvrir :\nL’utilisation des objets Pandas dans notebook jupyter\nLes Series\nLes DataFrames\nLes tris\nLes filtres\nLes  graphiques\nLes imports de fichiers\nLa manipulation des données\nEtc, etc…\nEt bien plus encore !\nVous avez absolument besoin de connaître Pandas !\nSi vous analysez des données avec vos tableurs habituels, vous augmenterez grandement vos compétences en analyse de données en utilisant Pandas. Ce cours sera parfait pour vous !\nPython est un langage très simple à apprendre.  Avec Pandas, cela en fait un outil très puissant pour l’analyse de vos données et pour accéder ensuite à l'intelligence artificielle.\nPandas est un outil indispensable qui vous permet de faire tout ce que vous voulez avec vos données.\nQuelques chiffres sur ce cours\n+ de 10 heures de vidéo\n17 chapitres\n+ de 20 exercices pratiques\n6 exemples complets de mise en application (1h30 de vidéo)\nUne communauté sans cesse croissante\nQuel est mon but ?\nPython et Pandas sont très demandés actuellement sur le marché du travail. Mon but est de vous fournir les connaissances nécessaires pour être apte à utiliser cette librairie dans votre société ou de postuler pour un nouvel emploi. Cette formation pourrait être l’investissement le plus rentable de votre vie !\nPendant plus de 10 heures, vous serez guidé pas à pas.\nVous découvrirez toute la puissance de Pandas et ses nombreuses fonctions.\nJe vous donnerai l’astuce pour accéder à une quantité incroyable de données françaises réelles.\nDans ce cours sur Pandas, vous aurez accès à des exemples concrets  de mise en pratique.\nVous trouverez également des dizaines d’exercices pour valider vos connaissances.\nMais SURTOUT !\nC’est un cours vivant et en perpétuel renouvellement. Pandas est une librairie avec des mises à jour régulières.\nAu fur et à mesure des mises à jour, vous aurez accès à de nouvelles vidéos, à de nouveaux exercices, à de nouvelles ressources.\nEn achetant ce cours une seule fois vous êtes certains d’être TOUJOURS à jour de vos connaissances.\nCe cours est aussi le vôtre !\nN’hésitez pas à poser vos questions, vos remarques directement dans l’interface Udemy.\nQuel est le public ciblé ?\nVous êtes intéressé par l’analyse des données\nLes utilisateurs d'Excel à la recherche d'un logiciel plus puissant pour l'analyse de données\nToute personne intéressée par la manipulation des données\nDernière remarque\nLa connaissance de Pandas est indispensable pour toute étude sérieuse de l’analyse des données et de l'IA. C’est la première brique de votre maison « Analyse des données ». Inutile d’apprendre les réseaux de neurones si vous ne savez pas utiliser Pandas ! C'est la brique indispensable pour faire du machine learning.",
      "target_audience": [
        "Développeurs python débutants qui veulent en savoir plus sur la science de données.",
        "Toute personne souhaitant découvrir les possibilités offertes par la librairie Pandas pour le data mining"
      ]
    },
    {
      "title": "Stimmen klonen mit Deep Learning in Python",
      "url": "https://www.udemy.com/course/voice-cloning/",
      "bio": "Imitiere jede beliebige Stimme mit nur 5 Sekunden Sprachaufnahme",
      "objectives": [
        "Trainieren von KI Modellen zum Klonen der eigenen Stimme",
        "Verstehen, was ein Encoder, Synthesizer und ein Vocoder macht",
        "Deep Learning in Python anzuwenden"
      ],
      "course_content": {},
      "requirements": [
        "Grundlagen von Python solllten beherrscht werden"
      ],
      "description": "Deep Learning ist dafür bekannt, bahnbrechende Ergebnisse in verschiedensten Disziplinen zu liefern - so auch in der Erzeugung von Sprache aus Text, dem sogenannten Text-To-Speech. In diesem Kurs werdet ihr lernen, wie man beliebige Stimmen klont und eine Anwendung schreibt, die mit einer kurzen Audioaufnahme einer Stimme und einem Text eine Audiodatei erzeugt, die genau diesen Text mit der angegebenen Stimme spricht.\nKernthemen dieser Disziplin sind:\nBeschaffung und Formatierung der Trainingsdaten, um die neuronalen Netze zu trainieren.\nDurchführung des Trainings eines Encoders zur Erzeugung eines Embeddings für die Stimmen der Sprecher\nDurchführen des Trainings eines Synthesizers zur Erzeugung von Phonemen und Mel Spektrogrammen\nDurchführung des Trainings eines Vocoders zur Generierung von Wave-Daten aus Mel Spektrogrammen\nIst das geschafft, zeige ich euch, wie ihr die Modelle in einer UI ladet oder sie einfach per Python API aufruft.\nWir werden in diesem Kurs auf der Arbeit von Corentin Jemine (Real Time Voice Cloning) aufsetzen, um nicht ganz von vorne beginnen zu müssen. Wenn ihr das Framework bereits kennt, wird euch dieser Kurs bei der Anwendung auf die deutsche (oder jede beliebige andere) Sprache helfen. Alle Werkzeuge, die wir verwenden, sind frei zugänglich und open-source, sodass ihr bei Bedarf jede Funktion bis in ihre tiefsten Tiefen nachvollziehen könnt.\nEin kleiner Hinweis am Schluss: Dieser Kurs ist dafür gedacht Stimmen zu klonen, von deren Besitzern ihr die Zustimmung habt.",
      "target_audience": [
        "Python Entwickler",
        "Data Scientists",
        "Künstler"
      ]
    },
    {
      "title": "Spatial Data Science",
      "url": "https://www.udemy.com/course/spatial-data-science/",
      "bio": "Pelatihan Dasar mengenai Spatial Data Science",
      "objectives": [
        "Peserta mampu mengetahui dan memahami mengenai pengetahuan dasar mengenai spatial data science",
        "Peserta mampu mengetahui dan memahami mengenai metode dan alat-alat yang dapat diimplementasikan dalam analisis spatial data science",
        "Peserta mampu melakukan analisis data spatial data science",
        "Peserta mampu memanfaatkan dan menggunakan package-package yang tersedia dalam bahasa pemrograman python"
      ],
      "course_content": {
        "Pengenalan Spatial Data Science": [
          "Pengenalan Pelatihan",
          "Headline",
          "Sistem Informasi Geografis",
          "Komponen GIS",
          "Tipe Data GIS",
          "Manfaat GIS",
          "Quiz GIS",
          "Spatial Data Science",
          "Pentingnya Spatial Data Science",
          "Perbedaan Spatial Data Science dan Data Science",
          "Perbedaan Spatial Data Science dan GIS",
          "Quiz Spatial Data Science",
          "Metode Spatial Data Science",
          "Quiz Metode Spatial Data Science",
          "Tools Spatial Data Science",
          "Tools Spatial Data Science (Anaconda)",
          "Tools Spatial Data Science (R)",
          "Tools Spatial Data Science (GeoDa)",
          "Tools Spatial Data Science (PostGIS)",
          "Tools Spatial Data Science (PostgreSQL)",
          "Tools Spatial Data Science (ArcGIS)",
          "Tools Spatial Data Science (QGIS)",
          "Quiz Tools Spatial Data Science",
          "Library Package Python",
          "Quiz Library Package Python",
          "Library Package R",
          "Quiz Library Package R",
          "Data Latihan",
          "Kode Latihan",
          "Praktek Instalasi Anaconda dan Download data",
          "Praktek Spatial Data Science 1",
          "Praktek Spatial Data Science 2"
        ],
        "Python untuk Spatial Data Science": [
          "Pendahuluan dan Overview Pelatihan",
          "Persiapan Software dan Library Package",
          "Python Library Package",
          "Mengapa Menggunakan Python",
          "Geopandas",
          "Dependensi Geopandas",
          "Pengolahan Data dengan Library Geopandas",
          "Quiz GeoPandas",
          "Assignment",
          "Data Latihan",
          "Kode Latihan",
          "Praktek Membaca dan Menulis Data",
          "Praktek Mengelola Spatial Data Frame",
          "Praktek Fungsi Spasial di Geopandas",
          "Praktek Membuat Maps Plotting dan Overlay",
          "Praktek Melakukan Geocoding",
          "Quiz Pengolahan Data dengan Library Geopandas"
        ],
        "Exploratory Spatial Data Analysis": [
          "Pengantar Eksploratory Spatial Data Analysis (ESDA)",
          "Mengapa Melakukan Analisis Eksplorasi Data",
          "Exploratory Data Analysis (EDA) vs Exploratory Spatial Data Analysis (ESDA)",
          "Ekspolarsi Data Analisis (EDA)",
          "Python Library untuk Ekspolarsi Data Analisis",
          "Quiz Exploratory Spatial Data Analysis",
          "Penjelasan Ekspolarsi Spasial Data Analisis",
          "Quiz Eksplorasi Spatial Data Analisis",
          "Data Latihan",
          "Kode Latihan",
          "Praktek EDA - Instalasi Geopandas dan Seaborn",
          "Praktek EDA - Import dan Identifikasi Data",
          "Praktek EDA - Persiapan Ekspolarsi Data Analisis",
          "Praktek EDA - Ekspolarsi Data Analisis",
          "Praktek ESDA - Instalasi Python Library Ekspolarsi Spasial Data Analisis",
          "Praktek ESDA - Persiapan Ekspolarsi Spasial Data Analisis",
          "Praktek ESDA - Ekspolarsi Spasial Data Analisis"
        ],
        "Sistem Manajemen Basis Data": [
          "Pengenalan Sistem Manajemen Basis Data",
          "Overview",
          "Manajemen Data",
          "Sistem Manajemen Basis Data",
          "Sistem Manajemen Basis Data Spatial",
          "Perintah SQL",
          "Tools",
          "Tools PostgreSQL",
          "Tools PostGIS",
          "SQL Joins",
          "Spatial Query di PostgreSQL",
          "Quiz Sistem Manajemen Basis Data",
          "Study Case",
          "Data Latihan",
          "Kode Latihan",
          "Praktek PgAdmin",
          "Praktek Import ESRI .shp ke PostGIS",
          "Praktek Basic Query CRUD (Create Read Update dan Delete)",
          "Praktek SQL Join (Inner Join)",
          "Praktek SQL Joins (Right Left Full Join)",
          "Praktek Spatial Query PostgreSQL",
          "PostgreSQL dengan Jupyter",
          "Praktek Study Case"
        ]
      },
      "requirements": [
        "Tidak diperlukan pengalaman pemrograman"
      ],
      "description": "Spatial Data Science merupakan cabang ilmu dari data sains yang berfokus pada keunikan karakteristik data spasial, mempelajari suatu fenomena dari data terkait alasan fenomena tersebut terjadi di suatu lokasi. Pemahaman Spatial Data Science harus didukung oleh dasar-dasar pengetahuan mengenai Sistem Informasi Geografi (SIG), Geostatistik dan Geokomputasi.\nPemanfaatan bahasa pemrograman Python dalam Spatial Data Science melalui library package yang tersedia dapat mendukung proses analisis data spasial menjadi lebih efektif dan scalable. Pada training ini akan dipaparkan pengetahuan tentang penggunaan library package tersebut untuk mendukung salah satu proses yang dibutuhkan dalam Spatial data science yaitu proses reformat dan cleaning data. proses tersebut menjadi sangat penting dalam tahap persiapan menuju proses selanjutnya dalam Spatial Data Science.\nPada pelatihan ini akan dipaparkan secara umum mengenai Spatial Data Science, GIS, metode dan alat yang digunakan dalam spatial data science serta melakukan analisis data spasial menggunakan package-package yang tersedia dalam bahasa pemrograman Python.\nPada akhir training ini juga akan diperlihatkan langkah-langkah penggunaan python dalam spatial data science pada suatu studi kasus serta melakukan assignment guna mengimplementasikan hasil pembelajaran pada suatu data spasial yang akan disediakan.\nPelatihan terdiri dari :\n1. Pengenalan Spatial Data Science\n2. Python untuk Spatial Data Science\n3. Eksplorasi Karakteristik Data Spasial\n4. Sistem Manajemen Basis Data",
      "target_audience": [
        "Peserta dengan latar belakang SIG/Geografi/Kartografi dan Penginderaan Jauh/Geografi Lingkungan/Pengembangan Wilayah/Geodesi/ Geomatika"
      ]
    },
    {
      "title": "ChatGPT - الدورة العربية الأولى في شرح واستخدام ChatGPT",
      "url": "https://www.udemy.com/course/arabic-chatgpt/",
      "bio": "أول دورة عربية في شرح واستخدام والإستفادة من الذكاء الأصطناعي ChatGPT في جميع المجالات",
      "objectives": [
        "إنشاء حساب في ChatGPT",
        "تسجيل الدخول إلى ChatGPT",
        "استعراض شاشة ChatGPT",
        "استخدام ChatGPT عن طريق بوتات Telegram",
        "كتابة المحادثات والقصائد والرسائل وحتى الشعر بستخدام ChatGPT",
        "البرمجة بستخدام ChatGPT",
        "إنشاء إضافة لمتصفح كروم بستخدام ChatGPT",
        "تصحيح الأكواد بستخدام ChatGPT",
        "كتابة ملفات json وقواعد البيانات باستخدام ChatGPT",
        "كتابة المقالات والأوصاف بستخدام ChatGPT",
        "البحث عن دوال Excel بستخدام ChatGPT",
        "التعلم من ChatGPT",
        "شرح الدوال البرمجية والقواعد اللغوية بستخدام ChatGPT",
        "البحث عن المعلومات العامة بستخدام ChatGPT",
        "كتابة خطاب إلى شركة بستخدام ChatGPT",
        "كتابة سيرة ذاتية بستخدام ChatGPT",
        "كتابة ملفات Excel بستخدام ChatGPT",
        "كتابة وصف برنامج بستخدام ChatGPT",
        "كتابة وصف لمنتج بستخدام ChatGPT",
        "الترجمة بستخدام ChatGPT"
      ],
      "course_content": {},
      "requirements": [
        "الوصول للأنترنت من خلال أي جهاز"
      ],
      "description": "ChatGPT - الدورة العربية الأولى في شرح واستخدام ChatGPT\n\n\nهل أنت مهتم بتعلم كيفية استخدام ChatGPT، البوت الرائع الذي قامت بتصميمه شركة openai, إذن، أنت في المكان المناسب.\n\n\nفي هذه الدورة، ستتعلم طريقة تشغيل ChatGPT من البداية، حيث سنتناول إنشاء حساب وتسجيل الدخول والكثير من الأمور الرائعة المختلفة. باستخدام ChatGPT، يمكنك التعرف والإستفادة من مجموعة كبيرة من الموضوعات، بما في ذلك العلوم والتاريخ والأدب والمزيد. يمكنك أيضًا تحسين مفرداتك ومهاراتك اللغوية، والحصول على تفسيرات وتعريفات للمفاهيم المعقدة، والبقاء على اطلاع دائم بالأحداث والأخبار الجارية، وحتى تلقي النصائح والإرشادات حول التطوير الشخصي والمهني.\n\n\nليس هذا فحسب، بل يمكنك أيضا الإستفادة من ChatGPT في عملية التطوير البرمجي، وشرح الدوال المعقدة، وكتابة السيرة الذاتية، والرسائل الشخصية. أيضا، يمكنك الإستفادة من ChatGPT في الترفيه عن نفسك بالدردشة معه كأنهُ أحد أصدقائك، بل حتى يمكنك أن تطلب منه أن يحكي لك قصة، أو يكتب لك قصيدة، أو يساعدك في تأليف رواية.\n\n\nومن الأشياء الرائعة أيضا، أنهُ يمكنك استخدامه في كتابة المقالات والأبحاث والقصص وأوصاف المنتجات بل وتقييمها أيضا بنائا على المعلومات التي تعطيها له حول المنتج.\n\n\nوسنرا أشياء كثيرة جدا ورائعة يمكننا الاستفادة من ChatGPT في الوصول إليها.\n\n\nChatGPT هو أحد أشكال GPT-3، وهو معروف بقدرته على المشاركة في محادثات اللغة الطبيعية مع البشر. هذا يجعله مثاليًا لتطبيقات chatbot، حيث يمكنه كتابة ردود شبه طبيعية وشبيهة بما يكتبه أي شخص عادي. كما أنها قادرة على التعامل مع مجموعة واسعة من الموضوعات، وذلك بفضل تدريبها على مجموعة بيانات متنوعة وكبيرة جدا، مما يجعلها مفيدة لمهام مثل إنشاء المحتوى الكتابي والتعليمي كما سنرا في الدورة التدريبية الخاصة بنا.\n\n\nأشياء يمكنك الإستفادة من ChatGPT فيها\nمعرفة عامة وحقائق حول مجموعة واسعة من الموضوعات، بما في ذلك العلوم والتاريخ والأدب وغير ذلك\n\n\nاستخدام المفردات اللغوية، بما في ذلك تعريفات الكلمات والعبارات، ونصائح للتواصل الفعال مع الآخرين.\n\n\nشروحات وتعريفات للمفاهيم والأفكار المعقدة\n\n\nمعلومات حول الأحداث والأخبار الجارية\n\n\nالنصح والإرشاد في مختلف الموضوعات، بما في ذلك التطوير الشخصي والمهني\n\n\nيمكن أن يوفر أيضًا توضيحًا ومزيدًا من المعلومات حول الموضوعات التي يتعلمها الأشخاص بالفعل، أو مساعدتهم على فهم المواد الصعبة عن طريق تقسيمها إلى أجزاء أكثر قابلية للفهم.\n\n\nبعض الموضوعات التي سنتعرف عليها في هذه الدورة:\nدردشة عامة مع ChatGPT\nكتابة رسالة إلى صديقي عن طريق ChatGPT\nمعرفة معلومات عامة بواسطة ChatGPT\nكتابة قصيدة بستخدام ChatGPT\nإنشاء برنامج عداد الكلمات والجمل  بستخدام ChatGPT\nتصحيح كود بستخدام ChatGPT\nإنشاء دالة عن طريق ChatGPT\nإنشاء إضافة لمتصفح Chrome بستخدام ChatGPT\nإنشاء برنامج معرفة معلومات الحاسوب بستخدام ChatGPT\nإنشاء صفحة تسجيل الدخول بستخدام ChatGPT\nإنشاء form إنشاء حساب بستخدام html, css, php, and sql\nإنشاء ملف Json بستخدام ChatGPT\nكتابة خطاب إلى شركة بستخدام ChatGPT\nكتابة سيرة ذاتية بستخدام ChatGPT\nكتابة مقال بستخدام ChatGPT\nكتابة ملفات Excel بستخدام ChatGPT\nكتابة وصف برنامج بستخدام ChatGPT\nكتابة وصف لمنتج بستخدام ChatGPT\nالترجمة بستخدام ChatGPT",
      "target_audience": [
        "أي شخص سمع عن ChatGPT",
        "أي شخص يريد تجربة ChatGPT",
        "أي شخص يحب الذكاء الاستناعي وبرامجه",
        "أي شخص يريد الإستفادة من الذكاء الإصطناعي في حياته العملية والمهنية"
      ]
    }
  ]
}